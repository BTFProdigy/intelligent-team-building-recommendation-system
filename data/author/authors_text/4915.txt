Proceedings of the 43rd Annual Meeting of the ACL, pages 467?474,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Alignment Model Adaptation for Domain-Specific Word Alignment 
WU Hua, WANG Haifeng, LIU Zhanyi 
Toshiba (China) Research and Development Center 
5/F., Tower W2, Oriental Plaza 
No.1, East Chang An Ave., Dong Cheng District 
Beijing, 100738, China  
{wuhua, wanghaifeng, liuzhanyi}@rdc.toshiba.com.cn   
 
Abstract 
This paper proposes an alignment 
adaptation approach to improve 
domain-specific (in-domain) word 
alignment. The basic idea of alignment 
adaptation is to use out-of-domain corpus 
to improve in-domain word alignment 
results. In this paper, we first train two 
statistical word alignment models with the 
large-scale out-of-domain corpus and the 
small-scale in-domain corpus respectively, 
and then interpolate these two models to 
improve the domain-specific word 
alignment. Experimental results show that 
our approach improves domain-specific 
word alignment in terms of both precision 
and recall, achieving a relative error rate 
reduction of 6.56% as compared with the 
state-of-the-art technologies. 
1 Introduction 
Word alignment was first proposed as an 
intermediate result of statistical machine 
translation (Brown et al, 1993). In recent years, 
many researchers have employed statistical models 
(Wu, 1997; Och and Ney, 2003; Cherry and Lin, 
2003) or association measures  (Smadja et al, 
1996; Ahrenberg et al, 1998; Tufis and Barbu, 
2002) to build alignment links. In order to achieve 
satisfactory results, all of these methods require a 
large-scale bilingual corpus for training. When the 
large-scale bilingual corpus is not available, some 
researchers use existing dictionaries to improve 
word alignment (Ker and Chang, 1997). However, 
only a few studies (Wu and Wang, 2004) directly 
address the problem of domain-specific word 
alignment when neither the large-scale 
domain-specific bilingual corpus nor the 
domain-specific translation dictionary is available. 
In this paper, we address the problem of word 
alignment in a specific domain, in which only a 
small-scale corpus is available. In the 
domain-specific (in-domain) corpus, there are two 
kinds of words: general words, which also 
frequently occur in the out-of-domain corpus, and 
domain-specific words, which only occur in the 
specific domain. Thus, we can use the 
out-of-domain bilingual corpus to improve the 
alignment for general words and use the in-domain 
bilingual corpus for domain-specific words. We 
implement this by using alignment model 
adaptation. 
Although the adaptation technology is widely 
used for other tasks such as language modeling 
(Iyer et al, 1997), only a few studies, to the best of 
our knowledge, directly address word alignment 
adaptation. Wu and Wang (2004) adapted the 
alignment results obtained with the out-of-domain 
corpus to the results obtained with the in-domain 
corpus. This method first trained two models and 
two translation dictionaries with the in-domain 
corpus and the out-of-domain corpus, respectively. 
Then these two models were applied to the 
in-domain corpus to get different results. The 
trained translation dictionaries were used to select 
alignment links from these different results. Thus, 
this method performed adaptation through result 
combination. The experimental results showed a 
significant error rate reduction as compared with 
the method directly combining the two corpora as 
training data.  
In this paper, we improve domain-specific word 
alignment through statistical alignment model 
adaptation instead of result adaptation. Our method 
includes the following steps: (1) two word 
alignment models are trained using a small-scale 
in-domain bilingual corpus and a large-scale 
467
out-of-domain bilingual corpus, respectively. (2) A 
new alignment model is built by interpolating the 
two trained models. (3) A translation dictionary is 
also built by interpolating the two dictionaries that 
are trained from the two training corpora. (4) The 
new alignment model and the translation dictionary 
are employed to improve domain-specific word 
alignment results. Experimental results show that 
our approach improves domain-specific word 
alignment in terms of both precision and recall, 
achieving a relative error rate reduction of 6.56% 
as compared with the state-of-the-art technologies. 
The remainder of the paper is organized as 
follows. Section 2 introduces the statistical word 
alignment model. Section 3 describes our 
alignment model adaptation method. Section 4 
describes the method used to build the translation 
dictionary. Section 5 describes the model 
adaptation algorithm. Section 6 presents the 
evaluation results. The last section concludes our 
approach. 
2 Statistical Word Alignment 
According to the IBM models (Brown et al, 1993), 
the statistical word alignment model can be 
generally represented as in Equation (1).  
?=
'
)|,'(
)|,(
),|(
a
ap
ap
ap
ef
efef  (1)
In this paper, we use a simplified IBM model 4 
(Al-Onaizan et al, 1999), which is shown in 
Equation (2). This simplified version does not take 
word classes into account as described in (Brown 
et al, 1993). 
))))(()](([                  
))()](([(                    
)|( )|(                     
                 
)|,Pr()|,(
0,1
1
0,1
1
11
1
2
0
0
0
),(
00
?
?
??
?
?=
>
?=
==
?
???
+??=
??
????
?
???
? ?=
=
m
aj
j
m
aj
j
m
j
aj
l
i
ii
m
j
j
ja
j
jpjdahj
cjdahj
eften
pp
m
ap
?
??
??
?
?
?
?? eef
 
(2)
ml,  are the lengths of the target sentence and the  
source sentence respectively. 
j  is the position index of the source word. 
ja  is the position of the target word aligned to 
    the jth source word. 
i?  is the fertility of . ie
1p  is the fertility probability for e , and 
. 
0
110 =+ pp
)
jaj|et(f  is the word translation probability. 
)|( ii en ?  is the fertility probability. 
)(1 jacjd ??  is the distortion probability for the  
head of each cept1. 
))((1 jpjd ?>  is the distortion probability for the  
remaining words of the cept. 
}:{min)( kk
aikih == is the head of cept i. 
}:{max)( kj
jk
aakjp ==
<
 
i?  is the first word before  with non-zero 
fertility. If , 
; else . 
ie
0?
}i
0|}0:{| '' ' ><<> iii i?
00 'i <<? 0=i?:max{ ' 'i ii >= ??
i
j j
i
jia
c ?
? ?== ][  is the center of cept i. 
During the training process, IBM model 3 is 
first trained, and then the parameters in model 3 
are employed to train model 4. During the testing 
process, the trained model 3 is also used to get an 
initial alignment result, and then the trained model 
4 is employed to improve this alignment result. For 
convenience, we describe model 3 in Equation (3). 
The main difference between model 3 and model 4 
lies in the calculation of distortion probability. 
??
??
?
?=
==
?
?
??
????
?
???
? ?=
=
m
aj
j
m
j
aj
l
i
i
l
i
ii
m
j
j
mlajdeft
en
pp
m
ap
0:1
11
1
2
0
0
0
),(
),,|()|(                     
!  )|(                     
                   
)|,Pr()|,(
00
??
?
?
??
??
??
eef
(3)
                                                           
1 A cept is defined as the set of target words connected to a source word 
(Brown et al, 1993).  
468
However, both model 3 and model 4 do not 
take the multiword cept into account. Only 
one-to-one and many-to-one word alignments are 
considered. Thus, some multi-word units in the 
domain-specific corpus cannot be correctly aligned. 
In order to deal with this problem, we perform 
word alignment in two directions (source to target, 
and target to source) as described in (Och and Ney, 
2000). The GIZA++ toolkit2 is used to perform 
statistical word alignment. 
We use  and  to represent the 
bi-directional alignment sets, which are shown in 
Equation (4) and (5). For alignment in both sets, 
we use j for source words and i for target words. If 
a target word in position i is connected to source 
words in positions  and , then . 
We call an element in the alignment set an 
alignment link. 
1SG 2SG
2j1j },{ 21 jjAi =
}}0 ,|{|),{(1 ?=== jjii aiajAiASG  (4)
}}0  ,|{|),{(2 ?=== jjjj aaiiAAjSG (5)
3 Word Alignment Model Adaptation 
In this paper, we first train two models using the 
out-of-domain training data and the in-domain 
training data, and then build a new alignment 
model through linear interpolation of the two 
trained models. In other words, we make use of the 
out-of-domain training data and the in-domain 
training data by interpolating the trained alignment 
models. One method to perform model adaptation 
is to directly interpolate the alignment models as 
shown in Equation (6).  
),|()1(),|(),|( efapefapefap OI ??+?= ??
 
(6)
),|( efapI  and  are the alignment 
model trained using the in-domain corpus and the 
out-of-domain corpus, respectively.
),|( efapO
?  is an 
interpolation weight. It can be a constant or a 
function of  and . f e
However, in both model 3 and model 4, there 
are mainly three kinds of parameters: translation 
probability, fertility probability and distortion 
probability. These three kinds of parameters have 
their own interpretation in these two models. In 
order to obtain fine-grained interpolation models, 
we separate the alignment model interpolation into 
three parts: translation probability interpolation, 
fertility probability interpolation and distortion 
probability interpolation. For these probabilities, 
we use different interpolation methods to calculate 
the interpolation weights. After interpolation, we 
replace the corresponding parameters in equation 
(2) and (3) with the interpolated probabilities to get 
new alignment models. 
                                                          
2 It is located at http://www.fjoch.com/GIZA++.html. 
In the following subsections, we will perform 
linear interpolation for word alignment in the 
source to target direction. For the word alignment 
in the target to source direction, we use the same 
interpolation method. 
3.1 Translation Probability Interpolation 
The word translation probability  is 
very important in translation models. The same 
word may have different distributions in the 
in-domain corpus and the out-of-domain corpus. 
Thus, the interpolation weight for the translation 
probability is taken as a variant. The interpolation 
model for  is described in Equation (7).  
)|(
jaj eft
)|(
jaj eft
)|())(1(                      
)|()()|(
jj
jjj
ajOat
ajIataj
efte
efteeft
??
+?=
?
?
 (7)
The interpolation weight  in (7) is a 
function of . It is calculated as shown in 
Equation (8).  
)(
jat e?
jae
?
? ???
?
???
?
+= )()(
)(
)(
jj
j
j
aOaI
aI
at epep
ep
e  (8)
)(
jaI ep  and  are the relative 
frequencies of  in the in-domain corpus and in 
the out-of-domain corpus, respectively. 
)(
jaO ep
jae
?  is an 
adaptation coefficient, such that 0?? . 
Equation (8) indicates that if a word occurs 
more frequently in a specific domain than in the 
general domain, it can usually be considered as a 
domain-specific word (Pe?as et al, 2001). For 
example, if  is much larger than , 
the word  is a domain-specific word and the 
interpolation weight approaches to 1. In this case, 
we trust more on the translation probability 
obtained from the in-domain corpus than that 
obtained from the out-of-domain corpus. 
)(
jaI ep
ja
)(
jaO ep
e
469
3.2 
3.3 
4 
Fertility Probability Interpolation 
The fertility probability describes the 
distribution of the number of words that  is 
aligned to. The interpolation model is shown in (9). 
)|( ii en ?
ie
)|()1()|()|( iiOniiInii enenen ????? ??+?= (9)
Where,  is a constant. This constant is obtained 
using a manually annotated held-out data set. In 
fact, we can also set the interpolation weight to be 
a function of the word . From the word 
alignment results on the held-out set, we conclude 
that these two weighting schemes do not perform 
quite differently. 
n?
ie
Distortion Probability Interpolation 
The distortion probability describes the distribution 
of alignment positions. We separate it into two 
parts: one is the distortion probability in model 3, 
and the other is the distortion probability in model 
4. The interpolation model for the distortion 
probability in model 3 is shown in (10). Since the 
distortion probability is irrelevant with any specific 
source or target words, we take  as a constant. 
This constant is obtained using the held-out set. 
d?
),,|()1(                          
),,|(),,|(
mlajd
mlajdmlajd
jOd
jIdj
??
+?=
?
?
 (10)
For the distortion probability in model 4, we 
use the same interpolation method and take the 
interpolation weight as a constant.  
Translation Dictionary Acquisition 
We use the translation dictionary trained from the 
training data to further improve the alignment 
results. When we train the bi-directional statistical 
word alignment models with the training data, we 
get two word alignment results for the training data. 
By taking the intersection of the two word 
alignment results, we build a new alignment set. 
The alignment links in this intersection set are 
extended by iteratively adding word alignment 
links into it as described in (Och and Ney, 2000). 
Based on the extended alignment links, we build a 
translation dictionary. In order to filter the noise 
caused by the error alignment links, we only retain 
those translation pairs whose log-likelihood ratio 
scores (Dunning, 1993) are above a threshold. 
Based on the alignment results on the 
out-of-domain corpus, we build a translation 
dictionary  filtered with a threshold . Based 
on the alignment results on a small-scale 
in-domain corpus, we build another translation 
dictionary  filtered with a threshold .  
1D
2D
1?
2?
After obtaining the two dictionaries, we 
combine two dictionaries through linearly 
interpolating the translation probabilities in the two 
dictionaries, which is shown in (11). The symbols f 
and e represent a single word or a phrase in the 
source and target languages. This differs from the 
translation probability in Equation (7), where these 
two symbols only represent single words. 
)|())(1()|()()|( efpeefpeefp OI ??+?= ?? (11)
The interpolation weight is also a function of e. It 
is calculated as shown in (12)3. 
)()(
)(
)(
epep
ep
e
OI
I
+=?  (12)
)(epI  and  represent the relative 
frequencies of e  in the in-domain corpus and 
out-of-domain corpus, respectively.  
)(epO
5 
6 Evaluation 
                                                          
Adaptation Algorithm 
The adaptation algorithms include two parts: a 
training algorithm and a testing algorithm. The 
training algorithm is shown in Figure 1.  
After getting the two adaptation models and the 
translation dictionary, we apply them to the 
in-domain corpus to perform word alignment. Here 
we call it testing algorithm. The detailed algorithm 
is shown in Figure 2. For each sentence pair, there 
are two different word alignment results, from 
which the final alignment links are selected 
according to their translation probabilities in the 
dictionary D. The selection order is similar to that 
in the competitive linking algorithm (Melamed, 
1997). The difference is that we allow many-to-one 
and one-to-many alignments. 
We compare our method with four other methods. 
The first method is descried in (Wu and Wang, 
2004). We call it ?Result Adaptation (ResAdapt)?. 
3 We also tried an adaptation coefficient to calculate the 
interpolation weight as in (8). However, the alignment results 
are not improved by using this coefficient for the dictionary. 
470
Input: In-domain training data 
      Out-of-domain training data 
(1) Train two alignment models 
(source to target) and  (target to 
source) using the in-domain corpus. 
st
IM
ts
IM
(2) Train the other two alignment models 
 and  using the out-of-domain 
corpus. 
st
OM
ts
OM
(3) Build an adaptation model stM  based on 
 and , and build the other 
adaptation model 
st
IM
st
OM
tsM  based on 
and  using the interpolation methods 
described in section 3. 
ts
IM
ts
OM
(4) Train a dictionary  using the 
alignment results on the in-domain 
training data. 
1D
(5) Train another dictionary  using the 
alignment results on the out-of-domain 
training data. 
2D
(6) Build an adaptation dictionary D  based 
on  and  using the interpolation 
method described in section 4. 
1D 2D
Output: Alignment models stM  and tsM  
       Translation dictionary D  
Figure 1. Training Algorithm 
Input: Alignment models stM  and tsM , 
translation dictionary D , and testing 
data 
(1) Apply the adaptation model stM and 
tsM  to the testing data to get two 
different alignment results. 
(2) Select the alignment links with higher 
translation probability in the translation 
dictionary D . 
Output: Alignment results on the testing data
Figure 2. Testing Algorithm 
The second method ?Gen+Spec? directly combines 
the out-of-domain corpus and the in-domain corpus 
as training data. The third method ?Gen? only uses 
the out-of-domain corpus as training data. The 
fourth method ?Spec? only uses the in-domain 
corpus as training data. For each of the last three 
methods, we first train bi-directional alignment 
models using the training data. Then we build a 
translation dictionary based on the alignment 
results on the training data and filter it using 
log-likelihood ratio as described in section 4. 
6.1 
6.2 
Training and Testing Data 
In this paper, we take English-Chinese word 
alignment as a case study. We use a sentence- 
aligned out-of-domain English-Chinese bilingual 
corpus, which includes 320,000 bilingual sentence 
pairs. The average length of the English sentences 
is 13.6 words while the average length of the 
Chinese sentences is 14.2 words. 
We also use a sentence-aligned in-domain 
English-Chinese bilingual corpus (operation 
manuals for diagnostic ultrasound systems), which 
includes 5,862 bilingual sentence pairs. The 
average length of the English sentences is 12.8 
words while the average length of the Chinese 
sentences is 11.8 words. From this domain-specific 
corpus, we randomly select 416 pairs as testing 
data. We also select 400 pairs to be manually 
annotated as held-out set (development set) to 
adjust parameters. The remained 5,046 pairs are 
used as domain-specific training data. 
The Chinese sentences in both the training set 
and the testing set are automatically segmented 
into words. In order to exclude the effect of the 
segmentation errors on our alignment results, the 
segmentation errors in our testing set are 
post-corrected. The alignments in the testing set 
are manually annotated, which includes 3,166 
alignment links. Among them, 504 alignment links 
include multiword units.  
Evaluation Metrics 
We use the same evaluation metrics as described in 
(Wu and Wang, 2004). If we use  to represent 
the set of alignment links identified by the 
proposed methods and  to denote the reference 
alignment set, the methods to calculate the 
precision, recall, f-measure, and alignment error 
rate (AER) are shown in Equation (13), (14), (15), 
and (16). It can be seen that the higher the 
f-measure is, the lower the alignment error rate is. 
Thus, we will only show precision, recall and AER 
scores in the evaluation results. 
GS
CS
|S|
|SS|
G
CG ?=precision      
(13)
471
|S|
 |SS|
C
CG ?=recall  
(14)
||||
||2
CG
CG
SS
SS
fmeasure +
??=  (15)
fmeasure
SS
SS
AER
CG
CG ?=+
???= 1
||||
||2
1 (16)
 
6.3 Evaluation Results 
We use the held-out set described in section 6.1 to 
set the interpolation weights. The coefficient ?  in 
Equation (8) is set to 0.8, the interpolation weight 
 in Equation (9) is set to 0.1, the interpolation 
weight  in model 3 in Equation (10) is set to 
0.1, and the interpolation weight  in model 4 is 
set to 1. In addition, log-likelihood ratio score 
thresholds are set to  and . With 
these parameters, we get the lowest alignment error 
rate on the held-out set. 
n?
d?
d?
301 =? 252 =?
Using these parameters, we build two 
adaptation models and a translation dictionary on 
the training data, which are applied to the testing 
set. The evaluation results on our testing set are 
shown in Table 1. From the results, it can be seen 
that our approach performs the best among all of 
the methods, achieving the lowest alignment error 
rate. Compared with the method ?ResAdapt?, our 
method achieves a higher precision without loss of 
recall, resulting in an error rate reduction of 6.56%. 
Compared with the method ?Gen+Spec?, our 
method gets a higher recall, resulting in an error 
rate reduction of 17.43%. This indicates that our 
model adaptation method is very effective to 
alleviate the data-sparseness problem of 
domain-specific word alignment. 
Method Precision Recall AER 
Ours 0.8490 0.7599 0.1980
ResAdapt 0.8198 0.7587 0.2119
Gen+Spec 0.8456 0.6905 0.2398
Gen 0.8589 0.6576 0.2551
Spec 0.8386 0.6731 0.2532
Table 1. Word Alignment Adaptation Results 
The method that only uses the large-scale 
out-of-domain corpus as training data does not 
produce good result. The alignment error rate is 
almost the same as that of the method only using 
the in-domain corpus. In order to further analyze 
the result, we classify the alignment links into two 
classes: single word alignment links (SWA) and 
multiword alignment links (MWA). Single word 
alignment links only include one-to-one 
alignments. The multiword alignment links include 
those links in which there are multiword units in 
the source language or/and the target language. 
The results are shown in Table 2. From the results, 
it can be seen that the method ?Spec? produces 
better results for multiword alignment while the 
method ?Gen? produces better results for single 
word alignment. This indicates that the multiword 
alignment links mainly include the domain-specific 
words. Among the 504 multiword alignment links, 
about 60% of the links include domain-specific 
words. In Table 2, we also present the results of 
our method. Our method achieves the lowest error 
rate results on both single word alignment and 
multiword alignment.  
Method Precision Recall AER 
Ours (SWA) 0.8703 0.8621 0.1338
Ours (MWA) 0.5635 0.2202 0.6833
Gen (SWA) 0.8816 0.7694 0.1783
Gen (MWA) 0.3366 0.0675 0.8876
Spec (SWA) 0.8710 0.7633 0.1864
Spec (MWA) 0.4760 0.1964 0.7219
Table 2. Single Word and Multiword Alignment 
Results 
In order to further compare our method with the 
method described in (Wu and Wang, 2004). We do 
another experiment using almost the same-scale 
in-domain training corpus as described in (Wu and 
Wang, 2004). From the in-domain training corpus, 
we randomly select about 500 sentence pairs to 
build the smaller training set. The testing data is 
the same as shown in section 6.1. The evaluation 
results are shown in Table 3. 
Method Precision Recall AER 
Ours 0.8424 0.7378 0.2134
ResAdapt 0.8027 0.7262 0.2375
Gen+Spec 0.8041 0.6857 0.2598
Table 3. Alignment Adaptation Results Using a 
Smaller In-Domain Corpus 
Compared with the method ?Gen+Spec?, our 
method achieves an error rate reduction of 17.86% 
472
while the method ?ResAdapt? described in (Wu 
and Wang, 2004) only achieves an error rate 
reduction of 8.59%. Compared with the method 
?ResAdapt?, our method achieves an error rate 
reduction of 10.15%. 
This result is different from that in (Wu and 
Wang, 2004), where their method achieved an 
error rate reduction of 21.96% as compared with 
the method ?Gen+Spec?. The main reason is that 
the in-domain training corpus and testing corpus in 
this paper are different from those in (Wu and 
Wang, 2004). The training data and the testing data 
described in (Wu and Wang, 2004) are from a 
single manual. The data in our corpus are from 
several manuals describing how to use the 
diagnostic ultrasound systems. 
In addition to the above evaluations, we also 
evaluate our model adaptation method using the 
"refined" combination in Och and Ney (2000) 
instead of the translation dictionary. Using the 
"refined" method to select the alignments produced 
by our model adaptation method (AER: 0.2371) 
still yields better result than directly combining 
out-of-domain and in-domain corpora as training 
data of the "refined" method (AER: 0.2290). 
6.4 The Effect of In-Domain Corpus 
In general, it is difficult to obtain large-scale 
in-domain bilingual corpus. For some domains, 
only a very small-scale bilingual sentence pairs are 
available. Thus, in order to analyze the effect of the 
size of in-domain corpus, we randomly select 
sentence pairs from the in-domain training corpus 
to generate five training sets. The numbers of 
sentence pairs in these five sets are 1,010, 2,020, 
3,030, 4,040 and 5,046. For each training set, we 
use model 4 in section 2 to train an in-domain 
model. The out-of-domain corpus for the 
adaptation experiments and the testing set are the 
same as described in section 6.1. 
# Sentence 
Pairs Precision Recall AER 
1010 0.8385 0.7394 0.2142
2020 0.8388 0.7514 0.2073
3030 0.8474 0.7558 0.2010
4040 0.8482 0.7555 0.2008
5046 0.8490 0.7599 0.1980
Table 4. Alignment Adaptation Results Using 
In-Domain Corpora of Different Sizes 
# Sentence 
Pairs Precision Recall AER 
1010 0.8737 0.6642 0.2453
2020 0.8502 0.6804 0.2442
3030 0.8473 0.6874 0.2410
4040 0.8430 0.6917 0.2401
5046 0.8456 0.6905 0.2398
Table 5. Alignment Results Directly Combining 
Out-of-Domain and In-Domain Corpora  
The results are shown in Table 4 and Table 5. 
Table 4 describes the alignment adaptation results 
using in-domain corpora of different sizes. Table 5 
describes the alignment results by directly 
combining the out-of-domain corpus and the 
in-domain corpus of different sizes.  From the 
results, it can be seen that the larger the size of 
in-domain corpus is, the smaller the alignment 
error rate is. However, when the number of the 
sentence pairs increase from 3030 to 5046, the 
error rate reduction in Table 4 is very small. This is 
because the contents in the specific domain are 
highly replicated. This also shows that increasing 
the domain-specific corpus does not obtain great 
improvement on the word alignment results. 
Comparing the results in Table 4 and Table 5, we 
find out that our adaptation method reduces the 
alignment error rate on all of the in-domain 
corpora of different sizes.  
6.5 The Effect of Out-of-Domain Corpus 
In order to further analyze the effect of the 
out-of-domain corpus on the adaptation results, we 
randomly select sentence pairs from the 
out-of-domain corpus to generate five sets. The 
numbers of sentence pairs in these five sets are 
65,000, 130,000, 195,000, 260,000, and 320,000 
(the entire out-of-domain corpus). In the adaptation 
experiments, we use the entire in-domain corpus 
(5046 sentence pairs). The adaptation results are 
shown in Table 6. 
From the results in Table 6, it can be seen that 
the larger the size of out-of-domain corpus is, the 
smaller the alignment error rate is. However, when 
the number of the sentence pairs is more than 
130,000, the error rate reduction is very small. This 
indicates that we do not need a very large bilingual 
out-of-domain corpus to improve domain-specific 
word alignment results. 
 
473
# Sentence 
Pairs (k) Precision Recall AER 
65 0.8441 0.7284 0.2180
130 0.8479 0.7413 0.2090
195 0.8454 0.7461 0.2073
260 0.8426 0.7508 0.2059
320 0.8490 0.7599 0.1980
Table 6. Adaptation Alignment Results Using 
Out-of-Domain Corpora of Different Sizes 
7 Conclusion 
This paper proposes an approach to improve 
domain-specific word alignment through alignment 
model adaptation. Our approach first trains two 
alignment models with a large-scale out-of-domain 
corpus and a small-scale domain-specific corpus. 
Second, we build a new adaptation model by 
linearly interpolating these two models. Third, we 
apply the new model to the domain-specific corpus 
and improve the word alignment results. In 
addition, with the training data, an interpolated 
translation dictionary is built to select the word 
alignment links from different alignment results. 
Experimental results indicate that our approach 
achieves a precision of 84.90% and a recall of 
75.99% for word alignment in a specific domain. 
Our method achieves a relative error rate reduction 
of 17.43% as compared with the method directly 
combining the out-of-domain corpus and the 
in-domain corpus as training data.  It also 
achieves a relative error rate reduction of 6.56% as 
compared with the previous work in (Wu and 
Wang, 2004). In addition, when we train the model 
with a smaller-scale in-domain corpus as described 
in (Wu and Wang, 2004), our method achieves an 
error rate reduction of 10.15% as compared with 
the method in (Wu and Wang, 2004). 
We also use in-domain corpora and 
out-of-domain corpora of different sizes to perform 
adaptation experiments. The experimental results 
show that our model adaptation method improves 
alignment results on in-domain corpora of different 
sizes.  The experimental results also show that 
even a not very large out-of-domain corpus can 
help to improve the domain-specific word 
alignment through alignment model adaptation. 
References 
L. Ahrenberg, M. Merkel, M. Andersson. 1998. A 
Simple Hybrid Aligner for Generating Lexical 
Correspondences in Parallel Tests. In Proc. of 
ACL/COLING-1998, pp. 29-35. 
Y. Al-Onaizan, J. Curin, M. Jahr, K. Knight, J. Lafferty, 
D. Melamed, F. J. Och, D. Purdy, N. A. Smith, D. 
Yarowsky. 1999. Statistical Machine Translation 
Final Report. Johns Hopkins University Workshop. 
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, R. 
Mercer. 1993. The Mathematics of Statistical 
Machine Translation: Parameter Estimation. 
Computational Linguistics, 19(2): 263-311. 
C. Cherry and D. Lin. 2003. A Probability Model to 
Improve Word Alignment. In Proc. of ACL-2003, pp. 
88-95. 
T. Dunning. 1993. Accurate Methods for the Statistics of 
Surprise and Coincidence. Computational Linguistics, 
19(1): 61-74. 
R. Iyer,  M. Ostendorf,  H. Gish.  1997. Using 
Out-of-Domain Data to Improve In-Domain 
Language Models. IEEE Signal Processing Letters, 
221-223. 
S. J. Ker and J. S. Chang. 1997. A Class-based 
Approach to Word Alignment. Computational 
Linguistics, 23(2): 313-343. 
I. D. Melamed. 1997. A Word-to-Word Model of 
Translational Equivalence. In Proc. of ACL 1997, pp. 
490-497. 
F. J. Och and H. Ney. 2000. Improved Statistical 
Alignment Models. In Proc. of ACL-2000, pp. 
440-447. 
A. Pe?as, F. Verdejo, J. Gonzalo. 2001. Corpus-based 
Terminology Extraction Applied to Information 
Access. In Proc. of the Corpus Linguistics 2001, vol. 
13. 
F. Smadja, K. R. McKeown, V. Hatzivassiloglou. 1996. 
Translating Collocations for Bilingual Lexicons: a 
Statistical Approach. Computational Linguistics, 
22(1): 1-38. 
D. Tufis and A. M. Barbu. 2002. Lexical Token 
Alignment: Experiments, Results and Application. In 
Proc. of LREC-2002, pp. 458-465. 
D. Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel 
Corpora. Computational Linguistics, 23(3): 377-403. 
H. Wu and H. Wang. 2004. Improving Domain-Specific 
Word Alignment with a General Bilingual Corpus. In 
R. E. Frederking and K. B. Taylor (Eds.), Machine 
Translation: From Real Users to Research: 6th 
conference of AMTA-2004, pp. 262-271. 
474
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 874?881,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Word Alignment for Languages with Scarce Resources 
Using Bilingual Corpora of Other Language Pairs 
 
Haifeng Wang      Hua Wu      Zhanyi Liu 
Toshiba (China) Research and Development Center 
5/F., Tower W2, Oriental Plaza, No.1, East Chang An Ave., Dong Cheng District 
Beijing, 100738, China 
{wanghaifeng, wuhua, liuzhanyi}@rdc.toshiba.com.cn 
 
  
 
Abstract 
This paper proposes an approach to im-
prove word alignment for languages with 
scarce resources using bilingual corpora 
of other language pairs. To perform word 
alignment between languages L1 and L2, 
we introduce a third language L3. Al-
though only small amounts of bilingual 
data are available for the desired lan-
guage pair L1-L2, large-scale bilingual 
corpora in L1-L3 and L2-L3 are available. 
Based on these two additional corpora 
and with L3 as the pivot language, we 
build a word alignment model for L1 and 
L2. This approach can build a word 
alignment model for two languages even 
if no bilingual corpus is available in this 
language pair. In addition, we build an-
other word alignment model for L1 and 
L2 using the small L1-L2 bilingual cor-
pus. Then we interpolate the above two 
models to further improve word align-
ment between L1 and L2. Experimental 
results indicate a relative error rate reduc-
tion of 21.30% as compared with the 
method only using the small bilingual 
corpus in L1 and L2. 
1 Introduction 
Word alignment was first proposed as an inter-
mediate result of statistical machine translation 
(Brown et al, 1993). Many researchers build 
alignment links with bilingual corpora (Wu, 
1997; Och and Ney, 2003; Cherry and Lin, 2003; 
Zhang and Gildea, 2005). In order to achieve 
satisfactory results, all of these methods require a 
large-scale bilingual corpus for training. When 
the large-scale bilingual corpus is unavailable, 
some researchers acquired class-based alignment 
rules with existing dictionaries to improve word 
alignment (Ker and Chang, 1997). Wu et al 
(2005) used a large-scale bilingual corpus in 
general domain to improve domain-specific word 
alignment when only a small-scale domain-
specific bilingual corpus is available. 
This paper proposes an approach to improve 
word alignment for languages with scarce re-
sources using bilingual corpora of other language 
pairs. To perform word alignment between lan-
guages L1 and L2, we introduce a third language 
L3 as the pivot language. Although only small 
amounts of bilingual data are available for the 
desired language pair L1-L2, large-scale bilin-
gual corpora in L1-L3 and L2-L3 are available. 
Using these two additional bilingual corpora, we 
train two word alignment models for language 
pairs L1-L3 and L2-L3, respectively. And then, 
with L3 as a pivot language, we can build a word 
alignment model for L1 and L2 based on the 
above two models. Here, we call this model an 
induced model. With this induced model, we per-
form word alignment between languages L1 and 
L2 even if no parallel corpus is available for this 
language pair. In addition, using the small bilin-
gual corpus in L1 and L2, we train another word 
alignment model for this language pair. Here, we 
call this model an original model. An interpo-
lated model can be built by interpolating the in-
duced model and the original model. 
As a case study, this paper uses English as the 
pivot language to improve word alignment be-
tween Chinese and Japanese. Experimental re-
sults show that the induced model performs bet-
ter than the original model trained on the small 
Chinese-Japanese corpus. And the interpolated 
model further improves the word alignment re-
sults, achieving a relative error rate reduction of 
874
21.30% as compared with results produced by 
the original model. 
The remainder of this paper is organized as 
follows. Section 2 discusses the related work. 
Section 3 introduces the statistical word align-
ment models. Section 4 describes the parameter 
estimation method using bilingual corpora of 
other language pairs. Section 5 presents the in-
terpolation model. Section 6 reports the experi-
mental results. Finally, we conclude and present 
the future work in section 7. 
2 Related Work 
A shared task on word alignment was organized 
as part of the ACL 2005 Workshop on Building 
and Using Parallel Texts (Martin et al, 2005). 
The focus of the task was on languages with 
scarce resources. Two different subtasks were 
defined: Limited resources and Unlimited re-
sources. The former subtask only allows partici-
pating systems to use the resources provided. 
The latter subtask allows participating systems to 
use any resources in addition to those provided. 
For the subtask of unlimited resources, As-
wani and Gaizauskas (2005) used a multi-feature 
approach for many-to-many word alignment on 
English-Hindi parallel corpora. This approach 
performed local word grouping on Hindi sen-
tences and used other methods such as dictionary 
lookup, transliteration similarity, expected Eng-
lish words, and nearest aligned neighbors. Martin 
et al (2005) reported that this method resulted in 
absolute improvements of up to 20% as com-
pared with the case of only using limited re-
sources. Tufis et al (2005) combined two word 
aligners: one is based on the limited resources 
and the other is based on the unlimited resources.  
The unlimited resource consists of a translation 
dictionary extracted from the alignment of Ro-
manian and English WordNet. Lopez and Resnik 
(2005) extended the HMM model by integrating 
a tree distortion model based on a dependency 
parser built on the English side of the parallel 
corpus. The latter two methods produced compa-
rable results with those methods using limited 
resources. All the above three methods use some 
language dependent resources such as dictionary, 
thesaurus, and dependency parser. And some 
methods, such as transliteration similarity, can 
only be used for very similar language pairs. 
In this paper, besides the limited resources for 
the given language pair, we make use of large 
amounts of resources available for other lan-
guage pairs to address the alignment problem for 
languages with scarce resources. Our method 
does not need language-dependent resources or 
deep linguistic processing. Thus, it is easy to 
adapt to any language pair where a pivot lan-
guage and corresponding large-scale bilingual 
corpora are available. 
3 Statistical Word Alignment 
According to the IBM models (Brown et al, 
1993), the statistical word alignment model can 
be generally represented as in equation (1).  
?=
a'
c|f,a'
c|fa,
c|fa,
)Pr(
)Pr(
)Pr(  
(1)
Where,  and  represent the source sentence 
and the target sentence, respectively
c f
1. 
In this paper, we use a simplified IBM model 
4 (Al-Onaizan et al, 1999), which is shown in 
equation (2). This version does not take into ac-
count word classes in Brown et al (1993). 
))))(()](([            
))()](([(           
)|( )|(             
   
         
)Pr(
0,1
1
0,1
11
11
1
2
0
0
0 00
?
?
??
?=
>
?=
?
==
?
???
+??=
??
????
?
???
? ?=
m
aj
j
m
aj
ij
m
j
aj
l
i
ii
m
j
j
j
jpjdahj
jdahj
cftcn
pp
m
?
?
?
? ??
c|fa,
 
(2)
ml,  are the lengths of the source sentence and 
the target sentence respectively. 
j  is the position index of the target word. 
ja  is the position of the source word aligned to 
the jth target word. 
i?  is the fertility of . ic
0p ,  are the fertility probabilities for , 
and 
1p 0c
110 =+ pp . 
)|
jaj
ct(f  is the word translation probability. 
)|( ii cn ?  is the fertility probability. 
)( 11 ?? ijd ?  is the distortion probability for the 
head word of the cept. 
))((1 jpjd ?>  is the distortion probability for 
the non-head words of the cept. 
                                                 
1 This paper uses c and f to represent a Chinese sentence 
and a Japanese sentence, respectively. And e represents an 
English sentence. 
875
}:{min)( k
k
aikih == is the head of cept i. 
}:{max)( kj
jk
aakjp ==
<
. 
i?  is the center of cept i. 
During the training process, IBM model 3 is 
first trained, and then the parameters in model 3 
are employed to train model 4. For convenience, 
we describe model 3 in equation (3). The main 
difference between model 3 and model 4 lies in 
the calculation of distortion probability. 
??
??
?==
==
?
?
??
????
?
???
? ?=
m
aj
j
m
j
aj
l
i
i
l
i
ii
m
j
j
mlajdcft
cn
pp
m
0,11
11
1
2
0
0
0
),,|()|(                   
!  )|(                   
   
)Pr( 00
??
?
? ??c|fa,
 
(3)
4 Parameter Estimation Using Bilingual 
Corpora of Other Language Pairs 
As shown in section 3, the word alignment 
model mainly has three kinds of parameters that 
must be specified, including the translation prob-
ability, the fertility probability, and the distortion 
probability. The parameters are usually estimated 
by using bilingual sentence pairs in the desired 
languages, namely Chinese and Japanese here. In 
this section, we describe how to estimate the pa-
rameters without using the Chinese-Japanese 
bilingual corpus. We introduce English as the 
pivot language, and use the Chinese-English and 
English-Japanese bilingual corpora to estimate 
the parameters of the Chinese-Japanese word 
alignment model. With these two corpora, we 
first build Chinese-English and English-Japanese 
word alignment models as described in section 3. 
Then, based on these two models, we estimate 
the parameters of Chinese-Japanese word align-
ment model. The estimated model is named in-
duced model. 
The following subsections describe the 
method to estimate the parameters of Chinese-
Japanese alignment model. For reversed Japa-
nese-Chinese word alignment, the parameters 
can be estimated with the same method. 
4.1  Translation Probability 
Basic Translation Probability  
We use the translation probabilities trained 
with Chinese-English and English-Japanese cor-
pora to estimate the Chinese-Japanese probabil-
ity as shown in equation (4). In (4), we assume 
that the translation probability  is 
independent of the Chinese word . 
),|(EJ ikj ceft
ic
)|()|(     
)|(),|(      
)|(
CEEJ
CEEJ
CJ
ik
e
kj
ik
e
ikj
ij
ceteft
cetceft
cft
k
k
?
?
?=
?=  
(4)
Where  is the translation probability 
for Chinese-Japanese word alignment. 
is the translation probability trained 
using the English-Japanese corpus.  is 
the translation probability trained using the Chi-
nese-English corpus. 
)|(CJ ij cft
)|(EJ kj eft
)|(CE ik cet
Cross-Language Word Similarity 
In any language, there are ambiguous words 
with more than one sense. Thus, some noise may 
be introduced by the ambiguous English word 
when we estimate the Chinese-Japanese transla-
tion probability using English as the pivot lan-
guage. For example, the English word "bank" has 
at least two senses, namely: 
bank1 - a financial organization 
bank2 - the border of a river 
Let us consider the Chinese word: 
?? - bank2 (the border of a river) 
And the Japanese word: 
?? - bank1 (a financial organization) 
In the Chinese-English corpus, there is high 
probability that the Chinese word "??(bank2)"  
would be translated into the English word "bank". 
And in the English-Japanese corpus, there is also 
high probability that the English word "bank" 
would be translated into the Japanese word "?
?(bank1)". 
As a result, when we estimate the translation 
probability using equation (4), the translation 
probability of "?? (bank1)" given "??
(bank2)" is high. Such a result is not what we 
expect. 
In order to alleviate this problem, we intro-
duce cross-language word similarity to improve 
translation probability estimation in equation (4). 
The cross-language word similarity describes 
how likely a Chinese word is to be translated into 
a Japanese word with an English word as the 
pivot. We make use of both the Chinese-English 
corpus and the English-Japanese corpus to calcu-
late the cross language word similarity between a 
Chinese word c and a Japanese word f given an 
876
Input: An English word e , a Chinese word , and a Japanese word ; c f
The Chinese-English corpus; The English-Japanese corpus. 
(1) Construct Set 1: identify those Chinese-English sentence pairs that include the given Chinese 
word  and English word , and put the English sentences in the pairs into Set 1. c e
(2) Construct Set 2: identify those English-Japanese sentence pairs that include the given English 
word  and Japanese word , and put the English sentences in the pairs into Set 2. e f
(3) Construct the feature vectors  and  of the given English word using all other words as 
context in Set 1 and Set 2, respectively. 
CEV EJV
>=< ),(, ... ),,(),,( 1122111CE nn ctectecteV  
>=< ),(, ... ),,(),,( 2222211EJ nn ctectecteV  
Where  is the frequency of the context word . ijct je 0=ijct  if  does not occur in Set i . je
(4) Given the English word e , calculate the cross-language word similarity between the Chinese 
word  and the Japanese word  as in equation (5) c f
??
?
?
?
==
j
j
j
j
j
jj
ctct
ctct
VVefcsim
2
2
2
1
21
EJCE
)()(
),cos();,(                                     (5) 
Output: The cross language word similarity  of the Chinese word c and the Japanese 
word given the English word  
);,( efcsim
f e
Figure 1. Similarity Calculation 
English word e. For the ambiguous English word 
e, both the Chinese word c and the Japanese 
word f can be translated into e. The sense of an 
instance of the ambiguous English word e can be 
determined by the context in which the instance 
appears. Thus, the cross-language word similar-
ity between the Chinese word c and the Japanese 
word f can be calculated according to the con-
texts of their English translation e. We use the 
feature vector constructed using the context 
words in the English sentence to represent the 
context. So we can calculate the cross-language 
word similarity using the feature vectors. The 
detailed algorithm is shown in figure 1. This idea 
is similar to translation lexicon extraction via a 
bridge language (Schafer and Yarowsky, 2002). 
For example, the Chinese word "??" and its 
English translation "bank" (the border of a river) 
appears in the following Chinese-English sen-
tence pair: 
(a) ?????????? 
(b) They walked home along the river bank. 
The Japanese word "??" and its English 
translation "bank" (a financial organization) ap-
pears in the following English-Japanese sentence 
pair: 
(c) He has plenty of money in the bank. 
(d) ???????????? 
The context words of the English word "bank" in 
sentences (b) and (c) are quite different. The dif-
ference indicates the cross language word simi-
larity of the Chinese word "??" and the Japa-
nese word "??" is low. So they tend to have 
different senses. 
Translation Probability Embedded with Cross 
Language Word Similarity 
Based on the cross language word similarity 
calculation in equation (5), we re-estimate the 
translation probability as shown in (6). Then we 
normalize it in equation (7). 
The word similarity of the Chinese word "?
? (bank2)" and the Japanese word " ? ?
(bank1)" given the word English word "bank" is 
low. Thus, using the updated estimation method, 
the translation probability of "?? (bank1)" 
given "??(bank2)" becomes low. 
));,()|()|((
)|('
CEEJ
CJ
kjiik
e
kj
ij
efcsimceteft
cft
k
??= ?
 
(6)
?=
'
CJ
CJ
CJ )|'('
)|('
)|(
f
i
ij
ij cft
cft
cft  (7)
4.2  Fertility Probability 
The induced fertility probability is calculated as 
shown in (8). Here, we assume that the probabil-
877
ity ),|(EJ iki cen ?  is independent of the Chinese 
word . ic
)|()|(
)|(),|(
)|(
CEEJ
CEEJ
CJ
ik
e
ki
ik
e
iki
ii
ceten
cetcen
cn
k
k
?=
?=
?
?
?
?
?
 
(8)
Where, )|(CJ ii cn ?  is the fertility probability for 
the Chinese-Japanese alignment. )|(EJ ki en ?  is 
the trained fertility probability for the English-
Japanese alignment. 
4.3  Distortion Probability in Model 3 
With the English language as a pivot language, 
we calculate the distortion probability of model 3. 
For this probability, we introduce two additional 
parameters: one is the position of English word 
and the other is the length of English sentence. 
The distortion probability is estimated as shown 
in (9). 
)),,|Pr(),,,|Pr(         
),,,,|(Pr(
),,|,Pr(),,,,|Pr(
),,|,,Pr(
),,|(
,
,
,
CJ
mlinmlink
mlinkj
mlinkmlinkj
mlinkj
mlijd
nk
nk
nk
?
?=
?=
=
?
?
?
 
(9)
Where, is the estimated distortion 
probability.  is the introduced position of an 
English word. n  is the introduced length of an 
English sentence.  
).,|(CJ mlijd
k
In the above equation, we assume that the po-
sition probability  is independent 
of the position of the Chinese word and the 
length of the Chinese sentence. And we assume 
that the position probability  is in-
dependent of the length of Japanese sentence. 
Thus, we rewrite these two probabilities as fol-
lows. 
),,,,|Pr( mlinkj
),,,|Pr( mlink
),,|(),,|Pr(),,,,|Pr( EJ mnkjdmnkjmlinkj =?  
),,|(),,|Pr(),,,|Pr( CE nlikdnliknmlik =?  
For the length probability, the English sen-
tence length n  is independent of the word posi-
tions i . And we assume that it is uniformly dis-
tributed. Thus, we take it as a constant, and re-
write it as follows.  
constant),|Pr(),,|Pr( == mlnmlin  
According to the above three assumptions, we 
ignore the length probability . Equa-
tion (9) is rewritten in (10).  
),|Pr( mln
? ?=
nk
nlikdmnkjd
mlijd
,
CEEJ
CJ
),,|(),,|(
).,|(
 (10)
4.4  Distortion Probability in Model 4 
In model 4, there are two parameters for the dis-
tortion probability: one for head words and the 
other for non-head words.  
Distortion Probability for Head Words 
The distortion probability for head 
words represents the relative position of the head 
word of the i
)( 11 ?? ijd ?
th cept and the center of the (i-1)th 
cept. Let 1??=? ijj ? , then  is independent of 
the absolute position. Thus, we estimate the dis-
tortion probability by introducing another rela-
tive position 
j?
'j? of English words, which is 
shown in (11).    
?
?
?
????=
?=?
'
EJCE,1
1CJ,1
)'|(Pr)'(
)(
j
i
jjjd
jjd ?
 (11)
Where, )( 1CJ1, ??=? ijjd ? is the estimated dis-
tortion probability for head words in Chinese-
Japanese alignment. is the distortion 
probability for head word in Chinese-English 
alignment. 
)'(CE1, jd ?
)'|(PrEJ jj ??  is the translation prob-
ability of relative Japanese position given rela-
tive English position.  
In order to simplify , we introduce 
and  and let 
)'|(PrEJ jj ??
'j 1'?i? 1''' ??=? ijj ? , where  and 
 are positions of English words. We rewrite 
'j
1'?i?
)'|(PrEJ jj ??  in (12).   
?
?=?
?=?
??
??
??
??
=
??=
??
'':,'
:,
1'1EJ
1'1EJ
EJ
1'1'
11
),'|,(Pr
)'|(Pr
)'|(Pr
jjj
jjj
ii
ii
ii
ii
jj
jj
jj
??
??
??
??  
(12)
The English word in position  is aligned to 
the Japanese word in position , and the English 
word in position  is aligned to the Japanese 
word in position . 
'j
j
1'?i?
1?i?
We assume that  and  are independent, 
 only depends on , and  only depends 
on . Then  can be esti-
mated as shown in (13). 
j 1?i?
j 'j 1?i?
1'?i? ),'|,(Pr 1'1EJ ?? ii jj ??
878
)|(Pr)'|(Pr
),'|,(Pr
1'1EJEJ
1'1EJ
??
??
?= ii
ii
jj
jj
??
??
 (13)
Both of the two parameters in (13) represent 
the position translation probabilities. Thus, we 
can estimate them from the distortion probability 
in model 3.  is estimated as shown in 
(14).  And  can be estimated in 
the same way. In (14), we also assume that the 
sentence length distribution  is inde-
pendent of the word position and that it is uni-
formly distributed. 
)'|(PrEJ jj
)|(Pr 1'1EJ ?? ii ??
)'|,Pr( jml
?
?
?
=
?=
=
ml
ml
ml
mljjd
jmlmljjd
jmljjj
,
EJ
,
EJ
,
EJEJ
),,'|(
)'|,Pr(),,'|(
)'|,,(Pr)'|(Pr
 (14)
Distortion Probability for Non-Head Words 
The distortion probability de-
scribes the distribution of the relative position of 
non-head words. In the same way, we introduce 
relative position of English words, and model 
the probability in (15). 
))((1 jpjd ?>
'j?
?
?
>
>
????=
?=?
'
EJCE,1
CJ,1
)'|(Pr)'(
))((
j
jjjd
jpjjd
 (15)
))((CJ1, jpjjd ?=?> is the estimated distortion 
probability for the non-head words in Chinese-
Japanese alignment.  is the distortion 
probability for non-head words in Chinese-
English alignment. 
)'(CE1, jd ?>
)'|(PrEJ jj ?? is the translation 
probability of the relative Japanese position 
given the relative English position.  
In fact,  has the same interpreta-
tion as in (12). Thus, we introduce two parame-
ters and  and let , where 
and  are positions of English words. The 
final distortion probability for non-head words 
can be estimated as shown in (16). 
)'|(PrEJ jj ??
'j )'( jp )'('' jpjj ?=?
'j )'( jp
)))'(|)((Pr)'|(Pr
)'(())((
')'(':)'(,'
)(:)(,
EJEJ
'
CE1,CJ1,
?
?
?=? ?=?
?
>>
?
??=?=?
jjpjjpj
jjpjjpj
j
jpjpjj
jdjpjjd
 (16)
5 Interpolation Model 
With the Chinese-English and English-Japanese 
corpora, we can build the induced model for Chi-
nese-Japanese word alignment as described in 
section 4. If we have small amounts of Chinese-
Japanese corpora, we can build another word 
alignment model using the method described in 
section 3, which is called the original model here. 
In order to further improve the performance of 
Chinese-Japanese word alignment, we build an 
interpolated model by interpolating the induced 
model and the original model.  
Generally, we can interpolate the induced 
model and the original model as shown in equa-
tion (17). 
)(Pr)1( )(Pr
)Pr(
IO c|fa,c|fa,
c|fa,
??+?= ??  (17)
Where is the original model trained 
from the Chinese-Japanese corpus, and 
 is the induced model trained from the 
Chinese-English and English-Japanese corpora. 
)(PrO c|fa,
)(PrI c|fa,
?  is an interpolation weight. It can be a constant 
or a function of f  and . c
 In both model 3 and model 4, there are mainly 
three kinds of parameters: translation probability, 
fertility probability and distortion probability. 
These three kinds of parameters have their own 
interpretation in these two models. In order to 
obtain fine-grained interpolation models, we in-
terpolate the three kinds of parameters using dif-
ferent weights, which are obtained in the same 
way as described in Wu et al (2005). t?  repre-
sents the weights for translation probability. n?  
represents the weights for fertility probability. 
d3?  and d4?  represent the weights for distortion 
probability in model 3 and in model 4, respec-
tively. d4?  is set as the interpolation weight for 
both the head words and the non-head words. 
The above four weights are obtained using a 
manually annotated held-out set. 
6 Experiments 
In this section, we compare different word 
alignment methods for Chinese-Japanese align-
ment. The "Original" method uses the original 
model trained with the small Chinese-Japanese 
corpus.  The "Basic Induced" method uses the 
induced model that employs the basic translation 
probability without introducing cross-language 
word similarity. The "Advanced Induced" 
method uses the induced model that introduces 
the cross-language word similarity into the calcu-
lation of the translation probability. The "Inter-
polated" method uses the interpolation of the 
word alignment models in the "Advanced In-
duced" and "Original" methods. 
879
6.1 Data 
There are three training corpora used in this pa-
per: Chinese-Japanese (CJ) corpus, Chinese-
English (CE) Corpus, and English-Japanese (EJ) 
Corpus. All of these tree corpora are from gen-
eral domain. The Chinese sentences and Japa-
nese sentences in the data are automatically seg-
mented into words. The statistics of these three 
corpora are shown in table 1. "# Source Words" 
and "# Target Words" mean the word number of 
the source and target sentences, respectively. 
Language 
Pairs 
#Sentence 
Pairs 
# Source 
Words 
# Target 
Words 
CJ 21,977 197,072 237,834 
CE 329,350 4,682,103 4,480,034
EJ 160,535 1,460,043 1,685,204
Table 1. Statistics for Training Data 
Besides the training data, we also have held-
out data and testing data. The held-out data in-
cludes 500 Chinese-Japanese sentence pairs, 
which is used to set the interpolated weights de-
scribed in section 5. We use another 1,000 Chi-
nese-Japanese sentence pairs as testing data, 
which is not included in the training data and the 
held-out data. The alignment links in the held-out 
data and the testing data are manually annotated. 
Testing data includes 4,926 alignment links2. 
6.2  Evaluation Metrics 
We use the same metrics as described in Wu et al 
(2005), which is similar to those in (Och and Ney, 
2000). The difference lies in that Wu et al (2005) 
took all alignment links as sure links. 
If we use  to represent the set of alignment 
links identified by the proposed methods and  
to denote the reference alignment set, the meth-
ods to calculate the precision, recall, f-measure, 
and alignment error rate (AER) are shown in 
equations (18), (19), (20), and (21), respectively. 
It can be seen that the higher the f-measure is, 
the lower the alignment error rate is. Thus, we 
will only show precision, recall and AER scores 
in the evaluation results. 
GS
CS
||
||
G
CG
S
SS
precision
?=      (18)
||
 ||
C
CG
S
SS
recall
?=  (19)
                                                 
2 For a non one-to-one link, if m source words are aligned to 
n target words, we take it as one alignment link instead of 
m?n alignment links. 
||||
||2
CG
CG
SS
SS
fmeasure +
?=  (20)
fmeasure
SS
SS
AER ?=+
??= 1
||||
||2
1
CG
CG  (21)
6.3 Experimental Results 
We use the held-out data described in section 6.1 
to set the interpolation weights in section 5. t?  is 
set to 0.3, n?  is set to 0.1, d3?  for model 3  is set 
to 0.5, and d4?  for model 4 is set to 0.1. With 
these parameters, we get the lowest alignment 
error rate on the held-out data. 
For each method described above, we perform 
bi-directional (source to target and target to 
source) word alignment and obtain two align-
ment results. Based on the two results, we get a 
result using "refined" combination as described 
in (Och and Ney, 2000). Thus, all of the results 
reported here describe the results of the "refined" 
combination. For model training, we use the 
GIZA++ toolkit3. 
Method Precision Recall AER 
Interpolated 0.6955 0.5802 0.3673
Advanced 
Induced 0.7382 0.4803 0.4181
Basic  
Induced 0.6787 0.4602 0.4515
Original 0.6026 0.4783 0.4667
Table 2. Word Alignment Results 
The evaluation results on the testing data are 
shown in table 2.  From the results, it can be seen 
that both of the two induced models perform bet-
ter than the "Original" method that only uses the 
limited Chinese-Japanese sentence pairs. The 
"Advanced Induced" method achieves a relative 
error rate reduction of 10.41% as compared with 
the "Original" method. Thus, with the Chinese-
English corpus and the English-Japanese corpus, 
we can achieve a good word alignment results 
even if no Chinese-Japanese parallel corpus is 
available. After introducing the cross-language 
word similarity into the translation probability, 
the "Advanced Induced" method achieves a rela-
tive error rate reduction of 7.40% as compared 
with the "Basic Induced" method. It indicates 
that cross-language word similarity is effective in 
the calculation of the translation probability. 
Moreover, the "interpolated" method further im-
proves the result, which achieves relative error 
                                                 
3 It is located at http://www.fjoch.com/ GIZA++.html. 
880
rate reductions of 12.51% and 21.30% as com-
pared with the "Advanced Induced" method and 
the "Original" method. 
7 Conclusion and Future Work 
This paper presented a word alignment approach 
for languages with scarce resources using bilin-
gual corpora of other language pairs. To perform 
word alignment between languages L1 and L2, 
we introduce a pivot language L3 and bilingual 
corpora in L1-L3 and L2-L3. Based on these two 
corpora and with the L3 as a pivot language, we 
proposed an approach to estimate the parameters 
of the statistical word alignment model. This ap-
proach can build a word alignment model for the 
desired language pair even if no bilingual corpus 
is available in this language pair. Experimental 
results indicate a relative error reduction of 
10.41% as compared with the method using the 
small bilingual corpus. 
In addition, we interpolated the above model 
with the model trained on the small L1-L2 bilin-
gual corpus to further improve word alignment 
between L1 and L2. This interpolated model fur-
ther improved the word alignment results by 
achieving a relative error rate reduction of 
12.51% as compared with the method using the 
two corpora in L1-L3 and L3-L2, and a relative 
error rate reduction of 21.30% as compared with 
the method using the small bilingual corpus in 
L1 and L2. 
In future work, we will perform more evalua-
tions. First, we will further investigate the effect 
of the size of corpora on the alignment results. 
Second, we will investigate different parameter 
combination of the induced model and the origi-
nal model. Third, we will also investigate how 
simpler IBM models 1 and 2 perform, in com-
parison with IBM models 3 and 4. Last, we will 
evaluate the word alignment results in a real ma-
chine translation system, to examine whether 
lower word alignment error rate will result in 
higher translation accuracy. 
References 
Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin 
Knight, John Lafferty, Dan Melamed, Franz-Josef 
Och, David Purdy, Noah A. Smith, and David 
Yarowsky. 1999. Statistical Machine Translation 
Final Report. Johns Hopkins University Workshop. 
Niraj Aswani and Robert Gaizauskas. 2005. Aligning 
Words in English-Hindi Parallel Corpora. In Proc. 
of the ACL 2005 Workshop on Building and Using 
Parallel Texts: Data-driven Machine Translation 
and Beyond, pages 115-118.  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimation. Computational Linguistics, 
19(2): 263-311. 
Colin Cherry and Dekang Lin. 2003. A Probability 
Model to Improve Word Alignment. In Proc. of the 
41st  Annual Meeting of the Association for Compu-
tational Linguistics (ACL-2003), pages 88-95. 
Sue J. Ker and Jason S. Chang. 1997. A Class-based 
Approach to Word Alignment. Computational Lin-
guistics, 23(2): 313-343. 
Adam Lopez and Philip Resnik. 2005. Improved 
HMM Alignment Models for Languages with 
Scarce Resources. In Proc. of the ACL-2005 Work-
shop on Building and Using Parallel Texts: Data-
driven Machine Translation and Beyond, pages 83-
86. 
Joel Martin, Rada Mihalcea, and Ted Pedersen. 2005. 
Word Alignment for Languages with Scarce Re-
sources. In Proc. of the ACL-2005 Workshop on 
Building and Using Parallel Texts: Data-driven 
Machine Translation and Beyond, pages 65-74. 
Charles Schafer and David Yarowsky. 2002. Inducing 
Translation Lexicons via Diverse Similarity Meas-
ures and Bridge Languages. In Proc. of the 6th 
Conference on Natural Language Learning 2002 
(CoNLL-2002), pages 1-7. 
Dan Tufis, Radu Ion, Alexandru Ceausu, and Dan 
Stefanescu. 2005. Combined Word Alignments. In 
Proc. of the ACL-2005 Workshop on Building and 
Using Parallel Texts: Data-driven Machine Trans-
lation and Beyond, pages 107-110. 
Franz Josef Och and Hermann Ney. 2000. Improved 
Statistical Alignment Models. In Proc. of the 38th 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL-2000), pages 440-447. 
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment 
Models. Computational Linguistics, 29(1):19-51. 
Dekai Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3):377-403. 
Hua Wu, Haifeng Wang, and Zhanyi Liu. 2005. 
Alignment Model Adaptation for Domain-Specific 
Word Alignment. In Proc. of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL-2005), pages 467-474. 
Hao Zhang and Daniel Gildea. 2005. Stochastic Lexi-
calized Inversion Transduction Grammar for 
Alignment. In Proc. of the 43rd Annual Meeting of 
the Association for Computational Linguistics 
(ACL-2005), pages 475-482. 
881
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 913?920,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Boosting Statistical Word Alignment Using  
Labeled and Unlabeled Data 
 
Hua Wu      Haifeng Wang      Zhanyi Liu 
Toshiba (China) Research and Development Center 
5/F., Tower W2, Oriental Plaza, No.1, East Chang An Ave., Dong Cheng District 
Beijing, 100738, China 
{wuhua, wanghaifeng, liuzhanyi}@rdc.toshiba.com.cn 
 
  
 
Abstract 
This paper proposes a semi-supervised 
boosting approach to improve statistical 
word alignment with limited labeled data 
and large amounts of unlabeled data. The 
proposed approach modifies the super-
vised boosting algorithm to a semi-
supervised learning algorithm by incor-
porating the unlabeled data. In this algo-
rithm, we build a word aligner by using 
both the labeled data and the unlabeled 
data. Then we build a pseudo reference 
set for the unlabeled data, and calculate 
the error rate of each word aligner using 
only the labeled data. Based on this semi-
supervised boosting algorithm, we inves-
tigate two boosting methods for word 
alignment. In addition, we improve the 
word alignment results by combining the 
results of the two semi-supervised boost-
ing methods. Experimental results on 
word alignment indicate that semi-
supervised boosting achieves relative er-
ror reductions of 28.29% and 19.52% as 
compared with supervised boosting and 
unsupervised boosting, respectively. 
1 Introduction 
Word alignment was first proposed as an inter-
mediate result of statistical machine translation 
(Brown et al, 1993). In recent years, many re-
searchers build alignment links with bilingual 
corpora (Wu, 1997; Och and Ney, 2003; Cherry 
and Lin, 2003; Wu et al, 2005; Zhang and 
Gildea, 2005). These methods unsupervisedly 
train the alignment models with unlabeled data. 
A question about word alignment is whether 
we can further improve the performances of the 
word aligners with available data and available 
alignment models. One possible solution is to use 
the boosting method (Freund and Schapire, 
1996), which is one of the ensemble methods 
(Dietterich, 2000). The underlying idea of boost-
ing is to combine simple "rules" to form an en-
semble such that the performance of the single 
ensemble is improved. The AdaBoost (Adaptive 
Boosting) algorithm by Freund and Schapire 
(1996) was developed for supervised learning. 
When it is applied to word alignment, it should 
solve the problem of building a reference set for 
the unlabeled data. Wu and Wang (2005) devel-
oped an unsupervised AdaBoost algorithm by 
automatically building a pseudo reference set for 
the unlabeled data to improve alignment results. 
In fact, large amounts of unlabeled data are 
available without difficulty, while labeled data is 
costly to obtain. However, labeled data is valu-
able to improve performance of learners. Conse-
quently, semi-supervised learning, which com-
bines both labeled and unlabeled data, has been 
applied to some NLP tasks such as word sense 
disambiguation (Yarowsky, 1995; Pham et al, 
2005), classification (Blum and Mitchell, 1998; 
Thorsten, 1999), clustering (Basu et al, 2004), 
named entity classification (Collins and Singer, 
1999), and parsing (Sarkar, 2001). 
In this paper, we propose a semi-supervised 
boosting method to improve statistical word 
alignment with both limited labeled data and 
large amounts of unlabeled data. The proposed 
approach modifies the supervised AdaBoost al-
gorithm to a semi-supervised learning algorithm 
by incorporating the unlabeled data. Therefore, it 
should address the following three problems. The 
first is to build a word alignment model with 
both labeled and unlabeled data. In this paper, 
with the labeled data, we build a supervised 
model by directly estimating the parameters in 
913
the model instead of using the Expectation 
Maximization (EM) algorithm in Brown et al 
(1993). With the unlabeled data, we build an un-
supervised model by estimating the parameters 
with the EM algorithm. Based on these two word 
alignment models, an interpolated model is built 
through linear interpolation. This interpolated 
model is used as a learner in the semi-supervised 
AdaBoost algorithm. The second is to build a 
reference set for the unlabeled data. It is auto-
matically built with a modified "refined" combi-
nation method as described in Och and Ney 
(2000). The third is to calculate the error rate on 
each round. Although we build a reference set 
for the unlabeled data, it still contains alignment 
errors. Thus, we use the reference set of the la-
beled data instead of that of the entire training 
data to calculate the error rate on each round.  
With the interpolated model as a learner in the 
semi-supervised AdaBoost algorithm, we inves-
tigate two boosting methods in this paper to im-
prove statistical word alignment. The first 
method uses the unlabeled data only in the inter-
polated model. During training, it only changes 
the distribution of the labeled data. The second 
method changes the distribution of both the la-
beled data and the unlabeled data during training. 
Experimental results show that both of these two 
methods improve the performance of statistical 
word alignment. 
In addition, we combine the final results of the 
above two semi-supervised boosting methods. 
Experimental results indicate that this combina-
tion outperforms the unsupervised boosting 
method as described in Wu and Wang (2005), 
achieving a relative error rate reduction of 
19.52%. And it also achieves a reduction of 
28.29% as compared with the supervised boost-
ing method that only uses the labeled data. 
The remainder of this paper is organized as 
follows. Section 2 briefly introduces the statisti-
cal word alignment model. Section 3 describes 
parameter estimation method using the labeled 
data. Section 4 presents our semi-supervised 
boosting method. Section 5 reports the experi-
mental results. Finally, we conclude in section 6. 
2 Statistical Word Alignment Model 
According to the IBM models (Brown et al, 
1993), the statistical word alignment model can 
be generally represented as in equation (1).  
?=
a'
e|f,a'
e|fa,
e|fa,
)Pr(
)Pr(
)Pr(  
(1)
Where  and f  represent the source sentence 
and the target sentence, respectively. 
e
In this paper, we use a simplified IBM model 
4 (Al-Onaizan et al, 1999), which is shown in 
equation (2). This simplified version does not 
take into account word classes as described in 
Brown et al (1993). 
))))(()](([                
))()](([(                 
)|( )|(                 
   
 )Pr(
0,1
1
0,1
1
11
1
2
0
0
0 00
?
?
??
?=
>
?=
==
?
???
+??=
??
????
?
???
? ?=
m
aj
j
m
aj
j
m
j
aj
l
i
ii
m
j
j
ja
j
jpjdahj
cjdahj
eften
pp
m
?
??
?
?
?
e|fa,
(2)
ml,  are the lengths of the source sentence and 
the target sentence respectively. 
j  is the position index of the target word. 
ja  is the position of the source word aligned to 
the  target word. thj
i?  is the number of target words that  is 
aligned to. 
ie
0p ,  are the fertility probabilities for , and 1p 0e
110 =+ pp . 
)|
jaj
et(f  is the word translation probability. 
)|( ii en ?  is the fertility probability. 
)(1
ja
cjd ??  is the distortion probability for the 
head word of cept1 i. 
))((1 jpjd ?>  is the distortion probability for the 
non-head words of cept i. 
}:{min)( k
k
aikih ==  is the head of cept i. 
}:{max)( kj
jk
aakjp ==
<
. 
i?  is the first word before  with non-zero  ie
fertility.  
ic  is the center of cept i. 
3 Parameter Estimation with Labeled 
Data 
With the labeled data, instead of using EM algo-
rithm, we directly estimate the three main pa-
rameters in model 4: translation probability, fer-
tility probability, and distortion probability. 
                                                 
1 A cept is defined as the set of target words connected to a source word 
(Brown et al, 1993).  
914
3.1 Translation Probability Where 1),( =yx?  if yx = . Otherwise, 0),( =yx? .  
The translation probability is estimated from the 
labeled data as described in (3). 4 Boosting with Labeled Data and 
Unlabeled Data 
?=
'
)',(
),(
)|(
f
i
ji
ij
fecount
fecount
eft  
(3) In this section, we first propose a semi-
supervised AdaBoost algorithm for word align-
ment, which uses both the labeled data and the 
unlabeled data. Based on the semi-supervised 
algorithm, we describe two boosting methods for 
word alignment. And then we develop a method 
to combine the results of the two boosting meth-
ods. 
Where  is the occurring frequency of 
 aligned to  in the labeled data. 
),( ji fecount
ie jf
3.2 Fertility Probability 
The fertility probability )|( ii en ?  describes the 
distribution of the numbers of words that  is 
aligned to. It is estimated as described in (4).  
ie 4.1 Semi-Supervised AdaBoost Algorithm 
for Word Alignment 
?=
'
),'(
),(
)|(
?
?
??
i
ii
ii ecount
ecount
en  
(4)
Figure 1 shows the semi-supervised AdaBoost 
algorithm for word alignment by using labeled 
and unlabeled data. Compared with the super-
vised Adaboost algorithm, this semi-supervised 
AdaBoost algorithm mainly has five differences.  
Where ),( ii ecount ? describes the occurring fre-
quency of word  aligned to ie i?  target words in 
the labeled data.  Word Alignment Model  
0p  and   describe the fertility probabilities 
for .  And  and  sum to 1. We estimate 
 directly from the labeled data, which is 
shown in (5). 
1p
0e 0p 1p
0p
The first is the word alignment model, which 
is taken as a learner in the boosting algorithm. 
The word alignment model is built using both the 
labeled data and the unlabeled data. With the 
labeled data, we train a supervised model by di-
rectly estimating the parameters in the IBM 
model as described in section 3. With the unla-
beled data, we train an unsupervised model using 
the same EM algorithm in Brown et al (1993). 
Then we build an interpolation model by linearly 
interpolating these two word alignment models, 
which is shown in (8). This interpolated model is 
used as the model  described in figure 1. lM
 
Aligned
NullAligned
p
#
##
0
?=  (5)
Where  is the occurring frequency of 
the target words that have counterparts in the 
source language. is the occurring fre-
quency of the target words that have no counter-
parts in the source language. 
Aligned#
Null#
3.3 Distortion Probability 
)(Pr)1()(Pr
)Pr(
US e|fa,e|fa,
e|fa,
??+?= ??  (8)There are two kinds of distortion probability in 
model 4: one for head words and the other for 
non-head words. Both of the distortion probabili-
ties describe the distribution of relative positions 
Thus, if we let 
i
cjj ??=? 1  and )(1 jpjj ?=? > , 
the distortion probabilities for head words and 
non-head words are estimated in (6) and (7) with 
the labeled data, respectively. 
Where  and  are the 
trained supervised model and unsupervised 
model, respectively. 
)(PrS e|fa, )(PrU e|fa,
?  is an interpolation weight. 
We train the weight in equation (8) in the same 
way as described in Wu et al (2005).  
Pseudo Reference Set for Unlabeled Data 
??
?
?
??
??
=?
'
1 '
'
'
,
''
1
,
1
11
),(
),(
)(
j cj
cj
i
i
i
i
cjj
cjj
jd
?
?
?
?
?
?
 (6)
? ?
?
>?
>
>
>> ??
??
=?
'
1
'' )(,
'''
1
)(,
1
11
))(,(
))(,(
)(
j jpj
jpj
jpjj
jpjj
jd ?
?
 (7)
The second is the reference set for the unla-
beled data. For the unlabeled data, we automati-
cally build a pseudo reference set. In order to 
build a reliable pseudo reference set, we perform 
bi-directional word alignment on the training 
data using the interpolated model trained on the 
first round. Bi-directional word alignment in-
cludes alignment in two directions (source to 
915
Input: A training set  including m  bilingual sentence pairs;  TS
The reference set  for the training data; TR
The reference sets  and  ( ) for the labeled data  and the unlabeled 
data  respectively, where 
LR UR TUL , RRR ? LS
US LUT SSS ?=  and NULLLU =? SS ; 
A loop count L. 
(1) Initialize the weights: 
mimiw ,...,1,/1)(1 ==  
(2) For , execute steps (3) to (9).  L l to1=
(3) For each sentence pair i, normalize the 
weights on the training set: 
? ==
j
lll mijwiwip ,...,1),(/)()(  
(4) Update the word alignment model  
based on the weighted training data. 
lM
(5) Perform word alignment on the training set 
with the alignment model :  lM
)( lll pMh =  
(6) Calculate the error of  with the reference 
set : 
lh
LR ? ?=
i
ll iip )()( ??  
Where )(i?  is calculated as in equation (9). 
(7) If 2/1>l? , then let , and end the 
training process. 
1?= lL
(8) Let )1/( lll ??? ?= . 
(9) For all i, compute new weights: 
nknkiwiw lll /))(()()(1 ???+?=+  
where, n represents n alignment links in 
the ith sentence pair. k represents the num-
ber of error links as compared with . TR
Output: The final word alignment result for a source word e : 
?
=
??==
L
l
ll
lff
fehfeWTfeRSeh
1
F )),((),()
1
(logmaxarg),(maxarg)( ??  
Where 1),( =yx?  if yx = . Otherwise, 0),( =yx? .  is the weight of the alignment link 
 produced by the model , which is calculated as described in equation (10). 
),( feWTl
),( fe lM
Figure 1. The Semi-Supervised Adaboost Algorithm for Word Alignment 
target and target to source) as described in Och 
and Ney (2000). Thus, we get two sets of align-
ment results  and  on the unlabeled data. 
Based on these two sets, we use a modified "re-
fined" method (Och and Ney, 2000) to construct 
a pseudo reference set .  
1A 2A
UR
(1) The intersection  is added to the 
reference set . 
21 AAI ?=
UR
(2) We add  to  if a) is satis-
fied or both b) and c) are satisfied.  
21)  ,( AAfe ?? UR
a) Neither  nor  has an alignment in  
and  is greater than a threshold 
e f UR
)|( efp 1? . 
?=
'
)',(
),(
)|(
f
fecount
fecount
efp  
Where  is the occurring fre-
quency of the alignment link  in 
the bi-directional word alignment results. 
),( fecount
)  ,( fe
b)  has a horizontal or a vertical 
neighbor that is already in . 
)  ,( fe
UR
c) The set does not contain 
alignments with both horizontal and ver-
tical neighbors. 
),(U feR ?
 Error of Word Aligner 
The third is the calculation of the error of the 
individual word aligner on each round. For word 
alignment, a sentence pair is taken as a sample. 
Thus, we calculate the error rate of each sentence 
pair as described in (9), which is the same as de-
scribed in Wu and Wang (2005).  
 
||||
||2
1)(
RW
RW
SS
SS
i +
??=?  (9)
Where  represents the set of alignment 
links of a sentence pair i identified by the indi-
vidual interpolated model on each round.  is 
the reference alignment set for the sentence pair. 
WS
RS
With the error rate of each sentence pair, we 
calculate the error of the word aligner on each 
round. Although we build a pseudo reference set 
 for the unlabeled data, it contains alignment 
errors. Thus, the weighted sum of the error rates 
of sentence pairs in the labeled data instead of 
that in the entire training data is used as the error 
of the word aligner. 
UR
 
916
 Weights Update for Sentence Pairs  
The forth is the weight update for sentence 
pairs according to the error and the reference set. 
In a sentence pair, there are usually several word 
alignment links. Some are correct, and others 
may be incorrect. Thus, we update the weights 
according to the number of correct and incorrect 
alignment links as compared with the reference 
set, which is shown in step (9) in figure 1.  
 Weights for Word Alignment Links  
The fifth is the weights used when we con-
struct the final ensemble. Besides the weight 
)/1log( l? , which is the confidence measure of 
the  word aligner, we also use the weight 
 to measure the confidence of each 
alignment link produced by the model . The 
weight  is calculated as shown in (10). 
Wu and Wang (2005) proved that adding this 
weight improved the word alignment results. 
thl
),( feWTl
lM
),( feWTl
?? +
?=
''
),'()',(
),(2
),(
ef
l fecountfecount
fecount
feWT
(10) 
Where  is the occurring frequency 
of the alignment link  in the word align-
ment results of the training data produced by the 
model . 
),( fecount
)  ,( fe
lM
4.2 Method 1 
This method only uses the labeled data as train-
ing data. According to the algorithm in figure 1, 
we obtain  and . Thus, we only 
change the distribution of the labeled data. How-
ever, we build an unsupervised model using the 
unlabeled data. On each round, we keep this un-
supervised model unchanged, and we rebuild the 
supervised model by estimating the parameters 
as described in section 3 with the weighted train-
ing data. Then we interpolate the supervised 
model and the unsupervised model to obtain an 
interpolated model as described in section 4.1. 
The interpolated model is used as the alignment 
model  in figure 1. Thus, in this interpolated 
model, we use both the labeled and unlabeled 
data. On each round, we rebuild the interpolated 
model using the rebuilt supervised model and the 
unchanged unsupervised model. This interpo-
lated model is used to align the training data.  
LT SS = LT RR =
lM
According to the reference set of the labeled 
data, we calculate the error of the word aligner 
on each round. According to the error and the 
reference set, we update the weight of each sam-
ple in the labeled data. 
4.3 Method 2 
This method uses both the labeled data and the 
unlabeled data as training data. Thus, we set 
ULT SSS ?=  and ULT RRR ?=  as described in 
figure 1. With the labeled data, we build a super-
vised model, which is kept unchanged on each 
round.2 With the weighted samples in the train-
ing data, we rebuild the unsupervised model with 
EM algorithm on each round. Based on these two 
models, we built an interpolated model as de-
scribed in section 4.1. The interpolated model is 
used as the alignment model  in figure 1. On 
each round, we rebuild the interpolated model 
using the unchanged supervised model and the 
rebuilt unsupervised model. Then the interpo-
lated model is used to align the training data. 
lM
Since the training data includes both labeled 
and unlabeled data, we need to build a pseudo 
reference set  for the unlabeled data using the 
method described in section 4.1.  According to 
the reference set  of the labeled data, we cal-
culate the error of the word aligner on each 
round. Then, according to the pseudo reference 
set  and the reference set , we update the 
weight of each sentence pair in the unlabeled 
data and in the labeled data, respectively.  
UR
LR
UR LR
There are four main differences between 
Method 2 and Method 1.  
(1) On each round, Method 2 changes the distri-
bution of both the labeled data and the unla-
beled data, while Method 1 only changes the 
distribution of the labeled data. 
(2) Method 2 rebuilds the unsupervised model, 
while Method 1 rebuilds the supervised 
model.  
(3) Method 2 uses the labeled data instead of the 
entire training data to estimate the error of 
the word aligner on each round. 
(4) Method 2 uses an automatically built pseudo 
reference set to update the weights for the 
sentence pairs in the unlabeled data. 
4.4 Combination 
In the above two sections, we described two 
semi-supervised boosting methods for word 
alignment. Although we use interpolated models 
                                                 
2 In fact, we can also rebuild the supervised model accord-
ing to the weighted labeled data. In this case, as we know, 
the error of the supervised model increases. Thus, we keep 
the supervised model unchanged in this method. 
917
for word alignment in both Method 1 and 
Method 2, the interpolated models are trained 
with different weighted data. Thus, they perform 
differently on word alignment. In order to further 
improve the word alignment results, we combine 
the results of the above two methods as described 
in (11). 
  )),(),((maxarg
)(
2211
F3,
feRSfeRS
eh
f
?+?= ??
ods to calculate the precision, recall, f-measure, 
and alignment error rate (AER) are shown in 
equations (12), (13), (14), and (15). It can be 
seen that the higher the f-measure is, the lower 
the alignment error rate is.  
|S|
|SS|
G
CG ?=precision      (12)
|S|
 |SS|
C
CG ?=recall  (11) (13)
||||
||2
CG
CG
SS
SS
fmeasure +
??=  Where  is the combined hypothesis for 
word alignment.  and  are the 
two ensemble results as shown in figure 1 for 
Method 1 and Method 2, respectively. 
)(F3, eh
),(1 feRS ),(2 feRS
1?  and 2?  
are the constant weights. 
(14)
fmeasure
SS
SS
AER ?=+
???= 1
||||
||2
1
CG
CG  (15)
5.3 Experimental Results 
5 Experiments With the data in section 5.1, we get the word 
alignment results shown in table 2. For all of the 
methods in this table, we perform bi-directional 
(source to target and target to source) word 
alignment, and obtain two alignment results on 
the testing set. Based on the two results, we get 
the "refined" combination as described in Och 
and Ney (2000). Thus, the results in table 2 are 
those of the "refined" combination. For EM 
training, we use the GIZA++ toolkit4. 
In this paper, we take English to Chinese word 
alignment as a case study. 
5.1 Data 
We have two kinds of training data from general 
domain: Labeled Data (LD) and Unlabeled Data 
(UD). The Chinese sentences in the data are 
automatically segmented into words. The statis-
tics for the data is shown in Table 1. The labeled 
data is manually word aligned, including 156,421 
alignment links. 
Data # Sentence Pairs 
# English 
Words 
 Results of Supervised Methods  
Using the labeled data, we use two methods to 
estimate the parameters in IBM model 4: one is 
to use the EM algorithm, and the other is to esti-
mate the parameters directly from the labeled 
data as described in section 3.  In table 2, the 
method "Labeled+EM" estimates the parameters 
with the EM algorithm, which is an unsupervised 
method without boosting. And the method "La-
beled+Direct" estimates the parameters directly 
from the labeled data, which is a supervised 
method without boosting. "Labeled+EM+Boost" 
and "Labeled+Direct+Boost" represent the two 
supervised boosting methods for the above two 
parameter estimation methods.  
# Chinese 
Words 
LD 31,069 255,504 302,470 
UD 329,350 4,682,103 4,480,034
Table 1. Statistics for Training Data 
We use 1,000 sentence pairs as testing set, 
which are not included in LD or UD. The testing 
set is also manually word aligned, including 
8,634 alignment links in the testing set3.  
5.2 Evaluation Metrics 
We use the same evaluation metrics as described 
in Wu et al (2005), which is similar to those in 
(Och and Ney, 2000). The difference lies in that 
Wu et al (2005) take all alignment links as sure 
links. 
Our methods that directly estimate parameters 
in IBM model 4 are better than that using the EM 
algorithm.  "Labeled+Direct" is better than "La-
beled+EM", achieving a relative error rate reduc-
tion of 22.97%. And "Labeled+Direct+Boost" is 
better than "Labeled+EM+Boost", achieving a 
relative error rate reduction of 22.98%. In addi-
tion, the two boosting methods perform better 
than their corresponding methods without
 If we use  to represent the set of alignment 
links identified by the proposed method and  
to denote the reference alignment set, the meth-
GS
CS
                                                 
3 For a non one-to-one link, if m source words are aligned to 
n target words, we take it as one alignment link instead of 
m?n alignment links. 
                                                 
4 It is located at http://www.fjoch.com/ GIZA++.html. 
918
Method Precision Recall F-Measure AER 
Labeled+EM 0.6588 0.5210 0.5819 0.4181 
Labeled+Direct 0.7269 0.6609 0.6924 0.3076 
Labeled+EM+Boost 0.7384 0.5651 0.6402 0.3598 
Labeled+Direct+Boost 0.7771 0.6757 0.7229 0.2771 
Unlabeled+EM 0.7485 0.6667 0.7052 0.2948 
Unlabeled+EM+Boost 0.8056 0.7070 0.7531 0.2469 
Interpolated 0.7555 0.7084 0.7312 0.2688 
Method 1 0.7986 0.7197 0.7571 0.2429 
Method 2 0.8060 0.7388 0.7709 0.2291 
Combination 0.8175 0.7858 0.8013 0.1987 
Table 2. Word Alignment Results 
boosting. For example, "Labeled+Direct+Boost" 
achieves an error rate reduction of 9.92% as 
compared with "Labeled+Direct". 
Results of Unsupervised Methods   
With the unlabeled data, we use the EM algo-
rithm to estimate the parameters in the model. 
The method "Unlabeled+EM" represents an un-
supervised method without boosting. And the 
method "Unlabeled+EM+Boost" uses the same 
unsupervised Adaboost algorithm as described in 
Wu and Wang (2005). 
The boosting method "Unlabeled+EM+Boost" 
achieves a relative error rate reduction of 16.25% 
as compared with "Unlabeled+EM". In addition, 
the unsupervised boosting method "Unla-
beled+EM+Boost" performs better than the su-
pervised boosting method "Labeled+Direct+ 
Boost", achieving an error rate reduction of 
10.90%. This is because the size of labeled data 
is too small to subject to data sparseness problem.  
Results of Semi-Supervised Methods    
By using both the labeled and the unlabeled 
data, we interpolate the models trained by "La-
beled+Direct" and "Unlabeled+EM" to get an 
interpolated model. Here, we use "interpolated" 
to represent it. "Method 1" and  "Method 2" rep-
resent the semi-supervised boosting methods de-
scribed in section 4.2 and section 4.3, respec-
tively. "Combination" denotes the method de-
scribed in section 4.4, which combines "Method 
1" and "Method 2".  Both of the weights 1?  and 
2?  in equation (11) are set to 0.5. 
 "Interpolated" performs better than the meth-
ods using only labeled data or unlabeled data. It 
achieves relative error rate reductions of 12.61% 
and 8.82% as compared with "Labeled+Direct" 
and "Unlabeled+EM", respectively. 
Using an interpolation model, the two semi-
supervised boosting methods "Method 1" and 
"Method 2" outperform the supervised boosting 
method "Labeled+Direct+Boost", achieving a 
relative error rate reduction of 12.34% and 
17.32% respectively. In addition, the two semi-
supervised boosting methods perform better than 
the unsupervised boosting method "Unlabeled+ 
EM+Boost". "Method 1" performs slightly better 
than "Unlabeled+EM+Boost". This is because 
we only change the distribution of the labeled 
data in "Method 1". "Method 2" achieves an er-
ror rate reduction of 7.77% as compared with 
"Unlabeled+EM+Boost". This is because we use 
the interpolated model in our semi-supervised 
boosting method, while "Unlabeled+EM+Boost" 
only uses the unsupervised model. 
Moreover, the combination of the two semi-
supervised boosting methods further improves 
the results, achieving relative error rate reduc-
tions of 18.20% and 13.27% as compared with 
"Method 1" and "Method 2", respectively. It also 
outperforms both the supervised boosting 
method "Labeled+Direct+Boost" and the unsu-
pervised boosting method "Unlabeled+EM+ 
Boost", achieving relative error rate reductions of 
28.29% and 19.52% respectively.  
Summary of the Results    
From the above result, it can be seen that all 
boosting methods perform better than their corre-
sponding methods without boosting. The semi-
supervised boosting methods outperform the su-
pervised boosting method and the unsupervised 
boosting method. 
6 Conclusion and Future Work 
This paper proposed a semi-supervised boosting 
algorithm to improve statistical word alignment 
with limited labeled data and large amounts of 
unlabeled data. In this algorithm, we built an in-
terpolated model by using both the labeled data 
919
and the unlabeled data. This interpolated model 
was employed as a learner in the algorithm. Then, 
we automatically built a pseudo reference for the 
unlabeled data, and calculated the error rate of 
each word aligner with the labeled data.  Based 
on this algorithm, we investigated two methods 
for word alignment. In addition, we developed a 
method to combine the results of the above two 
semi-supervised boosting methods. 
Experimental results indicate that our semi-
supervised boosting method outperforms the un-
supervised boosting method as described in Wu 
and Wang (2005), achieving a relative error rate 
reduction of 19.52%. And it also outperforms the 
supervised boosting method that only uses the 
labeled data, achieving a relative error rate re-
duction of 28.29%. Experimental results also 
show that all boosting methods outperform their 
corresponding methods without boosting. 
In the future, we will evaluate our method 
with an available standard testing set. And we 
will also evaluate the word alignment results in a 
machine translation system, to examine whether 
lower word alignment error rate will result in 
higher translation accuracy. 
References 
Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin 
Knight, John Lafferty, Dan Melamed, Franz-Josef 
Och, David Purdy, Noah A. Smith, and David 
Yarowsky. 1999. Statistical Machine Translation 
Final Report. Johns Hopkins University Workshop. 
Sugato Basu, Mikhail Bilenko, and Raymond J. 
Mooney.  2004. Probabilistic Framework for Semi-
Supervised Clustering. In Proc. of the 10th ACM 
SIGKDD International Conference on Knowledge 
Discovery and Data Mining (KDD-2004), pages 
59-68.  
Avrim Blum and Tom Mitchell. 1998. Combing La-
beled and Unlabeled Data with Co-training. In 
Proc. of the 11th Conference on Computational 
Learning Theory (COLT-1998), pages1-10.  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimation. Computational Linguistics, 
19(2): 263-311. 
Colin Cherry and Dekang Lin. 2003. A Probability 
Model to Improve Word Alignment. In Proc. of the 
41st Annual Meeting of the Association for Compu-
tational Linguistics (ACL-2003), pages 88-95. 
Michael Collins and Yoram Singer. 1999. Unsuper-
vised Models for Named Entity Classification. In 
Proc. of the Joint SIGDAT Conference on Empiri-
cal Methods in Natural Language Processing and 
Very Large Corpora (EMNLP/VLC-1999), pages 
100-110. 
Thomas G. Dietterich. 2000. Ensemble Methods in 
Machine Learning. In Proc. of the First Interna-
tional Workshop on Multiple Classifier Systems 
(MCS-2000), pages 1-15. 
Yoav Freund and Robert E. Schapire. 1996. Experi-
ments with a New Boosting Algorithm. In Proc. of 
the 13th International Conference on Machine 
Learning (ICML-1996), pages 148-156. 
Franz Josef Och and Hermann Ney. 2000. Improved 
Statistical Alignment Models. In Proc. of the 38th 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL-2000), pages 440-447. 
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment 
Models. Computational Linguistics, 29(1):19-51. 
Thanh Phong Pham, Hwee Tou Ng, and Wee Sun Lee 
2005. Word Sense Disambiguation with Semi-
Supervised Learning. In Proc. of the 20th National 
Conference on Artificial Intelligence (AAAI 2005), 
pages 1093-1098. 
Anoop Sarkar. 2001. Applying Co-Training Methods 
to Statistical Parsing. In Proc. of the 2nd Meeting of 
the North American Association for Computational 
Linguistics( NAACL-2001), pages 175-182. 
Joachims Thorsten. 1999. Transductive Inference for 
Text Classification Using Support Vector Ma-
chines. In Proc. of the 16th International Confer-
ence on Machine Learning (ICML-1999), pages 
200-209. 
Dekai Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3): 377-403. 
Hua Wu and Haifeng Wang. 2005. Boosting Statisti-
cal Word Alignment. In Proc. of the 10th Machine 
Translation Summit, pages 313-320. 
Hua Wu, Haifeng Wang, and Zhanyi Liu. 2005. 
Alignment Model Adaptation for Domain-Specific 
Word Alignment. In Proc. of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL-2005), pages 467-474. 
David Yarowsky. 1995. Unsupervised Word Sense 
Disambiguation Rivaling Supervised Methods. In 
Proc. of the 33rd Annual Meeting of the Association 
for Computational Linguistics (ACL-1995), pages 
189-196.  
Hao Zhang and Daniel Gildea. 2005. Stochastic Lexi-
calized Inversion Transduction Grammar for 
Alignment. In Proc. of the 43rd Annual Meeting of 
the Association for Computational Linguistics 
(ACL-2005), pages 475-482. 
920
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 487?495,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Collocation Extraction Using Monolingual Word Alignment Method 
 
Zhanyi Liu1,2, Haifeng Wang2, Hua Wu2, Sheng Li1 
1Harbin Institute of Technology, Harbin, China 
2Toshiba (China) Research and Development Center, Beijing, China 
{liuzhanyi,wanghaifeng,wuhua}@rdc.toshiba.com.cn 
lisheng@hit.edu.cn 
 
  
 
Abstract 
Statistical bilingual word alignment has been 
well studied in the context of machine trans-
lation. This paper adapts the bilingual word 
alignment algorithm to monolingual scenario 
to extract collocations from monolingual cor-
pus. The monolingual corpus is first repli-
cated to generate a parallel corpus, where 
each sentence pair consists of two identical 
sentences in the same language. Then the 
monolingual word alignment algorithm is 
employed to align the potentially collocated 
words in the monolingual sentences. Finally 
the aligned word pairs are ranked according 
to refined alignment probabilities and those 
with higher scores are extracted as colloca-
tions. We conducted experiments using Chi-
nese and English corpora individually. Com-
pared with previous approaches, which use 
association measures to extract collocations 
from the co-occurring word pairs within a 
given window, our method achieves higher 
precision and recall. According to human 
evaluation in terms of precision, our method 
achieves absolute improvements of 27.9% on 
the Chinese corpus and 23.6% on the English 
corpus, respectively. Especially, we can ex-
tract collocations with longer spans, achiev-
ing a high precision of 69% on the long-span 
(>6) Chinese collocations. 
1 Introduction 
Collocation is generally defined as a group of 
words that occur together more often than by 
chance (McKeown and Radev, 2000). In this pa-
per, a collocation is composed of two words oc-
curring as either a consecutive word sequence or 
an interrupted word sequence in sentences, such 
as "by accident" or "take ? advice". The collo-
cations in this paper include phrasal verbs (e.g. 
"put on"), proper nouns (e.g. "New York"), idi-
oms (e.g. "dry run"), compound nouns (e.g. "ice 
cream"), correlative conjunctions (e.g. "either ? 
or"), and the other commonly used combinations 
in following types: verb+noun, adjective+noun, 
adverb+verb, adverb+adjective and adjec-
tive+preposition (e.g. "break rules", "strong tea", 
"softly whisper", "fully aware", and "fond of"). 
Many studies on collocation extraction are 
carried out based on co-occurring frequencies of 
the word pairs in texts (Choueka et al, 1983; 
Church and Hanks, 1990; Smadja, 1993; Dun-
ning, 1993; Pearce, 2002; Evert, 2004). These 
approaches use association measures to discover 
collocations from the word pairs in a given win-
dow. To avoid explosion, these approaches gen-
erally limit the window size to a small number. 
As a result, long-span collocations can not be 
extracted1. In addition, since the word pairs in 
the given window are regarded as potential col-
locations, lots of false collocations exist. Al-
though these approaches used different associa-
tion measures to filter those false collocations, 
the precision of the extracted collocations is not 
high. The above problems could be partially 
solved by introducing more resources into collo-
cation extraction, such as chunker (Wermter and 
Hahn, 2004), parser (Lin, 1998; Seretan and We-
hrli, 2006) and WordNet (Pearce, 2001). 
This paper proposes a novel monolingual 
word alignment (MWA) method to extract collo-
cation of higher quality and with longer spans 
only from monolingual corpus, without using 
any additional resources. The difference between 
MWA and bilingual word alignment (Brown et 
al., 1993) is that the MWA method works on 
monolingual parallel corpus instead of bilingual 
corpus used by bilingual word alignment. The 
                                                 
1  Here, "span of collocation" means the distance of two 
words in a collocation. For example, if the span of the col-
location (w1, w2) is 6, it means there are 5 words interrupt-
ing between w1 and w2 in a sentence. 
487
monolingual corpus is replicated to generate a 
parallel corpus, where each sentence pair con-
sists of two identical sentences in the same lan-
guage, instead of a sentence in one language and 
its translation in another language. We adapt the 
bilingual word alignment algorithm to the mono-
lingual scenario to align the potentially collo-
cated word pairs in the monolingual sentences, 
with the constraint that a word is not allowed to 
be aligned with itself in a sentence. In addition, 
we propose a ranking method to finally extract 
the collocations from the aligned word pairs. 
This method assigns scores to the aligned word 
pairs by using alignment probabilities multiplied 
by a factor derived from the exponential function 
on the frequencies of the aligned word pairs. The 
pairs with higher scores are selected as colloca-
tions. 
The main contribution of this paper is that the 
well studied bilingual statistical word alignment 
method is successfully adapted to monolingual 
scenario for collocation extraction. Compared 
with the previous approaches, which use associa-
tion measures to extract collocations, our method 
achieves much higher precision and slightly 
higher recall. The MWA method has the follow-
ing three advantages. First, it explicitly models 
the co-occurring frequencies and position infor-
mation of word pairs, which are integrated into a 
model to search for the potentially collocated 
word pairs in a sentence. Second, a new feature, 
fertility, is employed to model the number of 
words that a word can collocate with in a sen-
tence. Finally, our method can obtain the long-
span collocations. Human evaluations on the ex-
tracted Chinese collocations show that 69% of 
the long-span (>6) collocations are correct. Al-
though the previous methods could also extract 
long-span collocations by setting the larger win-
dow size, the precision is very low. 
In the remainder of this paper, Section 2 de-
scribes the MWA model for collocation extrac-
tion. Section 3 describes the initial experimental 
results. In Section 4, we propose a method to 
improve the MWA models. Further experiments 
are shown in Sections 5 and 6, followed by a dis-
cussion in Section 7. Finally, the conclusions are 
presented in Section 8. 
2 Collocation Extraction With Mono-
lingual Word Alignment Method 
2.1 Monolingual Word Alignment 
Given a bilingual sentence pair, a source lan-
guage word can be aligned with its correspond- 
 
Figure 1. Bilingual word alignment 
ing target language word. Figure 1 shows an ex-
ample of Chinese-to-English word alignment. 
In Figure 1, a word in one language is aligned 
with its counterpart in the other language. For 
examples, the Chinese word "??/tuan-dui" is 
aligned with its English translation "team", while 
the Chinese word "???/fu-ze-ren" is aligned 
with its English translation "leader". 
In the Chinese sentence in Figure 1, there are 
some Chinese collocations, such as (??/tuan-
dui, ???/fu-ze-ren). There are also some Eng-
lish collocations in the English sentence, such as 
(team, leader). We separately illustrate the collo-
cations in the Chinese sentence and the English 
sentence in Figure 2, where the collocated words 
are aligned with each other. 
 
(a) Collocations in the Chinese sentence 
 
(b) Collocations in the English sentence 
Figure 2. Word alignments of collocations in 
sentence 
Comparing the alignments in Figures 1 and 2, 
we can see that the task of monolingual colloca-
tions construction is similar to that of bilingual 
word alignment. In a bilingual sentence pair, a 
source word is aligned with its corresponding 
target word, while in a monolingual sentence, a 
word is aligned with its collocates. Therefore, it 
is reasonable to regard collocation construction 
as a task of aligning the collocated words in 
monolingual sentences. 
?? ??? ? ??  ??  ?  ? ??  ??   ? 
tuan-dui fu-ze-ren zai xiang-mu jin-xing zhong qi guan-jian zuo-yong . 
The team leader plays a key role in the project undertaking . 
The team leader plays a key role in the project undertaking.
The team leader plays a key role in the project undertaking. 
?? ??? ? ??  ??  ?  ? ??  ??   ? 
tuan-dui fu-ze-ren zai xiang-mu jin-xing zhong qi guan-jian zuo-yong .
??  ??? ? ??  ??  ?  ? ??  ??   ?
tuan-dui fu-ze-ren zai xiang-mu jin-xing zhong qi guan-jian zuo-yong . 
488
Statistical bilingual word alignment method, 
which has been well studied in the context of 
machine translation, can extract the aligned bi-
lingual word pairs from a bilingual corpus. This 
paper adapts the bilingual word alignment algo-
rithm to monolingual scenario to align the collo-
cated words in a monolingual corpus. 
Given a sentence with l words },...,{ 1 lwwS = , 
the word alignments ]},1[|),{( liaiA i ?=  can be 
obtained by maximizing the word alignment 
probability of the sentence, according to Eq. (1). 
)|(maxarg SApA
A
?=
??
                    (1) 
Where Aai i ?),(  means that the word iw  is 
aligned with the word 
ia
w . 
In a monolingual sentence, a word never col-
locates with itself. Thus the alignment set is de-
noted as }&],1[|),{( ialiaiA ii ??= . 
We adapt the bilingual word alignment model, 
IBM Model 3 (Brown et al, 1993), to monolin-
gual word alignment. The probability of the 
alignment sequence is calculated using Eq. (2). 
???
==
l
j
jaj
l
i
ii lajdwwtwnSAp j
11
),|()|()|()|( ?   (2) 
Where i?  denotes the number of words that are 
aligned with iw . Three kinds of probabilities are 
involved: 
- Word collocation probability )|(
jaj
wwt , 
which describes the possibility of wj collo-
cating with 
ja
w ;  
- Position collocation probability d(j, aj, l), 
which describes the probability of a word 
in position aj collocating with another 
word in position j; 
- Fertility probability )|( ii wn ? , which de-
scribes the probability of the number of 
words that a word wi can collocate with 
(refer to subsection 7.1 for further discus-
sion). 
Figure 3 shows an example of word alignment 
on the English sentence in Figure 2 (b) with the 
MWA method. In the sentence, the 7th word 
"role" collocates with both the 4th word "play" 
and the 6th word "key". Thus, )|( 74 wwt  and 
)|( 76 wwt  describe the probabilities that the 
word "role" collocates with "play" and "key",  
 
Figure 3. Results of MWA method 
respectively. )12,7|4(d  and )12,7|6(d  describe 
the probabilities that the word in position 7 col-
locates with the words in position 4 and 6 in a 
sentence with 12 words. For the word "role", 7?  
is 2, which indicates that the word "role" collo-
cates with two words in the sentence. 
To train the MWA model, we implement a 
MWA tool for collocation extraction, which uses 
similar training methods for bilingual word 
alignment, except that a word can not be aligned 
to itself. 
2.2 Collocation Extraction 
Given a monolingual corpus, we use the trained 
MWA model to align the collocated words in 
each sentence. As a result, we can generate a set 
of aligned word pairs on the corpus. According 
to the alignment results, we calculate the fre-
quency for two words aligned in the corpus, de-
noted as ),( ji wwfreq . In our method, we filtered 
those aligned word pairs whose frequencies are 
lower than 5. Based on the alignment frequency, 
we estimate the alignment probabilities for each 
aligned word pair as shown in Eq. (3) and (4). 
? ?=
?w j
ji
ji wwfreq
wwfreq
wwp
),(
),(
)|(  (3) 
? ?=
?w i
ji
ij wwfreq
wwfreq
wwp
),(
),(
)|(  (4) 
With alignment probabilities, we assign scores 
to the aligned word pairs and those with higher 
scores are selected as collocations, which are 
estimated as shown in Eq. (5). 
2
)|()|(
),( ijjiji
wwpwwp
wwp
+=      (5) 
3 Initial Experiments 
In this experiment, we used the method as de-
scribed in Section 2 for collocation extraction. 
Since our method does not use any linguistic in-
formation, we compared our method with the  
The team leader plays a key role in the project undertaking . 
(1)        (2)           (3)           (4)      (5)   (6)      (7)      (8)    (9)        (10)               (11)               (12) 
The team leader plays a key role in the project undertaking .
(1)        (2)           (3)           (4)      (5)   (6)      (7)      (8)    (9)        (10)               (11)              (12) 
489
02
4
6
8
10
12
0 20 40 60 80 100 120 140 160 180 200
Top-N collocations (K)
Pr
ec
is
io
n 
(%
)
Our method (Probability)
Log-likelihood ratio
 
Figure 4. Precision of collocations 
baseline methods without using linguistic knowl-
edge. These baseline methods take all co-
occurring word pairs within a given window as 
collocation candidates, and then use association 
measures to rank the candidates. Those candi-
dates with higher association scores are extracted 
as collocations. In this paper, the window size is 
set to [-6, +6]. 
3.1 Data 
The experiments were carried out on a Chinese 
corpus, which consists of one year (2004) of the 
Xinhua news corpus from LDC 2 , containing 
about 28 millions of Chinese words. Since punc-
tuations are rarely used to construct collocations, 
they were removed from the corpora. To auto-
matically estimate the precision of extracted col-
locations on the Chinese corpus, we built a gold 
set by collecting Chinese collocations from 
handcrafted collocation dictionaries, containing 
56,888 collocations. 
3.2 Results 
The precision is automatically calculated against 
the gold set according to Eq. (6). 
)(#
)(#
Top
goldTop
N
N
C
CC
precision
?
?= I            (6) 
Where CTop-N and Cgold denote the top colloca-
tions in the N-best list and the collocations in the 
gold set, respectively. 
We compared our method with several base-
line methods using different association meas-
ures3: co-occurring frequency, log-likelihood 
                                                 
2 Available at: http://www.ldc.upenn.edu/Catalog/Catalog 
Entry.jsp?catalogId=LDC2007T03 
3 The definitions of these measures can be found in Man-
ning and Sch?tze (1999). 
0
20
40
60
80
100
0.0 2.5 3.7 4.8 5.8 6.8 7.8 8.9
log(frequency)
(%
)
Precision
Alignment Probability
 
Figure 5. Frequency vs. precision/alignment 
probability 
ratio, chi-square test, mutual information, and t-
test. Among them, the log-likelihood ratio meas-
ure achieves the best performance. Thus, in this 
paper, we only show the performance of the log-
likelihood ratio measure. 
Figure 4 shows the precisions of the top N col-
locations as N steadily increases with an incre-
ment of 1K, which are extracted by our method 
and the baseline method using log-likelihood 
ratio as the association measure. 
The absolute precision of collocations is not 
high in the figure. For example, among the top 
200K collocations, about 4% of the collocations 
are correct. This is because our gold set contains 
only about 57K collocations. Even if all colloca-
tions in the gold set are included in the 200K-
best list, the precision is only 28%. Thus, it is 
more useful to compare precision curves for col-
locations in the N-best lists extracted by different 
methods. In addition, since this gold set only in-
cludes a small number of collocations, the preci-
sion curves of our method and the baseline 
method are getting closer, as N increases. For 
example, when N is set to 200K, our method and 
the baseline method achieved precisions of 
4.09% and 3.12%, respectively. And when N is 
set to 400K, they achieved 2.78% and 2.26%, 
respectively. For convenience of comparison, we 
set N up to 200K in the experiments. 
From the results, it can also be seen that, 
among the N-best lists with N less than 20K, the 
precision of the collocations extracted by our 
method is lower than that of the collocations ex-
tracted by the baseline, and became higher when 
N is larger than 20K. 
In order to analyze the possible reasons, we 
investigated the relationships among the fre-
quencies of the aligned word pairs, the alignment 
490
xy
b =4
b =2
 
Figure 6.  xbey /?=  
probabilities, and precisions of collocations, 
which are shown in Figure 5. From the figure, 
we can see (1) that the lower the frequencies of 
the aligned word pairs are, the higher the align-
ment probabilities are; and (2) that the precisions 
of the aligned word pairs with lower frequencies 
is lower. According to the above observations, 
we conclude that it is the word pairs with lower 
frequencies but higher probabilities that caused 
the lower precision of the top 20K collocations 
extracted by our method. 
4 Improved MWA Method 
According to the analysis in subsection 3.2, we 
need to penalize the aligned word pairs with 
lower frequencies. In order to achieve the above 
goal, we need to refine the alignment probabili-
ties by using a penalization factor derived from a 
function on the frequencies of the aligned word 
pairs. This function )(xfy =  should satisfy the 
following two conditions, where x  represents 
the log function of frequencies. 
(1) The function is monotonic. When x  is set to 
a smaller number, y  is also small. This re-
sults in the penalization on the aligned word 
pairs with lower frequencies. 
(2) When ??x , y  is set to 1. This means that 
we don?t penalize the aligned word pairs 
with higher frequencies. 
According to the above descriptions, we pro-
pose to use the exponential function in Eq. (7).  
    xbey /?=  (7)
Figure 6 describes this function. The constant 
b in the function is used to adjust the shape of the 
line. The line is sharp with b set to a small num-
ber, while the line is flat with b set to a larger 
number. In our case, if b is set to a larger number,  
0
5
10
15
20
25
0 20 40 60 80 100 120 140 160 180 200
Top-N collocations (K)
Pr
ec
is
io
n 
(%
)
Refined probability
Probability
Baseline (Log-likelihood ratio)
 
Figure 7. Precision of collocations extracted by 
the improved method 
we assign a larger penalization weight to those 
aligned word pairs with lower frequencies. 
According to the above discussion, we can use 
the following measure to assign scores to the 
aligned words pairs generated by the MWA 
method. 
)),(log(
 
2
)|()|(
),(
ji wwfreq
b
ijji
jir
e
wwpwwp
wwp
?
?+=
  (8) 
Where wi and wj are two aligned words. p(wi|wj) 
and p(wj|wi) are alignment probabilities as shown 
in Eq. (3) and (4). )),(log( ji wwfreq  is the log 
function of the frequencies of the aligned word 
pairs (wi, wj). 
5 Evaluation on Chinese corpus 
We used the same Chinese corpus described in 
Section 3 to evaluate the improved method as 
shown in Section 4. In the experiments, b  was 
tuned by using a development set and set to 25. 
5.1 Precision 
In this section, we evaluated the extracted collo-
cations in terms of precision using both auto-
matic evaluation and human evaluation. 
Automatic Evaluation 
Figure 7 shows the precisions of the colloca-
tions in the N-best lists extracted by our method 
and the baseline method against the gold set in 
Section 3. For our methods, we used two differ-
ent measures to rank the aligned word pairs: 
alignment probabilities in Eq. (5) and refined 
491
 Our method Baseline 
True 569 290 
A 25 16 
B 5 4 
C 240 251 
False 
D 161 439 
Table 1. Manual evaluation of the top 1K Chi-
nese collocations. The precisions of our method 
and the baseline method are 56.9% and 29.0%, 
respectively. 
alignment probabilities in Eq. (8). From the re-
sults, it can be seen that with the refined align-
ment probabilities, our method achieved the 
highest precision on the N-best lists, which 
greatly outperforms the best baseline method. 
For example, in the top 1K list, our method 
achieves a precision of 20.6%, which is much 
higher than the precision of the baseline method 
(11.7%). This indicates that the exponential func-
tion used to penalize the alignment probabilities 
plays a key role in demoting most of the aligned 
word pairs with low frequencies. 
Human Evaluation 
In automatic evaluation, the gold set only con-
tains collocations in the existing dictionaries. 
Some collocations related to specific corpora are 
not included in the set. Therefore, we selected 
the top 1K collocations extracted by our im-
proved method to manually estimate the preci-
sion. During human evaluation, the true colloca-
tions are denoted as "True" in our experiments. 
The false collocations were further classified into 
the following classes. 
A: The candidate consists of two words that 
are semantically related, such as (?? doctor,  
?? nurse). 
B: The candidate is a part of the multi-word 
(? 3) collocation. For example, (?? self, ??  
mechanism) is a part of the three-word colloca-
tion (?? self, ?? regulating, ?? mecha-
nism). 
C: The candidates consist of the adjacent 
words that frequently occur together, such as (? 
he, ? say) and (? very, ? good). 
D: Two words in the candidates have no rela-
tionship with each other, but occur together fre-
quently, such as (?? Beijing, ? month) and 
(? and, ? for). 
Table 1 shows the evaluation results. Our 
method extracted 569 true collocations, which  
0
2
4
6
8
10
12
0 1 2 3 4 5 6 7 8 9 10 11 12
Training corpus (Months)
Pr
ec
is
io
n 
(%
)
Our method
Baseline
 
Figure 8. Corpus size vs. precision 
are much more than those extracted by the base-
line method. Further analysis shows that, in addi-
tion to extracting short-span collocations, our 
method extracted collocations with longer spans 
as compared with the baseline method. For ex-
ample, (?? in, ?? state) and (?? because, 
?? so) are two long-span collocations. Among 
the 1K collocations, there are 48 collocation can-
didates whose spans are larger than 6, which are 
not covered by the baseline method since the 
window size is set to 6.  And 33 of them are true 
collocations, with a higher precision of 69%. 
Classes C and D account for the most part of 
the false collocations. Although the words in 
these two classes co-occur frequently, they can 
not be regarded as collocations. And we also 
found out that the errors in class D produced by 
the baseline method are much more than that of 
those produced by our method. This indicates 
that our MWA method can remove much more 
noise from the frequently occurring word pairs. 
In Class A, the two words are semantically re-
lated and occur together in the corpus. These 
kinds of collocations can not be distinguished 
from the true collocations by our method without 
additional resources. 
Since only bigram collocations were extracted 
by our method, the multi-word (? 3) collocations 
were split into bigram collocations, which caused 
the error collocations in Class B4. 
Corpus size vs. precision 
Here, we investigated the effect of the corpus 
size on the precision of the extracted collocations. 
We evaluated the precision against the gold set 
as shown in the automatic evaluation. First, the 
whole corpus (one year of newspaper) was split 
into 12 parts according to the published months. 
Then we calculated the precisions as the training 
                                                 
4 Since only a very small faction of collocations contain 
more than two words, a few error collocations belong to 
Class B. 
492
020
40
60
80
100
0 20 40 60 80 100 120 140 160 180 200
Top-N collocations (K)
R
ec
al
l (
%
)
Our method
Baseline
 
Figure 9. Recall on the Chinese corpus 
corpus increases part by part. The top 20K collo-
cations were selected for evaluation. 
Figure 8 shows the experimental results. The 
precision of collocations extracted by our method 
is obviously higher than that of collocations ex-
tracted by the baseline method. When the size of 
the training corpus became larger, the difference 
between our method and the baseline method 
also became bigger. When the training corpus 
contains more than 9 months of corpora, the pre-
cision of collocations extracted by the baseline 
method did not increase anymore. However, the 
precision of collocations extracted by our method 
kept on increasing. This indicates the MWA 
method can extract more true collocations of 
higher quality when it is trained with larger size 
of training data. 
5.2 Recall 
Recall was evaluated on a manually labeled sub-
set of the training corpus. The subset contains 
100 sentences that were randomly selected from 
the whole corpus. The sentence average length is 
24. All true collocations (660) were labeled 
manually. The recall was calculated according to 
Eq. (9). 
)(#
)(#
subset
subsetTop
C
CC
recall N
I?=               (9) 
Here, CTop-N denotes the top collocations in the 
N-best list and Csubset denotes the true colloca-
tions in the subset. 
Figure 9 shows the recalls of collocations ex-
tracted by our method and the baseline method 
on the labeled subset. The results show that our 
method can extract more true collocations than 
the baseline method. 
0
20
40
60
80
100
0 20 40 60 80 100 120 140 160 180 200
Top-N collocations (K)
R
ec
al
l (
%
)
Our method
Baseline
 
Figure 10. Recall on the English corpus 
 Our method Baseline 
True 591 355 
A 11 4 
B 19 20 
C 200 136 
False
D 179 485 
Table 2. Manual evaluation of the top 1K Eng-
lish collocations. The precisions of our method 
and the baseline method are 59.1% and 35.5%, 
respectively. 
In our experiments, the baseline method ex-
tracts about 20 millions of collocation candidates, 
while our method only extracts about 3 millions 
of collocation candidates5. Although the colloca-
tions of our method are much less than that of the 
baseline, the experiments show that the recall of 
our method is higher. This again proved that our 
method has the stronger ability to distinguish 
true collocations from false collocations. 
6 Evaluation on English corpus 
We also manually evaluated the proposed 
method on an English corpus, which is a subset 
randomly extracted from the British National 
Corpus6. The English corpus contains about 20 
millions of words. 
6.1 Precision 
We estimated the precision of the top 1K collo-
cations. Table 2 shows the results. The classifica-
tion of the false collocations is the same as that 
in Table 1. The results show that our methods 
outperformed the baseline method using log- 
                                                 
5 We set the threshold to 7.88 with a confidence level  of 
005.0=?  (cf. page 174 of Chapter 5 in (McKeown and 
Radev, 2000) for more details). 
6 Available at: http://www.hcu.ox.ac.uk/BNC/ 
493
05
10
15
20
0 20 40 60 80 100 120 140 160 180
Top-N collocation (K)
Pr
ec
is
io
n 
(%
)
 
Figure 11. Fertility vs. precision 
likelihood ratio. And the distribution of the false 
collocations is similar to that on the Chinese cor-
pus. 
6.2 Recall 
We used the method described in subsection 5.2 
to calculate the recall. 100 English sentences 
were labeled manually, obtaining 205 true collo-
cations. Figure 10 shows the recall of the collo-
cations in the N-best lists. From the figure, it can 
be seen that the trend on the English corpus is 
similar to that on the Chinese corpus, which in-
dicates that our method is language-independent. 
7 Discussion 
7.1 The Effect of Fertility 
In the MWA model as described in subsection 
2.1, i?  denotes the number of words that can 
align with iw . Since a word only collocates with 
a few other words in a sentence, we should set a 
maximum number for ? , denote as max? . 
In order to set max? , we examined the true col-
locations in the manually labeled set described in 
subsection 5.2. We found that 78% of words col-
locate with only one word, and 17% of words 
collocate with two words. In sum, 95% of words 
in the corpus can only collocate with at most two 
words. According to the above observation, we 
set max?  to 2. 
In order to further examine the effect of max?  
on collocation extraction, we used several differ-
ent max?  in our experiments. The comparison 
0
1
2
3
4
5
6
7
8
0 20 40 60 80 100
Span of collocation
lo
g(
#(
al
ig
ne
d 
w
or
d 
pa
irs
))
 
Figure 12. Distribution of spans 
results are shown in Figure 11. The highest pre-
cision is achieved when max?  is set to 2. This 
result verifies our observation on the corpus. 
7.2 Span of Collocation 
One of the advantages of our method is that 
long-span collocations can be reliably extracted. 
In this subsection, we investigate the distribution 
of the span of the aligned word pairs. For the 
aligned word pairs occurring more than once, we 
calculated the average span as shown in Eq. (10). 
),(
);,(
),(
ji
corpuss
ji
ji wwfreq
swwSpan
wwAveSpan
?
= ?  (10) 
Where, );,( swwSpan ji  is the span of the words 
wi and wj in the sentence s; ),( ji wwAveSpan  is 
the average span. 
The distribution is shown in Figure 12. It can 
be seen that the number of the aligned word pairs 
decreased exponentially as the average span in-
creased. About 17% of the aligned word pairs 
have spans longer than 6. According to the hu-
man evaluation result for precision in subsection 
5.1, the precision of the long-span collocations is 
even higher than that of the short-span colloca-
tions. This indicates that our method can extract 
reliable collocations with long spans. 
8 Conclusion 
We have presented a monolingual word align-
ment method to extract collocations from mono-
lingual corpus. We first replicated the monolin-
gual corpus to generate a parallel corpus, in 
which each sentence pair consists of the two 
identical sentences in the same language. Then 
we adapted the bilingual word alignment algo-
rithm to the monolingual scenario to align the 
10
3
2
1
max
max
max
max
=
=
=
=
?
?
?
?
494
potentially collocated word pairs in the monolin-
gual sentences. In addition, a ranking method 
was proposed to finally extract the collocations 
from the aligned word pairs. It scores collocation 
candidates by using alignment probabilities mul-
tiplied by a factor derived from the exponential 
function on the frequencies. Those with higher 
scores are selected as collocations. Both Chinese 
and English collocation extraction experiments 
indicate that our method outperforms previous 
approaches in terms of both precision and recall. 
For example, according to the human evaluations 
on the Chinese corpus, our method achieved a 
precision of 56.9%, which is much higher than 
that of the baseline method (29.0%). Moreover, 
we can extract collocations with longer span. 
Human evaluation on the extracted Chinese col-
locations shows that 69% of the long-span (>6) 
collocations are correct. 
References 
Peter F. Brown, Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimation. Computational Linguistics, 
19(2): 263-311. 
Yaacov Choueka, S.T. Klein, and E. Neuwitz. 1983. 
Automatic Retrieval of Frequent Idiomatic and 
Collocational Expressions in a Large Corpus. 
Journal for Literary and Linguistic computing, 
4(1):34-38. 
Kenneth Church and Patrick Hanks. 1990. Word As-
sociation Norms, Mutual Information, and Lexi-
cography. Computational Linguistics, 16(1):22-29. 
Ted Dunning. 1993. Accurate Methods for the Statis-
tics of Surprise and Coincidence. Computational 
Linguistics, 19(1): 61-74. 
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis, 
University of Stuttgart. 
Dekang Lin. 1998. Extracting Collocations from Text 
Corpora. In Proceedings of the 1st Workshop on 
Computational Terminology, pp. 57-63. 
Christopher D. Manning and Hinrich Sch?tze. 1999. 
Foundations of Statistical Natural Language Proc-
essing, Cambridge, MA; London, U.K.: Bradford 
Book & MIT Press. 
Kathleen R. McKeown and Dragomir R. Radev. 2000. 
Collocations. In Robert Dale, Hermann Moisl, and 
Harold Somers (Ed.), A Handbook of Natural Lan-
guage Processing, pp. 507-523. 
Darren Pearce. 2001. Synonymy in Collocation Ex-
traction. In Proceedings of NAACL-2001 Workshop 
on Wordnet and Other Lexical Resources: Applica-
tions, Extensions and Customizations, pp. 41-46. 
Darren Pearce. 2002. A Comparative Evaluation of 
Collocation Extraction Techniques. In Proceedings 
of the 3rd International Conference on Language 
Resources and Evaluation, pp. 651-658. 
Violeta Seretan and Eric Wehrli. 2006. Accurate Col-
location Extraction Using a Multilingual Parser. In 
Proceedings of the 21st International Conference 
on Computational Linguistics and 44th Annual 
Meeting of the Association for Computational Lin-
guistics (COLING/ACL-2006), pp. 953-960 
Frank Smadja. 1993. Retrieving Collocations from 
Text: Xtract. Computational Linguistics, 19(1): 
143-177. 
Joachim Wermter and Udo Hahn. 2004. Collocation 
Extraction Based on Modifiability Statistics. In 
Proceedings of the 20th International Conference 
on Computational Linguistics (COLING-2004), pp. 
980-986. 
495
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 825?833,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Improving Statistical Machine Translation with 
Monolingual Collocation 
 
Zhanyi Liu1, Haifeng Wang2, Hua Wu2, Sheng Li1 
1Harbin Institute of Technology, Harbin, China 
2Baidu.com Inc., Beijing, China 
zhanyiliu@gmail.com 
{wanghaifeng, wu_hua}@baidu.com 
lisheng@hit.edu.cn 
 
Abstract? 
This paper proposes to use monolingual 
collocations to improve Statistical Ma-
chine Translation (SMT). We make use 
of the collocation probabilities, which are 
estimated from monolingual corpora, in 
two aspects, namely improving word 
alignment for various kinds of SMT sys-
tems and improving phrase table for 
phrase-based SMT. The experimental re-
sults show that our method improves the 
performance of both word alignment and 
translation quality significantly. As com-
pared to baseline systems, we achieve ab-
solute improvements of 2.40 BLEU score 
on a phrase-based SMT system and 1.76 
BLEU score on a parsing-based SMT 
system. 
1 Introduction 
Statistical bilingual word alignment (Brown et al 
1993) is the base of most SMT systems. As com-
pared to single-word alignment, multi-word 
alignment is more difficult to be identified. Al-
though many methods were proposed to improve 
the quality of word alignments (Wu, 1997; Och 
and Ney, 2000; Marcu and Wong, 2002; Cherry 
and Lin, 2003; Liu et al, 2005; Huang, 2009), 
the correlation of the words in multi-word 
alignments is not fully considered. 
In phrase-based SMT (Koehn et al, 2003), the 
phrase boundary is usually determined based on 
the bi-directional word alignments. But as far as 
we know, few previous studies exploit the collo-
cation relations of the words in a phrase. Some 
                                                 
This work was partially done at Toshiba (China) Research 
and Development Center. 
researches used soft syntactic constraints to pre-
dict whether source phrase can be translated to-
gether (Marton and Resnik, 2008; Xiong et al, 
2009). However, the constraints were learned 
from the parsed corpus, which is not available 
for many languages.  
In this paper, we propose to use monolingual 
collocations to improve SMT. We first identify 
potentially collocated words and estimate collo-
cation probabilities from monolingual corpora 
using a Monolingual Word Alignment (MWA) 
method (Liu et al, 2009), which does not need 
any additional resource or linguistic preprocess-
ing, and which outperforms previous methods on 
the same experimental data. Then the collocation 
information is employed to improve Bilingual 
Word Alignment (BWA) for various kinds of 
SMT systems and to improve phrase table for 
phrase-based SMT. 
To improve BWA, we re-estimate the align-
ment probabilities by using the collocation prob-
abilities of words in the same cept. A cept is the 
set of source words that are connected to the 
same target word (Brown et al, 1993). An 
alignment between a source multi-word cept and 
a target word is a many-to-one multi-word 
alignment. 
To improve phrase table, we calculate phrase 
collocation probabilities based on word colloca-
tion probabilities. Then the phrase collocation 
probabilities are used as additional features in 
phrase-based SMT systems. 
The evaluation results show that the proposed 
method in this paper significantly improves mul-
ti-word alignment, achieving an absolute error 
rate reduction of 29%. The alignment improve-
ment results in an improvement of 2.16 BLEU 
score on phrase-based SMT system and an im-
provement of 1.76 BLEU score on parsing-based 
SMT system. If we use phrase collocation proba-
bilities as additional features, the phrase-based 
825
SMT performance is further improved by 0.24 
BLEU score. 
The paper is organized as follows: In section 2, 
we introduce the collocation model based on the 
MWA method. In section 3 and 4, we show how 
to improve the BWA method and the phrase ta-
ble using collocation models respectively. We 
describe the experimental results in section 5, 6 
and 7. Lastly, we conclude in section 8. 
2 Collocation Model 
Collocation is generally defined as a group of 
words that occur together more often than by 
chance (McKeown and Radev, 2000). A colloca-
tion is composed of two words occurring as ei-
ther a consecutive word sequence or an inter-
rupted word sequence in sentences, such as "by 
accident" or "take ... advice". In this paper, we 
use the MWA method (Liu et al, 2009) for col-
location extraction. This method adapts the bi-
lingual word alignment algorithm to monolingual 
scenario to extract collocations only from mono-
lingual corpora. And the experimental results in 
(Liu et al, 2009) showed that this method 
achieved higher precision and recall than pre-
vious methods on the same experimental data. 
2.1 Monolingual word alignment 
The monolingual corpus is first replicated to 
generate a parallel corpus, where each sentence 
pair consists of two identical sentences in the 
same language. Then the monolingual word 
alignment algorithm is employed to align the 
potentially collocated words in the monolingual 
sentences. 
According to Liu et al (2009), we employ the 
MWA Model 3 (corresponding to IBM Model 3) 
to calculate the probability of the monolingual 
word alignment sequence, as shown in Eq. (1). 
? ?
???
?
?
l
j
jaj
l
i
ii
lajdwwt
wnSASp
j1
1
3 ModelMWA 
),|()|(
)|()|,( ?    (1) 
Where lwS 1?  is a monolingual sentence, i?  
denotes the number of words that are aligned 
with 
iw . Since a word never collocates with itself, 
the alignment set is denoted as 
}&],1[|),{( ialiaiA ii ??? . Three kinds of prob-
abilities are involved in this model: word collo-
cation probability 
)|( jaj wwt
, position colloca-
tion probability ),|( lajd j  and fertility probabili-
ty )|( ii wn ? . 
In the MWA method, the similar algorithm to 
bilingual word alignment is used to estimate the 
parameters of the models, except that a word 
cannot be aligned to itself.  
Figure 1 shows an example of the potentially 
collocated word pairs aligned by the MWA me-
thod. 
 
Figure 1. MWA Example 
2.2 Collocation probability 
Given the monolingual word aligned corpus, we 
calculate the frequency of two words aligned in 
the corpus, denoted as ),( ji wwfreq . We filtered 
the aligned words occurring only once. Then the 
probability for each aligned word pair is esti-
mated as follows: 
? ??
?w j
ji
ji wwfreq
wwfreqwwp ),(
),()|(
                 (2) 
? ??
?w i
ji
ij wwfreq
wwfreqwwp ),(
),()|(
                  (3) 
In this paper, the words of collocation are 
symmetric and we do not determine which word 
is the head and which word is the modifier. Thus, 
the collocation probability of two words is de-
fined as the average of both probabilities, as in 
Eq. (4). 
2
)|()|(),( ijjiji wwpwwpwwr ??
      (4) 
If we have multiple monolingual corpora to 
estimate the collocation probabilities, we interpo-
late the probabilities as shown in Eq. (5). 
),(),( jik kkji wwrwwr ?? ?
          (5) 
k?  denotes the interpolation coefficient for 
the probabilities estimated on the kth corpus. 
3 Improving Statistical Bilingual Word 
Alignment 
We use the collocation information to improve 
both one-directional and bi-directional bilingual 
word alignments. The alignment probabilities are 
re-estimated by using the collocation probabili-
ties of words in the same cept. 
The team leader plays a key role in the project undertaking. 
The team leader plays a key role in the project undertaking. 
 
826
3.1 Improving one-directional bilingual 
word alignment 
According to the BWA method, given a bilingual 
sentence pair leE 1?  and mfF 1? , the optimal 
alignment sequence A  between E and F can be 
obtained as in Eq. (6). 
)|,(maxarg* EAFpA A?
                   (6) 
The method is implemented in a series of five 
models (IBM Models). IBM Model 1 only em-
ploys the word translation model to calculate the 
probabilities of alignments. In IBM Model 2, 
both the word translation model and position dis-
tribution model are used. IBM Model 3, 4 and 5 
consider the fertility model in addition to the 
word translation model and position distribution 
model. And these three models are similar, ex-
cept for the word distortion models. 
One-to-one and many-to-one alignments could 
be produced by using IBM models. Although the 
fertility model is used to restrict the number of 
source words in a cept and the position distortion 
model is used to describe the correlation of the 
positions of the source words, the quality of 
many-to-one alignments is lower than that of 
one-to-one alignments. 
Intuitively, the probability of the source words 
aligned to a target word is not only related to the 
fertility ability and their relative positions, but 
also related to lexical tokens of words, such as 
common phrase or idiom. In this paper, we use 
the collocation probability of the source words in 
a cept to measure their correlation strength. Giv-
en source words }|{ iaf jj ?  aligned to ie , their 
collocation probability is calculated as in Eq. (7). 
)1(*
),(2
})|({
1
1 1
][][
?
? ?
??
?
? ??
ii
k kg
giki
jj
i i ffr
iafr ??
? ?
     (7) 
Here, 
kif ][
and 
gif ][
denote the thk  word and 
thg  word in }|{ iaf jj ? ; ),( ][][ giki ffr
 denotes 
the collocation probability of 
kif ][
and 
gif ][
, as 
shown in Eq. (4).  
Thus, the collocation probability of the align-
ment sequence of a sentence pair can be calcu-
lated according to Eq. (8). 
? ?? ?
l
i jj iafrEAFr 1 })|({)|,(
           (8) 
Based on maximum entropy framework, we 
combine the collocation model and the BWA 
model to calculate the word alignment probabili-
ty of a sentence pair, as shown in Eq. (9). 
? ? ?
?
?
'
)),,(exp(
)),,(exp(
)|,(
A i
ii
i
ii
r AEFh
AEFh
EAFp ?
?     (9) 
Here, ),,( AEFhi and i?  denote features and 
feature weights, respectively. We use two fea-
tures in this paper, namely alignment probabili-
ties and collocation probabilities. 
Thus, we obtain the decision rule: 
}),,({maxarg* ?? i iiA AEFhA ?
          (10) 
Based on the GIZA++ package 1 , we imple-
mented a tool for the improved BWA method. 
We first train IBM Model 4 and collocation 
model on bilingual corpus and monolingual cor-
pus respectively. Then we employ the hill-
climbing algorithm (Al-Onaizan et al, 1999) to 
search for the optimal alignment sequence of a 
given sentence pair, where the score of an align-
ment sequence is calculated as in Eq. (10). 
We note that Eq. (8) only deals with many-to-
one alignments, but the alignment sequence of a 
sentence pair also includes one-to-one align-
ments. To calculate the collocation probability of 
the alignment sequence, we should also consider 
the collocation probabilities of such one-to-one 
alignments. To solve this problem, we use the 
collocation probability of the whole source sen-
tence, )(Fr , as the collocation probability of 
one-word cept. 
3.2 Improving bi-directional bilingual word 
alignments 
In word alignment models implemented in GI-
ZA++, only one-to-one and many-to-one word 
alignment links can be found. Thus, some multi-
word units cannot be correctly aligned. The 
symmetrization method is used to effectively 
overcome this deficiency (Och and Ney, 2003). 
Bi-directional alignments are generally obtained 
from source-to-target algnments 
tsA 2  and target-
to-source alignments 
stA 2 , using some heuristic 
rules (Koehn et al, 2005). This method ignores 
the correlation of the words in the same align-
ment unit, so an alignment may include many 
unrelated words2 , which influences the perfor-
mances of SMT systems. 
                                                 
1 http://www.fjoch.com/GIZA++.html 
2 In our experiments, a multi-word unit may include up to 
40 words. 
827
In order to solve the above problem, we incor-
porate the collocation probabilities into the bi-
directional word alignment process. 
Given alignment sets 
tsA 2  and stA 2 . We can 
obtain the union 
sttsts AAA 22 ??? . The source 
sentence mf1  can be segmented into m?  cepts 
mf ?1 . The target sentence le1  can also be seg-
mented into l ?  cepts le ?1 . The words in the same 
cept can be a consecutive word sequence or an 
interrupted word sequence. 
Finally, the optimal alignments A  between 
mf ?1  and le ?1  can be obtained from tsA ?  using the 
following decision rule. 
})()(),({maxarg
),,(
321
),(
*'
1
'
1
????
??
???
? Afe
jiji
AA
ml
jits
frerfep
Afe     (11) 
Here, )( jfr  and )( ier  denote the collocation 
probabilities of the words in the source language 
and target language respectively, which are cal-
culated by using Eq. (7). ),( ji fep  denotes the 
word translation probability that is calculated 
according to Eq. (12). 
i?  denotes the weights of 
these probabilities. 
||*||
2/))|()|((
),(
ji
ee ff
ji fe
efpfep
fep i j
? ? ?
? ? ?
    (12) 
)|( fep  and )|( efp  are the source-to-target 
and target-to-source translation probabilities 
trained from the word aligned bilingual corpus. 
4 Improving Phrase Table 
Phrase-based SMT system automatically extracts 
bilingual phrase pairs from the word aligned bi-
lingual corpus. In such a system, an idiomatic 
expression may be split into several fragments, 
and the phrases may include irrelevant words. In 
this paper, we use the collocation probability to 
measure the possibility of words composing a 
phrase. 
For each bilingual phrase pair automatically 
extracted from word aligned corpus, we calculate 
the collocation probabilities of source phrase and 
target phrase respectively, according to Eq. (13). 
)1(*
),(2
)(
1
1 1
1 ?
? ?
?
?
? ??
nn
wwr
wr
n
i
n
ij
ji
n                  (13) 
Here, nw1  denotes a phrase with n words; 
),( ji wwr
 denotes the collocation probability of a 
Corpora 
Chinese 
words 
English 
words 
Bilingual corpus 6.3M 8.5M 
Additional monolingual 
corpora 
312M 203M 
Table 1. Statistics of training data 
word pair calculated according to Eq. (4). For the 
phrase only including one word, we set a fixed 
collocation probability that is the average of the 
collocation probabilities of the sentences on a 
development set. These collocation probabilities 
are incorporated into the phrase-based SMT sys-
tem as features.  
5 Experiments on Word Alignment 
5.1 Experimental settings 
We use a bilingual corpus, FBIS (LDC2003E14), 
to train the IBM models. To train the collocation 
models, besides the monolingual parts of FBIS, 
we also employ some other larger Chinese and 
English monolingual corpora, namely, Chinese 
Gigaword (LDC2007T38), English Gigaword 
(LDC2007T07), UN corpus (LDC2004E12), Si-
norama corpus (LDC2005T10), as shown in Ta-
ble 1. 
Using these corpora, we got three kinds of col-
location models: 
CM-1: the training data is the additional mo-
nolingual corpora; 
CM-2: the training data is either side of the bi-
lingual corpus; 
CM-3: the interpolation of CM-1 and CM-2. 
To investigate the quality of the generated 
word alignments, we randomly selected a subset 
from the bilingual corpus as test set, including 
500 sentence pairs. Then word alignments in the 
subset were manually labeled, referring to the 
guideline of the Chinese-to-English alignment 
(LDC2006E93), but we made some modifica-
tions for the guideline. For example, if a preposi-
tion appears after a verb as a phrase aligned to 
one single word in the corresponding sentence, 
then they are glued together. 
There are several different evaluation metrics 
for word alignment (Ahrenberg et al, 2000). We 
use precision (P), recall (R) and alignment error 
ratio (AER), which are similar to those in Och 
and Ney (2000), except that we consider each 
alignment as a sure link. 
828
Experiments 
Single word alignments Multi-word alignments 
P R AER P R AER 
Baseline 0.77 0.45 0.43 0.23 0.71 0.65 
Improved BWA methods 
CM-1 0.70 0.50 0.42 0.35 0.86 0.50 
CM-2 0.73 0.48 0.42 0.36 0.89 0.49 
CM-3 0.73 0.48 0.41 0.39 0.78 0.47 
Table 2. English-to-Chinese word alignment results 
 
Figure 2. Example of the English-to-Chinese word alignments generated by the BWA method and 
the improved BWA method using CM-3. " " denotes the alignments of our method; " " denotes 
the alignments of the baseline method. 
||
||
g
rg
S
SSP ??
                      (14) 
||
||
r
rg
S
SSR ??
                     (15) 
||||
||*21
rg
rg
SS
SSAER ???
?              (16) 
Where, 
gS
 and 
rS  denote the automatically 
generated alignments and the reference align-
ments. 
In order to tune the interpolation coefficients 
in Eq. (5) and the weights of the probabilities in 
Eq. (11), we also manually labeled a develop-
ment set including 100 sentence pairs, in the 
same manner as the test set. By minimizing the 
AER on the development set, the interpolation 
coefficients of the collocation probabilities on 
CM-1 and CM-2 were set to 0.1 and 0.9. And the 
weights of probabilities were set as 6.01 ?? , 
2.02 ?? and 2.03 ?? . 
5.2 Evaluation results 
One-directional alignment results 
To train a Chinese-to-English SMT system, 
we need to perform both Chinese-to-English and 
English-to-Chinese word alignment. We only 
evaluate the English-to-Chinese word alignment 
here. GIZA++ with the default settings is used as 
the baseline method. The evaluation results in 
Table 2 indicate that the performances of our 
methods on single word alignments are close to 
that of the baseline method. For multi-word 
alignments, our methods significantly outper-
form the baseline method in terms of both preci-
sion and recall, achieving up to 18% absolute 
error rate reduction. 
Although the size of the bilingual corpus is 
much smaller than that of additional monolingual 
corpora, our methods using CM-1 and CM-2 
achieve comparable performances. It is because 
CM-2 and the BWA model are derived from the 
same resource. By interpolating CM1 and CM2, 
i.e. CM-3, the error rate of multi-word alignment 
results is further reduced. 
Figure 2 shows an example of word alignment 
results generated by the baseline method and the 
improved method using CM-3. In this example, 
our method successfully identifies many-to-one 
alignments such as "the people of the world  
??". In our collocation model, the collocation 
probability of "the people of the world" is much 
higher than that of "people world". And our me-
thod is also effective to prevent the unrelated 
?? ? ???? ?? ?? ? ?? ? ?? ?? ? ?? ? 
China's science and technology research has made achievements which have gained the attention of the people of the world . 
??  ? ???? ?? ?? ? ?? ? ?? ?? ? ?? ? 
zhong-guo  de     ke-xue-ji-shu      yan-jiu      qu-de       le      xu-duo   ling   shi-ren     zhu-mu     de     cheng-jiu . 
china        DE    science and         research   obtain      LE      many     let    common    attract     DE  achievement . 
                             technology                                                                            people    attention   
829
Experiments 
Single word alignments Multi-word alignments All alignments 
P R AER P R AER P R AER 
Baseline 0.84 0.43 0.42 0.18 0.74 0.70 0.52 0.45 0.51 
Our methods 
WA-1 0.80 0.51 0.37 0.30 0.89 0.55 0.58 0.51 0.45 
WA-2 0.81 0.50 0.37 0.33 0.81 0.52 0.62 0.50 0.44 
WA-3 0.78 0.56 0.34 0.44 0.88 0.41 0.63 0.54 0.40 
Table 3. Bi-directional word alignment results 
words from being aligned. For example, in the 
baseline alignment "has made ... have ??", 
"have" and "has" are unrelated to the target word, 
while our method only generated "made  ?
?", this is because that the collocation probabili-
ties of "has/have" and "made" are much lower 
than that of the whole source sentence. 
Bi-directional alignment results 
We build a bi-directional alignment baseline 
in two steps: (1) GIZA++ is used to obtain the 
source-to-target and target-to-source alignments; 
(2) the bi-directional alignments are generated by 
using "grow-diag-final". We use the methods 
proposed in section 3 to replace the correspond-
ing steps in the baseline method. We evaluate 
three methods:  
WA-1: one-directional alignment method pro-
posed in section 3.1 and grow-diag-final; 
WA-2: GIZA++ and the bi-directional bilin-
gual word alignments method proposed in 
section 3.2; 
WA-3: both methods proposed in section 3. 
Here, CM-3 is used in our methods. The re-
sults are shown in Table 3. 
We can see that WA-1 achieves lower align-
ment error rate as compared to the baseline me-
thod, since the performance of the improved one-
directional alignment method is better than that 
of GIZA++. This result indicates that improving 
one-directional word alignment results in bi-
directional word alignment improvement. 
The results also show that the AER of WA-2 
is lower than that of the baseline. This is because 
the proposed bi-directional alignment method 
can effectively recognize the correct alignments 
from the alignment union, by leveraging colloca-
tion probabilities of the words in the same cept. 
Our method using both methods proposed in 
section 3 produces the best alignment perfor-
mance, achieving 11% absolute error rate reduc-
tion. 
Experiments BLEU (%) 
Baseline 29.62 
Our methods 
WA-1 
CM-1 30.85 
CM-2 31.28 
CM-3 31.48 
WA-2 
CM-1 31.00 
CM-2 31.33 
CM-3 31.51 
WA-3 
CM-1 31.43 
CM-2 31.62 
CM-3 31.78 
Table 4. Performances of Moses using the dif-
ferent bi-directional word alignments (Signifi-
cantly better than baseline with p < 0.01) 
6 Experiments on Phrase-Based SMT 
6.1 Experimental settings 
We use FBIS corpus to train the Chinese-to-
English SMT systems. Moses (Koehn et al, 2007) 
is used as the baseline phrase-based SMT system. 
We use SRI language modeling toolkit (Stolcke, 
2002) to train a 5-gram language model on the 
English sentences of FBIS corpus. We used the 
NIST MT-2002 set as the development set and 
the NIST MT-2004 test set as the test set. And 
Koehn's implementation of minimum error rate 
training (Och, 2003) is used to tune the feature 
weights on the development set. 
We use BLEU (Papineni et al, 2002) as eval-
uation metrics. We also calculate the statistical 
significance differences between our methods 
and the baseline method by using paired boot-
strap re-sample method (Koehn, 2004). 
6.2 Effect of improved word alignment on 
phrase-based SMT 
We investigate the effectiveness of the improved 
word alignments on the phrase-based SMT sys-
tem. The bi-directional alignments are obtained 
830
 Figure 3. Example of the translations generated by the baseline system and the system where the 
phrase collocation probabilities are added 
Experiments BLEU (%) 
Moses 29.62 
+ Phrase collocation probability 30.47 
+ Improved word alignments 
+ Phrase collocation probability 
32.02 
Table 5. Performances of Moses employing 
our proposed methods (Significantly better than 
baseline with p < 0.01) 
using the same methods as those shown in Table 
3. Here, we investigate three different collocation 
models for translation quality improvement. The 
results are shown in Table 4. 
From the results of Table 4, it can be seen that 
the systems using the improved bi-directional 
alignments achieve higher quality of translation 
than the baseline system. If the same alignment 
method is used, the systems using CM-3 got the 
highest BLEU scores. And if the same colloca-
tion model is used, the systems using WA-3 
achieved the higher scores. These results are 
consistent with the evaluations of word align-
ments as shown in Tables 2 and 3. 
6.3 Effect of phrase collocation probabili-
ties 
To investigate the effectiveness of the method 
proposed in section 4, we only use the colloca-
tion model CM-3 as described in section 5.1. The 
results are shown in Table 5. When the phrase 
collocation probabilities are incorporated into the 
SMT system, the translation quality is improved, 
achieving an absolute improvement of 0.85 
BLEU score. This result indicates that the collo-
cation probabilities of phrases are useful in de-
termining the boundary of phrase and predicting 
whether phrases should be translated together, 
which helps to improve the phrase-based SMT 
performance. 
Figure 3 shows an example: T1 is generated 
by the system where the phrase collocation prob-
abilities are used and T2 is generated by the 
baseline system. In this example, since the collo-
cation probability of "? ??" is much higher 
than that of "?? ?", our method tends to split 
"? ?? ?" into "(? ??) (?)", rather than 
"(?) (?? ?)". For the phrase "?? ??" in 
the source sentence, the collocation probability 
of the translation "in order to avoid" is higher 
than that of the translation "can we avoid". Thus, 
our method selects the former as the translation. 
Although the phrase "?? ?? ?? ?? ?
?" in the source sentence has the same transla-
tion "We must adopt effective measures", our 
method splits this phrase into two parts "?? ?
?" and "?? ?? ??", because two parts 
have higher collocation probabilities than the 
whole phrase. 
We also investigate the performance of the 
system employing both the word alignment im-
provement and phrase table improvement me-
thods. From the results in Table 5, it can be seen 
that the quality of translation is future improved. 
As compared with the baseline system, an abso-
lute improvement of 2.40 BLEU score is 
achieved. And this result is also better than  the 
results shown in Table 4. 
7 Experiments on Parsing-Based SMT 
We also investigate the effectiveness of the im-
proved word alignments on the parsing-based 
SMT system, Joshua (Li et al, 2009). In this sys-
tem, the Hiero-style SCFG model is used 
(Chiang, 2007), without syntactic information. 
The rules are extracted only based on the FBIS 
corpus, where words are aligned by "MW-3 & 
CM-3". And the language model is the same as 
that in Moses. The feature weights are tuned on 
the development set using the minimum error 
??  ??  ??  ??  ??  ??  ??  ?  ??  ? 
wo-men bi-xu      cai-qu   you-xiao  cuo-shi   cai-neng  bi-mian  chu      wen-ti      . 
we          must        use      effective   measure    can        avoid    out      problem  . 
We must  adopt effective measures  in order to avoid  problems  . 
 
 
We must adopt effective measures  can we avoid  out of the  question . 
T1: 
T2: 
831
Experiments BLEU (%) 
Joshua 30.05 
+ Improved word alignments 31.81 
Table 6. Performances of Joshua using the dif-
ferent word alignments (Significantly better than 
baseline with p < 0.01) 
rate training method. We use the same evaluation 
measure as described in section 6.1. 
The translation results on Joshua are shown in 
Table 6. The system using the improved word 
alignments achieves an absolute improvement of 
1.76 BLEU score, which indicates that the im-
provements of word alignments are also effective 
to improve the performance of the parsing-based 
SMT systems. 
8 Conclusion 
We presented a novel method to use monolingual 
collocations to improve SMT. We first used the 
MWA method to identify potentially collocated 
words and estimate collocation probabilities only 
from monolingual corpora, no additional re-
source or linguistic preprocessing is needed. 
Then the collocation information was employed 
to improve BWA for various kinds of SMT sys-
tems and to improve phrase table for phrase-
based SMT. 
To improve BWA, we re-estimate the align-
ment probabilities by using the collocation prob-
abilities of words in the same cept. To improve 
phrase table, we calculate phrase collocation 
probabilities based on word collocation probabil-
ities. Then the phrase collocation probabilities 
are used as additional features in phrase-based 
SMT systems. 
The evaluation results showed that the pro-
posed method significantly improved word 
alignment, achieving an absolute error rate re-
duction of 29% on multi-word alignment. The 
improved word alignment results in an improve-
ment of 2.16 BLEU score on a phrase-based 
SMT system and an improvement of 1.76 BLEU 
score on a parsing-based SMT system. When we 
also used phrase collocation probabilities as ad-
ditional features, the phrase-based SMT perfor-
mance is finally improved by 2.40 BLEU score 
as compared with the baseline system. 
Reference 
Lars Ahrenberg, Magnus Merkel, Anna Sagvall Hein, 
and Jorg Tiedemann. 2000. Evaluation of Word 
Alignment Systems. In Proceedings of the Second 
International Conference on Language Resources 
and Evaluation, pp. 1255-1261. 
Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin 
Knight, John Lafferty, Dan Melamed, Franz-Josef 
Och, David Purdy, Noah A. Smith, and David Ya-
rowsky. 1999. Statistical Machine Translation. Fi-
nal Report. In Johns Hopkins University Workshop. 
Peter F. Brown, Stephen A. Della Pietra, Vincent J. 
Della Pietra, and Robert. L. Mercer. 1993. The Ma-
thematics of Statistical Machine Translation: Pa-
rameter estimation. Computational Linguistics, 
19(2): 263-311. 
Colin Cherry and Dekang Lin. 2003. A Probability 
Model to Improve Word Alignment. In Proceed-
ings of the 41st Annual Meeting of the Association 
for Computational Linguistics, pp. 88-95. 
David Chiang. 2007. Hierarchical Phrase-Based 
Translation. Computational Linguistics, 33(2): 
201-228. 
Fei Huang. 2009. Confidence Measure for Word 
Alignment. In Proceedings of the 47th Annual 
Meeting of the ACL and the 4th IJCNLP, pp. 932-
940. 
Philipp Koehn. 2004. Statistical Significance Tests for 
Machine Translation Evaluation. In Proceedings of 
the 2004 Conference on Empirical Methods in 
Natural Language Processing, pp. 388-395. 
Philipp Koehn, Amittai Axelrod, Alexandra Birch 
Mayne, Chris Callison-Burch, Miles Osborne, and 
David Talbot. 2005. Edinburgh System Description 
for the 2005 IWSLT Speech Translation Evalua-
tion. In Processings of the International Workshop 
on Spoken Language Translation 2005. 
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. 
Statistical Phrase-based Translation. In Proceed-
ings of the Human Language Technology Confe-
rence and the North American Association for 
Computational Linguistics, pp. 127-133. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran Ri-
chard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. 
In Proceedings of the 45th Annual Meeting of the 
ACL, Poster and Demonstration Sessions, pp. 177-
180. 
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ga-
nitkevitch, Sanjeev Khudanpur, Lane Schwartz, 
Wren Thornton, Jonathan Weese, and Omar Zaidan. 
2009. Demonstration of Joshua: An Open Source 
Toolkit for Parsing-based Machine Translation. In 
Proceedings of the 47th Annual Meeting of the As-
832
sociation for Computational Linguistics, Software 
Demonstrations, pp. 25-28. 
Yang Liu, Qun Liu, and Shouxun Lin. Log-linear 
Models for Word Alignment. 2005. In Proceedings 
of the 43rd Annual Meeting of the Association for 
Computational Linguistics, pp. 459-466. 
Zhanyi Liu, Haifeng Wang, Hua Wu, and Sheng Li. 
2009. Collocation Extraction Using Monolingual 
Word Alignment Method. In Proceedings of the 
2009 Conference on Empirical Methods in Natural 
Language Processing, pp. 487-495. 
Daniel Marcu and William Wong. 2002. A Phrase-
Based, Joint Probability Model for Statistical Ma-
chine Translation. In Proceedings of the 2002 Con-
ference on Empirical Methods in Natural Lan-
guage Processing,  pp. 133-139. 
Yuval Marton and Philip Resnik. 2008. Soft Syntactic 
Constraints for Hierarchical Phrase-Based Transla-
tion. In Proceedings of the 46st Annual Meeting of 
the Association for Computational Linguistics, pp. 
1003-1011. 
Kathleen R. McKeown and Dragomir R. Radev. 2000. 
Collocations. In Robert Dale, Hermann Moisl, and 
Harold Somers (Ed.), A Handbook of Natural Lan-
guage Processing, pp. 507-523. 
Franz Josef Och and Hermann Ney. 2000. Improved 
Statistical Alignment Models. In Proceedings of 
the 38th Annual Meeting of the Association for 
Computational Linguistics, pp. 440-447. 
Franz Josef Och. 2003. Minimum Error Rate Training 
in Statistical Machine Translation. In Proceedings 
of the 41st Annual Meeting of the Association for 
Computational Linguistics, pp. 160-167. 
Franz Josef Och and Hermann Ney. 2003. A Syste-
matic Comparison of Various Statistical Alignment 
Models. Computational Linguistics, 29(1): 19-52. 
Kishore Papineni, Salim Roukos, Todd Ward, and 
Weijing Zhu. 2002. BLEU: A Method for Auto-
matic Evaluation of Machine Translation. In Pro-
ceedings of 40th annual meeting of the Association 
for Computational Linguistics, pp. 311-318. 
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings for the In-
ternational Conference on Spoken Language 
Processing, pp. 901-904. 
Dekai Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3): 377-403. 
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li. 
2009. A Syntax-Driven Bracketing Model for 
Phrase-Based Translation. In Proceedings of the 
47th Annual Meeting of the ACL and the 4th 
IJCNLP, pp. 315-323. 
 
833
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1036?1044,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Reordering with Source Language Collocations 
 
 
Zhanyi Liu1,2, Haifeng Wang2, Hua Wu2, Ting Liu1, Sheng Li1 
1Harbin Institute of Technology, Harbin, China 
2Baidu Inc., Beijing, China 
{liuzhanyi, wanghaifeng, wu_hua}@baidu.com  
{tliu, lisheng}@hit.edu.cn 
 
 
 
Abstract 
This paper proposes a novel reordering model 
for statistical machine translation (SMT) by 
means of modeling the translation orders of 
the source language collocations. The model 
is learned from a word-aligned bilingual cor-
pus where the collocated words in source sen-
tences are automatically detected. During 
decoding, the model is employed to softly 
constrain the translation orders of the source 
language collocations, so as to constrain the 
translation orders of those source phrases con-
taining these collocated words. The experi-
mental results show that the proposed method 
significantly improves the translation quality, 
achieving the absolute improvements of 
1.1~1.4 BLEU score over the baseline me-
thods. 
1 Introduction 
Reordering for SMT is first proposed in IBM mod-
els (Brown et al, 1993), usually called IBM con-
straint model, where the movement of words 
during translation is modeled. Soon after, Wu 
(1997) proposed an ITG (Inversion Transduction 
Grammar) model for SMT, called ITG constraint 
model, where the reordering of words or phrases is 
constrained to two kinds: straight and inverted. In 
order to further improve the reordering perfor-
mance, many structure-based methods are pro-
posed, including the reordering model in 
hierarchical phrase-based SMT systems (Chiang, 
2005) and syntax-based SMT systems (Zhang et al, 
2007; Marton and Resnik, 2008; Ge, 2010; Vis-
weswariah et al, 2010). Although the sentence 
structure has been taken into consideration, these 
methods don?t explicitly make use of the strong 
correlations between words, such as collocations, 
which can effectively indicate reordering in the 
target language. 
In this paper, we propose a novel method to im-
prove the reordering for SMT by estimating the 
reordering score of the source-language colloca-
tions (source collocations for short in this paper). 
Given a bilingual corpus, the collocations in the 
source sentence are first detected automatically 
using a monolingual word alignment (MWA) me-
thod without employing additional resources (Liu 
et al, 2009), and then the reordering model based 
on the detected collocations is learned from the 
word-aligned bilingual corpus. The source colloca-
tion based reordering model is integrated into SMT 
systems as an additional feature to softly constrain 
the translation orders of the source collocations in 
the sentence to be translated, so as to constrain the 
translation orders of those source phrases contain-
ing these collocated words. 
This method has two advantages: (1) it can au-
tomatically detect and leverage collocated words in 
a sentence, including long-distance collocated 
words; (2) such a reordering model can be inte-
grated into any SMT systems without resorting to 
any additional resources. 
We implemented the proposed reordering mod-
el in a phrase-based SMT system, and the evalua-
tion results show that our method significantly 
improves translation quality. As compared to the 
baseline systems, an absolute improvement of 
1.1~1.4 BLEU score is achieved.  
1036
The paper is organized as follows: In section 2, 
we describe the motivation to use source colloca-
tions for reordering, and briefly introduces the col-
location extraction method. In section 3, we 
present our reordering model. And then we de-
scribe the experimental results in section 4 and 5. 
In section 6, we describe the related work.  Lastly, 
we conclude in section 7. 
2 Collocation 
A collocation is generally composed of a group of 
words that occur together more often than by 
chance. Collocations effectively reveal the strong 
association among words in a sentence and are 
widely employed in a variety of NLP tasks 
(Mckeown and Radey, 2000).   
Given two words in a collocation, they can be 
translated in the same order as in the source lan-
guage, or in the inverted order. We name the first 
case as straight, and the second inverted. Based on 
the observation that some collocations tend to have 
fixed translation orders such as ??? jin-rong ?fi-
nancial? ??  wei-ji ?crisis?? (financial crisis) 
whose English translation order is usually straight, 
and  ???  fa-lv ?law? ??  fan-wei ?scope?? 
(scope of law) whose English translation order is 
generally inverted, some methods have been pro-
posed to improve the reordering model for SMT 
based on the collocated words crossing the neigh-
boring components (Xiong et al, 2006). We fur-
ther notice that some words are translated in 
different orders when they are collocated with dif-
ferent words. For instance, when ??? chao-liu 
?trend?? is collocated with ??? shi-dai ?times??, 
they are often translated into the ?trend of times?; 
when collocated with ??? li-shi ?history??, the 
translation usually becomes the ?historical trend?. 
Thus, if we can automatically detect the colloca-
tions in the sentence to be translated and their or-
ders in the target language, the reordering 
information of the collocations could be used to 
constrain the reordering of phrases during decod-
ing. Therefore, in this paper, we propose to im-
prove the reordering model for SMT by estimating 
the reordering score based on the translation orders 
of the source collocations. 
In general, the collocations can be automatically 
identified based on syntactic information such as 
dependency trees (Lin, 1998). However these me-
thods may suffer from parsing errors. Moreover, 
for many languages, no valid dependency parser 
exists. Liu et al (2009) proposed to automatically 
detect the collocated words in a sentence with the 
MWA method. The advantage of this method lies 
in that it can identify the collocated words in a sen-
tence without additional resources. In this paper, 
we employ MWA Model l~3 described in Liu et al 
(2009) to detect collocations in sentences, which 
are shown in Eq. (1)~(3). 
?
?
?
l
j
cj jwwtSAp 11 ModelMWA 
)|()|(
 (1) 
?
?
??
l
j
jcj lcjdwwtSAp j12 ModelMWA 
),|()|()|(
 (2) 
?
?
?
?
?
???
l
j
jcj
l
i
ii
lcjdwwt
wnSAp
j
1
1
3 ModelMWA 
),|()|(
)|()|(
 (3) 
Where lwS 1?  is a monolingual sentence; i?  de-
notes the number of words collocating with 
iw ; 
}&],1[|),{( icliciA ii ???  denotes the potentially 
collocated words in S. 
The MWA models measure the collocated 
words under different constraints. MWA Model 1 
only models word collocation probabilities 
)|( jcj wwt
. MWA Model 2 additionally employs 
position collocation probabilities 
),|( lcjd j
. Be-
sides the features in MWA Model 2, MWA Model 
3 also considers fertility probabilities )|( ii wn ? . 
Given a sentence, the optimal collocated words 
can be obtained according to Eq. (4). 
)|(maxarg*  ModelMWA SApA iA?
           (4) 
Given a monolingual word aligned corpus, the 
collocation probabilities can be estimated as fol-
lows. 
2
)|()|(),( ijjiji wwpwwpwwr ??           
(5) 
Where, 
?
?
??
w
j
ji
ji wwcount
wwcountwwp ),(
),()|(
; 
),( ji ww  
denotes the collocated words in the corpus and 
),( ji wwcount
 denotes the co-occurrence frequency. 
1037
3 Reordering Model with Source Lan-
guage Collocations 
In this section, we first describe how to estimate 
the orientation probabilities for a given collocation, 
and then describe the estimation of the reordering 
score during translation. Finally, we describe the 
integration of the reordering model into the SMT 
system. 
3.1 Reordering probability estimation 
Given a source collocation ),( ji ff
 and its corres-
ponding translations 
),( ji aa ee
 in a bilingual sen-
tence pair, the reordering orientation of the 
collocation can be defined as in Eq. (6).  
??
?
????
?????
jiji
jiji
aaji aajiaaji
aajiaajio ji &or& ifinverted
or ifstraight
,,,
(6) 
In our method, only those collocated words in 
source language that are aligned to different target 
words, are taken into consideration, and those be-
ing aligned to the same target word are ignored. 
Given a word-aligned bilingual corpus where 
the collocations in source sentences are detected, 
the probabilities of the translation orientation of 
collocations in the source language can be esti-
mated, as follows: 
? ? ?
???
o ji
ji
ji ffocount
ffocountffop ),,(
),,straight(),|straight(
   (7) 
? ? ?
???
o ji
ji
ji ffocount
ffocountffop ),,(
),,inverted(),|inverted(
   
(8) 
Here, ),,( ji ffocount
 is collected according to 
the algorithm in Figure 1. 
3.2 Reordering model 
Given a sentence lfF 1?  to be translated, the col-
locations are first detected using the algorithm de-
scribed in Eq. (4). Then the reordering score is 
estimated according to the reordering probability 
weighted by the collocation probability of the col-
located words. Formally, for a generated transla-
tion candidate T , the reordering score is calculated 
as follows. 
),|(log),(),( ,,,),( iiciii i ciaacici ciO ffopffrTFP ??
    (9) 
Input: A word-aligned bilingual corpus where 
the source collocations are detected 
Initialization: 
),,( ji ffocount
=0 
for each sentence pair <F, E> in the corpus do 
for each collocated word pair 
),( ici ff
in F do 
        if 
icii aaci ?? &
or 
icii aaci ?? &
 then 
            
??? ),,( ici ffstraightocount
 
        if 
icii aaci ?? &
or 
icii aaci ?? &
 then 
            
??? ),,( ici ffinvertedocount  
Output: ),,( ji ffocount
 
Figure 1. Algorithm of estimating  
reordering frequency 
Here, 
),( ici ffr
 denotes the collocation probabil-
ity of 
if  and icf
 as shown in Eq. (5). 
In addition to the detected collocated words in 
the sentence, we also consider other possible word 
pairs whose collocation probabilities are higher 
than a given threshold.  Thus, the reordering score 
is further improved according to Eq. (10). 
?
?
??
?
??
????
),(&
)},{(),(
,,,
,,,
),(
)},|(log),(
),|(log),(),(
ji
i
ji
iicii
i
i
ffr
ciji
jiaajiji
ciaaci
ci
ciO
ffopffr
ffopffrTFP
 
(10) 
Where ? and ?  are two interpolation weights. 
?  is the threshold of collocation probability. The 
weights and the threshold can be tuned using a de-
velopment set. 
3.3 Integrated into SMT system 
The SMT systems generally employ the log-linear 
model to integrate various features (Chiang, 2005; 
Koehn et al, 2007). Given an input sentence F, the 
final translation E* with the highest score is chosen 
from candidates, as in Eq. (11). 
}),({maxarg*
1
?
?
? M
m
mmE
FEhE ?
 (11) 
Where hm(E, F) (m=1,...,M) denotes fea-
tures.
m?  is a feature weight. 
Our reordering model can be integrated into the 
system as one feature as shown in (10). 
1038
 Figure 2. An example for reordering 
4 Evaluation of Our Method 
4.1 Implementation 
We implemented our method in a phrase-based 
SMT system (Koehn et al, 2007). Based on the 
GIZA++ package (Och and Ney, 2003), we im-
plemented a MWA tool for collocation detection. 
Thus, given a sentence to be translated, we first 
identify the collocations in the sentence, and then 
estimate the reordering score according to the 
translation hypothesis. For a translation option to 
be expanded, the reordering score inside this 
source phrase is calculated according to their trans-
lation orders of the collocations in the correspond-
ing target phrase. The reordering score crossing the 
current translation option and the covered parts can 
be calculated according to the relative position of 
the collocated words. If the source phrase matched 
by the current translation option is behind the cov-
ered parts in the source sentence, then 
...)|staight(log ?op  is used, otherwise 
...)|inverted(log ?op . For example, in Figure 2, the 
current translation option is (
4332 eeff ? ). The 
collocations related to this translation option are 
),( 31 ff , ),( 32 ff , ),( 53 ff . The reordering scores 
can be estimated as follows: 
),|straight(log),( 3131 ffopffr ? 
),|inverted(log),( 3232 ffopffr ? 
),|inverted(log),( 5353 ffopffr ? 
In order to improve the performance of the de-
coder, we design a heuristic function to estimate 
the future score, as shown in Figure 3. For any un-
covered word and its collocates in the input sen-
tence, if the collocate is uncovered, then the higher 
reordering probability is used. If the collocate has 
been covered, then the reordering orientation can 
Input: Input sentence LfF 1?  
Initialization: Score = 0 
for each uncovered word 
if  do 
for each word
jf
(
icj ?  
or 
??)( , ji ffr
) do 
if 
jf
 is covered then 
if i > j then 
Score+=
),|straight(log)( , jiji ffopffr ?
 
else 
Score+=
),|inverted(log)( , jiji ffopffr ? 
else 
 Score +=
),|(log)(maxarg , jijio ffopffr
 
Output: Score 
Figure 3. Heuristic function for estimating future 
score 
be determined according to the relative positions of 
the words and the corresponding reordering proba-
bility is employed. 
4.2 Settings 
We use the FBIS corpus (LDC2003E14) to train a 
Chinese-to-English phrase-based translation model. 
And the SRI language modeling toolkit (Stolcke, 
2002) is used to train a 5-gram language model on 
the English sentences of FBIS corpus.  
We used the NIST evaluation set of 2002 as the 
development set to tune the feature weights of the 
SMT system and the interpolation parameters, 
based on the minimum error rate training method 
(Och, 2003), and the NIST evaluation sets of 2004 
and 2008 (MT04 and MT08) as the test sets. 
We use BLEU (Papineni et al, 2002) as evalua-
tion metrics. We also calculate the statistical signi-
ficance differences between our methods and the 
baseline method by using the paired bootstrap re-
sample method (Koehn, 2004). 
4.3 Translation results 
We compare the proposed method with various 
reordering methods in previous work. 
Monotone model: no reordering model is used. 
Distortion based reordering (DBR) model: a 
distortion based reordering method (Al-
Onaizan & Papineni, 2006). In this method, the 
distortion cost is defined in terms of words, ra-
ther than phrases. This method considers out-
bound, inbound, and pairwise distortions that  
f1    f2     f3     f4      f5 
e4 
e3 
e2 
e1 
1039
Reorder models MT04 MT08 
Monotone model 26.99 18.30 
DBR model 26.64 17.83 
MSDR model (Baseline) 28.77 18.42 
MSDR+ 
DBR model 28.91 18.58 
SCBR Model 1 29.21 19.28 
SCBR Model 2 29.44 19.36 
SCBR Model 3 29.50 19.44 
SCBR models (1+2) 29.65 19.57 
SCBR models (1+2+3) 29.75 19.61 
Table 1. Translation results on various reordering models 
 
T1: The two sides are also the basic stand of not relaxed. 
T2: The basic stance of the two sides have not relaxed. 
Reference: The basic stances of both sides did not move. 
Figure 4. Translation example.  (*/*) denotes (pstraight / pinverted)
 are directly estimated by simple counting over 
alignments in the word-aligned bilingual cor-
pus. This method is similar to our proposed 
method. But our method considers the transla-
tion order of the collocated words. 
msd-bidirectional-fe reordering (MSDR or 
Baseline) model: it is one of the reordering 
models in Moses. It considers three different 
orientation types (monotone, swap, and discon-
tinuous) on both source phrases and target 
phrases. And the translation orders of both the 
next phrase and the previous phrase in respect 
to the current phrase are modeled. 
Source collocation based reordering (SCBR) 
model: our proposed method. We investigate 
three reordering models based on the corres-
ponding MWA models and their combinations. 
In SCBR Model i (i=1~3), we use MWA Mod-
el i as described in section 2 to obtain the col-
located words and estimate the reordering 
probabilities according to section 3. 
The experiential results are shown in Table 1. 
The DBR model suffers from serious data sparse-
ness. For example, the reordering cases in the 
trained pairwise distortion model only covered 
32~38% of those in the test sets. So its perfor-
mance is worse than that of the monotone model. 
The MSDR model achieves higher BLEU scores 
than the monotone model and the DBR model. Our 
models further improve the translation quality, 
achieving better performance than the combination 
of MSDR model and DBR model. The results in 
Table 1 show that ?MSDR + SCBR Model 3? per-
forms the best among the SCBR models. This is 
because, as compared to MWA Model 1 and 2, 
MWA Model 3 takes more information into con-
sideration, including not only the co-occurrence 
information of lexical tokens and the position of 
words, but also the fertility of words in a sentence. 
And when the three SCBR models are combined, 
the performance of the SMT system is further im-
proved. As compared to other reordering models, 
our models achieve an absolute improvement of 
0.98~1.19 BLEU score on the test sets, which are 
statistically significant (p < 0.05).  
Figure 4 shows an example: T1 is generated by 
the baseline system and T2 is generated by the sys-
tem where the SCBR models (1+2+3)1 are used.  
                                                          
1 In the remainder of this paper, ?SCBR models? means the 
combination of the SCBR models (1+2+3) unless it is explicit-
ly explained.  
Input:  ??     ?   ??      ??  ?    ?  ??  ??   ? 
shuang-fang    DE    ji-ben       li-chang   ye      dou mei-you song-dong . 
(0.99/0.01) 
both-side       DE     basic          stance  also    both    not        loose     . 
(0.21/0.79) 
(0.95/0.05) 
1040
Reordering models MT04 MT08 
MSDR model 28.77 18.42 
MSDR+ 
DBR model 28.91 18.58 
CBR model 28.96 18.77 
WCBR model 29.15 19.10 
WCBR+SCBR 
models 
29.87 19.83 
Table 2. Translation results of co-occurrence 
based reordering models 
 CBR model 
SCBR 
Model3 
Consecutive words 77.9% 73.5% 
Interrupted words 74.1% 87.8% 
Total 74.3% 84.9% 
Table 3. Precisions of the reordering models on 
the development set 
The input sentence contains three collocations. The 
collocation (??, ??) is included in the same 
phrase and translated together as a whole. Thus its 
translation is correct in both translations. For the 
other two long-distance collocations (??, ??) 
and (??, ??), their translation orders are not 
correctly handled by the reordering model in the 
baseline system. For the collocation (??, ??), 
since the SCBR models indicate p(o=straight|??, 
??) < p(o=inverted|??, ??), the system fi-
nally generates the translation T2 by constraining 
their translation order with the proposed model. 
5 Collocations vs. Co-occurring Words 
We compared our method with the method that 
models the reordering orientations based on co-
occurring words in the source sentences, rather 
than the collocations.  
5.1 Co-occurrence based reordering model 
We use the similar algorithm described in section 3 
to train the co-occurrence based reordering (CBR) 
model, except that the probability of the reordering 
orientation is estimated on the co-occurring words 
and the relative distance. Given an input sentence 
and a translation candidate, the reordering score is 
estimated as shown in Eq. (12). 
? ??? ),( ,,, ),,|(log),( ji jijiaajiO ffopTFP ji
        (12) 
Here, 
ji??
 is the relative distance of two words 
in the source sentence.  
We also construct the weighted co-occurrence 
based reordering (WCBR) model. In this model, 
the probability of the reordering orientation is ad-
ditionally weighted by the pointwise mutual infor-
mation 2  score of the two words (Manning and 
Sch?tze, 1999), which is estimated as shown in Eq. 
(13). 
? ???
),(
,,,MI ),,|(log),(
),(
ji
jijiaajiji
O
ffopffs
TFP
ji
   (13) 
5.2 Translation results 
Table 2 shows the translation results. It can be seen 
that the performance of the SMT system is im-
proved by integrating the CBR model. The perfor-
mance of the CBR model is also better than that of 
the DBR model. It is because the former is trained 
based on all co-occurring aligned words, while the 
latter only considers the adjacent aligned words. 
When the WCBR model is used, the translation 
quality is further improved. However, its perfor-
mance is still inferior to that of the SCBR models, 
indicating that our method (SCBR models) of 
modeling the translation orders of source colloca-
tions is more effective. Furthermore, we combine 
the weighted co-occurrence based model and our 
method, which outperform all the other models. 
5.3 Result analysis 
Precision of prediction 
First of all, we investigate the performance of 
the reordering models by calculating precisions of 
the translation orders predicted by the reordering 
models. Based on the source sentences and refer-
ence translations of the development set, where the 
source words and target words are automatically 
aligned by the bilingual word alignment method, 
we construct the reference translation orders for 
two words. Against the references, we calculate 
three kinds of precisions as follows: 
|}1|||{|
|}&1{|
,
,,,,
CW ??
???? jio
ooj||iP
ji
aajiji ji
 (14) 
                                                          
2 For occurring words extraction, the window size is set to [-6, 
+6]. 
1041
|}1|||{|
|}&1{|
,
,,,,
IW ??
???? jio
ooj||iP
ji
aajiji ji
 (15) 
 |}{|
|}{|
,
,,,,
total
ji
aajiji
o
ooP ji??
 (16) 
Here, 
jio ,
 denotes the translation order of (
ji ff ,
) 
predicted by the reordering models. If 
)|straight( , ji ffop ?
>
),inverted( ji f|fop ?
, then 
straight, ?jio
, else if 
)|straight( , ji ffop ?
< 
),inverted( ji f|fop ?
, then
inverted, ?jio
. 
ji aajio ,,,
 
denotes the translation order derived from the word 
alignments. If 
ji aajiji oo ,,,, ?
, then the predicted 
translation order is correct, otherwise wrong. 
CWP  
and 
IWP  denote the precisions calculated on the 
consecutive words and the interrupted words in the 
source sentences, respectively. 
totalP  denotes the 
precision on both cases. Here, the CBR model and 
SCBR Model 3 are compared. The results are 
shown in Table 3.  
From the results in Table 3, it can be seen that 
the CBR model has a higher precision on the con-
secutive words than the SCBR model, but lower 
precisions on the interrupted words. It is mainly 
because the CBR model introduces more noise 
when the relative distance of words is set to a large 
number, while the MWA method can effectively 
detect the long-distance collocations in sentences 
(Liu et al, 2009). This explains why the combina-
tion of the two models can obtain the highest 
BLEU score as shown in Table 2. On the whole, 
the SCBR Model 3 achieves higher precision than 
the CBR model. 
Effect of the reordering model 
Then we evaluate the reordering results of the 
generated translations in the test sets. Using the 
above method, we construct the reference transla-
tion orders of collocations in the test sets. For a 
given word pair in a source sentence, if the transla-
tion order in the generated translation is the same 
as that in the reference translations, then it is cor-
rect, otherwise wrong. 
We compare the translations of the baseline me-
thod, the co-occurrence based method, and our me-
thod (SCBR models). The precisions calculated on 
both kinds of words are shown in Table 4. From 
Test sets 
Baseline 
(MSDR) 
MSDR+ 
WCBR 
MSDR+ 
SCBR 
MT04 78.9% 80.8% 82.5% 
MT08 80.7% 83.8% 85.0% 
Table 4. Precisions (total) of the reordering 
models on the test sets 
the results, it can be seen that our method achieves 
higher precisions than both the baseline and the 
method modeling the translation orders of the co-
occurring words. It indicates that the proposed me-
thod effectively constrains the reordering of source 
words during decoding and improves the transla-
tion quality. 
6 Related Work 
Reordering was first proposed in the IBM models 
(Brown et al, 1993), later was named IBM con-
straint by Berger et al (1996). This model treats 
the source word sequence as a coverage set that is 
processed sequentially and a source token is cov-
ered when it is translated into a new target token. 
In 1997, another model called ITG constraint was 
presented, in which the reordering order can be 
hierarchically modeled as straight or inverted for 
two nodes in a binary branching structure (Wu, 
1997). Although the ITG constraint allows more 
flexible reordering during decoding, Zens and Ney 
(2003) showed that the IBM constraint results in 
higher BLEU scores. Our method models the reor-
dering of collocated words in sentences instead of 
all words in IBM models or two neighboring 
blocks in ITG models. 
For phrase-based SMT models, Koehn et al 
(2003) linearly modeled the distance of phrase 
movements, which results in poor global reorder-
ing. More methods are proposed to explicitly mod-
el the movements of phrases (Tillmann, 2004; 
Koehn et al, 2005) or to directly predict the orien-
tations of phrases (Tillmann and Zhang, 2005; 
Zens and Ney, 2006), conditioned on current 
source phrase or target phrase. Hierarchical phrase-
based SMT methods employ SCFG bilingual trans-
lation model and allow flexible reordering (Chiang, 
2005). However, these methods ignored the corre-
lations among words in the source language or in 
the target language. In our method, we automati-
cally detect the collocated words in sentences and 
1042
their translation orders in the target languages, 
which are used to constrain the ordering models 
with the estimated reordering (straight or inverted) 
score. Moreover, our method allows flexible reor-
dering by considering both consecutive words and 
interrupted words. 
In order to further improve translation results, 
many researchers employed syntax-based reorder-
ing methods (Zhang et al, 2007; Marton and Res-
nik, 2008; Ge, 2010; Visweswariah et al, 2010). 
However these methods are subject to parsing er-
rors to a large extent. Our method directly obtains 
collocation information without resorting to any 
linguistic knowledge or tools, therefore is suitable 
for any language pairs. 
In addition, a few models employed the collo-
cation information to improve the performance of 
the ITG constraints (Xiong et al, 2006). Xiong et 
al. used the consecutive co-occurring words as col-
location information to constrain the reordering, 
which did not lead to higher translation quality in 
their experiments. In our method, we first detect 
both consecutive and interrupted collocated words 
in the source sentence, and then estimated the 
reordering score of these collocated words, which 
are used to softly constrain the reordering of source 
phrases. 
7 Conclusions 
We presented a novel model to improve SMT by 
means of modeling the translation orders of source 
collocations. The model was learned from a word-
aligned bilingual corpus where the potentially col-
located words in source sentences were automati-
cally detected by the MWA method. During 
decoding, the model is employed to softly con-
strain the translation orders of the source language 
collocations. Since we only model the reordering 
of collocated words, our methods can partially al-
leviate the data sparseness encountered by other 
methods directly modeling the reordering based on 
source phrases or target phrases. In addition, this 
kind of reordering information can be integrated 
into any SMT systems without resorting to any 
additional resources. 
The experimental results show that the pro-
posed method significantly improves the transla-
tion quality of a phrase based SMT system, 
achieving an absolute improvement of 1.1~1.4 
BLEU score over the baseline methods. 
References 
Yaser Al-Onaizan and Kishore Papineni. 2006. Distor-
tion Models for Statistical Machine Translation. In 
Proceedings of the 21st International Conference on 
Computational Linguistics and 44th Annual Meeting 
of the ACL, pp. 529-536. 
Adam L. Berger, Peter F. Brown, Stephen A. Della Pie-
tra, Vincent J. Della Pietra, Andrew S. Kehler, and 
Robert L. Mercer. 1996. Language Translation Appa-
ratus and Method of Using Context-Based Transla-
tion Models. United States Patent, Patent Number 
5510981, April.  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Del-
la Pietra, and Robert. L. Mercer. 1993. The Mathe-
matics of Statistical Machine Translation: Parameter 
estimation. Computational Linguistics, 19(2): 263-
311. 
David Chiang. 2005. A Hierarchical Phrase-based Mod-
el for Statistical Machine Translation. In Proceedings 
of the 43rd Annual Meeting of the Association for 
Computational Linguistics, pp. 263-270. 
Niyu Ge. 2010. A Direct Syntax-Driven Reordering 
Model for Phrase-Based Machine Translation. In 
Proceedings of Human Language Technologies: The 
2010 Annual Conference of the North American 
Chapter of the ACL, pp. 849-857. 
Philipp Koehn. 2004. Statistical Significance Tests for 
Machine Translation Evaluation. In Proceedings of 
the 2004 Conference on Empirical Methods in Natu-
ral Language Processing, pp. 388-395. 
Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of the Joint Conference on Human Lan-
guage Technologies and the Annual Meeting of the 
North American Chapter of the Association of Com-
putational Linguistics, pp. 127-133. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran Ri-
chard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. In 
Proceedings of the 45th Annual Meeting of the ACL, 
Poster and Demonstration Sessions, pp. 177-180. 
Philipp Koehn, Amittai Axelrod, Alexandra Birch 
Mayne, Chris Callison-Burch, Miles Osborne, and 
David Talbot. 2005. Edinburgh System Description 
for the 2005 IWSLT Speech Translation Evaluation. 
In Proceedings of International Workshop on Spoken 
Language Translation. 
1043
Dekang Lin. 1998. Extracting Collocations from Text 
Corpora. In Proceedings of the 1st Workshop on 
Computational Terminology, pp. 57-63. 
Zhanyi Liu, Haifeng Wang, Hua Wu, and Sheng Li. 
2009. Collocation Extraction Using Monolingual 
Word Alignment Method. In Proceedings of the 2009 
Conference on Empirical Methods in Natural Lan-
guage Processing, pp. 487-495. 
Christopher D. Manning and Hinrich Sch?tze. 1999. 
Foundations of Statistical Natural Language 
Processing, Cambridge, MA; London, U.K.: Brad-
ford Book & MIT Press. 
Yuval Marton and Philip Resnik. 2008. Soft Syntactic 
Constraints for Hierarchical Phrased-based Transla-
tion. In Proceedings of the 46st Annual Meeting of 
the Association for Computational Linguistics: Hu-
man Language Technologies, pp. 1003-1011. 
Kathleen R. McKeown and Dragomir R. Radev. 2000. 
Collocations. In Robert Dale, Hermann Moisl, and 
Harold Somers (Ed.), A Handbook of Natural Lan-
guage Processing, pp. 507-523. 
Franz Josef Och. 2003. Minimum Error Rate Training in 
Statistical Machine Translation. In Proceedings of 
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pp. 160-167. 
Franz Josef Och and Hermann Ney. 2003. A Systematic 
Comparison of Various Statistical Alignment Models. 
Computational Linguistics, 29(1) : 19-51. 
Kishore Papineni, Salim Roukos, Todd Ward, and Weij-
ing Zhu. 2002. BLEU: A Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pp. 311-318. 
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings for the In-
ternational Conference on Spoken Language 
Processing, pp. 901-904. 
Christoph Tillmann. 2004. A Unigram Orientation 
Model for Statistical Machine Translation. In Pro-
ceedings of the Joint Conference on Human Lan-
guage Technologies and the Annual Meeting of the 
North American Chapter of the Association of Com-
putational Linguistics, pp. 101-104. 
Christoph Tillmann and Tong Zhang. 2005. A Localized 
Prediction Model for Statistical Machine Translation. 
In Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics, pp. 557-564. 
Karthik Visweswariah, Jiri Navratil, Jeffrey Sorensen, 
Vijil Chenthamarakshan, and Nanda Kambhatla. 
2010. Syntax Based Reordering with Automatically 
Derived Rules for Improved Statistical Machine 
Translation. In Proceedings of the 23rd International 
Conference on Computational Linguistics, pp. 1119-
1127. 
Dekai Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Corpora. 
Computational Linguistics, 23(3):377-403. 
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum Entropy Based Phrase Reordering Model for 
Statistical Machine Translation. In Proceedings of 
the 21st International Conference on Computational 
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pp. 521-528. 
Richard Zens and Herman Ney. 2003. A Comparative 
Study on Reordering Constraints in Statistical Ma-
chine Translation. In Proceedings of the 41st Annual 
Meeting of the Association for Computational Lin-
guistics, pp. 192-202. 
Richard Zens and Herman Ney. 2006. Discriminative 
Reordering Models for Statistical Machine Transla-
tion. In Proceedings of the Workshop on Statistical 
Machine Translation, pp. 55-63. 
Dongdong Zhang, Mu Li, Chi-Ho Li, and Ming Zhou. 
2007. Phrase Reordering Model Integrating Syntactic 
Knowledge for SMT. In Proceedings of the 2007 
Joint Conference on Empirical Methods in Natural 
Language Processing and Computational Natural 
Language Learning, pp. 533-540. 
 
 
 
1044
