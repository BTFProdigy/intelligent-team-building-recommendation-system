Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 18?25,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
What?s in a Message?
Stergos D. Afantenos and Nicolas Hernandez
LINA, (UMR CNRS 6241)
Universit? de Nantes, France
stergos.afantenos@univ-nantes.fr
nicolas.hernandez@univ-nantes.fr
Abstract
In this paper we present the first step in a larger
series of experiments for the induction of pred-
icate/argument structures. The structures that
we are inducing are very similar to the con-
ceptual structures that are used in Frame Se-
mantics (such as FrameNet). Those structures
are called messages and they were previously
used in the context of a multi-document sum-
marization system of evolving events. The se-
ries of experiments that we are proposing are
essentially composed from two stages. In the
first stage we are trying to extract a represen-
tative vocabulary of words. This vocabulary
is later used in the second stage, during which
we apply to it various clustering approaches in
order to identify the clusters of predicates and
arguments?or frames and semantic roles, to
use the jargon of Frame Semantics. This paper
presents in detail and evaluates the first stage.
1 Introduction
Take a sentence, any sentence for that matter; step back
for a while and try to perceive that sentence in its most
abstract form. What you will notice is that once you
try to abstract away sentences, several regularities be-
tween them will start to emerge. To start with, there is
almost always an action that is performed.1 Then, there
is most of the times an agent that is performing this ac-
tion and a patient or a benefactor that is receiving this
action, and it could be the case that this action is per-
formed with the aid of a certain instrument. In other
words, within a sentence?and in respect to its action-
denoting word, or predicate in linguistic terms?there
will be several entities that are associated with the pred-
icate, playing each time a specific semantic role.
The notion of semantic roles can be traced back to
Fillmore?s (1976) theory of Frame Semantics. Accord-
ing to this theory then, a frame is a conceptual structure
which tries to describe a stereotypical situation, event
or object along with its participants and props. Each
frame takes a name (e.g. COMMERCIAL TRANSAC-
TION) and contains a list of Lexical Units (LUs) which
1In linguistic terms, an action-denoting word is also
known as a predicate.
actually evoke this frame. An LU is nothing else than
a specific word or a specific meaning of a word in the
case of polysemous words. To continue the previous
example, some LUs that evoke the frame of COMMER-
CIAL TRANSACTION could be the verbs buy, sell,
etc. Finally, the frames contain several frame elements
or semantic roles which actually denote the abstract
conceptual entities that are involved with the particu-
lar frame.
Research in semantic roles can be distinguished into
two major branches. The first branch of research con-
sists in defining an ontology of semantic roles, the
frames in which the semantic roles are found as well as
defining the LUs that evoke those frames. The second
branch of research, on the other hand, stipulates the
existence of a set of frames, including semantic roles
and LUs; its goal then, is the creation of an algorithm
that given such a set of frames containing the semantic
roles, will be able to label the appropriate portions of
a sentence with the corresponding semantic roles. This
second branch of research is known as semantic role
labeling.
Most of the research concerning the definition of the
semantic roles has been carried out by linguists who are
manually examining a certain amount of frames before
finally defining the semantic roles and the frames that
contain those semantic roles. Two such projects that
are widely known are the FrameNet (Baker et al, 1998;
Ruppenhofer et al, 2006) and PropBank/NomBank 2
(Palmer et al, 2005; Meyers et al, 2004). Due to the
fact that the aforementioned projects are accompanied
by a large amount of annotated data, computer scien-
tists have started creating algorithms, mostly based on
statistics (Gildea and Jurafsky, 2002; Xue, 2008) in or-
der to automatically label the semantic roles in a sen-
tence. Those algorithms take as input the frame that
2We would like to note here that although the two ap-
proaches (FrameNet and PropBank/NomBank) share many
common elements, they have several differences as well.
Two major differences, for example, are the fact that the
Linguistic Units (FrameNet) are referred to as Relations
(PropBank/NomBank), and that for the definition of the se-
mantic roles in the case of PropBank/NomBank there is no
reference ontology. A detailed analysis of the differences be-
tween FrameNet and PropBank/NomBank would be out of
the scope of this paper.
18
contains the roles as well as the predicate3 of the sen-
tence.
Despite the fact that during the last years we have
seen an increasing interest concerning semantic role
labeling,4 we have not seen many advancements con-
cerning the issue of automatically inducing semantic
roles from raw textual corpora. Such a process of in-
duction would involve, firstly the identification of the
words that would serve as predicates and secondly the
creation of the appropriate clusters of word sequences,
within the limits of a sentence, that behave similarly
in relation to the given predicates. Although those
clusters of word sequences could not actually be said
to serve in themselves as the semantic roles,5 they
can nevertheless be viewed as containing characteris-
tic word sequences of specific semantic roles. The last
point has the implication that if one is looking for a
human intuitive naming of the semantic role that is im-
plied by the cluster then one should look elsewhere.
This is actually reminiscent of the approach that is car-
ried out by PropBank/NomBank in which each seman-
tic role is labeled as Arg1 through Arg5 with the se-
mantics given aside in a human readable natural lan-
guage sentence.
Our goal in this paper is to contribute to the research
problem of frame induction, that is of the creation of
frames, including their associated semantic roles, given
as input only a set of textual documents. More specifi-
cally we propose a general methodology to accomplish
this task, and we test its first stage which includes the
use of corpus statistics for the creation of a subset of
words, from the initial universe of initial words that are
present in the corpus. This subset will later be used
for the identification of the predicates as well as the
semantic roles. Knowing that the problem of frame in-
duction is very difficult in the general case, we limit
ourselves to a specific genre and domain trying to ex-
ploit the characteristics that exist in that domain. The
domain that we have chosen is that of the terroristic in-
cidents which involve hostages. Nevertheless, the same
methodology could be applied to other domains.
The rest of the paper is structured as follows. In sec-
tion 2 we describe the data on which we have applied
our methodology, which itself is described in detail in
section 3. Section 4 describes the actual experiments
that we have performed and the results obtained, while
a discussion of those results follows in section 5. Fi-
nally, section 6 contains a description of the related
work while we present our future work and conclusions
in section 7.
3In the case of FrameNet the predicate corresponds to a
?Linguistic Unit?, while in the case of PropBank/NomBank
it corresponds to what is named ?Relation?.
4Cf, for example, the August 2008 issue of the journal
Computational Linguistics (34:2).
5At least as the notion of semantic roles is proposed and
used by FrameNet.
2 The Annotated Data
The annotated data that we have used in order to
perform our experiments come from a previous work
on automatic multi-document summarization of events
that evolve through time (Afantenos et al, 2008; Afan-
tenos et al, 2005; Afantenos et al, 2004). The method-
ology that is followed is based on the identification of
similarities and differences?between documents that
describe the evolution of an event?synchronically as
well as diachronically. In order to do so, the notion of
Synchronic and Diachronic cross document Relations
(SDRs),6 was introduced. SDRs connect not the doc-
uments themselves but some semantic structures that
were called messages. The connection of the messages
with the SDRs resulted in the creation of a semantic
graph that was then fed to a Natural Language Gener-
ation (NLG) system in order to produce the final sum-
mary. Although the notion of messages was originally
inspired by the notion of messages as used in the area of
NLG, for example during the stage of Content Determi-
nation as described in (Reiter and Dale, 1997), and in
general they do follow the spirit of the initial definition
by Reiter & Dale, in the following section we would
like to make it clear what the notion of messages rep-
resents for us. In the rest of the paper, when we refer to
the notion of messages, it will be in the context of the
discussion that follows.
2.1 Messages
The intuition behind messages, is the fact that during
the evolution of an event we have several activities that
take place and each activity is further decomposed into
a series of actions. Messages were created in order to
capture this abstract notion of actions. Of course, ac-
tions usually implicate several entities. In this case, en-
tities were represented with the aid of a domain ontol-
ogy. Thus, in more formal terms a message m can be
defined as follows:
m = message_type (arg1, . . . , argn)
where argi ? Topic Ontology, i ? {1, . . . , n}
In order to give a simple example, let us take for in-
stance the case of the hijacking of an airplane by ter-
rorists. In such a case, we are interested in knowing
if the airplane has arrived to its destination, or even to
another place. This action can be captured by a mes-
sage of type arrive whose arguments can be the en-
tity that arrives (the airplane in our case, or a vehicle,
in general) and the location that it arrives. The specifi-
cations of such a message can be expressed as follows:
6Although a full analysis of the notion of Synchronic and
Diachronic Relations is out of the scope of this paper, we
would like simply to mention that the premises on which
those relations are defined are similar to the ones which gov-
ern the notion of Rhetorical Structure Relations in Rhetorical
Structure Theory (RST) (Taboada and Mann, 2006), with the
difference that in the case of SDRs the relations hold across
documents, while in the case of RSTs the relation hold inside
a document.
19
arrive (what, place)
what : Vehicle
place : Location
The concepts Vehicle and Location belong to the
ontology of the topic; the concept Airplane is a sub-
concept of the Vehicle. A sentence that might in-
stantiate this message is the following:
The Boeing 747 arrived at the airport of
Stanstend.
The above sentence instantiates the following message:
arrive ("Boeing 747", "airport of
Stanstend")
The domain which was chosen was that of terroris-
tic incidents that involve hostages. An empirical study,
by three people, of 163 journalistic articles?written in
Greek?that fell in the above category, resulted in the
definition of 48 different message types that represent
the most important information in the domain. At this
point we would like to stress that what we mean by
?most important information? is the information that
one would normally expect to see in a typical summary
of such kinds of events. Some of the messages that
have been created are shown in Table 1; figure 1 pro-
vides full specifications for two messages.
free explode
kill kidnap
enter arrest
negotiate encircle
escape_from block_the_way
give_deadline
Table 1: Some of the message types defined.
negotiate (who, with_whom, about)
who : Person
with_whom : Person
about : Activity
free (who, whom, from)
who : Person
whom : Person
from : Place ? Vehicle
Figure 1: An example of message specifications
Although in an abstract way the notion of messages,
as presented in this paper approaches the notion of
frame semantics?after all, both messages and frame
semantics are concerned with ?who did what, to whom,
when, where and how??it is our hope that our ap-
proach could ultimately be used for the problem of
frame induction. Nevertheless, the two structures have
several points in which they differ. In the following
section we would like to clarify those points in which
the two differ.
2.2 How Messages differ from Frame Semantics
As it might have been evident until now, the notions
of messages and frame semantics are quite similar, at
least from an abstract point of view. In practical terms
though, the two notions exhibit several differences.
To start with, the notion of messages has been used
until now only in the context of automatic text summa-
rization of multiple documents. Thus, the aim of mes-
sages is to capture the essential information that one
would expect to see in a typical summary of this do-
main.7 In contrast, semantic roles and the frames in
which they exist do not have this limitation.
Another differentiating characteristic of frame se-
mantics and messages is the fact that semantic roles al-
ways get instantiated within the boundaries of the sen-
tence in which the predicate exists. By contrast, in mes-
sages although in the vast majority of the cases there is
a one-to-one mapping from sentences to messages, in
some of the cases the arguments of a message, which
correspond to the semantic roles, are found in neigh-
boring sentences. The overwhelming majority of those
cases (which in any case were but a few) concern re-
ferring expressions. Due to the nature of the machine
learning experiments that were performed, the actual
entities were annotated as arguments of the messages,
instead of the referring expressions that might exist in
the sentence in which the message?s predicate resided.
A final difference that exists between messages and
frame semantics is the fact that messages were meant
to exist within a certain domain, while the definition of
semantic roles is usually independent of a domain.8
3 The Approach Followed
A schematic representation of our approach is shown
in Figure 2. As it can be seen from this figure, our ap-
proach comprises two stages. The first stage concerns
the creation of a lexicon which will contain as most as
possible?and, of course, as accurately as possible?
candidates that are characteristic either of the predi-
cates (message types) or of the semantic roles (argu-
ments of the messages). This stage can be thought of
as a filtering stage. The second stage involves the use
of unsupervised clustering techniques in order to create
the final clusters of words that are characteristic either
of the predicates or of the semantic roles that are asso-
7In this sense then, the notion of messages is reminiscent
of Schank & Abelson?s (1977) notion of scripts, with the dif-
ference that messages are not meant to exist inside a struc-
ture similar to Schank & Abelson?s ?scenario?. We would
like also to note that the notion of messages shares certain
similarities with the notion of templates of Information Ex-
traction, as those structures are used in conferences such as
MUC. Incidentally, it is not by chance that the ?M? in MUC
stands for Message (Understanding Conference).
8We would like to note at this point that this does not ex-
clude of course the fact that the notion of messages could be
used in a more general, domain independent way. Neverthe-
less, the notion of messages has for the moment been applied
in two specific domains (Afantenos et al, 2008).
20
ciated with those predicates. The focus of this paper is
on the first stage.
As we have said, our aim in this paper is the use
of statistical measures in order to extract from a given
corpus a set of words that are most characteristic of
the messages that exist in this corpus. In the context
of this paper, a word will be considered as being char-
acteristic of a message if this word is employed in a
sentence that has been annotated with that message. If
a particular word does not appear in any message an-
notated sentence, then this word will not be considered
as being characteristic of this message. In more formal
terms then, we can define our task as follows. If by U
we designate the set of all the words that exist in our
corpus, then we are looking for a setM such that:
M? U ?
w ?M? m appears at least once
in a message instance (1)
In order to extract the set M we have employed the
following four statistical measures:
Collection Frequency: The set that results from the
union of the n% most frequent words that appear
in the corpus.
Document Frequency: The set that results from the
union of the n% most frequent words of each doc-
ument in the corpus.
tf.idf: For each word in the corpus we calculate its
tf.idf . Then we create a set which is the union of
words with the highest n% tf.idf score in each
document.
Inter-document Frequency: A word has inter-docu-
ment frequency n if it appears in at least n docu-
ments in the corpus. The set with inter-document
frequency n is the set that results from the union
of all the words that have inter-document fre-
quency n.
As we have previously said in this paper, our goal is
the exploitation of the characteristic vocabulary that
exists in a specific genre and domain in order to ulti-
mately achieve our goal of message induction, some-
thing which justifies the use of the above statistical
measures. The first three measures are known to be
used in context of Information retrieval to capture top-
ical informations. The latter measure has been pro-
posed by (Hernandez and Grau, 2003) in order to ex-
tract rhetorical indicator phrases from a genre depen-
dant corpus.
In order to calculate the aforementioned statistics,
and create the appropriate set of words, we ignored all
the stop-words. In addition we worked only with the
verbs and nouns. The intuition behind this decision lies
in the fact that the created set will later be used for the
identification of the predicates and the induction of the
semantic roles. As Gildea & Jurafsky (2002)?among
others?have mentioned, predicates, or action denot-
ing words, are mostly represented by verbs or nouns.9
Thus, in this series of experiments we are mostly focus-
ing in the extraction of a set of words that approaches
the set that is obtained by the union of all the verbs and
nouns found in the annotated sentences.
4 Experiments and Results
The corpus that we have consists of 163 journalistic
articles which describe the evolution of five different
terroristic incidents that involved hostages. The cor-
pus was initially used in the context of training a multi-
document summarization system. Out of the 3,027 sen-
tences that the corpus contains, about one third (1,017
sentences) were annotated with the 48 message types
that were mentioned in section 2.1.
Number of Documents: 163
Number of Token: 71,888
Number of Sentences: 3,027
Annotated Sentences (messages): 1,017
Distinct Verbs and Nouns in the Corpus: 7,185
Distinct Verbs and Nouns in the Messages: 2,426
Table 2: Corpus Statistics.
The corpus contained 7,185 distinct verbs and nouns,
which actually constitute the U of the formula (1)
above. Out of those 7,185 distinct verbs and nouns
2,426 appear in the sentences that have been annotated
with the messages. Our goal was to create this set that
approached as much as possible to the set of 2,426 dis-
tinct verbs and nouns that are found in the messages.
Using the four different statistical measures pre-
sented in the previous section, we tried to reconstruct
that set. In order to understand how the statistical mea-
sures behaved, we varied for each one of them the value
of the threshold used. For each statistical measure used,
the threshold represents something different. For the
Collection Frequency measure the threshold represents
the n% most frequent words that appear in the cor-
pus. For the Document Frequency it represents the n%
most frequent words that appear in each document sep-
arately. For tf.idf it represents the words with the high-
est n% tf.idf score in each document. Finally for the
Inter-document Frequency the threshold represents the
verbs and nouns that appear in at least n documents.
Since for the first three measures the threshold repre-
sents a percentage, we varied it from 1 to 100 in order
to study how this measure behaves. For the case of
the Inter-document Frequency, we varied the threshold
from 1 to 73 which represents the maximum number of
documents in which a word appeared.
In order to measure the performance of the statistical
measures employed, we used four different evaluation
measures, often employed in the information retrieval
9In some rare cases predicates can be represented by ad-
jectives as well.
21
Lexicon Extraction(initial predicate filtering) Unsupervised Clustering
Clusters of predicates and semantic roles
Figure 2: Two different stages in the process of predicate clustering
field. Those measures are the Precision, Recall, F-
measure and Fallout. Precision represents the percent-
age of the correctly obtained verbs and nouns over the
total number of obtained verbs and nouns. Recall rep-
resents the percentage of the obtained verbs and nouns
over the target set of verbs and nouns. The F-measure
is the harmonic mean of Precision and Recall. Finally,
fallout represents the number of verbs and nouns that
were wrongly classified by the statistical measures as
belonging to a message, over the total number of verbs
and nouns that do not belong to a message. In an ideal
situation one expects a very high precision and recall
(and by consequence F-measure) and a very low Fall-
out.
The obtained graphs that combine the evaluation re-
sults for the four statistical measures presented in sec-
tion 3 are shown in Figures 3 through 6. A first remark
that we can make in respect to those graphs is that con-
cerning the collection frequency, document frequency
and tf.idf measures, for small threshold numbers we
have more or less high precision values while the recall
and fallout values are low. This implies that for smaller
threshold values the obtained sets are rather small, in
relation toM (and by consequence to U as well). As
the threshold increases we have the opposite situation,
that is the precision falls while the recall and the fall-
out increases, implying that we get much bigger sets of
verbs and nouns.
In terms of absolute numbers now, the best F-
measure is given by the Collection Frequency measure
with a threshold value of 46%. In other words, the
best results?in terms of F-measure?is given by the
union of the 46% most frequent verbs and nouns that
appear in the corpus. For this threshold the Precision
is 54.14%, the Recall is 72.18% and the F-measure is
61,87%. This high F-measure though comes at a cer-
tain cost since the Fallout is at 31.16%. This implies
that although we get a rather satisfying score in terms
of precision and recall, the number of false positives
that we get is rather high in relation to our universe.
As we have earlier said, a motivating factor of this pa-
per is the automatic induction of the structures that we
have called messages; the extracted lexicon of verbs
and messages will later be used by an unsupervised
clustering algorithm in order to create the classes of
words which will correspond to the message types. For
this reason, although we prefer to have an F-measure as
high as possible, we also want to have a fallout measure
as low as possible, so that the number of false positives
will not perturb the clustering algorithm.
If, on the other hand, we examine the relation be-
tween the F-measure and Fallout, we notice that for the
Inter-document Frequency with a threshold value of 4
we obtain a Precision of 71.60%, a recall of 43.86%
and an F-measure of 54.40%. Most importantly though
we get a fallout measure of 8.86% which implies that
the percentage of wrongly classified verbs and nouns
compose a small percentage of the total universe of
verbs and nouns. This combination of high F-measure
and very low Fallout is very important for later stages
during the process of message induction.
5 Discussion
As we have claimed in the introduction of this paper,
although we have applied our series of experiments in
a single domain, that of terroristic incidents which in-
volve hostages, we believe that the proposed procedure
can be viewed as a ?general? one. In the section we
would like to clarify what exactly we mean by this
statement.
In order to proceed, we would like to suggest that
one can view two different kinds of generalization for
the proposed procedure:
1. The proposed procedure is a general one in the
sense that it can be applied in a large corpus of het-
erogeneous documents incorporating various do-
mains and genres, in order to yield ?general?, i.e.
domain-independent, frames that can later be used
for any kind of domain.
2. The proposed procedure is a general one in the
sense that it can be used in any kind of domain
without any modifications. In contrast with the
first point, in this case the documents to which
the proposed procedure will be applied ought to
be homogeneous and rather representative of the
domain. The induced frames will not be general
ones, but instead will be domain dependent ones.
22
L e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cc
trtta
otrtta
ntrtta
 trtta
Etrtta
Lttrtta
Lotrtta
(lpdfgf)U
spduvvCmpug?lp
Cuvv)??
Figure 3: Collection Frequency statistics
L e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cc
trtta
otrtta
ntrtta
 trtta
Etrtta
Lttrtta
Lotrtta
(lpdfgf)U
spduvv
Cmpug?lp
Cuvv)??
Figure 4: Document Frequency statistics
Given the above two definitions of generality, we
could say that the procedure proposed in this paper
falls rather in the second category than in the first
one. Ignoring for the moment the second stage of the
procedure?clustering of word sequences characteris-
tic of specific semantic roles?and focusing on the ac-
tual work described in this paper, that is the use of
statistical methods for the identification of candidate
predicates, it becomes clear that the use of an hetero-
geneous, non-balanced corpus is prone to skewing the
results. By consequence, we believe that the proposed
procedure is general in the sense that we can use it for
any kind of domain which is described by an homoge-
neous corpus of documents.
6 Related Work
Teufel and Moens (2002) and Saggion and Lapalme
(2002) have shown that templates based on domain
concepts and relations descriptions can be used for the
task of automatic text summarization. The drawback
of their work is that they rely on manual acquisition
of lexical resources and semantic classes? definition.
Consequently, they do not avoid the time-consuming
task of elaborating linguistic resources. It is actually
for this kind of reason?that is, the laborious manual
work?that automatic induction of various structures is
a recurrent theme in different research areas of Natural
Language Processing.
An example of an inductive Information Extraction
algorithm is the one presented by Fabio Ciravegna
(2001). The algorithm is called (LP)2. The goal of the
algorithm is to induce several symbolic rules given as
input previous SGML tagged information by the user.
The induced rules will later be applied in new texts in
order to tag it with the appropriate SGML tags. The
induced rules by (LP)2 fall into two distinct categories.
In the first we have a bottom up procedure which gen-
eralizes the tag instances found in the training corpus
which uses shallow NLP knowledge. A second set of
rules is also created which have a corrective character;
that is, the application of this second set of rules aims
at correcting several of the mistakes that are performed
by the first set of rules.
On the other hand several researchers have pioneered
the automatic acquisition of lexical and semantic re-
sources (such as verb classes). Some approaches are
based on Harris?s (1951) distribution hypothesis: syn-
tactic structures with high occurrences can be used for
identifying word clusters with common contexts (Lin
and Pantel, 2001). Some others perform analysis from
semantic networks (Green et al, 2004). Poibeau and
Dutoit (2002) showed that both can be used in a com-
plementary way.
Currently, our approach follows the first trend.
Based on Hernandez and Grau (2003; 2004)?s proposal,
we aim at explicitly using corpus characteristics such as
its genre and domain features to reduce the quantity of
considered data. In this paper we have explored various
statistical measures which could be used as a filter for
improving results obtained by the previous mentioned
works.
23
L e x i c LLLeLxLi LcoLoeoxoi oceLeeexei ecnLnenxni ncxLxexxxi xc  L  e  x  i  c iL ie ix ii ic ELEeExEi EccLcecxci cc
trtta
otrtta
ntrtta
 trtta
Etrtta
Lttrtta
Lotrtta
(lpdfgf)U
spduvvCm?pug?lp
Cuvv)??
Figure 5: Tf.idf statistics
L ex i c on  ELtLLLeLxLiLcLoLnL LEeteLeeexeieceoene eExtxLxexxxixcxoxnx xEit iLieixii icioini iEctcLcecxcicccocnc cEotoLoeoxoiocooono oEntnLnenx
trtta
etrtta
itrtta
otrtta
 trtta
Lttrtta
Letrtta
(lpdfgf)UspduvvCmpug?lpCuvv)??
Figure 6: Inter-document frequency statistics
7 Conclusions and Future Work
In this paper we have presented a statistical approach
for the extraction of a lexicon which contains the verbs
and nouns that can be considered as candidates for use
as predicates for the induction of predicate/argument
structures that we call messages. Actually, the research
presented here can be considered as the first step in a
two-stages approach. The next step involves the use
of clustering algorithms on the extracted lexicon which
will provide the final clusters that will contain the pred-
icates and arguments for the messages. This process
is itself part of a larger process for the induction of
predicate/argument structures. Apart from messages,
such structures could as well be the structures that are
associated with frame semantics, that is the frames
and their associated semantic roles. Despite the great
resemblances that messages and frames have, one of
their great differences is the fact that messages were
firstly introduced in the context of automatic multi-
document summarization. By consequence they are
meant to capture the most important information in a
domain. Frames and semantic roles on the other hand,
do not have this restriction and thus are more general.
Nonetheless, it is our hope that the current research
could ultimately be useful for the induction of frame se-
mantics. In fact it is in our plans for the immediate fu-
ture work to apply the same procedure in FrameNet an-
notated data10 in order to extract a vocabulary of verbs
10See http://framenet.icsi.berkeley.edu/
index.php?option=com_wrapper&Itemid=84
and nouns which will be characteristic of the different
Linguistic Units (LUs) for the frames of FrameNet.
The proposed statistical measures are meant to be a
first step towards a fully automated process of mes-
sage induction. The immediate next step in the pro-
cess involves the application of various unsupervised
clustering techniques on the obtained lexicon in order
to create the 48 different classes each one of which
will represent a distinct vocabulary for the 48 differ-
ent message types. We are currently experimenting
with several algorithms such K-means, Expectation-
Minimization (EM), Cobweb and Farthest First. In ad-
dition to those clustering algorithms, we are also exam-
ining the use of various lexical association measures
such as Mutual Information, Dice coefficient, ?2, etc.
Although this approach will provide us with clusters of
predicates and candidate arguments, still the problem
of linking the predicates with their arguments remains.
Undoubtedly, the use of more linguistically oriented
techniques, such as syntactic analysis, is inevitable. We
are currently experimenting with the use of a shallow
parser (chunker) in order to identify the chunks that
behave similarly in respect to a given cluster of pred-
icates.
Concerning the evaluation of our approach, the high-
est F-measure score (61,87%) was given by the Col-
lection Frequency statistical measure with a threshold
value of 46%. This high F-measure though came at the
cost of a high Fallout score (31.16%). Since the ex-
tracted lexicon will later be used as an input to a clus-
tering algorithm, we would like to minimize as much as
24
possible the false positives. By consequence we have
opted in using the Inter-document Frequency measure
which presents an F-measure of 54.40% and a much
more limited Fallout of 8.86%.
Acknowledgments
The authors would like to thank Konstantina Liontou and
Maria Salapata for their help on the annotation of the mes-
sages, as well as the anonymous reviewers for their insightful
and constructive comments.
References
Stergos D. Afantenos, Irene Doura, Eleni Kapel-
lou, and Vangelis Karkaletsis. 2004. Exploit-
ing cross-document relations for multi-document
evolving summarization. In G. A. Vouros and
T. Panayiotopoulos, editors, Methods and Applica-
tions of Artificial Intelligence: Third Hellenic Con-
ference on AI, SETN 2004, volume 3025 of Lecture
Notes in Computer Science, pages 410?419, Samos,
Greece, May. Springer-Verlag Heidelberg.
Stergos D. Afantenos, Konstantina Liontou, Maria
Salapata, and Vangelis Karkaletsis. 2005. An in-
troduction to the summarization of evolving events:
Linear and non-linear evolution. In Bernadette
Sharp, editor, Proceedings of the 2nd International
Workshop on Natural Language Understanding and
Cognitive Science, NLUCS 2005, pages 91?99, Ma-
iami, Florida, USA, May. INSTICC Press.
Stergos D. Afantenos, Vangelis Karkaletsis, Panagio-
tis Stamatopoulos, and Constantin Halatsis. 2008.
Using synchronic and diachronic relations for sum-
marizing multiple documents describing evolving
events. Journal of Intelligent Information Systems,
30(3):183?226, June.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of the COLING-ACL, Montreal, Canada.
Fabio Ciravegna. 2001. Adaptive information extrac-
tion from text by rule induction and generalisation.
In 17th International Joint Conference on Artificial
Intelligence (IJCAI 2001), pages 1251?1256, Seat-
tle, USA, August.
C. J. Fillmore. 1976. Frame semantics and the na-
ture of language. Annals of the New York Academy
of Sciences: Conference on the Origin and Develop-
ment of Language and Speech, 280:20?32.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245?288.
Rebecca Green, Bonnie J. Dorr, and Philip Resnik.
2004. Inducing frame semantic verb classes from
wordnet and ldoce. In Proceedings of the 42nd
Meeting of the Association for Computational Lin-
guistics (ACL?04), Main Volume, pages 375?382,
Barcelona, Spain, July.
Zelig Harris. 1951. Structural Linguistics. University
of Chicago Press.
Nicolas Hernandez and Brigitte Grau. 2003. Auto-
matic extraction of meta-descriptors for text descrip-
tion. In International Conference on Recent Ad-
vances In Natural Language Processing (RANLP),
Borovets, Bulgaria, 10-12 September.
Nicolas Hernandez. 2004. D?tection et Description
Automatique de Structures de Texte. Ph.D. thesis,
Universit? de Paris-Sud XI.
Dekang Lin and Patrick Pantel. 2001. Induction of
semantic classes from natural language text. In Pro-
ceedings of ACM Conference on Knowledge Discov-
ery and Data Mining (KDD-01), pages 317?322, San
Francisco, CA.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. The nombank project:
An interim report. In Adam Meyers, editor, HLT-
NAACL 2004 Workshop: Frontiers in Corpus Anno-
tation, pages 24?31, Boston, Massachusetts, USA,
May. Association for Computational Linguistics.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106.
Thierry Poibeau and Dominique Dutoit. 2002. In-
ferring knowledge from a large semantic network.
In Proceeding of the Semantic networks workshop,
during the Computational Linguistics Conference
(COLING 2002), Taipei, Taiwan.
Ehud Reiter and Robert Dale. 1997. Building applied
natural language generation systems. Natural Lan-
guage Engineering, 3(1):57?87.
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, Christopher R. Johnson, and Jan Schef-
fczyk. 2006. Framenet ii: Extended theory and
practice. Unpublished manuscript; accessible at
http://framenet.icsi.berkeley.edu.
Horacio Saggion and Guy Lapalme. 2002. Generat-
ing indicative-informative summaries with sumum.
Computational Linguistics, 28(4):497?526.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
Plans, Goals and Understanding: an Inquiry into
Human Knowledge Structures. L. Erlbaum, Hills-
dale, NJ.
Maite Taboada and William C. Mann. 2006. Rhetor-
ical structure theory: Looking back and moving
ahead. Discourse Studies, 8(3):423?459, June.
Simone Teufel and Marc Moens. 2002. Summariz-
ing scientific articles: Experiments with relevance
and rhetorical status. Computational Linguistics,
28:409?445.
Nianwen Xue. 2008. Labeling chinese predicates
with semantic roles. Computational Linguistics,
34(2):225?255, June.
25
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1?9,
Beijing, August 2010
Testing SDRT?s Right Frontier
Stergos D. Afantenos and Nicholas Asher
Institut de recherche en informatique de Toulouse (IRIT),
CNRS, Universit? Paul Sabatier
{stergos.afantenos, nicholas.asher}@irit.fr
Abstract
The Right Frontier Constraint (RFC), as a
constraint on the attachment of new con-
stituents to an existing discourse struc-
ture, has important implications for the in-
terpretation of anaphoric elements in dis-
course and for Machine Learning (ML) ap-
proaches to learning discourse structures.
In this paper we provide strong empirical
support for SDRT?s version of RFC. The
analysis of about 100 doubly annotated
documents by five different naive annota-
tors shows that SDRT?s RFC is respected
about 95% of the time. The qualitative
analysis of presumed violations that we
have performed shows that they are either
click-errors or structural misconceptions.
1 Introduction
A cognitively plausible way to view the construc-
tion of a discourse structure for a text is an incre-
mental one. Interpreters integrate discourse con-
stituent n into the antecedently constructed dis-
course structure D for constituents 1 to n ? 1 by
linking n to some constituent in D with a dis-
course relation. SDRT?s Right Frontier Constraint
(RFC) (Asher, 1993; Asher and Lascarides, 2003)
says that a new constituent n cannot attach to an
arbitrary node in D. Instead it must attach to ei-
ther the last node entered into the graph or one of
the nodes that dominate this last node. Assuming
that the last node is usually found on the right of
the structure, this means that the nodes available
for attachment occur on the right frontier (RF) of
the discourse graph or SDRS.
Researchers working in different theoretical
paradigms have adopted some form of this con-
straint. Polanyi (1985; 1988) originally pro-
posed the RFC as a constraint on antecedents to
anaphoric pronouns. SDRT generalizes this to a
condition on all anaphoric elements. As the at-
tachment of new information to a contextually
given discourse graph in SDRT involves the reso-
lution of an anaphoric dependency, RFC furnishes
a constraint on the attachment problem. (Webber,
1988; Mann and Thompson, 1987; 1988) have
also adopted versions of this constraint. But there
are important differences. While SDRT and RST
both take RFC as a constraint on all discourse at-
tachments (in DLTAG, in contrast, anaphoric dis-
course particles are not limited to finding an an-
tecedent on the RF), SDRT?s notion of RF is sub-
stantially different from that of RST?s or Polanyi?s,
because SDRT?s notion of a RF depends on a 2-
dimensional discourse graph built from coordinat-
ing and subordinating discourse relations. Defin-
ing RFC with respect to SDRT?s 2-dimensional
graphs allows the RF to contain discourse con-
stituents that do not include the last constituent
entered into the graph (in contrast to RST). SDRT
also allows for multiple attachments of a con-
stituent to the RFC.
SDRT?s RFC has important implications for the
interpretation of various types of anaphoric ele-
ments: tense (Lascarides and Asher, 1993), ellip-
sis (Hardt et al, 2001; Hardt and Romero, 2004;
Asher, 2007), as well as pronouns referring to in-
dividuals and abstract entities (Asher, 1993; Asher
and Lascarides, 2003). The RFC, we believe, will
also benefit ML approaches to learning discourse
structures, as a constraint limiting the search space
for possible discourse attachments. Despite its
importance, SDRT?s RFC has never been empiri-
cally validated, however. We present evidence in
this paper providing strong empirical support for
SDRT?s version of the constraint. We have cho-
sen to study SDRT?s notion of a RF, because of
SDRT?s greater expressive power over RST (Dan-
los, 2008), the greater generality of SDRT?s defi-
1
nition of RFC, and because of SDRT?s greater the-
oretical reliance on the constraint for making se-
mantic predictions. SDRT also makes theoretically
clear why the RFC should apply to discourse re-
lation attachment, since it treats discourse struc-
ture construction as a dynamic process in which
all discourse relations are essentially anaphors.
The analysis of about 100 doubly annotated docu-
ments by five different naive annotators shows that
this constraint, as defined in SDRT, is respected
about 95% of the time. The qualitative analysis of
the presumed violations that we have performed
shows that they are either click-errors or structural
misconceptions by the annotators.
Below, we give a formal definition of SDRT?s
RFC; section 3 explains our annotation procedure.
Details of the statistical analysis we have per-
formed are given in section 4, and a qualitative
analysis is provided in section 5. Finally, sec-
tion 6 presents the implications of the empirical
study for ML techniques for the extraction of dis-
course structures while sections 7 and 8 present
the related work and conclusions.
2 The Right Frontier Constraint in SDRT
In SDRT, a discourse structure or SDRS (Seg-
mented Discourse Representation Structure) is a
tuple < A,F , LAST >, where A is the set of
labels representing the discourse constituents of
the structure, LAST ? A the last introduced label
and F a function which assigns each member of
A a well-formed formula of the SDRS language
(defined (Asher and Lascarides, 2003, p 138)).
SDRSs correspond to ? expressions with a contin-
uation style semantics. SDRT distinguishes coor-
dinating and subordinating discourse relations us-
ing a variety of linguistic tests (Asher and Vieu,
2005),1 and isolates structural relations (Parallel
and Contrast) based on their semantics.
The RF is the set of available attachment points
1The subordinating relations of SDRT are currently: Elab-
oration (a relation defined in terms of the main eventualities
of the related constituents), Entity-Elaboration (E-Elab(a,b)
iff b says more about an entity mentioned in a that is not the
main eventuality of a) Comment, Flashback (the reverse of
Narration), Background, Goal (intentional explanation), Ex-
planation, and Attribution. The coordinating relations are:
Narration, Contrast, Result, Parallel, Continuation, Alterna-
tion, and Conditional, all defined in Asher and Lascarides
(2003).
to which a new utterance can be attached. What
this set includes depends on the discourse relation
used to make the attachment. Here is the defini-
tion from (Asher and Lascarides, 2003, p 148).
Suppose that a constituent ? is to be attached to a
constituent in the SDRS with a discourse relation
other than Parallel or Contrast. Then the avail-
able attachment points for ? are:
1. The label ? = LAST;
2. Any label ? such that:
(a) i-outscopes(?, ?) (i.e. R(?, ?) or
R(?, ?) is a conjunct in F(?) for
some R and some ?); or
(b) R(?, ?) is a conjunct in F(?) for
some label ?, where R is a subordi-
nating discourse relation.
We gloss this as ? < ?.
3. Transitive Closure:
Any label ? that dominates ? through a
sequence of labels ?1, ?2, . . . ?n such that
? < ?1 < ?2 < . . . ?n < ?
We can represent an SDRS as a graph G, whose
nodes are the labels of the SDRSs constituents and
whose typed arcs represent the relations between
them. The nodes available for attachment of a new
element ? in G are the last introduced node LAST
and any other node dominating LAST, where the
notion of domination should be understood as the
transitive closure over the arrows given by sub-
ordinating relations or those holding between a
complex segment and its parts. Subordinating re-
lations like Elaboration extend the vertical dimen-
sion of the graph, whereas coordinating relations
like Narration expand the structure horizontally.
The graph of every SDRS has a unique top label
for the whole structure or formula; however, there
may be multiple < paths defined within a given
SDRS, allowing for multiple parents, in the ter-
minology of (Wolf and Gibson, 2006). Further-
more, SDRT allows for multiple arcs between con-
stituents and attachments to multiple constituents
on the RFC, making for a very rich structure.
SDRT?s RFC is restricted to non-structural rela-
tions, because structural relations postulate a par-
tial isomorphism from the discourse structure of
the second constituent to the discourse structure
of the first, which provides its own attachment
possibilities for subconstituents of the two related
structures (Asher, 1993). Sometimes such paral-
lelism or contrast, also known as discourse subor-
dination (Asher, 1993), can be enforced in a long
2
distance way by repeating the same wording in the
two constituents.
RFC has the name it does because the segments
that belong on this set (the ?s in the above def-
inition) are typically nodes on a discourse graph
which are geometrically placed at the RF of the
graph. Consider the following example embel-
lished from Asher and Lascarides (2003):
(1) (?1) John had a great evening last night. (?2) He first
had a great meal at Michel Sarran. (?3) He ate
profiterolles de foie gras, (?4) which is a specialty of
the chef. (?5) He had the lobster, (?6) which he had
been dreaming about for weeks. (?7) He then went
out to a several swank bars.
The graph of the SDRS for 1 looks like this:
(2) ?1
Elaboration
??
?2
ElaborationNarration
?7
???
?3
E-elabNarration
?5
Background
?4 ?6
where ?? and ??? represent complex segments.
Given that the last introduced utterance is repre-
sented by the node ?7, the set of nodes that are
on the RF are ?7 (LAST), ?? (the complex segment
that includes ?7) and ?1 (connected via a subordi-
nating relation to ??). All those nodes are geomet-
rically placed at the RF of the graph.
SDRT?s notion of a RF is more general than
RST?s or DLTAG?s. First, SDRSs can have com-
plex constituents with multiple elements linked
by coordinate relations that serve as arguments
to other relations, thus permitting instances of
shared structure that are difficult to capture in a
pure tree notation (Lee et al, 2008). In addi-
tion, in RST the RF picks out the adjacent con-
stituents, LAST and complex segments including
LAST. Contrary to RST, SDRT, as it uses 2-
dimensional graphs, predicts that an available at-
tachment point for ?7 is the non local and non ad-
jacent ?2, which is distinct from the complex con-
stituent consisting of ?2 to ?6.2 This difference
is crucial to the interpretation of the Narration:
2The 2-dimensionality of SDRSs also allows us to rep-
Narration claims a sequence of two events; mak-
ing the complex constituent (essentially a sub-
SDRS) an argument of Narration, as RST does,
makes it difficult to recover such an interpreta-
tion. Danlos?s (2008) interpretation of the Nu-
clearity Principle provides an interpretation of the
Narration([2-4],5) that is equivalent to the SDRS
graph above.3 But even an optional Nuclearlity
Principle interpretation won?t help with discourse
structures like (2) where the backgrounding ma-
terial in ?4 and the commentary in ?6 do not and
cannot figure as part of the Elaboration for seman-
tic reasons. In our corpus described below, over
20% of the attachments were non adjacent; i.e. the
attachment point for the new material did not in-
clude LAST.
A further difference between SDRT and other
theories is that, as SDRT?s RFC is applied re-
cursively over complex segments within a given
SDRS, many more attachment points are available
in SDRT. E.g., consider the SDRS for this example,
adapted from (Wolf and Gibson, 2006):
(3) (?1) Mary wanted garlic and thyme. (?2) She also
needed basil. (?3) The recipe called for them. (?4)
The basil would be hard to come by this time of year.
? Explanation
?1 Parallel ?2E-elab
?3
?4
Because ? is the complex segment consisting
of ?1 and ?2, attachment to ? with a subordinat-
ing discourse relation permits attachment ??s open
constituents as well.4
3 Annotated Corpus
Our corpus comes from the discourse structure an-
notation project ANNODIS5 which represents an
on going effort to build a discourse graph bank
for French texts with the two-fold goal of test-
ing various theoretical proposals about discourse
resent many examples with Elaboration that involve cross-
ing dependencies in Wolf and Gibson?s (2006) representation
without violation of the RFC.
3Baldridge et al (2007), however, show that the Nuclear-
ity Principle does not always hold.
4This part of the RFC was not used in (Asher and Las-
carides, 2003).
5http://w3.erss.univ-tlse2.fr/annodis
3
structure and providing a seed corpus for learning
discourse structures using ML techniques. ANN-
ODIS?s annotation manual provides detailed in-
structions about the segmentation of a text into
Elementary Discourse Units (EDUs). EDUs corre-
spond often to clauses but are also introduced by
frame adverbials,6 appositive elements, correla-
tive constructions ([the more you work,] [the more
you earn]), interjections and discourse markers
within coordinated VPs [John denied the charges]
[but then later admitted his guilt]. Appositive ele-
ments often introduce embedded EDUs; e.g., [Jim
Powers, [President of the University of Texas at
Austin], resigned today.], which makes our seg-
mentation more fine-grained than Wolf and Gib-
son?s (2006) or annotation schemes for RST or the
PDTB.
The manual also details the meaning of dis-
course relations but says nothing about the struc-
tural postulates of SDRT. For example, there is no
mention of the RFC in the manual and very little
about hierarchical structure. Subjects were told
to put whatever discourse relations from our list
above between constituents they felt were appro-
priate. They were also told that they could group
constituents together whenever they felt that as a
whole they jointly formed the term of a discourse
relation. We purposely avoided making the man-
ual too restrictive, because one of our goals was
to examine how well SDRT predicts the discourse
structure of subjects who have little knowledge of
discourse theories.
In total 5 subjects with little to no knowledge
of discourse theories that use RFC participated
in the annotation campaign. Three were under-
graduate linguistics students and two were grad-
uate linguistics students studying different areas.
The 3 undergraduates benefitted from a completed
and revised annotation manual. The two gradu-
ate students did their annotations while the anno-
tation manual was undergoing revisions. All in
all, our annotators doubly annotated about 100
French newspaper texts and Wikipedia articles.
Subjects first segmented each text into EDUs, and
then they were paired off and compared their seg-
6Frame adverbials are sentence initial adverbial phrases
that can either be temporal, spatial or ?topical" (in Chem-
istry).
mentations, resolving conflicts on their own or via
a supervisor. The annotation of the discourse re-
lations was performed by each subject working
in isolation. ANNODIS provided a new state of
the art tool, GLOZZ, for discourse annotation for
the three undergraduates. With GLOZZ annotators
could isolate sections of text corresponding to sev-
eral EDUs, and insert relations between selected
constituents using the mouse. Though it did por-
tray relations selected as lines between parts of the
text, GLOZZ did not provide a discourse graph or
SDRS as part of its graphical interface. The rep-
resentation often yielded a dense number of lines
between segments that annotators and evaluators
found hard to read. The inadequate interline spac-
ing in GLOZZ also contributed to certain number
of click errors that we detail below in the paper.
The statistics on the number of documents, EDUs
and relations provided by each annotator are in ta-
ble 1.
annotator # Docs # EDUs # Relations
undergrad 1 27 1342 1216
undergrad 2 31 1378 1302
undergrad 3 31 1376 1173
grad 1 47 1387 1390
grad 2 48 1314 1321
Table 1: Statistics on documents, EDUs and Rela-
tions.
4 Experiments and Results
Using ANNODIS?s annotated corpus, we checked
for all EDUs ?, whether ? was attached to a con-
stituent in the SDRS built from the previous EDUs
in a way that violated the RFC. Given a discourse
as a series of EDUs ?1, ?2, . . . , ?n, we constructed
for each ?i the corresponding sub-graph and cal-
culated the set of nodes on the RF of this sub-
graph. We then checked whether the EDU ?i+1
was attached to a node that was found in this set.
We also checked whether any newly created com-
plex segment was attached to a node on the RF of
this sub-graph.
4.1 Calculating the Nodes at the RF
To calculate the nodes on the RF, we slightly ex-
tended the annotated graphs, in order to add im-
4
plied relations left out by the annotators.7
Disconnected Graphs While checking the RFC
for the attachment of a node n, the SDRS graph
at this point might consist of 2 or more disjoint
subgraphs which get connected together at a later
point. Because we did not want to decide which
way these graphs should be connected, we defined
a right frontier for each one using its own LAST.
We then calculated the RF for each one of them
and set the set of available nodes to be those in
the union of the RFs of the disjoint subgraphs. If
the subgraphs were not connected at the end of
the incremental process in a way that conformed
to RFC, we counted this as a violation. Annotators
did not always provide us with a connected graph.
Postponed Decisions SDRT allows for the at-
tachment not only of EDUs but also of subgraphs
to an available node in the contextually given
SDRS. For instance, in the following example, the
intended meaning is given by the graph in which
the Contrast is between the first label and the com-
plex constituent composed of the disjunction of ?2
and ?3.
(?1) Bill doesn?t like sports. (?2) But Sam does.
(?3) Or John does.
?1 Contrast ?
?
?2 Altern. ?3
Naive annotators attached subgraphs instead of
EDUs to the RF with some regularity (around 2%).
This means that an EDU ?i+1 could be attached to
a node that was not present in the subgraph pro-
duced by ?1, . . . , ?i. There were two main rea-
sons for this: (1) ?i+1 came from a syntactically
fronted clause, a parenthetical or apposition in a
sentence whose main clause produced ?i+2 and
?i+1 was attached to ?i+2; (2) ?i+1 was attached
to a complex segment [. . . , ?i+1, . . . , ?i+k, . . .]
which was not yet introduced in the subgraph.
Since the nodes to which ?i+1 is attached in
such cases are not present in the graph, by def-
inition they are not in the RF and they could be
counted as violations. Nonetheless, if the nodes
7In similar work on TimeML annotations, Setzer et al
(2003; Muller and Raymonet (2005) add implied relations to
annotated, temporal graphs.
which connect nodes like ?i+1 eventually link up
to the incrementally built SDRS in the right way,
?i+1 might eventually end up linked to something
on the RF. For this reason, we postponed the de-
cision on nodes like ?i+1 until the nodes to which
they are attached were explicitly introduced in the
SDRS.
The Coherence of Complex Segments In an
SDRS, several EDUs may combine to form a com-
plex segment ? that serves as a term for a dis-
course relation R. The interpretation of the SDRS
implies that all of ??s constituents contribute to
the rhetorical function specified by R. This im-
plies that the coordinating relation Continuation
holds between the EDUs inside ?, unless there is
some other relation between them that is incom-
patible with Continuation (like a subordinating
relation). Continuations are often used in SDRT
(Asher, 1993; Asher and Lascarides, 2003). Dur-
ing the annotation procedure, our subjects did not
always explicitly link the EDUs within a complex
segment. In order to enforce the coherence of
those complex segments we added Continuation
relations between the constituents of a complex
segment unless there was already another path be-
tween those constituents.
Expanding Continuations Consider the fol-
lowing discourse:
(4) [John, [who owns a chain of restaurants]?2 , [and is a
director of a local charity organization,]?3 wanted to
sell his yacht.]?1 [He couldn?t afford it anymore.]?4
Annotators sometimes produced the following
SDRT graph for the first three EDUs of this dis-
course:
(5) ?1
E-Elab
?2 Continuation ?3
In this case the only open node is ?3 due to
the coordinating relation Continuation. Nonethe-
less, ?4 should be attached to ?1, without vi-
olating the RFC. Indeed, SDRT?s definition of
the Continuation relation enforces that if we have
R(?1, ?2) and Continuation(?2, ?3) then we ac-
tually have the complex segment [?2, ?3] with
R(?1, [?2, ?3]). So there is in fact a missing com-
plex segment in (5). The proper SDRS graph of (4)
is:
5
(6) ?1
E-Elab
?
?2 Continuation ?3
which makes ?1 an available attachment site for
?4. Such implied constituents have been added to
the SDRS graphs.
Factoring Related to the operation of Ex-
pansion, SDRT?s definition of Continuation and
various subordinating relations also requires
that if we have R(a, [?1, ?2, . . . , ?n]) where
[?1, ?2, . . . , ?n] is a complex segment with
?1, . . . ?n linked by Continuation and R is Elabo-
ration, Entity-Elaboration, Frame, Attribution, or
Commentary, then we also have R(a, ?i) for each
i. We added these relations when they were miss-
ing.
4.2 Results
With the operations just described, we added sev-
eral inferred relations to the graph. We then cal-
culated statistics concerning the percentage of at-
tachments for which the RFC is respected using
the following formula:
RFCEDU =
# EDUs attached to the RF
# EDUs in total
As we explained, an EDU can be attached to an
SDRT graph directly by itself or indirectly as part
of a bigger complex segment. In order to calcu-
late the nominator we determine first whether an
EDU directly attaches to the graph?s RF, and if that
fails we determine whether it is part of a larger
complex segment which is attached to the graph?s
RF. The results obtained are shown in the first two
columns of table 2. The RFC is respected by at
least some attachment decision 95% of the time?
i.e., 95% of the EDUs get attached to another node
that is found on the RF. The breakdown across our
annotators is given in table 2.
SDRT allows for multiple attachments of an
EDU to various nodes in an SDRS; e.g. while an
EDU may be attached via one relation to a node
on the RF, it may be attached to another node off
the RF. To take account of all the attachments for a
given EDU, we need another way of measuring the
percentage of attachments that respects the RFC.
So we counted the ways each EDU is related to a
node in the SDRS for the previous text and then
divided the number of attachment decisions that
respect the RFC by the total number of attachment
decisions?i.e. :
RFCr =
# RF attachment decisions
# Total attachment decisions
.
annotator RFCEDU RFCr
undergrad 1 98.57% 91.28%
undergrad 2 98.12% 94.39%
undergrad 3 91.93% 89.17%
grad 1 94.38% 86.54%
grad 2 92.68% 83.57%
Mean for all annotators 95.24% 88.91%
Mean for 3 undergrad 96.17% 91.71%
Table 2: The % with which each annotator has re-
spected SDRT?s RFC using the EDU and attachment
decision measures.
The third column of table 2 shows that having
a stable annotation manual and GLOZZ improved
the results across our two annotator populations,
even though the annotation manual did not say
anything about RFC or about the structure of the
discourse graphs. Moreover, the distribution of vi-
olations of the RFC follows a power law and only
4.56% of the documents contained more than 5 vi-
olations. This is strong evidence that there is little
propagation of violations.
5 Analysis of Presumed Violations
Although 95% of EDUs attach to nodes on the
RF of an SDRT graph, 5% of EDUs don?t. SDRT
experts performed a qualitative analysis of some
of these presumed violations. In many cases, the
experts judged that the presumed violations were
due to click-errors: sometimes the annotators sim-
ply clicked on something that did not translate into
a segment. Sometimes, the experts judged that the
annotators picked the wrong segment to attach a
new segment or the wrong type of relation during
the construction of the SDRT graph. For example,
in the graph that follows the relation between seg-
ments 74 and 75 is not a Comment but an Entity-
Elaboration.
6
As expected, there were also ?structural? er-
rors, arising from a lack or a misuse of complex
segments. Here is a typical example (translated
from the original French):
[Around her,]_74 [we should mention Joseph
Racaille]_75 [responsible for the magnificent ar-
rangements,]_76 [Christophe Dupouy]_77 [reg-
ular associate of Jean-Louis Murat responsi-
ble for mixing,]_78 [without forgetting her two
guardian angels:]_79 [her agent Olivier Gluz-
man]_80 [who signed after a love at first
sight,]_81 [and her husband Mokhtar]_82 [who
has taken care of the family]_83
Here is the annotated structure up to EDU 78:
74
Comment
75
E-elab Cont
77
E-elab
76 78 (LAST)
Note that the attachment of 77 to 75 is non-local
and non-adjacent. The annotator then attaches
EDU 79 to 75 which is blocked from the RF due to
the Continuation coordinating relation. By not
having created a complex segment due the enu-
meration that includes EDUs 75 to 78, the annota-
tor had no option but to violate the RF. Here is the
proper SDRT graph for segments 74 to 79 (where
the attachment of 79 to 74 is also both non-local
and non-adjacent):
74
Elab
Elab
? 79
75
E-elabContinuation
77
E-elab
76 78
In this case, before the introduction of EDU 79,
EDU 78 is LAST and by consequence 77, ? and 74
are on the RF. Attaching 79 to 74 is thus legiti-
mate.
We also found more interesting examples of
right frontier violations. One annotator produced
a graph for a story which is about the attacks of
9/11/2001 and is too long to quote here. A sim-
plified graph of the first part of the story is shown
below. EDU 4 elaborates on the main event of the
story but it is not on the RF for 19. However, 19
is the first recurrence of the complex definite de-
scription le 11 septembre 2001 since the title and
the term?s definition in EDU 4.
4
E-elab
Continuation
7 Result [11-13] Result [14-16]Comment
19
This reuse of the full definite description could be
considered a case of SDRT?s discourse subordina-
tion.
6 RFC and distances of attachment
Our empirical study vindicates SDRT?s RFC, but
it also has computational implications. Using the
RFC dramatically diminishes the number of at-
tachment possibilities and thus greatly reduces the
search space for any incremental discourse pars-
ing algorithm.8 The mean of nodes that are open
on the RF at any given moment on our ANNODIS
data is 16.43% of all the nodes in the graph.
Our data also allowed us to calculate the dis-
tance of attachment sites from LAST, which could
be an important constraint on machine learning
algorithms for constructing discourse structures.
Given a pair of constituents (?i, ?j) distance is
calculated either textually (the number of inter-
vening EDUs between ?i and ?j) or topologically
(the length the shortest path between ?i and ?j).
Topological distance, however, does not take into
account the fact that a textually further segment is
cognitively less salient. Moreover, this measure
can give the same distance to nodes that are textu-
ally far away between them due to long distance
pop-ups (Asher and Lascarides, 2003). A purely
textual distance, on the other hand, gives the same
distance to an EDU ?i and a complex segment
[?1, . . . , ?i] even if ?1 and ?i are textually dis-
tant (since both have the same span end). We used
a measure combining both. The distance scheme
that we used assigns to each EDU its textual dis-
tance from LAST in the graph under consideration,
while a complex segment of rank 1 gets a distance
which is computed from the highest distance of
their constituent EDUs plus 1. For a constituent ?
of rank n we have:
Dist = Max{dist(x) : x in ?}+ n
8An analogous approach for search space reduction is fol-
lowed by duVerle and Prendinger (2009) who use the ?Prin-
ciple of Sequentiality? (Marcu, 2000), though they do not say
how much the search space is reduced.
7
The distribution of attachment follows a power
law with 40% of attachments performed non-
locally, that is on segments of distance 2 or more
(figure 1). This implies that the distance between
candidate attachment sites that are on the RF is an
important feature for an ML algorithm. It is impor-
tant to note at this point that following the baseline
approach of always attaching on the LAST misses
40% of attachments. We also have 20.38% of the
non-local, non-adjacent attachments in our anno-
tations. So an RST parser using Marcu?s (2000)
adjacency constraint as do duVerle and Prendinger
(2009) would miss these.
0
10
20
30
40
50
60
0 2 4 6 8 10 12 14 16 18 20
P
e
r
c
e
n
t
ag
e
Attachment distance
3
3333333333333333333
Figure 1: Distribution of attachment distance
7 Related Work
Several studies have shown that the RFC may be
violated as an anaphoric constraint when there
are other clues, content or linguistic features, that
determine the antecedent. (Poesio and di Euge-
nio, 2001; Holler and Irmen, 2007; Asher, 2008;
Pr?vot and Vieu, 2008), for example, show that
anaphors such as definite descriptions and com-
plex demonstratives, which often provide enough
content on their own to isolate their antecedents,
or pronouns in languages like German which must
obey gender agreement, might remain felicitous
although the discourse relations between them and
their antecedents might violate the RFC. Usually
there are few linguistic clues that help find the
appropriate antecedent to a discourse relation, in
contrast to the anaphoric expressions mentioned
above. Exceptions involve stylistic devices like
direct quotation that license discourse subordina-
tion. Thus, SDRT predicts that RFC violations for
discourse attachments should be much more rare
than those for the resolution of anaphors that pro-
vide linguistic clues about their antecedents.
As regards other empirical validation of var-
ious versions of the RFC for the attachment of
discourse constituents, Wolf and Gibson (2006)
show an RST-like RFC is not supported in their
corpus GraphBank. Our study concurs in that
some 20% of the attachments in our corpus can-
not be formulated in RST.9 On the other hand,
we note that because of the 2 dimensional nature
of SDRT graphs and because of the caveats intro-
duced by structural relations and discourse sub-
ordination, the counterexamples from GraphBank
against, say, RST representations do not carry over
straightforwardly to SDRSs. In fact, once these
factors are taken into account, the RFC violations
in our corpus and in GraphBank are roughly about
the same.
8 Conclusions
We have shown that SDRT?s RFC has strong empir-
ical support: the attachments of our 3 completely
naive annotators fully comply with RFC 91.7% of
the time and partially comply with it 96% of the
time. As a constraint on discourse parsing SDRT?s
RFC, we have argued, is both empirically and
computationally motivated. We have also shown
that non-local attachments occur about 40% of the
time, which implies that attaching directly on the
LAST will not yield good results. Further, many of
the non local attachments do not respect RST?s ad-
jacency constraint. We need SDRT?s RFC to get the
right attachment points for our corpus. We believe
that empirical studies of the kind we have given
here are essential to finding robust and useful fea-
tures that will vastly improve discourse parsers.
9One other study we are aware of is Sassen and K?hn-
lein (2005), who show that in chat conversations, the RFC
does not always hold unconditionally. Since this genre of
discourse is not always coherent, it is expected that the RFC
will not always hold here.
8
References
Asher, N. and A. Lascarides. 2003. Logics of Con-
versation. Studies in Natural Language Processing.
Cambridge University Press, Cambridge, UK.
Asher, N. and L. Vieu. 2005. Subordinating and co-
ordinating discourse relations. Lingua, 115(4):591?
610.
Asher, N. 1993. Reference to Abstract Objects in Dis-
course. Kluwer Academic Publishers.
Asher, N. 2007. A large view of semantic content.
Pragmatics and Cognition, 15(1):17?39.
Asher, N. 2008. Troubles on the right frontier.
In Benz, A. and P. K?hnlein, editors, Constraints
in Discourse, Pragmatics and Beyond New Series,
chapter 2, pages 29?52. John Benjamins Publishing
Company.
Baldridge, J., N. Asher, and J. Hunter. 2007. An-
notation for and robust parsing of discourse struc-
ture on unrestricted texts. Zeitschrift fur Sprachwis-
senschaft, 26:213?239.
Danlos, L. 2008. Strong generative capacity of rst,
sdrt and discourse dependency dags. In Benz, A.
and P. K?hnlein, editors, Constraints in Discourse,
Pragmatics and Beyond New Series, pages 69?95.
John Benjamins Publishing Company.
duVerle, D. and H. Prendinger. 2009. A novel dis-
course parser based on support vector machine clas-
sification. In Proceedings of ACL, pages 665?673,
Suntec, Singapore, August.
Hardt, D. and M. Romero. 2004. Ellipsis and
the structure of discourse. Journal of Semantics,
21:375?414, November.
Hardt, D., N. Asher, and J. Busquets. 2001. Discourse
parallelism, scope and ellipsis. Journal of Seman-
tics, 18:1?16.
Holler, A. and L. Irmen. 2007. Empirically assessing
effects of the right frontier constraint. In Anaphora:
Analysis, Algorithms and Applications, pages 15?
27. Springer, Berlin/Heidelberg.
Lascarides, A. and N. Asher. 1993. Temporal interpre-
tation, discourse relations and commonsense entail-
ment. Linguistics and Philosophy, 16(5):437?493.
Lee, A., R. Prasad, A. Joshi, and B. Webber. 2008.
Departures from tree structures in discourse: Shared
arguments in the penn discourse treebank. In Con-
straints in Discourse (CID ?08), pages 61?68.
Mann, W. and S. Thompson. 1987. Rhetorical struc-
ture theory: A framework for the analysis of texts.
Technical Report ISI/RS-87-185, Information Sci-
ences Institute, Marina del Rey, California.
Mann, W. and S. Thompson. 1988. Rhetorical struc-
ture theory: Towards a functional theory of text or-
ganization. Text, 8(3):243?281.
Marcu, D. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. The MIT Press.
Muller, P. and A. Raymonet. 2005. Using inference
for evaluating models of temporal discourse. In
12th International Symposium on Temporal Repre-
sentation and Reasoning, pages 11?19. IEEE Com-
puter Society Press.
Poesio, M. and B. di Eugenio. 2001. Discourse struc-
ture and anaphoric accessibility. In Proc. of the
ESSLLI Workshop on Discourse Structure and In-
formation Structure, August.
Polanyi, L. 1985. A theory of discourse structure and
discourse coherence. In Kroeber, P. D., W. H. Eil-
fort, and K. L. Peterson, editors, Papers from the
General Session at the 21st Regional Meeting of the
Chicago Linguistics Society.
Polanyi, L. 1988. A formal model of the structure of
discourse. Journal of Pragmatics, 12:601?638.
Pr?vot, L. and L. Vieu. 2008. The moving right fron-
tier. In Benz, A. and P. K?hnlein, editors, Con-
straints in Discourse, Pragmatics and Beyond New
Series, chapter 3, pages 53?66. John Benjamins
Publishing Company.
Sassen, C. and P. K?hnlein. 2005. The right fron-
tier constraint as conditional. In Computational
Linguistics and Intelligent Text Processing, Lecture
Notes in Computer Science (LNCS), pages 222?
225.
Setzer, A., R. Gaizauskas, and M. Hepple. 2003.
Using semantic inferences for temporal annotation
comparison. In Proceedings of the Fourth Interna-
tional Workshop on Inference in Computational Se-
mantics (ICoS-4).
Webber, B. 1988. Title discourse deixis and discourse
processing. Technical Report MS-CIS-88-75, Uni-
versity of Pennsylvania, Department of Computer
and Information Science, September.
Wolf, F. and E. Gibson. 2006. Coherence in Natural
Language: Data Stuctures and Applications. The
MIT Press.
9
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 2184?2194, Dublin, Ireland, August 23-29 2014.
Unsupervised extraction of semantic relations using discourse cues
Juliette Conrath Stergos Afantenos Nicholas Asher Philippe Muller
IRIT, Universit? Toulouse & CNRS, Univ. Paul Sabatier, 118 Route de Narbonne, 31062 Toulouse
{firstname.lastname@irit.fr}
Abstract
This paper presents a knowledge base containing triples involving pairs of verbs associated with
semantic or discourse relations. The relations in these triples are marked by discourse connectors
between two adjacent instances of the verbs in the triple in the large French corpus, frWaC.
We detail several measures that evaluate the relevance of the triples and the strength of their
association. We use manual annotations to evaluate our method, and also study the coverage of
our resource with respect to the discourse annotated corpus Annodis. Our positive results show
the potential impact of our resource for discourse analysis tasks as well as other semantically
oriented tasks like temporal and causal information extraction.
1 Introduction
Relational lexical resources, which describe semantic relations between lexical items, have tradition-
ally focused on relations like synonymy or similarity in thesauri, perhaps including some hierarchical
semantic relations like hyperonymy or hyponomy or part-whole relations as in the resource Wordnet (Fel-
baum, 1998). Some distributional thesauri contain more varied relations, see e.g. (Grefenstette, 1994),
however these relations are not typed. The lexical semantics given by FrameNet (Baker et al., 1998) does
include causal and temporal relations, as does Verbocean (Chklovski and Pantel, 2004), but coverage is
limited and empirical validation of these resources is partial and still largely remains to be done.
Lexical relations, in particular between verbs, are nevertheless crucial for understanding natural lan-
guage and for many information processing tasks. They are needed for textual inference, in which one
has to infer certain relations between eventualities (Hashimoto et al., 2009; Tremper and Frank, 2013),
for information extraction tasks, like finding temporal relations between eventualities mentioned in a text
(UzZaman et al., 2013), for automatic summarization (Liu et al., 2007), and for discourse parsing in the
absence of explicit discourse markers (Sporleder and Lascarides, 2008).
In this paper we report on our efforts to extract semantic relations essential to the analysis of discourse
and its interpretation, in which links are made between units of text or rather their semantic representa-
tions as in (1) in virtue of semantic information about the two main verbs of those clauses.
(1) The candidate demonstrated his expertise during the interview. The committee was completely
convinced.
We follow similar work on the extraction of causal, temporal, entailment and presuppositional relations
from corpora (Do et al., 2011; Chambers and Jurafsky, 2008; Hashimoto et al., 2009; Tremper and Frank,
2013), though our goals and validation methods are different. While one of our goals is to use this
information to improve performance in predicting discourse relations between clauses, we believe that
such a lexical resource will have other uses in other tasks in which semantic information is needed.
Discourse analysis is a difficult task. Rhetorical relations are frequently implicit and require for their
identification inference using diverse sources of lexical and compositional semantic information. In the
Penn Discourse Treebank corpus for example, 52% of the discourse relations are unmarked (Prasad et
This work has been supported by the French agency Agence Nationale de la Recherche (ANR-12-CORD-0004).
It is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added
by the organizers. License details : http://creativecommons.org/licenses/by/4.0/.
2184
al., 2008). Accordingly, annotation with discourse structure is a slow and error prone task, and relatively
little annotated data is currently available ; and so machine learning approaches have had limited suc-
cess in this area. Our approach addresses this problem, using non annotated data with features that can
be automatically detected to find typical contexts (pairs of discourse units) in which various discourse
relations occur. We suppose with (Sporleder and Lascarides, 2008; Braud and Denis, 2013) that such
contexts display regular lexical associations, in particular with verbs in those discourse units. An ex-
plicit, manually compiled list of all possible associations between two verbs and the semantic relations
they suggest is infeasible, so we present here an automatic method for compiling such a list, inspired by
the Verbocean project (Chklovski and Pantel, 2004).
Our hypothesis, supported by existing corpora, is that adjacent clauses are often arguments of discourse
relations. When these clauses contain certain adverbs or other discourse connectors, we can recover
automatically one or more discourse relations that we associate with the main verbs of those clauses. We
extract triples consisting of the two verbs and a semantic relation from a large corpus with the aim of
inferring that such a pair of verbs can suggest the semantic relation even in the absence of an explicit
discourse marker. We thus also suppose, with (Sporleder and Lascarides, 2008; Braud and Denis, 2013),
that such discourse markers are at least partially redundant ; inferring a discourse relation between two
clauses relies not only the marker but on the two verbs in the related clauses as well. All of our work has
been done on French data.
Our paper is organized as follows. We describe first the knowledge base of verb semantic relation
triples that we have constructed (section 2) ; we then present our methods for isolating verb pairs impli-
cating discourse or temporal information (section 3). A third section describes our methods of evaluation
(section 4) and a fourth discusses related work (section 5).
2 Exploring relations between verbs in a corpus
We built a knowledge base (V
2
R)
1
using the frWaC corpus(Baroni et al., 2009). frWaC contains about
1.6 billion words and was collected on the Web on the .fr domain. We first parsed the documents in our
corpus using BONSAI
2
, which first produced a morpho-syntactic labeling using MElt (Denis and Sagot,
2012) and then a syntactic analysis in the form of dependency trees via a French version of the MaltParser
(Nivre et al., 2007).
Our goal is to find pairs of verbs linked by a relation explicitly marked by a discourse connector
in the corpus, as an indication of a regular semantic relation between the two verbs. The relations we
have considered are common to most theories of discourse analysis, and they can be grouped into four
classes (Prasad et al., 2008) : causal (contingency) relations, temporal relations, comparison relations
(mainly contrast type relations), and expansion relations (e.g. elaboration or continuation).
To find explicitly marked relations, we used a lexicon of discourse connectors for French, the man-
ually constructed LEXCONN resource (Roze et al., 2012)
3
. LEXCONN includes 358 connectors and
gives their syntactic category as well as associated discourse relations inspired from (Asher and Las-
carides, 2003). Some connectors are ambiguous in that they are associated with several relations. We
used only the unambiguous connectors (263 in all) in LEXCONN, as a first step. We regrouped the
LEXCONN relations into classes
4
: explanation relations (parce que/because) and result (ainsi/thus)
form the causal class ; temporal relations (puis, apr?s que/then,after that) form the narration group. We
also considered other relations like contrast (mais/but), continuation (et, encore/and,again), background
(alors que/while), temporal location (quand, pendant que/when), detachment (de toutes fa?ons/anyway),
elaboration (en particulier/in particular), alternation (ou/or), commentary (au fait/by the way), rephras-
ing (du moins/at least), and evidence (effectivement/indeed).
We searched our syntactically parsed corpus for connectors. When a connector is found and its syn-
tactic category verified, if it is close enough to the root of the sentence (at most one dependency link
from the root), we look for an inter-sentential link. The first verb of our pair corresponds in this case
1. Available as an SQLite database at https://dl.dropboxusercontent.com/u/78938139/v2r_db
2. http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html or (Candito et al., 2010)
3. Freely available at : https://gforge.inria.fr/frs/download.php/31052/lexconn.tar.gz.
4. We illustrate each relation with examples of potentially ambiguous markers.
2185
to the last verb of the previous sentence in the case of connectors for narration, or to its main verb for
all the other relations. We search for the second verb in the pair within a window of two dependency
links after the connector. If the connector is not close enough to the root of the sentence, we look for
a intra-sentential link. In this case, we look for the two verbs of the pair in the same sentence within a
forward and backward window of two dependency links.
If two verbs are found, we examine their local context to better characterize their usage and to improve
our results. If one of the verbs is a modal or support verb, we look for the verb dependent on the modal
or support verb and use that as the verb in our pair (if it exists), while keeping the presence of the
support verb in memory. Unlike support verbs, we use the presence of a negation or a reflexive particle
in the local context to distinguish verbs with different meanings ; e.g., comprendre/understand vs. ne pas
comprendre/not understand, agir/act vs. s?agir/concern are all distinct entries. To get at different verb
senses, we search for idiomatic usage of prepositions using the Dicovalence resource (Van Den Eynde
and Mertens, 2010), which contains valency frames for more than 3700 simple French verbs. We also
use the Lefff resource (Sagot, 2010) to find idiomatic verbal locutions. We also encode other information
that do not lead to distinct lexical entries : tense, and voice.
Once we have obtained a list of verb pairs associated with
Relation Distribution
contrast 50,104%
cause 33,108%
continuation 8,243%
narration 6,362%
background 1,853%
temporal localisation 0.177%
detachement 0.149%
elaboration 0.002%
alternation 0.002%
TABLE 1 ? Distribution of relations in
V
2
R ;commentary, reformulation and
evidence occur with negligible fre-
quency.
a connector, we aggregate this data to get a list of triple types
(verb1, verb2, relation). Given that we have used only unam-
biguous connectors (so classified by LEXCONN), the associ-
ation of a relation with a connector is immediate. We asso-
ciate to each triple type the number of intra-sentential, inter-
sentential and total number of occurrences. The other features
mentioned above are stored in a separate table.
Our method has isolated more than 1 million distinct types
of triples for V
2
R and 2 million occurrences, of which 95% are
intra-sentential
5
. Among these triples, 6.2% have 5 or more
occurrences.
Table 1 summarizes the distribution of triples by relation
in V
2
R. Note that triples with contrast and causal relations
comprise the majority. This does not mean that these are the
most frequent relations in the corpus but only that they are the
most frequently marked by the connectors we considered. This
makes for a very different distribution than that of the French manually annotated discourse corpus Ann-
odis (Afantenos et al., 2012).
3 Measuring the association of a pair of verbs with a relation
In the last section we presented our extraction method. We now present the measures we have used to
rank verb pairs with respect to the strength of their association with a particular discourse relation. We
adapted versions of standard lexical association measures like PMI (pointwise mutual information) and
their variants, as well as some measures specific to the association of a causal relation between items (Do
et al., 2011). We also experimented with a new measure specifically designed for our knowledge base.
Measures of lexical association used in research on co-occurrences in distributional semantics pick
out significant associations, taking into account the frequency of the related items. We examined over
10 measures ; we discuss the ones with the best results (see section 4). One simple measure, PMI, and
its variants, normalized, local (Evert, 2005), discounted (Lin and Pantel, 2002), which are designed
to reduce biases in the original measure, work well. The idea behind PMI is to estimate whether the
probability of the co-occurrence of two items is greater than the a priori probability of the two items
appearing independently. In distributional semantics, the measure is also used to estimate the significance
of two items co-occurring with a particular grammatical dependency relation like the subject or object
relation between an NP and a verb. This use of PMI measures over triples in distributional semantics
fits perfectly with our task of measuring the significance of triples consisting of a pair of verbs and
5. The low proportion of inter-sentential occurrences comes from our conservative scheme for finding these occurrences,
which uses only those connectors at the beginning of the second sentence. Other schemes are possible but would, we fear,
introduce too much noise into the data.
2186
a particular semantic or discourse relation ; our PMI measures estimate whether the co-occurrence of
two items with a particular discourse relation is higher than the a priori probability of the three items
occurring independently. Our measures consider co-occurrences of two lexical items in a certain relation
denoted by an explicit discourse marker. PMI and normalized PMI are defined as :
PMI = log(
P (V
1
, V
2
, R)
P (V
1
)? P (V
2
)? P (R)
)
PMI _normalized =
PMI
?2 log(P (V
1
, V
2
, R))
Indeed, when we have a complete co-occurrence of the three items, we have : P (V
1
) = P (V
2
) =
P (R) = P (V
1
, V
2
, R), and PMI = ?2 log(P (V
1
, V
2
, R)). The values of normalized PMI lie between
?1 and 1, approaching ?1 when the items never appear together, taking the value 0 in the case of
independence, and the value 1 when they always appear together. We also considered a weighted PMI
measure (Lin and Pantel, 2002) that corrects the bias of PMI for rare triples.
A specificity measure (Mirroshandel et al., 2013), originally used to measure the precision of subcat-
egorization frames, also performed well :
specificity =
1
3
? (
P (V
1
, V
2
, R)
?
i
P (V
1
, V
i
, R)
+
P (V
1
, V
2
, R)
?
i
P (V
i
, V
2
, R)
+
P (V
1
, V
2
, R)
?
i
P (V
1
, V
2
, R
i
)
)
A version of Do et al. (2011)?s measure for triples involving causal relations did not fare so well on
other types of relation. The definition of the measure can be found in (Do et al., 2011).
6
Finally, we investigated a measure that evaluates the contribution of each element in the triple to the
significance measure (this measure is similar to specificity).
W
combined
(V
1
, V
2
, R) =
1
3
(w
V
1
+ w
V
2
+ w
R
)
with : w
V
1
=
P (V
1
,V
2
,R)
max
i
(P (V
i
,V
2
,R))
, w
V
2
=
P (V
1
,V
2
,R)
max
i
(P (V
1
,V
i
,R))
, and w
R
=
P (V
1
,V
2
,R)
max
i
(P (V
1
,V
2
,R
i
))
.
4 Evaluating extracted relations
We evaluated V
2
R in several ways ; we provided : (i) an intrinsic evaluation of the relations between
verbs (section 4.1) and (ii) an extrinsic evaluation where we evaluated the coverage of the resource on a
discourse annotated corpus and its potential to help in predicting discourse relations in contexts with no
explicit marking (section 4.2).
4.1 Intrinsic evaluation
Our intrinsic evaluation first evaluates the feasibility of assigning an ?inherent? semantic link to a verb
pair, independently of any linguistic context. For example, is it possible to judge that there is a typical
causality link between push and fall, in scenarios where they share some arguments (subject, object, ...),
these scenarios being left to the annotator?s imagination (section 4.1.1). In a second stage, we selected
several verb pairs linked with different relations in V
2
R, and 40 contexts in which these verbs occur
together in the original corpus, to judge the semantic link in context (section 4.1.2).
In both cases we restricted the study to three relation groups : causal, contrastive, and narrative. These
are the most often marked relations and correspond to different types of links with a meaningful semantic
aspect (as opposed to the ?continuation? relation for instance, which is often marked too).
4.1.1 Out of context evaluation
For out of context judgments, we adopted the following protocol : one of the authors chose for each
relation 100 verbs with equivalent proportions of good and bad normalized PMI scores. Then the other
6. We simplified their measure by ignoring IDF (inverse document frequency) and the distance between the verbs, as neither
measure applies to our task.
2187
three authors judged the validity of associating each of the 300 pairs with the corresponding relation,
without any knowledge of the source of these pairs.
We measured the inter-annotator agreements with Cohen?s Kappa (Carletta, 1996), which resulted in :
0.17 for cause, 0.42 for narration and 0.56 for contrast as mean values. If a 0.6 kappa serves a measure for
a feasible semantic judgment task, out of context judgments appear very difficult, with only contrastive
pairs as a relative exception. We decided to only consider judgments about contrast, after an adjudication
phase, and we evaluated the measures presented in section 3 to see if they could discriminate between
the two verb groups, those judged positively or negatively according to human annotations. A Mann-
Whitney U statistical test showed all of our measures to be discriminative, with the exception of raw
co-occurrence counts for which p>0.05.
4.1.2 In context evaluation
We also judged associations in context.
Verb pair translation association
/human
Cause
inviter/souhaiter invite/wish 12.8%
promettre/?lire promise/elect 25.6%
aimer/trouver like/find 38.5%
b?n?ficier/cr?er benefit/create 51.3%
aider/gagner help/win 53.8%
Contrast
proposer/refuser propose/refuse 59.0%
augmenter/diminuer increase/decrease 64.1%
tenter/?chouer try/fail 64.1%
gagner/perdre win/lose 71.8%
autoriser/interdire authorize/forbid 74.4%
Narration
parler/r?fl?chir speak/think 42.5%
acheter/essayer buy/try 70.0%
atteindre/traverser reach/cross 77.5%
commencer/finir begin/end 80.0%
envoyer/transmettre send/transmit 82.5%
TABLE 2 ? For each relation, the list of verb pairs manu-
ally evaluated in context (and an approximate translation),
and the association percentage resulting from the adjudi-
cated human annotation.
This task was easier and also gave more
fine-grained results, because with it we can
quantify the degree of association, and the
typicality of the link, as a proportion of con-
texts where the two verbs appear together
in a given semantic relation. We can then
observe if this proportion is correlated with
the association measures we already pre-
sented. Nevertheless, this is a costly way of
evaluating a verb pair, as we require a num-
ber of judgments on each pair. It is also not
easy to sample the possible pairs with dif-
ferent values to be able to observe signif-
icant correlations, because we cannot pre-
dict in advance how they will be judged by
the annotators.
We selected 40 contexts for each of the
15 pairs of verbs we chose, 5 for each of the
target relation (cause, narration, contrast).
Selected pairs range over different values of
normalized PMI, again chosen by one of the
authors independently of the others, who
annotated the 600 contexts. Prior to adjudi-
cation, raw agreement was 78% on average,
for an average kappa of 0.46 (and a max-
imum of 0.49). These values seem moder-
ately good, as the task is also rather diffi-
cult.
Table 2 shows the results after adjudication : for each pair, the proportion of contexts in which the
considered relation is judged to appear.
We computed two correlation values between the association ratio in contexts manually annotated
and each association measure considered : one based on all annotated contexts, and one on the subset
of contexts devoid of explicit markers of a semantic relation (implicit contexts). The latter is important
to quantify the actual impact of the method, since explicit marking is already used as the basis of verb
association in the same corpus. Implicit contexts, however, never appeared in the computation of the verb
pair associations.
2188
normalized
PMI
specificity W_combined
discounted
PMI
PMI
local
PMI
U_do
raw fre-
quency
Global
correlation
0.749 0.747 0.720 0.716 0.709 0.434 0.376 0.170
Correlation
for implicit
instances
0.806 0.760 0.738 0.761 0.756 0.553 0.499 0.242
TABLE 3 ? Pearson correlation for the 15 pairs considered and measures from section 3, in decreasing
order.
Table 3 shows that mutual information measures are well correlated with human annotations, and
that our W_combined seems useful too. We also observed results on each relation separately, although
one should be careful drawing conclusions from these results since the correlations are then computed
on 5 points only. These results (not shown here) show a lot of variation between relations. The U_do
measure, designed for causal relations, does indeed produce good results for these relations, but does not
generalize well to our other chosen relations.
Also, local PMI seems to work very well on narration and causal relations. This needs to be confirmed
with more verb pairs.
We conclude that the best three measures are : normalized PMI, specificity, and W_combined. The last
two assign their maximal value to several pairs, so we used them in a lexicographical ordering to sort all
associated pairs, using normalized PMI to break ties.
Verb pair Translation Relation
abandonner / mener abandon / lead background
ne pas s?arr?ter / rouler not stop / drive narration
donner satisfaction sur / r??lire give satisfaction concerning / re-elect continuation
emporter / ne pas cesser take away / not stop summary
emprunter / assurer borrow / insure cause
ne pas manquer / prolonger not miss / prolong detachment
ratifier / trembler ratify / tremble background
avoir honte / faire piti? be ashamed / cause pity cause
avoir droit / cotiser pour be entitled / contribute to temploc
ne pas repr?senter / st?r?otyper not represent / stereotype temploc
TABLE 4 ? Ten best triples in the database.
Table 4 shows the best triples with our lexicographical ranking.
4.2 Extrinsic evaluation
In order to evaluate the performance of our resource relative to its main intended application?
predicting rhetorical relations in text, we intend to use our association measures as additional features
to an inductive prediction model. Whether this evaluation produces results depends on the proportion
of cases in which this information could help and on the coverage of our resource with respect to these
cases. We used the Annodis corpus (Afantenos et al., 2012), a set of French texts annotated with rhetori-
cal relations, for our study.
To improve existing models, a significant number of the predictions to be made must involve a verb
pair for which we have information in the resource. A first indication of its usefulness is also that the
verb pair appears most frequently with the relation group to which the annotation belongs, for instance
the fact that two verbs are related with a causal relation whenever we want to predict an explanation. This
is interesting only in the absence of an explicit marking of the target relation, i.e for implicit relations.
2189
Beyond that, it should be interesting to use all the available information about other semantic relations
too : for instance a potential causal link between two events could indicate the relevance of a temporal link
for the prediction of a relation. We relied again on the Lexconn marker database. As an approximation
we considered that a relation between two discourse units is explicit when a Lexconn marker is present
in any of the two segments, and one of the potential senses of the marker is the annotated relation.
This may overestimate the number of explicit instances but ensures that all implicit instances are indeed
implicit (assuming a good enough coverage of the marker resource). The Annodis corpus lists rhetorical
relations between elementary discourse units (EDUs), typically clauses, and complex discourse units
(sets of EDUs) ; as a simplification we only consider EDUs, since the question of what is a main verb of
a complex unit is difficult to answer. This is a relatively small corpus, as it includes about 2000 instances
of relations between elementary discourse units.
Table 5 present results for coverage, for the main relations in the annotated corpus. Note that only a
small part of the set of relations between EDUs is considered when we restrict instances to both EDUs
with verbs (about 20% of the whole). It turns out that a lot of EDUs in Annodis are short segments
(incises, detached segments, ...).
global narration cause contrast elab. cont. BG other
Annodis pairs 427 73 67 41 96 92 24 16
Annodis pairs ? V
2
R 68.9 71.2 70.8 78.0 68.3 61.9 74.1 62.5
Annodis triples ? V
2
R 26.5 34.2 50.0 70.7 0.0 20.6 11.1 0.0
Implicit Annodis pairs 83.4 71.2 79.2 36.6 99.0 94.8 88.9 100.0
Implicit Annodis pairs ? V
2
R
(any relation)
56.9 52.1 54.2 31.7 67.3 58.8 66.7 62.5
Implicit Annodis triples ?
V
2
R (with correct relation)
17.7 24.7 40.3 31.7 0.0 19.6 11.1 0.0
TABLE 5 ? Coverage of verb pairs in V
2
R with respect to EDU pairs in the Annodis corpus containing
two verbs. Except for the first line, all numbers are percentages. Pair = verb pairs in the EDUs linked
by a rhetorical relation R, Triple=verb pair associated with a relation R in V
2
R, BG = Background,
cont.=continuation, elab.=elaboration.
Our table includes : the proportion of verb pairs found in Annodis EDUs that appear in V
2
R, the
proportion of triples from Annodis that appear in V
2
R (with the correct relation), and the restriction
of these proportions to implicit contexts in Annodis. Except for a few exceptions due to lemmatisation
errors, all verbs in Annodis are in V
2
R in at least one pair, and we can see that the pairs in V
2
R cover
most of the pairs appearing in Annodis (almost 70% globally and between 60 and 80% depending on the
relation), and a little less of implicit cases (around 55% on average). We note that a high proportion of the
implicit cases contains verb pairs that have been collected in a marked context, even for rarely marked
relations like elaboration or continuation?contexts with these relations are the majority in Annodis.
Furthermore more than half of these contexts are associated with the right relation in V
2
R. Thus the
hypothesis of the partial redundancy of connectors appears useful when isolating verbal associations
relevant for discourse from a large corpus. We also looked at semantic neighbors of the verbs in V
2
R but
this did not increase coverage significantly.
A good test of the predictive power of the semantic information we gathered is also to include the
association measures as additional features to a predictive model, to improve classically low results
on implicit discourse relations. The only available discursive corpus in French, Annodis, is small, and
as shown above only about 400 instances have a verb in both related EDUs. We trained and tested
a maximum entropy model with and without the association measures as features, on top of features
presented in Muller et al. (2012), who trained a relation model on the same corpus. We did a 10-fold
cross-validation on the 400 instance subset as evaluation, and did not find a significant difference between
the two set-ups (F1 score was in the range .40?.42, similar to the cited paper), which is unsurprising
2190
given the size of the subset. We plan to evaluate our method relative to discourse parsing by building an
English resource like V
2
R ; we will then be able to use the much larger PDTB corpus (10 times as large
as Annodis) as a source of implicit discourse relations. This should prove a much more telling evaluation
of the usefulness of association measures in predicting implicit discourse relations.
5 Related work
There are two different groups of related work. The first group aims to alleviate the lack of annotated
data for discourse parsing by using a weakly supervised approach, exploiting the presence of discourse
connectors in a large non-annotated corpus. Each pair of elementary discourse units is automatically
annotated with the discourse relation triggered by the presence of the connector (connectors are often
filtered for non-discursive uses). Those connectors are afterwards eliminated from the corpus so that the
model trained on this dataset will not be informed by the presence of those connectors. The pioneering
article in this group is Marcu and Echihabi (2002). Such learning methods with such ?artificial data?
obtain low scores, barely above chance as shown in Sporleder and Lascarides (2008). Braud and Denis
(2013) observe that the performance of a classifier for the prediction of implicit relations is much lower
when using ?artificial? data than on ?natural? data (implicit relations annotated by a human being). They
propose a method which exploits these two different kinds of datasets together in various mixtures and
on the level of the prediction algorithm, obtaining thus a significant improvement on the Annodis corpus.
Our approach is different and complementary ; we isolate the semantic relations between pairs of verbs.
We can use that as a feature on discourse units for discourse parsing but it has other uses as well.
A second group aims at identifying discourse relations (implicit or not) by focusing on the use of fine-
grained lexical relations as another feature during the training phase. Most of this work focuses mainly
on the use of lexical relations between two verbs. Chklovski and Pantel (2004), for example, rely on
specific patterns constructed manually for each semantic relation between (similarity, strength, antonymy,
enablement and temporal happens-before). They use the web as a corpus in order to estimate the PMI
between a pattern and a pair of verbs (a precise measurement cannot be achieved over the web since the
probability of a pattern is not precisely known over all the web). A threshold on the value of the PMI
(manually fixed) permits thus to determine the pairs of verbs that are related to the relation denoted by the
pattern. In the same spirit, Kozareva (2012) is using a weakly supervised approach for the extraction of
pairs of verbs that are potentially implied in a cause-effect relation. Her method consists in using patterns
applied to the web in order to extract pairs and generate new seeds. Do et al. (2011) focus on causal
relations and take into account not only verbs but also event denoting nouns. According to this paper,
an event is denoted by a predicate with a specific number of arguments and thus the association of the
events is the sum of the association between predicates, between predicates and arguments and between
arguments. Their association measures are based on PMI and are quite complex. Our results show that
their measures do not generalize well to association with all discourse relations. Using Gigaword as a
corpus and a reimplementation of Lin et al. (2014) they have extracted discourse relations. An inductive
logic programming approach is finally used exploiting the interaction between causal pairs and discourse
relations in order to extract causal links. Those papers focus on specific relations with the exception of
Chklovski and Pantel (2004) who do not present a systematic evaluation of their results. An important
difference of our approach is also to consider predicates and their negation as separate entries.
Finally, we mention the approaches which while focusing on the learning of discourse structures,
nonetheless enrich their systems with lexical information. Feng and Hirst (2012) have used HILDA (Her-
nault et al., 2010) adding more features. A specific family of features represents lexical similarity based
on the hierarchical distance in VERBNET and WORDNET. In a similar fashion, Wellner et al. (2006) fo-
cus on intra-sentential discourse relations adding lexical information on the features based on measures
proposed by Lin (1998) calculated on the British National Corpus. Those approaches use thus only infor-
mation on lexical similarity without semantically typing this link. The impact of this information seems
limited. As far as evaluation is concerned, our method is similar to that followed in Tremper and Frank
(2013) for implication relations combining in and out of context evaluation for verbal associations. Their
inter-annotator agreement is similar to ours (0.42-0.44 of Kappa) with very different choices : the anno-
2191
tators were supposed to discriminate verbal links between the different possible sub-cases. The pairs of
verbs were identified by the system of Lin and Pantel. These authors also present a classification model
among the different types of relationships, assuming that two verbs are semantically related.
6 Conclusions
We have presented a knowledge base of triples involving pairs of verbs associated with semantic or
discourse relations. We extracted these triples from the large French corpus, frWaC, using discourse con-
nectors as markers of relations between two adjacent clauses containing verbs. We investigated several
measures to give the strength of association of a pair of verbs with a relation. We used manual annotations
to evaluate our method and select the best measures, and we also studied the coverage of our resource on
the discourse annotated corpus Annodis. Our positive results show our resource has the potential to help
discourse analysis as well as other semantically oriented tasks.
2192
References
Stergos Afantenos, Nicholas Asher, Farah Benamara, Myriam Bras, Cecile Fabre, Mai Ho-Dac, Anne Le Draoulec,
Philippe Muller, Marie-Paul Pery-Woodley, Laurent Prevot, Josette Rebeyrolles, Ludovic Tanguy, Marianne
Vergez-Couret, and Laure Vieu. 2012. An empirical resource for discovering cognitive principles of discourse
organisation : the ANNODIS corpus. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U?gur
Do?gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight
International Conference on Language Resources and Evaluation (LREC?12), Istanbul, Turkey, may. European
Language Resources Association (ELRA).
Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Studies in Natural Language Processing.
Cambridge University Press, Cambridge, UK.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of
the COLING-ACL, Montreal, Canada.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The wacky wide web : a collection
of very large linguistically processed web-crawled corpora. Language resources and evaluation, 43(3) :209?
226.
Chlo? Braud and Pascal Denis. 2013. Identification automatique des relations discursives "implicites" ? partir
de donn?es annot?es et de corpus bruts. In TALN - 20?me conf?rence du Traitement Automatique du Langage
Naturel 2013, volume 1, pages 104?117, Sables d?Olonne, France, June.
Marie Candito, Beno?t Crabb?, and Pascal Denis. 2010. Statistical french dependency parsing : Treebank conver-
sion and first results. In LREC.
Jean Carletta. 1996. Assessing agreement on classification tasks : the kappa statistic. Computational linguistics,
22(2) :249?254.
Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised Learning of Narrative Event Chains. In Proceedings
of ACL-08 : HLT, pages 789?797, Columbus, Ohio, June. Association for Computational Linguistics, Morris-
town, NJ, USA.
Timothy Chklovski and Patrick Pantel. 2004. Verbocean : Mining the web for fine-grained semantic verb relations.
In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 33?40, Barcelona, Spain, July.
Association for Computational Linguistics.
P. Denis and B. Sagot. 2012. Coupling an annotated corpus and a lexicon for state-of-the-art pos tagging. Lan-
guage Resources and Evaluation, (46) :721?736.
Quang Do, Yee Seng Chan, and Dan Roth. 2011. Minimally supervised event causality identification. In Proceed-
ings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 294?303, Edinburgh,
Scotland, UK., July. Association for Computational Linguistics.
Stefan Evert. 2005. The statistics of word cooccurrences. Ph.D. thesis, Stuttgart University.
C. Felbaum. 1998. Wordnet, an Electronic Lexical Database for English. Cambridge : MIT Press.
Vanessa Wei Feng and Graeme Hirst. 2012. Text-level discourse parsing with rich linguistic features. In Proceed-
ings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1 : Long Papers),
pages 60?68, Jeju Island, Korea, July. Association for Computational Linguistics.
G. Grefenstette. 1994. Explorations in automatic thesaurus discovery. Springer.
Chikara Hashimoto, Kentaro Torisawa, Kow Kuroda, Stijn De Saeger, Masaki Murata, and Jun?ichi Kazama. 2009.
Large-scale verb entailment acquisition from the Web. In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages 1172?1181, Singapore, August. Association for Computational
Linguistics.
Hugo Hernault, Helmut Prendinger, David A. duVerle, and Mitsuru Ishizuka. 2010. HILDA : A Discourse Parser
Using Support Vector Machine Classification. Dialogue and Discourse, 1(3) :1?33.
Zornitsa Kozareva. 2012. Cause-effect relation learning. In Workshop Proceedings of TextGraphs-7 : Graph-
based Methods for Natural Language Processing, pages 39?43, Jeju, Republic of Korea, July. Association for
Computational Linguistics.
Dekang Lin and Patrick Pantel. 2002. Concept discovery from text. In Proceedings of Coling 2002, pages 1?7.
Association for Computational Linguistics.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014. A PDTB-styled end-to-end discourse parser. Natural
Language Engineering, 20(2) :151?184.
Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 36th ACL and 17th
COLING joint conference, volume 2, pages 768?774, Montreal.
Maofu Liu, Wenjie Li, Mingli Wu, and Qin Lu. 2007. Extractive summarization based on event term clustering. In
Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume
Proceedings of the Demo and Poster Sessions, pages 185?188, Prague, Czech Republic, June. Association for
Computational Linguistics.
2193
Daniel Marcu and Abdessamad Echihabi. 2002. An Unsupervised Approach to Recognizing Discourse Relations.
In Proceedings of ACL, pages 368?375.
Seyed Abolghasem Mirroshandel, Alexis Nasr, and Beno?t Sagot. 2013. Enforcing subcategorization constraints in
a parser using sub-parses recombining. In Proceedings of the 2013 Conference of the North American Chapter
of the Association for Computational Linguistics : Human Language Technologies, pages 239?247, Atlanta,
Georgia, June. Association for Computational Linguistics.
Philippe Muller, Stergos Afantenos, Pascal Denis, and Nicholas Asher. 2012. Constrained decoding for text-
level discourse parsing. In Proceedings of COLING 2012, pages 1883?1900, Mumbai, India, December. The
COLING 2012 Organizing Committee.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G?lsen Eryigit, Sandra K?bler, Svetoslav Marinov, and
Erwin Marsi. 2007. Maltparser : A language-independent system for data-driven dependency parsing. Natural
Language Engineering, 13(2) :95?135.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie L. Webber.
2008. The Penn Discourse TreeBank 2.0. In Proceedings of LREC 2008.
Charlotte Roze, Laurence Danlos, and Philippe Muller. 2012. Lexconn : A french lexicon of discourse connectives.
Discours, (10).
Beno?t Sagot. 2010. The lefff, a freely available and large-coverage morphological and syntactic lexicon for
french. In 7th international conference on Language Resources and Evaluation (LREC 2010).
Caroline Sporleder and Alex Lascarides. 2008. Using Automatically Labelled Examples to Classify Rhetorical
Relations : An Assessment. Natural Language Engineering, 14(3) :369?416, July.
Galina Tremper and Anette Frank. 2013. A discriminative analysis of fine-grained semantic relations including
presupposition : Annotation and classification. Dialogue & Discourse, 4(2) :282?322.
Naushad UzZaman, Hector Llorens, Leon Derczynski, James Allen, Marc Verhagen, and James Pustejovsky. 2013.
Semeval-2013 task 1 : Tempeval-3 : Evaluating time expressions, events, and temporal relations. In Second
Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2 : Proceedings of the Seventh
International Workshop on Semantic Evaluation (SemEval 2013), pages 1?9, Atlanta, Georgia, USA, June.
Association for Computational Linguistics.
K. Van Den Eynde and P. Mertens, 2010. Le dictionnaire de valence : Dicovalence. Leuven : Universit? de
Leuven. [http ://bach. arts. kuleuven. be/dicovalence/].
Ben Wellner, James Pustejovsky, Catherine Havasi, Anna Rumshisky, and Roser Saur?. 2006. Classification of
discourse coherence relations : an exploratory study using multiple knowledge sources. In Proceedings of
the 7th SIGdial Workshop on Discourse and Dialogue, SigDIAL ?06, pages 117?125, Stroudsburg, PA, USA.
Association for Computational Linguistics.
2194
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 98?102, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
MELODI: Semantic Similarity of Words and Compositional Phrases
using Latent Vector Weighting
Tim Van de Cruys
IRIT, CNRS
tim.vandecruys@irit.fr
Stergos Afantenos
IRIT, Toulouse University
stergos.afantenos@irit.fr
Philippe Muller
IRIT, Toulouse University
philippe.muller@irit.fr
Abstract
In this paper we present our system for the
SemEval 2013 Task 5a on semantic similar-
ity of words and compositional phrases. Our
system uses a dependency-based vector space
model, in combination with a technique called
latent vector weighting. The system computes
the similarity between a particular noun in-
stance and the head noun of a particular noun
phrase, which was weighted according to the
semantics of the modifier. The system is en-
tirely unsupervised; one single parameter, the
similarity threshold, was tuned using the train-
ing data.
1 Introduction
In the course of the last two decades, vector space
models have gained considerable momentum for se-
mantic processing. Initially, these models only dealt
with individual words, ignoring the context in which
these words appear. More recently, two different but
related approaches emerged that take into account
the interaction between different words within a par-
ticular context. The first approach aims at building a
joint, compositional representation for larger units
beyond the individual word level (e.g., the com-
posed, semantic representation of the noun phrase
crispy chips). The second approach, different but re-
lated to the first one, computes the specific meaning
of a word within a particular context (e.g. the mean-
ing of the noun bank in the context of the adjective
bankrupt).
In this paper, we describe our system for the Sem-
Eval 2013 Task 5a: semantic similarity of words and
compositional phrases ? which follows the latter ap-
proach. Our system uses a dependency-based vector
space model, in combination with a technique called
latent vector weighting (Van de Cruys et al, 2011).
The system computes the similarity between a par-
ticular noun instance and the head noun of a par-
ticular noun phrase, which was weighted according
to the semantics of the modifier. The system is en-
tirely unsupervised; one single parameter, the simi-
larity threshold, was tuned using the training data.
2 Related work
In recent years, a number of methods have been de-
veloped that try to capture the compositional mean-
ing of units beyond the individual word level within
a distributional framework. One of the first ap-
proaches to tackle compositional phenomena in a
systematic way is Mitchell and Lapata?s (2008) ap-
proach. They explore a number of different mod-
els for vector composition, of which vector addition
(the sum of each feature) and vector multiplication
(the elementwise multiplication of each feature) are
the most important. Baroni and Zamparelli (2010)
present a method for the composition of adjectives
and nouns. In their model, an adjective is a linear
function of one vector (the noun vector) to another
vector (the vector for the adjective-noun pair). The
linear transformation for a particular adjective is rep-
resented by a matrix, and is learned automatically
from a corpus, using partial least-squares regression.
Coecke et al (2010) present an abstract theoretical
framework in which a sentence vector is a function
of the Kronecker product of its word vectors, which
allows for greater interaction between the different
98
word features. And Socher et al (2012) present a
model for compositionality based on recursive neu-
ral networks.
Closely related to the work on compositionality
is research on the computation of word meaning in
context. Erk and Pado? (2008, 2009) make use of
selectional preferences to express the meaning of
a word in context. And Dinu and Lapata (2010)
propose a probabilistic framework that models the
meaning of words as a probability distribution over
latent factors. This allows them to model contex-
tualized meaning as a change in the original sense
distribution.
Our work takes the latter approach of computing
word meaning in context, and is described in detail
below.
3 Methodology
Our method uses latent vector weighting (Van de
Cruys et al, 2011) in order to compute a se-
mantic representation for the meaning of a word
within a particular context. The method relies
upon a factorization model in which words, together
with their window-based context features and their
dependency-based context features, are linked to la-
tent dimensions. The factorization model allows us
to determine which dimensions are important for a
particular context, and adapt the dependency-based
feature vector of the word accordingly. The mod-
ified feature vector is then compared to the target
noun feature vector with the cosine similarity func-
tion.
This following sections describe our model in
more detail. In section 3.1, we describe non-
negative matrix factorization ? the factorization
technique that our model uses. Section 3.2 describes
our way of combining dependency-based context
features and window-based context features within
the same factorization model. Section 3.3, then, de-
scribes our method of computing the meaning of a
word within a particular context.
3.1 Non-negative Matrix Factorization
Our latent model uses a factorization technique
called non-negative matrix factorization (Lee and
Seung, 2000) in order to find latent dimensions. The
key idea is that a non-negative matrix A is factorized
into two other non-negative matrices, W and H
Ai? j ?Wi?kHk? j (1)
where k is much smaller than i, j so that both in-
stances and features are expressed in terms of a few
components. Non-negative matrix factorization en-
forces the constraint that all three matrices must be
non-negative, so all elements must be greater than or
equal to zero.
Using the minimization of the Kullback-Leibler
divergence as an objective function, we want to find
the matrices W and H for which the divergence
between A and WH (the multiplication of W and
H) is the smallest. This factorization is carried
out through the iterative application of update rules.
Matrices W and H are randomly initialized, and the
rules in 2 and 3 are iteratively applied ? alternating
between them. In each iteration, each vector is ade-
quately normalized, so that all dimension values sum
to 1.
Ha? ?Ha?
?i Wia
Ai?
(WH)i?
?k Wka
(2)
Wia?Wia
?? Ha?
Ai?
(WH)i?
?v Hav
(3)
3.2 Combining syntax and context words
Using an extension of non-negative matrix fac-
torization (Van de Cruys, 2008), it is possible
to jointly induce latent factors for three different
modes: nouns, their window-based context words,
and their dependency-based context features. The
intuition is that the window-based context words
inform us about broad, topical similarity, whereas
the dependency-based features get at a tighter,
synonym-like similarity. As input to the algo-
rithm, two matrices are constructed that capture the
pairwise co-occurrence frequencies for the different
modes. The first matrix contains co-occurrence fre-
quencies of words cross-classified by dependency-
based features, and the second matrix contains co-
occurrence frequencies of words cross-classified by
words that appear in the word?s context window.
NMF is then applied to the two matrices, and the
separate factorizations are interleaved (i.e. matrix
W, which contains the nouns by latent dimensions,
99
is shared between both factorizations). A graphical
representation of the interleaved factorization algo-
rithm is given in figure 1. The numbered arrows in-
dicate the sequence of the updates.
= W=
U
I
V
K
I
Anouns xdependencies
Bnouns xcontext wordsI
HK U
3
21
4 GK V
Figure 1: A graphical representation of the interleaved
NMF
When the factorization is finished, the three dif-
ferent modes (words, window-based context words
and dependency-based context features) are all rep-
resented according to a limited number of latent fac-
tors.
The factorization that comes out of the NMF
model can be interpreted probabilistically (Gaussier
and Goutte, 2005; Ding et al, 2008). More specifi-
cally, we can transform the factorization into a stan-
dard latent variable model of the form
p(wi,d j) =
K
?
z=1
p(z)p(wi|z)p(d j|z) (4)
by introducing two K?K diagonal scaling matrices
X and Y, such that Xkk = ?i Wik and Ykk = ? j Hk j.
The factorization WH can then be rewritten as
WH = (WX?1X)(YY?1H)
= (WX?1)(XY)(Y?1H)
(5)
such that WX?1 represents p(wi|z), (Y?1H)T rep-
resents p(d j|z), and XY represents p(z). Using
Bayes? theorem, it is now straightforward to deter-
mine p(z|d j).
p(z|d j) =
p(d j|z)p(z)
p(d j)
(6)
3.3 Meaning in Context
3.3.1 Overview
Using the results of the factorization model de-
scribed above, we can now adapt a word?s feature
vector according to the context in which it appears.
Intuitively, the context of the word (in our case,
the dependency-based context feature that acts as an
adjectival modifier to the head noun) pinpoint the
important semantic dimensions of the particular in-
stance, creating a probability distribution over latent
factors. The required probability vector, p(z|d j), is
yielded by our factorization model. This probabil-
ity distribution over latent factors can be interpreted
as a semantic fingerprint of the passage in which the
target word appears. Using this fingerprint, we can
now determine a new probability distribution over
dependency features given the context.
p(d|d j) = p(z|d j)p(d|z) (7)
The last step is to weight the original probability
vector of the word according to the probability vec-
tor of the dependency features given the word?s con-
text, by taking the pointwise multiplication of prob-
ability vectors p(d|wi) and p(d|d j).
p(d|wi,d j) = p(d|wi) ? p(d|d j) (8)
Note that this final step is a crucial one in our
approach. We do not just build a model based on
latent factors, but we use the latent factors to de-
termine which of the features in the original word
vector are the salient ones given a particular context.
This allows us to compute an accurate adaptation of
the original word vector in context.
3.3.2 Example
Let us exemplify the procedure with an example.
Say we want to compute the distributionally similar
words to the noun instrument within the phrases (1)
and (2), taken from the task?s test set:
(1) musical instrument
(2) optical instrument
First, we extract the context feature for both in-
stances, in this case C1 = {musicalad j} for phrase
(1), and C2 = {opticalad j} for phrase (2). Next, we
100
look up p(z|C1) and p(z|C2) ? the probability distri-
butions over latent factors given the context ? which
are yielded by our factorization model. Using these
probability distributions over latent factors, we can
now determine the probability of each dependency
feature given the different contexts ? p(d|C1) and
p(d|C2) (equation 7).
The former step yields a general probability dis-
tribution over dependency features that tells us how
likely a particular dependency feature is given the
context that our target word appears in. Our last step
is now to weight the original probability vector of
the target word (the aggregate of dependency-based
context features over all contexts of the target word)
according to the new distribution given the context
in which the target word appears (equation 8).
We can now return to our original matrix A and
compute the top similar words for the two adapted
vectors of instrument given the different contexts,
which yields the results presented below.
1. instrumentN , C1: percussion, flute, violin,
melody, harp
2. instrumentN , C2: sensor, detector, amplifier,
device, microscope
3.4 Implementational details
Our model has been trained on the UKWaC cor-
pus (Baroni et al, 2009). The corpus has been
part of speech tagged and lemmatized with Stan-
ford Part-Of-Speech Tagger (Toutanova and Man-
ning, 2000; Toutanova et al, 2003), and parsed with
MaltParser (Nivre et al, 2006) trained on sections
2-21 of the Wall Street Journal section of the Penn
Treebank extended with about 4000 questions from
the QuestionBank1, so that dependency triples could
be extracted.
The matrices needed for our interleaved NMF fac-
torization are extracted from the corpus. Our model
was built using 5K nouns, 80K dependency relations,
and 2K context words2 (excluding stop words) with
highest frequency in the training set, which yields
matrices of 5K nouns ? 80K dependency relations,
and 5K nouns ? 2K context words.
1http://maltparser.org/mco/english_parser/
engmalt.html
2We used a fairly large, paragraph-like window of four sen-
tences.
model accuracy precision recall F1
dist .69 .83 .48 .61
lvw .75 .84 .61 .71
Table 1: Results of the distributional model (dist) and la-
tent vector weighting model (lvw) on the SemEval task
5a
The interleaved NMF model was carried out using
K = 600 (the number of factorized dimensions in the
model), and applying 100 iterations. The interleaved
NMF algorithm was implemented in Matlab; the pre-
processing scripts and scripts for vector computation
in context were written in Python.
The model is entirely unsupervised. The only pa-
rameter to set, the cosine similarity threshold ? , is
induced from the training set. We set ? = .049.
4 Results
Table 1 shows the evaluation results of the simple
distributional model (which only takes into account
the head noun) and our model that uses latent vector
weighting. The results indicate that our model based
on latent vector weighting performs quite a bit bet-
ter than a standard dependency-based distributional
model. The lvw model attains an accuracy of .75 ?
a 6% improvement over the distributional model ?
and an F-measure of .71 ? a 10% improvement over
the distributional model.
5 Conclusion
In this paper we presented an entirely unsuper-
vised system for the assessment of the similarity of
words and compositional phrases. Our system uses a
dependency-based vector space model, in combina-
tion with latent vector weighting. The system com-
putes the similarity between a particular noun in-
stance and the head noun of a particular noun phrase,
which was weighted according to the semantics of
the modifier. Using our system yields a substantial
improvement over a simple dependency-based dis-
tributional model, which only takes the head noun
into account.
101
References
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1183?1193, Cambridge, MA, October. Association for
Computational Linguistics.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The wacky wide web: A
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209?226.
Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen Clark.
2010. Mathematical foundations for a compositional
distributed model of meaning. Lambek Festschrift,
Linguistic Analysis, vol. 36, 36.
Chris Ding, Tao Li, and Wei Peng. 2008. On the equiv-
alence between non-negative matrix factorization and
probabilistic latent semantic indexing. Computational
Statistics & Data Analysis, 52(8):3913?3927.
Georgiana Dinu and Mirella Lapata. 2010. Measuring
distributional similarity in context. In Proceedings of
the 2010 Conference on Empirical Methods in Natural
Language Processing, pages 1162?1172, Cambridge,
MA, October.
Katrin Erk and Sebastian Pado?. 2008. A structured
vector space model for word meaning in context. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 897?906,
Waikiki, Hawaii, USA.
Katrin Erk and Sebastian Pado?. 2009. Paraphrase as-
sessment in structured vector space: Exploring param-
eters and datasets. In Proceedings of the Workshop on
Geometrical Models of Natural Language Semantics,
pages 57?65, Athens, Greece.
Eric Gaussier and Cyril Goutte. 2005. Relation between
PLSA and NMF and implications. In Proceedings of
the 28th annual international ACM SIGIR conference
on Research and development in information retrieval,
pages 601?602, Salvador, Brazil.
Daniel D. Lee and H. Sebastian Seung. 2000. Algo-
rithms for non-negative matrix factorization. In Ad-
vances in Neural Information Processing Systems 13,
pages 556?562.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. proceedings of ACL-
08: HLT, pages 236?244.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006. Malt-
parser: A data-driven parser-generator for dependency
parsing. In Proceedings of LREC-2006, pages 2216?
2219.
Richard Socher, Brody Huval, Christopher D. Manning,
and Andrew Y. Ng. 2012. Semantic compositional-
ity through recursive matrix-vector spaces. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1201?
1211, Jeju Island, Korea, July. Association for Com-
putational Linguistics.
Kristina Toutanova and Christopher D. Manning. 2000.
Enriching the knowledge sources used in a maximum
entropy part-of-speech tagger. In Proceedings of the
Joint SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Corpora
(EMNLP/VLC-2000), pages 63?70.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of HLT-NAACL 2003, pages 252?259.
Tim Van de Cruys, Thierry Poibeau, and Anna Korho-
nen. 2011. Latent vector weighting for word meaning
in context. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing,
pages 1012?1022, Edinburgh, Scotland, UK., July. As-
sociation for Computational Linguistics.
Tim Van de Cruys. 2008. Using three way data for word
sense discrimination. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics
(Coling 2008), pages 929?936, Manchester.
102
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 144?147, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
MELODI: A Supervised Distributional Approach
for Free Paraphrasing of Noun Compounds
Tim Van de Cruys
IRIT, CNRS
tim.vandecruys@irit.fr
Stergos Afantenos
IRIT, Toulouse University
stergos.afantenos@irit.fr
Philippe Muller
IRIT, Toulouse University
philippe.muller@irit.fr
Abstract
This paper describes the system submitted
by the MELODI team for the SemEval-2013
Task 4: Free Paraphrases of Noun Compounds
(Hendrickx et al, 2013). Our approach com-
bines the strength of an unsupervised distri-
butional word space model with a supervised
maximum-entropy classification model; the
distributional model yields a feature represen-
tation for a particular compound noun, which
is subsequently used by the classifier to induce
a number of appropriate paraphrases.
1 Introduction
Interpretation of noun compounds is making explicit
the relation between the component nouns, for in-
stance that running shoes are shoes used in running
activities, while leather shoes are made from leather.
The relations can have very different meanings, and
existing work either postulates a fixed set of rela-
tions (Tratz and Hovy, 2010) or relies on appropri-
ate descriptions of the relations, through constrained
verbal paraphrases (Butnariu et al, 2010) or uncon-
strained paraphrases as in the present campaign. The
latter is much simpler for annotation purposes, but
raises difficult challenges involving not only com-
pound interpretation but also paraphrase evaluation
and ranking.
In terms of constrained verbal paraphrases
Wubben (2010), for example, uses a supervised
memory-based ranker using features from the
Google n-gram corpus as well as WordNet. Nulty
and Costello (2010) rank paraphrases of compounds
according to the number of times they co-occurred
with other paraphrases for other compounds. They
use these co-occurrences to compute conditional
probabilities estimating is-a relations between para-
phrases. Li et al (2010) provide a hybrid sys-
tem which combines a Bayesian algorithm exploit-
ing Google n-grams, a score which captures human
preferences at the tail distribution of the training
data, as well as a metric that captures pairwise para-
phrase preferences.
Our methodology consists of two steps. First,
an unsupervised distributional word space model is
constructed, which yields a feature representation
for a particular compound. The feature representa-
tion is then used by a maximum entropy classifier to
induce a number of appropriate paraphrases.
2 Methodology
2.1 Distributional word space model
In order to induce appropriate feature representa-
tions for the various noun compounds, we start by
constructing a standard distributional word space
model for nouns. We construct a co-occurrence
matrix of the 5K most frequent nouns1 by the 2K
most frequent context words2, which occur in a win-
dow of 5 words to the left and right of the target
word. The bare frequencies of the word-context ma-
trix are weighted using pointwise mutual informa-
tion (Church and Hanks, 1990).
Next, we compute a joint, compositional repre-
sentation of the noun compound, combining the se-
1making sure all nouns that appear in the training and test
set are included
2excluding the 50 most frequent context words as stop words
144
mantics of the head noun with the modifier noun. To
do so, we make use of a simple vector-based multi-
plicative model of compositionality, as proposed by
Mitchell and Lapata (2008). In order to compute the
compositional representation of a compound noun,
this model takes the elementwise multiplication of
the vectors for the head noun and the modifier noun,
i.e.
pi = uivi
for each feature i. The resulting features are used as
input to our next classification step.
We compare the performance of the abovemen-
tioned compositional model with a simpler model
that only takes into account the semantics of the
head noun. This model only uses the context fea-
tures for the head noun as input to our second clas-
sification step. This means that the model only takes
into account the semantics of the head noun, and ig-
nores the semantics of the modifier noun.
2.2 Maximum entropy classification
The second step of our paraphrasing system consists
of a supervised maximum entropy classification ap-
proach. Training vectors for each noun compound
from the training set are constructed according to
the approach described in the previous section. The
(non-zero) context features yielded by the first step
are used as input for the maximum entropy classi-
fier, together with the appropriate paraphrase labels
and the label counts (used to weight the instances),
which are extracted from the training set.
We then deploy the model in order to induce a
probability distribution over the various paraphrase
labels. Every paraphrase label above a threshold ? is
considered an appropriate paraphrase. Using a por-
tion of held-out training data (20%), we set ? = 0.01
for our official submission. In this paper, we show a
number of results using different thresholds.
2.3 Set of paraphrases labels
For our classification approach to work, we need to
extract an appropriate set of paraphrase labels from
the training data. In order to create this set, we
substitute the nouns that appear in the training set?s
paraphrases by dummy variables. Table 1 gives an
example of three different paraphrases and the re-
sulting paraphrase labels after substitution. Note
that we did not apply any NLP techniques to prop-
erly deal with inflected words.
We apply a frequency threshold of 2 (counted over
all the instances), so we discard paraphrase labels
that appear only once in the training set. This gives
us a total of 285 possible paraphrase labels.
One possible disadvantage of this supervised ap-
proach is a loss of recall on unseen paraphrases. A
rough estimation shows that our set of training labels
accounts for only 25% of the similarly constructed
labels extracted from the test set. However, the most
frequently used paraphrase labels are present in both
training and test set, so this does not prevent our
system to come up with a number of suitable para-
phrases for the test set.
2.4 Implementational details
All frequency co-occurrence information has been
extracted from the ukWaC corpus (Baroni et al,
2009). The corpus has been part of speech tagged
and lemmatized with Stanford Part-Of-Speech Tag-
ger (Toutanova and Manning, 2000; Toutanova et
al., 2003). Distributional word space algorithms
have been implemented in Python. The maximum
entropy classifier was implemented using the Maxi-
mum Entropy Modeling Toolkit for Python and C++
(Le, 2004).
3 Results
Table 2 shows the results of the different systems in
terms of the isomorphic and non-isomorphic evalu-
ation measures defined by the task organizers (Hen-
drickx et al, 2013). For comparison, we include a
number of baselines. The first baseline assigns the
two most frequent paraphrase labels (Y of X, Y for
X) to each test instance; the second baseline assigns
the four most frequent paraphrase labels (Y of X, Y
for X, Y on X, Y in X); and the third baseline assigns
all of the possible 285 paraphrase labels as correct
answer for each test instance.
For both our primary system (the multiplicative
model) and our contrastive system (the head noun
model), we vary the threshold used to select the final
set of paraphrases. A threshold ? = 0.01 results in
a smaller set of paraphrases, whereas a threshold of
? = 0.001 results in a broad set of paraphrases. Our
official submission uses the former threshold.
145
compound paraphrase paraphrase label
textile company company that makes textiles Y that makes Xs
textile company company that produces textiles Y that produces Xs
textile company company in textile industry Y in X industry
Table 1: Example of induced paraphrase labels
model ? isomorphic non-isomorphic
baseline (2) ? .058 .808
baseline (4) ? .090 .633
baseline (all) ? .332 .200
multiplicative .01 .130 .548
.001 .270 .259
head noun .01 .136 .536
.001 .277 .302
Table 2: Results
First of all, we note that the different baseline
models are able to obtain substantial scores for the
different evaluation measures. The first two base-
lines, which use a limited number of paraphrase
labels, perform very well in terms of the non-
isomorphic evaluation measure. The third baseline,
which uses a very large number of candidate para-
phrase labels, gets more balanced results in terms of
both the isomorphic and non-isomorphic measure.
Considering our different thresholds, the results
of our models are in line with the baseline re-
sults. A larger threshold, which results in a smaller
number of paraphrase labels, reaches a higher non-
isomorphic score. A smaller threshold, which re-
sults in a larger number of paraphrase labels, gives
more balanced results for the isomorphic and non-
isomorphic measure.
There does not seem to be a significant difference
between our primary system (multiplicative) and our
contrastive system (head noun). For ? = 0.01, the
results of both models are very similar; for ? =
0.001, the head noun model reaches slightly better
results, in particular for the non-isomorphic score.
Finally, we note that our models do not seem to
improve significantly on the baseline scores. For
? = 0.001, the results of our models seem somewhat
more balanced compared to the all baseline, but the
differences are not very large. In general, our sys-
tems (in line with the other systems participating in
the task) seem to have a hard time beating a num-
ber of simple baselines, in terms of the evaluation
measures defined by the task.
4 Conclusion
We have presented a system for producing free para-
phrases of noun compounds. Our methodology con-
sists of two steps. First, an unsupervised distribu-
tional word space model is constructed, which is
used to compute a feature representation for a par-
ticular compound. The feature representation is then
used by a maximum entropy classifier to induce a
number of appropriate paraphrases.
Although our models do seem to yield slightly
more balanced scores than the baseline models, the
differences are not very large. Moreover, there is
no substantial difference between our primary mul-
tiplicative model, which takes into account the se-
mantics of both head and modifier noun, and our
contrastive model, which only uses the semantics of
the head noun.
References
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The wacky wide web: A
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209?226.
Cristina Butnariu, Su Nam Kim, Preslav Nakov, Diar-
muid O? Se?aghdha, Stan Szpakowicz, and Tony Veale.
2010. Semeval-2 task 9: The interpretation of noun
compounds using paraphrasing verbs and prepositions.
In Proceedings of the 5th International Workshop on
Semantic Evaluation, pages 39?44, Uppsala, Sweden,
July. Association for Computational Linguistics.
Kenneth W. Church and Patrick Hanks. 1990. Word as-
sociation norms, mutual information & lexicography.
Computational Linguistics, 16(1):22?29.
146
Iris Hendrickx, Zornitsa Kozareva, Preslav Nakov, Diar-
muid O? Se?aghdha, Stan Szpakowicz, and Tony Veale.
2013. SemEval-2013 task 4: Free paraphrases of noun
compounds. In Proceedings of the International Work-
shop on Semantic Evaluation, SemEval ?13, June.
Zhang Le. 2004. Maximum entropy modeling toolkit for
python and c++. http://homepages.inf.ed.ac.
uk/lzhang10/maxent_toolkit.html.
Guofu Li, Alejandra Lopez-Fernandez, and Tony Veale.
2010. Ucd-goggle: A hybrid system for noun com-
pound paraphrasing. In Proceedings of the 5th In-
ternational Workshop on Semantic Evaluation, pages
230?233, Uppsala, Sweden, July. Association for
Computational Linguistics.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. proceedings of ACL-
08: HLT, pages 236?244.
Paul Nulty and Fintan Costello. 2010. Ucd-pn: Select-
ing general paraphrases using conditional probability.
In Proceedings of the 5th International Workshop on
Semantic Evaluation, pages 234?237, Uppsala, Swe-
den, July. Association for Computational Linguistics.
Kristina Toutanova and Christopher D. Manning. 2000.
Enriching the knowledge sources used in a maximum
entropy part-of-speech tagger. In Proceedings of the
Joint SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Corpora
(EMNLP/VLC-2000), pages 63?70.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of HLT-NAACL 2003, pages 252?259.
Stephen Tratz and Eduard Hovy. 2010. A taxonomy,
dataset, and classifier for automatic noun compound
interpretation. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 678?687, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Sander Wubben. 2010. Uvt: Memory-based pairwise
ranking of paraphrasing verbs. In Proceedings of the
5th International Workshop on Semantic Evaluation,
pages 260?263, Uppsala, Sweden, July. Association
for Computational Linguistics.
147
Proceedings of the SIGDIAL 2013 Conference, pages 2?11,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Expressivity and comparison of models of discourse structure
Antoine Venant1 Nicholas Asher2 Philippe Muller1 Pascal Denis3 Stergos Afantenos1
(1) IRIT, Toulouse University, France, (2) IRIT, CNRS, France (3) Mostrare, INRIA, France ?
Abstract
Several discourse annotated corpora now ex-
ist for NLP. But they use different, not eas-
ily comparable annotation schemes: are the
structures these schemes describe incompati-
ble, incomparable, or do they share interpre-
tations? In this paper, we relate three types
of discourse annotation used in corpora or dis-
course parsing: (i) RST, (ii) SDRT, and (iii)
dependency tree structures. We offer a com-
mon language in which their structures can be
defined and furnished a range of interpreta-
tions. We define translations between RST and
DT preserving these interpretations, and intro-
duce a similarity measure for discourse repre-
sentations in these frameworks. This will en-
able researchers to exploit different types of
discourse annotated data for automated tasks.
1 Introduction
Computer scientists and linguists now largely agree
that representing discourse structure as a hierarchical
relational structure over discourse units linked by dis-
course relations is appropriate to account for a variety
of interpretative tasks. There is also some agreement
over the taxonomy of discourse relations ?almost all
current theories include expressions that refer to rela-
tions like Elaboration, Explanation, Result, Narration,
Contrast, Attribution. Sanders, Spooren, and Noord-
man 1992; Bateman and Rondhuis 1997 discuss corre-
spondences between different taxonomies.
Different theories, however, assume different sets of
constraints that govern these representations; some ad-
vocate trees: RST Mann and Thompson 1987, DLTAG
Webber et al 1999; others, graphs of different sorts:
SDRT Asher and Lascarides 2003, Graphbank Wolf
and Gibson 2005. Consider:
(1) [?he was a very aggressive firefighter.]C1 [he
loved the work he was in,?]C2 [said acting fire
chief Lary Garcia.]C3 . [?He couldn?t be bested
in terms of his willingness and his ability to do
something to help you survive.?]C4 (from Egg
and Redeker 2010)
Using RST, Egg and Redeker 2010 provide the tree an-
notated with nuclearity features for this example (given
by the linear encoding in (s1)), while SDRT provides
?This research was supported by ERC grant 269427.
a different kind of structure (s2). Dependency trees
(DTs), similar to syntactic dependency trees and used
in Muller et al 2012 for automated parsing, give yet an-
other representation (s3). Elab stands for elaboration,
Attr for attribution, and Cont for continuation.
Elab1(Attr(Elab2(C1N ,C2S )N ,C3S )N ,C4S ) (s1)
Attr(pi,C3) ? pi :Elab(C1, pi1) ? pi1 :Cont(C2,C4) (s2)
Elab1(C1,C2) ? Attr(C1,C3) ? Elab(C1,C4) (s3)
Several corpora now exist annotated with such struc-
tures: RSTTB Carlson, Marcu, and Okurowski 2002,
Discor Baldridge, Asher, and Hunter 2007, Graph-
Bank1. But how exactly do these annotations compare?
In the illustrative example chosen and for the relation
types they agree on (Elaboration and Attribution), dif-
ferent annotation models and theoretical frameworks
invoke different numbers of instances of these relations
and assign the instances different arguments or differ-
ent scopes, at least on the surface. In this paper we de-
velop a method of comparing the scopes of relations in
different types of structures by developing a notion of
interpretation shared between different structures. This
interpretation specifies the set of possible scopes of re-
lations compatible with a given structure. This theoret-
ical work is important for furthering empirical research
on discourse. Discourse annotations are expensive. It
behooves researchers to use as much data as they can,
annotated in several formalisms, while pursuing pre-
diction or evaluation in their chosen theory. This paper
provides a theoretical basis to do this.
What a given structure expresses exactly is often not
clear; some discourse theories are not completely for-
malized or lack a worked out semantics. Neverthe-
less, in all of them rhetorical relations have semantic
consequences bearing on tasks like text summarization,
textual entailment, anaphora resolution, as well as the
temporal, spatial and thematic organization of a text
Hobbs, Stickel, and Martin 1993; Kehler 2002; Asher
1993; Lascarides and Asher 1993; Hobbs, Stickel, and
Martin 1993; Hitzeman, Moens, and Grover 1995, inter
alia. Theories like SDRT or Polanyi et al 2004 adopt a
conception of discourse structure as logical form. Dis-
course structures are like logical formulae and relations
1The Penn Discourse Treebank Prasad et al 2008 could
also be considered as a corpus with partial dependency struc-
tures.
2
function like logical operators on the meaning of their
arguments. Hence their exact scope has great semantic
impact on the phenomena we have mentioned, in ex-
actly the way the relative scope of quantifiers make a
great semantic difference in first order logic. By con-
centrating on exact meaning representations, however,
the syntax-semantics interface becomes quite complex:
as happens with quantifiers at the intra sentential level,
discourse relations might semantically require a scope
that is, at least a priori, not determined by syntactic
considerations alone and violates surface order (see s2).
Other theories like Polanyi?s Linguistic Discourse
Model (LDM) of Polanyi 1985; Polanyi and Scha 1984,
and DLTAG Webber et al 1999 explicitly adopt a
syntactic point of view, and RST with strongly con-
strained (tree-shaped) structures is subject to parsing
approaches duVerle and Prendinger 2009; Sagae 2009;
Subba and Di Eugenio 2009 that adhere to the syntac-
tic approach in adopting decoding strategies of syntac-
tic parsing. In such theories, discourse structure repre-
sentations, subject to syntactic constraints (e.g. domi-
nance of spans of text one over another) respect surface
order but do not always and unproblematically yield a
semantic interpretation that fits intuitions. According
to Marcu 1996, an RST tree is not by itself sufficient to
generate desired predictions; he employs the nuclearity
principle, NP, as an additional interpretation principle
on scopes of relations.
We focus on two theories: RST, which offers the
model for the annotations of the RST treebank Carl-
son, Marcu, and Okurowski 2002 and the Potsdam
commentary corpus Stede 2004, and on SDRT, which
counts several small corpora annotated with semantic
scopes, Discor Baldridge, Asher, and Hunter 2007 and
Annodis Afantenos et al 2012. We describe these the-
ories in section 2. We will also compare these two the-
ories to dependency tree representations of discourse
Muller et al 2012. Section 3 introduces a language for
describing semantics scopes of relations that is power-
ful enough to: i) compare the expressiveness (in terms
of what different scopes can be expressed) of the dif-
ferent formalisms considered; ii) give a formal target
language that will provide comparable interpretations
of the different structures at stake. Section 4 discusses
Marcu?s nuclearity principle and proposes an alterna-
tive way to interpret an RST tree as a set of different
possible scopes expressed in our language. Section 5
provides intertranslability results between the different
formalisms. Section 6 defines a measure of similarity
over discourse structures in different formalisms.
2 Discourse formalisms
These formalisms we introduce here all require the in-
put text to be segmented into elementary units (EDUs).
The definition of what an EDU is varies slightly with
the formalism, but roughly corresponds to the clause
level in RST, SDRT and other theories. We assume a
segmentation common to the different formalisms and
use examples with a non controversial and intuitive
segmentation.
Rhetorical Structure Theory (RST), the theory un-
derlying the RST-Treebank is the most used corpus for
discourse parsing, cf. duVerle and Prendinger 2009,
Subba and Di Eugenio 2009, inter alia.
In its Mann and Thompson 1987 formulation, RST
builds a descriptive tree for the discourse by the recur-
sive application of schemata in a bottom-up procedure.
Each schema application ideally reflects the most plau-
sible relation the writer intended between two contigu-
ous spans of text, as well as hierarchical information
about the arguments of the relation, distinguishing be-
tween nuclei as essential arguments of a relation and
satellites as more contingent parts. The set of RS Trees
is inductively defined as follows:
1- An EDU is a RS Tree.
2- if R is a nucleus-statellite relation symbol, s1 and
s2 are both RS Trees with contiguous spans (the left-
most leaf in s2 is textually located right after the right-
most one in s1), and ?a1, a2? ? {?N, S ?; ?S ,N?} then
R(t1 a1, t2 a2) is an RS Tree.
3- if R is a multinuclear relation symbol and
?s1, . . . , sn? are n RS Trees with contiguous spans then
R(s1 N, . . . , sn N) is an RS Tree.
Following Mann and Thompson 1987 a complete RS
tree makes explicit the content the author intended to
communicate. RS Trees are graphically represented
Marcu 1996 with intermediate nodes labelled with re-
lation names, leaves with symbols referring to EDUs,
and edges with nucleus/satellite distinctions.
Segmented Discourse Representation Theory
(SDRT), our second case-study theory, inherits a
framework from dynamic semantics and enriches
it with rhetorical relations. The set of SDRSs is
inductively defined as follows:
Assume a set of rhetorical relations R, distinguished
between coordinating and subordinating relations.
- Any EDU is an SDRS.
- Any Complex Discourse Unit (CDU) is a SDRS.
- a CDU is an acyclic labelled graph (A, E) where
every node is a discourse unit (DU) or SDRS and each
labelled edge is a discourse relation such that:
(i) every node is connected to some other node;
(ii) no two nodes are linked by subordinating and co-
ordinating relations,
(iii) given EDUs a1, . . . , an+1 in their textual order
that yield a CDU (A, E) = G, each EDU a j+1 j < n is
linked either: (a) to nodes on the right frontier of the
CDU G? a subgraph of G constructed from a1, . . . , a j;
or (b) to one or more nodes in G? = (A?,G?), a subgraph
of G, which linked to one or more nodes on the right
frontier of the graph G?, and where G? is constructed
from a subset of a j+2, . . . an.
The right frontier of a graph G consists of the nodes
a that are not the left arguments to any coordinating
relation and for which if any node b is linked to some
node dominating a, then there is a path of subordinating
3
relations from b to a.
A Segmented Discourse Representation Structure
(SDRS), is assigned a recursively computed meaning
in terms of context-change potential (relation between
pairs of ? world, assignation function ?) in the tradi-
tion of dynamic semantics. The semantics of a complex
constituent is compositionally defined from the seman-
tics of rhetorical relations and the interpretation of its
subconstituents. In the base case of an EDU, the se-
mantics is given in dynamic semantics.
We also consider dependency trees (DTs). Muller
et al 2012 derive DTs from the SDRSs of the ANN-
ODIS corpus to get a reduced search space, simplify-
ing automated discourse parsing. A DT is an SDRS
in which there are no CDUs and there is a unique arc
between any two nodes. Muller et al 2012 provide
a procedure from SDRSs to DTs, which we slightly
modify to respect the Frontier Contraint that they use.
? works in a bottom-up fashion replacing every CDU
X that is an argument of a rhetorical relation in ? by
their top-most immediate sub-constituent which do not
appear on the right of any relation in X, or distributing
the top relation when necessary to preserve projectivity.
To give a simple example: ?(R([R?(a, [R??(b, c)])], d)) =
?(R([R?(a, b) ? R??(b, c)], d)) = R(a, d) ? R?(a, b) ?
R??(b, c). (1) provides a more complicated example we
discuss in Section 6).
3 Describing the scope of relations
We provide here a language expressive and general
enough to express the structures of the 3 theories. All
our case-study theories involve structures described by
a list of rhetorical relations and their arguments. Two
things may vary: first, the nature of the arguments.
SDRT for instance, introduces complex constituents
as arguments of relations (e.g.
{
pi : Rsubord(b, c)
Rsubord(a, pi) ),
which finds a counterpart within RS Trees, where a
relation may directly appear as argument of another
(R(aN ,R(bN , cS )S )) but not within dependency trees.
Second, the set of constraints that restrict the possi-
ble lists of such relations can vary across theories (e.g.
right frontier, or requirement for a tree structure).
To deal with the first point above, we remark that
it suffices to list, for each instance of a discourse rela-
tion, the set of elementary constituents that belong to its
left and right scope in order to express the three kinds
of structures. We do this in a way that an isomorphic
structure can always be recovered. Models of our com-
mon language will be a list of relation instances and el-
ementary constituents, together with a set of predicates
stating what is in the scope of what. As for the second
point, we axiomatize each constraint in our common
language, thereby describing each of the 3 types of dis-
course structures as a theory in our language.
Our language contains only binary relations. Among
discourse formalisms, only RST makes serious (and
empirical) use of n?ary discourse relations. Neverthe-
less, such RST structures are expressible in our frame-
work, if we assume certain semantic equivalences.
RST allows for two cases of non-binary trees: (i) nu-
cleus with n satellites, each one linked to the nucleus
by some relation Rn. Such a structure is semantically
equivalent to the conjunction of n-binary relations Rn
between the nucleus and the nth satellite, which is ex-
pressible in our framework. (ii) RST also allows for n-
ary multinuclear relations such as List and Sequence. In
our understanding, multinuclear relations R(a1, . . . an),
essentially serve a purpose of expressiveness, and such
an n-ary tree is an equivalent to the split non-tree
shaped structure R(a1, a2) ? R(a2, a3) . . .R(a(n?1), an).
This seems clear for the Sequence relation, which
states that a1 . . . an are in temporal sequence and can
be equivalently formulated as ?each ai precedes ai+1?.
This might appear less obvious for the List relation.
The semantics (as it appears on the RST website http:
//www.sfu.ca/rst/) of this relation requires the ai to
be ?comparable?, and as far as this is a transitive prop-
erty, we can split the relation into a set of binary ones.
Formally, our scope language Lscopes is a fragment of
that of monadic second order logic with two sorts of in-
dividuals: relation instances (i), and elementary consti-
tuants (l). Below, we assume R is the set of all relation
names (elaboration, narration, justification, . . . ).
Definition 1 (Scoping language). Let S be the set {i, l}.
The set of primitive, disjoint types of Lscopes consists of
i, l and t (type of formulae). For each of the types in
S , we have a countable set of variable symbols Vi (Vl).
Two additional countable sets of variable symbols V?i,t?
and V?l,t? range over sets of individuals. These four sets
of variable symbols are pairwise disjoint.
The alphabet of our language is constituted by Vi, Vs,
a set of predicates, equality, connector and quantifier
symbols. The set of predicate symbols is as follows:
1) For each relation symbol r in R, LR is a unary
predicate of type ?i, t??i.e., LR : ?i, t? .
2) unary predicates, sub, coord and sub?1 : ?i, t?.
3) binary predicates ?l and ?r : ?i, l, t?.
4) two equality relations, =s : ?s, s, t? for s ? {i, l}.
Logical connectors, and quantifiers are as usual.
The sets of terms ?i,?l and ?t are recursively defined:
1. Vi ? ?i, Varl ? ?l. 2. For v ? Vs,t, v : ?s, t?. 3. For
each symbol ? of type ?u1, . . . , un? in the alphabet, for
all (t1, . . . , tn?1) ? ?u1?? ? ???un?1, ?[t1, . . . , tn?1] ? ?un .
?t is the set of well formed formulae of the scope lan-
guage.
The predicates ?l and ?r take a relation instance r of
type i and a elementary constituent x of type l as argu-
ments. Intuitively, they mean that x has to be included
in the left (for ?l) or right (for ?r) scope of r. For each
relation symbol R such as justification or elaboration,
the predicate LR takes a relation instance r has argu-
ment and states that r is an instance of the rhetorical re-
lation R. Predicates sub, coord and sub?1 apply to a re-
lation instance r, respectively specifying that r?s left ar-
gument hierarchically dominate its right argument, that
4
both are of equal hierarchical importance, or that the
left one is subordinate to the right one.
Definition 2 (Scope structure and Interpretation).
A scope structure is an Lscopes-structure M =
?Di,Dl, |.|M?. Di and Dl are disjoint sets of individu-
als for the sorts i and l respectively, and |.|M assigns to
each predicate symbol P of type ?u1, . . . , un, t? a func-
tion |.|P : Du1?? ? ??Dun 7? {0, 1}. Variables of type ?i, t?
are assigned subsets of Di and similarly for variables of
type ?l, t?, The predicates =i and =s are interpreted as
equality over Di and Dl respectively.
The interpretation ~?Mv of a formula ? ? ?S is the
standard interpretation of a monadic second order for-
mula w.r.t to a model and a valuation (interpretation of
first order quantifiers and connectors is as usual, quan-
tification over sets is over all sets of individuals). Va-
lidity |= also follows the standard definition.
These scope structures offer a common framework
for different discourse formalisms. Given one of the
three formalisms, we say that two structures S 1 and S 2
are equivalent iff there is an encoding from one struc-
ture into a scoped structure or set of scoped structures
and a decoding back from the scoped structure or set of
scoped structures into S 2
Fact 1. One can define two algorithms I and E such
that:
? from a given structure s which is a RS Tree, a
SDRS or a DT, I computes a scope structure I(s).
? given such a computed structure, E allow to re-
trieve the original structure s (E(I(s)) = s).
RST Encoding and Decoding To flesh out I and E
for RST, we need to define dominance. Set lArgs(r) =
{e ? Dl | (r, e) ? |?l|M}; rArgs(r) is defined analogously
(where ?r replaces ?l). The left and right dominance
relations vl and vr are defined as follows: r vl r? iff
(Args(r) ? lArgs(r?)).
- r vl r? ? ?z : l((z ?l r)? z ?r r))? z ?l r?) with r vr r?
defined analogously.
Dominance v is: v=vl ? vr.
- lArgs(r, X)??z : l(z ?l r) ? z ? X), with rArgs(r, X)
similar and
-Args(r, X)? ?z : l((z ?l r) ? z ?r r))? z ? X).
The NS, NN and NS schemes of RST will be re-
spectively encoded by the predicates sub, coord and
sub?1. We proceed recursively. If t is an EDU e, re-
turn Mt = ?Di = ?,Dl = {e}, ? where  is the inter-
pretation that assigns the empty set to each predicate
symbol. If the root of t is a binary node instantiating
a relation R(t1a1 , t2a2 ), let Tr ? {sub, coord, sub?1} bethe predicate that encodes the schema a1a2, let Mt1 =
?D1i ,D1l , |.|1? and Mt2 = ?D2i ,D2l , |.|2?. The algorithm re-turns Mt = ?D1i ? D2i ? {r},D1l ? D2l , |.|Mt ? where r is a?fresh? relation instance variable not in D1i or D2i , and
|.|Mt is updated in the appropriate fashion to reflect the
left and right arguments of r. Finally, if the root of t is
an n-ary node, split it into a sequence of binary relation
R1(t1, t2),R2(t2, t3), . . . , proceed to recursively compute
the scope-structures Mi for each of the relations using
2 (take care to introduce a ?fresh? relation instance in-
dividual for each relation of the sequence), then return
the union of the models Mi.
RST Decoding Given a finite scope structure M =
?Di,Dl, |.|M?, for each relation instance r compute the
left arguments of r and its right arguments. We then
identify L(r), the unique relation symbol R such that
r ? |LR|M. If that fails, the algorithm fails. Similarly
retrieve the right nuclearity schema from the adequate
predicate that applies to r. Then compute the domi-
nance relations for r. If the input structure M = I(t)
for some RS Tree t then there is at least one maximal
relation instance for the dominance relation. If t the
root node of t is a binary relation, there is exactly one
maximal element in the dominance relation. If there
is none, then we return fail. If there is exactly one,
recursively compute the two RS Trees obtained from
the models computed from the left and right arguments
and descendants of r. If there is more than one, the root
node of the encoded RS Tree was a n-ary relation and
one has to reconstruct the n-ary node if that is possi-
ble; if not the algorithm fails (but that means the input
structure was not obtained from a valid RS Tree).
SDRT Encoding and Decoding: This is similar to
the RST encoding and decoding; for the encoding al-
gorithm, we proceed recursively top down. A SDRS
s is a complex constituent that contents a graph g =
?V, E? whose edges are relations holding between sub-
constituents, simple or complex as well. First come
up with an encoding of the set E of all edges that
hold between two sub-constituents of s, i.e. a struc-
ture M = ?Di = Ei,Dl = V, {LR}, ?l, ?r?, where, for
each edge e ? Ei, LR encodes its relation type, and
?l1 and ?r1 consists of all the pairs (x, e) of left and
right nodes x of the edges e ? E. Finally, for each
complex immediate sub-constituent of s in Dl, update
M as follows: for c such a subconsituent, recursively
compute its encoding Mc, then add everything of Mc
to M, finally remove c from M but add instead for
each relation r scoping over c to the right (left), all
the pairs {(r, x) | x is a constituent in Mc}. The decod-
ing works again similarly to the one for RST, top-down
once again: one recursively retrieves immediate con-
tent of the current complex constituent at each level
then moves to inner constituents.
DT: Dependency trees are syntactically a special case
of SDRSs; there is only one CDU whose domain is
only EDUs.
The scope language allows us to axiomatize three
classes of scope structures corresponding to RS Trees,
SDRSs and DTs. Not every scope structure will yield
a RS Tree when fed to the RST decoding algorithm,
only those obtainable from encoding an RS tree. As not
all scope structures obey these axioms, our language is
5
strictly more expressive than any of these discourse for-
malisms.
As an example of an axiom, the following formula
expresses that a relation cannot have both left and right
scope over the same elementary constituent:
Strong Irreflexivity:
?r : i?x : l?(x ?l r ? x ?r r)) (A0)
Strong irreflexivity entails irreflexivity; a given relation
instance cannot have the same (complete) left and right
scopes. All discourse theories validate A0.
In the Appendix, we define left and right strong dom-
inance relations vl(r) as well as n-ary RS trees and
CDUs of SDRT. We exploit these facts in the Appendix
to express axioms (A1-A9) that axiomatize the struc-
tures corresponding to RST, SDRT and DTs. Axiom
A1 says that every discourse unit is linked via some dis-
course relation instance. Axiom A2 insures that all our
relation instances have the right number of arguments;
Axioms A3 and A4 ensure acyclicity and no crossing
dependencies. A5a and A5b restrict structures to a tree-
like dominance relation with a maximal dominating el-
ement, while A6 defines the Right Frontier constraint
for SDRT, and A7 fixes the domain for SDRT con-
straints on CDUs. A8 ensures that no coordinating and
subordinating relations have the same left and right ar-
guments, while A9 provide the restrictions needed to
define the set of DTs. We use the encoding and decod-
ing maps to show:
Fact 2.
1. The theory TRS T ={A0, A1, A2, A3, A4, A5a, A5b, A8}
characterizes RST structures in the sense that:
- E applied to any structure M such that M |= TRS T
yield an RST Tree.
- for any RST Tree t, I(t) |= TRS T .
2. The theory TS DRT ={A0, A1, A2, A3, A6, A7, A8}
similarly characterizes SDRSs.
3. The theory TDT =TS DRT ? {A9a, A9b} similarly
characterizes Dependency Trees structures.
4 Different Interpretations of Scope
The previous section defined the set of scope structures
as well as the means to import, and then retrieve, RS
trees, DTs, or SDRs into, and from, this set. Some of
these scope structures export both into RST and SDRT,
yielding a 1 ? 1 correspondence between a subset of
SDRT and RST structures. But what does this corre-
spondence actually tell us about these two structures?
In mathematics, the existence of an isomorphism relies
on a bijection that preserves structure. Our correspon-
dence preserves the immediate interpretation of the se-
mantic scopes of relations.
Immediate Interpretation Consider a scope struc-
tureM (validating A0, A1, A2). The predicates lArgs(r)
and rArgs(r) are the sets of all units in the left or right
scope of a relation instance r. Whether r, labelled by
relation name R holds of two discourse units or not
in M, depends on the semantic content of its left and
right arguments, recursively described by lArgs(r) and
all relations r? such that r? @l r, and rArgs(r) and all
relations r? such that r? @r r. Algorithm I computes
what we call the immediate interpretation of an input
structure. Intuitively, in this interpretation the semantic
scope of relations is directly read from the structures
themselves; a node R(t1, t2) in a RS Tree expresses that
R holds between contents expressed by the whole sub-
structures t1 and t2. Similarly, for SDRT and DTs, im-
mediate interpretation of an edge pi1 ?R pi2 is that R
holds between the whole content of pi1 and pi2.
While this immediate interpretation is standard in
SDRT, it is not in RST. Consider again (1) from the
introduction or:
(2) [In 1988, Kidder eked out a $ 46 mil-
lion profit,]31 [mainly because of severe cost
cutting.]32 [Its 1,400-member brokerage oper-
ation reported an estimated $ 5 million loss last
year,]33 [although Kidder expects to turn a profit
this year]34 (RST Treebank, wsj 0604).
(3) [Suzanne Sequin passed away Saturday at the
communal hospital of Bar-le-Duc,]3 [where she
had been admitted a month ago.]4 [. . . ] [Her fu-
neral will be held today at 10h30 at the church
of Saint-Etienne of Bar-le-Duc.]5 (annodis cor-
pus).
These examples involve what are called long distance
attachments. (2) involves a relation of contrast, or com-
parison between 31 and 33, but which does not involve
the contribution of 32 (the costs cutting of 1988). (3)
displays something comparable. A causal relation like
result, or at least a temporal narration holds between
3 and 5, but it should not scope over 4 if one does
not wish to make Sequin?s admission to the hospital
a month ago a consequence of her death last Saturday.
Finally in (1) C4 elaborates on C1, but not on the fact
that C1 is attributed to chief Garcia, so the correspond-
ing elaboration relation should not scope over C3.
It is impossible however, to account for long distance
attachment using the immediate interpretation of RST
trees. (2), for instance, also involves an explanation
relation between 31 and 32, which should include none
of 33 or 34 in its scope. Since 31 is in the scope of both
the explanation and the contrast relation, Axiom A5a of
the previous section entails than an RST tree involving
the two relations has to make one of the two relations
dominates the other.
Marcu?s Nuclearity Principle (NP) Marcu 1996 pro-
vides an alternative to the immediate interpretation and
captures some long distance attachments Danlos 2008;
Egg and Redeker 2010. According to the NP, a rela-
6
tion between two spans of text, expressed at a node of
a RS Tree should hold between the most salient parts
of these spans. Most salient part is recursively defined:
the most salient part of an elementary constituent is it-
self, for a multinuclear relation R(t1N , . . . , tkN) its most
salient part is the union of the most salient parts of the
ti2. Following Egg and Redeker 2010, the NP, or weak
NP is a constraint on which RST trees may correctly
characterize an input text; it is not a mechanism for
computing scopes. Given their analysis of (1) given in
the introduction, NP entails that Elab1 holds between
C1 and C4, accounting for the long distance attach-
ment, and that Attribution holds between C1 and C4
which meets intuition in this case. There is however no
requirement that Attribution do not hold between the
wider span [C1,C2] and C3, as there is no requirement
that Elab1 does not hold between [C1,C2,C3] and C4.
In order to accurately account for (1), the former must
be true and the latter false.
However, this interpretation of NP together with an
RST tree does not determine the semantic scope of all
relations. Danlos 2008 reformulates NP as a Mixed
Nuclearity Principle (MNP) that outputs determinate
scopes for a given structure. The MNP requires for a
given node, that the most salient parts of his daughters
furnish the exact semantic scope for the relation at that
node. The MNP transforms an RST tree t into a scope
structureMt, which validates A0 ? A3 but also A6.3, A7
and A8. HenceM could be exported back to SDRT and
the MNP would yield a translation from RST-trees to
SDRSs.
But when applied to the RST Treebank, the MNP
yields wrong, or at least incomplete, semantic scopes
for intuitively correct RS Trees. The mixed principle
applied to the tree of s1 gives the Attribution scope
over C1 only, but not C2, which is incorrect. Focus-
ing on the attribution relation which is the second most
frequent in the RST Treebank, we find out that, regard-
less of whether we assign Attribution?s arguments S
and N or N and S, this principle makes wrong predic-
tions 86% of the time in a random sampling of 50 cases
in which we have attributions with multi-clause second
argument spans. Consider the following example from
the RST Treebank:
(4) [Interprovincial Pipe Line Co. said]1 [it will de-
lay a proposed two-step, 830 million Canadian-
dollar [(US$705.6 million)]3 expansion of its
system]2 [because Canada?s output of crude oil
is shrinking.]4
Applied to the annotated RS Tree for this example (fig-
2Except for Sequence which only retains the most salient
part of tk
3That A6 is valid in the resulting model is not immediate.
Assume a multinuclear (coordinating) relation instance r has
scope over xn and xn+k later in the textual order. Then it is
impossible to attach with r? a later found constituent xn+k+l to
xn alone, for it would require that xn+1 escapes the scope of r?
from the MNP which it will not do by multinuclearity of r.
attribution
1
S
reason
restatement
2
N
3SN
5S
N
Figure 1: Annotated RST Tree for example (4).
ure 1), the MNP yields an incorrect scope of the attribu-
tion relation over 2 only, regardless of whether the at-
tribution is annotated N-S or S -N. The idea behind the
weak NP provides a better fit with intuitions. The prin-
ciple gives minimal semantic requirements for scoping
relations; everything beyond those requirements is left
underspecified. We formalize this as the relaxed Nu-
clearity Principle (RNP), which does not compute one
structure where each relation is given its exact scope,
but a set of such structures.
The target structures are not trees any more, but we
want them to still reflect the dominance information
present in the RS Tree. We therefore define a notion
of weak dominance over structures of the scoping lan-
guage: for two sets of constituents, X  Y iff X ? Y or
there is a subordinating relation whose left argument is
X and right one Y . Weak dominance is given by tran-
sitive closure ? of . For two relations, r ?l r? iff theleft argument of r weakly dominates both arguments
of r?. ?r is symmetrically defined. Finally, structures
computed by the RNP have to validate the weakened
version of A5: if two relations scope over the same el-
ementary constituent one has to weakly dominates the
other. Let AW5 denote this axiom.
Definition 3 (Relaxed Nuclearity Principle). One can
assign to an RS Tree t a formula of the scoping lan-
guage ?t = ?x??r??t ? ?t such that:
1? ?t is a formula specifying that all individuals
quantified in x? and r? are pairwise distinct, and that there
is no other individuals that the ones just mentioned. ?t
also specifies for each intermediate node n that the cor-
responding relation instance rn is labelled with the ad-
equate relation symbol R and relation type (subordinat-
ing if N-S . . . ).
2? ?t encodes the nuclearity principle applied to t:
for all intermediate nodes ni and n j in t such that nl is
the left (resp. right) daughter of ni, ?t specifies that ni
must scope to the left (resp. right) over the nucleus of
n j.
The interpretation ~t is defined as the set of struc-
turesM that validate ?t and A0, A1, A2, A3, AW5 (they allhave |t| individuals, as fixed by ?t). Moreover, it can
be shown that each model of this set validates TS DRT ;
so we have a interpretation of an RS-Tree into a set of
SDRSs.
5 Intertranslability between RST/DTs
DTs are a restriction of SDRSs to structures without
complex constituents. So the ? function of section 2
7
can transform distinct SDRSs transform into the same
DT with a consequent loss of information.
a?R1 pi
pi : b?R2 c | a?R1 b?R2 c |
pi?R2 b
pi : a?R1 b (1)
Each of the SDRSs above yields the same DT after sim-
plification, namely the second one a?R1 b?R2 c.
The natural interpretation of a DT g describes the
set of fully scoped SDRS structures that are compat-
ible with these minimal requirements, i.e that would
yield g by simplification. To get this set, every edge
r(x, y) in g, r, must be assigned left scope among the
descendants of x in g (and right scope among those of
y); this is a consequence of i) x and y being heads of the
left and right arguments of r and ii) the SDRSs that are
compatible with g do not admit relations with a right
argument in one constituent and a left one outside of it.
Definition 4. Assume that we map each node4 x of g
into a unique variable vx ? Vl and each edge e into a
unique variable symbol re ? Vi. Define x? and r? in an
analogous way as in definition 3.
For a given dependency tree g, we compute a for-
mula ?g = ?x??r? ?g ? ?g such that
? ?g is defined analogously as in definition 3, defin-
ing the set of relation instances and EDUs.
? ?g is the formula stating the minimal scopes for
each relation instance: for all edge in e = R(x, y)
in g, ?g entails i) re has vx in its left scope and
vy in its right scope and ii) let Des(x) be the set
of variable symbols for all the descendants of x in
g, ?g entails that if re has left scope over some vz
then vz is in Des(x) (symmetrically for y and right
scope).
The interpretation ~g of a DT is: {M | M |=
?g, A0-A3, A6, A7}. The DT a ?R1 b ?R2 c for in-
stance, is interpreted as a set of three structures iso-
morphic to the ones in (1) above.
We now relate DTs to RS Trees interpreted with the
RNP. To this aim, we focus on a restricted class of DTs,
those who involve i) coordinating chains of 3 edus or
more only if they involve a single coordinating relation:
x1 ?R1 x2 ?R2 ? ? ? ?Rn?1 xn may appear only for n >
2 if all the Ri are the same coordinating relation, and
ii) subordinating nests of 3 edus or more only if they
involve a single subordinating relation:
x
y1
R1
. . . yn
Rn
is allowed for n > 1 only if all Ri
are labelled with the same subor-
dinating relation.
This restricted class of DTs corresponds exactly with
the set of RS-Trees interpreted with the RNP, provided
that we restrict the interpretation of a DT in the fol-
lowing way: a principle called Continuing Discourse
Pattern, CDP Asher and Lascarides 2003 must apply,
4Recall that unlike RS Trees, DTs have EDUs as nodes
and relations as edges.
who states that whenever a sequence of coordinating
relation Ric originates as a node which appear to be
also in the right scope of a subordinating relation Rs,
Rs must totally include all the Ric in its right scope. A
second principle is required, who states that whenever
two subordinating relations R0s and R?s originate at the
same node in the DT, and the right argument of R?s is
located after the right argument of Rs, any structure in
the interpretation of the DT must verify R?s l Rs. The
translation needs these requirements to work, because:
i) with the NP a relation scoping over a multinuclear
one must includes all the nucleus in RST, and ii)a node
in a RS Tree cannot scope over something that is not its
descendant). Let CDP+ denote these requirements.
Using the restricted interpretation of a DT g;
~gCDP = {M | M |= A0-A3, A6, A7,CDP+}, we trans-
form an RS Tree t into a dependency graph G(t) such
that ~t = ~G(t)CDP:
Definition 5 (RS Trees to dependency graphs). The
translation G takes a RS Tree t as input and outputs
a pair ?G, n?, where G = ?Nodes, Edges? is the corre-
sponding dependency graph, and n an attachment point
used along the recursive definition of G.
? If t is an EDU x then (G)(t) = ?({x}, {}), x?.
? If t = R(t1N , t2S ) then let ?G1, n1? = G(t1) and
?G2, n2? = G(t2).
G(t) = ?(G1 ?G2 ? {Rsubord(n1, n2))}; n1?
? If t = R(t1S , t2N) then G(t) = G(R(t2N , t1S ))
? If t = R(t1N , . . . , tkN) (multinuclear), let ?Gi, ni? =
G(ti), let G be the result of adding a chain
n1 ?Rcoord ? ? ? ?Rcoord nk to the union of the Gi,
G(t) = ?G; n1?
? If t is a nuclear satellite relation with several satel-
lites R(t1S , . . . t jN , . . . tkS ), compute the Gi has inthe previous case, then add to the union of the Gi
the nest of k ? 1 subordinating relations R linking
n j to each of the ni, i , j.
Recall RS Tree (s1). Applying G to this tree yields
the dependency tree (s3): Elab1(C1,C2)?Attr(C1,C3)?
Elab2(C1,C4). ~s3 supports any reading of (s1) pro-
vided by RNP, but also an additional one where Attr
scopes over [C1,C2,C4]. This is however forbidden
by CDP+ for C4 is after C3 in the textual order but
Elab(C1,C4) l Attr(C1,C3).
6 Similarities and distances
The framework we have presented yields a notion of
similarity that applies to structures of different for-
malisms. To motivate our idea, recall example (1);
the structure in (s3) in which Attribution just scopes
over C1 differs from the intuitively correct interpreta-
tion only in that Attribution should also scope over C2
8
as in (s2), while a structure that does this but in which
C3 is in the scope of the Elaboration relation is intu-
itively further away from the correct interpretation.
Our similarity measure Sim over structures M1 and
M2 assumes a common set of elementary constituents
and a correspondence between relation types in the
structures. We measure similarity in terms of the
scopes given to the relations. The intuition, is that given
a map f from elements of relation instances inM1 re-
lation instances in M2, we achieve a similarity score
by counting for each relation instance r the number of
EDUs that are both in the left scope of one element of
r and in f (r), then divide this number by the total num-
ber of diffrents constituents in the left scope of r1 and
r2, and do the same for right scopes as well. The global
similarity is given by the correspondence which yields
the best score.
Given a relation r1 ? M1 and a relation r2?M2, let
?(r1, r2) =
{ 1 if r1 and r2 have the same label
0 otherwise . De-
fine Cl(r1, r2) = |{x : l | M1 |= x ?l r1 ?M2 |= x ?l r2}|,
the number of constituents over which r1 and r2 scope
and Dl(r1, r2) = |{x : l |M1 |= x ?l r1?M2 |= x ?l r2}|.
Define Cr and Dr analogously and assume thatM1 has
less relation instances thanM2. Let Inj(D1i ,D2i ) be theset of injections of relations instances of M1 to those
ofM2.
S im(M1,M2) = 12Max(|M1|, |M2|)?
Max
f?Inj(D1i ,D2i )
?
r:i
?(r, f (r)) ? ( Cl(r, f (r))Dl(r, f (r)) +
Cr(r, f (r))
Dr(r, f (r)) )
If M2 has more relation instances, Invert arguments
and use the definition above. If they have same number
of instances, both directions coincide.
d(M1,M2)=1 ? S im(M1,M2)
For a discourse structureM, S im(M,M) = 1; Sim
ranges between 1 and 0. d is a Jaccard-like met-
ric obeying symmetry, d(x, x) = 0 d(x, y) , 0 for
x , y, and the triangle equality. One can further define
the maximal or average similarity between any pair of
structures of two sets S 1 and S 2. This gives an idea
of the similarity between two underspecified interpre-
tations, such as the ones provided by RNP of section 4.
For example, the maximal similarity between (s2) in-
terpreted as itself (immediate interpretation) and a pos-
sible scope structure for the DT (s3), interpreted with
the underspecified ~ of section 5, is 7/12. It is pro-
vided by the interpretation of (s3) where Attr is given
left scope over C1,C2,C4, Elab1 holds between C1 and
C2, and the second Elab fails to match the continua-
tion of (s3). sim(~s2, ~?(s2) = 7/12 also, because
? must distribute [2, 4] in s2 to avoid crossing depen-
dencies; so ~?(s2)  ~s3. The maximal similarity
between the RS tree in (s1) with RNP (or equivalently,
(3) with ~CDP+) and (s2) is 19/36, achieved when both
C1 and C2 are left argument of Attr (though not C4).
With MNP, the similarity is 17/36.
Given our results in sections 4 and 5, we have:
Fact 3. (i) For any DT g without a > 3 length flat se-
quence and interpreted using CDP+, there an RS tree
t interpreted with RNP such that S im(g, t) = 1. (ii)
For any RS tree with RNP there is a DT g such that
S im(t, g) = 1.
To prove (i) construct a model using Definition 4 and
then use RST decoding. To prove (ii) construct a model
given Definition 3 and use DT encoding. Our similarity
measure provides general results for SDRSs and DTTs
(and a fortiori SDRSs and RS trees) (See Appendix).
7 Related Work
Our work shares a motivation with Blackburn, Gardent,
and Meyer-Viol 1993: Blackburn, Gardent, and Meyer-
Viol 1993 provides a modal logic framework for for-
malizing syntactic structures; we have used MSO and
our scope language to formalize discourse structures.
While many concepts of discourse structure admit of
a modal formalization, the fact that discourse relations
can have scope over multiple elementary nodes either
in their first or second argument makes an MSO treat-
ment more natural. Danlos 2008 compares RST, SDRT
and Directed Acyclic Graphs (DAGs) in terms of their
strong generative capacity in a study of structures and
examples involving 3 EDUS. We do not consider gen-
erative capacity, but we have given a generic and gen-
eral axiomatization of RST, SDRT and DT in a formal
interpreted language. We can translate any structure of
these theories into this language, independent of their
linguistic realization. We agree with Danlos that the
NP does not yield an accurate semantic representation
of some discourses. We agree with Egg and Redeker
2010 that the NP is rather a constraint on structures, and
we formalize this with the relaxed principle and show
how it furnishes a translation from RS trees to sets of
scoped structures. Danlos?s interesting correspondence
between restricted sets of RST trees, SDRSs and DAGs
assumes an already fixed scope-interpretation for each
kind of structure: SDRSs and DAGs are naturally in-
terpreted as themselves, and RS Trees are interpreted
with the mixed NP Our formalism allows us both to
describe the structures themselves and various ways of
computing alternate scopes for relations.
With regard to the discussion in Egg and Redeker
2008; Wolf and Gibson 2005 of tree vs. graph struc-
tures, we show exactly how tree based structures
like RST with or without the NP compare to graph
based formalisms like SDRT. We have not investigated
Graphbank here, but the scope language can axioma-
tize Graphbank (with A0-A3, A8).
8 Conclusions
We have investigated how to determine the semantic
scopes of discourse relations in various formalisms by
9
developing a canonical formalism that encodes scopes
of relations regardless of particular assumptions about
discourse structure. This provides a lingua franca for
comparing discourse formalisms and a way to measure
similarity between structures, which can help to com-
pare different annotations of a same text.
References
Afantenos, S. et al (2012). ?An empirical resource for
discovering cognitive principles of discourse organ-
isation: the ANNODIS corpus?. In: Proceedings of
LREC 2012. ELRA.
Asher, N. and A. Lascarides (2003). Logics of Conver-
sation. Cambridge University Press.
Asher, N. (1993). Reference to Abstract Objects in Dis-
course. Studies in Linguistics and Philosophy 50.
Dordrecht: Kluwer.
Baldridge, J., N. Asher, and J. Hunter (2007). ?Anno-
tation for and Robust Parsing of Discourse Structure
on Unrestricted Texts?. In: Zeitschrift fr Sprachwis-
senschaft 26, pp. 213?239.
Bateman, J. and K. J. Rondhuis (1997). ?Coherence re-
lations : Towards a general specification?. In: Dis-
course Processes 24.1, pp. 3?49.
Blackburn, P., C. Gardent, and W. Meyer-Viol (1993).
?Talking about Trees?. In: EACL 6, pp. 21?29.
Carlson, L., D. Marcu, and M. E. Okurowski (2002).
RST Discourse Treebank. Linguistic Data Consor-
tium, Philadelphia.
Danlos, L. (2008). ?Strong generative capacity of RST,
SDRT and discourse dependency DAGSs?. English.
In: Constraints in Discourse. Ed. by A. Benz and P.
Kuhnlein. Benjamins, pp. 69?95.
duVerle, D. and H. Prendinger (2009). ?A Novel Dis-
course Parser Based on Support Vector Machine
Classification?. In: Proceedings of ACL-IJCNLP
2009. ACL, pp. 665?673.
Egg, M. and G. Redeker (2008). ?Underspecified dis-
course representation?. In: PRAGMATICS AND BE-
YOND NEW SERIES 172, p. 117.
? (2010). ?How Complex is Discourse Structure?? In:
Proceedings of LREC?10. Ed. by N. Calzolari et al
ELRA.
Hitzeman, J., M. Moens, and C. Grover (1995). ?Algo-
rithms for Analyzing the Temporal Structure of Dis-
course?. In: Proceedings of the 7th Meeting of the
European Chapter of the Association for Computa-
tional Linguistics, pp. 253?260.
Hobbs, J. R., M. Stickel, and P. Martin (1993). ?In-
terpretation as Abduction?. In: Artificial Intelligence
63, pp. 69?142.
Kehler, A. (2002). Coherence, Reference and the The-
ory of Grammar. CSLI Publications.
Lascarides, A. and N. Asher (1993). ?Temporal In-
terpretation, Discourse Relations and Commonsense
Entailment?. In: Linguistics and Philosophy 16,
pp. 437?493.
Mann, W. C. and S. A. Thompson (1987). ?Rhetorical
Structure Theory: A Framework for the Analysis of
Texts?. In: International Pragmatics Association Pa-
pers in Pragmatics 1, pp. 79?105.
Marcu, D. (1996). ?Building up rhetorical structure
trees?. In: Proceedings of the thirteenth national
conference on Artificial intelligence - Volume 2.
AAAI?96. Portland, Oregon: AAAI Press, pp. 1069?
1074. isbn: 0-262-51091-X.
Muller, P. et al (2012). ?Constrained decoding for
text-level discourse parsing?. Anglais. In: COLING
- 24th International Conference on Computational
Linguistics. Mumbai, Inde.
Polanyi, L. (1985). ?A Theory of Discourse Structure
and Discourse Coherence?. In: Papers from the Gen-
eral Session at the 21st Regional Meeting of the
Chicago Linguistics Society. Ed. by P. D. K. W. H.
Eilfort and K. L. Peterson.
Polanyi, L. and R. Scha (1984). ?A Syntactic Ap-
proach to Discourse Semantics?. In: Proceedings of
the 10th International Conference on Computational
Linguistics (COLING84). Stanford, pp. 413?419.
Polanyi, L. et al (2004). ?A Rule Based Approach
to Discourse Parsing?. In: Proceedings of the 5th
SIGDIAL Workshop in Discourse and Dialogue,
pp. 108?117.
Prasad, R. et al (2008). ?The penn discourse tree-
bank 2.0?. In: Proceedings of the 6th International
Conference on Language Resources and Evaluation
(LREC 2008), p. 2961.
Sagae, K. (2009). ?Analysis of Discourse Structure
with Syntactic Dependencies and Data-Driven Shift-
Reduce Parsing?. In: Proceedings of IWPT?09. ACL,
pp. 81?84.
Sanders, T., W. Spooren, and L. Noordman (1992).
?Toward a taxonomy of coherence relations?. In:
Discourse processes 15.1, pp. 1?35.
Stede, M. (2004). ?The Potsdam Commentary Cor-
pus?. In: ACL 2004 Workshop on Discourse Annota-
tion. Ed. by B. Webber and D. K. Byron. Barcelona,
Spain: Association for Computational Linguistics,
pp. 96?102.
Subba, R. and B. Di Eugenio (2009). ?An effective Dis-
course Parser that uses Rich Linguistic Information?.
In: Proceedings of HLT-NAACL. ACL, pp. 566?574.
Webber, B. et al (1999). ?Discourse Relations: A
Structural and Presuppositional Account Using Lex-
icalised TAG?. In: Proceedings of the 37th ACL
Conference. College Park, Maryland, USA: Associ-
ation for Computational Linguistics, pp. 41?48. doi:
10.3115/1034678.1034695.
Wolf, F. and E. Gibson (2005). ?Representing Dis-
course Coherence: A Corpus Based Study?. In:
Computational Linguistics 31.2, pp. 249?287.
Appendix
In what follows, let @ denotes the irreflexive part of
v We assume that we have access to the textual order
10
of EDUs as a function f : EDUs ? N with an associ-
ated strict linear ordering < over EDUs. We also ap-
peal to the notion of a chain over EDUs {x1, x2, . . . xn}
with a set of relation instances r1, . . . , rn} all of which
are instances of an n-ary relation type, of the form
x1 ?r1 x2 ?r2 . . . ?rn xn which can be defined in
MSO. To handle RST relations with multiple satellites,
we define a nest: Nest(X,R) iff all r ? R have the same
left argument in X but take different right arguments in
X. Finally, we define CDUs:
cdu(X,R)? ?rArgs(r, X)?
?r? (?x x ?r r? ? x ? X)? r? ? R
Axiomatization
?x : l ?r : i (x ?l r) ? (x ?r r)
(A1:Weak Connectedness)
?r?x, y(x ?r r) ? y ?l r))
(A2 :Properness of the relation)
?X : (l, t)(X , 0? ?y?X ?n?y ?l n
(A3 :Acyclicity or Well Foundedness)
No crossing dependencies using the textual order < of
EDUs:
?x, y, z,w((x < y < z < w) ?
?m, n?(x ?l n ? z ?r n
? y ?l m ? w ?r m)) (A4)
Tree Structures. Define scopes(r, x) := x ?l r ? x ?r r.
?r, r? ((?(?X,R r, r? ? R ? chain(X,R) ? nest(X,R))
? (?x scopes(r, x) ? scopes(r?, x)))
? (r v r? ? r? v r))
(A5a)
?R : (i, t)?!r : i ?r? ? R r? v r (A5b)
Right Frontier:
?n, xn, xn+1?r ((xn+1 ?r r)? (xn ?l r) ? (?xn ?l r
? ?X,R(chain(X,R) ? ?r?(r? ? R? sub(r?))
? ?y ? X?z?k ?m, j ? R (scopes( j, y) ? acc(z, y)
? scopes(m, xn) ? z ?l k ? k ? ?xn+1)))) (A6)
(The definition of SDRS accessibility acc is easy)
CDUs or EDUs and no overlapping CDUs:
?!x : l ? ?X,R cdu(X,R)?
?X,Y,R,R? (cdu(X,R) ? cdu(Y,R?)?
(R ? R? , 0? (R ? R? ? R? ? R))
(A7)
The same arguments cannot be linked by subordinating
and coordinating relations. The formal axiom is evi-
dent.
Finally, two axioms for restricting SDRSs to depen-
dency trees:
?r?x, y((x ?l r) ? y ?l r))
? (x ?r r) ? y ?r r)))? x = y
(A9a : NoCDUs.)
?r?r??X,Y(lArgs(r, X) ? rArgs(r,Y)
? lArgs(r?, X) ? rArgs(r?,Y))
? r = r?
(A9b :unique arc)
We note that as a consequence of A5a and A5b we have
no danglers or contiguous spans:
?x, y, n (x ?l n ? y ?l n ? x , y)
? ??m?z (x ?l m ? z ?r m
? ?(z ?l n ? z ?r n))
We also note that A5a and A5b entail A7, A8 and A9b,
though not vice-versa.
Fact 4. Where ? is any SDRS and ? : S DRS ? DT as
in section 2, set R1 = {r : i : |{x : M? |= x ?l r)}| > 1},
R2 = {r : i : |{x : M? |= x ?r r)}| > 1}, and
R{x,y} = {r|?r? : i(x ?l r? ? y ?r r? ? r? , r}. Assume the
immediate interpretation of ? and ?(?):
S im(?, ?(?))=
2|I| ? |(R1 ? R2) ??x,y?D2l X{x,y}|
2|I|
+
1
2|I| {?r?R1
1
|x : M? |= x ?l r)}|
+?r?R2
1
|x : M? |= x ?r r)}| }
Explanation: We suppose that I is the number of re-
lation instances in the SDRS. ? removes CDUs in an
SDRS and attaches all incoming arcs to the CDUs to
the head of the CDU. It also removes multiple arcs
into any given node. So for any node m such that
|{r : m ?r r}| = a > 1, then the information contained
in the a ? 1 arcs will be lost. In addition ? will restrict
that one incoming arc that in the SDRS has in its scope
all the elements in the CDU to just the head. So the
scope information concerning all the other elements in
the CDU will be lost.
11
