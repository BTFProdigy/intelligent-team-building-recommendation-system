Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 456?464,
Beijing, August 2010
Standardizing Wordnets in the ISO Standard LMF: Wordnet-LMF for GermaNet 
Verena Henrich Universtiy of T?bingen Department of Linguistics verena.henrich@uni-tuebingen.de 
Erhard Hinrichs Universtiy of T?bingen Department of Linguistics erhard.hinrichs@uni-tuebingen.de  Abstract It has been recognized for quite some time that sustainable data formats play an important role in the development and curation of linguistic resources. The purpose of this paper is to show how GermaNet, the German version of the Princeton WordNet, can be con-verted to the Lexical Markup Frame-work (LMF), a published ISO standard (ISO-24613) for encoding lexical re-sources. The conversion builds on Wordnet-LMF, which has been pro-posed in the context of the EU KYOTO project as an LMF format for wordnets. The present paper proposes a number of crucial modifications and a set of extensions to Wordnet-LMF that are needed for conversion of wordnets in general and for conversion of Ger-maNet in particular. 1 Introduction It has been recognized for quite some time that sustainable data formats play an important role in the development and curation of linguistic resources. As witnessed by the success of the guidelines of the Text Encoding Initiative 1 (TEI) and of published standards issued by the International Standards Organization 2  (ISO), markup languages such as XML3 (short for: Extensible Markup Language) have become lingua francas for encoding linguistic resources of different types, including phonetic transcrip-                                                1 See http://www.tei-c.org 2 See http://www.iso.org 3 See http://www.w3.org/TR/REC-xml/ 
tions, (annotated) text corpora, and dictionar-ies. It is fair to say that it has become common practice among developers of new linguistic resources to consult TEI guidelines and ISO standards in order to develop standard-conformant encoding schemes that serve as an interchange format and that can be docu-mented and validated by Document Type Definitions (DTD) and XML schemata. However, for resources that were developed prior to or largely in parallel with the emerging acceptance of markup languages and of emerg-ing encoding standards, the situation is far more heterogeneous. A wide variety of legacy formats exists, many of which have persisted due to existing user communities and the availability of tools that can process only such idiosyncratic formats. The development of wordnets for a large number of languages is a typical example of a type of linguistic re-source, where legacy formats still persist as a de facto standard. WordNet 1.6 is encoded in the data format of lexicographer files4 that was designed for the English Princeton WordNet (Fellbaum, 1998). It is a plain-text format for storing wordnet data and allows lexicographers to encode lexical and conceptual relations among lexical units and synsets by use of spe-cial-purpose diacritics. There exist numerous tools that can process WordNet 1.6 lexicogra-pher files to extract relevant information or to transform the data into other special-purpose formats such as Prolog-fact databases. Even tough still widely used for the reasons just mentioned, the complexity of the format itself has a number of undesirable consequences. As Henrich and Hinrichs (2010) have pointed out,                                                 4 See http://wordnet.princeton.edu/man/lexnames.5 WN.html 
456
the editing of lexicographer files is highly er-ror-prone and time-consuming in actual lexi-cographic development. Moreover, format validation of the data as well as development of new tools for data visualization and data extraction become increasingly difficult since they cannot be based on generic state-of-the-art tools, that are, for example, available for XML-based encodings. For exactly these reasons, XML-based inter-change formats have been proposed in recent years also for wordnets. One of the first, if not the first, example is the XML format for Ger-maNet5, a wordnet for German (Lemnitzer and Kunze, 2002; Henrich and Hinrichs, 2010). An even more recent development along these lines is the specification of Wordnet-LMF (see Soria et al, 2009), an instantiation of the Lexi-cal Markup Framework6 (LMF, (Francopoulo et al, 2006)) customized for wordnets. Since LMF is an ISO standard (ISO-24613), it is a particularly attractive candidate for en-coding wordnets. Everything else being equal, ISO standards have a high chance of being adopted by a wide user community and of be-ing recognized as an interchange format.7 Such agreed-upon interchange formats are a crucial prerequisite for interoperable linguistic re-sources in the context of web services and of processing pipelines for linguistic resources. The purpose of this paper is threefold: 1. To compare and contrast the GermaNet XML initially proposed by Lemnitzer and Kunze (2002) with the Wordnet-LMF. This comparison is instructive since it reveals two completely differ-ent conceptions of representing seman-tic knowledge at the lexical level. 2. To point out a number of open issues that need to be resolved if Wordnet-LMF is to be adopted widely among 
                                                5 See http://www.sfs.uni-tuebingen.de/GermaNet/ 6 See http://www.lexicalmarkupframework.org 7 An anonymous reviewer raised the question why OWL is not a good candidate for encoding wordnets. On this issue, we agree with the assessment of Soria et al (2009) who point out that ?[?] RDF and OWL are conceptual repositories representation formats that are not designed to represent polysemy and store linguistic properties of words and word meanings.? 
wordnets for a steadily increasing number of languages. 3. To show how these open issues can be resolved in a customized version of Wordnet-LMF suitable for GermaNet. The remainder of this paper is structured as follows: section 2 provides a general introduc-tion to GermaNet. Details about the adapted XML format used for GermaNet up until now are provided in section 3. Section 4 introduces the challenge of how to represent a wordnet in the Lexical Markup Framework. As one possi-bility, Wordnet-LMF is regarded. Issues that arise during the conversion of GermaNet into Wordnet-LMF lead to a modified version of Wordnet-LMF. Finally, section 5 concludes with a comparison of the two representation formats. 2 GermaNet GermaNet is a lexical semantic network that is modeled after the Princeton WordNet for Eng-lish. It partitions the lexical space into a set of concepts that are interlinked by semantic rela-tions. A semantic concept is modeled by a syn-set. A synset is a set of words (called lexical units) where all the words are taken to have (almost) the same meaning. Thus a synset is a set-representation of the semantic relation of synonymy, which means that it consists of a list of lexical units and a paraphrase (repre-sented as a string). The lexical units in turn have frames (which specify the syntactic va-lence of the lexical unit) and examples. The list of lexical units for a synset is never empty, but any of the other properties may be. There are two types of semantic relations in GermaNet: conceptual and lexical relations. Conceptual relations hold between two seman-tic concepts, i.e. synsets. They include rela-tions such as hyperonymy, part-whole rela-tions, entailment, or causation. Lexical rela-tions hold between two individual lexical units. Antonymy, a pair of opposites, is an example of a lexical relation. GermaNet covers the three word categories of adjectives, nouns, and verbs, each of which is hierarchically structured in terms of the hy-peronymy relation of synsets.  
457
 Figure 1. Structure of the XML synset files.   3 Current GermaNet XML Format The structure of the XML files closely follows the internal structure of GermaNet, which means that the file structure mirrors the under-lying relational organization of the data. There are two DTDs that jointly describe the XML-encoded GermaNet. One DTD represents all synsets with their lexical units and their attrib-utes (see subsection 3.1). The other DTD rep-resents all relations, both conceptual and lexi-cal relations (see subsection 3.2). The GermaNet XML format was initially developed by Kunze and Lemnitzer (2002), but modifications of the GermaNet data itself led to an adopted XML format, which is presented here.8 3.1 XML Synset Files The XML files that represent all synsets and lexical units of GermaNet are organized around the three word categories currently in-cluded in GermaNet: nouns, adjectives, and verbs (altogether 54 synset files since the se-mantic space for each word category is divided into a number of semantic subfields). The structure of each of these files is illus-trated in Figure 19. Each synset represents a set of lexical units (lexUnits) which all express the same meaning. This grouping represents the                                                 8 The interested reader might compare the version at hand with (Lemnitzer and Kunze, 2002) or (Kunze and Lem-nitzer, 2002), which both describe the initial GermaNet XML version. 9 In fact, this figure is not quite complete for the reason of simplicity. 
semantic relation of synonymy. Further prop-erties of a synset (e.g., the word category or a describing paraphrase) and a lexical unit (e.g., a sense number or the orthographical form (orthForm)) are encoded appropriately. Figure 1 describes the underlying XML structure. Each box in the figure stands for an element in the XML files, and the properties in each box (listed underneath the wavy line) rep-resent the attributes of an XML element. This means, for example, that a synset element has the attributes of an id and a category.10 Figure 2 shows an example of a synset with two lexical units (lexUnit elements) and a paraphrase. The lexUnit elements in turn con-tain several attributes and an orthographical form (the orthForm element), e.g., leuchten (German verb for: to shine). The first of the two lexical units even has a frame and an ex-ample.  <synset id="s58377" category="verben">   <lexUnit id="l82207"            sense="1"            namedEntity="no"            artificial="no"            styleMarking="no">     <orthForm>leuchten</orthForm>     <frame>NN</frame>     <example>       <text>         Der Mond leuchtete in der Nacht.       </text>       <exframe>NN</exframe>     </example>   </lexUnit>   <lexUnit id="l82208"                                                 10 Note that XML element or attribute names appear italic if they are referenced in the text. 
458
           sense="2"            namedEntity="no"            artificial="no"            styleMarking="no">     <orthForm>strahlen</orthForm>   </lexUnit>   <paraphrase>     Lichtstrahlen aussenden,     gro?e Helligkeit verbreiten   </paraphrase> </synset> Figure 2. Synset file example.  3.2 XML Relation File This type of XML file represents both kinds of relations: conceptual and lexical relations. All relations are encoded within one XML file, whose structure is illustrated in Figure 3.  
 Figure 3. Structure of the XML relation file.  The boxes in Figure 3 again represent XML elements, which means that there is one rela-tions element that contains all lexical relations (lex_rel elements) and conceptual relations (con_rel elements). Both relation types contain several attributes. Figure 4 illustrates an example for each of the two relation types. The type of the concep-tual relation is hyperonymy (indicated by the name attribute), and it holds between the syn-set with ID s58377 (from attribute) and the synset with ID s58376 (to attribute). The lexi-cal relation is of type antonymy (again indi-cated by the name attribute), and holds be-tween the lexical units with the IDs l2471 (from attribute) and l12470 (to attribute). 
<con_rel name="hyperonymy"          from="s58377" to="s58376"          dir="revert" inv="hyponymy" /> <lex_rel name="antonymy"          from="l2471" to="l2470"          dir="both" /> Figure 4. Example from relation file.  4 Wordnet-LMF The Lexical Markup Framework (ISO-24613) is an ISO standard for encoding natural lan-guage processing lexicons and machine read-able dictionaries (Francopoulo et al, 2006). The intention of LMF is to provide a common model for the creation and use of lexical re-sources, to manage the exchange of data be-tween and among these resources, and to en-able the merging of a large number of individ-ual electronic resources to form extensive global electronic resources. 4.1 The Challenge The core structure of LMF is based on the pro-totypical structuring of a lexicon in terms of lexical entries, each of which enumerates the different senses of the lexical item in question. This word-driven perspective contrasts the synset-driven relational structure of wordnets ? the grouping of word senses (i.e., lexical units) that express the same meaning into synsets. Exactly these two radically different organiz-ing principles (relation-based in the case of wordnets versus lexical-entry-based in the case of LMF) constitute the challenge of encoding wordnets in LMF. We take up this challenge: How can a synset-based wordnet, e.g. Ger-maNet, be represented in a word-driven format like LMF? 4.2 Apply LMF to Wordnets The conversion of GermaNet to LMF will build on Wordnet-LMF (Soria et al, 2009; Lee et al, 2009), an existing Lexical Markup Framework subset11. Wordnet-LMF has been developed in the context of the EU KYOTO                                                11 Wordnet-LMF is a proper subset of LMF since there are specifications in LMF that are not in Wordnet-LMF and since there is nothing in Wordnet-LMF which is not in LMF. Soria et al (2009) themselves refer to Wordnet-LMF as an LMF dialect. 
459
 Figure 5. The Wordnet-LMF structure.   project12 and is especially tailored to encode wordnets in the LMF standard. Wordnet-LMF is specified by a Document Type Definition (see Appendix E in (Soria and Monachini, 2008)) and fully complies with standard LMF. The Wordnet-LMF XML structure is shown in Figure 513 . There is a Lexical Resource which contains at least one Lexicon (in this case a wordnet lexicon).14 A Lexical Entry rep-resents a word entry in a Lexicon, where the word itself is represented by the writtenForm attribute of the Lemma element. Lexical En-tries group different Senses of a particular word. The Senses have a synset attribute that relates them to a Synset element by the corre-sponding ID. If two Senses have the same syn-set attribute, they belong to the same Synset and are thus synonyms. A Synset can have several relations to other Synsets. These relations are encoded in Syn-setRelation elements.                                                 12 See http://www.kyoto-project.eu 13 Note that this figure does not show the whole Wordnet-LMF model. Only the monolingual part that is relevant for this paper is represented. The representation of multi-lingual resources (i.e., the optional SenseAxis element with its children) is not considered in this paper. For a complete picture, see Soria et Monachini (2008). 14 Here, XML element or attribute names again appear italic if they are referenced in the text. 
4.3 Apply Wordnet-LMF to GermaNet The differences between the synset-driven structure of GermaNet (see Figures 1 and 3) and the word-driven format of Wordnet-LMF (see Figure 5) are obvious. But there is also a strong commonality: Both formats have synset elements that cluster synonymous words. In GermaNet, the words are represented by lexi-cal units that are child elements of a synset. In Wordnet-LMF, senses, which correspond to the lexical units in GermaNet, are linked to a synset (by an attribute containing a synset ID). The conversion of GermaNet to Wordnet-LMF proceeds as follows: Each lexical unit of GermaNet is turned into a Sense element in Wordnet-LMF (see Figure 5). The synset at-tribute (containing a Synset ID) of the Sense element links this Sense with the Synset that it is a member of. The different Sense elements are grouped by their orthographical form (the Lemma in Wordnet-LMF) into Lexical Entries. An example of a GermaNet LexicalEntry in Wordnet-LMF is shown in Figure 6. This LexicalEntry represents the word leuchten (German verb for: to shine), as the written-Form attribute of the Lemma element indi-cates. This LexicalEntry has two Senses, which belong to different Synsets (see the different synset attributes of the Sense elements). 
460
Each Sense has a MonolingualExternalRefs element with at least one MonolingualExter-nalRef representing a reference to an external system. In this case, each Sense is linked to the corresponding entry in the GermaNet data-base 15 ; the externalReference attribute of a MonolingualExternalRef specifies the database table name with a database ID.  <LexicalEntry id="deu-52-l4601-v">   <Lemma writtenForm="leuchten"                        partOfSpeech="v" />   <Sense id="deu-52-l4601-v_1"                  synset="deu-52-s58377-v">     <MonolingualExternalRefs>       <MonolingualExternalRef         externalSystem="GermaNet-Database"         externalReference=                "lex_uni_table#id=82207" />     </MonolingualExternalRefs>   </Sense>   <Sense id="deu-52-l4601-v_2"                  synset="deu-52-s58718-v">     <MonolingualExternalRefs>       <MonolingualExternalRef         externalSystem="GermaNet-Database"         externalReference=                "lex_uni_table#id=82677" />     </MonolingualExternalRefs>   </Sense> </LexicalEntry> Figure 6. Example of a LexicalEntry.  In the next conversion step, all synsets of Ger-maNet are listed with their relations to other synsets. The corresponding Synset (with the ID deu-52-s58377-v) of the first Sense in Figure 6 is illustrated in Figure 7. It has, inter alia, a describing gloss and two example sentences. The element SynsetRelations encodes rela-tions to other Synset instances. The relations are simply encoded with a target attribute that contains the ID of the referencing Synset. The Synsets in Wordnet-LMF are logically the ?same? as the synsets in GermaNet XML, i.e. the concept that a synset expresses is exactly the same in both formats. Each Synset has a reference to the Ger-maNet database. Therefore, the Monolin-gualExternalRef element links to the corre-sponding entry in the GermaNet database; the 
                                                15 For efficency reasons, GermaNet is stored in a relational database. 
externalReference attribute specifies the data-base table name with the synsets database ID.  <Synset id="deu-52-s58377-v"                           baseConcept="1">   <Definition gloss="Lichtstrahlen                aussenden, gro?e Helligkeit                verbreiten">     <Statement example="Der Mond leuchtete                           in der Nacht."/>     <Statement example="Die Lichter der            Stadt strahlen in die Nacht."/>   </Definition>   <SynsetRelations>     <SynsetRelation                  target="deu-52-s58376-v"                  relType="has_hyperonym"/>   </SynsetRelations>   <MonolingualExternalRefs>     <MonolingualExternalRef         externalSystem="GermaNet-Database"         externalReference=                  "synset_table#id=58377"/>   </MonolingualExternalRefs> </Synset> Figure 7. Example of a Synset.  These two Figures 6 and 7 represent the same example in Wordnet-LMF that was already shown in the GermaNet XML format in Figure 1. 4.4 Necessary Modifications to Wordnet-LMF As the previous discussion has shown, Word-net-LMF provides a very useful basis for con-verting GermaNet into LMF. However, a number of modifications to Wordnet-LMF are needed if this conversion is to preserve all in-formation present in the original resource. The present section will discuss a number of modi-fications to Wordnet-LMF that are needed for conversion of wordnets in general. In addition, we will also discuss a set of extensions to Wordnet-LMF that are needed for conversion of GermaNet in particular. The most glaring omission in Wordnet-LMF concerns the modeling of lexical relations which hold between lexical units (i.e., Senses in the terminology of Wordnet-LMF). In the current Wordnet-LMF DTD only conceptual relations (i.e., SynsetRelations in the terminol-ogy of Wordnet-LMF), which hold between synsets, are modeled. Thus antonymy, which is a typical example of a lexical relation (see (Fellbaum, 1998) for further details), can cur-
461
rently not be modeled without violating the Wordnet-LMF DTD. Among the synset relations specified in Wordnet-LMF, the entailment relation is miss-ing, which plays a crucial role in the modeling of verbs in the Princeton WordNet and in GermaNet alke. The list of values of attribute relType for SynsetRelation elements (see Ap-pendix A in (Soria and Monachini, 2008)) therefore has to be amended accordingly.16 A third omission in the current Wordnet-LMF DTD concerns syntactic frames used in the Princeton WordNet to indicate the syntac-tic valence of a given word sense. Syntactic frames are also used in GermaNet, albeit using a different encoding17. Syntactic frames to-gether with example sentences, which illustrate the meaning and prototypical usage of a par-ticular word, help to distinguish among word senses. In WordNet both syntactic frames and ex-amples are linked to synsets. However, at least in the case of syntactic frames the linkage to synsets seems problematic since different members of the same synset may well have different valence frames. For example, the German verbs finden and begegnen both mean meet and thus belong to the same synset. Both are transitive verbs, but their object NPs have different cases: accusative case for treffen and dative case for begegnen. As this example shows, syntactic frames need to be associated with lexical units rather than synsets. This is exactly the design choice made in GermaNet, as shown in Figure 1. A related question concerns the anchoring of example sentences which illustrate the mean-ings and prototypical usage of a particular word sense. In both the Princeton WordNet and GermaNet such examples are associated
                                                16 Piek Vossen (personal communication) has pointed out to us that Wordnet-LMF does not impose a list of rela-tions as a standard yet. 17 In WordNet, frames are encoded in a controlled lan-guage using paraphrases such as Somebody ----s some-thing for a transitive verb with an animate subject and an inanimate object. The frames in GermaNet use comple-mentation codes provided with the German version of the CELEX Lexical Database (Baayen et al, 2005) such as NN.AN for transitive verbs with accusative objects. 
with lexical units18. GermaNet correlates ex-amples additionally with particular syntactic frames and treats both examples and syntactic frames as properties of lexical units, i.e. Senses in the terminology of Wordnet-LMF. The above issues lead to a modified version of the Wordnet-LMF DTD as shown in Figure 8. Compared to Figure 5, the Sense element is enriched by three optional subelements: Sen-seRelations, SenseExamples, and Subcategori-zationFrames. It has to be noted, though, that LMF proper contains all necessary elements. The three no-tions SenseRelation, SenseExample, and Sub-categorizationFrame come from LMF proper and these elements can be used to remedy the omissions in Wordnet-LMF. The SenseRelation element in Figure 8 rep-resents relations between different Senses (the lexical units in GermaNet). The SenseExam-ples and SubcategorizationFrames elements both group several SenseExample or Subcate-gorizationFrame instances. A Subcategoriza-tionFrame element represents the syntactic valence of a word sense. A SenseExample shows the prototypical usage of a word sense as an example sentence. The syntactic valence for a concrete example sentence can be speci-fied with the optional frame attribute of a Sen-seExample. 5 Conclusion: Comparing GermaNet XML with Wordnet-LMF XML We would like to conclude with a comparison between the GermaNet native XML format described in section 3 and the modified Word-net-LMF format described in section 4.4. Since the GermaNet native XML format was particu-larly tailored to the structure of GermaNet, it enjoys the usual advantages of such custom-ized solutions: it contains all and only the nec-essary XML elements and attributes to de-scribe the resource. Moreover, the data are dis-tributed over 55 different XML files, which facilitates easy data handling and efficient search by word classes and lexical fields. These properties are in fact exploited by a number of GermaNet-specific tools, including                                                18 In WordNet, the examples are placed at the synset level, but referencing to a word sense at the same time. 
462
 Figure 8. Revised Wordnet-LMF structure.   a GermaNet-Explorer, a tool for data explora-tion and retrieval, and a GermaNet Pathfinder, a tool for the calculation of semantic related-ness, similarity, and distance (Cramer and Finthammer, 2008). All of these tools utilize the Java API that has been developed for the GermaNet native XML format. At the same time the GermaNet native XML format is a proprietary data format that was developed at a time when the only de facto encoding standard for wordnets consisted of the lexicographer files, originally developed for the Princeton WordNet. As such GermaNet XML was never developed with the goal of providing an XML standard for modeling wordnets in general. With Wordnet-LMF a candidate standard has now been proposed that is compliant with the LMF ISO standard for lexical resources and that strives to provide a general encoding standard of wordnets for dif-ferent languages. As the discussion in section 4.4 has shown, the current Wordnet-LMF DTD still needs to be amended to account for the full range of wordnet relations, frames, and examples (see Figure 8). These elements are not in Wordnet-LMF because Wordnet-LMF is a subset, but these elements are defined in the ISO document 24613 where LMF proper is defined. However, Wordnet-LMF appears to be suitably mature to serve as an interchange format for wordnets of different languages as 
well as for linking wordnets of different lan-guages with one another19. Acknowledgements The research reported in this paper was funded by the BW-eSci(T) grant sponsored by the Ministerium f?r Wissenschaft, Forschung und Kunst Baden-W?rttemberg. We would like to thank Piek Vossen and an anonymous reviewer for valuable comments on an earlier version of this paper. References Baayen, R. H., R. Piepenbrock, and L. Gulikers. 2005. The CELEX Lexical Database (Release 2) CD-ROM. Philadelphia, PA: Linguistic Data Consortium, University of Pennsylvania (Distributor). Cramer, Irene, and Marc Finthammer. 2008. Tools for Exploring GermaNet in the Context of CL-Teaching. In: Angelika Storrer, Alexander Geyken, Alexander Siebert, and Kay-Michael W?rzner, (Eds.): Text Resources and Lexical Knowledge. Selected Papers from the 9th Con-ference on Natural Language Processing KON-VENS 2008. Berlin/New York: Mouton de Gruyter, 195-208. 
                                                19 For example, the Interlingual Index, based on the Princeton WordNet, can be used to link different word-nets with one another. 
463
Kunze, Claudia, and Lothar Lemnitzer. 2002. Ger-maNet ? representation, visualization, applica-tion. Proceedings of LREC 2002, main confer-ence, Vol V. pp. 1485-1491. Fellbaum, Christiane (eds.). 1998. WordNet ? An Electronic Lexical Database. The MIT Press. Francopoulo, Gil, Monte George, Nicoletta Calzo-lari, Monica Monachini, Nuria Bel, Mandy Pet, and Claudia Soria. 2006. Lexical markup framework (LMF). Proceedings of the 5th Inter-national Conference on Language Resources and Evaluation (LREC 2006). Genoa, Italy. Henrich, Verena, and Erhard Hinrichs. 2010. Gern-EdiT ? The GermaNet Editing Tool. Proceed-ings of LREC 2010, main conference. Valletta, Malta. Lee, Lung-Hao, Shu-Kai Hsieh, and Chu-Ren Huang. 2009. CWN-LMF: Chinese WordNet in the Lexical Markup Framework. Proceedings of the 7th Workshop on Asian Resources. Suntec, Singapore, August 06 - 07, 2009, pp. 123-130 Lemnitzer, Lothar, and Claudia Kunze. 2002. Adapting GermaNet for the Web. Proceedings of the First Global Wordnet Conference. Central Institute of Indian Languages, Mysore, India, 21.-25.01.2002, pp. 174-181 Soria, Claudia, Monica Monachini, and Piek Vossen. 2009. Wordnet-LMF: Fleshing out a Standardized Format for Wordnet Interoperabil-ity. Proceedings of ACM Workshop on Intercultural Collaboration. Soria, Claudia, and Monica Monachini. 2008. Kyoto-LMF ? Wordnet representation format. KYOTO Working paper: WP02_TR002_V04_Kyoto_LMF. Vossen, Piek, Eneko Agirre, Nicoletta Calzolari, Christiane Fellbaum, Shu-kai Hsieh, Chu-Ren Huang, Hitoshi Isahara, Kyoko Kanzaki, Andrea Marchetti, Monica Monachini, Federico Neri, Remo Raffaelli, German Rigau, Maurizio Tescon, and Joop VanGent. 2008. KYOTO: A system for mining, structuring and distributing knowledge across languages and cultures. Pro-ceedings of the Sixth International Language Re-sources and Evaluation (LREC?08). Marrakech, Morocco. 
464
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 387?396,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
WebCAGe ? A Web-Harvested Corpus Annotated with GermaNet Senses
Verena Henrich, Erhard Hinrichs, and Tatiana Vodolazova
University of Tu?bingen
Department of Linguistics
{firstname.lastname}@uni-tuebingen.de
Abstract
This paper describes an automatic method
for creating a domain-independent sense-
annotated corpus harvested from the web.
As a proof of concept, this method has
been applied to German, a language for
which sense-annotated corpora are still in
short supply. The sense inventory is taken
from the German wordnet GermaNet. The
web-harvesting relies on an existing map-
ping of GermaNet to the German version
of the web-based dictionary Wiktionary.
The data obtained by this method consti-
tute WebCAGe (short for: Web-Harvested
Corpus Annotated with GermaNet Senses),
a resource which currently represents the
largest sense-annotated corpus available for
German. While the present paper focuses
on one particular language, the method as
such is language-independent.
1 Motivation
The availability of large sense-annotated corpora
is a necessary prerequisite for any supervised and
many semi-supervised approaches to word sense
disambiguation (WSD). There has been steady
progress in the development and in the perfor-
mance of WSD algorithms for languages such as
English for which hand-crafted sense-annotated
corpora have been available (Agirre et al 2007;
Erk and Strapparava, 2012; Mihalcea et al 2004),
while WSD research for languages that lack these
corpora has lagged behind considerably or has
been impossible altogether.
Thus far, sense-annotated corpora have typi-
cally been constructed manually, making the cre-
ation of such resources expensive and the com-
pilation of larger data sets difficult, if not com-
pletely infeasible. It is therefore timely and ap-
propriate to explore alternatives to manual anno-
tation and to investigate automatic means of cre-
ating sense-annotated corpora. Ideally, any auto-
matic method should satisfy the following crite-
ria:
(1) The method used should be language inde-
pendent and should be applicable to as many
languages as possible for which the neces-
sary input resources are available.
(2) The quality of the automatically generated
data should be extremely high so as to be us-
able as is or with minimal amount of manual
post-correction.
(3) The resulting sense-annotated materials (i)
should be non-trivial in size and should be
dynamically expandable, (ii) should not be
restricted to a narrow subject domain, but
be as domain-independent as possible, and
(iii) should be freely available for other re-
searchers.
The method presented below satisfies all of
the above criteria and relies on the following re-
sources as input: (i) a sense inventory and (ii) a
mapping between the sense inventory in question
and a web-based resource such as Wiktionary1 or
1http://www.wiktionary.org/
387
Wikipedia2.
As a proof of concept, this automatic method
has been applied to German, a language for which
sense-annotated corpora are still in short supply
and fail to satisfy most if not all of the crite-
ria under (3) above. While the present paper
focuses on one particular language, the method
as such is language-independent. In the case
of German, the sense inventory is taken from
the German wordnet GermaNet3 (Henrich and
Hinrichs, 2010; Kunze and Lemnitzer, 2002).
The web-harvesting relies on an existing map-
ping of GermaNet to the German version of the
web-based dictionary Wiktionary. This mapping
is described in Henrich et al(2011). The
resulting resource consists of a web-harvested
corpus WebCAGe (short for: Web-Harvested
Corpus Annotated with GermaNet Senses),
which is freely available at: http://www.sfs.uni-
tuebingen.de/en/webcage.shtml
The remainder of this paper is structured as
follows: Section 2 provides a brief overview of
the resources GermaNet and Wiktionary. Sec-
tion 3 introduces the mapping of GermaNet to
Wiktionary and how this mapping can be used
to automatically harvest sense-annotated materi-
als from the web. The algorithm for identifying
the target words in the harvested texts is described
in Section 4. In Section 5, the approach of au-
tomatically creating a web-harvested corpus an-
notated with GermaNet senses is evaluated and
compared to existing sense-annotated corpora for
German. Related work is discussed in Section 6,
together with concluding remarks and an outlook
on future work.
2 Resources
2.1 GermaNet
GermaNet (Henrich and Hinrichs, 2010; Kunze
and Lemnitzer, 2002) is a lexical semantic net-
work that is modeled after the Princeton Word-
Net for English (Fellbaum, 1998). It partitions the
2http://www.wikipedia.org/
3Using a wordnet as the gold standard for the sense inven-
tory is fully in line with standard practice for English where
the Princeton WordNet (Fellbaum, 1998) is typically taken
as the gold standard.
lexical space into a set of concepts that are inter-
linked by semantic relations. A semantic concept
is represented as a synset, i.e., as a set of words
whose individual members (referred to as lexical
units) are taken to be (near) synonyms. Thus, a
synset is a set-representation of the semantic rela-
tion of synonymy.
There are two types of semantic relations in
GermaNet. Conceptual relations hold between
two semantic concepts, i.e. synsets. They in-
clude relations such as hypernymy, part-whole re-
lations, entailment, or causation. Lexical rela-
tions hold between two individual lexical units.
Antonymy, a pair of opposites, is an example of a
lexical relation.
GermaNet covers the three word categories of
adjectives, nouns, and verbs, each of which is
hierarchically structured in terms of the hyper-
nymy relation of synsets. The development of
GermaNet started in 1997, and is still in progress.
GermaNet?s version 6.0 (release of April 2011)
contains 93407 lexical units, which are grouped
into 69594 synsets.
2.2 Wiktionary
Wiktionary is a web-based dictionary that is avail-
able for many languages, including German. As
is the case for its sister project Wikipedia, it
is written collaboratively by volunteers and is
freely available4. The dictionary provides infor-
mation such as part-of-speech, hyphenation, pos-
sible translations, inflection, etc. for each word.
It includes, among others, the same three word
classes of adjectives, nouns, and verbs that are
also available in GermaNet. Distinct word senses
are distinguished by sense descriptions and ac-
companied with example sentences illustrating
the sense in question.
Further, Wiktionary provides relations to
other words, e.g., in the form of synonyms,
antonyms, hypernyms, hyponyms, holonyms, and
meronyms. In contrast to GermaNet, the relations
are (mostly) not disambiguated.
For the present project, a dump of the Ger-
man Wiktionary as of February 2, 2011 is uti-
4Wiktionary is available under the Cre-
ative Commons Attribution/Share-Alike license
http://creativecommons.org/licenses/by-sa/3.0/deed.en
388
Figure 1: Sense mapping of GermaNet and Wiktionary using the example of Bogen.
lized, consisting of 46457 German words com-
prising 70339 word senses. The Wiktionary data
was extracted by the freely available Java-based
library JWKTL5.
3 Creation of a Web-Harvested Corpus
The starting point for creating WebCAGe is an
existing mapping of GermaNet senses with Wik-
tionary sense definitions as described in Henrich
et al(2011). This mapping is the result of a
two-stage process: i) an automatic word overlap
alignment algorithm in order to match GermaNet
senses with Wiktionary sense descriptions, and
ii) a manual post-correction step of the automatic
alignment. Manual post-correction can be kept at
a reasonable level of effort due to the high accu-
racy (93.8%) of the automatic alignment.
The original purpose of this mapping was to
automatically add Wiktionary sense descriptions
to GermaNet. However, the alignment of these
two resources opens up a much wider range of
5http://www.ukp.tu-darmstadt.de/software/jwktl
possibilities for data mining community-driven
resources such as Wikipedia and web-generated
content more generally. It is precisely this poten-
tial that is fully exploited for the creation of the
WebCAGe sense-annotated corpus.
Fig. 1 illustrates the existing GermaNet-
Wiktionary mapping using the example word Bo-
gen. The polysemous word Bogen has three dis-
tinct senses in GermaNet which directly corre-
spond to three separate senses in Wiktionary6.
Each Wiktionary sense entry contains a definition
and one or more example sentences illustrating
the sense in question. The examples in turn are
often linked to external references, including sen-
tences contained in the German Gutenberg text
archive7 (see link in the topmost Wiktionary sense
entry in Fig. 1), Wikipedia articles (see link for
the third Wiktionary sense entry in Fig. 1), and
other textual sources (see the second sense en-
try in Fig. 1). It is precisely this collection of
6Note that there are further senses in both resources not
displayed here for reasons of space.
7http://gutenberg.spiegel.de/
389
Figure 2: Sense mapping of GermaNet and Wiktionary using the example of Archiv.
heterogeneous material that can be harvested for
the purpose of compiling a sense-annotated cor-
pus. Since the target word (rendered in Fig. 1
in bold face) in the example sentences for a par-
ticular Wiktionary sense is linked to a GermaNet
sense via the sense mapping of GermaNet with
Wiktionary, the example sentences are automati-
cally sense-annotated and can be included as part
of WebCAGe.
Additional material for WebCAGe is harvested
by following the links to Wikipedia, the Guten-
berg archive, and other web-based materials. The
external webpages and the Gutenberg texts are ob-
tained from the web by a web-crawler that takes
some URLs as input and outputs the texts of the
corresponding web sites. The Wikipedia articles
are obtained by the open-source Java Wikipedia
Library JWPL 8. Since the links to Wikipedia, the
Gutenberg archive, and other web-based materials
also belong to particular Wiktionary sense entries
that in turn are mapped to GermaNet senses, the
target words contained in these materials are au-
tomatically sense-annotated.
Notice that the target word often occurs more
8http://www.ukp.tu-darmstadt.de/software/jwpl/
than once in a given text. In keeping with
the widely used heuristic of ?one sense per dis-
course?, multiple occurrences of a target word in
a given text are all assigned to the same GermaNet
sense. An inspection of the annotated data shows
that this heuristic has proven to be highly reliable
in practice. It is correct in 99.96% of all target
word occurrences in the Wiktionary example sen-
tences, in 96.75% of all occurrences in the exter-
nal webpages, and in 95.62% of the Wikipedia
files.
WebCAGe is developed primarily for the pur-
pose of the word sense disambiguation task.
Therefore, only those target words that are gen-
uinely ambiguous are included in this resource.
Since WebCAGe uses GermaNet as its sense in-
ventory, this means that each target word has at
least two GermaNet senses, i.e., belongs to at least
two distinct synsets.
The GermaNet-Wiktionary mapping is not al-
ways one-to-one. Sometimes one GermaNet
sense is mapped to more than one sense in Wik-
tionary. Fig. 2 illustrates such a case. For
the word Archiv each resource records three dis-
tinct senses. The first sense (?data repository?)
390
in GermaNet corresponds to the first sense in
Wiktionary, and the second sense in GermaNet
(?archive?) corresponds to both the second and
third senses in Wiktionary. The third sense in
GermaNet (?archived file?) does not map onto any
sense in Wiktionary at all. As a result, the word
Archiv is included in the WebCAGe resource with
precisely the sense mappings connected by the
arrows shown in Fig. 2. The fact that the sec-
ond GermaNet sense corresponds to two sense
descriptions in Wiktionary simply means that the
target words in the example are both annotated by
the same sense. Furthermore, note that the word
Archiv is still genuinely ambiguous since there is
a second (one-to-one) mapping between the first
senses recorded in GermaNet and Wiktionary, re-
spectively. However, since the third GermaNet
sense is not mapped onto any Wiktionary sense at
all, WebCAGe will not contain any example sen-
tences for this particular GermaNet sense.
The following section describes how the target
words within these textual materials can be auto-
matically identified.
4 Automatic Detection of Target Words
For highly inflected languages such as German,
target word identification is more complex com-
pared to languages with an impoverished inflec-
tional morphology, such as English, and thus re-
quires automatic lemmatization. Moreover, the
target word in a text to be sense-annotated is
not always a simplex word but can also appear
as subpart of a complex word such as a com-
pound. Since the constituent parts of a compound
are not usually separated by blank spaces or hy-
phens, German compounding poses a particular
challenge for target word identification. Another
challenging case for automatic target word detec-
tion in German concerns particle verbs such as an-
ku?ndigen ?announce?. Here, the difficulty arises
when the verbal stem (e.g., ku?ndigen) is separated
from its particle (e.g., an) in German verb-initial
and verb-second clause types.
As a preprocessing step for target word identi-
fication, the text is split into individual sentences,
tokenized, and lemmatized. For this purpose, the
sentence detector and the tokenizer of the suite
of Apache OpenNLP tools9 and the TreeTagger
(Schmid, 1994) are used. Further, compounds
are split by using BananaSplit10. Since the au-
tomatic lemmatization obtained by the tagger and
the compound splitter are not 100% accurate, tar-
get word identification also utilizes the full set of
inflected forms for a target word whenever such
information is available. As it turns out, Wik-
tionary can often be used for this purpose as well
since the German version of Wiktionary often
contains the full set of word forms in tables11 such
as the one shown in Fig. 3 for the word Bogen.
Figure 3: Wiktionary inflection table for Bogen.
Fig. 4 shows an example of such a sense-
annotated text for the target word Bogen ?vi-
olin bow?. The text is an excerpt from the
Wikipedia article Violine ?violin?, where the target
word (rendered in bold face) appears many times.
Only the second occurrence shown in the figure
(marked with a 2 on the left) exactly matches the
word Bogen as is. All other occurrences are ei-
ther the plural form Bo?gen (4 and 7), the geni-
tive form Bogens (8), part of a compound such
as Bogenstange (3), or the plural form as part
of a compound such as in Fernambukbo?gen and
Schu?lerbo?gen (5 and 6). The first occurrence
of the target word in Fig. 4 is also part of a
compound. Here, the target word occurs in the
singular as part of the adjectival compound bo-
gengestrichenen.
For expository purposes, the data format shown
in Fig. 4 is much simplified compared to the ac-
tual, XML-based format in WebCAGe. The infor-
9http://incubator.apache.org/opennlp/
10http://niels.drni.de/s9y/pages/bananasplit.html
11The inflection table cannot be extracted with the Java
Wikipedia Library JWPL. It is rather extracted from the Wik-
tionary dump file.
391
Figure 4: Excerpt from Wikipedia article Violine ?violin? tagged with target word Bogen ?violin bow?.
mation for each occurrence of a target word con-
sists of the GermaNet sense, i.e., the lexical unit
ID, the lemma of the target word, and the Ger-
maNet word category information, i.e., ADJ for
adjectives, NN for nouns, and VB for verbs.
5 Evaluation
In order to assess the effectiveness of the ap-
proach, we examine the overall size of WebCAGe
and the relative size of the different text col-
lections (see Table 1), compare WebCAGe to
other sense-annotated corpora for German (see
Table 2), and present a precision- and recall-based
evaluation of the algorithm that is used for auto-
matically identifying target words in the harvested
texts (see Table 3).
Table 1 shows that Wiktionary (7644 tagged
word tokens) and Wikipedia (1732) contribute
by far the largest subsets of the total number of
tagged word tokens (10750) compared with the
external webpages (589) and the Gutenberg texts
(785). These tokens belong to 2607 distinct pol-
ysemous words contained in GermaNet, among
which there are 211 adjectives, 1499 nouns, and
897 verbs (see Table 2). On average, these words
have 2.9 senses in GermaNet (2.4 for adjectives,
2.6 for nouns, and 3.6 for verbs).
Table 2 also shows that WebCAGe is consid-
erably larger than the other two sense-annotated
corpora available for German ((Broscheit et al
2010) and (Raileanu et al 2002)). It is impor-
tant to keep in mind, though, that the other two
resources were manually constructed, whereas
WebCAGe is the result of an automatic harvesting
method. Such an automatic method will only con-
stitute a viable alternative to the labor-intensive
manual method if the results are of sufficient qual-
ity so that the harvested data set can be used as is
or can be further improved with a minimal amount
of manual post-editing.
For the purpose of the present evaluation, we
conducted a precision- and recall-based analy-
sis for the text types of Wiktionary examples,
external webpages, and Wikipedia articles sep-
392
Table 1: Current size of WebCAGe.
Wiktionary External Wikipedia Gutenberg All
examples webpages articles texts texts
Number of
tagged
word
tokens
adjectives 575 31 79 28 713
nouns 4103 446 1643 655 6847
verbs 2966 112 10 102 3190
all word classes 7644 589 1732 785 10750
Number of
tagged
sentences
adjectives 565 31 76 26 698
nouns 3965 420 1404 624 6413
verbs 2945 112 10 102 3169
all word classes 7475 563 1490 752 10280
Total
number of
sentences
adjectives 623 1297 430 65030 67380
nouns 4184 9630 6851 376159 396824
verbs 3087 5285 263 146755 155390
all word classes 7894 16212 7544 587944 619594
Table 2: Comparing WebCAGe to other sense-tagged corpora of German.
WebCAGe
Broscheit et Raileanu et
al., 2010 al., 2002
Sense
tagged
words
adjectives 211 6 0
nouns 1499 18 25
verbs 897 16 0
all word classes 2607 40 25
Number of tagged word tokens 10750 approx. 800 2421
Domain independent yes yes
medical
domain
arately for the three word classes of adjectives,
nouns, and verbs. Table 3 shows that precision
and recall for all three word classes that occur
for Wiktionary examples, external webpages, and
Wikipedia articles lies above 92%. The only size-
able deviations are the results for verbs that occur
in the Gutenberg texts. Apart from this one excep-
tion, the results in Table 3 prove the viability of
the proposed method for automatic harvesting of
sense-annotated data. The average precision for
all three word classes is of sufficient quality to be
used as-is if approximately 2-5% noise in the an-
notated data is acceptable. In order to eliminate
such noise, manual post-editing is required. How-
ever, such post-editing is within acceptable lim-
its: it took an experienced research assistant a to-
tal of 25 hours to hand-correct all the occurrences
of sense-annotated target words and to manually
sense-tag any missing target words for the four
text types.
6 Related Work and Future Directions
With relatively few exceptions to be discussed
shortly, the construction of sense-annotated cor-
pora has focussed on purely manual methods.
This is true for SemCor, the WordNet Gloss Cor-
pus, and for the training sets constructed for En-
glish as part of the SensEval and SemEval shared
task competitions (Agirre et al 2007; Erk and
Strapparava, 2012; Mihalcea et al 2004). Purely
manual methods were also used for the German
sense-annotated corpora constructed by Broscheit
et al(2010) and Raileanu et al(2002) as well as
for other languages including the Bulgarian and
393
Table 3: Evaluation of the algorithm of identifying the target words.
Wiktionary External Wikipedia Gutenberg
examples webpages articles texts
Precision
adjectives 97.70% 95.83% 99.34% 100%
nouns 98.17% 98.50% 95.87% 92.19%
verbs 97.38% 92.26% 100% 69.87%
all word classes 97.32% 96.19% 96.26% 87.43%
Recall
adjectives 97.70% 97.22% 98.08% 97.14%
nouns 98.30% 96.03% 92.70.% 97.38%
verbs 97.51% 99.60% 100% 89.20%
all word classes 97.94% 97.32% 93.36% 95.42%
the Chinese sense-tagged corpora (Koeva et al
2006; Wu et al 2006). The only previous at-
tempts of harvesting corpus data for the purpose
of constructing a sense-annotated corpus are the
semi-supervised method developed by Yarowsky
(1995), the knowledge-based approach of Lea-
cock et al(1998), later also used by Agirre and
Lopez de Lacalle (2004), and the automatic asso-
ciation of Web directories (from the Open Direc-
tory Project, ODP) to WordNet senses by Santa-
mar??a et al(2003).
The latter study (Santamar??a et al 2003) is
closest in spirit to the approach presented here.
It also relies on an automatic mapping between
wordnet senses and a second web resource. While
our approach is based on automatic mappings be-
tween GermaNet and Wiktionary, their mapping
algorithm maps WordNet senses to ODP subdi-
rectories. Since these ODP subdirectories contain
natural language descriptions of websites relevant
to the subdirectory in question, this textual mate-
rial can be used for harvesting sense-specific ex-
amples. The ODP project also covers German so
that, in principle, this harvesting method could be
applied to German in order to collect additional
sense-tagged data for WebCAGe.
The approach of Yarowsky (1995) first collects
all example sentences that contain a polysemous
word from a very large corpus. In a second step,
a small number of examples that are representa-
tive for each of the senses of the polysemous tar-
get word is selected from the large corpus from
step 1. These representative examples are manu-
ally sense-annotated and then fed into a decision-
list supervised WSD algorithm as a seed set for it-
eratively disambiguating the remaining examples
collected in step 1. The selection and annotation
of the representative examples in Yarowsky?s ap-
proach is performed completely manually and is
therefore limited to the amount of data that can
reasonably be annotated by hand.
Leacock et al(1998), Agirre and Lopez de La-
calle (2004), and Mihalcea and Moldovan (1999)
propose a set of methods for automatic harvesting
of web data for the purposes of creating sense-
annotated corpora. By focusing on web-based
data, their work resembles the research described
in the present paper. However, the underlying har-
vesting methods differ. While our approach re-
lies on a wordnet to Wiktionary mapping, their
approaches all rely on the monosemous relative
heuristic. Their heuristic works as follows: In or-
der to harvest corpus examples for a polysemous
word, the WordNet relations such as synonymy
and hypernymy are inspected for the presence of
unambiguous words, i.e., words that only appear
in exactly one synset. The examples found for
these monosemous relatives can then be sense-
annotated with the particular sense of its ambigu-
ous word relative. In order to increase coverage
of the monosemous relatives approach, Mihalcea
and Moldovan (1999) have developed a gloss-
based extension, which relies on word overlap of
the gloss and the WordNet sense in question for
all those cases where a monosemous relative is
not contained in the WordNet dataset.
The approaches of Leacock et al Agirre and
Lopez de Lacalle, and Mihalcea and Moldovan as
394
well as Yarowsky?s approach provide interesting
directions for further enhancing the WebCAGe re-
source. It would be worthwhile to use the au-
tomatically harvested sense-annotated examples
as the seed set for Yarowsky?s iterative method
for creating a large sense-annotated corpus. An-
other fruitful direction for further automatic ex-
pansion of WebCAGe is to use the heuristic of
monosemous relatives used by Leacock et al by
Agirre and Lopez de Lacalle, and by Mihalcea
and Moldovan. However, we have to leave these
matters for future research.
In order to validate the language independence
of our approach, we plan to apply our method to
sense inventories for languages other than Ger-
man. A precondition for such an experiment is an
existing mapping between the sense inventory in
question and a web-based resource such as Wik-
tionary or Wikipedia. With BabelNet, Navigli and
Ponzetto (2010) have created a multilingual re-
source that allows the testing of our approach to
languages other than German. As a first step in
this direction, we applied our approach to English
using the mapping between the Princeton Word-
Net and the English version of Wiktionary pro-
vided by Meyer and Gurevych (2011). The re-
sults of these experiments, which are reported in
Henrich et al(2012), confirm the general appli-
cability of our approach.
To conclude: This paper describes an automatic
method for creating a domain-independent sense-
annotated corpus harvested from the web. The
data obtained by this method for German have
resulted in the WebCAGe resource which cur-
rently represents the largest sense-annotated cor-
pus available for this language. The publication of
this paper is accompanied by making WebCAGe
freely available.
Acknowledgements
The research reported in this paper was jointly
funded by the SFB 833 grant of the DFG and by
the CLARIN-D grant of the BMBF. We would
like to thank Christina Hoppermann, Marie Hin-
richs as well as three anonymous EACL 2012 re-
viewers for their helpful comments on earlier ver-
sions of this paper. We are very grateful to Rein-
hild Barkey, Sarah Schulz, and Johannes Wahle
for their help with the evaluation reported in Sec-
tion 5. Special thanks go to Yana Panchenko and
Yannick Versley for their support with the web-
crawler and to Emanuel Dima and Klaus Sut-
tner for helping us to obtain the Gutenberg and
Wikipedia texts.
References
Agirre, E., Lopez de Lacalle, O. 2004. Publicly
available topic signatures for all WordNet nominal
senses. Proceedings of the 4th International Con-
ference on Languages Resources and Evaluations
(LREC?04), Lisbon, Portugal, pp. 1123?1126
Agirre, E., Marquez, L., Wicentowski, R. 2007. Pro-
ceedings of the 4th International Workshop on Se-
mantic Evaluations. Assoc. for Computational Lin-
guistics, Stroudsburg, PA, USA
Broscheit, S., Frank, A., Jehle, D., Ponzetto, S. P.,
Rehl, D., Summa, A., Suttner, K., Vola, S. 2010.
Rapid bootstrapping of Word Sense Disambigua-
tion resources for German. Proceedings of the 10.
Konferenz zur Verarbeitung Natu?rlicher Sprache,
Saarbru?cken, Germany, pp. 19?27
Erk, K., Strapparava, C. 2010. Proceedings of the 5th
International Workshop on Semantic Evaluation.
Assoc. for Computational Linguistics, Stroudsburg,
PA, USA
Fellbaum, C. (ed.). 1998. WordNet An Electronic
Lexical Database. The MIT Press.
Henrich, V., Hinrichs, E. 2010. GernEdiT ? The Ger-
maNet Editing Tool. Proceedings of the Seventh
Conference on International Language Resources
and Evaluation (LREC?10), Valletta, Malta, pp.
2228?2235
Henrich, V., Hinrichs, E., Vodolazova, T. 2011. Semi-
Automatic Extension of GermaNet with Sense Def-
initions from Wiktionary. Proceedings of the 5th
Language & Technology Conference: Human Lan-
guage Technologies as a Challenge for Computer
Science and Linguistics (LTC?11), Poznan, Poland,
pp. 126?130
Henrich, V., Hinrichs, E., Vodolazova, T. 2012. An
Automatic Method for Creating a Sense-Annotated
Corpus Harvested from the Web. Poster pre-
sented at 13th International Conference on Intelli-
gent Text Processing and Computational Linguistics
(CICLing-2012), New Delhi, India, March 2012
Koeva, S., Leseva, S., Todorova, M. 2006. Bul-
garian Sense Tagged Corpus. Proceedings of the
5th SALTMIL Workshop on Minority Languages:
395
Strategies for Developing Machine Translation for
Minority Languages, Genoa, Italy, pp. 79?87
Kunze, C., Lemnitzer, L. 2002. GermaNet rep-
resentation, visualization, application. Proceed-
ings of the 3rd International Language Resources
and Evaluation (LREC?02), Las Palmas, Canary Is-
lands, pp. 1485?1491
Leacock, C., Chodorow, M., Miller, G. A. 1998.
Using corpus statistics and wordnet relations for
sense identification. Computational Linguistics,
24(1):147?165
Meyer, C. M., Gurevych, I. 2011. What Psycholin-
guists Know About Chemistry: Aligning Wik-
tionary and WordNet for Increased Domain Cov-
erage. Proceedings of the 5th International Joint
Conference on Natural Language Processing (IJC-
NLP), Chiang Mai, Thailand, pp. 883?892
Mihalcea, R., Moldovan, D. 1999. An Auto-
matic Method for Generating Sense Tagged Cor-
pora. Proceedings of the American Association for
Artificial Intelligence (AAAI?99), Orlando, Florida,
pp. 461?466
Mihalcea, R., Chklovski, T., Kilgarriff, A. 2004. Pro-
ceedings of Senseval-3: Third International Work-
shop on the Evaluation of Systems for the Semantic
Analysis of Text, Barcelona, Spain
Navigli, R., Ponzetto, S. P. 2010. BabelNet: Build-
ing a Very Large Multilingual Semantic Network.
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics (ACL?10),
Uppsala, Sweden, pp. 216?225
Raileanu, D., Buitelaar, P., Vintar, S., Bay, J. 2002.
Evaluation Corpora for Sense Disambiguation in
the Medical Domain. Proceedings of the 3rd In-
ternational Language Resources and Evaluation
(LREC?02), Las Palmas, Canary Islands, pp. 609?
612
Santamar??a, C., Gonzalo, J., Verdejo, F. 2003. Au-
tomatic Association of Web Directories to Word
Senses. Computational Linguistics 29 (3), MIT
Press, PP. 485?502
Schmid, H. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. Proceedings of the In-
ternational Conference on New Methods in Lan-
guage Processing, Manchester, UK
Wu, Y., Jin, P., Zhang, Y., Yu, S. 2006. A Chinese
Corpus with Word Sense Annotation. Proceedings
of 21st International Conference on Computer Pro-
cessing of Oriental Languages (ICCPOL?06), Sin-
gapore, pp. 414?421
Yarowsky, D. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. Proceed-
ings of the 33rd Annual Meeting on Association
for Computational Linguistics (ACL?95), Associ-
ation for Computational Linguistics, Stroudsburg,
PA, USA, pp. 189?196
396
Proceedings of the ACL 2010 System Demonstrations, pages 19?24,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
GernEdiT: A Graphical Tool for GermaNet Development 
  Verena Henrich University of T?bingen T?bingen, Germany. verena.henrich@uni-tuebingen.de 
Erhard Hinrichs University of T?bingen T?bingen, Germany. erhard.hinrichs@uni-tuebingen.de     Abstract 
GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicogra-phers and developers of GermaNet to access and modify the underlying GermaNet re-source. GermaNet is a lexical-semantic word-net that is modeled after the Princeton Word-Net for English. The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. GernEdiT re-places the earlier development by a more user-friendly tool, which facilitates automatic checking of internal consistency and correct-ness of the linguistic resource. This paper pre-sents all these core functionalities of GernEdiT along with details about its usage and usabil-ity. 1 Introduction The main purpose of the GermaNet Editing Tool GernEdiT tool is to support lexicographers in accessing, modifying, and extending the Ger-maNet data (Kunze and Lemnitzer, 2002; Hen-rich and Hinrichs, 2010) in an easy and adaptive way and to aid in the navigation through the GermaNet word class hierarchies, so as to find the appropriate place in the hierarchy for new synsets (short for: synonymy set) and lexical units. GernEdiT replaces the traditional Ger-maNet development based on lexicographer files (Fellbaum, 1998) by a more user-friendly visual tool that supports versioning and collaborative annotation by several lexicographers working in parallel. Furthermore, GernEdiT facilitates internal consistency of the GermaNet data such as appro-priate linking of lexical units with synsets, connectedness of the synset graph, and automatic 
closure among relations and their inverse coun-terparts. All these functionalities along with the main aspects of GernEdiT?s usage and usability are presented in this paper. 2 The Structure of GermaNet GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English (Fellbaum, 1998). It covers the three word cate-gories of adjectives, nouns, and verbs and parti-tions the lexical space into a set of concepts that are interlinked by semantic relations. A semantic concept is modeled by a synset. A synset is a set of words (called lexical units) where all the words are taken to have (almost) the same mean-ing. Thus a synset is a set-representation of the semantic relation of synonymy, which means that it consists of a list of lexical units. There are two types of semantic relations in GermaNet: conceptual and lexical relations. Conceptual relations hold between two semantic concepts, i.e. synsets. They include relations such as hyperonymy, part-whole relations, en-tailment, or causation. GermaNet is hierarchi-cally structured in terms of the hyperonymy rela-tion. Lexical relations hold between two individ-ual lexical units. Antonymy, a pair of opposites, is an example of a lexical relation. 3 The GermaNet Editing Tool The GermaNet Editing Tool GernEdiT provides a graphical user interface, implemented as a Java Swing application, which primarily allows main-taining the GermaNet data in a user-friendly way. The editor represents an interface to a rela-tional database, where all GermaNet data is stored from now on. 
19
 Figure 1. The main view of GernEdiT.  3.1 Motivation The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. This is exactly why GernEdiT was de-veloped: It supports lexicographers who need to access, modify, and extend GermaNet data by providing these functions through simple button-clicks, searches, and form editing. There are sev-eral ways to search data and browse through the GermaNet graph. These functionalities allow lexicographers, among other things, to find the 
appropriate place in the hierarchy for the inser-tion of new synsets and lexical units. Last but not least, GernEdiT facilitates internal consistency and correctness of the linguistic resource and supports versioning and collaborative annotation of GermaNet by several lexicographers working in parallel. 3.2 The Main User Interface Figure 1 illustrates the main user panel of Gern-EdiT. It shows a Search panel above, two panels for Synsets and Lexical Units in the middle, and four tabs below: a Conceptual Relations Editor, a Graph with Hyperonyms and Hyponyms, a Lexi-
20
 Figure 2: Filtered list of lexical units.  cal Relations Editor, and an Examples and Frames tab. In Figure 1, a search for synsets consisting of lexical units with the word Nuss (German noun for: nut) has been executed. Accordingly, the Synsets panel displays the three resulting synsets that match the search item. The Synset Id is the unique database ID that unambiguously identi-fies a synset, and which can also be used to search for exactly that synset. Word Category specifies whether a synset is an adjective (adj), a noun (nomen), or a verb (verben), whereas Word Class classifies the synsets into semantic fields. The word class of the selected synset in Figure 1 is Nahrung (German noun for: food). The Para-phrase column contains a description of a synset, e.g., for the selected synset the paraphrase is: der essbare Kern einer Nuss (German phrase for: the edible kernel of a nut). The column All Orth Forms simply lists all orthographical variants of all its lexical units. Which lexical units are listed in the Lexical Units panel depends on the selected synset in the Synsets panel. Here, Lex Unit Id and Synset Id again reflect the corresponding unique database IDs. Orth Form (short for: orthographic form) represents the correct spelling of a word accord-ing to the rules of the spelling reform Neue Deutsche Rechtschreibung (Rat f?r deutsche Rechtschreibung, 2006), a recently adopted spelling reform. In our example, the main ortho-graphic form is Nuss. Orth Var may contain an 
alternative spelling that is admissible according to the Neue Deutsche Rechtschreibung. 1  Old Orth Form represents the main orthographic form prior to the Neue Deutsche Recht-schreibung. This means that Nu? was the correct spelling instead of Nuss before the German spell-ing reform. Old Orth Var contains any accepted variant prior to the Neue Deutsche Recht-schreibung. The Old Orth Var field is filled only if it is no longer allowed in the new orthography. The Boolean values Named Entity, Artificial, and Style Marking express further properties of a lexical unit, whether the lexical unit is a named entity, an artificial concept node, or a stylistic variant. For both the lexical units and the synsets, there are two buttons Use as From and Use as To, which help to add new relations (see the explana-tion of Figure 3 in section 3.6 below which ex-plains the creation of new relations). 3.3 Search Functionalities It is possible to search for words or synset data-base IDs via the search panel (see Figure 1 at the top). The check box Ignore Case offers the pos-sibility of searching without distinguishing be-tween upper and lower case.                                                  1 An example of this kind is the German word Delfin (Ger-man noun for: dolphin). Apart from the main form Delfin, there is an orthographic variant Delphin. 
21
 Figure 3. Conceptual Relations Editor tab.  Via the file menu, lists of all synsets or lexical units with their properties can be accessed. To these lists, very detailed filters can be applied: e.g., filtering the lexical units or synsets by parts of their orthographical forms. Figure 2 shows a list of lexical units to which a detailed filter has been applied: verbs have been chosen (see the chosen tab) whose orthographical forms start with an a- (see starts with check box and corre-sponding text field) and end with the suffix -ten (see ends with check box and corresponding text field). Only verbs that have a frame that contains NN are chosen (see Frame contains check box and corresponding text field). Furthermore, the resulting filtered list is sorted in descending or-der by their examples (see the little triangle in the Examples header of the result table). The number in the brackets behind the word category in the tab title indicates the count of the filtered lexical units (in this example 193 verbs pass the filter). 3.4 Visualization of the Graph Hierarchy There is the possibility to display a graph with all hyperonyms and hyponyms of a selected synset. This is shown in the bottom half of Figure 1 in the tab Graph with Hyperonyms and Hyponyms. The graph in Figure 1 visualizes a part of the hi-erarchical structure of GermaNet centered around the synset containing Nuss and displays the hyperonyms and hyponyms of this synset up to a certain parameterized depth (in this case depth 2 has been chosen). The Hyperonym Depth chooser allows unfolding the graph to the top up to the preselected depth. As it is not possible to visualize the whole GermaNet contents at once, the graph can be seen as a window to GermaNet. 
A click on any synset node within the graph, navigates to that synset. This functionality sup-ports lexicographers especially in finding the appropriate place in the hierarchy for the inser-tion of new synsets. 3.5 Modifications of Existing Items If the lexicographers? task is to modify existing synsets or lexical units, this is done by selecting a synset or lexical unit displayed in the Synsets and the Lexical Units panels shown in Figure 1. The properties of such selected items can be ed-ited by a click in the corresponding table cell. For example by clicking in the cell Orth Form the spelling of a lexical unit can be corrected in case of an earlier typo was made. If lexicographers want to edit examples, frames, conceptual, or lexical relations this is done by choosing the appropriate tab indicated at the bottom of Figure 1. By clicking one of these tabs, the corresponding panel appears below these tabs. In Figure 1 the panel for Graph with Hyperonyms and Hyponyms is displayed. It is possible to edit the examples and frames associated with a lexical unit via the Examples and Frames tab. Frames specify the syntactic valence of a lexical unit. Each frame can have an associated example that indicates a possible us-age of the lexical unit for that particular frame. The tab Examples and Frames is thus particu-larly geared towards the editing of verb entries. By clicking on the tab all examples and frames of a lexical unit are listed and can then be modi-fied by choosing the appropriate editing buttons. For more information about these editing func-tions see Henrich and Hinrichs (2010). 
22
    Figure 4. Synset Editor (left). Lexical Units Editor (right).  3.6 Editing of Relations If lexicographers want to add new conceptual or lexical relations to a synset or a lexical unit this is done by clicking on the Conceptual Relations Editor or the Lexical Relations Editor shown in Figure 1. Figure 3 shows the panel that appears if the Conceptual Relations Editor has been chosen for the synset containing Nuss. To create a new rela-tion, the lexicographer needs to use the buttons Use as From and Use as To shown in Figure 1. This will insert the ID of the selected synsets from the Synsets panel in the corresponding From or To field in Figure 3. The button Delete ConRel allows deletion of a conceptual relation, if all consistency checks are passed. The Lexical Relations Editor tab supports edit-ing all lexical relations. It is not displayed sepa-rately for reasons of space, but it is analogue to the Conceptual Relations Editor tab for editing conceptual relations. 3.7 Adding Synsets and Lexical Units The buttons Add New Hyponym and Add New LexUnit in the Synsets panel (see Figure 1) can be used to insert a new synset or lexical unit at the selected place in the GermaNet graph, and the buttons Delete Synset and Delete LexUnit remove the selected entry, respectively. The Synset Editor in Figure 4 (on the left) shows the window which appears after a click on Add New Hyponym. When clicking on the button Create Synset, the Lexical Unit Editor (shown in Figure 4, right) pops up. This workflow forces the parallel creation of a lexical unit while creat-ing a synset. 3.8 Consistency Checks GernEdiT facilitates internal consistency of the GermaNet data. This is achieved by the 
workflow-oriented design of the editor. It is not possible to create a synset without creating a lexical unit in parallel (as described in section 3.7). Furthermore, it is not possible to insert a new synset without specifying the place in the GermaNet hierarchy where the new synset should be added. This is achieved by the button Add New Hyponym (see Figure 1) which forces the user to identify the appropriate hyperonym for the new synset to be added. Furthermore, it is not possible to insert a lexical unit without speci-fying the corresponding synset. On deletion of a synset, all corresponding data such as conceptual relations, lexical units with their lexical relations, frames, and examples, are deleted automatically. Consistency checks also take effect for the ta-ble cell editing in the Synsets and Lexical Units panels of the main user interface (see Figure 1), e.g., the main orthographic form of a lexical unit may never be empty. All buttons in GernEdiT are enabled only if the corresponding functionalities meet the con-sistency requirements, e.g., if a synset consists only of one lexical unit, it is not possible to de-lete that lexical unit and thus the button Delete LexUnit is disabled. Also, if the deletion of a synset or a relation would violate the complete connectedness of the GermaNet graph, it is not possible to delete that synset. 3.9 Further Functionalities There are further functionalities available through the file menu. Besides retrieving the up-to-date statistics of GermaNet, an editing history makes it possible to list all modifications on the GermaNet data, with the information about who made the change and how the modified item looked before. GernEdiT supports various export functionali-ties. For example, it is possible to export all GermaNet contents into XML files, which are used as an exchange format of GermaNet, or to 
23
export a list of all verbs with their corresponding frames and examples. 4 Tool Evaluation In order to assess the usefulness of GernEdiT, we conducted in depth interviews with the Germa-Net lexicographers and with the senior researcher who oversees all lexicographic development. At the time of the interview all of these researchers had worked with the tool for about eight months. The present section summarizes the feedback about GernEdiT that was obtained in this way. The initial learning curve for getting familiar with GernEdiT is considerably lower compared to the learning curve required for the traditional development based on lexicographer files. Moreover, the GermaNet development with GernEdiT is both more efficient and accurate compared to the traditional development along the following dimensions: 1. The menu-driven and graphics-based navigation through the GermaNet graph is much easier compared to finding the cor-rect entry point in the purely text-based format of lexicographer files. 2. Lexicographers no longer need to learn the complex specification syntax of the lexi-cographer files. Thereby, syntax errors in the specification language ? a frequent source of errors prior to development with GernEdiT ? are entirely eliminated. 3. GernEdiT facilitates automatic checking of internal consistency and correctness of the GermaNet data such as appropriate linking of lexical units with synsets, con-nectedness of the synset graph, and auto-matic closure among relations and their inverse counterparts. 4. It is now even possible to perform further queries, which were not possible before, e.g., listing all hyponyms of a synset. 5. Especially for the senior researcher who is responsible for coordinating the GermaNet lexicographers, it is now much easier to trace back changes and to verify who was responsible for them. 6. The collaborative annotation by several lexicographers working in parallel is now easily possible and does not cause any management overhead as before. 
In sum, the lexicographers of GermaNet gave very positive feedback about the use of Gern-EdiT and also made smaller suggestions for im-proving its user-friendliness further. This under-scores the utility of GernEdiT from a practical point of view. 5 Conclusion and Future Work In this paper we have described the functionality of GernEdiT. The extremely positive feedback of the GermaNet lexicographers underscores the practical benefits gained by using the GernEdiT tool in practice. At the moment, GernEdiT is customized for maintaining the GermaNet data. In future work, we plan to adapt the tool so that it can be used with wordnets for other languages as well. This would mean that the wordnet data for a given language would have to be stored in a relational database and that the tool itself can handle the language specific data structures of the wordnet in question. Acknowledgements We would like to thank all GermaNet lexicogra-phers for their willingness to experiment with GernEdiT and to be interviewed about their ex-periences with the tool. Special thanks go to Reinhild Barkey for her valuable input on both the features and user-friendliness of GernEdiT and to Alexander Kis-lev for his contributions to the underlying data-base format. References Claudia Kunze and Lothar Lemnitzer. 2002. Ger-maNet ? representation, visualization, appli-cation. Proceedings of LREC 2002, Main Confer-ence, Vol V. pp. 1485-1491, 2002. Christiane Fellbaum (ed.). 1998. WordNet ? An Electronic Lexical Database. Cambridge, MA: MIT Press. Verena Henrich and Erhard Hinrichs. 2010. GernEdiT ? The GermaNet Editing Tool. Proceedings of LREC 2010, Main Conference, Valletta, Malta. Rat f?r deutsche Rechtschreibung (eds.) (2006). Deutsche Rechtschreibung ? Regeln und W?rterverzeichnis: Amtliche Regelung. Gunter Narr Verlag T?bingen. 
24
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 36?41,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Using Nominal Compounds for Word Sense DiscriminationYannick Versley
University of Tu?bingen
Department of Linguisticsversley@sfs.uni-tuebingen.de Verena HenrichUniversity of Tu?bingenDepartment of Linguisticsverena.henrich@uni-tuebingen.deAbstract
In many morphologically rich languages, con-
ceptually independent morphemes are glued
together to form a new word (a compound)
with a meaning that is often at least in part pre-
dictable from the meanings of the contribut-
ing morphemes. Assuming that most com-
pounds express a subconcept of exactly one
sense of its nominal head, we use compounds
as a higher-quality alternative to simply using
general second-order collocate terms in the
task of word sense discrimination. We eval-
uate our approach using lexical entries from
the German wordnet GermaNet (Henrich and
Hinrichs, 2010).1 Introduction
In several morphologically rich languages such as
German and Dutch, compounds are usually written
as one word: In a process where nouns, verbs and
other prefixes combine with a head noun (called the
simplex when it occurs on its own), a novel word
can be formed which is typically interpretable by
considering its parts and the means of combination.
The process of compounding is both highly produc-
tive and subject to lexicalization (i.e., the creation
of non-transparent compounds that can only be in-
terpreted as a whole rather than as a combination
of parts). The analysis of compounds have been
subject to interest in machine translation as well as
in the semantic processing of morphologically rich
languages. The analysis of compounds is generally
challenging for many reasons. In particular, com-
pounds leave us with the dilemma of either model-
ing them as complete units, yielding a more accu-
rate picture for lexicalized compounds but creating
a more severe sparse data problem in general, or try-
ing to separate out their parts and ending up with
problems of wrongly split lexicalized compounds,
or of incurring mis-splits where spurious ambigui-
ties occur.
The purpose of this paper is to address the ques-
tion of whether semantic information of compound
occurrences can be used to learn more about the
sense distribution of the simplex head, with respect
to a text collection. Specifically, this paper focuses
on the task of word sense discrimination, where the
goal is to find different senses of a word without
assuming a hand-crafted lexical resource as train-
ing material (in contrast to word sense disambigua-
tion, where the exact sense inventory to be tagged
is known at training and inference time, and where
making effective use of a resource such as WordNet
(Miller and Fellbaum, 1991) or GermaNet (Henrich
and Hinrichs, 2010) is an important part of the prob-
lem to be solved).
While the present paper focuses on nominal com-
pounds in German, the method as such can also be
applied to other languages where compounds are
written as one word.2 Related Work
Automatic word sense discrimination (WSD) is a
task that consists of the automatic discovery of a
sense inventory for a word and of associated exam-
ples for each sense.
To evaluate systems performing word sense dis-
crimination, earlier research such as Schu?tze (1998)
36
uses either pseudowords ? two words that have been
artificially conflated to yield an ambiguous concept
such as wide range/consulting firm ? or use (ex-
pensive) manually annotated data. Subsequently,
the contexts of these occurrences are clustered into
groups that correspond to training examples for each
postulated sense.
A different approach to the idea of word sense
discrimination can be found in the work of Pantel
and Lin (2002): they retrieve a set of most-similar
items to the target word, and then cluster these sim-
ilar items according to distributional semantic prop-
erties. In Pantel and Lin?s approach, the output of
the word sense induction algorithm is not a group
of contexts with the target word that will be used to
represent a sense, but instead one or more words that
are (hopefully) related to one particular sense. The
contexts in which the related words occur could then
be used as positive examples for that particular sense
of the target word.
Pantel and Lin aim at a principled approach to
compare the soft-clustering approaches they pro-
pose, in conjunction with a fixed set of related
words. While the main interest of this paper lies
in comparing different methods for generating the
candidate set of related words, the exact clustering
method is only of marginal interest. In this paper, a
simpler hard clustering method is used and only the
assignment for the tight center of a cluster is consid-
ered since the non-central items can be different or
even incomparable for the different methods.3 Our Approach
Our approach to word sense discrimination is based
on the idea that different compounds that have the
same simplex word as their head (e.g. Blu?tenblatt
?petal?, and Revolverblatt ?tabloid rag?) are less am-
biguous than the simplex (Blatt ?leaf?, ?newspa-
per?) itself. This assumption is along the lines with
what the ?one sense per collocation? heuristic of
Yarowsky (1993) would predict.
Yarowsky noted that in a corpus of homo-
graphs/homophones/near-homographs, translation
distinctions, and pseudo-words, a single collocation
(such as ?foreign? or ?presidential?) is often enough
to disambiguate the occurrence of a near-homograph
such as aid/aide. While Yarowsky claims that most
of the problems of such an approach would be due
to absent or unseen collocates, it is easily imagin-
able that collocates such as old or big can occur with
multiple senses of a word.
In German, noun compounds usually involve at
least a minimum degree of lexicalization: In En-
glish, ?red flag? and ?red beet? are lexicalized (i.e.,
denote something more specific than the composi-
tional interpretation would suggest), but ?red rag?
or ?red box? are purely compositional. In German,
Rotwein ?red wine? is a compound, but the more
compositional roter Apfel/*Rotapfel ?red apple? is
not a compound and points to the fact that ?red ap-
ple? only has a compositional interpretation. Be-
cause of this minimal required degree of lexicaliza-
tion, we would expect that German nominal com-
pounds (as well as any compounds in a language that
has a similar distinction between affixating and non-
affixating compounds) are, for the largest portion,
compositional enough to be interpretable, but lexi-
calized enough that a compound is always specific
to only one sense of its head simplex.3.1 Finding Committees
The method of finding committees that form sense
clusters is illustrated in Figure 1 using the target
word example Blatt. To generate a candidate list
of related terms, our method first retrieves all words
(compounds) that have the target word as a suffix
(step 3 in Figure 1). This candidate set is then sorted
according to distributional similarity with the target
word and cut off after N items (step 2 in Figure 1) to
reduce the influence of spurious matches and non-
taxonomic compounds and to avoid too much noise
in the candidate list.
In order to evaluate the method of selecting com-
pounds as candidate words, we first cluster the set
of candidate words into as many clusters as there
are target word senses represented in the candidate
words (step 3 in Figure 1, again using the distribu-
tional similarity vectors of the words described in
the following subsection 3.2).
To avoid biasing our method towards any partic-
ular method of choosing the candidate words, we
simply assume that it is possible to produce a ?rea-
sonable? number of clusters. In the next step, the
most central items of each cluster (the ?committee?)
are determined, purely by closeness to the cluster?s
37
Figure 1: Steps in the clustering method
centroid and disregarding similarity with the target
word. The committee words are rendered in bold
face in the circles in Figure 1. The quality of the
approach is then evaluated according to whether the
committees form a suitable representation for the set
of senses that the target word possesses.
An advantage of only including compounds in the
candidate list of related terms, instead of all words,
is that the related words generated by such an ap-
proach are conceptually considerably closer to the
target word than those using all words as candidates:
Using all words, the top candidates include the co-
ordinate terms Frucht ?fruit? and Blu?te ?flower?, as
well as more faraway terms such as Tuch ?cloth? or
Haar ?hair?; using only compounds of the simplex,
the candidate list contains mostly hyponyms such as
Laubblatt ?leaf?, Titelblatt ?title page? or Notenblatt
?sheet of music?.3.2 Distributional Similarity and Clustering
Both for the initial selection of candidate words
(where the list is cut off after the top-N similar
terms) and for the subsequent clustering step, fre-
quency profiles from a large corpus are used to cre-
ate a semantic vector from the target word and each
(potential or actual) candidate word.
To construct these frequency profiles, the web-
news corpus of Versley and Panchenko (2012) is
used, which contains 1.7 billion words of text from
various German online newspapers. The text is
parsed using MALTParser (Hall et al, 2006) and
the frequency of collocates with the ATTR (premod-
ifying adjective) and OBJA (accusative object) re-
lations is recorded. Vectors are weighted using the
conservative pointwise mutual information estimate
from Pantel and Lin (2002). For selecting most-
similar words in candidate selection, we use a ker-
nel based on the Jensen-Shannon Divergence across
both grammatical relations, similar to the method
proposed by O? Se?aghdha and Copestake (2008).
The resulting vector representations of words are
then clustered using average-link hierarchical ag-
glomerative clustering using the CLUTO toolkit
(Zhao and Karypis, 2005), which uses cosine sim-
ilarity to assess the similarity of two vectors. In the
study of Pantel and Lin (2002), agglomerative clus-
tering was among the best-performing off-the-shelf
clustering methods.
As we initially found that many features that were
used in clustering were less relevant to the differ-
ent senses of the head word that were targeted, we
also introduce a method to enforce a focus on tar-
get word compatible aspects of those words. In the
basic approach (raw), the normal vector representa-
tion of each word is used. In the modified approach
(intersect), only the features that are relevant for the
target word are selected, by using for each feature
the minimum value of (i) that feature?s value in the
candidate word?s vector and (ii) that feature?s value
in the target word?s vector.3.3 Competing and Upper Baselines
To see how well our method performs in relation to
other approaches for finding related terms describ-
38
ing each sense of a synset, two lower baselines and
one upper baseline have been implemented.
One lower baseline uses general distributionally
similar items. This is an intelligent (but realistic)general baseline method ? close in spirit to Pantel
and Lin (2002). It simply consists in retrieving the
distributionally most similar words for the clustering
task. Effectively, this resembles our own method,
but without the compound filtering step.
The second lower baseline assumes that it should
always be possible to find one word that is related to
one of the senses (yielding poor coverage but trivi-
alizing the clustering problem). This trivial baseline
is called one-cluster.
The upper baseline (called profile) assumes that
it knows which senses of the word should be mod-
eled and that errors can only be introduced by the
clustering step not reproducing the original sense.
This baseline retrieves the synsets corresponding to
each sense of the word from GermaNet, and, among
the terms in the neighbouring synsets (synonyms,
hypernyms, hyponyms as well as sibling synsets),
select those that are both unambiguous (i.e., do not
have other synsets corresponding to that word) and
are distributionally most similar to the (ambiguous)
target word.4 Evaluation Framework
Our evaluation framework is based on retrieving a
set of words related to the target item (the candidate
set), and then using collocate vectors extracted from
a corpus to cluster the candidate set into multiple
subsets.
Once we have a clustering of the generated terms,
we want a quantitative evaluation of the clustering.
The underlying idea for this is that we would like to
have, for each sense of the target word, a cluster that
has one or several words describing it. (We should
not assume that it is always possible to find many
related words for a particular sense).4.1 Evaluation Data
As target items, we used a list of simplexes that
are most productive in terms of compounding, us-
ing a set of gold-standard compound splits that were
created by Henrich and Hinrichs (2011); candidate
words (both compounds and general neighbours)
Figure 2: Evaluation procedure for the committees of re-
lated words
were selected using a frequency list extracted from
the Tu?PP-D/Z corpus (Mu?ller, 2004). For the ex-
periments themselves, no information about correct
splits of the compounds was assumed and potential
compounds were simply retrieved as lemma forms
that have the target word as a suffix.
The subsets from clustering the candidate set
are then evaluated according to whether the most-
central related words in that cluster are related to the
same sense of the target word, and how many senses
of the target word are covered by the clusters.4.2 Evaluation Metric
Given the committee lists that are output by the can-
didate selection and output, we calculate an evalua-
tion score by creating a mapping between senses of
the target word and the committees that are the out-
put of the clustering algorithm, choosing that map-
ping according to a quality measure that describes
how well the committee members match that synset
(the precision of that possible pairing between a
committee and a sense of the target word), as shown
in figure 2. Each candidate word is assigned a sense
of the target word, either because it is a hyponym of
that sense (for the compound-based method) or be-
cause its path distance in GermaNet?s taxonomy is
less than four (for the general terms method). If a
candidate word is not near any of the target word?s
sense synsets, it is assigned no sense (and always
39
candidates num vectors score quality coverage
compound 5 intersect 0.399 0.882 0.468
compound 30 intersect 0.489 0.721 0.702
compound 100 intersect 0.419 0.586 0.769
general 5 intersect 0.433 0.882 0.510
general 30 intersect 0.528 0.696 0.784
general 100 intersect 0.573 0.650 0.896
compound 5 raw 0.406 0.898 0.468
compound 30 raw 0.479 0.712 0.702
compound 100 raw 0.422 0.591 0.769
general 5 raw 0.441 0.902 0.510
general 30 raw 0.526 0.694 0.784
general 100 raw 0.551 0.630 0.896
profile 10n intersect 0.737 0.781 0.945
profile 10n raw 0.753 0.801 0.946
one-cluster 1 ? 0.325 1.000 0.325
Table 1: Evaluation scores for the different methods and
baselines
counted wrong).1
Given a committee C of these (at most) k most-
central candidate words in a cluster, we can calculate
a measure P (C, s) = |w2C:sense(w)=s||C| that describes
how well this cluster corresponds to a given sense.
(Ideally, the committee would contain words only
related to one sense).
Using the Kuhn-Munkres algorithm (Kuhn,
1955), we compute a mapping between each rep-
resented synset s and a cluster Cs such thatP
s P (Cs, s) is maximized. The final score for one
target word is this sum divided by the total number
of synsets for the target word ? this means that a
method that yields a less representative set of can-
didate words will normally not get a better score,
unless the clusters are of higher enough quality, than
one that has candidate terms for each cluster.
In addition to the score metric, we calculated a
quality metric that divides the raw sum by the num-
ber of senses covered in the candidate set, and a
coverage metric that corresponds to the fraction of
senses covered by the candidate set in the first place
(see Table 1).5 Results and Discussion
Table 1 contains quantitative results for the differ-
ent methods and also evaluation statistics for some
1If a candidate word is not represented in GermaNet at all,
it is discarded before the committee-building step, so that all
committee words are in fact GermaNet-represented terms.
lower and upper baselines: Selecting exactly one re-
lated word as a candidate (and putting it in a clus-
ter of its own) would yield a quality of 1.0, since
that cluster is related to exactly one synset, but a
very poor coverage of 0.325. For the profile up-
per baseline, which takes related terms from Ger-
maNet and uses imperfect information only in clus-
tering, we see that our clustering approach is able
to reconstruct committees of sense-identical terms
out of the candidate list fairly well: given related
terms for each sense, distributional similarity yields
fairly good quality (0.801) and, unsurprisingly, near-
perfect coverage for all senses (0.946).
For the actual methods using compounds of a
word (compound rows in Table 1) or distribution-
ally similar words (general rows), we find that the
compound-based candidate selection only reaches
very limited coverage numbers and furthermore
gives the best results with a smaller number of can-
didate words (30 for compounds versus 100 for gen-
eral). Whether this effect is due to minority senses
being less productive in compounding or whether
compounds of the minority senses are not repre-
sented in GermaNet is left to be investigated in fu-
ture work.6 Conclusion
We used compounds in the selection of candidate
words for representing a target word?s senses in a
word sense discrimination approach. Because com-
pounds are less-frequent overall than the similar-
frequency coordinate terms that are retrieved in the
general baseline approach, the proposed approach
does less well in covering all senses encoded in the
gold standard and gets lower results in our evalua-
tion metric. In contrast to previous work by Pantel
and Lin, our evaluation approach allows a principled
comparison between approaches to generate candi-
date lemmas in such a task and would be applicable
also to other alternative methods to do so.Acknowledgements We would like to thank Anne
Brock, as well as several anonymous reviewers, for
helpful comments of an earlier version of this pa-
per. The research in this paper was partially funded
by the Deutsche Forschungsgemeinschaft as part of
Collaborative Research Centre (SFB) 833.
40
References
Agirre, E., Aldezabal, I., and Pociello, E. (2006).
Lexicalization and multiword expression in the
Basque WordNet. In Proceedings of the first In-
ternational WordNet Conference.
Bentivogli, L. and Pianta, E. (2004). Extending
WordNet with syntagmatic information. In Pro-
ceedings of the Second Global WordNet Confer-
ence (GWC 2004).
Hall, J., Nivre, J., and Nilsson, J. (2006). Discrim-
inative classifiers for deterministic dependency
parsing. In Proceedings of the COLING/ACL
2006 Main Conference Poster Sessions.
Henrich, V. and Hinrichs, E. (2010). GernEdiT - the
GermaNet editing tool. In LREC 2010.
Henrich, V. and Hinrichs, E. (2011). Determin-
ing immediate constituents of compounds in Ger-
maNet. In Proc. International Conference Re-
cent Advances in Language Processing (RANLP
2011).
Kuhn, H. W. (1955). The hungarian method for the
assignment problem. Naval Research Logistics
Quarterly, 2:83?97.
Miller, G. A. and Fellbaum, C. (1991). Semantic
networks of English. Cognition, 41:197?229.
Mu?ller, F. H. (2004). Stylebook for the Tu?bingen
partially parsed corpus of written German (Tu?PP-
D/Z). Technischer Bericht, Seminar fu?r Sprach-
wissenschaft, Universita?t Tu?bingen.
O? Se?aghdha, D. and Copestake, A. (2008). Semantic
classification with distributional kernels. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics (COLING 2008).
Pantel, P. and Lin, D. (2002). Discovering word
senses from text. In Proceedings of ACM Confer-
ence on Knowledge Discovery and Data Mining
(KDD-02).
Schu?tze, H. (1998). Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97?123.
Versley, Y. and Panchenko, Y. (2012). Not just
bigger: Towards better-quality Web corpora. In
Proceedings of the 7th Web as Corpus Workshop
(WAC-7).
Yarowsky, D. (1993). One sense per collocation. In
HUMAN LANGUAGE TECHNOLOGY: Proceed-
ings of a Workshop Held at Plainsboro.
Zhao, Y. and Karypis, G. (2005). Hierarchical clus-
tering algorithms for document datasets. Data
Mining and Knowledge Discovery, 10:141?168.
41
