BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 114?115,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Statistical Term Profiling for Query Pattern Mining
Paul Buitelaar Pinar Oezden Wennerberg, Sonja ZillnerDFKI GmbH Siemens AGLanguage Technology Lab Knowledge Management CT IC 1Saarbr?cken, Germany Munich, Germanypaulb@dfki.de pinar.wennerberg.ext@siemens.com, sonja.zillner@siemens.com
1 Introduction
Through advanced technologies in clinical careand research, especially the rapid progress in imag-ing technologies, more and more medical imaging data and patient text data is generated by hospitals, pharmaceutical companies, and medical research. For enabling advanced access to clinical imaging and text data, it is relevant to know what kind of knowledge the clinician wants to know or the que-ries that clinicians are interested in. Through inten-sive interviews and discussions with radiologists and clinicians, we have learned that medical imag-ing data is analyzed - and hence queried ? from three different perspectives, i.e. the anatomic per-spective addressing the involved body parts, theradiology-specific spatial perspective describing the relationships of located anatomical regions to other anatomical parts, and the disease perspectivedistinguishing between normal and abnormal im-aging features. Our aim is to establish query pat-terns reflecting those three perspectives that would typically be used by clinicians and radiologists to find patient-specific sets of relevant images. The context of our work is in the Theseus-MEDICO1 project on cross-modal image and in-formation retrieval in the medical domain. The focus of the work reported here is on setting up Wikipedia-based corpora of human anatomy and radiology and on obtaining a statistical profile of concepts from three semantic knowledge resourceswith these corpora: the Foundational Model of Anatomy (FMA), the radiology lexicon RadLex, and a subset of the international classification of disease codes ICD-9 CM. Using this information,we intend to extract relations that are likely to oc-cur between statistically relevant terms and the concepts they express. The final goal of our work is to derive potential query patterns from the extracted set of relations that can be used in the MEDICO semantic-based 
1 http://theseus-programm.de/scenarios/en/medico
image retrieval application. For example when re-staging head and neck lymphoma, clinicians and radiologists look for information and images that report on essential radiological patterns as ?an enlargement in the dimension of the lymph node in the neck?. Therefore, within our approach, we aim at establishing hypotheses about possible user que-ries, i.e. the query patterns that reflect the three perspectives discussed above. Accordingly, an ex-ample query pattern might look like this:
[ANATOMICALSTRUCTURE] located_in [ANATOMICALSTRUCTURE]AND[[RADIOLOGY]IMAGE]Modality] is_about [ANATOMICALSTRUCTURE]AND[[RADIOLOGYIMAGE]Modality] shows_symptom [DISEASE SYMPTOM]
Once an initial set of similar patterns has been es-tablished in this way, they will be evaluated byclinicians for their validity and relevance.
2 Corpora
A central aspect of the query pattern mining task is the statistical analysis of the FMA and RadLexterms in relevant text collections. In this way rele-vance scores can be assigned to terms that allow to investigate the most likely expressed (and hence queried) relations between them. For this purpose we need access to a representative corpus of texts that at the same time reflects the joint view of anatomy, spatial aspects of radiology and disease that we are targeting. Patient records would be our first choice, but due to strict anonymization re-quirements these are difficult to obtain. We there-fore constructed a corpus based on the WikipediaCategories Anatomy and Radiology. We then ran all text sections of each corpus through a part-of-speech tagger (Brants, 2000) to extract all nouns in the corpus and to compute a relevance score (chi-square) for each by comparing anatomy and radi-ology frequencies with those in the British Na-
114
tional Corpus. A next step will be to parse and an-notate sentences with predicate-structure informa-tion, which may then be used for relation extraction along the lines of (Schutz and Buitelaar, 2005).
3 FMA Terms
The statistically most relevant FMA terms wereidentified on the basis of chi-square scores com-puted for nouns in each corpus. Single word terms in the FMA and occurring in the corpus correspond directly to the noun that the term is build up of(e.g. the noun ?ear? corresponds to the FMA term ear). In this case, the statistical relevance of the term is the chi-square score of the corresponding noun. In the case of multi-word terms occurring in the corpus, the statistical relevance is computed on the basis of the chi-square score for each constitut-ing noun and/or adjective in the term, summed and normalized over the length of the term. Thus, the relevance value for lymph node is the summation of chi-square scores for ?lymph? and ?node? di-vided by 2. In order to take frequency in account, we further multiplied the summed relevance value by the frequency of the term. This assures that only frequently occurring terms are judged as relevant.
FMA Term Freq. Score POS
lateral 464 338724,00 JJ
anterior 452 314721,00 JJ
artery 237 281961,00 NN
anterior spinal artery 2 219894,33 JJ JJ NN
lateral thoracic artery 2 217815,33 JJ JJ NNTable 1: top FMA terms in anatomy corpus
FMA Term Freq. Score POS
artery 65 6724,00 NN
coronary artery 17 5284,00 JJ NN
small bowel 11 4651,79 JJ NN
renal artery 3 4286,50 JJ NN
pulmonary artery 1 3974,50 JJ NNTable 2: top FMA terms in radiology corpus
4 RADLEX Terms 
Analogously, RadLex was used to identify the most relevant radiology terms. The most relevant RadLex terms are shown below. As with the FMA, the most relevant RadLex terms in the anatomy corpus are centered on ?artery?. In contrast, in the radiology corpus the RadLex relevance scores in-deed point to a radiology profile: 
RadLex Term Freq. Score POS
lateral 464 338724,00 JJ
anterior 452 314721,00 JJ
artery 237 281961,00 NN
anterior spinal artery 2 219894,33 JJ JJ NN
lateral thoracic artery 2 217815,33 JJ JJ NNTable 3: top RadLex terms in anatomy corpus
RadLex Term Freq. Score POS
x-ray 253 81901,64 NN
imaging modality 6 58682,00 NN NN
volume imaging 1 57855,09 NN NN
molecular imaging 4 57850,00 JJ NN
mr imaging 9 57850,00 JJ NNTable 4: topRadLex terms in radiology cor pus
5 Conclusions and Future Work
Using ICD-9 lymphoma terminology, we will derive a Pubmed-based corpus on lymphoma to analyse the context of the statistically top most relevant terms from the FMA and RadLex termi-nologies. In this way we will be able to identify relationships and eventually query patterns across the three dimensions of anatomy, radiology and lymphoma research. 
Acknowledgments
This research has been supported in part by the THESEUS- MEDICO Project, which is funded by the German Federal Ministry of Economics and Technology under the grant number 01MQ07016. 
References 
Brants T. (2000). TnT - A Statistical Part-of-SpeechTagger. In: Proc. of the 6th ANLP Conference, Seat-tle, WALanglotz, CP. (2006). RadLex: A New Method for In-dexing Online Educational Materials In: Radiograph-ics 26, pp.1595-1597.Rosse C. and J.L.V. Mejino Jr. (2003). A reference on-tology for biomedical informatics: The FoundationalModel of Anatomy. Journal of Biomedical Informat-ics, 36(6), pp. 478?500.Schutz A., and P Buitelaar. (2005). RelExt: A Tool for-Relation Extraction in Ontology Extension In: Proc.the 4th International Semantic Web Conference, Galway, Ireland.
115
Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 27?35,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Identifying pathological findings in German radiology reports using a
syntacto-semantic parsing approach
Claudia Bretschneider1,2, Sonja Zillner1 and Matthias Hammon3
1 Siemens AG, Corporate Technology, 81739 Munich, Germany
2 University Munich, Center for Information and Language Processing, 80538 Munich, Germany
3 University Hospital Erlangen, Department of Radiology, 91054 Erlangen, Germany
{claudia.bretschneider.ext,sonja.zillner}@siemens.com,
matthias.hammon@uk-erlangen.de
Abstract
In order to integrate heterogeneous clinical
information sources, semantically correlating
information entities have to be linked. Our
discussions with radiologists revealed that
anatomical entities with pathological findings
are of particular interest when linking radi-
ology text and images. Previous research to
identify pathological findings focused on sim-
plistic approaches that recognize diseases or
negated findings, but failed to establish a holis-
tic approach. In this paper, we introduce our
syntacto-semantic parsing approach to clas-
sify sentences in radiology reports as either
pathological or non-pathological based on the
findings they describe. Although we operate
with an incomplete, RadLex-based linguistic
resource, the obtained results show the effec-
tiveness of our approach by identifying a recall
value of 74.3% for the classification task.
1 Introduction
In radiology, descriptions of the patient?s health status
are stored in heterogeneous formats. They range from
radiology images - which are the primary source for ra-
diologists - over dictated reports about the image find-
ings up to written texts.
Although the various data items describe the same
status, they are distributed in non-linked systems. This
is hindering the radiologist?s workflow. Especially
when reading reports, radiologists want to link back
from the described finding (in the text) to the related
body location (in the images). Today, they establish
the link manually. This is obviously time-consuming
when state-of-the-art imaging modalities deliver a mass
of stacked images.
In order to link radiology images and reports, each
information source needs to be annotated with seman-
tic meta-information about the anatomical entities they
describe. The necessary semantic image annotations
for the integration have been made available as a result
of the Theseus MEDICO project (Seifert, 2010). Intro-
duced algorithms automatically detect anatomical en-
tities in radiology images and annotate those with the
corresponding RadLex IDs (Seifert et al, 2009). The
semantic annotations from the reports have to be in line
with those image annotations. Therefore, the final re-
sult of the text analysis system need to be anatomical
annotations based on RadLex. We introduce a mecha-
nism that extracts those semantic annotations from the
radiology reports to enable the integration.
We identified three challenges, which a text analy-
sis system has to consider when extracting the relevant
anatomical entities from text:
1. The linguistic characteristics of the reports differ
significantly from standard free-text,
2. the underlying German linguistic resource (the
RadLex taxonomy) is incomplete and
3. only a subset of the named anatomical entities in
the reports are relevant for annotating.
First, the special linguistic characteristics of the han-
dled German reports have to be taken into account.
While the linguistic characteristics English radiology
reports have been intensively studied (Friedman et al,
1994; Friedman et al, 2002; Sager et al, 1994), Ger-
man ones are still a young research area. German re-
ports are comparable to English ones when it comes
to structural particularities. One can observe two char-
acteristics in both languages: syntactic shortness and
reduced semantic complexity. But the reports differ in
richness of the language used. German language is rich
in inflection form; the same is true for German medical
language. Additionally, clinical texts extend the vari-
ety in inflection forms by introducing a huge amount of
Greek- and Latin-rooted vocabulary. Further linguistic
particularities will be introduced in a later section.
Second, the anatomical annotations will be es-
tablished based on the controlled vocabulary of the
RadLex taxonomy. Anatomical annotations of the im-
ages (based on RadLex) are already available and hence
impose the mandatory condition to use RadLex annota-
tions for the reports. We operate on German radiology
reports that is why we use the German RadLex taxon-
omy. Compared to the English version, the German
RadLex is lacking in terminology. This is an obstacle,
we have to overcome.
Third, we have to find a way to filter relevant
anatomical annotations. According to the radiolo-
gists we worked with, it is inappropriate to extract all
27
anatomical entities from the text to link them with the
image annotations. A large portion of the anatomies
is described with normal or absent findings, which do
not describe pathologies. Those findings are included
in the reports in order to exclude differential diag-
noses. However, radiologists are interested in images
of anatomical entities described with pathological find-
ings. Thus, a crucial part of our work is to extract the
anatomical entities with pathological findings in order
to link only those with the image positions.
The core contribution of this paper is the descrip-
tion of a syntacto-semantic parsing approach to identify
the sentences that describe pathological findings by us-
ing the German version of the RadLex taxonomy. The
results of this approach are used to integrate relevant
semantic information from heterogeneous data sources
and support radiologists significantly in their work rou-
tine.
To introduce our solution, the remainder of this pa-
per is organized as follows: Section 2 refers to related
work in the field and shows where sub-problems are
still unsolved. In Section 3, we analyze the linguistic
characteristics of the reports. Section 4 introduces the
text analysis system for integrating radiology text and
images. The system handles both the linguistic partic-
ularities of the reports and the shortcomings of RadLex
as linguistic resource and filters relevant anatomical en-
tities from the reports. Section 5 evaluates and dis-
cusses the classification and extraction results. Finally,
Section 6 concludes with possible future work.
2 Related work
Medical grammar-based text analysis systems In-
formation extraction from medical texts is a well-
researched task in medical natural language processing
(Meystre et al 2008). Especially radiology reports play
an important role.
Theoretical work in the linguistic characteristics of
the medical sublanguage has been conducted on the
adaption of theories of Harris by (Friedman et al,
2002). Early systems of (Sager et al, 1994; Friedman
et al, 1994) are adaptations of the theories and imple-
ment own (context-free) medical language grammar for
radiology reports. They show that parsing of medical
texts based on a combined semantic-syntactic grammar
can be successfully conducted ? but they conducted
their research using English reports. Even today, ad-
vances in grammar-based parsing of medical texts are
reached (Fan et al, 2011).
More recently, sophisticated semantic medical text
analysis systems have integrated a component to parse
texts. (Savova et al, 2010) They take the output of the
parsing process to extract semantic relationships be-
tween the medical concepts described.
All those systems work with elaborated lexicons that
fully cover the vocabulary used in English report.
Detecting diseases and Negated finding Most sys-
tems cover the problem of detecting pathological find-
ings in the reports just partially: In order to detect
pathologies, they automate the assignment of codes for
diseases listed in ontologies such as UMLS (Aronson,
2001; Lindberg, 1990; Long, 2005) or ICD (Computa-
tional Medicine Center, 2007; Pestian et al, 2007).
Non-pathological findings are identified using nega-
tion detection algorithms. Available approaches range
from simple algorithms based on dictionary lookup and
regular expressions (Chapman et al, 2001; Mutalik et
al., 2001) through machine learning (Goryachev et al,
2006) up to advanced approaches that apply a context-
free ?negation grammar? (Huang, 2007).
Gap analysis While the grammar-based analysis of
radiology reports has proven to be successful with com-
plete lexical resources, we have to face the shortcom-
ings of an incomplete lexicon. Furthermore, in other
systems the grammar is used to analyze the syntax of
the reports. Our approach to use it for classification is
novel and has not been applied so far.
Working with German clinical texts is another chal-
lenge in the field. English texts have been made avail-
able by a number of shared tasks and gained more and
more interest in the last decade. Medical corpora in
languages other than English are not available to that
extent.
That is perhaps also the reason for the tremendous
lack of German medical ontologies. While great effort
is put into the advance of English ontologies, German
language versions are rare.
Terminology acquisition and semantic classification
Semantic classifications beyond the hierarchical infor-
mation encoded in taxonomies and ontologies are still
rare for ontology concepts. In particular, semantic clas-
sifications such as information about the pathological
nature of the concepts are missing so far.
Several approaches address this lack of semantic in-
formation: Corpus-based approaches base their meth-
ods on statistical analyses about the coverage and us-
age frequency of UMLS ontology concepts (Liu et al,
2012; Wu et al, 2012). (Johnson, 1999) derives seman-
tic classes from ontology mapping and disambiguates
multiple senses in contexts of discharge summaries.
(Campbell et al, 1999) applies pattern-based rules and
combines them with UMLS concepts to acquire new
and semantically classified terminology. However, this
approach is limited to noun phrases.
Finally, (Zweigenbaum et al, 2003) introduce ap-
proaches to automatically extending the existing En-
glish UMLS ontology with non-English concepts based
on statistical algorithms.
3 Corpus analysis
3.1 Reference corpus
Since a publicly available corpus of German radiology
reports is missing, we build our own annotated corpus
28
based on 2713 de-identified reports from our clinical
partner, the University Hospital Erlangen. The reports
result from radiology examinations of lymphoma pa-
tients and range from April 2002 to July 2007. Each
report contains two free-text sections: The first one de-
scribes findings observed in the images. In the second
sections, the radiologist provides an overall evaluation
about the findings, derives probable diagnoses and ex-
cludes differential diagnoses.
3.2 Development set of reports
From the corpus, we selected 174 reports for the devel-
opment set. They are uniformly distributed across time
and length.
The development set serves multiple purposes:
1. It is used for the linguistic analysis.
2. We use it for grammar derivation.
3. And pathology classifications and additional vo-
cabulary are learned from the sentences.
A radiologist classified each of the contained sentences
either as pathological or non-pathological. This is done
based on the characteristics of the findings described in
the sentence. Sentences describing normal or negated
findings are classified as ?non-pathological? and those
containing descriptions of abnormalities are classified
as ?pathological?. In cases where sentences include
both types of findings, they are classified as ?patholog-
ical?. Hence, each sentence in the development set was
annotated with the classification information.
3.3 Statistics of the development set
The 174 reports in the development set contain 4295
sentences of which less than half are classified as
?pathological?. This ratio is in line with the radiol-
ogists? experience. As from their intuition, the ma-
jority of the findings described in radiology reports is
noted as absent or has normal status. In the reports,
they complement pathological findings in order to note
the absence of finding and to exclude suspected dis-
eases. However, those sentences classified as ?non-
pathological? are irrelevant for our setting of linking
the containing anatomies to the images.
Table 1 shows additional results of the statistical cor-
pus analysis.
Sentence classification
non-
Corpus characteristic pathological pathological
Sentences 1943 2352
Tokens used 16437 11572
Average sentence length 8.46 4.92
Distinct word types 2398 1581
Table 1: Results of statistical corpus analysis based on
the development set
Another significant characteristic of the sentences is
their average length. Pathological sentences are about
as twice as long as non-pathological ones and thus are
more complex in their syntax. The pathology classifier
has to cover this complexity.
Furthermore, from comparing the distinct word
types used, we conclude that the description of patho-
logical findings requires a richer language than those of
normal states and absent findings in non-pathological
sentences. The linguistic resource has to cover this re-
quired rich language.
3.4 Semantic and syntactic characteristics
One of the most apparent syntactic characteristics of
the reports is the elliptical style of the sentences. The
texts are rich in omission of verbs; verbs are dispens-
able as they only underline the absence or presence
of symptoms. An example that illustrates the facts is
shown below.
General language
In der Lunge sind keine Ergu?sse zu finden.
In the lung, there are no effusions found.
Radiologist?s style
Lunge: Kein Erguss.
Lung: No effusions.
The observation of the syntactic structure of the sen-
tences is in line with (Friedman et al, 2002) and will
simplify the classification of the sentences.
The second observation we made is that the medical
language uses a high amount of domain-specific vocab-
ulary. This vocabulary is rarely used in every-day lan-
guage and is highly connected with (implicit) medical
domain knowledge. Thus, the linguistic handling of
the reports requires a domain-specific lexicon. Further-
more, the vocabulary can be categorized into only a few
semantic classes representing the content, such as mea-
surements, dates, anatomies, modifier of the anatomies,
diseases, etc.
Third, one feature of the medical language is very
domain-specific: It uses a high amount of Greek- and
Latin-rooted words. This is important, because those
terms follow their own specific inflection forms. Fur-
thermore, for many terms there exist both German and
Latin-/Greek-rooted descriptions which are used inter-
changeably (e.g. descriptions of anatomical entities or
diseases). However, most lexicons only contain a sin-
gle term - not the complete list of synonyms.
Like the German language, the medical lan-
guage is also rich in compound terms such as
Nasenseptumdeviation (deviation of the nasal septum)
or Glukosestoffwechselsteigerung (increase in glucose
metabolism). Especially radiologists use a high num-
ber of compounds to describe pathological findings.
They will be of particular importance for the identifi-
cation of pathological findings. In many cases, only
after determining the pathology classification of each
29
subtoken, the classification of the compound can be de-
termined.
Systems that mine information from radiology re-
ports have to consider the named syntactic and se-
mantic characteristics and handle them as language-
specifics. In particular, the short length of the sentences
simplifies the development of a grammar with a limited
number of rules.
4 Methods
4.1 Grammar-based classification approach
Based on the observations from the corpus analysis,
we derive and apply a semantic context-free grammar
(CFG) to classify sentences.
Using a grammar to classify the sentences may not
seem intuitive for every-day language sentences. Nev-
ertheless, the language used in radiology reports allows
this approach. There are several facts that support the
usage of a grammar.
1. The structure of the sentences created by radiol-
ogists differs significantly from the structure of
general German language. To model this language
an own (sublanguage) grammar is necessary.
2. Since the sentences are short in length, a relatively
small number of grammar rules can represent their
syntax. In particular, the omission of verbs allows
us to create and use a simplified grammar.
3. As already researched by (Friedman et al, 2002),
the sentences contain a limited number of seman-
tic classes which are combined into few rules.
These observations support the approach to create a
grammar with few rules to classify the sentences.
4.2 Overview of the building blocks of the text
analysis system
After having analyzed the linguistic characteristics, we
designed a text analysis system to extract the rele-
vant information from the reports. The classification is
based on a grammar whose components are setup first:
The grammar rules are created and lexicon is setup.
To overcome the incompleteness of the lexicon and to
enhance the grammar with probabilities, we introduce
an additional learning step. These first three steps can
be regarded as preparation steps for the subsequent in-
tegration steps: Finally, the system is able to classify
report sentences and extracts anatomical annotations
from the sentences classified as ?pathological?. In the
end, the semantic annotations from text and images are
linked across the data sources. The described steps of
the target system are shown in Figure 1.
This paper focuses on the details of the created gram-
mar: how the parsing algorithm is adapted to learn new
linguistic knowledge and how the probabilistic parsing
algorithm is used to derive a classification for an input
sentence.
Derive
grammar
Create
lexicon
Learn
from the
development set
Preparation steps
Classify
Extract
and
Link
Integration steps
Figure 1: Processing steps in text analysis system
The following sections describe the details of the in-
dividual processing steps.
4.3 Derive grammar
The core component of the text processing system is
the grammar. Our grammar has two functions:
1. It is used to describe the structure of a given input
sentence, and
2. using the results of the parsing process, an input
sentence can be classified as either ?pathological?
or ?non-pathological?.
We use a semantic grammar for the description of
the syntactic structure of the sentences. That means,
instead of mapping syntactic categories from part-
of-speech tags as non-terminal symbols, we use se-
mantic representations of the content. E.g., the term
Niere [spleen] gets assigned the non-terminal symbol
ANATOMIE.
Following the proposal of (Friedman et al, 1994),
we create semantic classes that represent the content
of the radiology reports. However, we do not need
their fine-grained semantic class definition. Our task of
pathology classification requires only a reduced num-
ber of classes. We drop classes that do not change the
pathology classification result (such as degree, quan-
tity, technique, etc.) and introduce the generalized se-
mantic classes MOD (modifier) and TERM. The list of
semantic classes derived is shown in Table 2.
The grammar has to fulfill one condition to be able to
classify sentences. Only non-terminal symbols used for
classification are directly derived from the start symbol
(S). We use the non-terminal symbols PATH for clas-
sifying sentences as ?pathological? and NOPATH for
classifying as ?non-pathological?. Hence, the following
unary rules designate the classification in our grammar:
S ? PATH
S ? NOPATH
Any subsequent rules have to be hierarchically embed-
ded into those rules.
During the subsequent (manual) grammar derivation
process, we use the listed semantic classes as non-
terminal symbols and derive the grammar rules from
30
Structural non-terminals
ROOT
S
KOMMA
ENUM
FIND CONNECT
Classification non-terminals
PATH Constituents
(sentence-level,
modifier and term)
with pathology
classification
information
NOPATH
MOD PATH
MOD NOPATH
TERM PATH
TERM NOPATH
FINDING NOPATH
FINDING PATH
Semantic non-terminals
LOCATION
Non-terminals
representing
constituents with
specific semantic
meaning
DATE
MEASUREMENT
ANATOMIE
NEGATION
DISEASE
Linguistic non-terminals
ARTICLE Article non-terminal
ARTICLE GENITIV
PREP DATE Preposition
non-terminals
indicating different
semantic units
PREP LOCATION
PREP MEASUREMENT
Mapping semantic class - regular expression
DATE VALUE
MEASUREMENT VALUE
IMAGE VALUE
Table 2: List of semantic non-terminals
the development corpus. Because of the limited num-
ber of semantic classes and the elliptical sentence style,
a small set of 238 grammar rules suffices to describe
the sentence syntax. The resulting grammar rules con-
sider the syntactic complexity of the sentences describ-
ing pathological findings: 52% of the rules model the
constituent structure of pathological sentences.
4.4 Create lexicon
The linguistic resource of our system is a lexicon, cre-
ated based on the German version of the RadLex tax-
onomy.
RadLex (RSNA, 2012) is a taxonomy published by
the Radiological Society of North America (RNSA) in
order to deliver a uniform controlled vocabulary for in-
dexing and retrieval of radiology information sources.
The current English version 3.8 contains 39976 classes.
A German version has been worked-out (Marwede et
al., 2009) in 2007. The contained terms are organized
in 13 major categories: anatomical entity as one among
others such as treatment, image observation and imag-
ing observation characteristics. But as the development
of the German language version has been stopped, the
latest version 2.0 contains only a subset of classes
(n=10003). This lack in terminology is an obstacle to
overcome.
Linguistic resource From the German RadLex we
created a lexicon (n=9479), which we use as linguistic
resource. Each entry is represented by a list of proper-
ties.
Besides the structural properties label and RID, we
apply several steps of linguistic and semantic process-
ing to enrich the lexical entries. The normalized stem
of each entry results from an own tokenization, normal-
ization and stemming algorithm.
The normalization aligns German and Latin style
spellings (e.g. Karzinom/Carzinom, Okzipitallappen/-
Occipitallappen). The stemmer adapts the German
Porter stemmer and incorporates additional rules for
suffixes and inflection that are derived from Latin and
Greek. E.g., this extension enabled the mapping of Me-
diastinum and mediastinal to the same stem mediastin-,
which would not have been possible with the German
Porter stemmer.
Furthermore, during lexicon setup each entry is en-
riched with semantic classification information. The
semantic class is used during parsing. We use rea-
soning methods and the hierarchical is-a structure of
the RadLex taxonomy in order to deduct a semantic
class for each entry from the major categories. For ex-
ample, this mechanism enables us to assign to deduct
the semantic class ANATOMIE for sub-entities of the
major category ?Anatomical entity? (such as Prostata
[prostate]).
We apply a similar reasoning mechanism for the
pathology classification. As the lexicon entries are ini-
tially unclassified according to their pathological in-
formation, we analyzed them and found the following
mechanism: It is feasible to classify each of the major
categories unambiguously either as ?pathological? or
?non-pathological?. For example, entries with semantic
class ANATOMIE are classified as ?non-pathological?.
This pathological classification information is added to
10 out of 13 major RadLex categories and inferred to
all hyponyms. For three of the categories, the classifi-
cation is ambiguous. The determination of the pathol-
ogy classification results in the distribution shown in
Table 3.
Classification #
non-pathological 6001 63.3%
pathological 1714 18.1%
not to be determined 1764 18.6%
9479 100%
Table 3: Results of the initial pathology classification
of RadLex-based lexicon entries
The algorithm is able to classify 81.4 % of the lexicon
31
S? PATH
S? NOPATH
PATH? FIND PATH
NOPATH? FIND NOPATH
FIND PATH?MOD PATH ANATOMIE
FIND NOPATH?MOD NOPATH ANATOMIE
? ? vergro??ert
ANATOMIE? Prostata
Vergro??erte
(enlarged)
Prostata
(prostate)
MOD PATH MOD NOPATH ANATOMIE
FIND PATH
PATH
FIND NOPATH
NOPATH
S
Figure 2: Learning lexical knowledge from sentence Vergro??erte Prostata (enlarged prostate)
entries. We have to find a way to classify the remain-
ing unclassified entries. Only when all the lexical en-
tries are classified, the sentence classification algorithm
produces reliable results.
The finally derived lexical resource contains 9479
entries with 23588 tokens of which 6326 are distinct.
Comparing this number with the distinct word types
used in the development set (n=3172), one assumes that
the lexicon could cover the vocabulary used in the re-
ports. However, this is not the case. Important terms
that occur quite frequently in the development set and
have high relevance for the pathology classification are
either not included in the lexicon (e.g. La?sion/lesion)
or are included but are not classified (e.g. sklerosiert |
RID 5906 [sclerosing]).
That is why we argue that an additional corpus-based
learning step to extend the vocabulary and its classifi-
cation is mandatory.
4.5 Learn from the development set
We introduce an additional learning step to extend the
lexicon with missing items and to classify existing
item missing a pathology classification. At the same
time, the probabilities of the grammar rules are trained
during this step. The learning is conducted using an
adapted probabilistic CKY algorithm.
Extending the lexical resource How parsing is
adapted to learn from the sentences is illustrated in Fig-
ure 2. The sentence Vergro??erte Prostata [Enlarged
prostate] is input to the learning. From the sentence?s
annotation, we know that this sentence describes a
pathological finding (PATH). The subset of the gram-
mar necessary to parse this sentence is shown on the
left-hand side of the figure. The non-terminal mapping
of the words is shown below the grammar rules. Cur-
rently, only the mapping of the word Prostata to the
non-terminal symbol ANATOMIE can be derived from
the lexicon. Mapping vergro??ert is not possible. The
lexical entry has a semantic classification (Modifier) as-
signed, but no pathology classification. However, in
this case both information items are necessary to deter-
mine the non-terminal mapping. In order to learn the
missing pathology classification of this word, we apply
an adapted CKY parsing algorithm.
The standard CKY algorithm (Kasami, 1965) oper-
ates bottom-up and uses two complete components to
determine the parse tree of a given input sentence:
1. A complete lexicon to determine the non-terminal
mapping of the words, and
2. a complete list of all grammar rules.
Our setting is missing the complete lexicon. That is
why we adapt the standard algorithm and introduce a
top-down analysis in order to extend the linguistic re-
source while parsing.
There are two possible non-terminal mappings for
the word vergro??ert: MOD PATH (indicating a mod-
ifier for pathologies) or MOD NOPATH (indicating a
modifier not describing pathologies). Both of the op-
tions are used to determine the parse tree of the sen-
tence. The ambiguity is resolved at the top-most pars-
ing level: The sentence is annotated as ?pathological?,
hence, only rewritings that include the corresponding
non-terminal symbol PATH are allowed. Finally, the
parse tree of the sentence can be derived (as shown in
Figure 3).
S
PATH
FIND PATH
MOD PATH
Vergro??erte
(enlarged)
ANATOMIE
Prostata
(prostate)
Figure 3: Parse tree derived from sentence Vergro??erte
Prostata (Enlarged prostate)
In addition, the (formerly unknown) non-terminal
mapping of the word vergro??ert to MOD PATH is de-
ducted from the parse tree and the corresponding lexi-
cal entry is updated. Using this algorithm, we are also
able to learn vocabulary that was not available in the
lexicon before.
32
Training the grammar?s probabilities The parse
tree is also used as input for extending the grammar
to a probabilistic context-free grammar. Each of the
grammar rules used to form the parse tree is used to
re-calculate the probabilities of the grammar rules.
After the learning step, the lexicon is extended to
10344 entries (before 9479). But even more impor-
tant, the overall amount of lexicon entries classified as
?pathological? increased by 18.8 % to now 2036 entries
(before 1714). We consider this a key success of the
learning, as our classification depends on this encoded
knowledge.
4.6 Classify
After conducting the previous steps,
1. the extended lexicon,
2. the trained P-CFG, and
3. the standard probabilistic CKY parsing algorithm
are applied to parse unclassified sentences.
The sentence classification is conducted based on the
lexicon and the grammar rules. The lexicon helps to as-
sign non-terminal symbols to the words in the sentence.
Depending on non-terminal symbols assigned and the
grammar rules applied during the subsequent parsing
process, the parse tree will reveal the classification of
the sentence.
As parsing algorithm we apply the standard prob-
abilistic CKY (P-CKY) algorithm. It resolves both
syntactic and classification ambiguities. In case, the
sentence contains unknown words, the probabilistic
parsing feature helps to disambiguate the non-terminal
assignment. The derived parse tree describes both
the syntactic structure of the sentence and the derived
pathology classification.
4.7 Extract and Link
Finally, in case a sentence is classified as ?patholog-
ical?, the contained anatomical entities are extracted.
The sentences are annotated with the extracted anatom-
ical information. An external system combines the
anatomical annotations from images and reports. Thus,
links are created successfully and the correlating im-
age positions for pathological findings can be accessed
from the text.
5 Evaluation
We evaluate the classification system using 40
randomly-chosen reports containing 1296 sentences.
5.1 Precision and recall measurements
We evaluate the classification results and the success
of the alignment of radiology reports and images using
precision and recall values. Only for sentences classi-
fied as ?pathological?, the contained anatomical entities
are extracted and anatomical annotations are created.
That is why we prefer high recall values. If sentences
are misclassified as ?pathological? ? although they de-
scribe non-pathological findings (FP) ? this is a minor
issue. This misclassification results in alignment of
anatomical entities in text and images without patho-
logical findings. We accept lower precision values that
yield those additional, but not intended alignments.
5.2 Baseline evaluation
We compare the evaluation results of the classifica-
tion system with the results of a semantically-informed
baseline algorithm. This algorithm detects nega-
tions and classifies the containing sentences as ?non-
pathological?. Sentences containing diseases (deter-
mined based on Latin suffixes such as -itis, -ose, etc.)
or a pathological RadLex concepts (as determined dur-
ing the lexicon creation step) are classified as ?patho-
logical?. Any remaining sentences are assumed to de-
scribe non-pathological findings.
The results of the baseline classification are shown
in Table 4. The headings denote ?non-pathological?
sentences (NOPATH) respectively ?pathological? sen-
tences (PATH).
expected classification
PATH NOPATH
observed PATH 17 0
classification NOPATH 446 833
Table 4: Classification results using baseline algorithm
This baseline approach has the advantage of 100% pre-
cision value. However, it produces a low recall value
of 3.67 %, which shows that this approach is not appli-
cable for the alignment of text and images. The results
show that the identification of pathologies is not feasi-
ble by only using (1) suffixes to determine diseases and
(2) available pathology descriptions from the RadLex
taxonomy.
5.3 Evaluation of the parsing-based classification
results
Table 5 shows the system results of classifying the 1296
report sentences using the syntacto-semantic parsing
approach.
expected classification
PATH NOPATH
observed PATH 344 288
classification NOPATH 119 545
Table 5: Sentence classification results using syntacto-
semantic parsing approach
Taking into account the impact of the (still) incom-
plete lexicon, the recall value of 74.3 % indicates that
the chosen approach to classify pathological sentences
is successful. However, the precision value of 54.4 %
33
indicates that the classification of almost half of the
?pathological? sentences is incorrect.
Compared to the baseline, the acquisition of addi-
tional, pathology classified vocabulary and its incorpo-
ration into a parsing-based approach significantly im-
proves the recall value. That is why we regard the en-
richment of the lexicon at the crucial step for (further)
improvement of the classification results. However, a
large amount of sentences was classified incorrectly as
?pathological?. The error analysis will reveals some
causes.
5.4 Error analysis
We identified four error types that produce incorrectly
classified results.
1. Some of the pathology classification of the seman-
tic knowledge acquired during learning is incor-
rect.
Terms that do not describe pathological proper-
ties such as Voraufnahme [previous examination]
or Lymphknoten [lymph node] were classified as
?pathological?; also, pathological findings such as
La?sion [lesion] or Infiltrat [infiltrate] could not be
classified correctly. Because of their high usage
frequency (26, 116, 20, 7 times), these four terms
are accountable for 169 of the misclassified sen-
tences (both FP and FN) from the evaluation.
The disambiguation of (word-level) pathology
classification using sentence-level annotations is
obviously very vague and imprecise. In order to
improve the terminology acquisition results, we
will include distribution information and proba-
bilistic features into the learning process as future
work.
2. The terminology acquisition leads to an extended
lexicon, but still, terminology remains uncovered.
In particular, the description of pathological find-
ings requires a richer language, its lack inhibits
their correct classification. Even though our cor-
pus is limited to reports of lymphoma patients
(i.e., contains limited medical vocabulary), still,
the test set contains vocabulary that is not used in
the training set. For a further elaborated lexicon,
the training set has to be extended in size and also
in content.
3. Furthermore, the majority of long sentences is
not successfully parsed because of missing gram-
mar rules. Those long sentences are more likely
describing pathological findings, which leads to
false negatives. We found that sentences longer
than 8 tokens are rather incorrectly classified than
correctly; nevertheless, this concerns only 8 %
(99/1296) of all sentences. Thus, we regard this
as a minor issues.
4. Finally, our assumption of covering the seman-
tics with a limited number of non-terminals was
disproven. The oversimplification of semantic
classes is insufficient to parse the complex sen-
tence structures in the reports. In particular, the
structure of long sentences requires a wider range
of non-terminals (and more grammar rules) in or-
der to disambiguate the pathology classification.
E.g., the defined semantic classes do nor distin-
guish modifiers of locations or size for anatomi-
cal entities or temporal modifier for pathologies.
Their introduction will increase the resolution of
dependencies in complex sentences and the over-
all classification.
The learning step is the crucial step for improvement
of the classification results. It enriches the vocabulary.
If the pathology classification of the learned vocabulary
is optimized, the system will deliver even better results.
The optimization of the vocabulary learning step will
be future work.
6 Conclusion
We designed and implemented a system that aligns
findings from radiology reports to findings in images
based on semantic annotations. Providing the system,
we assume to reduce the time necessary to find corre-
lating descriptions of one finding in heterogeneous data
sources.
We build our system on tailored NLP algorithms
that extract relevant anatomical annotations with patho-
logical findings. To identify sentences that describe
pathological findings, we introduce a new, semantic
grammar-based classification approach. To bridge the
gap of the incomplete German terminology, a vocabu-
lary acquisition step is introduced. Incorporating this
newly learned vocabulary, the grammar-based classifi-
cation delivers a recall value of 74.3%.
We identified a major issue relevant for further work
on German clinical texts: The evaluation results reveal
a large gap in coverage between the vocabulary used in
non-English radiology texts and the controlled vocabu-
lary delivered by RadLex. Furthermore, we believe that
lexicons will be crucial resources for language process-
ing in the medical domain. We will focus our future
work on enriching existing lexicons and establishing
new resources for linguistic analysis.
Acknowledgements
This research has been supported in part by the THE-
SEUS Program in the MEDICO Project, which is
funded by the German Federal Ministry of Economics
and Technology under grant number 01MQ07016. The
responsibility for this publication lies with the authors.
References
A. R. Aronson. 2001. Effective mapping of biomedi-
cal text to the UMLS Metathesaurus: the MetaMap
program. Proc AMIA Symp, 17?21.
34
D. A. Campbell, S. B. Johnson. 1999. A technique
for semantic classification of unknown words using
UMLS resources.. Proc AMIA Symp, 716?20.
W. W. Chapman, W. Bridewell, P. Hanbury, G. F.
Cooper, and B. G. Buchanan. 2001. A simple algo-
rithm for identifying negated findings and diseases
in discharge summaries. J Biomed Inform, 34:301?
310.
W. W. Chapman, W. Bridewell, P. Hanbury, G. F.
Cooper, and B. G. Buchanan. 2001. Evaluation of
negation phrases in narrative clinical reports. Proc
AMIA Symp., 105-109.
Computational Medicine Center. 2007. Inter-
national Challenge: Classifying Clinical Free
Text Using Natural Language Processing..
http://www.computationalmedicine.
org/challenge/index.php.
J. W. Fan and C. Friedman. 2011. Deriving a proba-
bilistic syntacto-semantic grammar for biomedicine
based on domain-specific terminologies.. J Biomed
Inform, 44(5):805?14.
C. Friedman, P. O. Alderson, J. H. M. Austin, J. J.
Cimino, and S. B. Johnson. 1994. A General
Natural-Language Text Processor for Clinical Radi-
ology. J Am Med Inform Assoc, 1:161?174.
C. Friedman, P. Kra, and A. Rzhetksy. 2002. Two
biomedical sublanguages: a description based on the
theories of Zellig Harris. J Biomed Inform, 35:222?
235.
S. Goryachev, M. Sordo, Q. T. Zeng, and L. Ngo.
2006. Implementation and evaluation of four differ-
ent methods of negation detection.. Technical report,
DSG.
Y. Huang and H. J. Lowe. 2007. A Novel Hybrid
Approach to Automated Negation Detection in Clin-
ical Radiology Reports. J Am Med Inform Assoc,
14:304?311.
S. B. Johnson. 1999. A semantic lexicon for medi-
cal language processing.. J Am Med Inform Assoc,
6(3):205-18.
T. Kasami. 1965. An efficient recognition and syntax-
analysis algorithm for context-free languages. Sci-
entific Report AFCRL-65-758, Air Force Cambridge
Research Lab.
C. Lindberg. 1990. The Unified Medical Lan-
guage System (UMLS) of the National Library of
Medicine.. J Am Med Rec Assoc, 61(5):40?42.
H. Liu, S. T. Wu, D. Li, S. Jonnalagadda, S. Sohn, K.
Wagholikar, P. J. Haug, S. M. Huff, and C. G. Chute.
2012. Towards a semantic lexicon for clinical nat-
ural language processing.. AMIA Annu Symp Proc,
568-576.
W. Long. 2005. Extracting diagnoses from discharge
summaries. AMIA Annu Symp Proc, 470?4.
D. Marwede, P. Daumke, K. Marko, D. Lobsien, S.
Schulz, and T. Kahn. 2009. RadLex - German
version: a radiological lexicon for indexing image
and report information. Fortschr Ro?ntgenstr, 181(1):
38?44.
S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler,
and J. F. Hurdle. 2008. Extracting Information from
Textual Documents in the Electronic Health Record:
A Review of Recent Research. Yearb Med Inform,
24(11):128?144.
P. G. Mutalik, A. Deshpande, P. M. Nadkarni. 2001.
Use of general-purpose negation detection to aug-
ment concept indexing of medical documents: a
quantitative study using the UMLS.. J Am Med In-
form Assoc, 8(6):598?609.
J. P. Pestian, C. Brew, P. Matykiewicz, D. J. Hover-
male, N. Johnson, K. B. Cohen, and W. Duch. 2007.
A Shared Task Involving Multi-label Classification
of Clinical Free Text.. BioNLP 2007: Biological,
translational, and clinical language processing..
Radiological Society of North America. 2012.
RadLex. http://rsna.org/RadLex.aspx.
N. Sager, M. Lyman, C. Bucknall, N. Nhan, and L. J.
Tick. 1994. Natural Language Processing and the
Representation of Clinical Data. J Am Med Inform
Assoc, 1:142?160.
G. K. Savova, J. J. Masanz, P. V. Ogren, J. Zheng,
S. Sohn, K. C. Kipper-Schuler, and C. G. Chute.
2010. Mayo clinical Text Analysis and Knowledge
Extraction System (cTAKES): architecture, compo-
nent evaluation and applications.. J Am Med Inform
Assoc, 17(5):507?13.
S. Seifert. 2010. THESEUS-
Anwendungsszenario MEDICO. http:
//www.joint-research.org/
das-theseus-forschungsprogramm/
medico/.
S. Seifert, A. Barbu, K. Zhou, D. Liu, J. Feulner, M.
Huber, M. Suehling, A. Cavallaro, and D. Comani-
ciu. 2009. Hierarchical Parsing and Semantic Nav-
igation of Full Body CT Data. SPIE Medical Imag-
ing.
S. T. Wu, H. Liu, D. Li, C. Tao, M. A. Musen, C. G.
Chute, N. H. Shah. 2012. Unified Medical Lan-
guage System term occurrences in clinical notes: a
large-scale corpus analysis.. J Am Med Inform As-
soc, 19(1):149?56.
P. Zweigenbaum, R. Baud, A. Burgun, F. Namer, E.
Jarrousse N. Grabar, P. Ruch, F. Le Duff, B. Thirion,
and S. Darmoni. 2003. UMLF: a Unified Medical
Lexicon for French. AMIA Annu Symp Proc, 1062.
35
Proceedings of Third Workshop on Semantic Web and Information Extraction, pages 1?8,
Dublin, Ireland, 24 August, 2014.
Corpus-based Translation of Ontologies for Improved Multilingual
Semantic Annotation
Claudia Bretschneider
1,2
, Heiner Oberkampf
1,3
, Sonja Zillner
1
, Bernhard Bauer
3
, Matthias Hammon
4
1
Siemens AG, Corporate Technology, Munich, Germany
2
Center for Information and Language Processing, University Munich, Germany
3
Software Methodologies for Distributed Systems, University Augsburg, Germany
4
Department of Radiology, University Hospital Erlangen, Germany
{claudia.bretschneider.ext,heiner.oberkampf.ext,sonja.zillner}@siemens.com,
bernhard.bauer@informatik.uni-augsburg.de, matthias.hammon@uk-erlangen.de
Abstract
Ontologies have proven to be useful to enhance NLP-based applications such as information ex-
traction. In the biomedical domain rich ontologies are available and used for semantic annotation
of texts. However, most of them have either no or only few non-English concept labels and can-
not be used to annotate non-English texts. Since translations need expert review, a full translation
of large ontologies is often not feasible. For semantic annotation purpose, we propose to use the
corpus to be annotated to identify high occurrence terms and their translations to extend respec-
tive ontology concepts. Using our approach, the translation of a subset of ontology concepts is
sufficient to significantly enhance annotation coverage. For evaluation, we automatically trans-
lated RadLex ontology concepts from English into German. We show that by translating a rather
small set of concepts (in our case 433), which were identified by corpus analysis, we are able to
enhance the amount of annotated words from 27.36 % to 42.65 %.
1 Introduction
Ontologies offer a powerful way to represent a shared understanding of a conceptualization of a domain
(Gruber, 1993a). They define concepts and relations between them. Further linguistic information, such
as labels, synonyms, abbreviations or definitions, can be attached. This is how ontologies provide a con-
trolled vocabulary for the respective domain. In Information Extraction (IE), the controlled vocabulary
of ontologies is used to recognize ontology concepts in text (also referred to as semantic annotation) and
combine the textual information and the ontological knowledge to allow a deeper understanding of the
text?s semantics.
The problem, however, is that most of the available ontologies are not multilingual, i.e., they have ei-
ther no or only few non-English concept labels. To make ontologies applicable for IE-based applications
dealing with non-English texts, one has to translate at least some of the concept labels. Since high quality
translations need expert review, a full translation of big ontologies is often not feasible. In the biomedical
domain, ontologies have a long tradition and many well designed, large and semantically rich ontologies
exist. At the time of writing, the BioPortal (Noy et al., 2008), an ontology repository for the biomedical
domain, contains 370 ontologies, where 49 have more than 10,000 concepts. Their complete translation
would be very costly.
In many application scenarios, only a subset of ontology concepts is of relevance. This is especially
true for IE: If we consider, e.g., the semantic annotation of medical records in the context of a specific
disease, the translation of a subset of ontology concept labels can be sufficient to increase the number
of ontology concepts found. Thus, the translation of a small set of labels, which is relevant for the
application scenario, is sufficient to increase the ontology?s applicability for IE from non-English texts.
That is why we propose a translation approach that identifies the most relevant concepts for the ap-
plication scenario and adds their translations to the ontology. The application scenario is represented
by the corpus, a ?large set of domain-specific text?. In the context of IE, the main goal is to achieve a
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1
high annotation coverage, i.e., a high amount of words are semantically annotated with the correlating
ontology concepts. Therefore, we define the terms with high frequency in the corpus as most relevant for
translation, as the translation of high frequency terms increases the annotation coverage significantly. To
demonstrate the feasibility of our approach, we use the RadLex ontology (Langlotz, 2006) and a corpus
of German radiology reports of lymphoma patients.
2 Related Work
Ontology-based IE is a commonly used technique in the biomedical domain. (Meystre et al., 2008) give
a detailed overview of recent research activities. However, most projects focus on English texts. The
ontology translation problem was first described by (Gruber, 1993b) and further formalized by (Espinoza
et al., 2009b). The subproblem we are dealing with is ontology localization, which (Su?arez-figueroa and
G?omez-P?erez, 2008) refers to as ?the adaptation of an ontology to a particular language and culture?. The
challenges of ontology localization are analyzed in (Espinoza et al., 2009b) and a general methodology
for guiding the localization process is presented. By (Cimiano et al., 2010), ontology localization can
affect two different layers: the lexical layer (labels, definitions and accompanying documentation in
natural language) and the conceptualization itself. Thus, the translation of concept labels we conduct
can be seen as a subtask of ontology localization targeting only the lexical layer. The focus of our
work does not lie in the machine translation task itself but in the intelligent use of existing resources for
multilingual extension of ontologies with the aim to enhance the annotation coverage for a certain corpus.
(Espinoza et al., 2009a) focus on sense disambiguation as major problem in ontology localization, while
we investigate how to increase the efficiency by incorporating a corpus.
3 Overview of the approach
As explained, our main goal is to enhance the annotation coverage of a given non-English corpus by on-
tology translation. Using the corpus to be annotated within the translation process has three advantages:
? The translation is conducted more efficiently, since we reduce the number of translations that require
a review. This is because only concepts that actually occur in the corpus are proposed as translations.
? The process results in high quality translations, because the corpus can be used to disambiguate the
correct (target) translation candidate for a concept automatically.
? By facilitating a corpus, we make sure that the terms extracted as (target) translation candidates
result in semantic text annotations in the end.
Figure 1 illustrates the approach: Based on the corpus information, ?L?asion? is added as German trans-
lation to the ontology concept with RID38780. Now, the corpus term can be annotated, which was not
possible before.
RID58 Preferred name ?liver?. RID38780 Preferred name
RID58 Synonym ?Leber?. ?lesion?.
RID38780 rdfs:label ?L?asion?@de.
1 Corpus Analysis
2 Concept Filtering
3 Mapping Corpus Terms
to Ontology Concept
E
x
t
e
n
d
e
d
R
a
d
L
e
x
R
a
d
L
e
x
... Leber ohne fokale L?asion ...
... Leber ohne fokale L?asion ...
+
Figure 1: The text Leber ohne fokale L?asion ?Liver without focal lesion? from a large medical corpus is
processed and a new translation is added to the ontology to increase the number of semantic annotations.
2
The system designed makes use of this rationale and implements an approach that operates in three
steps (as illustrated in Figure 2) for translating the ontology vocabulary:
Input resources
A
B
C
A Ontology to be extended
B Domain-specific corpus
C Translation dictionaries
Linguistic Analysis
Semantic Annotation
N-Gram Calculation
Statistics
N-gram Filtering
Dictionary lookup
Concept Mapping
D
Output resource
D Extended ontology
1 Corpus Analysis
2 Concept Filtering
3 Mapping Corpus Terms
to Ontology Concept
Figure 2: Processing steps in text analysis system
@prefix rdfs:
<http://www.w3.org/2000/01/rdf-schema#> .
@prefix radlex:
<http://www.owl-ontologies.com/
Ontology1375951364.owl#> .
radlex:RID58
rdfs:subClassOf radlex:RID13419 ;
radlex:Preferred_name "liver"??xsd:string ;
radlex:Synonym "Leber"??xsd:string ;
radlex:RID38780
rdfs:subClassOf radlex:RID34300 ;
radlex:Preferred_name "lesion"??xsd:string ;
rdfs:label "L
?
asion"@de.
Figure 3: (Incomplete) RDF representation of
the RadLex concept radlex:RID58 with German
translation ?Leber? as currently maintained as
radlex:Synonym and concept radlex:RID38780
with translation ?L?asion? and proposed repre-
sentation using rdfs:label and language tags
1 Corpus Analysis The initial processing step is designed to make use of the corpus to find the high fre-
quency terms. Using this resource allows us to customize our approach for the required application
scenario. Its content is used to digest the most relevant concepts for translation and determine the
correct translation option. The processing incorporates linguistic and statistical NLP techniques to
extract terms in target language with high frequency from the corpus.
2 Concept Filtering As the list of extracted terms still includes terms without semantic importance,
we introduce this step in order to reduce the list. This includes the removal of terms with certain
technical characters but also those with special linguistic structures, which makes the approach more
efficient.
3 Mapping Corpus Terms to Ontology Concepts Our approach is targeted to translate only existing
ontology concepts. Thus, we need a mechanism to map the terms of the corpus to the ontology
concepts. We do this by employing state-of-the-art dictionary lookups: The English dictionary
equivalences of the German corpus terms are used to find ontology concepts with the same English
labels. Then, the (corpus) term is added as translation to the matching ontology concept as non-
English label. The resulting translated ontology can be used in subsequent NLP-based applications
and is able to serve the need for non-English texts.
In the end, the ontology will be extended with translations. In our case, the RadLex ontology currently
maintains translations as synonyms, but we propose the usage of rdfs:label and language tags as shown
in Figure 3. The introduced steps are described in detail in the following sections.
4 Corpus-Based Analysis and Concept Filtering
4.1 Corpus Description
One of the core resources for the approach is a domain-specific corpus. Combined with the ontology to
be translated it serves several purposes: On the one hand, based on IE techniques we find and extract
3
translations from the corpus in order to extend the ontology?s vocabulary. Further, we use the corpus as
semantic annotation target, which is annotated with ontology terms. The language-specific translations
used for semantic annotation were found before with the help of the corpus itself. For the study, we use
a corpus of 2,713 radiology reports (from 27 different readers
1
) of lymphoma patients containing the
findings and evaluation sections.
4.2 Linguistic Analysis
This initial analysis includes several steps that enable a statistical analysis of the textual context. Each of
the processing steps is implemented as a single UIMA annotator and integrated into an overall pipeline.
First, semantic information units such as dates and measurements are recognized using regular ex-
pressions. Medical language is rich in abbreviations. Particularly radiologists make use of them, because
they allow an efficient reporting. Therefore, as second step, we build an abbreviation recognition and
extension algorithm on a simple dictionary. The third linguistic task is the determination of the basic
processing units: (1) tokens and (2) sentences. Tokens are split employing the spaces and ?-? in the
text, hence no compound splitting is conducted. While token splitting is a rather simple task, sentence
splitting requires disambiguation facilities. Indicators like ???,?!?,?;?,?.? are used to determine sentence
ends. However, the full stop determines sentence ends only if they are not part of a measurement, date or
abbreviation. As a fourth step, stopwords are removed from the documents to reduce the content to only
relevant tokens. Available language-dependent stopword lists are employed. Finally, each of the tokens
in the text is stemmed with the German version of the Porter stemmer. (Porter, 1997)
4.3 Semantic Annotation
Since most ontologies are already partially translated, we make use of this fact and semantically annotate
concepts and exclude them in the subsequent filter process (Section 4.6). The annotator implementation
is based on the UIMA ConceptMapper (Tanenblatt et al., 2010). The annotation dictionary is built
from the preferred names and synonyms in the RadLex ontology (as shown in Figure 3). Our concept
mapper combines the stems of the dictionary terminology and the stems of the text tokens and annotates
the matches with the ontology information. If a dictionary term consists of more than one token, an
annotation is created if all of its stems are contained in a single sentence of the corpus. That is also how
single tokens can be assigned more than one annotation.
4.4 N-Gram Calculation
After the linguistic processing of the preceding steps, the actual term extraction can be performed. In
this initial work, we limit the length of n-grams to three because of performance reasons. Furthermore,
we define that the individual tokens of an n-gram have to co-occur within the same sentence. The output
of this step is a list of terms in target language that are candidates for ontology translation.
4.5 Statistics
The n-grams relevant for translation are determined by their frequency in the corpus. Based on the
stems, the frequency of each n-gram is calculated according to their (co-)occurrence. The individual
(co-)occurrence count of the terms is used for ordering of the terms, whereas the most frequent occurring
term is ranked top.
4.6 N-Gram Filtering
The list of high frequency terms still contains several terms with tokens representing special characters
and sentence ends (like ?.?, ???, ?<?, ?>?, ?/?) or semantic classes meaningless for ontology extension (like
dates, measurements, negation, and image references). Since the overall aim is to identify concepts that
should be added as translations to the ontology, we remove occurrences of these information units that
are very specific and without ontology importance. Also, if the term contains numbers, this precise and
1
In the radiology domain, readers are physicians, who read and interpret radiology images and produce the reports analyzed
in this work.
4
rather technical information is removed from the n-gram list. The resulting list contains terms we would
like to add as labels to respective ontology concepts if available.
5 Mapping Corpus Terms to Ontology Concepts
Based on the list of terms ranked by their frequency, we identify ontology concepts, whose translations
have a high impact on annotation coverage for the respective corpus. We assume that each ontology
concept has at least one label in the source language, in our case in English. In the following, we
describe our language resources employed in the approach and the mapping procedure.
5.1 Translation dictionaries
For this work, we used German-English translations from Dict.cc
2
and multilingual information from
DBpedia to create two dictionaries.
1. Medical Dictionary: 60,082 different English entries
Dict.cc contains specialized dictionaries for 130 different subjects. For our medical dictio-
nary, we collected all entries from the specialized dictionaries with subjects ?anatomy?, ?biol-
ogy?, ?chemistry?, ?medicine?, ?pharmacy?, and ?medical engineering and imaging?. Additionally,
we retrieved all medically relevant concepts from DBpedia that have an English and a German
or Latin label (about 9,500 concepts). More precisely, we used the DBpedia ontology (Bizer
et al., 2009) to retrieve all concepts of type dbp:AnatomicalStructure
3
, dbp:Disease, dbp:Drug,
dbp:ChemicalSubstance and subclasses (see SPARQL query in Figure 4).
2. General Dictionary: 623,294 different English entries
The general dictionary is the complete English-German Dict.cc dictionary without restriction to a
specific subject.
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX dbp: <http://dbpedia.org/ontology/>
PREFIX dbpedia2: <http://dbpedia.org/property/>
SELECT ?s ?labelEn ?labelDe ?labelLat
WHERE {
?s a ?type ;
rdfs:label ?labelEn .
FILTER ( ?type = dbp:AnatomicalStructure
|| ?type = dbp:Disease
|| ?type = dbp:Drug
|| ?type = dbp:ChemicalSubstance )
FILTER ( lang(?labelEn) = "en" )
OPTIONAL { ?s dbpedia2:latin ?labelLat }
OPTIONAL { ?s rdfs:label ?labelDe .
FILTER ( lang(?labelDe) = "de" ) }
FILTER( bound(?labelDe) || bound(?labelLat) )
}
Figure 4: SPARQL query to retrieve English-German and English-Latin translations from DBpedia using
the SPARQL endpoint at http://dbpedia.org/sparql.
5.2 Ontology concept translation
The mapping of given corpus terms to corresponding ontology concepts as translations involves two sub
steps.
1. Dictionary Lookup For all occurrences of a term, we try to find English options in our dictionaries.
If no complete lookup option is found for a n-gram, we try to find a lookup option in the dictionary
for each single token to combine them into a complete English n-gram. E.g. the corpus term
?L?asion? is translated to ?lesion? using the medical dictionary.
2
http://www.dict.cc/
3
We use the prefix notation dbp for http://dbpedia.org/ontology/AnatomicalStructure
5
2. Concept Mapping The list of English lookup options from the first step is used to find ontology
concepts, whose (English) labels match the dictionary lookup. We find that the ontology concept
with RID38780 is assigned the given preferred name ?lesion?. If a match is found, the German n-
gram that resulted in the match (?L?asion?) is regarded as probable translation. In order to increase
the quality of the translation, an expert review is conducted at this time. This is the only manual
step in the whole translation process. After the review, the n-gram is inserted as new RDF triple
for the respective ontology concept. In RadLex translations are currently maintained as synonyms.
However, as this modeling of translations as synonyms does not represent the correct semantics and
misses the important language information, we propose to use rdfs:label for translations added by a
corresponding language tag. Thus, for the example we insert ?L?asion? as additional German label
to the ontology concept (see Figure 3).
6 Evaluation
6.1 Resources
The evaluation of our system is based on the RadLex ontology and a corpus of 2,713 radiology reports of
lymphoma patients. We use the OWL DL version of RadLex3.9.1 from NCBO BioPortal. This version
contains 42,321 concepts, which all have an assigned (English) preferred name and few additionally syn-
onyms. The German translations are represented as synonyms. Most of the German labels were added in
2009, when a first German version was created. Even though the number of concepts is growing signif-
icantly (RadLex3.9 contained 34,899), the number of concepts with non-English labels is not evolving
the same way. Thus, in RadLex3.9.1 less than 25% of the 42,321 concepts have German labels.
Proposed translations for ontology concepts - as output of the described automatic approach - are
evaluated by a clinical expert. We restricted the corpus terms translated to those occurring at least
two times. The whole process results in a list of 742 German labels proposed for ontology extension.
The expert classified these translations as correct or incorrect. In order to assist the expert in better
understanding of the ontology concept to be extended, we provide information on the preferred name,
synonyms as well as preferred names of the next two super classes.
This list of evaluated translations is analyzed in detail using three dimensions: First, we analyze how
the choice of the dictionary influences the translation outcome. Second, we figure out how the term length
and the processing of multi-word terms influences the translation results. Third, the correct translations
are added to an extended RadLex ontology. We compare the annotation results using the initial and
extended RadLex version. We apply accuracy as evaluation measure, which is the proportion of correct
translations in the system-proposed set.
6.2 Evaluation of the Translation Services
As described in Section 5.1, we use two different dictionaries. As expected, the accuracy of the medical
dictionary is significantly higher than the accuracy of the general dictionary (see Table 1(a)). This is
because in many cases only the domain-specific dictionary contains the correct lookup entry for the
terms. Nevertheless, the general dictionary is necessary, because RadLex contains also general language
terms like ?increased? or ?normal?. Combining the two dictionaries accuracy reaches 75.2%.
6.3 Evaluation of the N-Gram Length
If we take a closer look at n-gram distribution of terms, we see that we translate mainly single words (1-
grams), while 2-grams and 3-grams are translated less often. However, the accuracy of 3-grams reaches
excellent values (see Table 1(b)). Nevertheless, the translation of n-grams is of high importance, as
most of the ontology concepts in the biomedical domain have multiword labels. In particular, labels of
anatomical entities are multiword terms; in RadLex they can grow to 10-grams. Consider for example
?Organ component of lymphatic tree organ? or ?Tendon of second palmar interosseous of left hand?.
Thus, a more sophisticated multiword translation is needed to enhance the number of translations for
n-grams. For us, the improved handling of stopwords is the main focus in future work: While we remove
stopwords in the n-grams, ontology concepts that contain stopwords prevent a match.
6
Table 1: Evaluation of translation outcomes by choice of dictionary and term length. Proposed de-
notes the number of German labels translated and added to the ontology. Correct denotes the subset of
translations evaluated by the expert as correct.
(a) Evaluation by translation dictionary
Translations
Proposed Correct Accuracy
medical dict 258 240 0.9302
general dict 484 318 0.6570
both dicts 742 558 0.7520
(b) Evaluation by n-gram length
Translations
Proposed Correct Accuracy
1-grams 609 451 0.7406
2-grams 118 92 0.7797
3-grams 15 15 1.0000
Table 2: Comparison of the annotation coverage using RadLex3.9.1 and the extended version. Total
number of tokens of the corpus: 346,963.
extended
RadLex3.9.1 RadLex3.9.1
Tokens with annotation 94,914 147,982 +0.5591
Annotation Coverage 27.36 % 42.65 % +0.5591
Tokens without annotation 252,049 198,981 - 0.2105
Number of annotations 133,156 204,491 +0.5357
6.4 Extension of RadLex and Evaluation of Annotation Coverage
From Table 1(a), one can see that we correctly translated 558 RadLex concept labels using both dictio-
naries. After the expert review, we added the (German) terms of these correct matches as labels to 433
distinct RadLex concepts. I.e., some concepts were assigned more than one additional German label.
We refer to the new ontology as the extended RadLex. For the analysis of how the added translations
influence the number of annotations, we conducted two annotation processes. Both the original and the
extended RadLex versions were used to semantically annotate the corpus using the annotator described
in Section 4.3. The measure to indicate the annotation success is annotation coverage, which denotes
the relative amount of tokens for which at least one annotation exists. Table 2 shows that we are able to
enhance the annotation coverage by about 56% by adding only 558 translations. This shows the effec-
tiveness of the approach. A comparison indicator of these numbers deliver English texts: In (Woods and
Eng, 2013) an annotation rate of 62 % was observed for English chest radiography reports. Despite the
restrictiveness of the comparison, we see that an annotation coverage of 42.65 % is high considering that
only about 25 % of the extended RadLex?s concepts have a German label.
6.5 Limitations
Due to the characteristics of our approach, the outcome of the increased annotation coverage is specific
for the corpus used: Even though the reports come from 27 different readers, the vocabulary of the
evaluated corpus is specific to one disease and thus limited to a certain degree. Because the vocabulary
differentiates in other corpora, the application of the translation added for texts describing other diseases
or reports may not result in increases of the annotation coverage as shown. For other corpora, one has
to run our approach a second time using the new corpus and add further concepts to obtain a similar
annotation coverage. However, we expect the additional effort needed to get smaller over time.
7 Conclusion
We propose a method to make ontologies usable for multilingual semantic annotation of texts by auto-
matically extending them with translations, without the need to invest much effort in a full translation.
We believe that our approach is able to unlock the high potential of existing ontologies also for low re-
7
sourced languages. We address the key problem of identifying those concepts that are worth translating
by defining the increase of annotation coverage for a given corpus as the main target. Although it might
seem intuitive to apply an English corpus to identify the most frequent terms and their (source) ontology
concepts to translate, we do not pursue this approach. Especially when dealing with a domain-specific
language, translations are often ambiguous. As the English corpus does not help picking the correct
(target) translation candidate, we decided to start the other way around and facilitate a corpus in target
language. We show the high quality and efficiency of the approach by translating medical terms from
English to German. According to the evaluation results, a better treatment of n-grams shows the biggest
potential for enhancement of the approach. Sophisticated linguistic algorithms for the translation, which
incorporate the ontology context, can increase the matching of the multi-word terms. In future work, we
plan to evaluate our approach using other ontologies from the BioPortal.
Acknowledgements
This research has been supported in part by the KDI project, which is funded by the German Federal
Ministry of Economics and Technology under grant number 01MT14001. We thank Dict.cc for providing
us with the dictionaries.
References
Christian Bizer, Jens Lehmann, Georgi Kobilarov, Sren Auer, Christian Becker, Richard Cyganiak, and Sebastian
Hellmann. 2009. {DBpedia} - a crystallization point for the web of data. Web Semantics: Science, Services
and Agents on the World Wide Web, 7(3):154 ? 165.
Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buitelaar, Mauricio Espinoza, and Asunci?on G?omez-P?erez. 2010.
A note on ontology localization. Applied Ontology, 5(2):127?137.
M Espinoza, A G?omez-P?erez, and E Montiel-Ponsoda. 2009a. Multilingual and Localization Support for Ontolo-
gies. The Semantic Web Research and Applications, 5554:821?825.
Mauricio Espinoza, Elena Montiel-Ponsoda, and Asunci?on G?omez-P?erez. 2009b. Ontology localization. In
Proceedings of the Fifth International Conference on Knowledge Capture, pages 33?40, New York. ACM.
Thomas R Gruber. 1993a. Toward Principles for the Design of Ontologies Used for Knowledge Sharing. Interna-
tional Journal Human-Computer Studies 43, pages 907?928.
Thomas R. Gruber. 1993b. A translation approach to portable ontology specifications. Knowl. Acquis., 5(2):199?
220, June.
Curtis P. Langlotz. 2006. Radlex: A new method for indexing online educational materials. RadioGraphics,
26(6):1595?1597. PMID: 17102038.
S.M. Meystre, G.K. Savova, K.C. Kipper-Schuler, and J.F. Hurdle. 2008. Extracting information from textual
documents in the electronic health record: A review of recent research. Yearbook of Medical Informatics, pages
128?144.
Natalya F. Noy, Nigam H. Shah, Benjamin Dai, Michael Dorf, Nicholas Griffith, Clement Jonquet, Michael J.
Montegut, Daniel L. Rubin, Cherie Youn, and Mark A. Musen. 2008. Bioportal: A web repository for biomed-
ical ontologies and data resources [demonstration].
M. F. Porter. 1997. Readings in information retrieval. chapter An Algorithm for Suffix Stripping, pages 313?316.
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
Mari Carmen Su?arez-figueroa and Asunci?on G?omez-P?erez. 2008. First Attempt towards a Standard Glossary of
Ontology Engineering Terminology. In Proceedings of the 8th International Conference on Terminology and
Knowledge Engineering (TKE2008).
Michael Tanenblatt, Anni Coden, and Igor Sominsky. 2010. The conceptmapper approach to named entity
recognition. In Proceedings of the Seventh conference on International Language Resources and Evaluation
(LREC?10), Valletta, Malta. European Language Resources Association (ELRA).
Ryan W. Woods and John Eng. 2013. Evaluating the Completeness of RadLex in the Chest Radiography Domain.
Academic Radiology, 20(11):1329?1333.
8
