Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 653?661,
Beijing, August 2010
Structure-Aware Review Mining and Summarization
Fangtao Li1, Chao Han1, Minlie Huang1, Xiaoyan Zhu1,
Ying-Ju Xia2, Shu Zhang2 and Hao Yu2
1State Key Laboratory of Intelligent Technology and Systems?
1Tsinghua National Laboratory for Information Science and Technology?
1Department of Computer Science and Technology, Tsinghua University
2Fujitsu Research and Development Center
fangtao06@gmail.com; zxy_dcs@tsinghua.edu.cn
Abstract
In this paper, we focus on object feature 1
1 Introduction
based review summarization. Different from 
most of previous work with linguistic rules or 
statistical methods, we formulate the review
mining task as a joint structure tagging prob-
lem. We propose a new machine learning 
framework based on Conditional Random 
Fields (CRFs). It can employ rich features to 
jointly extract positive opinions, negative opi-
nions and object features for review sentences.
The linguistic structure can be naturally inte-
grated into model representation. Besides li-
near-chain structure, we also investigate con-
junction structure and syntactic tree structure
in this framework. Through extensive experi-
ments on movie review and product review 
data sets, we show that structure-aware mod-
els outperform many state-of-the-art ap-
proaches to review mining.
With the rapid expansion of e-commerce, people 
are more likely to express their opinions and 
hands-on experiences on products or services
they have purchased. These reviews are impor-
tant for both business organizations and personal 
costumers. Companies can decide on their strat-
egies for marketing and products improvement. 
Customers can make a better decision when pur-
1 Note that there are two meanings for word ?feature?. 
We use ?object feature? to represent the target entity,
which the opinion expressed on, and use ?feature? as
the input for machine learning methods.
chasing products or services. Unfortunately, 
reading through all customer reviews is difficult, 
especially for popular items, the number of re-
views can be up to hundreds or even thousands. 
Therefore, it is necessary to provide coherent 
and concise summaries for these reviews.
Figure 1. Feature based Review Summarization
Inspired by previous work (Hu and Liu, 2004; 
Jin and Ho, 2009), we aim to provide object fea-
ture based review summarization. Figure 1 
shows a summary example for movie ?Gone 
with the wind?. The object (movie) features, 
such as ?movie?, ?actor?, with their correspond-
ing positive opinions and negative opinions, are 
listed in a structured way. The opinions are 
ranked by their frequencies. This provides a con-
cise view for reviews. To accomplish this goal, 
we need to do three tasks:  1), extract all the ob-
ject features and opinions; 2), determine the sen-
timent polarities for opinions; 3), for each object 
feature, determine the relevant opinions, i.e. ob-
ject feature-opinion pairs.
For the first two tasks, most previous studies
employ linguistic rules or statistical methods (Hu 
and Liu, 2004; Popescu and Etzioni 2005). They 
mainly use unsupervised learning methods,
which lack an effective way to address infre-
quent object features and opinions. They are also
hard to incorporate rich overlapping features.
Gone With The Wind:
Movie:
     Positive: great, good, amazing, ? , breathtaking
     Negative: bad, boring, waste time, ? , mistake
Actor: 
     Positive: charming , brilliant , great, ? , smart 
     Negative: poor, fail, dirty, ? , lame
Music:
     Positive: great, beautiful, very good, ? , top
     Negative: annoying, noise, too long, ? , unnecessary 
    ? ?
653
Actually, there are many useful features, which 
have not been fully exploited for review mining.
Meanwhile, most of previous methods extract 
object features, opinions, and determine the po-
larities for opinions separately. In fact, the object 
features, positive opinions and negative opinions
correlate with each other. 
In this paper, we formulate the first two tasks,
i.e. object feature, opinion extraction and opi-
nion polarity detection, as a joint structure tag-
ging problem, and propose a new machine learn-
ing framework based on Conditional Random 
Fields (CRFs). For each sentence in reviews, we 
employ CRFs to jointly extract object features,
positive opinions and negative opinions, which 
appear in the review sentence. This framework
can naturally encode the linguistic structure. Be-
sides the neighbor context with linear-chain 
CRFs, we propose to use Skip-chain CRFs and 
Tree CRFs to utilize the conjunction structure
and syntactic tree structure. We also propose a
new unified model, Skip-Tree CRFs to integrate 
these structures. Here, ?structure-aware? refers 
to the output structure, which model the relation-
ship among output labels. This is significantly 
different from the previous input structure me-
thods, which consider the linguistic structure as 
heuristic rules (Ding and Liu, 2007) or input fea-
tures for classification (Wilson et al 2009). Our 
proposed framework has the following advan-
tages: First, it can employ rich features for re-
view mining. We will analyze the effect of fea-
tures for review mining in this framework.
Second, the framework can utilize the relation-
ship among object features, positive opinions 
and negative opinions. It jointly extracts these 
three types of expressions in a unified way.
Third, the linguistic structure information can be 
naturally integrated into model representation,
which provides more semantic dependency for 
output labels. Through extensive experiments on 
movie review and product review, we show our 
proposed framework is effective for review min-
ing.
The rest of this paper is organized as follows: 
In Section 2, we review related work. We de-
scribe our structure aware review mining me-
thods in Section 3. Section 4 demonstrates the 
process of summary generation. In Section 5, we 
present and discuss the experiment results. Sec-
tion 6 is the conclusion and future work.
2 Related Work
Object feature based review summary has been 
studied in several papers. Zhuang et al (2006) 
summarized movie reviews by extracting object 
feature keywords and opinion keywords. Object 
feature-opinion pairs were identified by using a 
dependency grammar graph. However, it used a
manually annotated list of keywords to recognize 
movie features and opinions, and thus the system 
capability is limited. Hu and Liu (2004) pro-
posed a statistical approach to capture object 
features using association rules. They only con-
sidered adjective as opinions, and the polarities 
of opinions are recognized with WordNet expan-
sion to manually selected opinion seeds. Popescu 
and Etzioni (2005) proposed a relaxation labe-
ling approach to utilize linguistic rules for opi-
nion polarity detection. However, most of these 
studies focus on unsupervised methods, which
are hard to integrate various features. Some stu-
dies (Breck et al 2007; Wilson et al 2009; Ko-
bayashi et al 2007) have used classification 
based methods to integrate various features. But 
these methods separately extract object features
and opinions, which ignore the correlation 
among output labels, i.e. object features and opi-
nions. Qiu et al (2009) exploit the relations of 
opinions and object features by adding some lin-
guistic rules. However, they didn?t care the opi-
nion polarity. Our framework can not only em-
ploy various features, but also exploit the corre-
lations among the three types of expressions, i.e.
object features, positive opinions, and negative 
opinions, in a unified framework. Recently, Jin 
and Ho (2009) propose to use Lexicalized HMM
for review mining. Lexicalized HMM is a va-
riant of HMM. It is a generative model, which is 
hard to integrate rich, overlapping features. It 
may encounter sparse data problem, especially 
when simultaneously integrating multiple fea-
tures. Our framework is based on Conditional 
Random Fields (CRFs). CRFs is a discriminative 
model, which can easily integrate various fea-
tures.
These are some studies on opinion mining with 
Conditional Random Fields. For example, with 
CRFs, Zhao et al(2008) and McDonald et al 
(2007) performed sentiment classification in sen-
tence and document level; Breck et al(2007) 
identified opinion expressions from newswire 
documents; Choi et al (2005) determined opi-
654
nion holders to opinions also from newswire da-
ta. None of previous work focuses on jointly ex-
tracting object features, positive opinions and 
negative opinions simultaneously from review 
data. More importantly, we also show how to 
encode the linguistic structure, such as conjunc-
tion structure and syntactic tree structure, into 
model representation in our framework. This is 
significantly different from most of previous 
studies, which consider the structure information 
as heuristic rules (Hu and Liu, 2004) or input 
features (Wilson et al 2009).
Recently, there are some studies on joint sen-
timent/topic extraction (Mei et al 2007; Titov 
and McDonald, 2008; Snyder and Barzilay, 
2007). These methods represent reviews as sev-
eral coarse-grained topics, which can be consi-
dered as clusters of object features. They are
hard to indentify the low-frequency object fea-
tures and opinions. While in this paper, we will 
extract all the present object features and corres-
ponding opinions with their polarities. Besides, 
the joint sentiment/topic methods are mainly
based on review document for topic extraction.
In our framework, we focus on sentence-level
review extraction.
3 Structure Aware Review Mining
3.1 Problem Definition
To produce review summaries, we need to first 
finish two tasks: identifying object features, opi-
nions, and determining the polarities for opi-
nions. In this paper, we formulate these two 
tasks as a joint structure tagging problem. We
first describe some related definitions:
Definition (Object Feature): is defined as whole 
target expression that the subjective expressions 
have been commented on. Object features can be 
products, services or their elements and proper-
ties, such as ?character?, ?movie?, ?director? for 
movie review, and ?battery?, ?battery life?,
?memory card? for product review.
Definition (Review Opinion): is defined as the 
whole subjective expression on object features.
For example, in sentence ?The camera is easy to 
use?, ?easy to use? is a review opinion. ?opinion? 
is used for short.
Definition (Opinion Polarity): is defined as the 
sentiment category for review opinion. In this 
paper, we consider two types of polarities: posi-
tive opinion and negative opinion. For example,
?easy to use? belongs to positive opinion.
For our review mining task, we need to 
represent three types of expressions: object fea-
tures, positive opinions, and negative opinions. 
These expressions may be words, or whole
phrases. We use BIO encoding for tag represen-
tation, where the non-opinion and neutral opi-
nion words are represented as ?O?. With Nega-
tion (N), which is only one word, such as ?not?,
?don?t?, as an independent tag, there are totally 8 
tags, as shown in Table 1. The following is an 
example to denote the tags:
The/O camera/FB comes/O with/O a/O piti-
ful/CB 32mb/FB compact/FI flash/FI card/FI ./O
FB Feature Beginning CB Negative Beginning
FI Feature Inside CI Negative Inside
PB Positive Beginning N Negation Word 
PI Positive Inside O Other 
Table 1. Basic Tag Set for Review Mining
3.2 Structure Aware Model
In this section, we describe how to encode dif-
ferent linguistic structure into model representa-
tion based on our CRFs framework.
3.2.1 Using Linear CRFs.
For each sentence in a review, our task is to ex-
tract all the object features, positive opinions and 
negative opinions. This task can be modeled as a 
classification problem. Traditional classification 
tools, e.g. Maximum Entropy model (Berger et 
al, 1996), can be employed, where each word or 
phrase will be treated as an instance. However, 
they independently consider each word or 
phrase, and ignore the dependency relationship 
among them.
Actually, the context information plays an im-
portant role for review mining. For example, 
given two continuous words with same part of 
speech, if the previous word is a positive opi-
nion, the next word is more likely a positive opi-
nion. Another example is that if the previous 
word is an adjective, and it is an opinion, the 
next noun word is more likely an object feature.
To this end, we formulate the review mining 
task as a joint structure tagging problem, and 
propose a general framework based on Condi-
tional Random Fields (CRFs) (Lafferty et al, 
2001) which are able to model the dependencies 
655
y1 yn-1y3y2 yn
x1 xn-1x3x2 xn
(a) Linear-chain  CRFs
y4
x1 xn-1x3x2 xnxn-2
?
x4
y1 yn-2y3 yn
y2 yn-1
(c) Tree-CRFs
y4
x1 xn-1x3x2 xnxn-2
?
x4
y1 yn-2y3 yn
y2 yn-1
(d) Skip-Tree CRFs
(b) Skip-chain  CRFs
Figure 2 CRFs models
between nodes. (See Section 3.2.5 for more 
about CRFs)
In this section, we propose to use linear-chain
CRFs to model the sequential dependencies be-
tween continuous words, as discussed above. It 
views each word in the sentence as a node, and 
adjacent nodes are connected by an edge. The 
graphical representation is shown in Figure 2(a).
Linear CRFs can make use of dependency rela-
tionship among adjacent words.
3.2.2 Leveraging Conjunction Structure
We observe that the conjunctions play important 
roles on review mining: If the words or phrases 
are connected by conjunction ?and?, they mostly 
belong to the same opinion polarity. If the words 
or phrases are connected by conjunction ?but?, 
they mostly belong to different opinion polarity,
as reported in (Hatzivassiloglou and McKeown,
1997; Ding and Liu, 2007). For example, ?This
phone has a very cool and useful feature ? the
speakerphone?, if we only detect ?cool?, it is 
hard to determine its opinion polarity. But if we 
see ?cool? is connected with ?useful? by con-
junction ?and?, we can easily acquire the polari-
ty of ?cool? as positive. This conjunction struc-
ture not only helps to determine the opinions, but 
also helps to recognize object features. For ex-
ample, ?I like the special effects and music in 
this movie?, with word ?music? and conjunction
?and?, we can easily detect that ?special effects? 
as an object feature.
To model the long distance dependency with 
conjunctions, we use Skip-chain CRFs model to 
detect object features and opinions. The graphi-
cal representation of a Skip-chain CRFs, given in 
Figure 2(b), consists of two types of edges: li-
near-edge (

to 

) and skip-edge (

to 

). 
The linear-edge is described as linear CRFs. The 
skip-edge is imported as follows:
We first identify the conjunctions in the re-
view sentence, with a collected conjunction set,
including ?and?, ?but?, ?or?, ?however?, ?al-
though? etc. For each conjunction, we extract its 
connected two text sequences. The nearest two 
words with same part of speech from the two 
text sequences are connected with the skip-edge. 
Here, we just consider the noun, adjective, and 
adverb. For example, in ?good pictures and 
beautiful music?, there are two skip-edges: one 
connects two adjective words ?good? and ?beau-
tiful?; the other connects two nouns ?pictures? 
and ?music?. We also employ the general senti-
ment lexicons, SentiWordNet (Esuli and Sebas-
tiani, 2006), to connect opinions. Two nearest 
opinion words, detected by sentiment lexicon,
from two sequences, will also be connected by 
skip-edge. If the nearest distance exceeds the 
threshold, this skip edge will be discarded. Here,
we consider the threshold as nine.
Skip-chain CRFs improve the performance of 
review mining, because it naturally encodes the 
conjunction structure into model representation 
with skip-edges.
3.2.3 Leveraging Syntactic Tree Structure
Besides the conjunction structure, the syntactic 
tree structure also helps for review mining. The
tree denotes the syntactic relationship among 
words. In a syntactic dependency representation, 
each node is a surface word. For example, the 
corresponding dependency tree (Klein and Man-
ning, 2003) for the sentence, ?I really like this 
long movie?, is shown in Figure 3.
y1 yn-1y3y2 yn
x1 xn-1x3x2 xn
656
like
longthis
really movieI
nsubj dobjadvmod
det amod
Figure 3. Syntactic Dependency Tree Representation
In linear-chain structure and skip-chain structure, 
?like? and ?movie? have no direct edge, but in 
syntactic tree, ?movie? is directly connected 
with ?like?, and their relationship ?dobj? is also 
included, which shows ?movie? is an objective 
of ?like?. It can provide deeper syntactic depen-
dencies for object features, positive opinions and 
negative opinions. Therefore, it is important to 
consider the syntactic structure in the review 
mining task. 
In this section, we propose to use Tree CRFs to
model the syntactic tree structure for review 
mining. The representation of a Tree CRFs is 
shown in Figure 2(c). The syntactic tree structure 
is encoded into our model representation. Each 
node is corresponding to a word in the depen-
dency tree. The edge is corresponding to depen-
dency tree edge. Tree CRFs can make use of de-
pendency relationship in syntactic tree structure
to boost the performance.
3.2.4 Integrating Conjunction Structure and 
Syntactic Tree Structure
Conjunction structure provides the semantic re-
lations correlated with conjunctions. Syntactic 
tree structure provides dependency relation in 
the syntactic tree. They represent different se-
mantic dependencies. It is interesting to consider 
these two dependencies in a unified model. We 
propose Skip-Tree CRFs, to combine these two 
structure information. The graphical representa-
tion of a Skip-Tree CRFs, given in Figure 2(d),
consists of two types of edges: tree edges and 
conjunction skip-edges. We hope to simulta-
neously model the dependency in conjunction 
structure and syntactic tree structure.
We also notice that there is a relationship 
?conj? in syntactic dependency tree. However, 
we find that it only connects two head words for 
a few coordinating conjunction, such as ?and", 
?or", ?but?. Our designed conjunction skip-edge
provides more information for joint structure 
tagging. We analyze more conjunctions to con-
nect not only two head words, but also the words 
with same part of speech. We also connect the 
words with sentiment lexicon. We will show that 
the skip-tree CRFs, which combine the two 
structures, is effective in the experiment section.
3.2.5 Conditional Random Fields
A CRFs is an undirected graphical model G of 
the conditional distribution (	|
). Y are the 
random variables over the labels of the nodes 
that are globally conditioned on X, which are the 
random variables of the observations. The condi-
tional probability is defined as: 
P
(
	 
|


)
=  
1
(
)
    



(, 	|, 
)
,
+   



(, 	|, 
)
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1379?1388, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Part-of-Speech Tagging for Chinese-English Mixed Texts
with Dynamic Features
Jiayi Zhao? Xipeng Qiu? Shu Zhang? Feng Ji? Xuanjing Huang?
School of Computer Science, Fudan University, Shanghai, China ? ?
Fujitsu Research and Development Center, Beijing, China?
zjy.fudan@gmail.com?
{xpqiu,fengji,xjhuang}@fudan.edu.cn?
zhangshu@cn.fujitsu.com ?
Abstract
In modern Chinese articles or conversations,
it is very popular to involve a few English
words, especially in emails and Internet liter-
ature. Therefore, it becomes an important and
challenging topic to analyze Chinese-English
mixed texts. The underlying problem is how
to tag part-of-speech (POS) for the English
words involved. Due to the lack of specially
annotated corpus, most of the English words
are tagged as the oversimplified type, ?foreign
words?. In this paper, we present a method
using dynamic features to tag POS of mixed
texts. Experiments show that our method
achieves higher performance than traditional
sequence labeling methods. Meanwhile, our
method also boosts the performance of POS
tagging for pure Chinese texts.
1 Introduction
Nowadays, Chinese-English mixed texts are
prevalent in modern articles or emails. More and
more English words are used in Chinese texts as
names of organizations, products, terms and abbre-
viations, such as ?eBay?, ?iPhone?, ?GDP?, ?An-
droid? etc. On the other hand, it is also a common
phenomenon to use Chinese-English mixed texts
in daily conversation, especially in communication
among employers in large international corporations.
There are some challenges for analyzing Chinese-
English mixed texts:
1. How to define the POS tags for English words
in these mixed texts. Since the standard of
POS tags for English and Chinese are different,
we cannot use English POS to tag the English
words in mixed texts.
2. Due to lack of annotated corpus for mixed texts,
most of the English words are tagged as ?for-
eign words?, which is oversimplified. So we
cannot use them in further processing for the
syntactic and semantic analysis.
3. Most English words used in mixed texts are of-
ten out-of-vocabulary (OOV), which thus in-
creases the difficulties to tag them.
Currently, the mainstream method of Chinese
POS tagging is joint segmentation & tagging with
cross-labels, which can avoid the problem of error
propagation and achieve higher performance on both
subtasks(Ng and Low, 2004). Each label is the cross-
product of a segmentation label and a tagging la-
bel, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The fea-
tures are generated by position-based templates on
character-level.
Since the main part of mixed texts is in Chinese
and the role of English word is more like Chinese,
we use Chinese POS tags (Xia, 2000) to tag English
words. Since the categories of the most commonly
used English words are nouns, verbs and adjectives,
we can use ?NN?, ?NR?, ?VV?, ?VA?, ?JJ? to label
their POS tags.
For the English proper nouns and verbs, there
are no significant differences in Chinese and En-
glish POS tags except that English features plural
and tense forms.
For the English nouns, these are some English
nouns used as verbs, such as ??? [fan/VV]??(I
adore him very much.)? where ?fan? means ?adore?
and is used as a verb.
For the English adjectives, there are two corre-
sponding Chinese POS tags ?VA? and ?JJ?. For ex-
ample, the roles of some English words in Table 1,
1379
Table 1: The POS tags of English Adjectives in Mixed
Texts
Chinese English
? ? ? [profes-
sional/VA]?
I am very profes-
sional.
??? [high/VA]? Feel very high.
?? [super/JJ] [star/NN] He is a super star.
such as ?professional? and ?high?, are different with
their original ones.
Therefore, the POS tagging for mixed texts cannot
be settled with simple methods, such as looking up
in a dictionary.
One of the main differences between Chinese and
English in POS tagging is that the two languages
have character-based features and word-based fea-
tures respectively. To ensure the consistency of tag-
ging models, we prefer to use word-level informa-
tion in Chinese, which is both useful for Chinese-
English mixed texts and Chinese-only texts. For in-
stance, in a sentence ?X ?? Y ... (X or Y ...)?,
the word Y ought to have the same POS tag as the
word X . Another example is that the word follow-
ing a pronoun is usually a verb, and adjectives of-
ten describe nouns. Some related works show that
word-level features can improve the performance of
Chinese POS tagging (Jiang et al 2008; Sun, 2011).
In this paper, we propose a method to tag mixed
texts with dynamic features. Our method combines
these dynamic features, which are dynamically gen-
erated at the decoding stage, with traditional static
features. For Chinese-English mixed texts, the tra-
ditional features cannot yield a satisfied result due to
lack of training data. The proposed dynamic features
can improve the performance by using the informa-
tion of a word, such as POS tag or length of the whole
word, which is proven effective by experiments.
The rest of the paper is organized as follows: In
section 2, we introduce the sequence labeling mod-
els, thenwe describe our method of dynamic features
in section 3 and analyze its complexity in section 4.
Section 5 describes the training method. The exper-
imental results are manifested in section 6. Finally,
We review the relevant research works in section 7
and conclude our work in section 8.
2 Sequence Labeling Models
Sequence labeling is the task of assigning labels
y = y1, . . . , yn to an input sequence x = x1, . . . , xn.
Given a sample x, we define the feature ?(x, y).
Thus, we can label x with a score function,
y? = argmax
y
F (w,?(x, y)), (1)
where w is the parameter of function F (?).
For sequence labeling, the feature can be denoted
as?k(yi, yi?1, x, i), where i stands for the position in
the sequence and k stands for the number of feature
templates.
we use online Passive-Aggressive (PA) algorithm
(Crammer and Singer, 2003; Crammer et al 2006)
to train the model parameters. Following (Collins,
2002), the average strategy is used to avoid the over-
fitting problem.
3 Dynamic Features
The form of traditional features is shown in Table
2, where C represents a Chinese character, and T
represents the character-based tag. The subscript i
indicates its position related to the current character.
Table 2: Traditional Feature Templates
Ci, T0(i = ?2,?1, 0, 1, 2)
Ci, Cj , T0(i, j = ?2,?1, 0, 1, 2 and i ?= j)
T?1, T0
Traditional features are generated by position-
fixed templates. Since the length of Chinese word
is unfixed, their meanings are incomplete. We cat-
egorize them as ?static? features since they can be
calculated before tagging (except ?T?1, T0?).
The form of dynamic features is shown in Table
3, where WORD represents a Chinese word, and
POS (LEN ) is the POS tag (length) of the word.
The subscript of dynamic feature template indicates
its position related to the current word.
Table 4 shows an example. If the current posi-
tion is ? Apple?, then {POS?1=CC, POS?2=NR,
WORD?1=???, LEN?2=2}. Since these features
are unavailable before tagging, we call them ?dy-
namic? features.
1380
Table 3: Examples of Dynamic Feature Templates
POSi, POSj , T0(i, j = ?2,?1, 0 and i ?= j)
POSi,WORDj , T0(i, j = ?2,?1, 0)
WORDi, LENj , POSk, T0(i, j, k = ?2,?1, 0)
?
Dynamic features are more flexible because the
number of involved characters is dependent on the
length of previous words. Unlike static features, dy-
namic features do not merely rely on the input se-
quence C1:n, so the weights of dynamic features, in
which POS/LEN are involved, can be trained by
Chinese-only texts and used by mixed texts, which
resolve the problem of the lack of training data.
4 Tagging with Dynamic Features
In the tagging stage, we use the current best result
to approximately calculate the unknown tag infor-
mation. For an input sequence C1:n, the current best
tags from index 0 to i?1 can be calculated by Viterbi
algorithm and they can be used to generate dynamic
features for index i. The specific algorithm is shown
in Algorithm 1.
Here is an example to explain the time com-
plexity of the dynamic features. Normal template
xi?2xi?1yi requires to look for the positions of
i ? 2 and i ? 1 related to the current character
xi, but dynamic template posi?2posi?1yi needs to
know the pos tags of two words. If the length of
wordi?1/wordi?2 is 2, then the positions of i?4, i?
3, i?2, i?1 are needed to generate the dynamic fea-
tures.
For all dynamic features, it is unnecessary to
repetitively calculate the POS/WORD/LEN ar-
ray. Apart from that one time calculation of the ar-
ray, no distinction can be found between the time
complexity of the dynamic features and the tradi-
tional features. For input C1:n, the time complexity
isO(n?[O(op.2)+(Ts.num+Td.num)?O(op.1)+
O(op.4)]), n.b. O(op.1) = O(op.3). Universally
the dynamic features only require the information of
position i ? 2 and i ? 1, so the time complexity of
calculating the POS/WORD/LEN array can be
ignored as compared with the complexity of Viterbi
algorithm and feature extraction. The approximate
algorithm is thus faster than the Brute-Force way by
input : character sequence C1:n
static templates Ts
dynamic templates Td
number of labelsm
trans matrixM
output: resultsMax & Vp
Initialize: weight matrixW (n?m)
viterbi score matrix Vs (n?m)
viterbi path matrix Vp (n?m)
the index of current best labelMax
for i = 1 ? ? ?n do
for ts in Ts do
// create feature string Fs (Op.1)
Fs = createFeature(C1:n, ts);
W [i] += getWeightVector(Fs);
end
// create a list of <posk,wordk,lenk>
// (k = 0,?1,?2 . . .) (Op.2)
dList = getCurrentBestPath(Max, Vp);
for td in Td do
// create dynamic features string Fd
// (Op.3)
Fd = createFeature(C1:n, td, dList);
W [i] += getWeightVector(Fd);
end
// Update Vs[i], Vp[i] (Op.4)
viterbi_OneStep(Vs[i? 1],W [i],M );
Max = argmaxi(Vs[i]) ;
end
Algorithm 1: Tagging Algorithm with Dynamic
Features
using word-level information.
5 Training
Given an example (x, y), y? are denoted as the in-
correct labels with the highest score
y? = argmax
z ?=y
wT?(x, z). (2)
The margin ?(w; (x, y)) is defined as
?(w; (x, y)) = wT?(x, y)? wT?(x, y?). (3)
Thus, we calculate the hinge loss ?(w; (x, y), (ab-
breviated as ?w) by
1381
Table 4: Example for Chinese-English Mixed POS Tagging
? ? ? Apple ? OS ? ? ? ? ?
B-NR E-NR S-CC S-NR S-DEG S-NN B-NN E-NN B-VA E-VA S-PU
?w =
{
0, ?(w; (x, y)) > 1
1? ?(w; (x, y)), otherwise (4)
In round k, the new weight vector wk+1 is calcu-
lated by
wk+1 = argminw
1
2
||w? wk||2 + C ? ?,
s.t. ?(w; (xk, yk)) <= ? and ? >= 0 (5)
where ? is a non-negative slack variable, and C is
a positive parameter which controls the influence of
the slack term on the objective function.
Following the derivation in PA (Crammer et al
2006), we can get the update rule,
wk+1 = wk + ?k(?(xk, yk)? ?(xk, y?k)), (6)
where
?k = min(C,
?wk
??(xk, yk)? ?(xk, y?k)?2
) (7)
Our algorithm based on PA algorithm is shown in
Algorithm 2.
6 Experiments
We implement our system based on FudanNLP1.
We employ the commonly used label set {B, I, E,
S} for the segmentation part of cross-labels. {B,
I, E} represent Begin, Inside, End of a multi-node
segmentation respectively, and S represents a Single
node segmentation.
The F1 score is used for evaluation, which is the
harmonic mean of precision P (percentage of pre-
dict phrases that exactlymatch the reference phrases)
and recallR (percentage of reference phrases that re-
turned by system).
The feature templates, which are used to extract
features, are listed in Table 5. We set traditional
method (static features) as the baseline. The detailed
experimental settings and results are reported in the
following subsections.
1Available at http://code.google.com/p/fudannlp/
input : training data sets:
(xi, yi), i = 1, ? ? ? , N , and parameters:
C,K
output: wK
Initialize: wTemp? 0,w? 0;
for k = 0 ? ? ?K ? 1 do
for i = 1 ? ? ?N do
receive an example (xi, yi);
predict: y?i = argmax
y
?wk,?(xi, y)?;
if y?i ?= yi then
update wk+1 with Eq. 6;
end
end
wTemp = wTemp+ wk+1 ;
end
wK = wTemp/K ;
Algorithm 2: Training Algorithm
Table 5: Feature Templates
Static
xi?2yi, xi?1yi, xiyi, xi+1yi, xi+2yi
xi?1xiyi, xi+1xiyi, xi?1xi+1yi,
yi?1yi
Dynamic
posi?2posi?1yi, posi?1posiyi
posi?2wordi?1yi, posi?1wordiyi
posi?1wordi?1yi, posiwordiyi
wordi?2wordi?1yi, wordi?1wordiyi
wordileniyi
6.1 POS Tagging for Chinese-only Texts
Before the experiments onChinese-Englishmixed
texts, we evaluate the performance of our method on
Chinese-only texts. We use the CTB dataset from
the POS tagging task of the Fourth International Chi-
nese Language Processing Bakeoff (SIGHAN Bake-
off 2008)(Jin and Chen, 2008). The details are
shown in Table 6.
The performance comparison on joint segmenta-
tion & POS tagging is shown in Table 7. Our method
obtains an error reduction of 6.7% over the baseline.
The reason is that our dynamic features can utilize
1382
Table 6: POS Tagging Dataset in SIGHAN Bakeoff 2008
Train Set Test Set
(number) (number)
Sentence 23444 2079
Word
Total 642246 59955
NN 168896 16793
NR 42906 3970
VV 92887 8641
VA 9106 649
JJ 15640 1581
word-level information effectively and the feature
templates are more flexible.
Table 7: Performances of POS Tagging on Chinese-only
Texts with Static and Dynamic Features
Method P R F1
Baseline 89.68 89.60 89.64
Our 90.35 90.31 90.33
6.2 POS Tagging for Chinese-English Mixed
Texts
Without annotated corpus for Chinese-English
mixed texts, we use synthetic data as the alternative.
In Chinese-English mixed texts, English words of
noun(NN/NR), verb(VV/VA) and adjective(JJ) cat-
egories are the most commonly used, so we ran-
domly transform a certain percentage of Chinese
words with these POS tags in the SIGHAN Bakeoff
2008 dataset(Jin and Chen, 2008) into their English
counterparts.
6.2.1 Synthetic Data
Before trying out an experiment, we first study
how to generate the data of mixed texts.
We use two ways to produce the synthetic data:
?Respective Replacement? and ?Unified Replace-
ment?.
Respective Replacement We replace the selected
Chinese words into their corresponding English
counterparts.
Unified Replacement We replace the selected Chi-
nese words with a unified labelENG. The rea-
son we use the labelENG instead of real words
is that we want to consider the context of these
words but not the words themselves and over-
come the problem of out-of-vocabulary (OOV)
English words.
For our experiments, we just select 5% of the Chi-
nese nouns and verbs from SIGHAN dataset, and re-
place them in the above two ways. After replace-
ment, the training and test data have 12780 and 1254
English words, respectively. 5189 words are gener-
ated by way of ?Respective Replacement?. In the
test data, 326words are OOV, which comprises 25%
of the whole vocabulary. The information of gener-
ated data is shown in Table 8.
Table 8: The Synthetic Chinese-English Mixed Dataset
H
Dataset Numbers of ENGNN VV
H Train Set 8191 4589Test Set 842 412
We use H1 to represent the dataset generated by
way of ?Respective Replacement?, and H2 for the
dataset by way of with ?Unified Replacement?. The
experimental results on these two datasets are shown
in Table 9.
Table 9: Performances of POS Tagging on Dataset H1
and H2
Method Dataset ENG OOV TotalF1 F1oov F1
Baseline H1 73.60 54.91 88.93H2 77.59 73.93 89.11
Our H1 75.60 54.60 89.79H2 79.82 77.61 89.81
From Table 9, we can see that the ?Unified
Replacement? way is better than the ?Respective
Replacement? way for both the baseline and our
method. The main reason is that the ?Unified Re-
placement? way can greatly improve the tagging per-
formance of OOV words.
6.2.2 Detail Comparisons
For detail comparisons of all situations of
mixed texts, we design six synthetic datasets,
A/B/C/D1/D2/E by randomly selecting 10% or
15% of Chinese words (?NN/NR/VV/VA/JJ?) in the
1383
above SIGHANBakeoff 2008 dataset, and replacing
them with English label ENG.
The differences of these datasets are as following:
? Dataset A only contains English words with
tags ?NN/VV?.
? Dataset B contains English words with tags
?NN/VV/VA?.
? Dataset C contains one more tag ?NR? than
Dataset B.
? Datasets D1 and D2 contain one more tag ?JJ?
than Dataset B. The difference between D1
andD2 is thatD2 has about 50%more English
words than D1 in training set.
? Dataset E contains English words with all the
tags ?NN/NR/VV/VA/JJ?.
The detailed information of datasets
A/B/C/D1/D2/E is shown in Table 10.
Table 10: The Synthetic Chinese-English Mixed Dataset
Dataset Numbers of ENGNN NR VV VA JJ
A Train 16302 0 9007 0 0Test 1675 0 841 0 0
B Train 16116 0 8882 906 0Test 1573 0 830 58 0
C Train 16312 4057 9067 899 0Test 1549 400 795 61 0
D1
Train 16042 0 8957 855 1539
Test 1588 0 845 58 150
D2
Train 23705 0 13154 1300 2211
Test 1588 0 845 58 150
E Train 16066 4162 9156 886 1547Test 1647 415 809 57 141
The results are shown in Table 11. On dataset E,
our method achieves 6.78% higher performance on
tagging ENG labels than traditional static features.
This result is reasonable because our model can use
more flexible feature templates to extract features
and reduce the problem of being dependent on spe-
cific English words.
Tables 12/13/14/15/16/17 show the detailed re-
sults on datasets A/B/C/D1/D2/E.
Table 11: Performances of POS Tagging on Datasets
A/B/C/D1/D2/E
Dataset Method ENG labels TotalF1 F1
A Baseline 80.25 88.74Our 83.03 89.72
B Baseline 76.72 88.51Our 80.54 89.55
C Baseline 68.16 88.13Our 70.34 88.99
D1
Baseline 71.30 88.33
Our 74.02 89.15
D2
Baseline 69.59 88.09
Our 74.10 89.15
E Baseline 61.58 87.71Our 68.36 88.83
Experiment on dataset A gets the best result be-
cause ?NN? and ?VV? can be easily distinguished by
its context. Sometimes, ?VA? has the similar context
with ?VV?, experiment on datasetB shows its influ-
ence. The performances on datasetsB/C/E descend
in turn. The reason is that words with tag ?NN? or
?NR/JJ? have the similar usage/contexts in Chinese.
Since we use the same form ENG instead of real
words, there are no differences between these words,
which leads to some errors. Though the datasets is
generated randomly, we can see our method perform
better on every dataset than the baseline.
Table 12: Performances on Dataset A
POS tag Method P R F1
NN Baseline 84.36 86.33 85.33Our 85.37 89.91 87.58
VV Baseline 71.45 68.13 69.75Our 77.53 69.32 73.20
Table 13: Performances on Dataset B
POS tag Method P R F1
NN Baseline 84.89 80.36 82.56Our 83.51 88.87 86.11
VV Baseline 65.90 72.65 69.11Our 75.75 67.35 71.30
VA Baseline 36.84 36.21 36.52Our 51.02 43.10 46.73
1384
Table 14: Performances on Dataset C
POS tag Method P R F1
NN Baseline 73.77 78.24 75.94Our 76.84 77.99 77.41
VV Baseline 61.67 66.79 64.13Our 64.94 67.80 66.34
NR Baseline 55.22 37.00 44.31Our 55.65 50.50 52.95
VA Baseline 63.64 34.43 44.68Our 60.00 39.34 47.52
Table 15: Performances on DatasetD1
POS tag Method P R F1
NN Baseline 77.15 81.42 79.23Our 76.70 88.54 82.20
VV Baseline 67.53 64.50 65.98Our 79.65 59.76 68.29
JJ Baseline 25.00 18.00 20.93Our 22.92 14.67 17.89
VA Baseline 36.00 31.03 33.33Our 28.57 37.93 32.59
Table 16: Performances on DatasetD2
POS tag Method P R F1
NN Baseline 79.11 74.87 76.93Our 79.29 82.68 80.95
VV Baseline 55.77 72.78 65.64Our 69.17 70.89 70.02
JJ Baseline 27.27 12.00 16.67Our 34.38 22.00 26.83
VA Baseline 37.21 27.59 31.68Our 52.17 20.69 29.63
6.3 POS Tagging for Mixed Texts with a Real
Dataset
To investigate the actual performance, we collect
a real dataset from Web, which consists of 142 rep-
resentative Chinese-English mixed sentences. This
dataset contains 4, 238 Chinese characters and 275
English words. Since we focus on the performance
for English words, we only label the POS tags of the
English words. Table 18 shows some examples in
the real dataset of mixed texts.
Table 17: Performances on Dataset E
POS tag Method P R F1
NN Baseline 72.41 68.85 70.59Our 71.18 84.88 77.43
VV Baseline 63.65 59.09 61.28Our 76.19 55.38 64.14
JJ Baseline 28.57 25.53 26.97Our 30.21 20.57 24.47
VA Baseline 44.83 45.61 45.22Our 60.42 50.88 55.24
NR Baseline 38.03 52.05 43.95Our 52.01 46.75 49.24
Table 18: Examples in Real Dataset of Mixed Texts
?? [Ninja Cloud/NR] ????? [Ninja
Blocks/NR] ? ? [Facebook/NR]? [Twit-
ter/NR]?[Dropbox/NR]??????
By using [Ninja Cloud/NR], [Ninja
Blocks/NR] can connect to [Facebook/NR],
[Twitter/NR], [Dropbox/NR].
?? [follow/VV]?????????
You should [follow/VV] this man?s work.
?????????? [COOL/VA]?
... very [COOL/VA]!
The information of the real dataset is shown in Ta-
ble 19. If all involved English words are tagging as
?NN?, the precision is just 56%.
Table 19: The Numbers of English Words with Different
Tags in Dataset R
Dataset NN VV VA NR
R 154 58 28 35
Since there is no noun-modifier ?JJ? in our col-
lected data. We use the models trained on dataset
B and C to tag the real data. The results are shown
in Table 20. The difference between model B and
C is that model B regards all words with tag ?NR?
as ?NN?. Since it is difficult to distinguish between
?NR? and ?NN? merely according to the context,
model B performs better than model C.
The detail results of model B and C are shown in
Table 21 and 22.
1385
Table 20: Performances of POS Tagging on R
Model Method ENGF1
B Baseline 74.91Our 82.55
C Baseline 70.91Our 74.91
Table 21: Performances of Model B on Dataset R
POS tag Method P R F1
NN Baseline 88.62 78.31 83.15Our 91.67 87.30 89.43
VV Baseline 48.31 74.14 58.50Our 60.53 79.31 68.66
VA Baseline 78.95 53.57 63.83Our 84.21 57.14 68.09
Table 22: Performances of Model C on Dataset R
POS tag Method P R F1
NN Baseline 80.25 81.82 81.03Our 84.56 81.82 83.17
VV Baseline 54.88 77.59 64.29Our 61.25 84.48 71.01
VA Baseline 84.62 39.29 53.66Our 88.24 53.57 66.67
NR Baseline 56.52 37.14 44.83Our 55.17 45.71 50.00
7 Related Works
In recent years, POS tagging has undergone great
development. The mainstream method is to regard
POS tagging as sequence labeling problems (Ra-
biner, 1990; Xue, 2003; Peng et al 2004; Ng and
Low, 2004).
However, the analysis of Chinese-English mixed
texts is rarely involved in previous literature. In
the aspect of the general multilingual POS tagging,
most works focus on modeling cross-lingual corre-
lations and tagging multilingual POS on respective
monolingual texts, not on mixed texts (Cucerzan and
Yarowsky, 2002; Yarowsky et al 2001; Naseem et
al., 2009).
Since we choose to use dynamic word-level fea-
tures to improve the performance of POS tagging,
we also review some works on word-level features.
Semi-Markov Conditional Random Fields (semi-
CRF) (Sarawagi and Cohen, 2004) is a model in
which segmentation task is implicitly included into
the decoding algorithm. In this model, feature rep-
resentation would be more flexible than traditional
CRFs, since features can be extracted from the previ-
ous/the next segmentation within a window of vari-
able size. The problem of this approach lies in that
the decoding algorithm depends on the predefined
window size to exploit the boundaries of segmenta-
tions but not the real length of words.
Bunescu (2008) presents an improved pipeline
model in which the output of the previous subtasks
are considered as hidden variables, and the hidden
variables together with their probabilities denoting
the confidence are used as probabilistic features in
the next subtasks. One shortcoming of this method
is inefficiency caused by the calculation of marginal
probabilities of features. The other disadvantages
of the pipeline method are error propagation and the
need of separate training of different subtasks in the
pipeline. Another disadvantage of pipeline method
is error propagation.
Jiang et al(2008) proposes a cascaded linear
model for joint Chinese word segmentation and POS
tagging. With a character-based perceptron as the
core, combinedwith real-valued features such as lan-
guage models, the cascaded model can efficiently
utilize knowledge sources that are inconvenient to
incorporate into the perceptron directly. However,
they use POS tags or word information in a Brute-
Force way, which may suffer from the problem of
time complexity.
Sun (2011) presents a stacked sub-word model for
joint Chinese word segmentation and POS tagging.
By merging the outputs of the three predictors (in-
cluding one word-based segmenter) into sub-word
sequences, rich contextual features can be approx-
imately derived. The experiments are conducted to
show the effectiveness of using word-based informa-
tion.
The difference between the above methods and
ours is that our word-level features are dynamically
generated in the decoding stage without exhaustive
or preprocessed word segmentation.
1386
8 Conclusion
In this paper, we focus on Chinese-English mixed
texts and use dynamic features for POS tagging.
To overcome the problem of the lack of annotated
corpus on mixed texts, our features use both lo-
cal and non-local information and take advantage of
the characteristics of Chinese-English mixed texts.
The experiments demonstrate the effectiveness of
our method. It should be noted that our method is
also effective for the mixed texts of Chinese and any
foreign languages since we use ?Unified Replace-
ment?.
For future works, we plan to improve our approx-
imate tagging algorithm to reduce error propagation.
In addition, we will refer to an English dictionary
to generate some useful features to distinguish be-
tween ?NR? and ?NN? in Chinese-English mixed
texts and add some statistical features derived from
English resources, such as the most common tag of
each English word. We would also like to investi-
gate these features in more applications of natural
language processing, such as name entity recogni-
tion, information extraction, etc.
Acknowledgements
We would like to thank the anonymous reviewers
for their valuable comments. We also thanks Amy
Zhou for her help in spell and grammar checking.
This work was funded by NSFC (No.61003091 and
No.61073069), 863 Program (No.2011AA010604)
and 973 Program (No.2010CB327900).
References
Razvan C. Bunescu. 2008. Learning with probabilistic
features for improved pipeline models. In EMNLP,
pages 670?679. ACL.
Michael Collins. 2002. Discriminative training methods
for hidden markov models: theory and experiments
with perceptron algorithms. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing - Volume 10, EMNLP ?02, pages
1?8, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultraconser-
vative online algorithms for multiclass problems. J.
Mach. Learn. Res., 3:951?991, March.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. J. Mach. Learn. Res.,
7:551?585, December.
Silviu Cucerzan and David Yarowsky. 2002. Boot-
strapping a multilingual part-of-speech tagger in one
person-day. In proceedings of the 6th conference on
Natural language learning - Volume 20, COLING-
02, pages 1?7, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?.
2008. A cascaded linear model for joint chinese word
segmentation and part-of-speech tagging. In Kath-
leen McKeown, Johanna D. Moore, Simone Teufel,
James Allan, and Sadaoki Furui, editors, ACL, pages
897?904. The Association for Computer Linguistics.
C. Jin and X. Chen. 2008. The fourth international chi-
nese language processing bakeoff: Chinese word seg-
mentation, named entity recognition and chinese pos
tagging. In Sixth SIGHAN Workshop on Chinese Lan-
guage Processing, page 69.
T. Naseem, B. Snyder, J. Eisenstein, and R. Barzilay.
2009. Multilingual part-of-speech tagging: Two unsu-
pervised approaches. Journal of Artificial Intelligence
Research, 36(1):341?385.
H.T. Ng and J.K. Low. 2004. Chinese part-of-speech
tagging: One-at-a-time or all-at-once? word-based or
character-based. In Proceedings of EMNLP, volume
2004, page 277.
Fuchun Peng, Fangfang Feng, and Andrew McCallum.
2004. Chinese segmentation and new word detection
using conditional random fields. In Proceedings of the
20th international conference on Computational Lin-
guistics, COLING ?04, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Lawrence R. Rabiner. 1990. Readings in speech recog-
nition. chapter A tutorial on hidden Markov mod-
els and selected applications in speech recognition,
pages 267?296. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information ex-
traction. In NIPS.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Dekang Lin, Yuji Matsumoto, and Rada
Mihalcea, editors, ACL, pages 1385?1394. The Asso-
ciation for Computer Linguistics.
F. Xia. 2000. The part-of-speech tagging guidelines for
the Penn Chinese Treebank (3.0).
N. Xue. 2003. Chinese word segmentation as character
tagging. Computational Linguistics and Chinese Lan-
guage Processing, 8(1):29?48.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings of
1387
the first international conference on Human language
technology research, pages 1?8. Association for Com-
putational Linguistics.
1388
