Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 430?439,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Mining Name Translations from Entity Graph Mapping?
Gae-won You? Seung-won Hwang? Young-In Song? Long Jiang? Zaiqing Nie?
?Pohang University of Science and Technology, Pohang, Republic of Korea
{gwyou,swhwang}@postech.ac.kr
?Microsoft Research Asia, Beijing, China
{yosong,longj,znie}@microsoft.com
Abstract
This paper studies the problem of mining en-
tity translation, specifically, mining English
and Chinese name pairs. Existing efforts
can be categorized into (a) a transliteration-
based approach leveraging phonetic similar-
ity and (b) a corpus-based approach exploiting
bilingual co-occurrences, each of which suf-
fers from inaccuracy and scarcity respectively.
In clear contrast, we use unleveraged re-
sources of monolingual entity co-occurrences,
crawled from entity search engines, repre-
sented as two entity-relationship graphs ex-
tracted from two language corpora respec-
tively. Our problem is then abstracted as find-
ing correct mappings across two graphs. To
achieve this goal, we propose a holistic ap-
proach, of exploiting both transliteration sim-
ilarity and monolingual co-occurrences. This
approach, building upon monolingual corpora,
complements existing corpus-based work, re-
quiring scarce resources of parallel or compa-
rable corpus, while significantly boosting the
accuracy of transliteration-based work. We
validate our proposed system using real-life
datasets.
1 Introduction
Entity translation aims at mapping the entity names
(e.g., people, locations, and organizations) in source
language into their corresponding names in target
language. While high quality entity translation is es-
sential in cross-lingual information access and trans-
?This work was done when the first two authors visited Mi-
crosoft Research Asia.
lation, it is non-trivial to achieve, due to the chal-
lenge that entity translation, though typically bear-
ing pronunciation similarity, can also be arbitrary,
e.g., Jackie Chan and ? (pronounced Cheng
Long). Existing efforts to address these challenges
can be categorized into transliteration- and corpus-
based approaches. Transliteration-based approaches
(Wan and Verspoor, 1998; Knight and Graehl, 1998)
identify translations based on pronunciation similar-
ity, while corpus-based approaches mine bilingual
co-occurrences of translation pairs obtained from
parallel (Kupiec, 1993; Feng et al, 2004) or compa-
rable (Fung and Yee, 1998) corpora, or alternatively
mined from bilingual sentences (Lin et al, 2008;
Jiang et al, 2009). These two approaches have com-
plementary strength? transliteration-based similar-
ity can be computed for any name pair but cannot
mine translations of little (or none) phonetic simi-
larity. Corpus-based similarity can support arbitrary
translations, but require highly scarce resources of
bilingual co-occurrences, obtained from parallel or
comparable bilingual corpora.
In this paper, we propose a holistic approach,
leveraging both transliteration- and corpus-based
similarity. Our key contribution is to replace the
use of scarce resources of bilingual co-occurrences
with the use of untapped and significantly larger
resources of monolingual co-occurrences for trans-
lation. In particular, we extract monolingual co-
occurrences of entities from English and Chinese
Web corpora, which are readily available from en-
tity search engines such as PeopleEntityCube1, de-
ployed by Microsoft Research Asia. Such engine
1http://people.entitycube.com
430
automatically extracts people names from text and
their co-occurrences to retrieve related entities based
on co-occurrences. To illustrate, Figure 1(a) demon-
strates the query result for ?Bill Gates,? retrieving
and visualizing the ?entity-relationship graph? of re-
lated people names that frequently co-occur with
Bill in English corpus. Similarly, entity-relationship
graphs can be built over other language corpora, as
Figure 1(b) demonstrates the corresponding results
for the same query, from Renlifang2 on ChineseWeb
corpus. From this point on, for the sake of simplic-
ity, we refer to English and Chinese graphs, simply
asGe andGc respectively. Though we illustrate with
English-Chinese pairs in the paper, our method can
be easily adapted to other language pairs.
In particular, we propose a novel approach of ab-
stracting entity translation as a graph matching prob-
lem of two graphsGe andGc in Figures 1(a) and (b).
Specifically, the similarity between two nodes ve
and vc in Ge and Gc is initialized as their transliter-
ation similarity, which is iteratively refined based on
relational similarity obtained from monolingual co-
occurrences. To illustrate this, an English news ar-
ticle mentioning ?Bill Gates? and ?Melinda Gates?
evidences a relationship between the two entities,
which can be quantified from their co-occurrences
in the entire English Web corpus. Similarly, we
can mine Chinese news articles to obtain the re-
lationships between ???? and ???H??
?. Once these two bilingual graphs of people and
their relationships are harvested, entity translation
can leverage these parallel relationships to further
evidence the mapping between translation pairs, as
Figure 1(c) illustrates.
To highlight the advantage of our proposed ap-
proach, we compare our results with commercial
machine translators (1) Engkoo3 developed in Mi-
crosoft Research Asia and (2) Google Translator4.
In particular, Figure 2 reports the precision for two
groups? ?heads? that belong to top-100 popular peo-
ple (determined by the number of hits), among ran-
domly sampled 304 people names5 from six graph
pairs of size 1,000 each, and the remaining ?tails?.
Commercial translators such as Google, leveraging
2http://renlifang.msra.cn
3http://www.engkoo.com
4http://translate.google.com
5See Section 4 for the sampling process.
Ours Google Engkoo0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Pre
cis
ion
 
 
Tail
Head
Figure 2: Comparison for Head and Tail datasets
bilingual co-occurrences that are scarce for tails,
show significantly lower precision for tails. Mean-
while, our work, depending solely on monolin-
gual co-occurrences, shows high precision, for both
heads and tails.
Our focus is to boost translation accuracy for
long tails with non-trivial Web occurrences in each
monolingual corpus, but not with much bilingual co-
occurrences, e.g., researchers publishing actively in
two languages but not famous enough to be featured
in multi-lingual Wikipedia entries or news articles.
As existing translators are already highly accurate
for popular heads, this focus well addresses the re-
maining challenges for entity translation.
To summarize, we believe that this paper has the
following contributions:
? We abstract entity translation problem as
a graph mapping between entity-relationship
graphs in two languages.
? We develop an effective matching algo-
rithm leveraging both pronunciation and co-
occurrence similarity. This holistic approach
complements existing approaches and en-
hances the translation coverage and accuracy.
? We validate the effectiveness of our approach
using various real-life datasets.
The rest of this paper is organized as follows. Sec-
tion 2 reviews existing work. Section 3 then devel-
ops our framework. Section 4 reports experimental
results and Section 5 concludes our work.
431
(a) English PeopleEntityCube Ge (b) Chinese Renlifang Gc
(c) Abstracting translation as graph mapping
Figure 1: Illustration of entity-relationship graphs
2 Related Work
In this section, we first survey related efforts, cate-
gorized into transliteration-based and corpus-based
approaches. Our approach leveraging both is com-
plementary to these efforts.
2.1 Transliteration-based Approaches
Many name translations are loosely based on
phonetic similarity, which naturally inspires
transliteration-based translation of finding the
translation with the closest pronunciation similarity,
using either rule-based (Wan and Verspoor, 1998) or
statistical (Knight and Graehl, 1998; Li et al, 2004)
approaches. However, people are free to designate
arbitrary bilingual names of little (or none) pho-
netic similarity, for which the transliteration-based
approach is not effective.
2.2 Corpus-based Approaches
Corpus-based approach can mine arbitrary transla-
tion pairs, by mining bilingual co-occurrences from
parallel and comparable bilingual corpora. Using
parallel corpora (Kupiec, 1993; Feng et al, 2004),
e.g., bilingual Wikipedia entries on the same per-
son, renders high accuracy but suffers from high
scarcity. To alleviate such scarcity, (Fung and Yee,
432
1998; Shao and Ng, 2004) explore a more vast re-
source of comparable corpora, which share no par-
allel document- or sentence-alignments as in paral-
lel corpora but describe similar contents in two lan-
guages, e.g., news articles on the same event. Al-
ternatively, (Lin et al, 2008) extracts bilingual co-
occurrences from bilingual sentences, such as an-
notating terms with their corresponding translations
in English inside parentheses. Similarly, (Jiang et
al., 2009) identifies potential translation pairs from
bilingual sentences using lexical pattern analysis.
2.3 Holistic Approaches
The complementary strength of the above two ap-
proaches naturally calls for a holistic approach,
such as recent work combining transliteration-
and corpus-based similarity mining bilingual co-
occurrences using general search engines. Specifi-
cally, (Al-Onaizan and Knight, 2002) uses translit-
eration to generate candidates and then web corpora
to identify translations. Later, (Jiang et al, 2007)
enhances to use transliteration to guide web mining.
Our work is also a holistic approach, but leverag-
ing significantly larger corpora, specifically by ex-
ploiting monolingual co-occurrences. Such expan-
sion enables to translate ?long-tail? people entities
with non-trivial Web occurrences in each monolin-
gual corpus, but not much bilingual co-occurrences.
Specifically, we initialize name pair similarity using
transliteration-based approach, and iteratively rein-
forces base similarity using relational similarity.
3 Our Framework
Given two graphsGe = (Ve, Ee) andGc = (Vc, Ec)
harvested from English and Chinese corpora respec-
tively, our goal is to find translation pairs, or a set S
of matching node pairs such that S ? Ve ? Vc. Let
R be a |Ve|-by-|Vc| matrix where each Rij denotes
the similarity between two nodes i ? Ve and j ? Vc.
Overall, with the matrix R, our approach consists
of the following three steps, as we will discuss in the
following three sections respectively:
1. Initialization: computing base translation sim-
ilarities Rij between two entity nodes using
transliteration similarity
2. Reinforcement model: reinforcing the trans-
lation similarities Rij by exploiting the mono-
lingual co-occurrences
3. Matching extraction: extracting the matching
pairs from the final translation similarities Rij
3.1 Initialization with Transliteration
We initialize the translation similarity Rij as the
transliteration similarity. This section explains how
to get the transliteration similarity between English
and Chinese names using an unsupervised approach.
Formally, let an English name Ne =
(e1, e2, ? ? ? , en) and a Chinese name Nc =
(c1, c2, ? ? ? , cm) be given, where ei is an English
word and Ne is a sequence of the words, and ci
is a Chinese character and Nc is a sequence of
the characters. Our goal is to compute a score
indicating the similarity between the pronunciations
of the two names.
We first convert Nc into its Pinyin representation
PYc = (s1, s2, ? ? ? , sm), where si is the Pinyin rep-
resentation of ci. Pinyin is the romanization rep-
resentation of pronunciation of Chinese character.
For example, the Pinyin representation of Ne =
(?Barack?, ?Obama?) is PYc =(?ba?, ?la?, ?ke?,
?ao?, ?ba?, ?ma?). The Pinyin representations of
Chinese characters can be easily obtained from Chi-
nese character pronunciation dictionary. In our ex-
periments, we use an in-house dictionary, which
contains pronunciations of 20, 774 Chinese charac-
ters. For the Chinese characters having multiple pro-
nunciations, we only use the most popular one.
Calculation of transliteration similarity between
Ne and Nc is now transformed to calculation of pro-
nunciation similarity between Ne and PYc. Because
letters in Chinese Pinyins and English strings are
pronounced similarly, we can further approximate
pronunciation similarity between Ne and PYc us-
ing their spelling similarity. In this paper, we use
Edit Distance (ED) to measure the spelling similar-
ity. Moreover, since words in Ne are transliterated
into characters in PYc independently, it is more ac-
curate to compute the ED between Ne and PYc, i.e.,
EDname(Ne, PYc), as the sum of the EDs of all
component transliteration pairs, i.e., every ei in Ne
and its corresponding transliteration (si) in PYc. In
other words, we need to first align all sj?s in PYc
with corresponding ei in Ne based on whether they
433
are translations of each other. Then based on the
alignment, we can calculate EDname(Ne, PYc) us-
ing the following formula.
EDname(Ne, PYc) =
?
i
ED(ei, esi) (1)
where esi is a string generated by concatenating all
si?s that are aligned to ei and ED(ei, esi) is the
Edit Distance between ei and esi, i.e., the mini-
mum number of edit operations (including inser-
tion, deletion and substitution) needed to transform
ei into esi. Because an English word usually con-
sists of multiple syllables but every Chinese charac-
ter consists of only one syllable, when aligning ei?s
with sj?s, we add the constraint that each ei is al-
lowed to be aligned with 0 to 4 si?s but each si can
only be aligned with 0 to 1 ei. To get the align-
ment between PYc and Ne which has the minimal
EDname(Ne, PYc), we use a Dynamic Program-
ming based algorithm as defined in the following
formula:
EDname(N1,ie , PY 1,jc ) = min(
EDname(N1,i?1e , PY 1,jc ) + Len(ei),
EDname(N1,ie , PY 1,j?1c ) + Len(sj),
EDname(N1,i?1e , PY 1,j?1c ) + ED(ei, sj),
EDname(N1,i?1e , PY 1,j?2c ) + ED(ei, PY j?1,jc ),
EDname(N1,i?1e , PY 1,j?3c ) + ED(ei, PY j?2,jc ),
EDname(N1,i?1e , PY 1,j?4c ) + ED(ei, PY j?3,jc ))
where, given a sequence X = (x1, x2, ? ? ?)
such that xi is a word, X i,j is the subsequence
(xi, xi+1, ? ? ? , xj) of X and Len(X) is the number
of letters except spaces in the sequence X . For in-
stance, the minimal Edit Distance between the En-
glish name ?Barack Obama? and the Chinese Pinyin
representation ?ba la ke ao ba ma? is 4, as the
best alignment is: ?Barack? ? ?ba la ke? (ED: 3),
?Obama?? ?ao ba ma? (ED: 1). Finally the translit-
eration similarity between Nc and Ne is calculated
using the following formula.
Simtl(Nc, Ne) = 1?
EDname(Ne, PYc)
Len(PYc) + Len(Ne)
(2)
For example, Simtl(?Barack Obama?, ??n
.???j?) is 1? 411+12 = 0.826.
3.2 Reinforcement Model
From the initial similarity, we model our problem as
an iterative approach that iteratively reinforces the
similarityRij of the nodes i and j from the matching
similarities of their neighbor nodes u and v.
The basic intuition is built on exploiting the sim-
ilarity between monolingual co-occurrences of two
different languages. In particular, we assume two
entities with strong relationship co-occur frequently
in both corpora. In order to express this intuition, we
formally define an iterative reinforcement model as
follows. Let Rtij denote the similarity of nodes i and
j at t-th iteration:
Rt+1ij = ?
?
(u,v)k?Bt(i,j,?)
Rtuv
2k
+ (1? ?)R0ij (3)
The model is expressed as a linear combination
of (a) the relational similarity
?
Rtuv/2k and (b)
transliteration similarity R0ij . (? is the coefficient
for interpolating two similarities.)
In the relational similarity, Bt(i, j, ?) is an or-
dered set of the best matching pairs between neigh-
bor nodes of i and ones of j such that ?(u, v)k ?
Bt(i, j, ?), Rtuv ? ?, where (u, v)k is the match-
ing pair with k-th highest similarity score. We con-
sider (u, v) with similarity over some threshold ?,
or Rtuv ? ?, as a matching pair. In this neighbor
matching process, if many-to-many matches exist,
we select only one with the greatest matching score.
Figure 3 describes such matching process more for-
mally. N(i) andN(j) are the sets of neighbor nodes
of i and j, respectively, and H is a priority queue
sorting pairs in the decreasing order of similarity
scores.
Meanwhile, note that, in order to express that
the confidence for matching (i, j) progressively con-
verges as the number of matched neighbors in-
creases, we empirically use decaying coefficient
1/2k for Rtuv, because
??
k=1 1/2k = 1.
3.3 Matching Extraction
After the convergence of the above model, we get
the |Ve|-by-|Vc| similarity matrix R?. From this
matrix, we extract one-to-one matches maximizing
the overall similarity.
More formally, this problem can be stated as
the maximum weighted bipartite matching (West,
434
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
Bt(i, j, ?)? {}
?u ? N(i),?v ? N(j) : H.push(u, v;Rtuv)
while H is not empty do
(u, v; s)? H.pop()
if s < ? then
break
end if
if neither u nor v are matched yet then
Bt(i, j, ?)? Bt(i, j, ?) ? {(u, v)}
end if
end while
return Bt(i, j, ?)
Figure 3: How to get the ordered set Bt(i, j, ?)
2000)? Given two groups of entities Ve and Vc from
the two graphs Ge and Gc, we can build a weighted
bipartite graph is G = (V,E), where V = Ve ? Vc
and E is a set of edges (u, v) with weight R?uv. To
filter out null alignment, we construct only the edges
with weight R?uv ? ?. From this bipartite graph,
the maximum weighted bipartite matching problem
finds a set of pairwise non-adjacent edges S ? E
such that
?
(u,v)?S R?uv is the maximum. Well-
known algorithms include Hungarian algorithm with
time complexity of O(|V |2 log |V |+ |V ||E|) (West,
2000).
In this paper, to speed up processing, we consider
a greedy alternative with the following steps? (1)
choose the pair with the highest similarity score, (2)
remove the corresponding row and column from the
matrix, and (3) repeat (1) and (2) until their match-
ing scores are over a specific threshold ?.
4 Experiments
This section reports our experimental results to eval-
uate our proposed approach. First, we report our ex-
perimental setting in Section 4.1. Second, we vali-
date the effectiveness and the scalability of our ap-
proach over a real-life dataset in Section 4.2.
4.1 Experimental Settings
This section describes (1) how we collect the En-
glish and Chinese EntityCube datasets, (2) how to
build ground-truth test datasets for evaluating our
framework, and (3) how to set up three parameters
?, ?, and ?.
First, we crawled Ge = (Ve, Ee) and Gc =
(Vc, Ec) from English and Chinese EntityCubes.
Specifically, we built a graph pairs (Ge, Gc) expand-
ing from a ?seed pair? of nodes se ? Ve and sc ? Vc
until the number of nodes for each graph becomes
1,0006. More specifically, when we build a graph
Ge by expanding from se, we use a queue Q. We
first initialize Q by pushing the seed node se. We
then iteratively pop a node ve from Q, save ve into
Ve, and push its neighbor nodes in decreasing order
of co-occurrence scores with ve. Similarly, we can
get Gc from a counterpart seed node vc. By using
this procedure, we built six graph pairs from six dif-
ferent seed pairs. In particular, the six seed nodes
are English names and its corresponding Chinese
names representing a wide range of occupation do-
mains (e.g., ?Barack Obama,? ?Bill Gates,? ?Britney
Spears,? ?Bruno Senna,? ?Chris Paul,? and ?Eminem?)
as Table 1 depicts. Meanwhile, though we demon-
strate the effectiveness of the proposed method for
mining name translations in Chinese and English
languages, the method can be easily adapted to other
language pairs.
Table 1: Summary for graphs and test datasets obtained
from each seed pair
i |Ve|, |Vc| |Ti| English Name Chinese Name
1 1,000 51 Barack Obama ?n.???j
2 1,000 52 Bill Gates ??
3 1,000 40 Britney Spears Y}????
4 1,000 53 Bruno Senna Y0L??
5 1,000 51 Chris Paul .????[
6 1,000 57 Eminem ???
Second, we manually searched for about 50
?ground-truth? matched translations for each graph
pair to build test datasets Ti, by randomly selecting
nodes within two hops7 from the seed pair (se, sc),
since nodes outside two hops may include nodes
whose neighbors are not fully crawled. More specif-
ically, due to our crawling process expanding to add
neighbors from the seed, the nodes close to the seed
have all the neighbors they would have in the full
graph, while those far from the node may not. In or-
der to pick the nodes that well represent the actual
6Note, this is just a default setting, which we later increase
for scalability evaluation in Figure 6.
7Note that the numbers of nodes within two hops in Ge and
Gc are 327 and 399 on average respectively.
435
neighbors, we built test datasets among those within
two hops. However, this crawling is used for the
evaluation sake only, and thus does not suggest the
bias in our proposed framework. Table 1 describes
the size of such test dataset for each graph pair.
Lastly, we set up the three parameters ?, ?, and
? using 6-fold cross validation with 6 test datasets
Ti?s of the graphs. More specifically, for each
dataset Ti, we decide ?i and ?i such that average
MRR for the other 5 test datasets is maximized.
(About MRR, see more details of Equation (4) in
Section 4.2.) We then decide ?i such that average
F1-score is maximized. Figure 4 shows the average
MRR for ?i and ?i with default values ? = 0.66
and ? = 0.2. Based on these results, we set ?i with
values {0.2, 0.15, 0.2, 0.15, 0.2, 0.15} that optimize
MRR in datasets T1, . . . T6, and similarly ?i with
{0.67, 0.65, 0.67, 0.67, 0.65, 0.67}. We also set ?i
with values {0.63, 0.63, 0.61, 0.61, 0.61, 0.61} opti-
mizing F1-score with the same default values ? =
0.2 and ? = 0.66. We can observe the variances
of optimal parameter setting values are low, which
suggests the robustness of our framework.
4.2 Experimental Results
This section reports our experimental results using
the evaluation datasets explained in previous sec-
tion. For each graph pair, we evaluated the ef-
fectiveness of (1) reinforcement model using MRR
measure in Section 4.2.1 and (2) overall framework
using precision, recall, and F1 measures in Sec-
tion 4.2.2. We also validated (3) scalability of our
framework over larger scale of graphs (with up to
five thousand nodes) in Section 4.2.3. (In all experi-
mental results, Bold numbers indicate the best per-
formance for each metric.)
4.2.1 Effectiveness of reinforcement model
We evaluated the reinforcement model over
MRR (Voorhees, 2001), the average of the recipro-
cal ranks of the query results as the following for-
mula:
MRR = 1
|Q|
?
q?Q
1
rankq
(4)
Each q is a ground-truth matched pair (u, v) such
that u ? Ve and v ? Vc, and rankq is the rank of the
similarity score of Ruv among all Ruk?s such that
k ? Vc. Q is a set of such queries. By comparing
MRRs for two matricesR0 andR?, we can validate
the effectiveness of the reinforcement model.
? Baseline matrix (R0): using only the translit-
eration similarity score, i.e., without reinforce-
ment
? Reinforced matrix (R?): using the reinforced
similarity score obtained from Equation (3)
Table 2: MRR of baseline and reinforced matrices
Set MRRBaseline R0 Reinforced R?
T1 0.6964 0.8377
T2 0.6213 0.7581
T3 0.7095 0.7989
T4 0.8159 0.8378
T5 0.6984 0.8158
T6 0.5982 0.8011
Average 0.6900 0.8082
We empirically observed that the iterative model
converges within 5 iterations. In all experiments, we
used 5 iterations for the reinforcement.
Table 2 summarizes our experimental results. As
these figures show, MRR scores significantly in-
crease after applying our reinforcement model ex-
cept for the set T4 (on average from 69% to 81%),
which indirectly shows the effectiveness of our rein-
forcement model.
4.2.2 Effectiveness of overall framework
Based on the reinforced matrix, we evaluated
the effectiveness of our overall matching framework
using the following three measures?(1) precision:
how accurately the method returns matching pairs,
(2) recall: how many the method returns correct
matching pairs, and (3) F1-score: the harmonic
mean of precision and recall. We compared our ap-
proach with a baseline, mapping two graphs with
only transliteration similarity.
? Baseline: in matching extraction, using R0 as
the similarity matrix by bypassing the rein-
forcement step
? Ours: using R?, the similarity matrix con-
verged by Equation (3)
436
0.1 0.15 0.2 0.25 0.30.77
0.78
0.79
0.8
0.81
0.82
0.83
0.84
0.85
?(?=0.66)
AVG
(MR
R)
 
 
?1?2?3?4?5?6
0.61 0.63 0.65 0.67 0.690.74
0.76
0.78
0.8
0.82
0.84
? (?=0.2)
AVG
(MR
R)
 
 
?1
?2
?3
?4
?5
?6
0.57 0.59 0.61 0.63 0.650.68
0.69
0.7
0.71
0.72
0.73
0.74
?(?=0.2, ?=0.66)
AVG
(F1?
scor
e)
 
 
?1?2?3?4?5?6
Figure 4: Parameter setup for ?, ?, and ?
In addition, we compared ours with the machine
translators of Engkoo and Google. Table 3 summa-
rizes our experimental results.
As this table shows, our approach results in the
highest precision (about 80% on average) without
compromising the best recall of Google, i.e., 61%
of Google vs. 63% of ours. Overall, our approach
outperforms others in all three measures.
Meanwhile, in order to validate the translation ac-
curacy over popular head and long-tail, as discussed
in Section 1, we separated the test data into two
groups and analyzed the effectiveness separately.
Figure 5 plots the number of hits returned for the
names from Google search engine. According to the
distribution, we separate the test data into top-100
popular people with the highest hits and the remain-
ing, denoted head and tail, respectively.
0 50 100 150 200 250 300 35010
4
105
106
107
108
Number of names
Nu
mb
er o
f hi
ts i
n G
oog
le
Figure 5: Distribution over number of hits
Table 4 shows the effectiveness with both
datasets, respectively. As difference of the effective-
ness between tail and head (denoted diff ) with re-
spect to three measures shows, our approach shows
stably high precision, for both heads and tails.
4.2.3 Scalability
To validate the scalability of our approach, we
evaluated the effectiveness of our approach over the
number of nodes in two graphs. We built larger six
graph pairs (Ge, Gc) by expanding them from the
seed pairs further until the number of nodes reaches
5,000. Figure 6 shows the number of matched trans-
lations according to such increase. Overall, the num-
ber of matched pairs linearly increases as the num-
ber of nodes increases, which suggests scalability.
The ratio of node overlap in two graphs is about be-
tween 7% and 9% of total node size.
1000 2000 3000 4000 500050
100
150
200
250
300
350
|Ve| and |Vc|
# m
atc
hed
 tra
nsla
tion
s
Figure 6: Matched translations over |Ve| and |Vc|
5 Conclusion
This paper abstracted name translation problem as a
matching problem of two entity-relationship graphs.
This novel approach complements existing name
translation work, by not requiring rare resources
of parallel or comparable corpus yet outperforming
the state-of-the-art. More specifically, we combine
bilingual phonetic similarity and monolingual Web
co-occurrence similarity, to compute a holistic no-
tion of entity similarity. To achieve this goal, we de-
437
Table 3: Precision, Recall, and F1-score of Baseline, Engkoo, Google, and Ours over test sets Ti
Set Precision Recall F1-scoreEngkoo Google Baseline Ours Engkoo Google Baseline Ours Engkoo Google Baseline Ours
T1 0.5263 0.4510 0.5263 0.8974 0.3922 0.4510 0.1961 0.6863 0.4494 0.4510 0.2857 0.7778
T2 0.7551 0.75 0.7143 0.8056 0.7115 0.75 0.2885 0.5577 0.7327 0.75 0.4110 0.6591
T3 0.5833 0.7925 0.5556 0.7949 0.5283 0.7925 0.1887 0.5849 0.5545 0.7925 0.2817 0.6739
T4 0.5 0.45 0.7368 0.7353 0.425 0.45 0.35 0.625 0.4595 0.45 0.4746 0.6757
T5 0.6111 0.3137 0.5 0.7234 0.4314 0.3137 0.1765 0.6667 0.5057 0.3137 0.2609 0.6939
T6 0.5636 0.8947 0.6 0.8605 0.5438 0.8947 0.1053 0.6491 0.5536 0.8947 0.1791 0.74
AVG 0.5899 0.6086 0.6055 0.8028 0.5054 0.6086 0.2175 0.6283 0.5426 0.6086 0.3155 0.7034
Table 4: Precision, Recall, and F1-score of Engkoo, Google, and Ours with head and tail datasets
Method Precision Recall F1-scorehead tail diff head tail diff head tail diff
Engkoo 0.6082 0.5854 0.0229 0.59 0.4706 0.1194 0.5990 0.5217 0.0772
Google 0.75 0.5588 0.1912 0.75 0.5588 0.1912 0.75 0.5588 0.1912
Ours 0.8462 0.7812 0.0649 0.66 0.6127 0.0473 0.7416 0.6868 0.0548
veloped a graph alignment algorithm that iteratively
reinforces the matching similarity exploiting rela-
tional similarity and then extracts correct matches.
Our evaluation results empirically validated the ac-
curacy of our algorithm over real-life datasets, and
showed the effectiveness on our proposed perspec-
tive.
Acknowledgments
This work was supported by Microsoft Research
Asia NLP theme funding and MKE (Ministry of
Knowledge Economy), Korea, under the ITRC (In-
formation Technology Research Center) support
program supervised by the IITA (Institute for In-
formation Technology Advancement) (IITA-2009-
C1090-0902-0045).
References
Yaser Al-Onaizan and Kevin Knight. 2002. Trans-
lating Named Entities Using Monolingual and Bilin-
gual Resources. In Proceedings of the 40th Annual
Meeting on Association for Computational Linguistics
(ACL?02), pages 400?408. Association for Computa-
tional Linguistics.
Donghui Feng, Yajuan Lu?, and Ming Zhou. 2004.
A New Approach for English-Chinese Named En-
tity Alignment. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP?04), pages 372?379. Association for Com-
putational Linguistics.
Pascale Fung and Lo Yuen Yee. 1998. An IR Ap-
proach for Translating New Words from Nonparal-
lel,Comparable Texts. In Proceedings of the 17th In-
ternational Conference on Computational Linguistics
(COLING?98), pages 414?420. Association for Com-
putational Linguistics.
Long Jiang, Ming Zhou, Lee feng Chien, and Cheng Niu.
2007. Named Entity Translation withWebMining and
Transliteration. In Proceedings of the 20th Interna-
tional Joint Conference on Artificial Intelligence (IJ-
CAI?07), pages 1629?1634. Morgan Kaufmann Pub-
lishers Inc.
Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu, and
Qingsheng Zhu. 2009. Mining Bilingual Data from
the Web with Adaptively Learnt Patterns. In Proceed-
ings of the 47th Annual Meeting of the Association for
Computational Linguistics (ACL?09), pages 870?878.
Association for Computational Linguistics.
Kevin Knight and Jonathan Graehl. 1998. Ma-
chine Transliteration. Computational Linguistics,
24(4):599?612.
Julian Kupiec. 1993. An Algorithm for finding Noun
Phrase Correspondences in Bilingual Corpora. In Pro-
ceedings of the 31th Annual Meeting of the Association
for Computational Linguistics (ACL?93), pages 17?22.
Association for Computational Linguistics.
Haizhou Li, Zhang Min, and Su Jian. 2004. A Joint
Source-Channel Model for Machine Transliteration.
In Proceedings of the 42nd Annual Meeting on Associ-
ation for Computational Linguistics (ACL?04), pages
159?166. Association for Computational Linguistics.
Dekang Lin, Shaojun Zhao, Benjamin Van Durme, and
Marius Pasca. 2008. Mining Parenthetical Transla-
438
tions from the Web by Word Alignment. In Proceed-
ings of the 46th Annual Meeting of the Association
for Computational Linguistics (ACL?08), pages 994?
1002. Association for Computational Linguistics.
Li Shao and Hwee Tou Ng. 2004. Mining New Word
Translations from Comparable Corpora. In Proceed-
ings of the 20th International Conference on Computa-
tional Linguistics (COLING?04), pages 618?624. As-
sociation for Computational Linguistics.
Ellen M. Voorhees. 2001. The trec question answering
track. Natural Language Engineering, 7(4):361?378.
Stephen Wan and Cornelia Maria Verspoor. 1998. Auto-
matic English-Chinese Name Transliteration for De-
velopment of Multilingual Resources. In Proceed-
ings of the 17th International Conference on Compu-
tational Linguistics (COLING?98), pages 1352?1356.
Association for Computational Linguistics.
Douglas Brent West. 2000. Introduction to Graph The-
ory. Prentice Hall, second edition.
439
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 59?63,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
Map Translation Using Geo-tagged Social Media
Sunyou Lee, Taesung Lee, Seung-won Hwang
POSTECH, Korea
{sylque,elca4u,swhwang}@postech.edu
Abstract
This paper discusses the problem of map
translation, of servicing spatial entities in
multiple languages. Existing work on
entity translation harvests translation ev-
idence from text resources, not consider-
ing spatial locality in translation. In con-
trast, we mine geo-tagged sources for mul-
tilingual tags to improve recall, and con-
sider spatial properties of tags for transla-
tion to improve precision. Our approach
empirically improves accuracy from 0.562
to 0.746 using Taiwanese spatial entities.
1 Introduction
A map is becoming an essential online service for
mobile devices, providing a current location and
generating directions to spatial entities (SEs). Al-
though major map services aim to support a map
in more than 100 local languages, their current
support is often biased either to English or local
maps. For example, Figure 1 contrasts richly pop-
ulated Taiwanese entities (in the local language)
whereas only some of those entities are translated
in English version. Our goal is to translate richly
populated SEs into another language, in the finer
granularity such as restaurants.
A baseline approach would be adopting
existing work on entity transliteration work,
which uses phonetic similarity, such as trans-
lating ?Barack Obama? into ?????????
[Beilake?Aobama]. Another approach is using
automatically-harvested or manually-built transla-
tion resources, such as multilingual Gazetteer (or,
SE dictionary
1
). However, these resources are
often limited to well-known or large SEs, which
leads to translation with near-perfect precision but
low recall.
1
For example, http://tgnis.ascc.net provides SE transla-
tion pairs.
Moreover, blindly applying existing entity
translation methods to SE translation leads to ex-
tremely low accuracy. For example, an SE ??
???? should be translated into ?Shifen sta-
tion?, where ???? is transliterated to [Shifen],
whereas ???? is semantically translated based
on its meaning ?station?. However, due to this
complex nature often observed in SE translation,
an off-the-shelf translation service (e.g., Google
Translate) returns ?very station?
2
as an output. In
addition, SE names are frequently abbreviated so
that we cannot infer the meanings to semantically
translate them. For instance, ?United Nations? is
often abbreviated into ?UN? and its translation is
also often abbreviated. As a result, the abbrevia-
tion in the two languages, (UN, ???), shares
neither phonetic nor semantic similarity.
To overcome these limitations, we propose to
extract and leverage properties of SEs from a so-
cial media, namely Flickr. Especially, we ex-
ploit co-occurrence of names in two different lan-
guages. For example, ???? co-occurs with its
English translation ?Taipei? as tags on the same
photo. This is strong evidence that they are trans-
lations of each other. In addition to co-occurrence,
we leverage spatial properties of SEs. For ex-
ample, among tags that frequently co-occur with
????, such as ?Taipei? and ?Canon?, ?Taipei? is
2
As of Dec 26, 2013.
Figure 1: A map of Taipei in English. Google
Maps, as of Oct 14, 2013
59
Symbols Description
C A set of all Chinese spatial entities
c A Chinese spatial entity, c ? C
e An English entity
p A photo
D Photos
D
c
Photos with c
D
e
Photos with e
E
c
a set of English tags from D
c
G
c
a set of GPS coordinates from D
c
G
e
a set of GPS coordinates from D
e
Table 1: Overview of symbols
more likely to be its correct translation because
the spatial distributions of the two tags are simi-
larly skewed in the same area. Our approach sig-
nificantly improves the F1-score (0.562 to 0.746),
compared to an off-the-shelf translators.
2 Overall Framework
We provide the framework of our proposed
method using predefined symbols (Table 1). We
consider a scenario of translating each SE c in a
set of all SEs C in a Chinese map into English so
that we obtain an English map
3
.
STEP 1. Finding a set D
c
: We crawl a photo
set D with tags from Flickr. We consider each of
the tags as an entity. Given an SE c ? C, we find a
setD
c
? D. For each photo in D
c
, we obtain a set
of tags in multiple languages and GPS coordinates
of the photo as translation evidence (Table 2).
STEP 2. Collecting candidate English tags:
To obtain translation candidates of c, we build a
set E
c
of English tags that co-occur with c, and a
set D
e
? D of photos for each e ? E
c
.
STEP 3. Calculating matching score w(c, e):
For an English candidate e ? E
c
, we calculate the
matching score between c and e, and translate c
into e with the highest w(c, e) score. We describe
the details of computing w(c, e) in Section 3.
3
We use an example of translating from Chinese to En-
glish for illustration, but we stress that our work straightfor-
wardly extends if multilingual tags of these two languages are
sufficient.
Photos Chinese tag English tag
p
1
??? Taipei, The Queen?s
Head, food
p
2
?? love river, food, park,
dog
p
3
??,??? Yehliu, Taipei, food
p
4
??, ???,
???
The Queen?s Head,
Taipei, restaurant
p
5
??? Taipei, Tamsui river,
dog, food
Table 2: Structure of crawled photos D = {p
1
, p
2
,
p
3
, p
4
, p
5
}
e The Queen?s Head Taipei
D
e
{p
1
, p
4
} {p
1
, p
3
, p
4
, p
5
}
CF (c, e) (FB) 2 3
TS(c, e) 0 -0.3
w(c, e) (SB) 0 -0.9
Table 3: SB vs. FB: Translating c = ??? into
e ? E??? where D??? = {p1, p3, p4}
3 Matching Score
3.1 Naive Approach: Frequency-based
Translation (FB)
A naive solution for map translation is to use co-
occurrence of multilingual tags. For example, if a
Chinese tag ????? frequently co-occurs with an
English tag ?The Queen?s Head?, we can translate
????? into ?The Queen?s Head?. Specifically,
for a given Chinese SE c and a candidate English
tag e, we define co-occurring frequency CF (c, e).
Definition. Co-occurring Frequency CF (c, e).
Co-occurring frequencyCF (c, e) is the number of
photos in which c and e are co-tagged,
CF (c, e) = |D
c
?D
e
|, (1)
where D
c
and D
e
are photos with a Chinese SE c
and an English tag e, respectively.
We compute CF (c, e) for all candidates in e ?
E
c
and rank them. Then, FB translates c into e
with the highest CF (c, e) score. However, FB
cannot address the following two challenges that
occur due to tag sparseness.
? C1 : Large regions such as ?Taiwan?, ?Taipei?
(Section 3.2)
? C2 : Non-SEs such as ?dog?, ?food? (Section
3.3)
60
3.2 Overcoming C1: Scarcity-biased
Translation (SB)
Users tend to tag photos with both a specific SE
and large administrative regions such as ?Taiwan?
and ?Taipei?, which makes FB score of large re-
gions higher than the proper one. For exam-
ple, ?Taipei? is tagged in most photos in D (Ta-
ble 2); therefore, CF (???, Taipei) larger than
CF (???, The Queen?s Head) (Table 3).
To reduce the effect of large regions, we intro-
duce a new feature to give high scores for specific
SEs (e.g., ?The Queen?s Head?). We observe that
a large region?s tag is associated with many pho-
tos in D ? D
c
, whereas a scarce but useful tag
is particularly tagged in D
c
. We consider
|D
e
|
|D?D
c
|
to measure how many photos have e without c.
Therefore,
|D
e
|
|D?D
c
|
increases as e frequently ap-
pears where c does not. In contrast, if e appears
mostly with c, the ratio decreases. Taking inverse
of the ratio to give higher score when e appears
mostly with c, we define tag scarcity TS(c, e) and
apply it to the candidate ranking function.
Definition. Tag scarcity TS(c, e). Given an SE
c and a candidate English tag e ? E
c
, the tag
scarcity is defined as
TS(c, e) = log |D ?D
c
|/|D
e
|. (2)
Definition. Scarcity-biased Matching Score
w(c, e). Given an SE c and a candidate English
tag e ? E
c
, the matching score between c and e is
w(c, e) = CF (c, e) ? TS(c, e). (3)
To illustrate the effect of SB with our run-
ning example (Table 2), we compare ?The Queen?s
Head? to ?Taipei? for translating ????? (Ta-
ble 3). FB gives a higher score to ?Taipei? than
to the correct translation ?The Queen?s Head?. In
contrast, by reflecting TS, SB correctly concludes
that ?The Queen?s Head? is the best match.
Apart from SB, we can also leverage an ad-
ditional resource such as an administrative hier-
archy, if exists, to blacklist some large regions?
names from E
c
. By first translating larger re-
gions and excluding them, the precision for trans-
lating small SEs can increase. For instance, we
translate a country ??? (Taiwan)? earlier than a
city ??? (Taipei)?. Then, when translating ??
??, even though CF (??, Taiwan) is higher than
CF (??, Taipei), we ignore ?Taiwan? in E?? be-
cause it is already matched with ????.
3.3 Overcoming C2: Pruning Non-SEs (PN)
We prune non-SEs such as ?food? based on spatial
locality of a tag. We observe that the GPS coor-
dinates G
e
of photos with an SE tag e tend to be
more concentrated in a specific region than those
of photos with a non-SE. For instance, comparing
a non-SE ?food? and an SE ?The Queen?s Head?,
the GPS coordinates in G
food
are more widespread
all over Taiwan than those in G
The Queen?s Head
.
We leverage the coordinates of a distant SE
pair. For example, two spatially far SEs ???
(Taipei)? and ??? (Taitung)? compose a distant
SE pair. Because both SEs are unlikely to be
tagged in a single photo, an English tag that co-
occurs with both of them would be a non-SE.
Formally, we define two Chinese SEs c
1
and c
2
as a distant SE pair if G
c
1
?G
c
2
= ?, and M as a
set of all distant SE pairs among C?C. We judge
that an English tag e is a non-SE if G
e
intersects
with both G
c
1
and G
c
2
for a distant pair c
1
and
c
2
. Formally, an English tag e is non-SE if the
following equation PN(e) is nonzero.
PN(e) =
?
(c
1
,c
2
)?M
|G
c
1
?G
e
| ? |G
c
2
?G
e
|. (4)
4 Evaluation
4.1 Experimental Setting
Photo Data and Ground Truth: We crawled
227,669 photos taken in Taipei from Flickr, which
also provided GPS coordinates of photos. We took
a setD of 148,141 photos containing both Chinese
and English tags and manually labelled 200 gold
standard Chinese-English SE pairs whose names
appeared together in at least one photo in D.
Administrative Hierarchy: An administrative
hierarchy was obtained from Taiwan Geographi-
cal Names Information System
4
.
Baselines: We chose baselines available for
many languages except for the gazetteer and ex-
cluded methods that used specific textual corpora.
? Phonetic Similarity (PH) (Kim et al., 2013)
? Off-the-shelf Translator: Google Translate
5
,
Bing Translator
6
? Taiwanese-English Gazetteer (official SE
translation
4
)
4
http://tgnis.ascc.net/. Its latest modification
has done on August 23, 2013.
5
http://translate.google.co.kr/
6
http://www.bing.com/translator
61
Chinese SE SB+PN PH Google Translate Bing Translator Gazetteer
[Transliteration]
???? To House Astrid Rabbit Restaurant Hare House ?
[Tuzi Canting]
????? Denwell Restaurant Taipei Restaurants Dianhua Flagship Classic China ?
[Dianhua Gijianguan] Museum Flagship Center
Table 4: Example translation from our method and the baselines (Correct translations are boldfaced.)
Method P R F1
Transliteration .463 .463 .463
Google Translate .562 .562 .562
Bing Translator .425 .425 .425
Taiwanese-English Gazetteer .960 .485 .645
Table 5: P, R, and F1 of baselines
Measures: We measured precision (P), recall
(R), F1-Score (F1), and mean reciprocal rank
(MRR) where MRR =
1
|P |
?
(c,e
0
)?P
1
rank(c,e
0
)
,
for which P is a set of gold standard pairs (c, e
0
)
of a Chinese SE c and its correct translation e
0
, and
rank(c, e
0
) indicates the rank of w(c, e
0
) among
all w(c, e) s.t. e ? E
c
.
4.2 Experimental Results
Comparison to Baselines: The proposed ap-
proach (SB + PN) with or without the administra-
tive hierarchy provided higher R and F1 than did
the baseline methods (Table 5, 6).
The baseline methods showed generally low P,
R, and F1. Especially, the gazetteer produced
high precision, but poor recall because it could not
translate lesser-known SEs such as ????? (To
House)? and ?????? (Denwell Restaurant)?
(Table 4).
Effect of SB and PN: We experimented on the
effect of the combinations of the features (Ta-
ble 6). Using all the features FB+SB+PN with
hierarchy, which translated the upper level of the
hierarchy with FB and the lower level with SB,
showed the best effectiveness. Simple FB gave
both low precision and very low recall regardless
of whether we used the hierarchy. Replacing FB
with SB yielded both higher F1 and higher MRR.
PN increased F1, especially greatly when it was
used with SB or the hierarchy because PN filtered
out different types of noises, non-SEs. Apply-
ing PN, we classified 361 non-SEs and 6 SEs as
noises in total. Despite some misclassifications, it
Method P R F1 MRR
FB .215 .215 .215 .439
FB + PN .220 .220 .220 .454
SB .640 .640 .640 .730
SB + PN .680 . 670 .675 .752
(a) Without administrative hierarchy
Method P R F1 MRR
FB .515 .515 .515 .641
FB + PN .624 .615 .620 .730
SB .655 .655 .655 .733
SB + PN .706 .695 .700 .763
FB + SB + PN .751 .740 .746 .806
(b) With given hierarchy
Table 6: Effect of FB, SB, PN, and the hierarchy
improved the overall accuracy by ignoring highly
ranked non-SEs such as ?dog? and ?food?.
5 Conclusion
We propose a scalable map translator that uses
a geo-tagged corpus from social media to mine
translation evidence to translate between English
and maps in local languages. Our approach lever-
ages both co-occurrence of the SE tags in Chinese
and English and their scarcity and spatial property.
Our approach can translate small or emerging spa-
tial entities such as restaurants, which major map
services cannot support currently. We empirically
validated that our approach provided higher P, R,
F1, and MRR than the existing methods including
popular off-the-shelf translation services.
Acknowledgments
This research was supported by the MSIP (The
Ministry of Science, ICT and Future Planning),
Korea and Microsoft Research, under IT/SW
Creative research program supervised by the
NIPA(National IT Industry Promotion Agency).
(NIPA-2013-H0503-13-1009).
62
References
Jinhan Kim, Seung-won Hwang, Long Jiang, Y Song,
and Ming Zhou. 2013. Entity translation mining
from comparable corpora: Combining graph map-
ping with corpus latent features. IEEE Transactions
on Knowledge and Data Engineering, 25(8):1787?
1800.
63
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 631?640,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Bootstrapping Entity Translation on Weakly Comparable Corpora
Taesung Lee and Seung-won Hwang
Department of Computer Science and Engineering
Pohang University of Science and Technology (POSTECH)
Pohang, Republic of Korea
{elca4u, swhwang}@postech.edu
Abstract
This paper studies the problem of mining
named entity translations from compara-
ble corpora with some ?asymmetry?. Un-
like the previous approaches relying on the
?symmetry? found in parallel corpora, the
proposed method is tolerant to asymme-
try often found in comparable corpora, by
distinguishing different semantics of rela-
tions of entity pairs to selectively prop-
agate seed entity translations on weakly
comparable corpora. Our experimental
results on English-Chinese corpora show
that our selective propagation approach
outperforms the previous approaches in
named entity translation in terms of the
mean reciprocal rank by up to 0.16 for or-
ganization names, and 0.14 in a low com-
parability case.
1 Introduction
Identifying and understanding entities is a cru-
cial step in understanding text. This task is
more challenging in the presence of multilingual
text, because translating named entities (NEs),
such as persons, locations, or organizations, is
a non-trivial task. Early research on NE trans-
lation used phonetic similarities, for example,
to mine the translation ?Mandelson??????
??[ManDeErSen] with similar sounds. However,
not all NE translations are based on translitera-
tions, as shown in Table 1?Some translations,
especially the names of most organizations, are
based on semantic equivalences. Furthermore,
names can be abbreviated in one or both lan-
guages, e.g., the ?World Trade Organization? (?
?????) can be called the ?WTO? (???
?). Another challenging example is that, a trans-
lation can be arbitrary, e.g., ?Jackie Chan? ? ??
?? [ChengLong]. There are many approaches
English Chinese
World Trade
Organization
??????
[ShiJieMaoYiZuZhi]
WTO ???? [ShiMaoZuZhi]
Jackie Chan ?? [ChengLong]
Table 1: Examples of non-phonetic translations.
that deal with some of these challenges (Lam et
al., 2007; Yang et al, 2009), e.g., by combin-
ing phonetic similarity and a dictionary. How-
ever, arbitrary translations still cannot be handled
by examining the NE pair itself. Corpus-based ap-
proaches (Kupiec, 1993; Feng, 2004), by mining
external signals from a large corpus, such as par-
enthetical translation ??? (Jackie Chan)?, com-
plement the problem of transliteration-based ap-
proaches, but the coverage of this approach is lim-
ited to popular entities with such evidence.
The most effective known approach to NE
translation has been a holistic framework (You et
al., 2010; Kim et al, 2011; You et al, 2012) com-
bining transliteration- and corpus-based methods.
In these approaches, both 1) arbitrary translations
and 2) lesser-known entities can be handled, by
propagating the translation scores of known enti-
ties to lesser-known entities if they co-occur fre-
quently in both corpora. For example, a lesser-
known entity Tom Watson can be translated if
Mandelson and Tom Watson co-occur frequently
in an English corpus, and their Chinese transla-
tions also co-occur frequently in a Chinese corpus,
i.e., if the co-occurrences in the two corpora are
?symmetric?.
A research question we ask in this paper is:
What if comparable corpora are not comparable
enough to support this symmetry assumption? We
found that this is indeed the case. For exam-
ple, even English and Chinese news from the
same publisher may have different focus? the Chi-
nese version focuses more on Chinese Olympic
631
teams and Chinese local news. In the presence of
such asymmetry, all previous approaches, building
upon symmetry, quickly deteriorate by propagat-
ing false positives. For example, co-occurrence of
Mandelson and Tom Watson may not appear in a
Chinese corpus, which may lead to the translation
of Tom Watson into another Chinese entity Gor-
don Brown which happens to co-occur with the
Chinese translation of Mandelson.
Our key contribution is to avoid such false
propagation, by discerning the semantics of rela-
tions. For example, relations between Mandelson
and Tom Watson, should be semantically differ-
ent from Chinese relations between ???????
(Gordon Brown) and ?????? (Mandelson). A
naive approach would be finding documents with
a similar topic such as politics, and scientific dis-
covery, and allowing propagation only when the
topic agrees. However, we found that a topic is a
unit that is too coarse for this task because most
articles on Mandelson will invariably fall into the
same topic1. In clear contrast, we selectively prop-
agate seed translations, only when the relations in
the two corpora share the same semantics.
This selective propagation can be especially ef-
fective for translating challenging types of enti-
ties such as organizations including theWTO used
with and without abbreviation in both languages.
Applying a holistic approach (You et al, 2012)
on organizations leads to poor results, 0.06 in
terms of the F1-score. A naive approach to in-
crease the precision would be to consider multi-
type co-occurrences, hoping that highly precise
translations of some type, e.g., persons with an
F1-score of 0.69 (You et al, 2012), can be prop-
agated to boost the precision on organizations.
In our experiments, this naive multi-type prop-
agation still leads to an unsatisfactory F1-score
of 0.12. Such a low score can be explained by
the following example. When translating ?WTO?
using the co-occurrence with ?Mandelson?, other
co-occurrences such as (London, Mandelson) and
(EU, Mandelson) produce a lot of noise because
the right translation of WTO does not share much
phonetic/semantic similarity. Our understanding
of relation semantics, can distinguish ?Mandelson
was born in London? from ?Mandelson visited the
WTO?, to stop false propagations, which gener-
ates an F1-score 0.25 higher than the existing ap-
1The MRR for organization names achieved by a topic
model-based approach was 0.15 lower than our best.
proaches.
More formally, we enable selective propagation
of seed translations on weakly comparable cor-
pora, by 1) clarifying the detailed meaning of rela-
tional information of co-occurring entities, and 2)
identifying the contexts of the relational informa-
tion using statement-level context comparison. In
other words, we propagate the translation score of
a known translation pair to a neighbor pair if the
semantics of their relations in English and Chinese
corpora are equivalent to accurately propagate the
scores. For example, if we know ?Russia?????
??(1) and join???(2), then from a pair of state-
ments ?Russia(1) joins(2) theWTO(3)? and ????(1)
??(2) ????(3)?, we can propagate the trans-
lation score of (Russia, ???)(1) to (WTO, ?
???)(3). However, we do not exploit a pair of
statements ?Russia joined the WTO? and ????
??(2?) ???? because ??(2?) does not mean
join(2). Furthermore, we mine a similar English-
Chinese document pair that can be found by com-
paring the entity relationships, such as ?Mandel-
son visited Moscow? and ?Mandelson met Alexei
Kudrin?, within the English document and the
Chinese document to leverage similar contexts to
assure that we use symmetric parts.
For this goal, we first extract relations among
entities in documents, such as visit and join, and
mine semantically equivalent relations across the
languages, e.g., English and Chinese, such as
join???. Once these relation translations are
mined, similar document pairs can be identified
by comparing each constituent relationship among
entities using their relations. Knowing document
similarity improves NE translation, and improved
NE translation can boost the accuracy of document
and relationship similarity. This iterative process
can continue until convergence.
To the best of our knowledge, our approach is
the first to translate a broad range of multilin-
gual relations and exploit them to enhance NE
translation. In particular, our approach leverages
semantically similar document pairs to exclude
incomparable parts that appear in one language
only. Our method outperforms the previous ap-
proaches in translating NE up to 0.16 in terms of
the mean reciprocal rank (MRR) for organization
names. Moreover, our method shows robustness,
with 0.14 higher MRR than seed translations, on
less comparable corpora.
632
2 Related Work
This work is related to two research streams: NE
translation and semantically equivalent relation
mining.
Entity translation
Existing approaches on NE translation can be cat-
egorized into 1) transliteration-based, 2) corpus-
based, and 3) hybrid approaches.
Transliteration-based approaches (Wan and Ver-
spoor, 1998; Knight and Graehl, 1998) are the
foundations of many decent methods, but they
alone suffer from ambiguity (e.g., ??? and
??? have the same sounds) and cannot han-
dle non-transliterated cases such as ?Jackie Chan
(??[ChengLong])?. Some methods (Lam et al,
2007; Yang et al, 2009) rely on meanings of con-
stituent letters or words to handle organization
name translation such as ?Bank of China (??
??)?, whose translation is derived from ?China
(??)?, and ?a bank (??)?. However, many
names often originate from abbreviation (such as
?WTO?); hence we cannot always leverage mean-
ings.
Corpus-based approaches (Kupiec, 1993; Lin et
al., 2008; Jiang et al, 2009) exploit high-quality
bilingual evidence such as parenthetical transla-
tion, e.g., ??? (Jackie Chan)?, (Lin et al, 2008),
semi-structural patterns (Jiang et al, 2009), and
parallel corpus (Kupiec, 1993). However, the cov-
erage of the corpus-based approaches is limited to
popular entities with such bilingual evidences. On
the other hand, our method can cover entities with
monolingual occurrences in corpora, which signif-
icantly improves the coverage.
The most effective known approach is a holis-
tic framework that combines those two ap-
proaches (You et al, 2012; You et al, 2010; Kim
et al, 2011). You et al (2010; 2012) leverage two
graphs of entities in each language, that are gen-
erated from a pair of corpora, with edge weights
quantified as the strength of the relatedness of en-
tities. Then, two graphs are iteratively aligned us-
ing the common neighbors of two entities. Kim et
al. (2011) build such graphs using the context sim-
ilarity, measured with a bag of words approach, of
entities in news corpora to translate NEs. How-
ever, these approaches assume the symmetry of the
two graphs. This assumption holds if two corpora
are parallel, but such resources are scarce. But our
approach exploits comparable parts from corpora.
0
0.1
0.2
0.3
0 10 20 30 40 50
N
or
m
al
iz
ed
 O
cc
ur
re
nc
e
Weeks
WTO
????
Figure 1: Dissimilarity of temporal distributions
of ?WTO? in English and Chinese corpora.
Other interesting approaches such as (Klemen-
tiev and Roth, 2006; Kim et al, 2012) rely on tem-
poral distributions of entities. That is, two entities
are considered to be similar if the two entities in
different languages have similar occurrence distri-
butions over time. However, the effectiveness of
this feature also depends on the comparability of
entity occurrences in time-stamped corpora, which
may not hold as shown in Figure 1. In clear con-
trast, our method can find and compare articles,
on different dates, describing the same NE. More-
over, our method does not require time stamps.
Semantically similar relation mining
Recently, similar relation mining in one language
has been studied actively as a key part of automatic
knowledge base construction. In automatically
constructed knowledge bases, finding semanti-
cally similar relations can improve understanding
of the Web describing content with many different
expressions. As such an effort, PATTY (Nakas-
hole et al, 2012) finds similar relations with al-
most the same support sets?the sets of NE pairs
that co-occur with the relations. However, because
of the regional locality of information, bilingual
corpora contain many NE pairs that appear in only
one of the support sets of the semantically identi-
cal relations. NELL (Mohamed et al, 2011) finds
related relations using seed pairs of one given re-
lation; then, using K-means clustering, it finds re-
lations that are semantically similar to the given
relation. Unfortunately, this method requires that
we set K manually, and extract relations for each
given relation. Therefore, this is unsuitable to sup-
port general relations.
There are only few works on translating rela-
tions or obtaining multi-lingual similar relations.
Schone et al (2011) try to find relation patterns
633
in multiple languages for given seed pairs of a re-
lation. Because this approach finds seed pairs in
Wikipedia infoboxes, the number of retrievable re-
lations is restricted to five. Kim et al (2010) seek
more diverse types of relations, but it requires par-
allel corpora, which are scarce.
3 Framework Overview
In this section, we provide an overview of our
framework for translating NEs, using news cor-
pora in English and Chinese as a running example.
Because such corpora contain asymmetric parts,
the goal of our framework is to overcome asym-
metry by distinguishing the semantics of relations,
and leveraging document context defined by the
relations of entities.
(e) Iteration on ?? ????? ? ???  
(Section 4.5) 
(c) Relation 
Translation ? ? 
(Section 4.3) 
(d) Statement-Level 
Document Context 
Comparison ?? 
(Section 4.4) 
(b) Seed Entity 
Translation ? ??  
(Section 4.2) 
Iterative process 
English 
Corpus 
Chinese 
Corpus 
(a) Statement Extraction 
(Section 4.1) 
Figure 2: Framework overview.
For this purpose, we build a mutual bootstrap-
ping framework (Figure 2), between entity trans-
lation and relation translation using extracted re-
lationships of entities (Figure 2 (a), Section 4.1).
More formally, we use the following process:
1. Base condition (Figure 2 (a), Section 4.2): Ini-
tializing T (1)N (eE , eC), a seed entity translation
score, where eE is an English entity, and eC is
a Chinese entity. T (1)N can be initialized by pho-
netic similarity or other NE translation methods.
2. Iteration: Obtaining T t+1N using T tN .
1) Using T tN , we obtain a set of relation
translations with a semantic similarity score,
T tR(rE , rC), for an English relation rE and a
Chinese relation rC (Figure 2 (b), Section 4.3)
(e.g., rE =visit and rC =??).
2) Using T tN and T tR, we identify a set of seman-
tically similar document pairs that describe the
same event with a similarity score T tD(dE , dC)
where dE is an English document and dC is a
Chinese document (Figure 2 (c), Section 4.4).
3) Using T tN , T tR and T tD, we compute T t+1N , an
improved entity translation score (Figure 2 (d),
Section 4.5).
Each sub-goal reinforces the result of others in
the (t + 1)-th iteration, and by iteratively running
them, we can improve the quality of translations.
Note that, hereinafter, we omit (t) for readability
when there is no ambiguity.
4 Methods
In this section, we describe our method in de-
tail. First, we explain how we extract statements,
which are units of relational information, from
documents in Section 4.1, and how we obtain seed
name translations in Section 4.2. Next, we present
our method for discovering relation translations
across languages in Section 4.3. In Section 4.4, we
use the name translations and the relation trans-
lations to compare document contexts which can
boost the precision of NE translation. In Sec-
tion 4.5, we describe how we use the resources
obtained so far to improve NE translation.
4.1 Statement Extraction
We extract relational statements, which we exploit
to propagate translation scores, from an English
news corpus and a Chinese news corpus. A rela-
tional statement, or simply a statement is a triple
(x, r, y), representing a relationship between two
names, x and y. For example, from ?Mandel-
son recently visited Moscow,? we obtain this state-
ment: (Mandelson, visit, Moscow). We follow a
standard procedure to extract statements, as sim-
ilarly adopted by Nakashole et al (2012), using
Stanford CoreNLP (Klein and Manning, 2003) to
lemmatize and parse sentences. Here, we refer
readers to existing work for further details because
this is not our key contribution.
4.2 Seed Entity Translation
We need a few seed translation pairs to initi-
ate the framework. We build a seed transla-
tion score T (1)N (eE , eC) indicating the similar-
ity of an English entity eE and a Chinese en-
tity eC using an existing method. For exam-
ple, most methods would give high value for
634
T (1)N (Mandelson,???? [ManDeErSen]). In this
work, we adopted (You et al, 2012) with (Lam
et al, 2007) as a base translation matrix to build
the seed translation function. We also use a dictio-
nary to obtain non-NE translations such as ?gov-
ernment?. We use an English-Chinese general
word dictionary containing approximately 80,000
English-Chinese translation word pairs that was
also used by Kim et al (2011) to measure the sim-
ilarity of context words of entities.
4.3 Relation Translation
We need to identify relations that have the equiv-
alent semantics across languages, (e.g., visit??
?), to enable selective propagation of translation
scores. Formally, our goal is to measure a pair-
wise relation translation score TR(rE , rC) for an
English relation rE ? RE and a Chinese relation
rC ? RC whereRE is a set of all English relations
and RC is a set of all Chinese relations.
We first explain a basic feature to measure the
similarity of two relations, its limitations, and how
we address the problems. A basic clue is that re-
lations of the same meaning are likely to be men-
tioned with the same entity pairs. For example,
if we have (Mandelson, visit, Moscow) as well as
(Mandelson, head to, Moscow) in the corpus, this
is a positive signal that the two relations may share
the same meaning. Such NE pairs are called sup-
port pairs of the two relations.
We formally define this clue for relations in the
same language, and then describe that in the bilin-
gual setting. A support intersection Hm(ri, rj), a
set of support pairs, for monolingual relations ri
and rj is defined as
Hm(ri, rj) = H(ri) ?H(rj) (1)
where H(r) is the support set of a relation r de-
fined as H(r) = {(x, y)|(x, r, y) ? S}, and S is
either SE , a set of all English statements, or SC , a
set of all Chinese statements that we extracted in
Section 4.1.
Likewise, we can define a support intersection
for relations in the different languages using the
translation score TN (eE , eC). For an English rela-
tion rE and a Chinese relation rC ,
Hb(rE , rC) ={(xE , xC , yE , yC)|
TN (xE , xC) ? ?
and TN (yE , yC) ? ?
for (xE , rE , yE) ? SE
and (xC , rC , yC) ? SC}
(2)
where ? = 0.6 is a harsh threshold to exclude most
of the false translations by TN .
Finally, we define a support intersection, a set
of support pairs between two relations ri and rj of
any languages,
H(ri, rj) =
?
??
??
Hb(ri, rj) if ri ? RE and rj ? RC
Hb(rj , ri) if rj ? RE and ri ? RC
Hm(ri, rj) otherwise
(3)
Intuitively, |H(ri, rj)| indicates the strength of
the semantic similarity of two relations ri and
rj of any languages. However, as shown in Ta-
ble 2, we cannot use this value directly to mea-
sure the similarity because the support intersection
of semantically similar bilingual relations (e.g.,
|H(head to,??)| = 2) is generally very low,
and normalization cannot remedy this problem
as we can see from |H(visit,??)| = 27 and
|H(visit)| = 1617.
Set Cardinality
H(visit) 1617
H(??) 2788
H(visit,??) 27
H(head to,??) 2
Table 2: Evidence cardinality in the corpora.
?? 
visit 
head to 
call on 
denounce 
criticize 
blame 
ask 
request appeal to 
fly to 
8 
2 
1 
1 
2 4 
Figure 3: Network of relations. Edges indicate
that the relations have a non-empty support inter-
section, and edge labels show the size of the inter-
section.
We found that the connectivity among similar
relations is more important than the strength of
the similarity. For example, as shown in Figure 3,
visit is connected to most of the visit-relations
such as head to, ??. Although visit is con-
nected to criticize, visit is not connected to other
criticize-relations such as denounce and blame,
whereas criticize, denounce, and blame are inter-
635
?? 
visit 
head to 
visit-cluster 
denounce 
criticize 
blame      criticize-cluster 
call on 
10 
6 
fly to 
2 
call on ask 
request appeal to request-cluster 
Figure 4: Relation clusters and a few individual
relations. Edge labels show the size of the inter-
section.
connected. To exploit this feature, we use a ran-
dom walk-based graph clustering method.
Formally, we use Markov clustering (Van Don-
gen, 2000) on a graph G = (V,E) of relations,
where V = RE ? RC is a set of all English and
Chinese relations. An edge (ri, rj) indicates that
two relations in any languages are similar, and its
weight is quantified by a sigmoid function on a
linear transformation of |H(ri, rj)| that was em-
pirically found to produce good results.
Each resultant cluster forms a set of bilingual
similar relations, c = {rc1 , ..., rcM }, such as visit-
cluster, which consists of visit, head to, and??
in Figure 4. However, this cluster may not contain
all similar relations. A relation may have multi-
ple meanings (e.g., call on) so it can be clustered
to another cluster, or a relation might not be clus-
tered when its support set is too small (e.g., fly
to). For such relations, rather than assigning zero
similarity to visit-relations, we compute a cluster
membership function based on support pairs of the
cluster members and the target relation, and then
formulate a pairwise relation translation score.
Formally, we learn the membership function
of a relation r to a cluster c using support vec-
tor regression (Joachims, 1999) with the follow-
ing features based on the support set of cluster c,
H(c) = ?r?c H(r), and the support intersection
of r and c, H(r, c) = ?r??c H(r, r?).
? f1(r, c) = |H(r, c)|/|H(r)|: This quantifies the
degree of inclusion, H(c) ? H(r).
? f2(r, c) = |H(r, c)|/|H(c)|: This quantifies the
degree of inclusion, H(r) ? H(c).
? f3(r, c) = |Hwithin(r, c)|/|Hwithin(c)|: This is a
variation of f2 that considers only noun phrase
pairs shared at least once by relations in c.
? f4(r, c) = |Hwithin(r, c)|/|Hshared(c)|: This is a
variation of f2 that considers only noun phrase
pairs shared at least once by any pair of relations.
? f5(r, c) = |{r? ? c|H(r, r?) > 0}|/|c|: This
is the degree of connectivity to the cluster mem-
bers.
where Hwithin(r, c) = ?r??c H(r, c) ? H(r, r?),
the intersection, considering translation, of H(r)
and noun phrase pairs shared at once by rela-
tions in c, Hwithin(c) = ?r??c H(r?, c ? {r?}),
and Hshared(c) = ?r??RE?RC H(r?, c), the nounphrase pairs shared at once by any relations. The
use of Hwithin and Hshared is based on the obser-
vation that a noun phrase pair that appear in only
one relation tends to be an incorrectly chunked en-
tity such as ?World Trade? from the ?World Trade
Organization?.
Based on this membership function S(r, c), we
compute pairwise relation similarity. We consider
that two relations are similar if they have at least
one cluster that the both relations belong to, which
can be measured with S(r, c). More formally,
pairwise similarity of relations ri and rj is defined
as
TR(ri, rj) = maxc?C S(r
i, c) ? S(rj , c) (4)
where C is a set of all clusters.
4.4 Statement-level Document Context
Comparison
A brute-force statement matching approach often
fails due to ambiguity created by ignoring con-
text, and missing information in TN or TR. There-
fore, we detect similar document pairs to boost
the statement matching process. Unlike the pre-
vious approaches (e.g., bag-of-words), we focus
on the relationships of entities within documents
using the extracted statements.
Formally, we compute the similarity of two
statements sE = (xE , rE , yE) and sC =
(xC , rC , yC) in different languages as follows:
TS(sE , sC) = TN (xE , xC)TR(rE , rC)TN (yE , yC)
(5)
With this definition, we can find similar statements
described with different vocabularies in different
languages.
To compare a document pair, we use the fol-
lowing equation to measure the similarity of an
636
English document diE and a Chinese document djC
based on their statements SiE and SjC , respectively:
TD(diE , djC) =
?
(sE ,sC)?B TS(s
i,r
E , s
j,r
C )
|SiE |+ |SiE | ? |B|
(6)
whereB ? SiE?SjC is a greedy approximate solu-
tion of maximum bipartite matching (West, 1999)
on a bipartite graph GB = (VB = (SiE , SjC), EB)
with edge weights that are defined by TS . The
maximum bipartite matching finds a subset of
edges in SiE ? SjC that maximize the sum of the
selected edge weights and that do not share a node
as their anchor point.
4.5 Iteration on TN
In this section, we describe how we use the state-
ment similarity function TS , and the document
similarity function TD to improve and derive the
next generation entity translation function T (t+1)N .
We consider that a pair of an English entity eE and
a Chinese entity eC are likely to indicate the same
real world entity if they have 1) semantically sim-
ilar relations to the same entity 2) under the same
context. Formally, we define an increment func-
tion as follows.
?TN (eE , eC)=
?
diE
?
djC
TD(di, dj) max
(sE ,sC)?B?
TS(sE , sC)
(7)
whereB? is a subset ofB ? SiE?SjC such that the
connected statements mention eE and eC , andB is
the greedy approximate solution of maximum bi-
partite matching for the set SiE of statements of diE
and the set SjC of statements of djC . In other words,
B? is a set of matching statement pairs mention-
ing the translation target eE and eC in the docu-
ment pair. Then, we use the following equation to
improve the original entity translation function.
T (t+1)N (eE , eC) = (1? ?)
?TN (eE , eC)?
e?C
?TN (eE , e?C)
+ ?TN (eE , eC) (8)
where ? is a mixing parameter in [0, 1]. We set
? = 0.6 in our experiments.
With this update, we obtain the improved NE
translations considering the relations that an en-
tity has to other entities under the same context to
achieve higher precision.
5 Experiments
In this section, we present experimental settings
and results of translating entity names using our
methods compared with several baselines.
5.1 Data and Evaluation
We processed news articles for an entire year in
2008 by Xinhua news who publishes news in
both English and Chinese, which were also used
by Kim et al (2011) and Shao and Ng (2004). The
English corpus consists of 100,746 news articles,
and the Chinese corpus consists of 88,031 news
articles. The news corpora are not parallel but
comparable corpora, with asymmetry of entities
and relationship as the asymmetry in the number
of documents also suggest. Examples of such lo-
cality in Xinhua news include the more extensive
coverage of Chinese teams in the Olympics and
domestic sports in the Chinese news. Our frame-
work finds and leverages comparable parts from
the corpora without document-content-external in-
formation such as time stamps. We also show that,
under the decreasing comparability, our method
retains higher MRR than the baselines.
We follow the evaluation procedures used
by You et al (2012) and Kim et al (2011) to
fairly and precisely compare the effectiveness of
our methods with baselines. To measure perfor-
mance, we use mean reciprocal rank (MRR) to
evaluate a translation function T :
MRR(T ) = 1|Q|
?
(u,v)?Q
1
rankT (u, v)
(9)
where Q is the set of gold English-Chinese trans-
lation pairs (u, v) and rankT (u, v) is the rank of
T (u, v) in {T (u,w)|w is a Chinese entity}. In ad-
dition, we use precision, recall, and F1-score.
As gold translation pairs, we use the evaluation
data used by You et al (2012) with additional la-
bels, especially for organizations. The labeling
task is done by randomly selecting English enti-
ties and finding their Chinese translation from the
Chinese corpus. We only use entities with trans-
lations that appear in the Chinese corpus. We
present the evaluation results for persons and or-
ganizations to show the robustness of the meth-
ods. In total, we identified 490 English entities in
the English news with Chinese translations in the
Chinese news. Among the 490 entities, 221 NEs
are persons and 52 NEs are organizations.
637
Person Organization
MRR P. R. F1 MRR P. R. F1
T (2)N 0.80 0.81 0.79 0.80 0.53 0.56 0.52 0.54
T (1)N 0.77 0.80 0.77 0.78 0.44 0.49 0.44 0.46
TSPH+P 0.73 0.70 0.67 0.69 0.14 0.17 0.04 0.06
TMPH+P 0.68 0.70 0.68 0.69 0.08 0.31 0.08 0.12
THB 0.71 0.59 0.59 0.59 0.37 0.29 0.29 0.29
TDict 0.09 1.00 0.09 0.17 0.17 1.00 0.17 0.30
Table 3: Evaluation results of the methods.
5.2 Baselines
We compare our methods with the following base-
lines.
? TSPH+P (You et al, 2012) is a holistic method
that uses a transliteration method as base
translations, and then reinforces them to
achieve higher quality. This method uses
only a single type of entities to propagate the
translation scores.
? TMPH+P is the holistic method revised to use
naive multi-type propagation that uses multi-
ple types of entities to reinforce the transla-
tion scores.
? THB is a linear combination of transliteration
and semantic translation methods (Lam et al,
2007) tuned to achieve the highest MRR.
? TDict is a dictionary-only method. This dic-
tionary is used by both THB and TN .
Only the translation pairs of scores above 0.35
are used for TPH+P to maximize the F1-score to
measure precision, recall and F1-score. For our
method T (t)N , we use the result with (t) = 1,
the seed translations, and (t) = 2, which means
that only one pass of the whole framework is per-
formed to improve the seed translation function.
In addition, we use translation pairs with scores
above 0.05 to measure precision, recall, and F1-
score. Note that these thresholds do not affect
MRRs.
5.3 NE Translation Results
We show the result of the quantitative evaluation
in Table 3, where the highest values are boldfaced,
except TDict which shows 1.00 precision because
it is a manually created dictionary. For both the
person and organization cases, our method T (2)N
outperforms the state-of-the-art methods in terms
English
name
T (2)N T
(1)
N THB
Mandelson ????
[ManDeErSen]
????
[ManDeErSen]
????
[ManDeErSen]
WTO ????
[ShiMaoZuZhi]
????
[ShangHeZuZhi]
????
[BaJieZuZhi]
White House ??
[BaiGong]
??
[JiaZhou]
??
[JiaZhou]
Microsoft ????
[WeiRuanGongSi]
?????
[MeiGuoSiFaBu]
????
[MiLuoNuoFu]
Table 4: Example translations from the different
methods. Boldface indicates correct translations.
0.4
0.6
0.8
D0 D1 D2
t=2
t=1??? ??? 
Figure 6: MRR with decreasing comparability.
of precision, recall, F1-score and MRR. With only
one iteration of selective propagation, the seed
translation is improved to achieve the 0.09 higher
MRR.
The baselines show lower, but comparable
MRRs and F1-scores for persons that mostly con-
sist of transliterated cases. However, not all trans-
lations have phonetic similarity, especially orga-
nization names, as the low F1-score of TSPH+P ,
0.06, for organizations suggests. The naive multi-
type propagation TMPH+P shows decreased MRR
for both persons and organizations compared to
the single-type propagation TSPH+P , which shows
a negative influence of diverse relation semantics
of entities of different types. THB achieves a bet-
ter MRR than TPH+P due to the semantic transla-
tion of organization names. However, despite the
increased recall of THB over that of TDict, the pre-
cision of THB is unsatisfactory because THB maps
abbreviated names such as ?WTO? with other NEs.
On the other hand, our method achieves the high-
est MRR and precision in both the person and or-
ganization categories.
As shown in Table 4, THB translates ?WTO? in-
accurately, linking it to an incorrect organization
?????? (Palestine Liberation Organization).
638
The European Union (EU) Trade Commissioner (1) Peter Mandelson traveled to Moscow on 
Thursday for talks on ? Mandelson said it is a priority to see (2) Russia join the WTO, ? 
?????? (1) ??????14????????, ??????????????, 
(2) ?????????????????????, ? 
(Peter Mandelson, traveled to, Moscow) 
(??????, ????, ???) 
(Russia, join, WTO) 
(???, ??, ????) 
1) 2) 
Figure 5: Example of similar document pairs.
Moreover, the use of the corpora by T (1)N could
not fix this problem, and it finds another organi-
zation related to trade, ?????? (Shanghai Co-
operation Organization). In contrast, our selective
propagation method T (2)N , which uses the wrong
seed translation by T (1)N , ?????? (Shang-
hai Cooperation Organization), successfully trans-
lates the WTO using statements such as (Russia,
join, WTO), and its corresponding Chinese state-
ment (???, ??, ????). Similarly, both
the baseline THB and the seed translation T (1)N
matched Microsoft to incorrect Chinese entities
that are phonetically similar as indicated by the
underlined text. In contrast, T (2)N finds the correct
translation despite the phonetic dissimilarity.
5.4 NE Translation Results with Low Corpus
Comparability
We tested the methods using less comparable data
to evaluate the robustness with the following de-
rived datasets:
? D0:All news articles are used.
? D1: January-December English and July-
December Chinese articles are used.
? D2:April-September English and July-
December Chinese articles are used.
Figure 6 shows the MRR comparisons of our
method T (2)N and T (1)N on all test entities. Be-
cause the commonly appearing NEs are decreas-
ing, the performance decline is inevitable. How-
ever, we can see that the MRR of the seed trans-
lation method drops significantly on D1 and D2,
whereas our method shows 0.14 higher MRR for
both cases.
5.5 Similar Documents
In this section, we show an example of similar
documents in Figure 5. Both articles describe
the same event about the visit of Mandelson to
Moscow for the discussion on the joining of Rus-
sia to the WTO. The extracted statements are the
exact translations of each corresponding part as in-
dicated by the arrows. We stress this is an extreme
case for illustration, where the two sentences are
almost an exact translation, except for a minor
asymmetry involving the date (Thursday in En-
glish, and 14th in Chinese). In most similar doc-
uments, the asymmetry is more significant. The
seed translation score T 1N (WTO,????) is not
enough to match the entities. However, the context
similarity, due to other similar statements such as
(1), allows us to match (2). This match helps trans-
lation of ?WTO? by inspecting the organization
that Russia considers to join in both documents.
6 Conclusions
This paper proposed a bootstrapping approach
for entity translation using multilingual relational
clustering. Further, the proposed method could
finds similar document pairs by comparing state-
ments to enable us to focus on comparable parts of
evidence. We validated the quality of our approach
using real-life English and Chinese corpora, and
its performance significantly exceeds that of pre-
vious approaches.
Acknowledgment
This research was supported by the MKE (The
Ministry of Knowledge Economy), Korea and Mi-
crosoft Research, under IT/SW Creative research
program supervised by the NIPA (National IT In-
dustry Promotion Agency). (NIPA-2012-H0503-
12-1036).
639
References
Donghui Feng. 2004. A new approach for english-
chinese named entity alignment. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing EMNLP, pages 372?379.
Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu,
and Qingsheng Zhu. 2009. Mining bilingual data
from the web with adaptively learnt patterns. In
Joint Conference of the ACL and the IJCNLP, pages
870?878, Stroudsburg, PA, USA.
T. Joachims. 1999. Making large-scale SVM learning
practical. In B. Scho?lkopf, C. Burges, and A. Smola,
editors, Advances in Kernel Methods - Support Vec-
tor Learning. MIT Press, Cambridge, MA, USA.
Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, and
Gary Geunbae Lee. 2010. A cross-lingual anno-
tation projection approach for relation detection. In
COLING, pages 564?571, Stroudsburg, PA, USA.
Jinhan Kim, Long Jiang, Seung-won Hwang, Young-In
Song, and Ming Zhou. 2011. Mining entity trans-
lations from comparable corpora: a holistic graph
mapping approach. In CIKM, pages 1295?1304,
New York, NY, USA.
Jinhan Kim, Seung won Hwang, Long Jiang, Young-
In Song, and Ming Zhou. 2012. Entity transla-
tion mining from comparable corpora: Combining
graph mapping with corpus latent features. IEEE
Transactions on Knowledge and Data Engineering,
99(PrePrints).
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ?03, pages 423?
430, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proceedings of the
main conference on Human Language Technol-
ogy Conference of the North American Chapter of
the Association of Computational Linguistics, HLT-
NAACL ?06, pages 82?88, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Comput. Linguist., 24(4):599?612,
December.
Julian Kupiec. 1993. An algorithm for finding noun
phrase correspondences in bilingual corpora. In
ACL, pages 17?22, Stroudsburg, PA, USA.
Wai Lam, Shing-Kit Chan, and Ruizhang Huang.
2007. Named entity translation matching and learn-
ing: With application for mining unseen transla-
tions. ACM Trans. Inf. Syst., 25(1), February.
Dekang Lin, Shaojun Zhao, Benjamin Van Durme, and
Marius Pasca. 2008. Mining parenthetical transla-
tions from the web by word alignment. In ACL.
Thahir Mohamed, Estevam Hruschka, and Tom
Mitchell. 2011. Discovering relations between
noun categories. In EMNLP, pages 1447?1455, Ed-
inburgh, Scotland, UK., July.
Ndapandula Nakashole, Gerhard Weikum, and
Fabian M. Suchanek. 2012. PATTY: A Taxonomy
of Relational Patterns with Semantic Types. In
EMNLP.
Patrick Schone, Tim Allison, Chris Giannella, and
Craig Pfeifer. 2011. Bootstrapping multilin-
gual relation discovery using english wikipedia and
wikimedia-induced entity extraction. In ICTAI,
pages 944?951, Washington, DC, USA.
Li Shao and Hwee Tou Ng. 2004. Mining new word
translations from comparable corpora. In COLING,
Stroudsburg, PA, USA.
S. Van Dongen. 2000. Graph Clustering by Flow Sim-
ulation. Ph.D. thesis, University of Utrecht, The
Netherlands.
Stephen Wan and Cornelia Maria Verspoor. 1998. Au-
tomatic english-chinese name transliteration for de-
velopment of multilingual resources. In ACL, pages
1352?1356, Stroudsburg, PA, USA.
Douglas Brent West. 1999. Introduction to graph the-
ory (2nd edition). Prentice Hall.
Fan Yang, Jun Zhao, and Kang Liu. 2009. A chinese-
english organization name translation system using
heuristic web mining and asymmetric alignment. In
Joint Conference of the ACL and the IJCNLP, pages
387?395, Stroudsburg, PA, USA.
Gae-won You, Seung-won Hwang, Young-In Song,
Long Jiang, and Zaiqing Nie. 2010. Mining name
translations from entity graph mapping. In EMNLP,
pages 430?439, Stroudsburg, PA, USA.
Gae-Won You, Seung-Won Hwang, Young-In Song,
Long Jiang, and Zaiqing Nie. 2012. Efficient entity
translation mining: A parallelized graph alignment
approach. ACM Trans. Inf. Syst., 30(4):25:1?25:23,
November.
640
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 201?205,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Enriching Entity Translation Discovery using Selective Temporality
Gae-won You, Young-rok Cha, Jinhan Kim, and Seung-won Hwang
Pohang University of Science and Technology, Republic of Korea
{gwyou, line0930, wlsgks08, swhwang}@postech.edu
Abstract
This paper studies named entity trans-
lation and proposes ?selective temporal-
ity? as a new feature, as using temporal
features may be harmful for translating
?atemporal? entities. Our key contribution
is building an automatic classifier to dis-
tinguish temporal and atemporal entities
then align them in separate procedures to
boost translation accuracy by 6.1%.
1 Introduction
Named entity translation discovery aims at map-
ping entity names for people, locations, etc. in
source language into their corresponding names in
target language. As many new named entities ap-
pear every day in newspapers and web sites, their
translations are non-trivial yet essential.
Early efforts of named entity translation have
focused on using phonetic feature (called PH)
to estimate a phonetic similarity between two
names (Knight and Graehl, 1998; Li et al, 2004;
Virga and Khudanpur, 2003). In contrast, some
approaches have focused on using context feature
(called CX) which compares surrounding words
of entities (Fung and Yee, 1998; Diab and Finch,
2000; Laroche and Langlais, 2010).
Recently, holistic approaches combining such
similarities have been studied (Shao and Ng, 2004;
You et al, 2010; Kim et al, 2011). (Shao and
Ng, 2004) rank translation candidates using PH
and CX independently and return results with the
highest average rank. (You et al, 2010) compute
initial translation scores using PH and iteratively
update the scores using relationship feature (called
R). (Kim et al, 2011) boost You?s approach by ad-
ditionally leveraging CX.
More recent approaches consider temporal fea-
ture (called T) of entities in two corpora (Klemen-
tiev and Roth, 2006; Tao et al, 2006; Sproat et
0 5 10 15 20 25 30 35 40 45 500
50
100
150
200
250
300
Week
Freq
uen
cy
 
 EnglishChinese
(a) Temporal entity: ?Usain Bolt?
0 5 10 15 20 25 30 35 40 45 500
20
40
60
80
Week
Freq
uen
cy
 
 EnglishChinese
(b) Atemporal entity: ?Hillary Clinton?
Figure 1: Illustration on temporality
al., 2006; Kim et al, 2012). T is computed us-
ing frequency vectors for entities and combined
with PH (Klementiev and Roth, 2006; Tao et al,
2006). (Sproat et al, 2006) extend Tao?s approach
by iteratively updating overall similarities usingR.
(Kim et al, 2012) holistically combine all the fea-
tures: PH, CX, T, and R.
However, T used in previous approaches is a
good feature only if temporal behaviors are ?sym-
metric? across corpora. In contrast, Figure 1 il-
lustrates asymmetry, by showing the frequencies
of ?Usain Bolt,? a Jamaican sprinter, and ?Hillary
Clinton,? an American politician, in comparable
news articles during the year 2008. The former is
mostly mentioned in the context of some temporal
events, e.g., Beijing Olympics, while the latter is
not. In such case, as Hillary Clinton is a famous fe-
male leader, she may be associated with other Chi-
nese female leaders in Chinese corpus, while such
association is rarely observed in English corpus,
which causes asymmetry. That is, Hillary Clin-
ton is ?atemporal,? as Figure 1(b) shows, such that
using such dissimilarity against deciding this pair
as a correct translation would be harmful. In clear
contrast, for Usain Bolt, similarity of temporal dis-
201
tributions in Figure 1(a) is a good feature for con-
cluding this pair as a correct one.
To overcome such problems, we propose a new
notion of ?selective temporality? (called this fea-
ture ST to distinguish from T) to automatically
distinguish temporal and atemporal entities. To-
ward this goal, we design a classifier to distinguish
temporal entities from atemporal entities, based
on which we align temporal projections of entity
graphs for the temporal ones and the entire entity
graphs for the atemporal ones. We also propose
a method to identify the optimal window size for
temporal entities. We validate this ?selective? use
of temporal features boosts the accuracy by 6.1%.
2 Preliminaries
Our approach follows a graph alignment frame-
work proposed in (You et al, 2010). Our graph
alignment framework consists of 4 steps.
2.1 Step 1: Graph Construction
We first build a graph G = (V,E) from each lan-
guage corpus, where V is a set of entities (nodes)
and E is a set of co-occurrence relationships (un-
weighted edges) between entities. We consider en-
tities occurring more than ? times as nodes and en-
tity pairs co-occurring more than ? times as edges.
To identify entities, we use a CRF-based named
entity tagger (Finkel et al, 2005) and a Chinese
word breaker (Gao et al, 2003) for English and
Chinese corpora, respectively.
2.2 Step 2: Initialization
Given two graphs Ge = (Ve, Ee) and Gc =
(Vc, Ec), we initialize |Ve|-by-|Vc| initial similar-
ity matrix R0 using PH and CX for every pair
(e, c) where e ? Ve and c ? Vc.
For PH, we use a variant of Edit-Distance (You
et al, 2010) between English entity and a ro-
manized representation of Chinese entity called
Pinyin. ForCX, the context similarity is computed
based on entity context which is defined as a set of
words near to the entity (we ignore some words
such as stop words and other entities). We com-
pute similarity of the most frequent 20 words for
each entity using a variant of Jaccard index. To in-
tegrate two similarity scores, we adopt an average
as a composite function.
We finally compute initial similarity scores for
all pairs (e, c) where e ? Ve and c ? Vc, and build
the initial similarity matrix R0.
2.3 Step 3: Reinforcement
We reinforceR0 by leveragingR and obtain a con-
verged matrix R? using the following model:
Rt+1(i,j) = ?R
0
(i,j) + (1? ?)
?
(u,v)k?Bt(i,j,?)
Rt(u,v)
2k
This model is a linear combination of (a) the initial
similarity R0(i,j) of entity pair (i, j) ? Ve ? Vc and
(b) the similarities Rt(u,v) of their matched neigh-
bors (u, v) ? Ve ? Vc where t indicates iteration,
Bt(i, j, ?) is an ordered set of the matched neigh-
bors, and k is the rank of the matched neighbors.
? is the coefficient for balancing two terms.
However, as we cannot assure the correctly
matched neighbors (u, v), a chicken-and-egg
dilemma, we take advantage of the current simi-
larity Rt to estimate the next similarity Rt+1. Al-
gorithm 1 describes the process of matching the
neighbors where N(i) and N(j) are the sets of
neighbor nodes of i ? Ve and j ? Vc, respectively,
andH is a priority queue sorting the matched pairs
in non-increasing order of similarities. To guaran-
tee that the neighbors are correctly matched, we
use only the matches such that Rt(u,v) ? ?.
Algorithm 1 Bt(i, j, ?)
1: M ? {}; H ? {}
2: ?u ? N(i), ?v ? N(j) H.push(u, v) such that
Rt(u,v) ? ?3: while H is not empty do
4: (u, v)? H.pop()
5: if neither u nor v are matched yet then
6: M ?M ? {(u, v)}
7: end if
8: end while
9: return M
2.4 Step 4: Extraction
From R?, we finally extract one-to-one matches
by using simple greedy approach of three steps:
(1) choosing the pair with the highest similarity
score; (2) removing the corresponding row and
column from R?; (3) repeating (1) and (2) until
the matching score is not less than a threshold ?.
3 Entity Translation Discovery using
Selective Temporality
Overall Framework: We propose our framework
by putting together two separate procedures for
temporal and atemporal entities to compute the
overall similarity matrix R
202
We first build two temporal graphs from the cor-
pora within every time window, optimized in Sec-
tion 3.1. We then compute the reinforced matrix
R?s obtained from the window starting at the time-
stamp s. To keep the best match scores among
all windows, we update R using the best similar-
ity among ?s,R?s . we then extract the candidate
translation pairs Mours by running step 4.
As there can exist atemporal entities in Mours,
we classify them (Section 3.2). Specifically, we
build two entire graphs and computeR?. We then
distinguish temporal entities from atemporal ones
using our proposed metric for each matched pair
(i, j) ? Mours and, if the pair is atemporal, R(i,j)
is updated as the atemporal similarity R?(i,j).From the final matrixR, we extract the matched
pairs by running step 4 with R once again.
3.1 Projecting Graph for Temporal Entities
We first project graphs temporally to improve
translation quality for temporal entities. As the
optimal projection would differ across entities, we
generate many projected graphs by shifting time
window over all periods, and then identify the best
window for each entity.
The rest of this section describes how we set
the right window size w. Though each entity may
have its own optimal w, we find optimizing for
each entity may negatively influence on consider-
ing relationships with entities of different window
sizes. Thus, we instead find the optimal window
size w? to maximize the global ?symmetry? of the
given two graphs.
We now define ?symmetry? with respect to the
truth translation pair M . We note it is infeasi-
ble to assume we have M during translation, and
will later relax to consider how M can be approx-
imated.
Given a set of graph pairs segmented by the
shifted windows
{(G(0,w)e , G(0,w)c ), ? ? ? , (G(s,s+w)e , G(s,s+w)c ),
(G(s+?s,s+?s+w)e , G(s+?s,s+?s+w)c ), ? ? ? },
where s is the time-stamp, our goal is to find the
window size w? maximizing the average symmetry
S of graph pairs:
w? = arg max
?w
(?
s S(G
(s,s+w)
e , G(s,s+w)c ;M)
N
)
Given M , symmetry S can be defined for (1)
node and (2) edge respectively. We first define the
node symmetry Sn as follows:
Sn(Ge, Gc;M) =
?
(e,c)?Ve?Vc I(e, c;M)
max{|Ve|, |Vc|}
where I(u, v;M) to be 1 if (u, v) ? M , 0 other-
wise. High node symmetry leads to accurate trans-
lation in R0 (Initialization step). Similarly, we de-
fine the edge symmetry Se as follows:
Se(Ge, Gc;M) =?
(e1,e2)?Ee
?
(c1,c2)?Ec I(e1, c1;M)I(e2, c2;M)
max{|Ee|, |Ec|}
In contrast, high edge symmetry leads to accurate
translation in R? (Reinforcement step).
We finally define the symmetry S as the
weighted sum of Sn and Se with parameter ? (em-
pirically tuned to 0.8 in our experiment).
S(Ge, Gc;M) =
?Sn(Ge, Gc;M) + (1? ?)Se(Ge, Gc;M)
However, as it is infeasible to assume we have
the truth translation pair M , we approximate M
using intermediate translation results Mours com-
puted at step 4. To insert only true positive pairs in
Mours, we set threshold higher than the optimized
value from the step 4. We found out that symmetry
from Mours closely estimates that from M :
S(Ge, Gc;M) ? S(Ge, Gc;Mours)
Specifically, observe from Table 1 that, given a
manually built ground-truth set Mg ? M as de-
scribed in Section 4.1, S(Ge, Gc;Mours) returns
the best symmetry value in two weeks for person
entities, which is expectedly the same as the result
of S(Ge, Gc;Mg). This suggests that we can use
Mours for optimizing window size.
Weeks 26 13 4 2 1
Mg .0264 .0276 .0303 .0318 .0315
Mours .0077 .0084 .0102 .0113 .0107
Table 1: Symmetry of window size
3.2 Building Classifier
We then classify temporal/atemporal entities. As
a first step, we observe their characteristics: Tem-
poral entities have peaks in the frequency distri-
bution of both corpora and these peaks are aligned,
while such distribution of atemporal entities are
more uniform and less aligned.
203
Based on these observations, we identify the
following criteria for temporal entities: (1) Their
two distributions m in English corpus and n in
Chinese corpus should have aligned peaks. (2)
Frequencies at the peaks are the higher the better.
For the first criterion, we first normalize the two
vectors m? and n? since two corpora have different
scales, i.e., different number of documents. We
then calculate the inner product of the two vectors
x = ?m?, n??, such that this aggregated distribution
x peaks, only if both m? and n? peak at the same
time.
For the second criterion, we have a spectrum
of option from taking the frequencies at all peaks
in one extreme, to taking only the maximum fre-
quency in another extreme. A metric representing
such a spectrum is p-norm, which represents sum
when p = 1 and maximum when p = ?. We em-
pirically tune the right balance to distinguish tem-
poral and atemporal entities, which turns out to be
p = 2.2.
Overall, we define a metric d(m,n) which sat-
isfies both criteria as follow:
d(m,n) =
( n?
i=1
(m?in?i)p
) 1
p
For instance, this measure returns 0.50 and 0.03
for the distributions in Figure 1(a) and (b), respec-
tively, from which we can determine the transla-
tion of Figure 1(a) is temporal and the one of Fig-
ure 1(b) is atemporal.
4 Experimental Evaluation
4.1 Experimental Settings
We obtained comparable corpora from English
and Chinese Gigaword Corpora (LDC2009T13
and LDC2009T27) published by the Xinhua News
Agency during the year 2008. From them, we ex-
tracted person entities and built two graphs, Ge =
(Ve, Ee) and Gc = (Vc, Ec) by setting ? = 20
which was used in (Kim et al, 2011).
Next, we built a ground truth translation pair
set Mg for person entities. We first selected 500
person names randomly from English corpus. We
then hired a Chinese annotator to translate them
into their Chinese names. Among them, only 201
person names were matched to our Chinese cor-
pus. We used all such pairs to identify the best
parameters and compute the evaluation measures.
We implemented and compared the following
approaches denoted as the naming convention of
listing of the used features in a parenthesis ():
? (PH+R) in (You et al, 2010).
? (PH+CX+R) in (Kim et al, 2011).
? (PH+CX+R+T) in (Kim et al, 2012).
? (PH+CX+R+ST): This is our approach.
We evaluated the effectiveness of our new ap-
proach using four measures: MRR, precision, re-
call, and F1-score, where MRR (Voorhees, 2001)
is the average of the reciprocal ranks of the query
results defined as follows:
MRR = 1|Q|
?
(u,v)?Q
1
rank(u,v)
,
where Q is a set of ground-truth matched pairs
(u, v) such that u ? Ve and v ? Vc, and rank(u,v)
is the rank of R(u,v) among all R(u,w)?s such that
w ? Vc. We performed a 5-fold cross validation
by dividing ground truth into five groups. We used
four groups to training the parameters to maximize
F1-scores, used the remaining group as a test-set
using trained parameters, and computed average
of five results. (bold numbers indicate the best
performance for each metric.)
4.2 Experimental Results
Effect of window size
We first validated the effectiveness of our ap-
proach for various window sizes (Table 2). Ob-
serve that it shows the best performance in two
weeks for MRR and F1 measures. Interestingly,
this result also corresponds to our optimization re-
sult w? of Table 1 in Section 3.1.
Weeks 26 13 4 2 1
MRR .7436 .8066 .8166 .8233 .8148
Precision .7778 .7486 .8126 .8306 .8333
Recall .6617 .6875 .7320 .7295 .7214
F1 .7151 .7165 .7701 .7765 .7733
Table 2: Optimality of window size
Overall performance
Table 3 shows the results of four measures. Ob-
serve that (PH+CX+R+T) and (PH+CX+R+ST)
outperform the others in all our settings. We
can also observe the effect of selective temporal-
ity, which maximizes the symmetry between two
graphs as shown in Table 1, i.e., (PH+CX+R+ST)
204
Method MRR Precision Recall F1
(PH+R) .6500 .7230 .4548 .5552
(PH+CX+R) .7499 .7704 .6623 .7120
(PH+CX+R+T) .7658 .8223 .6608 .7321
(PH+CX+R+ST) .8233 .8306 .7295 .7765
Table 3: MRR, Precision, Recall, and F1-score


(QJOLVK1DPH 7/&;5 7/&;57 7/&;567
+X-LQWDR ??? ??? ???
.LP<RQJ1DP ??? ??? ???
.DU]DL ?? ?? ????
Figure 2: The translation examples where shaded
cells indicate the correctly translated pairs.
outperforms (PH+CX+R+T) by 6.1%. These im-
provements were statistically significant according
to the Student?s t-test at P < 0.05 level.
Figure 2 shows representative translation exam-
ples. All approaches found famous entities such
as ?Hu Jintao,? a former leader of China, but
(PH+CX+R) failed to find translation of lesser
known entities, such as ?Kim Yong Nam.? Using
temporal features help both (PH+CX+R+T) and
(PH+CX+R+ST) identify the right translation, as
Kim?s temporal occurrence is strong and symmet-
ric in both corpora. In contrast, (PH+CX+R+T)
failed to find the translation of ?Karzai?, the presi-
dent of Afghanistan, as it only appears weakly and
transiently during a short period time, for which
only (PH+CX+R+ST) applying varying sizes of
window per entity is effective.
5 Conclusion
This paper validated that considering temporal-
ity selectively is helpful for improving the trans-
lation quality. We developed a classifier to dis-
tinguish temporal/atemporal entities and our pro-
posed method outperforms the state-of-the-art ap-
proach by 6.1%.
Acknowledgment
This research was supported by the MKE (The
Ministry of Knowledge Economy), Korea and Mi-
crosoft Research, under IT/SW Creative research
program supervised by the NIPA (National IT In-
dustry Promotion Agency). (NIPA-2012- H0503-
12-1036).
References
Mona Diab and Steve Finch. 2000. A statistical word level
translation model for comparable corpora. In RIAO ?00.
Jenny Rose Finkel, Trond Grenager, and Christopher Man-
ning. 2005. Incorporating Non-local Information into
Information Extraction Systems by Gibbs Sampling. In
ACL.
Pascale Fung and Lo Yuen Yee. 1998. An IR Approach
for Translating New Words from Nonparallel,Comparable
Texts. In COLING.
Jianfeng Gao, Mu Li, and Chang-Ning Huang. 2003. Im-
proved Source-channel Models for Chinese Word Seg-
mentation. In ACL.
Jinhan Kim, Long Jiang, Seung-won Hwang, Young-In Song,
and Ming Zhou. 2011. Mining Entity Translations from
Comparable Corpora: A Holistic Graph Mapping Ap-
proach. In CIKM.
Jinhan Kim, Seung won Hwang, Long Jiang, Young-In Song,
and Ming Zhou. 2012. Entity Translation Mining from
Comparable Corpora: Combining Graph Mapping with
Corpus Latent Features. IEEE TKDE.
Alexandre Klementiev and Dan Roth. 2006. Named entity
transliteration and discovery from multilingual compara-
ble corpora. In HLT-NAACL ?06.
Kevin Knight and Jonathan Graehl. 1998. Machine Translit-
eration. Computational Linguistics.
Audrey Laroche and Philippe Langlais. 2010. Revisit-
ing context-based projection methods for term-translation
spotting in comparable corpora. In COLING.
Haizhou Li, Zhang Min, and Su Jian. 2004. A Joint Source-
Channel Model for Machine Transliteration. In ACL.
Li Shao and Hwee Tou Ng. 2004. Mining New Word Trans-
lations from Comparable Corpora. In COLING.
Richard Sproat, Tao Tao, and ChengXiang Zhai. 2006.
Named Entity Transliteration with Comparable Corpora.
In ACL.
Tao Tao, Su-Youn Yoon, Andrew Fister, Richard Sproat, and
ChengXiang Zhai. 2006. Unsupervised Named Entity
Transliteration Using Temporal and Phonetic Correlation.
In EMNLP.
Paola Virga and Sanjeev Khudanpur. 2003. Transliteration
of proper names in cross-language applications. In SIGIR
?03.
Ellen M. Voorhees. 2001. The TREC Question Answering
Track. Natural Language Engineering, 7(4):361?378.
Gae-won You, Seung-won Hwang, Young-In Song, Long
Jiang, and Zaiqing Nie. 2010. Mining Name Translations
from Entity Graph Mapping. In Proceedings of EMNLP,
pages 430?439.
205
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 848?853,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
Understanding Relation Temporality of Entities
Taesung Lee and Seung-won Hwang
Department of Computer Science and Engineering
Pohang University of Science and Technology (POSTECH)
Pohang, Republic of Korea
{elca4u, swhwang}@postech.edu
Abstract
This paper demonstrates the importance
of relation equivalence for entity trans-
lation pair discovery. Existing approach
of understanding relation equivalence has
focused on using explicit features of co-
occurring entities. In this paper, we ex-
plore latent features of temporality for un-
derstanding relation equivalence, and em-
pirically show that the explicit and latent
features complement each other. Our pro-
posed hybrid approach of using both ex-
plicit and latent features improves relation
translation by 0.16 F1-score, and in turn
improves entity translation by 0.02.
1 Introduction
Understanding relations is important in entity
tasks. In this paper, we illustrate such importance
using named entity (NE) translation mining prob-
lem. Early research on NE translation used pho-
netic similarities, for example, to mine the trans-
lation ?Mandelson????????[ManDeErSen]
with similar sounds (Knight and Graehl, 1998;
Wan and Verspoor, 1998). However, not all NE
translations are based on transliterations, but they
might be based on semantics (e.g., ?WTO????
????[ShiMaoZuZhi]), or even arbitrary (e.g.,
?Jackie Chan??????[ChengLong]).
To address this challenge, current state-of-the-
art approaches build an entity graph for each lan-
guage corpus, and align the two graphs by prop-
agating the seed translation similarities (Figure 1)
(Kim et al, 2011; You et al, 2012). For exam-
ple, arbitrary translation pair such as (Jackie Chan,
??) can be obtained, if he is connected to his
film ?DrunkenMaster? (??) in both graphs. That
is, we can propagate the seed translation similar-
ity of (Drunken Master,??) to neighbor entities
?Jackie Chan? and ???? in each graph.
??  (Drunken Master) ?? (Kung Fu) 
?? (Hong Kong) 
?? (Jackie Chan) 
Drunken Master 
Kung Fu 
Hong Kong 
Jackie Chan 
English Entity Graph Chinese Entity Graph 
Known translations Propagated translations 
Figure 1: Entity translation by propagation.
When two graphs are obtained from parallel
corpora, graphs are symmetric and ?blind prop-
agation? described above is effective. In con-
trast, Lee and Hwang (2013) propose ?selective
propagation? for asymmetric graphs, of compar-
ing the semantics of relations. A key contri-
bution of this paper is using relation temporal-
ity for determining relation equivalence. Exist-
ing work (Nakashole et al, 2012; Mohamed et
al., 2011; Lee and Hwang, 2013) uses only co-
occurring entity pairs, or explicit features (EF).
For example, for a relation pay an official visit to,
with a statement (Bush, pay an official visit to, China),
an entity pair (Bush, China) is in the ?support
set?, which is a set of co-occurring entity pairs
of pay an official visit to. When its support set is
{(Bush, China), (Mandelson, Moscow), (Rice, Is-
rael)}, and that of visit is {(Bush, China), (Rice,
Israel), (Medvedev, Cuba)}, we can infer their se-
mantic equivalence based on the set intersection:
{(Bush, China), (Rice, Israel)}.
In contrast, we propose to explore corpus latent
features (LF), to complement the sparsity problem
of EF: Out of 158 randomly chosen correct re-
lation translation pairs we labeled, 64% has only
one co-occurring entity pair, which makes EF not
very effective to identify these relation transla-
tions. Therefore, we leverage relation temporality,
which is both orthogonal and complementary to
existing efforts leveraging entity temporality (Kle-
848
mentiev and Roth, 2006; Kim et al, 2012; You
et al, 2013). In particular, we discover three new
challenges on using temporality for relation under-
standing in comparable corpora, which we discuss
in detail in Section 3.2. Based on these challenges,
we identify three new features for LF.
We observe the complementary nature of EF
and LF, then propose a hybrid approach combin-
ing both features. Our new hybrid approach sig-
nificantly improves the relation translation (0.16
higher F1-score than EF), and in turn improves the
entity translation (0.02 higher F1-score).
2 Preliminary: Entity Translation by
Selective Propagation
Selective propagation, leveraging the statements
extracted from bilingual comparable corpora, can
be summarized by several steps.
STEP 1 Initialize entity translation function T
(0)
N
.
STEP 2 Build relation translation function T
(t)
R
us-
ing T
(t)
N
.
STEP 3 Update entity translation function to ac-
quire T
(t+1)
N
using T
(t)
R
.
STEP 4 Repeat STEP 2 and STEP 3.
For STEP 1, an existing method for entity trans-
lation is adopted. In our experiments, we use a
non-selective (hence not requiring relation trans-
lations) propagation approach (You et al, 2012)
with (Lam et al, 2007) for a base translation ma-
trix. The focus of this paper is STEP 2, building the
translation score T
(t)
R
(r
E
, r
C
) of English relation
r
E
and Chinese relation r
C
: We will discuss the
detailed procedure of STEP 2 and propose how to
improve it in Section 3. STEP 3 is the stage that
selective propagation takes place.
STEP 2 and STEP 3 reinforce each other to im-
prove the final entity translation function. While
STEP 3 is well-defined in (Lee and Hwang, 2013),
to propagate entity translation scores when the re-
lation semantics of the edges are equivalent, STEP
2 has been restricted to the explicit feature, i.e., co-
occurring entities or shared context. In clear con-
trast, by discovering novel latent features based on
temporal properties, we can increase the accuracy
of both entity and relation translations. Note that
we omit t for readability in the following sections.
3 Relation Translation
In this section, we present our approaches to ob-
tain relations of equivalent semantics across lan-
guages (e.g., visit???). Formally, our goal
is to build the relation translation score function
T
R
(r
E
, r
C
) for English relation r
E
and Chinese
relation r
C
.
3.1 Baseline: Explicit Feature Approach (EF)
In this section, we briefly illustrate a baseline
method EF (Lee and Hwang, 2013). As we
mentioned in the introduction, traditional ap-
proaches leverage common co-occurring entity-
pairs. This observation also holds in the bilin-
gual environment by exploiting seed entity trans-
lations. For example, let us say that we have
two extracted statements: (Bruce Willis, star in,
The Sixth Sense) and (??????? (Bruce
Willis),?? (star in),??? (The Sixth Sense)).
Knowing a few seed entity translations using T
N
,
?Bruce Willis??????????? and ?The Sixth
Sense???????, we can find star in and??
are semantically similar.
Specifically, we quantify this similarity based
on the number of such common entity pairs that
we denote as |H(r
E
, r
C
)| for an English relation
r
E
and a Chinese relation r
C
. The existing ap-
proaches are variations of using |H(r
E
, r
C
)|. Our
baseline implementation uses the one by (Lee and
Hwang, 2013), and we refer the reader to the pa-
per for formal definitions and processing steps we
omitted due to the page limit.
Unfortunately, this approach suffers from spar-
sity of the common entity pairs due to the incom-
parability of the corpora and those entities that
cannot be translated by T
N
. Therefore, we lever-
age corpus latent features as an additional signal
to overcome this problem.
3.2 Latent Feature Approach (LF)
Temporal Feature Discovery
We exploit the temporal distribution d[x](t) of tex-
tual element x during t-th week in statements;
we count the occurrences of the element x on
a weekly basis, and normalize them to observe
?
t
d[x](t) = 1. For example, Figure 2a shows the
relation temporal distribution d[visit](t) against
week t. Unlike entities, we can easily observe
the dissimilarity of the temporal distributions of
semantically equivalent relations. We identify the
849
00.04
0.08
0 10 20 30 40 50
Week 
visit?? 
(a) Atemporality of equivalent relations: d[visit] and
d[??].
0
0.12
0.24
0 10 20 30 40 50
Week 
(Bush, visit, *)
(??, ??, *) 
(b) Temporality of equivalent entity-relation couplings:
d[Bush, visit, *] and d[??,??, *].
0
0.07
0.14
0 10 20 30 40 50
Week 
deploy?...?? 
(c) Temporality of non-equivalent relations: d[deploy]
and d[?...?? (deploy at)]
Figure 2: Temporal distributions of a relation, and
a coupling.
three big challenges in exploiting the temporality
in relation translations.
[C1] Considering temporal distributions d[r] of
relations alone is not sufficient. For relations, such
as visit, that involves diverse entities, the temporal
distributions are highly noisy (Figure 2a).
To address the first challenge, we use a finer-
granularity unit for observing the temporality.
More specifically, we exploit a coupling of a re-
lation and an entity: d[e, r, ?] where e is an en-
tity, r a relation, and * is a placeholder indicating
that any noun phrase is accepted for the second ar-
gument of a statement.
1
As shown in Figure 2b,
d[e, r, ?] is more distinctive and hence a key clue
to find semantically equivalent relations.
[C2] Considering entity-relation coupling dis-
tribution d[e, r, ?] alone is not sufficient due to
the domination of individual temporality. For ex-
ample, Figure 3 shows entity-dominating entity-
relation temporality. If an entity has a peak at
some period (Figure 3a), most relations that are
coupled with the entity would have a peak at the
very same period (Figure 3b). This makes all re-
lations that appear with this entity very similar to
1
We use both d[e, r, ?] and d[?, r, e] to measure the rela-
tion translation scores and leverage the average score. But in
this section, we only use d[e, r, ?] for readability.
0
0.32
0.64
0 10 20 30 40 50Week 
(a) Temporal distribution of
an entity having a peak.
0
0.32
0.64
0 10 20 30 40 50Week 
(b) Temporal distribution of
a coupling of a relation and
the entity.
Figure 3: False positive peak of an entity-relation
coupling.
each other regardlessly of semantics. To address
this challenge, we use features to measure whether
d[e, r, ?] is too close to either of d[e] or d[r].
[C3] Lastly, we have to eliminate false positives
in relation temporality. To illustrate, two relations
deploy and ?...?? (deploy at) have similar
temporal behaviors (Figure 2c). However, the first
relation takes [person], but the second relation [lo-
cation] for the second argument.
To address this, we check the common co-
occurring entity pair of the relations. For exam-
ple, we can obtain ?Russia deployed an aircraft
carrier?, but not ?Russia deployed at (?...??)
an aircraft carrier?. Thus, we cannot acquire any
common entity pair like (Russia, aircraft carrier)
for deploy and?...?? (deploy at).
Relation Similarity Computation
We compute the similarity of two relations r
E
in
English and r
C
in Chinese using the following 2-
steps.
? Compute the similarity S
CP
(r
E
, r
C
, e
E
, e
C
) of
temporal distributions of entity-relation cou-
plings for each bilingual entity pair (e
E
, e
C
).
? Compute the translation score T
LF
R
(r
E
, r
C
) by
aggregating the coupling similarities.
Considering the three challenges, we produce
a list of features {f
x
(r
E
, r
C
, e
E
, e
C
)} to mea-
sure the coupling similarity S
CP
(r
E
, r
C
, e
E
, e
C
)
as follows.
? [Base feature] f
ET
: T
N
(e
E
, e
C
). The entity
translation score obtained in the previous iter-
ation or the seed entity translation score.
? [C1] f
ER
: 1?JSD(d[e
E
, r
E
, ?], d[e
C
, r
C
, ?]).
The temporal similarity of the couplings, where
JSD(P,Q) is the Jensen-Shannon divergence
of two distributions P and Q, defined as
JSD(P,Q) =
1
2
D(P ||M) +
1
2
D(Q||M),
850
with M =
1
2
(P + Q) and D(P ||M) =
?
i
P (i) log
P (i)
M(i)
.
? [C2] f
D1,E
, f
D2,E
, f
D1,C
, f
D2,C
:
JSD(d[e
E
], d[e
E
, r
E
, ?]), JSD(d[r
E
], d[e
E
, r
E
, ?])
JSD(d[e
C
], d[e
C
, r
C
, ?]), JSD(d[r
C
], d[e
C
, r
C
, ?])
Entity to entity-relation distribution difference
(D1) and relation to entity-relation distribution
difference (D2), for English and Chinese re-
spectively.
? [C3] f
EX
: The existence of a common entity
pair using the seed entity translations (boolean).
That is, f
EX
= 1 if |H(r
E
, r
C
)| ? 1, and
f
EX
= 0 otherwise.
Additionally, we use the following features to
consider absolute frequencies freq(?) of textual
elements as well because 1) we are more confi-
dent with more evidence and 2) in the comparable
corpora, the equivalent elements are likely to show
similar frequencies.
? f
FW,E
, f
FW,C
: S(freq(e
E
, r
E
)) and
S(freq(e
C
, r
C
)). S(x) is a normalization
function, for which we use a sigmoid function
over a linear transformation of x.
? f
FS1
and f
FS2
:
min(freq(e
E
, r
E
), freq(e
C
, r
C
))
max(freq(e
E
, r
E
), freq(e
C
, r
C
))
,
min(freq(r
E
), freq(r
C
))
max(freq(r
E
), freq(r
C
))
With these features, we measure the similarity
of a pair of couplings as follows.
S
CP
(r
E
, r
C
, e
E
, e
C
) =
?
x
f
x
(r
E
, r
C
, e
E
, e
C
)
(1)
By aggregating coupling similarities, we mea-
sure the translation score of two relations:
T
LF
R
(r
E
, r
C
) =
?
(e
E
,e
C
)?T
S
CP
(r
E
, r
C
, e
E
, e
C
)
(2)
where T = {(e
E
, e
C
)|T
N
(e
E
, e
C
) ? ?} with ? =
0.6, a set of translation pairs obtained in the seeds
or previous iteration such as (Bush,??).
We normalize the obtained function values for
each English relations using the top-k Chinese
translations. That is, for (r
E
, r
C
), we redefine the
score as T
LF
R
(r
E
, r
C
)/
?
i?[1,k]
T
LF
R
(r
E
, r
rank
i
C
)
where r
rank
i
C
is the i-th rank Chinese relation for
r
E
by Equation 2. We empirically set k = 4.
English LF EF
visit ?? (visit) ?? (visit)
support ?...?? (provide to ...) -
ratify ?? (discuss)2 ?? (ratify)
Table 1: Examples of relation translations.
Person Organization
Method P. R. F1 P. R. F1
LF+EF 0.84 0.80 0.82 0.60 0.52 0.56
EF 0.81 0.79 0.80 0.56 0.52 0.54
Seed 0.80 0.77 0.78 0.49 0.44 0.46
PH+SM 0.59 0.59 0.59 0.29 0.29 0.29
Table 2: Entity translation comparison.
3.3 Hybrid Approach LF+EF
We find that LF and EF are complementary. Ta-
ble 1 shows the examples of relations and their
translations. In general, LF can translate more re-
lations (e.g., support and capture). However,
in some cases like ratify, highly related relations
may induce noise. That is, we always?? (dis-
cuss) before we ?? (ratify) something and
hence the temporal behavior of ?? (discuss)
is also very similar to that of ratify. On the other
hand, it can be correctly translated using EF.
Thus, we produce the hybrid relation transla-
tion, and we empirically set ? = 0.4:
T
LF+EF
R
(r
E
, r
C
)=?T
LF
R
(r
E
, r
C
)+(1 ? ?)T
EF
R
(r
E
, r
C
)
(3)
4 Evaluation
In this section, we evaluate the proposed approach
on the entity translation task and the relation trans-
lation task. We extract English and Chinese state-
ments from news articles in 2008 by Xinhua news
who publishes news in both English and Chinese,
which were also used by Lee and Hwang (2013).
The number of English articles is 100,746, and
that of Chinese articles is 88,031. As we can see
from the difference in the numbers of the docu-
ments, the news corpora are not direct translations,
but they have asymmetry of entities and relations.
4.1 Entity Translation
In this section, we present experimental settings
and results on translating entities using our pro-
posed approaches. To measure the effectiveness,
2
The correct translation?? (ratify) is ranked second.
851
Methods Precision Recall F1
LF+EF 0.37 0.44 0.40
LF 0.26 0.25 0.26
EF 0.41 0.17 0.24
Table 3: Relation translation comparison.
we use a set of gold standard entity translation
pairs which consist of 221 person entities and 52
organization entities. We measure precision, re-
call, and F1-score based on the returned trans-
lation pairs for each English entity as it is done
in (Lee and Hwang, 2013).
We compare our hybrid approach, which is de-
noted by LF+EF with EF (Lee and Hwang, 2013),
a combined approach PH+SM of phonetic similar-
ity and letter-wise semantic translation for better
accuracy for organizations (Lam et al, 2007), and
the seed translations Seed that we adopt (You et
al., 2012) with PH+SM as a base translation ma-
trix.
3
We process one iteration of the entire frame-
work (STEP 1-3) for both LF+EF and EF.
Table 2 shows the comparison of the methods.
Our proposed approach LF+EF shows higher F1-
score than the baselines. In particular, our ap-
proach outperforms EF. For example, ?Matthew
Emmons? is a lesser known entity, and we have
only few statements mentioning him in the cor-
pora. The corpus explicit feature EF alone cannot
translate the relation win and, in turn, ?Matthew
Emmons?. However, LF+EF translates him cor-
rectly into?????? through the relation win.
4.2 Relation Translation
This section considers the relation translation task.
Each relation translation method translates an En-
glish relation r
E
into a list of Chinese relations,
and we check whether a Chinese relation r
C
with
the highest translation score is the correct transla-
tion. We consider the relation translation is cor-
rect when the semantics are equivalent. For ex-
ample, ? (leave for/go to) is a correct trans-
lation of leave for, but ?? (leave) is not. To-
tal 3342 English-Chinese relation translation pairs
returned by our method and the baselines are ran-
domly shown and labeled. Out of 3342 pairs, 399
are labeled as correct.
3
Our results leveraging relational temporality outper-
forms the reported results using entity temporality on the
same data set. The two approaches using temporality are or-
thogonal and can be aggregated, which we leave as our future
directions.
Eng. Rel. C1 C1+C2 C1+C2+C3 EF
visit 15 4 1 1
drop 21 14 1 -
capture 6 4 1 -
Table 4: Rank of correct relation translation. The
symbol ?-? indicates no correct translation.
Table 3 shows the comparisons of LF, EF
and their hybrid LF+EF. We can clearly see that
LF shows higher recall than EF while EF shows
higher precision. As we emphasized in Sec-
tion 3.3, we can see their complementary property.
Their hybrid LF+EF has both high precision and
recall, thus has the highest F1-score.
Note that the absolute numbers (due to the harsh
evaluation criteria) may look low. But the top
translations are still relevant (e.g., fight is trans-
lated to ? (deploy troops)). In addition, the
lower ranked but correct relation translations also
affect entity translation. Therefore, even lower-
performing EF boosted the entity translations, and
in effect, our approach could achieve higher F1-
score in the entity translation task.
To illustrate the detailed effects of the corpus
latent features, Table 4 shows the ranks of correct
Chinese translations for English relations by meth-
ods using selected features for the challenges. For
comparison, the ranks of the correct translations
when using EF are shown. Our approach using
the entity-relation coupling similarity feature for
[C1] alone often cannot find the correct transla-
tions. But using all features removes such noise.
5 Conclusion
This paper studied temporality features for re-
lation equivalence. With the proposed features,
we devised a hybrid approach combining corpus
latent and explicit features with complementary
strength. We empirically showed the effectiveness
of our hybrid approach on relation translation, and
it, in turn, improved entity translation.
Acknowledgments
This research was supported by the MSIP (The
Ministry of Science, ICT and Future Planning),
Korea and Microsoft Research, under IT/SW
Creative research program supervised by the
NIPA(National IT Industry Promotion Agency).
(NIPA-2013-H0503-13-1009).
852
References
Jinhan Kim, Long Jiang, Seung-won Hwang, Young-In
Song, and Ming Zhou. 2011. Mining entity trans-
lations from comparable corpora: a holistic graph
mapping approach. In Proc. 20
th
ACM International
Conference on Information and Knowledge Man-
agement (CIKM 2011), pages 1295?1304. ACM.
Jinhan Kim, Seung-won Hwang, Long Jiang, Young-
In Song, and Ming Zhou. 2012. Entity translation
mining from comparable corpora: Combining graph
mapping with corpus latent features. In IEEE Trans-
actions on Knowledge and Data Engineering, pages
1787?1800.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proc. 8
th
Annual Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics (HLT-NAACL
2006), pages 82?88. Association for Computational
Linguistics.
Kevin Knight and Jonathan Graehl. 1998. Ma-
chine transliteration. Computational Linguistics,
24(4):599?612, December.
Wai Lam, Shing-Kit Chan, and Ruizhang Huang.
2007. Named entity translation matching and learn-
ing: With application for mining unseen transla-
tions. ACM Transactions on Information Systems,
25(1), February.
Taesung Lee and Seung-won Hwang. 2013. Bootstrap-
ping entity translation on weakly comparable cor-
pora. In Proc. 51
st
Annual Meeting on Association
for Computational Linguistics (ACL 2013). Associ-
ation for Computational Linguistics.
Thahir Mohamed, Estevam Hruschka, and Tom
Mitchell. 2011. Discovering relations between
noun categories. In Proc. 2011 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP 2011), pages 1447?1455. Association for
Computational Linguistics.
Ndapandula Nakashole, Gerhard Weikum, and
Fabian M. Suchanek. 2012. PATTY: A Taxonomy
of Relational Patterns with Semantic Types. In
Proc. 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computa-
tional Natural Language Learning (EMNLP-CoNLL
2012). Association for Computational Linguistics.
Stephen Wan and Cornelia Maria Verspoor. 1998.
Automatic English-Chinese name transliteration for
development of multilingual resources. In Proc.
36
th
Annual Meeting on Association for Computa-
tional Linguistics (ACL 1998) and 17
th
International
Conference on Computational Linguistics (COLING
1998), pages 1352?1356. Association for Computa-
tional Linguistics.
Gae-won You, Seung-won Hwang, Young-In Song,
Long Jiang, and Zaiqing Nie. 2012. Efficient en-
tity translation mining: A parallelized graph align-
ment approach. ACM Transactions on Information
Systems, 30(4):25:1?25:23, November.
Gae-won You, Young-rok Cha, Jinhan Kim, and
Seung-won Hwang. 2013. Enriching entity transla-
tion discovery using selective temporality. In Proc.
51
st
Annual Meeting on Association for Computa-
tional Linguistics (ACL 2013), pages 201?205. As-
sociation for Computational Linguistics.
853
