Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 633?644,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
A Neural Network for Factoid Question Answering over
Paragraphs
Mohit Iyyer
1
, Jordan Boyd-Graber
2
, Leonardo Claudino
1
,
Richard Socher
3
, Hal Daume? III
1
1
University of Maryland, Department of Computer Science and umiacs
2
University of Colorado, Department of Computer Science
3
Stanford University, Department of Computer Science
{miyyer,claudino,hal}@umiacs.umd.edu,
Jordan.Boyd.Graber@colorado.edu, richard@socher.org
Abstract
Text classification methods for tasks
like factoid question answering typi-
cally use manually defined string match-
ing rules or bag of words representa-
tions. These methods are ineffective
when question text contains very few
individual words (e.g., named entities)
that are indicative of the answer. We
introduce a recursive neural network
(rnn) model that can reason over such
input by modeling textual composition-
ality. We apply our model, qanta, to
a dataset of questions from a trivia
competition called quiz bowl. Unlike
previous rnn models, qanta learns
word and phrase-level representations
that combine across sentences to reason
about entities. The model outperforms
multiple baselines and, when combined
with information retrieval methods, ri-
vals the best human players.
1 Introduction
Deep neural networks have seen widespread
use in natural language processing tasks such
as parsing, language modeling, and sentiment
analysis (Bengio et al., 2003; Socher et al.,
2013a; Socher et al., 2013c). The vector spaces
learned by these models cluster words and
phrases together based on similarity. For exam-
ple, a neural network trained for a sentiment
analysis task such as restaurant review classifi-
cation might learn that ?tasty? and ?delicious?
should have similar representations since they
are synonymous adjectives.
These models have so far only seen success in
a limited range of text-based prediction tasks,
Later in its existence, this polity?s leader was chosen
by a group that included three bishops and six laymen,
up from the seven who traditionally made the decision.
Free imperial cities in this polity included Basel and
Speyer. Dissolved in 1806, its key events included the
Investiture Controversy and the Golden Bull of 1356.
Led by Charles V, Frederick Barbarossa, and Otto I,
for 10 points, name this polity, which ruled most of
what is now Germany through the Middle Ages and
rarely ruled its titular city.
Figure 1: An example quiz bowl question about
the Holy Roman Empire. The first sentence
contains no words or named entities that by
themselves are indicative of the answer, while
subsequent sentences contain more and more
obvious clues.
where inputs are typically a single sentence and
outputs are either continuous or a limited dis-
crete set. Neural networks have not yet shown
to be useful for tasks that require mapping
paragraph-length inputs to rich output spaces.
Consider factoid question answering: given
a description of an entity, identify the per-
son, place, or thing discussed. We describe a
task with high-quality mappings from natural
language text to entities in Section 2. This
task?quiz bowl?is a challenging natural lan-
guage problem with large amounts of diverse
and compositional data.
To answer quiz bowl questions, we develop
a dependency tree recursive neural network
in Section 3 and extend it to combine predic-
tions across sentences to produce a question
answering neural network with trans-sentential
averaging (qanta). We evaluate our model
against strong computer and human baselines
in Section 4 and conclude by examining the
latent space and model mistakes.
633
2 Matching Text to Entities: Quiz
Bowl
Every weekend, hundreds of high school and
college students play a game where they map
raw text to well-known entities. This is a trivia
competition called quiz bowl. Quiz bowl ques-
tions consist of four to six sentences and are
associated with factoid answers (e.g., history
questions ask players to identify specific battles,
presidents, or events). Every sentence in a quiz
bowl question is guaranteed to contain clues
that uniquely identify its answer, even without
the context of previous sentences. Players an-
swer at any time?ideally more quickly than
the opponent?and are rewarded for correct
answers.
Automatic approaches to quiz bowl based on
existing nlp techniques are doomed to failure.
Quiz bowl questions have a property called
pyramidality, which means that sentences early
in a question contain harder, more obscure
clues, while later sentences are ?giveaways?.
This design rewards players with deep knowl-
edge of a particular subject and thwarts bag
of words methods. Sometimes the first sen-
tence contains no named entities?answering
the question correctly requires an actual un-
derstanding of the sentence (Figure 1). Later
sentences, however, progressively reveal more
well-known and uniquely identifying terms.
Previous work answers quiz bowl ques-
tions using a bag of words (na??ve Bayes) ap-
proach (Boyd-Graber et al., 2012). These mod-
els fail on sentences like the first one in Figure 1,
a typical hard, initial clue. Recursive neural
networks (rnns), in contrast to simpler models,
can capture the compositional aspect of such
sentences (Hermann et al., 2013).
rnns require many redundant training exam-
ples to learn meaningful representations, which
in the quiz bowl setting means we need multiple
questions about the same answer. Fortunately,
hundreds of questions are produced during the
school year for quiz bowl competitions, yield-
ing many different examples of questions ask-
ing about any entity of note (see Section 4.1
for more details). Thus, we have built-in re-
dundancy (the number of ?askable? entities is
limited), but also built-in diversity, as difficult
clues cannot appear in every question without
becoming well-known.
3 Dependency-Tree Recursive
Neural Networks
To compute distributed representations for the
individual sentences within quiz bowl ques-
tions, we use a dependency-tree rnn (dt-rnn).
These representations are then aggregated and
fed into a multinomial logistic regression clas-
sifier, where class labels are the answers asso-
ciated with each question instance.
In previous work, Socher et al. (2014) use
dt-rnns to map text descriptions to images.
dt-rnns are robust to similar sentences with
slightly different syntax, which is ideal for our
problem since answers are often described by
many sentences that are similar in meaning
but different in structure. Our model improves
upon the existing dt-rnn model by jointly
learning answer and question representations
in the same vector space rather than learning
them separately.
3.1 Model Description
As in other rnn models, we begin by associ-
ating each word w in our vocabulary with a
vector representation x
w
? R
d
. These vectors
are stored as the columns of a d ? V dimen-
sional word embedding matrix W
e
, where V is
the size of the vocabulary. Our model takes
dependency parse trees of question sentences
(De Marneffe et al., 2006) and their correspond-
ing answers as input.
Each node n in the parse tree for a partic-
ular sentence is associated with a word w, a
word vector x
w
, and a hidden vector h
n
? R
d
of the same dimension as the word vectors. For
internal nodes, this vector is a phrase-level rep-
resentation, while at leaf nodes it is the word
vector x
w
mapped into the hidden space. Un-
like in constituency trees where all words reside
at the leaf level, internal nodes of dependency
trees are associated with words. Thus, the dt-
rnn has to combine the current node?s word
vector with its children?s hidden vectors to form
h
n
. This process continues recursively up to
the root, which represents the entire sentence.
We associate a separate d?d matrix W
r
with
each dependency relation r in our dataset and
learn these matrices during training.
1
Syntac-
tically untying these matrices improves com-
1
We had 46 unique dependency relations in our quiz
bowl dataset.
634
This city ?s economy depended on subjugated peasants called helots
ROOT
DET
POSSESSIVE
POSS
NSUBJ
PREP
POBJ
AMOD
VMOD
DOBJ
Figure 2: Dependency parse of a sentence from a question about Sparta.
positionality over the standard rnn model by
taking into account relation identity along with
tree structure. We include an additional d? d
matrix, W
v
, to incorporate the word vector x
w
at a node into the node vector h
n
.
Given a parse tree (Figure 2), we first com-
pute leaf representations. For example, the
hidden representation h
helots
is
h
helots
= f(W
v
? x
helots
+ b), (1)
where f is a non-linear activation function such
as tanh and b is a bias term. Once all leaves
are finished, we move to interior nodes with
already processed children. Continuing from
?helots? to its parent, ?called?, we compute
h
called
=f(W
DOBJ
? h
helots
+W
v
? x
called
+ b). (2)
We repeat this process up to the root, which is
h
depended
=f(W
NSUBJ
? h
economy
+W
PREP
? h
on
+W
v
? x
depended
+ b). (3)
The composition equation for any node n with
children K(n) and word vector x
w
is h
n
=
f(W
v
? x
w
+ b+
?
k?K(n)
W
R(n,k)
? h
k
), (4)
where R(n, k) is the dependency relation be-
tween node n and child node k.
3.2 Training
Our goal is to map questions to their corre-
sponding answer entities. Because there are
a limited number of possible answers, we can
view this as a multi-class classification task.
While a softmax layer over every node in the
tree could predict answers (Socher et al., 2011;
Iyyer et al., 2014), this method overlooks that
most answers are themselves words (features)
in other questions (e.g., a question on World
War II might mention the Battle of the Bulge
and vice versa). Thus, word vectors associated
with such answers can be trained in the same
vector space as question text,
2
enabling us to
model relationships between answers instead
of assuming incorrectly that all answers are
independent.
To take advantage of this observation, we
depart from Socher et al. (2014) by training
both the answers and questions jointly in a
single model, rather than training each sep-
arately and holding embeddings fixed during
dt-rnn training. This method cannot be ap-
plied to the multimodal text-to-image mapping
problem because text captions by definition are
made up of words and thus cannot include im-
ages; in our case, however, question text can
and frequently does include answer text.
Intuitively, we want to encourage the vectors
of question sentences to be near their correct
answers and far away from incorrect answers.
We accomplish this goal by using a contrastive
max-margin objective function described be-
low. While we are not interested in obtaining a
ranked list of answers,
3
we observe better per-
formance by adding the weighted approximate-
rank pairwise (warp) loss proposed in Weston
et al. (2011) to our objective function.
Given a sentence paired with its correct an-
swer c, we randomly select j incorrect answers
from the set of all incorrect answers and denote
this subset as Z. Since c is part of the vocab-
ulary, it has a vector x
c
? W
e
. An incorrect
answer z ? Z is also associated with a vector
x
z
?W
e
. We define S to be the set of all nodes
in the sentence?s dependency tree, where an
individual node s ? S is associated with the
2
Of course, questions never contain their own answer
as part of the text.
3
In quiz bowl, all wrong guesses are equally detri-
mental to a team?s score, no matter how ?close? a guess
is to the correct answer.
635
hidden vector h
s
. The error for the sentence is
C(S, ?) =
?
s?S
?
z?Z
L(rank(c, s, Z))max(0,
1? x
c
? h
s
+ x
z
? h
s
), (5)
where the function rank(c, s, Z) provides the
rank of correct answer c with respect to the
incorrect answers Z. We transform this rank
into a loss function
4
shown by Usunier et al.
(2009) to optimize the top of the ranked list,
L(r) =
r
?
i=1
1/i.
Since rank(c, s, Z) is expensive to compute,
we approximate it by randomly sampling K
incorrect answers until a violation is observed
(x
c
? h
s
< 1 + x
z
? h
s
) and set rank(c, s, Z) =
(|Z|?1)/K, as in previous work (Weston et al.,
2011; Hermann et al., 2014). The model mini-
mizes the sum of the error over all sentences T
normalized by the number of nodes N in the
training set,
J(?) =
1
N
?
t?T
C(t, ?). (6)
The parameters ? = (W
r?R
,W
v
,W
e
, b), where
R represents all dependency relations in the
data, are optimized using AdaGrad(Duchi et
al., 2011).
5
In Section 4 we compare perfor-
mance to an identical model (fixed-qanta)
that excludes answer vectors from W
e
and show
that training them as part of ? produces signif-
icantly better results.
The gradient of the objective function,
?C
??
=
1
N
?
t?T
?J(t)
??
, (7)
is computed using backpropagation through
structure (Goller and Kuchler, 1996).
3.3 From Sentences to Questions
The model we have just described considers
each sentence in a quiz bowl question indepen-
dently. However, previously-heard sentences
within the same question contain useful infor-
mation that we do not want our model to ignore.
4
Our experiments show that adding this loss term to
the objective function not only increases performance
but also speeds up convergence
5
We set the initial learning rate ? = 0.05 and reset
the squared gradient sum to zero every five epochs.
While past work on rnn models have been re-
stricted to the sentential and sub-sentential
levels, we show that sentence-level representa-
tions can be easily combined to generate useful
representations at the larger paragraph level.
The simplest and best
6
aggregation method
is just to average the representations of each
sentence seen so far in a particular question.
As we show in Section 4, this method is very
powerful and performs better than most of our
baselines. We call this averaged dt-rnn model
qanta: a question answering neural network
with trans-sentential averaging.
4 Experiments
We compare the performance of qanta against
multiple strong baselines on two datasets.
qanta outperforms all baselines trained only
on question text and improves an information
retrieval model trained on all of Wikipedia.
qanta requires that an input sentence de-
scribes an entity without mentioning that
entity, a constraint that is not followed by
Wikipedia sentences.
7
While ir methods can
operate over Wikipedia text with no issues,
we show that the representations learned by
qanta over just a dataset of question-answer
pairs can significantly improve the performance
of ir systems.
4.1 Datasets
We evaluate our algorithms on a corpus of over
100,000 question/answer pairs from two differ-
ent sources. First, we expand the dataset used
in Boyd-Graber et al. (2012) with publically-
available questions from quiz bowl tournaments
held after that work was published. This gives
us 46,842 questions in fourteen different cate-
gories. To this dataset we add 65,212 questions
from naqt, an organization that runs quiz
bowl tournaments and generously shared with
us all of their questions from 1998?2013.
6
We experimented with weighting earlier sentences
less than later ones in the average as well as learning an
additional RNN on top of the sentence-level representa-
tions. In the former case, we observed no improvements
over a uniform average, while in the latter case the
model overfit even with strong regularization.
7
We tried transforming Wikipedia sentences into
quiz bowl sentences by replacing answer mentions with
appropriate descriptors (e.g., ?Joseph Heller? with ?this
author?), but the resulting sentences suffered from a
variety of grammatical issues and did not help the final
result.
636
Because some categories contain substan-
tially fewer questions than others (e.g., astron-
omy has only 331 questions), we consider only
literature and history questions, as these two
categories account for more than 40% of the
corpus. This leaves us with 21,041 history ques-
tions and 22,956 literature questions.
4.1.1 Data Preparation
To make this problem feasible, we only consider
a limited set of the most popular quiz bowl an-
swers. Before we filter out uncommon answers,
we first need to map all raw answer strings to
a canonical set to get around formatting and
redundancy issues. Most quiz bowl answers are
written to provide as much information about
the entity as possible. For example, the follow-
ing is the raw answer text of a question on the
Chinese leader Sun Yat-sen: Sun Yat-sen; or
Sun Yixian; or Sun Wen; or Sun Deming; or
Nakayama Sho; or Nagao Takano. Quiz bowl
writers vary in how many alternate acceptable
answers they provide, which makes it tricky to
strip superfluous information from the answers
using rule-based approaches.
Instead, we use Whoosh,
8
an information re-
trieval library, to generate features in an active
learning classifier that matches existing answer
strings to Wikipedia titles. If we are unable
to find a match with a high enough confidence
score, we throw the question out of our dataset.
After this standardization process and manual
vetting of the resulting output, we can use the
Wikipedia page titles as training labels for the
dt-rnn and baseline models.
9
65.6% of answers only occur once or twice
in the corpus. We filter out all answers that
do not occur at least six times, which leaves
us with 451 history answers and 595 literature
answers that occur on average twelve times
in the corpus. These pruning steps result in
4,460 usable history questions and 5,685 liter-
ature questions. While ideally we would have
used all answers, our model benefits from many
training examples per answer to learn mean-
ingful representations; this issue can possibly
be addressed with techniques from zero shot
learning (Palatucci et al., 2009; Pasupat and
Liang, 2014), which we leave to future work.
8
https://pypi.python.org/pypi/Whoosh/
9
Code and non-naqt data available at http://cs.
umd.edu/
~
miyyer/qblearn.
We apply basic named entity recogni-
tion (ner) by replacing all occurrences of
answers in the question text with single
entities (e.g., Ernest Hemingway becomes
Ernest Hemingway). While we experimented
with more advanced ner systems to detect
non-answer entities, they could not handle
multi-word named entities like the book Love
in the Time of Cholera (title case) or battle
names (e.g., Battle of Midway). A simple
search/replace on all answers in our corpus
works better for multi-word entities.
The preprocessed data are split into folds
by tournament. We choose the past two na-
tional tournaments
10
as our test set as well
as questions previously answered by players in
Boyd-Graber et al. (2012) and assign all other
questions to train and dev sets. History results
are reported on a training set of 3,761 ques-
tions with 14,217 sentences and a test set of
699 questions with 2,768 sentences. Literature
results are reported on a training set of 4,777
questions with 17,972 sentences and a test set
of 908 questions with 3,577 sentences.
Finally, we initialize the word embedding
matrix W
e
with word2vec (Mikolov et al., 2013)
trained on the preprocessed question text in
our training set.
11
We use the hierarchical skip-
gram model setting with a window size of five
words.
4.2 Baselines
We pit qanta against two types of baselines:
bag of words models, which enable comparison
to a standard NLP baseline, and information
retrieval models, which allow us to compare
against traditional question answering tech-
niques.
BOW The bow baseline is a logistic regres-
sion classifier trained on binary unigram indi-
cators.
12
This simple discriminative model is
an improvement over the generative quiz bowl
answering model of Boyd-Graber et al. (2012).
10
The tournaments were selected because naqt does
not reuse any questions or clues within these tourna-
ments.
11
Out-of-vocabulary words from the test set are ini-
tialized randomly.
12
Raw word counts, frequencies, and TF-IDF
weighted features did not increase performance, nor
did adding bigrams to the feature set (possibly because
multi-word named entities are already collapsed into
single words).
637
BOW-DT The bow-dt baseline is identical
to bow except we augment the feature set with
dependency relation indicators. We include
this baseline to isolate the effects of the depen-
dency tree structure from our compositional
model.
IR-QB The ir-qb baseline maps questions to
answers using the state-of-the-art Whoosh ir
engine. The knowledge base for ir-qb consists
of ?pages? associated with each answer, where
each page is the union of training question text
for that answer. Given a partial question, the
text is first preprocessed using a query lan-
guage similar to that of Apache Lucene. This
processed query is then matched to pages uses
bm-25 term weighting, and the top-ranked page
is considered to be the model?s guess. We also
incorporate fuzzy queries to catch misspellings
and plurals and use Whoosh?s built-in query ex-
pansion functionality to add related keywords
to our queries. IR-WIKI The ir-wiki model
is identical to the ir-qb model except that each
?page? in its knowledge base also includes all
text from the associated answer?s Wikipedia
article. Since all other baselines and dt-rnn
models operate only on the question text, this
is not a valid comparison, but we offer it to
show that we can improve even this strong
model using qanta.
4.3 DT-RNN Configurations
For all dt-rnn models the vector dimension d
and the number of wrong answers per node j
is set to 100. All model parameters other than
W
e
are randomly initialized. The non-linearity
f is the normalized tanh function,
13
f(v) =
tanh(v)
?tanh(v)?
. (8)
qanta is our dt-rnn model with feature
averaging across previously-seen sentences in a
question. To obtain the final answer prediction
given a partial question, we first generate a
feature representation for each sentence within
that partial question. This representation is
computed by concatenating together the word
embeddings and hidden representations aver-
aged over all nodes in the tree as well as the
13
The standard tanh function produced heavy sat-
uration at higher levels of the trees, and corrective
weighting as in Socher et al. (2014) hurt our model
because named entities that occur as leaves are often
more important than non-terminal phrases.
root node?s hidden vector. Finally, we send
the average of all of the individual sentence fea-
tures
14
as input to a logistic regression classifier
for answer prediction.
fixed-qanta uses the same dt-rnn configu-
ration as qanta except the answer vectors are
kept constant as in the text-to-image model.
4.4 Human Comparison
Previous work provides human answers (Boyd-
Graber et al., 2012) for quiz bowl questions.
We use human records for 1,201 history guesses
and 1,715 literature guesses from twenty-two of
the quiz bowl players who answered the most
questions.
15
The standard scoring system for quiz bowl is
10 points for a correct guess and -5 points for
an incorrect guess. We use this metric to com-
pute a total score for each human. To obtain
the corresponding score for our model, we force
it to imitate each human?s guessing policy. For
example, Figure 3 shows a human answering
in the middle of the second sentence. Since our
model only considers sentence-level increments,
we compare the model?s prediction after the
first sentence to the human prediction, which
means our model is privy to less information
than humans.
The resulting distributions are shown in Fig-
ure 4?our model does better than the average
player on history questions, tying or defeat-
ing sixteen of the twenty-two players, but it
does worse on literature questions, where it
only ties or defeats eight players. The figure
indicates that literature questions are harder
than history questions for our model, which is
corroborated by the experimental results dis-
cussed in the next section.
5 Discussion
In this section, we examine why qanta im-
proves over our baselines by giving examples
of questions that are incorrectly classified by
all baselines but correctly classified by qanta.
We also take a close look at some sentences that
all models fail to answer correctly. Finally, we
visualize the answer space learned by qanta.
14
Initial experiments with L
2
regularization hurt per-
formance on a validation set.
15
Participants were skilled quiz bowl players and are
not representative of the general population.
638
History Literature
Model Pos 1 Pos 2 Full Pos 1 Pos 2 Full
bow 27.5 51.3 53.1 19.3 43.4 46.7
bow-dt 35.4 57.7 60.2 24.4 51.8 55.7
ir-qb 37.5 65.9 71.4 27.4 54.0 61.9
fixed-qanta 38.3 64.4 66.2 28.9 57.7 62.3
qanta 47.1 72.1 73.7 36.4 68.2 69.1
ir-wiki 53.7 76.6 77.5 41.8 74.0 73.3
qanta+ir-wiki 59.8 81.8 82.3 44.7 78.7 76.6
Table 1: Accuracy for history and literature at the first two sentence positions of each question
and the full question. The top half of the table compares models trained on questions only, while
the IR models in the bottom half have access to Wikipedia. qanta outperforms all baselines
that are restricted to just the question data, and it substantially improves an IR model with
access to Wikipedia despite being trained on much less data.
200
150
100
50
0
50
100
150
200
Sco
re D
iffe
ren
ce
History: Model vs. Human
Model losesModel wins 400300
200
100
0
100
200
Sco
re D
iffe
ren
ce
Literature: Model vs. Human
Model losesModel wins
Figure 4: Comparisons of qanta+ir-wiki to human quiz bowl players. Each bar represents an
individual human, and the bar height corresponds to the difference between the model score and
the human score. Bars are ordered by human skill. Red bars indicate that the human is winning,
while blue bars indicate that the model is winning. qanta+ir-wiki outperforms most humans
on history questions but fails to defeat the ?average? human on literature questions.
A minor character in this play can be summoned
by a bell that does not always work; that character
also doesn?t have eyelids. Near the end, a woman
who drowned her illegitimate child attempts to stab
another woman in the Second Empire-style
3
room
in which the entire play takes place. For 10 points,
Estelle and Ines are characters in which existentialist
play in which Garcin claims ?Hell is other people?,
written by Jean-Paul Sartre?
Figure 3: A question on the play ?No Exit?
with human buzz position marked as
3
. Since
the buzz occurs in the middle of the second
sentence, our model is only allowed to see the
first sentence.
5.1 Experimental Results
Table 1 shows that when bag of words and
information retrieval methods are restricted to
question data, they perform significantly worse
than qanta on early sentence positions. The
performance of bow-dt indicates that while
the dependency tree structure helps by itself,
the compositional distributed representations
learned by qanta are more useful. The signif-
icant improvement when we train answers as
part of our vocabulary (see Section 3.2) indi-
cates that our model uses answer occurrences
within question text to learn a more informa-
tive vector space.
The disparity between ir-qb and ir-wiki
indicates that the information retrieval models
need lots of external data to work well at all
sentence positions. ir-wiki performs better
than other models because Wikipedia contains
many more sentences that partially match spe-
cific words or phrases found in early clues than
the question training set. In particular, it is
impossible for all other models to answer clues
in the test set that have no semantically similar
639
or equivalent analogues in the training ques-
tion data. With that said, ir methods can
also operate over data that does not follow the
special constraints of quiz bowl questions (e.g.,
every sentence uniquely identifies the answer,
answers don?t appear in their corresponding
questions), which qanta cannot handle. By
combining qanta and ir-wiki, we are able to
leverage access to huge knowledge bases along
with deep compositional representations, giv-
ing us the best of both worlds.
5.2 Where the Attribute Space Helps
Answer Questions
We look closely at the first sentence from a
literature question about the author Thomas
Mann: ?He left unfinished a novel whose title
character forges his father?s signature to get
out of school and avoids the draft by feigning
desire to join?.
All baselines, including ir-wiki, are unable
to predict the correct answer given only this
sentence. However, qanta makes the correct
prediction. The sentence contains no named
entities, which makes it almost impossible for
bag of words or string matching algorithms to
predict correctly. Figure 6 shows that the plot
description associated with the ?novel? node
is strongly indicative of the answer. The five
highest-scored answers are all male authors,
16
which shows that our model is able to learn the
answer type without any hand-crafted rules.
Our next example, the first sentence in Ta-
ble 2, is from the first position of a question
on John Quincy Adams, which is correctly an-
swered by only qanta. The bag of words
model guesses Henry Clay, who was also a Sec-
retary of State in the nineteenth century and
helped John Quincy Adams get elected to the
presidency in a ?corrupt bargain?. However,
the model can reason that while Henry Clay
was active at the same time and involved in
the same political problems of the era, he did
not represent the Amistad slaves, nor did he
negotiate the Treaty of Ghent.
5.3 Where all Models Struggle
Quiz bowl questions are intentionally written to
make players work to get the answer, especially
at early sentence positions. Our model fails to
16
three of whom who also have well-known unfinished
novels
answer correctly more than half the time after
hearing only the first sentence. We examine
some examples to see if there are any patterns
to what makes a question ?hard? for machine
learning models.
Consider this question about the Italian ex-
plorer John Cabot: ?As a young man, this
native of Genoa disguised himself as a Muslim
to make a pilgrimage to Mecca?.
While it is obvious to human readers that
the man described in this sentence is not actu-
ally a Muslim, qanta has to accurately model
the verb disguised to make that inference. We
show the score plot of this sentence in Figure 7.
The model, after presumably seeing many in-
stances of muslim and mecca associated with
Mughal emperors, is unable to prevent this
information from propagating up to the root
node. On the bright side, our model is able to
learn that the question is expecting a human
answer rather than non-human entities like the
Umayyad Caliphate.
More examples of impressive answers by
qanta as well as incorrect guesses by all sys-
tems are shown in Table 2.
5.4 Examining the Attribute Space
Figure 5 shows a t-SNE visualization (Van der
Maaten and Hinton, 2008) of the 451 answers
in our history dataset. The vector space is
divided into six general clusters, and we focus
in particular on the us presidents. Zooming
in on this section reveals temporal clustering:
presidents who were in office during the same
timeframe occur closer together. This observa-
tion shows that qanta is capable of learning
attributes of entities during training.
6 Related Work
There are two threads of related work relevant
to this paper. First, we discuss previous ap-
plications of compositional vector models to
related NLP tasks. Then, we examine existing
work on factoid question-answering and review
the similarities and differences between these
tasks and the game of quiz bowl.
6.1 Recursive Neural Networks for
NLP
The principle of semantic composition states
that the meaning of a phrase can be derived
640
TSNE-1TSNE-2 Wars, rebellions, and battlesU.S. presidentsPrime ministersExplorers & emperorsPoliciesOthertammany_hall calvin_coolidgelollardy fourth_crusadesonghai_empire peace_of_westphaliainca_empireatahualpa charles_sumnerjohn_paul_jones wounded_knee_massacrehuldrych_zwingli darius_ibattle_of_ayacuchojohn_cabotghana ulysses_s._grant hartford_conventioncivilian_conservation_corpsroger_williams_(theologian)george_h._pendleton william_mckinleyvictoria_woodhullcredit_mobilier_of_america_scandal henry_cabot_lodge,_jr. mughal_empire john_marshallcultural_revolutionguadalcanallouisiana_purchasenight_of_the_long_kniveschandragupta_mauryasamuel_de_champlainthirty_years'_war compromise_of_1850battle_of_hastingsbattle_of_salamisakbar lewis_cassdawes_plan hernando_de_soto carthage joseph_mccarthymainesalvador_allende battle_of_gettysburgmikhail_gorbachev aaron_burrequal_rights_amendmentwar_of_the_spanish_successioncoxey's_army george_meadefourteen_pointsmapp_v._ohio sam_houston ming_ ynastyboxer_rebellionanti-masonic_partyporfirio_diaz treaty_of_portsmouththebes,_greece golden_hordefrancisco_i._madero hittitesjames_g._blaineschenck_v._united_states caligulawilliam_walker_(filibuster)henry_vii_of_ nglandkonrad_adenauerkellogg-briand_pact battle_of_cullodentreaty_of_brest-litovsk william_p nna._philip_randolphh nry_l._stimsonwhig_party_(united_states)caroline_affair clarence_darrowwhiskey_rebellionbattle_of_midwaybattle_of_lepantoadolf_eichmanngeorges_clemenceau battle_of_the_little_bighornpontiac_(person) black_hawk_warbattle_of_tannenbergclayton_antitrust_actprovisions_of_oxford battle_of_actiumsuez_crisis spartacusdorr_rebellion jay_treatytriangle_shirtwaist_factory_fire kamakura_shogunatejulius_nyerere frederick_douglasspierre_trudeaunagasaki suleiman_the_magnificentfalklands_war war_of_devolutioncharlemagnedaniel_boone edict_of_nantesharry_s._trumanshakapedro_alvares_cabralthomas_hart_benton_(politician)battle_of_the_coral_sea peterloo_massacrebattle_of_bosworth_fieldroger_b._taneybernardo_o'higginsneville_chamberlainhenry_hudson cyrus_the_great jane_addamsrough_ridersjames_a._garfieldnapoleon_iii missouri_compromisebattle_of_leyte_gulfambrose_burnsidetrent_affairmaria_theresawilliam_ewart_gladstone walter_mondalebarry_goldw terlouis_rielhideki_tojo marco_polobrian_mulroney truman_doctrineroald_amundsen tokugawa_shogunateeleanor_of_aquitaine louis_brandeisbattle_of_trentonkhmer_empirebenito_juarez battle_of_antietamwhiskey_ring otto_von_bismarckbook r_t._washingtonbattle_of_bannockburneugene_v._debs erie_canaljameson_raid green_mountain_boyshaymarket_affairfinlandfashoda_incident battle_of_shilohhannibal john_jayeaster_rising jamaicabrook_farm umayyad_caliph temuhammadfrancis_drakeclara_barton shays'_rebellion verdunhadrianvyacheslav_molotov oda_nobunagacanossasamuel_gompers battle_of_bunker_hi lbattle_of_plasseydavid_livingstonesol npericles tang_dynastyteutonic_knightssecond_vatican_councilalfred_dreyfushenry_the_navigatornelson_mandelapeasants'_revolt gaius_mariusgetulio_vargas horatio_gatesjohn_t._scopes league_of_nationsfirst_battle_of_bull_runalfred_the_greatleonid_brezhn cherokee long_marchemiliano_zapata james_monroewoodrow_wilsonvandals william_henry_harrisonbattle_of_puebla battle_of_zamajustinian_i thaddeus_stevenscecil_rhodeskwame_nkrumah diet_of_wormsgeorge_armstrong_custerbattle_of_agincourtseminole_wars shah_jahanamerigo_vespucci john_foster_dulleslester_b._pearson oregon_trail claudiuslateran_treatychester_a._arthuropium_wars treaty_of_utrechtknights_of_labor alexander_hamiltonplessy_v._ferguson hora e_greeleymary baker_eddyalex nder_kerensky jacquerie treaty_of_ghentb y_of_pigs_invasionantonio_lopez_de_santa_anna great_northern_warhenry_i_of_england council_of_trentchiang_kai-sheksamuel_j._tildenfidel_castro wilmot_proviso yu n_dynastybastille b njamin_harrisonwar_of_the_austrian_successioncrimean_warjohn_brown_(abolitionist)teapot_dome_scandal albert_b._fallmarcus_licinius_crassus earl_warrenwarren_g._harding gunpowder_plothomestead_strike samuel_adamsjohn_peter_zenger thomas_painefree_soil_partyst._barth lomew's_day_massacrearthur_wellesley,_1st_duke_of_wellingtoncharles_de_gaulleleon_trotsky hugh_capetal xander_h._stephens haile_selassieilliam_h._sewardrutherford_b._hayes safavid_dynastymuhammad_ali_jinnah kulturkampfmaximilien_de_robespierre hub rt_humphreyluddite hull_housephilip_ii_of_macedon guelphs_a d_ghibellines byzantine_empirealbigensian_crusade diocletianfort_ticonderoga parthian_empirecharles_martel william_jennings_bryanalexan er_ii_of_russiaferdinand_magellanstate_of_franklin ivan_the_terriblemartin_luther_(1953_film) millard_fillmorefrancisco_francoaethelred_th _unready ronald_reaganbenito_mussolini henry_claykitchen_cabinetblack_hole_of_calcuttaancient_corinth john_wilkes_b th john_tylerrobert_walpolehuey_long tokugawa_ieyasuthomas_nastnikita_khrushchev andrew_jacksonportug llabour_party_(uk) monroe_doctrine john_quincy_adamscongress_of_berlintecumsehjacques_cartier battle_ f_the_thamesspanis _civil_warethiopia fugitiv _slave_lawsjoh _a._macdonald council_of_chalcedonpancho_villa war_of_the_pacific george_ allacesusan_b._anthonymarcus_garvey grover_clevelandjohn_haygeorge_b._mcclellanoctober_manifestovitus_bering john_hanc ckwilliam_lloyd_garrisonplatt_amendmentmary,_queen_of_scotsfirst_triumviratefra cisc _vasquez_de_coronadomargaret_thatcher sherma _antitrust_acthanseatic_leaguehenry_morton_stanley ju y_revolutionstephen_a._douglas xyz_affair jimmy_ca terfrancisco_pizarrokublai_khanvasco_da_gama spartabattle_of_caporetto ostend_manifestomustafa_kemal_ataturk peter_the_greatgang_of_fourbattle_of_chance lorsvilledavid_lloyd_georgecardinal_mazarin embargo_act_of_1807 brigham_youngcharles_lindberghhudson's_bay_company attilaparis_commu e jefferson_davisamelia_earhart mali_empireadolf_hitler benedict_arnoldcamillo_benso,_count_of_cavour meiji_restorationblack_panther_party mark_antony f anklin_p ercemolly_maguires zachary_taylorhan_dynastyadlai_stevenson_iijames_k._polk douglas_macarthurboston_massacretoyotomi_hidey shigreenback_partysecond_boer_warthird_crusade j es_buchananjoh _she mangeorge_washingtonwars_of_the_rosesatlantic_charter eleanor_rooseveltcongress_ f_viennajohn_wycliffewinston_churchillmilio_aguinaldom guel_hidalgo_ costill second_bank_of_the_united_statescouncil_of constanceseneca_falls_convention first_crusade spiro_agnewtaiping_rebellionmao_zedong paul_von_hindenburgalbany_congressjawaharlal_nehru battle_of_blenheimethan_allenantonio_de_oliveira_salazar herbert_hooverpepin_the_shortindira_gandhi william_howard_taftthomas_jeffersonga a _abdel_nasser oliver_cromw llsalmon_p._chase battle_of_austerlitzbenjamin_disraeli gadsden purchasegirolamo_savonarola treaty_of_tordesillasbattle_of_marathon elizabeth_cady_stantonbattle_of_kings_mountainchristopher_colum uswilliam_the_conquerorbattle_of_trafalgar charles_evans_hughescleistheneswilliam_tecumseh_shermanmobutu_sese ek prague_spring babur peloponn sian_w rjacques_marquette neroparaguay hyksos artin_van_burenbonus rmycha les_stew rt_parnell edward_the_confessorbartolome _d ssalem_witch_trials battle of_ he_bulge john_ damsaginot_lin henry_cabot_logiuseppe_garib ldi daniel_websterjohn_c._calhoun treaty_of_waitangizebulon_pike genghis_khan
calvin_coolidgewilliam_mckinley
james_monroe
woodrow_wilson
william_henry_harrisonbenjamin_harrisonmillard_fillmoreronald_reagan
john_tyler andrew_jacksonjohn_quincy_adamsgrover_clevelandjimmy_carter
franklin_piercezachary_taylorjames_buchanangeorge_washington
herbert_hooverwilliam_howard_taft
thomas_jefferson
martin_van_buren
john_adams
Figure 5: t-SNE 2-D projections of 451 answer
vectors divided into six major clusters. The
blue cluster is predominantly populated by U.S.
presidents. The zoomed plot reveals temporal
clustering among the presidents based on the
years they spent in office.
from the meaning of the words that it con-
tains as well as the syntax that glues those
words together. Many computational models
of compositionality focus on learning vector
spaces (Zanzotto et al., 2010; Erk, 2012; Grefen-
stette et al., 2013; Yessenalina and Cardie,
2011). Recent approaches towards modeling
compositional vector spaces with neural net-
works have been successful, although simpler
functions have been proposed for short phrases
(Mitchell and Lapata, 2008).
Recursive neural networks have achieved
state-of-the-art performance in sentiment anal-
ysis and parsing (Socher et al., 2013c; Hermann
and Blunsom, 2013; Socher et al., 2013a). rnns
have not been previously used for learning at-
tribute spaces as we do here, although recursive
tensor networks were unsuccessfully applied to
a knowledge base completion task (Socher et
al., 2013b). More relevant to this work are the
dialogue analysis model proposed by Kalchbren-
ner & Blunsom (2013) and the paragraph vec-
tor model described in Le and Mikolov (2014),
both of which are able to generate distributed
representations of paragraphs. Here we present
a simpler approach where a single model is able
to learn complex sentence representations and
average them across paragraphs.
6.2 Factoid Question-Answering
Factoid question answering is often functionally
equivalent to information retrieval. Given a
knowledge base and a query, the goal is to
Thomas Mann
Joseph Conrad
Henrik Ibsen
Franz Kafka
Henry James
Figure 6: A question on the German novelist
Thomas Mann that contains no named entities,
along with the five top answers as scored by
qanta. Each cell in the heatmap corresponds
to the score (inner product) between a node
in the parse tree and the given answer, and
the dependency parse of the sentence is shown
on the left. All of our baselines, including ir-
wiki, are wrong, while qanta uses the plot
description to make a correct guess.
return the answer. Many approaches to this
problem rely on hand-crafted pattern matching
and answer-type classification to narrow down
the search space (Shen, 2007; Bilotti et al.,
2010; Wang, 2006). More recent factoid qa
systems incorporate the web and social media
into their retrieval systems (Bian et al., 2008).
In contrast to these approaches, we place the
burden of learning answer types and patterns
on the model.
7 Future Work
While we have shown that dt-rnns are effec-
tive models for quiz bowl question answering,
other factoid qa tasks are more challenging.
Questions like what does the aarp stand for?
from trec qa data require additional infras-
tructure. A more apt comparison would be to
IBM?s proprietary Watson system (Lally et al.,
2012) for Jeopardy, which is limited to single
sentences, or to models trained on Yago (Hof-
fart et al., 2013).
We would also like to fairly compare qanta
641
Akbar
Shah Jahan
Muhammad
Babur
Ghana
Figure 7: An extremely misleading question
about John Cabot, at least to computer models.
The words muslim and mecca lead to three
Mughal emperors in the top five guesses from
qanta; other models are similarly led awry.
with ir-wiki. A promising avenue for future
work would be to incorporate Wikipedia data
into qanta by transforming sentences to look
like quiz bowl questions (Wang et al., 2007) and
to select relevant sentences, as not every sen-
tence in a Wikipedia article directly describes
its subject. Syntax-specific annotation (Sayeed
et al., 2012) may help in this regard.
Finally, we could adapt the attribute space
learned by the dt-rnn to use information from
knowledge bases and to aid in knowledge base
completion. Having learned many facts about
entities that occur in question text, a dt-rnn
could add new facts to a knowledge base or
check existing relationships.
8 Conclusion
We present qanta, a dependency-tree recursive
neural network for factoid question answering
that outperforms bag of words and informa-
tion retrieval baselines. Our model improves
upon a contrastive max-margin objective func-
tion from previous work to dynamically update
answer vectors during training with a single
model. Finally, we show that sentence-level
representations can be easily and effectively
combined to generate paragraph-level represen-
Q he also successfully represented the amistad
slaves and negotiated the treaty of ghent and
the annexation of florida from spain during his
stint as secretary of state under james monroe
A john quincy adams, henry clay, andrew jack-
son
Q this work refers to people who fell on their
knees in hopeless cathedrals and who jumped
off the brooklyn bridge
A howl, the tempest, paradise lost
Q despite the fact that twenty six martyrs were
crucified here in the late sixteenth century it
remained the center of christianity in its coun-
try
A nagasaki, guadalcanal, ethiopia
Q this novel parodies freudianism in a chapter
about the protagonist ?s dream of holding a
live fish in his hands
A
billy budd, the ambassadors, all my sons
Q a contemporary of elizabeth i he came to power
two years before her and died two years later
A
grover cleveland, benjamin harrison, henry
cabot lodge
Table 2: Five example sentences occuring at
the first sentence position along with their top
three answers as scored by qanta; correct an-
swers are marked with blue and wrong answers
are marked with red. qanta gets the first
three correct, unlike all other baselines. The
last two questions are too difficult for all of
our models, requiring external knowledge (e.g.,
Freudianism) and temporal reasoning.
tations with more predictive power than those
of the individual sentences.
Acknowledgments
We thank the anonymous reviewers, Stephanie
Hwa, Bert Huang, and He He for their insight-
ful comments. We thank Sharad Vikram, R.
Hentzel, and the members of naqt for pro-
viding our data. This work was supported by
nsf Grant IIS-1320538. Boyd-Graber is also
supported by nsf Grant CCF-1018625. Any
opinions, findings, conclusions, or recommen-
dations expressed here are those of the authors
and do not necessarily reflect the view of the
sponsor.
642
References
Yoshua Bengio, Re?jean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. JMLR.
Jiang Bian, Yandong Liu, Eugene Agichtein, and
Hongyuan Zha. 2008. Finding the right facts in
the crowd: factoid question answering over social
media. In WWW.
Matthew W. Bilotti, Jonathan Elsas, Jaime Carbonell,
and Eric Nyberg. 2010. Rank learning for factoid
question answering with linguistic and semantic con-
straints. In CIKM.
Jordan Boyd-Graber, Brianna Satinoff, He He, and
Hal Daume III. 2012. Besting the quiz master:
Crowdsourcing incremental classification games. In
EMNLP.
Marie-Catherine De Marneffe, Bill MacCartney, Christo-
pher D Manning, et al. 2006. Generating typed
dependency parses from phrase structure parses. In
LREC.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. JMLR, 999999:2121?
2159.
Katrin Erk. 2012. Vector space models of word mean-
ing and phrase meaning: A survey. Language and
Linguistics Compass.
Christoph Goller and Andreas Kuchler. 1996. Learning
task-dependent distributed representations by back-
propagation through structure. In Neural Networks,
1996., IEEE International Conference on, volume 1.
Edward Grefenstette, Georgiana Dinu, Yao-Zhong
Zhang, Mehrnoosh Sadrzadeh, and Marco Baroni.
2013. Multi-step regression learning for composi-
tional distributional semantics. CoRR.
Karl Moritz Hermann and Phil Blunsom. 2013. The
Role of Syntax in Vector Space Models of Composi-
tional Semantics. In ACL.
Karl Moritz Hermann, Edward Grefenstette, and Phil
Blunsom. 2013. ?not not bad? is not ?bad?: A
distributional account of negation. Proceedings of the
ACL Workshop on Continuous Vector Space Models
and their Compositionality.
Karl Moritz Hermann, Dipanjan Das, Jason Weston,
and Kuzman Ganchev. 2014. Semantic frame iden-
tification with distributed word representations. In
ACL.
Johannes Hoffart, Fabian M Suchanek, Klaus Berberich,
and Gerhard Weikum. 2013. Yago2: A spatially and
temporally enhanced knowledge base from wikipedia.
Artificial Intelligence, 194:28?61.
Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and
Philip Resnik. 2014. Political ideology detection
using recursive neural networks.
Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
convolutional neural networks for discourse compo-
sitionality. Proceedings of the 2013 Workshop on
Continuous Vector Space Models and their Composi-
tionality.
Adam Lally, John M Prager, Michael C McCord,
BK Boguraev, Siddharth Patwardhan, James Fan,
Paul Fodor, and Jennifer Chu-Carroll. 2012. Ques-
tion analysis: How watson reads a clue. IBM Journal
of Research and Development.
Quoc V Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In ACL.
Mark Palatucci, Dean Pomerleau, Geoffrey E. Hinton,
and Tom M. Mitchell. 2009. Zero-shot learning with
semantic output codes. In NIPS.
P. Pasupat and P. Liang. 2014. Zero-shot entity extrac-
tion from web pages. In ACL.
Asad B Sayeed, Jordan Boyd-Graber, Bryan Rusk, and
Amy Weinberg. 2012. Grammatical structures for
word-level sentiment detection. In NAACL.
Dan Shen. 2007. Using semantic role to improve ques-
tion answering. In EMNLP.
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Semi-Supervised Recursive Autoencoders for Predict-
ing Sentiment Distributions. In EMNLP.
Richard Socher, John Bauer, Christopher D. Manning,
and Andrew Y. Ng. 2013a. Parsing With Composi-
tional Vector Grammars. In ACL.
Richard Socher, Danqi Chen, Christopher D. Manning,
and Andrew Y. Ng. 2013b. Reasoning With Neural
Tensor Networks For Knowledge Base Completion.
In NIPS.
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. 2013c. Recursive deep models for
semantic compositionality over a sentiment treebank.
In EMNLP.
Richard Socher, Quoc V Le, Christopher D Manning,
and Andrew Y Ng. 2014. Grounded compositional
semantics for finding and describing images with
sentences. TACL.
Nicolas Usunier, David Buffoni, and Patrick Gallinari.
2009. Ranking with ordered weighted pairwise clas-
sification. In ICML.
Laurens Van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-sne. JMLR.
Mengqiu Wang, Noah A. Smith, and Teruko Mita-
mura. 2007. What is the Jeopardy model? a quasi-
synchronous grammar for QA. In EMNLP.
643
Mengqiu Wang. 2006. A survey of answer extraction
techniques in factoid question answering. Computa-
tional Linguistics, 1(1).
Jason Weston, Samy Bengio, and Nicolas Usunier. 2011.
Wsabie: Scaling up to large vocabulary image anno-
tation. In IJCAI.
Ainur Yessenalina and Claire Cardie. 2011. Compo-
sitional matrix-space models for sentiment analysis.
In EMNLP.
Fabio Massimo Zanzotto, Ioannis Korkontzelos,
Francesca Fallucchi, and Suresh Manandhar. 2010.
Estimating linear models for compositional distribu-
tional semantics. In COLT.
644
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1342?1352,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
Don?t Until the Final Verb Wait:
Reinforcement Learning for Simultaneous Machine Translation
Alvin C. Grissom II
and Jordan Boyd-Graber
Computer Science
University of Colorado
Boulder, CO
Alvin.Grissom@colorado.edu
Jordan.Boyd.Graber@colorado.edu
He He, John Morgan,
and Hal Daume? III
Computer Science and UMIACS
University of Maryland
College Park, MD
{hhe,jjm,hal}@cs.umd.edu
Abstract
We introduce a reinforcement learning-
based approach to simultaneous ma-
chine translation?producing a trans-
lation while receiving input words?
between languages with drastically dif-
ferent word orders: from verb-final lan-
guages (e.g., German) to verb-medial
languages (English). In traditional ma-
chine translation, a translator must
?wait? for source material to appear be-
fore translation begins. We remove this
bottleneck by predicting the final verb
in advance. We use reinforcement learn-
ing to learn when to trust predictions
about unseen, future portions of the
sentence. We also introduce an evalua-
tion metric to measure expeditiousness
and quality. We show that our new
translation model outperforms batch
and monotone translation strategies.
1 Introduction
We introduce a simultaneous machine transla-
tion (MT) system that predicts unseen verbs
and uses reinforcement learning to learn when
to trust these predictions and when to wait for
more input.
Simultaneous translation is producing a par-
tial translation of a sentence before the input
sentence is complete, and is often used in im-
portant diplomatic settings. One of the first
noted uses of human simultaneous interpreta-
tion was the Nuremberg trials after the Sec-
ond World War. Siegfried Ramler (2009), the
Austrian-American who organized the transla-
tion teams, describes the linguistic predictions
and circumlocutions that translators would use
to achieve a tradeoff between translation la-
tency and accuracy. The audio recording tech-
nology used by those interpreters sowed the
seeds of technology-assisted interpretation at
the United Nations (Gaiba, 1998).
Performing real-time translation is especially
difficult when information that comes early in
the target language (the language you?re trans-
lating to) comes late in the source language (the
language you?re translating from). A common
example is when translating from a verb-final
(sov) language (e.g., German or Japanese) to
a verb-medial (svo) language, (e.g., English).
In the example in Figure 1, for instance, the
main verb of the sentence (in bold) appears
at the end of the German sentence. An of-
fline (or ?batch?) translation system waits until
the end of the sentence before translating any-
thing. While this is a reasonable approach, it
has obvious limitations. Real-time, interactive
scenarios?such as online multilingual video
conferences or diplomatic meetings?require
comprehensible partial interpretations before
a sentence ends. Thus, a significant goal in
interpretation is to make the translation as
expeditious as possible.
We present three components for an sov-to-
svo simultaneous mt system: a reinforcement
learning framework that uses predictions to
create expeditious translations (Section 2), a
system to predict how a sentence will end (e.g.,
predicting the main verb; Section 4), and a met-
ric that balances quality and expeditiousness
(Section 3). We combine these components in
a framework that learns when to begin trans-
lating sections of a sentence (Section 5).
Section 6 combines this framework with a
1342
ich bin mit dem Zug nach Ulm gefahren
I am with the train to Ulm traveled
I (. . . . . . waiting. . . . . . ) traveled by train to Ulm
Figure 1: An example of translating from a
verb-final language to English. The verb, in
bold, appears at the end of the sentence, pre-
venting coherent translations until the final
source word is revealed.
translation system that produces simultaneous
translations. We show that our data-driven
system can successfully predict unseen parts
of the sentence, learn when to trust them, and
outperform strong baselines (Section 7).
While some prior research has approached
the problem of simultaneous translation?we re-
view these systems in more detail in Section 8?
no current model learns when to definitively
begin translating chunks of an incomplete sen-
tence. Finally, in Section 9, we discuss the
limitations of our system: it only uses the most
frequent source language verbs, it only applies
to sentences with a single main verb, and it
uses an idealized translation system. However,
these limitations are not insurmountable; we
describe how a more robust system can be as-
sembled from these components.
2 Decision Process for
Simultaneous Translation
Human interpreters learn strategies for their
profession with experience and practice. As
words in the source language are observed, a
translator?human or machine?must decide
whether and how to translate, while, for cer-
tain language pairs, simultaneously predicting
future words. We would like our system to do
the same. To this end, we model simultaneous
mt as a Markov decision process (mdp) and
use reinforcement learning to effectively com-
bine predicting, waiting, and translating into
a coherent strategy.
2.1 States: What is, what is to come
The state s
t
represents the current view of
the world given that we have seen t words of
a source language sentence.
1
The state con-
tains information both about what is known
and what is predicted based on what is known.
1
We use t to evoke a discrete version of time. We
only allow actions after observing a complete source
word.
To compare the system to a human transla-
tor in a decision-making process, the state is
akin to the translator?s cognitive state. At any
given time, we have knowledge (observations)
and beliefs (predictions) with varying degrees
of certainty: that is, the state contains the re-
vealed words x
1:t
of a sentence; the state also
contains predictions about the remainder of
the sentence: we predict the next word in the
sentence and the final verb.
More formally, we have a prediction at time
t of the next source language word that will
appear, n
(t)
t+1
, and for the final verb, v
(t)
. For
example, given the partial observation ?ich
bin mit dem?, the state might contain a pre-
diction that the next word, n
(t)
t+1
, will be ?Zug?
and that the final verb v
(t)
will be ?gefahren?.
We discuss the mechanics of next-word and
verb prediction further in Section 4; for now,
consider these black boxes which, after observ-
ing every new source word x
t
, make predictions
of future words in the source language. This
representation of the state allows for a richer set
of actions, described below, permitting simul-
taneous translations that outpace the source
language input
2
by predicting the future.
2.2 Actions: What our system can do
Given observed and hypothesized input, our
simultaneous translation system must decide
when to translate them. This is expressed
in the form of four actions: our system can
commit to a partial translation, predict the
next word and use it to update the transla-
tion, predict the verb and use it to update the
translation, or wait for more words.
We discuss each of these actions in turn be-
fore describing how they come together to in-
crementally translate an entire sentence:
Wait Waiting is the simplest action. It pro-
duces no output and allows the system to re-
ceive more input, biding its time, so that when
it does choose to translate, the translation is
based on more information.
Commit Committing produces translation
output: given the observed source sentence,
produce the best translation possible.
2
Throughout, ?input? refers to source language in-
put, and ?output? refers to target language translation.
1343
STOP
C
o
m
m
i
t
 Observation  Observation (prediction)  Observation  Observation 
 Observation 
1. Mit dem Zug 2. Mit dem Zug bin
ich
3. Mit dem Zug bin
ich nach
4. Mit dem Zug bin
 ich nach ? gefahren ...
 Observation (prediction) 
5. Mit dem Zug bin ich
nach Ulm
? gefahren ...
6. Mit dem Zug bin ich
nach Ulm gefahren.
Output: I traveled
by train
Output: I traveled
by train
to Ulm
Output: I traveled 
by train
to Ulm.
S
with the 
train
I am
with the 
train
by train
to Ulm
S
by train
Wait Wait
Predict
S
I traveled
by train
with the 
train
to
C
o
m
m
i
t
Wait
Fixed 
output
Commit
s
t
a
t
e
Figure 2: A simultaneous translation from source (German) to target (English). The agent
chooses to wait until after (3). At this point, it is sufficiently confident to predict the final verb
of the sentence (4). Given this additional information, it can now begin translating the sentence
into English, constraining future translations (5). As the rest of the sentence is revealed, the
system can translate the remainder of the sentence.
Next Word The next word action takes
a prediction of the next source word and pro-
duces an updated translation based on that
prediction, i.e., appending the predicted word
to the source sentence and translating the new
sentence.
Verb Our system can also predict the source
sentence?s final verb (the last word in the sen-
tence). When our system takes the verb ac-
tion, it uses its verb prediction to update the
translation using the prediction, by placing it
at the end of the source sentence.
We can recreate a traditional batch trans-
lation system (interpreted temporally) by a
sequence of wait actions until all input is ob-
served, followed by a commit to the complete
translation. Our system can commit to par-
tial translations if it is confident, but producing
a good translation early in the sentence often
depends on missing information.
2.3 Translation Process
Having described the state, its components,
and the possible actions at a state, we present
the process in its entirety. In Figure 2, after
each German word is received, the system ar-
rives at a new state, which consists of the source
input, target translation so far, and predictions
of the unseen words. The translation system
must then take an action given information
about the current state. The action will result
in receiving and translating more source words,
transitioning the system to the next state. In
the example, for the first few source-language
words, the translator lacks the confidence to
produce any output due to insufficient informa-
tion at the state. However, after State 3, the
state shows high confidence in the predicted
verb ?gefahren?. Combined with the German
input it has observed, the system is sufficiently
confident to act on that prediction to produce
English translation.
2.4 Consensus Translations
Three straightforward actions?commit, next
word, and verb?all produce translations.
These rely black box access to a translation
(discussed in detail in Section 6): that is, given
a source language sentence fragment, the trans-
lation system produces a target language sen-
tence fragment.
Because these actions can happen more than
once in a sentence, we must form a single con-
sensus translation from all of the translations
that we might have seen. If we have only one
translation or if translations are identical, form-
ing the consensus translation is trivial. But
how should we resolve conflicting translations?
Any time our system chooses an action that
1344
produces output, the observed input (plus extra
predictions in the case of next-word or verb),
is passed into the translation system. That
system then produces a complete translation
of its input fragment.
Any new words?i.e., words whose target
index is greater than the length of any previ-
ous translation?are appended to the previous
translation.
3
Table 1 shows an example of
forming these consensus translations.
Now that we have defined how states evolve
based on our system?s actions, we need to know
how to select which actions to take. Eventu-
ally, we will formalize this as a learned policy
(Section 5) that maps from states to actions.
First, however, we need to define a reward that
measures how ?good? an action is.
3 Objective: What is a good
simultaneous translation?
Good simultaneous translations must optimize
two objectives that are often at odds, i.e., pro-
ducing translations that are, in the end, accu-
rate, and producing them in pieces that are
presented expeditiously. While there are exist-
ing automated metrics for assessing translation
quality (Papineni et al., 2002; Banerjee and
Lavie, 2005; Snover et al., 2006), these must
be modified to find the necessary compromise
between translation quality and expeditious-
ness. That is, a good metric for simultaneous
translation must achieve a balance between
translating chunks early and translating accu-
rately. All else being equal, maximizing either
goal in isolation is trivial: for accurate transla-
tions, use a batch system and wait until the
sentence is complete, translating it all at once;
for a maximally expeditious translation, cre-
ate monotone translations, translating each
word as it appears, as in Tillmann et al. (1997)
and Pytlik and Yarowsky (2006). The former
is not simultaneous at all; the latter is mere
word-for-word replacement and results in awk-
ward, often unintelligible translations of distant
language pairs.
Once we have predictions, we have an ex-
panded array of possibilities, however. On one
extreme, we can imagine a psychic translator?
3
Using constrained decoding to enforce consistent
translation prefixes would complicate our method but
is an appealing extension.
one that can completely translate an imagined
sentence after one word is uttered?as an un-
obtainable system. On the other extreme is a
standard batch translator, which waits until
it has access to the utterer?s complete sentence
before translating anything.
Again, we argue that a system can improve
on this by predicting unseen parts of the sen-
tence to find a better tradeoff between these
conflicting goals. However, to evaluate and op-
timize such a system, we must measure where
a system falls on the continuum of accuracy
versus expeditiousness.
Consider partial translations in a two-
dimensional space, with time (quantized by
the number of source words seen) increasing
from left to right on the x axis and the bleu
score (including brevity penalty against the
reference length) on the y axis. At each point
in time, the system may add to the consensus
translation, changing the precision (Figure 3).
Like an roc curve, a good system will be high
and to the left, optimizing the area under the
curve: the ideal system would produce points
as high as possible immediately. A translation
which is, in the end, accurate, but which is less
expeditious, would accrue its score more slowly
but outperform a similarly expeditious system
which nevertheless translates poorly.
An idealized psychic system achieves this,
claiming all of the area under the curve, as it
would have a perfect translation instantly, hav-
ing no need of even waiting for future input.
4
A batch system has only a narrow (but tall)
sliver to the right, since it translates nothing
until all of the words are observed.
Formally, let Q be the score function for a
partial translation, x the sequentially revealed
source words x
1
, x
2
, . . . , x
T
from time step 1 to
T , and y the partial translations y
1
, y
2
, . . . , y
T
,
where T is the length of the source language
input. Each incremental translation y
t
has a
bleu-n score with respect to a reference r. We
apply the usual bleu brevity penalty to all the
incremental translations (initially empty) to
4
One could reasonably argue that this is not ideal:
a fluid conversation requires the prosody and timing
between source and target to match exactly. Thus, a
psychic system would provide too much information
too quickly, making information exchange unnatural.
However, we take the information-centric approach:
more information faster is better.
1345
Pos Input Intermediate Consensus
1
2 Er He
1
He
1
3 Er wurde
gestaltet
It
1
was
2
designed
3
He
1
was
2
designed
3
4 It
1
was
2
designed
3
He
1
was
2
designed
3
5 Er wurde
gestern
renoviert
It
1
was
2
renovated
3
yesterday
4
He
1
was
2
designed
3
yesterday
4
Table 1: How intermediate translations are combined into a consensus translation. Incorrect
translations (e.g., ?he? for an inanimate object in position 3) and incorrect predictions (e.g.,
incorrectly predicting the verb gestaltet in position 5) are kept in the consensus translation.
When no translation is made, the consensus translation remains static.
Er ist zum Laden gegangen
He went to 
the store
He
He to the
He to the store
Psychic
Monotone
He went 
to the 
store
Batch
Policy
Prediction
He
He went
He went to 
the store
He to the 
store went
He went 
to  the
Source Sentence
?
Figure 3: Comparison of lbleu (the area under
the curve given by Equation 1) for an impossi-
ble psychic system, a traditional batch system,
a monotone (German word order) system, and
our prediction-based system. By correctly pre-
dicting the verb ?gegangen? (to go), we achieve
a better overall translation more quickly.
obtain latency-bleu (lbleu),
Q(x,y) =
1
T
?
t
bleu(y
t
, r) (1)
+ T ? bleu(y
T
, r)
The lbleu score is a word-by-word inte-
gral across the input source sentence. As each
source word is observed, the system receives a
reward based on the bleu score of the partial
translation. lbleu, then, represents the sum of
these T rewards at each point in the sentence.
The score of a simultaneous translation is the
sum of the scores of all individual segments
that contribute to the overall translation.
We multiply the final bleu score by T to en-
sure good final translations in learned systems
to compensate for the implicit bias toward low
latency.
5
4 Predicting Verbs and Next
Words
The next and verb actions depend on predic-
tions of the sentence?s next word and final verb;
this section describes our process for predict-
ing verbs and next words given a partial source
language sentence.
The prediction of the next word in the source
language sentence is modeled with a left-to-
right language model. This is (na??vely) anal-
ogous to how a human translator might use
his own ?language model? to guess upcoming
words to gain some speed by completing, for
example, collocations before they are uttered.
We use a simple bigram language model for
next-word prediction. We use Heafield et al.
(2013).
For verb prediction, we use a generative
model that combines the prior probability of
a particular verb v, p(v), with the likelihood
of the source context at time t given that
verb (namely, p(x
1:t
| v)), as estimated by a
smoothed Kneser-Ney language model (Kneser
and Ney, 1995). We use Pauls and Klein
(2011). The prior probability p(v) is estimated
by simple relative frequency estimation. The
context, x
1:t
, consists of all words observed.
We model p(x
1:t
| v) with verb-specific n-gram
language models. The predicted verb v
(t)
at
time t is then:
arg max
v
p(v)
t
?
i=1
p(x
i
| v, x
i?n+1:i?1
) (2)
5
One could replace T with a parameter, ?, to bias
towards different kinds of simultaneous translations. As
? ??, we recover batch translation.
1346
where x
i?n+1:i?1
is the n?1-gram context. To
narrow the search space, we consider only the
100 most frequent final verbs, where a ?final
verb? is defined as the sentence-final sequence
of verbs and particles as detected by a German
part-of-speech tagger (Toutanova et al., 2003).
6
5 Learning a Policy
We have a framework (states and actions) for
simultaneous machine translation and a metric
for assessing simultaneous translations. We
now describe the use of reinforcement learning
to learn a policy, a mapping from states to
actions, to maximize lbleu reward.
We use imitation learning (Abbeel and Ng,
2004; Syed et al., 2008): given an optimal se-
quence of actions, learn a generalized policy
that maps states to actions. This can be viewed
as a cost-sensitive classification (Langford and
Zadrozny, 2005): a state is represented as a fea-
ture vector, the loss corresponds to the quality
of the action, and the output of the classifier is
the action that should be taken in that state.
In this section, we explain each of these com-
ponents: generating an optimal policy, repre-
senting states through features, and learning a
policy that can generalize to new sentences.
5.1 Optimal Policies
Because we will eventually learn policies via
a classifier, we must provide training exam-
ples to our classifier. These training exam-
ples come from an oracle policy pi
?
that
demonstrates the optimal sequence?i.e., with
maximal lbleu score?of actions for each se-
quence. Using dynamic programming, we can
determine such actions for a fixed translation
model.
7
From this oracle policy, we generate
training examples for a supervised classifier.
State s
t
is represented as a tuple of the ob-
served words x
1:t
, predicted verb v
(t)
, and the
predicted word n
(t)
t+1
. We represent the state to
a classifier as a feature vector ?(x
1:t
, n
(t)
t+1
, v
(t)
).
6
This has the obvious disadvantage of ignoring mor-
phology and occasionally creating duplicates of common
verbs that have may be associated with multiple parti-
cles; nevertheless, it provides a straightforward verb to
predict.
7
This is possible for the limited class of consensus
translation schemes discussed in Section 2.4.
5.2 Feature Representation
We want a feature representation that will al-
low a classifier to generalize beyond the specific
examples on which it is trained. We use sev-
eral general classes of features: features that
describe the input, features that describe the
possible translations, and features that describe
the quality of the predictions.
Input We include both a bag of words rep-
resentation of the input sentence as well as
the most recent word and bigram to model
word-specific effects. We also use a feature
that encodes the length of the source sentence.
Prediction We include the identity of the
predicted verb and next word as well as their re-
spective probabilities under the language mod-
els that generate the predictions. If the model
is confident in the prediction, the classifier can
learn to more so trust the predictions.
Translation In addition to the state, we in-
clude features derived from the possible actions
the system might take. This includes a bag of
words representation of the target sentence, the
score of the translation (decreasing the score is
undesirable), the score of the current consen-
sus translation, and the difference between the
current and potential translation scores.
5.3 Policy Learning
Our goal is to learn a classifier that can accu-
rately mimic the oracle?s choices on previously
unseen data. However, at test time, when we
run the learned policy classifier, the learned
policy?s state distribution may deviate from
the optimal policy?s state distribution due to
imperfect imitation, arriving in states not on
the oracle?s path. To address this, we use
searn (Daume? III et al., 2009), an iterative
imitation learning algorithm. We learn from
the optimal policy in the first iteration, as in
standard supervised learning; in the following
iterations, we run an interpolated policy
pi
k+1
= pi
k
+ (1? )pi
?
, (3)
with k as the iteration number and  the mixing
probability. We collect examples by asking
the policy to label states on its path. The
interpolated policy will execute the optimal
action with probability 1?  and the learned
1347
policy?s action with probability . In the first
iteration, we have pi
0
= pi
?
.
Mixing in the learned policy allows the
learned policy to slowly change from the oracle
policy. As it trains on these no-longer-perfect
state trajectories, the state distribution at test
time will be more consistent with the states
used in training.
searn learns the policy by training a cost-
sensitive classifier. Besides providing the opti-
mal action, the oracle must also assign a cost
to an action
C(a
t
,x) ? Q(x, pi
?
(x
t
))?Q(x, a
t
(x
t
)), (4)
where a
t
(x
t
) represents the translation outcome
of taking action a
t
. The cost is the regret of
not taking the optimal action.
6 Translation System
The focus of this work is to show that given an
effective batch translation system and predic-
tions, we can learn a policy that will turn this
into a simultaneous translation system. Thus,
to separate translation errors from policy er-
rors, we perform experiments with a nearly
optimal translation system we call an omni-
scient translator.
More realistic translation systems will nat-
urally lower the objective function, often in
ways that make it difficult to show that we can
effectively predict the verbs in verb-final source
languages. For instance, German to English
translation systems often drop the verb; thus,
predicting a verb that will be ignored by the
translation system will not be effective.
The omniscient translator translates a source
sentence correctly once it has been fed the ap-
propriate source words as input. There are
two edge cases: empty input yields an empty
output, while a complete, correct source sen-
tence returns the correct, complete translation.
Intermediate cases?where the input is either
incomplete or incorrect?require using an align-
ment. The omniscient translator assumes as
input a reference translation r, a partial source
language input x
1:t
and a corresponding partial
output y. In addition, the omniscient transla-
tor assumes access to an alignment between r
and x. In practice, we use the hmm aligner (Vo-
gel et al., 1996; Och and Ney, 2003).
We first consider incomplete but correct in-
puts. Let y = ?(x
1:t
) be the translator?s output
given a partial source input x
1:t
with transla-
tion y. Then, ?(x
1:t
) produces all target words
y
j
if there is a source word x
i
in the input
aligned to those words?i.e., (i, j) ? a
x,y
?and
all preceding target words can be translated.
(That translations must be contiguous is a nat-
ural requirement for human recipients of trans-
lations). In the case where y
j
is unaligned, the
closest aligned target word to y
j
that has a
corresponding alignment entry is aligned to x
i
;
then, if x
i
is present in the input, y
j
appears in
the output. Thus, our omniscient translation
system will always produce the correct output
given the correct input.
However, our learned policy can make wrong
predictions, which can produce partial trans-
lations y that do not match the reference.
In this event, an incorrect source word x?
i
produces incorrect target words y?
j
, for all
j : (i, j) ? a
x,y
. These y?
j
are sampled from
the ibm Model 1 lexical probability table mul-
tiplied by the source language model y?
j
?
Mult(?
x?
i
)p
LM
(x?).
8
Thus, even if we predict
the correct verb using a next word action, it
will be in the wrong position and thus gener-
ate a translation from the lexical probabilities.
Since translations based on Model 1 probabil-
ities are generally inaccurate, the omniscient
translator will do very well when given correct
input but will produce very poor translations
otherwise.
7 Experiments
In this section, we describe our experimental
framework and results from our experiments.
From aligned data, we derive an omniscient
translator. We use monolingual data in the
source language to train the verb predictor and
the next word predictor. From these features,
we compute an optimal policy from which we
train a learned policy.
7.1 Data sets
For translation model and policy training, we
use data from the German-English Parallel ?de-
news? corpus of radio broadcast news (Koehn,
2000), which we lower-cased and stripped of
8
If a policy chooses an incorrect unaligned word, it
has no effect on the output. Alignments are position-
specific, so ?wrong? refers to position and type.
1348
punctuation. A total of 48, 601 sentence pairs
are randomly selected for building our system.
Of these, we use 70% (34, 528 pairs) for training
word alignments.
For training the translation policy, we re-
strict ourselves to sentences that end with one
of the 100 most frequent verbs (see Section 4).
This results in a data set of 4401 training sen-
tences and 1832 test sentences from the de-news
data. We did this to narrow the search space
(from thousands of possible, but mostly very
infrequent, verbs).
We used 1 million words of news text from
the Leipzig Wortschatz (Quasthoff et al., 2006)
German corpus to train 5-gram language mod-
els to predict a verb from the 100 most frequent
verbs.
For next-word prediction, we use the 18, 345
most frequent German bigrams from the train-
ing set to provide a set of candidates in a lan-
guage model trained on the same set. We use
frequent bigrams to reduce the computational
cost of finding the completion probability of
the next word.
7.2 Training Policies
In each iteration of searn, we learn a
multi-class classifier to implement the pol-
icy. The specific learning algorithm we use
is arow (Crammer et al., 2013). In the com-
plete version of searn, the cost of each action
is calculated as the highest expected reward
starting at the current state minus the actual
roll-out reward. However, computing the full
roll-out reward is computationally very expen-
sive. We thus use a surrogate binary cost: if
the predicted action is the same as the opti-
mal action, the cost is 0; otherwise, the cost
is 1. We then run searn for five iterations.
Results on the development data indicate that
continuing for more iterations yields no benefit.
7.3 Policy Rewards on Test Set
In Figure 4, we show performance of the opti-
mal policy vis-a`-vis the learned policy, as well
as the two baseline policies: the batch policy
and the monotone policy. The x-axis is the
percentage of the source sentence seen by the
model, and the y-axis is a smoothed average of
the reward as a function of the percentage of
the sentence revealed. The monotone policy?s
performance is close to the optimal policy for
llllllllll l l l l l l l l
l
0.25
0.50
0.75
1.00
1.25
0.00 0.25 0.50 0.75 1.00% of Sentence
Sm
oo
the
d A
ve
ra
ge
l Batch Monotone Optimal Searn
Figure 4: The final reward of policies on Ger-
man data. Our policy outperforms all baselines
by the end of the sentence.
0
2500
5000
7500
10000
0
2500
5000
7500
10000
0
2500
5000
7500
10000
0
2500
5000
7500
10000
Batch
Monotone
Optimal
Searn
COMMIT WAIT NEXTWORD VERBAction
Ac
tio
n C
ou
nt
Policy Actions
Figure 5: Histogram of actions taken by the
policies.
the first half of the sentence, as German and
English have similar word order, though they
diverge toward the end. Our learned policy
outperforms the monotone policy toward the
end and of course outperforms the batch policy
throughout the sentence.
Figure 5 shows counts of actions taken by
each policy. The batch policy always commits
at the end. The monotone policy commits at
each position. Our learned policy has an ac-
tion distribution similar to that of the optimal
policy, but is slightly more cautious.
7.4 What Policies Do
Figure 6 shows a policy that, predicting incor-
rectly, still produces sensible output. The pol-
icy correctly intuits that the person discussed
1349
VE
R
B
federal minister of the 
environment angela merkel 
shown the draft of an 
ecopolitical program
bundesumweltministerin 
merkel hat den entwurf
bundesumweltministerin
INPUT OUTPUT
federal minister of the 
environment angela merkel
federal minister of the 
environment angela merkel 
shown the draft
Merkel
gezeigt
bundesumweltministerin 
merkel hat den entwurf 
eines umweltpolitischen 
programms vorgestellt
C
O
M
M
I
T
N
E
X
T
Figure 6: An imperfect execution of a learned
policy. Despite choosing the wrong verb
?gezeigt? (showed) instead of ?vorgestellt? (pre-
sented), the translation retains the meaning.
is Angela Merkel, who was the environmen-
tal minister at the time, but the policy uses
an incorrectly predicted verb. Because of our
poor translation model (Section 6), it renders
this word as ?shown?, which is a poor transla-
tion. However, it is still comprehensible, and
the overall policy is similar to what a human
would do: intuit the subject of the sentence
from early clues and use a more general verb
to stand in for a more specific one.
8 Related Work
Just as mt was revolutionized by statistical
learning, we suspect that simultaneous mt will
similarly benefit from this paradigm, both from
a systematic system for simultaneous transla-
tion and from a framework for learning how to
incorporate predictions.
Simultaneous translation has been
dominated by rule and parse-based ap-
proaches (Mima et al., 1998a; Ryu et al., 2006).
In contrast, although Verbmobil (Wahlster,
2000) performs incremental translation using a
statistical mt module, its incremental decision-
making module is rule-based. Other recent
approaches in speech-based systems focus on
waiting until a pause to translate (Sakamoto
et al., 2013) or using word alignments (Ryu
et al., 2012) between languages to determine
optimal translation units.
Unlike our work, which focuses on predic-
tion and learning, previous strategies for deal-
ing with sov-to-svo translation use rule-based
methods (Mima et al., 1998b) (for instance,
passivization) to buy time for the translator to
hear more information in a spoken context?or
use phrase table and reordering probabilities to
decide where to translate with less delay (Fu-
jita et al., 2013). Oda et al. (2014) is the
most similar to our work on the translation
side. They frame word segmentation as an
optimization problem, using a greedy search
and dynamic programming to find segmenta-
tion strategies that maximize an evaluation
measure. However, unlike our work, the direc-
tion of translation was from from svo to svo,
obviating the need for verb prediction. Simul-
taneous translation is more straightforward for
languages with compatible word orders, such
as English and Spanish (Fu?gen, 2008).
To our knowledge, the only attempt to
specifically predict verbs or any late-occurring
terms (Matsubara et al., 2000) uses pattern
matching on what would today be considered
a small data set to predict English verbs for
Japanese to English simultaneous mt.
Incorporating verb predictions into the trans-
lation process is a significant component of
our framework, though n-gram models strongly
prefer highly frequent verbs. Verb prediction
might be improved by applying the insights
from psycholinguistics. Ferreira (2000) argues
that verb lemmas are required early in sentence
production?prior to the first noun phrase
argument?and that multiple possible syntac-
tic hypotheses are maintained in parallel as the
sentence is produced. Schriefers et al. (1998)
argues that, in simple German sentences, non-
initial verbs do not need lemma planning at
all. Momma et al. (2014), investigating these
prior claims, argues that the abstract relation-
ship between the internal arguments and verbs
triggers selective verb planning.
9 Conclusion and Future Work
Creating an effective simultaneous translation
system for sov to svo languages requires not
only translating partial sentences, but also ef-
fectively predicting a sentence?s verb. Both
elements of the system require substantial re-
finement before they are usable in a real-world
system.
Replacing our idealized translation system
is the most challenging and most important
next step. Supporting multiple translation hy-
potheses and incremental decoding (Sankaran
1350
et al., 2010) would improve both the efficiency
and effectiveness of our system. Using data
from human translators (Shimizu et al., 2014)
could also add richer strategies for simultane-
ous translation: passive constructions, reorder-
ing, etc.
Verb prediction also can be substantially im-
proved both in its scope in the system and
how we predict verbs. Verb-final languages
also often place verbs at the end of clauses,
and also predicting these verbs would improve
simultaneous translation, enabling its effective
application to a wider range of sentences. In-
stead predicting an exact verb early (which is
very difficult), predicting a semantically close
or a more general verb might yield interpretable
translations.
A natural next step is expanding this work
to other languages, such as Japanese, which not
only has sov word order but also requires tok-
enization and morphological analysis, perhaps
requiring sub-word prediction.
Acknowledgments
We thank the anonymous reviewers, as well as
Yusuke Miyao, Naho Orita, Doug Oard, and
Sudha Rao for their insightful comments. This
work was supported by NSF Grant IIS-1320538.
Boyd-Graber is also partially supported by
NSF Grant CCF-1018625. Daume? III and He
are also partially supported by NSF Grant IIS-
0964681. Any opinions, findings, conclusions,
or recommendations expressed here are those
of the authors and do not necessarily reflect
the view of the sponsor.
References
Pieter Abbeel and Andrew Y. Ng. 2004. Appren-
ticeship learning via inverse reinforcement learn-
ing. In Proceedings of the International Confer-
ence of Machine Learning.
Satanjeev Banerjee and Alon Lavie. 2005. ME-
TEOR: An automatic metric for MT evalua-
tion with improved correlation with human judg-
ments. In Proceedings of the Association for
Computational Linguistics. Association for Com-
putational Linguistics.
Koby Crammer, Alex Kulesza, and Mark Dredze.
2013. Adaptive regularization of weight vectors.
Machine Learning, 91(2):155?187.
Hal Daume? III, John Langford, and Daniel Marcu.
2009. Search-based structured prediction. Ma-
chine Learning Journal (MLJ).
Fernanda Ferreira. 2000. Syntax in language
production: An approach using tree-adjoining
grammars. Aspects of language production,
pages 291?330.
Christian Fu?gen. 2008. A system for simultane-
ous translation of lectures and speeches. Ph.D.
thesis, KIT-Bibliothek.
Tomoki Fujita, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013.
Simple, lexicalized choice of translation timing
for simultaneous speech translation. INTER-
SPEECH.
Francesca Gaiba. 1998. The origins of simultane-
ous interpretation: The Nuremberg Trial. Uni-
versity of Ottawa Press.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable
modified Kneser-Ney language model estima-
tion. In Proceedings of the Association for Com-
putational Linguistics.
Reinhard Kneser and Hermann Ney. 1995. Im-
proved backing-off for n-gram language model-
ing. In Acoustics, Speech, and Signal Processing,
1995. ICASSP-95., 1995 International Confer-
ence on. IEEE.
Philipp Koehn. 2000. German-english parallel cor-
pus ?de-news?.
John Langford and Bianca Zadrozny. 2005. Relat-
ing reinforcement learning performance to clas-
sification performance. In Proceedings of the In-
ternational Conference of Machine Learning.
Shigeki Matsubara, Keiichi Iwashima, Nobuo
Kawaguchi, Katsuhiko Toyama, and Yasuyoshi
Inagaki. 2000. Simultaneous Japanese-English
interpretation based on early predition of En-
glish verb. In Symposium on Natural Language
Processing.
Hideki Mima, Hitoshi Iida, and Osamu Furuse.
1998a. Simultaneous interpretation utilizing
example-based incremental transfer. In Pro-
ceedings of the 17th international conference on
Computational linguistics-Volume 2, pages 855?
861. Association for Computational Linguistics.
Hideki Mima, Hitoshi Iida, and Osamu Furuse.
1998b. Simultaneous interpretation utilizing
example-based incremental transfer. In Proceed-
ings of the Association for Computational Lin-
guistics.
Shota Momma, Robert Slevc, and Colin Phillips.
2014. The timing of verb selection in english
active and passive sentences.
1351
Franz Josef Och and Hermann Ney. 2003. A
systematic comparison of various statistical
alignment models. Computational Linguistics,
29(1):19?51.
Yusuke Oda, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2014. Op-
timizing segmentation strategies for simultane-
ous speech translation. In Proceedings of the As-
sociation for Computational Linguistics, June.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the Association for Computational
Linguistics.
Adam Pauls and Dan Klein. 2011. Faster and
smaller n-gram language models. In Proceed-
ings of the Association for Computational Lin-
guistics.
Brock Pytlik and David Yarowsky. 2006. Machine
translation for languages lacking bitext via mul-
tilingual gloss transduction. In 5th Conference
of the Association for Machine Translation in
the Americas (AMTA), August.
Uwe Quasthoff, Matthias Richter, and Christian
Biemann. 2006. Corpus portal for search in
monolingual corpora. In International Language
Resources and Evaluation, pages 1799?1802.
Siegfried Ramler and Paul Berry. 2009. Nuremberg
and Beyond: The Memoirs of Siegfried Ramler
from 20th Century Europe to Hawai?i. Booklines
Hawaii Limited.
Koichiro Ryu, Shigeki Matsubara, and Yasuyoshi
Inagaki. 2006. Simultaneous english-japanese
spoken language translation based on incremen-
tal dependency parsing and transfer. In Proceed-
ings of the Association for Computational Lin-
guistics.
Koichiro Ryu, Shigeki Matsubara, and Yasuyoshi
Inagaki. 2012. Alignment-based translation
unit for simultaneous japanese-english spoken di-
alogue translation. In Innovations in Intelligent
Machines?2, pages 33?44. Springer.
Akiko Sakamoto, Nayuko Watanabe, Satoshi Ka-
matani, and Kazuo Sumita. 2013. Development
of a simultaneous interpretation system for face-
to-face services and its evaluation experiment in
real situation.
Baskaran Sankaran, Ajeet Grewal, and Anoop
Sarkar. 2010. Incremental decoding for phrase-
based statistical machine translation. In Pro-
ceedings of the Joint Fifth Workshop on Statis-
tical Machine Translation.
H Schriefers, E Teruel, and RM Meinshausen.
1998. Producing simple sentences: Results from
picture?word interference experiments. Journal
of Memory and Language, 39(4):609?632.
Hiroaki Shimizu, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2014.
Collection of a simultaneous translation corpus
for comparative analysis. In International Lan-
guage Resources and Evaluation.
Matthew Snover, Bonnie Dorr, Richard Schwartz,
Linnea Micciulla, and John Makhoul. 2006. A
study of translation edit rate with targeted hu-
man annotation. In In Proceedings of Associa-
tion for Machine Translation in the Americas.
Umar Syed, Michael Bowling, and Robert E.
Schapire. 2008. Apprenticeship learning using
linear programming. In Proceedings of the Inter-
national Conference of Machine Learning.
Christoph Tillmann, Stephan Vogel, Hermann Ney,
and Alex Zubiaga. 1997. A dp-based search us-
ing monotone alignments in statistical transla-
tion. In Proceedings of the Association for Com-
putational Linguistics.
Kristina Toutanova, Dan Klein, Christopher D
Manning, and Yoram Singer. 2003. Feature-rich
part-of-speech tagging with a cyclic dependency
network. In Conference of the North American
Chapter of the Association for Computational
Linguistics, pages 173?180.
Stephan Vogel, Hermann Ney, and Christoph Till-
mann. 1996. HMM-based word alignment in
statistical translation. In Proceedings of the 16th
International Conference on Computational Lin-
guistics (COLING).
Wolfgang Wahlster. 2000. Verbmobil: foundations
of speech-to-speech translation. Springer.
1352
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 655?663,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
?I Object!? Modeling Latent Pragmatic Effects in Courtroom Dialogues
Dan Goldwasser
University of Maryland
Institute for Advanced Computer Studies
College Park, MD , USA
goldwas1@umiacs.edu
Hal Daum
?
e III
Department of Computer Science
University of Maryland
College Park, MD , USA
hal@cs.umd.edu
Abstract
Understanding the actionable outcomes of
a dialogue requires effectively modeling
situational roles of dialogue participants,
the structure of the dialogue and the rele-
vance of each utterance to an eventual ac-
tion. We develop a latent-variable model
that can capture these notions and apply
it in the context of courtroom dialogues,
in which the objection speech act is used
as binary supervision to drive the learning
process. We demonstrate quantitatively
and qualitatively that our model is able to
uncover natural discourse structure from
this distant supervision.
1 Introduction
Many dialogues lead to decisions and actions. The
participants in such dialogues each come with
their own goals and agendas, their own perspec-
tives on dialogue topics, and their own ways of
interacting with others. Understanding the action-
able results of a dialogue requires accurately mod-
eling both the content of dialogue utterances, as
well as the relevant features of its participants.
In this work, we devise a discriminative latent
variable model that is able to capture the overall
structure of a dialogue as relevant to specific acts
that occur as a result of that dialogue. We aim to
model both the relevance of preceding dialogue to
particular action, as well as a binary structured re-
lationship among utterances, while taking into ac-
count the pragmatic effect introduced by the dif-
ferent speakers? perspectives.
We focus on a particular domain of dialogue:
courtroom transcripts. This domain has the advan-
tage that while its range of topics can be broad, the
roles of participants are relatively well-defined.
Courtroom dialogues also contain a specialized
speech act: the objection.
In real court settings (as opposed to fictional-
ized courts), an objection is a decision made by the
party opposing the side holding the floor, to inter-
rupt the flow of the courtroom discussion. While
motivation behind taking this decision can stem
from different reasons, it is typically an indication
that a particular pragmatic rule has been broken.
The key insight is that objections are sustained
when a nuanced rule of court is being violated: for
instance, the argumentative objection is ?raised in
response to a question which prompts a witness to
draw inferences from facts of the case?
1
, as op-
posed to the witness stating concrete facts.
The objectionable aspects of the preceding di-
alogue can be identified by a well-trained person;
however these aspects are quite subtle to a com-
putational model. In this work we take a first step
toward addressing this problem computationally,
and focus on identifying the key properties of dia-
logue interactions relevant for learning to identify
and classify courtroom objections.
Our technical goal is to drive latent learning of
dialogue structure based on a combination of raw
input and pragmatic binary supervision. The bi-
nary supervision we use is derived from objection
speech acts appearing in the dialogue (described
in Section 2.1).
We are primarily interested in constructing a
representation suitable for learning the challeng-
ing task of identifying objections in courtroom
proceedings (Figure 1 provides an example).
In order to make classifications reliably, a
deeper representation of the dialogue is required.
1
Source: Wikipedia, July 2011, http://en.wikipedia.
org/wiki/Argumentative.
655
MR. COCHRAN Attorney  Defense 
Det. LANGE Witness  Prosecution  SPEA
KER  
SPEAKER  
DIALOGUE RELATION  
And then she filed the case, right?  
DETECTIVE LANGE  That?s correct 
MR. COCHRAN  And before you submitted this case you had heard or seen Miss Clarke on Television saying this was a sole murderer case; isn?t that correct? you had heard that, hadn?t you?  
MS. CLARKE  Objection your honor.  
THE COURT  Hearsay. Sustained  
2 
RELEVANCE 
1 
MR. COCHRAN 
Label 
Dialogue Input  
1 
1 
Figure 1: Moving from raw text to a meaningful rep-
resentation. The raw textual representation hides complex
interactions, relevant for understanding the dialogue flow and
making decisions over it. We break the text into dialogue
turns, each associated with a speaker, explicitly annotated
with their role and side in the court case. Judgements of the
relevance of each dialogue component for the classification
task, produce a more accurate representation of the dialogue
which is easier to learn. These judgments can be over indi-
vidual sentences ( 1 ) or over pairs of sentences across dif-
ferent turns ( 2 ), which represent relevant information flow.
The parameters required for making these judgements are ob-
tained via interaction with the learning process. We explain
these consideration and the construction stages in Section 2.
Our model makes use of three conceptually differ-
ent components capturing linguistic and pragmatic
considerations and their relevance in the context of
the dialogue structure.
Our linguistic model focuses on enriching a
lexical representation of the dialogue utterances
using linguistic resources capturing biased lan-
guage use, such as subjective speech, expressions
of sentiment, intensifiers and hedges. For exam-
ple, the phrase ?So he was driving negligently??
is an argumentative expression, as it requires the
witness to draw inferences, rather than describe
facts. Identifying the use of biased language in this
phrase can help capture this objectionable aspect.
In addition, we use a named entity recognizer, as
we observe that relevant entity mentions provide
a good indication of the dialogue focus. We refer
the reader to Section 2.2 for further explanations.
The surface representation of dialogue turns
hides the complex interactions between its partici-
pants. These interactions are driven by their agen-
das and roles in the trial. Understanding the lexical
cues in this context requires situating the dialogue
in the context of the court case. We condition the
lexical representation of a turn on its speaker, the
speaker?s role and side in the trial, thus allowing
the model to capture the relevant pragmatic influ-
ences introduced by the different speakers.
Next, a discriminative latent variable model
learns a structured representation of the dia-
logue that is useful in making high-level seman-
Notation Explanation
x Input dialogue
x
Sit
Situated dialogue
h Latent structure variables
t Dialogue turn
t.speaker.{name,role,side} Speaker information
t.text Text in a dialogue turn
t.s
i
.{text,type,subj,entities} Sentence level information
Table 1: Notation Summary
tic/pragmatic predictions (section 2.3). The latent
variable model consists of two types of variables.
The first type of latent variable aims to identify
content relevant for the objection identification de-
cision. To this end, it determines the relevance of
individual sentences to the classification decision,
based on properties such as the lexical items ap-
pearing in the sentence, the sentence type, and ex-
pressions of subjectivity. The second latent vari-
able type focuses on the information flow between
speakers. It identifies relevant dialogue relations
between turns. This decision is made by construct-
ing a joint representation of two sentences, across
different dialogue turns, capturing responses to
questions and joining lexical items appearing in
factual sentences across different turns.
Both dialogue aspects are formalized as latent
variables, trained jointly with the final classifica-
tion task using automatically extracted supervi-
sion. In Sec. 3 we describe the learning process.
We evaluate our approach over short dialogue
snippets extracted from the O.J. Simpson murder
trial. Our experiments evaluate the contribution of
the different aspects of our system, showing that
the dialogue representation determined by our la-
tent model results in considerable improvements.
Our evaluation process considers several differ-
ent views of the extracted data. Interestingly, de-
spite the formal definitions of objections, the ma-
jority of objections are raised without justification
(and are subsequently overruled), typically for the
purpose of interrupting the opposing side when
controversial topics are touched upon. Our exper-
iments analyze the differences between sustained
and overruled objections and show that sustained
objections are easier to detect. We describe our
experiments in section 4.
2 Dialogue Structure Modeling
Making predictions in such a complex domain re-
quires a rich representation, capturing the interac-
tions between different participants, the tone of
656
conversation, understanding of controversial is-
sues presented during the trial, and their different
interpretations by either side in the trial. Obtaining
this information manually is a labor intensive task,
furthermore, its subjective nature allows for many
different interpretations of the interactions leading
to the objection.
Our approach, therefore, tries to avoid this diffi-
culty by using a data-driven approach to learn the
correct representation for the input, jointly with
learning to classify correctly. Our representation
transforms the raw input, dialogue snippets ex-
tracted automatically from court proceedings, into
meaningful interactions between dialogue partic-
ipants using a set of variables to determine the
relevant parts of the dialogue and the relations
between them. We inform these decisions using
generic resources providing linguistic knowledge
and pragmatic information, situating the dialogue
in the context of the trial.
In this section we explain this process, starting
from the automatic process of extracting examples
(Section 2.1), the linguistic knowledge resources
and pragmatic information used (Section 2.2), we
summarize the notation used to describe the dia-
logue and its properties in Table 1. We formulate
the inference process, identifying the meaning-
ful interactions for prediction as an Integer Linear
Programming (ILP) optimization problem (Sec-
tion 2.3). The objective function used when solv-
ing this optimization problem is learned from data,
by treating these decisions as latent variables dur-
ing learning. We explain the learning process and
its interaction with inference in Section 3.
2.1 Mining Courtroom Proceedings
The first step in forming our dataset consists of
collecting a large set of relevant courtroom dia-
logue snippets. First, we look for textual occur-
rences of objections in the trial transcript by look-
ing for sustain or overrule word lemma patterns,
attributed to the judge. We treat the judge ruling
turn and the one preceding it as sources of super-
vision, from which an indication of an objection,
its type and sustained/overruled ruling, can be ex-
tracted.
2
We treat the preceding dialogue as the cause for
the objection, which could appear in any of the
previous turns (or sequence of several turns inter-
vening).We consider the previous n=6 turns as the
2
In 4 we provide details about the extracted dataset and its
distribution according to types.
context potentially relevant for the decision and let
the latent variable model learn which aspects of
the context are actually relevant.
2.2 Linguistic and Pragmatic Information
Objection decisions often rely on semantic and
pragmatic patterns which are not explicitly en-
coded. Rather than annotating these manually, we
use generic resources to enrich our representation.
We make a conceptual distinction between two
types of resources. The first, an array of linguis-
tic resources, which provides us an indication of
structure, topics of controversy, and the sentiment
and tone of language used in the dialogue.
The second captures pragmatic considerations
by situating the dialogue utterances in the context
of the courtroom. Each utterance is attributed to
a speaker, thus capturing meaningful patterns spe-
cific to individual speakers.
Linguistic Resources (1) Named Entities pro-
vide strong indications of the topics discussed in
the dialogue and help uncover relevant utterances,
such as ones making claims associating individu-
als with locations. We use the Named Entity Rec-
ognizer (NER) described in (Finkel et al., 2005) to
identify this information.
(2) Subjective and Biased Language Equally im-
portant to understanding the topics of conversation
is the way they are discussed. Expressions of sub-
jectivity and sentiment are useful linguistic tools
for changing the tone of the dialogue and are likely
to attract opposition. We use several resources
to capture this information. We use a lexicon of
subjective and positive/negative sentiment expres-
sions (Riloff and Wiebe, 2003). This resource can
help identify subjective statements attempting to
bias the discussion (e.g., ?So he was driving neg-
ligently??)
We use a list of hedges and boosters (Hyland,
2005). This resource can potentially allow the
model to identify evasive (?I might have seen
him?) and (overly) confident responses (?I am ab-
solutely sure that I have seen him?).
We use a lexicon of biased language provided
by (Recasens et al., 2013), this lexicon extracted
from Wikipedia edits consists of words indicative
of bias, for example in an attempt to frame the
facts raised in the discussion according to one of
the viewpoints (?The death of Nicolle Simposon?
vs. ?The murder of Nicolle Simposon?).
Finally we use a Patient Polarity Verbs lexi-
con (Goyal et al., 2010). This lexicon consists
657
of verbs in which the agent performs an action
with a positive (?He donated money to the foun-
dation?) or negative (?He stole money from the
foundation?) consequence to the patient.
(3) Sentence Segmentation Many turns discuss
multiple topics, some more relevant than others.
In order to accommodate a finer-grained analysis,
we segment each turn into its sentences. Each sen-
tence is associated with a label, taken from a small
set of generic labels. Labels include FORMALITY (e.g.,
a witness being sworn in), QUESTION, RESPONSE (which
could be either POSITIVE or NEGATIVE) and a general
STATEMENT
3
.
Capturing Pragmatic Effects We observe that
in the context of a courtroom discussion, utterance
interpretation (and subsequent dialogue actions) is
conditioned to a large extent on the speaker?s mo-
tivation and goals rather than in isolation. We cap-
ture this information by explicitly associating rele-
vant characteristics of the speakers involved in the
dialogue with their utterances. We use the list of
actors which appear in the trial transcripts, and as-
sociate each turn with a speaker, their role in the
trial and the side they represent. We augment the
lexical turn representation with this information
(see Sec. 2.3.4).
2.3 Identifying Relevant Interactions using
Constrained Optimization
In this section we take the next step towards a
meaningful representation by trying to identify di-
alogue content and information flow relevant for
objection identification. Since this information
is not pre-annotated, we allow it to be learned
as latent variables. These latent variables act as
boolean indicator variables, which determine how
each dialogue input example will be represented.
This process consists of two conceptual stages,
corresponding to two types of boolean variables:
(1) relevant utterances are identified; (2) mean-
ingful connections between them, across dialogue
turns, are identified. This information is exempli-
fied as 1 and 2 in Figure 1. These decisions
are taken jointly by formalizing this process as an
optimization problem over the space of possible
binary relations between dialogue turns and sen-
tences.
3
Determined by lexical information (question marks,
dis/agreement indications and sentence length)
2.3.1 Relevance Decisions
Our raw representation allows as many as six pre-
vious turns to be relevant to the classification de-
cision, however not all turns are indeed relevant,
and even relevant turns may consist only of a
handful of relevant sentences. Given a dialogue
consisting of (t
1
, .., t
n
) turns, each consisting of
(t
i
.s
1
, .., t
i
.s
k
) sentences, we associate with each
sentence.
? Relevance variables, denoted by h
r
i,j
, indi-
cating the relevance of the j-th sentence in the
i-th turn, for the classification decision.
? Irrelevance variables, denoted by h
i
i,j
, indi-
cating that the j-th sentence in the i-th turn is
not relevant for the classification decision.
? Variable pair activation constraints Given
a sentence the activation of these variables
should be mutually exclusive. We encode this
fact by constraining the decision with a linear
constraint.
?i, j, h
r
i,j
+ h
i
i,j
= 1 (1)
2.3.2 Dialogue Structure Decisions
In many cases the information required to make
the classification is not contained in a single dia-
logue turn, but rather is the product of the infor-
mation flow between dialogue participants. Given
a dialogue consisting of (t
1
, .., t
n
) turns, each con-
sisting of (t
i
.s
1
, .., t
i
.s
k
) sentences, we associate
with every two sentences, s
j
? t
i
, s
k
? t
l
, such
that (i 6= l):
? Sentences-Connected variables, denoted by
h
c
(i,j),(k,l)
, indicating that the combination of
the two sentences is relevant for the classifi-
cation decision.
? Sentences-not-Connected variables, de-
noted by h
n
(i,j),(k,l)
, indicating that the
combination of the two sentences is not
relevant for the classification decision.
? Variable pair activation constraints Given
a sentence pair the activation of these vari-
ables should be mutually exclusive. We en-
code this fact by constraining the decision
with a linear constraint.
?i, j, k, l h
c
(i,j),(k,l)
+ h
n
(i,j),(k,l)
= 1 (2)
658
? Decision Consistency constraints Given a
sentence pair, the activation of the variable
indicating the relevance of the sentence pair
entails the activation of the variables indicat-
ing the relevance of the individual sentences.
?i, j, k, l, (h
c
(i,j),(k,l)
) =? (h
r
i,j
? h
r
k,l
)
(3)
2.3.3 Overall Optimization Function
The boolean variables described in the previous
section define a space of competing dialogue rep-
resentations, each representation considers differ-
ent parts of the dialogue as relevant for the objec-
tion classification decision. When making this de-
cision a single representation is selected, by quan-
tifying the decisions and looking for the optimal
set of decisions maximizing the overall sum of de-
cision scores. We construct this objective function
by associating each decision with a feature vector,
obtained using a feature function ? (described in
Section 2.3.4), mapping the relevant part of the in-
put to a feature set.
More formally, given an input x, we denote the
space of all possible dialogue entities (i.e., sen-
tences and sentence pairs) as ?(x). Assuming that
?(x) is of size N , we denote latent representation
decisions as h ? {0, 1}
N
, a set of indicator vari-
ables, that selects a subset of the possible dialogue
entities that constitute the dialogue representation.
For a given dialogue input x and a dialog entity
s ? ?(x), we denote ?
s
(x) as the feature vector
of s. Given a fixed weight vector w that scores
intermediate representations for the final classifi-
cation task, our decision function (for predicting
?objectionable or not?) becomes:
f
w
(x) = max
h
?
s
h
s
w
T
?
s
(x)
subject to (1)-(3); ?s;h
s
? {0, 1}(4)
In our experiments, we formalize Eq. (4) as an
ILP instance, which we solve using the highly op-
timized Gurobi toolkit
4
.
2.3.4 Features
In this section we describe the features used in
each of the different decision types.
Relevance (h
r
) :
Bag-of-words: {(w, t.speaker. ?
5
)|?w ? t.s.text}
4
http://www.gurobi.com/
5
?
*
? denotes all properties
Biased-Language:{(w, resourceContains(w), t.speaker.?)
|?w ? t.s.text}
6
Irrelevance (h
i
) :
SentType: (t.s.type)
ContainsNamedEntity (t.s.entities 6= ?)
Sentences-(not)-Connected (h
c
,h
n
) :
SentTypes: (t
i
.s
j
.type, t
k
.s
l
.type)
QA pair: (t
i
.s
j
.type = Question) ? (t
k
.s
l
.type =
Response)
? {qa|?w ? t
i
.s
j
.text, qa = (w, t
k
.s
l
.type)}
FactPair: (t
i
.s
j
.type = Statement) ? (t
k
.s
l
.type =
Statement)
? {qa|?w ? t
i
.s
j
.text, qa = (w, t
k
.s
l
.type)}
SpeakerPair: (t
i
.speaker.?, t
k
.speaker.?)
3 Learning and Inference
Unlike the traditional classification settings, in
which learning is done over a fixed representation
of the input, we define the learning process over
a set of latent variables. The process of choos-
ing a good representation is formalized as an op-
timization problem that selects the elements and
associated features that best contribute to success-
ful classification. In the rest of this section we ex-
plain the learning process for the parameters of the
model needed both for the representation decision
and the final classification decision.
3.1 Learning
Similar to the traditional formalization of support
vector machines (Boser et al., 1992), learning is
formulated as the following margin-based opti-
mization problem, where ? is a regularization pa-
rameter, and ` is the squared-hinge loss function:
min
w
?
2
?w?
2
+
?
i
` (?y
i
f
w
(x
i
)) (5)
Unlike standard support vector machines, our de-
cision function f
w
(x
i
) is defined over a set of la-
tent variables. We substitute Eq. (4) into Eq.(5),
and obtain the following formulation for a latent
structure classifier:
min
w
?
2
?w?
2
+
?
i
`
?
?
?y
i
max
h?C
w
T
?
s??(x)
h
s
?
s
(x
i
)
?
?
(6)
6
refers to all linguistic resources used. We also included a
+/-1 word window around words appearing in these resources
659
This formulation is not a convex optimization
problem and care must be taken to find a good op-
timum. In our experiments, we use the algorithm
presented in (Chang et al., 2010) to solve this
problem. The algorithm solves this non-convex
optimization function iteratively, decreasing the
value of the objective in each iteration until con-
vergence. In each iteration, the algorithm deter-
mines the values of the latent variables of positive
examples, and optimizes the modified objective
function using a cutting plane algorithm. This al-
gorithmic approach is conceptually (and algorith-
mically) related to the algorithm suggested by (Yu
and Joachims, 2009).
As standard, we classify x as positive iff
f
w
(x) ? 0. In Eq. (4), w
T
?
s
(x) is the score
associated with the substructure s, and f
w
(x) is
the score for the entire intermediate representa-
tion. Therefore, our decision function f
w
(x) ? 0
makes use of the intermediate representation and
its score to classify the input.
4 Empirical Study
Our experiments were designed with two objec-
tives in mind. Since this work is the first to tackle
the challenging task of objection prediction, we
are interested in understanding the scope and fea-
sibility of finding learning-based solutions.
Our second goal is to examine the individual as-
pects of our model and how they impact the over-
all decision and the latent structure it imposes. In
particular, we are interested in understanding the
effect that modeling the situated context (pragmat-
ics) of the dialogue has on objection prediction.
4.1 Experimental Setup
Evaluated Systems In order to understand the
different components of our system, we construct
several variations, which differ according to the re-
sources used during learning (see Section 2.2 for
details), and the latent variable formulation used
(see Section 2.3). We compare our latent model
with and without using pragmatic information (de-
noted DIAL(x
Sit
) and DIAL(x), respectively). We also
compare two baseline systems, which do not use
the latent variable formulation, these systems are
trained, using linear SVM, directly over all the fea-
tures activated by the h
r
decisions for all the turns
in the dialogue. Again, we consider two varia-
tions, with and without pragmatic information (de-
noted ALL(x
Sit
) and ALL(x), respectively).
4.2 Datasets
Our dataset consists of dialogue snippets collected
from the transcripts of the famous O.J. Simpson
murder trial
7
, collected between January of 1995
to September of that year. We also extracted from
the same resource a list of all trial participants,
their roles in the murder case. Section 2.1 de-
scribes the technical details concerned with min-
ing these examples. The collected dataset consists
of 4981 dialogue snippets resulting in an objection
being raised, out of which 2153 were sustained. In
addition, we also mined the trial transcript for neg-
ative examples, collecting 6269 of those examples.
Negative examples are dialogue snippets which do
not result in an objection. To ensure fair evalua-
tion, we mined negative examples from each hear-
ing, proportionally to the number of positive ex-
amples identified in the same hearing. These ex-
amples were mined randomly, by selecting dia-
logue snippets that were not followed by an ob-
jection in any of the three subsequent turns.
We constructed several datasets, each capturing
different characteristics of courtroom interaction.
All Objections Our first dataset consists of all
the objections (both sustained and overruled). The
objection might not be justified, but the corre-
sponding dialogue either has the characteristics of
a justified objection, or it touches upon points of
controversy. In order to simulate this scenario,
we use all the examples, treating all examples re-
sulting in an objection as positive examples. We
randomly select 20% as test data. We refer to
this dataset as ALLOBJ. In addition, to examine
the different properties of sustained and overruled
objections we create two additional dataset, con-
sisting only of sustained/overruled objections and
negative examples. We denote the dataset con-
sisting only of sustained/overruled objections as
SUSTAINEDOBJ and OVERRULEDOBJ, respectively.
Objections by Type Our final dataset breaks the
objections down by type. Unfortunately, most ob-
jections are not raised with an explanation of their
type. We therefore can only use subsets of the
larger ALLOBJ dataset. We use the occurrences of
each objection type as the test dataset and match it
with negative examples, proportional to the size of
the typed dataset. For training, we use all the pos-
itive examples marked with an UNKNOWN type. The
size of each typed dataset appears in Table 3.
7
http://en.wikipedia.org/wiki/O._J._Simpson_
murder_case
660
Objection Type #Pos/#Neg DIAL(x
Sit
) DIAL(x) ALL(x
Sit
) ALL(x)
CALLS FOR SPECULATION 304 / 364 59.4 58.6 58 58
IRRELEVANT 275 / 330 58.5 58.6 55.2 56.6
LACK OF FOUNDATION 238 / 285 60.6 55 57 52.1
HEARSAY 164 / 196 60.3 57.2 60 55
ARGUMENTATIVE 153 / 183 68.8 65.8 64.8 64.8
FACTS NOT IN EVIDENCE 120 / 144 64.7 65.5 59.8 59.4
LEADING QUESTION 116 / 139 56.7 58.4 56.8 58
Table 3: Accuracy results by objection type. Note that the dataset size varies according to the objection type.
System ALLOBJ OVERRULEDOBJ SUSTAINEDOBJ
ALL(x) 64.9 63.7 66.9
ALL(x
Sit
) 65.1 63.7 67.9
DIAL(x) 65.4 65.1 66.7
DIAL(x
Sit
) 69.1 66.3 70.2
Table 2: Overall Accuracy results. Results show consider-
able improvement when using our latent learning framework
with pragmatic information.
4.3 Empirical Analysis
Overall results We begin our discussion with
the experiments conducted over the three larger
datasets (ALLOBJ, SUSTAINEDOBJ, OVERRULEDOBJ). Table 2
summarizes the results obtained by the different
variations of our systems over these datasets.
The most striking observation emerging from
these results is the combined contribution of cap-
turing relevant dialogue content and interaction
(using latent variables), combined with pragmatic
information. For example in the ALLOBJ, when used
in conjunction, their joint contribution pushed per-
formance to 69.1 accuracy, a considerable im-
provement over using each one in isolation - 65.1
for the deterministic system using pragmatic infor-
mation, and 65.4 of the latent-variable formulation
which does not use this information. These results
are consistent in all of our experiments.
We also observe that sustained objections are
easier to predict than overruled objections. This
is not surprising since objections raised for unjus-
tified reasons are harder to detect.
Pragmatic Considerations Pragmatic informa-
tion in our system is modeled by using the x
Sit
representation, which conditions all decisions on
the speaker identity and role. The results in Ta-
ble 2 show that this information typically results
in better quality predictions.
An interesting side effect of using pragmatic
information is its impact on the dialogue struc-
ture predictions learned as latent variables dur-
ing learning. We can quantify the effect by look-
ing at the number of latent variables activated
for each model. When pragmatic information is
used, 5.6 relevance variables are used on average
(per dialogue snipped). In contrast, when prag-
matic information is not used, this number rises to
6.3
8
. In addition, the average number of sentence-
connection variables active when pragmatic infor-
mation is used is 3.44. This number drops to 2.53
when it is not. These scores suggest that infor-
mation about the dialogue pragmatics allows the
model to take advantage of the dialogue structure
at the level of the latent information, focusing the
learner of higher level information, such as the re-
lation between turns, and less on low level, lexi-
cal information. The effect of using the pragmatic
information can be observed qualitatively as ex-
emplified in Figure 2, where the latent decisions,
when pragmatic information is available, construct
a more topically centered representation of the di-
alogue for the classification decision.
Typed Objections The results over the different
objection types are summarized in Table 3. These
results provide some intuition on which of the ob-
jection types are harder to predict, and the contri-
bution of each aspect of our system for that ob-
jection type.
9
We can see that across the objec-
tion types, using latent variables modeling typi-
cally results in a considerable improvement in per-
formance. The most striking example of the im-
portance of using pragmatic information is the LACK
OF FOUNDATION objection type. This objection defini-
tion as ?the evidence lacks testimony as to its au-
thenticity or source.?
10
can explain this fact, as
information about the side in the trial introducing
specific evidence in testimony is very likely to im-
pact the objection decision.
5 Related Work and Discussion
Our work applies latent variable learning to the
problem of uncovering pragmatic effects in court-
8
The average number of sentences per dialogue is 8.6
9
Since these datasets vary in size, their results are neither
directly comparable to each other nor to the results in Table 2.
10
http://en.wikipedia.org/wiki/Foundation_
(evidence)
661
MR. NEUFELD 
MR. NEUFELD  
MS. KESTLER  
 ?  MR. DARDEN  Your Honor, this is hearsay THE COURT   Overruled  MS. KESTLER    I don't recall if there was that day or not.  I know at some point, we had a meeting as to what evidence we had and what was going to be tested and who was going to test it.  
Do you recall being at a meeting with Erin Reilly, Collin Yamauchi and Dennis Fung and Greg Matheson about this case on June 16th?  
I don't recall.  
On the very next day, June 16th, did you participate in another meeting about this case?  
 ?  
Figure 2: Example of the pragmatic effect on latent
dialogue structure. Constructing the latent dialogue struc-
ture over situated text marks unrelated sentences as irrele-
vant, while marking topically related sentences and identi-
fying the connection between the question-answer pair (de-
cisions marked in solid blue lines). When trained without
situated information, the latent output structure marks topi-
cally unrelated sentences as relevant for objection classifica-
tion. Note that in this case all the edge variables are turned
off (marked with dashed red lines).
room dialogues. We adopted the structured latent
variable model defined in (Chang et al., 2010), and
use ILP to solve the structure prediction inference
problem (Roth and Yih, 2007).
Our prediction task, identifying the actionable
result of a dialogue, requires capturing the dia-
logue and discourse relations. While we view
these relations as latent variables in the context
of action prediction, studying these relations in-
dependently has been the focus of significant re-
search efforts, such as discourse relations (Prasad
et al., 2008), rhetorical structure (Marcu, 1997)
and dialogue act modeling (Stolcke et al., 2000).
Fully supervised approaches for learning to pre-
dict dialogue and discourse relations (such as
(Baldridge and Lascarides, 2005)) typically re-
quires heavy supervision and has been applied
only to limited domains.
Moving away from full supervision, the work of
(Golland et al., 2010) uses a game-theoretic model
to explicitly model the roles of dialogue partic-
ipants. In the context of dialogue and situated
language understanding, the work of (Artzi and
Zettlemoyer, 2011) shows how to derive supervi-
sion for dialogue processing from its structure.
Discriminative latent variables models have
seen a surge of interest in recent years, both in the
machine learning community (Yu and Joachims,
2009; Quattoni et al., 2007) as well as various ap-
plication domains such as NLP (T?ackstr?om and
McDonald, 2011) and computer vision (Felzen-
szwalb et al., 2010). In NLP, one of the most well-
known applications of discriminative latent struc-
tured classification is to the Textual Entailment
(TE) task (Chang et al., 2010; Wang and Manning,
2010). The TE task bears some resemblances ours,
as both tasks require making a binary decision
on the basis of a complex input object (i.e., the
history of dialogue, pairs of paragraphs), creating
the need for a learning framework that is flexible
enough to model the complex latent structure that
exists in the input. Another popular application
domain is sentiment analysis (Yessenalina et al.,
2010; T?ackstr?om and McDonald, 2011; Trivedi
and Eisenstein, 2013). The latent variable model
allows the learner to identify finer grained senti-
ment expression than annotated in the data.
A related area of work with different motiva-
tions and different technical approaches has fo-
cused on attempting to understand narrative struc-
ture. For instance, Chambers and Jurafsky (Cham-
bers and Jurafsky, 2008; Chambers and Juraf-
sky, 2009) model narrative flow in the style of
Schankian scripts (Schank and Abelson, 1977).
Their focus is on common sequences of actions,
not specifically related to dialogue. Somewhat
more related is recent work (Goyal et al., 2010)
that aimed to build a computational model of
Lehnert?s Plot Units (Lehnert, 1981) model. That
work focused primarily on actions and not on di-
alogue: in fact, their results showed that the lack
of dialogue understanding was a significant detri-
ment to their ability to model plot structure.
Instead of focusing on actions, like the above
work, we focus on dialogue content and relation-
ships between utterances. Furthermore, unlike
most of the relevant work in NLP, our approach
requires only very lightweight annotation coming
for ?free? in the form of courtroom objections,
and use a latent variable model to provide judge-
ments of relevant linguistic and dialogue relations,
rather than annotating it manually. We enhance
this model using pragmatic information, captur-
ing speakers? identity and role in the dialogue, and
show empirically the relevance of this information
when making predictions.
It is important to recognize that courtroom ob-
jections are not the only actionable result of di-
alogues. Many discussions that occur on online
forums, in social media, and by email result in
measurable real-world outcomes. We have shown
that one particular type of outcome, realized as a
speech-act, can drive dialogue interpretation; the
field is wide open to investigate others.
662
References
Adam Vogel and Christopher Potts and Dan Jurafsky.
2011. Implicatures and Nested Beliefs in Approxi-
mate Decentralized-POMDPs. In EMNLP.
Yoav Artzi and Luke S. Zettlemoyer. 2011. Boot-
strapping semantic parsers from conversations. In
EMNLP.
Jason Baldridge and Alex Lascarides. 2005. Proba-
bilistic head-driven parsing for discourse structure.
In CoNLL.
B. E. Boser, I. M. Guyon, and V. N. Vapnik. 1992.
A training algorithm for optimal margin classifiers.
In Proc. 5th Annu. Workshop on Comput. Learning
Theory, pages 144?152.
Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT, June.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In ACL/IJCNLP, pages 602?610.
Ming-Wei Chang, Dan Goldwasser, Dan Roth, and
Vivek Srikumar. 2010. Discriminative learning over
constrained latent representations. In NAACL.
Pedro F. Felzenszwalb, Ross B. Girshick, David A.
McAllester, and Deva Ramanan. 2010. Object
detection with discriminatively trained part-based
models. IEEE Trans. Pattern Anal. Mach. Intell.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In ACL.
Dave Golland, Percy Liang, and Dan Klein. 2010.
A game-theoretic approach to generating spatial de-
scriptions. In EMNLP.
Amit Goyal, Ellen Riloff, and Hal Daum?e III. 2010.
Automatically producing plot unit representations
for narrative text. In Empirical Methods in Natural
Language Processing (EMNLP).
K. Hyland. 2005. Metadiscourse: Exploring inter-
action in writing. In Continuum, London and New
York.
W. G. Lehnert. 1981. Plot units and narrative summa-
rization. In Cognitive Science.
Daniel Marcu. 1997. The rhetorical parsing of natural
language texts. In ACL.
R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki,
L Robaldo, A. Joshi, and B. Webber. 2008. The
penn discourse treebank 2.0. In LREC.
Ariadna Quattoni, Sybor Wang, L-P Morency, Michael
Collins, and Trevor Darrell. 2007. Hidden condi-
tional random fields. Pattern Analysis and Machine
Intelligence, IEEE Transactions on.
Marta Recasens, Cristian Danescu-Niculescu-Mizil,
and Dan Jurafsky. 2013. Linguistic models for an-
alyzing and detecting biased language. In Proceed-
ings of ACL.
E. Riloff and J. Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In NAACL.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In Lise Getoor and Ben Taskar, editors,
Introduction to Statistical Relational Learning. MIT
Press.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
plans, goals and understanding. In ACL/IJCNLP.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliz-
abeth Shriberg, Rebecca Bates, Daniel Jurafsky,
Paul Taylor, Rachel Martin, Carol Van Ess-Dykema,
and Marie Meteer. 2000. Dialogue act modeling
for automatic tagging and recognition of conversa-
tional speech. COMPUTATIONAL LINGUISTICS,
26:339?373.
Oscar T?ackstr?om and Ryan T. McDonald. 2011. Dis-
covering fine-grained sentiment with latent variable
structured prediction models. In ECIR.
Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse
connectors for latent subjectivity in sentiment anal-
ysis. classification. In NAACL.
Mengqiu Wang and Christopher D. Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question an-
swering. In Proceedings of the 23rd International
Conference on Computational Linguistics (COLING
2010).
Ainur Yessenalina, Yisong Yue, and Claire Cardie.
2010. Multi-level structured models for document-
level sentiment classification. In EMNLP.
C. Yu and T. Joachims. 2009. Learning structural svms
with latent variables. In Proc. of the International
Conference on Machine Learning (ICML).
663
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1123?1133,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
A Unified Model for Soft Linguistic Reordering Constraints
in Statistical Machine Translation
Junhui Li
?
Yuval Marton
?
Philip Resnik
?
Hal Daum
?
e III
?
?
UMIACS, University of Maryland, College Park, MD
{lijunhui, resnik, hal}@umiacs.umd.edu
?
Microsoft Corp., City Center Plaza, Bellevue, WA
yumarton@microsoft.com
Abstract
This paper explores a simple and effec-
tive unified framework for incorporating
soft linguistic reordering constraints into a
hierarchical phrase-based translation sys-
tem: 1) a syntactic reordering model
that explores reorderings for context free
grammar rules; and 2) a semantic re-
ordering model that focuses on the re-
ordering of predicate-argument structures.
We develop novel features based on both
models and use them as soft constraints
to guide the translation process. Ex-
periments on Chinese-English translation
show that the reordering approach can sig-
nificantly improve a state-of-the-art hier-
archical phrase-based translation system.
However, the gain achieved by the seman-
tic reordering model is limited in the pres-
ence of the syntactic reordering model,
and we therefore provide a detailed analy-
sis of the behavior differences between the
two.
1 Introduction
Reordering models in statistical machine transla-
tion (SMT) model the word order difference when
translating from one language to another. The
popular distortion or lexicalized reordering mod-
els in phrase-based SMT make good local pre-
dictions by focusing on reordering on word level,
while the synchronous context free grammars in
hierarchical phrase-based (HPB) translation mod-
els are capable of handling non-local reordering
on the translation phrase level. However, reorder-
ing, especially without any help of external knowl-
edge, remains a great challenge because an ac-
curate reordering is usually beyond these word
level or translation phrase level reordering mod-
els? ability. In addition, often these translation
models fail to respect linguistically-motivated syn-
tax and semantics. As a result, they tend to pro-
duce translations containing both syntactic and se-
mantic reordering confusions. In this paper our
goal is to take advantage of syntactic and seman-
tic parsing to improve translation quality. Rather
than introducing reordering models on either the
word level or the translation phrase level, we pro-
pose a unified approach to modeling reordering on
the linguistic unit level, e.g., syntactic constituents
and semantic roles. The reordering unit falls into
multiple granularities, from single words to more
complex constituents and semantic roles, and of-
ten crosses translation phrases. To show the ef-
fectiveness of our reordering models, we integrate
both syntactic constituent reordering models and
semantic role reordering models into a state-of-
the-art HPB system (Chiang, 2007; Dyer et al,
2010). We further contrast it with a stronger base-
line, already including fine-grained soft syntac-
tic constraint features (Marton and Resnik, 2008;
Chiang et al, 2008). The general ideas, however,
are applicable to other translation models, e.g.,
phrase-based model, as well.
Our syntactic constituent reordering model con-
siders context free grammar (CFG) rules in the
source language and predicts the reordering of
their elements on the target side, using word align-
ment information. Due to the fact that a con-
stituent, especially a long one, usually maps into
multiple discontinuous blocks in the target lan-
guage, there is more than one way to describe the
monotonicity or swapping patterns; we therefore
design two reordering models: one is based on the
leftmost aligned target word and the other based
on the rightmost target word.
While recently there has also been some encour-
aging work on incorporating semantic structure
(or, more specifically, predicate-argument struc-
ture: PAS) reordering in SMT, it is still an open
question whether semantic structure reordering
1123
strongly overlaps with syntactic structure reorder-
ing, since the semantic structure is closely tied to
syntax. To this end, we employ the same reorder-
ing framework as syntactic constituent reordering
and focus on semantic roles in a PAS. We then an-
alyze the differences between the syntactic and se-
mantic features.
The contributions of this paper include the fol-
lowing:
? We introduce novel soft reordering con-
straints, using syntactic constituents or se-
mantic roles, composed over word alignment
information in translation rules used during
decoding time;
? We introduce a unified framework to incor-
porate syntactic and semantic reordering con-
straints;
? We provide a detailed analysis providing in-
sight into why the semantic reordering model
is significantly less effective when syntactic
reordering features are also present.
The rest of the paper is organized as follows.
Section 2 provides an overview of HPB transla-
tion model. Section 3 describes the details of our
unified reordering models. Section 4 gives our ex-
perimental results and Section 5 discusses the be-
havior difference between syntactic constituent re-
ordering and semantic role reordering. Section 6
reviews related work and, finally Section 7 con-
cludes the paper.
2 HPB Translation Model: an Overview
In HPB models (Chiang, 2007), synchronous rules
take the formX ? ??, ?,??, whereX is the non-
terminal symbol, ? and ? are strings of lexical
items and non-terminals in the source and target
side, respectively, and ? indicates the one-to-one
correspondence between non-terminals in ? and ?.
Each such rule is associated with a set of transla-
tion model features {?
i
}, such as phrase transla-
tion probability p (? | ?) and its inverse p (? | ?),
the lexical translation probability p
lex
(? | ?) and
its inverse p
lex
(? | ?), and a rule penalty that af-
fects preference for longer or shorter derivations.
Two other widely used features are a target lan-
guage model feature and a target word penalty.
Given a derivation d, its translation log-
probability is estimated as:
logP (d) ?
?
i
?
i
?
i
(d)
(1)
	 ?
PAS	 ?
A0	 ?(NP)	 ? TMP	 ?(NP)	 ? Pre	 ?(VBD)	 ? A1	 ?(NP)	 ?Applicants	 ?	 ?	 ?	 ?	 ?	 ?yesterday	 ?	 ?	 ?	 ?	 ?	 ?filled	 ?	 ?	 ?	 ?	 ?	 ?the	 ?forms	 ?
Figure 1: Example of predicate-argument struc-
ture.
where ?
i
is the corresponding weight of feature ?
i
.
See (Chiang, 2007) for more details.
3 Unified Linguistic Reordering Models
As mentioned earlier, the linguistic reordering unit
is the syntactic constituent for syntactic reorder-
ing, and the semantic role for semantic reordering.
The syntactic reordering model takes a CFG rule
(e.g., VP ? VP PP PP) and models the reorder-
ing of the constituents on the left hand side by ex-
amining their translation or visit order according
to the target language. For the semantic reorder-
ing model, it takes a PAS and models its reorder-
ing on the target side. Figure 1 shows an example
of a PAS where the predicate (Pre) has two core
arguments (A0 and A1) and one adjunct (TMP).
Note that we refer all core arguments, adjuncts,
and predicates as semantic roles; thus we say the
PAS in Figure 1 has 4 roles. According to the an-
notation principles in (Chinese) PropBank (Palmer
et al, 2005; Xue and Palmer, 2009), all the roles
in a PAS map to a corresponding constituent in the
parse tree, and these constituents (e.g., NPs and
VBD in Figure 1) do not overlap with each other.
Next, we use a CFG rule to describe our syn-
tactic reordering model. Treating the two forms
of reorderings in a unified way, the semantic re-
ordering model is obtainable by regarding a PAS
as a CFG rule and considering a semantic role as a
constituent.
Because the translation of a source constituent
might result in multiple discontinuous blocks,
there can be several ways to describe or group
the reordering patterns. Therefore, we design
two general constituent reordering sub-models.
One is based on the leftmost aligned word (left-
most reordering model) and the other is based on
the rightmost aligned word (rightmost reordering
model), as follows. Figure 2 shows the model-
ing steps for the leftmost reordering model. Fig-
ure 2(a) is an example of a CFG rule in the source
1124
	 ?
XP	 ?XP1	 ? XP2	 ? XP3	 ? XP4	 ?f3	 ?	 ?f4	 ? f5	 ?	 ? f6	 ?	 ?f7	 ? f8	 ?...	 ?
...	 ?
...	 ?
...	 ?
?	 ?	 ?	 ?e2	 ?	 ?	 ?	 ?	 ?e3	 ?	 ?	 ?	 ?e4	 ?	 ?	 ?	 ?e5	 ?	 ?	 ?	 ?e6	 ?	 ?	 ?	 ?e7	 ?	 ?	 ?	 ?e8	 ?	 ?	 ?	 ?e9	 ?	 ??	 ? XP1	 ? XP2	 ? XP3	 ? XP4	 ?e2	 ? e3	 ? e5	 ?(a)	 ?a	 ?CFG	 ?rule	 ?and	 ?its	 ?alignment	 ? (b)	 ?leftmost	 ?aligned	 ?target	 ?words	 ?
XP1	 ? XP2	 ? XP3	 ? XP4	 ?1	 ? 4	 ? 2	 ? 3	 ? XP1	 ? XP2	 ? XP3	 ? XP4	 ?DM	 ? DS	 ? M	 ?(c)	 ?visit	 ?order	 ? (d)	 ?reordering	 ?types	 ?
Figure 2: Modeling process illustration for leftmost reordering model.
parse tree and its word alignment links to the target
language. Note that constituent XP
4
, which covers
word f
8
, has no alignment. Then for each XP
i
, we
find the leftmost target word which is aligned to a
source word covered by XP
i
. Figure 2(b) shows
that the leftmost target words for XP
1
, XP
2
, and
XP
3
are e
2
, e
5
, and e
3
, respectively, while XP
4
has no aligned target word. Then we get visit
order V = {v
i
} for {XP
i
} in the transformation
from Figure 2(b) to Figure 2(c), with the follow-
ing strategies for special cases:
? if the first constituent XP
1
is unaligned, we
add a NULL word at the beginning of the tar-
get side and link XP
1
to the NULL word;
? if a constituent XP
i
(i > 1) is unaligned, we
add a link to the target word which is aligned
to XP
i?1
, e.g., XP
4
will be linked to e
3
; and
? if k constituents XP
m
1
. . .XP
m
k
(m
1
<
. . . < m
k
) are linked to the same target word,
then v
m
i
= v
m
i+1
? 1, e.g., since XP
3
and
XP
4
are both linked to e
3
, then v
3
= v
4
? 1.
Finally Figure 2(d) converts the visit order V =
{v
1
, . . . v
n
} into a sequence of leftmost reordering
types LRT = {lrt
1
, . . . , lrt
n?1
}. For every two
adjacent constituents XP
i
and XP
i+1
with corre-
sponding visit order v
i
and v
i+1
, their reordering
could be one of the following:
? Monotone (M) if v
i+1
= v
i
+ 1;
? Discontinuous Monotone (DM) if v
i+1
> v
i
+ 1;
? Swap (S) if v
i+1
= v
i
? 1;
? Discontinuous Swap (DS) if v
i+1
< v
i
? 1.
Up to this point, we have generated a se-
quence of leftmost reordering types LRT =
{lrt
1
, . . . , lrt
n?1
} for a given CFG rule cfg:
XP ? XP
1
. . .XP
n
. The leftmost reordering
model takes the following form:
score
lrt
(cfg) = P
l
(lrt
1
, . . . , lrt
n?1
| ? (cfg))
(2)
where ? (cfg) indicates the surrounding context of
the CFG. By assuming that any two reordering
types in LRT = {lrt
1
, . . . , lrt
n?1
} are indepen-
dent of each other, we reformulate Eq. 2 into:
score
lrt
(cfg) =
n?1
?
i=1
P
l
(lrt
i
| ? (cfg))
(3)
Similarly, the sequence of rightmost reordering
types RRT can be decided for a CFG rule XP ?
XP
1
. . .XP
n
.
Accordingly, for a PAS pas: PAS ? R
1
. . .R
n
,
we can obtain its sequences of leftmost and right-
most reordering types by using the same way de-
scribed above.
3.1 Probability Estimation
In order to predict either the leftmost or right-
most reordering type for two adjacent constituents,
we use a maximum entropy classifier to esti-
mate the probability of the reordering type rt ?
{M,DM,S,DS} as follows:
P (rt | ? (cfg)) =
exp (
?
k
?
k
f
k
(rt, ? (cfg)))
?
rt
?
exp (
?
k
?
k
f
i
(rt
?
, ? (cfg)))
(4)
where f
k
are binary features, ?
k
are the weights of
these features. Most of our features f
k
are syntax-
based. For XP
i
and XP
i+1
in cfg, the features
1125
#Index Feature
cf1 L(XP
i
) & L(XP
i+1
) & L(XP)
cf2
for each XP
j
(j < i)
L(XP
i
) & L(XP
i+1
) & L(XP) & L(XP
j
)
cf3
for each XP
j
(j > i+ 1)
L(XP
i
) & L(XP
i+1
) & L(XP) & L(XP
j
)
cf4 L(XP
i
) & L(XP
i+1
) & P(XP
i
)
cf5 L(XP
i
) & L(XP
i+1
) &H(XP
i
)
cf6 L(XP
i
) & L(XP
i+1
) & P(XP
i+1
)
cf7 L(XP
i
) & L(XP
i+1
) &H(XP
i+1
)
cf8 L(XP
i
) & L(XP
i+1
) & S(XP
i
)
cf9 L(XP
i
) & L(XP
i+1
) & S(XP
i+1
)
cf10 L(XP
i
) & L(XP)
cf11 L(XP
i+1
) & L(XP)
Table 1: Features adopted in the syntactic leftmost
and rightmost reordering models. L (XP) returns
the syntactic category of XP, e.g., NP, VP, PP etc.;
H (XP) returns the head word of XP; P (XP) re-
turns the POS tagger of the head word; S (XP)
returns the translation status of XP on the target
language: un. if it is untranslated; cont. if it is
a continuous block; and discont. if it maps into
multiple discontinuous blocks.
are aimed to examine which of them should be
translated first. Therefore, most features share two
common components: the syntactic categories of
XP
i
and XP
i+1
. Table 1 shows the features used in
syntactic leftmost and rightmost reordering mod-
els. Note that we use the same features for both.
Although the semantic reordering model is
structured in precisely the same way, we use dif-
ferent feature sets to predict the reordering be-
tween two semantic roles. Given the two adjacent
roles R
i
and R
i+1
in a PAS pas, Table 2 shows the
features that are used in the semantic leftmost and
rightmost reordering models.
3.2 Integrating into the HPB Model
For models with syntactic reordering, we add two
new features (i.e., one for the leftmost reorder-
ing model and the other for the rightmost reorder-
ing model) into the log-linear translation model in
Eq. 1. Unlike the conventional phrase and lexi-
cal translation features, whose values are phrase
pair-determined and thus can be calculated offline,
the value of the reordering features can only be
obtained during decoding time, and requires word
alignment information as well. Before we present
the algorithm integrating the reordering models,
we define the following functions by assuming
XP
i
and XP
i+1
are the constituent pair of interest
in CFG rule cfg, H is the translation hypothesis
and a is its word alignment:
#Index Feature
rf1
R(R
i
) &R(R
i+1
) & P(pas)
R(R
i
) &R(R
i+1
)
rf2
for each R
j
(j < i)
R(R
i
) &R(R
i+1
) &R(R
j
) & P(pas)
R(R
i
) &R(R
i+1
) &R(R
j
)
rf3
for each R
j
(j > i+ 1)
R(R
i
) &R(R
i+1
) &R(R
j
) & P(pas)
R(R
i
) &R(R
i+1
) &R(R
j
)
rf4 R(R
i
) &R(R
i+1
) & P(R
i
)
rf5 R(R
i
) &R(R
i+1
) &H(R
i
)
rf6 R(R
i
) &R(R
i+1
) & L(R
i
)
rf7 R(R
i
) &R(R
i+1
) & P(R
i+1
)
rf8 R(R
i
) &R(R
i+1
) &H(R
i+1
)
rf9 R(R
i
) &R(R
i+1
) & L(R
i+1
)
rf10 R(R
i
) &R(R
i+1
) & S(R
i
)
rf11 R(R
i
) &R(R
i+1
) & S(R
i+1
)
rf12
R(R
i
) & P(pas)
R(R
i
)
rf13
R(R
i+1
) & P(pas)
R(R
i+1
)
Table 2: Features adopted in the semantic leftmost
and rightmost reordering models. P (pas) returns
the predicate content of pas;R (R) returns the role
type of R, e.g., Pred, A0, TMP, etc. For features
rf1, rf2, rf3, rf12 and rf13, we include another ver-
sion which excludes the predicate content P(pas)
for reasons of sparsity.
? F
1
(w
1
, w
2
, XP): returns true if constituent XP is
within the span from word w
1
to w
2
; otherwise returns
false.
? F
2
(H, cfg, XP
i
, XP
i+1
) returns true if the reordering
of the pair ?XP
i
, XP
i+1
? in rule cfg has not been calcu-
lated yet; otherwise returns false.
? F
3
(H, a, XP
i
, XP
i+1
) returns the leftmost and right-
most reordering types for the constituent pair ?XP
i
,
XP
i+1
?, given alignment a, according to Section 3.
? F
4
(rt, cfg, XP
i
, XP
i+1
) returns the probability of
leftmost reordering type rt for the constituent pair
?XP
i
, XP
i+1
? in rule cfg.
? F
5
(rt, cfg, XP
i
, XP
i+1
) returns the probability of
rightmost reordering type rt for the constituent pair
?XP
i
, XP
i+1
? in rule cfg.
Algorithm 1 integrates the syntactic leftmost
and rightmost reordering models into a CKY-style
decoder whenever a new hypothesis is generated.
Given a hypothesis H with its alignment a, it tra-
verses all CFG rules in the parse tree and sees if
two adjacent constituents are conditioned to trig-
ger the reordering models (lines 2-4). For each
pair of constituents, it first extracts its leftmost and
rightmost reordering types (line 6) and then gets
their respective probabilities returned by the max-
imum entropy classifiers defined in Section 3.1
1126
Algorithm 1: Integrating the syntactic reordering models
into a CKY-style decoder
Input: Sentence f in the source language
Parse tree t of f
All CFG rules {cfg} in t
Hypothesis H spanning from word w
1
to w
2
Alignment a of H
Output: Log-Probabilities of the syntactic leftmost
and rightmost reordering models
1. set l prob = r
p
rob = 0.0
2. foreach cfg in {cfg}
3. foreach pair XP
i
and XP
i+1
in cfg
4. if F
1
(w
1
, w
2
, XP
i
) = false or
F
1
(w
1
, w
2
, XP
i+1
) = false or
F
2
(H, cfg, XP
i
, XP
i+1
) = false
5. continue
6. (l type, r type) = F
3
(H, a, XP
i
, XP
i+1
)
7. l prob += logF
4
(l type, cfg,XP
i
,XP
i+1
)
8. r prob += logF
5
(r type, cfg,XP
i
,XP
i+1
)
9. return (l prob, r prob)
(lines 7-8). Then the algorithm returns two log-
probabilities of the syntactic reordering models.
Note that Function F
1
returns true if hypothesis
H fully covers, or fully contains, constituentXP
i
,
regardless of the reordering type of XP
i
. Do not
confuse any parsing tag XP
i
with the nameless
variables X
i
in Hiero or cdec rules.
For the semantic reordering models, we also
add two new features into the log-linear transla-
tion model. To get the two semantic reordering
model feature values, we simply use Algorithm 1
and its associated functions from F
1
to F
5
replac-
ing a CFG rule cfg with a PAS pas, and a con-
stituent XP
i
with a semantic role R
i
. Algorithm 1
therefore permits a unified treatment of syntactic
and PAS-based reordering, even though it is ex-
pressed in terms of syntactic reordering here for
ease of presentation.
4 Experiments
We have presented our unified approach to in-
corporating syntactic and semantic soft reorder-
ing constraints in an HPB system. In this section,
we test its effectiveness in Chinese-English trans-
lation.
4.1 Experimental Settings
For training we use 1.6M sentence pairs of the
non-UN and non-HK Hansards portions of NIST
MT training corpora, segmented with the Stan-
ford segmenter (Tseng et al, 2005). The En-
glish data is lowercased, tokenized and aligned
with GIZA++ (Och and Ney, 2000) to obtain bidi-
rectional alignments, which are symmetrized us-
ing the grow-diag-final-and method (Koehn et al,
2003). We train a 4-gram LM on the English
side of the corpus with 600M additional words
from non-NYT and non-LAT, randomly selected
portions of the Gigaword v4 corpus, using modi-
fied Kneser-Ney smoothing (Chen and Goodman,
1996). We use the HPB decoder cdec (Dyer et
al., 2010), with Mr. Mira (Eidelman et al, 2013),
which is a k-best variant of MIRA (Chiang et al,
2008), to tune the parameters of the system.
We use NIST MT 06 dataset (1664 sentence
pairs) for tuning, and NIST MT 03, 05, and 08
datasets (919, 1082, and 1357 sentence pairs, re-
spectively) for evaluation.
1
We use BLEU (Pap-
ineni et al, 2002) for both tuning and evaluation.
To obtain syntactic parse trees and semantic
roles on the tuning and test datasets, we first
parse the source sentences with the Berkeley
Parser (Petrov and Klein, 2007), trained on the
Chinese Treebank 7.0 (Xue et al, 2005). We
then pass the parses to a Chinese semantic role
labeler (Li et al, 2010), trained on the Chinese
PropBank 3.0 (Xue and Palmer, 2009), to anno-
tate semantic roles for all verbal predicates (part-
of-speech tag VV, VE, or VC).
Our basic baseline system employs 19 basic
features: a language model feature, 7 transla-
tion model features, word penalty, unknown word
penalty, the glue rule, date, number and 6 pass-
through features. Our stronger baseline employs,
in addition, the fine-grained syntactic soft con-
straint features of Marton and Resnik (2008), here-
after MR08. The syntactic soft constraint features
include both MR08 exact-matching and cross-
boundary constraints (denoted XP= and XP+).
Since the syntactic parses of the tuning and test
data contain 29 types of constituent labels and 35
types of POS tags, we have 29 types of XP+ fea-
tures and 64 types of XP= features.
4.2 Model Training
To train the syntactic and semantic reordering
models, we use a gold alignment dataset.
2
It con-
tains 7,870 sentences with 191,364 Chinese words
and 261,399 English words. We first run syn-
1
http://www.itl.nist.gov/iad/mig//tests/mt
2
This dataset includes LDC2006E86, and newswire
parts of LDC2012T16, LDC2012T20, LDC2012T24, and
LDC2013T05. Indeed, the reordering models can also be
trained on the MT training data with its automatic alignment.
However, our preliminary experiments showed that the re-
ordering models trained on gold alignment yielded higher im-
provement.
1127
Reordering
Type
Syntactic Semantic
l-m r-m l-m r-m
M 73.5 80.6 63.8 67.9
DM 3.9 3.3 14.0 12.0
S 19.5 13.2 13.1 10.7
DS 3.2 3.0 9.1 9.5
#instance 199,234 66,757
Table 3: Reordering type distribution over the re-
ordering model?s training data. Hereafter, l-m and
r-m are for leftmost and rightmost, respectively.
tactic parsing and semantic role labeling on the
Chinese sentences, then train the models by us-
ing MaxEnt toolkit with L1 regularizer (Tsuruoka
et al, 2009).
3
Table 3 shows the reordering type
distribution over the training data. Interestingly,
about 17% of the syntactic instances and 16% of
the semantic instances differ in their leftmost and
rightmost reordering types, indicating that the left-
most/rightmost distinction is informative. We also
see that the number of semantic instances is about
1/3 of that of syntactic instances, but the entropy
of the semantic reordering classes is higher, indi-
cating the reordering of semantic roles is harder
than that of syntactic constituents.
A deeper examination of the reordering model?s
training data reveals that some constituent pairs
and semantic role pairs have a preference for a
specific reordering type (monotone or swap). In
order to understand how well the MR08 system
respects their reordering preference, we use the
gold alignment dataset LDC2006E86, in which
the source sentences are from the Chinese Tree-
bank, and thus both the gold parse trees and gold
predicate-argument structures are available. Ta-
ble 4 presents examples comparing the reordering
distribution between gold alignment and the out-
put of the MR08 system. For example, the first
row shows that based on the gold alignment, for
?PP,VP?, 16% are in monotone and 76% are in
swap reordering. However, our MR08 system out-
puts 46% of them in monotone and and 50% in
swap reordering. Hence, the reordering accuracy
for ?PP,VP? is 54%. Table 4 also shows that the
semantic reordering between core arguments and
predicates (e.g., ?Pred,A1?, ?A0,Pred?) has a less
ambiguous pattern than that between adjuncts and
other roles (e.g., ?LOC,Pred?, ?A0,TMP?), indicat-
ing the higher reordering flexibility of adjuncts.
3
http://www.logos.ic.i.u-tokyo.ac.jp/?tsuruoka/maxent/
Const. Pair
Gold MR08 output
M S M S acc.
PP VP 16 76 46 50 54
NP LC 26 74 58 42 50
DNP NP 24 72 78 19 39
CP NP 26 67 84 10 33
NP DEG 39 61 31 69 66
... ... ...
all 81 13 79 14 80
Role Pair
Gold MR08 output
M S M S acc.
Pred A1 84 6 82 9 72
A0 Pred 82 11 79 8 75
LOC Pred 17 30 36 25 49
A0 TMP 35 25 61 6 45
TMP Pred 30 22 49 19 43
... ... ...
all 63 13 73 9 64
Table 4: Examples of the reordering distribution
(%) of gold alignment and the MR08 system out-
put. For simplicity, we only focus on (M)onotone
and (S)wap based on leftmost reordering.
4.3 Translation Experiment Results
Our first group of experiments investigates
whether the syntactic reordering models are able
to improve translation quality in terms of BLEU.
To this end, we respectively add our syntactic re-
ordering models into both the baseline and MR08
systems. The effect is shown in the rows of ?+ syn-
reorder? in Table 5. From the table, we have the
following two observations.
? Although the HPB model is capable of
handling non-local phrase reordering using
synchronous context free grammars, both
our syntactic leftmost reordering model and
rightmost model are still able to achieve im-
provement over both the baseline and MR08.
This suggests that our syntactic reordering
features interact well with the MR08 syntac-
tic soft constraints: the XP+ and XP= fea-
tures focus on a single constituent each, while
our reordering features focus on a pair of con-
stituents each.
? There is no clear indication of whether the
leftmost reordering model works better than
the other. In addition, integrating both the
leftmost and rightmost reordering models has
limited improvement over a single reordering
model.
Our second group of experiments is to vali-
date the semantic reordering models. Results are
1128
System
Tuning Test
MT06 MT03 MT05 MT08 Avg.
Baseline 34.1 36.1 32.3 27.4 31.9
+
syn-
reorder
l-m 35.2 36.9? 33.6? 28.4? 33.0
r-m 35.2 37.2? 33.7? 28.6? 33.2
both 35.6 37.1? 33.6? 28.8? 33.1
+
sem-
reorder
l-m 34.4 36.7? 33.0? 27.8? 32.5
r-m 34.5 36.7? 33.1? 27.8? 32.5
both 34.5 37.0? 33.6? 27.7? 32.8
+syn+sem 35.5 37.3? 33.7? 29.0? 33.3
MR08 35.6 37.4 34.2 28.7 33.4
+
syn-
reorder
l-m 36.0 38.2? 35.0? 29.2? 34.1
r-m 36.0 38.1? 34.8? 29.2? 34.0
both 35.9 38.2? 35.3? 29.5? 34.3
+
sem-
reorder
l-m 35.8 37.6? 34.7? 28.7 33.7
r-m 35.8 37.4 34.5? 28.8 33.6
both 35.8 37.6? 34.7? 28.8 33.7
+syn+sem 36.1 38.4? 35.2? 29.5? 34.4
Table 5: System performance in BLEU scores.
?/?: significant over baseline or MR08 at 0.01
/ 0.05, respectively, as tested by bootstrap re-
sampling (Koehn, 2004)
shown in the rows of ?+ sem-reorder? in Table 5.
Here we observe:
? The semantic reordering models also achieve
significant gain of 0.8 BLEU on average over
the baseline system, demonstrating the ef-
fectiveness of PAS-based reordering. How-
ever, the gain diminishes to 0.3 BLEU on the
MR08 system.
? The syntactic reordering models outperform
the semantic reordering models on both the
baseline and MR08 systems.
Finally, we integrate both the syntactic and se-
mantic reordering models into the final system.
The two models collectively achieve a gain of up
to 1.4 BLEU over the baseline and 1.0 BLEU over
MR08 on average, which is shown in the rows of
?+syn+sem? in Table 5.
5 Discussion
The trend of the results, summarized as perfor-
mance gain over the baseline and MR08 systems
averaged over all test sets, is presented in Table 6.
The syntactic reordering models outperform the
semantic reordering models, and the gain achieved
by the semantic reordering models is limited in the
presence of the MR08 syntactic features. In this
section, we look at MR08 system and the systems
improving it to explore the behavior differences
between the two reordering models.
Coverage analysis: Our statistics show that
syntactic reordering features (either leftmost or
System Baseline MR08
+syn-reorder 1.2 0.9
+sem-reorder 0.8 0.3
+ both 1.4 1.0
Table 6: Performance gain in BLEU over baseline
and MR08 systems averaged over all test sets.
rightmost) are called 24 times per sentence on av-
erage. This is compared to only 9 times per sen-
tence for semantic reordering features. This is not
surprising since the semantic reordering features
are exclusively attached to predicates, and the span
set of the semantic roles is a strict subset of the
span set of the syntactic constituents; only 22% of
syntactic constituents are semantic roles. On aver-
age, a sentences has 4 PASs and each PAS contains
3 semantic roles. Of all the semantic role pairs,
44% are in the same CFG rules, indicating that this
part of semantic reordering has overlap with syn-
tactic reordering. Therefore, the PAS model has
fewer opportunities to influence reordering.
Reordering accuracy analysis: The reordering
type distribution on the reordering model training
data in Table 3 suggests that semantic reordering
is more difficult than syntactic reordering. To val-
idate this conjecture on our translation test data,
we compare the reordering performance among
the MR08 system, the improved systems and the
maximum entropy classifiers. For the test set, we
have four reference translations. We run GIZA++
on the data combination of our translation train-
ing data and test data to get the alignment for the
test data and each reference translation. Once we
have the (semi-)gold alignment, we compute the
gold reordering types between two adjacent syn-
tactic constituents or semantic roles. Then we
evaluate the automatic reordering outputs gener-
ated from both our translation systems and max-
imum entropy classifiers. Table 7 shows the ac-
curacy averaged over the four gold reordering sets
(the four reference translations). It shows that 1)
as expected, our classifiers do worse on the harder
semantic reordering prediction than syntactic re-
ordering prediction; 2) thanks to the high accu-
racy obtained by the maxent classifiers, integrat-
ing either the syntactic or the semantic reorder-
ing constraints results in better reordering perfor-
mance from both syntactic and semantic perspec-
tives; 3) in terms of the mutual impact, the syn-
tactic reordering models help improving seman-
tic reordering more than the semantic reordering
1129
System
Syntactic Semantic
l-m r-m l-m r-m
MR08 75.0 78.0 66.3 68.5
+syn-reorder 78.4 80.9 69.0 70.2
+sem-reorder 76.0 78.8 70.7 72.7
+both 78.6 81.7 70.6 72.1
Maxent Classifier 80.7 85.6 70.9 73.5
Table 7: Reordering accuracy on four gold sets.
System
Syntactic Semantic
l-m r-m l-m r-m
+syn-reorder 1.2 1.2 - -
+sem-reorder - - 0.7 0.9
+both 1.2 1.0 0.5 0.4
Table 8: Reordering feature weights.
models help improving syntactic reordering; and
4) the rightmost models have a learnability advan-
tage over the leftmost models, achieving higher
accuracy across the board.
Feature weight analysis: Table 8 shows the
syntactic and semantic reordering feature weights.
It shows that the semantic feature weights de-
crease in the presence of the syntactic features, in-
dicating that the decoder learns to trust semantic
features less in the presence of the more accurate
syntactic features. This is consistent with our ob-
servation that semantic reordering is harder than
syntactic reordering, as seen in Tables 3 and 7.
Potential improvement analysis: Table 7 also
shows that our current maximum entropy classi-
fiers have room for improvement, especially for
semantic reordering. In order to explore the error
propagation from the classifiers themselves and
explore the upper bound for improvement from the
reordering models, we perform an ?oracle? study,
letting the classifiers be aware of the ?gold? re-
ordering type between two syntactic constituents
or two semantic roles, and returning a higher prob-
ability for the gold reordering type and a smaller
one for the others (i.e., we set 0.9 for the gold
System MT 03 MT 05 MT 08 Avg.
Non-
Oracle
MR08 37.4 34.2 28.7 33.4
+syn-
reorder
38.2 35.3 29.5 34.3
+sem-
reorder
37.6 34.7 28.8 33.7
+ both 38.4 35.2 29.5 34.4
Oracle
+syn-
reorder
39.2 35.9 29.6 34.9
+sem-
reorder
37.9 34.8 28.9 33.9
+ both 39.1 36.0 29.8 35.0
Table 9: Performance (BLEU score) comparison
between non-oracle and oracle experiments.
reordering type, and let the other non-gold three
types share 0.1). Again, to get the gold reorder-
ing type, we run GIZA++ to get the alignment for
tuning/test source sentences and each of four ref-
erence translations. We report the averaged per-
formance by using the gold reordering type ex-
tracted from the four reference translations. Ta-
ble 9 compares the performance between the non-
oracle and oracle settings. We clearly see that us-
ing gold syntactic reordering types significantly
improves the performance (e.g., 34.9 vs. 33.4 on
average) and there is still some room for improve-
ment by building a better maximum entropy clas-
sifiers (e.g., 34.9 vs. 34.3). To our surprise, how-
ever, the improvement achieved by gold semantic
reordering types is still small (e.g., 33.9 vs. 33.4),
suggesting that the potential improvement of se-
mantic reordering models is much more limited.
And we again see that the improvement achieved
by semantic reordering models is limited in the
presence of the syntactic reordering models.
6 Related Work
Syntax-based reordering: Some previous work
pre-ordered words in the source sentences, so that
the word order of source and target sentences is
similar. The reordering rules were either manu-
ally designed (Collins et al, 2005; Wang et al,
2007; Xu et al, 2009; Lee et al, 2010) or auto-
matically learned (Xia and McCord, 2004; Gen-
zel, 2010; Visweswariah et al, 2010; Khalilov
and Sima?an, 2011; Lerner and Petrov, 2013), us-
ing syntactic parses. Li et al (2007) focused on
finding the n-best pre-ordered source sentences by
predicting the reordering of sibling constituents,
while Yang et al (2012) obtained word order by
using a reranking approach to reposition nodes in
syntactic parse trees. Both are close to our work;
however, our model generates reordering features
that are integrated into the log-linear translation
model during decoding.
Another approach in previous work added soft
constraints as weighted features in the SMT de-
coder to reward good reorderings and penalize bad
ones. Marton and Resnik (2008) employed soft
syntactic constraints with weighted binary features
and no MaxEnt model. They did not explicitly
target reordering (beyond applying constraints on
HPB rules). Although employing linguistically
motivated labels in SCFG is capable of captur-
ing constituent reorderings (Chiang, 2010; Mylon-
1130
akis and Sima?an, 2011), the rules are sparser than
SCFG with nameless non-terminals (i.e., Xs) and
soft constraints. Ge (2010) presented a syntax-
driven maximum entropy reordering model that
predicted the source word translation order. Gao
et al (2011) employed dependency trees to predict
the translation order of a word and its head word.
Huang et al (2013) predicted the translation order
of two source words.
4
Our work, which shares this
approach, differs from their work primarily in that
our syntactic reordering models are based on the
constituent level, rather than the word level.
Semantics-based reordering: Semantics-
based reordering has also seen an increase
in activity recently. In the pre-ordering ap-
proach, Wu et al (2011) automatically learned
pre-ordering rules from PAS. In the soft con-
straint or reordering model approach, Liu and
Gildea (2010) modeled the reordering/deletion
of source-side semantic roles in a tree-to-string
translation model. Xiong et al (2012) and Li et
al. (2013) predicted the translation order between
either two arguments or an argument and its
predicate. Instead of decomposing a PAS into
individual units, Zhai et al (2013) constructed
a classifier for each source side PAS. Finally in
the post-processing approach category, Wu and
Fung (2009) performed semantic role labeling
on translation output and reordered arguments to
maximize the cross-lingual match of the semantic
frames between the source sentence and the target
translation. To our knowledge, their semantic
reordering models were PAS-specific. In contrast,
our model is universal and can be easily adopted
to model the reordering of other linguistic units
(e.g., syntactic constituents). Moreover, we
have studied the effectiveness of the semantic
reordering model in different scenarios.
Non-syntax-based reorderings in HPB: Re-
cently we have also seen work on lexicalized re-
ordering models without syntactic information in
HPB (Setiawan et al, 2009; Huck et al, 2013;
Nguyen and Vogel, 2013). The non-syntax-
based reordering approach models the reorder-
ing of translation words/phrases while the syntax-
based approach models the reordering of syn-
tactic constituents. Although there are overlaps
between translation phrases and syntactic con-
stituents, it is reasonable to think that the two re-
4
Note that they obtained the translation order of source
word pairs by predicting the reordering of adjacent con-
stituents, which was quite close to our work.
ordering approaches can work together well and
even complement each other, as the linguistic pat-
terns they capture differ substantially. Setiawan
et al (2013) modeled the orientation decisions
between anchors and two neighboring multi-unit
chunks which might cross phrase or rule bound-
aries. Last, we also note that recent work on non-
syntax-based reorderings in (flat) phrase-based
models (Cherry, 2013; Feng et al, 2013) can also
be potentially adopted to hpb models.
7 Conclusion and Future Work
In this paper, we have presented a unified reorder-
ing framework to incorporate soft linguistic con-
straints (of syntactic or semantic nature) into the
HPB translation model. The syntactic reordering
models take CFG rules and model their reordering
on the target side, while the semantic reordering
models work with PAS. Experiments on Chinese-
English translation show that the reordering ap-
proach can significantly improve a state-of-the-art
hierarchical phrase-based translation system. We
have also discussed the differences between the
two linguistic reordering models.
There are many directions in which this work
can be continued. First, the syntactic reordering
model can be extended to model reordering among
constituents that cross CFG rules. Second, al-
though we do not see obvious gain from the se-
mantic reordering model when the syntactic model
is adopted, it might be beneficial to further jointly
consider the two reordering models, focusing on
where each one does well. Third, to better exam-
ine the overlap or synergy between our approach
and the non-syntax-based reordering approach, we
will conduct direct comparisons and combinations
with the latter.
Acknowledgments
This research was supported in part by the
BOLT program of the Defense Advanced Re-
search Projects Agency, Contract No. HR0012-
12-C-0015. Any opinions, findings, conclusions
or recommendations expressed in this paper are
those of the authors and do not necessarily re-
flect the view of DARPA. The authors would like
to thank three anonymous reviewers for providing
helpful comments, and also acknowledge Ke Wu,
Vladimir Eidelman, Hua He, Doug Oard, Yuening
Hu, Jordan Boyd-Graber, and Jyothi Vinjumur for
useful discussions.
1131
References
Stanley F. Chen and Joshua Goodman. 1996. An em-
pirical study of smoothing techniques for language
modeling. In Proceedings of ACL 1996, pages 310?
318.
Colin Cherry. 2013. Improved reordering for phrase-
based translation using sparse features. In Proceed-
ings of HLT-NAACL 2013, pages 22?31.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of EMNLP
2008, pages 224?233.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of ACL 2010,
pages 1443?1452.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proceedings of ACL 2005, pages
531?540.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Seti-
awan, Vladimir Eidelman, and Philip Resnik. 2010.
cdec: A decoder, alignment, and learning framework
for finite-state and context-free translation models.
In Proceedings of ACL 2010 System Demonstra-
tions, pages 7?12.
Vladimir Eidelman, Ke Wu, Ferhan Ture, Philip
Resnik, and Jimmy Lin. 2013. Mr. mira: Open-
source large-margin structured learning on mapre-
duce. In Proceedings of ACL 2013 System Demon-
strations, pages 199?204.
Minwei Feng, Jan-Thorsten Peter, and Hermann Ney.
2013. Advancements in reordering models for sta-
tistical machine translation. In Proceedings of ACL
2013, pages 322?332.
Yang Gao, Philipp Koehn, and Alexandra Birch. 2011.
Soft dependency constraints for reordering in hier-
archical phrase-based translation. In Proceedings of
EMNLP 2011, pages 857?868.
Niyu Ge. 2010. A direct syntax-driven reordering
model for phrase-based machine translation. In Pro-
ceedings of HLT-NAACL 2010, pages 849?857.
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine transla-
tion. In Proceedings of COLING 2010, pages 376?
384.
Zhongqiang Huang, Jacob Devlin, and Rabih Zbib.
2013. Factored soft source syntactic constraints for
hierarchical machine translation. In Proceedings of
EMNLP 2013, pages 556?566.
Matthias Huck, Joern Wuebker, Felix Rietig, and Her-
mann Ney. 2013. A phrase orientation model for
hierarchical machine translation. In Proceedings of
WMT 2013, pages 452?463.
Maxim Khalilov and Khalil Sima?an. 2011. Context-
sensitive syntactic source-reordering by statistical
transduction. In Proceedings of IJCNLP 2011,
pages 38?46.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL 2003, pages 48?54.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP 2004, pages 388?395.
Young-Suk Lee, Bing Zhao, and Xiaoqian Luo.
2010. Constituent reordering and syntax models for
English-to-Japanese statistical machine translation.
In Proceedings of COLING 2010, pages 626?634.
Uri Lerner and Slav Petrov. 2013. Source-side clas-
sifier preordering for machine translation. In Pro-
ceedings of EMNLP 2013, pages 513?523.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,
Ming Zhou, and Yi Guan. 2007. A probabilistic
approach to syntax-based reordering for statistical
machine translation. In Proceedings of ACL 2007,
pages 720?727.
Junhui Li, Guodong Zhou, and Hwee Tou Ng. 2010.
Joint syntactic and semantic parsing of Chinese. In
Proceedings of ACL 2010, pages 1108?1117.
Junhui Li, Philip Resnik, and Hal Daum?e III. 2013.
Modeling syntactic and semantic structures in hier-
archical phrase-based translation. In Proceedings of
HLT-NAACL 2013, pages 540?549.
Ding Liu and Daniel Gildea. 2010. Semantic role
features for machine translation. In Proceedings of
COLING 2010, pages 716?724.
Yuval Marton and Philip Resnik. 2008. Soft syntac-
tic constraints for hierarchical phrased-based trans-
lation. In Proceedings of ACL-HLT 2008, pages
1003?1011.
Markos Mylonakis and Khalil Sima?an. 2011. Learn-
ing hierarchical translation structure with linguistic
annotations. In Proceedings of ACL 2011, pages
642?652.
ThuyLinh Nguyen and Stephan Vogel. 2013. Integrat-
ing phrase-based reordering features into a chart-
based decoder for machine translation. In Proceed-
ings of ACL 2013, pages 1587?1596.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of ACL
2000, pages 440?447.
1132
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In Proceedings
of ACL 2002, pages 311?318.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL 2007, pages 404?411.
Hendra Setiawan, Min Yen Kan, Haizhou Li, and Philip
Resnik. 2009. Topological ordering of function
words in hierarchical phrase-based translation. In
Proceedings of ACL-IJCNLP 2009, pages 324?332.
Hendra Setiawan, Bowen Zhou, Bing Xiang, and Libin
Shen. 2013. Two-neighbor orientation model with
cross-boundary global contexts. In Proceedings of
ACL 2013, pages 1264?1274.
Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel
Jurafsky, and Christopher Manning. 2005. A condi-
tional random field word segmenter for sighan bake-
off 2005. In Proceedings of the Fourth SIGHAN
Workshop on Chinese Language Processing, pages
168?171.
Yoshimasa Tsuruoka, Jun?ichi Tsujii, and Sophia Ana-
niadou. 2009. Stochastic gradient descent training
for l1-regularized log-linear models with cumula-
tive penalty. In Proceedings of ACL-IJCNLP 2009,
pages 477?485.
Karthik Visweswariah, Jiri Navratil, Jeffrey Sorensen,
Vijil Chenthamarakshan, and Nandakishore Kamb-
hatla. 2010. Syntax based reordering with automat-
ically derived rules for improved statistical machine
translation. In Proceedings of COLING 2010, pages
1119?1127.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proceedings of EMNLP
2007, pages 737?745.
Dekai Wu and Pascale Fung. 2009. Semantic roles for
smt: A hybrid two-pass model. In Proceedings of
HLT-NAACL 2009: short papers, pages 13?16.
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. 2011. Extracting
pre-ordering rules from predicate-argument struc-
tures. In Proceedings of IJCNLP 2011, pages 29?
37.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical mt system with automatically learned rewrite
patterns. In Proceedings of COLING 2004, pages
508?514.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Mod-
eling the translation of predicate-argument structure
for smt. In Proceedings of ACL 2012, pages 902?
911.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In Proceed-
ings of HLT-NAACL 2009, pages 245?253.
Nianwen Xue and Martha Palmer. 2009. Adding se-
mantic roles to the Chinese Treebank. Natural Lan-
guage Engineering, 15(1):143?172.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The Penn Chinese Treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Nan Yang, Mu Li, Dongdong Zhang, and Nenghai Yu.
2012. A ranking-based approach to word reordering
for statistical machine translation. In Proceedings of
ACL 2012, pages 912?920.
Feifei Zhai, Jiajun Zhang, Yu Zhou, and Chengqing
Zong. 2013. Handling ambiguities of bilingual
predicate-argument structures for statistical machine
translation. In Proceedings of ACL 2013, pages
1127?1136.
1133
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1501?1511,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Predicting Instructor?s Intervention in MOOC forums
Snigdha Chaturvedi Dan Goldwasser Hal Daum
?
e III
Department of Computer Science,
University of Maryland, College Park, Maryland
{snigdhac, goldwas1, hal}@umiacs.umd.edu
Abstract
Instructor intervention in student discus-
sion forums is a vital component in
Massive Open Online Courses (MOOCs),
where personalized interaction is limited.
This paper introduces the problem of pre-
dicting instructor interventions in MOOC
forums. We propose several prediction
models designed to capture unique aspects
of MOOCs, combining course informa-
tion, forum structure and posts content.
Our models abstract contents of individ-
ual posts of threads using latent categories,
learned jointly with the binary interven-
tion prediction problem. Experiments over
data from two Coursera MOOCs demon-
strate that incorporating the structure of
threads into the learning problem leads to
better predictive performance.
1 Introduction
Ubiquitous computing and easy access to high
bandwidth internet have reshaped the modus
operandi in distance education towards Massive
Open Online Courses (MOOCs). Courses offered
by ventures such as Coursera and Udacity now im-
part inexpensive and high-quality education from
field-experts to thousands of learners across geo-
graphic and cultural barriers.
Even as the MOOC model shows exciting pos-
sibilities, it presents a multitude of challenges that
must first be negotiated to completely realize its
potential. MOOCs platforms have been especially
criticized on grounds of lacking a personalized
educational experience (Edmundson, 2012). Un-
like traditional classrooms, the predominant mode
of interaction between students and instructors in
MOOCs is via online discussion forums. Ideally,
forum discussions can help make up for the lack
of direct interaction, by enabling students to ask
questions and clarify doubts. However, due to
huge class sizes, even during the short duration
of a course, MOOCs witness a very large number
of threads on these forums. Owing to extremely
skewed ratios of students to instructional staff, it
can be prohibitively time-consuming for the in-
structional staff to manually follow all threads of a
forum. Hence there is a pressing need for automat-
ically curating the discussions for the instructors.
In this paper, we focus on identifying situa-
tions in which instructor (used interchangeably
with ?instructional staff? in this paper) interven-
tion is warranted. Using existing forum posts and
interactions, we frame this as a binary prediction
problem of identifying instructor?s intervention in
forum threads. Our initial analysis revealed that
instructors usually intervene on threads discussing
students? issues close to a quiz or exam. They
also take interest in grading issues and logistics
problems. There are multiple cues specific to the
MOOC setting, which when combined with the
rich lexical information present in the forums, can
yield useful predictive models.
Analyzing forum-postings contents and bring-
ing the most pertinent content to the instructor?s
attention would help instructors receive timely
feedback and design interventions as needed.
From the students? perspective, the problem is ev-
ident from an examination of existing forum con-
tent, indicating that if students want instructor?s
input on some issues, the only way for them to
get his/her attention is by ?up-voting? their votes.
Fig. 1 provides some examples of this behavior.
This is clearly an inefficient solution.
Our main technical contribution is introducing
three different models addressing the task of pre-
dicting instructor interventions. The first uses a lo-
gistic regression model that primarily incorporates
high level information about threads and posts.
However, forum threads have structure which is
not leveraged our initial model. We present two
1501
?The problem summary: Anyone else having problems viewing the video lecture...very choppy. If you are also experi-
encing this issue; please upvote this post.?
?I read that by up-voting threads and posts you can get the instructors? attention faster.?
?Its is very bad to me that I achieved 10 marks in my 1st assignment and now 9 marks in my 2nd assignment, now I won?t
get certificate, please Course staff it is my appeal to change the passing scheme or please be lenient. Please upvote my
post so that staff take this problem under consideration.?
Figure 1: Sample posts that showing students desiring instructor?s attention have to resolve to the ineffi-
cient method of getting their posts upvoted.
additional structured models. Both models assume
that posts of a thread structure it in form of a story
or a ?chain of events.? For example, an opening
post of a thread might pose a question and the fol-
lowing posts can then answer or comment on the
question. Our second and third models tap this
linear ?chain of events? behavior by assuming that
individual posts belong to latent categories which
represent their textual content at an abstract level
and that an instructor?s decision to reply to a post
is based on this chain of events (represented by the
latent categories). We present two different ways
of utilizing this ?chain of events? behavior for pre-
dicting instructor?s intervention which can be ei-
ther simply modeled as the ?next step? is this chain
of events (Linear Chain Markov Model) or as a
decision globally depending on the entire chain
(Global Chain Model). Our experiments on two
different datasets reveal that using the latent post
categories helps in better prediction.
Our contributions can be summarized as:
? We motivate and introduce the important
problem of predicting instructor intervention
in MOOC forums
? We present two chain based models that in-
corporate thread structure.
? We show the utility of modeling thread struc-
ture, and the value of lexical and domain spe-
cific knowledge for the prediction task
2 Related Work
To the best of our knowledge, the problem of pre-
dicting instructor?s intervention in MOOC forums
has not been addressed yet. Prior work deals with
analyzing general online discussion forums of so-
cial media sites (Kleinberg, 2013): such as pre-
dicting comment volume (Backstrom et al, 2013;
De Choudhury et al, 2009; Wang et al, 2012;
Tsagkias et al, 2009; Yano and Smith, 2010; Artzi
et al, 2012) and rate of content diffusion (Kwak et
al., 2010; Lerman and Ghosh, 2010; Bakshy et al,
2011; Romero et al, 2011; Artzi et al, 2012) and
also question answering (Chaturvedi et al, 2014).
Wang et al (2007) incorporate thread structure
of conversations using features in email threads
while Goldwasser and Daum?e III (2014) use la-
tent structure, aimed to identify relevant dialog
segments, for predicting objections during court-
room deliberations. Other related work include
speech act recognition in emails and forums but
at a sentence level (Jeong et al, 2009), and us-
ing social network analysis to improve message
classification into pre-determined types (Fortuna
et al, 2007). Discussion forums data has also been
used to address other interesting challenges such
as extracting chatbox knowledge for use in gen-
eral online forums (Huang et al, 2007) and auto-
matically extracting answers from discussion fo-
rums (Catherine et al, 2013), subjectivity analy-
sis of online forums (Biyani et al, 2013). Most
of these methods use ideas similar to ours: identi-
fying that threads (or discussions) have an under-
lying structure and that messages belong to cate-
gories. However, they operate in a different do-
main, which makes their goals and methods dif-
ferent from ours.
Our work is most closely related to that of Back-
strom et al (2013) which introduced the re-entry
prediction task ?predicting whether a user who
has participated in a thread will later contribute
another comment to it. While seemingly related,
their prediction task, focusing on users who have
already commented on a thread, and their algorith-
mic approach are different than ours. Our work
is also very closely related to that of Wang et al
(2013) who predict solvedness ?which predicts
if there is a solution to the original problem posted
in the thread. Like us, they believe that category
of posts can assist in the prediction task, however,
possibly owing to the complexity of general dis-
cussion forums, they had to manually create and
annotate data with a sophisticated taxonomy. We
do not make such assumptions.
The work presented in (G?omez et al, 2008;
1502
Liben-Nowell and Kleinberg, 2008; Kumar et al,
2010; Golub and Jackson, 2010; Wang et al,
2011; Aumayr et al, 2011) discuss characteriz-
ing threads using reply-graphs (often trees) and
learning this structure. However, this representa-
tion is not natural for the MOOC domain where
discussions are relatively more focused on the
thread topic and are better organized using sec-
tions within the forums.
Although most prior work focuses on discus-
sion forums of social media sites such as Twitter
or Facebook, where the dynamics of interaction is
very different from MOOCs, a small number of
recent work address the unique MOOC setting.
Stump et al (2013) propose a framework for
categorizing forum posts by designing a taxonomy
and annotating posts manually to assist general fo-
rum analysis. Our model learns categories in a
data-driven manner guided by the binary super-
vision (intervention decision) and serves a differ-
ent purpose. Nevertheless, in Sec. 4.3 we compare
the categories learnt by our models with those pro-
posed by Stump et al (2013).
Apart from this, recent works have looked into
interesting challenges in this domain such as bet-
ter peer grading models (Piech et al, 2013), code
review (Huang et al, 2013; Nguyen et al, 2014),
improving student engagement (Anderson et al,
2014) and understanding how students learn and
code (Piech et al, 2012; Kizilcec et al, 2013;
Ramesh et al, 2013).
3 Intervention Prediction Models
In this section, we explain our models in detail.
3.1 Problem Setting
In our description it is assumed that a discus-
sion board is organized into multiple forums (rep-
resenting topics such as ?Assignment?, ?Study
Group? etc.). A forum consists of multiple
threads. Each thread (t) has a title and consists of
multiple posts (p
i
). Individual posts do not have
a title and the number of posts varies dramatically
from one thread to another. We address the prob-
lem of predicting if the course instructor would in-
tervene on a thread, t. The instructor?s decision to
intervene, r, equals 0 when the instructor doesn?t
reply to the thread and 1 otherwise. The individual
posts are not assumed to be labeled with any cat-
egory and the only supervision given to the model
during training is in form of intervention decision.
3.2 Logistic Regression (LR)
Our first attempt at solving this problem involved
training a logistic regression for the binary predic-
tion task which models P (r|t).
3.2.1 Feature Engineering
Our logistic regression model uses the follow-
ing two types of features: Thread only features
and Aggregated post features. ?Thread only fea-
tures? capture information about the thread such
as when, where, by who was the thread posted and
lexical features based on the title of the thread.
While these features provide a high-level infor-
mation about the thread, it is also important to
analyze the contents of the posts of the thread.
In order to maintain a manageable feature space,
we compress the features from posts and represent
them using our ?Aggregated post features?.
Thread only features:
1. a binary feature indicating if the thread was
started by an anonymous user
2. three binary features indicating whether the
thread was marked as approved, unresolved
or deleted (respectively)
3. forum id in which the thread was posted
4. time when the thread was started
5. time of last posting on the thread
6. total number of posts in the thread
7. a binary feature indicating if the thread title
contains the words lecture or lectures
8. a binary feature indicating if the thread title
contains the words assignment, quiz, grade,
project, exam (and their plural forms)
Aggregated post features:
9. sum of number of votes received by the indi-
vidual posts
10. mean and variance of the posting times of in-
dividual posts in the thread
11. mean of time difference between the post-
ing times of individual posts and the closest
course landmark. A course landmark is the
deadline of an assignment, exam or project.
12. sum of count of occurrences of assessment
related words e.g. grade, exam, assignment,
quiz, reading, project etc. in the posts
13. sum of count of occurrences of words indicat-
ing technical problems e.g. problem, error
14. sum of count of occurrences of thread con-
clusive words like thank you and thank
15. sum of count of occurrences of request, sub-
mit, suggest
1503
h1
h
2
h
n
r ?(t)
p
1
p
2
p
n
T
(a) Linear Chain Markov Model (LCMM)
h
1
h
2
h
n
r ?(t)
p
1
p
2
p
n
T
(b) Global Chain Model (GCM)
Figure 2: Diagrams of the Linear Chain Markov
Model (LCMM) and the Global Chain Model
(GCM). p
i
, r and ?(t) are observed and h
i
are the
latent variables. p
i
and h
i
represent the posts of
the thread and their latent categories respectively;
r represents the instructor?s intervention and ?(t)
represent the non-structural features used by the
logistic regression model.
We had also considered and dropped (because
of no performance gain) other features about iden-
tity of the user who started the thread, number
of distinct participants in the thread (an impor-
tant feature used by Backstrom et al (2013)), bi-
nary feature indicating if the first and the last posts
were by the same user, average number of words
in the thread?s posts, lexical features capturing ref-
erences to the instructors in the posts etc.
3.3 Linear Chain Markov Model (LCMM)
The logistic regression model is good at exploit-
ing the thread level features but not the content of
individual posts. The ?Aggregated post features?
attempt to capture this information but since the
number of posts in a thread is variable, these fea-
tures relied on aggregated values. We believe that
considering aggregate values is not sufficient for
the task in hand. As noted before, posts of a thread
are not independent of each other. Instead, they
are arranged chronologically such that a post is
published in reply to the preceding posts and this
For every thread, t, in the dataset:
1. Choose a start state, h
1
, and emit the first
post, p
1
.
2. For every subsequent post, p
i
? i ?
{2 . . . n} :
(a) Transition from h
i?1
to h
i
.
(b) Emit post p
i
.
3. Generate the instructor?s intervention
decision, r, using the last state h
n
and
non-structural features, ?(t).
Figure 3: Instructor?s intervention decision pro-
cess for the Linear Chain Markov Model.
might effect an instructor?s decision to reply. For
example, consider a thread that starts with a ques-
tion. The following posts will be students? attempt
to answer the question or raise further concerns or
comment on previous posts. The instructor?s post,
though a future event, will be a part of this process.
We, therefore, propose to model this complete
process using a linear chain markov model shown
in Fig. 2a. The model abstractly represents the in-
formation from individual posts (p
i
) using latent
categories (h
i
). The intervention decision, r, is
the last step in the chain and thus incorporates in-
formation from the individual posts. It also de-
pends on the thread level features: ?Thread only
features? and the ?Aggregated post features? jointly
represented by ?(t) (also referred to as the non-
structural features). This process is explained in
Fig. 3.
We use hand-crafted features to model the dy-
namics of the generative process. Whenever a la-
tent state emits a post or transits to another latent
state (or to the final intervention decision state),
emission and transition features get fired which are
then multiplied by respective weights to compute
a thread?s ?score?:
f
w
(t, p) = max
h
[w ? ?(p, r, h, t)] (1)
Note that the non-structural features, ?(t), also
contribute to the final score.
3.3.1 Learning and Inference
During training we maximize the combined scores
of all threads in the dataset using a generic EM
style algorithm. The supervision in this model is
provided only in form of the observed interven-
tion decision, r and the post categories, h
i
are hid-
1504
den. The model uses the pseudocode shown in Al-
gorithm 1 to iteratively refine the weight vectors.
In each iteration, the model first uses viterbi algo-
rithm to decode thread sequences with the current
weights w
t
to find optimal highest scoring latent
state sequences that agree with the observed in-
tervention state (r = r
?
). In the next step, given
the latent state assignments from the previous step,
a structured perceptron algorithm (Collins, 2002)
is used to update the weights w
t+1
using weights
from the previous step, w
t
, initialization.
Algorithm 1 Training algorithm for LCMM
1: Input: Labeled data D = {(t, p, r)
i
}
2: Output: Weights w
3: Initialization: Set w
j
randomly, ?j
4: for t : 1 to N do
5:
?
h
i
= argmax
h
[w
t
? ?(p, r, h, t)] such
that r = r
i
?i
6: w
t+1
= StructuredPerceptron(t, p,
?
h, r)
7: end for
8: return w
While testing, we use the learned weights and
viterbi decoding to compute the intervention state
and the best scoring latent category sequence.
3.3.2 Feature Engineering
In addition to the ?Thread Only Features? and the
?Aggregated post features?, ?(t) (Sec. 3.2.1, this
model uses the following emission and transition
features:
Post Emission Features:
1. ?(p
i
, h
i
) = count of occurrences of question
words or question marks in p
i
if the state is
h
i
; 0 otherwise.
2. ?(p
i
, h
i
) = count of occurrences of thank
words (thank you or thanks) in p
i
if the state
is h
i
; 0 otherwise.
3. ?(p
i
, h
i
) = count of occurrences of greeting
words (e.g. hi, hello, good morning, welcome
etc ) in p
i
if the state is h
i
; 0 otherwise.
4. ?(p
i
, h
i
) = count of occurrences of assess-
ment related words (e.g. grade, exam, assign-
ment, quiz, reading, project etc.) in p
i
if the
state is h
i
; 0 otherwise.
5. ?(p
i
, h
i
) = count of occurrences of request,
submit or suggest in p
i
if the state is h
i
; 0
otherwise.
6. ?(p
i
, h
i
) = log(course duration/t(p
i
)) if the
state is h
i
; 0 otherwise. Here t(p
i
) is the dif-
ference between the posting time of p
i
and
the closest course landmark (assignment or
project deadline or exam).
7. ?(p
i
, p
i?1
, h
i
) = difference between posting
times of p
i
and p
i?1
normalized by course
duration if the state is h
i
; 0 otherwise.
Transition Features:
1. ?(h
i?1
, h
i
) = 1 if previous state is h
i?1
and
current state is h
i
; 0 otherwise.
2. ?(h
i?1
, h
i
, p
i
, p
i?1
) = cosine similarity be-
tween p
i?1
and p
i
if previous state is h
i?1
and current state is h
i
; 0 otherwise.
3. ?(h
i?1
, h
i
, p
i
, p
i?1
) = length of p
i
if previ-
ous state is h
i?1
, p
i?1
has non-zero question
words and current state is h
i
; 0 otherwise.
4. ?(h
n
, r) = 1 if last post?s state is h
n
and in-
tervention decision is r; 0 otherwise.
5. ?(h
n
, r, p
n
) = 1 if last post?s state is h
n
, p
n
has non-zero question words and intervention
decision is r; 0 otherwise.
6. ?(h
n
, r, p
n
) = log(course duration/t(p
n
)) if
last post?s state is h
n
and intervention deci-
sion is r; 0 otherwise. Here t(p
n
) is the dif-
ference between the posting time of p
n
and
the closest course landmark (assignment or
project deadline or exam).
3.4 Global Chain Model (GCM)
In this model we propose another way of incorpo-
rating the chain structure of a thread. Like the pre-
vious model, this model also assumes that posts
belong to latent categories. It, however, doesn?t
model the instructor?s intervention decision as a
step in the thread generation process. Instead, it
assumes that instructor?s decision to intervene is
dependent on all the posts in the threads, mod-
eled using the latent post categories. This model
is shown in Fig. 2b. Assuming that p represents
posts of thread t, h represents the latent category
assignments, r represents the intervention deci-
sion; feature vector, ?(p, r, h, t), is extracted for
each thread and using the weight vector, w, this
model defines a decision function, similar to what
is shown in Equation 1.
3.4.1 Learning and Inference
Similar to the traditional maximum margin based
Support Vector Machine (SVM) formulation, our
model?s objective function is defined as:
min
w
?
2
||w||
2
+
T
?
j
l(?r
j
f
w
(t
j
, p
j
)) (2)
1505
where ? is the regularization coefficient, t
j
is the
j
th
thread with intervention decision r
j
and p
j
are
the posts of this thread. w is the weight vector, l(?)
is the squared hinge loss function and f
w
(t
j
, p
j
) is
defined in Equation 1.
Replacing the term f
w
(t
j
, p
j
) with the con-
tents of Equation 1 in the minimization objective
above, reveals the key difference from the tradi-
tional SVM formulation - the objective function
has a maximum term inside the global minimiza-
tion problem making it non-convex.
We, therefore, employ the optimization algo-
rithm presented in (Chang et al, 2010) to solve
this problem. Exploiting the semi-convexity prop-
erty (Felzenszwalb et al, 2010), the algorithm
works in two steps, each executed iteratively. In
the first step, it determines the latent variable as-
signments for positive examples. The algorithm
then performs two step iteratively - first it deter-
mines the structural assignments for the negative
examples, and then optimizes the fixed objective
function using a cutting plane algorithm. Once
this process converges for negative examples, the
algorithm reassigns values to the latent variables
for positive examples, and proceeds to the second
step. The algorithm stops once a local minimum
is reached. A somewhat similar approach, which
uses the Convex-Concave Procedure (CCCP) is
presented by (Yu and Joachims, 2009).
At test time, given a thread, t, and it posts, p,
we use the learned weights to compute f
w
(t, p)
and classify it as belonging to the positive class
(instructor intervenes) if f
w
(t, p) ? 0.
3.4.2 Feature Engineering
The feature set used by this model is very sim-
ilar to the features used by the previous model.
In addition to the non-structural features used
by the logistic regression model (Sec. 3.2.1), it
uses all the Post Emission features and the three
transition features represented by ?(h
i?1
, h
i
) and
?(h
i?1
, h
i
, p
i
, p
i?1
) as described in Sec. 3.3.2.
4 Empirical Evaluation
This section describes our experiments.
4.1 Datasets and Evaluation Measure
For our experiments, we have used the forum
content of two MOOCs from different domains
(science and humanities), offered by Coursera
1
,
1
https://www.coursera.org/
a leading education technology company. Both
courses were taught by professors from the Uni-
versity of Maryland, College Park.
Genes and the Human Condition (From Behav-
ior to Biotechnology) (GHC) dataset.
2
This
course was attended by 30,000 students and the
instructional staff comprised of 2 instructors, 3
Teaching Assistants and 56 technical support staff.
The discussion forum of this course consisted of
980 threads composed of about 3,800 posts.
Women and the Civil Rights Movement (WCR)
dataset.
3
The course consisted of a classroom
of about 14,600 students, 1 instructor, 6 Teaching
Assistants and 49 support staff. Its discussion fo-
rum consisted of 800 threads and 3,900 posts.
We evaluate our models on held-out test sets.
For the GHC dataset, the test set consisted of 186
threads out of which the instructor intervened on
24 while, for the WCR dataset, the instructor in-
tervened on 21 out of 155 threads.
Also, it was commonly observed that after an
instructor intervenes on a thread, its posting and/or
viewing behavior increases. We, therefore, only
consider the student posts until the instructor?s first
intervention. Care was also taken to not use fea-
tures that increased/decreased disproportionately
because of the instructor?s intervention such as
number of views or votes of a thread.
In our evaluation we approximate instructor?s
?should reply? instances with those where the in-
structor indeed replied. Unlike general forum
users, we believe that the correlation between the
two scenarios is quite high for instructors. It is
their responsibility to reply, and by choosing to a
MOOC, they have ?bought in? to the idea of forum
participation. The relatively smaller class sizes of
these two MOOCs also ensured that most threads
were manually reviewed, thus reducing instances
of ?missed? threads while retaining the posting be-
havior and content of a typical MOOC.
4.2 Experimental Results
Since the purpose of solving this problem is to
identify the threads which should be brought to
the notice of the instructors, we measure the per-
formance of our models using F-measure of the
positive class. The values of various parameters
were selected using 10-fold Cross Validation on
2
https://www.coursera.org/course/genes
3
https://www.coursera.org/course/
womencivilrights
1506
Model
Genes and the Human Condition (GHC) Women and the Civil Rights (WCR)
P R F P R F
LR 44.44 16.67 24.24 66.67 15.38 25.00
J48 45.50 20.80 28.55 25.00 23.10 24.01
LCMM 33.33 29.17 31.11 42.86 23.08 30.00
GCM 60.00 25.00 35.29 50.00 18.52 27.03
Table 1: Held-out test set performances of chain models, LCMM and GCM, are better than that of the
unstructured models, LR and J48.
Figure 4: Visualization of lexical contents of the
categories learnt by our model from the GHC
dataset. Each row is a category and each column
represents a feature vector. Bright cream color
represents high values while lower values are rep-
resented by darker shades. Dark beige columns
are used to better separate the five feature clusters,
F1-F5, which represent words that are common in
thanking, logistics-related, introductory, syllabus
related and miscellaneous posts respectively. Cat-
egories 1,2,3 and 4 are dominated by F2, F4, F1
and F3 respectively indicating a semantic segrega-
tion of posts by our model?s categories.
the training set. Table 1 presents the performances
of the proposed models on the held-out test sets.
We also report performance of a decision tree
(J48) on the test sets for sake of comparison.
We can see that the chain based models, Linear
Chain Markov Model (LCMM) and Global Chain
Model (GCM), outperform the unstructured mod-
els, namely Logistic regression (LR) and Decision
Trees (J48). This validates our hypothesis that us-
ing the post structure results in better modeling of
instructor?s intervention.
The table also reveals that GCM yields high pre-
cision and low recall values, which is possibly due
to the model being more conservative owing to in-
formation from all posts of the thread.
4.3 Visual Exploration of Categories
Our chain based models assume that posts belong
to different (latent) categories and use these cate-
gories to make intervention predictions. Since this
process of discovering categories is data driven, it
would be interesting to examine the contents of
these categories. Fig. 4 presents a heat map of
lexical content of categories identified by LCMM
from the GHC dataset. The value of H (num-
ber of categories) was set to be 4 and was pre-
determined during the model selection procedure.
Each row of the heat map represents a category
and the columns represent values of individual fea-
tures, f(w, c), defined as: f(w, c) =
C(w,c)
<C(w,c)>
where, C(w, c) is total count of occurrences of a
word, w, in all posts assigned to category, c and
< C(w, c) > represents its expected count based
on its frequency in the dataset. While the actual
size of vocabulary is huge, we use only a small
subset of words in our feature vector for this visu-
alization. These feature values, after normaliza-
tion, are represented in the heat map using col-
ors ranging from bright cream (high value) to dark
black (low value). The darker the shade of a cell,
the lower is the value represented by it.
For visual convenience, the features are man-
ually clustered into five groups (F1 to F5) each
separated by a dark beige colored column in the
heat map. The first column of the heat map rep-
resents the F1 group which consists of words like
thank you, thanks etc. These words are character-
istic of posts that mark either the conclusion of a
resolved thread or are posted towards the end of
the course. Rows corresponding to the category 3
in Table 2 show two examples of such posts. Simi-
larly, F2 represents the features related to logistics
of the course and F3 captures introductory posts
by new students. Finally, F4 contains words that
are closely related to the subfield of gene and hu-
man conditions and would appear in posts that dis-
cuss specific aspects or chapters of the course con-
1507
tents, while F5 contains general buzz words that
would appear frequently in any biology course.
Analyzing individual rows of the heat map, we
can see that out of F1 to F4, Categories 1, 2, 3 and
4 are dominated by logistics (F2), course content
related (F4), thank you (F1) and introductory posts
(F3) respectively, represented by bright colors in
their respective rows. We also observe similar cor-
relations while examining the columns of the heat
map. Also, F5, which contains words common to
the gene and human health domain, is scattered
across multiple categories. For example, dna/rna
and breeding are sufficiently frequent in category
1 as well as 2.
Table 2 gives examples of representative posts
from the four clusters. Due to space constraints,
we show only part of the complete post. We can
see that these examples agree with our observa-
tions from the heat map.
Furthermore, as noted in Sec. 2, we compare
the semantics of clusters learnt by our models with
those proposed by Stump et al (2013) even though
the two categorizations are not directly compara-
ble. Nevertheless, generally speaking, our cate-
gory 1 corresponds to Stump et al (2013)?s Course
structure/policies and category 2 corresponds to
Content. Interestingly, categories 3 and 4, which
represent valedictory and introductory posts, cor-
respond to a single Social/affective from the previ-
ous work.
We can, therefore, conclude that the model, in-
deed splits the posts into categories that look se-
mantically coherent to the human eyes.
4.4 Choice of Number of Categories
Our chain based models, assigning forum posts to
latent categories, are parameterized with H , the
number of categories. We therefore, study the sen-
sitivity of our models to this parameter. Fig. 5,
plots the 10-fold cross validation performance of
the models with increasing values ofH for the two
datasets. Interestingly, the sensitivity of the two
models to the value of H is very different.
The LCMM model?s performance fluctuates as
the value of H increases. The initial performance
improvement might be due to an increase in the ex-
pressive power of the model. Performance peaks
at H = 4 and then decreases, perhaps owing to
over-fitting of the data.
In contrast, GCM performance remains steady
for various values of H which might be attributed
(a) Genes and the Human Condition dataset
(b) Women and the Civil Rights Movement dataset
Figure 5: Cross validation performances of the
two models with increasing number of categories.
to the explicit regularization coefficient which
helps combat over-fitting, by encouraging zero
weights for unnecessary categories.
4.5 How important are linguistic features?
We now focus on the structure independent fea-
tures and experiment with their predictive value,
according to types. We divide the features used by
the LR into the following categories:
4
? Full: set of all features (feature no. 1 to 15)
? lexical: based on content of thread titles and
posts (feature no. 7 to 8 and 12 to 13)
? landmark: based on course landmarks (e.g,
exams, quizzes) information (feature no. 11)
? MOOCs-specific: features specific to the
MOOCs domain (lexical + landmark fea-
tures)
? post: based only on aggregated posts infor-
mation (feature no. 9 to 15)
? temporal: based on posting time patterns
(feature no. 4, 5 and 10)
Fig. 6 shows 10-fold cross validation F-measure
of the positive class for LR when different types of
features are excluded from the full set.
The figure reveals that the MOOCs-specific
features (purple bar) are important for both the
datasets indicating a need for designing special-
ized models for forums analysis in this domain.
4
Please refer to Sec 3.2.1 for description of the feature id.
1508
Category Example posts
1 ?I?m having some issues with video playback. I have downloaded the videos to my laptop...?
1 ?There was no mention of the nuclear envelope in the Week One lecture, yet it was in the quiz. Is this a mistake??
2 ?DNA methylation is a crucial part of normal development of organisms and cell differentiation in higher organisms...?
2 ?In the lecture, she said there are...I don?t see how tumor-suppressor genes are a cancer group mutation.?
3 ?Thank you very much for a most enjoyable and informative course.?
3 ?Great glossary! Thank you!?
4 ?Hello everyone, I?m ... from the Netherlands. I?m a life science student.
4 ?Hi, my name is ... this is my third class with coursera?
Table 2: Representative posts from the four categories learnt by our model. Due to space and privacy
concerns we omit some parts of the text, indicated by ?. . . ?.
(a) Genes and the Human Condition dataset
(b) Women and the Civil Rights Movement dataset
Figure 6: Cross validation performances of the
various feature types for the two datasets.
Also, lexical features (red bar) and post features
(blue bar) have pretty dramatic effects in GHC and
WCR data respectively.
Interestingly, removing the landmark feature set
(green bar) causes a considerable drop in predic-
tive performance, even though it consists of only
one feature. Other temporal features (orange bar)
also turn out to be important for the prediction.
From a separate instructor activity vs time graph
(not shown due to space constraints), we observed
that instructors tend to get more active as the
course progresses and their activity level also in-
creases around quizzes/exams deadlines.
We can, therefore, conclude that all feature
types are important and that lexical as well as
MOOC specific analysis is necessary for model-
ing instructor?s intervention.
5 Conclusion
One of the main challenges in MOOCs is man-
aging student-instructor interaction. The massive
scale of these courses rules out any form of per-
sonalized interaction, leaving instructors with the
need to go over the forum discussions, gauge stu-
dent reactions and selectively respond when ap-
propriate. This time consuming and error prone
task stresses the need for methods and tools sup-
plying this actionable information automatically.
This paper takes a first step in that direction,
and formulates the novel problem of predicting in-
structor intervention in MOOC discussion forums.
Our main technical contribution is to construct
predictive models combining information about
forum post content and posting behavior with in-
formation about the course and its landmarks.
We propose three models for addressing the
task. The first, a logistic regression model is
trained on thread level and aggregated post fea-
tures. The other two models take thread structure
into account when making the prediction. These
models assume that posts can be represented by
categories which characterize post content at an
abstract level, and treat category assignments as
latent variables organized according to, and influ-
enced by, the forum thread structure.
Our experiments on forum data from two differ-
ent Coursera MOOCs show that utilizing thread
structure is important for predicting instructor?s
behavior. Furthermore, our qualitative analysis
shows that our latent categories are semantically
coherent to human eye.
1509
References
Ashton Anderson, Daniel P. Huttenlocher, Jon M.
Kleinberg, and Jure Leskovec. 2014. Engaging with
massive online courses. In WWW, pages 687?698.
Yoav Artzi, Patrick Pantel, and Michael Gamon. 2012.
Predicting responses to microblog posts. In Pro-
ceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ?12, pages 602?606, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Erik Aumayr, Jeffrey Chan, and Conor Hayes. 2011.
Reconstruction of threaded conversations in online
discussion forums. In Lada A. Adamic, Ricardo A.
Baeza-Yates, and Scott Counts, editors, ICWSM.
The AAAI Press.
Lars Backstrom, Jon Kleinberg, Lillian Lee, and Cris-
tian Danescu-Niculescu-Mizil. 2013. Characteriz-
ing and curating conversation threads: Expansion,
focus, volume, re-entry. In Proceedings of the Sixth
ACM International Conference on Web Search and
Data Mining, WSDM ?13, pages 13?22, New York,
NY, USA. ACM.
Eytan Bakshy, Jake M. Hofman, Winter A. Mason, and
Duncan J. Watts. 2011. Everyone?s an influencer:
Quantifying influence on twitter. In Proceedings of
the Fourth ACM International Conference on Web
Search and Data Mining, WSDM ?11, pages 65?74,
New York, NY, USA. ACM.
Prakhar Biyani, Cornelia Caragea, and Prasenjit Mitra.
2013. Predicting subjectivity orientation of online
forum threads. In CICLing (2), pages 109?120.
Rose Catherine, Rashmi Gangadharaiah, Karthik
Visweswariah, and Dinesh Raghu. 2013. Semi-
supervised answer extraction from discussion fo-
rums. In Proceedings of the Sixth International Joint
Conference on Natural Language Processing, pages
1?9, Nagoya, Japan, October. Asian Federation of
Natural Language Processing.
Ming-Wei Chang, Dan Goldwasser, Dan Roth, and
Vivek Srikumar. 2010. Discriminative learning over
constrained latent representations. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, HLT ?10, pages 429?
437, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Snigdha Chaturvedi, Vittorio Castelli, Radu Florian,
Ramesh M. Nallapati, and Hema Raghavan. 2014.
Joint question clustering and relevance prediction
for open domain non-factoid question answering. In
Proceedings of the 23rd International Conference on
World Wide Web, WWW ?14, pages 503?514, Re-
public and Canton of Geneva, Switzerland. Interna-
tional World Wide Web Conferences Steering Com-
mittee.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 Conference on Empirical Methods in
Natural Language Processing - Volume 10, EMNLP
?02, pages 1?8, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Munmun De Choudhury, Hari Sundaram, Ajita John,
and Dor?ee Duncan Seligmann. 2009. What makes
conversations interesting? themes, participants and
consequences of conversations in online social me-
dia. In 18th International World Wide Web Confer-
ence (WWW), pages 331?331, April.
Mark Edmundson. 2012. The trouble with online edu-
cation, July 19. http://www.nytimes.com/
2012/07/20/opinion/the-trouble-
with-online-education.html.
Pedro F. Felzenszwalb, Ross B. Girshick, David
McAllester, and Deva Ramanan. 2010. Object
detection with discriminatively trained part-based
models. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 32(9):1627?1645.
Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa
Milic-Frayling. 2007. Improving the classifica-
tion of newsgroup messages through social network
analysis. In Proceedings of the Sixteenth ACM Con-
ference on Conference on Information and Knowl-
edge Management, CIKM ?07, pages 877?880, New
York, NY, USA. ACM.
Dan Goldwasser and Hal Daum?e III. 2014. ?I object!?
modeling latent pragmatic effects in courtroom di-
alogues. European Chapter of the Association for
Computational Linguistics (EACL), April. To ap-
pear.
Benjamin Golub and Matthew O. Jackson. 2010. See-
ing only the successes: The power of selection bias
in explaining the structure of observed internet dif-
fusions.
Vicenc? G?omez, Andreas Kaltenbrunner, and Vicente
L?opez. 2008. Statistical analysis of the social net-
work and discussion threads in slashdot. In Proceed-
ings of the 17th International Conference on World
Wide Web, WWW ?08, pages 645?654, New York,
NY, USA. ACM.
Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Ex-
tracting chatbox knowledge from online discussion
forums. In Proceedings of the 20th International
Joint Conference on Artifical Intelligence, IJCAI?07,
pages 423?428, San Francisco, CA, USA. Morgan
Kaufmann Publishers Inc.
Jonathan Huang, Chris Piech, Andy Nguyen, and
Leonidas J. Guibas. 2013. Syntactic and functional
variability of a million code submissions in a ma-
chine learning mooc. In AIED Workshops.
1510
Minwoo Jeong, Chin-Yew Lin, and Gary Geunbae Lee.
2009. Semi-supervised speech act recognition in
emails and forums. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 3 - Volume 3, EMNLP
?09, pages 1250?1259, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Ren?e F. Kizilcec, Chris Piech, and Emily Schnei-
der. 2013. Deconstructing disengagement: analyz-
ing learner subpopulations in massive open online
courses. In LAK, pages 170?179.
Jon M. Kleinberg. 2013. Computational perspectives
on social phenomena at global scales. In Francesca
Rossi, editor, IJCAI. IJCAI/AAAI.
Ravi Kumar, Mohammad Mahdian, and Mary McGlo-
hon. 2010. Dynamics of conversations. In Pro-
ceedings of the 16th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, KDD ?10, pages 553?562, New York, NY, USA.
ACM.
Haewoon Kwak, Changhyun Lee, Hosung Park, and
Sue Moon. 2010. What is twitter, a social network
or a news media? In Proceedings of the 19th In-
ternational Conference on World Wide Web, WWW
?10, pages 591?600, New York, NY, USA. ACM.
K. Lerman and R. Ghosh. 2010. Information conta-
gion: An empirical study of the spread of news on
digg and twitter social networks. In Proceedings of
4th International Conference on Weblogs and Social
Media (ICWSM).
David Liben-Nowell and Jon Kleinberg. 2008. Trac-
ing the flow of information on a global scale using
Internet chain-letter data. Proceedings of the Na-
tional Academy of Sciences, 105(12):4633?4638, 25
March.
Andy Nguyen, Christopher Piech, Jonathan Huang,
and Leonidas J. Guibas. 2014. Codewebs: scalable
homework search for massive open online program-
ming courses. In WWW, pages 491?502.
Chris Piech, Mehran Sahami, Daphne Koller, Steve
Cooper, and Paulo Blikstein. 2012. Modeling how
students learn to program. In SIGCSE, pages 153?
160.
Chris Piech, Jonathan Huang, Zhenghao Chen, Chuong
Do, Andrew Ng, and Daphne Koller. 2013. Tuned
models of peer assessment in MOOCs. In Proceed-
ings of The 6th International Conference on Educa-
tional Data Mining (EDM 2013).
Arti Ramesh, Dan Goldwasser, Bert Huang, Hal
Daum?e III, and Lise Getoor. 2013. Modeling
learner engagement in moocs using probabilistic soft
logic. In NIPS Workshop on Data Driven Education.
Daniel M. Romero, Brendan Meeder, and Jon Klein-
berg. 2011. Differences in the mechanics of in-
formation diffusion across topics: Idioms, political
hashtags, and complex contagion on twitter. In Pro-
ceedings of the 20th International Conference on
World Wide Web, WWW ?11, pages 695?704, New
York, NY, USA. ACM.
Glenda S. Stump, Jennifer DeBoer, Jonathan Whit-
tinghill, and Lori Breslow. 2013. Development of a
framework to classify mooc discussion forum posts:
Methodology and challenges.
Manos Tsagkias, Wouter Weerkamp, and Maarten
de Rijke. 2009. Predicting the volume of com-
ments on online news stories. In Proceedings of the
18th ACM Conference on Information and Knowl-
edge Management, CIKM ?09, pages 1765?1768,
New York, NY, USA. ACM.
Yi-Chia Wang, Mahesh Joshi, and Carolyn Penstein
Ros. 2007. A feature based approach to leveraging
context for classifying newsgroup style discussion
segments. In John A. Carroll, Antal van den Bosch,
and Annie Zaenen, editors, ACL. The Association
for Computational Linguistics.
Hongning Wang, Chi Wang, ChengXiang Zhai, and Ji-
awei Han. 2011. Learning online discussion struc-
tures by conditional random fields. In Proceedings
of the 34th International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, SIGIR ?11, pages 435?444, New York, NY,
USA. ACM.
Chunyan Wang, Mao Ye, and Bernardo A. Huberman.
2012. From user comments to on-line conversa-
tions. In Proceedings of the 18th ACM SIGKDD
International Conference on Knowledge Discovery
and Data Mining, KDD ?12, pages 244?252, New
York, NY, USA. ACM.
Li Wang, Su Nam Kim, and Timothy Baldwin. 2013.
The utility of discourse structure in forum thread re-
trieval. In AIRS, pages 284?295.
Tae Yano and Noah A. Smith. 2010. What?s worthy of
comment? content and comment volume in political
blogs. In William W. Cohen and Samuel Gosling,
editors, ICWSM. The AAAI Press.
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In
Proceedings of the 26th Annual International Con-
ference on Machine Learning, ICML ?09, pages
1169?1176, New York, NY, USA. ACM.
1511
