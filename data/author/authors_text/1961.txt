Non-Contiguous Word Sequences for Information Retrieval
Antoine Doucet and Helena Ahonen-Myka
Department of Computer Science
P.O. Box 26 (Teollisuuskatu 23)
FIN-00014 University of Helsinki,
Finland,
Antoine.Doucet@cs.helsinki.fi, Helena.Ahonen-Myka@cs.helsinki.fi
Abstract
The growing amount of textual information
available electronically has increased the need
for high performance retrieval. The use of
phrases was long seen as a natural way to im-
prove retrieval performance over the common
document models that ignore the sequential as-
pect of word occurrences in documents, consid-
ering them as ?bags of words?. However, both
statistical and syntactical phrases showed disap-
pointing results for large document collections.
In this paper we present a recent type of
multi-word expressions in the form of Maxi-
mal Frequent Sequences (Ahonen-Myka, 1999).
Mined phrases rather than statistical or syntac-
tical phrases, their main strengths are to form
a very compact index and to account for the
sequentiality and adjacency of meaningful word
co-occurrences, by allowing for a gap between
words.
We introduce a method for using these
phrases in information retrieval and present our
experiments. They show a clear improvement
over the well-known technique of extracting fre-
quent word pairs.
1 Introduction
The constantly growing number of electronic
documents increases the need for high perfor-
mance retrieval, the precision of a system being
the percentage of relevant documents among the
total number of hits returned to a query.
Most information retrieval systems do not ac-
count for word order in a document. However,
we can assume that there must exist a way to ac-
count for word order, which permits to improve
retrieval performance. Zhai et al (1997) men-
tion many problems due the use of single word
terms only. They observe that some word asso-
ciations have a totally different meaning of the
?sum? of the meanings of the words that com-
pose them (e.g., ?hot dog? is usually not used
to refer to a warm dog !). Other lexical units
pose similar problems (e.g., ?kick the bucket?).
Work on the use of phrases in IR has been car-
ried out for more than 25 years. Early results
were very promising. However, unexpectedly,
the constant growth of test collections caused
a drastic fall in the quality of the results. In
1975, Salton et al (1975) show an improve-
ment in average precision over 10 recall points
between 17% and 39%. In 1989, Fagan (1989)
reiterated the exact same experiments with a 10
Mb collection and obtained improvements from
11% to 20%. This negative impact of the col-
lection size was lately confirmed by Mitra et al
(1987) over a 655 Mb collection, improving the
average precison by only one percent ! Turpin
and Moffat (1999) revisited and extended this
work to obtain improvements between 4% and
6%.
A conclusion of this related work is that
phrases improve results in low levels of recall,
but are globally inefficient for the n first ranked
documents. According to Mitra et al (1987),
this low benefit from phrases to the best an-
swers is explained by the fact that phrases pro-
mote documents that deal with only one aspect
of possibly multi-faceted queries. For example,
a topic of TREC-4 is about ?problems associ-
ated with pension plans, such as fraud, skim-
ming, tapping or raiding?. Several top-ranked
documents discuss pension plans, but no related
problem. Mitra et al (1987) term this problem
as one of inadequate query coverage.
In our opinion, this does not contradict the
idea that adding document descriptors account-
ing for word order must permit to improve the
performance of IR systems. But related work
shows the need for another way to combine
phrase and word term descriptors (Smeaton and
Kelledy, 1998) and even more the fact that the
phrases currently used to model documents are
not well suited for that.
In the next section, we will briefly describe
Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 88-95
the vector space model (sometimes quoted as
?bag of words?, for it simply ignores words? po-
sitions). We will then describe the different
types of phrases used in related work (section
3). In section 4, we define our own phrases
(maximal frequent sequences) and explain how
they will be better document descriptors than
those found in the state of the art. In section 5,
we present a technique to incorporate maximal
frequent sequences into document indexing and
query processing, so as to properly take advan-
tage of this extra information in an information
retrieval framework. In section 6, we present
our experiments and results, before we conclude
the paper in section 7.
2 Vector Space Model
2.1 Preprocessing
The first step of the process is to clean the data.
A way to do this consists in skipping a set of
words that are considered least informative, the
stopwords. We also discarded all words of small
size (less than three characters).
We then reduced each word to its stem us-
ing the Porter algorithm (Porter, 1980). For
example, the words ?models?, ?modelling? and
?modeled? are all stemmed to ?model?. This
technique for reducing words to their root per-
mits to further reduce the number of word
terms.
This feature selection phase brings more com-
putational comfort for the next steps since it
greatly reduces the size of the document collec-
tion representation in the vector space model
(the dimension of the vector space).
2.2 Vector Space Model
The set of the distinct remaining word stems
W is used to represent the document collec-
tion within the vector space model. Each docu-
ment is represented by a ?W?-dimensional vec-
tor filled in with a weight standing for the im-
portance of each word token with respect to that
document. To calculate this weight, we use a tf-
normalized version of the ?tfc? term-weighted
components as described by Salton and Buck-
ley (1988), i.e.:
tfidfw =
tfw ? log Nnw
max(tf) ?
?
?
wi?W
(
tfwi ? log
N
nwi
)2
,
where tfw is the term frequency of the word
w. N is the total number of documents in the
collection and nw the number of documents in
which w occurs.
3 The use of phrases in IR
There are various ways to incorporate phrases
in the document modeling. The usual technique
is to consider phrases as supplementary terms
of the vector space, with the same technique
as for word terms. In other words, phrases are
thrown into the bag of words. However, Strza-
lkowski and Carballo (1996) argue that using
a standard weighting scheme is inappropriate
for mixed feature sets (such as single words and
phrases). The weight given to least frequent
phrases is considered too low. Their specificity
is nevertheless often crucial in order to deter-
mine the relevance of a document (Lahtinen,
2000). In weighting the phrases, the interde-
pendency between a phrase and the words that
compose it is another difficult issue to account
for Strzalkowski et al (1998).
There are two main types of phrases: statisti-
cal phrases, formed by straight word occurrence
counts, and syntactical phrases.
Statistical Phrases. Mitra et al (1987)
form a statistical phrase for each pair of 2
stemmed adjacent words that occur in at least
25 documents of the TREC-1 collection. The
selected pairs are then sorted in lexicograph-
ical order. In this technique, we see 2 prob-
lems. First, this lexicographical sorting means
to ignore crucial information about word pairs:
their order of occurrence ! This is equivalent
to saying that AB is identical to BA. Further-
more, no gap is allowed, although it is frequent
to represent the same concept by adding at least
one word between two others. For example,
this definition of a phrase does not permit to
note any similarity between the two text frag-
ments ?XML document retrieval? and ?XML
retrieval?. This model is thus quite far from
natural language.
Syntactical Phrases. The technique pre-
sented by Mitra et al (1987) for extracting
syntactical phrases is based on a parts-of-speech
analysis (POS) of the document collection. A
set of tag sequence patterns are predefined to
be recognized as useful phrases. All maximal
sequences of words accepted by this grammar
form the set of syntactical phrases. For exam-
ple, a sequence of words tagged as ?verb, car-
dinal number, adjective, adjective, noun? will
constitute a syntactical phrase of size 5. Every
sub-phrase occurring in this same order is also
generated, with an unlimited gap (e.g., the pair
?verb, noun? is also generated). This technique
offers a sensible representation of natural lan-
guage. Unfortunately, to obtain the POS of a
whole document collection is very costful. The
index size is another issue, given that all phrases
are stored, regardless of their frequency. In the
experiments, the authors indeed admit to cre-
ating no index a priori, but instead that the
phrases were generated according to each query.
This makes the process tractable, but implies
very slow answers from the retrieval system, and
quite a long wait for the end user.
On top of computational problems, we see a
few further issues. First, the lack of a mini-
mal frequency threshold to reduce the number
of phrases in the index. This means that unfre-
quent phrases are taking up most of the space,
and have a big influence on the results, whereas
their low frequency may simply illustrate an in-
adequate use or a typographical error. To al-
low an illimited gap so as to generate subpairs
is dangerous as well: the phrase ?I like to eat
hot dogs? will generate the subpair ?hot dogs?,
but it will also generate the subpair ?like dogs?,
whose semantical meaning is very far from that
of the original sentence.
Other types of phrases. Many efficient
techniques exist to extract multiword ex-
pressions, collocations, lexical units and id-
ioms (Church and Hanks, 1989; Smadja, 1993;
Dias et al, 2000; Dias, 2003). Unfortunately,
very few have been applied to information re-
trieval with a deep evaluation of the results.
Maximal Frequent Sequences. We pro-
pose Maximal Frequent Sequences (MFS) as a
new alternative to account for word ordering in
the modeling of textual documents. One of their
strength is the fact that they are extracted if
and only if they occur more often than a given
frequency threshold, which hopefully permits
to avoid storing the numerous least significant
phrases. A gap between words is allowed within
the extraction process itself, permitting to deal
with a larger variety of language.
4 Maximal Frequent Sequences
In our approach, we represent documents by
word features within the vector space model,
and by Maximal Frequent Sequences, account-
ing for the sequential aspect of text. For each
of those two representations, a Retrieval Sta-
tus Value (RSV) is computed. Those values are
later combined to form a single RSV per docu-
ment.
4.1 Definition and Extraction
Technique
MFS are sequences of words that are frequent
in the document collection and, moreover, that
are not contained in any other longer frequent
sequence. Given a frequency threshold ?, a se-
quence is considered to be frequent if it appears
in at least ? documents.
Ahonen-Myka (1999) presents an algorithm
combining bottom-up and greedy methods,
which permits to extract maximal sequences
without considering all their frequent subse-
quences. This is a necessity, since maximal fre-
quent sequences in documents may be rather
long.
Nevertheless, when we tried to extract the
maximal frequent sequences from the collection
of documents, their number and the total num-
ber of word features in the collection did pose a
clear computational problem and did not actu-
ally permit to obtain any result.
To bypass this complexity problem, we de-
composed the collection of documents into sev-
eral disjoint subcollections, small enough so
that we could efficiently extract the set of max-
imal frequent sequences of each subcollection.
Joining all the sets of MFS?, we obtained an ap-
proximate of the maximal frequent sequence set
for the full collection.
We conjecture that more consistent subcol-
lections permit to obtain a better approxima-
tion. This is due to the fact that maximal fre-
quent sequences are formed from similar text
fragments. Accordingly, we formed the subcol-
lection by clustering similar documents together
using the well-known k-means algorithm (see for
example Willett (1988) or Doucet and Ahonen-
Myka (2002)).
4.2 Main Strengths of the Maximal
Frequent Sequences
The method efficiently extracts all the maxi-
mal frequent word sequences from the collec-
tion. From the definitions above, a sequence is
said to be maximal if and only if no other fre-
quent sequence contains that sequence.
Furthermore, a gap between words is allowed:
in a sentence, the words do not have to appear
continuously. A parameter g tells how many
other words two words in a sequence can have
between them. The parameter g usually gets
values between 1 and 3.
For instance, if g = 2, a phrase ?President
Bush? will be found in both of the following
text fragments:
..President of the United States Bush..
..President George W. Bush..
Note: Articles, prepositions and small words
were pruned away during the preprocessing.
This allowance of gaps between words of a
sequence is probably the strongest specificity of
the method, compared to most existing meth-
ods for extracting text descriptors. This greatly
increases the quality of the phrase, since pro-
cessing takes the variety of natural language
into account.
The other powerful specificity of the tech-
nique is the ability to extract maximal frequent
sequences of any length. This permits to ob-
tain a very compact description of documents.
For example, by restricting the length of phrases
to 8, the presence, in the document collection,
of a frequent phrase of 25 words would result
in thousands of phrases representing the same
knowledge as this one maximal sequence.
The result of this extraction is that each doc-
ument of the collection is described by a (pos-
sibly empty) set of MFS.
5 Evaluating Documents
Once documents and queries are represented
within our two models, a way to estimate the
relevance of a document with respect to a query
remains to be found. As mentioned earlier,
we compute two separate RSV values for the
word features vector space model and the MFS
model. In the second step, we aggregate these
two RSVs into one single relevance score for
each document with respect to a query.
5.1 Word features RSV
The vector space model offers a very conve-
nient framework for computing similarities be-
tween documents and queries. Indeed, there
exist a number of techniques to compare two
vectors, Euclidean distance, Jaccard and cosine
similarity being the most frequently used in IR.
We have used cosine similarity because of its
computational efficiency. By normalizing the
vectors, which we did in the indexing phase,
cosine(
??
d1,
??
d2) indeed simplifies to the vector
product (d1 ? d2).
5.2 MFS RSV
The first step is to create an MFS index for
the document collection. Once a set of maxi-
mal frequent sequences has been extracted and
each document is attached to the correspond-
ing phrases, as detailed in the previous section,
it remains to define the procedure to match a
phrase describing a document and a keyphrase
(from a query).
Note that from here onwards, keyphrase de-
notes a phrase found in a query, and maximal
sequence denotes a phrase extracted from a doc-
ument.
Our approach consists in decomposing
keyphrases of the query into pairs. Each of
these pairs is bound to a score representing its
quantity of relevance. Informally speaking, the
quantity of relevance of a word pair tells how
much it makes a document relevant to include
an occurrence of this pair. This value depends
on the specificity of the pair (expressed in terms
of inverted document frequency) and modifiers,
among which is an adjacency coefficient, reduc-
ing the quantity of relevance given to a pair
formed by two words that are not adjacent.
5.2.1 Definitions:
Let D be a collection of N documents and
A1 . . . Am a keyphrase of size m. Let Ai and
Aj be 2 words of A1 . . . Am occurring in this or-
der, and n be the number of documents of the
collection in which AiAj was found. We define
the quantity of relevance of the pair AiAj to be:
Qrel(AiAj) = idf(AiAj , D) ? adj(AiAj),
where idf(AiAj , D) represents the specificity
of AiAj in collection D:
idf(AiAj , D) = log
(
N
n
)
,
and when decomposing the keyphrase
A1 . . . Am into pairs, adj(AiAj) is a score mod-
ifier to penalize word pairs AiAj formed from
non-adjacent words, and d(Ai,Aj) indicates the
number of words appearing between the two
words Ai and Aj (d(Ai,Aj) = 0 signifies that
Ai and Aj are adjacent):
adj(AiAj) =
?
??
??
1, if d(Ai,Aj) = 0
?1, 0 ? ?1 ? 1, if d(Ai,Aj) = 1
?2, 0 ? ?2 ? ?1 if d(Ai,Aj) = 2
. . .
?m?2, 0 ? ?m?2 ? ?m?3, if d(Ai,Aj) = m?2
Accordingly, the larger the distance between
the two words, the lower a quantity of relevance
is attributed to the corresponding pair. In our
runs, we will actually ignore distances higher
than 1 (i.e., (k > 1) ? (?k = 0)).
5.2.2 Example:
For example, ignoring distances above 1, a
keyphrase ABCD is decomposed into 5 tuples
(pair, adjacency coefficient):
(AB, 1), (BC, 1), (CD, 1), (AC, ?1), (BD, ?1)
Let us compare this keyphrase to the doc-
uments d1, d2, d3, d4 and d5, described respec-
tively by the frequent sequences AB, AC, AFB,
ABC and ACB. The corresponding quantities of
relevance brought by the keyphrase ABCD are
shown in table 1. Note that in practice, we lost
the maximality property during the partition-
join step presented in subsection 4.1. Hence,
there can be a frequent sequence AB together
with a frequent sequence ABC, if they were ex-
tracted from two different document clusters.
Assuming equal idf values, we observe that
the quantities of relevance form a coherent
order. The longest matches rank first, and
matches of equal size are untied by adja-
cency. Moreover, non-adjacent matches (AC
and ABC) are not ignored as in many other
phrase representations (Mitra et al, 1987).
5.3 Aggregated RSV
In practice, some queries do not contain any
keyphrase, and some documents do not contain
any MFS. However, there can of course be cor-
rect answers to these queries, and those docu-
ments must be relevant to some queries. Also,
all documents containing the same matching
phrases get the same MFS RSV. Therefore, it is
necessary to find a way to separate them. The
word-based cosine similarity measure is very ap-
propriate for that.
Another natural response would have been to
re-decompose the pairs into single words and
form document vectors accordingly. However,
this would not be satisfying, because the least
frequent words are all missed by the algorithm
for MFS extraction. An even more impor-
tant category of missed words is that of fre-
quent words that do not frequently co-occur
with other words. The loss would be consid-
erable.
This is the reason to compute another RSV
using a basic word-features vector space model.
<Keywords>
"concurrency control"
"semantic transaction management"
"application" "performance benefit"
"prototype" "simulation" "analysis"
</Keywords>
Figure 1: Topic 47
To combine both RSVs to one single score, we
must first make them comparable by mapping
them to a common interval. To do so, we
used Max Norm, as presented by Vogt and Cot-
trell (1998), which permits to bring all positive
scores within the range [0,1]:
New Score =
Old Score
Max Score
Following this normalization step, we aggre-
gate both RSVs using a linear interpolation fac-
tor ? representing the relative weight of scores
obtained with each technique (similarly as in
Marx et al (2002)).
Aggregated Score = ??RSVWord Features+(1??)?RSVMFS
The evidence of experiments with the INEX
2002 collection showed good results when
weighting the single word RSV with the num-
ber of distinct word terms in the query (let a be
that number), and the MFS RSV with the num-
ber of distinct word terms found in keyphrases
of the query (let b be that number). Thus:
? =
a
a+ b
For example, in Figure 1 showing topic 47,
there are 11 distinct word terms and 7 distinct
word terms occurring in keyphrases. Thus, for
this topic, we have ? = 1111+7 .
6 Experiments and Results
We based our experiments on the 494Mb INEX
document collection (Initiative for the Evalu-
ation of XML retrieval1). INEX was created
in 2002 to compensate the lack of an evalua-
tion forum for the XML information retrieval.
This collection consists of 12,107 scientific ar-
ticles written in English from IEEE journals,
combined to a set of queries and correspond-
ing manual assessments. The specificity of this
1available at http://inex.is.informatik.uni-
duisburg.de:2003/
Document MFS Corresponding pairs Matches Quantity of relevance
d1 AB AB AB idf(AB)
d2 ACD AC CD AD AC CD idf(CD) + ?1.idf(AC)
d3 AFB AF FB AB AB idf(AB)
d4 ABC AB BC AC AB BC AC idf(AB) + idf(BC) + ?1.idf(AC)
d5 ACB AC CB AB AC AB idf(AB) + ?1.idf(AC)
Table 1: Quantity of relevance stemming from various indexing phrases w.r.t. a keyphrase query
ABCD
document collection is its rich logical structure
into sections, subsections, paragraphs, lists, etc.
However, in the present experiments, we ignore
this structure and only exploit plain text to re-
turn full articles as our candidate retrieval an-
swers.
The manual assessments indeed tell us which
candidate answers are relevant and which ones
are not. We use these relevance values to com-
pute precision and recall measures, which per-
mit scoring each set of candidate answers, and
equivalently the means by which each set was
obtained. In our experiments, we used average
precision over the n first hits as our main refer-
ence. This evaluation measure was first intro-
duced by Raghavan et al (1989) and was used
as the official evaluation measure in the INEX
2002 campaign (Go?vert et al, 2003).
Protocol of the Experiments. As a base-
line, we computed and evaluated a run using
only single word terms, as detailed in section
2. Our goal was to compare our new tech-
nique to the state of the art. Thus we com-
puted one run using our technique (aggregat-
ing the MFS RSVs and the single word term
RSVs topic-wise, with the weighting scheme
mentioned hereabove), and one run by calcu-
lating all statistical phrases following the defi-
nition of Mitra et al (1987). The only differ-
ence is that we did not set a minimal document
frequency threshold. We made this choice from
the standpoint that our aim was not to mea-
sure efficiency, but the quality of the results.
The corresponding number of features is given
in table 2. We extracted 328,289 MFS of dif-
ferent sizes. Their splitting forms no more than
674,257 pairs (this number is probably lower be-
cause the same pair can be extracted from nu-
merous MFS).
MFS vs. Statistical Phrases. For those
representations, the average precision for the n
first retrieved documents are presented in ta-
ble 3. We learn two things from those results.
Number of Features
Word terms (Baseline) 156,723
Statitiscal Phrases 4,941,051
MFS 674,257
Table 2: Number of feature terms
Weight of the word RSV Words & Stat. Pairs
Topicwise (subsection 5.3.) 0.05825
20% 0.05902
40% 0.05957
60% 0.05843
80% 0.05527
100% 0.05302
Table 4: Average Precision@100 for various lin-
ear combinations
First, the fact that phrases improve results in
lower levels of recall is confirmed, as greater
improvement is obtained when we check fur-
ther down the ranked list. Second, our tech-
nique outperforms that of statistical phrases.
However, as we use different phrases indeed,
but also a different technique to match them
against queries, it remains to find out whether
the improvement stems from the MFS them-
selves, from the way they are used, or from both.
Thus we experimented with various linear
combinations to aggregate the word term RSV
and the statistical phrase RSV. The results are
presented in table 4. The technique of gath-
ering word and pairs features within the same
vector space clearly performs better in this case.
Therefore, the better performance of MFS is not
only due to the aggregation weigthing scheme
presented in subsection 5.3. This underlines
their intrinsic quality as document descriptors.
Word Terms Words and Stat. Phrases Words and MFS
Average Precision@100 0.05302 0.06199 (+16.9%) 0.06713 (+26.6%)
Average Precision@50 0.64419 0.62456 (-3.0%) 0.64411 (-0.0%)
Average Precision@10 0.67101 0.65021 (-3.1%) 0.66293 (-1.2%)
Table 3: Average Precision@n
7 Conclusions
We have introduced a new type of phrases to
the problem of information retrieval. We have
developed and presented a method to use maxi-
mal frequent sequences in information retrieval.
Using the INEX document collection, we com-
pared it to a well-known technique of the state
of the art. Our technique outperformed that
of statistical phrases, known to be perform-
ing comparably to syntactical and linguistical
phrases from the literature.
These results are due to the allowance of a
gap between words forming a sequence, offer-
ing a more realistic model of natural language.
Furthermore, the number of phrases to index is
rather small. A weak spot is the greedy algo-
rithm to extract MFS. But many improvements
are under way on this side, and the partition-
join technique mentioned in subsection 4.1 al-
ready permits to extract good approximations
efficiently.
Our results confirm that the best improve-
ments are obtained at the highest levels of re-
call. Therefore, MFS would be most useful in
the case of exhaustive information needs. Cases
where no relevant information should be missed,
and 100% recall should be reached in a mini-
mal number of hits (their inner ordering being
a less serious matter). Typically, examples of
such information lie in the judicial domain and
in patent searching.
More experiments remain to be done, to find
out whether similar improvements can be ob-
tained from other document collections. The
INEX collection is of scientific articles and con-
sistently uses a terminology of its own. Whether
similar performance would be observed from a
more general document collection such as news-
paper articles has to be verified.
The use of phrases is factual in many lan-
guages, which makes us optimistic regarding
an application of this work to multilingual
document corporas. Thinking of the other
techniques, the gap should give us robustness
against the challenges of multilingualism.
8 Acknowledgements
This work was funded by the Academy of Fin-
land under project 50959: DoReMi - Document
Management, Information Retrieval and Text
Mining.
References
Helena Ahonen-Myka. 1999. Finding All Fre-
quent Maximal Sequences in Text. In Pro-
ceedings of the 16th International Confer-
ence on Machine Learning ICML-99 Work-
shop on Machine Learning in Text Data Anal-
ysis, Ljubljana, Slovenia, pages 11?17. J. Ste-
fan Institute, eds. D. Mladenic and M. Gro-
belnik.
Kenneth W. Church and Patrick Hanks. 1989.
Word association norms, mutual information,
and lexicography. In Proceedings of the 27th
meeting of the Association for Computational
Linguistics (ACL), pages 76?83.
Gae?l Dias, Sylvie Guillore?, Jean-Claude Bas-
sano, and Jose? Gabriel Pereira Lopes. 2000.
Combining linguistics with statistics for mul-
tiword term extraction: A fruitful as-
sociation? In Proceedings of Recherche
d?Informations Assistee par Ordinateur 2000
(RIAO 2000).
G. Dias. 2003. Multiword unit hybrid extrac-
tion. In Workshop on Multiword Expressions
of the 41st ACL meeting. Sapporo. Japan.
A. Doucet and H. Ahonen-Myka. 2002. Naive
clustering of a large xml document collec-
tion. In Proceedings of the First Workshop
of the Initiative for the Evaluation of XML
Retrieval (INEX), pages 81?87, Schloss Dag-
suhl, Germany.
J. L. Fagan. 1989. The effectiveness of a non-
syntactic approach to automatic phrase in-
dexing for document retrieval. Journal of the
American Society for Information Science,
40:115?132.
Norbert Go?vert, Gabriella Kazai, Norbert Fuhr,
and Mounia Lalmas. 2003. Evaluating the ef-
fectiveness of content-oriented XML retrieval.
Technical report, University of Dortmund,
Computer Science 6.
Timo Lahtinen. 2000. Automatic Indexing: an
approach using an index term corpus and
combining linguistic and statistical methods.
Ph.D. thesis, University of Helsinki.
M. Marx, J. Kamps, and M. de Rijke. 2002.
The university of amsterdam at inex.
M. Mitra, C. Buckley, A. Singhal, and
C. Cardie. 1987. An analysis of statisti-
cal and syntactic phrases. In Proceedings
of RIAO97, Computer-Assisted Information
Searching on the Internet, pages 200?214.
M. F. Porter. 1980. An algorithm for suffix
stripping. Program, 14(3):130?137.
V. V. Raghavan, P. Bollmann, and Jung G. S.
1989. A critical investigation of recall and
precision as measures of retrieval system per-
formance. ACM Transactions on Informa-
tion Systems, 7(3):205?229.
G. Salton and C. Buckley. 1988. Term-
weighting approaches in automatic text re-
trieval. Information Processing and Manage-
ment: an International Journal, 24(5):513?
523.
G. Salton, C.S. Yang, and C.T. Yu. 1975. A
theory of term importance in automatic text
analysis. Journal of the American Society for
Information Science, 26:33?44.
F. Smadja. 1993. Retrieving collocations from
text: Xtract. Journal of Computational Lin-
guistics, 19:143?177.
A. F. Smeaton and F. Kelledy. 1998. User-
chosen phrases in interactive query formula-
tion for information retrieval. In Proceedings
of the 20th BCS-IRSG Colloquium.
Tomek Strzalkowski and Jose Perez Carballo.
1996. Natural language information retrieval:
TREC-4 report. In Text REtrieval Confer-
ence, pages 245?258.
Tomek Strzalkowski, Gees C. Stein, G. Bowden
Wise, Jose Perez Carballo, Pasi Tapanainen,
Timo Jarvinen, Atro Voutilainen, and Jussi
Karlgren. 1998. Natural language informa-
tion retrieval: TREC-6 report. In Text RE-
trieval Conference, pages 164?173.
A. Turpin and A. Moffat. 1999. Statistical
phrases for vector-space information retrieval.
In Proceedings of the 22nd ACM SIGIR Con-
ference on Research and Development in In-
formation Retrieval, pages 309?310.
Christopher C. Vogt and Garrison W. Cottrell.
1998. Predicting the performance of linearly
combined IR systems. In Research and Devel-
opment in Information Retrieval, pages 190?
196.
P. Willett. 1988. Recent trends in hierar-
chic document clustering: a critical re-
view. Information Processing and Manage-
ment, 24(5):577?597.
Zhai, Chengxiang, Xiang Tong,
N. Milic Frayling, and Evans D.A. 1997.
Evaluation of syntactic phrase indexing.
In Proceedings of the 5th Text Retrieval
Conference, TREC-5, pages 347?358.
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 243?248,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
?Let Everything Turn Well in Your Wife?:
Generation of Adult Humor Using Lexical Constraints
Alessandro Valitutti
Department of Computer Science
and HIIT
University of Helsinki, Finland
Hannu Toivonen
Department of Computer Science
and HIIT
University of Helsinki, Finland
Antoine Doucet
Normandy University ? UNICAEN
GREYC, CNRS UMR?6072
Caen, France
Jukka M. Toivanen
Department of Computer Science
and HIIT
University of Helsinki, Finland
Abstract
We propose a method for automated gen-
eration of adult humor by lexical replace-
ment and present empirical evaluation re-
sults of the obtained humor. We propose
three types of lexical constraints as build-
ing blocks of humorous word substitu-
tion: constraints concerning the similarity
of sounds or spellings of the original word
and the substitute, a constraint requiring
the substitute to be a taboo word, and con-
straints concerning the position and con-
text of the replacement. Empirical ev-
idence from extensive user studies indi-
cates that these constraints can increase
the effectiveness of humor generation sig-
nificantly.
1 Introduction
Incongruity and taboo meanings are typical ingre-
dients of humor. When used in the proper context,
the expression of contrasting or odd meanings can
induce surprise, confusion or embarrassment and,
thus, make people laugh. While methods from
computational linguistics can be used to estimate
the capability of words and phrases to induce in-
congruity or to evoke taboo meanings, computa-
tional generation of humorous texts has remained
a great challenge.
In this paper we propose a method for auto-
mated generation of adult humor by lexical re-
placement. We consider a setting where a short
text is provided to the system, such as an instant
message, and the task is to make the text funny by
replacing one word in it. Our approach is based
on careful introduction of incongruity and taboo
words to induce humor.
We propose three types of lexical constraints
as building blocks of humorous word substitu-
tion. (1) The form constraints turn the text into
a pun. The constraints thus concern the similarity
of sounds or spellings of the original word and the
substitute. (2) The taboo constraint requires the
substitute to be a taboo word. This is a well-known
feature in some jokes. We hypothesize that the ef-
fectiveness of humorous lexical replacement can
be increased with the introduction of taboo con-
straints. (3) Finally, the context constraints con-
cern the position and context of the replacement.
Our assumption is that a suitably positioned
substitution propagates the tabooness (defined
here as the capability to evoke taboo meanings)
to phrase level and amplifies the semantic con-
trast with the original text. Our second concrete
hypothesis is that the context constraints further
boost the funniness.
We evaluated the above hypotheses empirically
by generating 300 modified versions of SMS mes-
sages and having each of them evaluated by 90
subjects using a crowdsourcing platform. The
results show a statistically highly significant in-
crease of funniness and agreement with the use of
the humorous lexical constraints.
The rest of this paper is structured as follows.
In Section 2, we give a short overview of theoreti-
cal background and related work on humor gener-
ation. In Section 3, we present the three types of
constraints for lexical replacement to induce hu-
mor. The empirical evaluation is presented in Sec-
tion 4. Section 5 contains concluding remarks.
243
2 Background
Humor, Incongruity and Tabooness A set of
theories known as incongruity theory is probably
the most influential approach to the study of hu-
mor and laughter. The concept of incongruity, first
described by Beattie (1971), is related to the per-
ception of incoherence, semantic contrast, or inap-
propriateness, even though there is no precise and
agreed definition. Raskin (1985) formulated the
incongruity concept in terms of script opposition.
This has been developed further, into the Gen-
eral Theory of Verbal Humor (Attardo and Raskin,
1991). A cognitive treatment of incongruity in hu-
mor is described by Summerfelt et al (2010).
One specific form of jokes frequently discussed
in the literature consists of the so called forced
reinterpretation jokes. E.g.:
Alcohol isn?t a problem, it?s a solution...
Just ask any chemist.
In his analysis of forced reinterpretation jokes,
Ritchie (2002) emphasises the distinction between
three different elements of the joke processing:
CONFLICT is the initial perception of incompati-
bility between punchline and setup according to
the initial obvious interpretation; CONTRAST de-
notes the perception of the contrastive connec-
tion between the two interpretations; while INAP-
PROPRIATENESS refers to the intrinsic oddness or
tabooness characterising the funny interpretation.
All three concepts are often connected to the no-
tion of incongruity.
In his integrative approach to humor theories,
Martin (2007) discusses the connection between
tabooness and incongruity resolution. In partic-
ular, he discusses the salience hypothesis (Gold-
stein et al, 1972; Attardo and Raskin, 1991), ac-
cording to which ?the purpose of aggressive and
sexual elements in jokes is to make salient the in-
formation needed to resolve the incongruity?.
Humor Generation In previous research on
computational humor generation, puns are often
used as the core of more complex humorous texts,
for example as punchlines of simple jokes (Raskin
and Attardo, 1994; Levison and Lessard, 1992;
Venour, 1999; McKay, 2002). This differs from
our setting, where we transform an existing short
text into a punning statement.
Only few humor generation systems have been
empirically evaluated. The JAPE program (Bin-
sted et al, 1997) produces specific types of pun-
ning riddles. HAHAcronym (Stock and Strap-
parava, 2002) automatically generates humorous
versions of existing acronyms, or produces a new
funny acronym, starting with concepts provided
by the user. The evaluations indicate statistical
significance, but the test settings are relatively spe-
cific. Below, we will present an approach to eval-
uation that allows comparison of different systems
in the same generation task.
3 Lexical Constraints for Humorous
Word Substitution
The procedure gets as input a segment of English
text (e.g.: ?Let everything turn well in your life!?).
Then it performs a single word substitution (e.g:
?life?? ?wife?), and returns the resulting text. To
make it funny, the word replacement is performed
according to a number of lexical constraints, to be
described below. Additionally, the text can be ap-
pended with a phrase such as ?I mean ?life? not
?wife?.? The task of humor generation is thus re-
duced to a task of lexical selection. The adopted
task for humor generation is an extension of the
one described by Valitutti (2011).
We define three types of lexical constraints for
this task, which will be described next.
3.1 Form Constraints
Form constraints (FORM) require that the original
word and its substitute are similar in form. This
turns the text given as input into a kind of pun,
?text which relies crucially on phonetic similarity
for its humorous effect? (Ritchie, 2005).
Obviously, simply replacing a word potentially
results in a text that induces ?conflict? (and con-
fusion) in the audience. Using a phonetically sim-
ilar word as a replacement, however, makes the
statement pseudo-ambiguous, since the original
intended meaning can also be recovered. There
then are two ?conflicting? and ?contrasting? inter-
pretations ? the literal one and the original one ?
increasing the likelihood of humorous incongruity.
Requiring the substitute to share part-of-speech
with the original word works in this direction too,
and additionally increases the likelihood that the
resulting text is a valid English statement.
244
Implementation We adopt an extended defini-
tion of punning and also consider orthographically
similar or rhyming words as possible substitutes.
Two words are considered orthographically
similar if one word is obtained with a single char-
acter deletion, addition, or replacement from the
other one.
We call two words phonetically similar if their
phonetic transcription is orthographically similar
according to the above definition.
Two words rhyme if they have same positions of
tonic accent, and if they are phonetically identical
from the most stressed syllable to the end of the
word.
Our implementation of these constraints uses
the WordNet lexical database (Fellbaum, 1998)
and CMU pronunciation dictionary1. The lat-
ter also provides a collection of words not nor-
mally contained in standard English dictionaries,
but commonly used in informal language. This in-
creases the space of potential replacements. We
use the TreeTagger2 POS tagger in order to con-
sider only words with the same part-of-speech of
the word to be replaced.
3.2 Taboo Constraint
Taboo constraint (TABOO) requires that the sub-
stitute word is a taboo word or frequently used
in taboo expressions, insults, or vulgar expres-
sions. Taboo words ?represent a class of emo-
tionally arousing references with respect to body
products, body parts, sexual acts, ethnic or racial
insults, profanity, vulgarity, slang, and scatology?
(Jay et al, 2008), and they directly introduce ?in-
appropriateness? to the text.
Implementation We collected a list of 700
taboo words. A first subset contains words man-
ually selected from the domain SEXUALITY of
WordNet-Domains (Magnini and Cavaglia`, 2000).
A second subset was collected from the Web, and
contains words commonly used as insults. Finally,
a third subset was collected from a website post-
ing examples of funny autocorrection mistakes3
and includes words that are not directly referring
to taboos (e.g.: ?stimulation?) or often retrieved in
1available at http://www.speech.cs.cmu.edu/
cgi-bin/cmudict
2available at http://www.ims.unistuttgart.
de/projekte/corplex/TreeTagger
3http://www.damnyouautocorrect.com
jokes evoking taboo meanings (e.g.: ?wife?).
3.3 Contextual Constraints
Contextual constraints (CONT) require that the
substitution takes place at the end of the text, and
in a locally coherent manner.
By local coherence we mean that the substitute
word forms a feasible phrase with its immediate
predecessor. If this is not the case, then the text
is likely to make little sense. On the other hand,
if this is the case, then the taboo meaning is po-
tentially expanded to the phrase level. This in-
troduces a stronger semantic ?contrast? and thus
probably contributes to making the text funnier.
The semantic contrast is potentially even stronger
if the taboo word comes as a surprise in the end
of a seemingly innocent text. The humorous effect
then is similar to the one of the forced reinterpre-
tation jokes.
Implementation Local coherence is imple-
mented using n-grams. In the case of languages
that are read from left to right, such as English,
expectations will be built by the left-context of the
expected word. To estimate the level of expecta-
tion triggered by a left-context, we rely on a vast
collection of n-grams, the 2012 Google Books n-
grams collection4 (Michel et al, 2011) and com-
pute the cohesion of each n-gram, by comparing
their expected frequency (assuming word inde-
pence), to their observed number of occurrences.
A subsequent Student t-test allows to assign a
measure of cohesion to each n-gram (Doucet and
Ahonen-Myka, 2006). We use a substitute word
only if its cohesion with the previous word is high.
In order to use consistent natural language and
avoid time or location-based variations, we fo-
cused on contemporary American English. Thus
we only used the subsection of Google bigrams
for American English, and ignored all the statis-
tics stemming from books published before 1990.
4 Evaluation
We evaluated the method empirically using
CrowdFlower5, a crowdsourcing service. The aim
of the evaluation is to measure the potential effect
of the three types of constraints on funniness of
texts. In particular, we test the potential effect of
4available at http://books.google.com/ngrams
5available at http://www.crowdflower.com
245
adding the tabooness constraint to the form con-
straints, and the potential effect of further adding
contextual constraints. I.e., we consider three in-
creasingly constrained conditions: (1) substitution
according only to the form constraints (FORM),
(2) substitution according to both form and taboo
constraints (FORM+TABOO), and (3) substitution
according to form, taboo and context constraints
(FORM+TABOO+CONT).
One of the reasons for the choice of taboo words
as lexical constraint is that they allows the system
to generate humorous text potentially appreciated
by young adults, which are the majority of crowd-
sourcing users (Ross et al, 2010). We applied the
humor generation method on the first 5000 mes-
sages of NUS SMS Corpus6, a corpus of real SMS
messages (Chen and Kan, 2012).
We carried out every possible lexical replace-
ment under each of the three conditions mentioned
above, one at a time, so that the resulting mes-
sages have exactly one word substituted. We then
randomly picked 100 such modified messages for
each of the conditions. Table 1 shows two example
outputs of the humor generator under each of the
three experimental conditions. These two exam-
ples are the least funny and the funniest message
according to the empirical evaluation (see below).
For evaluation, this dataset of 300 messages
was randomly divided into groups of 20 mes-
sages each. We recruited 208 evaluators using
the crowdsourcing service, asking each subject to
evaluate one such group of 20 messages. Each
message in each group was judged by 90 different
participants.
We asked subjects to assess individual messages
for their funniness on a scale from 1 to 5. For the
analysis of the results, we then measured the effec-
tiveness of the constraints using two derived vari-
ables: the Collective Funniness (CF) of a message
is its mean funniness, while its Upper Agreement
(UA(t)) is the fraction of funniness scores greater
than or equal to a given threshold t. To rank the
generated messages, we take the product of Col-
lective Funniness and Upper Agreement UA(3)
and call it the overall Humor Effectiveness (HE).
In order to identify and remove potential scam-
mers in the crowdsourcing system, we simply
asked subjects to select the last word in the mes-
6available at http://wing.comp.nus.edu.sg/
SMSCorpus
sage. If a subject failed to answer correctly more
than three times all her judgements were removed.
As a result, 2% of judgments were discarded as
untrusted. From the experiment, we then have
a total of 26 534 trusted assessments of mes-
sages, 8 400 under FORM condition, 8 551 un-
der FORM+TABOO condition, and 8 633 under
FORM+TABOO+CONT condition.
The Collective Funniness of messages in-
creases, on average, from 2.29 under con-
dition FORM to 2.98 when the taboo con-
straint is added (FORM+TABOO), and further to
3.20 when the contextual constraints are added
(FORM+TABOO+CONT) (Table 2). The Upper
Agreement UA(4) increases from 0.18 to 0.36 and
to 0.43, respectively.
We analyzed the distributions of Collective
Funniness values of messages, as well as the
distributions of their Upper Agreements (for
all values from UA(2) to UA(5)) under the
three conditions. According to the one-sided
Wilcoxon rank-sum test, both Collective Funni-
ness and all Upper Agreements increase from
FORM to FORM+TABOO and from FORM+TABOO
to FORM+TABOO+CONT statistically significantly
(in all cases p < .002). Table 3 shows p-values
associated with all pairwise comparisons.
5 Conclusions
We have proposed a new approach for the study
of computational humor generation by lexical re-
placement. The generation task is based on a sim-
ple form of punning, where a given text is modi-
fied by replacing one word with a similar one.
We proved empirically that, in this setting, hu-
mor generation is more effective when using a list
of taboo words. The other strong empirical re-
sult regards the context of substitutions: using bi-
grams to model people?s expectations, and con-
straining the position of word replacement to the
end of the text, increases funniness significantly.
This is likely because of the form of surprise they
induce. At best of our knowledge, this is the first
time that these aspects of humor generation have
been successfully evaluated with a crowdsourcing
system and, thus, in a relatively quick and eco-
nomical way.
The statistical significance is particularly high,
even though there were several limitations in the
experimental setting. For example, as explained
in Section 3.2, the employed word list was built
246
Experimental Condition Text Generated by the System CF UA(3) HE
FORM Oh oh...Den muz change plat liao...Go back have yan jiu again... 1.68 0.26 0.43
Not ?plat?...?plan?.
FORM Jos ask if u wana melt up? ?meet? not ?melt?! 2.96 0.74 2.19
FORM+TABOO Got caught in the rain.Waited half n hour in the buss stop. 2.06 0.31 0.64
Not ?buss?...?bus?!
BASE+TABOO Hey pple... $ 700 or $ 900 for 5 nights...Excellent masturbation 3.98 0.85 3.39
wif breakfast hamper!!! Sorry I mean ?location?
FORM+TABOO+CONT Nope...Juz off from berk... Sorry I mean ?work? 2.25 0.39 0.87
FORM+TABOO+CONT I?ve sent you my fart.. I mean ?part? not ?fart?... 4.09 0.90 3.66
Table 1: Examples of outputs of the system. CF: Collective Funniness; UA(3): Upper Agreement; HE:
Humor Effectiveness.
Experimental Conditions
FORM FORM+TABOO FORM+TABOO+CONT
CF 2.29 ? 0.19 2.98 ? 0.43 3.20 ? 0.40
UA(2) 0.58 ? 0.09 0.78 ? 0.11 0.83 ? 0.09
UA(3) 0.41 ? 0.07 0.62 ? 0.13 0.69 ? 0.12
UA(4) 0.18 ? 0.04 0.36 ? 0.13 0.43 ? 0.13
UA(5) 0.12 ? 0.02 0.22 ? 0.09 0.26 ? 0.09
Table 2: Mean Collective Funniness (CF) and Upper Agreements (UA(?)) under the three experimental
conditions and their standard deviations.
Hypotheses
FORM? FORM+TABOO FORM+TABOO? FORM+TABOO+CONT
CF 10?15 9? 10?5
UA(2) 10?15 1? 10?15
UA(3) 10?15 7? 10?5
UA(4) 10?15 2? 10?4
UA(5) 10?15 2? 10?3
Table 3: P-values resulting from the application of one-sided Wilcoxon rank-sum test.
from different sources and contains words not di-
rectly referring to taboo meanings and, thus, not
widely recognizable as ?taboo words?. Further-
more, the possible presence of crowd-working
scammers (only partially filtered by the gold stan-
dard questions) could have reduced the statistical
power of our analysis. Finally, the adopted humor
generation task (based on a single word substitu-
tion) is extremely simple and the constraints might
have not been sufficiently capable to produce a de-
tectable increase of humor appreciation.
The statistically strong results that we obtained
can make this evaluation approach attractive for
related tasks. In our methodology, we focused at-
tention to the correlation between the parameters
of the system (in our case, the constraints used in
lexical selection) and the performance of humor
generation. We used a multi-dimensional mea-
sure of humorous effect (in terms of funniness and
agreement) to measure subtly different aspects of
the humorous response. We then adopted a com-
parative setting, where we can measure improve-
ments in the performance across different systems
or variants.
In the future, it would be interesting to use
a similar setting to empirically investigate more
subtle ways to generate humor, potentially with
weaker effects but still recognizable in this set-
ting. For instance, we would like to investigate
the use of other word lists besides taboo domains
and the extent to which the semantic relatedness
itself could contribute to the humorous effect.
The current techniques can be improved, too,
in various ways. In particular, we plan to extend
the use of n-grams to larger contexts and consider
more fine-grained tuning of other constraints, too.
One goal is to apply the proposed methodology
to isolate, on one hand, parameters for inducing
incongruity and, on the other hand, parameters for
making the incongruity funny.
Finally, we are interested in estimating the prob-
ability to induce a humor response by using differ-
ent constraints. This would offer a novel way to
intentionally control the humorous effect.
247
References
S. Attardo and V. Raskin. 1991. Script theory re-
vis(it)ed: joke similarity and joke representation
model. Humour, 4(3):293?347.
J. Beattie. 1971. An essay on laughter, and ludicrous
composition. In Essays. William Creech, Edinburgh,
1776. Reprinted by Garland, New York.
K. Binsted, H. Pain, and G. Ritchie. 1997. Children?s
evaluation of computer-generated punning riddles.
Pragmatics and Cognition, 2(5):305?354.
T. Chen and M.-Y. Kan. 2012. Creating a live, public
short message service corpus: The nus sms corpus.
Language Resources and Evaluation, August. pub-
lished online.
A. Doucet and H. Ahonen-Myka. 2006. Probability
and expected document frequency of discontinued
word sequences, an efficient method for their exact
computation. Traitement Automatique des Langues
(TAL), 46(2):13?37.
C. Fellbaum. 1998. WordNet. An Electronic Lexical
Database. The MIT Press.
J. H. Goldstein, J. M. Suls, and S.Anthony. 1972. En-
joyment of specific types of humor content: Moti-
vation or salience? In J. H. Goldstein and P. E.
McGhee, editors, The psychology of humor: The-
oretical perspectives and empirical issues, pages
159?171. Academic Press, New York.
T. Jay, C. Caldwell-Harris, and K. King. 2008. Recall-
ing taboo and nontaboo words. American Journal of
Psychology, 121(1):83?103, Spring.
M. Levison and G. Lessard. 1992. A system for nat-
ural language generation. Computers and the Hu-
manities, 26:43?58.
B. Magnini and G. Cavaglia`. 2000. Integrating sub-
ject field codes into wordnet. In Proc. of the 2nd In-
ternational Conference on Language Resources and
Evaluation (LREC2000), Athens, Greece.
R. A. Martin. 2007. The Psychology of Humor: An
Integrative Approach. Elsevier.
J. McKay. 2002. Generation of idiom-based witticisms
to aid second language learning. In (Stock et al,
2002).
J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres,
M. K. Gray, The Google Books Team, J. P. Pick-
ett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant,
S. Pinker, M. A. Nowak, and E. L. Aiden. 2011.
Quantitative analysis of culture using millions of
digitized books. Science, 331(6014):176?182.
V. Raskin and S. Attardo. 1994. Non-literalness and
non-bona-fide in language: approaches to formal
and computational treatments of humor. Pragmat-
ics and Cognition, 2(1):31?69.
V. Raskin. 1985. Semantic Mechanisms of Humor.
Dordrecht/Boston/Lancaster.
G. Ritchie. 2002. The structure of forced interpretation
jokes. In (Stock et al, 2002).
G. Ritchie. 2005. Computational mechanisms for pun
generation. In Proceedings of the 10th European
Natural Language Generation Workshop, Aberdeen,
August.
J. Ross, I. Irani, M. S. Silberman, A. Zaldivar, and
B. Tomlinson. 2010. Who are the crowdworkers?:
Shifting demographics in amazon mechanical turk.
In Proc. of the ACM CHI Conference.
O. Stock and C. Strapparava. 2002. HAHAcronym:
Humorous agents for humorous acronyms. In (Stock
et al, 2002).
O. Stock, C. Strapparava, and A. Nijholt, editors. 2002.
Proceedings of the The April Fools Day Workshop
on Computational Humour (TWLT20), Trento.
H. Summerfelt, L. Lippman, and I. E. Hyman Jr.
2010. The effect of humor on memory: Constrained
by the pun. The Journal of General Psychology,
137(4):376?394.
A. Valitutti. 2011. How many jokes are really funny?
towards a new approach to the evaluation of com-
putational humour generators. In Proc. of 8th Inter-
national Workshop on Natural Language Processing
and Cognitive Science, Copenhagen.
C. Venour. 1999. The computational generation of a
class of puns. Master?s thesis, Queen?s University,
Kingston, Ontario.
248
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 3?10,
Beijing, August 2010
Filtering news for epidemic surveillance:
towards processing more languages with fewer resources
Gae?l Lejeune1, Antoine Doucet1,
1GREYC, University of Caen
first.last@info.unicaen.fr
Roman Yangarber2, Nadine Lucas1
2CS department, University of Helsinki
yangarbe@cs.helsinki.fi
Abstract
Processing content for security be-
comes more and more important since
every local danger can have global
consequences. Being able to collect
and analyse information in different
languages is a great issue. This pa-
per addresses multilingual solutions
for analysis of press articles for epi-
demiological surveillance. The sys-
tem described here relies on pragmat-
ics and stylistics, giving up ?bag of
sentences? approach in favour of dis-
course repetition patterns. It only
needs light resources (compared to
existing systems) in order to process
new languages easily. In this pa-
per we present here results in En-
glish, French and Chinese, three lan-
guages with quite different character-
istics. These results show that simple
rules allow selection of relevant doc-
uments in a specialized database im-
proving the reliability of information
extraction.
1 Multilingual techniques in
information extraction
In natural language processing, information
extraction is a task where, given raw text, a
system is to give precise information fitting
in a predefined semantic template.
1.1 Epidemic surveillance
Automated news surveillance is an important
application of information extraction. The
detection of terrorist events and economic
surveillance were the first applications, in
particular in the framework of the evalua-
tion campaigns of the Message Understand-
ing Conference (MUC) (MUC, 1992; MUC,
1993). In MUC-3 (1991) and MUC-4 (1992),
about terrorism in Latin American countries,
the task of participants was, given a collec-
tion of news feed data, to fill in a prede-
termined semantic template containing the
name of the terrorist group that perpetrated
a terrorist event, the name of the victim(s),
the type of event, and the date and location
where it occurred. In economic surveillance,
one can for instance extract mergers or cor-
porate management changes.
An application of information extraction
that lately gained much importance is that
of epidemiological surveillance, with a spe-
cial emphasis on the detection of disease out-
breaks. Given news data, the task is to de-
tect epidemiological events, and extract the
location where they occurred, the name of
the disease, the number of victims, and the
?case?, that is, a text description of the
event, that may be the ?status? of victims
(sick, injured, dead, hospitalised . . . ) or a
written description of symptoms. Epidemio-
logical surveillance has become a crucial tool
with increasing world travel and the latest
crises of SARS, avian flu, H1N1 . . .
In this paper, we present an application to
epidemic surveillance, but it may be equally
applied to any subdomain of news surveil-
lance.
1.2 Multilingual information
extraction
As in many fields of NLP, most of the work in
information extraction long focused on En-
glish data (Etzioni et al, 2008).Multilingual
has often been understood as adding many
3
monolingual systems, except in pioneer mul-
tilingual parsing (Vergne, 2002). Whereas
English is nowadays the lingua franca in
many fields (in particular, business), we will
see that for several applications, this is not
sufficient. Most news agencies are translat-
ing part of their feed into English (e.g., AFP1
and Xinhua2 for which the source languages
are respectively French and Chinese), but a
good deal of the data is never translated,
while for the part that is, the translation
process naturally incurs a delay that is, by
essence, problematic in a field where exhaus-
tivity and early detection are crucial aspects.
Subsequently, the ability to simultane-
ously handle documents written in different
languages is becoming a more and more im-
portant feature (Poibeau et al, 2008; Gey et
al., 2009). Indeed, in the field of epidemio-
logical surveillance, it is especially important
to detect a new event the very first time it is
mentioned, and this very first occurrence will
almost always happen in the local language
(except for countries like Iraq for instance).
Therefore, it is not enough to be able to deal
with several languages : It is necessary to
handle many. For instance, the Medical In-
formation System (Medisys) of the European
Community gathers news data in 42 differ-
ent languages (Atkinson and der Goot, 2009)
(now 453).
1.3 Current approaches
There are currently 2 main approaches to
multilingual information extraction. The
first approach relies on the prior transla-
tion of all the documents into one com-
mon language (usually English), for which a
well-performing information extraction sys-
tem has been developed (Linge et al, 2009).
Whereas the simple design of this solution
is attractive, the current state of the art in
machine translation only allows for mediocre
results. Most monolingual information ex-
traction systems indeed rely on a combina-
1http://www.afp.com/afpcom/en
2http://www.xinhuanet.com/english2010/
3http://medusa.jrc.it/medisys/aboutMediSys.html
tion of grammatical patterns and specialized
lexicons (Grishman et al, 2002; Riloff, 1996).
The second main approach consists in leav-
ing documents in their original language but
to translate the lexicons and extraction pat-
terns into that language (Efimenko et al,
2004; Linge et al, 2009). However, the
same problems occur as in the first approach
because the patterns are strongly language-
related. Yet, to ?translate the system? seems
more realistic than to translate the docu-
ments, as it can be done manually, and of-
fline (once and for all, and not as docu-
ments arrive). The bottleneck is then that
the amount of work for each language is
enormous: it naturally requires the com-
plete translation of the lexicon (for all trig-
ger words), but the more challenging is-
sue is the translation of patterns, whose
language-dependence might well mean that
the amount of work needed to translate them
comes close to that required for writing them
from scratch. In addition, this task must
necessarily be achieved by a domain expert,
with excellent skills in the languages at hand.
One could want to tackle this problem by us-
ing machine learning but she will need train-
ing data in many languages. In practice,
this will often mean that only a few major
languages will be dealt with, whilst all the
others (amongst which all low-resource lan-
guages), will again be totally discarded. One
can then only wish that epidemics will chose
to occur in locations handled by surveillance
systems. . .
Both approaches additionally require a
number of linguistic processing tools, in a
number comparable to the number of lan-
guages to be dealt with: tokenizer, stem-
mer, syntactic analyzer, . . . One might there-
fore conclude that such techniques are not
properly multilingual but rather monolingual
methods that may be adapted to other lan-
guages individually.
In this paper, we explore a third approach
to multilingual information extraction. We
restrain ourselves to the sole use of truly mul-
4
tilingual elements, facts that are equally true
for any language. The approach hence relies
on universals, relying, e.g., on stylistics and
rhetorics.
2 Rationale of the experiment
The objective of the system is to monitor
news in a variety of languages to detect dis-
ease outbreaks which is an important issue
for an alert system in epidemic surveillance.
For this task a simple and clear framework is
needed in order to limit the amount of work
for new languages while keeping good relia-
bility. The main idea of our work is using
text granularity and discourse properties to
write rules that may be language indepen-
dent, fast and reliable (Vergne, 2002). For
this study, regularities at text level are ex-
ploited. These phenomena can be related to
stylistics and pragmatics. It has already been
shown that news discourse has its own con-
straints reflected in press articles of different
languages (Van Dijk, 1988; Lucas, 2004).
2.1 Stylistic rules
Journalists all over the world know how to
hook their potential readers. These meth-
ods are described in journalism schools (Itule
and Anderson, 2006). One very important
rule for journalists seems to be the?5W rule?
which emphasise on the fact that answering
to the questions?What?,?Where?,?When?,
?Why? and ?Who? is a priority at the start
of a paper. Only after that can journal-
ists develop and give secondary information.
This phenomenon is genre dependent and is
exploited for processing texts by searching
for repetitions.
Example 1 shows a piece of news where the
disease name is found in the beginning of the
news article and developed later on. No local
pattern is needed to detect what the article
is about, repetition phenomena is sufficient.
Example 2 is a counter example, where
a disease name is found but not repeated.
This French document reports on a pop mu-
sic band being the ?coqueluche? of Hip-Hop,
which can mean ?pertussis?, but here means
?fashion? in a figurative sense (underlining
the fast spread of the band?s popularity).
Usually, figurative meanings are not used
twice in the same article (Itule and Ander-
son, 2006) and hence the repetition criteria
allows one to rightfully ignore this article.
2.2 Pragmatic rules
As press articles are made for humans, strong
effort is exerted to ensure that readers will
understand the main information with as few
inferences as possible (Sperber and Wilson,
1998). In fact, the more inferences the reader
has to make, the more errors he is likely to
make and the more probability he will get
confused and not read the full article. Rep-
etitions are there to relieve the memory ef-
fort. A point that journalists pay much at-
tention to is leaving as few ambiguities on
main facts as possible. It means that poten-
tially unknown or complicated terms will be
used quite rarely. Only one main story will
be developed in an article, other facts that
are important will be developed elsewhere as
main stories.
3 Our system
The system is based on the comparison of
repetitions in the article to find documents
relevant for epidemic surveillance and extract
where the disease occurs and how many peo-
ple are concerned.
3.1 String repetitions: relevant
content
A system is not a human reader, so objec-
tive discourse marks are used by the sys-
tem. Repetitions are known since the an-
cient times as reflecting discourse structure.
A press article is divided into two parts,
roughly the head and the rest of the news.
The title and the first two sentences form
the head or thematic part and the rest of
the text is considered to be a development in
an expository discourse.
5
Measles outbreak spreads north in B.C.
Number of cases hits 44 provincewide B.C.?s measles outbreak appears to have spread to
northeastern areas of the province, after doctors confirmed two new cases of the disease
in the Fort St. John and Fort Nelson areas on Thursday.
The new cases bring the total number of confirmed cases in the province to 44, not
including suspected but unconfirmed cases, said the B.C. Centre for Disease Control.
Northern Health spokeswoman Eryn Collins said the virus had not been detected in the
north in more than six years and the two new cases involve people who weren?t immunized.
[...] ?It is suspected that at least two out-of-country visitors brought measles into Van-
couver sometime in February or early March, as two separate strains of the virus have been
identified,? said a statement from the B.C. Centre for Disease Control earlier this week. So
far, 17 cases of the measles have been detected in the Fraser Valley, 17 in the Vancouver
area, seven in the southern Interior, two in northern B.C. and one on Vancouver island.
Figure 1: Example in English: repetition of disease name and cases
Cameroun/Musique : X-Maleya nouvelle coqueluche du Hip-Hop camerounais !
Le trio Hip-Hop Cameounais X-Maleya, a le vent en poupe. Le groupe qui s?illustre dans
la tendance Hip-Hop, est aujourd?hui l?une des valeurs sres musicales gra?ce son second
opus Yelele.
Derrie`re ces trois pre?noms : Roger, Auguste et Ha??s, se cachent un trio camerounais
qui s?illustre dans le monde du Hip-Hop. [etc.] C?est donc, une nouvelle valeur su?re
qu?incarnent eux trois Roger, Auguste et Ha??s. Le groupe rencontre en effet, une ascension
fulgurante. Les trois faiseurs de Hip-Hop, ont une seule ide?e en te?te, continuer de se
produire pour ceux qui les appre?cient, toujours composer de belles me?lodies et, ne pas
oublier d?ou` ils viennent.
Figure 2: Example in French: no repetition
Strings that are present in both parts will
be referred to as?relevant content?. They are
found in the beginning of the news and re-
peated in the development. To process as
many languages as possible, repeated char-
acter strings will be searched (not words
because Chinese for instance does not use
graphic words).
3.2 Defining epidemic event
Epidemic events are captured through these
information slots:
? Disease (What)
? Location (Where)
? Case, i.e.,People concerned (Who)
3.3 Selecting potentially relevant
documents
This discourse related heuristic rule limits re-
sources needed by the system. Many char-
acter strings that are repeated in the text
reflect important terms. However, repeti-
tion alone does not allow to fill IE templates
with detailed information as required. Ac-
cordingly, a lexical filter is applied on the re-
peated strings. 200 common disease names
are used to filter information and find dis-
ease names. The idea behind the restricted
list is that a journalist will use a common
name to help his readers understand the mes-
sage. Similarly, for locations, a list of coun-
try names and capitals provided by UN is
6
WHO checks smallpox reports in Uganda
LONDON, Thursday
The World Health Organisation said today it was investigating reports of suspected cases
of the previously eradicated disease smallpox in eastern Uganda.
Smallpox is an acute contagious disease and was one of the worlds most feared sicknesses
until it was officially declared eradicated worldwide in 1979.
?WHO takes any report of smallpox seriously, Gregory Hartl, a spokesman for the Geneva-
based United Nations health agency, told Reuters via email.
?WHO is aware of the reports coming out of Uganda and is taking all the necessary
measures to investigate and verify.?[etc.]
Figure 3: Example in English: repetition and location
used (about 500 items). Finally, in order to
comply with a specific demand of partners,
blacklist terms were used to detect less rel-
evant articles (vaccination campaign for in-
stance).
When a disease name is found in the rele-
vant content, the article is selected as poten-
tially relevant and the system tries to extract
location and cases.
3.4 Extracting location and cases
To extract the location, the following heuris-
tic is applied: the relevant location corre-
sponds to a string in the?relevant content?.
For instance, Example 3 shows that it allows
for the system to find that the main event
concerns Uganda but not London.
If numerous locations match, the system
compares frequencies in the whole document:
if one location is more than twice as frequent
as others, it is considered as the relevant one.
If no location is found, the location of the
source is selected by default. In fact accord-
ing to pragmatic rules when one reads an
article in the Washington Post, she will be
sure that it is about the United States even
if it is not explicitly mentioned. To the con-
trary if the article is about Argentina it will
be clearly mentioned so the reader has less
chances of misunderstanding.
Concerning the cases, they are related to
the first numeric information found in the
document, provided the figures are not re-
lated to money or date (this is checked by a
blacklist and simple regular expressions).
Furthermore the extracted cases are con-
sidered more relevant if they appear twice in
the document, the system uses regular ex-
pressions to round up and compare them.
See Example 4 where the number of dead
people ?55? is the first numeric information
in the beginning and is repeated in the de-
velopment (we chose an example where it is
easy even for a non Chinese speaker to see
the repetition). One can also note that the
second repeated figure is ?19488? which is
the number of infected people.
4 Evaluation
It is important to insist on the fact that our
system extracts the main event from one ar-
ticle, considering that secondary events have
been or will be mentioned in another article.
Often, the more topics are presented in one
article, the less important each one is. In the
case of epidemic surveillance, review articles
or retrospectives are not first-hand, fresh and
valuable information.
4.1 Corpus and Languages
For each language we randomly extracted
documents from the Medisys website.
Medisys documents are gathered using key-
words: medical terms (including scientific
disease names), but also weaker keywords
such as casualties, hospital. . . This implies
that some news document not related
7
Figure 4: Example in Chinese: 55 deaths from H1N1
to epidemic surveillance, but to accident
reports for instance, are liable to be found
in the database.
We must underline that in this framework,
recall can only be estimated, notably because
the news documents are keyword-filtered be-
forehand. However, our aim is not to provide
an independent system, but to provide quick
sorting of irrelevant news, prior to detailed
analysis, which is the key issue of a surveil-
lance and alert system. 200 documents were
extracted for each language and manually
tagged by native speakers with the following
instructions:
? Is this article about an epidemic?
? If it is, please give when possible:
Disease(s)
Country (or Worldwide)
Number of cases
100 of these annotated documents were used
for fine-tuning the system, 100 others for
evaluating. We chose for this study 3 fairly
different languages for checking the generic-
ity of the approach
? French, with its rather rich morphology,
? English,a rather isolating language with
poor morphology,
? Chinese, a strict isolating language with
poor morphology.
4.2 Results
These results were computed from a set of
100 annotated documents, as described in
section 4. Table 1 shows recall, precision and
F-measure for document selection(more ex-
amples are available online 4 ) Table 2 com-
pares automatically extracted slots and hu-
man annotated slots, therefore if an event is
not detected by the system it will count as
an error for each slot.
Table 1 shows that selection of documents
is quite satisfactory and that recall is better
than precision. This is mostly due to the fact
that the system still extracts documents with
low relevance. We found it impossible to pre-
dict if this is a general bias and whether it
can be improved. The result analysis showed
that many false negatives are due to cases
when the piece of news is quite small, see
for instance Example 5 where ?Swine flu? is
only found in the first two sentences, which
implies the repetition criteria does not apply
(and the system misses the document).
Table 2 shows the accuracy of the infor-
mation entered into semantic slots, respec-
4http://sites.google.com/site/iesystemcoling2010
8
China has 100 cases of swine flu: state media
China has 100 confirmed cases of swine flu, state media said Tuesday, as data from the
World Health Organization showed the disease had spread to 73 countries.
?The health ministry has reported that so far, China has 100 confirmed cases of A(H1N1)
flu,? said a news report on state television CCTV. The report said the 100 cases were in
mainland China, which does not include Hong Kong or Macau.
Figure 5: Example in English: Disease name not in ?relevant content?
Language Recall Precision F-measure
French 93% 88% 90%
English 88% 84% 86%
Chinese 92% 85% 88%
Table 1: Selecting documents
Language Diseases Locations Cases
French 88% 87% 81%
English 81% 81% 78%
Chinese 82% 79% 77%
Table 2: Accuracy in filling slots
tively name of disease, location and number
of cases. It is important to say that the de-
scriptors extracted are really reliable in spite
of the fact that the annotated set used for
evaluation is fairly small: 100 documents per
language, 30 to 40 of which were marked as
relevant. The extraction of cases performs a
bit worse than that of locations but the loca-
tion is the most important to our end-users.
5 Discussion and Conclusion
Most research in Information Extraction (IE)
focuses on building independent systems for
each language, which is time and resource
consuming. To the contrary, using common
features of news discourse saves time. The
system is not quite independent, but it al-
lows filtering news feeds and it provides rea-
sonable information even when no resources
at all are available. Our results on English
are worse than some existing systems (about
93% precision for Global health Monitor for
instance) but these systems need strong re-
sources and are not multilingual. We then
really need a multilingual baseline to com-
pare both approaches.
Recall is important for an alert system,
but is very difficult to assess in the case of
epidemiological surveillance. This measure
is always problematic for web based docu-
ments, due to the fact that any randomly
checked sample would only by sheer luck con-
tain all the positive documents. The assump-
tion here is that no important news has been
missed by Medisys, and that no important
news filtered from Medisys has been rejected.
One explanation for missed articles lies
in the definition of the article header: it is
too rigid. While this is fine for standard
size news, it is inappropriate for short news,
hence meaningful repetitions are missed in
the short news. This is a flaw, because first
alerts are often short news. In the future, we
may wish to define a discourse wise detection
rule to improve the location slot filling. The
extraction of locations is currently plagued
by a very long list of countries and capitals,
most of which is not useful. Locations are ac-
tually mentioned in data according to states,
provinces, prefectures, etc. The country list
might be abandoned, since we do not favour
external resources.
The methods that are presented here
maintain good reliability in different lan-
guages, and the assumption that genre laws
are useful has not been challenged yet. Light
resources, about 750 items (to be compared
to tens of thousands in classical IE sys-
tems), make it possible to strongly divide the
amount of work needed for processing new
languages. It might be attempted to refine
the simple hypotheses underlying the pro-
9
gram and build a better system for filtering
relevant news. This approach is best suited
when combined with elaborate pattern-based
IE modules when available. Repetition can
be checked for selecting documents prior to
resource intensive semantic processing. It
can also provide a few, easily fixable and effi-
cient preliminary results where language re-
sources are scarce or not available at all.
References
Atkinson, Martin and Erik Van der Goot. 2009.
Near real time information mining in multilin-
gual news. In 18th International World Wide
Web Conference (WWW2009).
Efimenko, Irina, Vladimir Khoroshevsky, and
Victor Klintsov. 2004. Ontosminer family:
Multilingual ie systems. In SPECOM 2004:
9th Conference Speech and Computer.
Etzioni, Oren, Michele Banko, Stephen Soder-
land, and Daniel S. Weld. 2008. Open in-
formation extraction from the web. Commun.
ACM, 51(12):68?74.
Gey, Fredric, Jussi Karlgren, and Noriko Kando.
2009. Information access in a multilingual
world: transitioning from research to real-
world applications. SIGIR Forum, 43(2):24?
28.
Grishman, Ralph, Silja Huttunen, and Roman
Yangarber. 2002. Information extraction for
enhanced access to disease outbreak reports.
Journal of Biomedical Informatics, 35(4):236?
246.
Itule, Bruce and Douglas Anderson. 2006. News
Writing and Reporting for Today?s Media.
McGraw-Hill Humanities.
Linge, JP, R Steinberger, T P Weber, R Yan-
garber, E van der Goot, D H Al Khudhairy,
and N I Stilianakis. 2009. Internet surveil-
lance systems for early alerting of threats. Eu-
rosurveillance, 14.
Lucas, Nadine. 2004. The enunciative structure
of news dispatches, a contrastive rhetorical
approach. Language, culture, rhetoric, pages
154?164.
MUC. 1992. Proceedings of the 4th Confer-
ence on Message Understanding, MUC 1992,
McLean, Virginia, USA, June 16-18, 1992.
MUC. 1993. Proceedings of the 5th Conference
on Message Understanding, MUC 1993, Balti-
more, Maryland, USA, August 25-27, 1993.
Poibeau, Thierry, Horacio Saggion, and Roman
Yangarber, editors. 2008. MMIES ?08: Pro-
ceedings of the Workshop on Multi-source Mul-
tilingual Information Extraction and Summa-
rization, Morristown, NJ, USA. Association
for Computational Linguistics.
Riloff, Ellen. 1996. Automatically generating
extraction patterns from untagged text. In
AAAI/IAAI, Vol. 2, pages 1044?1049.
Sperber, Dan and Deirdre Wilson. 1998. Rele-
vance: Communication and cognition. Black-
well press, Oxford U.K.
Van Dijk, T.A. 1988. News as discourse.
Lawrence Erlbaum Associates, Hillsdale N.J.
Vergne, Jacques. 2002. Une me?thode pour
l?analyse descendante et calculatoire de corpus
multilingues: application au calcul des rela-
tions sujet-verbe. In TALN 2002, pages 63?74.
10
