Probabilistic Parsing and Psychological Plausibility 
Thors ten  Brants  and  Mat thew Crocker  
Saarland University, COlnl)U|;al;ional Linguistics 
D-6G041 Saarbriicken, Germany 
{brants ,  crocker}@coi?,  un?-sb ,  de 
Abst ract  
Given the recent evidence for prot)abilistic 
mechanisms in models of hmnan aml)iguity res- 
olution, this paper investigates the plausibil- 
ity of exl)loiting current wide-coverage, 1)rob- 
al)ilistic 1)arsing techniques to model hmnan 
linguistic t)ert'orman(:e. In l)arl.i(:ulm ', we in- 
vestigate the, t)crforlnance of stan(tar(l stoclms- 
tic parsers when they arc revis(;(l to el)crate 
incrementally, and with reduced nlenlory re- 
sources. We t)resent techniques for ranking 
and filtering mlMyses, together with exl)erimen- 
tal results. Our results confirm that stochas- 
tic parsers which a(lhere to these 1)sy('hologi- 
cally lnotivated constraints achieve goo(l l)er- 
f()rman(:e. Memory cast t)e reduce(t (lown to 
1% ((:Oml)are(l to exhausitve search) without re- 
ducing recall an(l 1)rox:ision. A(lditionally, thes(; 
models exhil)it substamtially faster l)ertbrmance. 
FinMly, we ~rgue that this generM result is likely 
to hold for more sophisticated, nnd i)sycholin- 
guistically plausil)le, probal)ilistic parsing mod- 
els. 
1 I n t roduct ion  
Language engineering and coml)ut~tional psy- 
cholinguistics are often viewed as (list|net re- 
search progrmnmes: engineering sohttions aim 
at practical methods which ('an achieve good 
1)erformance, typically paying little attention 
to linguistic or cognitive modelling. Comlm- 
tational i)sycholing,fistics, on the other hand, 
is often focussed on detailed mo(lelling of hu- 
man lmhaviour tbr a relatively small number 
of well-studied constructions. In this paper we 
suggest hat, broadly, the human sentence pro- 
cessing mechanism (HSPM) and current statis- 
ti(:al parsing technology can be viewed as having 
similar ol)jectives: to optimally (i.e. ral)idly and 
accurately) understand l;he text and utl;erances 
they encounter. 
Our aim is to show that large scale t)robabilis- 
tic t)arsers, when subjected to basic cognitive 
constraints, can still achieve high levels of pars- 
ing accuracy. If successful, this will contribute 
to a t)lausil)h; explanation of the fact th~tt I)(;() -
\])lc, in general, are also extremely accurate and 
rol)llS(;. Sllch a 1'o81111; Wollld also strellgthclt ex- 
isting results showing that related l)robal)ilistic 
lne('hanisms can exl)lain specific psycholinguis- 
tic phenomena. 
To investigate this issue, we construct a stan- 
dard 'l)aseline' stochastic parser, which mir- 
rors t;he pertbrmance of a similar systems (e.g. 
(,lohnson, 1998)). We then consider an incre- 
re(total version of th(', parser, and (;v~,htat(; tim 
etf'c(:ts of several l)rol)al)ilistic filtering strate- 
gies which m'e us(,(l to 1)rune the l)arser's earch 
space, and ther(;l)y r('(lu('(', memory load. 
rio &,,-;sess th(; generMity of oltr resnll;s for 
more Sol)histi(;ate(t prot)al)ilistic models, we also 
conduct experiments using a model in which 
parent-node intbrmation is encoded on the 
(laughters. This increase in contextual informa- 
tion has t)(;(;11 shown 1;o improve t)erforlnance 
(.Johnson, 1998), and the model is also shown 
to be rolmst to the inerementality and memory 
constraints investigated here. 
We present the results of parsing pertbr- 
mance ext)eriments , showing the accuracy of 
these systems with respect to l)oth a parsed 
corpus and the 1)aseline parser. Our experi- 
ments suggest hat a strictly incremental model, 
in which memory resources are substantially 
reduced through filtering, can achieve l)reci- 
sion and recall which equals that of 'unre- 
stricted' systems. Furthermore, implementa- 
tion of these restrictions leads to substantially 
faster 1)(;rtbrmance. In (:onchlsion, we argue 
that such 1)road-coverage probabilistic parsing 
111 
models provide a valuable framework tbr ex- 
plaining the human capacity to rapidly, accu- 
rately, and robustly understand "garden va- 
riety" language. This lends further supt)ort 
to psycholinguistic a counts which posit proba- 
bilistic ambiguity resolution mechanisms to ex- 
plain "garden path" phenomena. 
It is important to reiterate that our intention 
here is only to investigate the performance of 
probabilistic parsers under psycholinguistically 
motivated constraints. We do not argue for the 
psychological plausibility of SCFG parsers (or 
the parent-encoded variant) per se. Our inves- 
tigation of these models was motivated rather 
by our desire to obtain a generalizable result 
for these simple and well-understood models, 
since obtaining similar results for more sophisti- 
cated models (e.g. (Collins, 1996; Ratnaparkhi, 
199711 might have been attributed to special 
properties of these models. Rather, the current 
result should be taken as support br the poten- 
tial scaleability and performance ofprobabilistic 
I)sychological models uch as those proposed by 
(aurafsky, 1996) and (Crocker and Brants, to 
appear). 
2 Psycholinguistic Mot ivat ion  
Theories of human sentence processing have 
largely been shaped by the study of pathologies 
in tnnnan language processing behaviour. Most 
psycholinguistic models seek to explain the d{f- 
ficulty people have in comprehending structures 
that are ambiguous or memory-intensive (see 
(Crocker, 1999) for a recent overview). While 
often insightflfl, this approach diverts attention 
from the fact that people are in fact extremely 
accnrate and effective in understanding the 
vast majority of their "linguistic experience". 
This observation, combined with the mounting 
psycholinguistic evidence for statistically-based 
mechanisms, leads us to investigate the merit of 
exploiting robust, broad coverage, probabilistie 
parsing systems as models of hmnan linguistic 
pertbrmance. 
The view that hmnan language processing 
can be viewed as an optimally adapted sys- 
tem, within a probabilistic fl'amework, is ad- 
vanced by (Chater et al, 19981, while (Juraf- 
sky, 19961 has proposed a specific probabilis- 
tic parsing model of human sentence process- 
ing. In work on human lexical category dis- 
ambiguation, (Crocker and Corley, to appear), 
have demonstrated that a standard (iimrmnen- 
tal) HMM-based part-of-speech tagger mod- 
els the finding from a range of psycholinguis- 
tic experiments. In related research, (Crocker 
and Brants, 19991 present evidence that an 
incremental stochastic parser based oll Cas- 
caded Markov Models (Brants, 1999) can ac- 
count tbr a range of experimentally observed 
local ambiguity preferences. These include 
NP/S complement ambiguities, reduced relative 
clauses, noun-verb category ambiguities, and 
'that'-ambiguities (where 'that' can be either a 
complementizer or a determiner) (Crocker and 
Brants, to appear). 
Crucially, however, there are differences be- 
tween the classes of mechanisms which are psy- 
chologically plausible, and those which prevail 
in current language technology. We suggest that 
two of the most important differences concern 
incrcmentality~ and memory 7vso'urces. There is 
overwhehning experimental evidence that peo- 
ple construct connected (i.e. semantically in- 
terpretable) analyses for each initial substring 
of an utterance, as it is encountered. That is, 
processing takes place incrementally, from left 
to right, on a word by word basis. 
Secondly, it is universally accecpted that peo- 
ple can at most consider a relatively small 
number of competing analyses (indeed, some 
would argue that number is one, i.e. process- 
ing is strictly serial). In contrast, many exist- 
ing stochastic parsers are "unrestricted", in that 
they are optinfised tbr accuracy, and ignore such 
t)sychologically motivated constraints. Thus the 
appropriateness of nsing broad-coverage proba- 
bilistic parsers to model the high level of hu- 
man performance is contingent upon being able 
to maintain these levels of accuracy when the 
constraints of" incrementality and resource limi- 
rations are imposed. 
3 Incremental Stochastic 
Context-Free Parsing 
The fbllowing assumes that the reader is fa- 
miliar with stochastic context-free grammars 
(SCFG) and stochastic chart-parsing tech- 
niques. A good introduction can be found, e.g., 
in (Manning and Schfitze, 19991. We use stan- 
dard abbreviations for terminial nodes, 11051- 
terminal nodes, rules and probabilities. 
112 
This t)tq)er invcsl;igates tochastic (;onl;(;xl;- 
fl'ee parsing l)ascd on ~ grmmmu" (;hat is (tcrivc(l 
from a trcel)ank, start ing with 1)art-ofsl)eech 
ta,gs as t(;rlninals. The gl:;~nllnt~r is (lcriv(;d l)y 
(:olle(:ting M1 rul('.s X -+ c~ th;tt oc(:ur in the tr(',(;- 
bank mM (;heir ffe(lU(m(:i('~s f .  The l)l'()l);tl)ilil;y 
of a rule is set to 
.f(x l ' ( x  - (:l) 
E .f(x 
fl 
\],br ~ descril)l;ion of treebank grammars see 
(Charniak, 1.996). The gr~mmmr does not coii- 
ta.in c-rules, oth(:rwis(: th(:r(: is no restriction 
oll the rules. In particular, w(: do not r(:quir(' 
C homsky-NormM-Form. 
In addit ion to the rult:s tha(; corr(:st)ond 
(;o sl;rucl;ur(:s in th(: corpus, w(: a.dd ;~ new 
st~u:l; sylnl)ol ROOT to l;h(; grnmmar and rules 
ROOT -~ X for all non-t;(;rminals X togel;lwx 
with l)rol)al)iliti('s (h:):iv(:d l'roln th(: root n()(t(:s 
in th(: tort)us I. 
For t)m:sing th(:se gr~unmn)'s, w(: r(:ly upon 
n stan(tard l)oLi;onl-U t) (:ha.rl,-t)arsing t(:(:hniqu(: 
with n modification for in(:rcmental parsing, i.(:., 
tbt" each word, all edges nr(: proc(:ss(:d and l)ossi- 
b\]y 1)run(:d 1)(:ti)r(: \])ro(:e(:(ling to the next word. 
Th(: outlilm of th(: Mgorithm is as follows. 
A (:hart; (:ntry 1~ (:onsists of a sl;;u:I, aim (:n(l 1)o- 
s it ion i ;rod j ,  a (tott(:d rul(: X ~ (~:.'7, tim insi(t(: 
l)rol)nl)ility fl(Xi,.j) thud; X g(:n(:ra.tx:s l;ll(: t(:rmi- 
hal string from t)osi(:ion i to .7, mM information 
M)out th(: most l)robat)\](: ilL~i(t(' stru(:i;ur(:. 1t7 th(: 
dot of th(: dotte(t ruh: is nt th(' r ightmost i)osi- 
tion, the corresl)ondillg (:(lg(: is an inactive edg(:. 
If the (tot is at mty other 1)osition, il; is mt ,,ctivc, 
edge. Imu:l;ivo, e(tgcs repr(',scnt re('ogniz(',d hypo- 
(:heti(:a,1 constituents, whil(; a(:tiv(; (;(lg(',s r(;1)r(;- 
s(:nt 1)r(:lixes of hyl)ol;heticM (:()llsi;it;ll(:lll;s. 
Th(: i th t(:rminal nod(: I,i l;lla, t; (:nt(:rs th(: (:hart 
gencra, tcs an inactive edge for l;\]m span (i - 1, i). 
Ba, sed on this, n(;w active mid inactive (;(lges are 
generated according to the stan(t~tr(t algorithm. 
Sine(: we are ilfl;(:r(:stcd in th(: most i)robM)le 
pars(:, the chart can be minimized in th(: tbl- 
lowing way whik: sti\]l 1)crfi)rming an ('xhaustiv(: 
search. If" ther(: is mor(: l;hm~ one (:(lg(~ that  cov- 
ers a span ( i , j )  having (;h(', sa, me non-t(:rminM 
symbol on th(; lefIAmnd side of th(: (to(,(x:(l rule, 
1The ROOT node is used int;ernally fl)r parsing; it is 
neither emitted nor count,ed for recall and l)recision. 
only the one with the highest inside prol)M)ility 
is k(;1)t ill tit(; (:\]mrt. The others cmmot con- 
trilmt(; to th(; most i)rol)M)le 1)nrse.. 
For an ina('tiv(: edge si)aiming i to j and rei)- 
rcs(mting the rule X --> y1 . . .yq~ the inside 
l)robM)ility/31 is set to 
\[d 
il = 1"(x -+ H (2) 
/=\] 
wher(: il and jl mm'k the start and end t)ostition 
of Yl having i = il nnd j = Jr. The insid(: 
prol)M)ility tbr an active cdg(: fiA with the dot 
after th(: kth syml)ol of th(: right-hmM side is 
sol, to 
k 
I I  <r ' t I t  il,jl} (3) 
l-d 
W(: (lo not use the t)rol)M)i\]ity of th(: rule a.t this 
point. This allows us to ('oral)in(: a.ll (:(Ig(:s with 
(;h(: sam(: st)m~ and th(: dot al; th(: sam(: 1)osition 
but with (liiI'er(:uI; symbols on the l(,ft-hmM side. 
Jntrodu(:ing a distinguish(:(1 M't-hand sid(: only 
for in~mtiv(: (lg('s significantly r(:du(;(:s th(: nun> 
b(:r of a(:(;iv(: (:dg(:s in the (:hm't. This goes one 
st, e t) furth(:r than lint)licitly right-1)inarizing th(: 
grmmnar; not only suilix(:s of right-hmM si(h:s 
are join(:(t, but also l;hc ('orr(:sponding l(:fi;-hand 
sid(:s. 
d Memory  Rest r i c t ions  
\?(: inv(:stig~rt(: th(: (dimin~I;ion (pruning) ()f 
edges from th(: ('hnrt in our in('r(:nl(:n|;a| \])re's- 
ing sch(:m(:. Aft(:r processing a word and b(:fi))'(: 
1)roc(:cding to the n(:xt word during incremental 
1)re:sing, low rnnk(,d edges ~r(: removed. This is 
(:(luivM(:lfl; t;() imposing m(:mory rcsia'ictions on 
the t)ro(:('ssing system. 
The, original algor ithm k('ei)s on(; edge in th(: 
(:hart fi)r each (:oml)ination of span (start and 
cn(l position) ~md non-tcrmimd symbol (for in- 
active edges) or r ight-hand side l)r(:fixcs of (lot;- 
te(t rules (for active edges). With 1)tinting, we 
restric(; the mmfl)cr of edges allowed per span. 
The limit~tion (:an b(: cxi)resscd in two ways: 
1. Va'riable bcam,. Sch:ct a threshold 0 > 1. 
Edg(: c. is removed, ill its 1)rol)ability is p~:, 
I;lm 1)csl; l)rol)M)ility fi)r the span is Pl, and 
v,; < pl_. (~l) 
0 
113 
2. Fixed beam. Select a maximum number of 
edges per span m. An edge e is removed, if 
its prot)ability is not in the first m highest 
probabilities tbr edges with the same span. 
We pertbrmed exl)eriments using both types 
of beauls. Fixed beams yielded consistently bet- 
ter results than variable beams when t)lotting 
chart size vs. F-score. Thereibre, the following 
results are reported tbr fixed t)eams. 
We, compare and rank edges covering the 
same span only, and we rank active and inactive 
edges separately. This is in contrast to (Char- 
niak et al, 1998) who rank all edges. They 
use nornmlization in order to account tbr dif- 
ferent spans since in general, edges for longer 
spans involve more nmltiplications of t)robabil - 
ities, yielding lower probabilities. Charniak et 
al.'s normalization value is calculated by a dil- 
ferent probability model than the inside proba- 
bilities of the edges. So, in addition to the nor- 
malization for different span lengths, they need 
a normalizatio11 constant hat accounts tbr the 
different probability models. 
This investigation is based on a much simt)ler 
ranking tbrmula. We use what can be described 
as the unigram probability of a non-terminal 
node, i.e., the a priori prot)ability of the co l  
resl)onding non-ternlinal symbol(s) times the 
inside t)robat)ility. Thus, fi~r an inactive edge 
(i, j, X --> (~,/31(Xi,j)}, we use the l)rob~fl)ility 
Pm(X i , j )  = P (X)  . P ( tg . . . t j _ I IX )  (5) 
= 
for ranking. This is the prol)ability of the node 
and its yield being present in a parse. The 
higher this value, |;lie better is this node. flI is 
the inside probability for inactive edges as given 
in eqnation 2, P(X)  is the a priori probability 
tbr non-terminal X, (as estimated from the fre- 
quency in the training COrlmS) and Pm is the 
probability of the edge tbr the non-terminal X
spanning positions i to j that is used tbr rank- 
ing. 
For an active edge { i , j ,X  --~ y1 . . . yk .  
yk+l  ym,  y )  k ? " ~ , ,~ )) " ' "  ~A( i l , j l  (the (tot is aI" 
ter the kth symbol of 
llSe: 
the right-hand side) we 
(7) 
= P(Y I . . .Yk ) . f lA (E I~, :h . . .Y i~ , jk )  (9) 
p (y l  ,,, yk)  can be read ()If the corpus. It is 
the a priori probability that the right-hand side 
of a production has the prefix y1 ... y/c, which 
is estilnated by 
f (y l  . . .  yt~ is prefix) 00) 
N 
where N is the total number of productions in 
the corpus 2, i = ij, j = j/~ and flA is the inside 
probability of the pretix. 
5 Exper iments  
5.1 Data  
We use sections 2 - 21 of the Wall Street Jour- 
lYecl)ank (Marcus el; al., nal part of' the Penn ~ " 
1993) to generate a treebank grammar. Traces, 
flmctional tags and other tag extensions that do 
not mark syntactic ategory are removed before 
training 3. No other modifications are made. For 
testing, we use the \] 578 sentences of length 40 
or less of section 22. The input to the parser is 
the sequence of i)art-ofspeech tags. 
5.2 Eva luat ion 
For evaluation, we use the parsewfi measures 
and report labeld F-score (the harmolfiC mean 
of labeled recall and labeled precision). R.eport- 
ing the F-score makes ore" results comt)aral)le to 
those of other previous experinmnts using the 
same data sets. As a n leasure  of  the an lount  
of work done by the parser, we report the size 
of the chart. The mnnl)er of active and imm- 
rive edges that enter the chart is given tbr the 
exhaustive search, not cored;lug those hypothet- 
ical edges theft are replaced or rejected because 
there is an alternative dge with higher t)roba- 
t)ility 4. For t)runed search, we give |:tie percent- 
age of edges required. 
5.3 F ixed Beam 
For our experiments, we define the beam by a 
maximunl number of edges per span. Beams 
for active and inactive edges are set separately. 
The Imams run from 2 to 12, and we test all 
2Here, we use proper prefixes, i.e., all prefixes not 
including the last element. 
aAs an example, PP-TMP=3 is replaced 173, PP. 
4The size of the chart is corot)arable to the "number 
of edges popped" as given in (Chanfiak et al, 1998). 
114 
i 
78 
77 
(D 
8 7o cJ~ 
75 
(1) 
74 z$ 
73 
72 
71 
79 
Resu l ts  w i th  Or ig ina l  and  Parent  Encod ing  
A 
ctive: 8 
/ ma?.:l'~v?", "~I ;t(:l ix'(" (i 
/ j  j~  activ(',: 3 
C 
" ' ' ; "  F l l ldCt  1V( 12  
active: 9 
inactive,: 2 
active: 3 / 
1.0 1.2 
ina(:tiv(',: 6 ilmctive: 8 
a(:l.ive: d . a('tivo,: 7 
I I 1 \[ \] i I I i - -  
\] .d 1.6 1.8 2.0 2.2 2.d 2.6 2.8 3.0 % (:hart; size 
Figure 1: \]!}xt)erimental results tbr increJnelfl;al parsing and t)rmfing. The figm:e shows the percent- 
age of edges relative to (',xhaustiv(; s(;ar(:h mid l;h(', F-s(:()re a(:hieved with this chart size. Exhaustive 
search yiehled 71.21% fin" th(; original en(:o(ting and 7!).28% for the I)arent (m(:o(ting. l/.c, sull;s in the 
grey ar(;as are equiwflent with a (:()nli(l('n(:('~ (tegr(',e of (~ =: 0.99. 
12\] comlfi\]~ati(ms of the, s(~ lmmus for ac:i;ivc and 
illactiw~ edges, l~ach setting results in a lm.ri;ic -
ulm" average size of l;he chart and an F-score, 
which arc tel)erred ill (;he following se(:l;ioll. 
5.4  Exper imenta l  Resu l ts  
The results of our 121 tes(; Hills with (tifl'erent 
settings for active and in;u:tivc \])(~a.ms m'e given 
in figure 1. The (tittgranl shows ch~trt sizes vs. 
labeled F-scores. It sorts char|; sizes across d i f  
ferent sel;l;ings of the beams. If several beam 
sett;ings result in equiwdenfi chart sizes, the di- 
agram cent;tins the one yielding th(', highes|, F- 
SCOI ' (L  
The 111~ill tinding is thai: we can r('xlu(:e the 
size of the chart to l)el;ween 1% and 3% of 
the size required fi)r exhaustive s(,ar(:h without 
affecting the results. Only very small 1)cams 
d(;grad(' t)ertbrmance 5. The eiti;ct occurs for 
both models despite the simple ranking formub~. 
This significantly reduces memory r(,quirements 
'~Givc, n the' amount of test data (26,322 non-terminal 
nod(!s), results within a rang(' of around 0.7% arc cquiv- 
al(mt with a (:onfidcnc(; degr(',(, of (~ = 99%. 
(given as size of the chart) and increases l)m'sing 
qmed. 
i1 t Exhaustive search yields an I -Score of 
71.21 % when using the original Petal %'eel)ank 
cn(:odh~g. ()nly around 1% the edges are re- 
(tuir('.d to yield e.(tuiwdcnt resul(;s with incrcm(,.n- 
tal processing and printing after each word is 
added to the chart;. This result is, among other 
settings, obtained by a tixcd beam of 2 for in- 
active edges and 3 tin" active e(lges ri
1,br the parmtt encoding, exhaustive search 
yields an l,-Scorc of 79.28%. Only 1)etween 2 
mM 3% of the edges are required to yMd an 
equiwflcnt result with incremental t)l'OCcSSillg 
and pruning. As an cXmnl)le, the point at size 
= 3.0% F-score = 79.1% is generated by the 
beam setting of 12 for imml;ive and 9 tbr active 
edges. The parent encoding yields around 8% 
higher F-scores but it also imposes a higher ab- 
solute and relative memory load on t;he process. 
The higher (hw'ee of par~dlelism in l;he inactive 
(;Using variable Imams, wc would nccd \].95% of the 
\[:hart entries 1;o achieve an (Kl l l ivalenI ;  F - scor (x  
115 
chart stems from the parent hytmthesis in each 
node. In terms of pure node categories, the av- 
erage number of parallel nodes at this point is 
3.5 7 . 
Exhaustive search for the base encoding needs 
in average 140,000 edges per sentence, tbr tile 
parent encoding 200,000 edges; equivalent re- 
sults for the base encoding can be achieved with 
around 1% of these edges, equivalent results tbr 
the parent encoding need between 2 and 3%. 
The lower mmlber of edges significantly in- 
creases parsing speed. Using exhaustive search 
tbr the base model, the parser processes 3.0 to- 
kens per second (measured on a Pentium III 
500; no serious efforts of optimization have gone 
into the parser). With a chart size of 1%, speed 
is 630 tokens/second. This is a factor of 210 
without decreasing accuracy. Sl)eed for the par- 
ent model is 0.5 tokens/second (exhaustive) and 
111 tokens/seconds (3.0% chart size), yielding 
an improvement by factor 220. 
6 Related Work 
Probably mostly related to the work reported 
here are (Charniak et al, 1998) and (Roark and 
Johnson, 1999). Both report on significantly 
improved parsing efl:iciency by selecting only 
subset of edges tbr processing. There are three 
main differences to our at)t)roach. One is that 
they use a ranking fbr best-first search while 
we immediately prune hypotheses. They need 
to store a large number edges because it is not 
known in advance how maw of the edges will be 
used until a parse is found. Tile second differ- 
ence is that we proceed strictly incrementally 
without look-ahead. (Chanfiak et al, 1998) 
use a non-incremental procedure, (Roark and 
Johnson, 1999) use a look-ahead of one word. 
Thirdly, we use a much simpler ranking tbnnula. 
Additionally, (Chanfiak et al, 1998) and 
(Roark and Johnson, 1999) do not use the 
original Penntree encoding tbr the context-fl'ee 
structures. Betbre training and parsing, they 
change/remove some of the productions and in- 
troduce new part-of-speech tags tbr auxiliaries. 
The exact effect of these modifications is un- 
known, and it is unclear if these affect compa- 
7For the active chart, lmralellism cannot be given for 
different nodes types since active edges are introduced 
fbr right-hand side prefixes, collapsing all possible left- 
hand sides. 
rability to our results. 
Tile heavy restrictions in our method (imme- 
diate pruning, no look-ahead, very simple rank- 
ing formula) have consequences on the accuracy. 
Using right context and sorting instead of prun- 
ing yields roughly 2% higher results (compared 
to our base encodingS). But our work shows 
that even with these massive restrictions, the 
chart size can be reduced to 1% without a de- 
crease in accuracy when compared to exhaustive 
search. 
7 Conclusions 
A central challenge in computational psycholin- 
guistics is to explaiu how it is that people are 
so accurate and robust in processing language. 
Given the substantial psycholinguistic evidence 
tbr statistical cognitive mechanisms, our objec- 
tive in this paper was to assess the plausibility 
of using wide-coverage probabilistic parsers to 
model lmman linguistic performance. In par- 
ticular, we set out to investigate the effects of 
imposing incremental processing and significant 
memory limitations on such parsers. 
The central finding of our experiments i that 
incremental parsing with massive (97% - 99%) 
pruning of the search space does not impair 
the accuracy of stochastic ontext-free parsers. 
This basic finding was rotmst across different 
settings of the beams and tbr the original Penn 
Treebank encoding as well as the parent encod- 
ing. We did however, observe significantly re- 
duced memory and time requirements when us- 
ing combined active/inactive dge filtering. To 
our knowledge, this is the first investigation on 
tree-bank grammars that systematically varies 
the beam tbr pruning. 
Our ainl in this paper is not to challenge 
state-of-the-art parsing accuracy results. For 
our experiments we used a purely context-ti'ee 
stochastic parser combined with a very sim- 
ple pruning scheme based on simple "unigram" 
probabilities, and no use of right context. We 
do, however suggest hat our result should ap- 
ply to richer, more sophistacted probabilistic 
SComparison of results is not straight-forward since 
(Roark and Johnson, 1999) report accuracies only tbr 
those sentences for which a parse tree was generated (be- 
tween 93 and 98% of the sentences), while our parser 
(except for very small Imams) generates parses for vir- 
tually all sentences, hence we report; accuracies for all 
sentences. 
116 
models, e.g. when adding word st~tistics to the 
model (Charni~d?, 1997). 
We thereibre conclude theft wide-covcr~ge, 
prol)~fl)ilistic pnrsers do not suffer impaired a('- 
curacy when subject to strict cognii;iv(~ meXnOl'y 
limitntions mM incremental processing. Fm'- 
thermore, parse times are sut)stm~ti~fily reduced. 
This sltggt',sts that it; m~y lie fruit;tiff to tlur,sllC 
the use of these models within ?',onlt)utational 
l)sycholinguistics, where it: is necessary to ex- 
plain not Olfly the relatively r~tr(; 'pathologies' of 
the hmmm parser, but also its mor(; fl'e(tuently 
ol)scrved ~u:(:ur~my ~(1 rol)llSiilless. 
References  
Thorst;en \]h'mfl;s. 1999. Cascadt;d Mm'kov mod- 
els. In P'rocecdings Vf 9th, Cm@~'t'.'m:e. of
the EuTvpea'n Chapter of the Association ,fro" 
Com.p'atatiou, al Linguistics EA 6'\])-99, B(;rg(;n, 
Norway. 
Eugene Charni~k, Sharon (\]ohlwater, and Mnrk 
,Johnson. 1998. ltMge-b~sed lmst-tirst (:hart 
pro'sing. In l~'rocec.dings of l, hc. Si:cl, h. l,Vor/,:- 
shop on l/cry LaT~\](: Corpora (WVLC-9S), 
Montreal, K~ma(la. 
Eugene Ch~rni~fl?. 1996. '15:ee-bank grmmm~rs. 
In P'rocecding,~ of t,h,c Th, irtec'nth, National 
Cm@rc'.nce on A'rt'ti/icial lntdlig(:,m:~:, l)a.g(,,s 
1031 1036, Menlo Pnrk: AAA\] Press/M1T 
l)i.ess. 
\]!htgen('. Chm:nia.k. 1997. Sl;a.i;isti(:al \]mrs- 
ing wit;h ~t context-fr(:(~ gl:;41111llVtl' 2.1~11(1 \voF(| 
statistics. In P~'occ.cdings qf the \],b,a'rt,(:enth 
National Co~@'r('.nce o'n A'rt~ificial Intelli- 
gence, pagc.s 1031 1036, Menlo Park: AAAI 
Press/MIT Press. 
Nicholas Chafer, Matthew Crock(;l', ~md Martin 
Pickcring. 1998. The rational analysis of in- 
quiry: The case. for parsign. In Charter and 
O~ksfor(1, editors, Ratio'hal Models o/" Cog'ni- 
tion. Oxford University Press. 
Michael Collins. 1!196. A new st~tistical l)arscr 
b~tse.d on l)igr~un lexical depend(;neies, in 
Proceedings of ACL-96, Sa, llta, Cruz, CA, 
USA. 
Matthew Crocker and Thorsten Br~mts. 1999. 
Incremental probabilisti(: lnodels of lmman 
linguistic perform;race. In The 5th Cm@r- 
cnce on Arc:hitcctu~v.s a'nd Mcch, anism.,s for 
La'nguagc Processing, Edi~flmrgh, U.K. 
Matthew Crocker and Thorst;en Brmfl;s. to ~t)- 
l)car. Wide cover~ge l)rol)~flfilistic sentence 
processing. Journal of Psych, oling'aistic Re- 
search,, November 2000. 
M~tthew Cro('kex mM Steil'an Corley. to ~l)- 
peru:. Modulm" nrchitectures and statisticM 
mcchnnisms: The case. frolli lexical category 
disnmbiguntion. In Merlo and Stevenson, ed- 
itors, The Lczical Basis of Sentence Process- 
in9. John Bcnjamins. 
1VI~tthew Crocker. 1999. Mech~misms for scn- 
|;ellce, tn'oeessing. In Garrod and Pieker- 
ing, editors, Language Proc~ssing. Psychology 
\])ross, London, UK. 
Mm'k ,Johnson. 1998. PCFG models of linguis- 
tic t;rec \]'el)rcse\]fl;~tions. Com, p,utational Lin- 
g'aistic.~, 24(4):613 632. 
\])~mi(;l .\]m:at~ky. \]996. A t)robabilistic n|o(M of 
lexi(:~tl nnd syntactic a(:(:ess and (lisambigua- 
tion. Cognitive Science, 20:137 194. 
Christot)her Mmming mid Him'ieh S(:lfiil;ze_ 
1999. l,b,a.ndatiou, s of Statistical Natural Lan- 
9'uag(: P'roct'.s,si'ng. MKI' Press, Cmnl)ridge, 
Mass~Lc:husetts. 
Mit(:hell IVlarmts, \]{eatrice S~mtorini, and 
Mary Ann M~rcinkiewicz. 1993. Building 
a lm:ge mmotated corl)us of English: The 
P(mn Treet)ank. Computational Linguistics, 
|!)(2):313 330. 
A(twait l/.~ttnat)~trkhi. 11!)!)7. A \]inem" ol)served 
time stnl;isI;ic;d t)m;ser based on m~tximmn en- 
tropy models. In \])'rocc.c:ding.s of the Co',:fcr- 
?:'m:c o'n Empirical Methods in Nat'a'ral La'n- 
g'uafle P'lvccssing \]'?MNLP-gZ Providence, 
11\]. 
\]h'inn Ronrk ~md Mm:k Johnson. 1!199. Efficient 
t)rol)al)ilisl, ic tot)-(lown ;rod left-(:orner pars- 
illg. hi \])'l'occcdi~,.(l,s of the. ,~7111, A~l, t,'ttal Mcc.t- 
i'ng of the A.ssociation for Cou~,p'atation Lin- 
g'aistic.~ A CL- 99, M~rybmd. 
117 
Modelling Semantic Role Plausibility in Human Sentence Processing
Ulrike Pad? and Matthew Crocker
Computational Linguistics
Saarland University
66041 Saarbr?cken
Germany
{ulrike,crocker}@coli.uni-sb.de
Frank Keller
School of Informatics
University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW, UK
keller@inf.ed.ac.uk
Abstract
We present the psycholinguistically moti-
vated task of predicting human plausibility
judgements for verb-role-argument triples
and introduce a probabilistic model that
solves it. We also evaluate our model on
the related role-labelling task, and com-
pare it with a standard role labeller. For
both tasks, our model benefits from class-
based smoothing, which allows it to make
correct argument-specific predictions de-
spite a severe sparse data problem. The
standard labeller suffers from sparse data
and a strong reliance on syntactic cues, es-
pecially in the prediction task.
1 Introduction
Computational psycholinguistics is concerned
with modelling human language processing.
Much work has gone into the exploration of sen-
tence comprehension. Syntactic preferences that
unfold during the course of the sentence have been
successfully modelled using incremental proba-
bilistic context-free parsing models (e.g., Jurafsky,
1996; Crocker and Brants, 2000). These models
assume that humans prefer the most likely struc-
tural alternative at each point in the sentence. If
the preferred structure changes during processing,
such models correctly predict processing difficulty
for a range of experimentally investigated con-
structions. They do not, however, incorporate an
explicit notion of semantic processing, while there
are many phenomena in human sentence process-
ing that demonstrate a non-trivial interaction of
syntactic preferences and semantic plausibility.
Consider, for example, the well-studied case of
reduced relative clause constructions. When incre-
mentally processing the sentence The deer shot by
the hunter was used as a trophy, there is a local
ambiguity at shot between continuation as a main
clause (as in The deer shot the hunter) or as a re-
duced relative clause modifying deer (equivalent
to The deer which was shot . . . ). The main clause
continuation is syntactically more likely.
However, there is a second, semantic clue pro-
vided by the high plausibility of deer being shot
and the low plausibility of them shooting. This
influences readers to choose the syntactically dis-
preferred reduced relative reading which interprets
the deer as an object of shot (McRae et al, 1998).
Plausibility has overridden the syntactic default.
On the other hand, for a sentence like The hunter
shot by the teenager was only 30 years old, se-
mantic plausibility initially reinforces the syntac-
tic main clause preference and readers show diffi-
culty accommodating the subsequent disambigua-
tion towards the reduced relative.
In order to model effects like these, we need
to extend existing models of sentence process-
ing by introducing a semantic dimension. Pos-
sible ways of integrating different sources of in-
formation have been presented e.g. by McRae
et al (1998) and Narayanan and Jurafsky (2002).
Our aim is to formulate a model that reliably pre-
dicts human plausibility judgements from corpus
resources, in parallel to the standard practice of
basing the syntax component of psycholinguistic
models on corpus probabilities or even probabilis-
tic treebank grammars. We can then use both the
syntactic likelihood and the semantic plausibility
score to predict the preferred syntactic alterna-
tive, thus accounting for the effects shown e.g. by
McRae et al (1998).
Independent of a syntactic model, we want any
semantic model we define to satisfy two criteria:
First, it needs to be able to make predictions in-
345
crementally, in parallel with the syntactic model.
This entails dealing with incomplete or unspeci-
fied (syntactic) information. Second, we want to
extend to semantics the assumption made in syn-
tactic models that the most probable alternative is
the one preferred by humans. The model therefore
must be probabilistic.
We present such a probabilistic model that can
assign roles incrementally as soon as a predicate-
argument pair is seen. It uses the likelihood of the-
matic role assignments to model human interpre-
tation of verb-argument relations. Thematic roles
are a description of the link between verb and ar-
gument at the interface between syntax and se-
mantics. Thus, they provide a shallow level of
sentence semantics which can be learnt from an-
notated corpora.
We evaluate our model by verifying that it in-
deed correctly predicts human judgements, and by
comparing its performance with that of a standard
role labeller in terms of both judgement prediction
and role assignment. Our model has two advan-
tages over the standard labeller: It does not rely
on syntactic features (which can be hard to come
by in an incremental task) and our smoothing ap-
proach allows it to make argument-specific role
predictions in spite of extremely sparse training
data. We conclude that (a) our model solves the
task we set, and (b) our model is better equipped
for our task than a standard role labeller.
The outline of the paper is as follows: After
defining the prediction task more concretely (Sec-
tion 2), we present our simple probabilistic model
that is tailoured to the task (Section 3). We in-
troduce our test and training data in Section 4. It
becomes evident immediately that we face a se-
vere sparse data problem, which we tackle on two
levels: By smoothing the distribution and by ac-
quiring additional counts for sparse cases. The
smoothed model succeeds on the prediction task
(Section 5). Finally, in Section 6, we compare our
model to a standard role labeller.
2 The Judgement Prediction Task
We can measure our intuitions about the plau-
sibility of hunters shooting and deer being shot
in terms of plausibility judgements for verb-role-
argument triples. Two example items from McRae
et al (1998) are presented in Table 1. The judge-
ments were gathered by asking raters to assign a
value on a scale from 1 (not plausible) to 7 (very
Verb Noun Role Rating
shoot hunter agent 6.9
shoot hunter patient 2.8
shoot deer agent 1.0
shoot deer patient 6.4
Table 1: Test items: Verb-noun pairs with ratings
on a 7 point scale from McRae et al (1998).
plausible) to questions like How common is it for
a hunter to shoot something? (subject reading:
hunter must be agent) or How common is it for a
hunter to be shot? (object reading: hunter must be
patient). The number of ratings available in each
of our three sets of ratings is given in Table 2 (see
also Section 4).
The task for our model is to correctly predict the
plausibility of each verb-role-argument triple. We
evaluate this by correlating the model?s predicted
values and the judgements. The judgement data
is not normally distributed, so we correlate using
Spearman?s ? (a non-parametric rank-order test).
The ? value ranges between 0 and 1 and indicates
the strength of association between the two vari-
ables. A significant positive value indicates that
the model?s predictions are accurate.
3 A Model of Human Plausibility
Judgements
We can formulate a model to solve the prediction
task if we equate the plausibility of a role assign-
ment to a verb-argument pair with its probability,
as suggested above. This value is influenced as
well by the verb?s semantic class and the grammat-
ical function of the argument. The plausibility for
a verb-role-argument triple can thus be estimated
as the joint probability of the argument head a, the
role r, the verb v, the verb?s semantic class c and
the grammatical function g f of a:
Plausibilityv,r,a = P(r,a,v,c,g f )
This joint probability cannot be easily estimated
from co-occurrence counts due to lack of data.
But we can decompose this term into a number
of subterms that approximate intuitively impor-
tant information such as syntactic subcategorisa-
tion (P(g f |v,c)), the syntactic realisation of a se-
mantic role (P(r|v,c,g f )) and selectional prefer-
ences (P(a|v,c,g f ,r)):
Plausibilityv,r,a = P(r,a,v,c,g f ) =
P(v) ?P(c|v) ?P(g f |v,c) ?
P(r|v,c,g f ) ?P(a|v,c,g f ,r)
346
shoot.02: [The hunter Arg0] shot [the deer Arg1].
Killing: [The hunter Killer] shot [the deer Victim].
Figure 1: Example annotation: PropBank (above)
and FrameNet (below).
Each of these subterms can be estimated more eas-
ily from the semantically annotated training data
simply using the maximum likelihood estimate.
However, we still need to smooth our estimates,
especially as the P(a|v,c,g f ,r) term remains very
sparse. We describe our use of two complemen-
tary smoothing methods in Section 5.
Our model fulfils the requirements we have
specified: It is probabilistic, able to work incre-
mentally as soon as a single verb-argument pair
is available, and can make predictions even if the
input information is incomplete. The model gen-
erates the missing values if, e.g., the grammatical
function or the verb?s semantic class are not spec-
ified. This means that we can immediately evalu-
ate on the judgement data without needing further
verb sense or syntactic information.
4 Test and Training data
Training Data To date, there are two main
annotation efforts that have produced semanti-
cally annotated corpora: PropBank (PB) and
FrameNet (FN). Their approaches to annotation
differ enough to warrant a comparison of the cor-
pora as training resources. Figure 1 gives an exam-
ple sentence annotated in PropBank and FrameNet
style. The PropBank corpus (c. 120,000 propo-
sitions, c. 3,000 verbs) adds semantic annotation
to the Wall Street Journal part of the Penn Tree-
bank. Arguments and adjuncts are annotated for
every verbal proposition in the corpus. A common
set of argument labels Arg0 to Arg5 and ArgM
(adjuncts) is interpreted in a verb-specific way.
Some consistency in mapping has been achieved,
so that Arg0 generally denotes agents and Arg1
patients/themes.
The FrameNet corpus (c. 58,000 verbal propo-
sitions, c. 1,500 verbs in release 1.1) groups verbs
with similar meanings together into frames (i.e.
descriptions of situations) with a set of frame-
specific roles for participants and items involved
(e.g. a killer, instrument and victim in the Killing
frame). Both the definition of frames as semantic
verb classes and the semantic characterisation of
frame-specific roles introduces a level of informa-
tion that is not present in PropBank. Since corpus
annotation is frame-driven, only some senses of a
verb may be present and word frequencies may not
be representative of English.
Test Data Our main data set consists of 160 data
points from McRae et al (1998) that were split
randomly into a 60 data point development set and
a 100 data point test set. The data is made up of
two arguments per verb and two ratings for each
verb-argument pair, one for the subject and one
for the object reading of the argument (see Section
2). Each argument is highly plausible in one of
the readings, but implausible in the other (recall
Table 1). Human ratings are on a 7-point scale.
In order to further test the coverage of our
model, we also include 76 items from Trueswell
et al (1994) with one highly plausible object per
verb and a rating each for the subject and object
reading of the argument. The data were gath-
ered in the same rating study as the McRae et
al. data, so we can assume consistency of the rat-
ings. However, in comparison to the McRae data
set, the data is impoverished as it lacks ratings for
plausible agents (in terms of the example in Ta-
ble 1, this means there are no ratings for hunter).
Lastly, we use 180 items from Keller and Lapata
(2003). In contrast with the previous two studies,
the verbs and nouns for these data were not hand-
selected for the plausibility of their combination.
Rather, they were extracted from the BNC corpus
by frequency criteria: Half the verb-noun combi-
nations are seen in the BNC with high, medium
and low frequency, half are unseen combinations
of the verb set with nouns from the BNC. The
data consists of ratings for 30 verbs and 6 argu-
ments each, interpreted as objects. The human
ratings were gathered using the Magnitude Esti-
mation technique (Bard et al, 1996). This data
set alows us to test on items that were not hand-
selected for a psycholinguistic study, even though
the data lacks agenthood ratings and the items are
poorly covered by the FrameNet corpus.
All test pairs were hand-annotated with
FrameNet and PropBank roles following the
specifications in the FrameNet on-line database
and the PropBank frames files.1
The judgement prediction task is very hard to
solve if the verb is unseen during training. Back-
ing off to syntactic information or a frequency
1Although a single annotator assigned the roles, the anno-
tation should be reliable as roles were mostly unambiguous
and the annotated corpora were used for reference.
347
Total Revised
Source FN PB
McRae et al (1998) 100 64 (64%) 92 (92%)
Trueswell et al (1994) 76 52 (68.4%) 72 (94.7%)
Keller and Lapata (2003) 180 ? 162 (90%)
Table 2: Test sets: Total number of ratings and size of revised test sets containing only ratings for seen
verbs (% of total ratings). ?: Coverage too low (26.7%).
baseline only works if the role set is small and syn-
tactically motivated, which is the case for Prop-
Bank, but not FrameNet. We present results both
for the complete test sets and and for revised sets
containing only items with seen verbs. Exclud-
ing unseen verbs seems justified for FrameNet and
has little effect for the PropBank corpus, since its
coverage is generally much better. Table 2 shows
the total number of ratings for each test set and
the sizes of the revised test sets containing only
items with seen verbs. FrameNet alays has sub-
stantially lower coverage. Since only 27% of the
verbs in the Keller & Lapata items are covered in
FrameNet, we do not test this combination.
5 Experiment 1: Smoothing Methods
We now turn to evaluating our model. It is im-
mediately clear that we have a severe sparse data
problem. Even if all the verbs are seen, the com-
binations of verbs and arguments are still mostly
unseen in training for all data sets.
We describe two complementary approaches
to smoothing sparse training data. One, Good-
Turing smoothing, approaches the problem of un-
seen data points by assigning them a small proba-
bility. The other, class-based smoothing, attempts
to arrive at semantic generalisations for words.
These serve to identify equivalent verb-argument
pairs that furnish additional counts for the estima-
tion of P(a|v,c,g f ,r).
5.1 Good-Turing Smoothing and Linear
Interpolation
We first tackle the sparse data problem by smooth-
ing the distribution of co-occurrence counts. We
use the Good-Turing re-estimate on zero and one
counts to assign a small probability to unseen
events. This method relies on re-estimating the
probability of seen and unseen events based on
knowledge about more frequent events.
Adding Linear Interpolation We also exper-
imented with the linear interpolation method,
which is typically used for smoothing n-gram
models. It re-estimates the probability of the n-
gram in question as a weighted combination of the
n-gram, the n-1-gram and the n-2-gram. For ex-
ample, P(a|v,c,g f ,r) is interpolated as
P(a|v,c,g f ,r) = ?1P(a|v,c,g f ,r)+
?2P(a|v,c,r)+?3P(a|v,c)
The ? values were estimated on the training
data, separately for each of the model?s four con-
ditional probability terms, by maximising five-fold
cross-validation likelihood to avoid overfitting.
We smoothed all model terms using the Good-
Turing method and then interpolated the smoothed
terms. Table 3 lists the test results for both train-
ing corpora and all test sets when Good-Turing
smoothing (GT) is used alone and with linear in-
terpolation (GT/LI). We also give the unsmoothed
coverage and correlation. The need for smoothing
is obvious: Coverage is so low that we can only
compute correlations in two cases, and even for
those, less than 20% of the data are covered.
GT smoothing alone always outperforms the
combination of GT and LI smoothing, especially
for the FrameNet training set. Maximising the
data likelihood during ? estimation does not ap-
proximate our final task well enough: The log
likelihood of the test data is duly improved from
?797.1 to ?772.2 for the PropBank data and from
?501.9 to ?446.3 for the FrameNet data. How-
ever, especially for the FrameNet training data,
performance on the correlation task diminishes as
data probability rises. A better solution might be
to use the correlation task directly as a ? estima-
tion criterion, but this is much more complex, re-
quiring us to estimate all ? terms simultaneously.
Also, the main problem seems to be that the ? in-
terpolation smoothes by de-emphasising the most
specific (and sparsest) term, so that, on our final
task, the all-important argument-specific informa-
tion is not used efficiently when it is available. We
therefore restrict ourselves to GT smoothing.
348
Smoothed Unsmoothed
Train Smoothing Test Coverage ? Coverage ?
PB
GT
McRae 93.5% (86%) 0.112, ns 2% (2%) ?
Trueswell 100% (94.7%) 0.454, ** 17% (16%) ns
Keller&Lapata 100% (90%) 0.285, ** 5% (4%) 0.727, *
GT/LI
McRae 93.5% (86%) 0.110, ns 2% (2%) ?
Trueswell 100% (94.7%) 0.404, ** 17% (16%) ns
Keller&Lapata 100% (90%) 0.284, ** 5% (4%) 0.727, *
FN
GT McRae 87.5% (56%) 0.164, ns 6% (4%) ?Trueswell 76.9% (52.6%) 0.046, ns 6% (4%) ?
GT/LI McRae 87.5% (56%) 0.042, ns 6% (4%) ?Trueswell 76.9% (52.6%) 0.009, ns 6% (4%) ?
Table 3: Experiment 1, GT and Interpolation smoothing. Coverage on seen verbs (and on all items) and
correlation strength (Spearman?s ? for PB and FN data on all test sets. ?: too few data points, ns: not
significant, *: p < 0.05, **: p < 0.01.
Model Performance Both versions of the
smoothed model make predictions for all seen
verbs; the remaining uncovered data points are
those where the correct role is not accounted for
in the training data (the verb may be very sparse
or only seen in a different FrameNet frame). For
the FrameNet training data, there are no significant
correlations, but for the PropBank data, we see
correlations for the Trueswell and Keller&Lapata
sets. One reason for the good performance of
the PB-Trueswell and PB-Keller&Lapata combi-
nations is that in the PropBank training data, the
object role generally seems to be the most likely
one. If the most specific probability term is sparse
and expresses no role preference (which is the case
for most items: see Unsmoothed Coverage), our
model is biased towards the most likely role given
the verb, semantic class and grammatical function.
Recall that the Trueswell and Keller&Lapata data
contain ratings for (plausible) objects only, so that
preferring the patient role is a good strategy. This
also explains why the model performs worse for
the McRae et al data, which also has ratings for
good agents (and bad patients). On FrameNet, this
preference for ?patient? roles is not as marked, so
the FN-Trueswell case does not behave like the
PB-Trueswell case.
5.2 Class-Based Smoothing
In addition to smoothing the training distribution,
we also attempt to acquire more counts to es-
timate each P(a|v,c,g f ,r) by generalising from
tokens to word classes. The term we estimate
becomes P(classa|classv,g f ,r). This allows us
to make argument-specific predictions as we do
not rely on a uniform smoothed term for unseen
P(a|v,c,g f ,r) terms. We use lexicographic noun
classes from WordNet and verb classes induced
by soft unsupervised clustering, which outperform
lexicographic verb classes.
Noun Classes We tested both the coarsest and
the finest noun classification available in Word-
Net, namely the top-level ontology and the noun
synsets which contain only synonyms of the target
word.2 The top-level ontology proved to overgen-
erate alternative nouns, which raises coverage but
does not produce meaningful role predictions. We
therefore use the noun synsets below.
Verb Classes Verbs are clustered according to
linguistic context information, namely argument
head lemmas, the syntactic configuration of verb
and argument, the verb?s semantic class, the gold
role information and a combined feature of gold
role and syntactic configuration. The evaluation of
the clustering task itself is task-based: We choose
the clustering configuration that produces optimal
results in the the prediction task on the McRae de-
velopment set. The base corpus for clustering was
always used for frequency estimation.
We used an implementation of two soft clus-
tering algorithms derived from information the-
ory (Marx, 2004): the Information Distortion (ID)
(Gedeon et al, 2003) and Information Bottleneck
(IB) (Tishby et al, 1999) methods. Soft cluster-
ing allows us to take verb polysemy into account
that is often characterised by different patterns of
syntactic behaviour for each verb meaning.
2For ambiguous nouns, we chose the sense that led to the
highest probability for the current role assignment.
349
A number of parameters were set on the devel-
opment set, namely the clustering algorithm, the
smoothing method within the algorithms and the
number of clusters within each run. For our task,
the IB algorithm generally yielded better results.
We decided which clustering parametrisations
should be tried on the test sets based on the notion
of stability: Both algorithms increase the number
of clusters by one at each iteration. Thus, each
parametrisation yields a series of cluster configu-
rations as the number of iterations increases. We
chose those parametrisations where a series of at
least three consecutive cluster configurations re-
turned significant correlations on the development
set. This should be an indication of a generalisable
success, rather than a fluke caused by peculiarities
of the data. On the test sets, results are reported
for the configuration (characterised by the itera-
tion number) that returned the first significant re-
sult in such a series on the development set, as this
is the most general grouping.
5.3 Combining the Smoothing Methods
We now present results for combining the GT
and class-based smoothing methods. We use in-
duced verb classes and WordNet noun synsets for
class-based smoothing of P(a|v,c,g f ,r), and rely
on GT smoothing if the counts for this term are
still sparse. All other model terms are always
smoothed using the GT method. Table 4 contains
results for three clustering configurations each for
the PropBank and FrameNet data that have proven
stable on the development set. We characterise
them by the clustering algorithm (IB or ID) and
number of clusters. Note that the upper bound for
our ? values, human agreement or inter-rater cor-
relation, is below 1 (as indicated by a correlation
of Pearson?s r = .640 for the seen pairs from the
Keller and Lapata (2003) data).
For the FrameNet data, there is a marked in-
crease in performance for both test sets. The hu-
man judgements are now reliably predicted with
good coverage in five out of six cases. Clearly,
equivalent verb-argument counts have furnished
accurate item-specific estimates. On the PropBank
data set, class-based smoothing is less helpful: ?
values generally drop slightly. Apparently, the
FrameNet style of annotation allows us to induce
informative verb classes, whereas the PropBank
classes introduce noise at most.
6 Experiment 2: Role Labelling
We have shown that our model performs well on
its intended task of predicting plausibility judge-
ments, once we have proper smoothing methods
in place. But since this task has some similarity
to role labelling, we can also compare the model
to a standard role labeller on both the prediction
and role labelling tasks. The questions are: How
well do we do labelling, and does a standard role
labeller also predict human judgements?
Beginning with work by Gildea and Jurafsky
(2002), there has been a large interest in se-
mantic role labelling, as evidenced by its adop-
tion as a shared task in the Senseval-III compe-
tition (FrameNet data, Litkowski, 2004) and at
the CoNLL-2004 and 2005 conference (PropBank
data, Carreras and M?rquez, 2005). As our model
currently focuses on noun phrase arguments only,
we do not adopt these test sets but continue to use
ours, defining the correct role label to be the one
with the higher probability judgement. We evalu-
ate the model on the McRae test set (recall that the
other sets only contain good patients/themes and
are therefore susceptible to labeller biases).
We formulate frequency baselines for our train-
ing data. For PropBank, always assigning Arg1
results in F = 45.7 (43.8 on the full test set). For
FrameNet, we assign the most frequent role given
the verb, so the baseline is F = 34.4 (26.8).
We base our standard role labelling system on
the SVM labeller described in Giuglea and Mos-
chitti (2004), although without integrating infor-
mation from PropBank and VerbNet for FrameNet
classification as presented in their paper. Thus, we
are left with a set of fairly standard features, such
as phrase type, voice, governing category or path
through parse tree from predicate. These are used
to train two classifiers, one which decides which
phrases should be considered arguments and one
which assigns role labels to these arguments. The
SVM labeller?s F score on an unseen test set is
F = 80.5 for FrameNet data when using gold ar-
gument boundaries. We also trained the labeller
on the PropBank data, resulting in an F score of
F = 98.6 on Section 23, again on gold boundaries.
We also evaluate the SVM labeller on the cor-
relation task by normalising the scores that the la-
beller assigns to each role and then correlating the
normalised scores to the human ratings.
In order to extract features for the SVM labeller,
we had to present the verb-noun pairs in full sen-
350
Train Test Verb Clusters Coverage ?
PB
McRae
ID 4 93.5% (86%) 0.097, ns
IB 10 93.5% (86%) 0.104, ns
IB 5 93.5% (86%) 0.107, ns
Trueswell
ID 4 100% (94.7%) 0.419, **
IB 10 100% (94.7%) 0.366, **
IB 5 100% (94.7%) 0.439, **
Keller&Lapata
ID 4 100% (90%) 0.300, **
IB 10 100% (90%) 0.255, **
IB 5 100% (90%) 0.297, **
FN
McRae
ID 4 87.5% (56%) 0.304, *
IB 9 87.5% (56%) 0.275, *
IB 10 87.5% (56%) 0.267, *
Trueswell
ID 4 76.9% (52.6%) 0.256, ns
IB 9 76.9% (52.6%) 0.342, *
IB 10 76.9% (52.6%) 0.365, *
Table 4: Experiment 1: Combining the smoothing methods. Coverage on seen verbs (and on all items)
and correlation strength (Spearman?s ?) for PB and FN data. WN synsets as noun classes. Verb classes:
IB/ID: smoothing algorithm, followed by number of clusters. ns: not significant, *: p<0.05, **: p<0.01
tences, as the labeller relies on a number of fea-
tures from parse trees. We used the experimental
items from the McRae et al study, which are all
disambiguated towards a reduced relative reading
(object interpretation: The hunter shot by the ...)
of the argument. In doing this, we are potentially
biasing the SVM labeller towards one label, de-
pending on the influence of syntactic features on
role assignment. We therefore also created a main
clause reading of the verb-argument pairs (sub-
ject interpretation: The hunter shot the ...) and
present the results for comparison. For our model,
we have previously not specified the grammatical
function of the argument, but in order to put both
models on a level playing field, we now supply the
grammatical function of Ext (external argument),
which applies for both formulations of the items.
Table 5 shows that for the labelling task, our
model outperforms the labelling baseline and the
SVM labeller on the FrameNet data by at least
16 points F score while the correlation with hu-
man data remains significant. For the PropBank
data, labelling performance is on baseline level,
below the better of the two SVM labeller condi-
tions. This result underscores the usefulness of
argument-specific plausibility estimates furnished
by class-based smoothing for the FrameNet data.
For the PropBank data, our model essentially as-
signs the most frequent role for the verb.
The performance of the SVM labeller suggests
a strong influence of syntactic features: On the
PropBank data set, it always assigns the Arg0 la-
bel if the argument was presented as a subject
(this is correct in 50% of cases) and mostly the
appropriate ArgN label if the argument was pre-
sented as an object. On FrameNet, performance
again is above baseline only for the subject condi-
tion, where there is also a clear trend for assign-
ing agent-style roles. (The object condition is less
clear-cut.) This strong reliance on syntactic cues,
which may be misleading for our data, makes the
labeller perform much worse than on the standard
test sets. For both training corpora, it does not
take word-specific plausibility into account due to
data sparseness and usually assigns the same role
to both arguments of a verb. This precludes a sig-
nificant correlation with the human ratings.
Comparing the training corpora, we find that
both models perform better on the FrameNet data
even though there are many more role labels in
FrameNet, and the SVM labeller does not profit
from the greater smoothing power of FrameNet
verb clusters. Overall, FrameNet has proven more
useful to us, despite its smaller size.
In sum, our model does about as well (PB data)
or better (FN data) on the labelling task as the
SVM labeller, while the labeller does not solve
the prediction task. The success of our model, es-
pecially on the prediction task, stems partly from
the absence of global syntactic features that bias
the standard labeller strongly. This also makes our
model suited for an incremental task. Instead of
351
Train Model Coverage ? Labelling F Labelling Cov.
PB
Baseline ? ? 45.7 (43.8%) 100%
SVM Labeller (subj) 100% (92%) ns 50 (47.9%) 100%
SVM Labeller (obj) 100% (92%) ns 45.7 (43.8%) 100%
IB 5 (subj/obj) 93.5% (86%) ns 45.7 (43.8%) 100%
FN
Baseline ? ? 34.4 (26.8%) 100%
SVM Labeller (subj) 87.5% (56%) ns 40.6 (31.7%) 100%
SVM Labeller (obj) 87.5% (56%) ns 34.4 (26.8%) 100%
ID 4 (subj/obj) 87.5% (56%) 0.271, * 56.3 (43.9%) 100%
Table 5: Experiment 2: Standard SVM labeller vs our model. Coverage on seen verbs (and on all items),
correlation strength (Spearman?s ?), labelling F score and labelling coverage on seen verbs (and on all
items, if different) for PB and FN data on the McRae test set. ns: not significant, *: p<0.05.
syntactic cues, we successfully rely on argument-
specific plausibility estimates furnished by class-
based smoothing. Our joint probability model has
the further advantage of being conceptually much
simpler than the SVM labeller, which relies on a
sophisticated machine learning paradigm. Also,
we need to compute only about one-fifth of the
number of SVM features.
7 Conclusions
We have defined the psycholinguistically moti-
vated task of predicting human plausibility ratings
for verb-role-argument triples. To solve it, we
have presented an incremental probabilistic model
of human plausibility judgements. When we em-
ploy two complementary smoothing methods, the
model achieves both good coverage and reliable
correlations with human data. Our model per-
forms as well as or better than a standard role la-
beller on the task of assigning the preferred role to
each item in our test set. Further, the standard la-
beller does not succeed on the prediction task, as it
cannot overcome the extreme sparse data problem.
Acknowledgements Ulrike Pad? acknowledges
a DFG studentship in the International Post-
Graduate College ?Language Technology and
Cognitive Systems?. We thank Ana-Maria Giu-
glea, Alessandro Moschitti and Zvika Marx for
making their software available and are grateful to
Amit Dubey, Katrin Erk, Mirella Lapata and Se-
bastian Pad? for comments and discussions.
References
Bard, E. G., Robertson, D., and Sorace, A. (1996). Magnitude
estimation of linguistic acceptability. Language, 72(1),
32?68.
Carreras, X. and M?rquez, L. (2005). Introduction to the
CoNLL-2005 shared task: Semantic role labeling. In Pro-
ceedings of CoNLL-2005.
Crocker, M. and Brants, T. (2000). Wide-coverage proba-
bilistic sentence processing. Journal of Psycholinguistic
Research, 29(6), 647?669.
Gedeon, T., Parker, A., and Dimitrov, A. (2003). Information
distortion and neural coding. Canadian Applied Mathe-
matics Quarterly, 10(1), 33?70.
Gildea, D. and Jurafsky, D. (2002). Automatic labeling of
semantic roles. Computational Linguistics, 28(3), 245?
288.
Giuglea, A.-M. and Moschitti, A. (2004). Knowledge discov-
ery using FrameNet, VerbNet and PropBank. In Proceed-
ings of the Workshop on Ontology and Knowledge Discov-
ering at ECML 2004.
Jurafsky, D. (1996). A probabilistic model of lexical and syn-
tactic access and disambiguation. Cognitive Science, 20,
137?194.
Keller, F. and Lapata, M. (2003). Using the web to obtain fre-
quencies for unseen bigrams. Computational Linguistics,
29(3), 459?484.
Litkowski, K. (2004). Senseval-3 task: Automatic labeling of
semantic roles. In Proceedings of Senseval-3: The Third
International Workshop on the Evaluation of Systems for
the Semantic Analysis of Text.
Marx, Z. (2004). Structure-Based computational aspects of
similarity and analogy in natural language. Ph.D. thesis,
Hebrew University, Jerusalem.
McRae, K., Spivey-Knowlton, M., and Tanenhaus, M.
(1998). Modeling the influence of thematic fit (and other
constraints) in on-line sentence comprehension. Journal
of Memory and Language, 38, 283?312.
Narayanan, S. and Jurafsky, D. (2002). A Bayesian model
predicts human parse preference and reading time in sen-
tence processing. In S. B. T. G. Dietterich and Z. Ghahra-
mani, editors, Advances in Neural Information Processing
Systems 14, pages 59?65. MIT Press.
Tishby, N., Pereira, F. C., and Bialek, W. (1999). The in-
formation bottleneck method. In Proc. of the 37-th An-
nual Allerton Conference on Communication, Control and
Computing, pages 368?377.
Trueswell, J., Tanenhaus, M., and Garnsey, S. (1994). Seman-
tic influences on parsing: Use of thematic role information
in syntactic ambiguity resolution. Journal of Memory and
Language, 33, 285?318.
352
A Connectionist Model of Anticipation in Visual Worlds
Marshall R. Mayberry, III, Matthew W. Crocker, and Pia Knoeferle
Department of Computational Linguistics,
Saarland University, Saarbru?cken, Germany
{martym, crocker, knoferle}@coli.uni-sb.de
Abstract. Recent ?visual worlds? studies, wherein researchers study language in
context by monitoring eye-movements in a visual scene during sentence process-
ing, have revealed much about the interaction of diverse information sources and
the time course of their influence on comprehension. In this study, five experi-
ments that trade off scene context with a variety of linguistic factors are modelled
with a Simple Recurrent Network modified to integrate a scene representation
with the standard incremental input of a sentence. The results show that the model
captures the qualitative behavior observed during the experiments, while retain-
ing the ability to develop the correct interpretation in the absence of visual input.
1 Introduction
There are two prevalent theories of language acquisition. One view emphasizes syntac-
tic and semantic bootstrapping during language acquisition that enable children to learn
abstract concepts from mappings between different kinds of information sources [1,2].
Another view emerges from connectionist literature and emphasizes the learning of lin-
guistic structure from purely distributional properties of language usage [3,4]. While the
perspectives are often taken to be diametrically opposed, both can be seen as crucially
relying on correlations between words and their immediate context, be it the sentence
as a whole or extra-linguistic input, such as a scene.
We combine insights from both distributional and bootstrapping accounts in mod-
elling the on-line comprehension of utterances in both the absence and presence of a vi-
sual scene. This is an important achievement in at least two regards. First, it emphasizes
the complementarity between distributional and bootstrapping approaches?discovering
structure across linguistic and scene contexts [5]. Further, it is an important first step in
linking situated models of on-line utterance comprehension more tightly to accounts of
language acquisition, thus emphasizing the continuity of language processing.
We present results from two simulations on a Simple Recurrent Network (SRN; [3]).
Modification of the network to integrate input from a scene together with the charac-
teristic incremental processing of such networks allowed us to model people?s ability
to adaptively use the contextual information in order to more rapidly interpret and dis-
ambiguate a sentence. The model draws on recent studies that appeal to theories of lan-
guage acquisition to account for the comprehension of scene-related utterances [6,7].
Recent research within the visual worlds paradigm, wherein participants? gazes to a
scene while listening to an utterance are monitored, provides support for this view. Find-
ings from this paradigm support an account of scene-related utterance comprehension in
R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 849?861, 2005.
c? Springer-Verlag Berlin Heidelberg 2005
850 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
which the rapid coordinated interaction of information from the immediate scene, and
linguistic knowledge plays a major role in incremental and anticipatory comprehension.
2 Simulation 1
In Simulation 1, we simultaneously model four experiments that show the rapid influ-
ence of diverse informational sources?linguistic and world knowledge as well as scene
information ? on utterance comprehension. All experiments were conducted in German,
a language that allows both subject-verb-object (SVO) and object-verb-subject (OVS)
sentence types. In the face of word order ambiguity, case marking indicates the subject
or object grammatical function, except in the case of feminine and neuter noun phrases
where the article does not distinguish the nominative and accusative cases.
2.1 Anticipation Depending on Stereotypicality
The first two experiments that we modeled examined how linguistic and world knowl-
edge or stereotypicality enabled rapid thematic role assignment in unambiguous sen-
tences, thus determining who-does-what-to-whom in a scene.
Fig. 1. Selectional Restrictions
Experiment 1: Morphosyntactic and lexical verb information. To examine the influ-
ence of case-marking and verb plausibility on thematic role assignment, [8] presented
participants with utterances such as (1) or (2) that described a scene showing a hare, a
cabbage, a fox, and a distractor (see Figure 1) :
(1) Der Hase frisst gleich den Kohl.
The harenom eats shortly the cabbageacc.
(2) Den Hasen frisst gleich der Fuchs.
The hareacc eats shortly the foxnom.
After hearing ?The harenom eats ...? and ?The hareacc eats ...?, people made anticipatory
eye-movements to the cabbage and fox respectively. This reveals that people were able
to predict role fillers in a scene through linguistic/world knowledge that identified who-
does-what-to-whom.
A Connectionist Model of Anticipation in Visual Worlds 851
Experiment 2: Verb type information. To further investigate the role of verb infor-
mation, the authors replaced the agent/patient verbs like frisst (?eats?) with experi-
encer/theme verbs like interessiert (?interests?). This manipulation interchanged agent
(experiencer) and patient (theme) roles from Experiment 1. For Figure 1 and the subject-
first (3) or object-first sentence (4), participants showed gaze fixations complementary
to those of Experiment 1, confirming that both case and semantic verb information are
used to predict relevant role fillers.
(3) Der Hase interessiert ganz besonders den Fuchs.
The harenom interests especially the foxacc.
(4) Den Hasen interessiert ganz besonders der Kohl.
The hareacc interests especially the cabbagenom.
2.2 Anticipation Depending on Depicted Events
The second set of experiments investigated whether depicted events showing who-does-
what-to-whom can establish a scene character?s role as agent or patient when syntactic
and thematic role relations are temporarily ambiguous in the utterance.
Fig. 2. Depicted Events
Experiment 3: Verb-mediated depicted role relations. [9] presented such initially
ambiguous spoken SVO (5) and OVS sentences (6) together with a scene in which a
princess both paints a fencer and is washed by a pirate (Figure 2):
(5) Die Princessin malt offensichtlich den Fechter.
The princessnom paints obviously the fenceracc.
(6) Die Princessin wa?scht offensichtlich der Pirat.
The princessacc washes obviously the piratenom.
Linguistic disambiguation occurred on the second NP; disambiguation prior to the sec-
ond NP was only possible through use of the depicted events. When the verb identified
an action, the depicted role relations disambiguated towards either an agent-patient (5)
or patient-agent (6) role relation, as indicated by anticipatory eye-movements to the pa-
tient (pirate) or agent (fencer) respectively for (5) and (6). This gaze-pattern showed the
852 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
rapid influence of verb-mediated depicted events on the assignment of thematic roles to
a temporarily ambiguous sentence-initial noun phrase.
Experiment 4: Weak temporal adverb constraint. [9] also investigated German verb-
final active (7) and passive (8) constructions. In this type of sentence, the initial subject
noun phrase is role-ambiguous, and the auxiliary wird can have a passive or future
interpretation.
(7) Die Princessin wird sogleich den Pirat washen.
The princessnom will right away wash the pirateacc.
(8) Die Princessin wird soeben von dem Fechter gemalt.
The princessacc is just now painted by the fencernom.
To evoke early linguistic disambiguation, temporal adverbs biased the auxiliary wird to-
ward either the future (?will?) or passive (?is -ed?) reading. Since the verb was sentence-
final, the interplay of scene and linguistic cues (e.g., temporal adverbs) were rather more
subtle. When the listener heard a future-biased adverb such as sogleich, after the aux-
iliary wird, he interpreted the initial NP as agent of a future active construction, as evi-
denced by anticipatory eye-movements to the patient in the scene. Conversely, listeners
interpreted the passive-biased construction soeben with these roles exchanged.
2.3 Architecture
The Simple Recurrent Network is a type of neural network typically used to process
temporal sequences of patterns such as words in a sentence. A common approach is
for the modeller to train the network on prespecified targets, such as verbs and their
arguments, that represent what the network is expected to produce upon completing a
sentence. Processing is incremental, with each new input word interpreted in the con-
text of the sentence processed so far, represented by a copy of the previous hidden
layer serving as additional input or context to the current hidden layer. Because these
types of associationist models automatically develop correlations among the data they
are trained on, they will generally develop expectations about the output even before
processing is completed because sufficient information occurs early in the sentence to
warrant such predictions. Moreover, during the course of processing a sentence these
expectations can be overridden with subsequent input, often abruptly revising an inter-
pretation in a manner reminiscent of how humans seem to process language. Indeed,
it is these characteristics of incremental processing, the automatic development of ex-
pectations, seamless integration of multiple sources of information, and nonmonotonic
revision that have endeared neural network models to cognitive researchers.
In Simulation 1, the four experiments described above have been modelled simul-
taneously using a single network. The goal of modelling all experimental results by a
single architecture required enhancements to the SRN, the development and presenta-
tion of the training data, as well as the training regime itself. We describe these next.
In two of the experiments, only three characters are depicted, the representation of
which can be propagated directly to the network?s hidden layer. In the other two exper-
iments, the scene featured three characters involved in two events (e.g., pirate-washes-
princess and princess-paints-fencer, as shown in Figure 3). The middle character was
A Connectionist Model of Anticipation in Visual Worlds 853
hidden layer
context layer
event layers
waescht Prinzessin Pirat PAT
input layer
waescht
Fig. 3. Scene Integration
involved in both events, either as an agent or a patient (e.g., princess). Only one of the
events, however, corresponded to the spoken linguistic input.
The representation of this scene information and its integration into the model?s
processing was the primary modification to the SRN. Connections between representa-
tions for the depicted characters and the hidden layer were provided. Encoding of the
depicted events, when present, required additional links from the characters and de-
picted actions to event layers, and links from these event layers to the SRN?s hidden
layer. Representations for the events were developed in the event layers by compress-
ing the scene representations of the involved characters and depicted actions through
weights corresponding to the action, its agent and its patient for each event. This event
representation was kept simple and only provided conceptual input to the hidden layer:
who did what to whom was encoded for both events, when depicted; richer grammatical
information (e.g., case and gender on articles) only came from the linguistic input.
Neural networks will usually encode any correlations in the data that help to min-
imize error. In order to prevent the network from encoding regularities in its weights
regarding the position of the characters and events given in the scene (such as, for ex-
ample, that the central character in the scene corresponds to the first NP in the presented
sentence) which are not relevant to the role-assignment task, one set of weights was used
for all characters, and another set of weights used for both events. This weight-sharing
ensured that the network had to access the information encoded in the event layers, or
determine the relevant characters itself, thus improving generalization. The representa-
tions for the characters and actions were the same for both input (scene and sentence)
and output.
854 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
The input assemblies were the scene representations and the current word from the
input sentence. The output assemblies were the verb, the first and second nouns, and an
assembly that indicated whether the first noun was the agent or patient of the sentence
(token PAT in Figure 3). Typically, agent and patient assemblies would be fixed in a
case-role representation without such a discriminator, and the model required to learn
to instantiate them correctly [10]. However, we found that the model performed much
better when the task was recast as having to learn to isolate the nouns in the order in
which they are introduced, and separately mark how those nouns relate to the verb. The
input and output assemblies had 100 units each, the event layers contained 200 units
each, and the hidden and context layers consisted of 400 units.
2.4 Input Data, Training, and Experiments
We trained the network to correctly handle sentences involving non-stereotypical events
as well as stereotypical ones, both when visual context was present and when it was ab-
sent. As over half a billion sentence/scene combinations were possible for all of the
experiments, we adopted a grammar-based approach to randomly generate sentences
and scenes based on the materials from each experiment while holding out the actual
materials to be used for testing. Because of the complementary roles that stereotypical-
ity played in the two sets of experiments, there was virtually no lexical overlap between
them. In order to accurately model the first two experiments involving selectional re-
strictions on verbs, two additional words were added to the lexicon for each charac-
ter selected by a verb. For example, in the sentence Der Hase frisst gleich den Kohl,
the nouns Hase1, Hase2, Kohl1, and Kohl2 were used to develop training sentences.
These were meant to represent, for example, words such as ?rabbit? and ?jackrabbit? or
?carrot? and ?lettuce? in the lexicon that have the same distributional properties as the
orignal words ?hare? and ?cabbage?. With these extra tokens the network could learn
that Hase, frisst, and Kohl were correlated without ever encountering all three words
in the same training sentence. The experiments involving non-stereotypicality did not
pose this constraint, so training sentences were simply generated to avoid presenting
experimental items.
Some standard simplifications to the words have been made to facilitate modelling.
For example, multi-word adverbs such as fast immer were treated as one word through
hyphenation so that sentence length within a given experimental set up is maintained.
Nominal case markings such as -n in Hasen were removed to avoid sparse data as these
markings are idiosyncratic, and the case markings on the determiners are more infor-
mative overall. More importantly, morphemes such as the infinitive marker -en and
past participle ge- were removed, because, for example, the verb forms malt, malen,
and gemalt, would all be treated as unrelated tokens, again contributing unnecessarily
to the problem with sparse data. The result is that one verb form is used, and to per-
form accurately, the network must rely on its position in the sentence (either second or
sentence-final), as well as whether the word von occurs to indicate a participial reading
rather than infinitival. All 326 words in the lexicon for the first four experiments were
given random representations.
We trained the network by repeatedly presenting the model with 1000 randomly
generated sentences from each experiment (constituting one epoch) and testing every
A Connectionist Model of Anticipation in Visual Worlds 855
100 epochs against the held-out test materials for each of the five experiments. Scenes
were provided half of the time to provide an unbiased approximation to linguistic expe-
rience. The network was initialized with weights between -0.01 and 0.01. The learning
rate was initially set to 0.05 and gradually reduced to 0.002 over the course of 15000
epochs. Four splits took a little less than two weeks to complete on 1.6Ghz PCs.
2.5 Results
Figure 4 reports the percentage of targets at the network?s output layer that the model
correctly matches, both as measured at the adverb and at the end of the sentence. The
model clearly demonstrates the qualitative behavior observed in all four experiments in
that it is able to access the information either from the encoded scene or stereotypicality
and combine it with the incrementally presented sentence to anticipate forthcoming
arguments.
 85
 90
 95
 100
Exp 1 Exp 2 Exp 3 Exp 4
P e
rc
e n
ta
g e
 C
o r
re
c t
Adverb
NP2
Fig. 4. Results
For the two studies using stereotypical information (experiments 1 and 2), the net-
work achieved just over 96% at sentence end, and anticipation accuracy was just over
95% at the adverb. Because these sentences are unambiguous, the model is able to
correctly identify the role of the upcoming argument, but makes errors in token iden-
tification, confusing words that are within the selectionally restricted set, such as, for
example, Kohl and Kohl2. Thus, the model has not quite mastered the stereotypical
knowledge, particularly as it relates to the presence of the scene.
In the other two experiments using non-stereotypical characters and depicted events
(experiments 3 and 4), accuracy was 100% at the end of the sentence. More impor-
tantly, the model achieved over 98% early disambiguation on experiment 3, where the
sentences were simple, active SVO and OVS. Early disambiguation on experiment 4
was somewhat harder because the adverb is the disambiguating point in the sentence
as opposed to the verb in the other three experiments. As nonlinear dynamical sys-
tems, neural networks sometimes require an extra step to settle after a decision point is
reached due to the attractor dynamics of the weights. For both experiments, most errors
occurred on role-assignment due to the initially-ambiguous first noun phrase.
856 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
The difference in performance between the first two experiments and second two
experiments can be attributed to the event layer that was only available in experiments
3 and 4. Closer inspection of the model?s behavior during processing revealed that finer
discrimination was encoded in the links between the event layers and hidden layer than
that encoded in the weights between the characters and the hidden layer.
3 Simulation 2
The previous set of experiments demonstrated the rapid use of either linguistic knowl-
edge or depicted events to anticipate forthcoming arguments in a sentence. A further
important question is the relative importance of these two informational sources when
they conflict. We first review an experimental study by [6] designed to address this issue
and then report relevant modelling results.
Fig. 5. Scene vs Stored Knowledge
Scene vs Stored Knowledge. One goal of the study by [6] was to verify that stored
knowledge about non-depicted events and information from depicted, but non-stereo-
typical, events each enable rapid thematic interpretation. Case-marking on the first NP
always identified the pilot as a patient. After hearing the verb in (9) more inspections to
the only food-serving agent (detective) than to the other agent showed the influence of
depicted events. In contrast, when people heard the verb in condition two (10), a higher
proportion of anticipatory eye-movements to the only stereotypical agent (wizard) than
to the other agent revealed the influence of stereotypical knowledge (see Figure 5).
(9) Den Piloten verko?stigt gleich der Detektiv.
The pilotacc serves-food-to shortly the detectivenom.
(10) Den Piloten verzaubert gleich der Zauberer.
The pilotacc jinxes shortly the wizardnom.
Second, the study determined the relative importance of depicted events and verb-based
thematic role knowledge when these information sources competed. In conditions three
and four ((11) & (12)) participants heard an utterance in which the verb identified both a
A Connectionist Model of Anticipation in Visual Worlds 857
stereotypical (detective) and a depicted agent (wizard). In this case, people preferred to
rely on the immediate event depictions over stereotypical knowledge, and looked more
often at the wizard, the agent of the depicted event, than at the other, stereotypical agent
of the spying-action (the detective).
(11) Den Piloten bespitzelt gleich der Zauberer.
The pilotacc spies-on shortly the wizardnom.
(12) Den Piloten bespitzelt gleich der Detektiv.
The pilotacc spies-on shortly the detectivenom.
3.1 Architecture, Data, Training, and Results
In simulation 1, we modelled experiments that depended on stereotypicality or depicted
events, but not both. The experiment modelled in simulation 2, however, was specif-
ically designed to investigate how these two information sources interacted. Accord-
ingly, the network needed to learn to use either information from the scene or stereotyp-
icality when available, and, moreover, favor the scene when the two sources conflicted,
as observed in the empirical results. Recall that the network is trained only on the final
interpretation of a sentence. Thus, capturing the observed behavior required manipula-
tion of the frequencies of the four conditions described above during training. In order
to train the network to develop stereotypical agents for verbs, the frequency that a verb
occurs with its stereotypical agent, such as Detektiv and bespitzelt from example (12)
above, had to be greater than for a non-stereotypical agent. However, the frequency
should not be so great as to override the influence from the scene.
The solution we adopted is motivated by theories of language acquisition that take
into account the importance of early linguistic experience in a visual environment (see
the General Discussion). We found a small range of frequencies that permitted the net-
work to develop an early reliance on the information from the scene while it gradually
learned the stereotypical associations. Figure 6 shows the effect this training regime had
over 6000 epochs on the ability of the network to accurately anticipate the missing argu-
.
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 0  1000  2000  3000  4000  5000  6000
Cond 1
Cond 2
Cond 3
Cond 4
Epochs
P e
rc
e n
ta
g e
Fig. 6. Acquisition of Stereotypicality
858 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
ment in each of the four conditions described above when the ratio of non-stereotypical
to stereotypical sentences was 8:1. The network quickly learns to use the scene for con-
ditions 2-4 (examples 10-12), where the action in the linguistic input stream is also
depicted, allowing the network to determine the relevant event and deduce the missing
argument. (Because the graph shows the accuracy of the network at anticipating the
upcoming argument at the adverb, the lines for conditions 3 and 4 are, in fact, identi-
cal.) But condition 1 (sentence 9) requires only stereotypical knowledge. The accuracy
of condition 1 remains close to 75% (correctly producing the verb, first NP, and role
discriminator, but not the second NP) until around epoch 1800 or so and then gradually
improves as the network learns the appropriate stereotypical associations.
Results from several separate runs with different training parameters (such as learn-
ing rate and stereotypicality ratio) show that the network does indeed model the ob-
served experimental behavior. The best results thus far exceed 99% accuracy in cor-
rectly anticipating the proper roles and 100% accuracy at the end of sentence.
As in simulation 1, the training corpus was generated by exhaustively combining
participants and actions for all experimental conditions while holding out all test sen-
tences. However, we found that we were able to use a larger learning rate, 0.1, than 0.05
as in the first simulation.
Analysis of the network after successful training suggests why this training pol-
icy works. Early in training, before stereotypicality has been encoded in the network?s
weights, patterns are developed in the hidden layer once the verb is read in from the in-
put stream that enable the network to accurately decode that verb in the output layer. Not
surprisingly, the network uses these same patterns to encode the stereotypical agent; the
only constraint for the network is to ensure that the scene can still override this stereo-
typicality when the depicted event so dictates.
4 General Discussion and Future Work
The model demonstrates that reliance on correlations from distributional information
in the linguistic input and the scene during training of the model enabled successful
modelling of on-line utterance comprehension both in the presence and absence of rich
visual contexts. The model that we present acquires stereotypical knowledge from dis-
tributional properties of language during training. The mapping from words to the scene
representations is established through cooccurrence of scene-related utterances and de-
picted events during training. The network that emerges from this training regime suc-
cessfully models five visual worlds eye-tracking experiments in two simulations. A first
simulation of four experiments models the influence of either thematic and syntactic
knowledge in the utterance [8], or of depicted events showing who-does-what-to-whom
on incremental thematic role assignment [9]. Crucially in modelling the fifth experi-
ment we are able to account for the greater relative priority of depicted events when
event depictions and event knowledge conflict with each other.
The simple accuracy results belie the complexity of the task in both simulations. For
experiments 3 and 4, the network has to demonstrate anticipation of upcoming roles
when the scene is present, showing that it can indeed access the proper role and filler
from the compressed representation of the event associated with the verb processed in
A Connectionist Model of Anticipation in Visual Worlds 859
the linguistic stream when available. This task is rendered more difficult because the
appropriate event must be extracted from the superimposition of the two events in the
scene, which is what is propagated into the model?s hidden layer. In addition, it must
also still be able to process all sentences correctly when the scene is not present.
Simulation 2 is more challenging still. The experiment shows that information from
the scene takes precedence when there is a conflict with stereotypical knowledge; oth-
erwise, each source of knowledge is used when it is available. In the training regime
used in this simulation, the dominance of the scene is established early because it is
much more frequent than the more particular stereotypical knowledge. As training pro-
gresses, stereotypical knowledge is gradually learned because it is sufficiently frequent
for the network to capture the relevant associations. As the network weights gradually
saturate, it becomes more difficult to retune them. But encoding stereotypical knowl-
edge requires far fewer weight adjustments, so the network is able to learn that task
later during training.
According to the ?Coordinated Interplay? account in [7,6,11], the rapid integration
of scene and utterance information and the observed preferred reliance of the compre-
hension system on the visual context over stored knowledge might best be explained
by appealing to bootstrapping accounts of language acquisition. The development of
a child?s world knowledge occurs in a visual environment, which accordingly plays a
prominent role during language acquisition. The fact that the child can draw on two in-
formational sources (utterance and scene) enables it to infer information that it has not
yet acquired from what it already knows. Bootstrapping accounts for the fact that a child
can correlate event structure from the world around it with descriptions of events. When
a child perceives an event, the structural information it extracts from it can determine
how the child interprets a sentence that describes the event in question. The incremental
interpretation of a sentence can in turn direct the child?s attention to relevant entities
and events in the environment. Events are only present for a limited time when utter-
ances refer to such events during child language acquisition. This time-limited pres-
ence might determine the tight coordination with which attention in the scene interacts
with utterance comprehension and information extracted from the scene during adult
language comprehension. This contextual development may have shaped both our cog-
nitive architecture (i.e., providing for rapid, seamless integration of scene and linguistic
information), and comprehension mechanisms (e.g., people rapidly avail themselves of
information from the immediate scene when the utterance identifies it).
The model presented in this paper extends current models of on-line utterance com-
prehension when utterances relate to a scene [12] in several ways. Existing models ac-
count for processes of establishing reference in scene-sentence integration when scenes
contain only objects. Our network accounts for processes of establishing reference, and
furthermore models the rapid assignment of thematic roles based on linguistic and world
knowledge, as well as scene events. In this way, it achieves rapid scene-utterance inte-
gration for increasingly rich visual contexts, including the construction of propositional
representations on the basis of scene events. It models the integration of utterances
and relatively rich scenes (that contain actions and events) in addition to objects. Fur-
thermore, the model?in line with experimental findings ? successfully accounts for the
relative priority of depicted events in thematic interpretation. It importantly achieves
860 M.R. Mayberry, III, M.W. Crocker, and P. Knoeferle
this through a modification of the training regime that prioritizes scene information.
This confirms suggestions from [7] that a rapid interplay between utterance compre-
hension and the immediate scene context during acquisition is one potential cause for
the relative priority of depicted events during on-line comprehension.
Connectionist models such as the SRN have been used to model aspects of cogni-
tive development, including the time-course of emergent behaviors [13], making them
highly suitable for simulating developmental stages in child language acquisition (e.g.,
first learning names of objects in the immediate scene, and later proceeding to the acqui-
sition of stereotypical knowledge). The finding that modelling this aspect of develop-
ment provides an efficient way to naturally reproduce the observed adult comprehension
behavior promises to offer deeper insight into how adult performance is at least partially
a consequence of the acquisition process.
Future research will focus on combining all of the experiments in one model, and
expand the range of sentence types and fillers to which the network is exposed. The
architecture itself is being redesigned to scale up to much more complex linguistic con-
structions and have greater coverage while retaining the cognitively plausible behavior
described in this study [14].
Acknowledgements
The first two authors were supported by SFB 378 (project ?ALPHA?), and the third au-
thor by a PhD studentship (GRK 715), all awarded by the German Research Foundation
(DFG).
References
1. Steven Pinker. How could a child use verb syntax to learn verb semantics? In Lila Gleitman
and Barbara Landau, editors, The acquisition of the lexicon, pages 377?410. MIT Press,
Cambridge, MA, 1994.
2. Cynthia Fisher, D. G. Hall, S. Rakowitz, and Lila Gleitman. When it is better to receive
than to give: Syntactic and conceptual constraints on vocabulary growth. In Lila Gleitman
and Barbara Landau, editors, The acquisition of the lexicon, pages 333?375. MIT Press,
Cambridge, MA, 1994.
3. Jeffrey L. Elman. Finding structure in time. Cognitive Science, 14:179?211, 1990.
4. Martin Redington, Nick Chater, and Steven Finch. Distributional information: A powerful
cue for acquiring syntactic categories. Cognitive Science, 22:425?469, 1998.
5. Deb Roy and Alex Pentland. Learning words from sights and sounds: A computational
model. Cognitive Science, 26(1):113?146, 2002.
6. Pia Knoeferle and Matthew W. Crocker. Stored knowledge versus depicted events: what
guides auditory sentence comprehension. In Proceedings of the 26th Annual Conference of
the Cognitive Science Society. Mahawah, NJ: Erlbaum, 2004. 714?719.
7. Pia Knoeferle and Matthew W. Crocker. The coordinated interplay of scene, utterance, and
world knowledge: evidence from eye-tracking. submitted.
8. Yuki Kamide, Christoph Scheepers, and Gerry T. M. Altmann. Integration of syntactic and
semantic information in predictive processing: Cross-linguistic evidence from German and
English. Journal of Psycholinguistic Research, 32(1):37?55, 2003.
A Connectionist Model of Anticipation in Visual Worlds 861
9. Pia Knoeferle, Matthew W. Crocker, Christoph Scheepers, and Martin J. Pickering. The
influence of the immediate visual context on incremental thematic role-assignment: evidence
from eye-movements in depicted events. Cognition, 95:95?127, 2005.
10. Risto Miikkulainen. Natural language processing with subsymbolic neural networks. In
Antony Browne, editor, Neural Network Perspectives on Cognition and Adaptive Robotics,
pages 120?139. Institute of Physics Publishing, Bristol, UK; Philadelphia, PA, 1997.
11. Pia Knoeferle and Matthew W. Crocker. The coordinated processing of scene and utterance:
evidence from eye-tracking in depicted events. In Proceedings of International Conference
on Cognitive Science, Allahabad, India, 2004.
12. Deb Roy and Niloy Mukherjee. Towards situated speech understanding: Visual context prim-
ing of language models. Computer Speech and Language, 19(2):227?248, 2005.
13. Jeffrey L. Elman, Elizabeth A. Bates, Mark H. Johnson, Annette Karmiloff-Smith, Domenico
Parisi, and Kim Plunkett. Rethinking Innateness: A Connectionist Perspective on Develop-
ment. MIT Press, Cambridge, MA, 1996.
14. Marshall R. Mayberry and Matthew W. Crocker. Generating semantic graphs through self-
organization. In Proceedings of the AAAI Symposium on Compositional Connectionism in
Cognitive Science, pages 40?49, Washington, D.C., 2004.
Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 36?44,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
A Connectionist Model of Language-Scene Interaction
Marshall R. Mayberry, III Matthew W. Crocker Pia Knoeferle
Department of Computational Linguistics
Saarland University
Saarbru?cken 66041, Germany
martym,crocker,knoferle@coli.uni-sb.de
Abstract
Recent ?visual worlds? studies, wherein
researchers study language in context by
monitoring eye-movements in a visual
scene during sentence processing, have re-
vealed much about the interaction of di-
verse information sources and the time
course of their influence on comprehen-
sion. In this study, five experiments that
trade off scene context with a variety of
linguistic factors are modelled with a Sim-
ple Recurrent Network modified to inte-
grate a scene representation with the stan-
dard incremental input of a sentence. The
results show that the model captures the
qualitative behavior observed during the
experiments, while retaining the ability to
develop the correct interpretation in the
absence of visual input.
1 Introduction
People learn language within the context of the sur-
rounding world, and use it to refer to objects in that
world, as well as relationships among those objects
(e.g., Gleitman, 1990). Recent research in the vi-
sual worlds paradigm, wherein participants? gazes
in a scene while listening to an utterance are moni-
tored, has yielded a number of insights into the time
course of sentence comprehension. The careful ma-
nipulation of information sources in this experimen-
tal setting has begun to reveal important character-
istics of comprehension such as incrementality and
anticipation. For example, people?s attention to ob-
jects in a scene closely tracks their mention in a spo-
ken sentence (Tanenhaus et al, 1995), and world
and linguistic knowledge seem to be factors that fa-
cilitate object identification (Altmann and Kamide,
1999; Kamide et al, 2003). More recently, Knoe-
ferle et al (2005) have shown that when scenes in-
clude depicted events, such visual information helps
to establish important relations between the entities,
such as role relations.
Models of sentence comprehension to date, how-
ever, continue to focus on modelling reading behav-
ior. No model, to our knowledge, attempts to ac-
count for the use of immediate (non-linguistic) con-
text. In this paper we present results from two simu-
lations using a Simple Recurrent Network (SRN; El-
man, 1990) modified to integrate input from a scene
with the characteristic incremental processing of
such networks in order to model people?s ability to
adaptively use the contextual information in visual
scenes to more rapidly interpret and disambiguate a
sentence. In the modelling of five visual worlds ex-
periments reported here, accurate sentence interpre-
tation hinges on proper case-role assignment to sen-
tence referents. In particular, modelling is focussed
on the following aspects of sentence processing:
? anticipation of upcoming arguments and their
roles in a sentence
? adaptive use of the visual scene as context for a
spoken utterance
? influence of depicted events on developing in-
terpretation
? multiple/conflicting information sources and
their relative importance
36
Figure 1: Selectional Restrictions. Gaze fixations depend
on whether the hare is the subject or object of the sentence,
as well as the thematic role structure of the verb. These gaze
fixations reveal that people use linguistic and world knowledge
to anticipate upcoming arguments.
2 Simulation 1
In the first simulation, we simultaneously model
four experiments that featured revealing contrasts
between world knowledge and context. These four
experiments show that the human sentence proces-
sor is very adept at utilizing all available sources of
information to rapidly interpret language. In partic-
ular, information from visual context can readily be
integrated with linguistic and world knowledge to
disambiguate argument roles where the information
from the auditory stream is insufficient in itself.
All experiments were conducted in German, a
language that allows both subject-verb-object (SVO)
and object-verb-subject (OVS) sentence types, so
that word order alone cannot be relied upon to deter-
mine role assignments. Rather, case marking in Ger-
man is used to indicate grammatical function such
as subject or object, except in the case of feminine
and neuter nouns where the article does not carry
any distinguishing marking for the nominative and
accusative cases.
2.1 Anticipation depending on stereotypicality
The first two experiments modelled involved unam-
biguous sentences in which case-marking and verb
selectional restrictions in the linguistic input (i.e.,
linguistic and world knowledge or stereotypicality),
together with characters depicted in a visual scene,
allowed rapid assignment of the roles played by
those characters in the sentence.
Experiment 1: Morphosyntactic and lexical
verb information. In order to examine the influence
of linguistic knowledge of case-marking, Kamide
et al (2003) presented experiment participants with
a scene showing, for example, a hare, a cabbage, a
fox, and a distractor (see Figure 1), together with ei-
ther a spoken German SVO sentence (1) or with an
OVS sentence (2):
(1) Der Hase frisst gleich den Kohl.
The harenom eats shortly the cabbageacc.
(2) Den Hasen frisst gleich der Fuchs.
The hareacc eats shortly the foxnom.
The subject and object case-marking on the article of
the first noun phrase (NP) together with verb mean-
ing and world knowledge allowed anticipation of the
correct post-verbal referent. Participants made an-
ticipatory eye-movements to the cabbage after hear-
ing ?The harenom eats ...? and to the fox upon en-
countering ?The hareacc eats ...?. Thus, people are
able to predict upcoming referents when the utter-
ance is unambiguous and linguistic/world knowl-
edge restricts the domain of potential referents in a
scene.
Experiment 2: Verb type information. To fur-
ther investigate the role of verb information, the
authors used the same visual scenes in a follow-
up study, but replaced the agent/patient verbs like
frisst (?eats?) with experiencer/theme verbs like in-
teressiert (?interests?). The agent (experiencer) and
patient (theme) roles from Experiment 1 were inter-
changed. Given the same scene in Figure 1 but the
subject-first sentence (3) or object-first sentence (4),
participants showed gaze fixations complementary
to those in the first experiment, confirming that both
syntactic case information and semantic verb infor-
mation are used to predict subsequent referents.
(3) Der Hase interessiert ganz besonders den Fuchs.
The harenom interests especially the foxacc.
(4) Den Hasen interessiert ganz besonders der Kohl.
The hareacc interests especially the cabbagenom.
2.2 Anticipation depending on depicted events
The second set of experiments investigated tem-
porarily ambiguous German sentences. Findings
showed that depicted events?just like world and lin-
guistic knowledge in unambiguous sentences?can
establish a scene character?s role as agent or patient
in the face of linguistic structural ambiguity.
37
Figure 2: Depicted Events. The depiction of actions allows
role information to be extracted from the scene. People can use
this information to anticipate upcoming arguments even in the
face of ambiguous linguistic input.
Experiment 3: Verb-mediated depicted role re-
lations. Knoeferle et al (2005) investigated com-
prehension of spoken sentences with local structural
and thematic role ambiguity. An example of the Ger-
man SVO/OVS ambiguity is the SVO sentence (5)
versus the OVS sentence (6):
(5) Die Princessin malt offensichtlich den Fechter.
The princessnom paints obviously the fenceracc.
(6) Die Princessin wa?scht offensichtlich der Pirat.
The princessacc washes obviously the piratenom.
Together with the auditorily presented sentence a
scene was shown in which a princess both paints
a fencer and is washed by a pirate (see Figure 2).
Linguistic disambiguation occurred on the second
NP; in the absence of stereotypical verb-argument
relationships, disambiguation prior to the second NP
was only possible through use of the depicted events
and their associated depicted role relations. When
the verb identified an action, the depicted role rela-
tions disambiguated towards either an SVO agent-
patient (5) or OVS patient-agent role (6) relation, as
indicated by anticipatory eye-movements to the pa-
tient (pirate) or agent (fencer), respectively, for (5)
and (6). This gaze-pattern showed the rapid influ-
ence of verb-mediated depicted events on the assign-
ment of a thematic role to a temporarily ambiguous
sentence-initial noun phrase.
Experiment 4: Weak temporal adverb con-
straint. Knoeferle et al also investigated German
verb-final active/passive constructions. In both the
active future-tense (7) and the passive sentence (8),
the initial subject noun phrase is role-ambiguous,
and the auxiliary wird can have a passive or future
interpretation.
(7) Die Princessin wird sogleich den Pirat washen.
The princessnom will right away wash the pirateacc.
(8) Die Princessin wird soeben von dem Fechter gemalt.
The princessacc is just now painted by the fencernom.
To evoke early linguistic disambiguation, temporal
adverbs biased the auxiliary wird toward either the
future (?will?) or passive (?is -ed?) reading. Since
the verb was sentence-final, the interplay of scene
and linguistic cues (e.g., temporal adverbs) were
rather more subtle. When the listener heard a future-
biased adverb such as sogleich, after the auxiliary
wird, he interpreted the initial NP as an agent of a fu-
ture construction, as evidenced by anticipatory eye-
movements to the patient in the scene. Conversely,
listeners interpreted the passive-biased construction
with these roles exchanged.
2.3 Architecture
The Simple Recurrent Network is a type of neu-
ral network typically used to process temporal se-
quences of patterns such as words in a sentence.
A common approach is for the modeller to train
the network on prespecified targets, such as verbs
and their arguments, that represent what the net-
work is expected to produce upon completing a sen-
tence. Processing is incremental, with each new in-
put word interpreted in the context of the sentence
processed so far, represented by a copy of the pre-
vious hidden layer serving as additional input to the
current hidden layer. Because these types of asso-
ciationist models automatically develop correlations
among the sentence constituents they are trained
on, they will generally develop expectations about
the output even before processing is completed be-
cause sufficient information occurs early in the sen-
tence to warrant such predictions. Moreover, during
the course of processing a sentence these expecta-
tions can be overridden with subsequent input, often
abruptly revising an interpretation in a manner rem-
iniscent of how humans seem to process language.
Indeed, it is these characteristics of incremental pro-
cessing, the automatic development of expectations,
seamless integration of multiple sources of informa-
tion, and nonmonotonic revision that have endeared
neural network models to cognitive researchers.
In this study, the four experiments described
38
hidden layer
context layer
event layers
waescht Prinzessin Pirat PAT
input layer
waescht
Figure 3: Scene Integration. A simple conceptual rep-
resentation of the information in a scene, along with com-
pressed event information from depicted actions when present,
is fed into a standard SRN to model adaptive processing. The
links connecting the depicted characters to the hidden layer are
shared, as are the links connecting the event layers to the hidden
layer.
above have been modelled simultaneously using a
single network. The goal of modelling all experi-
mental results by a single architecture required en-
hancements to the SRN, the development and pre-
sentation of the training data, as well as the training
regime itself. These will be described in turn below.
In two of the experiments, only three characters
are depicted, representation of which can be propa-
gated directly to the network?s hidden layer. In the
other two experiments, the scene featured three char-
acters involved in two events (e.g., pirate-washes-
princess and princess-paints-fencer, as shown in
Figure 3). The middle character was involved in
both events, either as an agent or a patient (e.g.,
princess). Only one of the events, however, corre-
sponded to the spoken linguistic input.
The representation of this scene information and
its integration into the model?s processing was the
main modification to the SRN. Connections between
representations for the depicted characters and the
hidden layer were provided. Encoding of the de-
picted events, when present, required additional
links from the characters and depicted actions to
event layers, and links from these event layers to the
SRN?s hidden layer. The network developed repre-
sentations for the events in the event layers by com-
pressing the scene representations of the involved
characters and depicted actions through weights cor-
responding to the action, its agent and its patient for
each event. This event representation was kept sim-
ple and only provided conceptual input to the hidden
layer: who did what to whom was encoded for both
events, when depicted, but grammatical information
only came from the linguistic input. As the focus of
this study was on whether sentence processing could
adapt to information from the scene when present or
from stored knowledge, lower-level perceptual pro-
cesses such as attention were not modelled.
Neural networks will usually encode any correla-
tions in the data that help to minimize error. In order
to prevent the network from encoding regularities in
its weights regarding the position of the characters
and events given in the scene (such as, for example,
that the central character in the scene corresponds
to the first NP in the presented sentence) which are
not relevant to the role-assignment task, one set of
weights was used for all characters, and another set
of weights used for both events. This weight-sharing
ensured that the network had to access the informa-
tion encoded in the event layers, or determine the
relevant characters itself, thus improving generaliza-
tion. The representations for the characters and ac-
tions were the same for both input (scene and sen-
tence) and output.
The input assemblies were the scene represen-
tations and the current word from the input sen-
tence. The output assemblies were the verb, the
first and second nouns, and an assembly that indi-
cated whether the first noun was the agent or pa-
tient of the sentence (token PAT in Figure 3). Typ-
ically, agent and patient assemblies would be fixed
in a case-role representation without such a discrim-
inator, and the model required to learn to instantiate
them correctly (Miikkulainen, 1997). However, we
found that the model performed much better when
the task was recast as having to learn to isolate the
nouns in the order in which they are introduced, and
separately mark how those nouns relate to the verb.
The input and output assemblies had 100 units each,
the event layers contained 200 units each, and the
hidden and context layers consisted of 400 units.
39
2.4 Input Data, Training, and Experiments
We trained the network to correctly handle sentences
involving non-stereotypical events as well as stereo-
typical ones, both when visual context was present
and when it was absent. As over half a billion sen-
tence/scene combinations were possible for all of the
experiments, we adopted a grammar-based approach
to exhaustively generate sentences and scenes based
on the experimental materials while holding out the
actual materials to be used for testing. In order to
accurately model the first two experiments involv-
ing selectional restrictions on verbs, two additional
words were added to the lexicon for each charac-
ter selected by a verb. For example, in the sentence
Der Hase frisst gleich den Kohl, the nouns Hase1,
Hase2, Kohl1, and Kohl2 were used to develop train-
ing sentences. These were meant to represent, for
example, words such as ?rabbit? and ?jackrabbit? or
?carrot? and ?lettuce? in the lexicon that have the
same distributional properties as the original words
?hare? and ?cabbage?. With these extra tokens the
network could learn that Hase, frisst, and Kohl were
correlated without ever encountering all three words
in the same training sentence. The experiments in-
volving non-stereotypicality did not pose this con-
straint, so training sentences were simply generated
to avoid presenting experimental items.
Some standard simplifications to the words have
been made to facilitate modelling. For example,
multi-word adverbs such as fast immer were treated
as one word through hyphenation so that sentence
length within a given experimental set up is main-
tained. Nominal case markings such as -n in Hasen
were removed to avoid sparse data as these markings
are idiosyncratic, while the case markings on the de-
terminers are more informative overall. More impor-
tantly, morphemes such as the infinitive marker -en
and past participle ge- were removed, because, for
example, the verb forms malt, malen, and gemalt,
would all be treated as unrelated tokens, again con-
tributing unnecessarily to the problem with sparse
data. The result is that one verb form is used, and
to perform accurately, the network must rely on its
position in the sentence (either second or sentence-
final), as well as whether the word von occurs to
indicate a participial reading rather than infinitival.
All 326 words in the lexicon for the first four exper-
  
  
 
 

 
 
 










  
  
  
  
  
  
  
  
  
  










  
  
  
  
  
  
  
  
  
  
			
			
			
			
			
			
			
			
			

 
 


 
 


 
 


 
 


 
 


 
 


 
 


 
 


 
 









  
  
  
  
  
  
  
  







   
   
   
   
   
   
   









  
  
  
  
  
  
  
  
  










  
  
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
   
   
   
   
   
   
   
   
   
 85
 90
 95
 100
Exp 1 Exp 2 Exp 3 Exp 4
Pe
rce
nta
ge 
Co
rre
ct
Adverb
NP2
Figure 4: Results. In each of the four experiments modelled,
anticipation of the upcoming argument at the adverb is nearly
as accurate as at sentence end. However, the network has some
difficulty with distinguishing stereotypical arguments.
iments were given random representations over the
vertices of a 100-dimensional hypercube, which re-
sulted in marked improvement over sampling from
within the hypercube (Noelle et al, 1997).
We trained the network by repeatedly presenting
the model with 1000 randomly generated sentences
from each experiment (constituting one epoch) and
testing every 100 epochs against the held-out test
materials for each of the four experiments. Scenes
were provided half of the time to provide an un-
biased approximation to linguistic experience. The
network was initialized with weights between -0.01
and 0.01. The learning rate was initially set to 0.05
and gradually reduced to 0.002 over the course of
15000 epochs. Ten splits were run on 1.6Ghz PCs
and took a little over two weeks to complete.
2.5 Results
Figure 4 reports the percentage of targets at the
network?s output layer that the model correctly
matches, both as measured at the adverb and at the
end of the sentence. The model clearly demonstrates
the qualitative behavior observed in all four experi-
ments in that it is able to access the information from
the encoded scene or stereotypicality and combine it
with the incrementally presented sentence to antici-
pate forthcoming arguments.
For the two experiments (1 and 2) using stereotyp-
ical information, the network achieved just over 96%
at sentence end, and anticipation accuracy was just
over 95% at the adverb. Analysis shows that the net-
work makes errors in token identification, confus-
ing words that are within the selectionally restricted
40
set, such as, for example, Kohl and Kohl2. Thus,
the model has not quite mastered the stereotypical
knowledge, particularly as it relates to the presence
of the scene.
For the other two experiments using non-
stereotypical characters and depicted events (exper-
iments 3 and 4), accuracy was 100% at the end of
the sentence. More importantly, the model achieved
over 98% early disambiguation on experiment 3,
where the sentences were simple, active SVO and
OVS. Early disambiguation on experiment 4 was
somewhat harder because the adverb is the disam-
biguating point in the sentence as opposed to the
verb in the other three experiments. As nonlinear
dynamical systems, neural networks sometimes re-
quire an extra step to settle after a decision point is
reached due to the attractor dynamics of the weights.
On closer inspection of the model?s behavior dur-
ing processing, it is apparent that the event layers
provide enough additional information beyond that
encoded in the weights between the characters and
the hidden layer that the model is able to make finer
discriminations in experiments 3 and 4, enhancing
its performance.
3 Simulation 2
The previous set of experiments examined how peo-
ple are able to use either stereotypical knowledge or
depicted information to anticipate forthcoming ar-
guments in a sentence. But how does the human
sentence processor handle these information sources
when both are present? Which takes precedence
when they conflict? The experiment modelled in this
section was designed to provide some insight into
these questions.
Scene vs Stored Knowledge. Based on the find-
ings from the four experiments in Simulation 1,
Knoeferle and Crocker (2004b) examined two is-
sues. First, it verified that stored knowledge about
non-depicted events and information from depicted,
but non-stereotypical, events each enable rapid the-
matic interpretation. An example scene showed a
wizard, a pilot, and a detective serving food (Fig-
ure 5). When people heard condition 1 (example
sentence 9), the case-marking on the first NP identi-
fied the pilot as a patient. Stereotypical knowledge
identified the wizard as the only relevant agent, as
Figure 5: Scene vs Stored Knowledge. Experimental results
show that people rely on depicted information over stereotypical
knowledge when both are present during sentence processing.
indicated by a higher proportion of anticipatory eye-
movements to the stereotypical agent (wizard) than
to the detective. In contrast, when people heard the
verb in condition 2 (sentence 10), it uniquely iden-
tified the detective as the only food-serving agent,
revealed by more inspections to the agent of the de-
picted event (detective) than to the wizard.
(9) Den Piloten verzaubert gleich der Zauberer.
The pilotacc jinxes shortly the wizardnom.
(10) Den Piloten verko?stigt gleich der Detektiv.
The pilotacc serves-food-to shortly the detectivenom.
Second, the study determined the relative impor-
tance of depicted events and verb-based thematic
role knowledge when the information sources were
in competition. In both conditions 3 & 4 (sentences
11 & 12), participants heard an utterance in which
the verb identified both a stereotypical (detective)
and a depicted agent (wizard). When faced with this
conflict, people preferred to rely on the immediate
event depictions over stereotypical knowledge, and
looked more often at the wizard, the agent in the de-
picted event, than at the other, stereotypical agent of
the spying-action (the detective).
(11) Den Piloten bespitzelt gleich der Detektiv.
The pilotacc spies-on shortly the detectivenom.
(12) Den Piloten bespitzelt gleich der Zauberer.
The pilotacc spies-on shortly the wizardnom.
3.1 Architecture, Data, Training, and Results
In simulation 1, we modelled experiments that de-
pended on stereotypicality or depicted events, but
not both. The experiment modelled in simulation
2, however, was specifically designed to investigate
41
how these two information sources interacted. Ac-
cordingly, the network needed to learn to use either
information from the scene or stereotypicality when
available, and, moreover, favor the scene when the
two sources conflicted, as observed in the empirical
results. Recall that the network is trained only on the
final interpretation of a sentence. Thus, capturing
the observed behavior required manipulation of the
frequencies of the four conditions described above
during training. In order to train the network to de-
velop stereotypical agents for verbs, the frequency
that a verb occurs with its stereotypical agent, such
as Detektiv and bespitzelt from example (11) above,
had to be greater than for a non-stereotypical agent.
However, the frequency should not be so great that
it overrode the influence from the scene.
The solution we adopted is motivated by a the-
ory of language acquisition that takes into account
the importance of early linguistic experience in a vi-
sual environment (see the General Discussion). We
found a small range of ratios of stereotypicality to
non-stereotypicality that permitted the network to
develop an early reliance on information from the
scene while it gradually learned the stereotypical as-
sociations. When the ratio was lower than 6:1, the
network developed too strong a reliance on stereo-
typicality, overriding information from the scene.
When the ratio was greater than 15:1, the scene
always took precedence when it was present, but
stereotypical knowledge was used when the scene
was not present. Within this range, however, the
network quickly learns to extract information from
the scene because the scene representation remains
static while a sentence is processed incrementally.
It is the stereotypical associations, predictably, that
take longer for the network to learn in rough propor-
tion to their ratio over non-stereotypical agents.
Figure 6 shows the effect this training regime had
over 6000 epochs on the ability of the network to ac-
curately anticipate the missing argument in each of
the four conditions described above when the ratio
of non-stereotypical to stereotypical sentences was
8:1. The network quickly learns to use the scene for
conditions 2-4 (examples 10-12), where the action in
the linguistic input stream is also depicted, allowing
the network to determine the relevant event and de-
duce the missing argument. (Because conditions 3
and 4 are the same up to the second NP, their curves
.
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 0  1000  2000  3000  4000  5000  6000
Perce
ntage
Cond 1Cond 2Cond 3Cond 4
Figure 6: Acquisition of Stereotypicality. Stereotypical
knowledge (condition 1) is acquired much more gradually than
information from the scene (conditions 2-4).
are, in fact, identical.) But condition 1 (sentence 9)
requires only stereotypical knowledge. The accu-
racy of condition 1 remains close to 75% (correctly
producing the verb, first NP, and role discriminator,
but not the second NP) until around epoch 1200 or
so and then gradually improves as the network learns
the appropriate stereotypical associations. The con-
dition 1 curve asymptotically approaches 100% over
the course of 10,000 epochs.
Results from several runs with different training
parameters (such as learning rate and stereotypical-
ity ratio) show that the network does indeed model
the observed experimental behavior. The best results
so far exceed 99% accuracy in correctly anticipating
the proper roles and 100% accuracy at sentence end.
As in simulation 1, the training corpus was gen-
erated by exhaustively combining participants and
actions for all experimental conditions while hold-
ing out all test sentences. However, we found that
we were able to use a larger learning rate, 0.1, than
the 0.05 used in the first simulation. The 130 words
in the lexicon were given random binary representa-
tions from the vertices of a 100-dimensional hyper-
cube as described before.
Analysis of the network after successful training
suggests why the training regime of holding the ratio
of stereotypical to non-stereotypical sentences con-
stant works. Early in training, before stereotypical-
ity has been encoded in the network?s weights, pat-
terns are developed in the hidden layer as each word
is processed that enable the network to accurately
decode the words in the output layer. Once the verb
is read in, its hidden layer pattern is available to pro-
42
duce the correct output representations for both the
verb itself and its stereotypical agent. Not surpris-
ingly, the network thus learns to associate the hidden
layer pattern for the verb with its stereotypical agent
pattern in the second NP output slot. The only con-
straint for the network is to ensure that the scene can
still override this stereotypicality when the depicted
event so dictates.
4 General Discussion and Future Work
Experiments in the visual worlds paradigm have
clearly reinforced the view of language comprehen-
sion as an active, incremental, highly integrative
process in which anticipation of upcoming argu-
ments plays a crucial role. Visual context not only
facilitates identification of likely referents in a sen-
tence, but helps establish relationships between ref-
erents and the roles they may fill. Research thus far
has shown that the human sentence processor seems
to have easy access to whatever information is avail-
able, whether it be syntactic, lexical, semantic, or vi-
sual, and that it can combine these sources to achieve
as complete an interpretation as is possible at any
given point in comprehending a sentence.
The modelling results reported in this paper are an
important step toward the goal of understanding how
the human sentence processor is able to accomplish
these feats. The SRN provides a natural framework
for this research because its operation is premised
on incremental and integrative processing. Trained
simply to produce a representation of the complete
interpretation of a sentence as each new word is pro-
cessed (on the view that people learn to process lan-
guage by reviewing what they hear), the model au-
tomatically develops anticipations for upcoming ar-
guments that allow it to demonstrate the early dis-
ambiguation behavior observed in the visual worlds
experiments modelled here.
The simple accuracy results belie the complex-
ity of the task in both simulations. In Simulation
1, the network has to demonstrate early disambigua-
tion when the scene is present, showing that it can
indeed access the proper role and filler from the
compressed representation of the event associated
with the first NP and verb processed in the linguistic
stream. This task is rendered more difficult because
the proper event must be extracted from the super-
imposition of the two events in the scene, which is
what is propagated into the model?s hidden layer. In
addition, it must also still be able to process all sen-
tences correctly when the scene is not present.
Simulation 2 is more difficult still. The experi-
ment shows that information from the scene takes
precedence when there is a conflict with stereotypi-
cal knowledge; otherwise, each source of knowledge
is used when it is available. In the training regime
used in this simulation, the dominance of the scene
is established early because it is much more fre-
quent than the more particular stereotypical knowl-
edge. As training progresses, stereotypical knowl-
edge is gradually learned because it is sufficiently
frequent for the network to capture the relevant as-
sociations. As the network weights gradually satu-
rate, it becomes more difficult to retune them. But
encoding stereotypical knowledge requires far fewer
weight adjustments, so the network is able to learn
that task later during training.
Knoeferle and Crocker (2004a,b) suggest that the
preferred reliance of the comprehension system on
the visual context over stored knowledge might best
be explained by appealing to a boot-strapping ac-
count of language acquisition such as that of Gleit-
man (1990). The development of a child?s world
knowledge occurs in a visual environment, which
accordingly plays a prominent role during language
acquisition. The fact that the child can draw on two
informational sources (utterance and scene) enables
it to infer information that it has not yet acquired
from what it already knows. This contextual devel-
opment may have shaped both our cognitive archi-
tecture (i.e., providing for rapid, seamless integra-
tion of scene and linguistic information), and com-
prehension mechanisms (e.g., people rapidly avail
themselves of information from the immediate scene
when the utterance identifies it).
Connectionist models such as the SRN have been
used to model aspects of cognitive development, in-
cluding the timing of emergent behaviors (Elman
et al, 1996), making them highly suitable for sim-
ulating developmental stages in child language ac-
quisition (e.g., first learning names of objects in the
immediate scene, and later proceeding to the acqui-
sition of stereotypical knowledge). If there are de-
velopmental reasons for the preferred reliance of lis-
teners on the immediate scene during language com-
43
prehension, then the finding that modelling that de-
velopment provides the most efficient (if not only)
way to naturally reproduce the observed experimen-
tal behavior promises to offer deeper insight into
how such knowledge is instilled in the brain.
Future research will focus on combining all of the
experiments in one model, and expand the range of
sentence types and fillers to which the network is
exposed. The architecture itself is being redesigned
to scale up to much more complex linguistic con-
structions and have greater coverage while retaining
the cognitively plausible behavior described in this
study (Mayberry and Crocker, 2004).
5 Conclusion
We have presented a neural network architecture that
successfully models the results of five recent exper-
iments designed to study the interaction of visual
context with sentence processing. The model shows
that it can adaptively use information from the vi-
sual scene such as depicted events, when present,
to anticipate roles and fillers as observed in each of
the experiments, as well as demonstrate traditional
incremental processing when context is absent. Fur-
thermore, more recent results show that training the
network in a visual environment, with stereotypical
knowledge gradually learned and reinforced, allows
the model to negotiate even conflicting information
sources.
6 Acknowledgements
This research was funded by SFB 378 project ?AL-
PHA? to the first two authors and a PhD scholar-
ship to the last, all awarded by the German Research
Foundation (DFG).
References
Altmann, G. T. M. and Kamide, Y. (1999). Incre-
mental interpretation at verbs: Restricting the do-
main of subsequent reference. Cognition, 73:247?
264.
Elman, J. L. (1990). Finding structure in time. Cog-
nitive Science, 14:179?211.
Elman, J. L., Bates, E. A., Johnson, M. H.,
Karmiloff-Smith, A., Parisi, D., and Plunkett, K.
(1996). Rethinking Innateness: A Connectionist
Perspective on Development. MIT Press, Cam-
bridge, MA.
Gleitman, L. (1990). The structural sources of verb
meanings. Language Acquisition, 1:3?55.
Kamide, Y., Scheepers, C., and Altmann, G. T. M.
(2003). Integration of syntactic and seman-
tic information in predictive processing: Cross-
linguistic evidence from German and English.
Journal of Psycholinguistic Research, 32(1):37?
55.
Knoeferle, P. and Crocker, M. W. (2004a). The co-
ordinated processing of scene and utterance: ev-
idence from eye-tracking in depicted events. In
Proceedings of International Conference on Cog-
nitive Science, Allahabad, India.
Knoeferle, P. and Crocker, M. W. (2004b). Stored
knowledge versus depicted events: what guides
auditory sentence comprehension. In Proceedings
of the 26th Annual Conference of the Cognitive
Science Society. Mahawah, NJ: Erlbaum. 714?
719.
Knoeferle, P., Crocker, M. W., Scheepers, C., and
Pickering, M. J. (2005). The influence of the im-
mediate visual context on incremental thematic
role-assignment: evidence from eye-movements
in depicted events. Cognition, 95:95?127.
Mayberry, M. R. and Crocker, M. W. (2004). Gen-
erating semantic graphs through self-organization.
In Proceedings of the AAAI Symposium on Com-
positional Connectionism in Cognitive Science,
pages 40?49, Washington, D.C.
Miikkulainen, R. (1997). Natural language process-
ing with subsymbolic neural networks. In Browne,
A., editor, Neural Network Perspectives on Cogni-
tion and Adaptive Robotics, pages 120?139. Insti-
tute of Physics Publishing, Bristol, UK; Philadel-
phia, PA.
Noelle, D. C., Cottrell, G. W., and Wilms, F. (1997).
Extreme attraction: The benefits of corner attrac-
tors. Technical Report CS97-536, Department of
Computer Science and Engineering, UCSD, San
Diego, CA.
Tanenhaus, M. K., Spivey-Knowlton, M. J., Eber-
hard, K. M., and Sedivy, J. C. (1995). Integration
of visual and linguistic information in spoken lan-
guage comprehension. Science, 268:1632?1634.
44
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 30?39,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Enhancing Referential Success by Tracking Hearer Gaze
Alexander Koller
University of Potsdam
koller@ling.uni-potsdam.de
Konstantina Garoufi
University of Potsdam
garoufi@uni-potsdam.de
Maria Staudte
Saarland University
masta@coli.uni-saarland.de
Matthew Crocker
Saarland University
crocker@coli.uni-saarland.de
Abstract
The ability to monitor the communicative suc-
cess of its utterances and, if necessary, provide
feedback and repair is useful for a dialog sys-
tem. We show that in situated communication,
eyetracking can be used to reliably and effi-
ciently monitor the hearer?s reference resolu-
tion process. An interactive system that draws
on hearer gaze to provide positive or nega-
tive feedback after referring to objects outper-
forms baseline systems on metrics of referen-
tial success and user confusion.
1 Introduction
Because dialog is interactive, interlocutors are con-
stantly engaged in a process of predicting and mon-
itoring the effects of their utterances. Typically, a
speaker produces an utterance with a specific com-
municative goal in mind?e.g., that the hearer will
perform an action or adopt a certain belief?, and
chooses one particular utterance because they pre-
dict that it will achieve this communicative goal.
They will then monitor the hearer?s reactions and
infer from their observations whether the prediction
actually came true. If they recognize that the hearer
misunderstood the utterance, they may repair the
problem by diagnosing what caused the misunder-
standing and giving the hearer feedback. In a task-
oriented dialog in which the hearer must perform a
part of the task, feedback is especially important to
inform the hearer when they made a mistake in the
task. Ideally, the speaker should even detect when
the hearer is about to make a mistake, and use feed-
back to keep them from making the mistake at all.
Many implemented dialog systems include a com-
ponent for monitoring and repair. For instance,
Traum (1994) presents a model for monitoring the
grounding status of utterances in the TRAINS sys-
tem; Young et al (1994) show how the student?s
utterances in a dialog system can be used to un-
cover mistaken assumptions about their mental state;
and Paek and Horvitz (1999) discuss an automated
helpdesk system that can track grounding under un-
certainty. However, most of these systems rely on
the user?s verbal utterances as their primary source
of information; monitoring thus presupposes an
(error-prone) language understanding module.
In the context of situated communication, where
the speaker and hearer share a physical (or virtual)
environment, one type of observation that can poten-
tially give us a very direct handle on the hearer?s un-
derstanding of an utterance is eye gaze. Eyetracking
studies in psycholinguistics have shown that when
listeners hear a referring expression, they tend to
rapidly attend to the object in a scene to which they
resolve this expression (Tanenhaus et al, 1995; Al-
lopenna et al, 1998). For utterances that involve ref-
erences to objects in the current environment, one
can therefore ask whether eyetracking can be used
to reliably judge the communicative success of the
utterance. This would be of practical interest for
implemented dialog systems once eyetracking be-
comes a mainstream technology; and even today, a
system that reliably monitors communicative suc-
cess using eyetracking could serve as a testbed for
exploring monitoring and repair strategies.
In this paper, we present an interactive natural-
language generation (NLG) system that uses eye-
30
tracking to monitor communicative success. Our
system gives real-time instructions that are designed
to help the user perform a treasure-hunt task in the
virtual 3D environments of the recent Challenges
on Generating Instructions in Virtual Environments
(GIVE; Koller et al (2010)). It monitors how the
user resolves referring expressions (REs) by map-
ping the user?s gaze to objects in the virtual environ-
ment. The system takes gaze to the intended referent
as evidence of successful understanding, and gives
the user positive feedback; by contrast, gaze to other
objects triggers negative feedback. Crucially, this
feedback comes before the user interacts with the
object in the virtual environment, keeping the user
from making mistakes before they happen.
We evaluate our system against one baseline that
gives no feedback, and another that bases its feed-
back on monitoring the user?s movements and their
field of view. We find that the eyetracking-based
system outperforms both on referential success, and
that users interacting with it show significantly fewer
signs of confusion about how to complete their task.
This demonstrates that eyetracking can serve as a
reliable source of evidence in monitoring commu-
nicative success. The system is, to our knowledge,
the first dialog or NLG system that uses the hearer?s
gaze to monitor understanding of REs.
Plan of the paper. The paper is structured as fol-
lows. We first discuss related work in Section 2. We
then describe our approach as well as the baselines
in Section 3, set up the evaluation in Section 4 and
present the results in Section 5. In Sections 6 and 7
we discuss our findings and conclude.
2 Related work
Dialog systems model a process of grounding, in
which they decide to what extent the user has under-
stood the utterance and the communicative goal has
been reached. Observing the user behavior to moni-
tor the state of understanding is a key component in
this process. A full solution may require plan recog-
nition or abductive or epistemic reasoning (see e.g.
Young et al (1994), Hirst et al (1994)); in practice,
many systems use more streamlined (Traum, 1994)
or statistical methods (Paek and Horvitz, 1999).
Most dialog systems focus on the verbal interaction
of the system and user, and the user?s utterances are
therefore the primary source of evidence in the mon-
itoring process. Some incremental dialog systems
can monitor the user?s verbal reactions to the sys-
tem?s utterances in real time, and continuously up-
date the grounding state while the system utterance
is still in progress (Skantze and Schlangen, 2009;
Buss and Schlangen, 2010).
In this paper, we focus on the generation side of a
dialog system?the user is the hearer?and on mon-
itoring the user?s extralinguistic reactions, in par-
ticular their gaze. Tanenhaus et al (1995) and Al-
lopenna et al (1998) showed that subjects in psy-
cholinguistic experiments who hear an RE visually
attend to the object to which they resolve the RE.
The ?visual world? experimental paradigm exploits
this by presenting objects on a computer screen and
using an eyetracker to monitor the subject?s gaze.
This research uses gaze only as an experimental tool
and not as part of an interactive dialog system, and
the visual worlds are usually limited to static 2D
scenes. Also, such setups cannot account for the re-
ciprocal nature of dialog and the consequences that
hearer gaze has for the speaker?s monitoring process.
In the context of situated dialog systems, previ-
ous studies have employed robots and virtual agents
as speakers to explore how and when speaker gaze
helps human hearers to ground referring expressions
(Foster, 2007). For instance, Staudte and Crocker
(2011) show that an agent can make it easier for the
(human) hearer to resolve a system-generated RE by
looking at the intended referent, using head and eye
movements. Conversely, the performance of a sys-
tem for resolving human-produced REs can be im-
proved by taking the (human) speaker?s gaze into ac-
count (Iida et al, 2011). Gaze has also been used to
track the general dynamics of a dialog, such as turn
taking (Jokinen et al, in press).
Here we are interested in monitoring the hearer?s
gaze in order to determine whether they have under-
stood an RE. To our knowledge, there has been no
research on this; in particular, not in dynamic 3D
environments. The closest earlier work of which we
are aware comes from the context of the GIVE Chal-
lenge, a shared task for interactive, situated natural
language generation systems. These systems typi-
cally approximate hearer gaze as visibility of objects
on the screen and monitor grounding based on this
(Denis, 2010; Racca et al, 2011).
31
Figure 1: A first-person view of a virtual 3D environment.
3 Interactive natural-language generation
in virtual environments
In this paper, we consider the communicative situ-
ation of the GIVE Challenge (Koller et al, 2010;
Striegnitz et al, 2011). In this task, a human user can
move about freely in a virtual indoor environment
featuring several interconnected rooms and corri-
dors. A 3D view of the environment is displayed on
a computer screen as in Fig. 1, and the user can walk
forward/backward and turn left/right, using the cur-
sor keys. They can also press buttons attached to the
walls, by clicking on them with the mouse once they
are close enough. The small and big white circles in
Fig. 1, which represent eyetracking information, are
not actually visible to the user.
The user interacts with a real-time NLG system in
the context of a treasure-hunt game, where their task
is to find a trophy hidden in a wall safe. They must
press certain buttons in the correct sequence in or-
der to open the safe; however, they do not have prior
knowledge of which buttons to press, so they rely
on instructions and REs generated by the system. A
room may contain several buttons other than the tar-
get, which is the button that the user must press next.
These other buttons are called distractors. Next to
buttons, rooms also contain a number of landmark
objects, such as chairs and plants, which cannot di-
rectly be interacted with, but may be used in REs
to nearby targets. Fig. 2 shows a top-down map of
the virtual environment in which the scene of Fig. 1
arose. We call an entire game up to the successful
discovery of the trophy, an interaction of the system
and the user.
Figure 2: A map of the environment in Fig. 1; note the
user in the upper right room.
3.1 Monitoring communicative success
NLG systems in the GIVE setting are in an interac-
tive communicative situation. This situation repre-
sents one complete half of a dialog situation: Only
the system gets to use language, but the user moves
and acts in response to the system?s utterances. As a
result, the system should continuously monitor and
react to what the user does, in real time. This is
most tangible in the system?s use of REs. When a
user misinterprets (or simply does not understand)
a system-generated RE, there is a high chance that
they will end up pressing the wrong button. This
will hinder the completion of the task. A system
that predicts how the user resolves the RE by mon-
itoring their movements and actions, and that can
proactively give the user feedback to keep them from
making a mistake, will therefore perform better than
one which cannot do this. Furthermore, if the sys-
tem can give positive feedback when it detects that
the user is about to do the right thing, this may in-
crease the user?s confidence.
Monitoring communicative success in GIVE in-
teractions and providing the right feedback can be
challenging. For example, in the original interaction
from which we took the screenshot of Fig. 1, the sys-
tem instructed the user to ?push the right button to
the right of the green button?, referring to the right-
most blue button in the scene. In response, the user
first walked hesitantly towards the far pair of buttons
(green and blue), and then turned to face the other
pair, as seen in Fig. 3. A typical NLG system used
32
Figure 3: The scene of Fig. 1, after the user moved and
turned in response to a referring expression.
in the GIVE Challenge (e.g., Dionne et al (2009),
Denis (2010), Racca et al (2011)) may try to predict
how the user might resolve the RE based on the vis-
ibility of objects, timing data, or distances. Relying
only on such data, however, even a human observer
could have difficulties in interpreting the user?s reac-
tion; the user in Fig. 3 ended up closer to the green
and blue buttons, but the other buttons (the two blue
ones) are, to similar degrees, visually in focus.
The contribution of this paper is to present a
method for monitoring the communicative success
of an RE based on eyetracking. We start from the
hypothesis that when the user resolves an RE to a
certain object, they will tend to gaze at this object.
In the scene of Fig. 3, the user was indeed looking
at the system?s intended referent, which they later
pressed; the small white circles indicate a trace of re-
cent fixations on the screen, and the big white circle
marks the object in the virtual environment to which
the system resolved these screen positions. Our sys-
tem takes this gaze information, which is available in
real time, as evidence for how the user has resolved
its RE, and generates positive or negative feedback
based on this.
3.2 NLG systems
To demonstrate the usefulness of the eyetracking-
based approach, we implemented and compared
three different NLG systems. All of these use
an identical module for generating navigation in-
structions, which guides the user to a specific lo-
cation, as well as object manipulation instructions
such as ?push the blue button?; ?the blue button?
is an RE that describes an object to the user. The
systems generate REs that are optimized for being
easy for the hearer to understand, according to a
corpus-based model of understandability (Garoufi
and Koller, 2011). The model was trained on human
instructions produced in a subset of the virtual envi-
ronments we use in this work. The resulting system
computes referring expressions that are correct and
uniquely describe the referent as seen by the hearer
at the moment in which generation starts.
Unlike in the original GIVE Challenge, the gen-
erated instructions are converted to speech by the
Mary text-to-speech system (Schro?der and Trouvain,
2003) and presented via loudspeaker. At any point,
the user may press the ?H? key on their keyboard to
indicate that they are confused and request a clari-
fication. This will cause the system to generate an
instruction newly; if it contains an RE, this RE may
or may not be the same as the one used in the origi-
nal utterance.
The difference between the three systems is in the
way they monitor communicative success and deter-
mine when to give feedback to the user.
The no-feedback system. As a baseline system,
we used a system which does not monitor success
at all, and therefore never gives feedback on its own
initiative. Notice that the system still re-generates an
RE when the user presses the ?H? key.
Movement-based monitoring. As a second base-
line, we implemented a system that attempts to mon-
itor whether a user understood an RE based on their
movements. This system is intended to represent
the user monitoring that can be implemented, with
a reasonable amount of effort, on the basis of imme-
diately available information in the GIVE setting.
The movement-based system gives no feedback
until only a single button in the current room is vis-
ible to the user, since it can be hard to make a re-
liable prediction if the user sees several buttons on
their screen. Then it tracks the user?s distance from
this button, where ?distance? is a weighted sum of
walking distance to the button and the angle the user
must turn to face the button. If, after hearing the RE,
the user has decreased the distance by more than a
given threshold, the system concludes that the hearer
has resolved the RE as this button. If that is the but-
ton the system intended to refer to, the system utters
33
the positive feedback ?yes, that one?. For incorrect
buttons, it utters the negative feedback ?no, not that
one?. Although the negative feedback is relatively
vague, it has the advantage of limiting the variability
of the system?s outputs, which facilitates evaluation.
Eyetracking-based monitoring. Finally, the
eyetracking-based system attempts to predict
whether the user will press the correct button
or not by monitoring their gaze. At intervals of
approximately 15 ms, the system determines the
(x,y) position on the screen that the user is looking
at. It then identifies the object in the environment
that corresponds to this position by casting a ray
from the (virtual) camera through the screen plane,
and picking the closest object lying within a small
range of this ray (Fig. 1; see Staudte et al (2012) for
details). If the user continously looks at the same
object for more than a certain amount of time, the
system counts this as an inspection of the object; for
our experiments, we chose a threshold of 300 ms.
Once the system detects an inspection to a button in
the room, it generates positive or negative feedback
utterances in exactly the same way as the movement
system does.
Both the movement-based and the eyetracking-
based model withhold their feedback until a first
full description of the referent (a first-mention RE)
has been spoken. Additionally, they only provide
feedback once for every newly approached or in-
spected button and will not repeat this feedback un-
less the user has approached or inspected another
button in the meantime. Example interactions of a
user with each of the three systems are presented in
Appendix A.
4 Evaluation
We set up a human evaluation study in order to as-
sess the performance of the eyetracking system as
compared against the two baselines on the situated
instruction giving task. For this, we record partic-
ipant interactions with the three systems employed
in three different virtual environments. These en-
vironments were taken from Gargett et al (2010);
they vary as to the visual and spatial properties of
the objects they contain. One of these environments
is shown in Fig. 2. Overall, 31 participants (12 fe-
males) were tested. All reported their English skills
as fluent, and all were capable of completing the
tasks. Their mean age was 27.6 years.
4.1 Task and procedure
A faceLAB eyetracking system (http://www.
seeingmachines.com/product/facelab)
remotely monitored participants? eye movements on
a 24-inch monitor, as in Fig. 4 and 5 of Appendix B.
Before the experiment, participants received written
instructions that described the task and explained
that they would be given instructions by an NLG
system. They were encouraged to request additional
help any time they felt that the instructions were not
sufficient (by pressing the ?H? key).
The eyetracker was calibrated using a nine-point
fixation stimulus. We disguised the importance of
gaze from the participants by telling them that we
videotaped them and that the camera needed calibra-
tion. Each participant started with a short practice
session to familiarize themselves with the interface
and to clarify remaining questions. We then col-
lected three complete interactions, each with a dif-
ferent virtual environment and NLG system (alter-
nated according to a Latin square design). Finally,
each participant received a questionnaire which was
aimed to reveal whether they noticed that they were
eyetracked and that one of the generation systems
made use of that, and how satisfied they were with
this interaction. The entire experiment lasted ap-
proximately 30 minutes.
4.2 Analysis
For the assessment of communicative success in
these interactions, we considered as referential
scenes the parts of the interaction between the onset
of a first-mention RE to a given referent and the par-
ticipant?s reaction (pressing a button or navigating
away to another room). To control for external fac-
tors that could have an impact on this, we discarded
individual scenes in which the systems rephrased
their first-mention REs (e.g. by adding further at-
tributes), as well as a few scenes which the partic-
ipants had to go through a second time due to tech-
nical glitches. To remove errors in eyetracker cali-
bration, we included interactions with the eyetrack-
ing NLG system in the analysis only when we were
able to record inspections (to the referent or any dis-
tractor) in at least 80% of all referential scenes. This
34
success success w/out confusion #scenes
system all easy hard all easy hard all easy hard
eyetracking 93.4 100.0 90.4 91.9 100.0 88.2 198 62 136
with feedback 94.3 100.0 91.7 92.8 100.0 89.4 194 62 132
without feedback 50.0 - 50.0 50.0 - 50.0 4 0 4
no-feedback 86.6* 100.0? 80.6* 83.5** 98.9? 76.5** 284 88 196
movement 89.8? 100.0? 85.2? 87.5? 97.8? 82.8? 295 92 203
with feedback 93.9 100.0 90.6 91.9 97.7 88.7 247 88 159
without feedback 68.8 100.0 65.9 64.6 100.0 61.4 48 4 44
Table 1: Mean referential success rate (%) and number of scenes for the systems, broken down by scene complexity
and presence of feedback. Differences of overall system performances to the eyetracking system are: significant at
** p < 0.01, * p < 0.05; ? not significant.
filtered out 9 interactions out of the 93 we collected.
Inferential statistics on this data were carried out
using mixed-effect models from the lme4 package
in R (Baayen et al, 2008). Specifically, we used
logistic regression for modeling binary data, Poisson
regression for count variables and linear regression
for continuous data.
5 Results
On evaluating the post-task questionnaires, we did
not find any significant preferences for a particular
NLG system. Roughly the same number of them
chose each of the systems on questions such as
?which system did you prefer??. When asked for
differences between the systems in free-form ques-
tions, no participant mentioned the system?s reaction
to their eye gaze?though some noticed the (lack of)
feedback. We take this to mean that the participants
did not realize they were being eyetracked.
Below, we report results on objective metrics that
do not depend on participants? judgments.
5.1 Confusion
A key goal of any RE generation system is that
the user understands the REs easily. One measure
of the ease of understanding is the frequency with
which participants pressed the ?H? key to indicate
their confusion and ask for help. The overall average
of ?H? keystrokes per interaction was 1.14 for the
eyetracking-based system, 1.77 for the movement-
based system, and 2.26 for the no-feedback system.
A model fitted to the keystroke distribution per sys-
tem shows significant differences both between the
eyetracking and the no-feedback system (Coeff. =
0.703, SE = 0.233, Wald?s Z = 3.012, p < .01) and
between the eyetracking and the movement-based
system (Coeff. = 0.475, SE = 0.241, Wald?s Z =
1.967, p < .05). In other words, the feedback
given by the eyetracking-based system significantly
reduces user confusion.
5.2 Referential success
An even more direct way to measure the interac-
tion quality is the ratio of generated REs that the
participants were able to resolve correctly. In our
evaluation, we looked at two different definitions
of success. First, an RE can count as success-
ful if the first button that the user pressed after
hearing the RE was the system?s intended referent.
The results of this evaluation are shown in the left-
most part of Table 1, under ?success?. A logis-
tic mixed-effects model fitted to the referential suc-
cess data revealed a marginal main effect of sys-
tem (?2(2) = 5.55, p = .062). Pairwise com-
parisons further show that the eyetracking system
performs significantly better than the no-feedback
system (Coeff. = ?0.765, SE = 0.342, Wald?s Z =
?2.24, p < .05); no significant difference was found
between the eyetracking-based and the movement-
based system.
Second, we can additionally require that an RE
only counts as successful if the user did not press
the ?H? key between hearing the first-mention RE
and pressing the correct button. This is a stricter
version of referential success, which requires that
the system recognized cases of potential confusion
35
and did not force the user to take the initiative in
case of difficulties. It is in line with Dethlefs et al?s
(2010) findings that metrics that penalize difficul-
ties the user encountered before successfully com-
pleting the task are better predictors of user satisfac-
tion than ones that only consider the eventual task
completion. Our results on this metric are shown
in the middle part of Table 1, under ?success with-
out confusion?. We observe again a main effect of
system (?2(2) = 7.78, p < .05); furthermore, the
eyetracking system elicited again more correct but-
tons than the no-feedback system (Coeff. = ?0.813,
SE = 0.306, Wald?s Z = ?2.66, p < 0.01).
To obtain a more detailed view of when and to
what extent the systems? behavior differed, we dis-
tinguished scenes according to their complexity. A
scene was classified as easy if a) there were no dis-
tractors in it, or b) all distractors had different colors
from the target, while the system included the color
attribute in its RE. All other scenes were considered
hard. Note that ?easy? and ?hard? are properties of
the scene and not of the system, because every sys-
tem generated the same REs in each scene.
In the experiments, we found essentially no differ-
ence between the success rates of different systems
on easy scenes (see the ?easy? columns of Table 1):
All systems were almost always successful. The
differences came almost exclusively from the hard
scenes, where the eyetracking system performed sig-
nificantly better than the no-feedback system (suc-
cess: Coeff. = ?0.793, SE = 0.348, Wald?s Z =
?2.28, p < 0.05; success without confusion: Coeff.
= ?0.833, SE = 0.315, Wald?s Z = ?2.64, p < 0.01)
and, at least numerically, also much better than the
movement system.
There was a particularly interesting difference in
the feedback behavior of the eyetracking and move-
ment systems on hard scenes (see the rightmost part
of Table 1, labeled ?#scenes?). In easy scenes,
both systems almost always gave feedback (62/62
= 100.0%; 88/92 = 95.6%); but for hard scenes,
the ratio of scenes in which the movement system
gave feedback at all dropped to 159/203 = 78.3%,
whereas the ratio for the eyetracking system re-
mained high. This may have contributed to the over-
all performance difference between the two systems.
#actions distance duration idle
system (norm.) (norm.) (norm.) (sec)
eyetracking 1.06 1.22 1.49 256.6
no-feedback 1.22* 1.27 1.59 272.5
movement 1.16 1.26 1.56 274.4
Table 2: Mean values of additional metrics. Differences
to the eyetracking system are significant at * p < 0.05.
5.3 Further performance metrics
Finally, we measured a number of other objective
metrics, including the number of actions (i.e., but-
ton presses), the distance the user traveled, the to-
tal duration of the interaction, and the mean time
a participant spent idle. Even though these mea-
sures only partly provide statistically significant re-
sults, they help to draw a clearer picture of how the
eyetracking-based feedback affects performance.
Because the three virtual environments were of
different complexity, we normalized the number of
actions, distance, and duration by dividing the value
for a given interaction by the minimum value for all
interactions of the same virtual environment. The re-
sulting measures are shown in Table 2. Participants
performed significantly fewer actions in the eye-
tracking system than in the no-feedback system (Co-
eff. = 0.174, SE = 0.067, t = 2.57, p(mcmc) < .05);
there were also trends that users of the eyetracking-
based system traveled the shortest distance, needed
the least overall time, and spent the least time idle.
The only measure deviating from this trend is
movement speed, i.e., the speed at which users re-
acted to the systems? instructions to press certain
buttons. For all successful scenes (without confu-
sion), we computed the speed by dividing the GIVE
distance (including turning distance) between the
target referent and the user?s location at the time of
the instruction containing the first-mention RE by
the time (in seconds) between hearing the instruc-
tion and pressing the target. The mean movement
speed is 0.518 for the no-feedback system, 0.493 for
the movement system, and 0.472 for the eyetracking
system. A marginal main effect of movement speed
confirms this trend (?2(2) = 5.58, p = .061) and
shows that participants moved more slowly when
getting eyetracking-based feedback than when get-
ting no feedback at all (Coeff. = 0.0352, SE =
36
0.0166, t = ?4.97, p(mcmc) < .05).
6 Discussion
The results in Section 5 demonstrate the usefulness
of eyetracking as a foundation for monitoring and
feedback. Compared to the no-feedback system, the
eyetracking-based system achieved a significantly
lower confusion rate and a significantly higher RE
success rate, especially on hard instances. The dif-
ference increases further if we discount scenes in
which the user had to ask for help, thus forcing the
system to give feedback anyway. In other words,
eyetracking provides reliable and direct access to the
hearer?s reference resolution process. Real-time di-
alog systems can use gaze information to monitor
the success of REs and generate feedback before the
user actually makes a mistake.
Monitoring and feedback could also be achieved
without using eyetracking. To explore this alterna-
tive, we compared eyetracking against a movement-
based system. We found that the former outper-
formed the latter on hearer confusion and (at least
numerically) on referential success, while not per-
forming worse on other measures. This means that
the improvement comes not merely from the fact
that feedback was given; it is also important when
and where feedback is given. The crucial weakness
of the movement-based system is that it gave feed-
back for hard instances much more rarely than the
eyetracking system. Increasing recall by lowering
the system?s confidence threshold would introduce
fresh errors. Further improvements must therefore
come at the cost of a more complex monitoring sys-
tem, both conceptually and in terms of implementa-
tion effort. From this perspective, eyetracking offers
good performance at low implementation cost.
One result that seems to go against the trend is that
users of the eyetracking system moved significantly
more slowly on their way to a target. We see two
possible explanations for this. First, it may be that
users needed some time to listen to the feedback, or
were encouraged by it to look at more objects. A
second explanation is that this is not really a differ-
ence in the quality of the systems? behavior, but a
difference in the populations over which the mean
speed was computed: The speed was only averaged
over scenes in which the users resolved the RE cor-
rectly, and the eyetracking system achieved commu-
nicative success in many cases in which the others
did not?presumably complex scenes in which the
user had to work harder to find the correct button.
This issue bears more careful analysis.
Finally, the eyetracking-based system could be
improved further in many ways. On the one hand,
it suffers from the fact that all objects in the 3D en-
vironment shift on the screen when the user turns
or moves. The user?s eyes will typically follow the
object they are currently inspecting, but lag behind
until the screen comes to a stop again. One topic
for future work would be to remove noise of this
kind from the eyetracker signal. On the other hand,
the negative feedback our system gave (?no, not that
one?) was quite unspecific. More specific feedback
(?no, the BLUE button?) might further improve the
system?s performance.
7 Conclusion
We described an interactive NLG system that uses
eyetracking to monitor the communicative success
of the REs it generates. The communication is sit-
uated in a virtual 3D environment in which the user
can move freely, and our system automatically maps
eyetracking screen coordinates to objects in the en-
vironment. A task-based evaluation found that the
eyetracking-based system outperforms both a no-
feedback system and a system whose feedback is
based on the user?s movements in the virtual envi-
ronment, along with their field of view.
Eyetracking is currently widely available in re-
search institutions, which should make our system
easy to reimplement in other situated domains. We
anticipate that eyetracking may become mainstream
technology in the not-too-distant future. But even
in a purely research context, we believe that the di-
rectness with which eyetracking allows us to observe
the hearer?s interpretation process may be useful as
a testbed for efficient theories of grounding.
Acknowledgments. This research was partly sup-
ported by the Cluster of Excellence ?Multimodal
Computing and Interaction? at Saarland University.
We are grateful to Irena Dotcheva for help with
data collection as well as to Alexandre Denis and
Christoph Clodo for software support, and to Kristi-
ina Jokinen for helpful comments.
37
Figure 4: A screenshot from the faceLAB software, including visualization of eye-gaze position in 3D space.
References
Paul Allopenna, James Magnuson, and Michael Tanen-
haus. 1998. Tracking the Time Course of Spoken
Word Recognition Using Eye Movements: Evidence
for Continuous Mapping Models. Journal of Memory
and Language, 38:419?439.
R.H. Baayen, D.J. Davidson, and D.M. Bates. 2008.
Mixed-effects modeling with crossed random effects
for subjects and items. Journal of Memory and Lan-
guage, 59:390?412.
Okko Buss and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue systems.
In Aspects of Semantics and Pragmatics of Dialogue.
SemDial 2010, 14th Workshop on the Semantics and
Pragmatics of Dialogue, pages 33?41.
Alexandre Denis. 2010. Generating referring expres-
sions with reference domain theory. In Proceedings
of the 6th International Natural Language Generation
Conference.
Nina Dethlefs, Heriberto Cuayahuitl, Kai-Florian
Richter, Elena Andonova, and John Bateman. 2010.
Evaluating task success in a dialogue system for
indoor navigation. In Aspects of Semantics and Prag-
matics of Dialogue. SemDial 2010, 14th Workshop
on the Semantics and Pragmatics of Dialogue, pages
143?146.
Daniel Dionne, Salvador de la Puente, Carlos Leo?n,
Pablo Gerva?s, and Raquel Herva?s. 2009. A model
for human readable instruction generation using level-
based discourse planning and dynamic inference of at-
tributes. In Proceedings of the 12th European Work-
shop on Natural Language Generation.
Mary Ellen Foster. 2007. Enhancing human-computer
interaction with embodied conversational agents. In
Proceedings of HCI International 2007.
Andrew Gargett, Konstantina Garoufi, Alexander Koller,
and Kristina Striegnitz. 2010. The GIVE-2 Corpus of
Giving Instructions in Virtual Environments. In Pro-
ceedings of the 7th Conference on International Lan-
guage Resources and Evaluation.
Konstantina Garoufi and Alexander Koller. 2011. The
Potsdam NLG systems at the GIVE-2.5 Challenge. In
Proceedings of the Generation Challenges Session at
the 13th European Workshop on Natural Language
Generation.
Graeme Hirst, Susan McRoy, Peter Heeman, Philip Ed-
monds, and Diane Horton. 1994. Repairing conver-
sational misunderstandings and non-understandings.
Speech Communications, 15:213?229.
Ryu Iida, Masaaki Yasuhara, and Takenobu Tokunaga.
2011. Multi-modal reference resolution in situated
dialogue by integrating linguistic and extra-linguistic
clues. In Proceedings of 5th International Joint Con-
ference on Natural Language Processing.
K. Jokinen, H. Furukawa, M. Nishida, and S. Yamamoto.
in press. Gaze and turn-taking behaviour in casual
conversational interactions. ACM Trans. Interactive
Intelligent Systems. Special Issue on Eye Gaze in In-
telligent Human-Machine Interaction.
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Johanna Moore, and Jon
38
Oberlander. 2010. The First Challenge on Generating
Instructions in Virtual Environments. In Emiel Krah-
mer and Mariet Theune, editors, Empirical Methods in
Natural Language Generation, number 5790 in LNCS,
pages 337?361. Springer.
Tim Paek and Eric Horvitz. 1999. Uncertainty, utility,
and misunderstanding: A decision-theoretic perspec-
tive on grounding in conversational systems. In AAAI
Fall Symposium on Psychological Models of Commu-
nication in Collaborative Systems.
David Nicola?s Racca, Luciana Benotti, and Pablo
Duboue. 2011. The GIVE-2.5 C Generation System.
In Proceedings of the Generation Challenges Session
at the 13th European Workshop on Natural Language
Generation.
Marc Schro?der and J. Trouvain. 2003. The German
Text-to-Speech Synthesis System MARY: A Tool for
Research, Development and Teaching. International
Journal of Speech Technology, 6:365?377.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics.
Maria Staudte and Matthew W. Crocker. 2011. Inves-
tigating joint attention mechanisms through human-
robot interaction. Cognition, 120(2):268?291.
Maria Staudte, Alexander Koller, Konstantina Garoufi,
and Matthew W. Crocker. 2012. Using listener gaze
to augment speech generation in a virtual 3D environ-
ment. In Proceedings of the 34th Annual Conference
of the Cognitive Science Society. To appear.
Kristina Striegnitz, Alexandre Denis, Andrew Gargett,
Konstantina Garoufi, Alexander Koller, and Mariet
Theune. 2011. Report on the Second Second Chal-
lenge on Generating Instructions in Virtual Environ-
ments (GIVE-2.5). In Proceedings of the Generation
Challenges Session at the 13th European Workshop on
Natural Language Generation.
Michael K. Tanenhaus, Michael J. Spivey-Knowlton,
Kathleen M. Eberhard, and Julie C. Sedivy. 1995. In-
tegration of visual and linguistic information in spoken
language comprehension. Science, 268:1632?1634.
David Traum. 1994. A computational theory of ground-
ing in natural language conversation. Ph.D. thesis,
University of Rochester.
Michael Young, Johanna Moore, and Martha Pollack.
1994. Towards a principled representation for dis-
course plans. In Proceedings of the Sixteenth Annual
Meeting of the Cognitive Science Society.
A Example interactions
The following interactions between a user (U) and
each of the three systems (S) were recorded during
the systems? attempts to instruct the user to press the
rightmost blue button shown in Fig. 1.
A.1 Eyetracking system
(1) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
ton and inspects one of them)
S: No, not that one!
. . . (U inspects other buttons in the scene, while
S provides appropriate feedback)
U: (inspects the correct target)
S: Yes, that one!
U: (presses the correct button)
A.2 Movement system
(2) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
tons; once the user is very close to the blue but-
ton, it happens to become the only button visi-
ble on screen)
U: (continues moving closer to the blue button)
S: No, not that one!
U: (has no time to react to the system?s feed-
back and presses the wrong blue button)
A.3 No-feedback system
(3) S: Push the right button to the right of the green
button.
U: (presses the wrong blue button)
B The experimental setup
Figure 5: A faceLAB eyetracking system monitored par-
ticipants? eye movements during the interactions.
39
