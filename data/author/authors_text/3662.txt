Overview of Patent Retrieval Task at NTCIR-3 
Makoto Iwayama 
Tokyo Institute of 
Technology/Hitachi Ltd. 
iwayama@crl.hitachi.co.jp 
Atsushi Fujii 
University of Tsukuba/Japan 
Science and Technology Corp.
fujii@slis.tsukuba.ac.jp 
Noriko Kando 
National Institute of 
Informatics 
kando@nii.ac.jp 
Akihiko Takano 
National Institute of 
Informatics 
aki@acm.org 
 
 
Abstract 
We describe the overview of patent re-
trieval task at NTCIR-3. The main task was 
the technical survey task, where participants 
tried to retrieve relevant patents to news ar-
ticles. In this paper, we introduce the task 
design, the patent collections, the character-
istics of the submitted systems, and the re-
sults overview. We also arranged the free-
styled task, where participants could try 
anything they want as far as the patent col-
lections were used. We describe the brief 
summaries of the proposals submitted to the 
free-styled task. 
1 Introduction 
In the field of information retrieval, there have 
been held successive evaluation workshops, such 
as TREC [8], CREF [1], and NTCIR [5], to build 
and utilize various kinds of test collections. In the 
Third NTCIR Workshop (NTCIR-3), which was 
held from June 2001 to December 2003, a serious 
effort was first made in the ?Patent Retrieval Task? 
to explore information retrieval targeting patent 
documents. 
The goal of Patent Retrieval Task is to provide 
test collections for enhancing research on patent 
information processing, from patent retrieval to 
patent mining. Although there exist many com-
mercial patent retrieval systems and services, pat-
ent retrieval has not been paid much attention in 
the research field of information retrieval. One of 
the reasons is the lack of test collection on patent. 
TREC used patent documents as a part of the 
document collections, but there was no treatment 
specially applied to the patent collection. 
In SIGIR2000, the first workshop on patent re-
trieval was held [4] and there were many fruitful 
discussions on the current status and future direc-
tions of patent retrieval. The workshop convinced 
us that there was the need of test collections spe-
cifically for patents. 
We then asked for PATOLIS Co. [7] to provide 
patent collections for the patent retrieval task. Con-
sequently, we could release three kinds of patent 
collections; those were two years? Japanese full 
texts, five years? Japanese abstracts, and five 
years? English abstracts. At the same time, we 
could fortunately have cooperation with JIPA (Ja-
pan Intellectual Property Association) [3] in creat-
ing search topics and assessing the relevance. 
Since each member of JIPA belongs to the intellec-
tual property division in her/his company, they are 
all experts in patent searching. All the above 
contributions enabled us to kick off the first 
evaluation workshop designed for patent 
information processing. 
There are various phases and aspects in patent 
information processing. For example, various 
kinds of users (researchers, patent searchers, busi-
ness managers, and so on) search patents for vari-
ous purposes (technical survey, finding conflicting 
applications, buying/selling patents, and so on). 
Corresponding to each situation, an appropriate 
search model should be developed. The standard of 
the relevance judgments may also depend on each 
situation. In some cases, retrieving relevant patents 
is not enough but further analysis on the retrieved 
patents might be necessary. For example, creating 
a patent map of a product would clarify the patent 
relations between the techniques used to make the 
product. Cross-lingual patent retrieval is also im-
portant when applying patents to foreign countries. 
All of these are within scope of our project and this 
task was the first step toward our goal. 
2 Task Design 
In this workshop, we focused on a simple task of 
technical survey. End-users we assumed in the task 
were novice users, for example, business managers. 
The major reason of adopting such general task 
was that we could only use the two years? full texts 
that were not enough for trying more patent-
oriented task like finding conflicting applications 
from patents. 
 
 
Figure 1: Scenario of technology survey 
 
To fit the task to a real situation, we used Japa-
nese news articles as the original sources of search 
topics, so the task was conducting cross-database 
retrieval, searching patents by news articles. The 
task assumed the following situation that is de-
picted in Figure 1. When a business manager looks 
through news articles and is interested in one of 
them, she/he clips it out and asks a searcher to find 
related patents to the clipping. The manager passes 
the clipping to the searcher along with her/his 
memorandum, and this clipping with memorandum 
became the search topic in this task. The memo-
randum helps the searcher to have the exact infor-
mation need the manager has, when the clipping 
contains non-relevant topics or the clipping has 
little description on the information need. Task 
participants played the role of the searcher and 
tried to retrieve relevant patents to the clipping. 
Since the purpose of the searching was technical 
survey, the claim part in patent was not treated 
specifically in assessing the relevance. Patent 
documents were treated as if those were technical 
papers. 
Cross-database retrieval itself is so general that 
techniques investigated in the task can be applied 
to various combinations of databases. This is an-
other purpose of the task. 
We prepared search topics in four languages, 
Japanese, English, Korean, and Chinese (both tra-
ditional and simplified). Participants could try 
cross-lingual patent retrieval by using one of the 
non-Japanese topics. Unfortunately, only two 
groups submitted cross-lingual results and both of 
them used English topics. 
In addition to the technical survey task ex-
plained so far, we arranged the optional task, 
where participants could try anything they want as 
far as they used the patent collections provided. 
One of the purposes of this free-styled task is to 
explore next official tasks. 
3 Characteristics of Patent Applications 
In this section, we briefly review the characteristics 
of patent applications (patent documents). 
? There are structures, for example, claims, 
purposes, effects, and embodiments of the 
invention. 
? Although the claim part is the most impor-
tant in patent, it is written in an unusual style 
especially for Japanese patent; all the sub-
topics are written in single sentence. 
? To enlarge the scope of invention, vague or 
general terms are often used in claims. 
? Patents include much technical terminology. 
Applicants may define and use their original 
terms not used in other patents. 
? There are large variations in length. The 
longest patent in our collections contains 
about 30,000 Japanese words! 
? The search models would be significantly 
different between industries, for example, 
between chemical / pharmaceutical indus-
tries and computers / machinery / electric 
industries. 
? Classification exists. IPC (International Pat-
ent Classification) is the most popular one. 
? The criterion of evaluation depends on the 
purpose of searching. For example, high re-
call is required for finding conflicting appli-
cations. 
? In some industries, images are important to 
judge the relevance. 
Our task focused on few of the above character-
istics. We treated patent documents as technical 
documents rather than legal statements, so we did 
not distinguish between the claim part and the oth-
ers in assessing the relevance. High recall was not 
necessary, so we used the standard averaged preci-
sion to evaluate the results. Few groups used struc-
tures and classifications. Images were not included 
in the patent collections provided. 
4 Patent Collections 
PATOLIS Co. provided and we released the fol-
lowing patent collections. 
? kkh: Publication of unexamined patent ap-
plications (1998, 1999) (in Japanese) 
? jsh: JAPIO Patent Abstracts (1995?1999) 
(in Japanese) 
? paj: Patent Abstracts Japan (1995? 1999) (in 
English) 
?Kkh? contains full texts of unexamined patent 
applications in Japanese. Images were eliminated. 
?Jsh? contains human edited abstracts in Japanese. 
Although all the texts in ?kkh? have the abstracts 
written by the applicants, experts in JAPIO (Japan 
Patent Information Organization) [2] short-
ened/lengthened about half of them to fit the length 
within about 400 Japanese characters. They also 
normalized technical terms if necessary. ?Paj? is 
English translation of ?jsh?. 
translation by  
human experts 
 
modif ication of the original abstracts by 
human experts (JAPIO) 
 
kkh: (98,99) 
Publication of 
unexamined patent 
applications  
(in Japanese) 
 
jsh: (95-99) 
JAPIO Patent 
Abstracts 
(in Japanese) 
 
paj: (95-99) 
Patent Abstracts 
Japan 
(in English) 
 
 
Figure 2: Relationships between the patent col-
lections 
 
Figure 2 shows the relationships between these 
three collections. Here, we see parallel relations, 
for example, full texts vs. abstracts, original ab-
stracts vs. edited abstracts, and Japanese abstracts 
vs. English abstracts. Researchers can use these 
parallel collections for various purposes, for exam-
ple, finding rules of abstracting, creating a term 
normalization dictionary, acquiring translation 
knowledge, and so on. 
Table 1 summarizes the characteristics of the 
three collections. 
 
 kkh jsh paj 
Type Full text Abstract Abstract 
Language Japanese Japanese English 
Years 98,99 95-99 95-99 
Number of 
documents
697,262 1,706,154 1,701,339
Bytes 18139M 1883M 2711M 
 
Table 1: Characteristics of the patent collections 
5 Topics 
JIPA members created topics, six for the dry run 
and 25 for the formal run. Since the topics for the 
dry run were substantially revised after the dry run, 
we decided to re-use those in the formal run. In 
consequence, we had the total 31 topics for the 
formal run. 
Figure 3 is an example of the topics in English 
and Table 2 shows the explanations of the fields in 
the topics. In our task, <ARTICLE> and 
<SUPPLEMENT> correspond to the news clipping 
and the memorandum respectively. 
The topics also contain <DESCRIPTION> and 
<NARRATIVE> fields we are familiar with. Since 
many NTCIR tasks already have the results for 
using <DESCRIPTION> and <NARRATIVE> 
fields, we can compare our results of using these 
fields with the results of other tasks. 
Along with the grade of relevance (i.e., ?A?, 
?B?, ?C?, or ?D?), each judged patent has a mark 
(?S?, ?J?, or ?U?) representing the origin from 
which the patent was retrieved. Table 3 explains 
about the marks. For example, a document with 
?BJ? means that the document was judged as ?par-
tially relevant? (i.e. ?B-?) and only found by ex-
perts in their preliminary search (i.e., ?-J?). 
Here, note that all the submitted runs contrib-
uted to collecting the ?S? patents, but only the top 
30 patents for each run were used. Note also that 
we can restore the patent set retrieved by the man-
ual search (i.e., ?PJ? set) by collecting ?J? and ?U? 
patents. 
 
 
<TOPIC><NUM>P004</NUM><LANG>EN</LANG> 
<PURPOSE>technology survey</PURPOSE> 
<TITLE>Device to judge relative merits by comparing 
codes such as barcodes with each other</TITLE> 
<ARTICLE> 
<A-DOC> 
<A-DOCNO>JA-981031179</A-DOCNO> 
<A-LANG>JA</A-LANG> 
<A-SECTION>Society</A-SECTION> 
<A-AE>No</A-AE> 
<A-WORDS>189</A-WORDS> 
<A-HEADLINE>BANDAI lost a lawsuit for piracy filed by 
EPOCH at Tokyo District Court</A-HEADLINE> 
<A-DATE>1998-10-31</A-DATE> 
<A-TEXT>In settlement of the lawsuit filed by EPOCH 
INC., the toy manufacturer, against BANDAI CO., LTD. As 
compensation of 264 million for damages for infringement 
of a card game patent, the Tokyo District Court ordered 
BANDAI to pay about 114 million on the 30th. The presid-
ing judge, Mr. Yoshiyuki Mori, indicated that some func-
tions including key operation for the "Super Barcode 
Wars" mini game machine manufactured and sold by BANDAI 
CO., LTD. in July, 1992 to March, 1993 fell under the 
"technical range of a patent licensed to EPOCH 
INC.".</A-TEXT> 
</A-DOC> 
</ARTICLE> 
<SUPPLEMENT>Determination of victory or defeat by com-
paring each other's values based on codes from barcode 
readings does not conflict with the patent.</SUPPLEMENT> 
<DESCRIPTION>What kind of devices determines leaders or 
victors by reading several codes such as barcodes and 
comparing the values corresponding to these 
codes?</DESCRIPTION> 
<NARRATIVE>"Super Barcode Wars" is a type of mini game 
machine where recorded barcodes are read in cards fea-
turing characters and the game proceeds in semi-real 
time by operating offence and defense keys. Sample codes 
include barcodes and magnetic codes, but shall not be 
defined as limited only to these.</NARRATIVE> 
<CONCEPT>Sign, barcode, code, superiority or inferior-
ity, victory or defeat, comparison, judgment</CONCEPT> 
<PI>PATENT-KKH-G-H01-333373</PI> 
</TOPIC> 
 
Figure 3: Example of the topics 
 
 
Field Explanation 
<LANG> Language code 
<PURPOSE> Purpose of search 
<TITLE> Concise representation 
of search topic 
<ARTICLE> MAINICHI news article 
in NTCIR format 
<SUPPLEMENT> Supplemental informa-
tion of news article 
<DESCRIPTION> Short description of 
search topic 
<NARRATIVE> Long description of 
search topic 
<CONCEPT> List of keywords 
<PI> Original patents of news 
article 
 
Table 2: Explanations of the fields in topics 
6 
6.1 
Results Overview 
Participants 
Eight groups submitted the 36 runs. One group 
submitted runs only for pooling. We briefly de-
scribe the characteristics of each group. Refer to 
the proceedings of Patent Retrieval Task [6] for 
each detail. 
LAPIN: This group focused on the ?term distil-
lation? in cross-database retrieval, where the dif-
ference between the term frequency in source 
database and that in target database was integrated 
into the overall term weighting. 
SRGDU: This group tried several pseudo rele-
vance feedback methods in the context of patent 
retrieval. The proposed method using Taylor for-
mula was compared with the traditional Rocchio 
method. 
daikyo: This group made long gram-based in-
dex from the patent collections. Compared with the 
traditional gram-based indexing, proposed method 
produce more compact index. 
DTEC: This group searched various kinds of 
abstracts rather than full texts, and compared the 
effectiveness of those. The abstracts were JAPIO 
patent abstracts and the combinations of ?title?, 
?applicant?s abstract?, and ?claims?. Manual and 
automatic runs were compared. 
DOVE: This group also submitted manual and 
automatic runs. In the manual runs, non-relevant 
passages in <ARTICLE> were eliminated manu-
ally. 
IFLAB: This group evaluated their cross-
lingual IR system PRIME through several mono-
lingual runs. They also evaluated their translation 
extraction method by using Japanese-US patent 
families, which were not provided in this task. 
brkly: This group submitted both monolingual 
and cross-lingual runs. In the cross-lingual runs, 
words in English topics were translated into Japa-
nese words by using English-Japanese dictionary 
automatically created by the aligned bilingual cor-
pus (i.e., ?paj? and ?jsh?). Their method of creating 
the dictionary is based on word co-occurrence with 
the association measure. 
sics: This group also submitted cross-lingual 
runs, where they automatically created a cross-
lingual thesaurus form the aligned bilingual corpus, 
?paj? and ?jsh?, and used the thesaurus for word-
based query translation. The Random Indexing 
vector-space technique was used to extract the 
cross-lingual thesaurus. Note that, in both the 
?sics? and the ?brkly? groups, there was no mem-
ber who understands Japanese. 
6.2 
6.3 
6.4 
7 
Recall/Precision 
The recall/precision graphs of the mandatory runs 
are shown in Figure 4, and those of the optional 
runs in Figure 5. In each figure, there are both re-
sults for the strict relevance (?A?) and the relaxed 
relevance (?A? + ?B?). For each run in the figures, 
brief system description is specified; the descrip-
tion includes the searching mode (automatic or 
manual), the topic fields used in query construction, 
and the topic language. 
Topic-by-topic Results 
Figure 6 shows the median of the average preci-
sions for each topic. Figure 7 shows the breakdown 
of the relevance judgments. Detailed analysis on 
each topic will be given by JIPA, where it will be 
discussed about the reasons why systems could not 
find some patents human experts found and vise 
versa. 
Recall of the relevant patents retrieved in 
the preliminary human search 
Figure 8 shows the recall of the relevant patents 
retrieved in the preliminary human search. In the 
process of making pool, we used only the top 30 
documents for each run. Here, we extracted more 
documents from each run and investigated how 
many human retrieving relevant patents could be 
covered by the systems. 
Optional (Free-styled) Task 
The following two groups applied to the optional 
task. Refer to the proceedings of Patent Retrieval 
Task [6] for each detail. 
CRL: This group investigated the method of 
extracting various rules from the existing align-
ments in patents. The ?diff? command of UNIX 
was used to find the alignments between JAPIO 
patent abstracts and the original abstracts by appli-
cants, between claims and embodiments, and be-
tween different claims in an application. 
TIT: This group focused on the unusual style of 
Japanese claims, and tried to automatically struc-
ture the claims to raise the readability of claims. 
Rhetorical structure analysis was applied for this 
purpose. 
8 Summary and Future Directions 
In this paper, we described the overview of patent 
retrieval task at NTCIR-3. We are planning to con-
tinue our effort for the next patent retrieval task 
along with the following directions. 
? Longer range of years will be covered. 
? Purpose of search would shift to more real 
one, for example, searching conflicting ap-
plications.  
Acknowledgements 
 
We are grateful to PATOLIS Co. for providing the 
patent collections of this task. We also thank all the 
members of JIPA who created the topics and as-
sessed the relevance. Without their expertise in 
patent, this task would not be realized. Lastly, we 
thank all the participants for their contributions to 
this task. 
References 
[1] CLEF (Cross Language Evaluation Forum) 
(http://clef.iei.pi.cnr.it/) 
[2] JAPIO (Japan Patent Information Organization) 
(http://www.japio.or.jp/) 
[3] JIPA (Japan Intellectual Property Association) 
(http://www.jipa.or.jp/) 
[4] ACM-SIGIR Workshop on Patent Retrieval, or-
ganized by Mun-Kew Leong and Noriko Kando, 
2000. 
(http://research.nii.ac.jp/ntcir/sigir2000ws/) 
[5] NTCIR (NII-NACSIS Test Collection for IR Sys-
tems) 
(http://research.nii.ac.jp/ntcir/index-en.html) 
[6] Proceedings of the Third NTCIR Workshop on 
Research in Information Retrieval, Automatic Text 
Summarization and Question Answering, 2003. 
[7] PATOLIS Co.                                       
 (http://www.patolis.co.jp/e-index.html) 
[8] TREC (Text Retrieval Conference) 
(http://trec.nist.gov/) 
A, mandatory
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
pr
ec
is
io
n
LAPIN4(A)
DTEC1(M)
DOVE4(M)
brklypat1(A)
daikyo(M)
SRGDU5(A)
IFLAB6(A)
brklypat3(A,E)
A: auto
M: manual
E: English topics
A+B, mandatory
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
pr
ec
is
io
n
LAPIN4(A)
DOVE4(M)
DTEC1(M)
daikyo(M)
brklypat1(A)
SRGDU3(A)
IFLAB6(A)
brklypat3(A,E)
A: auto
M: manual
E: English topics
 
Figure 4: Recall/Precision of mandatory runs
A, optional
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
pr
ec
is
io
n
LAPIN1(A,TDNC)
brklypat2(A,DN)
DOVE3(A,DN)
DOVE2(A,D)
SRGDU6(A,DN)
IFLAB2(A,D)
IFLAB3(A,DN)
IFLAB7(A,T)
brklypat4(A,DN,E)
A: auto
M : manual
T: TITLE
D: DESCRIPTION
N: NARRATIVE
C: CONCEPT
E: English Topics
 
 A+B, optional
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
pr
ec
is
io
n
LAPIN1(A,TDNC)
DOVE3(A,DN)
brklypat2(A,DN)
DOVE2(A,D)
IFLAB2(A,D)
SRGDU4(A,DN)
IFLAB4(A,DN)
IFLAB7(A,T)
brklypat4(A,DN,E)
A: auto
M : manual
T: TITLE
D: DESCRIPTION
N: NARRATIVE
C: CONCEPT
E: English Topics
 
Figure 5: Recall/Precision of optional runs 
00.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6 7 8 9 1011 12 1314 15 16 1718 19 202122 23 24 25 26 272829 30 31
topic ID
m
ed
ia
n o
f 
a
v
e
ra
ge
 
pre
ci
si
on
s
A
A+B
 
Figure 6: Median of average precisions (all runs) 
 
0
50
10
150
20
250
30
350
400
450
BS
AS
BJ
AJ
BU
AU
BS 1 34 44 2 1543 9 29 7 3 6 15 0 6 2 2 15 5 4 0 1 0 1 7 151726 0 0 1 16
AS 0 5 27 2 0 0 55 0 1 0 1 57 6 37 0 2 0 6 9 1 0 1 1 10 49 11 5 35 0 5 15
BJ 10 7 2 2 2 0 9 42 10 3 0 47 22 2 8 4 9 36 0 5 0 0 2 3 3 16 18 3 0 2 19
AJ 4 0 0 0 0 0 23101711 1 17312 10 1 1 2 11 0 0 2 4 2 10812 6 7 7 0 1 16
BU 7 13 4 4 6 0 5 33 7 4 3 29 5 10 3 1 8 18 2 1 1 0 4 16 6 16 38 7 5 7 4
AU 22 13 6 10 15 12 27 23 18 15 4 101 22 17 5 15 5 17 36 4 8 4 4 72 49 12 19 40 6 3 16
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
topic ID
n
um
be
r 
of 
d
oc
um
en
ts
 
Figure 7: Breakdown of relevance judgments  
Recall of A J+AU
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0 100 200 300 400 500 600 700 800 900 1000
ranking
re
ca
ll a ll
m andatory
m andatory (au to)
Recall  of AJ+AU+BJ+BU
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0 100 200 300 400 500 600 700 800 900 1000
ranking
re
ca
ll a ll
m andatory
m andatory (au to)
 
Figure 8: Recall of the relevant patents retrieved in the preliminary human search 
Patent Claim Processing for Readability
- Structure Analysis and Term Explanation -
Akihiro SHINMORI
Department of
Computational
Intelligence and
Systems Sciences,
Tokyo Institute of
Technology, and
INTEC Web and
Genome Informatics Co.
shinmori@isl.intec.co.jp
Manabu OKUMURA
Precision and
Intelligence
Laboratory,
Tokyo Institute of
Technology
oku@pi.titech.ac.jp
Yuzo MARUKAWA
Japan Science and
Technology Corp., and
National Institute of
Informatics
maru@nii.ac.jp
Makoto IWAYAMA
Precision and
Intelligence
Laboratory,
Tokyo Institute of
Technology, and
Hitachi, Ltd.
iwayama@pi.titech.ac.jp
Abstract
Patent corpus processing should be cen-
tered around patent claim processing be-
cause claims are the most important part
in patent specifications. It is common that
claims written in Japanese are described in
one sentence with peculiar style and word-
ing and are difficult to understand for ordi-
nary people. The peculiarity is caused by
structural complexity of the sentences and
many difficult terms used in the descrip-
tion. We have already proposed a frame-
work to represent the structure of patent
claims and a method to automatically an-
alyze it. We are currently investigating a
method to clarify terms in patent claims
and to find the explanatory portions from
the detailed description part of the patent
specifications. Through both approaches,
we believe we can improve readability of
patent claims.
1 Introduction
The importance of intellectual property, specifically
patent, is being recognized more than ever. In the
academia, patent is being considered as the core
component for technology transfer to industry. With
the upsurge of business method patents and software
patents, more and more business persons are con-
cerned about patent.
Patent is described in patent specification which is
a kind of legal documents. The most important part
of patent specification is where the claims are writ-
ten, because ?the claims specify the boundaries of
the legal monopoly created by the patent? (Burgun-
der, 1995). Therefore, we believe that patent corpus
processing should be centered around patent claim
processing.
It is common that Japanese patent claims are de-
scribed in one sentence with peculiar style and word-
ing and that they are difficult to read and under-
stand for ordinary people. After surveying related
literature and investigating NTCIR3 patent collec-
tion (Iwayama et al, 2003), we found the difficulty
has two aspects: structural difficulty and term diffi-
culty.
In this paper, we first present the characteristics
of patent claims. Next, we present our work on the
structure analysis of patent claims. Third, we intro-
duce our on-going research on term explanation for
patent claims.
2 Characteristics of Patent Claim
Typical Japanese patent claims taken from two
patents are shown in Figure 1 and 2.
In general, Japanese sentences are inserted with
the touten ??? or ??? (comma) and end with the
kuten ??? or ??? (period) . The touten plays a
role of segmenting the sentence for disambiguating
the meaning and for improving readability. Accord-
ing to the literature (Maekawa, 1995), the average
length of Japanese sentences is 55.85 characters in
newspaper articles on politics and 75.37 characters
on social affairs articles.
The claims of Figure 1 and 2 are both written
in one sentence. Though they are appropriately in-
?????????????????????
??????????????????????
?????????????????????
???? ?????? ??????????
?????????????????????
????????????????????
??????? ????????? ????
?????????????????????
?????????????????????
?????????????????????
?????????????????????
?????????????????????
?????????
Figure 1: A sample Japanese patent claim
(Publication Number=10-011111)
??????????????????????
????????????????<nl>
?????????????????????
?????????????????????
?????????????????????
??????????????????
Figure 2: A sample Japanese patent claim con-
taining a newline (Publication Number=10-146993)
(Note: <nl> means a newline.)
serted with the touten ???, they are unusually long
with the length of 295 characters and 119 charac-
ters. It is definitely true that most Japanese who are
not accustomed to reading patent claims have diffi-
culty in reading them. In fact, according to (Kasuya,
1999), Japanese patent attorneys themselves recog-
nize that Japanese patent claims are difficult to read.
The salient characteristics of Japanese patent
claims from the viewpoint of readability are as fol-
lows:
1. The length of sentence is long.
2. The structure of description is complex.
3. There are several terms which are difficult to
understand or requires explanation for under-
standing.
To examine the first point, we extracted all of the
first claims of the sample data (59,968 patents) in the
NTCIR3 patent collection, and calculated the aver-
age sentence length. We found that it is 242 char-
acters and confirmed that Japanese patent claims are
unusually long.
With regard to the second point, we surveyed
several books and articles written for patent appli-
cants to explain how to draft patent claims(Kasai,
1999; Kasuya, 1999) and how to translate patent
claims(Lise, 2002).
Based on the survey, we classify the description
style into the following three. [Note: In the follow-
ing explanation, Japanese phrases are followed by
their literal expression in [] and their English trans-
lation in (). ]
Process sequence style As in ?...? [shi](does), ...
? [shi](does), ... ?? [shita] (and does)...??
the sequence of processes is described?Mainly
used in method inventions.
Element enumeration style As in ?...? [to](and),
... ? [to](and), ... ????? [to kara
naru](comprising), ...?, the set of element is de-
scribed. Mainly used in product inventions.
Jepson-like style As in ?...???? [ni oite](in), ...
?????? [wo tokuchou to suru](be charac-
terized by), ...?, the description consists of the
first half part and the last half part. In the first
half part, either the known or the precondition
part is described. In the last half part, either the
new or the main part is described 1.
These patterns are not mutually exclusive. For ex-
ample, the first half part of the Jepson-like style may
be written in the process sequence style or in the el-
ement enumeration style.
With regard to the third point, Figure 1 contains
the term ?????????(an actuator) and Figure
2 contains the term ???????(sticky ink) which
require explanation for understanding.
Because of these characteristics, the well-known
Japanese parser KNP (Kurohashi, 2000) incorrectly
analyze or cannot process most of the Japanese
patent claims.
KNP?s dependency analysis works by detecting
parallel structure utilizing thesaurus and dynamic
programming, but it does not work well for patent
1Note that the term ?Jepson claim? is rigidly defined and
used in Europe or in the USA to describe the kind of claims
in which the known part and the new part are clearly sepa-
rated. In Japan, that is not common and the separation is more
vague(Lise, 2002). That?s why we name this as ?Jepson-like
style?.
Table 1: Relations for Japanese patent claims
Type Relation Explanation Example
Multi- PROCEDURE Process Sequence [???][???][???]X
Nuclear Style [Note: The above means ?X which [does?,]
[does?,] [and does?].?]
Multi- COMPONENT Element Enumeration [???][???][??]?
Nuclear Style [Note: The above means ?[?,] [?,] [and?].?]
Mono- ELABORATION S elaborates N. [X? Y??][Z? A]
Nuclear [Note: The above means ?[A of Z] [which Y X].?]
Mono- FEATURE Characterization [X??? Y][??????]
Nuclear [Note: The above means ?[characterized
by] [Y which is X].?].
Mono- PRECONDITION Jepson-like Style [X?????][Y?? Z]
Nuclear [Note: The above means ?[In X,] [Z which Y].?.
Mono- COMPOSE Composition [????????][????]X
Nuclear [Note: The above means ?X [composed of] [?,
?, and?].?].
claims because they often include ?chain expres-
sions? in which one concept is first defined and next
another concept is defined using the first. For the
claim in Figure 1, although ???????? (a load
detection method), ??????????? (a fre-
quency transfer device no.1), ?????????
?? (a frequency transfer device no.2), ??????
(a modulation method), and ???????? (an os-
cillation generation method) need to be recognized
as parallel, it cannot be recognized due to the exis-
tence of the expressions designated by the underline.
3 Structure Analysis of Patent Claims
3.1 Background
To improve readability of Japanese patent claims,
we claim that the structure of description needs to
be presented in a readable way. To do so, the struc-
ture needs to be analyzed first.
Japanese patent claims are described in such a
way that multiple sentences are coerced into one
sentence(Kasuya, 1999). In other words, a claim
is composed of multiple sentences that have some
kind of relationships with each other. Therefore, we
decided to apply the RST (Rhetorical Structure The-
ory) (Mann, 1999) that was proposed to analyze dis-
course structure composed of multiple sentences.
RST was proposed in the 1980?s and has been
successfully applied to automatic summarization
(Marcu, 2000), automatic layout (John Bateman,
2000), and so on. A Tcl/Tk-based interactive tool
(OD?onnel, 1997) was developed to support to man-
ually edit and to visually show the structure.
3.2 Framework
For the structure analysis of Japanese patent claims,
we defined six relations as in Table 1. Two of them
are multi-nuclear where composing elements are
equally important. Four of them are mono-nuclear
where one element is nucleus, the other is satellite,
and the nucleus is more important than the satellite.
In the ?Example? column of Table 1, the regions en-
closed with ?[? and ?]? are segments or spans and
the underlined ones are nuclei.
Given the patent claims in Figure 1 and Figure
2, we can analyze their structure and present them
visually by using RSTTool (OD?onnel, 1997) as in
Figure 3 and Figure 4 2.
3.3 Cue-phrase-based Approach
In designing the algorithm, we took a similar ap-
proach to (Marcu, 2000). We collected cue phrases
that can be used for segmenting long claims and es-
tablishing relations among segments or spans.
2Because RSTTool is written in Tcl/Tk and Tcl/Tk is an in-
ternationalized language, we did not have to localize it to dis-
play Japanese characters.
Figure 3: A result of structure analysis of patent claim in Figure 1 (using RSTTool v2.7)
Figure 4: A result of structure analysis of patent claim in Figure 2 (using RSTTool v2.7)
Table 2: Description pattern just before the newlines
in claims in which newline are explicitly inserted
No Pattern Ratio
1 (Noun|Symbol)? (?|?) 46.1%
[Note: ??? means ?and?.]
2 (Verb-Cont-Form| 17.5%
AuxVerb-Cont-Form)(?|?)
3 (Noun|Symbol)???? (?|?) 16.4%
[Note: ?????? means ?in?.]
4 (Noun|Symbol)???? (?|?) 7.2%
[Note: ?????? means ?in?.]
Cue phrases were first collected manually by
reading patent claims. Then we found that about half
of the claims are inserted with newlines at seemingly
segment boundaries as in Figure 2.
We investigated all of the extracted first claims
of the sample data and 48.5% of them are newline-
inserted claims. It seems that the drafters of patent
claims explicitly inserted those newlines for read-
ability for themselves. We checked the description
pattern of the last three morphemes just before each
newline of those claims. The result is shown in Ta-
ble 2. In Table 2, ?Verb-Cont-Form? means ???
???? (verb in continuous form) and ?AuxVerb-
Cont-Form? means ???????? (auxiliary verb
in continuous form). Note that the description pat-
terns are expressed in the regular expression notation
of Perl.
Summarizing the above, we came up with the
cue phrases in Table 3. In Table 3, ?Verb-Basic-
Form? means ??????? (verb in basic form)
and ?AuxVerb-Basic-Form? means ????????
(auxiliary verb in basic form).
3.4 Algorithm and Implementation
We designed an algorithm for analyzing structure
of independent claims3. Although patent claims are
written in natural language, it?s not written in a free
form and is restricted in a sense that there are de-
scription styles established in the community. So,
we designed an algorithm composed of a lexical an-
alyzer and a parser as in the formal language proces-
sors.
3Independent claims are claims which do not refer to any
other claims.
First, the input claim is analyzed with the morpho-
logical analyzer ?chasen? (Matsumoto et al, 2002).
Because some patent claims explicitly contain new-
lines as in Figure 2, we use the ?-j? option setting
the sentence delimiter as ????? in ?.chasenrc?.
Next, the output from chasen is analyzed with the
lexical analyzer. The main point of our algorithm
is the context-dependent behavior of the lexical ana-
lyzer as follows:
? The lexical analyzer outputs two types of to-
ken: cue phrase token and morpheme token.
? Outputting morpheme tokens is done depend-
ing on some contextual conditions to avoid am-
biguities in the parsing.
? For other morphemes whose context did not
satisfy the above conditions, an anonymous
morpheme token (WORD) is output.
Next, the output from the lexical analyzer is pro-
cessed with the parser generated from a context-free
grammar (CFG) by using Bison (Donnelly and Stall-
man, 1995)-compatible parser generator. The CFG
we designed for Japanese patent claim consists of 57
rules, 11 terminals, and 19 non-terminals.
Finally, a structure tree is constructed in the form
of ?.rs2? file used in RSTTool v2.7. By using RST-
Tool, the output is visually displayed as in Figure 3
and Figure 4.
3.5 Evaluation
The evaluation was done by using the first claims 4
of 59,956 patents extracted from the NTCIR3 patent
data collection.
The NTCIR3 patent data collection consists of
697,262 patents opened to public in 1998 and in
1999. For the analysis, the collection of cue phrases,
and the creation of the CFG, we used patents in
1998. For the evaluation, we used patents in 1999.
We checked the IPC (International Patent Classi-
fication) code of 59,956 patents and confirmed that
the distribution is similar to the one of all opened
patents in 1999 disclosed by JPO (Japan Patent Of-
fice).
The evaluation was done in the following points:
4First claims are always independent claims.
Table 3: Cue phrases which can be used to analyze patent claims
Token Name Cue Phrase Gloss
JEPSON CUE ? (? |?)?? (?|?) [ni oite] (in)
???? (?|?) [de atte] (in)
???? (?|?) [ni atari] (in)
?? (?)?? (?|?) [ni atari] (in)
FEATURE CUE ???? (?? |??)(?|?)? [wo tokuchou to
(shita|suru)]
(characterized by)
COMPOSE CUE ????????? (? |? |???) (?|?)? [wo tousaishite kousei
sare (ta|ru|teiru)]
(comprising)
? (?|?)?(? |? |??)? (? |? |???) (?|?)? [wo sonae (ta|ru|teiru)]
(comprising)
? (?|?)??? (?? |?? |???? |????) [wo gubi (shita|suru|
(?|?)? shiteiru|shitenaru)]
(comprising)
(? |??)???? (? |???) (?|?)? [(de|kara) kousei sare
(ta|teiru)]
(comprising)
? (?|?)?? (?? |??) (?|?)? [wo yuu (suru|shita)]
(comprising)
? (?|?)??? (?? |??) (?|?)? [wo hougan (suru|shita)]
(comprising)
? (?|?)?? (? |??) (?|?)? [wo fuku (mu|nda)]
(comprising)
?? (?|?)?(?? |??? |?????) (?|?)? [kara (naru|natta
|natteiru)]
(comprising)
?? (?|?)?(?? |??? |?????) (?|?)? [kara (naru|natta
|natteiru)]
(comprising)
? (?|?)??? (? |???) (?|?)? [wo mouke (ta|teiru)]
(comprising)
? (?|?)??? (?? |?? |????) (?|?)? [wo soubi (suru|shita
|shiteiru)]
(comprising)
NOUN The sequence of ?(Noun|Symbol)? (?|?)?
POSTP TO
PUNCT TOUTEN
VERB RENYOU The sequence of
PUNCT TOUTEN ?(Verb-Cont-Form|AuxVerb-Cont-Form)(?|?)?
which exist before
?(Verb-Basic-Form|AuxVerb-Basic-Form)
(Noun|Symbol)?
Accept Ratio The ratio of claims accepted by the
parser generated by the CFG.
Processing Speed The time required to process one
claim.
Accuracy The accuracy of the analysis result eval-
uated indirectly and directly.
The accept ratio was more than 99.77%. The pro-
cessing speed was 0.30 second per each claim (eval-
uated on a Linux PC using Pentium III 1GHz and
512MB memory). So, it is almost real-time.
3.5.1 Indirect Evaluation on Accuracy
By specifying a command-line switch, our pro-
gram can be run without utilizing the originally in-
serted newlines. The newline insertion positions can
be predicted by the result of structure analysis and
some heuristics. So, indirect evaluation was done by
comparing the newline insertion positions between
the originally newline-inserted claims and the auto-
matically newline-inserted claims utilizing the result
of structure analysis. The recall(R), the precision(P),
and the F-measure(F) are calculated by the follow-
ings, where c is the number of correctly-inserted
newlines, n is the number of newlines in the orig-
inal claim, and i is the number of inserted newlines.
R =
c
n
(1)
P =
c
i
(2)
F =
2 ? R ? P
R + P
(3)
The baseline was set in that the newlines are in-
serted mechanically at the end of every sequence
of ?(NOUN|SYMBOL)(?|?)? and ?(Verb-Cont-
Form|AuxVerb-Cont-Form)(?|?)?.
Note that newlines are sometimes inserted at the
positions that are not segment boundaries in the
meaning of RST. For example, it is often the case
that at the end of ???? (a postpositional particle
representing the subject), newlines are inserted. So,
our newline-insertion prediction algorithm has the
inherent upper limit whose recall is 0.873.
The result is shown in Table 4.
Table 4: Evaluation result (Indirect)
Index Baseline Newline Upper
Insertion Limit
utilizing
RST
Recall(R) 0.478 0.674 0.8736
Precision(P) 0.374 0.663 N/A
F-measure 0.420 0.669 N/A
Table 5: Evaluation result (Direct)
Category Count Percentage
(Except
?No judgment?)
Correct 76 80.85%
Partially Correct 11 11.70%
Incorrect 7 7.45%
No judgment 6 -
3.5.2 Direct Evaluation on Accuracy
The direct evaluation on accuracy was done by us-
ing randomly selected 100 claims extracted. All of
these claims are the first claims. Again, we checked
the distribution of IPC and confirmed it?s similar to
the one of all opened patents in 1999 disclosed by
JPO.
The 100 claims were analyzed by our program
and the visually-displayed outputs like Figure 3 and
4 were presented to a subject who had some expe-
rience in reading patent specifications. The subject
evaluated the result by the following criteria:
? when the claim is in the Jepson-like style,
whether that is correctly recognized.
? when the claim is in the Jepson-like style,
whether the structure is correctly analyzed for
the first half part and for the last half part.
? when the claim is not in the Jepson-like style,
whether the structure is correctly analyzed for
the whole.
The result is shown in Table 5.
3.6 Application to Patent Claim Paraphrase
Once the structure of patent claims are analyzed, we
can apply the result to paraphrase patent claims.
To do so, the following actions are incorporated
into the lexical analyzer and the parser.
? The lexical analyzer deletes the words ????
(the), ??? (the), and ???? (the).
? For the parser, new actions are added which re-
locates the ?noun group? located at the end to
the front. Same thing for the ?noun group? lo-
cated just before JEPSON CUE for the Jepson-
like style claims.
? For the process sequence style, the lexical an-
alyzer conjugates verbs and adverbs from their
continuous form to basic form and replaces the
touten ?(?|?)? with the kuten ???.
? For the element enumeration style, the lexical
analyzer converts those cue phrases such as ??
????(consist of) and ?????? (include)
to their ??????(?teiru? form) plus ??? and
deletes ?? (?|?)? (and) at the end of each el-
ement.
? The lexical analyzer converts ????(thing)
just before ????????(characterized by)
to ????(the following).
? For the Jepson-like style, the parser separates
the first-half part and the last-half part by in-
serting a newline.
By doing the above processing, long patent claim
sentences are divided into multiple sentences. But
as there are cases where some of the generated sen-
tences are still too long, those sentences longer than
the threshold length (75 characters) are recursively
processed.
An example of paraphrase is shown in Figure 5.
We believe that paraphrasing can not only im-
prove readability of patent claims but also can work
effectively as a preprocessing for machine transla-
tion 5.
5In fact, there are several commercial machine translation
software which does special preprocessing for patent claims be-
fore translating from Japanese to English.
?????????????????????
???????????
?????????????????????
??????????:
?????????????????????
??????
?????????????????????
????????????????
?????????????????????
?????????????????
?????????????????????
?????????????????????
????????????
?????????????????????
????????
Figure 5: A sample paraphrase for Figure 1
4 Term Explanation for Patent Claims
4.1 Background and Motivation
Once the structure of patent claims are analyzed
and presented visually, next hurdle for readability is
terms.
There are many novel terms used in patent claim
description. They can be classified into the follow-
ing categories:
Terms specific to the invention Patent drafters of-
ten assign unique names to the invention, its
elements, and its processes for their identifica-
tion.
Terms specific to the domain The patent law re-
quires patents should be written so that those
who have ordinary knowledge in the domain
can understand and perform the invention. So,
technical terms that are established in the do-
main are often used. Additionally, there exist
?patent jargons? which are created by combin-
ing two kanji characters such as ???? (put
and insert) and ???? (put into the hall)(Kasai,
1999). They are first created by some patent
drafters for the sake of brevity and have been
widely used in the community. So, they are
terms specific to the inventions of the domain.
Those who do not have enough knowledge in
the domain or those who are not accustomed to
reading patent specifications have difficulty in
understanding them.
Giving appropriate explanations for these terms
would help to improve readability of patent claims.
4.2 Approach
First of all, it is necessary to recognize terms to be
explained. There are many research issues in term
extraction in general, but for our purpose we use
the following morphological pattern to extract terms
from patent claims:
(Prefix)*(Noun|Unknown-Words|Symbol
|Verb-Cont-Form|Verb-Compound-With-
Indeclinable-Word)+
By using the above pattern, we can extract such
terms as ?????????? (method to blow heat
wind), ????? (read value), and ???? (liquid
drop) which contain verbs.
Second, by using the result of structure analysis,
we can infer the categories of the terms as follows:
? If the term appears at the end of the claim or
just before the JEPSON CUE in the Jepson-
like style, or just before ??? (and) in the el-
ement enumeration style, it is a term specific
to the invention. For example, ???????
?????? (an operational virtual oscillation
generating device) and ????????(a load
detection method) in Figure 1 are terms specific
to this invention.
? If the term appears in the middle of the first half
in the Jepson-like style, it can be a term specific
to the domain. For example, ???????
??(an actuator) in Figure 1 is a technical term
in the domain.
? If the term is a two-kanji character and is not
listed in the ordinary dictionaries, it can be a
patent jargon.
Finally, by looking at the detailed description of
the invention or related inventions, we can back up
the above inference as follows:
? The terms specific to the invention should be
described after the ?means to solve the prob-
lem? section in the detailed description of the
invention.
? The terms specific to the domain are widely
used in the inventions of the domain. So, it is
highly possible that they occur frequently in the
related inventions. We can consider the collec-
tion of search result as the related inventions.
? Some of the technical terms specific to the do-
main are described in the ?prior art? section of
the detailed description of the invention or re-
lated inventions in the domain.
For those technical terms specific to the domain,
explanatory portions such as the following can be
found:
 ?...???????????????????????
?????????????????...?
(... driving the oil pressure cylinder (or the actuator) at
the speed of ...)
 ?...??????????...?
(... the spout (or the orifice) ...)
 ?...????????????????????...?
(... blowing out ink preliminarily (namely, purging ink)
...?
 ?...????????????????????...?
(... ink of the hot-melt type (or solid ink) ...
As can be seen in the above, explanatory por-
tions can be found by using cue phrases such as ?
?? and ???, ???? (?in the following?), and ???
?? (?or? or ?namely?).
4.3 Sample Scenario
From the patent claim in Figure 2, we find many
terms that are candidates for explanation such as ??
???? (time measurement), ???????? (the
method to measure time), ?????? (measurement
result), ??????? (sticky ink), ???????
?? (removal of sticky ink), ???????????
(removal processing of sticky ink), ???????
???? (the method to remove sticky ink).
Among the above terms, ???????? (the
method to measure time) and ?????????
?? (the method to remove sticky ink) are terms spe-
cific to the invention because they are judged as the
elements by structure analysis.
By searching the detailed description, we can find
the explanatory portion for ??????? (sticky
ink) as follows.
 ?...???????????????????????
????...?
(... the ink of increased stickiness (in the following, we
call it as ?sticky ink? ...)
4.4 Further Analysis and Experimentation
We continue to analyze the NTCIR3 patent data col-
lection, specifically ?Patolis Test Collection? which
is a test collection for patent retrieval consisting of
a set of query and search result. We use each search
result as ?related inventions? and analyze them to
collect cue phrases for finding explanatory portions
for technical terms specific to the domain.
5 Related Work
A NLP research for patent claim is already reported
in (Kameda, 1995). It is directed toward dependency
analysis of patent claims. Although it is proposed to
support ?analytic reading? of patent claims, the eval-
uation result for large-scale real patent data is not
reported. Our approach is different from (Kameda,
1995) in that the top-level structure is analyzed.
In (Sheremetyeva and Nirenburg, 1996), a re-
search on a system for authoring patent claims us-
ing NLP and knowledge engineering technique is re-
ported.
6 Concluding Remarks
We have presented a framework to represent the
structure of patent claims and a method to automat-
ically analyze it. The evaluation result suggest that
our approach is robust and practical.
We are currently investigating a method to clar-
ify terms in patent claims and to find the explana-
tory portions from the detailed description part of
the patent specifications.
It is not only a step toward improving readability,
but it can also lead to more challenging task of auto-
matic patent map generation(Study group on patent
map, 1990).
Acknowledgements
The NTCIR3 patent data collection was used in our research.
References
Lee B. Burgunder. 1995. Legal Aspects of Managing
Technology. South Western.
Charles Donnelly and Richard Stallman, 1995. Bison:
The YACC-compatible Parser Generator, Version 1.25.
Makoto Iwayama, Atsushi Fujii, Akihiko Takano, and
Noriko Kando. 2003. Overview of patent retrieval
task at ntcir-3. In The Third NTCIR Workshop on Re-
search in Information Retrieval, Automatic Text Sum-
marization and Question Answering. National Institute
of Informatics.
Jorg Kleinz Klaus Reichenberger John Bateman,
Thomas Kamps. 2000. Toward constructive text,
diagram, and layout generation for information pre-
sentation. Computational Linguistics, 27(3):409?449.
Masayuki Kameda. 1995. Support functions for reading
japanese text. In IPSJ SIGNotes Natural Language,
number 110. Information Processing Society of Japan.
(in Japanese).
Yasuji Kasai. 1999. Manual for Drafting Patent Claims.
Kougyo Chosakai. (in Japanese).
Youji Kasuya. 1999. On the description style of patent
claims and the techniques to draft them. Patent, 52(2).
(in Japanese).
Sadao Kurohashi. 2000. KNP - japanese parsing for real.
IPSJ MAGAZINE, 41(11). (in Japanese).
William Lise. 2002. An investigation of ter-
minology and syntax in japanese and us patents
and the implications for the patent translator.
http://www.lise.jp/patsur.html.
Mamoru Maekawa. 1995. Science of Sentences.
Iwanama. (in Japanese).
Bill Mann. 1999. An introduction
to rhetorical structure theory (RST).
http://www.sil.org/ mannb/rst/rintro99.htm.
Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. MIT Press.
Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita,
Yoshitaka Hirano, Hiroshi Matsuda, Kazuma Takaoka,
and Masayuki Asahara, 2002. Morphological Analy-
sis System ChaSen version 2.2.9 Manual. Nara Insti-
tute of Science and Technology.
Michael OD?onnel. 1997. RST-Tool: An RST analysis
tool. In The 6th European Workshop on Natural Lan-
guage Generation.
Svelana Sheremetyeva and Sergey Nirenburg. 1996.
Knowledge elicitation for authoring patent claims.
IEEE Computer, 57?63.
Study group on patent map, editor. 1990. Patent Map
and Information Strategy. Japan Institute of Invention
and Innovation. (in Japanese).
