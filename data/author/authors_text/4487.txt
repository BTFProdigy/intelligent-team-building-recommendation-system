Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 73?80, Vancouver, October 2005. c?2005 Association for Computational Linguistics
A Discriminative Matching Approach to Word Alignment
Ben Taskar Simon Lacoste-Julien Dan Klein
Computer Science Division, EECS Department
University of California, Berkeley
Berkeley, CA 94720
Abstract
We present a discriminative, large-
margin approach to feature-based
matching for word alignment. In this
framework, pairs of word tokens re-
ceive a matching score, which is based
on features of that pair, including mea-
sures of association between the words,
distortion between their positions, sim-
ilarity of the orthographic form, and so
on. Even with only 100 labeled train-
ing examples and simple features which
incorporate counts from a large unla-
beled corpus, we achieve AER perfor-
mance close to IBM Model 4, in much
less time. Including Model 4 predic-
tions as features, we achieve a relative
AER reduction of 22% in over inter-
sected Model 4 alignments.
1 Introduction
The standard approach to word alignment from
sentence-aligned bitexts has been to construct
models which generate sentences of one lan-
guage from the other, then fitting those genera-
tive models with EM (Brown et al, 1990; Och
and Ney, 2003). This approach has two primary
advantages and two primary drawbacks. In its
favor, generative models of alignment are well-
suited for use in a noisy-channel translation sys-
tem. In addition, they can be trained in an un-
supervised fashion, though in practice they do
require labeled validation alignments for tuning
model hyper-parameters, such as null counts or
smoothing amounts, which are crucial to pro-
ducing alignments of good quality. A primary
drawback of the generative approach to align-
ment is that, as in all generative models, explic-
itly incorporating arbitrary features of the in-
put is difficult. For example, when considering
whether to align two words in the IBM models
(Brown et al, 1990), one cannot easily include
information about such features as orthographic
similarity (for detecting cognates), presence of
the pair in various dictionaries, similarity of the
frequency of the two words, choices made by
other alignment systems on this sentence pair,
and so on. While clever models can implicitly
capture some of these information sources, it
takes considerable work, and can make the re-
sulting models quite complex. A second draw-
back of generative translation models is that,
since they are learned with EM, they require
extensive processing of large amounts of data
to achieve good performance. While tools like
GIZA++ (Och and Ney, 2003) do make it eas-
ier to build on the long history of the generative
IBM approach, they also underscore how com-
plex high-performance generative models can,
and have, become.
In this paper, we present a discriminative ap-
proach to word alignment. Word alignment is
cast as a maximum weighted matching problem
(Cormen et al, 1990) in which each pair of words
(e
j
, f
k
) in a sentence pair (e, f) is associated
with a score s
jk
(e, f) reflecting the desirability
of the alignment of that pair. The alignment
73
for the sentence pair is then the highest scoring
matching under some constraints, for example
the requirement that matchings be one-to-one.
This view of alignment as graph matching is
not, in itself, new: Melamed (2000) uses com-
petitive linking to greedily construct matchings
where the pair score is a measure of word-
to-word association, and Matusov et al (2004)
find exact maximum matchings where the pair
scores come from the alignment posteriors of
generative models. Tiedemann (2003) proposes
incorporating a variety of word association
?clues? into a greedy linking algorithm.
What we contribute here is a principled ap-
proach for tractable and efficient learning of the
alignment score s
jk
(e, f) as a function of ar-
bitrary features of that token pair. This con-
tribution opens up the possibility of doing the
kind of feature engineering for alignment that
has been so successful for other NLP tasks. We
first present the algorithm for large margin es-
timation of the scoring function. We then show
that our method can achieve AER rates com-
parable to unsymmetrized IBM Model 4, using
extremely little labeled data (as few as 100 sen-
tences) and a simple feature set. Remarkably,
by including bi-directional IBM Model 4 predic-
tions as features, we achieve an absolute AER
of 5.4 on the English-French Hansards alignment
task, a relative reduction of 22% in AER over in-
tersected Model 4 alignments and, to our knowl-
edge, the best AER result published on this task.
2 Algorithm
We model the alignment prediction task as a
maximum weight bipartite matching problem,
where nodes correspond to the words in the
two sentences. For simplicity, we assume here
that each word aligns to one or zero words in
the other sentence. The edge weight s
jk
repre-
sents the degree to which word j in one sentence
can translate into the word k in the other sen-
tence. Our goal is to find an alignment that
maximizes the sum of edge scores. We represent
a matching using a set of binary variables y
jk
that are set to 1 if word j is assigned to word
k in the other sentence, and 0 otherwise. The
score of an assignment is the sum of edge scores:
s(y) =
?
jk
s
jk
y
jk
. The maximum weight bi-
partite matching problem, arg maxy?Y s(y), can
be solved using well known combinatorial algo-
rithms or the following linear program:
max
z
?
jk
s
jk
z
jk
(1)
s.t.
?
j
z
jk
? 1,
?
k
z
jk
? 1, 0 ? z
jk
? 1,
where the continuous variables z
jk
correspond to
the binary variables y
jk
. This LP is guaranteed
to have integral (and hence optimal) solutions
for any scoring function s(y) (Schrijver, 2003).
Note that although the above LP can be used to
compute alignments, combinatorial algorithms
are generally more efficient. However, we use
the LP to develop the learning algorithm below.
For a sentence pair x, we denote position
pairs by x
jk
and their scores as s
jk
. We let
s
jk
= wf(x
jk
) for some user provided fea-
ture mapping f and abbreviate wf(x,y) =
?
jk
y
jk
wf(x
jk
). We can include in the fea-
ture vector the identity of the two words, their
relative positions in their respective sentences,
their part-of-speech tags, their string similarity
(for detecting cognates), and so on.
At this point, one can imagine estimating a
linear matching model in multiple ways, includ-
ing using conditional likelihood estimation, an
averaged perceptron update (see which match-
ings are proposed and adjust the weights ac-
cording to the difference between the guessed
and target structures (Collins, 2002)), or in
large-margin fashion. Conditional likelihood es-
timation using a log-linear model P (y | x) =
1
Z
w
(x)
exp{wf(x,y)} requires summing over all
matchings to compute the normalization Zw(x),
which is #P-complete (Valiant, 1979). In our
experiments, we therefore investigated the aver-
aged perceptron in addition to the large-margin
method outlined below.
2.1 Large-margin estimation
We follow the large-margin formulation of
Taskar et al (2005a). Our input is a set of
training instances {(x
i
,y
i
)}m
i=1
, where each in-
stance consists of a sentence pair x
i
and a target
74
alignment y
i
. We would like to find parameters
w that predict correct alignments on the train-
ing data:
y
i
= arg max
?y
i
?Y
i
wf(x
i
, y?
i
), ?i,
where Y
i
is the space of matchings appropriate
for the sentence pair i.
In standard classification problems, we typi-
cally measure the error of prediction, (y
i
, y?
i
),
using the simple 0-1 loss. In structured prob-
lems, where we are jointly predicting multiple
variables, the loss is often more complex. While
the F-measure is a natural loss function for this
task, we instead chose a sensible surrogate that
fits better in our framework: Hamming distance
between y
i
and y?
i
, which simply counts the
number of edges predicted incorrectly.
We use an SVM-like hinge upper bound on
the loss (y
i
, y?
i
), given by max
?y
i
?Y
i
[wf
i
(y?
i
) +

i
(y?
i
) ? wf
i
(y
i
)], where 
i
(y?
i
) = (y
i
, y?
i
), and
f
i
(y?
i
) = f(x
i
, y?
i
). Minimizing this upper bound
encourages the true alignment y
i
to be optimal
with respect to w for each instance i:
min
||w||??
?
i
max
?y
i
?Y
i
[wf
i
(y?
i
) + 
i
(y?
i
)] ? wf
i
(y
i
),
where ? is a regularization parameter.
In this form, the estimation problem is a mix-
ture of continuous optimization over w and com-
binatorial optimization over y
i
. In order to
transform it into a more standard optimization
problem, we need a way to efficiently handle the
loss-augmented inference, max
?y
i
?Y
i
[wf
i
(y?
i
) +

i
(y?
i
)]. This optimization problem has pre-
cisely the same form as the prediction prob-
lem whose parameters we are trying to learn
? max
?y
i
?Y
i
wf
i
(y?
i
) ? but with an additional
term corresponding to the loss function. Our as-
sumption that the loss function decomposes over
the edges is crucial to solving this problem. In
particular, we use weighted Hamming distance,
which counts the number of variables in which
a candidate solution y?
i
differs from the target
output y
i
, with different cost for false positives
(c+) and false negatives (c-):

i
(y?
i
) =
?
jk
[
c-y
i,jk
(1 ? y?
i,jk
) + c+y?
i,jk
(1 ? y
i,jk
)
]
=
?
jk
c-y
i,jk
+
?
jk
[c+ ? (c- + c+)y
i,jk
]y?
i,jk
.
The loss-augmented matching problem can then
be written as an LP similar to Equation 1 (with-
out the constant term
?
jk
c-y
i,jk
):
max
z
?
jk
z
i,jk
[wf(x
i,jk
) + c+ ? (c- + c+)y
i,jk
]
s.t.
?
j
z
i,jk
? 1,
?
k
z
i,jk
? 1, 0 ? z
i,jk
? 1.
Hence, without any approximations, we have a
continuous optimization problem instead of a
combinatorial one:
max
?y
i
?Y
i
wf
i
(y?
i
)+
i
(y?
i
) = d
i
+max
z
i
?Z
i
(wF
i
+c
i
)z
i
,
where d
i
=
?
jk
c-y
i,jk
is the constant term, F
i
is the appropriate matrix that has a column of
features f(x
i,jk
) for each edge jk, c
i
is the vector
of the loss terms c+ ? (c- + c+)y
i,jk
and finally
Z
i
= {z
i
:
?
j
z
i,jk
? 1,
?
k
z
i,jk
? 1, 0 ?
z
i,jk
? 1}.
Plugging this LP back into our estimation
problem, we have
min
||w||??
max
z?Z
?
i
wF
i
z
i
+ c
i
z
i
? wF
i
y
i
, (2)
where z = {z
1
, . . . , z
m
}, Z = Z
1
? . . .?Z
m
. In-
stead of the derivation in Taskar et al (2005a),
which produces a joint convex optimization
problem using Lagrangian duality, here we
tackle the problem in its natural saddle-point
form.
2.2 The extragradient method
For saddle-point problems, a well-known solu-
tion strategy is the extragradient method (Ko-
rpelevich, 1976), which is closely related to
projected-gradient methods.
The gradient of the objective in Equation 2
is given by:
?
i
F
i
(z
i
? y
i
) (with respect to w)
and F
i
w + c
i
(with respect to each z
i
). We de-
note the Euclidean projection of a vector onto
Z
i
as P
Z
i
(v) = arg minu?Z
i
||v ? u|| and pro-
jection onto the ball ||w|| ? ? as P
?
(w) =
?w/max(?, ||w||).
75
An iteration of the extragradient method con-
sists of two very simple steps, prediction:
w?t+1 = P
?
(wt + ?
k
?
i
F
i
(y
i
? zt
i
));
z?t+1
i
= P
Z
i
(zt
i
+ ?
k
(F
i
wt + c
i
));
and correction:
wt+1 = P
?
(wt + ?
k
?
i
F
i
(y
i
? z?t+1
i
));
zt+1
i
= P
Z
i
(zt
i
+ ?
k
(F
i
w?t+1 + c
i
)),
where ?
k
are appropriately chosen step sizes.
The method is guaranteed to converge linearly
to a solution w?, z? (Korpelevich, 1976; He and
Liao, 2002; Taskar et al, 2005b). Please see
www.cs.berkeley.edu/~taskar/extragradient.pdf
for more details.
The key subroutine of the algorithm is Eu-
clidean projection onto the feasible sets Z
i
. In
case of word alignment, Z
i
is the convex hull of
bipartite matchings and the problem reduces to
the much-studied minimum cost quadratic flow
problem (Bertsekas et al, 1997). The projection
problem P
Z
i
(z?
i
) is given by
min
z
?
jk
1
2
(z?
i,jk
? z
i,jk
)2
s.t.
?
j
z
i,jk
? 1,
?
k
z
i,jk
? 1, 0 ? z
i,jk
? 1.
We can now use a standard reduction of bipar-
tite matching to min cost flow by introducing a
source node connected to all the words in one
sentence and a sink node connected to all the
words in the other sentence, using edges of ca-
pacity 1 and cost 0. The original edges jk have
a quadratic cost 1
2
(z?
i,jk
? z
i,jk
)2 and capacity 1.
Now the minimum cost flow from the source to
the sink computes projection of z?
i
onto Z
i
We
use standard, publicly-available code for solving
this problem (Guerriero and Tseng, 2002).
3 Experiments
We applied this matching algorithm to word-
level alignment using the English-French
Hansards data from the 2003 NAACL shared
task (Mihalcea and Pedersen, 2003). This
corpus consists of 1.1M automatically aligned
sentences, and comes with a validation set of 39
sentence pairs and a test set of 447 sentences.
The validation and test sentences have been
hand-aligned (see Och and Ney (2003)) and are
marked with both sure and possible alignments.
Using these alignments, alignment error rate
(AER) is calculated as:
AER(A,S, P ) = 1 ? |A ? S| + |A ? P |
|A| + |S|
Here, A is a set of proposed index pairs, S is
the sure gold pairs, and P is the possible gold
pairs. For example, in Figure 1, proposed align-
ments are shown against gold alignments, with
open squares for sure alignments, rounded open
squares for possible alignments, and filled black
squares for proposed alignments.
Since our method is a supervised algorithm,
we need labeled examples. For the training data,
we split the original test set into 100 training
examples and 347 test examples. In all our ex-
periments, we used a structured loss function
(y
i
, y?
i
) that penalized false negatives 3 times
more than false positives, where 3 was picked by
testing several values on the validation set. In-
stead of selecting a regularization parameter ?
and running to convergence, we used early stop-
ping as a cheap regularization method, by set-
ting ? to a very large value (10000) and running
the algorithm for 500 iterations. We selected a
stopping point using the validation set by simply
picking the best iteration on the validation set in
terms of AER (ignoring the initial ten iterations,
which were very noisy in our experiments). All
selected iterations turned out to be in the first
50 iterations, as the algorithm converged fairly
rapidly.
3.1 Features and Results
Very broadly speaking, the classic IBM mod-
els of word-level translation exploit four primary
sources of knowledge and constraint: association
of words (all IBM models), competition between
alignments (all models), zero- or first-order pref-
erences of alignment positions (2,4+), and fer-
tility (3+). We model all of these in some way,
76
on
e of th
e
ma
jo
r
ob
je
ct
iv
es of
th
es
e
co
ns
ul
ta
ti
on
s is to
ma
ke
su
re
th
at th
e
re
co
ve
ry
be
ne
fi
ts al
l .
le
un
de
les
grands
objectifs
de
les
consultations
est
de
faire
en
sorte
que
la
relance
profite
e?galement
a`
tous
.
on
e of th
e
ma
jo
r
ob
je
ct
iv
es of
th
es
e
co
ns
ul
ta
ti
on
s is to
ma
ke
su
re
th
at th
e
re
co
ve
ry
be
ne
fi
ts al
l .
le
un
de
les
grands
objectifs
de
les
consultations
est
de
faire
en
sorte
que
la
relance
profite
e?galement
a`
tous
.
(a) Dice only (b) Dice and Distance
on
e of th
e
ma
jo
r
ob
je
ct
iv
es of
th
es
e
co
ns
ul
ta
ti
on
s is to
ma
ke
su
re
th
at th
e
re
co
ve
ry
be
ne
fi
ts al
l .
le
un
de
les
grands
objectifs
de
les
consultations
est
de
faire
en
sorte
que
la
relance
profite
e?galement
a`
tous
.
on
e of th
e
ma
jo
r
ob
je
ct
iv
es of
th
es
e
co
ns
ul
ta
ti
on
s is to
ma
ke
su
re
th
at th
e
re
co
ve
ry
be
ne
fi
ts al
l .
le
un
de
les
grands
objectifs
de
les
consultations
est
de
faire
en
sorte
que
la
relance
profite
e?galement
a`
tous
.
(c) Dice, Distance, Orthographic, and BothShort (d) All features
Figure 1: Example alignments for each successive feature set.
except fertility.1
First, and, most importantly, we want to in-
clude information about word association; trans-
lation pairs are likely to co-occur together in
a bitext. This information can be captured,
among many other ways, using a feature whose
1In principle, we can model also model fertility, by
allowing 0-k matches for each word rather than 0-1, and
having bias features on each word. However, we did not
explore this possibility.
value is the Dice coefficient (Dice, 1945):
Dice(e, f) = 2CEF (e, f)C
E
(e)C
F
(f)
Here, C
E
and C
F
are counts of word occurrences
in each language, while C
EF
is the number of
co-occurrences of the two words. With just this
feature on a pair of word tokens (which depends
only on their types), we can already make a stab
77
at word alignment, aligning, say, each English
word with the French word (or null) with the
highest Dice value (see (Melamed, 2000)), sim-
ply as a matching-free heuristic model. With
Dice counts taken from the 1.1M sentences, this
gives and AER of 38.7 with English as the tar-
get, and 36.0 with French as the target (in line
with the numbers from Och and Ney (2003)).
As observed in Melamed (2000), this use of
Dice misses the crucial constraint of competi-
tion: a candidate source word with high asso-
ciation to a target word may be unavailable for
alignment because some other target has an even
better affinity for that source word. Melamed
uses competitive linking to incorporate this con-
straint explicitly, while the IBM-style models
get this effect via explaining-away effects in EM
training. We can get something much like the
combination of Dice and competitive linking by
running with just one feature on each pair: the
Dice value of that pair?s words.2 With just a
Dice feature ? meaning no learning is needed
yet ? we achieve an AER of 29.8, between the
Dice with competitive linking result of 34.0 and
Model 1 of 25.9 given in Och and Ney (2003).
An example of the alignment at this stage is
shown in Figure 1(a). Note that most errors lie
off the diagonal, for example the often-correct
to-a` match.
IBM Model 2, as usually implemented, adds
the preference of alignments to lie near the di-
agonal. Model 2 is driven by the product of a
word-to-word measure and a (usually) Gaussian
distribution which penalizes distortion from the
diagonal. We can capture the same effect us-
ing features which reference the relative posi-
tions j and k of a pair (e
j
, f
k
). In addition to a
Model 2-style quadratic feature referencing rela-
tive position, we threw in the following proxim-
ity features: absolute difference in relative posi-
tion abs(j/|e|?k/|f |), and the square and square
root of this value. In addition, we used a con-
junction feature of the dice coefficient times the
proximity. Finally, we added a bias feature on
each edge, which acts as a threshold that allows
2This isn?t quite competitive linking, because we use
a non-greedy matching.
in
19
78
Am
er
ic
an
s
di
vo
rc
ed
1,
12
2,
00
0
ti
me
s .
en
1978
,
on
a
enregistre?
1,122,000
divorces
sur
le
continent
.
in
19
78
Am
er
ic
an
s
di
vo
rc
ed
1,
12
2,
00
0
ti
me
s .
en
1978
,
on
a
enregistre?
1,122,000
divorces
sur
le
continent
.
(a) (b)
Figure 2: Example alignments showing the ef-
fects of orthographic cognate features. (a) Dice
and Distance, (b) With Orthographic Features.
sparser, higher precision alignments. With these
features, we got an AER of 15.5 (compare to 19.5
for Model 2 in (Och and Ney, 2003)). Note that
we already have a capacity that Model 2 does
not: we can learn a non-quadratic penalty with
linear mixtures of our various components ? this
gives a similar effect to learning the variance of
the Gaussian for Model 2, but is, at least in
principle, more flexible.3 These features fix the
to-a` error in Figure 1(a), giving the alignment
in Figure 1(b).
On top of these features, we included other
kinds of information, such as word-similarity
features designed to capture cognate (and ex-
act match) information. We added a feature for
exact match of words, exact match ignoring ac-
cents, exact matching ignoring vowels, and frac-
tion overlap of the longest common subsequence.
Since these measures were only useful for long
words, we also added a feature which indicates
that both words in a pair are short. These or-
thographic and other features improved AER to
14.4. The running example now has the align-
ment in Figure 1(c), where one improvement
may be attributable to the short pair feature ? it
has stopped proposing the-de, partially because
the short pair feature downweights the score of
that pair. A clearer example of these features
making a difference is shown in Figure 2, where
both the exact-match and character overlap fea-
3The learned response was in fact close to a Gaussian,
but harsher near zero displacement.
78
tures are used.
One source of constraint which our model still
does not explicitly capture is the first-order de-
pendency between alignment positions, as in the
HMM model (Vogel et al, 1996) and IBM mod-
els 4+. The the-le error in Figure 1(c) is symp-
tomatic of this lack. In particular, it is a slightly
better pair according to the Dice value than the
correct the-les. However, the latter alignment
has the advantage that major-grands follows it.
To use this information source, we included a
feature which gives the Dice value of the words
following the pair.4 We also added a word-
frequency feature whose value is the absolute
difference in log rank of the words, discourag-
ing very common words from translating to very
rare ones. Finally, we threw in bilexical features
of the pairs of top 5 non-punctuation words in
each language.5 This helped by removing spe-
cific common errors like the residual tendency
for French de to mistakenly align to English the
(the two most common words). The resulting
model produces the alignment in Figure 1(d).
It has sorted out the the-le / the-les confusion,
and is also able to guess to-de, which is not the
most common translation for either word, but
which is supported by the good Dice value on
the following pair (make-faire).
With all these features, we got a final AER
of 10.7, broadly similar to the 8.9 or 9.7 AERs
of unsymmetrized IBM Model 4 trained on the
same data that the Dice counts were taken
from.6 Of course, symmetrizing Model 4 by in-
tersecting alignments from both directions does
yield an improved AER of 6.9, so, while our
model does do surprisingly well with cheaply ob-
tained count-based features, Model 4 does still
outperform it so far. However, our model can
4It is important to note that while our matching algo-
rithm has no first-order effects, the features can encode
such effects in this way, or in better ways ? e.g. using as
features posteriors from the HMM model in the style of
Matusov et al (2004).
5The number of such features which can be learned
depends on the number of training examples, and since
some of our experiments used only a few dozen training
examples we did not make heavy use of this feature.
6Note that the common word pair features affected
common errors and therefore had a particularly large im-
pact on AER.
Model AER
Dice (without matching) 38.7 / 36.0
Model 4 (E-F, F-E, intersected) 8.9 / 9.7/ 6.9
Discriminative Matching
Dice Feature Only 29.8
+ Distance Features 15.5
+ Word Shape and Frequency 14.4
+ Common Words and Next-Dice 10.7
+ Model 4 Predictions 5.4
Figure 3: AER on the Hansards task.
also easily incorporate the predictions of Model
4 as additional features. We therefore added
three new features for each edge: the prediction
of Model 4 in the English-French direction, the
prediction in the French-English direction, and
the intersection of the two predictions. With
these powerful new features, our AER dropped
dramatically to 5.4, a 22% improvement over the
intersected Model 4 performance.
Another way of doing the parameter estima-
tion for this matching task would have been
to use an averaged perceptron method, as in
Collins (2002). In this method, we merely run
our matching algorithm and update weights
based on the difference between the predicted
and target matchings. However, the perfor-
mance of the average perceptron learner on the
same feature set is much lower, only 8.1, not
even breaking the AER of its best single feature
(the intersected Model 4 predictions).
3.2 Scaling Experiments
We explored the scaling of our method by learn-
ing on a larger training set, which we created by
using GIZA++ intersected bi-directional Model
4 alignments for the unlabeled sentence pairs.
We then took the first 5K sentence pairs from
these 1.1M Model 4 alignments. This gave us
more training data, albeit with noisier labels.
On a 3.4GHz Intel Xeon CPU, GIZA++ took
18 hours to align the 1.1M words, while our
method learned its weights in between 6 min-
utes (100 training sentences) and three hours
(5K sentences).
79
4 Conclusions
We have presented a novel discriminative, large-
margin method for learning word-alignment
models on the basis of arbitrary features of word
pairs. We have shown that our method is suit-
able for the common situation where a moder-
ate number of good, fairly general features must
be balanced on the basis of a small amount of
labeled data. It is also likely that the method
will be useful in conjunction with a large labeled
alignment corpus (should such a set be created).
We presented features capturing a few separate
sources of information, producing alignments on
the order of those given by unsymmetrized IBM
Model 4 (using labeled training data of about
the size others have used to tune generative
models). In addition, when given bi-directional
Model 4 predictions as features, our method
provides a 22% AER reduction over intersected
Model 4 predictions alone. The resulting 5.4
AER on the English-French Hansarks task is,
to our knowledge, the best published AER fig-
ure for this training scenario (though since we
use a subset of the test set, evaluations are not
problem-free). Finally, our method scales to
large numbers of training sentences and trains
in minutes rather than hours or days for the
higher-numbered IBM models, a particular ad-
vantage when not using features derived from
those slower models.
References
D. P. Bertsekas, L. C. Polymenakos, and P. Tseng. 1997.
An e-relaxation method for separable convex cost net-
work flow problems. SIAM J. Optim., 7(3):853?870.
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and
P. S. Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2):79?85.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. EMNLP.
T. H. Cormen, C. E. Leiserson, and R. L. Rivest. 1990.
Introduction to Algorithms. MIT Press, Cambridge,
MA.
L. R. Dice. 1945. Measures of the amount of ecologic as-
sociation between species. Journal of Ecology, 26:297?
302.
F. Guerriero and P. Tseng. 2002. Implementation
and test of auction methods for solving generalized
network flow problems with separable convex cost.
Journal of Optimization Theory and Applications,
115(1):113?144, October.
B.S. He and L. Z. Liao. 2002. Improvements of some
projection methods for monotone nonlinear variational
inequalities. JOTA, 112:111:128.
G. M. Korpelevich. 1976. The extragradient method for
finding saddle points and other problems. Ekonomika
i Matematicheskie Metody, 12:747:756.
E. Matusov, R. Zens, and H. Ney. 2004. Symmetric word
alignments for statistical machine translation. In Proc.
of COLING 2004.
I. D. Melamed. 2000. Models of translational equivalence
among words. Computational Linguistics, 26(2):221?
249.
R. Mihalcea and T. Pedersen. 2003. An evaluation ex-
ercise for word alignment. In Proceedings of the HLT-
NAACL 2003 Workshop, Building and Using parallel
Texts: Data Driven Machine Translation and Beyond,
pages 1?6, Edmonton, Alberta, Canada.
F. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?52.
A. Schrijver. 2003. Combinatorial Optimization: Poly-
hedra and Efficiency. Springer.
B. Taskar, V. Chatalbashev, D. Koller, and C. Guestrin.
2005a. Learning structured prediction models: a large
margin approach. In Proceedings of the International
Conference on Machine Learning.
B. Taskar, S. Lacoste-Julien, and M. Jordan. 2005b.
Structured prediction via the extragradient method.
In Proceedings of Neural Information Processing Sys-
tems.
J. Tiedemann. 2003. Combining clues for word align-
ment. In Proceedings of EACL.
L. G. Valiant. 1979. The complexity of computing the
permanent. Theoretical Computer Science, 8:189?201.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
word alignment in statistical translation. In COLING
16, pages 836?841.
80
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 112?119,
New York, June 2006. c?2006 Association for Computational Linguistics
Word Alignment via Quadratic Assignment
Simon Lacoste-Julien
UC Berkeley, Berkeley, CA 94720
slacoste@cs.berkeley.edu
Ben Taskar
UC Berkeley, Berkeley, CA 94720
taskar@cs.berkeley.edu
Dan Klein
UC Berkeley, Berkeley, CA 94720
klein@cs.berkeley.edu
Michael I. Jordan
UC Berkeley, Berkeley, CA 94720
jordan@cs.berkeley.edu
Abstract
Recently, discriminative word alignment methods
have achieved state-of-the-art accuracies by extend-
ing the range of information sources that can be
easily incorporated into aligners. The chief advan-
tage of a discriminative framework is the ability
to score alignments based on arbitrary features of
the matching word tokens, including orthographic
form, predictions of other models, lexical context
and so on. However, the proposed bipartite match-
ing model of Taskar et al (2005), despite being
tractable and effective, has two important limita-
tions. First, it is limited by the restriction that
words have fertility of at most one. More impor-
tantly, first order correlations between consecutive
words cannot be directly captured by the model. In
this work, we address these limitations by enrich-
ing the model form. We give estimation and infer-
ence algorithms for these enhancements. Our best
model achieves a relative AER reduction of 25%
over the basic matching formulation, outperform-
ing intersected IBM Model 4 without using any
overly compute-intensive features. By including
predictions of other models as features, we achieve
AER of 3.8 on the standard Hansards dataset.
1 Introduction
Word alignment is a key component of most end-
to-end statistical machine translation systems. The
standard approach to word alignment is to construct
directional generative models (Brown et al, 1990;
Och and Ney, 2003), which produce a sentence in
one language given the sentence in another lan-
guage. While these models require sentence-aligned
bitexts, they can be trained with no further super-
vision, using EM. Generative alignment models do,
however, have serious drawbacks. First, they require
extensive tuning and processing of large amounts
of data which, for the better-performing models, is
a non-trivial resource requirement. Second, condi-
tioning on arbitrary features of the input is difficult;
for example, we would like to condition on the or-
thographic similarity of a word pair (for detecting
cognates), the presence of that pair in various dic-
tionaries, the similarity of the frequency of its two
words, choices made by other alignment systems,
and so on.
Recently, Moore (2005) proposed a discrimina-
tive model in which pairs of sentences (e, f) and
proposed alignments a are scored using a linear
combination of arbitrary features computed from the
tuples (a, e, f). While there are no restrictions on
the form of the model features, the problem of find-
ing the highest scoring alignment is very difficult
and involves heuristic search. Moreover, the param-
eters of the model must be estimated using averaged
perceptron training (Collins, 2002), which can be
unstable. In contrast, Taskar et al (2005) cast word
alignment as a maximum weighted matching prob-
lem, in which each pair of words (ej , fk) in a sen-
tence pair (e, f) is associated with a score sjk(e, f)
reflecting the desirability of the alignment of that
pair. Importantly, this problem is computationally
tractable. The alignment for the sentence pair is the
highest scoring matching under constraints (such as
the constraint that matchings be one-to-one). The
scoring model sjk(e, f) can be based on a rich fea-
ture set defined on word pairs (ej , fk) and their con-
text, including measures of association, orthogra-
phy, relative position, predictions of generative mod-
els, etc. The parameters of the model are estimated
within the framework of large-margin estimation; in
particular, the problem turns out to reduce to the
112
solution of a (relatively) small quadratic program
(QP). The authors show that large-margin estimation
is both more stable and more accurate than percep-
tron training.
While the bipartite matching approach is a use-
ful first step in the direction of discriminative word
alignment, for discriminative approaches to com-
pete with and eventually surpass the most sophisti-
cated generative models, it is necessary to consider
more realistic underlying statistical models. Note in
particular two substantial limitations of the bipartite
matching model of Taskar et al (2005): words have
fertility of at most one, and there is no way to incor-
porate pairwise interactions among alignment deci-
sions. Moving beyond these limitations?while re-
taining computational tractability?is the next major
challenge for discriminative word alignment.
In this paper, we show how to overcome both lim-
itations. First, we introduce a parameterized model
that penalizes different levels of fertility. While this
extension adds very useful expressive power to the
model, it turns out not to increase the computa-
tional complexity of the aligner, for either the pre-
diction or the parameter estimation problem. Sec-
ond, we introduce a more thoroughgoing extension
which incorporates first-order interactions between
alignments of consecutive words into the model. We
do this by formulating the alignment problem as a
quadratic assignment problem (QAP), where in ad-
dition to scoring individual edges, we also define
scores of pairs of edges that connect consecutive
words in an alignment. The predicted alignment is
the highest scoring quadratic assignment.
QAP is an NP-hard problem, but in the range of
problem sizes that we need to tackle the problem can
be solved efficiently. In particular, using standard
off-the-shelf integer program solvers, we are able to
solve the QAP problems in our experiments in under
a second. Moreover, the parameter estimation prob-
lem can also be solved efficiently by making use of
a linear relaxation of QAP for the min-max formu-
lation of large-margin estimation (Taskar, 2004).
We show that these two extensions yield signif-
icant improvements in error rates when compared
to the bipartite matching model. The addition of a
fertility model improves the AER by 0.4. Model-
ing first-order interactions improves the AER by 1.8.
Combining the two extensions results in an improve-
ment in AER of 2.3, yielding alignments of better
quality than intersected IBM Model 4. Moreover,
including predictions of bi-directional IBM Model
4 and model of Liang et al (2006) as features, we
achieve an absolute AER of 3.8 on the English-
French Hansards alignment task?the best AER re-
sult published on this task to date.
2 Models
We begin with a quick summary of the maximum
weight bipartite matching model in (Taskar et al,
2005). More precisely, nodes V = Vs ? V t cor-
respond to words in the ?source? (Vs) and ?tar-
get? (V t) sentences, and edges E = {jk : j ?
Vs, k ? V t} correspond to alignments between word
pairs.1 The edge weights sjk represent the degree
to which word j in one sentence can be translated
using the word k in the other sentence. The pre-
dicted alignment is chosen by maximizing the sum
of edge scores. A matching is represented using a
set of binary variables yjk that are set to 1 if word
j is assigned to word k in the other sentence, and 0
otherwise. The score of an assignment is the sum of
edge scores: s(y) = ?jk sjkyjk. For simplicity, let
us begin by assuming that each word aligns to one or
zero words in the other sentence; we revisit the issue
of fertility in the next section. The maximum weight
bipartite matching problem, arg maxy?Y s(y), can
be solved using combinatorial algorithms for min-
cost max-flow, expressed in a linear programming
(LP) formulation as follows:
max
0?z?1
?
jk?E
sjkzjk (1)
s.t.
?
j?Vs
zjk ? 1, ?k ? V t;
?
k?Vt
zjk ? 1, ?j ? Vs,
where the continuous variables zjk are a relax-
ation of the corresponding binary-valued variables
yjk. This LP is guaranteed to have integral (and
hence optimal) solutions for any scoring function
s(y) (Schrijver, 2003). Note that although the above
LP can be used to compute alignments, combina-
torial algorithms are generally more efficient. For
1The source/target designation is arbitrary, as the models
considered below are all symmetric.
113
t
he
ba
ck
bo
ne of
o
u
r
e
c
o
n
o
m
y
de
e?pine
dorsale
a`
notre
e?conomie
t
he
ba
ck
bo
ne of
o
u
r
e
c
o
n
o
m
y
de
e?pine
dorsale
a`
notre
e?conomie
(a) (b)
Figure 2: An example fragment that requires fertility
greater than one to correctly label. (a) The guess of
the baseline M model. (b) The guess of the M+F
fertility-augmented model.
example, in Figure 1(a), we show a standard con-
struction for an equivalent min-cost flow problem.
However, we build on this LP to develop our exten-
sions to this model below. Representing the predic-
tion problem as an LP or an integer LP provides a
precise (and concise) way of specifying the model
and allows us to use the large-margin framework
of Taskar (2004) for parameter estimation described
in Section 3.
For a sentence pair x, we denote position pairs by
xjk and their scores as sjk. We let sjk = w>f(xjk)
for some user provided feature mapping f and ab-
breviate w>f(x,y) = ?jk yjkw>f(xjk). We can
include in the feature vector the identity of the two
words, their relative positions in their respective sen-
tences, their part-of-speech tags, their string similar-
ity (for detecting cognates), and so on.
2.1 Fertility
An important limitation of the model in Eq. (1) is
that in each sentence, a word can align to at most
one word in the translation. Although it is common
that words have gold fertility zero or one, it is cer-
tainly not always true. Consider, for example, the
bitext fragment shown in Figure 2(a), where back-
bone is aligned to the phrase e?pine dorsal. In this
figure, outlines are gold alignments, square for sure
alignments, round for possibles, and filled squares
are target algnments (for details on gold alignments,
see Section 4). When considering only the sure
alignments on the standard Hansards dataset, 7 per-
cent of the word occurrences have fertility 2, and 1
percent have fertility 3 and above; when considering
the possible alignments high fertility is much more
common?31 percent of the words have fertility 3
and above.
One simple fix to the original matching model is
to increase the right hand sides for the constraints
in Eq. (1) from 1 to D, where D is the maximum
allowed fertility. However, this change results in
an undesirable bimodal behavior, where maximum
weight solutions either have all words with fertil-
ity 0 or D, depending on whether most scores sjk
are positive or negative. For example, if scores tend
to be positive, most words will want to collect as
many alignments as they are permitted. What the
model is missing is a means for encouraging the
common case of low fertility (0 or 1), while allowing
higher fertility when it is licensed. This end can be
achieved by introducing a penalty for having higher
fertility, with the goal of allowing that penalty to
vary based on features of the word in question (such
as its frequency or identity).
In order to model such a penalty, we introduce
indicator variables zdj? (and zd?k) with the intended
meaning: node j has fertility of at least d (and node
k has fertility of at least d). In the following LP, we
introduce a penalty of
?
2?d?D sdj?zdj? for fertility
of node j, where each term sdj? ? 0 is the penalty
increment for increasing the fertility from d ? 1 to
d:
max
0?z?1
?
jk?E
sjkzjk (2)
?
?
j?Vs,2?d?D
sdj?zdj? ?
?
k?Vt,2?d?D
sd?kzd?k
s.t.
?
j?Vs
zjk ? 1 +
?
2?d?D
zd?k, ?k ? V t;
?
k?Vt
zjk ? 1 +
?
2?d?D
zdj?, ?j ? Vs.
We can show that this LP always has integral so-
lutions by a reduction to a min-cost flow problem.
The construction is shown in Figure 1(b). To ensure
that the new variables have the intended semantics,
we need to make sure that sdj? ? sd?j? if d ? d?,
so that the lower cost zdj? is used before the higher
cost zd?j? to increase fertility. This restriction im-
114
(a) (b) (c)
Figure 1: (a) Maximum weight bipartite matching as min-cost flow. Diamond-shaped nodes represent flow
source and sink. All edge capacities are 1, with edges between round nodes (j, k) have cost ?sjk, edges
from source and to sink have cost 0. (b) Expanded min-cost flow graph with new edges from source and to
sink that allow fertility of up to 3. The capacities of the new edges are 1 and the costs are 0 for solid edges
from source and to sink, s2j?, s2?k for dashed edges, and s3j?, s3?k for dotted edges. (c) Three types of pairs
of edges included in the QAP model, where the nodes on both sides correspond to consecutive words.
fo
r
m
o
r
e
t
ha
n a
y
e
a
r
depuis
plus
de
un
an
fo
r
m
o
r
e
t
ha
n a
y
e
a
r
depuis
plus
de
un
an
(a) (b)
Figure 3: An example fragment with a monotonic
gold alignment. (a) The guess of the baseline M
model. (b) The guess of the M+Q quadratic model.
plies that the penalty must be monotonic and convex
as a function of the fertility.
To anticipate the results that we report in Sec-
tion 4, adding fertility to the basic matching model
makes the target algnment of the backbone example
feasible and, in this case, the model correctly labels
this fragment as shown in Figure 2(b).
2.2 First-order interactions
An even more significant limitation of the model
in Eq. (1) is that the edges interact only indi-
rectly through the competition induced by the con-
straints. Generative alignment models like the
HMM model (Vogel et al, 1996) and IBM models 4
and above (Brown et al, 1990; Och and Ney, 2003)
directly model correlations between alignments of
consecutive words (at least on one side). For exam-
ple, Figure 3 shows a bitext fragment whose gold
alignment is strictly monotonic. This monotonicity
is quite common ? 46% of the words in the hand-
aligned data diagonally follow a previous alignment
in this way. We can model the common local align-
ment configurations by adding bonuses for pairs of
edges. For example, strictly monotonic alignments
can be encouraged by boosting the scores of edges
of the form ?(j, k), (j + 1, k + 1)?. Another trend,
common in English-French translation (7% on the
hand-aligned data), is the local inversion of nouns
and adjectives, which typically involves a pair of
edges ?(j, k + 1), (j + 1, k)?. Finally, a word in one
language is often translated as a phrase (consecutive
sequence of words) in the other language. This pat-
tern involves pairs of edges with the same origin on
one side: ?(j, k), (j, k+1)? or ?(j, k), (j+1, k)?. All
three of these edge pair patterns are shown in Fig-
ure 1(c). Note that the set of such edge pairs Q =
{jklm : |j ? l| ? 1, |k ? m| ? 1} is of linear size
in the number of edges.
Formally, we add to the model variables zjklm
which indicate whether both edge jk and lm are in
the alignment. We also add a corresponding score
sjklm, which we assume to be non-negative, since
the correlations we described are positive. (Nega-
tive scores can also be used, but the resulting for-
mulation we present below would be slightly differ-
ent.) To enforce the semantics zjklm = zjkzlm, we
use a pair of constraints zjklm ? zjk; zjklm ? zlm.
Since sjklm is positive, at the optimum, zjklm =
115
min(zjk, zlm). If in addition zjk, zlm are integral (0
or 1), then zjklm = zjkzlm. Hence, solving the fol-
lowing LP as an integer linear program will find the
optimal quadratic assignment for our model:
max
0?z?1
?
jk?E
sjkzjk +
?
jklm?Q
sjklmzjklm (3)
s.t.
?
j?Vs
zjk ? 1, ?k ? V t;
?
k?Vt
zjk ? 1, ?j ? Vs;
zjklm ? zjk, zjklm ? zlm, ?jklm ? Q.
Note that we can also combine this extension with
the fertility extension described above.
To once again anticipate the results presented in
Section 4, the baseline model of Taskar et al (2005)
makes the prediction given in Figure 3(a) because
the two missing alignments are atypical translations
of common words. With the addition of edge pair
features, the overall monotonicity pushes the align-
ment to that of Figure 3(b).
3 Parameter estimation
To estimate the parameters of our model, we fol-
low the large-margin formulation of Taskar (2004).
Our input is a set of training instances {(xi,yi)}mi=1,
where each instance consists of a sentence pair xi
and a target algnment yi. We would like to find
parameters w that predict correct alignments on the
training data: yi = arg max
y?i?Yi
w>f(xi, y?i) for each i,
where Yi is the space of matchings for the sentence
pair xi.
In standard classification problems, we typically
measure the error of prediction, `(yi, y?i), using the
simple 0-1 loss. In structured problems, where we
are jointly predicting multiple variables, the loss is
often more complex. While the F-measure is a nat-
ural loss function for this task, we instead chose a
sensible surrogate that fits better in our framework:
weighted Hamming distance, which counts the num-
ber of variables in which a candidate solution y? dif-
fers from the target output y, with different penalty
for false positives (c+) and false negatives (c?):
`(y, y?) =
?
jk
[
c+(1 ? yjk)y?jk + c?(1 ? y?jk)yjk
]
.
We use an SVM-like hinge upper bound on
the loss `(yi, y?i), given by maxy?i?Yi [w>fi(y?i) +
`i(y?i) ? w>fi(yi)], where `i(y?i) = `(yi, y?i), and
fi(y?i) = f(xi, y?i). Minimizing this upper bound
encourages the true alignment yi to be optimal with
respect to w for each instance i:
min
||w||??
?
i
max
y?i?Yi
[w>fi(y?i) + `i(y?i)] ? w>fi(yi),
where ? is a regularization parameter.
In this form, the estimation problem is a mixture
of continuous optimization over w and combinato-
rial optimization over yi. In order to transform it
into a more standard optimization problem, we need
a way to efficiently handle the loss-augmented in-
ference, maxy?i?Yi [w>fi(y?i) + `i(y?i)]. This opti-
mization problem has precisely the same form as the
prediction problem whose parameters we are trying
to learn ? maxy?i?Yi w>fi(y?i) ? but with an addi-
tional term corresponding to the loss function. Our
assumption that the loss function decomposes over
the edges is crucial to solving this problem. We omit
the details here, but note that we can incorporate the
loss function into the LPs for various models we de-
scribed above and ?plug? them into the large-margin
formulation by converting the estimation problem
into a quadratic problem (QP) (Taskar, 2004). This
QP can be solved using any off-the-shelf solvers,
such as MOSEK or CPLEX.2 An important differ-
ence that comes into play for the estimation of the
quadratic assignment models in Equation (3) is that
inference involves solving an integer linear program,
not just an LP. In fact the LP is a relaxation of the in-
teger LP and provides an upper bound on the value
of the highest scoring assignment. Using the LP re-
laxation for the large-margin QP formulation is an
approximation, but as our experiments indicate, this
approximation is very effective. At testing time, we
use the integer LP to predict alignments. We have
also experimented with using just the LP relaxation
at testing time and then independently rounding each
fractional edge value, which actually incurs no loss
in alignment accuracy, as we discuss below.
2When training on 200 sentences, the QP we obtain contains
roughly 700K variables and 300K constraints and is solved in
roughly 10 minutes on a 2.8 GHz Pentium 4 machine. Aligning
the whole training set with the flow formulation takes a few
seconds, whereas using the integer programming (for the QAP
formulation) takes 1-2 minutes.
116
t
he
ho
n.
m
e
m
be
r
fo
r
V
e
r
du
n
w
o
u
ld
n
o
t
ha
ve
de
ni
gr
at
ed my
p
o
s
it
io
n
le
de?pute?
de
Verdun
ne
aurait
pas
de?pre?cie?
ma
position
t
he
ho
n.
m
e
m
be
r
fo
r
V
e
r
du
n
w
o
u
ld
n
o
t
ha
ve
de
ni
gr
at
ed my
p
o
s
it
io
n
le
de?pute?
de
Verdun
ne
aurait
pas
de?pre?cie?
ma
position
t
he
ho
n.
m
e
m
be
r
fo
r
V
e
r
du
n
w
o
u
ld
n
o
t
ha
ve
de
ni
gr
at
ed my
p
o
s
it
io
n
le
de?pute?
de
Verdun
ne
aurait
pas
de?pre?cie?
ma
position
(a) (b) (c)
Figure 4: An example fragment with several multiple fertility sure alignments. (a) The guess of the M+Q
model with maximum fertility of one. (b) The guess of the M+Q+F quadratic model with fertility two
permitted. (c) The guess of the M+Q+F model with lexical fertility features.
4 Experiments
We applied our algorithms to word-level alignment
using the English-French Hansards data from the
2003 NAACL shared task (Mihalcea and Pedersen,
2003). This corpus consists of 1.1M automatically
aligned sentences, and comes with a validation set of
37 sentence pairs and a test set of 447 sentences. The
validation and test sentences have been hand-aligned
(see Och and Ney (2003)) and are marked with both
sure and possible alignments. Using these align-
ments, alignment error rate (AER) is calculated as:
(
1 ? |A ? S| + |A ? P ||A| + |S|
)
? 100%.
Here, A is a set of proposed index pairs, S is the
sure gold pairs, and P is the possible gold pairs.
For example, in Figure 4, proposed alignments are
shown against gold alignments, with open squares
for sure alignments, rounded open squares for possi-
ble alignments, and filled black squares for proposed
alignments.
The input to our algorithm is a small number of
labeled examples. In order to make our results more
comparable with Moore (2005), we split the origi-
nal set into 200 training examples and 247 test ex-
amples. We also trained on only the first 100 to
make our results more comparable with the exper-
iments of Och and Ney (2003), in which IBM model
4 was tuned using 100 sentences. In all our experi-
ments, we used a structured loss function that penal-
ized false negatives 10 times more than false posi-
tives, where the value of 10 was picked by using a
validation set. The regularization parameter ? was
also chosen using the validation set.
4.1 Features and results
We parameterized all scoring functions sjk, sdj?,
sd?k and sjklm as weighted linear combinations of
feature sets. The features were computed from
the large unlabeled corpus of 1.1M automatically
aligned sentences.
In the remainder of this section we describe the
improvements to the model performance as various
features are added. One of the most useful features
for the basic matching model is, of course, the set of
predictions of IBM model 4. However, computing
these features is very expensive and we would like to
build a competitive model that doesn?t require them.
Instead, we made significant use of IBM model 2 as
a source of features. This model, although not very
accurate as a predictive model, is simple and cheap
to construct and it is a useful source of features.
The Basic Matching Model: Edge Features In
the basic matching model of Taskar et al (2005),
called M here, one can only specify features on pairs
of word tokens, i.e. alignment edges. These features
117
include word association, orthography, proximity,
etc., and are documented in Taskar et al (2005). We
also augment those features with the predictions of
IBM Model 2 run on the training and test sentences.
We provided features for model 2 trained in each
direction, as well as the intersected predictions, on
each edge. By including the IBM Model 2 features,
the performance of the model described in Taskar et
al. (2005) on our test set (trained on 200 sentences)
improves from 10.0 AER to 8.2 AER, outperforming
unsymmetrized IBM Model 4 (but not intersected
model 4).
As an example of the kinds of errors the baseline
M system makes, see Figure 2 (where multiple fer-
tility cannot be predicted), Figure 3 (where a prefer-
ence for monotonicity cannot be modeled), and Fig-
ure 4 (which shows several multi-fertile cases).
The Fertility Model: Node Features To address
errors like those shown in Figure 2, we increased
the maximum fertility to two using the parameter-
ized fertility model of Section 2.1. The model learns
costs on the second flow arc for each word via fea-
tures not of edges but of single words. The score of
taking a second match for a word w was based on
the following features: a bias feature, the proportion
of times w?s type was aligned to two or more words
by IBM model 2, and the bucketed frequency of the
word type. This model was called M+F. We also in-
cluded a lexicalized feature for words which were
common in our training set: whether w was ever
seen in a multiple fertility alignment (more on this
feature later). This enabled the system to learn that
certain words, such as the English not and French
verbs like aurait commonly participate in multiple
fertility configurations.
Figure 5 show the results using the fertility exten-
sion. Adding fertility lowered AER from 8.5 to 8.1,
though fertility was even more effective in conjunc-
tion with the quadratic features below. The M+F set-
ting was even able to correctly learn some multiple
fertility instances which were not seen in the training
data, such as those shown in Figure 2.
The First-Order Model: Quadratic Features
With or without the fertility model, the model makes
mistakes such as those shown in Figure 3, where
atypical translations of common words are not cho-
sen despite their local support from adjacent edges.
In the quadratic model, we can associate features
with pairs of edges. We began with features which
identify each specific pattern, enabling trends of
monotonicity (or inversion) to be captured. We also
added to each edge pair the fraction of times that
pair?s pattern (monotonic, inverted, one to two) oc-
curred according each version of IBM model 2 (for-
ward, backward, intersected).
Figure 5 shows the results of adding the quadratic
model. M+Q reduces error over M from 8.5 to 6.7
(and fixes the errors shown in Figure 3). When both
the fertility and quadratic extensions were added,
AER dropped further, to 6.2. This final model is
even able to capture the diamond pattern in Figure 4;
the adjacent cycle of alignments is reinforced by the
quadratic features which boost adjacency. The ex-
ample in Figure 4 shows another interesting phe-
nomenon: the multi-fertile alignments for not and
de?pute? are learned even without lexical fertility fea-
tures (Figure 4b), because the Dice coefficients of
those words with their two alignees are both high.
However the surface association of aurait with have
is much higher than with would. If, however, lexi-
cal features are added, would is correctly aligned as
well (Figure 4c), since it is observed in similar pe-
riphrastic constructions in the training set.
We have avoided using expensive-to-compute fea-
tures like IBM model 4 predictions up to this point.
However, if these are available, our model can im-
prove further. By adding model 4 predictions to the
edge features, we get a relative AER reduction of
27%, from 6.5 to 4.5. By also including as features
the posteriors of the model of Liang et al (2006), we
achieve AER of 3.8, and 96.7/95.5 precision/recall.
It is comforting to note that in practice, the burden
of running an integer linear program at test time can
be avoided. We experimented with using just the LP
relaxation and found that on the test set, only about
20% of sentences have fractional solutions and only
0.2% of all edges are fractional. Simple rounding3
of each edge value in the LP solution achieves the
same AER as the integer LP solution, while using
about a third of the computation time on average.
3We slightly bias the system on the recall side by rounding
0.5 up, but this doesn?t yield a noticeable difference in the re-
sults.
118
Model Prec Rec AER
Generative
IBM 2 (E?F) 73.6 87.7 21.7
IBM 2 (F?E) 75.4 87.0 20.6
IBM 2 (intersected) 90.1 80.4 14.3
IBM 4 (E?F) 90.3 92.1 9.0
IBM 4 (F?E) 90.8 91.3 9.0
IBM 4 (intersected) 98.0 88.1 6.5
Discriminative (100 sentences)
Matching (M) 94.1 88.5 8.5
M + Fertility (F) 93.9 89.4 8.1
M + Quadratic (Q) 94.4 91.9 6.7
M + F + Q 94.8 92.5 6.2
M + F + Q + IBM4 96.4 94.4 4.5
Discriminative (200 sentences)
Matching (M) 93.4 89.7 8.2
M + Fertility (F) 93.6 90.1 8.0
M + Quadratic (Q) 95.0 91.1 6.8
M + F + Q 95.2 92.4 6.1
M + F + Q + IBM4 96.0 95.0 4.4
Figure 5: AER on the Hansards task.
5 Conclusion
We have shown that the discriminative approach to
word alignment can be extended to allow flexible
fertility modeling and to capture first-order inter-
actions between alignments of consecutive words.
These extensions significantly enhance the expres-
sive power of the discriminative approach; in partic-
ular, they make it possible to capture phenomena of
monotonicity, local inversion and contiguous fertil-
ity trends?phenomena that are highly informative
for alignment. They do so while remaining compu-
tationally efficient in practice both for prediction and
for parameter estimation.
Our best model achieves a relative AER reduc-
tion of 25% over the basic matching formulation,
beating intersected IBM Model 4 without the use
of any compute-intensive features. Including Model
4 predictions as features, we achieve a further rela-
tive AER reduction of 32% over intersected Model
4 alignments. By also including predictions of an-
other model, we drive AER down to 3.8. We are
currently investigating whether the improvement in
AER results in better translation BLEU score. Al-
lowing higher fertility and optimizing a recall bi-
ased cost function provide a significant increase in
recall relative to the intersected IBM model 4 (from
88.1% to 94.4%), with only a small degradation in
precision. We view this as a particularly promising
aspect of our work, given that phrase-based systems
such as Pharaoh (Koehn et al, 2003) perform better
with higher recall alignments.
References
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and
P. S. Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2):79?85.
M. Collins. 2002. Discriminative training methods for
hidden Markov models: Theory and experiments with
perceptron algorithms. In Proc. EMNLP.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of HLT-NAACL 2003.
P. Liang, B. Taskar, and D. Klein. 2006. Alignment by
agreement. In HLT-NAACL.
R. Mihalcea and T. Pedersen. 2003. An evaluation exer-
cise for word alignment. In Proceedings of the HLT-
NAACL 2003 Workshop, Building and Using parallel
Texts: Data Driven Machine Translation and Beyond,
pages 1?6, Edmonton, Alberta, Canada.
Robert C. Moore. 2005. A discriminative framework for
bilingual word alignment. In Proc. HLT/EMNLP.
F. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?52.
A. Schrijver. 2003. Combinatorial Optimization: Poly-
hedra and Efficiency. Springer.
B. Taskar, S. Lacoste-Julien, and D. Klein. 2005. A dis-
criminative matching approach to word alignment. In
EMNLP.
B. Taskar. 2004. Learning Structured Prediction Mod-
els: A Large Margin Approach. Ph.D. thesis, Stanford
University.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
word alignment in statistical translation. In COLING
16, pages 836?841.
119
