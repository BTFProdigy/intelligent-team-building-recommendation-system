Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 102?107,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Broadcast Audio and Video Bimodal Corpus Exploitation and 
Application 
 
 
Zou Yu, Hou Min, Chen Yudong, Hu Fengguo, Fu Li 
Dept. of Applied Linguistics, Presentation Art School 
Communication University of China 
Beijing 100024, P. R. China 
{zouiy;byhoumin;bychenyudong;bushiwoshishui;red_fuli}@cuc.edu.cn
 
  
 
Abstract 
The main purpose of this paper is the ex-
ploitation and application of an audio and 
video bimodal corpus of the Chinese lan-
guage in broadcasting. It deals with the 
designation of the size and structure of 
speech samples according to radio and 
television program features. Secondly, it 
discusses annotation method of broadcast 
speech with achievements made and sug-
gested future improvements. Finally, it 
presents an attempt to describe the distri-
bution of annotated items in our corpus. 
1 Introduction 
Since the year of 2002, we?ve been engaged in 
setting up the Media Language Corpus aimed to 
provide the language resources for the research-
ers who are interested in broadcasting and televi-
sion media language, for teachers and for re-
searchers of presentation art. Up till now, we 
have established a 50 million word text corpus 
involving 40 million word television program 
text corpora and 10 million word radio program 
text corpora with 10 million annotated word cor-
pora. The work of this paper is to introduce a 
ten-hour segmented and prosodic labeled broad-
cast audio & video bimodal corpus that we built 
just now. 
Section 2 of this paper describes a method for 
selection of radio and television programs to re-
cord according to program features on radio and 
television stations. Recording conditions are pro-
posed to record a quality spoken language corpus. 
Section 3 is dedicated to annotation methods. 
Section 4 shows the distribution of syllables, ini-
tials, finals and tones etc. Finally, section 5 con-
tains the conclusion and outlines of our future 
work in this field. 
2 Corpus Information 
2.1 Corpus metadata 
First of all, we have to select radio and television 
programs to record. Since a broadcast bimodal 
corpus should represent the real life usages of 
spoken language in radio and television, the dif-
ferences between radio and television, the differ-
ences between central and local televisions, and 
the categories of programs should all together be 
taken into account during the process of collect-
ing. The followings are the framework (.wav 
files & .mpeg files matched with .txt files) of 
head information (metadata) of broadcast audio 
& video bimodal corpus that has been collected: 
 
----------------------------------------------------------- 
No.: ... 
Level: central, local, Hong Kong and Taiwan 
Station: CCTV, CNR, Phoenix Television... 
Style: monologue, dialogue, multi-style 
Register: (hypogyny of monologue) presentation,  
explanation, 
reading, talk 
(hypogyny of dialogue) two person talk show, 
three person talk show, 
multi-person talk show 
Content: news, literature, service 
Audiences: woman, children, elder... 
Program: News probe, The first time... 
Sub-program: ... 
Announcer: ... 
Gender: Male /female 
Recording condition: Pinnacle PCTV pro card... 
Sample rate/Resolution: 22 KHz/16bit... 
Topic: ... 
Time: xxxx-xx-xx 
----------------------------------------------------------- 
102
 2.2 Corpus structure 
The purpose of building the broadcast spoken 
language corpus is to provide the service for the 
research of broadcast spoken language, esp. for 
the contrastive studies of the prosodic features of 
different genres of broadcast language. Hence, 
the selections of samples of the corpus mainly 
involve monologues, dialogues or both. As the 
performing forms of radio and television pro-
grams are getting more and more diverse, it is 
very difficult to decide whether a program is a 
monologue or dialogue, because these two gen-
res of programs often co-occur in one program. 
Furthermore, these kinds of programs are in-
creasing their share of radio and television pro-
grams. Consequently, this kind of program is 
most frequent in the corpus. Table 1 displays the 
structural framework of the broadcast audio and 
video bimodal corpus. 
 
Table 1 the structure of broadcast bimodal corpus 
Style Example 
two person talk 
show / interview Face to face...etc. 
three person talk 
show / interview 
Behind the Headlines 
with Wen Tao...etc. Dialogue 
multi-person talk 
show / interview Utterly challenge... 
presentation News...etc. 
explanation Music story... etc. 
reading Reading and enjoy-ing... etc. 
Mono-
logue 
talk Tonight, Weather forecast... etc. 
Multi-style News probe, The first time...etc. 
 
2.3 Recording & management information 
All the recorded data are over the programs on 
radio and TV, that is, it is recorded directly from 
radio and TV programs by Pinnacle PCTV pro 
card to connect cable TV with our recording 
computers. The recorded speech data are saved 
as 22 kHz and 16bit, Windows PCM waveform, 
the video data are saved as MPEG or WMV for-
mat file by Ulead VideoStudio in a post-
processing step. Every program or segment of 
programs is composed of three parts: *.wav 
data, *.txt data, and *.mpeg/.wmv data. 
Zhao Shixia et al(2000) pointed out that the 
structure of a speech corpus consists of synchro-
nized objects (text files, wav files, and annotated 
prosodic files), arranged in deep hierarchies (re-
cording environment), and labeled with speaker-
attribute metadata. Therefore, the managed ob-
jects of our broadcast bimodal corpus are inte-
grated programs or segments of programs. All 
data are stored separately but have complex logi-
cal inter-relations. These inter-relations can be 
obtained through the description of the programs. 
Figure 1 displays the logical structure of the 
broadcast bimodal corpus.  
 
Database 
Describing file 
of program 1
Describing file 
of program 2 
Describing file 
of program n
Audio & 
video data
Text data Labeled data
? 
Figure 1 the logic structure of broadcast audio 
and video bimodal corpus 
3 Annotation 
Why should we annotate a corpus? An annota-
tion is the fundamental act of associating some 
content to a region in a signal. The annotation 
quality and depth have a direct impact on the 
utility and possible applications of the corpus 
(Ding Xinshan 1998). The annotation of our cor-
pus consists of transcription, segmental annota-
tion, and prosodic annotation. 
3.1 Transcription and segmentation 
Transcription is primarily composed of pinyin 
transcription of Chinese characters. Besides, 
tones are annotated ?1?, ?2?, ?3?, and  ?4? after 
the syllable, the neutral tone is labeled ?0?; final 
??? annotated as ?v?, and ??e? annotated as ?ue?, 
for example, ?? (l?)? annotated as ?lv3?, ?? 
(n??)? annotated as ?nue4?. 
In the utterance, compared with broken sylla-
bles, successive speech alters greatly, due to the 
influence of co-articulation, semantics and pros-
ody. The purpose of segmental annotating is to 
annotate the altered phonemes in the syllables 
amidst the utterance. For instances, the voicing 
of some plosives (e.g. b, d, g); labial?s influence 
on alveolar nasal (e.g. ?-n? in ?renmin? affected 
by the initial of ?min? gradually change into 
?labionasal??demonstrating the similarities be-
tween alveolar nasal and labionasal initial in the 
frequency spectrum). In the places of unapparent 
pauses, the stop in the front of plosives esp. af-
103
fricates often vanishes, which are called the in-
existence of silence.  
We transcription and segmentation we used 
BSCA (Broadcasting Speech Corpus Annotator) 
which was designed by ourselves (Hu Fengguo 
and Zou Yu 2005). An annotated example is 
shown in Figure 2: 
 
 
Figure 2 BSCA: a tool for annotation 
3.2 Prosodic annotation tiers 
Prosodic annotation increases the utility of a 
speech corpus. An annotated speech corpus can 
not only offer us a database for the research and 
exploration of speech information but can also 
enlarge our knowledge of speech and prosodic 
features through a visual and scientific method. 
Prosodic annotation is a categorical descrip-
tion for the prosodic features with linguistic 
functions, in other words, annotation of the 
changes of tone, the patterns of stress, and the 
prosodic structure with linguistic functions. The 
prosodic labeling conventions are a set of ma-
chine-readable codes for transforming speech 
prosodies and rule conventions. Based on ToBI   
(Kim Silverman et al 1992, John F. Pitrelli et al 
1994) and C-ToBI Conventions (Li Aijun 2002), 
according to the practical needs of broadcast 
speech language, the prosodic annotation mainly 
involves labeling the following parallel tiers: 
break index, stress index, and intonation con-
struction tier (Chen Yudong 2004, Zou Yu 2004). 
 
3.2.1 Break indices tier 
 
Based on Cao Jianfen?s (1999, 2001) categories 
of prosodic hierarchy structure combined with 
the practical needs of broadcast speech, we iden-
tified five break levels (0-4): 0 indicates the si-
lence or the boundary of default internal sylla-
bles amidst the prosodic words. 1 stands for the 
boundaries of the prosodic words including the 
short breaks with silent pause and breaks with 
filled pause. The prosodic words are the funda-
mental prosodic units in broadcast speech. Sim-
ple prosodic words are composed of 1~3 sylla-
bles. Complex prosodic words normally contain 
5~9 syllables, e.g., ?Shang4hai3 he2zuo4 
zu3zhi1? (i.e. the Shanghai Cooperation Organi-
zation). Break level 2 designates the boundaries 
of the prosodic phrases, most of which are ap-
parent breaks with silent pause, and their patterns 
of pitch have also changed. Break level 3 repre-
sent the boundaries of intonational phrases, or 
the boundaries of sentences. Break level 4 stands 
for the boundaries of intonation groups, similar 
to the boundary of the entire piece of news in a 
news broadcast, or of a talker turn in dialogue. 
At indefinite boundaries, the code ?-? is added 
after the numbers. The labels of the break tier 
occurring times are shown in table 2: 
 
Table 2 the labels of the break tier occurring in 4 
hours annotated corpora 
Break index Occurrence 
1 1512 
2 2998 
3 1986 
4 740 
 
3.2.2 Stress indices tier 
 
Stress is a significant prosodic feature. In train-
ing materials for broadcast announcers, emphasis 
is laid on labeling the stress on the basis of the 
purpose of the utterance, the pattern and rhythm 
of stresses, and the changes of emotions. Zhang 
Song?s (1983) classification of nuclear stresses 
can be the guideline for broadcasting production 
and practice. However, there are some shortcom-
ings in his classifications, for instances, the 
vague hierarchies between the sentences and dis-
courses. This gets in the way of the formal de-
scription of the stresses by the computers. Never-
theless, his theories on the judgment of primary 
and minor stresses (i.e. non-stresses, minor 
stresses, primary stresses etc.) have some refer-
ence value for stress annotations, because distin-
guishing the hierarchies of stress is a crucial 
practical problem for annotation. 
As to the problems with the hierarchies of 
stress, most of the experimental phonetics and 
speech processing researchers adopt Lin Mao-
can?s (2001, 2002) classifications of stress hier-
archies or some similar classifications. That is to 
say, the levels of stress include prosodic word 
stress, prosodic phrase stress, and sentence stress 
(or nuclear stress) in Chinese. According to real 
life broadcasting productions, this paper identi-
104
fies four categories of stresses in broadcast 
speech: the rhythm unit, the cross rhythm unit, 
the clause, and the discourse. Among them, the 
discourse stress often occurs at the place of an 
accented syllable, but they are relatively more 
important than the other sentence stresses. The 
labeling methods of all the ranks are listed as 
follows (Chen Yudong 2004): 
 
Table 3 the stress levels in the stress indices tier 
Ranks Labels 
Rhythm unit 1 
Cross rhythm unit 2 
Clause  3 
Discourse 4 
 
Table 4 the stress levels? mean of duration in 4 
hours annotated corpora 
Stress 
indices 
Mean of dura-
tion. (seconds) Variance
1 .585 .09628
2 .790 .19405
3 .728 .24882
4 .821 .29456
 
Furthermore, Zhang Song's (1983) other crite-
ria for stress annotation (utterance purpose and 
emotion change), while perceptually important, 
are meta-linguistic or para-linguistic in character, 
and will therefore not be addressed in this paper. 
 
3.2.3 Intonation construction tier 
 
In line with Shen Jiong?s view about intonation 
(Shen Jiong 1994), we found that the intonation 
construction tier is an important component of 
the annotation of discourses (Chen Yudong 
2004). It can display the changes of sentence in-
tonation structures. The annotation of the intona-
tion construction is mainly to label the relation-
ship of other syllables to the nuclear stress apart 
from prehead, dissociation etc. For example: 
 
Table 5 the labels of the intonation construction 
tier occurring in 4 hours annotated corpora 
Labels Description Occurrence 
P Prehead 794 
H Head 2980 
N Nucleus 2400 
T Tail 1600 
W Weak in stress 2321 
D Dissociation 527 
Top Topic 269 
Conj Conjunction 87 
 
A sentence can have one nuclear stress, or 
multiple nuclear stresses. 
Single nuclear stress: representing the fore-
and-aft places of the nuclear stress, the steepness 
of nuclear stress, and the length of nuclear stress. 
Examples are listed as follows: 
P-H-N-T;  
P-H-H-N;  
... ... 
Among the above examples, long nuclear 
splitting type ?H-N-T-H-N?-T?, with the features 
of multi-nuclear ?H-N1-T-H-N2-T? is greatly 
similar to multi-nuclear. However, ?H-N-T-H-
N?-T? differs from multi-nuclear in its dependent 
grammar unit.  
Multi-nuclear stress: The two or more nuclear 
stresses in a multi-nuclear sentence take the pat-
terns of like independent sentence intonation 
constructions, each with its own nucleus, pre-
ceded by a head and optional prehead, and fol-
lowed by a tail. In other words, these relatively 
independent patterns already have the features of 
relatively independent intonation constructions, 
with the apparent features of ?prehead, head, and 
nuclear ending?. This kind of nuclear stress often 
occurs in relatively longer and more complex 
constructions. Intonation constructions can be 
labeled separately. A case in point is the contras-
tive sentence ?zai4 wen3 ding4 de0 ji1 chu3 
shang0, qu3 de2 bi3 jiao4 gao1 su4 de0 fa1 
zhan3? (i.e. It got a comparative high-speed de-
velopment on the stable conditions) that can be 
annotated as ?H-N1-T, H-N2-T?. For example: 
 
 
Figure 3 the contrastive sentence ?zai4 wen3 
ding4 de0 ji1 chu3 shang0, qu3 de2 bi3 jiao4 
gao1 su4 de0 fa1 zhan3?(?????????
????????) 
 
3.3 Other items of annotation 
Some spoken language corpus can have some 
additional annotation information. For example, 
turn talking, paralinguistic and non-linguistic 
105
information (e.g. spot, background music, cough-
ing, sobbing and sneezing) and some hosts? ac-
cents (e.g. Shanghai accent) can be annotated in 
talk show corpus. There are 82 times of spot and 
31 times of background music in 4 hours anno-
tated data. Furthermore, some .wav files, .mpeg 
files can be annotated together for discourse 
analysis. 
4 Distribution of annotated items 
We conducted a statistic analysis of some an-
notated items using 4 hours of annotated data in 
our corpus. 
The syllables (initials and finals) of the 20 top 
frequent occurring are given in Table 6. In addi-
tion to this, the duration and variance distribution 
for them are calculation shown as follows. 
 
Table 6 the mean of duration and variance of the 
top 20 frequent occurring syllables 
Syllable Occurrence 
Mean of 
duration. 
(seconds) 
Variance
de0 1993 .1167 .00232 
shi4 912 .2051 .00572 
shi2 626 .2054 .00625 
zai4 602 .1889 .00341 
le0 540 .1325 .00334 
ta1 442 .1765 .00461 
bu4 423 .1492 .00267 
guo2 404 .1673 .00328 
yi4 398 .1656 .00350 
zhong1 395 .1996 .00390 
ren2 394 .1959 .00625 
zhe4 386 .1499 .00317 
you3 380 .1841 .00480 
yi1 357 .1475 .00295 
dao4 335 .1778 .00367 
he2 309 .2078 .00687 
wo3 287 .1704 .00755 
men0 287 .1568 .00426 
yi2 274 .1555 .00320 
jiu4 250 .1724 .00332 
 
Table 7 Distribution of initials (4 hours data) 
Initials Times Initials Times
b 1076 j 3136
p 443 q 1464
m 1636 x 2146
f 972 zh 2953
d 4635 ch 1112
t 1561 sh 3406
n 1085 r 895
l 2569 z 1705
g 2162 c 512
k 879 s 700
h 2071 ? 6099
 
Table 8 Distribution of finals (4 hours data) 
Finals Times Finals Times Finals Times
a 1653 ian 1767 ua 229
ai 1909 iang 919 uai 136
an 1425 iao 773 uan 632
ang 1192 ie 838 uang 389
ao 1205 in 1175 uei 1317
e 5074 ing 1480 uen 368
ei 807 iong 128 ueng 3
en 1515 iou 1144 uo 1760
eng 1237 o 176 v 932
er 353 ong 1658 van 432
i 6856 ou 831 ve 474
ia 586 u 2533 vn 209
 
Table 9 Distribution of tones (4 hours data) 
Tones 1 2 3 4 0 
Occur-
rence 8948 9194 7401 14683 6134
 
The occurrence distribution of initial, final, 
and tone are calculated. These are shown in table 
7, 8 and 9 respectively. 
We also measured the mean duration and F0 
of each tone in three speaking styles are listed in 
Table 10 and 11. 
 
Table 10 Mean duration of tones in various 
speaking styles (seconds)  
 T1 T2 T3 T4 T0 
Presen-
tation .189 .199 .192 .180 .129
Reading .338 .337 .324 .335 .277
Talk .167 .173 .163 .163 .154
 
Table 11 F0 of tones in various speaking styles (Hz) 
 Presentation Reading Talk 
T1 162.78 158.86 207.37
min. of T2 126.39 134.46 168.73
max. of T2 147.27 155.34 180.94
range of T2 79.12 20.88 12.21
min. of T3 101.94 119.12 151.21
max. of T4 163.96 170.07 209.86
min. of T4 113.39 120.98 175.49
range of T4 50.57 49.09 34.37
 
To summarize, we conclude that the mean du-
ration of tones of reading style is longer than that 
of presentation style; that of talk style is the 
shortest among three styles. As for the F0 of each 
106
tone, the F0 and pitch range of presentation style 
is high and has big fluctuation; that of talk style 
is high and has small fluctuation. However, the 
F0 of tone 3 of presentation style is lower than 
that of reading and talk styles. 
5 Further study 
The broadcast audio and video bimodal corpus1 
is a presentation art-oriented corpus with radio 
and television news as its basis. This paper 
probes the development and compilation of 
broadcast audio and video bimodal corpus. 
Firstly, on the collection of the corpus, what 
sort of audio and video corpus can represent the 
features of radio and television speech language? 
How can we auto-annotate the audio and video 
corpus? ...These are the problems that have al-
ways been bothering us. 
Secondly, this corpus can be a platform for 
further research into non-accented or accented 
syllables, intonation construction, the prosodic 
functions of paragraphs and discourses, the emo-
tions of speech, and genre styles. 
Finally, we can statistically analyze the spec-
tral and prosodic characteristics of various speak-
ing styles by the corpora, such as presentation, 
reading and talk. All speaking styles would be 
synthesized based on the analysis results. This is 
also work for the future. 
6 Acknowledgements 
We would like to thank Prof. Wolfgang Teu-
bert for his guidance and comments on this paper. 
I would also like to thank Mr. Daniel Zhang, Jan 
Van der Ven for their kind help. 
References 
Cao Jianfen. 1999. Acoustic-phonetic Characteristics 
of the Rhythm of Standard Chinese, In Proceedings 
of 4th National Conference on Modern Phonetics, 
Beijing, pp.155~159. 
Cao Jianfen. 2001. Phonetic and Linguistic Cues in 
Chinese Prosodic Segmentation and Grouping, In 
Proceedings of 5th National Conference on Mod-
ern Phonetics, Beijing, pp.176~179. 
Chen Yudong. 2004. The Utterance Construction and 
Adjustment in Media Spoken Language, PhD thesis, 
Peking University. 
                                                 
1 This research was supported by the National Working 
Committee on Language and Characters, project no. 
YB105-61A and Communication University of China, pro-
ject no. BBU211-15. 
Ding Xinshan.1998. Development and Research of 
Corpus Linguistics, Contemporary Linguistics, 1: 
4~12. 
Hu Fengguo, Zou Yu. 2005. The Design and Exploi-
tation of Broadcasting Speech Corpus System, 
In  Proceedings of the Eighth Joint Seminar of 
Computational Linguistics (JSCL-2005), Nanjing, 
China, pp.521~527. 
John F. Pitrelli, Mary E. Beckman, and Julia 
Hirschberg. 1994. Evaluation of Prosodic Tran-
scription Labeling reliability in the ToBI Frame-
work, In Proceedings of the 1994 International 
Conference on Spoken Language Process-
ing(ICSLP), Yokohama, Japan, pp.123-126. 
Kim Silverman, Mary Beckman, John Pitrelli, Mari 
Ostendorf, Colin Wightman, Patti Price, Janet Pier-
rehumbert, and Julia Hirschberg. 1992. ToBI: A 
Standard for Labeling English Prosody, In Pro-
ceedings of the 1992 International Conference on 
Spoken Language Processing(ICSLP), Banff, Al-
berta, Canada, vol.2, pp.867-870. 
Li Aijun. 2002. Chinese Prosody and Prosodic Label-
ing of Spontaneous Speech, In Speech Prosody 
2002 An International Conference, Aix-en-
Provence, France. 
Lin Maocan. 2001. Prosodic Structure and F0 Decli-
nation in Sentence of Standard Chinese, In Pro-
ceedings of 5th National Conference on Modern 
Phonetics, Beijing, pp.180~184. 
Lin Maocan. 2002. Prosodic Structure and Construc-
tion of F0 Top-Line and Bottom-Line in Utterances 
of Standard Chinese, Contemporary Linguistics, 4: 
254~265. 
Shen Jiong. 1994. Chinese Intonation structure and 
category, Dialect, 4: 221~228. 
Zhang Song. 1983. Recitation, Changsha: Hunan Edu-
cation Press. 
Zhao Shixia, Cai Lianhong, Chang Xiaolei. 2000. 
Construction of Mandarin Corpus for Chinese 
Speech Synthesis, Mini-Micro System, Vol.21 (3): 
295~297. 
Zou Yu. 2004. Primary Research on Prosodic Label-
ing in Chinese News Broadcasting Speech, In Pro-
ceedings of the 2nd Student Workshop on Compu-
tational Linguistics (SWCL2004), Beijing, pp.1-7. 
107
Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 38?45,
Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLP
Chinese-Uyghur Sentence Alignment:  An Approach Based on Anchor Sentences 
 Samat Mamitimin Xinjiang University Urumqi 830046, China  Communication University of China/ Beijing 100024, China 
tilchin@hotmail.com 
Min Hou Communication University of China Beijing 100024, China  
houminxx@263.net 
   
 
Abstract 
This paper, which builds on previous studies on sentence alignment, introduces a sentence alignment method in which some sentences are used as ?anchors? and a two step proce-dure is applied. In the first step, some lexical information such as proper names, technical terms, numbers and punctuation marks, loca-tion information and length information are used to generate anchor sentences that satisfy some conditions. In the second step, texts are divided into several segments by using the anchor sentences as boundaries, and then the sentences in each segment are aligned by us-ing a length-based approach. By applying this segmentation technique, the method avoids complex computation and error spreading. Experimental results show that the precision of the method is 94.6% on the average for Chinese-Uyghur sentence alignment for multi-domain texts. 
1 Introduction 
Parallel corpora are very useful for both theory-oriented linguistic research and application-oriented cross-language information processing. For parallel corpora, the most important annota-tion is alignment, especially sentence alignment, which is a minimal and essential requirement for the annotation of a parallel corpus. Aligning Chi-nese-Uyghur parallel texts at the sentence level, however, is already very difficult because of the considerable differences in the syntactic struc-tures and writing systems of the two languages.  A number of alignment techniques have been proposed for other language pairs, varying from statistical methods to lexical methods. There are basically three kinds of approaches on sentence alignment: the length-based approach (Gale and 
Church, 1991), the lexical approach (Kay and R?scheisen, 1993), and the combination of the two (Chen, 1993 and Wu, 1994).  The first approach is based on modeling the relationship between the lengths of sentences that are mutual translations. Similar algorithms based on this idea were developed independently by Brown, et al(1991) and Gale and Church (1993). However, their main targets are rigid translations that are almost literal translations. The method is applicable for structurally similar European lan-guages (i.e. English-French or English-German).  One alternative alignment method is the lexi-con based approach that uses lexical information to obtain higher accuracy. Kay and R?scheisen (1993) proposed a relaxation method to sentence alignment using the word correspondences ac-quired during the alignment process. Chen (1993) developed a method based on optimizing word translation probabilities which he showed gave better accuracy than the sentence-length based approach. Wu (1994) used a version of Gale and Church?s method adapted to Chinese along with lexical cues in the form of a small corpus-specific bilingual lexicon to improve alignment accuracy in text regions containing multiple sentences of similar length. Melamed (1996) also developed a method based on word correspondences, for which he reported sentence-alignment accuracy slightly better than Gale and Church. The method does not capture enough word correspondences for structurally different languages such as Chinese and Uyghur, mainly for the following two reasons. One is the differ-ence in the character types of the two languages. Chinese uses Chinese characters as its writing system while Uyghur uses alphabetic character. The other is the grammatical difference of the two languages. Chinese is an analytic language that has SVO word order. In contrast, Uyghur is 
38
a suffixing and agglutinative language that has SOV word order. Thus, it is impossible in gen-eral to apply the simple-feature based methods to Chinese-Uyghur sentence alignment.  This paper, on the basis of other sentence alignment methods, introduces an anchor sen-tence based sentence alignment method, in which some sentences are used as ?anchors? and two steps are applied. In the first step, some lexical information such as proper names, technical terms, numbers and punctuation marks, location information and length information are used to generate anchor sentences that satisfy some con-ditions. In the second step, texts are divided into several segments by using anchor sentences as boundaries, and then the sentences in each seg-ment are aligned by using a length-based ap-proach.  
2 The Chinese-Uyghur Parallel Corpus 
Uyghur is a Turkic language spoken by Uyghur people in Xinjiang Uyghur Autonomous Region of China and adjoining areas, which has about 9 million speakers. As one of the official languages in Xinjiang, Uyghur is widely used in many fields such as education, communication, public-ation, etc. Bilingualism in Xinjiang requires translation from Chinese to Uyghur or in the opposite direction. Therefore, it is possible and essential to build a Chinese-Uyghur parallel corpus for teaching and research in translation, bilingual lexicography, linguistics, and other NLP applications. Consequently, we began to build a Chinese-Uyghur parallel corpus for lin-guistic research, translation studies, teaching and applications such as machine translation. The corpus is a sentence aligned general corpus of medium size.  So far, over 1 million characters of Chinese texts, in total 263 texts, and their corresponding Uyghur texts have been collected from several sources and included into the raw corpus after sampling. The corpus texts cover a variety of styles, such as fiction, scientific texts, govern-ment documents, law texts, daily conversation and other texts. Presently, the size of the corpus is smaller than we expected because it is not easy to obtain such digital text data which also needs to be processed before it can be included in the corpus. The main sources of text data are pub-lished books, news papers, magazines and some web pages. The proportions of the different gen-res in the corpus are shown in Figure 1.   
Other, 3%
Scientifice,26%
Conversation,7%
Fiction, 26%
Law, 24%
Government,13%   Figure 1. Genres and their percentages counted in tokens 
3 System Overview  
There is no previous work or approach specific to Chinese-Uyghur sentence alignment. So we firstly examined many papers related to the sub-ject to find an appropriae  method for Chinese-Uyghur sentence alignment. Most approaches share many common properties in the methods they use and suggest only small modifications to the earlier approaches. The length based method is suitable for aligning a very large bilingual cor-pus. Since it does not use any lexical information for the alignment task, it can be used between any pair of languages. However, in distant lan-guages where characters differ, it is not so effi-cient. One alternative alignment method is the lexicon based approach that uses lexical informa-tion offering the potential for higher accuracy. However, it is not easy to capture enough word correspondences or cognates for Chinese and Uyghur. We may use bilingual dictionaries as an external resource to retrieve all possible word translations in such sentence alignment tasks. However, this is time-consuming and rather complex because word segmentation and lemma-tization have to be done before the process of word matching can be started. Secondly, we tried some tentative methods to Chinese-Uyghur sen-tence alignment. According to the preliminary examination, it is generally not possible to apply the simple-feature based methods to Chinese-Uyghur sentence alignment.  Finally, we decided to apply a mixed approach to obtain better and more efficient results by combining the three criteria: length, lexical in-formation and location information. Below are the detailed descriptions of this approach.  
39
Our algorithm combines techniques adapted from previous work on sentence and word align-ment. Our method is similar to Wu?s (1994) in that it uses both sentence length and lexical in-formation. But in our method, some lexical cor-respondences are used to find anchor sentences. Our method is similar to Simard?s (1992) in that it uses cognates or anchors for sentence align-ment. But in our method length information and anchors are used at different stages of sentence alignment. Our method is similar to Melamed?s (1999) in that it uses a bitext mapping technique to locate anchor points, but it uses sentences as anchor points instead of words or characters. A segmentation technique that splits the text into several sections is also introduced to improve the length-based approach. As we can see from Fig-ure 2, a two-step approach is applied to Chinese-Uyghur sentence alignment.   
paral l elt ext
Generat i onCor rect i onRecogni t i on
segment at i onSent enceal i gnment  i n eachsect i on
Al i gnmet nresul t Lastsect i on?
TF
Key Lexi con
Anchor  sent enceext ract i on
 Figure 2: Flowchart of Chinese-Uyghur sentence alignment  In the first step, some (1:1) sentence pairs, called anchor sentences, are extracted by using lexical information, location and length information. A three-phase method is applied to anchor sentence extraction which will be explained in the follow-ing section.  In the second step, texts are divided into sev-eral segments by using these sentences as an-chors, and then all sentences in each segment are aligned by using a length-based approach.  
4 Anchor Sentence Extraction Algo-rithm 
4.1 Anchor Sentence 
Brown (1991) firstly introduced the concept of alignment anchors when he aligned the Hansard corpus. In our method, we also introduced this concept, which in our case are anchor sentences. In a parallel corpus, the anchor sentences are specific (1:1) sentence pairs that are strongly re-lated and that satisfy some conditions. All such 
sentence pairs which were extracted from bilin-gual texts during the first step are seen as anchor sentences. These anchors divide the whole texts into short aligned segment. The goal of anchor sentence extraction is to divide the source text and the target text into one-to-one smaller seg-ments. And using this segmentation, we attempt to improve the sentence alignments produced by the length based alignment. Sentence alignment tends to be better with shorter segments and, consequently, better sentence alignments are ob-tained. For anchor sentence extraction, we applied a bitext mapping technique. A bitext map is a set of pairs (x, y), where x and y refer to precise lo-cations in the first and second texts respectively, with the intention of denoting portions of the texts that correspond to one another (Simard, 1998). However, we used a bitext map of sen-tence pairs instead of words or characters to point out the correspondences between these an-chor sentences (See Figure 3).   
0
10
20
30
40
50
60
70
80
90
100
110
0 10 20 30 40 50 60 70 80 90 100Uyghur Sentence Number
Chi
nese
 Sen
tenc
e N
umb
er
main diagonalanchor points
 Figure 3. Bitext map of sentence alignments  The horizontal axis denotes the sentence number in the Uyghur text, and the vertical axis denotes the sentence number in the Chinese text. The anchor sentences, which are shown as anchor points in the bitext map, can be characterized by three properties: Injectivity: no two anchor points in a bitext map can have the same x or y coordinates. Linearity: anchor points tend to line up straight. In other words, all anchor points are to appear around a straight line. 
40
Low variance of slope: The slope of the anchor points is rarely much different from the bitext slope. 
4.2 Algorithm Description 
In our anchor sentence extraction algorithm, a three-step process is applied to extract anchor sentences. In other words, the search for each anchor sentence pairs alternates between the fol-lowing three steps: generation phase, correction phase and recognition phase.  
? Generation phase 
In the generation phase, the algorithm generates candidate anchor sentence points within a search rectangle. We define a search rectangle as fol-lows: Rectangle(x, y, x+3, y+3) in which x=last anchor point(x) and y=last anchor point(y). The first search rectangle is anchored at the origin of the bitext map where x=0, y=0. Subse-quent search rectangles are anchored at the pre-viously found points.  In this step, the search for an anchor sentence begins in a small search rectangle in the bitext map, whose diagonal is parallel to the main di-agonal. If no candidate points are found, the search rectangle is proportionally expanded by the minimum possible amount, and the genera-tion cycle is repeated. The rectangle keeps ex-panding until at least one acceptable point is found. Three kinds of information such as sen-tence length, location information and lexical information are used to generate anchor points. Sentence pairs that satisfy the following three conditions are added to the candidate anchor sen-tence array.  (1) Sentence length ratio As was shown in the sentence alignment litera-ture (Church, 1993), the sentence length ratio is also a very good indication of the alignment of a sentence pair.  In our method, for sentence pair P(c,u), if Len-Ratio(c,u)?[MinLenRatio, MaxLenRatio], sen-tence pair P(c,u) would be candidate anchor sen-tences, in which LenRatio(c,u)= Lc/Lu (Lu is Uy-ghur sentence length, Lc is Chinese sentence length).  MinLenRatio and MaxLenRatio are calculated by using following formula:  MaxLenRatio=C?+A/( Lc+B) MinLenRatio= C?-A (Lc+B) C?=(C+ Len(C)/Len(U))/2  The constant C is the expected number of Chi-nese characters per Uyghur word. C? is the 
weighted value when taking text size into ac-count, the values of the constants are A=10?B=14.  (2) Matching score If the matching score of a sentence pair is above the threshold (we set the threshold = 1.1), it is considered a candidate anchor sentence. By ap-plying this condition, we reject some sentence pairs with a matching score smaller than the threshold. The matching score is calculated ac-cording to the matching degree of the key lexi-con and punctuations as described in section 4.3. (3) Maximum Angle Deviation (MAD)  According to the properties of the anchor sen-tences, the slope of the anchor points should not be much different from the bitext slope. So some sentence pairs are rejected by setting a maximum angle deviation. The angle of each anchor point?s least-squares line is compared to the arc tangent of the bitext slope. The anchor point is rejected if the difference exceeds the maximum angle de-viation threshold (MAD=3). The angle between the least-squares line and the bitext slope is cal-culated according to the following formula: 
 In this formula, A is the slope of the least-squares line, B is the bitext map slope. This filtering process generates anchor sen-tences with higher accuracy; however, it causes errors in some cases. So, we introduced another correction phase in order to reject some wrongly aligned sentence pairs.   
? Correction phase 
In this step, some candidate sentences that are no anchor sentences are eliminated according to characteristics of anchor sentences, namely the length ratios of corresponding segments. First, the algorithm checks if there are any conflicts between anchor points. The injective property of anchor sentences implies that when-ever two anchor points overlap in the x or y axis, but are not identical in the region of overlap, then one of the points must be wrong. To resolve such conflicts, we employed a lookup method to eliminate conflicting points.  Secondly, length ratios of corresponding seg-ments divided by candidate anchor sentences are calculated according to a similar formula as used for the sentence length ratio in order to reject wrongly aligned anchor points.  If the length ratio of the segments LenRa-tio(c,u)?[MinLenRatio, MaxLenRatio], the 
41
candidate anchor sentence must be an anchor sentence, otherwise it should be eliminated. MinLenRatio and MaxLenRatio are calculated by using the following formulae: MaxLenRatio=C?+A/( Lc+B) MinLenRatio= C?-A (Lc+B)  
? Recognition phase  
A number of candidate anchor sentences can be obtained in a certain search region during appli-cation of the above two steps. For anchor sen-tence alignment, accuracy is more important than recall rate. So it is essential to introduce a recog-nition step in order to achieve higher accuracy by eliminating some unlikely anchor sentences. In the recognition step, one best anchor sentence pair is selected from candidate anchor sentences according to two parameters: matching score and length similarity score. The anchor selection al-gorithm gives a score to each proposed sentence pair during the recognition phase, and finds the alignment with the largest sum of scores. A pa-rameter estimation method is described in the following section. 
4.3 Parameter Estimation 
Matching score: As previous work suggests, lexical information is critical for sentence align-ment, especially for finding anchor points. It is well-known that some proper names and techni-cal terms have rigid translations in many lan-guages; numbers and punctuations appear in the same or similar forms in both source text and translation text. In a parallel text, for instance, if a sentence contains a question mark, it is likely to be aligned to a sentence that also contains this mark, which can be a strong clue for sentence alignment. This is also true for Chinese-Uyghur translations. However, in our method, lexical and non-lexical clues are not used to align all sentences, but to estimate matching scores and to find the best anchor sentences. We used multiple clues such as proper names, technical terms, punctua-tion marks and numbers.  In most cases, proper names, including person names, location names, organization names, and technical terms have unique translations that will be matched easily. But, the problem is that per-son names and technical terms are often un-known words. How to identify them is a difficult problem. In our case, we first collected some popular proper names and the most frequent technical terms into a small lexicon that we call 
the key lexicon. More than 2000 words are in-cluded in the key lexicon at present. Then, a very simple searching method is applied to match cor-responding words.  In addition, punctuation marks, including other symbols (e.g. @#$%&), are the most obvi-ous clues in Chinese and Uyghur translation. The correlation between Chinese and Uyghur punc-tuations is extremely high as depicted in Table1.   Punctuation Chinese  Uyghur full stop ? . question mark ? ? exclamation mark ? ! comma ? ? ideographic comma ? ? semicolon ? ? colon ? : quotation mark ?? ?? ?? ?? ?? bracket ??[] () [] Title mark ?? ??  Table 1. Corresponding punctuation marks in Chinese and Uyghur  For punctuation and numbers, no external re-sources but some rules are applied to estimate the matching degree of these clues.  The matching scores are calculated according to the average number of matched clues. In other words, the more matched proper names, techni-cal terms, punctuation and numbers, the higher the matching score.  Length Similarity: Length similarity is a score that reflects the similarity between the length ratio of the current sentence pair and the ex-pected length ratio. The following formula will be applied to calculate the length similarity of a proposed sentence pair (AiC, AiU): LenSimilar(AiC, AiU )=|Len(AiC)/Len(AiU)-C|/C Hereby C is expected number of Chinese charac-ter per Uyghur words. We obtain C=2.01 ex-perimentally. Len(AiC) and Len(AiU) are the sentence lengths of AiC, AiU, respectively. However, the sentence length ratio is not sta-ble when a Chinese sentence is shorter than 10 characters. So it is necessary to add a weighting factor WF:  LenSimilar(AiC, AiU )=|Len(AiC)/Len(AiU)-C|/C *WF if Len(AiC)<= StableLen, then  WF =a*Len(AiC)/StableLen, else WF =1. Hereby StableLen=10, a=0.5 
42
The length similarity formula is also adjusted as follows: LenSimilar(AiC,AiU)=|Len(AiC)/Len(AiU)-C?|/C?* WF Hereby C? is the value weighted by the whole text size. 
5 Length Based Sentence Alignment  
According to previous work by Gale and Church, length-based approaches are simple and can achieve good performance for different language pairs. Because of this simplicity, many later re-searchers integrated this method to their sentence alignment methods. We also applied the length-based approach to the second step of sentence alignment.  
5.1 Measuring Length in Words and Charac-ters 
Different length measuring methods can be used in the length-based approach. Brown (1991) in-troduced the length-based algorithm based on the number of words in sentences, Gail and Church?s algorithm is similar to the Brown?s algorithm except that alignment is based on the number of characters in the sentences. Uyghur is an alphabetic language while Chi-nese is a non-alphabetic language. Therefore, it is a difficult problem to select the best length measuring model. In general, a Chinese sentence does not have word boundary information; so one way to define Chinese sentence length is to count the number of characters in a sentence. Another way is to count how many words are in a sentence after word segmentation. For Uyghur sentences, we can similarly define the length in characters or in words.  In our case, we examined three possible length models described in the following Table 2:   L-1 Both Uyghur and Chinese sentences are measured in characters L-2 Both Uyghur and Chinese sentences are measured in words1 L-3 An Uyghur sentence is measured in words and a Chinese sentence is meas-ured in characters Table 2. Three length models   The mean sentence length ratios, variances and correlation coefficients for each of the length models are calculated from hand aligned Chi-
                                                 1 Bbibst software is used for Chinese word segmentation. 
nese-Uyghur texts of 988 sentence pairs. Statis-tics of the three sentence length models are shown in Table 3.  L-1 L-2 L-3 Mean 3.99 1.07 2.01 Var 0.71 0.23  0.21 Correl 0.976 0.953 0.977 Table 3. Statistics of different length measuring methods  In general, the smaller the variance, the better the sentence length model should be. From Table 3, we can see that the character based length ratio model has significantly larger variance (0.71) than the other two models (L-2:0.23, L-3: 0.21). This means L-1 is not as reliable as L-2 and L-3. Both L-2 and L-3 have similar variance, but L-3 is better than L-2 with regard to the correlation coefficient, which indicates that sentence lengths have higher correlation if the lengths of Chinese and Uyghur texts are measured in characters and words, respectively. A regression analysis of the three models also proved this result. So we ap-plied the L-3 model to the length ratio examina-tion and length based sentence alignment. 
5.2 Preliminary Statistics for the Length-based Method 
A length-based sentence alignment program is based on a very simple statistical model of sen-tence lengths. The model makes use of the fact that longer sentences in one language tend to be translated into longer sentences in the other lan-guage, and that shorter sentences tend to be translated into shorter sentences. A probabilistic score is assigned to each pair of proposed sen-tence pairs, based on the ratio of lengths of the two sentences and the variance of this ratio. This probabilistic score is used in a dynamic pro-gramming framework in order to find the maxi-mum likelihood alignment of sentences.  The parameters C and S2 are used for likeli-hood estimation. C is the expected number of Chinese characters per Uyghur words. The pa-rameters C and S2 are determined empirically from a hand aligned parallel corpus of multi-domain texts. According to our statistical results, we obtained C=2.01 and S2 =3.24.  Brown (1991) assume that every parallel cor-pus can be aligned in terms of a sequence of minimal alignment segments, which they call ?beads?, in which sentences align 1-to-1, 1-to-2, 2-to-1, 2-to-2, 1-to-0, or 0-to-1. The alignment model is a generative probabilistic model for 
43
predicting the lengths of the sentences compos-ing sequences of such beads. The model assumes that each bead in the sequence is generated ac-cording to a fixed probability distribution over bead types. We also calculated the probability of different alignment types.   Type Frequency Percentage?%? 1:1 807 81.3 1:0 or 0:1 5 0.5 1:2 or 2:1 152 15.3 2:2 7 0.7 1:3 or 3:1 20 2.0 other 2 0.2 Total 993 100 Table 4. Proportion of alignment types  From the above statistical results, it is clear that the correlation between the length of a Chinese sentence in characters and the length of its Uy-ghur translation sentence in words is extremely high. This high correlation suggests that length might be a strong clue for sentence alignment.  In our cases, we applied the length-based ap-proach suggested by Gale and Church after some parameters had been changed. 
6 Experimental Results 
In this section, we report the results of experi-ments on aligning sentences by using two meth-ods. 
6.1 Test Corpus 
In our experiment, we selected ten texts as our testing corpus. The texts are varied in length and genres as summarized in Table 2. T1, T2 and T3 are fiction texts; T4 is a law text; T5 and T6 are official documents; T7 and T8 are scientific texts, T9 and T10 are news and other articles. The total size of the corpus is 72,000 tokens, about 1300 sentence pairs.  
6.2 Results 
Firstly, we aligned sentences by using two ap-proaches: a length-based algorithm, and an an-chor sentence based algorithm. Then we manu-ally checked the alignment results for errors and calculated precision and recall scores. Experi-mental results show that our anchor sentence based approach yields higher accuracy than the purely length based approach. The precision of the method is 94.6% on the average for Chinese-Uyghur sentence alignment on multi-domain 
texts. This is 2% higher than that of a purely length based approach.  
 length-based anchor sentence based  Precision recall precision recall T1 89.9 89.3 94.2 93.6 T2 94.9 94.9 97.5 97.5 T3 83.1 84.5 86.4 87.9 T4 100 100 100 100 T5 100 100 100 100 T6 98.8 98.8 100 100 T7 98.5 98.9 98.5 98.9 T8 65 66.7 72.5 74.4 T9 89.1 86.0 96.4 93.0 T10 96.8 95.8 94.7 93.8 average 92.7 92.8 94.6 94.8 Table 5. Experimental results  As we can see from Table 5, the error rates of the two methods vary from text to text. We analyzed all errors during sentence alignment in order to find reasons and solutions. The following is an error analysis. 
6.3 Error Analysis 
Firstly, the style of a text affects the sentence alignment results. In law texts and official docu-ments, precision is very high in comparison with the results in texts of other styles; even 100% accuracy has been achieved. The reason for this may be the language style of source texts and translated texts. The error rate is comparatively higher in fiction texts because of their free trans-lation style. Secondly, complex sentence beads that in-clude deletion and insertion during translation affect the alignment accuracy. According to Ta-ble 7, complex alignment types that the current alignment algorithm did not take into considera-tion account for 2.2% of the errors in Chinese-Uyghur translations. So errors caused by these "unorthodox" translation patterns are unavoid-able. There are many such errors in sample T8. By examination, we found that the number of sentences in the Chinese text (122 sentences) and corresponding Uyghur text (179 sentences) is so unbalanced that many complex alignment types are involved. This is a direct reason for the high error rate.  Finally, anchor sentences play an important role during alignment. However, we found that it leads to more mistakes once wrong anchor sen-tence are selected. For instance, in T9, just one wrong anchor sentence caused up to four errors 
44
during second-step sentence alignment. So it is crucial to align anchor sentences correctly.  
7 Conclusions 
We have developed a very effective sentence alignment method based on anchor sentences. In our method, firstly anchor sentences are ex-tracted from bilingual texts according to key lexical information, location information and length information; secondly, whole texts are divided into small segments by using anchor sen-tence points; finally, sentences in each small segment are aligned by using a length-based ap-proach. We have implemented the proposed method on the parallel Chinese-Uyghur corpus. Experimental results show that the precision rate of the method is 2% higher than that of a purely length-base approach. Differences and advan-tages of our anchor sentence based method are compared to other methods in Table 6.  
Methods Length based Lexical based Our method Advantages Length in-formation Yes No Yes Quick Lexical information No Yes Yes Higher ac-curacy Language resource No Dictionary Simple lexicon Simple Special character No No Yes Higher ac-curacy 
Multi level No No Yes Avoids er-ror spread-ing 
For multi- domain Good Not good Good 
Applicable to different  texts Table 6. Differences of three alignment methods  
References  
Brown, Peter, J. Lai and R. Mercer. 1991. Aligning Sentences in Parallel Corpora. in Proceedings of ACL-91, 169-176. 
Brown, P.F., Della Pietra, S. A., Della Pietra, V. J., Mercer, R.L. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Com-putational Linguistics, 19(2): 263?311. 
Chen, S.F. 1993. Aligning Sentences in Bilingual Corpora Using Lexical Information. In Proceed-ings of ACL-91.  
Chuang, Thomas and Kevin C. Yeh. 2005. Aligning Parallel Bilingual Corpora Statistically with Punc-
tuation Criteria. International Journal of Com-putational Linguistics and Chinese Language Processing , Vol. 10, No. 1. 
Gale, William A. and Kenneth W.Church. 1991. A Program for Aligning Sentences in Bilingual Cor-pora . Proceedings of ACL-91, 177-184. 
Fung, Pascale and Kenneth W. Church. 1994. K-vec: A new approach for aligning parallel texts. In Proceedings of the 5th International Confer-ence on Computational Linguistics, 1096-1102, Kyoto, Japan. 
Kay, M., R?scheisen, M. 1993. Text-Translation Alignment. Computational Linguistics, 19(1): 121-142. 
Melamed, I. D., Bitext Maps and Alignment via Pat-tern Recognition, Computational Linguistics, 25(1), 107-130, March, 1999. 
Melamed, I.D. 1996. A Geometric Approach to Map-ping Bitext Correspondence. IRCS Technical Re-port, 96-22, University of Pennsylvania. 
Melamed, I.D. 1997. A Portable Algorithm for Map-ping Bitext Correspondence. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, Madrid, Spain, 305-312. 
Moore, R. C. (2002). Fast and Accurate Sentence Alignment of Bilingual Corpora. In Machine Translation: From Research to Real Users (Proceedings, 5th Conference of the Association for Machine Translation in the Americas, Tiburon, California), Springer-Verlag, Heidelberg, Germany, 135-244 
Simard, M., Foster, G., and Isabelle, P. 1992. Using Cognates to Align Sentences in Bilingual Corpora. Fourth International Conference on Theoreti-cal and Methodological Issues in Machine Translation (TMI-92), Montreal, Canada. 
Simard, M., Plamondon, P.1998. Bilingual Sentence Alignment: Balancing Robustness and Accuracy. Machine Translation, 13(1), 59?80. 
Weigang Li, Ting Liu, Zhen Wang and Sheng Li. 1994. Aligning Bilingual Corpora Using Sentences Location Information, Proceedings of 3rd ACL SIGHAN Workshop, 141-147. 
Wu, D. 1994. Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria. In Pro-ceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, New Mexico, 80-87. 
45
Using Topic Sentiment Sentences to Recognize Sentiment      
Polarity in Chinese Reviews
Jiang Yang
School of Literature
Communication University of China
yangjiang@cuc.edu.cn
Min Hou
Broadcast Media Language Branch
Communication University of China
houminxx@263.net
Abstract
An approach to recognizing sentiment 
polarity in Chinese reviews based on 
topic sentiment sentences is presented.
Considering the features of Chinese re-
views, we firstly identify the topic of a 
review using an n-gram matching ap-
proach. To extract candidate topic senti-
ment sentences, we compute the seman-
tic similarity between a given sentence 
and the ascertained topic and meanwhile 
determine whether the sentence is sub-
jective. A certain number of these sen-
tences are then selected as representa-
tives according to their semantic simi-
larity value with relation to the topic. 
The average value of the representative 
topic sentiment sentences is calculated 
and taken as the sentiment polarity of a 
review. Experiment results show that the 
proposed method is feasible and can 
achieve relatively high precision.
1 Introduction
Sentiment analysis, also known as ?opinion min-
ing?, is the problem of analyzing the sentiment, 
opinion or any other subjectivity of written texts. 
With its potential applications to opinion search 
engine, public opinion analysis, product promo-
tion, etc., sentiment analysis has been receiving 
increasing interest in recent years.
What sentiment analysis processes are texts 
with subjectivity which mainly describe the 
writers? (or on behalf of a group or an organiza-
tion) private thoughts, attitudes or opinions on 
phenomena, persons, affairs and so on. Although 
various kinds of writings such as narration and 
exposition are possible to contain subjectivity, 
argumentation is the focus of sentiment analysis 
on which researchers put much strength at 
present. As a kind of argumentation and a typi-
cal and common subjective text, a review com-
ments on some specific phenomenon, person or 
affair. Reviews, especially news reviews, have a 
certain degree of influence on public opinion in 
virtue of mass media. Domain-specific reviews 
like automobile, hotel, movie reviews have po-
tential commercial value respectively. Therefore, 
recognizing sentiment polarity (SP thereafter) in 
reviews becomes necessary and practical.
Language is a hierarchical symbol system, 
which allows sentiment analysis to be conducted 
on different language levels. In general, most 
current studies concerning sentiment analysis are 
about determining the SP of words, phrases or 
sentences. Only a fraction of them addressed 
discourse level sentiment analysis. This paper, 
aiming at recognizing the overall SP of Chinese 
reviews, proposes a topic-sentiment-sentence 
based approach to carry out a discourse level 
sentiment analysis.
The remainder of this paper is organized as 
follows. Related works are presented in section 2. 
Section 3 is problem analysis and method de-
scription. Section 4 describes topic identification 
and topic sentiment sentence extraction. Section 
5 is about recognizing SP in Chinese reviews 
using the extracted topic sentiment sentences. 
Section 6 is the experiment results and section 7 
is the conclusion.
2 Related Works
The SP determination can be generally 
conducted on three language levels: the word 
level, the sentence level and the discourse level. 
The two main popular approaches, especially in 
real-world applications, have been based on 
machine learning techniques and based on 
semantic analysis techniques. Research aiming 
at recognizing the overall SP of discourse is 
represented by Turney (2002), Pang et al (2002) 
and Yi et al (2003). Turney proposed an 
unsupervised learning algorithm to classify the 
sentiment orientation of reviews. The mutual 
information difference between the given word 
or phrase and the words ?poor? and ?excellent? 
was calculated respectively to measure its 
semantic orientation; then the average semantic 
orientation of all the words in a given text was 
regarded as the overall semantic orientation. 
Pang et al employed such classification models 
as Na?ve Bayesian model, Maximum Entropy 
model and Support Vector Machine model to 
classify the semantic orientation of movie 
reviews, in which the features of models selected 
included unigrams, bigrams, parts of speech, 
word position, feature frequency and feature 
presence. Yi et al firstly analyzed the 
grammatical structure of sentences using NLP 
techniques. The semantic orientation of a 
sentence then is determined by referring to a 
sentiment lexicon and a sentiment pattern 
database. They applied the approach to 
classifying the overall SP of document.
Other related works are concerning the senti-
ment analysis of sentences and words which un-
derlie recognizing the overall SP of a whole text. 
Wiebe et al (2000, 2004) proved that the subjec-
tivity of a sentence could be judged according to 
the adjectives in it. Kim & Hovy (2004) and 
Weibe & Riloff (2005) explored the classifica-
tion of subjective and objective sentences. Yu et 
al. (2003) put forward an approach to extract 
opinionated sentences in order to serve an auto-
matic question answering system. The extracted 
sentences were classified and the SP of each was 
determined. Hu & Liu (2004) took advantage of 
WordNet to obtain sentiment words and their 
orientations. The polarity of a sentence thus is 
judged according to the dominant semantic 
orientation of sentiment words.
For Chinese, Wang et al (2005) proposed a 
hybrid approach to recognize the semantic orien-
tations of sentences in reviews based on heuris-
tic rules and Bayesian classification technique. 
Wang et al (2007) applied a Multi-redundant-
labeled CRFs method on sentence sentiment 
analysis. Experiments showed it solved ordinal 
regression problems effectively and obtained 
global optimal result over multiple cascaded 
subtasks. Meng et al (2008) designed a recogni-
tion system of text valence based on key word 
template in which they proposed template 
matching arithmetic and text valence value 
arithmetic for the calculation of the valence of 
Chinese texts. Zheng et al (2009) conducted a 
research on sentiment analysis to Chinese travel-
er reviews by SVM algorithm.
3 Problem Analysis and Method De-
scription
3.1 Discourse Structure of Chinese Texts
The overall SP of a Chinese text is the sum of 
the SP of all its component parts. However, the 
importance of each component part in a given 
text varies. This is because no matter which 
writing style a text belongs to, it has a particular 
discourse structure which determines the impor-
tance of the component parts.
Discourse structure is the organization and 
constitution law of language units (greater than 
sentence) within a discourse. It formally indi-
cates the hierarchy of discourse contents, seman-
tically guarantees the integrity of discourse con-
tents and logically reflects the coherence of dis-
course contents. In a word, discourse structure is 
the unity of discourse form, discourse meaning 
and discourse logic. A discourse consists of sev-
eral semantic parts. The central meaning of a 
discourse is the aggregation of the central mean-
ing of its semantic parts in a certain logic way. A 
semantic part is the set of paragraphs. It may be 
composed of as small as only a paragraph or as 
large as even a whole chapter. The basis for par-
titioning semantic parts depends on the writing 
styles, i.e., narration, description, argumentation 
and exposition. For argumentation, a typical ar-
gumentation may be divided into 4 parts as in-
troduction, viewpoint presentation, demonstra-
tion and conclusion. Recognizing semantic parts 
has great significance in understanding the cen-
tral idea of a text.
3.2 Features of Chinese Reviews
Chinese reviews are a kind of argumentation. 
According to what is reviewed, they can be ca-
tegorized into finance reviews (e.g., stock re-
view), literature reviews (e.g., book review), 
product reviews (e.g., automobile review), cur-
rent affairs reviews (e.g., news review), etc. 
Generally speaking, Chinese reviews bear the 
following features.
Firstly, the topic of a Chinese review is expli-
cit. A Chinese review always comments on some 
specific phenomenon, person or affair. The ob-
ject it deals with is very explicit.
Secondly, a Chinese review has generally on-
ly one topic. Thus, in a Chinese review, the re-
viewer always explicitly expresses his/her opi-
nion towards the topic. The sentiment of the dis-
cussed topic is rather explicit. Some Chinese 
reviews may discuss subtopics and correspond-
ing opinions on each subtopic may be shown. 
But it will not change or influence the reviewer?s 
basic sentiment on the topic.
Thirdly, the topic of a Chinese review is 
closely related to its title. Chinese Reviews often 
use concise expressions in titles to show clearly 
the topics or the themes. Therefore, the topic of 
a review can generally be found in its title.
Fourthly, Chinese reviews have fixed expres-
sion patterns. A typical Chinese review consists 
of 4 semantic parts as is mentioned above. The 
reviewer?s sentiment expressions towards the 
topic generally appears in the ?viewpoint presen-
tation? and ?conclusion? part.
To prove the correctness of our knowledge of 
Chinese reviews, we conducted a survey on 560 
Chinese reviews which were collected from 
newspapers and the Internet. The manually ex-
amined results, which are showed as follows, 
verify the above mentioned 4 features of Chi-
nese reviews.
Table 1 A Survey on Features of Chinese Reviews
Features Percent
Explicit Topic 100
One Topic 100
Title Reflects Topic 99.64
Discourse
Structure
I-D-C1 40.17
I-V-D-C 33.9
I-V-D 18.75
others 7.18
1
?I? stands for introduction, ?D? for demonstration, ?C? for 
conclusion and ?V? for viewpoint presentation.
3.3 Topic Sentiment Sentence
According to the above analysis, the SP of a 
Chinese review is manifested by a certain ex-
pression pattern through several semantic parts, 
and its overall SP is generally expressed in the 
?viewpoint presentation? and ?conclusion? part. 
Thus a straightforward idea to obtain the SP of a 
Chinese review is to: (1) partition the review 
into several semantic parts; (2) distinguish the
viewpoint presentation part and the conclusion 
part; (3) analyze only the sentiment of the view-
point presentation part and the conclusion part 
and take the result as the overall SP of the re-
view. Intuitively, this seemingly simple method 
can achieve very good result.
However, to perform an automatic discourse 
structure analysis itself is actually a hard task 
and will lose precision during the processing; to 
distinguish different semantic parts by means of 
language cues without a discourse structure 
analysis can only solve some instead of all prob-
lems. Therefore, we introduce the concept of 
topic sentiment sentence. 
A topic sentiment sentence is defined as a sen-
tence bearing both the topic concept and senti-
ment towards that topic. The topic sentiment 
sentences in a Chinese review are the intersec-
tion of the topic sentences and sentiment sen-
tences in it. Topic sentiment sentences are repre-
sentative for sentiment analysis because, firstly, 
they are homogeneous in topic. And more im-
portantly, the sentiment bearing in these sen-
tences refer to the same topic. This makes sen-
timent in each sentence computable. Earlier 
works like Turney (2002) or Pang et al(2002) 
don?t take into account the topic and the senti-
ment relating to that topic together as a whole, 
thus makes the result less reliable in that the sen-
timent words and phrases processed are not ho-
mogeneous in topic. Secondly, the degree of se-
mantic similarity between topic sentiment sen-
tences and the topic of the review reflects a po-
tential relatedness between the topic sentiment 
sentences and their corresponding semantic parts. 
The more a topic sentiment sentence is similar in 
meaning to the topic, the more likely it appears 
in the viewpoint presentation part or conclusion 
part. This is just the reason we avoid an analysis 
of discourse structure of a review. We also try to 
avoid an automatic partition of semantic parts of 
a review since the topic sentiment sentences 
themselves potentially point out the correspond-
ing semantic parts they belong to. Thirdly, the 
distribution of the topic sentiment sentences, 
including density and extensity, reflects more or 
less the writer?s intensity of attitude toward what 
is being discussed and can help with detailed 
sentiment analysis.
To summarize, with topic sentiment sentences, 
we can compute the SP of a Chinese review in a 
more simple and effective way without an auto-
matic discourse structure analysis. Moreover, we 
can obtain a ?shallow? structure since topic sen-
timent sentences potentially reflect the discourse 
structure of Chinese reviews. 
3.4 Method
We thus propose a new method to recognize the 
sentiment polarity of Chinese reviews using top-
ic sentiment sentences. It is described as follows. 
(1) Identify the topic of a review using an n-
gram matching approach. (2) Extract candidate 
topic sentiment sentences, compute the semantic 
similarity between a given sentence and the as-
certained topic and meanwhile determine wheth-
er the sentence is subjective. (3) A certain num-
ber of these sentences are selected as representa-
tives according to their semantic similarity value 
with relation to the topic. The average value of 
the representative topic sentiment sentences is 
calculated and taken as the sentiment polarity of 
a review. 
Experiment results show that the proposed 
method is feasible and can achieve relatively 
high precision.
4 Topic Identification and Topic Sen-
timent Sentence Extraction
4.1 Topic Identification of Chinese Reviews
The topic of a Chinese review is presented as a 
set of strings T={Wn1, Wn2, ?, Wni}, in which 
Wni refers to a word or several continuous words
and n indicates the number of words in a Wni.
The evaluation of whether any candidate Wni
belongs to T depends on its position and fre-
quency. Wni?s position reflects its distribution 
degree D(Wni): the more extensive Wni distri-
butes in a review, the more likely it relates to the 
topic. Wni?s frequency reflects its importance 
degree I(Wni): the more times Wni appears in a 
review, the more likely it relates to the topic. 
Thus the degree of Wni belongs to T is defined 
as membership degree C(Wni) and is measured 
by the formula:
C(Wn
i
)= ?? D(Wn
i
) +?? I(Wn
i
)    (1)
In (1), D(Wni) is determined by the number of 
paragraphs in which D(Wni) appears and the 
total number of paragraphs of a text,  I(Wni) is 
the binary logarithm of the frequency of Wni in a 
text, ? and ? are the weighted coefficients to ad-
just the weights of D(Wni) and I(Wni).
In order to quickly obtain T, an n-gram 
matching based approach is applied according to 
the following algorithm.
(1) Strings separated by punctuations in the 
title and the main text are segmented and then 
stored respectively in queue Tq and Bq.
(2) For n=1 to m (1?m? the maximum 
length of Tq), take out a Wni from Tq successive-
ly and search it in Bq. If there is a Wni in Bq,
then insert it into the index table G={Wni, posi-
tion, frequency}. When n=1, which means there 
is only one word in Wni, Wni should be a con-
tent word.
(3) Calculate the value of C(Wni) for every 
Wni and add Wni to T if its C(Wni) is greater 
than the threshold Lc. In this paper, we choose 
?=0.25, ?=1, and Lc=0.8 according to our expe-
rience and experiment results.
4.2 The Extraction of Topic Sentiment Sen-
tences
Topic sentiment sentences are essential in the 
analysis of the SP of reviews. Sentiment analysis 
based on topic sentiment sentences excludes un-
related sentiment and makes ?homogeneous? 
sentiment computable. Topic sentiment sen-
tences are extracted by 2 steps.
(1) Extract topic sentences from a review.
Given a definite T, to extract topic sentences is 
actually the computing of semantic similarity of 
candidate sentences and the topic T. Factors that 
influence the similarity degree are the amount of 
identical words and strings, the length of iden-
tical words and strings, the position of a candi-
date sentence, semantic similarity of non-
identical words. 
The amount of identical words and strings.
The more identical words or strings a candidate 
sentence has with T, the more likely they are 
similar in topic. 
The length of identical words and strings.
The longer an identical string (counted by word) 
shared by a candidate sentence and T, the more 
likely they are similar in topic. 
The position of a candidate sentence. We 
hold that sentences in a paragraph are not in the 
same importance. As is the general common 
knowledge, the beginning and ending sentence 
in a paragraph are often more important than 
other sentences and thus receive more weights. 
We use HowNet, a Chinese ontology, to com-
pute the semantic similarity and assign each 
candidate sentence a value of similarity. If the 
similarity value of a sentence is greater than the 
threshold Ls, it is taken as a topic sentence.
(2) Extract sentiment sentences from topic 
sentences. We use a precompiled sentiment lex-
icon to roughly judge whether a sentence ex-
presses sentiment or not. 
Through the above procedures, the topic sen-
timent sentences in a Chinese review, each with 
a value indicating the distance in similarity with 
the topic, are extracted and arranged into order 
by value. We call them the set of candidate topic 
sentiment sentences.
5 Recognizing the Sentiment Polarity 
Based on Topic Sentiment Sentences
Based on section 3.3, in Chinese reviews, the 
higher similarity degree a topic sentiment sen-
tence gets, the more likely it is a key sentence 
expressing the writers? basic sentiment orienta-
tion. But meanwhile, to avoid excessively rely-
ing on too few candidate topic sentiment sen-
tences, more sentences are required to be ana-
lyzed to assure precision. Therefore, the number 
of sentences selected from the set of candidate 
topic sentiment sentences for final sentiment 
analysis is quite a question worth careful consid-
eration. 
Different Chinese reviews have different 
numbers of topic sentiment sentences. How 
many topic sentiment sentences a review has is 
determined by various factors. We find out, after 
an investigation of 560 Chinese reviews, that 
generally a Chinese review has not more than 7 
topic sentiment sentences and the average num-
ber of that is about 4. Besides, long reviews tend 
to have rather more topic sentiment sentence. 
Thus we define that for any review the number 
of topic sentiment sentences which are needed to 
be analyzed as: 
N(tss) ??                                                (2)
? LQ WKH DERYH IRUPXOD LV DQ DGMXVWDEOHSDUa-
meter which is determined by the ratio of the 
length of the analyzing review and the average 
length of a set of reference reviews.
N(tss) topic sentiment sentences with most 
weights are drawn from the set of candidate top-
ic sentiment sentences and then are computed by 
a sentence-level sentiment analyzer. The average 
score of them is taken as O(r), i.e. the overall SP 
of a review.
?
 
 
)(
1
)(
)(
1
)(
tssN
i
i
tssSP
tssN
rO
          (3)
We use a semantic approach in the sentence-
level sentiment analyzer. For each sentence, a 
Chinese dependency parser is used to distinguish 
the dependency relations between language units, 
especially the probable relations between the 
topic words and the sentiment expressions, and 
the relations between the sentiment expressions 
and their modifiers. Making use of the syntactic 
information, the sentiment of a sentence is de-
termined mainly by the sentiment expressions in 
it according to a precompiled sentiment lexicon. 
Meanwhile, the following factors are considered.
Negatives. Negatives inverse the sentiment of 
a sentence.
Connectors. Some connectors strengthen the 
original sentiment while others inverse the origi-
nal sentiment.
Intensifiers. Intensifiers make the original 
sentiment more forcefully.
Discourse makers. In linguistics, a discourse 
marker is a word or phrase that is relatively syn-
tax-independent and does not change the mean-
ing of the sentence. However, discourse marker 
itself has certain semantic orientation: some of 
them are positive, some are negative and others 
are neutral. Thus discourse marker help recog-
nize the SP in a sentence.
Punctuations. We pay special attention to 
question mark and exclamatory mark, especially 
when there is a negative in a question sentence.
6 Experiments and Results
6.1 Data
The data used in the experiment are Chinese cur-
rent affairs reviews. They are originally col-
lected from the web-
site http://opinion.people.com.cn/ and then 
cleansed and stored as text. 400 texts are ran-
domly selected from the reviews set. 3 annota-
tors are trained and then instructed to annotate 
the topic sentiment sentences and judge the SP 
the 400 reviews individually. The following ta-
ble shows the general information of the annota-
tion result.
Table 2 General Information of the Annotation 
Results
Annotator
Pos.
texts
Neg.
texts
Other
texts
1 87 302 11
2 93 298 9
3 88 288 14
Finally we get 370 texts (86 positive and 284 
negative) totally agreed by the 3 annotators. We
use them as the test reviews.
6.2 Resources
In order to perform an SP analysis, the following 
resources are required to use.
Sentiment Lexicon. We manually build up 
the sentiment lexicon. The words and phrases in 
the lexicon are mainly from three dictionaries: 
Positive Word Dictionary, Negative Word Dic-
tionary and A Student?s Positive and Negative 
Word Dictionary. We also get some words from 
HowNet Sentiment Dictionary and NTUSD. For 
each word or phrase, we give its part of speech, 
positive value and negative value. The positive 
and negative values of words and phrases are 
manually assigned by annotators according to 
human intuition. 
Other lexicons. We collect as many negatives, 
connectors, intensifiers and discourse markers as 
we can and make them into different lexicons.
HowNet. As a Chinese ontology, HowNet is 
used to compute the semantic similarity of 
words.
LTP. LTP (Language Technology Platform 
developed by HIT) is a package of tools to 
process Chinese text, with a Chinese dependen-
cy parser in it. We use the dependency parser to 
perform a syntactic analysis of sentences.
CUCSeg. CUCSeg is a Chinese pos tagger. 
We use it to segment Chinese words.
6.3 Results of the Extraction of Topic Sen-
timent Sentences Experiment
The extraction of topic sentiment sentences is a 
vital task in this research. Annotators judge in 
the test reviews which sentences are topic senti-
ment sentences firstly and method described in 
4.2 is applied and the result of which is eva-
luated. We adopt the commonly used precision, 
recall and F-measure to measure the result. It 
shows as follows.
Table 3 Result of the Extraction of topic Senti-
ment Sentences
Threshold Precision Recall F1
Ls=0.64 89.9 82.3 86.1
Ls=0.55 86.1 90.6 88.3
Ls=0.37 77.8 98.4 88.1
The above result shows we get a rather high 
precision and recall when Ls=0.55.
6.4 Results of Recognizing the SP of Chi-
nese Reviews Experiment
We use precision to measure the result. Compar-
ison is made among Turney?s method (2002),
Pang?s SVM method (2002) and our method.
Table 4 Result of the SP of Chinese reviews
Method Precision
Turney?s 74.39
Pang?s SVM 82.9
Ours 86.8
  
Compared to reports in earlier works, our ap-
proach achieves a relatively high precision. 
We reexamine the 49 texts which are judged 
wrong, together with the 4 extracted representa-
tive topic sentiment sentences of each text. Error 
analysis shows that about 35% of errors are 
made by the topic identification step, about 49% 
of errors are made by the sentence-level senti-
ment analysis, about 4% of errors are made due 
to the faultiness of the sentiment lexicon. And 
the causes of other errors are to be explored.
7 Conclusion
We have presented a topic sentiment sentence-
based approach to explore the overall sentiment 
polarity of Chinese reviews. Considering the 
features of Chinese reviews, we identify the top-
ic of a review using an n-gram approach. To ex-
tract topic sentiment sentences, we compute the 
semantic similarity of a candidate sentence and 
the ascertained topic and meanwhile determine 
whether the sentence is subjective. A certain 
number of these sentences are selected as repre-
sentatives according to their semantic similarity 
value with relation to the topic. The average val-
ue of the representative topic sentiment sen-
tences is calculated and taken as the sentiment 
polarity of a review.
Error analysis indicates that to enhance the 
identification of topic, to build up a better sen-
tence-level sentiment analyzer and to compile a 
better sentiment lexicon will help improve the 
final result.
Acknowledgements
We thank Prof. Ting Liu at Harbin Institute of Tech-
nology for sharing the LTP package and Mr. Zhen-
dong Dong for sharing the HowNet. We highly ap-
preciate that Hanbing Zhao, Nan Li and Yifu Xue 
have done a lot of heavy and tedious annotation work 
for this research.
References
Hu, M. and Liu, Bing. 2004. Mining and summariz-
ing customer reviews. In Proceedings of the 10th 
ACM SIGKDD.168- 177.
Kim, S., Hovy E. 2004. Determining the Sentiment of 
Opinions. In Proceedings of COLING-04: the 20th 
International Conference on Computational Lin-
guistics.
Lun-Wei Ku and Hsin-Hsi Chen 2007. Mining Opi-
nions from the Web: Beyond Relevance Retrieval. 
Journal of American Society for Information 
Science and Technology, Special Issue on Mining 
Web Resources for Enhancing Information Re-
trieval, 58(12): 1838-1850.
Meng, F., L. Cai, B. Chen, and P. Wu. 2008. Re-
search on the recognition of text valence. Journal 
of Chinese Computer Systems, 28(2007): 1-4.
Pang Bo, Lillian Lee, and Shivakumar Vaithyanathan. 
2002. Thumbs up? Sentiment classification using 
machine learning techniques. In Proceedings of 
EMNLP, pages 79-86.
Turney, P. 2002. Thumbs Up or Thumbs Down? Se-
mantic Orientation Applied to Unsupervised Clas-
sification of Reviews. In Proceedings of the 40th 
Annual Meeting of the Association for Computa-
tional Linguistics. 417-424.
Wang, Gen and Jun Zhao. 2007. Sentence Sentiment 
Analysis Based on Multi-redundant-labeled CRFs. 
Journal of Chinese Information Processing, 21(5):
51-56.
Wang, C., Lu, J., Zhang, G. 2005. A semantic classi-
fication approach for online Product reviews. In 
Proceedings of the 2005 IEEE/WIC/ACM Interna-
tional Conference on web intelligence (Wl?5). 
Wang, G. and Zhao, J. 2007. Sentence Sentiment 
Analysis Based on Multi-redundant-labeled CRFs. 
Journal of Chinese Information Processing. 5, 51-
56.
Wang,C. J. Lu and G. Zhang. 2005. A semantic clas-
sification approach for online product reviews, In 
Proceedings of the 2005 IEEE/WIC/ACM Interna-
tional Conference on Web Intelligence. 276-279.
Wiebe J. 2000. Learning subjective adjectives from 
corpora. In Proceeding of the 17th National Confe-
rence on Artificial intelligence. Menlo Park, Calif. 
AAAI Press, 735-740.
Wiebe J., Riloff E.2005. Creating Subjective and Ob-
jective Sentence Classifiers from Unannotated 
Text. In: Proceedings of CICLING.
Wiebe J., Wilson T., BrueeR., Bell M. and Martin 
M.2004. Learning subjective language, Computa-
tional Linguistics, 30(3):277-308.
Yi J., Nasukawa T., Bunescu R., Niblack 
W.2003.Sentiment analyzer: Extracting sentiments 
about a given topic using natural language 
processing techniques. In Proceeding of the Third 
IEEE International Conference on Data Mining. 
Yu, H. and Hatzivassiloglou Vasileios.2003. Towards 
answering opinion questions. In Proceeding of 
EMNLP. 2003.
Zheng, W. and Q. Ye. 2005. Sentiment classification 
of Chinese traveler reviews by support vector ma-
chine algorithm. In The Third International Sym-
posium on Intelligent Information Technology 
Application, 335-338.
CMDMC: A Diachronic Digital Museum of Chinese Mandarin
Hou Min1, Zou Yu1, Teng Yonglin1, He Wei
Wang Yan
1
1,2, Liu Jun1,2, and Wu Jiyuan1,2
1
Monitoring and Research Center at Communication University of China
Broadcast Media Language Branch, National Language Resources
2
Beijing 100024, China
School of Literature, Communication University of China
{houmin, zouiy, tengyonglin, hewei}@cuc.edu.cn?
forget1812@sina.com, {aaa_0119, wjy__00}@163.com
Abstract
Modern Chinese Mandarin has gone 
through near a hundred years, it is very 
important to store its representative 
sample in digital form permanently. In 
this paper, we propose a Chinese Man-
darin Digital Multi-modal Corpus 
(CMDMC), which is a digital speech 
museum with diachronic, opened, cross-
media and sharable features. It has over 
3460 hours video and audio files with 
metadata tagging. The materials, which 
were generated by the authoritative 
speakers (e.g. announcers at TV or radio 
station) with normality, are required 
samples if we can get them. Based on 
this resource, we also intend to analyze 
the syntactic correlations of prosodic 
phrase in broadcasting news speech, and 
compare the phonetic and prosodic fea-
tures in movie dialogues among several 
same-name movies in different histori-
cal eras.
1 Introduction
Modern Chinese Mandarin has gone through 
near a hundred years. As language changes as 
society develops, Mandarin must be periodically 
marked with the different features of different 
historical eras. It is very important to design and 
construct a Chinese Mandarin Digital Multi-
modal Corpus (CMDMC), and store its repre-
sentative sample in digital form permanently.
It?s international trend to establish large-scale 
natural language corpus, and many countries 
pay more attention to research and preserve 
their national language. For instance, the Lin-
guistic Data Consortium (LDC) is an open con-
sortium of universities, companies and govern-
ment research laboratories. It creates, collects 
and distributes speech and text databases, lex-
icons, and other resources for research and de-
velopment purposes1. Since its foundation, the 
LDC has delivered data to 197 member institu-
tions and 458 non-member institutions. Moreo-
ver, European Language Resources Association 
(ELRA)2
The paper is organized as follows: Section 2 
describes the resources and data processing of 
our CMDMC. The experiment and evaluation is 
designed and carried out in section 3. Section 4 
is dedicated to analyze the syntactic correlations 
of prosodic phrase in broadcast news speech on 
CNR (China National Radio), and compare the 
is the driving force to make available 
the language resources for language engineering 
and to evaluate language engineering technolo-
gies. In order to achieve this goal, ELRA is ac-
tive in identification, distribution, collection, 
validation, standardization, improvement, in 
promoting the production of language resources, 
in supporting the infrastructure to perform eval-
uation campaigns and in developing a scientific 
field of language resources and evaluation. In
this paper, we intend to establish the CMDMC 
with the goal of showing the history of the de-
velopment of Chinese Mandarin, and represen-
tation the real character in different historical 
eras.
1 The Linguistic Data Consortium (LDC),
http://www.ldc.upenn.edu.
2 European Language Resources Association (EL-
RA), http://www.elra.info/.
phonetic and prosodic features in movie dialo-
gues. Finally, some conclusions and outlines of 
our future work are given in section 5.
2 General Description of CMDMC
In order to show the history of the development 
of Chinese Mandarin, and representation the 
real character in different historical periods, the 
CMDMC, which is a dynamic miniature model 
(or speech museum) with diachronic, opened, 
cross-media and sharable features, is designed
and constructed by Broadcast Media Language 
Branch of National Language Resources 
Monitor & Research Center at Communication 
University of China.
In China, announcers in Radio & TV stations, 
as well as movie or stage actors, are the authori-
ty of the national language standardization. 
Therefore, the speech in radio, television and 
movie can be taken as the paradigm and repre-
sentative of Mandarin. They can reflect the 
phonetic situation of that era. All of these are 
the source of the sample data for CMDMC.
2.1 Description of Resources
In order to fully demonstrate the development 
of Chinese Mandarin by the past 100 years, we 
try to collect all the video or audio materials in 
different periods. Therefore, a state-of-the-art 
classification is defined based on the corpora 
that we got.
Language styles: According to characteristic 
speaking styles of different media, there are 
three categories was defined, such as broadcast 
media language, movie or drama dialogue, and 
the dialogue in folk art (e.g. xiangsheng, ping-
shu etc.) and so on. To sum up, the three speak-
ing styles accounted for about 64.9%, 27.2%
and 7.9% of total corpora, respectively.
Mediums: The materials can be divided into 
audio, video, text and image/picture. The audio 
or video files are the main materials in our cor-
pus, and the aligned texts are transcribed based 
on the audio or video. The documents of image 
are subsidiary corpora.
Historical eras: Based on the characteristics 
of social and language changes, we also define 
six historical stages of Chinese Mandarin: 1) 
Before1949 (or 1919-1949), it is a theoretical
stage for corpora collection. In fact, the earliest 
speech materials, which we can collect, is re-
leased in 1932; 2) 1949-1965; 3) 1966-1977; 4) 
1978-1989; 5) 1990-1999; 6) 2000 to today.
Table 1 shows the distribution of detailed data
in different eras.
Eras
Broadcast 
media
(hours)
Movie 
/drama
(hours)
Folk 
art
(hours)
Percent
of total
(%)
1932-49 39.3 1.1 
1949-65 5.2 191.4 20 6.2 
1966-77 17.5 93.0 3.2 
1978-89 52.4 145.9 75.5 7.9 
1990-99 43.5 137.5 11.5 5.6 
2000-- 2131.5 337.0 167.1 76.0 
Total 2250.1 944.1 274.1
Table 1: The distribution of video and audio 
materials in different eras.
2.2 Data Processing
The data processing includes metadata tagging, 
text transcription and aligning, phonetic and 
prosodic annotation, POS and syntactic tagging
and so on.
As for labeling prosodic phrase boundaries, 
we strictly dependent on the prosodic criteria 
and perception by using the wave files and their 
transcriptions, which use many prosodic fea-
tures such as F0 contour, energy contour etc. At 
the same time, some spoken phenomena are 
considered.
3 Experiment and Evaluation
Firstly, in order to investigate the correlations 
between prosody and syntax, about 13 hours 
speech materials were selected to segment and 
label, including break index, stress index and 
summary of emotional tendentiousness etc.
Before the real annotation, six transcribers have 
been trained in accordance with the prosodic 
labeling conventions, until a high consistency of 
prosodic annotation can be carried out.
According to above experiment and annota-
tion, the number of occurrences of the various 
boundaries was calculated in table 2.
Secondly, we also designed a perception ex-
periment to determine phonetic diversification
for elimination as much as possible the subjec-
tivity which could be caused by the different 
personal intuition of language. Ten people at-
tended the perception experiment of this study:
3 men and 7 women. The average age is 25 
years. Nearly all of them were graduates major-
ing in linguistics. During the experiment, the 
participants were asked to discriminate 12 para-
graphs of random materials and judge the natu-
ralness, pitch, and speech rate of the sentences 
produced in each paragraph. These 12 para-
graphs consisted of 4 from 21 paragraphs of the 
1995 version, 4 from 21 paragraphs of the 1975 
version and 4 from modern materials. 
Boundaries
Types Index Marker Frequency
PW 1 /1, /1+ 55237
PP 2 /2 28867
C-PP 2 /2* 5976
IP 3 /3 7147
IG 4 /4 2781
MEC 5 /5 1770
Table 2: Distribution of all boundaries. The PW, 
PP, C-PP, IP, IG and MEC are the abbreviation of 
prosodic word, normal prosodic phrase, complex 
prosodic phrase, intonational phrase, intonational 
group and meaning expression cluster respectively.
In the perceptive procedure, we disordered all 
these materials for experiment, and three choic-
es were given to these ten people: 1) natural, in 
conformity with the standard of modern Manda-
rin; 2) fairly natural, close to the standard of 
modern Mandarin; 3) unnatural, a little stagy. 
Every paragraph was released twice with an 
interval of 10 seconds. After one hour of conti-
nuous work, a 10-minute break was given.
Only the results with at least a 90% agree-
ment rate were considered for analysis. 
4 Related Works
Based on this resource, we intend to analyze the 
syntactic correlations of prosodic phrase in 
broadcasting news speech on CNR, and com-
pare the phonetic and prosodic features in 
movie dialogues among several same-name 
movies in different historical eras.
4.1 Correlation between Syntax & Prosody
In English, there is a strong correlation between 
prosodic phrase boundaries and syntactic phrase 
boundaries (Price et al 1991). That is to say, 
prosodic phrase boundaries can play an impor-
tant role in understanding utterance as punctua-
tion marks do in written language. An investiga-
tion propose that boundary strength according to 
the measure, which the boundary strength is 
applied to syntactic structures and the phrase 
structure is viewed as an immediate constituen-
cy tree exclusively, corresponds much more 
closely to empirical prosodic boundary strength 
than does syntactic boundary strength according 
to a standard measure (Abney, 1992). In Greek, 
some study indicated that prosodic phrasing has 
a 95% identification rate, and a major effect on 
final tonal boundaries (Botinis et al 2004).
In Chinese, some researchers also proposed a 
statistical model to predict prosodic words from 
lexical words. In their model, both length of the 
word and the tagging from POS are two essen-
tial features to predict prosodic words, and the 
results showed approximately 90% of prediction 
for prosodic words (Chen at el. 2004).
What the correlation between syntax and 
prosody is in Chinese broadcasting news speech?
In order to investigate the syntactic correlations 
of prosodic phrase in real read speech on radio, 
we chose the representative speech materials 
from Xinwen he Baozhi Zhaiyao (News and 
Newspapers Summary) from CMDMC, which is 
a very famous broadcast news program of CNR.
This news program contains more syntactic, 
semantic and prosodic information, speaking
styles and high quality voice in real context. 
Therefore, 908 programs, which contain 454 
hours speech data from January 2006 to June 
2008, were selected for pre-processing. After 
the pre-processing step, we selected two fe-
male?s 13 hours speech materials (one female 
announcer?s material forms the main data, and 
another one?s is supplemented for comparable 
data) as a core database, which segmentation, 
transcription and prosodic annotation (including 
break index, stress index and summary of emo-
tional tendentiousness etc) was made by six 
transcribers. 
According to the characteristic of broadcast-
ing news speech, a new prosodic hierarchical 
structure (Zou et al 2009) and two different 
types of prosodic phrase (i.e. the normal prosod-
ic phrase and the complex prosodic phrase) 
boundaries were defined and used in our data 
labeling.
Top pitch value Bottom pitch value
Categories Location N SD Mean N SD Mean
PW Left 3478 3.917 16.1 3253 4.761 8.5
Right 3701 4.894 14.7 3165 5.457 9.9
PP Left 1741 3.891 14.7 1718 4.302 6.2
Right 627 3.481 16.5 492 5.077 9.3
C-PP Left 314 4.085 13.5 317 4.135 4.8
Right 361 3.616 17.9 285 5.092 10.0
IP Left 536 4.817 12.9 456 5.575 3.9
Right 531 3.019 18.8 473 3.720 13.8
IG Left 211 4.363 11.4 203 6.055 4.7
Right 229 2.377 19.4 185 2.927 15.0
MEC Left 104 4.238 8.1 95 4.937 2.6
Right 22 2.178 18.7 12 2.893 16.2
Table 3: The distribution of pitch on different boundaries. The phonetic acoustic data of each 
syllable was extracted by Praat script, and the foundational frequency was normalized by semi-
tones, the normalization formula is ST=12*log (F0/Fref)/log2 (the female?s reference frequency 
is 100Hz). (?top? is the mean of the highest pitch value at the first tone and the fourth tone; 
?bottom? is the mean of the lowest pitch value at the third tone and the fourth tone; ?N? refers 
the number of samples; ?SD? is the abbreviation of standard deviation)
In the further step, we selected 100 minutes 
speech materials from core annotated data, and 
investigated its features of pitch and duration at 
boundary (Zou et al 2010). The detailed data 
are shown in table 3 and 4 respectively.
Boundaries
Types Marker N Mean SD
PW /1 or/1+ 118 65.2 61.714
PP /2 659 97.6 84.140
C-PP /2* 193 108.7 82.483
IP /3 877 343.2 138.906
IG /4 375 699.2 254.287
MEC /5 31 771.0 208.580
Table 4: The mean of silent pause duration at
boundaries.
There are two ways of representation to pitch 
feature at prosodic boundary: Firstly, the pitch 
contour is un-continuity; secondly, the pitch 
resetting of the declination contour (de Pijper et 
al 1994). According to Table 3, we can find that 
there is a few resetting of bottom pitch value at 
PW boundary, that is to say, the bottom of the
PW boundary right is 1.4 semitones higher than 
that of its left. At other boundaries, the bottom 
pitch values at right side are much higher than 
that at left side, for instance, there is 3.1, 5.2, 
9.9, 11.3 and 13.6 semitones resetting from PP 
to MEC boundary successively. Especially, at 
the IP boundary its resetting has about two 
times than that of C-PP boundary. This shows 
that there are very obvious prosodic feature at 
various boundaries in broadcasting news speech.
Generally, we know that 90ms is the floor of 
threshold for perceiving the silent pause. From 
Table 4, the mean of silent pause duration from 
long to short followed by MEC > IG > IP > C-
PP > PP > PW. Except there is no perceived 
silent pause at PW boundary, the other bounda-
ries have obvious silent pause that can be per-
ceived. The length of silent pause at PP and C-
PP are 97.6ms and 108.7ms respectively, and 
the length at IP has over three times longer than 
that at C-PP. According to this, we propose that 
the PP and C-PP lie in the same position at the 
prosodic hierarchical structure, and the C-PP is 
a special prosodic phrase.
From our core data we got 6728 C-PPs. Ac-
cording to the C-PP that contains the number of 
PW, we divided them into four categories, such 
as three-PW, four-PW, five-PW and six-PW. 
The distribution of them is shown in Table 5.
After preliminary analysis we found that the 
C-PP, which contains three PWs, has a simple 
syntactic structure although it is absolute major-
ity in the number, and that is compose of four 
PWs should be done for correlations of prosody 
and syntax. There are about 6 types of prosodic 
structure if the C-PP contains four PWs. The 
detail data of this type C-PP followed in table 6.
From the data, we know that the fourth type, 
which is (A+B) +(C+D), is the most, and that is 
composed by (A+B) +C+D is the least in all of 
the six types. Although there are just six types 
of prosodic structure that can be found, there are 
more than 985 syntactic categories in this 1835 
C-PPs. There are 23 types which occur more 
than 10 times, and most of them occur only one 
time. To some extent, it can explain that the 
syntactic structure is more complex than the 
prosodic one.
An example of prosodic and syntactic struc-
tures in the utterance, which is ou1 yang2 yu3 
hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 
ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand), is given in 
figure 1. The left side of figure is the prosodic 
structure, and the syntactic one lies at the right 
side.
In figure 1, there is a little difference of jin3 
jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (???
??????) between its prosodic structure 
?A+(B+C+D)? and its syntactic structure ?[VP 
[VP jin3jin0/adv bao4zhu4/v] [NP [AP 
lou2ti1/n de0/u] [NP lan2gan1/n]]]?, but the 
differences between its prosodic and syntactic 
structure are obvious because the jin3 jin0 is 
stressed in speech for semantic expression.
Categories Example Num.
Three-PW ??/1+ ??/1 ??/2* 4433
Four-PW ???/1+ ??/1 ??/1 ??/2* 1835
Five-PW ??/1 ??/2 ??/1 ??/1 ??/2* 414
Six-PW ?/1+ ??/1 ??/2 ??/1 ??/2 ??/2* 46
Total 6728
Table 5: The distribution of four kinds of C-PP
Types Example Num. Percent (%)
A+(B+C)+D ?/1+ ??/1 ??/2 ??/2* 441 24.03
A+(B+C+D) ??/1+ ?/1 ?/1 ???/2* 495 26.98
A+B+(C+D) ??/1+ ??/1+ ??/1 ??/2* 97 5.29
(A+B)+(C+D) ?/1 ??/2 ??/1 ??/2* 529 28.83
(A+B+C)+D ??/1 ??/1 ??/2 ??/2* 259 14.11
(A+B)+C+D ?/1 ??/2 ??/2 ??/2* 14 0.76
Total 1835 100
Table 6: The distribution of prosodic type in C-PP of four-PW
Figure 1: An example of (a) prosodic structure vs. (b) syntactic structure in an utterance: ou1 yang2 
yu3 hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand).
Figure 2: The pitch contour of the same utterance.
Figure 2 shows the pitch contour of the same 
utterance. In this utterance, there is a nesting 
structure at jin3 jin0 bao4 zhu4 lou2 ti1 de0 
lan2 gan1 (held fast to the staircase railing)
based on the length of perceived silent pause. 
Furthermore, the pitch declination trend within 
the C-PP is obvious despite small resetting be-
tween zhu4 and lou2. So we suggest that there is 
a stable prosodic pattern within a C-PP in 
broadcasting news speech.
Conversely, what is the correlation between 
the prosody and syntax? From above analysis, 
we know that the conjunction and particle, such
as?(de0), ?(deng3),?(he2), ?(dan4) and so 
on, more likely attached to the end of left struc-
ture or the beginning of right one and form a 
prosodic word. If it has just four lexical words 
including the conjunction or particle they form a 
prosodic word by itself. That is to say, it has 
very great flexibility in prosodic structures for 
conjunctions and particles, such as ? ?
(zhan4)/1+ ??(quan2guo2)/1 ??(shi1di4)/1 
???(mian4ji1 de0)/2* (occupy/1+ country-
wide/1everglade/1 acreage/2*)?, ??(he2)/1 ?
? (she4hui4)/2 ? ? (jiu4zhu4)/1 ? ?
(zhi4du4)/2* (and/1 social/2 assistance/1 sys-
tem/2*)? and so on.
4.2 Diachronic Comparative Phonetic and 
Prosodic Analysis in Movie Dialogues
Which diachronic phonetic changes happened in 
Mandarin by the past 100 years? We also ana-
lyze and compare the phonetic features of Chi-
nese Mandarin among several same-name mov-
ies in different historical eras from CMDMC
(Wang et al 2010). In order to minimize the 
divergence of the variables and maximize the 
reliability of conclusions, we chose two pairs of 
same-name movies screened in different histori-
cal periods. These movies are: Pingyuan Youji-
dui (The Plains Guerrillas) shot in 1955 and 
1975, Dujiang Zhencha Ji (Reconnaissance 
across the Yangtze River) shot in 1954 and 1974 
respectively.
Pitch Feature: In the analysis of pitch, we 
put aside the stresses and the neutral tone syl-
lables, and make the statistical investigations on 
the top pitch value and the bottom pitch value of 
the syllables.
Figure 3: The pitch data of 1955 and 1975 ver-
sion in the Plains Guerrillas. The fundamental 
frequency also was normalized by semitones;
the male?s reference frequency is 50Hz.
Figure 3 shows that the mean of the top pitch 
value in the 1950s? materials is lower than that 
of 1970s?. In the 1955 version, the leading cha-
racter, Speaker A, possesses a mean value of the 
top pitch value which is 20.9 semitones. This 
value is lower than that of 1975s? by a differ-
ence of 0.9 semitones. The negative character, 
Speaker B, has a mean value of the top pitch 
value which is 24.5 semitones in the 1955 ver-
sion. The value in the 1975 version is 27 semi-
tones, with a difference of 2.5 semitones left, 
also showing that the value in the 1975 version 
is comparatively high. Comparing the data of 
the bottom pitch value in the 1955 version with 
that in the 1975 version, we know that these 
data seem closer than the top pitch value, but 
still the higher ones belong to the 1975 version. 
That the bottom pitch value is higher tells us 
that the whole pitch register is raised.
Furthermore, we can easily see from Figure 3
that the pitch range of the same character in the 
1975 version is wider. Speaker A of the 1955 
version has a pitch range of 4.8 semitones. In 
contrast, the same character in the 1975 version 
has a pitch range of 6 semitones. Speaker C of
the 1955 version has 4 semitones pitch range, 
but in the 1975 version, he has 5.9 semitones 
pitch range. The gap between them is 1.9 semi-
tones. Through this comparison, we find that the 
pitch range in the 1975 version is wider than 
that in the 1955 version in the whole. 
To some extent, the speaking, both the top
pitch value and the bottom pitch value in the 
1975 version are higher. This proves that, on the 
whole, the pitch of the 1970s? materials is high-
er and more unnatural than that of 50s? because 
of the effect by the Cultural Revolution era.
And this also proves the feeling of the partici-
pants in the perceptional experiment at section 3 
about the 1970s? materials, that is, the 1970s?
Mandarin has a loud and sonorous voice; the 
characters pronounce harder; the general pitch is 
higher.
Duration feature: In the respect of duration, 
we also compared and analyzed the presenters?
speech on TV in 20053
According to table 7, there is a little differ-
ence of the durations mean among them (fol-
lowing four tones), especially it?s very closely 
between the 1975 and the 2005, and those of the 
1975 version are a few longer than those of the 
1955 version. But, except the first tone (Sig. 
=.077), the differences of the duration means 
between the others, which is in the 1955, the 
with the materials ex-
tracted from the movie dialogues the 1955 and 
the 1975. Table 7 is the relevant data.
3 In this work, we just chose the male?s speech data 
from Zou (2007).
1975 and the 2005, are significant (Sig. 
=.000, .000, .002?.05 respectively).
mean SD N
Movie:1955 T1 153.6 69.5 243
T2 136.8 58.1 242
T3 132.8 58.7 321
T4 133.5 52.0 539
Movie:1975 T1 177.8 72.1 258
T2 155.5 52.0 263
T3 152.5 57.6 289
T4 156.7 59.9 505
TV: 2005 T1 163.1 65.7 1471
T2 156.0 66.5 1743
T3 156.8 67.6 1054
T4 145.9 62.3 2652
Table 7: The duration mean of four tones in 
movie dialogues (1955 and 1975) vs. that of
presenters? spoken language on TV in 2005(ms).
Demonstrations of the four-syllable pro-
sodic words: The comparative pitch contour of 
two four-syllable prosodic words, which are 
?bu2 yao4 lu4 mian4? (don?t appear) and ?gan4
shen2 me0 de0? (What are you doing?), are 
shown in Figure 4 and 5, respectively.
Figure 4: The pitch contour of ?bu2 yao4 lu4
mian4? (don?t appear)
Figure 5: The pitch contour of ?gan4 shen2 me0
de0? (What are you doing?)
By observing the above two figures, we find 
that the pitch contour of the 1975 and that of the 
1955 are almost identical except the latter is 
always lower than the former. This may explain 
that although the Mandarin has gone through a 
hundred years, the pitch pattern is relatively 
stable.
5 Conclusions and Future Work
This paper proposes to design a Chinese 
Mandarin Digital Multi-modal Corpus
(CMDMC). Through this corpus, the historical 
trace of Mandarin development can be followed;
the fresh and alive data and material resources 
can be drawn up for the modern researchers and 
successors. We also intend to analyze the syn-
tactic correlations of prosodic phrase in broad-
casting news speech, and compare the phonetic 
and prosodic features in movie dialogues among 
several same-name movies in different histori-
cal eras. The contributions are as follows.
Firstly, the syntactic structure is more com-
plex than the prosodic structure, some conjunc-
tion and particle, such as de0, deng3, he2, dan4
and so on, more likely attached to the end of left 
structure or the beginning of right one and form 
a prosodic word, if the number of lexical words 
mismatch the prosodic words. Otherwise, they 
have almost similar structure.
Secondly, the speech of 1970s in last century 
is greatly influenced by the special era. People 
usually use exaggerated voice, pronounce hard 
and raise the pitch unnaturally, giving others a 
taste of lecturing and ordering. In contrast, the 
speech of Mandarin in 1950s is more natural 
and close to the daily life pronunciation and 
intonation. Even so, the pitch patterns have no 
big changes, and this may explain that the pitch
patterns are comparatively stable in Chinese 
Mandarin.
Future research will include treatment of cor-
relation between syntax and prosody within IP
or IG, ideally comparing the diachronic phonet-
ic or prosodic changes in Mandarin by the past 
100 years. Additionally, we would like to tackle 
the problem of data management, update and 
periodical increasing as time passes.
6 Acknowledgements
This work was supported by the Department of 
Science and Technology at Ministry of Educa-
tion (No. 107118), and ?211? Key Projects of 
Communication University of China (No. 
21103010105, 21103010106). We would like to 
thank the anonymous reviewers for their in-
sightful comments.
References
Abney, S. 1992. Prosodic Structure, Performance 
Structure and Phrase Structure. Proceedings of 5th 
Darpa Workshop on Speech & Natural Language.
Botinis, A., Ganetsou, S., Griva, M., and Bizani, H.
2004. Prosodic Phrasing and Syntactic Structure 
in Greek. Proceedings of FONETIK 2004, Dept. 
of Linguistics, Stockholm University.
Chen, Keh-jiann, Tseng, Chiu-yu, Peng, Hua-jiu and 
Chen, Chi-ching. 2004. Predicting Prosodic 
Words from Lexical Words -- A First Step to-
wards Predicting Prosody from Text . Proceed-
ings of the 4th International Symposium on Chi-
nese Spoken Language Processing (ISCSLP 2004).
Hong Kong, 173-176.
de Pijper, J. R., and Sanderman, A. A. 1994. On the 
Perceptual Strength of Prosodic Boundaries and 
its Relation to Suprasegmental Cues. Journal of 
the Acoustical Society of America, 96(4), 2037-
2047.
Price, P., Ostendorf, M., Shattuck-Hufnagel, S., and 
Fong, C. 1991. The Use of Prosody in Syntactic 
Disambiguation. Journal of the Acoustic Society 
of American, 90, 2956-2970.
Wang Yan, Liu Jun, Kan Minggang, Hou Min, Zou 
Yu. 2010. Phonetic Diachronic Diversification in 
Mandarin: A Case of the Same Movie?s Dialogue 
in 1950s and 1970s. Proc. of YWCL 2010, Wuhan, 
Hubei, Oct 10-13. (Accepted)
Zou Yu. 2007. A Formal Study on Prosody of Pre-
senter's Spoken Language Based on Broadcast 
Speech Corpus. PhD thesis, Communication Uni-
versity of China.
Zou Yu, He Wei, Zhang Yuqiang, Hou Min and Zhu 
Weibin. 2009. A Special Prosodic Phrasing in 
Broadcasting News Programs. Computational 
Sciences and Optimization: Theory, Simulation 
and Experiment (Vol. 2), Sanya, Hainan, China, 
24-26 April, 406-408.
Zou Yu, Wu Jiyuan, He Wei, Hou Min, Teng Yon-
glin. 2010. Syntactic Correlations of Prosodic 
Phrase in Broadcasting News Speech. The 6th 
IEEE International Conference on Natural Lan-
guage Processing and Knowledge Engineering 
(NLP-KE 2010), Beijing, China, Aug. 21-23.
