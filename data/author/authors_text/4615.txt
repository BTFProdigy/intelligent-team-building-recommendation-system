A Transformation-based Sentence Splitting Method for Statistical Ma-
chine Translation 
Jonghoon Lee, Donghyeon Lee and Gary Geunbae Lee 
Department of Computer Science and Engineering 
Pohang University of Science & Technology (POSTECH) 
{jh21983, semko, gblee}@postech.ac.kr 
 
 
 
Abstract 
We propose a transformation based sen-
tence splitting method for statistical ma-
chine translation. Transformations are ex-
panded to improve machine translation 
quality after automatically obtained from 
manually split corpus. Through a series of 
experiments we show that the transforma-
tion based sentence splitting is effective 
pre-processing to long sentence translation. 
1 Introduction 
Statistical approaches to machine translation have 
been studied actively, after the formalism of statis-
tical machine translation (SMT) is proposed by 
Brown et al (1993). Although many approaches of 
them were effective, there are still lots of problems 
to solve. Among others, we have an interest in the 
problems occurring with long sentence decoding. 
Various problems occur when we try to translate 
long input sentences because a longer sentence 
contains more possibilities of selecting translation 
options and reordering phrases. However, reorder-
ing models in traditional phrase-based systems are 
not sufficient to treat such complex cases when we 
translate long sentences (Koehn et al 2003). 
Some methods which can offer powerful reor-
dering policies have been proposed like syntax 
based machine translation (Yamada and Knight, 
2001) and Inversion Transduction Grammar (Wu, 
1997). Although these approaches are effective, 
decoding long sentences is still difficult due to 
their computational complexity. As the length of 
an input sentence becomes longer, the analysis and 
decoding become more complex. The complexity 
causes approximations and errors inevitable during 
the decoding search. 
In order to reduce this kind of difficulty caused 
by the complexity, a long sentence can be paraph-
rased by several shorter sentences with the same 
meaning. Generally, however, decomposing a 
complex sentence into sub-sentences requires in-
formation of the sentence structures which can be 
obtained by syntactic or semantic analysis. Unfor-
tunately, the high level syntactic and semantic 
analysis can be erroneous and costs as expensive as 
SMT itself. So, we don?t want to fully analyze the 
sentences to get a series of sub-sentences, and our 
approach to this problem considers splitting only 
compound sentences. 
In the past years, many research works were 
concerned with sentence splitting methods to im-
prove machine translation quality. This idea had 
been used in speech translation (Furuse et al 1998) 
and example based machine translation (Doi and 
Sumita, 2004). These research works achieved 
meaningful results in terms of machine translation 
quality. Unfortunately, however, the method of 
Doi and Sumita using n-gram is not available if the 
source language is Korean. In Korean language, 
most of sentences have special form of ending 
morphemes at the end. For that reason, we should 
determine not only the splitting position but also 
the ending morphemes that we should replace in-
stead of connecting morphemes. And the Furuse et 
al?s method involves parsing which requires heavy 
cost. 
In this paper we propose a transformation based 
splitting method to improve machine translation 
quality which can be applied to the translation 
tasks with Korean as a source language. 
2 Methods 
Our task is splitting a long compound sentence into 
short sub-sentences to improve the performance of 
phrase-based statistical machine translation system. 
We use a transformation based approach to 
accomplish our goal. 
2.1 A Concept of Transformation 
The transformation based learning (TBL) is a kind 
of rule learning methods. The formalism of TBL is 
introduced by Brill (1995). In past years, the TBL 
approach was used to solve various problems in 
natural language processing such as part of speech 
(POS) tagging and parsing (Brill, 1993). 
A transformation consists of two parts: a trigger-
ing environment and a rewriting rule. And the re-
writing rule consists of a source pattern and a tar-
get pattern. Our consideration is how to get the 
right transformations and apply them to split the 
long sentences. 
A transformation works in the following man-
ner; some portion of the input is changed by the 
rewriting rule if the input meets a condition speci-
fied in the triggering environment. The rewriting 
rule finds the source pattern in the input and rep-
laces it with the target pattern. For example, sup-
pose that a transformation which have a triggering 
environment A, source pattern B and target pattern 
C. We can describe this transformation as a sen-
tence: if a condition A is satisfied by an input sen-
tence, then replace pattern B in the input sentence 
with pattern C. 
2.2 A Transformation Based Sentence Split-
ting Method 
Normally, we have two choices when there are 
two or more transformations available for an input 
pattern at the same time. The first choice is apply-
ing the transformation one by one, and the second 
choice is applying them simultaneously. The 
choice is up to the characteristics of the problem 
that we want to solve. In our problem, we choose 
the former strategy which is applying the transfor-
mations one by one, because it gives direct intui-
tion about the process of splitting sentences. By 
choosing this strategy, we can design splitting 
process as a recursive algorithm. 
At first, we try to split an input sentence into 
two sub-sentences. If the sentence has been split by 
some transformation, the result involves exactly 
two sub-sentences. And then we try to split each 
sub-sentence again. We repeat this process in re-
cursive manner until no sub-sentences are split. 
In the above process, a sentence is split into at 
most two sub-sentences through a single trial. In a 
single trial, a transformation works in the follow-
ing manner:  If an input sentence satisfies the envi-
ronment, we substitute the source pattern into the 
target pattern. That is, replace the connecting mor-
phemes with the proper ending morphemes. And 
then we split the sentence with pre-defined posi-
tion in the transformation. And finally, we insert 
the junction word that is also pre-defined in the 
transformation between the split sentences after the 
sub sentences are translated independently. 
From the above process, we can notice easily 
that a transformation for sentence splitting consists 
of the four components: a triggering environment, 
a rewriting rule, a splitting position and a junction 
type. The contents of each component are as fol-
lows. (1) A triggering environment contains a se-
quence of morphemes with their POS tags. (2) A 
rewriting consists of a pair of sequences of POS 
tagged morphemes. (3) A junction type can have 
one of four types: ?and?, ?or?, ?but? and ?NULL?. 
(4) A splitting position is a non-negative integer 
that means the position of starting word of second 
sub-sentence. 
2.3 Learning the Transformation for Sen-
tence Splitting 
At the training phase, TBL process determines 
the order of application (or rank) of the transforma-
tions to minimize the error-rate defined by a spe-
cific measure. The order is determined by choosing 
the best rule for a given situation and applying the 
best rule for each situation iteratively. In the sen-
tence splitting task, we maximize the machine 
translation quality with BLEU score (Papineni et 
al., 2001) instead of minimizing the error of sen-
tence splitting. 
During the training phase, we determine the or-
der of applying transformation after we build a set 
of transformations. To build the set of transforma-
tions, we need manually split examples to learn the 
transformations. 
Building a transformation starts from extracting 
a rewriting rule by calculating edit-distance matrix 
between an original sentence and its split form 
from the corpus. We can easily extract the different 
parts from the matrix. 
BaseBLEU :=  BLEU score of the baseline system 
S := Split example sentence 
T := Extracted initial transformation  
for each t? T  
    for each s?S 
        while true 
             try to split s with t 
             if mis-splitting is occurred 
                  Expand environment 
             else exit while loop 
             if environment cannot be expanded 
                  exit while loop 
S? := apply t to S 
    Decode S? 
    BLEU := measure BLEU 
    Discard t if BLEU < BaseBLEU 
sort  T w.r.t. BLEU 
From the difference pattern, we can make the 
source pattern of a rewriting rule by taking the dif-
ferent parts of the original sentence side. Similarly, 
the target pattern can be obtained from the differ-
ent parts of split form. And the junction type and 
splitting position are directly obtained from the 
difference pattern. Finally, the transformation is 
completed by setting the triggering environment as 
same to the source pattern. The set of initial trans-
formations is obtained by repeating this process on 
all the examples. 
The Transformations for sentence splitting are 
built from the initial transformations through ex-
panding process. In the expanding process, each 
rule is applied to the split examples. We expand 
the triggering environment with some heuristics (in 
section 2.4), if a sentence is a mis-split. 
And finally, in order to determine the rank of 
each transformation, we sorted the extracted trans-
formations by decreasing order of resulted BLEU 
scores after applying the transformation to each 
training sentence. And some transformations are 
discarded if they decrease the BLEU score. This 
process is different from original TBL. The mod-
ified TBL learning process is described in figure 1. 
2.4 Expanding Triggering Environments 
Expanding environment should be treated very 
carefully. If the environment is too specific, the 
transformation cannot be used in real situation. On 
the other hand, if it is too general, then the trans-
formation becomes erroneous. 
Our main strategy for expanding the environ-
ment is to increase context window size of the 
triggering environment one by one until it causes 
no error on the training sentences. In this manner, 
we can get minimal error-free transformations on 
the sentence splitting corpus. 
We use two different windows to define a trig-
gering environment: one for morpheme and anoth-
er for its part of speech (POS) tag. Figure 2 shows 
this concept of two windows. The circles corres-
pond to sequences of morphemes and POS tags in 
a splitting example. Window 1 represents a mor-
pheme context and window 2 represents a POS tag 
context. The windows are independently expanded 
from the initial environment which consists of a 
morpheme ?A? and its POS tag. In the figure, win-
dow 1 is expanded to one forward morpheme and 
one backward morpheme while window 2 is ex-
panded to two backward POS tags. 
In order to control these windows, we defined 
some heuristics by specifying the following three 
policies of expanding windows: no expansion, 
forward only and forward and backward. From 
those three polices, we have 9 combinations of 
heuristics because we have two windows. By ob-
serving the behavior of these heuristics, we can 
estimate what kind of information is most impor-
tant to determine the triggering environment. 
Figure 1. Modified TBL for sentence splitting 
 
 
 
Figure 2. Window-based heuristics for triggering 
environments 
 
 
 
 
  
 
Test No. Window1 policy Window2 policy 
Test 1 
No expansion 
No expansion 
Test 2 Forward only 
Test 3 Free expansion 
Test 4 
Forward only 
No expansion 
Test 5 Forward only 
Test 6 Free expansion 
Test 7 
Free expansion 
No expansion 
Test 8 Forward only 
Test 9 Free expansion 
 
Table 2.Experimental setup 
 
 
 
 
We have at most 4 choices for a single step of 
the expanding procedure: forward morpheme, 
backward morpheme, forward POS tag, and back-
ward POS tag. We choose one of them in a fixed 
order: forward POS tag, forward morpheme, 
backward POS tag and backward morpheme. 
These choices can be limited by 9 heuristics. For 
example, suppose that we use a heuristic with for-
ward policy on morpheme context window and no 
expansion policy for POS tag context window. In 
this case we have only one choice: forward mor-
pheme. 
3  Experiments 
We performed a series of experiments on Korean 
to English translation task to see how the sentence 
splitting affects machine translation quality and 
which heuristics are the best. Our baseline system 
built with Pharaoh (Koehn, 2004) which is most 
popular phrase-based decoder. And trigram lan-
guage model with KN-discounting (Kneser and 
Ney, 1995) built by SRILM toolkit (Stolcke, 2002) 
is used. 
Test 
No. 
# of  af-
fected sen-
tences 
BLEU score 
Before 
splitting 
After 
splitting 
Test 1 209 0.1778 0.1838 
Test 2 142 0.1564 0.1846 
Test 3 110 0.1634 0.1863 
Test 4 9 0.1871 0.2150 
Test 5 96 0.1398 0.1682 
Test 6 100 0.1452 0.1699 
Test 7 8 0.2122 0.2433 
Test 8 157 0.1515 0.1727 
Test 9 98 0.1409 0.1664 
Table 1 shows the corpus statistics used in the 
experiments. The training corpus for MT system 
has been built by manually translating Korean sen-
tences which are collected from various sources. 
We built 123,425 sentence pairs for training SMT, 
1,577 pairs for splitting and another 1,577 pairs for 
testing. The domain of the text is daily conversa-
tions and travel expressions. The sentence splitting 
corpus has been built by extracting long sentences 
from the source-side mono-lingual corpus. The 
sentences in the splitting corpus have been manual-
ly split. 
The experimental settings for comparing 9 heu-
ristics described in the section 2.4 are listed in ta-
ble 2. Each experiment corresponds to a heuristic. 
To see the effect of sentence splitting on transla-
tion quality, we evaluated BLEU score for affected 
sentenced by the splitting.  The results are shown 
in table 3. Each test number shows the effect of 
transformation-based sentence splitting with dif-
ferent window selection heuristics listed in table 2. 
The scores are consistently increased with signifi-
cant differences. After analyzing the results of ta-
ble 3, we notice that we can expect some perfor-
 
SMT Splitting 
Korean English Before Split After Split 
Train # of Sentences 123,425 1,577 1,906 
# of Words 1,083,912 916,950 19,918 20,243 
Vocabulary 15,002 14,242 1,956 1,952 
Test #of Sentences 1,577 - - 
 
Table 1. Corpus statistics 
Table 3. BLEU scores of affected sentences 
 
mance gain when the average sentence length is 
long. 
The human evaluation shows more promising 
results in table 4. In the table, the superior change 
means that the splitting results in better translation 
and inferior means the opposite case. Two ratios 
are calculated to see the effects of sentence split-
ting. The ratio ?sup/inf? shows the ratio of superior 
over inferior splitting. And ratio trans/change 
shows how many sentences are affected by a trans-
formation in an average. In most of the experi-
ments, the number of superior splitting is over 
three times larger than that of inferior ones. This 
result means that the sentence splitting is a helpful 
pre-processing for machine translation. 
We listed some example translations affected by 
sentence splitting in the table 5. In the three cases, 
junction words don?t appear in the results of trans-
lation after split because their junction types are 
NULL that involves no junction word. Although 
several kinds of improvements are observed in su-
perior cases, the most interesting case occurs in 
out-of-vocabulary (OOV) cases. A translation re-
sult has a tendency to be a word salad when 
OOV?s are included in the input sentence. In this 
case, the whole sentence may lose its original 
meaning in the result of translation. But after split-
ting the input sentence, the OOV?s have a high 
chance to be located in one of the split sub-
sentences. Then the translation result can save at 
least a part of its original meaning. This case oc-
curs easily if an input sentence includes only one 
OOV. The Superior change of table 5 is the case. 
Although both baseline and split are far from the 
reference, split catches some portion of the mean-
ing. 
Test 
No. 
# of trans-
formations 
(rules) 
# of 
changes 
(sentences) 
# of supe-
rior 
changes 
# of infe-
rior 
changes 
# of insig-
nificant 
changes 
Ratio 
Sup/Inf 
Ratio 
trans/chang
e 
1 34 209 60 30 119 2.00 6.15 
2 177 142 43 9 90 4.78 0.802 
3 213 110 29 9 72 3.22 0.516 
4 287 9 4 1 4 4.00 0.031 
5 206 96 25 4 67 6.25 0.466 
6 209 100 23 8 69 2.88 0.478 
7 256 8 3 1 4 3.00 0.031 
8 177 157 42 10 102 4.20 0.887 
9 210 98 21 4 73 5.25 0.467 
Table 4. Human evaluation results 
Superior change 
Reference I saw that some items are on sale on window . what are they ? 
Baseline 
What kind of items do you have this item in OOV some discount, I get a 
discount ? 
Split 
You have this item in OOV some discount . what kind of items do I get 
a discount ? 
Insignificant 
change 
Reference What is necessary to be issued a new credit card? 
Baseline I ?d like to make a credit card . What do I need? 
Split I ?d like to make a credit card . What is necessary? 
Inferior change 
 
Reference 
I ?d like to make a reservation by phone and tell me the phone number 
please . 
Baseline 
I ?d like to make a reservation but can you tell me the phone number , 
please . 
Split I  ?d like to make a reservation . can you tell me the , please . 
Table 5. Example translations (The sentences are manually re-cased for readability) 
Most of the Inferior cases are caused by mis-
splitting. Mis-splitting includes a case of splitting a 
sentence that should not be split or splitting a sen-
tence on the wrong position. This case can be re-
duced by controlling the heuristics described in 
section 2.4. But the problem is that the effort to 
reducing inferior cases also reduces the superior 
cases. To compare the heuristics each other in this 
condition, we calculated the ratio of superior and 
inferior cases. The best heuristic is test no. 5 in 
terms of the ratio of sup/inf. 
The test no. 4 and 7 show that a trans-formation 
becomes very specific when lexical information is 
used alone. Hence the ratio trans/change becomes 
below 0.01 in this case.  And test no. 1 shows that 
the transformations with no environment expan-
sion are erroneous since it has the lowest ratio of 
sup/inf. 
4 Conclusion 
We introduced a transformation based sentence 
splitting method for machine translation as a effec-
tive and efficient pre-processing. A transformation 
consists of a triggering environment and a rewrit-
ing rule with position and junction type informa-
tion. The triggering environment of a transforma-
tion is extended to be error-free with respect to 
training corpus after a rewriting rule is extracted 
from manually split examples. The expanding 
process for the transformation can be generalized 
by adding POS tag information into the triggering 
environment. 
The experimental results show that the effect of 
splitting is clear in terms of both automatic evalua-
tion metric and human evaluation. The results con-
sistently state that the statistical machine transla-
tion quality can be improved by transformation 
based sentence splitting method. 
Acknowledgments 
This research was supported by the MIC (Ministry 
of Information and Communication), Korea, under 
the ITRC (Information Technology Research Cen-
ter) support program supervised by the IITA (Insti-
tute of Information Technology Assessment) (II-
TA-2006-C1090-0603-0045). The parallel corpus 
was courteously provided by Infinity Telecom, Inc. 
References 
Eric Brill. 1993. Transformation-based error-driven 
parsing. In Proc. of third International Workshop on 
Parsing.  
Eric Brill. 1995. Transformation-based error-driven 
learning and natural language processing: A Case 
Study in Part-of-Speech Tagging. Computational 
Linguistics 21(4):543-565. 
Peter F. Brown, Stephen A. Della Pietra, Vincent 
J.Della Pietra and Robert L. Mercer. 1993. The Ma-
thematics of Statistical Machine Translation: Parame-
ter estimation. Computational Linguistics, 19(2):263-
312. 
Takao Doi and Eiichiro Sumita. 2004. Splitting input 
sentence for machine translation using language 
model with sentence similarity. In Proc. of the 20th 
international conference on Computational Linguis-
tics. 
Osamu Furuse, Setsuo Yamada and Kazuhide Yamamo-
to. 1998. Splitting Long or Ill-formed Input for Ro-
bust Spoken-language Translation. In Proc of the 36th 
annual meeting on Association for Computational 
Linguistics. 
Reinhard Kneser and Hermann Ney. 1995. Improved 
backing-off for m-gram lnguage modeling. In Proc. 
of the International Conference on Acoustics, Speech, 
and Signal Processing (ICASSP). 
Philipp Koehn. 2004. Pharaoh: a beam search decoder 
for phrase-based statistical machine translation mod-
els. In Proc. of the 6th Conference of the Association 
for Machine translation in the Americas. 
Philipp Koehn, Franz Josef Och and Kevin Knight. 
2003. Statistical Phrase-Based Translation. In Proc of 
the of the 2003 Conference of the North American 
Chapter of the Association for Computational Lin-
guistics on Human Language Technology. 
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: A method for automatic 
evaluation of Machine Translation. Technical Report 
RC22176, IBM. 
Andreas Stolcke. 2002. SRILM - an extensible language 
modeling toolkit. In Proc. of the 7th International 
Conference on Spoken Language Processing (ICSLP). 
 Dekai Wu. 1997. Stochastic inversion transduction 
grammars and bilingual parsing of parallel corpora. 
Computational Linguistics 23(3):377-404. 
Kenji Yamada and Kevin Knight. 2001. A syntax-based 
statistical translation Model. In Proc. of the confe-
rence of the Association for Computational Linguis-
tics (ACL). 
 
NAACL HLT Demonstration Program, pages 7?8,
Rochester, New York, USA, April 2007. c?2007 Association for Computational Linguistics
POSSLT: A Korean to English Spoken Language Translation System 
 
 
Donghyeon Lee, Jonghoon Lee, Gary Geunbae Lee 
Department of Computer Science and Engineering 
Pohang University of Science & Technology (POSTECH) 
San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea 
{semko, jh21983, gblee}@postech.ac.kr 
 
 
 
 
Abstract 
The POSSLT 1  is a Korean to English 
spoken language translation (SLT) system. 
Like most other SLT systems, automatic 
speech recognition (ASR), machine trans-
lation (MT), and text-to-speech (TTS) are 
coupled in a cascading manner in our 
POSSLT. However, several novel tech-
niques are applied to improve overall 
translation quality and speed. Models 
used in POSSLT are trained on a travel 
domain conversational corpus. 
1 Introduction 
Spoken language translation (SLT) has become 
more important due to globalization. SLT systems 
consist of three major components: automatic 
speech recognition (ASR), statistical machine 
translation (SMT), text-to-speech (TTS). Currently, 
most of SLT systems are developed in a cascading 
method. Simple SLT systems translate a single best 
recognizer output, but, translation quality can be 
improved using the N-best hypotheses or lattice 
provided by the ASR (Zhang et. al., 2004; Saleem 
et. al., 2004). 
In POSSLT, we used an N-best hypothesis re-
ranking based on both ASR and SMT features, and 
divided the language model of the ASR according 
to the specific domain situation. To improve the 
Korean-English SMT quality, several new tech-
                                                          
1 POSSLT stands for POSTECH Spoken Language Transla-
tion system 
niques can be applied (Lee et. al., 2006-b). The 
POSSLT applies most of these techniques using a 
preprocessor. 
2 System Description 
The POSSLT was developed by integrating ASR, 
SMT, and TTS. The system has a pipelined archi-
tecture as shown in Fig. 1. LM loader, preproces-
sor and re-ranking module are newly developed to 
improve the translation quality and speed for 
POSSLT. 
 
 
Figure 1: Overview of POSSLT 
2.1 ASR 
The system used HTK-based continuous speech 
recognition engine properly trained for Korean. 
The acoustic model, lexical model and language 
model of Korean are trained for conversational 
corpus. The phonetic set for Korean has 48 pho-
neme-like-units, and we used three-state tri-phone 
hidden Markov models and trigram language mod-
7
els. Pronunciation lexicons are automatically built 
by a Korean grapheme-to-phoneme (G2P) tool 
(Lee et. al., 2006-a). We used an eojeol2 as a basic 
recognition unit for lexical and language models, 
because an eojeol-based recognition unit has the 
higher accuracy than the morpheme-based one. 
The ASR produces the N-best hypotheses deter-
mined through the decoding process, which are 
used as the input of SMT. 
2.2 SMT 
We implemented a Korean-English phrase-based 
SMT decoder based on Pharaoh (Koehn, 2004). 
The decoder needs a phrase translation model for 
the Korean-English pair and a language model for 
English. We used the Pharaoh training module and 
GIZA++ (Och and Ney, 2000) to construct the 
phrase translation table. For language modeling, 
SRILM toolkit (Stolcke, 2002) was used to build a 
trigram language model. 
2.3 TTS 
We used Microsoft SAPI 5.1 TTS engine for Eng-
lish TTS. The final best translation is pronounced 
using the engine. 
2.4 LM Loader 
In cascading SLT systems, SMT coverage depends 
on the used ASR. In order to increase the ASR 
coverage, our system loads and unloads the ASR 
language models dynamically. In our system which 
uses a travel corpus, language models are built for 
ten domain situation categories such as an airport, 
a hotel, a shopping, etc. Besides user utterances, 
user selection of the situation is needed as an input 
to decide which language model have to be loaded 
in advance. By using the divided language models, 
many benefits such as fast decoding, higher accu-
racy and more coverage can be obtained. 
2.5 Preprocessor 
In the Korean-English SMT task, there have been 
developed several techniques for improving the 
translation quality such as changing spacing units 
into morphemes, adding POS tag information, and 
deleting useless words (Lee et. al., 2006-b). 
                                                          
2 Eojeol is a spacing unit in Korean and typically consists of 
more than one morpheme. 
However, for these techniques, Part-Of-Speech 
(POS) tagger is needed. If the final analyzed form 
of an eojeol (in the form of a sequence of mor-
phemes plus POS tags) is defined as a word in the 
ASR lexicon, the transformed sentences are direct-
ly generated by the ASR only, so POS tagger er-
rors can be removed from the system. Preprocessor 
also removes useless words in SMT in the trans-
formed sentences produced by the ASR. 
2.6 Re-ranking Module  
We implemented a re-ranking module to make a 
robust SLT system against the speech recognition 
errors. The re-ranking module uses several fea-
tures: ASR acoustic model scores, ASR language 
model scores, and SMT translation scores. Finally, 
the re-ranking module sorts the N-best lists by 
comparing the total scores. 
Acknowledgements  
This research was supported by the MIC (Ministry of 
Information and Communication), Korea, under the 
ITRC (Information Technology Research Center) sup-
port program supervised by the IITA (Institute of In-
formation Technology Assessment; IITA-2005-C1090-
0501-0018) 
References  
A. Stolcke. 2002. SRILM ? An Extensible Language Modeling 
Toolkit. Proc. of ICSLP. 
F. J. Och and H. Ney. 2000. Improved statistical alignment 
models. Proc. of 38th Annual Meeting of the ACL, page 
440-447, Hongkong, China, October 2000. 
Jinsik Lee, Seungwon Kim, Gary Geunbae Lee. 2006-a. Gra-
pheme-to-Phoneme Conversion Using Automatically Ex-
tracted Associative Rules for Korean TTS System. Proc. of 
Interspeech-ICSLP. 
Jonghoon Lee, Donghyeon Lee, Gary Geunbae Lee. 2006-b. 
Improving Phrase-based Korean-English Statistical Ma-
chine Translation. Proc. of Interspeech-ICSLP. 
P. Koehn. 2004. Pharaoh: A Beam Search Decoder for 
Phrase-based Statistical Machine Translation Models. 
Proc. of AMTA, Washington DC. 
R. Zhang, G. Kikui, H. Yamamoto, T. Watanabe, F. Soong, 
and W. K. Lo. 2004. A unified approach in speech-to-
speech translation: Integrating features of speech recogni-
tion and machine translation. Proc. of Coling 2004, Geve-
va. 
S. Saleem, S. Chen Jou, S. Vogel, and T.Schultz. 2004. Using 
word lattice information for a tighter coupling in speech 
translation systems. Proc. of ICSLP 2004, Jeju, Korea. 
8
Proceedings of the SIGDIAL 2013 Conference, pages 349?353,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Counseling Dialog System with 5W1H Extraction 
 
 
Sangdo Han, Kyusong Lee, Donghyeon Lee, Gary Geunbae Lee 
Department of Computer Science and Engineering, POSTECH, South Korea 
{hansd,kyusonglee,semko,gblee}@postech.ac.kr 
 
  
 
Abstract 
In this paper, we introduce our counseling dia-
log system. Our system interacts with users by 
recognizing what the users say, predicting the 
context, and following the users? feelings. For 
this interaction, our system follows three basic 
counseling techniques: paraphrasing, asking 
open questions, and reflecting feelings. To fol-
low counseling techniques, we extracted 
5W1H information and user emotions from 
user utterances, and we generated system ut-
terances while using the counseling techniques. 
We used the conditional random field algo-
rithm to extract 5W1H information, and con-
structed our counseling algorithm using a dia-
log strategy that was based on counseling 
techniques. A total of 16 adults tested our sys-
tem and rated it with a higher score as an in-
teractive communicator compared with the 
baseline system. 
1 Introduction 
Over the past 45 years, suicide rates have in-
creased by 60% worldwide.1 To prevent suicide, 
suicide people need to counsel with counselors. 
However, counseling with a human counselor 
requires a substantial cost, and in addition, there 
is a location restriction. Developing a counseling 
dialog system could be an effective solution to 
address this problem because the system has no 
limitations with respect to time and location. 
In this study, we present a counseling dialog 
system. The system interacts with users by rec-
ognizing what the users say, predicting the con-
text, and following the users? feelings. We used 
three counseling techniques for our system, to 
interact with the users. The system performs par-
aphrasing, asks open questions, and reflects feel-
ings. 
                                                 
1 
http://www.who.int/mental_health/prevention/suicide/suicid
eprevent/en/ 
Paraphrasing is a technique that paraphrases 
user utterances. For example, when a user utter-
ance is ?My dog picked up the ball?, then it 
could be paraphrased by ?Oh, your dog picked 
up the ball?. The technique of asking open ques-
tions is to ask some questions to the user, to ob-
tain more information. For example, when a user 
says ?I played computer games?, then the coun-
selor could say ?When did you play?? or ?Where 
did you play??. Finally, reflecting a feeling is a 
similar technique to paraphrasing, but it includes 
emotional comments. For example, when a user 
says ?My dog died. I?m so sad?, then the counse-
lor could say, ?Oh, your dog died. You look de-
pressed.? or ?You look so sad?. 
In our approach, we extract 5W1H (who, what, 
when, where, why, how) information and four 
basic emotions (happy, afraid, sad, and angry) 
from user utterances. We generate system utter-
ances using 5W1H information and basic emo-
tions. 
2 Counseling Techniques 
Counselors show empathy with clients by listen-
ing and understanding them. Clients feel com-
fortable by a counselor?s attention. Counselors 
listen, ask questions, answer questions, and con-
centrate on clients. Attention and empathy is im-
portant for counseling. Counselors show interest 
and care about the clients? emotions. Our coun-
seling dialog system also focused on attending 
and empathy. 
Many counseling techniques are used in coun-
seling. Basic attending, self-expression, and mi-
cro-training skills are introduced in Theron et al 
(2008). Basic attending and self-expression skills 
are about non-verbal behavior, such as tone of 
voice and eye contact. Micro-training skills are 
the basic verbal counseling techniques that are 
learned for counseling beginners: open and 
closed questions, minimal encouragement, para-
phrasing, reflection of feelings and summariza-
tion. 
349
We chose three micro-training skills to attend 
and show empathy with clients. These skills are 
open questions, paraphrasing, and reflection of 
feelings because they are basic techniques to 
show emphasize effectively. 
3 Related Work 
The SEMAINE project aims to build a Sensitive 
Artificial Listeners (SAL) ? conversational 
agents that are designed to interact with a human 
user through robust recognition and the genera-
tion of non-verbal behavior (Schr?der et al, 
2008). This system detects user emotions by 
multimodal sensors (camera, microphone). A 
virtual face in this system shows facial expres-
sions based on user emotions, and it encourages 
the user to speak by reacting and asking ques-
tions. These techniques could show empathy 
with users. However, it has limited verbal skills 
because SEMAINE does not have language un-
derstanding module. In our research, our system 
follows user utterances and generates system ut-
terances based on user?s 5W1H. 
4 Data Collection 
We generated 4,284 utterances by using fifty-
three 5W1H information sets and four basic 
emotions (Figure 1). Each utterance could be 
generated by using part of the 5W1H information 
and four emotions. 
 
Wh When Where What How Why
My 
om
Yesterday Park Key Lost
Her pocket
was punctured
Emotion
Sad
My mom lost key yesterday.
Yesterday, my mom lost key at the park.
Sadly, my mom lost key yesterday.
My mom lost key because her pocket was punctured.
Given Situation
Collected Corpus
 
Figure 1. Counseling Corpus Collecting Process 
 
We tagged each 5W1H element in each utter-
ance and the user intention for each utterance 
(Table 1). The system?s actions were labeled by 
following counseling strategies which will be 
discussed in section 5.3. 
 
Tagged Corpus User Intention System Action
<who>My mom</who> <how>lost</how> <what>a 
key</what> <when>yesterday</when>.
Inform_5W1H Ask_Open_Question
<when>Yesterday</when>, <who>my mom</who> 
<how>lost</how> <what>a key</what> at the 
<where>park</where>.
Inform_5W1H Paraphrase
<who>My mom</who> <how>lost</how> <what>a 
key</what> <when>yesterday</when>. I?m so sad.
Inform_5W1H_
Emotion
Reflect_Feeling
I?m so sad. Inform_Emotion Reflect_Feeling
Thank you. Thank Welcome
Good bye. Bye Bye
 
Table 1.  Corpus Tagging Examples 
 
User intentions we defined can be separated in 
two groups: ?counseling? and ?others?. Utterances 
in ?counseling? group include 5W1H information 
or emotional information. Utterances which do 
not including them are in ?others? group. Greet-
ings, thanks, and farewells are included (Table 2). 
 
Couns ing group Others group
Inform_5W1H,
Inform_emotion, 
Inform_5W1H_emotion, ?
Thank, Bye, Greeting, Agree, 
Disagree,?
 
Table 2. Two Separated Groups of User Intentions 
5 Method 
5.1 Architecture 
Our system architecture is given in graph 2. 
When a user inputs a sentence, a natural lan-
guage understanding (NLU) module understands 
the main action (the user?s intention) and extracts 
the 5W1H entities from the user?s utterance. The 
emotion detection module detects the user?s 
emotions using the emotional keyword diction-
ary. The dialog management module decides the 
system?s action from the main action and the 
5W1H information from the trained module from 
the example dialog corpus. The natural language 
generation (NLG) module generates the system 
utterance using a system utterance template. We 
can generate the system utterance by replacing 
5W1H slots with entities. 
 
User
Natural 
Language 
Understanding
Dialog 
Manager
Natural 
Language 
Generation
Dialog 
Template
Emotion 
Detector
Output
Emotional 
Keyword
 
Figure 2. Counseling Dialog System Hierarchy 
350
5.2 Natural Language Understanding 
In our approach, the NLU module understands 
the user utterance by classifying the main action 
and the 5W1H entities from the user utterance. 
To classify user intention, we used maximum 
entropy model (Ratnaparkhi, 1998) trained on a 
linguistically motivated features. We used a lexi-
cal word features for the utterance model. The 
lexical word features are lexical trigrams using 
previous, current, and next lexical words. To ex-
tract 5W1H entities, we used a conditional ran-
dom field (CRF) model (Laffery et al, 2001). 
We also used lexical word features (lexical tri-
grams) to train model. 
5.3 Dialog Management with Counseling 
Strategy 
When we extract 5W1H information or user 
emotions, the dialog management module keeps 
them in the emotion slot or in the six 5W1H slots. 
This slot information is discussed in a dialog. 
The dialog management module decides the 
system?s action by the main action, the 5W1H 
entities, and the user?s emotions. Dialog man-
agement follows the rules in figure 3, which is 
our dialog strategy for the counseling system. In 
figure 3, ?Counseling group?? node finds users 
intentions included in ?others group? (rejection or 
thanks could be included). The ?User Emotion 
Detection? node figures out whether the user ut-
terance is to include emotional keywords or 
whether the user emotion is already known by 
the discourse. The ?6 slot empty? node checks 
whether the user utterance includes at least one 
of the 5W1H elements or whether the 5W1H en-
tity is already known. The ?6 slot full? node de-
cides whether the user utterance with a discourse 
has all six 5W1H entries. From this strategy, we 
can notice that we cannot reflect a user?s feeling 
without the user?s emotion. We cannot ask open 
questions when all of the 5W1H slots are filled. 
 
Yes
No
No
No
No
No
Yes
No
Yes
YesYes
Yes
6 slot 
empty
6 slot 
full
6 slot 
empty
6 slot 
full
Counseling 
group?
User 
Utterance
User 
Emotion 
Detection
Particular 
System Actions
Ask Open 
Question
Reflect
Feeling
Ask Open 
Question
Reflect
Feeling
Paraphrase
Ask Open 
Question
Paraphrase
Reflect 
Feeling
Paraphrase
Ask Open 
Question
Paraphrase
 
Figure 3. Dialog Strategy Architecture 
5.4 Emotion Detection 
The emotion detection module decides the user?s 
emotion with respect to the four basic emotions. 
To detect the user?s emotions, we find emotional 
keywords in the user?s utterances. If any emo-
tional keyword appears in a user utterance, we 
decide that the user?s emotion which includes 
that keyword. For this approach, we made a dic-
tionary of emotional keywords for each basic 
emotion. The dictionary has approximately 15 
emotional keywords for each basic emotion (Ta-
ble 3). 
 
E otion Keywords
Happy happy, joy, glad, pleasure, ?
Sad sad, depress, grief, sorrow,?
Angry anger, rage, indignation, wrath, ?
Afraid afraid, fear, terror, dread, ?
 
Table 3. Emotional Keywords for Emotions 
5.5 Natural Language Generation 
The NLG module generates the system?s utter-
ances by selecting an utterance template from the 
template database. There are various system 
templates for each system action, for the 5W1H 
slot entities, and for the user?s emotions (Figure 
4). When the system template is chosen, we can 
generate system utterances by replacing the 
5W1H slot with a 5W1H discourse. ?O? means 
we should have the entity, ?X? means we do not 
have the entity, and ?*? means we do not care 
whether we have the entity or not. 
 
Who When Where What How Why Emotion System Action
O X O O O X O Reflect Emotion
O X O O O X * Paraphrase
System Action System Template
Reflect Emotion Oh, <who> <how> <what>. You look so sad.
Paraphrase Oh, did <who> <how> <what>?
System Utterance
Oh, your mom lost a key. You look so sad.
Oh, did your mom lost a key?
Who When Where What How Why
My 
mom
Yesterday Park Key Lost
Her pocket
was punctured
Emotion
Sad
 
Figure 4. System Utterance Generation 
 
Our overall counseling dialog example is shown 
in (Table 4). 
351
 User My mom lost a key yesterday.
System Oh, where did you mom lost a key?
User At the park.
System Your mom lost a key at the park, right?
User Yes, that?s right. I?m so sad.
System You look so sad. Cheer up.
User Thank you.
System My pleasure.
 
Table 4. Counseling Dialog Example 
6 Experiment 
We measured how systems show empathy with 
users. Our baseline system is a Korean chat-
oriented dialog system (Kim et al, 2012). The 
chat-oriented dialog system shows empathy by 
understanding user utterances and making a con-
versation. In our experiment, 7 basic situations 
are given for each person. Situations are ex-
plained by 5W1H, and users generated various 
utterances using that information. Each person 
generated approximately 100 utterances during 
30 minutes and made estimates for each system. 
We recruited 16 volunteers to use our system and 
to estimate its effectiveness. Each user checked 
17 questions from 1 to 10. The questions ask us-
ers how does each system understand the user 
utterance, is it appropriate for counseling, and 
does it satisfy the users (Table 5). 
 
Question
Chat-
Oriented
Counseling
1-1. The system used counseling techniques: 
paraphrasing, open question, reflect feeling.
3.50 7.06
1-2. The system knows my emotion. 3.44 6.88
1-3. There was no break in the conversation. 2.63 6.88
1-4. The system acts like a counselor. 2.88 6.69
1-5. The system shows empathy with me. 4.69 7.31
1-6. I feel the system understands me. 2.56 6.50
2-1. The system understands what I said. 2.88 6.81
2-2. The system understands 5W1H information. 4.13 7.44
2-3. System utterances are appropriate. 2.75 6.94
2-4. System utterances have no problem. 3.50 5.50
3-1. I could speak about various situations. 4.31 6.38
3-2. I had a casual conversation. 4.75 6.88
3-3. Scenarios look expandable. 5.50 7.63
4-1. I satisfied overall conversation. 3.10 6.56
4-2. I satisfied overall counseling. 2.38 6.56
4-3. The system looks appropriate as a counselor. 2.50 6.38
4-4. I?ll recommend the system as a counselor to my
friends.
2.31 5.38
Mean 3.40 6.69
Standard Deviation 0.96 0.59
 
Table 5. Experiment Results 
 
Questions 1-1 to 1-6 ask users how each sys-
tem is appropriate as a counselor. Counseling 
system rated 6.89 for mean. Questions 2-1 to 2-4 
are about users? tterances understandability. In 
these questions, counseling system rated 6.67 on 
the average. Questions 3-1 to 3-3 show how var-
ious dialogs covered. Our system got 6.96 for 
mean. Finally, questions 4-1 to 4-4 are about 
overall satisfaction. These questions rated 6.22 
for mean. Our p-value through t-test was 
3.77*10-11. 
Counseling system got higher score than chat-
oriented system because users felt empathy better 
with our system than baseline system. As a coun-
selor, counseling system is much better than 
chat-oriented system. Our baseline system was 
not appropriate as a counselor because it rated 
3.39 for average. However, our system scored 
over 6.5 overall. It means our system is valuable 
as a counselor.  
7 Conclusion 
In this study, we introduced counseling tech-
niques that we used to implement counseling 
dialog system. The experimental results showed 
that our system shows empathy with users. Alt-
hough the results of this study bring us a step 
closer to implementing counseling dialog system, 
the results are only valid with 5W1H information 
in Korean. Our future works are to improve our 
counseling dialog system using new NLU mod-
ule which extracts 5W1H information from more 
general utterances, with new emotion detection 
method, and with more counseling techniques. 
 
Acknowledgments 
This research was supported by the Basic Sci-
ence Research Program through the National Re-
search Foundation of Korea(NRF) funded by the 
Ministry of Education, Science and Technolo-
gy(2012-0008835). 
This research was supported by the 
MSIP(Ministry of Science, ICT&Future Plan-
ning), Korea, under the ITRC(Information Tech-
nology Research Center) support program super-
vised by the NIPA(National IT Industry Promo-
tion Agency) (NIPA-2013-H0301-13-3002) 
References  
Kim, Y., Noh, H., & Lee, G. G. (2012). Dialog man-
agement on chatting system based on lexico-
syntactic patterns and named entity types. Proceed-
ings of Spring Conference of Korean Society of 
Speech Sciences, 41-42,  Seoul, Korea. 
352
Lafferty, J., McCallum, A., & Pereira, F. (2001). 
Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. 
Proceedings of the 18th International Confer-
ence on Machine Learning, 282-289. 
Ratnaparkhi, A. (1998). Maximum entropy models 
for natural language ambiguity resolution. 
Computer and Information Science, University 
of Pennsylvania, Philadelphia, USA.  
Schr?der, M., Cowie, R., Heylen, D., Pantic, M., Pe-
lachaud, C., & Shuller, B. (2008). Towards re-
sponsive sensitive artificial listeners. Workshop 
on Human-Computer Conversation, Bellagio, Italy. 
Theron, M. J. (2008). A manual for basic relational 
skills training in psychotherapy. Masters of Arts 
in Clinical Psychology, University of South Africa, 
South Africa. 
353
