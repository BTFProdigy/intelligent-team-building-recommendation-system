Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 656?666, Dublin, Ireland, August 23-29 2014.
Knowledge Sharing via Social Login: Exploiting Microblogging Service
for Warming up Social Question Answering Websites
Yang Xiao
1
, Wayne Xin Zhao
2
, Kun Wang
1
and Zhen Xiao
1
1
School of Electronics Engineering and Computer Science, Peking University, China
2
School of Information, Renmin University of China, China
{xiaoyangpku, batmanfly}@gmail.com
{wangkun, xiaozhen}@net.pku.edu.cn
Abstract
Community Question Answering (CQA) websites such as Quora are widely used for users to get
high quality answers. Users are the most important resource for CQA services, and the awareness
of user expertise at early stage is critical to improve user experience and reduce churn rate.
However, due to the lack of engagement, it is difficult to infer the expertise levels of newcomers.
Despite that newcomers expose little expertise evidence in CQA services, they might have left
footprints on external social media websites. Social login is a technical mechanism to unify
multiple social identities on different sites corresponding to a single person entity. We utilize the
social login as a bridge and leverage social media knowledge for improving user performance
prediction in CQA services. In this paper, we construct a dataset of 20,742 users who have
been linked across Zhihu (similar to Quora) and Sina Weibo. We perform extensive experiments
including hypothesis test and real task evaluation. The results of hypothesis test indicate that
both prestige and relevance knowledge on Weibo are correlated with user performance in Zhihu.
The evaluation results suggest that the social media knowledge largely improves the performance
when the available training data is not sufficient.
1 Introduction
One of the main challenges for social startup websites is how to gain a considerable number of users
quickly. A growing number of social startups outsource sign-up process to existing social networking
services. They allow users to log in to the services using their existing social media accounts. For exam-
ple, Quora allows users to log in with their Google, Twitter or Facebook accounts based on the OpenID
technology. Lots of startup web services benefit from the huge number of users and rich relationships
accumulated by social network sites. Social login helps the newborn web services to collect crowds of
users in a short time. Moreover, startup web services can gain reliable profiles through social login. It
also offers a convenient mechanism for users to surf the web using a unified social identity (e.g., Twit-
ter account). For example, by the end of 2013, there are about 600,000 web services including mobile
applications using social login offered by Sina Weibo.
When we go beyond simple import of profiles and consider the general problem of leveraging knowl-
edge from social media, many subtasks arise. One of them is how to incorporate data from social media
and startup web service to better predict user performance. In this paper, we take the largest social based
question answering service Zhihu in China, which closely resembles Quora, as the testbed. Different
from traditional CQA sites such as Baidu Zhidao, Zhihu have more prominent social features, which
supports login with Sina Weibo accounts. Although Zhihu grows quickly and attracts more and more
users, about 85% of the users answer fewer than 10 questions and 60% of the users answer fewer than 4
questions in our dataset, which is a large sample of Zhihu.
Previously, many studies have been proposed to improve expertise ranking on CQA services. Link
analysis based approaches (Jurczyk and Agichtein, 2007; Zhang et al., 2007) exploit the question-
answering relationships to construct a graph and run PageRank or HITS on the graph. Jeon et al. (2006)
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
656
propose a method based on the non-textual behaviors. Moreover, co-training model (Bian et al., 2009)
jointly infers answer quality and user expertise. Liu et al. (2011) formalize expertise ranking as a com-
petition game with the insight that the best answerer beats other answerers in the same question thread.
However, the above studies highly rely on the history data, which might not work well for newcomers or
users with few answering records. For startup services, many users may not accumulate sufficient data to
support the reliable estimation for their expertise levels. Indeed, the importance of newcomers has been
noted in related studies, and it has been shown that the effective evaluation of users? performance at an
early stage significantly affects the overall development of QA services (Nam et al., 2009; Sung et al.,
2013).
In this paper, we propose a method that incorporates social media and social startup data to predict
newcomers? performance. This problem is technically challenging due to the heterogeneous charac-
teristics across websites. Given a user, we hypothesize that her capability of contributing high quality
answers is dependent on her prestige and relevance. The more contents a user publishes on an area and
the higher prestige a user has on social media sites, the higher likelihood that user can offer high quality
answers. Thus, the first goal is to precisely measure the relevance between question and a user?s tweets.
Owing to the short question length and noisy tweet content, this problem brings technical challenges.
We make use of user-annotated tags and adopt a translation based model to improve relevance estima-
tion. For prestige, a straightforward way is to use the standard graph based ranking algorithm, however,
Zhihu users have very sparse links on Weibo and the standard PageRank algorithm does not work well
on sparse graphs. To address it, we add virtual links to alleviate the sparsity problem by finding available
paths on a large Weibo graph. Furthermore, we propose a performance biased random walk algorithm
and naturally incorporates Zhihu performance history as the supervised information.
We carefully construct a dataset of 20,742 users who have been linked across Zhihu and Weibo, which
represent the social startup and the social media site respectively. We first conduct Spearman correlation
test for these two hypotheses. Our results have shown that prestige in Weibo has a strong correlation with
overall performance in Zhihu. For the performance in question level, we have found that the relevance
of Weibo contents is also significantly correlated with answer quality in Zhihu. Based on these findings,
we further incorporate the extracted prestige and relevance knowledge into the existing framework for
user performance prediction. To simulate the process of history data accumulation, we also conduct
experiments with the varying observed number of answers. The experiment results suggest that the
borrowed social media knowledge, i.e., prestige and relevance information in Weibo, largely improves
the performance when the available training data is not sufficient. Interestingly, we have found that even
individual prestige feature can achieve very competitive results.
Although our approach is tested on a joint combination of Weibo and Zhihu, it is equally applicable
to other knowledge sharing startup web services. The flexibility of our approach lies in that we identify
two important and general types of knowledge that are easy to leverage from external social media sites.
The rest of this paper is organized as follows. The construction of the dataset collection and the
problem formulation are given in Section 2 and 3 respectively. Section 4 presents the detailed feature
engineering and is followed by the experiment part in Section 5. Finally, the related work and conclusions
are given in Section 6 and 7 respectively.
2 Construction of the Dataset Collection
We focus on a popular social question answering website, Zhihu as the studied service. We select Sina
Weibo, the largest Chinese microblogging service as the external website to help improve user exper-
tise estimation task in Zhihu. We exploit the social login mechanism to identify the same user across
these two platforms: if a user logs in Zhihu with her Weibo account, her Zhihu profile will contain the
corresponding Weibo account link. This approach accurately links users across websites.
Zhihu dataset. Zhihu
1
is a social based question answering site in China, which is similar to Quora in
terms of overall design and service. Zhihu has three major components: users, questions, and topics.
Users on Zhihu can ask and answer questions, furthermore, they can comment on or vote for answers.
1
http://www.zhihu.com
657
Each question is usually assigned with a small set of topic tags by the asker and opens a discussion thread
consisting of candidate answers. Topics are represented as tags and organized in a directed acyclic graph
where a child topic can have multiple parent topics.
Zhihu was founded in January 2011, and we obtain the data between January 2011 and November
2013 via a Web crawler. The dataset contains 266,672 users, 819,125 questions and 2,730,013 answers.
These questions are associated with 44,333 topic tags. Since the aim is to examine whether knowledge
extracted from Weibo is helpful to improve tasks in Zhihu, we only keep the users who explicitly use
social login and get 136,002 cross-site users, which roughly covers 50% of the users in our dataset. For
a robust evaluation, we further remove users who have answered fewer than ten questions. Finally, we
obtain a total of 20,742 users and summarize the data statistics in Table 1.
#users #topics #questions #answers
20,742 44,333 335,145 883,373
Table 1: Basic statistics of Zhihu dataset for linked users.
Weibo Dataset. Sina Weibo is the largest Chinese microblogging service which has about 500 million
registered users by the end of 2012. We have crawled all the detailed information of these 20,742 linked
users, including tweets, followers, and following links. These users are indeed active on Weibo and have
posted 21,121,955 tweets in total. In later sections, we will adopt the PageRank algorithm to estimate the
prestige scores of these linked users, thus we need a dense following graph for reliable estimation. By
using these linked users as seeds, we further crawl their followings and followers as well as the following
links between all the crawled users. Finally, we obtain 253,361,449 edges between 1,322,425 users. Note
that we only use these 20,742 linked users for further study, and the rest are only used to help compute
more accurate PageRank scores.
In what follows, we refer to a user who has both a Weibo account and a Zhihu account in our dataset
as a linked user.
3 Problem Formulation
Users are the most valuable resource in community question answering (CQA) services. Discovering
users? expertise at an early stage is important to improve the service quality. A typical task on CQA
services is to predict users? performance or expertise: given a question, it aims to estimate the user
expertise level and identify experts who can provide good answers to this question.
Borrowing the ideas from information retrieval, we solve the performance prediction task via the
learning to rank framework (Liu, 2009). Formally, we assume that there are a set of m questions (i.e.,
queries)Q = {q
(1)
, q
(2)
, q
(3)
, ...q
(m)
}. A question is associated with a set of n
(i)
answers {a
(i)
1
, ..., a
(i)
n
(i)
}
provided by n
(i)
users {u
(i)
1
, ..., u
(i)
n
(i)
} respectively. For each user, let y
(i)
j
denote the performance score
of user u
(i)
j
with respect to query q
(i)
. A higher value of y
(i)
j
indicates better performance for query
q
(i)
. In our work, we instantiate the performance score by the number of votes that a user receives on a
question. A feature vector x
(i)
j
is constructed based on a pair of question and user (q
(i)
, u
(i)
j
). The aim
of the learning task is to derive a ranking function f such that, for each feature vector x
(i)
j
, it outputs a
prediction score f(x
(i)
j
) for the performance of user u
(i)
j
on the question q
(i)
. With this function, when a
new question comes, we can predict who will be competent at it.
For prediction tasks, the answer information {a
(i)
1
, ..., a
(i)
n
(i)
} is not available during training. Besides
users? accumulated history data on Zhihu, external knowledge from Weibo is available to help construct
the query-user feature vector. We assume that the studied Zhihu users have already been linked to
the corresponding Weibo accounts, and we can obtain their Weibo information, including tweets and
followings/followers. The key of the learning to rank framework is how to derive effective features. In
our task, we consider two types of features, i.e., Zhihu features and Weibo features. Our focus in this
paper is how to leverage microblogging information for improving CQA service, i.e., how to incorporate
knowledge from Weibo as features into the learning to rank framework.
658
4 Feature Engineering
In this section, we discuss how to derive effective features from both Zhihu and Weibo. In particular, we
mainly study how to leverage Weibo knowledge for the current task.
4.1 Weibo features
In our work, we focus on two types of Weibo features: prestige and relevance. For prestige, it aims to
capture the social status of a user. In our setting, it refers to the status or authority level of a user on online
social networks (Anderson et al., 2012). We hypothesize that a user is likely to have similar status levels
across multiple online communities, thus the prestige scores of Zhihu users can be roughly estimated
based on the rich link information of Weibo. The second type of knowledge we consider is relevance.
A user is more likely to be an expert on an area that she is interested in, and Weibo provides a good
platform to identify users? interests. Since Weibo and Zhihu are text based websites, we hypothesize that
a user will show similar interests on these two medias.
Prestige. Prestige features aim to capture the status of one user. Status characteristic theory posits
that one with higher status characteristic is expected to perform better in the group task (Oldmeadow
et al., 2003). Prestige estimation has been a classical problem in both web graph analysis and social
networking analysis (Easley and Kleinberg, 2012). We are motivated by previous study on authority
ranking in Twitter (Kwak et al., 2010), which utilizes the following relations as the evidence of authority.
A straightforward way is to run standard PageRank algorithm on the Weibo subgraph consisting of these
20,742 linked users. However, the subgraph of these linked users is very sparse, each linked user has
only about 5 out-links to other linked users on average. Such a sparse graph will not produce meaningful
ranking results.
Our solution is to add virtual links between linked users. Let N (N = 20, 742) denote the number
of linked users andM
N?N
denote the transition matrix based on the graph of these linked users. Given
two users u
i
and u
j
, we check whether there is a directed path between them on our large Weibo graph.
Recall that we have 253,361,449 edges between 1,322,425 users in Weibo dataset. We run the breadth-
first search algorithm to find the shortest path between two linked users. If there exists a directed path
between two linked users, we add a virtual link between them and set the weight to the reciprocal of the
shortest path length, i.e., I(i, j) =
1
len(u
i
?u
j
)
, where len(u
i
? u
j
) denotes the length of the shortest
path between u
i
and u
j
. In this way, we have M
ij
=
I(i,j)?
k
I(i,k)
. By adding virtual links, we obtain a more
dense graph of these linked users. Formally, the standard PageRank algorithm (Brin and Page, 1998) can
be formulated as:
r
(n+1)
= ? ?M
T
? r
(n)
+ (1? ?) ? y (1)
where ? is the damping factor usually set to 0.85 and y is the restart probability vector usually set to be
uniform (Yan et al., 2012). When the algorithm converges, we can obtain the stationary distribution of
users (i.e., r) as the prestige scores.
The above method assumes that users have same restart probability, which may not be true in reality.
Since we are considering improving Zhihu service quality, we incorporate users? history data from Zhihu
as supervised information. The main idea is that instead of using a uniform restart distribution y, we use
a performance biased restart distribution in Eq. 1. We set the restart probability of a user to her average
vote ratio based on the questions she has answered. Formally, we set y
u
= Average(
?
q
#vote(q,u)?
v
#vote(q,v)
),
where #vote(q, u) denotes the number of votes user u receives on question q and
?
v
#vote(q, v)
denotes the total number of votes that all users receive on question q. We do not use other measures such
as best answer ratio because we assume that the history window is very limited and our proposed method
provides more robust estimation. Let us further explain the idea. At the beginning of each iteration,
each user is assigned to her performance score estimated based on Zhihu data: the more competent she
is, the larger score she has. During the iteration, each user begins to collect authority evidence from
her incoming neighbors on the Weibo graph. The final score is indeed a trade-off between her own
performance on Zhihu and her authority on Weibo.
659
There are also other measures to consider, e.g., the follower number and the times of being retweeted.
In our experiments, we have tried these variants and found that no one is more effective than the above
method.
Relevance. Intuitively, a user is more likely to be an expert on an area that she is interested in. In
the setting of Zhihu, a user tends to perform better on the topics that are more relevant to her interests.
Status characteristic theory also conveys that task relevance is an important factor which affects one?s
performance (Oldmeadow et al., 2003). Weibo provides a good platform to infer users? interests, which
is helpful to derive relevance scores.
We formulate relevance estimation as an information retrieval task. Let V denote a term vocabu-
lary and w denote a word in V . Note that we take the union of the Weibo vocabulary and Zhihu vo-
cabulary. The interest of a user u is modeled as a multinomial distribution over the terms in V , i.e.,
?
u
= {?
u
w
}
w?V
. Given a question q, we also model it as a multinomial distribution over the terms in V ,
i.e., ?
q
= {?
q
w
}
w?V
. Following (Zhai, 2008), the relevance score between question q and user u can be
estimated by the negative Kullback-Leibler divergence between ?
q
and ?
u
:
Rel(q, u) = ?KL(?
q
, ?
u
) = ?
?
w?V
p(w|?
q
) log
p(w|?
q
)
p(w|?
u
)
(2)
We first estimate ?
q
. The straightforward way is to estimate ?
q
based on the question text. However, the
question text is usually short and noisy, which does not yield good results in our experiments. Recall a
question is associated with a small set of user-annotated topic tags, and tags are good semantic indicators
of the question. A topic tag usually indexes a considerable amount of questions, and we can use tags to
leverage semantics from the indexed questions. Formally, we adopt the translation based model (Zhai,
2008) to estimate the question model:
?
q
w
?
?
t?q
p(w, t|q) =
?
t?q
p(w|t)p(t|q) (3)
where p(w|t) is the translation probability from a tag to a term, and p(t|q) is the empirical distribution of
tag t in question q. Here we make an independent assumption: given a tag, the question is independent
of a word, i.e., p(w|t, q) = p(w|t). The procedure can be interpreted as follows: sample a tag from the
question and then compute the probability of translating the tag into a specific word. We estimate the tag-
term translation probability as p(w|t) =
#(w,t)+1?
w
?
?V
#(w
?
,t)+|V|
, where #(w, t) denotes the term frequency
of w in the question text that tag t indexes. We use the additive-one smoothing.
We also try to incorporate the question text into the above estimation formula. However, it does
not result in any improvement. The main reason is that the question words may be too specific, as
a comparison, tags provide a general level of semantics, which is more effective to identify expertise
areas.
Next, we estimate user interest model ?
u
. We consider aggregating all the tweets of a user as a ?doc-
ument?, and then estimate the document-term probability as ?
u
w
=
#(w,u)+1?
w
?
?V
#(w
?
,u)+|V|
, where #(w, u)
denotes the term frequency of w in the aggregated document of user u.
4.2 Zhihu features
Now we describe the features extracted from Zhihu, and we refer to them as baseline features since we
take the performance of them as a base reference. We summarize these features in Table 2.
These features have been extensively tested to be very effective by previous related studies (Song et
al., 2010; Liu et al., 2011), which represent the state-of-art of the current task.
Summary. We have considered two general types of knowledge in social media which are potential to
improve user expertise estimation in Zhihu. It is easy to see that our approach can be equally applicable
to other third-party websites which is text based and contain manually annotated tags.
660
Features Abbr Formulas
Number of Best Answers NBA ?
Number of Answers NA ?
Number of Received Votes NV ?
Average Number of Votes AVA ?
Smoothed Average number of Votes SAVA SAVA(u) =
?
q
?(v(q,u))
NA(u)
, ?(x) =
1
1+e
(?x)
Best Answer Ratio BAR BAR(u) =
NBA(u)
NA(u)
Smoothed Best Answer Ratio SBAR SBAR(u) =
BAR(u)?NA(u)+BAR
avg
?NA
avg
NA
avg
+NA(u)
Average Answer Length AAL ?
Table 2: List of baseline features with corresponding abbreviations and formulas. Here u denotes a Zhihu
user.
5 Experiment
Questions with fewer than five answerers do not receive much attention, and we only keep questions
which involve at least six users. In this way, we have obtained a total of 25,262 questions. The number
of votes is used as the measure of answer quality. The question threads are sorted by the post time, and
we can simulate the cold-start phenomenon to examine the performance of different methods. We split
the dataset into a training set and a test set by question threads with the ratio of 3:1. The ?history? data
of a user is put into the training set and the rest is treated as test data. We further vary the size of ?history
data? that can be used for performance prediction in three levels, i.e., at most 3, 5, and 10 ?historical?
question threads have been observed for a given user.
5.1 Hypothesis Testing
In this part, we first examine the fundamental hypotheses of our work: whether Weibo knowledge is
potentially effective to improve the performance of tasks in Zhihu. We conduct significance test to
examine the correlation between user features extracted from Weibo and user performance in Zhihu. We
adopt the Spearman?s rank correlation coefficient as the test measure. For a sample of size n, the n raw
scores X
i
, Y
i
are converted to ranks x
i
, y
i
, and the Spearman correlation coefficient ? is computed as
? = 1 ?
6
?
i
d
2
i
n(n
2
?1)
, where d
i
= x
i
? y
i
. The Spearman?s coefficient ? lies in the interval [?1, 1], and a
value of ?+1? or ?-1? indicates a perfect, positive or negative Spearman correlation.
Test of prestige. In our test, the overall performance of a user is estimated by the average vote counts she
receives per answer, and the prestige level of a user is estimated by her PageRank score on the original
Weibo following graph with a uniform restart probability. With these two measures, it is straightforward
to generate two rankings of users, either by user prestige level or by user performance. However, it is
noted that ? is usually very sensitive when the sample size is too large, and it is difficult to obtain robust
correlation values in this case. To better capture the overall correlation patterns, we group users according
to their prestige levels and examine the correlation degree in the group level. We sort users according to
their PageRank scores in a descending order, and split users equally into 100 buckets. The correlation
value between performance and PageRank is ? = 0.5617 at the significance level of 9.879e
?10
, which
indicates there is a strong correlation between performance and prestige.
Test of relevance. Different from prestige, relevance is defined to be question specific, so we cannot
perform global correlation analysis. We perform the correlation analysis in the question level. For
each question, we have two rankings of involved users: the relevance ranking and the question-specific
performance ranking. Let ? denote the correlation coefficient between the relevance ranking and the
performance ranking for a given question. Formally, given a question, we have the null hypothesis H
0
being ?? is zero?, whereas H
1
being ?? is not zero?. If H
0
is rejected, we can conclude that prestige
in Weibo is correlated with users? performance on Zhihu for the given question. Our experiments have
shown that 14.48% of the questions rejected the H
0
hypothesis at the confidence level of 0.9.
661
5.2 Evaluation metrics
In the above, we have shown that prestige and relevance knowledge extracted from Weibo are correlated
with user performance in Zhihu. Next we are going a step further to examine the feasibility of using
these external features to improve user performance ranking in CQA service. In this paper, we consider
studying this problem in two aspects: in the first case, we only focus on the user who provides the best
answer; while in the second case, we focus on the overall ranking of all engaged answerers in a given
question thread. By following previous studies (Song et al., 2010; Deng et al., 2012), we adopt traditional
evaluation metrics in information retrieval for evaluating user performance prediction in CQA services.
Best answer prediction. Our first task is to predict which user will provide the best answer given a
question. The user who has received the maximum vote counts in a question thread will be labeled as
relevant and the rest will be treated as non-relevant. Then we can adopt the widely used relevance metrics
Precision at rank n (P@n) and Mean Reciprocal Rank (MRR).
Top expert recommendation. Unlike best answer prediction, top expert recommendation aims to pro-
vide a short list of candidate experts given a question. By following the study (Liu et al., 2011), we use
nDCG (normalized Discounted Cumulative Gain) as the evaluation metrics. Let vote(i) denote the vote
counts of the answer ranked at i in a system output. To reduce the effects of large outliers, we set the
gain value for an answer with the vote counts v to be log(v + 1). The metrics are formally defined as
follows:
DCG@n =
n
?
i=1
log(vote(i) + 1)
log(i+ 1)
(4)
maxDCG@n =
n
?
i=1
log(vote
?
(i) + 1)
log(i+ 1)
(5)
nDCG@n =
DCG@n
maxDCG@n
(6)
where vote
?
denotes the vote counts list of the ideal ranking system, i.e., the answer list is sorted by vote
counts in the descending order.
Similar to query-specific information retrieval tasks, all our experiments are question specific. For
a system, we evaluate its performance of each question and then average all the results as the final
performance.
5.3 Results
As studied in Section 3, the above two tasks can be formulated as the learning to rank problem. Following
previous work (Song et al., 2010), we adopt SVMRank as the ranking model and implement SVMRank
using the tool package SVMLight
2
. We use the linear kernel for SVMRank, and report the results in
Table 3 and Table 4.
We refer to the system with all Zhihu features as Baseline. We use two ways to compute prestige
features: P+UniformG denotes the system which implements the standard PageRank algorithm with
uniform restart probability, while P+HisG denotes the system which implements the biased PageRank
algorithm with users? history performance on Zhihu as the restart probability. Rel denotes the system
with only relevance features and Baseline+Weibo denotes the system with all the features.
Analysis of baseline results. The baseline system is built with all Zhihu features, which are estimated
using history data, and it is natural to see that the performance of the baseline system improves with
the increasing of the history data. Recall that all the question threads in our dataset contain more than
six answers, indeed, 36.3% of them contain more than ten answers. A random algorithm to guess the
best answer can only achieve a poor P@1 value of 11.07%. Results in Table 3 and Table 4 show that
our baseline is competitive even on long question threads. In our experiments, the system performance
begins to stay stable when the history window is set to ten question threads since quite a few users have
engaged in fewer than ten question threads.
2
http://svmlight.joachims.org
662
History Window Size Systems NDCG@1 NDCG@3 NDCG@5
NULL P+UniformG 0.510 0.555 0.621
Rel. 0.360 0.434 0.519
?3 question threads (B)aseline 0.508 0.582 0.656
P+HisG 0.550 0.596 0.658
B.+Weibo 0.580 0.617 0.676
vs. B.
+14.17%
??
+6.01%
???
+3.05%
???
?5 question threads (B)aseline 0.509 0.578 0.658
P+HisG 0.556 0.603 0.668
B.+Weibo 0.589 0.625 0.687
vs. B.
+15.72%
???
+8.13%
???
+4.41%
???
?10 question threads (B)aseline 0.534 0.602 0.671
P+HisG 0.568 0.616 0.679
B.+Weibo 0.595 0.637 0.696
vs. B.
+11.42% +5.81% +3.73%
?
Table 3: Overall ranking performance with varying history window sizes. ?*?, ?**?, ?***? indicate the
improvement is significant at the level of 0.1, 0.05 and 0.01 respectively.
Analysis of the effect of Weibo features. We now incorporate Weibo features and check whether they
can help improve the system performance. In Table 3 and Table 4, we present the improvement ratios
over baselines with the incorporation of Weibo features. We can see that Weibo features yield a large
improvement over the baseline system, especially when the size of history window is small, i.e., ?3
question threads. This indicates the effectiveness of Weibo features on alleviating the cold-start problem
in Zhihu. When we have more history data, i.e.,?10 question threads, the improvement becomes smaller.
It is noteworthy that the single prestige feature (i.e., P+UniformG and P+HisG) achieves good per-
formance. Especially, P+HisG obtains very competitive results compared with the baseline system.
P+HisG naturally combines history data on Zhihu and prestige information on Weibo, which largely
improves the standard prestige estimation method P+UniformG. As a comparison, the relevance feature
is not that effective but still improves the overall performance a bit. These findings indicate that the
incorporation of social media data can be a very promising way to improve the tasks of startup services.
History Window Size Systems MRR P@1 P@3
NULL P+UniformG 0.457 0.261 0.544
Rel. 0.353 0.157 0.404
?3 question threads (B)aseline 0.474 0.263 0.589
P+HisG 0.498 0.303 0.604
B.+Weibo 0.516 0.323 0.624
vs. B.
+8.86%
???
+22.81%
??
+5.94%
??
?5 question threads (B)aseline 0.478 0.271 0.590
P+HisG 0.501 0.303 0.613
B.+Weibo 0.521 0.327 0.627
vs. B.
+9.00%
???
+20.66%
???
+6.27%
???
?10 question threads (B)aseline 0.494 0.286 0.612
P+HisG 0.514 0.316 0.627
B.+Weibo 0.530 0.332 0.643
vs. B.
+7.29% +16.08% +5.07%
Table 4: Best answer prediction performance with varying history window sizes. ?*?, ?**?, ?***?
indicate the improvement is significant at the level of 0.1, 0.05 and 0.01 respectively.
663
6 Related Work
Our task is built on community question and answering site and researchers have studied CQA from
many perspectives. One perspective focuses on user expertise estimation. Generally, there are two prin-
ciple methods for expertise ranking, interaction graph analysis and interest modeling. Interaction graph
based methods (Jurczyk and Agichtein, 2007; Zhang et al., 2007) construct a graph using interaction(e.g.,
asking and answering) behavior, and rank users using some generalization of PageRank (Brin and Page,
1998) or HITS (Kleinberg, 1999). Interest modeling methods characterize users? interests using ques-
tion category (Guo et al., 2008) or latent topic modeling (Liu et al., 2005). There are also methods that
combine both interest modeling and graph structure (Zhou et al., 2012; Yang et al., 2013) to rank users.
Another research perspective on question answering service is quality prediction including answer qual-
ity prediction (Harper et al., 2008; Shah and Pomerantz, 2010; Severyn and Moschitti, 2012; Severyn
et al., 2013) and question quality prediction (Anderson et al., 2012). However, since the methods men-
tioned above are based on the history data, the system will experience the cold start problem. Our work
explore to what extent can external features help relieve the problem.
This work is also concerned with mining across heterogeneous social networks. Recently, many re-
searches focus on mapping accounts from different sites to one single identity (Zafarani and Liu, 2013;
Liu et al., 2013; Kong et al., 2013). By utilizing these recent studies on linking users across communities,
our work can be extended to larger scale datasets. From another perspective, cross-domain recommen-
dation has also been widely studied. Zhang et al. (Zhang and Pennacchiotti, 2013a; Zhang and Pennac-
chiotti, 2013b) explore how Facebook profiles can help boost product recommendation on e-commerce
site. Previous work (Zhang et al., 2014) analyze user novelty seeking traits on social network and e-
commerce site, which can be used to personalized recommendation and targeted advertisement. Dif-
ferent from simply borrowing user?s profiles or psychological traits, our work integrates user footprints
from heterogenous social networks and captures performance related characteristics more precisely.
7 Conclusion
In this paper, we take the initiative attempt to leverage social media knowledge for improving the social
startup service. We carefully construct a dataset of 20,742 users who have been linked across Zhihu and
Weibo, which are social startup and external social media websites respectively. We hypothesize that a
user with higher prestige and more relevant Weibo contents to a question is more likely to have better
performance.
We first carefully construct testing experiments for these two hypotheses. Our results indicate that
prestige in Weibo has strong correlation with overall performance in Zhihu. For question specific per-
formance, we have found that relevance between questions and a user?s tweets also correlates with user
performance on Zhihu. Based on these findings, we further add prestige and relevance knowledge into
existing user performance prediction framework. The experiment results show that prestige and rele-
vance information in Weibo largely improve the performance when the available training data is not suf-
ficient. Moreover, individual prestige feature achieves very competitive results. Our approach is equally
applicable to other knowledge sharing web services with appropriate external social media information.
Acknowledgements
The authors would like to thank the anonymous reviewers for their comments. This work is supported
by the National Grand Fundamental Research 973 Program of China under Grant No.2014CB340405
and the National Natural Science Foundation of China (Grant No.61170056). The contact author is Zhen
Xiao.
References
Ashton Anderson, Daniel Huttenlocher, Jon Kleinberg, and Jure Leskovec. 2012. Discovering value from com-
munity activity on focused question answering sites: a case study of stack overflow. In Proceedings of the 18th
ACM SIGKDD international conference on Knowledge discovery and data mining, pages 850?858. ACM.
664
Jiang Bian, Yandong Liu, Ding Zhou, Eugene Agichtein, and Hongyuan Zha. 2009. Learning to recognize reliable
users and content in social media with coupled mutual reinforcement. In Proceedings of the 18th international
conference on World wide web, pages 51?60. ACM.
Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual web search engine. Computer
networks and ISDN systems, 30(1):107?117.
Hongbo Deng, Jiawei Han, Michael R Lyu, and Irwin King. 2012. Modeling and exploiting heterogeneous
bibliographic networks for expertise ranking. In Proceedings of the 12th ACM/IEEE-CS joint conference on
Digital Libraries, pages 71?80. ACM.
David Easley and Jon Kleinberg. 2012. Networks, crowds, and markets: Reasoning about a highly connected
world.
Jinwen Guo, Shengliang Xu, Shenghua Bao, and Yong Yu. 2008. Tapping on the potential of q&a community by
recommending answer providers. In Proceedings of the 17th ACM conference on Information and knowledge
management, pages 921?930. ACM.
F Maxwell Harper, Daphne Raban, Sheizaf Rafaeli, and Joseph A Konstan. 2008. Predictors of answer quality in
online q&a sites. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages
865?874. ACM.
Jiwoon Jeon, W Bruce Croft, Joon Ho Lee, and Soyeon Park. 2006. A framework to predict the quality of answers
with non-textual features. In Proceedings of the 29th annual international ACM SIGIR conference on Research
and development in information retrieval, pages 228?235. ACM.
Pawel Jurczyk and Eugene Agichtein. 2007. Discovering authorities in question answer communities by using
link analysis. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge
management, pages 919?922. ACM.
Jon M Kleinberg. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM (JACM),
46(5):604?632.
Xiangnan Kong, Jiawei Zhang, and Philip S Yu. 2013. Inferring anchor links across multiple heterogeneous
social networks. In Proceedings of the 22nd ACM international conference on Conference on information &
knowledge management, pages 179?188. ACM.
Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is twitter, a social network or a news
media? In Proceedings of the 19th international conference on World wide web, pages 591?600. ACM.
Xiaoyong Liu, W Bruce Croft, and Matthew Koll. 2005. Finding experts in community-based question-answering
services. In Proceedings of the 14th ACM international conference on Information and knowledge management,
pages 315?316. ACM.
Jing Liu, Young-In Song, and Chin-Yew Lin. 2011. Competition-based user expertise score estimation. In
Proceedings of the 34th international ACM SIGIR conference on Research and development in Information
Retrieval, pages 425?434. ACM.
Jing Liu, Fan Zhang, Xinying Song, Young-In Song, Chin-Yew Lin, and Hsiao-Wuen Hon. 2013. What?s in a
name?: An unsupervised approach to link users across communities. In Proceedings of the Sixth ACM Interna-
tional Conference on Web Search and Data Mining, WSDM ?13.
Tie-Yan Liu. 2009. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval,
3(3):225?331.
Kevin Kyung Nam, Mark S Ackerman, and Lada A Adamic. 2009. Questions in, knowledge in?: a study of naver?s
question answering community. In Proceedings of the SIGCHI conference on human factors in computing
systems, pages 779?788. ACM.
Julian Oldmeadow, Michael Platow, Margaret Foddy, and Donna Anderson. 2003. Self-categorization, status, and
social influence. Social Psychology Quarterly, 66(2):138?152.
Aliaksei Severyn and Alessandro Moschitti. 2012. Structural relationships for large-scale learning of answer
re-ranking. In Proceedings of the 35th international ACM SIGIR conference on Research and development in
information retrieval, pages 741?750. ACM.
Aliaksei Severyn, Massimo Nicosia, and Alessandro Moschitti. 2013. Learning adaptable patterns for passage
reranking. CoNLL-2013, page 75.
665
Chirag Shah and Jefferey Pomerantz. 2010. Evaluating and predicting answer quality in community qa. In
Proceedings of the 33rd international ACM SIGIR conference on Research and development in information
retrieval, pages 411?418. ACM.
Young-In Song, Jing Liu, Tetsuya Sakai, Xin-Jing Wang, Guwen Feng, Yunbo Cao, Hisami Suzuki, and Chin-Yew
Lin. 2010. Microsoft research asia with redmond at the ntcir-8 community qa pilot task. In NTCIR-8.
Juyup Sung, Jae-Gil Lee, and Uichin Lee. 2013. Booming up the long tails: Discovering potentially contributive
users in community-based question answering services.
Rui Yan, Mirella Lapata, and Xiaoming Li. 2012. Tweet recommendation with graph co-ranking. In Proceedings
of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages
516?525. Association for Computational Linguistics.
Liu Yang, Minghui Qiu, Swapna Gottipati, Feida Zhu, Jing Jiang, Huiping Sun, and Zhong Chen. 2013. Cqarank:
jointly model topics and expertise in community question answering. In Proceedings of the 22nd ACM interna-
tional conference on Conference on information & knowledge management, pages 99?108. ACM.
Reza Zafarani and Huan Liu. 2013. Connecting users across social media sites: a behavioral-modeling approach.
In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,
pages 41?49. ACM.
ChengXiang Zhai. 2008. Statistical language models for information retrieval. Synthesis Lectures on Human
Language Technologies, pages 1?141.
Yongzheng Zhang and Marco Pennacchiotti. 2013a. Predicting purchase behaviors from social media. In Pro-
ceedings of the 22nd international conference on World Wide Web, pages 1521?1532. International World Wide
Web Conferences Steering Committee.
Yongzheng Zhang and Marco Pennacchiotti. 2013b. Recommending branded products from social media. In
Proceedings of the 7th ACM conference on Recommender systems, pages 77?84. ACM.
Jun Zhang, Mark S Ackerman, and Lada Adamic. 2007. Expertise networks in online communities: structure and
algorithms. In Proceedings of the 16th international conference on World Wide Web, pages 221?230. ACM.
Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, and Xing Xie. 2014. Mining novelty-seeking trait across het-
erogeneous domains. In Proceedings of the 23rd international conference on World wide web, pages 373?384.
International World Wide Web Conferences Steering Committee.
Guangyou Zhou, Siwei Lai, Kang Liu, and Jun Zhao. 2012. Topic-sensitive probabilistic model for expert finding
in question answer communities. In Proceedings of the 21st ACM international conference on Information and
knowledge management, pages 1662?1666. ACM.
666
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1337?1347,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Mining New Business Opportunities: Identifying Trend related Products by
Leveraging Commercial Intents from Microblogs
Jinpeng Wang1, Wayne Xin Zhao1, Haitian Wei2, Hongfei Yan1 and Xiaoming Li1
1School of Electronic Engineering and Computer Science, Peking University, China
2Daton Securities Co., Ltd., No.93 Jianguo Rd, Chaoyang District, Beijing, China
JooPoo@pku.edu.cn, {batmanfly,haataa.wei,yhf1029}@gmail.com, lxm@pku.edu.cn
Abstract
Hot trends are likely to bring new business
opportunities. For example, ?Air Pollution?
might lead to a significant increase of the sales
of related products, e.g., mouth mask. For e-
commerce companies, it is very important to
make rapid and correct response to these hot
trends in order to improve product sales. In
this paper, we take the initiative to study the
task of how to identify trend related products.
The major novelty of our work is that we au-
tomatically learn commercial intents revealed
from microblogs. We carefully construct a da-
ta collection for this task and present quite a
few insightful findings. In order to solve this
problem, we further propose a graph based
method, which jointly models relevance and
associativity. We perform extensive experi-
ments and the results showed that our methods
are very effective.
1 Introduction
A trend is a hot topic (e.g., the release of a popular
movie) which is being widely discussed by the pub-
lic. Hot trends usually attract much attention from
the public, and they are likely to bring new business
opportunities. Consider the following e-shopping s-
cenario. A user in Beijing would like to buy some-
thing to reduce the health impacts of Beijing air pol-
lution1. Different from traditional e-shopping sto-
ries, in this case the user may not have a clear idea of
what she should buy, and cannot even formulate the
1See http://www.nytimes.com/2013/04/04/world/asia/two-major-
air-pollutants-increase-in-china.html to find more details about the
trending topic ?Beijing Air Pollution?.
purchase needs into a clear query. Faced with trend-
driven business opportunities, e-commerce compa-
nies typically ask workers to manually identify relat-
ed products and make heuristic rules to match user
queries (e.g., incorporating trending keywords into
related product titles).
To improve trend-driven e-commerce, in this pa-
per, we propose to study the novel task of automat-
ically identifying trend related products. Why is
it compelling to understand and study trend-driven
product purchase? Because hot trends are closely
related to business opportunities directly or indirect-
ly. As a case of direct causal relationship, the world-
wide popularity of the movie series ?Harry Potter?
created the great success of the original novels of
?Harry Potter?. As a case of indirect causal rela-
tionship, the stock rise or salary increase might exert
positive effects on product sale. Based on our empir-
ical analysis (See Section 3), a considerable propor-
tion, i.e. 50%, of hot trends discussed on the largest
Chinese microblog (i.e. Sina Weibo) indeed have
corresponding product entries in the largest Chinese
C2C e-commerce website (i.e. Taobao), which in-
dicates a strong correlation between hot trends and
product sale.
Although the task is important and emergent, it
has at least two major challenges. First of all, how to
infer users? trend-driven purchase intents promptly.
A trend usually happens unexpectedly. Without pri-
or knowledge and experiences, it is particularly diffi-
cult to make rapid response to relate the trend to can-
didate products. Our solution is to leverage trend-
related commercial intents from microblogs by min-
ing users? real-time response to a trending topic. We
adopt the solution based on two key considerations:
(1) Microblogs are fast. As previous studies showed,
1337
the first story of a trending topic indeed was usu-
ally reported in microblogs rather than traditional
news media (Sakaki et al, 2010; Kwak et al, 2010;
Leskovec et al, 2009). (2) Microblogs contain user-
s? commercial intents. The microblogging service
has become one of the most popular social network
platforms, where users may tweet about their needs
and desires (Hollerit et al, 2013). E.g., a microblog
user may complain about the air quality and evince
the desire to buy a mouth mask in a tweet. The ex-
ample indicates we can make use of tweet-level re-
latedness to capture the correlation between trends
and products.
Second, how to achieve a comprehensive cover-
age of related products but not hurting precision.
The above solution will miss the related products
which have not been discussed in microblogs. Our
idea is to take the associativity between products in-
to consideration. Our definition about associativity
is very general and can have different instantiation-
s in specific settings. For example, we can define
product associativity to be the similarity between
product descriptions, or the ratio of historical pur-
chase records in e-commerce companies. Howev-
er, one-step associativity may not fully discover the
underlying relatedness between products due to the
fact that the product associativity is indeed transi-
tive. Thus, a transitable associativity model is need-
ed.
To address these two challenges, we propose a u-
nified graph based ranking algorithm which jointly
models the above two aspects, i.e., relevance and
associativity. Given a trend, the algorithm runs in
an iterative way and seeks a trade-off between rel-
evance and associativity by propagating the scores
on the product graph. Our contribution can be sum-
marized as follows: (1) we introduce the novel task
of identifying trend related products, most of all, we
propose to leverage trend-related commercial intents
from microblogs; (2) we present insightful empiri-
cal analysis to illustrate the correlation between hot
trends and product sale (See Section 3); (3) we pro-
pose a novel graph based ranking algorithm which
jointly considers relevance and associativity; (4) we
carefully construct the test collection based on re-
al data of the largest microblog and the largest C2C
e-commerce website in China. (5) we perform ex-
tensive experiments and present some important im-
plications for practice.
To the best of our knowledge, our work was the
first to consider identifying trend related products by
leveraging commercial intents from microblogs. We
believe the current work will have important impact
on industry and inspire more follow-up research s-
tudies. The rest of this paper is organized as fol-
lows. We present the data collection and empiri-
cal analysis of the impact of hot trends on product
sale in Section 3. We present a novel graph-based
method in Section 4. Experimental setup and result-
s are discussed in Section 5 and Section 6. Finally,
the related work is discussed in Section 7. And the
conclusions and future work are given in Section 8.
2 Problem Definition
A trend is a hot topic widely discussed by the public,
e.g., the release of a hot movie. Usually, a trend e
can be described by a small set of keywords denoted
by Ke and a corresponding time span Te.
Trend-related Products Identification: Given a
trend e, we assume that the following inputs are
available: 1) tweets that contain trend keywords Ke
and 2) a product database which provides a set of
candidate products P = {p1, p2, ..., pn} with nec-
essary detailed information, e.g., titles and descrip-
tions. The objective of trend-related products iden-
tification is to identify products in P that are related
to trend e within the time span Te, denoted by PR.
For convenience, we will not explicitly mention the
time span unless needed.
To better understand the problem, we first present
an illustrative example in Table 1, which will be dis-
cussed as the running case throughout the paper. In
this example, we can see that a few users tweet their
product needs related to the trend ?Air Pollution?.
We take Taobao as the product database and present
a few related products in it.
Table 1: An illustrative example for the studied task.
Trend keywords: Air Pollution
Tweets:
What bad air! We need to buy masks ASAP!!!
I am planing to buy an air purifier. Hoping it can defend air pollution.
#air pollution I will recommend to keep some houseplants at home.
Product database: Taobao2
Related products: Mouth Mask, Air Purifier, Houseplant
2The biggest C2C e-commerce site in China, similar to eBay.
1338
3 Data and Observations
As discussed earlier, hot trends may exert positive
effects on the sale of related products. In this sec-
tion, we will construct a deep analysis on this point
by presenting quantitative answers to the following
two problems:
? Q1: What is the proportion of hot trends that
potentially lead to business opportunities, and
how is their impact on related products?
? Q2: How is the associativity between related
products?
These findings are key and fundamental to develop
our models.
3.1 Data Collection
To perform the above analysis, the key is how to con-
struct an experimental data collection which relates
hot trends to corresponding related products. We
jointly consider microblogs and e-commerce plat-
forms: we obtain hot trends in microblogs and man-
ually identify trend-related products in e-commerce
websites. In this paper, we adopt Sina Weibo3
as the microbloging platform and Taobao4 as the
e-commerce platform, which are the biggest mi-
croblogging service and the largest C2C company in
China respectively. The analysis method is general
and can equally apply to other platforms. For both t-
wo data signals, we consider a two-month time span,
i.e. from May 2013 to June 2013.
Trend detection. Since trend detection is not our
focus, we directly obtained trends from ?trending
topics? provided by the microblog platform. Our
work can be easily extended to incorporate a trend
detection component. Similar to ?trending topic-
s? in Twitter, Sina Weibo provides a public list of
top searched keywords which can be obtained by
the Weibo search API5. In the list, top 50 keyword-
s are presented and ordered by the number of be-
ing searched. Weibo classifies these keywords in-
to five categories: China, movie, business, person
and sports. We consider these keywords to be trend
keywords. These keywords are dynamically updated
and we monitor the trend lists in the considered time
3http://www.weibo.com/
4http://www.taobao.com/
5http://s.weibo.com/top/summary
span. We define the start and end time of a trend to
be the first day and the last day on the trend list re-
spectively, which spans the active interval of a trend.
We only keep the trend which has an active interval
with more than one day. For each trend, we use the
trend keywords to retrieve all related tweets in the
active interval, and use the pattern based method in
(Hollerit et al, 2013) to extract all mentioned prod-
uct keywords. We present a few example patterns
used for extracting product keywords in Table 2. Af-
ter that we can obtain a set of product keywords for
each trend.
Table 2: Example patterns for extracting product key-
words.
Patterns Example segments of tweets
?(buy) ?
?|?SLxI?
bought father a Philips PT720 (Electric Razor).
?^(use) ?^N95???$?/
use N95 (mouth mask) to reduce the impact of bad air
? ?Galaxy S4
(recommend) recommend Galaxy S4 (cell phone)
Related product identification and annotation.
For each trend, we have the product keyword set to-
gether with the trend keywords as described above.
We use these keywords to retrieve candidate prod-
ucts in the product search engine of Taobao with-
in the active interval of the trend. For each can-
didate product, we further crawl its product page
and obtain corresponding related products suggest-
ed by Taobao, which are treated as candidate, too.
We invite two senior post-graduate students major
in economics as human judges. The judge is re-
quired to make a binary decision whether a product
is related to a trend by following a detailed guide-
line compiled by a senior officer of an e-commerce
company in Beijing. For each trend, we provide the
trend keywords, product keywords in tweets, relat-
ed tweets, related news articles from China Daily6.
Web access is available during the annotation pro-
cess. Due to space limit, we do not present the an-
notation guideline here. We use Cohen?s kappa to
measure the agreement of these two judges, which
has a high value of 0.75. To speed up the work,
we further group all products which have the same
lowest categorial label (e.g., leaf label) 7, and we
6http://www.chinadaily.com.cn
7Taobao has provided a category tree for products:
http://list.taobao.com/browse/cat-0.htm).
1339
will treat a group as a product in later experiments.
We only keep the products with the same judgments
and the trends with at least one related product. We
present the statistics of data set in Table 3 8. Since
current e-commerce search engines mainly adop-
t keyword matching based retrieval method, we fur-
ther examine the performance of simply using trend
keywords as queries. We compute the percentage
of related/unrelated products with at least one trend
keyword in their description. We can see that on-
ly 29.7% related products can be found on average.
These statistics indicate that more effective methods
are needed for the current task.
Table 3: Statitics of the data set.
# business-related trends 113
average candidate products per trend 55.1
average related products per trend 7.3
average perc. of rel. prod. with trend keywords 29.7%
average perc. of unrel. prod. with trend keywords 6.3%
3.2 Observations
Now we analyze the data collection and present our
observations.
A1: First of all, it is important to find out the pro-
portion of hot trends that potentially leads to busi-
ness opportunities. Recall that each trend has a cat-
egory label and possibly a set of related products i-
dentified by the judges. We refer to a trend with
related products as a business-related trend. We
present the statistics in Fig. 1. We can see that
about 36% of all trends have corresponding relat-
ed products in Taobao, which indicates that these
trends highly relate to business. Movies and Sport-
s have higher proportions of business-related trend-
s, i.e. 81% and 52% respectively, while the other
categories have lower proportions but still with a
substantial number of business related trends. It is
noteworthy that Business has the lowest proportion,
the major reason is that trends in Business are usual-
ly general events, i.e., the release of new economic
policy, which do not directly correspond to related
products. As we discussed earlier, these trends may
have indirect impact on product sales. Currently,
we only focus on direct impact, and indirect impacts
will be considered in future work.
8The data set can be downloaded at http://sewm.pku.
edu.cn/?wjp.
Next we continue to examine the impact of hot
trends on the sale of related products. We obtain
product sales from Taobao product pages. As we can
see in Fig. 2, the average sale of related products in
all categories gradually increased with trends going
on. Interestingly, we can see that categories Movies
and China achieved very significant increase. Prod-
ucts related to Movies trends are usually related to
the movie itself, e.g., movie tickets; while prod-
ucts related to China tend to be commodities (e.g.,
the mouth masks for the trend of ?Air Pollution?)
or trending products (e.g., Shenzhou-10 Spacecraft
Model for the trend of ?the launch of Shenzhou-
10?).
business person sports China movie
# tr
end
s
0
20
40
60
80
100
120
140
160
% b
usin
ess
-rea
ted 
tren
ds
0%
20%
40%
60%
80%
100%
busi.-related trends
other trend% busi.-reated trends
Figure 1: The proportion and volume of business-related
trends in five categories.
A2: Recall we have discussed that product asso-
ciativity is useful for improving the coverage of re-
lated products. Here we would like to quantitatively
examine the associativity between related products
given a trend. For a trend, we first compute the av-
erage pairwise similarity between related products
in terms of their descriptive texts (e.g. title and de-
scription). Since there are more unrelated products,
we randomly sample an equal number of unrelated
products from the candidate products we previously
generated. Then we compute the average similarity
between a related product and an unrelated product.
We further average these values over all the trends
of each category. The average similarity of related-
related product pairs is 0.112, while the average sim-
ilarities of unrelated-unrelated and related-unrelated
1340
Days0 1 2 3 4 5 6
Gro
wth
 rat
e of
 sal
es v
olum
e
1.00
1.02
1.04
1.06
1.08
1.10
1.12
1.14
1.16
1.18
businessperson
sportsChina
movie
Figure 2: An illustrative analysis of the impact on related
products in five categories. We measure the impact by
computing the average growth ratio of sale in Taobao.
product pairs are 0.039 and 0.058 respectively.9
In summary, A1 indicates that a large proportion
of hot trends are potentially related to products and
will exert positive effects on product sale; A2 in-
dicates that there is a strong associativity between
related products, which can be utilized to improve
both precision and recall of the algorithm.
4 The Proposed Method
In this section, we present a graph based ranking al-
gorithm jointly models the relevance of a product
and the associativity between products. Recall that
we have collected a set of product keywords and a
set of candidate products for each trend. Our aim is
to re-rank these candidate products to obtain a better
ranking of related products. We adopt a biased ran-
dom walk algorithm: 1) relevance is modeled as bi-
ased restart probability and 2) associativity is mod-
eled through random walk on the product graph.
4.1 Modeling the Product Relevance
Recall that in Section 2 we use the pattern based
method to extract product keywords from tweets re-
lated to a trend. However, to stimulate the real sce-
nario that we want to identify the related products at
the beginning of a trend, we only keep the keyword-
s which were contained in tweets published in the
first three days when a trend began. These extracted
9The difference was tested to be statistically significant.
product keywords directly reveal users? commercial
intents on the trends. Instead of modeling person-
alized intents, we consider learning a unified trend-
driven intent by representing the intent as a weighted
vector over these product keywords. And the key is
how to set the keyword weight.
Keyword weighting. A good weighting method
should be able to leverage commercial interest-
s/intents of users well and emphasize the keyword-
s users really focus on. Thus we consider making
use of the retweeting (a.k.a. forwarding) mechanis-
m in microblogs. Retweet links are shown to be bet-
ter in revealing relevance and interests (Welch et al,
2011). Formally, we use the following weighting
formula for a keyword k:
Weight(k) =
?
t?Ck
log10 (#rtt + 1), (1)
where Ck is the set of all originally-written tweets
(i.e., not a retweet) that contain the keyword k in
the considered time span, and #rtt is the retweet
number of a tweet t. We further normalize and build
the weight vector over all the considered keywords,
called as intent vector. We denote the intent vector
of a trend e by ~e.
Product relevance. Having the intent vector, now
we discuss about how to define the product rele-
vance. Given a product p, we extract all the words in
the title and description parts of a product. We rep-
resent it as a vector using the widely tf-idf weighting
method. We denote the weight vector of product p
by ~p. We measure the product relevance between e
and p as rel(e, p) = ~e?~p|~e||~p| .
4.2 Modeling the Associativity between
Products
To start this part, we first present an illustrative ex-
ample in Fig. 3. We can see there are four relat-
ed products for the trend ?Air Pollution?. We as-
sume that only ?mouth mask? was mentioned in mi-
croblogs. Now we expect to mine more related prod-
ucts with ?mouth mask? as a known related produc-
t. We can compute the similarity between a pair of
products. Intuitively, if the similarity between a can-
didate product and ?mouth mask? is higher than a
predefined threshold, we can consider it to be relat-
ed, too. In this example, ?air detector? and ?air pu-
rifier? are similar to ?mouth mask? in terms of prod-
1341
Figure 3: An example to illustrate the importance of as-
sociativity. Products which were mentioned in tweets related to ?Air
Pollution? are marked in red circles while the others are marked in blue
circles. The link between products indicate the similarity between two
products. Links with weights lower than a predefined threshold are not
considered. Although ?green plants? is related to this trend, it was not
mentioned in tweets and did not have a direct link to ?mouth mask?.
uct descriptions and considered to be related, while
?Green plants? is determined to be unrelated since
it has very little overlap words with ?mouth mask?
in the description. It indicates one-step similarity
method is not able to fully capture the real associa-
tivity between products.
Thus, we propose to use the random walk method
to propagate the relatedness score on the produc-
t graph. Let P denote the number of all the can-
didate products, and rP?1 denote the relatedness s-
core vector where ri denote the relatedness score of
product pi.
We first construct the product graph. We repre-
sent each candidate product as a vertex in the graph
and built the link with the cosine similarity between
the descriptive texts of two products as the link
weight.10 We denote the similarity matrix byMP?P
and Mi,j denotes the similarity between products pi
and pj . Formally, we formulate the problem in a s-
tandard PageRank form
r(n+1) = ? ? r(n) ?M+ (1? ?) ? y, (2)
where y is the restart probability vector usually
set to be uniform. With this method, it is easy to
see that relatedness score can be propagated on the
product graph, which better captures underlying as-
sociativity between products.
10Other similarity methods can be used, e.g., co-purse history
record.
4.3 Jointly Modeling Relevance and
Associativity
Having discussed about how to model both rele-
vance and associativity, now we are ready to present
a joint model to capture these two factors. By fol-
lowing (Zhao et al, 2013), the main idea is that in-
stead of using a uniform restart distribution y, we
use an relevance biased restart distribution in E-
q. 2. We set the restart probability of a produc-
t to its corresponding relevance. Formally, we set
yi = rel(e, pi). Let us further explain the idea. At
the beginning of each iteration, each product is first
assigned to its relevance score: the more relevant it
is, the larger score it has. During the iteration, each
product begins to collect relevance evidence from its
neighbors on the product graph: the more relevan-
t neighbors it has, the larger score it obtains. And
the final score is indeed a trade-off between its own
relevance score and neighboring relevance scores it
receives. In order to obtain an ergodic walk, we add
a small value, i.e. 1e ? 4, to each entry of y and
then normalize this vector. We denote our algorithm
as JMRA (Jointly Modeling Relevance and Associa-
tivity).
To have an intuitive understanding of our algo-
rithm, let us turn to the example in Fig. 3 again. At
the beginning, only ?mouth mask? has a large rele-
vance score, with the iteration going on, the related-
ness score will be propagated between products on
the graph. Although ?green plants? has not a direct
link with ?mouth mask?, it can obtain relatedness s-
core from its neighbors, i.e. ?air detector? and ?air
purifier?. JMRA is able to discover such latent asso-
ciativity between products.
5 Experimental Setup
We use the test collection which have been described
in Section 3. The statistics of the data set is shown
in Table 3.
5.1 Evaluation Metrics
For a real product search engine, top results are par-
ticularly important, thus we adopt precision@5 and
precision@10 as the evaluation metrics. Similar to
Information Retrieval, we also consider using Mean
Average Precision (MAP) as metrics to measure the
overall quality of retrieved products.
1342
5.2 Methods to Compare
We compare the following methods for inferring re-
lating products:
SALES: we rank the candidate products by their
historical sales volume descendingly.
TREND: we use trend keywords as queries and rank
the products by their relevance.
TREND+fb: based on TREND, we further incorpo-
rate pseudo-relevance feedback (Salton, 1971;
Salton and Buckley, 1997). After some tun-
ing (See Section 6.5), top 3 search results were
used to update the query.
JMRAr: it is our method which only considers
product relevance in Section 4.1.
JMRAr + fb: we further apply pseudo-relevance
feedback to JMRAr.
JMRAr+a: it is our method which considers both
relevance and associativity in Section 4.3.
JMRAr+a+fb: we further apply pseudo-relevance
feedback to JMRAr+a.
6 Experimental Results and Analysis
In this section, we first evaluate the performance of
the proposed approach and the comparison method-
s. Next, we analyze a problem in real e-commerce
search engines, i.e., the cold start. Then, we give
a qualitative case study to further demonstrate the
effectiveness of the proposed approach. Finally,
we examine the parameter sensitivity to the perfor-
mance.
6.1 Comparison of Performance
We present the results of various methods in Table
4. We first examine the performance of baselines
SALES, TREND and TREND+fb. First, SALES has
the worst performance due to the fact that a trend
usually happen unexpectedly and historical records
may not predict it well. The second observation is
that the improvement of TREND+fb over TREND is
little. This is mainly because that very few related
products can be identified only based on trend key-
words so feedback method does not work very well
on it.
Then we compare our relevance based method-
s with the above three baselines. Note that the
major difference between JMRAr and TREND is
that JMRAr makes uses of both trend keywords
and product keywords extracted from microblogs.
We can see that JMRAr performs better than al-
l three baselines. It proves the effectiveness of lever-
aging commercial intents from microblogs. An-
other interesting point is that the relative improve-
ment JMRAr+fb over JMRAr is larger than that
TREND+fb over TREND. The reason is that pseudo
relevance feedback relies highly on top results and a
system with better search quality will benefit more
from it.
Finally, we consider evaluating our full models
which jointly consider relevance and associativity. It
is easy to see JMRAr+a yields a significant improve-
ment over JMRAr and even outperforms JMRAr+fb.
This observation supports our assumption that prod-
uct associativity is very important in this task. A-
gain, pseudo relevance feedback has also improved
JMRAr+a.
In summary, our results have shown some impor-
tant implications for trend-related product retrieval
on e-commerce search engines: 1) microblogs are
very good signals to learn users? commercial intents;
2) product associativity is particularly important; 3)
other advanced retrieval methods are potentially use-
ful, e.g., pseudo relevance feedback.
Table 4: The overall performance of all the methods.
Models P@5 P@10 MAP
SALES 0.345 0.379 0.225
TREND 0.543 0.325 0.327
TREND+fb 0.550 0.325 0.328
JMRAr 0.611 0.527 0.336
JMRAr+fb 0.661 0.552 0.348
JMRAr+a 0.733 0.609 0.392
JMRAr+a+fb 0.734 0.624 0.404
6.2 Cold Start
It is noteworthy that we have considered all the can-
didate products within the entire active interval of a
trend when constructing the test collection. This is
mainly to obtain a good coverage of related product-
s since some e-commerce companies might release
new products as the response to a trend. During the
active interval of a trend, the e-commerce companies
may make some heuristic rules to enhance the re-
trieval of related products, e.g., incorporating trend
keywords into product titles and descriptions. In the
1343
real application scenario, an effective method is ex-
pected to identify related products at the beginning
of a trend when the e-commerce workers may not
make any response to the trend. How would it be
if we do not have the manually generated trend key-
words from workers in product titles and descrip-
tions?
To answer the question, in this part, we contin-
ue to examine the impact of cold start on different
methods. We select three methods as comparisons,
i.e., TREND+fb, JMRAr + fb and JMRAr+a + fb.
We first use keyword matching methods to obtain
all the products that related to trend keywords. The
descriptive text (i.e., title and description) of these
products has been refined to match trend queries by
sellers in e-commerce websites. We further removed
all the trend keywords in the desriptive text of these
products, and gradually add the trend keywords back
to original products. In such a process, we would
like to examine how cold start affects the perfor-
mance of different methods.
0% 20% 40% 60% 80% 100%
P@
10
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
JMRAr + fbJMRAr+a + fbTREND + fb
Figure 4: The impact of cold start for different meth-
ods.
We present the results in Fig. 4. First, per-
formance of all these methods improve with the
increase of products with trend keywords. Sec-
ond, cold start does not affect the relative perfor-
mance order of different methods, i.e., TREND+fb
< JMRAr + fb < JMRAr+a + fb. Finally, all the
methods display similar impact patterns: ?signifi-
cantli increasing? ? ?stable?. An interesting ob-
servation is that JMRAr + fb and JMRAr+a + fb
have much more stable performance compared to
TREND+fb. It indicates that our methods are very
robust to the cold start, and potentially applicable in
real e-commerce search engines.
6.3 Case Study
In order to have a intuitive understanding of how
different method perform, we present a case study
in this part. We select JMRAr, JMRAr+fb and
JMRAr+a+fb as comparisons. The results are shown
in Table 5. We can see that JMRAr+a+fb have iden-
tified the most related products. We further analyze
the contribution of different factors. Compared with
JMRAr, JMRAr+fb has got one more related prod-
uct ?Houseplant? due to the reason pseudo feedback
can make use of top related search results to im-
prove the queries. In this case, ?Houseplant? is i-
dentified to be related because it is very similar to
?Air Detector? (We have presented the correspond-
ing most associative products in brackets in Table 5).
Similarly, the comparison between JMRAr+fb and
JMRAr+a+fb shows the effectiveness of product as-
sociativity.
6.4 Error Analysis
To further understand the shortcomings of the pro-
posed methods, we use the example in Table 5 for er-
ror analysis. Based on our manual inspection, errors
may arise from two major sources for our method:
? Product keyword extraction errors: we use
a pattern-based product keyword extraction
method, and it tends to incorporate some irrel-
evant words. For example, given the topic ?air
pollution?, users would talk about the impact
of ?car exhaust? on air quality and advocate to
reduce automobile usage and sale. The current
keyword extraction method might mistake the
word ?car? for a product related keyword.
? Search engine retrieval errors: in this paper,
we rely on the Taobao product search engine
for candidate product generation. It is high-
ly based on surface-form matching to retrieve
related products. Therefore, given a query
?mouth mask?, it might return some irrelevant
products, e.g., ?party mask?. Clearly, pseudo-
relevance feedback will also bring additional ir-
relevant products if top search results contain
irrelevant ones.
1344
Table 5: A qualitative comparison of three methods on the topic of ?Air Pollution?. We mark related products in bold.
Sample keywords learnt from microblogs:
air pollution, mouth mask, air, air purifier, respirator, house, mask,
warm, bus, car, purified water
JMRAr JMRAr+fb JMRAr+a+fb
Mouth Mask Mouth Mask Mouth Mask
Air Detector Air Detector Air Purifier
Air Purifier Air Purifier Air Detector
Toy House Humidifier Respirator
Respirator Respirator Oxygen Bag (Mouth Mask)
Toy Car Party Mask Humidifier
Environment-friendly Bags Toy Car Houseplant (Air Detector)
Humidifier Houseplant (Air Detector) Anti-pollution Medicine (Oxygen Bag)
Purified Water Environment-friendly bags Purified Water
Warmer Purified Water Party Mask
(a)
0 2 4 6 8 10
P@10
0.54
0.56
0.58
0.60
0.62
0.64 JMRAr + fbJMRAr+a + fb
(b)
Figure 5: Parameter sensitivity. a) The impact of the
damping factor ? and b) the impact of the number of top
products used for pseudo feedback.
To solve these problems, one promising way is to
leverage more context information about the candi-
date products and construct deep semantic analysis.
We will leave it as future work.
6.5 Parameter Sensitivity
The only parameter for JMRA is the damping fac-
tor in the random walk model, i.e., ?. Intuitively,
a larger value of ? emphasize the associativity more
while a smaller value emphasize the relevance more.
We tune this parameter at a step of 0.1 and present
the results in Fig. 5(a). We can see the performance
of JMRAr+a+fb is consistently better than that of
JMRAr+fb and peaks at around ?0.8?. It indicates
the robustness of JMRAr+a+fb and the importance
of product associtivity.
We further examine the impact of the num-
ber of top products used for pseudo feedback for
JMRAr+fb and JMRAr+a+fb. In Fig. 5(b), we can
see that both JMRAr+a+fb and JMRAr+fb achieved
their best at ?3?. It indicates that we only need to
consider very top results for pseudo feedback.
6.6 Title or Description?
In previous experiments, for each product, we used
the descriptive text in both title and description. In
this part, we consider examining the individual ef-
fect of title and description. We use JMRAr+a+fb as
the examined method since both relevance and asso-
ciativity relies on the text information.
Table 6: Evaluating the performance of JMRAr+a+fb
with different text sources.
sources P@5 P@10 MAP
title 0.690 0.591 0.364
description 0.711 0.602 0.387
title+description 0.734 0.624 0.404
As shown in Table 6, we can see that the perfor-
mance of only using description is better than that
of only using title and a combination of both parts
achieve the best. title is usually carefully compiled
by e-commerce sellers, thus it reveals the most high-
lights of the products but very short; while descrip-
tion contains more informative text but tends to in-
corporate noise. In future work, we will consider a
more principled way to combine title and descrip-
tion, e.g., weighted combination.
1345
6.7 Efficiency
Finally, we present a few discussions about the issue
of efficiency. All codes were implemented in Python
2.7, and all experiments were performed on a PC
with Intel(R) Core(TM)i5 CPU 760 @ 2.8GHz and
8GB memory.
Sicne we group products by the categorial label,
the number of candidate products is usually very s-
mall. Thus, our method JMRA runs very efficiently.
Even on an extremely large set of candidate product-
s, the iterative random walk algorithm can be easily
implemented in a distributed way (Bahmani et al,
2011) and would have very good efficiency.
7 Related Work
Our work is mainly related to the following lines:
Mining the microblogs. Microblogs have been
one of the most popular social networking platform-
s, and they have recently attracted much attention
from research communities. The studies on trend
(or event) detection (Benson et al, 2011; Weng and
Lee, 2011; Sakaki et al, 2010; Zhao et al, 2012)
tried to make use of the rapid response of microblogs
users as the signal to automatically identify exter-
nal events. Another important aspect is the content
analysis of tweets, including the recommendation of
real-time topical news (Phelan et al, 2009), senti-
ment or opinions analysis (Meng et al, 2012), event
summarization using tweets (Chakrabarti and Puner-
a, 2011; Lin et al, 2012; Zhao et al, 2013), etc. Our
work do not explicitly incorporate a trend detection
component, instead we make use of the trending top-
ics provided by the microblogs platforms. It will be
easy to incorporate other trend detection methods as
our input.
Identifying online users? commercial intents.
The identification of online users? commercial in-
tents has been quite an important research prob-
lem in the past. Most researches focus on captur-
ing commercial intention from search queries (Dai
et al, 2006; Strohmaier and Kro?ll, 2012), click-
through behaviors (Ashkan and Clarke, 2009), user-
s? mouse movements or scrolling behaviors (Guo
and Agichtein, 2010) and search logs (Strohmaier
and Kro?ll, 2012). The most related to our work is
the work in (Hollerit et al, 2013), which attempts to
detect commercial intent on twitter. But we have
very different focus. They aim to identify tweet-
level commercial intents while ours aim to identify
trend-driven commercial intents. In addition, we al-
so present how to make use of these identified intents
and our paper focuses on how to identify trend relat-
ed products for e-commerce companies to improve
service when faced with hot trends.
8 Conclusions
In this paper, we make the first attempt to identify
trend related products by leveraging commercial in-
tents from microblogs. We propose a way to con-
struct the evaluation set for this task and present
some insightful findings. We propose a graph based
method to joint model relevance and associativity.
We perform extensive experiments, including quan-
titative and qualitative analysis.
Currently, our approach is indeed a framework
to solve this task, and we may consider improving
the individual components in it, e.g. consider non-
product keywords in tweets. For future work, we
will consider incorporating a trend detection com-
ponent into our method, which can be more flexible
to adapt to various trend signals. We can also refine
the method of the product keyword extraction by us-
ing more principled solutions.
Acknowledgments
We thank the anonymous reviewers for the construc-
tive comments. The work was partially supported by
NSFC Grant 60933004, 61073082 and 61272340.
Jinpeng Wang was supported by the Singapore Na-
tional Research Foundation under its IDM Futures
Funding Initiative and administered by the Interac-
tive & Digital Media Programme Office, Media De-
velopment Authority. We thank Taobao for the ac-
cess to the product data and all Taobao data in this
paper will be only used for research purpose.
References
Azin Ashkan and Charles LA Clarke. 2009. Term-
based commercial intent analysis. In Proceedings
of the 32nd international ACM SIGIR conference on
Research and development in information retrieval,
pages 800?801. ACM.
Bahman Bahmani, Kaushik Chakrabarti, and Dong Xin.
2011. Fast personalized pagerank on mapreduce. In
1346
Proceedings of the 2011 ACM SIGMOD Internation-
al Conference on Management of data, SIGMOD ?11,
pages 973?984, New York, NY, USA. ACM.
Edward Benson, Aria Haghighi, and Regina Barzilay.
2011. Event discovery in social media feeds. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies-Volume 1, pages 389?398. Association
for Computational Linguistics.
Deepayan Chakrabarti and Kunal Punera. 2011. Event
summarization using tweets. In Proceedings of the 5th
Int?l AAAI Conference on Weblogs and Social Media
(ICWSM), July.
Honghua Kathy Dai, Lingzhi Zhao, Zaiqing Nie, Ji-Rong
Wen, Lee Wang, and Ying Li. 2006. Detecting online
commercial intention (oci). In Proceedings of the 15th
international conference on World Wide Web, pages
829?837. ACM.
Qi Guo and Eugene Agichtein. 2010. Ready to buy or
just browsing?: detecting web searcher goals from in-
teraction data. In Proceedings of the 33rd internation-
al ACM SIGIR conference on Research and develop-
ment in information retrieval, pages 130?137. ACM.
Bernd Hollerit, Mark Kro?ll, and Markus Strohmaier.
2013. Towards linking buyers and sellers: detect-
ing commercial intent on twitter. In Proceedings of
the 22nd international conference on World Wide Web
companion, pages 629?632. International World Wide
Web Conferences Steering Committee.
Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue
Moon. 2010. What is Twitter, a social network or a
news media? In WWW ?10: Proceedings of the 19th
international conference on World wide web, pages
591?600. ACM.
Jure Leskovec, Lars Backstrom, and Jon Kleinberg.
2009. Meme-tracking and the dynamics of the news
cycle. In Proceedings of the 15th ACM SIGKDD inter-
national conference on Knowledge discovery and data
mining, KDD ?09, pages 497?506, New York, NY, US-
A. ACM.
Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang, Yang
Chen, and Tao Li. 2012. Generating event storylines
from microblogs. In Proceedings of the 21st ACM in-
ternational conference on Information and knowledge
management, pages 175?184. ACM.
Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou, Sujian
Li, and Houfeng Wang. 2012. Entity-centric topic-
oriented opinion summarization in twitter. In Proceed-
ings of the 18th ACM SIGKDD international confer-
ence on Knowledge discovery and data mining, pages
379?387. ACM.
Owen Phelan, Kevin McCarthy, and Barry Smyth. 2009.
Using twitter to recommend real-time topical news. In
Proceedings of the third ACM conference on Recom-
mender systems, pages 385?388. ACM.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: real-time event
detection by social sensors. In Proceedings of the 19th
international conference on World wide web, WWW
?10, pages 851?860, New York, NY, USA. ACM.
Gerard Salton and Chris Buckley. 1997. Readings in
information retrieval. chapter Improving retrieval per-
formance by relevance feedback, pages 355?364. Mor-
gan Kaufmann Publishers Inc., San Francisco, CA,
USA.
Gerard Salton, editor. 1971. The SMART Retrieval Sys-
tem - Experiments in Automatic Document Processing.
Prentice Hall, Englewood, Cliffs, New Jersey.
Markus Strohmaier and Mark Kro?ll. 2012. Acquiring
knowledge about human goals from search query logs.
Information Processing & Management, 48(1):63?82.
Michael J. Welch, Uri Schonfeld, Dan He, and Junghoo
Cho. 2011. Topical semantics of twitter links. In Pro-
ceedings of the fourth ACM international conference
on Web search and data mining, WSDM ?11, pages
327?336, New York, NY, USA. ACM.
Jianshu Weng and Bu-Sung Lee. 2011. Event detection
in Twitter. In Proceedings of the Fifth International
Conference on Weblogs and Social Media (ICWSM),
Menlo Park, CA, USA. AAAI.
Wayne Xin Zhao, Baihan Shu, Jing Jiang, Yang Song,
Hongfei Yan, and Xiaoming Li. 2012. Identifying
event-related bursts via social media activities. In
EMNLP-CoNLL, pages 1466?1477.
Wayne Xin Zhao, Yanwei Guo, Rui Yan, Yulan He, and
Xiaoming Li. 2013. Timeline generation with so-
cial attention. In Proceedings of the 36th international
ACM SIGIR conference on Research and development
in information retrieval, SIGIR ?13, pages 1061?1064.
1347
