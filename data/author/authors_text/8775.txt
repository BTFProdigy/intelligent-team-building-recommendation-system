131
132
133
134
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 953?960,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Accurate Collocation Extraction Using a Multilingual Parser
Violeta Seretan
Language Technology Laboratory
University of Geneva
2, rue de Candolle, 1211 Geneva
Violeta.Seretan@latl.unige.ch
Eric Wehrli
Language Technology Laboratory
University of Geneva
2, rue de Candolle, 1211 Geneva
Eric.Wehrli@latl.unige.ch
Abstract
This paper focuses on the use of advanced
techniques of text analysis as support for
collocation extraction. A hybrid system is
presented that combines statistical meth-
ods and multilingual parsing for detecting
accurate collocational information from
English, French, Spanish and Italian cor-
pora. The advantage of relying on full
parsing over using a traditional window
method (which ignores the syntactic in-
formation) is first theoretically motivated,
then empirically validated by a compara-
tive evaluation experiment.
1 Introduction
Recent computational linguistics research fully ac-
knowledged the stringent need for a systematic
and appropriate treatment of phraseological units
in natural language processing applications (Sag
et al, 2002). Syntagmatic relations between words
? also called multi-word expressions, or ?id-
iosyncratic interpretations that cross word bound-
aries? (Sag et al, 2002, 2) ? constitute an im-
portant part of the lexicon of a language: accord-
ing to Jackendoff (1997), they are at least as nu-
merous as the single words, while according to
Mel?c?uk (1998) they outnumber single words ten
to one.
Phraseological units include a wide range of
phenomena, among which we mention compound
nouns (dead end), phrasal verbs (ask out), idioms
(lend somebody a hand), and collocations (fierce
battle, daunting task, schedule a meeting). They
pose important problems for NLP applications,
both text analysis and text production perspectives
being concerned.
In particular, collocations1 are highly problem-
atic, for at least two reasons: first, because their
linguistic status and properties are unclear (as
pointed out by McKeown and Radev (2000), their
definition is rather vague, and the distinction from
other types of expressions is not clearly drawn);
second, because they are prevalent in language.
Mel?c?uk (1998, 24) claims that ?collocations make
up the lions share of the phraseme inventory?, and
a recent study referred in (Pearce, 2001) showed
that each sentence is likely to contain at least one
collocation.
Collocational information is not only useful, but
also indispensable in many applications. In ma-
chine translation, for instance, it is considered ?the
key to producing more acceptable output? (Orliac
and Dillinger, 2003, 292).
This article presents a system that extracts ac-
curate collocational information from corpora by
using a syntactic parser that supports several lan-
guages. After describing the underlying method-
ology (section 2), we report several extraction re-
sults for English, French, Spanish and Italian (sec-
tion 3). Then we present in sections 4 and 5 a com-
parative evaluation experiment proving that a hy-
brid approach leads to more accurate results than a
classical approach in which syntactic information
is not taken into account.
2 Hybrid Collocation Extraction
We consider that syntactic analysis of source cor-
pora is an inescapable precondition for colloca-
tion extraction, and that the syntactic structure of
source text has to be taken into account in order to
ensure the quality and interpretability of results.
1To put it simply, collocations are non-idiomatical, but
restricted, conventional lexical combinations.
953
As a matter of fact, some of the existing colloca-
tion extraction systems already employ (but only
to a limited extent) linguistic tools in order to sup-
port the collocation identification in text corpora.
For instance, lemmatizers are often used for recog-
nizing all the inflected forms of a lexical item, and
POS taggers are used for ruling out certain cate-
gories of words, e.g., in (Justeson and Katz, 1995).
Syntactic analysis has long since been recog-
nized as a prerequisite for collocation extraction
(for instance, by Smadja2), but the traditional sys-
tems simply ignored it because of the lack, at that
time, of efficient and robust parsers required for
processing large corpora. Oddly enough, this situ-
ation is nowadays perpetuated, in spite of the dra-
matic advances in parsing technology. Only a few
exceptions exists, e.g., (Lin, 1998; Krenn and Ev-
ert, 2001).
One possible reason for this might be the way
that collocations are generally understood, as a
purely statistical phenomenon. Some of the best-
known definitions are the following: ?Colloca-
tions of a given word are statements of the ha-
bitual and customary places of that word? (Firth,
1957, 181); ?arbitrary and recurrent word combi-
nation? (Benson, 1990); or ?sequences of lexical
items that habitually co-occur? (Cruse, 1986, 40).
Most of the authors make no claims with respect to
the grammatical status of the collocation, although
this can indirectly inferred from the examples they
provide.
On the contrary, other definitions state explic-
itly that a collocation is an expression of language:
?co-occurrence of two or more lexical items as
realizations of structural elements within a given
syntactic pattern? (Cowie, 1978); ?a sequence of
two or more consecutive words, that has character-
istics of a syntactic and semantic unit? (Choueka,
1988). Our approach is committed to these later
definitions, hence the importance we lend to us-
ing appropriate extraction methodologies, based
on syntactic analysis.
The hybrid method we developed relies on the
parser Fips (Wehrli, 2004), that implements the
Government and Binding formalism and supports
several languages (besides the ones mentioned in
2?Ideally, in order to identify lexical relations in a corpus
one would need to first parse it to verify that the words are
used in a single phrase structure. However, in practice, free-
style texts contain a great deal of nonstandard features over
which automatic parsers would fail. This fact is being seri-
ously challenged by current research (...), and might not be
true in the near future? (Smadja, 1993, 151).
the abstract, a few other are also partly dealt with).
We will not present details about the parser here;
what is relevant for this paper is the type of syn-
tactic structures it uses. Each constituent is rep-
resented by a simplified X-bar structure (without
intermediate level), in which to the lexical head is
attached a list of left constituents (its specifiers)
and right constituents (its complements), and each
of these are in turn represented by the same type
of structure, recursively.
Generally speaking, a collocation extraction can
be seen as a two-stage process:
I. in stage one, collocation candidates are iden-
tified from the text corpora, based on criteria
which are specific to each system;
II. in stage two, the candidates are scored and
ranked using specific association measures
(a review can be found in (Manning and
Schu?tze, 1999; Evert, 2004; Pecina, 2005)).
According to this description, in our approach
the parser is used in the first stage of extraction,
for identifying the collocation candidates. A pair
of lexical items is selected as a candidate only if
there is a syntactic relation holding between the
two items (one being the head of the current parse
structure, and the other the lexical head of its spec-
ifier/complement). Therefore, the criterion we em-
ploy for candidate selection is the syntactic prox-
imity, as opposed to the linear proximity used by
traditional, window-based methods.
As the parsing goes on, the syntactic word pairs
are extracted from the parse structures created,
from each head-specifier or head-complement re-
lation. The pairs obtained are then partitioned
according to their syntactic configuration (e.g.,
noun + adjectival or nominal specifier, noun +
argument, noun + adjective in predications, verb
+ adverbial specifier, verb + argument (subject,
object), verb + adjunt, etc). Finally, the log-
likelihood ratios test (henceforth LLR) (Dunning,
1993) is applied on each set of pairs. We call
this method hybrid, since it combines syntactic
and statistical information (about word and co-
occurrence frequency).
The following examples ? which, like all the
examples in this paper, are actual extraction re-
sults ? demonstrate the potential of our system
to detect collocation candidates, even if subject to
complex syntactic transformations.
954
1.a) raise question: The question of
political leadership has been raised
several times by previous speakers.
1.b) play role: What role can Canada?s
immigration program play in help-
ing developing nations... ?
1.c) make mistake: We could look back
and probably see a lot of mistakes
that all parties including Canada
perhaps may have made.
3 Multilingual Extraction Results
In this section, we present several extraction re-
sults obtained with the system presented in sec-
tion 2. The experiments were performed on data
in the four languages, and involved the following
corpora: for English and French, a subpart or the
Hansard Corpus of proceedings from the Canadian
Parliament; for Italian, documents from the Swiss
Parliament; and for Spanish, a news corpus dis-
tributed by the Linguistic Data Consortium.
Some statistics on these corpora, some process-
ing details and quantitative results are provided in
Table 1. The first row lists the corpora size (in
tokens); the next three rows show some parsing
statistics3, and the last rows display the number of
collocation candidates extracted and of candidates
for which the LLR score could be computed4.
Statistics English French Spanish Italian
tokens 3509704 1649914 1023249 287804
sentences 197401 70342 67502 12008
compl. parse 139498 50458 13245 4511
avg. length 17.78 23.46 15.16 23.97
pairs 725025 370932 162802 58258
(extracted) 276670 147293 56717 37914
pairs 633345 308410 128679 47771
(scored) 251046 131384 49495 30586
Table 1: Extraction statistics
In Table 2 we list the top collocations (of length
two) extracted for each language. We do not
specifically discuss here multilingual issues in col-
location extraction; these are dealt with in a sepa-
rate paper (Seretan and Wehrli, 2006).
3The low rate of completely parsed sentences for Spanish
and Italian are due to the relatively reduced coverage of the
parsers of these two languages (under development). How-
ever, even if a sentence is not assigned a complete parse tree,
some syntactic pairs can still be collected from the partial
parses.
4The log-likelihood ratios score is undefined for those
pairs having a cell of the contingency table equal to 0.
Language Key1 Key2 LLR score
English federal government 7229.69
reform party 6530.69
house common 6006.84
minister finance 5829.05
acting speaker 5551.09
red book 5292.63
create job 4131.55
right Hon 4117.52
official opposition 3640.00
deputy speaker 3549.09
French premier ministre 4317.57
bloc que?be?cois 3946.08
discours tro?ne 3894.04
ve?rificateur ge?ne?ral 3796.68
parti re?formiste 3615.04
gouvernement fe?de?ral 3461.88
missile croisie`re 3147.42
Chambre commune 3083.02
livre rouge 2536.94
secre?taire parlementaire 2524.68
Spanish banco central 4210.48
millo?n do?lar 3312.68
millo?n peso 2335.00
libre comercio 2169.02
nuevo peso 1322.06
tasa intere?s 1179.62
deuda externo 1119.91
ca?mara representante 1015.07
asamblea ordinario 992.85
papel comercial 963.95
Italian consiglio federale 3513.19
scrivere consiglio 594.54
unione europeo 479.73
servizio pubblico 452.92
milione franco 447.63
formazione continuo 388.80
iniziativa popolare 383.68
testo interpellanza 377.46
punto vista 373.24
scrivere risposta 348.77
Table 2: Top ten collocations extracted for each
language
The collocation pairs obtained were further pro-
cessed with a procedure of long collocations ex-
traction described elsewhere (Seretan et al, 2003).
Some examples of collocations of length 3, 4
and 5 obtained are: minister of Canadian her-
itage, house proceed to statement by, secretary to
leader of gouvernment in house of common (En),
question adresser a` ministre, programme de aide
a` re?novation re?sidentielle, agent employer force
susceptible causer (Fr), bolsa de comercio local,
peso en cuota de fondo de inversio?n, permitir uso
de papel de deuda esterno (Sp), consiglio federale
disporre, creazione di nuovo posto di lavoro, cos-
tituire fattore penalizzante per regione (It)5.
5Note that the output of the procedure contains lemmas
rather than inflected forms.
955
4 Comparative Evaluation Hypotheses
4.1 Does Parsing Really Help?
Extracting collocations from raw text, without pre-
processing the source corpora, offers some clear
advantages over linguistically-informed methods
such as ours, which is based on the syntactic anal-
ysis: speed (in contrast, parsing large corpora of
texts is expected to be much more time consum-
ing), robustness (symbolic parsers are often not
robust enough for processing large quantities of
data), portability (no need to a priori define syn-
tactic configurations for collocations candidates).
On the other hand, these basic systems suffer
from the combinatorial explosion if the candidate
pairs are chosen from a large search space. To
cope with this problem, a candidate pair is usu-
ally chosen so that both words are inside a context
(?collocational?) window of a small length. A 5-
word window is the norm, while longer windows
prove impractical (Dias, 2003).
It has been argued that a window size of 5 is
actually sufficient for capturing most of the col-
locational relations from texts in English. But
there is no evidence sustaining that the same holds
for other languages, like German or the Romance
ones that exhibit freer word order. Therefore, as
window-based systems miss the ?long-distance?
pairs, their recall is presumably lower than that of
parse-based systems. However, the parser could
also miss relevant pairs due to inherent analysis
errors.
As for precision, the window systems are sus-
ceptible to return more noise, produced by the
grammatically unrelated pairs inside the colloca-
tional window. By dividing the number of gram-
matical pairs by the total number of candidates
considered, we obtain the overall precision with
respect to grammaticality; this result is expected to
be considerably worse in the case of basic method
than for the parse-based methods, just by virtue
of the parsing task. As for the overall precision
with respect to collocability, we expect the propor-
tional figures to be preserved. This is because the
parser-based methods return less, but better pairs
(i.e., only the pairs identified as grammatical), and
because collocations are a subset of the grammat-
ical pairs.
Summing up, the evaluation hypothesis that can
be stated here is the following: parse-based meth-
ods outperform basic methods thanks to a drastic
reduction of noise. While unquestionable under
the assumption of perfect parsing, this hypothesis
has to be empirically validated in an actual setting.
4.2 Is More Data Better Than Better Data?
The hypothesis above refers to the overall preci-
sion and recall, that is, relative to the entire list of
selected candidates. One might argue that these
numbers are less relevant for practice than they
are from a theoretical (evaluation) perspective, and
that the exact composition of the list of candi-
dates identified is unimportant if only the top re-
sults (i.e., those pairs situated above a threshold)
are looked at by a lexicographer or an application.
Considering a threshold for the n-best candi-
dates works very much in the favor of basic meth-
ods. As the amount of data increases, there is
a reduction of the noise among the best-scored
pairs, which tend to be more grammatical because
the likelihood of encountering many similar noisy
pairs is lower. However, as the following example
shows, noisy pairs may still appear in top, if they
occur often in a longer collocation:
2.a) les essais du missile de croisie`re
2.b) essai - croisie`re
The pair essai - croisie`re is marked by the basic
systems as a collocation because of the recurrent
association of the two words in text as part or the
longer collocation essai du missile de croisie`re. It
is an grammatically unrelated pair, while the cor-
rect pairs reflecting the right syntactic attachment
are essai missile and missile (de) croisie`re.
We mentioned that parsing helps detecting the
?long-distance? pairs that are outside the limits
of the collocational window. Retrieving all such
complex instances (including all the extraposition
cases) certainly augment the recall of extraction
systems, but this goal might seem unjustified, be-
cause the risk of not having a collocation repre-
sented at all diminishes as more and more data
is processed. One might think that systematically
missing long-distance pairs might be very simply
compensated by supplying the system with more
data, and thus that larger data is a valid alternative
to performing complex processing.
While we agree that the inclusion of more data
compensates for the ?difficult? cases, we do con-
sider this truly helpful in deriving collocational
information, for the following reasons: (1) more
data means more noise for the basic methods; (2)
some collocations might systematically appear in
956
a complex grammatical environment (such as pas-
sive constructions or with additional material in-
serted between the two items); (3) more impor-
tantly, the complex cases not taken into account
alter the frequency profile of the pairs concerned.
These observations entitle us to believe that,
even when more data is added, the n-best precision
might remain lower for the basic methods with re-
spect to the parse-based ones.
4.3 How Real the Counts Are?
Syntactic analysis (including shallower levels of
linguistic analysis traditionally used in collocation
extraction, such as lemmatization, POS tagging, or
chunking) has two main functions.
On the one hand, it guides the extraction system
in the candidate selection process, in order to bet-
ter pinpoint the pairs that might form collocations
and to exclude the ones considered as inappropri-
ate (e.g., the pairs combining function words, such
as a preposition followed by a determiner).
On the other, parsing supports the association
measures that will be applied on the selected can-
didates, by providing more exact frequency infor-
mation on words ? the inflected forms count as
instances of the same lexical item ? and on their
co-occurrence frequency ? certain pairs might
count as instance of the same pair, others do not.
In the following example, the pair loi modifier
is an instance of a subject-verb collocation in 3.a),
and of a verb-object collocation type in 3.b). Basic
methods are unable to distinguish between the two
types, and therefore count them as equivalent.
3.a) Loi modifiant la Loi sur la respons-
abilite? civile
3.b) la loi devrait e?tre modifie?e
Parsing helps to create a more realistic fre-
quency profile for the candidate pairs, not only be-
cause of the grammaticality constraint it applies
on the pairs (wrong pairs are excluded), but also
because it can detect the long-distance pairs that
are outside the collocational window.
Given that the association measures rely heav-
ily on the frequency information, the erroneous
counts have a direct influence on the ranking of
candidates and, consequently, on the top candi-
dates returned. We believe that in order to achieve
a good performance, extraction systems should be
as close as possible to the real frequency counts
and, of course, to the real syntactic interpretation
provided in the source texts6.
Since parser-based methods rely on more accu-
rate frequency information for words and their co-
occurrence than window methods, it follows that
the n-best list obtained with the first methods will
probably show an increase in quality over the sec-
ond.
To conclude this section, we enumerate the hy-
potheses that have been formulated so far: (1)
Parse methods provide a noise-freer list of collo-
cation candidates, in comparison with the window
methods; (2) Local precision (of best-scored re-
sults) with respect to grammaticality is higher for
parse methods, since in basic methods some noise
still persists, even if more data is included; (3) Lo-
cal precision with respect to collocability is higher
for parse methods, because they use a more realis-
tic image of word co-occurrence frequency.
5 Comparative Evaluation
We compare our hybrid method (based on syntac-
tic processing of texts) against the window method
classically used in collocation extraction, from the
point of view of their precision with respect to
grammaticality and collocability.
5.1 The Method
The n-best extraction results, for a given n (in our
experiment, n varies from 50 to 500 at intervals
of 50) are checked in each case for grammatical
well-formedness and for lexicalization. By lexi-
calization we mean the quality of a pair to con-
stitute (part of) a multi-word expression ? be it
compound, collocation, idiom or another type of
syntagmatic lexical combination. We avoid giving
collocability judgments since the classification of
multi-word expressions cannot be made precisely
and with objective criteria (McKeown and Radev,
2000). We rather distinguish between lexicaliz-
able and trivial combinations (completely regular
productions, such as big house, buy bread, that
do not deserve a place in the lexicon). As in
(Choueka, 1988) and (Evert, 2004), we consider
that a dominant feature of collocations is that they
are unpredictable for speakers and therefore have
to be stored into a lexicon.
6To exemplify this point: the pair de?veloppement hu-
main (which has been detected as a collocation by the basic
method) looks like a valid expression, but the source text con-
sistently offers a different interpretation: de?veloppement des
ressources humaines.
957
Each collocation from the n-best list at the
different levels considered is therefore annotated
with one of the three flags: 1. ungrammatical;
2. trivial combination; 3. multi-word expression
(MWE).
On the one side, we evaluate the results of our
hybrid, parse-based method; on the other, we sim-
ulate a window method, by performing the fol-
lowing steps: POS-tag the source texts; filter the
lexical items and retain only the open-class POS;
consider all their combinations within a colloca-
tional window of length 5; and, finally, apply the
log-likelihood ratios test on the pairs of each con-
figuration type.
In accordance with (Evert and Kermes, 2003),
we consider that the comparative evaluation of
collocation extraction systems should not be done
at the end of the extraction process, but separately
for each stage: after the candidate selection stage,
for evaluating the quality (in terms of grammati-
cality) of candidates proposed; and after the ap-
plication of collocability measures, for evaluating
the measures applied. In each of these cases, dif-
ferent evaluation methodologies and resources are
required. In our case, since we used the same mea-
sure for the second stage (the log-likelihood ratios
test), we could still compare the final output of ba-
sic and parse-based methods, as given by the com-
bination of the first stage with the same collocabil-
ity measure.
Again, similarly to Krenn and Evert (2001), we
believe that the homogeneity of data is important
for the collocability measures. We therefore ap-
plied the LLR test on our data after first partition-
ing it into separate sets, according to the syntacti-
cal relation holding in each candidate pair. As the
data used in the basic method contains no syntac-
tic information, the partitioning was done based on
POS-combination type.
5.2 The Data
The evaluation experiment was performed on the
whole French corpus used in the extraction exper-
iment (section 2), that is, a subpart of the Hansard
corpus of Canadian Parliament proceedings. It
contains 112 text files totalling 8.43 MB, with
an average of 628.1 sentences/file and 23.46 to-
kens/sentence (as detected by the parser). The to-
tal number of tokens is 1, 649, 914.
On the one hand, the texts were parsed and
370, 932 candidate pairs were extracted using the
hybrid method we presented. Among the pairs ex-
tracted, 11.86% (44, 002 pairs) were multi-word
expressions identified at parse-time, since present
in the parser?s lexicon. The log-likelihood ratios
test was applied on the rest of pairs. A score
could be associated to 308, 410 of these pairs (cor-
responding to 131, 384 types); for the others, the
score was undefined.
On the other hand, the texts were POS-tagged
using the same parser as in the first case. If in the
first case the candidate pairs were extracted dur-
ing the parsing, in the second they were generated
after the open-class filtering. From 673, 789 POS-
filtered tokens, a number of 1, 024, 888 combina-
tions (560, 073 types) were created using the 5-
length window criterion, while taking care not to
cross a punctuation mark. A score could be asso-
ciated to 1, 018, 773 token pairs (554, 202 types),
which means that the candidate list is considerably
larger than in the first case. The processing time
was more than twice longer than in the first case,
because of the large amount of data to handle.
5.3 Results
The 500 best-scored collocations retrieved with
the two methods were manually checked by three
human judges and annotated, as explained in 5.1,
as either ungrammatical, trivial or MWE. The
agreement statistics on the annotations for each
method are shown in Table 3.
Method Agr. 1,2,3 1,2 1,3 2,3
parse observed 285 365 362 340
k-score 55.4% 62.6% 69% 64%
window observed 226 339 327 269
k-score 43.1% 63.8% 61.1% 48%
Table 3: Inter-annotator agreement
For reporting n-best precision results, we used
as reference set the annotated pairs on which at
least two of the three annotators agreed. That
is, from the 500 initial pairs retrieved with each
method, 497 pairs were retained in the first case
(parse method), and 483 pairs in the second (win-
dow method).
Table 4 shows the comparative evaluation re-
sults for precision at different levels in the list
of best-scored pairs, both with respect to gram-
maticality and to collocability (or, more exactly,
the potential of a pair to constitute a MWE). The
numbers show that a drastic reduction of noise is
achieved by parsing the texts. The error rate with
958
Precision (gram.) Precision (MWE)
n window parse window parse
50 94.0 96.0 80.0 72.0
100 91.0 98.0 75.0 74.0
150 87.3 98.7 72.7 73.3
200 85.5 98.5 70.5 74.0
250 82.8 98.8 67.6 69.6
300 82.3 98.7 65.0 69.3
350 80.3 98.9 63.7 67.4
400 80.0 99.0 62.5 67.0
450 79.6 99.1 61.1 66.0
500 78.3 99.0 60.1 66.0
Table 4: Comparative evaluation results
respect to grammaticality is, on average, 15.9%
for the window method; with parsing, it drops to
1.5% (i.e., 10.6 times smaller).
This result confirms our hypothesis regarding
the local precision which was stated in section 4.2.
Despite the inherent parsing errors, the noise re-
duction is substantial. It is also worth noting that
we compared our method against a rather high
baseline, as we made a series of choices suscep-
tible to alleviate the candidates identification with
the window-based method: we filtered out func-
tion words, we used a parser for POS-tagging (that
eliminated POS-ambiguity), and we filtered out
cross-punctuation pairs.
As for the MWE precision, the window method
performs better for the first 100 pairs7); on the re-
maining part, the parsing-based method is on aver-
age 3.7% better. The precision curve for the win-
dow method shows a more rapid degradation than
it does for the other. Therefore we can conclude
that parsing is especially advantageous if one in-
vestigates more that the first hundred results (as
it seems reasonable for large extraction experi-
ments).
In spite of the rough classification we used in
annotation, we believe that the comparison per-
formed is nonetheless meaningful since results
should be first checked for grammaticality and
?triviality? before defining more difficult tasks
such as collocability.
6 Conclusion
In this paper, we provided both theoretical and em-
pirical arguments in the favor of performing syn-
tactic analysis of texts prior to the extraction of
collocations with statistical methods.
7A closer look at the data revealed that this might be ex-
plained by some inconsistencies between annotations.
Part of the extraction work that, like ours, re-
lies on parsing was cited in section 2. Most of-
ten, it concerns chunking rather than complete
parsing; specific syntactic configurations (such as
adjective-noun, preposition-noun-verb); and lan-
guages other than the ones we deal with (usually,
English and German). Parsing has been also used
after extraction (Smadja, 1993) for filtering out in-
valid results. We believe that this is not enough
and that parsing is required prior to the applica-
tion of statistical tests, for computing a realistic
frequency profile for the pairs tested.
As for evaluation, unlike most of the existing
work, we are not concerned here with compar-
ing the performance of association measures (cf.
(Evert, 2004; Pecina, 2005) for comprehensive
references), but with a contrastive evaluation of
syntactic-based and standard extraction methods,
combined with the same statistical computation.
Our study finally clear the doubts on the use-
fulness of parsing for collocation extraction. Pre-
vious work that quantified the influence of parsing
on the quality of results suggested the performance
for tagged and parsed texts is similar (Evert and
Kermes, 2003). This result applies to a quite rigid
syntactic pattern, namely adjective-noun in Ger-
man. But a preceding study on noun-verb pairs
(Breidt, 1993) came to the conclusion that good
precision can only be achieved for German with
parsing. Its author had to simulate parsing because
of the lack, at the time, of parsing tools for Ger-
man. Our report, that concerns an actual system
and a large data set, validates Breidt?s finding for
a new language (French).
Our experimental results confirm the hypothe-
ses put forth in section 4, and show that parsing
(even if imperfect) benefits to extraction, notably
by a drastic reduction of the noise in the top of
the significance list. In future work, we consider
investigating other levels of the significance list,
extending the evaluation to other languages, com-
paring against shallow-parsing methods instead of
the window method, and performing recall-based
evaluation as well.
Acknowledgements
We would like to thank Jorge Antonio Leoni de
Leon, Mar Ndiaye, Vincenzo Pallotta and Yves
Scherrer for participating to the annotation task.
We are also grateful to Gabrielle Musillo and to
the anonymous reviewers of an earlier version of
959
this paper for useful comments and suggestions.
References
Morton Benson. 1990. Collocations and general-
purpose dictionaries. International Journal of Lexi-
cography, 3(1):23?35.
Elisabeth Breidt. 1993. Extraction of V-N-collocations
from text corpora: A feasibility study for Ger-
man. In Proceedings of the Workshop on Very
Large Corpora: Academic and Industrial Perspec-
tives, Columbus, U.S.A.
Yaacov Choueka. 1988. Looking for needles in a
haystack, or locating interesting collocational ex-
pressions in large textual databases expressions in
large textual databases. In Proceedings of the In-
ternational Conference on User-Oriented Content-
Based Text and Image Handling, pages 609?623,
Cambridge, MA.
Anthony P. Cowie. 1978. The place of illustrative ma-
terial and collocations in the design of a learner?s
dictionary. In P. Strevens, editor, In Honour of A.S.
Hornby, pages 127?139. Oxford: Oxford University
Press.
D. Alan Cruse. 1986. Lexical Semantics. Cambridge
University Press, Cambridge.
Gae?l Dias. 2003. Multiword unit hybrid extraction.
In Proceedings of the ACL Workshop on Multiword
Expressions, pages 41?48, Sapporo, Japan.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61?74.
Stefan Evert and Hannah Kermes. 2003. Experi-
ments on candidate data for collocation extraction.
In Companion Volume to the Proceedings of the 10th
Conference of The European Chapter of the Associ-
ation for Computational Linguistics, pages 83?86,
Budapest, Hungary.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations Word Pairs and
Collocations. Ph.D. thesis, University of Stuttgart.
John Rupert Firth. 1957. Papers in Linguistics 1934-
1951. Oxford Univ. Press, Oxford.
Ray Jackendoff. 1997. The Architecture of the Lan-
guage Faculty. MIT Press, Cambridge, MA.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: Some linguistis properties and an al-
gorithm for identification in text. Natural Language
Engineering, 1:9?27.
Brigitte Krenn and Stefan Evert. 2001. Can we do
better than frequency? A case study on extracting
PP-verb collocations. In Proceedings of the ACL
Workshop on Collocations, pages 39?46, Toulouse,
France.
Dekang Lin. 1998. Extracting collocations from text
corpora. In First Workshop on Computational Ter-
minology, pages 57?63, Montreal.
Christopher Manning and Heinrich Schu?tze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. MIT Press, Cambridge, Mass.
Kathleen R. McKeown and Dragomir R. Radev. 2000.
Collocations. In Robert Dale, Hermann Moisl,
and Harold Somers, editors, A Handbook of Nat-
ural Language Processing, pages 507?523. Marcel
Dekker, New York, U.S.A.
Igor Mel?c?uk. 1998. Collocations and lexical func-
tions. In Anthony P. Cowie, editor, Phraseology.
Theory, Analysis, and Applications, pages 23?53.
Claredon Press, Oxford.
Brigitte Orliac and Mike Dillinger. 2003. Collocation
extraction for machine translation. In Proceedings
of Machine Translation Summit IX, pages 292?298,
New Orleans, Lousiana, U.S.A.
Darren Pearce. 2001. Synonymy in collocation extrac-
tion. In WordNet and Other Lexical Resources: Ap-
plications, Extensions and Customizations (NAACL
2001 Workshop), pages 41?46, Carnegie Mellon
University, Pittsburgh.
Pavel Pecina. 2005. An extensive empirical study of
collocation extraction methods. In Proceedings of
the ACL Student Research Workshop, pages 13?18,
Ann Arbor, Michigan, June. Association for Com-
putational Linguistics.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1?15, Mexico City.
Violeta Seretan and Eric Wehrli. 2006. Multilingual
collocation extraction: Issues and solutions solu-
tions. In Proceedings or COLING/ACL Workshop
on Multilingual Language Resources and Interoper-
ability, Sydney, Australia, July. To appear.
Violeta Seretan, Luka Nerima, and Eric Wehrli. 2003.
Extraction of multi-word collocations using syn-
tactic bigram composition. In Proceedings of
the Fourth International Conference on Recent Ad-
vances in NLP (RANLP-2003), pages 424?431,
Borovets, Bulgaria.
Frank Smadja. 1993. Retrieving collocations form
text: Xtract. Computational Linguistics, 19(1):143?
177.
Eric Wehrli. 2004. Un mode`le multilingue d?analyse
syntaxique. In A. Auchlin et al, editor, Structures
et discours - Me?langes offerts a` Eddy Roulet, pages
311?329. E?ditions Nota bene, Que?bec.
960
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 61?64,
Sydney, July 2006. c?2006 Association for Computational Linguistics
TwicPen : Hand-held Scanner and Translation Software for non-Native
Readers
Eric Wehrli
LATL-Dept. of Linguistics
University of Geneva
Eric.Wehrli@lettres.unige.ch
Abstract
TwicPen is a terminology-assistance sys-
tem for readers of printed (ie. off-line)
material in foreign languages. It consists
of a hand-held scanner and sophisticated
parsing and translation software to provide
readers a limited number of translations
selected on the basis of a linguistic analy-
sis of the whole scanned text fragment (a
phrase, part of the sentence, etc.). The use
of a morphological and syntactic parser
makes it possible (i) to disambiguate to
a large extent the word selected by the
user (and hence to drastically reduce the
noise in the response), and (ii) to handle
expressions (compounds, collocations, id-
ioms), often a major source of difficulty
for non-native readers. The system exists
for the following language-pairs: English-
French, French-English, German-French
and Italian-French.
1 Introduction
As a consequence of globalization, a large and in-
creasing number of people must cope with docu-
ments in a language other than their own. While
readers who do not know the language can find
help with machine translation services, people
who have a basic fluency in the language while
still experiencing some terminological difficulties
do not want a full translation but rather more spe-
cific help for an unknown term or an opaque ex-
pression. Such typical users are the huge crowd
of students and scientists around the world who
routinely browse documents in English on the In-
ternet or elsewhere. For on-line documents, a va-
riety of terminological tools are available, some
of them commercially, such as the ones provided
by Google (word translation services) or Babylon
Ltd. More advanced, research-oriented systems
based on computational linguistics technologies
have also been developed, such as GLOSSER-
RuG (Nerbonne et al 1996, 1999), Compass
(Breidt et al, 1997) or TWiC (Wehrli, 2003,
2004).
Similar needs are less easy to satisfy when
it comes to more traditional documents such as
books and other printed material. Multilingual
scanning devices have been commercialized1, but
they lack the computational linguistic resources to
make them truly useful. The shortcomings of such
systems are particularly blatant with inflected lan-
guages, or with compound-rich languages such as
German, while the inadequate treatment of multi-
word expressions is obvious for all languages.
TwicPen has been designed to overcome these
shortcomings and intends to provide readers of
printed material with the same kind and quality of
terminological help as is available for on-line doc-
uments. For concreteness, we will take our typical
user to be a French-speaking reader with knowl-
edge of English and German reading printed ma-
terial, for instance a novel or a technical document,
in English or in German.
For such a user, German vocabulary is likely
to be a major source of difficulty due in part to
its opacity (for non-Germanic language speakers),
the richness of its inflection and, above all, the
number and the complexity of its compounds, as
exemplified in figure 1 below.2
1The three main text scanner manufacturers are
Whizcom Technologies (http://www.whizcomtech.com),
C-Pen (http://www.cpen.com) and Iris Pen
(http://www.irislink.com).
2See the discussion on ?The Longest German Word? on
http://german.about.com/library/blwort long.htm.
61
This paper will describe the TwicPen system,
showing how an in-depth linguistic analysis of
the sentence in which a problematic word occurs
helps to provide a relevant answer to the reader.
We will show, in particular, that the advantage of
such an approach over a more traditional bilin-
gual terminology system is (i) to reduce the noise
with a better selection (disambiguation) of the
source word, (ii) to provide in-depth morpholog-
ical analysis and (iii) to handle multi-word ex-
pressions (compounds, collocations, idioms), even
when the terms of the expression are not adjacent.
2 Overview of TwicPen
The TwicPen system is a natural follow-up of
TWiC (Translation of Words in Context), (see
Wehrli, 2003, 2004), which is a system for on-
line terminological help based on a full linguistic
analysis of the source material. TwicPen uses a
very similar technology, but is available on per-
sonal computers (or even PDAs) and uses a hand-
held scanner to get the input material. In other
words, TwicPen consists of (i) a simple hand-held
scanner and (ii) parsing and translation software.
TwicPen functions as follows :
? The user scans a fragment of text, which can
be as short as one word or as long as a whole
sentence or even a whole paragraph.
? The text appears in the user interface of the
TwicPen system and is immediately parsed
and tagged by the Fips parser described in the
next section.
? The user can either position the cursor on the
specific word for which help is requested, or
navigate word by word in the sentence.
? For each word, the system retrieves from the
tagged information the relevant lexeme and
consults a bilingual dictionary to get one or
several translations, which are then displayed
in the user interface.
Figure 1 shows the user interface. The input text
is the well-known German compound discussed
by Kay et al (1994) reproduced in (1):
(1) Lebensversicherungsgesellschaftsangestellter
Leben(s)-versicherung(s)-gesellschaft(s)-
angestellter
life-insurance-company-employee
Such examples are not at all uncommon in Ger-
man, in particular in administrative or technical
documents.
Figure 1: TwicPen user interface with a German
compound
Notice that the word Versicherungsgesellschaft
(English insurance company and French com-
pagnie d?assurance), which is a compound, has
not been analyzed. This is due to the fact that,
like many common compounds, it has been lexi-
calized.
3 The Fips parser
Fips is a robust multilingual parser which is based
on generative grammar concepts for its linguis-
tic component and object-oriented design for its
implementation. It uses a bottom-up parsing al-
gorithm with parallel treatment of alternatives, as
well as heuristics to rank alternatives (and cut their
numbers when necessary).
The syntactic structures built by Fips are all
of the same pattern, that is : [ XP L X R ],
where L stands for the possibly empty list of left
constituents, X for the (possibly empty) head of
the phrase and R for the (possibly empty) list
of right constituents. The possible values for X
are the usual part of speech Adverb, Adjective,
Noun, Determiner, Verb, Tense, Preposition,
Complementizer, Interjection.
The parser makes use of 3 fundamental mecha-
nisms : projection, merge and move.
3.1 Projection
The projection mechanism assigns a fully devel-
oped structure to each incoming word, based on
their category and other inherent properties. Thus,
a common noun is directly projected to an NP
62
structure, with the noun as its head, an adjective
to an AP structure, a preposition to a PP struc-
ture, and so on. We assume that pronouns and,
in some languages proper nouns, project to a DP
structure (as illustrated in (2a). Furthermore, the
occurrence of a tensed verb triggers a more elabo-
rate projection, since a whole TP-VP structure will
be assigned. For instance, in French, tensed verbs
occur in T position, as illustrated in (2b):
(2)a. [ DP Paul ], [ DP elle ]
b. [ TP mangesi [ VP ei ] ]
3.2 Merge
The merge mechanism combines two adjacent
constituents, A and B, either by attaching con-
stituent A as a left constituent of B, or by attach-
ing B as a right constituent of any active node of
A (an active node is one that can still accept sub-
constituents).
Merge operations are constrained by various,
mostly language-specific, conditions which can be
described by means of procedural rules. Those
rules are stated in a pseudo formalism which at-
tempts to be both intuitive for linguists and rela-
tively straightforward to code (for the time being,
this is done manually). The conditions take the
form of boolean functions, as described in (3) for
left attachments and in (4) for right attachments,
where a and b refer, respectively, to the first and to
the second constituent of a merge operation.
(3) D + T
a.AgreeWith(b,{number,person})
a.IsArgumentOf(b,subject)
Rule 3 states that a DP constituent (ie. a tra-
ditional noun phrase) can (left-)merge with a TP
constituent (ie. an inflected verb phrase con-
stituent) if (i) both constituents agree in number
and person and (ii) the DP constituent can be in-
terpreted as the subject of the TP constituent.
(4)a. D + N
a.HasSelectionFeature(Ncomplement)
b.HasFeature(commonNoun)
a.AgreeWith(b,{number,gender})
b. V + D
a.HasFeature(mainVerb)
b.IsArgumentOf(a, directObject)
Rule (4a) states that a common noun can be
(right-)attached to a determiner phrase, under the
conditions (i) that the head of the DP bears the se-
lectional feature [+Ncomplement] (ie. the de-
terminer selects a noun), and (ii) the determiner
and the noun agree in gender and number. Finally,
rule (4b) allows the attachment of a DP as a right
subconstituent of a verb (i) if the verb is not an
auxiliary or modal (ie. it is a main verb) and (ii) if
the DP can be interpreted as a direct object argu-
ment of the verb.
3.3 Move
Although the general architecture of surface struc-
tures results from the combination of projection
and merge operations, an additional mechanism is
necessary to handle so-called extraposed elements
and link them to empty constituents (noted e in the
structural representation below) in canonical posi-
tions, thereby creating a chain between the base
(canonical) position and the surface (extraposed)
position of the ?moved? constituent as illustrated
in the following example:
(5)a. who did you invite ?
b. [ CP [ DP who]ididj [ TP [ DP you ] ej [ VP
invite[ DP e]i ] ] ]
4 Multi-word expressions
Perhaps the most advanced feature of TwicPen is
its ability to handle multiword expressions (id-
ioms, collocations), including those in which the
elements of the expression are not immediately
adjacent to each other. Consider the French verb-
object collocation battre-record (break-record), il-
lustrated in (6a, b), as well as in the figure 3.
(6)a. Paul a battu le record national.
Paul broke the national record
b. L?ancien record de Bob Hayes a finalement
e?te? battu.
Bob Hayes? old record was finally broken.
The collocation is relatively easy to identify in
(6a), where the verb and the direct object noun
are almost adjacent and occur in the expected or-
der. It is of course much harder to spot in the (6b)
sentence, where the order is reversed (due to pas-
sivization) and the distance between the two ele-
ments of the collocation is seven words. Never-
theless, as Figure 3 shows, TwicPen is capable of
identifying the collocation.
The screenshot given in Figure 3 shows that the
user selected the word battu, which is a form of
63
Figure 2: Example of a collocation
the transitive verb battre, as indicated in the base
form field of the user interface. This lexeme is
commonly translated into English as to beat, to
bang, to rattle, etc.. However, the collocation
field shows that battu in that sentence is part of
the collocation battre-record which is translated as
break-record.
The ability of TwicPen to handle expressions
comes from the quality of the linguistic analysis
provided by the multilingual Fips parser and of the
collocation knowledge base (Seretan et al, 2004).
A sample analysis is given in (7b), showing how
extraposed elements are connected with canoni-
cal empty positions, as assumed by generative lin-
guists.
(7)a. The record that John broke was old.
b. [ TP [ DP the [ NP recordi [ CP thati [ TP [ DP
John ] [ VP broke [ DP e]i ] ] ] ] ] [ VP was
[ AP old ] ] ]
In this analysis, notice that the noun record is
coindexed with the relative pronoun that, which in
turn is coindexed with the empty direct object of
the verb broke. Given this antecedent-trace chain,
it is relatively easy for the system to identify the
verb-object collocation break-record.
5 Conclusion
Demand for terminological tools for readers of
material in a foreign language, either on-line or
off-line, is likely to increase with the development
of global, multilingual societies. The TwicPen
system presented in this paper has been developed
for readers of printed material. They scan the sen-
tence (or a fragment of it) containing a word that
they don?t understand and the system will display
(on their laptop) a short list of translations. We
have argued that the use of a linguistic parser in
such a system brings several major benefits for the
word translation task, such as (i) determining the
citation form of the word, (ii) drastically reduc-
ing word ambiguities, and (iii) identifying multi-
words expressions even when their constituents
are not adjacent to each other.
Acknowledgement
Thanks to Luka Nerima and Antonio Leoni de Len
for their suggestions and comments. The research
described in this paper has been supported in part
by a grant for the Swiss National Science Founda-
tion (No 101412-103999).
6 References
Breidt, E. and H. Feldweg, 1997. ?Accessing For-
eign Languages with COMPASS?, Machine
Translation, 12:1-2, 153-174.
Kay, M., M. Gawron and P. Norvig, 1994. Verb-
mobil : A Translation System for Face-to-
Face Dialog, Lecture Notes 33, Stanford,
CSLI.
Nerbonne, J. and P. Smit, 1996. ?GLOSSER-
RuG: in Support of Reading in Proceedings
of COLING-1996, 830-835.
Nerbonne, J. and D. Dokter, 1999. ?An Intelligent
Word-Based Language Learning Assistant in
TAL 40:1, 125-142.
Seretan V., Nerima L. and E. Wehrli, 2004.
?Multi-word collocation extraction by syn-
tactic composition of collocation bigrams?,
in Nicolas Nicolov et al (eds), Recent Ad-
vances in Natural Language Processing III:
Selected Papers from RANLP 2003, Amster-
dam, John Benjamins, 91-100.
Wehrli, E. 2003. ?Translation of Words in Con-
text?, Proceedings of MT-Summit IX, New
Orleans, 502-504.
Wehrli, E. 2004. ?Traduction, traduction de mots,
traduction de phrases?, in B. Bel et I. Marlien
(eds.), Proceedings of TALN XI, Fes, 483-
491.
64
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40?49,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Multilingual Collocation Extraction: Issues and Solutions
Violeta Seretan
Language Technology Laboratory
University of Geneva
2, rue de Candolle, 1211 Geneva
Violeta.Seretan@latl.unige.ch
Eric Wehrli
Language Technology Laboratory
University of Geneva
2, rue de Candolle, 1211 Geneva
Eric.Wehrli@latl.unige.ch
Abstract
Although traditionally seen as a language-
independent task, collocation extraction
relies nowadays more and more on the
linguistic preprocessing of texts (e.g.,
lemmatization, POS tagging, chunking or
parsing) prior to the application of sta-
tistical measures. This paper provides
a language-oriented review of the exist-
ing extraction work. It points out sev-
eral language-specific issues related to ex-
traction and proposes a strategy for cop-
ing with them. It then describes a hybrid
extraction system based on a multilingual
parser. Finally, it presents a case-study on
the performance of an association measure
across a number of languages.
1 Introduction
Collocations are understood in this paper as ?id-
iosyncratic syntagmatic combination of lexical
items? (Fontenelle, 1992, 222): heavy rain, light
breeze, great difficulty, grow steadily, meet re-
quirement, reach consensus, pay attention, ask a
question. Unlike idioms (kick the bucket, lend a
hand, pull someone?s leg), their meaning is fairly
transparent and easy to decode. Yet, differently
from the regular productions, (big house, cultural
activity, read a book), collocational expressions
are highly idiosyncratic, since the lexical items
a headword combines with in order to express
a given meaning is contingent upon that word
(Mel?c?uk, 2003).
This is apparent when comparing a colloca-
tion?s equivalents across different languages. The
English collocation ask a question translates as
poser une question in French (lit., ?put a question),
and as fare una domanda, hacer una pregunta in
Italian and Spanish (lit., to make a question).
As it has been pointed out by many researchers
(Cruse, 1986; Benson, 1990; McKeown and
Radev, 2000), collocations cannot be described
by means of general syntactic and semantic rules.
They are arbitrary and unpredictable, and there-
fore need to be memorized and used as such. They
constitute the so-called ?semi-finished products?
of language (Hausmann, 1985) or the ?islands of
reliability? (Lewis, 2000) on which the speakers
build their utterances.
2 Motivation
The key importance of collocations in text pro-
duction tasks such as machine translation and nat-
ural language generation has been stressed many
times. It has been equally shown that collocations
are useful in a range of other applications, such as
word sense disambiguation (Brown et al, 1991)
and parsing (Alshawi and Carter, 1994).
The NLP community fully acknowledged the
need for an appropriate treatment of multi-word
expressions in general (Sag et al, 2002). Collo-
cations are particularly important because of their
prevalence in language, regardless of the domain
or genre. According to Jackendoff (1997, 156)
and Mel?c?uk (1998, 24), collocations constitute
the bulk of a language?s lexicon.
The last decades have witnessed a considerable
development of collocation extraction techniques,
that concern both monolingual and (parallel) mul-
tilingual corpora.
We can mention here only part of this work:
(Berry-Rogghe, 1973; Church et al, 1989;
Smadja, 1993; Lin, 1998; Krenn and Evert, 2001)
for monolingual extraction, and (Kupiec, 1993;
Wu, 1994; Smadja et al, 1996; Kitamura and Mat-
40
sumoto, 1996; Melamed, 1997) for bilingual ex-
traction via alignment.
Traditionally, collocation extraction was con-
sidered a language-independent task. Since collo-
cations are recurrent, typical lexical combinations,
a wide range of statistical methods based on word
co-occurrence frequency have been heavily used
for detecting them in text corpora. Among the
most often used types of lexical association mea-
sures (henceforth AMs) we mention: statistical
hypothesis tests (e.g., binomial, Poisson, Fisher, z-
score, chi-squared, t-score, and log-likelihood ra-
tio tests), that measure the significance of the asso-
ciation between two words based on a contingency
table listing their joint and marginal frequency,
and Information-theoretic measures (Mutual In-
formation ? henceforth MI ? and its variants),
that quantity of ?information? shared by two ran-
dom variables. A detailed review of the statistical
methods employed in collocation extraction can be
found, for instance, in (Evert, 2004). A compre-
hensive list of AMs is given (Pecina, 2005).
Very often, in addition to the information on co-
occurrence frequency, language-specific informa-
tion is also integrated in a collocation extraction
system (as it will be seen in section 3):
- morphological information, in order to count
inflected word forms as instances of the same
base form. For instance, ask questions, asks
question, asked question are all instances of
the same word pair, ask - question;
- syntactic information, in order to recognize a
word pair even if subject to (complex) syntac-
tic transformations: ask multiple questions,
question asked, questions that one might ask.
The language-specific modules thus aim at cop-
ing with the problem of morphosyntactic varia-
tion, in order to improve the accuracy of frequency
information. This becomes truly important espe-
cially for free-word order and for high-inflection
languages, for which the token(form)-based fre-
quency figures become too skewed due to the high
lexical dispersion. Not only the data scattering
modify the frequency numbers used by AMs, but
it also alters the performance of AMs, if the the
probabilities in the contingency table become very
low.
Morphosyntactic information has in fact been
shown to significantly improve the extraction re-
sults (Breidt, 1993; Smadja, 1993; Zajac et al,
2003). Morphological tools such as lemmatizers
and POS taggers are being commonly used in ex-
traction systems; they are employed both for deal-
ing with text variation and for validating the can-
didate pairs: combinations of function words are
typically ruled out (Justeson and Katz, 1995), as
are the ungrammatical combinations in the sys-
tems that make use of parsers (Church and Hanks,
1990; Smadja, 1993; Basili et al, 1994; Lin, 1998;
Goldman et al, 2001; Seretan et al, 2004).
Given the motivations for performing a
linguistically-informed extraction ? which were
also put forth, among others, by Church and
Hanks (1990, 25), Smadja (1993, 151) and Heid
(1994) ? and given the recent development of
linguistic analysis tools, it seems plausible that the
linguistic structure will be more and more taken
into account by collocation extraction systems.
The rest of the paper is organized as follows. In
section 3 we provide a language-oriented review
of the existing collocation extraction work. Then
we highlight, in section 4, a series of problems that
arise in the transfer of methodology to a new lan-
guage, and we propose a strategy for dealing with
them. Section 5 describes an extraction system,
and, finally, section 6 presents a case-study on the
collocations extracted for four languages, illustrat-
ing the cross-lingual variation in the performance
of a particular AM.
3 Overview of Extraction Work
3.1 English
As one might expect, the bulk of the collocation
extraction work concerns the English language:
(Choueka, 1988; Church et al, 1989; Church and
Hanks, 1990; Smadja, 1993; Justeson and Katz,
1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998),
among many others1.
Choueka?s method (1988) detects n-grams (ad-
jacent words) only, by simply computing the co-
occurrence frequency. Justeson and Katz (1995)
apply a POS-filter on the pairs they extract. As in
(Kjellmer, 1994), the AM they use is the simple
frequency.
Smadja (1993) employs the z-score in conjunc-
tion with several heuristics (e.g., the systematic
occurrence of two lexical items at the same dis-
tance in text) and extracts predicative collocations,
1E.g., (Frantzi et al, 2000; Pearce, 2001; Goldman et al,
2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al,
2004; Pecina, 2005), and the list can be continued.
41
rigid noun phrases and phrasal templates. He then
uses the a parser in order to validate the results.
The parsing is shown to lead to an increase in ac-
curacy from 40% to 80%.
(Church et al, 1989) and (Church and Hanks,
1990) use POS information and a parser to extract
verb-object pairs, which then they rank according
to the mutual information (MI) measure they in-
troduce.
Lin?s (1998) is also a hybrid approach that relies
on a dependency parser. The candidates extracted
are then ranked with MI.
3.2 German
German is the second most investigated language,
thanks to the early work of Breidt (1993) and,
more recently, to that of Krenn and Evert, such as
(Krenn and Evert, 2001; Evert and Krenn, 2001;
Evert, 2004) centered on evaluation.
Breidt uses MI and t-score and compares the
results accuracy when various parameters vary,
such as the window size, presence vs. absence
of lemmatization, corpus size, and presence vs.
absence of POS and syntactic information. She
focuses on N-V pairs2 and, despite the lack of
syntactic analysis tools at the time, by simulating
parsing she comes to the conclusion that ?Very
high precision rates, which are an indispensable
requirement for lexical acquisition, can only real-
istically be envisaged for German with parsed cor-
pora? (Breidt, 1993, 82).
Later, Krenn and Evert (2001) used a German
chunker to extract syntactic pairs such as P-N-V.
Their work put the basis of formal and system-
atic methods in collocation extraction evaluation.
Zinsmeister and Heid (2003; 2004) focused on
N-V and A-N-V combinations identified using a
stochastic parser. They applied machine learning
techniques in combination to the log-likelihood
measure (henceforth LL) for distinguishing trivial
compounds from lexicalized ones.
Finally, Wermter and Hahn (2004) identified
PP-V combinations using a POS tagger and a
chunker. They based their method on a linguistic
criterion (that of limited modifiability) and com-
pared their results with those obtained using the
t-score and LL tests.
2The following abbreviations are used in this paper: N -
noun, V - verb, A - adjective, Adv - adverb, Det - determiner,
Conj - conjunction, P - preposition.
3.3 French
Thanks to the outstanding work of Gross on
lexicon-grammar (1984), French is one of the
most studied languages in terms of distributional
and transformational potential of words. This
work has been carried out before the computer era
and the advent of corpus linguistics, while auto-
matic extraction was later performed, for instance,
in (Lafon, 1984; Daille, 1994; Bourigault, 1992;
Goldman et al, 2001).
Daille (1994) aimed at extracting compound
nouns, defined a priori by means of certain syn-
tactic patterns, like N-A, N-N, N-a`-N, N-de-N, N
P Det N. She used a lemmatizer and a POS-tagger
before applying a series of AMs, which she then
evaluated against a domain-specific terminology
dictionary and against a gold-standard manually
created from the extraction corpus.
Similarly, Bourigault (1992) extracted noun-
phrases from shallow-parsed text, and Goldman et
al. (2001) extracted syntactic collocations by us-
ing a full parser and applying the LL test.
3.4 Other Languages
In addition to English, German and French, other
languages for which notable collocation extraction
work was performed, are ? as we are aware of ?
the following:
? Italian: early extraction work was carried out
by Calzolari and Bindi (1990) and employed
MI. It was followed by (Basili et al, 1994),
that made use of parsing information;
? Korean: (Shimohata et al, 1997) used an ad-
jacency n-gram model, and (Kim et al, 1999)
relied on POS-tagging;
? Chinese: (Huang et al, 2005) used POS in-
formation, while (Lu et al, 2004) applied ex-
traction techniques similar to Xtract system
(Smadja, 1993);
? Japanese: (Ikehara et al, 1995) was based on
an improved n-gram method.
As for multilingual extraction via alignment
(where collocations are first detected in one lan-
guage and then matched with their translation in
another language), most or the existing work con-
cern the English-French language pair, and the
Hansard corpus of Canadian Parliament proceed-
ings. Wu (1994) signals a number of problems
42
that non-Indo-European languages pose for the
existing alignment methods based on word- and
sentence-length: in Chinese, for instance, most of
the words are just one or two characters long, and
there are no word delimiters. This result suggests
that the portability of existing alignment methods
to new language pairs is questionable.
We are not concerned here with extraction via
alignment. We assume, instead, that multilingual
support in collocation extraction means the cus-
tomization of the extraction procedure for each
language. This topic will be addressed in the next
sections.
4 Multilingualism: Why and How?
4.1 Some Issues
As the previous section showed, many systems of
collocation extraction rely on the linguistic pre-
processing of source corpora in order to support
the candidate identification process. Language-
specific information, such as the one derived from
morphological and syntactic analysis, was shown
to be highly beneficial for extraction. Moreover,
the possibility to apply the association measures
on syntactically homogenous material is argued to
benefit extraction, as the performance of associa-
tion measures might vary with the syntactic con-
figurations because of the differences in distribu-
tion (Krenn and Evert, 2001).
The lexical distribution is therefore a relevant
issue from the perspective of multilingual colloca-
tion extraction. Different languages show different
proportions of lexical categories (N, V, A, Adv,
P, etc.) which are evenly distributed across syn-
tactic types3. Depending on the frequency num-
bers, a given AM could be more suited for a spe-
cific syntactic configuration in one language, and
less suited for the same configuration in another.
Ideally, each language should be assigned a suit-
able set of AMs to be applied on syntactically-
homogenous data.
Another issue that is relevant in the multi-
lingualism perspective is that of the syntactic
configurations characterizing collocations. Sev-
eral such relations (e.g., noun-adjectival modifier,
predicate-argument) are likely to remain constant
through languages, i.e., to be judged as colloca-
tionally interesting in many languages. However,
3For instance, V-P pairs are more represented in English
than in other languages (as phrasal verbs or verb-particle con-
structions).
other configurations could be language-specific
(like P-N-V in German, whose English equiva-
lent is V-P-N). Yet other configurations might have
no counterpart at all in another language (e.g., the
French P-A pair a` neuf is translated into English
as a Conj-A pair, as new).
Finding all the collocationally-relevant syntac-
tic types for a language is therefore another prob-
lem that has to be solved in multilingual extrac-
tion. Since a priori defining these types based
on intuition does not ensure the necessary cover-
age, an alternative proposal is to induce them from
POS data and dependency relations, as in (Seretan,
2005).
The morphoyntactic differences between lan-
guages also have to be taken into account. With
English as the most investigated language, several
hypotheses were put forth in extraction and be-
came common place.
For instance, using a 5-words window as search
space for collocation pairs is a usual practice, since
this span length was shown sufficient to cover a
high percentage of syntactic co-occurrences in En-
glish. But ? as suggested by other researchers,
e.g., (Goldman et al, 2001) ?, this assumption
does not necessary hold for other languages.
Similarly, the higher inflection and the higher
transformation potential shown by some lan-
guages pose additional problems in extraction,
which were rather ignored for English. As Kim et
al. (1999) notice, collocation extraction is particu-
larly difficult in free-order languages like Korean,
where arguments scramble freely. Breidt (1993)
also pointed out a couple of problems that makes
extraction for German more difficult than for En-
glish: the strong inflection for verbs, the variable
word-order, and the positional ambiguity of the ar-
guments. She shows that even distinguishing sub-
jects from objects is very difficult without parsing.
4.2 A Strategy for Multilingual Extraction
Summing up the previous discussion, the cus-
tomization of collocation extraction for a given
language needs to take into account:
- the syntactic configurations characterizing
collocations,
- the lexical distribution over syntactic config-
urations,
- the adequacy of AMs to these configurations.
43
These are language-specific parameters which
need to be set in a successful multilingual extrac-
tion procedure. Truly multilingual systems have
not been developed yet, but we suggest the fol-
lowing strategy for building such a system:
A. parse the source corpus, extract all the syn-
tactic pairs (e.g., head-modifier, predicate-
argument) and rank them with a given AM,
B. analyze the results and find the syntactic con-
figurations characterizing collocations,
C. evaluate the adequacy of AMs for ranking col-
locations in each syntactic configuration, and
find the most convenient mapping configura-
tions - AMs.
Once customized for a language, the extraction
procedure involves:
Stage 1. parsing the source corpus for extract-
ing the lexical pairs in the relevant,
language-specific syntactic configura-
tions found in step B;
Stage 2. ranking the pairs from each syntactic
class with the AM assigned in step C.
5 A Multilingual Collocation Extractor
Based on Parsing
Ever since the collocation was brought to the at-
tention of linguists in the framework of contextu-
alism (Firth, 1957; Firth, 1968), it has been pre-
ponderantly seen as a pure statistical phenomenon
of lexical association. In fact, according to a well-
known definition, ?a collocation is an arbitrary and
recurrent word combination? (Benson, 1990).
This approach was at the basis of the computa-
tional work on collocation, although there exist an
alternative approach ? the linguistic, or lexico-
graphic one ? that imposes a restricted view on
collocation, which is seen first of all as an expres-
sion of language.
The existing extraction work (section 3) shows
that there is a growing interest in adopting the
more restricted (linguistic) view. As mentioned in
section 3, the importance of parsing for extraction
was confirmed by several evaluation experiments.
With the recent development in the field of linguis-
tic analysis, hybrid extraction systems (i.e., sys-
tems relying on syntactical analysis for colloca-
tion extraction) are likely to become the rule rather
than the exception.
Our system (Goldman et al, 2001; Seretan and
Wehrli, 2006) is ? to our knowledge ? the first
to perform the full syntactic analysis as support for
collocation extraction; similar approaches rely on
dependency parsers or on chunking.
It is based on a symbolic parser that was de-
veloped over the last decade (Wehrli, 2004) and
achieves a high level of performance, in terms of
accuracy, speed and robustness. The languages it
supports are, for the time being, French, English,
Italian, Spanish and German. A few other lan-
guages are being also implemented in the frame-
work of a multilingualism project.
Provided that collocation extraction can be seen
as a two-stage process (where, in stage 1, collo-
cation candidates are identified in the text corpora,
and in stage 2, they are ranked according to a given
AM, cf. section 4.2), the role of the parser is to
support the first stage. A pair of lexical items is
selected as a candidate only if there exist a syntac-
tic relation holding between the two items.
Unlike the traditional, window-based methods,
candidate selection is based on syntactic proxim-
ity (as opposed to textual proximity). Another
peculiarity of our system is that candidate pairs
are identified as the parsing goes on; in other ap-
proaches, they are extracted by post-processing
the output of syntactic tools.
The candidate pairs identified are classified into
syntactically homogenous sets, according to the
syntactic relations holding between the two items.
Only certain predefined syntactic relations are
kept, that were judged as collocationally rele-
vant after multiple experiments of extraction and
data analysis (e.g., adjective-noun, verb-object,
subject-verb, noun-noun, verb-preposition-noun).
The sets obtained are then ranked using the log-
likelihood ratios test (Dunning, 1993).
More details about the system and its perfor-
mance can be found in (Seretan and Wehrli, 2006).
The following examples (taken from the extraction
experiment we will describe below) illustrate its
potential to detect collocation candidates, even if
these are subject to complex syntactic transforma-
tions:
1.a) atteindre objectif (Fr): Les objec-
tifs fixe?s a` l?e?chelle internationale
visant a` re?duire les e?missions ne
peuvent pas e?tre atteints a` l?aide de
ces seuls programmes.
1.b) accogliere emendamento (It):
44
Posso pertanto accogliere in parte
e in linea di principio gli emenda-
menti nn. 43-46 e l?emendamento
n. 85.
1.c) reforzar cooperacio?n (Es): Quer-
emos permitir a los pases que lo
deseen reforzar, en un contexto
unitario, su cooperacio?n en cierto
nu?mero de sectores.
The collocation extractor is part of a bigger sys-
tem (Seretan et al, 2004) that integrates a con-
cordancer and a sentence aligner, and that sup-
ports the visualization, the manual validation and
the management of a multilingual terminology
database. The validated collocations are used for
populating the lexicon of the parser and that of a
translation system (Wehrli, 2003).
6 A Cross-Lingual Extraction
Experiment
A collocation extraction experiment concern-
ing four different languages (English, Spanish,
French, Italian) has been conducted on a parallel
subcorpus of 42 files from the European Parlia-
ment proceedings. Several statistics and extraction
results are reported in Table 1.
Statistics English Spanish Italian French
tokens 2526403 2666764 2575858 2938118
sent/file 2329.1 2513.7 2331.6 2392.8
complete
parses 63.4% 35.5% 46.8% 63.7%
tokens/sent 25.8 25.3 26.3 29.2
extr. pairs
(tokens) 617353 568998 666122 565287
token/type 2.6 2.5 2.3 2.3
LL is def. 85.9% 90.6% 83.5% 92.8%
Table 1: Extraction statistics
We computed the distribution of pair tokens
according to the syntactic type and noted that
the most marked distributional difference among
these languages concern the following types: N-A
(7.12), A-N (4.26), V-O (2.68), V-P (4.16), N-P-N
(3.81)4.
Unsurprisingly, the Romance languages are less
different in terms of syntactic co-occurrence dis-
tribution, and the deviation of English from the
Romance mean is more pronounced ? in particu-
lar, for N-A (9.72), V-P (5.63), A-N (5.25), N-P-N
4The numbers represent the values the standard deviation
of the relative percentages in the whole lists of pairs.
(4.77), and V-O (3.57). These distributional differ-
ences might account for the types of collocations
highlighted by a particular AM (such as LL) in a
language vs. another. Figure 1 displays the rela-
tive proportions of 3 syntactic types ? adjective-
noun, subject-verb and verb-object ? that can be
found at different levels in the significance list re-
turned by LL.
Figure 1: Cross-lingual proportions of A-N, S-V
and V-O pairs at different levels in the significance
lists
We performed a contrastive analysis of results,
by carrying out a case-study aimed at checking
the LL performance variability across languages.
The study concerned the verb-object collocations
having the noun policy as the direct object. We
specifically focused on the best-scored collocation
extracted from the French corpus, namely mener
une politique (lit., conduct a policy).
We looked at the translation equivalents of its
74 instances identified by our extraction system
in the corpus. The analysis revealed that ? at
least in this particular case ? the verbal collo-
cates of this noun are highly scattered: pursue,
implement, conduct, adopt, apply, develop, have,
draft, launch, run, carry out for English; prac-
ticar, llevar a cabo, desarrollar, realizar, aplicar,
seguir, hacer, adoptar, ejercer for Spanish; con-
durre, attuare, portare avanti, perseguire, pratti-
care, adottare, fare for Italian (among several oth-
ers). Some of the collocates (those listed first) are
more prominently used. But generally they are
highly dispersed, and this might indicate a bigger
difficulty for LL to pinpoint the best collocate in a
language vs. another.
We also observed that quite frequently (in about
25% of the cases) the collocation did not conserve
its syntactic configuration. Either the verb ? here,
45
the equivalent for the French mener ? is omitted
in translations (like in 2.b below):
2.a) des contradictions existent dans la
politique qui est mene?e (Fr);
2.b) we are dealing with contradictory
policy (En),
or, in a few other cases, the whole collocation
disappears, since paraphrased with a completely
different syntactic construction:
3.a) direction qui a mene? une politique
insense?e de re?duction de personnel
(Fr);
3.b) a management that foolishly en-
gaged in staff reductions (En).
In order to quantify the impact such factors have
on the performance of the AM considered, we
further scrutinized the collocates list for politique
proposed by LL test for each language (see Table
2). The rank of a pair in the whole list of verb-
object collocations extracted, as assigned by the
LL test, is shown in the last column. In these sig-
nificance lists, the collocations with politique as an
object constitute a small fraction, and from these,
only the top collocations are displayed in Table 2.
The threshold was manually defined in accordance
with our intuition that the lower-scored pairs ob-
served manifest less a collocational strength. It
happens to be situated around the LL value of 20
for each language (and is of course specific to the
size of our corpus and to the number of V-O tokens
identified therein).
If we consider the LL rank as the success mea-
sure for collocate detection, we can infer that the
collocates of the word under investigation are eas-
ier to found in French, as compared to English,
Italian or Spanish, because the value in the first
row of the last column is smaller. This holds if we
are interested in only one (the most salient) collo-
cate for a word.
If we measure the success of retrieving all the
collocates (by considering, for instance, the speed
to access them in the results list ? the higher the
rank, the better), then French can be again consid-
ered the easiest because overall, the positions in
the V-O list are higher (i.e., the mean of the rank
column is smaller) with respect to Spanish, Italian
and, respectively, English.
This latter result corresponds, approximately,
to the order given by relative proportion of V-O
Language collocate freq LL score rank
French mener 74 376.8 45
politique e?laborer 17 50.1 734
adapter 5 48.3 780
axer 8 41.4 955
pratiquer 9 39.7 1011
de?velopper 13 28.1 1599
adapter 8 25.2 1867
poursuivre 11 24.4 1943
English pursue 39 214.9 122
policy implement 38 108.7 325
develop 30 81.1 473
conduct 8 28.9 2014
harmonize 9 28.2 2090
gear 5 27.7 2201
need 25 24.9 2615
apply 16 23.3 2930
Spanish practicar 17 98.7 246
pol??tica desarrollar 27 82.4 312
aplicar 25 65.7 431
seguir 17 33.5 1003
coordinar 8 31.0 1112
basar 11 25.1 1473
orientar 6 22.5 1707
adaptar 5 20.0 1987
construir 6 19.4 2057
Italian attuare 23 79.5 382
politica perseguire 14 46.4 735
praticare 8 37.6 976
seguire 18 30.2 1314
portare 12 29.7 1348
rivedere 9 26.0 1607
riformare 7 25.6 1639
sviluppare 12 22.1 1975
adottare 20 21.2 2087
Table 2: Verbal collocates for the headword policy
pairs in each language (Spanish 15.12%, French
15.14%, Italian 17.06%, and English 20.82%).
Given that in English V-O pairs are more numer-
ous and the verbs also participate in V-P construc-
tions, it might seem reasonable to expect lower
LL scores for V-O collocations in English vs. the
other 3 languages.
In general, we expect a correlation between ex-
traction difficulty and the distributional properties
of co-occurrence types.
7 Conclusion
The paper pointed out several issues that oc-
cur in transfering a hybrid collocation extraction
methodology (that combines linguistic with statis-
tic information) to a new language.
Besides the questionable availability of
language-specific text analysis tools for the new
language, a number of issues that are relevant to
extraction proper were addressed: the changes
in the distribution of (syntactic) word pairs, and
the need to find, for each language, the most
46
appropriate association measure to apply for each
syntactic type (given that AMs are sensitive to
distributions and syntactic types); the lack of
a priori defined syntactic types for a language;
and, finally, the portability of some widely used
techniques (such as the window method) from
English to other languages exhibiting a higher
word order freedom.
It is again in the multilingualism perspective
that the inescapable need for preprocessing the
text emerged (cf. different researchers cited in sec-
tion 3): highly inflected languages need lemma-
tizers, free-word order languages need structural
information in order to guarantee acceptable re-
sults. As language tools become nowadays more
and more available, we expect the collocation ex-
traction (and terminology acquisition in general)
to be exclusively performed in the future by re-
lying on linguistic analysis. We therefore believe
that multilingualism is a true concern for colloca-
tion extraction.
The paper reviewed the extraction work in a
language-oriented fashion, while mentioning the
type of linguistic preprocessing performed when-
ever it was the case, as well as the language-
specific issues identified by the authors. It then
proposed a strategy for implementing a multilin-
gual extraction procedure that takes into account
the language-specific issues identified.
An extraction system for four different lan-
guages, based on full parsing, was then described.
Finally, an experiment was carried out as a case
study, which pointed out several factors that might
determine a particular AM to perform differently
across languages. The experiment suggested that
log-likelihood ratios test might highlight certain
verb-object collocations easier in French than in
Spanish, Italian and English (in terms of salience
in the significance list).
Future work needs to extend the type of cross-
linguistic analysis initiated here, in order to pro-
vide more insights on the differences expected at
extraction between one language and another and
on the responsible factors, and, accordingly, to de-
fines strategies to deal with them.
Acknowledgements
The research described in this paper has been sup-
ported in part by a grant from the Swiss National
Foundation (No. 101412-103999).
References
Hiyan Alshawi and David Carter. 1994. Training
and scaling preference functions for disambiguation.
Computational Linguistics, 20(4):635?648.
Roberto Basili, Maria Teresa Pazienza, and Paola Ve-
lardi. 1994. A ?not-so-shallow? parser for colloca-
tional analysis. In Proceedings of the 15th confer-
ence on Computational linguistics, pages 447?453,
Kyoto, Japan. Association for Computational Lin-
guistics.
Morton Benson. 1990. Collocations and general-
purpose dictionaries. International Journal of Lexi-
cography, 3(1):23?35.
Godelieve L. M. Berry-Rogghe. 1973. The com-
putation of collocations and their relevance to lex-
ical studies. In A. J. Aitken, R. W. Bailey, and
N. Hamilton-Smith, editors, The Computer and Lit-
erary Studies, pages 103?112. Edinburgh.
Didier Bourigault. 1992. Surface grammatical analysis
for the extraction of terminological noun phrases. In
Proceedings of the 15th International Conference on
Computational Linguistics, pages 977?981, Nantes,
France.
Elisabeth Breidt. 1993. Extraction of V-N-collocations
from text corpora: A feasibility study for Ger-
man. In Proceedings of the Workshop on Very
Large Corpora: Academic and Industrial Perspec-
tives, Columbus, U.S.A.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1991. Word-
sense disambiguation using statistical methods. In
Proceedings of the 29th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 1991),
pages 264?270, Berkeley, California.
Nicoletta Calzolari and Remo Bindi. 1990. Acqui-
sition of lexical information from a large textual
Italian corpus. In Proceedings of the 13th Inter-
national Conference on Computational Linguistics,
pages 54?59, Helsinki, Finland.
Yaacov Choueka. 1988. Looking for needles in a
haystack, or locating interesting collocational ex-
pressions in large textual databases. In Proceedings
of the International Conference on User-Oriented
Content-Based Text and Image Handling, pages
609?623, Cambridge, U.S.A.
Kenneth Church and Patrick Hanks. 1990. Word as-
sociation norms, mutual information, and lexicogra-
phy. Computational Linguistics, 16(1):22?29.
Kenneth Church, William Gale, Patrick Hanks, and
Donald Hindle. 1989. Parsing, word associations
and typical predicate-argument relations. In Pro-
ceedings of the International Workshop on Parsing
Technologies, pages 103?112, Pittsburgh. Carnegie
Mellon University.
47
D. Alan Cruse. 1986. Lexical Semantics. Cambridge
University Press, Cambridge.
Be?atrice Daille. 1994. Approche mixte pour
l?extraction automatique de terminologie : statis-
tiques lexicales et filtres linguistiques. Ph.D. thesis,
Universite? Paris 7.
Gae?l Dias. 2003. Multiword unit hybrid extraction.
In Proceedings of the ACL Workshop on Multiword
Expressions, pages 41?48, Sapporo, Japan.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61?74.
Stefan Evert and Brigitte Krenn. 2001. Methods for
the qualitative evaluation of lexical association mea-
sures. In Proceedings of the 39th Annual Meeting
of the Association for Computational Linguistics,
pages 188?195, Toulouse, France.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
University of Stuttgart.
John Rupert Firth, 1957. Papers in Linguistics 1934-
1951, chapter Modes of Meaning, pages 190?215.
Oxford Univ. Press, Oxford.
J. R. Firth. 1968. A synopsis of linguistic theory,
1930?55. In F.R. Palmer, editor, Selected papers
of J. R. Firth, 1952-1959. Indiana University Press,
Bloomington.
Thierry Fontenelle. 1992. Collocation acquisition
from a corpus or from a dictionary: a comparison.
Proceedings I-II. Papers submitted to the 5th EU-
RALEX International Congress on Lexicography in
Tampere, pages 221?228.
Katerina T. Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic recognition of multi-word
terms: the C-value/NC-value method. International
Journal on Digital Libraries, 2(3):115?130.
Jean-Philippe Goldman, Luka Nerima, and Eric
Wehrli. 2001. Collocation extraction using a syn-
tactic parser. In Proceedings of the ACL Workshop
on Collocations, pages 61?66, Toulouse, France.
Maurice Gross. 1984. Lexicon-grammar and the syn-
tactic analysis of French. In Proceedings of the 22nd
conference on Association for Computational Lin-
guistics, pages 275?282, Morristown, NJ, USA.
Franz Iosef Hausmann. 1985. Kollokationen im
deutschen wo?rterbuch. ein beitrag zur theorie des
lexikographischen beispiels?. In Henning Bergen-
holtz and Joachim Mugdan, editors, Lezikographie
und Grammatik. Akten des Essener Kolloquiums zur
Grammatik im Wo?rterbuch., Lexicographica. Series
Major 3, pages 118?129.
Ulrich Heid. 1994. On ways words work together -
research topics in lexical combinatorics. In W. Mar-
tin, W. Meijs, M. Moerland, E. ten Pas, P. van
Sterkenburg, and P. Vossen, editors, Proceedings of
the VIth Euralex International Congress (EURALEX
?94), pages 226?257, Amsterdam.
Chu-Ren Huang, Adam Kilgarriff, Yiching Wu, Chih-
Ming Chiu, Simon Smith, Pavel Rychly, Ming-Hong
Bai, and Keh-Jiann Chen. 2005. Chinese Sketch
Engine and the extraction of grammatical colloca-
tions. In Proceedings of the Fourth SIGHAN Work-
shop on Chinese Language Processing, pages 48?
55, Jeju Island, Republic of Korea.
Satoru Ikehara, Satoshi Shirai, and Tsukasa Kawaoka.
1995. Automatic extraction of uninterrupted collo-
cations by n-gram statistics. In Proceedings of first
Annual Meeting of the Association for Natural Lan-
guage Processing, pages 313?316.
Ray Jackendoff. 1997. The Architecture of the Lan-
guage Faculty. MIT Press, Cambridge, MA.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: Some linguistis properties and an al-
gorithm for identification in text. Natural Language
Engineering, 1:9?27.
Seonho Kim, Zooil Yang, Mansuk Song, and Jung-Ho
Ahn. 1999. Retrieving collocations from Korean
text. In Proceedings of the 1999 Joint SIGDAT Con-
ference on Empirical Methods in Natural Language
Processing and Very Large Corpora, pages 71?81,
Maryland, U.S.A.
Mihoko Kitamura and Yuji Matsumoto. 1996. Auto-
matic extraction of word sequence correspondences
in parallel corpora. In Proceedings of the 4th Work-
shop on Very Large Corpora, pages 79?87, Copen-
hagen, Denmark, August.
Go?ran Kjellmer. 1994. A Dictionary of English Collo-
cations. Claredon Press, Oxford.
Brigitte Krenn and Stefan Evert. 2001. Can we do
better than frequency? A case study on extracting
PP-verb collocations. In Proceedings of the ACL
Workshop on Collocations, pages 39?46, Toulouse,
France.
Julian Kupiec. 1993. An algorithm for finding noun
phrase correspondences in bilingual corpora. In 31st
Annual Meeting of the Association for Computa-
tional Linguistics, pages 17?22, Columbus, Ohio,
U.S.A.
P. Lafon. 1984. De?pouillement et statistique en
le?xicometrie. Slatkine-Champion, Paris.
Michael Lewis. 2000. Teaching Collocations. Further
Developments In The Lexical Approach. Language
Teaching Publications, Hove.
Dekang Lin. 1998. Extracting collocations from text
corpora. In First Workshop on Computational Ter-
minology, pages 57?63, Montreal.
48
Qin Lu, Yin Li, and Ruifeng Xu. 2004. Improving
Xtract for Chinese collocation extraction. In Pro-
ceedings of IEEE International Conference on Natu-
ral Language Processing and Knowledge Engineer-
ing, pages 333?338.
Kathleen R. McKeown and Dragomir R. Radev. 2000.
Collocations. In Robert Dale, Hermann Moisl,
and Harold Somers, editors, A Handbook of Nat-
ural Language Processing, pages 507?523. Marcel
Dekker, New York, U.S.A.
I. Dan Melamed. 1997. A portable algorithm for
mapping bitext correspondence. In Proceedings of
the 35th Conference of the Association for Com-
putational Linguistics (ACL?97), pages 305?312,
Madrid, Spain.
Igor Mel?c?uk. 1998. Collocations and lexical func-
tions. In Anthony P. Cowie, editor, Phraseology.
Theory, Analysis, and Applications, pages 23?53.
Claredon Press, Oxford.
Igor Mel?c?uk. 2003. Collocations: de?finition, ro?le et
utilite?. In Francis Grossmann and Agne`s Tutin, ed-
itors, Les collocations: analyse et traitement, pages
23?32. Editions ?De Werelt?, Amsterdam.
Darren Pearce. 2001. Synonymy in collocation extrac-
tion. In WordNet and Other Lexical Resources: Ap-
plications, Extensions and Customizations (NAACL
2001 Workshop), pages 41?46, Pittsburgh, U.S.A.
Pavel Pecina. 2005. An extensive empirical study of
collocation extraction methods. In Proceedings of
the ACL Student Research Workshop, pages 13?18,
Ann Arbor, Michigan, June.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1?15, Mexico City.
Violeta Seretan and Eric Wehrli. 2006. Accurate col-
location extraction using a multilingual parser. In
Proceedings of COLING/ACL 2006. To appear.
Violeta Seretan, Luka Nerima, and Eric Wehrli. 2004.
A tool for multi-word collocation extraction and vi-
sualization in multilingual corpora. In Proceedings
of the Eleventh EURALEX International Congress,
EURALEX 2004, pages 755?766, Lorient, France.
Violeta Seretan. 2005. Induction of syntactic col-
location patterns from generic syntactic relations.
In Proceedings of Nineteenth International Joint
Conference on Artificial Intelligence (IJCAI 2005),
pages 1698?1699, Edinburgh, Scotland, July.
Sayori Shimohata, Toshiyuki Sugio, and Junji Nagata.
1997. Retrieving collocations by co-occurrences
and word order constraints. In Proceedings of the
Annual Meeting of the Association for Computa-
tional Linguistics, pages 476?481, Madrid, Spain.
John Sinclair. 1995. Collins Cobuild English Dictio-
nary. Harper Collins, London.
Frank Smadja, Kathleen McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: a statistical approach. Computa-
tional Linguistics, 22(1):1?38.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics, 19(1):143?
177.
Eric Wehrli. 2003. Translation of words in context.
In Proceedings of Machine Translation Summit IX,
pages 502?504, New Orleans, Lousiana, U.S.A.
Eric Wehrli. 2004. Un mode`le multilingue d?analyse
syntaxique. In A. Auchlin et al, editor, Structures
et discours - Me?langes offerts a` Eddy Roulet, pages
311?329. E?ditions Nota bene, Que?bec.
Joachim Wermter and Udo Hahn. 2004. Collocation
extraction based on modifiability statistics. In Pro-
ceedings of the 20th International Conference on
Computational Linguistics (COLING 2004), pages
980?986, Geneva, Switzerland.
Dekai Wu. 1994. Aligning a parallel English-Chinese
corpus statistically with lexical criteria. In Proceed-
ings of the 32nd Annual Meeting of the Association
for Computational Linguistics (ACL 1994), pages
80?87, Las Cruces (New Mexico), U.S.A.
Diana Zaiu Inkpen and Graeme Hirst. 2002. Ac-
quiring collocations for lexical choice between near-
synonyms. In Proceedings of the ACL-02 Workshop
on Unsupervised Lexical Acquisition, pages 67?76,
Philadephia, Pennsylvania.
Re?mi Zajac, Elke Lange, and Jin Yang. 2003. Cus-
tomizing complex lexical entries for high-quality
MT. In Proceedings of the Ninth Machine Trans-
lation Summit, New Orleans, U.S.A.
Heike Zinsmeister and Ulrich Heid. 2003. Signif-
icant triples: Adjective+Noun+Verb combinations.
In Proceedings of the 7th Conference on Compu-
tational Lexicography and Text Research (Complex
2003), Budapest.
Heike Zinsmeister and Ulrich Heid. 2004. Colloca-
tions of complex nouns: Evidence for lexicalisation.
In Proceedings of KONVENS 2004, Vienna, Austria.
49
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 120?127,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Fips, a ?Deep? Linguistic Multilingual Parser
Eric Wehrli
LATL-Dept. of Linguistics
University of Geneva
Eric.Wehrli@lettres.unige.ch
Abstract
The development of robust ?deep? linguis-
tic parsers is known to be a difficult task.
Few such systems can claim to satisfy the
needs of large-scale NLP applications in
terms of robustness, efficiency, granular-
ity or precision. Adapting such systems
to more than one language makes the task
even more challenging.
This paper describes some of the proper-
ties of Fips, a multilingual parsing sys-
tem that has been for a number of years
(and still is) under development at LATL.
Based on Chomsky?s generative grammar
for its grammatical aspects, and on object-
oriented (OO) sofware engineering tech-
niques for its implementation, Fips is de-
signed to efficiently parse the four Swiss
?national? languages (German, French,
Italian and English) to which we also
added Spanish and (more recently) Greek.
1 Introduction
This papers describes the Fips project, which
aims at developing a robust, multilingual ?deep?
linguistic parsing system efficient enough for a
wide-range of NLP applications. The system
is currently available for six languages (English,
French, German, Italian, Spanish and Greek), and
has been extensively used for terminology extrac-
tion (Seretan & Wehrli, 2006), as well as for ter-
minology assistance and translation (Wehrli, 2004,
2006).
This paper is organized as follows. The next
section gives an overview of the Fips parser, de-
scribing some of its linguistic properties and its
main processes. In section 3, we present the
object-oriented design adopted for the project.
Section 4 discusses some cases of cross-linguistic
syntactic variation. Finally, section 5 provides
some details about the results and presents an eval-
uation of the parser for the six languages.
2 The Fips parser
Fips is a robust ?deep? linguistic parser which as-
signs to an input sentence an enriched S-structure
type of representation, along with a predicate-
argument representation. Fips can also be used
as a tagger, outputing for each word of a given
sentence a POS-tag and optionally the grammat-
ical function (associated to the first word of a con-
stituent), the base form (citation form) of the word,
and whether a word is part of an expression or a
collocation.
As an illustation, figure 1 shows the enriched
structure representation and figure 2 the POS-tags
returned by Fips for sentence (1). Notation is ex-
plained below.
(1) The record she broke was very old.
[
TP
[
DP
the [
NP
recordi [ CP [ DP e]i [ TP [ DP
she ] broke [
DP
e]i ] ] ] ] was [FP [AP [Adv very
] old ] ] ]
Figure 1: Enriched S-Structure representation for
sentence (1)
The linguistic assumptions used in this project
correspond roughly to a free-adaptation of Chom-
sky?s generative linguistics, borrowing concepts
from the Minimalist model (Chomsky, 1995,
2004), from the Simpler Syntax model (Culicover
& Jackendoff, 2005), as well as from Lexical
Functional Grammar (Bresnan, 1982, 2001).
120
word tag expression
the DET-SIN
record NOM-SIN break-record
she PRO-PER-SIN-FEM
broke VER-PAS-3-SIN break-record
was VER-PAS-3-SIN
very ADV
old ADJ
Figure 2: POS-tag output for sentence (1)
Roughly, the grammar is lexicalist, exploiting a
rich lexicon which specifies, among others,
? the selectional properties of functional ele-
ments such as prepositions, auxiliaries, deter-
miners, etc. For instance, the English auxil-
iary have selects a [+past participle] verbal
projection. Similarly, in German, werden se-
lects an infinitival verbal complement;
? arguments selected by predicative heads
(nouns, verbs, adjectives);
? other syntactic or semantic features which
might be relevant for syntactic processing
such as [+pronominal] feature associated to
certain verbs in French, Italian, German, etc.,
types and subtypes of adverbs, control prop-
erties of verbs selecting infinitival comple-
ments, and so on.
As shown in figure 1 above, the fundamental
structures built by Fips all follow the same pat-
tern, that is : LeftSubconstituents Head RightSub-
constituents, which can be abbreviated as L X R,
where L stands for the (possibly empty) list of
left subconstituents, X for the (possibly empty)
head of the phrase and R for the (possibly empty)
list of right subconstituents. The possible val-
ues for X are the usual lexical categories Adverb,
Adjective, Noun, Determiner, Verb, Preposition,
Complementizer, Interjection. To this list we add
the functional category Tense, which is the head
of a sentence (TP), as well as Functional, used to
represent predicative objects headed either by an
adjective, an adverb, a noun or a preposition.
Compared to current mainstream Chomskyan
representations, Fips constituent structures are rel-
atively flat and make a rather parsimonious use of
functional projections. They do, however, contain
empty categories, either to represent empty sub-
jects, for instance in infinitival complements, rep-
resented as sentences with a (usually lexically un-
realized) subject. Empty categories are also used
to represent ?traces? of extraposed constituents, as
in wh-constructions, where a chain of coindexed
constituents is computed, headed by the extra-
posed element and footed by its ?trace?, an empty
constituent in argument or adjunct position. An
example of such chain is given in figure 1, where
the noun record is first coindexed with the (lex-
ically unrealized) relative pronoun in the speci-
fier position of the CP constituent, which is itself
related to the empty constituent [
DP
e]i in the
canonical direct object position of the verb form
broke.
Although quite complex, the computation of
such chains brings many benefits in terms of qual-
ity and accuracy of the analysis. One clear exam-
ple is provided by the identification of collocation,
as exemplified in example (1) with the collocation
break-record. In that sentence, the two terms of
the collocation do not occur in the expected order
and do not even occur in the same clause, since
record is the subject of the main clause, while
broke is in the relative clause. However, as the
structure give in fig. 1 shows, the presence of the
?trace? of record in the direct object position of
the verb form broke makes the identification of the
collocation rather simple, and fig. 2 confirms that
Fips has indeed recognized the collocation.
The grammar itself consists of both rules and
processes. Rules specify the attachment of con-
stituents, thus determining, at least for the main
part, the constituent structure associated to a sen-
tence. The grammatical processes, which roughly
correspond to some of the earlier transformation
rules of Generative Grammar, are primarily re-
sponsible for tasks such as:
? filling up the argument table associated with
predicative elements (mostly verbs);
? chain formation, ie. establishing a link be-
tween an extraposed element, such as a wh-
element and an empty category in an argu-
ment or adjunct canonical position;
? modifications of the argument structure of
predicates (adding, deleting, modifying argu-
ments), as is necessary to account for passive
or Romance causative constructions;
? coordination or enumeration structures.
121
In all such cases, the claim is that a procedural
account is simpler than a rule-based description,
leading furthermore to a more efficient implemen-
tation.
3 Object-oriented design
The computational model adopted for the Fips
project relies on object-oriented (OO) concepts
(see, for instance, Mo?ssenbo?ck, 1995). An ab-
stract model is assumed both for objects and
for their associated procedures (usually called
?methods? in OO-jargon) ? roughly correspond-
ing to the ?universal? linguistic level ? from which
language-specific objects and procedures are de-
rived. In other words, linguistic objects are defined
as abstract data types, whose implementation can
vary from language to language. Such variation
is handled by the type extension feature provided
by OO-models when the variation concerns data
structures or by the procedure redefinition feature
when variation concerns a process.
Fips relies on three main objects:
? lexical units (LexicalItem), which correspond
to the ?words? of a language, as they appear
in the lexical database;
? syntactic projections (Projection), which are
the syntactic constituents;
? items (Item), which correspond to an analysis
(partial or complete) ? since the parser uses a
parallel strategy, many items are maintained
throughout the parsing process.
The main procedures (methods) associated to
those objects are Project, Merge and Move, cor-
responding to the operation of projection, combi-
nation and movement, respectively. The following
subsections will briefly discuss them in turn.
3.1 Project
The projection mechanism creates a syntactic
constituent (an object of type Projection in our
model), either on the basis of a lexical object, or on
the basis of another syntactic constituent. For in-
stance, any lexical item, as computed and retrieved
from the lexical database by the lexical analysis is
projected into a syntactic constituent, with the lex-
ical item as its head. Thus, given lex, a lexical
item, lex.Project(p) creates a syntactic projection
p headed by lex, as in example (2):
(2)a. chat ?? [
NP
chat ]
b. eine ?? [
DP
eine ]
c. with ?? [
PP
with ]
A more powerful variant of the projection
mechanism, called metaprojection, can create
richer syntactic constituents based either on spe-
cific lexical items or on other syntactic projec-
tions. For instance, we consider pronouns to be
nominal-type lexical elements which project to a
DP level. Similarly, verbs are taken as sentence
heads, and will therefore give rise to richer syn-
tactic constituents, as illustrated in the following
examples:
(3)a. pronouns
[
DP
[
NP
toi ] ]
b. mangeras (?will-eat?)
[
TP
mangerasi [ VP ei ] ]
c. reads
[
TP
[
VP
reads ] ]
d. regnet (?rains?)
[
CP
regneti [ TP [ VP ei ] ] ]
Notice that the position of the tensed verb is dif-
ferent in the the structures given in (3b,c,d). We
assume that tensed verbs in French (and more gen-
erally in Romance) ?move? to the head of TP, as
shown in (3b), while such movement does not oc-
cur in English (3c). An even more drastic example
of metaprojection occurs in German, where we as-
sume that a whole clause structure is projected on
the basis of a tensed verb (in matrix clause), as il-
lustrated in (3d).
3.2 Merge
Merge is the fundamental combination mechanism
in our parsing model. Each time the parser reads
a word, it is first transformed into a syntactic
constituent, a projection, as we have just seen.
The projection, in turn, must now be combined
(merged) with (partial or complete) constituents
in its immediate left context. Two scenarios are
considered, corresponding to left attachment and
to right attachment. Left attachment occurs when
the projection in the left context of the new pro-
jection can be attached as a left subconstituent of
the new projection. Right attachment corresponds
to the situation where the new projection can be
attached as a right subconstituent of the projection
in its left context. In fact, to be more accurate, the
122
incoming projection can attach as a subconstituent
not just of the projection in its left context, but to
any active node of it, as illustrated in Figure 3 be-
low:
Merge must be validated either by lexical prop-
erties such as selectional features or by general
properties (adverbs, adjuncts, parentheticals can
relatively freely modify projections).
TP
   
   
   



...
...
the
Left context: Active node stack :
Constituent to be attached :
boy
eaten
has
a
big
ice?cream
NP
AP
DP
VPDP
NP
   
   
   



Figure 3: Active node stack
3.3 Move
Although the general architecture of surface struc-
tures results from the combination of projection
and merge operations, an additional mechanism
is necessary to satisfy well-formedness conditions
such as thematic assignment. As mentioned ear-
lier, such a mechanism reveals quite useful for the
collocation identification process (cf. fig. 2). This
mechanism handles extraposed elements and link
them to empty constituents in canonical positions,
thereby creating a chain between the base (canoni-
cal) position and the surface (extraposed) position
of the moved constituent. To take another simple
example, let us consider the interrogative sentence
given in (4a) and the (slightly simplified) associ-
ated structure in (4b):
(4)a. who did you invite ?
b. [ CP [ DP who]i didj [ TP [ DP you ] ej [ VP
invite [
DP
e]i ] ] ]
The chain mechanism functions as follows: as
the parser encounters a wh-word in an extraposed
position, it stores it in a stack associated with its
governing category (typically the CP projection
which dominates it). As the parse proceeds, the
stack is transferred along the right edge of the
structure, provided it does violate island condi-
tions (cf. Ross, 1967). Whenever a predicative el-
ement is added to the structure, an attempt is made
to complete the chain, ie. to interpret the projec-
tion on top of the stack with respect to the predi-
cate. If successful, an empty category coindexed
with the extraposed projection is inserted into the
structure and the projection is removed from the
stack. At the end of the parse, items containing
unresolved chains are heavily penalized.
3.4 A parsing example
To illustrate the parsing procedure and the inter-
action of the 3 mechanisms described above, con-
sider the following simple sentence in French.
(5)a. Paul mange une pomme.
?Paul eats an apple?
b. [
TP
[
DP
[
NP
Paul ] ] mangei [VP e i [DP une
[
NP
pomme ] ] ] ]
Step 1 the parser reads ?Paul? and metaprojects a
DP structure [
DP
[
NP
Paul ] ].
Step 2 the parser reads ?manges? and metapro-
jects a TP-VP structure [
TP
mangei [ VP ei ]
]. A merge operation is possible with the pre-
ceding DP structure, which yields [
TP
[
DP
[
NP
Paul ] ] mangei [ VP ei ] ].
Step 3 the parser reads the determiner ?une? and
creates a DP structure [
DP
une ]. A merge op-
eration is possible with the left-adjacent TP
constituent, with DP attached as right con-
stituent of the internal VP node [
TP
[
DP
[
NP
Paul ] ] mangei [ VP ei [ DP une ] ] ].
Step 4 the parser reads the noun ?pomme?, cre-
ates an NP structure [
NP
pomme ], and attach
it (merge operation) as a right constituent of
the DP structure in the TP structure, which
yields the complete structure (5b).
3.5 The grammar
Merge operations are constrained by various
mostly language-specific conditions which can be
described by means of rules. Those rules are
stated in a pseudo formalism which attempts to be
both intuitive for linguists and relatively straight-
forward to code. The conditions associated to the
rules take the form of boolean functions, as de-
scribed in the examples (6) for left attachments
123
and in the examples (7) for right attachments,
where a and b refer, respectively, to the first and
to the second constituent of a merge operation.
(6)a. AP + NP
a.HasFeat(prenominal)
a.AgreeWith(b, {gender, number})
b. DP + NP
a.HasSelectionFeat( nCompl)
a.AgreeWith(b,{gender, number, case})
Rule 6a specifies that an adjective projection
structure (an AP constituent) can (left-)merge with
a noun projection structure (an NP constituent) un-
der the two conditions (i) that the first constituent
(the adjective) bears the feature prenominal
and (ii) that both constituents agree in number and
gender. This rule, which is part of our French
grammar, will allow for petit animal (?small ani-
mal?), but not pre?historique animal (?prehistorical
animal?), since the adjective pre?historique does
not bear the feature [+prenominal], nor pe-
tit animaux (?small animals?), since petit is singu-
lar while animaux is plural and hence both do not
agree in number.
Rule (6b) is taken from our German grammar. It
states that a common noun can be (right-)attached
to a determiner phrase, under the conditions (i)
that the head of the DP bears the selectional fea-
ture [+Ncomplement] (ie. the determiner se-
lects a noun), and (ii) the determiner and the noun
agree in gender, number and case.
3.6 Procedural grammar
One of the original features of the Fips parser is its
procedural approach to several grammatical prop-
erties. In addition to the chain mechanism de-
scribed in the previous section, the procedural ap-
proach also concerns the treatment of passive and
other restructuring constructions, as well as coor-
dination. The next two paragraphs briefly sketch
our treatment of passive and coordination con-
structions.
3.6.1 passives
Along with many linguists or various persua-
sions, we assume that the fundamental property
of passives is the elimination (or demotion) of the
subject argument of a predicate. Based on that
assumption, our treatment is essentially a case of
argument-structure modification: demotion of the
subject argument to an optional ?by-phrase? ar-
gument, promotion of the direct object argument
to the subject argument slot. In our implemen-
tation, the treatment of passives takes the form
of a grammar rule specifying the attachment of a
[+past participle] verbal projection as complement
of the passive auxiliary. This attachment triggers
the restructuring process described above1.
3.6.2 coordination
Coordinate structures constitute a well-known
problem for both theoretical and computational
linguistics. For the latter, coordination is prob-
lematic because it is a major source of non-
determinism. Given the fact that such structures
are extremely common in both speech and writ-
ing, it is therefore mandatory for NLP systems to
handle them efficiently. Our treatment of coordi-
nation is based on the following assumptions:
? Coordination can affect any pair of like con-
stituents;
? coordinate structures do not strictly obey the
X schema. They have the following structure:
[
XP
[ ConjP XP Conj XP ] ], where X takes
its value in the set of lexical categories aug-
mented by T and F (see section 2 above), and
CONJ is a coordination conjunction (eg. and,
or, but, etc.).
The coordination procedure is triggered by the
presence of a conjunction. All the nodes on the
right edge of the constituent in its immediate left
context are considered potential candidates for the
coordination structure. A metaprojection creates
a coordinate projection, in which the node on the
right edge is the left subconstituent of the conjunc-
tion. The set of such projections is quickly filtered
out by further incoming material.
To illustrate our treatment of coordinate struc-
tures, in particular the type of structure we assume
(slightly simplified in the (8) sentences) as well as
the potential ambiguity of coordination, consider
the following simple English examples.
(7)a. the old men and women
b. [
DP
[
ConjP [ DP the [ NP [ AP old ] men ] ]
and ] [
DP
[
NP
women ] ] ]
c. [
DP
the [
NP
[
AP
old ] [ConjP [NP men ] and
[
NP
women ] ] ] ]
1The same restructuring process applies to particial struc-
tures, as in John left the room, followed by his dog.
124
d. [
DP
the [
NP
[ ConjP [ NP [ A old ] men ] ]
and ] [
NP
women ] ]
(8)a. John believes Bill and Mary will be to blame.
b. John believes [
TP
[
DP
Bill and Mary ] will
be to blame ]
c. [
TP
John believes Bill ] and [
TP
Mary will
be to blame ]
4 Examples of cross-linguistic variation
In the Fips system, language variation occurs not
only at the level of the grammar, as expected, but
also at the level of the associated procedures. Con-
sider for example, the case of the argument check-
ing procedure. Whereas a preverbal DP can be in-
terpreted as the subject of a verb if it agrees with
it (number, person) in languages such as French
or English (as well as other so-called ?configu-
rational languages?), the same criteria would not
hold for case-marked languages, such as German
or Modern Greek. In those languages, subjects
can essentially occur anywhere in the sentence but
must be marked [+nominative] and of course
agree with the verb (number, person)2. Relatively
similar at an abstract level, the argument check-
ing procedure must be ?tuned? for each individual
language.
Our second example of cross-linguistic varia-
tion concerns clitic pronouns. The relevant data
structures (objects) and interpretation procedures
(methods) to handle clitics are defined at an ab-
stract level. Specific languages (ie. Spanish, Ital-
ian, French, Greek, etc.) inherit those objects
and methods, which they can further specialize ac-
cording to language-specific properties and con-
straints. The general mechanism to handle clitics
comprises two distinct steps: attachment and in-
terpretation3 . As a clitic is read (as an independent
word or as an orthographically attached affix), it is
attached to the head of the verb form which fol-
lows it (proclitic) or which precedes it (enclitic).
Since this verbal head is not necessarily the one
with respect to which the clitic pronoun can be in-
terpreted (it might be an auxiliary, for instance),
2We assume that German (and Modern Greek) are so-
called scrambling languages with an unmarked basic word
order (cf. Haider and Rosengren, 1998, Hinterho?lzl, 2006).
3From now on, the discussion will only focus on Romance
clitics.
a temporary data structure is used to store clitics
until the parser has identified the main predicate
of the sentence4 . Only then can the interpretation
process start. All the clitics in the temporary data
structure must be interpreted either as argument or
as adjunct of the verb5. The examples below il-
lustrate our analysis of clitics, applied to Italian
(9), French (10) and Spanish (11). The Italian and
French examples display proclitics (pre-verbal cl-
itics), while the Spanish example is a case of encl-
itics (post-verbal clitics). Notice also that in Ital-
ian and Spanish we have clitic clusters (two clitics
concatenated in one orthographical word), and in
the Spanish example, the cluster is itself concate-
nated to the verb. In all three examples, the clitic
pronouns have be properly analyzed, ie. inter-
preted as arguments of the verb. This is expressed
in the resulting structures by the chains connect-
ing a pronoun and an empty category in postverbal
position. As in the wh-chains discussed earlier, all
the elements are coindexed.
(9)a. Glielo ho dato. (?I have given it to him?)
b. [
TP
[
DP
e ] glii-loj ho [VP dato [PP ei ] [DP
ej ] ] ](10)a. Paul le lui a donne?. (?Paul has given it to
him?)
b. [
TP
[
DP
Paul ] lei luij a [ VP donne? [ DP ei ]
[
PP
ej ] ] ]
(11)a. Da?mmelo. (?Give it to me?)
b. [
TP
[
DP
e ] dai-mej-lok [ VP ei [ PP ej ] [ DP
ek ] ] ]
Although very similar in their fundamental be-
havior, clitics across Romance languages are nev-
ertheless too different to be handled by exactly
the same mechanism. Furthermore, even if such
mechanism could be implemented, chances are
that it would prove insufficient or inadequate in
some ways to handle an additional Romance lan-
guage such as Romanian or Portuguese. Our ap-
proach, based on a general abstract mechanism,
which can be specialized to suit the specific prop-
erties of each language seems therefore more ap-
propriate.
4This temporary structure is also used to check the well-
formedness of clitic sequences.
5For the sake of simplicity, we will leave aside a few more
complex cases, such as French clitic ?en? corresponding to
complements of the direct object of the main verb (Paul en
conna??t la raison ?Paul knows the reason of it?) or so-called
?long-distance? clitics in Italian or Spanish restructuration
constructions.
125
5 Results and evaluation
To date, the Fips multilingual parser has been de-
veloped for 6 languages (English, French, Ger-
man, Italian, Spanish and Greek). Other lan-
guages have been very partially treated, such as
Romanian, Russian, Polish and Romansch Sursil-
van.
A significant effort has been made at the lexical
level, qualitatively and quantitatively. The table in
figure 4 below shows the curren approximate size
of each lexicon.
language lexemes words collocations
anglais 54?000 90?000 5?000
franc?ais 37?000 227?000 12?500
allemand 39?000 410?000 2?000
italien 31?000 220?000 2?500
espagnol 22?500 260?000 320
grec 12?000 90?000 225
Figure 4: Number of entries in the lexical database
At the grammar level, the coverage of the Eng-
lish and French grammar is quite satisfactory, Ital-
ian, Spanish and especially German still need im-
provements, while the Greek grammar is very par-
tial.
Fips attempts to produce complete analyzes
for input sentences. Since the parsing strategy
is (pseudo-)parallel, many analyzes are produced
and ranked according to preferences such as local
vs. non-local attachments, argument vs. adjunct
interpretation, presence vs. absence of a collo-
cation, etc. When a complete analysis fails, the
parser outputs a sequence of partial analyzes cov-
ering the whole sentence.
A comparative evaluation has been conducted
to show how the various implementations of Fips
compare with respect to a near identical cor-
pus, the European Parliament corpus (cf. Koehn,
2005). We parsed approximately 1 million words
in each of the six languages. The table given in
figure 5 show the results:
The first line in table 5 show the size of each file
in terms of symbols (word, punctuation, format-
ting symbol, etc.), approximately 1 million sym-
bols for each file. The second line gives the num-
ber of unknown words, not counting words start-
ing with an uppercase letter which are assumed
to be proper nouns (given the fact that in Ger-
man common nouns are capitalized, we did not
leave aside capitalized unknown words for that
language). The third line indicates the number
of sentences approximately 40?000 for each file,
slightly more for the German file. We can see
that the average length of a sentence is roughly
20 to 25 symbols (slightly more for French). The
fourth line shows the percentage of sentences for
which Fips returned a complete analysis. The best
score is obtained with English (71.95%), closely
followed by French (70.01%). Greek is clearly
behind with only about 31%, largely due to the
fact that its grammar as well as its lexicon have
received much less attention so far. We can ob-
serve a quite clear (and unsurprising) correlation
between rich lexical coverage (English, French)
and high number of complete analyzes.
Finally the last line shows the speed of the
parser in terms of number of words per second.
The mean speed of Fips is between 130 and 180
word/second. FipsGreek is somewhat faster, pre-
sumably because its grammar is less developed
than the grammar of the other languages at this
point. It came up as a surprise to see that FipsEn-
glish was clearly slower. The reason has probably
to do with the high number of lexical ambiguities
of the type N/V (e.g. lead, study, balance, need)
which are likely to significantly increase the num-
ber of parallel (partial) analyzes.
6 Concluding remarks
Although the research described in this paper is
by no means completed, it has already achieved
several important goals. First of all, it has shown
that ?deep linguistic parsing? should not neces-
sarily be equated with ?inefficient parsing?. Al-
though clearly slower than shallow parsers, Fips is
fast enough for such demanding tasks as transla-
tion or terminology extraction.
At the software level, the adopted design makes
it possible to ?plug? an additional language with-
out any change or any recompilation of the sys-
tem. It is sufficient to add the language-specific
modules and lexical databases to have a fully func-
tional parser for that language. Arguably the
model has so far not been tested with languages
belonging to widely distinct language types. In
fact, it has only been applied to (a small set) of Eu-
ropean languages. Future work will address that
issue, and we are planning to extend our work to-
wards Asian and Semitic languages.
126
language German English Spanish French Greek Italian
number of symbols 1082117 1046431 1041466 1144345 1045778 998871
unknown words 13569 879 6825 853 26529 3099
number of sentences 45880 40348 40576 38653 39812 37726
% of complete analyzes 48.04% 71.95% 56.87% 70.01% 30.99% 58.74%
speed (word/second) 138 82 127 133 243 182
Figure 5: Comparative evaluation of the parsers
Acknowledgement
Thanks to Luka Nerima, Christopher Laenzlinger,
Gabriele Musillo and Antonio Leoni de Leo?n for
various suggestions and comments on earlier ver-
sions of this paper. The research described here
has been supported in part by a grant from the
Swiss national science foundation (no 101412-
103999).
7 References
Bresnan, J. (e?d.), 1982. The Mental Representa-
tion of Grammatical Relations, Cambridge,
Mass., MIT Press.
Bresnan, J., 2001. Lexical Functional Syntax, Ox-
ford, Blackwell.
Chomsky, N. 1995. The Minimalist Program,
Cambridge, Mass., MIT Press.
Chomsky, N. 2004. ?Beyond Explanatory Ade-
quacy?, in A. Belletti (ed.) The Cartography
of Syntactic Structures, Oxford, Oxford Uni-
versity Press.
Culicover, P. et R. Jackendoff, 2005. Simpler Syn-
tax, Oxford, Oxford University Press.
Haider, H. and I. Rosengren 1998. ?Scrambling?
Sprache und Pragmatik 49, Lund University.
Hinterho?lzl, R. 2006. Scrambling, Remnant
Movement and Restructuring in West Ger-
manic, Oxford, Oxford University Press.
Koehn, Ph., 2005. ?Europarl: A Parallel Cor-
pus for Statistical Machine Translation, MT
Summit.
Mo?ssenbo?ck, H. 1995. Object-Oriented Program-
ming in Oberon-2, New York, Springer.
Ross, .R. 1967. Constraints on Variables in Syn-
tax, Ph.D. dissertation, MIT.
Seretan, V. et E. Wehrli, 2006. ?Accurate colloca-
tion extraction using a multilingual parser? in
Proceedings of the 21st International Confer-
ence on Computational Linguistics and 44th
Annual Meeting of the Association for Com-
putational Linguistics (COLING/ACL 2006),
Sydney, 952-960.
Wehrli, E. 2004. ?Traduction, traduction de mots,
traduction de phrases?, in B. Bel et I. Marlien
(eds.), Proceedings of TALN XI, Fes, 483-
491.
Wehrli, E. 2006. ?TwicPen : Hand-held Scan-
ner and Translation Software for non-Native
Readers?, in Proceedings of the 21st Interna-
tional Conference on Computational Linguis-
tics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics (COL-
ING/ACL 2006), Sydney.
127
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 90?94,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
Deep Linguistic Multilingual Translation and Bilingual Dictionaries
Eric Wehrli, Luka Nerima & Yves Scherrer
LATL-Department of Linguistics
University of Geneva
fEric.Wehrli, Luka.Nerima, Yves.Scherrerg@unige.ch
Abstract
This paper describes the MulTra project,
aiming at the development of an efficient
multilingual translation technology based
on an abstract and generic linguistic model
as well as on object-oriented software de-
sign. In particular, we will address the is-
sue of the rapid growth both of the trans-
fer modules and of the bilingual databases.
For the latter, we will show that a signifi-
cant part of bilingual lexical databases can
be derived automatically through transitiv-
ity, with corpus validation.
1 Introduction
The goal of the MulTra project is to develop a
grammar-based translation model capable of han-
dling not just a couple of languages, but poten-
tially a large number of languages. This is not
an original goal, but as 50 years of work and in-
vestment have shown, the task is by no means an
easy one, and although SMT has shown fast and
impressive results towards it (e.g. EuroMatrix),
we believe that a (principled) grammar-based ap-
proach is worth developing, taking advantage of
the remarkable similarities displayed by languages
at an abstract level of representation. In the first
phase of this project (2007-2009), our work has
focused on French, English, German, Italian and
Spanish, with preliminary steps towards Greek,
Romanian, Russian and Japanese.
To evaluate the quality of the (still under devel-
opment) system, we decided to join the WMT09
translation evaluation with prototypes for the fol-
lowing language pairs: English to French, French
to English and German to English. In this short
paper, we will first give a rough description of the
MulTra system architecture and then turn to the
difficult issue of the bilingual dictionaries.
The MulTra project relies to a large extent on
abstract linguistics, inspired from recent work in
generative grammar (Chomsky, 1995, Culicover &
Jackendoff, 2005, Bresnan, 2001). The grammar
formalism developed for this project is both rich
enough to express the structural diversity of all the
languages taken into account, and abstract enough
to capture the generalizations hidden behind ob-
vious surface diversity. At the software level, an
object-oriented design has been used, similar in
many ways to the one adopted for the multilingual
parser (cf. Wehrli, 2007).
The rapid growth of the number of transfer
modules has often been viewed as a major flaw
of the transfer model when applied to multilingual
translation (cf. Arnold, 2000, Kay, 1997). This ar-
gument, which relies on the fact that the number of
transfer modules and of the corresponding bilin-
gual dictionaries increases as a quadratic function
of the number of languages, is considerably weak-
ened if one can show that transfer modules can
be made relatively simple and light (cf. section 2),
compared to the analysis and generation modules
(whose numbers are a linear function of the num-
ber of languages). Likewise, section 3 will show
how one can drastically reduce the amount of work
by deriving bilingual dictionaries by transitivity.
2 The architecture of the MulTra system
To a large extent, this system can be viewed as an
extension of the Multilingual Fips parsing project.
For one thing, the availability of the ?deep linguis-
tic? Fips parser for the targeted languages is a cru-
cial element for the MulTra project; second, the
MulTra software design matches the one devel-
oped for the multilingual parser. In both cases, the
goal is to set up a generic system which can be re-
defined (through type extension and method rede-
finition) to suit the specific needs of, respectively,
a particular language or a particular language pair.
90
2.1 Methodology
The translation algorithm follows the traditional
pattern of a transfer system. First the input
sentence is parsed by the Fips parser, produc-
ing an information-rich phrase-structure repre-
sentation with associated predicate-argument rep-
resentations. The parser also identifies multi-
word expressions such as idioms and colloca-
tions ? crucial elements for a translation sys-
tem (cf. Seretan & Wehrli, 2006). The transfer
module maps the source-language abstract repre-
sentation into the target-language representation.
Given the abstract nature of this level of repre-
sentation, the mapping operation is relatively sim-
ple and can be sketched as follows: recursively
traverse the source-language phrase structure in
the order: head, right subconstituents, left sub-
constituents. Lexical transfer (the mapping of a
source-language lexical item with an equivalent
target-language item) occurs at the head-transfer
level (provided the head is not empty) and yields
a target-language equivalent term often, but by no
means always, of the same category. Following
the projection principle used in the Fips parser, the
target-language structure is projected on the ba-
sis of the lexical item which is its head. In other
words, we assume that the lexical head determines
a syntactic projection (or meta-projection).
Projections (ie. constituents) which have been
analyzed as arguments of a predicate undergo
a slightly different transfer process, since their
precise target-language properties may be in
part determined by the subcategorization fea-
tures of the target-language predicate. To take
a simple example, the direct object of the
French verb regarder in (1a) will be trans-
ferred into English as a prepositional phrase
headed by the preposition at, as illustrated in
(2a). This information comes from the lexical
database. More specifically, the French-English
bilingual lexicon specifies a correspondence be-
tween the French lexeme [
VP
regarder NP ]
and the English lexeme [
VP
look [
PP
at NP ] ].
For both sentences, we also illustrate the syntactic
structures as built, respectively, by the parser for
the source sentence and by the translator for the
target sentence.
(1)a. Paul a regarde? la voiture.
b. [
TP
[
DP
Paul ] a [
VP
regarde? [
DP
la [
NP
voiture
] ] ] ]
(2)a. Paul looked at the car.
b. [
TP
[
DP
Paul ] [
VP
looked [
PP
at [
DP
the [
NP
car ] ] ] ] ]
2.2 Adding a language to the system
Given the general model as sketched above, the
addition of a language to the system requires (i) a
parser and (ii) a generator. Then for each language
pair for which that language is concerned, the sys-
tem needs (iii) a (potentially empty) language-pair
specific transfer module, and (iv) a bilingual lex-
ical database. The first three components are de-
scribed below, while the fourth will be the topic of
section 3.
Parser The Fips multilingual parser is assumed.
Adding a new language requires the following
tasks: (i) grammar description in the Fips formal-
ism, (ii) redefinition of the language-specific pars-
ing methods to suit particular properties of the lan-
guage, and (iii) creation of an appropriate lexical
database for the language.
Generator Target-language generation is done
in a largely generic fashion (as described above
with the transfer and projection mechanisms).
What remains specific in the generation phase is
the selection of the proper morphological form of
a lexical item.
Language-pair-specific transfer Transfer from
language A to language B requires no language-
pair specification if the language structures of A
and B are isomorphic. Simplifying a little bit,
this happens among closely related languages,
such as Spanish and Italian for instance. For
languages which are typologically different, the
transfer module must indicate how the precise
mapping is to be done.
Consider, for instance, word-order differences
such as adjectives which are prenominal in Eng-
lish and postnominal in French ? a red car vs.
une voiture rouge. The specific English-French
transfer module specifies that French adjectives,
which do not bear the [+prenominal] lexical fea-
ture, correspond to right subconstituents (vs. left
subconstituents) of the head noun. Other cases are
more complicated, such as the V2 phenomenon
in German, pronominal cliticization in Romance
languages, or even the use of the do auxiliary in
English interrogative or negative sentences. Such
cases are handled by means of specific procedures,
91
which are in some ways reminiscent of transfor-
mation rules of the standard theory of generative
grammar, ie. rules that can insert, move or even
delete phrase-structure constituents (cf. Akmajian
& Heny, 1975).
So far, the languages taken into account in
the MulTra project are those for which the Fips
parser has been well developed, that is English,
French, German, Italian and Spanish. Of the 20
potential language pairs five are currently opera-
tional (English-French, French-English, German-
French, German-English, Italian-French), while 6
other pairs are at various stages of development.
3 Multilingual lexical database
3.1 Overview of the lexical database
The lexical database is composed for each lan-
guage of (i) a lexicon of words, containing all
the inflected forms of the words of the language,
(ii) a lexicon of lexemes, containing the syn-
tactic/semantic information of the words (corre-
sponding roughly to the entries of a classical dic-
tionary) and (iii) a lexicon of collocations (in fact
multi-word expressions including collocations and
idioms). We call the lexemes and the collocations
the lexical items of a language.
The bilingual lexical database contains the in-
formation necessary for the lexical transfer from
one language to another. For storage purposes, we
use a relational database management system. For
each language pair, the bilingual dictionary is im-
plemented as a relational table containing the asso-
ciations between lexical items of language A and
lexical items of language B. The bilingual dictio-
nary is bi-directional, i.e. it also associates lexi-
cal items of language B with lexical items of lan-
guage A. In addition to these links, the table con-
tains transfer information such as translation con-
text (eg. sport, finance, law, etc.), ranking of the
pairs in a one-to-many correspondence, seman-
tic descriptors (used for interactive disambigua-
tion), argument matching for predicates (mostly
for verbs). The table structures are identical for
all pairs of languages.
Although the bilingual lexicon is bidirectional,
it is not symmetrical. If a word v from lan-
guage A has only one translation w in language
B, it doesn?t necessarily mean that w has only one
translation v. For instance the word tongue cor-
responds to French langue, while in the opposite
direction the word langue has two translations,
tongue and language. In this case the descriptor
attribute from French to English will mention re-
spectively ?body part? and ?language?. Another
element of asymmetry is the ranking attribute used
to mark the preferred correspondences in a one-to-
many translation1. For instance the lexicographer
can mark his preference to translate lovely into the
French word charmant rather than agre?able. Of
course the opposite translation direction must be
considered independently.
What is challenging in this project is that it ne-
cessitates as many bilingual tables as the number
of language pairs considered, i.e. n(n   1)=2 ta-
bles. We consider that an appropriate bilingual
coverage (for general purpose translation) requires
well over 60?000 correspondences per language
pair.
In the framework of this project we consider
5 languages (French, English, German, Italian,
Spanish). Currently, our database contains 4 bilin-
gual dictionaries (out of the 10 needed) with the
number of entries given in figure 1:
language pair Number of entries
English - French 77?569
German - French 47?797
French - Italian 38?188
Spanish - French 23?696
Figure 1: Number of correspondences in bilingual
dictionaries
Note that these 4 bilingual dictionaries were
manually created by lexicographers and the qual-
ity of the entries can be considered as good.
3.2 Automatic generation
The importance of multilingual lexical resources
in MT and, unfortunately, the lack of available
multilingual lexical resources has motivated many
initiatives and research work to establish collabo-
ratively made multilingual lexicons, e.g. the Pa-
pillon project (Boitet & al. 2002) or automatically
generated multilingual lexicons (see for instance
Aymerish & Camelo, 2007, Gamallo, 2007).
We plan to use semi-automatic generation to
build the 6 remaining dictionaries. For this pur-
pose we will derive a bilingual lexicon by transi-
tivity, using two existing ones. For instance, if we
have bilingual correspondences for language pair
1This attribute takes the form of an integer between 6 (pre-
ferred) and 0 (lowest).
92
A! B and B! C, we can obtain A! C. We will
see below how the correspondences are validated.
The idea of using a pivot language for deriv-
ing bilingual lexicons from existing ones is not
new. The reader can find related approaches in
(Paik & al. 2004, Ahn & Frampton 2006, Zhang
& al. 2007) . The specificity of our approach is
that the initial resources are manually made, i.e.
non noisy, lexicons.
The derivation process goes as follows:
1. Take two bilingual tables for language pairs
(A, B) and (B, C) and perform a relational
equi-join. Perform a filtering based on the
preference attribute to avoid combinatory ex-
plosion of the number of generated corre-
spondences.
2. Consider as valid all the unambiguous cor-
respondences. We consider that a generated
correspondence a ! c is unambiguous if for
the lexical item a there exists only one corre-
spondence a! b in the bilingual lexicon (A,
B) and for b there exists only one correspon-
dence b ! c in (B, C). As the lexicon is non
symmetrical, this process is performed twice,
once for each translation direction.
3. Consider as valid all the correspondences ob-
tained by a pivot lexical item of type colloca-
tion. We consider as very improbable that a
collocation is ambiguous.
4. All other correspondences are checked in a
parallel corpus, i.e. only the correspondences
actually used as translations in the corpus
are kept. First, the parallel corpus is tagged
by the Fips tagger (Wehrli, 2007) in order
to lemmatize the words. This is especially
valuable for languages with rich inflection,
as well as for verbs with particles. In order
to check the validity of the correspondences,
we count the effective occurrences of a given
correspondence in a sentence-aligned paral-
lel corpus, as well as the occurrences of each
of the lexical items of the correspondence. At
the end of the process, we apply the log like-
lihood ratio test to decide whether to keep or
discard the correspondence.
3.3 Results of automatic generation
The English-German lexicon that we used in the
shared translation task was generated automati-
cally. We derived it on the basis of English-French
and German-French lexicons. For the checking of
the validity of the correspondences (point 4 of the
process) we used the parallel corpus of the debates
of the European Parliament during the period 1996
to 2001 (Koehn, 2005). Figure 2 summarizes the
results of the four steps of the derivation process:
Step Type Eng.-Ger.
1 Candidate corresp. 89?022
2 Unambiguous corresp. 67?012
3 Collocation pivot 2?642
4 Corpus checked 2?404
Total validated corresp. 72?058
Figure 2: Number of derived entries for English-
German
We obtained a number of entries compara-
ble to those of the manually built bilingual lex-
icons. The number of the correspondences for
which a validation is necessary is 19?368 (89?022-
(67?012+2?642)), of which 2?404 (approximately
12%) have been validated based on the the Eu-
roParl corpus, as explained above. The low figure,
well below our expectations, is due to the fact that
the corpus we used is not large enough and is prob-
ably not representative of the general language.
Up to now, the English-German dictionary re-
quired approximately 1?400 entries to be added
manually, which is less than 2% of the entire lexi-
con.
4 Conclusion
Based on a deep linguistic transfer approach and
an object-oriented design, the MulTra multilingual
translation system aims at developing a large num-
ber of language pairs while significantly reduc-
ing the development cost as the number of pairs
grows. We have argued that the use of an abstract
and relatively generic linguistic level of represen-
tation, as well as the use of an object-oriented soft-
ware design play a major role in the reduction of
the complexity of language-pair transfer modules.
With respect to the bilingual databases, (corpus-
checked) automatic derivation by transitivity has
been shown to drastically reduce the amount of
work.
Acknowledgments
The research described in this paper has been sup-
ported in part by a grant from the Swiss national
science foundation (no 100015-113864).
93
5 References
Ahn, K. and Frampton, M. 2006. ?Automatic Gen-
eration of Translation Dictionaries Using In-
termediary Languages?? in Cross-Language
knowledge Induction Workshop of the EACL
06, Trento, Italy, pp 41- 44.
Akmajian, A. and F. Heny, 1975. An Introduction
to the Principles of Generative Syntax, MIT
Press.
Arnold, D. 2000. ?Why translation is difficult for
computers? in H.L. Somers (ed.) Computers
and Translation : a handbook for translators,
John Benjamin.
Aymerich, J. and Camelo, H. 2007.? Automatic
extraction of entries for a machine translation
dictionary using bitexts?? in MT Summit XI,
Copenhagen, pp. 21-27
Boitet, Ch. 2001. ?Four technical and organi-
zational keys to handle more languages and
improve quality (on demand) in MT? in Pro-
ceedings of MT-Summit VIII, Santiago de
Compostela, 18-22.
Boitet, Ch., Mangeot, M. and Se?rasset, G.
2002. ?The PAPILLON project: coopera-
tively building a multilingual lexical data-
base to derive open source dictionaries & lex-
icons? in Proceedings of the 2nd workshop
on NLP and XML, COLING 2002, Taipei,
Taiwan.
Bresnan, J. 2001. Lexical Functional Syntax, Ox-
ford, Blackwell.
Chomsky, N. 1995. The Minimalist Program,
Cambridge, Mass., MIT Press.
Culicover, P. & R. Jackendoff, 2005. Simpler Syn-
tax, Oxford, Oxford University Press.
Gamallo, P. 2007. ?Learning Bilingual Lexi-
cons from Comparable English and Spanish
Corpora? in Proceedings of MT Summit XI,
Copenhagen.
Hutchins, J. 2003. ?Has machine translation im-
proved?? in Proceedings of MT-Summit IX,
New Orleans, 23-27.
Kay, M. 1997. ?Machine Translation : the Dis-
appointing Past and Present? in R.A. Cole, J.
Mariani, H. Uskoreit, G. Varile, A. Zaenen
and A. Zampoli Survey of the State of the
Art in Human Language Technology, Giar-
dini Editori.
Koehn, P. 2005. ?Europarl: A Parallel Corpus
for Statistical Machine Translation?? in MT
Summit 2005.
Ney, H. 2005. ?One Decade of Statistical Machine
Translation? in Proceedings of MT-Summit
X, Pukhet, Thailand.
Paik, K., Shirai, S. and Nakaiwa, H. 2004. ?Au-
tomatic Construction of a Transfer Dictio-
nary Considering Directionality?, in COL-
ING 2004 Multilingual Linguistic Resources
Workshop, Geneva, pp. 25-32.
Seretan, V. & E. Wehrli, 2006. ?Accurate Colloca-
tion Extraction Using a Multilingual Parser?
in Proceedings of the ACL, 953-960, Sydney,
Australia.
Wehrli, E. 2007. ?Fips, a ?deep? linguistic mul-
tilingual parse? in Proceedings of the ACL
2007 Workshop on Deep Linguistic process-
ing, 120-127, Prague, Czech Republic.
Zhang, Y., Ma, Q. and Isahara, H. 2007. ?Build-
ing Japanese-Chinese Translation Dictionary
Based on EDR Japanese-English Bilingual
Dictionary? inMT Summit XI, Copenhagen,
pp 551-557.
94
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 28?36,
Beijing, August 2010
Sentence Analysis and Collocation Identification
Eric Wehrli, Violeta Seretan, Luka Nerima
Language Technology Laboratory
University of Geneva
{Eric.Wehrli, Violeta.Seretan, Luka.Nerima}@unige.ch
Abstract
Identifying collocations in a sentence, in
order to ensure their proper processing in
subsequent applications, and performing
the syntactic analysis of the sentence are
interrelated processes. Syntactic informa-
tion is crucial for detecting collocations,
and vice versa, collocational information
is useful for parsing. This article describes
an original approach in which collocations
are identified in a sentence as soon as pos-
sible during the analysis of that sentence,
rather than at the end of the analysis, as in
our previous work. In this way, priority is
given to parsing alternatives involving col-
locations, and collocational information
guide the parser through the maze of alter-
natives. This solution was shown to lead
to substantial improvements in the perfor-
mance of both tasks (collocation identifi-
cation and parsing), and in that of a sub-
sequent task (machine translation).
1 Introduction
Collocations1 constitute a central language phe-
nomenon and an impressive amount of work has
been devoted over the past decades to the automa-
tic acquisition of collocational resources ? as at-
tested, among others, by initiatives like the MWE
2008 shared task aimed at creating a repository of
reference data (Gre?goire et al, 2008). However,
little or no reference exist in the literature about
1We adopt the lexicographic understanding for the term
collocation (Benson et al, 1986), as opposed to the British
contextualist tradition focused on statistical co-occurrence
(Firth, 1957; Sinclair, 1991).
the actual use made of these resources in other
NLP applications.
In this paper, we consider the particular appli-
cation of syntactic parsing. Just as other types of
multi-word expressions (henceforth, MWEs), col-
locations are problematic for parsing because they
have to be recognised and treated as a whole, ra-
ther than compositionally, i.e., in a word by word
fashion (Sag et al, 2002). The standard approach
in dealing with MWEs in parsing is to apply
a ?words-with-spaces? preprocessing step, which
marks the MWEs in the input sentence as units
which will later be integrated as single blocks in
the parse tree built during analysis.
We argue that such an approach, albeit suffi-
ciently appropriate for some subtypes of MWEs2,
is not really adequate for processing colloca-
tions. Unlike other expressions that are fixed or
semi-fixed3, collocations do not allow a ?words-
with-spaces? treatment because they have a high
morpho-syntactic flexibility.
There is no systematic restriction, for instance,
on the number of forms a lexical item (such as a
verb) may have in a collocation, on the order of
items in a collocation, or on the number of words
that may intervene between these items. Collo-
cations are situated at the intersection of lexicon
and grammar; therefore, they cannot be accounted
for merely by the lexical component of a parsing
system, but have to be integrated to the grammati-
cal component as well, as the parser has to consi-
2Sag et al (2002) thoroughly discusses the extend to
which a ?words-with-spaces? approach is appropriate for dif-
ferent kinds of MWEs.
3For instance, compound words: by and large, ad hoc;
named entities: New York City; and non-decomposable
idioms: shoot the breeze.
28
der all the possible syntactic realisations of collo-
cations.
Alternatively, a post-processing approach (such
as the one we pursued previously in Wehrli et
al. (2009b)) would identify collocations after the
syntactic analysis has been performed, and out-
put a parse tree in which collocational relations
are highlighted between the composing items, in
order to inform the subsequent processing appli-
cations (e.g., a machine translation application).
Again, this solution is not fully appropriate, and
the reason lies with the important observation that
prior collocational knowledge is highly relevant
for parsing. Collocational restrictions are, along
with other types of information like selectional
preferences and subcategorization frames, a major
means of structural disambiguation. Collocational
relations between the words in a sentence proved
very helpful in selecting the most plausible among
all the possible parse trees for a sentence (Hindle
and Rooth, 1993; Alshawi and Carter, 1994; Ber-
thouzoz and Merlo, 1997; Wehrli, 2000). Hence,
the question whether collocations should be iden-
tified in a sentence before or after parsing is not an
easy one. The previous literature on parsing and
collocations fails to provide insightful details on
how this circular issue is (or can be) solved.
In this paper, we argue that the identification of
collocations and the construction of a parse tree
are interrelated processes, that must be accounted
for simultaneously. We present a processing mo-
del in which collocations, if present in a lexicon,
are identified in the input sentence during the ana-
lysis of that sentence. At the same time, they are
used to rank competing parsing hypotheses.
The paper is organised as follows. Section 2
reviews the previous work on the interrelation
between parsing and processing of collocations
(or, more generally, MWEs). Section 3 introduces
our approach, and section 4 evaluates it by compa-
ring it against the standard non-simultaneous ap-
proach. Section 5 provides concluding remarks
and presents directions for future work.
2 Related Work
Extending the lexical component of a parser with
MWEs was proved to contribute to a significant
improvement of the coverage and accuracy of par-
sing results. For instance, Brun (1998) compared
the coverage of a French parser with and wi-
thout terminology recognition in the preproces-
sing stage. She found that the integration of 210
nominal terms in the preprocessing components of
the parser resulted in a significant reduction of the
number of alternative parses (from an average of
4.21 to 2.79). The eliminated parses were found
to be semantically undesirable. No valid analy-
sis were ruled out. Similarly, Zhang and Kor-
doni (2006) extended a lexicon with 373 additio-
nal MWE lexical entries and obtained a significant
increase in the coverage of an English grammar
(14.4%, from 4.3% to 18.7%).
In the cases mentioned above, a ?words-with-
spaces? approach was used. In contrast, Ale-
gria et al (2004) and Villavicencio et al (2007)
adopted a compositional approach to the enco-
ding of MWEs, able to capture more morpho-
syntactically flexible MWEs. Alegria et al (2004)
showed that by using a MWE processor in the pre-
processing stage of their parser (in development)
for Basque, a significant improvement in the POS-
tagging precision is obtained. Villavicencio et al
(2007) found that the addition of 21 new MWEs
to the lexicon led to a significant increase in the
grammar coverage (from 7.1% to 22.7%), without
altering the grammar accuracy.
An area of intensive research in parsing is
concerned with the use of lexical preferences, co-
occurrence frequencies, collocations, and contex-
tually similar words for PP attachment disambi-
guation. Thus, an important number of unsupervi-
sed (Hindle and Rooth, 1993; Ratnaparkhi, 1998;
Pantel and Lin, 2000), supervised (Alshawi and
Carter, 1994; Berthouzoz and Merlo, 1997), and
combined (Volk, 2002) methods have been deve-
loped to this end.
However, as Hindle and Rooth (1993) pointed
out, the parsers used by such methods lack pre-
cisely the kind of corpus-based information that
is required to resolve ambiguity, because many
of the existing attachments may be missing or
wrong. The current literature provides no indi-
cation about the manner in which this circular
problem can be circumvented, and on whether
flexible MWEs should be processed before, du-
ring or after the sentence analysis takes place.
29
3 Parsing and Collocations
As argued by many researchers ? e.g., Heid (1994)
? collocation identification is best performed on
the basis of parsed material. This is due to the
fact that collocations are co-occurrences of lexi-
cal items in a specific syntactic configuration. The
collocation break record, for instance, is obtained
only in the configurations where break is a verb
whose direct object is (semantically) headed by
the lexical item record. In other words, the collo-
cation is not defined in terms of linear proximity,
but in terms of a specific grammatical relation.
As the examples in this section show, the rela-
tive order of the two items is not relevant, nor is
the distance between the two terms, which is unli-
mited as long as the grammatical relation holds4.
In our system, the grammatical relations are com-
puted by a syntactic parser, namely, Fips (Wehrli,
2007; Wehrli and Nerima, 2009). Until now, the
collocation identification process took place at the
end of the parse in a so-called ?interpretation?
procedure applied to the complete parse trees. Al-
though quite successful, this way of doing pre-
sents a major drawback: it happens too late to
help the parser. This section discusses this point
and describes the alternative that we are currently
developing, which consists in identifying colloca-
tions as soon as possible during the parse.
One of the major hurdles for non-deterministic
parsers is the huge number of alternatives that
must be considered. Given the high fre-
quency of lexical ambiguities, the high level of
non-determinism of natural language grammars,
grammar-based parsers are faced with a number
of alternatives which grows exponentially with the
length of the input sentence. Various methods
have been proposed to reduce that number, and
in most cases heuristics are added to the parsing
algorithm to limit the number of alternatives. Wi-
thout such heuristics, the performance of a parser
might not be satisfactory enough for large scale
applications such as machine translation or other
tasks involving large corpora.
We would like to argue, along the lines of
previous work (section 2), that collocations can
4Goldman et al (2001) report examples in which the dis-
tance between the two terms of a collocation can exceed 30
words.
contribute to the disambiguation process so cru-
cial for parsing. To put it differently, identifying
collocations should not be seen as a burden, as an
additional task the parser should perform, but on
the contrary as a process which may help the par-
ser through the maze of alternatives. Collocations,
in their vast majority, are made of frequently used
terms, often highly ambiguous (e.g., break record,
loose change). Identifying them and giving them
high priority over alternatives is an efficient way
to reduce the ambiguity level. Ambiguity reduc-
tion through the identification of collocations is
not limited to lexical ambiguities, but also applies
to attachment ambiguities, and in particular to the
well-known problem of PP attachment. Consider
the following French examples in which the pre-
positions are highlighted:
(1)a. ligne de partage des eaux (?watershed?)
b. syste`me de gestion de base de donne?es (?da-
tabase management system?)
c. force de maintien de la paix (?peacekeeping
force?)
d. organisation de protection de
l?environnement (?environmental protection
agency?)
In such cases, the identification of a noun-
preposition-noun collocation will prevent or dis-
courage any other type of prepositional attach-
ment that the parser would otherwise consider.
3.1 The Method
To fulfill the goal of interconnecting the parsing
procedure and the identification of collocations,
we have incorporated the collocation identifica-
tion mechanism within the constituent attachment
procedure of our parser Fips (Wehrli, 2007). This
parser, like many grammar-based parsers, uses
left attachment and right attachment rules to build
respectively left subconstituents and right sub-
constituents. Given the fact that Fips? rules always
involve exactly two constituents ? see Wehrli
(2007) for details ? it is easy to add to the attach-
ment mechanism the task of collocation identifica-
tion. To take a very simple example, when the rule
attaching a prenominal adjective to a noun applies,
the collocation identification procedure is invo-
ked. It first verifies that both terms bear the lexical
30
feature [+partOfCollocation], which signals that a
given word is associated in our lexical database to
one or several collocations, and then searches the
collocation database for an adjective-noun collo-
cation with those two terms. If successful, the cor-
responding parse tree will be given a high priority.
With examples such as loose change, the iden-
tification of the collocation will immediately re-
legate any (partial) analysis based on the verbal
reading of either terms.
To take a somewhat more complex example,
consider a verb-object collocation such as break
record, as in example (2)5.
(2)a. John broke a record.
b. [TP [DP John ] broke [DP a [NP record ] ] ]
Here, it is a right attachment rule which will
trigger the identification procedure. To be precise,
the right attachment rule in this case concerns the
attachment of the noun record as complement
of the indefinite determiner (head of the DP
direct object of the verb). The identification
procedure considers, in turn, all the governing
nodes dominating the noun record, halting at the
first node of category Noun6, Verb or Adjective.
In our example, the determiner node and then
the verb node will be considered. Notice that the
procedure will, quite correctly, identify a colloca-
tion in the French example (3a), but not in (3b),
although both structures are identical. The reason
has to do with the fact that the noun governing
record in the first example is a [+number] noun,
that is a classifier noun which is transparent for
the identification procedure7.
(3)a. Jean a battu un grand nombre de records.
?Jean broke a large number of records?
5We use the following labels in our phrase-structure re-
presentations: TP-Tense phrase, for simple sentence (the S of
standard CFG), CP-Complementizer phrase, for a sentence
with a conjunction or a complementizer, DP-Determiner
phrase for standard noun phrases (we assume the DP hy-
pothesis, whereby the determiner constitutes the syntac-
tic head of a noun phrase), NP-Noun phrase for nominal
projections (nouns with their modifiers/complements), VP-
Verb phrase, PP-Prepositional phrase, AP-Adjectival phrase,
AdvP-Adverbial phrase, FP-Functional phrase (used for se-
condary predicates).
6Unless the node it marked [+number], as we will see
shortly.
7See Fontenelle (1999) for a detailed account of transpa-
rent nouns.
b. Jean a battu le de?tenteur du record.
?Jean has beaten the holder of the record?
As in the other examples, an analysis in which
a collocation has been found is given high prio-
rity over alternatives. In the case of (2), this will
relegate potential analyses based on the adjectival
reading of broke or the verbal reading of record.
Notice that exactly the same procedure applies
when the trace of an extraposed element is (right)
inserted, as in the examples (4), which illustrate
the case of wh-interrogative (a), relative clause
(b), tough-movement (c).
(4)a. Which record will Paul try to break ?
b. The record Paul broke was very old.
c. This record is difficult to break.
In all such cases, that is, when the right inserted
element is a trace, the identification procedure
will consider its antecedent, or to be more precise,
the semantic head of its antecedent. Finally, the
grammatical processes involved in example (4a,c)
can combine as in the more complex example (5),
for which we give the slightly simplified structure
with the chain of elements with index i extending
from the fronted wh-phrase which record to the
direct object position of the verb break, via the
direct object position of the verb consider and the
subject position of the secondary predicate (FP)
headed by the [+tough] adjective difficult.
(5)a. Which record did Paul consider difficult to
break ?
b. [ CP [ DP which record]i [ TP did [ DP Paul
] [ VP consider ][ DP e]i [ FP [ DP e]i [ AP
difficult [ TP to [ VP break [ DP e]i ] ] ] ] ] ]
3.2 Complex Collocations
As stated, for instance, by (Heid, 1994), colloca-
tions can involve more than two (main) terms and
it is possible to adopt a recursive definition of col-
locations, i.e., complex collocations can be vie-
wed as collocations of collocations. The colloca-
tion identification procedure has been extended to
handle such cases. Consider examples (6) below.
(6)a. La voiture tombera probablement en panne
d?essence.
?the car will probably run out of gas?
31
b. natural language processing
c. He broke a world record.
In the French sentence (6a), panne d?essence
(literally, ?breakdown of gas?, ?out of gas?) is
a collocation of type Noun+Prep+Noun, which
combines with the verb tomber (literally, ?to
fall?) to form a larger collocation of type
Verb+PrepObject tomber en panne d?essence (?to
run out of gas?). Given the strict left to right
processing order assumed by the parser, it will
first identify the collocation tomber en panne (?to
break down?) when attaching the word panne.
Then, reading the last word, essence (?gas?), the
parser will first identify the collocation panne
d?essence. Since that collocation bears the lexi-
cal feature [+partOfCollocation], the identifica-
tion procedure goes on, through the governors
of that item. The search succeeds with the verb
tomber, and the collocation tomber en panne
d?essence (?run out of gas?) is identified.
4 Evaluation Experiments
In this section, we describe the experiments we
performed in order to evaluate the precision and
recall of the method introduced in section 3, and
to compare it against the previous method (fully
described in Wehrli et al (2009b)). We extend
this comparison by performing a task-based eva-
luation, which investigates the impact that the new
method has on the quality of translations produ-
ced by a machine translation system relying on
our parser (Wehrli et al, 2009a).
4.1 Precision Evaluation
The data considered in this experiment consist of
a subpart of a corpus of newspaper articles collec-
ted from the on-line version of The Economist8,
containing slightly more that 0.5 million words.
On these data, we run two versions of our parser:
? V1: a version implementing the previous me-
thod of collocation identification,
? V2: a version implementing the new method
described in section 3.
8URL:http://www.economist.com/
(accessed June, 2010).
The lexicon of the parser was kept constant,
which is to say that both versions used the same
lexicon (which contains slightly more than 7500
English collocation entries), only the parsing mo-
dule handling collocations was different. From
the output of each parser version, we collected
statistics on the number of collocations (present
in the lexicon) that were identified in the test cor-
pus. More precisely, we traversed the output trees
and counted the items that were marked as col-
location heads, each time this was the case (note
that an item may participate in several colloca-
tions, not only one). Table 1 presents the num-
ber of collocations identified, both with respect to
collocation instances and collocation types.
V1 V2 common V1 only V2 only
Tokens 4716 5412 4347 399 1003
Types 1218 1301 1182 143 368
Table 1. Collocation identification results.
As the results show, the new method (column
V2) is more efficient in retrieving collocation ins-
tances. It detects 696 more instances, which cor-
respond to an increase of 14.8% relative to the
previous method (column V1). As we lack the
means to compare on a large scale the correspon-
ding syntactic trees, we can only speculate that the
increase is mainly due to the fact that more appro-
priate analyses are produced by the new method.
A large number of instances are found by both
versions of the parser. The difference between
the two methods is more visible for some syn-
tactic types than for others. Table 2 details the
number of instances of each syntactic type which
are retrieved exclusively by one method or by the
other.
To measure the precision of the two methods,
we randomly selected 20 collocation instances
among those identified by each version of the par-
ser, V1 and V2, and manually checked whether
these instances are correct. Correctness means
that in the given context (i.e., the sentence in
which they were identified), the word combina-
tion marked as instance of a lexicalized colloca-
tion is indeed an instance of that collocation. A
counterexample would be, for instance, to mark
the pair decision - make in the sentence in (7) as
32
Syntactic type V1 V2 Difference V2-V1
A-N 72 152 80
N-N 63 270 207
V-O 22 190 168
V-P-N 6 10 4
N-P-N 1 62 61
V-A 25 166 141
P-N 200 142 -58
N&N 6 2 -4
Adv-Adv 4 9 5
Table 2. Differences between the two methods:
number of tokens retrieved exclusively by each
method.
an instance of the verb-object collocation to make
a decision, which is an entry in our lexicon.
(7)a. The decision to make an offer to buy or sell
property at price is a management decision
that cannot be delegated to staff.
Since judging the correctness of a collocation ins-
tance in context is a rather straightforward task,
we do not require multiple judges for this evalua-
tion. The precision obtained is 90% for V1, and
100% for V2.
The small size of test set is motivated by the
fact that the precision is expected to be very high,
since the presence of both collocation components
in a sentence in the relevant syntactic relation al-
most certainly means that the recognition of the
corresponding collocation is justified. Exceptions
would correspond to a minority of cases in which
the parser either wrongly establishes a relation
between two items which happen to belong to an
entry in the lexicon, or the two items are related
but the combination corresponds to a literal usage
(examples are provided later in this section).
The errors of V1 correspond, in fact, to cases in
which a combination of words used literally was
wrongly attributed to a collocation: in example
(8a), V1 assigned the words on and business to
the lexical entry on business, and in example (8b),
it assigned in and country to the entry in the coun-
try9.
(8)a. It is not, by any means, specific to the
countryside, but it falls especially heavily on
small businesses.
9V1 makes the same error on (8a), but does better on (8b).
These expressions are frozen and should not be treated as
standard collocations.
b. Industrial labour costs in western Germany
are higher than in any other country.
To better pinpoint the difference between V1
and V2, we performed a similar evaluation on an
additional set of 20 instances, randomly selected
among the collocations identified exclusively by
each method. Thus, the precision of V1, when
measured on the tokens in ?V1 only?, was 65%.
The precision of V2 on ?V2 only? was 90%. The
2 errors of V2 concern the pair in country, found
in contexts similar to the one shown in example
(8b). The errors of V1 also concerned the same
pair, with one exception ? the identification of the
collocation world trade from the context the des-
truction of the World Trade Centre. Since World
Trade Centre is not in the parser lexicon, V1 ana-
lysed it and assigned the first two words to the en-
try world trade. World was wrongly attached to
Trade, rather than to Centre.
When reported on the totality of the instances
tested, the precision of V1 is 77.5% and that of
V2 is 95%. Besides the increase in the precision
of identified collocations, the new method also
contributes to an increase in the parser coverage10,
from 81.7% to 83.3%. The V1 parser version suc-
ceeds in building a complete parse tree for 23187
of the total 28375 sentences in the corpus, while
V2 does so for 23629 sentences.
4.2 Recall Evaluation
To compare the recall of two methods we perfor-
med a similar experiment, in which we run the two
versions of the parser, V1 and V2, on a small col-
lection of sentences containing annotated colloca-
tion instances. These sentences were randomly
selected from the Europarl corpus (Koehn, 2005).
The collocations they contain are all verb-object
collocations. We limit our present investigation
to this syntactic type for two reasons: a) anno-
tating a corpus with all instances of collocation
entries in the lexicon would be a time-consuming
task; and b) verb-object collocations are among
the most syntactically flexible and therefore diffi-
cult to detect in real texts. Thus, this test set pro-
vides realistic information on recall.
10Coverage refers more precisely to the ratio of sentences
for which a complete parse tree could be built.
33
The test set is divided in two parts: 100 sen-
tences are in English, and 100 other in Italian,
which allows for a cross-linguistic evaluation of
the two methods. Each sentence contains one an-
notated collocation instance, and there are 10 ins-
tances for a collocation type. Table 3 lists the col-
location types in the test set (the even rows in co-
lumn 2 display the glosses for the words in the
Italian collocations).
English Italian
bridge gap assumere atteggiamento
?assume? ?attitude?
draw distinction attuare politica
?carry out? ?policy?
foot bill avanzare proposta
?advance? ?proposal?
give support avviare dialogo
?start? ?dialogue?
hold presidency compiere sforzo
?commit? ?effort?
meet condition dare contributo
?give? ?contribution?
pose threat dedicare attenzione
?dedicate? ?attention?
reach compromise operare scelta
?operate? ?choice?
shoulder responsibility porgere benvenuto
?give? ?welcome?
strike balance raggiungere intesa
?reach? ?understanding?
Table 3. Collocation types in the test set.
The evaluation results are presented in table 4.
V1 achieves 63% recall performance on the En-
glish data, and 44% on the Italian data. V2 shows
considerably better results: 76% on English and
66% on Italian data. The poorer performance
of both methods on Italian data is explained by
the difference in performance between the English
and Italian parsers, and more precisely, by the dif-
ference in their grammatical coverage. The En-
glish parser succeeds in building a complete parse
tree for more than 70% of the sentences in the test
set, while the Italian parser only for about 60%.
As found in the previous experiment (presen-
ted in section 4.1), for both languages considered
in this experiment, the new method of processing
collocations contributes to improving the parsing
coverage. The coverage of the English parser in-
creases from 71% to 76%, and that of the Italian
parser from 57% to 61%.
V1 V2 Common V1 only V2 only
English 63 76 61 2 15
Italian 44 66 42 2 24
Table 4. Recall evaluation results: number of cor-
rect collocation instances identified.
4.3 Task-based Evaluation
In addition to reporting the performance results by
using the standard measures of precision and re-
call, we performed a task-based performance eva-
luation, in which we quantified the impact that the
newly-proposed method has on the quality of the
output of a machine translation system. As the
examples in table 3 suggest, a literal translation of
collocations is rarely the most appropriate. In fact,
as stated by Orliac and Dillinger (2003), know-
ledge of collocations is crucial for machine trans-
lation systems. An important purpose in iden-
tifying collocations with our parser is to enable
their proper treatment in our translation system, a
rule-based system that performs syntactic transfer
by relying on the structures produced by the par-
ser.
In this system, the translation of a collocation
takes place as follows. When the parser identi-
fies a collocation in the source sentence, its com-
ponent words are marked as collocation mem-
bers, in order to prevent their literal translation.
When the transfer module processes the collo-
cation head, the system checks in the bilingual
lexicon whether an entry exists for that colloca-
tion. If not, the literal translation will apply;
otherwise, the transfer module projects a target-
language structure as specified in the correspon-
ding target lexical entry. More precisely, the trans-
fer yields a target language abstract representa-
tion, to which grammatical transformations and
morphological generation will apply to create the
target sentence. The identification of collocations
in the source text is a necessary, yet not a sufficient
condition for their successful translation.
In this experiment, we considered the test set
described in section 4.2 and we manually eva-
luated the translation obtained for each colloca-
tion instance. Both subsets (100 English sen-
tences and 100 Italian sentences) were translated
into French. We compared the translations obtai-
34
Task Measure Test set Language Increase
Collocation identification precision 40 instances English 17.5%
recall 200 instances English, Italian 17.5%
100 instances English 13%
100 instances Italian 22%
Collocation translation precision 200 instances {English, Italian}-French 13%
100 instances English-French 10%
100 instances Italian-French 16%
Parsing coverage 28375 sentences English 1.6%
200 sentences English 5%
200 sentences Italian 4%
Table 5. Summary of evaluation results.
ned by relying on the versions V1 and V2 of our
parser (recall that V2 corresponds to the newly-
proposed method and V1 to the previous method).
The use of automatic metrics for evaluating the
translation output was not considered appropriate
in this context, since such n-gram based metrics
underestimate the effect that the substitution of a
single word (like in our case, the verb in a verb-
object collocation) has on the fluency, adequacy,
and even on the interpretability of the output sen-
tence.
The comparison showed that, for both language
pairs considered (English-French and Italian-
French), the version of parser which integrates the
new method is indeed more useful for the ma-
chine translation system than the previous version.
When V2 was used, 10 more collocation instances
were correctly translated from English to French
than when using V1. For the Italian-French pair,
V2 helped correctly translating 16 more colloca-
tion instances in comparison with V1. This cor-
responds to an increase in precision of 13% on the
whole test set of 200 sentences. The increase in
performance obtained in all the experiments des-
cribed in this section is summarized in table 5.
5 Conclusion
In this paper, we addressed the issue of the inter-
connection between collocation identification and
syntactic parsing, and we proposed an original so-
lution for identifying collocations in a sentence as
soon as possible during the analysis (rather than at
the end of the parsing process). The major advan-
tage of this approach is that collocational informa-
tion may be used to guide the parser through the
maze of alternatives.
The experimental results performed showed
that the proposed method, which couples parsing
and collocation identification, leads to substan-
tial improvements in terms of precision and re-
call over the standard identification method, while
contributing to augment the coverage of the par-
ser. In addition, it was shown that it has a posi-
tive impact on the results of a subsequent appli-
cation, namely, machine translation. Future work
will concentrate on improving our method so that
it accounts for all the possible syntactic configu-
rations of collocational attachments, and on exten-
ding its recall evaluation to other syntactic types.
Acknowledgements
Thanks to Lorenza Russo and Paola Merlo for a
thorough reading and comments. Part of the re-
search described in this paper has been supported
by a grant from the Swiss National Science Foun-
dation, grant no 100015-117944.
References
Alegria, In?aki, Olatz Ansa, Xabier Artola, Nerea
Ezeiza, Koldo Gojenola, and Ruben Urizar. 2004.
Representation and treatment of multiword expres-
sions in basque. In Second ACL Workshop on Mul-
tiword Expressions: Integrating Processing, pages
48?55, Barcelona, Spain.
Alshawi, Hiyan and David Carter. 1994. Training
and scaling preference functions for disambigua-
tion. Computational Linguistics, 20(4):635?648.
Benson, Morton, Evelyn Benson, and Robert Ilson.
1986. The BBI Dictionary of English Word Combi-
nations. John Benjamins, Amsterdam/Philadelphia.
Berthouzoz, Cathy and Paola Merlo. 1997. Statis-
tical ambiguity resolution for principle-based par-
sing. In Nicolov, Nicolas and Ruslan Mitkov, edi-
35
tors, Recent Advances in Natural Language Pro-
cessing: Selected Papers from RANLP?97, Current
Issues in Linguistic Theory, pages 179?186. John
Benjamins, Amsterdam/Philadelphia.
Brun, Caroline. 1998. Terminology finite-state pre-
processing for computational LFG. In Proceedings
of the 36th Annual Meeting of the Association for
Computational Linguistics and 17th International
Conference on Computational Linguistics, pages
196?200, Morristown, NJ, USA.
Firth, John R. 1957. Papers in Linguistics 1934-1951.
Oxford Univ. Press, Oxford.
Fontenelle, Thierry. 1999. Semantic resources for
word sense disambiguation: a sine qua non? Lin-
guistica e Filologia, (9):25?43. Dipartimento di
Linguistica e Letterature Comparate, Universita` de-
gli Studi di Bergamo.
Goldman, Jean-Philippe, Luka Nerima, and Eric
Wehrli. 2001. Collocation extraction using a syn-
tactic parser. In Proceedings of the ACL Work-
shop on Collocation: Computational Extraction,
Analysis and Exploitation, pages 61?66, Toulouse,
France.
Gre?goire, Nicole, Stefan Evert, and Brigitte Krenn,
editors. 2008. Proceedings of the LREC Workshop
Towards a Shared Task for Multiword Expressions
(MWE 2008). European Language Resources Asso-
ciation (ELRA), Marrakech, Morocco.
Heid, Ulrich. 1994. On ways words work together
? research topics in lexical combinatorics. In Pro-
ceedings of the 6th Euralex International Congress
on Lexicography (EURALEX ?94), pages 226?257,
Amsterdam, The Netherlands.
Hindle, Donald and Mats Rooth. 1993. Structural am-
biguity and lexical relations. Computational Lin-
guistics, 19(1):103?120.
Koehn, Philipp. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of
The Tenth Machine Translation Summit (MT Sum-
mit X), pages 79?86, Phuket, Thailand, September.
Orliac, Brigitte and Mike Dillinger. 2003. Collocation
extraction for machine translation. In Proceedings
of Machine Translation Summit IX, pages 292?298,
New Orleans, Lousiana, USA.
Pantel, Patrick and Dekang Lin. 2000. An unsuper-
vised approach to prepositional phrase attachment
using contextually similar words. In Proceedings
of the 38th Annual Meeting of the Association for
Computational Linguistics, pages 101?108, Hong
Kong, China.
Ratnaparkhi, Adwait. 1998. Statistical models for un-
supervised prepositional phrase attachment. In Pro-
ceedings of the 36th Annual Meeting of the Associa-
tion for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics,
pages 1079?1085, Montreal, Quebec, Canada.
Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1?15, Mexico City.
Sinclair, John. 1991. Corpus, Concordance, Colloca-
tion. Oxford University Press, Oxford.
Villavicencio, Aline, Valia Kordoni, Yi Zhang, Marco
Idiart, and Carlos Ramisch. 2007. Validation and
evaluation of automatically acquired multiword ex-
pressions for grammar engineering. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computatio-
nal Natural Language Learning (EMNLP-CoNLL),
pages 1034?1043, Prague, Czech Republic, June.
Volk, Martin. 2002. Combining unsupervised and
supervised methods for PP attachment disambi-
guation. In Proceedings of the 19th Internatio-
nal Conference on Computational Linguistics (CO-
LING?02), pages 25?32, Taipei, Taiwan.
Wehrli, Eric and Luka Nerima. 2009. L?analyseur
syntaxique Fips. In Proceedings of the IWPT 2009
ATALA Workshop: What French parsing systems?,
Paris, France.
Wehrli, Eric, Luka Nerima, and Yves Scherrer. 2009a.
Deep linguistic multilingual translation and bilin-
gual dictionaries. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
90?94, Athens, Greece. Association for Computa-
tional Linguistics.
Wehrli, Eric, Violeta Seretan, Luka Nerima, and Lo-
renza Russo. 2009b. Collocations in a rule-based
MT system: A case study evaluation of their trans-
lation adequacy. In Proceedings of the 13th Annual
Meeting of the European Association for Machine
Translation, pages 128?135, Barcelona, Spain.
Wehrli, Eric. 2000. Parsing and collocations. In
Christodoulakis, D., editor, Natural Language Pro-
cessing, pages 272?282. Springer Verlag.
Wehrli, Eric. 2007. Fips, a ?deep? linguistic multilin-
gual parser. In ACL 2007 Workshop on Deep Lin-
guistic Processing, pages 120?127, Prague, Czech
Republic.
Zhang, Yi and Valia Kordoni. 2006. Automated deep
lexical acquisition for robust open texts processing.
In Proceedings of LREC-2006, pages 275?280, Ge-
noa, Italy.
36
Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 125?127,
Portland, Oregon, USA, 23 June 2011. c?2011 Association for Computational Linguistics
FipsCoView: On-line Visualisation of Collocations
Extracted from Multilingual Parallel Corpora
Violeta Seretan
School of Informatics
University of Edinburgh
violeta.seretan@gmail.com
Eric Wehrli
Language Technology Laboratory
University of Geneva
eric.wehrli@unige.ch
Abstract
We introduce FipsCoView, an on-line inter-
face for dictionary-like visualisation of collo-
cations detected from parallel corpora using a
syntactically-informed extraction method.
1 Introduction
Multilingual (parallel) corpora?e.g., Europarl
(Koehn, 2005)?represent a valuable resource
for tasks related to language production that is
exploitable in a wide variety of settings, such as
second language learning, lexicography, as well as
human or automatic translation. We focus on lexi-
cographic exploitation of such resources and present
a system, called FipsCoView,1 which is specifically
aimed at supporting the work of lexicographers who
compile multilingual collocation resources.
Collocation, a rather ill-defined linguistic con-
cept referring to a large and heterogeneous sub-class
of multi-word expressions, is understood here as a
combination of words that produces natural-soun-
ding speech and writing (Lea and Runcie, 2002)
and that has syntactic and semantic properties which
cannot be entirely predicted from those of its com-
ponents and therefore has to be listed in a lexicon
(Evert, 2004). Collocations are particularly interest-
ing from a translation point of view, and our system
can also be used to facilitate the task of translators
looking for the right translation of a word in context.
The usage scenario is the following. Given a
word, like money, our system provides a concise and
intuitive presentation of the list of collocations with
1Available at http://tinyurl.com/FipsCoView.
that word, which have previously been detected in
the source language version of the parallel corpus.
By selecting one of the items in this list, e.g., money
laundering, users will be able to see the contexts of
that item, represented by the sentences in which it
occurs. In addition, users can select a target lan-
guage from the list of other languages in which the
multilingual corpus is available2 and visualise the
target language version of the source sentences.
This presentation enables users to find potential
translation equivalents for collocations by inspecting
the target sentences. Thus, in the case of French, the
preferred equivalent found is blanchiment d?argent,
lit., ?money whitening?, rather than the literal trans-
lation from English, *lavage d?argent. In the case of
Italian, this is riciclaggio di denaro, lit., ?recycling
of money?, rather than the literal translation ?lavag-
gio di soldi, also possible but much less preferred.
Access to target sentences is important as it allows
users to see how the translation of a collocation vary
depending on the context. Besides, it provides use-
ful usage clues, indicating, inter alia, the allowed or
preferred morphosyntactic features of a collocation.
In this paper, we present the architecture of
FipsCoView and outline its main functionalities.
This system is an extension of FipsCo, a larger
fully-fledged off-line system, which, in turn, is in-
tegrated into a complex framework for process-
ing multi-word expressions (Seretan, 2009). While
the off-line system finds direct applicability in our
on-going projects of large-scale multilingual syntac-
2Europarl includes 11 languages: French, Italian, Spanish,
Portuguese, English, Dutch, German, Danish, Swedish, Greek,
Finnish. Note that our tool is not tailored to this specific corpus.
125
Figure 1: FipsCoView: System architecture.
tic parsing (Wehrli, 2007) and syntax-based machine
translation (Wehrli et al, 2009), the on-line version
is designed to offer access to the derived collocation
resources to a broader community.
2 Architecture and Main Functionalities
Figure 1 shows the architecture of FipsCoView. The
main system modules are the collocation extraction
module, the search & visualisation module, the con-
cordancing and the sentence alignment modules.
The processing flow is pipelined. The key mod-
ule of the system, collocation extraction, relies on
a syntax-based methodology that combines lexi-
cal statistics with syntactic information provided by
Fips, a deep symbolic parser (Wehrli, 2007). This
methodology is fully described and evaluated in
Seretan (2011). In principle, the extraction takes
place only once, but new corpora can be processed
later and results are cumulated. The sentence align-
ment (Nerima et al, 2003) is performed partially,
i.e., only for the sentences actually displayed by the
concordancing module. It is done on the fly, thus
eliminating the need of pre-aligning the corpora.
The role of the concordancing module is to
present the sentence contexts for a selected colloca-
tion (cf. scenario described in ?1). The words in this
collocation are highlighted for readability. The list
of sentences is displayed in the order given by the
syntactic variation of collocations, that is, the collo-
cation instances for which the distance between the
components is larger are displayed first. This func-
tionality is designed to support the work of users in-
specting the syntactic properties of collocations.
The search & visualisation module takes as input
the word entered by the user in the system interface,
performs a search in the database that stores the col-
location extraction results, and provides a one-page
presentation of the collocational information related
to the sought word. Users can set visualisation pa-
rameters such as the minimal frequency and associa-
tion score, which limit the displayed results accord-
ing to the number of occurrences in the corpus and
the ?association strength? between the component
words, as given by the lexical association measure
used to extract collocations. The measure we typi-
cally use is log-likelihood ratio (Dunning, 1993); see
Pecina (2008) for an inventory of measures.
Depending on these parameters, the automatically
created collocation entry is more or less exhaustive
(the output adapts to the specific user?s purpose). A
different sub-entry is created for each part of speech
of the sought word (for instance, report can either
be a noun or a verb). Under each sub-entry, colloca-
tions are organised by syntactic type, e.g., adjective-
noun (comprehensive report), noun-noun (initiative
report), subject-verb (report highlights), verb-object
(produce a report). To avoid redundancy, only the
collocating words are shown. The sought word is
understood and is replaced by a tilde character, in
a paper dictionary style. Unlike in paper dictionary
presentations, the online presentation benefits from
the HTML environment by using colours, adapt-
ing the font size so that it reflects the association
strength (the most important combinations are more
visually salient), displaying additional information
such as score and frequency, and using hyper-links
for navigating from one word to another.
With respect to similar systems (Barlow, 2002;
Scott, 2004; Kilgarriff et al, 2004; Charest et al,
2007; Rayson, 2009; Fletcher, 2011), our system
uniquely combines parallel concordancing with col-
location detection based on deep syntactic process-
ing. It is available for English, French, Spanish and
Italian and it is being extended to other languages.
Acknowledgement
This work is partly supported by the Swiss National
Science Foundation (grant no. PA00P1 131512).
126
References
Michael Barlow. 2002. Paraconc: Concordance software
for multilingual parallel corpora. In Proceedings of
the Third International Conference on Language Re-
sources and Evaluation. Workshop on Language Re-
sources in Translation Work and Research, pages 20?
24, Las Palmas, Spain.
Simon Charest, E?ric Brunelle, Jean Fontaine, and
Bertrand Pelletier. 2007. E?laboration automatique
d?un dictionnaire de cooccurrences grand public. In
Actes de la 14e confe?rence sur le Traitement Au-
tomatique des Langues Naturelles (TALN 2007), pages
283?292, Toulouse, France, June.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics, 19(1):61?74.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
University of Stuttgart.
William H. Fletcher. 2011. Phrases in english: Online
database for the study of English words and phrases.
http://phrasesinenglish.org. Accessed
March, 2011.
Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and David
Tugwell. 2004. The Sketch Engine. In Proceedings of
the Eleventh EURALEX International Congress, pages
105?116, Lorient, France.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of The
Tenth Machine Translation Summit (MT Summit X),
pages 79?86, Phuket, Thailand, September.
Diana Lea and Moira Runcie, editors. 2002. Oxford Col-
locations Dictionary for Students of English. Oxford
University Press, Oxford.
Luka Nerima, Violeta Seretan, and Eric Wehrli. 2003.
Creating a multilingual collocation dictionary from
large text corpora. In Companion Volume to the
Proceedings of the 10th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL?03), pages 131?134, Budapest, Hungary.
Pavel Pecina. 2008. Lexical Association Measures: Col-
location Extraction. Ph.D. thesis, Charles University
in Prague.
Paul Rayson. 2009. Wmatrix: a web-based corpus
processing environment. http://ucrel.lancs.
ac.uk/wmatrix. Accessed March, 2011.
Mike Scott. 2004. WordSmith Tools version 4. Oxford
University Press, Oxford.
Violeta Seretan. 2009. An integrated environment for
extracting and translating collocations. In Michaela
Mahlberg, Victorina Gonza?lez-D??az, and Catherine
Smith, editors, Proceedings of the Corpus Linguistics
Conference CL2009, Liverpool, UK.
Violeta Seretan. 2011. Syntax-Based Collocation Ex-
traction. Text, Speech and Language Technology.
Springer, Dordrecht.
Eric Wehrli, Luka Nerima, and Yves Scherrer. 2009.
Deep linguistic multilingual translation and bilingual
dictionaries. In Proceedings of the Fourth Work-
shop on Statistical Machine Translation, pages 90?94,
Athens, Greece. Association for Computational Lin-
guistics.
Eric Wehrli. 2007. Fips, a ?deep? linguistic multilingual
parser. In ACL 2007 Workshop on Deep Linguistic
Processing, pages 120?127, Prague, Czech Republic.
127
Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 26?32,
Gothenburg, Sweden, 26-27 April 2014.
c?2014 Association for Computational Linguistics
The Relevance of Collocations for Parsing
Eric Wehrli
LATL-CUI
University of Geneva
Eric.Wehrli@unige.ch
Abstract
Although multiword expressions
(MWEs) have received an increasing
amount of attention in the NLP com-
munity over the last two decades, few
papers have been dedicated to the spe-
cific problem of the interaction between
MWEs and parsing. In this paper, we will
discuss how the collocation identification
task has been integrated in our rule-
based parser and show how collocation
knowledge has a positive impact on the
parsing process. A manual evaluation
has been conducted over a corpus of
4000 sentences, comparing outputs of
the parser used with and without the
collocation component. Results of the
evaluation clearly support our claim.
1 Introduction
Collocations and more generally multiword ex-
pressions (MWEs) have received a large and in-
creasing amount of attention in the NLP com-
munity over the last two decades, as attested
by the number of workshops, special interest
groups, and ?of course? publications. The im-
portance of this phenomenon is now clearly rec-
ognized within the NLP community.
It is fair to say that collocation extraction has
been the main focus of attention, and a great
deal of research has been devoted to developing
techniques for collocation extraction from cor-
pora (Church & Hanks, 1990; Smadja, 1993;
Evert, 2004; Seretan & Wehrli, 2009, among
many others). Much less attention has been paid
to the interaction between collocations and the
parsing process
1
. In this paper, we will argue (i)
that collocation detection should be considered
as a component of the parsing process, and (ii)
that contrary to a common view, collocations
(and more generally MWEs) do not constitute
a problem or a hurdle for NLP (cf. Green et al.,
2011; Sag et al., 2002), but rather have a posi-
tive impact on parsing results.
Section 2 shows how collocation identifica-
tion has been integrated into the parsing pro-
cess. An evaluation which compares the re-
sults of the parse of a corpus with and without
the collocation identification component will be
discussed in section 3.
2 Parsing collocations
That syntactic information is useful ? indeed
necessary ? for a proper identification of collo-
cations is widely acknowledged by now. More
controversial, however, is the dual point, that is
1
Preprocessing, that is, the detection of MWEs during
tokenisation (ie. before parsing) is used in several sys-
tems ? for instance, ParGram (Butt et al., 1999), or more
recently, Talismane (Urieli, 2013). However, this tech-
nique can only be successfully applied to MWEs whose
components are adjacent (or near-adjacent), leaving aside
most of the cases that will be discussed below.
26
that collocation identification is useful for pars-
ing.
Several researchers (cf. Seretan et al., 2009;
Seretan, 2011, and references given there) have
convincingly argued that collocation identifica-
tion crucially depends on precise and detailed
syntactic information. One main argument sup-
porting that view is the fact that in some col-
locations, the two constituents can be far away
from each other, or in reverse order, depend-
ing on grammatical processes such as extraposi-
tion, relativization, passive, etc. Based on such
considerations, we developed a collocation ex-
traction system based on our Fips multilingual
rule-based parser(cf. Wehrli, 2007; Wehrli et
al., 2010). Although quite satisfactory in terms
of extraction precision, we noticed some short-
comings in terms of recall, due to the fact that
the parser would not always return the most ap-
propriate structure. A closer examination of
some of the cases where the parser failed to
return the structure containing a collocation ?
and therefore failed to identify it ? showed that
heuristics had (wrongly) favoured an alternative
structure. Had the parser known that there was
a collocation, the correct structure could have
received a higher score.
These observations led us to revise our po-
sition and consider that parsing and the identi-
fication of collocations are in fact interrelated
tasks. Not only does collocation identifica-
tion rely on syntactic dependencies, and thus on
parsed data, but the parser can fruitfully use col-
locational knowledge to favour some analyses
over competing ones. A new version of the Fips
parser has since been developed, in which col-
locations are identified as soon as the relevant
structure is computed, that is as soon as the sec-
ond term of the collocation is attached to the
structure.
The collocation identification process is trig-
gered by the (left or right) attachment of a
lexical element marked [+partOfCollocation]
2
.
Governing nodes are iteratively considered,
halting at the first node of major category (noun,
verb, adjective, adverb). If that second node
is itself marked [+partOfCollocation], then we
check whether the two terms correspond to a
known collocation.
Consider first some simple cases, as illus-
trated in (1).
(1)a. He had no loose change.
b. Paul took up a new challenge.
The collocation loose change in sentence (1a)
is identified when the adjective loose is (left-)
attached to the noun change. Both elements are
lexically marked [+partOfCollocation], the pro-
cedure looked up the collocation database for
a [
NP
[
AP
loose ] change ] collocation. In
the second example (1b), the procedure is trig-
gered by the attachment of the noun challenge
to the determiner phrase (DP) a, which is al-
ready attached as direct object subconstituent
of the verb took (up). As pointed out above,
the procedure checks the governing nodes un-
til finding a node of major category ? in this
case the verb. Both the verb and the noun are
marked [+partOfCollocation], so that the pro-
cedure looks up the database for a collocation
of type verb-direct object.
Let us now turn to somewhat more complex
cases, such as the ones illustrated (2):
(2)a. Which record did Paul break?
b. The record Paul has just broken was very
old.
c. This record seems difficult to break.
d. This record, Paul will break at the next
Olympic Games.
2
The collocation identification process only concerns
lexicalized collocations, that is collocations that we have
entered into the parser?s lexical database.
27
e. Which record did Paul consider difficult to
break?
f. The record will be broken.
g. The record is likely to be broken.
h. Ce d
?
efi, Jean le consid`ere comme difficile
`a relever.
?This challenge, Jean considers [it] as dif-
ficult to take up?
Sentence (2a) is a wh-interrogative clause,
in which the direct object constituent occurs
at the beginning of the sentence. Assuming
a generative grammar analysis, we consider
that such preposed constituents are connected
to so-called canonical positions. In this case,
the fronted element being a direct object, the
canonical position is the typical direct object
position in an English declarative sentence, that
is a postverbal DP position immediately dom-
inated by the VP node. The parser establishes
such a link and returns the structure below,
where [
DP
e]
i
stands for the empty category
(the ?trace?) of the preposed constituent which
record.
(3) [
CP
[
DP
which record]
i
] did [
TP
[
DP
Paul
] break [
DP
e]
i
]
In such cases, the collocation identification
process is triggered by the insertion of the
empty constituent in the direct object position
of the verb. Since the empty constituent is con-
nected to the preposed constituent, such exam-
ples can be easily treated as a minor variant of
case (1b).
All so-called wh-constructions
3
are treated in
a similar fashion, that is relative clause (2b) and
topicalization (2c). Sentence (2d) concerns the
tough-movement construction, that is construc-
tions involving adjectives such as tough, easy,
3
See Chomsky (1977) for a general analysis of wh-
constructions.
difficult, etc. governing an infinitival clause. In
such constructions, the matrix subject is con-
strued as the direct object of the infinitival verb.
In dealing with such structures, the parser will
hypothesize an abstract wh-operator in the spec-
ifier position of the infinitival clause, which
is linked to the matrix subject. Like all wh-
constituents, the abstract operator will itself be
connected to an empty constituent later on in the
analysis, giving rise to a chain connecting the
subject of the main clause and the direct object
position of the infinitival clause. The structure
as computed by the parser is given in (4), with
the chain marked by the index i.
(4) [
TP
[
DP
this record]
i
seems [
AP
difficult
[
CP
[
DP
e]
i
[
TP
to [
VP
break [
DP
e]
i
] ] ]
] ]
Finally, examples (2f,g) concern the passive
construction, in which we assume that the direct
object is promoted to the subject position. In
the tradition of generative grammar, we could
say that the ?surface? subject is interpreted as
the ?deep? direct object of the verb. Given such
an analysis of passive, the parser will connect
the subject constituent of a passive verb with an
empty constituent in direct object position, as
illustrated in (5).
(5) [
TP
[
DP
the record]
i
will [
VP
be [
VP
broken
[
DP
e]
i
] ] ]
The detection of a verb-object collocation in
a passive sentence is thus triggered by the inser-
tion of the empty constituent in direct object po-
sition. The collocation identification procedure
checks whether the antecedent of the (empty)
direct object and the verb constitute a (verb-
object) collocation.
2.1 Why collocations help
The parser can benefit from collocation knowl-
edge in two ways. The improvement comes ei-
ther from a better choice of lexical element (in
28
case of ambiguous words), or from a more fe-
licitous phrase attachment. Both cases are illus-
trated below, by means of examples taken from
our evaluation corpus. Consider first colloca-
tions of the noun-noun type containing syntac-
tically ambiguous words (in the sense that they
can be assigned more than one lexical category)
as in (6):
(6)a. balancing act
eating habits
nursing care
living standards
working conditions
b. austerity measures
opinion polls
tax cuts
protest marches
As illustrated by Chomsky?s famous example
Flying planes can be dangerous, -ing forms of
English transitive verbs are quite systematically
ambiguous, between a verbal reading (gerund)
and an adjectival reading (participle use). The
examples given in (6a) are all cases of colloca-
tions involving a present participle modifying a
noun. All those examples were wrongly inter-
preted as gerunds by the parser running without
the collocation identification procedure. The
noun-noun collocations in (6b) all have a noun
head which is ambiguous between a nominal
and a verbal reading. Such examples were
also wrongly interpreted with the verbal read-
ing when parsed without the identification pro-
cedure.
The second way in which collocational
knowledge can help the parser has to do with
structural ambiguities. This concerns particu-
larly collocations which include a prepositional
phrase, such as the noun-preposition-noun col-
locations, as in (7):
(7) bone of contention
state of emergency
struggle for life
flag of convenience
The attachment of prepositional phrases is
known to be a very difficult task for parsers (cf.
Church & Patil, 1982). So, knowing that a par-
ticular prepositional phrase is part of a colloca-
tion (and giving priority to such analyses con-
taining collocations over other possible analy-
ses) is an effective way to solve many cases of
PP attachments.
3 Evaluation
To evaluate the effect of collocational knowl-
edge on parsing, we compared the results pro-
duced by the parser with and without the col-
location identification procedure. The corpus
used for this evaluation consists of 56 arti-
cles taken from the magazine The Economist,
corresponding to almost 4000 sentences. We
first compared the number of complete analy-
ses achieved by both runs, with the results in
Figure 1
4
:
with collocations without collocations
70.3% 69.2%
Figure 1: Percentage of complete analyses
Although the number of complete parses
(sentences for which the parser can assign a
complete structure) varies very slightly (a little
more than a percent point better for the version
with collocation identification, at 70.3%), the
content of the analyses may differ in significant
ways, as the next evaluation will show.
A manual evaluation of the results was con-
ducted over the corpus, using a specific user in-
terface. To simplify the evaluation, we selected
the POS-tagging mode of the parser, and further
4
By complete analysis, we mean a single constituent
covering the whole sentence. When the Fips parser fails
to achieve a complete analysis, it returns a sequence of
chunks (usually 2 or 3) covering the whole sentence.
29
diff. diff N vs V with coll. without coll.
416 148 116 32
Figure 3: Differences with and without collocation
restricted the output to the triple (word, pos-tag,
position)
5
. For the POS tagset, we opted for the
universal tagset (cf. Petrov et al., 2012). Both
output files could then easily be manually com-
pared using a specific user interface as illus-
trated in figure 2 below, where differences are
displayed in red.
Notice that in order to facilitate the manual
evaluation, we only took into account differ-
ences involving the NOUN and VERB tags. In
the screenshot the two result files are displayed,
on the left the results obtained by the parser
with (W) the collocation identification compo-
nent, on the right the results obtained with the
parser without (WO) the collocation identifica-
tion component. For each file, one line contains
the input lexical item (simple word or com-
pound), its tag, and its position with respect to
the beginning of file (article). Differences (re-
stricted here to NOUN vs VERB tags) between
the two files are indicated in red. For each dif-
ference, the user selects the best choice, using
the Better left or Better right button or the
Skip button if the difference is irrelevant (or if
neither tag is correct). After each choice, the
next difference is immediately displayed.
The results are given in figure 3. Column 1
gives the total number of differences, column
2 the number of differences for the NOUN vs
VERB tags, columns 3 and 4 show how many
times the result (NOUN / VERB) is better with
the collocation component (column 3) or with-
out it (column 4).
This manual evaluation clearly shows that
5
Using Fips in POS-tagging mode only means that the
output will restricted to word and POS-tags. The analysis
itself is identical whether we use Fips in parsing mode or
in Pos-tagging mode.
the quality of the parses improves significantly
when the parser ?knows? about collocations,
that is when collocation detection takes place
during the parse. The comparison of the results
obtained with and without collocation knowl-
edge shows a total 416 differences of POS-tags,
of which 148 concern the difference between
Noun vs Verb tags. In 116 cases (nearly 80%)
the choice was better when the parser had collo-
cational knowledge, while in 32 cases (approx.
21%) the choice was better without the colloca-
tional knowledge.
The fact that in a little over 20% of the cases
the parser makes a better choice without col-
locational knowledge may seem a bit odd or
counter-intuitive. Going through several such
cases revealed that in all of them, the parser
could not achieve a full parse and returned a se-
quence of chunks. It turns out that in its current
state, the Fips parser does not use collocational
knowledge to rank chunks. Nor can it iden-
tify collocations that spread over two chunks.
Clearly something to be updated.
4 Concluding remarks and future
work
In this paper, we have argued that collocation
identification and parsing should be viewed as
interrelated tasks. One the one hand, colloca-
tion identification relies on precise and detailed
syntactic information, while on the other hand
the parser can fruitfully use collocation knowl-
edge in order to rank competing analyses and,
more interestingly, to disambiguate some other-
wise difficult cases.
This preliminary study focused primarily on
the NOUN vs VERB ambiguity, an ambiguity
which is very common in English and which
may have a devastating effect when the wrong
reading is chosen. For instance, in a translation
task, such mistakes are very likely to lead to in-
comprehensible results.
30
Figure 2: Manual evaluation user interface
31
In future work, we intend (i) to perform a
evaluation over a much larger corpus, (ii) to take
into account all types of collocations, and (iii) to
consider other languages, such as French, Ger-
man or Italian.
5 References
Butt, M., T.H. King, M.-E. Ni?no & F. Segond,
1999. A Grammar Writer?s Cookbook,
Stanford, CSLI Publications.
Church, K. & P. Hanks, 1990. ?Word as-
sociation norms, mutual information, and
lexicography?, Computational Linguistics
16(1), 22-29.
Church, K. & R. Patil, 1982. ?Coping with Syn-
tactic Ambiguity or How to Put the Block
in the Box on the Table?, American Journal
of Computational Linguistics, vol. 8, num-
ber 3-4, 139-150.
Chomsky, N. 1977. ?On Wh-Movement?,
in Peter Culicover, Thomas Wasow, and
Adrian Akmajian, eds., Formal Syntax,
New York: Academic Press, 71-132.
Evert, S., 2004. The Statistics of Word
Cooccurrences: Word Pairs and Colloca-
tions, PhD dissertation, IMS, University of
Stuttgart.
Green S., M.-C. de Marneffe, J. Bauer &
Ch.D. Manning, 2011. ?Multiword Ex-
pression Identification with Tree Substitu-
tion Grammars: A Parsing tour de force
with French?, Proceedings of the 2011
Conference on Empirical Methods in Nat-
ural Language Processing, 725-735.
Petrov, S., D. Das & R. McDonald, 2012.
?A Universal Part-of-Speech Tagset?, Pro-
ceedings of LREC-2011.
Sag, I., T. Baldwin, F. Bond, A. Copestake &
D. Flickinger (2002), ?Multiword Expres-
sions: A Pain in the Neck for NLP?, Pro-
ceedings of Cicling 2002, Springer-Verlag.
Seretan, V., 2011. Syntax-Based Collocation
Extraction, Springer Verlag.
Seretan, V. & E. Wehrli, 2009. ?Multilin-
gual Collocation Extraction with a Syntac-
tic Parser?, Language Resources and Eval-
uation 43:1, 71-85.
Smadja, F., 1993. ?Retrieving collocations from
text: Xtract?, Computational Linguistics
19(1), 143-177.
Urieli, A., 2013. Robust French Syntax
Analysis: reconciling statistical meth-
ods and linguistic knowledge in the Tal-
ismane toolkit, PhD dissertation, Uni-
versity of Toulouse. [http://redac.univ-
tlse2.fr/applications/talismane/biblio/
URIELI-thesis-2013.pdf]
Wehrli, E., 2007. ?Fips, a deep linguistic multi-
lingual parser? in Proceedings of the ACL
2007 Workshop on Deep Linguistic Pro-
cessing, Prague, Czech Republic, 120-127.
Wehrli, E., V. Seretan & L. Nerima, 2010. ?Sen-
tence Analysis and Collocation Identifi-
cation? in Proceedings of the Workshop
on Multiword Expressions: from The-
ory to Applications (MWE 2010), Beijing,
China, 27-35.
32
