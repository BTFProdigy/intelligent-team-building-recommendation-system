Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 827?836, Dublin, Ireland, August 23-29 2014.
Identifying Emotional and Informational Support in Online Health
Communities
Prakhar Biyani
1
Cornelia Caragea
2
Prasenjit Mitra
1
John Yen
1
(1) College of Information Sciences and Technology, The Pennsylvania State University, USA
(2) Department of Computer Science and Engineering, University of North Texas, USA
pxb5080@ist.psu.edu, ccaragea@unt.edu, {pmitra,jyen}@ist.psu.edu
Abstract
A large number of online health communities exist today, helping millions of people with social
support during difficult phases of their lives when they suffer from serious diseases. Interactions
between members in these communities contain discussions on practical problems faced by peo-
ple during their illness such as depression, side-effects of medications, etc and answers to those
problems provided by other members. Analyzing these interactions can be helpful in getting
crucial information about the community such as dominant health issues, identifying sentimental
effects of interactions on individual members and identifying influential members. In this paper,
we analyze user messages of an online cancer support community, Cancer Survivors Network
(CSN), to identity the two types of social support present in them: emotional support and infor-
mational support. We model the task as a binary classification problem. We use several generic
and novel domain-specific features. Experimental results show that we achieve high classifica-
tion performance. We, then, use the classifier to predict the type of support in CSN messages
and analyze the posting behaviors of regular members and influential members in CSN in terms
of the type of support they provide in their messages. We find that influential members generally
provide more emotional support as compared to regular members in CSN.
1 Introduction
Increasingly more people turn to online health communities (OHCs) to seek social support during their
illnesses (LaCoursiere, 2001; Beaudoin and Tao, 2007). When people suffering from a serious disease
such as cancer or AIDS interact with other people who have experienced similar medical conditions,
they feel emotionally supported. In addition, through these interactions, people can obtain important
information about the disease, e.g., about various medications, symptoms, and side-effects. Although
authoritative health-related web sites contain the information they search for, obtaining this information
directly from people in OHCs adds substantial value to it. Previous studies showed that obtaining social
support in OHCs can help people feel better (Dunkel-Schetter, 1984; Maloney-Krichmar and Preece,
2005; Beaudoin and Tao, 2007; Vilhauer, 2009; Qiu et al., 2011).
As a result of online interactions in OHCs, a huge volume of user-generated content exists today
on various issues/problems related to specific diseases. This content comprises of important information
such as people?s experiences with diseases, recommendations and feedbacks about certain medications or
medical procedures, and emotional support in the form of encouragement, sympathy, and success stories.
Mining this content can prove to be very useful in obtaining crucial insights into community dynamics
such as identifying dominant health issues or the effects of social support on community members,
identifying influential members, as well as designing smart information retrieval systems for users.
In this study, we focus on an online cancer support community, the Cancer Survivors Network
1
(CSN)
of the American Cancer Society. We analyze user messages of CSN to identify the two most important
types of social support present in them: informational and emotional support (Davison et al., 2000).
Emotional support comprises of seeking or providing caring/concern, understanding, empathy, sympathy,
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
http://www.csn.cancer.org
827
encouragement, affirmation and validation. In contrast, informational support comprises of seeking or
providing knowledge such as advice, referrals, and suggestions (Bambina, 2007). We further explore the
relation between the type of support present in messages and users? influence in the community.
Identifying the type of support in user messages in an OHC can potentially be used in many important
applications including the following:
1. Identify influential members in OHCs: Every community has a set of members who influence
(a much larger set of) other members in the community. These members are called leaders or
influential members. The attributes of a leader in a community depends upon the community?s
nature (QA, Twitter, OHC, forum, blogsite, etc.). For example, high activity may not be an indicator
of high influence in the blogosphere (Agarwal et al., 2008) and high popularity does not necessarily
imply influence in Twitter (Romero et al., 2011). In OHCs, bringing positivity in the community and
answering members? concerns effectively by posting messages that contain certain type of support
(informational or emotional) may be an indicator of influence.
2. Improve information search in OHCs: Interactions in OHCs contain valuable information in the
form of people?s experiences, advice, referrals, pertaining to diseases, medications, side-effects,
etc. Users embed this information often in messages containing other types of support, of which
emotional support constitutes a major part. To efficiently search OHCs for this information, it must
be separated from emotional support. Hence, identifying the type of support in user messages can
help improve search and retrieval in OHCs.
3. Understand social relationships in OHCs: Emotional support is one of the dimensions of social
tie strength between members in a social network (Gilbert and Karahalios, 2009). Previous stud-
ies have shown that members receiving emotional support in OHCs are more likely to remain in
the community for a longer period of time as compared to members receiving informational sup-
port (Wang et al., 2012). Identifying emotional and informational support can help understand the
social dynamics of an OHC. For example, it would be interesting to see if there is a correlation
between the social tie strength of members and the type of support present in their interactions.
Hi X, I had a bilateral with radical on the right and prophylactic on the left. I think all you can do is
gentle exercises to strengthen your back (yoga). There are also herbal painkillers that work well too.
I just tolerate the pain and consider it a signal of my new limit and go down to rest. You want to talk,
anytime! We are all there with you.
Table 1: A user message. Sentences in grey and black fonts are informational and emotional, respectively.
We model the task of identifying the two types of supports as a binary classification problem. Specifi-
cally, we classify each sentence in a user message as containing either emotional or informational sup-
port
2
. Table 1 shows a user message containing emotional and informational supports. We use several
features computed from sentences of messages such as unigrams, part-of-speech tags, lexicon-based fea-
tures and word patterns for the classification. After building the classification model, we predict the
amounts of the two supports in all CSN messages and explore the following research question:
RQ: Do influential members of CSN post one of the two types of supports significantly more
compared to regular members?
We analyze messages posted by regular members and messages posted by certain members, identified
as influential by the CSN community managers and two staff members who monitor the contents of the
CSN on a full time basis, for the type of support (informational and emotional) present in them. Using
the classification model, we calculate the amounts of the two supports posted by influential members and
regular members and compare them across the two populations (For details, see Section 3.1).
Previous works on analyzing social support in OHCs have mainly been in the field of social sci-
ence (Eriksson and Lauri, 2000; Rodgers and Chen, 2005; H?ybye et al., 2005; Pfeil and Zaphiris, 2007;
Beaudoin and Tao, 2007; Buis, 2008; Han et al., 2011). These works used manual techniques for iden-
tifying the type of support in user messages and hence, are limited to a small number of messages as
2
Although a sentence may belong to both the classes, we did not find such cases in our data.
828
compared to the real world data. In contrast, the current work builds machine learning classifiers that
can automatically predict the type of support in messages. Also, to the best of our knowledge, there have
been no reported works on analyzing the relationship between users? influence and the type of support
present in their messages in OHCs. Next, we review related works.
2 Related Work
Many studies in social science have focused on analyzing social support in user messages of OHCs (Cour-
saris and Liu, 2009; Han et al., 2011; Pfeil and Zaphiris, 2007), finding impacts of social support on
users (Eriksson and Lauri, 2000; Rodgers and Chen, 2005; Buis, 2008; H?ybye et al., 2005), identifying
information needs of users in OHCs (Rozmovits and Ziebland, 2004), etc. Among various types of social
supports, emotional support and informational support have received major attention. In this section, we
first review social science works on analyzing online social support, discuss works on identifying the
type of social support, and, finally, compare the current problem with subjectivity analysis.
LaCoursiere (2001) presented an integrated theory conceptualizing online social support. She defined
three channels through which online social support occurs: 1) perceptual: individual feeling the need of
social support arising due to emotional states such as stress, etc, 2) cognitive: individual seeking infor-
mation about certain medical entities such as procedures, medication, etc, 3) transactional: individual
evaluating the received social support. In our case, these channels correspond to emotional support and
informational support. H?ybye et al. (2005) conducted a qualitative study to analyze the effects of online
social support by interviewing women with breast cancer who used an online support group and found
that the women were empowered by the exchanges of knowledge and experience within the online sup-
port group. Rodgers et al. (2005) conducted a longitudinal content analysis of messages of participants
in a breast cancer discussion board to analyze changes in affect/sentiment of the participants towards
breast cancer and found that a positive shift in sentiment occurred over the period of time. Pfeil and
Zaphiris (2007) analyzed messages of SeniorNet forum to extract language patterns used to provide em-
pathic support. Budak and Agrawal (2013) interviewed participants of group chats in Twitter and found
that informational support is more important than emotional support in educational Twitter chats.
All the above works used manual methods of data preparation such as interviews with users of sup-
port groups, manual coding of messages to identify emotional and informational support and performed
further qualitative and/or quantitative analyses based on that data. Since, manual methods have seri-
ous limitations in terms of scalability, the number of messages used for analysis in these studies is too
small compared to the real world data which contains millions of messages. To address these limitations,
we develop automatic methods for identifying the type of support in user messages in an online cancer
support group using machine learning. We develop a classifier that learns on a smaller set of manually
labeled messages and makes predictions on a much larger set of messages with a very high accuracy.
A recent work by Wang et al. (2012) is close to our work. They used a linear regression model to
predict the amount of informational and emotional supports present in messages of a cancer forum. For
a test message, the trained model predicts the amount of the two supports on a scale of 1 ? 7. Since a
message may contain both types of support, it is generally difficult for human annotators to assess the
amount of each support in an entire message on a particular scale for model training. In contrast, we label
each sentence as belonging to either informational or emotional support class and identify the two types
of support at sentence level in messages (using binary classification). Note that it is much easier and less
ambiguous for a human annotator to identify the type of support present in a sentence (of a message)
compared to giving a score to an entire message based on the amount of the two supports present in it.
Relationship with Subjectivity Analysis: Subjectivity analysis is an active area of research in com-
putational linguistics. It essentially deals with separating subjective parts (e.g., expressing opinion, emo-
tion, speculation and other private states of mind) from objective parts (presenting facts, verifiable infor-
mation) of a text (Wiebe et al., 1999; Biyani et al., 2012a). It has been widely used in applications like
opinion mining from product reviews (Liu, 2010), community question-answering (Li et al., 2008a; Stoy-
anov et al., 2005a; Somasundaran et al., 2007), summarization (Carenini et al., 2006; Seki et al., 2005),
and finding opinionative threads in online forums (Biyani et al., 2014; Biyani et al., 2012b; Biyani et al.,
2013a). Though the current work has some relation with subjectivity analysis in the sense that both are
829
text classification, there are important differences between the two problems. The two classes in sub-
jectivity analysis (subjective and objective) are different from the two types of support that we identify.
While emotional support is subjective in nature, informational support is not necessarily objective as it
also contains opinions of users. Also, social support in OHCs encompasses several types of supports
such as understanding, caring, concern, sympathy, empathy, knowledge about medications, etc. which
are generally not provided by users in other sites such as product reviews, question-answering sites, etc.
These differences make the two problems different in both the nature and the approaches that can be used
to address them. For example, we use certain word patterns to identify sympathy and affirmation and use
the presence of terms related to cancer medications, procedures and side-effects for computing features
for classification. These features have not been used in subjectivity classification.
3 Problem Formulation
Online health communities provide social support to its members of which emotional and informational
supports constitute a major part and have received major attention as compared to other supports such
as companionship, community building, network support, etc. (Bambina, 2007; Meier et al., 2007;
Himle et al., 1991; Wang et al., 2012; Pfeil and Zaphiris, 2007). We focus on the two supports and
follow their definitions as given by Bambina (2007) in their study of social supports expressed in a can-
cer support group. They define emotional messages as the messages that have the following supports:
caring/concern, understanding, empathy, sympathy, encouragement, affirmation and validation. Infor-
mational support is defined as providing advice, knowledge and referrals. Since a user message often
contains a mixture of these supports, we identify the two supports at sentence level. Table 1 contains a
user message with sentences marked with the type of support in them. Specifically, given a sentence s,
in a user message, we want to classify it into one of the two classes: emotional support or informational
support. We use machine learning methods for classification. After training the classifier, we use it to
predict the type of support in the sentences of user messages in CSN and address our research question
outlined in Section 1. We present the details of the features used for classification in Section 3.2.
3.1 Research Question
To address the research question (RQ), we need to compute the amounts of the two supports in the
messages of regular and influential members and then compare the two amounts. Let u denote a user and
M be the set of messages posted by her such that M = {m
1
,m
2
, ....m
p
} where p is the total number
of messages in the set M . For a message m
k
? M , we compute its emotional index, e
uk
= n
ek
/(n
k
)
where n
ek
and n
k
are the number of sentences containing emotional support and the total number of
sentences in m
k
. Since a sentence can belong to either emotional support or informational support class,
informational index of m
k
, i
uk
= 1 ? e
uk
. The overall emotional index of u (e
u
) is the average of the
emotional indices of her messages: e
u
=
1
p
?
p
k=1
e
uk
. The informational index of u, i
u
= 1 ? e
u
.
Since, the informational index can be derived from emotional index, we compute only emotional indices
for all regular and influential members and compare them between the two user populations (regular
and influential). We compute the emotional indices of regular members, E
R
, and emotional indices of
influential members, E
I
. We compare the means of the two populations of emotional indices (?
Re
and
?
Ie
) and test the null hypothesis (H
0
) and the alternate hypothesis (H
1
) as follows:
H
0
: The two populations have equal means, i.e., ?
Re
? ?
Ie
= 0.
H
1
: The two populations have significantly different means , i.e., ?
Re
? ?
Ie
6= 0.
For one of the population indices to be significantly more than the other, we should have the null
hypothesis rejected. We use one-sided t-test to conduct hypothesis testing and report the results in Sec-
tion 4.5. Next, we discuss the features used in the classification.
3.2 Features for Classification
3.2.1 Words and POS tags
Words and their part-of-speech tags capture basic lexical properties of text and have been extensively
used in text classification problems such as subjectivity classification and sentiment classification (Li et
al., 2008b; Yu and Hatzivassiloglou, 2003; Biyani et al., 2013b). We use frequency of words and their
POS tags in a sentence as features in our classification model.
830
3.2.2 Lexicon-based Features
Emotional support expresses caring, concern, sympathy, and other kinds of sentimental support whereas
informational support provides knowledge about cancer medications, cancer reports, referrals, and other
kinds of information (Bambina, 2007). Due to this difference in the nature of these supports, a sentence
expressing emotional support is likely to contain emotional words which are subjective in nature and a
sentence containing informational support is likely to have cancer-related keywords such as drug names,
names of cancer procedures, etc. To capture this difference, we use frequencies of subjective words and
cancer-related keywords as features. Specifically, we design five features to code frequencies of weak
subjective words (numWeak), strong subjective words (numStrong), cancer drugs (numDrug), side-
effects of cancer medications (numSide), and cancer procedures (numProc) respectively in a sentence.
We use the subjectivity lexicon compiled from the MPQA corpus (Stoyanov et al., 2005b) to get weak
and strong subjective words. We compile lexicon of cancer drugs
3
, and CSN staff members helped get
a list of side-effects and cancer procedures. Some of the side-effects of cancer medications are hair loss,
neuropathy, fatigue, fibrosis, etc.
3.2.3 Linguistic Features
We analyzed user messages to find patterns that are expressive of emotional and informational support.
We found that members, generally, use certain word patterns to express similar feelings. For example,
to provide affirmation and sympathy, people use positive verbs such as know, feel, understand, sense,
support, etc. in patterns <I $posVerb> and <I $aux $posVerb>, where $posVerb is a positive verb and
$aux is an auxiliary verb from the set {can, could, do, would, will, may}. Some people use ?We? instead
of ?I? in their messages to provide support such as ?we understand what you are going through?.
To take into account such cases, we use the same patterns by replacing ?I ? with ?We?. Hence, we
get four patterns for emotional support. For providing informational support, people often use patterns
such as <You $advice>, <I $opinion>, <I $aux $opinion> to provide advice and opinions. $advice
is an auxilliary verb from the set {should, must, need, might}, $opinion is an opinion verb from the
set {recommend, advise, suggest, advocate, request}, and $aux is an auxilliary verb. People also give
information about their experiences using patterns such as <I too>, <I also> and <I $pastVerb> to
tell their own experiences related to similar problems as that of the support seeker where $pastVerb is a
past tense verb such as underwent, undergone, experienced, had, found, etc. So, we get six patterns for
informational support. We design two features (IsEmPattern and IsInPattern) to encode presence (1)
or absence (0) of the two types of patterns.
For a sentence, we also use its number of words (numWords) and its type, question sentence (IsQues)
and/or exclamatory sentence (isExclaim), as features. To identify question sentences, we see if a sen-
tence starts with any of the 5W1H words (what, why, who, when, where, how) or words in the set {do,
does, did} or ends with a question mark.
4 Experiments
We now describe our data and the experimental setting, and present our results.
4.1 Data Preparation
We use data from a popular online cancer support community, the Cancer Survivors? Network (CSN),
developed and maintained by the American Cancer Society. CSN is an online community for cancer
patients, cancer survivors, their families and friends. Its features are similar to many online forums
with dynamic interactive medium such as chat rooms, discussion boards, etc. Members of CSN post
in discussion boards for seeking and sharing information about cancer related issues and for seeking
and providing emotional support. To conduct our experiments, we used user messages in the discussion
threads of the Breast Cancer sub forum of CSN that were posted between June 2000 to June 2012. Breast
cancer is the largest among all the sub-forums of CSN. A dataset of 250, 868 messages posted by 5516
users in 22, 297 discussion threads is used in this study.
To prepare the evaluation dataset for classification experiments, we randomly sampled 240 messages
from 27 discussion threads. Since, our focus is on the messages that provide support, we do not consider
3
http://www.cancer.gov/cancertopics/druginfo/alphalist
831
messages posted by thread starters in discussion threads as they seek support. We took help of three
human annotators to tag all the sentences of all the messages in one of the two support classes. First,
two annotators tagged all the sentences. The percentage agreement between them was 89%. For the
remaining 11% sentences, majority vote was taken with the help of the third annotator. Following this
tagging scheme, we obtained a total of 1066 sentences with 390 sentences in the informational support
class and 676 sentences in the emotional support class. In many cases, members only write a few words,
e.g., see you, bye, or their names at the end of a message. To deal with these situations, we filter out
sentences that have less than four words.
4.2 Experimental Protocol
We experimented with various machine learning algorithms (Naive Bayes, Support Vector Machines,
Logistic Regression, Bagging, Boosting, etc.) to conduct our classification experiments. Naive Bayes
Multinomial gave the best performance with words & POS tags features, logistic regression with lexicon-
based features and AdaBoost (with Decision Stump as the weak learner) with linguistic features. For
combining the models built on the three types of features, we used the following three methods:
1. Feature combination: Classification model built on the feature set generated by combining the
three types of features. It is denoted by All. We use Multinomial Naive Bayes for this model.
2. Average confidence: Ensemble of the three classifiers built on the three types of features respec-
tively. The final confidence of the ensemble is calculated by taking average of the confidences
outputted by the three classifiers. It is denoted by AllAvgConf.
3. Highest confidence: Similar to the AllAvgConf model but the final prediction of the ensemble is
taken as the prediction of the most confident classifier of the three classifiers. More precisely, the
prediction for an instance is given by the classifier that returns the maximum prediction confidence
for one class or the other. It is denoted by AllMostConf.
Model Precision Recall F-1
Emotional support class
Words & POS tags 0.855 0.858 0.857
Lexicon-based features 0.722 0.836 0.775
Linguistic features 0.698 0.837 0.761
All 0.862 0.861 0.862
AllAvgConf 0.848 0.893 0.87
AllMostConf 0.851 0.911 0.88
Informational support class
Words & POS tags 0.753 0.749 0.751
Lexicon-based features 0.608 0.441 0.511
Linguistic features 0.569 0.372 0.45
All 0.76 0.762 0.761
AllAvgConf 0.797 0.723 0.758
AllMostConf 0.825 0.723 0.77
Overall
Words & POS tags 0.818 0.818 0.818
Lexicon-based features 0.68 0.691 0.678
Linguistic features 0.651 0.667 0.647
All 0.825 0.825 0.825
AllAvgConf 0.829 0.830 0.83
AllMostConf 0.841 0.842 0.84
Table 2: Classification results.
We used Weka data mining toolkit (Hall et al.,
2009) to conduct classification experiments. To
evaluate the performance of our classifiers, we
used macro-averaged precision, recall and F-1
score. We use F-1 score to compare perfor-
mances of two classifiers and used 10-fold cross
validation. A naive baseline that classifies all
the instances in the majority class will have a
macro-averaged precision, recall and F-1 score
of 0.402, 0.634 and 0.492, respectively.
4.3 Classification Results
Table 2 presents the results of the support clas-
sification experiments. The table reports preci-
sion, recall and F-1 score of different classifi-
cation models for the individual classes and the
overall result. Words & POS tags are the best
performing features followed by lexicon-based
features and linguistic features. Further, com-
bining all the features (model denoted as ?All?)
improves the performance over individual fea-
ture types for both classes. We see that All-
MostConf model is the best performing of all
the models, particularly outperforming All and
AllAvgConf models. This observation suggests that the three classifiers built on the three features types
have different knowledge. For some instances, a particular classifier is more confident than the rest while
for other instances, other classifiers are more confident. Hence, we see that taking prediction of the most
832
confident classifier gives the best performance. It is interesting to note that combining the three classi-
fiers? knowledge in this fashion is more effective than simply combining all the three types of features
and train a single classifier on the combined feature set. We also note that all the models have better
performance for the emotional support class than for the informational support class. This can be caused
by the fact that there are significantly more number of instances in the former class and, hence, more
patterns to learn for the class.
4.4 Informative Features
Next, we study the importance of individual features by measuring their chi-squared statistic with respect
to the class variable. We, first, study the word features and then present rankings of the other types of
features. Figure 1 shows a cloud of top 26 most informative words. The size of a word is proportional to
its chi-squared statistic, i.e., bigger a word, more informative it is. We see that cancer specific keywords
such as herceptin, tamoxifen, chemo, dose, stage, etc and words conveying emotions such as good, hope,
glad, pain, hugs, etc are highly informative for the support classification. Since, chi-square method
gives feature ranking for the class variable and not for individual classes, we compute word rankings for
individual classes using tf ? idf scores of words. Specifically, for a term t and a class c, we compute
the term frequency of t by counting its number of occurrences in the instances (sentences) belonging
to c and multiply the term frequency with the inverse document frequency of t (calculated from the
entire corpus) to get the tf ? idf score of t for c. Using this method, we calculated tf ? idf scores
for all the words and ranked them according to their scores for the two classes. Figure 2 shows top ten
tf? idf ranked keywords for the two classes. We see that cancer-related keywords and words expressing
emotions are among the top ten most informative words for the informational and the emotional support
classes respectively. We also note that most of the top ten words for the two classes in Figure 2 are in
the word cloud of the top 26 words computed using chi-squared method except ?keep? for the emotional
support class and ?after?, ?first?, ?because? and ?cancer? for the informational class. These words have
semantic relationships with the classes. For example, ?keep? is often used by support providers in phrases
such as ?keep you in prayers?, ?may god keep you in good health?, etc to provide emotional support and
?after? and ?first? are used in the context of providing one?s own experience related to cancer procedures,
medications, etc such as ?After my first chemo, I did not feel light?.
Figure 1: Top 26 words ranked by Chi-squared
test.
Emotional support Informational support
good chemo
know after
glad radiation
news first
hope herceptin
keep treatment
prayers tamoxifen
luck cancer
hugs because
better pain
Figure 2: Top ten words for the two classes
ranked using tf-idf scheme.
We, now, discuss the ranking of non-word features: POS tags, lexicon-based and linguistic features.
The chi-squared ranking for the lexicon-based and linguistic features is as follows: numStrong > num-
Words > isExclaim > numDrug > numSide > numProc > isInPattern > isEmPattern > numWeak >
isQues. The features on the right side of > have higher rank than those on the left side. We see that the
number of strong subjective words in a sentence is the most informative feature followed by number of
words in a sentence. Among cancer-related terms, drug names are more informative than side-effects
and cancer procedures. Also, informational support word patterns are more informative than word pat-
terns capturing emotional support. It is interesting to note that isQues is the least informative feature,
maybe due to the fact that, while providing support, people generally do not ask questions. The top 5
833
most informative POS tags are: cardinal number (CD) followed by singular noun (NN), participle verb
(VBN), past tense verb (VBD) and preposition (IN).
4.5 Influence versus Support type
Figure 3: Plot showing the change in mean emo-
tional indices of influential members (pink) and reg-
ular members (blue) with the threshold on the num-
ber of messages posted by them.
CSN managers provided a list of 62 influential
members (IMs) for the breast cancer forum. IMs
posted a total of 340, 147 sentences in 85, 244
messages and regular members posted 825, 651
sentences in 165, 624 messages in the breast
cancer forum. As described in Section 3, we
conduct statistical hypothesis testing on the two
populations of emotional indices (regular mem-
bers and IMs) to understand if there is a sig-
nificant difference in their posting behaviors in
terms of providing one of the two supports more
often than the other. To test our hypothesis, we
conducted one sided t-test on the two popula-
tions. We found that the mean of emotional in-
dices of IMs (0.713) is significantly larger than
that of the regular members (0.542). We also
note that the posting behavior of regular mem-
bers in CSN follows a power law distribution with most of the members posting very few messages
(mode = 1, median = 2, mean = 30) and only a few members posting very many messages. To verify
that this behavior does not have impacts on our hypothesis testing, we conducted three more t-tests be-
tween the two populations using a threshold on the number of messages that a member has posted. We
used three threshold values on the number of messages: 1, 2, and 30 (as mode, median and mean values).
For all the three t-tests, the null hypothesis was rejected at p-value< 0.001, suggesting that IMs posted
significantly more emotional support than regular members. The values of Mean Emotional Indices cor-
responding to the three thresholds are 0.715, 0.719 and 0.746 for influential members and 0.564, 0.581
and 0.646 for regular members respectively.
In our analysis, we observed an interesting behavior. As we increased the threshold, the mean of
emotional indices also increased. To further investigate this finding, we plotted the means of emotional
indices of regular members and IMs as the function of the threshold on the number of messages posted
by them. We increased the threshold from 10 to 1000 in steps of 10. Figure 3 reports the finding. We see
that the mean of emotional indices of regular members increase with the threshold suggesting that more
active members post more emotional support as compared to the less active members. We also see that
the mean of emotional indices of IMs is higher than that of regular members for all the thresholds. These
interesting observations can be helpful in analyzing behavior of influential members in OHCs.
5 Acknowledgments
We would like to thank Iulia Bivolaru for her help with data preparation. This material is based upon
work supported by the National Science Foundation under Grant No. 0845487.
6 Conclusion and Future Work
We identified two types of social support, emotional and informational, provided in user messages of an
online cancer support community using machine learning classification models. We used three types of
features and got the best results by using ensemble of the three classifiers built on the three individual
feature types. Our models achieved strong results with over 80% F-1 score. We also found that influ-
ential members provide significantly more emotional support to the community as compared to regular
members. The finding can be helpful in identifying properties of influential members in online health
communities. In future, we plan to analyze effects of the two types of supports on OHCs? dynamics and
use it to improve information search in OHCs.
834
References
Nitin Agarwal, Huan Liu, Lei Tang, and Philip S Yu. 2008. Identifying the influential bloggers in a community.
In Proceedings of the 2008 international conference on web search and data mining, pages 207?218. ACM.
Antonina Bambina. 2007. Online social support: The interplay of social networks and computer-mediated com-
munication. Cambria press.
Christopher E Beaudoin and Chen-Chao Tao. 2007. Benefiting from social capital in online support groups: An
empirical study of cancer patients. CyberPsychology & Behavior, 10(4):587?590.
Prakhar Biyani, Sumit Bhatia, Cornelia Caragea, and Prasenjit Mitra. 2012a. Thread specific features are help-
ful for identifying subjectivity orientation of online forum threads. In Proceedings of the 24th International
Conference on Computational Linguistics, pages 295?310.
Prakhar Biyani, Cornelia Caragea, Amit Singh, and Prasenjit Mitra. 2012b. I want what i need!: analyzing
subjectivity of online forum threads. In Proceedings of the 21st ACM International Conference on Information
and Knowledge Management, pages 2495?2498.
Prakhar Biyani, Cornelia Caragea, and Prasenjit Mitra. 2013a. Predicting subjectivity orientation of online forum
threads. In Proceedings of the 14th International Conference on Intelligent Text Processing and Computational
Linguistics, pages 109?120.
Prakhar Biyani, Cornelia Caragea, Prasenjit Mitra, Chong Zhou, John Yen, Greta E Greer, and Kenneth Portier.
2013b. Co-training over domain-independent and domain-dependent features for sentiment analysis of an online
cancer support community. In ASONAM, pages 413?417. ACM.
Prakhar Biyani, Sumit Bhatia, Cornelia Caragea, and Prasenjit Mitra. 2014. Using non-lexical features for identi-
fying factual and opinionative threads in online forums. Knowledge-Based Systems.
Ceren Budak and Rakesh Agrawal. 2013. On participation in group chats on twitter. In Proceedings of the
22nd international conference on World Wide Web, pages 165?176. International World Wide Web Conferences
Steering Committee.
Lorraine R Buis. 2008. Emotional and informational support messages in an online hospice support community.
Computers Informatics Nursing, 26(6):358?367.
G. Carenini, R. Ng, and A. Pauls. 2006. Multi-document summarization of evaluative text. In EACL, pages
305?312.
Constantinos K Coursaris and Ming Liu. 2009. An analysis of social support exchanges in online hiv/aids self-help
groups. Computers in Human Behavior, 25(4):911?918.
Kathryn P Davison, James W Pennebaker, and Sally S Dickerson. 2000. Who talks? the social psychology of
illness support groups. American Psychologist, 55(2):205.
Christine Dunkel-Schetter. 1984. Social support and cancer: Findings based on patient interviews and their
implications. Journal of Social Issues, 40(4):77?98.
Elina Eriksson and Sirkka Lauri. 2000. Informational and emotional support for cancer patients relatives. Euro-
pean Journal of Cancer Care, 9(1):8?15.
Eric Gilbert and Karrie Karahalios. 2009. Predicting tie strength with social media. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, pages 211?220. ACM.
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I.H. Witten. 2009. The weka data mining
software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10?18.
Jeong Yeob Han, Dhavan V Shah, Eunkyung Kim, Kang Namkoong, Sun-Young Lee, Tae Joon Moon, Rich
Cleland, Q Lisa Bu, Fiona M McTavish, and David H Gustafson. 2011. Empathic exchanges in online cancer
support groups: distinguishing message expression and reception effects. Health communication, 26(2):185?
197.
David P Himle, Srinika Jayaratne, and Paul Thyness. 1991. Buffering effects of four social support types on
burnout among social workers. In Social Work Research and Abstracts, volume 27, pages 22?27. Oxford
University Press.
835
Mette Terp H?ybye, Christoffer Johansen, and Tine Tj?rnh?j-Thomsen. 2005. Online interaction. effects of
storytelling in an internet breast cancer support group. Psycho-Oncology, 14(3):211?220.
Sheryl Perreault LaCoursiere. 2001. A theory of online social support. Advances in Nursing Science, 24(1):60?77.
B. Li, Y. Liu, A. Ram, E.V. Garcia, and E. Agichtein. 2008a. Exploring question subjectivity prediction in
community qa. In SIGIR, pages 735?736. ACM.
Baoli Li, Yandong Liu, and Eugene Agichtein. 2008b. Cocqa: co-training over questions and answers with an
application to predicting question subjectivity orientation. In EMNLP ?08, pages 937?946.
B. Liu. 2010. Sentiment analysis and subjectivity. Handbook of Natural Language Processing,, pages 978?
1420085921.
Diane Maloney-Krichmar and Jenny Preece. 2005. A multilevel analysis of sociability, usability, and community
dynamics in an online health community. TOCHI, 12(2):201?232.
Andrea Meier, Elizabeth J Lyons, Gilles Frydman, Michael Forlenza, and Barbara K Rimer. 2007. How cancer
survivors provide support on cancer-related internet mailing lists. Journal of Medical Internet Research, 9(2).
Ulrike Pfeil and Panayiotis Zaphiris. 2007. Patterns of empathy in online communication. In Proceedings of the
SIGCHI conference on Human factors in computing systems, pages 919?928. ACM.
Baojun Qiu, Kang Zhao, P. Mitra, Dinghao Wu, C. Caragea, J. Yen, G.E. Greer, and K. Portier. 2011. Get online
support, feel better ? sentiment analysis and dynamics in an online cancer survivor community. In SocialComm?
11, pages 274?281.
Shelly Rodgers and Qimei Chen. 2005. Internet community group participation: Psychosocial benefits for women
with breast cancer. Journal of Computer-Mediated Communication, 10(4):00?00.
Daniel M Romero, Wojciech Galuba, Sitaram Asur, and Bernardo A Huberman. 2011. Influence and passivity in
social media. In Machine learning and knowledge discovery in databases, pages 18?33. Springer.
Linda Rozmovits and Sue Ziebland. 2004. What do patients with prostate or breast cancer want from an internet
site? a qualitative study of information needs. Patient education and counseling, 53(1):57?64.
Y. Seki, K. Eguchi, N. Kando, and M. Aono. 2005. Multi-document summarization with subjectivity analysis at
duc 2005. In DUC. Citeseer.
S. Somasundaran, T. Wilson, J. Wiebe, and V. Stoyanov. 2007. Qa with attitude: Exploiting opinion type analysis
for improving question answering in on-line discussions and the news. In ICWSM.
V. Stoyanov, C. Cardie, and J. Wiebe. 2005a. Multi-perspective question answering using the opqa corpus. In
EMNLP 2005, pages 923?930. ACL.
Veselin Stoyanov, Claire Cardie, and Janyce Wiebe. 2005b. Multi-perspective question answering using the opqa
corpus. In HLT-EMNLP ?05, HLT ?05, pages 923?930, Stroudsburg, PA, USA. ACL.
Ruvanee P Vilhauer. 2009. Perceived benefits of online support groups for women with metastatic breast cancer.
Women & health, 49(5):381?404.
Yi-Chia Wang, Robert Kraut, and John M Levine. 2012. To stay or leave?: the relationship of emotional and infor-
mational support to commitment in online health support groups. In Proceedings of the ACM 2012 conference
on Computer Supported Cooperative Work, pages 833?842. ACM.
J.M. Wiebe, R.F. Bruce, and T.P. O?Hara. 1999. Development and use of a gold-standard data set for subjectivity
classifications. In ACL, pages 246?253. ACL.
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from
opinions and identifying the polarity of opinion sentences. In Proceedings of the 2003 conference on Empirical
methods in natural language processing, pages 129?136. Association for Computational Linguistics.
836
Proceedings of the 2014 ACL Workshop on Cognitive Modeling and Computational Linguistics, pages 55?62,
Baltimore, Maryland USA, June 26 2014.
c?2014 Association for Computational Linguistics
Linguistic Adaptation in Conversation Threads:
Analyzing Alignment in Online Health Communities
Yafei Wang, David Reitter, and John Yen
Information Science and Technology
Penn State University
University Park, PA, 16801
yxw184@ist.psu.edu, reitter@psu.edu, jyen@ist.psu.edu
Abstract
Previous studies of alignment have
focused on two-party conversations. We
study multi-party conversation in online
health communities, which have shown
benefits for their members from forum
conversations. So far, our understanding
of the relationship between alignment in
such multi-party conversations and its
possible connection to member benefits
has been limited. This paper quantifies
linguistic alignment in the oldest and the
largest cancer online forum. Alignment
at lexical and syntactic levels, as well as
decay of alignment was observed in forum
threads, although the decay was slower
than commonly found in psycholinguistic
studies. The different pattern of adaptation
to the initial post on a thread suggests that
specific roles in the online forum (e.g.,
seeking support from the community) can
potentially be revealed through alignment
theory and its extensions.
1 Introduction
Linguistic alignment leads conversation partners
to adapt their language patterns to match their
conversation partners. Such patterns comprise of
word choice, sentence structure, and more. For
example, if one conversation partner uses passive
voice in the conversation, other conversation
participants tend to use passive voice at a later
point in time. The mechanism of adaptation are
better understood now (Bock and Griffin, 2000;
Pickering and Ferreira, 2008; Kaschak et al.,
2011a; Reitter et al., 2011). The Interactive
Alignment Model (IAM) (Pickering and Garrod,
2004) attributes dialogic function to the priming
effect; it suggests that adaptation helps people
reach mutual understanding. Some recent studies
(Reitter and Moore, 2007; Fusaroli et al., 2012)
lend empirical confirmation to this thesis.
Repetition effects are not purely mechanistic.
They are sometimes moderated in response to
situational requirements or framing. For example,
they can vary in strength when humans (believe
to) communicate with computers (Branigan et al.,
2010). Repetition intensifies when the purpose of
conversation is to collaborate on a common task
(Reitter et al., 2006). Of course, communication
between individuals is more than a linguistic
event; it is also social. For example, it can be
found as a cue to social relationships in film scripts
(Danescu-Niculescu-Mizil and Lee, 2011). A
more specific aspect of language-based interaction
is pragmatic convention in multi-party dialogue,
which determines turn-taking, shifts in topic, and
more.
One would expect alignment to also occur in
social situations involving multiple speakers. The
social moderators and functions of adaptation
effects, however, are largely unclear. The question
we ask in this paper is whether alignment is
moderated by the role of a speaker?s contribution
to the conversation. In this paper, we deal with
written interaction only; our data are internet
forum conversations.
The first question is whether linguistic
adaptation exists in online communities and
online groups. Dialogues in threads of online
communities are different from previous types of
dialogues. Unlike some spontaneous, free-form
dialogues, threaded conversations have specific
topic. In addition, thread conversations do not
have specific tasks. Therefore, we investigate
whether dialogues in the threads also exhibit
linguistic adaptation, be it as an artifact of
mechanistic language processing or because
adaptation acts as a social or conversational signal.
Adaptation tends to decay over time, although this
decay has not been studied in the context of such
55
slow, asychronuous communication. Therefore,
we will characterize the time-scale of dacay.
More generally, if alignment exists in forums, is it
correlated with the communicative role of a text
or the social role of its author?
The contributions of this paper are: (1)
an exploratory analysis of linguistic adaptation
based on 3,000 conversations threads and 23,045
posts in an online cancer survivor community
(http://csn.cancer.org). Specifically,
we find reliable linguistic adaptation effects in
this corpus. (2) We show that properties of
conversation threads that are different from regular
conversations.
In the following sections, we first survey related
work on linguistic adaptation. Then, we describe
our data and make preliminary definitions. We
then introduce measures of linguistic adaptation.
Last, we discuss a set of properties in online
thread conversations which are unlike other types
of dialogues.
2 Related Work
Linguistic alignment phenomenon in social
interaction has been well explored in previous
literature. It happens because of multiple reasons.
Firstly, it could be due to unconscious linguistic
adaptation. Pickering and Garrod (2004) suggests
that conversations have linguistic coordination
at lexical level. Branigan et al. (2000) and Gries
(2005) show that priming effects exist at the
syntactic level. However, linguistic alignment
could happen consciously by conversation
participants. Some literature suggest that people
flexibly adapt their linguistic patterns to each
other?s in order to improve collective performance
and social coordination (Healey and Mills, 2006;
Garrod and Pickering, 2009).
Linguistic alignment has been found in written
communication as well, which is close to our
work. Danescu-Niculescu-Mizil et al. (2011)
examines conversations in a Twitter corpus,
showing convergence of Linguistic Inquiry and
Word Count (LIWC) measures. This result
confirms that linguistic alignment exists in written
online social media. Furthermore, in Huffaker
et al. (2006); Scissors et al. (2008); Backstrom
et al. (2013) also show that people adjust their
linguistic style, such as linguistic features, in the
online written chatroom and online community.
Also, priming effects at syntactic level (Gries,
2005; Branigan et al., 2000) have been explored
in several written dataset settings (Pickering and
Ferreira, 2008).
In order to quantify the linguistic alignment
phenomenon, researchers have introduced several
quantitative measures. Several methods evaluate
repetition of linguistic events, such as the use of
words, syntactic rules or a small set of expressions
(Church, 2000; Reitter et al., 2006; Fusaroli et al.,
2012). These approaches typically test whether
linguistic alignment is due to linguistic adaptation
or intrinsic repetition. Moreover, linguistic
feature similarity (Stenchikova and Stent, 2007;
Danescu-Niculescu-Mizil et al., 2011) is also
widely used to measure linguistic adaptation
precisely.
3 Online Health Communities
Online health communities (OHC) typically
include features such as discussion boards where
cancer survivors and their caregivers can interact
with each other. Support and information
from people with similar cancers or problems
is very valuable because cancer experiences are
unique. Therefore, an online community for
cancer survivors and caregivers enables them to
share experiences related to cancer, seek solutions
to daily living issues, and in general support
one another (Bambina, 2007) in ways that is not
often possible with other close family, friends
or even health care providers. Benefits to
cancer survivors who have participated in an
OHC are reported in the literature. Studies
of cancer OHC have indicated that participation
increases social support (Dunkel-Schetter, 1984;
Rodgers and Chen, 2005), reduces levels of
stress, depression, and psychological trauma
(Beaudoin and Tao, 2008; Winzelberg et al.,
2003), and helps participants be more optimistic
about the course of their life with cancer (Rodgers
and Chen, 2005). The support received from
other OHC members help cancer patients better
cope with their disease and improve their lives
both physically and mentally (Dunkel-Schetter,
1984). Further understanding about these
benefits has been provided by computational text
analysis and machine learning methods, which
enable fine-grained analysis of the sentiments of
individual posts in the discussion forum of cancer
OHC Qiu et al. (2011). It has been shown that
those who started a thread in a cancer OHC often
56
show a more positive sentiment in their posts
later in the thread, after other OHC members
provided replies Qiu et al. (2011); Portier et al.
(2013). However, the potential relationship
between alignment theory and these benefits of
cancer OHC has not been explored. This motivates
us to study the alignment of posts on a thread to the
initial post that starts the thread.
4 Data Description and Preliminary
Definitions
The data used in this study stem from the
Cancer Survivor?s Network (CSN) (http://
csn.cancer.org). The CSN is the oldest and
the largest cancer online community for cancer
survivors, which includes cancer patients, and
their friends and families. CSN has more than
166,000 members (Portier et al., 2013). Members
in CSN present their concerns, ask questions,
share their personal experience and provide social
support to each other through discussion threads.
Similar to other online communities, CSN threads
consist of an initial post followed by a sequence
of reply posts ordered by time. A thread
could be represented as a sequence of post, <
P
1
, P
2
, ? ? ? , P
i
, ? ? ? , P
n
>. In order to better
explain the problem, we show some properties of
a post in the thread.
Absolute Position: Given a post P
i
in a thread, the
absolute position of post P
i
is i
Relative Position: Given a post P
i
in a thread with
n posts, the relative position of P
i
is i/n
We construct the CSN corpus by randomly
sampling 3,000 threads from CSN between 2000
and 2010. Using Stanford?s CoreNLP tool (Klein
and Manning, 2003), we generate the syntactic
structure of the text in each post. In order
to calculate linguistic adaptation, we convert
every syntactic tree into structure rules in phrases
(Reitter et al., 2006). The data distribution of CSN
corpus is shown in Figure 1.
5 Measures of Linguistic Adaptation
Following previous work, we implement
Indiscriminate Local Linguistic Alignment
(Fusaroli et al., 2012) at the levels of syntax and
lexicon. In general, indiscriminate local linguistic
alignment measures the repetition of language use
in the target post repeating prime posts. LILA, as
defined, is a normalized measure of the number of
words that occur in both the prime and the target.
l l l l l l l llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll
l
l
1 2 5 10 20 50 100 200
1
10
100
100
0
100
00
 
Post Distance
# o
f Po
st P
airs
Figure 1: The distribution of posts based on post
distance.
The normalization factor is the product of the
length of the prime and the length of the target.
Alignment has been demonstrated for
syntax and lexicon, ranging from controlled
experimentation to broad-coverage naturalistic
text (e.g., Bock, 1986; Gries, 2005; Ferreira
and Bock, 2006; Reitter et al., 2006). In this
paper, we present primarily exploratory analyses
that emphasize minimal filtering and data
processing. While some priming effects discussed
in the literature indeed require careful post-hoc
control using many explanatory variables,
the phenomena we discuss are evident with
exploratory, early-stage methods.
5.1 Indiscriminate local linguistic alignment
at the lexical level
Lexical Indiscriminate Local Linguistic Alignment
(LILLA) measures word repetition between one
or more prime post and a target post. The
prime always precedes the target. LILLA, in our
implementation, can be seen as the probability
of a word occurring in a single location, given it
occurred in a prime period. Formally,
LILLA(target, prime) =
p(target|prime)
p(target)
(1)
=
?
word
i
target
?(word
i
)
length(prime) ? length(target)
(2)
57
?(word
i
) =
{
1 if word
i
 prime
0 otherwise
(3)
where length(X) is the number of words in post
X , and target post is any post following the
prime post. The distance between the two posts
is measured in posts. In different experiment
settings, we focus on certain prime posts, such as
the first post of a thread, or all posts written by a
certain author.
To sum up, LILLA is measured as word
repetition conditioned on the word having been
primed in a previous post. A high value of
LILLA indicates an increased level of linguistic
alignment. Alignment at the lexical level can
have a number of underlying causes, including
lexical priming, but also simply topicality of the
posts. Therefore, it is important to also inspect
indiscriminate local linguistic alignment at the
syntactic level.
5.2 Indiscriminate local linguistic alignment
at the syntactic level
Here, we consider a priming effect of syntactic
structure, which shows users? implicit linguistic
adaptation. Similar to Reitter et al. (2006), our
cancer survivor network corpus was annotated
with phrase structure trees; unlike in previous
work, we do so using a parser (from the Stanford
CoreNLP package (Klein and Manning, 2003)).
Each post is encoded as a series of syntactic rules.
Indiscriminate local linguistic alignment at the
syntactic level (SILLA) measures the repetition of
syntactic rules in the target post. Similar to our
experiments in lexical repetition, prime posts will
vary in different experimental settings.
5.3 Alignment and Adaptation
In this paper, we distinguish alignment and
adaptation. Alignment is the general adoption
of words, phrases, syntax, and any linguistic
representation that was heard, read, spoken or
written previously. Adaptation is a special case
of alignment: here, speakers permanently adjust
their linguistic preferences, or they learn from
their linguistic experiences. Alignment can be
due to a memory effect (e.g., priming), while
adaptation may alternatively be the result of
speakers discussing a topic. When they do, they
are more likely to use the same words. Both
alignment and adaptation may decay over time.
0.000 0.002 0.004 0.006 0.008
0
200
400
600
800
 
Lexical Indiscriminate Local Linguistic Alignment
Den
sity
NotOneThreadOneThread
Figure 2: Distribution of lexical indiscriminate
local linguistic alignment compared to a control
(NotOneThread).
6 Linguistic properties of conversation
threads
In this section, we will set up four experiments
to show the alignment properties of conversation
threads. For simplification, we will only consider
replies whose post distance is less than 100 (data
distribution shown in Figure 1).
6.1 Linguistic alignment
We assume that there is a constant level of random
indiscriminate local linguistic repetition in human
language, both lexically and syntactically.
We designed a post-hoc experiment to test
whether linguistic alignment effect is due to
linguistic adaptation or intrinsic repetition in
human language, following methodology to
measure long-term adaptation developed in Reitter
and Moore (2007). We split each of 3,000 threads
into two equal-size (by posts) halves. Out of the
resulting 6,000 thread halves, we produce pairs
combining any two sampled thread halves.
We define the binary OneThread variable,
indicating whether a pair consists of material from
the same thread, or if it consists of a first half
from one thread, but a second half from another
thread. This allows us to contrast repetition within
and between threads. If linguistic adaptation exist,
linguistic repetition at the lexical and syntactic
levels between the two halves of a pair will be
58
0.000 0.005 0.010 0.015 0.020
0
50
100
150
200
250
 
Syntactic Indiscriminate Local Linguistic Alignment
Den
sity
NotOneThreadOneThread
Figure 3: Distribution of syntactic indiscriminate
local linguistic alignment compared to a control
(NotOneThread).
more common if OneThread is true.
Figures 2 and 3 show that linguistic
repetition in the same thread is greater than
the control (repetition between different
threads) (Wilcoxon-test p
LILLA
< 0.001,
p
SILLA
< 0.001). However, despite the statistical
difference, it is obvious that there is a strong
lexical alignment effect, but much less syntactic
alignment. As a result, we conclude that at
least some linguistic repetition in the online
conversation is due to linguistic adaptation.
Again, at the lexical level, we would expect
some of this repetition to be due to the preferred
repetition of topical words; at the syntactic level,
this is unlikely to be the case.
6.2 Linguistic Adaptation Decays
Strong syntactic repetition has been shown
to diminish within seconds (Reitter et al.,
2006). Precisely, given an use of a syntactic
construction at one point in time, the probability
of this construction being used again is strongly
increased for the first seconds, but decays rapidly
towards its prior probability. In our experiment,
we replicate the decay of linguistic repetition
at the larger scale of forum threads. From a
psycholinguistic perspective, one would expect
only a relatively weak effect, given that syntactic
short-term priming is often short-lived (Branigan
et al., 1999). However, there is also weaker, slow,
long-term persistence (Bock and Griffin, 2000),
which can even be cumulative (Jaeger and Snider,
2007; Kaschak et al., 2011b). The messages in
such forums are written at a much larger timescale
than the priming models and short-term priming
lab experiments investigate.
In the experiment, we split a thread into a
sequence of posts. Given a target post P
j
, the
prime post is one post in the subsequence of posts
< P
1
, ? ? ? , P
i
, ? ? ? , P
j?1
>. We calculate LILLA
and SILLA of posts for prime-target distances
below 100. We will use the same method in this
and following experiments.
Figures 4 and 5 show that LILLA and SILLA
drop as the post-distance between a target post and
a prime post in the thread increases. Comparing
syntactic and lexical decay, we note that the
slope of LILLA?s decay is stronger than that of
SILLA?s decay. Both two measurements imply
that linguistic alignment decays over time, by
?utterance? (for some definition of utterance), or
by post. These results parallel standard results
from the priming literature. Surprisingly, for
forum threads we find this effect at a much larger
scale than in one-on-one spoken dialogue.
6.3 Linguistic adaptation to the initial post
So far, we have largely replicated a known
alignment effect for the case of written
communication in the online forum. There
are some properties of the forum communication
that allow us to investigate a number of open
questions pertaining to alignment in multi-party
dialogue. The main question concerns the
function of alignment. Is it more than an artifact
of low-level memory effects (priming)? Does
it, as Pickering and Garrod (2004) have argued,
contribute to mutual understanding? Or is it,
beyond that, a mechanism to express or establish
social relationships? If alignment is not just a
purely functional phenomenon, but also carries
pragmatic weight or social functions, we would
not expect it to be blind to the role of the author
of the source (prime) post.
In a self-help online discussion forum, the
role of the initial post differs from that of
other messages. The initial post raises an issue
generally, or it poses a concrete question. In
this experiment, we test whether initial posts in
the thread are more important than other replies
59
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
ll
l
l
l l
l
l0.002
0.003
0.004
0.005
0 25 50 75 100Post distance between prime and target post
LIL
LA(w
ord
 ?
 
targ
et | w
ord
 ?
 
prim
e po
st)
primeType
l
l
l
initial post
any post by initial author
any post
Figure 4: Lexical indiscriminate local linguistic
adaptation to any post, the initial post and the posts
from the initial author of the thread. The light
gray horizontal line shows the mean LILLA to any
post in the thread. Error bars: standard errors.
(The dashed horizontal line shows the prior, which
is large due to the large number of many short
threads.)
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
0.004
0.006
0.008
0.010
0.012
0 25 50 75 100Post distance between prime and target post
SIL
LA(r
ule 
?
 
targ
et | r
ule 
?
 
prim
e po
st)
primeType
l
l
l
initial post
any post by initial author
any post
Figure 5: Syntactic indiscriminate local linguistic
adaptation to any post, the initial post, and the
posts from the initial author in the thread. The
light gray horizontal line shows the mean SILLA
to any post in the thread.
in online conversations. That is, given an initial
post, does linguistic alignment still decline with
increasing post distance between the initial post
and the reply post in the online discussion thread?
Also, is linguistic alignment to the initial post
higher than that to any post?
Figure 4 plots lexical alignment (LILLA). We
can see that lexical alignment is present for the
initial post as well, but not more so than in general.
In fact, the absolute level as well as the decay of
LILLA to the initial post is weaker than that of
LILLA to any post in the thread.
To distinguish linguistic adaptation from more
general alignment effects, we also test syntactic
alignment, SILLA. Figure 5 plots this measure.
SILLA shows a different story compared to
LILLA. It shows that syntactic adaptation takes
place (and decays) for all posts, but that there
is less, if even initial anti-alignment with the
posts from the initial author. The results may be
supported by properties of conversation in internet
threads. In an online community, initial posts
generally raise questions. Different sentence types
(e.g., questions) may be used by someone seeking
help. So, alignment with the initial post may
seem to decay after post 25, but also shows more
variance (due to fewer data-points).
In sum, both measurements suggest that
linguistic alignment takes place with general
material presented before the target text, and
that repetition probability does decrease over
time or linguistic material (posts) as theoretically
predicted. We do not see evidence for a strong
social role of alignment.
6.4 Linguistic adaptation to the author of the
first post
As the previous experiment showed, lexical
alignment to the initial post decays over time.
There is no evidence that alignment with the initial
post is related to its informational role in the
thread. However, is alignment affected by the
social role taken on by the author that asks the
initial question? In other words, do writers align
more with posts from the initial author than with
others?
Figure 4 shows that LILLA drops gradually
when prime posts are restricted to the initial
author. Lexical alignment to the initial author
behaves similarly to alignment with the initial
post. At the lexical level, repetition of material
60
provided by the initial author or initial post
does not drop as rapidly as it does for general
material, and it starts at a lower level. Further
investigations will be needed to better understand
the alignment effects and the slow decay with
the thread-initiating post. For example, further
analysis is needed to investigate whether the
slow decay is related to the support function
the community provides to the thread initiators.
Syntactic alignment (SILLA, Figure 5) suggests
weaker alignment effects for the initial author
and the initial post. Further investigations will
also be needed to study the syntactic alignment
of replying posts to early reply posts. If such
alignment exists, it provides further insights about
the leadership role in the community (Zhao et al.,
2014).
This finding result may be supported by
properties of online support communities.
Specifically, the author of the initial post is the
person that would like to receive support from
other community members. People who reply
provide support to that initial author. Therefore,
replies in the thread are likely to have expressions
different from those used in the initial post and by
the initial author.
7 Conclusion
Motivated by analyzing linguistic adaptation
behavior in online communities, we provide
a descriptive analysis that qualifies linguistic
alignment at both the lexical and syntactic levels.
A novel observation is that we find reliable
linguistic adaptation in online communities. We
replicate the temporal, logarithmic decay, but we
found it at a much slower pace or larger scale than
psycholinguistic work has done in experiment or
corpus studies.
The distinction we make between syntactic and
lexical alignment has implications for the possible
mechanisms behind the adaptation effect. A
writer?s lexical choices are influenced by topic,
while syntactic composition happens implicitly,
i.e., without (conscious) attention. Topics do
not remain the same during a conversation: they
shift throughout the thread. This clustering of
topics can create alignment and decay but as far
as permanent adaptation is concerned there is
nothing but the illusion of it.
Our study provides some insight into properties
of linguistic alignment particularly in thread-based
discussions. Different from regular dialogues,
the initial post and the author of the initial
post may have a special role in such dialogues.
We see differences in lexical and syntactic
alignment. We assume that these are likely due
to conversational properties rather than underlying
cognitive processes.
This phenomenon provides an interesting
angle to study online communities as well as
linguistic alignment from the perspectives of
communication and psycholinguistics.
Following these exploratory studies, we plan
to measure discriminate alignment next. Here,
priming spans across semantic relationships rather
than only word identity (Swinney et al., 1979).
Also, a next step would be to build a model that
can quantify alignment (or even adaptation) and
relate it to the factors pertinent to the discussion
and the community, such as network measures and
an individual propensity to align.
8 Acknowledgements
This research was made possible by a
collaboration agreement between Penn State
and the American Cancer Society. The authors
would like to thank the society and collaborators
Kenneth Portier and Greta E. Greer for their work
in producing the CSN dataset, as well as Prasenjit
Mitra and Yang Xu.
References
Lars Backstrom, Jon Kleinberg, Lillian Lee, and Cristian
Danescu-Niculescu-Mizil. Characterizing and curating
conversation threads: expansion, focus, volume, re-entry.
In Proceedings of the sixth ACM international conference
onWeb search and data mining, pages 13?22. ACM, 2013.
Antonina Bambina. Online social support: the interplay of
social networks and computer-mediated communication.
Cambria press, 2007.
Christopher E Beaudoin and Chen-Chao Tao. Modeling the
impact of online cancer resources on supporters of cancer
patients. New Media & Society, 10(2):321?344, 2008.
J Kathryn Bock. Syntactic persistence in language
production. Cognitive psychology, 18(3):355?387, 1986.
Kathryn Bock and Zenzi M Griffin. The persistence
of structural priming: Transient activation or implicit
learning? Journal of Experimental Psychology: General,
129(2):177, 2000.
Holly P. Branigan, Martin J. Pickering, and Alexandra A.
Cleland. Syntactic priming in language production:
Evidence for rapid decay. Psychonomic Bulletin and
Review, 6(4):635?640, 1999.
Holly P Branigan, Martin J Pickering, and Alexandra A
Cleland. Syntactic co-ordination in dialogue. Cognition,
75(2):B13?B25, 2000.
61
Holly P Branigan, Martin J Pickering, Jamie Pearson, and
Janet F McLean. Linguistic alignment between people
and computers. Journal of Pragmatics, 42(9):2355?2368,
2010.
Kenneth W. Church. Empirial estimates of adaptation: The
chance of two Noriegas is closer to p/2 than p
2
. In
Proceedings of the 18th Conference on Computational
Linguistics (COLING), pages 180?186, Saarbr?ucken,
Germany, 2000.
Cristian Danescu-Niculescu-Mizil and Lillian Lee.
Chameleons in imagined conversations: A new approach
to understanding coordination of linguistic style in
dialogs. In Proceedings of the 2nd Workshop on Cognitive
Modeling and Computational Linguistics, pages 76?87.
Association for Computational Linguistics, 2011.
Cristian Danescu-Niculescu-Mizil, Michael Gamon, and
Susan Dumais. Mark my words!: linguistic style
accommodation in social media. In Proceedings of the
20th international conference on World Wide Web, pages
745?754. ACM, 2011.
Christine Dunkel-Schetter. Social support and cancer:
Findings based on patient interviews and their
implications. Journal of Social Issues, 40(4):77?98,
1984.
Victor Ferreira and Kathryn Bock. The functions of structural
priming. Language and Cognitive Processes, 21(7-8):
1011?1029, 2006.
Riccardo Fusaroli, Bahador Bahrami, Karsten Olsen,
Andreas Roepstorff, Geraint Rees, Chris Frith, and
Kristian Tyl?en. Coming to terms quantifying the benefits
of linguistic coordination. Psychological Science, 23(8):
931?939, 2012.
Simon Garrod and Martin J Pickering. Joint action,
interactive alignment, and dialog. Topics in Cognitive
Science, 1(2):292?304, 2009.
Stefan Th. Gries. Syntactic priming: A corpus-based
approach. Journal of Psycholinguistic Research, 34(4):
365?399, 2005.
Patrick GT Healey and Gregory Mills. Participation,
precedence and co-ordination in dialogue. In Proceedings
of the 28th Annual Conference of the Cognitive Science
Society, pages 1470?1475, 2006.
David Huffaker, Joseph Jorgensen, Francisco Iacobelli, Paul
Tepper, and Justine Cassell. Computational measures for
language similarity across time in online communities.
In Proceedings of the HLT-NAACL 2006 Workshop on
Analyzing Conversations in Text and Speech, pages 15?22.
Association for Computational Linguistics, 2006.
T. Florian Jaeger and Neal Snider. Implicit learning
and syntactic persistence: Surprisal and cumulativity.
University of Rochester Working Papers in the Language
Sciences, 3(1):26?44, 2007.
Michael P Kaschak, Timothy J Kutta, and John L Jones.
Structural priming as implicit learning: Cumulative
priming effects and individual differences. Psychonomic
Bulletin & Review, 18(6):1133?1139, 2011a.
Michael P Kaschak, Timothy J Kutta, and Christopher
Schatschneider. Long-term cumulative structural priming
persists for (at least) one week. Memory & Cognition, 39
(3):381?388, 2011b.
Dan Klein and Christopher D Manning. Fast exact inference
with a factored model for natural language parsing.
Advances in Neural Information Processing Systems,
pages 3?10, 2003.
Martin J Pickering and Victor S Ferreira. Structural priming:
a critical review. Psychological Bulletin, 134(3):427,
2008.
Martin J Pickering and Simon Garrod. The
interactive-alignment model: Developments and
refinements. Behavioral and Brain Sciences, 27
(02):212?225, 2004.
Kenneth Portier, Greta E Greer, Lior Rokach, Nir Ofek, Yafei
Wang, Prakhar Biyani, Mo Yu, Siddhartha Banerjee, Kang
Zhao, Prasenjit Mitra, et al. Understanding topics and
sentiment in an online cancer survivor community. JNCI
Monographs, 2013(47):195?198, 2013.
Baojun Qiu, Kang Zhao, Prasenjit Mitra, Dinghao Wu,
Cornelia Caragea, John Yen, Greta E Greer, and Kenneth
Portier. Get online support, feel better?sentiment analysis
and dynamics in an online cancer survivor community.
In Privacy, security, risk and trust (passat), 2011 ieee
third international conference on and 2011 ieee third
international conference on social computing (socialcom),
pages 274?281. IEEE, 2011.
David Reitter and Johanna D Moore. Predicting success
in dialogue. In Annual Meeting of the Association for
Computational Linguistics, volume 45, page 808, 2007.
David Reitter, Johanna D. Moore, and Frank Keller.
Priming of syntactic rules in task-oriented dialogue and
spontaneous conversation. In Proceedings of the 28th
Annual Conference of the Cognitive Science Society
(CogSci), pages 685?690, Vancouver, Canada, 2006.
David Reitter, Frank Keller, and Johanna D. Moore. A
computational cognitive model of syntactic priming.
Cognitive Science, 35(4):587?637, 2011.
Shelly Rodgers and Qimei Chen. Internet community
group participation: Psychosocial benefits for women
with breast cancer. Journal of Computer-Mediated
Communication, 10(4):00?00, 2005.
Lauren E Scissors, Alastair J Gill, and Darren Gergle.
Linguistic mimicry and trust in text-based cmc. In
Proceedings of the 2008 ACM Conference on Computer
Supported Cooperative Work, pages 277?280. ACM,
2008.
Svetlana Stenchikova and Amanda Stent. Measuring
adaptation between dialogs. In Proc. of the 8th SIGdial
Workshop on Discourse and Dialogue. Citeseer, 2007.
David Swinney, W. Onifer, P. Prather, and M. Hirshkowitz.
Semantic facilitation across modalities in the processing
of individual words and sentences. Memory and
Cognition, 7:159?165, 1979.
Andrew J Winzelberg, Catherine Classen, Georg W Alpers,
Heidi Roberts, Cheryl Koopman, Robert E Adams,
Heidemarie Ernst, Parvati Dev, and C Barr Taylor.
Evaluation of an internet support group for women with
primary breast cancer. Cancer, 97(5):1164?1173, 2003.
Kang Zhao, John Yen, Greta Greer, Baojun Qiu, Prasenjit
Mitra, and Kenneth Portier. Finding inuential users
of online health communities: a new metric based on
sentiment inuence. J Am Med Inform Assoc, 2014. doi:
10.1136/amiajnl-2013-002282.
62
