Towards User-Adaptive Annotation Guidelines
Stefanie Dipper, Michael Go?tze, Stavros Skopeteas
Dept. of Linguistics
D-14415 Potsdam, Germany
{dipper,goetze}@ling.uni-potsdam.de
skopetea@rz.uni-potsdam.de
Abstract
In this paper we address the issue of user-
adaptivity for annotation guidelines. We show
that different user groups have different needs
towards these documents, a fact neglected by
most of current annotation guidelines. We pro-
pose a formal specification of the structure of
annotation guidelines, thus suggesting a mini-
mum set of requirements that guidelines should
fulfill. Finally, we sketch the use of these speci-
fications by exemplary applications, resulting in
user-specific guideline representations.
1 Introduction
Linguistic research nowadays makes heavy use of
annotated corpora. The benefit that researchers may
gain from corpora depends to a large extent on doc-
umentation of the annotation. According to Leech?s
maxims, the guidelines that were applied in the an-
notation of the corpus should be accessible to the
user of the corpus (and thus serve as a kind of doc-
umentation), see Leech (1993).1
In this paper, we argue that annotation guidelines,
which are optimized for use by the annotators of the
corpus, often cannot serve as suitable documenta-
tion for users of the annotated corpus. We illustrate
this claim by different types of prototypical corpus
users, who have different needs with respect to doc-
umentation. Extending the proposal by MATE (Dy-
bkjaer et al, 1998), we sketch a preliminary specifi-
cation for annotation guidelines. We then show how
guidelines that are standardized in this way may be
adapted to different user needs and serve both as
guidelines, applied in the annotation process, and
documentation, used by different corpus users.
1
?The annotation scheme should be based on guide-
lines which are available to the end user. Most corpora
have a manual which contains full details of the annota-
tion scheme and guidelines issued to the annotators. This
enables the user to understand fully what each instance of
annotation represents without resorting to guesswork, and
to understand in cases of ambiguity why a particular an-
notation decision was made at that point.?, Leech (1993),
cited by http://www.ling.lancs.ac.uk/monkey/
ihe/linguistics/corpus2/2maxims.htm.
This paper grew out of our work in the Son-
derforschungsbereich (SFB, collaborative research
center) on information structure at the University of
Potsdam.2 In the context of this SFB, several indi-
vidual projects collect a large amount of data of di-
verse languages and annotate them on various anno-
tation levels: phonetics/phonology, morpho-syntax,
semantics, and information structure.
Within the SFB, guidelines for the different anno-
tation levels are being created. In order to maximize
the profit of these data, we are developing standard
recommendations on the format and content of the
SFB annotation guidelines. These guidelines ought
to serve the SFB annotators as well as the research
community.
The paper is organized as follows. We first
present different user profiles with different needs
towards annotation guidelines (sec. 2). We then ana-
lyze the form and content of selected existing guide-
lines to some detail (sec. 3) and show that these
guidelines fulfill the user needs only inadequately
(sec. 4). Finally, we sketch a formal specification of
the structure of annotation guidelines and indicate
how XML/XSLT technology can be used to support
user-adaptive annotation guidelines (sec. 5).
2 Guideline Users
Annotation guidelines are used by different types of
users with different requirements. These require-
ments depend on (i) the user?s objectives and (ii)
the user?s background.
2.1 User Objectives
People are interested in annotation guidelines for
different reasons. According to their respective ob-
jectives, we define five user profiles.3
The annotator Annotators assign linguistic fea-
tures to language data, according to criteria and
2http://www.ling.uni-potsdam.de/sfb/
3In a similar way, Carletta and Isard (1999) define three
user types: the coder, the coding consumer, and the coding de-
veloper. These classes, however, refer to users of annotation
workbenches rather than annotation guidelines.
instructions specified in the annotation guidelines.
Important annotation criteria are consistency and
speed.
The corpus explorer The group of corpus explor-
ers encompasses all those who aim at exploiting lin-
guistic data in order to find evidence for or against
linguistic hypotheses. These people need to know
(i) how to find instances of specific phenomena they
are interested in, and (ii) how to interpret the anno-
tations of the phenomena in question.
The language engineer Instead of inspecting the
data ?manually?, as the corpus explorer does, the
language engineer applies automatic methods to the
annotated data to process them further. This in-
cludes a variety of tasks, such as statistical evalu-
ations, training and testing of algorithms, and the
extraction of various types of linguistic information.
The guideline explorer The guidelines per se
(i.e., independently of a corpus) are of interest to,
e.g., theoretical linguists who want to know the
principles that underlie the annotation guidelines. In
addition, the guidelines may serve as an example for
authors of other annotation guidelines.
The guideline author The process of writing
guidelines is usually a time-consuming and step-
wise process. Hence, during the process of writ-
ing, the authors themselves make use of their own
guidelines to look up related or similar phenomena
that are already covered therein.
2.2 User Background
A further factor putting constraints on annotation
guidelines is the user?s background. First, (non-)
acquaintance with the language of the corpus is an
important factor: if corpora should be useful also
for people who do not or hardly know the language
of the corpus, annotation guidelines should provide
translations for example sentences and basic infor-
mation about linguistic properties of the object lan-
guage.
Second, (non-)acquaintance with theoretical
analyses of the phenomena has an impact on re-
quirements towards guidelines. People who are ac-
quainted with the linguistic theory that the guide-
lines are based on do not need theoretical introduc-
tions; an example is the Feldertheorie (field theory
of word order) in German, which serves as the basis
of the analyses in the German Verbmobil Treebank
(Stegmann et al, 2000). In addition, people who
know about alternative (competing) analyses of the
phenomena in question may want to know the rea-
sons of the chosen analysis.
3 Form and Content of Guidelines
We consider sample guidelines from different types
of annotation; all sample guidelines are available
via the internet. These guidelines have been cho-
sen to set out the diversity among different lev-
els of linguistic analysis?from morphology to
pragmatics?and among practices established in
different linguists? communities?from typologists
to language engineers.4
Interlinear morphemic transcription EU-
ROTYP (Ko?nig et al, 1993), Leipzig Glossing
Rules (Bickel et al, 2004). These guidelines deal
with the annotation of morpheme boundaries and
morpheme-by-morpheme translation (glossing);
these guidelines have been created by and for
typologists.5
Morphosyntactic annotation Penn Treebank
(POS-tagging guidelines, ?POS?) (Santorini,
1995), STTS (Schiller et al, 1999). These guide-
lines have been developed by language engineers
for (semi-)automatic annotation of morphosyntactic
information.6
Syntactic annotation Penn Treebank (bracketing
guidelines, ?BG?) (Bies et al, 1995), SPARKLE
(Carroll et al, 1997), VerbMobil, German Treebank
(Stegmann et al, 2000).7
Semantic/pragmatic annotation PropBank
(PropBank Project, 2002), Penn Discourse Tree-
bank (Mitsakaki et al, 2004), DAMSL (Dialog
Act Markup in Several Layers, Allen and Core
(1997)). PropBank and Penn Discourse Treebank
are extensions of the Penn Treebank.
We focus on three aspects of annotation guide-
lines: the components of guideline documents
4The sample guidelines also vary with regard to size (e.g.,
the Leipzig Glossing Rules comprise 9 pages, the Penn Tree-
bank Bracketing Guidelines 317 pages) and status (e.g., the
VerbMobil guidelines are completed, whereas guidelines such
as the Penn Discourse Treebank guidelines are still being de-
veloped).
5We consider only the rules for morphemic transcription
and not the glossing abbreviations in these documents.
6EAGLES provides recommendations for the design of
morphosyntactic tagsets (Leech and Wilson, 1996). Tagsets
represent only a component of annotation guidelines. The
STTS tagset can be viewed as an instantiation of the EAGLES
recommendations.
7A very detailed annotation scheme for syntactic, semantic
and speech annotation is available in book form for the SU-
SANNE corpus (Sampson, 1995). These guidelines are ad-
dressed primarily to the guideline explorer rather than the an-
notator. In this vein, the book provides a detailed discussion
of the annotation principles and theoretical background. We do
not include these guideline in our discussion, since they are not
available electronically.
A B C D E F G H I J K L M N O P
EUROTYP + + + + + +
Leipzig Glossing Rules + + + + + + + +
Penn Treebank (POS) + + + + + + + +
STTS + + + + + + +
Penn Treebank (BG) + + + + + + + + +
VerbMobil Treebank + + + + + + + + +
SPARKLE + + + + + + + +
PropBank + + + + + + + +
Penn Discourse Treebank + + + + + +
DAMSL + + + + + +
Document components:
A general principles
B underlying linguistic theory
C tagset declaration
D related annotation schemes
E tag index
F keyword index
Instruction components:
G keywords
H criteria
I examples
J related instructions
K alternative analyses
Instruction ordering:
L alphabetical tags
M alphabetical keywords
N content-based structure
O default?specific/exceptional
P simple?difficult
Figure 1: Features of the sample guidelines
(sec. 3.1), the components of an annotation instruc-
tion (sec. 3.2), and the ordering of instructions with
respect to each other (sec. 3.3).
3.1 Document Components
The document architecture varies to some extent in
the sample guidelines. In general, however, there is
(i) an introductory part, (ii) the main section, and
(iii) appendices. In the following, we sketch pro-
totypical components of these parts; to a large ex-
tent, these components overlap with the elements
proposed by Dybkjaer et al (1998). The table in
fig. 1 presents an overview of most of the guide-
line components considered here. The differences
between the guidelines can (partly) be attributed to
the fact that the guidelines address different types of
users.
Introductory part This part comprises basic in-
formation such as the name of the guidelines, the
annotation goal, the type of source data, the anno-
tation markup (e.g., syntactic annotation can be en-
coded by brackets vs. graphs, etc.). In addition, it
addresses general design principles, including gen-
eral annotation conventions (A8), and the underly-
ing linguistic theory and/or statements about theo-
retical problems (B). A general tagset declaration
in the form of an exhaustive list of all admissible
tags plus a short description is often included (C).
Some guidelines refer to related annotation schemes
or standard recommendations like EAGLES (Leech
and Wilson, 1996) (D). Finally, creation notes in-
form about the authors, creation date, status of the
guidelines, etc.
8The letters refer to the table in fig. 1.
Main section This section is always devoted to
the presentation of the actual annotation guidelines,
which we call ?(annotation) instructions?. These
will be discussed in detail in sec. 3.2 and 3.3.
Appendices Some guidelines provide tutorials in
the form of exercises for practicing the use of the an-
notation guidelines. Different types of indices (i.e.,
listings of items, e.g. tags, and numbers of all pages
that refer to these items) may be included: alpha-
betical index of the tags (E); thematic indices, e.g.
an index of keywords such as ?wh-clefts? (F). In ad-
dition, lists of specific problematic words or con-
structions may be given. Finally, some guidelines
include recommendations for annotation tools and
methods.
3.2 Instruction Components
The core component of annotation guidelines is rep-
resented by the annotation instructions. We first de-
scribe the form and content of an individual instruc-
tion before addressing the question of how the set
of instructions is ordered/structured (sec. 3.3). We
illustrate the description by two annotation instruc-
tions from the Penn Treebank (POS), displayed in
fig. 2.
An individual instruction always refers to one (or
more) tags that represent the information to be an-
notated, e.g., ?VB?. The instruction usually provides
some sort of keywords (G) for the phenomenon in
question, e.g., ?verb, base form? (e.g., headers may
provide such keywords). The guidelines in the sam-
ple include annotation criteria (H) in the form of
a descriptive text (?This tag subsumes . . . ?) and
some illustrative examples (I) (?Do/VB it.?). Some-
Verb, base form?VB
This tag subsumes imperatives, infinitives and subjunctives.
EXAMPLES: Imperative: Do/VB it.
Infinitive: You should do/VB it. [. . . ]
Subjunctive: We suggested that he do/VB it.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
VB or VBP
If you are unsure whether a form is subjunctive (VB) or a present tense verb (VBP), replace the subject by a
third person pronoun. If the verb takes an -s ending, then the original form is a present tense verb (VBP); if
not, it is a subjunctive (VB).
EXAMPLE: I recommended that you do/VB it.
(cf. I recommended that he do/*does it.)
Figure 2: Two instructions from the Penn Treebank POS-tagging guidelines (Santorini, 1995, pp. 5, 21)
times, the guidelines also specify how to segment
the source data.
Often, the instructions make reference to other,
closely related instructions (whose annotation crite-
ria are similar to the current criteria) and emphasize
the differences between them (?If you are unsure
whether . . . ?) (J). Finally, alternative (competing)
analyses may be given (K).9
3.3 Instruction Ordering
Guidelines present annotation instructions in a cer-
tain order. The ordering of instructions is a crucial
aspect of the instructions? presentation: different or-
dering principles implement different perspectives
to the guidelines and, consequently, serve require-
ments of different groups of users (cf. sec. 4).
The sample guidelines make use of the following
ordering principles:
Alphabetical order of the tags (L) In the sec-
tion on problematic cases, the Penn Treebank (POS)
present the tags and their instructions in an alpha-
betical order (from ?CC? to ?WDT?). (Other guide-
lines make use of this type of ordering in an addi-
tional tag index.)
Alphabetical order of keywords (M) Canonical
cases in the Penn Treebank (POS) are ordered al-
phabetically with respect to keywords (from ?Adjec-
tive? to ?Wh-adverb?).
Content-based structure (N) Instructions are of-
ten presented in thematic units, e.g. all tags encod-
ing nominal features are grouped together. More-
over, complex annotation guidelines are usually or-
ganized in an hierarchical structure, with chapters,
sections, etc., which mirror the complex structure of
9The guidelines considered here at most allude implicitely
to alternative analyses: by giving arguments in favour of the
chosen analaysis.
the described phenomena. For instance, the Verb-
Mobil guidelines contain a chapter about the anno-
tation of phrasal constituents, with sections address-
ing NPs, PPs, etc., and PP subsections addressing
prepositions and circum/postpositions. In DAMSL,
criteria in the form of decision trees guide the anno-
tator through the annotation.
From default to specific/exceptional cases (O)
This is an ordering principle that is usually used
in combination with other principles. For instance,
single sentences are presented before multiple sen-
tences in the guidelines of the Penn Discourse Tree-
bank.
Degree of difficulty (P) Similarly, in combina-
tion with other ordering principles, the guidelines
often proceed from easy to difficult cases. For in-
stance, the Leipzig Glossing Rules first introduce
morphemic transcription of prefixes and suffixes.
Only later are infixes and circumfixes addressed;
these represent a problematic case for interlinear
morphemic translations due to the lack of isomor-
phism between the layer of transcription and the
layer of translation.
Usually, guidelines make use of several ordering
principles, e.g., main instructions are structured ac-
cording to content, (embedded) subinstructions are
ordered from default to specific case, and indices are
ordered alphabetically according to keywords.
4 User Requirements
Current annotation projects usually do not provide
separate guideline documents for different types of
users. Usually, annotation documentation emerges
from the annotating practice, supporting the an-
notator in the annotation task. At the publish-
ing stage, this documentation is often transferred
into a more general document, by adding informa-
tion about annotation conventions, format, methods,
etc.?however, the basic structure of the annotations
instructions remains unaltered. The obvious conse-
quence of this practice is that existing guidelines of-
ten ignore the requirements of certain types of users.
We illustrate different user requirements by some
typical examples. These requirements concern (i)
document components, (ii) instruction components,
and (iii) instruction ordering:
Annotator Typical users are annotators who are
confronted with the guidelines for the first time.
(i) Annotators primarily need a tutorial introduction
and maybe information about the annotation goals.
(ii) They have to learn specific instructions, sup-
ported by didactic examples.
(iii) The appropriate order is from default to excep-
tional or from easy to difficult. Orderings in the
form of decision trees may facilitate the acquisition.
Corpus explorer A further sample user is a re-
searcher who looks for a specific phenomenon in
the corpus:
(i) Corpus explorers need an index of phenomena
(keywords) to look up the tags that encode the phe-
nomenon they are interested in. Moreover, when
inspecting the encoding of this phenomenon, they
might come across other tags they are not yet famil-
iar with. Hence, they also need an index of tags (or
a tagset declaration) to look up the meaning of these
tags.
(ii) They need detailed information about the anno-
tation criteria. Take, for instance, a corpus that is
annotated with respect to information-structural cat-
egories and imagine a corpus explorer who is inter-
ested in topic and focus. Before looking for data,
s/he has to know the exact definitions (criteria) of
topic and focus that have been applied in the anno-
tation.
(iii) The easiest way for the corpus explorer to find
annotation criteria of phenomena and tags is by
means of an alphabetic ordering.
Language engineer Finally, language engineers
may undertake a statistical evaluation of the corpus
data:
(i) They primarily need a tagset declaration, with-
out being interested in any details. In addition, the
circumstances of the annotation are relevant (e.g.,
whether the corpus has been annotated manually,
twice, etc.).
(ii), (iii) Probably, the language engineer would not
need any information about annotation instructions.
Comparing these user requirements and the
guideline features in fig. 1, we see that the guide-
lines are more oriented towards the annotator than
the corpus explorer: Features such as indices (E, F)
are often missing, whereas the predominant instruc-
tion ordering is content-based ordering (N).
5 Towards User-Adaptive Annotation
Guidelines
In what follows, we present a preliminary guideline
specification that allows for generating user-adapted
guideline representations. In the second part, we
illustrate the applicability of the specification.
5.1 Guideline Specification
For the specification of user-adaptive guidelines we
adopt ideas from the MATE Markup Framework
(Dybkjaer et al, 1998), which uses so-called Cod-
ing Modules for the specification and representa-
tion of annotation schemes. Building upon MATE,
we define semi-formal class specifications, Guide-
line modules, which we extend with an Instruction
module for the annotation instructions.10 In con-
trast to MATE, we understand the Guideline module
as an underlying specification from which different
representations can be generated. We sketch how
the guidelines can be encoded by XML, which en-
ables the generation of user-adapted representations
through stylesheet technology (e.g. XSLT).
The Guideline module The guideline module
(see fig. 3) constitutes the basis for the specifica-
tion of annotation guidelines. It includes a subset
of the items in the MATE Coding modules and the
document components introduced and explained in
sec. 3.1. Components that can be derived automati-
cally, such as the tagset declaration and indices, are
not part of the specification, since these can be gen-
erated from the information present in the Instruc-
tion module.
The Instruction module Annotation instructions
are specified in the Instruction module. In fig. 4,
we sketch a preliminary XML representation of the
two instructions in fig. 2. The single elements and
attributes specify the instruction components exem-
plified there. In addition, the instruction for the tag
?VB? refers to the second instruction via the ?re-
lated? element, marking it as a ?problematic case?.
The second instruction indeed helps the annotator
to decide between the assignment of two tags, ?VB?
and ?VBP?. For both tags, ?criterion? elements with
application conditions, the respective annotation ac-
tion, and examples are declared.
10The MATE Markup Framework neither addresses the en-
coding of annotation guidelines nor the issue of user-adaptivity
explicitly.
# Component Example
1 Guideline title Part-of-speech tagging guidelines for the Penn Treebank, 3rd Revision
2 Annotated information Part of speech
3 Type of source data English text
4 General principles ...
(annotation conventions & format)
5 Relation to linguistic theories ...
6 Related annotation schemes Bies et al (1995):?Bracketing Guidelines for Treebank II Style?, . . .
7 Annotation instructions ? INSTRUCTION MODULE
8 Creation notes: authors, status, etc. Beatrice Santorini, 1995, 3rd revision
Figure 3: The Guideline module
<instruction tags="VB" keywords="verb, base form" difficulty="easy"
id="instr 1">
<text>This tag subsumes imperatives, infinitives and subjunctives</text>
<criterion>
<condition>verb in base form</condition>
<action>label VB</action>
<example comment="imperative">Do/VB it.</example>
<example comment="infinitive">You should do/VB it.</example>
<example comment="subjunctive">We suggested that he do/VB it.</example>
</criterion>
<related type="problematic case" ref="instr 23"/>
</instruction>
......................................................................................................
<instruction tags="VB, VBP" keywords="verb, subjunctive, present tense"
difficulty="medium" id="instr 23">
<text>If you are unsure whether a form is a subjunctive (VB) or a present
tense verb (VBP), replace the subject by a third person pronoun.</text>
<criterion>
<condition>verb does not take an -s ending</condition>
<action>label VB</action>
<example>I recommended that you do/VB it.</example>
<test>I recommend that he do/*does it.</test>
</criterion>
<criterion>
<condition>verb takes an -s ending</condition>
<action>label VBP</action>
</criterion>
</instruction>
Figure 4: Instructions of fig. 2 as specified in the Instruction module
5.2 Application Examples
The exemplary encoding enables the generation of
a number of various types of user-adapted guideline
representations and document components:
? For all user profiles: The ?tags? and ?keywords?
attributes of the instruction elements in fig. 4 al-
low us to automatically generate indices as lists of
tag:page-number pairs (resp. keyword:page-number
pairs) and tagset declarations as tag:keyword pairs.
? For the annotator: The ?difficulty? attribute can be
used as a guiding principle for the creation of tu-
torial exercises for the annotator, which might start
with easy annotation examples and develop towards
more difficult instructions. Furthermore, when the
annotator annotates a certain tag, the annotation tool
may display the corresponding ?text? element as an
?online help? for the annotator.
? For the guideline author: When the author as-
signs keywords to the instruction s/he is currently
working on, the ?keywords? attribute can be used
to point to related instructions (marked by the same
keywords). The formal specification in general can
be used to support the guideline authors, by com-
pleteness and consistency checks.
6 Conclusions
Current guidelines only provide support for a subset
of the potential users. As we have shown in this pa-
per, different user types, such as annotators, corpus
explorers, language engineers, etc., require different
forms of guidelines in order to fulfill their specific
tasks related to an annotated corpus.
To answer these requirements, we propose a gen-
eral guideline structure which serves as the basis for
generation of user-adapted documents. With the use
of XML/XSLT technology, a broad variety of user-
specific applications can be realized.
It is clear that the detailed specification we pro-
pose make high demands on the guideline authors.
However, forcing the authors to fulfill requirements
such as explicitness (as for the declaration of the
exact annotation action), completeness (keywords,
examples for every instruction), etc., will result
in high-quality standardized annotation guidelines,
which we believe will pay off in greater benefit from
the annotated corpora.
References
James Allen and Mark Core. 1997. DAMSL: Di-
alog Act Markup in Several Layers. Draft;
http://www.cs.rochester.edu/
research/cisd/resources/damsl/
RevisedManual/RevisedManual.html.
Balthasar Bickel, Bernard Comrie, and Martin Haspel-
math. 2004. The Leipzig Glossing Rules. Conven-
tions for interlinear morpheme by morpheme glosses.
Max Planck Institute for Evolutionary Anthropol-
ogy and Department of Linguistics, University of
Leipzig; http://www.eva.mpg.de/lingua/
files/morpheme.html.
Ann Bies, Mark Ferguson, Karen Katz, and Robert
MacIntyre. 1995. Bracketing Guidelines for Tree-
bank II Style, Penn Treebank Project. Department
of Computer and Information Science, University
of Pennsylvania; ftp://ftp.cis.upenn.edu/
pub/treebank/doc/manual/.
Jean Carletta and Amy Isard. 1999. The MATE annota-
tion workbench: User requirements. In Proceedings
of the ACL Workshop Towards Standards and Tools
for Discourse Tagging, University of Maryland.
John Carroll, Ted Briscoe, Nicoletta Calzolari, Stefano
Federici, Simonetta Montemagni, Vito Pirrelli, Greg
Grefenstette, Antonio Sanfilippo, Glenn Carroll, and
Mats Rooth. 1997. SPARKLE Work Package 1: Spec-
ification of Phrasal Parsing. Final Report, 1997-TR-
1; http://dienst.iei.pi.cnr.it/.
Laila Dybkjaer, Niels Ole Bernsen, Hans Dybkjaer,
David McKelvie, and Andreas Mengel. 1998. The
MATE Markup Framework. MATE Deliverable D1.2,
http://mate.nis.sdu.dk/information/
d12/.
Ekkehard Ko?nig, Dik Bakker, ?Oesten Dahl, Mar-
tin Haspelmath, Maria Koptjevskaja-Tamm, Chris-
tian Lehmann, and Anna Siewierska. 1993. EU-
ROTYP Guidelines. European Science Foundation
Programme in Language Typology. http://
www-uilots.let.uu.nl/ltrc/eurotyp/.
Geoffrey Leech and Andrew Wilson. 1996. EAGLES
recommendations for the morphosyntactic annotation
of corpora. Technical Report EAG-TCWG-MAC/R,
ILC-CNR, Pisa; http://www.ilc.cnr.it/
EAGLES96/annotate/annotate.html.
Geoffrey Leech. 1993. Corpus annotation schemes. Lit-
erary and Linguistic Computing, 8(4):275?281.
Eleni Mitsakaki, Rashmi Prasad, Aravind Joshi,
and Bonnie Weber. 2004. Penn Discourse Tree-
bank: Annotation Tutorial. Institute for Research
in Cognitive Science, University of Pennsylva-
nia; http://www.cis.upenn.edu/?pdtb/
dltag-webpage-stuff/pdtb-tutorial.
pdf.
PropBank Project. 2002. PropBank Annotation Guide-
lines. Version 3; http://www.cis.upenn.
edu/?ace/propbank-guidelines-feb02.
pdf.
Geoffrey Sampson. 1995. English for the computer:
The SUSANNE corpus and analytic scheme. Oxford:
Clarendon Press.
Beatrice Santorini. 1995. Part-of-Speech Tagging
Guidelines for the Penn Treebank Project. 3rd
Revision, 2nd printing; ftp://ftp.cis.upenn.
edu/pub/treebank/doc/tagguide.ps.gz;
Department of Computer and Information Science,
University of Pennsylvania.
Anne Schiller, Simone Teufel, Christine Sto?ckert, and
Christine Thielen. 1999. Guidelines fu?r das Tagging
deutscher Korpora mit STTS. http://www.ims.
uni-stuttgart.de/projekte/corplex/
TagSets/stts-1999.pdf.
Rosmary Stegmann, Heike Telljohann, and Erhard
Hinrichs. 2000. Stylebook for the German Treebank
in VERBMOBIL. Technical Report 239, Verbmobil;
http://verbmobil.dfki.de/cgi-bin/
verbmobil/htbin/decode.cgi/share/
VM-depot/FTP-SERVER/vm-reports/
report-239-00.ps.
ANNIS: Complex Multilevel Annotations in a Linguistic Database
Michael Go?tze and Stefanie Dipper
Department of Linguistics, University of Potsdam
14415 Potsdam, Germany
{goetze,dipper}@ling.uni-potsdam.de
Abstract
We present ANNIS, a linguistic database
that aims at facilitating the process of ex-
ploiting richly annotated language data by
naive users. We describe the role of the
database in our research project and the
project requirements, with a special focus
on aspects of multilevel annotation. We
then illustrate the usability of the database
by illustrative examples. We also address
current challenges and next steps.
1 Introduction
Until recently, working with data that is anno-
tated at multiple levels with different types of an-
notation required rather advanced computer skills,
which cannot be expected from the majority of po-
tentially interested users.
We present ANNIS, a linguistic database that
aims at providing the infrastructure for supporting
linguists in their work on multilevel annotations.
We describe and illustrate the current state of our
work and sketch the next steps.
In sec. 2, we present the research scenario AN-
NIS is developed for, show the role of the linguis-
tic database therein, and sketch the major require-
ments it aims to fulfill. We then describe the archi-
tecture and current functionality, and discuss the
way difficult aspects of multidimensional annota-
tions are treated (sec. 3). In sec. 4, we illustrate
the work with the database by three exemplary ap-
proaches. Finally, we sketch our next steps.
2 Background
Research Scenario
The database ANNIS is being developed in the
Collaborative Research Center SFB 632 on Infor-
mation Structure, which consists of 13 individual
research projects from disciplines such as theoret-
ical linguistics, psycholinguistics, first and second
language acquisition, typology and historical lin-
guistics.1 In the research center, data of various
languages is collected and annotated at the levels
of phonology, morphology, syntax, semantics, and
pragmatics?levels that contribute in ways yet to
be determined to the information structural parti-
tioning of discourse and utterances.
For annotation, task-specific tools are being
used, e.g. EXMARaLDA, annotate, RSTTool, and
MMAX.2 Data is then converted into a standoff
data interchange format, which is fed into the lin-
guistic database ANNIS. ANNIS aims at providing
functionalities for exploring and querying the data,
offering suitable means for both visualization and
export.
User Requirements
Central requirements evolving out of the scenario
sketched above and, as we believe, for multilevel
annotation in general are Data heterogeneity, Data
reuse, and Accessibility (cf. (Dipper and Go?tze,
2005)).
Data heterogeneity is a result of: (i) the lan-
guage data to be annotated, varying with respect
to size (single sentences vs. narrations), modal-
ity (monologue vs. dialogue, text vs. speech) and
language; (ii) the annotations, which use different
1http://www.sfb632.uni-potsdam.de/.
For more information about ANNIS, see http://www.
sfb632.uni-potsdam.de/annis/ and (Dipper et al,
2004).
2http://www.rrz.uni-hamburg.de/
exmaralda/
http://www.coli.uni-saarland.de/
projects/sfb378/negra-corpus/
http://www.wagsoft.com/RSTTool
http://mmax.eml-research.de/
61
data structures (attribute-value pairs, trees, point-
ers, etc.); and (iii) data formats that stem from dif-
ferent task-specific annotation tools.
Data reuse must be supported, e.g. for further
or re-annotation, statistical analyses, or reuse of
the data in other tools.
Accessibility of both tools and data is an obvi-
ous prerequisite for data reuse.
In the following section, we will address those
aspects that are particularly relevant for these re-
quirements and discuss their treatment in ANNIS.
3 ANNIS
3.1 Main Features
ANNIS is a Java servlet application that can be ac-
cessed via standard web browsers. In its current
state, it is not database-backed; data is read into
memory and exploited for querying and visualiza-
tion in memory.3
Data format and interoperability The data
model must be suffiently expressive for captur-
ing the data heterogeneity sketched above, includ-
ing the representation of overlapping segments, in-
tersecting hierarchies, and alternative annotations
(e.g., for ambiguous annotations). It should fur-
ther facilitate the addition of new annotations.
In our approach, we use a flexible standoff
XML format, the SFB-standard interchange for-
mat, as the interface format (Dipper, 2005). In this
format, primary data is stored in a file that option-
ally specifies a header, followed by a tag <body>,
which contains the source text. The format makes
use of generic XML elements to encode data struc-
tures and annotations: <mark> (markable) tags
specify text positions or spans of text (or spans of
other markables) that can be annotated by linguis-
tic information. Trees and graphs are encoded by
<struct> (structure) and <rel> (relation) el-
ements, which specify local subtrees. <feat>
(feature) tags specify the information that is an-
notated to markables or structures, which are re-
ferred to by xlink attributes. Each type of anno-
tation is stored in a separate file, hence, competing
or ambiguous annotations can be represented in
a straightforward way: by distributing them over
different files.
Our format allows us to represent different
kinds of annotations in a uniform way. We pro-
3For a more elaborate discussion of the basic concepts of
ANNIS, see (Dipper et al, 2004).
vide importers for the export format of the an-
notation tools annotate, EXMARaLDA, RST Tool,
and MMAX. Our PCC corpus (see sec. 4) im-
ports and synchronizes the following annotations,
which have been annotated by these tools: syn-
tax, information structure, rhetorical structure, and
coreference.
Visualization Suitable means for visualizing in-
formation is crucial for exploring and interpreting
linguistic data. Due to the high degree of data
heterogeneity, special attention has been paid to
the support of visualizing various data structures.
In addition, annotations may refer to segments of
different sizes, e.g. syntax vs. discourse structure.
Furthermore, richness of information in multilevel
annotations has to be taken into account; this re-
quires a certain degree of user-adaptivity, allowing
the user to modify the way information of interest
is displayed.
In ANNIS, we start from a basic interactive tier-
based view, which allows for a compact simulta-
neous representation of many annotation types and
whose appearance can be modified by the user in a
format file. In addition, a discourse view helps the
user to orient him/herself in the discourse. Further
views can be added.
Query support Among the numerous require-
ments for a good query facility for multilevel
annotation, expressiveness, efficiency, and user-
friendly query-formulation appear to be the most
relevant. Even a very brief discussion of these is-
sues would go beyond the limits of this paper, the
reader is instead referred to (Heid et al, 2004).
Currently, ANNIS uses a query language proto-
type which allows the user to query text and anno-
tations, by means of regular expressions and wild-
cards, and various common relational operators
(e.g. for stating relations in tree structures, such as
dominance or sibling relations). However, the set
for querying sequential relations is not sufficiently
expressive, and querying co-reference relations is
not supported yet. Furthermore, user support for
formulating queries is rather poor.
3.2 Open Issues
Data alignment Alignment of annotations cre-
ated by different annotation tools appears to be
most suitable at the level of tokens. However, tools
often come with their own tokenizers and mis-
matches do occur frequently. We currently use a
62
Figure 1: The ANNIS user interface, displaying data from the PCC
simple script that checks for text and token iden-
tity in the standoff files that we generate from the
output of the individual tools. However, all mis-
matches have to be corrected manually. At least
for white-space differences, an automatic fixing
procedure should be feasible (similar to the one
implemented by (Witt et al, 2005)).
Efficient Querying Current querying is re-
stricted to rather small amounts of data, and com-
plex queries may take some time until finishing the
search.
Overlapping elements and intersecting hierar-
chies The query language does not yet support
comfortable searching for overlapping elements.
However, exactly what kinds of queries on over-
lapping segments or intersecting relations should
be supported is an open question.
4 Use Cases
We illustrate the use of ANNIS in linguistic re-
search, exemplified with research questions from
three different linguistic areas.
Historical investigations The project B4: The
role of information structure in the development of
word order regularities in Germanic investigates
the verb-second phenomenon, which occurred in
certain Germanic languages only (e.g., it did in
Modern German, but not in Modern English). One
of their findings is that verb placement in the Old
High German translation of Tatian correlates with
discourse relations: verb-initial sentences usually
occur in narrative contexts and signal continuation
of the story. In contrast, verb-second sentences
indicate subordinative relations (Hinterho?lzl and
Petrova, 2005).
Typological studies In the research project D2:
Typology of Information Structure (cf., e.g.,
(Go?tze et al, To appear)), a typological question-
naire is designed, with which language data can be
elicited using largely language-independent meth-
ods. Currently, data from 13 different languages is
elicited and annotated with information from var-
ious linguistic levels (morphosyntax, phonology,
semantics, and information structure).
An interesting query might look for nominal
phrases (const=np) that are new in the discourse
(given=new) and belong to the (information-) fo-
cus of a sentence (focus=ans), e.g. for inves-
tigating the phonological realization of these.
63
The according query has the form: const=np &
given=new & focus=ans & #1 = #2.4
Queries in ANNIS can be restricted to subsets
of a corpus, by queries such as focus=ans &
doc=*81-11*, which searches for all answer foci
in the data that has been elicited by means of the
task 81-11 in the questionnaire, yielding matching
data from all languages in our database.
Discourse studies The Potsdam Commentary
Corpus, PCC (Stede, 2004), consists of 173 news-
paper commentaries, annotated for morphosyn-
tax, coreference, discourse structure according
to Rhetorical Structure Theory, and information
structure.
A question of interest here is the information-
structural pattern of sentences introducing dis-
course segments that elaborate on another part
of the discourse: elaboration & rel=satellite &
(cat=vroot & aboutness-topic) & #1 > #2 &
#2 = #3. Another research issue is the relation-
ship of coreference and discourse structure. How-
ever, querying for coreference relations is not sup-
ported yet.
5 Future Work
Currently we are working on integrating a native
XML database into our system. To make process-
ing more efficient, we are developing an internal
inline representation of the standoff interchange
format, encoding overlapping segments by means
of milestones or fragments (Barnard et al, 1995).
Furthermore, the query language will be ex-
tended to cover different kinds of queries on se-
quential relations as well as coreference relations.
Finally, we will add basic statistical means to
the query facility, which, e.g., can point to rare
and, hence, potentially interesting feature combi-
nations.
6 Demo
In our demonstration of ANNIS, we will show ex-
ample data from the PCC, Old High German, and
data elicited by the typological questionnaire. We
then illustrate by means of example queries how
the researchers make use of our database in their
daily work, as described above. This includes pre-
senting the visualization and querying facilities of
ANNIS.
4The expression #n refers to the nth constraint stated in
the query; the binary operator = requires extensional iden-
tity (Dipper et al, 2004).
References
David Barnard, Lou Burnard, Jean-Pierre Gaspart,
Lynne A. Price, C. M. Sperberg-McQueen, and Gio-
vanni Batista Varile. 1995. Hierarchical encod-
ing of text: Technical problems and SGML solu-
tions. Text Encoding Initiative: Background and
Context. Special Issue of Computers and the Hu-
manities, 29(211?231).
Stefanie Dipper and Michael Go?tze. 2005. Access-
ing heterogeneous linguistic data ? generic XML-
based representation and flexible visualization. In
Proceedings of the 2nd Language & Technology
Conference 2005.
Stefanie Dipper, Michael Go?tze, Manfred Stede, and
Tillmann Wegst. 2004. ANNIS: A linguistic
database for exploring information structure. In
Shinichiro Ishihara, Michaela Schmitz, and Anne
Schwarz, editors, Interdisciplinary Studies on Infor-
mation Structure (ISIS), volume 1, pages 245?279.
Universita?tsverlag Potsdam, Potsdam, Germany.
Stefanie Dipper. 2005. XML-based stand-off repre-
sentation and exploitation of multi-level linguistic
annotation. In Proceedings of Berliner XML Tage
2005 (BXML 2005), pages 39?50, Berlin, Germany.
Michael Go?tze, Torsten Roloff, Stavros Skopeteas,
and Ruben Stoel. To appear. Exploring a cross-
linguistic production data corpus. In Proceedings of
the Sixth International Tbilisi Symposium on Lan-
guage, Logic and Computation. Batumi, Georgia.
Ulrich Heid, Holger Voormann, Jan-Torsten Milde, Ul-
rike Gut, Katrin Erk, and Sebastian Pado?. 2004.
Querying both time-aligned and hierarchical corpora
with NXT Search. In Proceedings of the Forth In-
ternational Conference on Language Resources and
Evaluation (LREC 2004), pages 1455?1458, Lisbon.
Roland Hinterho?lzl and Svetlana Petrova. 2005.
Rhetorical relations and verb placement in early ger-
manic languages. Evidence from the Old High Ger-
man Tatian translation (9th century). In M. Stede,
C. Chiarcos, M. Grabski, and L. Lagerwerf, edi-
tors, Salience in Discourse. Multidisciplinary Ap-
proaches to Discourse, pages 71?79.
Manfred Stede. 2004. The Potsdam Commentary Cor-
pus. In Proceedings of the ACL Workshop on Dis-
course Annotation, pages 96?102, Barcelona.
Andreas Witt, Daniela Goecke, Felix Sasaki, and Har-
ald Lu?ngen. 2005. Unification of XML documents
with concurrent markup. Literary and Linguistic
Computing, 20(1):103?116.
64
Proceedings of the Linguistic Annotation Workshop, pages 148?155,
Prague, June 2007. c?2007 Association for Computational Linguistics
Standoff Coordination for Multi-Tool Annotation in a Dialogue Corpus
Kepa Joseba Rodr??guez?, Stefanie Dipper?, Michael Go?tze?, Massimo Poesio?,
Giuseppe Riccardi?, Christian Raymond?, Joanna Wisniewska?
?Piedmont Consortium for Information Systems (CSI-Piemonte)
KepaJoseba.Rodriguez@csi.it
?Department of Linguistics. University of Potsdam.
{dipper|goetze}@ling.uni-potsdam.de
?Center for Mind/Brain Sciences. University of Trento.
massimo.poesio@unitn.it
?Department of Information and Communication Technology. University of Trento.
{christian.raymond|riccardi}@dit.unitn.it
?Institute of Computer Science. Polish Academy of Science.
jwisniewska@poczta.uw.edu.pl
Abstract
The LUNA corpus is a multi-lingual, multi-
domain spoken dialogue corpus currently
under development that will be used to de-
velop a robust natural spoken language un-
derstanding toolkit for multilingual dialogue
services. The LUNA corpus will be an-
notated at multiple levels to include an-
notations of syntactic, semantic, and dis-
course information; specialized annotation
tools will be used for the annotation at each
of these levels. In order to synchronize these
multiple layers of annotation, the PAULA
standoff exchange format will be used. In
this paper, we present the corpus and its
PAULA-based architecture.1
1 Introduction
XML standoff markup (Thompson and McKelvie,
1997; Dybkj?r et al, 1998) is emerging as the clean-
est way to organize multi-level annotations of cor-
pora. In many of the current annotation efforts based
on standoff a single multi-purpose tool such as the
NITE XML Toolkit (Carletta et al, 2003) or Word-
Freak (Morton and LaCivita, 2003) is used to anno-
1The members of the LUNA project consortium are: Pied-
mont Consortium for Information Systems (IT), University of
Trento (IT), Loquendo SpA (IT), RWTH-Aachen (DE), Uni-
versity of Avignon (FR), France Telecom R&D Division S.A.
(FR), Polish-Japanese Institute of Information Technology (PL)
and the Institute for Computer Science of the Polish Academy
of Sciences (PL), http://www.ist-luna.eu.
This research was performed in the LUNA project funded by the
EC, DG Infso, Unit E1 and in the Collaborative Research Cen-
ter 632 ?Information Structure?, funded by the German Science
Foundation, http://www.sfb632.uni-potsdam.de.
tate as well as maintain all annotation levels (cf. the
SAMMIE annotation effort (Kruijff-Korbayova? et al,
2006b)).
However, it is often the case that specialized tools
are developed to facilitate the annotation of particu-
lar levels: examples include tools for segmentation
and transcription of the speech signal like PRAAT
(Boersma and Weenink, 2005) and TRANSCRIBER
(Barras et al, 1998), the SALSA tools for FrameNet-
style annotation (Burchardt et al, 2006), and MMAX
(Mu?ller and Strube, 2003) for coreference annota-
tion. Even in these cases, however, it may still be
useful, or even necessary, to be able to visualize
more than one level at once, or to ?knit? together2
multiple levels to create a file that can be used to
train a model for a particular type of annotation.
The Linguistic Annotation Framework by (Ide et al,
2003) was proposed as a unifying markup format to
be used to synchronize heterogeneous markup for-
mats for such purposes.
In this paper, we discuss how the PAULA represen-
tation format, a standoff format inspired by the Lin-
guistic Annotation Framework, is being used to syn-
chronize multiple levels of annotation in the LUNA
corpus, a corpus of spoken dialogues in multiple lan-
guages and multiple domains that is being created to
support the development of robust spoken language
understanding models for multilingual dialogue ser-
vices. The corpus is richly annotated with linguistic
information that is considered relevant for research
on dialogue, including chunks, named entities, argu-
ment structure, coreference, and dialogue acts. We
chose to adopt specialized tools for each level: e.g.,
2In the sense of the knit tool of the LT-XML suite.
148
transcription using TRANSCRIBER, coreference us-
ing MMAX, attributes using SEMANTIZER, etc. To
synchronize the annotation and allow cross-layer op-
erations, the annotations are mapped to a common
representation format, PAULA.
The structure of the paper is as follows. In Sec-
tion 2, we present the LUNA project and the LUNA
corpus with its main annotation levels. In Section 3,
we introduce the PAULA exchange format, focusing
on the representation of time alignment and dialogue
phenomena. Finally we show how PAULA is used in
the LUNA corpus and discuss alternative formats.
2 The LUNA project
The aim of the LUNA project is to advance the state
of the art in understanding conversational speech
in Spoken Dialogue Systems (Gupta et al, 2005),
(Bimbot et al, 2006).
Three aspects of Spoken Language Understand-
ing (SLU) are of particular concern in LUNA: gen-
eration of semantic concept tags, semantic compo-
sition into conceptual structures and context sensi-
tive validation using information provided by the di-
alogue manager. In order to train and evaluate SLU
models, we will create an annotated corpus of spo-
ken dialogues in multiple domains and multiple lan-
guages: French, Italian, and Polish.
2.1 The LUNA corpus
The LUNA corpus is currently being collected, with
a target to collect 8100 human-machine dialogues
and 1000 human-human dialogues in Polish, Italian
and French. The dialogues are collected in the fol-
lowing application domains: stock exchange, hotel
reservation and tourism inquiries, customer support
service/help-desk and public transportation.
2.2 Multilevel annotation
Semantic interpretation involves a number of sub-
tasks, ranging from identifying the meaning of indi-
vidual words to understanding which objects are be-
ing referred to up to recovering the relation between
different semantic objects in the utterance and dis-
course level to, finally, understanding the commu-
nicative force of an utterance.
In some annotation efforts?e.g., in the annotation
of the French MEDIA Corpus (Bonneau-Maynard
and Rosset, 2003)? information about the meaning
of semantic chunks, contextual information about
coreference, and information about dialogue acts are
all kept in a single file. This approach however suf-
fers from a number of problems, including the fact
that errors introduced during the annotation at one
level may make other levels of annotation unusable
as well, and that it is not possible for two anno-
tators to work on different types of annotation for
the same file at the same time. Most current an-
notation efforts, therefore, tend to adopt the ?multi-
level? approach pioneered during the development
of the MAPTASK corpus and then developed as part
of work on the EU-funded MATE project (McKelvie
et al, 2001), in which each aspect of interpreta-
tion is annotated in a separate level, independently
maintained. This approach is being followed, for
instance, in the ONTONOTES project (Hovy et al,
2006) and the SAMMIE project (Kruijff-Korbayova
et al, 2006a).
For the annotation of the LUNA corpus, we de-
cided to follow the multilevel approach as well. That
allows us to achieve more granularity in the anno-
tation of each of the levels and to investigate more
easily dependencies between features that belong to
different levels. Furthermore, we can use different
specialized off-the-shelf annotation tools, splitting
up the annotation task and thus facilitating consis-
tent annotation.
2.3 Annotation levels
The LUNA corpus will contain different types of in-
formation. The first levels are necessary to prepare
the corpus for subsequent semantic annotation, and
include segmentation of the corpus in dialogue turns,
transcription of the speech signal, and syntactic pre-
processing with POS-tagging and shallow parsing.
The next level consists of the annotation of do-
main information using attribute-value pairs. This
annotation will be performed on all dialogues in the
corpus.
The other levels of the annotation scheme are not
mandatory, but at least a part of the dialogues will
be annotated in order to investigate contextual as-
pects of the semantic interpretation. These levels in-
clude the predicate structure, the relations between
referring expressions, and the annotation of dialogue
acts.
149
2.3.1 Segmentation and transcription of the
speech signal
Before transcription and annotation can begin, it
is necessary to segment the speech signal into dia-
logue turns and annotate them with speaker identity
and mark where speaker overlap occurs. The goal
of this segmentation is to be able to perform a tran-
scription and annotation of the dialogue turns with
or without dialogue context. While dialogue context
is preferable for semantic annotation, it slows down
the annotation process.
The tool we will use for the segmentation and
transcription of the speech signal is the open source
tool TRANSCRIBER3 (Barras et al, 1998).
The next step is the transcription of the speech
signal, using conventions for the orthographic tran-
scription and for the annotation of non-linguistic
acoustic events.
2.3.2 Part Of Speech Tagging and Chunking
The transcribed material will be annotated with
POS-tags, morphosyntactic information like agree-
ment features, and segmented based on syntactic
constituency.
For the POS-tags and morphosyntactic features,
we will follow the recommendations made in EA-
GLES (EAGLES, 1996), which allows us to have a
unified representation format for the corpus, inde-
pendently of the tools used for each language.
2.3.3 Domain Attribute Annotation
At this level, semantic segments will be anno-
tated following an approach used for the annotation
for the French MEDIA dialogue corpus (Bonneau-
Maynard and Rosset, 2003).
We specify the domain knowledge in domain on-
tologies. These are used to build domain-specific
dictionaries. Each dictionary contains:
? Concepts corresponding to classes of the ontol-
ogy and attributes of the annotation.
? Values corresponding to the individuals of the
domain.
? Constraints on the admissible values for each
concept.
3http://trans.sourceforge.net
The concept dictionaries are used to annotate se-
mantic segments with attribute-value pairs. The se-
mantic segments are produced by concatenation of
the chunks produced by the shallow parser. A se-
mantic segment is a unit that corresponds unambigu-
ously to a concept of the dictionary.
(1) buongiorno lei [puo` iscriversi]concept1 [agli
esami]concept2 [oppure]concept3 [ottenere
delle informazioni]concept4 come la posso
aiutare4
<concept1 action:inscription>
<concept2 objectDB:examen>
<concept3 conjunctor:alternative>
<concept4 action:obtain info>
2.3.4 Predicate structure
The annotation of predicate structure facilitates
the interpretation of the relation between entities and
events occurring in the dialogue.
There are different approaches to annotate predi-
cate structure. Some of them are based upon syntac-
tic structure, with PropBank (Kingsbury and Palmer,
2003) being one of the most relevant, building the
annotation upon the syntactic representation of the
TreeBank corpus (Marcus et al, 1993). An alter-
native to syntax-driven approaches is the annotation
using semantic roles as in FrameNet (Baker et al,
1998).
For the annotation of predicate structure in the
LUNA corpus, we decided to use a FrameNet-like
approach, rather than a syntax-based approach:
1. Annotation of dialogue interaction has to deal
with disfluencies, non-complete sentences, un-
grammaticality, etc., which complicates the use
of deep syntactic representations.
2. If we start from a syntactic representation, we
have to follow a long way to achieve the seman-
tic interpretation. Syntactic constituents must
be mapped to ?-roles, and then to semantic
roles. FrameNet offers the possibility of anno-
tating using directly semantic criteria.
4Good morning, you can register for the exam or obtain in-
formation. How can I help you?
150
For each domain, we define a set of frames. These
frames are defined based on the domain ontology,
with the named entities providing the frame ele-
ments. For all the frames we introduce the negation
as a default frame element.
For the annotation, first of all we annotate the en-
tities with a frame and a frame element.
Then if the target is overtly realized we make a
pointer from the frame elements to the target. The
next step is putting the frame elements and the target
(if overtly realized) in a set.
(2) buongiorno [lei]fe1 [puo` iscriversi]fe2
[agli esami]fe3 oppure [ottenere delle
informazioni]fe4 come la posso aiutare
set1 = {id1, id2, id3}
frame: inscription
frame-elements:{student, examen, date}
set2 = {id4}
frame = info-request
frame-elements:{student, addressee, topic}
<fe1 frame="inscription"
FE="student" member="set1"
pointer="fe2">
<fe2 frame="inscription"
FE="target" member="set1">
<fe3 frame="inscription"
FE="examen" member="set1"
pointer="fe2">
<fe4 frame="information"
FE="target" member="set2">
2.3.5 Coreference / Anaphoric relations
To annotate anaphoric relations we will use an an-
notation scheme close to the one used in the ARRAU
project (Artstein and Poesio, 2006). This scheme
has been extensively tested with dialogue corpora
and includes instructions for annotating a variety of
anaphoric relations, including bridging relations. A
further reason is the robustness of the scheme that
doesn?t require one single interpretation in the an-
notation.
The first step is the annotation of the information
status of the markables with the tags given and
new. If the markables are annotated with given,
the annotator will select the most recent occurrence
of the object and add a pointer to it. If the mark-
able is annotated with new, we distinguish between
markables that are related to a previously mentioned
object (associative reference) or don?t have such a
relation.
If there are alternative interpretations, which of a
list of candidates can be the antecedent, the annota-
tor can annotate the markable as ambiguous and
add a pointer to each of the possible antecedents.
(3) Wizard: buongiorno [lei]cr1 [puo`
iscriversi]cr2 [agli esami]cr3 oppure ot-
tenere [delle informazioni]cr4 come la posso
aiutare
<cr1 inf status="new" related="no">
<cr2 inf status="new" related="no">
<cr3 inf status="new" related="no">
<cr4 inf status="new" related="no">
Caller: [iscrizione]cr5 [esami]cr65
<cr5 inf status="given"
single phrase antecedent="cr2"
ambiguity="unambiguous">
<cr6 inf status="given"
single phrase antecedent="cr3"
ambiguity="unambiguous">
2.3.6 Dialogue acts
In order to associate the intentions of the speaker
with the propositional content of the utterances, the
segmentation of the dialogue turns in utterances is
based on the annotation of predicate structure. Each
set of frame elements will correspond to an utter-
ance.
Each utterance will be annotated using a multi-
dimensional annotation scheme partially based on
the DAMSL scheme (Allen and Core, 1997) and on
the proposals of ICSI-MRDA (Dhillon et al, 2004).
We have selected nine dialogue acts from the
DAMSL scheme as initial tagset, that can be extended
for the different application domains. Each utter-
ance will be annotated with as many tags as applica-
ble.
(4) Wizard: [buongiorno]utt1 [lei puo` iscriversi
agli esami]utt2 oppure [ottenere delle
5Register for the exam.
151
informzaioni]utt3 [come la posso aiutare]utt4
<utt1 d-act="opening/closing">
<utt2 d-act="statement"
link-frame="set1">
<utt3 d-act="statement"
link-frame="set2">
<utt4 d-act="info-request">
Caller: [iscrizione esami]utt5
<utt5 d-act="answer;statement"
link-frame="set3">
3 PAULA - a Linguistic Standoff Exchange
Format
PAULA stands for Potsdamer Austauschformat fu?r
linguistische Annotation (?Potsdam Interchange
Format for Linguistic Annotation?) and has been de-
veloped for the representation of data annotated at
multiple layers. The application scenario is sketched
in Fig 1: researchers use multiple, specialized off-
the-shelf annotation tools, such as EXMARALDA or
MMAX, to enrich data with linguistic information.
The tools store the data in tool-specific formats and,
hence, it is not straightforward to combine informa-
tion from different sources and, e.g., to search for
correlations across multiple annotation layers.
This is where PAULA comes in: PAULA maps
the tool-specific formats to a common format and
serves as an interchange format between these
tools.6 Moreover, the annotations from the different
sources are merged into one single representation.
PAULA makes this data available for further appli-
cations, such as searching the data by means of the
tool ANNIS7, or to feed statistical applications like
WEKA8.
PAULA is an XML-based standoff format for lin-
guistic annotations, inspired by the ?dump format?
6Currently, we provide PAULA import filters for the follow-
ing tools and formats: Exmaralda, MMAX, RST Tool/URML,
annotate/TIGER XML. Export from PAULA to the tool formats
is at present supported for the original source format only. We
plan to support the export of selected annotations to other tools.
This is, however, not a trivial task since it may involve loss of
information.
7ANNIS: http://www.sfb632.uni-potsdam.de/
annis
8WEKA: http://www.cs.waikato.ac.nz/ml/
weka
Figure 1: PAULA annotation scenario
of the Linguistic Annotation Framework (Ide et al,
2003).9 With PAULA, not only is the primary data
separated from its annotations, but individual anno-
tation layers (such as parts of speech and dialogue
acts) are separated from each other as well. The
standoff approach allows us to mark overlapping
segments in a straightforward way: by distributing
annotations over different files (XML as such does
not easily account for overlapping segments, since
its object model is a hierarchical, tree-like structure).
Moreover, new annotation layers can be added eas-
ily.
PAULA assumes that a representation of the pri-
mary data is stored in a file that optionally spec-
ifies a header with meta information, followed by
a tag <body>, which contains a representation of
the primary data. In Fig. 2, the first box displays
the transcription, with all contributions from the first
speaker coming first, and the contributions from the
other speaker(s) following (put in italics in the Fig-
ure).
The basic type of ?annotation? are markables, en-
coded by the XML element <mark>. Markables
specify ?anchors?, i.e., locations or ranges that can
be annotated by linguistic information. The loca-
tions and ranges are positions or spans in the source
text or timeline, which are referenced by means of
XLinks and XPointer expressions. For instance, the
?Token? markables in Fig. 2 define spans that cor-
9The term ?standoff? describes the situation where primary
data (e.g., the transcription) and annotations of this data are
stored in separate files (Thompson and McKelvie, 1997).
152
 

	
	

Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 166?169,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Annotating Discourse Anaphora
Stefanie Dipper
Institute of Linguistics
Bochum University
dipper@linguistics.rub.de
Heike Zinsmeister
Institute of Linguistics
Konstanz University
Heike.Zinsmeister@uni-konstanz.de
Abstract
In this paper, we present preliminary work on
corpus-based anaphora resolution of discourse
deixis in German. Our annotation guidelines
provide linguistic tests for locating the antecedent,
and for determining the semantic types of both the
antecedent and the anaphor. The corpus consists of
selected speaker turns from the Europarl corpus.
1 Introduction
An important component of text understanding is
anaphora resolution, i.e. to determine the refer-
ence of constituents whose interpretation depends
on (the reference of) other textual elements. The
majority of anaphora are instances of noun phrase
anaphora, which relate a noun phrase anaphor to
a nominal antecedent. Grammatical restrictions
(gender, number agreement) and saliency (gram-
matical function, recency) guide the resolution
process in these cases. In addition to pronouns,
definite noun phrases can be viewed as anaphoric
in that they may corefer to some other NP in the
given context. To solve the latter type of anaphora,
lexical semantic knowledge is required, as pro-
vided by an ontology or a database like WordNet.
Another type of anaphora is discourse deixis
(Webber 1988; 1991), which relates a noun phrase
anaphor to a verbal or (multi-)clausal antecedent.
The discourse entities that are introduced by
antecedents of discourse deictic pronouns are
called ?abstract objects? since they refer to prop-
erties and propositional entities (Asher, 1993).
Grammatical restrictions cannot apply since the
antecedent is non-nominal and the anaphor?
commonly in the form of a personal or demonstra-
tive pronoun?is usually in neuter singular. We
assume that in addition to saliency the resolution
process needs to take semantic restrictions into ac-
count (cf. Hegarty et al (2002)).
The automatic procedure of our research effort
can be envisaged as follows: Given some text we
first locate discourse anaphors. Next, the semantic
(= abstract) type of each anaphor is determined,
based on contextual features that are derived from
annotated corpus data. The anaphor?s semantic
type restricts the semantic type of the antecedent,
and thus narrows down the search space. Finally,
the antecedent is located with the help of these se-
mantic restrictions and, again, with contextual fea-
tures derived from the corpus.
2 Related Work
Corpus-based studies have shown that abstract ob-
jects are less salient than other discourse referents,
which has an effect on the choice of the anaphoric
element (Hegarty et al, 2002). The abstract type
of the antecedent and that of the anaphor do not
necessarily coincide. The data suggests that refer-
ence to other types (referred to in the literature as
coercion) is possible only in accordance to an ab-
stractness hierarchy (Hegarty, 2003; Consten and
Knees, 2005; Consten et al, 2007). The hierarchy
starts with events as the most concrete type, which
are anchored in spatial-temporal dimensions, and
ends with propositions as the most abstract types.
Anaphoric reference is possible to antecedents that
are of the same type or less abstract than the
anaphor (Consten and Knees, 2005).
Most works concerning the annotation of
anaphora resolution do not make reference to ab-
stract entities. OntoNotes, for example, only an-
notates reference to verbs (Pradhan et al, 2007).
Annotation research efforts on discourse deixis in-
clude: Eckert and Strube (2000), Byron (2002),
Poesio and Modjeska (2005), Poesio and Artstein
(2008), and Mu?ller (2007) for English; Navarretta
(2000) for Danish; and Recasens (2008) for Span-
ish/Catalan. To our knowledge, there has been no
attempt to systematically annotate such a corpus
of German.
166
Test: Die Zusammenfu?hrung der nationalen und europa?ischen Ebene ist sehr wohl notwendig , obwohl natu?rlich die
Hauptta?tigkeit in den Mitgliedstaaten stattfinden sollte und nur dann auf europa?ischer Ebene eingegriffen werden sollte ,
wenn dies ? na?mlich auf europa?ischer Ebene einzugreifen ? unbedingt notwendig ist .
Anno: Die Zusammenfu?hrung der nationalen und europa?ischen Ebene ist sehr wohl notwendig , obwohl natu?rlich die
Hauptta?tigkeit in den Mitgliedstaaten stattfinden sollte und nur dann [auf europa?ischer Ebene eingegriffen]prop werden
sollte , wenn [dies]prop unbedingt notwendig ist .
Engl: ?It is indeed necessary to bring the national and European levels together, even though, of course, the main work should
be done in the Member States, with the European level intervening only when this is absolutely necessary.?
Figure 1: Paraphrase test to determine the extension of the antecedent.
3 The Corpus
Our corpus consists of texts from the Europarl cor-
pus (Koehn, 2005). As our basis, we selected all
contributions whose original language is German
(including Austrian German).
For the annotation task, we isolated medium-
sized turns, consisting of 15?20 sentences. This
was done to guarantee that the turns were not
too lengthy but still provided enough information
for the annotators to understand the broader con-
text of discussion, so that they could resolve the
anaphors without comprehension problems. From
these turns, we selected those that contained the
anaphor dies ?this?. This is the only anaphor in
German which unambiguously refers to discourse
units.
4 The Guidelines
Our guidelines are based on theoretical research
on discourse semantics as well as work on anno-
tating discourse phenomena.
Given some discourse anaphor (i.e., anaphoric
das, dies, was, es ?that, this, which, it?), the guide-
lines define (i) how to locate the antecedent, (ii)
how to determine the semantic type of the an-
tecedent, and (iii) how to determine the seman-
tic type of the anaphor. For each of these tasks,
the guidelines provide linguistic tests (Dipper and
Zinsmeister, 2009).
4.1 Locating the antecedent
To determine the antecedent of the anaphoric re-
lation, a ?paraphrase test? is applied: The anno-
tator supplements the anaphor by a paraphrase in
the form of na?mlich . . . ?namely . . . ?. The part
that fills the . . . corresponds to the antecedent that
we are looking for, cf. Fig. 1.1 Antecedents can
1The Test line displays the sentence with the anaphor
(marked in bold-face) followed by the inserted paraphrase
(in bold-face and italics). The Anno line shows the same ex-
consist of VPs, (fragments of) main or subordinate
clauses, or multiple sentences.2
4.2 The semantic type of the antecedent
We distinguish 10 types of propositional enti-
ties. Many verbs prototypically denote one type
of propositional entity; gewinnen ?win?, for in-
stance, usually expresses an event. Often, how-
ever, the type of entity that is denoted depends on
the context and usage of the verb; Hans hat A?pfel
gegessen (?Hans ate apples?) denotes a process,
whereas Hans hat zwei A?pfel gegessen (?Hans ate
two apples?) denotes an event because the action
has an end (when both apples are eaten)?i.e., the
action is telic. The semantic types are defined in
terms of the following features: world-dependent,
time-dependent, dynamic, telic, and modal (with
subtypes deontic and epistemic, generic, subjec-
tive) (see e.g., Vendler (1967), Asher (1993)). Ta-
ble 1 displays the different types of propositional
entities and their defining features. It also lists the
labels used for annotating these entities. The en-
tity types are ordered according to their degree of
abstractness.
The entity type ?deict? (deictic) does not fit in
the abstractness hierarchy of the table. It refers
to extra-linguistic entities, such as the external sit-
uation, or an issue that is currently the focus of
attention in parliament, etc.
ample with the identified antecedent underlined. Both the
antecedent and the anaphor are labeled with their seman-
tic types (see below). The Engl line presents an English
translation that is based on the original translations from Eu-
roparl. We used the tool OPUS (http://urd.let.rug.
nl/tiedeman/OPUS) to retrieve the English translations.
2E.g., the anaphor dies alles ?all this? often refers to
an antecedent consisting of multiple sentences. The ac-
tual antecedent can diverge from the one constructed by
the paraphrase test in minor aspects, such as active-passive-
alternations, or bare infinitive vs. zu-infinitive vs. participle.
In some cases, the divergences are more important and could
involve, for instance, the insertion or modification of the main
verb. In such cases, annotators were asked to note and record
the differences.
167
Prop. Entity Label Defining Features Replacement Test
W T Dyn Tel Mod
1. Event ev + + + + - Ereignis (?event?)
2. Process proc + + + - - Vorgang (?process?)
3. State state + + - (-) - Zustand (?state?)
4. Circumstance circ + + - - - Umstand (?circumstance?)
5. Modal (deontic
+ epistemic)
mod + + - - mod Notwendigkeit, Mo?glichkeit, Chance, . . . (?ne-
cessity, possibility, opportunity, . . . ?)
6. Opinion, claim op + + - - subj Meinung, Ansicht, Behauptung, Einscha?tzung,
Forderung, . . . (?opinion, view, claim, assess-
ment, request, . . . ?)
7. Generic gen + +/- - - gen wohlbekannte, allgemeingu?ltige Tatsache (?the
well-known, universal fact?)
8. Fact fact + +/- +/- +/- - Tatsache (?fact?)
9. Proposition prop - - +/- +/- - (Art von) Aktivita?t, Aktion, Eigenschaft, . . .
?(kind of) activity, action, property, . . . ?)
Table 1: Semantic types and their defining features: W(orld), T(ime), Dyn(amic), (Tel)ic, Mod(al)
4.3 The semantic type of the anaphor
To determine the type of anaphors, we defined a
?replacement test?. With this test, the demonstra-
tive anaphor dies, das, etc. is replaced by a suitable
NP, such as dieses Ereignis, dieser Vorgang. The
head noun indicates the type of the propositional
entity (e.g., event, process).3 Table 1 lists the dif-
ferent types of propositional entities and suitable
replacement nouns. The annotators are asked to
choose the most concrete, suitable noun.
5 Results
As a first pilot study on the reliability of our an-
notation guidelines, two student annotators anno-
tated 32 texts that included 48 instances of the
demonstrative pronoun dies ?this?. The pronouns
were marked in bold face, and the annotation was
performed on paper. After annotating 17 texts, the
annotators discussed their intermediate results.
Locating the antecedent: In one case, one of
the annotators decided on a deictic reading and did
not mark an antecedent at all. 40 out of 47 an-
tecedents (85%) were marked with identical spans.
In four cases they chose differing but adjacent
spans and in one case one of the annotators chose
a longer string than the other.
The semantic type of the antecedent: The
type of the antecedents coincided in 28 out of 47
cases (60%, ?=0.52).4 Agreement improved af-
3We use the term ?semantic type of the anaphor? in a
somewhat sloppy way. Put more precisely, the ?semantic type
of the anaphor? indicates the way that the anaphor refers to
(parts of) the propositional discourse referent that is denoted
by the antecedent.
4We computed ? according to www.asc.upenn.edu/
usr/krippendorff/webreliability.doc.
ter the discussion period: 11/17 cases matched
(?=0.60).
The semantic type of the anaphor: The results
with respect to the semantic type of the anaphor
seemed more disappointing: the annotators agreed
in only 22 out of 48 instances (46%, ?=0.37).
However, after the discussion period, agreement
leveled that of the type of the antecedent: 12 out
of 17 cases coincided (?=0.66). In addition to the
semantic type, we annotated the grammatical role
of the anaphor, which occurred as the subject in
79% of cases and as objects elsewhere.
Annotators agreed most often on the four most
concrete types (?ev, proc, state, circ?) and least of-
ten on the three most abstract types (?gen, fact,
prop?). This might be due to the fact that the most
abstract types are applicable in many cases, but an-
notators are advised to choose the most concrete
type that is available. In the majority of the cases
(73%), the anaphor?s type was identical with or
more abstract than the antecedent?s type.
6 Conclusion
In this paper, we presented a corpus-driven ap-
proach to discourse deictic anaphora in German.
We introduced annotation guidelines that provide
linguistic tests for locating the antecedent, and
for determining the semantic types of both the
antecedent and the anaphor. Further work will
include exploitation of contextual information in
combination with the semantic types to confine the
set of potential antecedents.
Our corpus consists of selected speaker turns
from the Europarl corpus. In this study, 32 texts
(providing 48 instances of discourse deixis) were
168
annotated according to these guidelines, and first
results concerning inter-annotator agreement are
promising (with an agreement of 85% on the ex-
tension of the antecedent, 60% on the antecedent
type, and 46% on the type of the anaphor). The
pilot study indicates that the paraphrase test helps
the annotators in determining on the extension of
the abstract antecedent.5 It also shows that the lin-
guistic tests for the semantic types have to be re-
fined.
In the next steps, we will switch from paper-
and-pencil annotation to annotation based on the
tool MMAX26. In addition to manually determin-
ing the semantic types of anaphors, we will in-
vestigate robust, fully-automatic approaches to the
derivation of contextual features for anaphora res-
olution. For instance, we plan to take into account
anaphors of the form dieses Ereignis, dieser Um-
stand, etc. (?this event, this circumstance?), which
explicitly name the semantic type of the anaphor.
In a later step other, more ambiguous, types of
anaphors will be included in the investigation.
Acknowledgments
We would like to thank the anonymous review-
ers for their helpful comments, and our student
annotators: Doris Aimer, Iris Bra?uning, Christine
Enzinger, Stefanie Konetzka, Barbara Mrzyglod.
The work was in part supported by Europa?ischer
Sozialfonds in Baden-Wu?rttemberg.
References
Nicholas Asher. 1993. Reference to Abstract Objects
in Discourse. Kluwer Academic Publishers, Boston
MA.
Donna K. Byron. 2002. Resolving pronominal refer-
ence to abstract entities. In Proceedings of the ACL-
02 conference, pages 80?87.
Manfred Consten and Mareile Knees. 2005. Complex
anaphors ? ontology and resolution. In P. Dekker,
editor, Proceedings of the 15th Amsterdam Collo-
quium, Amsterdam: University.
Manfred Consten, Mareile Knees, and Monika
Schwarz-Friesel. 2007. The function of com-
plex anaphors in texts: Evidence from corpus stud-
ies and ontological considerations. In Anaphors
in Text, pages 81?102. John Benjamins, Amster-
dam/Philadephia.
5The study was restricted to instances of the unambiguous
anaphor dies ?this?, which might have simplified the task of
selecting an antecedent.
6MMAX2: http://mmax2.sourceforge.net/.
Stefanie Dipper and Heike Zinsmeister. 2009. An-
notation guidelines ?Discourse-Deictic Anaphora?.
Draft. Universities of Bochum and Konstanz.
Miriam Eckert and Michael Strube. 2000. Dialogue
acts, synchronising units and anaphora resolution.
Journal of Semantics, 17(1):51?89.
Michael Hegarty, Jeanette K. Gundel, and Kaja
Borthen. 2002. Information structure and the ac-
cessibility of clausally introduced referents. Theo-
retical Linguistics, 27(2-3):163?186.
Michael Hegarty. 2003. Type shifting of Entities in
Discourse. Presentation at the First International
Workshop on Current Research in the Semantics-
Pragmatics Interface, Michigan State University.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
of MT Summit.
Christoph Mu?ller. 2007. Resolving it, this, and that
in unrestricted multi-party dialog. In Proceedings of
the 45th Annual Meeting of the ACL, pages 816?823,
Prague, Czech Republic, June.
Costanza Navarretta. 2000. Abstract Anaphora Res-
olution in Danish. In 1st SIGdial Workshop on
Discourse and Dialogue, pages 56?65, Hong Kong,
China, October.
Massimo Poesio and Ron Artstein. 2008. Anaphoric
annotation in the ARRAU corpus. In Proceedings
of the LREC 2008, Marrakech, Morocco.
Massimo Poesio and Natalia N. Modjeska. 2005. Fo-
cus, activation, and this-noun phrases: An empirical
study. In Anto?nio Branco, Tony McEnery, and Rus-
lan Mitkov, editors, Anaphora Processing, volume
263 of Current Issues in Linguistic Theory, pages
429?442. John Benjamins.
Sameer Pradhan, Lance Ramshaw, Ralph Weischedel,
Jessica MacBride, and Linnea Micciulla. 2007.
Unrestricted coreference: Identifying entities and
events in OntoNotes. In Proceedings of the IEEE
International Conference on Semantic Computing
(ICSC), Irvine, CA.
Marta Recasens. 2008. Discourse deixis and coref-
erence: Evidence from AnCora. In Proceedings of
the SecondWorkshop on Anaphora Resolution (WAR
II), pages 73?82.
Zeno Vendler, 1967. Linguistics in Philosophy, chapter
Verbs and Time, pages 97?121. Cornell University
Press, Ithaca.
Bonnie L. Webber. 1988. Discourse deixis: Reference
to discourse segments. In Proceedings of the ACL-
88 conference, pages 113?122.
Bonnie L. Webber. 1991. Structure and ostention in
the interpretation of discourse deixis. Language and
Cognitive Processes, 6:107?135.
169
Grammar Modularity and its Impact
on Grammar Documentation
Stefanie Dipper
Universita?t Potsdam Humboldt-Universita?t zu Berlin
Institut fu?r Linguistik Inst. fu?r deutsche Sprache und Linguistik
D-14415 Potsdam D-10099 Berlin
Germany Germany
dipper@ling.uni-potsdam.de stefanie.dipper@rz.hu-berlin.de
Abstract
This paper addresses the documentation of
large-scale grammars.1 We argue that grammar
implementation differs from ordinary software
programs: the concept of modules, as known
from software engineering, cannot be trans-
ferred directly to grammar implementations,
due to grammar-specific properties. These
properties also put special constraints on the
form of grammar documentation. To fulfill
these constraints, we propose an XML-based,
grammar-specific documentation technique.
1 Introduction
Research in the field of grammar development fo-
cuses on grammar modularization, ambiguity man-
agement, robustness, testing and evaluation, main-
tainability and reusability. A point which has of-
ten been neglected is the detailed documentation
of large-scale grammars?despite the fact that thor-
ough documentation of the grammar code is a pre-
requisite for code maintainability and reusability.
In this paper, we argue that documenting large-
scale grammars is a complex task that requires spe-
cial, grammar-specific documentation techniques.
The line of reasoning goes as follows. We show
that maintainability (and, hence, reusability) of a
grammar depends to a large extent on the modular-
ization of the grammar rules: a large-scale gram-
mar remains maintainable only if linguistic gener-
alizations are encoded explicitly, i.e., by modules
(sec. 3.1). However, in contrast to modules in ordi-
nary software programs, (certain) grammar modules
cannot be black boxes (sec. 3.2). This property puts
special constraints on the form of grammar docu-
mentation (sec. 4). Finally, we present an XML-
based documentation technique that allows us to ac-
comodate these constraints (sec. 5).
1The paper is based on my doctoral dissertation (Dipper,
2003), which I wrote at the IMS Stuttgart. I am very grateful
to Anette Frank for invaluable discussions of the dissertation.
Many thanks go to Bryan Jurish and the anonymous reviewers
for helpful comments on the paper.
To illustrate the needs of documentation, we refer
to a German LFG toy grammar (Lexical-Functional
Grammar, cf. sec. 2). Our argumentation, however,
applies not only to grammars in the LFG formalism
but to any grammar that is modularized to a certain
extent.
2 Lexical-Functional Grammar
LFG is a constraint-based linguistic theory (Bresnan
(2001), Dalrymple (2001)). It defines different lev-
els of representation to encode syntactic, semantic
and other information.
The levels that are relevant here are constituent
structure (c-structure) and functional structure (f-
structure). The level of c-structure represents the
constituents of a sentence and the order of the ter-
minals. The level of f-structure encodes the func-
tions of the constituents (e.g. subject, adjunct) and
morpho-syntactic information, such as case, num-
ber, and tense.
The c-structure of a sentence is determined by a
context-free phrase structure grammar and is repre-
sented by a tree. In contrast, the f-structure is rep-
resented by a matrix of attribute-value pairs. The
structures are linked by a correspondence function
(or mapping relation), called ??-projection?.
The (simplified) analysis of the sentence in (1)
illustrates both representation levels, see fig. 1.
(1) Maria liest oft Bu?cher
M. reads often books
?Maria often reads books?
As an example, we display the CP rule in (2)
(which gives rise to the top-most subtree in fig. 1).
(2) CP ? NP C?
(?SUBJ)=? ?=?
The arrows ? and ? refer to f-structures; they de-
fine the ?-projection from c-structure nodes to f-
structures. The ?-arrow refers to the f-structure of
CP
NP C?
Maria V VP
liest ADV NP
oft Bu?cher
?
?
?
?
?
?
?
?
?
?
?
?
?
PRED ?read<SUBJ,OBJ>?
SUBJ
?
?
PRED ?Maria?
CASE nom
NUM sg
?
?
OBJ
?
?
PRED ?book?
CASE acc
NUM pl
?
?
ADJUNCT
{ [
PRED ?often?
]}
TENSE present
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 1: LFG c-structure and f-structure analysis of Maria liest oft Bu?cher
the mother node (= the CP), the ?-arrow to the f-
structure of the node itself (= NP, C?).2
That is, the above rule states that CP dominates
an NP and a C? node; the NP functions as the sub-
ject (SUBJ) of CP, and C? is the head of CP (shar-
ing all features, by unification of their respective f-
structures).
However, the NP preceding C? may as well func-
tion as the direct (OBJ) or indirect object (OBJ2),
depending on case marking. We therefore refine the
CP rule by making use of disjunctive annotations,
marked by curly brackets, cf. (3).
(3) CP ?
NP C?
{ (?SUBJ)=? (?CASE)=nom ?= ?
| (?OBJ)=? (?CASE)=acc
| (?OBJ2)=? (?CASE)=dat }
3 Grammar Modularity
Large grammars are similar to other types of large
software projects in that modularity plays an impor-
tant role in the maintainability and, hence, reusabil-
ity of the code. Modularity implies that the software
code consists of different modules, which in ordi-
nary sofware engineering are characterized by two
prominent properties: (P1) they are ?black boxes?,
and (P2) they are functional units.
Black boxes Modules serve to encapsulate data
and are ?black boxes? to each other. That is, the
input and output of each module (i.e. the interfaces
between the modules) are clearly defined, while the
module-internal routines, which map the input to
the output, are invisible to other modules.
Functional units Usually, a module consists of
pieces of code that belong together in some way
(e.g. they perform similar actions on the input).
2Whenever an arrow is followed by a feature, e.g. SUBJ,
they are enclosed in parentheses, (?SUBJ).
That is, the code is structured according to func-
tional considerations.
Modular code design supports transparency, con-
sistency, and maintainability of the code. (i) Trans-
parency: irrelevant details of the implementation
can be hidden in a module, i.e. the code is not ob-
scured by too many details. (ii) Consistency is fur-
thered by applying once-defined modules to many
problem instances. (iii) Maintainability: if a certain
functionality of the software is to be modified, the
software developer ideally only has to modify the
code within the module encoding that functionality.
In this way, all modifications are local in the sense
that they do not require subsequent adjustments to
other modules.
Turning now to modules in grammar implemen-
tations, we see that similar to modules in ordinary
software projects, grammar modules encode gener-
alizations (functional units, property P2). However,
we argue below that (certain) grammar modules are
not black boxes (whose internal structure is irrel-
evant, property P1), because these generalizations
encode important linguistic insights.
3.1 Grammar Modules
Similarly to modules in ordinary software projects,
modules in grammar implementations assemble
pieces of code that are functionally related: they
do this by encoding linguistic generalizations. A
linguistic generalization is a statement about prop-
erties that are common to/shared by different con-
structions. A grammar module consists of a coher-
ent piece of code that encodes such common prop-
erties and in this sense represents a functional unit.
In a modularized grammar, all constructions that
share a certain property should make use of the
same grammar module to encode this property.
Generalizations that remain implicit (i.e. gener-
alizations that are not encoded by modules) are
error-prone. If the analysis of a certain phe-
nomenon is modified, all constructions that adhere
to the same principles should be affected as well,
automatically?which is not the case with implicit
generalizations.
Which sorts of modules can be distinghuished in
a grammar implementation? In this paper, we limit
ourselves to two candidate modules: (i) syntactic
rules and (ii) macros.
Syntactic rules Each syntactic rule, such as the
CP rule in (3), can be viewed as a module. A syn-
tactic category occurring on the right-hand side of
a rule (e.g. NP in (3)) then corresponds to a mod-
ule call (routine call); the f-structure annotations of
such a category ((?SUBJ)=?) can be seen as the in-
stantiated (actual) parameters that are passed to the
routine. Groups of rules (e.g. CP, C?, and C) form
higher-level modules: X?-projections.
To sum up, syntactic rules can sensibly be viewed
as modules (cf. also Wintner (1999), Zajac and
Amtrup (2000)). Their internal expansion is irrele-
vant for the calling rule (property P1), and they form
a linguistically motivated unit (property P2).3
Macros Grammar development environments
(such as XLE, Xerox Linguistic Environment,
described in Butt et al (1999, ch. 11)) provide
further means of abstraction to modularize the
grammar code, e.g. (parametrized) macros and
templates. Each macro/template can be viewed as a
module, encoding common properties.4
An example macro is NPfunc in (4), which may
be used by the closely related annotations of NPs in
different positions in German, e.g. the annotations
of NPs dominated by CP and by VP, cf. (5). (Macro
calls are indicated by ?@?.)
(4) NPfunc =
{ (?SUBJ)=? (?CASE)=nom
| (?OBJ)=? (?CASE)=acc
| (?OBJ2)=? (?CASE)=dat }
(5) CP ? NP C?
@NPfunc ?=?
VP ? ADV NP
??(?ADJUNCT) @NPfunc
3With regard to f-structure, however, these modules are not
canonical black boxes. LFG provides powerful referencing
means within global f-structures, i.e. f-structure restrictions are
not (and can in general not be) limited to local subtrees. In a
way, f-structure information represents what is called ?global
data? in software engineering: all rules and macros are essen-
tially operating on the same ?global? data structures.
4XLE macros/templates can be used to encapsulate c-
structure and f-structure code. Moreover, macros/templates can
be nested, and can thus be used to model constraints similar to
type hierarchies (Dalrymple et al, To Appear).
That is, NPfunc is used to encapsulate the alterna-
tive NP functions in German. This encoding tech-
nique has the advantage that the code is easier to
maintain. For instance, the grammar writer might
decide to rename the function OBJ2 by IOBJ. Then
she/he simply has to modify the definition of the
macro NPfunc rather than the annotations of all NPs
in the code. Clearly, NPfunc represents a functional
unit; the question of whether NPfunc is a black box
to other modules, such as the syntactic rule CP, is
addressed in the next section.
3.2 Code Transparency and Black Boxes
The above example shows how macros can be used
to encode common properties. In this way, the in-
tentions of the grammar writer are encoded explic-
itly: it is not by accident that the NPs within the CP
and VP are annotated by identical annotations. In
this sense, the use of macros improves code trans-
parency. Further, macros help guarantee code main-
tainability: if the analysis of the NP functions is
modified, only one macro (NPfunc) has to be ad-
justed.
In another sense, however, the grammar code is
now obscured: the functionality of the CP and VP
rules cannot be understood properly without the def-
inition of the macro NPfunc. Macro definitions may
even be stacked, and thus need to be traced back to
understand the rule encodings. In this sense, one
might say that the use of macros hinders code trans-
parency.5
In order to distinguish these opposing views more
precisely we introduce two notions of transparency,
which we call intensional and extensional.
Intensional transparency of grammar code
means that the characteristic defining properties of
a construction are encoded by means of suitable
macros, i.e in terms of generalizing definitions.
Hence, all constructions that share certain defining
properties make use of the same macros to encode
these properties (e.g. the CP and VP rules in (5)).
Conversely, distinguishing properties of differ-
ent constructions are encoded by different macros?
even if the content of the macros is identical.
Extensional transparency means that linguis-
tic generalizations are stated ?extensionally?, i.e.
macros are replaced by their content/definition
(similar to a compiled version of the code). The
grammar rules thus introduce the constraints di-
rectly rather than by calling a macro that would in-
troduce them (similar to the CP rule in (3)).
5The same argumentation applies to type hierarchies: to un-
derstand the functionality of a certain type, constraints that are
inherited from less specific, related types must be traced back.
Comparing both versions, the extensional version
(3) may seem easier to grasp and, hence, more trans-
parent. To understand the generalized version in (5),
it is necessary to follow the macro calls and look up
the respective definitions. Obviously, one needs to
read more lines of code in this version, and often
these lines of code are spread over different places
and files. For instance, the CP rule may be part of a
file covering the CP internal rules, while the macro
NPfunc figures in some other file.
Especially for people who are not well acquainted
with the grammar, the intensional version thus re-
quires more effort for understanding. In contrast,
people who work regularly on the grammar code
know the definitions/functionalities of macros more
or less by heart. They certainly grasp the grammar
and its generalizations more easily in the intensional
version.
One might argue that to know the name of a
macro, such as NPfunc, often suffices to ?under-
stand? or ?know? (or to correctly guess) the func-
tionality of the macro. Hence, a macro would be a
black box (whose definition/internal structure is ir-
relevant), similar to modules in ordinary software
programs.
However, there is an important difference be-
tween grammar implementations and canonical
software programs: grammars encode linguistic in-
sights. The grammar code by itself represents im-
portant information in that it encodes formalizations
of linguistic phenomena (in a particular linguistic
framework). As a consequence, users of the gram-
mar are not only interested in the pure functionality
(the input-output behaviour) of a grammar module.
Instead, the concrete definition of the module is rel-
evant, since it represents the formalization of a lin-
guistic generalization.
We therefore conclude that macro modules, such
as NPfunc, are only defined by property P2 (func-
tional unit), not by property P1 (black box).
The criteria of maintainability and consistency
clearly favour intensional over extensional trans-
parency. We argue that the shortcomings of inten-
sional transparency?namely, poorer readability for
casual users of the grammar?can be compensated
for by a special documentation structure.
4 Grammar Documentation
In large software projects, code documentation
consists of high-level and low-level documenta-
tion. The high-level documentation comprises in-
formation about the function and requirements of
(high-level) modules and keeps track of higher-level
design decisions (e.g. which modules are distin-
guished). More detailed documentation includes
lower-level design decisions, such as the reasons for
the chosen algorithms or data structures.
The lowest level is that of code-level documen-
tation. It reports about the code?s intent rather
than implementation details however, i.e. it focuses
on ?why? rather than ?how?. For instance, it
summarizes relevant features of functions and rou-
tines. A large part of the code-level documenta-
tion is taken over by ?good programming style?,
e.g. ?use of straightforward and easily understand-
able approaches, good variable names, good routine
names? (McConnell (1993, p. 454)).
The level that is of interest to us is that of code-
level documentation. In contrast to documentation
of other types of software, grammar documentation
has to focus both on ?why? and ?how?, due to the
fact that in a grammar implementation the code in
and of itself represents important information, as ar-
gued above. That is, the details of the input?output
mapping represent the actual linguistic analysis. As
a consequence, large parts of grammar documenta-
tion consist of highly detailed code-level documen-
tation.
Moreover, the content/definition of certain de-
pendent modules (such as macros) is relevant to
the understanding of the functionality of the mother
rule. Hence, the content of dependent modules must
be accessible in some way within the documentation
of the mother rule.
One way of encoding such dependencies is by
means of links. Within the documentation of the
mother rule, a pointer would point to the documen-
tation of the macros that are called by this rule.
The reader of the documentation would simply fol-
low these links (which might be realized by hyper-
links).6 However, a typical grammar rule calls many
macros, and macros often call other macros. This
hierarchical structure makes the reading of link-
based documentation troublesome, since the reader
has to follow all the links to understand the func-
tionality of the top-most module.7
We therefore conclude that the structure of the
6Certain programming languages provide tools for the au-
tomatic generation of documentation, based on comments
within the program code (e.g. Java provides the docu-
mentation tool Javadoc, URL: http://java.sun.com/
javadoc/). The generated documentation makes use of hy-
perlinks as described above, which point to the documentation
of all routines and functions that are used by the documented
module.
7Routines and functions in ordinary software may be hier-
archically organized as well. In contrast to grammar modules,
however, these modules are (usually) black boxes. That is, a
reader of the documentation is not forced to follow all the links
Source Documentation
(XML)
Source Grammar
(LFG)
Perl Processing Perl Scripts
Grammar (XML)
XSLT Processing Stylesheets
Documentation
(LATEX)
Documentation
(HTML)
Documentation
(. . . )
Figure 2: XML-based grammar documentation
documentation should be independent of the struc-
ture of the grammar code. We suggest a documenta-
tion method that permits copying of relevant gram-
mar parts (such as macros) and results in a user-
friendly presentation of the documentation.
5 An XML-based Grammar
Documentation Technique
In our approach, grammar code and documentation
are represented by separate documents. The docu-
mentation of a rule comprises (automatically gen-
erated) copies of the relevant macros rather than
simple links to these macros. In a way, our docu-
mentation tool mirrors a compiler, which replaces
each macro call by the content/definition of the re-
spective macro. In constrast to a (simple) com-
piler, however, our documentation keeps a record
of the macro calls (i.e. the original macro calls are
still apparent). In the terminology introduced above,
our documentation thus combines extensional trans-
parency (by copying the content of the macros) with
intensional transparency (by keeping a record of the
macro calls).
The copy-based method has the advantage that
the structure of the documentation is totally inde-
pendent of the structure of the code which is being
documented.
We propose an XML-based documentation
method, i.e. the source documentation and the
grammar code are enriched by XML markup. XSLT
stylesheets operate on this markup to generate the
actual documentation (e.g. an HTML document or
a LaTeX document, which is further processed to
to understand the functionality of the top-most module.
result in a postscript or PDF file). The XML tags
are used to link and join the documentation text and
the grammar code. In this way, the documentation
is independent of the structure of the code.
Fig. 2 presents the generation of the output doc-
umentation. The source documentation is created
manually in XML format (e.g. by means of an XML
editor); the source grammar is written manually in
LFG/XLE format. Next, XML markup is added to
the source LFG grammar via Perl processing. Spe-
cific XML tags within the documentation refer to
tags within the grammar code. The XSLT process-
ing copies the referenced parts of the code to the
output documentation.
This approach guarantees that the code fragments
that are displayed in the documentation are always
up-to-date: whenever the source documentation or
grammar have been modified, the output documen-
tation is newly created by XSLT processing, which
newly copies the code parts from the most recent
version of the grammar.
5.1 Further Features of the Approach
The described documentation method is a powerful
tool. Besides the copying task, it can be exploited
in various other ways, both to further the readibil-
ity of the documentation and to support the task of
grammar writing (see also the suggestions by Er-
bach (1992)).8
Snapshots Grammar documentation is much eas-
ier to read if pictures of c- and f-structures illustrate
the analyses of example sentences. XLE supports
8Except for the different output formats, all of the features
mentioned in this paper have been implemented.
the generation of snapshot postscript files, display-
ing trees and f-structures, which can be included in
a LaTeX document. Note, however, that after any
grammar modification, such snapshots have to be
updated, since the modified grammar may now yield
different c- and f-structure analyses.
In our approach, snapshots are updated automat-
ically: All example sentences in the source docu-
mentation are marked by a special XML tag. XLE
snapshots are triggered by this markup and auto-
matically generated and updated for the entire doc-
umentation, by running the XSLT stylesheet.
Indices In our approach, the documentation does
not follow the grammar structure but assembles
grammar code from different modules. Moreover,
documentation may refer to partial rules only (or
macros). That is, the complete documentation of
an entire rule can be spread over different sections
of the documentation.
User-friendly documentation therefore has to in-
clude an index that associates a grammar rule (or
macro) with the documentation sections that com-
ment on this rule. That is, besides referencing from
the documentation to the grammar (by copying), the
documentation must also support referencing (in-
dexing) from various parts of the grammar to the
relevant parts of the documentation.
Again, such indices are generated automatically
based on XML tags in our approach.
Test-Suites Example sentences in the documenta-
tion can be used to automatically generate a test-
suite. In this way, the grammar writer can easily
check whether the supposed coverage?as reported
by the documentation?and the actual coverage of
the grammar are identical.
It is also possible to create specialized test-suites.
For instance, one can create a test-suite of inter-
rogative NPs, by extracting all examples occurring
within the section documenting interrogative NPs.
Up to now, we have seen how to create and ex-
ploit XML-based grammar documentation. The
next section addresses the question of how to main-
tain such a type of documentation.
5.2 Maintainability
A grammar implementation is a complex software
project and, hence, often needs to be modified, e.g.
to fix bugs, to widen coverage, to reduce overgen-
eration, to improve performance, or to adapt the
grammar to specific applications. Obviously, the
documentation sections that document the modified
grammar parts need to be modified as well.9
9As mentioned above, in some respects, the (output) doc-
umentation is updated automatically by our XML/XSLT-based
In our approach, grammar code and docu-
mentation are represented by separate documents.
Compared to code-internal comments, such code-
external documentation is less likey to remain up-to-
date, because it is not as closely associated with the
code. This section discusses techniques that could
be applied to support maintenance of our XML-
based documentation.
We distinguish three types of grammar modifi-
cations. (i) An existing rule (or macro) is deleted.
(ii) An existing rule is modified. (iii) A new rule is
added to the code.
In case (i), the XSLT processing indicates
whether a documentation update is necessary: Any
rule that is documented in the documentation is ref-
erenced by its ?id? attribute. If such a rule is deleted
from the code, the referenced ?id? attribute does not
exist any more. In this case, the XSLT process-
ing prints out a warning that the referenced element
could not be found.
If, instead, rules are modified or added (cases (ii)
and (iii)), utilities such as the UNIX command ?diff?
can be applied to the output text files: Suppose that
the grammar has been modified while leaving the
documentation text untouched. Now, if the LaTeX
files are newly generated, the only parts that may
possibly have changed are the parts citing grammar
code. These parts can be located by means of the
?diff? command. If such changes between the last
and the current LaTeX files have occurred, these
changes indicate that the surrounding documenta-
tion sections may need to be updated. If no changes
have occurred, despite the grammar modifications,
this implies that the modified parts are not docu-
mented in the (external) documentation and, hence,
no update is necessary. By this technique, the gram-
mar writer gets precise hints as to where to search
for documentation parts that may need to be ad-
justed.
To sum up, maintenance of the documentation
text can be supported by techniques that give hints
as to where the text needs to be adjusted. In the sce-
narios sketched above, the grammar writer would
first modify the grammar only and generate some
new, temporary output documentation. Comparing
the current with the last version of the output doc-
umentation would yield the desired hints. After an
update of the documentation text, a second run of
the XSLT processing would generate the final out-
put documentation.
approach. XSLT operates on the most recent version of the
grammar, therefore all grammar-related elements within the
output documentation that are generated via XSLT are automat-
ically synchronized to the current grammar (e.g. snapshots).
6 Conclusion and Outlook
In this paper, we discussed the importance of main-
tainability and documentation in grammar devel-
opment. A modular and transparent design of the
grammar and detailed documentation are prerequi-
sites for reusability of the grammar code in general.
A modularized grammar is ?intensionally trans-
parent?, as we put it, and thus favours maintain-
ability. However, for casual users of the grammar,
modularity may result in decreased readability. This
is related to the fact that grammar modules are not
black boxes, since they encode linguistic general-
izations. We argued that this can be compensated
for by a special documentation technique, which al-
lows for user-friendly documentation that is inde-
pendent of the structure of the grammar code.
Similar to common grammar-specific tools that
are provided by grammar development environ-
ments, we propose a grammar-specific documenta-
tion technique (which ought to be integrated into
the grammar development environments, as also
suggested by Erbach and Uszkoreit (1990), Erbach
(1992)).
Our XML-based documentation technique is a
very powerful means that can be exploited to sup-
port the difficult task of grammar (and documen-
tation) development in various further ways. For
instance, the grammar code can be ?translated? to
a pure XML document, i.e. each atomic element
of the code (syntactic categories such as NP; f-
structure elements, e.g. ?, SUBJ, =) is marked by
a tag. This markup can be used in various ways, for
instance:
? The grammar code can be displayed with re-
fined highlighting, e.g. c-structure and f-structure
elements can be printed in different colours. This
improves the transparency and readability of the
code.
? The grammar code can be mapped to a repre-
sentation that uses annotated trees instead of rules.
This may result in a better understanding of the
code. (However, the mapping to the annotated-tree
representation is not trivial, since c-structure rules
make use of regular expressions.)
References
Joan Bresnan. 2001. Lexical-Functional Syntax,
volume 16 of Textbooks in Linguistics. Oxford,
UK: Blackwell.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999. A Grammar
Writer?s Cookbook. Number 95 in CSLI Lecture
Notes. Stanford, CA: CSLI.
Mary Dalrymple, Ron Kaplan, and Tracy H. King.
To Appear. Lexical structure as generalizations
over descriptions. In Miriam Butt and Tracy H.
King, editors, Proceedings of the LFG04 Confer-
ence. CSLI Online Proceedings.
Mary Dalrymple. 2001. Lexical Functional Gram-
mar, volume 34 of Syntax and Semantics. New
York et al: Academic Press.
Stefanie Dipper. 2003. Implementing and Docu-
menting Large-Scale Grammars?German LFG,
volume 9(1) of AIMS (Arbeitspapiere des Insti-
tuts fu?r Maschinelle Sprachverarbeitung). Uni-
versity of Stuttgart.
Gregor Erbach and Hans Uszkoreit. 1990. Gram-
mar engineering: Problems and prospects.
CLAUS Report No. 1. Report on the Saarbr u?cken
Grammar Engineering Workshop, University of
the Saarland, Germany.
Gregor Erbach. 1992. Tools for grammar engineer-
ing. In Proceedings of ANLP-92, pages 243?244,
Trento, Italy.
Steve McConnell. 1993. Code Complete. A Prac-
tical Handbook of Software Construction. Red-
mond, WA: Microsoft Press.
Shuly Wintner. 1999. Modularized context-free
grammars. In Proceedings of MOL6?Sixth
Meeting on Mathematics of Language, pages 61?
72, Orlando, Florida.
Re?mi Zajac and Jan W. Amtrup. 2000. Modular
unification-based parsers. In Proceedings of the
Sixth International Workshop on Parsing Tech-
nologies, Trento, Italy.
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 182?185,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
OTTO: A Transcription and Management Tool for Historical Texts
Stefanie Dipper, Lara Kresse, Martin Schnurrenberger & Seong-Eun Cho
Institute of Linguistics, Ruhr University Bochum
D ? 44780 Bochum
dipper@linguistics.rub.de, lara.kresse@rub.de,
martin.schnurrenberger@rub.de, seong-eun.cho@rub.de
Abstract
This paper presents OTTO, a transcription
tool designed for diplomatic transcription
of historical language data. The tool sup-
ports easy and fast typing and instant ren-
dering of transcription in order to gain a
look as close to the original manuscript
as possible. In addition, the tool provides
support for the management of transcrip-
tion projects which involve distributed,
collaborative working of multiple parties
on collections of documents.
1 Corpora of Historical Languages1
The only way to study historical languages is, of
course, by looking at texts, or corpora from these
languages. Compared to texts from modern lan-
guages, early manuscripts or prints pose particular
challenges. Depending on physical condition of
the manuscripts, passages can be hard to decipher,
or pages can be damaged or missing completely.
Some texts contain words or passages that have
been added later, e.g., to clarify the meaning of a
text segment, or to correct (real or assumed) errors.
Moreover, historical texts exhibit a large
amount of character peculiarities (special letters,
punctuation marks, abbreviations, etc.), which are
not easily encoded by, e.g., the ASCII encoding
standard. For instance, medieval German texts of-
ten use superscribed letters to represent emerging
or remnant forms of diphthongs, e.g. ou. Some texts
distinguish two forms of the (modern) letter <s>,
the so-called short vs. long s: <s> vs. <?>. Con-
versely, some texts do not differentiate between
the (modern) letters <u> and <v>.
The existence of letter variants is often at-
tributed to aesthetic reasons or to save (expen-
1The research reported in this paper was financed by
Deutsche Forschungsgemeinschaft, Grant DI 1558/1-1.
We would like to thank the anonymous reviewers for their
helpful comments.
sive) space. Thus, when early manuscripts are
to be transcribed, it must first be decided whether
the differences between such variants are consid-
ered irrelevant and, hence, can be safely ignored,
or whether they constitute a (possibly) interesting
phenomenon and potential research issue.
This discussion relates to the level of tran-
scription, i.e. ?how much of the information in
the original document is included (or otherwise
noted) by the transcriber in his or her transcrip-
tion? (Driscoll, 2006). Diplomatic transcription
aims at reproducing a large range of features of the
original manuscript or print, such as large initials
or variant letter forms.
Another important issue with historical corpora
is meta-information. A lot of research on histor-
ical texts focuses on the text proper and its con-
tent, rather than its language. For instance, re-
searchers are interested in the history of a text
(?who wrote this text and where??), its relation-
ship to other texts (?did the writer know about or
copy another text??), its provenance (?who were
the owners of this text??), or its role in the cul-
tural context (?why did the author write about this
subject, and why in this way??). To answer such
questions, information about past and current de-
positories of a manuscript, peculiarities of the ma-
terial that the text is written on, etc. are collected.
In addition, any indicator of the author (or writer)
of the text is noted down. Here, the text?s language
becomes relevant as a means to gather information
about the author. Linguistic features can be used to
determine the text?s date of origin and the author?s
social and regional affiliation. Usually, this kind
of information is encoded in the header (see, e.g.,
the TEI header (TEI Consortium (eds), 2007)).2
From the above, we derive the following re-
quirements:
Above all, use of Unicode is indispensable, to
2Text Encoding Initiative, www.tei-c.org
182
be able to encode and represent the numerous spe-
cial symbols and characters in a reliable and sus-
tainable way. Of course, not all characters that oc-
cur in historical texts are already covered by the
current version of Unicode. This is especially true
of character combinations, which are only sup-
ported partially (the main reason being that Uni-
code?s Combining Diacritical Marks focus on su-
perscribed diacritics rather than characters in gen-
eral). Therefore, Unicode?s Private Use Area has
to be used as well.
Similarly, there are characters without glyphs
defined and designed for them. Hence, an ideal
transcription tool should support the user in creat-
ing new glyphs whenever needed.
Since there are many more characters in histori-
cal texts than keys on a keyboard, the transcription
tool must provide some means to key in all char-
acters and combinations (similar issues arise from
logographic scripts, such as Chinese). In princi-
ple, there are two ways to do this:
(i) The transcriber uses a virtual keyboard,
which supports various character sets simultane-
ously and is operated by the mouse. Virtual key-
boards are ?WYSIWYG? in that their keys are la-
beled by the special characters, which can then be
selected by the user by mouse clicks. As is well
known, virtual keyboards are often preferred by
casual users, beginners, or non-experts, since they
are straightforward to operate and do not require
any extra knowledge. However, the drawback is
that ?typing? with a computer mouse is rather slow
and tedious and, hence, not a long-term solution.
(ii) Alternatively, special characters, such as
?$?, ?@?, etc., are used as substitutes for historical
characters, commonly in combination with ordi-
nary characters, to yield a larger number of char-
acters that can be represented. Regular and ad-
vanced users usually prefer substitute characters
to virtual keyboards, because once the user knows
the substitutes, typing them becomes very natural
and fast. Of course, with this solution transcribers
have to learn and memorize the substitutes.
Some tools convert substitutes to the actual
characters immediately after typing (this is the
case, e.g., with shortcuts in Emacs), while others
require additional post-processing by interpreters
and viewers to display the intended glyphs (e.g.,
LaTeX encodings converted to postscript). Imme-
diate preview seems advantageous in that it pro-
vides immediate feedback to the user. On the other
hand, it might be easier to memorize substitutes if
the user can actually see them.
Which input method is to be preferred for his-
torical data? Transcription projects often involve
both beginners and advanced users: having people
(e.g. student assistants) join and leave the team is
rather often the case, because transcribing is a very
labor- and time-intensive task.
Our transcription tool OTTO faces this fact by
combining the advantages of the two methods.
The user types and views character substitutes but
simultaneously gets feedback in a separate win-
dow about whether the input is correct or not. This
lessens the uncertainty of new team members and
helps avoiding typing mistakes, thus increasing
the quality of transcription.
Another important requirement is the possibil-
ity to mark additions, deletions, uncertain read-
ings, etc. To encode such information, TEI also
provides a standardized representation format.
Finally, projects that involve multiple parties
distributed over different sites add a further re-
quirement. In such scenarios, tools are preferably
hosted by a server and operated via a web browser.
This way, there is no need of multiple installations
at different sites, and data on the server does not
need to be synchronized but is always up to date.
To our knowledge, there is no transcription tool
that (i) would support Unicode, (ii) allow for fast
typing, using character substitutes, and (iii) is
web-based. In MS Word, special characters are
usually inserted by means of virtual keyboards but
character substitutes can be defined via macros.
However, macros often pose problems when Word
is upgraded. Moreover, Word is not web-based.
LaTeX, which supports character substitutes, is of-
ten considered too complex for non-expert users,
does not offer instant preview, and is not web-
based.
2 The Transcription Tool OTTO3
OTTO is an online transcription tool for editing,
viewing and storing information of historical lan-
guage data. OTTO?s data model is a directed
graph. Nodes point to a (possibly empty) stretch
of primary data and are labeled.
The tool is written in PHP and also uses some
Java Script; data is stored in a mySQL database.
3A prior version of OTTO has been described in Dipper
and Schnurrenberger (2009).
183
Figure 1: Screenshot of the text editor
Any server which runs PHP >5.2 can be a host
for OTTO. Users can login to the tool from any-
where using a standard web browser. A live demo
of OTTO, with slightly restricted functionality,
can be tried out here: http://underberg.
linguistics.rub.de/ottolive.
2.1 Transcribing with OTTO
OTTO integrates a user-definable header editor, to
enter meta information about the manuscript, such
as its title, author, date of origin, etc. However, the
tool?s core feature is the text editor. The upper part
of the text editor in Fig. 1 displays the lines that
have been transcribed and saved already. Each line
is preceded by the bibliographic key, M117_sd2,
the folio and line numbers, which are automati-
cally generated.
The bottom part is dominated by two separate
frames. The frame on the left, called Transcrip-
tion, is the currently ?active? field, where the user
enters the transcription (or edits an existing one).
The transcriber can use substitute characters to en-
code non-ASCII characters. In the figure, the dol-
lar sign ($) serves as a substitute for long s (<?>,
see the first word of the text, De$), and u\o stands
for ou (see Cu\onrat in the Transcription field at the
bottom).
The frame on the right, called Unicode, directly
transforms the user input to its diplomatic tran-
scription form, using a set of transcription rules.
The diplomatic Unicode view thus provides imme-
diate feedback to the transcriber whether the input
is correct or not.
Transcription rules have the form of ?search-
and-replace? patterns. The first entity specifies the
character ?to be searched? (e.g. $), the second en-
tity specifies the diplomatic Unicode character that
?replaces? the actual character. Transcription rules
are defined by the user, who can consult a database
such as the ENRICH Gaiji Bank4 to look up Uni-
code code points and standardized mappings for
them, or define new ones. OTTO uses the Juni-
code font, which supports many of MUFI?s me-
dieval characters, partly defined in Unicode?s Pri-
vate Use Area.5
Rules can be defined locally?i.e., applying to
the current transcription only?or globally, i.e.,
applying to all documents contained in OTTO?s
database.6 The rules are used to map the lines
entered in the Transcription frame to the lines in
diplomatic form in the Unicode frame.
OTTO allows for the use of comments, which
4http://beta.manuscriptorium.com/
5Junicode: http://junicode.sourceforge.
net/; MUFI (Medieval Unicode Font Initiative):
http://www.mufi.info/
6Global rules can be thought of as the application of a
project?s transcription criteria; local rules can be viewed as
handy abbreviations defined by individual users.
184
can be inserted at any point of the text. Since the
current version of OTTO does not provide special
means to take record of passages that have been
added, deleted, or modified otherwise, the com-
ment mechanism could be exploited for this pur-
pose.
The transcription, both in original (typed) and
in Unicode version, can be exported to a (cus-
tomized) TEI-conform XML format. Transcrip-
tion rules are optionally included in the header.
2.2 Transcription Projects
Projects that deal with the creation of historical
corpora often involve a cascade of successive pro-
cessing steps that a transcription has to undergo.
For instance, high-quality transcriptions are often
entered twice, by two transcribers independently
from each other, and their outcomes are compared
and adjusted. In the case of diplomatic transcrip-
tions, a further step called collating is necessary.
Collating means comparing the transcription and
the original manuscript in full detail. Often two
people are involved: One person reads out the
manuscript letter for letter, and also reports on any
superscript, white-space, etc. The other person
simultaneously tracks the transcription, letter for
letter. This way, high-quality diplomatic transcrip-
tion can be achieved.
To cope with the numerous processing steps,
transcription projects often involve a lot of people,
who work on different manuscripts (or different
pages of the same manuscript), in different pro-
cessing states.
OTTO supports such transcription projects in
several aspects: First, it allows for remote access
to the database, via standard web browsers. Sec-
ond, documents that are currently edited by some
user are locked, i.e., cannot be edited or modi-
fied otherwise by another user. Third, OTTO pro-
vides facilities to support and promote communi-
cation among project members. Finally, graphical
progress bars show the progress for each transcrip-
tion, measuring the ratio of the subtasks already
completed to all subtasks,
3 Conclusion and Future Work
This paper presented OTTO, an online transcrip-
tion tool for easy and fast typing, by the use of
user-defined special characters, and, simultane-
ously, providing a view on the manuscript that is as
close to the original as possible. OTTO also sup-
ports distributed, collaborative working of multi-
ple parties on collections of documents.
Future work includes adding further support for
transcribing special characters. First, we plan to
integrate a virtual keyboard for casual users. The
keyboard can also be used in the creation of tran-
scription rules, in order to specify the Unicode re-
placement characters, or if the user wants to look
up the substitute character defined for a specific
Unicode character in the set of transcription rules.
We plan to use the TEI gaiji module for the
representation of transcription rules and substitute
characters; similarly, elements from the TEI tran-
scr module could be used for the encoding of ad-
ditions, deletions, etc.7
For facilitating the collation process, we plan
to integrate transparent overlays. The user would
have to rescale an image of the original manuscript
and adjust it to the transcription, so that corre-
sponding characters would match.
OTTO is designed as to allow for adding cus-
tom functions, by being programmed according
to the paradigm of object-oriented programming.
Additional functionality can easily be integrated
(known as Plug-Ins). We currently work on in-
tegrating a normalizer into OTTO which maps
spelling and dialectal variants of word forms to a
standardized word form (Schnurrenberger, 2010).
OTTO will be made freely available to the re-
search community.
References
Stefanie Dipper and Martin Schnurrenberger. 2009.
OTTO: A tool for diplomatic transcription of histor-
ical texts. In Proceedings of 4th Language & Tech-
nology Conference, Poznan, Poland. To appear.
Matthew J. Driscoll. 2006. Levels of transcription.
In Lou Burnard, Katherine O?Brien O?Keeffe,
and John Unsworth, editors, Electronic Textual
Editing, pages 254?261. New York: Modern
Language Association of America. URL: http:
//www.tei-c.org/About/Archive_new/
ETE/Preview/driscoll.xml.
Martin Schnurrenberger. 2010. Methods for
graphemic normalization of unstandardized written
lang uage from Middle High German Corpora. Mas-
ter?s thesis, Ruhr University Bochum.
TEI Consortium (eds). 2007. TEI P5: Guidelines for
electronic text encoding and interchange. http:
//www.tei-c.org/Guidelines/P5/.
7http://www.tei-c.org/release/doc/
tei-p5-doc/html/WD.html and PH.html
185
Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 86?90,
Gothenburg, Sweden, April 26 2014.
c?2014 Association for Computational Linguistics
CorA: A web-based annotation tool for historical
and other non-standard language data
Marcel Bollmann, Florian Petran, Stefanie Dipper, Julia Krasselt
Department of Linguistics
Ruhr-University Bochum, 44780 Bochum, Germany
{bollmann|petran|dipper|krasselt}@linguistics.rub.de
Abstract
We present CorA, a web-based annotation
tool for manual annotation of historical and
other non-standard language data. It allows
for editing the primary data and modify-
ing token boundaries during the annotation
process. Further, it supports immediate re-
training of taggers on newly annotated data.
1 Introduction
1
In recent years, the focus of research in natural
language processing has shifted from highly stan-
dardized text types, such as newspaper texts, to text
types that often infringe orthographic, grammatical
and stylistic norms normally associated with writ-
ten language. Prime examples are language data
produced in the context of computer-mediated com-
munication (CMC), such as Twitter or SMS data,
or contributions in chat rooms. Further examples
are data produced by learners or historical texts.
Tools trained on standardized data perform con-
siderably worse on ?non-standard varieties? such
as internet data (cf. Giesbrecht and Evert (2009)?s
work on tagging the web or Foster et al. (2011)?s
results for parsing Twitter data) or historical lan-
guage data (Rayson et al., 2007; Scheible et al.,
2011). This can mainly be attributed to the facts
that tools are applied out of domain, or only small
amounts of manually-annotated training data are
available.
A more fundamental problem is that common
and established methods and categories for lan-
guage analysis often do not fit the phenomena oc-
curring in non-standard data. For instance, gram-
maticalization is a process of language evolution
where new parts of speech are created or words
switch from one class to another. It is difficult to
draw strict categorial boundaries between words
1
The research reported here was financed by Deutsche
Forschungsgemeinschaft (DFG), Grant DI 1558/5-1.
that take part in a continuous smooth transition of
categories. Factors like these can also affect the
way the data should be tokenized, along with other
problems such as the lack of a fixed orthography.
In the light of the above, we developed a web-
based tool for manual annotation of non-standard
data. It allows for editing the primary data, e.g.
for correcting OCR errors of historical texts, or
for modifying token boundaries during the annota-
tion process. Furthermore, it supports immediate
retraining of taggers on newly annotated data, to
attenuate the problem of sparse training data.
CorA is currently used in several projects that
annotate historical data, and one project that ana-
lyzes chat data. So far, about 200,000 tokens in
84 texts have been annotated in CorA. Once the
annotation process is completed, the transcriptions
and their annotations are imported into the ANNIS
corpus tool (Zeldes et al., 2009) where they can be
searched and visualized.
The paper focuses on the annotation of historical
data. Sec. 2 presents the tool, and Sec. 3 describes
the data model. Sec. 4 concludes.
2 Tool Description
CorA uses a web-based architecture:
2
All data
is stored on a server, while users can access and
edit annotations from anywhere using their web
browser. This approach greatly simplifies collabo-
rative work within a project, as it ensures that all
users are working on the same version of the data
at all times, and requires no software installation
on the user?s side. Users can be assigned to indi-
vidual project groups and are only able to access
documents within their group(s).
2.1 The annotation editor
All annotation in CorA is done on a token level;
the currently supported annotation types are part-
2
It implements a standard AJAX architecture using PHP 5,
MySQL, and JavaScript.
86
Figure 1: Web interface of CorA showing the annotation editor
of-speech tags, morphology tags, lemmatization,
and (spelling) normalization. The tool is designed
to increase productivity for these particular an-
notation tasks, while sacrificing some amount of
flexibility (e.g., using different annotation layers,
or annotating spans of tokens). Note that this is
mainly a restriction of the web interface; the under-
lying database structure is much more flexible (cf.
Sec. 3), facilitating the later addition of other types
of annotation, if desired.
Tokens are displayed vertically, i.e., one token
per line. This way, the annotations also line up
vertically and are always within view. Addition-
ally, a horizontal text preview can be displayed at
the bottom of the screen, which makes it easier
to read a continuous text passage. Fig. 1 shows a
sample screenshot of the editor window.
3
Users
can customize the editor, e.g. by hiding selected
columns.
Parts-of-speech and morphology Within the
editor, both POS and morphology tags can be se-
lected from a dropdown box, which has the ad-
vantage of allowing both mouse-based and faster
keyboard-based input. Tagsets can be defined in-
dividually for each text. If morphology tags are
used, the selection of tags in the dropdown box is
restricted by the chosen POS tag.
3
The user interface is only available in German at the time
of writing, but an English version is planned.
Lemmatization Lemma forms are entered into
a text field, which can optionally be linked to a
pre-defined lexicon from which it retrieves auto-
completion suggestions. Furthermore, if an identi-
cal token has already been annotated with a lemma
form elsewhere within the same project, that lemma
is always displayed as a highlighted suggestion.
Normalization For corpora of non-standard lan-
guage varieties, spelling normalization is often
found as an annotation layer, see, e.g., Scheible
et al. (2011) for historical data and Reznicek et al.
(2013) for learner data.
In addition to normalization, an optional mod-
ernization layer can be used that defaults to the
content of the normalization field. The normaliza-
tion layer can be used for standardizing spelling,
and the modernization layer for standardizing in-
flection and semantics (Bollmann et al., 2012).
Meta information CorA features a progress indi-
cator which can be used to mark annotations as ver-
ified (see the green bar in Fig. 1). Besides serving
as a visual aid for the annotator, it is also used for
the automatic annotation component (cf. Sec. 2.2).
Additionally, tokens can be marked as needing fur-
ther review (indicated with a red checkbox), and
comments can be added.
2.2 Automatic annotation
CorA supports (semi-)automatic annotation by in-
tegrating external annotation software on the server
87
side. Currently, RFTagger (Schmid and Laws,
2008) and the Norma tool for automatic normaliza-
tion (Bollmann, 2012) are supported, but in princi-
ple any other annotation tool can be integrated as
well. The ?retraining? feature collects all verified
annotations from a project and feeds them to the
tools? training functions. The user is then able to
invoke the automatic annotation process using the
newly trained parametrizations, which causes all
tokens not yet marked as verified to be overwritten
with the new annotations.
The retraining module is particularly relevant for
non-standard language varieties where appropriate
language models may not be available. The idea
is that as more data is manually annotated within
a corpus, the performance of automatic annotation
tools increases when retrained on that data. This
in turn makes it desirable to re-apply the automatic
tools during the annotation process.
2.3 Editing primary data
In diplomatic transcriptions of historical
manuscripts, the transcripts reproduce the
manuscripts in the most accurate way, by encoding
all relevant details of special graphemes and
diacritics, and also preserving layout information.
Transcribers often use ASCII-based encodings for
special characters, e.g., the dollar sign $ in place
of a long s (???).
The data model of CorA (cf. Sec. 3) distin-
guishes between different types of token representa-
tions. In the annotation editor, the user can choose
to display either the original transcription layer or
the UTF-8 representation.
If an error in the primary data?e.g., a transcrip-
tion error or wrong tokenization?is noticed during
the annotation, it can be corrected directly within
the editor. CorA provides functionality to edit, add,
or delete existing tokens. Furthermore, external
scripts can be embedded to process any changes,
by checking an edited token for validity (e.g., if
tokens need to conform to a certain transcription
format), or generating the UTF-8 representation
by interpreting special characters (e.g., mapping $
to ?).
2.4 Comparison to related tools
There is a range of annotation tools that can be
used for enriching data with different kinds of an-
notations. Prominent examples are GATE, EX-
MARaLDA, MMAX2, brat, and WebAnno.
4
Many
annotation projects nowadays require distributed
collaborative working of multiple parties. The cur-
rently preferred solution is to use a tool with an
underlying database which is operated through a
standard web-browser. Among the tools above,
only brat and WebAnno are web-based tools. Com-
pared to CorA, these tools are more flexible in
that they support more annotation layers and more
complex (e.g., multi-word) annotations. WebAnno,
in addition, offers facilities for measuring inter-
annotator agreement and data curation. However,
brat and WebAnno do not allow edits to the source
document from within the tool, which is particu-
larly relevant for non-standard language varieties.
Similarly, they do not support retraining on newly
annotated data.
3 Data Model
The requirements described in Sec. 2 present vari-
ous challenges to the data storage, which necessi-
tated the development of our own data model. A
data model in this context is a conceptual model
of the data structure that allows serialization into
various representations such as XML or databases.
Such a model also allows for easy conversion be-
tween serializations and hence facilitates interop-
erability with existing formats and tools. The
complex, multi-layered layout, the differences in
tokenization, and the fine-grained description of
graphematic pecularities in the primary data cannot
be captured well using existing formats. For exam-
ple, tokenization differences as they are handled
by formats such as <tiger2/> (Bosch et al., 2012)
pertain only to the contraction of underlying units
to original forms, and not the other way around.
This means that while a conversion in such formats
is easily possible, some of the data structure that
is captured by our model is necessarily lost in the
process. To come up with a data model that min-
imizes redundancy and allows for flexibility and
extensibility, and accomodates the work flow of
our transcriptors and annotators, we employed nor-
malization techniques from database development.
A slightly simplified version of the data model is
shown in Fig. 2.
4
GATE: http://gate.ac.uk/
EXMARaLDA: http://www.exmaralda.org/
MMAX2: http://mmax2.sourceforge.net/
brat: http://brat.nlplab.org/
WebAnno: https://code.google.com/p/webanno/
88
Figure 2: Data model used for CorA
Token and Text The model is centered around
two units, a text and a token. A token is a virtual
unit that can manifest in two ways, the diplomatic
token and the modern token, each of which has
a one-to-many relation with a token (cf. Fig. 3).
Diplomatic tokens are tokens as they appear in
the original, historical text, while modern tokens
mirror modern conventions for token boundaries,
representing suitable units for further annotations,
e.g. with POS tags. All physical layout information
on the other hand relates to the diplomatic token.
The text is the entirety of a transcribed document
that can be partitioned in various ways. The layout
is captured by its relation to the page, column, and
line, which in turn relate to the diplomatic tokens.
Furthermore, a text can be assigned one or more
tagsets. The tagsets in turn can be open, such as
lemmatization tags, or closed, such as POS tags.
Each text can be assigned different tagsets.
Extensions In addition, the data model also al-
lows for the import of markup annotations with the
texts, which may denote layout-related or linguistic
peculiarities encoded by the transcriptors, as well
as information about its annotation status such as
progress, or dubious annotations. The model is
easily extendable for user management that can tie
in to the text table, e.g., a user can be set as owner
or creator of a text.
As XML serialization is not optimized for data
which is not strictly hierarchically structured, stor-
age and retrieval is rather inefficient, and extensions
are not easily possible. For this reason, we chose
to implement the application with an SQL database
<token>
<!-- diplomatic tokenization -->
<dipl trans="ober"/>
<dipl trans="czugemich"/>
<!-- modern tokenization -->
<mod trans="oberczuge">
<norm tag="?berzeuge"/>
<pos tag="VVIMP.Sg"/>
</mod>
<mod trans="mich">
<norm tag="mich"/>
<pos tag="PPER.1.Sg.
*
.Acc"/>
</mod>
</token>
Figure 3: Example serialization of ober czugemich
(modern ?berzeuge mich ?convince me?) in XML
serialization of the data model.
4 Conclusion
We described CorA, a web-based annotation tool.
Its main features are the integration of automatic
annotation software, the possibility of making edits
to the source document, and the conceptual dis-
tinction between diplomatic and modern tokens in
the data model. We believe that these features are
particularly useful for annotators of non-standard
language data such as historical texts, and set CorA
apart from other existing annotation tools.
We plan to make the tool available under an
open source license eventually. However, we are
currently still working on implementing additional
functionality. In future work, we plan to integrate
features to evaluate annotation quality, such as au-
tomatically calculating inter-annotator agreement.
89
References
Marcel Bollmann, Stefanie Dipper, Julia Krasselt, and
Florian Petran. 2012. Manual and semi-automatic
normalization of historical spelling ? case studies
from Early New High German. In Proceedings of
the First International Workshop on Language Tech-
nology for Historical Text(s) (LThist2012), Vienna,
Austria.
Marcel Bollmann. 2012. (Semi-)automatic normaliza-
tion of historical texts using distance measures and
the Norma tool. In Proceedings of the Second Work-
shop on Annotation of Corpora for Research in the
Humanities (ACRH-2), Lisbon, Portugal.
Sonja Bosch, Key-Sun Choi, ?ric de la Clergerie, Alex
Chengyu Fang, Gertrud Faa?, Kiyong Lee, Antonio
Pareja-Lora, Laurent Romary, Andreas Witt, Amir
Zeldes, and Florian Zipser. 2012. <tiger2/> as a
standardised serialisation for ISO 24615. In Pro-
ceedings of the 11th Workshop on Treebanks and
Linguistic Theory (TLT), Lisbon, Portugal.
Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,
Joseph Le Roux, Stephen Hogan, Joakim Nivre,
Deirdre Hogan, and Josef van Genabith. 2011.
#hardtoparse: POS tagging and parsing the twitter-
verse. In Proceedings of AAAI-11 Workshop on
Analysing Microtext, San Francisco, CA.
Eugenie Giesbrecht and Stefan Evert. 2009. Part-of-
speech tagging ? a solved task? An evaluation of
POS taggers for the German Web as Corpus. In
Proceedings of the 5th Web as Corpus Workshop
(WAC5), pages 27?35, San Sebastian, Spain.
Paul Rayson, Dawn Archer, Alistair Baron, Jonathan
Culpeper, and Nicholas Smith. 2007. Tagging the
Bard: Evaluating the accuracy of a modern POS tag-
ger on Early Modern English corpora. In Proceed-
ings of Corpus Linguistics 2007, University of Birm-
ingham, UK.
Marc Reznicek, Anke L?deling, and Hagen
Hirschmann. 2013. Competing target hypotheses
in the Falko Corpus: A flexible multi-layer corpus
architecture. In Ana D?az-Negrillo, Nicolas Ballier,
and Paul Thompson, editors, Automatic Treatment
and Analysis of Learner Corpus Data, pages
101?123. Amsterdam: Benjamins.
Silke Scheible, Richard J. Whitt, Martin Durrell, and
Paul Bennett. 2011. Evaluating an ?off-the-shelf?
POS-tagger on Early Modern German text. In Pro-
ceedings of the ACL-HLT 2011 Workshop on Lan-
guage Technology for Cultural Heritage, Social Sci-
ences, and Humanities (LaTeCH 2011), pages 19?
23, Portland, Oregon, USA.
Helmut Schmid and Florian Laws. 2008. Estimation of
conditional probabilities with decision trees and an
application to fine-grained POS tagging. In Proceed-
ings of COLING ?08, Manchester, Great Britain.
Amir Zeldes, Julia Ritz, Anke L?deling, and Christian
Chiarcos. 2009. ANNIS: a search tool for multi-
layer annotated corpora. In Proceedings of Corpus
Linguistics, Liverpool, UK.
90
