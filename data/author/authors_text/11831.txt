Proceedings of the Workshop on BioNLP: Shared Task, pages 107?110,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
A Multi-Phase Approach to Biomedical Event Extraction
Hyoung-Gyu Lee, Han-Cheol Cho, Min-Jeong Kim
Joo-Young Lee, Gumwon Hong, Hae-Chang Rim
Department of Computer and Radio Communications Engineering
Korea University
Seoul, South Korea
{hglee,hccho,mjkim,jylee,gwhong,rim}@nlp.korea.ac.kr
Abstract
In this paper, we propose a system for biomed-
ical event extraction using multi-phase ap-
proach. It consists of event trigger detector,
event type classifier, and relation recognizer
and event compositor. The system firstly iden-
tifies triggers in a given sentence. Then, it
classifies the triggers into one of nine pre-
defined classes. Lastly, the system examines
each trigger whether it has a relation with
participant candidates, and composites events
with the extracted relations. The official score
of the proposed system recorded 61.65 preci-
sion, 9.40 recall and 16.31 f-score in approxi-
mate span matching. However, we found that
the threshold tuning for the third phase had
negative effect. Without the threshold tuning,
the system showed 55.32 precision, 16.18 re-
call and 25.04 f-score.
1 Introduction
As the volume of biomedical literature grows expo-
nentially, new biomedical terms and their relations
are also generated. However, it is still not easy for
researchers to access necessary information quickly
since it is lost within large volumes of text. This is
the reason that the study of information extraction
is receiving the attention of biomedical and natural
language processing (NLP) researchers today.
In the shared task, the organizers provide partic-
ipants with raw biomedical text, tagged biomedical
terms (proteins), and the analyzed data with various
NLP techniques such as tokenization, POS-tagging,
phrase structure and dependency parsing and so on.
The expected results are the events, which exist in
the given text, consisting of a trigger and its partici-
pant(s) (Kim et al, 2009).
The proposed system consists of three phases;
event trigger detection phase(TD phase), event type
classification phase(TC phase), relation recognition
and event composition phase(RE phase). It works in
the following manner. Firstly, it identifies triggers of
a given biomedical sentence. Then, it classifies trig-
gers into nine pre-defined classes. Lastly, the sys-
tem finds the relations between triggers and partic-
ipant candidates by examining each trigger whether
it has relations with participant candidates, and com-
posites events with the extracted relations. In the
last phase, multiple relations of the same trigger
can be combined into an event for Binding event
type. In addition, multiple relations can be com-
bined and their participant types can be classified
into not only theme but also cause for three Regu-
lation event types.
In this paper, we mainly use dependency pars-
ing information of the analyzed data because sev-
eral previous studies for SRL have improved their
performance by using features extracted from this
information (Hacioglu, 2004; Tsai et al, 2006).
In the experimental results, the proposed system
showed 68.46 f-score in TD phase, 85.20 accuracy
in TC phase, 89.91 f-score in the initial step of RE
phase and 81.24 f-score in the iterative step of RE
phase, but officially achieved 61.65 precision, 9.40
recall and 16.31 f-score in approximate span match-
ing. These figures were the lowest among twenty-
four shared-task participants. However, we found
that the threshold tuning for RE phase had caused
a negative effect. It deteriorates the f-score of the
107
Event Trigger Detector
Event Type Classifier
Relation Recognizer &
Event Compositor
Initial Step
Iterative Step
Source Data
Analyzed Data
Result of Event Extraction
Figure 1: System Architecture
proposed system by enlarging the gap between pre-
cision and recall. With the default threshold, the sys-
tem showed better result in the final test data, 55.32
precision, 16.18 recall and 25.04 f-score with the
rank 17th among 24 teams.
2 System Description
Figure 1 shows our bio-event extraction system
which consists of Event Trigger Detector, Event
Type Classifier and Relation Recognizer & Event
Compositor. Each component includes single or
multiple Maximum Entropy models trained by gold
annotation data. The inputs of the system are source
data and analyzed data. The former is raw text with
entity annotation, and the latter is tokenized, POS
tagged and parsed data of the raw text.1
Because the event type is useful to recognize the
relation, we perform TC phase before RE phase.
One of important characteristics of bio-event is
that one event as well as a protein may participate
in another event. Considering this, we designed the
system in which the Relation Recognizer be per-
formed through two steps. In the initial step, the sys-
tems examines each trigger whether it has the rela-
tions with only proteins, and composites events with
recognized relations. In the iterative step, it repeat-
edly examines remained triggers in the same man-
1We used the GDep result provided by organizers of the
shared task as analyzed data.
ner. This step allows the system to extract chain-
style events, which means that one event participates
in another one and the other participates in the for-
mer.
To increase the f-score, we tuned a threshold for
RE phase which is a binary classification task; de-
ciding whether a given relation candidate is correct
one or not. When the output probability of a maxi-
mum entropy model is lower than the threshold, we
discard a relation candidate.
2.1 Event Trigger Detection
We assume that an event trigger is a single word.
In other words, we do not consider the multi-word
trigger detection. Because the trigger statistic in
the training data showed that about 93% of triggers
are single word, we concentrated on the single word
trigger detection.
This phase is simply defined as the task that clas-
sify whether each token is a trigger or not in a doc-
ument. It is necessary to select targets to classify
among all tokens, because a set of all tokens includes
too many negative examples. For this, the follow-
ing filtering rules are applied to each token. Though
these rules filtered out 69.5% of tokens, the trigger
recall was 94.8%.
? Filter out tokens whose POS tag is not matched
to anything among NN, NNS, VB, VBD, VBG,
VBN, VBP, VBZ, JJ and JJR.
? Filter out tokens that are a biomedical named
entity.
? Filter out sentences that do not have any pro-
teins.
Proposed features for the binary classification of
tokens include both features similar to those used in
(Hacioglu, 2004; Tsai et al, 2006; Ahn, 2006) and
novel ones. The selected feature set is showed in
Table 1.
2.2 Event Type Classification
In TC phase, tokens recognized as trigger are clas-
sified into nine pre-defined classes. Although more
than a dozen features had been tested, the features
except word and lemma features hardly contributed
to the performance improvement. The tuned feature
set is showed in Table 2.
108
Word level features
- Token word
- Token lemma
- Token POS
- POSs of previous two tokens
- Distance, word and POS of the nearest protein
- Positional independence: Whether a noun or a
verb is adjacent to the current token
Dependency level features
- Dependency label path of the nearest protein
- The existence of protein in family: This feature is
motivated by the study in (Hacioglu, 2004)
- A boolean feature which is true if token?s child is
a proposition and the chunk of the child include a
protein
- A boolean feature which is true if token?s child is
a protein and its dependency label is OBJ
Table 1: Features for event trigger detection
Features for the event type classification
- Trigger word
- Trigger lemma
- A boolean feature which is true if a protein exists
within left and right two words
Table 2: Features for event type classification
We found that TC phase showed relatively high
precision and recall with simple lexical features in
the experiment. However, it was quite difficult to
find additional features that could improve the per-
formance.
2.3 Relation Recognition and Event
Composition
In the last phase, the system examines each trigger
whether it has relations with participant candidates,
and composites events with the extracted relations.
(A relation consists of one trigger and one partici-
pant)
We devised a two-step process, consisting of ini-
tial and iterative steps, because a participant candi-
date can be a protein or an event. In the initial step,
the system finds relations between triggers and pro-
tein participant candidates. Features are explained
in Table 3. Then, it generates one event with one
relation for event types that have only one partici-
pant. For Binding event type, the system combines
at most three relations of the same trigger into one
Word level features
- Trigger word
- Trigger lemma
- Trigger type (I-1)
- Entity word
- Entity type (I-2)
- Word sequence between T&P (I-1)
- Word distance
- Existence of another trigger between T&P
- The number of triggers of above feature
- Existence of another participant candidate
- The number of participants of above feature
Dependency level features
- Trigger dependency label (I-1)
- Entity dependency label
- Lemma of trigger?s head word (I-1)
- POS of trigger?s head word
- Lemma of entity?s head word (I-1)
- POS of entity?s head word
- Lemma of trigger?s head word + Lemma of en-
tity?s head word
- Right lemma of trigger?s head word
- 2nd right lemma of trigger?s head word (I-1)
- Right lemma of entity?s head word
- 2nd right lemma of entity?s head word (I-1)
- Dependency path between T&P
- Dependency distance between T&P
- Direct descendant: a participant candidate is a di-
rect descendant of a given trigger
Table 3: Features for relation recognition between a trig-
ger and a participant (T&P)
event. For Regulation event types, we trained a bi-
nary classifier to classify participants of a Regulation
event into theme or cause. Features for participant
type classification is explained in Table 4. Among
multiple participants of a Regulation event, only two
participants having highest probabilities for theme
and cause constitute one event.
In the iterative step, the system finds relations be-
tween triggers and event participant candidates that
were extracted in the previous step, and generates
events in the same manner. The system performs it-
erative steps three times to find chain events.
Features are basically common in the initial (I-1)
step and the iterative (I-2) step, but some features
improve the performance only in one step. In order
to represent the difference in Table 3, we indicate (I-
1) when a feature is used in the initial step only, and
indicate (I-2) when it used in the iterative step only.
109
Word level features
- Trigger word
- Trigger lemma
- Participant words - event?s trigger words if a par-
ticipant is an event
- Left lemma of a participant
- Right lemma of a participant
- Trigger word + Participant words
- Trigger lemma + Participant lemmas
- Participant lemmas
- Right lemma of a trigger
- 2nd right lemma of a trigger
- Right lemma of a participant
- 2nd left lemma of a participant
Dependency level features
- Dependency path
- Dependency relation to trigger?s head
- Dependency relation to participant?s head
- POS pattern of common head chunk of a trigger
and a participant
- POS pattern of common head chunk of a trigger
and a participant + The presence of an object word
in dependency path
Table 4: Features of the participant type classifier for
Regulation events
3 Experimental Result
Table 5 shows the official results of the final test
data. After the feature selection, we have performed
the experiments with the development data to tune
the threshold to be used in RE phase. The work im-
proved the performance slightly. The new thresh-
old discovered by the work was 0.65 rather than
the default value, 0.5. However, we found that the
tuned threshold was over-fitted to development data.
When we tested without any threshold change, the
proposed system showed better f-score by reducing
the gap between precision and recall. Table 6 shows
the performance in this case.
Nevertheless, recall is still quite lower than preci-
sion in Table 6. The reason is that many triggers are
not detected in TD phase. The recall of the trigger
detector was 63% with the development data. An-
alyzing errors of TD phase, we found that the sys-
tem missed terms such as role, prevent while it easily
detected bio-terms such as phosphorylation, regula-
tion. It implies that the word feature causes not only
high precision but also low recall in TD phase.
Event equality recall precision f-score
Strict 8.99 58.97 15.60
Approximate Span 9.40 61.65 16.31
Table 5: The official results with threshold tuning
Event equality recall precision f-score
Strict 15.46 52.85 23.92
Approximate Span 16.18 55.32 25.04
Table 6: The results without threshold tuning
4 Conclusion
In this paper, we have presented a biomedical
event extraction system consisting of trigger detec-
tor, event type classifier and two-step participant rec-
ognizer. The system uses dependency parsing and
predicate argument information as main sources for
feature extraction.
For future work, we would like to increase the
performance of TD phase by adopting two-step
method similar to RE phase. We also will exploit
more analyzed data such as phrase structure parsing
information to improve the performance.
References
Kadri Hacioglu. 2004. Semantic Role Labeling Using
Dependency Trees. In Proceedings of COLING-2004,
Geneva, Switzerland.
Richard Tzong-Han Tsai, Wen-Chi Chou, Yu-Chun Lin,
Cheng-Lung Sung, Wei Ku, Ying-shan Su, Ting-Yi
Sung and Wen-Lian Hsu. 2006. BIOSMILE: Adapt-
ing Semantic Role Labeling for Biomedical Verbs: An
Exponential Model Coupled with Automatically Gen-
erated Template Features. In Proceedings of BioNLP-
2006.
Mihai Surdeanu, Sanda Harabagiu, John Williams and
Paul Aarseth. 2003. Using Predicate-Argument Struc-
tures for Information Extraction. In Proceedings of
ACL-2003, Sapporo, Japan.
David Ahn. 2006. The stages of event extraction. In Pro-
ceedings of Workshop On Annotating And Reasoning
About Time And Events.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on Event Extraction.
In Proceedings of Natural Language Processing in
Biomedicine (BioNLP) NAACL 2009 Workshop.
110
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 108?111,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
A Hybrid Approach to English-Korean Name Transliteration
Gumwon Hong?, Min-Jeong Kim?, Do-Gil Lee+ and Hae-Chang Rim?
?Department of Computer Science & Engineering, Korea University, Seoul 136-713, Korea
{gwhong,mjkim,rim}@nlp.korea.ac.kr
+Institute of Korean Culture, Korea University, Seoul 136-701, Korea
motdg@korea.ac.kr
Abstract
This paper presents a hybrid approach to
English-Korean name transliteration. The
base system is built on MOSES with en-
abled factored translation features. We
expand the base system by combining
with various transliteration methods in-
cluding a Web-based n-best re-ranking, a
dictionary-based method, and a rule-based
method. Our standard run and best non-
standard run achieve 45.1 and 78.5, re-
spectively, in top-1 accuracy. Experimen-
tal results show that expanding training
data size significantly contributes to the
performance. Also we discover that the
Web-based re-ranking method can be suc-
cessfully applied to the English-Korean
transliteration.
1 Introduction
Often, named entities such as person names or
place names from foreign origin do not appear in
the dictionary, and such out of vocabulary words
are a common source of errors in processing nat-
ural languages. For example, in statistical ma-
chine translation (SMT), if a new word occurs
in the input source sentence, the decoder will at
best drop the unknown word or directly copy the
source word to the target sentence. Transliteration,
a method of mapping phonemes or graphemes of
source language into those of target language, can
be used in this case in order to identify a possible
translation of the word.
The approaches to automatic transliteration be-
tween English and Korean can be performed
through the following ways: First, in learning how
to write the names of foreign origin, we can re-
fer to a transliteration standard which is estab-
lished by the government or some official linguis-
tic organizations. No matter where the standard
comes from, the basic principle of the standard
is based on the correct pronunciation of foreign
words. Second, since constructing such rules are
very costly in terms of time and money, we can
rely on a statistical method such as SMT. We be-
lieve that the rule-based method can guarantee to
increase accuracy for known cases, and the statis-
tical method can be robust to handle various ex-
ceptions.
In this paper, we present a variety of tech-
niques for English-Korean name transliteration.
First, we use a phrase-base SMT model with some
factored translation features for the transliteration
task. Second, we expand the base system by ap-
plying Web-based n-best re-ranking of the results.
Third, we apply a pronouncing dictionary-based
method to the base system which utilizes the pro-
nunciation symbols which is motivated by linguis-
tic knowledge. Finally, we introduce a phonics-
based method which is originally designed for
teaching speakers of English to read and write that
language.
2 Proposed Approach
In order to build our base system, we use MOSES
(Koehn et al, 2007), a well-known phrase-based
system designed for SMT. MOSES offers a con-
venient framework which can be directly applied
to machine transliteration experiments. In this
framework, the transliteration can be performed
in a very similar process of SMT task except the
following changes. First, the unit of translation
is changed from words to characters. Second, a
phrase in transliteration refers to any contiguous
block of character sequence which can be directly
matched from a source word to a target word.
Also, we do not have to worry about any distortion
parameters because decoding can be performed in
a totally monotonic way.
The process of the general transliteration ap-
proach begins by matching the unit of a source
108
LetterAlignment
Bilingual Corpus
Factored Phrase-based Training
Trained Model
EumjeolDecomposition MOSESDecoder
Input Word
EumjeolRe-composition
Target Word
EumjeolDecomposition
N-bestRe-ranking
Web
Dictionary
Phonics
Figure 1: System Architecture
word to the unit of a target word. The unit can be
based on graphemes or phonemes, depending on
language pairs or approaches. In English-Korean
transliteration, both grapheme-to-grapheme and
grapheme-to-phoneme approaches are possible. In
our method, we select grapheme-to-grapheme ap-
proach as a base system, and we apply grapheme-
to-phoneme functions in pronouncing dictionary-
based approach.
The transliteration between Korean and other
languages requires some special preprocessing
techniques. First of all, Korean alphabet is or-
ganized into syllabic blocks called Eumjeol. Ko-
rean transliteration standard allows each Eumjeol
to consist of either two or three of the 24 Korean
letters, with (1) leading 14 consonants, (2) inter-
mediate 10 vowels, and (3) optionally, trailing 7
consonants (out of the possible 14). Therefore,
Korean Eumjeol should be decomposed into letters
before performing training or decoding any input.
Consequently, after the letter-unit transliteration is
finished, all the letters should be re-composed to
form a correct sequence of Eumjeols.
Figure 1 shows the overall architecture of our
system. The alignment between English letter and
Korean letter is performed using GIZA++ (Och
and Ney, 2003). We use MOSES decoder in or-
der to search the best sequence of transliteration.
In this paper we focus on describing factored
phrase-based training and n-best re-ranking tech-
niques including a Web-based method, a pro-
nouncing dictionary-based method, and a phonics-
based method.
Figure 2: Alignment example between ?Knight?
and ?s?? [naiteu]?
2.1 Factored Phrase-based Training
Koehn and Hoang (2007) introduces an integration
of different information for phrase-based SMT
model. We report on experiments with three fac-
tors: surface form, positional information, and
the type of a letter. Surface form indicates a
letter itself. For positional information, we add
a BIO label to each input character in both the
source words and the target words. The intuition is
that certain character is differently pronounced de-
pending on its position in a word. For example, ?k?
in ?Knight? or ?h? in ?Sarah? are not pronounced.
The type of a letter is used to classify whether a
given letter is a vowel or a consonant. We assume
that a consonant in source word would more likely
be linked to a consonant in a target word. Figure 2
shows an example of alignment with factored fea-
tures.
2.2 Web-based Re-ranking
We re-ranked the top n results of the decoder by
referring to how many times both source word and
target word co-occur on the Web. In news articles
on the Web, a translation of a foreign name is of-
ten provided near the foreign name to describe its
pronunciation or description. To reflect this obser-
vation, we use Google?s proximity search by re-
stricting two terms should occur within four-word
distance. The frequency is adjusted as relative fre-
quency form by dividing each frequency by total
frequency of all n-best results.
Also, we linearly interpolate the n-best score
with the relative frequency of candidate output. To
make fair interpolation, we adjust both scores to be
between 0 and 1. Also, in this method, we decide
to remove all the candidates whose frequencies are
zero.
2.3 Pronouncing Dictionary-based Method
According to ?Oeraeeo pyogibeop1? (Korean or-
thography and writing method of borrowed for-
1http://www.korean.go.kr/08 new/data/rule03.jsp
109
Methods Acc.1 Mean F1 Mean Fdec MRR MAPref MAP10 MAPsys
BS 0.451 0.720 0.852 0.576 0.451 0.181 0.181
ER 0.740 0.868 0.930 0.806 0.740 0.243 0.243
WR 0.784 0.889 0.944 0.840 0.784 0.252 0.484
PD 0.781 0.885 0.941 0.839 0.781 0.252 0.460
PB 0.785 0.887 0.943 0.840 0.785 0.252 0.441
Table 1: Experimental Results (EnKo)
eign words), the primary principle of English-to-
Korean transliteration is to spell according to the
mapping table between the international phonetic
alphabets and the Korean alphabets. Therefore,
we can say that a pronouncing dictionary-based
method is very suitable for this principle.
We use the following two resources for build-
ing a pronouncing dictionary: one is an English-
Korean dictionary that contains 130,000 words.
The other is the CMU pronouncing dictionary2
created by Carnegie Mellon University that con-
tains over 125,000 words and their transcriptions.
Phonetic symbols for English words in the
dictionaries are transformed to their pronuncia-
tion information by using an internal code table.
The internal code table represents mappings from
each phonetic symbol to a single character within
ASCII code table. Our pronouncing dictionary in-
cludes a list of words and their pronunciation in-
formation.
For a given English word, if the word exists
in the pronouncing dictionary, then its pronunci-
ations are translated to Korean graphemes by a
mapping table and transformation rules, which are
defined by ?Oeraeeo pyogibeop?.
2.4 Phonics-based Method
Phonics is a pronunciation-based linguistic teach-
ing method, especially for children (Strickland,
1998). Originally, it was designed to connect the
sounds of spoken English with group of English
letters. In this research, we modify the phonics
in order to connect English sounds to Korean let-
ter because in Korean there is nearly a one-to-one
correspondence between sounds and the letter pat-
terns that represent them. For example, alpha-
bet ?b? can be pronounced to ??(bieup) in Ko-
rean. Consequently, we construct about 150 rules
which map English alphabet into one or more sev-
eral Korean graphemes, by referring to the phon-
ics. Though phonics cannot reveal all of the pro-
2http://www.speech.cs.cmu.edu/cgi-bin/cmudict
nunciation of English words, the conversion from
English alphabet into Korean letter is performed
simply and efficiently. We apply the phonics in
serial order from left to right of each input word.
If multiple rules are applicable, the most specific
rules are fist applied.
3 Experiments
3.1 Experimental Setup
We participate in both standard and non-standard
tracks for English-Korean name transliteration in
NEWS 2009 Machine Transliteration Shared Task
(Li et al, 2009). Experimenting on the develop-
ment data, we determine the best performing pa-
rameters for MOSES as follows.
? Maximum Phrase Length: 3
? Language Model N-gram Order: 3
? Language Model Smoothing: Kneser-Ney
? Phrase Alignment Heuristic: grow-diag-final
? Reordering: Monotone
? Maximum Distortion Length: 0
With above parameter setup, the results are pro-
duced from the following five different systems.
? Baseline System (BS): For the standard task,
we use only given official training data 3 to con-
struct translation model and language model for
our base system.
? Expanded Resource (ER): For all four non-
standard tasks, we use the examples of writing for-
eign names as additional training data. The ex-
amples are provided from the National Institute of
the Korean Language4. The data originally con-
sists of around 27,000 person names and around
7,000 place names including non-Ascii characters
for English side words as well as duplicate entries.
We preprocess the data in order to use 13,194 dis-
3Refer to Website http://www.cjk.org for more informa-
tion
4The resource is open to public. See
http://www.korean.go.kr/eng for more information.
110
tinct pairs of English names and Korean transliter-
ation.
? Web-based Re-ranking (WR): We re-rank the
result of ER by applying the method described in
section 2.2.
? Pronouncing Dictionary-based Method (PD):
The re-ranking of WR by combining with the
method described in section 2.3.
? Phonics-based Method (PB): The re-ranking
of WR by combining with the method described in
section 2.4.
The last two methods re-rank the WR method
by applying pronouncing dictionary-based method
and Phonics-based method. We restrict that
the pronouncing dictionary-based method and
Phonics-based method can produce only one out-
put, and use the outputs of the two methods to re-
rank (again) the result of Web-based re-ranking.
When re-ranking the results, we heuristically com-
bined the outputs of PD or PB with the n-best re-
sult of WR. If the outputs of the two methods exist
in the result of WR, we add some positive scores to
the original scores of WR. Otherwise, we inserted
the result into fixed position of the rank. The fixed
position of rank is empirically decided using de-
velopment set. We inserted the output of PD and
PB at second rank and at sixth rank, respectively.
3.2 Experimental Results
Table 1 shows our experimental results of the five
systems on the test data. We found that the use
of additional training data (ER) and web-based re-
ranking (WR) have a strong effect on translitera-
tion performance. However, the integration of the
PD or PB with WB proves not to significantly con-
tribute the performance. To find more elaborate
integration of those results will be one of our fu-
ture work.
The MAPsys value of the three re-ranking
methods WR, PD, and PB are relatively higher
than other methods because we filter out some
candidates in n-best by their Web frequencies. In
addition to the standard evaluation measures, we
include the Mean Fdec to measure the Levenshtein
distance between reference and the output of the
decoder (decomposed result).
4 Conclusions
In this paper, we proposed a hybrid approach to
English-Korean name transliteration. The system
is built on MOSES with factored translation fea-
tures. When evaluating the proposed methods,
we found that the use of additional training data
can significantly outperforms the baseline system.
Also, the experimental result of using three n-best
re-ranking techniques shows that the Web-based
re-ranking is proved to be a useful method. How-
ever, our two integration methods with dictionary-
based or rule-based method does not show the sig-
nificant gain over the Web-based re-ranking.
For future work, we plan to devise more elab-
orate way to integrate statistical method and dic-
tionary or rule-based method to further improve
the transliteration performance. Also, we will ap-
ply the proposed techniques to possible applica-
tions such as SMT or Cross Lingual Information
Retrieval.
References
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868?876,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In ACL 2007, Demo and Poster Sessions, June.
Haizhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009. Whitepaper of news 2009
machine transliteration shared task. In Proceed-
ings of ACL-IJCNLP 2009 Named Entities Work-
shop (NEWS 2009), Singapore.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29.
D.S. Strickland. 1998. Teaching phonics today: A
primer for educators. International Reading Asso-
ciation.
111
