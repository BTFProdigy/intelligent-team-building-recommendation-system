A State of the Art of Thai Language Resources
and
Thai Language Behavior Analysis and Modeling
Asanee Kawtrakul, Mukda  Suktarachan, Patcharee Varasai,
Hutchatai Chanlekha
Department of Computer Engineering,
Faculty of Engineering, Kasetsart University, Bangkok, Thailand 10900.
E-mail: ak, mukda, pom, aim@vivaldi.cpe.ku.ac.th,
Abstract
As electronic communications is now increasing, the term Natural Language Processing should be
considered in the broader aspect of Multi-Language processing system. Observation of the language
behavior will provide a good basis for design of computational language model and also creating cost-
effective solutions to the practical problems. In order to have a good language modeling, the language
resources are necessary for the language behavior analysis.
This paper intended to express what we have and what we have done by the desire to make a bridge
between the languages and to share and make maximal use of the existing lexica, corpus and the tools.
Three main topics are, then, focussed: A State of the Art of Thai language Resources, Thai language
behaviors and their computational models.
1. Introduction
As electronic communications are now
increasing, the term Natural Language Processing
should be considered in the broader aspect of
Multi- Language Processing system. An important
phase in the system development process is
requirement engineering, which can define as the
process of analyzing the problems in a certain
language. An essential part of the requirement-
engineering phase is computational language
modeling which is an abstract representation of
the behavior of the language.  In order to have a
good language model for creating cost-effective
solutions to the practical problems, the language
resources are necessary for the language behavior
analysis.
This paper intended to express what we
have and what we have done by the desire to
make a bridge between the languages and to
share and make maximal use of the existing
lexica, corpus and the tools. Three main topics
are, then, focussed:
? A State of the Art of Thai language
Resources that will give an overview of what we
have in Corpus, Lexicon and tools for corpus
processing and analysis.
? Thai language behaviors (only in word
and phrase level) analyzed from the varieties
of corpus which consist of Lexicon growth,
New word formation and Phrase/Sentence
construction, and
?  The computational models providing
for those behaviors, which consist of Unknown
Word Extraction and Name Entities identification,
New word generation and Noun phrase
recognition.
The remainder of the paper is organized as
follows. In section 2, we give the gateway of Thai
language resources.  Thai Language behaviors are
discussed in section 3. In section 4, then, provides
Thai Language Computational Modeling as a
basis for creating cost-effective solutions to those
practical problems.
2. A State of the Art of Thai Language
Resource
 This section gives a survey of a state of the
art of Thai Language Resources consisting of
Corpus, Lexicon and Tools. Here, we will present
only the resources that open for public access.
2.1 Corpus
The existing Thai corpus is divided into 2 
types; speech and text corpus developed by many 
Thai Universities. Thai Language Audio Resource 
Center of Thammasart University (ThaiARC) 
(http:// thaiarc.ac.th) developed speech corpus 
aimed to provide digitized audio information for 
dissemination via Internet. The project pioneers 
the production and collection of various types of 
audio information and various styles of Thai 
speech, such as royal speeches, academic lectures, 
oral literature, etc.
For Text corpus, originally, the goal of the 
corpus collecting is used only inside the 
laboratory.  Until 1996, National Electronics and 
Computer Technology Center (NECTEC) and 
Communications Research Laboratory (CRL) had 
a collaboration project with the purpose of 
preparing Thai language corpus from technical 
proceedings for language study and application 
research. It named ORCHID corpus (NECTEC, 
1997). NAiST Corpus began in 1996 with the 
primary aim of collecting document from 
magazines for training and testing program in 
Written Production Assistance (Asanee, 1995). 
The existing corpus can be summarized as shown 
in Table 1.
Table 1: The List of Thai Corpus
List Corpus Type Amount Status
NECTEC Orchid
Corpus
POS-
Tagged Text
2,560,000
words
Online
Kasetsart
Univ.
NAiST
Corpus Text
60,511,974
words Online
Thammasart
Univ.
Thai
ARC
Digitized
audio
4000
words++ online
2.2 Lexicon
There are a number of Thai lexicons, which
has been developed as shown in Table 2.
Table 2: The List of Thai Dictionaries
Dictionary Type Size
(word)
status Web site
Royal
Institute
Dictionary
Mono 33,582 Online http://rirs3.royin.
go.th/riThdict/loo
kup.html
Lexitron Bi 50,000 Online http://www.links.
nectec.or.th/lexit/
lex_t.html
NaiST
Lexibase
Mono 15,000 Online http://beethoven.
cpe.ku.ac.th/
So
Sethaputra
Dictionary
Bi - 48,000
Eng
words
- 38,000
Thai
words
Online http://www.thais
oftware.co.th/
Dictionary Type Size
(word)
status Web site
Narin?s
Thailand
homepage
Bi - Online http://www.wiwi.
uni-
frankfurt.de/~sas
cha/thailand/dicti
onary/dictionary
_index.html
Saikam
online
Bi 133,524 Online http://saikam.nii.
ac.jp/.
Lao-Thai-
English Dic.
Multi 5,000 Offline -
From the table 2, Only Lexitron (from
NECTEC) and NAiST Lexibase (from Kasetsart
University) that were applied to NLP. NAiST
Lexibase has been developed based on relational
model for managing and maintaining easily in the
future. It contains 15,000 words list with their
syntax and the semantic concept information in
the concept code.
2.3 Corpus and Language Analysis
Tools
Corpus is not only the resource of Linguistic 
Knowledge but is used for training, improving and 
evaluating the NLP systems. The tools for corpus 
manipulation and knowledge acquisition become 
necessary.
NAiST Lab. has developed the toolkit for 
sharing via the Internet. It has been designed for 
corpus collecting, annotating, maintaining and 
analyzing. Additionally, it has been designed as 
the engine, which the end user could use with their 
data. (See a service on http://naist.cpe.ku.ac.th).
3. Thai Language Behavior Analysis
In order to have a good language model for
creating cost-effective solutions to the practical
problems in application development, language
behavior must be observed. Next is Thai language
behavior analysis based on NAiST corpus
consisting of Lexicon growth, Thai word
formation and Phrase construction.
3.1 Lexicon Growth
The lexicon growth is studied by using Word 
list Extraction tool to extract word lists from a 
large-scale corpus and mapping to the Royal 
Institute Dictionary (RID). It is noticeable that 
there are two types of lexicon: common and 
unknown words. The common word lists are some 
words in RID, which occur in almost every 
document, and use in daily life. They are primitive 
c3c4c5
c1c2c3c4c5
c1c2
c4c5c1c2c3
words but not being proper names or colloquial 
words. The unknown or new words occur much in 
the real document such as Proper names, 
Colloquial words, Abbreviations, and Foreign 
words.
The lexicon growth is observed from corpus 
size, 400,000, 2,154,700 and 60,511,974 words 
from Newspaper, Magazine and Agriculture text. 
We found that common word lists increased from 
111,954 to 839,522 and 49,136,408 words 
according to the corpus size, while the unknown 
word lists increased from 288,046 to 1,315,178 
and 11,375,566 words respectively as shown in 
table3.
Table 3 : Lexicon-growth
Size of Corpus/ words Common words Unknown
words
400,000 111,954 288,046
2,154,700 839,522 1,315,178
60,511,974 49,136,408 11,375,566
Regarding to 60,511,974 words corpus in the 
table 3, it composes of 35,127,012 words from 
Newspaper, 18,359,724 words from Magazine and 
7,025,238 words from Agricultural Text. 
Unknown words occur in each category as shown 
in table 4.
Table 4: The Categories of Unknown words 
according to the various corpus genres
Types of
unknown word
Newspaper
(words)
Magazine
(words)
Agricultural
Text (words)
Proper name 4,809,160 1,272,747 1,170,076
Spoken words 58,335 8,787 0
Abbreviation 70,109 43,056 0
Foreign words 304,519 239,107 3,399,670
Total 5,242,123 1,563,697 4,569,746
According to table 3 and 4, we could observe that 
not only unknown words increase but common 
words also increase and the main categories of 
increasing unknown word are proper names and 
foreign words. Consequently, a computational 
model of unknown word extraction and name 
entity identification has been developed and also 
of new word construction.
3.2 New Word Formation and Core
Noun
Regarding to the growth of common word
shown in table 3, we studied how the new words
come from.
3.2.1 Basic Information about Thai
Thai words are multi-syllabic words which
stringing together could form a new word. Since
Thai has no inflection and no word delimiters,
Thai morphological processing is mainly to
recognize word boundaries instead of recognizing
a lexical form from a surface form as in English.
Let  C  be a sequence of characters
C  = c1c2c3?cn : n>=1
Let  W  be a sequence of words
W = w1w2w3?wm : m>=1
Where wi = c1ic2i?ci r: i>=1, r>=2
Since Thai sentences are formed with a
sequence of words with a stream of characters,
i.e., c1c2c3?cn mostly without explicit
delimiters, the word boundary in ?c1c2c3c4c5?
pattern as shown below could have two
ambiguous forms. One is ?c1c2? and  ?c3c4c5?.
The other one is  ?c1c2c3? and  ?c4c5?
(Kawtrakul, 1997)
Stream of characters
Figure 1: Word Boundary Ambiguity
F gure 1, i acters  grouped
differ meaning ords w hanged
too. For example, ????? n be gr  to ????-
??(fold one's arms across the chest)?
clump of flower)?. From our corp
that the sentence with 45 chara
combinations of words sequence.
3.2.2 New word construction
Almost all-Thai new words ar
means of compounding and nomi
using a set of prefixes.
3.2.2.1 Nominalization
Nominalization is a process by 
can be formed as a noun by using p
Noun words formed by using prefix
and ?????(khwa:m)?are nouns which 
action. Words formed by using pref
????(t?ha:w)?  and ????(nak)?are noun
human or profession.
Prefix ? ???(ka:n)? ? ????(khwa:m
the process of forming a noun fromill be c
oupedrom the fi
ently, the  of w
?? caweref char and ???-??? (a
us, we found
cters has 30
e formed by
nalization, by
which a word
refixes added.
es ????(ka:n)?
signal state or
ixes ????(phu:)?
s which signal
)?  are used in
 verb or verb
phrase and sometimes from noun
(Nominalization). ???(ka:n) that co-occur with
noun, represents the meaning about duty or
function of noun it relates to. ???(ka:n) that co-
occur with verbs, always occur with action verbs.
????(khwa:m) always co-occur with state verbs.
Prefix ? ???(phu:) ? ? ???(nak)? and ????(t?ha:w)?
are used in the process of new word formation. ???
(phu:)  and ???(nak) co-occur with verb phrase. ???
(nak) sometimes can occur with a few fields of
nouns, such as sport and music. So at the first time
we kept words, which constructed from prefix ????
(nak)? plus noun in the lexicon for solving the
problem. Prefix ????(t?ha:w)? can co-occur with
noun only.
3.2.2.2 Compounding
Thai new words can, also, be combined to
form compound nouns and are invented almost
daily. They normally have at least two parts. The
first part represents a pointed object or person
such as ??(man), ????(pot), ???(tail), ???(plant). The
second part identifies what kind of object or
person it is, or what its purpose is like ?????(drive a
car), ???????(cook rice), ????(tiger), ??? ?(water). Table 5
shows the examples of compound noun in Thai.
Table 5: The Examples of Thai Compound Noun
What or who What type / what purpose
??(man) ?????(drive a car),
????(pot) ???????(cook rice)
???(tail) ????(tiger)
???(plant) ??? ?(water)
Table 6 shows the patterns of compound noun.
Table 6: Compound noun pattern
Compound
noun
structure
Examples Meaning
n + n
???(tail)????(tiger)
???(plant)??? ?(water)
Rudder
Water Plant
n + v
????(room)???(sleep)
???????(chair)???(rock)
Bedroom
rocking chair
n + v + n
??(man)???(drive)?? (car)
????(pot)???(cook)????(rice)
Driver
A Pot For Cooking Rice
n + n + v
????(child)??(hair)???(long)
??(human)??(leg)???(lame)
A Long Hair Child
A Lame Man
n + n + n
????(home)???(shape)???
(Thai)
????(rice)??(leg)???(pig)
Thai Style House
A kind of dishes
n + v + v
??(leaf)???(drive)???(ride)
????(room)????(sit)????(play)
Driving License
Living Room
From Table 6, it has shown that some
compound nouns maintain some parts of those
primitive word meaning but some changed to a
new meaning. In this paper, we are only interested
in compound noun grouping from primitive words
which were changed the meaning to more abstract
but still maintain some parts of those primitive
word meanings, e.g. ?????(driver) ??????(cooker)
etc.? The word ???? maintains its meaning which
has a concept of human, but when it was
compounded with ???(car)? and ?????(kitchen)?,
their meanings have changed to the occupation by
the word relation in the equivalent level. In case of
compound noun that change a whole meaning
such as ???????? (a boy scout)?, it will be kept in the
lexicon.
3.2.2.3 Compound noun extraction problems
There are three non-trivial problems
? Compound Noun VS Sentence Distinction
? Compound Noun Boundary Ambiguity
? Core noun Detection
Compound Noun VS Sentence
Several NP structures have the same pattern as
sentences. Since Thai language is flexible and has
no word derivation, including to preposition in
compound noun can be omitted, etc. This causes a
compound noun having the same pattern as
sentence.  Thus, Thai NP analysis in IR system is
more difficult than English. (See Figure 2)
Figure 2: The comparison of noun phrase and
sentence structure
In figure 2, compound noun ????????????? (a
dining table) actually omit the preposition ??? ?????
(for)?, which is a relation that point to the purpose
of the first noun ?????(table)?.
The Compound Noun Boundary Ambiguity
After we have extracted noun phrase aiming
for enhancing the IR system, we have to segment
Sentence: ??????????   (birds eat fruit)
In Thai: ?? ??? ?????
 Birds eat fruit
Syntactic cn          tv cn
Category
Compound Noun: ??????????? (a dining table)
In Thai: ????(?? ?????) ??? ????
table  eat rice
Syntactic cn  tv cn
Category 
that noun phrase into sub noun phrase or
compound noun in order to specify the core noun
as index and its modifier as sub-index. For
example, compound noun with ?noun + noun +
verb? structure: ????(child/N)??(hair/N)??? (long/V)
etc. In this case, the second noun and verb have to
be grouped firstly since it behaves similarly to a
modifier by omitting the relative pronoun that
represents its purpose, i.e., ?who has?.
Another case of Compound Noun Boundary
Ambiguity is word combination. Consider the
sequence of words as the example of NP that
composes of four words as follows:
NP = N1N2N3N4
There are 8 word combinations of compound
noun as shown in figure 3.
In figure 3, word string has to be grouped
correctly for the correct meaning.
The ambiguity of noun phrase boundary has
also directly effected the efficiency of text
retrieval.
Core Noun detection
Due to the Information Retrieval, a head or
core of noun phrase detection is necessary. In this
paper, core noun refers to the most important and
specific word that the information retrieval and
extraction can directly retrieve or extract without
over generating candidate words.  However, by
the observation, the core of noun phrase needs not
to be the initial words. Some of them are at the
final position and some have word relation in the
equivalent level (As shown in Table 7).
Table 7: The examples of core noun in NP
Noun phrase(NP) Core noun
     W1              W2
????????? + ??????
structure   +  sentence
  W1       W2
???   +   ?? ??
stain        annual ring
W1        W2         W3
?? + ?????? + ???
fruit     papaya    green
be W1 located at the initial position
be W2 located at the final position
be W2 located at the second
position
As mentioned above, the models of New Word
Generation and Noun Phrase Recognition become
one of the interesting works in Thai processing.
3.3 Phrase and Sentence Construction
Next, we will indicate the main problems that 
influence to MT, IE and IR system. These are 
constituent movement, zero anaphora and iterative 
relative clause.
3.3.1 Constituent Movement
      Constituent is the relationship between lexicon 
units, which are parts of a larger unit. 
Constituency is usually shown by a tree diagram 
or by square brackets:
Ex.      [[???????????????????]  [????????????]]
         [[meeting committee] [very smoothly]].
Constituent acts as a chunk that can be moved 
together and it often occurs in Thai language (see 
Fig. 4). The constituents can be moved to the 
front, the middle or the end of the sentence.
S =
Figure 4 The movements of constituent
Ex.:      ???????  ????????  ???????  ?????
In the morning, the fisherman goes to catch the fish
????????  ???????  ?????  ???????
The fisherman goes to catch the fish in the morning.
????????  ???????  ???????  ?????
The fisherman goes to in the morning, catch the fish
???????  ?????  ????????  ???????
In the morning, catch the fish, the fisherman goes to.
Noun, adverb, and prepositional phrase are 
often move while verb phrases are.
3.3.2 Zero Anaphora
To make the cohesion in the discourse, the 
anaphora is used as a reference to ?point back? to 
some entities called referent or antecedent, given 
in the preceding discourse. Halliday, M.A.K. and 
Hasan, Rugaiya (1976) divided cohesion in 
English into 5 categories as shown in Table 8:
Table 8: Categories of anaphora
Reference - Personal Reference, Demonstrative 
Reference, Comparative Reference
Substitution - Nominal Substitution, Verbal Substitution, 
Causal Substitution
Ellipsis - Nominal Ellipsis, Verbal Ellipsis, Causal 
Ellipsis
Conjunction - Additive, Adversative, Casual, Temporal
Lexical Cohesion - Reiteration(Repetition, Synonym or Near 
Synonym, Super ordinate, General word)
- Collocation
Figure 3: Patterns of noun phrase analysis
C1 C2 C3 C4
Observing from the corpus in: news, magazine 
and agricultural text, there are 4 types of 
anaphora. Ellipsis or zero anaphora was found 
most frequently in Thai documents and other 
anaphora happened as show in table 9.
Table 9: Types of reference
Type of Anaphora Magazine news agriculture
Zero anaphora 49.88% 52.38% 50.04%
repetition 32.04% 27.78% 34.49%
personal reference 12.18% 12.70% 1.87%
nominal substitution 5.90% 6.08% 13.60%
Zero anaphora is the use of a gap, in a phrase 
or clause that has an anaphoric function similar to 
a pro-form. It is often described as ?referring 
back? to an expression that supplies the 
information necessary for interpreting the gap
The following is a sentence that illustrates 
zero anaphora:
????????????????????   ????????? ???????????????????
? There are two roads to eternity, straight 
but narrow, and broad but crooked.
In this sentence, the gaps in straight but 
narrow [gap], and broad but crooked [gap] have 
a zero anaphoric relationship to two roads to 
eternity.
Table 10 also shows the occurrence of zero 
anaphora in various parts of a sentence.
Table 10: Position of reference in sentences
Position Frequency
Subject 49.88%
Object 32.04%
Possessive Pronoun 12.18%
Following a Preposition 5.90%
It is noticeable that zero anaphora in the 
position of the subject occurs with high frequency 
(49.88%). It shows that in Thai language, the 
position of subject is the most commonly 
replaced.
3.3.3 Iterative Relative Clause
Thai relative pronouns ????? (thi) ?????(sung)? and ?
???(un)?  relate to group of nouns or other pronouns 
(The student  ????? (thi)  studies hardest usually does 
the best.). The word  ????? (thi) connects or relates 
the subject, student, to the verb within the 
dependent clause (studies). Generally, we use ?????
(thi)  and  ? ?????(sung)? to introduce clauses that are 
parenthetical in nature (i.e., that can be removed 
from the sentence without changing the essential 
meaning of the sentence. The pronoun ????? (thi) and ?????(sung)? refers to things and people and ????(un)?
usually refers to things, but it can also refer to 
event in general.
The relative pronoun is sometimes omitted 
because it makes the sentence more efficient and 
elegant.? ???????    ???/????    ???     ????????   ??? ????????  ?????????????? 2
???????
The book that you ordered from that shop arrived two days
later.
Sometimes relative pronoun refers to an event 
that takes place repeatedly in a phrase.
Figure 5 The structure of relative clause
Ex.    [???????]N  [(???) ??????????????? ??????]Rel Cl.
         [The chef] [who won the cooking competition]
[(????) ????????????????????????] Rel Cl.   [(???) ?????????] Rel Cl.
        [which compete at France]              [that I employ]
Although a sentence, which has several
clauses inside, will be grammatical, but it is not a
good style in writing and always causes a problem
for parser and noun phrase recognition.
4. The Computational Model
The computational models in word and phrase
level are developed according to the phenomena
mentioned in section 3.
4.1 Unknown Word Extraction
Unknown word extraction model composes of
2 sub-modules: unknown word recognition and
name entity identification.
4.1.1 Unknown word recognition
The hybrid model approach has been used for
unknown word recognition. The approach is the
combination of a statistical model and a set of
context based rules. A statistical model is used to
identify unknown word?s boundary. The set of
context based rules, then, will be used to extract
the unknown word?s semantic concept. If the
unknown word has no context, a set of unknown
word information, which has defined through
corpus analysis, will be generated and the best one
will be selected, as its semantic concept, by using
the semantic tagging model. Unknown word
recognition process is shown in figure 6.
N RELATIVECL.
RELATIVE
CL.
RELATIVE
CL.
Probabilistic
Semantic
Tagging
Model
w1 w2 UNK1 w3 UNK2
Extract and Record a
New word(or error)
STOP
? Lexi Base? Heuristic
Rule Base
Domain Specific
Dictionary
START
Unknown Word
Recognition Process
Guessing the
boundary of Unk
Generating information and
replace it to Unk
Computing probabilist
semantic chain
Figure 6: Unknown word recognition process
4.1.2 Name Entity Identification
After unknown words have been extracted,
Named Entity (NE) Identification will define the
category of unknown word. The model based on
heuristic rules and mutual information. Mutual
information or statistical analysis of word
collocation is used to solve boundary ambiguity
when names were composed with known and
unknown words. We use Knowledge based such
as list of known name (such as country names),
clue word list (such as person?s title) to support
the heuristic rules. Using clue word or common
noun that precedes the name can specify NE
categorization. Based on the case grammar, NE
categories can also defined. Moreover, the lists of
the names from predefined NE Ontology can be
used for predicting category too. The overview of
our system is shown in figure 7. More detail sees
(Chanlekha, H. et al 2002)
4.2 New Word Generation
Word formation is proposed to reduce the
lexicon size by constructing new words or
compound noun from the existing words. Based
on word formation rules and common dictionary,
the shallow parser will extract a set of candidate
compound nouns. Then probabilistic approach
based on syntactic structure and statistical data is
used to solve the problem of over- and under-
generation of new word construction and prune
the erroneous of compound noun from the
candidate set. The process of new word
construction is shown in figure 8. See more detail
in (Pengphon, N. et al 2002)
Figure 8 : New Word Construction process
4.3 Noun Phrase Recognition
Entities or concepts are usually described by
noun phrases. This indicates that text chunks like
noun phrases play an important role in human
language processing. In order to analyze NP, both
statistical and linguistic data are used. The model
of NP analysis system is shown in figure 9. More
detail sees (Pengphon, N. et al 2002)
Raw text
Morphological
Analysis
Word formation
Relation extraction
NP boundary
identification
NP segmentation
Knowledge Base? Dictionary? Prohibit pattern? Heuristic rule? Word formation rules? probabilistic? NP Rules? Ignore word lists? Clue word
Output
Figure 9 The architecture of system
Compound nouns
List of candidate
compound nouns
Parser
Syntactic Structure &
Statistical Analysis
- Word formation
rules
- Lexicon data
Figure 7 : Named Entity Recognition System
NE recognition
Word tokenization &
POS tagging
NE identification and
boundary detection
NE categorization
- NE lexicon
- Heuristic rules
Extracted NE matching
Figure 11: Noun phrase relation
Head modifier   ; f1 > f2, f3, f4
w1w2w3w4
 f1 f2 f3 f4
w1  w2w3w4
Compound        ; f1 = f2 = f3 = f4
   w1w2w3w4
The first step is morphological analysis for
word segmentation and POS tagging. At the
second step, the compound word is grouped into
one word by using word formation module (see
4.2). The third step, statistical-based technique is
used to identify phrase boundary. This step was
provided for identifying the phrase boundary by
using NP rules. Next step is Noun Phrase
Segmentation. The condition of noun phrase
segmentation is shown in figure 10.
After noun phrase is correctly detected, the
relation in noun phrases will be extracted. There
are 2 types of relation: head-head noun phrase and
head-modifier noun phrase. The process is based
on statistical techniques by considering the
frequency (fi) of each word (wi) in the document
(See figure 11).
5. Conclusion
The computational language models for
Thai in word and phrase level, consisting of
Unknown Word Extraction and Name Entities
identification, New word generation and Noun
phrase recognition, are studied on the basis of
their behavior analysis from the varieties of
corpus. We expected that it could create cost-
effective solutions to the practical problems in the
application developments especially in Thai
Information Retrieval and Information extraction
system. We also give the gateway to access Thai
language resources with hoping that it could be
the bridge of the international collaboration for
developing Multi-Language Processing
applications.
Acknowledgement
This project has been supported by NECTEC.
Reference
[1]  Bourigault, D.?Surface Grammatical Analysis
for the Extraction of Terminological Noun
Phrases?. Proc. COLING 1992, 1992.
[2]  Chen Kuang-hua and Chen Hsin-His,
?Extracting Noun Phrases from large-scale
Texts: A Hybrid Approach and Its Automatic
Evaluation?, Proc. of the 32nd ACL Annual
Meeting, 1994.
[3]   Chanlekha, H. et al ? Statistical and
Heuristic Rule Based Model for Thai Named
Entity Recognition?, Proc. of SNLP 2002,
2002.
[4]  G. Salton, ?Automatic Text Processing. The
Transformation, Analysis, and Retrieval of
Information by Computer?, Singapore:
Addison-Wesley Publishing Company, 1989.
[5]  Halliday,M.A.K and Hasan,Rugaiya.
?Cohesion in English?. Longman Group,
London, 1976.
[6]  Kawtrakul, A.et.al., ?Automatic Thai
Unknown Word Recognition?, Proc.of the
Natural Language Processing Pacific Rim
Symposium, Phuket,1997.
[7]  Kawtrakul, A.et.al.,?Backward Transliteration
for Thai Document Retrieval?, Proc.of
The1998 IEEE Asia-Pacific Conference on
Circuits and Systems, Chiangmai, 1998.
[8]  Kawtrakul, A. et.al., ?Toward Automatic
Multilevel Indexing for Thai Text retrieval
System?, In Proceedings of The 1998 IEEE
Asia-Pacific Conference on Circuits and
Systems, Chiangmai, 1998.
[9]  Kawtrakul, A.?A Lexibase Model for Writing
Production Assistant System? Proc.SNLP?95,
1995.
[10] Kawtrakul, A.?Anaphora Resolution Based
On Context Model Approach In Database-
Oriented Discourse?. A Doctoral Thesis to
The Department of Information Engineering,
School of Engineering, Nagoya University,
Japan, 1991.
[11]  Pengphon, N. et al ?Word Formation
Approach and Noun Phrase Analysis for
Thai? ?, Proc. of SNLP 2002, 2002.
[12]  Sornlertlamvanich, V. et.al., ?ORCHID:
THAI Part of Speech Tagged Corpus.
Technical Report of NECTEC, 1997.
[13] WEBSITE : http:// thaiarc.ku.ac.th
Figure 10 Noun phrase Segmentation
{w1,w2,R12}
w2 ? clue word set
R12 < threshold
; w2=start sub np
; w2= start sub np
else ; w1w2 is one unit
Plaesarn: Machine-Aided Translation Tool for English-to-Thai
Prachya Boonkwan and Asanee Kawtrakul
Specialty Research Unit of Natural Language Processing
and Intelligent Information System Technology
Department of Computer Engineering
Kasetsart University
Email: ak@vivaldi.cpe.ku.ac.th
Abstract
English-Thai MT systems are nowadays re-
stricted by incomplete vocabularies and trans-
lation knowledge. Users must consequently ac-
cept only one translation result that is some-
times semantically divergent or ungrammatical.
With the according reason, we propose novel
Internet-based translation assistant software in
order to facilitate document translation from
English to Thai. In this project, we utilize
the structural transfer model as the mechanism.
This project differs from current English-Thai
MT systems in the aspects that it empowers the
users to manually select the most appropriate
translation from every possibility and to manu-
ally train new translation rules to the system if
it is necessary. With the applied model, we over-
come four translation problems?lexicon rear-
rangement, structural ambiguity, phrase trans-
lation, and classifier generation. Finally, we
started the system evaluation with 322 ran-
domly selected sentences on the Future Mag-
azine bilingual corpus and the system yielded
59.87% and 83.08% translation accuracy for the
best case and the worse case based on 90.1%
average precision of the parser.
Introduction
Information comprehension of Thai people
should not be only limited in Thai; in con-
trast, it should also include a considerably large
amount of information sources from foreign
countries. Insufficient basic language knowl-
edge, a result of inadequate distribution in the
past, conversely, is the major obstruction for in-
formation comprehension. There are presently
several English-Thai MT systems?for instance,
Parsit (Sornlertlamvanich, 2000), Plae Thai,
and AgentDict. The first one applies seman-
tic transfer model via the methodology similar
to the lexical functional grammar (Kaplan et
al., 1989) and it is develop with the intention of
public use. The latter two implicitly apply the
direct transfer model with the purpose of com-
mercial use. Nonetheless, by limited vocabular-
ies and translation rules, the users must accept
the only one translation result that is occasion-
ally semantically divergent or ungrammatical.
Due to the according reason, we initiated
this project in order to relieve language prob-
lem of Thai people. In this project, we de-
velop a semi-automatic translation system to
assist them to translate English documents into
Thai. For this paper, the term semi-automatic
translation means the sentence translation with
user interaction to manually resolve structural
and semantic ambiguities during translation pe-
riod. Despite manual disambiguation, we pro-
vided a simple statistical disambiguation in or-
der to pre-select the most possible translation
for each source language sentence, though. The
automatic semantic disambiguation can be thus
excluded with this approach.
1 Translation Approaches
We can classify current translation approaches
into three major models as follows?structural
transfer, semantic transfer, and lexical transfer
(Trujillo, 1999).
? Structural transfer: this methodology
heavily depends on syntactic analysis (say,
grammar). Translation transfers the source
language structures into the target lan-
guage. This method is established by
the assumption that every language in the
world uses syntactic structure in order to
represent the meaning of sentences.
? Semantic transfer: this methodology
heavily depends on semantic analysis (say,
meaning). This model applies syntactic
analysis as well. On the contrary to the
structural transfer, a source language sen-
tence is not immediately translated into
the target language, but it is first trans-
lated into semantic representation (Inter-
lingua is mostly referred), and afterwards
into the target language. This method is
established by the assumption that every
language in the world describes the same
world; hence, there exists the semantic rep-
resentation for every language.
? Lexical transfer: this methodology heav-
ily depends on lexicon ordering patterns.
The translation occurs at the level of mor-
pheme. The translation process transfers
a set of morpheme in the source language
into that of the target language.
In this project, we decided to utilize the struc-
tural transfer approach, since it is more ap-
propriate for rapid development. In addition,
semantic representation that covers every lan-
guage is now still under research.
2 Relevant Problems and Their
Solutions
2.1 Structural Ambiguity
By the reason of the ambiguities of natural lan-
guages, a sentence may be translated or inter-
preted into many senses. An example of struc-
tural ambiguity is ?I saw a girl in the park with
a telescope.? This sentence can be grammati-
cally interpreted into four senses as follows.
? I saw a girl, to whom a telescope belonged,
who was in the park.
? I used a telescope to see a girl, who was in
the park.
? I was in the park and seeing a girl, to whom
a telescope belonged.
? I was in the park and using a telescope to
see a girl.
Furthermore, an example of word-sense am-
biguity is ?I live near the bank.? The noun bank
can be semantically interpreted into at least two
senses as follows.
? n. a financial institution that accepts de-
posits and channels the money into lending
activities
? n. sloping land (especially the slope beside
a body of water)
In order to resolve structural ambiguity, we
apply the concept of the statistical machine
translation approach (Brown et al, 1990). We
apply the Maximum-Entropy-Inspired Parser
(Charniak, 1999) (so-called Charniak Parser) to
analyze and determine the appropriate gram-
matical structure of an English sentence. From
(Charniak, 1999), Charniak presented that the
parser uses the Penn Tree Bank tag set (Marcus
et al, 1994) (or PTB in abbreviation) as a gram-
matical structure representation, and it yielded
90.1% average precision for sentences of length
40 or less, and 89.5% for sentences of length
100 and less. Moreover, with the intention to
resolve word-sense ambiguity, we embedded a
numerical statistic value with each translation
rule (including lexical transfer rule) with the
major aim of assisting to select the best transla-
tion parse tree from every possibility (Charniak,
1997). Section 3.4 will describe the method and
the tool to do so.
2.2 Phrase Translation
Phrase is a word-ordering pattern that cannot
be separately translated. An example is the
translation of the verb to be. The translation
of that depends on the context?for instance,
to be succeeding with noun phrase is trans-
lated to ???? /penm/, succeeding with preposi-
tional phrase to ???? /yuul/, in progressive tenses
to ????? /kammlangm/, in passive voice to ???
/thuukl/, and succeeding with adjectival phrase
to translation omission. Another example is the
verbal phrase to look for something. It must
be translated to ????? /m??ngmhaar/ not to
????????? /m??ngm samrrabl/. The word look
is translated to ??? /m??ngm/, and for to
?????? /samrrabl/.
From empirical observation, we found that
the PTB tag set is rather problematical to
translate into Thai. We hence implement the
parse tree modification process in order to re-
lieve the complexity of transformation process
(Trujillo, 1999). In this process, the heads of
the tree are recursively modified so as to facili-
tate phrase translation. A portion of parse tree
modification rules shown on Table 1 is described
in parenthesis format.
Obviously, from Table 1, we can more easily
compose the rules in Table 2 to translate the
verb to be and the phrasal verb look for some-
thing.
2.3 Lexicon Rearrangement
In English, we can normally modify a cer-
tain core noun with modifiers in two ways?
Table 1: Rules for the parse tree modification
process
Original PTB Modified
(VP (AUX (be)) (NP)) (VP (be) (NP))
(VP (AUX (be)) (PP)) (VP (be) (PP))
(VP (AUX (be)) (VP
(VBG) *))
(VP (be) (VBG) *)
(VP (AUX (be)) (VP (VBN)
*))
(VP (be) (VBN) *)
(VP (AUX (be)) (ADJP)) (VP (be) (ADJP))
(VP (VBP (look)) (PP (IN
(for)) (NP)))
(VP (look) (for) (NP))
Table 2: Rules to translate the verb to be and
the verbal phrase look for something
English Rules Thai Rules
VP ? be NP VP ? ???? NP
VP ? be PP VP ? ???? PP
VP ? be VBG VP ? ????? VBG
VP ? be VBN VP ? ??? VBN
VP ? be ADJP VP ? ADJP
VP ? look up NP VP ? ????? NP
putting them in front of or behind it. We
will focus the first case in this paper. The
problem occurs as soon as we would like to
translate a sequence of nouns and a sequence
of adjectives. The first case is translated
backwards, while the second forwards. An
example for this problem is that ?she is a
beautiful diligent slim laboratory member? is
translated to ??????????????????????????????/th??m
penm salmaamchikh thiif suayr khalyanr
ph??mr/. The word she is translated to ???,
is to ????, member to ??????, laboratory to ????,
beautiful to ???, diligent to ????, and slim to ???.
With the purpose to solve this problem, we
first group nouns and adjectives into groups?
NNS and ADJS?and we apply a number of
structural transfer rules. Table 3 shows a por-
tion of transfer rules.
Table 3: A portion of structural transfer rules
to solve the lexicon reordering
English Rules Thai Rules
NP ? ADJS NNS NP ? NNS ADJS
ADJS ? adj ADJS ? adj
ADJS ? adj ADJS ADJS ? adj ADJS
NNS ? nn NNS ? nn
NNS ? nn NNS NNS ? NNS nn
2.4 Classifier Generation
The vital linguistic divergence between English
and Thai is head-noun-corresponding classifiers
(Lamduan, 1983). In English, classifiers are
never used in order to identify the numeric num-
ber of a noun or definiteness. On the contrary,
classifiers are generally used in Thai?for ex-
ample, in English, a number precedes a noun
phrase; but in contrast, a classifier together with
the number succeeds in Thai.
In order to generate a classifier, we develop
the classifier matching algorithm. By empirical
observation, it is noticeable that the head noun
in the noun phrase always indicates the classi-
fier. For example, supposing the rules in Table 4
are amassed in the linguistic knowledge base.
Table 4: An example of rules for classifier gen-
eration
Head Noun Classifier
?? /rothh/ ??? /khanm/
???? /rothhfaim/ ???? /khalbuanm/
Thus, we can revise ????????????????
/rothhfaim h?l tiimlangmkaam/ 3 <cl>?
and ??????? /rothhyonm/ 4 <cl>? can be
respectively revised to ???????????????? 3 ?????
(three roller coasters) and ??????? 4 ???? (four
automobiles). If there is no rule that can match
the noun phrase, its head noun is used as the
classifier (Lamduan, 1983)?for example, ??????
Figure 1: System Overview
/praltheesf/ is a Thai word that there is, in
fact, no corresponding classifier. As soon as
we would like to specify, as the latter example,
the numeric number, we say ???????????????? 3
??????? /praltheesf phathhthahnaam l??wh/
(three developed countries).
3 System Overview
As illustrated in the Figure 1, the system com-
prises of four principle components?syntactic
analysis, structural transformation, sentence
generation, and linguistic knowledge acquisi-
tion.
3.1 Syntactic Analysis and Parse-Tree
Modification
In this process, we analyze each sentence of the
source documents with the Charniak Parser and
afterwards transform each of which into a parse
tree.
The first process that we have to accomplish
first is the sentence boundary identification. In
this step, we require users to manually pre-
pare sentence boundaries by inserting a new-line
character among sentences.
The next step is the sentence-parsing process.
We analyze the surface structure of a sentence
with the Charniak Parser. In this case, the orig-
inal Charniak Parser nevertheless spends long
time for self-initiation to load its considerably
huge database. Consequently, we patched it to
be a client-server program so as to eliminate
such time.
As stated earlier, in the view of the fact that
parse trees generated by the Charniak Parser
are quite complicated to translate into Thai, we
therefore implement the parse tree modification
process (see Section 2.2).
3.2 Structural Transformation
This process performs recursive transformation
from the source language parse trees into a set of
corresponding Thai translation parse trees with
their probabilities. As stated earlier, there are
some complexity in order to transfer a PTB-
formatted parse tree into Thai, we thus imple-
mented the parse tree modification process (see
Section 2.2) before performing transformation.
The transformation relies on the transformation
rules from the linguistic knowledge base.
A single step of transformation process
matches the root node and single-depth child
nodes with the transformation rules and after-
wards returns a set of transformation produc-
tions. As stated earlier, we embedded the prob-
ability of each rule. The probability of a parse
tree pi is given by the equation
P (pi) = ?(cpi, cpi1 , cpi2 , cpi3 , . . . , cpin)
n?
k=1
P (pik)
where pik is the k-th subtree of the parse tree pi
whose number of member subtrees is n, cpi rep-
resents the constituent of the tree pi, and ? is a
probability relation that maps the constituents
of the root and its single-depth children to the
probability value.
3.3 Sentence Generation
This process generates a target language sen-
tence from the parse tree. This stage also re-
lies on the linguistic knowledge base. The addi-
tional process is the noun classifier. We apply
the methodology defined in classifier matching
algorithm (see Section 2.4). Finally, the system
will show the translations of the most possibil-
ity and let the users change each solution if they
would like to do so.
3.4 Linguistic Knowledge Acquisition
We provided an advantageous tool so as to man-
ually train new translation knowledge. Cur-
rently, it comprises of the translation rule
learner and the English-Thai unknown word
aligner (Kampanya et al, 2002).
In this module, the translation rule learner
obtains document and analyzes that into a set
of parse trees. Afterwards, the users manually
teach it the rules to grammatically translate a
certain tree from the source language into the
target language with the rules following to the
Backus-Naur Form (Lewis and Paradimitriou,
1998) (or BNF in abbreviation). This module
will determine whether the rule is re-trained.
If so, the module will raise the probability of
that rule up. If not, it will add that rule to the
knowledge base.
Moreover, the aligner is utilized to automat-
ically update the bilingual dictionary. For our
future work, we intend to develop a system to
automatically learn new translation rules from
our corpora.
4 Evaluation
We established the system evaluation on the Fu-
ture Magazine bilingual corpus. We categorized
the evaluation into two environments?under
restricted knowledge base and under increasing
knowledge base. Each of which is also catego-
rized into two environments?with parsing er-
rors and without parsing errors.
In the evaluation, we randomly selected 322
sentences from the corpus. In order to have
a manageable task and facilitate performance
measurement, we classify translation result into
the following three categories?exact (the same
as in the corpus), moderate (understandable
result), and incomprehensible (obviously non-
understandable result). Table 5 shows the eval-
uation results.
In this evaluation, we consider the results in
the exact and moderate categories as reason-
Table 5: Evaluation Results (in percentages)
The column A represents evaluation with restricted knowl-
edge base and with parsing errors, B as with restricted knowl-
edge base but without parsing errors, C as with increasing
knowledge base but with parsing errors, and D as with in-
creasing knowledge base and without parsing errors.
Categories A B C D
Exact 3.97 4.41 4.97 5.52
Moderate 55.90 62.04 69.88 77.56
Incomprehensible 40.13 33.55 25.15 16.92
Accuracy 59.87 66.45 74.85 83.08
able translations. Moreover, we also consider
that the evaluation with restricted knowledge
base and with parsing errors is the worst case
performance, and the evaluation with increas-
ing knowledge base and without parsing errors
is the best case performance.
From the constraints we established, we found
that the system yielded the translation accuracy
for 59.87% for the worst case and 83.08% for the
best case.
5 Conclusions
In this paper, we propose novel Internet-based
translation assistant software in order to fa-
cilitate document translation from English to
Thai. We utilize the structural transfer model
as the translation mechanism. This project dif-
fers from the current MT systems in the point
that the users have a capability to manually se-
lect the most appropriate translation, and they
can, in addition, teach new translation knowl-
edge if it is necessary.
The four translation problems?Lexicon Re-
arrangement, Structural Ambiguity, Phrase
Translation, and Classifier Generation?are ac-
complished with various methodologies. To re-
solve the lexicon rearrangement problem, we
compose a number of structural transfer rules.
For the structural ambiguity, we apply the sta-
tistical method by embedding probability val-
ues to each transfer rules. In order to relieve the
complexity of the phrase translation, we develop
the parse tree modification process to modify
some tree structure so as to more easily compose
translation rules. Finally, with the purpose of
resolving the classifier generation problem, we
define the classifier matching algorithm which
matches the longest head noun to the appropri-
ate classifier.
In the evaluation, we established the sys-
tem experiment on the Future Magazine bilin-
gual corpus and we categorized the evaluation
into two environments?under restricted knowl-
edge base and under increasing knowledge base.
From the evaluation, the system yielded the
translation accuracy for 59.87% for the worst
case and 83.08% for the best case.
References
Peter F. Brown, John Cocke, Stephen Della
Pietra, Vincent J. Della Pietra, Frederick Je-
linek, John D. Lafferty, Robert L. Mercer,
and Paul S. Roossin. 1990. A statistical
approach to machine translation. Computa-
tional Linguistics, 16(2):79?85.
Eugene Charniak. 1997. Statistical parsing
with a context-free grammar and word statis-
tics. In AAAI/IAAI, pages 598?603.
Eugene Charniak. 1999. A maximum-entropy-
inspired parser. Technical Report CS-99-12,
Brown Laboratory for Natural Language Pro-
cessing.
Nithiwat Kampanya, Prachya Boonkwan, and
Asanee Kawtrakul. 2002. Bilingual unknown
word alignment tool for english-thai. In Pro-
ceedings of the SNLP-Oriental COCOSDA,
Specialty Research Unit of Natural Lan-
guage Processing and Intelligent Informa-
tion System Technology, Kasetsart Univer-
sity, Bangkok, Thailand.
Ronald M. Kaplan, Klaus Netter, Ju?rgen
Wedekind, and Annie Zaenen. 1989. Trans-
lation by structural correspondences. In Pro-
ceedings of the 4th. Annual Meeting of the
European Chapter of the Association for
Computational Linguistics, pages 272?281,
UMIST, Manchester, England.
Somchai Lamduan, 1983. Thai Grammar (in
Thai), chapter 4: Parts of Speech, pages 128?
131. Odeon Store Publisher.
Harry R. Lewis and Christos H. Paradimitriou,
1998. Elements of the Theory of Compu-
tation, chapter 3: Context-Free Grammar.
Prentice-Hall International Inc.
Mitchell P. Marcus, Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1994. Building
a large annotated corpus of english: The
penn treebank. Computational Linguistics,
19(2):313?330.
Virach Sornlertlamvanich. 2000. The state of
the art in thai language processing.
Arturo Trujillo, 1999. Translation Engines:
Techniques for Machine Translation, chapter
6: Transfer MT, pages 121?166. Springer-
Verlag (London Limited).
Proceedings of the Third ACL-SIGSEM Workshop on Prepositions, pages 51?56,
Trento, Italy, April 2006. c?2006 Association for Computational Linguistics
A Multilingual Analysis of the Notion of Instrumentality
Asanee Kawtrakul, Mukda Suktarachan (Kasetsart univ. Bangkok, Thailand),
Bali Ranaivo-Malancon, Pek Kuan Ng, (Univ. Sains Malaysia, Penang, Malaysia),
Achla Raina (IIT Kanpur, India),
Sudeshna Sarkar (IIT Kharagpur, India),
Alda Mari (Enst-Cnrs, Paris, France),
Sina Zarriess (Universita?t Potsdam, Germany),
Elixabete Murguia (Univ. Deusto, Bilbao, Spain),
Patrick Saint-Dizier (Irit-Cnrs, Toulouse, France)
Abstract
Instruments are expressed in language by
various means: prepositions, postposi-
tions, affixes including case marks, nonfi-
nite verbs, etc. We consider here 12 lan-
guages from five families in order to be
able to identify the different meaning com-
ponents that structure instrumentality.
1 Credits
This work has been made possible partly via the
STIC-Asia cooperation framework.
2 Introduction
It is difficult to give a comprehensive definition of
what instrumentality is. In WordNet it is defined
as ?an artifact, or a set of artifacts, that are instru-
mental (i.e. behave as instruments) in accomplish-
ing some end?, i.e. reaching a certain goal. In
this definition, the triple relation agent-instrument-
goal (as in: John cuts the bread with a knife, where
John is agent, knife is instrument that does the cut-
ting, and bread cut is the goal), is left vague in
what concerns the exact involvement of the agent
and the instrument in the action, and the control
the agent has on the instrument and on the action
(Mari and St-Dizier 01).
If almost anything can be an instrument, we can
nevertheless formulate a few criteria that we will
try to elaborate in this paper. First, an instrument
is basically non volitional. When humans play the
role of instruments, they are obviously volitional,
but the action is controlled by another agent who
acts as an ?initiator agent?, taking the initiative of
the action. Instruments cannot be easily associated
with traditional thematic roles, in fact this is not
of much interest, because this is too superficial a
notion and also because instruments are generally
modifiers, not arguments.
In this paper, we address instrumentality as con-
veyed by prepositions or equivalent means (e.g.
postpositions, affixes). Our aim in this study
is twofold: (1) to identify the conceptual facets
of instrumentality so that a conceptual seman-
tics can be defined in the spirit of (Talmy, 01,
03), (Wierzbicka 92, 96) and (2) to elaborate an
accurate enough model for answering questions
about instruments within a cooperative question-
answering system. Instead of focusing on a spe-
cific language to elaborate all possible forms of
instrumentality, we found it more adequate to de-
velop a multilingual approach, considering lan-
guages from various families.
We consider for Europe: German, Spanish,
French, Italian; for India: Kashmiri, Urdu, Hindi
and Bengali; for the far-east: Thai and Malay;
for Northern Africa and the Middle East: Ara-
bic, and Berber dialects (in the group of Amazigh
languages). In this paper, we use the first let-
ter of each language to identify it: Thai, Malay,
Hindi, Urdu, Kashmiri, Bengali, German, Span-
ish, French, Italian, Arabic, BeRber). We have
also more or less adequately transcribed characters
into latin characters. The upper case A is equiva-
lent to aa.
3 An overview of preposition structures
3.1 European languages
German, Spanish, Italian and French, like most
European languages have prepositions that in-
troduce instrumental PPs. The most current
prepositions are:
- German: mit, mit Hilfe von,
mittels, durch, anhand, kraft,
51
dank, per.
- French: avec, par, au moyen de,
gra?ce a`, a` l?aide de, a` travers.
- Spanish: con, en, por, a trave?s de,
mediante, por medio de, a base
de, con la ayuda de, gracias a.
- Italian: con, per mezzo di, tramite,
per, grazie a, con l?aiuto di.
3.2 Arabic and Berber
Arabic essentially has the preposition bi, used as
a prefix of the noun it heads:
Aktoub bi al kalami (I write with a pen).
bi can also be associated with a specific noun
or deverbal form (e.g. ?by applying?) to char-
acterize in more depth the instrumental relation.
This entails generic forms such as bi-tarika,
bi-istemali (by means of, the first form rein-
forces the importance of the instrument, while the
latter is more formal) and bi-fadli (thanks to).
For example, we have a kind of nominal form is-
tikhdam (= using or with the use of, constructed
from the root ?use?) in:
Fasser el massala bi istikhdam mithel (explain a
problem ?with the use of? example). Arabic makes
explicit the metonymy we have in European lan-
guages.
There are a few other prepositions such as min
khilal (through) and min a to express the du-
ality source + instrument of the argument (as in
drink with a bottle, litterally). In the spatial con-
text, au can be used (to reach the top by this trail),
and ala is used to express a channel of commu-
nication.
Berber is composed of a large number of di-
alects, some just spoken in small ?tribes?, others
in larger communities. It is basically dialectal, but
a number of common elements can be identified.
We consider here Berber from the Moroccan Rif,
and the Algerian Kabyle. The main instrumental
preposition is e`g, but prefixes are also used s-,
ge-, th-, kh- which affect the morphology
of the noun they are attached to. The prefix s-
is widely used, with some variants (si, sei,
so in Kabyle), e`g (also realized as g? or ge in
some places), is appropriate only when the action
is under full control of the agent. It is not em-
ployed when the instrument is abstract. In the Rif
area, s- focusses on the instrument contributing to
the action, it makes a kind of fusion between the
action verb and the instrumental noun. ge is only
used in spatial contexts involving means of trans-
portation (travelling by plane), kh is used only in
spatial contexts involving paths.
3.3 The Indic language family
The four languages considered, Kashmiri (Raina,
02), Urdu, Hindi and Bengali, share some simil-
itudes due to their common origins but also
contrasts that result from independent evolutions
which are useful to our analysis. They all have suf-
fixes and postpositions. Case suffixes (vibakhti)
are added to nouns or pronouns, but case suf-
fixes do not correspond strictly to thematic roles
(kAraka). Postpositions may also be used instead
of vibhaktis or in conjunction with them, as a kind
or re-inforcement. Basically, but with some nu-
ances, Hindi, Urdu, Bengali and Kashmiri lan-
guages have the following kernels:
? direct instrument: se (H/U), sity (K), -e/-te,
diye after null, dwArA after -r (B). Example:
H: raam ne chaabi se taala khola (ram - erg.
key with lock open-past= Ram openened the
lock with a key).
? means instrument: me (H/U), ke zariye (U),
manz (K), -e/-te (B). Example: U: raam
gaadi ke zariye daftar gayaa (ram car by
means of office go-past = Ram went to work
by car).
? causal instrument: ke kaaran (H), ki vajah se
(U), kiny (K), kArANe, kripAya (B). Exam-
ple: K: dil chi sayaahat kiny amir (Delhi be-
present tourism with rich = Delhi is rich with
tourism),
B: dillI paryatan-er khAtire samriddha or dillI
paryatan-er kripAya samriddha (Delhi be-
rich-er thanks to tourism)
? agentive instrument: ke dwaraa (H) ke zariye
(U) zariy, desi (K), diye (B) after -ke when
the nominal form is animate and specific,
diye after null when the nominal form is an-
imate and general (B). Example: H: raam ne
shyaam dwara apna kaam karvaaya (ram erg.
shyam by self?s work do-cause-past = Ram
got his work done by Shyam)
? action instrumentalised: kar (H/U), kerith
(K). Example: U: raam kuud kar ghar ke an-
dar daakhil huaa (ram jump participle house
52
into enter-past = Ram entered the house by
jumping in it)
There are less important cases that capture no-
tions like containment, which will be detailed in
section 5. Postpositions may vary also depending
on the semantic type of the NP they head.
In Bengali, case is indicated in several ways.
Vibhaktis are suffixes that are added to the stems
to form surface forms of words. In Bengali the
nominal stems take one of the following suffixes:
null or shunya vibhakti, -e, -te, -r, etc. Case is also
indicated in Bengali by the use of postpositions.
We have, for example: Cut bread with a knife, re-
alized as either:
1. chhuri diye ruti kATa (knife diye bread cut), or:
2. chhuri-te ruti kAta (knife-te bread cut)
Postpositions in Bengali are derived from certain
inflected forms of nouns, and also certain verbs
in participle form. When these words are used
as postpositions they are often not considered in
their original sense but define a specific type of re-
lationship of the noun phrase with the finite verb
phrase in the sentence. These words are appear
in a fixed form (indeclinables) as postpositions.
When a postposition is used to denote the case,
the nominal word preceding the postposition takes
on a vibhakti that is determined by the particu-
lar postposition. ?diye? is used after null vibhakti,
?dwArA? after -r vibhakti, etc.
3.4 Thai and Malay
Thai and Malay, although spoken in neighbour
countries, are substantially different.
Thai, from the Thai-Kadai family, has 6 prepo-
sitions (Silapasarn, 98) to denote instruments, the
most common being doi and duai which are
used for concrete instruments, means of trans-
portation, instruments close to manners, etc. kap
is used when the instrument is a part of the body,
while thang is used for means of transportation
only. tam characterizes control of the agent, and
chak is restricted to the instruments that convey
an idea of source. Examples:
khian - duai - din so (Write - with - pencil)
pai - pa ris - doi - khrueang bin (Go - Paris - by -
plane)
These semantic distinctions are, however, often vi-
olated in colloquial Thai.
Malay, from the Malayo-polynesian family, has
three ways to introduce instruments: preposition +
NP, affixes and compounding. Affixed words are
built from stems which are instrumental nouns,
this allows for the construction of the equivalent
of PPs, based on the prototypical use of the instru-
mental noun. The most common being: prefixes:
beR- (from kuda, horse, berkuda, on horseback),
meN- (from kunci, key, mengunci, lock with key),
prefix + suffix: meN- + -kan (from paku, nail,
memakukan, to fasten with nails), and with suffix
-i (from ubat, medicine, mengubati, by means of
medicine). Prepositions occur as the head of PPs,
and in verb particle constructions. PPs may also
be subject complements, avoiding the use of verbs
(dia di rumah, she at home). Besides affixes,
Malay has 6 prepositions that denote instrumen-
tality: dengan, melalui, mengikut,
menerusi, dengan menggunakan,
secara.
A simple example is:
berhubung - melalui - telefon (communicate - by -
telephone).
4 The meaning components of
instrumentality
Let us now consider the different meaning compo-
nents that emerge from our multilingual analysis.
The results presented below are still exploratory
due to the complexity of the notion. The distinc-
tions made (e.g. between concrete and abstract in-
struments) may seem arbitrary: they are just meant
to structure the presentation.
4.1 Concrete instruments
All languages studied have at least one basic in-
strumental mark operating over concrete objects
(T: duai, M: dengan, H: se, U: se, K: sity, B: diye,
-e, -te, G: mit, S: con, F: avec, A: bi, BR: e`g). Sev-
eral refinements are identified, for specific types of
NPs, or to denote a specific intention:
? the instrument is a recipient (S: en) or, more
generally, conveys an idea of container (e.g.
spoon) (B: -e kare), the idea behing is that
the container is used to carry the object along
a certain trajectory,
? the instrument is a part of the body (e.g.
hand): T: kap. In this case, the instrument
is not strictly artifactual.
? the goal is difficult to reach, it requires some
efforts from the agent (S: a base de),
53
? the focus can be emphasized by using ded-
icated marks (G: mit Hilfe (von), Mittels
(more fomal: Das Gericht hat mittels einst-
weiliger Verfu?gung den Drogenhandel unter-
sagt (the court has with provisional ordinance
the drug traffic prohibited))).
The second major difficulty is prototypicality
(Rosch, 78). When the instrument used is not very
prototypical of the action, several languages re-
inforce the instrumental prepositions to, sort of,
coerce the type of the noun so that it can become
an acceptable instrument. We have examples in S:
por medio de, B: sAhAjye, sahojoge,
I: per mezzo di, F: au moyen de, par
le biais de (biais= bias which directly ex-
presses this idea), as in:
F: Il a ouvert la porte au moyen d?un cric (he
opened the door by means of a jack).
At a conceptual level, it is quite difficult to
characterize what is a prototypical instrument
for a given action (characterized by subject-verb-
object: John opens the door). Each event has its
own prototypical instrument, making corpus stud-
ies extremely large, probably unfeasable. When
searching on the web, we find an incredible variety
of instruments to open a door, almost impossible
to classify. Next, prototypicality is not a boolean
notion: instruments are more or less prototypical.
Since the instrument is very much dependent on
the verb and on the object, we cannot foresee any
form of incorporation in the verb that would give
us indications. A direction could be to assume
Qualia structures (Pustejovsky 91) associated with
each potential instrument that describes the func-
tion of the object in the telic role. For example,
key(X) would have open(X, door), with door be-
ing quite generic. This approach could work via a
large lexical development for concrete nouns, it is
much more risky when terms are abstract.
4.2 Abstract instruments
Abstract instruments (theorems, regulations, ex-
amples, etc.) are realized identically to concrete
instruments, but with some typical marks such
as: T: tam, H: dwAra, K: zariyi, B: dwArA,
M. mengikut. At this stage, it is difficult to ex-
plain why marks are different from concrete in-
struments. An hypothesis could be that abstract in-
struments are closer to causes (see 5.5), or to more
formal situations for which specific terms were de-
veloped (e.g. for G: kraft).
There are additional marks dedicated to partic-
ular fields: B: sahajoge, and A: min khilal
when instruments are of type ?example? (explain
with an example). U: -ke zariye, S: por
medio de and G: Anhand, Kraft are more
formal, stronger for Kraft and apply particularly
to areas like juridical or psychological domains.
People and organizations can be seen as appro-
priate intermediaries for reaching a goal. They
may be conceived as metaphorical instruments.
Investigations show that people can get controlled
much in the same way as concrete objects:
F: Elle a informe? Paul de son de?part par Pauline
(She informed Paul of her leaving ?by? Pauline).
If we now consider: S: Juan env??o este paquete
por correo (John sent this parcel ?by? post)
Since post is the by-default medium to send pack-
ages, por is the only choice. Using more precise
services, like FedEx, is considered to be an alter-
native way, in that case F: par, avec S: por,
con are both acceptable.
4.3 Metaphorical instruments
Both concrete and abstract objects can be used
metaphorically as instruments. Examples abound
in the literature and on the Web. In 5.6 we ex-
amine the path metaphor which is very produc-
tive. Besides this case, we have a number of
metaphors, such as: write with your heart, fight
with your head, etc. These are not essentially dif-
ferent from metaphors observed in other situations
(Lakoff and Johnson 99).
4.4 The overlap instrument-manner
In a number of cases, it is not very easy to make
a distinction between instrument and manner. It
seems there is a continuum between these two no-
tions or even some form of overlap, where the ob-
ject is both an instrument and a manner at various
degrees, which may depend on context. A vari-
ety of marks contribute to characterize this over-
lap, manners at stake being quite diverse, but we
will not go into the study of manners. Specific
marks dealing with the manner/instrument am-
biguity are: T: doi, G: durch (which is also
used for metaphorical spatial uses), M: dengan
menggunakan, S: en, con, a as in S: es-
cribir en/con rojo (write in red),
T: khian - duai - muek - daeng (write - with - red -
ink)
BR: te`te s-e?fe`ssen (She-eats with-hands).
54
4.5 Causality
It is clear that, a priori, instruments can be viewed
at various degrees as causes of an event. There is
a kind of overlap between these two notions. In-
struments are not volitional, so they are under the
partial or full control of an agent (humans playing
the role of instruments are also controlled by an
agent). Typically I: a causa di, F: a cause
de, S: a causa de signal that the instrument
has brought about an event:
I : Il castello e distrutto a causa di un violento in-
cendio. (The castle has been destroyed ?because
of? a violent fire.)
Causality (e.g. Talmy, 01) being a complex no-
tion, it is not surprising that instruments, viewed
as intermediaries at various degrees, share some
features with causes. For example in cut the bread
with a knife, the cause of the bread being cut is
the action of the agent, but also the use of a pro-
totypical property of the knife: the knife does the
cutting. In (Talmy 01), the instrument is embed-
ded into the causing event:
(caused event) RESULTS FROM (causing event)
where the causing event has the structure:
Instrument ACTON object, where object is bound
or related in some way to the object in the caused
event.
As analyzed in (Mari and Saint-Dizier, 01), in-
strumentality is the convergence of several factors:
? the degree of involvement of the instrument
in the action, therefore, the fact that the in-
strument causes the action or is just a means
managed by the agent who is the main cause,
? the type of control the agent has on the instru-
ment for the action at stake, from full control
to lack of control,
? the control the agent has over the action as a
whole.
Indic languages and Thai are particular explicit on
these matters. They have specific marks for two
major cases:
1. agentive instrument, action not controlled by
the agent: H: ke dwAra, U: ke zariye
K: zariy, desi, T: doi,
2. causal instrument that does most of the ac-
tion, under the control of the agent: H ke
kAran, U: ki vajah se, K. kiny, T:
duai,
Berber allows e`g only when the agent controls the
instrument. The other cases are expressed by non
prepositional forms.
4.6 Instruments and paths
Another productive situation is the use of spatial
metaphors to express instrumentality. The use of
F: par and other marks (e.g. in B., U.), show
that there is a close link between instrumentality
and path descriptions (spatial as well as temporal
paths). This is a kind of metaphorical use of paths
viewed as instruments (as can be seen in (Lakoff
et al 99): ?action is motion, goals are paths, actors
are travellers?). Using an instrument parallels the
use of paths in the domain of space.
Marks denoting paths or sources are of much
interest. Some have really restricted uses, whereas
others are more flexible. We observe the following
main components:
? paths: T: tam, A: min khilal, S: por, a trave?s
de(por correo, by post), de, G: durch, F:
a` travers, note the distinctions, e.g. in M:
melalui (metaphorical paths: M : berhubung
melalui telefon (communicate by telephone)),
menerusi (channel of transmission), H, U:
me, se, T: thang. In B, -e and -te denote
paths where the agent that does the action has
no control, whereas diye and dhare involve at
least a partial control from the agent. In M,
metaphorical passages require melalui.
? sources: F: a`, A: min a, T: chak (for con-
crete and abstract sources). Example: A:
Achroubou mina Karoura (I am drinking with
bottle), which is also a kind of manner.
The duality path/instrument is particularly visi-
ble in, e.g.:
K: raam vot tshochi vati kiny gari (ram reach-past
short route via home = Ram reached home by the
short route).
Another interesting phenomenon occurs when
an argument is both an instrument and a path,
as in look at the moon in a telescope. Tele-
scope is indeed the instrument used and also
the path through which one looks, or which the
light traverses. This double facet of the argu-
ment is visible in surface realizations, where the
preposition used is ambiguous between instrument
(first preposition) and path (second one) readings:
G: mit, durch, S: con, por, M: dengan,
melalui, F: avec, dans. When one wants
55
to strongly stress the path interpretation, then a
more path-oriented preposition is used, e.g. S: a
trave`s de.
4.7 Means of transportation as instruments
Means of transportation (trains, spoons, boxes, en-
velopes, etc.), sometimes viewed as containers,
and mediums of transportation (by air) receive a
special treatment in a number of languages: T:
doi, thang, M: menerusi, melalui (for metaphorical
mediums and passages), H: me, U: ke zariye, K:
manz, zariy, B: kare, -e kare, -ya kare, A: ala, BR:
ge-, kh-, G: per, S: por, en, F: par. We have, for ex-
ample: U: raam gaadi ke zariye daftar gayaa (ram
car by means of office go-past = ram went to post
office by car)
T: pai - pa ris - doi - khrueang bin (Go to - Paris -
by - plane)
B: Nouko-ya kare phuketa jAo or Nouko-ya
phuketa jAo (boat-e kare phuket go or boat-e
phuket go = go by boat to Phuket)
A distinction is made between the medium and
the means as for: M: secara, which is used for
means of communication such as email or letters.
If the agent has effective control over the means,
then, for example, S uses con.
4.8 Language levels
Some marks are proper to formal discourse: G:
Mittels, Kraft, Anhand, H: dwAra.
4.9 Positive or negative orientation
The languages we studied also abound in positive-
oriented marks that express in a certain way the
idea of ?thanks to?: T: khop khun (+kah for fem-
inime and krup for masculine), H: ke kAran, U:
ki vajah, K: kiny, B: -er khAtire, (-er) kripAya, G:
dank, S: gracias a, F: gra?ce a`.
There are also several negative-oriented marks
such as the following prepositional compounds:
F: de la faute de, I: per colpa di, S:
por colpa de (by the fault of), where the term
?fault? conveys a negative orientation.
4.10 Metonymies
In most languages, the prototypical action denoted
by the instrument is implicit, it is analyzed as a
metonymy: object for action. Action is inferred
from the instrument and the verb in the given con-
text. In a number of situations, A and M need
to make explicit the action. For particular cases,
gerundive forms may be prefered to PPs (but not
to be confused with manners, e.g. ?by swim-
ming?), so that the verb that lexicalizes the action
is present.
For example, in M, ?by the trail? in to reach the
top of a mountain by the trail requires to make ex-
plicit how the trail is used: dengan mengikuti de-
nai itu (litt.: with follow trail DET (same cases
in Arabic and German)). Another case is: G:
Mit Flugzeugen la?sst sich Geld verdienen, (With
planes you can money earn), where a concrete ob-
ject replaces the whole procedure.
The metonymy could be reconstructed, for sim-
ple cases, by the Generative Lexicon (Pustejovsky
86), whose role is precisely to make explicit pro-
totypical functions of objects via their telic role, as
advocated above.
References
Dowty, D., 1989, On the Semantic Content of the No-
tion of Thematic Role, in G. Cherchia, B. Partee,
R. Turner (eds), Properties, Types and meaning,
Kluwer Academic.
Dowty, D., 1991, Thematic Proto-roles and Argument
Selection, Language, vol. 67-3.
Lakoff G., JohnsonM., 1999. Philosophy in the Flesh.
Basic books, NY, USA.
Mari, A., Saint-Dizier, P., 2001, A Conceptual Se-
mantics for Prepositions Denoting Instrumentality,
in proc. 1st workshop on prepositions, Toulouse, and
in Syntax and semantics of prepositions, P. Saint-
Dizier (ed), Kluwer academic, 2006.
Pustejovsky, J., 1991, The Generative Lexicon, Com-
putational Linguistics, vol. 17, MIT Press.
Raina, Achla M., 2002. The Verb Second Phe-
nomenon, O.N. Koul and K Wali (eds.), Topics in
Kashmiri Linguistics. Creative Books, New Delhi,
India.
Rosch, E., 1978. Principles of Categorization. In E.
Rosch and B.B. Lloyd (eds.), Cognition and Catego-
rization. Hillsdale : Lawrence Erlbaum Associates
Publishers.
Sinlapasarn, Upakitt. 1998. Thai Grammar. Thai
Watthana Panich, Bangkok, Thailand.
Talmy L., 2001, 2003. Towards a Cognitive Seman-
tics, vol. 1 and 2. MIT Press.
Wiezbicka, A.,1996. Semantics primes and universals.
Oxford: Oxford University Press.
Wierzbicka, A., 1992, Semantic Primitives and Se-
mantic Fields, in A. Lehrer and E.F. Kittay (eds.),
Frames, Fields and Contrasts. Hillsdale: Lawrence
Erlbaum Associates, pp. 208-227.
56
Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 3?10,
Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLP
The Development of a Question-Answering Services System for  
the Farmer through SMS: Query Analysis 
 
 
Mukda Suktarachan,  
Patthrawan Rattanamanee 
Department of Computer Engineer-
ing, Kasetsart University, Bangkok, 
Thailand, 10900 
naist_da_da@yahoo.com, 
tiptop317@hotmail.com 
Asanee Kawtrakul  
Department of Computer Engineering, Kasetsart 
University, Bangkok, Thailand, 10900 
National Electronics and Computer Technology 
Center, Thailand 
asanee_naist@yahoo.com 
asanee.kawtrakul@nectec.or.th 
 
  
Abstract 
 
In this paper, we propose the development of 
the Question-Answering Services System for 
the Farmer, through SMS, by focusing on 
query analysis and annotation based on a simi-
lar technique previously applied to language 
generation, thematic roles, and primitive sys-
tems of the Lexical Conceptual Structure 
(LCS).  The annotation places emphasis on the 
semantics model of ?What? and ?How? que-
ries, lexical inference identification, and se-
mantic role, for the answer. Finally, we show 
how these annotations and inference rules con-
tribute to the generalization of the matching 
system over semantic categories in order to 
have a large scale question-answering system. 
1    Challenges and Goals 
In the era of Information and Communications 
Technology (ICT), mobile is a fast and conven-
ient way to communicate over a network. 
Knowledge service via a mobile as ?a right in-
formation for a right man? is a challenging task. 
However, this means of interchange between 
persons has the limitation of personal timing. 
Therefore, Short Message Service (SMS) is a 
better way for giving knowledge service, espe-
cially automatic interchange of short text mes-
sages, by providing the information from an 
automatic Question & Answering System.  
From the results of the statistical ICT data 
survey concerning the number and percent of the 
population 6 years of age and over who use in-
formation and communication technology: 2003 
- 2007 by the National Statistical Office1, Thai-
land, it was found that  47.2% of people in the 
entire kingdom have owned their mobile(s). 
Consequently, communicating via SMS facili-
tates an effective knowledge service for support-
ing the farmers in problem-solving, decision 
making, and early warning, and also supports the 
government, or a related organization, in order to 
e-communicate to the farmer by changing the 
model of ?Training and Visit? to e-service and 
changing the collective to support cooperative 
problem solving. This kind of communication 
will provide the necessary long-term cost reduc-
tions to the agricultural economy in the areas of 
travel, visiting, productivity, etc.  
Nowadays, providing a knowledge service 
through SMS is not limited to only a Question-
Answering Services System, but also for such 
one-way services as early warning systems, for 
example, a Tsunami Alert System2, a FloodSMS 
? Early Detection and Warning of Catastrophic 
Flooding via SMS3, etc. 
The development of a Question-Answering 
Services System through SMS is not the design 
of a new technology. There have been several 
theories developed earlier, in the context of NLP 
or cognitive sciences, such as Natural Language 
Information Retrieval (NLIR), rule based Q&A, 
etc.  Nevertheless, some former theories of Q&A 
relied on complex semantic information. For in-
stance, a Wireless Natural Language Search En-
gine [6] was implemented using a system resid-
                                                          
1  http://web.nso.go.th/en/survey/keystat/keystat08.pdf 
2  http://www.wap.ait.ac.th/tsunami.html 
3  http://www.netsquared.org/projects/floodsms-
%E2%80%93-early-detection-and-warning-
catastrophic-flooding-sms 
3
ing on a server, which can translate questions or 
phrases into search engine queries or queries to 
SOAP Web services, where a gateway mediates 
between the mobile network and the Internet. 
Also, [15] developed the SMS for Question-
Answering in the m-Learning Scenario System 
by using the Simple Matching Algorithm to 
match the learners? answer messages with the 
original answer string, thus facilitating the learn-
ers to get the necessary feedback and assessment.  
In this paper, we propose the development of 
the Question-Answering Services System for the 
Farmer through SMS by focusing on query 
analysis and annotation, as well as on selected 
text matching utilizing lexical inference and se-
mantic roles. The annotation emphasizes the se-
mantics model of ?What? and ?How? queries. 
Finally, we show how these annotations and in-
ference rules contribute to the generalization of 
the matching system over semantic categories in 
order to have a large scale question-answering 
system.  
In the current stage, we have designed Q&A 
schema with thematic roles and have borrowed 
some primitive systems of the Lexical Concep-
tual Structure (LCS). Also, we are annotating 
1000 questions and text related to the query (but 
we randomly choose 100 pairs of Q&A for the 
experiment). In the same time, we are generaliz-
ing inference rules in order to match a question 
to its answer. This is particularly crucial when 
there is no straightforward response, e.g. when 
they require some form of lexical inference, 
elaboration, and reasoning or when the response 
is not a simple item, but a well-formed fragment 
of text, e.g. a chain of events leading to a conse-
quence, a procedure, etc.  
The project we present here emerged from a 
need of the real end-users, the Agricultural Land 
Reform Office, Ministry of Agriculture and Co-
operative, Thailand, in the project of ALRO Cy-
berBrain [3], which is a social network frame-
work that combines approaches based on knowl-
edge science and engineering with language en-
gineering, consisting of an ontology-based search 
engine, information extraction for Q&A system, 
knowledge aggregation through a knowledge 
portal and visualized in a browser with semantic 
links between problems, methods of problems 
solving and man who is the problem solver 
(PMM map Model) [1]. The main goal is to de-
velop tools for e-Farming, in particular rice farm-
ing, so that farmers can easily get information on 
farming rice and rice diseases. Now, it has been 
extended to provide question-answering services 
for the farmers through SMS [2].  
2    Problem Statements 
There are two main problems in Q&A analy-
sis: semantic interpretation for a question word 
and answer identification. 
2.1    Question?s Semantic Roles 
2.1.1    Question Word Interpretation.  
In general, when we query for the answer by a 
traditional search engine system, we might get 
many answers at different levels, depending on 
the role of the question: Definition vs Fact or set 
of Facts.  For example, with the question  
Q1: ????|????|???|????? 
     Rice| Blast| is| what 
    ?What is a Rice Blast??  
The answer can be returned as the definitions, 
fact or a set of facts, which are: 
A1.1: Blast, also called rotten neck, is one of the 
most destructive diseases of Missouri rice. 
Blast does not develop every year but is 
very destructive when it occurs.4   
A1.2:   Disease of Leave Burnt caused by Pyricu-
laria Oryzae can destroy all rice growing 
period  from start until harvest period.5 
The answer can be returned as the characteris-
tics detail or set of facts, such as the following: 
A1.3 : Blast symptoms can occur on leaves, 
leaf collars, nodes and panicles. Leaf spots are 
typically diamond shaped, with gray- white cen-
ters and brown to red-brown margins. Fully de-
veloped leaf lesions are approximately 0.4 to 0.7 
inch long and 0.1 to 0.2 inch wide. Both the 
shape and color vary depending on the environ-
ment, age of the lesion and rice variety.6  
2.1.2    Variety of Question Forms.  
In natural language, the question can be asked 
with different words and styles, for example:  
Q2.1:??????|????????|???|???|????|????|??????? 
situation| outbreak| of| disease| Rice Blast| 
is| how  
?What is the situation of Rice Blast?? 
Q2.2:????????|???|???|????|??|??????|??????? 
outbreak| of| disease| Rice Blast| is| characteristic| how 
     ?How does the rice blast outbreak look like?? 
                                                          
4  http://aes.missouri.edu/delta/muguide/mp645.stm  
5  http://www.sotus.co.th/article_4.html 
6  http://aes.missouri.edu/delta/muguide/mp645.stm 
 
4
Q2.3:???|????|?????|???|??????? 
Rice Blast| disperse| able| how 
?How can the rice blast disperse?? 
The reply can be returned the same answers 
with a descriptive set of events, as the following: 
A2.1: To prevent the Rice Blast: for the places 
that we often found the disease, use the dis-
ease-resistant rice variety. Don't sow the 
rice seed too densely. Don't use to much Ni-
trogen. If it is severe outbreak and it is the 
state of young plant, plow and sow again. If 
it was the epidemic state, use Fungus-
Removal chemical as Carbendasim. 
A2.2: Brown spot may be reduced by balanced 
fertilization, crop rotation, and the use of 
high quality planting seed. Seed treatment 
fungicides reduce the incidence and severity 
of seedling blight caused by this fungus. 
The examples above show that using different 
verbs or noun phrases can be represent the same 
meaning. Moreover, there is non-correspondent 
focus word between Q and A. 
2.2    Answer Type Identification 
2.2.1    Ambiguity between subtopic and an-
swer form 
To identify the answer, sometimes there is an 
ambiguity that verb phrases occurring after the 
focus word of the question can be both subtopics 
and the answer, like a procedural answer, for 
example,: 
Q3: ???????|???????|???|????|???|???|??????? 
 method| control| Rice Blast| to do| how 
 ?What method can be used to control Rice 
Blast??  
A3:  ???????|???????|???|????|??|?????? 
 method| control| Rice Blast| have| such as 
?Methods for preventing the Rice Blast are:? 
? ???|???????|???|??????? 
 use| Chemical Substance | that| appropriate 
?Use appropriate Chemical Substance.? 
? ???|??????|???|??????? 
 use| type of rice | that| appropriate 
?Use appropriate type of rice.? 
? ???|????|??|???|??????? 
 use| mechanism| in| prevent 
?Use mechanism to prevent.? 
? ???|???????|??????? 
 use| methods| hybrid 
?Use hybrid  methods.? 
The examples above convey the 4 types of 
method for Rice Blast control or names of meth-
ods, but it is not the process or the answers that 
represent how to control the disease. 
2.2.2    Non-correspondence between Q & A: 
Sometimes, the question and answer were not 
matched because the clue words or focus words 
in the question have never appeared in the an-
swers. This makes the question not correspond to 
the answer and also causes difficulty in finding 
the expected answer. For example, 
Q4: ??????|??????|????|?????|????|????????|???|??????? 
can| control| pests | rice | these | How  
?How can these rice pests be controlled??  
A4: ????|?????|????????|??????|??????|???|???|???|???????|????|
??????|???|???| |???| |????|????|??????|???????|???|,| |????|
????|???|??????|, |??????|?????|????|??|?? |???|???|???|???|
???|???|????|???|???|???|????|???|?????|?????||???|???| 
?These pests can be managed through inte-
grated approach including sowing insect re-
sistant rice varieties, sowing rice crop at rec-
ommended time, proper water management 
conservation and augmentation of bio-control 
predators.? 
From the example, the focus word of the 
question is ?control,? but there is no word ?con-
trol? in the answer. For this kind of Q&A match-
ing solution, WordNet and ontology are neces-
sary. 
3    Outline of the Project and Methodol-
ogy  
The needs of the Thai Ministry of Agriculture 
have been specified in a simple way via a corpus 
composed of (1) questions raised in real life by 
farmers (about 1000 questions), (2) the responses 
which have been provided by experts, based on 
existing documents (possibly several responses 
per question) and, quite often, (3) the texts they 
originate from. In general, the response is found 
in a unique text: there are no multiple answers, 
since most texts are not redundant, although 
some responses, in particular complex (e.g. 
evaluative questions) or indirect ones, may in-
volve the taking into account of several inde-
pendent texts. We will not address here the prob-
lem of message length reduction so that it fits 
into an SMS format (although this is also an im-
portant semantic problem). 
The system overview is shown in Figure 2. 
 
 
5
 
Figure 2. System Architecture 
To develop a Thai QA system, the preprocess-
ing of Thai morphology and syntax is necessary. 
The NAIST lab at the University of Kasetsart has 
basic tools to manage morphological analysis, 
parts-of-speech recognition, simple syntactic 
analysis, as well as Thai parsing, and an Element 
Discourse Unit System (EDU). These tools were 
designed as basic tools in natural language proc-
essing applications. (accessible on 
http://vivaldi.cpe.ku.ac.th:9292/ with a recom-
mendation to use the Mozilla Firefox browser) 
A few examples of question-answer pairs are: 
Q5:  ???????|???????|??????|????|??????|???|???|??????? 
?How to prevent the Weedy rice? 
A5.1: ???|????|????|????|???|??? 
?Skip some seasons when growing rice,? 
A5.2: ????|???|???|?????|???? 
?Grow hydrotonics plants.? 
Q6:  ???|??|???|?????|???|??|???????|??????|??????? 
?How to control the Bacterial Leaf 
Streak  Disease? 
A6: ???|???|???|????|????????|???|??????| 
  ?Do not put too much Nitrogen.? 
Q7:  ???|??|??????|??|?????| |??????|??????|????|???|
???|????|????|?? 
?How to eradicate the rice thrips? 
A7:  ???|???|????|?????????|????|?????????|???|???????|  |
???|????|???|???|????|???| |?| |???|??? 
?Spray with Malathion or Carbaryl 
every week, add fertilizer and water 
every two days.? 
Questions are essentially factoid questions 
(e.g. best periods for rice planting, rice varieties 
suggestion, symptoms of a disease), why ques-
tions, where responses are chains of events (rea-
sons for something to happen) and a large num-
ber of procedural questions [4], in particular for 
treating diseases. There are relatively few com-
parative or evaluative questions besides general 
questions, such as: What are the major rice 
pests? 
In most cases, questions do not have responses 
which can be immediately found in the texts by 
standard term matching techniques. For example: 
?How does the Sheath Blight affect the rice 
growth?? has the following response in a text: 
Plants heavily infected at these stages produce 
poorly filled grain, particularly in the lower por-
tion of the panicle. Additional losses result from 
... Therefore, some lexical semantics devices 
(e.g. a semantic link between affect and infect) or 
more elaborated reasoning schemas, based on 
domain knowledge, are needed to allow appro-
priate question-text matching [11, 7]. The kind of 
domain knowledge at stake may be quite unex-
pected (i.e., not the main topics that everyone 
knows, but more subtle pieces of information, as 
will be seen in 4.3). This is the major challenge 
of this work, which we try to resolve via a full 
annotation of the matching process, from ques-
tion parsing to response production, identifying 
matching and reasoning aspects. 
Complex questions may, e.g., require the 
elaboration of a diagnosis from premises given in 
the question before finding the response, either 
factoid or procedural (My rice has weedy leaves 
and some yellow spots, what should I do?). This 
question requires one to select all texts where 
such a symptom is identified, and then, e.g., to 
enter into a dialogue with the user if there are 
several possible diagnoses, leading to different 
treatments. 
The second aspect of this problem is to be able 
to extract the complete text portion that responds 
to the question. For that purpose we are develop-
ing an annotation methodology whose goal is to 
identify the different processes at stake and the 
needed resources. This method allows us to iden-
tify relevant text portions and then to delimit 
them appropriately. 
4    The Question-Answering Process An-
notation 
Since the task is quite large (a large group of stu-
dents are annotating a set of 600 questions and 
related texts), we need to establish norms and 
annotation guidelines. Using the research con-
ducted at IRIT on annotating procedural ques-
tions and instructions based on semantic roles 
    Question  
Question Analysis 
and Annotation
WordNet 
Ontology 
Q&A Matching and 
Answer Generation
Preprocessing Process 
Word Segmentation
POS Tagging
Name Entities Recognition
EDU Segmentation
Text Analysis and Annotation
Document Indexing 
Titles Recognition 
Text Annotation 
6
(TextCoop project) and a few rhetorical relations 
(e.g. elaboration, example, explanation), we first 
annotated the questions and their corresponding 
responses in texts provided by the Thai Ministry 
of Agriculture. One of the challenges was to 
identify relevant linguistic marks or patterns [9, 
10, 14]. 
There are many attempts to annotate argu-
ments by means of primitives; our approach, 
here, is oriented towards the precise task at stake 
and the specific actions. Therefore roles are not 
as standard as they are in general. An earlier at-
tempt with a similar technique applied to lan-
guage generation was carried out in, e.g., [10, 7]. 
Semantic tags are either close to thematic roles 
(instrument, location, etc.) [8], or borrowed from 
the primitive systems of the Lexical Conceptual 
Structure (LCS) [13], in particular, to establish 
useful links between arguments or between a 
large variety of constituents, which thematic 
roles cannot do. For example, in the first Thai 
university we have a link between 'first' and 'Thai 
university' which is either loctemp or loc+char+ident, 
depending on the interpretation of first (oldest or 
the best). However, in a majority of cases, se-
mantic roles based on thematic roles have a suf-
ficient granularity, and these are the ones which 
are used in the examples in 4.1. 
The main roles we consider are: agents (for 
humans and animals like insects, and metaphori-
cally for diseases and natural forces), themes 
(undergoing actions, basically plants and soils, 
and artificial products), location (spatial), time 
(covering dates and also periods), instruments 
(from tools to chemical products), manners, 
means, conditions (under which to realize an ac-
tion, or related to observation e.g. of a disease), 
cause, goals, and results. 
Besides, the tags <action>?</action> or 
<fact>?</fact> were considered to tag the verb 
with it?s arguments or adjuncts. 
In the remainder of this section we briefly re-
port the different steps of the process as they 
stand at the moment, i.e. almost at the end of the 
experimental stage, before automating knowl-
edge acquisition, and implementing the applica-
tion. 
4.1    Dealing with Questions 
As in most systems dealing with complex types 
of questions, questions are represented by a tri-
ple: the question type (which can be in our case 
polymorphic), the question focus (usually an NP 
or a VP in case events or procedures are induced) 
and the question body, annotated by means of 
semantic roles, as indicated above. 
The main types of questions we have identi-
fied from our corpus are the following; they are 
quite different from standard classifications, but 
they correspond to more operational views: 
F: fact, with subtypes: temp (temporal, time, 
date), loc (location) or product, 
E: an event (with a subtype event: cause)  
SF: set of facts  
SE: set of events (not related, and without any 
form of sequence: different from SqE be-
low)  
PROC: procedure, more or less complex, it 
may be just a single instruction; it can also 
describe the use of an instrument.  
SqE: sequence of events, which follow each 
other.  
EVAL: evaluation, making value decisions 
about issues or resolving controversies or 
differences of opinion.  
DEF: definition, the description of object.  
Some questions may bear several non-
conflicting types, in particular when the nature of 
the response is not straightforward to determine 
from the question. For example, ?What is the 
symptom of Bakanae?? would get the types SF 
and SE. 
An annotated question is, for example: 
 
As can be noted, the response is the set of 
those facts that contribute, together or independ-
ently, to the spreading of the disease. 
By the observation from 100 random inter-
rogative sentences corpus analysis, we found that 
the semantic types of questions correspondent to 
the question words are the following 
Q-Types What When Where Why Who Which How 
F 11 6 1   1 9 2 
E       1     6 
SF 3         15 3 
SE 7         2 5 
PROC             15 
SqE             7 
EVAL 2       1     
DEF 3             
Table 1 the correspondence between questions 
and semantic types of questions 
From Table 1, it is clear that ?what? and 
?how? questions vary in types of question, be-
cause they have many forms to use, for example, 
?how + verb to be + noun?, ?how + do(es) + 
noun + verb?, ?how to?, ?how can?, etc. or  
?what + verb to be + noun?, ?what + noun + 
auxiliary verb?, etc. This is why we point out the 
?What? and ?How? questions. 
<question type=? SF or SE? focus=? symptom of 
Bakanae?> What <fact> is <theme> the symp-
tom of Bakanae </theme> </fact> ? </question>
7
4.2    Dealing with texts: document indexing 
and associated annotations 
Texts are initially indexed based on the main 
terms they contain which are relevant w.r.t. the 
questions given in the corpus. Our representation 
resembles a frame approach, but it is more 
flexible since there is no predefined structure to 
represent indexes. This is more in accordance 
with the variety of texts in terms of contents. In-
dexes basically are formed from: 
? Top-level terms that structure the domain: 
for example, concepts like symptom, 
spreading, treatment, time, place, effect, 
etc. where predicative (action terms) terms 
as well as entities are found, 
? relatively generic terms, found in the 
questions and structured in the domain on-
tology: water, clean, control, eradicate, 
etc., which are organized w.r.t. the top 
concepts above, 
? named entities, typed as: disease names, 
location names, chemical product names, 
bacteria names, etc. 
In our representation, those generic terms (and 
near synonyms) are represented as predicates, 
while arguments are represented as attribute-
value pairs (or attributes alone), include typed 
name entities and any kind of terms besides the 
generic terms.  
Indexes are associated with texts in the text 
database. Indexes must remain general so that 
indexing is fast and as reliable as possible. The 
idea is that when a question is uttered, a small 
number of texts are first selected on the basis of 
the indexes for further analysis. An example  
below can be indexed and annotated [2] as the 
following: 
 
Index: disease-name (Bakanae), symptoms (disease: Bakanae), 
origin (disease: Bakanae, place: California, date: 1999), spread-
ing(disease: Bakanae, period: winter, medium: [soil, water]), treat-
ment(disease: Bakanae, product). 
 
<title type=?goal? level=?1? > Rice Bakanae </title> 
<title type=?goal? level=?2?>SYMPTOMS </title> 
  <task type = ?SF?>  
<theme>Symptoms of Bakanae</theme> first appear about a 
month after planting. Infected seedlings appear to be taller, more 
slender, and slightly chlorotic ... The rapid elongation of infected 
plants is caused by the pathogen?s production of the plant hormone, 
gibberellin.....</task> 
 
<title type=?goal? level=?2?>COMMENTS ON THE DISEASE 
</title> 
Bakanae is one of the oldest known diseases of rice in Asia but has 
only been observed in California rice since 1999 and now occurs in 
all California rice-growing regions. While very damaging in Asia, 
the extent to which Bakanae may effect California rice production 
is unknown. As diseased plants ..... 
 
4.3   Matching selected texts with questions: 
the deep indexing level 
The main words of the question focus and body 
are used to select a subset of indexed texts as 
potential candidates containing the response. 
Then, in each of these texts, the few sentences 
where the terms of the question or derived terms 
(closely related terms) are effectively found are 
annotated by means of semantic roles as for the 
question, for further analysis and investigations.  
For that purpose, we have developed guide-
lines for annotating those text fragments where 
the response is and the associated knowledge, 
based on the same semantic roles as those used 
in the questions. These annotations remain so far 
exploratory, in terms of feasibility and automa-
tion. Our major concern is to develop a method 
for annotators so that a large number of texts can 
be tagged homogeneously and also so that the 
technique can be reproduced for other technical 
areas. Finally, in terms of response identification, 
the goal is to define a metric that defines the best 
match and selects the text fragment(s) that best 
respond(s) to the question among several poten-
tial candidates. 
Let us first consider a simple example. Given 
the question: 
Q8: ?How to eradicate Bakanae ??  
with the following representation: 
 
The main terms of the question are ?eradicate? 
and ?Bakanae?. The text above is therefore se-
lected on the basis of its indexes, because ?treat-
ment? is a closely related term (in terms of se-
mantic relation: ?way to realize an event?) of 
?eradicate? in the domain ontology. 
Then, the question terms are searched in the 
selected text and the sentences that contain them 
are annotated using semantic roles. For example, 
the following sentence is a candidate: 
The most effective means to treat this disease 
is the use of noninfested seeds.  
It is tagged as: 
<title type=?goal? level=?2?>MANAGEMENT</title> 
<task type = ?PROC?>  
The most effective means to<action> treat <theme> this disease 
</theme> </action> is the <instruction compound><instruction 
type="imperative">use of noninfested seed</instruction>. 
Also,<connector type="advice"> when possible</connector>, <ad-
vice>burning plant residues</advice> with known infection in fall 
may help limit the disease. ..... Field trials indicate that a seed treat-
ment with sodium hypochlorite (Ultra Clorox Germicidal Bleach) is 
effective at reducing the incidence of this disease.... </instruction 
compound></task> 
<question type=?PROC or SqE? focus ?eradi-
cate Bakanae? > How to <action> eradicate 
<theme> Bakanae </theme>  </action> ? 
</question> 
8
 
The answer is the above sentence and the text 
fragment that follows (introduced by the connec-
tor also) since the response is of type procedure: 
The most effective means to treat this disease 
is the use of noninfested seed. Also, when possi-
ble, burning plant residues with known infection 
in fall may help limit the disease. 
Following [5], this structure is annotated as a 
single instructional compound, which is the fun-
damental unit in a procedural text. This is the 
structure which is typically returned to users. 
Let us present here another illustrative exam-
ple of a text fragment where the response is an-
notated together with the required related reason-
ing elements: 
Q9: ?How can thrips destroy the rice ?? 
annotation: 
 
The text fragment that corresponds to the an-
swer is annotated as follows: 
 
To match the action ?destroy? in the question 
with the text portion from which the response is 
extracted, it is then necessary to identify the in-
ference: 
 
 This example shows that (1) in the question 
and in the answer, annotations are used to iden-
tify the different components, arguments, ad-
juncts, but also some other components (e.g. 
temporal adverbs), and (2) the annotation is de-
veloped to characterize the matching steps and 
inferential components (either lexical or domain 
knowledge) between the question and the an-
swer. This latter form of annotation, which is 
quite time-consuming to develop, is the means 
we use to induce and develop domain dependent 
forms of lexical inference (or other phenomena 
like synonymy, lexical equivalence, etc.) and 
relevant domain knowledge. The types and lexi-
cal functions which are introduced are then used 
in the process of induction of generalizations 
over some semantic categories (plants, products, 
etc.), and verb classes. This way of annotating 
knowledge and inferences is obviously a simple 
bottom-up process, with well known limitations, 
but we feel it may have some advantages for in-
ducing an upper organization of knowledge, in 
conjunction, and as a complement to, the domain 
ontology. It is also simple and accessible to an-
notators. Obviously this remains to be evaluated.  
4.4  Generalizing inferences for question-
answer matching 
At this level, the inferences which may be drawn 
are directly attached to the terms which are 
tagged. This is obviously too limited. We are 
now experimenting with different generalization 
strategies in order to tune the lexical inference 
rules. This process involves: 
(1) developing various generic principles over 
different types and categories (via the domain 
ontology), We will annotation the title for match-
ing the ?theme? of the answer to the ?theme? and 
?Focus? of the question by using word net and 
ontology as shown below.  
Surface Form Concept 
destroy, destruct, eliminate, kill,? destroy 
treat, prevent, eradicate, protect,? manage 
suck, eat, bite, drink,? consume 
spread out, diffuse, disperse,? spread 
(2) a set of principles that limit these generali-
zations via, for example, the taking into account 
of the semantics restrictions imposed by lexical 
items, in particular verbs. The main words of the 
question focus and text body that already anno-
tated will be considered for extracting the poten-
tial candidates containing the response. The sen-
tences, where the terms of the question or de-
rived terms (closely related terms) are effectively 
found, will be the corresponding answer by using 
matching function as shown below. 
 
Function Matching (Question Q, Answer A){ 
      Match = false; 
     // Relevant document 
     If  (Q.focus  =  A.index)  then 
             // Relevant answer 
             If  (Q.type =  A.task type) then      
                    //Detect Answer for the Question 
                    If (Q.focus = A.title) then 
                         Match = true; 
                    Else if (Q.action = A.action and 
                               Q.theme = A.theme or 
                               Q.agent = A.agent) then 
                         Match = true; 
                    End If 
             End If 
       End If 
Return Match;} 
The tuning of the level of these generalizations 
is obviously one main parameter of our project. 
It has several conceptual dimensions that we ex-
plore and may also be domain dependent. 
<lex_inference>  <action> Suck sap of X 
</action>  <entail>  <modality> probably  
</modality>  <action> destroy X </action>  
</entail> ,  <type> X : plant </type>   
<part-of> sap : X </part-of >  </lex inference>  
<response>  <agent> The rice thrips</agent> 
<action>  sucks the sap <source>  from the young
plant. </source> </action> </response> 
<question type=?SqE? focus = ?destroy?>How 
can <agent> thrips </agent> <action>destroy 
<theme>the rice</theme> </action>?</question>
?<action> treat <theme> this disease </theme>   
is the use of <instrument> noninfested seeds 
</instrument> </action> . 
9
Perspectives 
The matching problem between questions and 
documents to retrieve answers in question-
answering systems in concrete applicative con-
texts is often a difficult problem. This matching 
procedure often requires very accurate domain 
knowledge, besides ontological descriptions. It is 
not always easy to access this knowledge in a 
structured way or to extract it from texts. The 
present contribution, still experimental and in an 
early stage of development, is an attempt, via 
annotations, at resolving this problem, following 
a simple and clear methodology. 
This task needs to be developed and evaluated 
gradually. So far, it is too early to evaluate the 
quality of the generalizations and the inferential 
patterns we get.  
This approach, and the principles we have 
briefly outlined, allow us to introduce a working 
method for the development of question-
answering systems for concrete applications, es-
pecially for non-factoid questions, an area which 
is still not very much developed in spite of its 
obvious usefulness. One of the reasons is that 
non-factoid questions require a language proc-
essing technology, analysis methods, reasoning 
aspects, and a conceptual approach, which are 
substantially different from what is used for fac-
toid questions. 
Acknowledgments 
The work described in this paper has been sup-
ported by the NECTEC No. NT-B-22-KE-12-50-
19, within the project, ?I-KnowII: CAT, EAT, 
RATs,? and ?Agricultural Question & Answer-
ing Service System,? granted by the KURDI, 
Kasetsart University. We would like to espe-
cially thank Prof. Patrick Saint Dizier for origi-
nating, advising and collaborating in the devel-
opment of Q&A system. We also thank Prof. 
William I. Grosky for helping to revise our Eng-
lish. 
References 
1. Asanee Kawtrakul, et al Chaveevan Pechsiri, Sa-
chit Rajbhandari,  Frederic Andres, Problems-
Solving Map Extraction with Collective Intelli-
gence Analy-sis and Language Engineering , Book 
Chapter 18, Medical Information Science Refer-
ence in Information Retrieval in Biomedicine 
ISBN: 978-1-60566-274-9; pp 460 
2. Asanee Kawtrakul, et al 2009. From CyberBrain to 
Q&A Services: A Development of Question - An-
swering Services System for the Farmer through 
the SMS, WCCA2009, Grand Sierra Resort, Reno, 
Nevada, USA.  
3. Asanee Kawtrakul, et al 2008. ?CyberBrain: To-
wards the Next Generation Social Intelligence? 
IAALD AFITA WCCA 2008, Tokyo, Japan. 
4. Dan Moldovan, Sanda Harabagiu, Marius Pasca, 
Rada Mihalcea, Roxana Girju, Richard Goodrum, 
Vasile Rus. 2000. The Structure and Performance 
of an Open-Domain Question Answering System, 
Proceedings of the 38th Meeting of the Association 
for Computational Linguistics (ACL), Hong Kong. 
5. Estelle Delpech, Patrick Saint-Dizier. 2008. Inves-
tigating the Structure of Procedural Texts for An-
swering How-to Questions, LREC2008, Marra-
kech. 
6. Jochen L. Leidner, 2005. A wireless natural lan-
guage search engine. Proceedings of the 28th an-
nual international ACM SIGIR conference on Re-
search and development in information retrieval 
table of contents: 677 ? 677, ACM,  New York,  
USA  
7. Judy Delin, Anthony Hartley, Cecile Paris,  Donia 
Scott, Keith Vander Linden. 1994. Expressing Pro-
cedural Relation-ships in Multilingual Instructions, 
Proceedings of the 7th International Workshop on 
Natural Language Generation: 61-70, Maine, USA. 
8. Karen Sparck Jones, Branimir Boguraev.1987. A 
note on a study of cases, research note in Computa-
tional Linguistics archive, Volume 13 ,  Issue 1-2  
(January-June 1987) : 65 - 68. 
9. Leonard Talmy. 1976. Semantic Causative Types, 
In M. Shibatani (ed.), Syntax and Semantics 6: The 
Grammar of Causative Constructions. New York: 
Academic Press: 43-116. 
10. Leonard Talmy. 1985. Lexicalization Patterns: 
Seman-tic Structure in Lexical Forms, in Language 
Typol-ogy and Syntactic Description 3: Grammati-
cal Categories and the Lexicon, T. Shopen(ed.), 
57-149, Cambridge University Press. 
11. Mark Thomas Maybury. 2004. New Directions in 
Question Answering, The MIT Press, Menlo Park. 
12. Mineki Takechi, Takenobu Tokunaga, Yuji Ma-
tsumoto, Hozumi Tanaka. 2003. Feature Selection 
in Categorizing Procedural Expressions, The 6th 
International Workshop on Information Retrieval 
with Asian Languages (IRAL2003):49-56. 
13. Ray Jackendoff. 1990. Semantic Structures, MIT 
Press. 
14. Robert E. Longacre. 1982. Discourse Typology in 
Relation to Language Typology, Sture Allen ?ed., 
Text Processing, Proceeding of Nobel Symposium 
51, Stockholm, Almquist and Wiksell, 457-486. 
15. Sadhu  Balasundaram  Ramakishnan and 
Balakrishnan  Ramadoss. 2007. SMS for Question-
Answering in the m-Learning Scena-rio, Journal of 
Computer Science 3(2):119-121. 
10
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 215?222,
Beijing, August 2010
An ontology-driven system for detecting global health events
Nigel Collier
National Inst. Informatics
collier@nii.ac.jp
Reiko Matsuda Goodwin
Fordham University
reikogoodwin@gmail.com
John McCrae
Bielefeld University
johnmccrae@gmail.com
Son Doan
Vanderbilt University
son.doan@vanderbilt.edu
Ai Kawazoe
Tsuda College
zoeai@tsuda.ac.jp
Mike Conway
University of Pittsburgh
conwaym@pitt.edu
Asanee Kawtrakul
Kasetart University
ak@ku.ac.th
Koichi Takeuchi
Okayama University
koichi@cs.okayama-u.ac.jp
Dinh Dien
VietNam National University
ddien66@yahoo.com
Abstract
Text mining for global health surveillance
is an emerging technology that is gaining
increased attention from public health or-
ganisations and governments. The lack
of multilingual resources such as Word-
Nets specifically targeted at this task have
so far been a major bottleneck. This pa-
per reports on a major upgrade to the
BioCaster Web monitoring system and
its freely available multilingual ontology;
improving its original design and extend-
ing its coverage of diseases from 70 to 336
in 12 languages.
1 Introduction
The number of countries who can sustain teams
of experts for global monitoring of human/animal
health is limited by scarce national budgets.
Whilst some countries have advanced sensor net-
works, the world remains at risk from the health
impacts of infectious diseases and environmen-
tal accidents. As seen by the recent A(H5N1),
A(H1N1) and SARS outbreaks, a problem in one
part of the world can be rapidly exported, leading
to global hardship.
The World Health Organization (WHO) esti-
mates that in the future, between 2 to 7.4 mil-
lion people could be at risk worldwide from a
highly contageous avian flu virus that spreads
rapidly through the international air travel net-
work (WHO, 2005). Pandemics of novel
pathogens have the capacity to overwhelm health-
care systems, leading to widespread morbidity,
mortality and socio-economic disruption (Cox
et al, 2003). Furthermore, outbreaks of live-
stock diseases, such as foot-and-mouth disease or
equine influenza can have a devastating impact on
industry, commerce and human health (Blake et
al., 2003). The challenge is to enhance vigilance
and control the emergence of outbreaks. Whilst
human analysis remains essential to spot complex
relationships, automated analysis has a key role
to play in filtering the vast volume of data in real
time and highlighting unusual trends using reli-
able predictor indicators.
BioCaster (http://born.nii.ac.jp) (Collier et al,
2008) is a Web 2.0 monitoring station for the early
detection of infectious disease events. The sys-
tem exploits a high-throughput semantic process-
ing pipeline, converting unstructured news texts
to structured records, alerting events based on
time-series analysis and then sharing this informa-
tion with users via geolocating maps (Fig. 1(a)),
graphs (Fig. 1(b)) and alerts. Underlying the sys-
tem is a publicly available multilingual applica-
tion ontology. Launched in 2006 (Collier et al,
2006) the BioCaster Ontology (BCO) has been
downloaded by over 70 academic and industrial
groups worldwide. This paper reports on a ma-
jor upgrade to the system and the ontology - ex-
panding the number of languages from 6 to 12,
redefining key relations and extending coverage in
the number of diseases from 70 to 336, including
many veterinary diseases.
215
(a) Bio-geographic map (b) Trend graph analyser
(c) BioCaster processes
Figure 1: (a)BioCaster?s bio-geographic map for a suspected foot-and-mouth outbreak on 22nd March,
2010 with links to the multilingual ontology, NCBI, HighWire, GoPubMed and Google Scholar; (b)
The trends analyser showing aggregated document counts for health events in China between 13nd
March and 12th April, 2010; (c) The system?s pipeline of processes with example semantic markup.
216
2 Background
As the world becomes more interconnected and
urbanized and animal production becomes in-
creasingly intensive, the speed with which epi-
demics spread becomes faster, adding to pressure
on biomedical experts and governments to make
quick decisions. Traditional validation methods
such as field investigations or laboratory analysis
are the mainstay of public health but can require
days or weeks to issue reports. The World Wide
Web with its economical and real time delivery of
information represents a new modality in health
surveillance (Wagner and Johnson, 2006) and has
been shown to be an effective source by the World
Health Organization (WHO) when Public Health
Canada?s GPHIN system detected the SARS out-
break in southern China from news reports dur-
ing November 2002. The recent A(H1N1) ?swine
flu? pandemic highlighted the trend towards agen-
cies using unvalidated sources. The technologi-
cal basis for such systems can be found in sta-
tistical classification approaches and light weight
ontological reasoning. For example, Google Flu
Trends (Ginsberg et al, 2009) is a system that de-
pends almost entirely on automatic statistical clas-
sification of user queries; MedISys-PULS (Yan-
garber et al, 2008), HealthMap (Freifeld et al,
2008) and BioCaster use a mixture of statisti-
cal and ontological classification; and GPHIN
(Mawudeku and Blench, 2006) and Argus (Wil-
son, 2007) rely on a mixture of ontological classi-
fication and manual analysis.
Compared to other similar systems BioCaster
is characterized by its richly featured and pub-
licly downloadable ontology and emphasizes crit-
ical evaluation of its text mining modules. Em-
pirical results have included: topic classification,
named entity recognition, formal concept anal-
ysis and event recognition. In the absence of
a community gold standard, task performance
was assessed on the best available ?silver? stan-
dard - the ProMED-mail network (Madoff and
Woodall, 2005), achieving F-score of 0.63 on 14
disease-country pairs over a 365-day period (Col-
lier, 2010).
Despite initial skepticism within the public
health community, health surveillance systems
based on NLP-supported human analysis of me-
dia reports are becoming firmly established in
Europe, North America and Japan as sources of
health information available to governments and
the public (Hartley et al, 2010). Whilst there is no
substitute for trained human analysts, automated
filtering has helped experts save time by allow-
ing them to sift quickly through massive volumes
of media data. It has also enabled them to sup-
plement traditional sources with a broader base of
information.
In comparison with other areas of biomedical
NLP such as the clinical and genetics? domains, a
relative lack of building block resources may have
hindered the wider participation of NLP groups
in public health applications. It is hoped that the
provision of common resources like the BCO can
help encourage further development and bench-
marking.
3 Method
BioCaster performs analysis of over 9000 news ar-
ticles per day using the NPACI Rocks cluster mid-
dleware (http://www.rockcsclusters.org) on a plat-
form of 48 3.0GHz Xeon cores. Data is ingested
24/7 into a semantic processing pipeline in a short
1 hour cycle from over 1700 public domain RSS
feeds such as Google news, the European Media
Monitor and ProMED-mail. Since 2009, news has
also being gathered under contract from a com-
mercial news aggregation company, providing ac-
cess to over 80,000 sources across the world?s lan-
guages.
The new 2010 version of BioCaster uses ma-
chine translation into English (eleven languages)
to source news stories related to currently oc-
curring infectious and environmental disease out-
breaks in humans, animals and plants.
Access to the site is freely available but lo-
gin registration applies to some functions such as
email alerts. Processing is totally automatic, but
we have the potential within the login system to
enable human moderated alerts which broadcast
to Twitter and RSS.
Below we describe in detail two key aspects of
the system that have been significantly upgraded:
the BCO and the event detection system.
217
3.1 Ontology
3.1.1 Aim
The BioCaster Ontology aims:
? To describe the terms and relations necessary
to detect and risk assess public health events
in the grey literature;
? To bridge the gap between (multilingual)
grey literature and existing standards in
biomedicine;
? To mediate integration of content across lan-
guages;
? To be freely available.
The central knowledge source for BioCaster
is the multilingual ontology containing domain
terms such as diseases, agents, symptoms, syn-
dromes and species as well as domain sensitive
relations such as a disease causing symptoms or
an agent affecting particular host species. This al-
lows the text mining system to have a basic un-
derstanding of the key concepts and relationships
within the domain to fill in gaps not mentioned
explicitly in the news reports. To the best of our
knowledge the BCO is unique as an application
ontology, providing freely available multilingual
support to system developers interested in out-
break surveillance in the language of the open me-
dia.
The BCO however has little to say outside of
its application domain, e.g. in disease-gene in-
teraction or for supporting automatic diagnosis.
As discussed in Grey Cowell and Smith (2010),
there are many other resources available that have
the potential to support applications for infec-
tious disease analysis including controlled vocab-
ularies and ontologies such as the the Unified
Medical Language System (UMLS) (Lindberg et
al., 1993), International Classification of Diseases
(ICD-10) (WHO, 2004), SNOMED CT (Stearns
et al, 2001), Medical Subject Headings (MeSH)
(Lipscomb, 2000) and the Infectious Disease On-
tology (IDO) (Grey Cowell and Smith, 2010). In
(Collier et al, 2006) we discussed how BCO com-
pared to such ontologies so we will focus from
now on the implication of the extensions.
3.1.2 Scope
The new version of the BCO now covers 12 lan-
guages including all the United Nation?s official
languages: Arabic (968 terms), English (4113),
French (1281), Indonesian (1081), Japanese
(2077), Korean (1176), Malaysian (1001), Rus-
sian (1187), Spanish (1171), Thai (1485), Viet-
namese (1297) and Chinese (1142). The multi-
lingual ontology can be used as a direct knowl-
edge source in language-specific text mining mod-
ules, as an indexing resource for searching across
concepts in various languages and as a dictionary
for future translation modules. Currently news in
all 12 languages is available via the Web portal
but news in additional languages such as German,
Italian and Dutch are being added using machine
translation.
3.1.3 Design
Like EuroWordNet (Vossen, 1998), on which
it is loosely based, the BCO adopts a thesaurus-
like structure with synonym sets linking to-
gether terms across languages with similar mean-
ing. Synonym sets are referred to using root
terms. Root terms themselves are fully defined in-
stances that provide bridges to external classifica-
tion schemes and nomenclatures such as ICD10,
MeSH, SNOMED CT and Wikipedia. The central
backbone taxonomy is deliberately shallow and
taken from the ISO?s Suggested Upper Merged
Ontology (Niles and Pease, 2001). To maintain
consistency and computability we kept a single
inheritance structure throughout. 18 core domain
concepts corresponding to named entities in the
text mining system such as DISEASE and SYMP-
TOM were the results of analysis using a formal
theory (Guarino and Welty, 2000).
We have endeavoured to construct definitions
for root terms along Aristotelean principles by
specifying the difference to the parent. For ex-
ample in the case of Eastern encephalitis virus:
Eastern equine encephalitis virus is a
species of virus that belongs to the
genus Alphavirus of the family Togaviri-
dae (order unassigned) of the group
IV ((+)ssRNA) that possesses a positive
single stranded RNA genome. It is the
218
etiological agent of the eastern equine
encephalitis.
We are conscious though that terms used in
the definitions still require more rigorous control
to be considered useful for machine reasoning.
To aid both human and machine analysis root
terms are linked by a rich relational structure
reflecting domain sensitive relations such as
causes(virus,disease), has symptom(disease,
symptom), has associated syndrome(disease,
syndrome), has reservoir(virus, organism).
In such a large undertaking, the order of work
was critical. We proceeded by collecting a list of
notifiable diseases from national health agencies
and then grouped the diseases according to per-
ceived relevance to the International Health Reg-
ulations 2005 (Lawrence and Gostin, 2004). In
this way we covered approximately 200 diseases,
and then explored freely available resources and
the biomedical literature to find academic and lay-
man?s terminology to describe their agents, af-
fected hosts, vector species, symptoms, etc. We
then expanded the coverage to less well known
human diseases, zoonotic diseases, animal dis-
eases and diseases caused by toxic substances
such as sarin, hydrogen sulfide, sulfur dioxide and
ethylene. At regular stages we checked and val-
idated terms against those appearing in the news
media.
As we expanded the number of conditions to in-
clude veterinary diseases we found a major struc-
tural reorganization was needed to support animal
symptoms. For example, a high temperature in
humans would not be the same as one in bovids.
This prompted us in the new version to group dis-
eases and symptoms around major animal familes
and related groups, e.g. high temperature (human)
and high temperature (bovine).
A second issue that we encountered was the
need to restructure the hierarchy under Organi-
cObject which was divided between MicroOrgan-
ism and Animal. The structure of the previous
version meant that the former were doing dou-
ble duty as infecting agents and the later were af-
fected hosts. The MicroOrganism class contained
bacterium, helminth, protozoan, fungus and virus,
which then became the domain in a relation ?x
causes y?. Expansion forced us to accomodate the
fact that some animals such as worms and mites
(e.g. scabies) also infect humans as well as ani-
mals. The result was a restructuring of the organic
classes using the Linnean taxonomy as a guide-
line, although this is probably not free from errors
(e.g. virus is typically not considered to be an or-
ganism).
3.2 Event alerting system
Figure 1(c) shows a schematic of the modular de-
sign used by the BioCaster text mining system.
Following on from machine translation and topic
classification is named entity recognition and tem-
plate recognition which we describe in more detail
below. The final structured event frames include
slot values normalized to ontology root terms for
disease, pathogen (virus or bacterium), country
and province. Additionally we also identify 15 as-
pects of public health events critical to risk assess-
ment such as: spread across international borders,
hospital worker infection, accidental or deliberate
release, food contamination and vaccine contami-
nation.
Latitude and longitude of events down to the
province level are found in two ways: using the
Google API up to a limit of 15000 lookups per
day, and then using lookup on the BCO taxonomy
of 5000 country and province names derived from
open sources such as Wikipedia.
Each hour events are automatically alerted to
a Web portal page by comparing daily aggre-
gated event counts against historical norms (Col-
lier, 2010). Login users can also sign up to receive
emails on specific topics. A topic would normally
specify a disease or syndrome, a country or region
and a specific risk condition.
In order to extract knowledge from docu-
ments, BioCaster maintains a collection of rule
patterns in a regular expression language that
converts surface expressions into structured in-
formation. For example the surface phrase
?man exposes airline passengers to measles?
would be converted into the three templates
?species(human); disease(measles); interna-
tional travel(true)?. Writing patterns to produce
such templates can be very time consuming and
so the BioCaster project has developed its own
219
D3: :- name(disease){ list(@undiagnosed) words(,1) list(@disease) }
S2: :- name(symptom) { list(@severity) list(@symptom)}
CF1: contaminated food(?true?) :- ?caused? ?by? list(@contaminate verbs past)
list(@injested material)
SP4: species(?animal?) :- name(animal,A) words(,3) list(@cull verbs past)
Table 1: Examples of SRL rules for named entity and template recognition. Template rules contain
a label, a head and a body, where the head specifies the template pattern to be output if the body
expression matches. The body can contain word lists, literals, and wild cards. Various conditions can
be placed on each of these such as orthographic matching.
light weight rule language - called the Simple
Rule Language (SRL) and a pattern building inter-
face for maintaining the rule base (McCrae et al,
2009). Both are freely available to the research
community under an open source license. Cur-
rently BioCaster uses approximately 130 rules for
entity recognition, 1000 word lists and 3200 tem-
plate rules (of which half are for location recogni-
tion) to identify events of interest in English. Us-
ing SRL allows us to quickly adapt the system to
newly emerging terminology such as the 11+ des-
ignations given to A(H1N1) during the first stages
of the 2009 pandemic.
The SRL rulebook for BioCaster can recognize
a range of entities related to the task of disease
surveillance such as bacteria, chemicals, diseases,
countries, provinces, cities and major airports.
Many of these classes are recognized using terms
imported from the BCO. The rule book also con-
tains specialised thesauri to recognize subclasses
of entities such as locations of habitation, eater-
ies and medical service centres. Verb lists are
maintained for lexical classes such as detection,
mutation, investigation, causation, contamination,
culling, blaming, and spreading.
Some examples of SRL rules for named entity
recognition are shown in Table 1 and described
below:
Rule D3 in the rulebook tags phrases like ?mys-
tery illness? or ?unknown killer bug? by matching
on strings contained within two wordlists, @un-
diagnosed and @disease, separated by up to one
word.
Rule S2 allows severity indicators such as ?se-
vere? or ?acute? to modify a list of known symp-
toms in order to identify symptom entities.
Rule CF1 is an example of a template rule. If
the body of the rule matches by picking out ex-
pressions such as ?was caused by tainted juice?,
this triggers the head to output an alert for con-
taminated food.
Rule SP4 identifies the victim species as ?ani-
mal? in contexts like ?250 geese were destroyed?.
The rulebook also supports more complex in-
ferences such as the home country of national
public health organizations.
Since BioCaster does not employ systematic
manual checking of its reports, it uses a number of
heuristic filters to increase specificity (the propor-
tion of correctly identified negatives) for reports
that appear on the public Web portal pages. For
example, reports with no identified disease and
country are rejected. Since these heuristics may
reduce sensitivity they are not applied to news that
appears on the user login portal pages.
4 Results and Discussion
Version 3 of the ontology represents a significant
expansion in the coverage of diseases, symptoms
and pathogens on version 2. Table 2 summarizes
the number of root terms for diseases classified by
animal familes.
The thesaurus like structure of the BCO is com-
patible in many respects to the Simple Knowledge
Organization System (SKOS) (Miles et al, 2005).
In order to extend exchange and re-use we have
produced a SKOS version of the BCO which is
available from the BCO site. We have also con-
verted the BCO terms into 12 SRL rule books (1
for each language) for entity tagging. These too
are freely available from the BCO site.
As the ontology expands we will consider
adopting a more detailed typing of diseases such
as hasInfectingPart to indicate the organ affected
220
Species N Example
Avian 22 Fowl pox
Bee 6 Chalk brood
disease
Bovine 24 Bluetongue
Canine 4 Blastomycosis
(Canine)
Caprine 14 Contagious
agalactia
Cervine 2 Chronic wasting
disease
Equine 17 Strangles
Feline 4 Feline AIDS
Fish 2 Viral hemorr
hagic septicemia
Human 216 Scarlet fever
Lagomorph 2 Myxomatosis
Non-human 16 Sylvan
primate yellow fever
Other 2 Crayfish plague
Rodent 8 Colorado tick
fever (Rodent)
Swine 12 Swine erysipelas
Table 2: Major disease groups organized by af-
fected animal family. N represents the number of
root terms.
or hasProtectionMethod to indicate broad classes
of methods used to prevent or treat a condition.
The typology of diseases could also be extended
in a more fine grained manner to logically group
conditions, e.g. West Nile virus encephalitis,
Powassan encephalitis and the Japanese B en-
cephalitis could be connected through a hasType
relation on encephalitis.
5 Conclusion
Multilingual resources specifically targeted at the
task of global health surveillance have so far been
very rare. We hope that the release of version 3
can be used to support a range of applications such
as text classification, cross language search, ma-
chine translation, query expansion and so on.
The BCO has been constructed to provide core
vocabulary and knowledge support to the Bio-
Caster project but it has also been influential
in the construction of other public health ori-
ented application ontologies such as the Syn-
dromic Surveillance Ontology (Okhamatovskaia
et al, 2009). The BCO is freely available from
http://code.google.com/p/biocaster-ontology/ un-
der a Creative Commons license.
Acknowledgements
The authors greatly acknowledge the many co-
workers who have provided comments and feed-
back on BioCaster. Funding support was pro-
vided in part by the Japan Science and Technology
Agency under the PRESTO programme.
References
Blake, A., M. T. Sinclair, and G. Sugiyarto. 2003.
Quantifying the impact of foot and mouth disease on
tourism and the UK economy. Tourism Economics,
9(4):449?465.
Collier, N., A. Kawazoe, L. Jin, M. Shigematsu,
D. Dien, R. Barrero, K. Takeuchi, and A. Kaw-
trakul. 2006. A multilingual ontology for infectious
disease surveillance: rationale, design and chal-
lenges. Language Resources and Evaluation, 40(3?
4). DOI: 10.1007/s10579-007-9019-7.
Collier, N., S. Doan, A. Kawazoe, R. Matsuda Good-
win, M. Conway, Y. Tateno, Q. Ngo, D. Dien,
A. Kawtrakul, K. Takeuchi, M. Shigematsu, and
K. Taniguchi. 2008. BioCaster:detecting public
health rumors with a web-based text mining sys-
tem. Bioinformatics, 24(24):2940?1, December.
doi:10.1093/bioinformatics/btn534.
Collier, N. 2010. What?s unusual in online dis-
ease outbreak news? Biomedical Semantics, 1(1),
March. doi:10.1186/2041-1480-1-2.
Cox, N., S. Temblyn, and T. Tam. 2003. Influenza
pandemic planning. Vaccine, 21(16):1801?1803.
Freifeld, C., K. Mandl, B. Reis, and J. Brownstein.
2008. Healthmap: global infectious disease mon-
itoring through automated classification and visual-
ization of internet media reports. J. American Med-
ical Informatics Association, 15:150?157.
Ginsberg, J., M. Mohebbi, R. Patel, L. Brammer,
M. Smolinski, and L. Brilliant. 2009. Detecting
influenza epidemics using search engine query data.
Nature, 457:1012?1014.
Grey Cowell, L. and B. Smith. 2010. Infectious dis-
ease informatics. In Sintchenko, V., editor, Infec-
tious Disease Informatics, pages 373?395. Springer
New York.
221
Guarino, N. and C. Welty. 2000. A formal ontology
of properties. In Dieng, R. and O. Corby, editors,
EKAW-2000: Proc. 12th Int. Conf. on Knowledge
Engineering and Knowledge Management, pages
97?112.
Hartley, D., N. Nelson, R. Walters, R. Arthur, R. Yan-
garber, L. Madoff, J. Linge, A. Mawudeku, N. Col-
lier, J. Brownstein, G. Thinus, and N. Lightfoot.
2010. The landscape of international biosurveil-
lance. Emerging Health Threats J., 3(e3), January.
doi:10.1093/bioinformatics/btn534.
Lawrence, O. and J. Gostin. 2004. International
infectious disease law - revision of the World
Health Organization?s international health regula-
tions. J. American Medical Informatics Associa-
tion, 291(21):2623?2627.
Lindberg, Donald A.B., L. Humphreys, Betsy, and
T. McCray, Alexa. 1993. The unified medical lan-
guage system. Methods of Information in Medicine,
32:281?291.
Lipscomb, C. 2000. Medical subject headings
(MeSH). Bulletin of the Medical Library Assoca-
tion, 88:256?266.
Madoff, Lawrence C. and John P. Woodall. 2005. The
internet and the global monitoring of emerging dis-
eases: Lessons from the first 10 years of promed-
mail. Archives of Medical Research, 36(6):724 ?
730. Infectious Diseases: Revisiting Past Problems
and Addressing Future Challenges.
Mawudeku, A. and M. Blench. 2006. Global pub-
lic health intelligence network (gphin). In Proc. 7th
Int. Conf. of the Association for Machine Transla-
tion in the Americas, Cambridge, MA, USA, August
8?12.
McCrae, J., M. Conway, and N. Collier. 2009. Simple
rule language editor. Google code project, Septem-
ber. Available from: http://code.google.com/p/srl-
editor/.
Miles, A., B. Matthews, and M. Wilson. 2005. SKOS
Core: Simple knowledge organization for the web.
In Proc. Int. Conf. on Dublin Core and Metadata
Applications, Madrid, Spain, 12?15 September.
Niles, I. and A. Pease. 2001. Towards a standard up-
per ontology. In Welty, C. and B. Smith, editors,
2nd Int. Conf. on Formal Ontology in Information
Systems FOIS-2001, Maine, USA, October 17?19.
Okhamatovskaia, A., W. Chapman, N. Collier, J. Es-
pino, and D. Buckeridge. 2009. SSO: The syn-
dromic surveillance ontology. In Proc. Int. Soc. for
Disease Surveillance, Miami, USA, December 3?4.
Stearns, M. Q., C. Price, K. A. Spackman, and A. Y.
Wang. 2001. SNOMED clinical terms: overview of
the development process and project status. In Proc.
American Medical Informatics Association (AMIA)
Symposium, pages 662?666.
Vossen, P. 1998. Introduction to EuroWordNet. Com-
puters and the Humanities, 32:73?89.
Wagner, M. and H. Johnson. 2006. The internet as
sentinel. In Wagner, M. et al, editor, The Hand-
book of Biosurveillance, pages 375?385. Academic
Press.
WHO. 2004. ICD-10, International Statistical Classi-
fication of Diseases and Related Health Problems,
Tenth Revision. World Health Organization, De-
cember.
WHO. 2005. Avian influenza: assessing the pandemic
threat. Technical Report WHO/CDS/2005.29,
World Health Organization, Geneva, January.
Wilson, J. 2007. Argus: a global detection and track-
ing system for biological events. Advances in Dis-
ease Surveillance, 4.
Yangarber, R., P. von Etter, and R. Steinberger. 2008.
Content collection and analysis in the domain of
epidemiology. In Proc. Int. Workshop on Describ-
ingMedical Web Resources (DRMED 2008), Goten-
burg, Sweden, May 27th.
222
Proceedings of the 8th Workshop on Asian Language Resources, pages 129?136,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
A Supervised Learning based Chunking in Thai  
using Categorial Grammar 
Thepchai Supnithi, Peerachet Porkaew, 
Taneth Ruangrajitpakorn, Kanokorn 
Trakultaweekool 
Human Language Technology, 
National Electronics and Computer  
Technology Center 
{thepchai.sup, peera-
chet.por, taneth.rua, ka-
nokorn.tra}@nectec.or.th 
 
Chanon Onman, Asanee Kaw-
trakul  
Department of Computer Engineer-
ing, Kasetsart University and  
National Electronics and Computer  
Technology Center 
 
chanon.onman@gmail.com, 
asanee.kaw@nectec.or.th 
Abstract 
One of the challenging problems in Thai 
NLP is to manage a problem on a syn-
tactical analysis of a long sentence.  
This paper applies conditional random 
field and categorical grammar to devel-
op a chunking method, which can group 
words into larger unit. Based on the ex-
periment, we found the impressive re-
sults. We gain around 74.17% on sen-
tence level chunking. Furthermore we 
got a more correct parsed tree based on 
our technique. Around 50% of tree can 
be added. Finally, we solved the prob-
lem on implicit sentential NP which is 
one of the difficult Thai language pro-
cessing.  58.65% of sentential NP is cor-
rectly detected. 
1 Introduction 
Recently, many languages applied chunking, or 
shallow parsing, using supervised learning ap-
proaches. Basili (1999) utilized clause boundary 
recognition for shallow parsing. Osborne (2000) 
and McCallum et al (2000) applied Maximum 
Entropy tagger for chunking. Lafferty (2001) 
proposed Conditional Random Fields for se-
quence labeling. CRF can be recognized as a 
generative model that is able to reach global 
optimum while other sequential classifiers focus 
on making the best local decision. Sha and Pe-
reira (2003) compared CRF to other supervised 
learning in CoNLL task. They achieved results 
better than other approaches. Molina et al 
(2002) improved the accuracy of HMM-based 
shallow parser by introducing the specialized 
HMMs. 
In Thai language processing, many research-
es focus on fundamental level of NLP, such as 
word segmentation, POS tagging. For example, 
Kruengkrai et al (2006) introduced CRF for 
word segmentation and POS tagging trained 
over Orchid corpus (Sornlertlamvanich et al, 
1998.). However, the number of tagged texts in 
Orchid is specific on a technical report, which is 
difficult to be applied to other domains such as 
news, document, etc. Furthermore, very little 
researches on other fundamental tools, such as 
chunking, unknown word detection and parser, 
have been done. Pengphon et al (2002) ana-
lyzed chunks of noun phrase in Thai for infor-
mation retrieval task. All researches assume that 
sentence segmentation has been primarily done 
in corpus. Since Thai has no explicit sentence 
boundary, defining a concrete concept of sen-
tence break is extremely difficult. 
Most sentence segmentation researches con-
centrate on "space" and apply to Orchid corpus 
(Meknavin 1987, Pradit 2002). Because of am-
biguities on using space, the accuracy is not im-
pressive when we apply into a real application. 
Let consider the following paragraph which 
is a practical usage from news: 
129
"??????????????????????????????? ????????????????????????????????????
??????????????? | ?????????????????  | ??????????????????????????"  
lit: ?The red shirts have put bunkers around 
the assembly area and put oil and tires. The 
traffic is opened normally.? 
We found that three events are described in 
this paragraph. We found that both the first and 
second event do not contain a subject. The third 
event does not semantically relate to the previ-
ous two events. With a literal translation to Eng-
lish, the first and second can be combined into 
one sentence; however, the third events should 
be separated. 
As we survey in BEST corpus (Kosawat 
2009), a ten-million word Thai segmented cor-
pus. It contains twelve genres. The number of 
word in sentence is varied from one word to 
2,633 words and the average word per line is 
40.07 words. Considering to a News domain, 
which is the most practical usage in BEST, we 
found that the number of words are ranged from 
one to 415 words, and the average word length 
in sentence is 53.20. It is obvious that there is a 
heavy burden load for parser when these long 
texts are applied. 
Example 1:  
   ??                  ???                 ????????               ??                ???????????? ?
man(n) drive(v)   taxi(n)  find(v)   wallet(n) 
 
lit1: A man drove a taxi and found a wallet. 
lit2: A taxi chauffeur found a wallet. 
Example 2: 
   ???            ??          ????      ??????              ?????               ?????? 
should will must    can    develop(v) country(n) 
 
lit: possibly have to develop country. 
 
Figure 1. Examples of compounds in Thai 
Two issues are raised in this paper. The first 
question is "How to separate a long paragraph 
into a larger unit than word effectively?" We are 
looking at the possibility of combining words 
into a larger grain size. It enables the system to 
understand the complicate structure in Thai as 
explained in the example. Chunking approach in 
this paper is closely similar to the work of Sha 
and Pereira (2003). Second question is "How to 
analyze the compound noun structure in Thai?" 
Thai allows a compound construction for a noun 
and its structures can be either a sequence of 
nouns or a combination of nouns and verbs. The 
second structure is unique since the word order 
is as same as a word order of a sentence. We 
call this compound noun structure as a ?senten-
tial NP?. 
Let us exemplify some Thai examples related to 
compound word and serial construction problem 
in Figure 1. The example 1 shows a sentence 
which contains a combination of nouns and 
verbs. It can be ambiguously represented into 
two structures. The first alternative is that this 
sentence shows an evidence of a serial verb 
construction. The first word serves as a subject 
of the two following predicates. Another alter-
native is that the first three word can be formed 
together as a compound noun and they refer to 
?a taxi driver? which serve as a subject of the 
following verb and noun. The second alternative 
is more commonly used in practical language. 
However, to set the ?N V N? pattern as a noun 
can be very ambiguous since in the example 1 
can be formed a sentential NP from either the 
first three words or the last three words. 
From the Example 2, an auxiliary verb serial-
ization is represented. It is a combination of 
auxiliary verbs and verb. The word order is 
shown in Aux Aux Aux Aux V N sequence. 
The given examples show complex cases that 
require chunking to reduce an ambiguity while 
Thai text is applied into a syntactical analysis 
such as parsing. Moreover, there is more chance 
to get a syntactically incorrect result from either 
rule-based parser or statistical parser with a high 
amount of word per input. 
This paper is organized as follows. Section 2 
explains Thai categorial grammar. Section 3 
130
illustrates CRF, which is supervised method 
applied in this work.  Section 4 explains the 
methodology and experiment framework. Sec-
tion 5 shows experiments setting and result. 
Section 6 shows discussion. Conclusion and 
future work are illustrated in section 7. 
2 Linguistic Knowledge 
2.1 Categorial Grammar 
Categorial grammar (Aka. CG or classical cate-
gorial grammar) (Ajdukiewicz, 1935; Bar-
Hillel, 1953; Carpenter, 1992; Buszkowski, 
1998; Steedman, 2000) is formalism in natural 
language syntax motivated by the principle of 
constitutionality and organized according to the 
syntactic elements. The syntactic elements are 
categorised in terms of their ability to combine 
with one another to form larger constituents as 
functions or according to a function-argument 
relationship. All syntactic categories in CG are 
distinguished by a syntactic category identifying 
them as one of the following two types: 
1. Argument: this type is a basic category, 
such as s (sentence) and np (noun 
phrase).  
2. Functor (or function category): this cat-
egory type is a combination of argu-
ment and operator(s) '/' and '\'. Functor 
is marked to a complex constituent to 
assist argument to complete sentence 
such as s\np (intransitive verb) requires 
noun phrase from the left side to com-
plete a sentence. 
CG captures the same information by associ-
ating a functional type or category with all 
grammatical entities. The notation ?/? is a 
rightward-combining functor over a domain of ? 
into a range of ?. The notation ?\? is a leftward-
combining functor over ? into ?. ? and ? are 
both argument syntactic categories 
(Hockenmaier and Steedman, 2002; Baldridge 
and Kruijff, 2003). 
The basic concept is to find the core of the 
combination and replace the grammatical modi-
fier and complement with set of categories 
based on the same concept with fractions. For 
example, intransitive verb is needed to combine 
with a subject to complete a sentence therefore 
intransitive verb is written as s\np which means  
Figure 2 Example of Thai CG-parsed Tree. 
it needs a noun phrase from the left side to  
complete a sentence. If there is a noun phrase 
exists on the left side, the rule of fraction can-
cellation is applied as np*s\np = s. With CG, 
each constituent is annotated with its own syn-
tactic category as its function in text. Currently 
there are 79 categories in Thai. An example of 
CG derivation from Thai is shown in Figure 2.  
2.2 CG-Set 
CG-Set are used as a feature when no CG are 
tagged to the input. We aim to apply our chunk-
er to a real world application. Therefore, in case 
that we have only sentence without CG tags, we 
will use CG-Set instead.           
Cat-
Set 
Index 
Cat-Set Member 
0 np ????????? 
2 s\np/pp,s\np/np,s\np/pp/np,s\np ????, ???? 
3 
(np\np)/(np\np), 
((s\np)\(s\np))/spnum, 
np, 
(np\np)\num,np\num, 
(np\np)/spnum, 
((s\np)\(s\np))\num 
????, 
?????? 
62 (s\np)\(s\np),s\s ??'?, ??'?, ??? 
134 np/(s\np), 
np/((s\np)/np) ???, ???? 
Table 1 Example of CG-Set  
131
The concept of CG-Set is to group words that 
their all possible CGs are equivalent to the 
other. Therefore every word will be assigned to 
only one CG-Set. By using CG-Set we use the 
lookup table for tagging the input. Table 1 
shows examples of CG-set. Currently, there are 
183 CG set. 
3 Conditional Random Field (CRF) 
CRF is an undirected graph model in which 
each vertex represents a random variable whose 
distribution is to be inferred, and edge 
represents a dependency between two random 
variables. It is a supervised framework for 
labeling a sequence data such as POS tagging 
and chunking. Let X  is a random variable of 
observed input sequence, such as sequence of 
words, and Y is a random variable of label 
sequence corresponding to X , such as sequence 
of POS or CG. The most probable label 
sequence ( y? ) can be obtain by 
                     )|(maxarg? xypy =  
 Where nxxxx ,...,, 21= and nyyyy ,...,, 21=  
)|( xyp  is the conditional probability 
distribution of a label sequence given by an 
input sequence. CRF defines )|( xyp as 
                  ?
?
??
?
?= ?
=
n
i
ixyF
Z
xyP
1
),,(exp1)|(  
where ( )? ? == y ni ixyFZ 1 ),,(exp  is a 
normalization factor over all state sequences. 
),,( ixyF  is the global feature vector of CRF 
for sequence x and y at position i . ),,( ixyF  
can be calculated by using summation of local 
features. 
?? += ?
j
jj
i
iiii tyxgtyyfixyF ),,(),,(),,( 1 ??
Each local feature consists of transition feature 
function ),,( 1 tyyf iii ?  and per-state feature 
function ),,( tyxg j . Where i? and j? are 
weight vectors of transition feature function and 
per-state feature function respectively.  
The parameter of CRF can be calculated by 
maximizing the likelihood function on the 
training data. Viterbi algorithm is normally 
applied for searching the most suitable output. 
4 Methodology 
Figure 3 shows the methodology of our 
experiments. To prepare the training set, we 
start with our corpus annotated with CG tag. 
Then, each sentence in the corpus was parsed by 
Figure 3 Experimental Framework 
132
our Thai CG parser, developed by GLR tech-
technique. However, not all sentences can be 
parsed successfully due to the complexity of the 
sentence. We kept parsable sentences and 
unparsable sentences separately. The parsable 
sentences were selected to be the training set.  
There are four features ? surface, CG, CG-set 
and chunk marker ? in our experiments. CRF is 
applied using 5-fold cross validation over 
combination of these features. Accuracy in term 
of averaged precision and recall are reported. 
We select the best model from the experiment 
to implement the chunker. To investigate 
performance of the chunker, we feed the 
unparsable sentences to the chunker and 
evaluate them manually.  
After that, the sentences which are correctly 
chunked will be sent to our Thai CG parser. We 
calculate the number of successfully-parsed 
sentences and the number of correct chunks. 
5 Experiment Settings and Results 
5.1 Experiment on chunking 
5.1.1 Experiment setting 
To develop chunker, we apply CG Dictionary 
and CG tagged corpus as input. Four features 
are provided to CRF. Surface is a word surface. 
CG is a categorial grammar of the word. CG-set 
is a combination of CG of the word. IOB 
represents a method to mark chunk in a 
sentence. "I" means "inner" which represents 
the word within the chunk. "O" means "outside" 
which represents the word outside the chunk. 
"B" means "boundary" which represents the 
word as a boundary position. It accompanied 
with five chunk types. "NP" stands for noun 
phrase, "VP" stands for verb phrase, "PP" stands 
for preposition phrase, "ADVP" stands for 
adverb phrase and S-BAR stands for 
complementizer that link two phrases.  
Surface and CG-set are developed from CG 
dictionary. CG is retrieved from CG tagged 
corpus. IOB is developed by parsing tree. We 
apply Thai CG parser to obtain the parsed tree. 
Figure 4 shows an example of our prepared 
data. We provide 4,201 sentences as a training 
data in CRF to obtain a chunked model. In this 
experiment, we use 5-fold cross validation to 
evaluation the model in term of F-measure.  
surface cg_set cg chunk_label 
?? 74 s/s/np B-ADVP 
??? 3 np I-ADVP 
?? 180 (np\np)/(s\np) I-ADVP 
?? ? 54 (s\np)/(s\np) I-ADVP 
???? 7 s\np I-ADVP 
???? 130 ((s/s)\(s/s))/(s/s) I-ADVP 
?? 74 s/s/np I-ADVP 
??????? 0 np I-ADVP 
??? 0 np B-NP 
??? 8 s\np/np B-VP 
???'? 0 np B-NP 
?? 148 (s\np)/(s\np) B-VP 
???????? 2 s\np I-VP 
Figure 4 An example of prepared data 
 
Table 2 Chunking accuracy of each chunk 
133
  
5.1.2 Experiment result 
From Table 2, considering on chunk based lev-
el, we found that CG gives the best result 
among surface, CG-set, CG and their combina-
tion. The average on three types in terms of F-
measure is 86.20.  When we analyze infor-
mation in detail, we found that NP, VP and PP 
show the same results. Using CG shows the F-
measure for each of them, 81.15, 90.96 and 
99.56 respectively.   
From Table 3, considering in both word level 
and sentence level, we got the similar results, 
CG gives the best results. F-measure is 93.24 in 
word level and 74.17 in sentence level. This 
shows the evidence that CG plays an important 
role to improve the accuracy on chunking. 
5.2 Experiment on parsing 
5.2.1 Experiment setting 
We investigate the improvement of parsing con-
sidering unparsable sentences.  There are 14,885 
unparsable sentences from our CG parser. These 
sentences are inputted in chunked model to ob-
tain a chunked corpus. We manually evaluate 
the results by linguist. Linguists evaluate the 
chunked output in three types. 0 means incorrect 
chunk. 1 means correct chunk and 2 represents a 
special case for Thai NP, a sentential NP. 
5.2.2 Experiment result 
From the experiment, we got an impressive re-
sult. We found that 11,698 sentences (78.59%) 
are changed from unparsable to parsable sen-
tence. Only 3,187 (21.41%) are unparsable.  We 
manually evaluate the parsable sentence by ran-
domly select 7,369 sentences. Linguists found 
3,689 correct sentences (50.06%). In addition, 
we investigate the number of parsable chunk 
calculated from the parsable result and found 
37,743 correct chunks from 47,718 chunks 
(78.47%).  We also classified chunk into three 
types NN VP and PP and gain the accuracy in 
each type 79.14% ,74.66% and 92.57% respec-
tively. 
6 Discussion 
6.1 Error analysis 
From the experiment results, we found the fol-
lowing errors. 
6.1.1 Chunking Type missing 
Some chunk missing types are found in experi-
ment results. For example, [PP ?????? (rec-
ord)][NP ????????????????? (character about)]. [PP 
Table 3 Chunking accuracy based on  
word and sentence. 
Figure 4 An Example of sentential NP 
134
?????? (record)] should be defined as VP instead 
of PP. 
6.1.2 Over-grouping 
In the sentence ?[VP ?? ? (Using)][NP 
(medicine)][VP ????? (treat) ][NP ???????????' ?????
?????? (each disease have to)][PP ??? (follow) ]
[NP ???????????????? ?(doctor?s instruction)] ?, we 
found that ?NP ???????????' ??????????? (each disease 
have to) ? has over-grouping. IT is necessary to 
breakdown to NP ???????????' ?(each disease)  and  
VP ??????????(have to). The reason of this error is 
due to allow the sentential structure NP VP NP, 
and then NP and VP are combined. 
6.1.3 Sentential NP 
We investigated the number of sentential NP. If 
the number of chunk equal to 1, sentence should 
not be recognized as NP. Other cases are de-
fined as NP. We found that 929 from 1,584 sen-
tences (58.65 % of sentences) are correct sen-
tential NP. This evidence shows the impressive 
results to solve implicit NP in Thai. Figure 4 
shows an example of sentential NP.  
6.1.4 CG-set  
Since CG-set is another representation of word 
and can only detect from CG dictionary. It is 
very easy to develop a tag sequence using CG-
set. We found that CG-set is more powerful than 
surface. It might be another alternative for less 
language resource situation. 
6.2 The Effect of Linguistic Knowledge on 
chunking 
Since CG is formalism in natural language syn-
tax motivated by the principle of constitutionali-
ty and organised according to the syntactic ele-
ments, we would like to find out whether lin-
guistic knowledge effects to the model. We 
grouped 89 categorial grammars into 17 groups, 
called CG-17.  
It is categorized into Noun, Prep, Noun 
Modifier, Number modifier for noun, Number 
modifier for verb, Number, Clause Marker, 
Verb with no argument, Verb with 1 argument, 
Verb with 2 or more arguments, Prefix noun, 
Prefix predicate, Prefix predicate modifier, 
Noun linker, Predicate Modification, Predicate 
linker, and Sentence Modifier.  
We found that F-measure is slightly improved 
from 74.17% to 75.06%. This shows the evi-
dence that if we carefully categorized data based 
on linguistics viewpoint, it may improve more 
accuracy.  
7 Conclusions and Future Work 
In this paper, we stated Thai language problems 
on the long sentence pattern and find the novel 
method to chunk sentence into smaller unit, 
which larger than word. We concluded that us-
ing CRF accompanied with categorical grammar 
show the impressive results. The accuracy of 
chunking in sentence level is 74.17%. We are 
possible to collect 50% more on correct tree. 
This technique enables us to solve the implicit 
sentential NP problem. With our technique, we 
found 58% of implicit sentential NP. In the fu-
ture work, there are several issues to be im-
proved. First, we have to trade-off between 
over-grouping problem and implicit sentential 
problem. Second, we plan to consider ADVP, 
SBAR, which has a very small size of data. It is 
not adequate to train for a good result. Finally, 
we plan to apply more linguistics knowledge to 
assist more accuracy. 
References 
Abney S., and Tenny C., editors, 1991. Parsing 
by chunks, Priciple-based Parsing. Kluwer 
Academic Publishers. 
Awasthi P., Rao D., Ravindram B., 2006. Part 
of Speech Tagging and Chunking with HMM 
and CRF, Proceeding of the NLPAI Machine 
Learning Competition. 
Basili R., Pazienza T., and Massio F., 1999. 
Lexicalizing a shallow parser, Proceedings of 
135
Traitement Automatique du Langage Naturel 
1999. Corgese, Corsica. 
Charoenporn Thatsanee, Sornlertlamvanich Vi-
rach,  and Isahara Hitoshi. 1997. Building A 
Large Thai Text Corpus - Part-Of-Speech 
Tagged Corpus: ORCHID. Proceedings of 
Natural Language Processing Pacific Rim 
Symposium. 
Kosawat Krit, Boriboon Monthika, Chootrakool 
Patcharika, Chotimongkol Ananlada, Klaithin 
Supon, Kongyoung Sarawoot, Kriengket 
Kanyanut, Phaholphinyo Sitthaa, Puroda-
kananda Sumonmas,Thanakulwarapas 
Tipraporn, and Wutiwiwatchai Chai. 2009. 
BEST 2009: Thai Word Segmentation Soft-
ware Contest. The Eigth International Sym-
posium on Natural Language Processing  : 
83-88. 
Kruengkrai C., Sornlertlumvanich V., Isahara H, 
2006. A Conditional Random Field Frame-
work for Thai Morphological Analysis, Pro-
ceedings of 5th International Conference on 
Language Resources and Evaluation (LREC-
2006). 
Kudo T., and Matsumoto Y., 2001. Chunking 
with support vector machines, Proceeding of 
NAACL. 
Lafferty J., McCallum A., and Pereira F., 2001. 
Conditional Random Fields : Probabilistic 
models for segmenting and labeling sequence 
data. In Proceeding of ICML-01, 282-289. 
McCallum A., Freitag D., and Pereira F. 2000. 
Maximum entropy markov model for infor-
mation extraction and segmentation. Pro-
ceedings of ICML. 
Molina A., and Pla F., 2002. Shallow Parsing 
using Specialized HMMs, Journal of Machine 
Learning Research 2,595-613 
Nguyen L. Minh, Nguyen H. Thao, and Nguyen 
P., Thai. 2009. An Empirical Study of Viet-
namese Noun Phrase Chunking with Discrim-
inative Sequence Models, Proceedings of the 
7th Workshop on Asian Language Resources, 
ACL-IJCNLP 2009,9-16 
Osborne M. 2000. Shallow Parsing as Part-of-
Speech Tagging. Proceedings of CoNLL-
2000 and LLL-2000, Lisbon, Portugal. 
Pengphon N., Kawtrakul A., Suktarachan M., 
2002. Word Formation Approach to Noun 
Phrase Analysis for Thai,  Proceedings of 
SNLP2002. 
Sha F. and Pereira F., 2003. Shallow Parsing 
with Conditional Random Fields, Proceeding 
of HLT-NAACL. 
 
136
