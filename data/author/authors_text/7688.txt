Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 827?834,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Infrastructure for standardization of Asian language resources
Tokunaga Takenobu
Tokyo Inst. of Tech.
Virach Sornlertlamvanich
TCL, NICT
Thatsanee Charoenporn
TCL, NICT
Nicoletta Calzolari
ILC/CNR
Monica Monachini
ILC/CNR
Claudia Soria
ILC/CNR
Chu-Ren Huang
Academia Sinica
Xia YingJu
Fujitsu R&D Center
Yu Hao
Fujitsu R&D Center
Laurent Prevot
Academia Sinica
Shirai Kiyoaki
JAIST
Abstract
As an area of great linguistic and cul-
tural diversity, Asian language resources
have received much less attention than
their western counterparts. Creating a
common standard for Asian language re-
sources that is compatible with an interna-
tional standard has at least three strong ad-
vantages: to increase the competitive edge
of Asian countries, to bring Asian coun-
tries to closer to their western counter-
parts, and to bring more cohesion among
Asian countries. To achieve this goal, we
have launched a two year project to create
a common standard for Asian language re-
sources. The project is comprised of four
research items, (1) building a description
framework of lexical entries, (2) building
sample lexicons, (3) building an upper-
layer ontology and (4) evaluating the pro-
posed framework through an application.
This paper outlines the project in terms of
its aim and approach.
1 Introduction
There is a long history of creating a standard
for western language resources. The human
language technology (HLT) society in Europe
has been particularly zealous for the standardiza-
tion, making a series of attempts such as EA-
GLES1, PAROLE/SIMPLE (Lenci et al, 2000),
ISLE/MILE (Calzolari et al, 2003) and LIRICS2.
These continuous efforts has been crystallized as
activities in ISO-TC37/SC4 which aims to make
an international standard for language resources.
1http://www.ilc.cnr.it/Eagles96/home.html
2lirics.loria.fr/documents.html
(1) Description 
framework of lexical 
entries
(2) Sample lexicons
(4) Evaluation 
through application
(3) Upper layer 
ontologyrefinement
description classification
refinement
evaluationevaluation
Figure 1: Relations among research items
On the other hand, since Asia has great lin-
guistic and cultural diversity, Asian language re-
sources have received much less attention than
their western counterparts. Creating a common
standard for Asian language resources that is com-
patible with an international standard has at least
three strong advantages: to increase the competi-
tive edge of Asian countries, to bring Asian coun-
tries to closer to their western counterparts, and to
bring more cohesion among Asian countries.
To achieve this goal, we have launched a two
year project to create a common standard for
Asian language resources. The project is com-
prised of the following four research items.
(1) building a description framework of lexical
entries
(2) building sample lexicons
(3) building an upper-layer ontology
(4) evaluating the proposed framework through
an application
Figure 1 illustrates the relations among these re-
search items.
Our main aim is the research item (1), building
a description framework of lexical entries which
827
fits with as many Asian languages as possible, and
contributing to the ISO-TC37/SC4 activities. As
a starting point, we employ an existing descrip-
tion framework, the MILE framework (Bertagna
et al, 2004a), to describe several lexical entries of
several Asian languages. Through building sam-
ple lexicons (research item (2)), we will find prob-
lems of the existing framework, and extend it so
as to fit with Asian languages. In this extension,
we need to be careful in keeping consistency with
the existing framework. We start with Chinese,
Japanese and Thai as target Asian languages and
plan to expand the coverage of languages. The re-
search items (2) and (3) also comprise the similar
feedback loop. Through building sample lexicons,
we refine an upper-layer ontology. An application
built in the research item (4) is dedicated to evalu-
ating the proposed framework. We plan to build an
information retrieval system using a lexicon built
by extending the sample lexicon.
In what follows, section 2 briefly reviews the
MILE framework which is a basis of our de-
scription framework. Since the MILE framework
is originally designed for European languages, it
does not always fit with Asian languages. We ex-
emplify some of the problems in section 3 and sug-
gest some directions to solve them. We expect
that further problems will come into clear view
through building sample lexicons. Section 4 de-
scribes a criteria to choose lexical entries in sam-
ple lexicons. Section 5 describes an approach
to build an upper-layer ontology which can be
sharable among languages. Section 6 describes
an application through which we evaluate the pro-
posed framework.
2 The MILE framework for
interoperability of lexicons
The ISLE (International Standards for Language
Engineering) Computational Lexicon Working
Group has consensually defined the MILE (Mul-
tilingual ISLE Lexical Entry) as a standardized
infrastructure to develop multilingual lexical re-
sources for HLT applications, with particular at-
tention toMachine Translation (MT) and Crosslin-
gual Information Retrieval (CLIR) application
systems.
The MILE is a general architecture devised
for the encoding of multilingual lexical informa-
tion, a meta-entry acting as a common representa-
tional layer for multilingual lexicons, by allowing
integration and interoperability between different
monolingual lexicons3.
This formal and standardized framework to en-
code MILE-conformant lexical entries is provided
to lexicon and application developers by the over-
all MILE Lexical Model (MLM). As concerns
the horizontal organization, the MLM consists of
two independent, but interlinked primary compo-
nents, the monolingual and the multilingual mod-
ules. The monolingual component, on the vertical
dimension, is organized over three different repre-
sentational layers which allow to describe differ-
ent dimensions of lexical entries, namely the mor-
phological, syntactic and semantic layers. More-
over, an intermediate module allows to define
mechanisms of linkage and mapping between the
syntactic and semantic layers. Within each layer, a
basic linguistic information unit is identified; basic
units are separated but still interlinked each other
across the different layers.
Within each of the MLM layers, different types
of lexical object are distinguished :
? the MILE Lexical Classes (MLC) represent
the main building blocks which formalize
the basic lexical notions. They can be seen
as a set of structural elements organized in
a layered fashion: they constitute an on-
tology of lexical objects as an abstraction
over different lexical models and architec-
tures. These elements are the backbone of
the structural model. In the MLM a defini-
tion of the classes is provided together with
their attributes and the way they relate to each
other. Classes represent notions like Inflec-
tionalParadigm, SyntacticFunction, Syntac-
ticPhrase, Predicate, Argument,
? the MILE Data Categories (MDC) which
constitute the attributes and values to adorn
the structural classes and allow concrete en-
tries to be instantiated. MDC can belong to
a shared repository or be user-defined. ?NP?
and ?VP? are data category instances of the
class SyntacticPhrase, whereas and ?subj?
and ?obj? are data category instances of the
class SyntacticFunction.
? lexical operations, which are special lexical
entities allowing the user to define multilin-
3MILE is based on the experience derived from exist-
ing computational lexicons (e.g. LE-PAROLE, SIMPLE, Eu-
roWordNet, etc.).
828
gual conditions and perform operations on
lexical entries.
Originally, in order to meet expectations placed
upon lexicons as critical resources for content pro-
cessing in the Semantic Web, the MILE syntactic
and semantic lexical objects have been formalized
in RDF(S), thus providing a web-based means to
implement the MILE architecture and allowing for
encoding individual lexical entries as instances of
the model (Ide et al, 2003; Bertagna et al, 2004b).
In the framework of our project, by situating our
work in the context of W3C standards and relying
on standardized technologies underlying this com-
munity, the original RDF schema for ISLE lexi-
cal entries has been made compliant to OWL. The
whole data model has been formalized in OWL by
using Prote?ge? 3.2 beta and has been extended to
cover the morphological component as well (see
Figure 2). Prote?ge? 3.2 beta has been also used as
a tool to instantiate the lexical entries of our sam-
ple monolingual lexicons, thus ensuring adherence
to the model, encoding coherence and inter- and
intra-lexicon consistency.
3 Existing problems with the MILE
framework for Asian languages
In this section, we will explain some problematic
phenomena of Asian languages and discuss pos-
sible extensions of the MILE framework to solve
them.
Inflection The MILE provides the powerful
framework to describe the information about in-
flection. InflectedForm class is devoted to de-
scribe inflected forms of a word, while Inflec-
tionalParadigm to define general inflection rules.
However, there is no inflection in several Asian
languages, such as Chinese and Thai. For these
languages, we do not use the Inflected Form and
Inflectional Paradigm.
Classifier Many Asian languages, such as
Japanese, Chinese, Thai and Korean, do not dis-
tinguish singularity and plurality of nouns, but use
classifiers to denote the number of objects. The
followings are examples of classifiers of Japanese.
? inu
(dog)
ni
(two)
hiki
(CL)
? ? ? two dogs
? hon
(book)
go
(five)
satsu
(CL)
? ? ? five books
?CL? stands for a classifier. They always follow
cardinal numbers in Japanese. Note that differ-
ent classifiers are used for different nouns. In the
above examples, classifier ?hiki? is used to count
noun ?inu (dog)?, while ?satsu? for ?hon (book)?.
The classifier is determined based on the semantic
type of the noun.
In the Thai language, classifiers are used in var-
ious situations (Sornlertlamvanich et al, 1994).
The classifier plays an important role in construc-
tion with noun to express ordinal, pronoun, for in-
stance. The classifier phrase is syntactically gener-
ated according to a specific pattern. Here are some
usages of classifiers and their syntactic patterns.
? Enumeration
(Noun/Verb)-(cardinal number)-(CL)
e.g. nakrian
(student)
3 khon
(CL)
? ? ? three students
? Ordinal
(Noun)-(CL)-/thi:/-(cardinal number)
e.g. kaew
(glass)
bai
(CL)
thi: 4
(4th)
? ? ? the 4th glass
? Determination
(Noun)-(CL)-(Determiner)
e.g. kruangkhidlek
(calculator)
kruang
(CL)
nii
(this)
? ? ? this calculator
Classifiers could be dealt as a class of the part-
of-speech. However, since classifiers depend on
the semantic type of nouns, we need to refer to
semantic features in the morphological layer, and
vice versa. Some mechanism to link between fea-
tures beyond layers needs to be introduced into the
current MILE framework.
Orthographic variants Many Chinese words
have orthographic variants. For instance, the con-
cept of rising can be represented by either char-
acter variants of sheng1: ? or ?. However,
the free variants become non-free in certain com-
pound forms. For instance, only? allowed for?
? ?liter?, and only? is allowed for?? ?to sub-
lime?. The interaction of lemmas and orthographic
variations is not yet represented in MILE.
Reduplication as a derivational process In
some Asian languages, reduplication of words de-
rives another word, and the derived word often has
a different part-of-speech. Here are some exam-
ples of reduplication in Chinese. Man4 ? ?to be
slow? is a state verb, while a reduplicated form
829
Inflectional
Paradigm
Lexical Entry SyntacticUnit
Form Lemmatized Form Stem
Inflected Form
Combiner
Calculator Mrophfeat
Operation Argument
Morph
DataCats
0..*
0..* 0..*
0..*
0..*
0..1
0..*
0..*
1..*
<LemmatizedForm rdf:ID="LFstar">
  <hasInflectedForm>
    <InflectedForm rdf:ID="stars">
      <hasMorphoFeat>
<MorphoFeat rdf:ID="pl">
  <number rdf:datatype="http://www.w3c.org/
2001/ XMLSchema#string">
    plural
  </number>
</MorphoFeat>
      </hasMorphoFeat>
    </InflectedForm>
  </hasInflectedForm>
  <hasInflectedForm>
    <InflectedForm rdf:ID="star">
      <hasMorphoFeat>
<MorphoFeat rdf:ID="sg">
  <number rdf:datatype="http://www.w3c.org/
2001/ XMLSchema#string">
    singular
  </number>
</MorphoFeat>
      </hasMorphoFeat>
    </InflectedForm>
  </hasInflectedForm>
</LemmatiedForm>
Figure 2: Formalization of the morphological layer and excerpt of a sample RDF instantiation
man4-man4 ?? is an adverb. Another example
of reduplication involves verbal aspect. Kan4 ?
?to look? is an activity verb, while the reduplica-
tive form kan4-kan4 ??, refers to the tentative
aspect, introducing either stage-like sub-division
or the event or tentativeness of the action of the
agent. This morphological process is not provided
for in the current MILE standard.
There are also various usages of reduplication in
Thai. Some words reduplicate themselves to add a
specific aspect to the original meaning. The redu-
plication can be grouped into 3 types according to
the tonal sound change of the original word.
? Word reduplication without sound change
e.g. /dek-dek/ ? ? ? (N) children, (ADV) child-
ishly, (ADJ) childish
/sa:w-sa:w/ ? ? ? (N) women
? Word reduplication with high tone on the first
word
e.g. /dam4-dam/ ? ? ? (ADJ) extremely black
/bo:i4-bo:i/ ? ? ? (ADV) really often
? Triple word reduplication with high tone on
the second word
e.g. /dern-dern4-dern/ ?? (V) intensively walk
/norn-norn4-norn/??(V) intensively sleep
In fact, only the reduplication of the same sound
is accepted in the written text, and a special sym-
bol, namely /mai-yamok/ is attached to the origi-
nal word to represent the reduplication. The redu-
plication occurs in many parts-of-speech, such as
noun, verb, adverb, classifier, adjective, preposi-
tion. Furthermore, various aspects can be added
to the original meaning of the word by reduplica-
tion, such as pluralization, emphasis, generaliza-
tion, and so on. These aspects should be instanti-
ated as features.
Change of parts-of-speech by affixes Af-
fixes change parts-of-speech of words in
Thai (Charoenporn et al, 1997). There are
three prefixes changing the part-of-speech of the
original word, namely /ka:n/, /khwa:m/, /ya:ng/.
They are used in the following cases.
? Nominalization
/ka:n/ is used to prefix an action verb and
/khwa:m/ is used to prefix a state verb
in nominalization such as /ka:n-tham-nga:n/
(working), /khwa:m-suk/ (happiness).
? Adverbialization
An adverb can be derived by using /ya:ng/ to
prefix a state verb such as /ya:ng-di:/ (well).
Note that these prefixes are also words, and form
multi-word expressions with the original word.
This phenomenon is similar to derivation which
is not handled in the current MILE framework.
Derivation is traditionally considered as a different
phenomenon from inflection, and current MILE
focuses on inflection. The MILE framework is al-
ready being extended to treat such linguistic phe-
nomenon, since it is important to European lan-
guages as well. It would be handled in either the
morphological layer or syntactic layer.
830
Function Type Function types of predicates
(verbs, adjectives etc.) might be handled in a
partially different way for Japanese. In the syn-
tactic layer of the MILE framework, Function-
Type class is prepared to denote subcategorization
frames of predicates, and they have function types
such as ?subj? and ?obj?. For example, the verb
?eat? has two FunctionType data categories of
?subj? and ?obj?. Function types basically stand
for positions of case filler nouns. In Japanese,
cases are usually marked by postpositions and case
filler positions themselves do not provide much in-
formation on case marking. For example, both of
the following sentences mean the same, ?She eats
a pizza.?
? kanojo
(she)
ga
(NOM)
piza
(pizza)
wo
(ACC)
taberu
(eat)
? piza
(pizza)
wo
(ACC)
kanojo
(she)
ga
(NOM)
taberu
(eat)
?Ga? and ?wo? are postpositions which mark
nominative and accusative cases respectively.
Note that two case filler nouns ?she? and ?pizza?
can be exchanged. That is, the number of slots is
important, but their order is not.
For Japanese, we might use the set of post-
positions as values of FunctionType instead of
conventional function types such as ?subj? and
?obj?. It might be an user defined data category or
language dependent data category. Furthermore,
it is preferable to prepare the mapping between
Japanese postpositions and conventional function
types. This is interesting because it seems more
a terminological difference, but the model can be
applied also to Japanese.
4 Building sample lexicons
4.1 Swadesh list and basic lexicon
The issue involved in defining a basic lexicon for a
given language is more complicated than one may
think (Zhang et al, 2004). The naive approach of
simply taking the most frequent words in a lan-
guage is flawed in many ways. First, all frequency
counts are corpus-based and hence inherit the bias
of corpus sampling. For instance, since it is eas-
ier to sample written formal texts, words used pre-
dominantly in informal contexts are usually under-
represented. Second, frequency of content words
is topic-dependent and may vary from corpus to
corpus. Last, and most crucially, frequency of a
word does not correlate to its conceptual necessity,
which should be an important, if not only, criteria
for core lexicon. The definition of a cross-lingual
basic lexicon is even more complicated. The first
issue involves determination of cross-lingual lexi-
cal equivalencies. That is, how to determine that
word a (and not a?) in language A really is word b
in language B. The second issue involves the deter-
mination of what is a basic word in a multilingual
context. In this case, not even the frequency of-
fers an easy answer since lexical frequency may
vary greatly among different languages. The third
issue involves lexical gaps. That is, if there is a
word that meets all criteria of being a basic word
in language A, yet it does not exist in language D
(though it may exist in languages B, and C). Is this
word still qualified to be included in the multilin-
gual basic lexicon?
It is clear not all the above issues can be un-
equivocally solved with the time frame of our
project. Fortunately, there is an empirical core lex-
icon that we can adopt as a starting point. The
Swadesh list was proposed by the historical lin-
guist Morris Swadesh (Swadesh, 1952), and has
been widely used by field and historical linguists
for languages over the world. The Swadesh list
was first proposed as lexico-statistical metrics.
That is, these are words that can be reliably ex-
pected to occur in all historical languages and can
be used as the metrics for quantifying language
variations and language distance. The Swadesh
list is also widely used by field linguists when
they encounter a new language, since almost all
of these terms can be expected to occur in any
language. Note that the Swadesh list consists of
terms that embody human direct experience, with
culture-specific terms avoided. Swadesh started
with a 215 items list, before cutting back to 200
items and then to 100 items. A standard list of
207 items is arrived at by unifying the 200 items
list and the 100 items list. We take the 207 terms
from the Swadesh list as the core of our basic lex-
icon. Inclusion of the Swadesh list also gives us
the possibility of covering many Asian languages
in which we do not have the resources to make a
full and fully annotated lexicon. For some of these
languages, a Swadesh lexicon for reference is pro-
vided by a collaborator.
4.2 Aligning multilingual lexical entries
Since our goal is to build a multilingual sample
lexicon, it is required to align words in several
831
Asian languages. In this subsection, we propose
a simple method to align words in different lan-
guages. The basic idea for multilingual alignment
is an intermediary by English. That is, first we
prepare word pairs between English and other lan-
guages, then combine them together to make cor-
respondence among words in several languages.
The multilingual alignment method currently we
consider is as follows:
1. Preparing the set of frequent words of each
language
Suppose that {Jw
i
}, {Cw
i
}, {Tw
i
} is the
set of frequent words of Japanese, Chinese
and Thai, respectively. Now we try to con-
struct a multilingual lexicon for these three
languages, however, our multilingual align-
ment method can be easily extended to han-
dle more languages.
2. Obtaining English translations
A word Xw
i
is translated into a set of En-
glish words EXw
ij
by referring to the bilin-
gual dictionary, where X denotes one of our
languages, J , C or T . We can obtain map-
pings as in (1).
Jw
1
: EJw
11
, EJw
12
, ? ? ?
Jw
2
: EJw
21
, EJw
22
, ? ? ?
...
Cw
1
: ECw
11
, ECw
12
, ? ? ?
Cw
2
: ECw
21
, ECw
22
, ? ? ?
...
Tw
1
: ETw
11
, ETw
12
, ? ? ?
Tw
2
: ETw
21
, ETw
22
, ? ? ?
...
(1)
Notice that this procedure is automatically
done and ambiguities would be left at this
stage.
3. Generating new mapping
From mappings in (1), a new mapping is gen-
erated by inverting the key. That is, in the
new mapping, a key is an English word Ew
i
and a correspondence for each key is sets
of translations XEw
ij
for 3 languages, as
shown in (2):
Ew
1
: (JEw
11
, JEw
12
, ? ? ?)
(CEw
11
, CEw
12
, ? ? ?)
(TEw
11
, TEw
12
, ? ? ?)
Ew
2
: (JEw
21
, JEw
22
, ? ? ?)
(CEw
21
, CEw
22
, ? ? ?)
(TEw
21
, TEw
22
, ? ? ?)
...
(2)
Notice that at this stage, correspondence be-
tween different languages is very loose, since
they are aligned on the basis of sharing only
a single English word.
4. Refinement of alignment
Groups of English words are constructed by
referring to the WordNet synset information.
For example, suppose that Ew
i
and Ew
j
be-
long to the same synset S
k
. We will make a
new alignment by making an intersection of
{XEw
i
} and {XEw
j
} as shown in (3).
Ew
i
: (JEw
i1
, ??) (CEw
i1
, ??) (TEw
i1
, ??)
Ew
j
: (JEw
j1
, ??)(CEw
j1
, ??)(TEw
j1
, ??)
? intersection
S
k
: (JEw?
k1
, ??)(CEw?
k1
, ??)(TEw?
k1
, ??)
(3)
In (3), the key is a synset S
k
, which is sup-
posed to be a conjunction of Ew
i
and Ew
j
,
and the counterpart is the intersection of set
of translations for each language. This oper-
ation would reduce the number of words of
each language. That means, we can expect
that the correspondence among words of dif-
ferent languages becomes more precise. This
new word alignment based on a synset is a
final result.
To evaluate the performance of this method,
we conducted a preliminary experiment using the
Swadesh list. Given the Swadesh list of Chi-
nese, Italian, Japanese and Thai as a gold stan-
dard, we tried to replicate these lists from the En-
glish Swadesh list and bilingual dictionaries be-
tween English and these languages. In this experi-
ment, we did not perform the refinement step with
WordNet. From 207 words in the Swadesh list,
we dropped 4 words (?at?, ?in?, ?with? and ?and?)
due to their too many ambiguities in translation.
As a result, we obtained 181 word groups
aligned across 5 languages (Chinese, English, Ital-
ian, Japanese and Thai) for 203 words. An
aligned word group was judged ?correct? when the
words of each language include only words in the
Swadesh list of that language. It was judged ?par-
tially correct? when the words of a language also
include the words which are not in the Swadesh
list. Based on the correct instances, we obtain
0.497 for precision and 0.443 for recall. These fig-
ures go up to 0.912 for precision and 0.813 for re-
call when based on the partially correct instances.
This is quite a promising result.
832
5 Upper-layer ontology
The empirical success of the Swadesh list poses
an interesting question that has not been explored
before. That is, does the Swadesh list instantiates a
shared, fundamental human conceptual structure?
And if there is such as a structure, can we discover
it?
In the project these fundamental issues are as-
sociated with our quest for cross-lingual interop-
erability. We must make sure that the items of
the basic lexicon are given the same interpreta-
tion. One measure taken to ensure this consists in
constructing an upper-ontology based on the ba-
sic lexicon. Our preliminary work of mapping the
Swadesh list items to SUMO (Suggested Upper
Merged Ontology) (Niles and Pease, 2001) has al-
ready been completed. We are in the process of
mapping the list to DOLCE (Descriptive Ontology
for Linguistic and Cognitive Engineering) (Ma-
solo et al, 2003). After the initial mapping, we
carry on the work to restructure the mapped nodes
to form a genuine conceptual ontology based on
the language universal basic lexical items. How-
ever one important observation that we have made
so far is that the success of the Swadesh list is
partly due to its underspecification and to the lib-
erty it gives to compilers of the list in a new lan-
guage. If this idea of underspecification is essen-
tial for basic lexicon for human languages, then we
must resolve this apparent dilemma of specifying
them in a formal ontology that requires fully spec-
ified categories. For the time being, genuine ambi-
guities resulted in the introduction of each disam-
biguated sense in the ontology. We are currently
investigating another solution that allows the in-
clusion of underspecified elements in the ontology
without threatening its coherence. More specifi-
cally we introduce a underspecified relation in the
structure for linking the underspecified meaning
to the different specified meaning. The specified
meanings are included in the taxonomic hierarchy
in a traditional manner, while a hierarchy of un-
derspecified meanings can be derived thanks to the
new relation. An underspecified node only inherits
from the most specific common mother of its fully
specified terms. Such distinction avoids the clas-
sical misuse of the subsumption relation for rep-
resenting multiple meanings. This method does
not reflect a dubious collapse of the linguistic and
conceptual levels but the treatment of such under-
specifications as truly conceptual. Moreover we
Internet
Query
Local 
DB
User interest
 model
Topic
Feedback
Search
engine
Crawler
Retrieval
results
Figure 3: The system architecture
hope this proposal will provide a knowledge rep-
resentation framework for the multilingual align-
ment method presented in the previous section.
Finally, our ontology will not only play the role
of a structured interlingual index. It will also serve
as a common conceptual base for lexical expan-
sion, as well as for comparative studies of the lex-
ical differences of different languages.
6 Evaluation through an application
To evaluate the proposed framework, we are build-
ing an information retrieval system. Figure 3
shows the system architecture.
A user can input a topic to retrieve the docu-
ments related to that topic. A topic can consist
of keywords, website URL?s and documents which
describe the topic. From the topic information, the
system builds a user interest model. The system
then uses a search engine and a crawler to search
for information related to this topic in WWW and
stores the results in the local database. Generally,
the search results include many noises. To filter
out these noises, we build a query from the user
interest model and then use this query to retrieve
documents in the local database. Those documents
similar to the query are considered as more related
to the topic and the user?s interest, and are returned
to the user. When the user obtains these retrieval
results, he can evaluate these documents and give
the feedback to the system, which is used for the
further refinement of the user interest model.
Language resources can contribute to improv-
ing the system performance in various ways.
Query expansion is a well-known technique which
expands user?s query terms into a set of similar and
related terms by referring to ontologies. Our sys-
tem is based on the vector space model (VSM) and
traditional query expansion can be applicable us-
ing the ontology.
There has been less research on using lexical in-
833
formation for information retrieval systems. One
possibility we are considering is query expansion
by using predicate-argument structures of terms.
Suppose a user inputs two keywords, ?hockey?
and ?ticket? as a query. The conventional query
expansion technique expands these keywords to
a set of similar words based on an ontology. By
referring to predicate-argument structures in the
lexicon, we can derive actions and events as well
which take these words as arguments. In the above
example, by referring to the predicate-argument
structure of ?buy? or ?sell?, and knowing that
these verbs can take ?ticket? in their object role,
we can add ?buy? and ?sell? to the user?s query.
This new type of expansion requires rich lexical
information such as predicate argument structures,
and the information retrieval system would be a
good touchstone of the lexical information.
7 Concluding remarks
This paper outlined a new project for creating a
common standard for Asian language resources
in cooperation with other initiatives. We start
with three Asian languages, Chinese, Japanese
and Thai, on top of the existing framework which
was designed mainly for European languages.
We plan to distribute our draft to HLT soci-
eties of other Asian languages, requesting for
their feedback through various networks, such
as the Asian language resource committee net-
work under Asian Federation of Natural Language
Processing (AFNLP)4, and Asian Language Re-
source Network project5. We believe our ef-
forts contribute to international activities like ISO-
TC37/SC46 (Francopoulo et al, 2006) and to the
revision of the ISO Data Category Registry (ISO
12620), making it possible to come close to the
ideal international standard of language resources.
Acknowledgment
This research was carried out through financial
support provided under the NEDO International
Joint Research Grant Program (NEDO Grant).
References
F. Bertagna, A. Lenci, M. Monachini, and N. Calzo-
lari. 2004a. Content interoperability of lexical re-
sources, open issues and ?MILE? perspectives. In
4http://www.afnlp.org/
5http://www.language-resource.net/
6http://www.tc37sc4.org/
Proceedings of the 4th International Conference on
Language Resources and Evaluation (LREC2004),
pages 131?134.
F. Bertagna, A. Lenci, M. Monachini, and N. Calzo-
lari. 2004b. The MILE lexical classes: Data cat-
egories for content interoperability among lexicons.
In A Registry of Linguistic Data Categories within
an Integrated Language Resources Repository Area
? LREC2004 Satellite Workshop, page 8.
N. Calzolari, F. Bertagna, A. Lenci, and M. Mona-
chini. 2003. Standards and best practice for mul-
tilingual computational lexicons. MILE (the mul-
tilingual ISLE lexical entry). ISLE Deliverable
D2.2&3.2.
T. Charoenporn, V. Sornlertlamvanich, and H. Isahara.
1997. Building a large Thai text corpus ? part-
of-speech tagged corpus: ORCHID?. In Proceed-
ings of the Natural LanguageProcessing Pacific Rim
Symposium.
G. Francopoulo, G. Monte, N. Calzolari, M. Mona-
chini, N. Bel, M. Pet, and C. Soria. 2006. Lex-
ical markup framework (LMF). In Proceedings of
LREC2006 (forthcoming).
N. Ide, A. Lenci, and N. Calzolari. 2003. RDF in-
stantiation of ISLE/MILE lexical entries. In Pro-
ceedings of the ACL 2003 Workshop on Linguistic
Annotation: Getting the Model Right, pages 25?34.
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola,
M. Monachini, A. Ogonowsky, I. Peters, W. Peters,
N. Ruimy, M. Villegas, and A. Zampolli. 2000.
SIMPLE: A general framework for the development
of multilingual lexicons. International Journal of
Lexicography, Special Issue, Dictionaries, Thesauri
and Lexical-Semantic Relations, XIII(4):249?263.
C. Masolo, A. Borgo, S.; Gangemi, N. Guarino, and
A. Oltramari. 2003. Wonderweb deliverable d18
?ontology library (final)?. Technical report, Labo-
ratory for Applied Ontology, ISTC-CNR.
I. Niles and A Pease. 2001. Towards a standard upper
ontology. In Proceedings of the 2nd International
Conference on Formal Ontology in Information Sys-
tems (FOIS-2001).
V. Sornlertlamvanich, W. Pantachat, and S. Mek-
navin. 1994. Classifier assignment by corpus-
based approach. In Proceedings of the 15th Inter-
national Conference on Computational Linguistics
(COLING-94), pages 556?561.
M. Swadesh. 1952. Lexico-statistical dating of pre-
historic ethnic contacts: With special reference to
north American Indians and Eskimos. In Proceed-
ings of the American Philo-sophical Society, vol-
ume 96, pages 452?463.
H. Zhang, C. Huang, and S. Yu. 2004. Distributional
consistency: A general method for defining a core
lexicon. In Proceedings of the 4th International
Conference on Language Resources and Evaluation
(LREC2004), pages 1119?1222.
834
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 9?12,
Sydney, July 2006. c?2006 Association for Computational Linguistics
LeXFlow: a System for Cross-fertilization of Computational Lexicons 
Maurizio Tesconi and Andrea Marchetti 
CNR-IIT 
Via Moruzzi 1, 56024 Pisa, Italy 
{maurizio.tesconi,andrea.marchetti}@iit.cnr.it 
Francesca Bertagna and Monica Monachini and Claudia Soria and Nicoletta Calzolari 
CNR-ILC 
Via Moruzzi 1, 56024 Pisa, Italy 
{francesca.bertagna,monica.monachini, 
claudia.soria,nicoletta.calzolari}@ilc.cnr.it 
 
  
Abstract 
This demo presents LeXFlow, a work-
flow management system for cross-
fertilization of computational lexicons. 
Borrowing from techniques used in the 
domain of document workflows, we 
model the activity of lexicon manage-
ment as a set of workflow types, where 
lexical entries move across agents in the 
process of being dynamically updated. A 
prototype of LeXFlow has been imple-
mented with extensive use of XML tech-
nologies (XSLT, XPath, XForms, SVG) 
and open-source tools (Cocoon, Tomcat, 
MySQL). LeXFlow is a web-based ap-
plication that enables the cooperative and 
distributed management of computational 
lexicons. 
1 Introduction 
LeXFlow is a workflow management system 
aimed at enabling the semi-automatic manage-
ment of computational lexicons. By management 
we mean not only creation, population and vali-
dation of lexical entries but also integration and 
enrichment of different lexicons.  
A lexicon can be enriched by resorting to 
automatically acquired information, for instance 
by means of an application extracting informa-
tion from corpora. But a lexicon can be enriched 
also by resorting to the information available in 
another lexicon, which can happen to encode 
different types of information, or at different lev-
els of granularity. LeXFlow intends to address 
the request by the computational lexicon com-
munity for a change in perspective on computa-
tional lexicons: from static resources towards 
dynamically configurable multi-source entities, 
where the content of lexical entries is dynami-
cally modified and updated on the basis of the 
integration of knowledge coming from different 
sources (indifferently represented by human ac-
tors, other lexical resources, or applications for 
the automatic extraction of lexical information 
from texts). 
This scenario has at least two strictly related 
prerequisites: i) existing lexicons have to be 
available in or be mappable to a standard form 
enabling the overcoming of their respective dif-
ferences and idiosyncrasies, thus making their 
mutual comprehensibility a reality; ii) an archi-
tectural framework should be used for the effec-
tive and practical management of lexicons, by 
providing the communicative channel through 
which lexicons can really communicate and 
share the information encoded therein. 
For the first point, standardization issues obvi-
ously play the central role. Important and exten-
sive efforts have been and are being made to-
wards the extension and integration of existing 
and emerging open lexical and terminological 
standards and best practices, such as EAGLES, 
ISLE, TEI, OLIF, Martif (ISO 12200), Data 
Categories (ISO 12620), ISO/TC37/SC4, and 
LIRICS. An important achievement in this re-
spect is the MILE, a meta-entry for the encoding 
of multilingual lexical information (Calzolari et 
al., 2003); in our approach we have embraced the 
MILE model.  
As far as the second point is concerned, some 
initial steps have been made to realize frame-
works enabling inter-lexica access, search, inte-
gration and operability. Nevertheless, the general 
impression is that little has been made towards 
the development of new methods and techniques 
9
for the concrete interoperability among lexical 
and textual resources. The intent of LeXFlow is 
to fill in this gap.  
2 LeXFlow Design and Application 
LeXFlow is conceived as a metaphoric extension 
and adaptation to computational lexicons of 
XFlow, a framework for the management of 
document workflows (DW, Marchetti et al, 
2005).  
A DW can be seen as a process of cooperative 
authoring where the document can be the goal of 
the process or just a side effect of the coopera-
tion. Through a DW, a document life-cycle is 
tracked and supervised, continually providing 
control over the actions leading to document 
compilation In this environment a document 
travels among agents who essentially carry out 
the pipeline receive-process-send activity.  
Each lexical entry can be modelled as a docu-
ment instance (formally represented as an XML 
representation of the MILE lexical entry), whose 
behaviour can be formally specified by means of 
a document workflow type (DWT) where differ-
ent agents, with clear-cut roles and responsibili-
ties, act over different portions of the same entry 
by performing different tasks.  
Two types of agents are envisaged: external 
agents are human or software actors which per-
form activities dependent from the particular 
DWT, and internal agents are software actors 
providing general-purpose activities useful for 
any DWT and, for this reason, implemented di-
rectly into the system. Internal agents perform 
general functionalities such as creat-
ing/converting a document belonging to a par-
ticular DWT, populating it with some initial data, 
duplicating a document to be sent to multiple 
agents, splitting a document and sending portions 
of information to different agents, merging du-
plicated documents coming from multiple agents, 
aggregating fragments, and finally terminating 
operations over the document. An external agent 
executes some processing using the document 
content and possibly other data, e.g. updates the 
document inserting the results of the preceding 
processing, signs the updating and finally sends 
the document to the next agent(s). 
The state diagram in Figure 1 describes the 
different states of the document instances. At the 
starting point of the document life cycle there is 
a creation phase, in which the system raises a 
new instance of a document with information 
attached.  
Figure 1. Document State Diagram. 
 
The document instance goes into pending 
state. When an agent gets the document, it goes 
into processing state in which the agent compiles 
the parts under his/her responsibility. If the 
agent, for some reason, doesn?t complete the in-
stance elaboration, he can save the work per-
formed until that moment and the document in-
stance goes into freezing state. If the elaboration 
is completed (submitted), or cancelled, the in-
stance goes back into pending state, waiting for a 
new elaboration. 
Borrowing from techniques used in DWs, we 
have modelled the activity of lexicon manage-
ment as a set of DWT, where lexical entries 
move across agents and become dynamically 
updated.  
3 Lexical Workflow General Architec-
ture 
As already written, LeXFlow is based on XFlow 
which is composed of three parts: i) the Agent 
Environment, i.e. the agents participating to all 
DWs; ii) the Data, i.e. the DW descriptions plus 
the documents created by the DW and iii) the 
Engine. Figure 2 illustrates the architecture of the 
framework. 
Figure 2. General Architecture. 
 
The DW environment is the set of human and 
software agents participating to at least one DW. 
10
The description of a DW can be seen as an ex-
tension of the XML document class. A class of 
documents, created in a DW, shares the schema 
of their structure, as well as the definition of the 
procedural rules driving the DWT and the list of 
the agents attending to it. Therefore, in order to 
describe a DWT, we need four components:  
? a schema of the documents involved in the 
DWT; 
? the agent roles chart, i.e. the set of the ex-
ternal and internal agents, operating on the 
document flow. Inside the role chart these 
agents are organized in roles and groups in 
order to define who has access to the 
document. This component constitutes the 
DW environment; 
? a document interface description used by 
external agents to access the documents. 
This component also allows checking ac-
cess permissions to the document; 
? a document workflow description defining 
all the paths that a document can follow in 
its life-cycle, the activities and policies for 
each role.  
The document workflow engine constitutes the 
run-time support for the DW, it implements the 
internal agents, the support for agents? activities, 
and some system modules that the external agents 
have to use to interact with the DW system. 
Also, the engine is responsible for two kinds of 
documents useful for each document flow: the 
documents system logs and the documents system 
metadata. 
4 The lexicon Augmentation Workflow 
Type 
In this section we present a first DWT, called 
?lexicon augmentation?, for dynamic augmenta-
tion of semantic MILE-compliant lexicons. This 
DWT corresponds to the scenario where an entry 
of a lexicon A becomes enriched via basically 
two steps. First, by virtue of being mapped onto 
a corresponding entry belonging to a lexicon B, 
the entry(A) inherits the semantic relations avail-
able in the mapped entry(B). Second, by resorting 
to an automatic application that acquires infor-
mation about semantic relations from corpora, 
the acquired relations are integrated into the en-
try and proposed to the human encoder. 
In order to test the system we considered the 
Simple/Clips (Ruimy et al, 2003) and ItalWord-
Net (Roventini et al, 2003) lexicons.  
An overall picture of the flow is shown in Fig-
ure 3, illustrating the different agents participat-
ing to the flow. Rectangles represent human ac-
tors over the entries, while the other figures 
symbolize software agents: ovals are internal 
agents and octagons external ones. The function-
ality offered to human agents are: display of 
MILE-encoded lexical entries, selection of lexi-
cal entries, mapping between lexical entries be-
longing to different lexicons1, automatic calcula-
tions of new semantic relations (either automati-
cally derived from corpora and mutually inferred 
from the mapping) and manual verification of the 
newly proposed semantic relations.  
5 Implementation Overview 
Our system is currently implemented as a web-
based application where the human external 
agents interact with system through a web 
browser. All the human external agents attending 
the different document workflows are the users 
of system. Once authenticated through username 
and password the user accesses his workload 
area where the system lists all his pending docu-
ments (i.e. entries) sorted by type of flow. 
The system shows only the flows to which the 
user has access. From the workload area the user 
                                                 
1 We hypothesize a human agent, but the same role could be 
performed by a software agent. To this end, we are investi-
gating the possibility of automatically exploiting the proce-
dure described in (Ruimy and Roventini, 2005). 
Figure 3. Lexicon Augmentation Workflow. 
 
11
can browse his documents and select some op-
erations  
 
Figure 4. LeXFlow User Activity State Diagram. 
 
such as: selecting and processing pending docu-
ment; creating a new document; displaying a 
graph representing a DW of a previously created 
document; highlighting the current position of 
the document. This information is rendered as an 
SVG (Scalable Vector Graphics) image. Figure 5 
illustrates the overall implementation of the sys-
tem. 
5.1 The Client Side: External Agent Inter-
action 
The form used to process the documents is ren-
dered with XForms. Using XForms, a browser 
can communicate with the server through XML 
documents and is capable of displaying the 
document with a user interface that can be de-
fined for each type of document. A browser with 
XForms capabilities will receive an XML docu-
ment that will be displayed according to the 
specified template, then it will let the user edit 
the document and finally it will send the modi-
fied document to the server. 
5.2 The Server Side 
The server-side is implemented with Apache 
Tomcat, Apache Cocoon and MySQL. Tomcat is 
used as the web server, authentication module 
(when the communication between the server 
and the client needs to be encrypted) and servlet 
container. Cocoon is a publishing framework that 
uses the power of XML. The entire functioning 
of Cocoon is based on one key concept: compo-
nent pipelines. The pipeline connotes a series of 
events, which consists of taking a request as in-
put, processing and transforming it, and then giv-
ing the desired response. MySQL is used for 
storing and retrieving the documents and the 
status of the documents. 
Each software agent is implemented as a web-
service and the WSDL language is used to define 
its interface.  
References 
Nicoletta Calzolari, Francesca Bertagna, Alessandro 
Lenci and Monica Monachini, editors. 2003. Stan-
dards and Best Practice for Multilingual Computa-
tional Lexicons. MILE (the Multilingual ISLE 
Lexical Entry). ISLE Deliverable D2.2 & 3.2. Pisa. 
Andrea Marchetti, Maurizio Tesconi, and Salvatore 
Minutoli. 2005. XFlow: An XML-Based Docu-
ment-Centric Workflow. In Proceedings of WI-
SE?05, pages 290- 303, New York, NY, USA. 
Adriana Roventini, Antonietta Alonge, Francesca 
Bertagna, Nicoletta Calzolari, Christian Girardi, 
Bernardo Magnini, Rita Marinelli, and Antonio 
Zampolli. 2003. ItalWordNet: Building a Large 
Semantic Database for the Automatic Treatment of 
Italian. In Antonio Zampolli, Nicoletta Calzolari, 
and Laura Cignoni, editors, Computational Lingui-
stics in Pisa, Istituto Editoriale e Poligrafico Inter-
nazionale, Pisa-Roma, pages 745-791. 
Nilda Ruimy, Monica Monachini, Elisabetta Gola, 
Nicoletta Calzolari, Cristina Del Fiorentino, Marisa 
Ulivieri, and Sergio Rossi. 2003. A Computational 
Semantic Lexicon of Italian: SIMPLE. In Antonio 
Zampolli, Nicoletta Calzolari, and Laura Cignoni, 
editors, Computational Linguistics in Pisa, Istituto 
Editoriale e Poligrafico Internazionale, Pisa-Roma, 
pages 821-864. 
Nilda Ruimy and Adriana Roventini. 2005. Towards 
the linking of two electronic lexical databases of 
Italian. In  Proceedings of L&T'05 - Language 
Technologies as a Challenge for Computer Science 
and Linguistics, pages 230-234, Poznan, Poland.
Figure 5. Overall System Implementation. 
12
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 1?8,
Sydney, July 2006. c?2006 Association for Computational Linguistics
LEXICAL MARKUP FRAMEWORK (LMF)  
FOR NLP MULTILINGUAL RESOURCES 
Gil Francopoulo1, Nuria Bel2, Monte George3, Nicoletta Calzolari4, 
Monica Monachini5, Mandy Pet6, Claudia Soria7
 
1INRIA-Loria: gil.francopoulo@wanadoo.fr 
2UPF: nuria.bel@upf.edu 
3ANSI: dracalpha@earthlink.net 
4CNR-ILC: glottolo@ilc.cnr.it 
5CNR-ILC: monica.monachini@ilc.cnr.it 
6MITRE: mpet@mitre.org 
7CNR-ILC: claudia.soria@ilc.cnr.it 
 
Abstract 
Optimizing the production, maintenance 
and extension of lexical resources is one 
the crucial aspects impacting Natural 
Language Processing (NLP). A second 
aspect involves optimizing the process 
leading to their integration in applica-
tions. With this respect, we believe that 
the production of a consensual specifica-
tion on multilingual lexicons can be a 
useful aid for the various NLP actors. 
Within ISO, one purpose of LMF (ISO-
24613) is to define a standard for lexi-
cons that covers multilingual data. 
1 Introduction 
Lexical Markup Framework (LMF) is a model 
that provides a common standardized framework 
for the construction of Natural Language Proc-
essing (NLP) lexicons. The goals of LMF are to 
provide a common model for the creation and 
use of lexical resources, to manage the exchange 
of data between and among these resources, and 
to enable the merging of a large number of indi-
vidual electronic resources to form extensive 
global electronic resources. 
Types of individual instantiations of LMF can 
include monolingual, bilingual or multilingual 
lexical resources. The same specifications are to 
be used for both small and large lexicons. The 
descriptions range from morphology, syntax, 
semantic to translation information organized as 
different extensions of an obligatory core pack-
age. The model is being developed to cover all 
natural languages. The range of targeted NLP 
applications is not restricted. LMF is also used to 
model machine readable dictionaries (MRD), 
which are not within the scope of this paper. 
2 History and current context 
In the past, this subject has been studied and de-
veloped by a series of projects like GENELEX 
[Antoni-Lay], EAGLES, MULTEXT, PAROLE, 
SIMPLE, ISLE and MILE [Bertagna]. More re-
cently within ISO1 the standard for terminology 
management has been successfully elaborated by 
the sub-committee three of ISO-TC37 and pub-
lished under the name "Terminology Markup 
Framework" (TMF) with the ISO-16642 refer-
ence. Afterwards, the ISO-TC37 National dele-
gations decided to address standards dedicated to 
NLP. These standards are currently elaborated as 
high level specifications and deal with word 
segmentation (ISO 24614), annotations 
(ISO 24611, 24612 and 24615), feature struc-
tures (ISO 24610), and lexicons (ISO 24613) 
with this latest one being the focus of the current 
paper. These standards are based on low level 
specifications dedicated to constants, namely 
data categories (revision of ISO 12620), lan-
guage codes (ISO 639), script codes 
(ISO 15924), country codes (ISO 3166), dates 
(ISO 8601) and Unicode (ISO 10646). 
 
This work is in progress. The two level organiza-
tion will form a coherent family of standards 
with the following simple rules: 
1) the low level specifications provide standard-
ized constants; 
                                                 
1 www.iso.org 
1
2) the high level specifications provide struc-
tural elements that are adorned by the standard-
ized constants. 
3 Scope and challenges 
The task of designing a lexicon model that satis-
fies every user is not an easy task. But all the 
efforts are directed to elaborate a proposal that 
fits the major needs of most existing models. 
In order to summarise the objectives, let's see 
what is in the scope and what is not. 
 
LMF addresses the following difficult chal-
lenges: 
? Represent words in languages where 
multiple orthographies (native scripts or 
transliterations) are possible, e.g. some 
Asian languages. 
? Represent explicitly (i.e. in extension) 
the morphology of languages where a de-
scription of all inflected forms (from a list 
of lemmatised forms) is manageable, e.g. 
English. 
? Represent the morphology of languages 
where a description in extension of all in-
flected forms is not manageable (e.g. Hun-
garian). In this case, representation in in-
tension is the only manageable issue. 
? Easily associate written forms and spo-
ken forms for all languages. 
? Represent complex agglutinating com-
pound words like in German. 
? Represent fixed, semi-fixed and flexible 
multiword expressions. 
? Represent specific syntactic behaviors, 
as in the Eagles recommendations. 
? Allow complex argument mapping be-
tween syntax and semantic descriptions, as 
in the Eagles recommendations. 
? Allow a semantic organisation based on 
SynSets (like in WordNet) or on semantic 
predicates (like in FrameNet). 
? Represent large scale multilingual re-
sources based on interlingual pivots or on 
transfer linking. 
LMF does not address the following topics: 
? General sentence grammar of a language 
? World knowledge representation 
In other words, LMF is mainly focused on the 
linguistic representation of lexical information. 
4 Key standards used by LMF 
LMF utilizes Unicode in order to represent the 
orthographies used in lexical entries regardless of 
language. 
Linguistic constants, like /feminine/ or 
/transitive/, are not defined within LMF but are 
specified in the Data Category Registry (DCR) 
that is maintained as a global resource by 
ISO TC37 in compliance with ISO/IEC 11179-
3:2003. 
The LMF specification complies with the 
modeling principles of Unified Modeling Lan-
guage (UML) as defined by OMG2 [Rumbaugh 
2004]. A model is specified by a UML class dia-
gram within a UML package: the class name is 
not underlined in the diagrams. The various ex-
amples of word description are represented by 
UML instance diagrams: the class name is under-
lined.  
5 Structure and core package 
LMF is comprised of two components: 
1) The core package consists of a structural 
skeleton that describes the basic hierarchy of in-
formation in a lexical entry. 
2) Extensions to the core package are ex-
pressed in a framework that describes the reuse 
of the core components in conjunction with addi-
tional components required for the description of 
the contents of a specific lexical resource. 
In the core package, the class called Database 
represents the entire resource and is a container 
for one or more lexicons. The Lexicon class is 
the container for all the lexical entries of the 
same language within the database. The Lexicon 
Information class contains administrative infor-
mation and other general attributes. The Lexical 
Entry class is a container for managing the top 
level language components. As a consequence, 
the number of representatives of single words, 
multi-word expressions and affixes of the lexicon 
is equal to the number of lexical entries in a 
given lexicon. The Form and Sense classes are 
parts of the Lexical Entry. Form consists of a text 
string that represents the word. Sense specifies or 
identifies the meaning and context of the related 
form. Therefore, the Lexical Entry manages the 
relationship between sets of related forms and 
their senses. If there is more than one orthogra-
                                                 
2 www.omg.org 
2
phy for the word form (e.g. transliteration) the 
Form class may be associated with one to many 
Representation Frames, each of which contains a 
specific orthography and one to many data cate-
gories that describe the attributes of that orthog-
raphy. 
The core package classes are linked by the re-
lations as defined in the following UML class 
diagram: 
 
Representation Frame
Lexicon Information
Form Sense
Entry Relation
Sense Relation
Lexical Entry
Database
Lexicon
0..* 0..*
0..*1
0..* 0..*
0..*1
1
0..*
1
1
1
0..*
1
1..*
1
0..*
1
1..*
1..*
1
 
 
Form class can be sub-classed into Lemmatised 
Form and Inflected Form class as follows: 
 
Lemmatised Form Inflected Form
Form
 
 
A subset of the core package classes are ex-
tended to cover different kinds of linguistic data. 
All extensions conform to the LMF core package 
and cannot be used to represent lexical data in-
dependently of the core package. From the point 
of view of UML, an extension is a UML pack-
age. Current extensions for NLP dictionaries are: 
NLP Morphology3, NLP inflectional paradigm, 
NLP Multiword Expression pattern, NLP Syntax, 
NLP Semantic and Multilingual notations, which 
is the focus of this paper. 
6 NLP Multilingual Extension 
The NLP multilingual notation extension is 
dedicated to the description of the mapping be-
tween two or more languages in a LMF database. 
The model is based on the notion of Axis that 
links Senses, Syntactic Behavior and examples 
pertaining to different languages. "Axis" is a 
                                                 
3 Morphology, Syntax and Semantic packages are 
described in [Francopoulo]. 
3
term taken from the Papillon4 project [S?rasset 
2001] 5 . Axis can be organized at the lexicon 
manager convenience in order to link directly or 
indirectly objects of different languages.  
 
6.1 Considerations for standardizing multi-
lingual data  
The simplest configuration of multilingual 
data is a bilingual lexicon where a single link is 
used to represent the translation of a given 
form/sense pair from one language into another. 
But a survey of actual practices clearly reveals 
other requirements that make the model more 
complex. Consequently, LMF has focused on the 
following ones: 
 
(i) Cases where the relation 1-to-1 is impos-
sible because of lexical differences among lan-
guages. An example is the case of English word 
?river? that relates to French words ?rivi?re? and 
?fleuve?, where the latter is used for specifying 
that the referent is a river that flows into the sea. 
The bilingual lexicon should specify how these 
units relate. 
 
(ii) The bilingual lexicon approach should 
be optimized to allow the easiest management of 
large databases for real multilingual scenarios. In 
order to reduce the explosion of links in a multi-
bilingual scenario, translation equivalence can be 
managed through an intermediate "Axis". This 
object can be shared in order to contain the num-
ber of links in manageable proportions. 
 
(iii) The model should cover both transfer 
and pivot approaches to translation, taking also 
into account hybrid approaches. In LMF, the 
pivot approach is implemented by a ?Sense 
Axis?. The transfer approach is implemented by 
a ?Transfer Axis?. 
 
(iv) A situation that is not very easy to deal 
with is how to represent translations to languages 
that are similar or variants. The problem arises, 
for instance, when the task is to represent transla-
tions from English to both European Portuguese 
and Brazilian Portuguese. It is difficult to con-
                                                 
4 www.papillon-dictionary.org  
5 To be more precise, Papillon uses the term "axie" 
from "axis" and "lexie". In the beginning of the LMF 
project, we used the term "axie" but after some bad 
comments about using a non-English term in a stan-
dard, we decided to use the term "axis". 
sider them as two separate languages. In fact, one 
is a variant of the other. The differences are mi-
nor: a certain number of words are different and 
some limited phenomena in syntax are different. 
Instead of managing two distinct copies, it is 
more effective to manage one lexicon with some 
objects that are marked with a dialectal attribute. 
Concerning the translation from English to Por-
tuguese: a limited number of specific Axis in-
stances record this variation and the vast major-
ity of Axis instances is shared. 
 
(v) The model should allow for representing 
the information that restricts or conditions the 
translations. The representation of tests that 
combine logical operations upon syntactic and 
semantic features must be covered. 
6.2 Structure 
The model is based on the notion of Axis that 
link Senses, Syntactic Behavior and examples 
pertaining to different languages. Axis can be 
organized at the lexicon manager convenience in 
order to link directly or indirectly objects of dif-
ferent languages. A direct link is implemented by 
a single axis. An indirect link is implemented by 
several axis and one or several relations. 
The model is based on three main classes: 
Sense Axis, Transfer Axis, Example Axis. 
6.3 Sense Axis 
Sense Axis is used to link closely related 
senses in different languages, under the same 
assumptions of the interlingual pivot approach, 
and, optionally, it can also be used to refer to one 
or several external knowledge representation sys-
tems.  
The use of the Sense Axis facilitates the repre-
sentation of the translation of words that do not 
necessarily have the same valence or morpho-
logical form in one language than in another. For 
example, in a language, we can have a single 
word that will be translated by a compound word 
into another language: English ?wheelchair? to 
Spanish ?silla de ruedas?. Sense Axis may have 
the following attributes: a label, the name of an 
external descriptive system, a reference to a spe-
cific node inside an external description. 
6.4 Sense Axis Relation 
Sense Axis Relation permits to describe the 
linking between two different Sense Axis in-
stances. The element may have attributes like 
label, view, etc. 
4
6.6 Transfer Axis Relation 
Transfer Axis Relation links two Transfer Axis 
instances. The element may have attributes like: 
label, variation. 
The label enables the coding of simple inter-
lingual relations like the specialization of 
?fleuve? compared to ?rivi?re? and ?river?. It is 
not, however, the goal of this strategy to code a 
complex system for knowledge representation, 
which ideally should be structured as a complete 
coherent system designed specifically for that 
purpose. 
6.7 Source Test and Target Test 
Source Test permits to express a condition on 
the translation on the source language side while 
Target Test does it on the target language side. 
Both elements may have attributes like: text and 
comment. 
6.5 Transfer Axis 
Transfer Axis is designed to represent multi-
lingual transfer approach. Here, linkage refers to 
information contained in syntax. For example, 
this approach enables the representation of syn-
tactic actants involving inversion, such as (1): 
6.8 Example Axis  
Example Axis supplies documentation for 
sample translations. The purpose is not to record 
large scale multilingual corpora. The goal is to 
link a Lexical Entry with a typical example of 
translation. The element may have attributes like: 
comment, source. 
 
(1) fra:?elle me manque? => 
eng:?I miss her? 
 
Due to the fact that a lexical entry can be a 
support verb, it is possible to represent transla-
tions that start from a plain verb to a support verb 
like (2) that means "Mary dreams": 
6.9 Class Model Diagram 
The UML class model is an UML package. The 
diagram for multilingual notations is as follows:  
(2)  fra:?Marie r?ve? =>  
  jpn:"Marie wa yume wo miru"  
Transfer Axis Relation
Sense Axis Relation
Syntactic Behavior
SenseExample
Transfer Axis
Example Axis
Source Test
Sense Axis
Target Test
SynSet
Sense
0..*
0..*
0..*
0..*
1
0..*
0..* 0..*
0..*
0..*
1
0..*
1
0..1
1
0..*
0..1
1
1
0..*
1
0..*
1
0..*
5
7 Three examples 
7.1 First example 
The first example is about the interlingual ap-
proach with two axis instances to represent a 
near match between "fleuve" in French and 
"river" in English. In the diagram, French is lo-
cated on the left side and English on the right 
side. The axis on the top is not linked directly to 
any English sense because this notion does not 
exist in English.  
: Sense Axis Relation
comment = flows into the sea
label = more precise
: Sense
label = eng:riverlabel = fra:rivi?re
: Sense
: Sense
label = fra:fleuve
: Sense Axis
: Sense Axis
 
 
7.2 Second example 
Let's see now an example about the transfer 
approach about slight variations between vari-
ants. The example is about English on one side 
and European Portuguese and Brazilian on the 
other side. Due to the fact that these two last 
variants have a very similar syntax, but with 
some local exceptions, the goal is to avoid a full 
and dummy duplication. For instance, the nomi-
native forms of the third person clitics are largely 
preferred in Brazilian rather than the oblique 
form as in European Portuguese. The transfer 
axis relations hold a label to distinguish which 
axis to use depending on the target object. 
 
: Transfer Axis Relation
label = European Portuguese
: Transfer Axis Relation
label = Brazilian
: Syntactic Behavior
label = let me see
: Syntactic Behavior
label = Deixa eu ver
: Syntactic Behavior
label = Deixa-me ver
: Transfer Axis
: Transfer Axis
: Transfer Axis
 
7.3 Third example 
A third example shows how to use the Trans-
fer Axis relation to relate different information in 
a multilingual transfer lexicon. It represents the 
translation of the English ?develop? into Italian 
and Spanish. Recall that the more general sense 
links ?eng:develop? and ?esp:desarrollar?. Both, 
Spanish and Italian, have restrictions that should 
6
be tested in the source language: if the second 
argument of the construction refers to certain 
elements (picture, mentalCreation, building) it 
should be translated into specific verbs.  
 
: Source Test
semanticRestriction = eng:mentalCreation
syntacticArgument = 2
: Source Test
semanticRestriction = eng:picture
syntacticArgument = 2
: Source Test
semanticRestriction = eng:building
syntacticArgument = 2
: Transfer Axis Relation
: Transfer Axis Relation
: Transfer Axis Relation
: Syntactic Behavior
label = esp:revelar
: Syntactic Behavior
label = ita:sviluppare
: Syntactic Behavior
label = ita:costruire
: Syntactic Behavior
label = eng:develop
: Syntactic Behavior
label = esp:construir
: Syntactic Behavior
label = esp:desarrollar
: Transfer Axis
: Transfer Axis
: Transfer Axis
: Transfer Axis
 
8 LMF in XML  
During the last three years, the ISO group fo-
cused on the UML specification. In the last ver-
sion of the LMF document [LMF 2006] a DTD 
has been provided as an informative annex. The 
following conventions are adopted: 
? each UML attribute is transcoded as a 
DC (for Data Category) element 
? each UML class is transcoded as an 
XML element 
? UML aggregations are transcoded as 
content inclusion 
? UML shared associations (i.e. associa-
tions that are not aggregations) are 
transcoded as IDREF(S) 
The first example (i.e. "river") can be represented 
with the following XML tags: 
 
 
<Database> 
<!?   French section ? 
<Lexicon> 
<LexiconInformation 
<DC att="name" val=?French Extract?/> 
<DC att="language" val="fra"/> 
</LexiconInformation> 
<LexicalEntry > 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
<DC att="writtenForm" val=?fleuve?/> 
</LemmatisedForm> 
<Sense id=?fra.fleuve1?> 
 <SemanticDefinition> 
                  <DC att="text" 
val=?Grande rivi?re lorsqu'elle aboutit ? la mer?/> 
<DC att="source" val=?Le Petit Robert 2003?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
<LexicalEntry> 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
  <DC att="writtenForm" val=?rivi?re?/> 
</LemmatisedForm> 
<Sense id=?fra.riviere1?> 
 <SemanticDefinition> 
<DC att="text"  
val=?Cours d'eau naturel de moyenne importance?/> 
<DC att="source" val=?Le Petit Robert 2003?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
</Lexicon> 
<!?                                                 Multilingual section ? 
<SenseAxis id=?A1? senses="fra.fleuve1"> 
7
<SenseAxisRelation targets="A2"> 
 <DC att="comment" val="flows into the sea"/> 
 <DC att="label" val="more precise"/> 
</SenseAxisRelation> 
</SenseAxis> 
<SenseAxis id=?A2? senses="fra.riviere1 eng.river1"/> 
<!?                                                English section ? 
<Lexicon> 
<LexiconInformation> 
<DC att="name" val=?English Extract?/> 
<DC att="language" val="eng"/> 
</LexiconInformation> 
<LexicalEntry> 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
<DC att="writtenForm" val=?river?/> 
</LemmatisedForm> 
<Sense id=?eng.river1?> 
 <SemanticDefinition> 
<DC att="text" 
val=?A natural and continuous flow of water in a long 
line across a country into the sea?/> 
<DC att="source" val=?Longman DCE 2005?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
</Lexicon> 
</Database> 
 
 
9 Comparison 
A serious comparison with previously existing 
models is not possible in this current paper due 
to the lack of space. We advice the interested 
colleague to consult the technical report "Ex-
tended examples of lexicons using LMF" located 
at:  "http://lirics.loria.fr" in the document area. 
The report explains how to use LMF in order to 
represent OLIF-2, Parole/Clips, LC-Star, Word-
Net, FrameNet and BD?f. 
10 Conclusion 
In this paper we presented the results of the 
ongoing research activity of the LMF ISO stan-
dard. The design of a common and standardized 
framework for multilingual lexical databases will 
contribute to the optimization of the use of lexi-
cal resources, specially their reusability for dif-
ferent applications and tasks. Interoperability is 
the condition of a effective deployment of usable 
lexical resources. 
In order to reach a consensus, the work done 
has paid attention to the similarities and differ-
ences of existing lexicons and the models behind 
them. 
Acknowledgements 
The work presented here is partially funded by 
the EU eContent-22236 LIRICS project 6 , par-
tially by the French TECHNOLANGUE 7 + 
OUTILEX8 programs. 
References 
Antoni-Lay M-H., Francopoulo G., Zaysser L. 1994 
A generic model for reusable lexicons: the 
GENELEX project. Literary and linguistic comput-
ing 9(1) 47-54 
Bertagna F., Lenci A., Monachini M., Calzolari N. 
2004 Content interoperability of lexical resources, 
open issues and MILE perspectives LREC Lisbon 
Francopoulo G., George M., Calzolari N., Monachini 
M., Bel N., Pet M., Soria C. 2006 Lexical Markup 
Framework (LMF) LREC Genoa. 
LMF 2006 Lexical Markup Framework ISO-
CD24613-revision-9, ISO Geneva 
Rumbaugh J., Jacobson I.,Booch G. 2004 The unified 
modeling language reference manual, second edi-
tion, Addison Wesley 
S?rasset G., Mangeot-Lerebours M. 2001 Papillon 
Lexical Database project: monolingual dictionaries 
& interlingual links NLPRS Tokyo 
                                                 
6 http://lirics.loria.fr 
7 www.technolangue.net 
8 www.at-lci.com/outilex/outilex.html 
8
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 17?24,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Towards Agent-based Cross-lingual Interoperability of Distributed    
Lexical Resources 
Claudia Soria* Maurizio Tesconi? Andrea Marchetti?
Francesca Bertagna* Monica Monachini*
Chu-Ren Huang?    Nicoletta Calzolari*
*CNR-ILC and ?CNR-IIT 
Via Moruzzi 1, 56024 Pisa 
Italy 
{firstname.lastname@ilc.cnr.it} 
{firstname.lastname@iit.cnr.it} 
?Academia Sinica  
Nankang, Taipei  
Taiwan 
churen@gate.sinica.edu.tw 
 
  
 
Abstract 
In this paper we present an application 
fostering the integration and interopera-
bility of computational lexicons, focusing 
on the particular case of mutual linking 
and cross-lingual enrichment of two wor-
dnets, the ItalWordNet and Sinica BOW 
lexicons. This is intended as a case-study 
investigating the needs and requirements 
of semi-automatic integration and inter-
operability of lexical resources. 
1 Introduction 
In this paper we present an application fostering 
the integration and interoperability of computa-
tional lexicons, focusing on the particular case of 
mutual linking and cross-lingual enrichment of 
two wordnets. The development of this applica-
tion is intended as a case-study and a test-bed for 
trying out needs and requirements posed by the 
challenge of semi-automatic integration and en-
richment of practical, large-scale multilingual 
lexicons for use in computer applications. While 
a number of lexicons already exist, few of them 
are practically useful, either since they are not 
sufficiently broad or because they don?t cover 
the necessary level of detailed information. 
Moreover, multilingual language resources are 
not as widely available and are very costly to 
construct: the work process for manual develop-
ment of new lexical resources or for tailoring 
existing ones is too expensive in terms of effort 
and time to be practically attractive.  
The need of ever growing lexical resources for 
effective multilingual content processing has 
urged the language resource community to call 
for a radical change in the perspective of lan-
guage resource creation and maintenance and the 
design of a ?new generation? of LRs: from static, 
closed and locally developed resources to shared 
and distributed language services, based on open 
content interoperability standards. This has often 
been called a ?change in paradigm? (in the sense 
of Kuhn, see Calzolari and Soria, 2005; Calzolari 
2006). Leaving aside the tantalizing task of 
building on-site resources, the new paradigm 
depicts a scenario where lexical resources are 
cooperatively built as the result of controlled co-
operation of different agents, adopting the para-
digm of accumulation of knowledge so success-
ful in more mature disciplines, such as biology 
and physics (Calzolari, 2006).  
According to this view (or, better, this vision), 
different lexical resources reside over distributed 
places and can not only be accessed but choreo-
graphed by agents presiding the actions that can 
be executed over them. This implies the ability to 
build on each other achievements, to merge re-
sults, and to have them accessible to various sys-
tems and applications. 
At the same time, there is another argument in 
favor of distributed lexical resources: language 
resources, lexicons included, are inherently dis-
tributed because of the diversity of languages 
distributed over the world. It is not only natural 
that language resources to be developed and 
maintained in their native environment. Since 
language evolves and changes over time, it is not 
possible to describe the current state of the lan-
17
guage away from where the language is spoken. 
Lastly, the vast range of diversity of languages 
also makes it impossible to have one single uni-
versal centralized resource, or even a centralized 
repository of resources. 
Although the paradigm of distributed and in-
teroperable lexical resources has largely been 
discussed and invoked, very little has been made 
in comparison for the development of new meth-
ods and techniques for its practical realization. 
Some initial steps are made to design frame-
works enabling inter-lexica access, search, inte-
gration and operability. An example is the Lexus 
tool (Kemps-Snijders et al, 2006), based on the 
Lexical Markup Framework (Romary et al, 
2006), that goes in the direction of managing the 
exchange of data among large-scale lexical re-
sources. A similar tool, but more tailored to the 
collaborative creation of lexicons for endangered 
language, is SHAWEL (Gulrajani and Harrison, 
2002). However, the general impression is that 
little has been made towards the development of 
new methods and techniques for attaining a con-
crete interoperability among lexical resources. 
Admittedly, this is a long-term scenario requiring 
the contribution of many different actors and ini-
tiatives (among which we only mention stan-
dardisation, distribution and international coop-
eration).  
Nevertheless, the intent of our project is to 
contribute to fill in this gap, by exploring in a 
controlled way the requirement and implications 
posed by new generation multilingual lexical 
resources. The paper is organized as follows: 
section 2 describes the general architectural de-
sign of our project; section 3 describes the mod-
ule taking care of cross-lingual integration of 
lexical resources, by also presenting a case-study 
involving an Italian and Chinese lexicons. Fi-
nally, section 4 presents our considerations and 
lessons learned on the basis of this exploratory 
testing. 
2 An Architecture for Integrating Lexi-
cal Resources 
 LeXFlow (Soria et al, 2006) was developed 
having in mind the long-term goal of lexical re-
source interoperability. In a sense, LeXFlow is 
intended as a proof of concept attempting to 
make the vision of an infrastructure for access 
and sharing of linguistic resources more tangible. 
LeXFlow is an adaptation to computational 
lexicons of XFlow, a cooperative web applica-
tion for the management of document workflows 
(DW, Marchetti et al, 2005). A DW can be seen 
as a process of cooperative authoring where a 
document can be the goal of the process or just a 
side effect of the cooperation. Through a DW, a 
document life-cycle is tracked and supervised, 
continually providing control over the actions 
leading to document compilation. In this envi-
ronment a document travels among agents who 
essentially carry out the pipeline receive-process-
send activity.  
There are two types of agents: external agents 
are human or software actors performing activi-
ties dependent from the particular Document 
Workflow Type; internal agents are software 
actors providing general-purpose activities useful 
for many DWTs and, for this reason, imple-
mented directly into the system. Internal agents 
perform general functionalities such as creat-
ing/converting a document belonging to a par-
ticular DW, populating it with some initial data, 
duplicating a document to be sent to multiple 
agents, splitting a document and sending portions 
of information to different agents, merging du-
plicated documents coming from multiple agents, 
aggregating fragments, and finally terminating 
operations over the document. External agents 
basically execute some processing using the 
document content and possibly other data; for 
instance, accessing an external database or 
launching an application.  
LeXFlow was born by tailoring XFlow to 
management of lexical entries; in doing so, we 
have assumed that each lexical entry can be 
modelled as a document instance, whose behav-
iour can be formally specified by means of a 
lexical workflow type (LWT). A LWT describes 
the life-cycle of a lexical entry, the agents al-
lowed to act over it, the actions to be performed 
by the agents, and the order in which the actions 
are to be executed. Embracing the view of coop-
erative workflows, agents can have different 
rights or views over the same entry: this nicely 
suits the needs of lexicographic work, where we 
can define different roles (such as encoder, anno-
tator, validator) that can be played by either hu-
man or software agents. Other software modules 
can be inserted in the flow, such as an automatic 
acquirer of information from corpora or from the 
web. Moreover, deriving from a tool designed 
for the cooperation of agents, LeXFlow allows to 
manage workflows where the different agents 
can reside over distributed places.  
LeXFlow thus inherits from XFlow the gen-
eral design and architecture, and can be consid-
ered as a specialized version of it through design 
18
of specific Lexical Workflow Types and plug-in 
of dedicated external software agents. In the next 
section we briefly illustrate a particular Lexical 
Workflow Type and the external software agents 
developed for the purpose of integrating different 
lexicons belonging to the same language. Since it 
allows the independent and coordinated sharing 
of actions over portions of lexicons, LeXFlow 
naturally lends itself as a tool for the manage-
ment of distributed lexical resources. 
Due to its versatility, LeXFlow is both a gen-
eral framework where ideas on automatic lexical 
resource integration can be tested and an infra-
structure for proving new methods for coopera-
tion among lexicon experts. 
2.1 Using LeXFlow for Lexicon Enrichment 
In previous work (Soria et al, 2006),  the LeX-
Flow framework has been tested for integration 
of lexicons with differently conceived lexical 
architectures and diverging formats. It was 
shown how interoperability is possible between 
two Italian lexicons from the SIMPLE and 
WordNet families, respectively, namely the 
SIMPLE/CLIPS (Ruimy et al, 2003) and Ital-
WordNet (Roventini et al, 2003) lexicons.  
In particular, a Lexical Workflow Type was 
designed where the two different monolingual 
semantic lexicons interact by reciprocally enrich-
ing themselves and moreover integrate informa-
tion coming from corpora. This LWT, called 
?lexicon augmentation?, explicitly addresses dy-
namic augmentation of semantic lexicons. In this 
scenario, an entry of a lexicon A becomes en-
riched via basically two steps. First, by virtue of 
being mapped onto a corresponding entry be-
longing to a lexicon B, the entryA inherits the 
semantic relations available in the mapped en-
tryB. Second, by resorting to an automatic appli-
cation that acquires information about semantic 
relations from corpora, the acquired relations are 
integrated into the entry and proposed to the hu-
man encoder. 
B
An overall picture of the flow is shown in 
Figure 1, illustrating the different agents partici-
pating in the flow. Rectangles represent human 
actors over the entries, while the other figures 
symbolize software agents: ovals are internal 
agents and octagons external ones. The two ex-
ternal agents involved in this flow are the ?rela-
tion calculator? and the ?corpora extractor?. The 
first is responsible for the mapping between the 
sets of semantic relations used by the different 
lexicons. The ?corpora extractor? module in-
vokes an application that acquires information 
about part-of relations by identifying syntactic 
constructions in a vast Italian corpus. It then 
takes care of creating the appropriate candidate 
semantic relations for each lemma that is pro-
posed by the application. 
Figure 1. Lexicons Augmentation Workflow 
Type. 
A prototype of LeXFlow has been imple-
mented with an extensive use of XML technolo-
gies (XML Schema, XSLT, XPath, XForms, 
SVG) and open-source tools (Cocoon, Tomcat, 
mySQL). It is a web-based application where 
human agents interact with the system through 
an XForms browser that displays the document 
to process as a web form whereas software 
agents interact with the system via web services. 
3 Multilingual WN Service 
In the Section above we have illustrated the gen-
eral architecture of LeXFlow and showed how a 
Lexical Workflow Type can be implemented in 
order to enrich already existing lexicons belong-
ing to the same language but realizing different 
models of lexicon encoding. In this section we 
move to a cross-lingual perspective of lexicon 
integration. We present a module that similarly 
addresses the issue of lexicon augmentation or 
enrichment focusing on mutual enrichment of 
two wordnets in different languages and residing 
at different sites. 
This module, named ?multilingual WN Ser-
vice? is responsible for the automatic cross-
lingual fertilization of lexicons having a Word-
19
Net-like structure. Put it very simply, the idea 
behind this module is that a monolingual word-
net can be enriched by accessing the semantic 
information encoded in corresponding entries of 
other monolingual wordnets.  
Since each entry in the monolingual lexicons 
is linked to the Interlingual Index (ILI, cf. Sec-
tion 3.1), a synset of a WN(A) is indirectly 
linked to another synset in another WN(B). On 
the basis of this correspondence, a synset(A) can 
be enriched by importing the relations that the 
corresponding synset(B) holds with other syn-
sets(B), and vice-versa. Moreover, the enrich-
ment of WN(A) will not only import the relations 
found in WN(B), but it will also propose target 
synsets in the language(A) on the basis of those 
found in language(B). 
The various WN lexicons reside over distrib-
uted servers and can be queried through web ser-
vice interfaces. The overall architecture for mul-
tilingual wordnet service is depicted in Figure 2. 
 
 
Figure 2. Multilingual Wordnet Service Archi-
tecture. 
 
Put in the framework of the general LeXFlow 
architecture, the Multilingual wordnet Service 
can be seen as an additional external software 
agent that can be added to the augmentation 
workflow or included in other types of lexical 
flows. For instance, it can be used not only to 
enrich a monolingual lexicon but to bootstrap a 
bilingual lexicon. 
3.1 Linking Lexicons through the ILI  
The entire mechanism of the Multilingual WN 
Service is based on the exploitation of Interlin-
gual Index (Peters et al, 1998), an unstructured 
version of WordNet used in EuroWordNet 
(Vossen et al, 1998) to link wordnets of different 
languages; each synset in the language-specific 
wordnet is linked to at least one record of the ILI 
by means of a set of equivalence relations 
(among which the most important is the 
EQ_SYNONYM, that expresses a total, perfect 
equivalence between two synsets).  
Figure 6 describes the schema of a WN lexical 
entry. Under the root ?synset? we find both in-
ternal relations (?synset relations?) and ILI Rela-
tions, which link to ILI synsets. 
Figure 3 shows the role played by the ILI as 
set of pivot nodes allowing the linkage between 
concepts belonging to different wordnets.  
 
 
Figure 3. Interlingual Linking of Language-
specific Synsets. 
 
In the Multilingual WN Service, only equiva-
lence relations of type EQ_SYNONYM and 
EQ_NEAR_SYNONYM have been taken into ac-
count, being them the ones used to represent a 
translation of concepts and also because they are 
the most exploited (for example, in IWN, they 
cover about the 60% of the encoded equivalence 
relations). The EQ_SYNONYM relation is used to 
realize the one-to-one mapping between the lan-
guage-specific synset and the ILI, while multiple 
EQ_NEAR_SYNONYM relations (because of their 
nature) might be encoded to link a single lan-
guage-specific synset to more than one ILI re-
cord. In Figure 4 we represented the possible 
relevant combinations of equivalence relations 
that can realize the mapping between synsets 
belonging to two languages. In all the four cases, 
a synset ?a? is linked via the ILI record to a syn-
set ?b? but a specific procedure has been fore-
seen in order to calculate different ?plausibility 
scores? to each situation. The procedure relies on 
different rates assigned to the two equivalence 
relations (rate ?1? to EQ_NEAR_SYNONYM rela-
tion and rate ?0? to the EQ_SYNONYM). In this 
way we can distinguish the four cases by assign-
ing respectively a weight of ?0?, ?1?, ?1? and 
?2?. 
20
  
Figure 4. Possible Combinations of Relations 
between two Lexicons A and B and the ILI. 
 
The ILI is a quite powerful yet simple method 
to link concepts across the many lexicons be-
longing to the WordNet-family. Unfortunately, 
no version of the ILI can be considered a stan-
dard and often the various lexicons exploit dif-
ferent version of WordNet as ILI 1 . This is a 
problem that is handled at web-service level, by 
incorporating the conversion tables provided by 
(Daud? et al, 2001). In this way, the use of dif-
ferent versions of WN does not have to be taken 
into consideration by the user who accesses the 
system but it is something that is resolved by the 
system itself2. This is why the version of the ILI 
is a parameter of the query to web service (see 
Section below). 
3.2 Description of the Procedure 
On the basis of ILI linking, a synset can be en-
riched by importing the relations contained in the 
corresponding synsets belonging to another 
wordnet. 
In the procedure adopted, the enrichment is 
performed on a synset-by-synset basis. In other 
words, a certain synset is selected from a word-
net resource, say WN(A). The cross-lingual mod-
ule identifies the corresponding ILI synset, on 
the basis of the information encoded in the syn-
set. It then sends a query to the WN(B) web ser-
vice providing the ID of ILI synset together with 
the ILI version of the starting WN. The WN(B) 
web service returns the synset(s) corresponding 
to the WN(A) synset, together with reliability 
scores. If WN(B) is based on a different ILI ver-
sion, it can carry out the mapping between ILI 
versions (for instance by querying the ILI map-
ping web service). The cross-lingual module then 
analyzes the synset relations encoded in the 
                                                 
1 For example, the Chinese and the Italian wordnets consid-
ered as our case-study use respectively versions 1.6 and 1.5. 
2 It should be noted, however, that the conversion between 
different WN versions could not be accurate so the mapping 
is always proposed with a probability score.
WN(B) synset and for each of them creates a 
new synset relation for the WN(A) synset. 
If the queried wordnets do not use the same set 
of synset relations, the module must take care of 
the mapping between different relation sets. In  
our case-study no mapping was needed, since the 
two sets were completely equivalent.   
Each new relation is obtained by substituting 
the target WN(B)  synset  with the corresponding 
synset WN(A), which again is found by querying 
back the WN(A) web service (all these steps 
through the ILI). The procedure is formally de-
fined by the following formula: 
 
 
 
 
 
Figure 5. Finding New Relations. 
 
Every local wordnet has to provide a web ser-
vice API  with the following methods: 
 
1. GetWeightedSynsetsByIli(ILIid, ILIversion) 
2. GetSynsetById(sysnsetID) 
3. GetSynsetsByLemma(lemma) 
 
21
The returned synsets of each method must be 
formatted in XML following the schema de-
picted in Figure 6: 
 
Figure 6. Schema of Wordnet Synsets Returned 
by WN Web Services. 
 
The scores returned by the method ?Get-
WeightedSynsetsByIli? are used by our module 
to calculate the reliability rating for each new 
proposed relation. 
3.3 A Case Study: Cross-fertilization be-
tween Italian and Chinese Wordnets. 
We explore this idea with a case-study involving 
the ItalianWordNet (Roventini et al, 2003) and 
the Academia Sinica Bilingual Ontological 
Wordnet (Sinica BOW, Huang et al, 2004).  
The BOW integrates three resources: Word-
Net, English-Chinese Translation Equivalents 
Database (ECTED), and SUMO (Suggested Up-
per Merged Ontology). With the integration of 
these three key resources, Sinica BOW functions 
both as an English-Chinese bilingual wordnet 
and a bilingual lexical access to SUMO. Sinica 
Bow currently has two bilingual versions, corre-
sponding to WordNet 1.6. and 1.7. Based on 
these bootstrapped versions, a Chinese Wordnet 
(CWN, Huang et al 2005) is under construction 
with handcrafted senses and lexical semantic re-
lations. For the current experiment, we have used 
the version linking to WordNet 1.6. 
ItalWordNet was realized as an extension of 
the Italian component of EuroWordNet. It com-
prises a general component consisting of about 
50,000 synsets and terminological wordnets 
linked to the generic wordnet by means of a spe-
cific set of relations. Each synset of ItalWordNet 
is linked to the Interlingual-Index (ILI). 
The two lexicons refer to different versions of 
the ILI (1.5 for IWN and 1.6 for BOW), thus 
making it necessary to provide a mapping be-
tween the two versions. On the other hand, no 
mapping is necessary for the set of synset rela-
tions used, since both of them adopt the same set. 
For the purposes of evaluating the cross-
lingual module, we have developed two web-
services for managing a subset of the two re-
sources.  
The following Figure shows a very simple ex-
ample where our procedure discovers and pro-
poses a new meronymy relation for the Italian 
synset {passaggio,strada,via}. This synset is 
equivalent to the ILI ?road,route? that is ILI-
connected with BOW synset ???,? ,?? (da-
o_lu, dao, lu) (Figure 7, A) . The Chinese synset 
has a meronymy relation with the synset ???
??? (wan) (B). This last  synset is equivalent 
to the ILI ?bend, crook, turn? that is ILI-
connected with Italian WordNet synset ?curva-
tura, svolta, curva? (C). Therefore the procedure 
will propose a new candidate meronymy relation 
between the two Italian WordNet synsets (D). 
 
 
Figure 7. Example of a New Proposed Mero-
nymy Relation for Italian. 
3.4 Considerations and Lessons Learned 
Given the diversity of the languages for which 
wordnets exist, we note that it is difficult to im-
plement an operational standard across all typo-
logically different languages. Work on enriching 
and merging multilingual resources presupposes 
that the resources involved are all encoded with 
the same standard. However, even with the best 
efforts of the NLP community, there are only a 
small number of language resources encoded in 
any given standard. In the current work, we pre-
suppose a de-facto standard, i.e. a shared and 
conventionalized architecture, the WordNet one. 
Since the WordNet framework is both conven-
tionalized and widely followed, our system is 
22
able to rely on it without resorting to a more sub-
stantial and comprehensive standard. In the case, 
for instance, of integration of lexicons with dif-
ferent underlying linguistic models, the availabil-
ity of the MILE (Calzolari et al, 2003) was an 
essential prerequisite of our work. Nevertheless, 
even from the perspective of the same model, a 
certain degree of standardization is required, at 
least at the format level. 
From a more general point of view, and even 
from the perspective of a limited experiment 
such as the one described in this paper, we must 
note that the realization of the new vision of dis-
tributed and interoperable language resources is 
strictly intertwined with at least two prerequi-
sites. On the one side, the language resources 
need to be available over the web; on the other, 
the language resource community will have to 
reconsider current distribution policies, and to 
investigate the possibility of developing an 
?Open Source? concept for LRs. 
4 Conclusion 
Our proposal to make distributed wordnets inter-
operable has the following applications in proc-
essing of lexical resources: 
 
? Enriching existing resources: informa-
tion is often not complete in any given 
wordnet: by making two wordnets inter-
operable, we can bootstrap semantic rela-
tions and other information from other 
wordnets. 
? Creation of new resources: multilingual 
lexicons can be bootstrapped by linking 
different language wordnets through ILI. 
? Validation of existing resources: seman-
tic relation information and other synset 
assignments can be validated when it is re-
inforced by data from a different wordnet. 
In particular, our work can be proposed as a 
prototype of a web application that would sup-
port the Global WordNet Grid initiative 
(www.globalwordnet.org/gwa/gwa_grid.htm).  
Any multilingual process, such as cross-
lingual information retrieval, must involve both 
resources and tools in a specific language and 
language pairs. For instance, a multilingual query 
given in Italian but intended for querying Eng-
lish, Chinese, French, German, and Russian 
texts, can be send to five different nodes on the 
Grid for query expansion, as well as performing 
the query itself. In this way, language specific 
query techniques can be applied in parallel to 
achieve best results that can be integrated in the 
future. As multilingualism clearly becomes one 
of the major challenges of the future of web-
based knowledge engineering, WordNet emerges 
as one leading candidate for a shared platform 
for representing a lexical knowledge model for 
different languages of the world. This is true 
even if it has to be recognized that the wordnet 
model is lacking in some important semantic in-
formation (like, for instance, a way to represent 
the semantic predicate). However, such knowl-
edge and resources are distributed. In order to 
create a shared multi-lingual knowledge base for 
cross-lingual processing based on these distrib-
uted resources, an initiative to create a grid-like 
structure has been recently proposed and pro-
moted by the Global WordNet Association, but 
until now has remained a wishful thinking. The 
success of this initiative will depend on whether 
there will be tools to access and manipulate the 
rich internal semantic structure of distributed 
multi-lingual WordNets. We believe that our 
work on LeXFlow offers such a tool to provide 
inter-operable web-services to access distributed 
multilingual WordNets on the grid. 
This allows us to exploit in a cross-lingual 
framework the wealth of monolingual lexical 
information built in the last decade. 
5 References 
Nicoletta Calzolari, Francesca Bertagna, Alessandro 
Lenci and Monica Monachini, editors. 2003. Stan-
dards and Best Practice for Multilingual Computa-
tional Lexicons. MILE (the Multilingual ISLE 
Lexical Entry). ISLE CLWG Deliverable D2.2 & 
3.2. Pisa. 
Nicoletta Calzolari and Claudia Soria. 2005. A New 
Paradigm for an Open Distributed Language Re-
source Infrastructure: the Case of Computational 
Lexicons. In Proceedings of the AAAI Spring Sym-
posium ?Knowledge Collection from Volunteer 
Contributors (KCVC05)?, pages 110-114, Stan-
ford, CA. 
Nicoletta Calzolari. 2006. Technical and Strategic 
issues on Language Resources for a Research In-
frastructure In Proceedings of the International 
Symposium on Large-scale Knowledge Resources 
(LKR2006), pages 53-58, Tokyo, Tokyo Institute 
of Technology. 
Jordi Daud?, Lluis Padr? and German Rigau. 2001. A 
Complete WN1.5 to WN1.6 Mapping. In Proceed-
ings of NAACL Workshop "WordNet and Other 
Lexical Resources: Applications, Extensions and 
23
Customizations", pages 83-88, Pittsburg, PA, USA, 
Association for Computational Linguistics.  
Greg Gulrajani and David Harrison. 2002. SHAWEL: 
Sharable and Interactive Web-Lexicons. In Pro-
ceedings of the LREC2002 Workshop on Tools and 
Resources in Field Linguistics, pages 1-4, Las 
Palmas, Canary Islands, Spain. 
Chu-Ren Huang, Ru-Yng Chang,  and Shiang-Bin 
Lee. 2004. Sinica BOW (Bilingual Ontological 
Wordnet): Integration of Bilingual WordNet and 
SUMO. In Proceedings of LREC2004, pages 1553-
1556, Lisbon, Portugal. 
Chu-Ren Huang, Chun-Ling Chen, Cui-Xia Weng, 
Hsiang-Ping Lee, Yong-Xiang Chen and Keh-jiann 
Chen. 2005. The Sinica Sense Management Sys-
tem: Design and Implementation. Computational 
Linguistics and Chinese Language Processing. 
10(4): 417-430. 
Marc Kemps-Snijders, Mark-Jan Nederhof, and Peter 
Wittenburg. 2006. LEXUS, a web-based tool for 
manipulating lexical resources. Accepted for publi-
cation in Proceedings of LREC2006, Genoa, Italy. 
Andrea Marchetti, Maurizio Tesconi, and Salvatore 
Minutoli. 2005. XFlow: An XML-Based Docu-
ment-Centric Workflow. In Proceedings of 
WISE?05, pages 290-303, New York, NY, USA. 
Wim Peters, Piek Vossen, Pedro Diez-Orzas, and 
Geert Adriaens. 1998. Cross-linguistic Alignment 
of Wordnets with an Inter-Lingual-Index. In Nancy 
Ide, Daniel Greenstein, and Piek Vossen, editors, 
Special Issue on EuroWordNet, Computers and the 
Humanities, 32(2-3): 221-251. 
Laurent Romary, Gil Francopoulo, Monica Monachi-
ni, and Susanne Salmon-Alt 2006. Lexical Markup 
Framework (LMF): working to reach a consensual 
ISO standard on lexicons. Accepted for publication 
in Proceedings of LREC2006, Genoa, Italy. 
Adriana Roventini, Antonietta Alonge, Francesca 
Bertagna, Nicoletta Calzolari, Christian Girardi, 
Bernardo Magnini, Rita Marinelli, and Antonio 
Zampolli. 2003. ItalWordNet: Building a Large 
Semantic Database for the Automatic Treatment of 
Italian. In Antonio Zampolli, Nicoletta Calzolari, 
and Laura Cignoni, editors, Computational Lingui-
stics in Pisa, IEPI, Pisa-Roma, pages 745-791. 
Nilda Ruimy, Monica Monachini, Elisabetta Gola, 
Nicoletta Calzolari, Cristina Del Fiorentino, Marisa 
Ulivieri, and Sergio Rossi. 2003. A Computational 
Semantic Lexicon of Italian: SIMPLE. In Antonio 
Zampolli, Nicoletta Calzolari, and Laura Cignoni, 
editors, Computational Linguistics in Pisa, IEPI, 
Pisa-Roma, pages 821-864. 
Claudia Soria, Maurizio Tesconi, Francesca Bertagna, 
Nicoletta Calzolari, Andrea Marchetti, and Monica 
Monachini. 2006. Moving to Dynamic Computa-
tional Lexicons with LeXFlow. Accepted for pu-
blication in Proceedings of LREC2006, Genova, I-
taly.  
Piek Vossen. 1998. Introduction to EuroWordNet. In 
Nancy Ide, Daniel Greenstein, and Piek Vossen, 
editors, Special Issue on EuroWordNet, Computers 
and the Humanities, 32(2-3): 73-89. 
 
 
 
 
24
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 178?181,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
The SILT and FlaReNet International Collaboration for Interoperability
Nancy Ide
Department of Computer Science
Vassar College
Poughkeepsie, New York USA
ide@cs.vassar.edu
James Pustejovsky
Department of Computer Science
Brandeis University
Waltham, Massachusetts USA
jamesp@cs.brandeis.edu
Nicoletta Calzolari
CNR-ILC
Pisa, Italy
glottolo@ilc.cnr.it
Claudia Soria
CNR-ILC
Pisa, Italy
claudia.soria@ilc.cnr.it
Abstract
Two major projects in the U.S. and Eu-
rope have joined in a collaboration to work
toward achieving interoperability among
language resources. In the U.S., a project
entitled ?Sustainable Interoperability for
Language Technology? (SILT) has been
funded by the National Science Founda-
tion under the INTEROP program, and in
Europe, FLaReNet Fostering Language
Resources Network has been funded
by the European Commission under the
eContentPlus framework. This interna-
tional collaborative effort involves mem-
bers of the language processing commu-
nity and others working in related ar-
eas to build consensus regarding the shar-
ing of data and technologies for language
resources and applications, to work to-
wards interoperability of existing data,
and, where possible, to promote standards
for annotation and resource building. In
addition to broad-based US and European
participation, we are seeking the partici-
pation of colleagues in Asia. This pre-
sentation describing the projects and their
goals will, we hope, serve to involve mem-
bers of the community who may not have
been aware of the effort before, in particu-
lar colleagues in Asia.
1 Overview
One of today?s greatest challenges is the develop-
ment of language processing capabilities that will
enable easy and natural access to computing facil-
ities and information. Because natural language
processing (NLP) research relies heavily on such
resources to provide training data to develop lan-
guage models and optimize statistical algorithms,
language resources?including (usually large) col-
lections of language data and linguistic descrip-
tions in machine readable form, together with
tools and systems (lemmatizers, parsers, summa-
rizers, information extractors, speech recognizers,
annotation development software, etc.)? are criti-
cal to this development.
Over the past two decades, the NLP commu-
nity has invested substantial effort in the creation
of computational lexicons and compendia of se-
mantic information (e.g., framenets, ontologies,
knowledge bases) together with language corpora
annotated for all varieties of linguistic features,
which comprise the central resource for current
NLP research. However, the lack of a thorough,
well-articulated longer-term vision for language
processing research has engendered the creation of
a disjointed set of language resources and tools,
which exist in a wide variety of (often incom-
patible) formats, are often unusable with systems
other than those for which they were developed,
and utilize linguistic categories derived from dif-
ferent theoretical frameworks. Furthermore, these
expensive investments are often produced only for
one of several relatively isolated subfields (e.g.,
NLP, information retrieval, machine translation,
speech processing), or even worse, for one appli-
cation in one subfield. In addition, the high cost of
resource development has prevented the creation
of reliable, large-scale language data and anno-
tations for many phenomena, and for languages
other than English.
Interoperability of resources, tools, and frame-
works has recently come to be recognized as per-
haps the most pressing current need for language
processing research. Interoperability is especially
178
critical at this time because of the widely recog-
nized need to create and merge annotations and
information at different linguistic levels in order
to study interactions and interleave processing at
these different levels. It has also become criti-
cal because new data and tools for emerging and
strategic languages such as Chinese and Arabic as
well as minor languages are in the early stages of
development.
Two major projects in the U.S. and Europe have
joined in a collaboration to work toward achiev-
ing interoperability among language resources. In
the U.S., a project entitled ?Sustainable Interoper-
ability for Language Technology? (SILT) has been
funded by the National Science Foundation under
the INTEROP program, and in Europe, FLaReNet
Fostering Language Resources Network has been
funded by the European Commission under the
eContentPlus framework. This international col-
laborative effort involves members of the lan-
guage processing community and others working
in related areas to build consensus regarding the
sharing of data and technologies for language re-
sources and applications, to work towards inter-
operability of existing data, and, where possible,
to promote standards for annotation and resource
building. In addition to broad-based US and Eu-
ropean participation, we are seeking the participa-
tion of colleagues in Asia.
To ensure full community involvement and con-
solidation of effort, SILT and FLaReNet are estab-
lishing ties with major ongoing projects and con-
sortia, including the International Standards Orga-
nization TC37 SC4 (Language Resource Manage-
ment)1, The World Wide Web Consortium (W3C),
the Text Encoding Initiative, the ACL Special In-
terest Group on Annotation (SIGANN)2, and oth-
ers. The ultimate goal is to create an Open Lan-
guage Infrastructure (OLI) that will provide free
and open access to resources, tools, and other in-
formation that support work in the field, in order to
facilitate collaboration, accessibility for all mem-
bers of the community, and convergence toward
interoperability.
The following sections outline the goals of SILT
and FLaReNet.
1http://www.tc37sc4.org
2http://www.cs.vassar.edu/sigann
2 SILT
The creation and use of language resources spans
several related but relatively isolated disciplines,
including NLP, information retrieval, machine
translation, speech, and the semantic web. SILT?s
goal is to turn existing, fragmented technology and
resources developed within these groups in rela-
tive isolation into accessible, stable, and interop-
erable resources that can be readily reused across
several fields.
The major activities of the effort are:
? carefully surveying the field to identify the
resources, tools, and frameworks in order to
examine what exists and what needs to be
developed, and to identify those areas for
which interoperability would have the broad-
est impact in advancing research and devel-
opment and significant applications depen-
dent on them;
? identifying the major efforts on standards de-
velopment and interoperable system design
together with existing and developing tech-
nologies, and examining ways to leverage
their results to define an interoperablity in-
frastructure for both tools and data;
? analyzing innovative methods and techniques
for the creation and maintenance of language
resources in order to reduce the high costs,
increase productivity, and enable rapid devel-
opment of resources for languages that cur-
rently lack them;
? implementing proposed annotation standards
and best practices in corpora currently under
development (e.g., American National Cor-
pus3, TimeBank4) to evaluate their viability
and feed into the process of further standards
development, testing, and use of interoper-
ability frameworks (e.g., GATE5, UIMA6)
and implementation of processing modules,
and distributing all software, data, and anno-
tations.
? ensuring the broadest possible community
engagement in the development of consensus
and agreement on strategies, priorities, and
3http://www.anc.org
4http://www.timeml.org/site/timebank/timebank.html
5http://gate.ac.uk
6http://www.oasis-open.org/committees/uima/
179
best approaches for achieving broad interop-
erability by means of sessions, open meet-
ings, and special workshops at major confer-
ences in the field, together with active main-
tenance of and involvement in open web fo-
rums and Wikis;
? providing the technical expertise necessary to
turn consensus and agreement into robust in-
teroperability frameworks along with the ap-
propriate tools and resources for their broad
use and implementation by means of tutorials
and training workshops, especially for under-
graduate and graduate students in the field.
3 FLaReNet
The multilingual Europe urgently needs language
technologies in order to bridge its language bar-
riers. In order to achieve better quality and fast
development of language technologies that seam-
lessly work on all devices, for spoken and written
language alike, the European scenario now needs a
coherent and unified effort. The demand for cross-
lingual technologies is pressing, the expectations
are high, and at the same time, the field is suf-
fering from fragmentation, lack of vision and di-
rection. The main objective of FLaReNet is to
steer the process that in the near future will de-
fine the actors, the overall direction and the prac-
tical forms of collaboration in language technolo-
gies and their ?raw material?, language resources.
Under this respect, the goals of FLaReNet lie at
a higher level than those of SILT, as they are ori-
ented towards consolidating a community around
a number of key topics that, in the end, will allow
networking of language technology professionals
and their clients, as well as easy sharing of data,
corpora, language resources and tools.
From this perspective, FLaReNet has three
main lines of action:
The creation and mobilization of a unified
and committed community in the field of Lan-
guage Resources and Technologies. To this end,
FLaReNet is bringing together leading experts of
research institutions, academies, companies, fund-
ing agencies, public and private bodies, both at
European and international level, with the spe-
cific purpose of creating consensus around short,
medium and long-term strategic objectives. The
Network is currently composed of around 200 in-
dividuals belonging to academia, research insti-
tutes, industries and government.
The identification of a set of priority themes
on which to stimulate action, under the form of a
roadmap for Language Resources and Technolo-
gies. In order to avoid scattered or conflicting ef-
forts, the major players in the field of Language
Resources and Technologies need to consensually
work together and indicate a clear direction of ac-
tion and a shared policy for the next years. This
will take the form of identification of priorities of
intervention as well as short, medium, and long-
term strategic objectives at all levels, from re-
search directions to implementation choices, from
distribution and access policies to the landscape
of languages, domain and modalities covered by
Language Resources and Technologies.
The elaboration of a blueprint of priority ar-
eas for actions in the field and a coherent set of
recommendations for the policy-makers (funding
agencies especially), the business community and
the public at large. Whatever action cannot be im-
plemented on a long term without the help of the
necessary financial and political framework to sus-
tain them. This is even most true for actions re-
garding Language Resources that typically imply
a sustained effort at national level. To this end,
the FLaReNet Network will propose the priority
themes under the form of consensual recommen-
dations and a plan of action for EC Member States,
other European-wide decision makers, companies,
as well as non-EU and International organizations.
The following Thematic Areas are currently
covered by FLaReNet:
? The Chart for the area of LRs and LT in its
different dimensions
? Methods and models for LR building, reuse,
interlinking, and maintenance
? Harmonisation of formats and standards
? Definition of evaluation and validation proto-
cols and procedures
? Methods for the automatic construction and
processing of Language Resources
FLaReNet builds upon years of research and de-
velopment in the field of standards and language
resources, as well as on the achievements (both
in terms of results and community awareness),
of past EU projects such as EAGLES7, ISLE8,
7http://www.ilc.cnr.it/EAGLES/home.html
8http://www.ilc.cnr.it/EAGLES/isle/ISLE Home Page.htm
180
INTERA9, and LIRICS10. Close collaboration is
also established with many relevant ongoing EU
projects, such as CLARIN11.
9http://www.elda.org/intera
10http://lirics.loria.fr/
11http://www.clarin.eu
181
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 145?152,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Query Expansion using LMF-Compliant Lexical Resources
Tokunaga Takenobu
Tokyo Inst. of Tech.
Dain Kaplan
Tokyo Inst. of Tech.
Nicoletta Calzolari
ILC/CNR
Monica Monachini
ILC/CNR
Claudia Soria
ILC/CNR
Virach Sornlertlamvanich
TCL, NICT
Thatsanee Charoenporn
TCL, NICT
Xia Yingju
Fujitsu R&D Center
Chu-Ren Huang
The Hong Kong Polytec. Univ.
Shu-Kai Hsieh
National Taiwan Normal Univ.
Shirai Kiyoaki
JAIST
Abstract
This paper reports prototype multilin-
gual query expansion system relying on
LMF compliant lexical resources. The
system is one of the deliverables of a
three-year project aiming at establish-
ing an international standard for language
resources which is applicable to Asian
languages. Our important contributions
to ISO 24613, standard Lexical Markup
Framework (LMF) include its robustness
to deal with Asian languages, and its ap-
plicability to cross-lingual query tasks, as
illustrated by the prototype introduced in
this paper.
1 Introduction
During the last two decades corpus-based ap-
proaches have come to the forefront of NLP re-
search. Since without corpora there can be no
corpus-based research, the creation of such lan-
guage resources has also necessarily advanced
as well, in a mutually beneficial synergetic re-
lationship. One of the advantages of corpus-
based approaches is that the techniques used
are less language specific than classical rule-
based approaches where a human analyses the
behaviour of target languages and constructs
rules manually. This naturally led the way
for international resource standardisation, and in-
deed there is a long standing precedent in the
West for it. The Human Language Technol-
ogy (HLT) society in Europe has been particu-
larly zealous in this regard, propelling the cre-
ation of resource interoperability through a se-
ries of initiatives, namely EAGLES (Sanfilippo et
al., 1999), PAROLE/SIMPLE (Lenci et al, 2000),
ISLE/MILE (Ide et al, 2003), and LIRICS1. These
1http://lirics.loria.fr/
continuous efforts have matured into activities in
ISO-TC37/SC42, which aims at making an inter-
national standard for language resources.
However, due to the great diversity of languages
themselves and the differing degree of technolog-
ical development for each, Asian languages, have
received less attention for creating resources than
their Western counterparts. Thus, it has yet to be
determined if corpus-based techniques developed
for well-computerised languages are applicable on
a broader scale to all languages. In order to effi-
ciently develop Asian language resources, utilis-
ing an international standard in this creation has
substantial merits.
We launched a three-year project to create an
international standard for language resources that
includes Asian languages. We took the following
approach in seeking this goal.
? Based on existing description frameworks,
each research member tries to describe sev-
eral lexical entries and find problems with
them.
? Through periodical meetings, we exchange
information about problems found and gen-
eralise them to propose solutions.
? Through an implementation of an application
system, we verify the effectiveness of the pro-
posed framework.
Below we summarise our significant contribution
to an International Standard (ISO24613; Lexical
Markup Framework: LMF).
1st year After considering many characteristics
of Asian languages, we elucidated the shortcom-
ings of the LMF draft (ISO24613 Rev.9). The
draft lacks the following devices for Asian lan-
guages.
2http://www.tc37sc4.org/
145
(1) A mapping mechanism between syntactic
and semantic arguments
(2) Derivation (including reduplication)
(3) Classifiers
(4) Orthography
(5) Honorifics
Among these, we proposed solutions for (1) and
(2) to the ISO-TC37 SC4 working group.
2nd year We proposed solutions for above the
(2), (3) and (4) in the comments of the Committee
Draft (ISO24613 Rev. 13) to the ISO-TC37 SC4
working group. Our proposal was included in DIS
(Draft International Standard).
(2?) a package for derivational morphology
(3?) the syntax-semantic interface resolving the
problem of classifiers
(4?) representational issues with the richness of
writing systems in Asian languages
3rd year Since ISO 24613 was in the FDIS stage
and fairly stable, we built sample lexicons in Chi-
nese, English, Italian, Japanese, and Thai based
on ISO24613. At the same time, we implemented
a query expansion system utilising rich linguis-
tic resources including lexicons described in the
ISO 24613 framework. We confirmed that a sys-
tem was feasible which worked on the tested lan-
guages (including both Western and Asian lan-
guages) when given lexicons compliant with the
framework. ISO 24613 (LMF) was approved by
the October 2008 ballot and published as ISO-
24613:2008 on 17th November 2008.
Since we have already reported our first 2 year
activities elsewhere (Tokunaga and others, 2006;
Tokunaga and others, 2008), we focus on the
above query expansion system in this paper.
2 Query expansion using
LMF-compliant lexical resources
We evaluated the effectiveness of LMF on a mul-
tilingual information retrieval system, particularly
the effectiveness for linguistically motivated query
expansion.
The linguistically motivated query expansion
system aims to refine a user?s query by exploiting
the richer information contained within a lexicon
described using the adapted LMF framework. Our
lexicons are completely complaint with this inter-
national standard. For example, a user inputs a
keyword ?ticket? as a query. Conventional query
expansion techniques expand this keyword to a
set of related words by using thesauri or ontolo-
gies (Baeza-Yates and Ribeiro-Neto, 1999). Using
the framework proposed by this project, expand-
ing the user?s query becomes a matter of following
links within the lexicon, from the source lexical
entry or entries through predicate-argument struc-
tures to all relevant entries (Figure 1). We focus
on expanding the user inputted list of nouns to rel-
evant verbs, but the reverse would also be possible
using the same technique and the same lexicon.
This link between entries is established through
the semantic type of a given sense within a lexical
entry. These semantic types are defined by higher-
level ontologies, such as MILO or SIMPLE (Lenci
et al, 2000) and are used in semantic predicates
that take such semantic types as a restriction ar-
gument. Since senses for verbs contain a link to
a semantic predicate, using this semantic type, the
system can then find any/all entries within the lexi-
con that have this semantic type as the value of the
restriction feature of a semantic predicate for any
of their senses. As a concrete example, let us con-
tinue using the ?ticket? scenario from above. The
lexical entry for ?ticket? might contain a semantic
type definition something like in Figure 2.
<LexicalEntry ...>
<feat att="POS" val="N"/>
<Lemma>
<feat att="writtenForm"
val="ticket"/>
</Lemma>
<Sense ...>
<feat att="semanticType"
val="ARTIFACT"/>
...
</Sense>
...
</LexicalEntry>
Figure 2: Lexical entry for ?ticket?
By referring to the lexicon, we can then derive
any actions and events that take the semantic type
?ARTIFACT? as an argument.
First all semantic predicates are searched for ar-
guments that have an appropriate restriction, in
this case ?ARTIFACT? as shown in Figure 3, and
then any lexical entries that refer to these predi-
cates are returned. An equally similar definition
would exist for ?buy?, ?find? and so on. Thus,
by referring to the predicate-argument structure of
related verbs, we know that these verbs can take
146
<LexicalEntry ...>
  <feat att="POS" val="Noun"/>
  <Lemma>
    <feat att="writtenForm" val="ticket"/>
  </Lemma>
  <Sense ...>
    <feat att="semanticType" val="ARTIFACT"/>
    ...
  </Sense>
  ...
</LexicalEntry>
User Inputs
ticket
<Sense>
<SemanticFeature>
Semantic Features of type 
"restriction" that take 
Sense's semanticType
All senses for 
matched nouns
<SemanticPredicate 
  id="pred-sell-1">
  <SemanticArgument>
    <feat att="label" val="X"/>
    <feat att="semanticRole" val="Agent"/>
    <feat att="restriction" val="Human"/>
  </SemanticArgument>
  ...
  <SemanticArgument>
    <feat att="label" val="Z"/>
    <feat att="semanticRole" val="Patient"/>
    <feat att="restriction" 
          val="ARTIFACT,LOCATION"/>
  </SemanticArgument>
</SemanticPredicate>
All Semantic Predicates 
that contain matched 
Semantic Features
<Sense>
Senses that use matched 
Semantic Predicates
<LexicalEntry ...>
  <feat att="POS" val="Verb"/>
  <Lemma>
    <feat att="writtenForm" val="sell"/>
  </Lemma>
  <Sense id="sell-1" ...>
    ...
    <PredicativeRepresentation
      predicate="pred-sell-1" ...>
  </Sense>
</LexicalEntry>
<LexicalEntry>
<SemanticPredicate>
<LexicalEntry>
System outputs
"sell", ...
For each <Sense> find all 
<SemanticArgument> that 
take this semanticType as 
a feature of type 
"restriction"
Find all verbs <LexicalEntry> 
that use these 
<SemanticPredicate>
All verbs that have 
matched Senses
Figure 1: QE Process Flow
147
<LexicalEntry ...>
<feat att="POS" val="V"/>
<Lemma>
<feat att="writtenForm"
val="sell"/>
</Lemma>
<Sense id="sell-1" ...>
<feat att="semanticType"
val="Transaction"/>
<PredicativeRepresentation
predicate="pred-sell-1"
correspondences="map-sell1">
</Sense>
</LexicalEntry>
<SemanticPredicate id="pred-sell-1">
<SemanticArgument ...>
...
<feat att="restriction"
val="ARTIFACT"/>
</SemanticArgument>
</SemanticPredicate>
Figure 3: Lexical entry for ?sell? with its semantic
predicate
?ticket? in the role of object. The system then re-
turns all relevant entries, here ?buy?, ?sell? and
?find?, in response to the user?s query. Figure 1
schematically shows this flow.
3 A prototype system in detail
3.1 Overview
To test the efficacy of the LMF-compliant lexi-
cal resources, we created a system implementing
the query expansion mechanism explained above.
The system was developed in Java for its ?com-
pile once, run anywhere? portability and its high-
availability of reusable off-the-shelf components.
On top of Java 5, the system was developed us-
ing JBoss Application Server 4.2.3, the latest stan-
dard, stable version of the product at the time of
development. To provide fast access times, and
easy traversal of relational data, a RDB was used.
The most popular free open-source database was
selected, MySQL, to store all lexicons imported
into the system, and the system was accessed, as a
web-application, via any web browser.
3.2 Database
The finalised database schema is shown in Fig-
ure 4. It describes the relationships between en-
tities, and more or less mirrors the classes found
within the adapted LMF framework, with mostly
only minor exceptions where it was efficacious for
querying the data. Due to space constraints, meta-
data fields, such as creation time-stamps have been
left out of this diagram. Since the system also al-
lows for multiple lexicons to co-exist, a lexicon id
resides in every table. This foreign key has been
highlighted in a different color, but not connected
via arrows to make the diagram easier to read. In
addition, though in actuality this foreign key is not
required for all tables, it has been inserted as a con-
venience for querying data more efficiently, even
within join tables (indicated in blue). Having mul-
tiple lexical resources co-existing within the same
database allows for several advantageous features,
and will be described later. Some tables also con-
tain a text id, which stores the original id attribute
for that element found within the XML. This is
not used in the system itself, and is stored only for
reference.
3.3 System design
As mentioned above, the application is deployed
to JBoss AS as an ear-file. The system it-
self is composed of java classes encapsulating
the data contained within the database, a Pars-
ing/Importing class for handling the LMF XML
files after they have been validated, and JSPs,
which contain HTML, for displaying the inter-
face to the user. There are three main sections
to the application: Search, Browse, and Config-
ure. Explaining last to first, the Configure section,
shown in Figure 5, allows users to create a new
lexicon within the system or append to an exist-
ing lexicon by uploading a LMF XML file from
their web browser, or delete existing lexicons that
are no longer needed/used. After import, the data
may be immediately queried upon with no other
changes to system configuration, from within both
the Browse and Search sections. Regardless of
language, the rich syntactic/semantic information
contained within the lexicon is sufficient for car-
rying out query expansion on its own.
The Browse section (Figure 6) allows the user to
select any available lexicon to see the relationships
contained within it, which contains tabs for view-
ing all noun to verb connections, a list of nouns, a
list of verbs, and a list of semantic types. Each has
appropriate links allowing the user to easily jump
to a different tab of the system. Clicking on a noun
takes them to the Search section (Figure 7). In this
section, the user may select many lexicons to per-
form query extraction on, as is visible in Figure 7.
148
semantic_link 
VARCHAR (64)
sense
sense_id
PRIMARY KEY
synset_id
FOREIGN KEY
syn_sem_correspondence_id
FOREIGN KEY
semantic_predicate_id
FOREIGN KEY
semantic_type
VARCHAR (64)
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
lexicon_id
FOREIGN KEY
text_id
VARCHAR (100)
semantic_predicate_id
PRIMARY KEY
semantic_predicate
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
semantic_argument_id
PRIMARY KEY
semantic_argument
value
VARCHAR (100)
attribute
VARCHAR (100)
lexicon_id
FOREIGN KEY
semantic_feature_id
PRIMARY KEY
semantic_feature
lexicon_id
FOREIGN KEY
semantic_argument_id
FOREIGN KEY
semantic_predicate_id
FOREIGN KEY
semantic_predicate_to_argument
lexicon_id
FOREIGN KEY
semantic_feature_id
FOREIGN KEY
semantic_argument_id 
FOREIGN KEY
semantic_argument_to_feature
description
TEXT
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
synset_id
PRIMARY KEY
synset
written_form
VARCHAR (64) NOT NULL
part_of_speech
ENUM( 'Verb', 'Noun' , 'Unknown')
lexical_entry
text_id
VARCHAR (64)
entry_id 
PRIMARY KEY
lexicon_id 
FOREIGN KEY
semantic_feature
FOREIGN KEY
syntactic_feature
FOREIGN KEY
lexicon_id
FOREIGN KEY
argument_map_id
PRIMARY KEY
syn_sem_argument_map
lexicon_id
FOREIGN KEY
argument_map_id
FOREIGN KEY
syn_sem_correspondence_id 
FOREIGN KEY
syn_sem_correspondence_to_map
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
syn_sem_correspondence_id
PRIMARY KEY
syn_sem_correspondence
lexicon_id
FOREIGN KEY
sense_id
FOREIGN KEY
entry_id
FOREIGN KEY
lexical_entry_to_sense
lexicon_id
FOREIGN KEY
text_id
VARCHAR (100)
frame_id
PRIMARY KEY
subcat_frame
lexicon_id
FOREIGN KEY
frame_id
FOREIGN KEY
sense_id
FOREIGN KEY
entry_id
FOREIGN KEY
lexical_entry_to_subcat_frame
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
syntactic_argument_id
PRIMARY KEY
syntactic_argument
value
VARCHAR (100)
attribute
VARCHAR (100)
lexicon_id
FOREIGN KEY
syntactic_feature_id
PRIMARY KEY
syntactic_feature
lexicon_id
FOREIGN KEY
syntactic_argument_id
FOREIGN KEY
frame_id
FOREIGN KEY
subcat_frame_to_argument
lexicon_id
FOREIGN KEY
syntactic_feature_id
FOREIGN KEY
syntactic_argument_id 
FOREIGN KEY
syntactic_argument_to_feature
description
VARCHAR(128)
language
VARCHAR(64)
lexicon_id
PRIMARY KEY
lexicon
relation_type 
VARCHAR (64)
lexicon_id
FOREIGN KEY
related_sense_id
FOREIGN KEY
sense_id
FOREIGN KEY
sense_relation
Figure 4: Database schema
Figure 5: QE System - Configure Figure 6: QE System - Browse
149
Figure 7: QE System - Search
3.4 Semantic information
This new type of query expansion requires rich
lexical information. We augmented our data using
the SIMPLE ontology for semantic types, using
the same data for different languages. This had
the added benefit of allowing cross-language ex-
pansion as a result. In steps two and three of Fig-
ure 1 when senses are retrieved that take specific
semantic types as arguments, this process can be
done across all (or as many as are selected) lex-
icons in the database. Thus, results such as are
shown in Figure 7 are possible. In this figure the
Japanese word for ?nail? is entered, and results for
both selected languages, Japanese and Italian, are
returned. This feature requires the unification of
the semantic type ontology strata.
3.5 Possible extension
Next steps for the QE platform are to explore the
use of other information already defined within the
adapted framework, specifically sense relations.
Given to the small size of our sample lexicon, data
sparsity is naturally an issue, but hopefully by ex-
ploring and exploiting these sense relations prop-
erly, the system may be able to further expand a
user?s query to include a broader range of selec-
tions using any additional semantic types belong-
ing to these related senses. The framework also
contains information about the order in which syn-
tactic arguments should be placed. This informa-
tion should be used to format the results from the
user?s query appropriately.
4 An Additional Evaluation
We conducted some additional query expansion
experiments using a corpus that was acquired from
Chinese LDC (No. ?2004-863-009?) as a base (see
below). This corpus marked an initial achievement
in building a multi-lingual parallel corpus for sup-
porting development of cross-lingual NLP appli-
cations catering to the Beijing 2008 Olympics.
The corpus contains parallel texts in Chinese,
English and Japanese and covers 5 domains that
are closely related to the Olympics: traveling, din-
ing, sports, traffic and business. The corpus con-
sists of example sentences, typical dialogues and
articles from the Internet, as well as other language
teaching materials. To deal with the different lan-
guages in a uniform manner, we converted the cor-
pus into our proposed LMF-compliant lexical re-
sources framework, which allowed the system to
expand the query between all the languages within
the converted resources without additional modifi-
cations.
As an example of how this IR system func-
tioned, suppose that Mr. Smith will be visiting
Beijing to see the Olympic games and wants to
know how to buy a newspaper. Using this system,
he would first enter the query ?newspaper?. For
this query, with the given corpus, the system re-
turns 31 documents, fragments of the first 5 shown
below.
(1) I?ll bring an English newspaper immediately.
(2) Would you please hand me the newspaper.
(3) There?s no use to go over the newspaper ads.
(4) Let?s consult the newspaper for such a film.
(5) I have little confidence in what the newspa-
pers say.
Yet it can be seen that the displayed results are not
yet useful enough to know how to buy a newspa-
per, though useful information may in fact be in-
cluded within some of the 31 documents. Using
the lexical resources, the query expansion module
suggests ?buy?, ?send?, ?get?, ?read?, and ?sell?
as candidates to add for a revised query.
Mr. Smith wants to buy a newspaper, so he se-
lects ?buy? as the expansion term. With this query
the system returns 11 documents, fragments of the
first 5 listed below.
(6) I?d like some newspapers, please.
150
(7) Oh, we have a barber shop, a laundry, a store,
telegram services, a newspaper stand, table
tennis, video games and so on.
(8) We can put an ad in the newspaper.
(9) Have you read about the Olympic Games of
Table Tennis in today?s newspaper, Miss?
(10) newspaper says we must be cautious about
tidal waves.
This list shows improvement, as information about
newspapers and shopping is present, but still ap-
pears to lack any documents directly related to
how to buy a newspaper.
Using co-occurrence indexes, the IR system
returns document (11) below, because the noun
?newspaper? and the verb ?buy? appear in the
same sentence.
(11) You can make change at some stores, just buy
a newspaper or something.
From this example it is apparent that this sort
of query expansion is still too naive to apply to
real IR systems. It should be noted, however, that
our current aim of evaluation was in confirming
the advantage of LMF in dealing with multiple
languages, for which we conducted a similar run
with Chinese and Japanese. Results of these tests
showed that in following the LMF framework in
describing lexical resources, it was possibile to
deal with all three languages without changing the
mechanics of the system at all.
5 Discussion
LMF is, admittedly, a ?high-level? specification,
that is, an abstract model that needs to be fur-
ther developed, adapted and specified by the lex-
icon encoder. LMF does not provide any off-the-
shelf representation for a lexical resource; instead,
it gives the basic structural components of a lexi-
con, leaving full freedom for modeling the partic-
ular features of a lexical resource. One drawback
is that LMF provides only a specification manual
with a few examples. Specifications are by no
means instructions, exactly as XML specifications
are by no means instructions on how to represent
a particular type of data.
Going from LMF specifications to a true instan-
tiation of an LMF-compliant lexicon is a long way,
and comprehensive, illustrative and detailed ex-
amples for doing this are needed. Our prototype
system provides a good starting example for this
direction. LMF is often taken as a prescriptive
description, and its examples taken as pre-defined
normative examples to be used as coding guide-
lines. Controlled and careful examples of conver-
sion to LMF-compliant formats are also needed to
avoid too subjective an interpretation of the stan-
dard.
We believe that LMF will be a major base
for various SemanticWeb applications because it
provides interoperability across languages and di-
rectly contributes to the applications themselves,
such as multilingual translation, machine aided
translation and terminology access in different lan-
guages.
From the viewpoint of LMF, our prototype
demonstrates the adaptability of LMF to a rep-
resentation of real-scale lexicons, thus promoting
its adoption to a wider community. This project
is one of the first test-beds for LMF (as one of
its drawbacks being that it has not been tested on
a wide variety of lexicons), particularly relevant
since it is related to both Western and Asian lan-
guage lexicons. This project is a concrete attempt
to specify an LMF-compliant XML format, tested
for representative and parsing efficiency, and to
provide guidelines for the implementation of an
LMF-compliant format, thus contributing to the
reduction of subjectivity in interpretation of stan-
dards.
From our viewpoint, LMF has provided a for-
mat for exchange of information across differently
conceived lexicons. Thus LMF provides a stan-
dardised format for relating them to other lexical
models, in a linguistically controlled way. This
seems an important and promising achievement in
order to move the sector forward.
6 Conclusion
This paper described the results of a three-year
project for creating an international standard for
language resources in cooperation with other ini-
tiatives. In particular, we focused on query expan-
sion using the standard.
Our main contribution can be summarised as
follows.
? We have contributed to ISO TC37/SC4 ac-
tivities, by testing and ensuring the portabil-
ity and applicability of LMF to the devel-
opment of a description framework for NLP
lexicons for Asian languages. Our contribu-
tion includes (1) a package for derivational
151
morphology, (2) the syntax-semantic inter-
face with the problem of classifiers, and (3)
representational issues with the richness of
writing systems in Asian languages. As of
October 2008, LMF including our contribu-
tions has been approved as the international
standard ISO 26413.
? We discussed Data Categories necessary
for Asian languages, and exemplified sev-
eral Data Categories including reduplication,
classifier, honorifics and orthography. We
will continue to harmonise our activity with
that of ISO TC37/SC4 TDG2 with respect to
Data Categories.
? We designed and implemented an evaluation
platform of our description framework. We
focused on linguistically motivated query ex-
pansion module. The system works with lexi-
cons compliant with LMF and ontologies. Its
most significant feature is that the system can
deal with any language as far as the those lex-
icons are described according to LMF. To our
knowledge, this is the first working system
adopting LMF.
In this project, we mainly worked on three
Asian languages, Chinese, Japanese and Thai, on
top of the existing framework which was designed
mainly for European languages. We plan to dis-
tribute our results to HLT societies of other Asian
languages, requesting for their feedback through
various networks, such as the Asian language re-
source committee network under Asian Federation
of Natural Language Processing (AFNLP)3, and
the Asian Language Resource Network project4.
We believe our efforts contribute to international
activities like ISO-TC37/SC45 (Francopoulo et al,
2006).
Acknowledgments
This research was carried out through financial
support provided under the NEDO International
Joint Research Grant Program (NEDO Grant).
References
R. Baeza-Yates and B. Ribeiro-Neto. 1999. Modern
Information Retrieval. Addison-Wesley.
3http://www.afnlp.org/
4http://www.language-resource.net/
5http://www.tc37sc4.org/
G. Francopoulo, G. Monte, N. Calzolari, M. Mona-
chini, N. Bel, M. Pet, and C. Soria. 2006. Lex-
ical markup framework (LMF). In Proceedings of
LREC2006.
N. Ide, A. Lenci, and N. Calzolari. 2003. RDF in-
stantiation of ISLE/MILE lexical entries. In Pro-
ceedings of the ACL 2003 Workshop on Linguistic
Annotation: Getting the Model Right, pages 25?34.
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola,
M. Monachini, A. Ogonowsky, I. Peters, W. Peters,
N. Ruimy, M. Villegas, and A. Zampolli. 2000.
SIMPLE: A general framework for the development
of multilingual lexicons. International Journal of
Lexicography, Special Issue, Dictionaries, Thesauri
and Lexical-Semantic Relations, XIII(4):249?263.
A. Sanfilippo, N. Calzolari, S. Ananiadou,
R. Gaizauskas, P. Saint-Dizier, and P. Vossen.
1999. EAGLES recommendations on semantic
encoding. EAGLES LE3-4244 Final Report.
T. Tokunaga et al 2006. Infrastructure for standard-
ization of Asian language resources. In Proceedings
of the COLING/ACL 2006 Main Conference Poster
Sessions, pages 827?834.
T. Tokunaga et al 2008. Adapting international stan-
dard for asian language technologies. In Proceed-
ings of the Sixth International Language Resources
and Evaluation (LREC?08).
152
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 161?164,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
The FLaReNet Thematic Network: A Global Forum for Cooperation 
 
 
Nicoletta Calzolari 
Consiglio Nazionale delle Ricerche  
Istituto di Linguistica Computazionale 
?A. Zampolli? 
nicoletta.calzolari@ilc.cnr.it 
Claudia Soria 
Consiglio Nazionale delle Ricerche  
Istituto di Linguistica Computazionale 
?A. Zampolli? 
claudia.soria@ilc.cnr.it 
 
  
 
Abstract 
 
The aim of this short paper is to present the 
FLaReNet Thematic Network for Language 
Resources and Language Technologies to the 
Asian Language Resources Community. 
Creation of a wide and committed community 
and of a shared policy in the field of Language 
Resources is essential in order to foster a 
substantial advancement of the field. This 
paper presents the background, overall 
objectives and methodology of work of the 
project, as well as a set of preliminary results. 
1 Introduction 
The field of Language Resources and 
Technologies has been developing for years to 
reach now a stable and consolidated status, 
attaining the right to be considered a discipline in 
itself, and as testified by the number of 
conferences and publications explicitly dedicated 
to the topic. Even if Language Resources (in the 
widest sense, i.e. spoken, written and multi-
modal resources and basic related tools) have a 
rather short history, they are nowadays 
recognized as one of the pillars of NLP. The 
availability of adequate Language Resources for 
as many languages as possible is a pre-requisite 
for the development of a truly multilingual 
Information Society. 
At the same time, however, the discipline has 
seen considerable fragmentation during those 
years of fast and enthusiast development, and the 
landscape is now composed by a kaleidoscope of 
different, often conflicting initiatives that vary as 
for research directions, theoretical approaches, 
implementation choices, distribution and access 
policies, languages, domain and modalities 
covered, etc. 
The growth of the field in the last years should 
be now complemented by a common reflection 
and by an effort that identifies synergies and 
overcomes fragmentation. The consolidation of 
the area is a pre-condition to enhance 
competitiveness at EU level and worldwide. 
There is the need of working together to define 
common strategies and to identify priorities for 
the field to advance. Multiple concurring signs 
are now indicating that time is ripe for 
establishing an open language infrastructure, 
something that many of us have been pushing 
since some time and that is now increasingly 
recognized in the community at large as a 
necessary step for building on each other 
achievements. 
Such an open infrastructure can only be 
realized if the Language Resources community is 
cohesive enough to be able to focus on a number 
or priority targets and collectively work towards 
them, and, at the same time, whether it is 
powerful enough to permeate the user 
community, the industry, and the policy-makers. 
2 Why FLaReNet  
Creation of the necessary conditions for the 
development of such an infrastructure cannot 
rely on research activities only and even more 
cannot rely on the initiative of individual groups. 
Instead, strategic actions are crucial, such as 
making contacts with and involving all interested 
parties, sensitize the policy makers and 
institutional bodies, involve associations and 
consortia, disseminating widely the results of 
common efforts. Only by mobilizing this wide 
and heterogeneous panorama of actors can such 
an ambitious goal be attained. 
FLaReNet ? Fostering Language Resources 
Network ? is a Thematic Network funded by the 
161
European Commission under the eContentPlus 
framework (ECP-2007-LANG-617001) 1 . The 
FLaReNet Thematic Network was born with the 
specific aim ? as required by the European 
Commission itself ? to enhance European 
competitiveness in the field of Language 
Resources and Technologies, especially by 
consolidating a common vision and fostering a 
European strategy for the future. A major, long-
term objective ? as well as a powerful means for 
community creation ? is creating the preparatory 
environment for making an open language 
infrastructure a reality. 
3 Objectives 
The objectives of FLaReNet are threefold: 
? The creation and mobilization of a 
unified and committed community in the 
field of Language Resources and 
Technologies; 
? The identification of a set of priority 
themes on which to stimulate action, under 
the form of a roadmap for Language 
Resources and Technologies; 
? The elaboration of a blueprint of priority 
areas for actions in the field and a 
coherent set of recommendations for the 
policy-makers (funding agencies 
especially), the business community and 
the public at large. 
3.1 Creation of a community  
FLaReNet has the challenging task of creating a 
network of people around the notion of 
Language Resources and Technologies. To this 
end, FLaReNet is bringing together leading 
experts of research institutions, academies, 
companies, funding agencies, with the specific 
purpose of creating consensus around short, 
medium and long-term strategic objectives. It is 
of foremost importance that the FLaReNet 
Network be composed of the as widest as 
possible representation of experiences, practices, 
research lines, industrial and political strategies; 
this in order to derive an overall picture of the 
field of Language Resources and Technologies 
that is not limited to the European scenario, but 
can also be globally inspired. The Network is 
currently composed of around 200 individuals 
belonging to academia, research institutes, 
industries and government. Such a community 
                                               
1 http://www.flarenet.eu 
also needs to be constantly increased in a 
concentric way that starts from the core 
disciplines but gradually projects itself towards 
?neighboring? ones, such as cognitive science, 
semantic web, etc. 
3.2 Identification of priority themes 
Language technologies and language resources 
are the necessary ingredients for the development 
of applications that will help bridging language 
barriers in a global single information space, in a 
variety of means (the Web as well as 
communication devices) and for a variety of 
channels (spoken and written language alike). It 
is of utmost importance, however, to identify 
priorities as well as short, medium, and long-
term strategic objectives in order to avoid 
scattered or conflicting efforts. 
The major players in the field of Language 
Resources and Technologies need to 
consensually work together and indicate a clear 
direction and priorities for the next years. 
3.3 Elaboration of a blueprint of actions 
However, whatever action cannot be 
implemented on a long term without the help of 
the necessary financial and political framework 
to sustain them. This is even most true for 
actions regarding Language Resources that 
typically imply a sustained effort at national 
level. To this end, the FLaReNet Network must 
propose the priority themes under the form of 
consensual recommendations and a plan of 
action for EC Member States, other European-
wide decision makers, companies, as well as 
non-EU and International organizations. 
 FLaReNet goals are very ambitious and its 
objectives are to be seen in a more global 
framework. Although they are shaped by the 
European landscape of the field of LR&T, its 
mission is therefore inherently cross-boundary: 
in order to attain such goals getting a global view 
is fundamental. 
To this end, it is important that FLaReNet is 
known by the Asian community, and it knows 
the Asian community. Some Asian community 
players are already members of the Network. 
4 How FLaReNet works 
Work in FLaReNet is inherently collaborative.  
Its means are the following: 
? Working groups 
? Organization of workshops and meetings 
162
? External liaisons 
4.1 Working Groups 
Working Groups are intended as ?think-tanks? of 
experts (researchers and users) who jointly 
reflect on selected topics and come up with 
conclusions and recommendations. The Working 
Groups are clustered in thematic areas and carry 
out their activities through workshops, meetings, 
and via a collaborative Wiki platform. The 
FLaReNet Thematic Areas are: 
? The Chart for the area of Language 
Resources and Technologies in its 
different dimensions 
? Methods and models for Language 
Resource building, reuse, interlinking, 
maintenance, sharing, and distribution 
? Harmonization of formats and standards 
? Definition of evaluation and validation 
protocols and procedures 
? Methods for the automatic construction 
and processing of Language Resources. 
4.2 Organization of workshops and 
meetings 
Meetings and events lie at the core of FLaReNet 
action plan and dissemination strategies. They 
can either be specifically oriented to the 
dissemination of results and recommendations 
(content-pushing events) or, rather, to their 
elicitation (content-pulling events). Three types 
of meetings are envisaged: 
? Annual Workshops, such as the 
?European Language Resources and 
Technologies Forum? held in Vienna, 
February 2009 
? Thematic Workshops related to the work 
of Working Groups 
? Liaison meetings (e.g. those with NSF-
SILT, CLARIN, ISO and other projects as 
the need may arise). 
Annual workshops are targeted to gather the  
broad FLaReNet community together. They are 
conceived as big events, and they aim at 
becoming major events in the Language 
Resources and Technology community of the 
kind able to attract a considerable audience. 
Given the success of the formula exploited for 
the FLaReNet ?Vienna Event?2, it is likely that 
Annual workshops will be organized along the 
same lines. However, this type of event cannot 
be repeated on a frequent schedule. At the same 
time, more focused events centered on specific 
topics and with extensive time allocated for 
discussion are essential. 
To this end, Annual Workshops will be 
complemented by many Thematic workshops, 
i.e. more focused, dedicated meetings with a 
more restricted audience. These are directly 
linked to the work being carried out by the 
various Working Groups and are organized in a 
de-centralized manner, by direct initiative of the 
Working Group or Work package Leaders. In an 
attempt to increase FLaReNet sensitivity to hot 
issues, selection of topics and issues to be 
addressed will be also based on a bottom-up 
approach: FLaReNet members and subscribers 
are invited to submit topics of interest either 
freely or as a consequence of ?Call for topics? 
related to particular events. 
Finally, liaison meetings are those elicited by 
FLaReNet to make contact and create synergies 
with national and international projects that are 
partially overlapping with FLaReNet in either 
their objectives or the target audience. Examples 
of these are the FLaReNet-CLARIN and the 
FLaReNet-SILT liaison meetings. 
4.3 External liaisons  
For a Network like FLaReNet, whose aim is the 
development of strategies and recommendations 
for the field of Language Resources and 
Technologies, coordination of actions at a 
worldwide level is of utmost importance. To this 
end, FLaReNet is planning to establish contacts 
and liaisons with national and international 
associations and consortia, such as LDC, ISO, 
ALTA, AFNLP, W3C, TEI, COCOSDA, 
Oriental-COCOSDA. Specific actions of this 
kind have started already, such as the 
International Cooperation Round Table that took 
place in Vienna. The members of the 
International Cooperation Round Table will form 
the initial nucleus of the FLaReNet International 
Advisory Board. 
5 First results and recommendations 
More than a hundred players worldwide gathered 
at the latest FLaReNet Vienna Forum, with the 
                                               
2 http://www.flarenet.eu/?q=Vienna09, see the Event 
Program to get an idea of the event structure. 
163
specific purpose of setting up a brainstorming 
force to make emerge the technological, market 
and policy challenges to be faced in a 
multilingual digital Europe. 
Over a two-day programme, the participants to 
the Forum had the opportunity to start assessing 
the current conditions of the LR&T field and to 
propose emerging directions of intervention. 
Some messages recurred repeatedly across the 
various sessions, as a sign both of a great 
convergence around these ideas and also of their 
relevance in the field. A clear set of priorities 
thus emerged for fostering the field of Language 
Resources and Language Technology. 
Language Resource Creation. The effort 
required to build all needed language resources 
and common tools should impose on all players a 
strong cooperation at the international level and 
the community should define how to enhance 
current coordination of language resource 
collection between all involved agencies and 
ensure efficiency (e.g. through interoperability).  
With data-driven methods dominating the 
current paradigms, language resource building, 
annotation, cataloguing, accessibility, 
availability is what the research community is 
calling for. Major institutional translation 
services, holding large volumes of useful data, 
seem to be ready to share their data and 
FLaReNet could possibly play a facilitating role.  
More efforts should be devoted to solve how to 
automate the production of the large quantity of 
resources demanded, and of enough quality to 
get acceptable results in industrial environments. 
Standards and Interoperability. In the long 
term, interoperability will be the cornerstone of a 
global network of language processing 
capabilities. The time and circumstances are ripe 
to take a broad and forward-looking view in 
order to establish and implement the standards 
and technologies necessary to ensure language 
resource interoperability in the future. This can 
only be achieved through a coordinated, 
community-wide effort that will ensure both 
comprehensive coverage and widespread 
acceptance. 
Coordination of Language Technology 
Evaluation. Looking at the way forward, it 
clearly appears that language technology 
evaluation needs coordination at international 
level: in order to ensure the link between 
technologies and applications, between 
evaluation campaigns and projects, in order to 
conduct evaluation campaigns (for ensuring 
synchrony or for addressing the influence of a 
component on a system on the same data), in 
order to produce language resources from 
language technology evaluation, or to port an 
already evaluated language technology to other 
languages (best practices, tools, metrics, 
protocols?), in order to avoid ?reinventing the 
wheel?, while being very cautious that there are 
language and cultural specificities which have to 
be taken into account (tone languages, oral 
languages with no writing system, etc). 
Availability of Resources, Tools and 
Information. Infrastructure building seems to be 
one of the main messages for FLaReNet. For a 
new worldwide language infrastructure the issue 
of access to Language Resources and 
Technologies is a critical one that should involve 
? and have impact on ? all the community. There 
is the need to create the means to plug together 
different Language Resources & Language 
Technologies, in an internet-based resource and 
technology grid, with the possibility to easily 
create new workflows. Related to this is 
openness and availability of information. The 
related issues of access rights and IPR also call 
for cooperation. 
6 Join FLaReNet 
In order to constantly increase the community of 
people involved in FLaReNet, as well as to 
ensure their commitment to the objectives of the 
Network, a recruiting campaign is always open. 
People wishing to join the Network can do so by 
filling an appropriate web form available on the 
FLaReNet web site. The FLaReNet Network is 
open to participation by public and private, 
research and industrial organizations. 
7 Conclusions 
The field of Language Resources and 
Technologies needs a strong and coherent 
international cooperation policy to become more 
competitive and play a leading role globally. It is 
crucial to discuss future policies and priorities 
for the field of Language Resources and 
Technologies ? as in the mission of FLaReNet ? 
not only on the European scene, but also in a 
worldwide context. Cooperation is an issue that 
needs to be prepared. FLaReNet may become 
one of the privileged places where these ? and 
future ? initiatives get together to discuss and 
promote collaboration actions. 
164
ADAM:  An  Archi tecture for xml -based Dia logue Annotat ion  
on Mult ip le levels 
Claud ia  Sor ia  
ILC - CNR 
Pisa, Italy 
soria@ilc.pi.cnr.it 
Ro ldano  Cat ton i  
ITC-irst 
Trento, Italy 
cattoni@itc.it 
Morena  Danie l i  
CSELT 
Torino, Italy 
Morena.Danieli@cselt.it 
Abst rac t  
In this paper annotation modular- 
ity and use of annotation meta- 
schemes are identified as basic re- 
quirements for achieving actual cor- 
pora reusability. We discuss these 
concepts and the way they are 
implemented in the architectural 
framework of the ADAM corpus, 
which is a corpus of 450 Italian spon- 
taneous dialogues. The design of 
ADAM architecture is compatible 
with as many practices of dialogue 
annotation as possible, as well as ap- 
proaches to annotation at different 
levels. 
1 In t roduct ion  
In this paper we describe the methodological 
assumptions and general architectural frame- 
work underlying the ADAM Corpus, which 
is currently being developed as part of the 
Italian national project SI-TAL (Autori vari, 
2000) 1. Annotated ialogue corpora are of 
crucial importance for the development of vo- 
cal applications. Because of their cost, how- 
ever, it is essential that their acquisition and 
annotation be designed in order to maximize 
their reusability as much as possible. The 
main assumption behind the design of the 
ADAM corpus is that actual reusability of 
corpora cruciMly depends on the strategic 
choices concerning the architectural design of 
the corpus, i.e. the way in which annotation 
tThe final version of the ADAM Corpus will be 
released by the end of 2001. A pilot set, consisting of
30 dialogues, i  currently available. 
is organized and structured, and the way in 
which this is represented in a given physical 
format 2. Corpus reusability is traditionally 
seen as mainly a by-product of either corpus 
representativeness anddegree of standardiza- 
tion of annotation schemes. We claim that 
two other requirements should be taken into 
account when designing and building an anno- 
tated corpus that aims at reusability, namely 
modularity of annotation, and use of annota- 
tion meta-schemes. The meaning of these no- 
tions, as well as the way in which they are 
realized by the ADAM Corpus will be de- 
scribed in detail throughout the paper. Sec- 
tion 2 introduces the corpus; section 3 focuses 
on ADAM: the motivations underlying its ar- 
chitecture are presented and the adoption of 
XML as mark-up language is discussed. Fi- 
nally, the various annotation schemes are il- 
lustrated in section 4. 
2 Corpus  Descr ip t ion  
The ADAM Corpus, which is currently be- 
ing developed, will consist of 450 Italian 
dialogues, both human-human and human- 
machine, belonging to the tourist domain. 
The human-machine component of the corpus 
is represented by human-machine dialogues 
over the phone, which are recordings of ac- 
tual interactions occurring between customers 
and the Italian national railway information 
system (FS-Informa, (Bahia et al, 2000)). 
The human-human component is represented 
by task-oriented dialogues between a person 
playing the role of a travel agent and another 
playing the role of a customer. Each dia- 
logue in the corpus is represented by an or- 
2For a similar view see (Ide and Brew, 2000). 
9 
thographic transcription, recording the words 
uttered by the speakers plus any other non 
linguistic sound. The transcription is linked 
to an audio file in PCM format. In addi- 
tion, each dialogue is annotated according to 
five annotation levels, namely prosody, mor- 
phosyntax, syntax, semantics and pragmatics 
(see below). 
3 ADAM:  Arch i tec tura l  P r inc ip les  
3.1 Reusabi l i ty  Requ i rements  
The ADAM approach is mainly driven by the 
need of meeting the requirements of poten- 
tial users of annotated corpora, with a par- 
ticular emphasis on corpora reusability. An 
annotated corpus is reusable as far as it com- 
plies with several requirements, such as cor- 
pus representativeness and use of standard- 
ized annotation schemes (see some widely 
renoWned standardization efforts uch as EA- 
GLES, MATE, DRI, ATLAS, etc.). The 
physical format or mark-up language for cor- 
pus encoding is another crucial issue, as it 
will be argued in section 3.4. In addition to 
this, we claim that an annotated corpus is 
useful beyond the immediate particular ap- 
plication aims only to the extent o which it 
is designed so as to meet two other important 
needs. A fundamental requirement appears 
to revolve around the way annotation is orga- 
nized, structured and represented in a corpus. 
In short, it is essential that the annotation, 
i.e. the linguistic information added to the 
data, should be easily and quickly modifiable 
at a moderately ow cost by subsequent users 
of the corpus. We can think of at least two 
possible scenarios, referring to two orthogo- 
nal dimensions of customization operations. 
First, it might be the case that a user wishes 
to reuse a corpus which is annotated for sev- 
eral types of linguistic information, but lacks 
of a particular annotation type; the poten- 
tial user could nevertheless be interested in 
the existing annotations, and would like to 
supplement them with a new one. On the 
other hand, it might be the case that a user 
is interested in some annotation only (e.g., 
pos-tagging or syntactic structure) and s/he 
might want to leave aside other annotation 
types. Reusability of an annotated corpus 
can thus be thought of as a function of the 
extent o which new levels of linguistic infor- 
mation can be added, or uninteresting ones 
can be removed. This is what we call the ver- 
tical dimension of customization i annotated 
corpora. Second, for each level of linguistic 
analysis, an annotated corpus is likely to be 
reused depending on the extent o which ex- 
isting annotation can be changed, so as to ac- 
commodate different annotation practices. It 
is often the case that a corpus which is anno- 
tated with a given annotation scheme "hard- 
wires" the annotation so as it is impossible 
to replace the annotation without reverting 
to the raw text and rebuilding the annotation 
from scratch, which is enormously expensive. 
This is what we call the horizontal dimension 
off customization of an annoted corpus. 
The extent to which an annotated corpus 
can be compliant with these two requirements 
clearly depends on the architectural choices 
made at the design level: if, for instance, all 
types of annotation are flattened onto a single 
representation level, it is clear that the cus- 
tomizing operations above become hardly fea- 
sible. We claim that the vertical and horizon- 
tal customization requirements can be easily 
achieved on the one hand by appealing to the 
two related notions of modularity of annota- 
tion and use of annotation meta-schemes, and 
on the other by exploiting a physical format 
of encoding that fully supports them. In the 
next three sections we illustrate the two con- 
cepts as well as the way they are implemented 
in the ADAM Corpus. 
3.2 Annotation Modularity 
In an annotated corpus, several different 
types of annotation or linguistic information 
may be present in relation to the same in- 
put data. These types of information can be 
thought of as independent, yet related, levels 
or dimensions of linguistic description . We 
thus can think of a level of prosodic analy- 
sis, another of pos-tagging, another of seman- 
tic analysis, etc. By annotat ion  modular -  
i ty  we mean that the different layers of an- 
10 
notation are to be kept independent one of 
another. In the ADAM Corpus we provide 
five layers of annotation: prosodic, morpho- 
syntactic (pos tagging), syntactic, conceptual- 
semantic, and pragmatic. Each dialogue in 
the corpus is annotated at the above five lev- 
els of analysis; synchronization among the dif- 
ferent analyses and between these and the 
speech signal is ensured by the different anno- 
tations (stored as separate files) making ref- 
erence to the same input file. This file, con- 
taining the transcription ofthe dialogue, is in 
turn linked to the audio file in PCM (a-low 
or u-low) format. As it will be argued in sec- 
tion 3.3, support for this structure isprovided 
by the use of XML as mark-up language. By 
adopting this structure, annotation layers are 
linguistically heterogeneous and mutually or- 
thogonal, so that changing one of them af- 
fects others only to a limited extent; layers 
are nevertheless indirectly related through a) 
their hinging on a common reference file (the 
"raw" text represented by the transcription 
file); b) the indirect correlation of the lin- 
guistic information they convey. This verti- 
cal modularity of the ADAM approach has 
interesting consequences for the purposes of 
reusability. A potential user of the ADAM 
Corpus is left free to select, among the pro- 
posed levels of annotation, those which best 
reflect his/her theoretical nd practical inter- 
ests. (S)he can also feel the need for adding 
a new layer of information, ot contemplated 
in today's ADAM realization. By the way, 
level modularity is also of theoretical inter- 
est, since most annotation schemes we know 
differ mainly in the way pieces of linguistic in- 
formation categorized, rather than in the in- 
trinsic nature of these levels. Moreover, level 
modularity seems to have a useful impact on 
our theoretical understanding of the linguistic 
phenomena at stake, since it is capable of ex- 
pressing correlations between layers, and ulti- 
mately between dimensions of linguistic anal- 
ysis. 
3.3 Annotat ion meta-schemes 
Horizontal customization i annotated cor- 
pora can be enhanced by implementing the 
concept of annotation meta-schemes. The 
different layers of linguistic description ira- 
pried by the concept of annotation modular- 
ity presuppose as many annotation schemes. 
As it will be made clear in section 4, for 
each of the five annotation layers envisaged 
for the ADAM Corpus, a particular annota- 
tion scheme has been designed and applied. 
However, it should be emphasized how the 
ADAM specifications do not merely amount 
to another set of ready-made, off-the-shelf an- 
notation schemes. Rather, we would like to 
focus the attention on what we call an an- 
notation meta-scheme, and on the implica- 
tions of this choice. According to our view, 
an annotation meta-scheme is a general de- 
scriptive framework in which different annota- 
tion schemes can be accommodated. In many 
cases the same unit of linguistic information 
can be annotated in different, arguably mutu- 
ally incompatible ways, which are nonetheless 
all compatible with the recommended vertical 
modularity described above: so it is better 
to provide the potential user with the pos- 
sibility of adopting any arbitrary annotation 
scheme without being forced to re-build the 
annotation from scratch or to forcefully com- 
ply with some other annotation scheme, no 
matter how standardized. To do so, it is nec- 
essary to have a representation format for the 
annotation that is general enough for com- 
peting schemes to be mutually substitutable. 
In ADAM we achieve this aim by building 
a general scheme where those features that 
are common to several competing schemes be- 
come slots or descriptive lement ags to be 
associated with linguistic elements; the val- 
ues of these attributes can be any arbitrary 
set of tags. Let's consider, for instance, the 
case of pragmatic annotation. The main dif- 
ference between annotation schemes for this 
level of analysis lies in the particular types of 
dialogue act chosen rather than in the notion 
of dialogue act itself, which appears to be un- 
controversial. If, however, we adopt a scheme 
where the basic descriptive element of any ar- 
bitrarily long set of words is the general tag 
<dialogue act>, further described by an at- 
tribute type, different schemes can be applied 
11 
to the same corpus without totally discarding 
the existing annotation: a substitution i  the 
set of values will be enough. It is our belief 
that enforcing this practice in the design of 
annotation schemes will bring us to more ef- 
fective corpora exchange and reuse 3 
3.4 XML-based  Annotat ion  
In fact, actual corpus reusability also cru- 
cially depends on the physical \]ormat or mark- 
up language used for corpus encoding. The 
mark-up language used for the ,encoding of the 
ADAM Corpus is XML. XML proved to be 
the ideal candidate for a number of reasons, 
all related to corpus reusability. First, it is 
an emerging and widespread standard, which 
ensures a good degree of corpus reusability 
in the times to come. Second, because of 
its platform-independence it enhances the po- 
tential for wide circulation of the annotated 
material, together with a considerable flexi- 
bility of use. More crucially, however, XML 
proved essential for implementation f the ar- 
chitectural choices described above. Anno- 
tation modularity is supported via extensive 
use of Xlink elements (DeRose et al, 2000). 
Each XML element in the annotation files is 
actually an hypertextual link which refers to 
an element (or set of elements) in the tran- 
scription file. All annotations for each di- 
alogue are thus connected to the same in- 
put reference source (the transcription), thus 
ensuring synchronization of the different an- 
notations and still preserving their indepen- 
dence. On the other hand, the concept of 
annotation meta-scheme is implemented by 
making the XML translation of the different 
annotation schemes content-independent. In 
other words, a general preference was given 
towards representing the different ~nnotation 
tags as values of generic, scheme-independent 
attributes of XML elements. In this way the 
different annotation schemes (represented as 
different DTDs) are represented in a generic 
enough way, so that a future user of the cor- 
pus will only need to change the values of 
Sin addition, the meta-scheme can be seen as a 
tool for effective compariso n of alternative annotation 
schemes. 
the different attributes for the entire annota- 
tion scheme to be changed. We believe that 
this approach represents a further value of the 
ADAM Corpus. 
3.5 Prev ious  and re lated work  
Our work builds on some important standard- 
ization efforts which were going on during the 
past few years in the field of dialogue an- 
notation (DRI, EAGLES, and MATE). We 
are also indebted to the experience gained 
in other projects using stand-off XML an- 
notation, and in particular to the MATE 
project. The multi-level markup framework 
adopted in ADAM closely reflects the MATE 
approach (Dybkjaer et al, 1998). In addi- 
tion, in our project we are using the MATE 
workbench (Dybkjaer and Bernsen, 2000) for 
visualization and information extraction pur- 
poses. However, at the best of our knowl- 
edge ADAM is the first corpus being archi- 
tecturally designed by explicitly adopting the 
concept of annotation modularity and meta- 
scheme at different levels. A recent standard- 
ization project in the annotation field is con- 
stituted by the ATLAS (Bird et al, 2000) con- 
sortium, including NIST, LDC and MITRE. 
The ATLAS architecture is based on a formal 
model for annotating linguistic data (Bird 
and Liberman, 1999). ATLAS offers a three- 
layers solution to the problem of integrating 
different data storage formats by providing 
a logical level which consists of the language 
formalism and the API. The architecture we 
are proposing for the ADAM corpus is not 
a software architecture such as the one im- 
plemented by ATLAS. While the latter one 
meets the requirement of flexible and dynamic 
extension of the sofware modules, the ADAM 
architecture mainly refers to functional orga- 
nization of the different annotation layers. In 
ADAM the flexibility requirement is about 
the possible xtensions of those layers. In ad- 
dition, the ATLAS architecture covers a large 
variety of possibly annotated ata (not only 
linguistic data, but visual data of different 
kinds too), while ADAM is only focused on 
linguistic and speech annotations. 
12 
4 Leve ls  o f  Annotat ion  
The ADAM's five levels of annotation were 
mainly chosen in consideration of their inter- 
est for practical applications of the annotated 
material. In spite of the number of levels con- 
sidered, and their sometimes conflicting re- 
quirements, we tried to develop a coherent, 
unitary approach to design and application 
of annotation schemes. In particular, in de- 
veloping the different annotation schemes for 
the five levels envisaged, attention was paid 
to be consistent with criteria of robustness, 
wide coverage and compliance with existing 
standards. 
4.1 The prosodic  level 
For the annotation of the prosodic phenomena 
of dialogue we are adopting the meta-scheme 
for prosody annotation developed by Quazza 
and Garrido (Klein et al, 1998) within the 
MATE project. This meta-scheme allows to 
annotate the prosodic phenomena of natural 
dialogue by distinguishing the following four 
sub-levels of prosodic annotation: 
? phonetic transcription 
? phonetic representation f intonation 
? phonological representation f intonation 
? prosodic phrasing 
The four levels do not represent a fixed hi- 
erarchy. The two phonetic levels are directly 
aligned with the speech signal and in this 
sense may be considered as base levels. The 
two phonological levels keep a natural rela- 
tionship both with the base prosodic levels 
and with other linguistic units. In the actual 
use of the scheme, the levels and their links 
can be fully or partially specified. In a lin- 
guistic text-oriented analysis, prosody could 
be considered in its function, leaving out the 
details of its realization. In this case, the sole 
phonological levels may be filled and linked 
to the orthographic level of words. Com- 
plex schemes like ToBI could be used in this 
way, or simpler schemes providing labels to 
distinguish types of accents, associated with 
words, and types of intonation boundaries. In 
a speech technology context, a more signal- 
oriented approach could be adopted. In or- 
der to recognize or synthesize prosodic pat- 
terns, detailed phonetic descriptions are nec- 
essary, requiring both phonetic segmentation 
and phonetic representation f intonation - in 
terms of pitch movements or target f0 levels. 
The ADAM prosodic annotation is done at 
the level of the prosodic phrasing. The third 
section of Appendix B reports an excerpt 
of the prosodic annotation file of a human- 
human dialogue of the corpus. These are four 
dialogue turns whose text is translated in the 
first section of the Appendix. The element 
breakindex allows to encode the ToBI labels 
which constitute the values of the attribute 
type. For example, the brkndx_O07 is an- 
notated with type label 3p to mark-up an 
hesitation pause. 
4.2 The Morpho~Syntact ic  and 
Syntact ic  Levels 
The ADAM proposal for the morphosyntac- 
tic level is a two-layer annotation structure, 
containing respectively information on word 
category and morphosyntactic features (pos 
tagging), and non recursive phrasal nuclei 
(called chunks). Robustness and coverage 
were a crucial aspect in the development of 
the two schemes, in particular for what con- 
cerns i) syntactic onstructions specific of spo- 
ken dialogues (ellipses, anacolutha, non ver- 
bal predicative sentences etc.), and ii) dis- 
fluencies (repetitions, false starts, trailing off 
etc.). The morphosyntactic annotation level 
encodes the following information: a) iden- 
tification of morphological words and linking 
to their corresponding orthographic ounter- 
parts; b) annotation of their pos-category; c)
annotation of morphosyntactic features (such 
as number, gender, person, tense, etc.); d) an- 
notation of their corresponding lemma. The 
partic~ar tag set, though adapted to repre- 
sentation of Italian, is compliant with EA- 
GLES recommendations (Gibbon, 1999). In 
addition, the tag set is structured into a core 
scheme, supplying basic means for annotating 
morphological information, and a periphery 
tag set, which serves the purpose of making 
13 
provision for further linguistic annotation to 
be added to obligatory information. The syn- 
tactic annotation level is built on top of the 
previous one and consists in identification of 
non-recursive phrasal nuclei (called chunks) 
and annotation of their category (Mengel et 
al., 1999). The preference given to shallow 
parsing over, e.g., phrase structure trees is 
chiefly motivated by the locality of the anal- 
ysis offered by this approach, a useful feature 
if one wants to prevent a local parsing failure 
from backfiring and causing the entire parse 
of an utterance to fail. This is particularly 
desirable when dealing with particularly noisy 
and fragmented input such as spoken dialogue 
transcripts. For an illustration of morphosyn- 
tactic and syntactic annotation, see examples 
4 and 5 in Appendix B. 
4.3 The Conceptua l  Level  
The annotation scheme for the conceptual 
level has been designed on the following re- 
quirements and assumptions: 
? portabi l i ty :  although most of concepts 
encode strictly domain-dependent i for- 
mation, the annotation scheme should be 
domain-independent as much as possible; 
? expressiveness:  the scheme should al- 
low the representation of the content of 
complex dialogues; 
? minimal i ty:  a turn should be annotated 
in a unique way; 
? simplicity: the syntactical complexity 
of the concept is to be minlmized; 
? locality: the annotation should not take 
in account he history of the dialogue. 
The proposed annotation scheme takes inspi- 
ration from the so called "Frame-based De- 
scription Languages" (Cattoni and Franconi, 
1990), a well established framework in the 
field of the Knowledge Representation. In 
our annotation scheme a concept is encoded 
like a "frame", a typed structure with "slots". 
Slots represent the properties of the concept 
and its relations with Other concepts. Slots 
are encoded with the couple <slot-name, slot- 
value>: the former contains the name of a 
property, the latter either a simple value or 
a reference to another concept. This recur- 
sion allows the encoding of complex and struc- 
tured semantics information. Concepts are 
typed: different ypes of concepts (e.g. "trip", 
"room") encode different contents to be rep- 
resented. 
For example given the sentence to be an- 
notated "the train leaves from rome at eigth 
o'clock of monday fifteen", its conceptual an- 
notation is: 
<concept id="c_O01" ctype="trip"> 
<slot shame= "transport at ion-t ype" 
svalue =" train"/> 
<slot sname="origin" svalue="rome"/> 
<slot sname="departure-time" svalue="*c_O02"/> 
</concept> 
<concept id="c_O02" ctype="time"> 
<slot sname="hour" svalue="8:00"/> 
<slot sname="week-day" svalue="monday"/> 
<slot sname="month-day " svalue="md15"/> 
</concept> 
where the concept c_001 of type trip 
has tre slots; the slot representing the 
departure- t ime encodes a reference (intro- 
duced by the character '*') to the other con- 
cept c_002 of type time. 
The annotation scheme is domain indepen- 
den/: the tag set does not change when the 
domain changes ince the domain-dependent 
information is encoded in the values of the 
attributes. The user is free to adopt the pre- 
ferred ontology, although a good reference are 
the symbols adopted by the C-STAR consor- 
tium (Waibel, 1996) for the inter-lingua: they 
have been developed on the basis of the ex- 
perience on six different (Asiatic and Euro- 
pean) languages and this appears to guaran- 
tee a good portability inter-lingua. 
4.4 The Pragmat ic  Level 
For annotating the pragmatic level of dia- 
logue, we base our work on the concept of 
dialogue act. Informally speaking, a dia- 
logue act tag is a label belonging to a tag 
set which refers to a given iUocutionary di- 
mension that may be performed by uttering 
a sentence. A dialogue utterance may be an- 
notated with a dialogue act label for repre- 
senting the discourse function it plays in the 
14 
dialogue. The annotation scheme used for the 
pragmatic level of the ADAM corpus is an 
extension of both DAMSL (Core and Allen, 
1997) and SWITCHBOARD-DAMSL (Juraf- 
sky et al, 1997). The extension was not mo- 
tivated by domain, rather by the dependency 
on the dialogue type. Actually, most of dia- 
logue acts encode information that is strictly 
dependent on whether the communication is 
task-oriented, familiar, formal, and so on. So 
the inventory of dialogue acts labei should be 
sufficiently wide to cover different types of di- 
alogues, and sufficiently open to add new dia- 
logue act labels for different annotation tasks. 
For the design of the extended tag set we have 
identified the following requirements and as- 
sumptious: 
? m in ima l i ty :  an utterance should be 
tagged with an unique dialogue act label; 
? context-sensit iveness: each turn is 
managed by considering the previous 
turns, that is the annotation should take 
into account he history of the dialogue. 
The tag set used in the corpus is reported in 
Table 1 (see the Appendix). In Appendix B, 
Section 7 the four dialogue turns translated at 
the beginning of the Appendix are annotated 
by using the ADAM pragmatic tag set. Each 
dialogue turn is annotated as a whole by tag- 
ging the communicative level of the turn itself 
(if it is about the task or about managing the 
task, for example). Within the turn the differ- 
ent communicative intentions are labeled on 
the basis of the dialogue act tag set. 
5 Conc lus ions  
In this paper we have identified two ba- 
sic requirements for achieving actual cor- 
pora reusability, namely annotation modu- 
larity and use of annotation meta-schemes , 
and described how they are addressed in the 
ADAM Corpus. We claim that, for effective 
circulation and re-use of corpora, it is essen- 
tial to make provision for as many practices 
of dialogue annotation as possible, as well as 
approaches to annotation at different levels, 
instead of providing fixed levels and schemes 
of analysis, no matter how standardized. Cor- 
pora will have a chance to be reused as far as 
it will be easy and relatively inexpensive to 
adapt hem to different needs and application 
purposes. Use of XML as mark-up language 
is a further step toward this end. 
Re ferences  
Autori Vari 2000. SITAL: Manuale Operativo. 
Deliverable 1.1, Italy. 
Baggia, P., Castagneri, G. and M. Danieli. 
2000. Field Trials of the Italian ARISE Train 
Timetable System. Speech Communication, 31, 
pages 355-367. 
Bird, S. and M. Liberman. 1999. A Formal 
Framework for Linguistic Annotation. Techni- 
cal Report MS-CIS-99-01, Department ofCom- 
puter and Information Science, University of 
Pennsylvania. 
Bird, S., Day, D., Garofolo, J., Henderson, J., 
Laprun, C. and M. Liberman. 2000. ATLAS: 
A Flexible and Extensible Architecture for Lin- 
guistic Annotation. In Proceedings of LREC 
2000, Athens, Greece. 
Cattoni, R. and E. Franconi. 1990. Walking 
through the Semantics of Frame-Based Descrip- 
tion Languages: A Case Study. In Proceed- 
ings of the Fifth International Symposium IS- 
MIS '90, pages 234--241, Knoxville, TN. 
Core, M. and J. Allen. 1997. Coding Dia- 
logues with the DAMSL Annotation Scheme. 
In Working Notes of the AAAI Fall Symposium 
on Communicative Actions in Humans and Ma- 
chines, pages 28-35. Cambridge, MA. 
DeRose, S., Maler, E., Orchard, D. and B. 
Trafford. 2000. XML Linking Language 
(Xlink). W3C Working Draft, 21 February 
2000. http ://www. w3. org/TR/xlink/. 
Dybkjaer, L., Berusen, N. O., Dybkjaer, H., McK- 
elvie, D., and A. Mengel. 1998. The MATE 
Markup Framework. MATE Deliverable 1.2. 
http://mate, hiS. sdu. dk. 
Dybkjaer, L. and N.-O. Bernsen. 2000. The 
MATE Workbench. In Proceedings of LREC 
P000, Athens, Greece. 
Gibbon, D. (ed.). 1999. Handbook of Standards 
and Resources for Spoken Language Systems. 
First supplement, EAGLES LE3-4244, Spoken 
Language Working Group. 
15 
Ide, N. and C. Brew. 2000. Requirements, Tools, 
and Architectures for Annotwted Corpora. In 
Proceedings o /LREC 2000, Athens, Greece. 
Jura?sky, D., Shriberg, E. and D. Briasca. 1997. 
Switchboard DAMSL Labelhlg Project Coder's 
Manual. Technical Report 97-02, University of 
Colorado, Institute of Cognitive Science, Boul- 
der, CO. http://www, colorado, edu/ling/~ 
juraf sky/manual, august I. html. 
Klein, M., Bernsen, N. 0., Davi~, S., Dybkjaer, 
L., Garrido, J., Kasch, H., Mengel, A., Pirrelli, 
V., Poesio, M., Quazza, S. and\[ C. Sofia. 1998. 
Supported Coding Schemes. MATE Deliver- 
able i.I. http://mate .his. sdu.d.k. 
Mengel, A., Dybkjaer, L., Garrido, J., Heid, U., 
Klein, M., Pirrelli, V., Poesio, M., Quazza, S., 
Schiffrin, A. and C. Sofia. 1999. MATE Dia- 
logue Annotation Guidelines. MATE Deliver- 
able 2.1. http://mate, nis. sdu. dk. 
Waibel, A. 1996. Interactive Translation of Con- 
versational Speech. Computer, 29(7):41-48. 
Append ix  A. D ia logue-Act  Tag Set  
LABEL EXAMPLE 
Statement I 'm leaving today 
Request I 'd need a double 
room 
Accept The flight leaving at 
ten is nice for me 
Accept-Part Yes, but I 'd need an 
extra-bed for my child 
Open-Option Do you want me to 
reserve the return 
flight? 
A~ion-Dire~ive 
Repeat-Rephrase 
Collaborative-Completion 
Conventional-Opening 
Please, reserve two 
seats on the BA3476 
Oh, you said 
BA3476, the one 
leaving at I0 pm 
...and I want to leave 
from NY next Sunday 
Hello, this is the 
Tourist Information 
Desk 
Conventional-Closing Good-bye 
Backchannel/Acknowledge Y s, of course 
Backchannel/Question Is that ok? 
Or-Question Do you prefer a room 
with view on the gar- 
den or on the street? 
Apology Excuse me 
Thanking Thank you for calling 
Offer-Commit 
Yes/No-Question 
I 've to check i f  there 
is a reduced fare 
available 
Do you want to re- 
serve the return flight 
on Thursday? 
Open-Question Which company do 
you prefer to travel? 
Reject No, I don't like to 
travel with this air 
company 
Yes-Answer Yes 
No-Answer No 
Response- 
Acknowledgement 
Dispreferred-Answers 
I agree 
No, I 'd prefer to have 
a smoking room 
Opinion I believe this is the 
best solution 
Appreciation 
Abandoned/Uninterpretabh 
Suggestion 
Signal-Non-Understanding 
Signal-Understanding 
3rd-Paxty-Conversation 
I enjoyed very much 
to work with you 
I t in... 
Perhaps we could try 
with another travel 
agent 
Pardon f
I see 
Fido, stop barking, I 
can't hear a word/ 
Other You know, I 'd need to 
take a week off 
16 
Append ix  B.  Annotat ion  Examples  
1. An example of a short dialogue 
Turn  I (spk A): ~lobearo??er viag~i buongiorno 
globetrotter travel good mo~,'ning 
Turn  2,  ( spk  B) :  buon~iorno sono aDl~ama.v~a de~asperi  eeh 
vo~rei prenotare un(n) v i~ io  in Creno da(a) 1~a a 
ve~na 
good morning my name is Annarnar ia  DegoJpem ehm I 
would like to book a trip by train f rom Roma to Verona 
Turn  3~ (spk  A) :  t reno da ro~aa a verona quando? 
t ra in / rom Roma to Verona when.  ~
2. The XML Transcription File 
<?ranscrip~ion id="d~al_002" type:"hh~"> 
<~uzn ~d""t_001" vho-"A" searS-"0" 0nd="2255" 
f~le:"d~al_002_001 .p~"> 
<spk id="s_001" desc='*brea~:h" S?~="O"  end-"85"/> 
<word ~d="w_001 " S~'~:"85"  end="58~">~lobearo~ter</wo~d> 
<word ~d:"w_002" #~=* '585"  end:"915">v~aEsi</~ord> 
<word ~d="~_003" starts'*915" end:"1445">buo~iorD0</~ord> 
<spk ~d-"s_002" desc="puff" saar~="1445" end="1545"/> 
<pause id="p_001 ' s?~T~="1545" end-"1555"/> 
<spk Id-"s_O03" desc='*p~f" s~ar~="155~" e~d="2255"l> 
</turn> 
<?uzn id="?_002" vho-"B" sears="0 " end="7137" 
fi le="dial_002_002, pcm"> 
<f~l Id="~_001" sCat"L="75" end:"235">e</f~l> 
<word ~d""v_004" seal"t="235" end:"905">buon~orno</word> 
<word id="w_005 " scare="905" end="l145">sono</word> 
<voz~4 id="v_006" ~t~="1145"  end=" lS35">-~la</word> 
<word id="v_O07" s~szt:"1535" end:"2325">de~asperi</word> 
<spk id="s_004" des?="brea~h " start="2325" end="2665"/> 
<pause id="p_002" saar~-"2665" end="2675"/> 
<f~l id-"f .002" saal~="2675" end="2805">e</f~l> 
<word ~d="w.008" saart-"2805" end="3135">vorre~</vord> 
<~oz~d ~d="v_009 " staR="3135" ond-"3835'*>prenc~aro</vord> 
<voz~ id="w 010 " saaz~="3835" end*"4275">un(n)</vord> 
<pause ~d="p_003" start="4275" ~nd-"42S5"/> 
<word id="w_011" steA't:"4285" end="4675">vie, EEio</vord> 
<word ~d:"v_012" start='*4675 '* end=n4slS">in</vord> 
<word id='*v.O13'* sta~="4815" e~d:"543,5">treno</vord> 
<word ~d~"v.014 '* start="5435" *nd-"5815">da(a)</word> 
<word id="v_O~5 " s t~="5815"  end="6105'*>ro~a<l~ord> 
<word id:"w_016" s~a~="6105" snd="6135">a</word> 
<word id:"v_017" s~="6135"  end:"5785">verona</word> 
<pause ~d="p_004" staR="6785" end-"6825"/> 
<spk id~"s.005" desc="puff" stare:"6825" end="7135"/> 
</?urn> 
<?ul-n 1d="t.O03" ~ho="A" s'tax'?="O" end~"2831" 
f ~le="dial_O02.003. pcm"> 
<word id"**~_018" s ta r t : "O"  end:"555">~reno</word> 
<word id='*~_019" stars:"555" end:"895*'>da</word> 
<word ~d'"v_020" s~m="895" ond:"l195">rc~a</wor~ 
<word ~d:"w_021" s~aZ~-"1195" end:"1225">a</vord> 
<word Id="~_022" s~az~:"1225" end="1675">verona</vord> 
<vord ~d="~_023" s~art="1675" end:"2175">quando</vord> 
<spk ~d="s_006" dosc="puf~" s~ez~="2175" end="2465"/> 
<spk id="s_007" desc="pu~f" staz~:*'2465" ends"2815"/> 
<pause id:"p_OOS" stale="2815" end="2835"/> </?u~n> 
</transcript ion> 
3. The XML Prosodic Annotation File 
<prosod~cphrasln 8 id-"d~al_O02"> 
<breakAndex id-"brkndx_O01" aype="l ''
h~ef="d~al.OO2_~:a.~l~1d(v_O01)" start="585" ~nd:"585"/> 
<break,lxulex id="b=kndx_002" type:"1" 
hz~fs-~al_002_?ra.z~l~id(~_002)" searS-"915" end="915"/> 
<breaklndex id="brkndx_O03" aype-"4" 
h~ef="dial_OO2_1~ra.~m1#Id(v.O03)" st~r~="~445" end-"1445"/> 
<bz~ak~dex id="br\]mdx_O04" aype="2" 
~Tef-Odial_002_?ra.=ml#id(~_004)" sta~="905" end="905"/> 
<breakindex id-"br\]mdx_O05" type="1" 
h~ef*"d~al_002_?ra.~l~d(v_O05)*' sear't="1145" en4-"1145"/> 
<hreak/ndez id="brk~dx_O06" tTpe~"l" 
href="dla1_002_tra.~B~d(v_006)" s~r~="1535" ~="I~35"/> 
~oroaYAndex ?d="brlmdx_O07" typo="3p" 
href~"~Lia~_002_tra.~l~d(v_007)" S?~T~="2325 " e~d="232~"/> 
~breaklndox ~du"brknd~_008" aTpo="1" 
h~efe"~al.002_?ra.~iS~d(v_008)" stare-"3135" end="3135"/> 
<breakindex Id='*br~dx_O09" aTpe="l" 
b~ef-"~al.002_~ra.~1#Id(v_009)" s~az~-"3835" end="3835"/> 
<breakindex ~d="t~dx_010" ~ype-"3p" 
href="dla l .OO2_tra.xml~d(v_OlO)"  s tar t : "4275"  end="4275"/> 
? breaklndox id="brkndx_011" CTpe="l" 
h~ef="d~a1.002 ara.xm1#id(v.011)"  saar~="4675" end-"4675"/> 
<~reaXindex Sd="b~dx_012 " aype="2" 
href="d~a1_002_?ra.xml$~d(~_012)" s~az~="4815" ends"4815"/> 
<l~-eak~ndex Id="b~kndx_013" ~ype="2p" 
hrefs"d~al_002 ara.~15~d(~.013)" saart="543S" end="5435"/> 
<break~ndex ~d="brkndx_014" tTpe="lp" 
href-"d~a1_002_?ra.~l~Id(v_014)" start:"5815" end:"5815"/> 
<hreak/ndo: ~d="br~dx_015" ~Tpe="l TM 
hre~:"dial_002_?ra.~lSid(v_015)" s~a~="6105" end:"6105"/> 
<brea2Ande: id="brk=~dx_016" type="1" 
h~ef="dial_002_?ra.~l#id(v_016)" sta~-~="6135" end-"6135"/> 
~broak~=dex Id="brkndx_0/7" aTpe="4 ''
href="d~al_002_?ra.~1=Id(v_017)" san-t="6785" end-"6785"/> 
~oreaklndox id="br~dx.018"  aypo="2p" 
href-"d~al_O02 ara.x~1#~d(v_Ol8)" stars="555" ~nd-"555"/> 
<breaklndex id-"br\]mdx_Ol9" aype="2" 
hre~="d~al_OO2_?ra.~l#id(w_Ol9)" stax~-"$95" ~nd="895"/> 
<break~ndez id="br~mdx.020" aype=-l,, 
hzef-"d~al.002_?ra.~ml#~d(v.020)" staz~="1195" end:"llgS"/> 
~bre~ndox id="br~dx_021" aypeu"l" 
href=,,dial_002 ara.~1$id(v_02|)" star~="1225" end="1225"/> 
~breakindex Id="br~dx_022" Cy!~s"l" 
b1-ef=.d~a.l_OO2_?ra.~l#id(w_022)" s~art:"1675" end="1675"/> 
<break/ride= Id:"brk=~dx_023" aype="4" 
href-"d~al_OO2_?ra.~m1#~d(~_023)" saar~="2~T5" end="2175"/>' 
</phosod~ cp~rasing> 
4. The XML Morphosyntactic Annotation 
File 
~morpho log iaa1~ot  at  ion Id~"dial_O02"> 
<my id="mv_O01" i~ma="~LOBETROTTER" pos="SP" mfeats="NN" 
href=,,dial_OO2_~ra, xmlt id  (v_O01 ) ,,>globearo??ex~/mw> 
<my Id='~w_O02" Ieama=*'VIAGGZO" pos="S" mfea~s="~" 
hrefs"dlal_OO2_tra,  xmlZid(w_O02) ">vla~i</mw> 
<row id="mw_O03" 1/~a="BUONGZOR.NO" pos="I" mfea~s="Z" 
href="dia1_OO2_tra, ml#Id  (w_O03) ">buo~iorno</~v> 
<~v Id="mw.0?4" Inma="BU~GIORN0" pos="I" =~eats-"X" 
hr-ef="dial_002_?ra, mlSid(v_004) ">buongioz~o</mv> 
<my id='~J_00S" I~a="ESSERE" pos="V" mfeats="SIIP" 
href="dia~_002_?ra, zm181d(v.005) ">sono</mw> 
<my ids'~_006" ie~a="ANNAMARIA" pos="SP" mfeats="FS" 
href -"d~al.002_?ra. ~I#i d (v. 006) "> . . . . .  ~a</mv> 
<row Id='~.007" iemma~"DEGASPE~I" posm"$P" mfea~$="NN" 
h~ef=" dial.002_?ra, retold (w_007) ">deEas~er~</~> 
<row Id="mv_008" ie~a="VOLERE " pos="V " mfeats="S|DP" 
href=" d~al_002, tra. ~m1#Id (,_008) ">vozTsi</mw> 
<m~ id="mv_O09" Ie~a-"PRENOT?RE" pos-"V" ~fea~ss"F" 
h~ef="d~al_002_?ra, zml$~d(v_009) ">prenota~e</m~> 
~mv id='hnw_010" lemma="~" pos="RI" mfeats="MS" 
hre~="dla1_002_~ra. ~lSld(w_0~O) ">~m</~> 
id="m~_011" Ie~ma="VIAGGI0" pos="S" mfea~s="MS" 
href="d~a1_002.tra. ~1~d(,_011 ) ">vi~gEio</~v> 
<m~ id="mw_012 " 1~ma="IN" pos="E" mfea~s="X TM 
b~f=-d~al_002.?ra. ~l$$d(w.012) ">in</m~> 
h~f=" d/a1.002, t ra. xm1~id (-_013) ">?re~o</~> 
<row id-'~_014" 1~a="D?" pos="E" mfeats="X" 
h~ef="d~l_002_t ra. m1#id(,_014) ">da</m~> 
<m~ id='~w_015" I~a-"ROM~" pos-"SP" mfea$s="F~" 
hre~="d~al_002_?ra. ~=l~Id(,_015) ">~oma</~> 
<~v id-'~_0~6" le~a-"A" pos="E" mfeats="X" 
href -"d~al.002.t ra. ~l#Id(w_016) ">da</m~> 
<m~ Id="mv_017" le~a="1~t0N?" pos="SP" =feats="FN" 
href ="dla1_002_tra. ~l#Id (v.017) ">verona</mv> 
hze~=-dlal.002_tra, ml$1d (w_018) ">?reno</~> 
<m~ id='~v_019" l~nma="D?" pos="E" ~eats="X"  
hre~,,dla1_OO2_~ra. ~l~id(w_019)  ">da</my> 
<mY ~d:'~_020" Ie~a="ROM?" pos="SP" mfeats="~" 
h~ef:"d/al_002_tra, z~l$~d(v_020) ">~oma</~> 
id="m'~_O~l" e~a=,,A - pcs="E" m~ea~s="Z" 
h~ef-" d~al.002.tra, xmlSld(v_021) ">da<Imv> 
<my Ids"mv_022" ie~a="VEROR?" ~os="SP" ~oaSs="T~" 
hre~=-di~l.OO2_?ra. ~151d (w_022) ">verona</mv> 
<m~ ids"m~_023" lemma="~JE~D0" pos="B" infector"X" 
href =-d~al.002.?ra, x~l$1d(~_023) ">qUaDdO</~> 
</morphol s i ca l  au~ot anion> 
5. The XML Syntactic Annotation File 
<synaac~Icmmot at ion Id="dlal.O02"> 
<pn Id='~n_O01 m aypem"N" href=,,dlal.OO2.mo~.xmlSid(m~.O01)"> 
g lobetrot  t e r  
<h Id="h_O01" href-"dla1_OO2.mor.xmlSld(~v.O01)"/> </pn> 
<pn Id="pn_O02" aypo-'*N" hzef=-dial_OO2_mor.xmlSld(mv_O02)"> 
~h id-"h_O02" h~ef="d/al.OO2_mor.xml#Id(mv.O02)"/> </pn> 
17 
<pn id:"pn.003" ~yp,="INT" href:"dtal_002.mor.xmllid(mv_003)"> 
t~o~ioz~o 
<h id="h_003" href="dial.002_mor.xmll|.d(mv_003)"/> </pn> 
<~n Id:"pn_004" type="INT" hre~:"~al..002.mo~.xmllid(:~_004)"> 
buon~orno 
<h ~d*'*h_004" h~ef="dial_002_mor.zmllld(mv_004)"l> </pn> 
<pn ~d="pn_005" type:"F~" hzef~xd~al_(~2_mor.~mllid(mg_005)"> 
s~no 
<h id-"h.005" href-"d~al_OO2_mor.xmllld(m,a.O05)"l> </pn> 
<pn Id="pn_O06" ?ype:"N" hzef="d~a1.~_mor.xmllld(m~_006)'*> 
<h id:"h.006" h~e~="d~al_002_mor.xml~id(~.006)"/> </~n> 
<pn ~d:"pn.007" ~e=*'F~" href="d~al.(~2_mor.~l#~d(mv_007)"> 
degasper~ 
<h ~d'"h_007" href~"~al_002.mor.xmllJd(mv.007)"/> </pn> 
<pn $d=*'~_008" ~ype-"FV" 
href="d~al_002_m~:, xml$id (my_008).. ~.d (m~.0O9) ">vorrei prenoCaro 
<d ~d:"d.001" Cype='~oda~"-h:ef-"d~al..002.mor.xml#~d(m~.008)"/> 
<h ~d=~h_008" hx~f-"d~al_OO2_m~r.xmlli.d(mw.O09)"l> <IF
<pn ~d="~q~.009" ~ype-'*N" 
href:"d~al_002.mo=, xmll~d (my_010 ).. $ d (row.011 ) ">un v~as~io 
<h id="h_009" hzefa"d~al_002_mor.:~l#~d(m~.011)"/> </~n> 
<pn id="pn_010" Cy~e="P" 
hzof="dlal _002_too=. ::llld (:~_012).. ~ d (row_013) ">In t~r.mo 
<d Stir"d_002" Cype='~rep" hzef*"41al.?~2.mor.~znllid(m~_0$2)"/> 
<h Id-"h_010" href="dial_002.mor.zm1#Id(~_013)"/> </pn> 
<pn id-"~.011" ~ype="P" 
href-"d~al.002.mor .~ll~d(mv_014).. Id (my.015) ">da z~a 
<d td="d_003" ~Fpe-"prep" bzef="d~a1_002_mor.~l#id(mv_014)"/> 
<h id="h_011" hr*~="dlal_OO2.mor.xml#Id(m~_015)"l> <Ipn
<pn ~dz"pn.012" ?~=" I  c'" 
hzef:*'d~a/_002_mor. =~llid (~_016).. i d (m~_0~ 7 ) ">a verona 
<d id'"d_004" ~ype='*prep" href="dial_?~2_mor.~ll~d(mv_016)"/> 
<h ?d:"h_012" href*"d?al_002.mor.xmllJd(mv.0~7)"/> </p~> 
<pn Sd-"pn~013" Cype:"N" href-"dtal.0?2_mor.~lS~d(mv.018)'> 
~reno 
<h id='~_013" hzef="dial_002.mor.xml#~d(~v.018)"/> </F~> 
<pn Sd="l~t_O~4" type:"P" 
~.Tef: "d/a1_002.~or. ~mllid (~.019).. $ d (m~_020) ">da ~oma 
<d id'"d_O05" ~ype="p~ep" hzefz"~al.002_mor.~l#~d(m~.0~9)'*/> 
<h id:"h_014" hzef="d~a/_002.mo:.~llld(mv_020)'t/> </pn> 
<pn ~d="pn_015" ~ype="P" 
bzef = "Hal .  002_mot. ~=nl~id (rag_021).. ~d (~.022) ">a vez~na 
<d ?d:"d_006" ~Tpe="p~ep" href-"d~al_002_~o=.~m1:~d(:~_021)"/> 
<h ~d="h_015" href="d~a1_002_mo=.xml#$d(m~_022)"/> </pn> 
<pn id="pn_016" ~y~:+'ADV" href:"dial.O02_mor.=mll~d(~v_023)"> 
q~do 
<h ?d=*'h_016" bzef="dia1_002_mor.~l#~d(mw_023)"/> < pn> 
</synCact $ca~no~a~on> 
<pr~sat ??a~not a~ton td="d?al_002"> 
<~m ~d""~_00X" hzef-"dlal_002_~ra.xm1~?d(t_001)" 
c~mlevel:'*~ask"> 
g lobet ro t ter  v la~i  bu~nsiorno 
<dialo~ac+ ids"da_OOi" ~ype-"conv-ope" 
href :"d~al.202_~ra. xmlZSd(~_001)., id (v_003) "1> 
</turn> 
<txn~ Id:"~n_002" bxwf=*'d~al_002_zra.rm1:id(t_002)" 
co~level:"~ask"> 
buongiorno sono a ~ . a  desuper i  VOZTei ~renot~re un 
v ia~.o  in treno da x'oma a verona 
<dialogac~ id-"da.002" typ~=*'conv-o~*" 
hr~f:"d~al .~02.~ra,  xml#~d (~_004).. Id(v_0OT)*'l> 
<d~alogac~ id="da.003" ~ype="req" 
href= "dial_202_?ra. ~lS~d (~_008).. ~d(v.017)"/> 
</turn> 
<turn id="?n_003 *' href="~al_002_~ra.:~ll~d(~.003)" 
co~level:*'~ask"> 
? r~o  da r~a a verona quando 
<dL..alogac~ d:"da_O04" type="backc-ack" :rela~ion~o.:*'da_O03*' 
href="dial_202.~ra. :x::ll ?d (~_018).. id(v_022) "I> 
<dialoEac~ ?d-"da_005" ~ype="ope-ques" 
href="d~al_~O2_~ra. l l i d  (v.023) "/> 
</tur.> 
</pra~ma~ica~not at ~ 
6. The XML Conceptual-Semantic Annota- 
tion File 
< concept ualaDno~ at ion ld:"dAal_002" > 
<~n id:"~_001" href :"dia l .002_tra.~Sid(?_001)"> 
g lo~trot t~ vi~g, gi buo~o~o 
<concept id="c_001" ?~ype~"aff i l?att~"> 
<slo~ sname="value" svalue*"globe~ro~er_viaEg?"/> 
</co~cop~> 
<Itux~> 
<~urn ?d="~_002 ~ href*"dia/_002_~ra.zml#?d(~.002)'*> 
buonE?orno sono *~-~-~ia  degasperl VOZTO? px~no~ro 
tm vt~o in t~no da roma a vezona 
<?xmcept id="?_002" ctype:"perl~-n~me"> 
<slot sna~e:"given-n~e" sva lue=* '~ la" /> 
<sloe s~ame:"fa~ly-n~e" svalue="degasper?"/> 
<Ic~copt> 
<concept id="c_003" ?~ypeo"~rip"> 
<slot sn~e-'*?=ansporta~?on-?ype" svLlue-"?ratn"/> 
<Slo~ *~'*0~**  svalue="=~ae"/> 
<slO~ ~-~="des~ina~ion" svalue="verona"/> 
</concept> 
</gum> 
<turn id='~_003" hzef-"dlsl_002_~ra.~lSid(t_003)"> 
' t~o  de. :~a  a verona quando 
<c~cep~ Id*"c_004" c~pes"tz4p"> 
<s /~ sname~"oz~Igln" ~raluo-"~e"/> 
<sloe ~a~el"des~ina~on " svalu~:**verona"/> 
</coacep~> 
<c~cep~ $dm"?.005" c~ype~"~ime "> 
<slot re - "va lue"  svalue="quest$on"/> 
</c~mcept> 
</~zn> 
< / co:,cep~ualal~o~ a~ $ o:> 
7. The XML Pragmatic Annotation File 
18 
