Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 447?455,
Beijing, August 2010
A Novel Reordering Model Based on Multi-layer Phrase for Sta-
tistical Machine Translation 
Yanqing He1,     Yu Zhou2,     Chengqing Zong2,     Huilin Wang1
1Institute of Scientific and Technical 
Information of China 
{heyq,wanghl}@istic.ac.cn
2Institute of Automation, Chinese  
Academy of Sciences 
{yzhou,cqzong}@nlpr.ia.ac.cn
Abstract
Phrase reordering is of great importance 
for statistical machine translation. Ac-
cording to the movement of phrase trans-
lation, the pattern of phrase reordering 
can be divided into three classes: mono-
tone, BTG (Bracket Transduction 
Grammar) and hierarchy. It is a good 
way to use different styles of reordering 
models to reorder different phrases ac-
cording to the characteristics of both the 
reordering models and phrases itself.  In 
this paper a novel reordering model 
based on multi-layer phrase (PRML) is 
proposed, where the source sentence is 
segmented into different layers of phras-
es on which different reordering models 
are applied to get the final translation.  
This model has some advantages: differ-
ent styles of phrase reordering models 
are easily incorporated together; when a 
complicated reordering model is em-
ployed, it can be limited in a smaller 
scope and replaced with an easier reor-
dering model in larger scope. So this 
model better trade-offs the translation 
speed and performance simultaneously.  
1 Introduction 
In statistical machine translation (SMT), phrase 
reordering is a complicated problem. According 
to the type of phrases, the existing phrase reor-
dering models are divided into two categories: 
contiguous phrase-based reordering models and 
non-contiguous phrase-based reordering models.  
Contiguous phrase-based reordering models 
are designed to reorder contiguous phrases. In 
such type of reordering models, a contiguous 
phrase is reordered as a unit and the movements 
of phrase don?t involve insertions inside the oth-
er phrases. Some of these models are content-
independent, such as distortion models (Och and 
Ney, 2004; Koehn et al, 2003) which penalize 
translation according to jump distance of phrases, 
and flat reordering model (Wu, 1995; Zens et al, 
2004)which assigns constant probabilities for 
monotone order and non-monotone order. These 
reordering models are simple and the contents of 
phrases have not been considered. So it?s hard to 
obtain a satisfactory translation performance. 
Some lexicalized reordering models (Och et al, 
2004; Tillmann 2004, Kumar and Byrne, 2005, 
Koehn et al, 2005) learn local orientations (mo-
notone or non-monotone) with probabilities for 
each bilingual phrase from training data. These 
models are phrase-dependent, so improvements 
over content-independent reordering models are 
obtained. However, many parameters need to be 
estimated.  
Non-contiguous phrase-based reordering 
models are proposed to process non-contiguous 
phrases and the movements of phrase involve 
insertion operations. This type of reordering 
models mainly includes all kinds of syntax-
based models where more structural information 
is employed to obtain a more flexible phrase 
movement. Linguistically syntactic approaches 
(Yamada and Knight, 2001; Galley et al, 2004, 
2006; Marcu et al, 2006; Liu et al, 2006; Shie-
ber et al, 1990; Eisner, 2003; Quirk et al, 2005; 
Ding and Palmer, 2005) employ linguistically 
syntactic information to enhance their reordering 
capability and use non-contiguous phrases to 
447
obtain some generalization. The formally syn-
tax-based models use synchronous context-free 
grammar (SCFG) but induce a grammar from a 
parallel text without relying on any linguistic 
annotations or assumptions (Chiang, 2005; 
Xiong et al, 2006). A hierarchical phrase-based 
translation model (HPTM) reorganizes phrases 
into hierarchical ones by reducing sub-phrases to 
variables (Chiang 2005). Xiong et al (2006) is 
an enhanced bracket transduction grammar with 
a maximum entropy-based reordering model 
(MEBTG). Compared with contiguous phrase-
based reordering model, Syntax-based models 
need to shoulder a great deal of rules and have 
high computational cost of time and space. The 
type of reordering models has a weaker ability of 
processing long sentences and large-scale data, 
which heavily restrict their application. 
The above methods have provided various 
phrases reordering strategies. According to the 
movement of phrase translation, the pattern of 
phrase reordering can be divided into three 
classes: monotone, BTG (Bracket Transduction 
Grammar) (Wu, 1995) and hierarchy.  In fact for 
most sentences, there may be some phrases 
which have simple reordering patterns, such as 
monotone or BTG style. It is not necessary to 
reorder them with a complicated mechanism, e.g. 
hierarchy. It is a good idea that different reorder-
ing models are employed to reorder different 
phrases according to the characteristics of both 
the reordering models and the phrases itself. 
This paper thus gives a novel reordering model 
based on multi-layer phrase (PRML), where the 
source sentence is segmented into different lay-
ers of phrases on which different reordering 
models are applied to get the final translation. 
Our model has the advantages as follow: (1) 
PRML segments source sentence into multiple-
layer phrases by using punctuation and syntactic 
information and the design of segmentation al-
gorithm corresponds to each reordering model. 
Different reordering models are chosen for each 
layer of phrases. (2) In our model different reor-
dering models can be easily integrated together 
to obtain a combination of multiple phrase reor-
dering models.  (3) Our model can incorporate 
some complicated reordering models. We limit 
them in relatively smaller scopes and replace 
them with easier reordering models in larger 
scopes. In such way our model better trade-offs 
the translation speed and performance simulta-
neously. (4) Our segmentation strategy doesn?t 
impair translation quality by controlling phrase 
translation tables to determine the scope of each 
reordering model in each source sentence.  The 
poor phrase translations generated by the former 
reordering model, still have chances of being 
revised by the latter reordering model.  
Our work is similar to the phrase-level system 
combination (Mellebeek et al, 2006). We share 
one important characteristic: we decompose in-
put sentence into chunks and recompose the 
translated chunks in output. The differences are 
that, we segment the input sentence into multi-
layer phrases and we reorder their translations 
with a multi-layer decoder.  
The remainder of the paper is organized as 
follows: Section 2 gives our reordering model 
PRML. Section 3 presents the details of the sen-
tence segmentation algorithm and the decoding 
algorithm. Section 4 shows the experimental re-
sults. Finally, the concluding remarks are given 
in Section 5. 
2 The Model 
We use an example to demonstrate our motiva-
tion. Figure 1 shows a Chinese and English sen-
tence pair with word alignment. Each solid line 
denotes the corresponding relation between a 
Chinese word and an English word. Figure 2 
shows our reordering mechanism. For the source 
sentence, the phrases in rectangle with round 
corner in row 2 obviously have a monotone 
translation order. For such kinds of phrase a mo-
notone reordering model is enough to arrange 
their translations.  Any two neighbor consecutive 
phrases in the ellipses in row 3 have a straight 
orders or inverted order. So BTG reordering 
model is appropriate to predict the order of this 
type of phrases. Inside the phrases in the ellipses 
in row 3 there are possibly more complicated 
hierarchical structures. For the phrase ??? ??
? ??, a rule ? 1 1X towards the road to X&o ?? ??? ?
has the ascendancy over the monotone and BTG 
style of reordering model.  Hierarchy style of 
reordering models, such as HPTM reordering 
model, can translate non-contiguous phrases and 
has the advantage of capturing the translation of 
such kind of phrases. 
The whole frame of our model PRML is 
shown in Figure 3. PRML is composed of a 
448
segmentation sentence module and a decoder 
which consists of three different styles of phrase 
reordering models. The source sentence is seg-
mented into 3 layers of phrases: the original 
whole sentence, sub-sentences and chunks. The 
original whole sentence is considered as the 
first-layer phrase and is segmented into sub-
sentences to get the second-layer phrase. By fur-
ther segmenting these sub-sentences, the chunks 
are obtained as the third-layer phrase. The whole 
translation process includes three steps: 1) In 
order to capture the most complicated structure 
of phrases inside chunks, HPTM reordering 
model are chosen to translate the chunks. So the 
translations of chunks are obtained. 2) Combine 
the bilingual chunks generated by step 1 with 
those bilingual phases generated by the MEBTG 
training model as the final phrase table and 
translate the sub-sentences with MEBTG reor-
dering model, the translations of sub-sentences 
are obtained. 3) Combine the bilingual sub-
sentences generated by step 2 with those bilin-
gual phases generated by the Monotone training 
model as the final phrase table and translate the 
original whole sentences with monotone reorder- 
Figure 1.  An example of Chinese-English sentence pair with their word alignment 
Figure 2.  Diagram of Translation Using PRML.  
Figure 3. Frame of PRML 
449
Figure 4. General frame of our model 
ing model, the translations of  the original whole 
sentences are obtained. 
We also give a general frame of our model in 
Figure 4. In the segmentation module, an input 
source sentence is segmented into G layers of 
contiguous source strings, Layer 1, Layer 2, ?, 
Layer G. The phrases of lower-order layer are 
re-segmented into the phrases of higher-order 
layer. The phrases of the same layer can be 
combined into the whole source sentence. The 
decoding process starts from the phrases of the 
highest-order layer. For each layer of phrases a 
reordering model is chosen to generate the trans-
lations of phrases according to their characteris-
tics. The generated translations of phrases in the 
higher-order layer are fed as a new added trans-
lation source into the next lower-order reorder-
ing model. After the translations of the phrase in 
Layer 2 are obtained, they are fed into the Reor-
dering model 1 as well as the source sentence 
(the phrase in Layer 1) to get the target transla-
tion.  
Due to the complexity of the language, there 
may be some sentences whose structures don?t 
conform to the pattern of the reordering models 
we choose. So in our segmentation module, if 
the sentence doesn?t satisfy the segmentation 
conditions of current layer, it will be fed into the 
segmentation algorithm of the next layer. Even 
in the worst condition when the sentence isn?t 
segmented into any phrase by segmentation 
module, it will be translated as the whole sen-
tence to get the final translation by the highest-
order reordering model.  
Our model tries to grasp firstly the simple 
reordering modes in source sentence by the low-
er layer of phrase segmentations and controls 
more complicated reordering modes inside the 
higher layers of phrases. Then we choose some 
complicated reordering models to translate those 
phrases. Thus search space and computational 
complexity are both reduced. After obtaining the 
translation of higher layer?s phrases, it is enough 
for simple reordering models to reorder them.  
Due to phrase segmentation some phrases may 
be translated poorly by the higher layer of reor-
dering models, but they still have chances of be-
ing revised by the lower layer of reordering 
model because in lower layer of reordering mod-
el the input phrases have not these hard segmen-
tation boundary and our model uses phrase trans-
lation tables to determine the scope of each reor-
dering model.  
 There are two key issues in our model. The 
first one is how to segment the source sentence 
into different layers of phrases. The second one 
is how to choose a reordering model for different 
layer of phrases. In any case the design of seg-
menting sentence module should consider the 
characteristic of the reordering model of phrases. 
3 Implementation 
The segmentation module consists of the sub-
sentence segmentation and chunk segmentation. 
The decoder combines three reordering models, 
HPTM, MEBTG, and a monotone reordering 
model. 
3.1 Segmentation module
We define the sub-sentence as the word se-
quence which can be translated in monotone or-
der. The following six punctua-
tions: ? ? ?  ?  ?  ? in Chinese, 
and . ! ? , : ; in English are chosen as the seg-
mentation anchor candidates.   Except Chinese 
comma, all the other five punctuations can ex-
450
press one semantic end and another semantic 
beginning.  In most of the time, it has high error 
risk to segment the source sentence by commas. 
So we get help from syntactic information of 
Chinese dependency tree to guarantee the mono-
tone order of Chinese sub-sentences.  
The whole process of sub-sentence 
segmentation includes training and segmenting. 
Training: 1) The word alignment of training 
parallel corpus is obtained; 2) The parallel 
sentence pairs in training corpus are segmented 
into sub-sentences candidates. For a Chinese-
English sentence pair with their word alignment 
in training data, all bilingual punctuations are 
found firstly, six punctuations respectively 
???????? in Chinese and ?? ! . , : ;? in 
English. The punctuation identification number 
(id) sets in Chinese and English are respectively 
extracted.  For a correct punctuation id pair (id_c,
id_e), the phrase before id_e in English sentence 
should be the translation of the phrase before 
id_c in Chinese sentence, namely the number of 
the links 1 between the two phrases should be 
equal. In order to guarantees the property we 
calculate a bilingual alignment ratio for each 
Chinese-English punctuation id pair according to 
the following equation. For the punctuation id 
pair (id_c, id_e), bilingual alignment ratio 
consists of two value, Chinese-English 
alignment ratio (CER) and English-Chinese 
alignment ratio (ECR).
1 _
1
1 _
1
( )
( )
ij
i id c
j J
ij
j id e
i I
A
CER
A
G
G
d d
d d
d d
d d
 
?
?
1 _
1
1 _
1
( )
( )
ij
j id e
i I
ij
i id c
j J
A
ECR
A
G
G
d d
d d
d d
d d
 
?
?
where ( )ijAG is an indicator function whose value 
is 1 when the word id pair ( , )i j is in the word 
alignment and is 0 otherwise.  I and J are the 
length of the Chinese English sentence pair. 
CER of a correct punctuation id pair will be 
equal to 1.0. So does ECR.  In view of the error 
rate of word alignment, the punctuation id pairs 
will be looked as the segmentation anchor if 
both CER and ECR are falling into the threshold 
range (minvalue, maxvalue). Then all the 
punctuation id pairs are judged according to the 
same method and those punctuation id pairs 
1 Here a link between a Chinese word and an English word 
means the word alignment between them.
satisfying the requirement segment the sentence 
pair into sub-sentence pairs. 3) The first word of 
Chinese sub-sentence in each bilingual sub-
sentence pair is collected.  We filter these words 
whose frequency is larger than predefined 
threshold to get segmentation anchor word set 
(SAWS).
Segmenting: 1) The test sentence in Chinese is 
segmented into segments by the six Chinese 
punctuation ???????? in the sentence. 2)
If the first word of a segment is in SAWS the 
punctuation at the end of the segment is chosen 
as the segmentation punctuation. 3) If a segment 
satisfies the property of ?dependency integrity? 
the punctuation at the end of the segment is also 
chosen as the segmentation punctuation. Here 
?dependency integrity? is defined in a 
dependency tree. Figure 5 gives the part output  
Figure 5. The part dependency parser output 
of a Chinese sentence. 
of ?lexical dependency parser?2  for a Chinese 
sentence. There are five columns of data for each 
word which are respectively the word id, the 
word itself, its speech of part, the id of its head 
word and their dependency type. In the sentence 
the Chinese word sequence ??? ?? ?? ?
? (US congressional representatives say that)? 
has such a property: Each word in the sequence 
has a dependency relation with the word which 
is still in the sequence except one word which 
has a dependency relation with the root, e.g. id 4. 
We define the property as ?dependency integri-
ty?. Our reason is: a sub-sentence with the prop-
erty of ?dependency integrity? has relatively in-
dependent semantic meaning and a large possi-
bility of monotone translation order. 4) The un-
ion of the segmentation punctuations in step 2) 
and 3) are the final sub-sentence segmentation 
tags.
2 http://www.seas.upenn.edu/
~strctlrn/MSTParser/MSTParser.html
ID              word          POS        head id  dependency type 
1 ?? NR 3 NMOD 
2 ?? NN 3 NMOD 
3 ?? NN 4 SUB 
4 ?? VV 0 ROOT 
5 ? PU 4 P 
6 ??? NN 7 VMOD 
7 ?? VV 9 VMOD 
8 ? PU 9 P 
? ?            ? ?            ? ?            ? ?                  ? ? 
451
After sub-sentence segmentation, chunks 
segmentation is carried out in each sub-sentence. 
We define the chunks as the word sequence 
which can be translated in monotone order or 
inverted order. Here the knowledge of the 
?phrase structure parser? 3  and the ?lexicalized 
dependency parser? are integrated to segment 
the sub-sentence into chunks. In a Chinese 
phrase structure parser tree the nouns phrase (NP) 
and preposition phrase (PP) are relatively inde-
pendent in semantic expressing and relatively 
flexible in translation. So in the chunk segmenta-
tion, only the NP structure and PP structure in 
the Chinese structure parsing tree are found as 
phrase structure chunk. The process of chunk 
segmentation is described as follows: 1) the test 
sub-sentence is parsed to get the phrase structure 
tree and dependency parsing tree; 2) We traverse 
the phrase structure tree to extract sub-tree of 
?NP? and ?PP? to obtain the phrase structure 
chunks. 3) We mark off the word sequences with 
?dependency integrity? in the dependency tree. 4)
Both the two kinds of chunks are recombined to 
obtain the final result of chunk segmentation. 
3.2 Decoding
Our decoder is composed of three styles of reor-
dering models: HPTM, MEBTG and a monotone 
reordering model. 
According to Chiang (2005), given the 
chunk chunkc , a CKY parser finds ch u n ke

, the Eng-
lish yield of the best derivation hptmD

that has 
Chinese yield chunkc :
( )
( )
( argmax Pr( ))
hptm chunk
chunk chunk hptm
chunk hptm
C D C
e e D
e D
 
 
 

Here the chunks not the whole source sentence 
are fed into HPTM decoder to get the L-best 
translations and feature scores of the chunks. We 
combine all the chunks, their L-best translations 
and the feature scores into a phrase table, namely 
chunk phrase table. We only choose 4 translation 
scores (two translation probability based on fre-
quency and two lexical weights based on word 
alignment) because the language model score, 
phrase penalty score and word penalty score will 
be re-calculated in the lower layer of reordering 
3 http://nlp.stanford.edu/software/lex-parser.shtml
model and need not be kept here. Meantime we 
change the log values of the scores into probabil-
ity value. In the chunk phrase table each phrase 
pair has a Chinese phrase, an English phrase and 
four translations feature scores. In each phrase 
pair the Chinese phrase is one of our chunks, the 
English phrase is one translation of L-best of the 
chunk. 
 In MEBTG (Xiong et al, 2006), three rules 
are used to derive the translation of each sub-
sentence: lexical rule, straight rule and inverted 
rule. Given a source sub-sentence sub sentC  , it 
finds the final sub-sentence translation sub sentE 

from the best derivation m eb tgD

:
( )
( )
( arg max Pr( ))
mebtg sub sent
sub sent sub sent mebtg
mebtg
C D C
E E D
E D

 
 
 
 
 
Generally chunk segmentation will make some 
HPTM rules useless and reduce the translation 
performance. So in MEBTG we also use base 
phrase pair table which contains the contiguous 
phrase translation pairs consistent with word 
alignment.  We merge the chunk phrase table 
and base phrase table together and feed them 
into MEBTG to translate each sub-sentence. 
Thus the K-Best translation and feature scores of 
each sub-sentence are obtained and then are re-
combined into a new phrase table, namely sub-
sentence phrase table, by using the same method 
with chunk phrase table. 
 Having obtained the translation of each sub-
sentence we generate the final translation of the 
whole source sentence by a monotone reordering 
model. Our monotone reordering model employs 
a log-linear direct translation model. Three 
phrase tables: chunk phrase table, sub-sentence 
phrase table and base phrase table are merged 
together and fed into the monotone decoder. 
Thus the decoder will automatically choose 
those phrases it need. In each phrase table each 
source phrase only has four translation probabili-
ties for its candidate translation. So it?s easy to 
merge them together. In such way all kinds of 
phrase pairs will automatically compete accord-
ing to their translation probabilities. So our 
PRML model can automatically decide which 
reordering model is employed in each phrase 
scope of the whole source sentence. It?s worth 
noting that the inputs of the three reordering 
452
model have no segmentation tag. Because any 
segmentation for the input before decoding will 
influence the use of some rules or phrase pairs 
and may cause some rules or phrase pairs losses. 
It would be better to employ different phrase 
table to limit reordering models and let each de-
coder automatically decide reordering model for 
each segments of the input. Thus by controlling 
the phrase tables we apply different reordering 
models on different phrases. For each reordering 
model we perform the maximum BLEU training 
(Venugopal et al 2005) on a development set. 
For HPTM the training is same as Chiang 2007. 
For MEBTG we use chunk phrase table and base 
table to obtain translation parameters. For mono-
tone reordering model all the three phrase tables 
are merged to get translation weights. 
4  Experiments 
This section gives the experiments with Chinese-
to-English translation task in news domain. Our 
evaluation metric is case-insensitive BLEU-4 
(Papineni et al 2002). We use NIST MT 2005, 
NIST MT 2006 and NIST MT 2008 as our test 
data. Our training data is filtered from the LDC 
corpus4. Table 1 gives the statistics of our data.  
4.1 Evaluating translation Performance  
We compare our PRML against two baselines: 
MEBTG system developed in house according 
to Xiong (2006, 2008) and HPTM system5 in 
PYTHON based on HPTM reordering model 
(Chiang 2007). In MEBTG phrases of up to 10 
words in length on the Chinese side are extracted 
and reordering examples are obtained without 
limiting the length of each example.  Only the 
last word of each reordering example is used as 
lexical feature in training the reordering model 
by the maximum entropy based classifier6. We 
also set a swapping window size as 8 and the 
beam threshold as 10.  It is worth noting that our 
MEBTG system uses cube-pruning algorithm 
(Chiang 2005) from bottom to up to generate the  
4 LDC corpus lists: LDC2000T46,  LDC2000T50, 
LDC2002E18, LDC2002E27, LDC2002L27, LDC2002T01, 
LDC2003E07, LDC2003E14, LDC2003T17, LDC2004E12, 
LDC2004T07, LDC2004T08, LDC2005T01, LDC2005T06, 
LDC2005T10, LDC2005T34, LDC2006T04, LDC2007T09 
5 We are extremely thankful to David Chiang who original-
ly implement the PYTHON decoder and share with us. 
6 http://maxent.sourceforge.net/
Set Language Sentence Vocabulary A. S. L
Train
data
Chinese 297,069 6,263 11.9
English 297,069 8,069 13.6
NIST
05 
Chinese 1,082 5669 28.2
English 4,328 7575 32.7
NIST
06 
Chinese 1,664 6686 23.5
English 6,656 9388 28.9
NIST
08 
Chinese 1,357 6,628 24.5
English 5,428 9,594 30.8
Table 1. The statistics of training data and test 
data, A. S. L is average sentence length. 
N-best list not the lazy algorithm of (Huang and 
Chiang, 2005). We also limit the length of the 
HPTM initial rules no more than 10 words and 
the number of non-terminals within two. In the 
decoding for the rules the beam pruning parame-
ter is 30 and threshold pruning parameter is 1.0. 
For hypotheses the two pruning parameters are 
respectively 30 and 10. In our PRML minva-
lue=0.8, maxvalue=1.25, which are obtained by 
minimum error rate training on the development 
set. The predefined value for filtering SAWS is
set as 100.
The translation performance of the three reor-
dering model is shown in Table 2. We can find 
that PRML has a better performance than 
MEBTG with a relatively 2.09% BLEU score in 
NIST05, 5.60% BLEU score in NIST06 and  
5.0% BLEU score in NIST08. This indicates that 
the chunk phrase table increases the reordering 
ability of MEBTG. Compared with HPTM, 
PRML has a comparable translation performance 
in NIST08. In NIST05 and NIST06 our model 
has a slightly better performance than HPTM. 
Because PRML limit hierarchical structure reor-
dering model in chunks while HPTM use them 
in the whole sentence scope (or in a length 
scope), HPTM has a more complicated reorder-
ing mechanism than PRML. The experiment re-
sult shows even though we use easier reordering 
moels in larger scope, e.g. MEBTG and monoto- 
Model Nist05 Nist06 Nist08 
HPTM 0.3183 0.1956 0.1525 
MEBTG 0.3049 0.1890 0.1419 
PRML 0.3205 0.1996 0.1495 
Table 2. The translation performance  
453
ne reordering model, we have a comparatively 
translation performance as HPTM.  
4.2 Evaluating translation speed  
Table 3 shows the average decoding time on test 
data for the three phrase reordering models on a 
double processor of a dual 2.0 Xeon machine. 
Time denotes mean time of per-sentence, in 
seconds. It is seen that PRML is the slower than 
MEBTG but reduce decoding time with a rela-
tively 54.85% seconds in NIST05, 75.67% 
seconds in NIST06 and 65.28% seconds in 
NIST08. For PRML, 93.65% average decoding 
time in NIST05 is spent in HPTM, 4.89% time 
in MEBTG and 1.46% time in monotone reor-
dering decoder.  
Model Nist05 Nist06 Nist08 
HPTM 932.96 1235.21 675 
MEBTG 43.46 27.16 10.24 
PRML 421.20 300.52 234.33 
Table 3. The average decoding time 
4.3 Evaluating the performance of each 
layer of phrase table
In order to evaluate the performance of each 
reordering model, we run the monotone decoder 
with different phrase table in NIST05. Table 4 
list the size of each phrase table. From the re-
sults in Table 5 it is seen that the performance of 
using three phrase tables is the best.  Compared 
with the base phrase table, the   translation per-
formances are improved with relatively 10.86% 
BLEU score by adding chunk phrase table and 
11% BLEU score by adding sub-sentence table. 
The result of row 4 has a comparable to the one 
in row 5. It indicates the sub-sentence phrase 
table has contained the information of HPTM 
reordering model. The case of row 4 to row 2 is 
the same. 
Phrase table Phrase pair 
Base 732732 
Chunk 86401 
Sub-sentence 24710 
Table 4.  The size of each phrase table. 
Phrase table Reordering model BLEU
Base Monotone 0.2871
Base +chunk monotone+HPTM 0.3180
Base +sub-
sentence table
monotone+HPTM 
+MEBTG
0.3187
Base +chunk 
+subsentence
monotone+HPTM 
+MEBTG
0.3205
Table 5.  The performance of phrase table 
5  Conclusions 
In this paper, we propose a novel reordering 
model based on multi-layer phrases (PRML), 
where the source sentence is segmented into dif-
ferent layers of phrases and different reordering 
models are applied to get the final translation. 
Our model easily incorporates different styles of 
phrase reordering models together, including 
monotone, BTG, and hierarchy or other more 
complicated reordering models. When a compli-
cated reordering model is used, our model can 
limit it in a smaller scope and replace it with an 
easier reordering model in larger scope. In such 
way our model better trade-offs the translation 
speed and performance simultaneously.  
In the next step, we will use more features to 
segment the sentences such as syntactical fea-
tures or adding a dictionary to supervise the 
segmentation. And also we will try to incorpo-
rate other systems into our model to improve the 
translation performance. 
6 Acknowledgements 
The research work has been partially funded by 
the Natural Science Foundation of China under 
Grant No. 6097 5053, and 60736014, the Na-
tional Key Technology R&D Program under 
Grant No. 2006BAH03B02, the Hi-Tech Re-
search and Development Program (?863? Pro-
gram) of China under Grant No. 
2006AA010108-4, and also supported by the 
China-Singapore Institute of Digital Media 
(CSIDM) project under grant No. CSIDM-
200804, and Research Project ?Language and 
Knowledge Technology? of Institute of Scientif-
ic and Technical Information of China 
(2009DP01-6). 
454
References 
David Chiang. 2005. A hierarchical phrase-based 
model for statistical machine translation. In Pro-
ceedings of ACL 2005, pages 263?270. 
David Chiang, 2007. Hierarchical Phrase-based 
Translation. Computational Linguistics,33(2):201-
228. 
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency 
insertion grammars. In proceeding of 43th Meet-
ing of the Association for Computational Linguis-
tics, 541-548 
Jason Eisner. 2003. Learning non-isomorphic tree 
mappings for machine translation. In proceedings 
of the 41th Meeting of the Association for Compu-
tational Linguistics (companion volume). 
Michel Galley, Mark Hopkins, Kevin Knight and 
Daniel Marcu. 2004. What?s in a translation rule?
In proceedings of HLTNAACL- 2004. 
Michel Galley, Jonathan Graehl, Kevin Knight, Da-
niel Marcu, Steve DeNeefe, Wei Wang, Ignacio 
Thayer. 2006. Scalable Inference and Training of 
Context-Rich Syntactic Translation Models. In 
Proceedings of the joint conference of the Interna-
tional Committee on Computational Linguistics 
and the Association for Computational Linguistics. 
Sydney, Australia. 
Liang Huang and David Chiang. 2005. Better k-best 
parsing. In Proceedings of the Ninth International 
Workshop on Parsing Technology, Vancouver, 
October, pages 53?64. 
Papineni, Kishore, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu, 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the ACL. 
page 311-318, Philadelphia, PA. 
Philipp Koehn, Franz J. Och and Daniel Marcu. 2003. 
Statistical phrase-based translation. In proceed-
ings of HLT-NAACL-03, 127-133 
Philipp Koehn, Amittai Axelrod, Alexandra Birch 
Mayne, Chris Callison-Burch, Miles Osborne and 
David Talbot. 2005. Edinburgh System Descrip-
tion for the 2005 IWSLT Speech Translation Eval-
uation. In International Workshop on Spoken Lan-
guage Translation. 
Shankar Kumar and William Byrne. 2005. Local 
phrase reordering models for statistical machine 
translation. In Proceedings of HLT-EMNLP. 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine 
Translation. In proceedings of ACL-06, 609-616. 
Daniel Marcu and William Wong. 2002. A phrase-
based, joint probability model for statistical ma-
chine translation. In proceedings of EMNLP-02, 
133-139. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi, 
and Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Lan-
guage Phrases. In Proceedings of EMNLP-2006, 
44-52, Sydney, Australia 
Bart Mellebeek, Karolina Owczarzak, Josef Van Ge-
nabith, Andy Way. 2006. Multi-Engine Machine 
Translation By Recursive Sentence Decomposition.
In Proceedings of AMTA 2006 
Franz J. Och and Hermann Ney. 2004. The alignment 
template approach to statistical machine transla-
tion. Computational Linguistics, 30(4):417-449 
Franz Josef Och, Ignacio Thayer, Daniel Marcu, Ke-
vin Knight, Dragos Stefan Munteanu, Quamrul Ti-
pu, Michel Galley, andMark Hopkins. 2004. Arab-
ic and Chinese MT at USC/ISI. Presentation given 
at NIST Machine Translation Evaluation Work-
shop.
Chris Quirk, Arul Menezes and Colin Cherry. 2005. 
Dependency treelet translation: Syntactically in-
formed phrasal SMT. In proceedings of the 43th 
Meeting of the Association for Computational 
Linguistics, 271-279 
S. Shieber and Y. Schabes. 1990. Synchronous tree 
adjoining grammars. In proceedings of COLING-
90. 
Christoph Tillmann. 2004. A block orientation model 
for statistical machine translation. In HLT-
NAACL, Boston, MA, USA. 
Ashish Venugopal, Stephan Vogel and Alex Waibel. 
2003. Effective Phrase Translation Extraction 
from Alignment Models, in Proceedings of the 41st 
ACL,  319-326. 
Dekai Wu. 1995. Stochastic inversion transduction 
grammars, with application to segmentation, 
bracketing, and alignment of parallel corpora. In 
proceeding of IJCAL 1995, 1328-1334,Montreal, 
August.  
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Max-
imum Entropy Based phrase reordering model for 
statistical machine translation. In proceedings of 
COLING-ACL, Sydney, Australia. 
Deyi Xiong, Min Zhang, Ai Ti Aw, Haitao Mi, Qun 
Liu and Shouxun Lin. Refinements in BTG-based 
Statistical Machine Translation. In Proceedings of 
IJCNLP 2008. 
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In proceedings 
of the 39th Meeting of the ACL, 523-530. 
R. Zens, H. Ney, T. Watanabe, and E. Sumita. 2004. 
Reordering Constraints for Phrase-Based Statis-
tical MachineTranslation. In Proceedings of CoL-
ing 2004, Geneva, Switzerland, pp. 205-211. 
455
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1127?1136,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Handling Ambiguities of Bilingual Predicate-Argument Structures for 
Statistical Machine Translation 
 
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing Zong 
National Laboratory of Pattern Recognition, Institute of Automation, 
Chinese Academy of Sciences, Beijing, China 
{ffzhai,jjzhang,yzhou,cqzong}@nlpr.ia.ac.cn 
 
 
 
Abstract 
Predicate-argument structure (PAS) has been 
demonstrated to be very effective in improving 
SMT performance. However, since a source-
side PAS might correspond to multiple differ-
ent target-side PASs, there usually exist many 
PAS ambiguities during translation. In this pa-
per, we group PAS ambiguities into two types: 
role ambiguity and gap ambiguity. Then we 
propose two novel methods to handle the two 
PAS ambiguities for SMT accordingly: 1) in-
side context integration; 2) a novel maximum 
entropy PAS disambiguation (MEPD) model. 
In this way, we incorporate rich context in-
formation of PAS for disambiguation. Then 
we integrate the two methods into a PAS-
based translation framework. Experiments 
show that our approach helps to achieve sig-
nificant improvements on translation quality. 
1 Introduction 
Predicate-argument structure (PAS) depicts the 
relationship between a predicate and its associat-
ed arguments, which indicates the skeleton struc-
ture of a sentence on semantic level. Basically, 
PAS agrees much better between two languages 
than syntax structure (Fung et al, 2006; Wu and 
Fung, 2009b). Considering that current syntax-
based translation models are always impaired by 
cross-lingual structure divergence (Eisner, 2003; 
Zhang et al, 2010), PAS is really a better repre-
sentation of a sentence pair to model the bilin-
gual structure mapping. 
However, since a source-side PAS might 
correspond to multiple different target-side PASs, 
there usually exist many PAS ambiguities during 
translation. For example, in Figure 1, (a) and (b) 
carry the same source-side PAS <[A0]1 
[Pred(?)]2 [A1]3> for Chinese predicate ???. 
However, in Figure 1(a), the corresponding 
target-side-like PAS is <[X1] [X2] [X3]>, while in 
Figure 1(b), the counterpart target-side-like PAS1 
is <[X2] [X3] [X1]>. This is because the two 
PASs play different roles in their corresponding 
sentences. Actually, Figure 1(a) is an independ-
ent PAS, while Figure 1(b) is a modifier of the 
noun phrase ??? ? ????. We call this kind 
of PAS ambiguity role ambiguity. 
??  ?  ??? ?? ???
[           A0         ]1 [     A1    ]3[Pred]2
?
being , should  ?two major countries
[           X3            ][X2]
China and Russia
[          X1           ]
? ?
?? ?? ? ???
[ A0 ]1 [          A1         ]3[Pred]2
flood  prevention is the  primary  mission
[           X1          ] [ X2 ] [              X3              ]
??? ? ?? ? ??? ? ? ? ?
[      A0      ]1 [    A1   ]3[Pred]2
the location of the olympic village for athletesis the best
[     X3    ][X2][                    X1                     ]
(a)
(c)
(b)
 
Figure 1. An example of ambiguous PASs. 
Meanwhile, Figure 1 also depicts another kind 
of PAS ambiguity. From Figure 1, we can see 
that (a) and (c) get the same source-side PAS and 
target-side-like PAS. However, they are different 
because in Figure 1(c), there is a gap string ?? 
???? between [A0] and [Pred]. Generally, the 
gap strings are due to the low recall of automatic 
semantic role labeling (SRL) or complex sen-
tence structures. For example, in Figure 1(c), the 
gap string ?? ???? is actually an argument 
?AM-PRP? of the PAS, but the SRL system has 
                                                 
1We use target-side-like PAS to refer to a list of general 
non-terminals in target language order, where a non-
terminal aligns to a source argument. 
1127
ignored it. We call this kind of PAS ambiguity 
gap ambiguity. 
During translation, these PAS ambiguities will 
greatly affect the PAS-based translation models. 
Therefore, in order to incorporate the bilingual 
PAS into machine translation effectively, we 
need to decide which target-side-like PAS should 
be chosen for a specific source-side PAS. We 
call this task PAS disambiguation. 
In this paper, we propose two novel methods 
to incorporate rich context information to handle 
PAS ambiguities. Towards the gap ambiguity, 
we adopt a method called inside context 
integration to extend PAS to IC-PAS. In terms of 
IC-PAS, the gap strings are combined effectively 
to deal with the gap ambiguities. As to the role 
ambiguity, we design a novel maximum entropy 
PAS disambiguation (MEPD) model to combine 
various context features, such as context words 
of PAS. For each ambiguous source-side PAS, 
we build a specific MEPD model to select 
appropriate target-side-like PAS for translation. 
We will detail the two methods in Section 3 and 
4 respectively. 
Finally, we integrate the above two methods 
into a PAS-based translation framework (Zhai et 
al. 2012). Experiments show that the two PAS 
disambiguation methods significantly improve 
the baseline translation system. The main 
contribution of this work can be concluded as 
follows: 
1) We define two kinds of PAS ambiguities: 
role ambiguity and gap ambiguity. To our 
best knowledge, we are the first to handle 
these PAS ambiguities for SMT. 
2) Towards the two different ambiguities, we 
design two specific methods for PAS 
disambiguation: inside context integration 
and the novel MEPD model.  
2 PAS-based Translation Framework 
PAS-based translation framework is to perform 
translation based on PAS transformation (Zhai et 
al., 2012). In the framework, a source-side PAS 
is first converted into target-side-like PASs by 
PAS transformation rules, and then perform 
translation based on the obtained target-side-like 
PASs. 
2.1 PAS Transformation Rules 
PAS transformation rules (PASTR) are used to 
convert a source-side PAS into a target one. 
Formally, a PASTR is a triple <Pred, SP, TP>: 
? Pred means the predicate where the rule is 
extracted. 
? SP denotes the list of source elements in 
source language order. 
? TP refers to the target-side-like PAS, i.e., a 
list of general non-terminals in target 
language order. 
For example, Figure 2 shows the PASTR 
extracted from Figure 1(a). In this PASTR, Pred 
is Chinese verb ???, SP is the source element 
list <[A0]1 [Pred]2 [A1]3>, and TP is the list of 
non-terminals <X1 X2 X3>. The same subscript in 
SP and TP means a one-to-one mapping between 
a source element and a target non-terminal. Here, 
we utilize the source element to refer to the 
predicate or argument of the source-side PAS. 
[X3] [X2] [A0]1 [Pred]2 [A1]3 [X1] 
source-side PAS(?) target-side-like PAS
 
Figure 2. An example PASTR. 
2.2 PAS Decoding 
The PAS decoding process is divided into 3 steps: 
(1) PAS acquisition: perform semantic role 
labeling (SRL) on the input sentences to achieve 
their PASs, i.e., source-side PASs; 
(2) Transformation: use the PASTR to match 
the source-side PAS i.e., the predicate Pred and 
the source element list SP. Then by the matching 
PASTRs, transform source-side PASs to target-
side-like PASs. 
(3) Translation: in this step, the decoder first 
translates each source element respectively, and 
then a CKY-style decoding algorithm is adopted 
to combine the translation of each element and 
get the final translation of the PAS.  
2.3 Sentence Decoding with the PAS-based 
translation framework 
Sometimes, the source sentence cannot be fully 
covered by the PAS, especially when there are 
several predicates. Thus to translate the whole 
sentence, Zhai et al (2012) further designed an 
algorithm to decode the entire sentence.  
In the algorithm, they organized the space of 
translation candidates into a hypergraph. For the 
span covered by PAS (PAS span), a multiple-
branch hyperedge is employed to connect it to 
the PAS?s elements. For the span not covered by 
PAS (non-PAS span), the decoder considers all 
the possible binary segmentations of it and uti-
lizes binary hyperedges to link them. 
1128
During translation, the decoder fills the spans 
with translation candidates in a bottom-up man-
ner. For the PAS span, the PAS-based translation 
framework is adopted. Otherwise, the BTG sys-
tem (Xiong et al, 2006) is used. When the span 
covers the whole sentence, we get the final trans-
lation result. 
 
Obviously, PAS ambiguities are not 
considered in this framework at all. The target-
side-like PAS is selected only according to the 
language model and translation probabilities, 
without considering any context information of 
PAS. Consequently, it would be difficult for the 
decoder to distinguish the source-side PAS from 
different context. This harms the translation 
quality. Thus to overcome this problem, we de-
sign two novel methods to cope with the PAS 
ambiguities: inside-context integration and a 
maximum entropy PAS disambiguation (MEPD) 
model. They will be detailed in the next two sec-
tions. 
3 Inside Context Integration 
In this section, we integrate the inside context of 
the PAS into PASTRs to do PAS disambiguation. 
Basically, a PAS consists of several elements (a 
predicate and several arguments), which are ac-
tually a series of continuous spans. For a specific 
PAS <E1,?, En>, such as the source-side PAS 
<[A0][Pred][A1]> in Figure 2, its controlled range 
is defined as: 
( ) { ( ), [1, ]}irange PAS s E i n= ? ?  
where s(Ei) denotes the span of element Ei. Fur-
ther, we define the closure range of a PAS. It 
refers to the shortest continuous span covered by 
the entire PAS: 
0( ) ( )
_ min , max
nj s E j s E
closure range j j
? ?
? ?= ? ?? ?
 
Here, E0 and En are the leftmost and rightmost 
element of the PAS respectively. The closure 
range is introduced here because adjacent source 
elements in a PAS are usually separated by gap 
strings in the sentence. We call these gap strings 
the inside context (IC) of the PAS, which satisfy: 
_ ( ) ( ( ) ( ) )closure range PAS IC PAS range PAS= ? ?  
The operator ?  takes a list of neighboring spans 
as input2, and returns their combined continuous 
span. As an example, towards the PAS ?<[A0] 
[Pred][A1]>? (the one for Chinese predicate ??
(shi)?) in Figure 3, its controlled range is 
{[3,5],[8,8],[9,11]} and its closure range is [3,11]. 
The IC of the PAS is thus {[6,7]}. 
To consider the PAS?s IC during PAS trans-
formation process, we incorporate its IC into the 
extracted PASTR. For each gap string in IC, we 
abstract it by the sequence of highest node cate-
gories (named as s-tag sequence). The s-tag se-
quence dominates the corresponding syntactic 
tree fragments in the parse tree. For example, in 
Figure 3, the s-tag sequence for span [6,8] is ?PP 
VC?. Thus, the sequence for the IC (span [6,7]) 
in Figure 3 is ?PP?. We combine the s-tag se-
quences with elements of the PAS in order. The 
resulting PAS is called IC-PAS, just like the left 
side of Figure 4(b) shows. 
[           A0           ] [        PP        ]
???3 ???7 ?8 ?10
de wei-zhiao-yun-cun
??5?4 ?6
dui yun-dong-yuan shi
?9 ?11
zui hao de
NN DEC NN
NP
P NN
PP
VC AD VA DEC
CP
VP
IP
??1
VV
biao-shi
VP
,2
PU
?0
PN
ta
?
PU
IP
DNP
[Pred] [      A1     ]  
Figure 3. The illustration of inside context (IC). The 
subscript in each word refers to its position in sen-
tence. 
Differently, Zhai et al (2012) attached the IC 
to its neighboring elements based on parse trees. 
For example, in Figure 3, they would attach the 
gap string ??(dui) ???(yun-dong-yuan)? to the 
PAS?s element ?Pred?, and then the span of 
?Pred? would become [6,8]. Consequently, the 
span [6,8] will be translated as a whole source 
element in the decoder. This results in a bad 
translation because the gap string ??(dui) ???
(yun-dong-yuan)? and predicate ??(shi)? should 
be translated separately, just as Figure 4(a) 
shows. Therefore, we can see that the attachment 
decision in (Zhai et al, 2012) is sometimes un-
reasonable and the IC also cannot be used for 
PAS disambiguation at all. In contrast, our meth-
                                                 
2 Here, two spans are neighboring means that the beginning 
of the latter span is the former span?s subsequent word in 
the sentence. For example, span [3,6] and [7,10] are neigh-
boring spans. 
1129
od of inside context integration is much flexible 
and beneficial for PAS disambiguation. 
(a)
(b)
[X1] [X2] [X4] [A0]1 [PP]2 [Pred]3 [A1]4 [X3] 
source-side PAS(?) target-side-like PAS
??? ??? ? ?
[            A0            ]1 [      A1     ]4[Pred]3
[the location of the olympic village]1 [for athletes]2[is]3 [the best]4
[         PP         ]2
de wei-zhiao-yun-cun
??? ?
dui yun-dong-yuan shi
? ?
zui hao de
 
Figure 4. Example of IC-PASTR. (a) The aligned 
span of each element of the PAS in Figure 3; (b) The 
extracted IC-PASTR from (a). 
Using the IC-PASs, we look for the aligned 
target span for each element of the IC-PAS. We 
demand that every element and its corresponding 
target span must be consistent with word align-
ment. Otherwise, we discard the IC-PAS. After-
wards, we can easily extract a rule for PAS trans-
formation, which we call IC-PASTR. As an ex-
ample, Figure 4(b) is the extracted IC-PASTR 
from Figure 4(a). 
Note that we only apply the source-side PAS 
and word alignment for IC-PASTR extraction. 
By contrast, Zhai et al (2012) utilized the result 
of bilingual SRL (Zhuang and Zong, 2010b). 
Generally, bilingual SRL could give a better 
alignment between bilingual elements. However, 
bilingual SRL usually achieves a really low re-
call on PASs, about 226,968 entries in our train-
ing set while it is 882,702 by using monolingual 
SRL system. Thus to get a high recall for PASs, 
we only utilize word alignment instead of captur-
ing the relation between bilingual elements. In 
addition, to guarantee the accuracy of IC-
PASTRs, we only retain rules with more than 5 
occurrences. 
4 Maximum Entropy PAS Disambigua-
tion (MEPD) Model 
In order to handle the role ambiguities, in this 
section, we concentrate on utilizing a maximum 
entropy model to incorporate the context infor-
mation for PAS disambiguation. Actually, the 
disambiguation problem can be considered as a 
multi-class classification task. That is to say, for 
a source-side PAS, every corresponding target-
side-like PAS can be considered as a label. For 
example, in Figure 1, for the source-side PAS 
?[A0]1[Pred]2[A1]3?, the target-side-like PAS 
?[X1] [X2] [X3]? in Figure 1(a) is thus a label and 
?[X2] [X3] [X1]? in Figure 1(b) is another label of 
this classification problem. 
The maximum entropy model is the classical 
way to handle this problem: 
exp( ( , , ( ), ( )))
( | , ( ), ( ))
exp( ( , , ( ), ( )))
i i i
tp i i i
h sp tp c sp c tp
P tp sp c sp c tp
h sp tp c sp c tp?
?
??
= ?
? ?
 
where sp and tp refer to the source-side PAS (not 
including the predicate) and the target-side-like 
PAS respectively. c(sp) and c(tp) denote the sur-
rounding context of sp and tp. hi is a binary fea-
ture function and ?i is the weight of hi. 
We train a maximum entropy classifier for 
each sp via the off-the-shelf MaxEnt toolkit 3 . 
Note that to avoid sparseness, sp does not in-
clude predicate of the PAS. Practically, the pred-
icate serves as a feature of the MEPD model. As 
an example, for the rule illustrated in Figure 4(b), 
we build a MEPD model for its source element 
list sp <[A0] [PP] [Pred] [A1]>, and integrate the 
predicate ??(shi)? into the MEPD model as a 
feature. 
In detail, we design a list of features for each 
pair <sp, tp> as follows: 
?   Lexical Features. These features include 
the words immediately to the left and right of sp, 
represented as w-1 and w+1. Moreover, the head 
word of each argument also serves as a lexical 
feature, named as hw(Ei). For example, Figure 3 
shows the context of the IC-PASTR in Figure 
4(b), and the extracted lexical features of the in-
stance are: w-1=? , w+1=? , hw([A0]1)=??
(wei-zhi), hw([A1]4)=?(hao). 
?   POS Features. These features are defined 
as the POS tags of the lexical features, p-1, p+1 
and phw(Ei) respectively. Thus, the correspond-
ing POS features of Figure 4 (b) are: p-1=PU, 
p+1=PU, phw([A0]1)=NN, phw([A1]4)=VA. 
?   Predicate Feature. It is the pair of source 
predicate and its corresponding target predicate. 
For example, in Figure 4(b), the source and tar-
get predicate are ??(shi)? and ?is? respectively. 
The predicate feature is thus ?PredF=?(shi)+is?. 
The target predicate is determined by: 
_ ( )
- arg max ( | - )j
j t range PAS
t pred p t s pred
?
=  
where s-pred is the source predicate and t-pred 
is the corresponding target predicate. 
                                                 
3http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.htm
l 
1130
t_range(PAS) refers to the target range covering 
all the words that are reachable from the PAS via 
word alignment.  tj refers to the jth word in 
t_range(PAS). The utilized lexical translation 
probabilities are from the toolkit in Moses 
(Koehn et al, 2007). 
?   Syntax Features. These features include 
st(Ei), i.e., the highest syntax tag for each argu-
ment, and fst(PAS) which is the lowest father 
node of sp in the parse tree. For example, for the 
rule shown in Figure 4(b), syntax features are 
st([A0]1)=NP, st([A1]4)=CP, and fst(PAS)=IP 
respectively.  
Using these features, we can train the MEPD 
model. We set the Gaussian prior to 1.0 and per-
form 100 iterations of the L-BFGS algorithm for 
each MEPD model. At last, we build 160 and 
215 different MEPD classifiers, respectively, for 
the PASTRs and IC-PASTRs. Note that since the 
training procedure of maximum entropy classifi-
er is really fast, it does not take much time to 
train these classifiers. 
5 Integrating into the PAS-based Trans-
lation Framework 
In this section, we integrate our method of PAS 
disambiguation into the PAS-based translation 
framework when translating each test sentence. 
For inside context integration, since the format 
of IC-PASTR is the same to PASTR4, we can 
use the IC-PASTR to substitute PASTR for 
building a PAS-based translation system directly. 
We use ?IC-PASTR? to denote this system. In 
addition, since our method of rule extraction is 
different from (Zhai et al, 2012), we also use 
PASTR to construct a translation system as the 
baseline system, which we call ?PASTR?. 
On the basis of PASTR and IC-PASTR, we 
further integrate our MEPD model into transla-
tion. Specifically, we take the score of the MEPD 
model as another informative feature for the de-
coder to distinguish good target-side-like PASs 
from bad ones. The weights of the MEPD feature 
can be tuned by MERT (Och, 2003) together 
with other translation features, such as language 
model. 
6 Related Work 
The method of PAS disambiguation for SMT is 
relevant to the previous work on context depend-
                                                 
4 The only difference between IC-PASTR and PASTR is 
that there are many syntactic labels in IC-PASTRs.  
ent translation. 
Carpuat and Wu (2007a, 2007b) and Chan et 
al. (2007) have integrated word sense disambig-
uation (WSD) and phrase sense disambiguation 
(PSD) into SMT systems. They combine rich 
context information to do disambiguation for 
words or phrases, and achieve improved transla-
tion performance. 
Differently, He et al (2008), Liu et al (2008) 
and Cui et al (2010) designed maximum entropy 
(ME) classifiers to do better rule section for hier-
archical phrase-based model and tree-to-string 
model respectively. By incorporating the rich 
context information as features, they chose better 
rules for translation and yielded stable improve-
ments on translation quality. 
Our work differs from the above work in the 
following two aspects: 1) in our work, we focus 
on the problem of disambiguates on PAS; 2) we 
define two kinds of PAS ambiguities: role 
ambiguity and gap ambiguity. 3) towards the two 
different ambiguities, we design two specific 
methods for PAS disambiguation: inside context 
integration and the novel MEPD model. 
In addition, Xiong et al (2012) proposed an 
argument reordering model to predict the relative 
position between predicates and arguments. They 
also combine the context information in the 
model. But they only focus on the relation be-
tween the predicate and a specific argument, ra-
ther than the entire PAS. Different from their 
work, we incorporate the context information to 
do PAS disambiguation based on the entire PAS. 
This is very beneficial for global reordering dur-
ing translation (Zhai et al, 2012). 
7 Experiment 
7.1 Experimental Setup  
We perform Chinese-to-English translation to 
demonstrate the effectiveness of our PAS disam-
biguation method. The training data contains 
about 260K sentence pairs5. To get accurate SRL 
results, we ensure that the length of each sen-
tence in the training data is among 10 and 30 
words. We run GIZA++ and then employ the 
grow-diag-final-and (gdfa) strategy to produce 
symmetric word alignments. The development 
set and test set come from the NIST evaluation 
test data (from 2003 to 2005). Similar to the 
training set, we also only retain the sentences 
                                                 
5 It is extracted from the LDC corpus. The LDC category 
number : LDC2000T50, LDC2002E18, LDC2003E07, 
LDC2004T07, LDC2005T06, LDC2002L27, LDC2005T10 
and LDC2005T34. 
1131
whose lengths are among 10 and 30 words. Fi-
nally, the development set includes 595 sentenc-
es from NIST MT03 and the test set contains 
1,786 sentences from NIST MT04 and MT05. 
We train a 5-gram language model with the 
Xinhua portion of English Gigaword corpus and 
target part of the training data. The translation 
quality is evaluated by case-insensitive BLEU-4 
with shortest length penalty. The statistical sig-
nificance test is performed by the re-sampling 
approach (Koehn, 2004). 
We perform SRL on the source part of the 
training set, development set and test set by the 
Chinese SRL system used in (Zhuang and Zong, 
2010b). To relieve the negative effect of SRL 
errors, we get the multiple SRL results by 
providing the SRL system with 3-best parse trees 
of Berkeley parser (Petrov and Klein, 2007), 1-
best parse tree of Bikel parser (Bikel, 2004) and 
Stanford parser (Klein and Manning, 2003). 
Therefore, at last, we can get 5 SRL result for 
each sentence. For the training set, we use these 
SRL results to do rule extraction respectively. 
We combine the obtained rules together to get a 
combined rule set. We discard the rules with 
fewer than 5 appearances. Using this set, we can 
train our MEPD model directly. 
As to translation, we match the 5 SRL results 
with transformation rules respectively, and then 
apply the resulting target-side-like PASs for de-
coding. As we mentioned in section 2.3, we use 
the state-of-the-art BTG system to translate the 
non-PAS spans. 
source-side PAS counts number of classes 
[A0] [Pred(?)] [A1] 245 6 
[A0] [Pred(?)] [A1] 148 6 
[A0] [AM-ADV] [Pred(?)] [A1] 68 20 
[A0] [Pred(??)] [A1] 66 6 
[A0] [Pred(?)] [A1] 42 6 
[A0] [Pred(??)] [A1] 32 4 
[A0] [AM-ADV] [Pred(?)] [A1] 32 19 
[A0] [Pred(??)] [A1] 29 4 
[AM-ADV] [Pred(?)] [A1] 26 6 
[A2] [Pred(?)] [A1] 16 5 
Table 1. The top 10 frequent source-side PASs in the 
dev and test set. 
7.2 Ambiguities in Source-side PASs 
We first give Table 1 to show some examples of 
role ambiguity. In the table, for instance, the se-
cond line denotes that the source-side PAS ?[A0] 
[Pred(?)] [A1]? appears 148 times in the devel-
opment and test set al together, and it corre-
sponds to 6 different target-side-like PASs in the 
training set. 
As we can see from Table 1, all the top 10 
PASs correspond to several different target-side-
like PASs. Moreover, according to our statistics, 
among all PASs appearing in the development 
set and test set, 56.7% of them carry gap strings. 
These statistics demonstrate the importance of 
handling the role ambiguity and gap ambiguity in 
the PAS-based translation framework. Therefore, 
we believe that our PAS disambiguation method 
would be helpful for translation. 
7.3 Translation Result  
We compare the translation result using PASTR, 
IC-PASTR and our MEPD model in this section. 
The final translation results are shown in Table 2. 
As we can see, after employing PAS for transla-
tion, all systems outperform the baseline BTG 
system significantly. This comparison verifies 
the conclusion of (Zhai et al, 2012) and thus also 
demonstrates the effectiveness of PAS. 
MT system Test set 
n-gram precision 
1 2 3 4 
BTG 32.75 74.39 41.91 24.75 14.91 
PASTR 33.24* 75.28 42.62 25.18 15.10 
PASTR+MEPD 33.78* 75.32 43.08 25.75 15.58 
IC-PASTR 33.95*# 75.62 43.36 25.92 15.58 
IC-PASTR+MEPD 34.19*# 75.66 43.40 26.15 15.92 
Table 2. Result of baseline system and the MT sys-
tems using our PAS-based disambiguation method. 
The ?*? and ?#? denote that the result is significantly 
better than BTG and PASTR respectively (p<0.01).  
Specifically, after integrating the inside con-
text information of PAS into transformation, we 
can see that system IC-PASTR significantly out-
performs system PASTR by 0.71 BLEU points. 
Moreover, after we import the MEPD model into 
system PASTR, we get a significant improve-
ment over PASTR (by 0.54 BLEU points). These 
comparisons indicate that both the inside context 
integration and our MEPD model are beneficial 
for the decoder to choose better target-side-like 
PAS for translation. 
On the basis of IC-PASTR, we further add our 
MEPD model into translation and get system IC-
PASTR+MEPD. We can see that this system 
further achieves a remarkable improvement over 
system PASTR (0.95 BLEU points).  
However, from Table 2, we find that system 
IC-PASTR+MEPD only outperforms system IC-
PASTR slightly (0.24 BLEU points). The result 
seems to show that our MEPD model is not such 
1132
useful after using IC-PASTR. We will explore 
the reason in section 7.5. 
7.4 Effectiveness of Inside Context Integra-
tion 
The method of inside context integration is used 
to combine the inside context (gap strings) into 
PAS for translation, i.e., extend the PASTR to 
IC-PASTR. In order to demonstrate the effec-
tiveness of inside context integration, we first 
give Table 3, which illustrates statistics on the 
matching PASs. The statistics are conducted on 
the combination of development set and test set. 
Transformation 
Rules 
Matching PAS 
None Gap PAS Gap PAS Total 
PASTR 1702 1539 3241 
IC-PASTR 1546 832 2378 
Table 3. Statistics on the matching PAS. 
In Table 3, for example, the line for PASTR 
means that if we use PASTR for the combined 
set, 3241 PASs (column ?Total?) can match 
PASTRs in total. Among these matching PASs, 
1539 ones (column ?Gap PAS?) carry gap strings, 
while 1702 ones do not (column ?None Gap 
PAS?). Consequently, since PASTR does not 
consider the inside context during translation, the 
Gap PASs, which account for 47% (1539/3241) 
of all matching PASs, might be handled inappro-
priately in the PAS-based translation framework. 
Therefore, integrating the inside context into 
PASTRs, i.e., using the proposed IC-PASTRs, 
would be helpful for translation. The translation 
result shown in Table 2 also demonstrates this 
conclusion. 
(a) reference
(c) translation result using IC-PASTR
[for economic recovery , especially of investment confidence is]
[  A0  ] [                              PP                               ] [Pred] [      A1      ]
? ? ? ? ???? ?? ?? ? ??? ?? ?? ??
[ a good sign ] [ for economic recovery , especially of investment confidence ]this is
? ? ? ? ??? ?? ?? ? ??? ?? ?? ??  ? 
[a good sign]this
(b) translation result using PASTR
[  A0  ] [                              PP                               ] [Pred] [      A1      ]
? ? ? ? ???? ?? ?? ? ??? ?? ?? ??
[a good sign]this is [for economic recovery and the restoration of investors ' confidence]
[  A0  ] [                            Pred                             ] [      A1      ]
 
Figure 5. Translation examples to verify the effec-
tiveness of inside context.  
From Table 3, we can also find that the num-
ber of matching PASs decreases after using IC-
PASTR. This is because IC-PASTR is more spe-
cific than PASTR. Therefore, for a PAS with 
specific inside context (gap strings), even if the 
matched PASTR is available, the matched IC-
PASTR might not. This indicates that comparing 
with PASTR, IC-PASTR is more capable of dis-
tinguishing different PASs. Therefore, based on 
this advantage, although the number of matching 
PASs decreases, IC-PASTR still improves the 
translation system using PASTR significantly. Of 
course, we believe that it is also possible to inte-
grate the inside context without decreasing the 
number of matching PASs and we plan this as 
our future work. 
We further give a translation example in Fig-
ure 5 to illustrate the effectiveness of our inside 
context integration method. In the example, the  
automatic SRL system ignores the long preposi-
tion phrase ?? ???? ???? ?? ???
?? for the PAS. Thus, the system using PASTRs 
can only attach the long phrase to the predicate 
??? according to the parse tree, and meanwhile, 
make use of a transformation rule as follows: 
[X3] [X2] [A0]1 [Pred]2 [A1]3 [X1] 
source-side PAS(?) target-side-like PAS
 
In this way, the translation result is very bad, just 
as Figure 5(b) shows. The long preposition 
phrases are wrongly positioned in the translation. 
In contrast, after inside context integration, we 
match the inside context during PAS transfor-
mation. As Figure 5(c) shows, the inside context 
helps to selects a right transformation rule as fol-
lows and gets a good translation result finally. 
[X1] [X2] [X4] [A0]1 [PP]2 [Pred]3 [A1]4 [X3] 
source-side PAS(?) target-side-like PAS
 
7.5 Effectiveness of the MEPD Model 
The MEPD model incorporates various context 
features to select better target-side-like PAS for 
translation. On the basis of PASTR and IC-
PASTR, we build 160 and 215 different MEPD 
classifies, respectively, for the frequent source-
side PASs. 
In Table 2, we have found that our MEPD 
model improves system IC-PASTR slightly. We 
conjecture that this phenomenon is due to two 
possible reasons. On one hand, sometimes, many 
PAS ambiguities might be resolved by both in-
side context and the MEPD model. Therefore, 
the improvement would not be such significant 
1133
when we combine these two methods together. 
On the other hand, as Table 3 shows, the number 
of matching PASs decreases after using IC-
PASTR. Since the MEPD model works on PASs, 
its effectiveness would also weaken to some ex-
tent. Future work will explore this phenomenon 
more thoroughly. 
PASTR
Ref
PASTR 
+ MEPD
...  ,  [??]A0    [?]Pred    [? ?? ??]A1  ?
...  [the hague]     [is]      [the last leg]  .
...  ,  [??]    [?]    [? ?? ??]  ?
...  [the hague]   [is]   [his last stop]  .
...  ,  [??]A0    [?]Pred    [? ?? ??]A1  ?
...   [is]    [his last leg of]    [the hague] .
 
Figure 6. Translation examples to demonstrate the 
effectiveness of our MEPD model. 
Now, we give Figure 6 to demonstrate the ef-
fectiveness of our MEPD model. From the Fig-
ure, we can see that the system using PASTRs 
selects an inappropriate transformation rule for 
translation: 
[X1] [X3] [A0]1 [Pred]2 [A1]3 [X2] 
source-side PAS(?) target-side-like PAS
 
This rule wrongly moves the subject ???
(Hague)? to the end of the translation. We do not 
give the translation result of the BTG system 
here because it makes the same mistake. 
Conversely, by considering the context infor-
mation, the PASTR+MEPD system chooses a 
correct rule for translation: 
[X3] [X2] [A0]1 [Pred]2 [A1]3 [X1] 
source-side PAS(?) target-side-like PAS
 
As we can see, the used rule helps to keep the 
SVO structure unchanged, and gets the correct 
translation. 
8 Conclusion and Future Work 
In this paper, we focus on the problem of ambi-
guities for PASs. We first propose two ambigui-
ties: gap ambiguity and role ambiguity. Accord-
ingly, we design two novel methods to do effi-
cient PAS disambiguation: inside-context inte-
gration and a novel MEPD model. For inside 
context integration, we abstract the inside con-
text and combine them into the PASTRs for PAS 
transformation. Towards the MEPD model, we 
design a maximum entropy model for each ambi-
tious source-side PASs. The two methods suc-
cessfully incorporate the rich context information 
into the translation process. Experiments show 
that our PAS disambiguation methods help to 
improve the translation performance significantly.  
In the next step, we will conduct experiments 
on other language pairs to demonstrate the effec-
tiveness of our PAS disambiguation method. In 
addition, we also will try to explore more useful 
and representative features for our MEPD model. 
Acknowledgments 
The research work has been funded by the Hi-
Tech Research and Development Program (?863? 
Program) of China under Grant No. 
2011AA01A207, 2012AA011101, and 
2012AA011102 and also supported by the Key 
Project of Knowledge Innovation Program of 
Chinese Academy of Sciences under Grant 
No.KGZD-EW-501. We thank the anonymous 
reviewers for their valuable comments and sug-
gestions. 
References  
Wilker Aziz, Miguel Rios, and Lucia Specia. (2011). 
Shallow semantic trees for smt. In Proceedings of 
the Sixth Workshop on Statistical Machine Trans-
lation, pages 316?322, Edinburgh, Scotland, July. 
Daniel Bikel. (2004). Intricacies of Collins parsing 
model. Computational Linguistics, 30(4):480-511. 
David Chiang, (2007). Hierarchical phrase-based 
translation. Computational Linguistics, 33 (2):201?
228. 
Marine Carpuat and Dekai Wu. 2007a. How phrase-
sense disambiguation outperforms word sense dis-
ambiguation for statistical machine translation. In 
11th Conference on Theoretical and Methodologi-
cal Issues in Machine Translation, pages 43?52. 
Marine Carpuat and Dekai Wu. 2007b. Improving 
statistical machine translation using word sense 
disambiguation. In Proceedings of EMNLP-CoNLL 
2007, pages 61?72. 
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 
2007. Word sense disambiguation improves statis-
tical machine translation. In Proc. ACL 2007, pag-
es 33?40. 
Lei Cui, Dongdong Zhang, Mu Li, Ming Zhou and 
Tiejun Zhao. A Joint Rule Selection Model for 
Hierarchical Phrase-Based Translation. In Proc. 
of ACL 2010. 
1134
Jason Eisner. (2003). Learning non-isomorphic tree 
mappings for machine translation. In Proc. of ACL 
2003. 
Pascale Fung, Wu Zhaojun, Yang Yongsheng, and 
Dekai Wu. (2006). Automatic learning of chinese 
english semantic structure mapping. In IEEE/ACL 
2006 Workshop on Spoken Language Technology 
(SLT 2006), Aruba, December. 
Pascale Fung, Zhaojun Wu, Yongsheng Yang and 
Dekai Wu. (2007). Learning bilingual semantic 
frames: shallow semantic sarsing vs. semantic sole 
projection. In Proceedings of the 11th Conference 
on Theoretical and Methodological Issues in Ma-
chine Translation, pages 75-84. 
Qin Gao and Stephan Vogel. (2011). Utilizing target-
side semantic role labels to assist hierarchical 
phrase-based machine translation. In Proceedings 
of Fifth Workshop on Syntax, Semantics and Struc-
ture in Statistical Translation, pages 107?115, 
Portland, Oregon, USA, June 2011. Association for 
Computational Linguistics 
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexi-
calized rule selection. In Proc. of Coling 2008, 
pages 321?328. 
Franz Josef Och. (2003). Minimum error rate training 
in statistical machine translation. In Proc. of ACL 
2003, pages 160?167. 
Franz Josef Och and Hermann Ney. (2004). The 
alignment template approach to statistical machine 
translation. Computational Linguistics, 30:417?449. 
Dan Klein and Christopher D. Manning. (2003). Ac-
curate unlexicalized parsing. In Proc. of ACL-2003, 
pages 423-430. 
Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 
(2003). Statistical phrase-based translation. In Pro-
ceedings of NAACL 2003, pages 58?54, Edmonton, 
Canada, May-June. 
Philipp Koehn. (2004). Statistical significance tests 
for machine translation evaluation. In Proceedings 
of EMNLP 2004, pages 388?395, Barcelona, Spain, 
July. 
P Koehn, H Hoang, A Birch, C Callison-Burch, M 
Federico, N Bertoldi, B Cowan, W Shen, C Moran 
and R Zens, (2007). Moses: Open source toolkit for 
statistical machine translation. In Proc. of ACL 
2007. pages 177?180, Prague, Czech Republic, 
June. Association for Computational Linguistics. 
Mamoru Komachi and Yuji Matsumoto. (2006). 
Phrase reordering for statistical machine translation 
based on predicate-argument structure. In Proceed-
ings of the International Workshop on Spoken 
Language Translation: Evaluation Campaign on 
Spoken Language Translation, pages 77?82. 
Ding Liu and Daniel Gildea. (2008). Improved tree-
to-string transducer for machine Translation. In 
Proceedings of the Third Workshop on Statistical 
Machine Translation, pages 62?69, Columbus, 
Ohio, USA, June 2008. 
Ding Liu and Daniel Gildea. (2010). Semantic role 
features for machine translation. In Proc. of Coling 
2010, pages 716?724, Beijing, China, August. 
Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin. 
Maximum Entropy based Rule Selection Model for 
Syntax-based Statistical Machine Translation. In 
Proc. of EMNLP 2008.  
Yang Liu, Qun Liu and Shouxun Lin. (2006). Tree-to-
string alignment template for statistical machine 
translation. In Proc. of ACL-COLING 2006. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. (2006). SPMT: Statistical machine 
translation with syntactified target language 
phrases. In Proc. of EMNLP 2006, pages 44-52. 
Kishore Papineni, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. (2002). Bleu: a method for automat-
ic evaluation of machine translation. In Proc. ACL 
2002, pages 311?318, Philadelphia, Pennsylvania, 
USA, July. 
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan 
Klein. (2006). Learning accurate, compact, and in-
terpretable tree annotation. In Proceedings of the 
21st International Conference on Computational 
Linguistics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 433?
440, Sydney, Australia, July. Association for Com-
putational Linguistics. 
Andreas Stolcke. (2002). Srilm ? an extensible lan-
guage modelling toolkit. In Proceedings of the 7th 
International Conference on Spoken Language 
Processing, pages 901?904, Denver, Colorado, 
USA, September. 
Dekai Wu and Pascale Fung. (2009a). Can semantic 
role labelling improve smt. In Proceedings of the 
13th Annual Conference of the EAMT, pages 218?
225, Barcelona, May. 
Dekai Wu and Pascale Fung. (2009b). Semantic roles 
for smt: A hybrid two-pass model. In Proc. NAACL 
2009, pages 13?16, Boulder, Colorado, June. 
ShuminWu and Martha Palmer. (2011). Semantic 
mapping using automatic word alignment and se-
mantic role labelling. In Proceedings of Fifth 
Workshop on Syntax, Semantics and Structure in 
Statistical Translation, pages 21?30, Portland, Or-
egon, USA, June 2011. 
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime 
Tsukada, and Masaaki Nagata. (2011). Extracting 
preordering rules from predicate-argument struc-
tures. In Proc. IJCNLP 2011, pages 29?37, Chiang 
Mai, Thailand, November.  
1135
Deyi Xiong, Qun Liu, and Shouxun Lin. (2006). Max-
imum entropy based phrase reordering model for 
statistical machine translation. In Proceedings of 
the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the 
Association for Computational Linguistics, pages 
521?528, Sydney, Australia, July. 
Deyi Xiong, Min Zhang, and Haizhou Li. (2012). 
Modelling the translation of predicate-argument 
structure for smt. In Proc. of ACL 2012, pages 
902?911, Jeju, Republic of Korea, 8-14 July 2012. 
Nianwen Xue. (2008). Labelling chinese predicates 
with semantic roles. Computational Linguistics, 
34(2): 225-255. 
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing 
Zong. Machine Translation by Modeling Predicate- 
Argument Structure Transformation. In Proc. of 
COLING 2012. 
Hui Zhang, Min  Zhang, Haizhou Li and Eng Siong 
Chng. (2010). Non-isomorphic Forest Pair Transla-
tion. In Proceedings of EMNLP 2010, pages 440-
450, Massachusetts, USA, 9-11 October 2010.  
Tao Zhuang, and Chengqing Zong. (2010a). A mini-
mum error weighting combination strategy for chi-
nese semantic role labelling. In Proceedings of 
COLING-2010, pages 1362-1370. 
Tao Zhuang and Chengqing Zong. (2010b). Joint in-
ference for bilingual semantic role labelling. In 
Proceedings of EMNLP 2010, pages 304?314, 
Massachusetts, USA, 9-11 October 2010.  
1136
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 370?374,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
A Novel Translation Framework Based on Rhetorical Structure Theory 
 
 
Mei Tu             Yu Zhou           Chengqing Zong 
National Laboratory of Pattern Recognition, Institute of Automation,  
Chinese Academy of Sciences 
{mtu,yzhou,cqzong}@nlpr.ia.ac.cn 
  
 
 
 
Abstract 
Rhetorical structure theory (RST) is widely 
used for discourse understanding, which repre-
sents a discourse as a hierarchically semantic 
structure. In this paper, we propose a novel 
translation framework with the help of RST. In 
our framework, the translation process mainly 
includes three steps: 1) Source RST-tree ac-
quisition: a source sentence is parsed into an 
RST tree; 2) Rule extraction: translation rules 
are extracted from the source tree and the tar-
get string via bilingual word alignment; 3) 
RST-based translation: the source RST-tree 
is translated with translation rules. Experi-
ments on Chinese-to-English show that our 
RST-based approach achieves improvements 
of 2.3/0.77/1.43 BLEU points on 
NIST04/NIST05/CWMT2008 respectively. 
1 Introduction 
For statistical machine translation (SMT), a cru-
cial issue is how to build a translation model to 
extract as much accurate and generative transla-
tion knowledge as possible. The existing SMT 
models have made much progress. However, 
they still suffer from the bad performance of un-
natural or even unreadable translation, especially 
when the sentences become complicated. We 
think the deep reason is that those models only 
extract translation information on lexical or syn-
tactic level, but fail to give an overall under-
standing of source sentences on semantic level of 
discourse. In order to solve such problem, (Gong 
et al, 2011; Xiao et al, 2011; Wong and Kit, 
2012) build discourse-based translation models 
to ensure the lexical coherence or consistency. 
Although some lexicons can be translated better 
by their models, the overall structure still re-
mains unnatural. Marcu et al  (2000) design a 
discourse structure transferring module, but leave 
much work to do, especially on how to integrate 
this module into SMT and how to automatically 
analyze the structures. Those reasons urge us to 
seek a new translation framework under the idea 
of ?translation with overall understanding?. 
Rhetorical structure theory (RST) (Mann and 
Thompson, 1988) provides us with a good per-
spective and inspiration to build such a frame-
work. Generally, an RST tree can explicitly show 
the minimal spans with semantic functional in-
tegrity, which are called elementary discourse 
units (edus) (Marcu et al, 2000), and it also de-
picts the hierarchical relations among edus. Fur-
thermore, since different languages? edus are 
usually equivalent on semantic level, it is intui-
tive to create a new framework based on RST by 
directly mapping the source edus to target ones. 
Taking the Chinese-to-English translation as 
an example, our translation framework works as 
the following steps:  
1) Source RST-tree acquisition: a source 
sentence is parsed into an RST-tree;  
2) Rule extraction: translation rules are ex-
tracted from the source tree and the target string 
via bilingual word alignment;  
3) RST-based translation:  the source RST-
tree is translated into target sentence with ex-
tracted translation rules. 
Experiments on Chinese-to-English sentence-
level discourses demonstrate that this method 
achieves significant improvements. 
2 Chinese RST Parser  
2.1 Annotation of Chinese RST Tree 
Similar to (Soricut and Marcu, 2003), a node of 
RST tree is represented as a tuple R-[s, m, e], 
which means the relation R controls two seman-
tic spans U1 and U2 , U1 starts from word position 
s and stops at word position m. U2 starts from 
m+1 and ends with e. Under the guidance of def-
inition of RST, Yue (2008) defined 12 groups1 of 
                                                 
1They are Parallel, Alternative, Condition, Reason, Elabo-
ration, Means, Preparation, Enablement, Antithesis, Back-
ground, Evidences, Others. 
370
rhetorical relations for Chinese particularly, upon 
which our Chinese RST parser is developed. 
Figure 1 illustrates an example of Chinese 
RST tree and its alignment to the English string. 
There are two levels in this tree. The Antithesis 
relation controls U1 from 0 to 9 and U2 from 10 
to 21. Thus it is written as Antithesis-[0,9,21]. 
Different shadow blocks denote the alignments 
of different edus. Links between source and tar-
get words are alignments of cue words. Cue 
words are viewed as the strongest clues for rhe-
torical relation recognition and always found at 
the beginning of text (Reitter, 2003), such as ??
?(although), ??(because of)?. With the cue 
words included, the relations are much easier to 
be analyzed. So we focus on the explicit relations 
with cue words in this paper as our first try. 
2.2 Bayesian Method for Chinese RST Parser 
For Chinese RST parser, there are two tasks. One 
is the segmentation of edu and the other is the 
relation tagging between two semantic spans. 
Feature Meaning 
F1(F6) left(right) child is a syntactic sub-tree? 
F2(F5) left(right) child ends with a punctuation? 
F3(F4) cue words of left (right) child. 
F7 left and right children are sibling nodes? 
F8(F9) syntactic head symbol of left(right) child. 
Table 1: 9 features used in our Bayesian model 
Inspired by the features used in English RST 
parser (Soricut and Marcu, 2003; Reitter, 2003; 
Duverle and Prendinger, 2009; Hernault et al, 
2010a), we design a Bayesian model to build a 
joint parser for segmentation and tagging simul-
taneously. In this model, 9 features in Table 1 are 
used. In the table, punctuations include comma, 
semicolons, period and question mark. We view 
explicit connectives as cue words in this paper. 
Figure 2 illustrates the conditional independ-
ences of 9 features which are denoted with F1~F9. 
 
The segmentation and parsing conditional 
probabilities are computed as follows: 
P (mjF 91 ) = P (mjF 31 ; F8) (1)
P (ejF 91 ) = P (ejF 74 ; F9) (2)
P (ReljF 91 ) = P (ReljF 43 ) (3) 
where Fn represents the nth  feature , F ln means 
features from n  to l . Rel  is short for relation. (1) 
and (2) describe the conditional probabilities of 
m and e. When using Formula (3) to predict the 
relation, we search all the cue-words pair, as 
shown in Figure 1, to get the best match. When 
training, we use maximum likelihood estimation 
to get al the associated probabilities. For decod-
ing, the pseudo codes are given as below. 
 
m e
F1 F2 F3
Rel
F4 F5 F6 F7F8 F9
 
Figure 2: The graph for conditional independences 
of 9 features. 
1: Nodes={[]} 
2: Parser(0,End)  
3: Parser(s,e): // recursive parser function 
4:    if s > e or e is -1: return -1; 
5:    m = GetMaxM(s,e)  //compute m through Formu-
la(1);if no cue words found, 
then m=-1; 
6:      e? = GetMaxE(s,m,e)  //compute e? through F (2); 
7:    if m or e? equals to -1: return -1; 
8:   Rel=GetRelation(s,m,e?) //compute relation by F 
(3) 
9:    push [Rel,s,m,e?] into Nodes   
10:  Parser(s,m)  
11:  Parser(m+1,e?) 
12:  Parser(e?+1,e) 
13:   Rel=GetRelation(s,e?,e) 
14:   push [Rel,s,e?,e] into Nodes 
15:   return e 
J?sh?     l?b?    du? me?yu?n  de m?ngy?   hu?l? xi?ji?ng  le    ,
??       ??       ?    ??          ?   ??          ??     ??      ?    ?
  0               1           2         3              4        5                6            7          8     9
y?uy?  g?o t?ngzh?ng ,
 ??       ?    ??            ?
   10          11      12            13
q?    sh?j?   hu?l?    y?  sh?  sh?ngsh?ng de    .
?    ??      ??      ?   ?           ??          ?    ?
14      15           16        17   18             19            20   21   
Although the rupee's nominal rate against the dollar was held down , India's real exchange rate rose because of  high inflation . 
Reason 
Antithesis
U1:[0,9] U2:[10,21]
U1:[10,13] U2:[14,21]
Cue-words pair matching set of cue words for span [0,9] and [10,21]:{??/??,??/NULL,NULL/??}
Cue-words pair matching set of cue words for span [10,13] and [14,21]:{??/NULL}
RST-based Rules:  Antithesis:: ??[X]/[Y] => Although[X]/[Y] ;  Reason::??[X]/[Y] => [Y]/because of[X]
Example 1:
Figure 1: An example of Chinese RST tree and its word alignment of the corresponding English string. 
371
For example in Figure 1, for the first iteration, 
s=0 and m will be chosen from {1-20}. We get 
m=9 through Formula (1). Then, similar with m, 
we get e=21 through Formula (2). Finally, the 
relation is figured out by Formula (3). Thus, a 
node is generated. A complete RST tree con-
structs until the end of the iterative process for 
this sentence. This method can run fast due to the 
simple greedy algorithm.  It is plausible in our 
cases, because we only have a small scale of 
manually-annotated Chinese RST corpus, which 
prefers simple rather than complicated models.  
3 Translation Model 
3.1 Rule Extraction 
As shown in Figure 1, the RST tree-to-string 
alignment provides us with two types of transla-
tion rules. One is common phrase-based rules, 
which are just like those in phrase-based model 
(Koehn et al, 2003). The other is RST tree-to-
string rule, and it?s defined as, 
relation ::U1(?;X)=U2(?; Y )
) U1(tr(?); tr(X)) ? U2(tr(?); tr(Y ))
 
where the terminal characters ? and ? represent 
the cue words which are optimum match for 
maximizing Formula (3). While the non-
terminals X and Y represent the rest of the se-
quence. Function tr(? ) means the translation 
of ?. The operator ~ is an operator to indicate 
that the order of tr(U1) and tr(U2) is monotone or 
reverse. During rules? extraction, if the mean 
position of all the words in tr(U1) precedes that 
in tr(U2), ~ is monotone. Otherwise, ~ is reverse.   
For example in Figure 1, the Reason relation 
controls U1:[10,13] and U2:[14,21]. Because the 
mean position of tr(U2) is before that of tr(U1), 
the reverse order is selected. We list the RST-
based rules for Example 1 in Figure 1. 
3.2 Probabilities Estimation  
For the phrase-based translation rules, we use 
four common probabilities and the probabilities? 
estimation is the same with those in (Koehn et al, 
2003). While the probabilities of RST-based 
translation rules are given as follows,  
(1) P(rejrf ;Rel) = Count(re;rf ;relation)Count(rf ;relation)
:  where re  
is the target side of the rule, ignorance of the or-
der, i.e. U1(tr(?); tr(X)) ? U2(tr(?); tr(Y )) with 
two directions, rf is the source side, i.e. 
U1(?;X)=U2(?;Y ), and Rel  means the relation 
type.  
(2) P(?jre; rf ;Rel) = Count(?;re;rf ;relation)Count(re;rf ;relation)
: 
? 2 fmonotone; reverseg. It is the conditional 
probability of re-ordering. 
4 Decoding 
The decoding procedure of a discourse can be 
derived from the original decoding formula 
eI1 = argmaxeI1P (eI1jfJ1 )
. Given the rhetorical 
structure of a source sentence and the corre-
sponding rule-table, the translating process is to 
find an optimal path to get the highest score un-
der structure constrains, which is, 
argmaxesfP (esj; ft)g
= argmaxesf
Y
fn2ft
P (eu1; eu2; ? jfn)g
 
where ft  is a source  RST tree combined by a set 
of node fn . es is the target string combined by 
series of en  (translations of fn ).  fn  consists of  
U1 and U2. eu1  and eu2  are translations of U1 and 
U2 respectively. This global optimization prob-
lem is approximately simplified to local optimi-
zation to reduce the complexity,  
Y
fn2ft
argmaxenfP(eu1; eu2; ? jfn)g
 
In our paper, we have the following two ways 
to factorize the above formula, 
Decoder 1: 
P (eu1; eu2; ? jfn)
= P (ecp; eX ; eY ; ? jfcp; fX ; fY )
= P (ecpjfcp)P (? jecp; fcp)P (eX jfX )P (eY jfY )
= P (rejrf ;Rel)P (? jre; rf ; Rel)P (eX jfX )P (eY jfY )   
where eX, eY are the translation of non-terminal 
parts. fcp  and ecp  are cue-words pair of source 
and target sides. The first and second factors are 
just the probabilities introduced in Section 3.2. 
After approximately simplified to local optimiza-
tion, the final formulae are re-written as, 
argmaxrfP (rejrf ; Rel)P (? jre; rf ; Rel)g (4)
argmaxeX fP (eX jfX )g (5)
argmaxeY fP (eY jfY )g (6)
 
Taking the source sentence with its RST tree 
in Figure 1 for instance, we adopt a bottom-up 
manner to do translation recursively. Suppose the 
best rules selected by (4) are just those written in 
the figure, Then span [11,13] and [14,21] are 
firstly translated by (5) and (6). Their translations 
are then re-packaged by the rule of Reason-
[10,13,21]. Iteratively, the translations of span 
[1,9] and [10,21] are re-packaged by the rule of 
Antithesis-[0,9,21] to form the final translation.  
372
Decoder 2 : Suppose that the translating process 
of two spans U1 and U2 are independent of each 
other, we rewrite P(eu1; eu2; ? jfn)   as follows, 
P (eu1; eu2; ? jfn)
= P (eu1; eu2; ? jfu1; fu2)
= P (eu1jfu1)P (eu2jfu2)P (? jrf ; Rel)
= P (eu1jfu1)P (eu2jfu2)
X
re
P (? jre; rf ; Rel)P (rejrf ; Rel)
after approximately simplified to local optimization, 
the final formulae are re-written as below,
 
argmaxeu1fPr(eu1jfu1)g (7)
argmaxeu2fPr(eu2jfu2)g (8)
argmaxrf
X
e
Pr(? jre; rf ; Rel)Pr(rejrf ; Rel)g (9)
 
We also adopt the bottom-up manner similar 
to Decoder 1. In Figure 1, U1 and U2 of Reason 
node are firstly translated. Their translations are 
then re-ordered. Then the translations of two 
spans of Antithesis node are re-ordered and con-
structed into the final translation. In Decoder 2, 
the minimal translation-unit is edu. While in De-
coder 1, an edu is further split into cue-word part 
and the rest part to obtain the respective transla-
tion.  
In our decoders, language model(LM) is used 
for translating edus in Formula(5),(6),(7),(8), but 
not for reordering the upper spans because with 
the bottom-to-up combination, the spans become 
longer and harder to be judged by a traditional 
language model. So we only use RST rules to 
guide the reordering.  But LM will be properly 
considered in our future work. 
5 Experiment 
5.1 Setup 
In order to do Chinese RST parser, we annotated 
over 1,000 complicated sentences on CTB (Xue 
et al, 2005), among which 1,107 sentences are 
used for training, and 500 sentences are used for 
testing. Berkeley parser2 is used for getting the 
syntactic trees.  
The translation experiment is conducted on 
Chinese-to-English direction. The bilingual train-
ing data is from the LDC corpus3. The training 
corpus contains 2.1M sentence pairs. We obtain 
the word alignment with the grow-diag-final-and 
strategy by GIZA++4. A 5-gram language model 
is trained on the Xinhua portion of the English 
                                                 
2
 http://code.google.com/p/berkeleyparser/ 
3
 LDC category number : LDC2000T50, LDC2002E18, 
LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27, 
LDC2005T10 and LDC2005T34 
4 http://code.google.com/p/giza-pp/ 
Gigaword corpus. For tuning and testing, we use 
NIST03 evaluation data as the development set, 
and extract the relatively long and complicated 
sentences from NIST04, NIST05 and CWMT085  
evaluation data as the test set. The number and 
average word-length of sentences are 511/36, 
320/34, 590/38 respectively. We use case-
insensitive BLEU-4 with the shortest length pen-
alty for evaluation.  
To create the baseline system, we use the 
toolkit Moses6 to build a phrase-based translation 
system. Meanwhile, considering that Xiong et al 
(2009) have presented good results by dividing 
long and complicated sentences into sub-
sentences only by punctuations during decoding, 
we re-implement their method for comparison. 
5.2 Results of Chinese RST Parser 
Table 2 shows the results of RST parsing. On 
average, our RS trees are 2 layers deep. The 
parsing errors mostly result from the segmenta-
tion errors, which are mainly caused by syntactic 
parsing errors. On the other hand, the polyse-
mous cue words, such as ??(but, and, thus)? 
may lead ambiguity for relation recognition, be-
cause they can be clues for different relations.  
Task Precision Recall F1 
Segmentation 0.74 0.83 0.78 
Labeling 0.71 0.78 0.75 
Table 2: Segmentation and labeling result. 
5.3 Results of Translation 
Table 3 presents the translation comparison re-
sults. In this table, XD represents the method in 
(Xiong et al, 2009). D1 stands for Decoder-1, 
and D2 for Decoder-2. Values with boldface are 
the highest scores in comparison. D2 performs 
best on the test data with 2.3/0.77/1.43/1.16 
points. Compared with XD, our results also out-
perform by 0.52 points on the whole test data. 
Observing and comparing the translation re-
sults, we find that our translation results are more 
readable by maintaining the semantic integrality 
of the edus and by giving more appreciate reor-
ganization of the translated edus. 
Testing Set Baseline XD D1 D2 
NIST04 29.39 31.52 31.34 31.69 
NIST05 29.86 29.80 30.28 30.63 
CWMT08 24.31 25.24 25.74 25.74 
ALL 27.85 28.49 28.66 29.01 
Table 3: Comparison with related models. 
                                                 
5
 China Workshop on Machine Translation 2008 
6
 www.statmt.org/moses/index.php?n=Main.HomePage 
373
6 Conclusion and Future Work 
In this paper, we present an RST-based transla-
tion framework for modeling semantic structures 
in translation model, so as to maintain the se-
mantically functional integrity and hierarchical 
relations of edus during translating. With respect 
to the existing models, we think our translation 
framework works more similarly to what human 
does, and we believe that this research is a cru-
cial step towards discourse-oriented translation. 
In the next step, we will study on the implicit 
discourse relations for Chinese and further modi-
fy the RST-based framework. Besides, we will 
try to combine other current translation models 
such as syntactic model and hierarchical model 
into our framework. Furthermore, the more accu-
rate evaluation metric for discourse-oriented 
translation will be further studied. 
 
Acknowledgments 
The research work has been funded by the Hi-Tech 
Research and Development Program (?863? Pro-
gram) of China under Grant No. 2011AA01A207, 
2012AA011101, and 2012AA011102 and also sup-
ported by the Key Project of Knowledge Innova-
tion Program of Chinese Academy of Sciences un-
der Grant No.KGZD-EW-501. 
References  
David A Duverle and Helmut Prendinger. 2009. A 
novel discourse parser based on support vector ma-
chine classification. In Proceedings of the Joint 
Conference of the 47th Annual Meeting of the ACL 
and the 4th International Joint Conference on Nat-
ural Language Processing of the AFNLP: Volume 
2-Volume 2, pages 665?673. Association for Com-
putational Linguistics. 
Zhengxian Gong, Min Zhang, and Guodong Zhou. 
2011. Cache-based document-level statistical ma-
chine translation. In Proceedings of the Conference 
on Empirical Methods in Natural Language Pro-
cessing, pages 909?919. Association for Computa-
tional Linguistics. 
Hugo Hernault, Danushka Bollegala, and Mitsuru 
Ishizuka. 2010a. A sequential model for discourse 
segmentation. Computational Linguistics and Intel-
ligent Text Processing, pages 315?326. 
Hugo Hernault, Helmut Prendinger, Mitsuru Ishizuka, 
et al 2010b. Hilda: A discourse parser using sup-
port vector machine classification. Dialogue & 
Discourse, 1(3). 
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology 
Volume 1, pages 48?54. Association for Computa-
tional Linguistics. 
William C Mann and Sandra A Thompson. 1986. 
Rhetorical structure theory: Description and con-
struction of text structures. Technical report, DTIC 
Document. 
William C Mann and Sandra A Thompson. 1987. 
Rhetorical structure theory: A framework for the 
analysis of texts. Technical report, DTIC Docu-
ment. 
William C Mann and Sandra A Thompson. 1988. 
Rhetorical structure theory: Toward a functional 
theory of text organization. Text, 8(3):243?281. 
Daniel Marcu, Lynn Carlson, and Maki Watanabe. 
2000. The automatic translation of discourse struc-
tures. In Proceedings of the 1st North American 
chapter of the Association for Computational Lin-
guistics conference, pages 9?17. Morgan Kauf-
mann Publishers Inc. 
David Reitter. 2003. Simple signals for complex rhet-
orics: On rhetorical analysis with rich-feature sup-
port vector models. Language, 18:52. 
Radu Soricut and Daniel Marcu. 2003. Sentence level 
discourse parsing using syntactic and lexical in-
formation. In Proceedings of the 2003 Conference 
of the North American Chapter of the Association 
for Computational Linguistics on Human Lan-
guage Technology-Volume 1, pages 149?156. As-
sociation for Computational Linguistics. 
Billy TM Wong and Chunyu Kit. 2012. Extending 
machine translation evaluation metrics with lexical 
cohesion to document level. In Proceedings of the 
2012 Joint Conference on Empirical Methods in 
Natural Language Processing and Computational 
Natural Language Learning, page 1060?1068. As-
sociation for Computational Linguistics. 
Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang. 
2011. Document-level consistency verification in 
machine translation. In Machine Translation Sum-
mit, volume 13, pages 131?138. 
Hao Xiong, Wenwen Xu, Haitao Mi, Yang Liu, and 
Qun Liu. 2009. Sub-sentence division for tree-
based machine translation. In Proceedings of the 
ACL-IJCNLP 2009 Conference Short Papers, pag-
es 137?140. Association for Computational Lin-
guistics. 
Naiwen Xue, Fei Xia, Fu-Dong Chiou, and Marta 
Palmer. 2005. The Penn Chinese treebank: Phrase 
structure annotation of a large corpus. Natural 
Language Engineering, 11(2):207. 
Ming Yue. 2008. Rhetorical structure annotation of 
Chinese news commentaries. Journal of Chinese 
Information Processing, 4:002. 
374
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 850?860,
Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational Linguistics
Enhancing Grammatical Cohesion: 
Generating Transitional Expressions for SMT 
 
Mei Tu             Yu Zhou           Chengqing Zong 
National Laboratory of Pattern Recognition,  
Institute of Automation,  
Chinese Academy of Sciences 
{mtu,yzhou,cqzong}@nlpr.ia.ac.cn 
 
  
 
 
Abstract 
Transitional expressions provide glue that 
holds ideas together in a text and enhance the 
logical organization, which together help im-
prove readability of a text. However, in most 
current statistical machine translation (SMT) 
systems, the outputs of compound-complex 
sentences still lack proper transitional expres-
sions. As a result, the translations are often 
hard to read and understand. To address this 
issue, we propose two novel models to en-
courage generating such transitional expres-
sions by introducing the source compound-
complex sentence structure (CSS). Our models 
include a CSS-based translation model, which 
generates new CSS-based translation rules, 
and a generative transfer model, which en-
courages producing transitional expressions 
during decoding. The two models are integrat-
ed into a hierarchical phrase-based translation 
system to evaluate their effectiveness. The ex-
perimental results show that significant im-
provements are achieved on various test data 
meanwhile the translations are more cohesive 
and smooth.  
1 Introduction 
During the last decade, great progress has been 
made on statistical machine translation (SMT) 
models. However, these translations still suffer 
from poor readability, especially translations of 
compound-complex sentences. One of the main 
reasons may be that most existing models con-
centrate more on producing well-translated local 
sentence fragments, but largely ignore global 
cohesion between the fragments. Generally, co-
hesion, including lexical and grammatical cohe-
sion, contributes much to the understandability 
and smoothness of a text.  
Recently, researchers have begun addressing 
the lexical cohesion of SMT (Gong et al, 2011; 
Xiao et al, 2011; Wong and Kit, 2012; Xiong, 
2013). These efforts focus mainly on the co-
occurrence of lexical items in a similar environ-
ment. Grammatical cohesion1 (Halliday and Has-
san, 1976) in SMT has been little mentioned in 
previous work. Translations without grammatical 
cohesion is hard to read, mostly due to loss of 
cohesive and transitional expressions between 
two sentence fragments. Thus, generating transi-
tional expressions is necessary for achieving 
grammatical cohesion. However, it is not easy to 
produce such transitional expressions in SMT. 
As an example, consider the Chinese-to-English 
translation in Figure 1.  
Source Chinese sentence:  
  [??         ??     ??     ?   ??     ??      ?]1   [  ??          
Alth ugh   reduce  pollution  of   calls    continue  ,           public      
   ??       ??   ?]2   [??       ??    ??       ?        ??                               
gr wing    angry  ,         pollution  still    become   more   worse 
   ?   ?]3  [??  ??         ??                         ?    ??? ?]4
already   ,   more   show  environment  protection  of    urgent .
Target English golden translation:
Despite frequent calls for cutting pollution, and 
growing public anger, the proble  has only g t worse, 
which increasingly shows the urgency of environmental 
protection.
Figure 1: An example of Chinese-to-English transla-
tion. The English translation sentence has three transi-
tional phrases: Despite, and, which. 
 
There are 4 sub-sentences separated by com-
mas in the Chinese sentence. We have tried to 
translate the Chinese sentence using many well-
                                                 
1
 Grammatical cohesion can make relations among sentenc-
es more explicit. There are various grammatically cohesive 
devices (reference, substitution ellipsis and conjunction) 
that tie fragments together in a cohesive way.    
850
known online translators, but find that it is very 
difficult to generate the target transitional ex-
pressions, especially when there is no explicit 
connective word in the source sentence, such as 
generating ?and ? and ?which? in Figure 1. 
Fortunately, the functional relationships be-
tween two neighboring source sub-sentences 
provide us with a good perspective and the inspi-
ration to generate those transitional phrases. Fig-
ure 1 shows that the first and the second Chinese 
sub-sentences form a parallel relation. Thus, 
even though there is no distinct connective word 
at the beginning of the second source sub-
sentence, a good translator is still able to insert or 
generate an ?and? as a connection word to make 
the target translation more cohesive.  
Based on the above analysis, this paper focus-
es on the target grammatical cohesion in SMT to 
make the translation more understandable, espe-
cially for languages with great difference in lin-
guistic structure like Chinese and English. To the 
best of our knowledge, our work is the first at-
tempt to generate target transitional expressions 
for SMT grammatical cohesion by introducing 
the functional relationships of source sentences. 
In this work, we propose two models. One is a 
new translation model that is utilized to generate 
new translation rules combined with the infor-
mation of source functional relationships. The 
other is a generative transfer model that encour-
ages producing transitional phrases during de-
coding. Our experimental results on Chinese-to-
English translation demonstrate that the transla-
tion readability is greatly improved by introduc-
ing the cohesive information. 
The remainder of the paper is organized as 
follows. In Section 2, we describe the functional 
relationships of Chinese compound-complex sen-
tences. In Section 3, we present our models and 
show how to integrate the models into an SMT 
system. Our experimental results are reported in 
Section 4. A survey of related work is conducted 
in Section 5, and we conclude our work and out-
line the future work in Section 6.  
2 Chinese Compound-Complex Sen-
tence Structure 
To acquire the functional relationships of a Chi-
nese compound-complex sentence, Zhou (2004) 
proposed a well-annotated scheme to build the 
Compound-complex Sentence Structure (CSS). 
The structure explicitly shows the minimal se-
mantic spans, called elementary units (eus), and 
also depicts the hierarchical relations among eus. 
There are 11 common types of functional rela-
tionships 2  annotated in the Tsinghua Chinese 
Treebank (Zhou, 2004).  
Under the annotation scheme of the Tsinghua 
Chinese Treebank, the Chinese sentence of ex-
ample in Figure 1 is represented as the tree 
shown in Figure 2. In this example, each sub-
sentence is an eu. eu1 and eu2 are combined with 
a parallel relationship, followed by eu3 with an 
adversative relationship. eu1, eu2, and eu3 form a 
large semantic span3, connected with eu4 by a 
consequence relationship. All of the eus are or-
ganized into various functional relationships and 
finally form a hierarchical tree. 
par llel-[(1,1), (2,2)]
dversative-[(1,2),(3,3)]
consequence-[(1,3),(4,4)]
??  ?? 
??  ?   
??  ?   ?
??    ??   
??  ?  
??? ?
eu1
eu2
eu3
eu4
??  ??      
??  ?  
?? ?? ?
?? ?? 
??     ?
 
Figure 2: The compound-complex sentence 
structure of the Chinese sentence in Figure 1. 
Formally, given a compound-complex sen-
tence structure (CSS), each node in the CSS can 
be represented as a tuple
1 1[( , ),...( , ),..., ( , )]? l l L LR s e s e s e. R represents the 
relationship, which has L children. For each 
child of R , a pair ( , )lls e records its start and end 
eus. For example, adversative-[(1,2), (3,3)] in 
Figure 2 means that two children are controlled 
by the relationship adversative, and the left child 
consists of eu1 and eu2, while the right child con-
tains only eu3.  
CSS has much in common with Rhetorical 
Structure (Mann and Thompson, 1988) in Eng-
lish, which also describe the semantic relation 
between discourse units. But the Rhetorical 
Structure involves much richer relations on the 
document-level, and little corpus is open for 
Chinese.    
In the following, we will describe in detail 
how to utilize such CSS information for model-
ling in SMT.  
                                                 
2 They are parallel, consequence, progressive, alternative, 
causal, purpose, hypothesis, condition, adversative, expla-
nation, and flowing relationships. 
3 A semantic span can include one or more eus. 
851
3 Modelling 
Our purpose is to enhance the grammatical cohe-
sion by exploiting the source CSS information. 
Therefore, theoretically, the conditional probabil-
ity of a target translation es conditioned on the 
source CSS-based tree ft is given by ( | )s tP e f , 
and the final translation se  is obtained with the 
following formula: 
argmax{P( | )} (1)?
S
s s te
e e f
  
    Following Och and Ney (2002), our model is 
framed as a log-linear model: 
 exp ( , )( | ) (2)
exp ( , )
?
??
? ?? ?
s
k k k s t
s t
k k k s t
hP
he
e fe f
e' f
 
 
where ( , )s th e f is a feature with weight? . Then, 
the best translation is: 
 
argmaxexp ( , ) (3)
s
s k k k s th?? ?ee e f
 
Our models make use of CSS with two strate-
gies:  
1) CSS-based translation model: following 
formula (1), we obtain the cohesion information 
by modifying the translation rules with their 
probabilities ( | )s tP e f  based on word align-
ments between the source CSS-tree and the tar-
get string; 
 2) CSS-based transfer model: following 
formula (3), we introduce a transfer score to en-
courage the decoder to generate transitional 
words and phrases; the score is utilized as an ad-
ditional feature ( , )k s th e f  in the log-linear model.  
3.1 CSS-based Translation Model 
For the existing translation models, the entire 
training process is conducted at the lexical or 
syntactic level without grammatically cohesive 
information. As a result, it is difficult to utilize 
such cohesive information during decoding. In-
stead, we reserve the cohesive information in the 
training process by converting the original source 
sentence into tagged-flattened CSS and then per-
form word alignment and extract the translation 
rules from the bilingual flattened source CSS and 
the target string.  
As introduced in Section 2, a CSS consists of 
nodes, and a node can be represented as a tuple
1 1[( , ),...( , ),...,( , )]L Ll lR s e s e s e? . In this represen-
tation, the relationship R is the most important 
factor because different relationships directly 
reflect different cohesive expressions. In addition, 
the children?s positions always play a strong role 
in choosing cohesive expressions because transi-
tional expressions vary for children with differ-
ent positions. For example, when translating the 
last child of a parallel relation, we always use 
word ?and? as the transitional expression seen in 
Figure 3, but we will not use it for the first child 
of a parallel relation. Therefore, in the training 
process we just keep the information of relation-
ships and children?s positions when converting 
Despite    frequent    calls   for   cutting   pollution  ,   and   growing   public   anger   ,
<Parallel  @B>  ??  ??   ??  ?   ??  ??  ?          <Parallel  @E>  ??      ??   ??  ?
parallel
??     ??    ??    ?     ??     ??  ? ??    ??    ??     ?
Despite    frequent    calls   for   cutting   pollution  ,   and   growing   public   anger   ,
(a)
(b)
Original hierarchical rules:
                               [X] ?? |||  and growing [X]
Modified hierarchical rules:
                       <parallel  @E >  [X] ??  |||  and growing [X]
(c)
 
Figure 3: An example of modifying translation rules. @B means the current structure information 
comes from the first child, and @E means from the last child.  
852
the source CSS to a tagged-flattened string. 
 Considering that the absolute position (index 
of the eu, such as 1, 2, 3) is somehow sparse in 
the corpus, we employ the relative position in-
stead. B (Beginning) represents the first child of 
a relationship, E (End) means the last child of a 
relationship, and M (Middle) represents all the 
middle children.  
Under this agreement, the original Chinese 
CSS-based tree will be converted to a new 
tagged-flattened string. Note the converting ex-
ample from Figure 3(a) to Figure 3(b): node par-
allel-[(1,1), (2,2)] (see Figure 2) is converted to 
a flat string. Its first child is represented as <par-
allel, @B> with the semantic span, while the last 
child is <parallel, @E> with the corresponding 
semantic span. 
We then perform word alignment on the modi-
fied bilingual sentences, and extract the new 
translation rules based on the new alignment, as 
shown in Figure 3(b) to Figure 3(c). Now the 
newly extracted rule ?<parallel, @E > [X] ?? 
||| and growing [X] ? is tagged with cohesive in-
formation. Thus, if the similar relationship paral-
lel occurs in the test source sentence, this type of 
rule is more likely to be chosen to generate the 
cohesive word ?and? during decoding because it 
is more discriminating than the original rules ([X] 
?? ||| and growing [X]). The conditional prob-
abilities of the new translation rules are calculat-
ed following (Chiang, 2005). 
3.2 CSS-based Transfer model  
In general, according to formula (3), the transla-
tion quality based on the log-linear model is re-
lated tightly with the features chosen. Most trans-
lation systems adopt the features from a transla-
tion model, a language model, and sometimes a 
reordering model. To give a bonus to generating 
cohesive expressions during decoding, we have 
designed a special additional feature. The addi-
tional feature is represented as a probability cal-
culated by a transfer model. 
Given the source CSS information, we want 
our transfer model to predict the most possible 
cohesive expressions. For example, given two 
semantic spans with a parallel relationship and 
many translation candidates, our transfer model 
is expected to assign higher scores to those with 
transitional expressions such as ?and? or ?as well 
as?. 
Let 
0 1, ,... nw w w?w  represent the transitional 
expressions observed in the target string. Our 
transfer model can be represented as a condition-
al probability: 
( | ) (4)P CSSw  
    By deriving each node of the CSS, we can 
obtain a factored formula: 
,( | ) ( | , ) (5)i j ij i jP CSS P R RP??w w 
where 
ijw
is the transitional expression produced 
by the thj child of the thi node of the CSS. iR is 
the relationship type of the thi node. For the thj
child in the thi  node, 
jRP
is its relative position 
(B, M or E) introduced in Section 3.1.  
    The process of training this transfer model and 
smoothing is similar to the process of training a 
language model. We obtain the factored transfer 
probability as follows, 
1
1
0 0
( | , )
( | , ) ( | , , ) (6)
ij i j
i
n
k
j k
k
i j
P R RP
P w R RP P w w R RP?
?
? ?
w  
where  
 
0 0 ,... (7)nij nw w w? ?w
 
Following (Bilmes and Kirchhoff, 2003), the 
conditional probabilities 10( | , , )ik jkP w w R RP? in 
formula (6) are estimated in the same way as a 
factored language model, which has the ad-
vantage of easily incorporating various linguistic 
information. 
Considering that 
ijw
 commonly appears at the 
beginning of the target translation of a source 
semantic span such as ?which ??, namely, the 
left-frontier phrases, we focus only on the left-
frontier phrases when training this model. Note 
that if there exists a target word before a left 
frontier, and this word is aligned to NULL, we 
will expand the left frontier to this word. The 
expansion process will be repeated until there is 
no such word. For example, if we take the CSS 
and the alignment in Figure 3(a) for training, the 
left frontier of the second child will be expanded 
from ?growing? to ?and?. In addition, taking the 
tri-gram left-frontier phrase for example, we can 
obtain a training sample such as 
ijw
= and grow-
ing public, R=parallel, RP = E. 
By learning such probabilities for different 
transitional expressions conditioned on different 
relationships, we are able to capture the inner 
connection between the source CSS and the pro-
jected target cohesive phrases. Thus, during de-
coding, if we add the probability generated by 
the transfer model of ( | )P CSSw as a feature in 
853
formula (3), it will certainly contribute to select-
ing more cohesive candidates.  
3.3 Elementary-Unit Cohesion Constraint 
As mentioned in Section 3.2, in the transfer 
model, the transitional phrases are expected to 
occur at the left frontier of a projected span on 
target side. In fact, this depends on the assump-
tion that the projected translations of any two 
disjoint source semantic spans are also disjoint to 
keep their own semantic integrity. We call this 
assumption the integrity assumption. This as-
sumption is intuitive and supported by statistics. 
After analyzing 1,007 golden aligned Chinese-
English sentence-pairs, we find that approxi-
mately 90% of the pairs comply with the as-
sumption. However, in real automatically aligned 
noisy data, the ratio of complying pairs reduces 
to 71%4. Two projected translations that violate 
the integrity assumption may mutually overlap, 
which causes our confusion on where to extract 
the transitional phrases. In this case, extracted 
transitional phrases are likely to be wrong. 
    To increase the chance of extracting correct 
transitional phrases, the alignment results must 
be modified to reduce the impact of incorrect 
alignment. We propose a dynamic cleaning 
method to ensure that the most expressive transi-
tional phrases fall in the accessible extraction 
range before training the transfer model. 
3.3.1 EUC and non-EUC 
As we have defined in Section 2, the minimal 
semantic span is called elementary unit (eu). If 
the source eu and its projected target span com-
ply with the integrity assumption, we say that 
such an eu and its projected span have Elemen-
tary-Unit-Cohesion (EUC). We define EUC 
formally as follows. 
Given two elementary units 
Aeu  and Beu , 
and their projected target spans 
Aps and Bps
bound by the word alignment, the alignment 
complies with EUC only if there is no overlap 
between 
Aps  and Bps . Otherwise, the alignment 
is called non-EUC. The common EUC and non-
EUC cases are illustrated in Figure 4. 
EUC is the basic case for the integrity as-
sumption. For the best cases, the elementary 
units comply with EUC, and thus the semantic 
                                                 
4 The aligning tool is GIZA++ with 5 iterations of Model 1, 
5 iterations of HMM, and 10 iterations of Model 4. The 
GIZA++ code can be downloaded from 
https://code.google.com/p/giza-pp/ 
spans combined by elementary units are certainly 
subject to the integrity assumption.  
 
uA euB
psA psB 
(a) mono EUC case 
euA euB
psApsB  
(b) swap EUC case euA euB
psA psB 
(c) non-EUC case 
Figure.4 The schematic diagram of EUC cases 
and non-EUC case.  
3.3.2 A Dynamic Cleaning Method 
An intuitive method to clean the alignment re-
sults is to drop off the noisy word-to-word links 
that cause non-EUC. Considering that the drop-
ping process is a post-editing method for the 
original alignment obtained by a state-of-the-art 
aligner such as GIZA++, we do not expect over-
deleting. Therefore, we tend to take a relatively 
conservative strategy to minimize the deleting 
operation. 
Given a sentence-pair (f, e), suppose that 
0{ ,..., ,..., }i If f f?f  is divided into M elemen-
tary units 
0{ ,..., ,..., }m MU u u u? , and e has N 
words, that is, 
0{ ,..., ,..., }n Ne e e?e . If A  is the 
word alignment of (f, e), then the goal is to con-
struct the maximum subset *A A? under the 
condition that *A  is the word alignment with the 
constraint of EU. The search process can be de-
scribed as the pseudo code in Figure 5. 
In Figure 5, we scan each target word and each 
source eu to assign each word to a unique eu un-
der the EUC constraint with the lowest cost. 
Function cost( , )n m  in line 6 computes the 
counts of deleted links that force the thn target 
word to align only to words in the range of the 
thm eu. For example, if the thn target word is 
aligned to the thi , ( 1)thi ? , and ( 2)thi ? word in 
source side, while the thi word belongs to 
1`mu
 
and the ( 1)thi ?  and ( 2)thi ?  words belong to 
2mu
, then 
1cost( , ) 2mn u ?
, and 
2cost( , ) 1mn u ?
. 
In line 6, Score[n][m] saves a list of scores, each 
score computed by adding the current cost(n, m) 
with the history score of each list of Score[n-1]. 
854
Before the next iteration, the bad branches are 
pruned, as seen in line 5. We adopt the following 
two ways to prune:  
(1) EUC constraint: if the current link violates 
EUC alignment, delete it. 
(2) Keep the hypothesis with a fixed maximum 
size to avoid too large a searching space. 
 
 
 
Figure 5. The pseudo code of dynamic cleaning 
method.  
4 Experiments 
4.1 Experimental Setup 
To obtain the CSSs of Chinese sentences, we use 
the Chinese parser proposed in (Tu et al, 2013a). 
Their parser first segments the compound-
complex sentence into a series of elementary 
units, and then builds structure of the hierarchical 
relationships among these elementary units. 
Their parser was reported to achieve an F-score 
for elementary unit segmentation of approxi-
mately 0.89. The progressive, causal, and condi-
tion terms of functional relationships can be rec-
ognized with precisions of 0.86, 0.8, and 0.75, 
respectively, while others, such as purpose, par-
allel, and flowing, achieve only 0.5, 0.59 and 
0.62, respectively.  
The translation experiments have been con-
ducted in the Chinese-to-English direction. The 
bilingual training data for translation model and 
CSS-based transfer model is FBIS corpus with 
approximately 7.1 million Chinese words and 9.2 
million English words. We obtain the word 
alignment with the grow-diag-final-and strategy 
with GIZA++. Before training the CSS-based 
transfer model, the alignment for transfer model 
is modified by our dynamic cleaning method. 
During the cleaning process, the maximum size 
of hypothesis is limited to 5. A 5-gram language 
model is trained with SRILM5 on the combina-
tion of the Xinhua portion of the English Giga-
word corpus combined with the English part of 
FBIS. For tuning and testing, we use NIST03 
evaluation data as the development set. 
NIST04/05/06, CWMT08-Development 6  and 
CWMT08-Evaluation data are used for testing 
under the measure metric of BLEU-4 (Papineni 
et al 2002) with the shortest length penalty.  
Table 1 shows how the CSS is distributed in 
all testing sets. According to the statistics in Ta-
ble 1, we see that CSS is really widely distribut-
ed in the NIST and CWMT corpora, which im-
plies that the translation quality may benefit sub-
stantially from the CSS information, if it is well 
considered in SMT.  
 
4.2 Extracted Transitional Expressions 
Eleven types of Chinese functional relationships 
and their English left-frontier phrases (tri-gram) 
learned by our transfer model are given in Table 
2.  
The results in Table 2 show that some left-
frontier phrases reflect the source functional rela-
tionship well, especially for those with better 
precision of relationship recognition, such as 
progressive, causal and condition. Conversely, 
lower precision of relationship recognition may 
weaken the learning ability of the transfer model. 
For example, noisy left-frontier phrases are easi-
ly generated under relationships such as parallel 
and purpose. 
                                                 
5 http://www.speech.sri.com/projects/srilm/ 
6 The China Workshop on Machine Translation 
//Pseudo code for dynamic cleaning                             
1: Score [N+1][M]={[0]}N M?          /* initialize  
                                      cumulative cost score chart*/ 
2: Path [M]=[[]]                  /*initialize tracking path*/ 
3: forn = 1 N? :{           /*  scan target words*/ 
4:   for 0 1m M? ? ? :{        /*scan source U set */ 
5:     PrunePath();   
                 /* prune invalid  path and high-cost path*/ 
6:     Score[n][m]=GetScore(Score[n-1], cost(n, m)) 
       /*compute current cumulative cost score by previ-
ous score and current cost*/ 
7:      SaveCurrentPath(Path[m]);  
/*add current index to Path*/ 
8:  }//end m    
9:}//end n  
10: OptimalPath = 
[ ]argmax{ [ ][ ]}Path m Score N m
; 
 
 Total CSS Ratio(%) 
NIST04 1,788 1,307 73.1 
NIST05 1,082 849 78.5 
NIST06 1,000 745 74.5 
CWMT08-Dev. 1,006 818 81.3 
CWMT08-Eval. 1,006 818 81.3 
Table 1. The numbers of sentences and the 
CSS ratios of all sentences. CWMT08-Dev. is 
short for CWMT08 Development data and 
CWMT08-Eval. is CWMT08 Evaluation da-
ta. 
855
 4.3 Results on SMT with Different Strategies 
For this work, we use an in-house decoder to 
build the SMT baseline; it combines the hierar-
chical phrase-based translation model (Chiang, 
2005; Chiang, 2007) with the BTG (Wu, 1996) 
reordering model (Xiong et al, 2006; Zens and 
Ney, 2006; He et al, 2010).  
To test the effectiveness of the proposed mod-
els, we have compared the translation quality of 
different integration strategies. First, we adopted 
only the tagged-flattened rules in the hierarchical 
translation system. Next, we added the log prob-
ability generated by the transfer model as a fea-
ture into the baseline features. The baseline fea-
tures include bi-directional phrase translation 
probabilities, bi-directional lexical translation 
probabilities, the BTG re-ordering features, and 
the language model feature. The tri-gram left-
frontier phrase was adopted in the experiment. 
Then the probability generated by the transfer 
model with EUC constraint is added. Finally, we 
incorporated the tagged-flattened rules and the 
additional transfer model feature together.  
Table 3 shows the results of these different in-
tegrated strategies. In Table 3, almost all BLEU 
scores are improved, no matter what strategy is 
used. In particular, the best performance marked 
in bold is as high as 1.24, 0.94, and 0.82 BLEU 
points, respectively, over the baseline system on 
NIST04, CWMT08 Development, and CWMT08 
Evaluation data. The strategy of ?TFS+ Flat-
tened Rule? is the most stable. Meanwhile the 
?Flattened Rule? achieves better performance 
than ?TFS?. The merits of ?Flattened Rule? are 
two-fold: 1) In training process, the new word 
alignment upon modified sentence pairs can 
align transitional expressions to flattened CSS 
tags; 2) In decoding process, the CSS-based rules 
are more discriminating than the original rules, 
which is more flexible than ?TFS?.  From the 
table, we cannot conclude that the EUC con-
straint will certainly promote translation quality, 
but the transfer model performs better with the 
constraint on most testing sets. 
4.4 Analysis of Different Effects of Different 
N-grams 
As mentioned in Section 4.3, we have noted the 
effectiveness of tri-gram transfer model, which 
means 2n ? in formula (7). In fact, the lengths of 
common transitional expressions vary from one 
word to several words. To evaluate the effects of 
different n-grams for our proposed transfer mod-
el, we compared the uni-/bi-/tri-gram transfer 
models in SMT, and illustrate the results in Fig-
Relation Left-frontier phrases (tri-gram) 
parallel as well as;   at the same; ? 
progressive but will also; in addition to;? 
causal 
therefore , the;   for this reason;   as a 
result; because it is;   so it is;? 
condition as long as;   only when the? 
hypothesis if we do; if it is;  if the us; ? 
alternative regardless of whether;? 
purpose 
it is necessary;  
further promote the ;? 
explanation that is ,;  the first is; first is the;? 
adversative however , the ;  but it is; ? 
flowing this is a; which is an; ? 
consequence so that the; to ensure that? 
Table 2. Chinese functional relations and their 
corresponding English left-frontier phrases 
learned by our transfer model. The noun phrases 
starting with a definite / indefinite word are fil-
tered because they are unlikely to be the transi-
tional phrases. 
 
 
 
NIST04 NIST05 NIST06 
CWMT08?s 
Dev. 
CWMT08?s 
Eval. 
Baseline   33.42   31.99   33.88       26.14       23.88 
+Flattened Rule   34.54**   32.32   34.58**       26.79**       24.70** 
+TFS (without EUC)   33.93**   32.04   34.40*       26.44       24.58** 
+TFS   33.84**   32.63*   34.15       27.08**       24.65** 
+TFS+ Flattened Rule   34.66**   32.54 34.52**       26.87**       24.49** 
       + Flattened Rule: only use the tagged-flattened translation rules 
       + TFS:  only use the transfer model score as an additional feature (based on 3-gramtransitional phrase) 
       + TFS + Flattened Rule: both are used 
       *: value with * means that it is significantly better than the baseline with p<0.05 
       **: value with ** means that it is significantly better than the baseline with p<0.01 
Table 3. BLEU scores of the testing sets with different integrating strategies 
856
ure 6. In this experiment, the CSS-based transla-
tion rules and the CSS-based transfer model are 
both incorporated. Considering time and compu-
ting resources, in the rest of our paper, our analy-
sis is conducted on NIST05 and NIST06.  
We choose 0,1, 2n ?  in this experiment for 
that the common English transitional expressions 
are primarily conjunctions, most of which are 
less than 4 words. Results in Figure 6 show that 
the uni-gram and tri-gram transitional expres-
sions seem more fitting for our transfer model. 
One possible reason is that uni-gram or tri-gram 
conjunctions are more utilized in an English text. 
In a conjunction expression list proposed by 
(Williams, 1983) which summarizes the differ-
ent kinds of conjunctions based on the work of 
Halliday and Hassan (1976), we obtain the statis-
tical results on uni-/bi-/tri-gram expressions, 
which are about 52.1%/16.9%/23.9% respective-
ly. 
 
4.5 Experiments on Big Training Data 
To further evaluate the effectiveness of the pro-
posed models, we also conducted an experiment 
on a larger set of bilingual training data from the 
LDC corpus7 for translation model and transfer 
model. The training corpus contains 2.1M sen-
tence pairs with approximately 27.7M Chinese 
words and 31.9M English words. All the other 
settings were the same as the SMT experiments 
of sub-section 4.3. The final BLEU scores on 
NIST05 and NIST06 are given in Table 4.  
The results in Table 4 further verify the effec-
tiveness of our proposed models. The best per-
formance with bold marking scored as high as 
0.83 and 0.64 BLEU points, respectively over the 
                                                 
7 LDC category number: LDC2000T50, DC2002E18, 
LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27, 
LDC2005T10 and LDC2005T34. 
baseline system on NIST05 and NIST06 evalua-
tion data.  
 
4.6 Translation Examples  
Two SMT examples of Chinese-to-English are 
given in Table 5. We observe that compared to 
the baseline, our approach has obvious ad-
vantages on translating the implicit relations, due   
to generating translational expressions on target 
side. Moreover, with the transitional expressions, 
cohesion of the entire translation improves. No-
tably, the transitional expressions in this work 
like ?including, there are, the core of which? are 
not linguistic conjunctions. We would like to call 
them ?generalized? conjunctions, because they 
tie semantic fragments together, analogously to 
linguistic conjunctions. 
5 Related Work  
Improving cohesion for complex sentences or 
discourse translation has attracted much attention 
in recent years. Such research efforts can be 
roughly divided into two groups: 1) research on 
lexical cohesion, which mainly contributes to the 
selection of generated target words; 2) efforts to 
improve the grammatical cohesion, such as dis-
ambiguation of references and connectives.  
In lexical cohesion work, (Gong et al, 2011; 
Xiao et al, 2011; Wong and Kit, 2012) built dis-
course-based models to ensure lexical cohesion 
or consistency. In (Xiong et al, 2013a), three 
different features were designed to capture the 
lexical cohesion for document-level machine 
translation. (Xiong et al, 2013b) incorporated 
lexical-chain-based models (Morris and Hirst, 
1991) into machine translation. They generated 
the target lexical chains based on the source 
 
Figure 6.  Different translation qualities along 
with different n-grams for transfer model.  
30
31
32
33
34
35
NIST05 NIST06
BLEU 
Testing Set 
Uni-gram
Bi-gram
Tri-gram
 NIST05 NIST06 
Baseline    35.20     35.52 
+Flattened Rule    36.03** 36.10* 
+TFS    35.56* 36.04* 
+TFS +Flattened Rule    36.02**    36.16** 
+ Flattened Rule: only use the tagged-flattened transla-
tion rules 
 + TFS:  only use the transfer model score as an addi-
tional feature (3-gram transitional phrase) 
+ TFS + Flattened Rule: both are used 
*: value with * means that it is significantly better than 
the baseline with p<0.05 
**: value with ** means that it is significantly better 
than the baseline with p<0.01 
Table 4. BLEU scores on the large-scale training 
data.  
857
chains via maximum entropy classifiers, and 
used the target chains to work on the word selec-
tion. 
 Limited work has been conducted on gram-
matical cohesion. (Marcu et al, 2000) designed a 
discourse structure transfer module, but it fo-
cused on converting the semantic structure rather 
than actual translation. (Tu et al, 2013b) provid-
ed a Rhetorical-Structure-Theory-based tree-to-
string translation method for complex sentences 
with explicit relations inspired by (Marcu et al, 
2000), but their models worked only for explicit 
functional relations, and they were concerned 
mainly with the translation integrity of semantic 
span rather than cohesion. (Meyer and Popescu-
Belis, 2012) used sense-labeled discourse con-
nectives for machine translation from English to 
French. They added the labels assigned to con-
nectives as an additional input to an SMT system, 
but their experimental results show that the im-
provements under the evaluation metric of BLEU 
were not significant. (Nagard and Koehn, 2010) 
addresses the problems of reference or anaphora 
resolution inspired by work of Mitkov et al 
(1995). 
To the best of our knowledge, our work is the 
first attempt to exploit the source functional rela-
tionship to generate the target transitional ex-
pressions for grammatical cohesion, and we have 
successfully incorporated the proposed models 
into an SMT system with significant improve-
ment of BLEU metrics. 
6 Conclusion 
In this paper, we focus on capturing cohesion 
information to enhance the grammatical cohesion 
of machine translation. By taking the source CSS 
into consideration, we build bridges to connect 
the source functional relationships in CSS to tar-
get transitional expressions; such a process is 
very similar to human translating. 
    Our contributions can be summarized as: 1) 
the new translation rules are more discriminative 
and sensitive to cohesive information by convert-
ing the source string into a CSS-based tagged-
flattened string; 2) the new additional features 
embedded in the log-linear model can encourage 
the decoder to produce transitional expressions. 
The experimental results show that significant 
improvements have been achieved on various 
test data, meanwhile the translations are more 
cohesive and smooth, which together demon-
strate the effectiveness of our proposed models.  
In the future, we will extend our methods to 
other translation models, such as the syntax-
based model, to study how to further improve the 
performance of SMT systems. Besides, more 
language pairs with various linguistic structures 
will be taken into consideration.  
Acknowledgement 
We would like to thank Jiajun Zhang for provid-
ing the BTG-based hierarchical decoder. The 
research work has been partially funded by the 
Natural Science Foundation of China under 
Grant No. 61333018, the Hi-Tech Research and 
Development Program (?863? Program) of China 
under Grant No. 2012AA011101, and also 
the Key Project of Knowledge Innovation Pro-
gram of Chinese Academy of Sciences under 
Grant No. KGZD-EW-501 as well.  
     
Source ?????????????????? ????????????????? ? ? 
Reference 
In the past three years, the sequencing of three chromosomes has been completed, including 
chromosomes 20 , 21 , and 22 . 
Baseline 
In the past three years , now has three terms of the completion of the chromosomes , 20 , 21 
and 22 . 
Improved 
In the past three years , there are three chromosomes to accomplish , including 20 , 21 and 
22 . 
Source ??????????????????????????????????? 
Reference 
The above-mentioned propositions constitute the basic connotation of this one-china principle 
with safeguarding china ' s sovereignty and territorial integrity as its core . 
Baseline 
The above-mentioned propositions constitute the basic meaning of the one-china principle is 
the core of safeguard china ' s sovereignty and territorial integrity . 
Improved 
The above-mentioned propositions constitute the basic meaning of the one-china principle , 
the core of which is to safeguard china ' s sovereignty and territorial integrity . 
Table 5. Examples of baseline and the improved system outputs. 
 
858
References  
Jeff A. Bilmes and Katrin Kirchhoff. Factored lan-
guage models and generalized parallel backoff. In 
Proceedings of the 2003 Conference of the North 
American Chapter of the Association for Compu-
tational Linguistics on Human Language Technol-
ogy: companion volume of the Proceedings of 
HLT-NAACL 2003--short papers-Volume 2: 4-6. 
David Chiang. 2005. A hierarchical phrase-based 
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 263?
270. 
David Chiang. 2007. Hierarchical phrase-based 
translation. Computational Linguistics, pages 
33(2):201?228. 
Zhengxian Gong, Min Zhang, and Guodong Zhou. 
Cache-based document-level statistical machine 
translation, 2011, Edinburgh, Scotland, UK. In 
Proceedings of the 2011 Conference on Empirical 
Methods in Natural Language Processing, pages 
909?919. 
Liane Guillou. 2013. Analysing lexical consistency in 
translation. In Proceedings of the Workshop on 
Discourse in Machine Translation, pages 10?18, 
Sofia 
Michael A.K. Halliday, Hasan R. Cohesion in English. 
1976. London: Longman. 
Zhongjun He, Yao Meng, and Hao Yu. 2010b. Maxi-
mum Entropy Based Phrase Reordering for Hier-
archical Phrase-based Translation. In Proc. of the 
Conf. on Empirical Methods for Natural Language 
Processing (EMNLP), pages 555?563. 
Annie Louis and Ani Nenkova. 2012. A coherence 
model based on syntactic patterns. In Proceedings 
of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning, pages 1157?
1168, Jeju Island, Korea, July.  
William C Mann and Sandra A Thompson. 1988. 
Rhetorical structure theory: Toward a functional 
theory of text organization. Text, 8(3):243?281. 
Ruslan Mitkov, Sung-Kwon Choi, and Randall Sharp. 
1995. Anaphora resolution in Machine Transla-
tion. In Proceedings of the Sixth International 
Conference on Theoretical and Methodological Is-
sues in Machine Translation. 
Thomas Meyer and Andrei Popescu-Belis. Using 
sense-labeled discourse connectives for statistical 
machine translation, 2012, In Proceedings of the 
Joint Workshop on Exploiting Synergies between 
Information Retrieval and Machine Translation 
(ESIRMT) and Hybrid Approaches to Machine 
Translation (HyTra), pages:129-138. 
Jane Morris and Graeme Hirst. 1991. Lexical cohe-
sion computed by thesaural relations as an indica-
tor of the structure of text. Comput. Linguist., 
17(1):21?48, March. 
Ronan L Nagard and Philipp Koehn. 2010, Aiding 
pronoun translation with co-reference resolution, 
In proceedings of the Joint Fifth Workshop on Sta-
tistical Machine Translation and MetricsMATR, 
pages 252-261. 
Franz J Och and Hermann Ney. 2002. Discriminative 
training and maximum entropy models for statisti-
cal machine translation. In Proc. of ACL, pages 
295?302. 
Kishore Papineni, Salim Roukos, Todd Ward, et al 
2002, BLEU: a method for automatic evaluation 
of machine translation. In proceedings of the 40th 
annual meeting on association for computational 
linguistics. pages: 311-318. 
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni 
Miltsakaki, Livio Robaldo, Aravind Joshi, and 
Bonnie Webber. 2008. The Penn Discourse Tree-
bank 2.0. In Proceedings of the 6th International 
Conference on Language Resources and Evalua-
tion (LREC 2008). 
Williams Ray. Teaching the Recognition of Cohesive 
Ties in Reading a Foreign, 1983. Reading in a 
foreign language, 1(1), pages: 35-52. 
Radu Soricut and Daniel Marcu. 2003. Sentence level 
discourse parsing using syntactic and lexical in-
formation. In Proceedings of the 2003 Conference 
of the North American Chapter of the Association 
for Computational Linguistics on Human Lan-
guage Technology-Volume 1, pages 149?156. 
Mei Tu, Yu Zhou, and Chengqing Zong. 2013a, A 
Novel Translation Framework Based on Rhetori-
cal Structure Theory. In Proceedings of the 51st 
Annual Meeting of the Association for Computa-
tional Linguistics, short paper, Sofia, Bulgaria, 
pages 370?374. 
Mei Tu, Yu Zhou, Chengqing Zong. 2013b, Automat-
ically Parsing Chinese Discourse Based on Maxi-
mum Entropy. In The 2nd Conference on Natural 
Language Processing & Chinese Computing. 
Ashish Vaswani, Liang Huang and David Chiang, 
Huang L, Chiang D. 2012, Smaller alignment 
models for better translations: unsupervised word 
alignment with the l 0-norm. In Proceedings of the 
50th Annual Meeting of the Association for Com-
putational Linguistics: Long Papers-Volume 
1,pages 311-319. 
Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang. 
Document-level consistency verification in ma-
chine translation. September 2011, Xiamen, China. 
In Proceedings of the 2011 MT summit XIII, pag-
es 131?138. 
859
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for 
statistical machine translation. In Proceedings of 
the 44th Annual Meeting of the Association for 
Computational Linguistics, pages 521?528. 
Deyi Xiong, Guosheng Ben, Min Zhang, Yajuan Lv, 
and Qun Liu. 2013 (a). Modeling lexical cohesion 
for document-level machine translation. In Pro-
ceedings of the Twenty-Third International Joint 
Conference on Artificial Intelligence (IJCAI-13), 
Beijing, China, August. 
Deyi Xiong, Ding Yang, Min Zhang and Chew Lim 
Tan, 2013 (b). Lexical Chain Based Cohesion 
Models for Document-Level Statistical Machine 
Translation. In Proceedings of the 2013 Confer-
ence on Empirical Methods in Natural Language 
Processing, pages: 1563-1573. 
Richard Zens and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine 
translation. In Proceedings of theWorkshop on 
Statistical Machine Translation, pages 55?63. 
Qiang Zhou, 2004, Annotation Scheme for Chinese 
Treebank, Journal of Chinese Information Pro-
cessing, 18(4): 1-8. 
 
 
 
 
 
 
860
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 779?784,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
RNN-based Derivation Structure Prediction for SMT
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing Zong
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
{ffzhai, jjzhang, yzhou, cqzong}@nlpr.ia.ac.cn
Abstract
In this paper, we propose a novel deriva-
tion structure prediction (DSP) model
for SMT using recursive neural network
(RNN). Within the model, two steps are
involved: (1) phrase-pair vector represen-
tation, to learn vector representations for
phrase pairs; (2) derivation structure pre-
diction, to generate a bilingual RNN that
aims to distinguish good derivation struc-
tures from bad ones. Final experimental
results show that our DSP model can sig-
nificantly improve the translation quality.
1 Introduction
Derivation structure is important for SMT decod-
ing, especially for the translation model based
on nested structures of languages, such as BTG
(bracket transduction grammar) model (Wu, 1997;
Xiong et al, 2006), hierarchical phrase-based
model (Chiang, 2007), and syntax-based model
(Galley et al, 2006; Marcu et al, 2006; Liu et
al., 2006; Huang et al, 2006; Zhang et al, 2008;
Zhang et al, 2011; Zhai et al, 2013). In general,
derivation structure refers to the tuple that records
the used translation rules and their compositions
during decoding, just as Figure 1 shows.
Intuitively, a good derivation structure usually
yields a good translation, while bad derivations al-
ways result in bad translations. For example in
Figure 1, (a) and (b) are two different derivations
for Chinese sentence ??? ? ?9 ?1 
 ?
!?. Comparing the two derivations, (a) is more
reasonable and yields a better translation. How-
ever, (b) wrongly translates phrase ?? ?9? to
?and Sharon? and combines it with [??;Bush]
incorrectly, leading to a bad translation.
To explore the derivation structure?s potential
on yielding good translations, in this paper, we
propose a novel derivation structure prediction
(DSP) model for SMT decoding.
(a) (b)
??
Bush
??? ??
held a talk
? ??
with Sharon
?? ? ??
held a talk
? ??
with Sharon
??
Bush
?? ? ??
held a talk
? ??with Sharon
??
Bush
Bush and
? ??
Sharon
??
??
Bush
??? ??
held a talk
? ??
and Sharon
? ??
and Sharon
?? ? ??
held a talk
Figure 1: Two different derivation structures of
BTG translation model. In the structure, leaf
nodes denote the used translation rules. For each
node, the first line is the source string, while the
second line is its corresponding translation.
The proposed DSP model is built on recur-
sive neural network (RNN). Within the model,
two steps are involved: (1) phrase-pair vector
representation, to learn vector representations for
phrase pairs; (2) derivation structure prediction,
to build a bilingual RNN that aims to distinguish
good derivation structures from bad ones. Ex-
tensive experiments show that the proposed DSP
model significantly improves the translation qual-
ity, and thus verify the effectiveness of derivation
structure on indicating good translations.
We make the following contributions in this
work:
? We propose a novel RNN-based model to do
derivation structure prediction for SMT de-
coding. To our best knowledge, this is the
first work on this issue in SMT community;
? In current work, RNN has only been verified
to be useful on monolingual structure learn-
ing (Socher et al, 2011a; Socher et al, 2013).
We go a step further, and design a bilingual
RNN to represent the derivation structure;
? To train the RNN-based DSP model, we pro-
pose a max-margin objective that prefers gold
derivations yielded by forced decoding to
n-best derivations generated by the conven-
tional BTG translation model.
779
2 The DSP Model
The basic idea of DSP model is to represent the
derivation structure by RNN (Figure 2). Here, we
build the DSP model for BTG translation model,
which is naturally compatible with RNN. We be-
lieve that the DSP model is also beneficial to other
translation models. We leave them as our future
work.
2.1 Phrase-Pair Vector Representation
Phrase pairs, i.e., the used translation rules, are the
leaf nodes of derivation structure. Hence, to repre-
sent the derivation structure by RNN, we need first
to represent the phrase pairs. To do this, we use
two unsupervised recursive autoencoders (RAE)
(Socher et al, 2011b), one for the source phrase
and the other for the target phrase. We call the unit
of the two RAEs the Leaf Node Network (LNN).
Using n-dimension word embedding, RAE can
learn a n-dimension vector for any phrase. Mean-
while, RAE will build a binary tree for the phrase,
as Figure 2 (in box) shows, and compute a re-
construction error to evaluate the vector. We use
E(T
ph
) to denote the reconstruction error given by
RAE, where ph is the phrase and T
ph
is the corre-
sponding binary tree. In RAE, higher error corre-
sponds to worse vector. More details can be found
in (Socher et al, 2011b).
Given a phrase pair (sp, tp), we can use LNN
to generate two n-dimension vectors, representing
sp and tp respectively. Then, we concatenate the
two vectors directly, and get a vector r ? R
2n
to
represent phrase pair (sp, tp) (shown in Figure
2). The vector r is evaluated by combining the
reconstruction error on both sides:
E(T
sp
, T
tp
) =
1
2
[E(T
sp
) + E(T
tp
) ?
N
s
N
t
]
(1)
where T
sp
and T
tp
are the binary trees for sp and
tp. N
s
and N
t
denote the number of nodes in T
sp
and T
tp
. Note that in order to unify the errors on
the two sides, we use ratio N
s
/N
t
to eliminate the
influence of phrase length.
Then, according to Equation (1), we compute
an LNN score to evaluate the vector of all phrase
pairs, i.e., leaf nodes, in derivation d:
LNN(d) = ?
?
(sp,tp)
E(T
sp
, T
tp
)
(2)
where (sp, tp) is the used phrase pair in derivation
d. Obviously, the derivation with better phrase-
pair representations will get a higher LNN score.
??
? ?? with Sharon
?? ? ?? held a talk
Bush
Figure 2: Illustration of DSP model, based on the
derivation structure in Figure 1(a).
The LNN score will serve as part of the DSP
model for predicting good derivation structures.
2.2 Derivation Structure Prediction
Using the vector representations of phrase pairs,
we then build a Derivation Structure Network
(DSN) for prediction (Figure 2).
In DSN, the derivation structure is repre-
sented by repeatedly applying unit neural net-
work (UNN, Figure 3) at each non-leaf node. The
UNN receives two node vectors r
1
? R
2n
and
r
2
? R
2n
as input, and induces a vector p ? R
2n
to represent the parent node.
r1 r2
p
score
Figure 3: The unit neural network used in DSN.
For example, in Figure 2, node [? ?9; with
Sharon] serves as the first child with vector r
1
,
and node [?1
?!; held a talk] as the second
child with vector r
2
. The parent node vector p,
representing [? ?9 ?1 
 ?!; held a talk
with Sharon], is computed by merging r
1
and r
2
:
p = f(W
UNN
[r
1
; r
2
] + b
UNN
) (3)
where [r
1
; r
2
] ? R
4n?1
is the concatenation of r
1
and r
2
, W
UNN
? R
2n?4n
and b
UNN
? R
2n?1
are
the network?s parameter weight matrix and bias
term respectively. We use tanh(?) as function f .
Then, we compute a local score using a simple
inner product with a row vector W
score
UNN
? R
1?2n
:
s(p) = W
score
UNN
? p (4)
The score measures how well the two child nodes
r
1
and r
2
are merged into the parent node p.
As we all know, in BTG derivations, we have
two different ways to merge translation candi-
dates, monotone or inverted, meaning that we
780
merge two candidates in a monotone or inverted
order. We believe that different merging or-
der (monotone or inverted) needs different UNN.
Hence, we keep two different ones in DSN, one for
monotone order (with parameter W
mono
, b
mono
,
and W
score
mono
), and the other for inverted (with pa-
rameter W
inv
, b
inv
, and W
score
inv
). The idea is that
the merging order of the two candidates will de-
termine which UNN will be used to generate their
parent?s vector and compute the score in Equa-
tion (4). Using a set of gold derivations, we can
train the network so that correct order will receive
a high score by Equation (4) and incorrect one will
receive a low score.
Thus, when we merge the candidates of two ad-
jacent spans during BTG-based decoding, the lo-
cal score in Equation (4) is useful in two aspects:
(1) for the same merging order, it evaluates how
well the two candidates are merged; (2) for the dif-
ferent order, it compares the candidates generated
by monotone order and inverted order.
Further, to assess the entire derivation structure,
we apply UNN to each node recursively, until the
root node. The final score utilized for derivation
structure prediction is the sum of all local scores:
DSN(d) =
?
p
s(p) (5)
where d denotes the derivation structure and p is
the non-leaf node in d. Obviously, by this score,
we can easily assess different derivations. Good
derivations will get higher scores while bad ones
will get lower scores.
Li et al (2013) presented a network to predict
how to merge translation candidates, in monotone
or inverted order. Our DSN differs from Li?s work
in two points. For one thing, DSN can not only
predict how to merge candidates, but also evaluate
whether two candidates should be merged. For an-
other, DSN focuses on the entire derivation struc-
ture, rather than only the two candidates for merg-
ing. Therefore, the translation decoder will pursue
good derivation structures via DSN. Actually, Li?s
work can be easily integrated into our work. We
leave it as our future work.
3 Training
In this section, we present the method of training
the DSP model. The parameters involved in this
process include: word embedding, parameters of
the two unsupervised RAEs in LNN, and parame-
ters in DSN.
3.1 Max-Margin Framework
In DSP model, our goal is to assign higher scores
to gold derivations, and lower scores to bad ones.
To reach this goal, we adopt a max-margin frame-
work (Socher et al, 2010; Socher et al, 2011a;
Socher et al, 2013) for training.
Specifically, suppose we have a training data
like (u
i
,G(u
i
),A(u
i
)), where u
i
is the input
source sentence, G(u
i
) is the gold derivation set
containing all gold derivations of u
i
1
, and A(u
i
)
is the possible derivation set that contains all
possible derivations of u
i
. We want to minimize
the following regularized risk function:
J(?) =
1
N
N
?
i=1
R
i
(?) +
?
2
? ? ?
2
, where
R
i
(?) = max
?
d?A(u
i
)
(
s
(
?, u
i
,
?
d
)
+ ?
(
?
d,G(u
i
)
)
)
? max
d?G(u
i
)
(
s
(
?, u
i
, d
)
)
(6)
Here, ? is the model parameter. s(?, u
i
, d) is the
DSP score for sentence u
i
?s derivation d. It is
computed by summing LNN score (Equation (2))
and DSN score (Equation (5)):
s(?, u, d) = LNN
?
(d) +DSN
?
(d) (7)
?(
?
d,G(u
i
)) is the structure loss margin, which
penalizes derivation
?
d more if it deviates more
from gold derivations. It is formulated as:
?
(
?
d,G(u
i
)
)
=
?
pi?
?
d
?
s
?{pi 6? G(u
i
)}+ ?
t
Dist(y(
?
d), ref)
(8)
The margin includes two parts. For the first part,
pi is the source span in derivation
?
d, ? {?} is an
indicator function. We use the first part to count
the number of source spans in derivation
?
d, but
not in gold derivations. The second part is for
target side. Dist(y(
?
d), ref) computes the edit-
distance between the translation result y(
?
d) de-
fined by derivation
?
d and the reference translation
ref . Obviously, this margin can effectively esti-
mate the difference between derivation
?
d and gold
derivations, both on source side and target side.
Note that ?
s
and ?
t
are only two hyperparameters
for scaling. They are independent of each other,
and we set ?
s
= 0.1 and ?
t
= 0.1 respectively.
1
We investigate the general case here and suppose that
one sentence could have several different gold derivations.In
the experiment, we only use one gold derivation for simple
implementation.
781
3.2 Learning
As the risk function, Equation (6) is not differ-
entiable. We train the model via the subgradient
method (Ratliff et al, 2007; Socher et al, 2013).
For parameter ?, the subgriadient of J(?) is:
?J
??
=
1
N
?
i
?s(?, u
i
,
?
d
m
)
??
?
?s(?, u
i
, d
m
)
??
+??
where
?
d
m
is the derivation with the highest DSP
score, and d
m
denotes the gold derivation with the
highest DSP score. We adopt the diagonal vari-
ant of AdaGrad (Duchi et al, 2011; Socher et al,
2013) to minimize the risk function for training.
3.3 Training Instances Collection
In order to train the model, we need to collect the
gold derivation set G(u
i
) and possible derivation
set A(u
i
) for input sentence u
i
.
For G(u
i
) , we define it by force decoding
derivation (FDD). Basically, FDD refers to the
derivation that produces the exact reference trans-
lation (single reference in our training data). For
example, since ?Bush held a talk with Sharon? is
the reference of test sentence ??? ? ?9 ?
1
?!?, then Figure 1(a) is one of the FDDs.
As FDD can produce reference translation, we be-
lieve that FDD is of high quality, and take them as
gold derivations for training.
For A(u
i
), it should contain all possible deriva-
tions of u
i
. However, it is too difficult to obtain
all derivations. Thus, we use n-best derivations of
SMT decoding to simulate the complete derivation
space, and take them as the derivations in A(u
i
).
4 Integrating the DSP Model into SMT
To integrate the DSP model into decoding, we take
it (named DSP feature) as one of the features in the
log-linear framework of SMT. During decoding,
the DSP feature is distributed to each node in the
derivation structure. For the leaf node, the score
in Equation (2), i.e., LNN score, serves as the fea-
ture. For the non-leaf node, Equation (4) plays
the role. In order to give positive feature value to
the log-linear framework (for logarithm), we nor-
malize the DSP scores to [0,1] during decoding.
Due to the length limit, we ignore the specific nor-
malization methods here. We just preform some
simple transformations (such as adding a constant,
computing reciprocal), and convert the scores pro-
portionally to [0,1] at last.
5 Experiments
5.1 Experimental Setup
To verify the effectiveness of our DSP model, we
perform experiments on Chinese-to-English trans-
lation. The training data contains about 2.1M sen-
tence pairs with about 27.7M Chinese words and
31.9M English words
2
. We train a 5-gram lan-
guage model by the Xinhua portion of Gigaword
corpus and the English part of the training data.
We obtain word alignment by GIZA++, and adopt
the grow-diag-final-and strategy to generate the
symmetric alignment. We use NIST MT 2003 data
as the development set, and NIST MT04-08
3
as
the test set. We use MERT (Och, 2004) to tune pa-
rameters. The translation quality is evaluated by
case-insensitive BLEU-4 (Papineni et al, 2002).
The statistical significance test is performed by
the re-sampling approach (Koehn, 2004). The
baseline system is our in-house BTG system (Wu,
1997; Xiong et al, 2006; Zhang and Zong, 2009).
To train the DSP model, we first use Word2Vec
4
toolkit to pre-train the word embedding on large-
scale monolingual data. The used monolingual
data contains about 1.06B words for Chinese and
1.12B words for English. The dimensionality of
our vectors is 50. The detiled training process is
as follows:
(1) Using the BTG system to perform force de-
coding on FBIS part of the bilingual training data
5
,
and collect the sentences succeeded in force de-
coding (86,902 sentences in total)
6
. We then col-
lect the corresponding force decoding derivations
as gold derivations. Here, we only use the best
force decoding derivation for simple implementa-
tion. In future, we will try to use multiple force
decoding derivations for training.
(2) Collecting the bilingual phrases in the leaf
nodes of gold derivations. We train LNN by these
phrases via L-BFGS algorithm. Finally, we get
351,448 source phrases to train the source side
RAE and 370,948 target phrases to train the tar-
get side RAE.
2
LDC category number : LDC2000T50, LDC2002E18,
LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27,
LDC2005T10 and LDC2005T34.
3
For MT06 and MT08, we only use the part of news data.
4
https://code.google.com/p/word2vec/
5
Here we only use the high quality corpus FBIS to guar-
antee the quality of force decoding derivation.
6
Many sentence pairs fail in forced decoding due to many
reasons, such as reordering limit, noisy alignment, and phrase
length limit (Yu et al, 2013).
782
(3) Decoding the 86902 sentences by the BTG
system to get n-best translations and correspond-
ing derivations. The n-best derivations are used to
simulate the entire derivation space. We retain at
most 200-best derivations for each sentence.
(4) Leveraging force decoding derivations and
n-best derivations to train the DSP model. Note
that all parameters, including word embedding and
parameters in LNN and DSN, are tuned together in
this step. It takes about 15 hours to train the entire
network using a 16-core, 2.9 GHz Xeon machine.
5.2 Experimental Results
We compare baseline BTG system and the DSP-
augmented BTG system in this section. The final
translation results are shown in Table 1.
After integrating the DSP model into BTG sys-
tem, we get significant improvement on all test
sets, about 1.0 BLEU points over BTG system on
average. This comparison strongly demonstrates
that our DSP model is useful and will be a good
complement to current translation models.
Systems
BLEU(%)
MT04 MT05 MT06 MT08 Aver
BTG 36.91 34.69 33.83 27.17 33.15
BTG+DSP 37.41 35.77 35.08 28.42 34.17
Table 1: Final translation results. Bold numbers
denote that the result is significantly better than
baseline BTG system (p < 0.05). Column ?Aver?
gives the average BLEU points of the 4 test sets.
To have a better intuition for the effectiveness
of our DSP model, we give a case study in Figure
4. It depicts two derivations built by BTG system
and BTG+DSP system respectively.
From Figure 4(b), we can see that BTG system
yields a bad translation due to the bad derivation
structure. In the figure, BTG system makes three
mistakes. It attaches candidates [??; achieve-
ments], [? ? ; has reached] and [#\?;
singapore] to the big candidate [?UTransactions of the Association for Computational Linguistics, 1 (2013) 243?254. Action Editor: Philipp Koehn.
Submitted 12/2012; Revised 3/2013; Published 5/2013. c?2013 Association for Computational Linguistics.
Unsupervised Tree Induction for Tree-based Translation 
 
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing Zong 
National Laboratory of Pattern Recognition, Institute of Automation,  
Chinese Academy of Sciences, Beijing, China 
{ffzhai,jjzhang,yzhou,cqzong}@nlpr.ia.ac.cn 
  
 
 
 
 
Abstract 
In current research, most tree-based translation 
models are built directly from parse trees. In 
this study, we go in another direction and build 
a translation model with an unsupervised tree 
structure derived from a novel non-parametric 
Bayesian model. In the model, we utilize 
synchronous tree substitution grammars (STSG) 
to capture the bilingual mapping between 
language pairs. To train the model efficiently, 
we develop a Gibbs sampler with three novel 
Gibbs operators. The sampler is capable of 
exploring the infinite space of tree structures by 
performing local changes on the tree nodes. 
Experimental results show that the string-to-
tree translation system using our Bayesian tree 
structures significantly outperforms the strong 
baseline string-to-tree system using parse trees. 
1 Introduction 
In recent years, tree-based translation models1 are 
drawing more and more attention in the 
community of statistical machine translation 
(SMT). Due to their remarkable ability to 
incorporate context structure information and long 
distance reordering into the translation process, 
tree-based translation models have shown 
promising progress in improving translation 
quality (Liu et al, 2006, 2009; Quirk et al, 2005; 
Galley et al, 2004, 2006; Marcu et al, 2006; Shen 
et al, 2008; Zhang et al, 2011b). 
However, tree-based translation models always 
suffer from two major challenges: 1) They are 
usually built directly from parse trees, which are 
generated by supervised linguistic parsers. 
                                                          
1 A tree-based translation model is defined as a model 
using tree structures on one side or both sides. 
However, for many language pairs, it is difficult to 
acquire such corresponding linguistic parsers due 
to the lack of Tree-bank resources for training. 2) 
Parse trees are actually only used to model and 
explain the monolingual structure, rather than the 
bilingual mapping between language pairs. This 
indicates that parse trees are usually not the 
optimal choice for training tree-based translation 
models (Wang et al, 2010). 
Based on the above analysis, we can conclude 
that the tree structure that is independent from 
Tree-bank resources and simultaneously considers 
the bilingual mapping inside the bilingual sentence 
pairs would be a good choice for building tree-
based translation models. 
Therefore, complying with the above conditions, 
we propose an unsupervised tree structure for tree-
based translation models in this study. In the 
structures, tree nodes are labeled by combining the 
word classes of their boundary words rather than 
by syntactic labels, such as NP, VP. Furthermore, 
using these node labels, we design a generative 
Bayesian model to infer the final tree structure 
based on synchronous tree substitution grammars 
(STSG) 2 . STSG is derived from the word 
alignments and thus can grasp the bilingual 
mapping effectively. 
Training the Bayesian model is difficult due to 
the exponential space of possible tree structures for 
each training instance. We therefore develop an 
efficient Gibbs sampler with three novel Gibbs 
operators for training. The sampler is capable of 
exploring the infinite space of tree structures by 
performing local changes on the tree nodes. 
                                                          
2 We believe it is possible to design a model to infer the 
node label and tree structure jointly. We plan this as 
future work, and here, we focus only on inferring the 
tree structure in terms of the node labels derived from 
word classes. 
243
The tree structure formed in this way is 
independent from the Tree-bank resources and 
simultaneously exploits the bilingual mapping 
effectively. Experiments show that the proposed 
unsupervised tree (U-tree) is more effective and 
reasonable for tree-based translation than the parse 
tree. 
The main contributions of this study are as 
follows: 
1) Instead of the parse tree, we propose a 
Bayesian model to induce a U-tree for tree-
based translation. The U-tree exploits the 
bilingual mapping effectively and does not 
rely on any Tree-bank resources. 
2) We design a Gibbs sampler with three novel 
Gibbs operators to train the Bayesian model 
efficiently. 
The remainder of the paper is organized as 
follows. Section 2 introduces the related work. 
Section 3 describes the STSG generation process, 
and Section 4 depicts the adopted Bayesian model. 
Section 5 describes the Gibbs sampling algorithm 
and Gibbs operators. In Section 6, we analyze the 
achieved U-trees and evaluate their effectiveness. 
Finally, we conclude the paper in Section 7. 
2 Related Work 
In this study, we move in a new direction to build a 
tree-based translation model with effective 
unsupervised U-tree structures. 
For unsupervised tree structure induction, 
DeNero and Uszkoreit (2011) adopted a parallel 
parsing model to induce unlabeled trees of source 
sentences for syntactic pre-reordering. Our 
previous work (Zhai et al, 2012) designed an EM-
based method to construct unsupervised trees for 
tree-based translation models. This work differs 
from the above work in that we design a novel 
Bayesian model to induce unsupervised U-trees, 
and prior knowledge can be encoded into the 
model more freely and effectively. 
Blunsom et al (2008, 2009, 2010) utilized 
Bayesian methods to learn synchronous context 
free grammars (SCFG) from a parallel corpus. The 
obtained SCFG is further used in a phrase-based 
and hierarchical phrase-based system (Chiang, 
2007). Levenberg et al (2012) employed a 
Bayesian method to learn discontinuous SCFG 
rules. This study differs from their work because 
we concentrate on constructing tree structures for 
tree-based translation models. Our U-trees are 
learned based on STSG, which is more appropriate 
for tree-based translation models than SCFG. 
Burkett and Klein (2008) and Burkett et al 
(2010) focused on joint parsing and alignment. 
They utilized the bilingual Tree-bank to train a 
joint model for both parsing and word alignment. 
Cohn and Blunsom (2009) adopted a Bayesian 
method to infer an STSG by exploring the space of 
alignments based on parse trees. Liu et al (2012) 
re-trained the linguistic parsers bilingually based 
on word alignment. Burkett and Klein (2012) 
utilized a transformation-based method to learn a 
sequence of monolingual tree transformations for 
translation. Compared to their work, we do not rely 
on any Tree-bank resources and focus on 
generating effective unsupervised tree structures 
for tree-based translation models. 
Zollmann and Venugopal (2006) substituted the 
non-terminal X in hierarchical phrase-based model 
by extended syntactic categories. Zollmann and 
Vogel (2011) further labeled the SCFG rules with 
POS tags and unsupervised word classes. Our work 
differs from theirs in that we present a Bayesian 
model to learn effective STSG translation rules and 
U-tree structures for tree-based translation models, 
rather than designing a labeling strategy for 
translation rules. 
3 The STSG Generation Process 
In this work, we induce effective U-trees for the 
string-to-tree translation model, which is based on 
a synchronous tree substitution grammar (STSG) 
between source strings and target tree fragments. 
We take STSG as the generation grammar to match 
the translation model. Typically, such an STSG3 is 
a 5-tuple as follows: 
( , , , , )s t t tG N S P ? ?  
where: 
i s?  and t?  represent the set of source and 
target words, respectively, 
i tN  is the set of target non-terminals, 
i t tS N?  is the start root non-terminal, and 
i P  is the production rule set. 
                                                          
3 Generally, an STSG involves tree fragments on both 
sides. Here we only consider the special case where the 
source side is actually a string. 
244
Apart from the start non-terminal tS , we define 
all the other non-terminals in tN  by word classes. 
Inspired by (Zollmann and Vogel, 2011), we 
divide these non-terminals into three categories: 
one-word, two-word and multi-word non-terminals. 
The one-word non-terminal is a word class, such as 
C, meaning that it dominates a word whose word 
class is C. Two-word non-terminals are used to 
stand for two word strings. They are labeled in the 
form of C1+C2, where C1 and C2 are the word 
classes of the two words separately. Accordingly, 
multi-word non-terminals represent the strings 
containing more than two words. They are labeled 
as C1?Cn, demanding that the word classes of the 
leftmost word and the rightmost word are C1 and 
Cn, respectively. 
We use POS tag to play the role of word class4. 
For example, the head node of the rule in Figure 1 
is a multi-word non-terminal PRP?RB. It requires 
that the POS tags of the leftmost and rightmost 
word must be PRP and RB, respectively. Xiong et 
al. (2006) showed that the boundary word is an 
effective indicator for phrase reordering. Thus, we 
believe that combining the word class of boundary 
words can denote the whole phrase well. 
PRP...RB
we
PRP
VBP:x0 RB:x1
VBP+RB
??   x1   x0
wo-men
 
Figure 1. An example of an STSG production rule. 
Each production rule in P  consists of a source 
string and a target tree fragment. In the target tree 
fragment, each internal node is labeled with a non-
terminal in tN , and each leaf node is labeled with 
either a target word in t?  or a non-terminal in tN . 
The source string in a production rule comprises 
source words and variables. Each variable 
corresponds to a leaf non-terminal in the target tree 
fragment. In the STSG, the production rule is used 
to rewrite the root node into a string and a tree 
fragment. For example, in Figure 1, the rule 
rewrites the head node PRP?RB into the 
corresponding string and fragment. 
An STSG derivation refers to the process of 
generating a specific source string and target tree 
                                                          
4 The demand of a POS tagger impairs the independence 
from manual resources to some extent. In future, we 
plan to design a method to learn effective unsupervised 
labels for the non-terminals. 
structure by production rules. This process begins 
with the start non-terminal tS  and an empty source 
string. We repeatedly choose production rules to 
rewrite the leaf non-terminals and expand the 
string until no leaf non-terminal is left. Finally, we 
acquire a source string and a target tree structure 
defined by the derivation. The probability of a 
derivation is given as follows: 
  
1
( ) ( | )
n
i i
i
p d p r N
 
 ?  (1) 
where the derivation comprises a sequence of rules 
d=(r1,?,rn), and Ni represents the root node of rule 
ri. Hence, for a specific bilingual sentence pair, we 
can generate the best target-side tree structure 
based on the STSG, independent from the Tree-
bank resources. The STSG used in the above 
process is learned by the Bayesian model that is 
detailed in the next section. 
Actually, SCFG can also be used to build the U-
trees. We do not use SCFG because most of the 
tree-based models are based on STSG. In our 
Bayesian model, the U-trees are optimized through 
selecting a set of STSG rules. These STSG rules 
are consistent with the translation rules used in the 
tree-based models. 
Another reason is that STSG has a stronger 
expressive power on tree construction than SCFG. 
In a STSG-based U-tree or a STSG rule, although 
not linguistically informed, the nodes labeled by 
POS tags are also effective on distinguishing 
different ones. However, with SCFG, we have to 
discard all the internal nodes (i.e., flattening the U-
trees or rules) to express the same sequence, 
leading to a poor ability of distinguishing different 
U-trees and production rules. Thus, using STSG, 
we can build more specific U-trees for translation.  
In addition, we find that the Bayesian SCFG 
grammar cannot even significantly outperform the 
heuristic SCFG grammar (Blunsom et al 2009)5. 
This would indicate that the SCFG-based 
derivation tree as by-product is also not such good 
for tree-based translation models. Considering the 
above reasons, we believe that the STSG-based 
learning procedure would result in a better 
translation grammar for tree-based models. 
                                                          
5 In (Blunsom et al, 2009), for Chinese-to-English 
translation, the Bayesian SCFG grammar only 
outperform the heuristic SCFG grammar by 0.1 BLEU 
points on NIST MT 2004 and 0.6 BLEU points on NIST 
MT 2005 in the NEWS domain. 
245
4 Bayesian Model 
In this section, we present a Bayesian model to 
learn STSG defined in section 3. In the model, we 
use ?N to denote the probability distribution 
( | )p r N  in Equation (1). ?N follows a multinomial 
distribution and we impose a Dirichlet prior (DP) 
on it: 
  
0 0
| ~ ( )
| , ~ ( , ( | ) )
N
N N N
r N Multi
P DP P N
T
T D D <  (2) 
where 0 ( | )P N<  (base distribution) is used to assign 
prior probabilities to the STSG production rules. ?N 
controls the model?s tendency to either reuse 
existing rules or create new ones using the base 
distribution 0 ( | )P N< . 
Instead of denoting the multinomial distribution 
explicitly with a specific ?N, we integrate over all 
possible values of ?N to achieve the probabilities of 
rules. This integration results in the following 
conditional probability for rule ri given the 
previously observed rules r-i = r1 ,?, ri-1: 
 
0
0
( | )
( | , , , ) i
i
r N ii
i N i
N N
n P r N
p r r N P
n
DD D




   (3) 
Where n-i ri  denotes the number of ri in ir , and n
-i 
N  
represents the total count of rules rewriting non-
terminal N in ir . Thanks to the exchangeability of 
the model, all permutations of the rules are actually 
equiprobable. This means that we can compute the 
probability of each rule based on the previous and 
subsequent rules (i.e. consider each rule as the last 
one). This characteristic allows us to design an 
efficient Gibbs sampling algorithm to train the 
Bayesian model. 
4.1  Base Distribution 
The base distribution 0 ( | )P r N  is designed to 
assign prior probabilities to the STSG production 
rules. Because each rule r consists of a target tree 
fragment frag and a source string str in the model, 
we follow Cohn and Blunsom (2009) and 
decompose the prior probability 0 ( | )P r N  into two 
factors as follows: 
  0 ( | ) ( | ) ( | )P r N P frag N P str frag ?  (4) 
where ( | )P frag N  is the probability of 
producing the target tree fragment frag. To 
generate frag, Cohn and Blunsom (2009) used a 
geometric prior to decide how many child nodes to 
assign each node. Differently, we require that each 
multi-word non-terminal node must have two child 
nodes. This is because the binary structure has 
been verified to be very effective for tree-based 
translation (Wang et al, 2007; Zhang et al, 2011a).  
The generation process starts at root node N. At 
first, root node N is expanded into two child nodes. 
Then, each newly generated node will be checked 
to expand into two new child nodes with 
probability pexpand. This process repeats until all the 
new non-terminal nodes are checked. Obviously, 
pexpand controls the scale of tree fragments, where a 
large pexpand corresponds to large fragments
6. The 
new terminal nodes (words) are drawn uniformly 
from the target-side vocabulary, and the non-
terminal nodes are created by asking two questions 
as follows: 
1) What type is the node, one-word, two-
word or multi-word non-terminal? 
2) What tag is used to label the node? 
The answer to question 1) is chosen from a 
uniform distribution, i.e., the probability is 1/3 for 
each type of non-terminal. The entire generation 
process is in a top-down manner, i.e., generating a 
parent node first and then its children. 
With respect to question 2), because the father 
node has determined the POS tags of boundary 
words, we only need one POS tag to generate the 
label of the current node. For example, in Figure 1, 
as the father node PRP?RB demands that the POS 
tag of the rightmost word is RB, the right child of 
PRP?RB must also satisfy this condition. 
Therefore, we choose a POS tag VBP and obtain 
the label VBP+RB. The POS tag is drawn 
uniformly from the POS tag set. If the current node 
is a one-word non-terminal, question 2) is 
unnecessary. Similarly, with respect to the two-
word non-terminal node, questions 1) and 2) are 
both unnecessary for its two child nodes because 
they have already been defined by their father node. 
As an example of the generative process, the 
tree fragment in Figure 1 is created as follows: 
a. Determine that the left child of PRP?RB is 
a one-word non-terminal (labeled with PRP); 
b. Expand PRP and generate the word ?we? for 
PRP; 
                                                          
6 In our experiment, we set pexpand to 1/3 to encourage 
small tree fragments.  
246
c. Determine that the right child of PRP?RB is 
a two-word non-terminal; 
d. Utilize the predetermined RB and a POS tag 
VBP to form the tag of the two-word non-
terminal: VBP+RB; 
e. Expand VBP+RB (to VBP and RB); 
f. Do not expand VBP and RB. 
( | )P str frag  in Equation (4) is the probability of 
generating the source string, which contains 
several source words and variables. Inspired by 
(Blunsom et al, 2009) and (Cohn and Blunsom, 
2009), we define ( | )P str frag  as follows: 
 
var
1
1 1
( | ) ( ;1)
| |
poisson sw
sw
sw
c
c
s i
P str frag P c
c i 
 u u? ?  (5) 
where csw is the number of words in the source 
string. ?s means the source vocabulary set. Further, 
cvar denotes the number of variables, which is 
determined by the tree fragment frag. 
As shown in Equation(5), we first determine 
how many source words to generate using a 
Poisson distribution Ppoisson(csw;1), which imposes a 
stable preference for short source strings. Then, we 
draw each source word from a uniform distribution 
over ?s. Afterwards, we insert the variables into 
the string. The variables are inserted one at a time 
using a uniform distribution over the possible 
positions. This factor discourages more variables.  
For the example rule in Figure 1, the generative 
process of the source string is: 
a. Decide to generate one source word;  
b. Generate the source word ??? (wo-men) ?;  
c. Insert the first variable after the word;  
d. Insert the second variable between the word 
and the first variable. 
Intuitively, a good translation grammar should 
carry both small translation rules with enough 
generality and large rules with enough context 
information. DeNero and Klein (2007) proposed 
this statement, and Cohn and Blunsom (2009) has 
verified it in their experiments with parse trees. 
Our base distribution is also designed based on 
this intuition. Considering the two factors in our 
base distribution, we penalize both large target tree 
fragments with many nodes and long source strings 
with many words and variables. The Bayesian 
model tends to select both small and frequent 
STSG production rules to construct the U-trees. 
With these types of trees, we can extract small 
rules with good generality and simultaneously 
obtain large rules with enough context information 
by composition. We will show the effectiveness of 
our U-trees in the verification experiment. 
5 Model Training by Gibbs Sampling 
In this section, we introduce a collapsed Gibbs 
sampler, which enables us to train the Bayesian 
model efficiently. 
5.1 Initialization State 
At first, we use random binary trees to initialize the 
sampler. To get the initial U-trees, we recursively 
and randomly segment a sentence into two parts 
and simultaneously create a tree node to dominate 
each part. The created tree nodes are labeled by the 
non-terminals described in section 3. 
Using the initial target U-trees, source sentences 
and word alignment, we extract minimal GHKM 
translation rules7 in terms of frontier nodes (Galley 
et al, 2004). Frontier nodes are the tree nodes that 
can map onto contiguous substrings on the source 
side via word alignment. For example, the bold 
italic nodes with shadows in Figure 2 are frontier 
nodes. In addition, it should be noted that the word 
alignment is fixed8, and we only explore the entire 
space of tree structures in our sampler. Differently, 
Cohn and Blunsom (2009) designed a sampler to 
infer an STSG by fixing the tree structure and 
exploring the space of alignment. We believe that 
it is possible to investigate the space of both tree 
structure and alignment simultaneously. This 
subject will be one of our future work topics. 
For each training instance (a pair of source 
sentence and target U-tree structure), the extracted 
GHKM minimal translation rules compose a 
unique STSG derivation9. Moreover, all the rules 
developed from the training data constitute an 
initial STSG for the Gibbs sampler. 
                                                          
7 We attach the unaligned word to the lowest frontier 
node that can cover it in terms of word alignment. 
8 The sampler might reinforce the frequent alignment 
errors (AE), which would harm the translation model 
(TM). Actually, the frequent AEs also greatly impair the 
conventional TM. Besides, our sampler encourages the 
correct alignments and simultaneously discourages the 
infrequent AEs. Thus, compared with the conventional 
TMs, we believe that our final TM would not be worse 
due to AEs. Our final experiments verify this point and 
we will conduct a much detailed analysis in future. 
9 We only use the minimal GHKM rules (Galley et al, 
2004) here to reduce the complexity of the sampler. 
247
jin-tian jian-mianwo-men zai-ci
PRP+VBP
today
NN
we
PRP
meet
VBP
again
RB
?? ?? ?? ??
PRP...RB
NN...RB
 
Figure 2. Illustration of an initial U-tree structure. The 
bold italic nodes with shadows are frontier nodes. 
Under this initial STSG, the sampler modifies 
the initial U-trees (initial sample) to create a series 
of new ones (new samples) by the Gibbs operators. 
Consequently, new STSGs are created based on the 
new U-trees simultaneously and used for the next 
sampling operation. Repeatedly and after a number 
of iterations, we can obtain the final U-trees for 
building translation models. 
5.2 The Gibbs Operators 
In this section, we develop three novel Gibbs 
operators for the sampler. They explore the entire 
space of the U-tree structures by performing local 
changes on the tree nodes. 
For a U-tree of a given sentence, we define s-
node as the non-root node covering at least two 
words. Thus, the set of s-node contains all the tree 
nodes except the root node, the pre-terminal nodes 
and leaf nodes, which we call non-s-node. For 
example, in Figure 2, PRB?RB and PRP+VBP are 
s-nodes, while NN and NN?RB are non-s-nodes. 
Since the POS tag sequence of the sentence is 
fixed, all non-s-nodes would stay unchanged in all 
possible U-trees of the sentence. Based on this fact, 
our Gibbs operators work only on s-nodes. 
Further, we assign 3 descendant candidates (DC) 
for each s-node: its left child, right child and its 
sibling. For example, in Figure 3, the 3 DCs for the 
s-node are node PRP, VBP and RB respectively. 
According to the different DCs it governs, every s-
node might be in one of the two different states: 
1) Left state: as Figure 3(a) shows, the s-node 
governs the left two DCs, PRP and VBP, 
and is labeled PRP+VBP. 
2) Right state: as Figure 3(b) shows, the s-node 
governs the right two DCs, VBP and RB, and 
is labeled VBP+RB. 
For a specific U-tree, the states of s-nodes are fixed. 
Thus, by changing an s-node?s state, we can easily 
transform this U-tree to another one, i.e., from the 
current sample to a new one. 
To formulate the U-tree transformation process, 
we associate a binary variable ??{0,1} with each 
s-node, indicating whether the s-node is in the left 
?  or right state ?  Then we can change 
the U-tree by changing value of the ? parameters. 
Our first Gibbs operator, Rotate, just works by 
sampling value of the ?parameters, one at a time, 
and changing the U-tree accordingly. For example, 
in Figure 3(a), the s-node is currently in the left 
VWDWH? :HVDPSOHWKH?RIWKLVQRGHDQGLI
WKHVDPSOHGYDOXHRI?LVZHNHHSWKHVWUXFWXUH
unchanged, i.e., in the left state. Otherwise, we 
change its state to the right state ? , and 
transform the U-tree to Figure 3(b) accordingly. 
jian-mianwo-men zai-ci
s-node
we
PRP
meet
VBP
again
RB
?? ?? ??
PRP...RB
PRP+VBP
jian-mianwo-men zai-ci
s-node
we
PRP
meet
VBP
again
RB
?? ?? ??
PRP...RB
VBP+RB
(b) ?=1(a) ?=0
Rotate
 
Figure 3. Illustration of the Rotate operator. In the 
figure, (a) and (b) denote the s-node?s left state and right 
state respectively. The bold italic nodes with shadows in 
the figure are frontier nodes. 
Obviously, towards an s-node for sampling, the 
two values of ? would define two different U-trees. 
Using the GHKM algorithm (Galley et al 2004), 
we can get two different STSG derivations from 
the two U-trees based on the fixed word alignment. 
Each derivation carries a set of STSG rules (i.e., 
minimal GHKM translation rules) of its own. In 
the two derivations, the STSG rules defined by the 
two states include the one rooted at the s-node?s 
lowest ancestor frontier node, and the one rooted at 
the s-node if it is a frontier node. For instance, in 
Figure 3(a), as the s-node is not a frontier node, the 
left state (? ) defines only one rule: 
 
0 2 1
0 1 2
:
... ( ( : : ) : )
leftr x x x
PRP RB PRP VBP x PRP x VBP x RB
o
  
Differently, in Figure 3(b), the s-node is a 
frontier node and thus the right state (? 1) defines 
two rules: 
248
 
0 0 1 0 1
1 1 0 0 1
: ... ( : : )
: ( : : )
right
right
r x x PRP RB x PRP x VBP RB
r x x VBP RB x VBP x RB


o 
o   
Using these STSG rules, the two derivations are 
evaluated as follows (We use the value of ? to 
denote the corresponding STSG derivation): 
0 1
0 1 0
( 0) ( | )
( 1) ( , | )
( | ) ( | , )
left
right right
right right right
p p r r
p p r r r
p r r p r r r


 
 
  
<  v
<  v
 
 
Where r  refers to the conditional context, i.e., the 
set of all other rules in the training data. All the 
probabilities in the above formulas are computed 
by Equation(3). We then normalize the two scores 
and sample a value of ? based on them. With the 
Bayesian model described in section 4, the sampler 
ZLOOSUHIHUWKH?WKDWSURGXFHVVPDOODQGIUHTXHQW
STSG rules. This tendency results in more frontier 
nodes in the U-tree (i.e., the s-node tends to be in 
the state that is a frontier node), which will factor 
the training instance into more small STSG rules. 
In this way, the overall likelihood of the bilingual 
data is improved by the sampler. 
Theoretically, the Rotate operator is capable of 
arriving at any possible U-tree from the initial U-
tree. This is because we can first convert the initial 
U-tree to a left branch tree by the Rotate operator, 
and then transform it to any other U-tree. However, 
it may take a long time to do so. Thus, to speed up 
the structure transformation process, we employ a 
Two-level-Rotate operator, which takes a pair of s-
nodes in a parent-child relationship as a unit for 
sampling. Similar to the Rotate operator, we also 
assign a binary variable ??{0,1} to each unit and 
update the U-tree by sampling the value of ?. The 
method of sampling ? is similar to the one used for 
?. Figure 4 shows an example of the operator. As 
shown in Figure 4(a), the unit NN?VBP and 
PRP+VBP is in the left state (?=0), and governs 
the left three descendants: NN, PRP, and VBP. By 
the Two-level-Rotate operator, we can convert the 
unit to Figure 4(b), i.e., the ULJKWVWDWH?=1). Just as 
Figure 4(b) shows, the governed descendants of the 
unit are turned to PRP, VBP, and RB. 
It may be confusing when choosing the parent-
child s-node pair for sampling because the parent 
node always faces two choices: combining the left 
child or right child for sampling. To avoid 
confusion, we split the Two-level-Rotate operator 
into two operators: Two-level-left-Rotate operator, 
which works with the parent node and its left child, 
and Two-level-right-Rotate operator, which only 
considers the parent node and its right child 10 . 
Therefore, the operator used in Figure 4 is a Two-
level-right-Rotate operator. 
jin-tian jian-mianwo-men zai-ci
PRP+VBP
Today
NN
we
PRP
meet
VBP
again
RB
?? ?? ?? ??
NN...VBP
NN...RB
jin-tian jian-mianwo-men zai-ci
VBP+RB
Today
NN
we
PRP
meet
VBP
again
RB
?? ?? ?? ??
PRP...RB
NN...RB
(a) ?=0 (b) ?=1
Two-level-right-Rotate
 
Figure 4. Illustration of the Two-level-Rotate operator. 
The bold italic nodes with shadows in the Figure are 
frontier nodes. 
During sampling, for each training instance, the 
sampler first applies the Two-level-left-Rotate 
operator to all candidate pairs of s-nodes (parent s-
node and its left child s-node) in the U-tree. After 
that, the Two-level-right-Rotate operator is applied 
to all the candidate pairs of s-nodes (parent s-node 
and its right child s-node). Then, we use the Rotate 
operator on every s-node in the U-tree. By utilizing 
the operators separately, we can guarantee that our 
sampler satisfies detailed balance. We visit all the 
training instances in a random order (one iteration). 
After a number of iterations, we can obtain the 
final U-tree structures and build the tree-based 
translation model accordingly. 
6 Experiments 
6.1 Experimental Setup 
The experiments are conducted on Chinese-to-
English translation. The training data are the FBIS 
corpus with approximately 7.1 million Chinese 
words and 9.2 million English words. We obtain 
the bidirectional word alignment with GIZA++, 
and then adopt the grow-diag-final-and strategy to 
obtain the final symmetric alignment. We train a 5-
gram language model on the Xinhua portion of the 
English Gigaword corpus and the English part of 
                                                          
10 We can also take more nodes as a unit for sampling, 
but this would make the algorithm much more complex. 
249
the training data. For tuning and testing, we use the 
NIST MT 2003 evaluation data as the development 
set, and use the NIST MT04 and MT05 data as the 
test set. We use MERT (Och, 2004) to tune 
parameters. Since MERT is prone to search errors, 
we run MERT 5 times and select the best tuning 
parameters in the tuning set. The translation quality 
is evaluated by case-insensitive BLEU-4 with the 
shortest length penalty. The statistical significance 
test is performed by the re-sampling approach 
(Koehn, 2004). 
To create the baseline system, we use the open-
source Joshua 4.0 system (Ganitkevitch et al, 2012) 
to build a hierarchical phrase-based (HPB) system, 
and a syntax-augmented MT (SAMT) 11  system 
(Zollmann and Venugopal, 2006) respectively. 
The translation system used for testing the 
effectiveness of our U-trees is our in-house string-
to-tree system (abbreviated as s2t). The system is 
implemented based on (Galley et al, 2006) and 
(Marcu et al 2006). In the system, we extract both 
the minimal GHKM rules (Galley et al, 2004), and 
the rules of SPMT Model 1 (Galley et al, 2006) 
with phrases up to length L=5 on the source side. 
We then obtain the composed rules by composing 
two or three adjacent minimal rules. 
To build the above s2t system, we first use the 
parse tree, which is generated by parsing the 
English side of the bilingual data with the Berkeley 
parser (Petrov et al, 2006). Then, we binarize the 
English parse trees using the head binarization 
approach (Wang et al, 2007) and use the resulting 
binary parse trees to build another s2t system. 
For the U-trees, we run the Gibbs sampler for 
1000 iterations on the whole corpus. The sampler 
uses 1,087s per iteration, on average, using a single 
core, 2.3 GHz Intel Xeon machine. For the 
hyperparameters, we set ? to 0.1 and pexpand = 1/3 
to give a preference to the rules with small 
fragments. We built an s2t translation system with 
the achieved U-trees after the 1000th iteration. We 
only use one sample to extract the translation 
grammar because multiple samples would result in 
a grammar that would be too large. 
                                                          
11 From (Zollmann and Vogel, 2011), we find that the 
performance of SAMT system is similar with the 
method of labeling SCFG rules with POS tags. Thus, to 
be convenient, we only conduct experiments with the 
SAMT system. 
6.2 Analysis of The Gibbs Sampler 
To evaluate the effectiveness of the Gibbs sampler, 
we explore the change of the training data?s 
likelihood with increasing sampling iterations. 
1.239E+08
1.243E+08
1.247E+08
1.251E+08
1.255E+08
1.259E+08
100 200 300 400 500 600 700 800 900 1000
Number of Sampling Iterations 
N
e
g
a
ti
v
e
-L
o
g
 L
ik
e
li
h
o
o
d random 1
random 2
random 3
 
Figure 5. Histograms of the training data?s likelihood vs. 
the number of sampling iterations. In the figure, random 
1 to 3 refers to three independent runs of the sampler 
with different initial U-trees as initialization states. 
Figure 5 depicts the negative-log likelihood of 
the training data after several sampling iterations. 
The results show that the overall likelihood of the 
training data is improved by the sampler. Moreover, 
comparing the three independent runs, we see that 
although the sampler begins with different initial 
U-trees, the training data?s likelihood is always 
similar during sampling. This demonstrates that 
our sampler is not sensitive to the random initial 
U-trees and can always arrive at a good final state 
beginning from different initialization states. Thus, 
we only utilize the U-trees from random 1 for 
further analysis hereafter. 
1.035E+07
1.040E+07
1.045E+07
1.050E+07
1.055E+07
1.060E+07
100 200 300 400 500 600 700 800 900 1000
Number of Sampling Iterations 
T
o
ta
l 
N
u
m
b
e
r 
o
f 
F
ro
n
ti
e
r 
N
o
d
e
s
random 1
random 2
random 3
 
Figure 6. The total number of frontier nodes for the 
three independent runs. 
6.3 Analysis of the U-tree Structure 
Acquiring better U-trees for translation is our final 
purpose. However, are the U-trees achieved by the 
250
Gibbs sampler appropriate for the tree-based 
translation model? 
To answer this question, we first analyze the 
effect of the sampler on the U-trees. Figure 6 
shows the total number of frontier nodes in the 
training data during sampling. The results show 
that the number of frontier nodes increases with 
increased sampling. This tendency indicates that 
our sampler prefers the tree structure with more 
frontier nodes. Consequently, the final U-tree 
structures can always be factored into many small 
minimal translation rules. Just as we have argued 
in section 4.1, this is beneficial for a good 
translation grammar. 
To demonstrate the above analysis, Figure 7 
shows a visual comparison between our U-tree 
(from random 1) and the binary parse tree (found 
by head binarization). Because the traditional parse 
tree is not binarized, we do not consider it for this 
analysis. Figure 7 shows that whether it is the 
target tree fragment or the source string of the rule, 
our U-trees always tend to obtain the smaller 
ones12. This comparison verifies that our Bayesian 
tree induction model is effective in shifting the tree 
structures away from complex minimal rules, 
which tend to negatively affect translation. 
0
200k
400k
600k
800k
1000k
2 3 4 5 6 7 8 9 10 >=11
U-Tree
binary parse tree
Number of Nodes in the Target Tree Fragment
N
um
be
r 
of
 R
ul
es
Number of Words and Variables in the Source String
0
300k
600k
900k
1200k
1 2 3 4 5 6 7
N
um
be
r 
of
 R
ul
es
 
Figure 7. Histograms over minimal translation rule 
statistics comparing our U-trees and binary parse trees. 
                                                          
12 Binary parse trees get more tree fragments with two 
nodes than U-trees. This is because there are many 
unary edges in the binary parse trees, while no unary 
edge exists in our U-trees. 
Specifically, we show an example of a binary 
parse tree and our U-tree in Figure 8. The example 
U-tree is more conducive to extracting effective 
translation rules. For example, to translate the 
Chinese phrase ?? ??, we can extract a rule (R2 
in Figure 9) directly from the U-tree because the 
phrase ?? ?? is governed by a frontier node, i.e., 
node ?VBD+RB?. However, because no node 
governs ?? ?? in the binary parse tree, we can 
only obtain a rule (R1 in Figure 9) with many extra 
nodes and edges, such as node CD in R1. Due to 
these extra things, R1 is too large to show good 
generality. 
was
QP
dollarsUS1500only
VBD NNSNNPCDRB
NP
NP
? ???????
NP-COMP
(a) binary parse tree
(b) U-tree
was dollarsUS1500only
VBD NNSNNPCDRB
? ???????
VBD+RB NNP+NNS
CD...NNS
VBD...NNS
 
Figure 8. Example of different tree structures. The node 
NP-COMP is achieved by head binarization. The bold 
italic nodes with shadows denote frontier nodes. 
was QP
only
VBD
CD:x0RB
NP
NP
NP-COMP:x1
was only
VBD RB
? ?VBD+RB
? x1x0?
R1:
R2:
 
Figure 9. Example rules to translate the Chinese phrase 
??  ? .? R1 is extracted from Figure 8(a), i.e., the 
binary parse tree. R2 is from Figure 8(b), i.e., the U-tree. 
251
Based on the above analysis, we can conclude 
that our proposed U-tree structures are conducive 
to extracting small, minimal translation rules. This 
indicates that the U-trees are more consistent with 
the word alignment and are good at capturing 
bilingual mapping information. Therefore, because 
parse trees are always constrained by cross-lingual 
structure divergence, we believe that the proposed 
U-trees would result in a better translation 
grammar. We demonstrate this conclusion in the 
next sub-section. 
6.4 Final Translation Results 
The final translation results are shown in Table 1. 
In the table, lines 3-6 refer to the string-to-tree 
systems built with different types of tree structures. 
Table 1 shows that all our s2t systems 
outperform the Joshua (HPB) and Joshua (SAMT) 
system significantly. This comparison verifies the 
superiority of our in-house s2t system. Moreover, 
the results shown in Table 1 also demonstrate the 
effectiveness of head binarization, which helps to 
improve the s2t system using parse trees in all 
translation tasks. 
To test the effectiveness of our U-trees, we give 
the s2t translation system using the U-trees (from 
random 1). The results show that the system using 
U-trees achieves the best translation result from all 
of the systems. It surpasses the s2t system using 
parse trees by 1.47 BLEU points on MT04 and 
1.44 BLEU points on MT05. Moreover, even using 
the binary parse trees, the achieved s2t system is 
still lower than our U-tree-based s2t system by 
0.97 BLEU points on the combined test set. From 
the translation results, we can validate our former 
analysis that the U-trees generated by our Bayesian 
tree induction model are more appropriate for 
string-to-tree translation than parse trees. 
System MT04 MT05 All 
Joshua (HPB) 31.73 28.82 30.64 
Joshua (SAMT) 32.48 29.77 31.56 
s2t (parse-tree) 33.73* 30.25* 32.75* 
s2t (binary-parse-tree) 34.09* 30.99*# 32.92* 
s2t (U-tree) 35.20*# 31.69*# 33.89*# 
Table 1. Results (in case-insensitive BLEU-4 scores) of 
s2t systems using different types of trees. The ?*? and 
?#? denote that the results are significantly better than 
the Joshua (SAMT) system and the s2t system using 
parse trees (p<0.01). 
6.5 Large Data 
We also conduct an experiment on a larger 
bilingual training data from the LDC corpus13. The 
training corpus contains 2.1M sentence pairs with 
approximately 27.7M Chinese words and 31.9M 
English words. Similarly, we train a 5-gram 
language model using the Xinhua portion of the 
English Gigaword corpus and the English part of 
the training corpus. With the same settings as 
before, we run the Gibbs sampler for 1000 
iterations and utilize the final U-tree structure to 
build a string-to-tree translation system. 
The final BLEU score results are shown in Table 
2. In the scenario with a large data, the string-to-
tree system using our U-trees still significantly 
outperforms the system using parse trees. 
System MT04 MT05 All 
Joshua (HPB) 34.55 33.11 34.01 
Joshua (SAMT) 34.76 33.72 34.37 
s2t (parse-tree) 36.40* 34.53* 35.70* 
s2t (binary-parse-tree) 37.38*# 35.14*# 36.54*# 
s2t (U-tree) 38.02*# 36.12*# 37.34*# 
Table 2. Results (in case-insensitive BLEU-4 scores) for 
the large training data. The meaning of ?*? and ?#? are 
similar to Table 1. 
7 Conclusion and Future Work 
In this paper, we explored a new direction to build 
a tree-based model based on unsupervised 
Bayesian trees rather than supervised parse trees. 
To achieve this purpose, we have made two major 
efforts in this paper: 
(1) We have proposed a novel generative 
Bayesian model to induce effective U-trees for 
tree-based translation. We utilized STSG in the 
model to grasp bilingual mapping information. We 
further imposed a reasonable hierarchical prior on 
the tree structures, encouraging small and frequent 
minimal rules for translation. 
(2) To train the Bayesian tree induction 
model efficiently, we developed a Gibbs sampler 
with three novel Gibbs operators. The operators are 
designed specifically to explore the infinite space 
of tree structures by performing local changes on 
the tree structure. 
                                                          
13 LDC category number : LDC2000T50, LDC2002E18, 
LDC2003E07, LDC2004T07, LDC2005T06, 
LDC2002L27, LDC2005T10 and LDC2005T34. 
252
Experiments on the string-to-tree translation 
model demonstrated that our U-trees are better 
than the parse trees. The translation results verify 
that the well-designed unsupervised trees are 
actually more appropriate for tree-based translation 
than parse trees. Therefore, we believe that the 
unsupervised tree structure would be a promising 
research direction for tree-based translation. 
In future, we plan to testify our sampler with 
various initial trees, such as the tree structure 
formed by (Zhang et al, 2008). We also plan to 
perform a detailed empirical comparison between 
STST and SCFG under our settings. Moreover, we 
will further conduct experiments to compare our 
methods with other relevant works, such as (Cohn 
and Blunsom, 2009) and (Burkett and Klein, 2012). 
Acknowledgments 
We would like to thank Philipp Koehn and three 
anonymous reviewers for their valuable comments 
and suggestions. The research work has been 
funded by the Hi-Tech Research and Development 
Program (?863? Program) of China under Grant 
No. 2011AA01A207, 2012AA011101, and 
2012AA011102. 
References 
Phil Blunsom, Trevor Cohn, Miles Osborne. 2008. 
Bayesian synchronous grammar induction. In 
Advances in Neural Information Processing Systems, 
volume 21, pages 161-168. 
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles 
Osborne. 2009. A gibbs sampler for phrasal 
synchronous grammar induction. In Proc. of ACL 
2009, pages 782-790. 
Phil Blunsom and Trevor Cohn. 2010. Inducing 
synchronous grammars with slice sampling. In Proc. 
of NAACL 2010, pages 238-241. 
David Burkett and Dan Klein. 2008. Two languages are 
better than one (for syntactic Parsing). In Proc. of 
EMNLP 2008, pages 877-886. 
David Burkett, John Blitzer, and Dan Klein. 2010. Joint 
parsing and alignment with weakly synchronized 
grammars. In Proc. of NAACL 2010, pages 127-135.  
David Burkett and Dan Klein. 2012. Transforming trees 
to improve syntactic convergence. In Proc. of 
EMNLP 2012, pages 863-872. 
David Chiang. 2007. Hierarchical phrase-based 
translation. Computational Linguistics, 33 (2). pages 
201-228. 
Dekai Wu. 1996. A polynomial-time algorithm for 
statistical machine translation. In Proc. of ACL 1996, 
pages 152-158. 
Dekai Wu. 1997. Stochastic inversion transduction 
grammars and bilingual parsing of parallel corpora. 
Computational Linguistics, 23:377-404. 
Trevor Cohn and Phil Blunsom. 2009. A bayesian 
model of syntax-directed tree to string grammar 
induction. In Proc. of EMNLP 2009, pages 352-361. 
Trevor Cohn, Phil Blunsom, and Sharon Goldwater. 
2010. Inducing tree-substitution grammars. Journal 
of Machine Learning Research, pages 3053-3096. 
Brooke Cowan, Ivona Kucerova and Michael Collins. 
2006. A discriminative model for tree-to-tree 
translation. In Proc. of EMNLP 2006, pages 232-241. 
John DeNero and Dan Klein. 2007. Tailoring word 
alignments to syntactic machine translation. In Proc. 
of ACL 2007, pages 17-24. 
John DeNero and Jakob Uszkoreit. 2011. Inducing 
sentence structure from parallel corpora for 
reordering. In Proc. of EMNLP 2011, pages 193-203. 
Chris Dyer. 2010. Two monolingual parses are better 
than one (synchronous parse). In Proc. of NAACL 
2010, pages 263-266. 
Jason Eisner. 2003. Learning non-isomorphic tree 
mappings for machine translation. In Proc. of ACL 
2003, pages 205-208. 
Michel Galley, Mark Hopkins, Kevin Knight and Daniel 
Marcu. 2004. What?s in a translation rule. In Proc. of 
HLT-NAACL 2004, pages 273?280. 
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel 
Marcu, Steve DeNeefe, Wei Wang and Ignacio 
Thayer. 2006. Scalable inference and training of 
context-rich syntactic translation models. In Proc. of 
ACL-COLING 2006, pages 961-968. 
Jonathan Weese, Juri Ganitkevitch, Chris Callison-
Burch, Matt Post and Adam Lopez. 2011. Joshua 3.0: 
syntax-based machine translation with the thrax 
Grammar Extractor. In Proc of WMT11, pages 478-
484. 
Liang Huang, Kevin Knight and Aravind Joshi. 2006. A 
syntax-directed translator with extended domain of 
locality. In Proc. of AMTA 2006, pages 65-73. 
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.  
Statistical phrase-based translation, In Proc. of 
HLT/NAACL 2003, pages 48-54.  
253
Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proc. of EMNLP 
2004, pages 388?395. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
RichDUG =HQV &KULV '\HU DQG 2QG?HM %RMDU. 2007. 
Moses: open source toolkit for statistical machine 
translation. In Proc. of ACL 2007, pages 177-180. 
Abby Levenberg, Chris Dyer and Phil Blunsom. 2012. 
A bayesian model for learning SCFGs with 
discontiguous Rules. In Proc. of EMNLP 2012, pages 
223-232. 
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri 
Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, 
Wren N.G. Thornton, Jonathan Weese and Omar F. 
Zaidan. 2009. Joshua: An open source toolkit for 
parsing-based machine translation. In Proc. of ACL 
2009, pages 135-139. 
Shujie Liu, Chi-Ho Li, Mu Li, Ming Zhou. 2012. Re-
training monolingual parser bilingually for syntactic 
SMT. In Proc. of EMNLP 2012, pages 854-862. 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine 
translation. In Proc. of ACL-COLING 2006, pages 
609-616. 
Yang Liu, Yajuan Lv and Qun Liu. 2009. Improving 
tree-to-tree translation with packed forests. In Proc. 
of ACL-IJCNLP 2009, pages 558-566. 
Daniel Marcu, Wei Wang, Abdessamad Echihabi and 
Kevin Knight. 2006. SPMT: Statistical machine 
translation with syntactified target language phrases. 
In Proc. of EMNLP 2006, pages 44-52. 
Franz Och, 2003. Minimum error rate training in 
statistical machine translation. In Proc. of ACL 2003, 
pages 160-167. 
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic 
evaluation of machine translation. In Proc. of ACL 
2002, pages 311-318. 
Slav Petrov, Leon Barrett, Romain Thibaux and Dan 
Klein. 2006. Learning accurate, compact, and 
interpretable tree annotation. In Proc. of COLING-
ACL 2006, pages 433-440. 
Chris Quirk, Arul Menezes and Colin Cherry. 2005. 
Dependency treelet translation: syntactically 
informed phrasal SMT. In Proc. of ACL 2005, pages 
271-279. 
Libin Shen, Jinxi Xu and Ralph Weischedel. 2008. A 
new string-to-dependency machine translation 
algorithm with a target dependency language model. 
In Proc. of ACL-08, pages 577-585. 
Wei Wang, Kevin Knight, and Daniel Marcu. 2007. 
Binarizing syntax trees to improve syntax-based 
machine translation accuracy. In Proc. of EMNLP 
2007, pages 746-754. 
Wei Wang, Jonathan May, Kevin Knight, and Daniel 
Marcu. 2010. Re-structuring, re-labeling, and re-
aligning for syntax-based machine translation. 
Computational Linguistics, 36(2):247?277. 
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing 
Zong. 2012. Tree-based translation without using 
parse trees. In Proc. of COLING 2012, pages 3037-
3054. 
Hao Zhang, Liang Huang, Daniel Gildea and Kevin 
Knight. 2006. Synchronous binarization for machine 
translation. In Proc. of HLT-NAACL 2006, pages 
256-263. 
Hao Zhang, Daniel Gildea, and David Chiang. 2008. 
Extracting synchronous grammars rules from word 
level alignments in linear time. In Proc. of COLING 
2008, pages 1081-1088. 
Hao Zhang, Licheng Fang, Peng Xu, Xiaoyun Wu.  
2011a. Binarized forest to string translation. In Proc. 
of ACL 2011, pages 835-845. 
Hui Zhang, Min Zhang, Haizhou Li, Aiti Aw, Chew 
Lim Tan. 2009. Forest-based tree sequence to string 
translation model. In Proc. of ACL-IJCNLP 2009, 
pages 172-180. 
Jiajun Zhang, Feifei Zhai and Chengqing Zong. 2011b. 
Augmenting string-to-tree translation models with 
fuzzy use of source-side syntax. In Proc. of EMNLP 
2011, pages 204-215. 
Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, Chew 
Lim Tan and Sheng Li. 2007. A tree-to-tree 
alignment-based model for statistical Machine 
translation. MT-Summit-07. pages 535-542 
Min Zhang, Hongfei Jiang, Ai ti Aw, Haizhou Li, Chew 
Lim Tan and Sheng Li. 2008. A tree sequence 
alignment-based tree-to-tree translation model. In 
Proc. of ACL 2008, pages 559-567. 
Andreas Zollmann and Ashish Venugopal. 2006. Syntax 
augmented machine translation via chart parsing. In 
Proc. of Workshop on Statistical Machine 
Translation 2006, pages 138-141. 
Andreas Zollmann and Stephan Vogel. 2011. A word-
class approach to labeling PSCFG rules for machine 
translation. In Proc. of ACL 2011, pages 1-11. 
254
