Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1728?1739, Dublin, Ireland, August 23-29 2014.
Towards Semantic Validation of a Derivational Lexicon
Britta D. Zeller
?
Sebastian Pad
?
o
?
Jan
?
Snajder
?
?
Heidelberg University, Institut f?ur Computerlinguistik
69120 Heidelberg, Germany
?
Stuttgart University, Institut f?ur maschinelle Sprachverarbeitung
70569 Stuttgart, Germany
?
University of Zagreb, Faculty of Electrical Engineering and Computing
Unska 3, 10000 Zagreb, Croatia
zeller@cl.uni-heidelberg.de pado@ims.uni-stuttgart.de jan.snajder@fer.hr
Abstract
Derivationally related lemmas like friend
N
? friendly
A
? friendship
N
are derived from a common
stem. Frequently, their meanings are also systematically related. However, there are also many
examples of derivationally related lemma pairs whose meanings differ substantially, e.g., object
N
? objective
N
. Most broad-coverage derivational lexicons do not reflect this distinction, mixing up
semantically related and unrelated word pairs.
In this paper, we investigate strategies to recover the above distinction by recognizing semantically
related lemma pairs, a process we call semantic validation. We make two main contributions:
First, we perform a detailed data analysis on the basis of a large German derivational lexicon. It
reveals two promising sources of information (distributional semantics and structural information
about derivational rules), but also systematic problems with these sources. Second, we develop
a classification model for the task that reflects the noisy nature of the data. It achieves an
improvement of 13.6% in precision and 5.8% in F1-score over a strong majority class baseline.
Our experiments confirm that both information sources contribute to semantic validation, and that
they are complementary enough that the best results are obtained from a combined model.
1 Introduction
Morphological processing forms the first step of virtually all linguistic processing toolchains in natural
language processing (NLP) and precedes other analyses such as part of speech tagging, parsing, or
named entity recognition. There are three major types of morphological processes: (a) Inflection modifies
word forms according to the grammatical context; (b) derivation constructs new words from individual
existing words, typically through affixation; (c) composition combines multiple words into new lexical
items. Computational treatment of morphology is often restricted to normalization, such as lemmatization
(covering inflection only) or stemming (covering inflection and derivation heuristically, Porter (1980)).
An important reason is that English is morphologically a relatively simple language. Composition is
not marked morphologically (zoo gate) and an important derivational pattern is zero derivation where the
input and output terms are identical surface forms (a fish / to fish). Thus, lemmatization or stemming go a
long way towards treating the aspects of English morphology relevant for NLP. The situation is different
for languages with a complex morphology that calls for explicit treatment. In fact, recent years have seen
a growing body of computational work in particular on derivation, which is a very productive process of
word formation in Slavic languages but also in languages more closely related to English, like German
(
?
Stekauer and Lieber, 2005).
Derivation comprises a large number of distinct patterns, many of which cross part of speech boundaries
(nominalization, verbalization, adjectivization), but some of which do not (gender indicators like master /
mistress, approximations like red / reddish). A simple way to conceptualize derivation is that it partitions a
language?s vocabulary into derivational families of derivationally related lemmas (cf. Zeller et al. (2013),
Gaussier (1999)). In WordNet, this type of information has been included to some extent by so-called
?morpho-semantic? relations (Fellbaum et al., 2009), and the approach has been applied to languages other
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1728
lachen Lacher l?acherlich
sfx ?er?V N
Append suffix ?er? to the stem of
the verb to obtain a noun
try uml &
sfx ?lich?N
A
Try to turn the noun?s vowels into umlauts, then
append suffix ?lich? to obtain an adjective
to laugh laugh laughable
Figure 1: (Part of) a derivational family from DERIVBASE including derivational rules
than English (Bilgin et al., 2004; Pala and Hlav?a?ckov?a, 2007). Another source of derivational information
are stand-alone derivational lexicons such as CatVar (Habash and Dorr, 2003) for English, DERIVBASE
(Zeller et al., 2013) for German, or the multilingual CELEX (Baayen et al., 1996).
Recent work has demonstrated that NLP can benefit from derivational knowledge. Shnarch et al. (2011)
employ derivational knowledge in recognizing English textual entailment to better gauge the semantic
similarity of text and hypothesis. Pad?o et al. (2013) improve the prediction of German semantic similarity
judgments for lemma pairs by backing off to derivational families for infrequent lemmas. Luong et al.
(2013) and Lazaridou et al. (2013) improve distributional semantic representations.
Note that all of these applications make use of derivational knowledge to address various semantic tasks,
working on the assumption that derivationally related words, as represented in derivational lexicons, are
strongly semantically related. This assumption is not completely warranted, though. The development of
wide-coverage derivational lexicons is generally driven by morphological information, using for example
finite-state technology (Karttunen and Beesley, 2005) to characterize known derivational patterns in terms
of string transformations. Even though there is a strong correlation in derivation between morphology
and semantics, it is not perfect. The absence of (synchronic) semantic relatedness can have a number of
reasons, including accidental instantiation of derivational patterns (corn ? corner) and diachronic meaning
drift (dog (animal) ? dogged (determined)). In other words, a substantial number of the lemma pairs in
those lexicons are false positives regarding the level of semantic relatedness.
Our goal in this paper is to ameliorate this situation by developing strategies for the semantic validation
of derivational lexicons, i.e., methods to determine, for lemma pairs that are derivationally related
at the morphological level, whether they are in fact semantically related. We base our study on the
German derivational lexicon DERIVBASE, and start by assessing which strategies can be used for its
semantic validation (Section 2). In Sections 3 and 4, we analyze the contributions of semantic information
(distributional semantics) as well as structural information (derivational rules). On the basis of our
observations, we train a classifier that is able to semantically validate DERIVBASE at 89.9% F
1
-score
(Section 5), significantly outperforming a majority-class baseline of 84.1%. Section 6 reviews related
work. Section 7 concludes the paper and outlines future work.
2 A Lexicon for German Derivation
2.1 DERIVBASE
DERIVBASE (Zeller et al., 2013) is a freely available derivational lexicon for German.
1
We used a
rule-based framework to define derivation rules that cover suffixation, prefixation, and zero derivation as
well as stem changes. Following the work of
?
Snajder and Dalbelo Ba?si?c (2010), derivational processes are
defined using derivational rules and higher-order string transformation functions. The only requirements
for this method are (a) a comprehensive set of lemmas and (b) knowledge about admissible derivational
rules, which can be gathered, for example, from linguistics textbooks.
Figure 1 shows a small sample from a derivational family with three lemmas and two derivational rules,
one turning a verb into the corresponding event noun (in this case a semelfactive), and one turning the
event into an adjective associated with it. Note that there are two perspectives on such a family: It can
1
http://www.cl.uni-heidelberg.de/
?
zeller/res/derivbase/
1729
?Positive? Precision Recall
DERIVBASE release class % %
1.2 (Zeller et al., 2013)
3
R and M 83.0 71.0
1.4 (our analysis) R and M 85.1 91.4
1.4 (our analysis) R only 76.7 93.8
Table 1: DERIVBASE evaluation across releases on the DERIVBASE release 1.2 P and R samples
either be seen as a set of lemmas, or as a set of (independent) lemma pairs. We will assume the latter
perspective in this paper, leaving questions of global coherence for future work.
DERIVBASE is a good example for the problems sketched in Section 1. It is defined purely on
morphological grounds, without semantic validation of derivational families. Consequently, it contains a
substantial number of words that are not semantically related.
2.2 Morphological and Semantic Relatedness in DERIVBASE
Our original evaluation of the quality of DERIVBASE in Zeller et al. (2013) was based on manually
classified samples of lemma pairs. We introduce two samples, the ?R sample?, drawn from a large
population of lemma pairs with high string similarity, in order to calculate recall, and the ?P sample?,
drawn from the DERIVBASE families, in order to compute precision. Each lemma pair was classified into
one of five categories (R: morphologically and semantically related; M: only morphologically related;
N: not related; L: lemmatization errors; C: compounds) and inter-annotator agreement was checked to
be substantial.
2
The overall best model (L123) showed 83% precision and 71% recall. However, this
evaluation is limited in two important respects. First, it refers to DERIVBASE release 1.2 from 2013.
Since then, we have extended DERIVBASE, e.g., with rules covering particle verbs, a very productive
area of German derivation. Secondly, and more seriously, the previous evaluation considered all instances
of R and M as true positives. In other words, in Zeller et al. (2013) we only evaluated the morphological
relatedness of the lemma pairs but not the semantic relatedness.
We therefore start by presenting an evaluation of DERIVBASE focusing on the R instances in Table 1,
reusing the DERIVBASE 1.2 ?P? and ?R? samples introduced in Zeller et al. (2013, see there for evaluation
details). Between DERIVBASE 1.2 and 1.4, precision increased marginally and recall substantially, due
mainly to the inclusion of rules that cover particle verbs. However, the numbers change substantially when
only R (truly semantically related pairs) are counted as true positives. Recall increases by about 2.5%, but
precision drops about 8.5%. Almost one quarter of all pairs in the lexicon are not semantically related.
A possible confounder of this analysis is that the ?P sample? was drawn on DERIVBASE 1.2 and
therefore does not include the novel items in DERIVBASE 1.4. We therefore created a novel DERIVBASE
1.4 extended sample by combining the existing ?P sample? with those pairs from the ?R sample? that are
in the coverage of a DERIVBASE rule as of DERIVBASE 1.4, resulting in 2,545 lemma pairs.
This DERIVBASE 1.4 extended sample will form the basis of all our analyses in this paper. The class
distribution in the new sample is similar, but not identical, to the old P sample, as shown in Table 2. The
relative frequency of R drops another 2%. Since this number also corresponds to the precision of the
resource, the precision of the extended sample is 74.6%.
There are almost no compound errors C, which is not surprising given the rule-based construction of
the lexicon, and only a relatively small number (about 5%) of lemmatization errors L, which fall outside
the scope of our work. In contrast, both N and M occur with substantial frequency: Each class accounts
for around 10% of the pairs. An analysis of N shows many cases of rule overgeneration: These are often
pairs of lemmas whose stems are sufficiently similar that they might be related, e.g., by stem-changing
derivation rules. Although such rules are valid in other contexts (Verkauf
N
? Verk?aufer
N
(selling ? seller)),
2
Although we believe semantic relatedness to be fundamentally a graded scale, we adopt a binary notion of it as a convenient
operational simplification that is supported by the good inter-annotator agreement for manual labeling in DERIVBASE.
3
DERIVBASE 1.2 corresponds to DERIVBASE ?L123? in (Zeller et al., 2013, p. 1207).
1730
R M N L C
Frequency 1899 265 240 131 8
Percentage overall 74.6 10.4 9.5 5.2 0.3
Percentage on dev. set 75.5 10.3 9.0 4.8 0.3
Percentage of test set 72.6 10.6 10.6 5.9 0.3
Table 2: Class distribution in our new DERIVBASE 1.4 extended sample
erroneous application leads to N cases like Blase
N
? Bl?aser
N
(bubble ? blower). Also, we find false
matches of common noun rules with named entities (Empire
N
? Empirismus
N
(Empire ? empiricism)).
In contrast, many cases of M (as sketched in Section 1) refer to different senses of the same stem. As
an example, consider beruhen
V
? unruhig
A
(to rest on ? restless), both related to Ruhe
N
(rest). In other
cases, one of the two lemmas appears to have undergone a meaning shift (Rappel
N
? rappeln
V
(craze ?
to rattle)). This is particularly prominent for particle verbs (bauen
V
? erbaulich
A
(build ? edifying)).
We divide the DERIVBASE 1.4 extended sample into a development and a test partition (70:30 ratio);
the subsequent analyses consider only the development set.
2.3 Hypotheses for Semantic Validation
The preceding analysis of DERIVBASE has established that the lexicon contains a substantial number
(around one fourth) of lemma pairs that are not semantically related. Therefore, it is in need of semantic
validation, i.e., a computational procedure that can filter out semantically unrelated words.
In this paper, we frame semantic validation as a binary classification task that classifies all lemma pairs
within one derivational family as either semantically related or unrelated. We consider this a first step
towards splitting the current, morphologically motivated, DERIVBASE families into smaller, semantically
coherent, families. We base our work on two general hypotheses about the types of information that might
be helpful in this endeavor.
Hypothesis 1. Distributional similarity indicates semantic relatedness between derivationally related
words. The instances of polysemy and meaning shift that we observe, in particular in the M class,
motivate the use of distributional similarity (Turney and Pantel, 2010) since we expect these lemma
pairs to be distributionally less related than cases of true semantic relatedness.
Hypothesis 2. Derivational rules differ in their reliability. Both the evidence from M and N indicate
that some rules are more meaning-preserving than others. We expect this to be tied to both lexical
properties of the rules (particle verbs are more likely than diminutives to radically change meaning)
as well as structural properties (more specific rules are presumably more precise than generic rules).
In the two following Sections, we will operationalize these hypotheses and analyze the development set of
the DERIVBASE 1.4 extended sample with respect to their empirical adequacy.
3 Analysis 1: Distributional Similarity for Semantic Validation
3.1 Measuring Distributional Similarity
We examine semantic similarities as predicted by simple bag-of-words semantic space models built from
the lemmatized SDeWaC (Faa? et al., 2010), a large German web corpus containing about 880 million
words. We compute vectors for all words covered in DERIVBASE using a window of ?5 words within
sentence boundaries and considering the 10k most frequent lemma-part of speech combinations of nouns,
verbs, and adjectives in SDeWaC as contexts. Distributional vectors are built from co-occurrences which
are measured with Local Mutual Information (Evert, 2005). The semantic similarity is measured by the
cosine similarity between the vectors. Despite the size of the corpus, many lemmas from DERIVBASE
occur very infrequently, and due to the inflection in German, it is important to retrieve as many occurrences
of each lemma as possible.
1731
We therefore use a very permissive two-step lemmatization scheme that starts from lemmas from
the lexicon-based TreeTagger (Schmid, 1994), which provides reliable lemmas but with relatively low
coverage, and supplements them with lemmas and parts of speech produced by the probabilistic MATE
toolkit (Bohnet, 2010) when TreeTagger abstains.
3.2 Frequency Considerations
The advantage of the string transformation-based construction of DERIVBASE is its ability to include
infrequent lemmas in the lexicon, and in fact DERIVBASE includes more than 250,000 content lemmas,
some of which occur not more than three times in SDeWaC. However, this is a potential problem when
we build distributional representations for all lemmas in DERIVBASE since it is known from the literature
that similarity predictions for infrequent lemmas are often unreliable (Bullinaria and Levy, 2007).
Our data conform to expectations in this regard ? infrequent lemmas are indeed problematic for
validating the semantic relatedness of lemma pairs. More specifically, the semantic similarity of related
lemmas (R) is systematically underestimated, because the lemma pairs from our sample are often too
infrequent to share any dimensions. Consequently, they receive a low or zero cosine even when they are
semantically strongly related. For example, each of the lemmas Drogenverkauf
N
? Drogenverk?aufer
N
(drug selling ? drug seller) has only nine lemmas as dimensions, and those are completely disjoint. This
underestimation constitutes a general trend. The model assigns cosine scores below 0.1 to 64% of the
related pairs in the development set, cosines below 0.2 to 81%, and cosines below 0.3 to 87%. Such low
scores are problematic for separating related from unrelated pairs.
Two-step lemmatization is important for the proper handling of infrequent words. Compared to
just using TreeTagger, the TreeTagger+MATE vectors for auferstehen
V
? auferstehend
A
(to resurrect ?
resurrecting) share seven more dimensions, including Jesus, Lord, myth, and suffering. Correspondingly,
the cosine value of this pair rises by 50%. Generally, the amount of zero cosines in the DERIVBASE
1.4 extended sample drops by 45% using two-step lemmatization compared to one-step TreeTagger
lemmatization.
3.3 Conceptual Considerations
In addition to the frequency considerations discussed above, we find three conceptual phenomena that
affect distributional similarity independently of the frequency aspects.
The first one is the influence of parts of speech. Derivational rules often change the part of speech of the
input lemma, and the parts of speech of its context words change as well. This decreases context overlap.
For example,
?
Ubersch?atzung
N
? ?ubersch?atzt
A
(overestimate ? overestimated) is assigned a cosine of
merely 0.09. The upper half of Table 3 shows the top ten individual and shared context words for this
pair, ranked by LMI. The context words of the noun are mainly nominal heads of genitive complements
(overestimation of possibility/force/. . . ), while the context words of the adjective comprise many adverbs
(totally, widely, . . . ). None of the shared contexts rank among of the top ten for both target lemmas. This
is even more surprising considering that German adjectives and adverbs have the same surface realization
(as opposed to English) and are more likely to form matching context words.
The second phenomenon that we identified as influencing semantic similarity is markedness (Battistella,
1996). A considerable number of derivational rules systematically produce marked terms. A striking
example is the feminine suffix ?-in? as in Entertainer
N
? Entertainerin
N
: Although the lemmas are
intuitively very similar, their cosine is as low as 0.1. The reason is that the female versions tend to be
used in contexts where the gender of the entertainer is relevant. This is illustrated in the lower half of
Table 3. The first two contexts for both words (actor, singer) stem from frequent enumerations (actor and
entertainer X) and are almost identical, but again the female versions are marked for gender. We also find
two female given names. As a result, the target lemmas receive a low distributional similarity.
The third example are cases of mild meaning shifts that were tagged by the annotators as R. These
are lemmas where the semantic relatedness is intuitively clearly recognizable but may be accompanied
by pretty substantial changes in the distribution of contexts. Consider the semantically related pair
Absteiger
N
? absteigend
A
(descender (person) ? descending/decreasing). It achieves only a cosine of
1732
word pair (l
1
, l
2
) context(l
1
) context(l
2
) shared contexts(l
1
, l
2
)
?
Ubersch
?
atzung ?
?ubersch
?
atzt
(overestimation ?
overestimated),
cos = 0.09
eigen (own) v?ollig (totally) v?ollig (totally)
warnen (to alert) Problem (problem) M?oglichkeit (possibility)
M?oglichkeit (possibility) Gefahr (danger) Bedeutung (meaning)
f?uhren (to lead) Autor (author) Gefahr (danger)
Kraft (force) weit (widely) Einflu? (influence)
Bedeutung (meaning) total (totally) ?uberh?oht (excessive)
F?ahigkeit (ability) ernst (seriously) Macht (power)
Leistungsf?ahigkeit (performance) ?uberh?oht (excessive) gnadenlos (mercilessly)
neigen (to tend) gnadenlos (mercilessly) Kraft (force)
Einflu? (influence) Hollywood (Hollywood) h?aufig (frequent)
Entertainer ?
Entertainerin
(entertainer ? female
entertainer),
cos = 0.1
S?anger (singer) S?angerin (female singer) Schauspieler (actor)
Schauspieler (actor) Schauspielerin (actress) Musiker (musician)
Musiker (musician) Helga (female given name) Talent (talent)
Harald (male given name) Mutter (mother) bekannt (well-known)
Moderator (anchorman) ber?uhmt (famous) S?angerin (female singer)
Schmidt (surname) brillant (brilliant) beliebt (popular)
gro? (big) Lisa (female given name) gro? (big)
K?unstler (artist) K?unstlerin (female artist) ber?uhmt (famous)
Talent (talent) verstorben (deceased) Sportler (sportsman)
gut (good) Talent (talent) Schauspielerin (actress)
Table 3: Top ten individual and shared context words for
?
Ubersch?atzung
N
? ?ubersch?atzt
A
(overestimation
? overestimated) and Entertainer
N
? Entertainerin
N
. Individual context words are ranked by LMI, shared
context words by the product of their LMIs for the two target words. Shared context words that occur in
the top ten contexts for both words are marked in boldface.
0.005, because Absteiger is almost exclusively used to refer to relegated sport teams while absteigend is
used as a general verb of scalar change.
3.4 Ranking of Distributional Information
Given the results reported above, the standard distributional approach of using plain cosine scores to
measure the absolute amount of co-occurrences does not seem very promising, due to the low absolute
numbers of shared dimensions of the two lemmas. We expect other similarity measures, e.g., the Lin
measure (Lin, 1998), to perform equally poorly since they do not change the fundamental approach. Also,
although using a large corpus for semantic space construction might ameliorate the situation, we would
prefer to make improvements on the modeling side of semantic validation.
We follow the ideas of Hare et al. (2009) and Lapesa and Evert (2013) who propose to consider semantic
similarity in terms of ranks rather than absolute values. The advantage of rank-based similarity is that
it takes the density of regions in the semantic space into account. That is, a low cosine value does not
necessarily indicate low semantic relatedness ? provided that the two words are located in a ?sparse?
region. Conversely, a high cosine value can be meaningless in a densely populated region. A second
conceptual benefit of rank-based similarity is that it is directed: It is possible to distinguish the ?forward?
rank (the rank of l
1
in the neighborhood of l
2
) and the ?backward? rank (the rank of l
2
in the neighborhood
of l
1
). The previous studies found rank-based similarity to be beneficial for the prediction of priming
results. In our case, it suggests a refined version of our Hypothesis 1:
Hypothesis 1?. High rank-based distributional similarity indicates semantic relatedness between deriva-
tionally related words.
4 Analysis 2: Derivational Rules for Semantic Validation
As discussed in Section 2.3, a second source of information that should be able to complement the
problematic distributional similarity is provided by the derivational rules that are encoded in DERIVBASE
(cf. the arrows in Figure 1). Our intuition is that some rules are ?semantically stable?, meaning that they
reliably connect semantically similar lemmas, while other rules tend to cause semantic drifts. To examine
1733
this situation, we perform a qualitative analysis on all lemma pairs connected by rule paths of length one
(?simplex paths?), which are easy to analyze. Longer paths (?complex paths?) are considered below.
We find that rules indeed behave differently. For example, the ?-in? female marking rule from Section 3.3
is very reliable: every lemma pair connected by this rule is semantically related. At the other end of the
scale, there are rules that consistently lead to semantically unrelated lemmas, e.g., the ?ver-? noun-verb
prefixation: Zweifel
N
? verzweifeln
V
(doubt ? to despair). Foreign suffixes like ?-ktiv? in instruieren
V
? instruktiv
A
(to instruct ? instructive) retain semantic relatedness in most cases, but sometimes link
actually unrelated lemmas (N, C, L). For example, Objektiv
N
? Objektivismus
N
(lens ? objectivism),
is an N pair for the suffix ?-ismus?. Finally, zero derivations and very short suffixes are less reliable:
Since they easily match, they are often applied to incorrectly lemmatized words (L). For example, the
?-n? suffix, which relates nationalities with countries (Schwede
N
? Schweden
N
(Swede ? Sweden)). It
matches many wrongly lemmatized nouns due to its syncretism with the plural dative/accusative suffix -n,
as in Schweineschnitzel
N
? Schweineschnitzeln
N
(pork cutlet ? pork cutlets
dat/acc-pl
). This suggests that
rule-specific reliability is a promising feature for semantic validation. Fortunately, due to its construction,
DERIVBASE provides a rule chain for each lemma pair so that these reliabilities can be ?read off?. For
other rules, however, the variance of the individual lemma pairs that instantiate the rule is large, and the
applicability of the rule is influenced by the particular combination of rule and lemma pair. Such cases
suggest that distributional knowledge and structural rule information should be combined, a direction that
we will pursue in the next section.
On word pairs that are linked by ?complex paths?, i.e., more than one rule (lachen
V
? l?acherlich
A
in
Figure 1), our main observation in this respect is that rule paths show a clear ?weakest link? property. One
unreliable rule can be sufficient to cause a semantic drift, and only a sequence of reliable rules is likely to
link two semantically related words. We will act on this observation in the next section.
5 A Machine Learning Model for Semantic Validation
5.1 Classification
The findings of our analyses suggest that the decision to classify lemma pairs as semantically related
or unrelated can draw on a range of considerations. We therefore decided to adopt a machine learning
approach and phrase semantic validation as a binary classification task, using the analyses we performed
in Sections 3 and 4 as motivation for feature definition.
We train a classifier on the development portion of the DERIVBASE 1.4 extended sample (1,780
training instances, cf. Section 2.2). We learn a binary decision: Semantic relatedness (R) vs. non-semantic
relatedness (M, N, C, L) within derivationally related pairs. For classification, we use a nonlinear model:
Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel. Using the RBF kernel allows
us to capture the non-linear dependencies between the features.
4
We rely on LIBSVM (Chang and Lin,
2011), a well-known SVM implementation. We optimize the C and ? hyperparameters of the SVM model
using 3-fold cross-validation on the training data (i.e., the development portion of the extended sample).
5.2 Features
Our analyses motivate three feature groups comprising 35 individual features: Distributional, derivation
rule-based (?structural?), and hybrid features. Table 4 gives a list.
Distributional features. All distributional features apply to the lemma or pair level. They are calculated
from our BOW model with permissive lemmatization (Section 3.1). We use absolute and rank-based cosine
similarity (Section 3.4) as well as the number of shared contexts (computed with LMI, cf. Section 3.3)
and lemma frequency. To speed up processing, we compute the forward rank similarity for a lemma pair
(l
1
, l
2
) not on the complete vocabulary but by pairing l
1
with a random sample of 1,000 lemmas from
DERIVBASE (plus l
2
if it is not included). We do the computation analogously for the backward rank.
4
The nonlinear SVM model outperforms a linear SVM. The difference is 0.8% F-Score, statistically significant at p=0.05.
1734
Feature group Type Feature name Description
(# features) (# features)
Distributio- l Lemma frequency (2) Normalized SDeWaC corpus lemma frequencies
nal (6) p Cosine similarity Standard cosine lemma similarity
p Dimensions shared Number of shared context words
p Cos. rank similarity (2) Rank-based forward and backward similarity
Structural (25) r Rule identity (11) Indicator features for the top ten rules in the dev
set + one aggregate feature for the rest
r Rule reliability Percentage of rule applications on R pairs among
all applications of the rule in dev set
r Rule frequency rank (2) Rank-based rule frequency in DERIVBASE
r Avg. string distance (2) Avg. Levenshtein distance for all rule instances
p POS combinations (6) Indicator features for lemma POS combinations
p Path length Length of the shortest path between the lemmas
p String distance (2) Dice bigram coefficient; Levenshtein distance
Hybrid (4) r Average rank sim (2) Frequency-weighted average rank similarity of
rules on shortest path
p Rank sim deviation (2) Difference between lemma pair rank similarity
and average rule rank similarity
Table 4: Features used to characterize derivationally related lemma pairs. ?Type? indicates the level at
which each feature applies: l lemma level, p pair level, r rule level.
Structural features. The structural features encode properties of the rules and paths in DERIVBASE.
Most features apply to the level of derivation rules. This includes the identity of the rule; its reliability
(estimated as the ratio of its application on R pairs among all its applications on the dev set); its frequency
rank among all rules (as a measure of specificity)
5
; and the average Levenshtein distance between the
input and output lemmas (estimating rule complexity by measuring the amount of string modification).
For lemma pairs linked by complex paths (i.e., more than one rule, cf. Figure 1), the question arises
how the rule-level features should be computed. Following our observations on ?weakest link? behavior
in Section 4, we always combine the feature values for the individual rules adopting the most pessimistic
combination function (e.g., minimum in the case of reliability, maximum in the case of frequency rank).
Three more structural features are computed directly at the lemma pair level: their part of speech
combination (e.g., ?NV? for oxide
N
? oxidate
V
), the length of the shortest path connecting them, and the
Levenshtein and Dice string distances between the two lemmas.
Hybrid features. Hybrid features combine rule-based and distributional information to avoid their
respective shortcomings. We work with two hybrid features, one at rule level and one at pair level. The
rule-level feature models the reliability of the rule. It is the average rank similarity for each rule (computed
as a log frequency-weighted average over rule instances). This feature is a counterpart to rule reliability
that is unsupervised in that it does not require class labels. We compute it by randomly drawing 200
lemma pairs for each rule from DERIVBASE (less if the rule has fewer instances). The pair-level feature
is the difference between the rule?s average rank similarity and the rank similarity for the current pair. It
measures the rank of a pair relative to the rule?s ?baseline? rank and indicates how similar and dissimilar
lemma pairs are compared to the rule average. In parallel to the structural features, values for complex
rule paths are computed by minimum. Since the rank similarity is directional, we compute both hybrid
features in two variants, one for each direction.
6
5
We compute this feature once only on simplex paths and once on all instances of the rule in DERIVBASE, trading reliability
against noise.
6
We also tested hybrid features based on raw cosine; however, this yielded worse results than the rank-based hybrid features.
1735
Validation method Precision Recall F
1
Accuracy
Majority baseline 72.6 100 84.1 72.6
Classifier, only ?cosine similarity? feature 72.6 100 84.1 72.6
Classifier only ?similarity rank? feature 80.3 90.3 85.0 76.8
Classifier, only ?rule identity? feature 73.7 99.5 84.6 73.8
Classifier, hybrid group 80.4 95.3 87.2 79.7
Classifier, distributional group 80.5 96.6 87.8 80.5
Classifier, structural group 82.7 93.1 87.6 80.9
Classifier, hybrid + distributional groups 82.6 93.3 87.6 80.9
Classifier, hybrid + structural groups 84.9 93.7 89.1 83.4
Classifier, distributional + structural groups 85.3 94.6 89.7 84.3
Classifier, all features 86.2 93.9 89.9 84.7
Table 5: Accuracy, precision, recall, and F
1
on the test portion of the DERIVBASE 1.4 extended sample.
5.3 Results and Discussion
We applied the trained classifier to the test portion of the DERIVBASE 1.4 extended sample (cf. Section 2.2).
Table 5 summarizes precision, recall, and F
1
-score of the classifier for various combinations of features
and feature groups. Recall that since our motivation is semantic validation, i.e., the removal of false
positives, we are in particular interested in improving the precision of our predictions. We test significance
of F
1
differences among models with bootstrap resampling (Efron and Tibshirani, 1993).
Our baseline is the majority class in the sample, R. Due to the sample?s skewed class distribution (cf.
Table 2), the frequency baseline is quite high (precision 72.6, F
1
-score 84.1). We next consider the three
most prominent individual features: Distributional similarity measured as cosine, distributional similarity
measured as similarity rank, and rule identity. As expected from our analyses, the cosine similarity on
its own is not reliable; in fact, it performs at baseline level. The rank-based similarity already leads to a
considerable gain (precision +7.7%), but only a slight F
1
-score increase of 0.9% that is not statistically
significant at p=0.05. These results provide good empirical evidence for Hypothesis 1? (Section 3.4)
and underscore that 1? is a more accurate statement than Hypothesis 1 (Section 2.3). On the structural
side, rule identity alone improves the precision by 1.1%, with an F
1
-score increase in 0.5% (again not
significant).
We now proceed to complete feature groups, all of which perform at least 3% F
1
-score better than the
baseline, proving that the features within these groups are complementary. The hybrid feature group is the
worst among the three. The distributional feature group is able to improve only slightly over the individual
rank-based similarity feature in precision (80.5 vs. 80.3), but gains 6.3% in recall. This is sufficient for
a significant improvement in F
1
(+3.7%, significant at p=0.01). The structural feature group performs
surprisingly well, given that these features are very simple and most are computed only on the relatively
small training set. It yields by far the highest precision (82.7), and its F
1
-score is only slightly lower than
the one of the distributional group (87.6 vs. 87.8). We take this as further evidence for the usefulness of
structural information, as expressed by Hypothesis 2 (cf. Section 2.3).
Ultimately, all three feature groups turn out to be complementary. We obtain an improvement in
F
1
-score for two out of the three feature group combinations, and a clear improvement in precision in all
cases. Finally, the best overall result is shown by the combination of all three feature groups. It attains an
F
1
-score of 89.9, an improvement of 5.8% over the baseline and 2.1% over the best feature group (both
differences significant at p=0.01). Crucially, this model gains over 13% in precision while losing only 6%
of recall compared to the baseline. This corresponds to a reduction of false positives in the sample by
about half (from 27% to 14%) while the true positives were reduced only by 5% (from 73% to 68%).
Table 6 shows a breakdown of the predictions by the best model in terms of the five gold standard classes
1736
R M N L C total
Gold annotation 554 81 81 45 2 763
Classified as R 520 36 16 29 2 603
Classified as not R 34 45 65 16 0 160
Table 6: Predictions on the test set of the all features Classifier per annotation class.
(R, M, N, L, C). Ignoring compounds (C), of which there are too few cases to analyze, we first find that
the classifier achieves a high R recall. It is also very good in filtering out unrelated cases (N), of which it
discards around 80%. The model recognizes morphologically but not semantically related word pairs (M)
fairly well and manages to remove more than half of these. It has the hardest time with lemmatization
errors (L), of which only about 35% were removed. However, this is not surprising: Lemmatization errors
do not form a coherent category that would be easy to retrieve with the kinds of features that we have
developed. We believe that such errors should be handled in an earlier stage, i.e., during preprocessing.
6 Related Work
Given that many derivational lexicons were only developed in recent years, we are only aware of one study
(Jacquemin, 2010) that semantically validates the output of an existing derivational lexicon (Gaussier,
1999) to apply it to Question Answering. In contrast to our study, it requires elaborate dictionary
information to look up which derivations are permitted for a specific lemma, as well as word sense
disambiguation to determine the meaning of ambiguous words in context. Other related work comes from
two areas: unsupervised morphology induction and semantic clustering.
Unsupervised morphology induction is concerned with the automatic identification of morphological
relations (cf. Hammarstr?om and Borin (2011) for an overview). Most approaches in this area do not differ-
entiate between the inflectional and derivational level of morphology (Gaussier (1999) is an exception)
and restrict themselves to the string level. Only a small number of studies (Schone and Jurafsky, 2000;
Baroni et al., 2002) take distributional information into account.
Semantic clustering is the task of inducing semantic classes from (broadly speaking) distributional
information (Turney and Pantel, 2010; im Walde, 2006). Boleda et al. (2012) include derivational
properties in their feature set to learn Catalan adjective classes. However, the input to such studies is
almost always a set of words from the same part of speech with no prior morphological constraints, while
our input lemmas are morphologically preselected (via derivational rules), are often extremely infrequent,
and exhibit systematical variation in parts of speech. To our knowledge, this challenging situation has not
been addressed in previous studies.
Recent work has also considered the opposite problem, namely using derivational morphology for
improving distributional similarity predictions. Luong et al. (2013) use recursive neural networks to learn
representations of morphologically complex words and demonstrate the usefulness of their approach
on word similarity tasks across different datasets. Similarly, Lazaridou et al. (2013) improve the word
representations of derivationally related words by composing vector space representations of stems and
derivational suffixes.
7 Conclusions
Almost all existing derivational lexicons do not distinguish between only morphologically related words
on one hand and words that are both morphologically and semantically related words on the other hand.
In this paper, we have addressed the task of recovering this distinction and called it semantic validation.
We have used DERIVBASE, a German derivation lexicon, as the basis of our investigation.
We have made two contributions: (a) providing a detailed analysis of the types of information available
for this task (distributional similarity as well as structural information about derivation rules) and the prob-
lems associated with each information type; and (b) training a machine learning classifier on linguistically
1737
motivated features. The classifier, although not perfect, can substantially improve the precision of the
word pairs in DERIVBASE and thus help to filter the derivational families in the lexicon. We are making
this semantic validation information available in the DERIVBASE lexicon by attaching a probability for
the class R to each lemma pair (see footnote 1 for the DERIVBASE URL).
The approach that we have described should transfer straightforwardly to other derivational lexicons
and other languages on the conceptual level. The practical requirements are an appropriate corpus (for the
distributional features) and derivational rule information (for the structural features).
There are two clear directions for future work. First, we plan to broaden our attention from word pairs
to clusters and use the relatedness probabilities to cluster the derivational families in DERIVBASE into
semantically coherent subfamilies. Second, we will demonstrate the impact of semantic validation on
applications of derivational knowledge such as derivation-driven smoothing of distributional models (Pad?o
et al., 2013).
Acknowledgments. We gratefully acknowledge partial funding by the European Commission (project
EXCITEMENT (FP7 ICT-287923), first and second authors) as well as the Croatian Science Foundation
(project 02.03/162: ?Derivational Semantic Models for Information Retrieval?, third author). We thank
the reviewers for their valuable feedback.
References
Harald R. Baayen, Richard Piepenbrock, and Leon Gulikers. 1996. The CELEX Lexical Database. Release 2.
LDC96L14. Linguistic Data Consortium, University of Pennsylvania, Philadelphia, Pennsylvania.
Marco Baroni, Johannes Matiasek, and Harald Trost. 2002. Unsupervised Discovery of Morphologically Related
Words Based on Orthographic and Semantic Similarity. Computing Research Repository, cs.CL/0205006.
Edwin L. Battistella. 1996. The Logic of Markedness. Oxford University Press.
Orhan Bilgin, Ozlem C?etino?glu, and Kemal Oflazer. 2004. Morphosemantic relations in and across Wordnets. In
Proceedings of the Global Wordnet Conference, pages 60?66, Brno, Czech Republic.
Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the
International Conference on Computational Linguistics, pages 89?97, Beijing, China.
Gemma Boleda, Sabine Schulte im Walde, and Toni Badia. 2012. Modeling Regular Polysemy: A Study on the
Semantic Classification of Catalan Adjectives. Computational Linguistics, 38(3):575?616.
John A. Bullinaria and Joe P. Levy. 2007. Extracting Semantic Representations from Word Co-occurrence Statis-
tics: A Computational Study. Behavior Research Methods, 39(3):510?526.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions
on Intelligent Systems Technology, 2(3):27:1?27:27.
Bradley Efron and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman and Hall, New York.
Stefan Evert. 2005. The Statistics of Word Cooccurrences Word Pairs and Collocations. Ph.D. thesis, University
of Stuttgart.
Gertrud Faa?, Ulrich Heid, and Helmut Schmid. 2010. Design and Application of a Gold Standard for Morpholog-
ical Analysis: SMOR in Validation. In Proceedings of the Conference on Language Resources and Evaluation,
pages 803?810, Valletta, Malta.
Christiane Fellbaum, Anne Osherson, and Peter Clark. 2009. Putting semantics into WordNet?s ?morphosemantic?
links. In Proceedings of Human Language Technology. Challenges of the Information Society, pages 350?358,
Pozna?n, Poland.
?
Eric Gaussier. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL
Workshop Proceedings on Unsupervised Learning in Natural Language Processing, pages 24?30, College Park,
Maryland.
Nizar Habash and Bonnie Dorr. 2003. A categorial variation database for English. In Proceedings of the North
American Association for Computational Linguistics, pages 96?102, Edmonton, Canada.
1738
Harald Hammarstr?om and Lars Borin. 2011. Unsupervised Learning of Morphology. Computational Linguistics,
37(2):309?350.
Mary Hare, Michael Jones, Caroline Thomson, Sarah Kelly, and Ken McRae. 2009. Activating Event Knowledge.
Cognition, 111(2):151?167.
Sabine Schulte im Walde. 2006. Experiments on the Automatic Induction of German Semantic Verb Classes.
Computational Linguistics, 32(2):159?194.
Bernard Jacquemin. 2010. A derivational rephrasing experiment for question answering. In Proceedings of the
Conference on Language Resources and Evaluation, pages 2380?2387, Valletta, Malta.
Lauri Karttunen and Kenneth R. Beesley. 2005. Twenty-five Years of Finite-state Morphology. In Inquiries into
Words, Constraints and Contexts. Festschrift for Kimmo Koskenniemi on his 60th Birthday, pages 71?83. CSLI
Publications, Stanford, California.
Gabriella Lapesa and Stefan Evert. 2013. Evaluating neighbor rank and distance measures as predictors of se-
mantic priming. In Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, pages
66?74, Sofia, Bulgaria.
Angeliki Lazaridou, Marco Marelli, Roberto Zamparelli, and Marco Baroni. 2013. Compositional-ly derived rep-
resentations of morphologically complex words in distributional semantics. In Proceedings of the Association
for Computational Linguistics, pages 1517?1526, Sofia, Bulgaria.
Dekang Lin. 1998. An information-theoretic definition of similarity. In Proceedings of the International Confer-
ence on Machine Learning, ICML, pages 296?304, San Francisco, California.
Minh-Thang Luong, Richard Socher, and Christopher D. Manning. 2013. Better word representations with recur-
sive neural networks for morphology. In Proceedings of the Conference on Natural Language Learning, pages
104?113, Sofia, Bulgaria.
Sebastian Pad?o, Jan
?
Snajder, and Britta Zeller. 2013. Derivational smoothing for syntactic distributional semantics.
In Proceedings of the Association for Computational Linguistics, pages 731?735, Sofia, Bulgaria.
Karel Pala and Dana Hlav?a?ckov?a. 2007. Derivational relations in Czech wordnet. In Proceedings of the Workshop
on Balto-Slavonic Natural Language Processing: Information Extraction and Enabling Technologies, pages
75?81, Prague, Czech Republic.
Martin Porter. 1980. An Algorithm for Suffix Stripping. Program, 14(3):130?137.
Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the Interna-
tional Conference on Natural Language Processing, Manchester, UK.
Patrick Schone and Daniel Jurafsky. 2000. Knowledge-free induction of morphology using latent semantic analy-
sis. In Proceedings of the Conference on Natural Language Learning, pages 67?72. Lisbon, Portugal.
Eyal Shnarch, Jacob Goldberger, and Ido Dagan. 2011. A probabilistic modeling framework for lexical entailment.
In Proceedings of the Annual Meeting of the Association for Computational Linguistics: Human Language
Technologies, pages 558?563, Portland, Oregon.
Jan
?
Snajder and Bojana Dalbelo Ba?si?c. 2010. A computational model of Croatian derivational morphology. In
Proceedings of the International Conference on Formal Approaches to South Slavic and Balkan Languages,
pages 109?118, Dubrovnik, Croatia.
Pavol
?
Stekauer and Rochelle Lieber, editors. 2005. Handbook of Word-Formation, volume 64 of Studies in Natural
Language and Linguistic Theory. Springer.
Peter D. Turney and Patrick Pantel. 2010. From Frequency to Meaning: Vector Space Models of Semantics.
Journal of Artificial Intelligence Research, 37(1):141?188.
Britta Zeller, Jan
?
Snajder, and Sebastian Pad?o. 2013. DErivBase: Inducing and evaluating a derivational mor-
phology resource for German. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics, pages 1201?1211, Sofia, Bulgaria.
1739
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201?1211,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
DERIVBASE: Inducing and Evaluating a
Derivational Morphology Resource for German
Britta Zeller? Jan ?najder? Sebastian Pad??
?Heidelberg University, Institut f?r Computerlinguistik
69120 Heidelberg, Germany
?University of Zagreb, Faculty of Electrical Engineering and Computing
Unska 3, 10000 Zagreb, Croatia
{zeller, pado}@cl.uni-heidelberg.de jan.snajder@fer.hr
Abstract
Derivational models are still an under-
researched area in computational morphol-
ogy. Even for German, a rather resource-
rich language, there is a lack of large-
coverage derivational knowledge. This pa-
per describes a rule-based framework for
inducing derivational families (i.e., clus-
ters of lemmas in derivational relation-
ships) and its application to create a high-
coverage German resource, DERIVBASE,
mapping over 280k lemmas into more than
17k non-singleton clusters. We focus on the
rule component and a qualitative and quan-
titative evaluation. Our approach achieves
up to 93% precision and 71% recall. We
attribute the high precision to the fact that
our rules are based on information from
grammar books.
1 Introduction
Morphological processing is generally recognized
as an important step for many NLP tasks. Morpho-
logical analyzers such as lemmatizers and part of
speech (POS) taggers are commonly the first NLP
tools developed for any language (Koskenniemi,
1983; Brill, 1992). They are also applied in NLP
applications where little other linguistic analysis is
performed, such as linguistic annotation of corpora
or terminology acquisition; see Daille et al (2002)
for an informative summary.
Most work on computational morphology has
focused on inflectional morphology, that is, the
handling of grammatically determined variation of
form (Bickel and Nichols, 2001), which can be
understood, overimplifying somewhat, as a normal-
ization step. Derivational morphology, which is
concerned with the formation of new words from
existing ones, has received less attention. Exam-
ples are nominalization (to understand? the un-
derstanding), verbalization (the shelf ? to shelve),
and adjectivization (the size ? sizable). Part of
the reason for the relative lack of attention lies in
the morphological properties of English, such as
the presence of many zero derivations (the fish?
to fish), the dominance of suffixation, and the rel-
ative absence of stem changes in derivation. For
these reasons, simple stemming algorithms (Porter,
1980) provide a cheap and accurate approximation
to English derivation.
Two major NLP resources deal with derivation.
WordNet lists so-called ?morphosemantic? rela-
tions (Fellbaum et al, 2009) for English, and a
number of proposals exist for extending WordNets
in other languages with derivational relations (Bil-
gin et al, 2004; Pala and Hlav?c?kov?, 2007). Cat-
Var, the ?Categorial Variation Database of English?
(Habash and Dorr, 2003), is a lexicon aimed specif-
ically at derivation. It groups English nouns, verbs,
adjectives, and adverbs into derivational equiva-
lence classes or derivational families such as
askV askerN askingN askingA
Derivational families are commonly understood as
groups of derivationally related lemmas (Daille et
al., 2002; Milin et al, 2009). The lemmas in CatVar
come from various open word classes, and multiple
words may be listed for the same POS. The above
family lists two nouns: an event noun (asking) and
an agentive noun (asker). However, CatVar does
not consider prefixation, which is why, e.g., the
adjective unasked is missing.
CatVar has found application in different areas
of English NLP. Examples are the acquisition of
paraphrases that cut across POS lines, applied, for
example, in textual entailment (Szpektor and Da-
gan, 2008; Berant et al, 2012). Then there is the
induction and extension of semantic roles resources
for predicates of various parts of speech (Meyers et
al., 2004; Green et al, 2004). Finally, CatVar has
1201
been used as a lexical resource to generate sentence
intersections (Thadani and McKeown, 2011).
In this paper, we describe the project of obtain-
ing derivational knowledge for German to enable
similar applications. Even though there are two
derivational resources for this language, IMSLEX
(Fitschen, 2004) and CELEX (Baayen et al, 1996),
both have shortcomings. The former does not ap-
pear to be publicly available, and the latter has a
limited coverage (50k lemmas) and does not ex-
plicitly represent derivational relationships within
families, which are necessary for fine-grained op-
timization of families. For this reason, we look
into building a novel derivational resource for Ger-
man. Unfortuantely, the approach used to build
CatVar cannot be adopted: it builds on a collection
of high-quality lexical-semantic resources such as
NOMLEX (Macleod et al, 1998), which are not
available for German.
Instead, we employ a rule-based framework to
define derivation rules that cover both suffixation
and prefixation and describes stem changes. Fol-
lowing the work of ?najder and Dalbelo Ba?ic?
(2010), we define the derivational processes using
derivational rules and higher-order string transfor-
mation functions. The derivational rules induce
a partition of the language?s lemmas into deriva-
tional families. Our method is applicable to many
languages if the following are available: (1) a com-
prehensive set of lemmas (optionally including gen-
der information); (2) knowledge about admissible
derivational patterns, which can be gathered, for
example, from linguistics textbooks.
The result is a freely available high-precision
high-coverage resource for German derivational
morphology that has a structure parallel to Cat-
Var, but was obtained without using manually con-
structed lexical-semantic resources. We conduct
a thorough evaluation of the induced derivational
families both regarding precision and recall.
Plan of the paper. Section 2 discusses prior
work. Section 3 defines our derivation model that
is applied to German in Section 4. Sections 5 and
6 present our evaluation setup and results. Section
7 concludes the paper and outlines future work.
2 Related Work
Computational models of morphology have a long
tradition. Koskenniemi (1983) was the first who
analyzed and generated morphological phenomena
computationally. His two-level theory has been
applied in finite state transducers (FST) for several
languages (Karttunen and Beesley, 2005).
Many recent approaches automatically induce
morphological information from corpora. They
are either based solely on corpus statistics (D?jean,
1998), measure semantic similarity between input
and output lemma (Schone and Jurafsky, 2000),
or bootstrap derivation rules starting from seed ex-
amples (Piasecki et al, 2012). Hammarstr?m and
Borin (2011) give an extensive overview of state-
of-the-art unsupervised learning of morphology.
Unsupervised approaches operate at the level of
word-forms and have complementary strengths and
weaknesses to rule-based approaches. On the up-
side, they do not require linguistic knowledge; on
the downside, they have a harder time distinguish-
ing between derivation and inflection, which may
result in lower precision, and are not guaranteed
to yield analyses that correspond to linguistic intu-
ition. An exception is the work by Gaussier (1999),
who applies an unsupervised model to construct
derivational families for French.
For German, several morphological tools exist.
Morphix is a classification-based analyzer and gen-
erator of German words on the inflectional level
(Finkler and Neumann, 1988). SMOR (Schmid
et al, 2004) employs a finite-state transducer to
analyze German words at the inflectional, deriva-
tional, and compositional level, and has been used
in other morphological analyzers, e.g., Morphisto
(Zielinski and Simon, 2008). The site canoonet1 of-
fers broad-coverage information about the German
language including derivational word formation.
3 Framework
In this section, we describe our rule-based model of
derivation, its operation to define derivational fam-
ilies, and the application of the model to German.
We note that the model is purely surface-based,
i.e., it does not model any semantic regularities be-
yond those implicit in string transformations. We
begin by outlining the characteristics of German
derivational morphology.
3.1 German Derivational Morphology
As German is a morphologically complex language,
we analyzed its derivation processes before imple-
menting our rule-based model. We relied on tradi-
tional grammar books and lexicons, e.g., Hoeppner
(1980) and Augst (1975), in order to linguistically
1http://canoo.net
1202
justify our assumptions as well as to achieve the
best possible precision and coverage.
We concentrate on German derivational pro-
cesses that involve nouns, verbs, and adjectives.2
Nouns are simple to recognize due to capitaliza-
tion: stauenV ? StauN (to jam ? jam), essenV ?
EssenN (to eat ? food). Verbs bear three typical
suffixes (-en, -eln, -ern). An example of a derived
verb is festA ? festigenV (tight ? to tighten), where
-ig is the derivational suffix. Adjectivization works
similarlty: TagN ? t?glichA (day ? daily).
This example shows that derivation can also in-
volve stem changes in the form of umlaut (e.g.,
a ? ?) and ablaut shift, e.g., siedenV ? SudN
(to boil ? infusion). Other frequent processes
in German derivation are circumfixation (HaftN
? inhaftierenV (arrest ? to arrest)) and prefixation
(hebenV ? behebenV (to raise ? to remedy)). Pre-
fixation often indicates a semantic shift, either in
terms of the general meaning (as above) or in terms
of the polarity ( klarA ? unklarA (clear ? unclear)).
Also note that affixes can be either Germanic, e.g.,
?len ? ?lung (to oil ? oiling), or Latin/Greek, e.g.,
generieren ? Generator (to generate ? generator).
As this analysis shows, derivation in German
involves transformation as well as affixation pro-
cesses, which has to be taken into account when
modeling a derivational resource.
3.2 A Rule-based Derivation Model
The purpose of a derivational model is to define
a set of transformations that correspond to valid
derivational word formation rules. Rule-based
frameworks offer convenient representations for
derivational morphology because they can take ad-
vantage of linguistic knowledge about derivation,
have interpretable representations, and can be fine-
tuned for high precision. The choice of the frame-
work is in principle arbitrary, as long as it can con-
veniently express the derivational phenomena of
a language. Typically used for this purpose are
two-level formalism rules (Karttunen and Beesley,
1992) or XFST replace rules (Beesley and Kart-
tunen, 2003).
In this paper, we adopt the modeling framework
proposed by ?najder and Dalbelo Ba?ic? (2010).
The framework corresponds closely to simple,
human-readable descriptions in traditional gram-
2We ignore adverb derivation; the German language dis-
tinguishes between adverbial adjectives and adverbs, the latter
being a rather unproductive class and thus of no interest for
derivation (Schiller et al, 1999).
mar books. The expressiveness of the formalism
is equivalent to the replacement rules commonly
used in finite state frameworks, thus the rules can
be compiled into FSTs for efficient processing.
The framework makes a clear distinction be-
tween inflectional and derivational morphology and
provides separate modeling components for these
two; we only make use of the derivation modeling
component. We use an implementation of the mod-
eling framework in Haskell. For details, see the
studies by ?najder and Dalbelo Ba?ic? (2008) and
?najder and Dalbelo Ba?ic? (2010).
The building blocks of the derivational compo-
nent are derivational rules (patterns) and transfor-
mation functions. A derivational rule describes the
derivation of a derived word from a basis word. A
derivational rule d is defined as a triple:
d = (t,P1,P2) (1)
where t is the transformation function that maps
the word?s stem (or lemma) into the derived word?s
stem (or lemma), while P1 and P2 are the sets of
inflectional paradigms of the basis word and the
derived word, respectively, which specify the mor-
phological properties of the rule?s input and output.
For German, our study assumes that inflectional
paradigms are combinations of part-of-speech and
gender information (for nouns).
A transformation function t : S ? ?(S) maps
strings to a set of strings, representing possible
transformations. At the lowest level, t is defined
in terms of atomic string replacement operations
(replacement of prefixes, suffixes, and infixes). The
framework then uses the notion of higher-order
functions ? functions that take other transforma-
tions as arguments and return new transformations
as results ? to succinctly define common deriva-
tional processes such as prefixation, suffixation,
and stem change. More complex word-formation
rules, such as those combining prefixation and suf-
fixation, can be obtained straightforwardly by func-
tional composition.
Table 1 summarizes the syntax we use for trans-
formation functions and shows two example deriva-
tional rules. Rule 1 defines an English adjectiviza-
tion rule. It uses the conditional try operator to
apply to nouns with and without the -ion suffix
(action ? active, instinct ? instinctive). Infix re-
placement is used to model stem alternation, as
shown in rule 2 for German nominalization, e.g.,
vermachtA ? Verm?chtnisN (bequethed ? bequest).
1203
Function Description
sfx (s) concatenate the suffix s
dsfx (s) delete the suffix s
aifx (s1, s2) alternate the infix s1 to s2
try(t) perform transformation t, if possible
opt(t) optionally perform transformation t
uml alternate infixes for an umlaut shift:
uml = aifx ({(a, ?), (o, ?), (u, ?)})
Examples
1 (EN) (sfx (ive) ? try(dsfx (ion)),N ,A)
?derive -ive adjectives from nouns poten-
tially ending in -ion?
2 (DE) (sfx (nis) ? try(uml),A,N )
?derive -nis nouns from adjectives with
optional umlaut creation?
Table 1: Transformation functions and exemplary
derivational rules in the framework by ?najder and
Dalbelo Ba?ic? (2010)
N and A denote the paradigms for nouns (without
gender restriction) and adjectives, respectively.
3.3 Induction of Derivational Families
Recall that our goal is to induce derivational fami-
lies, that is, classes of derivationally related words.
We define derivational families on the basis of
derivational rules as follows.
Given a lemma-paradigm pair (l, p) as input,
a single derivational rule d = (t,P1,P2) gen-
erates a set of possible derivations Ld(l, p) =
{(l1, p1), . . . , (ln, pn)}, where p ? P1 and pi ? P2
for all i. Given a set of derivational rules D, we de-
fine a binary derivation relation?D between two
lemma-paradigm pairs that holds if the second pair
can be derived from the first one as:
(l1, p1)?D (l2, p2) (2)
iff ?d ? D. (l2, p2) ? Ld(l1, p1)
Let L denote the set of lemma-paradigm pairs. The
set of derivational families defined by D on L is
given by the equivalence classes of the transitive,
symmetric, and reflexive closure of?D over L.
Note that in addition to the quality of the rules,
the properties ofL plays a central role in the quality
of the induced families. High coverage of L is im-
portant because the transitivity of?D ranges only
over lemmas in L, so low coverage of L may result
in fragmented derivational families. However, L
should also not contain erroneous lemma-paradigm
pairs. The reason is that the derivational rules only
define admissible derivations, which need not be
morphologically valid, and therefore routinely over-
generate; L plays an important role in filtering out
derivations that are not attested in the data.
4 Building the Resource
4.1 Derivational Rules
We implemented the derivational rules from Hoepp-
ner (1980) for verbs, nouns, and adjectives, cov-
ering all processes described in Section 3.1 (zero
derivation, prefixation, suffixation, circumfixation,
and stem changes). We found many derivational
patterns in German to be conceptually simple (e.g.,
verb-noun zero derivation) so that substantial cov-
erage can already be achieved with very simple
transformation functions. However, there are many
more complex patterns (e.g., suffixation combined
with optional stem changes) that in sum also af-
fect a considerable number of lemmas, which re-
quired us to either implement low-coverage rules
or generalize existing rules. In order to preserve
precision as much as possible, we restricted rule
application by using try instead of opt, and by using
gender information from the noun paradigms (for
example, some rules only apply to masculine nouns
and produce female nouns). As a result, we end
up with high-coverage rules, such as derivations
of person-denoting nouns (SchuleN ? Sch?lerN
(school ? pupil)) as well as high-accuracy rules
such as negation prefixes (PolN ? GegenpolN (pole
? antipole)).
Even though we did not focus on the explana-
tory relevance of rules, we found that the under-
lying modeling formalism, and the methodology
used to develop the model, offer substantial lin-
guistic plausibility in practice. We had to resort to
heuristics mostly for words with derivational trans-
formations that are motivated by Latin or Greek
morphology and do not occur regularly in German,
e.g., selegierenV ? SelektionN (select ? selection).
In the initial development phase, we imple-
mented 154 rules, which took about 22 person-
hours. We then revised the rules with the aim of
increasing both precision and recall. To this end,
we constructed a development set comprised of a
sample of 1,000 derivational families induced us-
ing our rules. On this set, we inspected the deriva-
tional families for false positives, identified the
problematic rules, and identified unused and redun-
dant rules. In order to identify the false negatives,
we additionally sampled a list of 1,000 lemmas and
used string distance measures (cf. Section 5.1) to re-
trieve the 10 most similar words for each lemma not
1204
Process N-N N-A N-V A-A A-V V-V
Zero derivation ? 1 5 ? ? ?
Prefixation 10 ? 5 5 2 9
+ Stem change ? ? 3 ? 1 ?
Suffixation 15 35 20 1 14 ?
+ Stem change 2 8 7 ? 3 1
Circumfixation ? ? 1 ? ? ?
+ Stem change ? ? 1 ? ? ?
Stem change ? ? 7 ? ? 2
Total 27 44 49 6 20 12
Table 2: Breakdown of derivation rules by category
of the basis and the derived word
already covered by the derivational families. The
refinement process took another 8 person-hours. It
revealed three redundant rules and seven missing
rules, leading us to a total of 158 rules.
Table 2 shows the distribution of rules with re-
spect to the derivational processes they implement
and the part of speech combinations for the ba-
sis and the derived words. All affixations occur
both with and without stem changes, mostly um-
laut shifts. Suffixation is by far the most frequently
used derivation process, and noun-verb derivation
is most diverse in terms of derivational processes.
We also estimated the reliability of derivational
rules by analyzing the accuracy of each rule on
the development set. We assigned each rule a con-
fidence rating on a three-level scale: L3 ? very
reliable (high-accuracy rules), L2 ? generally reli-
able, and L1 ? less reliable (low-accuracy rules).
We manually analyzed the correctness of rule ap-
plications for 100 derivational families of different
size (counting 2 up to 114 lemmas), and assigned
55, 79, and 24 rules to L3, L2 and L1, respectively.
4.2 Data and Preprocessing
For an accurate application of nominal derivation
rules, we need a lemma list with POS and gender
information. We POS-tag and lemmatize SDEWAC,
a large German-language web corpus from which
boilerplate paragraphs, ungrammatical sentences,
and duplicate pages were removed (Faa? et al,
2010). For POS tagging and lemmatization, we use
TreeTagger (Schmid, 1994) and determine gram-
matical gender with the morphological layer of
the MATE Tools (Bohnet, 2010). We treat proper
nouns like common nouns.
We apply three language-specific filtering steps
based on observations in Section 3.1. First, we dis-
card non-capitalized nominal lemmas. Second, we
deleted verbal lemmas not ending in verb suffixes.
Third, we removed frequently occurring erroneous
comparative forms of adjectives (usually formed
by adding -er, like neuer / newer) by checking for
the presence of lemmas without -er (neu / new).
An additional complication in German concerns
prefix verbs, because prefix is separated in tensed
instances. For example, the 3rd person male singu-
lar of aufh?ren (to stop) is er h?rt auf (he stops).
Since most prefixes double as prepositions, the cor-
rect lemmas can only be reconstructed by parsing.
We parse the corpus using the MST parser (Mc-
Donald et al, 2006) and recover prefix verbs by
searching for instances of the dependency relation
labeled PTKVZ.
Since SDEWAC, as a web corpus, still contains
errors, we only take into account lemmas that occur
three times or more in the corpus. Considering the
size of SDEWAC, we consider this as a conservative
filtering step that preserves high recall and provides
a comprehensive basis for evaluation. After prepro-
cessing and filtering, we run the induction of the
derivational families as explained in Section 3 to
obtain the DERIVBASE resource.
4.3 Statistics on DERIVBASE
The preparation of the SDEWAC corpus as ex-
plained in Section 4.2 yields 280,336 lemmas,
which we cover with our resource. We induced
a total of 239,680 derivational families from this
data, with 17,799 non-singletons and 221,881 sin-
gletons (most of them due to compound nouns).
11,039 of the families consist of two lemmas, while
the biggest contains 116 lemmas (an overgenerated
family). The biggest family with perfect precision
(i.e., it contains only morphologically related lem-
mas) contains 40 lemmas, e.g., haltenV , erhaltenV ,
Verh?ltnisN (to hold, to uphold, relation), etc. For
comparison, CatVar v2.1 contains only 82,676 lem-
mas in 13,368 non-singleton clusters and 38,604
singletons.
The following sample family has seven members
across all three POSes and includes prefixation,
suffixation, and infix umlaut shifts:
taubA (numbA), TaubheitNf (numbnessN ),
bet?ubenV (to anesthetizeV ), Bet?ubungNf
(anesthesiaN ), bet?ubtA (anesthetizedA),
bet?ubendA (anestheticA), Bet?ubenNn
(act of anesthetizingN )
1205
5 Evaluation
5.1 Baselines
We use two baselines against which we compare
the induced derivational families: (1) clusters ob-
tained with the German version of Porter?s stem-
mer (Porter, 1980)3 and (2) clusters obtained us-
ing string distance-based clustering. We have con-
sidered a number of string distance measures and
tested them on the development set (cf. Section
4.1). The measure proposed by Majumder et al
(2007) turned out to be the most effective in cap-
turing suffixal variation. For words X and Y , it is
defined as
D4(X,Y ) =
n?m+ 1
n+ 1
n?
i=m
1
2i?m (3)
where m is the position of left-most character mis-
match, and n + 1 is the length of the longer of
the two strings. To capture prefixal variation and
stem changes, we use the n-gram based measure
proposed by Adamson and Boreham (1974):
Dicen(X,Y ) = 1?
2c
x+ y (4)
where x and y are the total number of distinct n-
grams inX and Y , respectively, and c is the number
of distinct n-grams shared by both words. In our
experiments, the best performance was achieved
with n = 3.
We used hierarchical agglomerative clustering
with average linkage. To reduce the computational
complexity, we performed a preclustering step by
recursively partitioning the set of lemmas sharing
the same prefix into partitions of manageable size
(1000 lemmas). Initially, we set the number of clus-
ters to be roughly equal to the number of induced
derivational families. For the final evaluation, we
optimized the number of clusters based on F1 score
on calibration and validation sets (cf. Section 5.3).
5.2 Evaluation Methodology
The induction of derivational families could be eval-
uated globally as a clustering problem. Unfortu-
nately, cluster evaluation is a non-trivial task for
which there is no consensus on the best approach
(Amig? et al, 2009). We decided to perform our
evaluation at the level of pairs: we manually judge
for a set of pairs whether they are derivationally
related or not.
3http://snowball.tartarus.org
We obtain the gold standard for this evaluation
by sampling lemmas from the lemma list. With ran-
dom sampling, the evaluation would be unrealistic
because a vast majority of pairs would be deriva-
tionally unrelated and count as true negatives in our
analysis. Moreover, in order to reliably estimate the
overall precision of the obtained derivational fam-
ilies, we need to evaluate on pairs sampled from
these families. On the other hand, in order to assess
recall, we need to sample from pairs that are not
included in our derivational families.
To obtain reliable estimates of both precision
and recall, we decided to draw two different sam-
ples: (1) a sample of lemma pairs sampled from
the induced derivational families, on which we
estimate precision (P-sample) and (2) a sample
of lemma pairs sampled from the set of possibly
derivationally related lemma pairs, on which we
estimate recall (R-sample). In both cases, pairs
(l1, l2) are sampled in two steps: first a lemma l1
is drawn from a non-singleton family, then the sec-
ond lemma l2 is drawn from the derivational family
of l1 (P-sample) or the set of lemmas possibly re-
lated to l1 (R-sample). The set of possibly related
lemmas is a union of the derivational family of l1,
the clusters of l1 obtained with the baseline meth-
ods, and k lemmas most similar to l1 according to
the two string distance measures. We use k = 7
in our experiments. This is based on preliminary
experiments on the development set (cf. Section
4.1), which showed that k = 7 retrieves about 92%
of the related lemmas retrieved for k = 20 with
a much smaller number of true negatives. Thus,
the evaluation on the R-sample might overestimate
the recall, but only slightly so, while the P-sample
yields a reliable estimate of precision by reducing
the number of true negatives in the sample.
Both samples contain 2400 lemma pairs each.
Lemmas included in the development set (Sec-
tion 4.1) were excluded from sampling.
5.3 Gold Standard Annotation
Two German native speakers annotated the pairs
from the P-sample and R-samples. We defined five
categories into which all lemma pairs are classified
as shown in Table 3. We count R and M as positives
and N, C, L as negatives (cf. Section 3).4 Note
that this binary distinction would be sufficient to
compute recall and precision. However, the more
4Ambiguous lemmas are categorized as positive (R or M)
if there is a matching sense.
1206
Label Description Example
R l1 and l2 are morphologi-
cally and semantically re-
lated
kratzigA ? verkratztA(scratchy ? scuffed)
M l1 and l2 are morphologi-
cally but not semantically
related
bombenV ? bombigA(to bomb ? smashing)
N no morphological relation belebtA ? lobenV
(lively ? to praise)
C no derivational relation,
but the pair is composi-
tionally related
FilmendeN ? filmenV(end of film ? to film)
L not a valid lemma (mis-
lemmatization, wrong
gender, foreign words)
HaufeN ? H?ufungN(N/A ? accumulation)
Table 3: Categories for lemma pair classification
Agreement Cohen?s ?
R-sample 0.85 0.79
P-sample 0.86 0.70
Table 4: Inter-annotator agreement on validation
sample
fine-grained five-class annotation scheme provides
a more detailed picture. The separation between R
and M gives a deeper insight into the semantics of
the derivational families. Distinguishing between
C and N, in turn, allows us to identify the pairs that
are derivationally unrelated, but compositionally
related, e.g., EhemannN ? EhefrauN (husband ?
wife).
We first carried out a calibration phase in which
the annotators double-annotated 200 pairs from
each of the two samples and refined the annotation
guidelines. In a subsequent validation phase, we
computed inter-annotator agreements on the anno-
tations of another 200 pairs each from the P- and
the R-samples. Table 4 shows the proportion of
identical annotations by both annotators as well as
Cohen?s ? score (Cohen, 1968). We achieve sub-
stantial agreement for ? (Carletta, 1996). On the
P-sample, ? is a little lower because the distribu-
tion of the categories is skewed towards R, which
makes an agreement by chance more probable.
In our opinion, the IAA results were sufficiently
high to switch to single annotation for the produc-
tion phase. Here, each annotator annotated another
1000 pairs from the P-sample and R-sample so
that the final test set consists of 2000 pairs from
each sample. The P-sample contains 1663 positive
(R+M) and 337 negative (N+C+L) pairs, respec-
tively, the R-sample contains 575 positive and 1425
negative pairs. As expected, there are more positive
Precision Recall
Method P-sample R-sample
DERIVBASE (initial) 0.83 0.58
DERIVBASE-L123 0.83 0.71
DERIVBASE-L23 0.88 0.61
DERIVBASE-L3 0.93 0.35
R-sample
Stemming 0.66 0.07
String distance D4 0.36 0.20
String distance Dice3 0.23 0.23
Table 5: Precision and recall on test samples
pairs in the P-sample and more negative pairs in
the R-sample.
6 Results
6.1 Quantitative Evaluation
Table 5 presents the overall results. We eval-
uate four variants of the induced derivational
families: those obtained before rule refinement
(DERIVBASE initial), and three variants after rule
refinement: using all rules (DERIVBASE-L123),
excluding the least reliable rules (DERIVBASE-
L23), and using only highly reliable rules
(DERIVBASE-L3).
We measure the precision of our method on the
P-sample and recall on the R-sample. For the base-
lines, precision was also computed on the R-sample
(computing it on P-sample, which is obtained from
the induced derivational families, would severely
underestimate the number of false positives). We
omit the F1 score because its use for precision and
recall estimates from different samples is unclear.
DERIVBASE reaches 83% precision when us-
ing all rules and 93% precision when using only
highly reliable rules. DERIVBASE-L123 achieves
the highest recall, outperforming other methods
and variants by a large margin. Refinement of the
initial model has produced a significant improve-
ment in recall without losses in precision. The base-
lines perform worse than our method: the stemmer
we use is rather conservative, which fragments the
families and leads to a very low recall. The string
distance-based approaches achieve more balanced
precision and recall scores. Note that for these
methods, precision and recall can be traded off
against each other by varying the number of clus-
ters; we chose the number of clusters by optimizing
the F1 score on the calibration and validaton sets.
All subsequent analyses refer to DERIVBASE-
1207
Accuracy
Coverage High Low Total
High 18 ? 18
Low 53 21 74
Total 71 21 92
Table 6: Proportions of accuracy and coverage for
direct derivations (measured on P-sample)
P R P R
N-N 0.78 0.68 N-A 0.89 0.83
A-A 0.87 0.70 N-V 0.79 0.68
V-V 0.55 0.24 A-V 0.88 0.73
Table 7: Precision and recall across different part
of speech (first POS: basis; second POS: derived
word)
L123, which is the model with the highest recall.
If optimal precision is required, DERIVBASE-L3
should however be preferred.
Analysis by frequency. We cross-classified our
rules according to high/low accuracy and high/low
coverage based on the pairs in the P-sample.
We only considered directly derivationally related
(?D) pairs and defined ?high accuracy? and ?high
coverage? as all rules above the 25th percentile in
terms of accuracy and coverage, respectively. The
results are shown in Table 6: all high-coverage
rules are also highly accurate. Most rules are ac-
curate but infrequent. Only 21 rules have a low
accuracy, but all of them apply infrequently.
Analysis by parts of speech. Table 7 shows pre-
cision and recall values for different part of speech
combinations for the basis and derived words. High
precision and recall are achieved for N-A deriva-
tions. The recall is lowest for V-V derivations,
suggesting that the derivational phenomena for this
POS combination are not yet covered satisfactorily.
6.2 Error analysis
Table 8 shows the frequencies of true positives and
false positives on the P-sample and false negatives
on the R-sample for each annotated category. True
negatives are not reported, since their analysis gives
no deeper insight.
True positives. In our analysis we treated both R
and M pairs as related, but it is interesting to see
how many of the true positives are in fact semanti-
cally unrelated. Out of 1,663 pairs, 90% are seman-
tically as well as morphologically related (R), e.g.,
TPs FPs FNs
Label P-sample P-sample R-sample
R 1,492 ? 107
M 171 ? 60
N ? 216 ?
C ? 7 ?
L ? 114 ?
Total 1,663 337 167
Table 8: Predictions over annotated categories
alkoholisierenV ? antialkoholischA (to alcoholize
? nonalcoholic), BeschuldigungN ? unschuldigA
(accusation ? innocent). Most R pairs result from
high-accuracy rules, i.e., zero derivation, negation
prefixation and simple suffixation. The remaining
10% are only morphologically related (M), e.g.,
beschwingtA ? schwingenV (cheerful ? to swing),
StolzierenN ? stolzA (strut ? proud). In both pairs,
the two lemmas share a common semantic concept
? i.e., being in motion or being proud ? but nowa-
day?s meanings have grown apart from each other.
Among the M true positives, we observe prefixa-
tion derivations in 66% of the cases, often involv-
ing prefixation at both lemmas, e.g., ErdenklicheN
? bedenklichA (imaginable ? questionable).
False positives. We observe many errors in pairs
involving short lemmas, e.g., GenN ? genierenV
(gene ? to be embarrassed), where orthographic
context is unsufficient to reject the derivation.
About 64% of the 337 incorrect pairs are of class
N (unrelated lemmas). For example, the rule for
deriving nouns denoting a male person incorrectly
links MorseN ? M?rserN (Morse ? mortar). Tran-
sitively applied rules often produce incorrect pairs;
e.g., SpeicheN ? speicherbarA (spoke ? storable)
results from the rule chain SpeicheN ? SpeicherN
? speichernV ? speicherbarA (spoke? storage
? to store? storable). Chains that involve ablaut
shifts (cf. Section 3.1) can lead to surprising re-
sults, e.g., ErringungN ? rangiertA (achievement ?
shunted). Meanwhile, some pairs judged as un-
related by the annotators might conceivably be
weakly related, such as schl?rfenV and schlurfenV
(to sip ? to shuffle), both of which refer to specific
long drawn out sounds. About 20% out of these un-
related lemma pairs is due to derivations between
proper nouns (PNs) and common nouns. This hap-
pens especially for short PNs (cf. the above exam-
ple of Morse). However, since PNs also participate
in valid derivations (e.g., Chaplin ? chaplinesque),
1208
one could investigate their impact on derivations
rather than omitting them.
Errors of the category L ? 34% of the false posi-
tives ? are caused during preprocessing by the lem-
matizer. They cannot be blamed on our derivational
model, but of course form part of the output.
False negatives. Errors of this type are due to
missing derivation rules, erroneous rules that leave
some lemmas undiscovered, or the absence of lem-
mas in the corpus required for transitive closure.
About 64% of the 167 missed pairs are of category
R. About half of these pairs result from a lack of
prefixation rules ? mainly affecting verbs ? with a
wide variety of prefixes (zu-, um-, etc.), including
prepositional prefixes like herum- (around) or ?ber-
(over). We intentionally ignored these derivations,
since they frequently lead to semantically unrelated
pairs. In fact, merely five of the remaining 36%
false negative pairs (M) do not involve prefixation.
However, this analysis as well as the rather low cov-
erage for verb-involved rules (cf. Table 7) shows
that DERIVBASE might benefit from more prefix
rules. Apart from the lack of prefixation coverage
and a few other, rather infrequent rules, we did not
find any substantial deficits. Most of the remaining
errors are due to German idiosyncrasies and excep-
tional derivations, e.g., fahrenV ? FahrtN (drive ?
trip), where the regular zero derivation would result
in Fahr.
7 Conclusion and Future Work
In this paper, we present DERIVBASE, a deriva-
tional resource for German based on a rule-based
framework. A few work days were enough to build
the underlying rules with the aid of grammar text-
books. We collected derivational families for over
280,000 lemmas with high accuracy as well as solid
coverage. The resource is freely available.5
Our approach for compiling a derivational re-
source is not restricted to German. In addition
to the typologically most similar Germanic and
Romance languages, it is also applicable to agglu-
tinative languages like Finnish, or other fusional
languages like Russian. Its main requirements are
a large list of lemmas for the language (optionally
with further morphological features) and linguistic
literature on morphological patterns.
We have employed an evaluation method that
uses two separate samples to assess precision and
5http://goo.gl/7KG2U; license cc-by-sa 3.0
recall to deal with the high number of false neg-
atives. Our analyses indicate two interesting di-
rections for future work: (a) specific handling of
proper nouns, which partake in specific derivations;
and (b) the use of graph clustering instead of the
transitive closure to avoid errors resulting from
long transitive chains.
Finally, we plan to employ distributional seman-
tics methods (Turney and Pantel, 2010) to help re-
move semantically unrelated pairs as well as distin-
guish automatically between only morphologically
(M) or both morphologically and semantically (R)
related pairs. Last, but not least, this allows us to
group derivation rules according to their semantic
properties. For example, nouns with -er suffixes
often denote persons and are agentivizations of a
basis word (Bilgin et al, 2004).
Acknowledgments
The first and third authors were supported by
the EC project EXCITEMENT (FP7 ICT-287923).
The second author was supported by the Croatian
Science Foundation (project 02.03/162: ?Deriva-
tional Semantic Models for Information Retrieval?).
We thank the reviewers for their constructive com-
ments.
References
George W. Adamson and Jillian Boreham. 1974. The
use of an association measure based on character
structure to identify semantically related pairs of
words and document titles. Information Processing
and Management, 10(7/8):253?260.
Enrique Amig?, Julio Gonzalo, Javier Artiles, and Fe-
lisa Verdejo. 2009. A comparison of extrinsic
clustering evaluation metrics based on formal con-
straints. Information Retrieval, 12(4):461?486.
Gerhard Augst. 1975. Lexikon zur Wortbil-
dung. Forschungsberichte des Instituts f?r Deutsche
Sprache. Narr, T?bingen.
Harald R. Baayen, Richard Piepenbrock, and Leon Gu-
likers. 1996. The CELEX Lexical Database. Re-
lease 2. LDC96L14. Linguistic Data Consortium,
University of Pennsylvania, Philadelphia, PA.
Kenneth R Beesley and Lauri Karttunen. 2003. Finite
state morphology, volume 18. CSLI publications
Stanford.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2012. Learning entailment relations by global graph
structure optimization. Computational Linguistics,
38(1):73?111.
1209
Balthazar Bickel and Johanna Nichols. 2001. Inflec-
tional morphology. In Timothy Shopen, editor, Lan-
guage Typology and Syntactic Description, Volume
III: Grammatical categories and the lexicon, pages
169?240. CUP, Cambridge.
Orhan Bilgin, ?zlem ?etinog?lu, and Kemal Oflazer.
2004. Morphosemantic relations in and across
Wordnets. In Proceedings of the Global WordNet
Conference, pages 60?66, Brno, Czech Republic.
Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 89?97, Beijing, China.
Eric Brill. 1992. A simple rule-based part of speech
tagger. In Proceedings of the Workshop on Speech
and Natural Language, pages 112?116, Harriman,
New York.
Jean C. Carletta. 1996. Assessing agreement on clas-
sification tasks: the kappa statistic. Computational
Linguistics, 22(2):249?254.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
agreement with provision for scaled disagreement or
partial credit. Psychological Bulletin, 70:213?220.
B?atrice Daille, C?cile Fabre, and Pascale S?billot.
2002. Applications of computational morphology.
In Paul Boucher, editor, Many Morphologies, pages
210?234. Cascadilla Press.
Herv? D?jean. 1998. Morphemes as necessary concept
for structures discovery from untagged corpora. In
Proceedings of the Joint Conferences on New Meth-
ods in Language Processing and Computational Nat-
ural Language Learning, pages 295?298, Sydney,
Australia.
Gertrud Faa?, Ulrich Heid, and Helmut Schmid. 2010.
Design and application of a gold standard for mor-
phological analysis: SMOR in validation. In Pro-
ceedings of the Seventh International Conference
on Language Resources and Evaluation, pages 803?
810.
Christiane Fellbaum, Anne Osherson, and Peter Clark.
2009. Putting semantics into WordNet?s "morphose-
mantic" links. In Proceedings of the Third Language
and Technology Conference, pages 350?358, Poz-
nan?, Poland.
Wolfgang Finkler and G?nter Neumann. 1988. Mor-
phix - a fast realization of a classification-based ap-
proach to morphology. In Proceedings of 4th Aus-
trian Conference of Artificial Intelligence, pages 11?
19, Vienna, Austria.
Arne Fitschen. 2004. Ein computerlinguistisches
Lexikon als komplexes System. Ph.D. thesis, IMS,
Universit?t Stuttgart.
?ric Gaussier. 1999. Unsupervised learning of deriva-
tional morphology from inflectional lexicons. In
ACL?99 Workshop Proceedings on Unsupervised
Learning in Natural Language Processing, pages
24?30, College Park, Maryland, USA.
Rebecca Green, Bonnie J. Dorr, and Philip Resnik.
2004. Inducing frame semantic verb classes from
wordnet and ldoce. In Proceedings of the 42nd An-
nual Meeting on Association for Computational Lin-
guistics, pages 375?382, Barcelona, Spain.
Nizar Habash and Bonnie Dorr. 2003. A categorial
variation database for English. In Proceedings of
the Anuual Meeting of the North American Associ-
ation for Computational Linguistics, pages 96?102,
Edmonton, Canada.
Harald Hammarstr?m and Lars Borin. 2011. Unsuper-
vised learning of morphology. Computational Lin-
guistics, 37(2):309?350.
Wolfgang Hoeppner. 1980. Derivative Wortbildung
der deutschen Gegenwartssprache und ihre algorith-
mische Analyse. Narr, T?bingen.
Lauri Karttunen and Kenneth R Beesley. 1992. Two-
level rule compiler. Xerox Corporation. Palo Alto
Research Center.
Lauri Karttunen and Kenneth R. Beesley. 2005.
Twenty-five years of finite-state morphology. In
Antti Arppe, Lauri Carlson, Krister Lind?n, Jussi Pi-
itulainen, Mickael Suominen, Martti Vainio, Hanna
Westerlund, and Anssi Yli-Jyr, editors, Inquiries
into Words, Constraints and Contexts. Festschrift for
Kimmo Koskenniemi on his 60th Birthday, pages 71?
83. CSLI Publications, Stanford, California.
Kimmo Koskenniemi. 1983. Two-level Morphology:
A General Computational Model for Word-Form
Recognition and Production. Ph.D. thesis, Univer-
sity of Helsinki.
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A lexicon of nominalizations. In In Proceedings of
Euralex98, pages 187?193.
Prasenjit Majumder, Mandar Mitra, Swapan K. Parui,
Gobinda Kole, Pabitra Mitra, and Kalyankumar
Datta. 2007. YASS: Yet another suffix strip-
per. ACM Transactions on Information Systems,
25(4):18:1?18:20.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a
two-stage discriminative parser. In In Proceedings
of the Conference on Computational Natural Lan-
guage Learning, pages 216?220, New York, NY.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. Annotating noun ar-
gument structure for NomBank. In Proceedings of
the 4th International Conference on Language Re-
sources and Evaluation, Lisbon, Portugal.
1210
Petar Milin, Victor Kuperman, Aleksandar Kostic, and
R Harald Baayen. 2009. Paradigms bit by bit: An
information theoretic approach to the processing of
paradigmatic structure in inflection and derivation.
Analogy in grammar: Form and acquisition, pages
214?252.
Karel Pala and Dana Hlav?c?kov?. 2007. Derivational
relations in Czech WordNet. In Proceedings of the
ACL Workshop on Balto-Slavonic Natural Language
Processing: Information Extraction and Enabling
Technologies, pages 75?81.
Maciej Piasecki, Radoslaw Ramocki, and Marek
Maziarz. 2012. Recognition of Polish derivational
relations based on supervised learning scheme. In
Proceedings of the Eighth International Conference
on Language Resources and Evaluation, pages 916?
922, Istanbul, Turkey.
Martin Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Anne Schiller, Simone Teufel, Christine St?ckert, and
Christine Thielen. 1999. Guidelines f?r das Tag-
ging deutscher Textcorpora mit STTS. Technical
report, Institut fur maschinelle Sprachverarbeitung,
Stuttgart.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
Smor: A German computational morphology cover-
ing derivation, composition and inflection. In Pro-
ceedings of the Fourth International Conference on
Language Resources and Evaluation, Lisbon, Portu-
gal.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44?49, Manchester, UK.
Patrick Schone and Daniel Jurafsky. 2000.
Knowledge-free induction of morphology us-
ing latent semantic analysis. In Proceedings of the
Conference on Natural Language Learning, pages
67?72, Lisbon, Portugal.
Jan ?najder and Bojana Dalbelo Ba?ic?. 2008. Higher-
order functional representation of Croatian inflec-
tional morphology. In Proceedings of the 6th In-
ternational Conference on Formal Approaches to
South Slavic and Balkan Languages, pages 121?130,
Dubrovnik, Croatia.
Jan ?najder and Bojana Dalbelo Ba?ic?. 2010. A
computational model of Croatian derivational mor-
phology. In Proceedings of the 7th International
Conference on Formal Approaches to South Slavic
and Balkan Languages, pages 109?118, Dubrovnik,
Croatia.
Idan Szpektor and Ido Dagan. 2008. Learning en-
tailment rules for unary templates. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics, pages 849?856, Manchester, UK.
Kapil Thadani and Kathleen McKeown. 2011. To-
wards strict sentence intersection: Decoding and
evaluation strategies. In Proceedings of the ACL
Workshop on Monolingual Text-To-Text Generation,
pages 43?53, Portland, Oregon.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37(1):141?188.
Andrea Zielinski and Christian Simon. 2008. Mor-
phisto - an open source morphological analyzer for
German. In Proceedings of the 7th International
Workshop on Finite-State Methods and Natural Lan-
guage Processing, pages 224?231, Ispra, Italy.
1211
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 731?735,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Derivational Smoothing for Syntactic Distributional Semantics
Sebastian Pado?? Jan S?najder? Britta Zeller?
?Heidelberg University, Institut fu?r Computerlinguistik
69120 Heidelberg, Germany
?University of Zagreb, Faculty of Electrical Engineering and Computing
Unska 3, 10000 Zagreb, Croatia
{pado, zeller}@cl.uni-heidelberg.de jan.snajder@fer.hr
Abstract
Syntax-based vector spaces are used widely
in lexical semantics and are more versatile
than word-based spaces (Baroni and Lenci,
2010). However, they are also sparse, with
resulting reliability and coverage problems.
We address this problem by derivational
smoothing, which uses knowledge about
derivationally related words (oldish? old)
to improve semantic similarity estimates.
We develop a set of derivational smoothing
methods and evaluate them on two lexical
semantics tasks in German. Even for mod-
els built from very large corpora, simple
derivational smoothing can improve cover-
age considerably.
1 Introduction
Distributional semantics (Turney and Pantel, 2010)
builds on the assumption that the semantic similar-
ity of words is strongly correlated to the overlap
between their linguistic contexts. This hypothesis
can be used to construct context vectors for words
directly from large text corpora in an unsupervised
manner. Such vector spaces have been applied suc-
cessfully to many problems in NLP (see Turney and
Pantel (2010) or Erk (2012) for current overviews).
Most distributional models in computational lex-
ical semantics are either (a) bag-of-words models,
where the context features are words within a sur-
face window around the target word, or (b) syn-
tactic models, where context features are typically
pairs of dependency relations and context words.
The advantage of syntactic models is that they
incorporate a richer, structured notion of context.
This makes them more versatile; the Distributional
Memory framework by Baroni and Lenci (2010) is
applicable to a wide range of tasks. It is also able ?
at least in principle ? to capture more fine-grained
types of semantic similarity such as predicate-
argument plausibility (Erk et al, 2010). At the
same time, syntactic spaces are much more prone
to sparsity problems, as their contexts are sparser.
This leads to reliability and coverage problems.
In this paper, we propose a novel strategy
for combating sparsity in syntactic vector spaces,
derivational smoothing. It follows the intuition that
derivationally related words (feed ? feeder, blocked
? blockage) are, as a rule, semantically highly simi-
lar. Consequently, knowledge about derivationally
related words can be used as a ?back off? for sparse
vectors in syntactic spaces. For example, the pair
oldish ? ancient should receive a high semantic
similarity, but in practice, the vector for oldish will
be very sparse, which makes this result uncertain.
Knowing that oldish is derivationally related to old
allows us to use the much less sparse vector for old
as a proxy for oldish.
We present a set of general methods for smooth-
ing vector similarity computations given a resource
that groups words into derivational families (equiv-
alence classes) and evaluate these methods on Ger-
man for two distributional tasks (similarity predic-
tion and synonym choice). We find that even for
syntactic models built from very large corpora, a
simple derivational resource that groups words on
morphological grounds can improve the results.
2 Related Work
Smoothing techniques ? either statistical, distribu-
tional, or knowledge-based ? are widely applied in
all areas of NLP. Many of the methods were first
applied in Language Modeling to deal with unseen
n-grams (Chen and Goodman, 1999; Dagan et al,
1999). Query expansion methods in Information
Retrieval are also prominent cases of smoothing
that addresses the lexical mismatch between query
and document (Voorhees, 1994; Gonzalo et al,
1998; Navigli and Velardi, 2003). In lexical se-
mantics, smoothing is often achieved by backing
731
off from words to semantic classes, either adopted
from a resource such as WordNet (Resnik, 1996) or
induced from data (Pantel and Lin, 2002; Wang et
al., 2005; Erk et al, 2010). Similarly, distributional
features support generalization in Named Entity
Recognition (Finkel et al, 2005).
Although distributional information is often used
for smoothing, to our knowledge there is little
work on smoothing distributional models them-
selves. We see two main precursor studies for our
work. Bergsma et al (2008) build models of se-
lectional preferences that include morphological
features such as capitalization and the presence of
digits. However, their approach is task-specific and
requires a (semi-)supervised setting. Allan and Ku-
maran (2003) make use of morphology by building
language models for stemming-based equivalence
classes. Our approach also uses morphological
processing, albeit more precise than stemming.
3 A Resource for German Derivation
Derivational morphology describes the process of
building new (derived) words from other (basis)
words. Derived words can, but do not have to, share
the part-of-speech (POS) with their basis (oldA?
oldishA vs. warmA? warmV , warmthN ). Words
can be grouped into derivational families by form-
ing the transitive closure over individual derivation
relations. The words in these families are typically
semantically similar, although the exact degree de-
pends on the type of relation and idiosyncratic fac-
tors (bookN ? bookishA, Lieber (2009)).
For German, there are several resources with
derivational information. We use version 1.3
of DERIVBASE (Zeller et al, 2013),1 a freely
available resource that groups over 280,000 verbs,
nouns, and adjectives into more than 17,000 non-
singleton derivational families. It has a precision of
84% and a recall of 71%. Its higher coverage com-
pared to CELEX (Baayen et al, 1996) and IMSLEX
(Fitschen, 2004) makes it particularly suitable for
the use in smoothing, where the resource should
include low-frequency lemmas.
The following example illustrates a family that
covers three POSes as well as a word with a pre-
dominant metaphorical reading (to kneel? to beg):
knieenV (to kneelV ), beknieenV (to
begV ), KniendeN (kneeling personN ),
kniendA (kneelingA), KnieNn (kneeN )
1Downloadable from: http://goo.gl/7KG2U
Using derivational knowledge for smoothing raises
the question of how semantically similar the lem-
mas within a family really are. Fortunately, DE-
RIVBASE provides information that can be used in
this manner. It was constructed with hand-written
derivation rules, employing string transformation
functions that map basis lemmas onto derived lem-
mas. For example, a suffixation rule using the affix
?heit? generates the derivation dunkel ? Dunkel-
heit (darkA ? darknessN ). Since derivational fam-
ilies are defined as transitive closures, each pair
of words in a family is connected by a derivation
path. Because the rules do not have a perfect pre-
cision, our confidence in pairs of words decreases
the longer the derivation path between them. To re-
flect this, we assign each pair a confidence of 1/n,
where n is the length of the shortest path between
the lemmas. For example, bekleiden (enrobeV ) is
connected to Verkleidung (disguiseN ) through three
steps via the lemmas kleiden (dressV ) and verklei-
den (disguiseV ) and is assigned the confidence 1/3.
4 Models for Derivational Smoothing
Derivational smoothing exploits the fact that deriva-
tionally related words are also semantically related,
by combining and/or comparing distributional rep-
resentations of derivationally related words. The
definition of a derivational smoothing algorithm
consists of two parts: a trigger and a scheme.
Notation. Given a word w, we use w to denote
its distributional vector and D(w) to denote the set
of vectors for the derivational family of w. We
assume that w ? D(w). For words that have no
derivations in DERIVBASE, D(w) is a singleton
set, D(w) = {w}. Let ?(w,w?) denote the confi-
dence of the pair (w,w?), as explained in Section 3.
Smoothing trigger. As discussed above, there is
no guarantee for high semantic similarity within a
derivational family. For this reason, smoothing may
also drown out information. In this paper, we report
on two triggers: smooth always always performs
smoothing; smooth if sim=0 smooths only when
the unsmoothed similarity sim(w1,w2) is zero or
unknown (due to w1 or w2 not being in the model).
Smoothing scheme. We present three smoothing
schemes, all of which apply to the level of complete
families. The first two schemes are exemplar-based
schemes, which define the smoothed similarity for
a word pair as a function of the pairwise similarities
between all words of the two derivational families.
732
The first one, maxSim, checks for particularly simi-
lar words in the families:
maxSim(w1, w2) = max
w?1?D(w1)
w?2?D(w2)
sim(w?1,w?2)
The second one, avgSim, computes the average
pairwise similarity (N is the number of pairs):
avgSim(w1, w2) =
1
N
?
w?1?D(w1)
w?2?D(w2)
sim(w?1,w?2)
The third scheme, centSim, is prototype-based. It
computes a centroid vector for each derivational
family, which can be thought of as a representation
for the concept(s) that it expresses:
centSim(w1, w2) = sim
(
c(D(w1)), c(D(w2))
)
where c(D(w)) =?w??D(w) ?(w,w?) ?w? is the
confidence-weighted centroid vector. centSim is
similar to avgSim. It is more efficient to calculate
and effectively introduces a kind or regularization,
where outliers in either family have less impact on
the overall result.
These models only represents a sample of possi-
ble derivational smoothing methods. We performed
a number of additional experiments (POS-restricted
smoothing, word-based, and pair-based smoothing
triggers), but they did not yield any improvements
over the simpler models we present here.
5 Experimental Evaluation
Syntactic Distributional Model. The syntactic
distributional model that we use represents target
words by pairs of dependency relations and context
words. More specifically, we use the W ? LW
matricization of DM.DE, the German version (Pado?
and Utt, 2012) of Distributional Memory (Baroni
and Lenci, 2010). DM.DE was created on the basis
of the 884M-token SDEWAC web corpus (Faa? et
al., 2010), lemmatized, tagged, and parsed with the
German MATE toolkit (Bohnet, 2010).
Experiments. We evaluate the impact of smooth-
ing on two standard tasks from lexical semantics.
The first task is predicting semantic similarity. We
lemmatized and POS-tagged the German GUR350
dataset (Zesch et al, 2007), a set of 350 word pairs
with human similarity judgments, created analo-
gously to the well-known Rubenstein and Good-
enough (1965) dataset for English.2 We predict
2Downloadable from: http://goo.gl/bFokI
semantic similarity as cosine similarity. We make
a prediction for a word pair if both words are repre-
sented in the semantic space and their vectors have
a non-zero similarity.
The second task is synonym choice on the Ger-
man version of the Reader?s Digest WordPower
dataset (Wallace and Wallace, 2005).2 This dataset,
which we also lemmatized and POS-tagged, con-
sists of 984 target words with four synonym can-
didates each (including phrases), one of which is
correct. Again, we compute semantic similarity as
the cosine between target and a candidate vector
and pick the highest-similarity candidate as syn-
onym. For phrases, we compute the maximum
pairwise word similarity. We make a prediction for
an item if the target as well as at least one candi-
date are represented in the semantic space and their
vectors have a non-zero similarity.
We expect differences between the two tasks
with regard to derivational smoothing, since the
words within derivational families are generally re-
lated but often not synonymous (cf. the example
in Section 3). Thus, semantic similarity judgments
should profit more easily from derivational smooth-
ing than synonym choice.
Baseline. Our baseline is a standard bag-of-
words vector space (BOW), which represents target
words by the words occurring in their context. We
use standard parameters (?10 word window, 8.000
most frequent verb, noun, and adjective lemmas).
The model was created from the same corpus as
DM.DE. We also applied derivational smoothing
to this model, but did not obtain improvements.
Evaluation. To analyze the impact of smoothing,
we evaluate the coverage of models and the quality
of their predictions separately. In both tasks, cover-
age is the percentage of items for which we make
a prediction. We measure quality of the semantic
similarity task as the Pearson correlation between
the model predictions and the human judgments
for covered items (Zesch et al, 2007). For syn-
onym choice, we follow the method established by
Mohammad et al (2007), measuring accuracy over
covered items, with partial credit for ties.
Results for Semantic Similarity. Table 1 shows
the results for the first task. The unsmoothed
DM.DE model attains a correlation of r = 0.44
and a coverage of 58.9%. Smoothing increases the
coverage substantially to 88%. Additionally, con-
servative, prototype-based smoothing (if sim = 0)
733
Smoothing
trigger
Smoothing
scheme
r Cov
%
DM.DE, unsmoothed .44 58.9
DM.DE,
smooth always
avgSim .30 88.0
maxSim .43 88.0
centSim .44 88.0
DM.DE,
smooth if sim = 0
avgSim .43 88.0
maxSim .42 88.0
centSim .47 88.0
BOW baseline .36 94.9
Table 1: Results on the semantic similarity task
(r: Pearson correlation, Cov: Coverage)
increases correlation somewhat to r = 0.47. The
difference to the unsmoothed model is not signif-
icant at p = 0.05 according to Fisher?s (1925)
method of comparing correlation coefficients.
The bag-of-words baseline (BOW) has a greater
coverage than DM.DE models, but at the cost
of lower correlation across the board. The only
DM.DE model that performs worse than the BOW
baseline is the non-conservative avgSim (average
similarity) scheme. We attribute this weak per-
formance to the presence of many pairwise zero
similarities in the data, which makes the avgSim
predictions unreliable.
To our knowledge, there are no previous pub-
lished papers on distributional approaches to mod-
eling this dataset. The best previous result is a
GermaNet/Wikipedia-based model by Zesch et al
(2007). It reports a higher correlation (r = 0.59)
but a very low coverage at 33.1%.
Results for Synonym Choice. The results for
the second task are shown in Table 2. The un-
smoothed model achieves an accuracy of 53.7%
and a coverage of 80.8%, as reported by Pado?
and Utt (2012). Smoothing increases the cover-
age by almost 6% to 86.6% (for example, a ques-
tion item for inferior becomes covered after back-
ing off from the target to Inferiorita?t (inferiority)).
All smoothed models show a loss in accuracy, al-
beit small. The best model is again a conservative
smoothing model (sim = 0) with a loss of 1.1% ac-
curacy. Using bootstrap resampling (Efron and Tib-
shirani, 1993), we established that the difference
to the unsmoothed DM.DE model is not signifi-
cant at p < 0.05. This time, the avgSim (average
similarity) smoothing scheme performs best, with
the prototype-based scheme in second place. Thus,
the results for synonym choice are less clear-cut:
derivational smoothing can trade accuracy against
Smoothing
trigger
Smoothing
scheme
Acc
%
Cov
%
DM.DE, unsmoothed (Pado? & Utt 2012) 53.7 80.8
DM.DE,
smooth always
avgSim 46.0 86.6
maxSim 50.3 86.6
centSim 49.1 86.6
DM.DE,
smooth if sim = 0
avgSim 52.6 86.6
maxSim 51.2 86.6
centSim 51.3 86.6
BOW ?baseline? 56.9 98.5
Table 2: Results on the synonym choice task
(Acc: Accuracy, Cov: Coverage)
coverage but does not lead to a clear improvement.
What is more, the BOW ?baseline? significantly
outperforms all syntactic models, smoothed and
unsmoothed, with an almost perfect coverage com-
bined with a higher accuracy.
6 Conclusions and Outlook
In this paper, we have introduced derivational
smoothing, a novel strategy to combating sparsity
in syntactic vector spaces by comparing and com-
bining the vectors of morphologically related lem-
mas. The only information strictly necessary for
the methods we propose is a grouping of lemmas
into derivationally related classes. We have demon-
strated that derivational smoothing improves two
tasks, increasing coverage substantially and also
leading to a numerically higher correlation in the
semantic similarity task, even for vectors created
from a very large corpus. We obtained the best re-
sults for a conservative approach, smoothing only
zero similarities. This also explains our failure
to improve less sparse word-based models, where
very few pairs are assigned a similarity of zero.
A comparison of prototype- and exemplar-based
schemes did not yield a clear winner. The estima-
tion of generic semantic similarity can profit more
from derivational smoothing than the induction of
specific lexical relations.
In future work, we plan to work on other eval-
uation tasks, application to other languages, and
more sophisticated smoothing schemes.
Acknowledgments. Authors 1 and 3 were sup-
ported by the EC project EXCITEMENT (FP7 ICT-
287923). Author 2 was supported by the Croatian
Science Foundation (project 02.03/162: ?Deriva-
tional Semantic Models for Information Retrieval?).
We thank Jason Utt for his support and expertise.
734
References
James Allan and Giridhar Kumaran. 2003. Stemming
in the Language Modeling Framework. In Proceed-
ings of SIGIR, pages 455?456.
Harald R. Baayen, Richard Piepenbrock, and Leon Gu-
likers. 1996. The CELEX Lexical Database. Re-
lease 2. LDC96L14. Linguistic Data Consortium,
University of Pennsylvania, Philadelphia, Pennsyl-
vania.
Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional Memory: A General Framework for
Corpus-based Semantics. Computational Linguis-
tics, 36(4):673?721.
Shane Bergsma, Dekang Lin, and Randy Goebel. 2008.
Discriminative Learning of Selectional Preference
from Unlabeled Text. In Proceedings of EMNLP,
pages 59?68, Honolulu, Hawaii.
Bernd Bohnet. 2010. Top Accuracy and Fast Depen-
dency Parsing is not a Contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89?97, Beijing, China.
Stanley F. Chen and Joshua Goodman. 1999. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Computer Speech and Language,
13(4):359?394.
Ido Dagan, Lillian Lee, and Fernando C. N. Pereira.
1999. Similarity-Based Models of Word Cooccur-
rence Probabilities. Machine Learning, 34(1?3):43?
69.
Bradley Efron and Robert J. Tibshirani. 1993. An
Introduction to the Bootstrap. Chapman and Hall,
New York.
Katrin Erk, Sebastian Pado?, and Ulrike Pado?. 2010.
A Flexible, Corpus-driven Model of Regular and In-
verse Selectional Preferences. Computational Lin-
guistics, 36(4):723?763.
Katrin Erk. 2012. Vector Space Models of Word Mean-
ing and Phrase Meaning: A Survey. Language and
Linguistics Compass, 6(10):635?653.
Gertrud Faa?, Ulrich Heid, and Helmut Schmid. 2010.
Design and Application of a Gold Standard for Mor-
phological Analysis: SMOR in Validation. In Pro-
ceedings of LREC-2010, pages 803?810.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating Non-local Informa-
tion into Information Extraction Systems by Gibbs
Sampling. In Proceedings of the 43rd Annual Meet-
ing of the ACL, pages 363?370.
Ronald Aylmer Fisher. 1925. Statistical methods for
research workers. Oliver and Boyd, Edinburgh.
Arne Fitschen. 2004. Ein computerlinguistisches
Lexikon als komplexes System. Ph.D. thesis, IMS,
Universita?t Stuttgart.
Julio Gonzalo, Felisa Verdejo, Irina Chugur, and
Juan M. Cigarra?n. 1998. Indexing with WordNet
Synsets Can Improve Text Retrieval. In Proceed-
ings of the COLING/ACL Workshop on Usage of
WordNet in Natural Language Processing Systems,
Montre?al, Canada.
Rochelle Lieber. 2009. Morphology and Lexical Se-
mantics. Cambridge University Press.
Saif Mohammad, Iryna Gurevych, Graeme Hirst, and
Torsten Zesch. 2007. Cross-Lingual Distributional
Profiles of Concepts for Measuring Semantic Dis-
tance. In Proceedings of the 2007 Joint Conference
on EMNLP and CoNLL, pages 571?580, Prague,
Czech Republic.
Roberto Navigli and Paola Velardi. 2003. An Analysis
of Ontology-based Query Expansion Strategies. In
Workshop on Adaptive Text Extraction and Mining,
Dubrovnik, Croatia.
Sebastian Pado? and Jason Utt. 2012. A Distributional
Memory for German. In Proceedings of KONVENS
2012 workshop on lexical-semantic resources and
applications, pages 462?470, Vienna, Austria.
Patrick Pantel and Dekang Lin. 2002. Discovering
Word Senses from Text. In In Proceedings of ACM
SIGKDD Conference on Knowledge Discovery and
Data Mining, pages 613?619.
Philip Resnik. 1996. Selectional Constraints: An
Information-theoretic Model and its Computational
Realization. Cognition, 61(1-2):127?159.
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual Correlates of Synonymy. Communica-
tions of the ACM, 8(10):627?633.
Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artificial Intelligence Research,
37(1):141?188.
Ellen M. Voorhees. 1994. Query Expansion Using
Lexical-semantic Relations. In Proceedings of SI-
GIR, pages 61?69.
DeWitt Wallace and Lila Acheson Wallace. 2005.
Reader?s Digest, das Beste fu?r Deutschland. Verlag
Das Beste, Stuttgart.
Qin Iris Wang, Dale Schuurmans, and Dekang Lin.
2005. Strictly Lexical Dependency Parsing. In Pro-
ceedings of IWPT, pages 152?159.
Britta Zeller, Jan S?najder, and Sebastian Pado?. 2013.
DErivBase: Inducing and Evaluating a Derivational
Morphology Resource for German. In Proceedings
of ACL, Sofia, Bulgaria.
Torsten Zesch, Iryna Gurevych, and Max Mu?hlha?user.
2007. Comparing Wikipedia and German Word-
net by Evaluating Semantic Relatedness on Multi-
ple Datasets. In Proceedings of NAACL/HLT, pages
205?208, Rochester, NY.
735
