Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 26?27,
Vancouver, October 2005.
Japanese Speech Understanding Using Grammar Specialization
Manny Rayner, Nikos Chatzichrisafis, Pierrette Bouillon
University of Geneva, TIM/ISSCO
40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
mrayner@riacs.edu
{Pierrette.Bouillon,Nikolaos.Chatzichrisafis}@issco.unige.ch
Yukie Nakao, Hitoshi Isahara, Kyoko Kanzaki
National Institute of Information and Communications Technology
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
yukie-n@khn.nict.go.jp, {isahara,kanzaki}@nict.go.jp
Beth Ann Hockey
UCSC/NASA Ames Research Center
Moffet Field, CA 94035
bahockey@riacs.edu
Marianne Santaholma, Marianne Starlander
University of Geneva, TIM/ISSCO
40 bvd du Pont-d?Arve
CH-1211 Geneva 4, Switzerland
Marianne.Santaholma@eti.unige.ch
Marianne.Starlander@eti.unige.ch
The most common speech understanding archi-
tecture for spoken dialogue systems is a combination
of speech recognition based on a class N-gram lan-
guage model, and robust parsing. For many types
of applications, however, grammar-based recogni-
tion can offer concrete advantages. Training a
good class N-gram language model requires sub-
stantial quantities of corpus data, which is gen-
erally not available at the start of a new project.
Head-to-head comparisons of class N-gram/robust
and grammar-based systems also suggest that users
who are familiar with system coverage get better re-
sults from grammar-based architectures (Knight et
al., 2001). As a consequence, deployed spoken dia-
logue systems for real-world applications frequently
use grammar-based methods. This is particularly
the case for speech translation systems. Although
leading research systems like Verbmobil and NE-
SPOLE! (Wahlster, 2000; Lavie et al, 2001) usu-
ally employ complex architectures combining sta-
tistical and rule-based methods, successful practical
examples like Phraselator and S-MINDS (Phrasela-
tor, 2005; Sehda, 2005) are typically phrasal trans-
lators with grammar-based recognizers.
Voice recognition platforms like the Nuance
Toolkit provide CFG-based languages for writing
grammar-based language models (GLMs), but it is
challenging to develop and maintain grammars con-
sisting of large sets of ad hoc phrase-structure rules.
For this reason, there has been considerable inter-
est in developing systems that permit language mod-
els be specified in higher-level formalisms, normally
some kind of unification grammar (UG), and then
compile these grammars down to the low-level plat-
form formalisms. A prominent early example of this
approach is the Gemini system (Moore, 1998).
Gemini raises the level of abstraction signifi-
cantly, but still assumes that the grammars will be
domain-dependent. In the Open Source REGULUS
project (Regulus, 2005; Rayner et al, 2003), we
have taken a further step in the direction of increased
abstraction, and derive all recognizers from a sin-
gle linguistically motivated UG. This derivation pro-
cedure starts with a large, application-independent
UG for a language. An application-specific UG is
then derived using an Explanation Based Learning
(EBL) specialization technique. This corpus-based
specialization process is parameterized by the train-
ing corpus and operationality criteria. The training
corpus, which can be relatively small, consists of ex-
amples of utterances that should be recognized by
the target application. The sentences of the corpus
are parsed using the general grammar, then those
parses are partitioned into phrases based on the op-
erationality criteria. Each phrase defined by the
operationality criteria is flattened, producing rules
of a phrasal grammar for the application domain.
This application-specific UG is then compiled into
26
a CFG, formatted to be compatible with the Nuance
recognition platform. The CFG is compiled into the
runtime recognizer using Nuance tools.
Previously, the REGULUS grammar specialization
programme has only been implemented for English.
In this demo, we will show how we can apply the
same methodology to Japanese. Japanese is struc-
turally a very different language from English, so it
is by no means obvious that methods which work
for English will be applicable in this new context:
in fact, they appear to work very well. We will
demo the grammars and resulting recognizers in the
context of Japanese ? English and Japanese ?
French versions of the Open Source MedSLT medi-
cal speech translation system (Bouillon et al, 2005;
MedSLT, 2005).
The generic problem to be solved when building
any sort of recognition grammar is that syntax alone
is insufficiently constraining; many of the real con-
straints in a given domain and use situation tend to
be semantic and pragmatic in nature. The challenge
is thus to include enough non-syntactic constraints
in the grammar to create a language model that can
support reliable domain-specific speech recognition:
we sketch our solution for Japanese.
The basic structure of our current general
Japanese grammar is as follows. There are four main
groups of rules, covering NP, PP, VP and CLAUSE
structure respectively. The NP and PP rules each as-
sign a sortal type to the head constituent, based on
the domain-specific sortal constraints defined in the
lexicon. VP rules define the complement structure
of each syntactic class of verb, again making use of
the sortal features. There are also rules that allow
a VP to combine with optional adjuncts, and rules
which allow null constituents, in particular null sub-
jects and objects. Finally, clause-level rules form a
clause out of a VP, an optional subject and optional
adjuncts. The sortal features constrain the subject
and the complements combining with a verb, but the
lack of constraints on null constituents and optional
adjuncts still means that the grammar is very loose.
The grammar specialization mechanism flattens the
grammar into a set of much simpler structures, elim-
inating the VP level and only permitting specific pat-
terns of null constituents and adjuncts licenced by
the training corpus.
We will demo several different versions of the
Japanese-input medical speech translation system,
differing with respect to the target language and
the recognition architecture used. In particular, we
will show a) that versions based on the specialized
Japanese grammar offer fast and accurate recogni-
tion on utterances within the intended coverage of
the system (Word Error Rate around 5%, speed un-
der 0.1?RT), b) that versions based on the original
general Japanese grammar are much less accurate
and more than an order of magnitude slower.
References
P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,
and H. Isahara. 2005. A generic multi-lingual open
source platform for limited-domain medical speech
translation. In In Proceedings of the 10th Conference
of the European Association for Machine Translation
(EAMT), Budapest, Hungary.
S. Knight, G. Gorrell, M. Rayner, D. Milward, R. Koel-
ing, and I. Lewin. 2001. Comparing grammar-based
and robust approaches to speech understanding: a case
study. In Proceedings of Eurospeech 2001, pages
1779?1782, Aalborg, Denmark.
A. Lavie, C. Langley, A. Waibel, F. Pianesi, G. Lazzari,
P. Coletti, L. Taddei, and F. Balducci. 2001. Ar-
chitecture and design considerations in NESPOLE!:
a speech translation system for e-commerce applica-
tions. In Proceedings of HLT: Human Language Tech-
nology Conference, San Diego, California.
MedSLT, 2005. http://sourceforge.net/projects/medslt/.
As of 9 June 2005.
R. Moore. 1998. Using natural language knowledge
sources in speech recognition. In Proceedings of the
NATO Advanced Studies Institute.
Phraselator, 2005. http://www.phraselator.com/. As of 9
June 2005.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
Regulus, 2005. http://sourceforge.net/projects/regulus/.
As of 9 June 2005.
Sehda, 2005. http://www.sehda.com/. As of 9 June 2005.
W. Wahlster, editor. 2000. Verbmobil: Foundations of
Speech-to-Speech Translation. Springer.
27
MedSLT: A Limited-Domain Unidirectional Grammar-Based Medical
Speech Translator
Manny Rayner, Pierrette Bouillon, Nikos Chatzichrisafis, Marianne Santaholma, Marianne Starlander
University of Geneva, TIM/ISSCO, 40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
Emmanuel.Rayner@issco.unige.ch
Pierrette.Bouillon@issco.unige.ch, Nikos.Chatzichrisafis@vozZup.com
Marianne.Santaholma@eti.unige.ch, Marianne.Starlander@eti.unige.ch
Beth Ann Hockey
UCSC/NASA Ames Research Center, Moffet Field, CA 94035
bahockey@email.arc.nasa.gov
Yukie Nakao, Hitoshi Isahara, Kyoko Kanzaki
National Institute of Information and Communications Technology
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
yukie-n@khn.nict.go.jp, {isahara,kanzaki}@nict.go.jp
Abstract
MedSLT is a unidirectional medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several differ-
ent language pairs and subdomains. Vo-
cabulary ranges from about 350 to 1000
surface words, depending on the language
and subdomain. We will demo both the
system itself and the development envi-
ronment, which uses a combination of
rule-based and data-driven methods to
construct efficient recognisers, generators
and transfer rule sets from small corpora.
1 Overview
The mainstream in speech translation work is for the
moment statistical, but rule-based systems are still a
very respectable alternative. In particular, nearly all
systems which have actually been deployed are rule-
based. Prominent examples are (Phraselator, 2006;
S-MINDS, 2006; MedBridge, 2006).
MedSLT (MedSLT, 2005; Bouillon et al, 2005)
is a unidirectional medical speech translation system
for use in doctor-patient diagnosis dialogues, which
covers several different language pairs and subdo-
mains. Recognition is performed using grammar-
based language models, and translation uses a rule-
based interlingual framework. The system, includ-
ing the development environment, is built on top of
Regulus (Regulus, 2006), an Open Source platform
for developing grammar-based speech applications,
which in turn sits on top of the Nuance Toolkit.
The demo will show how MedSLT can be used
to carry out non-trivial diagnostic dialogues. In par-
ticular, we will demonstrate how an integrated intel-
ligent help system counteracts the brittleness inher-
ent in rule-based processing, and rapidly leads new
users towards the supported system coverage. We
will also demo the development environment, and
show how grammars and sets of transfer rules can be
efficiently constructed from small corpora of a few
hundred to a thousand examples.
2 The MedSLT system
The MedSLT demonstrator has already been exten-
sively described elsewhere (Bouillon et al, 2005;
Rayner et al, 2005a), so this section will only
present a brief summary. The main components are
a set of speech recognisers for the source languages,
a set of generators for the target languages, a transla-
tion engine, sets of rules for translating to and from
interlingua, a simple discourse engine for dealing
with context-dependent translation, and a top-level
which manages the information flow between the
other modules and the user.
MedSLT also includes an intelligent help mod-
ule, which adds robustness to the system and guides
the user towards the supported coverage. The help
module uses a backup recogniser, equipped with a
statistical language model, and matches the results
from this second recogniser against a corpus of utter-
ances which are within system coverage and trans-
late correctly. In previous studies, we showed that
the grammar-based recogniser performs much bet-
ter than the statistical one on in-coverage utterances,
but worse on out-of-coverage ones. Having the help
system available approximately doubled the speed
at which subjects learned, measured as the average
difference in semantic error rate between the results
for their first quarter-session and their last quarter-
session (Rayner et al, 2005a). It is also possible to
recover from recognition errors by selecting a dis-
played help sentence; this typically increases the
number of acceptably processed utterances by about
10% (Starlander et al, 2005).
We will demo several versions of the system, us-
ing different source languages, target languages and
subdomains. Coverage is based on standard exami-
nation questions obtained from doctors, and consists
mainly of yes/no questions, though there is also sup-
port for WH-questions and elliptical utterances. Ta-
ble 1 gives examples of the coverage in the English-
input headache version, and Table 2 summarises
recognition performance in this domain for the three
main input languages. Differences in the sizes of the
recognition vocabularies are primarily due to differ-
ences in use of inflection. Japanese, with little in-
flectional morphology, has the smallest vocabulary;
French, which inflects most parts of speech, has the
largest.
3 The development environment
Although the MedSLT system is rule-based, we
would, for the usual reasons, prefer to acquire these
rules from corpora using some well-defined method.
There is, however, little or no material available for
most medical speech translation domains, including
ours. As noted in (Probst and Levin, 2002), scarcity
of data generally implies use of some strategy to ob-
tain a carefully structured training corpus. If the cor-
pus is not organised in this way, conflicts between
alternate learned rules occur, and it is hard to in-
Where?
?do you experience the pain in your jaw?
?does the pain spread to the shoulder?
When?
?have you had the pain for more than a month?
?do the headaches ever occur in the morning?
How long?
?does the pain typically last a few minutes?
?does the pain ever last more than two hours?
How often?
?do you get headaches several times a week?
?are the headaches occurring more often?
How?
?is it a stabbing pain?
?is the pain usually severe?
Associated symptoms?
?do you vomit when you get the headaches?
?is the pain accompanied by blurred vision?
Why?
?does bright light make the pain worse?
?do you get headaches when you eat cheese?
What helps?
?does sleep make the pain better?
?does massage help?
Background?
?do you have a history of sinus disease?
?have you had an e c g?
Table 1: Examples of English MedSLT coverage
duce a stable set of rules. As Probst and Levin sug-
gest, one obvious way to attack the problem is to
implement a (formal or informal) elicitation strat-
egy, which biases the informant towards translations
which are consistent with the existing ones. This is
the approach we have adopted in MedSLT.
The Regulus platform, on which MedSLT
is based, supports rapid construction of com-
plex grammar-based language models; it uses an
example-based method driven by small corpora
of disambiguated parsed examples (Rayner et al,
2003; Rayner et al, 2006), which extracts most of
the structure of the model from a general linguis-
tically motivated resource grammar. The result is
a specialised version of the general grammar, tai-
lored to the example corpus, which can then be com-
piled into an efficient recogniser or into a genera-
Language Vocab WER SemER
English 441 6% 18%
French 1025 8% 10%
Japanese 347 4% 4%
Table 2: Recognition performance for English,
French and Japanese headache-domain recognisers.
?Vocab? = number of surface words in source lan-
guage recogniser vocabulary; ?WER? = Word Error
Rate for source language recogniser, on in-coverage
material; ?SemER? = semantic error rate for source
language recogniser, on in-coverage material.
tion module. Regulus-based recognisers and gen-
erators are easy to maintain, and grammar struc-
ture is shared automatically across different subdo-
mains. Resource grammars are available for several
languages, including English, Japanese, French and
Spanish.
Nuance recognisers derived from the resource
grammars produce both a recognition string and a
semantic representation. This representation con-
sists of a list of key/value pairs, optionally including
one level of nesting; the format of interlingua and
target language representations is similar. The for-
malism is sufficiently expressive that a reasonable
range of temporal and causal constructions can be
represented (Rayner et al, 2005b). A typical exam-
ple is shown in Figure 1. A translation rule maps
a list of key/value pairs to a list of key/value pairs,
optionally specifying conditions requiring that other
key/value pairs either be present or absent in the
source representation.
When developing new coverage for a given lan-
guage pair, the developer has two main tasks. First,
they need to add new training examples to the
corpora used to derive the specialised grammars
used for the source and target languages; second,
they must add translation rules to handle the new
key/value pairs. The simple structure of the Med-
SLT representations makes it easy to support semi-
automatic acquisition of both of these types of in-
formation. The basic principle is to attempt to find
the minimal set of new rules that can be added to the
existing set, in order to cover the new corpus exam-
ple; this is done through a short elicitation dialogue
with the developer. We illustrate this with a simple
example.
Suppose we are developing coverage for the En-
glish ? Spanish version of the system, and that
the English corpus sentence ?does the pain occur at
night? fails to translate. The acquisition tool first
notes that processing fails when converting from in-
terlingua to Spanish. The interlingua representation
is
[[utterance_type,ynq],
[pronoun,you],
[state,have_symptom],
[symptom,pain],[tense,present],
[prep,in_time],[time,night]]
Applying Interlingua ? Spanish rules, the result is
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
failed:[time,night]]
where the tag failed indicates that the element
[time,night] could not be processed. The tool
matches the incomplete transferred representation
against a set of correctly translated examples, and
shows the developer the English and Spanish strings
for the three most similar ones, here
does it appear in the morning
-> tiene el dolor por la man?ana
does the pain appear in the morning
-> tiene el dolor por la man?ana
does the pain come in the morning
-> tiene el dolor por la man?ana
This suggests that a translation for ?does the pain
occur at night? consistent with the existing rules
would be ?tiene el dolor por la noche?. The devel-
oper gives this example to the system, which parses
it using both the general Spanish resource grammar
and the specialised grammar used for generation in
the headache domain. The specialised grammar fails
to produce an analysis, while the resource grammar
produces two analyses,
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[[utterance_type,ynq],[pronoun,you],[state,have_symptom],
[tense,present],[symptom,headache],[sc,when],
[[clause,[[utterance_type,dcl],[pronoun,you],
[action,drink],[tense,present],[cause,coffee]]]]
Figure 1: Representation of ?do you get headaches when you drink coffee?
[tense,present],
[prep,por_temporal],
[temporal,noche]]
and
[[utterance_type,dcl],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
[temporal,noche]]
The first of these corresponds to the YN-question
reading of the sentence (?do you have the pain at
night?), while the second is the declarative reading
(?you have the pain at night?). Since the first (YN-
question) reading matches the Interlingua represen-
tation better, the acquisition tool assumes that it is
the intended one. It can now suggest two pieces of
information to extend the system?s coverage.
First, it adds the YN-question reading of ?tiene
el dolor por la noche? to the corpus used to train
the specialised generation grammar. The piece
of information acquired from this example is that
[temporal,noche] should be realised in this
domain as ?la noche?. Second, it compares the cor-
rect Spanish representation with the incomplete one
produced by the current set of rules, and induces a
new Interlingua to Spanish translation rule. This will
be of the form
[time,night] -> [temporal,noche]
In the demo, we will show how the development
environment makes it possible to quickly add new
coverage to the system, while also checking that old
coverage is not broken.
References
P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,
and H. Isahara. 2005. A generic multi-lingual open
source platform for limited-domain medical speech
translation. In In Proceedings of the 10th Conference
of the European Association for Machine Translation
(EAMT), Budapest, Hungary.
MedBridge, 2006. http://www.medtablet.com/index.html.
As of 15 March 2006.
MedSLT, 2005. http://sourceforge.net/projects/medslt/.
As of 15 March 2005.
Phraselator, 2006. http://www.phraselator.com. As of 15
March 2006.
K. Probst and L. Levin. 2002. Challenges in automatic
elicitation of a controlled bilingual corpus. In Pro-
ceedings of the 9th International Conference on The-
oretical and Methodological Issues in Machine Trans-
lation.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner, P. Bouillon, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, H. Isahara, K. Kankazi,
and Y. Nakao. 2005a. A methodology for comparing
grammar-based and robust approaches to speech un-
derstanding. In Proceedings of the 9th International
Conference on Spoken Language Processing (ICSLP),
Lisboa, Portugal.
M. Rayner, P. Bouillon, M. Santaholma, and Y. Nakao.
2005b. Representational and architectural issues in a
limited-domain medical speech translator. In Proceed-
ings of TALN/RECITAL, Dourdan, France.
M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting
Linguistics into Speech Recognition: The Regulus
Grammar Compiler. CSLI Press, Chicago.
Regulus, 2006. http://sourceforge.net/projects/regulus/.
As of 15 March 2006.
S-MINDS, 2006. http://www.sehda.com. As of 15
March 2006.
M. Starlander, P. Bouillon, N. Chatzichrisafis, M. Santa-
holma, M. Rayner, B.A. Hockey, H. Isahara, K. Kan-
zaki, and Y. Nakao. 2005. Practicing controlled lan-
guage through a help system integrated into the medi-
cal speech translation system (MedSLT). In Proceed-
ings of the MT Summit X, Phuket, Thailand.
Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 713?720
Manchester, August 2008
Almost Flat Functional Semantics for Speech Translation
Manny Rayner1, Pierrette Bouillon1, Beth Ann Hockey2, Yukie Nakao3
1 University of Geneva, TIM/ISSCO
40 bvd du Pont-d?Arve
CH-1211 Geneva 4, Switzerland
Emmanuel.Rayner@issco.unige.ch
Pierrette.Bouillon@issco.unige.ch
2 UCSC UARC, Mail Stop 19-26
NASA Ames Research Center
Moffet Field, CA 94035
bahockey@ucsc.edu
3 University of Nantes, LINA
2, rue de la Houssinie`re
BP 92208 44322 Nantes Cedex 03
yukie.nakao@univ-nantes.fr
Abstract
We introduce a novel semantic represen-
tation formalism, Almost Flat Functional
semantics (AFF), which is designed as an
intelligent compromise between linguis-
tically motivated predicate/argument se-
mantics and ad hoc engineering solutions
based on flat feature/value lists; the cen-
tral idea is to tag each semantic element
with the functional marking which most
closely surrounds it. We argue that AFF is
well-suited for medium-vocabulary speech
translation applications, and describe sim-
ple and general algorithms for parsing,
generating and performing transfer using
AFF representations. The formalism has
been fully implemented within a medium-
vocabulary interlingua-based Open Source
speech translation system which translates
between English, French, Japanese and
Arabic.
1 Introduction
Many speech translation architectures require
some way to represent the meaning of spoken ut-
terances, but even a brief review of the literature
reveals a serious divergence of opinion as to how
this may best be done. At risk of oversimplifying
a little, there are two competing heritages. On the
one hand, there is the mainstream computational
semantics approach, which ultimately goes back
to philosophers like Montague, Russell and Frege
and views predicate calculus as the paradigm rep-
resentation language. On this view of things, a
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
suitable way to represent meaning is to use com-
plex structures, in which components and relation-
ships are based on deep grammatical functions.
Typical ways to realise this strategy are unscoped
logical forms, neo-Davidsonian semantics, mini-
mal recursion semantics, and similar formalisms.
Thus a sentence like ?I want a pepperoni pizza?
might be represented as something like
want1(E, X, Y),
ref(X, pronoun(i)),
quant(Y, indef), pizza1(Y),
pepperoni1(Z), nn(Z, Y)
Approaches based in the linguistic tradition were
dominant about 10 to 15 years ago, when they were
used in major systems like Germany?s Verbmo-
bil (Wahlster, 2000) and SRI?s Spoken Language
Translator (Rayner et al, 2000). They are still
reasonably popular today, as exemplified by major
systems like PARC?s XLE (Riezler et al, 2002).
The competing heritage has its roots in engi-
neering approaches to spoken language systems,
which historically have been intimately connected
with Machine Learning. On this view of things,
a typical semantic representation is a flat list of
feature-value pairs, with the features represent-
ing semantic concepts: here, ?I want a pepperoni
pizza? would be represented as something like
[utterance_type=request,
food=pizza, type=pepperoni]
It is interesting to see how little contact there
has been between these two traditions. Writers
on formal semantics usually treat ad hoc feature-
value representations as not even worthy of serious
discussion. Conversely, proponents of engineer-
ing/machine learning approaches often assume in
practice that all semantic representations will be
some version of a flat feature-value list; a good
713
example of this tendency is Young?s widely cited
2002 survey of machine learning approaches to
spoken dialogue (Young, 2002).
Trying to be as neutral as possible, it is reason-
able to argue that both approaches have important
things to offer, and that it is worth trying to find
some compromise between them. Other things be-
ing equal, flat feature-value representations have
desirable formal properties: they are simple, and
easy to manipulate and reason with. Their draw-
back is that they are an impoverished represen-
tation language, which can lose important infor-
mation. This means that concepts may be im-
possible to represent, or, alternately viewed, that
the representation format may conflate concepts
which we would prefer to distinguish. In the other
direction, hierarchical logic-based representations
are highly expressive, but pose much more serious
challenges in terms of formal manipulability. Al-
though they are more easily capable of represent-
ing semantic distinctions, it is harder to use them to
perform concrete reasoning operations. In transla-
tion systems, these abstract issues manifest them-
selves in a tradeoff between complexity of trans-
lation rules, and ambiguity of semantic represen-
tations. A flat semantic representation formalism
means that translation rules are simple to write;
however, it also means that the semantic represen-
tations they operate on are more likely to be am-
biguous.
In this paper, we will explore the tradeoffs be-
tween the two competing positions outlined above
in the context of a concrete Open Source sys-
tem, the MedSLT medical speech translator. Pre-
vious versions of MedSLT have used a represen-
tation strategy intermediate between the ?logic-
based semantics? and the ?flat semantics? ap-
proaches, though much closer to the ?flat? end of
the scale. We will discuss the strengths and weak-
nesses of the original MedSLT representation for-
malism, and then present a revised version, ?Al-
most Flat Functional Semantics? (AFF). As the
name suggests, AFF incorporates functional mark-
ings, characteristic of a logic-based semantics ap-
proach, into a representation formalism which still
mainly consists of flat list structures. We will show
how grammars using semantics written in AFF can
be compiled into parsers and generators, and de-
scribe a simple formalism that can be used to spec-
ify rules for translating AFF expressions into AFF
expressions. Finally, we will show how use of AFF
in MedSLT has allowed us to address in a princi-
pled way most of the examples which are problem-
atic for the original version of the system, while
still retaining a simple and transparent framework
for writing translation rules.
2 The MedSLT System
MedSLT (Bouillon et al, 2005) is a medium-
vocabulary Open Source speech translation system
for medical domains, implemented using the Open
Source Regulus compiler (Rayner et al, 2006)
and the Nuance recognition platform. Process-
ing is primarily rule-based. Recognition uses a
grammar-based language model, which produces
a source-langage semantic representation. This is
first translated by one set of rules into an interlin-
gual form, and then by a second set into a target
language representation. A target-language gram-
mar, compiled into generation form, turns this into
one or more possible surface strings, after which
a set of generation preferences picks one out. Fi-
nally, the selected string is realised in spoken form.
There is also some use of corpus-based statistical
methods, both to tune the language model (Rayner
et al, 2006, Section 11.5) and to drive a robust em-
bedded help system (Chatzichrisafis et al, 2006).
The treatment of syntactic structure is a care-
fully thought-out compromise between linguistic
and engineering traditions. All grammars used
are extracted from general linguistically motivated
resource grammars, using corpus-based methods
driven by small sets of examples (Rayner et al,
2006, Chapter 9). This results in a simpler and flat-
ter grammar specific to the domain, whose struc-
ture is similar to the ad hoc phrasal grammars typ-
ical of engineering approaches. The treatment of
semantics is however less sophisticated, and ba-
sically represents a minimal approach in the en-
gineering tradition. Each lexicon item contributes
a set of zero or more feature-value pairs (in most
cases exactly one pair). Most of the grammar rules
simply concatenate the sets of pairs received from
their daughters. A small number of rules, primarily
those for subordinate clauses, create a nested sub-
structure representing the embedded clause. Fig-
ure 1 shows an example representation.
It should be obvious from the example that the
flat representation is potentially very ambiguous,
since nearly all information about grammatical
functions has been lost. The example also illus-
trates, however, why this is often unimportant in
714
[[utterance_type,sentence],
[pronoun,vous],
[path_proc,avoir],
[voice,active],
[tense,present],
[cause,nause?e], [sc,quand],
[clause,
[[pronoun,vous],
[symptom,mal],
[path_proc,avoir],
[voice,active],
[tense,present]]])]
Figure 1: Semantic representation produced by the
current MedSLT system for the French sentence
Avez-vous des nause?es quand vous avez mal? (?Do
you have nausea when you have the pain??)
practice. From a purely syntactic point of view,
the fragment
[[pronoun,vous],
[path_proc,avoir],
[cause,nause?e]]
could either represent vous avez des nause?es (?you
have nausea?) or des nause?es vous ont (?nausea
has you?). Except, possibly, in certain kinds of
literary contexts, the second realisation is so im-
plausible that it can be discounted. It is thus rea-
sonable to add sortal constraints to the lexical en-
tries involved, which permit des nause?es to occur
in well-formed utterances as the object of avoir,
but not as its subject. Thus the representation is
in fact unambiguous, and will only generate one
surface realisation.
With the moderate vocabularies used by Med-
SLT (for example, the current French module has
a vocabulary of about 1 100 surface words), the
vast majority of constructions can be rendered un-
ambiguous using similar strategies. The result is
that most translation rules are easy to write, since
they have to do no more than map lists of feature-
value pairs to lists of feature-value pairs. To take
a typical example, the Japanese question itami wa
koutoubu desu ka (?pain-TOPIC back-part-head is-
Q?) receives the representation
[[utterance_type,sentence],
[symptom,itami],
[body_part,koutoubu],
[verb,desu], [tense,present]]
which we wish to map to the interlingua represen-
tation
[[utterance_type,ynq], [verb,be],
[tense,present], [voice,active],
[symptom,pain], [prep,in_loc],
[part,back], [body_part,head]]
(?is the pain in the back of the head?). In a more
expressive semantic framework, the structural mis-
matches here would be non-trivial to resolve. In
the flat MedSLT notation, we only need the fol-
lowing two list-to-list translation rules:
transfer_rule(
[[body_part,koutoubu]],
[[prep,in_loc], [part,back],
[body_part,head]]).
(koutoubu ? ?in the back of the head?) and
transfer_rule(
[[verb, desu]],
[[verb, be]]).
(desu ? ?is?).
As usual, however, we pay a price for simplicity.
In the terminology of Statistical Machine Transla-
tion, what we are essentially doing here is weaken-
ing the channel model, and relying on the strength
of the target language model. This is a reason-
able strategy partly because of the restricted nature
of the domain, and partly because of the fact that
the initial parsing stage makes it possible for us
to work with bags of concepts rather than bags of
words; clearly, bags of concepts are more expres-
sive.
None the less, it is normal to expect the un-
derspecified channel model to cause some prob-
lems, and this indeed proves to be the case. Al-
though most semantic relationships in the domain
are unambiguous even as bags of concepts (?back
of the head? is possible; ?head of the back? isn?t),
there are unpleasant counterexamples. For in-
stance, {?visit?, ?doctor?, ?patient?} can be re-
alised as either ?patient visits doctor? or ?doc-
tor visits patient?. Similarly, {?precede?, ?nau-
sea?, ?headache?} can be either ?nausea precedes
headache? or ?headache precedes nausea?. Cases
like these must be dealt with using ad hoc solu-
tions based on domain pragmatics. In the current
version of the system, ?patient visits doctor? is
forced by producing both surface realisations, and
defining a generation preference. In the case of
{?precede?, ?nausea?, ?headache?}, the problem
is addressed by dividing symptoms into ?primary?
(the symptom the patient is being examined for,
e.g. ?headache?) and ?secondary? (other possibly
715
utterance:[sem=concat(Verb, [[tag, obj, Np]])] -->
verb:[sem=Verb], np:[sem=Np].
np:[sem=concat(Adj, Noun)] -->
spec:[], ?adj:[sem=Adj], noun:[sem=Noun].
np:[sem=concat(Np, PP)] -->
np:[sem=Np], pp:[sem=PP].
pp:[sem=[[tag, Tag, Np]]] -->
prep:[sem=Tag], np:[sem=Np].
verb:[sem=[[action, grasp]]] --> grasp.
noun:[sem=[[thing, block]]] --> block.
noun:[sem=[[loc, table]]] --> table.
adj:[sem=[[colour, red]]] --> red.
spec:[] --> the.
prep:[sem=on] --> on.
Figure 2: Toy grammar with nested predicate-argument semantics.
related symptoms, e.g. ?nausea?). It is reasonable
in practice to assume that the doctor will only be
interested in secondary symptoms that may cause
primary ones, and hence will precede them.
Although each language in the current version
of MedSLT only contains a handful of similar
cases, solutions like those outlined above are both
inelegant and brittle. It would be desirable to find
some more principled way to deal with them; we
would, however, like to do this without sacrificing
the appealing simplicity of the translation rule for-
malism. In the next section, we will show how it is
possible to reconcile these two conflicting goals.
3 Almost Flat Functional Semantics
As we have seen, the problem with a simple bag-
of-concepts representation is its ambiguity; what
we would like to do is find some principled way to
reduce that ambiguity, without greatly increasing
the formalism?s representational complexity. At
this point, a linguistic intuition is helpful. The
bag-of-concepts representation can reasonably be
thought of as an artificial free word-order lan-
guage. There are many natural free word-order
languages; the reason why they are in general no
more ambiguous than fixed word-order languages
is that they use case-marking to convey functional
information which constrains the space of pos-
sible interpretations. For speakers of European
languages, the best-known example will proba-
bly be Classical Latin. For instance, when St.
Jerome wrote Amor ordinem nescit (?love-NOM
order-ACC not-know-PRES-3-SING?), the case-
markings make it clear that he meant ?Love does
not know order? rather than ?Order does not know
love?.
The comparison with free word-order languages
suggests a natural extension of the original bag-
of-concepts representation, where each element is
associated with an additional functional tag which
does the work that a case-marking would do in a
natural free word-order language. It also suggests
a simple construction which can be used to cre-
ate an unordered linear representation that includes
functional tags. We start by defining a standard
nested predicate-argument semantics; we then flat-
ten the representation of each clause S, marking
each primitive semantic element with the imme-
diately surrounding functional tag in S, or with a
null marking if there is no such tag. The resulting
semantic representations still represent each clause
as an unordered list, but in contrast to the MedSLT
bag-of-concepts representation now include func-
tional information. We will call this style of rep-
resentation Almost Flat Functional (AFF) seman-
tics; the ?almost? comes from the fact that there is
still a minimal amount of nested structure, repre-
senting the distinction between main and embed-
ded clauses.
Figures 2 and 3 give a concrete illustration of the
716
[[action, grasp], [null=[action, grasp],
[tag, obj, obj=[colour, red],
[[colour, red], obj=[thing, block],
[thing, block], on=[loc, table]]
[tag, on,
[[loc, table]]]]]]
Figure 3: Construction of AFF representation for ?grasp the red block on the table?. The AFF represen-
tation (right) is a flattened version of the original nested predicate-argument one (left).
AFF construction. Figure 2 presents a toy Regulus
grammar, which allows a few sentences like ?grasp
the red block on the table? and assigns a nested
functional semantics to them. The representations
of most constituents are unordered lists. In the case
of utterance and np, these are formed by con-
catenating the representations of their daughters.
There are two examples of functional markings:
the rule for utterance wraps an [tag, obj
...] around its np daughter, and the rule for pp
wraps a tag around its np daughter, whose label is
determined by the semantic value of the p daugh-
ter.
Figure 3 introduces the AFF construction itself.
The left-hand side of the figure shows the nested
predicate-argument representation of the sentence,
in which elements of the form
[tag, Tag, Arg]
represent tags and their associated arguments. The
right-hand side shows the derived AFF representa-
tion, where each element that is within the scope of
a [tag ...] has been marked with the tag that
would be immediately above it in the nested ver-
sion. Thus the element [loc, table] is inside
the scope of both the obj tag and the on tag; how-
ever, the AFF version assigns it the on tag, since
this is the innermost one.
In the rest of this section, we will describe how
we can parse surface strings into AFF represen-
tations, generate surface strings from AFF repre-
sentations, and define translation rules which map
AFF representations to AFF representations.
3.1 Analysis and generation
For both analysis and generation, the starting point
is a grammar with a nested predicate-argument se-
mantics like the one shown in the left half of Fig-
ure 3. Analysis is straightforward. We first use a
standard parser-generator to compile the grammar
into a parser; the nested predicate-argument repre-
sentations it produces are then subjected to a post-
processing phase, which flattens them in the way
illustrated in the figure.
This simple approach is however not feasible for
generation, since the flattening operation is highly
non-deterministic in the reverse direction; finding
all possible ?unflattenings? and then attempting
to generate from each one would in most cases
be hopelessly inefficient. A better solution is to
transform the original grammar into one with AFF
semantics, where the current functional marking
is specified as an extra features on relevant con-
stituents, and percolated through the rules. In ef-
fect, the ?unflattening? and generation operations
can now proceed simultaneously, with each one
constraining the other.
Figure 4 presents an example, showing the re-
sult of performing this transformation on the toy
Regulus grammar from Figure 2. Here, the origi-
nal [tag, ...] wrappers have been removed,
and replaced by the new feature tag, which has
been added to all constituents whose semantics is
a list of items of the form Tag=Value. The value
of the tag feature on each constituent where it
is defined is the tag for the most closely enclos-
ing [tag, ...] in the original grammar; these
values are percolated down to the lexical rules,
where they unify with the tags on the semantic
fragment contributed by the rule. The transforma-
tion is straightforward to define in its general form,
and the transformed grammars can be readily com-
piled into efficient generators by standard feature-
grammar generator-compiler algorithms like Se-
mantic Head-Driven Generation (Shieber et al,
1990). For the concrete experiments described
later, we used a slightly extended version of the
Open Source Regulus generator compiler.
3.2 Transfer
Our basic strategy for defining transfer between
AFF expressions is to make it as close as pos-
sible to transfer on the original bag-of-concepts
717
utterance:[sem=concat(Verb, Np)] -->
verb:[sem=Verb, tag=null], np:[sem=Np, tag=obj].
np:[sem=concat(Adj, Noun), tag=Tag] -->
spec:[], ?adj:[sem=Adj, tag=Tag], noun:[sem=Noun, tag=Tag].
np:[sem=concat(Np, PP), tag=Tag] -->
np:[sem=Np, tag=Tag], pp:[sem=PP, tag=Tag].
pp:[sem=Np] -->
prep:[sem=Tag], np:[sem=Np, tag=Tag].
verb:[sem=[Tag=[action, grasp]], tag=Tag] --> grasp.
noun:[sem=[Tag=[thing, block]], tag=Tag] --> block.
noun:[sem=[Tag=[loc, table]], tag=Tag] --> table.
adj:[sem=[Tag=[colour, red]], tag=Tag] --> red.
spec:[] --> the.
prep:[sem=on] --> on.
Figure 4: Version of grammar from Figure 2 after transformation to AFF semantics.
representations, which is conditional mapping of
lists to lists. Since AFF is an extension of bag-
of-concepts, and bag-of-concepts is usually suffi-
ciently unambiguous as it stands, we only want
to add the functional markings in the cases where
they are required. Most of our rules will thus still
be transfer rules like the ones shown in Sec-
tion 2, except that they now map lists of function-
marking-tagged items to lists of function-marking-
tagged items; however, in accordance with the
stated design principles, we allow tags to be omit-
ted when desired, with the convention that an omit-
ted tag denotes an uninstantiated tag value.
One of the underlying linguistic intuitions be-
hind AFF is that there are correspondences be-
tween functional markings in different languages,
with each given functional marking f
s
in the
source language typically mapping to a specific
functional marking f
t
in the target language.
For this reason, it would be highly unnatural
only to specify transformations of tag values us-
ing transfer rules. We consequently intro-
duce a second kind of rule, which we call a
tag transfer rule; as the name suggests,
this defines a direct mapping from tags to tags.
Given the fact that functional tags have some claim
to universality, it is reasonable to hope that many
tags will map onto themselves. Thus a typical tag
rule might map the English subj tag to the Arabic
subj tag, which we write as
tag_transfer_rule(subj, subj).
Most tag transfer rules will be of the above
simple form. However, there are always cases
where languages diverge structurally, and here it
will be necessary to make the tag transfer rule con-
ditional on its surrounding context. For example,
English constructions with the verb ?last? (?Does
the headache last more than ten minutes??) are
realised differently in Arabic, using the transitive
verb tahus bi (?feel?), thus here hal tahus bi al
soudaa li akthar min achr daqayq? (?Do (you)
feel the headache during more than ten minutes??).
Here, ?headache? is marked as subj in English,
but the correspoding Arabic word, soudaa, is the
obj of tahus bi. We express the general fact that
we wish to map subj to obj in the context of the
verb ?last? using the rule
tag_transfer_rule(subj, obj) :-
context([state, last]).
We also require a normal transfer rule
which maps ?last? to tahus bi. This also has to
introduce an implicit second person subject, so the
full rule is
transfer_rule(
[[state, last]],
[[state, tahus_bi],
subj=[pronoun, anta]]).
(anta = ?you?). Related sets of rules of this kind
can be written more concisely with a small exten-
718
sion to the formalism, as follows:
transfer_rule(
[[state, last]],
[[state, tahus_bi],
subj=[pronoun, anta]],
[subj:obj]).
An important question we have so far postponed
discussing is how to fill in unspecified tag values
on the RHS of a transfer rule application.
At first, we believed that several possible strate-
gies were feasible; rather to our surprise, examina-
tion of some examples convinced us that only one
of these strategies actually made sense. The algo-
rithm is as follows. We assume a transfer -
rule R, whose LHS has successfully matched a
set of tag/concept pairs, and consider the following
cases:
1. R explicitly assigns values to all of the tags
on its RHS. There is nothing more to do.
2. Not all of the tags on the RHS are assigned
values by R. Apply tag transfer rules
to all the matched tags on the LHS which
were not originally assigned values by R, giv-
ing a set of tags {T
1
...T
n
}. There are now two
subcases:
(a) n = 1, i.e. only one transferred tag is
produced. Set the values of all the unin-
stantiated tags on the transferred RHS to
T
1
.
(b) n > 1, i.e. several different transferred
tags are produced. Leave the values of
the ininstantiated tags on the transferred
RHS uninstantiated.
The least obvious part of this is (2a), which
is easier to understand when we consider some
more specific cases. The simplest and most com-
mon example is the case where R is a ?lex-
ical? transfer rule which contains exactly
one tag/concept pair on each side, each tag be-
ing left unspecified. We evidently need to apply
a tag transfer rule to the tag matched by the
single pair on the LHS, to get the value of the tag
attached to the transferred RHS.
To take a slightly more complex case, consider
an English ? Japanese rule which maps the ex-
pression ?back of the head? to the single word
koutoubu. We could write this as
transfer_rule(
[[part, back],
of=[body_part,head]],
[[body_part, koutoubu]])
Here, it is clear that we want to translate the tag
on the source-language pair that matches [part,
back], and assign it to the target-language ele-
ment [body part, koutoubu]. The transla-
tion of the tag of is irrelevant.
4 Using AFF in MedSLT
We have implemented and tested a version of AFF
inside the Open Source MedSLT system, building
AFF versions of the grammars for English, French
Japanese, Arabic and the Interlingua. We also cre-
ated AFF versions of the translation rules between
the four surface languages and the Interlingua, in
both directions. Coverage and performance of the
two versions of the system on development data
were essentially the same; the key differences were
architectural in nature. We now briefly summarise
these differences.
The basic tradeoff is between analysis and gen-
eration on one hand, and translation on the other.
The more expressive AFF formalism implies that
representations are less ambiguous, which means
fewer problems in the analysis and generation
components. The downside is that the translation
rules become more complex. On the positive side,
switching from bag-of-concepts to AFF allowed us
to implement clean solutions to a substantial num-
ber of problems which were previously handled in
an ad hoc manner. As previously noted, English
constructions using verbs like ?precede?, ?cause?,
?accompany?, ?visit? and ?be in contact with? are
in general ambiguous in the bag-of-words repre-
sentation, and had to be solved by artificially con-
straining their arguments; AFF makes it possible
to do this by simply differentiating between subj
and obj tags. Similar considerations applied to
constructions in the other two languages. For ex-
ample, using bag-of-words, the Arabic frequency
expressions thalath marrat fi al ousbou (?three
times a week?) and marra kul thalathat assabii
(?once every three weeks?) were previously rep-
resented in the same way, necessitating addition of
a brittle generation preference. AFF once again
allows the two expressions to be cleanly distin-
guished.
It was evident from the start that we would
win on this kind of example; what was less clear
719
was the price we would have to pay, in terms
of increased complexity of the transfer rule set.
Gratifyingly, the conservative nature of the ex-
tension meant that this price turned out to be
quite low. We had originally wondered whether
it would be necessary to write many condi-
tional tag transfer rules, or add functional
tags to a large proportion of the transfer -
rules. In fact, out of the total of 4444 rules
used by the eight language pairs together, only
39 (0.9%) were conditional tag transfer -
rules, and 524 (11.8%) were transfer rules
containing at least one functional tag. A fur-
ther 120 rules (2.7%) were unconditional tag -
transfer rules. The remaining 3761 rules
(84.6%) were transfer rules which did not
explicitly mention functional tags, and were thus
essentially bag-of-concepts mapping rules. To
summarise, less than a sixth of the rules were af-
fected by moving to the new framework.
5 Summary and Conclusions
We have described Almost Flat Functional seman-
tics, a formalism which adds functional markings
to a flat atheoretical feature/value representation.
The additional functional information in AFF is
sufficient to resolve nearly all of the representa-
tional ambiguities which caused problems for the
flat bag-of-concepts formalism. In terms of repre-
sentational complexity, however, the AFF formal-
ism appears to be only slightly less tractable than
bag-of-concepts. It seems reasonable to us that,
like bag-of-concepts, it could also support learn-
able surface-oriented parsing; this could be com-
bined with statistical recognition to provide a ro-
bust back-up to grammar-based speech processing
(Rayner et al, 2005), a claim that we hope to inves-
tigate empirically in the near future. It is much less
clear that full logic-based representations could be
used for such purposes.
What we find interesting here, from a general
perspective, is that we were able to create a re-
duced, but still essentially clean, form of a main-
stream linguistic treatment, and incorporate it into
an ad hoc engineering framework in a way that
only marginally affected that framework?s perfor-
mance characteristics. Without wishing to exag-
gerate the importance of our results, we think ex-
amples like AFF suggest that the gulf between
these two types of approach is not, perhaps, as
wide as is sometimes suggested.
References
Bouillon, P., M. Rayner, N. Chatzichrisafis, B.A.
Hockey, M. Santaholma, M. Starlander, Y. Nakao,
K. Kanzaki, and H. Isahara. 2005. A generic multi-
lingual open source platform for limited-domain
medical speech translation. In Proceedings of the
10th Conference of the European Association for
Machine Translation (EAMT), pages 50?58, Bu-
dapest, Hungary.
Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-
holma, M. Starlander, and B.A. Hockey. 2006. Eval-
uating task performance for a unidirectional con-
trolled language medical speech translation system.
In Proceedings of the HLT-NAACL International
Workshop on Medical Speech Translation, pages 9?
16, New York.
Rayner, M., D. Carter, P. Bouillon, V. Digalakis, and
M. Wire?n, editors. 2000. The Spoken Language
Translator. Cambridge University Press.
Rayner, M., P. Bouillon, N. Chatzichrisafis, B.A.
Hockey, M. Santaholma, M. Starlander, H. Isahara,
K. Kanzaki, and Y. Nakao. 2005. A methodol-
ogy for comparing grammar-based and robust ap-
proaches to speech understanding. In Proceedings
of the 9th International Conference on Spoken Lan-
guage Processing (ICSLP), pages 1103?1107, Lis-
boa, Portugal.
Rayner, M., B.A. Hockey, and P. Bouillon. 2006.
Putting Linguistics into Speech Recognition: The
Regulus Grammar Compiler. CSLI Press, Chicago.
Riezler, S., T.H. King, R.M. Kaplan, R. Crouch, J.T.
Maxwell, and M. Johnson. 2002. Parsing the
wall street journal using a lexical-functional gram-
mar and discriminative estimation techniques. In
Proceedings of the 40th Annual Meeting of the Asso-
ciation for Computational Linguistics (demo track),
Philadelphia, PA.
Shieber, S., G. van Noord, F.C.N. Pereira, and R.C.
Moore. 1990. Semantic-head-driven generation.
Computational Linguistics, 16(1).
Wahlster, W., editor. 2000. Verbmobil: Foundations of
Speech-to-Speech Translation. Springer.
Young, S. 2002. Talking to machines (statistically
speaking). In Proceedings of the 7th International
Conference on Spoken Language Processing (IC-
SLP), pages 9?16, Denver, CO.
720
Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 54?62,
Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLP
Using Artiially Generated Data
to Evaluate Statistial Mahine Translation
Manny Rayner, Paula Estrella, Pierrette Bouillon
University of Geneva, TIM/ISSCO
40 bvd du Pont-d'Arve, CH-1211 Geneva 4, Switzerland
fEmmanuel.Rayner,Paula.Estrella,Pierrette.Bouillongunige.h
Beth Ann Hokey
Mail Stop 19-26, UCSC UARC
NASA Ames Researh Center, Moffett Field, CA 94035?1000
bahokeyus.edu
Yukie Nakao
LINA, Nantes University, 2, rue de la Houssiniere, BP 92208 44322 Nantes Cedex 03
yukie.nakaouniv-nantes.fr
Abstrat
Although Statistial Mahine Translation
(SMT) is now the dominant paradigm
within Mahine Translation, we argue that
it is far from lear that it an outperform
Rule-Based Mahine Translation (RBMT)
on small- to medium-voabulary applia-
tions where high preision is more impor-
tant than reall. A partiularly important
pratial example is medial speeh trans-
lation. We report the results of exper-
iments where we ongured the various
grammars and rule-sets in an Open Soure
medium-voabulary multi-lingual medial
speeh translation system to generate large
aligned bilingual orpora for English !
Frenh and English ! Japanese, whih
were then used to train SMT models based
on the ommon ombination of Giza++,
Moses and SRILM. The resulting SMTs
were unable fully to reprodue the per-
formane of the RBMT, with performane
topping out, even for English ! Frenh,
with less than 70% of the SMT translations
of previously unseen sentenes agreeing
with RBMT translations. When the out-
puts of the two systems differed, human
judges reported the SMT result as fre-
quently being worse than the RBMT re-
sult, and hardly ever better; moreover, the
added robustness of the SMT only yielded
a small improvement in reall, with a large
penalty in preision.
1 Introdution
When Statistial Mahine Translation (SMT) was
rst introdued in the early 90s, it enountered a
hostile reeption, and many people in the researh
ommunity were unwilling to believe it ould ever
be a serious ompetitor to symboli approahes
(f. for example (Arnold et al, 1994)). The pendu-
lum has now swung all the way to the other end of
the sale; right now, the prevailing wisdom within
the researh ommunity is that SMT is the only
truly viable arhiteture, and that rule-based ma-
hine translation (RBMT) is ultimately doomed to
failure. In this paper, one of our initial onerns
will be to argue for a ompromise position. In our
opinion, the initial septiism about SMT was not
groundless; the arguments presented against it of-
ten took the form of examples involving deep lin-
guisti reasoning, whih, it was laimed, would be
hard to address using surfae methods. Proponents
of RBMT had, however, greatly underestimated
the extent to whih SMT would be able to takle
the problem of robustness, where it appears to be
far more powerful than RBMT. For most mahine
translation appliations, robustness is the entral
issue, so SMT's urrent preeminene is hardly sur-
prising.
Even for the large-voabulary tasks where SMT
does best, the situation is by no means as lear as
one might imagine: aording to (Wilks, 2007),
purely statistial systems are still unable to out-
perform SYSTRAN. In this paper, we will how-
ever be more onerned with limited-domain MT
tasks, where robustness is not the key requirement,
and auray is paramount. An immediate exam-
54
ple is medial speeh translation, whih is estab-
lishing itself as an an appliation area of some sig-
niane (Bouillon et al, 2006; Bouillon et al,
2008a). Translation in medial appliations needs
to be extremely aurate, sine mistranslations
an have serious or even fatal onsequenes. At
the panel disussion at the 2008 COLING work-
shop on safety-ritial speeh translation (Rayner
et al, 2008), the onsensus opinion, based on in-
put from pratising physiians, was that an appro-
priate evaluation metri for medial appliations
would be heavily slanted towards auray, as op-
posed to robustness. If the metri is normalised so
as to award 0 points for no translation, and 1 point
for a orret translation, the estimate was that a
suitable sore for an inorret translation would
be something between ?25 and ?100 points. With
these requirements, it seems unlikely that a robust,
broad-overage arhiteture has muh hane of
suess. The obvious strategy is to build a limited-
domain ontrolled-language system, and tune it to
the point where auray reahes the desired level.
For systems of this kind, it is at least oneiv-
able that RBMT may be able to outperform SMT.
The next question is how to investigate the issues
in a methodologially even-handed way. A few
studies, notably (Seneff et al, 2006), suggest that
rule-based translation may in fat be preferable in
these ases. (Another related experiment is de-
sribed in (Dugast et al, 2008), though this was
arried out in a large-voabulary system). These
studies, however, have not been widely ited. One
possible explanation is suspiion about method-
ologial issues. Seneff and her olleagues trained
their SMT system on 20 000 sentene pairs, a
small number by the standards of SMT. It is a pri-
ori not implausible that more training data would
have enabled them to reate an SMT system that
was as good as, or better than, the rule-based sys-
tem.
In this paper, our primary goal is to take this
kind of objetion seriously, and develop a method-
ology designed to enable a tight omparison be-
tween rule-based and statistial arhitetures. In
partiular, we wish to examine the widely be-
lieved laim that SMT is now inherently better
than RBMT. In order to do this, we start with a
limited-domain RBMT system; we use it to auto-
matially generate a large orpus of aligned pairs,
whih is used to train a orresponding SMT sys-
tem. We then ompare the performane of the two
systems.
Our argument will be that this situation essen-
tially represents an upper bound for what is possi-
ble using the SMT approah in a limited domain.
It has been widely remarked that quality, as well
as quantity, of training data is important for good
SMT; in many projets, signiant effort is ex-
pended to lean the original training data. Here,
sine the data is automatially generated by a rule-
based system, we an be sure that it is already
ompletely lean (in the sense of being internally
onsistent), and we an generate as large a quan-
tity of it as we require. The appliation, more-
over, uses only a smallish voabulary and a fairly
onstrained syntax. If the derived SMT system is
unable to math the original RBMT system's per-
formane, it seems reasonable to laim that this
shows that there are types of appliations where
RBMT arhitetures are superior.
The experiments desribed have been arried
out using MedSLT, an Open Soure interlingua-
based limited-domain medial speeh translation
system. The rest of the paper is organised as fol-
lows. Setion 2 provides bakground on the Med-
SLT system. Setion 3 desribes the experimen-
tal framework, and Setion 4 the results obtained.
Setion 5 onludes.
2 The MedSLT System
MedSLT (Bouillon et al, 2005; Bouillon et al,
2008b) is a medium-voabulary interlingua-based
Open Soure speeh translation system for dotor-
patient medial examination questions, whih
provides any-language-to-any-language transla-
tion apabilities for all languages in the set En-
glish, Frenh, Japanese, Arabi, Catalan. Both
speeh reognition and translation are rule-based.
Speeh reognition runs on the Nuane 8.5 reog-
nition platform, with grammar-based language
models built using the Open Soure Regulus om-
piler. As desribed in (Rayner et al, 2006),
eah domain-spei language model is extrated
from a general resoure grammar using orpus-
based methods driven by a seed orpus of domain-
spei examples. The seed orpus, whih typi-
ally ontains between 500 and 1500 utteranes,
is then used a seond time to add probabilisti
weights to the grammar rules; this substantially
improves reognition performane (Rayner et al,
2006, x11.5). Voabulary sizes and performane
measures for speeh reognition in the three lan-
55
guages where serious evaluations have been ar-
ried out are shown in Figure 1.
Language Voab WER SemER
English 447 6% 11%
Frenh 1025 8% 10%
Japanese 422 3% 4%
Table 1: Reognition performane for English,
Frenh and Japanese MedSLT reognisers. ?Vo-
ab? = number of surfae words in soure lan-
guage reogniser voabulary; ?WER? = Word Er-
ror Rate for soure language reogniser, on in-
overage material; ?SemER? = semanti error rate
(proportion of utteranes failing to produe orret
interlingua) for soure language reogniser, on in-
overage material.
At run-time, the reogniser produes a soure-
langage semanti representation. This is rst
translated by one set of rules into an interlingual
form, and then by a seond set into a target lan-
guage representation. A target-language Regu-
lus grammar, ompiled into generation form, turns
this into one or more possible surfae strings, af-
ter whih a set of generation preferenes piks
one out. Finally, the seleted string is realised in
spoken form. Robustness issues are addressed by
means of a bak-up statistial reogniser, whih
drives a robust embedded help system. The pur-
pose of the help system (Chatzihrisas et al,
2006) is to guide the user towards supported ov-
erage; it performs approximate mathing of out-
put from the statistial reogniser again a library
of sentenes whih have been marked as orretly
proessed during system development, and then
presents the losest mathes to the user.
Examples of typial English domain sentenes
and their translations into Frenh and Japanese are
shown in Figure 2.
3 Experimental framework
In the literature on language modelling, there is
a known tehnique for bootstrapping a statisti-
al language model (SLM) from a grammar-based
language model (GLM). The grammar whih
forms the basis of the GLM is sampled randomly
in order to reate an arbitrarily large orpus of ex-
amples; these examples are then used as a train-
ing orpus to build the SLM (Jurafsky et al, 1995;
Jonson, 2005). We adapt this proess in a straight-
forward way to onstrut an SMT for a given
language pair, using the soure language gram-
mar, the soure-to-interlingua translation rules, the
interlingua-to-target-language rules, and the tar-
get language generation grammar. We start in the
same way, using the soure language grammar to
build a randomly generated soure language or-
pus; as shown in (Hokey et al, 2008), it is im-
portant to have a probabilisti grammar. We then
use the omposition of the other omponents to
attempt to translate eah soure language sentene
into a target language equivalent, disarding the
examples for whih no translation is produed.
The result is an aligned bilingual orpus of ar-
bitrary size, whih an be used to train an SMT
model.
We used this method to generate aligned or-
pora for the two MedSLT language pairs English
! Frenh and English ! Japanese. For eah lan-
guage pair, we rst generated one million soure-
language utteranes; we next ltered them to keep
only examples whih were full sentenes, as op-
posed to elliptial phrases, and nally used the
translation rules and target-language generators to
attempt to translate eah sentene. This reated
approximately 305K aligned sentene-pairs for
English ! Frenh (1901K words English, 1993K
words Frenh), and 311K aligned sentene-pairs
for English ! Japanese (1941K words English,
2214K words Japanese). We held out 2.5% of
eah set as development data, and 2.5% as test
data. Using Giza++, Moses and SRILM (Oh and
Ney, 2000; Koehn et al, 2007; Stolke, 2002), we
trained SMT models from inreasingly large sub-
sets of the training portion, using the development
portion in the usual way to optimize parameter val-
ues. Finally, we used the resulting models to trans-
late the test portion.
Our primary goal was to measure the extent to
whih the derived versions of the SMT were able
to approximate the original RBMT on data whih
was within the RBMT's overage. There is a sim-
ple and natural way to perform this measurement:
we apply the BLEU metri (Papineni et al, 2001),
with the RBMT's translation taken as the refer-
ene. This means that perfet orrespondene be-
tween the two translations would yield a BLEU
sore of 1.0.
This raises an important point. The BLEU
sores we are using here are non-standard; they
measure the extent to whih the SMT approxi-
mates the RBMT, rather than, as usual, measuring
56
English Is the pain above your eye?
Frenh Avez-vous mal au dessus des yeux?
Japanese Itami wa me no ue no atari desu ka?
English Have you had the pain for more than a month?
Frenh Avez-vous mal depuis plus d'un mois?
Japanese Ikkagetsu ijou itami wa tsuzuki mashita ka?
English Is the pain assoiated with nausea?
Frenh Avez-vous des nause?es quand vous avez la douleur?
Japanese Itamu to hakike wa okori masu ka?
English Does bright light make the pain worse?
Frenh La douleur est-elle aggrave?e par une lumiere forte?
Japanese Akarui hikari wo miru to zutsu wa hidoku nari masu ka?
Table 2: Examples of English domain sentenes, and the system's translations into Frenh and Japanese.
the extent to whih it approximates human trans-
lations. It is important to bring in human judge-
ment, to evaluate the ases where the SMT and
RBMT differ. If, in these ases, it transpired that
human judges typially thought that the SMT was
as good as the RBMT, then the differene would
be purely aademi. We need to satisfy ourselves
that human judges typially asribe differenes be-
tween SMT and RBMT to shortomings in the
SMT rather than in the RBMT.
Conretely, we olleted all the different
hSoure, SMT-translation, RBMT-translationi
triples produed during the ourse of the ex-
periments, and extrated those where the two
translations were different. We randomly seleted
a set of examples for eah language pair, and
asked human judges to lassify them into one of
the following ategories:
 RBMT better: The RBMT translation was
better, in terms of preserving meaning and/or
being grammatially orret;
 SMT better: The SMT translation was bet-
ter, in terms of preserving meaning and/or be-
ing grammatially orret;
 Similar: Both translations were about
equally good OR the soure sentene was
meaningless in the domain.
In order to show that our metris are intuitively
meaningful, it is sufient to demonstrate that the
frequeny of ourrene of RBMT better is both
large in omparison to that of SMT better, and
aounts for a substantial proportion of the total
population.
Finally, we onsider the question of whether
the SMT, whih is apable of translating out-of-
grammar sentenes, an add useful robustness to
the base system. We olleted, from the set used in
the experiments desribed in (Rayner et al, 2005),
all the English sentenes whih failed to be trans-
lated into Frenh. We used the best version of
the English ! Frenh SMT to translate eah of
these sentenes, and asked human judges to eval-
uate the translations as being learly aeptable,
learly unaeptable, or borderline.
In the next setion, we present the results of the
various experiments we have just desribed.
4 Results
We begin with Figure 1, whih shows non-
standard BLEU sores for versions of the English
! Frenh SMT system trained on quantities of
data inreasing from 14 287 to 285 740 pairs. As
an be seen, translation performane improves up
to about 175 000 pairs. After this, it levels out
at around BLEU = 0.90, well below that of the
RBMT system with whih it is being ompared.
A more diret way to report the result is simply to
ount the proportion of test sentenes that are not
in the training data, whih are translated similarly
by the SMT and the RBMT. This gure tops out at
around 68%.
The results strongly suggest that the SMT is
unable to repliate the RBMT's performane at
all losely even in an easy language-pair, irre-
spetive of the amount of training data available.
Out of uriosity, and to reassure ourselves that the
automati generation proedure was doing some-
thing useful, we also tried training the English !
Frenh SMT on pairs derived from the 669 ut-
57
Figure 1: Non-standard BLEU sores against
number of pairs of training sentenes for English
! Frenh; training and test data both indepen-
dently generated, hene overlapping.
terane ?seed orpus? used to generate the gram-
mar (f. Setion 2). This produed utterly dis-
mal performane, with BLEU = 0.52. The result is
more interesting than it may rst appear, sine, in
speeh reognition, the differene in performane
between the SLMs trained from seed orpora and
large generated orpora is fairly small (Hokey et
al., 2008).
It seemed possible that the improvement in per-
formane with inreased quantities of training data
might, in effet, only be due to the SMT fun-
tioning as a translation memory; sine training
and test data are independently generated by the
same random proess, they overlap, with the de-
gree of overlap inreasing as the training set gets
larger. In order to investigate this hypothesis,
we repeated the experiments with data whih had
been uniqued, so that the training and test sets
were ompletely disjoint, and neither ontained
any dupliate sentenes
1
. In fat, Figure 2 show
that the graph for uniqued English ! Frenh data
are fairly similar to the one for the original non-
uniqued data shown in Figures 1. The main differ-
ene is that the non-standard BLEU sore for the
1
Our opinion is that this is not a realisti way to evaluate
the performane of a small-voabulary system; for example,
in MedSLT, one expets that at least some training sentenes,
e.g. ?Where is the pain??, will also our frequently in test
data.
Figure 2: Non-standard BLEU sores against
number of pairs of training sentenes for English
! Frenh; training and test data both indepen-
dently generated, then uniqued to remove dupli-
ates and overlapping items.
uniqued data, unsurprisingly, tops out at a lower
level, reeting the fat that a ?translation mem-
ory? effet does indeed our to some extent.
Results for English ! Japanese showed the
same trends as English ! Frenh, but were more
pronouned. Table 3 ompares the performane
of the best versions of the SMTs for the two
language-pairs, using both plain and artiially
uniqued data. We see that, with plain data, the
English ! Japanese SMT falls even further short
of repliating the performane of the RBMT than
was the ase for English ! Frenh; BLEU is
only 0.76. The differene between the plain and
uniqued versions is also more extreme. BLEU
(0.64) is onsiderably lower for the version trained
on uniqued data, suggesting that the SMT for this
language pair is nding it harder to generalise,
and is in effet loser to funtioning as a trans-
lation memory. This is onrmed by ounting
the sentenes in test data and not in training data
whih were translated similarly by the SMT and
the RBMT; we nd that the gure tops out at the
very low value of 26%.
As noted in our disussion of the experimental
framework, the non-standard BLEU sores only
address the question of whether the performane
of the SMT and RBMT systems is the same. It is
58
Training data Test data BLEU
English ! Frenh
Generated Generated 0.90
Gen/uniqued Gen/uniqued 0.85
English ! Japanese
Generated Generated 0.76
Gen/uniqued Gen/uniqued 0.64
Table 3: Translation performane, in terms of non-
standard BLEU metri, for different ongura-
tions, training on all available data of the spe-
ied type. ?Generated? = data randomly gener-
ated; ?Gen/uniqued? = data randomly generated,
then uniqued so that dupliates are removed and
test and training pairs do not overlap.
neessary to establish what the differenes mean
in terms of human judgements. We onsequently
turn to evaluation of the pairs for whih the SMT
and the RBMT systems produed different trans-
lation results.
Table 4 shows the ategorisation, aording to
the riteria outlined at the end of Setion 3, for 500
English ! Frenh pairs randomly seleted from
the set of examples where RBMT and SMT gave
different results; we asked three judges to evalu-
ate them independently, and ombined their judg-
ments by majority deision where appropriate. We
observed a very heavy bias towards the RBMT,
with unanimous agreement among the judges that
the RBMT translation was better in 201/500 ases,
and 2-1 agreement in a further 127. In ontrast,
there were only 4/500 ases where the judges
unanimously thought that the SMT translation was
preferable, with a further 12 supported by a ma-
jority deision. The rest of the table gives the
ases where the RBMT and SMT translations were
judged the same or ases in whih the judges dis-
agreed; there were only 41/500 ases where no
majority deision was reahed. Our overall on-
lusion is that we are justied in evaluating the
SMT by using the BLEU sores with the RBMT as
the referene. Of the ases where the two systems
differ, only a tiny fration, at most 16/500, indi-
ate a better translation from the SMT, and well
over half are translated better by the RBMT. Ta-
ble 5 presents typial examples of bad SMT trans-
lations in the English ! Frenh pair, ontrasted
with the translations produed by the RBMT. The
rst two are grammatial errors (a superuous ex-
tra verb in the rst, and agreement errors in the
seond). The third is an bad hoie of tense and
preposition; although grammatial, the target lan-
guage sentene fails to preserve the meaning, and,
rather than referring to a 20 day period ending
now, instead refers to a 20 day period some time
in the past.
Result Agreement Count
RBMT better all judges 201
RBMT better majority 127
SMT better all judges 4
SMT better majority 12
Similar all judges 34
Similar majority 81
Unlear disagree 41
Total 500
Table 4: Comparison of RBMT and SMT perfor-
mane on 500 randomly hosen English ! Frenh
translation examples, evaluated independently by
three judges.
Table 6 shows a similar evaluation for the En-
glish ! Japanese. Here, the differene between
the SMT and RBMT versions was so pronouned
that we felt justied in taking a smaller sample, of
only 150 sentenes. This time, 92/150 ases were
unanimously judged as having a better RBMT
translation, and there was not a single ase where
even a majority found that the SMT was better.
Agreement was good here too, with only 8/150
ases not yielding at least a majority deision.
Result Agreement Count
RBMT better all judges 92
RBMT better majority 32
SMT better all judges 0
SMT better majority 0
Similar all judges 2
Similar majority 16
Unlear disagree 8
Total 150
Table 6: Comparison of RBMT and SMT per-
formane on 150 randomly hosen English !
Japanese translation examples, evaluated indepen-
dently by three judges.
Finally, we look at the performane of the SMT
on material whih the RBMT is not able to trans-
late. This would seem to be a situation where
59
English does a temperature hange ause the headahe
RBMT Frenh vos maux de t?ete sont-ils ause?s par des hangements de tempe?rature
(your headahes are-they aused by hanges of temperature)
SMT Frenh avez-vous vos maux de t?ete sont-ils ause?s par des hangements de tempe?rature
(have-you your headahes are-they aused by hanges of temperature)
English are headahes relieved in the afternoon
RBMT Frenh vos maux de t?ete diminuent-ils l'apres-midi
(your headahes (MASC-PLUR) derease-MASC-PLUR the afternoon)
SMT Frenh vos maux de t?ete diminue-t-elle l'apres-midi
(your headahes (MASC-PLUR) derease-FEM-SING the afternoon)
English have you had them for twenty days
RBMT Frenh avez-vous vos maux de t?ete depuis vingt jours
(have-you your headahes sine twenty days)
SMT Frenh avez-vous eu vos maux de t?ete pendant vingt jours
(have-you had your headahes during twenty days)
Table 5: Examples of inorret SMT translations from English into Frenh. Errors are highlighted in
bold.
the SMT ould have an advantage; robustness is
generally a strength of statistial approahes. We
return to English ! Frenh in Table 7, whih
presents the result of running the best SMT model
on the 357 examples from the test set in (Rayner
et al, 2005) whih failed to be translated by the
RBMT. We divide the set into ategories based on
the reason for failure of the RBMT.
In the most populous group, translations that
failed due to out of voabulary items, the SMT
was, more or less by onstrution, also unable
to produe a translation. For the 110 items that
were out of grammar overage for the RBMT, the
SMT produed 38 good translations, and another 4
borderline translations. There were 50 items that
were within the soure grammar overage of the
RBMT, but failed somewhere in transfer and gen-
eration proessing. Of those, the majority (32)
represented ?bad? soure sentenes, onsidered as
ill-formed for the purposes of this experiment. Out
of the remaining items that were within RBMT
grammar overage, the SMT managed to produe
5 good translations and 1 borderline translation. In
total, on the most lenient interpretation, the SMT
produed 48 additional translations out of 357.
While this improvement in reall is arguably worth
having, it would ome at the prie of a substantial
deline in preision.
5 Disussion and Conlusions
We have presented a novel methodology for om-
paring RBMT and SMT, and tested it on a spe-
Result Count
Out of voabulary
Bad translation 187
Out of soure grammar overage
Good translation 38
Bad translation 44
Borderline translation 4
Bad soure sentene 34
In soure grammar overage
Good translation 5
Bad translation 12
Borderline translation 1
Bad soure sentene 32
Total 357
Table 7: English ! Frenh SMT performane on
examples from the test set whih failed to be trans-
lated by the RBMT, evaluated by one judge.
i pair of RBMT and SMT arhitetures. Our
laim is that these results show that the version
of SMT used here is not in fat apable of repro-
duing the output of the RBMT system. Although
there has been some interest in attempting to train
SMT systems from RBMT output, the evaluation
issues that arise when omparing SMT and RBMT
versions of a high-preision limited-domain sys-
tem are different from those arising in most MT
tasks, and neessitate a orrespondingly different
methodology. It is easy to gain the impression that
it is unsound, and that the experiment has been set
60
up in suh a way that only one result is possible.
This is not, in fat, true.
When we have disussed the methodology with
people who work primarily with SMT, we have
heard two main objetions. The rst is that the
SMT is being trained on RBMT output, and hene
an only be worse; a ommon suggestion is that
a system trained on human-produed translations
ould yield better results. It is not at all implau-
sible that an SMT trained on this kind of data
might perform better on material whih is outside
the overage of the RBMT system. In this do-
main, however, the important issue is preision,
not reall; what is ritial is the ability to trans-
late aurately on material that is within the on-
strained language dened by the RBMT overage.
The RBMT engine gives very good performane
on in-overage data, as has been shown in other
evaluations of the MedSLT system, e.g. (Rayner et
al., 2005); over 97% of all in-overage sentenes
are orretly translated. Human-generated transla-
tions would often, no doubt, be more natural than
those produed by the RBMT, and there would be
slightly fewer outright mistranslations. But the
primary reason why the SMT is doing badly is
not that the training material ontains bad trans-
lations, but rather that the SMT is inapable of
orretly reproduing the translations it sees in the
training data. Even in the easy English ! Frenh
language-pair, the SMT often produes a different
translation from the RBMT. It ould a priori have
been oneivable that the differenes were unin-
teresting, in the sense that SMT outputs different
from RBMT outputs were as good, or even better.
In fat, Table 4 show that this is not true; when the
two translations differ, although the SMT transla-
tion an oasionally be better, it is usually worse.
Table 6 shows that this problem is onsiderably
more aute in English ! Japanese. Thus the
SMT system's inability to model the RBMT sys-
tem points to a real limitation.
If the SMT had instead been trained on human-
generated data, its performane on in-overage
material ould only have improved substantially if
the SMT for some reason found it easier to learn to
reprodue patterns in human-generated data than
in RBMT-generated data. This seems unlikely.
The SMT is being trained from a set of translation
pairs whih are guaranteed to be ompletely on-
sistent, sine they have been automatially gener-
ated by the RBMT; the fat that the RBMT system
only has a small voabulary should also work in
its favour. If the SMT is unable to reprodue the
RBMT's output, it is reasonable to assume it will
have even greater difulty reproduing transla-
tions present in normal human-generated training
data, whih is always far from onsistent, and will
have a larger voabulary.
The seond objetion we have heard is that the
non-standard BLEU sores whih we have used to
measure performane use the RBMT translations
as a referene. People are quik to point out that,
if real human translations were sored in this way,
they would do less well on the non-standard met-
ris than the RBMT translations. This is, indeed,
absolutely true, and explains why it was essential
to arry out the omparison judging shown in Ta-
bles 4 and 6. If we had ompared human transla-
tions with RBMT translations in the same way, we
would have found that human translations whih
differed from RBMT translations were sometimes
better, and hardly ever worse. This would have
shown that the non-standard metris were inap-
propriate for the task of evaluating human trans-
lations. In the atual ase onsidered in this paper,
we nd a ompletely different pattern: the differ-
enes are one-sided in the opposite diretion, in-
diating that the non-standard metris do in fat
agree with human judgements here.
A general objetion to all these experiments is
that there may be more powerful SMT arhite-
tures. We used the Giza++/Moses/SRILM om-
binination beause it is the de fato standard. We
have posted the data we used at http://www.
bahr.net/geaf2009; this will allow other
groups to experiment with alternate arhitetures,
and determine whether they do in fat yield sig-
niant improvements. For the moment, however,
we think it is reasonable to laim that, in domains
where high auray is required, it remains to be
shown that SMT approahes are apable of ahiev-
ing the levels of performane that rule-based sys-
tems an deliver.
61
Referenes
D. Arnold, L. Balkan, S. Meijer, R.L. Humphreys, and
L. Sadler. 1994. Mahine Translation: An Introdu-
tory Guide. Blakwell, Oxford.
P. Bouillon, M. Rayner, N. Chatzihrisas, B.A.
Hokey, M. Santaholma, M. Starlander, Y. Nakao,
K. Kanzaki, and H. Isahara. 2005. A generi multi-
lingual open soure platform for limited-domain
medial speeh translation. In Proeedings of the
10th Conferene of the European Assoiation for
Mahine Translation (EAMT), pages 50?58, Bu-
dapest, Hungary.
P. Bouillon, F. Ehsani, R. Frederking, and M. Rayner,
editors. 2006. Proeedings of the HLT-NAACL In-
ternational Workshop on Medial Speeh Transla-
tion, New York.
P. Bouillon, F. Ehsani, R. Frederking, M. MTear,
and M. Rayner, editors. 2008a. Proeedings of
the COLING Workshop on Speeh Proessing for
Safety Critial Translation and Pervasive Applia-
tions, Manhester.
P. Bouillon, G. Flores, M. Georgesul, S. Halimi,
B.A. Hokey, H. Isahara, K. Kanzaki, Y. Nakao,
M. Rayner, M. Santaholma, M. Starlander, and
N. Tsourakis. 2008b. Many-to-many multilingual
medial speeh translation on a PDA. In Proeed-
ings of The Eighth Conferene of the Assoiation
for Mahine Translation in the Amerias, Waikiki,
Hawaii.
N. Chatzihrisas, P. Bouillon, M. Rayner, M. San-
taholma, M. Starlander, and B.A. Hokey. 2006.
Evaluating task performane for a unidiretional
ontrolled language medial speeh translation sys-
tem. In Proeedings of the HLT-NAACL Interna-
tional Workshop on Medial Speeh Translation,
pages 9?16, New York.
L. Dugast, J. Senellart, and P. Koehn. 2008. Can we
relearn an RBMT system? In Proeedings of the
Third Workshop on Statistial Mahine Translation,
pages 175?178, Columbus, Ohio.
B.A. Hokey, M. Rayner, and G. Christian. 2008.
Training statistial language models from grammar-
generated data: A omparative ase-study. In Pro-
eedings of the 6th International Conferene on Nat-
ural Language Proessing, Gothenburg, Sweden.
R. Jonson. 2005. Generating statistial language mod-
els from interpretation grammars in dialogue sys-
tems. In Proeedings of the 11th EACL, Trento,
Italy.
A. Jurafsky, C. Wooters, J. Segal, A. Stolke, E. Fos-
ler, G. Tajhman, and N. Morgan. 1995. Us-
ing a stohasti ontext-free grammar as a language
model for speeh reognition. In Proeedings of
the IEEE International Conferene on Aoustis,
Speeh and Signal Proessing, pages 189?192.
P. Koehn, H. Hoang, A. Birh, C. Callison-Burh,
M. Federio, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al 2007. Moses: Open soure
toolkit for statistial mahine translation. In AN-
NUAL MEETING-ASSOCIATION FOR COMPU-
TATIONAL LINGUISTICS, volume 45, page 2.
F.J. Oh and H. Ney. 2000. Improved statistial align-
ment models. In Proeedings of the 38th Annual
Meeting of the Assoiation for Computational Lin-
guistis, Hong Kong.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2001.
BLEU: a method for automati evaluation of ma-
hine translation. Researh Report, Computer Si-
ene RC22176 (W0109-022), IBM Researh Divi-
sion, T.J.Watson Researh Center.
M. Rayner, P. Bouillon, N. Chatzihrisas, B.A.
Hokey, M. Santaholma, M. Starlander, H. Isahara,
K. Kanzaki, and Y. Nakao. 2005. A methodol-
ogy for omparing grammar-based and robust ap-
proahes to speeh understanding. In Proeedings
of the 9th International Conferene on Spoken Lan-
guage Proessing (ICSLP), pages 1103?1107, Lis-
boa, Portugal.
M. Rayner, B.A. Hokey, and P. Bouillon. 2006.
Putting Linguistis into Speeh Reognition: The
Regulus Grammar Compiler. CSLI Press, Chiago.
M. Rayner, P. Bouillon, G. Flores, F. Ehsani, M. Star-
lander, B. A. Hokey, J. Brotanek, and L. Biewald.
2008. A small-voabulary shared task for medial
speeh translation. In Proeedings of the COLING
Workshop on Speeh Proessing for Safety Criti-
al Translation and Pervasive Appliations, Manh-
ester.
S. Seneff, C. Wang, and J. Lee. 2006. Combining lin-
guisti and statistial methods for bi-diretional En-
glish Chinese translation in the ight domain. In
Proeedings of AMTA 2006.
A. Stolke. 2002. SRILM - an extensible language
modeling toolkit. In Seventh International Confer-
ene on Spoken Language Proessing. ISCA.
Y. Wilks. 2007. Stone soup and the Frenh room. In
K. Ahmad, C. Brewster, and M. Stevenson, editors,
Words and Intelligene I: Seleted Papers by Yorik
Wilks, pages 255?265.
62
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 32?35
Manchester, August 2008
The 2008 MedSLT System
Manny Rayner1, Pierrette Bouillon1, Jane Brotanek2, Glenn Flores2
Sonia Halimi1, Beth Ann Hockey3, Hitoshi Isahara4, Kyoko Kanzaki4
Elisabeth Kron5, Yukie Nakao6, Marianne Santaholma1
Marianne Starlander1, Nikos Tsourakis1
1 University of Geneva, TIM/ISSCO, 40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
{Emmanuel.Rayner,Pierrette.Bouillon,Nikolaos.Tsourakis}@issco.unige.ch
{Sonia.Halimi,Marianne.Santaholma,Marianne.Starlander}@eti.unige.ch
2 UT Southwestern Medical Center, Children?s Medical Center of Dallas
{Glenn.Flores,Jane.Brotanek}@utsouthwestern.edu
3 Mail Stop 19-26, UCSC UARC, NASA Ames Research Center, Moffett Field, CA 94035?1000
bahockey@ucsc.edu
4 NICT, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
{isahara,kanzaki}@nict.go.jp
5 3 St Margarets Road, Cambridge CB3 0LT, England
elisabethkron@yahoo.co.uk
6 University of Nantes, LINA, 2, rue de la Houssinie`re, BP 92208 44322 Nantes Cedex 03
yukie.nakao@univ-nantes.fr
Abstract
MedSLT is a grammar-based medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several dif-
ferent subdomains and multiple language
pairs. Vocabulary ranges from about 350 to
1000 surface words, depending on the lan-
guage and subdomain. We will demo three
different versions of the system: an any-
to-any multilingual version involving the
languages Japanese, English, French and
Arabic, a bidirectional English ? Span-
ish version, and a mobile version run-
ning on a hand-held PDA. We will also
demo the Regulus development environ-
ment, focussing on features which sup-
port rapid prototyping of grammar-based
speech translation systems.
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1 Introduction
MedSLT is a medium-vocabulary grammar-based
medical speech translation system built on top of
the Regulus platform (Rayner et al, 2006). It is
intended for use in doctor-patient diagnosis dia-
logues, and provides coverage of several subdo-
mains and a large number of different language-
pairs. Coverage is based on standard examina-
tion questions obtained from physicians, and fo-
cusses primarily on yes/no questions, though there
is also support for WH-questions and elliptical ut-
terances.
Detailed descriptions of MedSLT can be found
in earlier papers (Bouillon et al, 2005; Bouil-
lon et al, 2008)1. In the rest of this note, we
will briefly sketch several versions of the system
that we intend to demo at the workshop, each of
which displays new features developed over the
last year. Section 2 describes an any-language-to-
any-language multilingual version of the system;
Section 3, a bidirectional English ? Spanish ver-
sion; Section 4, a version running on a mobile PDA
1All MedSLT publications are available on-line
at http://www.issco.unige.ch/projects/
medslt/publications.shtml.
32
platform; and Section 5, the Regulus development
environment.
2 A multilingual version
During the last few months, we have reorganised
the MedSLT translation model in several ways2. In
particular, we give a much more central role to the
interlingua; we now treat this as a language in its
own right, defined by a normal Regulus grammar,
and using a syntax which essentially amounts to
a greatly simplified form of English. Making the
interlingua into another language has made it easy
to enforce tight constraints on well-formedness of
interlingual semantic expressions, since checking
well-formedness now just amounts to performing
generation using the interlingua grammar.
Another major advantage of the scheme is that
it is also possible to systematise multilingual de-
velopment, and only work with translation from
source language to interlingua, and from interlin-
gua to target language; here, the important point
is that the human-readable interlingua surface syn-
tax makes it feasible in practice to evaluate transla-
tion between normal languages and the interlingua.
Development of rules for translation to interlingua
is based on appropriate corpora for each source
language. Development of rules for translating
from interlingua uses a corpus which is formed by
merging together the results of translating each of
the individual source-language corpora into inter-
lingua.
We will demonstrate our new capabilities in
interlingua-based translation, using a version of
the system which translates doctor questions in the
headache domain from any language to any lan-
guage in the set {English, French, Japanese, Ara-
bic}. Table 1 gives examples of the coverage of the
English-input headache-domain version, and Ta-
ble 2 summarises recognition performance in this
domain for the three input languages where we
have so far performed serious evaluations. Differ-
ences in the sizes of the recognition vocabularies
are primarily due to differences in use of inflec-
tion.
3 A bidirectional version
The system from the preceding section is unidi-
rectional; all communication is in the doctor-to-
patient direction, the expectation being that the pa-
2The ideas in the section are described at greater length in
(Bouillon et al, 2008).
Language Vocab WER SemER
English 447 6% 11%
French 1025 8% 10%
Japanese 422 3% 4%
Table 2: Recognition performance for English,
French and Japanese headache-domain recognis-
ers. ?Vocab? = number of surface words in source
language recogniser vocabulary; ?WER? = Word
Error Rate for source language recogniser, on in-
coverage material; ?SemER? = semantic error rate
for source language recogniser, on in-coverage
material.
tient will respond non-verbally. Our second demo,
an early version of which is described in (Bouillon
et al, 2007), supports bidirectional translation for
the sore throat domain, in the English ? Spanish
pair. Here, the English-speaking doctor typically
asks WH-questions, and the Spanish-speaking pa-
tient responds with elliptical utterances, which are
translated as full sentence responses. A short ex-
ample dialogue is shown in Table 3.
Doctor: Where is the pain?
?Do?nde le duele?
Patient: En la garganta.
I experience the pain in my throat.
Doctor: How long have you had a pain
in your throat?
?Desde cua?ndo le duele la garganta?
Patient: Ma?s de tres d??as.
I have experienced the pain in my
throat for more than three days.
Table 3: Short dialogue with bidirectional English
? Spanish version. System translations are in ital-
ics.
4 A mobile platform version
When we have shown MedSLT to medical profes-
sionals, one of the most common complaints has
been that a laptop is not an ideal platform for use
in emergency medical situations. Our third demo
shows an experimental version of the system us-
ing a client/server architecture. The client, which
contains the user interface, runs on a Nokia Linux
N800 Internet Tablet; most of the heavy process-
ing, including in particular speech recognition, is
hosted on the remote server, with the nodes com-
municating over a wireless network. A picture of
33
Where? Is the pain above your eye?
When? Have you had the pain for more than a month?
How long? Does the pain typically last a few minutes?
How often? Do you get headaches several times a week?
How? Is it a stabbing pain?
Associated symptoms? Do you vomit when you get the headaches?
Why? Does bright light make the pain worse?
What helps? Does sleep make the pain better?
Background? Do you have a history of sinus disease?
Table 1: Examples of English MedSLT coverage
the tablet, showing the user interface, is presented
in Figure 1. The sentences appearing under the
back-translation at the top are produced by an on-
line help component, and are intended to guide the
user into the grammar?s coverage (Chatzichrisafis
et al, 2006).
The architecture is described further in
(Tsourakis et al, 2008), which also gives perfor-
mance results for another Regulus applications.
These strongly suggest that recognition perfor-
mance in the client/server environment is no
worse than on a laptop, as long as a comparable
microphone is used.
5 The development environment
Our final demo highlights the new Regulus devel-
opment environment (Kron et al, 2007), which has
over the last few months acquired a large amount
of new functionality designed to facilitate rapid
prototyping of spoken language applications3 . The
developer initially constructs and debugs her com-
ponents (grammar, translation rules etc) in a text
view. As soon as they are consistent, she is able
to compile the source-language grammar into a
recogniser, and combine this with other compo-
nents to run a complete speech translation system
within the development environment. Connections
between components are defined by a simple con-
fig file. Figure 2 shows an example.
References
Bouillon, P., M. Rayner, N. Chatzichrisafis, B.A.
Hockey, M. Santaholma, M. Starlander, Y. Nakao,
K. Kanzaki, and H. Isahara. 2005. A generic multi-
lingual open source platform for limited-domain
medical speech translation. In Proceedings of the
10th Conference of the European Association for
3This work is presented in a paper currently under review.
Machine Translation (EAMT), pages 50?58, Bu-
dapest, Hungary.
Bouillon, P., G. Flores, M. Starlander,
N. Chatzichrisafis, M. Santaholma, N. Tsourakis,
M. Rayner, and B.A. Hockey. 2007. A bidirectional
grammar-based medical speech translator. In Pro-
ceedings of the ACL Workshop on Grammar-based
Approaches to Spoken Language Processing, pages
41?48, Prague, Czech Republic.
Bouillon, P., S. Halimi, Y. Nakao, K. Kanzaki, H. Isa-
hara, N. Tsourakis, M. Starlander, B.A. Hockey, and
M. Rayner. 2008. Developing non-european trans-
lation pairs in a medium-vocabulary medical speech
translation system. In Proceedings of LREC 2008,
Marrakesh, Morocco.
Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-
holma, M. Starlander, and B.A. Hockey. 2006. Eval-
uating task performance for a unidirectional con-
trolled language medical speech translation system.
In Proceedings of the HLT-NAACL International
Workshop on Medical Speech Translation, pages 9?
16, New York.
Kron, E., M. Rayner, P. Bouillon, and M. Santa-
holma. 2007. A development environment for build-
ing grammar-based speech-enabled applications. In
Proceedings of the ACL Workshop on Grammar-
based Approaches to Spoken Language Processing,
pages 49?52, Prague, Czech Republic.
Rayner, M., B.A. Hockey, and P. Bouillon. 2006.
Putting Linguistics into Speech Recognition: The
Regulus Grammar Compiler. CSLI Press, Chicago.
Tsourakis, N., M. Georghescul, P. Bouillon, and
M. Rayner. 2008. Building mobile spoken dialogue
applications using regulus. In Proceedings of LREC
2008, Marrakesh, Morocco.
34
Figure 1: Mobile version of the MedSLT system, running on a Nokia tablet.
Figure 2: Speech to speech translation from the development environment, using a Japanese to Arabic
translator built from MedSLT components. The user presses the Recognise button (top right), speaks in
Japanese, and receives a spoken translation in Arabic together with screen display of various processing
results. The application is defined by a config file which combines a Japanese recogniser and analy-
sis grammar, Japanese to Interlingua and Interlingua to Arabic translation rules, an Arabic generation
grammar, and recorded Arabic wavfiles used to construct a spoken result.
35
