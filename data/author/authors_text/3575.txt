Proceedings of the ACL 2007 Demo and Poster Sessions, pages 9?12,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multimedia Blog Creation System using Dialogue  
with Intelligent Robot 
Akitoshi Okumura, Takahiro Ikeda, Toshihiro Nishizawa, Shin-ichi Ando, 
and Fumihiro Adachi 
Common Platform Software Research Laboratries,  
NEC Corporation 
1753 Shimonumabe Nakahara-ku, Kawasaki-city, Kanagawa 211-8666 JAPAN 
{a-okumura@bx,nishizawa@bk,s-ando@cw,f-adachi@aj}.jp.nec.com 
 
Abstract 
A multimedia blog creation system is de-
scribed that uses Japanese dialogue with an 
intelligent robot. Although multimedia 
blogs are increasing in popularity, creating 
blogs is not easy for users who lack high-
level information literacy skills. Even 
skilled users have to waste time creating 
and assigning text descriptions to their 
blogs and searching related multimedia 
such as images, music, and illustrations. To 
enable effortless and enjoyable creation of 
multimedia blogs, we developed the system 
on a prototype robot called PaPeRo. Video 
messages are recorded and converted into 
text descriptions by PaPeRo using continu-
ous speech recognition. PaPeRo then 
searches for suitable multimedia contents 
on the internet and databases, and then, 
based on the search results, chooses appro-
priate sympathetic comments by using 
natural language text retrieval. The re-
trieved contents, PaPeRo's comments, and 
the video recording on the user's blog is 
automatically uploaded and edited. The 
system was evaluated by 10 users for creat-
ing travel blogs and proved to be helpful 
for both inexperienced and experienced us-
ers. The system enabled easy multimedia-
rich blog creation and even provided users 
the pleasure of chatting with PaPeRo. 
1 Introduction 
Blogs have become popular and are used in a vari-
ety of settings not only for personal use, but are 
also used in the internal communications of or-
ganizations. A multimedia blog, which contains 
videos, music, and illustrations, is increasing in 
popularity because it enables users to express their 
thoughts creatively. However, users are unsatisfied 
with the current multimedia blog creation methods. 
Users have three requirements. First, they need 
easier methods to create blogs. Most multimedia 
blogs are created in one of two ways: 1) A user 
creates audio-visual contents by cameras and or 
some other recording devices, and then assigns a 
text description to the contents as indexes. 2) A 
user creates a text blog, and then searches for mul-
timedia contents on the internet and databases to 
attach them to his blog. Both methods require 
high-level information literacy skills. Second, they 
would like to reduce their blog-creation time. Even 
skilled users have to waste time assigning text de-
scription and searching related multimedia con-
tents. Third, they like to be encouraged by other 
peoples? comments on their blogs. Although some 
users utilize pet-type agents making automatic 
comments to their blogs, the agents do not always 
satisfy them because the comments do not consider 
users' moods. To meet the three requirements, we 
developed a multimedia blog creation system using 
Japanese dialogue with an intelligent robot. The 
system was developed on a prototype robot called 
PaPeRo (Fujita, 2002), which has the same CPU 
and memory as a mobile PC. In this paper, we de-
scribe the multimedia blog creation method and 
the evaluation results in a practical setting. 
2 Multimedia Blog Creation 
2.1 Outline of system processes 
The system has four sequential processes: video 
message recording, continuous speech recognition, 
natural language text retrieval, and blog coordina-
9
tion. The first process is activated when a user be-
gins a conversation with PaPeRo. The process 
stores a video message recorded on PaPeRo's mi-
crophones and CCD cameras, and the second 
process converts the speech contents of the video 
message into a text description to extract important 
keywords. Then, the third process searches for 
suitable multimedia contents on pre-specified web 
sites and databases based on the text description. 
The first three processes can simplify multimedia 
blog creation and reduce creation costs. The last 
process detects a user?s mood, such as delight, an-
ger, sorrow, and pleasure, by extracting typical 
expressions from the text description, and then 
chooses appropriate sympathetic comments to en-
courage the user. Finally, the last process coordi-
nates uploading the recorded video message, the 
text description, the extracted keywords, the 
searched contents, and the sympathetic comments 
on the user's blog. 
2.2 Continuous Speech Recognition 
The system converts the speech content of the 
video message into text descriptions and extracts 
important keywords based on their lexical infor-
mation. The system should, therefore, be equipped 
with a large-vocabulary continuous speech recog-
nition engine capable of dealing with spontaneous 
speech. This is because blog messages usually con-
tain various kinds of words and expressions. As 
this kind of engine needs a large amount of mem-
ory and computational resources, it is generally 
difficult to install the engine on small intelligent 
robots because the robot requires its own computa-
tional resources for their own intelligent operations, 
such as image recognition and movement control. 
To solve this problem, we used a compact and 
scalable large-vocabulary continuous speech rec-
ognition framework, which has been shown to 
work on low-power devices, such as PDAs (Isotani 
et al,2005). The framework achieves compact and 
high-speed processing by the following techniques: 
 - Efficient reduction of Gaussian components us-
ing MDL criterion (Shinoda, et al, 2002) 
- High-speed likelihood calculation using tree-
structured probability density functions (Wata-
nabe, et al, 1995) 
- Compaction of search algorithm using lexical 
prefix tree and shared usage of calculated lan-
guage model scores (Isotani et al, 2005) 
The framework we developed contained a Japanese 
lexicon of 50,000 words typically used in travel 
conversations based on a speech translation system 
(Isotani, et al, 2002). We were able to evaluate the 
developed system by making a travel blog using 
Japanese dialogue with PaPeRo.  
2.3 Natural Language Text Retrieval 
The system generates a query sentence from a 
text description converted using the above-
mentioned framework. As few multimedia contents 
contain retrieval keywords, the system matches the 
query to text in web pages and documents contain-
ing multimedia contents. The system then chooses 
multimedia contents located adjacent to the highly-
matched text as retrieval results. To achieve high 
precision for avoiding user interaction with the 
retrieved results, the system is enhanced using the 
Okapi BM25 model (Robertson, et al, 1995) by 
the following techniques (Ikeda, et al, 2005): 
(1) Utilization of syntactic relationships 
The system needs to distinguish illustrations 
based on the context. For example, an illustration 
of fish to be eaten in a restaurant should be differ-
ent from that of fish to be seen in an aquarium. To 
achieve this, the system utilizes the syntactic rela-
tionships between a pair of words. The system 
produces a higher score for text containing the 
same syntactic relationship as that of a pair of 
words in a query sentence when calculating the 
matching score.  
(2) Distinction of negation and affirmation 
The system needs to distinguish negative and af-
firmative expressions because their meanings are 
clearly opposite. To achieve this, the system 
checks adjuncts attached to the expressions when 
matching a query sentence and text. 
(3) Identification of synonyms  
As different expressions have the same meaning, 
the system normalizes expressions by using a 
synonym dictionary containing 500 words before 
matching a query sentence and text. 
2.4 Blog Coordination 
The system detects users? mood to choose en-
couraging comments. Users? moods are sometimes 
detected by the expressions used and the manner in 
which the utterances are spoken. Although speak-
ing manner can clearly detect emotions, such as 
laughing or crying, some emotions are not always 
indicated. Expressions that clearly identify a per-
10
son?s mood can be indicated (Nakamura, 1993). 
By studying moods that are easily detectable from 
expressions, including modality, we developed a 
database of 10 moods (delight, anger, sorrow, 
pleasure, desire, fear, shame, relief, surprise, and 
normal) individually linked with 100 kinds of spe-
cific expressions. The database is searched based 
on the above-mentioned natural language text re-
trieval, which considers syntactic relationships, 
negative and affirmative responses, and synonyms. 
The database is also linked to PaPeRo?s response 
to convey the most appropriate sympathy for each 
mood. The response includes verbal comments, 
such as ?I'm happy for you? and ?It's really too 
bad?, and gestures, such as dancing and crying de-
picted using GIF animation files. Responses are 
chosen based on the mood detected. Finally, the 
system coordinates uploading a recorded video 
message, the text description, the extracted impor-
tant keywords, the searched multimedia contents, 
and PaPeRo?s responses on the user's blog. 
3 Example Use in Practical Setting 
We developed a prototype system for creating a 
travel blog on PaPeRo, which can retrieve 2000 
web pages containing 1500 illustrations and 550 
songs. PaPeRo is activated by hearing the phrase, 
?can you help me make my blog please??, as listed 
in Table. 1, and creates a blog, as shown in Figure 
1. Figure 1 shows a screen shot of a video message 
attached to the blog, a text description converted 
by the speech recognition and a button for playing 
the video message (A). Keywords, in this case Yo-
semite, Las Vegas, and Roulette, extracted from 
the text description are displayed (B). Three illus-
trations searched based on a query using the text 
description are displayed (C). A button for playing 
a searched song is available (D). PaPeRo?s com-
ments, such as ?I hope that happens?, are displayed 
(E). The user?s mood is detected as desire from her 
saying ?I would like to go there again.? The com-
ment is displayed together with the appropriate 
PaPeRo?s response.  
Table 1. Dialogue example (Excerpt) 
A user  : Can you help me make my blog please? 
PaPeRo: Yes, please push the button on my head. 
A user  : I went to Yosemite for my winter vacation. 
 I played the roulette for the first time in Las 
Vegas. I would like to go there again. 
PaPeRo: Ok, now your blog is ready for viewing. 
B
C
E
A
D
?????
????
 
Figure 1. Example of Created Blog  
4 Evaluation and Discussion 
4.1  Evaluation 
The system needs to be evaluated from two per-
spectives. The first is to individually evaluate the 
performance of each process mentioned in section 
2. The second is to evaluate total performance, in-
cluding the users? subjective opinions. As per-
formance has been evaluated using different appli-
cation systems, such as an automatic speech trans-
lation system (Isotani, et al, 2002) and a speech-
activated text retrieval system (Ikeda, et al, 2005), 
we concentrated on evaluating the total perform-
ance based on surveying users? opinions about the 
blogs they created using the developed system. The 
survey results were analyzed in terms of speech 
recognition accuracy and users? blog making ex-
perience to improve the system.  
4.2 Results and Discussion 
The system was evaluated by 10 users. Half had 
blog making experiences, and the other half had 
no experience at all. All users input 20 sentences, 
and half of the sentences input were on travel is-
sues, but the other half were unrelated because we 
needed opinions based on the results from low 
speech recognition accuracy. Users were inter-
viewed on their automatically created blogs. 
Their opinions are listed in Table 2. The first row 
contains opinions about blogs created based on 
speech recognition results that had high word ac-
curacy (85-95%). The second row contains opin-
ions that had low accuracy (50-84%). The third 
row shows opinions regardless of the accuracy. 
11
The left column contains opinions of users with 
blog-making experience. The middle column con-
tains opinions of inexperienced users. The right 
column shows opinions regardless of the experi-
ence. The table leads to the following discussion: 
(1) Expectations for multimedia blog creation 
Users were satisfied with the system when high 
speech recognition accuracy was used regardless 
of their blog-making experience. Some users ex-
pected that the system could promote spread of 
multimedia contents with index keywords, even 
though few multimedia contents currently have 
indexes for retrieval. 
(2) Robustness and tolerability for low accuracy 
Users understood the results when low speech 
recognition accuracy was used because the mul-
timedia content search is still fairly successful 
when keywords are accurately recognized, even 
though the total accuracy is not high. Users can 
appreciate the funny side of speech recognition 
errors and unexpected multimedia contents from 
PaPeRo?s mistakes. However, as the errors do not 
always lead to amusing results, an edit interface 
should be equipped to improve keywords, illus-
trations and the total blog page layout. 
(3) More expectations of dialogue with PaPeRo 
Users would like to more enjoy themselves with 
PaPeRo, regardless of the speech recognition ac-
curacy. They expect PaPeRo to give them more 
information, such as track-back and comments, 
based on dialogue history. As PaPeRo stores all 
the messages in himself, he has the ability to gen-
erate more sophisticated comments and track-
back messages with users. Also, when the dia-
logue scenario is improved, he can ask the users 
some encouraging questions to make their blog 
more interesting and attractive while recording 
their video messages. 
5 Conclusion  
We developed a multimedia blog creation system 
using Japanese dialogue with an intelligent robot. 
The system was developed on PaPeRo for creating 
travel blogs and was evaluated by 10 users. Results 
showed that the system was effective for inexperi-
enced and experienced users. The system enabled 
easy and simple creation of multimedia-rich blogs, 
while enabling users the pleasure of chatting with 
PaPeRo. We plan to improve the system by sup-
porting the edit interface and enhancing the dia-
logue scenario so that users can enjoy themselves 
with more sophisticated and complex interaction 
with PaPeRo.  
Table 2. Survey of Users? Opinions 
References 
Yoshihiro Fujita. 2002. Personal Robot PaPeRo. Jour-
nal of Robotics and Mechatronics, 14(1): 60?63. 
Takahiro Ikeda, at al. 2005. Speech-Activated Text Re-
trieval System for Cellular Phones with Web Brows-
ing Capability. In Proceedings of PACLIC19, 265?
272. 
Ryosuke Isotani, et al 2002. An Automatic Speech 
Translation System on PDAs for Travel Conversation. 
In Proceedings of ICMI2002, 211?216. 
Ryosuke Isotani, et al 2005. Basic Technologies for 
Spontaneous Speech Recognition and Its Applica-
tions. In IPSJ-SIGNL, 2005-NL-169, 209?116 (in 
Japanese). 
Akira Nakamura (ed.). 1993. Kanjo hyogen jiten (Emo-
tional Expressions Dictionary). Tokyodo Shuppan, 
Tokyo (in Japanese). 
Stephen E. Robertson, et al 1995. Okapi at TREC-3. In 
Proceedings of TREC-3, 109?126. 
Koichi Shinoda and et al 2002. Efficient Reduction of 
Gaussian Components Using MDL Criterion for 
HMM-based Speech Recognition, In Proceedings of 
ICASSP-2002, 869?872. 
Takao Watanabe, et al 1995. High Speed Speech Rec-
ognition Using Tree-Structured Probability Density 
Function. In Proceedings of ICASSP-1995, 556?559. 
Blog-making experience  
Experienced Inexperienced Either 
Hi
gh
 
-This system 
makes multi-
media con-
tents more 
searchable on 
the internet. 
-I would like to 
create blogs with 
PaPeRo. 
-Easy to create 
blog only by 
chatting. 
-PaPeRo?s 
comments are 
nice. 
Lo
w 
-Keywords, 
searched con-
tents, and the 
total lay-out of 
blogs should 
be edited. 
-Searched con-
tents are good. 
-Even unexpect-
edly searched 
contents because 
of recognition 
errors are funny. 
-PaPeRo could 
be allowed for 
his mistake. 
- Unexpected 
texts tempt users 
to play the 
video.  
Sp
ee
ch
 re
co
gn
itio
n a
cc
ura
cy
 
Ei
the
r 
-PaPeRo?s 
track-back is 
wanted as well 
as more dia-
logue varia-
tion. 
-PaPeRo should 
talk on reasons 
of his choosing a 
song. 
-PaPeRo should 
consider a his-
tory of recorded 
messages and his 
comments. 
12
 Topic Detection Based on Dialogue History 
 
Takayuki NAKATA, Takahiro IKEDA, Shinichi ANDO, Akitoshi OKUMURA 
Multimedia Research Laboratories, NEC Corporation 
4-1-1, Miyazaki, Miyamae-ku, Kawasaki, KANAGAWA, 216-8555, JAPAN 
t-nakata@bk.jp.nec.com, t-ikeda@di.jp.nec.co.jp, s-ando@cw.jp.nec.com, a-okumura@bx.jp.nec.com
 
 
 
Abstract 
In this paper, we propose a topic detection 
method using a dialogue history for 
selecting a scene in the automatic 
interpretation system (Ikeda et al, 2002).  
The method uses a k-nearest neighbor 
method for the algorithm, automatically 
clusters target topics into smaller topics 
grouped by similarity, and incorporates 
dialogue history weighted in terms of time 
to detect and track topics on spoken 
phrases.  From the evaluation of 
detection performance using test corpus 
comprised of realistic spoken dialogue, 
the method has shown to perform better 
with clustering incorporated, and 
combined with time-weighted dialogue 
history of three sentences, gives detection 
accuracy of 77.0%. 
1 Introduction 
In recent years, speech-to-speech translation 
systems have been developed that integrate three 
components: speech recognition, machine 
translation, and speech synthesis (Watanabe et 
al., 2000).  However, these systems cannot 
guarantee accurate translation because the 
individual components do not always provide 
correct results.  To overcome this restriction, 
we proposed a method to use parallel text based 
translation for supporting free-style sentence 
translation.  In addition, we built a prototype 
automatic interpretation system for Japanese 
overseas travelers (Ikeda et al, 2002).  With 
this system, the user searches for an appropriate 
sentence in source language from the registered 
parallel text by using the criteria of an utterance, 
a scene, and a situation, and then uses the target 
language sentence for a translation. 
Although parallel text based translation 
provides guaranteed translation results, it has 
two problems as the user searches for the 
sentence.  One is difficulty in searching an 
appropriate sentence from user?s short utterance, 
which is often heard in travel conversation.  
Short phrases provide only a few keywords and 
make the search result too broad.  Specifying 
the exact scene and action helps narrow down 
the result, but the task may cause user frustration 
in having to select the right option from the vast 
categories of scenes and actions. 
The other problem is existence of nonadaptive 
sentences that may be inappropriate in some of 
the scenes.  Users usually select sentences 
according to the scenes so they can exclude 
those inapplicable sentences, but some new 
users may accidentally select those nonadaptive 
sentences by failing to specify a scene. 
 Here, we propose a method to detect a topic 
for each utterance.  We define a topic as 
corresponding to a scene that is a place or a 
situation in which the user converses.  The 
proposed method is based on the k-nearest 
neighbor method, which is improved for 
dialogue utterances by clustering training data 
and using dialogue history.  We use the 
detected topic for specifying a scene condition in 
parallel text based translation, and thereby solve 
the two problems described above. 
Detecting topics also helps improve accuracy 
of the automatic interpretation system by 
disambiguating polysemy.  Some words should 
be translated into different words according to 
the scene and context selection.  Topic 
detection can enhance speech recognition 
accuracy by selecting the correct word 
                                            Association for Computational Linguistics.
                            Algorithms and Systems, Philadelphia, July 2002, pp. 9-14.
                          Proceedings of the Workshop on Speech-to-Speech Translation:
 dictionary and resources, which are organized 
according to the topic. 
The remainder of this paper is organized as 
follows.  Section 2 describes the constraints in 
detecting a topic from dialogue utterances.  
Section 3 describes our topic detection algorithm 
to overcome these constraints.  Section 4 
explains the evaluation of our method by using a 
travel conversation corpus and Section 5 
presents the evaluation result.  Section 6 
discusses the effect of our method from a 
comparison of the results on typical dialogue 
data and on real situation dialogue data.  We 
conclude in Section 7 with some final remarks 
and mention of future work. 
2 Topic detection 
Among conventional topic detection methods, 
one uses compound words that features certain 
topic as trigger information for detecting a topic 
(Hatori et al, 2000), and another uses 
domain-dependant dictionaries and thesauruses 
to construct knowledge applicable to a certain 
topic (Tsunoda et al, 1996).  In the former 
method, a scene-dependant dictionary provides 
the knowledge relevant to the scene and 
compound words in the dictionary are used for 
detecting a topic.  In the latter method, words 
appearing in a scene are defined as the 
knowledge relevant to the scene and 
superordinate/subordinate relation and 
synonyms provided by thesauruses are used to 
enhance the robustness. 
These conventional methods are suitable for 
written texts but not for dialogue utterances in a 
speech translation system.  The following two 
major constraints make the topic detection for 
dialogue utterances more difficult. 
 
(1) Constraint due to single sentence process 
- Sentences in a dialogue are usually 
short with few keywords. 
- In a dialogue, the frequency values of 
the word in a sentence are mostly one, 
making it difficult to apply a statistical 
method. 
 
(2) Constraint due to the nature of spoken 
dialogue 
- In a dialogue, one topic is sometimes 
expressed with two or more sentences. 
- The words appearing in a sentence are 
sometimes replaced by anaphora or 
omitted by ellipsis in the next sentence. 
- Topics frequently change in a dialogue. 
 
On the other hand, a speech translation system 
requires the following: 
- Topic detection for each utterance in a 
dialogue; 
- Prompt topic detection in real time 
processing; 
- Dynamic tracking of topic transition. 
 
To make topic detection adaptive to the 
speech translation system, we propose a method 
applicable to one utterance in a dialogue as an 
input, which can be used for tracking the topic 
transitions dynamically and outputting most 
appropriate topic for the latest utterance.  The 
k-nearest neighbor method (Yang, 1994) is used 
with the clustering method linked with the 
dialogue history as a topic detection algorithm 
for dialogue utterance.  The k-nearest neighbor 
method is known to have high precision 
performance with less restriction in the field of 
document categorization.  This method is 
frequently used as a baseline in the field and also 
applied to topic detection for story but not for a 
single sentence (Yang et al, 1999).  This paper 
incorporates two new methods to the k-nearest 
neighbor method to overcome two constraints 
mentioned above. 
To overcome the first constraint, we cluster a 
set of sentences in training data into subsets 
(called subtopics) based on similarity between 
the sentences.  A topic is detected by 
calculating the relevance between the input 
sentence and these subtopics.  Clustering 
sentences on the same subtopic increases 
number of characteristic words to be compared 
with input sentence in calculation. 
To overcome the second constraint, we group 
an input sentence with other sentences in the 
dialogue history.  A topic is detected by 
calculating the relevance between this group and 
each possible topic.  Grouping the input 
sentence with the preceding sentences increases 
number of characteristic words to be compared 
with topics in calculation.  We consider the 
 order of the sentences in the dialogue in 
calculating the relevance to avoid the influence 
of topic change in the dialogue. 
3 Topic detection algorithm 
This section explains three methods used in 
the proposed topic detection algorithm: 1) 
k-nearest neighbor method, 2) the clustering 
method using TF-IDF, and 3) the application of 
the dialogue history. 
3.1 k-nearest neighbor method 
We denote the character vector for a given 
sentence in the training data as Dj, and that for a 
given input sentence as X.  Each vector has a 
TF-IDF value of the word in the sentence as its 
element value (Salton 1989). 
The similarity between the input sentence X 
and the training data Dj is calculated by taking 
the inner product of the character vectors. 
 
 
 
The conditional probability of topic Cl being 
related to the training data Dj is calculated as: 
 
?
?
j
l
jl D
C
DCPr
  the torelated being 
  topicsofnumber  The
1)|( =  
 
The relevance score between the input sentence 
X and each topic Cl is calculated as the sum of 
similarity for k sentences taken from the training 
data in descending order of similarity. 
 
?
?
?=
}sentence  ranking  k  top{
)|(),()|(
jD
jljl DCPrDXSimXCRel  
3.2 Topics clustering method 
This method clusters topics into smaller 
subtopics.  The word ?topic? used in this 
method consists of several subtopics 
representing detailed situations.  The topic 
?Hotel? consists of subtopics such as ?Checking 
In? and ?Room Service?.  Sentences in training 
data categorized under the same topic are further 
grouped into subtopics based on their similarity.  
Calculating the relevance between the test data 
input and these subsets of training data provides 
more keywords in detecting topics.  Our 
method to create the subtopics identifies a 
keyword in a sentence set, and then recursively 
divides the set into two smaller subsets, one that 
includes the keyword and one that does not. 
 
TF-IDF Clustering Method 
(1) Find the word that has the highest TF-IDF 
value among the words in the sentence 
set; 
(2) Divide the sentence set into two subsets; 
one that contains the word obtained in 
step (1) and one that does not; 
(3) Repeat steps (1) and (2) recursively until 
TF-IDF value reaches the threshold. 
 
Subtopics created by this method consist of 
keywords featuring each subtopic and their 
related words. 
3.3 Application of the dialogue history 
The proposed method applies the dialog 
history in topic detection.  The method 
interprets a current input sentence and the 
sentences prior to the current input as a dialogue 
history subset, and detects topics by calculating 
the relevance score between the dialogue history 
subset and the each topic.  The method 
increases number of keywords in the input for 
calculation.  We assign a weight to each 
sentence in the dialogue history subset to control 
the effect of time-sequence in sentences. 
The relevance score combined with the dialog 
history is calculated as: 
 
)Xr|C(lRer...)Xr|C(lRer
)X|C(lRe)Xr,...,Xr,X|C(lRe
nlnl
lnl
??
?
+++
=
11
1  
 
Here the similarity is calculated with the input 
sentence X and the sentence in the dialog history 
subset Xri, taking ? and ?ri as the weights for the 
input sentences and the sentences in the dialogue 
history, respectively. 
4 Evaluation 
To evaluate the proposed method, we 
prepared training data and test data from a travel 
conversation corpus.  We also prepared three 
22 || || || || 
) , ( 
j 
i ij i 
j D X
d x 
D X Sim 
? 
? 
= 
? 
 types of clusters with different thresholds and 
two types of dialogue history with different 
weight values. 
4.1 Training data 
In the evaluation, we used approximately 
25,000 sentences from our original travel 
conversation corpus as our training data.  The 
sentences are manually classified into four 
topics: 1) Hotel, 2) Restaurant, 3) Shopping, and 
4) Others.  The topic ?Others? consists of 
sentences not categorized into the remaining 
three. Topics such as ?Transportation? or 
?Illnesses and injuries? are placed into this 
?Others? in this evaluation. 
4.2 Test data 
We prepared two sets of test data.  One set 
consists of 62 typical travel dialogues 
comprising 896 sentences (hereafter called 
?typical dialogue data?).  The other set consists 
of 45 dialogues comprising 498 sentences, 
which may include irregular expressions but 
closely representing daily spoken language 
(hereafter called ?real situation dialogue data?). 
Sentences in ?typical dialogue data? are often 
heard in travel planning and travelling situations, 
and form a variety of initiating dialogues as the 
travel conversation unfolds.  The data includes 
words and phrases often used in the topics listed 
above, and each sentence is short with little 
redundancy.  On the other hand, ?real situation 
dialogue data? consists of spoken dialogue 
phrases which are likely to appear in 
user-specific situations in the travel domain.  
Some phrases may be typically used, while 
others may consist of colloquial expressions and 
words and phrases that are redundant.  Some of 
the words may not appear in the training data. 
4.3 Clustering the topics 
We applied the clustering with the 
aforementioned method to 8,457 sentences from 
training data which are categorized into one or 
more of the three topics: 1) Hotel, 2) Restaurant, 
and 3) Shopping.  Clusters are created on three 
different thresholds: 8,409 clusters (small-sized 
cluster), 3,845 clusters (medium-sized cluster) 
and 2,203 clusters (large-sized cluster).  In 
carrying out clustering, we set one sentence as 
one cluster if the sentence does not contain a 
word whose TF-IDF value is not equal to or 
greater than the threshold.  We excluded data 
that falls only under the topic ?Others? and data 
that falls under all four topics, which are 
considered to be general conversation.  
Variations of these topics produce 13 probable 
combinations. 
The number of clusters is smallest (13) when 
we set one topic as one cluster and largest 
(8,457) when we set one sentence as one cluster. 
4.4 Use of the dialogue history 
To evaluate the effect of the dialogue history, 
we use an input sentence, the most preceding 
and the next preceding sentence (hereafter 
?sentence 0?, ?sentence -1?, and ?sentence -2?) 
as a dialogue history.  Two types of sentence 
weights are applied to these three sentences, one 
of equal weights and one of weights based on a 
time series.  These sets are: 
 
0.33) 0.33, (0.33,  
2)- sentence 1,- sentence 0, (sentence
=
0.2) 0.3, (0.5, 
 2)- sentence 1,- sentence 0, (sentence
=
 
 
5 Results 
We performed the detection test described in 
4.3 on 13 types of topic combinations using 
typical dialogue data and real situation dialogue 
data. 
5.1 Test results on typical dialogue data 
Figure 1 shows the results of topic detection 
on typical dialogue data for a varying number of 
clusters.  The figure shows that the accuracy is 
highest when one sentence is set as one cluster 
(one sentence per cluster) in each topic, and 
lowest when one whole topic is set as one 
cluster. 
  
5.2 Test result on real situation dialogue 
data 
Figure 2 shows the results of topic detection 
on real situation dialogue data for a varying 
number of clusters.  The figure shows that the 
accuracy of the medium cluster is slightly better 
than that for one sentence per cluster.  This 
indicates that sentences grouped in terms of 
similarity heighten the accuracy of similarity 
calculation between input sentences and the 
training data. 
 
5.3 Results of dialogue history 
application 
We evaluated the effect of the dialogue 
history for typical dialogue test data, and 
compared the case of one sentence per cluster 
with the case of medium cluster.  Using only 
the input sentence, the topic detection accuracy 
was 59.2% for the former and 56.0% for the 
latter.  Using three sentences from the dialogue 
history, the respective figures were 72.0% and 
70.0% with equal weights, 76.7% and 77.0% 
with time series weights.  
 
6 Discussion 
Looking at the results on the typical dialogue 
data, it can be argued that the 
one-sentence-per-cluster case shows the highest 
accuracy because the data is a typical dialogue 
and each sentence is short, so that feature words 
in the input sentences and those of the learning 
data are likely to match.  On the other hand, it 
can be argued that the one-topic-per-cluster case 
shows the lowest accuracy because feature 
words become less effective when so many 
subtopics are in one cluster. 
For example, let us look at the sentence in the 
learning data, ?Is it all right to pick it up with 
my hand??  This sentence can be used when 
deciding what to buy, and so is categorized 
under the topic ?Shopping?.  When a cluster is 
one sentence, the result will likely be 
satisfactory if you input the sentence, ?Is it all 
right to pick it up with my hand?? because the 
input sentence is similar to the cluster.  
However, when a cluster is one topic, this 
sentence might be categorized under the topic 
?Others?, along with sentences used to express 
physical conditions such as ?My hand hurts? or 
?I am all right?.  Therefore, it can be concluded 
that it is better to divide a large topic into 
smaller groups or even into single sentences. 
Looking at the results on real situation 
dialogue data, we find the ratio of correct 
answers is almost the same for the 
one-sentence-per-cluster and the medium-cluster 
cases, but the actual sentences correctly detected 
topics differed significantly between them.  In 
the former case, topics are identified correctly 
when there are strong feature words, while in the 
latter case, it works well when there is no strong 
feature word but the topics can be determined by 
sets of words.  From this fact, we can conclude 
that typical input sentences can be compared 
easily with the one-sentence-per-cluster case, 
and real situation input sentences can be 
Figure 2: The result on real situation test data 
Figure 1: The result on typical test data 
0
10
20
30
40
50
60
one t
opic 
per c
luste
r
large
 clus
ter
medi
um c
luste
r
small
 clus
ter
one s
enten
ce pe
r clus
ter
number of cluster
ac
cu
ra
cy
 ra
te
42
44
46
48
50
52
54
56
58
one t
opic 
per c
luste
r
large
 clus
ter
medi
um c
luste
r
small
 clus
ter
one s
enten
ce pe
r clus
ter
number of cluster
ac
cu
ra
cy
 ra
te
 compared with the medium-cluster case even 
though the sentences are different from those in 
typical dialogue in terms of content and 
expressions.  We find that with typical dialogue 
data, the accuracy level is almost the same for 
the one-sentence-per-cluster and the 
medium-cluster cases, but with the real situation 
dialogue data, the accuracy level is slightly 
improved.  Therefore, it might be possible to 
improve the practicality of topic detection by 
collecting a large amount of data, dividing the 
data into typical and real situation dialogues, and 
setting the appropriate clusters to each type. 
7 Conclusions 
In this paper, we proposed a topic detection 
method using a dialogue history to select a scene 
for the automatic interpretation system.  We 
investigated its limitation in dialogue utterances 
and provided solutions by clustering training 
data and utilizing dialogue history.  Our 
method showed topic detection accuracy of at 
least 50% for both typical and real situation 
dialogues in 13 topic combinations.  For typical 
dialogues, we found that the best results were 
obtained when one sentence is used for one 
cluster, and for real situation dialogues, we 
found slightly better results were obtained when 
clustering was introduced.  Therefore, it can be 
argued that the topic detection accuracy is 
improved for both typical and real situation 
sentences if an appropriate size cluster is 
introduced. 
We plan to use our topic detection technique 
for specifying a scene condition of parallel text 
based translation in our automatic interpretation 
system.  Detecting topics also helps improve 
accuracy of the automatic interpretation system 
by disambiguating polysemy. Topic detection 
can enhance speech recognition accuracy by 
selecting the correct word dictionary and 
resources, which are organized according to the 
topic. 
Our method is also applicable in determining 
time series behavior such as topic transition.  
Our future studies will focus on linking the 
dialogue history and clustering more closely to 
improve the topic detection accuracy. 
References  
H. Hatori, Y. Kamiyama (2000) Web translation 
by feeding back information for judging 
category, Information Processing Society of 
Japan 63rd. Annual Meeting, Vol. 2, pp. 
253-254. 
 
T. Ikeda, S. Ando, K. Satoh, A. Okumura, T. 
Watanabe (2002) Automatic Interpretation 
System Integrating Free-style  Sentence 
Translation and Parallel Text Based Translation, 
ACL-02 Workshop on Speech-to-speech 
Translation (to appear). 
 
G. Salton (1989) The vector space model, 
automatic text processing ? the   
transformation, analysis, and retrieval of 
information by computer, Addison-Wesley 
Publishing Company Inc., pp.312-325. 
 
T. Tsunoda and H. Tanaka (1996) Evaluation of 
Scene Information as Context for English Noun 
Disambiguation, Natural Language Processing, 
Vol.3 No.1, pp. 3-27. 
 
T. Watanabe, A. Okumura, S. Sakai, K. 
Yamabana, S. Doi, K. Hanazawa (2000) An 
Automatic Interpretation System for Travel 
Conversation, The Proceeding of the 6th 
International Conference on Spoken Language 
Processing Vol. 4, pp. 444-447. 
 
Y. Yang (1994) Expert Network, Effective and 
Efficient Learning from Human Decisions in 
Text Categorization and Retrieval, Proceedings 
of the 17th Annual International ACM SIGIR 
Conference on Research and Development in 
Information Retrieval (SIGIR?94) 1994:11-21. 
 
Y. Yang, J.G. Carbonell, R. Brown, T. Pierce, B. 
T. Archibald, and X. Liu (1999) Learning 
approaches for detecting and tracking news 
events, IEEE Intelligent Systems, 14(4), pp. 
32-43. 
Automatic Interpretation System Integrating
Free-style Sentence Translation and Parallel Text Based Translation
Takahiro Ikeda Shinichi Ando Kenji Satoh Akitoshi Okumura Takao Watanabe
Multimedia Res. Labs. NEC Labs.
4-1-1 Miyazaki, Miyamae-ku, Kawasaki, Kanagawa 216
t-ikeda@di.jp.nec.com, s-ando@cw.jp.nec.com, k-satoh@da.jp.nec.com,
a-okumura@bx.jp.nec.com, t-watanabe@ay.jp.nec.com
Abstract
This paper proposes an automatic in-
terpretation system that integrates free-
style sentence translation and parallel text
based translation. Free-style sentence
translation accepts natural language sen-
tences and translates them by machine
translation. Parallel text based translation
provides a proper translation for a sen-
tence in the parallel text by referring to a
corresponding translation of the sentence
and supplements free-style sentence trans-
lation. We developed a prototype of an au-
tomatic interpretation system for Japanese
overseas travelers with parallel text based
translation using 9206 parallel bilingual
sentences prepared in task-oriented man-
ner. Evaluation results show that the par-
allel text based translation covers 72% of
typical utterances for overseas travel and
the user can easily find an appropriate sen-
tence from a natural utterance for 64% of
typical traveler?s tasks. This indicates that
the user can benefit from reliable transla-
tion based on parallel text for fundamental
utterances necessary for overseas travel.
1 Introduction
A speech-to-speech translation system must inte-
grate at least three components ? speech recogni-
tion, machine translation, and speech synthesis. In
practice, each component does not always output
the correct result for various inputs, and an error
in one component often leads to an incorrect result
being produced by the total system even for a lim-
ited domain. Clearly, we need ways to complement
speech-to-speech translation systems that cannot re-
liably produce a correct result.
Although some robust methods that make the er-
roneous results of other components acceptable have
been proposed (Yumi et al, 1997; Furuse et al,
1998), there is no guarantee that the final output
from a system will be appropriate even with these
methods. To deal with this problem, we have taken a
more practical approach to developing an automatic
interpretation system where the user can obtain a
correct result instead of having to apply additional
operations and judgment.
In actual use of a speech-to-speech translation
system, an error in the speech-recognition or speech-
synthesis components is not a large problem if the
system has a screen that displays each result. The
user of the system can correct errors in the recogni-
tion result on the screen, and can communicate by
showing the other person the translated sentence on
the screen.
On the other hand, an error in the machine-
translation component is critical because a user who
is not familiar with the target language is unlikely
to notice the error in some cases. When a nonsensi-
cal sentence is generated by machine translation, the
user may realize that the listener does not understand
the translated sentence. However, when a plausible
sentence that means something different from the in-
tended meaning is generated by the machine trans-
lation, the user may incorrectly assume that the ut-
terance was properly communicated. Consequently,
the user can seldom be sure that the listener cor-
rectly understood the intended meaning when using
a speech-to-speech translation system. A conversa-
                                            Association for Computational Linguistics.
                           Algorithms and Systems, Philadelphia, July 2002, pp. 85-92.
                          Proceedings of the Workshop on Speech-to-Speech Translation:
tion could continue for some time before it became
apparent that the two sides misunderstood what the
other was saying.
Moreover, if the user realizes that there is an er-
ror in the machine translation, correcting it will be
difficult. Without knowing the source of the error,
the user cannot modify the input to obtain a correct
result.
These error problems severely limit the usability
of speech-to-speech translation.
In this paper, we propose an automatic interpreta-
tion system that integrates free-style sentence trans-
lation and parallel text based translation. In this sys-
tem, free-style sentence translation accepts natural
language sentences and translates them by machine
translation without guaranteeing the quality of the
translation. On the other hand, parallel text based
translation uses parallel bilingual sentences regis-
tered in the system and translates a registered sen-
tence by referring to the corresponding translation.
Although this translation process limits the input to
registered sentences, it is a robust means of han-
dling input with recognition errors and consistently
provides a correct translation. We integrated these
two types of translation to realize a robust transla-
tion system where the two types of translation com-
pensate for the shortcomings of each other.
For appropriate integration of free-style sentence
translation and parallel text based translation, we
had to consider three main points.
1. User interface: how best to present the two
functions to the user?
2. Content of registered sentences: How many ut-
terances should be covered by registered sen-
tences?
3. Retrieval system: What methods of searching
among the registered sentences should be pro-
vided to the user?
In this paper, we discuss these three points with
respect to a translation system for Japanese travelers
in the overseas travel domain. We construct a model
of the integration of free-style sentence translation
and parallel text based translation in Section 2. We
describe a prototype system based on the model in
Section 3 and evaluate it in Section 4. Related work
on translation systems utilizing parallel text are dis-
cussed in Section 5, and we conclude in Section 6.
2 The Integration Model
2.1 User Interface
Although parallel text based translation provides a
correct result, the registered parallel bilingual sen-
tences cannot cover all possible utterances by the
user in the target domain. Free-style sentence trans-
lation, on the contrary, accepts free-style input sen-
tences but provides no guarantee as to the quality of
results.
For many routine situations, users will clearly
benefit from using parallel text based translation.
In such cases, the system will probably include a
sentence that totally or partially fits what they want
to say. To ensure high translation reliability, users
should use free-style sentence translation only for
utterances not covered by the registered sentences.
However, users usually will not know what sen-
tences are registered in the system and will have to
search for an appropriate sentence before they can
use parallel text based translation. In some cases, the
user will be forced to use free-style sentence trans-
lation if unable to find an appropriate sentence.
A seamless user interface that allows the user to
easily switch between free-style sentence transla-
tion and parallel text based translation is therefore
needed in a system integrating these two forms of
translation. Two conditions in particular had to be
met to make the system easy to use.
1. The user should be able to use an input sen-
tence seamlessly as both a source sentence for
free-style sentence translation and a key sen-
tence for registered sentence retrieval.
2. The user should be able to use each sentence in-
cluded in the results of the registered sentence
retrieval and the input sentence as a source
sentence for translation. (The former would
be used for parallel text based translation, and
the latter would be used for free-style sentence
translation.)
2.2 Content of Registered Sentences
Registered sentences must cover the utterances nec-
essary for accomplishing typical tasks in the target
domain to provide correct translation for minimal
communication. In a translation system for overseas
travelers, some typical tasks are changing money,
checking in at a hotel, and ordering at a restaurant.
We adopted a three-tier model that consists of
scenes, tasks, and subtasks to prepare a sufficient set
Table 1: Examples of scenes, tasks, subtasks, and templates of sentences
Scene Task Subtask Template of sentence
Hotel Check-in Checking in I?d like to check in, please.
Hotel Check-in Requesting a type of room I?d like a room with the ocean view.
Restaurant Order Requesting cooking time for your steak Medium, please.
Restaurant Order Asking what they recommend What do you recommend for appetizers?
of necessary sentences to be registered in the sys-
tem. A scene comprised a place or situation that
corresponds to where a traveler is likely to be (e.g., a
hotel) and a problem that could arise. We made a list
of typical travelers? tasks that would be necessary in
various travel scenes, divided each task into smaller
primitive tasks (subtasks), and assigned a sentence
template to each subtask based on the model.
In general, more than one round of conversation
is necessary to accomplish each task. We assumed
that a task would consist of smaller subtasks, each
of which would correspond to one round of conver-
sation that consisted simply of an utterance from a
traveler to a respondent and a response from the re-
spondent to the traveler. For example, the task of
checking in to a hotel consists of subtasks such as
giving your name, confirming your departure date,
and so on. Each subtask should be the smallest unit
of a task because users cannot use a registered sen-
tence effectively if it includes more than what they
want to say.
In this way, only one sentence template is needed
for each subtask with regard to an utterance from a
traveler to a respondent. For example, we can assign
a sentence template of ?I?d like to have ....? to the
subtask of ordering a dish in a restaurant. We can
provide a sufficient number of sentences by enabling
the user to fill in the part denoted as ?...? (referred to
as a slot) with words applicable to the situation.
Table 1 shows examples of scenes, tasks, sub-
tasks, and sentence templates. An underlined part
represents a slot. We define a list of words individu-
ally for each slot.
For each task, both the utterances from a traveler
to a respondent and the responses from a respon-
dent to a traveler are significant. Responses should
also be supported by parallel text based translation to
ensure reliable communication. However, inputting
the response and retrieving a registered sentence that
matches it will be difficult and time consuming for
the respondent who is unlikely to be familiar with
the translation system.
We use a system that presents a menu of responses
for the respondent to choose from. The system keeps
typical responses in parallel bilingual form for each
registered sentence that the traveler can use and dis-
plays these as candidate responses when the traveler
uses the sentence. The system then shows the trav-
eler the translation of the response selected by the
respondent.
This approach enables travelers to obtain a reli-
able response and also enables respondents to easily
select an appropriate response.
2.3 Retrieval System
The retrieval system to search for a registered sen-
tence that we use is based on a combination of three
conditions ? the natural language sentence, scene,
and action.
Registered sentence retrieval based on a natural
language sentence is essential for seamless integra-
tion of free-style sentence translation and parallel
text based translation. We used a simple keyword-
based retrieval system for registered sentence re-
trieval. This system extracts keywords from an in-
putted natural language sentence, searches for sen-
tences including the keywords, and presents the re-
sults ranked mainly by the number of keywords in-
cluded in each sentence.
The system retrieves all sentences including more
than one keyword to reduce the chance of an appro-
priate sentence not being retrieved. We overcame
the increased retrieval noise in the result by applying
an additional retrieval system to search for registered
sentences in terms of the scene and action.
Each registered sentence to be retrieved for trans-
lation corresponds to a set of a scene, a task, and
a subtask as described in the previous section. A
scene represents a place or a situation where the user
wishes to accomplish the task and the subtask. A
task and a subtask represent a user?s actions. This
means that the user?s utterance is related to the user?s
intention regarding where (scene) the user wants to
do something (action).
We use the additional retrieval system in situa-
tions where the user has to search for sentences from
	
		


	

	

	


	
	
	


		




		
	
	

		


	
	


	
