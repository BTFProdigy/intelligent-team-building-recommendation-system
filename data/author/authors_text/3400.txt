Best Analysis Selection in Inflectional Languages
Ales? Hora?k and Pavel Smrz?
Faculty of Informatics, Masaryk University Brno
Botanicka? 68a, 602 00 Brno, Czech Republic
E-mail: {hales,smrz}@fi.muni.cz
Abstract
Ambiguity is the fundamental property of
natural language. Perhaps, the most bur-
densome case of ambiguity manifests itself
on the syntactic level of analysis. In order
to face up to the high number of obtained
derivation trees, this paper describes several
techniques for evaluation of the figures of
merit, which define a sort order on parsing
trees. The presented methods are based on
language specific features of synthetical lan-
guages and they improve the results of sim-
ple stochastic approaches.
1 Introduction
Ambiguity on all levels of representation is
an inherent property of natural languages
and it also forms a central problem of natu-
ral language parsing. A consequence of the
natural language ambiguity is a high num-
ber of possible outputs of a parser that are
usually represented by labeled trees. The av-
erage number of parsing trees per input sen-
tence strongly depends on the background
grammar and thence on the language. There
are natural language grammars producing
at most hundreds or thousands of parsing
trees but also highly ambiguous grammar
systems producing enormous number of re-
sults. For example, a grammar extracted
from the Penn Treebank and tested on a
set of sentences randomly generated from a
probabilistic version of the grammar has on
average 7.2?1027 parses per sentence accord-
ing to Moore?s work (Moore, 2000). Such a
mammoth extent of result is also no excep-
tion in parsing of Czech (Smrz? and Hora?k,
2000) (see Fig. 1) due to free word order and
Figure 1: The dependence of number of re-
sulting analysis on the number of words in
the input sentence
rich morphology of word forms whose gram-
matical case cannot often be unambiguously
determined.
A traditional solution for these problems
is presented by probabilistic parsing tech-
niques (Bunt and Nijholt, 2000) aiming at
finding the most probable parse of a given
input sentence. This methodology is usually
based on the relative frequencies of occur-
rences of the possible relations in a repre-
sentative corpus. ?Best? trees are judged by
a probabilistic figure of merit (FOM).
The term ?figure of merit? is usually used
to refer to a function that prunes implausi-
ble partial analyses during parsing. In this
paper, we rather take figure of merit as a
measure bounding the true probabilities of
the complete parses.
S

HH
H
NP1
 HH
AP


HH
HH
ADJ and ADJ
N1
V NP4
 HH
ADJ NP4
 HH
N4 N2
??
selected trigrams: [ADJ,and,ADJ]
[ADJ,N1,V]
[N1,V,N4]
[V,ADJ,N4]
[ADJ,N4,N2]
Figure 2: Lexical heads as n-gram?s elements.
The standard methods of the best analy-
sis selection (Caraballo and Charniak, 1998)
usually use simple stochastic functions inde-
pendent on the peculiarities of the underly-
ing language. This approach seems to work
satisfactorily in case of analytical languages.
On the other hand, the obstacles brought
by the synthetical languages in relationship
with those simple statistical techniques are
indispensable.
Therefore, we try to improve the standard
FOMs taking into consideration specific fea-
tures of free word order languages. The fol-
lowing text discusses the assets of three fig-
ures of merit that reflect selected phenomena
of the Czech language.
2 Figures of Merit
The overall figure of merit of the syntactic
analysis results is determined as a combina-
tion of several contributory FOMs that re-
flect particular language features such as
? frequency of syntactic constructs repre-
sented by pre-computed rule probabili-
ties
? augmented n-gram model based on the
occurrence of adjacent lexical heads
standing for the corresponding subtrees
? affinity between constituents modeled
by valency frames of verbs, adjectives
and nouns
The selected FOMs participate on the de-
termination of the most probable analysis.
A straightforward approach lies in the linear
combination of FOMs:
? = ?1 ? ?1 + ?2 ? ?2 + ?3 ? ?3
where ?i are the FOMs? contributions and
?i are empirically assigned weights (usually
taken as normalizing coefficients). However,
our experiments showed that the weights ?i
need to reflect the behaviour of particular
lexical items, their categories or even anal-
ysed constituents. We thus need to handle
the ?i variables as functions of various pa-
rameters.
? = ?1( ) ? ?1 + ?2( ) ? ?2 + ?3( ) ? ?3
The following sections deal with the figures
of merit that play a crucial role in the search
for the best output analysis.
2.1 Rule-tied Actions and ?1 FOM
A key question is then what the good can-
didates for FOMs are. The use of proba-
bilistic context-free grammars (PCFGs) in-
volves simple CF rule probabilities to form
a FOM (Chitrao and Grishman, 1990; Bo-
brow, 1991).
The evaluation of the first FOM is based
on the mechanism of contextual actions built
into the metagrammar conception (Smrz? and
Hora?k, 2000). It distinguishes four kinds of
contextual actions, tests or constraints:
1. rule-tied actions
2. agreement fulfilment constraints
3. post-processing actions
4. actions based on derivation tree
The rule-based probability estimations are
solved on the first level by the rule-tied ac-
tions, which also serve as rule parameteriza-
tion modifiers.
Agreement fulfilment constraints are used
in generating the expanded grammar (Smrz?
and Hora?k, 1999) or they serve also as
chart pruning actions. In terms of (Maxwell
III and Kaplan, 1991), the agreement ful-
filment constraints represent the functional
constraints, whose processing can be inter-
leaved with that of phrasal constraints.
The post-processing actions are not trig-
gered until the chart is already completed.
The main part of FOM computation for a
particular input sentence is driven by ac-
tions on this level. Some figures of merit
(e.g. verb valency FOM, see Section 2.3) de-
mand exponential resources for computation
over the whole chart structure. This prob-
lem is solved by splitting the calculation pro-
cess into the pruning part (run on the level
of post-processing actions) and the reorder-
ing part, that is postponed until the actions
based on derivation tree.
The actions that do not need to work with
the whole chart structure are run after the
best or n most probable derivation trees are
selected. These actions are used, for exam-
ple, for determination of possible verb va-
lencies within the input sentence, which can
produce a new ordering of the selected trees.
2.2 Augmented n-grams and ?2 FOM
The ?1 FOM is based on rule frequencies and
is not capable of describing the contextual
information in the input. A popular tech-
nique for capturing the relations between
sentence constituents is the n-gram method,
which takes advantage of a fast and efficient
evaluation algorithm.
For instance, (Caraballo and Charniak,
1998) presents and evaluate different figures
of merit in the context of best-first chart
parsing. They recommend boundary trigram
estimate that has achieved the best perfor-
mance on two testing grammars. This tech-
nique, as well as stochastic POS tagging
based on n-gram statistics, achieves satis-
factory results for analytical languages (like
English). However, in case of free word or-
der languages, current studies suggest that
these simple stochastic techniques consider-
ably suffer from the data sparseness problem
and require a huge amount of training data.
The reduction of the number of possible
training schemata, which correctly keeps the
correspondence with the syntactic tree struc-
ture, is achieved by elaborate selection of
n-gram candidates. While the standard n-
gram techniques work on the surface level,
this approach allows us to move up to the
syntactic tree level. We advantageously use
the ability of lexical heads to represent the
key features of the subtree formed by its de-
pendants (see Figure 2). The principle of
lexical heads has shown to be fruitfully ex-
ploited in the analysis of free word order
languages. The obtained cut-down of the
amount of training data may be also crucial
to the usability of this stochastic technique.
2.3 Verb Valencies and ?3 FOM
Our experiments have shown that, in case of
a really free word order language, the FOMs
?1 and ?2 are not always able to discover
the correct reordering of analyses. So as
to cope with the above mentioned difficul-
ties in Slavonic languages (namely Czech),
we propose to exploit the language specific
features. Preliminary results indicate that
the most advantageous approach is the one
based upon valencies of the verb phrase ? a
crucial concept in traditional linguistics.
The part of the system dedicated to ex-
ploitation of information obtained from a list
of verb valencies (Pala and S?evec?ek, 1997)
is necessary for solving the prepositional at-
tachment problem in particular. During the
analysis of noun groups and prepositional
noun groups in the role of verb valencies
in a given input sentence one needs to be
able to distinguish free adjuncts or modi-
fiers from obligatory valencies. We are test-
ing a set of heuristic rules that determine
With Charles Peter angered at the last meeting
Na Karla? ?? ?
<HUMAN>
se Petr rozhne?val na posledn?? sch?uzi? ?? ?
<ACTIVITY>
about the lost advance for payroll
kv?uli ztracene? za?loze na mzdu.? ?? ?
<RECOMPENSE>
Figure 3: Free adjuncts identification by means of lexico-semantic constraints.
whether a found noun group typically serves
as a free adjunct. The heuristics are based
on the lexico-semantic constraints (Smrz? and
Hora?k, 1999).
An example of the application of the heuris-
tics is depicted in Figure 3. In the presented
Czech sentence, the expression na Karla
(with Charles) is denoted as a verb argument
by the valency list of the verb rozhne?vat se
(anger), while the prepositional noun phrase
na schu?zi (at the meeting) is classified as
a free adjunct by the rule specifying that
the preposition na (at) in combination with
an <ACTIVITY> class member (in locative)
forms a location expression. The remaining
constituent na mzdu (for payroll) is finally
recommended as a modifier of the preceding
noun phrase za?loze ([about the] advance).
Certainly, we also need to discharge the
dependence on the surface order. Therefore,
before the system confronts the actual verb
valencies from the input sentence with the
list of valency frames found in the lexicon,
all the valency expressions are reordered. By
using the standard ordering of participants,
the valency frames can be handled as pure
sets independent on the current position of
verb arguments.
2.4 Preferred Word Order
In analytical languages, the word order is
usually taken as rather fixed and that is why
it can be employed in parsing tree prun-
ing algorithms. However, in case of inflec-
tional languages, the approaches to word or-
der analysis are diverse. The most influen-
tial theory works with the topic-focus artic-
ulation (Sgall et al, 1986). Although nearly
all rules that could limit the order of con-
stituents in Czech sentences can be fully re-
laxed, a standard order of participants can
be defined. A corpus analysis of general
texts affirms that this preferred word order
is often followed and that it can be advanta-
geously used as an arbiter for best analysis
selection.
Cases where the ?i FOMs do not unam-
biguously elect the best candidates can be
routed by the preferred word order in the
form of functional weights ?i( ) with appro-
priate parameters.
3 Results
This section presents results of experiments
with the stated figures of merit for the best
analysis selection algorithm. First, the ac-
quisition of training data set derived by ex-
ploitation of a standard dependency tree
bank for Czech is described. Then, we step
to a comparison of parser running times with
that of another available parser.
3.1 The Training Set Acquisition
A common approach to acquiring the sta-
tistical data for analysis of syntax employs
learning the values from a fully tagged tree
bank training corpus. Building of such cor-
pora is a tedious and expensive work and
it requires a team cooperation of linguists
and computer scientists. At present the only
source of Czech tree bank data is the Prague
Dependency Tree Bank (PDTB) (Hajic?,
1998), which includes dependency analyses
of about 100 000 Czech sentences.
First, in order to be able to exploit the
data from PDTB, we have supplemented our
grammar with the dependency specification
precision on sentences percentage
of 1-10 words 86.9%
of 11-20 words 78.2%
of more than 20 words 63.1%
overall precision 79.3%
number of sentences with 8.0%
mistakes in input
Table 1: Precision estimate
for constituents. Thus the output of the
analysis can be presented in the form of pure
dependency tree. In the same time we unify
classes of derivation trees that correspond to
one dependency structure. We then define a
canonical form of the derivation to select one
representative of the class that is used for as-
signing the edge probabilities.
This technique enables us to relate the
output of our parser to the PDTB data.
However, the profit of exploitation of the
information from the dependency structures
can be higher than that and can run in an
automatically controlled environment. For
this purpose, we use the mechanism of prun-
ing constraints. A set of strict limitations is
given to the syntactic analyser, which passes
on just the compliant parses. The con-
straints can be either supplied manually for
particular sentence by linguists, or obtained
from the transformed dependency tree in
PDTB.
The Table 1 summarizes the precision es-
timates counted on real corpus data. These
measurements presented here may discount
the actual benefits of our approach due to
the estimated 8% of mistakes in the input
corpus.
3.2 Running Time Comparison
The effectivity comparison of different
parsers and parsing techniques brings a
strong impulse to improving the actual im-
plementations. Since there is no other gen-
erally applicable and available NL parser for
Czech, we have compared the running times
of our syntactic analyser on the data pro-
vided at http://www.cogs.susx.ac.uk/
lab/nlp/carroll/cfg-resources/.
These WWW pages resulted from discus-
sions at the Efficiency in Large Scale Parsing
Systems Workshop at COLING?2000, where
one of the main conclusions was the need for
a bank of data for standardization of parser
benchmarking. The best results reported
on standard data sets (ATIS and PT gram-
mars) until today are the comparison data
by Robert C. Moore (Moore, 2000). In the
package, only the testing grammars with in-
put sentences are at the disposal, the release
of referential implementation of the parser is
currently being prepared (Moore, personal
communication).
ATIS grammar, Moore?s LC3 + UTF 11.6
ATIS grammar, our system 7.2
PT grammar, Moore?s LC3 + UTF 41.8
PT grammar, our system 57.2
Table 2: Running times comparison (in sec-
onds)
Since we could not run the referential im-
plementation of Moore?s parser on the same
machine, the above mentioned times are not
fully comparable (we assume that our tests
were run on a slightly faster machine than
that of Moore?s tests). We prepare a de-
tailed comparison, which will try to explain
the differences of results when parsing with
grammars of varying ambiguity level.
4 Conclusions
The methods of the best analysis selection
algorithm described in this paper show that
the parsing of inflectional languages calls for
sensitive approaches to the evaluation of the
appropriate figures of merit. The case study
of Czech suggests that the use of language
specific features can improve the results of
simple stochastic techniques on annotated
corpus data.
Future directions of our research lead to
improvements of the quality of training data
set so that it would cover all the most fre-
quent language phenomena. Our investiga-
tions indicate that, in addition to verbs, the
best analysis selection algorithms could also
take advantage of valency frames of other
POS categories (nouns, adjectives).
References
R. J. Bobrow. 1991. Statistical agenda
parsing. In Proceedings of the February
1991 DARPA Speech and Natural Lan-
guage Workshop, pages 222?224. San Ma-
teo: Morgan Kaufmann.
H. Bunt and A. Nijholt, editors. 2000. Ad-
vances in Probabilistic and Other Parsing
Technologies. Kluwer Academic Publish-
ers.
S. Caraballo and E. Charniak. 1998. New
figures of merit for best-first probabilistic
chart parsing. Computational Linguistics,
24(2):275?298.
M. Chitrao and R. Grishman. 1990. Statisti-
cal parsing of messages. In Proceedings of
the Speech and Natural Language Work-
shop, pages 263?266, Hidden Valley, PA.
J. Hajic?. 1998. Building a syntactically an-
notated corpus: The Prague Dependency
Treebank. In Issues of Valency and Mean-
ing, pages 106?132, Prague. Karolinum.
J. T. Maxwell III and R. M. Kaplan. 1991.
The interface between phrasal and func-
tional constraints. In M. Rosner, C. J.
Rupp, and R. Johnson, editors, Proceed-
ings of the Workshop on Constraint Prop-
agation, Linguistic Description, and Com-
putation, pages 105?120. Instituto Dalle
Molle IDSIA, Lugano. Also in Computa-
tional Linguistics, Vol. 19, No. 4, 571?590,
1994.
R. C. Moore. 2000. Improved left-corner
chart parsing for large context-free gram-
mars. In Proceedings of the 6th IWPT,
pages 171?182, Trento, Italy.
K. Pala and P. S?evec?ek. 1997. Valencies of
Czech verbs. In Proceedings of Works of
Philosophical Faculty at the University of
Brno, pages 41?54. Brno. (in Czech).
P. Sgall, E. Hajic?ova?, and J. Panevova?.
1986. The Meaning of the Sentence
and Its Semantic and Pragmatic As-
pects. Academia/Reidel Publishing Com-
pany, Prague, Czech Republic/Dordrecht,
Netherlands.
P. Smrz? and A. Hora?k. 1999. Implementa-
tion of efficient and portable parser for
Czech. In Text, Speech and Dialogue:
Proceedings of the Second International
Workshop TSD?1999, Pilsen, Czech Re-
public. Springer Verlag, Lecture Notes in
Computer Science, Volume 1692.
Pavel Smrz? and Ales? Hora?k. 2000. Large
scale parsing of Czech. In Proceedings of
Efficiency in Large-Scale Parsing Systems
Workshop, COLING?2000, pages 43?50,
Saarbrucken: Universitaet des Saarlandes.
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97?104,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Verb Valency Semantic Representation for Deep Linguistic Processing 
 Ale? Hor?k1, Karel Pala1, Marie Du??2, Pavel Materna1  
 1: Faculty of Informatics, Masaryk University 
Botanicka 68a 
602 00 Brno 
Czech Republic 
{hales,pala}@fi.muni.cz 
2: VSB-Technical University of Ostrava 
17.listopadu 15 
708 33 Ostrava-Poruba 
Czech Republic 
marie.duzi@vsb.cz 
 
 
 
Abstract 
In the paper, we describe methods for 
exploitation of a new lexical database of 
valency frames (VerbaLex) in relation to 
Transparent Intensional Logic (TIL). We 
present a detailed description of the 
Complex Valency Frames (CVF) as they 
appear in VerbaLex including basic 
ontology of the VerbaLex semantic roles. 
TIL is a typed logical system developed for 
natural language semantic representation 
using TIL logical forms known as 
constructions. TIL is well suited to handle 
the difficult language phenomena such as 
temporal relations, intensionality and 
propositional attitudes. Here we make use 
of the long-term development of the 
Normal Translation Algorithm aimed at 
automatic translation of natural language 
sentences into TIL constructions. 
We examine the relations between CVFs 
and TIL constructions of predicate-
argument structures and discuss the 
procedure of automatic acquisition of the 
verbal object constructions. The 
exploitation of CVFs in the syntactic 
parsing is also briefly mentioned. 
1 Introduction 
In the paper we propose a method to integrate the 
logical analysis of sentences with the linguistic 
approach to semantics, exploiting the complex 
valency frames (CVFs) in the VerbaLex verb 
valency lexicon, see (Hlav??kov?, Hor?k, Kadlec 
2006). To this end we first present a brief survey of 
the logic we are going to use, namely Transparent 
Intensional Logic (TIL), which was originated by 
P. Tich? (Tich? 1988). Theoretical aspects of TIL 
were further developed in particular by P. Materna 
(Materna 1998) and also by co-authors of this 
paper (see, Materna, Du?? 2005, Hor?k 2002). A 
question may be asked why we do not exploit first 
order predicate logic (PL1) where some of the 
presented problems have already been explored 
and PL1 has been used to represent logical forms. 
It is a well established fact that PL1 is not able to 
handle systematically the phenomena like 
propositional verbs (which, of course, appear in 
our valency frames), grammatical tenses and 
modalities (modal verbs and modal particles in 
natural language). On the other hand, since TIL 
works with types these problems either do not arise 
or they can be solved in an intuitive way (see Ti-
ch? 1988). 
In the second linguistic section we present CVFs 
by means of which the semantics of verbs in 
natural language such as Czech or English can be 
described.  
In Section 3 we show how CVFs describe the 
surface valencies of verbs (i.e. their respective 
morphological cases in Czech) as well as the 
semantics of their predicate-argument structure. 
Concerning the latter we make use of the deep 
semantic roles expressed by two-level labels based 
partly on the Top Ontology (EuroWordNet) and 
partly on the selected literals from Princeton 
WordNet. 
Since so far these two ways of description, namely 
the logical and linguistic one, have been treated 
separately, the task we set is to propose a method 
97
of their interrelation and coordination. Needless to 
say that both ways of description of verb semantics 
are useful.  
Hence we are going to show how to combine a 
logical description using mostly terms like types, 
individuals, classes, relations, propositions, or, in 
general, constructions of these entities, with the  
linguistic framework capturing the idiosyncratic 
semantic features of the verbs such as 
SUBS(liquid:1) or AG(person:1|animal:1).  
In Section 4 we adduce an example of the analysis 
of selected English and Czech verbs for which the 
above mentioned integration has been proposed.  
   
2 Basics of Transparent Intensional 
Logic 
In this Section we provide an introductory 
explanation of the main notions of Transparent 
Intensional Logic (TIL). For exact definitions and 
details see, e.g., Tich? (1988), Tich? (2004), 
Materna (1998), Materna (2004) and Materna, 
Du?? (2005). TIL  approach to knowledge 
representation can be characterised as the ?top-
down approach?. TIL ?generalises to the hardest 
case? and obtains the ?less hard cases? by lifting 
various restrictions that apply only higher up. This 
way of proceeding is opposite to how semantic 
theories tend to be built up. The standard approach 
(e.g. predicate logic) consists in beginning with 
atomic sentences, then proceeding to molecular 
sentences formed by means of truth-functional 
connectives or by quantifiers, and from there to 
sentences containing modal operators and, finally, 
attitudinal operators. 
Thus, to use a simple case for illustration, once a 
vocabulary and rules of formation have been laid 
down, semantics gets off the ground by analysing 
an atomic sentence as follows: 
 (1) ?Charles is happy?: Fa 
And further upwards: 
 (2) ?Charles is happy, and Thelma is 
grumpy?: Fa ? Gb 
 (3) ?Somebody is happy?: ?x (Fx) 
 (4) ?Possibly, Charles is happy?:  (Fa) 
 (5) ?Thelma believes that Charles is happy?: 
Bb (Fa). 
In non-hyperintensional (i.e., non-procedural) 
theories of formal semantics, attitudinal operators 
are swallowed by the modal ones. But when they 
are not, we have three levels of granularity: the 
coarse level of truth-values, the fine-grained level 
of truth-conditions (propositions, truth-values-in-
intension), and the very fine-grained level of 
hyper-propositions, i.e., constructions of 
propositions. TIL operates with these three levels 
of granularity. We start out by analysing sentences 
from the uppermost end, furnishing them with a 
hyperintensional1 semantics, and working our way 
downwards, furnishing even the lowest-end 
sentences (and other empirical expressions) with a 
hyperintensional semantics. That is, the sense of a 
sentence such as ?Charles is happy? is a hyper-
proposition, namely the construction of the 
denoted proposition (i.e., the instruction how to 
evaluate the truth-conditions of the sentence in any 
state of affairs). 
When assigning a construction to an expression as 
its meaning, we specify a procedural know-how, 
which must not be confused with the respective 
performancy know-how. Distinguishing 
performatory know-how from procedural know-
how, the latter could be characterised ?that a 
knower x knows how A is done in the sense that x 
can spell out instructions for doing A.? For 
instance, to know what Goldbach Conjecture 
means is to understand the instruction to find 
whether ?all positive even integers ? 4 can be 
expressed as the sum of two primes?. It does not 
include either actually finding out (whether it is 
true or not by following a procedure or by luck) or 
possessing the skill to do so.2  
Furthermore, the sentence ?Charles is happy? is an 
?intensional context?, in the sense that its logical 
analysis must involve reference to empirical 
parameters, in this case both possible worlds and 
instants of time. Charles is only contingently 
happy; i.e., he is only happy at some worlds and 
only sometimes. The other reason is because the 
analysans must be capable of figuring as an 
argument for functions whose domain are 
propositions rather than truth-values. Construing 
?Fa? as a name of a truth-value works only in the 
case of (1), (2) and (3). It won?t work in (5), since 
truth-values are not the sort of thing that can be 
                                                           
1  The term ?hyperintensional? has been introduced by 
Max Cresswell in Cresswell (1975). See also 
Cresswell (1985). 
2  For details on TIL handling knowledge see Du??, 
Jespersen, M?ller (2005). 
98
believed. Nor will it work in (4), since truth-values 
are not the sort of thing that can be possible. 
Constructions are procedures, or instructions, 
specifying how to arrive at less-structured entities. 
Being procedures, constructions are structured 
from the algorithmic point of view, unlike set-
theoretical objects. The TIL ?language of 
constructions? is a modified hyper-intensional 
version of the typed ?-calculus, where Montague-
like ?-terms denote, not the functions constructed, 
but the constructions themselves. Constructions 
qua procedures operate on input objects (of any 
type, even on constructions of any order) and yield 
as output (or, in well defined cases fail to yield) 
objects of any type; in this way constructions 
construct partial functions, and functions, rather 
than relations, are basic objects of our ontology.  
By claiming that constructions are algorithmically 
structured, we mean the following: a construction 
C ? being an instruction ? consists of particular 
steps, i.e., sub-instructions (or, constituents) that 
have to be executed in order to execute C. The 
concrete/abstract objects an instruction operates on 
are not its constituents, they are just mentioned. 
Hence objects have to be supplied by another 
(albeit trivial) construction. The constructions 
themselves may also be only mentioned: therefore 
one should not conflate using constructions as 
constituents of composed constructions and 
mentioning constructions that enter as input into 
composed constructions, so we have to strictly 
distinguish between using and mentioning 
constructions. Just briefly: Mentioning is, in 
principle, achieved by using atomic constructions. 
A construction is atomic if it is a procedure that 
does not contain any other construction as a used 
subconstruction (a constituent). There are two 
atomic constructions that supply objects (of any 
type) on which complex constructions operate: 
variables and trivializations.  
Variables are constructions that construct an object 
dependently on valuation: they v-construct, where 
v is the parameter of valuations. When X is an 
object (including constructions) of any type, the 
Trivialization of X, denoted 0X, constructs X 
without the mediation of any other construction. 0X 
is the atomic concept of X: it is the primitive, non-
perspectival mode of presentation of X. 
There are three compound constructions, which 
consist of other constructions: Composition, 
Closure and Double Execution. Composition [X Y1 
? Ym] is the procedure of applying a function f v-
constructed by X to an argument A v-constructed 
by Y1,?,Ym, i.e., the instruction to apply f to A to 
obtain the value (if any) of f at A. Closure 
[?x1?xm Y] is the procedure of constructing a 
function by abstracting over variables, i.e., the 
instruction to do so. Finally, higher-order 
construction X can be used twice over as a 
constituent of a composed construction. This is 
achieved by the fifth construction called Double 
Execution 2X.  
TIL constructions, as well as the entities they 
construct, all receive a type. On the ground level of 
the type-hierarchy, there are entities unstructured 
from the algorithmic point of view belonging to a 
type of order 1. Given a so-called epistemic (or 
?objectual?) base of atomic types  (?-truth values, 
?-individuals, ?-time moments / real numbers, ?-
possible worlds), mereological complexity is 
increased by the induction rule for forming partial 
functions: where ?, ?1,?,?n are types of order 1, 
the set of partial mappings from ?1 ??? ?n to ?, 
denoted (??1??n), is a type of order 1 as well. 
Constructions that construct entities of order 1 are 
constructions of order 1. They belong to a type of 
order 2, denoted by *1. Inductively we define type 
of order n, *n.  
TIL is specific in a precise solution for intensions 
as non-empirical objects of the real world. 
Intensions are qualified as functions of a type 
((??)?), i.e., functions from possible worlds to 
chronologies of the type ? (in symbols: ???), 
where a chronology is a function of type (??). 
Some important kinds of intensions are:  
Propositions, type ??? (shortened as ?). They are 
denoted by empirical (declarative) sentences. 
Properties of members of a type ?, or simply ?-
properties, type (??)??.3 General terms (some 
substantives, intransitive verbs) denote properties, 
mostly of individuals. 
Relations-in-intension, type (??1??m)??. For 
example transitive empirical verbs, also attitudinal 
verbs denote these relations. Omitting ?? we get the 
type (??1??m) of relations-in-extension (to be met 
mainly in mathematics). 
                                                           
3  Collections, sets, classes of ??-objects? are members 
of type (??); TIL handles classes (subsets of a type) 
as characteristic functions. Similarly relations (-in-
extension) are of type(s) (??1??m). 
99
?-roles or offices, type ???, where ? ? (??). 
Frequently ??? (an individual office). Often denoted 
by concatenation of a superlative and a noun (?the 
highest mountain?). Individual roles correspond to 
what Church calls an ?individual concept?. 
 
3 The Complex Valency Frames 
Valency frames have been built in several projects 
(VALLEX for Czech PDT (?abokrtsk? 2005) or 
VerbNet (Kipper et al2006)). Motivation for the 
VerbaLex project came from comparing Czech 
WordNet verb frames with VALLEX. The main 
goal of VerbaLex is an automatic processing of 
verb phrases exploiting explicit links to Princeton 
WordNet. The complex valency frames we are 
working with can be characterized as data 
structures (tree graphs) describing predicate-
argument structure of a verb which contains the 
verb itself and the arguments determined by the 
verb meaning (their number usually varies from 1-
5). The argument structure also displays the 
semantic preferences on the arguments. On the 
syntactic (surface) level the arguments are most 
frequently expressed as noun or pronominal groups 
in one of the seven cases (in Czech) and also as 
prepositional cases or adverbials.  
An example of a complex valency frame for the 
verb zab?t (kill) looks like: 
usmrtit:1/zab?t:1/dostat:11 (kill:1) 
-frame: AG<person:1|animal:1>who_nomobl   
 VERBobl   
 PAT<person:1|animal:1>whom_accobl   
 INS<instrument:1>with_what_insopt    
-example: vrah zabil svou ob?? no?em (A murderer 
has killed the victim with a knife). 
-synonym: 
-use: prim 
More examples of CVFs for some selected verbs 
can be found below in Section 4. 
The semantics of the arguments is typically labeled 
as belonging to a given semantic role (or deep 
case), which represents a general role plus 
subcategorization features (or selectional 
restrictions). Thus valency frames in Verbalex 
include information about:  
1. the syntactic (surface) information about 
the syntactic valencies of a verb, i.e. what 
morphological cases (direct and 
prepositional ones in highly inflected 
languages such as Czech) are associated 
with (required by) a particular verb, and 
also adverbials, 
2. semantic roles (deep cases) that represent 
the integration of the general labels with 
subcategorization features (or selectional 
restrictions) required by the meaning of the 
verb.   
The inventory of the semantic roles is partly 
inspired by the Top Ontology and Base Concepts 
as they have been defined within EuroWordNet 
project. Thus we work with the general or ?large? 
roles like AG, ART(IFACT), SUBS(TANCE), 
PART, CAUSE, OBJ(ECT) (natural object), 
INFO(RMATION), FOOD, GARMENT, 
VEHICLE and others. They are combined with the 
literals from Princeton WordNet 2.0 where literals 
represent subcategorization features allowing us to 
climb down the hypero/hyponymical trees to the 
individual lexical units. For example, we have 
AG(person:1|animal:1) or SUBS(liquid:1) that can 
be used within the individual CVFs. 
The verb entries are linked to the Czech and 
Princeton WordNet 2.0, i.e. they are organized 
around the respective lemma in synsets with 
numbered senses.  
The Czech lexical resource being now developed is 
then a list of Czech CVFs ? this work is going on 
within the Verbalex project at FI MU (Hlav??kov?, 
Hor?k, 2005). Verbalex now contains approx. 
11000 verb literals organized in synsets. The 
current goal is to enlarge the lexicon to 15 000 
verbs. 
The inventory of the semantic roles we work with 
clearly represents a sort of ontology which tries to 
cover word stock of Czech verbs and can be used 
as a base for a semantic classification and 
subclassification of the verbs. The ontologies 
represent theoretical constructs designed from the 
?top? and as such they are not directly based on the 
empirical evidence, i.e. corpus data. Thus there is a 
need to confront the ontologies and the inventories 
of the semantic roles that can be derived from them 
with the corpus data and see how well they can 
correspond to them. For this purpose we are 
experimenting with the corpus data obtained from 
the Word Sketch Engine (Kilgarriff, Rychl?,  
Smr?, Tugwell 2006). 
 
100
4 Logical Analysis Using CVFs 
In this section we describe the translation of 
VerbaLex CVFs into a verb phrase, which is a core 
of a sentence logical analysis.  
TIL comes with a dissociation of significant verbs 
into two groups according to the classification of 
their meaning: 
1. by attributive verbs we ascribe qualities or 
properties to objects. Attributive verbs are 
typically expressed by the respective form 
of the verb ?to be? combined with an 
expression denoting a property; examples: 
?to be red? or ?to be mellow? or with a 
general substantive like ?to be a traitor?, ?to 
be a tree?. 
2. episodic verbs, on the other hand, specify 
actions performed by a subject. 
An episodic verb does not describe its subject's 
state in any moment of time, it rather describes an 
episode of doing something at the certain time 
moment (and necessarily some time before that 
moment plus the expectation that it will last also in 
the next few moments, at least). TIL provides a 
complex handling of episodic verbs including the 
verb tense, aspect (perfective/imperfective) or 
active/passive state. All these features are 
concentrated around the so called verbal object, the 
construction of which (i.e., the meaning of a 
particular verb phrase) is the application of (the 
construction of) the verb to (the constructions of) 
the verb's arguments. 
Since the analysis of attributive verbs is usually 
quite simple, we will concentrate in the following 
text on the examples of selected episodic verbs 
from VerbaLex and their logical analysis using the 
complex valency frames. 
The TIL type of episodic verbal objects is 
(?(??)(??))?, where ? is the type of propositions 
(???). See (Hor?k 2002, pp. 64-73) and (Tich? 
1980) for detailed explanation. Our analysis is 
driven by a linguistic (syntactic) context that 
signals the semantic fact that there is always a 
function involved here, so that we have to ascribe 
types to its arguments and value. 
 
4.1 Examples of Logical Analysis 
We have chosen cca 10 verbs with their verb 
frames from VerbaLex and we will use them as 
examples of the algorithm for determining the verb 
type in the TIL logical analysis procedure. 
 
d?t (give) 
d?t:2 / d?vat:2 / darovat:1 / v?novat:1 (give:8, 
gift:2, present:7) 
-frame: DON<organization:1>what_nomobl VERBobl  
OBJ<object:1>what_accobl  
BEN<person:1>to_whom_datobl 
-example: firma v?novala zam?stnanc?m nov? auta 
(a company gave new cars to the employees) 
-use: prim 
The verb arguments in this frame are: who, to 
whom, what (all obligatory) with (at least) two 
options: a) to whom  is an individual, b) to whom is 
a class of individuals. The respective verb types 
are ad a): ((?(??)(??))????),  
ad b): ((?(??)(??))??(??)?).  
For example to whom = to the employees of a 
given institution. To be an employee of the 
institution XY is a property, say Z / (??)??. So ?The 
company gave to the employees of XY??, not 
taking into account grammatical tenses and 
omitting trivializations we get ?w?t [Givewt XY 
Zwt etc.] (XY has the type ? here, being a collective 
rather than a class.) 
With this example, we can show that CVFs are 
used not only for determining the verbal object 
type, but also for stating additional prerequisities 
(necessary conditions) for the sentence 
constituents. The full analysis using the verb frame 
above thus contains, except the verb phrase part, 
the conditions saying that ?X gives Y to Z ? 
organization(X)  ? object(Y) ? person(Z)?. The 
predicates organization, object and person here 
represent the properties denoted by the 
corresponding terms in the wordnet hypero-
hyponymical hierarchy. 
 
d?t:15 / d?vat:15 / nab?dnout:3 / nab?zet:3 
(give:37) 
-frame: AG<person:1>who_nomobl VERBobl   
ABS<abstraction:1>what_accobl
 REC<person:1>to_whom_datobl 
-example: dal j? sv? slovo (he gave her his word) 
-example: nab?dl j? sv? srdce (he offered her his 
heart) 
-use: fig 
 
Here we have an idiom (?to give word?), which 
corresponds to an (episodic) relation between two 
101
individuals. Thus the type of the verb is 
((?(??)(??))???), the second ? corresponds to to 
whom. 
 
 
br?nit (prevent) 
br?nit:1 / zabr?nit:2 / zabra?ovat:2 / zamezit:2 / 
zamezovat:2 (prevent:2, keep:4) 
-frame: AG<person:1>who_nomobl  VERBobl 
PAT<person:1>to_whom_datobl   ACT<act:1>infobl  
-example: zabr?nila mu uhodit syna (she prevented 
him from hitting the son) 
-use: prim 
 
br?nit:1 / zabr?nit:2 / zabra?ovat:2 / zamezit:2 / 
zamezovat:2 (prevent:2, keep:4) 
-frame: AG<institution:1>what_nomobl VERBobl   
PAT<person:1>to_whom_datobl
 ACT<act:2>in_what_locopt 
-example: policie mu zabr?nila v cest? do zahrani?? 
(police prevented him from going abroad) 
-use: prim 
 
Here, arguments of the verb correspond to the 
phrases who, to whom, in (from). The third 
argument has the type of an activity given, of 
course, by an episodic verb hit the son, travel 
abroad (the substantive form travelling abroad can 
be construed as that activity). The type of the verb 
is ((?(??)(??))???((?(??)(??))?)). 
 
??ct (say) 
??ct:1 / ??kat:1 / ??ci:1 / ??kat:1 / pravit:1 (say:6) 
-frame: AG<person:1>who_nomobl   VERBobl   
COM<speech act:1>what_acc,that,dspobl   
ADR<person:1>to_whom_datopt 
-example: ??ct kolegovi dobr? den (say hello to a 
colleague) 
-example: ?ekl, ?e to plat? (he said that it holds) 
-example: pravil: "Dobr? den" (he said: ?Good 
day?) 
-use: prim 
 
The case questions for the corresponding 
arguments of the verb ??ct are a) who, what1, 
b) who, what2, c) who, to whom, what1, and d) who, 
to whom, what2. Examples of instantiated 
sentences can be a) Charles says ?Hello?, 
b) Charles says that he is ill, c) Charles says to his 
colleague ?Hello?, or d) Charles says to his 
colleague that he is ill.  
The quotation context (ad a), c)) is normally 
impossible to type. Unless we want to go into some 
deep analyses we can ascribe to any quoted 
expression the type of individual. The relation to 
and unquoted subordinate clause is analysed as a 
general construction of type ?n.  The resulting 
types of verbs are then  
a) ((?(??)(??))???),  
b) ((?(??)(??))???n),  
c) ((?(??)(??))????),  
d) ((?(??)(??))????n). 
 
bre?et1 (cry) because of something, for 
something 
bre?et:1 / plakat:1 (cry:2, weep:1) 
-frame: AG<person:1>who_nomobl   VERBobl   
CAUSE<cause:4>due+to+what_dat,over+what_ins,for+what_accobl    
-example: bre?ela kv?li zni?en?m ?at?m (she cried 
for spoiled clothes) 
-example: plakal nad svou chudobou (he cried over 
his poverty) 
-example: plakal pro sv? h??chy (he cried for his 
sins) 
-use: prim 
 
bre?et2 (cry) for somebody 
bre?et:1 / plakat:1 (cry:2, weep:1) 
-frame: AG<person:1>who_nomobl VERBobl  
ENT<person:1>for+whom_accobl  
-example: plakala pro mil?ho (she cried for her 
boy) 
-use: prim 
 
If I cry because of, for etc., then the role of causing 
is played by this because of. Crying is an episodic 
verb, whereas because of etc. is a relation between 
propositions, often between events. We have 
therefore because of / (???)??, where the first 
?(=???) belongs to the proposition denoted, e.g., by 
clothes have been spoiled or that the respective 
individual is poor, sinful etc., and the second ? to 
the proposition that the respective individual cries.  
In case of to cry for somebody the respective type 
is again a ?relation? ((?(??)(??))???), although this 
for hides some cause, which is, however, not 
mentioned.  
With this verb, we will describe the analysis of 
verb entailment handling in TIL. If we analyse a 
general case of the above mentioned meanings of 
cry (cry1-because of something, cry2-for 
102
somebody) simply to cry, (He cries all the time). 
This verb?s type is a verbal object without 
arguments, (?(??)(??))?. In addition to this the 
following rule holds: If X cries because of? or X 
cries for?, then X cries. In this way the semantic 
dependence between the three cases of crying is 
given; otherwise we would not be able to detect 
this connection, e.g. between bre?et1 and bre?et2. 
 
absolvovat (undergo) 
absolvovat:2 / pro??t:1 / pro??vat:1 (experience:1, 
undergo:2, see:21, go through:1) 
-frame: AG<person:1>who_nomobl VERBobl  
EVEN<experience:3>what_accobl  
LOC<location:1>in_what_locopt  
-example: absolvoval vy?et?en? na psychiatrick? 
klinice (he went through investigation in a 
psychiatric clinic) 
-use: prim 
In general it is an episodic relation to an event 
(type ?)4, so the type is ((?(??)(??))???). In some 
cases we may also use a relation to an episode 
(specific class of events, type (??)), then the type 
is ((?(??)(??))??(??)), and investigation in a clinic 
has to be defined as a sequence of events. 
 
akceptovat (accept) 
akceptovat:3 / p?ijmout:6 / p?ij?mat:6 (accept:4) 
-frame: AG<person:1|social group:1>who_nomobl 
VERBobl  
STATE<state:4>|EVEN<event:1>|INFO<info:1>wh
at_acc
obl 
-example: akceptujeme jeho povahu (we accept his 
character) 
-example: lid? p?ijali nov? z?kon s nad?en?m 
(people accepted new law with enthusiasm) 
-use: prim 
We can accept nearly anything. Here we meet the 
problem of type-theoretical polymorphism, which 
is handled here as a type scheme ((?(??)(??))???), 
for an arbitrary type ?. A quintessence of such a 
polymorphism: think on (about) ? one can think 
of an object of any kind. 
 
u?it (teach) 
nau?it:1 / u?it:2 / vyu?ovat:1 (teach:1, learn:5, 
instruct:1) 
                                                           
4 see (Hor?k 2002, p. 65) and (Tich? 1980). 
-frame: AG<person:1>who_nomobl VERBobl  
PAT<person:1>whom_accopt   
KNOW<subject:3>what_acc,to_what_datobl 
-example: nau?il d?t? abecedu (he educated a 
children in the alphabet)  
-example: u?? studenty matematiku (he teaches 
mathematics for students) 
-example: vyu?uje d?jepisu (he/she teaches 
history) 
-use: prim 
If understood as in ?What does (s)he live off? (S)he 
teaches.? it is the case of cry3 (see above). To 
teach understood as in ?He teaches history, 
maths?, etc., the analysis depends on which type is 
given to the school subjects, disciplines. One 
possibility is to analyse them as properties of a set 
of propositions, (?(??))??. Then to teach receives 
the type ((?(??)(??))??(?(??))??). If ?teaches 
alphabet? is the case then we have to decide what 
we mean by alphabet. Here the point is to teach 
(learn) to associate symbols and sounds 
(phonemes?), so the respective type of alphabet is 
(??), where ? is the type of symbols, ? the type of 
sounds. In the analysis of ?to educate somebody in 
something? the verb takes an individual as its 
additional argument: ((?(??)(??))????), where ? is 
the type of the discipline. 
In all the examples, we have displayed the 
relations between the two-level semantic roles used 
in the VerbaLex verb frames and the resulting 
logical analysis types of the verbal object as the 
main part of the clause?s logical construction. The 
algorithmisation of this procedure uses a list of all 
roles used in the lexicon (there are about 200 roles 
used) with the corresponding (ambiguous) logical 
types of the constituents. In this way we can form a 
basic skeleton of the automatic translation of text 
to logical constructions. 
5 Conclusions 
The paper presented a first outline of comparison 
and integration of the two approaches, namely 
logical and linguistic, to the semantics of verbs in a 
natural language (English and Czech). We are 
aware that this work is still in a great progress and 
the results so presented rather fragmentary. Still, 
we are convinced that the research project we aim 
at is a relevant contribution to the semantics of 
natural language. 
103
We have shown that pursuing such a research is 
reasonable and comes up with a new viewpoint to 
the meaning of verbs. In this way we extend our 
knowledge in the important way. Actually, we are 
dealing with two deep levels of the meaning 
description and a question may be asked which one 
is deeper and better. Our answer is, do not contrast 
the two levels, and make use of both of them. In 
this way we believe to integrate them into one 
compact whole and perhaps obtain a unique data 
structure. The results of the presented research can 
be immediately applied in the area of knowledge 
representation and in the long-term Normal 
Translation System project that is being prepared. 
We have not tackled the other deep descriptions, 
such as the method that exploits the 
tectogramatical level as it is presently applied in 
PDT (Haji? 2004). This, obviously, is a topic of 
another paper.  
 
Acknowledgments 
This work has been supported by the Academy of 
Sciences of the Czech Republic, project No. 
T100300414, by the Ministry of Education                
of CR within the Center of basic research LC536, 
by the program ?Information Society? of Czech 
Academy of Sciences, project No. 1ET101940420 
"Logic and Artificial Intelligence for multi-agent 
systems", and by the Czech Science Foundation 
under the project 201/05/2781. 
References 
 
Cresswell, M.J. (1975): ?Hyperintensional Logic?. 
Studia Logica 34, pp.25-38. 
Cresswell, M.J. (1985): Structured meanings. MIT 
Press, Cambridge, Mass. 
Du??, M., Jespersen, B., M?ller, J. (2005): Epistemic 
Closure and Inferable Knowledge. The Logica 
Yearbook 2004, ed. L. B?hounek, M. B?lkov?, 
Filosofia Prague, pp. 125-140. 
Fellbaum, C., editor. 1998. WordNet: An Electronic 
Lexical Database. The MIT Press, Cambridge, 
Massachusetts, London, England. 
Haji?, Jan (2004): Complex Corpus Annotation: The 
Prague Dependency Treebank, Jazykovedny Ustav 
L.Stura, Bratislava, Slovakia, 2004. 
Hlav??kov?, Dana - Hor?k, Ale? - Kadlec, Vladim?r 
(2006). Exploitation of the VerbaLex Verb Valency 
Lexicon in the Syntactic Analysis of Czech. Lecture 
Notes in Artificial Intelligence, Proceedings of Text, 
Speech and Dialogue 2006, Berlin, Heidelberg : 
Springer, 2006. 
Hor?k, Ale? (2002). The Normal Translation Algorithm 
in  Transparent Intensional Logic for Czech, Ph.D. 
Dissertation, Masaryk University, Brno, 2002. 
Kilgarriff, Adam - Rychl?, Pavel - Smr?, Pavel - 
Tugwell, David (2006). The Sketch Engine. In 
Proceedings of the Eleventh EURALEX 
International Congress. Lorient, France : Universite 
de Bretagne-Sud, pp. 105-116, 2004. 
Karin Kipper, Anna Korhonen, Neville Ryant, and 
Martha Palmer (2006): Extensive Classifications of 
English verbs. Proceedings of the 12th EURALEX 
International Congress. Turin, Italy. September, 
2006. 
Materna, P. (1998): Concepts and Objects. Acta 
Philosophica Fennica, Vol. 63, Helsinki.  
Materna, P. (2004): Conceptual Systems. Logos Verlag, 
Berlin. 
Materna, P., Du??, M. (2005): Parmenides Principle. 
Philosophia, vol. 32 (1-4), pp. 155-180. 
Tich?, P. (1988): The Foundations of Frege?s Logic, 
Berlin, New York: DeGruyter. 
Tich?, P. (1980): The Semantics of Episodic Verbs, 
Theoretical Linguistics 7, pp. 263-296, 1980. 
Tich?, P. (2004): Collected Papers in Logic and 
Philosophy, V. Svoboda, B. Jespersen, C. Cheyne 
(eds.), Prague: Filosofia, Czech Academy of 
Sciences, and Dunedin: University of Otago Press 
?abokrtsk?, Z. (2005): Valency Lexicon of Czech Verbs. 
Ph.D. Thesis, Faculty of Mathematics and Physics, 
Charles University in Prague, 2005. 
104
