Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 115?120,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Development and Analysis of NLP Pipelines in Argo
Rafal Rak, Andrew Rowley, Jacob Carter, and Sophia Ananiadou
National Centre for Text Mining
School of Computer Science, University of Manchester
Manchester Institute of Biotechnology
131 Princess St, M1 7DN, Manchester, UK
{rafal.rak,andrew.rowley,jacob.carter,sophia.ananiadou}@manchester.ac.uk
Abstract
Developing sophisticated NLP pipelines
composed of multiple processing tools
and components available through differ-
ent providers may pose a challenge in
terms of their interoperability. The Un-
structured Information Management Ar-
chitecture (UIMA) is an industry stan-
dard whose aim is to ensure such in-
teroperability by defining common data
structures and interfaces. The architec-
ture has been gaining attention from in-
dustry and academia alike, resulting in a
large volume of UIMA-compliant process-
ing components. In this paper, we demon-
strate Argo, a Web-based workbench for
the development and processing of NLP
pipelines/workflows. The workbench is
based upon UIMA, and thus has the poten-
tial of using many of the existing UIMA
resources. We present features, and show
examples, of facilitating the distributed de-
velopment of components and the analysis
of processing results. The latter includes
annotation visualisers and editors, as well
as serialisation to RDF format, which en-
ables flexible querying in addition to data
manipulation thanks to the semantic query
language SPARQL. The distributed devel-
opment feature allows users to seamlessly
connect their tools to workflows running
in Argo, and thus take advantage of both
the available library of components (with-
out the need of installing them locally) and
the analytical tools.
1 Introduction
Building NLP applications usually involves a se-
ries of individual tasks. For instance, the ex-
traction of relationships between named entities
in text is preceded by text segmentation, part-of-
speech recognition, the recognition of named enti-
ties, and dependency parsing. Currently, the avail-
ability of such atomic processing components is
no longer an issue; the problem lies in ensur-
ing their compatibility, as combining components
coming from multiple repositories, written in dif-
ferent programming languages, requiring different
installation procedures, and having incompatible
input/output formats can be a source of frustration
and poses a real challenge for developers.
Unstructured Information Management Archi-
tecture (UIMA) (Ferrucci and Lally, 2004) is a
framework that tackles the problem of interoper-
ability of processing components. Originally de-
veloped by IBM, it is currently an Apache Soft-
ware Foundation open-source project1 that is also
registered at the Organization for the Advance-
ment of Structured Information Standards (OA-
SIS)2. UIMA has been gaining much interest from
industry and academia alike for the past decade.
Notable repositories of UIMA-compliant tools
include U-Compare component library3, DKPro
(Gurevych et al, 2007), cTAKES (Savova et
al., 2010), BioNLP-UIMA Component Reposi-
tory (Baumgartner et al, 2008), and JULIE Lab?s
UIMA Component Repository (JCoRe) (Hahn et
al., 2008).
In this work we demonstrate Argo4, a Web-
based (remotely-accessed) workbench for collabo-
rative development of text-processing workflows.
We focus primarily on the process of development
and analysis of both individual processing com-
ponents and workflows composed of such compo-
nents.
The next section demonstrates general features
of Argo and lays out several technical details about
1http://uima.apache.org
2http://www.oasis-open.org/committees/uima
3http://nactem.ac.uk/ucompare/
4http://argo.nactem.ac.uk
115
UIMA that will ease the understanding of the re-
maining sections. Sections 3?5 discuss selected
features that are useful in the development and
analysis of components and workflows. Section 6
mentions related efforts, and Section 7 concludes
the paper.
2 Overview of Argo
Argo comes equipped with an ever-growing li-
brary of atomic processing components that can be
put together by users to form meaningful pipelines
or workflows. The processing components range
from simple data serialisers to complex text an-
alytics and include text segmentation, part-of-
speech tagging, parsing, named entity recognition,
and discourse analysis.
Users interact with the workbench through a
graphical user interface (GUI) that is accessible
entirely through a Web browser. Figure 1 shows
two views of the interface: the main, resource
management window (Figure 1(a)) and the work-
flow diagramming window (Figure 1(b)). The
main window provides access to emphdocuments,
workflows, and processes separated in easily ac-
cessible panels.
The Documents panel lists primarily user-
owned files that are uploaded (through the GUI)
by users into their respective personal spaces on
the remote host. Documents may also be gener-
ated as a result of executing workflows (e.g., XML
files containing annotations), in which case they
are available for users to download.
The Workflows panel lists users? workflows,
i.e., the user-defined arrangements of processing
components together with their settings. Users
compose workflows through a flexible, graphi-
cal diagramming editor by connecting the com-
ponents (represented as blocks) with lines signi-
fying the flow of data between components (see
Figure 1(b)). The most common arrangement is to
form a pipeline, i.e., each participating component
has at most one incoming and at most one out-
going connection; however, the system also sup-
ports multiple branching and merging points in the
workflow. An example is shown in Figure 2 dis-
cussed farther in text. For ease of use, components
are categorized into readers, analytics, and con-
sumers, indicating what role they are set to play in
a workflow. Readers are responsible for delivering
data for processing and have only an outgoing port
(represented as a green triangle). The role of an-
(a) Workflow management view
(b) Worflow diagram editor view
Figure 1: Screenshots of Argo Web browser con-
tent.
alytics is to modify incoming data structures and
pass them onto following components in a work-
flow, and thus they have both incoming and outgo-
ing ports. Finally, the consumers are responsible
for serialising or visualising (selected or all) anno-
tations in the data structures without modification,
and so they have only an incoming port.
The Processes panel lists resources that are cre-
ated automatically when workflows are submit-
ted for execution by users. Users may follow the
progress of the executing workflows (processes) as
well as manage the execution from this panel. The
processing of workflows is carried out on remote
servers, and thus frees users from using their own
processing resources.
2.1 Argo and UIMA
Argo supports and is based upon UIMA and thus
can run any UIMA-compliant processing compo-
nent. Each such component defines or imports
type systems and modifies common annotation
structures (CAS). A type system is the represen-
116
tation of a data model that is shared between com-
ponents, whereas a CAS is the container of data
whose structure complies with the type system. A
CAS stores feature structures, e.g., a token with
its text boundaries and a part-of-speech tag. Fea-
ture structures may, and often do, refer to a sub-
ject of annotation (Sofa), a structure that (in text-
processing applications) stores the text. UIMA
comes with built-in data types including primitive
types (boolean, integer, string, etc.), arrays, lists,
as well as several complex types, e.g., Annotation
that holds a reference to a Sofa the annotation is
asserted about, and two features, begin and end,
for marking boundaries of a span of text. A devel-
oper is free to extend any of the complex types.
2.2 Architecture
Although the Apache UIMA project provides an
implementation of the UIMA framework, Argo
incorporates home-grown solutions, especially in
terms of the management of workflow processing.
This includes features such as workflow branching
and merging points, user-interactive components
(see Section 4), as well as distributed processing.
The primary processing is carried out on a
multi-core server. Additionally, in order to in-
crease computing throughput, we have incorpo-
rated cloud computing capabilities into Argo,
which is designed to work with various cloud
computing providers. As a proof of concept,
the current implementation uses HTCondor, an
open-source, high-throughput computing software
framework. Currently, Argo is capable of switch-
ing the processing of workflows to a local cluster
of over 3,000 processor cores. Further extensions
to use the Microsoft Azure5 and Amazon EC26
cloud platforms are also planned.
The Argo platform is available entirely us-
ing RESTful Web services (Fielding and Taylor,
2002), and therefore it is possible to gain access
to all or selected features of Argo by implement-
ing a compliant client. In fact, the ?native? Web
interface shown in Figure 1 is an example of such
a client.
3 Distributed Development
Argo includes a Generic Listener component that
permits execution of a UIMA component that is
running externally of the Argo system. It is pri-
5http://www.windowsazure.com
6http://aws.amazon.com/ec2
marily intended to be used during the develop-
ment of processing components, as it allows a de-
veloper to rapidly make any necessary changes,
whilst continuing to make use of the existing com-
ponents available within Argo, which may other-
wise be unavailable if developing on the devel-
oper?s local system. Any component that a user
wishes to deploy on the Argo system has to un-
dergo a verification process, which could lead to
a slower development lifecycle without the avail-
ability of this component.
Generic Listener operates in a reverse manner
to a traditional Web service; rather than Argo con-
necting to the developer?s component, the compo-
nent connects to Argo. This behaviour was de-
liberately chosen to avoid network-related issues,
such as firewall port blocking, which could be-
come a source of frustration to developers.
When a workflow, containing a Generic Lis-
tener, is executed within Argo, it will continue
as normal until the point at which the Generic
Listener receives its first CAS object. Argo will
prompt the user with a unique URL, which must
be supplied to the client component run by the
user, allowing it to connect to the Argo workflow
and continue its execution.
A skeleton Java project has been provided to as-
sist in the production of such components. It con-
tains a Maven structure, Eclipse IDE project files,
and required libraries, in addition to a number of
shell scripts to simplify the running of the compo-
nent. The project provides both a command-line
interface (CLI) and GUI runner applications that
take, as arguments, the name of the class of the lo-
cally developed component and the URL provided
by Argo, upon each run of a workflow containing
the remote component.
An example of a workflow with a Generic Lis-
tener is shown in Figure 2. The workflow is de-
signed for the analysis and evaluation of a solu-
tion (in this case, the automatic extraction of bio-
logical events) that is being developed locally by
the user. The reader (BioNLP ST Data Reader)
provides text documents together with gold (i.e.,
manually created) event annotations prepared for
the BioNLP Shared Task7. The annotations are
selectively removed with the Annotation Remover
and the remaining data is sent onto the Generic
Listener component, and consequently, onto the
developer?s machine. The developer?s task is to
7http://2013.bionlp-st.org/
117
Figure 2: Example of a workflow for development,
analysis, and evaluation of a user-developed solu-
tion for the BioNLP Shared Task.
connect to Argo, retrieve CASes from the run-
ning workflow, and for each CAS recreate the re-
moved annotations as faithfully as possible. The
developer can then track the performance of their
solution by observing standard information ex-
traction measures (precision, recall, etc.) com-
puted by the Reference Evaluator component that
compares the original, gold annotations (coming
from the reader) against the developer?s annota-
tions (coming from the Generic Listener), and
saves these measures for each document/CAS into
a tabular-format file. Moreover, the differences
can be tracked visually though the interactive Brat
BioNLP ST Comparator component, discussed in
the next section.
4 Annotation Analysis and Manipulation
Traditionally, NLP pipelines (including existing
UIMA-supporting platforms), once set up, are
executed without human involvement. One of
the novelties in Argo is an introduction of user-
interactive components, a special type of analytic
that, if present in a workflow, cause the execu-
tion of the workflow to pause. Argo resumes the
execution only after receiving input from a user.
This feature allows for manual intervention in the
otherwise automatic processing by, e.g., manipu-
lating automatically created annotations. Exam-
ples of user-interactive components include Anno-
tation Editor and Brat BioNLP ST Comparator.
The Brat BioNLP ST Comparator component
Figure 3: Example of an annotated fragment of
a document visualised with the Brat BioNLP ST
Comparator component. The component high-
lights (in red and green) differences between two
sources of annotations.
Figure 4: Example of manual annotation with the
user-interactive Annotation Editor component.
expects two incoming connections from compo-
nents processing the same subject of annotation.
As a result, using brat visualisation (Stenetorp et
al., 2012), it will show annotation structures by
laying them out above text and mark differences
between the two inputs by colour-coding missing
or additional annotations in each input. A sam-
ple of visualisation coming from the workflow in
Figure 2 is shown in Figure 3. Since in this par-
ticular workflow the Brat BioNLP ST Comparator
receives gold annotations (from the BioNLP ST
Data Reader) as one of its inputs, the highlighted
differences are, in fact, false positives and false
negatives.
Annotation Editor is another example of a user-
interactive component that allows the user to add,
delete or modify annotations. Figure 4 shows the
editor in action. The user has an option to cre-
ate a span-of-text annotation by selecting a text
fragment and assigning an annotation type. More
complex annotation types, such as tokens with
part-of-speech tags or annotations that do not re-
fer to the text (meta-annotations) can be created
or modified using an expandable tree-like struc-
ture (shown on the right-hand side of the figure),
which makes it possible to create any annotation
118
(a) Select query
neAText neACat neBText neBCat count
Ki-67 Protein p53 Protein 85
DC CellType p53 Protein 61
DC CellType KCOT Protein 47
(b) Results (fragment)
(c) Insert query
Figure 5: Example of (a) a SPARQL query that returns biological interactions; (b) a fragment of retrieved
results; and (c) a SPARQL query that creates new UIMA feature structures. Namespaces and data types
are omitted for brevity.
structure permissible by a given type system.
5 Querying Serialised Data
Argo comes with several (de)serialisation com-
ponents for reading and storing collections of
data, such as a generic reader of text (Document
Reader) or readers and writers of CASes in XMI
format (CAS Reader and CAS Writer). One of
the more useful in terms of annotation analysis
is, however, the RDF Writer component as well
as its counterpart, RDF Reader. RDF Writer se-
rialises data into RDF files and supports several
RDF formats such as RDF/XML, Turtle, and N-
Triple. A resulting RDF graph consists of both the
data model (type system) and the data itself (CAS)
and thus constitutes a self-contained knowledge
base. RDF Writer has an option to create a graph
for each CAS or a single graph for an entire collec-
tion. Such a knowledge base can be queried with
languages such as SPARQL8, an official W3C
Recommendation.
Figure 5 shows an example of a SPARQL query
that is performed on the output of an RDF Writer
in the workflow shown in Figure 1(b). This work-
flow results in several types of annotations in-
cluding the boundaries of sentences, tokens with
part-of-speech tags and lemmas, chunks, as well
as biological entities, such as DNA, RNA, cell
line and cell type. The SPARQL query is meant
to retrieve pairs of seemingly interacting biolog-
ical entities ranked according to their occurrence
in the entire collection. The interaction here is
(na??vely) defined as co-occurrence of two entities
in the same sentence. The query includes pat-
terns for retrieving the boundaries of sentences
(syn:Sentence) and two biological entities
(sem:NamedEntity) and then filters out the
crossproduct of those by ensuring that the two en-
8http://www.w3.org/TR/2013/REC-sparql11-overview-
20130321/
119
tities are enclosed in a sentence. As a result, the
query returns a list of biological entity pairs ac-
companied by their categories and the number of
appearances, as shown in Figure 5(b). Note that
the query itself does not list the four biological cat-
egories; instead, it requests their common seman-
tic ancestor sem:NamedEntity. This is one of
the advantages of using semantically-enabled lan-
guages, such as SPARQL.
SPARQL also supports graph manipulation.
Suppose a user is interested in placing the re-
trieved biological entity interactions from our run-
ning example into the UIMA structure Relation-
ship that simply defines a pair of references to
other structures of any type. This can be accom-
plished, without resorting to programming, by is-
suing a SPARQL insert query shown in Figure
5(c). The query will create triple statements com-
pliant with the definition of Relationship. The re-
sulting modified RDF graph can then be read back
to Argo by the RDF Reader component that will
convert the new RDF graph back into a CAS.
6 Related Work
Other notable examples of NLP platforms that
provide graphical interfaces for managing work-
flows include GATE (Cunningham et al, 2002)
and U-Compare (Kano et al, 2010). GATE is
a standalone suite of text processing and annota-
tion tools and comes with its own programming
interface. In contrast, U-Compare?similarly to
Argo?uses UIMA as its base interoperability
framework. The key features of Argo that distin-
guish it from U-Compare are the Web availabil-
ity of the platform, primarily remote processing
of workflows, a multi-user, collaborative architec-
ture, and the availability of user-interactive com-
ponents.
7 Conclusions
Argo emerges as a one-stop solution for develop-
ing and processing NLP tasks. Moreover, the pre-
sented annotation viewer and editor, performance
evaluator, and lastly RDF (de)serialisers are in-
dispensable for the analysis of processing tasks
at hand. Together with the distributed develop-
ment support for developers wishing to create their
own components or run their own tools with the
help of resources available in Argo, the workbench
becomes a powerful development and analytical
NLP tool.
Acknowledgments
This work was partially funded by the MRC Text
Mining and Screening grant (MR/J005037/1).
References
W A Baumgartner, K B Cohen, and L Hunter. 2008.
An open-source framework for large-scale, flexible
evaluation of biomedical text mining systems. Jour-
nal of biomedical discovery and collaboration, 3:1+.
H Cunningham, D Maynard, K Bontcheva, and
V Tablan. 2002. GATE: A framework and graphical
development environment for robust NLP tools and
applications. In Proceedings of the 40th Anniver-
sary Meeting of the Association for Computational
Linguistics.
D Ferrucci and A Lally. 2004. UIMA: An Ar-
chitectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327?348.
R T Fielding and R N Taylor. 2002. Principled de-
sign of the modern Web architecture. ACM Trans.
Internet Technol., 2(2):115?150, May.
I Gurevych, M Mu?hlha?user, C Mu?ller, J Steimle,
M Weimer, and T Zesch. 2007. Darmstadt knowl-
edge processing repository based on uima. In Pro-
ceedings of the First Workshop on Unstructured
Information Management Architecture, Tu?bingen,
Germany.
U Hahn, E Buyko, R Landefeld, M Mu?hlhausen,
M Poprat, K Tomanek, and J Wermter. 2008. An
Overview of JCORE, the JULIE Lab UIMA Compo-
nent Repository. In Language Resources and Eval-
uation Workshop, Towards Enhanc. Interoperability
Large HLT Syst.: UIMA NLP, pages 1?8.
Y Kano, R Dorado, L McCrochon, S Ananiadou, and
J Tsujii. 2010. U-Compare: An integrated language
resource evaluation platform including a compre-
hensive UIMA resource library. In Proceedings of
the Seventh International Conference on Language
Resources and Evaluation, pages 428?434.
G K Savova, J J Masanz, P V Ogren, J Zheng, S Sohn,
K C Kipper-Schuler, and C G Chute. 2010. Mayo
clinical Text Analysis and Knowledge Extraction
System (cTAKES): architecture, component evalua-
tion and applications. Journal of the American Med-
ical Informatics Association, 17(5):507?513.
P Stenetorp, S Pyysalo, G Topic?, T Ohta, S Ananiadou,
and J Tsujii. 2012. brat: a web-based tool for nlp-
assisted text annotation. In Proceedings of the 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 102?107,
Avignon, France.
120
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 67?75,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013
Tomoko Ohta 1, Sampo Pyysalo 1, Rafal Rak 1, Andrew Rowley1, Hong-Woo Chun2,
Sung-Jae Jung 2,3, Chang-Hoo Jeong 2 Sung-Pil Choi 2,3, Jun?ichi Tsujii 4,Sophia Ananiadou 1
1National Centre for Text Mining and School of Computer Science, University of Manchester
2Software Research Center, Korea Institute of Science and Technology Information (KISTI)
3Department of Applied Information Science, University of Science and Technology (UST)
4Microsoft Research Asia, Beijing, China
Abstract
We present the Pathway Curation (PC)
task, a main event extraction task of
the BioNLP shared task (ST) 2013.
The PC task concerns the automatic ex-
traction of biomolecular reactions from
text. The task setting, representation
and semantics are defined with respect
to pathway model standards and ontolo-
gies (SBML, BioPAX, SBO) and docu-
ments selected by relevance to specific
model reactions. Two BioNLP ST 2013
participants successfully completed the
PC task. The highest achieved F-
score, 52.8%, indicates that event extrac-
tion is a promising approach to support-
ing pathway curation efforts. The PC
task continues as an open challenge with
data, resources and tools available from
http://2013.bionlp-st.org/
1 Introduction
Following developments in molecular biology, bi-
ological phenomena are increasingly understood
on the molecular level, as the products of complex
systems of molecular reactions. Pathway mod-
els formalizing biomolecules and their reactions
in machine readable representations are a key way
of sharing and communicating human understand-
ing of these phenomena and of developing com-
putational models of biological systems (Kitano,
2002). Many pathway models integrate knowl-
edge from hundreds or thousands of scientific pub-
lications, and their curation requires substantial
manual effort. To support this effort, we have de-
veloped PathText (Kemper et al, 2010) which pro-
vides a seamless environment integrating a path-
way visualizer, text mining systems and annota-
tion tools. Furthermore, automatic processing of
the domain literature could thus potentially play
pyruvate kinase catalyzes the conversion of PEP to pyruvate.
GGP +Regulation Conversion Chem ChemicalThemeCause Theme Product
Figure 1: Event representation for a conversion re-
action.
an important role in the support of pathway cura-
tion.
Information extraction targeting biomolecular
reactions has been a major focus of efforts in
biomedical natural language processing, with sev-
eral tasks, resources, and tools addressing in par-
ticular protein-protein interactions (Krallinger et
al., 2007; Pyysalo et al, 2008; Tikk et al, 2010).
However, most such efforts have employed sim-
ple representations, such as entity pairs, that are
not sufficient for capturing molecular reactions to
the level of detail required to support the curation
of pathway models. Additionally, previous efforts
have not directly involved the semantics (e.g. re-
action type definitions) of such models. Perhaps
in part due to these reasons, natural language pro-
cessing and information extraction methods have
not been widely embraced by biomedical pathway
curation communities (Ohta et al, 2011c; Ohta et
al., 2011a).
We believe that the extraction of structured
event representations (Figure 1) pursued in the
BioNLP Shared Tasks offers many opportuni-
ties to make significant contributions to support
the development, evaluation and maintenance of
biomolecular pathways. The Pathway Curation
(PC) task, a main task of the BioNLP Shared Task
2013, is proposed as a step toward realizing these
opportunities. The PC task aims to evaluate the ap-
plicability of event extraction systems to pathway
curation and to encourage the further development
of methods for related tasks. The design of the
task aims to address current issues in information
extraction for pathway curation by explicitly bas-
ing its representation and extraction targets on ma-
67
GTP GDP
GAPs
re1
re1 Protein Molecule MoleculeReactantModifier ProductConversion GAPs catalyze the hydrolysis of GTP to GDP.GGP +Reg Conversion Chem Chem
Cause ThemeTheme Product
(a) CONVERSION
p38 gamma Pp38 gamma
MKK6
re1
re1
MKK6 phosphorylates p38 gamma.Protein Protein
Protein
Modifier Reactant
Product
Phosphorylation MKK6 phosphorylates p38 gamma.GGP Phosphorylation GGP
Cause Theme
(b) PHOSPHORYLATION
NF-kappaB
p65
p50
p65
p50re1
p65 binds to p50.
GGP Bind GGPTheme Theme2
p65-p50 complex formation.
Complex BindingProduct
p65 and p50 form p65-p50 complex.
Protein Protein NC binding ComplexReactant2 Product
Reactant
(c) BINDING
Figure 2: Illustration of pathway reaction (left), matching representation as an idealized text-bound event
structure (middle) and applied event representation for statements actually appearing in text (right).
jor standards developed in the biomolecular path-
way curation community, such as SBML (Hucka
et al, 2003) and BioPAX (Mi et al, 2011), and
ontologies such as the Systems Biology Ontology1
(SBO) (Courtot et al, 2011). Further, The corpus
texts are selected on the basis of relevance to a se-
lection of pathway models from PANTHER Path-
way DB2 (Mi and Thomas, 2009) and BioMod-
els3 (Li et al, 2010) repositories. The PC task set-
ting and its document selection protocol aim to ac-
count for both signalling and metabolic pathways,
the latter of which has received comparatively lit-
tle attention in recent domain IE efforts (Li et al,
2013).
2 Task setting
The PC task is formulated as an event extraction
task (Ananiadou et al, 2010) following the general
representation and task setting first introduced in
the BioNLP ST 2009 (Kim et al, 2011). The pri-
mary aim is the extraction of event structures, or
events, each of which can involve any number of
physical entities or other events in specific roles.
The event representation is sufficiently expres-
sive to allow the definition of event structures that
closely parallel the definition of reactions in path-
way representations such as SBML and BioPAX.
These pathway representations differentiate be-
tween three primary groups of reaction partici-
pants: reactants (?inputs?), products (?outputs?),
and modifiers, where the specific roles of modi-
fiers can be further identified to differentiate e.g.
1http://www.ebi.ac.uk/sbo/main/
2http://www.pantherdb.org/pathway/
3http://www.ebi.ac.uk/biomodels-main/
reaction catalysts from inhibitors. Correspond-
ingly, the PC task applies the Theme role defined
in previous BioNLP ST tasks to capture reactants,
introduces a new Product role for products, and
applies the previously defined Cause role and reg-
ulatory events to capture modifiers (Figure 2; see
also Section 2.3).
It is important to note that while the event repre-
sentation allows a one-to-one mapping to reactions
in principle, an annotation scheme cannot guar-
antee that actual statements in text map to fully
specified reactions: in free-form text, authors fre-
quently omit mention of some entities taking part
in reactions, perhaps most typically to avoid re-
dundancies such as in ?p38? is phosphorylated
into phospho-p38?? (Figure 2b). Representations
extracted from explicit statements in text will thus
in some cases omit aspects of the corresponding
complete reactions in pathway models.
Systems addressing the PC task are expected to
extract events of specific types given 1) free-form
text and 2) gold standard annotation for mentions
of physical entities in that text. The task annota-
tions also include equivalence relations and event
modifications, a secondary extraction target. The
annotation types are detailed below.
2.1 Entities
The entity annotation marks mentions of physical
entities using start and end offsets in text (contigu-
ous span) and a type selected from a fixed set. The
following four entity types are marked in the PC
task: SIMPLE CHEMICAL, annotated with refer-
ence to the Chemical Entities of Biological Inter-
est (ChEBI) resource (Degtyarenko et al, 2008);
68
Entity type Scope Reference Ontology ID
SIMPLE CHEMICAL simple, non-repetitive chemical entities ChEBI SBO:0000247
GENE OR GENE PRODUCT genes, RNA and proteins gene/protein DBs SBO:0000246
COMPLEX entities of non-covalently linked components complex DBs SBO:0000253
CELLULAR COMPONENT parts of cell and extracellular environment GO-CC SBO:0000290
Table 1: Entity types, definitions, and reference resources.
Event type Core arguments Additional arguments Ontology ID
CONVERSION Theme:Molecule, Product:Molecule SBO:0000182
PHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000216
DEPHOSPHORYLATION Theme:Molecule, Cause:Molecule Site:SIMPLE CHEMICAL SBO:0000330
(Other modifications, such as ACETYLATION, defined similarly.)
LOCALIZATION Theme:Molecule At/From/ToLoc:CELL. COMP. GO:0051179
TRANSPORT Theme:Molecule From/ToLoc:CELL. COMP. SBO:0000185
GENE EXPRESSION Theme:GENE OR GENE PRODUCT GO:0010467
TRANSCRIPTION Theme:GENE OR GENE PRODUCT SBO:0000183
TRANSLATION Theme:GENE OR GENE PRODUCT SBO:0000184
DEGRADATION Theme:Molecule SBO:0000179
BINDING Theme:Molecule, Product:COMPLEX SBO:0000177
DISSOCIATION Theme:COMPLEX, Product:Molecule SBO:0000180
REGULATION Theme:ANY, Cause:ANY GO:0065007
POSITIVE REGULATION Theme:ANY, Cause:ANY
GO:0048518,
GO:0044093
ACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
NEGATIVE REGULATION Theme:ANY, Cause:ANY
GO:0048519,
GO:0044092
INACTIVATION Theme:Molecule, Cause:ANY SBO:0000412
PATHWAY Participant:Molecule SBO:0000375
Table 2: Event types and arguments. ?Molecule? refers to an entity annotation of any of the types
SIMPLE CHEMICAL, GENE OR GENE PRODUCT, or COMPLEX, and ?ANY? refers to an annotation of
any type, either entity or event. The indentation corresponds to ontological relationships between the
event types: for example, PHOSPHORYLATION is-a CONVERSION and TRANSCRIPTION part-of
GENE EXPRESSION.
GENE OR GENE PRODUCT, annotated with refer-
ence to gene and protein databases such as UniProt
(Consortium, 2011), Entrez Gene (Maglott et al,
2005) and PFam (Finn et al, 2010); COMPLEX,
annotated with reference to database resources
covering complexes; and CELLULAR COMPO-
NENT, annotated following the scope of the Gene
Ontology cellular component subontology
(Ashburner et al, 2000) (Table 1). For discussion
of the relation between these types and the repre-
sentations applied in pathway models, we refer to
Ohta et al (2011c).
In terms of mention types in text, the annotation
for SIMPLE CHEMICAL, GENE OR GENE PROD-
UCT and COMPLEX covers entity name mentions
only, while the annotation for CELLULAR COM-
PONENT covers entity name mentions, nominal
mentions, and adjectival references (e.g. ?mito-
chondrial?).
2.2 Relations
The PC task defines one relation type, Equiv
(equivalence), which can hold between entity
mitogen-activated protein kinase (MAPK, also known as ERK)
Gene or gene product GGP GGPEquivEquiv
Figure 3: Example Equiv annotation.
mentions of the same type and specifies that they
refer to the same real-world entity (Figure 3).
These relations are only applied to determine if
two events match during evaluation, where entities
connected by an Equiv relation are considered in-
terchangeable. Gold standard Equiv relations are
applied also for test data, and systems participat-
ing in the task are not expected to extract these
relations.
2.3 Events
The event annotation marks references to reac-
tions, processes and comparable associations in
scope of the annotation using the event represen-
tation. For the definition and scope of the event
annotation, we rely primarily on the Systems Biol-
ogy Ontology (SBO), drawing some general types
not in scope of this ontology from the Gene Ontol-
ogy (GO). Table 2 presents the event types anno-
69
Pathway Repository ID Publication
mTOR BioModels MODEL1012220002 (Caron et al, 2010)
mTORC1 upstream regulators BioModels MODEL1012220003 (Caron et al, 2010)
TLR BioModels MODEL2463683119 (Oda and Kitano, 2006)
Yeast Cell Cycle BioModels MODEL1011020000 (Kaizu et al, 2010)
Rb BioModels MODEL4132046015 (Calzone et al, 2008)
EGFR BioModels MODEL2463576061 (Oda et al, 2005)
Human Metabolic Network BioModels MODEL6399676120 (Duarte et al, 2007)
NF-kappaB pathway - - (Oda et al, 2008)
p38 MAPK PANTHER DB P05918 -
p53 PANTHER DB P00059 -
p53 feedback loop pathway PANTHER DB P04392 -
Wnt signaling pathway PANTHER DB P00057 -
Table 3: Pathway models used to select documents for the task, with pathway repository model identifiers
and publications presenting each model (when applicable).
tated in the PC task and their arguments. We refer
again to Ohta et al (2011c) for detailed discussion
of the relation between these types and other rep-
resentations applied in pathway models.
The role in which each event argument (entity
or other event) participates in an event is specified
as one of the following:
Theme entity/event that undergoes the effects of
the event. For example, the entity that is tran-
scribed in a TRANSCRIPTION event or transported
in a TRANSPORT event.
Cause entity/event that is causally active in the
event. Marks, for example, ?P1? in ?P1 inhibits P2
expression?.
AtLoc,FromLoc,ToLoc : location in which the
Theme entity of a LOCALIZATION event is local-
ized (At) in LOCALIZATION events not involving
movement or is transported (or moves) from/to
(From/To) in LOCALIZATION and TRANSPORT
events involving movement.
Site site on the Theme entity that is modified in
the event. Can be specified for modification events
such as PHOSPHORYLATION.
Participant general role type identifying an en-
tity that participates in some underspecified way in
a high-level process. Only applied for the PATH-
WAY type.
2.4 Event modifications
In addition to events, the PC task defines a sec-
ondary extraction target, event modifications. Two
modification types are defined: NEGATION and
SPECULATION. Both are binary flags that mod-
ify events, the former marking an event as be-
ing explicitly stated as not occurring (e.g. ?P is
not phosphorylated?) and the latter as being stated
in a speculative context (?P may be phosphory-
lated.?). Both are defined in terms of annotation
scope and semantics identically as in the BioNLP
ST?09 (Kim et al, 2009).
2.5 Evaluation
The PC task evaluation applies the standard evalu-
ation criteria established in the BioNLP ST 2009.
These criteria relax exact matching between gold
and predicted events in two aspects: approximate
trigger boundary matching, and approximate re-
cursive event matching. The former allows pre-
dicted event triggers to differ from gold triggers
by one word, and the latter requires recursively re-
ferred events to only match in their core arguments
(see Table 2). We refer to Kim et al (2011) for a
detailed definition of these criteria.
3 Corpus
This section presents the PC task corpus and its
annotation process.
3.1 Document selection
To assure that the documents annotated for the PC
task corpus are relevant to pathway reactions, we
applied two complementary approaches, both se-
lecting documents on the basis of relevance to a
specific pathway reaction. First, we selected from
the BioModels repository those pathway models
with the largest numbers of manually created an-
notations referencing a specific PubMed document
identifier. For each of these models, we extracted
literature references, selected a random subset,
downloaded the documents, and manually filtered
to select abstracts that explicitly discuss relevant
molecular reactions. Second, as only a small sub-
set of models include explicit references to the
70
literature providing evidence for specific pathway
reactions, we applied an alternative strategy where
reactions from a selection of PANTHER DB mod-
els were entered into the PathText system (Kem-
per et al, 2010),4 which is capable of suggest-
ing documents relevant to given reactions based
on an SBML model. We then selected a random
set of reactions to query the system, and manually
evaluated the highest-ranking documents to iden-
tify those whose abstracts explicitly discuss the se-
lected reaction. We refer to Miwa et al (2013a)
for a detailed description of this approach. Table 3
presents the pathway models on which the docu-
ment selection was based.
3.2 Annotation process
The base entity annotation for the PC corpus was
created automatically using state-of-the-art entity
mention taggers for each of the targeted entity
types. For SIMPLE CHEMICAL tagging, the OS-
CAR4 system (Jessop et al, 2011) trained on
the chemical named entity recognition corpus of
Corbett and Copestake (2008) was applied. For
GENE OR GENE PRODUCT mention detection, the
NERsuite5 system trained on the BioCreative 2
Gene Mention task (Wilbur et al, 2007) corpus
was used. NERsuite was also applied for CEL-
LULAR COMPONENT mention detection, for this
task trained on the Anatomical Entity Mention
(AnEM) corpus (Ohta et al, 2012). Finally, COM-
PLEX annotations were created using a combi-
nation of a dictionary and heuristics making use
of the GENE OR GENE PRODUCT annotation (for
mentions such as ?cyclin E/CDK2 complex?). To
support the curation process, these tools were in-
tegrated into the NaCTeM text-analysis workflow
system Argo (Rak et al, 2012).
Based on the evaluations of each of these tools
in the studies presenting them, we expected initial
automatic tagging performance to be in the range
80-90% in both precision and recall. Following
initial automatic annotation, the entity mention an-
notation was manually revised to improve quality
and consistency. As the entity annotation is not
itself a target of extraction in the shared task, we
did not separately evaluate the consistency of the
revised entity mention annotation.
To assure that the quality and consistency of
the event annotation are as high as possible, ini-
4http://nactem.ac.uk/pathtext/
5http://nersuite.nlplab.org/
Item Train Devel Test Total
Documents 260 90 175 525
Words 53811 18579 35966 108356
Entities 7855 2734 5312 15901
Events 5992 2129 4004 12125
Modifications 317 80 174 571
Table 4: PC corpus statistics
tial event annotation was created entirely man-
ually, without automatic support. This annota-
tion effort was carried out using the BRAT anno-
tation tool (Stenetorp et al, 2012) by a group of
biologists in collaboration between NaCTeM and
KISTI. Following initial annotator training and re-
finement of guidelines based on the event type def-
initions provided by the reference ontologies, the
primary event annotation was created by three bi-
ologists. To evaluate and maintain annotation con-
sistency, a random 20% of documents were an-
notated redundantly by all annotators, and these
overlapping annotations were periodically evalu-
ated and differences in annotation were discussed
between the annotators and annotation coordina-
tors. Following initial annotation, a round of semi-
automatic consistency checks were applied using
BRAT. Evaluation of the redundantly annotated
documents using the primary task evaluation cri-
teria gave an inter-annotator agreement of 61.0%
in F-score. For the final corpus, the redundantly
annotated documents were evaluated separately by
an annotation coordinator to select the best of each
set.6
The overall statistics of the corpus are summa-
rized in Table 4. We note that the among the
previous BioNLP ST corpora, only the GENIA
(GE) task corpus has a larger number of annotated
events than the PC corpus.
4 Results
4.1 Participation
Two groups submitted final results to the PC
task, one from the National Centre for Text Min-
ing (NaCTeM) and one from the University of
Turku BioNLP group (TEES-2.1) (Table 5). Both
participants applied their well-established, state-
of-the-art event extraction systems, EventMine7
(Miwa et al, 2012) (NaCTeM) and the Turku
6This selection implies that the consistency of the event
annotation of the final corpus is expected to exceed the 61%
F-score of the IAA experiment. Consistency after selection
was not separately evaluated.
7http://nactem.ac.uk/EventMine/
71
NLP Events Other resources
Rank Team Org Word Parse Trig. Arg. Group. Modif. Corpora Other
1 NaCTeM 1NLP Snowball Enju, GDep SVM SVM SVM SVM (see text) triggers
2 TEES-2.1 1BI Porter McCCJ + SD SVM SVM SVM SVM GE hedge words
Table 5: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician,
NLP=Natural Language Processing researcher, McCCJ=McClosky-Charniak-Johnson parser, Char-
niak=Charniak parser, SD=Stanford Dependency conversion, GE=GE task corpus.
Team recall prec. F-score
NaCTeM 52.23 53.48 52.84
TEES-2.1 47.15 55.78 51.10
Table 6: Primary evaluation results
Event Extraction System8 (Bjo?rne et al, 2011)
(TEES). The two systems share the same over-
all architecture, a one-best pipeline with SVM-
based stages for event trigger detection, trigger-
argument relation detection, argument grouping
into event structures, and modification prediction.
The feature representations of both systems draw
on substructures of dependency-like representa-
tions of sentence syntax, derived from full parses
of input sentences. TEES applies the Charniak
and Johnson (2005) parser with the McClosky
(2009) biomedical model, converting the phrase-
structure parses into dependencies using the Stan-
ford tools (de Marneffe et al, 2006). By contrast,
EventMine uses a combination of the predicate-
argument structure analyses created by the deep
parser Enju (Miyao and Tsujii, 2008) and the out-
put of the the GDep best-first shift-reduce depen-
dency parser (Sagae and Tsujii, 2007). All three
parsers have models trained in part on the biomed-
ical domain GENIA treebank (Tateisi et al, 2005).
Interestingly, both systems make use of the GE
task data, but the application of EventMine ex-
tends on this considerably by applying a stacked
model (Miwa et al, 2013b) with predictions also
from models trained on the BioNLP ST 2011 EPI
and ID tasks (Pyysalo et al, 2012) as well as from
four corpora introduced outside of the shared tasks
by Thompson et al (2011), Pyysalo et al (2011),
Ohta et al (2011b) and Ohta et al (2011c).
4.2 Evaluation results
Table 6 summarizes the primary evaluation results.
The two systems demonstrate broadly similar per-
formance in terms of F-scores, with NaCTeM
achieving an 1.7% point higher overall result.
8http://jbjorne.github.io/TEES/
However, the systems show quite different per-
formance in terms of the precision/recall balance:
while the NaCTeM system has little difference
between precision and recall, TEES-2.1 shows a
clear preference for precision, with 8.6% lower re-
call than precision.
Results are shown separately for each event type
in Table 7. The results largely mirror the over-
all performance, with the NaCTeM system show-
ing better performance for 13 out of the 21 event
types present in the test data and more balanced
precision and recall than TEES-2.1, which em-
phasizes precision over recall for almost all event
types. Although the results do not include evalu-
ation of EventMine with a reduced set of stacked
models in training, the modest difference in per-
formance suggests that comprehensive use of pre-
viously released event resources in EventMine did
not confer a decisive advantage, perhaps in part
due to differences in the event definitions between
the PC task and previous resources.
Overall, the two systems appear quite similar
not only in architecture but also performance, with
the clearest systematic difference observed being
the different emphases on precision vs. recall. As
both systems are based on machine learning meth-
ods with real-valued outputs, it would be relatively
straightforward to use prediction confidences to
analyse performance over the entire precision-
recall curve instead of a single fixed point. Such
analysis could provide further insight into the rel-
ative strengths and weaknesses of these two sys-
tems.
5 Discussion
Although participation in this initial run of the PC
task was somewhat limited, the two participating
systems have been applied to a large variety of
event extraction tasks over the last years and have
shown consistently competitive performance with
the state of the art (Bjo?rne and Salakoski, 2011;
Miwa et al, 2012). It is thus reasonable to as-
sume that the higher performance achieved by the
72
NaCTeM TEES-2.1
Event recall prec. F-score recall prec. F-score
CONVERSION 34.33 35.48 34.90 35.82 42.86 39.02
PHOSPHORYLATION 62.46 55.94 59.02 53.40 66.00 59.03
DEPHOSPHORYLATION 45.00 56.25 50.00 35.00 77.78 48.28
ACETYLATION 69.57 72.73 71.11 82.61 76.00 79.17
DEACETYLATION 33.33 33.33 33.33 0.00 0.00 0.00
METHYLATION 42.86 60.00 50.00 57.14 80.00 66.67
DEMETHYLATION 100.00 100.00 100.00 100.00 100.00 100.00
UBIQUITINATION 52.94 64.29 58.06 58.82 76.92 66.67
DEUBIQUITINATION 100.00 100.00 100.00 100.00 100.00 100.00
LOCALIZATION 42.25 61.22 50.00 43.66 54.39 48.44
TRANSPORT 65.52 61.29 63.33 56.55 59.85 58.16
GENE EXPRESSION 90.65 83.15 86.74 84.55 79.39 81.89
TRANSCRIPTION 71.15 82.22 76.29 57.69 73.17 64.52
TRANSLATION 0.00 0.00 0.00 50.00 100.00 66.67
Simple-total 66.42 64.80 65.60 60.40 67.87 63.92
DEGRADATION 78.57 89.19 83.54 78.57 78.57 78.57
ACTIVATION 78.54 70.96 74.56 72.06 72.06 72.06
INACTIVATION 44.62 55.77 49.57 38.46 45.45 41.67
BINDING 64.96 47.30 54.74 53.96 53.96 53.96
DISSOCIATION 38.46 46.88 42.25 35.90 45.16 40.00
PATHWAY 84.91 75.50 79.93 70.94 75.50 73.15
General-total 69.07 62.69 65.72 61.16 65.74 63.37
REGULATION 33.33 33.97 33.65 29.73 39.51 33.93
POSITIVE REGULATION 35.49 42.81 38.81 34.51 45.45 39.23
NEGATIVE REGULATION 45.75 50.64 48.07 41.02 47.37 43.97
Regulation-total 37.73 42.79 40.10 35.17 44.76 39.39
Sub-total 53.47 53.96 53.72 48.23 56.22 51.92
NEGATION 24.52 35.87 29.13 25.16 41.30 31.27
SPECULATION 15.79 22.22 18.46 0.00 0.00 0.00
Modification-total 23.56 34.65 28.05 22.41 40.00 28.73
Total 52.23 53.48 52.84 47.15 55.78 51.10
Table 7: Primary evaluation results by event type.
task participants, a balanced F-score of 52.8%, is
a good estimate of the performance level that can
be attained for this task by present event extraction
technology.
The results achieved by the two systems are
broadly comparable to the best results achieved by
any system in similar previously introduced event
extraction tasks (Kim et al, 2012; Pyysalo et al,
2012). Given the novelty of the task domain and
reference resource and the broad selection of doc-
uments, we find the results highly encouraging re-
garding the applicability of event extraction tech-
nology to supporting the development, evaluation,
and maintenance of pathway models.
6 Conclusions
This paper presented the Pathway Curation (PC)
task, a main event extraction task of the BioNLP
ST 2013. The task was organized in collaboration
between groups with an interest in pathway cura-
tion with the aim of evaluating and advancing the
state of the art in event extraction toward methods
for developing, evaluating and maintaining formal
pathway models in representations such as SBML
and BioPAX. We introduced an event extraction
task setting with reference to pathway model stan-
dards and the Systems Biology Ontology, selected
a set of 525 publication abstracts relevant to spe-
cific model reactions, and created fully manual
73
event annotation marking over 12,000 event struc-
tures in the corpus.
Two participants in the BioNLP ST 2013 sub-
mitted final predictions to the PC task, applying
established, state-of-the-art event extraction sys-
tems, EventMine and the Turku Event Extrac-
tion System. Both systems achieved F-scores
over 50%, with the EventMine system achiev-
ing the best overall result of 52.8%. This level
of performance is broadly comparable with re-
sults achieved in comparable previously proposed
tasks, indicating that current event extraction tech-
nology is applicable to the projected pathway cu-
ration support tasks.
To allow the further development and evalua-
tion of event extraction methods for the task, the
PC task continues as an open challenge to all inter-
ested participants, with the annotated corpus data,
supporting resources, and evaluation tools avail-
able under open licenses from the task homepage,
http://2013.bionlp-st.org/
Acknowledgments
We would like to thank Yonghwa Jo, Hyeyeon
Choi, Jeong-Ik Lee and Ssang-Goo Cho of
Konkuk University for their contribution to the de-
velopment of the relevance judgment annotation
criteria. We also wish to thank Hyun Uk Kim,
Jinki Kim and Kyusang Hwang of KAIST for
their efforts in producing the PC task annotation.
This work is a part of joint research of KISTI and
NaCTeM, and partially supported by the Biotech-
nology and Biological Sciences Research Council
(BBSRC) [BB/G53025X/1].
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and Dou-
glas B. Kell. 2010. Event extraction for systems biology
by text mining the literature. Trends in Biotechnology,
28(7):381?390.
Michael Ashburner, Catherine A. Ball, Judith A. Blake,
David Botstein, Heather Butler, J. Michael Cherry, Al-
lan P. Davis, Kara Dolinski, et al 2000. Gene ontology:
tool for the unification of biology. Nature genetics, 25:25?
29.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola, Tapio
Pahikkala, and Tapio Salakoski. 2011. Extracting contex-
tualized complex biological events with rich graph-based
feature sets. Computational Intelligence, 27(4):541?557.
Laurence Calzone, Ame?lie Gelay, Andrei Zinovyev, Franc?ois
Radvanyl, and Emmanuel Barillot. 2008. A comprehen-
sive modular map of molecular interactions in rb/e2f path-
way. Molecular systems biology, 4(1).
Etienne Caron, Samik Ghosh, Yukiko Matsuoka, Dariel
Ashton-Beaucage, Marc Therrien, Se?bastien Lemieux,
Claude Perreault, Philippe P Roux, and Hiroaki Kitano.
2010. A comprehensive map of the mtor signaling net-
work. Molecular systems biology, 6(1).
Eugene Charniak and Mark Johnson. 2005. Coarse-to-Fine
n-Best Parsing and MaxEnt Discriminative Reranking. In
Proceedings of ACL?05, pages 173?180.
The UniProt Consortium. 2011. Ongoing and future devel-
opments at the universal protein resource. Nucleic Acids
Research, 39(suppl 1):D214?D219.
Peter Corbett and Ann Copestake. 2008. Cascaded classifiers
for confidence-based chemical named entity recognition.
BMC Bioinformatics, 9(Suppl 11):S4.
Me?lanie Courtot, Nick Juty, Christian Knu?pfer, Dagmar Wal-
temath, Anna Zhukova, Andreas Dra?ger, Michel Dumon-
tier, Andrew Finney, Martin Golebiewski, Janna Hastings,
et al 2011. Controlled vocabularies and semantics in sys-
tems biology. Molecular systems biology, 7(1).
Marie-Catherine de Marneffe, Bill MacCartney, and Christo-
pher D Manning. 2006. Generating typed dependency
parses from phrase structure parses. In Proceedings of
LREC, volume 6, pages 449?454.
Kirill Degtyarenko, Paula De Matos, Marcus Ennis, Janna
Hastings, Martin Zbinden, Alan Mcnaught, Rafael
Alca?ntara, Michael Darsow, Mickae?l Guedj, and Michael
Ashburner. 2008. Chebi: a database and ontology for
chemical entities of biological interest. Nucleic acids re-
search, 36(suppl 1):D344?D350.
Natalie C Duarte, Scott A Becker, Neema Jamshidi, Ines
Thiele, Monica L Mo, Thuy D Vo, Rohith Srivas, and
Bernhard ? Palsson. 2007. Global reconstruction of
the human metabolic network based on genomic and bib-
liomic data. Proceedings of the National Academy of Sci-
ences, 104(6):1777?1782.
Robert D. Finn, Jaina Mistry, John Tate, Penny Coggill, An-
dreas Heger, Joanne E. Pollington, O. Luke Gavin, Prasad
Gunasekaran, et al 2010. The Pfam protein families
database. Nucleic Acids Research, 38(suppl 1):D211?
D222.
Michael Hucka, Andrew Finney, Herbert M Sauro, Hamid
Bolouri, John C Doyle, Hiroaki Kitano, Adam P Arkin,
Benjamin J Bornstein, et al 2003. The systems biology
markup language (SBML): a medium for representation
and exchange of biochemical network models. Bioinfor-
matics, 19(4):524?531.
David M. Jessop, Sam Adams, Egon L. Willighagen, Lezan
Hawizy, and Peter Murray-Rust. 2011. Oscar4: a flexible
architecture for chemical text-mining. Journal of chemin-
formatics, 3(1):1?12.
Kazunari Kaizu, Samik Ghosh, Yukiko Matsuoka, Hisao
Moriya, Yuki Shimizu-Yoshida, and Hiroaki Kitano.
2010. A comprehensive molecular interaction map of the
budding yeast cell cycle. Molecular systems biology, 6(1).
Brian Kemper, Takuya Matsuzaki, Yukiko Matsuoka, Yoshi-
masa Tsuruoka, Hiroaki Kitano, Sophia Ananiadou, and
Jun?ichi Tsujii. 2010. Pathtext: a text mining integra-
tor for biological pathway visualizations. Bioinformatics,
26(12):i374?i381.
74
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Jun?ichi Tsujii. 2009. Overview of BioNLP?09
Shared Task on Event Extraction. In Proceedings of
BioNLP?09.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Junichi Tsujii. 2011. Extracting bio-molecular
events from literature ? the bionlp?09 shared task. Com-
putational Intelligence, 27(4):513?540.
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsujii,
Toshihisa Takagi, and Akinori Yonezawa. 2012. The
genia event and protein coreference tasks of the bionlp
shared task 2011. BMC bioinformatics, 13(Suppl 11):S1.
Hiroaki Kitano. 2002. Systems biology: a brief overview.
Science, 295(5560):1662?1664.
Martin Krallinger, Florian Leitner, and Alfonso Valencia.
2007. Assessment of the Second BioCreative PPI task:
Automatic Extraction of Protein-Protein Interactions. In
L. Hirschman, M. Krallinger, and A. Valencia, editors,
Proceedings of BioCreative II, pages 29?39.
Chen Li, Marco Donizelli, Nicolas Rodriguez, Harish
Dharuri, Lukas Endler, Vijayalakshmi Chelliah, Lu Li,
Enuo He, et al 2010. BioModels Database: An enhanced,
curated and annotated resource for published quantitative
kinetic models. BMC Systems Biology, 4:92.
Chen Li, Maria Liakata, and Dietrich Rebholz-Schuhmann.
2013. Biological network extraction from scientific litera-
ture: state of the art and challenges. Briefings in bioinfor-
matics.
Donna Maglott, Jim Ostell, Kim D. Pruitt, and Tatiana
Tatusova. 2005. Entrez gene: gene-centered information
at ncbi. Nucleic Acids Research, 33(suppl 1):D54.
David McClosky. 2009. Any Domain Parsing: Automatic
Domain Adaptation for Natural Language Parsing. Ph.D.
thesis, Brown University.
Huaiyu Mi and Paul Thomas. 2009. PANTHER pathway: an
ontology-based pathway database coupled with data anal-
ysis tools. In Protein Networks and Pathway Analysis,
pages 123?140. Springer.
Huaiyu Mi, Anushya Muruganujan, Emek Demir, Yukiko
Matsuoka, Akira Funahashi, Hiroaki Kitano, and Paul D
Thomas. 2011. Biopax support in celldesigner. Bioinfor-
matics, 27(24):3437?3438.
Makoto Miwa, Paul Thompson, and Sophia Ananiadou.
2012. Boosting automatic event extraction from the liter-
ature using domain adaptation and coreference resolution.
Bioinformatics, 28(13):1759?1765.
Makoto Miwa, Tomoko Ohta, Rafal Rak, Andrew Rowley,
Douglas B. Kell, Sampo Pyysalo, and Sophia Ananiadou.
2013a. A method for integrating and ranking the evidence
for biochemical pathways by mining reactions from text.
Bioinformatics. in press.
Makoto Miwa, Sampo Pyysalo, Tomoko Ohta, and Sophia
Ananiadou. 2013b. Wide coverage biomedical event
extraction using multiple partially overlapping corpora.
BMC bioinformatics, 14(1):175.
Yusuke Miyao and Jun?ichi Tsujii. 2008. Feature forest mod-
els for probabilistic HPSG parsing. Computational Lin-
guistics, 34(1):35?80.
Kanae Oda and Hiroaki Kitano. 2006. A comprehensive
map of the toll-like receptor signaling network. Molecular
Systems Biology, 2(1).
Kanae Oda, Yukiko Matsuoka, Akira Funahashi, and Hiroaki
Kitano. 2005. A comprehensive pathway map of epider-
mal growth factor receptor signaling. Molecular systems
biology, 1(1).
Kanae Oda, Jin-Dong Kim, Tomoko Ohta, Daisuke
Okanohara, Takuya Matsuzaki, Yuka Tateisi, and Jun?ichi
Tsujii. 2008. New challenges for text mining: mapping
between text and manually curated pathways. BMC bioin-
formatics, 9(Suppl 3):S5.
Tomoko Ohta, Sampo Pyysalo, Sophia Ananiadou, and Ju-
nichi Tsujii. 2011a. Pathway curation support as an infor-
mation extraction task. Proceedings of LBM?11.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and Jun?ichi
Tsujii. 2011b. Event extraction for dna methylation.
Journal of Biomedical Semantics, 2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii. 2011c.
From pathways to biomolecular events: opportunities and
challenges. In Proceedings of BioNLP?11, pages 105?
113.
Tomoko Ohta, Sampo Pyysalo, Jun?ichi Tsujii, and Sophia
Ananiadou. 2012. Open-domain anatomical entity men-
tion detection. In Proceedings of DSSD?12, pages 27?36.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari Bjo?rne,
Filip Ginter, and Tapio Salakoski. 2008. Comparative
analysis of five protein-protein interaction corpora. BMC
Bioinformatics, 9(Suppl 3):S6.
Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, and Jun?ichi
Tsujii. 2011. Towards exhaustive event extraction for pro-
tein modifications. In Proceedings of BioNLP?11, pages
114?123.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan,
Chunhong Mao, Chunxia Wang, Bruno Sobral, Jun?ichi
Tsujii, and Sophia Ananiadou. 2012. Overview of the id,
epi and rel tasks of bionlp shared task 2011. BMC bioin-
formatics, 13(Suppl 11):S2.
Rafal Rak, Andrew Rowley, William Black, and Sophia Ana-
niadou. 2012. Argo: an integrative, interactive, text
mining-based workbench supporting curation. Database:
The Journal of Biological Databases and Curation, 2012.
Kenji Sagae and Jun?ichi Tsujii. 2007. Dependency parsing
and domain adaptation with lr models and parser ensem-
bles. In Proceedings of the CoNLL Shared Task Session of
EMNLP-CoNLL 2007, pages 1044?1050.
Pontus Stenetorp, Sampo Pyysalo, Goran Topic?, Tomoko
Ohta, Sophia Ananiadou, and Jun?ichi Tsujii. 2012. Brat:
a web-based tool for nlp-assisted text annotation. In Pro-
ceedings of EACL?12, pages 102?107.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Junichi
Tsujii. 2005. Syntax annotation for the genia corpus. In
Proceedings of IJCNLP, volume 5, pages 222?227.
Paul Thompson, Raheel Nawaz, John McNaught, and Sophia
Ananiadou. 2011. Enriching a biomedical event corpus
with meta-knowledge annotation. BMC Bioinformatics,
12(1):393.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg Haken-
berg, and Ulf Leser. 2010. A comprehensive benchmark
of kernel methods to extract protein-protein interactions
from literature. PLoS Comput Biol, 6(7):e1000837, 07.
John Wilbur, Lawrence Smith, and Lorraine Tanabe. 2007.
BioCreative 2. Gene Mention Task. In L. Hirschman,
M. Krallinger, and A. Valencia, editors, Proceedings of
BioCreative II, pages 7?16.
75
