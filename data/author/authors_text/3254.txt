Construction of Conceptual Graph representation of texts
Svetlana Hensman
Department of Computer Science
University College Dublin
Belfield, Dublin 4
svetlana.damianova@ucd.ie
Abstract
This paper describes a system for construct-
ing conceptual graph representation of text by
using a combination of existing linguistic re-
sources (VerbNet and WordNet). We use a two-
step approach, by firstly identifying the seman-
tic roles in a sentence, and then using these
roles, together with semi-automatically com-
piled domain-specific knowledge to construct
the conceptual graph representation.
1 Introduction
The problem of automatic acquisition of knowledge is an
interesting and challenging one and has been tackled by
linguists for some time.
This paper describes a system for automatic concep-
tual graph acquisition using a combination of linguistic
resources, such as VerbNet and WordNet, together with
semi-automatically compiled domain-specific knowl-
edge.
Such semantic information has a number of possi-
ble applications. One possible application is in the
area of information retrieval/extraction for enhancing the
search methods and for providing more precise search
results. Another application is in question-answering
systems, allowing users to communicate with the sys-
tem in natural language (English) and translating their
queries/responses into a machine-understandable repre-
sentation.
We use conceptual graphs (CGs) (Sowa, 1984), a
knowledge-representation formalism based on semantic
networks and the existential graphs of C. S. Peirce. There
is a defined mapping between a conceptual graph and a
corresponding first-order logical formula, although con-
ceptual graphs also allow for representation of temporal
and non-monotonic logics, thus exceeding the expressive
power of FOL.
One of the first systems for the generation of concep-
tual graph representation of text is described in (Sowa and
Way, 1986). It uses a lexicon of canonical graphs that rep-
resent valid (possible) relations between concepts. These
canonical graphs are then combined to build a conceptual
graph representation of a sentence.
Veraldi at al. (1988) describe a prototype of a semantic
processor for Italian sentences. It uses a lexicon of about
850 word-sense definitions, each including 10-20 surface
semantic patterns (SSPs). Each SSP represents both us-
age information and semantic constrains and is manually
acquired.
There are also systems aimed at extracting partial
knowledge from texts, by either filling semantic tem-
plates (Hobbs et al, 1996) or by generation of a set of
linguistic patterns for information extraction (Harabagiu
and Maiorano, 2000), to name few.
The following section describes the general overview
of the system, together with the documents we used to
test our algorithms. Section 3 describes the semantic role
identification module, Section 4 outlines the algorithm
for constructing the conceptual graph representation of
a sentence. The experiments that we performed are de-
scribed in Section 5, while in Section 6 we draw some
conclusions and outline ongoing and future work.
2 System overview
We use a two-step approach for conceptual graph repre-
sentation of texts: first, by using VerbNet and WordNet,
we identify the semantic roles in a sentence, and second,
using these semantic roles and a set of syntactic/semantic
rules we construct a conceptual graph.
The general architecture of the system is represented
in Figure 1.
To apply our algorithms we use documents from two
corpora in different domains. The first corpus is the freely
available Reuters-21578 text categorization test collec-
tion (Reuters, 1987). The other corpus we use is the col-
lection of aviation incident reports provided by the Irish
Air Accident Investigation Unit (AAIU) (2004) .
Figure 1: General architecture for the graph construction
All documents are converted to XML format and sen-
tential boundaries are identified. The documents are then
parsed using Eugene Charniak?s maximum entropy in-
spired parser (Charniak, 2000). This probabilistic parser
produces Penn tree-bank style trees and achieves 90.1%
average accuracy for sentences not exceeding 40 words
long and 89.5% for sentences with length under 100
words when trained and tested on the Wall Street Jour-
nal treebank.
3 Semantic role identification
The problem of automatic semantic role identification is
an important part of many natural language processing
systems and while recent syntactic parsers can correctly
label over 95% of the constituents of a sentence, finding
a representation in terms of semantic roles is still unsat-
isfactory.
There are number of quite different existing ap-
proaches for identifying semantic roles. The traditional
parsing approaches, such as HPSG grammars and Lexi-
cal functional grammars, to a certain extent all suggest se-
mantic relationships corresponding to the syntactic ones.
They rely strongly on manually-developed grammars and
lexicons, which must encode all possible realisations of
the semantic roles. Developing such grammars is a time-
consuming and tedious process and such systems usually
work well within limited domains only.
The data-driven approach is an alternative approach,
based on filling semantic templates. Applying such
a model to information extraction, in AutoSlog Riloff
(1993) builds a list of patterns for filling in semantic slots
in a specific domain, as well as a method for automatic
acquisition of case frames (Riloff and Schmelzenbach,
1998). In the domain of the Air Traveler Information
System, Miller at al. (1996) apply statistical methods to
compute the probability of a constituent in order to fill in
a semantic slot within a semantic frame.
Gildea and Jurafsky (2000, 2002) describe a statistical
approach for semantic role labelling using data collected
from FrameNet. They investigate the influence of the
following features for identification of a semantic role:
phrase type, grammatical function (the relationship of the
constituent to the rest of the sentence), position in the sen-
tence, voice and head word, as well as a combination of
features. They also describe a model for estimating the
probability a phrase to be assigned a specific semantic
role.
The approach we propose for semantic role identifica-
tion uses information about each verb?s behaviour, pro-
vided in VerbNet, and the WordNet taxonomy when de-
ciding whether a phrase can be a suitable match for a se-
mantic role.
VerbNet (Kipper et al, 2000) is a computational verb
lexicon, based on Levin?s verb classes (Levin, 1993), that
contains syntactic and semantic information for English
verbs. Each VerbNet class defines a list of members, a list
of possible thematic roles, and a list of frames (patterns)
of how these semantic roles can be realized in a sentence.
WordNet (Fellbaum, 1998) is an English lexical
database containing about 120 000 entries of nouns,
verbs, adjectives and adverbs, hierarchically organized in
synonym groups (called synsets), and linked with rela-
tions, such as hypernym, hyponym, holonym and others.
The algorithm for semantic role identification of a sen-
tence that we propose consists of the following three
steps:
1. Firstly, for each clause in the sentence we identify
the main verb and build a sentence pattern using the
parse tree;
2. Secondly, for each verb in the sentence we extract
a list of possible semantic frames from VerbNet, to-
gether with selectional restrictions for each semantic
role;
3. Thirdly, we match the sentence pattern to each of
the available semantic frames, taking into account
the semantic role?s constraints. As a result we are
presented with a list of all possible semantic role as-
signments, from which we have to identify the cor-
rect one.
These steps are described in more detail in the follow-
ing sub-sections.
3.1 Constructing sentence patterns for the verbs in
a sentence
As mentioned earlier, during the pre-processing stage we
produce a parse tree for each sentence using the Char-
niak parser. From this parse tree for each clause of the
sentence we construct a sentence pattern, which is a flat
parse representation that identifies the main verb and the
other main categories of the clause. For example, from
the parse tree for the sentence
USAir bought Piedmont for 69 dlrs cash per
share
we construct the following pattern:
NP VERB(buy) NP PP
As a sentence can have subordinate clauses, we may
have more than one syntactic pattern per sentence. Each
such pattern is processed individually.
3.2 Extracting VerbNet semantic role frames
Each verb can be described in VerbNet as a member of
more than one class (for example the verb make is listed
as a member of the verb classes dub-29.3 and build-26.1,
each of which correspond to different verb senses), and
therefore the list of its possible semantic frames is a com-
bination of the semantic frames defined in each of the
classes in which it participates (currently we do not dis-
tinguish between different verb senses and therefore do
not process the WordNet sense information attached to
each verb class member).
We extract all the semantic frames in a class and con-
siders them to be possible semantic frames for each of
the verbs that are members of this class. For example, for
all the verbs that are members of the VerbNet class get-
13.5.1 (including the verb buy) we extract the semantic
frames shown in Figure 2.
Agent V Theme (1)
Agent V Theme Prep(from) Source (2)
Agent V Theme Prep(for) Beneficiary (3)
Agent V Beneficiary Theme (4)
Agent V Theme Prep(for) Asset (5)
Asset V Theme (6)
Figure 2: Semantic frames and selectional restrictions ex-
tracted for the verbs in class get-13.5.1
The verb classes also define a list of selectional con-
straints each semantic roles should satisfy. For example,
the roles defined in the VerbNet class get-13.5.1 should
satisfy the restrictions shown in Figure 3.
Some frames define additional restrictions local to the
frame. In this case these restrictions are combined with
the restrictions defined in the frames.
Agent[+animate OR +organization]
Theme[]
Source[+concrete]
Beneficiary[+animate OR +organization]
Asset[+currency]
Figure 3: Selectional constraints for the semantic roles
defined in class get-13.5.1
3.3 Matching algorithm
The matching algorithm matches the sentence pattern
against each of the possible semantic role frames ex-
tracted from VerbNet. We independently match the con-
stituents before and after the verb in the sentence pattern
to the semantic roles before and after the verb in the se-
mantic role frame.
If the number of the available constituents in the sen-
tence pattern is less than the number of the required slots
in the frame, the match fails.
If there is more than one constituent available to fill a
slot in a semantic frame, they are assigned priorities using
heuristic rules. For example, in the cases where we have
a choice of a few possible role fillers for the Agent, a
higher weight is given to noun phrases, especially if they
are marked as proper nouns (NNP) or contain at least one
proper noun.
If, for a semantic frame, we find a constituent for each
of the semantic role slots that complies with the selec-
tional constraints, the algorithm considers this a possible
match. Currently, if the algorithm returns more than one
match, we manually select the best one.
3.4 Selectional constraints check
The selectional constraints check verifies if a candidate
constituent for a thematic role fulfills the selectional con-
straints assigned to this role. For example, a common
requirement for a constituent to fill the role of Agent is to
be of type animate or organization.
The selectional constraints check is implemented us-
ing one or combination of the following techniques: hy-
pernym relations defined in WordNet, pattern matching
techniques, syntactic rules and some heuristics.
For example, the restriction machine is a type restric-
tion and is fulfilled if the word represented by the con-
stituent is a member of a synset that is a hyponym of the
synset containing the word machine.
Other restrictions, like infinitival and sentential, are re-
solved only by checking the syntactic parse structure of
the parse tree.
Restrictions such as animate and organization are re-
solved by applying a combination of the synset hierarchy
in WordNet and pre-compiled lists of organization and
personal names, and if no satisfactory answer is found,
using heuristics to identify if the phrase contains proper
nouns.
We also check for a suitable preposition before the con-
stituent to be matched. For example, for the frame
Agent V Topic Prep(to) Recipient
the constituent filling the semantic role of Recipient
should be a prepositional phrase headed by the preposi-
tion to (e.g. Bob said a few words to Mary).
4 Building conceptual graphs
The previous section describes the process of identify-
ing the semantic roles of the constituents in a sentence.
These roles are used to build a conceptual graph represen-
tation of the sentence by applying series of transforma-
tions, starting with more generic concepts and relations
and replacing them with more specific ones.
The conceptual graph is built through the following
steps:
  Step 1 ? For each of the constituents of the sentence
we build a conceptual graph representation
Each phrase (part of the sentence) should be repre-
sented by a conceptual graph. This is done recur-
sively by analysing the syntactical structure of the
phrase.
  Step 2 ? Link all the conceptual graphs representing
the constituents in a single graph
All the conceptual graphs built during the previ-
ous step are attached to the concept representing the
verb, thus creating a conceptual graph representa-
tion for the complete sentence.
  Step 3 ? Resolve the unknown relations
This step attempts to identify all generic labels as-
signed during the previous two steps. This is done
by using a list of relation correction rules.
Each of these steps are described in more detail in the
following sub-sections.
4.1 Building a conceptual graph representation of a
phrase
This step involves building a conceptual graph for a
phrase. Our general assumption is that each lexeme in the
sentence is represented using a separate concept, there-
fore all nouns, adjectives, adverbs and pronouns are rep-
resented using concepts, while the determiners and num-
bers are used as a referent of the relevant concept (thus
further specifying the concept).
Here we will outline the process of building a concep-
tual graph for a phrase depending on the part of speech
category of the phrase.
4.1.1 Noun phrases
The list of some of the most common syntactic patterns
for noun phrases is shown in Table 1.
Syntactic pattern % AAIU % Reuters
(1) NP -  DT NN 20.42% 9.10%
(2) NP -  NP PP 12.99% 14.17%
(3) NP -  DT JJ NN 5.32% 2.49%
(4) NP -  NN 5.18% 4.01%
(5) NP -  NNP 4.59% 6.09%
(6) NP -  PRP 3.57% 4.47%
(7) NP -  NNP NNP 3.22% 2.15%
(8) NP -  CD NNS 2.88% 1.81%
(9) NP -  DT NN NN 2.20% 1.17%
(10) NP -  NP SBAR 0.88% 1.29%
Table 1: A list of some of the most common syntactic
patterns for noun phrases
Each of these cases is resolved individually. For exam-
ple, for pattern (1) we create a concept for the NN with a
referent, corresponding to the type of the determiner (an
existential quantifier referent if the word marked as DT
is the, a defined quantifier if the word is every, or none
if the word is a). For pattern (3) we create concepts rep-
resenting the adjective and the noun and link them by an
Attribute relation. Pattern (10) represents phrases where
the noun is further specified by the SBAR (for example,
The co-pilot, who was acting as a main pilot, landed the
plane.) For these patterns a conceptual graph is built for
the SBAR and the head concept, which could be a WHNP
phrase (e.g. which or who) or WHADVP (e.g. where) is
replaced by the concept, created for the NP (also see Ta-
ble 3).
4.1.2 Prepositional phrases
The conceptual graph representation of propositional
phrases, similarly on the noun phrases, depends on their
syntactic structure. A list of the most common syntactic
patterns for prepositional phrases is shown in Table 2.
Syntactic pattern % AAIU % Reuters
(1) PP -  IN NP 77.99% 82.57%
(2) PP -  TO NP 13.81% 8.81%
Table 2: A list of the most common syntactic patterns for
prepositional phrases
The two most common patterns consist of a preposi-
tion followed by a noun phrase. For such prepositional
phrases we construct a conceptual graph representing the
noun phrase. We also keep track of the preposition head-
ing the prepositional phrase, as it is used to mark the re-
lation between this phrase and the rest of relevant phrases
in the sentence.
4.1.3 Subordinate clauses
The list of the most common syntactic patterns for
phrases representing subordinate clauses (and marked as
SBAR) is shown in Table 3.
Syntactic pattern % AAIU % Reuters
(1) SBAR -  IN S 52.76% 24.33%
(2) SBAR -  WHNP S 18.90% 12.57%
(3) SBAR -  WHADVP S 12.60% 2.53%
(4) SBAR -  S 3.94% 56.34%
Table 3: A list of the most common syntactic patterns for
subordinate phrases
For all these cases the embedded clause S is treated
as an independent sentence, and we recursively create a
conceptual graph for it. To link the resulting graph to the
main graph we either use a relation with label related to
the preposition marked as IN (in case (1)) or by replac-
ing the concept representing the WHNP or the WHADVP
node with the concept representing the node it refers to.
4.2 Attaching all constituents to the verb
After building separate graphs for each of the con-
stituents, we link them together in a single conceptual
graph. As each of them describe some aspect of the con-
cept represented with the verb, we link them to that con-
cept. Here we use the term main node to denote the node
(concept) in the conceptual graph representing the head
of the constituent. We identify the head using syntactic
information about the constituent. For example, if the
constituent is a noun phrase consisting of a noun phrase,
followed by a prepositional phrase, its head is the head of
the noun phrase and the PP is a modifier. Alternatively,
if the constituent is a noun phrase that consists of an ad-
jective followed by a noun, the noun is the head and the
adjective is a modifier.
If the constituent already has a semantic role attached
to it, the same relation is used when constructing the
conceptual graph between the CG representing the con-
stituent and the verb.
If the constituent does not have any semantic roles at-
tached to it, a relation with a generic label is used. Using
a generic type of relation allows us to build the structure
of the CG, concentrating on the concepts involved, and to
resolve the remaining relations later. If the constituent is
not a propositional phrase (this includes NP, SBAR, etc.),
we use a generic label REL.
If the constituent is a prepositional phrase (PP) headed
with a proposition prep, we use a generic label REL prep.
For example, for the phrase a flight from Dublin we create
a concept of a flight and a concept of a city, called Dublin
and link them with a generic relation REL from.
4.3 Resolving unknown relations
This is the final step in the conceptual graph construction,
where we resolve the unknown (generic) relations in the
conceptual graph.
We keep a database of most common syntactic reali-
sation of relations between concepts with specific types.
Figure 4 shows some of the relation correction rules we
use for the documents in the AAIU corpus. The left
part of the rule represents the two concepts linked with a
generic relation, while the right side represents this graph
after the correction. For example, the first pattern states
that if in our graph there are concepts Runway and Air-
port linked with relation REL at, we replace the relation
with Location.
Runway REL at Airport -  Runway Location Airport
Flight REL from Airport -  Flight Source Airport
Flight REL from City -  Flight Source City
Flight REL to Airport -  Flight Destination Airport
Flight REL to City -  Flight Destination City
Flight REL for Airport -  Flight Destination Airport
Flight REL for City -  Flight Destination City
Land REL on Runway -  Land Destination Runway
Route REL from City -  Route Source City
Route REL to City -  Route Destination City
Figure 4: A sample list of relation correction rules
Building the relation correction rules database is
a challenging task. Currently, the process is semi-
automated by scanning the corpus for commonly occur-
ring syntactic patterns. Such patterns are then manually
evaluated and the semantic relations are identified.
Here is an example of applying a relation correction
rule: for the NP the flight from Dublin on step 2 we create
the conceptual graph
[FLIGHT:*a]-  (REL from)-  [City:Dublin]
Using the correction rule 3 we substitute the relation
REL from with Source to produce the graph
[FLIGHT:*a]-  (Source)-  [City:Dublin]
This is an useful approach for resolving relations be-
tween nouns, as no such information is available in Verb-
Net.
5 Experimental results
We currently are in the process of testing and tuning our
system. We have some preliminary results for the per-
formance of the semantic role annotation module, both
on Reuters news articles and AAIU reports. The tests on
the Reuters documents are performed on a quarter of the
available corpus (reut2-003.sgm) and for the AAIU doc-
uments on the reports from years 1998, 1999 and 2000.
The coverage (the percentage of the verbs in the cor-
pus that have a VerbNet description) of VerbNet for both
corpora is relatively low: 66% for Reuters and 53% for
the AAIU.
To evaluate the performance of the semantic role la-
belling algorithm we randomly selected 1% of the verbs
from each corpus and manually analysed the assigned se-
mantic roles. Our tests show that the semantic roles are
correctly identified in 39% of cases in Reuters corpus and
35% of the cases in the AAIU reports, which is 59% and
66% respectively of the verbs present in VerbNet (the per-
centage of the correctly identified out of all that are cov-
ered by VerbNet).
We are currently extending the coverage of VerbNet by
manually identifying frames present in the corpora and
not included in VerbNet, which we believe should signif-
icantly increase the performance.
6 Conclusions
In this paper we described an approach for constructing
conceptual graphs for English sentences, using syntactic
and semantic information from VerbNet and WordNet, as
well as some domain-specific knowledge. We tested the
semantic role labeling algorithm on parts of Reuters cor-
pus and on Irish Air Accident reports. The achieved ac-
curacy is strongly influenced by the lack of VerbNet de-
scription of many verbs present in the corpora, as well as
the lack of semantic frames for the verb sense.
The work on the system is ongoing and the efforts
are continuing to implement a verb sense disambiguation
component and to test the conceptual graph construction
module.
7 Acknowledgments
This work is developed as part of the INTINN project,
funded under the Enterprise Ireland Informatics Research
Initiative. I would also like to thank my supervisor, John
Dunnion, and the anonymous reviewers for their useful
comments.
References
Air Accident Investigation Unit. 2004. Irish Air Ac-
cident Investigation Unit Reports. Available online:
(http://www.aaiu.ie/).
Eugene Charniak. 2000. A Maximum-Entropy-Inspired
Parser. In Proceedings of NAACL-2000, pages 132?
139.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, May.
Daniel Gildea and Daniel Jurafsky. 2000. Automatic La-
beling of Semantic Roles. In Proceedings of 38th An-
nual Conference of the Association for Computational
Linguistics (ACL-00), pages 512?520, Hong Kong,
October.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic La-
beling of Semantic Roles. Computational Linguistics,
28(3):245?288.
Sanda Harabagiu and Steven Maiorano. 2000. Acqui-
sition of linguistic patterns for knowledge-based in-
formation extraction. In Proceedings of LREC-2000,
Athens, June.
Jerry Hobbs, Douglas Appelt, John Bear, David Israel,
Megumi Kameyama, Mark Stickel, and Mabry Tyson.
1996. FASTUS: A cascaded finite-state transducer for
extracting information from natural-language text. In
In Finite State Devices for Natural Language Process-
ing, Cambridge, MA. MIT Press.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-Based Construction of a Verb Lexicon.
In Proceedings of Seventeenth National Conference on
Artificial Intelligence (AAAI-2000), pages 691 ? 696,
Austin, TX, July 30 - August 3.
Beth Levin. 1993. English Verb Classes And Alterna-
tions: A Preliminary Investigation. The University of
Chicago Press.
Scott Miller, David Stallard, Robert Bobrow, and Richard
Schwartz. 1996. A fully statistical approach to nat-
ural language interfaces. In Proceedings of the 34th
Annual Meeting of the Association for Computational
Linguistics, pages 55?61, Santa Cruz, CA, June. Mor-
gan Kaufmann Publishers, Inc.
Reuters. 1987. Reuters-21578 Text Categorization
Collection. Available online: (http://kdd.ics.uci.edu/-
databases/reuters21578/reuters21578.html).
Ellen Riloff and Mark Schmelzenbach. 1998. An Empir-
ical Approach to Conceptual Case Frame Acquisition.
In Proceedings of the Sixth Workshop on Very Large
Corpora.
Ellen Riloff. 1993. Automatically Constructing a Dictio-
nary for Information Extraction Tasks. In Proceedings
of the Eleventh National Conference on Artificial In-
telligence (AAAI-93), pages 811?816. AAAI Press/The
MIT Press.
John F. Sowa and Eileen C. Way. 1986. Implementing
a semantic interpreter using conceptual graphs. IBM
Journal of Research and Development, 30(1):57?69,
January.
John F. Sowa. 1984. Conceptual Structures: Information
Processing in Mind and Machine. Addison-Wesley,
Reading, M.
Paola Velardi, Maria Teresa Pazienza, and Mario
De?Giovanetti. 1988. Conceptual graphs for the anal-
ysis and generation of sentences. IBM Journal of Re-
search and Development, 32(2):251?267, March.
Representing semantics of texts - a non-statistical approach
Svetlana Hensman
School of Computing
Dublin Institute of Technology
Kevin Street
Dublin 8, Ireland
Svetlana.Hensman@comp.dit.ie
John Dunnion
Intelligent Information Retrieval Group
Department of Computer Science
University College Dublin
Belfield, Dublin 4, Ireland
John.Dunnion@ucd.ie
Abstract
This paper describes a non-statistical
approach for semantic annotation of
documents by analysing their syntax
and by using semantic/syntactic behav-
iour patterns described in VerbNet. We
use a two-stage approach, firstly iden-
tifying the semantic roles in a sen-
tence, and then using these roles to rep-
resent some of the relations between
the concepts in the sentence and a list
of noun behaviour patterns to resolve
some of the unknown (generic) rela-
tions between concepts. All outlined
algorithms were tested on two corpora
which differs in size, type, style and
genre, and the performance does not
vary significantly.
1 Introduction
This paper describes a system for semi-automatic
conceptual graph acquisition using a combina-
tion of linguistic resources, such as VerbNet and
WordNet, together with semi-automatically com-
piled domain-specific knowledge. Such seman-
tic information has a number of possible applica-
tions, for example in the area of information re-
trieval/extraction for enhancing the search meth-
ods or in question-answering systems, allowing
users to communicate with the system in natural
language (English).
We use conceptual graphs (CGs) (Sowa, 1984),
a knowledge-representation formalism based on
semantic networks and the existential graphs of
C. S. Pierce, to represent the semantics of doc-
uments. There are number of systems for gen-
erating conceptual graphs representation of sen-
tences: Sowa and Way (Sowa and Way, 1986)
use a lexicon of canonical graphs which are com-
bined to build a conceptual graph representation
of a sentence, while Veraldi at al. (Velardi et al,
1988) describe a prototype of a semantic proces-
sor for Italian sentences, which uses a manually
acquired lexicon of about 850 word-sense defin-
itions, each including 10 ? 20 surface semantic
patterns (SSPs) representing both usage informa-
tion and semantic constraints.
There are also systems aimed at extracting par-
tial knowledge from texts, by either filling seman-
tic templates (Hobbs et al, 1996) or by generating
a set of linguistic patterns for information extrac-
tion (Harabagiu and Maiorano, 2000), to name
but a few.
The following sections describe in more detail
the various aspects of our system, the experiments
that we carried out to test the proposed algorithms
and finally draw some conclusions.
2 System overview
We use a two-step approach for constructing con-
ceptual graph representations of texts: firstly,
by using VerbNet and WordNet, we identify
the semantic roles in a sentence, and secondly,
using these semantic roles and a set of syn-
tactic/semantic rules we construct a conceptual
graph.
To evaluate our algorithms we use test docu-
ments from two corpora in different domains ?
the Reuters-21578 text categorization test collec-
209
tion (Reuters, 1987) and the collection of aviation
incident reports provided by the Irish Air Acci-
dent Investigation Unit (AAIU) (Air Accident In-
vestigation Unit, 2004). All documents are parsed
using Eugene Charniak?s maximum entropy in-
spired parser (Charniak, 2000).
3 Semantic role identification
There are number of different existing ap-
proaches for identifying semantic roles, varying
from traditional parsing approaches, for exam-
ple using HPSG grammars and Lexical Func-
tional Grammars, that strongly rely on manually-
developed grammars and lexicons, to data-driven
approaches, for example AutoSlog (Riloff and
Schmelzenbach, 1998). In the domain of the Air
Traveler Information System (Miller et al, 1996)
the authors apply statistical methods to compute
the probability that a constituent can fill in a se-
mantic slot within a semantic frame. Gildea and
Jurafsky (Gildea and Jurafsky, 2002) describe a
statistical approach for semantic role labelling us-
ing data collected from FrameNet by analysing a
number of features such as phrase type, grammat-
ical function, position in the sentence, etc.
Shi and Mihalcea (Shi and Mihalcea, 2004)
propose a rule-based approach for semantic pars-
ing using FrameNet and WordNet. They extract
rules from the tagged data provided by FrameNet,
which specify the realisation (order and different
syntactic features) for the present semantic roles.
They also create a feature set representation of
the sentence and match it to each of the extracted
rules. The result is the rule providing the most
feature matches. The authors do not provide any
information on how they select between different
matches with the same score, or if there is any
semantic check on suitability of a phrase to re-
alise a semantic role (FrameNet does not provide
any restrictions on the semantic roles similar to
the selectional restrictions present in VerbNet).
The approach we propose for semantic role
identification uses information about each verb?s
behaviour, provided in VerbNet, and the Word-
Net taxonomy to decide whether a phrase can be
a suitable match for a semantic role.
VerbNet (Kipper et al, 2000) is a computa-
tional verb lexicon, based on Levin?s verb classes,
that contains syntactic and semantic information
for English verbs. Each VerbNet class defines a
list of members, a list of possible thematic roles,
and a list of frames (patterns) of how these se-
mantic roles can be realized in a sentence.
WordNet (Fellbaum, 1998) is an English lex-
ical database containing about 120 000 entries
of nouns, verbs, adjectives and adverbs, hier-
archically organized in synonym groups (called
synsets), and linked with relations such as hyper-
nym, hyponym, holonym and others.
To identify the semantic roles for a clause in a
sentence we identify and match the clause pattern
to each of the possible semantic frames for the
clause verb (from VerbNet). The result is a list
of all possible semantic role assignments, from
which we must identify the correct one.
3.1 Constructing sentence patterns for the
verbs in a sentence
For each sentence clause we construct a syntac-
tical pattern, which is a flat parse representation
that identifies the main verb and the other main
categories of the clause. As a sentence can have
subordinate clauses, we usually have more than
one syntactic pattern per sentence. Each such pat-
tern is processed individually.
Using a constituency parser (such as Char-
niak?s) is suitable in the majority of cases, but
there are some sentences where the correct set of
role fillers cannot be identified by using the parse
tree. For example, for sentences such as
The price of oil will rise by 5 cents by
the end of the year.
the phrase the price of oil will be identified as
a possible role filler by our system, while the cor-
rect result would have the price identified as the
Attribute and oil as the Patient. For such cases the
use of a dependency parser (such as a Link Gram-
mar parser or a Functional Dependency Grammar
parser) would be required.
We also address some simple cases of pronoun
anaphoric reference. For example, for patterns
such as
Iomega Corp said it has laid off over a
quarter of its professional and manage-
ment staff.
210
we identify the pronoun it as referring to the
subject of the verb in the main clause (which here
is Iomega Corp) if they agree by gender and num-
ber. In cases where the type of the concept repre-
sented by the phrase is known, an agreement by
type is also required.
Some cases of intersentential pronoun
anaphoric references are also resolved by
analysing the previous sentence context for
suitable candidates, that agree by gender, number
and type. Agreement by type is present if the
type of the phrase is compatible (or the same) as
the type of the phrase it references. For example,
if the company refers to Iomega Corp, which is
listed as an instance of the type organization, then
the types of the two phrases are compatible, as
company is defined as sub-type of organization.
If agreement by type cannot be assured, the
reference is not resolved. The reference is only
resolved if there is a single possibility for its
resolution.
3.2 Extracting VerbNet semantic role frames
Each verb can be described in VerbNet as a mem-
ber of more than one class, and therefore the list
of its possible semantic frames is a combination
of the semantic frames defined in each of the
classes in which it participates.
We extract all the semantic frames in a class
and consider them to be possible semantic frames
for each of the verbs that are members of this
class. Each verb class also defines a list of se-
lectional constraints for the semantic roles. For
example, for all the verbs that are members of the
VerbNet class get-13.5.1 one of the possible se-
mantic role frames is:
Agent[+animate OR +organization] V Theme
Prep(from) Source[+concrete].
The selectional constraints check is imple-
mented using one or a combination of the fol-
lowing techniques: hypernym relations defined in
WordNet, pattern matching techniques, syntactic
rules and some heuristics.
3.3 Matching algorithm
The matching algorithm matches the sentence
pattern against each of the possible semantic role
frames extracted from VerbNet. We match the
constituents before and after the verb in the sen-
tence pattern to the semantic roles before and after
the verb in the semantic role frame.
If the number of the available constituents in
the sentence pattern is less than the number of
the required slots in the frame, the match fails.
If there is more than one constituent available to
fill a slot in a semantic frame, each of them is
considered a different match. If, for a seman-
tic frame, we find a constituent for each of the
semantic role slots that complies with the selec-
tional constraints, the algorithm considers this a
possible match.
Multiple results are identified when there are
two or more phrases in a sentence that are possi-
ble semantic role realisations, or if there are two
or more semantic frames for which matches were
found. To select the correct role assignment we
use a weighting function that assigns scores to
each result and returns the one with the highest
score. For each identified role the weighting func-
tion adds one point if the role does not have any
selectional restrictions, and two points if there are
restrictions (including prepositional restrictions).
The total score for a solution is the sum of the
scores for each identified roles. The solution with
the highest score is selected.
For example, for the sentence
USAir bought Piedmont for 69 dlrs
cash per share.
the algorithm identifies two possible role as-
signments:
Agent[+animate OR +organization]
matching NP(The company)
Theme[] matching NP(the shares)
Asset[+currency] matching PP(for 69
dlrs cash per share)
with weightframe1 = 2 + 1 + 2 = 5 and the
second solution
Agent[+animate OR +organization]
matching NP(The company)
Theme[] matching the NP(the shares)
with weightframe5 = 2 + 1 = 3
Therefore, the algorithm returns the first set of
role assignments as a result.
211
4 Building conceptual graphs
The conceptual graph representation of the sen-
tence is built through the following steps: firstly,
for each of the constituents of the sentence we re-
cursively build a conceptual graph representation;
then we link all the conceptual graphs represent-
ing the constituents into a single graph; and fi-
nally, we resolve the unknown (generic) relations.
Each of these steps is described in more detail in
the following sub-sections.
4.1 Building a conceptual graph
representation of a phrase
The first step involves building a conceptual graph
for a phrase. Our general assumption is that
each lexeme in the sentence is represented us-
ing a separate concept, therefore all nouns, adjec-
tives, adverbs and pronouns are represented using
concepts, while the determiners and numbers are
used to specify the referent of the relevant concept
(thus further specifying the concept).
Below we illustrate the procedure for building
a conceptual graph for some of the most common
types of phrases.
 NP -> DT JJ NN
For phrases following this pattern we create
two concepts - one for the NNwith a concept
referent corresponding to the type of the de-
terminer DT, and another concept represent-
ing the adjective, and link both of them by
an Attribute relation. If the phrase contains
more than one adjective, each of them is rep-
resented by a separate concept and they are
all linked with Attribute relations to the con-
cept representing the noun.
 NP -> NP , SBAR ,
This pattern represents phrases where the
noun is further specified by the SBAR (for
example, The co-pilot, who was acting as
a main pilot, landed the plane.) For these
patterns a conceptual graph is built for the
SBAR and the head concept, if a WHNP
phrase (e.g. which or who), is replaced by
the concept created for the NP.
 PP -> IN NP
For such prepositional phrases we construct
a conceptual graph representing the noun
phrase. We also keep track of the preposition
heading the prepositional phrase, as it is used
to mark the relation between this phrase and
the other relevant phrases in the sentence.
4.2 Attaching all constituents to the verb
Once the graphs for each of the constituents are
constructed they are linked together in a single
conceptual graph. As each of them describes
some aspect of the concept represented by the
verb, we link them to that concept.
If the constituent already has an identified se-
mantic role during the previous phase, the same
relation is used when constructing the concep-
tual graph between the CG representing the con-
stituent and the verb. If the constituent does not
have any semantic roles identified, a relation with
a generic label is used, which allows us to build
the structure of the CG concentrating on the con-
cepts involved, and to resolve the generic labels
at a later stage. The generic labels used are ei-
ther REL, or in the case of prepositional phrases
headed with a proposition prep, REL prep (e.g.
REL on).
4.3 Resolving unknown relations
Finally we resolve some of the unknown (generic)
relations in the conceptual graph. We keep a data-
base of the most common syntactic realisation of
relations between concepts with specific types.
An example of a relation correction rule is:
Flight REL from City -> Flight Source City
where the left part of the rule represents the two
concepts linked by a generic relation and the right
side represents the graph after the modification.
All generic relations present after this step must
be manually resolved by the user. The system of-
fers help by suggesting possible relations intro-
duced by a preposition. For example, the preposi-
tion for can indicate Beneficiary (e.g. a book for
Mary), Duration (e.g. for three hours), etc.
5 Query representation
Representation of questions differs than represen-
tation of declarative sentences and deserves spe-
cial attention. For sentences representing ques-
tions we try to identify the statement that will
212
correspond to the question and then construct the
conceptual graph in a similar way as for declara-
tive sentences.
5.1 Yes/No questions
We process simple yes/no questions (questions
that require a yes/no answer) that are constructed
by a subject-verb inversion by applying a trans-
formation to reverse the question to a declarative
sentence.
5.2 Wh question
The parse tree of a sentence expressing a
wh question has the following general struc-
ture: SBARQ ->WH phrase SQ ? where the
WH phrase is either WHNP, WHADVP or WHPP
and represents the concept that triggers the query.
The SQ represents the rest of the sentence.
Similarly to yes/no questions, these type of
questions are also transformed to declarative sen-
tences. The wh word (e.g. who, what, where,
when) is represented by a generic concept. The
relation that attaches this concept to the verb de-
pends on the type of the wh phrase and can be one
of the following:
WHNP
These phrases are headed by the wh ques-
tion words who, what or which. The rela-
tion between the wh phrase and the verb is
either identified from applying a suitable se-
mantic frame for this verb, or it is a generic
one, REL.
WHADVP
These phrases represent an adverbial modi-
fier for time, place or location. If the phrase
marked as WHADVP is where the relation is
locative; if it is when, the relation is tempo-
ral; and if it is how, the relation is manner.
WHPP
Such phrases are not processed by our sys-
tem.
6 Experimental results
Each module of the system was evaluated sepa-
rately.
The first experiment we carried out was to es-
timate the accuracy of the sentence frame con-
structed by the role labelling module and it was
performed on randomly selected 2% of the verbs
in Reuters and 7% of the verbs in AAIU corpora.
The parse trees produced by Charniak?s parser
were manually edited to avoid any errors due to
incorrect parses. The results showed that the sys-
tem identified the correct set of possible candi-
dates for semantic roles for 90% and 89% of the
verbs in the Reuters and in the AAIU documents
respectively.
Further experiments were carried out to eval-
uate the performance of the role assigning mod-
ule. As a testbed we randomly selected 2% of
the verbs in Reuters and 15% of the verbs in
the AAIU documents. From these, we analysed
only those cases where the verb is a member of
at least one VerbNet frame and the possible role
candidates were correctly identified. For 60% and
70% of the remaining verbs, respectively, the al-
gorithm identifies a single correct solution. In
3% and 4% of the cases respectively a partially
correct result is found (in the majority of such
cases it is Agent, Patient and Theme roles that are
correctly identified, together with some incorrect
ones).
In 11% and 9% of the cases for Reuters and
AAIU, respectively, the algorithm identifies a set
of possible solutions, containing the correct and
several incorrect ones. For these cases the weight-
ing function identifies the correct solution in 38%
of the of the cases for AAIU documents and 59%
of the cases for the Reuters documents, while in
40% and 21% of the cases, respectively, it identi-
fies the correct and one or more incorrect results.
We also evaluated the percentage of the syntac-
tic patterns that the graph builder recognises: for
AAUI and Reuters documents, respectively, we
can build a graph for 76% and 67% of the noun
phrases, for 95% and 94% of the prepositional
phrases and for 91% and 97% of the subordinate
clauses.
7 Conclusions
In this paper we have described an approach
for constructing conceptual graphs for English
sentences, using VerbNet, WordNet and some
domain-specific knowledge. The achieved accu-
213
racy is strongly influenced by the lack of VerbNet
descriptions of many verbs present in both cor-
pora, as well as the lack of semantic frames for
the present verb sense. Also, as the approach is
not statistical, it does not require large amount of
training data.
There are several other lexical resources cur-
rently available that seem suitable for semantic
role identification, among them FrameNet and
PropBank. Our choice of VerbNet as a lexical re-
source is based on our belief that a set of domain-
independent descriptive role labels (such as those
defined in VerbNet) is more suitable as it allows
for generalisations.
A drawback of both FrameNet and PropBank
is that the roles do not include any selectional
restrictions, which makes it hard for a non-
statistical method to identify the correct filler for
each role. As shown earlier, the selectional re-
strictions defined for the semantic roles prove to
be a valuable asset when deciding if a phrase can
be a role filler. While we can resolve the majority
of them by analysing the syntactic structure or by
using the WordNet hierarchy, some are more dif-
ficult to resolve. For example, the restriction solid
describes an attribute or a state of an object, rela-
tions which cannot be checked by using WordNet.
FrameNet on the other hand defines usages not
only for verbs, but also for nouns. As one of the
causes for the relatively poor performance of the
conceptual graph building module is the lack of a
sufficient number of relation-correction rules, our
current approach to increasing their number is try-
ing to extract the rules from FrameNet.
Work on the system is ongoing and efforts
are continuing to implement a verb sense disam-
biguation component.
References
Air Accident Investigation Unit. 2004. Irish Air Acci-
dent Investigation Unit Reports. Available online:
(http://www.aaiu.ie/).
Eugene Charniak. 2000. A Maximum-Entropy-
Inspired Parser. In Proceedings of NAACL-2000,
pages 132?139.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, May.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
Labeling of Semantic Roles. Computational Lin-
guistics, 28(3):245?288.
Sanda Harabagiu and Steven Maiorano. 2000. Ac-
quisition of linguistic patterns for knowledge-based
information extraction. In Proceedings of LREC-
2000, Athens, June.
Jerry Hobbs, Douglas Appelt, John Bear, David Is-
rael, Megumi Kameyama, Mark Stickel, and Mabry
Tyson. 1996. FASTUS: A cascaded finite-state
transducer for extracting information from natural-
language text. In In Finite State Devices for Natural
Language Processing, Cambridge, MA. MIT Press.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-Based Construction of a Verb Lexicon.
In Proceedings of Seventeenth National Conference
on Artificial Intelligence (AAAI-2000), pages 691 ?
696, Austin, TX, July 30 - August 3.
Scott Miller, David Stallard, Robert Bobrow, and
Richard Schwartz. 1996. A fully statistical ap-
proach to natural language interfaces. In Proceed-
ings of the 34th Annual Meeting of the Association
for Computational Linguistics, pages 55?61, Santa
Cruz, June. Morgan Kaufmann Publishers, Inc.
Reuters. 1987. Reuters-21578 Text Cate-
gorization Collection. Available online:
(http://kdd.ics.uci.edu/databases/reuters21578/-
reuters21578.html).
Ellen Riloff and Mark Schmelzenbach. 1998. An Em-
pirical Approach to Conceptual Case Frame Acqui-
sition. In Proceedings of the Sixth Workshop on
Very Large Corpora.
Lei Shi and Rada Mihalcea. 2004. Open Text Parsing
Using FrameNet and WordNet. In Daniel Marcu
Susan Dumais and Salim Roukos, editors, Proceed-
ings of HLT-NAACL 2004: Demonstration Papers,
pages 247?250, Boston, Massachusetts, USA, May
2 ? May 7. Association for Computational Linguis-
tics.
John F. Sowa and Eileen C. Way. 1986. Imple-
menting a semantic interpreter using conceptual
graphs. IBM Journal of Research and Develop-
ment, 30(1):57?69, January.
John F. Sowa. 1984. Conceptual Structures: Infor-
mation Processing in Mind and Machine. Addison-
Wesley, Reading, M.
Paola Velardi, Maria Teresa Pazienza, and Mario De-
Giovanetti. 1988. Conceptual graphs for the analy-
sis and generation of sentences. IBM Journal of Re-
search and Development, 32(2):251?267,March.
214
