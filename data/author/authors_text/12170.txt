Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1446?1454,
Singapore, 6-7 August 2009.
c?2009 ACL and AFNLP
Construction of a Blog Emotion Corpus for Chinese Emotional
Expression Analysis
Changqin Quan
Faculty of Engineering
University of Tokushima
2-1 Minamijosanjima Tokushima Japan
quan-c@is.tokushima-u.ac.jp
Fuji Ren
Faculty of Engineering
University of Tokushima
2-1 Minamijosanjima Tokushima Japan
ren@is.tokushima-u.ac.jp
Abstract
There is plenty of evidence that emotion
analysis has many valuable applications.
In this study a blog emotion corpus is con-
structed for Chinese emotional expression
analysis. This corpus contains manual an-
notation of eight emotional categories (ex-
pect, joy, love, surprise, anxiety, sorrow,
angry and hate), emotion intensity, emo-
tion holder/target, emotional word/phrase,
degree word, negative word, conjunction,
rhetoric, punctuation and other linguistic
expressions that indicate emotion. An-
notation agreement analyses for emotion
classes and emotional words and phrases
are described. Then, using this corpus,
we explore emotion expressions in Chi-
nese and present the analyses on them.
1 Introduction
Textual emotion analysis is becoming increasingly
important due to augmented communication via
computer mediated communication (CMC) inter-
net sources such as weblogs, email, websites, fo-
rums, and chat rooms. Especially, blogspace con-
sists of millions of users who maintain an online
diary, containing frequently-updated views and
personal remarks about a range of issues.
Despite the increased focus on analysis of web
content, there has been limited emotion analy-
sis of web contents, with the majority of studies
focusing on sentiment analysis or opinion min-
ing. Classifying the mood of a single text is a
hard task; state-of-the-art methods in text classi-
fication achieve only modest performance in this
domain (Mishne, 2005). In this area, some of
the hardest problems involve acquiring basic re-
sources. Corpora are fundamental both for devel-
oping sound conceptual analyses and for training
these emotion-oriented systems at different lev-
els: to recognize emotions, to express appropriate
emotions, to anticipate emotions, and other emo-
tion processing applications.
In this study we propose a relatively fine-
grained annotation scheme, annotating emotion in
text at three levels: document, paragraph, and sen-
tence. We select eight emotion classes (expect,
joy, love, surprise, anxiety, sorrow, angry and hate)
for this annotation, and explore various linguis-
tic expressions that indicate emotion in Chinese.
The annotation scheme has been employed in the
manual annotation of a corpus containing 1,487
documents, with 11,255 paragraphs, 35,096 sen-
tences, and 878,164 Chinese words. Then, using
this corpus, we explore and present data analy-
ses on emotions, involving emotion states, accom-
panying emotions, transfer emotions, independent
emotions in texts.
The remainder of this paper is organized as fol-
lows. Section 2 describes the emotion corpus an-
notation scheme. Section 3 presents the inter-
annotator agreement study. Section 4 describes
the analysis of emotion expressions. Section 5
presents a review of current emotion corpora for
textual emotion analysis. Section 6 concludes this
study with closing remarks and future directions.
2 Blog Emotion Corpus Annotation
Scheme
Weblogs are an increasingly popular mode of
communication in the ever changing online world.
Writing suits the recording of facts and the com-
munication of ideas, and their textual basis makes
them equally suitable for recording emotions and
opinions. So, we select blogs as object and data
source for this emotion corpus annotation.
2.1 Emotional Expression in Text
An important starting point in constructing this
corpus is to represent emotion in text. One of the
biggest questions in affect recognition is, ?What
1446
are the couplings between affective states and their
patterns of expressions? (Picard, 1997).
In this study we propose an emotional expres-
sion space model to represent emotion in text,
which is hierarchical in consistent with the natural
structure of a document. Emotion of a document
is represented by a vector
??
d =< e
1
, e
2
, ..., e
i
, ..., e
n
> (1)
Here, e
i
is a basic emotion class contained in doc-
ument d. The values of e
i
range from 0.0 to 1.0
(discrete), indicating the intensities of the basic
emotion classes. Similar to a document, emotion
of each paragraph and each sentence in a docu-
ment is represented by an emotion vector.
Basic emotions may be defined in many ways.
To decrease confusions on emotion categories? se-
lection and to contain the most common emotion
classes in blogs, we select eight emotion classes
(expect, joy, love, surprise, anxiety, sorrow, angry
and hate) for this manual annotation, and they are
agreed by eleven annotators through a testing an-
notation period. Table 1 shows the numbers of the
eight emotion classes in documents, paragraphs,
and sentences in this corpus.
Emotions Doc Para Sen
Expect 656 2,145 4,588
Joy 565 2,740 6,211
Love 911 4,991 11,866
Surprise 124 503 1,118
Anxiety 732 4,128 10,115
Sorrow 693 3643 8,166
Angry 189 900 2,221
Hate 335 1,589 3,555
Sum 4,205 20,639 47,840
Table 1: Num. of the eight emotion classes
As shown in Table 1, we have reasonably large
counts for all 8 emotions in all 3 units of text. And
we also can get the average value for the numbers
of emotion classes in each document, each para-
graph and each sentence; they are 2.83, 1.84, and
1.36 respectively.
2.2 The Multi-level Annotation Frame
The annotation frame includes 3 levels: docu-
ment, paragraph, and sentence. Sentence level
is the basic level for emotion annotation; the an-
notation includes intensities of the eight basic
emotion classes, emotion holder/target, emotional
words/phrases, rhetoric, emotional punctuations,
emotion objective/subjective and emotion polarity.
Paragraph level is the upper level of sentence level;
the annotation includes intensities of the eight ba-
sic emotion classes, topic words to reflect the topic
of a paragraph, and the number of topic sentence
that can express the main points of this paragraph.
Document level is the uppermost level; its anno-
tation is similar to paragraph level. The tokenized
text files are organized into XML documents. An
example document is listed in Figure 1.
Figure 1: An annotated document in XML format
1447
2.3 Sentence Level Annotation
Sentences are basic units for emotional expres-
sion. The central aim of sentence level annotation
is to explore as much linguistic expressions for re-
flecting emotion in Chinese as possible.
a) Emotion holder/target
In the task of opinion analysis, the problem of
opinion holder identification has also been stud-
ied, (Bethard, Steven et al, 2004; Choi, Cardie,
et al, 2005; Kim and Hovy, 2005). As for emo-
tion holder/target identification, little research has
been conducted, but we believe it is important for
exploring emotional expression and emotion anal-
ysis. Emotion holder is the one who holds the
emotions, and an emotion target is the object of
an emotion holder. For instance,
(1) ????????(English: I like this
teacher.) In sentence (1),?? (English: I)? is the
emotion holder, and ?????(English: this
teacher.)? is the emotion target.
In this corpus, not every sentence is annotated
with emotion holder or emotion target, and emo-
tion holder or emotion target may not appear in
pairs in one sentence. If one sentence has more
than one emotion holders or emotion targets, they
are all annotated.
b) Emotional words and phrases
Lexicon-based methods have received a lot of
attention in opinion analysis task. There are many
lexical resources for these tasks. For emotion anal-
ysis tasks, the function of words is equally funda-
mental. In most sentimental lexicons, the words
usually bear direct emotions or opinions, such as
happy or sad, good or bad. However, there are a
lot of sentences can evoke emotions without direct
emotional words, for example,
(2) ????????????????
??(English: Spring is in children?s eyes, and in
their hearts.)
In sentence (2), we may feel joy, love or ex-
pect delivered by the writer. Indeed, as (Ortony,
Andrew, et al, 1987) indicates, besides words di-
rectly referring to emotional states and for which
an appropriate lexicon would help, there are words
that act only as an indirect reference to emotions
depending on the context.
In this annotation scheme, direct emotional
words and indirect emotional words in a sen-
tence are all annotated. In sentence (2), ?
??(English: spring)?, ????(English: chil-
dren)? are labeled. An emotional word or phrase
is represented as a vector to record its intensi-
ties of the eight basic emotional classes. For in-
stance, the vector for the word ???(English:
like)?
??
w = (0.0, 0.3, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0)
indicates the emotions of weak joy and strong
love. For indirect emotional words, we anno-
tate their emotion vectors according to their con-
texts, for example, the possible emotion vec-
tor for the word ???(English: spring)? ??w =
(0.1, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0) indicates the
emotions of weak expect, joy and love. (The emo-
tions and intensity values may be different because
of different annotators).
Emotional phrases are combination of words,
such as Chinese proverbs, like ???????
?????(English: Where there is a will, there
is a way) ?. For an emotional phrase, the positions
of its first and character in a sentence are labeled,
and also for emotional words if there are Chinese
word segmentation mistakes.
The statistics show that 84.9% of all emotional
words have one emotion, and 14.7% have two
emotions, only 0.4% have three or four emotions,
but they are indispensable for expressing complex
feelings in use of language.
Table 2 shows the numbers of emotional words
with different POS (part-of-speech) tags. The set
of POS includes 35 classes; Table 2 lists the top
five classes.
POS
Num. of words
(have repeat)
Verb 37,572
Noun 21,308
Adj. 20,265
Adv. 4,223
Gerund 2,789
Table 2: Emotional words with different POS
As shown in Table 2, verbs, nouns, adjectives
and adverbs are strong markers of emotion in Chi-
nese.
c) Degree words, negative words, conjunc-
tions
Degree words are associated with the intensi-
ties of emotions. In Chinese, degree words ap-
pear with high frequency. In this corpus, there
are 1,039 different degree words annotated, the to-
tal occurring number of them is 16,713, in which,
8,294 degree words modify emotional words or
phrases directly. Degree words and the modifying
1448
contents are all labeled.
Negative words can be placed almost every-
where in a sentence to change the meaning, also
to change the emotions. Negative words are fre-
quently used in Chinese. The statistical data shows
that there are 645 different negative words anno-
tated in this corpus, the total occurring number of
them is 13,750, in which, 3,668 negative words
modify emotional words or phrases directly.
Besides, conjunctions may change the emotion
of a sentence. for example,
(3)?????????????????
????(Jin guan wo men xi huan zhe ge lao shi,
dan ta yi jing li kai le wo men; English: Although
we like this teacher, she has leaved.)
Sentence (3) uses the conjunctions ??
?...?...(jin guan...dan..., English: although)?
express emotions of love and sorrow. There
are 297 different conjunctions annotated in this
corpus. Conjunctions and the modifying contents
are all labeled. If conjunctions appear in pairs
in a sentence, the position of pairing words
for each conjunction are also labeled. For the
above sentence (3), conjunctions are annotated as
follows (Figure. 2).
Figure 2: An example of conjunctions annotation
Figure 3 shows the growth curve of word num-
ber with document number from 300 to 1487. As
can be seen from Figure 3, the increase numbers of
emotional words/phrases slow down with the in-
crease in the number of documents, and the num-
bers of negative words, degree words and conjunc-
tions basically remained stable. We can look for-
ward to containing most of common emotional ex-
pressions in weblogs articles.
d) Rhetorics, punctuations
Chinese rhetoric has been well studied from
the view of linguistics and literature. We se-
lect nine common rhetoric categories to anno-
tate: ??(English: metaphor), English: ?
?(exaggeration), ? ?(English: personifica-
tion), ??(English: antithesis or parallel), ?
Figure 3: Growth curve of word number
?(English: parallelism sentence), ??(English:
rhetorical question with answer), ??(English:
rhetorical question), ??(English: repeat), ?
?(English: irony). Especially, ??(English:
irony) is a way as to imply the contrary of what one
says, if a sentence is annotated with irony, its emo-
tions maybe totally different from the emotions of
words that it contains. We annotate rhetoric cate-
gory and the corresponding emotion category.
Punctuation is the use of standard marks and
signs in writing to separate words into sentences,
clauses, and phrases in order to clarify meaning.
Some punctuation marks can express emotions,
for example, an exclamation mark (!) or a question
mark (?) is used at the end of a sentence to show
strong emotion. Balog, Mishne, et al (2006) sug-
gests that people relied on four strategies includ-
ing punctuation to express happiness versus sad-
ness. Punctuation effect is also shown in (Leshed
and Kaye, 2006) to extend to emoticon placement
in website text messages. We annotate punctua-
tion with emotion and the corresponding emotion
category.
e) Emotion objective/subjective, emotion po-
larity
Distinguishing a sentence between factual and
subjective information could support for many
natural language processing applications. Objec-
tive and subjective in our annotation scheme is to
distinguish a sentence between writer?s emotion
and non-writer?s emotion.
There is a positive side or a negative side on
emotion. We call this an emotional polarity. Emo-
tion polarity of a sentence is determined by inte-
grating its emotions. A sentence without emotion
is annotated with neutral.
An annotation tool is developed for this corpus
1449
annotation. Input files are text files with Chinese
segmentation and part-of-speech tags, the anno-
tated output files are XML files.
3 Annotation Agreement analysis
Emotion annotation is a hard task because the na-
ture of emotion is inherently ambiguous. In the
process of annotation, annotators were encouraged
to follow their ?first intuition?. To measure agree-
ment on various aspects of the annotation scheme,
three annotators independently annotated 26 doc-
uments with a total of 270 paragraphs, 701 sen-
tences.
3.1 Agreement for Emotion Classes
The kappa coefficient of agreement is a statistic
adopted by the Computational Linguistics com-
munity as a standard measure for this purpose
(Carletta, 1996). We measured two agreements for
emotion classes? annotation:
Agreement (a): the agreement on classifi-
cation of containing or not containing some
emotions. In this case, we distinguish two
classes: emotion intensity e
i
? {0.0} or e
i
?
{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0};
Agreement (b): the agreement on classifica-
tion of emotion intensity. In this case, we dis-
tinguish four classes: e
i
? {0.0} or e
i
?
{0.1, 0.2, 0.3, 0.4}, or e
i
? {0.5, 0.6, 0.7}, or e
i
?
{0.8, 0.9, 1.0}.
Table 3 shows Agreement (a) and (b) measure
on documents, paragraphs and sentences.
Agreement(a) Agreement(b)
documents 0.831 0.695
paragraphs 0.705 0.616
sentences 0.756 0.648
Average 0.764 0.653
Table 3: Agreement on emotion classes
As shown in Table 3, it is easier for annotators
to agree at the coarser levels of granularity, and it
is more difficult to agree on the level of emotion
intensity.
3.2 Agreement for Emotional Words and
Phrases
Measuring agreement for emotional words and
phrases is to verify that annotators agree on which
expressions should be marked. To illustrate this
agreement problem, consider the emotional words
and phrases identified by annotators a and b. This
sentence was preprocessed by Chinese segmenta-
tion and tagged with part-of-speech.
(4) ??/t ?/w ?/d ?/v ??/n ?/u ??/n
??/v ??/n ?/Ng ?/w ??/v ??/ad ?
?/v?/v??/m??/d?/u??/a??/n?/w
?/r ?/d ?/v ?/w ????/n ?/w ??/n ?
?/z?(English: This morning, when I walked to
the meeting with sunshine, some wonderful words
that have not been used for many years crossed my
mind, which are ?the autumn sky is clear, the air
is crisp? and ?shinning with gold color?)
a: ??,??,????,??,??;
b: ??,??,??,????,??;
In sentence (4), the two annotators agree that
????, ????, ?????? and ???? can ex-
press emotion. In addition, annotator a marked the
word ????, and annotator b marked the word
????.
In this task, there is no guarantee that the an-
notators will identify the same set of expressions.
Thus, to measure agreement we want to consider
how much intersection there is between the sets
of expressions identified by the annotators. We
use the following voting-agreement metric to mea-
sure agreement in identifying emotional words
and phrases.
Metric voting-agreement is defined as follows.
Let A, B and C be the sets of expressions anno-
tated by annotators a, b and c respectively. The
expert coder is the set of expressions that agreed
by at least two annotators, see Equation 2.
voting agreement = Avg(
count(t
i
= e
j
)
count((t
i
)
)
(2)
In which, t
i
? T, e
j
? E, T = A
?
B
?
C,
E = (A
?
B)
?
(A
?
C)
?
(B
?
C).
The agreement for emotional words and phrases
is 0.785.
4 Emotional Expressions Analysis
4.1 Emotion State
?Emotion state in text? is the state of combined
emotions in a text unit. An emotion state is repre-
sented by 8 binary digits, each digit corresponding
to a basic emotion class respectively. As an exam-
ple, a document emotion state ?01100000? is the
state of combined emotions by joy and love.
The statistics show that, in this corpus, there
are 149 different emotion states in all of the 1,487
1450
documents, 165 different emotion states in all of
the 11,255 paragraphs, and 143 different emotion
states in all of the 35,096 sentences respectively.
That indicates the set of emotion state in texts is
relatively small. We also found some basic emo-
tions tend to combine together, such as {expect,
joy, love}, {anxiety, sorrow}, {angry, hate}. How-
ever, some emotions have small or scarce possibil-
ity appear together, such as joy and hate, surprise
and angry.
4.2 Accompanying Emotions
In an emotion state, some basic emotions are
mixed together. When an emotion e
j
arise, emo-
tion e
i
(i 6= j) arise with accompany, then, e
i
is
an accompanying emotion of e
j
. To compute the
probability of the accompanying emotion given an
emotion e
j
, we count the cooccurrence of e
i
and
e
j
in a text unit (a document, a paragraph, or a
sentence).
P (e
i
|e
j
) =
count(e
i
with e
j
)
count(e
j
)
(3)
Table 4 shows the accompanying emotions with
the highest probabilities for the eight basic emo-
tions in documents, paragraphs and sentences.
Emotions Docs Paras Sens
Expect Love Love Love
Joy Love Love Love
Love Joy Joy Joy
Surprise Anxiety Love Love
Anxiety Sorrow Sorrow Sorrow
Sorrow Anxiety Anxiety Anxiety
Angry Anxiety Hate Hate
Hate Anxiety Sorrow Angry
Table 4: Accompanying emotions
In Table 4, the accompanying emotions has
shown a high uniformity in the 3 units of text.
4.3 Transfer Emotions
When emotion change from one emotion class to
another one, we call this emotion transfer. Using
the context relation of paragraphs and sentences,
we compute the probability P (e
i
? e
j
).
P (e
i
? e
j
) =
count(e
t
= e
i
, e
t+1
= e
j
)
count(e
t
= e
i
)
(4)
In which, e
t
is an emotion class in paragraph t
(or sentence t), and e
t+1
is another emotion class
in paragraph t + 1 (or sentence t + 1). Table 4
shows the transfer emotions with the highest prob-
abilities for the eight basic emotions in paragraphs
and sentences.
Emotions Paras Sens
Expect Love Expect
Joy Love Love
Love Love Love
Surprise Love Love
Anxiety Anxiety Anxiety
Sorrow Sorrow Sorrow
Angry Anxiety Angry
Hate Hate Hate
Table 5: Transfer emotions
Similar to this, we can compute the probability
of emotion state transfer P (e state
i
? e state
j
).
This may help a lot for emotion prediction, for
example, if we know the current emotion state is
?00000110? (sorrow an angry), we can estimate
the probability of this emotion state to another
emotion state ?00000001? (hate).
4.4 Independent Emotion
When a text unit (a document, a paragraph, or
a sentence) only contains one emotion class, this
emotion class is an independent emotion. The
statistics show that emotion of love has high in-
dependence, however, joy, surprise and angry has
relative low independence. The intuition is love
can be the only topic emotion in a text unit, but
emotions of joy, surprise and anxiety more incline
to combine with other emotions.
5 Related work
Previous approaches to textual emotion analysis
have employed some different corpora. Mishne
(2005) experimented mood classification in blog
posts on a corpus of 815,494 blog posts from Live-
journal (http://www.livejournal.com), a free we-
blog service with a large community. Livejour-
nal also used as data source for finding happi-
ness (Mihalcea and Liu, 2006), capturing global
mood levels (Mishne and De Rijke, 2006), clas-
sifying mood (Jung, Park, et al, 2006; Jung,
Choi, et al, 2007), discovering mood irregu-
larities (Balog, Mishne, et al, 2006), recogniz-
ing affect (Leshed and Kaye, 2006). A similar
emotion corpus in Chinese is Yahoo!?s Chinese
news (http://tw.news.yahoo.com), which is used
1451
for Chinese emotion classification of news read-
ers (Lin, Yang, et al, 2007) and emotion lexi-
con building (Yang, Lin, et al, 2007). Tokuhima
(2008) also use web as data resources to obtain
a huge collection of emotion-provoking event in-
stances for Japanese emotion classification. More
and more weblogs have added mood column to
record blog users? moods when they read or write
a blog.
Two merits let them well accepted as emotion
corpora: a large number of weblogs contained and
moods annotated by blog users. However, there is
a great inconsistency on emotion categories given
by different websites. Livejournal gives a pre-
defined list of 132 common moods, while Ya-
hoo!?s Chinese news provides readers 8 emotion
categories. Too many mood classes may confuse
users, and Mishne (2005) also pointed out one ob-
vious drawback of the mood ?annotation? in this
corpora is that they are not provided in a consistent
manner; the blog writers differ greatly from each
other, and their definitions of moods differ accord-
ingly. In addition, some words are not fitted to be
taken as emotion classes, such as ?useful? in Ya-
hoo!?s emotion categories. These corpora may be
helpful for analyzing the global moods on a full
text, but the inconsistent emotion categories is a
problem, and no more labeled information can be
exploited from them.
The emotion analysis on sentence level may
also be important for more detailed emotion anal-
ysis systems. Alm, Roth, et al (2005) ex-
plore the text-based emotion prediction problem;
they annotated a corpus of 22 Grimms?tales on
sentence level with eight emotion categories (an-
gry, disgusted, fearful, happy, sad, positively sur-
prised, negatively surprised), contain 1580 sen-
tences. Neviarouskaya, Prendinger et al (2007)
address the tasks of recognition and interpreta-
tion of affect communicated through text messag-
ing. They collected 160 sentences labeled with
one of nine emotions categories (anger, disgust,
fear, guilt, interest, joy, sadness, shame, and sur-
prise) from a corpus of online diary-like blog
posts and a corresponding intensity value. Aman
and Szpakowicz (2007) classify emotional and
non-emotional sentences based on a knowledge-
based approach. They used a corpus with tags
of emotion category, emotion intensity and the
words/phrases that indicate emotion in text. An
emotion corpus for Japanese was built for rec-
ognizing emotions and emotion estimation (Ren,
2009; Matsumoto, 2006). However, the sizes of
these corpora seem not enough for large scale tex-
tual emotion analysis, a lot of linguistic features
are not reflected from them. A more fine-grained
opinion and emotion corpus is the MPQA Corpus
(Wiebe, Wilson, et al, 2005), which contains 535
news articles (10,000-sentence) from a wide va-
riety of news sources, manually annotated at the
sentential and subsentential level for opinions and
other private states. But emotion categories are not
included in it.
To the best of our knowledge, at present, there?s
no relatively large corpora annotated with detailed
linguistic expressions for emotion in Chinese, and
we believe that such corpora would support the de-
velopment and evaluation of emotion analysis sys-
tems.
6 Conclusions and Future Work
In this study we proposed an emotional expres-
sion space model. Emotion of a document, a para-
graph, a sentence, or even a word is represented
by an emotional vector. Based on this model,
we described a relatively fine-grained annotation
scheme and annotated emotion in text. We also
gave the inter-annotator agreement study on an-
notation. Then, we explore the emotional expres-
sions in texts.
This annotated dataset can be obtained for free
with license
1
. Eleven annotators made efforts
on it spanning a period of ten months (They are
Ph.D and M.S. candidates specialize in Natural
Language Processing and Emotion Analysis). To
ensure the quality of this dataset, each document
was performed a three pass annotation, in which
the first pass is annotated by one annotator and
then the second and the third verification pass were
performed by other two annotators. The process
of this corpus annotation is easy to make mistakes
because of a lot of information should be anno-
tated. The verification pass is to check the an-
notation mistakes (such as the start and end po-
sitions of emotional phrases in sentences), but not
to change the choices of emotion classes or emo-
tional words which had been annotated by other
annotators.
Using this corpus, we will make a more exten-
sive study of textual emotion analysis in Chinese,
1
http://a1-www.is.tokushima-u.ac.jp/member/ren/Ren-
CECps1.0/Ren-CECps1.0.html
1452
for example, the influence of degree words, nega-
tive words, or other elements on emotional expres-
sion; the difference between subjective emotion
and objective emotion; emotion transfer tracking.
More applications also will be explored, such as
emotional summarization, emotional question an-
swering; emotional topic discovering. At the same
time, new research problems will arise, for exam-
ples, how to acquiring more emotional words and
to generate their emotional vectors automatically;
how to generate emotional vectors for sentences,
paragraphs and documents with known emotional
elements in them? There is need to immerge fur-
ther into these problems.
Acknowledgments
We are grateful to our annotators: Huana Li,
Ye Wu, Lei Chen, Yu Zhang, Ji Li, Ziliang Du,
Yuanlu Fu, Rong Mu, Yan Sun, Cheng Wang,
Yunong Wu, and other participants and support-
ers. We are also grateful to Dr. Suzuki and Dr.
Matsumoto for the helpful advice. This research
has been partially supported by Ministry of Edu-
cation, Science, Sprots and Culture, Grant-in-Aid
for Challenging Exploratory Research, 21650030.
References
Alena Neviarouskaya, Helmut Prendinger, Mitsuru
Ishizuka. 2007. Textual Affect Sensing for Social
and Expressive Online Communication. Proceed-
ings of the 2nd international conference on Affective
Computing and Intelligent Interaction, pp. 218-229.
Bethard, Steven, Hong Yu, Ashley Thornton, Vasileios
Hatzivassiloglou, and Dan Jurafsky. 2004. Auto-
matic Extraction of Opinion Propositions and their
Holders. AAAI Spring Symposium on Exploring At-
titude and Affect in Text: Theories and Applications
, pp. 133?136.
Changhua Yang, Kevin Hsin-Yih Lin, Hsin-Hsi Chen.
2007. Building Emotion Lexicon from Weblog Cor-
pora. Proceedings of the ACL 2007 Demo and Poster
Sessions, pp. 133?136.
Cecilia Ovesdotter Alm, Dan Roth, Richard Sproat.
2005. Emotions from text: Machine learning for
text-based emotion prediction. Proceedings of Hu-
man Language Technology Conference and Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pp. 579-586, Vancouver, British
Columbia, Canada.
Fuji Ren. 2009. Affective Information Processing and
Recognizing Human Emotion. Electronic Notes in
Theoretical Computer Science, 225: 39-50.
Gilad Mishne. 2005. Emotions from text: Machine
learning for text-based emotion prediction. Proceed-
ings of Style2005 in SIGIR?05, pp. 15-19.
Gilad Mishne and Maarten de Rijke. 2006. Captur-
ing global mood levels using blog posts. AAAI 2006
Spring Symposium on Computational Approaches to
Analysing Weblogs, pp.145-152.
Gilly Leshed and Joseph Kaye. 2006. Understanding
how bloggers feel: recognizing affect in blog posts.
Conference on Human Factors in Computing Sys-
tems CHI ?06 extended abstracts on Human factors
in computing systems, pp. 1019- 1024.
Janyce Wiebe, Theresa Wilson, Claire Cardie. 2005.
Annotating expressions of opinions and emotions in
language. Language Resources and Evaluation. 39:
164?210.
Jean Carletta. 1996. Assessing Agreement on Classi-
fication Tasks: The Kappa Statistic. Computational
Linguistics. 22(2):249-254.
Kazuyuki Matsumoto, Fuji Ren, Shingo Kuroiwa.
2006. Emotion Estimation System based on Emo-
tion Occurrence Sentence Pattern. Computational
Intelligence, Lecture Notes in Computer Sciences,
pp.902-911.
Kevin Hsin-Yih Lin, Changhua Yang, Hsin-Hsi Chen.
2007. What emotions do news articles trigger in their
readers? Annual ACM Conference on Research and
Development in Information Retrieval, pp. 733- 734.
Krisztian Balog. Gilad Mishne. Maarten de Rijke.
2006. Why are they excited? identifying and ex-
plaining spikes in blog mood levels. Proceedings
11th Meeting of the European Chapter of the Asso-
ciation for Computational Linguistics, pp. 207-210.
Ortony, Andrew, Gerald L. Clore, and Mark A. Foss.
1987. The referential structure of the affective lexi-
con. Cognitive Science, 11: 341-364.
Rada Mihalcea and Hugo Liu. 2006. A corpus-based
approach to finding happiness. Proceedings of the
AAAI Spring Symposium on Computational, pp.
139-144.
Rosalind Picard. 1997. Affective Computing. The MIT
Press, MA, USA.
Ryoko Tokuhisa, Kentaro. Inui, and Yuji. Matsumoto.
2008. Emotion Classification Using Massive Exam-
ples Extracted from the Web. Proceedings of COL-
ING 2008, pp. 881-888.
Saima Aman and Stan Szpakowicz. 2007. Identifying
Expressions of Emotion in Text. Lecture Notes in
Computer Science. 4629: 196-205.
Soo-Min Kim and Eduard Hovy. 2005. Identifying
Opinion Holders for Question Answering in Opinion
Texts. Proceedings of AAAI-05 Workshop on Ques-
tion Answering in Restricted Domains, pp. 1367-
1373.
1453
Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth
Patwardhan. 2005. Identifying Sources of Opinions
with ConditionalRandom Fields and Extraction Pat-
terns. Proceedings of HLT/EMNLP-05, pp. 355-362.
Yuchul Jung, Hogun Park, Sung Hyon Myaeng. 2006.
A Hybrid Mood Classification Approach for Blog
Text. Lecture Notes in Computer Science, pp.1099-
1103.
Yuchul Jung, Yoonjung Choi, Sung-Hyon Myaeng.
2007. Determining Mood for a Blog by Combin-
ing Multiple Sources of Evidence. IEEE/WIC/ACM
International Conference on Web Intelligence, pp.
271-274.
1454
Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 54?62,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
Accurate Learning for Chinese Function Tags from Minimal Features
Caixia Yuan
1,2
, Fuji Ren
1,2
and Xiaojie Wang
2
1
The University of Tokushima, Tokushima, Japan
2
Beijing University of Posts and Telecommunications, Beijing, China
{yuancai,ren}@is.tokushima-u.ac.jp
xjwang@bupt.edu.cn
Abstract
Data-driven function tag assignment has
been studied for English using Penn Tree-
bank data. In this paper, we address
the question of whether such method can
be applied to other languages and Tree-
bank resources. In addition to simply
extend previous method from English to
Chinese, we also proposed an effective
way to recognize function tags directly
from lexical information, which is eas-
ily scalable for languages that lack suf-
ficient parsing resources or have inher-
ent linguistic challenges for parsing. We
investigated a supervised sequence learn-
ing method to automatically recognize
function tags, which achieves an F-score
of 0.938 on gold-standard POS (Part-of-
Speech) tagged Chinese text ? a statisti-
cally significant improvement over exist-
ing Chinese function label assignment sys-
tems. Results show that a small number
of linguistically motivated lexical features
are sufficient to achieve comparable per-
formance to systems using sophisticated
parse trees.
1 Introduction
Function tags, such as subject, object, time, loca-
tion, etc. are conceptually appealing by encoding
an event in the format of ?who did what to whom,
where, when?, which provides useful semantic in-
formation of the sentences. Lexical semantic re-
sources such as Penn Treebank (Marcus et al,
1994) have been annotated with phrase tree struc-
tures and function tags. Figure 1 shows the parse
tree with function tags for a sample sentence form
the Penn Chinese Treebank 5.0
1
(Xue et al, 2000)
(file 0043.fid).
1
released by Linguistic Data Consortium (LDC) catalog
NO. LDC2005T01
Figure 1: Simplified parse tree with function tags
(in black bold) for example sentence.
When dealing with the task of function tag
assignment (or function labeling thereafter), one
basic question that must be addressed is what
features can be extracted in practice for distin-
guishing different function tag types. In answer-
ing this question, several pieces of work (Blaheta
and Charniak, 2000; Blaheta, 2004; Merlo and
Musillo, 2005; Gildea and Palmer, 2002) have
already been proposed. (Blaheta and Charniak,
2000; Blaheta, 2004) described a statistical sys-
tem trained on the data of Penn Treebank to au-
tomatically assign function tags for English text.
The system first passed sentences through an au-
tomatic parser, then extracted features from the
parse trees and predicted the most plausible func-
tion label of constituent from these features. Not-
ing that parsing errors are difficult or even impos-
sible to recover at function tag recognition stage,
the alternative approaches are obtained by assign-
ing function tags at the same time as producing
parse trees (Merlo and Musillo, 2005), through
learning deeper syntactic properties such as finer-
grained labels, features from the nodes to the left
of the current node.
Through all that research, however, success-
fully addressing function labeling requires accu-
rate parsing model and training data, and the re-
54
sults of them show that the performance ceil-
ing of function labeling is limited by the parsers
they used. Given the imperfection of existing
automatic parsers, which are far from producing
gold-standard results, function tags output by such
models cannot be satisfactory for practical use.
The limitation is even more pertinent for the lan-
guages that do not have sophisticated parsing re-
sources, or languages that have inherent linguistic
challenges for parsing (like Chinese). It is there-
fore worthwhile to investigate alternatives to func-
tion labeling for languages under the parsing bot-
tleneck, both in terms of features used and effec-
tive learning algorithms.
In current study, we focused on the use of
parser-independent features for function labeling.
Specifically, our proposal is to classify function
types directly from lexical features like words and
their POS tags and the surface sentence informa-
tion like the word position. The hypothesis that
underlies our proposal is that lexical features are
informative for different function types, and cap-
ture fundamental properties of the semantics that
sometimes can not be concluded from the glance
of parse structure. Such cases come when distin-
guishing phrases of the same structure that differ
by just one word ? for instance, telling ?3??
(in Shanghai)?, which is locative, from ?3?
(in May)?, which is temporal.
At a high level, we can say that class-based dif-
ferences in function labels are reflected in statistics
over the lexical features in large-scale annotated
corpus, and that such knowledge can be encoded
by learning algorithms. By exploiting lexical in-
formation collected from Penn Chinese Treebank
(CTB) (Xue et al, 2000), we investigate a super-
vised sequence learning model to test our core hy-
pothesis ? that function tags could be guessed pre-
cisely through informative lexical features and ef-
fective learning methods. At the end of this pa-
per, we extend previous function labeling meth-
ods from English to Chinese. The result proves, at
least for Chinese language, our proposed method
outperforms previous ones that utilize sophisti-
cated parse trees.
In section 2 we will introduce the CTB re-
sources and function tags used in our study. In
section 3, we will describe the sequence learn-
ing algorithm in the framework of maximum mar-
gin learning, showing how to approximate func-
tion tagging by simple lexical statistics. Section 4
Table 1: Complete set of function labels in Chi-
nese Treebank and function labels used in our sys-
tem (selected labels).
type labels in CTB selected labels
clause types IMP imperative
Q question
(function/form)
ADV adverbial
?
discrepancies
grammatical roles EXT extent
?
FOC focus
?
IO indirect object
?
OBJ direct object
?
PRD predicate
?
SBJ subject
?
TPC topic
?
adverbials BNF beneficiary
?
CND condition
?
DIR direction
?
IJ interjective
?
LGS logic subject
?
LOC locative
?
MNR manner
?
PRP purpose/reason
?
TMP temporal
?
VOC vocative
?
miscellaneous APP appositive
HLN headline
PN proper names
SHORT short form
TTL title
WH wh-phrase
gives a detailed discussion of our experiment and
comparison with pieces of related work. Some fi-
nal remarks will be given in Section 5.
2 Chinese Function Tags
The label such as subject, object, time, location,
etc. are named as function tags
2
in Penn Chi-
nese Treebank (Xue et al, 2000), a complete list
of which is shown in Table 1. Among the 5 cat-
egories, grammatical roles such as SBJ, OBJ are
useful in recovering predicate-argument structure,
while adverbials are actually semantically oriented
labels (though not true for all cases, see (Merlo
and Palmer, 2006)) that carry semantic role infor-
mation.
As for the task of function parsing, it is reason-
able to ignore the IMP and Q in Table 1 since they
do not form natural syntactic or semantic classes.
In addition, we regard the miscellaneous labels as
an ?O? label (out of any function chunks) like la-
beling constituents that do not bear any function
2
The annotation guidelines of Penn Chinese Treebank talk
of function tags. We will use the term function labels and
function tags identically, and hence make no distinction be-
tween function labeling and function tagging throughout this
paper. Also, the term function chunk signifies a sequence of
words that are decorated with the same function label.
55
tags. Punctuation marks like comma, semi-colon
and period that separate sentences are also denoted
as ?O?. But the punctuation that appear within one
sentence like double quotes are denoted with the
same function labels with the content they quote.
In the annotation guidelines of CTB (Xue et al,
2000), the function tag ?PRD? is assigned to non-
verbal predicate. Since VP (verb phrase) is always
predicate, ?PRD? is assumed and no function tag
is attached to it. We make a slight modification to
such standard by calling this kind of VP ?verbal
predicates?, and assigning them with function la-
bel ?TAR (target verb)?, which is grouped into the
same grammar roles type with ?PRD?.
To a large extent, PP (preposition phrase) al-
ways plays a functional role in sentence, like ?PP-
MNR? in Figure 1. But there are many such PPs
bare of any function type in CTB resources. Like
in the sentence ?'c??O 25% (increase
by 25% over the same period of last year)?, ?'
c?? (over the same period of last year)? is la-
beled as ?PP? in CTB without any function labels
attached, thus losing to describe the relationship
with the predicate ?O (increases)?. In order to
capture various relationships related to the predi-
cate, we assign function label ?ADT (adjunct)? for
this scenario, and merge it with other adverbials
to form adverbials category. There are 1,415 such
cases in CTB resources, which account for a large
proportion of adverbials types.
After the modifications discussed above, in our
final system we use 20 function labels
3
(18 origi-
nal CTB labels shown in Table 2 and two newly
added labels) that are grouped into two types:
grammatical roles and adverbials.
We calculate the frequency (the number of times
each tag occurs) and average length (the average
number of words each tag covers) of each func-
tion category in our selected sentences, which are
listed in Table 2. As can be seen, the frequency of
adverbials is much smaller than that of grammati-
cal roles. Furthermore, the average length of most
adverbials are somewhat larger than 4. Such data
distribution is likely to be one cause of the lower
identification accuracy of adverbials as we will see
in the experiments.
From the layer of function labeling, sentences
3
ADV includes ADV and ADVP in CTB recourses,
grouped into adverbials. In function labeling level, EXT that
signifies degree, amount of the predicates should be grouped
into adverbials like in the work of (Blaheta and Charniak,
2000) and (Merlo and Musillo, 2005).
Table 2: Categories of function tags with their rel-
ative frequencies and average length.
Function Labels Frequency Average Length
grammatical roles 99507 2.62
FOC 133 1.89
IO 126 1.26
OBJ 25834 4.15
PRD 4428 5.20
SBJ 23809 3.02
TPC 676 3.51
TAR 44501 1.25
adverbials 33287 2.11
ADT 1415 4.51
ADV 21891 1.32
BNF 465 4.66
CND 68 3.15
DIR 1558 4.68
EXT 1048 1.99
IJ 1 1.00
LGS 204 5.42
LOC 2051 4.27
MNR 1053 4.48
PRP 224 4.91
TMP 3309 2.25
in CTB are described with the structure of ?SV?
which indicates a sentence is basically composed
of ?subject + verb?. But in order to identify objects
and complements of predicates, we express sen-
tence by ?SVO? framework in our system, which
regards sentence as a structure of ?subject + verb +
object?. The structure transformation is obtained
through a preprocessing procedure, by upgrading
OBJs and complements (EXT, DIR, etc.) which
are under VP in layered brackets.
3 Learning Function Labels
Function labeling deals with the problem of pre-
dicting a sequence of function tags y = y
1
, ..., y
T
,
from a given sequence of input words x =
x
1
, ..., x
T
, where y
i
? ?. Therefore the function
labeling task can be formulated as a stream of se-
quence learning problem. The general approach
is to learn a w-parameterized mapping function
F : X?Y ? < based on training sample of input-
output pairs and to maximize F (x, y;w) over the
response variable to make a prediction.
There has been several algorithms for label-
ing sequence data including hidden Markov model
(Rabiner, 1989), maximum entropy Markov model
(Mccallum et al, 2000), conditional random fields
(Lafferty et al, 2001) and hidden Markov support
vector machine (HM-SVM) (Altun et al, 2003;
Tsochantaridis et al, 2004), among which HM-
SVM shows notable advantages by its learning
56
non-linear discriminant functions via kernel func-
tion, the properties inherited from support vec-
tor machines (SVMs). Furthermore, HM-SVM
retains some of the key advantages of Markov
model, namely the Markov chain dependency
structure between labels and an efficient dynamic
programming formulation.
In this paper we investigate the application of
the HM-SVM model to Chinese function labeling
task. In order to keep the completeness of paper,
we here address briefly the HM-SVM algorithm,
more details of which could be founded in (Altun
et al, 2003; Tsochantaridis et al, 2004), then we
will concentrate on the techniques of applying it to
our specific task.
3.1 Learning Model
The framework from which HM-SVM are derived
is a maximum margin formulation for joint fea-
ture functions in kernel learning setting. Given n
labeled examples (x
1
, y
1
), ..., (x
n
, y
n
), the notion
of a separation margin proposed in standard SVMs
is generalized by defining the margin of a train-
ing example with respect to a discriminant func-
tion F (x, y;w), as:
?
i
= F (x
i
, y
i
;w)?max
y/?y
i
F (x
i
, y;w). (1)
Then the maximum margin problem can be de-
fined as finding a weight vector w that maxi-
mizes min
i
?
i
. By fixing the functional margin
(max
i
?
i
? 1) like in the standard setting of SVMs
with binary labels, we get the following hard-
margin optimization problem with a quadratic ob-
jective:
min
w
1
2
||w||
2
, (2)
with constraints,
F (x
i
, y
i
;w)? F (x
i
, y;w) ? 1,?
n
i=1
,?
y 6=y
i
.
In the particular setting of SVM, F is as-
sumed to be linear in some combined feature
representation of inputs and outputs ?(x, y), i.e.
F (x, y;w) = ?w,?(x, y)?. ?(x, y) can be
specified by extracting features from an obser-
vation/label sequence pair (x, y). Inspired by
HMMs, we propose to define two types of fea-
tures, interactions between neighboring labels
along the chain as well as interactions between at-
tributes of the observation vectors and a specific
label. For instance, in our function labeling task,
we might think of a label-label feature of the form
?(y
t?1
, y
t
) = [[y
t?1
= SBJ ? y
t
= TAR]], (3)
that equals 1 if a SBJ is followed by a TAR. Anal-
ogously, a label-observation feature may be
?(x
t
, y
t
) = [[y
t
= SBJ ? x
t
is a noun]], (4)
which equals 1 if x at position t is a noun and la-
beled as SBJ. The described feature map exhibits
a first-order Markov property and as a result, de-
coding can be performed by a Viterbi algorithm in
O(T |?|
2
).
All the features extracted at location t are sim-
ply stacked together to form ?(x, y; t). Finally,
this feature map is extended to sequences (x, y) of
length T in an additive manner as
?(x, y) =
T
?
t=1
?(x, y; t). (5)
3.2 Features
It deserves to note that features in HM-SVM
model can be easily changeable regardless of de-
pendency among them. In this prospect, features
are very far from independent can be cooperated
in the model.
By observing the particular property of function
structure in Chinese sentences, we design several
sets of label-observation features which are inde-
pendent of parse trees, namely:
Words and POS tags: The lexical context is ex-
tremely important in function labeling, as indi-
cated by their importance in related task of phrase
chunking. Due to long-distance dependency of
function structure, intuitively, more wider con-
text window will bring more accurate prediction.
However, the wider context window is more likely
to bring sparseness problem of features and in-
crease computation cost. So there should be a
proper compromise among them. In our experi-
ment, we start from a context of [-2, +2] and then
expand it to [-4, 4], that is, four words (and POS
tags) around the word in question, which is closest
to the average length of most function types shown
in Table 2.
Bi-gram of POS tags: Apart from POS tags them-
selves, we also try on the bi-gram of POS tags. We
regard POS tag sequence as an analog to function
57
chains, which reveals somewhat the dependent re-
lations among words.
Verbs: Function labels like subject and object
specify the relations between verb and its argu-
ments. As observed in English verbs (Levin,
1993), each class of verb is associated with a set
of syntactic frames. Similar criteria can also be
found in Chinese. In this sense, we can rely on
the surface verb for distinguishing argument roles
syntactically. Besides the verbs themselves, we
also take into account the special words sharing
common property with verbs in Chinese language,
which are active voice ?r(BA)? and passive voice
?Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 922?930,
Beijing, August 2010
An Exploration of Features for Recognizing Word Emotion
Changqin Quan
Faculty of Engineering
University of Tokushima
quan-c@is.tokushima-u.ac.jp
Fuji Ren
Faculty of Engineering
University of Tokushima
ren@is.tokushima-u.ac.jp
Abstract
Emotion words have been well used as the
most obvious choice as feature in the task
of textual emotion recognition and auto-
matic emotion lexicon construction. In
this work, we explore features for rec-
ognizing word emotion. Based on Ren-
CECps (an annotated emotion corpus) and
MaxEnt (Maximum entropy) model, sev-
eral contextual features and their com-
bination have been experimented. Then
PLSA (probabilistic latent semantic anal-
ysis) is used to get semantic feature by
clustering words and sentences. The ex-
perimental results demonstrate the effec-
tiveness of using semantic feature for
word emotion recognition. After that,
?word emotion components? is proposed
to describe the combined basic emotions
in a word. A significant performance
improvement over contextual and seman-
tic features was observed after adding
word emotion components as feature.
1 Introduction
Textual emotion analysis is becoming increas-
ingly important due to augmented communication
via computer mediated communication (CMC). A
possible application of textual emotion recogni-
tion is online chat system. An emotion feedback
system can recognize users? emotion and give ap-
propriate responses. Another application exam-
ple is weblog emotion recognition and prediction.
Blogspace consists of millions of users who main-
tain their online diaries, containing frequently-
updated views and personal remarks about a range
of issues. An emotion recognition and predic-
tion system can understand the public?s reaction to
some social issues and predict emotion changes. It
would be helpful for solving some psychological
problems or giving early warnings, such as suicide
or terrorism.
Textual emotion analysis also can improve
the accuracy of other nonverbal modalities like
speech or facial emotion recognition, and to im-
prove human computer interaction systems. How-
ever, automatic recognition of emotion meaning
from texts presents a great challenge. One of the
reasons is the manifoldness of expressed emotions
in words.
Emotion words have been well used as the
most obvious choice as feature in the task of tex-
tual emotion recognition and automatic emotion
lexicon construction (Virginia and Pablo, 2006;
Tokuhisa et al, 2008, etc.). And there are many
lexical resources developed for these tasks, such
as GI (Stone et al, 1966), WordNet-Affect (Strap-
parava and Valitutti, 2004), NTU Sentiment Dic-
tionary (Ku et al, 2006), Hownet (Dong and
Dong, 2003), SentiWordnet (Esuli and Sebastiani,
2006). In these sentimental or affective lexicons,
the words usually bear direct emotions or opin-
ions, such as happy or sad, good or bad. Al-
though they play a role in some applications, sev-
eral problems of emotion expression in words
have been ignored.
Firstly, there are a lot of sentences can evoke
emotions without direct emotion words. For ex-
ample,
(1) SU3?f??p!3?f?%
p"(Spring is in children?s eyes, and in their
hearts.)
In sentence (1), we may feel joy, love or expect
delivered by the writer. But there are no direct
emotion words can be found from lexicons. As
Ortony (1987) indicates, besides words directly
referring to emotion states (e.g., ?fear?, ?cheer-
ful?) and for which an appropriate lexicon would
help, there are words that act only as an indirect
922
reference to emotions depending on the context.
Strapparava et al (2006) also address this issue.
The authors believed that all words can potentially
convey affective meaning, and they distinguished
between words directly referring to emotion states
(direct affective words) and those having only an
indirect reference that depends on the context (in-
direct affective words).
The second problem is emotion ambiguity of
words. The same word in different contexts may
reflect different emotions. For example,
(2) ??8c???U?"(This is cur-
rently the only thing I can do.)
(3)?????"(He is my only one.)
In sentence (2), the word ??? (only)? may
express the emotion of anxiety or expect; but in
sentence (3), the word ??? (only)? may express
the emotion of love or expect. The emotion cat-
egories can not be determined without their cer-
tain contexts especially for the words with emo-
tion ambiguity.
In addition, some words can express multiple
emotions, such as ?U\ (mingled feelings
of joy and sorrow)?. Statistics on an annotated
emotion corpus (Ren-CECps 1, Chinese emotion
corpus developed by Ren-lab) showed that 84.9%
of all emotion words have one emotion, 15.1%
have more than one emotions (Quan and Ren,
2010). Multi-emotion words are indispensable for
expressing complex feelings in use of language.
In this work, we explore features for recogniz-
ing word emotion in sentences. Based on Ren-
CECps and MaxEnt model, several contextual
features and their combination have been exper-
imented. Then PLSA (probabilistic latent seman-
tic analysis) is used to get semantic feature by
clustering word and sentence. The experimental
results demonstrate the effectiveness of using se-
mantic feature for word emotion recognition. Af-
ter that, the notion of ?word emotion components?
is proposed to describe the combined basic emo-
tions in a word. A significant performance im-
provement over only using contextual and seman-
tic features was observed after adding word emo-
tion components as feature and output in MaxEnt
based model.
1http://a1-www.is.tokushima-u.ac.jp/member
/ren/Ren-CECps1.0/Ren-CECps1.0.html
This paper is organized as follows. In section 2,
based on Ren-CECps and MaxEnt, an exploration
of using contextual feature for Chinese word emo-
tion recognition is described. In section 3, using
PLSA technique, the performance of adding se-
mantic feature is presented. In section 4, the no-
tion of ?word emotion components? is proposed
and the performance of using encoding feature is
presented. In section 5, the discussions are de-
scribed. Section 6 is conclusions.
2 Chinese Word Emotion Recognition
2.1 Related Works
There are many researches concerning comput-
ing semantics of words, while the researches on
computing emotions of words are relatively less.
Computing word emotions is a challenge task be-
cause the inherent of emotion is ambiguous and
natural language is very rich in emotion termi-
nology. Using the textual emotion information,
several methods have been explored for comput-
ing lexical emotions. Wilson et al (2009) pro-
posed a two-step approach to classify word po-
larity out of context firstly, and then to clas-
sify word polarity in context with a wide vari-
ety of features. Strapparava et al (2007) im-
plemented a variation of Latent Semantic Anal-
ysis (LSA) to measure the similarities between di-
rect affective terms and generic terms. Lee and
Narayanan (2005) proposed a method of comput-
ing mutual information between a specific word
and emotion category to measure how much in-
formation a word provides about a given emo-
tion category (emotion salience). Based on struc-
tural similarity, Bhowmick (2008) computed the
structural similarity of words in WordNet to dis-
tinguish the emotion words from the non-emotion
words. Kazemzadeh (2008) measured similar-
ity between word and emotion category based on
interval type-2 fuzzy logic method. Takamura
(2005) used a spin model to extract emotion po-
larity of words.
Different from the above researches, in this
work, we explore which features are effective for
word emotion recognition. The features include
contextual feature, semantic feature and encoding
feature.
923
2.2 Ren-CECps and MaxEnt based Chinese
Word Emotion Recognition
Ren-CECps is constructed based on a relative
fine-grained annotation scheme, annotating emo-
tion in text at three levels: document, paragraph,
and sentence. The all dataset consisted of 1,487
blog articles published at sina blog, sciencenet
blog, etc. There are 11,255 paragraphs, 35,096
sentences, and 878,164 Chinese words contained
in this corpus (more details can be found in (Quan
and Ren, 2010)).
In the emotion word annotation scheme of Ren-
CECps, direct emotion words and indirect emo-
tion words in a sentence are all annotated. For
example, in sentence (1) /SU (spring)0and
/?f? (the children)0are labeled. An emo-
tion keyword or phrase is represented as a vec-
tor to record its intensities of the eight basic emo-
tion classes (expect, joy, love, surprise, anxiety,
sorrow, angry and hate). For instance, the emo-
tion vector for the word /SU (spring)0??w =
(0.1,0.3,0.3,0.0,0.0,0.0,0.0,0.0) indicates the
emotions of weak expect, joy and love. In this
work, we focus on if a word contains some emo-
tion(s) in a certain context. The analysis on emo-
tion intensity of emotion words is included in our
future work.
As word emotion is subjective entity, a word
in a certain context may evoke multiple emotions
in different people?s mind. A part of documents
in Ren-CECps have been annotated by three an-
notators independently to measure agreement on
the annotation of this corpus, which include 26
documents with a total of 805 sentences, 19,738
words. This part of corpus is used as testing cor-
pus to evaluate the experimental results. (Section
5.1 shows the analysis on the annotation agree-
ment on word emotion.)
MaxEnt modeling provides a framework for in-
tegrating information from many heterogeneous
information sources for classification (Manning,
1999). MaxEnt principle is a well used technique
provides probability of belongingness of a token
to a class. In word emotion recognition, the Max-
Ent estimation process produces a model in which
each feature fi is assigned a weight ?i. The de-
terministic model produces conditional probabil-
ity (Berger, 1996), see equation (1) and (2). In
experiments, we have used a Java based open-nlp
MaxEnt toolkit 2.
p(e|context) = 1Z(context) ?i ?
fi(context,e)
i (1)
Z(context) = ??
i
? fi(context,e)i (2)
2.3 Contextual Features
The contextual features used in MaxEnt for Chi-
nese word emotion recognition are described as
follows:
Word Feature (WF): Word itself to be recog-
nized.
N-words Feature (NF): To know the rela-
tionship between word emotion and its con-
text, the surrounding words of length n for the
word (wi) to be recognized are used as feature:
(wi?n...wi...wi+n).
POS Feature (POSF): The part of speech of
the current word and surrounding words are used
as feature. We have used a Chinese segmentation
and POS tagger (Ren-CMAS) developed by Ren-
lab, which has an accuracy about 97%. The set of
POS includes 35 classes.
Pre-N-words Emotion Feature (PNEF): The
emotions of the current word may be influenced
by the emotions of its previous words. So the
emotions of previous n words are used as feature.
The value of this feature for a word (wi) is ob-
tained only after the computation of the emotions
for its previous words.
Pre-is-degree-word Feature (PDF), Pre-
is-negative-word Feature (PNF), Pre-is-
conjunction Feature (PCF): To determine if
the previous word is a degree word, a negative
word, or a conjunction may be helpful to identify
word emotions. The degree word list (contains
1,039 words), negative word list (contains 645
words), and conjunction list (contains 297 words)
extracted from Ren-CECps have been used.
2.4 The Performance of Using Contextual
Feature
We use the documents in Ren-CECps that have
been annotated by three annotators independently
2http://maxent.sourceforge.net/
924
as testing corpus. An output of word emotion(s)
will be regarded as a correct result if it is in agree-
ment with any one item of word emotion(s) pro-
vided by the three annotators. The numbers of
training and testing corpus are shown in table 1.
The accuracies are measured by F-value.
Table 1: Number of training and testing corpus
Number Training Testing
Documents 1,450 26
Sentences 33,825 805
Words 813,507 19,738
Emotion words 99,571 2,271?
(*) At least agreed by two annotators.
Table 2 gives the results of F-value for differ-
ent contextual features in the MaxEnt based Chi-
nese word emotion recognition. The results of F-
value include: (a) recognize emotion and unemo-
tion words; (b) recognize the eight basic emotions
for emotion words (complete matching); (c) rec-
ognize the eight basic emotions for emotion words
(single emotion matching).
As shown in table 2, when we only use Word
Feature(WF), the F-value of task (a) achieved a
high value (96.3). However, the F-values of task
(b) and (c) are relative low, that means the prob-
lem of recognizing the eight basic emotions for
emotion words is a lot more difficult than the
problem of recognizing emotion and unemotion
words, so we focus on task (b) and (c).
When we experiment with Word Feature(WF)
and N-words Feature (NF), we have observed
that word feature (wi) and a window of previ-
ous and next word (wi?1,wi,wi+1) give the best
results (a=96.5, b=50.4, c=69.0). Compared
with (wi?1,wi,wi+1), a larger window of previous
and next two words (wi?2,wi?1,wi,wi+1,wi+2) re-
duces the F-value. This demonstrates that wi and
wi?1,wi,wi+1 are effective features for word emo-
tion recognition.
When POS Feature (POSF) is added, the F-
value is increased. Especially the F-value is in-
creased to (a=97.1, b=51.9, c=72.0) when posi
and posi?1, posi, posi+1 are added.
We also find that Pre-N-words Emotion Fea-
ture (PNEF) (pre e0, ..., pre ei?1) increases the F-
value, but previous one word emotion can not in-
creases the F-value.
As can be seen from table 2, when only con-
textual features are used, the highest F-value
is (a=97.1, b=53.0, c=72.7) when Pre-is-degree-
word Feature (PDF), Pre-is-negative-word Fea-
ture (PNF), Pre-is-conjunction Feature (PCF) are
added.
3 Semantic Feature
To know if semantic information is useful for
emotion recognition, we have used probabilis-
tic latent semantic analysis (PLSA) (Hofmann,
1999) to cluster words and sentences. PLSA clus-
ters documents based on the term-document co-
occurrence which results in semantic decomposi-
tion of the term-document matrix into a lower di-
mensional latent space. PLSA can be defined as:
P(s,w) = ?
z?Z
P(z)P(s|z)P(w|z) (3)
where p(s,w) is the probability of word w and
sentence s co-occurrence, P(s|z) is the probability
of a sentence given a semantic class z, and P(w|z)
is the probability of a word given a semantic class
z.
For word clustering, We made the assignment
based on the maximum p(z|w), if p(z? |w) = max
p(z|w), then w was assigned to z? . Sentence clus-
tering is similar to word clustering. Word clus-
tering and sentence clustering are run separately.
The word class id and sentence class id are used
as semantic feature (SF), which including sen-
tence class feature (SCF) and word class feature
(WCF). PeenAspect implementation of PLSA has
been used for our expriments 3.
Table 3 gives the results of F-value for com-
bined all contextual features and semantic fea-
ture in the MaxEnt based Chinese word emotion
recognition.
As can be seen from table 3, when SCF is used,
the best result is obtained when the cluster num-
ber is 100; when WCF is used, the best result is
obtained when the cluster number is 100 or 160.
The results demonstrate the effectiveness of using
SCF is a little higher than using WCF.
3http://www.cis.upenn.edu/datamining/software dist/
PennAspect/
925
Table 2: F-value for different contextual features in the MaxEnt based Chinese word emotion recogni-
tion
(a) recognize emotion or unemotion words
(b) recognize the eight basic emotions for emotion words (complete matching)
(c) recognize the eight basic emotions for emotion words (single emotion matching)
Feature Features F-value
type (a) (b) (c)
WF f 1 = wi 96.3 45.9 63.0
NF f 1 = wi?1,wi,wi+1 94.8 44.8 60.7
f 1 = wi?2,wi?1,wi,wi+1,wi+2 92.4 28.4 40.3
WF+NF f 1 = wi; f 2 = wi?1,wi,wi+1 96.5 50.4 69.0
WF+NF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi 96.8 51.5 71.1
+POSF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi?1, posi, posi+1 97.0 51.7 71.6
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi f 4 = posi?1, posi, posi+1 97.1 51.9 72.0
WF+NF
+POSF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1 f 5 = pre ei?1 97.1 51.9 72.0
+PNEF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1 97.1 52.4 72.2
WF+NF
+POSF
+PNEF
+PDF
+PNF
+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1
f 6 =?(wi?1 is a degree word)
f 7 =?(wi?1 is a negative word)
f 8 =?(wi?1 is a con junction)
97.1 53.0 72.7
4 Encoding Feature: Emotion
Components of Word
Researches on the psychology of concepts show
that categories in the human mind are not sim-
ply sets with clearcut boundaries (Murphy, 2002;
Hampton, 2007). Word emotions are certainly re-
lated to mental concepts. As for emotion states,
most theorists appear to take a combinatorial view.
Plutchik (1962), for example, talks about ?mixed
states?, ?dyads? and ?triads? of primary emotions.
Similarly, Averill (1975) argues for compound
emotions based on more elementary ones. And
one model, suggested by Ekman (1982) (emotion
blends) and Plutchik (mixed states), is that emo-
tions mix (Ortony, 1988). According to these re-
searches, we use an encoding feature: emotion
components of word.
?Emotion components of word? describes the
combined basic emotions in a word, which is rep-
resented by eight binary digits, and each digit cor-
responding to a basic emotion class respectively.
For example, the word ?U? (like)?, its possi-
ble emotion components in a certain context is
?01100000?, which expresses the combined emo-
tions by joy and love.
With the expression of emotion components
of word, it is possible to distinguish direct emo-
tion words and indirect emotion words. Those
words always demonstrate similar emotion com-
ponents in different contexts can be regarded as
direct emotion words, accordingly, those words
demonstrate different emotion components in dif-
ferent contexts can be regarded as indirect emo-
tion words. With the expression of emotion com-
ponents in word, the problem of expressing emo-
tion ambiguity in words can be solved. The same
word in different contexts may reflect different
emotions, which can be expressed by different
emotion components. The emotions of words with
multiple emotions also can be expressed by emo-
tion components.
926
Table 3: F-value for combined contextual features
(CF) and semantic feature (SF) (including sen-
tence class feature (SCF) and word class feature
(WCF))
Feature Cluster F-value
type number (a) (b) (c)
CF+SCF 20 97.0 53.1 72.8
40 97.0 53.4 72.7
60 97.0 53.5 72.8
80 97.0 52.9 72.5
100 97.0 53.6 73.1
120 97.0 53.1 72.7
150 97.0 53.2 72.9
180 97.0 53.4 73.1
CF+WCF 40 97.0 53.1 72.8
100 97.0 53.4 72.9
160 97.0 53.4 72.9
220 97.0 53.3 72.9
280 97.0 53.2 72.8
370 97.0 53.1 72.8
The statistics of word emotion components in
Ren-CECps show that there are a total of 68 emo-
tion components in all of 22,095 annotated emo-
tion words without repetitions. Figure 1 shows the
growth curve of word emotion components num-
ber with emotion word number increase.
As can be seen from figure 1, the number in-
crease of word emotion components shows a very
slow growth rate with the number increase of
emotion words. We can conclude that the space
of word emotion components is a relatively small
space.
In the model of MaxEnt based Chinese word
emotion recognition, the Pre-N-words Emotion
Feature (PNEF) and emotion output can be en-
coded to emotion components.
Pre-N-words Emotion Components Feature
(PNECF): The emotion components of its previ-
ous words for a word (wi). The value of this fea-
ture is obtained only after the computation of the
emotion components for its previous words.
Table 4 gives the results of F-value for the com-
bined contextual features and encoding feature.
As can be seen in table 4, when Pre-N-words
Emotion Feature (PNEF) is replaced by Pre-N-
Figure 1: The growth curve of word emotion com-
ponents
words Emotion Components Feature (PNECF),
and emotion components are output as results, F-
value is increased up to (a=97.3, b=57.3, c=73.3).
Then based on this result, we firstly trained a word
emotion based model, then the word emotion out-
puts of this model are used as Pre-N-words Emo-
tion Feature (PNEF) for the word emotion com-
ponents based model. A significant F-value im-
provement of task (b) and (c) (b=62.5, c=73.7)
over only using contextual and semantic features
was observed after adding the combined word
emotion and word emotion components as feature.
5 Discussion
5.1 Word Emotion Agreement on People?s
Judgments
The final aim of a human-computer interaction
recognition system is to get the result close to peo-
ple?s judgments. As word emotion is inherently
uncertain and subjective, here we report the anno-
tation agreement on word emotion of Ren-CECps,
which can be taken as an evaluation criteria for a
algorithm.
To measure the annotation agreement of Ren-
CECps, three annotators independently annotated
26 documents with a total of 805 sentences,
19,738 words. We use the following two metrics
to measure agreement on word emotion annota-
tion.
(1) Kappa coefficient of agreement (Carletta,
1996). It is a statistic adopted by the computa-
927
Table 4: F-value for the combined contextual features and encoding feature
Feature type Features F-value
(a) (b) (c)
WF+NF+POSF+PNECF
+PDF+PNF+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1
f 5 = pre es0, ..., pre esi?1
f 6 =?(wi?1 is a degree word)
f 7 =?(wi?1 is a negative word)
f 8 =?(wi?1 is a con junction)
97.3 57.3 73.3
WF+NF+POSF+PNEF
+PNECF+PDF+PNF+PCF
f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi
f 4 = posi?1, posi, posi+1
f 5 = pre e0, ..., pre ei?1
f 6 = pre es0, ..., pre esi?1
f 7 =?(wi?1 is a degree word)
f 8 =?(wi?1 is a negative word)
f 9 =?(wi?1 is a con junction)
97.3 62.5 73.7
tional linguistics community as a standard mea-
sure.
(2) Voting agreement. It is used to mea-
sure how much intersection there is between
the sets of word emotions identified by the
annotators. It includes majority-voting agree-
ment (AgreementMV ) and all-voting agreement
(AgreementAV ). AgreementMV is defined as fol-
lows. Let A, B and C be the sets of word emo-
tion components annotated by annotators a, b and
c respectively. The expert coder is the set of ex-
pressions that agreed by at least two annotators,
see equation (4).
AgreementMV = Avg(count(ti = e j)count(ti) ) (4)
In which, ti ? T , e j ? E, T = A?B?C, E =
(A?B)?(A?C)?(B?C).
Accordingly, the expert coder of AgreementAV
is the set of expressions that agreed by all annota-
tors.
The above two metrics are used to measure the
agreements on: (a) determine if a word is an emo-
tion or unemotion word; (b) determine the eight
basic emotions for emotion words (complete emo-
tion matching); (c) determine the eight basic emo-
tions for emotion words (single matching). (b)
and (c) are provided that at least two people to be-
lieve the word is an emotion word. Table 5 shows
the agreements measured by the two metrics.
As shown in table 5, it is easier for annotators to
agree at if a word contains emotion, but it is more
difficult to agree on emotions or emotion compo-
nents of a word. Compared with the agreement on
people?s judgments, our experiments gave promis-
ing results.
Table 5: Agreement of word emotion annotation
measured by Kappa, Majority-voting (MV), and
All-voting (AV)
Measure Kappa MV AV
(a) 84.3 98.5 95.1
(b) 66.7 70.3 26.2
(c) 77.5 100 84.9
5.2 Error Analysis
Conducting an error analysis, we find that a lot
of errors occur due to the recognition on multi-
emotion words and indirect emotion words, espe-
cially in short sentences because the features can
be extracted are too few. So more features should
be considered from larger contexts, such as the
topic emotion of paragraph or document.
There are some errors occur due to more than
one emotion holders exist in one sentence, for ex-
928
ample of sentence (4).
(4) ?uy?wX?a,?"(I
found that daughter was looking at the toys of her
interest.)
In sentence (4), three annotators all agree that
the emotion components of the word ?a, (in-
terest)? is ?00000000? since they believe that this
word is an unemotion word from the view of the
writer. But our system give a result of ?00100000?
because the emotion holder ?? (daughter)? of
the emotion word ?a, (interest)? has not been
considered in our algorithm. Therefore, the recog-
nition of emotion holder is indispensable for an
accurate emotion analysis system.
In addition, Chinese segmentation mistakes and
phrasing error also cause errors.
6 Conclusions
Automatically perceive the emotions from text
has potentially important applications in CMC
(computer-mediated communication) that range
from identifying emotions from online blogs to
enabling dynamically adaptive interfaces. Therein
words play important role in emotion expressions
of text.
In this paper we explored features for recogniz-
ing word emotions in sentences. Different from
previous researches on textual emotion recogni-
tion that based on affective lexicons, we believe
that besides obvious emotion words referring to
emotions, there are words can potentially convey
emotions act only as an indirect reference. Also,
quite often words that bear emotion ambiguity and
multiple emotions are difficult to be recognized
depending on emotion lexicons. Emotion of a
word should be determined with its context.
Based on Ren-CECps (an annotated emotion
corpus) and MaxEnt (Maximum entropy) model,
we have experimented several contextual features
and their combination, then using PLSA (proba-
bilistic latent semantic analysis), semantic feature
are demonstrated the effectiveness for word emo-
tion recognition. A significant performance im-
provement over only using contextual and seman-
tic features was observed after adding encoding
feature (word emotion components). Determining
intensity of word emotion and recognizing emo-
tion of sentence or document based on word emo-
tion are included in our future work.
Acknowledgments
This research has been partially supported by
Ministry of Education, Science, Sprots and Cul-
ture, Grant-in-Aid for Challenging Exploratory
Research, 21650030. We also wish to acknowl-
edge the anonymous reviewer?s insightful com-
ments and suggestions.
References
J. R. Averill. 1975. A semantic atlas of emotional con-
cepts. JSAS Catalog of Selected Documents in Psy-
chology.
Adam Berger, Vincent Della Pietra and Stephen A.
Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistic 22(1), pages 39?71.
Plaban Kumar Bhowmick, Animesh Mukherjee, Aritra
Banik, Pabitra Mitra, Anupam Basu. 2008. A com-
parative study of the properties of emotional and
non-Emotional words in the Wordnet: A complex
network approach. In Proceedings of International
conference on natural language processing (ICON
2008).
Jean Carletta. 1996. Assessing agreement on classifica-
tion tasks: the Kappa statistic. Computational Lin-
guistics. 22(2): 249-254.
Z. Dong and Q. Dong. 2003. HowNet)a hybrid
language and knowledge resource. In Proceedings
of Int?l Conf. Natural Language Processing and
Knowledge Eng., pages 820?824.
Paul Ekman. 1982. Emotion in the human face. Cam-
bridge University Press.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. In Proceedings of the Fifth Inter-
national Conference on Language Resources and
Evaluation (LREC 2006), pages 417-422.
James A. Hampton. 2007. Typicality, graded
membership, and vagueness. Cognitive Science
31:355?384.
Thomas Hofmann. 1999. Probabilistic latent semantic
analysis. In Proceedings of the Fifteenth Conference
on Uncertainty in Artificial Intelligence (UAI?99).
Abe Kazemzadeh, Sungbok Lee, and Shrikanth
Narayanan. 2008. An interval type-2 fuzzy logic
system to translate between emotion-related ocab-
ularies. In Proceedings of Interspeech.
929
Lun-Wei Ku, Yu-Ting Liang and Hsin-Hsi Chen. 2006.
Tagging heterogeneous evaluation corpora for opin-
ionated tasks. In Proceedings of Conference on
Language Resources and Evaluation (LREC 2006),
pages 667-670.
Chul Min Lee, Shrikanth S. Narayanan. 2005. Toward
detecting emotions in spoken dialogs. Journal of
the American Society for Information Science. IEEE
Trans. on Speech and Audio Processing 13(2):293-
303.
Christopher D. Manning and Hinrich Schjtze. 1999.
Foundations of statistical natural language process-
ing. Cambridge, MA: MIT Press.
Gregory L. Murphy. 2002. The Big Book of Concepts.
Cambridge, MA: MIT Press.
Andrew Ortony. Gerald l. Clore. Mark A. Foss. 1987.
The referential structure of the affective lexicon.
Cognitive Science 11:341-364.
Andrew Ortony, Gerald L. Clore, Allan Collins. 1988.
The Cognitive Structure of Emotions. Cambridge
University Press.
Robert Plutchik. 1962. The emotions: Facts, theories,
and a new model. New York: Random House.
Changqin Quan and Fuji Ren. 2010. A blog
emotion corpus for emotional expression analy-
sis in Chinese. Computer Speech & Language,
24(4):726?749.
Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,
and Daniel M. Ogilvie. 1966. The General Inquirer:
A computer approach to content analysis. The MIT
Press.
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of word-
net. In Proceedings of the 4th International Con-
ference on Language Resources and Evaluation
(LREC 2004), pages 1083-1086.
Carlo Strapparava, Alessandro Valitutti, and Oliviero
Stock. 2006. The affective weight of lexicon. In Pro-
ceedings of the Fifth International Conference on
Language Resources and Evaluation (LREC 2006),
pages 423-426.
Carlo Strapparava, Alessandro Valitutti, Oliviero
Stock. 2007. Dances with words. In Proceed-
ings of the Twentieth International Joint Confer-
ence on Artificial Intelligence (IJCAI 2007), pages
1719?1724.
Hiroya Takamura, Takashi Inui, and Manabu Oku-
mura. Extracting emotional polarity of words using
spin model. 2005. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL 2005), pages 133?140.
Ryoko Tokuhisa, Kentaro Inui, Yuji Matsumoto. 2008.
Emotion classification using massive examples ex-
tracted from the web. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008). pages 881?888.
Francisco Virginia and GervSs Pablo. 2006. Exploring
the compositionality of emotions in text: word emo-
tions, sentence emotions and sutomated Tagging. In
Proceedings of the AAAI-06 Workshop on Computa-
tional Aesthetics: Artificial Intelligence Approaches
to Beauty and Happiness, pages 16?20.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing Contextual Polarity: an explo-
ration of features for phrase-level sentiment analy-
sis. Computational Linguistics 35(3): 1?34.
930
Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 54?63,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Gene?disease association extraction by text mining and network 
analysis 
 
Changqin Quan 
AnHui Province Key Laboratory of 
Affective Computing and Advanced 
Intelligent Machine, 
School of Computer and Information, 
HeFei University of Technology 
quanchqin@gmail.com  
Fuji Ren 
Faculty of Engineering, 
University of Tokushima, 
ren@is.tokushima-u.ac.jp 
 
Abstract 
Biomedical relations play an important role in 
biological processes. In this work, we combine 
information filtering, grammar parsing and 
network analysis for gene-disease association 
extraction. The proposed method first extracts 
sentences potentially containing information about 
gene-diseases interactions based on maximum 
entropy classifier with topic features. And then 
Probabilistic Context?Free Grammars is applied 
for gene-disease association extraction. The 
network of genes and the disease is constituted by 
the extracted interactions, network centrality 
metrics are used for calculating the importance of 
each gene. We used breast cancer as testing disease 
for system evaluation. The 31 top ranked genes and 
diseases by the weighted degree, betweenness, and 
closeness centralities have been checked relevance 
with breast cancer through NCBI database. The 
evaluation showed 83.9% accuracy for the testing 
genes and diseases, 74.2% accuracy for the testing 
genes. 
1 Introduction 
Since the start of Human Genome Project in 
1990, over 40 kinds of organism genome have 
been sequenced. Biological databases expand 
rapidly with the exponential growth of biological 
data. For instance, until now, over 260,000 
named organisms have their nucleotide 
sequences in the GenBank (Benson et al. 2008) 
which integrates data from the major DNA and 
protein sequence. However, data is not 
information. Compared with situations before 
2003, the key problem today has turned to 
methods of knowledge extraction. Understanding 
the role of genetics in diseases is one of the 
major goals of the post-genome era. The 
expanding rate of knowledge in gene?disease 
associations can hardly match up with the growth 
of biological data. It takes time before new 
discoveries are included in the databases such as 
Online Mendelian Inheritance in Man (OMIM), 
and most of the information represented in these 
databases is manually collected from literature. 
    To address this challenge, we proposed an 
automatic gene-disease association extraction 
approach based on text mining and network 
analysis. We combine information filtering, 
grammar parsing and network analysis. We 
started by calculating main topics of each 
sentences in the corpus based on supervised 
Latent Dirichlet Allocation (sLDA) model (Blei 
and McAuliffe 2007). The most probable topics 
derived from sLDA model for each sentence are 
used as features for training maximum entropy 
(MaxEnt) (Manning and Schutze, 1999) 
classifier, which extracts sentences potentially 
containing information about gene-diseases 
interactions. After that, Probabilistic Context?
Free Grammars (PCFGs) (Klein and Christopher 
2003) is applied for sentence grammar parsing. 
Based on the syntactic tree of each sentence, we 
extract paths between specific entities such as 
diseases or genes. The network of all candidate 
genes and the disease is constituted by the 
interactions extracted from the sentences in the 
corpus. Our main hypothesis in network analysis 
is that the most important and the most central 
genes in an interaction network are most likely to 
be related to the disease. Last, network centrality 
metrics are used for calculating the importance 
of each gene.  
The rest of this paper is organized as follows. 
Section 2 surveys related work. In Section 3, we 
introduce the proposed approach of extracting 
interactions from literature. Section 4 presents 
gene-disease interaction network analysis. And 
54
then Section 5 presents and discusses the 
experimental results. Lastly we conclude this 
paper and discuss future work in Section 6. 
2 Related Work  
Much effort is currently spent on extracting 
gene?disease associations (?zg?r et al. 2008; 
Chun et al. 2006). Biomedical relation extraction 
techniques basically include two branches: 
interaction database based methods and text 
mining methods. Interaction database based 
methods rely on the availability of interaction 
databases, such as OMIM, MINT (Zanzoni et al. 
2002), IntAct (Kerrien et al. 2012), BIND (Bader 
et al. 2003), which predict interactions between 
entities using sequence, structural, or 
evolutionary information (Krallinger, Leitner, 
and Valencia 2010). Although these databases 
host a large collection of manually extracted 
interactions from the literature, manually curated 
databases require considerable effort and time 
with the rapid increasing of biomedical literature.  
 Since most biological facts are available in 
the free text of biomedical articles, the wealth of 
interaction information provided in biomedical 
articles motivated the implementation of text 
mining approaches to automatically extract 
biomedical relations. Text mining approaches to 
gene?disease association extraction have shown 
an evolution from simple systems that rely solely 
on co-occurrence statistics (Adamic et al. 2002; 
Al-Mubaid and Singh 2005) to complex systems 
utilizing natural language processing techniques 
and machine learning algorithms (Freudenberg 
and Propping 2002; Glenisson et al. 2004; ?zg?r 
et al. 2008). Well-known tools for discovering 
gene?disease associations include DAVID 
(Huang et al. 2009), GSEA (Subramanian et al. 
2005), GOToolBox (Martin et al. 2004), rcNet 
(Huang et al. 2011) and many others. However, 
in many cases, since the existing annotations of 
disease-causative genes is far from complete 
(McKusick 2007), and a gene set might only 
contain a short list of poorly annotated genes, 
existing approaches often fail to reveal the 
associations between gene sets and disease 
phenotypes (Huang et al. 2011). 
    Network-based approaches (Wuchty, Oltvai, 
and Barab?si, 2003; Schwikowski et al. 2000; 
Chen et al. 2006) is performed by assessing how 
much genes interact together and are close to 
known disease genes in protein networks. 
Relation extraction among genes is the 
fundamental step for gene-interaction network 
creation. Recently, syntactic analysis has been 
considered for relation extraction, and different 
parsing grammars have been applied. Temkin 
and Gilder (2003) used a full parser with a 
lexical analyzer and a context free grammar 
(CFG) to extract protein-protein interactions. In 
Yakushiji et al. (2005)?s work, they proposed a 
protein-protein interaction extraction system 
based on head-driven phrase structure grammar 
(HPSG). Although the pattern generation is 
complicated, the performance is not satisfactory. 
In addition, dependency grammar is used 
frequently in this domain. Erkan et al. (2007) 
proposed a semi-supervised classification for 
extracting protein interaction sentences using 
dependency parsing. Katrin et al. (2007) defined 
some rules based on dependency parse tree for 
relation extraction. The problem of those systems 
using dependency parse is that they cannot treat 
non-local dependencies, and thus rules acquired 
from the constructions are partial (Yakushiji et al. 
2005). Differently, in this work, we apply 
sentence filtering based on topics and phrase 
structure parsing for relation extraction. The 
extracted sentences potentially contain 
information about gene-diseases interactions. 
Phrase structure grammars are based on the 
constituency relation, as opposed to the 
dependency relation associated with dependency 
grammars. Phrase structure parsing is full 
parsing, which takes into account the full 
sentence structure. 
 In addition, many researches (Aerts et al. 
2005; Chen et al. 2009; Ma et al. 2007; Hutz et al. 
2008; Morrison et al. 2005; ?zg?r et al. 2008) 
used an initial list of seed genes to build a 
disease-specific gene-interaction network, and 
thus they are biased in favor of the seed genes, 
consequently the results also depend on the 
pickup seed genes.  
3 Extracting interactions from 
literature  
3.1 The Corpus 
We used 44,064 articles from PubMed Central 
(PMC) Open Access which is a free full-text 
archive of biomedical and life sciences journal 
literature. All articles were extracted by querying 
the keyword of ?breast cancer?. We applied a 
segmentation tool Splitta for segmenting articles 
into sentences which includes proper 
tokenization and models for high accuracy 
55
sentence boundary detection with reported error 
rates near 0.25% coded by Gillick (2009). 
A gene name dictionary was built from 
OMIM database. The disease name dictionary 
was built based on Genetic Association Database 
(GAD) which is an archive of human genetic 
association studies of complex diseases and 
disorders. 
3.2 Key sentences extraction 
We applied MaxEnt classifier with topic features 
for key sentences extraction. The extracted 
sentences potentially contain information about 
genes and breast cancer interactions. 
A Latent Dirichlet Allocation (LDA) model 
was used to infer topics of sentences. Three most 
probable topics of each sentence were put into 
trained MaxEnt classifier as features for 
extracting sentences that potentially contain 
interaction relationship between genes and 
diseases. 
3.2.1 Key words annotation 
We assume that each sentence indicating 
interactions should contain at least one gene and 
target disease name. Key words are the words 
increasing possibility of sentence containing 
interaction relationships, such as genes and 
diseases. As mentioned above, we built the gene 
name dictionary with data from OMIM database 
and disease name dictionary from Genetic 
Association Database (GAD). All gene names 
and disease names were considered as key words. 
3.2.2 Topic model based on Gibbs Sampling  
Latent Dirichlet Allocation (LDA) was applied 
based on Gibbs Sampling method in our system. 
Compared with algorithm obtaining approximate 
maximum-likelihood estimates for topics-words 
distribution and the hyperparameters of the prior 
on documents-topics distribution given by Blei, 
Ng and Jordan (2002), Gibbs Sampling method 
doesn?t need to explicitly represent the model 
parameters which effect on the final results 
(Griffiths, 2002). 
For a word w  in a specific article, the 
possibility it belongs to topic j  can be given by : 
( | , ) ( | , , ) ( | )? ? ? ?= ? = =i i i i i i i iP z j z w P w z j z w P z j z  (1) 
where 
iz  represents current topic, iz?  
represents all topics except for i , w represents 
all words in the article, 
iw  represents current 
word and 
iw?  represents all words except for iw . 
Formula (1) could be represented as follow 
after derivation: 
( ) ( )
,
( )( )
, ,
( | , )
? ?
? ?
?
? ?
? ? ?
+ += ?
+ +
i i
i
w d
i j
i i d
i j i
n n
P z j z w
n W n T    (2) 
where )(
,
?
? jin  represents count of words belong 
to topic j  except for current word. )( ,i
w
jin?  
represents count of word iw  belong to topic j  in 
the article except for current one. )( idn  represents 
total of words in article id , while )( ,i
d
in ??  represents 
count of words in document id  not including the 
current one. ?  and ?  are hyperparameters that 
determine extent of smooth of this empirical 
distribution, and how heavily this distribution 
can be chosen to give the desired resolution in 
the resulting distribution. W  stands for count of 
words while T  stands for count of topics. 
3.2.3 Training of topic model 
We randomly selected sentences from 8000 
documents in our corpus as training set and set 
number of topics Kas 10. Topic that contains most 
words in gene name dictionary and disease name 
dictionary was treated as a key topic. Then we 
manually assigned each word in gene name 
dictionary or disease name dictionary to key 
topic, and each word doesn?t belong to the two 
dictionaries was assigned to the most probable 
topic of itself. 
3.2.4 Prediction of key sentences 
The sentences containing interactions among 
genes or diseases were marked as ?Key? and 
others were marked as ?None?. A MaxEnt 
classifier 1  was trained based on the topic 
distribution.  
3.3 Extracting interactions from key 
sentences  
In order to extract interactions from sentences, 
we used phrase structure parsing which generates 
parse tree of a sentence that can be analyzed for 
relationships among words. Stanford parser tool2 
(de Marneffe et al. 2006) is employed for 
sentence parsing. Figure 1 shows an example of 
phrase structure parse tree. 
We extracted interactions by depth-first 
search in the parse tree. Each path between 
keyword nodes (e.g. gene or disease) and the root 
node were collected. A list of interaction verbs 
                                                           
1 http://morphix-nlp.berlios.de/manual/node36.html 
2 http://nlp.stanford.edu/software/stanford-
dependencies.shtml 
56
were compiled from VerbNet3, which consists of 
1048 verbs. We captured interactions from the 
paths which contain an interaction verb. 
 
Figure 1. Part of the phrase structure parse tree of 
the sentence ?AA, an inhibitor of p300, can suppress 
AR and its target genes, which can induce cells cycle 
arrest and apoptosis of Lncap cells through AR 
signaling.? 
For instance, two genes ?AA? and ?AR? could 
be extracted from sentence ?AA, an inhibitor of 
p300, can suppress AR and its target genes, 
which can induce cells cycle arrest and apoptosis 
of Lncap cells through AR signaling?. The path 
from ?AA? to ?AR? in the syntactic tree is 
?NP(AA) ->NP ->NP ->S ->VP(can) -
>VP(suppress) ->NP ->NP ->NP(AR)?, where 
?suppress (VP)? is an interaction verb. Therefore, 
we consider there is a ?suppression? interaction 
between ?AA? and ?AR?. 
4 Interaction network analysis 
The extracted interactions can be represented by 
an adjacency matrix, where 
1, =jiA
 if there is an 
edge between node i  and j , and 
0, =jiA
 if there 
is no edge between node i  and j . We establish 
disease-specific interaction network through 
searching for nodes within 3 distance unit from 
the target disease node. To gain the most related 
gene of the target disease, Centrality approach is 
used for calculating correlation of each gene 
based on its weight in this specific disease 
network. 
4.1 Degree centrality 
Degree centrality represents central tendency of 
each node in the network, the more direct 
connects it has, the more power it has in the 
network and so the more important it is. The 
degree centrality )(vCD  of node v  is calculated 
as follows.  
                                                           
3 http://verbs.colorado.edu/~mpalmer/projects/verbnet.html 
?
=
=
n
j
ijD AvC
1
)(                         (3) 
4.2 Betweenness centrality 
Betweenness centrality reflects the ability of a 
node taking control of other nodes? 
communication and the capability of controlling 
resources in the network. The more nodes that 
shortest paths pass through, the more 
communications of other nodes depend on it, and 
the more betweenness centrality the node has. 
The betweenness centrality )(vCB  of node v  is 
calculated as follows: 
?
???
=
Vtvs st
st
B
v
vC ?
? )(
)(                       (4)
 
where 
st?  is the total number of shortest paths 
from node s  to t  and )(vst?  is the number of 
paths that pass through v . 
4.3 Closeness centrality 
Closeness centrality reflects the ability a node 
has of not being controlled by other nodes. The 
closeness centrality of a node measures how 
close it is to other nodes in the whole network. 
The smaller the total distance from a node to 
other nodes in the network, the less dependency 
the node has on nodes in the network, and thus 
the higher its centrality is. The closeness 
centrality )(vC c  of node v  is calculated as 
follows. 
?
?
?=
vVt
tvd
C
GvC
\
),(2)(               (5)
 
where ),( tvdG  represents distance from node v  
to node t . 
4.4 Weighted centrality 
Formula (6) is applied to assigne weights for 
each measure of centrality equally:  
C
C
B
B
D
D
A C
vC
C
vC
C
vC
vC
3
)(
3
)(
3
)(
)( ++=            (6) 
where 
DC  represents the largest degree 
centrality of all nodes in the network, 
BC  
represents the largest betweenness centrality of 
the whole network and 
CC  represents the largest 
closeness centrality among all nodes. 
5 Results and Discussion 
As a common disease with high incidence, breast 
cancer gains much attention among researchers 
and has a rather large literature accumulation. 
57
We used breast cancer as testing disease for 
system evaluation.  
The corpus contains 3,209,385 sentences 
from 44,064 articles. All articles were extracted 
from PMC with keyword of ?breast cancer? 
(search date: March 1 2013). The gene name 
dictionary consists of 19,195 gene names 
searched from OMIM database while the disease 
dictionary consists of 5644 disease names from 
Genetic Association database (GAD).  
5.1 Evaluation on key sentence extraction 
MaxEnt classifier is applied with topic features 
for key sentences extraction. We randomly 
selected sentences from 8000 documents in our 
corpus as training set. We set number of topics 
K  as 10. The results of topics-words distribution 
predicted by Gibbs Sampling based topic model 
and topic correction are shown in Table 1.  
Topic0 Topic1 Topic2 Topic3 Topic4 
molecul
ar 
use increase cancer cluster 
receptor analysis rate organis
m 
compari
son body table exhibit gene melanog
aster clone differen
ce 
consider MLL identical 
organis
m 
significa
nt 
evolutio
n 
HBB place 
utator set degree DLC1 share 
band map due GRXCR
1 
rDNA 
expressi
on 
group position XRCC1 parental 
replicate score distance GST01 pattern 
Topic5 Topic6 Topic7 Topic8 Topic9 
indicate observe control chromos
ome 
growth 
test Demons
trate 
express carry medium 
line dominan
t 
suppress
or 
male assay 
determi
ne 
fact elegans female conditio
n experim
ent 
reductio
n 
germlin
e 
cross colony 
represen
t 
weak deficien
cy 
homozy
gous 
culture 
measure strong distinct segregat
ion 
syntheti
c derive enhance
r 
close recover survival 
conversi
on 
still segment hybrid cell 
Table 1: The results of topics-words distribution 
predicted by Gibbs Sampling based topic model and 
topic correction. 
There are totally 1037,637 key sentences were 
extracted, and the extraction precision is 66.4%. 
5.2 Interaction network analysis  
5.2.1 Degree centrality 
The breast cancer related gene-interaction 
network consists of 4636 distinct gene nodes and 
19,972 interactions extracted among them. 
Figure 2 illustrates degree centrality of the 
interaction network of breast cancer. Different 
color and size indicate different degree centrality 
of each node. The node in red with the largest 
degree centrality 1069 in the figure represents 
breast cancer. This indicates that 1069 genes 
have direct interactions with breast cancer 
referred in all sentences. 
Figure 2. Degree centrality of the gene-breast cancer 
interaction network. 
Figure 3 shows the relationship between each 
degree centrality and its count of nodes. 
 
Figure 3. The relationship between each degree 
centrality and its count of nodes. 
As shown in Figure 3, the node with 
maximum degree centrality 1069 is target disease 
while most of other nodes distribute from degree 
centrality of 1 to 10 which are considered as least 
related genes. Table 2 lists part of ranks of all 
1069 genes in the order of degree centrality. 
Gene Degree Centrality 
TNF 359 
EGFR 342 
CRC 301 
IL-6 245 
EGF 200 
BRCA1 195 
HR 193 
GAPDH 190 
AR 188 
ATM 148 
TP53 138 
BRCA2 94 
Table 2: Part of ranks of all 1069 genes in the order of 
degree centrality. 
58
From Table 2, we can find that BRCA1 and 
BRCA2 are known familial breast cancer genes 
which have gained authority validation. 
Although their mutations are not common in 
sporadic breast cancer patients, they accounts for 
approximately 80% to 90% among all hereditary 
breast cancer. 
TP53 is a kind of mutant gene with high 
penetrance which has also been verified 
association with breast cancer in genetics. 
Moreover, ATM and AR are low frequency 
genes belong to specific loci, about 5% to 10% 
of breast cancer relate to at least one or more 
changes in the susceptibility genes mentioned 
above. 
The result of CRC in contrast is more like 
some kind of institution's name: Cooperative 
Research Centre for Discovery of Genes for 
Common Human Diseases or the abbreviation of 
another disease: Colorectal Cancer (CRC). There 
haven?t been any evidence reveals direct 
correlation between CRC gene and breast cancer, 
we can only consider this as a misrecognition. 
In addition to genes described above, other 
genes in the list have also been verified in 
authoritative sites or papers. These results 
preliminarily verified the accuracy of our system. 
5.2.2 Betweenness centrality 
Figure 4 illustrates betweenness centrality of the 
interaction network of breast cancer. Color and 
size of each point reflect betweenness of the 
node, which indicate the ability to control other 
nodes in the network. Nodes in green have the 
minimum betweenness centrality while the color 
of jade-green shows larger betweenness 
centrality. Yellow nodes indicate betweenness 
centrality larger than jade-green and orange 
represents the largest.  
Figure 4. Betweenness centrality of the gene-breast 
cancer interaction network 
Figure 5 shows relationship between each 
betweenness centrality and its count of neighbors. 
 
Figure 5. Relationship between each betweenness 
centrality and its count of neighbors. 
As shown in Figure 5, the more adjacent nodes, 
the larger betweenness centrality. The node with 
most neighbors of 1068 has maximum 
betweenness centrality of 0.35 while most nodes 
in the network have the count of neighbors from 
0 to 200 with their betweenness centrality 
between 0 and 0.04. Table 3 lists part of ranks of 
all 1069 genes in the order of betweenness 
centrality. 
Gene Betweenness Centrality 
TNF 0.05981684 
EGFR 0.05912439 
CRC 0.04896846 
AR 0.02892632 
GAPDH 0.02877095 
AD 0.02863766 
IL-6 0.02545676 
HR 0.02381936 
BRCA1 0.02202402 
TP53 0.01603455 
ATM 0.01566084 
BRCA2 0.00507333 
Table 3: Part of ranks of all 1069 genes in the order of 
betweenness centrality. 
As can be seen from Table 3, the rank of 
betweenness centrality is approximately matched 
with the rank of degree centrality. TNF, EGFR 
and CRC are still the highest ranked genes while 
IL-6, AR, HR , GAPDH and ATM simply 
exchanged their order. AR, androgen receptor, 
has a quick raise in the rank list. It plays a vital 
role in the development and maintenance of male 
reproductive function and the cause of prostate 
cancer, but the effect and function on breast 
cancer of AR have not been clear until 2010 
(most of the literature published before 2010). 
This result shows that the genes excavated by our 
system not only include genes in the known 
interaction network, but also reflect research 
59
tendency at present or in a certain period of time. 
This also indicates the effectiveness of 
understanding scientific research tendency of our 
system. 
As the definition of betweenness centrality, it 
reflects the ability to affect other nodes in the 
network. If a gene interacts with another gene 
through an intermediate gene such as suppression 
or promotion, then the role played by this 
intermediate gene is decisive in this association. 
The more intermediate roles played in 
associations, the greater the influence of the gene 
in the network. Similarly, among all genes in the 
neighborhood of a specific gene, the greater the 
betweenness centrality of a gene, the more 
influence it has on that specific gene.  
5.2.3 Closeness centrality 
Figure 6 illustrates closeness centrality of the 
interaction network of breast cancer. 
 
Figure 6. Closeness centrality of the gene-breast 
cancer interaction network. 
As can be seen from Figure 6, red node at the 
center of the network represents breast cancer 
and neighboring orange nodes stand for direct 
related genes while peripheral nodes in green 
represents least related genes. Figure 7 shows 
relationship between each closeness centrality 
and its count of neighbors. 
 
Figure 7. Relationship between each closeness 
centrality and its count of neighbors. 
Figure 7 shows the tendency of closeness 
centrality in the network while number of 
neighbors increases. There is an approximate 
positive correlation between the count of 
neighbors and the closeness centrality of nodes 
but not so obvious compared with betweenness 
centrality or degree centrality. For instance, the 
closeness centrality ranges from 0.14 to 0.34 for 
nodes with only one neighbor. This tendency 
represents that closeness centrality reflect 
geographical centricity of each node more 
efficiently compared with degree centrality and 
betweenness centrality with less dependence on 
count of neighbors. For example, if a node has 
only one edge to the center of the network, this 
node is bound to own large closeness centrality 
even though this edge is the only edge it has. 
Meanwhile, another node has much more than 
one edge but far away from the center of the 
network, the closeness centrality of it can never 
be larger than the former one. Table 4 lists part 
of ranks of all 1069 genes in the order of 
closeness centrality. 
Gene Closeness Centrality 
TNF 0.43612418 
EGFR 0.43550963 
CRC 0.4247366 
PTEN 0.41920608 
IL-6 0.41814738 
AR 0.41092005 
EGF 0.40954064 
BRCA1 0.40914306 
STAT3 0.4088544 
MMP-9 0.40386793 
HR 0.40330579 
MMP-2 0.40031085 
Table 4: Part of ranks of all 1069 genes in the order of 
closeness centrality. 
Table 4 shows that list ordered by closeness 
centrality is generally similar to list ordered by 
degree centrality and betweenness centrality. 
TNF, EGFR and CRC are still highest ranking 
genes. However, genes like STAT3, MMP-9 and 
MMP-2 appear firstly in the list where STAT3 
ranks 18 in degree centrality and 14 in 
betweenness centrality. The details of STAT3 
has been clearly described in Hsieh FC et al. 
STAT3 full-called signal transducer and 
activator of transcription 3, which is often 
detected in breast cancer tissues and its cell lines. 
STAT3 has already been defined as an oncogene 
since its activated form in nude mice can produce 
malignant transformation of cultured cells and 
ultimately form tumors. MMP-9 and MMP-2 are 
gelatinase, proteolytic enzymes involved in 
60
process of tumor invasion which is considered as 
a potential tumor marker in breast cancer.  
All these three genes can be identified as 
direct related genes with breast cancer. These 
associations which are not obvious in degree 
centrality and betweenness centrality indicating 
the effectiveness of closeness centrality in 
finding related gene to a specific disease. 
5.3 Result Evaluation  
We enumerate 31 top genes ranked with 
weighted centrality considered as related to 
breast cancer due to our system. Table 5 lists the 
gene or disease symbol, ID, and full name from 
OMIM database. 
Gene 
Symbol 
Gene 
ID 
Gene Full Name 
TNF *191160 TUMOR NECROSIS FACTOR 
EGFR *131550 EPIDERMAL GROWTH FACTOR 
RECEPTOR 
CRC  COLORECTAL CANCER 
PTEN +601728 PHOSPHATASE AND TENSIN 
HOMOLOG 
IL-6 *147620 INTERLEUKIN 6 
AR *313700 ANDROGEN RECEPTOR 
BRCA1 *113705 BREAST CANCER 1 GENE 
EGF *131530 EPIDERMAL GROWTH FACTOR 
GAPDH *138400 GLYCERALDEHYDE-3-
PHOSPHATE DEHYDROGENASE 
HR *602302 HAIRLESS, MOUSE, HOMOLOG 
OF 
AML #601626 LEUKEMIA, ACUTE MYELOID 
CD4 *186940 CD4 ANTIGEN 
STAT3 *102582 SIGNAL TRANSDUCER AND 
ACTIVATOR OF 
TRANSCRIPTION 3;  
AD #104300 ALZHEIMER DISEASE 
MMP-9 *120361 MATRIX METALLOPROTEINASE 
9 
MS #126200 MULTIPLE SCLEROSIS, 
SUSCEPTIBILITY TO 
RD #111620 RADIN BLOOD GROUP ANTIGEN 
MYC *190080  V-MYC AVIAN 
MYELOCYTOMATOSIS VIRAL 
ONCOGENE HOMOLOG 
S6 *185520 SURFACE ANTIGEN 6 
TP53 *191170 TUMOR PROTEIN p53 
ATM *607585 ATAXIA-TELANGIECTASIA 
MUTATED GENE 
IL-8 *146930 INTERLEUKIN 8 
AP1  activator protein-1 
MMP-2 *120360 MATRIX METALLOPROTEINASE 
2 
GC +139200 GROUP-SPECIFIC COMPONENT 
FBS #227810 FANCONI-BICKEL SYNDROME 
ES #612219 EWING SARCOMA 
RA #180300 RHEUMATOID ARTHRITIS 
CXCR4 *162643 CHEMOKINE, CXC MOTIF, 
RECEPTOR 4 
IL-10 *124092 INTERLEUKIN 10 
BRCA2 *600185 BRCA2 GENE 
Table 5: The gene or disease symbol, ID, and full 
name from OMIM database. 
The Genes and diseases in Table 5 inferred by 
degree, betweenness, closeness centralities and 
the relevance are listed in Table 6. 
Gene Degree Betweenness Closeness Relevance 
TNF 359 0.05985761 0.43401678 Yes 
EGFR 342 0.05904224 0.4332496 Yes 
CRC 301 0.04875035 0.4225186 No 
PTEN 229 0.03029572 0.41695765 Yes 
IL-6 245 0.02541463 0.41613797 Yes 
AR 188 0.02883127 0.40890333 Yes 
BRCA1 195 0.02190664 0.40704484 Yes 
EGF 200 0.01992148 0.40747222 Yes 
GAPDH 190 0.02868382 0.39946818 Yes 
HR 193 0.02371613 0.40136172 Yes 
AML 177 0.02417702 0.39779619 Disease 
CD4 179 0.01865428 0.40467501 Yes 
STAT3 182 0.01563346 0.40683148 Yes 
AD 159 0.02853342 0.39769428 Yes 
MMP-9 160 0.01347212 0.40188126 Yes 
MS 148 0.01806096 0.39967388 Disease 
RD 166 0.0113587 0.3970162 No 
MYC 141 0.02132884 0.39052411 Yes 
S6 136 0.01504618 0.39912581 Yes 
TP53 138 0.01607533 0.39607076 Yes 
ATM 148 0.01556309 0.39170662 Yes 
IL-8 146 0.00944026 0.40108518 Yes 
AP1 141 0.01531257 0.39286317 Yes 
MMP-2 138 0.01241541 0.39837468 Yes 
GC 131 0.01515181 0.39055686 No 
FBS 126 0.0117904 0.39749061 No 
ES 128 0.01325333 0.39283003 No 
RA 133 0.01256221 0.3894464 Disease 
CXCR4 138 0.01019905 0.39039316 Yes 
IL-10 128 0.00680617 0.39045862 Yes 
BRCA2 94 0.00504479 0.38194046 Yes 
Table 6: Genes inferred by degree, betweenness, and 
closeness centralities and the relevance. 
As results listed in Table 6, all 31 top ranked 
genes and diseases have been checked relevance 
with breast cancer through NCBI database. 
Terms marked as ?No? are none-relevant to 
breast cancer and words marked as ?disease? are 
related diseases to breast cancer. The accuracy 
rate is 83.9% for these top 31 genes and diseases 
and 74.2% for these top 31 genes. 
6 Conclusion 
Understanding the role of genetics in diseases is 
one of the major goals of the post-genome era. 
We have proposed an automatic gene-disease 
association extraction approach based on text 
mining and network analysis.  
Gene-breast cancer interaction network 
analysis demonstrated that degree, betweenness, 
and closeness centralities can estimate disease 
related genes effectively. And closeness 
centrality is able to find disease related genes 
which are not obvious ranked by degree 
centrality and betweenness centrality. In addition, 
this result showed that the genes excavated by 
our system not only include genes in the known 
interaction network, but also reflect research 
tendency at present or in a certain period of time. 
This also indicates the effectiveness of 
understanding scientific research tendency of our 
system. 
61
Acknowledgment 
This research has been partially supported by the 
National High-Tech Research & Development 
Program of China 863 Program under Grant No. 
2012AA011103, National Natural Science 
Foundation of China under Grant No. 61203312, 
National Program on Key Basic Research Project 
of China (973 Program) under Grant No. 
2014CB347600, the Scientific Research 
Foundation for the Returned Overseas Chinese 
Scholars, State Education Ministry, and Key 
Science and Technology Program of Anhui 
Province under Grant No. 1206c0805039. 
References  
Adamic, L.A., Wilkinson, D., Huberman, B.A., and 
Adar, E. 2002. A literature based method for 
identifying gene-disease connections. In 
Proceedings of the IEEE Computer Society 
Conference on Bioinformatics, Stanford, CA, pp. 
109?117. 
Aerts, S., Lambrechts, D., Maity, S., Van Loo, P., 
Coessens, B., De Smet, F., Tranchevent, L.-C. C., 
De Moor, B., Marynen, P., Hassan, B., Carmeliet, 
P. & Moreau, Y. 2006. Gene prioritization through 
genomic data fusion. Nature biotechnology 
24(5):537?544. 
Al-Mubaid, H., and Singh, R.K. 2005. A new text 
mining approach for finding protein-to-disease 
associations. Am J Biochem Biotechnol, 1:145?152. 
Bader, G., Betel, D., Hogue, C. 2003. Bind ? the 
biomolecular interaction network database. Nucleic 
Acids Research, 31, pp. 248?250. 
Benson, D.A., Karsch-Mizrachi, I., Lipman, D.J., 
Ostell, J., Ouellette, B.F.F., Rapp, B.A. and 
Wheeler, D.L. 2000. GenBank. Nucleic Acids 
Research, 28. pp. 15?18. 
Blei, D. and McAuliffe, J. 2007. Supervised topic 
models. Neural Information Processing System 21.  
Blei, D.M., Ng, A., Jordan, M.I. 2002. Latent 
Dirichlet Allocation. NIPS. 
Chen, J.Y., Shen, C., Sivachenko, A.Y. 2006. Mining 
Alzheimer disease relevant proteins from 
integrated protein interactome data. Pac. Symp. 
Biocomput., 11, 367?378. 
Chen, J., Bardes, E. E., Aronow, B. J. & Jegga, A. G. 
2009. Toppgene suite for gene list enrichment 
analysis and candidate gene prioritization, Nucleic 
Acids Research, 37(Web Server issue): gkp427+. 
Christopher D. Manning and Hinrich Schjtze. 1999. 
Foundations of statistical natural language 
processing. Cambridge, MA: MIT Press. 
Chun, H., Tsuruoka, Y., Kim, J. Shiba, R., Nagata, N., 
Hishiki, T., and Tsujii, J. 2006. Extraction of gene-
disease relations from MEDLINE using domain 
dictionaries and machine learning. In Proceedings 
of the Pacific Symposium on Biocomputing, pp. 4?
15. 
Erkan, G., Radev, D., Ozgur, A. 2007. Semi-
supervised classification for extracting protein 
interaction sentences using dependency parsing. In 
Proceedings of the Joint Conference on Empirical 
Methods in Natural Language Processing and 
Computational Natural Language Learning, 
Prague, Czech Republic, pp. 228?237. 
Freudenberg, J., and Propping, P. 2002. A similarity-
based method for genomewide prediction of 
disease-relevant human genes. Bioinformatics, 18 
(Suppl. 2), pp. S110?S115. 
Gillick, D., Sentence Boundary Detection and the 
Problem with the U.S. NAACL 2009. pp. 241?244, 
Glenisson, P., Coessens, B., Vooren, S. V., Mathys, J., 
Moreau, Y., and De Moor, B. 2004. TXTGate: 
profiling gene groups with text-based information. 
Genome Biol., 5, R43. 
Griffiths, T., 2002. Gibbs sampling in the generative 
model of Latent Dirichlet Allocation.  
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=
10.1.1.138.3760. 
Huang, D.W., Sherman, B.T., and Lempicki, R.A. 
2009. Systematic and integrative analysis of large 
gene lists using david bioinformatics resources. 
Nat. Protoc., 4: 44?57. 
Hutz, J., Kraja, A., McLeod, H. & Province, M. 2008. 
Candid: a flexible method for prioritizing candidate 
genes for complex human traits., Genetic 
Epidemiology 32(8): 779?790. 
Kerrien, S., Aranda, B., Breuza L., Bridge, A., 
Broackes-Carter, F., and Chen, C. 2002. The IntAct 
molecular interaction database in 2012. Nucleic 
Acids Research, 40, pp. 841?846. 
Klein, D. and Christopher D. M. 2003. Accurate 
Unlexicalized Parsing. In Proceedings of the 41st 
Meeting of the Association for Computational 
Linguistics, pp. 423?430. 
Krallinger, M., Leitner, F., Valencia, A. 2010. 
Analysis of biological processes and diseases using 
text mining approaches. Methods Mol Biol, 593:  
341?82. 
Ma, X., Lee, H., Wang, L. & Sun, F. 2007. Cgi: a new 
approach for prioritizing genes by combining gene 
expression and protein-protein interaction data, 
Bioinformatics 23(2): 215?221. 
Martin, D., Brun. C., Remy, E., Mouren, P., Thieffry, 
D., and Jacq, B. 2004. GOToolbox: functional 
62
analysis of gene datasets based on gene ontology. 
Genome Biol., 5, R101. 
McKusick,V. 2007. Mendelian inheritance in man and 
its online version, OMIM. Am. J. Hum. Genet., 80, 
pp. 588?604. 
Morrison, J. L., Breitling, R., Higham, D. J., and 
Gilbert, D. R. 2005. Generank: using search engine 
technology for the analysis of microarray 
experiments., BMC Bioinformatics 6: 233. URL: 
http://www.biomedsearch.com/nih/GeneRank-
using-search-engine-technology/16176585.html 
OMIM. 2007. Online Mendelian inheritance in man, 
OMIM (TM).McKusick-Nathans Institute of 
Genetic Medicine, Johns Hopkins University 
(Baltimore, MD) and National Center for 
Biotechnology Information, National Library of 
Medicine (Bethesda, MD). 
?zg?r, A., Vu, T., Erkan, G., and Radev D. R. 2008. 
Identifying gene-disease associations using 
centrality on a literature mined gene-interaction 
network. Bioinformatics, 24. pp. 277?285. 
Schwikowski, B., Uetz, P., and Fields, S. 2000. A 
network of protein-protein interactions in yeast. 
Nat.Biotechnol., 18, pp. 1257?1261. 
Subramanian, A., Tamayo, P., Mootha, V.K., 
Mukherjee, S., Ebert, B.L., Gillette, M.A., 
Paulovich, A., Pomeroy, S.L., Golub, T.R., Lander, 
E.S., and Mesirov, J.P. 2005. Gene set enrichment 
analysis: a knowledge-based approach for 
interpreting genome-wide expression profiles. Proc. 
Natl Acad. Sci. USA, 102, pp. 15545?15550. 
Hwang, T., Zhang, W., Xie, M., Liu, J., and Kuang, R. 
2011. Inferring disease and gene set associations 
with rank coherence in networks. Bioinformatics, 
27(19): 2692?2699.  
Temkin, J. and Gilder, M. 2003. Extraction of protein 
interaction information from unstructured text 
using a context-free grammar. Bioinformatics, 
19:2046?2053. 
Wuchty, S., Oltvai, Z.N., Barab?si, A.L. 2003. 
Evolutionary conservation of motif constituents in 
the yeast protein interaction network. Nat. Genet., 
35:176?179. 
Yakushiji, A., Miyao, Y., Tateisi, Y., and Tsujii J. 
2005. Biomedical information extraction with 
predicate argument structure patterns. In 
Proceedings of the Eleventh Annual Meeting of the 
Association for Natural Language Processing, pp. 
93?96. 
Zanzoni, A., Montecchi-Palazzi, L., Quondam, M., 
Ausiello, G., Helmer-Citterich, M., Cesareni, G. 
2002. Mint: A molecular interaction database. 
FEBS Letters, 513: 135?140. 
 
63
Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 80?84,
Dublin, Ireland, August 23-29 2014.
Real Time Early-stage Influenza Detection with Emotion Factors from 
Sina Microblog 
 
 
Xiao SUN 
School of Computer and In-
formation 
Hefei University of Technol-
ogy 
Hefei, Anhui, China 
Anhui Province Key Labora-
tory of Affective Computing 
and Advanced Intelligent 
Machine 
suntian@gmail.com  
Jiaqi YE 
School of Computer and In-
formation 
Hefei University of Technol-
ogy 
Hefei, Anhui, China 
Anhui Province Key Labora-
tory of Affective Computing 
and Advanced Intelligent 
Machine 
lane_3000@163.com 
Fuji REN 
School of Computer and In-
formation 
Hefei University of Technol-
ogy 
Hefei, Anhui, China 
Faculty of Engineering, Uni-
versity of Tokushima 
Tokushima, Japan 
ren2fuji@gmail.com 
 
  
 
Abstract 
Influenza is an acute respiratory illness that occurs every year. Detection of Influenza in its 
earliest stage would reduce the spread of the illness. Sina microblog is a popular microblog-
ging service, provides perfect sources for flu detection due to its real-time nature and large 
number of users. In this paper we investigate the real-time flu detection problem and describe 
a Flu model with emotion factors and sematic information (em-flu model). Experimental re-
sults show the robustness and effectiveness of our method and we are hopeful that it would 
help health organizations in identifying flu outbreak and take timely actions to control. 
1 Introduction 
Influenza is a highly contagious acute respiratory disease caused by influenza virus. As the highly 
genetic variation, influenza can cause global epidemic, which not only brought huge dis-asters to peo-
ple?s life and health, but also have significant disruptions to economy. There are about 10-15% of 
people who get influenza every year and results in up to 50 million illnesses and 500,000 deaths in the 
world each year. Influenza is a worldwide public health problem and there are no effective measures 
to control its epidemic at present. The prevalence of influenza in China is one of the most notable 
problems.  
The epidemic of SARS, H1N1 and H5N9 influenza make us realized that people really need to ex-
pand surveillance efforts to establish a more sensitive and effective precaution indicator system for 
infectious disease forecasting. In order to detect influenza epidemic timely and im-prove the ability of 
early precaution, the research of early forecasting technique is urgently needed. 
Nowadays influenza surveillance systems have been established via the European Influenza Surveil-
lance Scheme (EISS) in Europe and the Centre for Disease Control (CDC) in the US to collect data 
from clinical diagnoses. The research of forecasting methods started relatively late in China and these 
systems have about two-week delay. The need for efficient sources of data for forecasting have in-
creased due to the Public health authorities? need to forecast at the earliest time to ensure effective 
treatment. Another surveillance system is Google?s flu trends service which is web-based click flu re-
porting system. Google?s flu trend uses the linear model to link the influenza-like illness visits. 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 
80
Sina Weibo is a Chinese popular microblog service that can potentially provide a good source for 
early stage flu detection due to its large data scale and real-time features. When flu breaks out, infect-
ed users might post related microblog with corresponding emotions in a timely way which can be re-
garded as indicators or sensors of Influenza. Based on the real-time data of mi-croblog, there has been 
many applications such as earthquake detection (Sakaki T et al., 2010), public health tracking (Collier 
N, 2012; Paul M J et al., 2011) and also flu detection (Achrekar H et al., 2011; Culotta A,2010).  
The measures of collecting clinical diagnoses and web-based clicks on key word with linear model 
are quite good but not fair enough. Our research tries to use the big real-time data as re-sources and 
design a machine learning mode with the emotional factors and sematic information to help find the 
break point of influenza. 
The rest of this paper is organized as follows: In section 2, we describe our Flu model with emotion 
factors (em-flu model). We describe the preparation of our dataset in Section 3. Exper-imental results 
are illustrated in Section 4. We conclude this paper in Section 5. 
2 Em-flu Model 
Existing works on flu prediction suffer the following limitations: Spatial information is seldom con-
sidered and sematic or emotion factors are out of consideration. To address this problem, in this paper, 
we try to introduce an unsupervised approach called Em-flu Markov Network for early stage flu detec-
tion. Spatial information are modelled in a four-phase Markov switching model, i.e. non-epidemic 
phase (NE), rising epidemic phase (RE), stationary epidemic phase (SE) and declining epidemic phase 
(DE). Our approach assumes microblog users as "sensors" and collective posts containing flu key-
words as early indicators. Our algorithm can capture flu outbreaks more promptly and accurately 
compared with baselines. Based on our proposed algorithm, we create a real-time flu surveillance sys-
tem. For early stage flu detection, we use a probabilistic graphical Bayesian approach based on Mar-
kov Network. The key of the flu detection task is to detect the transition time from non-epidemic 
phase to epidemic phase.  
Basically, our model is based on a segmentation of the series of differences into an epidemic and a 
non-epidemic phase using a four-stage Markov switching model. Suppose we collect flu related mi-
croblog data from N location. For each location i?[1,N], we segment the data into a time series. Zi,t 
denotes the phase location i takes on at time t. Zi,t=0,1,2,3 correspond to the phase NE, RE SE and DE. 
Yi,t is the observant variable, which denotes the number of flu related microblog at time t, join in loca-
tion i. ?Yi,t =(Yi,t ? Yi,t-1)/ Yi,t-1. The underlying idea of Markov switching models is to associate each 
Yi,t with a random variable Zi,t that determines the conditional distribution of Yi,t given Zi,t. In our case, 
each Zi,t. is an unobserved random variable that indicates which phase the system is in. Moreover, the 
unobserved sequence of Zi,t. follows a four-stage Markov chain with transition probabilities. For loca-
tion i, N(i) denotes the subset containing its neighbors. We simplify the model by only considering 
bordering states in N(i). 
We model the spatial information in a unified Markov Network, where the phase for location i at 
each time is not only dependent upon its previous phase, but its neighbors. In this work, for simplifica-
tion, we only treat bordering States as neighbors. Since the influence from non-bordering States can be 
transmitted through bordering ones, such simplification makes sense and experimental results also 
demonstrate this point. A Generalized Linear Model is used to integrate the spatial information in a 
unified framework. For location i at time t, the probability that Zi,t takes on value Z is illustrated as 
follows: 
, 1 , , , 1 , ,
, , 1 , 1
, , , 1 , , , 1
exp( , , , )P Pr( | , , ( )exp( , , , )
i t i t i t i t j t i t
i t j t i t
j t i t i t i t i t i tz
Z Z Z Z ZZ Z Z j N iZ Z Z Z Z
? ?
? ?
? ?
? ?? ? ??? ? ? ??? ?? ??
?
? ?         (1) 
Where ?  and ?  respectively correspond to parameters that control temporal and spatial influence. 
We give a non-informative Gaussian prior for each element in ?  and? : 
2
, ,~ (0, )i j i jN? ?           2, ,~ (0, )i j i jN? ?                 (2) 
Next, we describe the characteristics for the dynamics of different phases. Generally speaking, the 
course of influenza may last a week or two, for a single microblog user, we believe his or her mi-
croblog contents will record a series of feelings when user is sick or catching flu. When a person got 
the flu, he will go through NE, RE, SE, DE phases; the main emotion in these four phases would natu-
81
rally change by the phase change to another phase. All these individuals? data could be combined into 
datasheet segmented by time. From the statistics theories, the dynamics for NE, RE, DE and SE can be 
characterized as Gaussian process: 
,
2
( ) ( )|Pr( ) ~ (E , )day t dai t y tNY z ??                       (3) 
Where Eday(t) corresponds to the average microblog records? number every day, and 2 ( )day t?  corre-
sponds to the variance of the records. 
 
3 Data Preparation 
We extend our earlier work on Sina microblog data acquisition and developed a crawler to fetch data at 
regular time intervals. We fetched microblog records containing indicator words shown in Table 1 and col-
lect about 4 million flu-related microblog starting from January 2013 to January 2014. Location details can 
be obtained from the profile page. We select tweets whose location are in China and discard those ones with 
meaningless locations. 
 
Indicator words ???(pectoral),??(transfusion),??(cold),??(running nose),??(flu),??
(cough),???(antibiotic),???(Sore throat),??(influenza),??(fever),???
(high fever),??(snot) 
Table 1: Indicator seed words set for data collection 
 
Not all microblog containing indicator keywords indicate that the user is infected. Meanwhile the indi-
cator words list may not be perfect, so the indicator words list needs to expand from the data we have and 
the dataset needs to be processed before be used for our task.  
The words in Table 1 will be used as seed words to find the initial dataset and then computing vector in 
the dataset to find other keyword which can be the representations of seed words. In this way, words list 
could be expanded and adapt the changes of cyber word. The necessity of filtering in real-time task has 
been demonstrated in many existing works (Aramaki E et al., 2011; Sakaki T et al., 2010).To filter out these 
bias tweets, we first prepared manually labeled training data, which was comprised of 3000 microblog rec-
ords containing key words. We manually annotate them as positive examples and negative ones.  
We built a classifier based on support vector machine. We use SVMlight with a polynomial kernel, and 
employ the following simple text-based features. 
Feature A: Collocation features, representing words of the query word within a window size of three. 
Feature B: unigrams, denoting the presence or absence of the terms from the dataset. 
Performances for different combinations of features are illustrated at Table 2. We observe that A+B is 
much better than A or B. So in our following experiments, microblog are selected according to a classifier 
based on feather A+B. 
 
Features Accuracy Precision Recall 
A 84.21% 82.31% 89.40% 
B 85.10% 84.92% 87.00% 
A+B 87.40% 88.75% 89.64% 
Table 2: Result of different combinations of features for filtering 
 
We briefly demonstrate the relatedness between microblog data and CNIC (Chinese National Influenza 
Center) surveillance weekly report data, which would support the claim that microblog data can be used for 
the flu detection task. We observe that performing svm filtering and microblog selection would definitely 
make microblog data more correlated with real world CNIC data. 
For these flu-related microblog records, we generate another microblog web crawler to deal with 
every record. For every record?s user, we use this tool to backup user?s microblog content and cut rec-
ords by a window of time with one week before and after the flu-related microblog record which we 
had captured. Then the emotional SVM is established to help get the trend of these series of microblog 
records. 
 
82
4 Experiments and Data Analysis 
The main goal of our task is to help raise an alarm at those moments when there is a high probability 
that the flu breaks out. In real time situations, for each time, available data only comes from the previous 
days, and there is no known information about what will happen in the following days or week. By adding 
the data day by day, we calculate the posterior probability for transiting to epidemic states based on previ-
ous observed data. The sum over parameter Zi,t-1 and Zj,t makes it infeasible to calculate. We use Gibbs 
Sampling by first sampling Zi,t-1 and Zj,t first and then attain the value of Zi,t given Zi,t-1,Zi,t-1,?:  
, , , , 1 , , 1arg max (Z z | Z , Z ,...,Y ,Y ,...)i t i t j t i t j t i tZ P ? ?? ?                                     (3) 
Figure 1 shows the global distribution of DE, SE and RE in the year of 2013. The left hand side figure 
corresponds to number of flu-related microblog records overtime. Purple symbols denote the phase of RE, 
red symbols denote the phase of SE and white symbols denote the phase of DE.  
Figure 2 shows the result of searching key words like influenza on Baidu Index platform. Compared to 
Figure 1 seems our influenza curve matches well. The interesting thing we observe from figure 1 is that if 
the percentage of RE > 0.5, there is strong possibility to convince the flu alarm is coming.  
  
 Figure 1: Predictions of the year 2013 
 
 Figure 2: Searching Resutl on Baidu Index platform 
 
For comparison, we employ the following baseline in this paper: 
Average: Uses the averager frequency of micrblog records containing keywords based on previous 
years as the threshold. 
Two-Phase: A simple version of our approach but using a simple two-phase in Markove network. 
We only report partial experimental results for one province. As we can see from figure 3, our 
model can best fit the actual microblog data and semms stable. The other two measures also represent 
the actual truth but not stable enough. 
 
 Figre 3: Prediction of Anhui province of the year 2013 
83
5 Conclusions 
In this paper, we introduced an unsupervised Bayesian model based on Markov Network based on four 
phases and microblog emotional factors are appended in the model to help detect early stage flu detection 
on Sina Microblog. We test our model on real time datasets for multiple applications and experiments re-
sults demonstrate the effectiveness of our model. We are hopeful that our approach would help to facilitate 
timely action by those who want to decrease the number of unnecessary illnesses and deaths. At present, the 
method also has a few shortcomings; we will continually develop it for further research and exploration. 
 
ACKNOWLEDGMENT 
The work is supported by National Natural Sci-ence Funds for Distinguished Young Schol-
ar(No.61203315) and 863 National Advanced Tech-nology Research Program of China (NO. 
2012AA011103), and also supported by the Funding Project for AnHui Province Key Laboratory of Affec-
tive Computing and Advanced Intelligent Machine, HeFei University of Technology.  
 
Reference 
Sakaki T, Okazaki M, Matsuo Y. 2010. Earthquake shakes Twitter users: real-time event detection by so-cial 
sensors[C]//Proceedings of the 19th international conference on World wide web. ACM, 851-860. 
Collier N. 2012.  Uncovering text mining: A survey of current work on web-based epidemic intelli-gence[J]. 
Global public health, 7(7): 731-749. 
Paul M J, Dredze M. You are what you Tweet: Analyzing Twitter for public health[C]//ICWSM. 2011. 
Achrekar H, Gandhe A, Lazarus R, et al. 2011. Predicting flu trends using twitter data[C]//Computer Communi-
cations Workshops (INFOCOM WKSHPS), 2011 IEEE Conference on. IEEE, 702-707. 
Culotta A. 2010. Towards detecting influenza epidemics by analyzing Twitter messag-es[C]//Proceedings of the 
first workshop on social media analytics. ACM, 115-122. 
Aramaki E, Maskawa S, Morita M. 2011. Twitter catches the flu: detecting influenza epidemics using Twit-
ter[C]//Proceedings of the Conference on Empirical Methods in Natural Language Processing. Asso-ciation 
for Computational Linguistics, 1568-1576. 
Lamb A, Paul M J, Dredze M. 2013. Separating fact from fear: Tracking flu infections on twit-
ter[C]//Proceedings of NAACL-HLT.789-795. 
Sakaki T, Okazaki M, Matsuo Y. 2010. Earthquake shakes Twitter users: real-time event detection by so-cial 
sensors[C]//Proceedings of the 19th international conference on World wide web. ACM, 851-860. 
Achrekar H. 2012. ONLINE SOCIAL NETWORK FLU TRACKER A NOVEL SENSORY APPROACH TO 
PREDICT FLU TRENDS[D]. University of Massachusetts, 
Aschwanden C. 2004.Spatial Simulation Model for Infectious Viral Diseases with Focus on SARS and the 
Common Flu[C]//HICSS. 
84
