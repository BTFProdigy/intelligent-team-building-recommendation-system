Towards Translingual Information Access 
using Portable Information Extraction 
Michael White, Claire Cardie, Chung-hye Han, Nari Kim, # 
Benoit Lavoie, Martha Palmer, Owen Rainbow,* Juntae Yoon 
CoGenTex, Inc. 
Ithaca, NY, USA 
\[mike,benoit.owen\] 
@cogentex.com 
Institute for Research in 
Cognitive Science 
University of Pennsylvania 
Philadelphia, PA, USA 
chunghye@babel, ling. upenn, edu 
\[ nari, mpalmer, j tyoon } 
@linc. cis.upenn.edu 
Dept. of Computer Science 
Cornell University 
Ithaca, NY, USA 
cardie@cs, cornell, edu 
Abstract 
We report on a small study undertaken to 
demonstrate the feasibility of combining 
portable information extraction with MT in 
order to support translingual information 
access. After describing the proposed 
system's usage scenario and system design, 
we describe our investigation of transferring 
information extraction techniques developed 
for English to Korean. We conclude with a 
brief discussion of related MT issues we plan 
to investigate in future work. 
1 Introduction 
In this paper, we report on a small study 
undertaken to demonstrate the feasibility of 
combining portable information extraction with 
MT in order to support ranslingual information 
access. The goal of our proposed system is to 
better enable analysts to perform information 
filtering tasks on foreign language documents. 
This effort was funded by a SBIR Phase I award 
from the U.S. Army Research Lab, and will be 
pursued further under the DARPA TIDES 
initiative. 
Information extraction (IE) systems are 
designed to extract specific types of information 
from natural language texts. In order to achieve 
acceptable accuracy, IE systems need to be 
tuned for a given topic domain. Since this 
domain tuning can be labor intensive, recent IE 
research has focused on developing learning 
algorithms for training IE system components 
(cf. Cardie, 1997, for a survey). To date, 
however, little work has been done on IE 
systems for languages other than English 
(though cf. MUC-5, 1994, and MUC-7, 1998, 
for Japanese IE systems); and, to our knowledge, 
none of the available techniques for the core task 
of learning information extraction patterns have 
been extended or evaluated for multilingual 
information extraction (though again cf. MUC-7, 
1998, where the use of learning techniques for 
the IE subtasks of named entity recognition and 
coreference r solution are described). 
Given this situation, the primary objective of 
our study was to demonstrate he feasibility of 
using portable--i.e., easily trainable--IE 
technology on Korean documents, focusing on 
techniques for learning information extraction 
patterns. Secondary objectives of the study were 
to elaborate the analyst scenario and system 
design. 
2 Analyst Scenario 
Figure 1 illustrates how an intelligence analyst 
might use the proposed system: 
? The analyst selects one or more Korean 
documents in which to search for 
information (this step not shown). 
# Current affiliation: Konan Technology, Inc., Korea, nari@konantech.co.kr 
* Current affiliation: A'IT Labs-Research, Florham Park, NJ, USA, rambow@research.att.com 
31 
Ouery  
Find Report 
Event: Nest !!lg ........... 
sourcn:l . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  ~ ~ 
sate :  I ................. ' ......................... ' ................. i 
Locat Ion: I~u.'~h K..e~.e..a.; ..................................... j I~ 
Part clpant : I .................................................................. i 
Iseun:i~'North Korea" AND "missiles" i 
I 
Response  to  Ouery  
The reports Indicate 2 meetings held In South Korea on the 
issues of North Korea anti missiles: 
Sources Translated Extracts 
Joon,ap~l A ~ ~  
. . . .  I ,4 ~t ln ,  g ~# ,#~=1# o,1 Apf J l  ~ sLYout tP~ I10t 
,!nerF, orea j /ine? ~t~wn Saoul end Tokyo for  the 
Noes / - -  t~Q I ela~gen?? d~/tu~tlons ~uc/t eg Alottl I  Kofgm'~ 
Trans la t ion  o f  Korean  Source  Repor t  
\[Joongang Dally\] 
Korean. Japanese H in i s ters  Discuss NK Po l i cy  
The tmo ministers ~9rsed that any further launching of a 
missile by North Korean would undermine the security of 
~Northeast Asia and the Korea, the United States and Japan 
should take Joint steps against the North Korean missile 
threat. 
}-long requested that Koeura cork to normalize Japan's 
relations with North Korea. rather than cutting channels 
of dialogue bet#men the two countries. 
Koeura said that i f  North Korea continues Its missile 
testing, the Japanese government will definitely stop 
making contributions to KEDO. 
The tee ministers also tentatively agreed that J~anese 
primo minister Kslzo Obuchl should make a state visit  to 
Korea on or around Nerch 20. 
Korean  Source  Repor t  
E t -~ "~I -D lX i '~  ~oo ~ Cll~o" 
oj_a, xd~. ~ ~.\]Ol D IXF~ ~F ~,~FI,,t ~'-9-, ~.~OF ~t~l.~. ~t l  
ud~Otl ~l . : , r t}  ~\]l~i/ ~ol~.-E.II .?-INto ?,,toiSF.~. ~t.-Ol-~ 8-.~01 
~XlI~II= = ~ZISH LDFPI~_ ~C.F~ uH~C3 ~-~-  ~.1-~..~ OF-..It~ 
~01 ~cF.  
x~.~ ~.~OI ~l,.Lt~ EH~=  ~S lO I  ...~CI.~ ~.~_o~ ~It~,/~F 
a~_tOI LO~O KILL= ~0~OPj ~-~/~1 )H~F ~dXl~ 8~9F 
Figure 1 
The analyst selects one or more scenario 
template, to activate in the query. Each 
scenario template corresponds to a specific 
type of event. Available scenario templates 
might include troop movements, acts of 
violence, meetings and negotiathms, 
protests, etc. In Figure 1, the selected event 
is of type meeting (understood broadly). 
The analyst fills in the available slots of the 
selected scenario template in order to restrict 
the search to the information considered to 
be relevant. In Figure 1, the values specified 
in the scenario template indicate that the 
information to f'md is about meetings having 
as location South Korea and as issue North 
Korea and missiles. The analyst also 
32  
specifies what information s/he wants to be 
reported when information matching the 
query is found. In Figure 1, the selected 
boxes under the Report column indicate that 
all information found satisfying the query 
should be reported except for the meeting 
participants. 1 
? Once the analyst submits the query for 
evaluation, the system searches the input 
documents for information matching the 
query. As a result, a hypertext document is 
generated describing the information 
matching the query as well as the source of 
this information. Note that the query 
contains English keywords that are 
automatically translated into Korean prior to 
matching. The extracted information is 
presented in English after being translated 
from Korean. In Figure 1, the generated 
hypertext response indicates two documents 
in the input set that matched the query 
totally or in part. Each summary in the 
response includes just the translations of the 
extracted information that the analyst 
requested to be reported. 
? For each document extract matching the 
analyst query, the analyst can obtain a 
complete machine translation of the Korean 
document where the match was found, and 
where the matched information is 
highlighted. Working with a human 
translator, the analyst can also verify the 
accuracy of the reported information by 
accessing the documents in their original 
language. 
3 System Design 
Figure 2 shows the high-level design of the 
system. It consists of the following components: 
? The User Interface. The browser-based 
interface is for entering queries and 
displaying the resulting presentations. 
? The Portable Information Extractor (PIE) 
component. The PIE component uses the 
While in this example the exclusion of participant 
information in the resulting report is rather artificial, 
in general a scenario template may contain many 
different ypes of information, not all of which are 
likely to interest an analyst at once. 
Extraction Pattem Library - -  which 
contains the set of extraction patterns 
learned in the lab, one set per scenario 
template - -  to extract specific types of 
information from the input Korean 
documents, once parsed. 
? The Ranker component. This component 
ranks the extracted information returned by 
the PIE component according to how well it 
matches the keyword restrictions in the 
query. The MT component's English-to- 
Korean Transfer Lexicon is used to map the 
English keywords to corresponding Korean 
ones. When the match falls below a user- 
? configurable threshold, the extracted 
information is filtered out. 
? The MT component. The MT component 
(cf. Lavoie et al, 2000) translates the 
extracted Korean phrases or sentences into 
corresponding English ones. 
? The Presentation Generator component. 
This component generates well-organized, 
easy-to-read hypertext presentations by 
organizing and formatting the ranked 
extracted information. It uses existing NLG 
components, including the Exemplars text 
planning framework (White and Caldwell, 
1998) and the RealPro syntactic realizer 
(Lavoie and Rainbow, 1997). 
In our feasibility study, the majority of the effort 
went towards developing the PIE component, 
described in the next section. This component 
was implemented in a general way, i.e. in a way 
that we would expect to work beyond the 
specific training/test corpus described below. In 
contrast, we only implemented initial versions of 
the User Interface, Ranker and Presentation 
Generator components, in order to demonstrate 
the system concept; that is, these initial versions 
were only intended.to work with our training/test 
corpus, and will require considerable further 
development prior to reaching operational status. 
For the MT component, we used an early 
version of the lexical transfer-based system 
currently under development in an ongoing 
SBIR Phase II project (cf. Nasr et al, 1997; 
Palmer et al, 1998; Lavoie et al, 2000), though 
with a limited lexicon specifically for translating 
the slot fillers in our training/test corpus. 
33 
Korean Documents 
Parser 
Tagged l 
Korean Documents ( LexiconK?rean 1
~ Syntactic . . . . . .  Eaglish Grammar Structure (English) RealPro 
English Lexicon / ' S~'ntactic Realizer Sentence (English) 
t Parsed Document ~ ::i~i?~'~vii~i? ' .~:Qi~I~:i~-'-iL \[:!::ili:::.:: ~t r~.  :::::::::::::::::::::::: 
Extracted Information \[ 
(Korean) 
Ordered Extracted 
Information(Korean) 
Parsed Document \] Machine "lYanslation I ( 
~l Component (MT) 
Ordered Extracted 
Information (English) 
User Input Data Presentation (E glish) 
Information Extraction 
Query (English) 1 
i : rla0 Inf0rntauonl 
English-Korean 7 
Transfer Lexicon J
Korean-English 
Transfer Lexicon ) 
T 
Miiiiii ii 
? 
Presentation (English) 
End user Document Processing Knowledge base 
component component 
D (C)OTS component 
\[\]Component created in Phase I 
\[\]Component created or improved in Phase II 
Figure 2 
4 Portable Information Extraction 
4.1 Scenario Template and Training/Fest 
Corpus 
For our Phase I feasibility demonstration, we 
chose a minimal scenario template for meeting 
and negotiation events consisting of one or more 
participant slots plus optional date and location 
slots. 2 We then gathered a small corpus of thirty 
articles by searching for articles containing 
"North Korea" and one or more of about 15 
keywords. The first two sentences (with a few 
exceptions) were then annotated with the slots to 
be extracted, leading to a total of 51 sentences 
containing 47 scenario templates and 89 total 
2 In the end, we did not use the 'issue' slot shown in 
Figure 1, as it contained more complex Idlers than 
those that ypically have been handled in IE systems. 
correct slots. Note that in a couple of cases 
more than one template was given for a single 
long sentence. 
When compared to the MUC scenario 
template task, our extraction task was 
considerably simpler, for the following reasons: 
* The answer keys only contained information 
that could be found within a single sentence, 
i.e. the answer keys did not require merging 
information across entences. 
? The answer keys did not require anaphoric 
references to be resolved, and we did not 
deal with conjuncts eparately. 
? We did not attempt o normalize dates or 
remove appositives from NPs. 
4.2 Extraction Pattern Learning 
For our feasibility study, we chose to follow the 
AutoSlog (Lehnert et al, 1992; Riloff, 1993) 
approach to extraction pattern acquisition. In 
this approach, extraction patterns are acquired 
34 
i. E: 
K: 
<target-np>=<subject> <active voice verb> 
<participant> MET 
<target-np>=<subject> <active voice verb> 
<John-i> MANNASSTA 
<John-nom>'MET 
2. E: 
K: 
<target-np>=<subject> <verb> <infinitive> 
<participant> agreed to MEET 
<target-np>=<subject> <verbl-ki- lo> <verb2> 
<John-un> MANNA-ki- lo hapuyhayssta 
<John-nom> MEET-ki- lo agreed 
(-ki: nominalization ending, -io: an adverbial postposition) 
Figure 3 
via a one-shot general-to-specific learning 
algorithm designed specifically for the 
information extraction task. 3 The learning 
algorithm is straightforward and depends only 
on the existence of a (partial) parser and a small 
set of general inguistic patterns that direct the 
creation of specific patterns. As a training 
corpus, it requires a set of texts with noun 
phrases annotated with the slot type to be 
extracted. 
To adapt the AutoSlog approach to Korean, 
we first devised Korean equivalents of the 
English patterns, two of which are shown in 
Figure 3. It turned out that for our corpus, we 
could collapse some of these patterns, though 
some new ones were also needed. In the end we 
used just nine generic patterns. 
Important issues that arose in adapting the 
approach were (1) greater flexibility in word 
order and heavier reliance on morphological 
cues in Korean, and (2) the predominance of 
light verbs (verbs with little semantic ontent of 
their own) and aspectual verbs in the chosen 
domain. We discuss these issues in the next two 
sections. 
4.3 Korean Parser 
We used Yoon's hybrid statistical Korean parser 
(Yoon et al, 1997, 1999; Yoon, 1999) to process 
the input sentences prior to extraction. The 
parser incorporates a POS tagger and 
3 For TIDES, we plan to use more sophisticated 
learning algorithms, as well as active learning 
techniques, such as those described in Thompson et 
al. (1999). 
morphological nalyzer and yields a dependency 
representation as its output? The use of a 
dependency representation e abled us to handle 
the greater flexibility in word order in Korean. 
To facilitate pattern matching, we wrote a 
simple program to convert he parser's output o 
XML form. During the XML conversion, two 
simple heuristics were applied, one to recover 
implicit subjects, and another to correct a 
recurring misanalysis of noun compounds. 
4.4 Trigger Word Filtering and 
Generalization 
In the newswire corpus we looked at, meeting 
events were rarely described with the verb 
'mannata' ('to meet'). Instead, they were 
usually described with a noun that stands for 
'meeting' and a light or aspectual verb, for 
example, 'hoyuy-lul kacta' ('to have a meeting') 
or 'hoyuy-lul machita' ('to finish a meeting'). 
In order to acquire extraction patterns that made 
appropriate use of such collocations, we decided 
to go beyond the AutoSlog approach and 
explicitly group trigger words (such as 'hoyuy') 
into classes, and to likewise group any 
collocations, such as those involving light verbs 
or aspectual verbs. To fmd collocations for the 
trigger words, we reviewed a Korean lexical co- 
occurrence base which was constructed from a 
corpus of 40 million words (Yoon et al, 1997). 
We then used the resulting specification to filter 
the learned patterns to just those containing the 
4 Overall dependency precision is reported to be 
89.4% (Yoon, 1999). 
35 
. - !  
trigger words or trigger word collocations, as 
well as to generalize the patterns to the word 
class level. Because the number of tr:igger 
words is small, this specification can be done 
quickly, and soon pays off in terms of time 
saved in manually filtering the learned patterns. 
4.5 Results 
In testing our approach, we obtained overall 
results of 79% recall and 67% precision in a 
hold-one-out cross validation test. In a cross 
validation test, one repeatedly divides a corpus 
into different raining and test sets, averaging the 
results; in the hold-one-out version, the system 
is tested on a held-out example after being 
trained on the rest. In the IE setting, the recall 
measure is the number of correct slots found 
divided by the total number of correct slots, 
while the precision measure is the number of 
correct slots found divided by the total number 
of slots found. 
While direct comparisons with the MUC 
conference results cannot be made for the 
reasons we gave above, we nevertheless 
consider these results quite promising, as these 
scores exceed the best scores reported at MUC-6 
on the scenario template task. 5 
Table 1: Hold-One-Out Cross Validation 
Slots Recall Precision 
All 79% 67% 
Participant 75% 84% 
Date/Location 86% 54% 
Table2: Hold-One-OutCross Validat~n 
wi~outGeneralizafion 
Slots Recall Precision 
All 61% 64% 
Participant 57% 81% 
Date/Location 67% 52% 
A breakdown by slot is shown in Table 1. We 
may note that precision is low for date and 
location slots because we used a simplistic 
sentence-level merge, rather than dependencies. 
To measure the impact of our approach to 
generalization, we may compare the results in 
5 
http://www.nist.gov/itl/div894/894.02/related_project 
s/tipster/muc.htm 
Table 1 with those shown in Table 2, where 
generalization is not used. As can be seen, the 
generalization step adds substantially to overall 
recall. 
To illustrate the effect of generalization, 
consider the pattern to extract he subject NP of 
the light verb 'kac (hold)' when paired with an 
object NP headed by the noun 'hyepsang 
(negotiation)'. Since this pattern only occurs 
once in our corpus, the slot is not successfully 
extracted in the cross-validation test without 
generalization. However, since this example 
does fall under the more generalized pattern of 
extracting the subject NP of a verb in the light 
verb class when paired with an object NP 
headed by a noun the 'hoytam-hyepsang' class, 
the slot is successfully extracted in the cross- 
validation test using the generalized patterns. 
Cases like these are the source of the 18% boost 
in recall of participant slots, from 57% to 75%. 
5 Discussion 
Our feasibility study has focused our attention 
on several questions concerning the interaction 
of IE and MT, which we hope to pursue under 
the DARPA TIDES initiative. One question is 
the extent o which slot filler translation is more 
practicable than general-purpose MT; one would 
expect to achieve much higher quality on slot 
fillers, as they are typically relatively brief noun 
phrases, and instantiation of a slot implies a 
degree of semantic lassification. On the other 
hand, one might find that higher quality is 
required in order to take translated phrases out 
of their original context. Another question is 
how to automate the construction of bilingual 
lexicons. An important issue here will be how 
to combine information from different sources, 
given that automatically acquired lexical 
information is apt to be less reliable, though 
domain-specific. 
Acknowledgements 
Our thanks go to Richard Kittredge and Tanya 
Korelsky for helpful comments and advice. This 
work was supported by ARL contract DAAD 17- 
99-C-0005. 
36 
References 
Cardie, C. (1997). Empirical Methods in Information 
Extraction. AI Magazine 18(4):65-79. 
Lavoie, B. and Rambow, O. (1997). RealPro - -  A 
fast, portable sentence realizer. In Proceedings of 
the Conference on Applied Natural Language 
Processing (ANLP'97), Washington, DC. 
Lavoie, B., Korelsky, T., and Rambow, O. (2000). A 
Framework for MT and Multilingual NLG Systems 
Based on Uniform Lexico-Structural Processing. 
To appear in Proceedings of the Sixth Conference 
on Applied Natural Language Processing (ANLP- 
2000), Seattle, WA. 
Lehnert, W., Cardie, C., Fisher, D., McCarthy, J., 
Riloff, E., and Soderland, S. (1992). University of 
Massachusetts: Description of the CIRCUS system 
as used in MUC-4. In Proceedings of the Fourth 
Message Understanding Conference (MUC-4), 
pages 282-288, San Mateo, CA. Morgan 
Kaufmann. 
MUC-5 (1994). Proceedings of the Fifth Message 
Understanding Conference (MUC-5). Morgan 
Kaufmann, San Mateo, CA. 
MUC-7 (1998). Proceedings of the Seventh Message 
Understanding Conference (MUC-7). Morgan 
Kaufmann, San Francisco, CA. 
Nasr, A., Rambow, O., Palmer, M., and Rosenzweig, 
J. (1997). Enriching lexical transfer with cross- 
linguistic semantic features. In Proceedings of the 
lnterlingua Workshop at the MT Summit, San 
Diego, CA. 
Palmer, M., Rambow, O., and Nasr, A. (1998). 
Rapid prototyping of domain-specific machine 
translation systems. In Machine Translation and 
the Information Soup - Proceedings of the Third 
Conference of the Association for Machine 
Translation in the Americas AMTA'98, Springer 
Verlag (Lecture Notes in Artificial Intelligence No. 
1529), Berlin. 
Riloff, E. (1993). Automatically constructing a
dictionary for information exlxaction tasks. In 
Proceedings of the Eleventh National Conference 
on Artificial Intelligence, pages 811-816, 
Washington, DC. AAAI Press / MIT Press. 
Thompson, C. A., Califf, M. E., and Mooney, R. J. 
(1999). Active learning for natural language 
parsing and information extraction. In Proceedings 
of the Sixteenth International Machine Learning 
Conference (1CML-99), Bled, Slovenia. 
White, M. and Caldwell, T. (1998). EXEMPLARS: A 
practical, extensible framework for dynamic text 
generation. In Proceedings of the 8th International 
Workshop on Natural Language Generation, 
Niagara-on-the-Lake, Ontario. 
Yoon, J. (1999). Efficient dependency parsing based 
on three types of chunking and lexical association. 
Submitted. 
Yoon, J., Choi, K.-S., and Song, M. (1999). Three 
types of chunking in Korean and dependency 
analysis based on lexical association. In 
Proceedings of lCCPOL. 
Yoon, J., Kim, S., and Song, M. (1997). New parsing 
method using global association table. In 
Proceedings of the 5th International Workshop on 
Parsing Technology. 
37 
? 
Comparing Lexicalized Treebank Grammars Extracted from 
Chinese, Korean, and English Corpora 
Fei  X ia ,  Chung-hye  Han,  Mar tha  Pa lmer ,  and  Arav ind  Josh i  
University of Pennsylvania 
Phi ladelphia PA 19104, USA 
{fxia, chunghye, mpalmer, j oshi}@linc, cis. upenn, edu 
Abst rac t  
In this paper, we present a method 
for comparing Lexicalized Tree Ad- 
joining Grammars extracted from 
annotated corpora for three lan- 
guages: English, Chinese and Ko- 
rean. This method makes it possi- 
ble to do a quantitative comparison 
between the syntactic structures of 
each language, thereby providing a 
way of testing the Universal Gram- 
mar Hypothesis, the foundation of 
modern linguistic theories. 
1 In t roduct ion  
The comparison of the grammars extracted 
from annotated corpora (i.e., Treebanks) is 
important on both theoretical and engineer- 
ing grounds. Theoretically, it allows us to do 
a quantitative testing of the Universal Gram- 
mar Hypothesis. One of the major concerns 
in modern linguistics is to establish an ex- 
planatory basis for the similarities and varia- 
tions among languages. The working assump- 
tion is that languages of the world share a set 
of universal linguistic principles and the ap- 
parent structural differences attested among 
languages can be explained as variation in 
the way the universal principles are instan- 
tiated. Comparison of the extracted syntac- 
tic trees allows us to quantitatively evaluate 
how similar the syntactic structures of differ- 
ent languages are. From an engineering per- 
spective the extracted grammars and the links 
between the syntactic structures in the gram- 
mars are valuable resources for NLP applica- 
tions, such as parsing, computational lexicon 
development, and machine translation (MT), 
to name a few. 
In this paper we first briefly discuss some 
linguistic characteristics of English, Chinese, 
and Korean, and introduce the Treebanks for 
the three languages. We then describe a 
tool that extracts Lexicalized Tree Adjoin- 
ing Grammars (LTAGs) from Treebanks and 
the results of its application to these three 
Treebanks. Next, we describe our methodol- 
ogy for automatic comparison of the extracted 
Treebank grammars, This consists primar- 
ily of matching syntactic structures (namely, 
templates and sub-templates) in each pair 
of Treebank grammars. The ability to per- 
form this type of comparison for different lan- 
guages has a definite positive impact on the 
possibility of sorting out the universal ver- 
sus language-dependent features of languages. 
Therefore, our grammar extraction tool is not 
only an engineering tool of great value in im- 
proving the efficiency and accuracy of gram- 
mar development, but it is also very useful for 
investigating theoretical linguistics. 
2 Three  Languages  and  Three  
' r reebanks  
In this section, we briefly discuss some lin- 
guistic characteristics of English, Chinese, 
and Korean, and introduce the Treebanks for 
these languages. 
2.1 Three  Languages 
These three languages belong to different lan- 
guage families: English is Germanic, Chinese 
is Sino-Tibetan, and Korean is Altaic (Com- 
rie, 1987). There are several major differences 
between these languages. First, both English 
52 
and Chinese have predominantly subject- 
verb-object (SVO) word order, whereas Ko- 
rean has underlying SOV order. Second, the 
word order in Korean is freer than in English 
and Chinese in the sense that argument NPs 
are freely permutable (subject o certain dis- 
course constraints). Third, Korean and Chi- 
nese freely allow subject and object deletion, 
but English does not. Fourth, Korean has 
richer inflectional morphology than English, 
whereas Chinese has little, if any, inflectional 
morphology. 
2.2 Three Treebanks  
The Treebanks that we used in this paper are 
the English Penn Treebank II (Marcus et al, 
1993), the Chinese Penn Treebank (Xia et 
al., 2000b), and the Korean Penn Treebank 
(Chung-hye Han, 2000). The main param- 
eters of these Treebanks are summarized in 
Table 1.1 The tags in each tagset can be 
classified into one of four types: (1) syntac- 
tic tags for phrase-level annotation, (2) Part- 
Of-Speech (POS) tags for head-level annota- 
tion, (3) function tags for grammatical func- 
tion annotation, and (4) empty category tags 
for dropped arguments, traces, and so on. 
We chose these Treebanks because they all 
use phrase structure annotation and their an- 
notation schemata re similar, which facili- 
tates the comparison between the extracted 
Treebank grammars. Figure 1 shows an an- 
notated sentence from the Penn English Tree- 
bank. 
3 LTAGs  and  Ext rac t ion  
A lgor i thm 
In this section, we give a brief introduction to 
the LTAG formalism and to a system named 
LexTract, which we build to extract LTAGs 
from Treeb~.nks. 
1The reason why the average sentence length for 
Korean is much shorter than those for English and 
Chinese is that a big portion of the corpus for Ko- 
rean Treebank includes dialogues that contain many 
one-word replies, whereas English and Chinese cor- 
pora consist of newspaper articles. 
((S (ppoLOC (IN at) 
(NP (NNP FNX)) 
(NP-SBJ-1 (bINS underwriters)) 
(ADVP (RB stin)) 
(VP (VBP draft) 
(NP (bINS policies)) 
(S-MNR 
(NP-SBJ (-NONE- *-1 )) 
(VP (VBG using) 
(NP 
(NP (iNN fountain) (NNS pens)) 
(CO and) 
(NP (VBG blotting) (NN papers)))))))) 
Figure 1: An example from Penn English 
Treebank 
3.1 LTAG fo rmal i sm 
LTAGs are based on the Tree Adjoining 
Grammar formalism developed by Joshi, 
Levy, and Takahashi (Joshi et al, 1975; Joshi 
and Schabes, 1997). The primitive elements 
of an LTAG are elementary trees (etrees). 
Each etree is associated with a lexical item 
(called the anchor of the tree) on its fron- 
tier. LTAGs possess many desirable proper- 
ties, such as the Extended Domain of Local- 
ity, which allows the encapsulation f all argu- 
ments of the anchor associated with an etree. 
There are two types of etrees: initial trees and 
auxiliary trees. An auxiliary tree represents 
a recursive structure and has a unique leaf 
node, called the foot node, which has the same 
syntactic category as the root node. Leaf 
nodes other than anchor nodes and foot nodes 
are substitution odes. Etrees are combined 
by two operations: substitution and adjunc- 
tion. The resulting structure of the combined 
etrees is called a derived tree. The combina- 
tion process is expressed as a derivation tree. 
Figure 2 shows the etrees, the derived tree, 
and the derivation tree for the sentence un- 
derwriters still draft policies. Foot and sub- 
stitution nodes are marked by ,, and $, re- 
spectively. The dashed and solid lines in the 
derivation tree are for adjunction and substi- 
tution operations, respectively. 
3.2 The Form of  Target Grammars 
Without further constraints, the etrees in 
the target grammar (i.e., the grammar to be 
extracted by LexTract) could be of various 
shapes. LexTract recognizes three types of 
53 
# of POS # ofsyntac- 
tags tic tags 
Language corpus size 
(words) 
English 1,174K 
Chinese 100K 
Korean 30K 
average sen- 
tence length 
23.85 words 
| Ib"~ ' - l l~ , ) _o~ 
34 
17 
of ftmc- # of empty cat- 
tion tags egory tags 
20 12 
26 7 
17 4 
Table 1: Size of the Treebanks and the tagsets used in each Treebank 
#h ~ vP -~,~ #3: S #4: 
I ADVP VP" ", ~, vP / I 
~s I ', . . . . .  ~ /Nns  
vBP ~/  I I ? ' v" , , .  
m~. , r ia .~ ~,ill draR pc u.mm,..~ 
(a) et re~ 
NF VP 
Jail~ draft NN$ 
I 
ptfliei~ 
draf t (#3)  
- - " - - ' "T ' - - - - " - - - -  
undcxwrRcrs(# 1 ) \ policies(#4) 
still(#2) 
(h) dcrivcd trc? (c) dczivatitm trcc 
Figure 2: Etrees, derived tree, and derivation 
tree for underwriters till draft policies 
x TM 
x ~ wq 
y~ X~= w~ X m )?,. cc  I X ~ 
xo z,~ /~  x, 
{ xo z~ x/~'X.z ,~
knti.~l itgm I 
(a) spinc-ctr~ (b) rm~-ctrce (c) c,,nj-etree 
Figure 3: Three types of elementary trees in 
the target grammar 
relation (namely, predicate-argument, modi- 
fication, and coordination relations) between 
the anchor of an etree and other nodes in the 
etree, and imposes the constraint that all the 
etrees to be extracted should fall into exactly 
one of the three patterns in Figure 3. 
The spine-etrees for predicate-argument 
relations. X ? is the head of X m and the 
anchor of the etree. The etree is formed 
by a spine X m ~ X m-1 ~ .. ~ X ? and 
the arguments of X ?. 
The mod-etrees for modification rela- 
tions. The root of the etree has two chil- 
dren, one is a foot node with the label 
Wq,  and the other node X m is a modifier 
of the foot node. X m is further expanded 
into a spine-etree whose head X ? is the 
anchor of the whole mod-etree. 
The conj-etrees for coordination rela- 
tions. In a conj-etree, the children of the 
root are two conjoined constituents and 
a node for a coordination conjunction. 
One conjoined constituent is marked as 
the foot node, and the other is expanded 
into a spine-etree whose head is the an- 
chor of the whole tree. 
Spine-etrees are initial trees, whereas mod- 
etrees and conj-etrees are auxiliary trees. 
3.3  Ext rac t ion  a lgor i thm 
The core of LexTract is an extraction algo- 
rithm that takes a Treebank sentence such as 
the one in Figure 1 and Treebank-specific in-
formation provided by the user of LexTract, 
and produces a set of etrees as in Figure 4 
and a derivation tree. We have described 
LexTract's architecture, its extraction algo- 
rithm, and its applications in (Xia, 1999; Xia 
et al, 2000a). Therefore, we shall not re- 
peat them in this paper other than point- 
ing out that LexTract is completely anguage- 
independent. 
3.4  Exper iments  
The results of running LexTract on English, 
Chinese, and Korean Treebanks are shown in 
Table 2. Templates are etrees with the lexical 
items removed. For instance, #3, #6, and #9 
in Figure 4 are three distinct etrees but they 
share the same template. 
Figure 5 shows the log frequency of tem- 
plates in the English Treebank and percent- 
age of template tokens covered by template 
54 
m 
m ~i \ ] lml~ i J  
template etree word etree types 
types types types per word type 
6926 131,397 49,206 
1140 21,125 10,772 
etree types 
per word token 
CFG rules 
(unlexicalized) 
2.67 34.68 1524 
1.96 9.13 515 
1.45 2.76 : 177 
Table 2: Grammars extracted from three Treebanks 
#1: re2: #3: #4: #5: #6: 
S NP NP VP S NP 
PP S* NNS ADVP VP* NP| VP NNS / ~  NNP 
, . . P ,  I I R', vBf'~-.~ I 
l FNX enderwri,~,~ { { polid~ 
s0ll draft at 
#7: #8: #9: #I0: #l l :  #12: 
VP NP NP NP NP 
VP" S NN NP" N VBG Np~ NIP" CC| NP 
NP VP 
{ ~ finmtain bltXting 
e V~O NP; pen.~ I 
pap~ 
~ing 
Figure 4: The extracted etrees from the fully 
bracketed ttree 
types. 2 In both cases, template types are 
sorted according to their frequencies and plot- 
ted on the X-axis. The figure shows that 
a small subset of template types, which oc- 
curs very frequently in the Treebank and can 
be seen as the core of the Treebank gram- 
mar, covers the majority of template tokens 
in the Treebank. For instance, the most 
frequent template type covers 9.37% of the 
template tokens and the top 100 (500, 1000 
and 1500, respectively) template types cover 
87.1% (96.6%, 98.4% and 99.0%, respectively) 
of the tokens, whereas about half (3440) of 
the template types occur once, accounting for 
only 0.32% of template tokens in total. 
4 Compar ing  Three  Treebank  
Grammars  
In this section, we describe our methodology 
for comparing Treebank gr3.mmars and the 
experimental results. 
4.1 Methodo logy  
To compare Treeb~nb grammars, we need to 
ensure that the Treebank grammars are based 
on the same tagset. To achieve that, we first 
create a new tagset that includes all the tags 
2If a template occurs n times in the corpus, it is 
counted as one template type but n template tokens. 
(a) Frequency (b) Coverage 
Figure 5: Etree template types and template 
tokens in the Penn English Treebank 
(X-axes: (a) and (b) template types 
Y-axes: (a) log frequency of templates; (b) 
percentage of template token covered by tem- 
plate types) 
from the three Treebanks. Then we merge 
some tags in this new tagset into a single tag. 
This step is necessary because certain distinc- 
tions among some tags in one language do not 
exist in another language. For example, the 
English Treebank has distinct tags for verbs 
in past tense, past participals, gerunds, and 
so on; however, no such distinction is mor- 
phologically marked in Chinese and, there- 
fore, the Chinese Treebank uses the same tag 
for verbs regardless of the tense and aspect. 
To make the conversion straightforward for 
verbs, we use a single tag for verbs in the new 
tagset. Next, we replace the tags in the origi- 
nal Treebanks with the tags in the new tagset, 
and then re-run LexTract to build Treebank 
gr~mraars from those Treebanks. 
Now that the Treebank grammars are based 
on the same tagset, we can compare them ac- 
cording to the templates and sub-templates 
that appear in more than one 'rreebank m 
that is, given a pair of Treebank grammars, 
we first calculate how many templates oc- 
cur in both grammars; 3 Next, we decompose 
SIdeally, to get more accurate comparison results, 
we would like to compare trees, rather than templates 
(which are non-lexicalized); however, comparing etrees 
requires bilingual parallel corpora, which we are cur- 
55 
templates: sub-templates: 
~ spine: S -> VP -> V 
NP| ~ subca~ (:NP, V@. NP) 
V@ NP! with root S 
(a) spine-etree template 
VP spine: PP-> P 
VP'~ PP ~ subeat: (P@, NP) 
with root PP 
P@ NP~ rood-pair: (VP*, PP) 
(b) mod-etree t mplate 
I . . . . . . .~  spine: NP->N 
NP* cc~ r~P ~ subeat ~@) with root NP 
lq@ conj-tuple: (NP*, CC, NP) 
(c) conj-etree t mplate 
Figure 6: The decompositions of etree tem- 
plates (In sub-templates, @ marks the anchor 
in subcategorization frame, * marks the mod- 
ifiee in a modifier-modifiee pair.) 
each template into a list of sub-templates (e.g., 
spines and subcategorization frames) and cal- 
culate how many of those sub-templates occur 
in both grammars. A template is decomposed 
as follows: A spine-etree template is decom- 
posed into a spine and a subcategorization 
frame; a mod-etree template is decomposed 
into a spine, a subcategorization frame, and a 
modifier-modifiee pair; a conj-etree template 
is decomposed into a spine, a subcategoriza- 
tion frame, and a coordination tuple. Figure 
6 shows examples of this decomposition for 
each type of template. 
4.2 Exper iments  
After tags in original Treebn.nks being re- 
placed with the tags in the new tagset, the 
numbers of templates in the new Treebank 
gra.mmars decrease by about 50%, as shown 
in the second colnmn of Table 3 (cf. the sec- 
ond column in Table 2). Table 3 also lists the 
numbers of sub-templates, such as spines and 
subcategorization frames, for each grammar. 
Table 4 lists the numbers of template types 
shared by each pair of Treeba.nk gr3.mmars 
and the percentage of the template tokens 
rently building. 
in each Treebank which are covered by these 
common template types. For example, there 
are 237 template types that appear in both 
English and Chinese Treebank grammars. 
These 237 template types account for 80.1% 
of template tokens in the English Treebank, 
and 81.5% of template tokens in the Chi- 
nese Treebank. The table shows that, al- 
though the number of matched templates are 
not very high, they are among the most fre- 
quent emplates and they account for the ma- 
jority of template tokens in the Treebanks. 
For instance, in the (Eng, Ch) pair, the 237 
template types that appear in both gram- 
mars is only 77.5% of all the English template 
types, but they cover 80.1% of template to- 
kens in the English Treebank. If we define the 
core grammar of a language as the set of the 
templates that occur very often in the Tree- 
bnnk, the data suggest hat the majority of 
the core grammars are easily inter-mappable 
structures for these three languages. 
If we compare sub-templates, rather than 
templates, in the Treebank grammars, the 
percentages of matched sub-template tokens 
(as in Table 5) are higher than the percent- 
ages of matched template tokens. This is be- 
cause two distinct templates may share com- 
mon sub-templates. 
4.3 Unmatched templates  
Our previous experiments ( ee Table 4) show 
that the percentages of unmatched template 
tokens in three Treebanks range from 16.0% 
to 43.8%, depending on the language pairs. 
Given a language pair, there are many pos- 
sible reasons why a template appears in one 
Treebank grammar, but not in the other. We 
divide those unmatched templates into two 
categories: spuriously unmatched templates 
and truly unmatched templates. 
Spuriously unmatched templates Spu- 
riously unmatched templates are templates 
that either should have found a matched tem- 
plate in the other gra.mmar or should not have 
been created by LexTract in the first place 
if the Treebanks were complete, uniformly 
annotated, and error-free. A spuriously un- 
matched template xists because of one of the 
56 
templates subtemplates 
spines subcat~ames mod-pairs 
Eng 3139 500 541 332 53 
Ch 547 108 180 152 18 
Kor 271 55 58 53 6 
(Eng,Ch) 
(Eng, Kor) 
(Ch, Kor) 
conj-tuples total 
1426 
458 
172 
Table 3: Treebank grammars with the new tagset 
type (#) 
token (%) 
type (#) 
token (%) 
type (:~) 
token (%) 
matched templates 
(237, 237) 
(80.1, 81.5) 
(83, 83) 
(57.7, 82.8) 
(59,59) 
(57.2, 84.0) 
templates with 
unique tags 
(536, 99) 
(2.8, 12.3) 
(2075, 6) 
(28.1, 0.1) 
(324,6) 
(29.4, 0.1) 
other unmatched 
templates 
(2366, 211) 
(17.1, 6.2) 
(981, 182) 
(14.2, 17.1) 
(164, 206) 
(13.4, 16.0) 
Table 4: Comparisons of templatea in three Treebank grammars 
following reasons: 
(Sl)  T reebank  size: The template is lin- 
guistically sound in both languages, and, 
therefore, should belong to the grarnmars 
for these languages. However, the tem- 
plate appears in only one Treebank gram- 
mar because the other Treebank is too 
small to include such a template. Figure 
7(S1) shows a template that is valid for 
both English and Chinese, but it appears 
only in the English Treebank, not in the 
Chinese Treebank. 
($2) Annotat ion  difference: Treebanks 
may choose different annotations for 
the same constructions; consequentially, 
the templates for those constructions 
look different. Figure 7($2) shows the 
templates used in English and Chinese 
for a VP such as "surged 7 (dollars)". 
In the template for English, the QP 
projects to an NP, but in the template 
for Chinese, it does not. 
($3) Treeb~nk annotat ion  error:  A tem- 
plate in a Treebank may result from an- 
notation errors in that Treebank. If no 
corresponding mistakes are made in the 
other Treebank, the template in the first 
Treebank will not match any template in 
the second 'I~reebank. For instance, in the 
English Treebank the word about in the 
sentence About 5 people showed up is of- 
ten mis-tagged as a preposition, resulting 
in the template in Figure 7($3). Not sur- 
prisingly, that template does not match 
any template in the Chinese Treebank. 
Tru ly  unmatched templates  A truly un- 
matched template is a template that does not 
match any template in the other Treebank 
even if we assume both Treebanks are per- 
fectly annotated. Here, we list three reasons 
why a truly unmatched template xist. 
(T1) Word order:  The word order deter- 
mines the positions of arguments w.r.t. 
their heads, and the positions of modi- 
fiers w.r.t, their modifiees. If two lan- 
guages have different word orders, their 
templates which include arguments of a 
head or a modifier are likely to look dif- 
ferent. For example, Figure 8(T1) show 
the templates for transitive verbs in Chi- 
nese and Korean grammars. The tem- 
plates do not match because of the dif- 
ferent positions of the object of the verb. 
(T2) Unique tags: For each pair of lan- 
guages, some Part-of-speech tags and 
syntactic tags may appear in only one 
language. Therefore, the templates with 
those tags will not match any templates 
in the other language. For instance, in 
Korean the counterparts of preposition 
phrases in English and Chinese are noun 
phrases (with postpositions attaching to 
them, not preposition phrases); there- 
fore, the templates with PP in Chinese, 
57 
(Eng,Ch) 
(Eng, Kor) 
(Ch, Kor) 
Table 
spines subcat frames rood-pairs conj-tuples total 
type (60,60) (92, 92) (83,83) (II,II) (246,246) 
token (94.7,87.2) (94.0, 86.3) (82.6, 80.0) (84.2, 99.1) (91.4, 85.2) 
type (39, 39) (40, 40) (46, 46) (1, 1) (126,126) 
token (70.3, 96.9) (62.1, 96.6) (56.8, 99.5) (9.3, 52.3) (63.4,97.3) 
type (28, 28) (25,25) (29,29) (I, I) (83, 83) 
token I (74.2, 99.2) (63.1, 98.1) (60.2, 93.4) (0.i, 0.4) (66.1, 96.9) 
5: Comparisons of sub-templates in three Treebank grammars 
VP 
VP* CC! VP 
V @ NIL Nl-~ 
English 
vp yP 
A 
VP* NP " VP* 
I QP Qp I 
I cD~ 
CD~ 
English Chinese 
QP 
P@ QP* 
English 
(S 1) Treebank size ($2) annotation difference ($3) annotation crmr 
Figure 7: Examples of spuriously unmatched templates 
such as the left one in Figure 8(T2), do 
not match any template in Korean. 
(T3) Un ique  syntact ic  re lat ions:  Some 
syntactic relations may be present in 
only one of the pair of languages being 
compared. For instance, the template 
in Figure 8(T3) is used for the sentence 
such as "You should go," said John, 
where the subject of the verb said ap- 
pears after the verb. No such template 
exists in Chinese. 
So far, we have listed six possible reasons 
for unmatched templates. Without manually 
examining all the unmatched templates, it is 
difficult to tell how many unmatched tem- 
plates are caused by a particular reason. Nev- 
ertheless, these reasons help us to interpret 
the results in Table 4. For instance, the ta- 
ble shows that Korean grammars cover only 
57.7% of template tokens in the English Tree- 
bank, and 57.2% in the Chinese Treebank, 
whereas the coverages for other language pairs 
are all above 80%. We suspect that this 
difference of coverage is mainly caused by 
(S1), (T1), and (T2). That is, first, Ko- 
rean Treebank is much smaller than the En- 
glish and the Chinese Treebanks, English and 
Chinese Treebanks may have many tree tem- 
plates that simply was not found in the Ko- 
rean Treebank; Second, English and Chinese 
are predominantly head-initial, whereas Ko- 
rean is head-final, therefore, many templates 
in English and Chinese can not find matched 
templates in Korean because of the word or- 
der difference; Third, Korean does not have 
preposition phrases, causing all the templates 
in English and Chinese with PPs become un- 
matched. To measure the effect of the word 
order factor to the matching rate, we re-did 
the experiment in Section 4.2, but this time 
we ignored the word order - -  that is, we treat 
templates as unordered trees. The results are 
given in Table 6. Comparing this table with 
Table 4, we can clearly see that, the percent- 
ages of matched templates increase substan- 
tially for (Eng, Kor) and (Ch, Kor) when the 
word order is ignored. Notice that the match- 
ing percentage for (Eng, Ch) does not change 
as much because the word orders in English 
and Chinese are much similar than the orders 
in English and Korean. 
5 Conclusion 
We have presented a method of quantitatively 
comparing LTAGs extracted from Treebanks. 
Our experimental results show a high pro- 
portion of easily inter-mappable structures, 
giving a positive implications for Universal 
Grammar hypothesis, We have also described 
a number of reasons why a particular tern- 
58 
$ $ 
A 
V~ NPt NPt V~ 
Chinese Korean 
(TI) word order 
vP  
A 
VP* NP VP* 
I 
P@ NPt N@ 
Chinese Korean 
(T2) unique rags 
s 
s(" 's  
NPt 
V~ $ 
! 
? 
English 
(T3) unique relation 
Figure 8: Truly unmatched templates 
(Eng,Ch) 
(Eng, Kor) 
(Ch, Kor) 
matched templates 
type (334, 259) 
token (82.8, 82.2) 
type (222, 167) 
token (66.4, 92.4) 
type (126,125) 
token (68.3, 97.3) 
tag mismatches 
i (536, 99) 
! (2.8, 12.3) 
I (2075, 6) 
! (28.1, 0.1) 
(324,6) 
(29.4, 0.1) 
other mismatches 
(2269, 189) 
(14.4, 5.5) 
(842, 98) 
(5.5, 7.5) 
(97, 140) 
(2.3, 2.6) 
Table 6: Comparisons of templates w/o orders 
plate does not match any template in other 
languages and tested the effect of word order 
on matching percentages. 
There are two natural extensions of this 
work. First, running an alignment algorithm 
on parallel bracketed corpora to produce 
word-to, word mappings. Given such word-to- 
word mappings and our template matching 
algorithm, we can automatically create lexi- 
calized etree-to-etree mappings, which can be 
used for semi-automatic transfer lexicon con- 
struction. Second, LexTract can build deriva- 
tion trees for each sentence in the corpora. By 
comparing derivation trees for parallel sen- 
tences in two languages, instances of struc- 
tural divergences (Dorr, 1993; Dorr, 1994; 
Palmer et al, 1998) can be automatically de- 
tected. 
Re ferences  
Chung-hye Hart. 2000. Bracketing Guide- 
lines for the Penn Korean Treebank (draft). 
www.cis.upenn.edu/xtag/korean.tag. 
Bernard Comrie. 1987. The World's Major Lan- 
guages. Oxford University Press, New York. 
B. J. Dorr. 1993. Machine ~D'anslation: a View 
from the Lexicon. MIT Press, Boston, Mass. 
B. J. Dorr. 1994. Machine translation diver- 
gences: a formal description and proposed so- 
lution. Computational Linguistics, 20(4):597- 
635. 
Aravind Joshi and Yves Schabes. 1997. Tree 
Adjoining Grammars. In A. Salomma and 
G. Rosenberg, editors, Handbook off For- 
mal Languages and Automata. Springer-Verlag, 
Herdelberg. 
Aravind K. Joshi, L. Levy, and M. Takahashi. 
1975. Tree Adjunct Grammars. Journal off 
Computer and System Sciences. 
M. Marcus, B. Santorini, and M. A. 
Marcinkiewicz. 1993.  Building a Large 
Annotated Corpus of English: the Penn 
Treebank. Computational Lingustics. 
Martha Palmer, Owen Rainbow, and Alexis Nasr. 
1998. Rapid Prototyping of Domain-Specific 
Machine Translation System. In Proc. of 
AMTA-1998, Langhorne, PA. 
Fei Xia, Martha Palmer, and Aravind Joshi. 
2000a. A Uniform Method of Grammar Ex- 
traction and its Applications. In Proc. off Joint 
SIGDAT Conference on Empirical Methods in 
Natural Language Processing and Very Large 
Corpora (EMNLP/VLC). 
Fei Xia, Martha Palmer, Nianwen Xue, 
Mary Ellen Okurowski, John Kovarik, Shizhe 
Huang, Tony Kroch, and Mitch Marcus. 
2000b. Developing Guidelines and Ensuring 
Consistency for Chinese Text Annotation. 
In Proc. off the 2nd International Confer- 
ence on Language Resources and Evaluation 
(LREC-2000), Athens, Greece. 
Fei Xia. 1999. Extracting Tree Adjoining Gram- 
mars from Bracketed Corpora. In Proc. off 5th 
Natural Language Processing Pacific Rim Sym- 
posium (NLPRS-99), Beijing, China. 
59 
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 33?40,
Sydney, July 2006. c?2006 Association for Computational Linguistics
A Tree Adjoining Grammar Analysis of the Syntax and Semantics of
It-Clefts
Chung-hye Han
Department of Linguistics
Simon Fraser University
chunghye@sfu.ca
Nancy Hedberg
Department of Linguistics
Simon Fraser University
hedberg@sfu.ca
Abstract
In this paper, we argue that in it-clefts as
in It was Ohno who won, the cleft pronoun
(it) and the cleft clause (who won) form
a discontinuous syntactic constituent, and
a semantic unit as a definite description,
presenting arguments from Percus (1997)
and Hedberg (2000). We propose a syn-
tax of it-clefts using Tree-Local Multi-
Component Tree Adjoining Grammar and
a compositional semantics on the pro-
posed syntax using Synchronous Tree Ad-
joining Grammar.
1 Introduction
The extant literature on the syntax of it-clefts, as
in (1), can be classified into two main approaches.
First, the cleft pronoun it is an expletive, and the
cleft clause bears a direct syntactic or semantic
relation to the clefted constituent, such as one
of predication (Jesperson, 1937; Chomsky, 1977;
Williams, 1980; Delin, 1989; Delahunty, 1982;
Rochemont, 1986; Heggie, 1988; ?E. Kiss, 1998).
Second, the cleft clause bears a direct syntactic
or semantic relation to the cleft pronoun and is
spelled-out after the clefted constituent through
extraposition or by forming a discontinuous con-
stituent with the cleft pronoun from the base-
generated position at the end of the sentence (Jes-
person, 1927; Akmajian, 1970; Emonds, 1976;
Gundel, 1977; Wirth, 1978; Percus, 1997; Hed-
berg, 2000). Under this second approach, the cleft
pronoun is not necessarily expletive but rather has
a semantic function such as that of a definite arti-
cle.
(1) It
cleft pronoun +
was
copula +
OHNO
clefted constituent +
[who
cleft
won].
clause
In this paper, we argue for a particular version of
the second approach, in which the cleft pronoun
and the cleft clause form a discontinuous syntac-
tic constituent, and a semantic unit as a definite
description. We propose a syntax of it-clefts us-
ing Tree-Local Multi-Component Tree Adjoining
Grammar (MCTAG), and a compositional seman-
tics on the proposed syntax using Synchronous
Tree Adjoining Grammar (STAG). In section 2, we
present arguments against the expletive approach,
and in section 3, we provide arguments supporting
the discontinuous constituent analysis. We present
our TAG analysis in section 4 and extend our pro-
posal to grammatical variations on it-clefts in sec-
tion 5.
2 Arguments against the expletive
approach
It has been shown in Hedberg (2000) that the cleft
pronoun can be replaced with this or that, as in
(2), depending on the discourse contextual inter-
pretation of the cleft clause. The fact that the
choice of the cleft pronoun is subject to pragmatic
constraints indicates that the cleft pronoun cannot
simply be an expletive element devoid of any se-
mantic content.
(2) a. This is not Iowa we?re talking about.
(Hedberg 2000, ex. 17)
b. That?s the French flag you see flying
over there. (Hedberg 2000, ex. 20)
Although the details are different, many exple-
tive analyses advocate for the position that the
clefted constituent is syntactically associated with
the gap in the cleft clause either directly through
movement, or indirectly through co-indexation
with an operator in the cleft clause. One thing that
is common in all these analyses is that the cleft
clause is not considered to have the internal struc-
ture of a restrictive relative clause. We point out
33
that the initial element in the cleft clause may be
realized either as a wh-word (1) or as that (3a), or
it may be absent altogether when the gap is not in
the subject position (2, 3b). It may even be in the
form of a genitive wh-word as in (3c). The cleft
clause is thus a restrictive relative clause.
(3) a. It was Ohno that won.
b. It was Ohno Ahn beat.
c. It was Ohno whose Dad cheered.
The cleft clause, however, does not relate to the
clefted constituent in the way that a restrictive rel-
ative clause relates to its head noun, as first noted
in Jespersen (1927). This is because the clefted
constituent can be a proper noun, unlike a head
noun modified by a restrictive relative clause, as
illustrated in (4). This suggests that there is no
syntactic link between the clefted constituent and
the gap in the cleft clause.
(4) * Ohno that won is an American.
3 A discontinuous constituent analysis
As pointed out in Percus (1997) and Hedberg
(2000), it-clefts have existential and exhaustive
presuppositions, just as definite descriptions do.
The inference in (5c) associated with (5a) survives
in the negative counterpart in (5b). This is ex-
actly the way the presupposition associated with
the definite description the king of France behaves:
the presupposition spelled-out in (6c) survives in
both the affirmative (6a) and the negative counter-
part in (6b). Both authors argue that this paral-
lelism between definite descriptions and it-clefts
can be accounted for if the cleft pronoun and the
cleft clause form a semantic unit, with it playing
the role of the definite article and the cleft clause
the descriptive component. What this translates
to syntactically is that the cleft clause is a restric-
tive relative clause which is situated at the end of
the sentence, forming a discontinuous constituent
with the cleft pronoun.
(5) a. It was Ohno who won.
b. It was not Ohno who won.
c. Someone won, and only one person
won.
(6) a. The king of France is bald.
b. The king of France is not bald.
c. There is one and only one king of
France.
Percus (1997) further points out that it-clefts
pattern with copular sentences containing definite
description subjects with regard to anaphor bind-
ing. In the absence of c-command, an anaphor in
the clefted constituent position can be bound by
an antecedent inside the cleft clause, as shown in
(7a). While we don?t yet have an explanation for
how this type of binding takes place, we follow
Percus in noting that since copular sentences with
definite description subjects also exhibit this pat-
tern of binding, as shown in (7b), a uniform expla-
nation for the two cases can be sought if the cleft
pronoun and the cleft clause together form a defi-
nite description.
(7) a. It was herself that Mary saw first.
b. The one that Mary saw first was herself.
Under the discontinuous constituent analysis, it-
clefts reduce to copular sentences, and therefore
the observation that they can have equative and
predicational interpretations (Ball 1978, DeClerck
1988, Hedberg 2000), the readings attested in cop-
ular sentences, follows. For instance, (5a) (re-
peated as (8a)) can be paraphrased as (8b), and
corresponds to a typical equative sentence. And
(9a) can be paraphrased as (9b), and corresponds
to a typical predicational sentence. According to
our analysis, (8a) will be assigned the semantic
representation in (8c), and (9a) will be assigned
the semantic representation in (9c).
(8) a. It was Ohno who won.
b. The one who won was Ohno.
c. THEz [won(z)] [z = Ohno?]
(9) a. It was a kid who beat John.
b. The one who beat John was a kid.
c. THEz [beat(z, John?)] [kid(z)]
4 Our TAG analysis
Inspired by work of Kroch and Joshi (1987) and
Abeille? (1994) on discontinuous constituents re-
sulting from extraposition, we propose a tree-local
MCTAG analysis for the syntax of it-clefts. Cru-
cially, we propose that the elementary trees for
cleft pronoun and the cleft clause form a multi-
component set, as in {(?it), (?who won)} in Fig-
ure 1 and {(?it), (?who beat)} in Figure 4.
34
?(?Ohno) DP
D
Ohno
(??Ohno) T
Ohno?
?
?(?was) TP
DP0i? 1 T?
T
wask
CopP
Cop
tk
FP 1
DP0
ti
F?
F

DP1? 2
(??was) F 1
R
?x?y.x = y
T? 1 T? 2
?
?
{ (?it) DP
D
it
(?who won) FP
FP* CP
DPl
D
who
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V
won
}
{ (??it) T
z
(??who won) F
THEz F
R
?x.won(x)
T
z
F*
}
?
Figure 1: Syntactic and semantic elementary trees for It was Ohno who won
?(?8a) (?was)
(?Ohno)
DP1
(?it)
DP0
(?who won)
FP
(??8a) (??was)
(??Ohno) (??it) (??who won)
?
Figure 2: Syntactic and semantic derivation trees
for It was Ohno who won
For the derivation of equative it-clefts as in (8a),
we adopt the copular tree in (?was), a tree simi-
lar to the one proposed in Frank (2002) for copu-
lar sentences. In this tree, FP is a small clause of
the copula from which the two DPs being equated
originate. (8a) is derived by substituting (?it) into
DP0 in (?was), adjoining (?who won) into FP
in (?was), and substituting (?Ohno) into DP1 in
(?was). The syntactic derivation tree and the de-
rived tree for (8a) are given in (?8a) in Figure 2
and (?8a) in Figure 3 respectively.
Postulating separate projections for the copula
and the small clause can account for the fact that
the clefted constituent and the cleft clause seem
to form a constituent, as in (10ab) (from Hedberg
2000), and yet they can be separated by an adver-
bial phrase, as in (10c). In our analysis, (10ab)
are possible because the bracketed parts are FPs.
(10c) is possible because an adverbial phrase can
adjoin onto FP or F?, separating the clefted con-
stituent and the cleft clause.
(10) a. I said it should have been [Bill who ne-
gotiated the new contract], and it should
have been.
b. It must have been [Fred that kissed
Mary] but [Bill that left with her].
c. It was Kim, in my opinion, who won
the race.
We propose to do compositional semantics us-
ing STAG as defined in Shieber (1994). In STAG,
each syntactic elementary tree is paired with one
or more semantic tree with links between match-
ing nodes. A synchronous derivation proceeds by
mapping a derivation tree from the syntax side
to an isomorphic derivation tree in the semantics
side, and is synchronized by the links specified in
the elementary tree pairs. In the tree pairs given
in Figure 1, the trees on the left side are syntactic
elementary trees and the ones on the right side are
semantic trees. In the semantic trees, F stands for
formulas, R for predicates and T for terms. (??it)
and (??who won) in the multi-component set in
Figure 1 together define semantics of quantifica-
tion, where the former contributes the argument
variable and the latter the restriction and scope,
and (??was) represents the semantics of equative
sentences. The derivation tree for the semantics of
(8a) is given in (??8a) in Figure 2, and the seman-
35
?(?8a) TP
DPi
D
it
T?
T
wask
CopP
Cop
tk
FP
FP
DP
ti
F?
F

DP
D
Ohno
CP
DPl
D
who
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V
won
(??8a) F
THEz F
R
?x.won(x)
T
z
F
R
?x?y.x = y
T
z
T
Ohno?
?
Figure 3: Syntactic and semantic derived trees for It was Ohno who won
tic derived tree is given in (??8a) in Figure 3. Note
that the semantic derivation tree in (??8a) is iso-
morphic to the syntactic one in (?8a). The seman-
tic derived tree in (??8a) can be reduced to the for-
mula in (11) after the application of ?-conversion.
(11) THEz [won(z)] [z = Ohno?]
For the derivation of predicational it-clefts as
in (9a), we use the tree pairs in <(?was kid),
(??was kid)>, <(?John), (??John)>, and
<{(?it), (?who beat)}, {(??it), (??who beat)}>
in Figure 4. The elementary tree in (?was kid)
which represents a predicational copular sentence
is similar to the one in (?was) in that in both
trees, the copula combines with a small clause FP.
The important difference is that in (?was kid) the
subject DP is an argument substitution site and the
predicative DP (a kid) is lexicalized, whereas in
(?was) both the subject and the non-subject DPs
are argument substitution sites. This difference is
reflected in the semantic trees, as seen in (??was)
in Figure 1 with two term nodes and (??was kid)
in Figure 4 with one term node. The syntactic and
semantic derivation trees, which are isomorphic,
are given in <(?9a), (??9a)> in Figure 5, and the
corresponding derived trees are given in <(?9a),
(??9a)> in Figure 6. The semantic derived tree in
(??9a) can be reduced to the formula in (12) after
the application of ?-conversion.
(12) THEz [beat(z, John?)] [kid(z)]
?(?9a) (?was kid)
(?it)
DP0
(?who beat)
FP
(?John)
DP
(??9a) (??was kid)
(??it) (??who beat)
(??John)
?
Figure 5: Syntactic and semantic derivation trees
for It was a kid who beat John
5 Extensions
In this section, we extend the proposed syntactic
analysis to grammatical variations on it-clefts: wh-
extraction of the clefted constituent as in (13), un-
bounded dependency between the relative pronoun
and its gap in the cleft clause as in (14), and coor-
dination of the constituent containing the clefted
constituent and the cleft clause as in (15).
(13) Whoj was it tj who won?
(14) It was Ohno whol the judges said tl won.
(15) It was [Ohno who won] and [Kim who lost].
For the derivation of (13), the elementary trees
in Figure 7 are required in addition to {(?it),
(?who won)} in Figure 1. (?who was) represents
the structure with the wh-extraction of the clefted
constituent. Substituting (?who) into DP1 and
(?it) into DP0, and adjoining (?who won) onto FP
in (?who was), as in the derivation tree in (?13),
produces the derived tree in (?13) in Figure 8.
For the derivation of (14), the elementary trees
in Figure 9 are required in addition to {(?it),
36
?(?was kid) TP
DP0i? 1 T?
T
wask
CopP
Cop
tk
FP 1
DP0
ti
F?
F

DP
D
a
NP
N
kid
(??was kid) F 1
R
?x.kid(x)
T? 1
?
?(?John) DP
D
John
(??John) T
John?
?
?
{(?it) DP
D
it
(?who beat) FP
FP* CP
DPl
D
who
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V?
V
beat
DP?
}
{ (??it) T
z
(??who beat) F
THEz F
R
R
?x?y.beat(y, x)
T?
T
z
F*
}
?
Figure 4: Syntactic and semantic elementary trees for It was a kid who beat John
?(?9a) TP
DPi
D
it
T?
T
wask
CopP
Cop
tk
FP
FP
DP
ti
F?
F

DP
D
a
NP
N
kid
CP
DPl
D
who
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V?
V
beat
DP
D
John
(??9a) F
THEz F
R
R
?x?y.beat(y, x)
T
John?
T
z
F
R
?x.kid(x)
T
z
?
Figure 6: Syntactic and semantic derived trees for It was a kid who beat John
37
(?who) DP
D
who
(?who was) CP
DP1j? C?
C
wask
TP
DP0i? T?
T
tk
CopP
Cop
tk
FP
DP0
ti
F?
F

DP1
tj
Figure 7: Syntactic elementary trees for Who was
it who won?
(?13) (?who was)
(?who)
DP1
(?it)
DP0
(?who won)
FP
(?13) CP
DPj
D
who
C?
C
wask
TP
DPi
D
it
T?
T
tk
CopP
Cop
tk
FP
FP
DP
ti
F?
F

DP
tj
CP
DPl
D
who
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V
won
Figure 8: Derivation and derived trees for Who
was it who won?
(?the judges) DP
D
the
NP
N
judges
(?said) C?
C TP
DPm? T?
T
[past]
VP
DP
tm
V?
V
said
C?
Figure 9: Syntactic elementary trees for It was
Ohno who the judges said won
(?who won)} in Figure 1. Adjoining (?said)
onto the C? node in (?who won) has the effect
of stretching the dependency between the relative
pronoun who and its gap in the cleft clause. The
derivation and the derived trees for (14) are given
in Figure 10.
To handle the coordination of the constituent
containing the clefted constituent and the cleft
clause, as illustrated in (15), we propose to use
Node Contraction and Conjoin proposed in Sarkar
and Joshi (1996). Informally, Node Contraction
takes two nodes of like categories and collapses
them into a single node, and Conjoin coordinates
the least nodes dominating the two contiguous
strings. We use the conjunction tree in Figure 11
to apply Conjoin at FP.
Figure 12 contains the elementary tree anchor-
ing equative was. We mark the nodes to be con-
tracted with a box, and augment the name of the
elementary tree with a set listing these contrac-
tion nodes. Thus, (?was){DP i,T,Cop} means that
DPi, T and Cop nodes are marked for contraction
in (?was) elementary tree.
Composition of (?was){DP i,T,Cop} tree in
Figure 12 and another (?was){DP i,T,Cop} tree
with the conjunction tree in Figure 11, along
with the substitution and adjoining of (?Ohno)
and an equivalent tree (?Kim) anchoring Kim,
(?who won) and an equivalent tree (?who lost)
anchoring lost, and (?it) in appropriate places,
yields the derived structure in Figure 13, where the
contracted nodes get identified. In this structure,
the DP hosting it is dominated by two TP nodes,
T is dominated by two T? nodes and Cop is domi-
nated by two CopP nodes. Thus, the derived struc-
ture produced by Conjoin and Node Contraction is
a directed graph, not a tree.
38
(?15)
  i
TP
FP             CP
DP             F?
F             DP
D
TP
   Cop            FP
FP             CP
DP             F?
F             DP
who won
D
D
it
T          CopP
T?
CopP
 FP
who lost
Kim
FP
Conj
and
DP             T?
t
was
 t
Ohno
 ? ?
i
i
k
k
 t
Figure 13: Derived structure for It was Ohno who won and Kim who lost
(?14) (?was)
(?Ohno)
DP1
(?it)
DP0
(?who won)
FP
(?said)
C?
(?the judges)
DP
(?14) TP
DPi
D
it
T?
T
wask
CopP
Cop
tk
FP
FP
DP
ti
F?
F

DP
D
Ohno
CP
DPl
D
who
C?
C TP
DPm
D
the
NP
N
judges
T?
T
[past]
VP
DP
tm
V?
V
said
C?
C TP
DP
tl
T?
T
[past]
VP
DP
tl
V
won
Figure 10: Derivation and derived trees for It was
Ohno who the judges said won
Conj(and) FP
FP Conj
and
FP
Figure 11: Elementary tree for conjunction
(?was){DP i,T,Cop} TP
DP0i ? T?
T
wask
CopP
Cop
tk
FP
DP
ti
F?
F

DP1?
Figure 12: Elementary tree anchoring equative
was with contraction nodes
(?15)
 it)
Conj(and)
FP FP
FP FPDP1 DP0 DP0 DP1
{DP0,T,Cop} (?  was)
(?Ohno)
  (?   was) {DP0,T,Cop}
who?won)(? (?who?lost) (?Kim)(? 
Figure 14: Derivation structure for It was Ohno
who won and Kim who lost
The derivation structure for (15) is also a di-
rected graph, as shown in Figure 14. (?it)
is dominated by two (?was){DP i,T,Cop} trees,
indicating that it is being shared by the two
(?was){DP i,T,Cop} trees.
6 Conclusion
We have proposed a syntax and semantics of it-
clefts, using tree-local MCTAG and STAG, and
shown that the proposed syntactic analysis is ex-
39
tendable to handle various grammatical variations
on it-clefts such as wh-extraction of the clefted
constituent, unbounded dependency between the
relative pronoun and its gap in the cleft clause
and coordination of the constituent containing the
clefted constituent and the cleft clause. In our
TAG analysis of it-clefts, the cleft pronoun and
the cleft clause bear a direct syntactic relation be-
cause the elementary trees for the two parts belong
to a single multi-component set. They do not ac-
tually form a syntactic constituent in the derived
tree, but as the elementary trees for the two belong
to the same multi-component set, the intuition that
they form a discontinuous constituent is captured.
Further, the semantics of the two trees is defined
as a definite quantified phrase, capturing the intu-
ition that they form a semantic unit as a definite
description.
Acknowledgment
We thank Anoop Sarkar and the three anonymous
reviewers for their insightful comments.
References
Ann Abeille?. 1994. Syntax or semantics? han-
dling nonlocal dependencies with MCTAGs or Syn-
chronous tags. Computational Intelligence, 10:471?
485.
Adrian Akmajian. 1970. On deriving cleft sentences
from pseudo-cleft sentences. Linguistic Inquiry,
1:149?168.
Noam Chomsky. 1977. On wh-movement. In P. W.
Culicover, T. Wasow, and A. Akmajian, editors, For-
mal Syntax, pages 71?132. Academic Press, New
York.
Gerald P. Delahunty. 1982. Topics in the syntax and
semantics of English cleft sentences. Indiana Uni-
versity Linguistics Club, Bloomington.
Judy L. Delin. 1989. Cleft constructions in discourse.
Ph.D. thesis, University of Edinburgh.
Katalin ?E. Kiss. 1998. Identificatinoal focus versus
information focus. Language, 74(245-273).
Joseph E. Emonds. 1976. A Transformational Ap-
proach to English Syntax. Academic Press, New
York.
Robert Frank. 2002. Phrase Structure Composi-
tion and Syntactic Dependencies. MIT Press, Cam-
bridge, MA.
Jeanette K. Gundel. 1977. Where do cleft sentences
come from? Language, 53:53?59.
Nancy Hedberg. 2000. The referential status of clefts.
Language, 76(4):891?920.
Lorie A. Heggie. 1988. The syntax of copular struc-
tures. Ph.D. thesis, University of Southern Califor-
nia, Los Angeles.
Otto Jesperson. 1927. A Modern English Grammar,
volume 3. Allen and Unwin, London.
Otto Jesperson. 1937. Analytic Syntax. Allen and Un-
win, London.
Anthony S. Kroch and Aravind K. Joshi. 1987. Ana-
lyzing extraposition in a Tree Adjoining Grammar.
In G. Huck and A. Ojeda, editors, Discontinuous
Constituents, volume 20 of Syntax and Semantics.
Academic Press.
Orin Percus. 1997. Prying open the cleft. In
K. Kusumoto, editor, Proceedings of the 27th An-
nual Meeting of the North East Linguistics Society,
pages 337?351. GLSA.
Michael Rochemont. 1986. Focus in Generative
Grammar. John Benjamins, Amsterdam.
Anoop Sarkar and Aravind Joshi. 1996. Coordination
in tree adjoining grammars: formalization and im-
plementation. In Proceedings of COLING?96, pages
610?615, Copenhagen.
Stuart Shieber. 1994. Restricting the weak-generative
capacity of synchronous tree-adjoining grammars.
Computational Intelligence, 10(4).
Edwin Williams. 1980. Predication. Linguistic In-
quiry, 11:203?238.
Jessica R. Wirth. 1978. The derivation of cleft sen-
tences in English. Glossa, 12(58-81).
40
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 41?48,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Pied-Piping in Relative Clauses: Syntax and Compositional Semantics
based on Synchronous Tree Adjoining Grammar
Chung-hye Han
Department of Linguistics
Simon Fraser University
chunghye@sfu.ca
Abstract
In relative clauses, the wh relative pro-
noun can be embedded in a larger phrase,
as in a boy [whose brother] Mary hit.
In such examples, we say that the larger
phrase has pied-piped along with the wh-
word. In this paper, using a similar syntac-
tic analysis for wh pied-piping as in Han
(2002) and further developed in Kallmeyer
and Scheffler (2004), I propose a composi-
tional semantics for relative clauses based
on Synchronous Tree Adjoining Gram-
mar. It will be shown that (i) the elemen-
tary tree representing the logical form of
a wh-word provides a generalized quanti-
fier, and (ii) the semantic composition of
the pied-piped material and the wh-word is
achieved through adjoining in the seman-
tics of the former onto the latter.
1 Introduction
In relative clauses, the wh relative pronoun can be
embedded in a larger phrase, as in (1) and (2). In
such examples, we say that the larger phrase con-
taining the wh-word has PIED-PIPED along with
the wh-word.
(1) a boy [ [whose brother]i Mary hit ti ]
(2) a boy [[whose brother?s friend]i Mary hit ti]
In this paper, using a similar syntactic analysis for
wh pied-piping as in Han (2002) and further devel-
oped in Kallmeyer and Scheffler (2004), I propose
a compositional semantics for relative clauses of
the sort illustrated in (1) and (2), based on Syn-
chronous Tree Adjoining Grammar (STAG). The
two main components of my proposal are that (i)
the semantic tree representing the logical form of a
wh relative pronoun provides a generalized quan-
tifier, and (ii) the semantic composition of the
pied-piped material and the wh-word is achieved
through adjoining of the former onto the latter in
the semantics. Although TAG semantics for rel-
ative clauses based on flat semantics have been
proposed before (Han, 2002; Kallmeyer, 2003), no
STAG-based analysis exists, as far as I know.
In section 2, I introduce the framework of
STAG and STAG-based compositional semantics
and clarify my assumptions. In section 3, I present
my analysis of relative clauses and pied-piping. I
extend the proposed analysis to relative clauses in
which wh-word is in a PP and those in which no
pied-piping has taken place in section 4.
2 STAG-based Compositional Semantics
Before presenting my analysis of relative clauses, I
first illustrate the framework of STAG-based com-
positional semantics and clarify my assumptions,
using a simple sentence that contains an existential
quantifier and an attributive adjective in (3).
(3) John saw a good movie.
I use STAG as defined in Shieber (1994). In an
STAG, each syntactic elementary tree is paired
with one or more semantic trees that represent its
logical form with links between matching nodes.
A synchronous derivation proceeds by mapping a
derivation tree from the syntax side to an isomor-
phic derivation tree in the semantics side, and is
synchronized by the links specified in the elemen-
tary tree pairs. In the tree pairs given in Figure 1,
the trees in the left side are syntactic elementary
trees and the ones in the right side are semantic
trees. In the semantic trees, F stands for formulas,
R for predicates and T for terms. I assume that
these nodes are typed and I represent predicates
as unreduced ?-expressions. The linked nodes are
shown with boxed numbers. For sake of simplic-
ity, in the elementary tree pairs, I only include
links that are relevant for the derivation of given
examples.
Figure 1 contains elementary trees required to
generate the syntactic structure and the logical
41
?(?john) DP
D
John
(??john) T
John?
?
?
(?a movie) DP
D
a
NP 1
N
movie
{(??a movie) T
x
(??a movie) F
?x F
R 1
?x.movie(x)
T
x
F*
}
?
?(?good) NP
AdjP
Adj
good
NP*
(??good) R
R
?x.good(x)
R*
?
?(?saw) TP
DPi? 1 T?
T VP
DP
ti
V?
V
saw
DP? 2
(??saw) F 2
R
?x?y.saw(y, x)
T? 2 T? 1
?
Figure 1: Elementary trees for John saw a good movie.
form of (3). All the syntactic elementary trees sat-
isfy Frank?s (2002) Condition on Elementary Tree
Minimality (CETM), which states that ?the syn-
tactic heads in an elementary tree and their projec-
tions must form an extended projection of a sin-
gle lexical head? (Frank 2002, p. 54). Particu-
larly, (?a movie) is a valid elementary tree, as a
noun can form an extended projection with a DP,
in line with the DP Hypothesis. The proper name
tree in (?John) is paired with a tree representing
a term in the semantics, and the attributive adjec-
tive tree in (?good) is paired with an auxiliary tree
in the semantics that represents a one-place predi-
cate to be adjoined to another one-place predicate.
As for the syntax-semantics pairing of elementary
trees for quantified DPs, I follow Shieber and Sch-
abes (1990), and use Tree Local Multi-Component
TAG (as defined in Weir (1988)) in the seman-
tics. Thus, the DP in (?a movie) is paired with a
multi-component set {(??a movie), (??a movie)}
in the semantics: (??a movie) provides an argu-
ment variable, and (??a movie) provides the ex-
istential quantifier with the restriction and scope.
The transitive tree in (?saw) is paired with a se-
mantic tree representing a formula that consists of
a two-place predicate and two term nodes. The
links, shown with boxed numbers, guarantee that
whatever substitutes into DPi, the corresponding
semantic tree will substitute into the term node
marked with 1 , and whatever substitutes into DP
is paired up with a multi-component set in the se-
mantics where one of the components will substi-
tute into the term node marked with 2 and the
other will adjoin onto the F node marked with
2 . The syntactic and semantic derivation trees
are given in Figure 2, and the derived trees are
given in Figure 3. I leave out the tree addresses
in the semantic derivation tree, as these are deter-
mined by the links between the syntactic and se-
mantic elementary trees.1
?(?3) (?saw)
(?a movie)
DP
(?good)
NP
(?John)
DPi
(??3) (??saw)
{(??a movie), (??a movie)}
(??good)
(??John)
?
Figure 2: Derivation trees for John saw a good
movie.
The semantic derived trees can be reduced by
applying ?-conversion, as the nodes dominate
typed ?-expressions and terms. When reducing se-
mantic derived trees, in addition to ?-conversion, I
propose to use Predicate Modification, as defined
in Heim and Kratzer (1998) in (4).
(4) Predicate Modification
If ? has the form ?
? ?
,
1In sentences with more than one quantified DPs, I as-
sume multiple adjoining (as defined in Schabes and Shieber
(1994)) of quantifier trees at the same F node, leaving the
order unspecified. This provides an underspecified represen-
tation and accounts for scope ambiguity.
42
?(?3) TP
DPi
D
John
T?
T VP
DP
ti
V?
V
saw
DP
D
a
NP
AdjP
Adj
good
NP
N
movie
(??3) F
?x F
R
R
?x.good(x)
R
?x.movie(x)
T
x
F
R
?x?y.saw(y, x)
T
x
T
John?
?
Figure 3: Derived trees for John saw a good movie.
and [[?]]s and [[?]]s are both in D<e,t>, then
[[?]]s = ?xe[[?]]s(x) ? [[?]]s(x).
The application of Predicate Modification and ?-
conversion to (??3) reduces it to the formula in (5).
(5) ?x[good(x) ? movie(x)] [saw(John?, x)]
3 An STAG analysis of pied-piping in
relative clauses
I propose the elementary tree pairs in Figure 4
for the syntactic derivation and semantic compo-
sition of the relative clause in (1). In the syntax
side, (?who) substitutes into DPj in (?hit), and the
pied-piping of the rest of the DP is achieved by ad-
joining (??s brother) onto (?who). The tree in (??s
brother) is a widely-accepted genitive structure ac-
cording to the DP hypothesis, where the genitive ?s
heads the DP tree. This satisfies CETM, as a DP
is an extended projection of a noun. Substituting
(?mary) into DPi in (?hit) completes the deriva-
tion of the relative clause.
The derivation tree for the relative clause is in
(?1) in Figure 5 and the derived tree is in (?1) in
Figure 6.
?(?1) (?hit)
(?who)
DPj
(??s brother)
DP
(?Mary)
DPi
(??1) (??hit)
(??who)
(???s brother)
(??Mary)
?
Figure 5: Derivation trees for whose brother Mary
hit
Semantically, we must make sure that the vari-
able coming from the wh-word is also the one be-
ing predicated of the head noun (boy in (1)), and
yet the same variable does not serve as an argu-
ment of the predicate (hit in (1)) in the relative
clause. I argue that the introduction of a gener-
alized quantifier (GQ) node in the semantic tree in
(??who) and adjoining of (???s brother) onto the
GQ node guarantee this. I define the logical form
of a wh relative pronoun as an auxiliary tree given
in (??who). In (??who), ?x binds x in the gen-
eralized quantifier, ?P.P (x). Adjoining (??who)
onto the relative clause elementary tree in (??hit)
essentially has the effect of abstracting over the
variable coming from the wh-word in the relative
clause, turning it into a one-place predicate. This
therefore ensures that the relative clause and the
head noun are predicating over the same variable,
deriving the interpretation of the relative clause
as a modifier of the head noun. The meaning of
the pied-piped material ?s brother is added onto
the meaning of who by adjoining the auxiliary
tree defined in (???s brother) onto the GQ node
in (??who). In (???s brother), ?y ensures that the
variable coming from the DP* (who) is in some
relation with the variable coming from the head
of the pied-piped DP (whose brother), and ?Q, by
turning whose brother into a GQ, ensures that the
variable coming from the head of the pied-piped
DP is the argument of the predicate that the DP
combines with. The derivation tree and the de-
rived tree in the semantics side are given in (??1)
in Figure 5 and (??1) in Figure 6. After all the ?-
conversions have applied, (??1) can be reduced to
the expression in (6).
(6) ?x.THEz?[brother(z?) ?
Rel(x, z?)] [hit(Mary?, z?)]
43
?(?mary) DP
D
Mary
(??mary) T
Mary?
?
?(??s brother) DP
DP* D?
D
?s
NP
N
brother
(???s brother) GQ
?Q F
GQ* R
?y F
THEz? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
?
?(?hit) NP
NP* CP
DPj? 1 C?
C TP
DPi? 2 T?
T VP
DP
ti
V?
V
hit
DP
tj
(??hit) R
R* R 1
R
?x?y.hit(x, y)
T? 2
?
?(?who) DP
D
who
(??who) R
?x F
GQ
?P.P (x)
R*
?
Figure 4: Elementary trees for whose brother Mary hit
?(?1) NP
NP* CP
DPj
DP
D
who
D?
D
?s
NP
N
brother
C?
C TP
DPi
D
Mary
T?
T VP
DP
ti
V?
V
hit
DP
tj
(??1) R
R* R
?x F
GQ
?Q F
GQ
?P.P (x)
R
?y F
THEz? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
R
R
?x?y.hit(x, y)
T
Mary?
?
Figure 6: Derived trees for whose brother Mary hit
44
The expression in (6) is a one-place predicate
which can be paraphrased as a set of all x?s such
that there is a unique brother z? and x is in some
relation with z? and Mary hit z?. As the seman-
tics of relative clauses is defined to be a one-place
predicate, it is analogous to attributive adjectives.
This means that the semantic tree resulting from
the adjoining of (??1) onto the logical form of the
head noun boy can be reduced to the expression in
(7) through Predication Modification.
(7) ?x.boy(x) ? THEz?[brother(z?) ?
Rel(x, z?)] [hit(Mary?, z?)]
The derivation of a sentence containing (1), a
boy whose brother Mary hit, as the object, as in
(8), proceeds in a similar fashion as in (3), yielding
the semantic derived tree which is reducible to the
formula in (9).
(8) John saw a boy whose brother Mary hit.
(9) ?x[boy(x) ? THEz?[brother(z?) ?
Rel(x, z?)] [hit(Mary?, z?)]] [saw(John?, x)]
For the syntactic derivation and the composi-
tional semantics of the relative clause in (2), all we
need to do is add the tree pair in Figure 7 to the set
of elementary tree pairs in Figure 4. In the syntax
side, (??s friend) adjoins onto (??s brother) and
in the semantics side, (???s friend) adjoins onto
(???s brother), as shown in the derivation trees in
Figure 8. The derived trees are given in Figure 9.
The semantic derived tree (??2) can be reduced to
the expression in (10) through ?-conversions.
?(??s friend) DP
DP* D?
D
?s
NP
N
friend
(???s friend) GQ
?Q F
GQ* R
?y F
THEz? F
F
friend(z?)
F
Rel(y, z?)
F
Q(z?)
?
Figure 7: Elementary trees for ?s friend
(10) ?x.THEz?[brother(z?) ?
Rel(x, z?)] [THEz?[friend(z?) ?
Rel(z?, z?)] [hit(Mary?, z?)]]
?(?2) (?hit)
(?who)
DPj
(??s brother)
DP
(??s friend)
DP
(?Mary)
DPi
(??2) (??hit)
(??who)
(???s brother)
(???s friend)
(??Mary)
?
Figure 8: Derivation trees for whose brother?s
friend Mary hit
4 Extensions
The proposed syntax and the semantics of pied-
piping can straightforwardly be extended to cases
in which the wh-word is embedded in a PP, as in
(11).
(11) a boy [ [DP the brother of whom]i Mary hit
ti ]
For the derivation of (11), we need to change two
of the elementary tree pairs in Figure 4 slightly.
The elementary tree pairs <(?who), (??who)>
and <(??s brother), ???s brother)> need to be re-
placed with the pairs in Figure 10. Since the rel-
ative pronoun in (11) is whom, we use a DP tree
anchoring whom in (?whom). The corresponding
semantic tree (??whom) remains exactly the same
as before. (?the brother of) represents the pied-
piped material in DP. It is a well-formed elemen-
tary tree according to CETM as it has a single lexi-
cal head brother and DP is an extended projection
of this head, and PP is not subject to CETM be-
cause P is a functional head, not a lexical head.
Moreover, DP* is licensed as it is an argument
of the lexical head brother, as argued in Kroch
(1989). The semantics of the brother of whom is
equivalent to whose brother, and therefore, we pair
up (?the brother of) with the exact same semantic
tree as (???s brother).
The derivation trees for the relative clause in
(11) are given in Figure 11. They look exactly the
same as the ones for the relative clause in (1), ex-
cept for names of the elementary trees in a few
nodes. The derived trees are given in Figure 12.
While the syntactic derived tree (?11) is different
from (?1) in Figure 6 in the structure of DP con-
taining the pied-piped material, the semantic de-
rived tree (??11) looks exactly the same as (??1)
in Figure 6. This is as it should be given that the
meaning of (1) and the meaning of (11) are equiv-
alent.
45
?(?2) NP
NP* CP
DPj
DP
DP
D
who
D?
D
?s
NP
N
brother
D?
D
?s
NP
N
friend
C?
C TP
DPi
D
Mary
T?
T VP
DP
ti
V?
V
hit
DP
tj
(??2) R
R* R
?x F
GQ
?Q F
GQ
?Q F
GQ
?P.P (x)
R
?y F
THEz? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
R
?y F
THEz? F
F
friend(z?)
F
Rel(y, z?)
F
Q(z?)
R
R
?x?y.hit(x, y)
T
Mary?
?
Figure 9: Derived trees for whose brother?s friend Mary hit
?(?whom) DP
D
whom
(??whom) R
?x F
GQ
?P.P (x)
R*
?
?(?the brother of) DP
D
the
NP
N
brother
PP
P
of
DP*
(??the brother of) GQ
?Q F
GQ* R
?y F
THEz? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
?
Figure 10: Elementary trees for whom and the brother of
?(?11) NP
NP* CP
DPj
D
the
NP
N
brother
PP
P
of
DP
D
whom
C?
C TP
DPi
D
Mary
T?
T VP
DP
ti
V?
V
hit
DP
tj
(??11) R
R* R
?x F
GQ
?Q F
GQ
?P.P (x)
R
?y F
THEz? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
R
R
?x?y.hit(x, y)
T
Mary?
?
Figure 12: Derived trees for the brother of whom Mary hit
46
?(?11) (?hit)
(?whom)
DPj
(?the brother of)
DP
(?Mary)
DPi
(??11) (??hit)
(??whom)
(??the brother of)
(??Mary)
?
Figure 11: Derivation trees for the brother of
whom Mary hit
?(?a brother of) DP
D
a
NP
N
brother
PP
P
of
DP*
(??a brother of) GQ
?Q F
GQ* R
?y F
?z? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
?
Figure 13: Elementary trees for whom and a
brother of
The proposed analysis can also be extended to
relative clauses in which no pied-piping has taken
place. When the larger DP containing the relative
pronoun is indefinite or non-specific, the DP can
be stranded, as in (12). This gives us a configura-
tion where a wh-word has extracted out of a DP.
(12) a boy [whomi Mary hit [DP a brother of ti]]
Since we now have a DP with an indefinite
article, a tree pair in Figure 13 is needed, for
the derivation of (12). Using the semantic tree
(??a brother of), the semantic composition of the
relative clause in (12) can proceed as before: the
semantic tree (??a brother of) adjoins onto the se-
mantic tree (??whom) in Figure 10, which then
adjoins onto (??hit) in Figure 4. In the syntax,
however, we must make sure that (?a brother of)
does not adjoin onto the relative pronoun whom,
because if it did, we would end up with the string
a brother of whom. Instead, what we need is
for (?a brother of) to adjoin onto the DP domi-
nating the trace of the extracted object in (?hit).
This however is not a valid derivation in STAG,
as elementary trees in a single pair are composing
with two trees from two different pairs. A slight
modification in the syntactic elementary tree for
(?whom) in Figure 14 can fix this problem. I pro-
pose to do this by turning (?whom) into a multi-
component set {(?whom), (?whom)} as in Fig-
ure 14. An auxiliary tree like (?whom), which
?
{(?whom) DP
D
whom
(?whom) DP* }
(??whom) R
?x F
GQ
?P.P (x)
R*
?
Figure 14: Elementary trees for whom
?(?12) (?hit)
{(?whom), (?whom)}
DPj ,DP
(?a brother of)
DP
(?Mary)
DPi
(??12) (??hit)
(??whom)
(??a brother of)
(??Mary)
?
Figure 15: Derivation trees for whom Mary hit a
brother of
does not dominate any other nodes, is a degenerate
tree, and has been used in Kroch (1989) and Frank
(2002) to handle extraction from a wh-island, as in
[Which car]i does Sally wonder how to fix ti?
In syntax, to derive the relative clause in (12),
(?whom) substitutes into DPj in (?hit) as be-
fore, and (?whom) adjoins onto the DP domi-
nating the trace of the extracted object in (?hit),
as shown in the derivation tree (?12) in Figure
15. And in semantics, (??whom) adjoins onto
(??hit) as before, as shown in (??12) in Figure
15. Subsequently, in syntax (?a brother of) ad-
joins onto (?whom) giving us the DP a brother of
tj , and in semantics (??a brother of) adjoins onto
(??whom). Thus, by using the multi-component
set {(?whom), (?whom)}, we now have a situ-
ation where two elementary trees in a single pair
are composing with two trees belonging to another
pair. The syntactic and the semantic derived trees
are given in Figure 16. After ?-conversions, (??12)
can be reduced to the expression in (13).2
(13) ?x.?z?[brother(z?) ?
Rel(x, z?)] [hit(Mary?, z?)]
5 Conclusion
I have shown that STAG-based compositional se-
mantics for relative clauses with pied-piping is
2Partial stranding as in a boy [a picture of whom]i Mary
made a copy of ti can be handled by composing a multi-
component set for whom containing a degenerate DP tree and
another multi-component set for a picture of containing a de-
generate DP tree. Further, the impossibility of the stranding
of subject DP, as in *a boy whomi [a brother of ti] hit Mary,
can be handled by placing an NA constraint on the subject
DP dominating a trace in the relative clause tree.
47
?(?12) NP
NP* CP
DPj
D
whom
C?
C TP
DPi
D
Mary
T?
T VP
DP
ti
V?
V
hit
DP
D
a
NP
N
brother
PP
P
of
DP
tj
(??12) R
R* R
?x F
GQ
?Q F
GQ
?P.P (x)
R
?y F
?z? F
F
brother(z?)
F
Rel(y, z?)
F
Q(z?)
R
R
?x?y.hit(x, y)
T
Mary?
?
Figure 16: Derived trees for whom Mary hit a brother of
possible using examples in which the wh-word
is embedded in a genitive DP, and shown that
the proposed analysis can straightforwardly be ex-
tended to cases in which the wh-word is embed-
ded in a PP. The main ingredients of the proposed
analysis are: in syntax, the pied-piped material ad-
joins to the wh-word, and in semantics, the wh-
word provides a GQ to which the meaning of the
pied-piped material adjoins. I have also shown
that similar analysis can handle cases in which the
wh-word alone has moved to [Spec,CP], strand-
ing the rest of the DP in situ, if we use a multi-
component set containing a degenerate DP for the
syntax of the relative pronoun. The proposed anal-
ysis utilizes composition operations in semantics
that are already available in syntax, substitution
and adjoining, thereby making syntax-semantics
mapping in TAG simple and straightforward.
Acknowledgment
I thank Anoop Sarkar and the three anonymous re-
viewers for their insightful comments.
References
Robert Frank. 2002. Phrase Structure Composi-
tion and Syntactic Dependencies. MIT Press, Cam-
bridge, MA.
Chung-hye Han. 2002. Compositional semantics
for relative clauses in Lexicalized Tree Adjoining
Grammar. A talk presented at TAG+6, Venice, Italy,
www.sfu.ca/?chunghye/papers/tag6-rc-slides.pdf.
Irene Heim and Angelika Kratzer. 1998. Semantics in
Generative Grammar. Blackwell, Oxford.
Laura Kallmeyer and Tatjana Scheffler. 2004. LTAG
analysis for pied-piping and stranding of wh-
phrases. In Proceedings of TAG+7, pages 32?39,
Vancouver, Canada.
Laura Kallmeyer. 2003. LTAG semantics for relative
clauses. In Proceedings of the Fifth International
Workshop on Computational Semantics (IWCS-5),
Tilburg.
Anthony Kroch. 1989. Asymmetries in long-distance
extraction in a Tree Adjoining Grammar. In Mark
Baltin and Anthony Kroch, editors, Alternative Con-
ceptions of Phrase Structure, pages 66?98. Univer-
sity of Chicago Press, Chicago.
Yves Schabes and Stuart M. Shieber. 1994. An al-
ternative conception of Tree-Adjoining derivation.
Computational Linguistics, pages 167?176.
Stuart Shieber and Yves Schabes. 1990. Synchronous
Tree Adjoining Grammars. In Proceedings of COL-
ING?90, Helsinki, Finland.
Stuart Shieber. 1994. Restricting the weak-generative
capacity of Synchronous Tree-Adjoining Gram-
mars. Computational Intelligence, 10(4).
David Weir. 1988. Characterizing Mildly Context-
Sensitive Grammar Formalisms. Ph.D. thesis, Uni-
versity of Pennsylvania.
48
