Automatic Acronym Recognition
Dana Danne?lls
Computational Linguistics, Department of Linguistics and
Department of Swedish Language
Go?teborg University
Go?teborg, Sweden
cl2ddoyt@cling.gu.se
Abstract
This paper deals with the problem
of recognizing and extracting acronym-
definition pairs in Swedish medical texts.
This project applies a rule-based method
to solve the acronym recognition task and
compares and evaluates the results of dif-
ferent machine learning algorithms on the
same task. The method proposed is based
on the approach that acronym-definition
pairs follow a set of patterns and other
regularities that can be usefully applied
for the acronym identification task. Su-
pervised machine learning was applied to
monitor the performance of the rule-based
method, using Memory Based Learning
(MBL). The rule-based algorithm was
evaluated on a hand tagged acronym cor-
pus and performance was measured using
standard measures recall, precision and f-
score. The results show that performance
could further improve by increasing the
training set and modifying the input set-
tings for the machine learning algorithms.
An analysis of the errors produced indi-
cates that further improvement of the rule-
based method requires the use of syntactic
information and textual pre-processing.
1 Introduction
There are many on-line documents which contain
important information that we want to understand,
thus the need to extract glossaries of domain-
specific names and terms increases, especially in
technical fields such as biomedicine where the vo-
cabulary is quickly expanding. One known phe-
nomenon in biomedical literature is the growth of
new acronyms.
Acronyms are a subset of abbreviations and
are generally formed with capital letters from the
original word or phrase, however many acronyms
are realized in different surface forms i.e. use
of Arabic-numbers, mixed alpha-numeric forms,
low-case acronyms etc.
Several approaches have been proposed for au-
tomatic acronym extraction, with the most com-
mon tools including pattern-matching techniques
and machine learning algorithms. Considering the
large variety in the Swedish acronym-definition
pairs it is practical to use pattern-matching tech-
niques. These will enable to extract relevant in-
formation of which a suitable set of schema will
give a representation valid to present the different
acronym pairs.
This project presents a rule-based algorithm to
process and automatically detect different forms of
acronym-definition pairs. Since machine learning
techniques are generally more robust, can easily
be retrained for a new data and successfully clas-
sify unknown examples, different algorithms were
tested. The acronym pair candidates recognized
by the rule-based algorithm were presented as fea-
ture vectors and were used as the training data for
the supervised machine learning system.
This approach has the advantage of using ma-
chine learning techniques without the need for
manual tagging of the training data. Several ma-
chine learning algorithms were tested and their re-
sults were compared on the task.
2 Related work
The task of automatically extracting acronym-
definition pairs from biomedical literature has
been studied, almost exclusively for English, over
the past few decades using technologies from Nat-
ural Language Processing (NLP). This section
167
presents a few approaches and techniques that
were applied to the acronym identification task.
Taghva and Gilbreth (1999) present the
Acronyms Finding Program (AFP), based on
pattern matching. Their program seeks for
acronym candidates which appear as upper case
words. They calculate a heuristic score for each
competing definition by classifying words into:
(1) stop words (?the?, ?of?, ?and?), (2) hyphen-
ated words (3) normal words (words that don?t
fall into any of the above categories) and (4) the
acronyms themselves (since an acronym can
sometimes be a part of the definition). The AFP
utilizes the Longest Common Subsequence (LCS)
algorithm (Hunt and Szymanski, 1977) to find all
possible alignments of the acronym to the text,
followed by simple scoring rules which are based
on matches. The performance reported from their
experiment are: recall of 86% at precision of 98%.
An alternative approach to the AFP was pre-
sented by Yeates (1999). In his program, Three
Letters Acronyms (TLA), he uses more complex
methods and general heuristics to match charac-
ters of the acronym candidate with letters in the
definition string, Yeates reported f-score of 77.8%.
Another approach recognizes that the align-
ment between an acronym and its definition of-
ten follows a set of patterns (Park and Byrd,
2001), (Larkey et al, 2000). Pattern-based meth-
ods use strong constraints to limit the number of
acronyms respectively definitions recognized and
ensure reasonable precision.
Nadeau and Turney (2005) present a machine
learning approach that uses weak constraints to re-
duce the search space of the acronym candidates
and the definition candidates, they reached recall
of 89% at precision of 88%.
Schwartz and Hearst (2003) present a simple al-
gorithm for extracting abbreviations from biomed-
ical text. The algorithm extracts acronym candi-
dates, assuming that either the acronym or the def-
inition occurs between parentheses and by giving
some restrictions for the definition candidate such
as length and capital letter initialization. When an
acronym candidate is found the algorithm scans
the words in the right and left side of the found
acronym and tries to match the shortest definition
that matches the letters in the acronym. Their ap-
proach is based on previous work (Pustejovsky et
al., 2001), they achieved recall of 82% at precision
of 96%.
It should be emphasized that the common char-
acteristic of previous approaches in the surveyed
literature is the use of parentheses as indication for
the acronym pairs, see Nadeau and Turney (2005)
table 1. This limitation has many drawbacks
since it excludes the acronym-definition candi-
dates which don?t occur within parentheses and
thereby don?t provide a complete coverage for all
the acronyms formation.
3 Methods and implementation
The method presented in this section is based on
a similar algorithm described by Schwartz and
Hearst (2003). However it has the advantage of
recognizing acronym-definition pairs which are
not indicated by parentheses.
3.1 Finding Acronym-Definition Candidates
A valid acronym candidate is a string of alpha-
betic, numeric and special characters such as ?-?
and ?/?. It is found if the string satisfies the condi-
tions (i) and (ii) and either (iii) or (iv):
(i) The string contains at least two charac-
ters. (ii) The string is not in the list of rejected
words1. (iii) The string contains at least one capi-
tal letter. (iv) The strings? first or last character is
lower case letter or numeric.
When an acronym is found, the algorithm
searches the words surrounding the acronym for a
definition candidate string that satisfies the follow-
ing conditions (all are necessary in conjunction):
(i) At least one letter of the words in the string
matches the letter in the acronym. (ii) The string
doesn?t contain a colon, semi-colon, question
mark or exclamation mark. (iii) The maximum
length of the string is min(|A|+5,|A|*2), where
|A| is the acronym length (Park and Byrd, 2001).
(iv) The string doesn?t contain only upper case let-
ters.
3.2 Matching Acronyms with Definitions
The process of extracting acronym-definition pairs
from a raw text, according to the constraints de-
scribed in Section 3.1 is divided into two steps:
1. Parentheses matching. In practice, most of
the acronym-definition pairs come inside paren-
theses (Schwartz and Hearst, 2003) and can cor-
respond to two different patterns: (i) defini-
tion (acronym) (ii) acronym (definition). The
1The rejected word list contains frequent acronyms which
appear in the corpus without their definition, e.g. ?USA?,
?UK?, ?EU?.
168
algorithm extracts acronym-definition candidates
which correspond to one of these two patterns.
2. Non parentheses matching. The algorithm
seeks for acronym candidates that follow the con-
straints, described in Section 3.1 and are not en-
closed in parentheses. Once an acronym candidate
is found it scans the previous and following con-
text, where the acronymwas found, for a definition
candidate. The search space for the definition can-
didate string is limited to four words multiplied by
the number of letters in the acronym candidate.
The next step is to choose the correct substring
of the definition candidate for the acronym can-
didate. This is done by reducing the definition
candidate string as follows: the algorithm searches
for identical characters between the acronym and
the definition starting from the end of both strings
and succeeds in finding a correct substring for
the acronym candidate if it satisfies the follow-
ing conditions: (i) at least one character in the
acronym string matches with a character in the
substring of the definition; (ii) the first character
in the acronym string matches the first character
of the leftmost word in the definition substring, ig-
noring upper/lower case letters.
3.3 Machine Learning Approach
To test and compare different supervised learn-
ing algorithms, Tilburg Memory-Based Learner
(TiMBL)2 was used. In memory-based learning
the training set is stored as examples for later eval-
uation. Features vectors were calculated to de-
scribe the acronym-definition pairs. The ten fol-
lowing (numeric) features were chosen: (1) the
acronym or the definition is between parenthe-
ses (0-false, 1-true), (2) the definition appears be-
fore the acronym (0-false, 1-true), (3) the dis-
tance in words between the acronym and the
definition, (4) the number of characters in the
acronym, (5) the number of characters in the def-
inition, (6) the number of lower case letters in the
acronym, (7) the number of lower case letters in
the definition, (8) the number of upper case let-
ters in the acronym, (9) the number of upper case
letters in the definition and (10) the number of
words in the definition. The 11th feature is the
class to predict: true candidate (+), false candi-
date (-). An example of the acronym-definition
pair ??vCJD?, ?variant CJD?? represented as
a feature vector is: 0,1,1,4,11,1,7,3,3,2,+.
2http://ilk.uvt.nl
4 Evaluation and Results
4.1 Evaluation Corpus
The data set used in this experiment consists of
861 acronym-definition pairs. The set was ex-
tracted from Swedish medical texts, the MEDLEX
corpus (Kokkinakis, 2006) and was manually an-
notated using XML tags. For the majority of the
cases there exist one acronym-definition pair per
sentence, but there are cases where two or more
pairs can be found.
4.2 Experiment and Results
The rule-based algorithm was evaluated on the un-
tagged MEDLEX corpus samples. Recall, pre-
cision and F-score were used to calculate the
acronym-expansion matching. The algorithm rec-
ognized 671 acronym-definition pairs of which 47
were incorrectly identified. The results obtained
were 93% precision and 72.5% recall, yielding F-
score of 81.5%.
A closer look at the 47 incorrect acronym pairs
that were found showed that the algorithm failed
to make a correct match when: (1) words that
appear in the definition string don?t have a corre-
sponding letter in the acronym string, (2) letters
in the acronym string don?t have a corresponding
word in the definition string, such as ?PGA? from
?glycol alginate lo?sning?, (3) letters in the defini-
tion string don?t match the letters in the acronym
string.
The error analysis showed that the reasons for
missing 190 acronym-definition pairs are: (1) let-
ters in the definition string don?t appear in the
acronym string, due to a mixture of a Swedish
definition with an acronym written in English,
(2) mixture of Arabic and Roman numerals, such
as ?USH3? from ?Usher typ III?, (3) position of
numbers/letters, (4) acronyms of three characters
which appear in lower case letters.
4.3 Machine Learning Experiment
The acronym-definition pairs recognized by the
rule-based algorithm were used as the training ma-
terial in this experiment. The 671 pairs were pre-
sented as feature vectors according to the features
described in Section 3.3. The material was di-
vided into two data files: (1) 80% training data;
(2) 20% test data. Four different algorithms were
used to create models. These algorithms are: IB1,
IGTREE, TRIBL and TRIBL2. The results ob-
tained are given in Table 1.
169
Algorithm Precision Recall F-score
IB1 90.6 % 97.1 % 93.7 %
IGTREE 95.4 % 97.2 % 96.3 %
TRIBL 92.0 % 96.3 % 94.1 %
TRIBL2 92.8 % 96.3 % 94.5 %
Table 1: Memory-Based algorithm results.
5 Conclusions
The approach presented in this paper relies on
already existing acronym pairs which are seen
in different Swedish texts. The rule-based algo-
rithm utilizes predefined strong constraints to find
and extract acronym-definition pairs with differ-
ent patterns, it has the advantage of recognizing
acronyms and definitions which are not indicated
by parentheses. The recognized pairs were used
to test and compare several machine learning al-
gorithms. This approach does not requires manual
tagging of the training data.
The results given by the rule-based algorithm
are as good as reported from earlier experiments
that have dealt with the same task for the English
language. The algorithm uses backward search al-
gorithm and to increase recall it is necessary to
combine it with forward search algorithm.
The variety of the Swedish acronym pairs is
large and includes structures which are hard to de-
tect, for example: ??V F?, ?kammarflimmer??
and ??CT?, ?datortomografi??, the acronym
is in English while the extension is written in
Swedish. These structures require a dictio-
nary/database lookup3, especially because there
are also counter examples in the Swedish text
where both the acronym and the definition are in
English. Another problematic structure is three
letter acronyms which consist of only lowercase
letters since there are many prepositions, verbs and
determinates that correspond to this structure. To
solve this problem it may be suitable to combine
textual pre-processing such as part-of-speech an-
notation or/and parsing with the exiting code.
The machine learning experiment shows that
the best results were given by the IGTREE algo-
rithm4. Performance can further improve by mod-
ifying the input settings e.g test different feature
weighting schemes, such as Shared Variance and
3Due to short time available and the lack of resources this
feature was not used in the experiment.
4The IGTREE algorithm uses information gain in a com-
pressed decision tree structure.
Gain Ratio and combine different values of k for
the k-nearest neighbour classifier5.
On-going work aim to improve the rule-based
method and combine it with a supervised machine
learning algorithm. The model produced will later
be used for making prediction on a new data.
Acknowledgements
Project funded in part by the SematicMining EU
FP6 NoE 507505. This research has been car-
ried out thanks to Lars Borin and Dimitrios Kokki-
nakis. I thank Torbjo?rn Lager for his guidance
and encouragement. I would like to thank Walter
Daelemans, Ko van der Sloot Antal van den Bosch
and Robert Andersson for their help and support.
References
Ariel S. Schwartz and Marti A. Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical texts. Proc. of the Pacific Symposium on
Biocomputing. University of California, Berkeley.
David Nadeau and Peter Turney. 2005. A Supervised
Learning Approach to Acronym Identification. In-
formation Technology National Research Council,
Ottawa, Ontario, Canada.
Dimitrios Kokkinakis. 2006. Collection, Encoding
and Linguistic Processing of a Swedish Medical
Corpus: The MEDLEX Experience. Proc. of the 5th
LREC. Genoa, Italy.
James W. Hunt and Thomas G. Szymanski. 1977. A
fast algorithm for computing longest common sub-
sequences. Commun. of the ACM, 20(5):350-353.
James Pustejovsky, Jose? Castan?o, Brent Cochran, Ma-
ciej Kotecki and Michael Morrella. 2001. Au-
tomation Extraction of Acronym-MeaningPairs from
Medline Databases. In Proceedings of Medinfo.
Kazen Taghva and Jeff Gilbreth. 1999. Technical Re-
port. Recognizing Acronyms and their Definitions.
University of Nevada, Las Vegas.
Leah S. Larkey, Paul Ogilvie, Andrew M. Price and
Brenden Tamilio. 2000. Acrophile: An Automated
Acronym Extractor and Server. University of Mas-
sachusetts, Dallas TX.
Stuart Yeates. 1999. Automatic extraction of acronyms
from text. Proc. of the Third New Zealand Computer
Science Research Students? Conference. University
of Waikato, New Zealand.
Youngja Park and Roy J. Byrd. 2001. Hybrid Text Min-
ing for Finding Abbreviations and Their Definitions.
IMB Thomas J. Watson Research Center, NY, USA.
5In the machine learning experiment default value is used,
k=1.
170
Applying semantic frame theory to automate natural language
template generation from ontology statements
Dana Danne?lls
NLP research unit, Department of Swedish Language
University of Gothenburg, SE-405 30 Gothenburg, Sweden
dana.dannells@svenska.gu.se
Abstract
Today there exist a growing number of
framenet-like resources offering seman-
tic and syntactic phrase specifications that
can be exploited by natural language gen-
eration systems. In this paper we present
on-going work that provides a starting
point for exploiting framenet information
for multilingual natural language genera-
tion. We describe the kind of information
offered by modern computational lexical
resources and discuss how template-based
generation systems can benefit from them.
1 Introduction
Existing open-source multilingual natural lan-
guage generators such as NaturalOWL (Galanis
and Androutsopoulos, 2007) and MPIRO (Isard et
al., 2003) require a large amount of manual lin-
guistic input to map ontology statements onto se-
mantic and syntactic structures, as exemplified in
Table 1. In this table, each statement contains a
property and two instances; each template con-
tains the lexicalized, reflected property and the two
ontology classes (capitalized) the statement?s in-
stances belong to.
Ontology statement Sentence template
painted-by (ex14, p-Kleo) VESSEL was decorated by PAINTER
exhibit-depicts (ex12, en914) PORTRAIT depicts EXHIBIT-STORY
current-location (ex11, wag-mus) COIN is currently displayed in MUSEUM
Table 1: MPIRO ontology statements and their
corresponding sentence templates.
Consider adapting such systems to museum vis-
itors in multilingual environments: as each state-
ment is packaged into a sentence through a fixed
sentence template, where lexical items, style of
reference and linguistic morphology have already
been determined, this adaptation process requires
an extensive amount of manual input for each lan-
guage, which is a labour-intensive task.
One way to automate this natural language map-
ping process, avoiding manual work is through
language-specific resources that provide semantic
and syntactic phrase specifications that are, for ex-
ample, presented by means of lexicalized frames.
An example of such a resource in which frame
principles have been applied to the description and
the analysis of lexical entries from a variety of se-
mantic domains is the Berkeley FrameNet (FN)
project (Fillmore et al, 2003). The outcome of
the English FN has formed the basis for the devel-
opment of more sophisticated and computation-
ally oriented multilingual FrameNets that today
are freely available (Boas, 2009).
This rapid development in computational lexi-
cography circles has produced a growing number
of framenet-like resources that we argue are rel-
evant for natural language generators. We claim
that semantic and syntactic information, such as
that provided in a FrameNet, facilitates mapping
of ontology statements to natural language. In
this paper we describe the kind of information
which is offered by modern computational lexi-
cal resources and discuss how template-based nat-
ural language generation (NLG) systems can ben-
efit from them.
1.1 Semantic frames
A frame, according to Fillmore?s frame semantics,
describes the meaning of lexical units with refer-
ence to a structured background that motivates the
conceptual roles they encode. Conceptual roles
are represented with a set of slots called frame
elements (FEs). A semantic frame carries infor-
mation about the different syntactic realizations of
the frame elements (syntactic valency), and about
their semantic characteristics (semantic valency).
A frame can be described with the help of
two types of frame elements that are classified
in terms of how central they are to a particular
frame, namely: core and peripheral. A core ele-
ment is one that instantiates a conceptually nec-
essary component of a frame while making the
frame unique and different from other frames. A
peripheral element does not uniquely characterize
a frame and can be instantiated in any semantically
appropriate frame.
1.2 The language generation module
The kind of language generation system discussed
here consists of a language generation module
that is guided by linguistic principles to map its
non-linguistic input (i.e. a set of logical state-
ments) to syntactic and semantic templates. This
kind of generation system follows the approaches
that have been discussed elsewhere (Reiter, 1999;
Busemann and Horacek, 1998; Geldof and van de
Velde, 1997; Reiter and Mellish, 1993).
The goal of the proposed module is to associate
an ontology statement with relevant syntactic and
semantic specifications. This generation process
should be carried out during microplanning (cf.
Reiter and Dale (2000)) before aggregation and re-
ferring expression generation take place.
1.3 The knowledge representation
The knowledge representation which serves as the
input to the language generator is a structured on-
tology specified in the Web Ontology Language
(OWL) (Berners-Lee, 2004) on which programs
can perform logical reasoning over data.
Ontological knowledge represented in OWL
contains a hierarchical description of classes (con-
cepts) and properties (relations) in a domain. It
may also contain instances that are associated with
particular classes, and assertions (axioms), which
allow reasoning about them. Generating linguis-
tic output from this originally non-linguistic input
requires instantiations of the ontology content, i.e.
concepts, properties and instances by lexical units.
2 From ontology statements to template
specifications
Our approach to automatic template generation
from ontology statements has three major steps:
(1) determining the base lexeme of a statement?s
property and identifying the frame it evokes,1 (2)
matching the statement?s associated concepts with
the frame elements, and (3) extracting the syntac-
tic patterns that are linked to each frame element.
1Base lexemes become words after they are subjected to
morphological processing which is guided by the syntactic
context.
The remainder of this section describes how
base lexemes are chosen and how information
about the syntactic and semantic distribution of the
lexemes underlying an ontological statement are
acquired.
2.1 Lexical units? determination and frame
identification
The first, most essential step that is required for
recognizing which semantic frame is associated
with an ontology statement is lexicalization. Most
Web ontologies contain a large amount of linguis-
tic information that can be exploited to map the
ontology content to linguistic units automatically
(Mellish and Sun, 2006). However, direct verbal-
ization of the ontology properties and concepts re-
quires preprocessing, extensive linguistic knowl-
edge and sophisticated disambiguation algorithms
to produce accurate results. For the purposes of
this paper where we are only interested in lexical-
izing the ontology properties, we avoid applying
automatic verbalization; instead we choose man-
ual lexicalization.
The grammatical categories that are utilized to
manifest the ontology properties are verb lexemes.
These are determined according to the frame defi-
nitions and with the help of the ontology class hi-
erarchy. For example, consider the statement cre-
ate (bellini, napoleon). In this domain, i.e. the
cultural heritage domain, the property create has
two possible interpretations: (1) to create a physi-
cal object which serves as the representation of the
presented entity, (2) to create an artifact that is an
iconic representation of an actual or imagined en-
tity or event. FrameNet contains two frames that
correspond to these two definitions, namely: Cre-
ate Representation and Create physical artwork.
Figure 1: A fragment of the ontology.
By following the ontological representation de-
parting from the given instances, as illustrated in
Figure 1, we learn that bellini is an instance of the
class Actor, napoleon is an instance of the class
Represented Object, and that napoleon is the rep-
resented entity in the painting p-163. Thus, in this
context, an appropriate lexicalization of the prop-
erty create is the verb paint which evokes the Cre-
ate Representation frame.
For clarity, we specify in Table 2 part of the in-
formation that is coded in the frame. In this ta-
ble we find the name of the frame, its definition,
the set of lexical units belonging to the frame, the
names of its core elements and a number of sen-
tences annotated with these core FEs.
Create representation
Def
A Creator produces a physical object which is to serve as a Representation
of an actual or imagined entity or event, the Represented.
LUs carve.v, cast.v, draw.v, paint.v, photograph.v, sketch.v
core
Creator (C) (1) Since [ Frans]C PHOTOGRAPHED [them]R ten
FEs
years ago the population has increased.
(2) [ Picasso]C DREW [some violent-looking birds]R .
Represented (R) (3) When [ Nadar]C PHOTOGRAPHED [ her ]R ,
Desbordes-Valmore was sixty-eight.
(4) [ Munch]C PAINTED [ himself ]R as a ghost.
Table 2: Frame Create representation.
2.2 Matching the ontology concepts with
frame elements
In this step, the set of core frame elements which
function as the obligatory arguments of the re-
quired lexeme are matched with their correspond-
ing ontology concepts. The algorithm that is ap-
plied to carry out this process utilizes the FE Tax-
onomy and the ontology class hierarchy.2
Matching is based on the class hierarchies. For
example: Actor, which is a subclass of Person is
matched with the core element Creator, which is
a subclass of Agent because they are both charac-
terized as animate objects that have human prop-
erties. Similarly, Represented Object, which is a
subclass of Conceptual Object, is matched with
the core element Represented, which is a subclass
of Entity because they are both characterized as
the results of a human creation that comprises non-
material products of the human mind.
This matching process leads to consistent speci-
fications of the semantic roles specifying sentence
constituents which are not bound to the input on-
tology structure.3
2.3 Semantic and syntactic knowledge
extraction
Semantic frames, besides providing information
about a lexeme?s semantic content, provide infor-
mation about the valency pattern associated with
2The Frame Element Taxonomy: http://www.
clres.com/db/feindex.html
3One of the basic assumptions of our approach is that se-
mantically, languages have a rather high degree of similarity,
whereas syntactically they tend to differ.
it, i.e. how semantic roles are realized syntac-
tically and what are the different types of gram-
matical functions they may fulfill when occurring
with other elements. An example of the syntactic
patterns and possible realizations of the semantic
elements that appear in the Create representation
frame are summarized in Table 3.4 From this in-
formation we learn the kind of syntactic valency
patterns that are associated with each semantic el-
ement. For example, we learn that in active con-
structions Creator appears in the subject position
while in passive constructions it follows the prepo-
sition by. It can also be eliminated in passive con-
structions when other peripheral elements appear
(Example 2), in this case it is the FE Time (T).
Although it is a peripheral element, it plays an im-
portant role in this context.
FEs Syntactic Pattern
[C, R] [ [ NP Ext], [NPObj ] ]
Example 1: [Leonardo da Vinci]C painted [this scene]R
[R, T] [ [ [NPExt], PP[in]Dep] ]
Example 2: [The lovely Sibyls]R were painted in [the last century]T .
[R, C, T] [ [ NP Ext] , [ PP[by]Dep], [ PP[in]Dep] ]
Example 3: [The Gerichtsstube]R was painted by [Kuhn]C in [1763]T .
Table 3: Syntactic realizations of the lexical entry
paint.
This knowledge is extracted automatically from
the FN database and is converted to sentence spec-
ifications with the help of a simple Perl script. Be-
low is a template example which specifies the sen-
tence construction of the sentence in Example 3:
(template ( type: passive)
(( head: |paint|) (feature: (tense: past) )
( arg1 (Represented (head: |gerichtsstube|) (
determiner: |the|))
arg2 (Creator (head: |kuhn|) (mod: |by|))
arg3 (Time (head: |1763|) (mod: |in|))))
3 Testing the method
To test our approach, we employ the MPIRO do-
main ontology content.5 Table 4 illustrates some
of the results, i.e. examples of the ontology state-
ments, the frame that matched their property lex-
icalization, and their possible realization patterns
that were extracted from the English FrameNet.
The results demonstrate some of the advantages
of the syntactic and semantic valency properties
provided in FN that are relevant for expressing nat-
ural language. These include: Verb collocations
4FN?s abbreviations: Constructional Null Instantia-
tion (CNI), External Argument (Ext), Dependent (Dep).
5<http://users.iit.demokritos.gr/
?eleon/ELEONDownloads.html>
Nr Ontology statement Frame Possible realization patterns
(1) depict (portraitMED , storyITE) Communicate MEDIUM depict CATEGORY.
categorization MEDIUM depict ITEM of CATEGORY.
(2) depict (modigCRE , portraitREP ) Create physical artwork CREATOR paint REPRESENTATION.
CREATOR paint REPRESENTATION
from REFERENCE in PLACE.
(3) depict (kuhnCRE , flowerREP ) Create representation CREATOR paint REPRESENTED.
REPRESENTED is painted by CREATOR in TIME.
(4) locate (portraitTHE , louvreLOC) Being located THEME is located LOCATION.
(5) copy (portraitORI , portraitCOP ) Duplication COPY replicate ORIGINAL.
CREATOR replicate ORIGINAL.
Table 4: Ontology statements and their possible realization patterns extracted from frames. Each instance
is annotated with the three first letters of the core frame element it has been associated with.
examples (1) and (2). Intransitive usages, exam-
ple (4). Semantic focus shifts, examples (3) and
(5). Lexical variations and realizations of the same
property, examples (1), (2) and (3).
4 Discussion and related work
Applying frame semantics theory has been sug-
gested before in the context of multilingual lan-
guage generation (De Bleecker, 2005; Stede,
1996). However, to our knowledge, no generation
application has tried to extract semantic frame in-
formation directly from a framenet resource and
integrate the extracted information in the genera-
tion machinery. Perhaps because it is not until now
that automatic processing of multilingual framenet
data become available (Boas, 2009). Moreover,
the rapid increase of Web ontologies has only re-
cently become acknowledged in the NLG commu-
nity, who started to recognize the new needs for
establishing feasible methods that facilitate gen-
eration and aggregation of natural language from
these emerging standards (Mellish and Sun, 2006).
Authors who have been experimenting with
NLG from Web ontologies (Bontcheva and Wilks,
2004; Wilcock and Jokinen, 2003) have demon-
strated the usefulness of performing aggregation
and applying some kind of discourse structures in
the early stages of the microplanning process. As
mentioned in Section 1.1, peripheral elements can
help in deciding on how the domain information
should be packed into sentences. In the next step
of our work, when we proceed with aggregations
and discourse generation we intend to utilize the
essential information provided by these elements.
Currently, the ontology properties are lexical-
ized manually, a process which relies solely on the
frames and the ontology class hierarchies. To in-
crease efficiency and accuracy, additional lexical
resources such as WordNet must be integrated into
the system. This kind of integration has already
proved feasible in the context of NLG (Jing and
McKeown, 1998) and has several implications for
automatic lexicalization.
5 Conclusions
In this paper we presented on-going research on
applying semantic frame theory to automate natu-
ral language template generation.
The proposed method has many advantages.
First, the extracted templates and syntactic alterna-
tions provide varying degrees of complexity of lin-
guistic entities which eliminate the need for man-
ual input of language-specific heuristics. Second,
the division of phases and the separation of the dif-
ferent tasks enables flexibility and re-use possibil-
ities. This is in particular appealing for modular
NLG systems. Third, it provides multilingual ex-
tension possibilities. Framenet resources offer an
extended amount of semantic and syntactic phrase
specifications that are only now becoming avail-
able in languages other than English. Because
non-English framenets share the same type of con-
ceptual backbone as the English FN, the steps in-
volved in adapting the proposed method to other
languages mainly concern lexicalization of the on-
tology properties.
Future work aims to enhance the proposed
method along the lines discussed in Section 4 and
test it on the Italian and Spanish framenets. We
intend to experiment with the information about
synonymous words and related terms provided in
FN (which we haven?t taken advantage of yet) and
demonstrate how existing NLG applications that
are designed to accommodate different user needs
can benefit from it.
Acknowledgments
The author would like to express her gratitude to
Maria Toporowska Gronostaj for useful discus-
sions about lexical semantics and to Olga Caprotti
for making suggestions for improving the paper.
I thank three anonymous reviewers for their en-
couraging comments on an earlier version of this
paper.
References
Tim Berners-Lee. 2004. OWL Web Ontology Lan-
guage reference, February. W3C Recommendation.
Hans C. Boas. 2009. Multilingual FrameNets in Com-
putational Lexicography.
Kalina Bontcheva and Yorick Wilks. 2004. Automatic
report generation from ontologies: the MIAKT ap-
proach. In Proceedings of the Nineth International
Conference on Applications of Natural Language to
Information Systems (NLDB), pages 324?335.
Stephan Busemann and Helmut Horacek. 1998. A
flexible shallow approach to text generation. In Pro-
ceedings of the 9th International Workshop on Nat-
ural Language Generation (IWNLG 98), pages 238?
247, Niagara-on-the-Lake, Ontario.
Inge M. R. De Bleecker. 2005. Towards an optimal
lexicalization in a natural-sounding portable natural
language generator for dialog systems. In ACL ?05:
Proceedings of the ACL Student Research Workshop,
pages 61?66, Morristown, NJ, USA. Association for
Computational Linguistics.
Charles J. Fillmore, Christopher R. Johnson, and
Miriam R.L. Petruck. 2003. Background to
framenet. International Journal of Lexicography,
16(3):235?250.
Dimitrios Galanis and Ion Androutsopoulos. 2007.
Generating multilingual descriptions from linguisti-
cally annotated OWL ontologies: the NaturalOWL
system. In Proceedings of the 11th European
Workshop on Natural Language Generation, Schloss
Dagstuhl.
Sabine Geldof and Walter van de Velde. 1997. An
architecture for template-based (hyper)text genera-
tion. In Proceedings of the Sixth European Work-
shop on Natural Language Generation, pages 28?
37, Duisburg, Germany.
Amy Isard, Jon Oberlander, Ion Androutsopoulos,
and Colin Matheson. 2003. Speaking the users?
languages. IEEE Intelligent Systems Magazine,
18(1):40?45.
Hongyan Jing and Kathleen McKeown. 1998. Com-
bining multiple, large-scale resources in a reusable
lexicon for natural language generation. In Proceed-
ings of the 17th international conference on Compu-
tational linguistics, pages 607?613, Morristown, NJ,
USA. Association for Computational Linguistics.
Chris Mellish and Xiantang Sun. 2006. The semantic
web as a linguistic resource: Opportunities for natu-
ral language generation. Knowledge-Based Systems,
19(5):298?303.
Ehud Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. MIT Press and The
McGraw-Hill Companies, Inc.
Ehud Reiter and Chris Mellish. 1993. Optimizing the
costs and benefits of natural language generation.
In Proceedings of the 13th International Joint Con-
ference on Artificial Intelligence (IJCAI 93), pages
1164?1169, Chambery, France.
Ehud Reiter. 1999. Shallow vs. deep techniques for
handling linguistic constraints and optimisations. In
DFKI, editor, In Proceedings of the KI99 Workshop.
Manfred Stede. 1996. Lexical semantics and knowl-
edge representation in multilingual sentence gener-
ation. Ph.D. thesis, Department of Computer Sci-
ence, University of Toronto.
Graham Wilcock and Kristiina Jokinen. 2003. Gen-
erating responses and explanations from RDF/XML
and DAML+OIL. In Knowledge and Reasoning
in Practical Dialogue Systems IJCAI, pages 58?63,
Acapulco.
Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 18?23,
Avignon, France, 24 April 2012. c?2012 Association for Computational Linguistics
Toward a Language Independent Methodology for Generating
Artwork Descriptions ? Exploring Framenet Information
Dana Dann?lls
Spr?kbanken
Department of Swedish
University of Gothenburg, Sweden
dana.dannells@svenska.gu.se
Lars Borin
Spr?kbanken
Department of Swedish
University of Gothenburg, Sweden
lars.borin@svenska.gu.se
Abstract
Today museums and other cultural her-
itage institutions are increasingly stor-
ing object descriptions using seman-
tic web domain ontologies. To make
this content accessible in a multilin-
gual world, it will need to be conveyed
in many languages, a language gen-
eration task which is domain specific
and language dependent. This paper
describes how semantic and syntactic
information such as that provided in a
framenet can contribute to solving this
task. It is argued that the kind of in-
formation offered by such lexical re-
sources enhances the output quality of
a multilingual language generation ap-
plication, in particular when generat-
ing domain specific content.
1 Introduction
Today museums and other cultural her-
itage institutions are increasingly storing ob-
ject descriptions using structured informa-
tion representation formats, such as seman-
tic web domain ontologies. To make such
cultural heritage content accessible to differ-
ent groups and individuals in a multilingual
world, this information will need to be con-
veyed in textual or spoken form in many lan-
guages, a language generation task which is
domain specific and language dependent.
Generating multilingual natural language
texts from domain specific semantic repre-
sentations, such as semantic web domain on-
tologies, is a task which involves lexicaliza-
tion and syntactic realization of the discourse
relations. This paper deals with the syntac-
tic realization problem, which is best illus-
trated with an example. Consider the pos-
sible formulations of the semantic relation
Create_representation that has been lexicalized
with the English verb paint:
1. Leonardo da Vinci painted this scene.
2. The lovely Sibyls were painted in the last cen-
tury.
3. The Gerichtsstube was painted by Kuhn in
1763.
The syntactic structure of each sentence
differs in terms of the semantic roles of the
verb arguments and other constituents of the
sentence. The first sentence contains the se-
mantic roles Creator and Represented, the sec-
ond sentence contains Represented and Time,
and in the third sentence we find Creator, Rep-
resented and Time.
As the examples show there are several
ways of semantically characterizing the sit-
uation expressed by a verb, with implica-
tions for the syntactic realization of that verb.
When generating natural language from se-
mantic web ontologies it is important to find
generic strategies that allow us to identify
the semantic elements of a verb and associate
them with the appropriate argument realiza-
tion of that verb. This is particularly relevant
in multilingual settings because the semantic
and syntactic behavior of verbs will vary de-
pending on the target language, both in the
constructions found and in their distribution.
Previous work on natural language gener-
ation of cultural heritage information from
semantic web ontologies has relied on a
large amount of specially tailored manual
linguistic information to produce descrip-
tions that are targeted to a specific group of
readers (Androutsopoulos et al, 2001; Dan-
18
n?lls, 2008; Konstantopoulos et al, 2009). Al-
though valuable information for generating
natural languages is found in computational
lexical-semantic resources such as the Berke-
ley FrameNet (section 3) which exist today in
several languages (Erk et al, 2003; Subirats
and Petruck, 2003; Ohara et al, 2003; Borin et
al., 2010), there has been little emphasis on
how to manage digitized data from digital
libraries using these open source resources.
In this paper we demonstrate how the infor-
mation available in such electronically avail-
able resources can be exploited for generat-
ing multilingual artwork descriptions.
In the remainder of this paper we describe
a case study on English and Swedish that un-
derscores the importance of using a lexical
resource such as a framenet (section 2). We
present the kind of information that is offered
by two existing framenets (section 3). We
demonstrate how a domain specific natural
language generator can benefit from the in-
formation that is available in both framenets
(section 4). We end with a discussion and
pointers to future work (section 5).
2 Data Collection and Text Analysis
2.1 Corpus Data
To identify the semantic and syntactic con-
structions that characterize object descrip-
tions in the cultural heritage domain, we
have collected parallel texts from Wikipedia
in two languages: English and Swedish. In
total, we analyzed 40 parallel texts that are
available under the category Painting. Addi-
tionally, we selected object descriptions from
digital libraries that are available through on-
line museum databases. The majority of the
Swedish descriptions were taken from the
World Culture Museum,1 the majority of the
English descriptions were collected from the
Met Museum.2
2.2 Semantic Analysis
The strategy we employed to analyze the
texts follows the approach presented by
McKeown (1985) on how to formalize prin-
1<http://collections.smvk.se/pls/vkm/
rigby.welcome>
2<http://www.metmuseum.org>
ciples of discourse for use in a computational
process. Seven frame elements have been ex-
amined, these include: Location (L), Creator
(CR), Representation (RE), Represented (R), De-
scriptor (D), Time (TI), Type (T). The text anal-
ysis has shown that the following combina-
tions of these major frame elements are the
most common:
1. RE, T, CR, TI, L, D, R
2. RE, T, CR, R, TI, L, D
3. RE, TI, T, CR, D, L, R
4. RE, TI, CR, D, R, L
The listed semantic combinations reflect
the word order that we have found in the
text analysis for the two languages. How-
ever, since many of the analyzed sentences
that begin with the object in focus (the Rep-
resentation) appear in the passive voice, i.e,
was painted by, was created by, the word or-
der of these combinations may vary. Further-
more, not all of the listed semantic elements
are mandatory in the object descriptions. For
example, although corresponding to the first
combination of semantic elements, the sen-
tence De Hooch probably painted this picture
in the early 1660s only contains the frame el-
ements CR, RE and TI.
2.3 Syntactic Analysis
The texts have been syntactically annotated
using the Maltparser (Nivre et al, 2007). Fig-
ure 1 shows two example sentences con-
verted to constituent trees.
S
XXXXX

NP
HHH

The portrait
VP
aaa
!!!
V
HHH

was painted
PP
Z
Z
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 76?84,
Utica, May 2012. c?2012 Association for Computational Linguistics
On generating coherent multilingual descriptions of museum objects
from Semantic Web ontologies
Dana Dann?lls
Spr?kbanken
Department of Swedish
University of Gothenburg, Sweden
dana.dannells@svenska.gu.se
Abstract
During the last decade, there has been
a shift from developing natural lan-
guage generation systems to developing
generic systems that are capable of pro-
ducing natural language descriptions di-
rectly from Web ontologies. To make
these descriptions coherent and accessi-
ble in different languages, a methodol-
ogy is needed for identifying the gen-
eral principles that would determine the
distribution of referential forms. Pre-
vious work has proved through cross-
linguistic investigations that strategies for
building coreference are language depen-
dent. However, to our knowledge, there is
no language generation methodology that
makes a distinction between languages
about the generation of referential chains.
To determine the principles governing
referential chains, we gathered data from
three languages: English, Swedish and
Hebrew, and studied how coreference is
expressed in a discourse. As a result of
the study, a set of language specific coref-
erence strategies were identified. Using
these strategies, an ontology-based mul-
tilingual grammar for generating writ-
ten natural language descriptions about
paintings was implemented in the Gram-
matical Framework. A preliminary eval-
uation of our method shows language-
dependent coreference strategies lead to
better generation results.
createdBy (Guernica, PabloPicasso)
currentLocation (Guernica, MuseoReinaSof?a)
hasColor (Guernica, White)
hasColor (Guernica, Gray)
hasColor (Guernica, Black)
Guernica is created by Pablo Picasso.
Guernica has as current location the Museo
Reina Sof?a. Guernica has as color
White, Gray and Black.
Figure 1: A natural language description generated
from a set of ontology statements.
1 Introduction
During the last decade, there has been a shift
from developing natural language generation
systems to developing generic systems that are
capable of producing natural language descrip-
tions directly from Web ontologies (Schwitter
and Tilbrook, 2004; Fuchs et al, 2008; Williams
et al, 2011). These systems employ controlled
language mechanisms and Natural Language
Generation (NLG) technologies such as dis-
course structures and simple aggregation meth-
ods to verbalise Web ontology statements, as
exemplified in figure 1.
If we want to adapt such systems to the gen-
eration of coherent multilingual object descrip-
tions, at least three language dependent prob-
lems must be faced, viz. lexicalisation, aggre-
gation and generation of referring expressions.
The ontology itself may contain the lexical in-
76
Guernica is created by Pablo Picasso.
It has as current location the Museo Reina Sof?a.
It has as color White, Gray and Black.
Guernica m?lades av Pablo Picasso.
Den finns p? Museo Reina Sof?a.
Den ?r m?lad i vitt, svart och gr?tt.
Figure 2: A museum object description generated in
English and Swedish.
formation needed to generate natural language
(McCrae et al, 2012) but it may not carry any
information either about the aggregation of se-
mantic concepts or the generation of a coher-
ent discourse from referring expressions. Hall-
iday and Hasan (1976), and other well known
theories such as Centering Theory (Grosz et
al., 1995), propose establishing a coherent de-
scription by replacing the entity referring to the
Main Subject Reference (MSR) with a pronoun
? a replacement which might result in sim-
ple descriptions such as illustrated in figure 2.
Although these descriptions are coherent, i.e.
they have a connectedness that contributes to
the reader?s understanding of the text, they are
considered non-idiomatic and undeveloped by
many readers because of consecutive pronouns
? a usage which in this particular context is un-
acceptable.
Since previous theories do not specify the
types of linguistic expressions different enti-
ties may bear in different languages or do-
mains, there remain many open questions that
need to be addressed. The question addressed
here is the choice of referential forms to re-
place a sequence of pronouns, which makes
the discourse coherent in different languages.
Our claim is that different languages use dif-
ferent linguistic expressions when referring to
a discourse entity depending on the seman-
tic context. Hence a natural language gen-
erator must employ language dependent co-
referential strategies to produce coherent de-
scriptions. This claim is based on cross-
linguistic investigations into how coreference
is expressed, depending on the target language
and the domain (Giv?n, 1983; Hein, 1989; Ariel,
1990; Prince, 1992; Vallduv? and Engdahl, 1996).
In this paper we present a contrasting study
conducted in English, Swedish and Hebrew to
learn how coreference is expressed. The study
was carried out in the domain of art, more
specifically focusing on naturally-occurring
museum object descriptions. As a result of the
study, strategies for generating coreference in
three languages are suggested. We show how
these strategies are captured in a grammar de-
veloped in the Grammatical Framework (GF).1
We evaluated our method by experimenting
with lexicalised semantic web ontology state-
ments which were structured according to par-
ticular organizing principles. The result of the
evaluation shows language-dependent corefer-
ence strategies lead to better generation results.
2 Related work
Also Prasad (2003) employed a corpus-based
methodology to study the usage of referring ex-
pressions. Based on the results of the analy-
sis, he developed an algorithm to generate ref-
erential chains in Hindi. Other algorithms for
characterizing referential expressions based on
corpus studies have been proposed and imple-
mented in Japanese (Walker et al, 1996), Ital-
ian (Di Eugenio, 1998), Catalan and Spanish
(Potau, 2008), and Romanian (Harabagiu and
Maiorano, 2000).
Although there has been computational
work related to Centering for generating a co-
herent text (Kibble and Power, 2000; Barzilay
and Lee, 2004; Karamanis et al, 2009), we are
not aware of any methodology or NLG system
that employs ontologies to guide the generation
of referential chains depending on the language
considered.
3 Data collection, annotations and
analysis
3.1 Material
To study the domain-specific conventions and
the ways of signalling linguistic content in En-
1http://www.grammaticalframework.org/
77
glish, Swedish and Hebrew, we collected ob-
ject descriptions written by native speakers of
each language from digital libraries that are
available through on-line museum databases.
The majority of the Swedish descriptions were
taken from the World Culture Museum.2 The
majority of the English descriptions were col-
lected from the Metropolitan Museum.3 The
majority of the Hebrew descriptions were taken
from Artchive.4 Table 1 gives an overview of
the three text collections. In addition, we ex-
tracted 40 parallel texts that are available under
the sub-domain Painting from Wikipedia.
Number of Eng. Swe. Heb.
Descriptions 394 386 110
Tokens 42792 27142 5690
Sentences 1877 2214 445
Tokens/sentence 24 13 13
Sentences/description 5 6 4
Table 1: Statistics of the text collections.
3.2 Syntactic annotation
All sentences in the reference material were
tokenised, part-of-speech tagged, lemmatized,
and parsed using open-source software. We
used Hunpos, an open-source Hidden Markov
Model (HMM) tagger (Hal?csy et al, 2007) and
Maltparser, version 1.4 (Nivre et al, 2007). The
English model for tagging was downloaded
from the Hunpos web page.5 The model for
Swedish was trained on the Stockholm Ume?
Corpus (SUC) and is available to download
from the Swedish Language Bank web page.6
The Hebrew tagger and parsing models are de-
scribed in Goldberg and Elhadad (2010).
3.3 Semantic annotation
The texts were semantically annotated by the
author. The annotation schema for the seman-
tic annotation is taken from the CIDOC Con-
2http://collections.smvk.se/pls/vkm/
rigby.welcome
3http://www.metmuseum.org
4http://www.artchive.com/
5http://code.google.com/p/hunpos/
downloads/list
6http://spraakbanken.gu.se/
ceptual Reference Model (CRM) (Crofts et al,
2008).7 Ten of the CIDOC-CRM concepts were
employed to annotate the data semantically.
These are given in table 2. Examples of seman-
tically annotated texts are given in figure 3.8
Actor Man-Made_Object
Actor Appellation Material
Collection Place
Dimension Time-span
Legal Body Title
Table 2: The semantic concepts for annotation.
3.4 Referential expressions annotation
The task of identifying referential instances of
a painting entity, which is our main subject
reference, requires a meaningful semantic def-
inition of the concept Man-Made Object. Such
a fine-grained semantic definition is available
in the ontology of paintings (Dann?lls, 2011),9
which was developed in the Web Ontology
Language (OWL) to allow expressing useful
descriptions of paintings.10 The ontology con-
tains specific concepts of painting types, exam-
ples of the hierarchy of concepts that are speci-
fied in the ontology are listed below.
subClassOf(Artwork, E22_Man-Made_Object)
subClassOf(Painting, Artwork)
subClassOf(PortraitPainting, Painting and
depicts(Painting, AnimateThing))
subClassOf(OilPainting, Painting and
hasMaterial(Painting, OilPaint))
When analysing the corpus-data, we look
closer at two linguistic forms of reference ex-
pressions: definite noun phrases and pronouns,
focusing on three semantic relations: direct hy-
pernym (for example Painting is direct hyper-
nym of Portrait Painting), higher hypernym (for
example, both Artwork and Man-Made Object
are higher hypernyms of Portrait Painting) and
7http://cidoc.ics.forth.gr/
8In the Hebrew examples we use a Latin transliteration
instead of the Hebrew alphabet.
9http://spraakdata.gu.se/svedd/
painting-ontology/painting.owl
10http://www.w3.org/TR/owl-features/
78
Eng: (1) [[The Starry Night]Man?Made_Object]i is [[ a painting]Man?Made_Object]i by [[Dutch
Post-Impressionist artist]Actor_Appellation]j [[Vincent van Gogh]Actor]j . (2) Since [1941]Time?Span
[[ it ]Man?Made_Object]i has been in the permanent collection of [the Museum of Modern Art]place,
[New York City]Place. (3) Reproduced often, [[ the painting]Man?Made_Object]i is widely
hailed as his magnum opus.
Swe: (1) [[Stj?rnenatten]Man?Made_Object]i ?r [[en m?lning]Man?Made_Object]i av [[den nederl?ndske
postimpressionistiske konstn?ren]Actor_Appellation]j [[Vincent van Gogh]Actor]j fr?n [1889]Time?Span.
(2) Sedan [1941]Time?Span har [[den]Man?Made_Object]i varit med i den permanenta utst?llningen vid
[det moderna museet]place i [New York]Place. (3) [[Tavlan]Man?Made_Object]i har allm?nt hyllats
som [[hans]Actor]j magnum opus och har reproducerats m?nga g?nger och ?r [en av [[hans]Actor]j
mest v?lk?nda m?lningar]Man?Made_Object]i.
Heb: (1) [[lila ?ohavim]Man?Made_Object]i hyno [[stiyor s?hemen]Man?Made_Object]i s?el
[[hastayar haholandi]Actor_Appellation]j [[vincent van gogh]Actor]j , hametoharac lesnat [1889]Time?Span.
(2) [[hastiyor]Man?Made_Object]i mostag kayom [bemozehon lehomanot modernit]place [sebahir new
york]Place. (3) [[ho]Man?Made_Object]i exad hastiyorim hayedoyim beyoter sel [[van gogh]Actor]j .
Figure 3: A comprehensive semantic annotation example.
synonym, i.e. two different linguistic units of
reference expressions belonging to the same
concept.
3.5 Data analysis and results
The analysis consisted of two phases: (1) anal-
yse the texts for discourse patterns, and (2)
analyse the texts for patterns of coreference in
the discourse.
Discourse patterns A discourse pattern (DP)
is an approach to text structuring through
which particular organizing principles of the
texts are defined through linguistic analysis.
The approach follows McKeown (1985) to for-
malize principles of discourse for use in a com-
putational process. Following this approach,
we have identified three discourse patterns for
describing paintings that are common in the
three languages. These are summarised below.
? DP1 Man-Made_Object, Object-Type, Ac-
tor, Time-span, Place, Dimension
? DP2 Man-Made_Object, Time-span,
Object-Type, Actor, Dimension, Place
? DP3 Man-Made_Object, Actor, Time-span,
Dimension, Place
Patterns of coreference In the analysis for
coreference, we only considered entities ap-
pearing in subject positions. Below follows ex-
amples of the most common types of corefer-
ence found in the corpus-data.
As seen in (1b) and in many other exam-
ples, the first reference expressions are the def-
inite noun phrase the painting, i.e. coreference
is build through the direct hypernym relation.
The choice of the reference expression in the fol-
lowing sentence (1c) is the definite noun phrase
the work, which is a higher hypernym of the
main subject of reference The Old Musician.
(1) a. The Old Musician is an 1862 painting
by French painter, ?douard Manet.
b. The painting shows the influence of
the work of Gustave Courbet.
c. This work is one of Manet?s largest
paintings and ? is now conserved at
the National Gallery of Art in
Washington.
Sentence (2b) shows a noun is avoided; the
linguistic unit of the reference expression is a
pronoun preceding a conjunction, followed by
an ellipsis.
(2) a. The Birth of Venus is a painting by
the French artist Alexandre Cabanel.
b. It was painted in 1863, and ? is now
in the Mus?e d?Orsay in Paris.
In the Swedish texts we also find occurrences
of pronouns in the second sentence of the dis-
course, as in (3b). We learn that the most com-
mon linguistic units of the reference expres-
sions also are definite noun phrases given by
the direct hypernym relation.
79
(3) a. Stj?rnenatten ?r en m?lning av den
nederl?ndske postimpressionistiske
konstn?ren Vincent van Gogh fr?n
1889.
b. Sedan 1941 har den varit med i den
permanenta utst?llningen vid det
moderna museet i New York.
c. Tavlan har allm?nt hyllats som hans
magnum opus och har reproducerats
m?nga g?nger.
((a) The Starry Night is a painting by the
dutch artist Vincent van Gogh, created in
1889. (b) Since 1941 it was in the
permanent exhibition of the museum in
New York. (c) The picture is widely
hailed as his magnum opus and has been
reproduced many times.)
Similar to English, the most common linguis-
tic units of the reference expressions are definite
noun phrases, as in (4b). However, the relation
of these phrases with respect to the main sub-
ject of reference is either a direct hypernym or a
synonym, such as tavlan in (3c) and (5b).
(4) a. Wilhelm Tells g?ta ?r en m?lning av
den surrealistiske konstn?ren
Salvador Dal?.
b. M?lningen utf?rdes 1933 och ? finns
idag p? Moderna museet i Stockholm.
((a) Wilhelm Tell?s Street is a painting by
the artist Salvador Dali. (b) The painting
was completed in 1933 and today it is
stored in the modern museum in
Stockholm.)
(5) a. Baptisterna ?r en m?lning av Gustaf
Cederstr?m fr?n 1886, och ?
f?rest?ller baptister som samlats f?r
att f?rr?tt dop.
b. Tavlan finns att besk?da i Betel
folkh?gskolas lokaler.
((a) The Baptists is a painting by Gustaf
Cederstr?m from 1886, and depicts
baptists that have gathered for a bad.
(b) The picture can be seen in Betel at the
people?s high school premises.)
The Hebrew examples also include definite
noun phrases determined by the direct hyper-
nym relation, as hastiyor in (6b). Pronouns only
occur in a context that contains a comparison,
for example (6c). In other cases, e.g. (7b), (7c),
the relation selected for the reference expres-
sion is higher-hypernym.
(6) a. lila ?ohavim hyno stiyor s?hemen s?el
hasayar haholandi vincent van gogh,
hametoharac lesnat 1889.
b. hastiyor mosag kayom bemozehon
lehomanot modernit sebahir new
york.
c. ho exad hastiyorim hayedoyim
beyoter sel van gogh.
((a) The Starry Night is an oil painting by
the dutch painter Vincent van Gogh,
created in 1899. (b) The painting is stored
in the Museum of Modern Art in New
York. (c) It is one of the most famous
works of Vincent van Gogh.)
(7) a. hahalmon nehaviyon ho stiyor sel
pablo picasso hametaher hames
zonot.
b. hayestira sestzoyra ben ha sanyim
1906-1907 nehsevet lehahat min
heyestirot hayedohot sel picasso vesel
hahomanot hamodernit.
c. hayestira mosteget kayom
bemostehon lehomanot modernitt
sebe new york.
((a) The Young Ladies of Avignon is a
painting by Pablo Picasso that portrays
five prostitutes. (b) The artwork that was
painted during 1906-1907 is one of the
most known works by Picasso in the
modern art. (c) The artwork can today be
seen in the Museum of Modern Art in
New York City.)
The synonym relation occurs when giving
the dimensions of the painting, as in (8b).
(8) a. Soded haken (1568) ho stiyor semen
al luax est meet hastayar hapalmi
peter broigel haav.
80
b. hatmona hi begodel 59 al 68
centimeter, ve ? motseget bemozeon
letoldot haaomanot bevina.
((a) The Nest thief (1568) is an oil painting
made on wood by the painter Peter Brogel
Hav. (b) The picture measures 59 x 68 cm,
and is displayed in the art museum in
Vienna.)
3.6 The results of the analysis
The above examples show a range of differ-
ences in the way chains of coreference are con-
structed. Table 3 summarizes the results the
analysis revealed. 1st, 2nd and 3rd correspond
to the first, second and third reference expres-
sion in the discourse. In summary, we found:
? Pronoun is common in Swedish and En-
glish, and rare in Hebrew
? Direct-hypernym is common in English,
Swedish and Hebrew
? Higher-hypernym is rare in English and
Swedish, and common in Hebrew
? Synonym is common in Swedish, less fre-
quent in English, and rare in Hebrew
DP English Swedish Hebrew1st 2nd 3rd 1st 2nd 3rd 1st 2nd 3rd
1 DH P DH P DH ?
1 DH HH ? DH ? DH
1 P ? P ?
1 P P ? ? DH
1 ? P DH
1,2 P DH P S ?
2 HH HH
2 HH ? HH
3 P DH P DH
Table 3: Coreference strategies for a painting object
realisation. Pronoun (P), Synonym (S), Direct Hy-
pernym (DH), Higher Hypernym (HH), Ellipsis (?).
Although the identified strategies are con-
strained by a relatively simple syntax and
a domain ontology, they show clear differ-
ences between the languages. As table 3
shows, consecutive pronouns occur commonly
in English, while consecutive higher hypernym
noun phrases are common in Hebrew.
4 Generating referential chains from
Web ontology
4.1 Experimental data
We made use of the data available in the paint-
ing ontology presented in section 3.4 to gener-
ate multilingual descriptions by following the
domain discourse patterns. The data consists of
around 1000 ontology statements and over 250
lexicalised entities extracted from the Swedish
National Museums of World Culture and the
Gothenburg City Museum.
4.2 The generation grammar
The grammar was implemented in GF, a gram-
mar formalism oriented toward multilingual
grammar development and generation (Ranta,
2004). It is a logical framework based on a gen-
eral treatment of syntax, rules, and proofs by
means of a typed ?-calculus with dependent
types (Ranta, 1994). Similar to other logical
formalisms, GF separates between abstract and
concrete syntaxes. The abstract syntax reflects
the type theoretical part of a grammar. The con-
crete syntax is formulated as a set of lineariza-
tion rules that can be superimposed on an ab-
stract syntax to generate words, phrases, sen-
tences, and texts of a desirable language. In ad-
dition, GF has an associated grammar library
(Ranta, 2009); a set of parallel natural language
grammars that can be used as a resource for
various language processing tasks.
Our grammar consists of one abstract mod-
ule that reflects the domain knowledge and is
common to all languages, plus three concrete
modules, one for each language, which en-
code the language dependent strategies. Rather
than giving details of the grammatical formal-
ism, we will show how GF captures the con-
straints presented in section 3.6. The examples
include the following GF constructors: mkText
(Text), mkPhr (Phrase), mkS (Sentence), mkCl
(Clause), mkNP (Noun Phrase), mkVP (Verb
Phrase), mkAdv (Verb Phrase modifying ad-
verb), passiveVP (Passive Verb Phrase), mkN
(Noun).
81
English
painting paintingtype painter
year museum = let
str1 : Phr = mkPhr
(mkS (mkCl (mkNP painting) (mkVP
(mkVP (mkNP
(mkNP a_Art paintingtype) make_V2))
(mkAdv by8agent_Prep
(mkNP (mkNP painter)
(mkAdv in_Prep year.s))))));
str2 : Phr = mkPhr (mkS
(mkCl (mkNP the_Art paintingtype)
(mkVP (passiveVP display_V2)
(mkAdv at_Prep museum.s))))
in mkText str1 (mkText str2) ;
Swedish
painting paintingtype painter
year museum = let
str1 : Phr = mkPhr
(mkS (mkCl (mkNP painting)
(mkVP (mkVP
(mkNP a_Art paintingtype))
(mkAdv by8agent_Prep
(mkNP (mkNP painter)
(mkAdv from_Prep (mkNP year)))))));
str2 : Phr = mkPhr
(mkS (mkCl (mkNP the_Art
(mkN "tavla" "tavla"))
(mkVP (mkVP (depV finna_V))
(mkAdv on_Prep (mkNP museum)))) )
in mkText str1 (mkText str2) ;
Hebrew
painting paintingtype painter
year museum = let
str1 : Str = ({s = painting.s ++
paintingtype.s ++ "sl " ++
painter.s ++ "msnt " ++ year.s}).s;
str2 : Str = ({s = artwork_N.s ++
(displayed_V ! Fem) ++ at_Prep.s ++
museum.s}).s in
ss (str1 ++ " ." ++ str2 ++ " ." );
The above extracts from the concrete mod-
ules follow the observed organization prin-
ciples concerning the order of semantic in-
formation in a discourse and the generation
of language-dependent referential chains (pre-
sented in the right-hand column of table 4). In
these extracts, variations in referential forms
are captured in the noun phrase of str2. In the
English module, the paintingtype that is the di-
rect hypernym of the painting object is coded,
while in the Swedish module, a synonym word
of the painting concept is coded, e.g tavla. In
the Hebrew module, a higher concept in the hi-
erarchy of paintings, artwork_N.s is coded.
4.3 Experiments and results
A preliminary evaluation was conducted to test
how significant is the approach of adapting
language-dependent coreference strategies to
produce coherent descriptions. Nine human
subjects participated in the evaluation, three
native speakers of each language.
The subjects were given forty object descrip-
tion pairs. One description containing only
pronouns as the type of referring expressions
and one description that was automatically
generated by applying the language dependent
coreference strategies. Examples of the descrip-
tion pairs the subjects were asked to evaluate
are given in table 4. We asked the subjects to
choose the description they find most coherent
based on their intuitive judgements. Partici-
pant agreement was measured using the kappa
statistic (Fleiss, 1971). The results of the evalu-
ation are reported in table 5.
Pronouns Pronouns/NPs K
English 17 18 0.66
Swedish 9 29 0.78
Hebrew 6 28 0.72
Table 5: A summary of the human evaluation.
On average, the evaluators approved at least
half of the automatically generated descrip-
tions, with a considerably good agreement. A
closer look at the examples where chains of pro-
nouns were preferred revealed that these oc-
curred in English when a description consisted
of two or three sentences and the second and
third sentences specified the painting dimen-
sions or a date. In Swedish, these were pre-
ferred whenever a description consisted of two
sentences. In Hebrew, the evaluators preferred
a description containing a pronoun over a de-
scription containing the higher hypernym Man-
made object, and also preferred the pronoun
when a description consisted of two sentences,
82
English
The Long Winter is an oil-painting The Long Winter is an oil-painting
by Peter Kandre from 1909. It is displayed in by Peter Kandre from 1909. The painting is
the Museum Of World Culture. displayed in the Museum Of World Culture.
The Little White Girl is a painting The Little White Girl is a painting
by James Abbott McNeill Whistler. by James Abbott McNeill Whistler.
It is held in the Gotheburg Art Museum. The painting is held in the Gotheburg Art Museum.
The Long Winter is a painting by Peter The Long Winter is a painting by Peter
Kandre from 1909. It measures 102 by 43 cm. Kandre from 1909. It measures 102 by 43 cm.
It is displayed in the Museum The painting is displayed in the Museum
Of World Culture. Of World Culture.
Swedish
Den l?nga vintern ?r en oljem?lning av Den l?nga vintern ?r en oljem?lning av
Peter Kandre fr?n 1909. Peter Kandre fr?n 1909.
Den ?terfinns p? V?rldskulturmuseet. Tavlan ?terfinns p? V?rldskulturmuseet.
Den lilla vita flickan ?r en m?lning Den lilla vita flickan ?r en m?lning
av James Abbott McNeill Whistler. Den av James Abbott McNeill Whistler. M?lningen
?terfinns p? G?teborgs Konstmuseum. ?terfinns p? G?teborgs Konstmuseum.
Den l?nga vintern m?lades av Peter Den l?nga vintern m?lades av Peter
Kandre 1909. Den ?r 102 cm l?ng och 43 Kandre 1909. M?lningen ?r 102 cm l?ng och 43
cm bred. Den ?terfinns p? V?rldskulturmuseet. cm bred. Tavlan ?terfinns p? V?rldskulturmuseet.
Hebrew
hHwrP hArwK hnw Zywr smN sl pyTr qndrh hHwrP hArwK hnw Zywr smN sl pyTr qndrh
msnt 1909. msnt 1909.
hyA mwZg bmwzAwN sl OlM htrbwt. hZywr mwZg bmwzAwN sl OlM htrbwt.
hyaldh hktnh alevmh hi tmona hyaldh hktnh alevmh hi tmona
sl abut mcnil wistl. hyA mwZgt sl abut mcnil wistl. hyZyrh mwZgt
bmwzAwN homanot sl gwTnbwrg. bmwzAwN homanot sl gwTnbwrg.
HwrP ArwK tzoyar el?yedy pyTr qndrh b?1909. HwrP ArwK tzoyar el?yedy pyTr qndrh b?1909.
hyA bgwdl 102 Ol 43 Sg2m. hyZyrh bgwdl 102 Ol 43 Sg2m.
hyA mwZgt bmwzAwN sl OlM htrbwt. hyZyrh mwZgt bmwzAwN sl OlM htrbwt.
Table 4: Examples of object description pairs that were used in the evaluation.
the second of which concerned the painting di-
mensions.
5 Conclusions and future work
This paper has presented a cross-linguistic
study and demonstrated some differences
in how coreference is expressed in English,
Swedish and Hebrew. As a result of the in-
vestigation, a set of language-specific coref-
erence strategies were identified and imple-
mented in GF. This multilingual grammar was
used to generate object descriptions which
were then evaluated by native speakers of each
language. The evaluation results, although per-
formed with a small number of descriptions
and human evaluators, indicate that language-
dependent coreference strategies lead to better
output. Although the data used to compare
the co-referential chains was restricted in size, it
was sufficient to determine several differences
between the languages for the given domain.
Future work aims to extend the grammar to
cover more ontology statements and discourse
patterns. We will consider conjunctions and el-
lipsis in these patterns. We intend to formalize
and generalize the strategies presented in this
paper and test whether there exist universal co-
referential chains, which might result in coher-
ent descriptions in more than three languages.
Acknowledgments
The research presented in this paper was sup-
ported in part by MOLTO European Union
Seventh Framework Programme (FP7/2007-
83
2013) under grant agreement FP7-ICT-247914.11
I would like to thank the Centre for Lan-
guage Technology (CLT) in Gothenburg and the
anonymous INLG reviewers.12
References
Mira Ariel. 1990. Accessing Noun Phrase Antecedents.
Routlege, London.
Regina Barzilay and Lillia Lee. 2004. Catching the
drift: Probabilistic content models, with applica-
tions to generation and summarization. In Proc.
of HLT-NAACL, pages 113?120.
Nick Crofts, Martin Doerr, Tony Gill, Stephen Stead,
and Matthew Stiff, 2008. Definition of the CIDOC
Conceptual Reference Model.
Dana Dann?lls. 2011. An ontology model of paint-
ings. Journal of Applied Ontologies. Submitted.
B. Di Eugenio, 1998. Centering in Italian, pages 115?
137. Oxford: Clarendon Press.
Joseph L. Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 76(5):378?382.
Norbert E. Fuchs, Kaarel Kaljurand, and Tobias
Kuhn. 2008. Attempto Controlled English for
Knowledge Representation. In Reasoning Web,
Fourth International Summer School. Springer.
T. Giv?n, editor. 1983. Topic continuity in discourse: A
quantitative cross-language study. Amsterdam and
Philadelphia: John Benjamins.
Yoav Goldberg and Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional de-
pendency parsing. In Proc. of NAACL 2010.
Barbara J. Grosz, Scott Weinstein, and Aravind K.
Joshi. 1995. Centering: A framework for mod-
eling the local coherence of discourse. Computa-
tional Linguistics, 21(2).
P?ter Hal?csy, Andr?s Kornai, and Csaba Oravecz.
2007. HunPos: an open source trigram tagger. In
Proc. of ACL on Interactive Poster and Demonstration
Sessions, pages 209?212, Morristown, NJ, USA.
Michael A. K. Halliday and R. Hasan. 1976. Cohe-
sion in English. Longman Pub Group.
S. Harabagiu and S. Maiorano. 2000. Multilingual
coreference resolution. In Proc. of ANLP.
Anna S?gvall Hein. 1989. Definite NPs and back-
ground knowledge in medical text. Computer and
Artificial Intelligence, 8(6):547?563.
11http://www.molto-project.eu/
12http://www.clt.gu.se/
Nikiforos Karamanis, Massimo Poesio, Chris Mel-
lish, and Jon Oberlander. 2009. Evaluating Cen-
tering for Information Ordering using Corpora.
Computational Linguistics, 35(1).
Rodger Kibble and Richard Power. 2000. Opti-
mizing Referential Coherence in Text Generation.
Computational Linguistics, 30(4).
J. McCrae, G. Aguado-de Cea, P. Buitelaar, P. Cimi-
ano, T. Declerck, A. Gomez-Perez, J. Gracia,
L. Hollink, E. Montiel-Ponsoda, D. Spohr, and
T. Wunner. 2012. Interchanging lexical resources
on the semantic web. Language Resources and
Evaluation.
Kathleen R. McKeown. 1985. Text generation : us-
ing discourse strategies and focus constraints to gen-
erate natural language text. Cambridge University
Press.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G?lsen Eryigit, Sandra K?bler, Svetoslav
Marinov, and Erwin Marsi. 2007. Maltparser:
A language-independent system for data-driven
dependency parsing. Natural Language Engineer-
ing, 13(2):95?135.
Marta Recasens Potau. 2008. Towards Coreference
Resolution for Catalan and Spanish. Ph.D. thesis,
University of Barcelona.
Rashmi Prasad. 2003. Constraints on the generation of
referring expressions, with special reference to hindi.
Ph.D. thesis, University of Pennsylvania.
Ellen F. Prince. 1992. The ZPG letter: Subjects, defi-
niteness, and information-status. In Discourse de-
scription. diverse linguistic analyses of a fund-raising
text, volume 10, pages 159?173.
Aarne Ranta. 1994. Type-theoretical grammar: A Type-
theoretical Grammar Formalism. Oxford University
Press, Oxford, UK.
Aarne Ranta. 2004. Grammatical Framework, a
type-theoretical grammar formalism. Journal of
Functional Programming, 14(2):145?189.
Aarne Ranta. 2009. The GF resource grammar li-
brary. The on-line journal Linguistics in Language
Technology (LiLT), 2(2).
R. Schwitter and M. Tilbrook. 2004. Controlled
Natural Language meets the Semantic Web. In
Proceedings of the Australasian Language Technology
Workshop, pages 55?62, Macquarie University.
Enric Vallduv? and Elisabet Engdahl. 1996. The lin-
guistic realization of information packaging. Lin-
guistics, (34):459?519.
M. A. Walker, M. Iida, and S. Cote. 1996. Centering
in Japanese Discourse. Computational Linguistics.
Sandra Williams, Allan Third, and Richard Power.
2011. Levels of organisation in ontology verbali-
sation. In Proc. of ENLG, pages 158?163.
84
Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 107?115,
Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational Linguistics
Multilingual access to cultural heritage content
on the Semantic Web
Dana Danne?lls and Aarne Ranta and Ramona Enache
University of Gothenburg and Chalmers University of Technology
SE-412 96 Gothenburg, Sweden
{dana.dannells, aarne.ranta, ramona.enache}@chalmers.se
Mariana Damova and Maria Mateva
Ontotext
Sofia 1784, Bulgaria
{mariana.damova,maria.mateva}@ontotext.com
Abstract
As the amount of cultural data avail-
able on the Semantic Web is expand-
ing, the demand of accessing this
data in multiple languages is increas-
ing. Previous work on multilingual
access to cultural heritage informa-
tion has shown that at least two dif-
ferent problems must be dealt with
when mapping from ontologies to nat-
ural language: (1) mapping multilin-
gual metadata to interoperable knowl-
edge sources; (2) assigning multilin-
gual knowledge to cultural data. This
paper presents our effort to deal with
these problems. We describe our expe-
riences with processing museum data
extracted from two distinct sources,
harmonizing this data and making its
content accessible in natural language.
We extend prior work in two ways.
First, we present a grammar-based sys-
tem that is designed to generate co-
herent texts from Semantic Web on-
tologies in 15 languages. Second, we
describe how this multilingual system
is exploited to form queries using the
standard query language SPARQL. The
generation and retrieval system builds
on W3C standards and is available for
further research.
1 Introduction
As the amount of cultural data available on
the Semantic Web is expanding (Dekkers et
al., 2009; Brugman et al, 2008), the demand
of accessing this data in multiple languages
is increasing (Stiller and Olensky, 2012).
There have been several applications that
applied Natural Language Generation (NLG)
technologies to allow multilingual access to
Semantic Web ontologies (Androutsopoulos
et al, 2001; O?Donnell et al, 2001; Androut-
sopoulos and Karkaletsis, 2005; Androut-
sopoulos and Karkaletsis, 2007; Davies, 2009;
Bouayad-Agha et al, 2012). The above au-
thors have shown it is necessary to have
an extensive lexical and syntactic knowl-
edge when generating multilingual natu-
ral language from Semantic Web ontologies.
However, because previous applications are
mainly concerned with two or three lan-
guages, it is still not clear how to minimize
the efforts in assigning lexical and syntactic
knowledge for the purpose of enhancing au-
tomatic generation of adequate descriptions
in multiple languages.
This paper presents our work on mak-
ing Cultural Heritage (CH) content avail-
able on the Semantic Web and accessible in
15 languages using the Grammatical Frame-
work, GF (Ranta, 2011). The objective of
our work is both to form queries and to
retrieve semantic content in multiple lan-
guages. We describe our experiences with
processing museum data extracted from two
different sources, harmonizing this data and
making its content accessible in natural lan-
guage (NL). The generation and retrieval sys-
tem builds on the World Wide Web Consor-
tium (W3C) standards and is available for
further research.1
The remainder of this paper is structured
as followed. We present the related work in
Section 2. We describe the underlying tech-
1The generation and retrieval system is available
online: http://museum.ontotext.com/
107
nology in Section 3. We provide a detailed
description of the data and present the ap-
proach taken to make this data accessible in
the Linked Open Data (LOD) in Section 4. We
outline the multilingual approach and dis-
cuss the challenges we faced in Section 5.
We discuss the results in Section 6. We end
with some conclusions and pointers to future
work in Section 7.
2 Related work
Lately there has been a lot of interest in en-
abling multilingual access to cultural her-
itage content that is available on the Se-
mantic Web. Androutsopoulos et al (2001)
and O?Donnell et al (2001) have shown that
accessing ontology content in multiple lan-
guages requires extensive linguistic data as-
sociated with the ontology classes and prop-
erties. However, they did not attempt to gen-
erate descriptions in real time from a large set
of ontologies.
Similar to Bouayad-Agha et al (2012), our
system relies on a multi-layered ontology ap-
proach for generating multilingual descrip-
tions. In contrast to Dekkers et al (2009) and
Brugman et al (2008) whose systems make
use of Google translation services, which are
data driven, our system is grammar driven.
Moreover, we present a multilingual
grammar-based approach to SPARQL
(SPARQL Protocol and RDF Query Lan-
guage) (Garlik and Andy, 2013). The method
differs from the verbalization methods pre-
sented by Ngonga Ngomo et al (2013) and
Ell et al (2012) in that it realizes the ontology
content rather than the ontology axioms.
Thus providing a more natural realization of
the query language.
3 The technological infrastructure
Although the architecture of the Semantic
Web and Linked Open Data provides access
to distributed data sets,2 many of the re-
sources available in these sets are not accessi-
ble because of cross-language meta-data. To
overcome this limitation, the knowledge rep-
resentation infrastructure adopted in our ap-
proach is designed as a Reason-able View of
2http://linkeddata.org
the Web of Data. The Reason-able View is a
compound dataset composed of several Re-
source Description Frameworks (RDFs). To
query such a compound dataset, the user has
to be intimately familiar with the schemata
of each single composing dataset. That is
why the Reason-able View approach is ex-
tended with the so called ontological refer-
ence layer, which introduces a unification on-
tology, mapped to the schemata of all single
datasets from a given Reason-able View and
thus provides a mechanism for efficient ac-
cess and navigation of the data.
3.1 Museum Reason-able View (MRV)
The Museum Reason-able View is an as-
sembly of cultural heritage dominated RDF
datasets (Danne?lls et al, 2011). It is loaded
into OWLIM-SE (Bishop et al, 2011) with in-
ference preformed on the data with respect to
OWL Horst (ter Horst, 2005).
3.2 The ontological reference layer
The Museum Reason-able View gathers:
(a) datasets from LOD, including DBpe-
dia;3 (b) the unification ontology PROTON,4
an upper-level ontology, consisting of 542
classes and 183 properties; (c) two cultural
heritage specific ontologies: (i) CIDOC-CRM
(Crofts et al, 2008),5 consisting of 90 classes
and 148 properties; (ii) Museum Artifacts
Ontology (MAO),6 developed for mapping
between museum data and the K-samso?k
schema.7 It has 10 classes and 20 properties;
(d) the Painting ontology,8 an application on-
tology developed to cover detailed informa-
tion about painting objects in the framework
3DBPedia, structured information from Wikipedia:
http://dbpedia.org.
4http://www.ontotext.com/
proton-ontology
5http://www.cidoc-crm.org/
6It is just a coincidence that this ontology has the
same name as the Finnish MAO (Hyvyonen et al,
2008), which also describes museum artifacts for the
Finnish museums.
7K-samso?k http://www.ksamsok.se/
in-english/), the Swedish Open Cultural Her-
itage (SOCH), provides a Web service for applications
to retrieve data from cultural heritage institutions or
associations with cultural heritage information.
8http://spraakdata.gu.se/svedd/
painting-ontology/painting.owl
108
of the Semantic Web. It contains 197 classes
and 107 properties of which 24 classes are
equivalent to classes from the CIDOC-CRM
and 17 properties are sub-properties of the
CIDOC-CRM properties.
3.3 Grammatical Framework (GF)
The Grammatical Framework (GF) (Ranta,
2004) is a grammar formalism targeted to-
wards parsing and generation. The key fea-
ture of GF is the distinction between an ab-
stract syntax, representing the domain, and
concrete syntaxes, representing lineariza-
tions in various target languages, natural or
formal.
GF comes with a resource grammar li-
brary (RGL) (Ranta, 2009) which aids the
development of new grammars for specific
domains by providing syntactic operations
for basic grammatical constructions (Ranta,
2011). More than 30 languages are available
in the RGL. Our application targets 15 of
those, including: Bulgarian, Catalan, Dan-
ish, Dutch, English, Finnish, French, Hebrew,
Italian, German, Norwegian, Romanian, Rus-
sian, Spanish, and Swedish.
4 Cultural heritage data
The data we have been experimenting with
to enable multilingual descriptions of mu-
seum objects and answering to queries over
them is a subset of the Gothenburg City Mu-
seum (GCM) database,9 and a subset of the
DBpedia dataset. Because these two datasets
are very different in size and nature, the pre-
processing of each set differs substantially. In
the following we describe each of the sets and
the pre-processing steps in more details.
4.1 Gothenburg City Museum (GCM)
The set from the GCM contains 48 painting
records. Its content, both the metadata and
data that were originally in Swedish, were
translated to English. An example of a record
from GCM is shown in Table 1.
4.2 DBpedia
The set from DBpedia contains 662 painting
records, the data covers at least 5 languages,
9http://stadsmuseum.goteborg.se/wps/
portal/stadsm/english
Record field Value
Field nr. 4063
Prefix GIM
Object nr. 8364
Search word painting
Class nr 353532
Classification Gothenburg portrait
Amount 1
Producer E.Glud
Produced year 1984
Length cm 106
Width cm 78
Description oil painting
represents a studio indoors
History Up to 1986 belonged to Datema
AB, Flo?jelbergsg 8, Gbg
Material oil paint
Current keeper 2
Location Polstja?rnegatan 4
Package nr. 299
Registration 19930831
Signature BI
Search field Bilder:TAVLOR PICT:GIM
Table 1: A painting object representation from the
GCM database.
the metadata is in English. An example of a
record from DBpedia is shown in Table 2.
4.3 Transition of data to the MRV
Making the museum data available through
the knowledge infrastructure required trans-
lations of the record fields and values, and
mapping to a unified ontology. This process
also required pre-processing of the free text
fields such as Description and History (see Ta-
ble 1) to enrich the data content.
To make the DBpedia data accessible
through the knowledge infrastructure, it re-
quired some preprocessing, cleaning, and
mapping to the Painting ontology for data
consistency. This unification was needed to
use a consistent SPARQL queries from where
NL descriptions could be generated.
Firstly, we attempted to clean data noise
and results that would make a single paint-
ing reappear in the query results. Then, we
transformed year and size strings into only
numbers. For each painter, museum and
painting literal we had a single representa-
tion in the data. All names were normalized,
for example, Salvador Dal?? was converted
109
<result>
<binding name=?painting?>
<uri>http://dbpedia.org/resource/
Virgin of the Rocks</uri> </binding>
<binding name=?museum?>
<literal xml:lang=?en?>Muse?e du Louvre
</literal> </binding>
<binding name=?author?>
<literal xml:lang=?en?>da Vinci, Leonardo
</literal> </binding>
<binding name=?height?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
190</literal> </binding>
<binding name=?width?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
120</literal>mateva </binding>
<binding name=?title?>
<literal xml:lang=?en?>London version
</literal> </binding>
<binding name=?type?>
<literal xml:lang=?fr?>Huile sur panneau
</literal> </binding>
<binding name=?year?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
1495</literal> </binding> </result>
Table 2: A painting object representation from
DBpedia
to Salvador Dal . For different Uniform Re-
source Identifiers (URIs) pointing to the same
painting, we used the OWL (W3C, 2012)
construct owl:sameAs. With this construct we
were able to keep the data linked in the other
graphs in the LOD cloud.
5 Multilingual linked data
Our application is targeted towards lay users
who wish to formulate queries and retrieve
information in any language. Such users do
not have any knowledge about ontologies or
semantic data processing. For us it was there-
fore necessary to enable interactions in a sim-
ple use.
The work towards making Semantic Web
data accessible to different users required
lexicalizations of ontology classes, proper-
ties and individuals (literal strings associated
with a certain class).
Following the GF mechanism, lexicaliza-
tions is accomplished through linearizations
of functions. Linearization of functions varies
depending on the language.
5.1 Lexicalizations of classes and
properties
Most of the ontology classes defined in our
grammar are linearized with noun phrases
in the concrete syntaxes. These were trans-
lated manually by a native speaker of the
language. Examples from four languages are
shown below. In the examples we find the
following RGL constructions: mkCN (Com-
mon noun) and mkN (Noun).
Class: Painting
Swe. mkCN (mkN "ma?lning");
Fre. mkCN (mkN "tableau");
Fin. mkCN (mkN "maalaus");
Ger. mkCN mkN "Bild"
"Bilder" neuter;
Class: Portrait
Swe. mkCN (regGenN "portra?tt"
neutrum);
Fre. mkCN (mkN "portrait");
Fin. mkCN (mkN "muoto"
(mkN "kuva"));
Ger. mkCN (mkN "Portra?t"
"Portra?ts" neuter);
Two of the ontology classes that are not
linearized with a noun phrase are: Year and
Size. These are linearized with prepositional
phrases in which the preposition is language
dependent. Below are some examples which
show how the Year string, i.e. YInt function, is
realized in six languages. In the examples we
find the following RGL constructions: mkAdv
(Verb Phrase modifying adverb), Prep (Prepo-
sition) and symb (Symbolic).
Bul. YInt i = mkAdv prez_Prep
(symb (i.s ++ year_Str));
Fin. YInt i = mkAdv (prePrep
nominative "vuonna") (symb i);
Fre. YInt i = mkAdv en_Prep (symb i);
Ger. YInt i = mkAdv in_Prep (symb i);
Swe. YInt i = mkAdv noPrep
(symb ("a?r" ++ i.s));
Rus. YInt i = mkAdv in_Prep
(symb (i.s ++ godu_Str));
The ontology properties are defined with
operations in the concrete syntaxes. Because
110
Table 3: The amount of lexicalized literals in a
subset of the MRV
Class literals
Title 662
Painter 116
Museum 104
Place 22
an ontology property is linearized differently
depending on how it is realized in the target
language, these operations are of type: verbs
(e.g. paint V2), adverbs (e.g. painted A) and
prepositions (e.g. Prep). Examples from three
languages are shown below.
Swe. paint_V2 : V2 = mkV2 "ma?la";
painted_A : A = mkA "ma?lad";
at_Prep = mkPrep "pa?" ;
Fin. paint_V2 = mkV2 "maalata";
painted_A = mkA "maalattu";
Ger. paint_V2 : V2 = mkV2
(mkV "malen");
painted_A : A = mkA "gemalt";
at_Prep = in_Prep ;
The above functions correspond to three
ontological properties, namely painted by,
painted and created in. This approach to ontol-
ogy lexicalization permits variations regard-
ing the lexical units the ontology properties
should be mapped to. It allows to make prin-
cipled choices about the different realizations
of an ontology property.
5.2 Lexicalizations of literals
The part of the MRV to which we provide
translations for consists of 906 individuals,
their distribution across four classes is pro-
vided in Table 3. The lexical units assigned to
paining titles, painters and museum literals
are by default the original strings as they ap-
pear in the data. The majority of strings are
given in English. However, because without
translations of the name entities the results
can become artificial and for some languages
ungrammatical, we run a script that trans-
lates museum literals from Wikipedia auto-
matically.
Automatic translation was done by:
(1) curling for Web pages for a museum
string; (2) extracting the retrieved trans-
Table 4: The number of automatically translated
museum names from Wikipedia
Language Translated names
Bulgarian 26
Catalan 63
Danish 33
Dutch 81
Finnish 40
French 94
Hebrew 46
Italian 94
German 99
Norwegian 50
Romanian 27
Russian 87
Spanish 89
Swedish 58
lated entry for each string; (3) reducing
the retrieved list by removing duplicated
and ambiguous entries. This process was
repeated for each language.
As a result of the translation process, a
list of lexical pairs was created for each lan-
guage. Museum literals were then linearized
automatically by consulting the created list
for each language. In the cases where no
translation was found, the original string, as
it appears in the dataset was used.
Unfortunately, the amount of the trans-
lated museum names was not equal for all
languages. The distribution of the translated
names is given in Table 4. Below follow some
examples of how museum names are repre-
sented in the grammar:
Swe. MGothenburg_City_Museum =
mkMuseum "Go?teborgs stadsmuseum";
MMus_e_du_Louvre =
mkMuseum "Louvren";
Ita. MGothenburg_City_Museum =
mkMuseum
"museo municipale di Goteburgo";
MMus_e_du_Louvre =
mkMuseum "Museo del Louvre";
Fre. MGothenburg_City_Museum =
mkMuseum
"muse?e municipal de Go?teborg";
MMus_e_du_Louvre =
mkMuseum "Muse?e du Louvre";
Cat. MGothenburg_City_Museum =
mkMuseum "Gothenburg_City_Museum";
MMus_e_du_Louvre =
111
mkMuseum "Museu del Louvre";
Ger. MGothenburg_City_Museum =
mkMuseum "Gothenburg_City_Museum";
MMus_e_du_Louvre =
mkMuseum "Der Louvre ";
Where the construct mkMuseum has been
defined to build a noun phrase from a given
string. A special case of mkMuseum appears
in four languages: Italian, Catalan, Spanish
and French, where a masculine gender is as-
signed to the museum string to get the cor-
rect inflection form of the noun.
5.3 Realization of sentences
To generate sentences from a set of classes
we had to make different judgements about
how to order the different classes. Below we
provide an example of a sentence lineariza-
tion from four languages. The sentence com-
prises four semantic classes: Painting, Mate-
rial, Painter and Year. In the examples we find
following RGL constructors: mkText (Text),
mkS (Sentence), mkCl (Clause), mkNP (Noun
Phrase), and mkVP (Verb Phrase).
Ita. s1 : Text = mkText (mkS
(mkCl painting (mkVP (mkVP (mkVP
(mkVP dipinto_A) material.s)
(SyntaxIta.mkAdv by8agent_Prep
(title painter.long))) year.s))) ;
Fre. s1 : Text = mkText
(mkS anteriorAnt
(mkCl painting (mkVP (mkVP (mkVP
(passiveVP paint_V2) material.s)
(SyntaxFre.mkAdv by8agent_Prep
(title painter.long))) year.s))) ;
Ger. s1 : Text = mkText
(mkS pastTense
(mkCl painting (mkVP (mkVP
(mkVP (passiveVP paint_V2) year.s)
(SyntaxGer.mkAdv von_Prep
(title painter.long))) material.s)));
Rus. s1 : Text = mkText
(mkS pastTense
(mkCl painting (mkVP (mkVP (mkVP
(passiveVP paint_V2)
(SyntaxRus.mkAdv part_Prep
(title painter.long
masculine animate)))
material.s) year.s))) ;
Some of the distinguishing differences be-
tween the languages are: in Finnish the use
of an active voice, in Italian, present tense,
in French, past participle, in Spanish, present
simple. The order of the categories is also dif-
ferent. In German the material string appears
at the end of the sentence as opposed to the
other languages where year is often the last
string.
5.4 Realizations of texts
The text grammar has been designed to gen-
erate a coherent natural language descrip-
tions from a selected set of the returned
triples. More specifically, our grammar cov-
ers eight concepts that are most commonly
used to describe a painting, including: Title,
Painter, Painting type, Material, Colour, Year,
Museum and Size. In the grammar mod-
ule called TextPainting they are defined as
categories and are captured in one function
DPainting which has the following represen-
tation in the abstract syntax.
DPainting :
Painting -> Painter ->
PaintingType -> OptColours ->
OptSize -> OptMaterial ->
OptYear -> OptMuseum -> Description;
In the function DPainting five arguments
have been implemented as optional, i.e.
OptColour, OptSize, OptMaterial, OptYear and
OptMuseum. Each of these categories can be
left out in a text.
In the current implementation we limited
the length of a description to three sentences.
A minimal description consists of only one
sentences. Below follow some examples of
texts generated in English to exemplify the
different descriptions we are able to generate
from one single function call with a varying
number of instantiated parameters.
? Interior was painted on canvas by Edgar
Degas in 1868. It measures 81 by 114 cm
and it is painted in red and white. This
painting is displayed at the Philadelphia
Museum of Art.
? Interior was painted by Edgar Degas in
1868. It measures 81 by 114 cm. This
painting is displayed at the Philadelphia
Museum of Art.
? Interior was painted on canvas by Edgar
Degas in 1868. It is painted in red and
white. This painting is displayed at the
Philadelphia Museum of Art.
112
Figure 1: A semantic tree realization of nine ontology classes
? Interior was painted by Edgar Degas. It
measures 81 by 114 cm and it is painted
in red and white. This painting is dis-
played at the Philadelphia Museum of
Art.
? Interior was painted on canvas by Edgar
Degas. It measures 81 by 114 cm and it is
painted in red and white.
? Interior was painted by Edgar Degas in
1868. This painting is displayed at the
Philadelphia Museum of Art.
? Interior was painted by Edgar Degas.
5.5 Multilingual querying
Semantic Web technologies offer the tech-
nological backbone to meet the requirement
of integrating heterogeneous data easily, but
they are still more adapted to be consumed
by computers than by humans. As a con-
sequence, to retrieve semantic content from
the knowledge base the user must: 1. mas-
ter SPARQL, the query language for RDF;
2. have knowledge about each integrated
dataset in the knowledge base.
Ngonga Ngomo et al (2013) have shown
that realizations of SPARQL queries in natu-
ral language enhance the user understanding
of the formulated queries and the retrieved
results.
We have implemented an extra SPARQL
module that allow us to map from any
of the 15 supported languages to SPARQL
and from SPARQL to any of the 15 sup-
ported languages. The grammar reuses a
more generic query module that allows to
form both domain specific and domain in-
dependent queries. Some examples of the
queries that can be formulated with the
multilingual grammar and transformed to
SPARQL are:
1. Some X
2. All About X
3. Show everything about X
4. All X painted by Y
5. Some X painted on Y
6. What is the material of X
7. Show everything about all X that are painted
on Y
In GF, realization of SPARQL queries is
done by introducing new parameters, for ex-
ample:
QPainter p = {
wh1 = "?author";
prop = p ;
wh2 ="painting:createdBy ?painter.
?painter rdfs:label ?author ."} ;
The function QPainter defined to formulate
a query such as who painted Mona Lisa? has
been added two additional parameters, i.e.
wh1 and wh2. With these parameters it is pos-
sible to formulate SPARQL queries such as
the one below.
SELECT ?author
WHERE {
?painting rdf:type
painting:Painting ;
painting:createdBy ?painter ;
rdfs:label ?title
FILTER (str(?title)="Mona_Lisa").
?painter rdfs:label ?author.
}
113
Figure 2: Multilingual generation results
5.6 Multilingual text generation
Our approach allows different texts to be
generated depending on the information that
is available in the ontology. A minimal de-
scription consists of three classes: a title, a
painter and a painting type. A complete de-
scription consists of nine classes, as illus-
trated in Figure 1. With only one function
DPainting our system is able to generate 16
different text variants. Figure 2 illustrates a
generation results in 15 languages.
6 Discussion
The majority of the challenges in the produc-
tion of the CH data pool stemmed from the
very nature of the Linked Open Data. The
data in the LOD cloud are notoriously noisy
and inconsistent.
The multilingual labels from the FactForge
datasets and more precisely from DBpedia,
are not always available in all the supported
languages. Although DBpedia in its large
pool of data provides access to multilingual
content, it is inconsistent. Many of the entries
it contains are missing translations. There is a
mixture of numeric and string literals. There
are many duplications, most of them occur
because the same ID appears in different lan-
guages. The content of the data is verbose, for
example place-names and museum-names
are represented with one string, for example:
?Rijksmuseum, Amsterdam?, instead of two
different strings linked by two separate con-
cepts, i.e. Museum and Place. This kind of in-
consistent data representation had an impact
on the translation of museum names.
Another problem was that not all art ob-
jects are uniformly described with the same
set of characteristics. For instance, some
paintings were missing a title or a painter
name. Because we constructed the grammar
in such a way that disallows absence of this
information, we had to replace titles with
id numbers and empty painter names with
the string unknown. Moreover, the data con-
tained many duplications. This occurred be-
cause some of the property assertions were
presented with different strings and trig-
gered many RDF triples.
We also faced many linguistic challenges
on different levels. Lexicalizations of ontol-
ogy classes and properties regarding use
of compounds, variations of verbs, adverbs
and prepositions. On sentence level, order of
classes, variations of tense and voice. On both
sentence and discourse levels, aggregation
variations and use of coreference elements.
7 Conclusions
We presented an ontology-based multilin-
gual application developed in the Gram-
matical Framework and a cross-language re-
trieval system that uses this application for
generating museum object descriptions in
the Semantic Web.
The generation and retrieval system builds
on W3C standards. It covers semantic data
from the Gothenburg City Museum database
and DBpedia. The grammar enables descrip-
tions of paintings and answering to queries
over them, covering 15 languages for base-
line functionality.
114
Acknowledgment
This research has been supported by
MOLTO, the European Union?s Seventh
Framework Programme (FP7/2007-2013)
under grant agreement FP7-ICT-247914.
References
S. Kallonis Androutsopoulos and V. Karkaletsis.
2005. Exploiting OWL ontologies in the mul-
tilingual generation of object descriptions. In
The 10th European Workshop on NLG, pages 150?
155, Aberdeen, UK.
J. Oberlander Androutsopoulos and V. Karkalet-
sis. 2007. Source authoring for multilingual
generation of personalised object descriptions.
Natural Language Engineering, 13(3):191?233.
Ion Androutsopoulos, Vassiliki Kokkinaki, Agge-
liki Dimitromanolaki, Jo Calder, Jon Oberl, and
Elena Not. 2001. Generating multilingual per-
sonalized descriptions of museum exhibits: the
M-PIRO project. In Proceedings of the Interna-
tional Conference on Computer Applications and
Quantitative Methods in Archaeology.
B. Bishop, A. Kiryakov, D. Ognyanoff, I. Peikov,
Z. Tashev, and R. Velkov. 2011. OWLIM: A
family of scalable semantic repositories. Se-
mantic Web Journal, Special Issue: Real-World Ap-
plications of OWL.
Nadjet Bouayad-Agha, Gerard Casamayor, Si-
mon Mille, Marco Rospocher, Horacio Saggion,
Luciano Serafini, and Leo Wanner. 2012. From
Ontology to NL: Generation of multilingual
user-oriented environmental reports. Lecture
Notes in Computer Science, 7337.
Hennie Brugman, Ve?ronique Malaise?, and Laura
Hollink. 2008. A common multimedia annota-
tion framework for cross linking cultural her-
itage digital collections. In International Confer-
ence on Language Resources and Evaluation.
Nick Crofts, Martin Doerr, Tony Gill, Stephen
Stead, and Matthew Stiff, 2008. Definition of the
CIDOC Conceptual Reference Model.
Dana Danne?lls, Mariana Damova, Ramona
Enache, and Milen Chechev. 2011. A Frame-
work for Improved Access to Museum
Databases in the Semantic Web. In Recent Ad-
vances in Natural Language Processing (RANLP).
Language Technologies for Digital Humanities and
Cultural Heritage (LaTeCH).
Rob Davies. 2009. EuropeanaLocal ? its role
in improving access to Europe?s cultural her-
itage through the European digital library. In
Proceedings of IACH workshop at ECDL2009 (Eu-
ropean Conference on Digital Libraries), Aarhus,
September.
Makx Dekkers, Stefan Gradmann, and Carlo
Meghini. 2009. Europeana outline func-
tional specification for development of an op-
erational european digital library. Technical
report. Europeana Thematic Network Deliv-
erables 2.5. Contributors and peer reviewers:
Europeana.net WP2 Working Group members,
Europeana office.
Basil Ell, Denny Vrandec?ic?, and Elena Sim-
perl. 2012. SPARTIQULATION ? Verbalizing
SPARQL queries. In Proceedings of ILD Work-
shop, ESWC 2012.
Steve Harris Garlik and Seaborne Andy, 2013.
SPARQL 1.1 Query Language, March. http:
//www.w3.org/TR/sparql11-query/.
E Hyvyonen, E. Maekelae, M. Salminen, A. Valo,
K. Viljanen, S. Saarela, M. Junnila, and S. Ket-
tula. 2008. Museum finland. In Finnihs Mu-
seum on the Semantic Web.
Axel-Cyrille Ngonga Ngomo, Lorenz Bu?hmann,
Christina Unger, Jens Lehmann, and Daniel
Gerber. 2013. Sorry, i don?t speak sparql: trans-
lating sparql queries into natural language. In
Proceedings of the 22nd international conference
on World Wide Web, WWW ?13, pages 977?
988, Republic and Canton of Geneva, Switzer-
land. International World Wide Web Confer-
ences Steering Committee.
Michael J. O?Donnell, Chris Mellish, Jon Oberlan-
der, and Alistair Knott. 2001. ILEX: An archi-
tecture for a dynamic hypertext generation sys-
tem. Natural Language Engineering, 7(3):225?
250.
Aarne Ranta. 2004. Grammatical Framework, a
type-theoretical grammar formalism. Journal of
Functional Programming, 14(2):145?189.
Aarne Ranta. 2009. The GF resource gram-
mar library. The on-line journal Linguistics
in Language Technology (LiLT), 2(2). http:
//elanguage.net/journals/index.
php/lilt/article/viewFile/214/158.
Aarne Ranta. 2011. Grammatical Framework: Pro-
gramming with Multilingual Grammars. CSLI
Publications, Stanford. ISBN-10: 1-57586-626-9
(Paper), 1-57586-627-7 (Cloth).
J. Stiller and M. Olensky. 2012. Europeana: A
multilingual trailblazer. In The W3C Workshop:
The Multilingual Web - Linked Open Data and
Multilingual Web-LT Requirements, Dublin.
H. J. ter Horst. 2005. Combining RDF and Part
of OWL with Rules: Semantics, Decidability,
Complexity. In Proceedings of The Semantic Web
ISWC, volume 3729 of LNCS, pages 668?684,
Heidelberg. Springer Berlin.
W3C, 2012. OWL Web Ontology Language
Overview, December. http://www.w3.org/
TR/owl2-overview/.
115
Proceedings of the Workshop on Lexical and Grammatical Resources for Language Processing, pages 8?17,
Coling 2014, Dublin, Ireland, August 24 2014.
Using language technology resources and tools
to construct Swedish FrameNet
Dana Dann
?
ells Karin Friberg Heppin
Department of Swedish
University of Gothenburg
firstname.lastname@svenska.gu.se
Anna Ehrlemark
Abstract
Having access to large lexical and grammatical resources when creating a new language resource
is essential for its enhancement and enrichment. This paper describes the interplay and interac-
tive utilization of different language technology tools and resources, in particular the Swedish
lexicon SALDO and Swedish Constructicon, in the creation of Swedish FrameNet. We show
how integrating resources in a larger infrastructure is much more than the sum of the parts.
1 Introduction
This paper describes how Swedish language technology resources are exploited to construct Swedish
FrameNet (SweFN),
1
a lexical-semantic resource that has been expanded from and constructed in line
with Berkeley FrameNet (BFN). The resource has been developed within the framework of the theory
of Frame Semantics (Fillmore, 1985). According to this theory, semantic frames including their partic-
ipants represent cognitive scenarios as schematic representations of events, objects, situations, or states
of affairs. The participants are called frame elements (FEs) and are described in terms of semantic roles
such as AGENT, LOCATION, or MANNER. Frames are evoked by lexical units (LUs) which are pairings
of lemmas and meanings.
To get a visualization of the notion of semantic frames consider the frame Vehicle landing. It
has the following definition in BFN: ?A flying VEHICLE comes to the ground at a GOAL in a controlled
fashion, typically (but not necessarily) operated by an operator.? VEHICLE and GOAL are the core
elements that together with the description uniquely characterize the frame. Their semantic types are
Physical object and Location. The non-core elements of the frame are: CIRCUMSTANCES, COTHEME,
DEGREE, DEPICTIVE, EVENT DESCRIPTION, FREQUENCY, GOAL CONDITIONS, MANNER, MEANS,
MODE OF TRANSPORTATION, PATH, PERIOD OF ITERATIONS, PLACE, PURPOSE, RE ENCODING,
SOURCE, and TIME. The lexical units evoking the frame are: land.v, set down.v, and touch down.v. In
addition, the frame contains a number of example sentences which are annotated in terms of LUs and
FEs. These sentences carry valence information about different syntactic realizations of the FEs and
about their semantic characteristics.
Currently SweFN contains around 1,150 frames with over 29,000 lexical units of which 5,000 are
verbs, and also 8,300 semantically and syntactically annotated sentences, selected from a corpus.
SweFN has mainly been created manually, but as a response to an ever increasing complexity, volume,
and specialization of textual evidence, the creation of SweFN is enhanced with automated Natural Lan-
guage Processing (NLP) techniques. In contrast to the construction of English resources, as well as the
construction of framenets for other languages, the resources used to construct SweFN are all linked in a
unique infrastructure of language resources.
2 The development of framenets in other languages
FrameNet-like resources have been developed in several languages and have been exploited in a range
of NLP applications such as semantic parsing (Das et al., 2014), information extraction (Moschitti et
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
http://spraakbanken.gu.se/eng/resource/swefn
8
al., 2003), natural language generation (Roth and Frank, 2009), and semi-automatic disambiguation of
polysemous words (Alonso et al., 2013).
Currently the most active framenet research teams are working on Swedish FrameNet (SweFN) (Borin
et al., 2010; Heppin and Gronostaj, 2014), Japanese FrameNet (JFN) covering 565 frames, 8,500 LUs,
and 60,000 annotated example sentences (Ohara, 2013) and FrameNet Brazil (Br-FN) for Brazilian Por-
tuguese (Torrent, 2013) covering 179 frames, 196 LUs, and 12,100 annotated sentences.
2
Even though the point of departure for all FrameNet-like resources is BFN, they differ in a number of
important aspects. SweFN has focused on transferring frames and populating them with LUs. For each
frame there are annotated example sentences extracted from corpora. Sentences illustrate the instanti-
ation of a number of LUs and FEs with regard to the frame, but many LUs do not yet have associated
example sentences. BFN and Spanish FrameNet (Subirats, 2009) also use isolated corpus sentences for
annotation while the SALSA project for German (Burchardt et al., 2009) has the aim of creating full-text
annotation of a German corpus. JFN, Spanish FrameNet, and FN-Br all use BFN software to construct
frames, while SweFN uses its own software and tools. Even though JFN uses BFN software and an-
notations tools for as much compatibility with BFN as possible, the Japanese writing system differs
considerably from that of English, and several modifications have been necessary to handle the different
character systems and word boundary issues.
Most framenets have the intention of covering general language. However, there are domain spe-
cific resources such as, the Copa 2014 FrameNet Brasil, a multilingual resource for the language of
soccer and tourism (Torrent et al., 2014) covering Portuguese, English and Spanish. Bertoldi and de
Oliveira Chishman (2011) describe work buiding a FrameNet-like ontology for the language of criminal
justice contrasting the differences between English and Portuguese languages and legal cultures.
3 Lexical and grammatical resources and tools for Swedish
Swedish FrameNet is part of SweFN++, a larger project with the goal to create a multifaceted panchronic
lexical macro-structure for Swedish to be used as an infrastructure component for Swedish language
technology and development of NLP applications and annotated corpora. One goal of SweFN++ is to
re-use and enhance existing in-house and external lexical resources and harmonize them into a single
macro-structure for processing both modern and historic Swedish text (Borin et al., 2010). Another goal
is to release all SweFN++ resources under an open content license.
3.1 SALDO ? association lexicon
SALDO (Borin et al., 2013a)
3
is a Swedish association lexicon which contains morphological and
lexical-semantic information for more than 131,000 entries, of which around 10% are verbs. SALDO en-
tries are arranged in a hierarchical structure capturing semantic closeness between lexemes. Each lexical
entry of SALDO has a unique identifier. Each lexical entry, except 41 top nodes, also has a main descrip-
tor, which may be complemented with a second determinative descriptor. These descriptors are other,
more central, entries from SALDO. The SALDO entry for the noun flaska ?bottle?, with its descriptors,
is shown in figure 1.
SALDO is the pivot of all the Swedish lexical language technology resources maintained at
Spr?akbanken. Having one pivot resource makes it possible for all Spr?akbanken resources to be com-
patible with each other (Borin and Forsberg, 2014).
3.2 Swedish Constructicon
The Swedish Constructicon (SweCcn)
4
is an electronic database of Swedish constructions (Lyngfelt
et al., 2012; Sk?oldberg et al., 2013). Just as it is precursor the Berkeley Constructicon,
5
it builds on
experiences from Construction Grammar and is historically, methodologically and theoretically closely
related to Frame Semantics and FrameNet (Fillmore et al., 2012). While framenets map single lexical
2
http://www.framenetbr.ufjf.br
3
http://spraakbanken.gu.se/saldo
4
http://spraakbanken.gu.se/swe/swecxn
5
http://www1.icsi.berkeley.edu/
?
hsato/cxn00/21colorTag/index.html
9
Figure 1: A search for the noun flaska ?bottle? in SALDO shows that it only has one sense. We are also
shown the lemma, the part of speech, the primary descriptor f?orvara ?store.v?, the secondary descriptor
h?alla ?pour.v?, and finally primary and secondary children, that is entries which have flaska as primary
or secondary descriptor.
units to the frames they evoke, a constructicon deals with the pairing of form and meaning in more
complex linguistic units, typically (partially) schematic multiword units that cannot easily be referred to
by either grammatical or lexicographic descriptions alone.
In SweCcn each construction is described individually in a construction entry, defined by its spe-
cific characteristics in form, meaning, function, and distribution. Each entry includes a free text def-
inition, schematic structural description, definitions of construction elements (CEs) and annotated ex-
ample sentences. Since the constructicon must account for both form and meaning, the construc-
tion elements can be both semantic roles and syntactic constituents. For example, the construction
reflexiv resultativ, instantiated in ?ata sig m?att ?eat oneself full?, is defined as a verb phrase
where somebody (ACTOR) or something (THEME) performs an action (ACTIVITY) that leads to a result
which affects the ACTOR/THEME, expressed with a reflexive particle. The construction roughly means
?achieve something by V-ing?, and can be applied to both transitive and intransitive verbs, altering the
verbs? inherent valence restrictions. The syntactic structure of the construction is [V refl AP], and the
construction elements are defined as the semantic roles ACTOR, THEME, ACTIVITY and RESULT, as
well as the reflexive particle. Example sentences like dricka sig full ?drink oneself drunk? and springa
sig varm ?run oneself warm? are added to the entry, while an example like k?anna sig tr?ott ?feel tired?
does not fit since one doesn?t get tired by feeling.
Swedish Constructicon is developed as an extension of Swedish FrameNet and forms a part of the
SweFN++ infrastructure. Swedish Constructicon currently consists of about 300 construction entries,
ranging from general linguistic patterns to partially fixed expressions, of which a significant part are con-
structions in the borderland between grammar and lexicon, commonly neglected from both perspectives.
3.3 Karp ? open lexical infrastructure
Karp is an open lexical infrastructure with three main functions: (1) support the creation, cura-
tion, and mutual integration of the lexical resources of SweFN++; (2) publish all lexical resources at
Spr?akbanken, making them searchable and downloadable in various formats such as Lexical Markup
Framework (LMF) (Francopoulo et al., 2006), and Resource Description Framework (RDF) (Lassila
and Swick, 1999); (3) offer advanced editing functionalities with support for exploitation of corpora
resources (Borin et al., 2013b).
There are 21 resources with over 700,000 lexical entries available in Karp. Since all resources uti-
lize the lexical entries of SALDO, a large amount of information becomes accessible when performing
simple searches. For example when we look up the SALDO entry flaska..1 ?bottle?, we find information
about the synset from Swesaurus,
6
a WordNet-like Swedish resource, as well as synset and sense from
Princeton WordNet,
7
syntactic valence from PAROLE,
8
identifier from Loan Typology Wordlist (LWT),
9
6
http://spraakbanken.gu.se/eng/resource/swesaurus
7
http://wordnet.princeton.edu/
8
http://spraakdata.gu.se/parole/lexikon/swedish.parole.lexikon.html
9
http://lingweb.eva.mpg.de/cgi-bin/ids/ids.pl?com=simple_browse&lg_id=187
10
the lexical ID from Lexin,
10
etc. Each of these resources is in turn linked to mono- and multi-lingual
information that can be exploited by any other resource or application.
3.4 Korp ? Swedish corpora
Korp is a Swedish corpus search interface developed at Spr?akbanken. It provides access to over 1.6
billion tokens from both modern and historic Swedish texts (Borin et al., 2012; Ahlberg et al., 2013).
The interface allows advanced searches and comparisons between different corpora, all automatically
annotated with dependency structure using MaltParser (Nivre et al., 2007).
One functionality provided by Korp is Related Words. This shows a list of words fetched from SALDO
which are semantically related to the search term. Only words that actually occur in the corpora are
retrieved by this function. By clicking on one of these, a new corpus search is done with this word as
search term (Borin et al., 2012). Another functionality in Korp is Word Picture which uses statistical
data to select typical examples illustrating collocational semantic relations for chosen expressions. This
query system extracts frequent collocations of the word in question along with an analysis of the parts-
of-speech of the collocating words.
4 The development of SweFN
As described by the BFN research team, manual construction of a framenet resource involves several
steps, including defining frames and frame elements, collecting appropriate lexical units for the frames,
comparing the findings with printed dictionaries, extracting syntactic and collocational contexts to illus-
trate the frame, and analyzing sentences to explore the use of LUs (Fillmore et al., 2003).
The work procedure of SweFN is based on transfer of information from BFN. To a large extent we
follow the BFN development process, but the development of SweFN differs in three crucial aspects:
(1) when we transfer frames from BFN to Swedish, there is usually no need to re-define them. How-
ever, the frames are checked for compatibility with Swedish language and culture; (2) our inventory of
LUs is derived from the SALDO lexicon; (3) we utilize in-house resources, all linked in the Swedish
infrastructure for language technology, SweFN++.
Taking BFN as a starting point saves time and effort in developing frames. Most of the effort goes
to figure out what SALDO entries evoke which frames and to find suitable example sentences. In order
to find appropriate LUs evoking a particular frame we consult: (1) the lexical resources in Karp (see
section 4.3); (2) printed dictionaries; (3) the corpus infrastructure Korp for concordance search in order to
investigate additional uses of the words. This process occasionally results in new frames or modification
of the frames of BFN (see section 4.4).
4.1 SALDO
The manual process of constructing a SweFN frame begins with choosing a frame from BFN or word of
interest. When we create a frame equivalent to one which already exists in BFN, we transfer the frame
features which are more or less language independent from the BFN frame to the SweFN frame. These
features include frame description, frame-to-frame relations, and FEs. We then search for appropriate
SALDO entries evoking the frame as well as example sentences for annotation. If suitable entries exist
in SALDO they are chosen for use as LUs. Otherwise we suggest entries to be added to SALDO (Borin
et al., 2013a). Each SALDO sense is allowed to populate only one SweFN frame except in a few cases
where some inflectional forms evoke one frame and other forms another frame.
When we instead use a word or expression as a starting point we look up all senses in SALDO and
systematically add each sense to the frame it evokes. The selection of LUs from SALDO to populate
the frames of SweFN is done in different ways. One method is to determine which of the English LUs
of BFN frames have suitable equivalents in Swedish. Thereafter different types of searches are made
in SALDO. For example, working on the frame Containers, having introduced the noun LU flaska
?bottle? one can search for entries ending with flaska, thus finding a number of compounds such as cham-
pagneflaska ?champagne bottle?, droppflaska ?dropper bottle (med.)?, eng?angsflaska (one+time+bottle)
10
http://lexin2.nada.kth.se/lexin/
11
?non-returnable bottle?, glasflaska ?glass bottle?, halvflaska (half+bottle) ?375ml bottle?, miniatyrflaska
?miniature bottle?, nappflaska (pacifier+bottle) ?baby bottle?, sprayflaska (spray+bottle) ?spray can?, tom-
flaska ?empty bottle?, vattenflaska ?water bottle?, v?armeflaska (heat+bottle) ?warm water bottle?, to name
a few. Another method is searching for entries having the LU in question as one of the determiners. For
example, working on the Animal frame, a search may be done on the determiner djur ?animal? resulting
in a long list of lexical entries for different species of animals, which may be entered into the frame.
The possibility of doing searches in SALDO as described above, in combination with compounding
being very productive in Swedish, is one reason for the relatively large number of LUs in SweFN.
4.2 Swedish Constructicon
Constructions are more complex linguistic units than words, they are common in use and difficult to ig-
nore when working with authentic text. One way to enrich SweFN with more representative examples of
how to express meaning in language is to include constructions as frame-evoking units in the database.
Currently work is being done on systematically linking constructions in SweCcn with frames in SweFN
(Ehrlemark, 2014), but the task is not as straight-forward as identifying which frame is evoked by a
certain LU. First, not all constructions evoke frames, carrying little meaning from a semantic point of
view. This includes such general patterns as constructions for modification, predication, passive voice
or filler-gap constructions. Second, constructions that potentially correspond with frames do not always
fit the distribution pattern of frame elements described in the target frame. This group includes fig-
urative constructions or constructions that are more, or less, general than the target frame in SweFN.
Constructions which do correspond with frames may be called frame-bearing constructions (Fillmore
et al., 2012). A frame-bearing construction evokes a target frame in the same manner as an LU, with
matching construction elements and frame elements.
The linking of constructions with frames is carried out through manual analysis of constructions and
their semantic valence patterns. The work includes paraphrasing the meaning of a construction to identify
which frame or frames it may evoke, and thereafter comparing the construction elements with the FEs of
the target frame. For example, SweCcn includes three constructions for comparisons: j?amf?orelse
?comparison?, which has the two subordinate constructions j?amf?orelse.likhet ?compari-
son.similarity? and j?amf?orelse.olikhet ?comparison.difference? ? all three are Swedish equiva-
lents of corresponding constructions in the Berkeley Constructicon (B?ackstr?om et al., 2014). In all three
cases the CEs in the construction entries correspond to the FEs in the Evaluative comparison
frame which has the following definition: a PROFILED ITEM is compared to a STANDARD ITEM with re-
spect to some ATTRIBUTE. By establishing a link between, in this case the comparison constructions
and the Evaluative comparison frame, we may enrich the frame with typical example sentences
such as Hennes cykel ?ar b?attre ?an min ?Her bicycle is better than mine? and Popband ?ar lika arga som
rockband ?Popbands are as angry as rockbands?.
Another example is the pair of constructions proportion i om and proportion per, which
distinguish different syntactic patterns for expressing proportion in Swedish. In both cases,
the construction combines two entities, a numerator and a denominator, joined by a preposi-
tion. However, they differ regarding domain of use, preposition used, and definiteness of the
second noun phrase. The construction proportion i om describes time, and therefore cor-
responds to frames that express proportion in relation to time units, such as Frequency and
Speed description. The construction proportion per is a more general construction
that expresses Frequency and Speed description as well as other ratio relations as de-
scribed in the frames Relational quantity, Rate quantification, Proportion, and
Price per unit. Thus, a link between SweFN and SweCcn may refer the user to correct Swedish
constructions for ratio relations from the frames they evoke.
At the time of writing, about half of the entries in SweCcn are linked to frames in SweFN. The
continuing work with comparing and linking the two resources does not aim to link all constructions
with frames, but rather to distinguish frame-bearing from non-frame-bearing constructions. The linking
allows the user to easily go between a construction and the frame or frames it evokes and correspondingly
12
from a frame to constructions evoking the frame. In this way, both SweCcn and SweFN become more
representative of the language they set out to describe and better incorporated for future pedagogical and
language technological uses.
4.3 Karp
As well as being the editing tool used to build SweFN and other resources, Karp is an important tool
for accessing information. Searching on any expression, word form or lemma results in a display of
every occurrence in all SweFN++ resources, except instances in the corpus. This gives, for example, an
overview of different senses of polysemous words, in which resources they have been entered and how.
Thus, we can see which SweFN frames are evoked by different senses of a word, we can see synonymous
words in Swesaurus (Borin and Forsberg, 2014), the morphology of the word as well as multiword units
containing this word in SALDO, samples of sentences from Korp where the chosen word occurs, and
constructions in Swedish Constructicon which use this word (Lyngfelt et al., 2012).
SweFN developers use Karp to find SALDO entries that evoke a particular frame, SweCcn developers
use Karp to find frames evoked by constructions, or constructions that evoke frames. Figure 2 shows an
example of a view in Karp. In this particular view SweFN and SweCcn resources were selected, but other
choices are also possible. The combination of searches shown here are in turn for a certain construction
or frame (two first boxes), for constructions that match a certain frame (third box). This particular search
is for constructions that match Similarity, which here resulted in 14 different constructions, each
of which contained potential patterns which in turn could be used to perform new searches in Korp.
Finally, in the fourth box the search is for a particular SALDO sense, and in the fifth box for a certain
LU. Searches for other types of units such as frame elements, etc. are also possible.
Figure 2: The Karp editing tool provides various functionalities to extract information from a number
of different lexical resources. The combination of searches above is selected to illustrate the variety of
possibilities in Karp.
13
4.4 Korp
The Korp corpora and search interface serve several purposes in the creation of SweFN. The coverage
of lexical variation found in corpora is much larger than the variation we find in a lexicon and this helps
in defining senses of polysemous words. From the corpora, example sentences are extracted to illustrate
valence structures of LUs evoking frames. Korp extended search allows searches that combine SweFN
LUs and syntactic structures of SweCcn constructions. The Related Words function provides a method of
easily expanding the set of LUs populating a frame and giving easy access to example sentences where
lexical variations are observed. Word Picture offers guidance in disambiguation as of LUs well as in
analyzing semantic and syntactic structures.
Korp is a useful tool to check for compatibility with Swedish language and culture. Extended searches
help us modify BFN frames and create new frames. There are two situations when BFN frames have
been modified for SweFN (Heppin and Gronostaj, 2014): (1) the BFN frames are not suitable because
of linguistic or cultural differences. For example the BFN frame Jury deliberation has been re-
defined to Deliberation in SweFN. In Deliberation the FE corresponding to the FE JURY in
BFN is changed to DELIBERATION GROUP seeing that there is no jury in the Swedish legal process
and a more general frame is appropriate as it covers deliberations in different kinds of legal systems;
(2) the BFN frames are too general for our purposes, for example Sound makers in BFN corresponds
to two more specific frames in SweFN: Noise makers and Musical instruments. Completely
new frames have also been created when there is a need for a frame not yet created for BFN. SweFN, for
example, has a greater emphasis on nominal LUs than framenets for other languages. Therefore, frames
such as Animals, Countries, and Plants have been created.
After determining the appropriate pairing of SALDO units and SweFN frames, searches are made for
example sentences manifesting these LUs in the Korp corpora. The sentences we aim to find should have
a variation of valence structure to give a broad overall picture of the LU patterns.
Figure 3: Word picture from Korp of the verb bygga ?build? in present tense, e.g. bygger. The columns
display from left to right subjects, objects, and adverbials. The number to the right in each column is the
frequency of the collocation in Korp.
Word Picture is useful when taking a starting point in individual, polysemous words, to determine
which frames are evoked by the different senses. In figure 3 items, which are listed in subject and object
14
positions respectively, highlight two different senses of the verb bygga ?build?, one abstract and one
concrete sense. The nouns found in subject position, such as film ?film?, system ?system?, unders?okning
?examination?, metod ?method?, rapport ?report?, etc., occur with the sense of bygga ?build? which is
typically found in an abstract intransitive construction with the preposition p?a ?on? as in ?founded on?,
?built on?, or ?based on?. This sense evokes the Use as a starting point frame. The nouns in the
object position, such as hus ?house? and bro ?bridge?, collocate with the agentive verb bygga ?build? in
the concrete sense of ?construct? or ?erect?, which evokes the Building frame (Heppin and Gronostaj,
2014).
5 Consistency checks and automatic extension of the data
There is no gold standard to evaluate the quality of SweFN against as there is no other comparable
resource. FrameNet-like resources for other languages are constructed with different foci and under
different conditions. However, there is a constant assessment of the correctness of the resources built
into the workflow and ongoing consistency checks to avoid inconsistency between resources. The Karp
tool gives error messages, for example when SALDO entries are listed in more than one frame. Other
types of checks are run with certain intervals, for example to see if there are annotation tags which do not
follow the standard format. Confronted with different types of error messages the developers go back to
the frames in question to revise the contents of the frame, such as which LUs are said to evoke the frame,
or the choice of and annotation of example sentences.
One part of the work is directed towards developing computational methods to facilitate the man-
ual construction of SweFN. We have so far focused on three tasks: (1) semantic role labeling (SRL)
(Johansson et al., 2012); (2) automatic sentence extraction, i.e. finding example sentences with varied
syntactic and semantic complexities (Pil?an et al., 2013); (3) automatic expansion of the SweFN lexicon
to determine which frame is evoked by a given word by combining statistical and rule-based methods
based on SALDO descriptors and extracted information from Korp (Johansson, 2014).
6 Conclusions
The building of one big macro-resource for Swedish language technology, where the individual resources
interact with and enhance each other, provides a unique overview of the Swedish language. One search
on a lexical expression results in a list of descriptions from all of the separate resources. The information
derived is not only useful for the end user, but also for the continuing work on all parts of the linguistic
macro-structure.
We have here focused on how two language technology resources, SALDO and SweCcn, are exploited
in the development of SweFN, but also on how these resources enhance each other and other resources.
We mainly address the manual perspectives of the workflow, illustrating what data may derive from the
different resources, how this data may be used to facilitate work, and how the contents of one resource
may reappear in the contents of another. We have given a sketch of the language technology tools with
the aim to reveal their potential importance in the development of SweFN.
The construction of SweFN, and even more so the construction of a macro-resource such as SweFN++,
will continue to develop in the foreseeable future. New insights as well as new problems will continue
to give rise to changes.
Acknowledgements
The authors would like to thank the Department of Swedish at the University of Gothenburg and the
three anonymous reviewers. The research presented here was supported by the Swedish Research
Council (grant agreement 2010-6013), the Bank of Sweden Tercentenary Foundation (grant agreement
P120076:1), and by the University of Gothenburg through its support of the Centre for Language Tech-
nology and of Spr?akbanken.
15
References
Malin Ahlberg, Lars Borin, Markus Forsberg, Martin Hammarstedt, Leif-J?oran Olsson, Olof Olsson, Johan Roxen-
dal, and Jonatan Uppstr?om. 2013. Korp and Karp a bestiary of language resources: the research infrastructure
of Spr?akbanken. In Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA
2013), Oslo University, Norway. NEALT Proceedings Series 16, number 16, pages 429?433.
H?ector Mart??nez Alonso, Bolette Sandford Pedersen, and N?uria Bel. 2013. Annotation of regular polysemy and
underspecification. In ACL (2), pages 725?730. The Association for Computer Linguistics.
Linn?ea B?ackstr?om, Benjamin Lyngfelt, and Emma Sk?oldberg. 2014. Towards interlingual constructicography. on
correspondence between constructicon resources for English and Swedish. Constructions and Frames, 6(1):9?
32. John Benjamins Publishing Company.
Anderson Bertoldi and Rove Luiza de Oliveira Chishman. 2011. The limits of using FrameNet frames to build a
legal ontology. In CEUR Workshop Proceedings, volume 776, pages 207?212.
Lars Borin and Markus Forsberg. 2014. Swesaurus; or, The Frankenstein approach to Wordnet construction. In
Proceedings of the Seventh Global WordNet Conference (GWC 2014).
Lars Borin, Dana Dann?ells, Markus Forsberg, Maria Toporowska Gronostaj, and Dimitrios Kokkinakis. 2010. The
past meets the present in Swedish FrameNet++. In Proceedings of the 14th EURALEX International Congress,
pages 269?281.
Lars Borin, Markus Forsberg, and Johan Roxendal. 2012. Korp the corpus infrastructure of Spr?akbanken. In
Proceedings of LREC 2012. Istanbul: ELRA.
Lars Borin, Markus Forsberg, and Lennart L?onngren. 2013a. SALDO: a touch of yin to WordNet?s yang. Lan-
guage Resources and Evaluation, 47(4):1191?1211.
Lars Borin, Markus Forsberg, Leif-J?oran Olsson, Olof Olsson, and Jonatan Uppstr?om. 2013b. The lexical editing
system of Karp. In Proceedings of the eLex 2013 conference, pages 503?516, Tallin.
Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea Kowalski, Sebastian Pad?o, and Manfred Pinkal, 2009.
Multilingual FrameNets in computational lexicography, chapter Using FrameNet for the semantic analysis of
German annotation, representation, and annotation. Berlin: Mouton de Gryter.
Dipanjan Das, Desai Chen, Andr?e F. T. Martins, Nathan Schneider, and Noah A. Smith. 2014. Frame semantic
parsing. Computational Linguistics, 40(1):9?56.
Anna Ehrlemark. 2014. Ramar och konstruktioner ? en k?arlekshistoria [Frames and constructions ? a love story].
Department of Swedish, University of Gothenburg. GU-ISS 2014-01.
Charles J. Fillmore, Miriam R.L. Petruck, Josef Ruppenhofer, and Abby Wright. 2003. FrameNet in Action: The
Case of Attaching. IJL, 16(3):297?332, September.
Charles J. Fillmore, Russell Lee-Goldman, and Russell Rhomieux, 2012. Sign-based construction grammar,
chapter The FrameNet constructicon. Stanford: CSLI.
Charles J. Fillmore. 1985. Frames and the semantics of understanding. Quaderni di Semantica, 6(2):222?254.
Gil Francopoulo, Monte George, Nicoletta Calzolari, Monica Monachini, Nuria Bel, Mandy Pet, and Claudia
Soria. 2006. LMF for Multilingual, Specialized Lexicons. In Proceedings of the 5
th
International Conference
on Language Resources and Evaluation (LREC), pages 233?236.
Karin Friberg Heppin and Maria Toporowska Gronostaj. 2014. Exploiting FrameNet for Swedish: Mismatch?
Constructions and Frames, 6(1):51?71. John Benjamins Publishing Company.
Richard Johansson, Karin Friberg Heppin, and Dimitrios Kokkinakis. 2012. Semantic role labeling with the
Swedish FrameNet. In Proceedings of the 8
th
Conference on International Language Resources and Evaluation
(LREC), pages 3697?3700, Istanbul, Turkey.
Richard Johansson. 2014. Automatic expansion of the Swedish FrameNet lexicon ? Comparing and combining
lexicon-based and corpus-based methods. Constructions and Frames, 6(1):91?112. John Benjamins Publishing
Company.
Ora Lassila and Ralph Swick. 1999. Resource Description Framework (RDF). Model and Syntax Specification.
Technical report, W3C. http://www.w3.org/TR/REC-rdf-syntax.
16
Benjamin Lyngfelt, Lars Borin, Markus Forsberg, Julia Prentice, Rudolf Rydstedt, Emma Sk?oldberg, and Sofia
Tingsell. 2012. Adding a Constructicon to the Swedish resource network of Spr?akbanken. In Proceedings of
KONVENS 2012, Vienna. LexSem workshop.
Alessandro Moschitti, Paul Morarescu, and Sanda M. Harabagiu. 2003. Open domain information extraction via
automatic semantic labeling. In Proceedings of the 16th International FLAIRS Conference, pages 397?401.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Glsen Eryigit, Sandra Kbler, Svetoslav Marinov, and
Erwin Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing. Natural
Language Engineering, 13(2):95?135.
Kyoko Hirose Ohara. 2013. Toward constructicon building for Japanese in Japanese FrameNet. Veredas: Frame
Semantics and Its Technological Applications, 17(1):11?28.
Ildik?o Pil?an, Elena Volodina, and Richard Johansson. 2013. Automatic selection of suitable sentences for language
learning exercises. In 20 Years of EUROCALL: Learning from the Past, Looking to the Future. 2013 EUROCALL
Conference, 11th to 14th September 2013 Evora, Portugal, Proceedings., pages 218?225.
Michael Roth and Anette Frank. 2009. A NLG-based application for walking directions. In Proceedings of the
47th ACL and the 4th IJCNLP Conference (Software Demonstrations), pages 37?40.
Emma Sk?oldberg, Linn?ea B?ackstr?om, Lars Borin, Markus Forsberg, Benjamin Lyngfelt, Leif-J?oran Olsson, Julia
Prentice, Rudolf Rydstedt, Sofia Tingsell, and Jonatan Uppstr?om. 2013. Between grammars and dictionaries: a
Swedish Constructicon. In Proceedings of the eLex 2013 conference, pages 310?327, Tallin.
Carlos Subirats, 2009. Multilingual FrameNets in Computational Lexicography, chapter Spanish FrameNet: a
frame-semantic analysis of the Spanish lexicon. Berlin: Mouton de Gryter.
Tiago Timponi Torrent, Maria Margarida Martins Salom?ao, Ely Edison da SilvaMatos, Maucha Andrade Ganomal,
J?ulia Gonc?alves, Bruno Pereira de Souza, Daniela Sim?oes, and Simone Rodrigues Peron-Corr?ea. 2014. Mul-
tilingual lexicographic annotation for domain-specific electronic dictionaries: the Copa 2014 FrameNet Brasil
project. Constructions and Frames, 6(1):72?90. John Benjamins Publishing Company.
Tiago Timpioni Torrent. 2013. Behind the labels: Criteria for defining analytical categories in FrameNet Brasil.
Veredas: Frame Semantics and Its Technological Applications, 17(1):44?65.
17
