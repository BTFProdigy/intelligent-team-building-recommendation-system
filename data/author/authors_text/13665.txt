Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 15?19, Dublin, Ireland, August 23-29 2014.
Creating Custom Taggers by Integrating Web Page Annotation and
Machine Learning
Srikrishna Raamadhurai
?
Oskar Kohonen
?
Teemu Ruokolainen
??
?
Aalto University, Department of Information and Computer Science, Finland
??
Aalto University, Department of Signal Processing and Acoustics, Finland
firstname.lastname@aalto.fi
Abstract
We present an on-going work on a software package that integrates discriminative machine learn-
ing with the open source WebAnnotator system of Tannier (2012). The WebAnnotator system
allows users to annotate web pages within their browser with custom tag sets. Meanwhile, we
integrate the WebAnnotator system with a machine learning package which enables automatic
tagging of new web pages. We hope the software evolves into a useful information extraction
tool for motivated hobbyists who have domain expertise on their task of interest but lack machine
learning or programming knowledge. This paper presents the system architecture, including the
WebAnnotator-based front-end and the machine learning component. The system is available
under an open source license.
1 Introduction
A typical development cycle of a natural language processing (NLP) tool involves several different ex-
perts whose time is often limited as well as expensive. In particular, rule-based systems need experts to
construct the rules, while data-driven systems require domain experts to produce annotated training data
and machine learning experts to train the systems. Because of the required investment, tasks which lack
commercial or academic interest are often left completely without applicable tools. Nevertheless, we
believe that there exist many relatively simple tasks where necessary annotation for a machine learning
system could be produced by motivated hobbyists who possess domain expertise but lack machine learn-
ing or programming knowledge. For example, consider identifying fields in classified ads such as product
name, dimensions and price, or segmenting individual posts in a web forum. To this end, we present a
software package that integrates discriminative machine learning with the open source WebAnnotator
system (Tannier, 2012).
The combination of an annotation tool and machine learning is, of course, not a new idea, as it goes
back at least to the Alembic system (Day et al., 1997), which was developed to accelerate the process
of tailoring NLP tools to new domains, languages, and tasks, by attempting to reduce the work load of
human annotators by employing pre-taggers learned from previously annotated data. Despite these ideas
being around for a long time, they do not seem to have been integrated into a web-browser previously.
Since a large amount of information is consumed using the web-browser, it is desirable to be able to train
and apply automatic analysis tools directly within that context.
The paper is organized as follows. In Section 2, we review how the system is used, its general archi-
tecture and details related to how the machine learning is implemented. Section 4 provides discussion
and conclusions on the work.
2 System
In this section we present in some detail the system that integrates discriminative machine learning
with the open source WebAnnotator (Tannier, 2012). We review the usage of the system, its software
architecture, the central aspects related to how machine learning is applied: the employed Conditional
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
15
Random Fields-method, indexing and pre-processing web-pages, how training sets are constructed, and
the applied feature extraction. Finally, we review how the trained system is applied to new web-pages.
The latest version of the software can be found at https://github.com/okohonen/
semantify.
2.1 Overview of Usage
The system is installed as an add-on to the Firefox browser. Subsequently, it can be activated for any
web page. The user can train several different models by indicating which model a particular annotation
belongs to. The user can also define the tag set used for annotation. To annotate, the user highlights
parts of the page with the mouse and selects the desired tag from the shown menu. Assigned annotations
are denoted by colors. This process is presented in Figure 1 (a). When the user is done, she stores the
annotated page as shown in Figure 1 (b). The system then stores the annotated page in its page index.
Meanwhile, in the background, the system automatically produces a training set that contains all the
pages annotated so far and learns a tagger. The user can ask the system to tag a new page as shown in
Figure 1 (c), in which case the system pre-processes and tags the current page using the latest trained
model. The system then adds the annotations matching the output of the machine learning model to the
viewed web page. The automatically assigned tags are visually distinct from the manually annotated
ones (lighter color scheme). The automatic taggings can then be corrected manually and added to the
training set. An example of an automatically annotated page is shown in figure 1 (d).
2.2 Overview of Architecture
The system architecture consists of two main components, namely, 1) an add-on to the Firefox-browser
that allows annotation of web pages directly in the browser window, and 2) a machine learning compo-
nent for annotating new pages. The browser add-on extends the WebAnnotator system (Tannier, 2012)
by integrating it with the machine learning component and with functionality to show and edit the tags
produced by the trained taggers. The machine learning component indexes the annotated web pages, pre-
processes them to produce training sets of sentences, and trains models that can then be applied to new
data. The Firefox add-on is implemented in Javascript and XUL while the machine learning component
is implemented in Python. To bridge the language gap they communicate using XMLHTTPRequest.
The machine learning component implements the well-known conditional random field (CRF) method,
a discriminative modeling framework for sequence labeling (Lafferty et al., 2001).
2.3 Conditional Random Fields
Our system implements the linear-chain CRF model (Lafferty et al., 2001) which can inherently accom-
modate the arbitrary, overlapping features described below in Section 2.7. The CRF model is estimated
based on the available training set of exemplar input-output sequence pairs. Test instances are decoded
using the standard Viterbi search (Lafferty et al., 2001).
CRF parameter estimation is most commonly associated with the maximum likelihood approach em-
ployed by Lafferty et al.(2001). However, in our system, we rely on the averaged perceptron algorithm
following Collins (2002a). (Note that the CRFs correspond to discriminatively trained hidden Markov
models, and Collins (2002a) employs the latter terminology.) We apply the averaged perceptron learning
approach for its simplicity and competitive performance (Zhang and Clark, 2011).
2.4 Web Page Index
The web page index in the machine learning component stores the annotated pages using the internal
format of WebAnnotator, which is simply the original HTML-page augmented with <span>-tags to
encode and visualize the annotations. Apart from annotated pages, it is also possible to index unannotated
pages if one has a particular set of pages that are to be tagged by the model.
16
Figure 1: Sample screenshots of the tool depicting typical scenarios.
2.5 Pre-processing
We parse the HTML using the Beautiful Soup-library
1
, extracting the visible text parts. Subsequently, we
tokenize the text by splitting at white space and at non-alphanumeric characters. The token sequence is
grouped into sentences based on punctuation and HTML-tags. We consider that if an HTML-tag defines
a new block then it also starts a new sentence (e.g. <div> starts a block, while <span> does not). For
each token position we apply feature functions that are described in detail in Section 2.7.
The user?s annotations are stored as span-tags that are identified by their class attributes. The
span-tags are parsed so that the label information is extracted, but they are ignored when calculating
the feature functions which should be identical regardless of how the page is annotated. If the user has
not assigned any label we assume a default Outside class.
2.6 Building the Training Sets
The CRF parameter estimation requires training and development sets which must be drawn from an-
notated web pages in the page index. A special characteristic of the data set is that the label distribu-
tion is typically very skewed towards many Outside taggings and few non-Outside taggings. To
ensure that the development set gets sufficiently many non-Outside taggings, we use use a modulus-
based scheme that assigns 10% of the sentences to the development set while making sure that there are
enough sentences containing taggings from each class. The training set and development set are formed
by concatenating the preprocessed files for each individual page.
2.7 Feature Extraction
In addition to standard first-order state transition features, the CRF model includes feature functions
which operate on the token sequence of the sentence and the HTML-tree of the page. We use ortho-
graphic features and HTML-features which consider the token string and HTML-tree, respectively. For
orthographic features, we use the word in lower case, and generalized character-based following Collins
(2002b). We extract features based on the following properties of the current node in the HTML-tree:
parent nodes and the class-attribute. For the parent nodes we calculate both individual features for im-
1
http://www.crummy.com/software/BeautifulSoup/
17
mediate parents as well as very specific features that concatenates all parents up to the body-tag. For
the class-attribute we provide it both as it is and apply the same generalization functions as in the or-
thographic feature set. One could also extract features from other attributes than class. However, we
suspect that they are less informative for the tagging task compared to the class-attribute which is often
used to indicate structural properties of the page content. We also window the features to consider the
previous and next positions in the input.
2.8 Annotating New Pages Automatically
When the user asks the system to tag a new page, the current page is sent to the machine learning
component for preprocessing. The latest trained CRF is applied to the preprocessed page and each token
is assigned a tag. We produce <span>-tags similar to the internal format used by WebAnnotator, but
with distinct attributes so the browser extension can distinguish manual and automatic annotation. To
produce the modified HTML-page, we need to know the position in the HTML-string for each token in
the preproessed file. In order to achieve this, we create an index of the HTML-string during preprocessing
that maps every token to its original position in the string.
3 Discussion
For a software tool of the presented kind, the key performance measures are: accuracy on the task at
hand, as a function of the number of annotations; and training time. As both measures are specific to task
and implementation, addressing them both experimentally would require a large number of experiments
which is not feasible in the allowed space. However, for illustration purposes, we will present a simple
example application.
In general, for the proposed system to yield high accuracy, it needs to learn the desired categories from
a few annotated examples. This requires input features that predict the desired target category well. The
key benefit of the discriminative training employed is the ability to use a large set of rich and overlapping
features. This allows the construction of feature sets that yield good performance on several different
tasks, reducing the need for task-specific feature engineering which requires domain and programming
expertise. Future work includes identifying additional features that yield good performance in a number
of different tasks.
For training time, it would be ideal if the system could be trained in real time, that is, once the user
has submitted an annotated web page to the system, the training would be completed when the user
wants to apply the model to a new web page. This would require training times on the order of a few
seconds. Training time depends mostly on the employed classifier, training algorithm, and the number of
sequences and tokens in the training set. We had assumed that training time would not be an issue, even
for a naive implementation, because a typical user would only gather small data sets. However, it turned
out that while the annotation may be small in the number of annotated web pages, typical web pages
were larger in terms of token counts than we had anticipated and more advanced training techniques may
be needed to reach real-time performance.
To illustrate the properties related to tagging web pages using the current implementation, we present
a simple example application of the system to the task of extracting fields from the Internet Movie
Database (IMDB).
2
We annotated 50 web pages from IMDB, each describing a different movie. The
following fields were annotated: director, genre, title, rating, theme, writer, and release year. It should
be noted that this task is from the easier end of the spectrum, as the fields can be extracted with a high
accuracy using the markup structure alone. For experimental purposes, we performed cross-validation
with training, development, and test sets constructed from 36, 4, and 10 web pages respectively. The
system yielded the following token F-scores by category, director: 73%, genre: 99%, title: 86%, rating:
100%, theme: 100%, writer: 80%, and release year: 100%. This level of performance is promising,
as several fields were extracted with perfect, or near perfect accuracy. The training times for the 36-
page training sets varied between 1.5 and 3.5 minutes on a standard desktop computer (Intel i5-2500
with 16Gb RAM). The variance in training time is explained by the employed stopping criterion which
2
http://www.imdb.com
18
terminates training based on the performance on the development set, resulting in varying numbers of
passes over the training data. In the above example task, the training set sizes were on average: 22K
sequences, 133K tokens, and 30K features.
The empirical training times are longer than what could be considered real-time performance. The
goal of the current implementation has been accuracy rather than execution time, and for the latter, there
is certainly room for improvement. However, for real-time performance, the improvement needed is
large enough that a different training procedure may be necessary. A promising approach, that suits the
setting well, is using online training, such that one would only train on the latest submitted web-page.
Furthermore, it is usually the case, that the non-Outside annotation is concentrated on a fairly small
subpart of the web page. This structure could be utilized to reduce computational cost. These approaches
will be evaluated in future work.
4 Conclusions
We presented on-going work on a software package that integrates discriminative machine learning with
the open source WebAnnotator system of Tannier (2012). The system allows users to annotate web
pages directly within their web browser and train a machine learning tagger applicable for annotating
new web pages. We hope the software evolves into a useful information extraction tool for motivated
hobbyists who have domain expertise on their task of interest but lack machine learning or programming
knowledge.
In future work, we plan to investigate the following aspects of the system. The utility of the system
should be evaluated in real-life tasks and for the target user group. The machine learning component
could then be improved further based on user experience. Perhaps most importantly, the extracted fea-
tures can be improved using both generic and task-specific features. Also, while the system currently
applies only supervised learning, it would be a natural setting to apply semi-supervised learning.
Acknowledgements
The work was funded by an Exploratory Research Project grant from Aalto Science Institute, the
Academy of Finland research project on Multimodal Language Technology, Langnet (Finnish doctoral
programme in language studies), and the Academy of Finland under the Finnish Centre of Excellence
Program 2012?2017 (grant no. 251170).
References
Michael Collins. 2002a. Discriminative training methods for hidden Markov models: Theory and experiments
with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural lan-
guage processing, volume 10, pages 1?8.
Michael Collins. 2002b. Ranking algorithms for named-entity extraction: Boosting and the voted perceptron.
In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 489?496.
Association for Computational Linguistics.
David Day, John Aberdeen, Lynette Hirschman, Robyn Kozierok, Patricia Robinson, and Marc Vilain. 1997.
Mixed-initiative development of language processing systems. In Proceedings of the Fifth Conference on Ap-
plied Natural Language Processing, ANLC ?97, pages 348?355, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
John Lafferty, Andrew McCallum, and Fernando C.N. Pereira. 2001. Conditional random fields: Probabilistic
models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference
on Machine Learning, pages 282?289.
Xavier Tannier. 2012. WebAnnotator, an Annotation Tool for Web Pages. In Proceedings of the 8th International
Conference on Language Resources and Evaluation (LREC 2012), Istanbul, Turkey, May.
Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search.
Computational Linguistics, 37(1):105?151.
19
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 84?89,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Painless Semi-Supervised Morphological Segmentation using Conditional
Random Fields
Teemu Ruokolainen
a
Oskar Kohonen
b
Sami Virpioja
b
Mikko Kurimo
a
a
Department of Signal Processing and Acoustics, Aalto University
b
Department of Information and Computer Science, Aalto University
firstname.lastname@aalto.fi
Abstract
We discuss data-driven morphological
segmentation, in which word forms are
segmented into morphs, that is the surface
forms of morphemes. We extend a re-
cent segmentation approach based on con-
ditional random fields from purely super-
vised to semi-supervised learning by ex-
ploiting available unsupervised segmenta-
tion techniques. We integrate the unsu-
pervised techniques into the conditional
random field model via feature set aug-
mentation. Experiments on three di-
verse languages show that this straight-
forward semi-supervised extension greatly
improves the segmentation accuracy of the
purely supervised CRFs in a computation-
ally efficient manner.
1 Introduction
We discuss data-driven morphological segmenta-
tion, in which word forms are segmented into
morphs, the surface forms of morphemes. This
type of morphological analysis can be useful for
alleviating language model sparsity inherent to
morphologically rich languages (Hirsim?ki et al.,
2006; Creutz et al., 2007; Turunen and Kurimo,
2011; Luong et al., 2013). Particularly, we focus
on a low-resource learning setting, in which only
a small amount of annotated word forms are avail-
able for model training, while unannotated word
forms are available in abundance.
We study morphological segmentation using
conditional random fields (CRFs), a discrimina-
tive model for sequential tagging and segmenta-
tion (Lafferty et al., 2001). Recently, Ruoko-
lainen et al. (2013) showed that the CRFs can
yield competitive segmentation accuracy com-
pared to more complex, previous state-of-the-
art techniques. While CRFs yielded generally
the highest accuracy compared to their reference
methods (Poon et al., 2009; Kohonen et al., 2010),
on the smallest considered annotated data sets of
100 word forms, they were outperformed by the
semi-supervised Morfessor algorithm (Kohonen et
al., 2010). However, Ruokolainen et al. (2013)
trained the CRFs solely on the annotated data,
without any use of the available unannotated data.
In this work, we extend the CRF-based ap-
proach to leverage unannotated data in a straight-
forward and computationally efficient manner via
feature set augmentation, utilizing predictions of
unsupervised segmentation algorithms. Experi-
ments on three diverse languages show that the
semi-supervised extension substantially improves
the segmentation accuracy of the CRFs. The ex-
tension also provides higher accuracies on all the
considered data set sizes and languages compared
to the semi-supervised Morfessor (Kohonen et al.,
2010).
In addition to feature set augmentation, there
exists numerous approaches for semi-supervised
CRF model estimation, exemplified by minimum
entropy regularization (Jiao et al., 2006), gen-
eralized expectations criteria (Mann and McCal-
lum, 2008), and posterior regularization (He et al.,
2013). In this work, we employ the feature-based
approach due to its simplicity and the availabil-
ity of useful unsupervised segmentation methods.
Varying feature set augmentation approaches have
been successfully applied in several related tasks,
such as Chinese word segmentation (Wang et al.,
2011; Sun and Xu, 2011) and chunking (Turian et
al., 2010).
The paper is organized as follows. In Section 2,
we describe the CRF-based morphological seg-
mentation approach following (Ruokolainen et al.,
2013), and then show how to extend this approach
to leverage unannotated data in an efficient man-
ner. Our experimental setup and results are dis-
cussed in Sections 3 and 4, respectively. Finally,
84
we present conclusions on the work in Section 5.
2 Methods
2.1 Supervised Morphological Segmentation
using CRFs
We present the morphological segmentation task
as a sequential labeling problem by assigning each
character to one of three classes, namely {be-
ginning of a multi-character morph (B), middle
of a multi-character morph (M), single character
morph (S)}. We then perform the sequential label-
ing using linear-chain CRFs (Lafferty et al., 2001).
Formally, the linear-chain CRF model distribu-
tion for label sequence y = (y
1
, y
2
, . . . , y
T
) and
a word form x = (x
1
, x
2
, . . . , x
T
) is written as a
conditional probability
p (y |x;w) ?
T
?
t=2
exp
(
w ? ?(y
t?1
, y
t
, x, t)
)
,
(1)
where t indexes the character positions,w denotes
the model parameter vector, and ? the vector-
valued feature extracting function. The model pa-
rameters w are estimated discrimatively based on
a training set of exemplar input-output pairs (x, y)
using, for example, the averaged perceptron algo-
rithm (Collins, 2002). Subsequent to estimation,
the CRF model segments test word forms using
the Viterbi algorithm (Lafferty et al., 2001).
We next describe the feature set
{?
i
(y
t?1
, y
t
, x, t)}
|?|
i=1
by defining emission
and transition features. Denoting the label set {B,
M, S} as Y , the emission feature set is defined as
{?
m
(x, t)1(y
t
= y
?
t
) |m ? 1..M ,?y
?
t
? Y} ,
(2)
where the indicator function 1(y
t
= y
?
t
) returns
one if and only if y
t
= y
?
t
and zero otherwise, that
is
1(y
t
= y
?
t
) =
{
1 if y
t
= y
?
t
0 otherwise
, (3)
and {?
m
(x, t)}
M
m=1
is the set of functions describ-
ing the character position t. Following Ruoko-
lainen et al. (2013), we employ binary functions
that describe the position t of word x using all left
and right substrings up to a maximum length ?.
The maximum substring length ?
max
is considered
a hyper-parameter to be adjusted using a develop-
ment set. While the emission features associate
the input to labels, the transition feature set
{1(y
t?1
= y
?
t?1
)1(y
t
= y
?
t
) | y
?
t
, y
?
t?1
? Y} (4)
captures the dependencies between adjacent labels
as irrespective of the input x.
2.2 Leveraging Unannotated Data
In order to utilize unannotated data, we explore a
straightforward approach based on feature set aug-
mentation. We exploit predictions of unsupervised
segmentation algorithms by defining variants of
the features described in Section 2.1. The idea is
to compensate the weaknesses of the CRF model
trained on the small annotated data set using the
strengths of the unsupervised methods that learn
from large amounts of unannotated data.
For example, consider utilizing predictions of
the unsupervised Morfessor algorithm (Creutz and
Lagus, 2007) in the CRF model. In order to ac-
complish this, we first learn the Morfessor model
from the unannotated training data, and then ap-
ply the learned model on the word forms in the
annotated training set. Assuming the annotated
training data includes the English word drivers,
the Morfessor algorithm might, for instance, re-
turn a (partially correct) segmentation driv + ers.
We present this segmentation by defining a func-
tion ?(t), which returns 0 or 1, if the position t is
in the middle of a segment or in the beginning of a
segment, respectively, as in
t 1 2 3 4 5 6 7
x
t
d r i v e r s
?(t) 1 0 0 0 1 0 0
Now, given a set of U functions {?
u
(t)}
U
u=1
, we
define variants of the emission features in (2) as
{?
u
(x, t)?
m
(x, t)1(y
t
= y
?
t
) |
?u ? 1..U ,?m ? 1..M ,?y
?
t
? Y} . (5)
By adding the expanded features of form (5), the
CRF model learns to associate the output of the
unsupervised algorithms in relation to the sur-
rounding substring context. Similarly, an ex-
panded transition feature is written as
{?
u
(x, t)1(y
t?1
= y
?
t?1
)1(y
t
= y
?
t
) |
?u ? 1..U ,?y
?
t
, y
?
t?1
? Y} . (6)
After defining the augmented feature set, the
CRF model parameters can be estimated in a stan-
dard manner on the small, annotated training data
set. Subsequent to CRF training, the Morfessor
model is applied on the test instances in order to
allow the feature set augmentation and standard
decoding with the estimated CRF model. We ex-
pect the Morfessor features to specifically improve
85
segmentation of compound words (for example,
brain+storm), which are modeled with high ac-
curacy by the unsupervised Morfessor algorithm
(Creutz and Lagus, 2007), but can not be learned
from the small number of annotated examples
available for the supervised CRF training.
As another example of a means to augment the
feature set, we make use of the fact that the output
of the unsupervised algorithms does not have to be
binary (zeros and ones). To this end, we employ
the classic letter successor variety (LSV) scores
presented originally by (Harris, 1955).
1
The LSV
scores utilize the insight that the predictability of
successive letters should be high within morph
segments, and low at the boundaries. Conse-
quently, a high variety of letters following a prefix
indicates a high probability of a boundary. We use
a variant of the LSV values presented by ??ltekin
(2010), in which we first normalize the scores by
the average score at each position t, and subse-
qently logarithmize the normalized value. While
LSV score tracks predictability given prefixes, the
same idea can be utilized for suffixes, providing
the letter predecessor variety (LPV). Subsequent
to augmenting the feature set using the functions
LSV (t) and LPV (t), the CRF model learns to
associate high successor and predecessor values
(low predictability) to high probability of a seg-
ment boundary. Appealingly, the Harris features
can be obtained in a computationally inexpensive
manner, as they merely require counting statistics
from the unannotated data.
The feature set augmentation approach de-
scribed above is computationally efficient, if the
computational overhead from the unsupervised
methods is small. This is because the CRF param-
eter estimation is still based on the small amount
of labeled examples as described in Section 2.1,
while the number of features incorporated in the
CRF model (equal to the number of parameters)
grows linearly in the number of exploited unsu-
pervised algorithms.
3 Experimental Setup
3.1 Data
We perform the experiments on the Morpho Chal-
lenge 2009/2010 data set (Kurimo et al., 2009; Ku-
1
We also experimented on modifying the output of the
Morfessor algorithm from binary to probabilistic, but these
soft cues provided no consistent advantage over the standard
binary output.
English Finnish Turkish
Train (unann.) 384,903 2,206,719 617,298
Train (ann.) 1,000 1,000 1,000
Devel. 694 835 763
Test 10,000 10,000 10,000
Table 1: Number of word types in the Morpho
Challenge data set.
rimo et al., 2010) consisting of manually prepared
morphological segmentations in English, Finnish
and Turkish. We follow the experiment setup, in-
cluding data partitions and evaluation metrics, de-
scribed by Ruokolainen et al. (2013). Table 1
shows the total number of instances available for
model estimation and testing.
3.2 CRF Feature Extraction and Training
The substring features included in the CRF model
are described in Section 2.1. We include all sub-
strings which occur in the training data. The Mor-
fessor and Harris (successor and predecessor va-
riety) features employed by the semi-supervised
extension are described in Section 2.2. We ex-
perimented on two variants of the Morfessor al-
gorithm, namely, the Morfessor Baseline (Creutz
and Lagus, 2002) and Morfessor Categories-MAP
(Creutz and Lagus, 2005), CatMAP for short. The
Baseline models were trained on word types and
the perplexity thresholds of the CatMAP models
were set equivalently to the reference runs in Mor-
pho Challenge 2010 (English: 450, Finnish: 250,
Turkish: 100); otherwise the default parameters
were used. The Harris features do not require any
hyper-parameters.
The CRF model (supervised and semi-
supervised) is trained using the averaged
perceptron algorithm (Collins, 2002). The num-
ber of passes over the training set made by the
perceptron algorithm, and the maximum length of
substring features are optimized on the held-out
development sets.
The experiments are run on a standard desktop
computer using a Python-based single-threaded
CRF implementation. For Morfessor Baseline, we
use the recently published implementation by Vir-
pioja et al. (2013). For Morfessor CatMAP, we
used the Perl implementation by Creutz and La-
gus (2005).
86
3.3 Reference Methods
We compare our method?s performance with
the fully supervised CRF model and the semi-
supervised Morfessor algorithm (Kohonen et al.,
2010). For semi-supervised Morfessor, we use the
Python implementation by Virpioja et al. (2013).
4 Results
Segmentation accuracies for all languages are pre-
sented in Table 2. The columns titled Train (ann.)
and Train (unann.) denote the number of anno-
tated and unannotated training instances utilized
by the method, respectively. To summarize, the
semi-supervised CRF extension greatly improved
the segmentation accuracy of the purely super-
vised CRFs, and also provided higher accuracies
compared to the semi-supervised Morfessor algo-
rithm
2
.
Appealingly, the semi-supervised CRF exten-
sion already provided consistent improvement
over the supervised CRFs, when utilizing the com-
putationally inexpensive Harris features. Addi-
tional gains were then obtained using the Morfes-
sor features. On all languages, highest accuracies
were obtained using a combination of Harris and
CatMAP features.
Running the CRF parameter estimation (includ-
ing hyper-parameters) consumed typically up to a
few minutes. Computing statistics for the Harris
features also took up roughly a few minutes on
all languages. Learning the unsupervised Mor-
fessor algorithm consumed 3, 47, and 20 min-
utes for English, Finnish, and Turkish, respec-
tively. Meanwhile, CatMAP model estimation
was considerably slower, consuming roughly 10,
50, and 7 hours for English, Finnish and Turkish,
respectively. Training and decoding with semi-
supervised Morfessor took 21, 111, and 47 hours
for English, Finnish and Turkish, respectively.
5 Conclusions
We extended a recent morphological segmenta-
tion approach based on CRFs from purely super-
vised to semi-supervised learning. We accom-
plished this in an efficient manner using feature set
augmentation and available unsupervised segmen-
tation techniques. Experiments on three diverse
2
The improvements over the supervised CRFs and semi-
supervised Morfessor were statistically significant (confi-
dence level 0.95) according to the standard 1-sided Wilcoxon
signed-rank test performed on 10 randomly divided, non-
overlapping subsets of the complete test sets.
Method Train (ann.) Train (unann.) F1
English
CRF 100 0 78.8
S-MORF. 100 384,903 83.7
CRF (Harris) 100 384,903 80.9
CRF (BL+Harris) 100 384,903 82.6
CRF (CM+Harris) 100 384,903 84.4
CRF 1,000 0 85.9
S-MORF. 1,000 384,903 84.3
CRF (Harris) 1,000 384,903 87.6
CRF (BL+Harris) 1,000 384,903 87.9
CRF (CM+Harris) 1,000 384,903 88.4
Finnish
CRF 100 0 65.5
S-MORF. 100 2,206,719 70.4
CRF (Harris) 100 2,206,719 78.9
CRF (BL+Harris) 100 2,206,719 79.3
CRF (CM+Harris) 100 2,206,719 82.0
CRF 1,000 0 83.8
S-MORF. 1,000 2,206,719 76.4
CRF (Harris) 1,000 2,206,719 88.3
CRF (BL+Harris) 1,000 2,206,719 88.9
CRF (CM+Harris) 1,000 2,206,719 89.4
Turkish
CRF 100 0 77.7
S-MORF. 100 617,298 78.2
CRF (Harris) 100 617,298 82.6
CRF (BL+Harris) 100 617,298 84.9
CRF (CM+Harris) 100 617,298 85.5
CRF 1,000 0 88.6
S-MORF. 1,000 617,298 87.0
CRF (Harris) 1,000 617,298 90.1
CRF (BL+Harris) 1,000 617,298 91.7
CRF (CM+Harris) 1,000 617,298 91.8
Table 2: Results on test data. CRF (BL+Harris)
denotes semi-supervised CRF extension using
Morfessor Baseline and Harris features, while
CRF (CM+Harris) denotes CRF extension em-
ploying Morfessor CatMAP and Harris features.
languages showed that this straightforward semi-
supervised extension greatly improves the seg-
mentation accuracy of the supervised CRFs, while
being computationally efficient. The extension
also outperformed the semi-supervised Morfessor
algorithm on all data set sizes and languages.
Acknowledgements
This work was financially supported by Langnet
(Finnish doctoral programme in language studies)
and the Academy of Finland under the Finnish
Centre of Excellence Program 2012?2017 (grant
no. 251170), project Multimodally grounded lan-
guage technology (no. 254104), and LASTU Pro-
gramme (nos. 256887 and 259934).
87
References
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing (EMNLP 2002), vol-
ume 10, pages 1?8. Association for Computational
Linguistics.
?agr? ??ltekin. 2010. Improving successor variety
for morphological segmentation. In Proceedings of
the 20th Meeting of Computational Linguistics in the
Netherlands.
Mathias Creutz and Krista Lagus. 2002. Unsupervised
discovery of morphemes. In Mike Maxwell, editor,
Proceedings of the ACL-02 Workshop on Morpho-
logical and Phonological Learning, pages 21?30,
Philadelphia, PA, USA, July. Association for Com-
putational Linguistics.
Mathias Creutz and Krista Lagus. 2005. Inducing the
morphological lexicon of a natural language from
unannotated text. In Timo Honkela, Ville K?n?nen,
Matti P?ll?, and Olli Simula, editors, Proceedings of
AKRR?05, International and Interdisciplinary Con-
ference on Adaptive Knowledge Representation and
Reasoning, pages 106?113, Espoo, Finland, June.
Helsinki University of Technology, Laboratory of
Computer and Information Science.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing, 4(1):3:1?3:34, January.
Mathias Creutz, Teemu Hirsim?ki, Mikko Kurimo,
Antti Puurula, Janne Pylkk?nen, Vesa Siivola, Matti
Varjokallio, Ebru Arisoy, Murat Sara?lar, and An-
dreas Stolcke. 2007. Morph-based speech recog-
nition and modeling of out-of-vocabulary words
across languages. ACM Transactions on Speech and
Language Processing, 5(1):3:1?3:29, December.
Zellig Harris. 1955. From phoneme to morpheme.
Language, 31(2):190?222.
Luheng He, Jennifer Gillenwater, and Ben Taskar.
2013. Graph-based posterior regularization for
semi-supervised structured prediction. In Proceed-
ings of the Seventeenth Conference on Computa-
tional Natural Language Learning, pages 38?46,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
Teemu Hirsim?ki, Mathias Creutz, Vesa Siivola, Mikko
Kurimo, Sami Virpioja, and Janne Pylkk?nen.
2006. Unlimited vocabulary speech recognition
with morph language models applied to Finnish.
Computer Speech and Language, 20(4):515?541,
October.
Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell
Greiner, and Dale Schuurmans. 2006. Semi-
supervised conditional random fields for improved
sequence segmentation and labeling. In Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics,
pages 209?216. Association for Computational Lin-
guistics.
Oskar Kohonen, Sami Virpioja, and Krista Lagus.
2010. Semi-supervised learning of concatenative
morphology. In Proceedings of the 11th Meeting of
the ACL Special Interest Group on Computational
Morphology and Phonology, pages 78?86, Uppsala,
Sweden, July. Association for Computational Lin-
guistics.
Mikko Kurimo, Sami Virpioja, Ville Turunen,
Graeme W. Blackwood, and William Byrne. 2009.
Overview and results of Morpho Challenge 2009. In
Working Notes for the CLEF 2009 Workshop, Corfu,
Greece, September.
Mikko Kurimo, Sami Virpioja, and Ville Turunen.
2010. Overview and results of Morpho Chal-
lenge 2010. In Proceedings of the Morpho Chal-
lenge 2010 Workshop, pages 7?24, Espoo, Finland,
September. Aalto University School of Science and
Technology, Department of Information and Com-
puter Science. Technical Report TKK-ICS-R37.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Carla E. Brodley and Andrea Po-
horeckyj Danyluk, editors, Proceedings of the Eigh-
teenth International Conference on Machine Learn-
ing, pages 282?289, Williamstown, MA, USA. Mor-
gan Kaufmann.
Minh-Thang Luong, Richard Socher, and Christo-
pher D Manning. 2013. Better word representa-
tions with recursive neural networks for morphol-
ogy. In Proceedings of the Seventeenth Confer-
ence on Computational Natural Language Learning
(CoNLL), pages 29?37. Association for Computa-
tional Linguistics, August.
Gideon Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learn-
ing of conditional random fields. In Proceedings
of ACL-08: HLT, pages 870?878. Association for
Computational Linguistics.
Hoifung Poon, Colin Cherry, and Kristina Toutanova.
2009. Unsupervised morphological segmentation
with log-linear models. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 209?217.
Association for Computational Linguistics.
Teemu Ruokolainen, Oskar Kohonen, Sami Virpioja,
and Mikko Kurimo. 2013. Supervised morpholog-
ical segmentation in a low-resource learning setting
using conditional random fields. In Proceedings of
88
the Seventeenth Conference on Computational Nat-
ural Language Learning (CoNLL), pages 29?37. As-
sociation for Computational Linguistics, August.
Weiwei Sun and Jia Xu. 2011. Enhancing Chinese
word segmentation using unlabeled data. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 970?979. As-
sociation for Computational Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 384?394. Association for
Computational Linguistics.
Ville Turunen and Mikko Kurimo. 2011. Speech re-
trieval from unsegmented Finnish audio using statis-
tical morpheme-like units for segmentation, recog-
nition, and retrieval. ACM Transactions on Speech
and Language Processing, 8(1):1:1?1:25, October.
Sami Virpioja, Peter Smit, Stig-Arne Gr?nroos, and
Mikko Kurimo. 2013. Morfessor 2.0: Python im-
plementation and extensions for Morfessor Baseline.
Report 25/2013 in Aalto University publication se-
ries SCIENCE + TECHNOLOGY, Department of
Signal Processing and Acoustics, Aalto University.
Yiou Wang, Yoshimasa Tsuruoka Jun?ichi Kazama,
Yoshimasa Tsuruoka, Wenliang Chen, Yujie Zhang,
and Kentaro Torisawa. 2011. Improving Chinese
word segmentation and POS tagging with semi-
supervised methods using large auto-analyzed data.
In IJCNLP, pages 309?317.
89
Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 78?86,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Semi-supervised learning of concatenative morphology
Oskar Kohonen and Sami Virpioja and Krista Lagus
Aalto University School of Science and Technology
Adaptive Informatics Research Centre
P.O. Box 15400, FI-00076 AALTO, Finland
{oskar.kohonen,sami.virpioja,krista.lagus}@tkk.fi
Abstract
We consider morphology learning in a
semi-supervised setting, where a small
set of linguistic gold standard analyses is
available. We extend Morfessor Base-
line, which is a method for unsupervised
morphological segmentation, to this task.
We show that known linguistic segmenta-
tions can be exploited by adding them into
the data likelihood function and optimiz-
ing separate weights for unlabeled and la-
beled data. Experiments on English and
Finnish are presented with varying amount
of labeled data. Results of the linguis-
tic evaluation of Morpho Challenge im-
prove rapidly already with small amounts
of labeled data, surpassing the state-of-
the-art unsupervised methods at 1000 la-
beled words for English and at 100 labeled
words for Finnish.
1 Introduction
Morphological analysis is required in many natu-
ral language processing problems. Especially, in
agglutinative and compounding languages, where
each word form consists of a combination of stems
and affixes, the number of unique word forms in
a corpus is very large. This leads to problems in
word-based statistical language modeling: Even
with a large training corpus, many of the words en-
countered when applying the model did not occur
in the training corpus, and thus there is no infor-
mation available on how to process them. Using
morphological units, such as stems and affixes, in-
stead of complete word forms alleviates this prob-
lem. Unfortunately, for many languages morpho-
logical analysis tools either do not exist or they
are not freely available. In many cases, the prob-
lems of availability also apply to morphologically
annotated corpora, making supervised learning in-
feasible.
In consequence, there has been a need for ap-
proaches for morphological processing that would
require little language-dependent resources. Due
to this need, as well as the general interest in
language acquisition and unsupervised language
learning, the research on unsupervised learning
of morphology has been active during the past
ten years. Especially, methods that perform mor-
phological segmentation have been studied exten-
sively (Goldsmith, 2001; Creutz and Lagus, 2002;
Monson et al, 2004; Bernhard, 2006; Dasgupta
and Ng, 2007; Snyder and Barzilay, 2008b; Poon
et al, 2009). These methods have shown to pro-
duce results that improve performance in several
applications, such as speech recognition and in-
formation retrieval (Creutz et al, 2007; Kurimo et
al., 2008).
While unsupervised methods often work quite
well across different languages, it is difficult to
avoid biases toward certain kinds of languages and
analyses. For example, in isolating languages, the
average amount of morphemes per word is low,
whereas in synthetic languages the amount may be
very high. Also, different applications may need
a particular bias, for example, not analyzing fre-
quent compound words as consisting of smaller
parts could be beneficial in information retrieval.
In many cases, even a small amount of labeled data
can be used to adapt a method to a particular lan-
guage and task. Methodologically, this is referred
to as semi-supervised learning.
In semi-supervised learning, the learning sys-
tem has access to both labeled and unlabeled data.
Typically, the labeled data set is too small for su-
pervised methods to be effective, but there is a
large amount of unlabeled data available. There
are many different approaches to this class of
problems, as presented by Zhu (2005). One ap-
proach is to use generative models, which spec-
ify a join distribution over all variables in the
model. They can be utilized both in unsupervised
78
and supervised learning. In contrast, discrimina-
tive models only specify the conditional distribu-
tion between input data and labels, and therefore
require labeled data. Both, however, can be ex-
tended to the semi-supervised case. For generative
models, it is, in principle, very easy to use both la-
beled and unlabeled data. For unsupervised learn-
ing one can consider the labels as missing data and
estimate their values using the Expectation Maxi-
mization (EM) algorithm (Dempster et al, 1977).
In the semi-supervised case, some labels are avail-
able, and the rest are considered missing and esti-
mated with EM.
In this paper, we extend the Morfessor Base-
line method for the semi-supervised case. Morfes-
sor (Creutz and Lagus, 2002; Creutz and Lagus,
2005; Creutz and Lagus, 2007, etc.) is one of the
well-established methods for morphological seg-
mentation. It applies a simple generative model.
The basic idea, inspired by the Minimum Descrip-
tion Length principle (Rissanen, 1989), is to en-
code the words in the training data with a lexicon
of morphs, that are segments of the words. The
number of bits needed to encode both the morph
lexicon and the data using the lexicon should be
minimized. Morfessor does not limit the num-
ber of morphemes per word form, making it suit-
able for modeling a large variety of agglutinative
languages irrespective of them being more isolat-
ing or synthetic. We show that the model can be
trained in a similar fashion in the semi-supervised
case as in the unsupervised case. However, with
a large set of unlabeled data, the effect of the su-
pervision on the results tends to be small. Thus,
we add a discriminative weighting scheme, where
a small set of word forms with gold standard ana-
lyzes are used for tuning the respective weights of
the labeled and unlabeled data.
The paper is organized as follows: First, we
discuss related work on semi-supervised learning.
Then we describe the Morfessor Baseline model
and the unsupervised algorithm, followed by our
semi-supervised extension. Finally, we present ex-
perimental results for English and Finnish using
the Morpho Challenge data sets (Kurimo et al,
2009).
1.1 Related work
There is surprisingly little work that consider im-
proving the unsupervised models of morphology
with small amounts of annotated data. In the
related tasks that deal with sequential labeling
(word segmentation, POS tagging, shallow pars-
ing, named-entity recognition), semi-supervised
learning is more common.
Snyder and Barzilay (2008a; 2008b) consider
learning morphological segmentation with non-
parametric Bayesian model from multilingual
data. For multilingual settings, they extract 6 139
parallel short phrases from the Hebrew, Arabic,
Aramaic and English bible. Using the aligned
phrase pairs, the model can learn the segmen-
tations for two languages at the same time. In
one of the papers (2008a), they consider also
semi-supervised scenarios, where annotated data
is available either in only one language or both of
the languages. However, the amount of annotated
data is fixed to the half of the full data. This differs
from our experimental setting, where the amount
of unlabeled data is very large and the amount of
labeled data relatively small.
Poon et al (2009) apply a log-linear, undi-
rected generative model for learning the morphol-
ogy of Arabic and Hebrew. They report results
for the same small data set as Snyder and Barzilay
(2008a) in both unsupervised and semi-supervised
settings. For the latter, they use somewhat smaller
proportions of annotated data, varying from 25%
to 100% of the total data, but the amount of unla-
beled data is still very small. Results are reported
also for a larger 120 000 word Arabic data set, but
only for unsupervised learning.
A problem similar to morphological segmen-
tation is word segmentation for the languages
where orthography does not specify word bound-
aries. However, the amount of labeled data is
usually large, and unlabeled data is just an addi-
tional source of information. Li and McCallum
(2005) apply a semi-supervised approach to Chi-
nese word segmentation where unlabeled data is
utilized for forming word clusters, which are then
used as features for a supervised classifier. Xu
et al (2008) adapt a Chinese word segmentation
specifically to a machine translation task, by using
the indirect supervision from a parallel corpus.
2 Method
We present an extension of the Morfessor Baseline
method to the semi-supervised setting. Morfes-
sor Baseline is based on a generative probabilis-
tic model. It is a method for modeling concatena-
tive morphology, where the morphs?i.e., the sur-
79
face forms of morphemes?of a word are its non-
overlapping segments. The model parameters ?
encode a morph lexicon, which includes the prop-
erties of the morphs, such as their string represen-
tations. Each morph m in the lexicon has a proba-
bility of occurring in a word, P (M = m |?).1 The
probabilities are assumed to be independent. The
model uses a prior P (?), derived using the Min-
imum Description Length (MDL) principle, that
controls the complexity of the model. Intuitively,
the prior assigns higher probability to models that
store fewer morphs, where a morph is considered
stored if P (M = m |?) > 0. During model learn-
ing, ? is optimized to maximize the posterior prob-
ability:
?
MAP
= argmax
?
P (?|D
W
)
= argmax
?
{
P (?)P (D
W
|?)
}
, (1)
where D
W
includes the words in the training
data. In this section, we first consider sepa-
rately the likelihood P (D
W
|?) and the prior P (?)
used in Morfessor Baseline. Then we describe
the algorithms, first unsupervised and then semi-
supervised, for finding optimal model parameters.
Last, we shortly discuss the algorithm for seg-
menting new words after the model training.
2.1 Likelihood
The latent variable of the model, Z =
(Z
1
, . . . , Z
|D
W
|
), contains the analyses of the
words in the training data D
W
. An instance of
a single analysis for the j:th word is a sequence of
morphs, z
j
= (m
j1
, . . . ,m
j|z
j
|
). During training,
each word w
j
is assumed to have only one possible
analysis. Thus, instead of using the joint distribu-
tion P (D
W
,Z |?), we need to use the likelihood
function only conditioned on the analyses of the
observed words, P (D
W
|Z,?). The conditional
likelihood is
P (D
W
|Z = z,?)
=
|D
W
|
?
j=1
P (W = w
j
|Z = z,?)
=
|D
W
|
?
j=1
|z
j
|
?
i=1
P (M = m
ji
|?), (2)
where m
ij
is the i:th morph in word w
j
.
1We denote variables with uppercase letters and their in-
stances with lowercase letters.
2.2 Priors
Morfessor applies Maximum A Posteriori (MAP)
estimation, so priors for the model parameters
need to be defined. The parameters ? of the model
are:
? Morph type count, or the size of the morph
lexicon, ? ? Z
+
? Morph token count, or the number of morphs
tokens in the observed data, ? ? Z
+
? Morph strings (?
1
, . . . , ?
?
), ?
i
? ?
?
? Morph counts (?
1
, . . . , ?
?
), ?
i
? {1, . . . , ?},
?
i
?
i
= ?. Normalized with ?, these give
the probabilities of the morphs.
MDL-inspired and non-informative priors have
been preferred. When using such priors, morph
type count and morph token counts can be ne-
glected when optimizing the model. The morph
string prior is based on length distribution P (L)
and distribution P (C) of characters over the char-
acter set ?, both assumed to be known:
P (?
i
) = P (L = |?
i
|)
|?
i
|
?
j=1
P (C = ?
ij
) (3)
We use the implicit length prior (Creutz and La-
gus, 2005), which is obtained by removing P (L)
and using end-of-word mark as an additional char-
acter in P (C). For morph counts, the non-
informative prior
P (?
1
, . . . , ?
?
) = 1/
(
? ? 1
?? 1
)
(4)
gives equal probability to each possible combina-
tion of the counts when ? and ? are known, as
there are
(
??1
??1
)
possible ways to choose ? positive
integers that sum up to ?.
2.3 Unsupervised learning
In principle, unsupervised learning can be per-
formed by looking for the MAP estimate with the
EM-algorithm. In the case of Morfessor Baseline,
this is problematic, because the prior only assigns
higher probability to lexicons where fewer morphs
have nonzero probabilities. The EM-algorithm has
the property that it will not assign a zero probabil-
ity to any morph, that has a nonzero likelihood in
the previous step, and this will hold for all morphs
80
that initially have a nonzero probability. In con-
sequence, Morfessor Baseline instead uses a local
search algorithm, which will assign zero probabil-
ity to a large part of the potential morphs. This
is memory-efficient, since only the morphs with
nonzero probabilities need to be stored in mem-
ory. The training algorithm of Morfessor Base-
line, described by Creutz and Lagus (2005), tries
to minimize the cost function
L(?, z,D
W
) = ? lnP (?)? lnP (D
W
| z,?)
(5)
by testing local changes to z, modifying the pa-
rameters according to each change, and selecting
the best one. More specifically, one word is pro-
cessed at a time, and the segmentation that min-
imizes the cost function with the optimal model
parameters is selected:
z
(t+1)
j
= argmin
z
j
{
min
?
L(?, z
(t)
,D
W
)
}
. (6)
Next, the parameters are updated:
?
(t+1)
= argmin
?
{
L(?, z
(t+1)
,D
W
)
}
. (7)
As neither of the steps can increase the cost func-
tion, this will converge to a local optimum. The
initial parameters are obtained by adding all the
words into the morph lexicon. Due to the context
independence of the morphs within a word, the op-
timal analysis for a segment does not depend on
in which context the segment appears. Thus, it is
possible to encode z as a binary tree-like graph,
where the words are the top nodes and morphs the
leaf nodes. For each word, every possible split into
two morphs is tested in addition to no split. If the
word is split, the same test is applied recursively
to its parts. See, e.g., Creutz and Lagus (2005) for
more details and pseudo-code.
2.4 Semi-supervised learning
A straightforward way to do semi-supervised
learning is to fix the analyses z for the labeled ex-
amples. Early experiments indicated that this has
little effect on the results. The Morfessor Baseline
model only contains local parameters for morphs,
and relies on the bias given by its prior to guide
the amount of segmentation. Therefore, it may not
be well suited for semi-supervised learning. The
labeled data affects only the morphs that are found
in the labeled data, and even their analyses can be
overwhelmed by a large amount of unsupervised
data and the bias of the prior.
We suggest a fairly simple solution to this by
introducing extra parameters that guide the more
general behavior of the model. The amount of
segmentation is mostly affected by the balance
between the prior and the model. The Morfes-
sor Baseline model has been developed to ensure
this balance is sensible. However, the labeled
data gives a strong source of information regarding
the amount of segmentation preferred by the gold
standard. We can utilize this information by intro-
ducing the weight ? on the likelihood. To address
the problem of labeled data being overwhelmed by
the large amount of unlabeled data we introduce a
second weight ? on the likelihood for the labeled
data. These weights are optimized on a separate
held-out set. Thus, instead of optimizing the MAP
estimate, we minimize the following function:
L(?, z,D
W
,D
W 7?A
) =
? lnP (?)
? ?? lnP (D
W
| z,?)
? ? ? lnP (D
W 7?A
| z,?) (8)
The labeled training set D
W 7?A
may include al-
ternative analyses for some of the words. Let
A(w
j
) = {a
j1
, . . . , a
jk
} be the set of known anal-
yses for word w
j
. Assuming the training samples
are independent, and giving equal weight for each
analysis, the likelihood of the labeled data would
be
P (D
W 7?A
|?)
=
|D
W 7?A
|
?
j=1
?
a
jk
?A(w
j
)
|a
jk
|
?
i=1
P (M = m
jki
|?). (9)
However, when the analyses of the words are
fixed, the product over alternative analyses in A
is problematic, because the model cannot select
several of them at the same time. A sum over
A(w
j
):s would avoid this problem, but then the
logarithm of the likelihood function becomes non-
trivial (i.e., logarithm of sum of products) and too
slow to calculate during the training. Instead, we
use the hidden variable Z to select only one anal-
ysis also for the labeled samples, but now with the
restriction that Z
j
? A(w
j
). The likelihood func-
tion for D
W 7?A
is then equivalent to Equation 2.
Because the recursive algorithm search assumes
that a string is segmented in the same way irre-
spective of its context, the labeled data can still
81
get zero probabilities. In practice, zero probabil-
ities in the labeled data likelihood are treated as
very large, but not infinite, costs.
2.5 Segmenting new words
After training the model, a Viterbi-like algorithm
can be applied to find the optimal segmentation
of each word. As proposed by Virpioja and Ko-
honen (2009), also new morph types can be al-
lowed by utilizing an approximate cost of adding
them to the lexicon. As this enables reasonable re-
sults also when the training data is small, we use a
similar technique. The cost is calculated from the
decrease in the probabilities given in Equations 3
and 4 when a new morph is assumed to be in the
lexicon.
3 Experiments
In the experiments, we compare six different vari-
ants of the Morfessor Baseline algorithm:
? Unsupervised: The classic, unsupervised
Morfessor baseline.
? Unsupervised + weighting: A held-out set
is used for adjusting the weight of the likeli-
hood ?. When ? = 1 the method is equiva-
lent to the unsupervised baseline. The main
effect of adjusting ? is to control how many
segments per word the algorithm prefers.
Higher ? leads to fewer and lower ? to more
segments per word.
? Supervised: The semi-supervised method
trained with only the labeled data.
? Supervised + weighting: As above, but the
weight of the likelihood ? is optimized on
the held-out set. The weight can only af-
fect which segmentations are selected from
the possible alternative segmentations in the
labeled data.
? Semi-supervised: The semi-supervised
method trained with both labeled and
unlabeled data.
? Semi-supervised + weighting: As above,
but the parameters ? and ? are optimized us-
ing the the held-out set.
All variations are evaluated using the linguistic
gold standard evaluation of Morpho Challenge
2009. For supervised and semi-supervised meth-
ods, the amount of labeled data is varied be-
tween 100 and 10 000 words, whereas the held-
out set has 500 gold standard analyzes. To obtain
precision-recall curves, we calculated weighted
F0.5 and F2 scores in addition to the normal F1
score. The parameters ? and ? were optimized
also for those.
3.1 Data and evaluation
We used the English and Finnish data sets from
Competition 1 of Morpho Challenge 2009 (Ku-
rimo et al, 2009). Both are extracted from a
three million sentence corpora. For English, there
were 62 185 728 word tokens and 384 903 word
types. For Finnish, there were 36 207 308 word
tokens and 2 206 719 word types. The complexity
of Finnish morphology is indicated by the almost
ten times larger number of word types than in En-
glish, while the number of word tokens is smaller.
We applied also the evaluation method of the
Morpho Challenge 2009: The results of the mor-
phological segmentation were compared to a lin-
guistic gold standard analysis. Precision measures
whether the words that share morphemes in the
proposed analysis have common morphemes also
in the gold standard, and recall measures the op-
posite. The final score to optimize was F-measure,
i.e, the harmonic mean of the precision and re-
call.2 In addition to the unweighted F1 score, we
have applied F2 and F0.5 scores, which give more
weight to recall and precision, respectively.
Finnish gold standards are based on FINT-
WOL morphological analyzer from Lingsoft, Inc.,
that applies the two-level model by Koskenniemi
(1983). English gold standards are from the
CELEX English database. The final test sets are
the same as in Morpho Challenge, based on 10 000
English word forms and 200 000 Finnish word
forms. The test sets are divided into ten parts for
calculating deviations and statistical significances.
For parameter tuning, we applied a small held-out
set containing 500 word forms that were not in-
cluded in the test set.
For supervised and semi-supervised training,
we created sets of five different sizes: 100, 300,
1 000, 3 000, and 10 000. They did not contain any
of the word forms in the final test set, but were
otherwise randomly selected from the words for
2Both the data sets and evaluation scripts are available
from the Morpho Challenge 2009 web page: http://www.
cis.hut.fi/morphochallenge2009/
82
Figure 1: The F-measure for English as a function
of the number of labeled training samples.
which the gold standard analyses were available.
In order to use them for training Morfessor, the
morpheme analyses were converted to segmenta-
tions using the Hutmegs package by Creutz and
Linde?n (2004).
3.2 Results
Figure 1 shows a comparison of the unsupervised,
supervised and semi-supervised Morfessor Base-
line for English. It can be seen that optimiz-
ing the likelihood weight ? alone does not im-
prove much over the unsupervised case, imply-
ing that the Morfessor Baseline is well suited for
English morphology. Without weighting of the
likelihood function, semi-supervised training im-
proves the results somewhat, but it outperforms
weighted unsupervised model only barely. With
weighting, however, semi-supervised training im-
proves the results significantly already for only
100 labeled training samples. For comparison,
in Morpho Challenges (Kurimo et al, 2009), the
unsupervised Morfessor Baseline and Morfessor
Categories-MAP by Creutz and Lagus (2007) have
achieved F-measures of 59.84% and 50.50%, re-
spectively, and the all time best unsupervised re-
sult by a method that does not provide alternative
analyses for words is 66.24%, obtained by Bern-
hard (2008).3 This best unsupervised result is sur-
passed by the semi-supervised algorithm at 1000
labeled samples.
As shown in Figure 1, the supervised method
obtains inconsistent scores for English with the
3Better results (68.71%) have been achieved by Monson
et al (2008), but as they were obtained by combining of
two systems as alternative analyses, the comparison is not as
meaningful.
Figure 2: The F-measure for Finnish as a function
of the number of labeled training samples. The
semi-supervised and unsupervised lines overlap.
smallest training data sizes. The supervised al-
gorithm only knows the morphs in the training
set, and therefore is crucially dependent on the
Viterbi segmentation algorithm for analyzing new
data. Thus, overfitting to some small data sets is
not surprising. At 10 000 labeled training samples
it clearly outperforms the unsupervised algorithm.
The improvement obtained from tuning the weight
? in the supervised case is small.
Figure 2 shows the corresponding results for
Finnish. The optimization of the likelihood weight
gives a large improvement to the F-measure al-
ready in the unsupervised case. This is mainly be-
cause the standard unsupervised Morfessor Base-
line method does not, on average, segment words
into as many segments as would be appropriate for
Finnish. Without weighting, the semi-supervised
method does not improve over the unsupervised
one: The unlabeled training data is so much larger
that the labeled data has no real effect.
For Finnish, the unsupervised Morfessor Base-
line and Categories-MAP obtain F-measures of
26.75% and 44.61%, respectively (Kurimo et al,
2009). The all time best for an unsupervised
method is 52.45% by Bernhard (2008). With op-
timized likelihood weights, the semi-supervised
Morfessor Baseline achieves higher F-measures
with only 100 labeled training samples. Fur-
thermore, the largest improvement for the semi-
supervised method is achieved already from 1000
labeled training samples. Unlike English, the su-
pervised method is quite a lot worse than the un-
supervised one for small training data. This is
natural because of the more complex morphology
83
Figure 3: Precision-recall graph for English with
varying amount of labeled training data. Parame-
ters ? and ? have been optimized for three differ-
ent measures: F0.5, F1 and F2 on the held-out set.
Precision and recall values are from the final test
set, error bars indicate one standard deviation.
in Finnish; good results are not achieved just by
knowing the few most common suffixes.
Figures 3 and 4 show precision-recall graphs
of the performance of the semi-supervised method
for English and Finnish. The parameters ? and ?
have been optimized for three differently weighted
F-measures (F0.5, F1, and F2) on the held-out set.
The weight tells how much recall is emphasized;
F1 is the symmetric F-measure that emphasizes
precision and recall alike. The graphs show that
the more there are labeled training data, the more
constrained the model parameters are: With many
labeled examples, the model cannot be forced to
achieve high precision or recall only. The phe-
nomenon is more evident in the Finnish data (Fig-
ure 3), where the same amount of words contains
more information (morphemes) than in the En-
glish data. Table 1 shows the F0.5, F1 and F2
measures numerically.
Table 2 shows the values for the F1-optimal
weights ? and ? that were chosen for different
amounts of labeled data using the held-out set. As
even the largest labeled sets are much smaller than
the unlabeled training set, it is natural that ? ? ?.
The small optimal ? for Finnish explains why the
difference between unsupervised unweighted and
weighted versions in Figure 2 was so large. Gener-
ally, the more there is labeled data, the smaller ? is
needed. A possible increase in overall likelihood
cost is compensated by a smaller ?. Finnish with
100 labeled words is an exception; probably a very
Figure 4: Precision-recall graph for Finnish with
varying amount of labeled training data. Param-
eters ? and ? have been optimized for three dif-
ferent measures: F0.5, F1 and F2 on the held-out
set. Precision and recall values are from the final
test set, error bars indicate one standard deviation,
which here is very small.
high ? would end in overlearning of the small set
words at the cost of overall performance.
4 Discussion
The method developed in this paper is a straight-
forward extension of Morfessor Baseline. In the
semi-supervised setting, it should be possible to
develop a generative model that would not require
any discriminative reweighting, but could learn,
e.g., the amount of segmentation from the labeled
data. Moreover, it would be possible to learn the
morpheme labels instead of just the segmentation
into morphs, either within the current model or as
a separate step after the segmentation. We made
initial experiment with a trivial context-free label-
ing: A mapping between the segments and mor-
pheme labels was extracted from the labeled train-
ing data. If some label did not have a correspond-
ing segment, it was appended to the previous la-
bel. E.g., if the labels for ?found? are ?find V
+PAST?, ?found? was mapped to both labels. Af-
ter segmentation, each segment in the test data was
replaced by the most common label or label se-
quence whenever such was available. The results
using training data with 1 000 and 10 000 labeled
samples are shown in Table 3. Although preci-
sions decrease somewhat, recalls improve consid-
erably, and significant gains in F-measure are ob-
tained. A more advanced, context-sensitive label-
ing should perform much better.
84
English
labeled data F0.5 F1 F2
0 69.16 61.05 62.70
100 73.23 65.18 68.30
300 72.98 65.63 68.81
1000 71.86 68.29 69.68
3000 74.34 69.13 72.01
10000 76.04 72.85 73.89
Finnish
labeled data F0.5 F1 F2
0 56.81 49.07 53.95
100 58.96 52.66 57.01
300 59.33 54.92 57.16
1000 61.75 56.38 58.24
3000 63.72 58.21 58.90
10000 66.58 60.26 57.24
Table 1: The F0.5, F1 and F2 measures for the
semi-supervised + weighting method.
English Finnish
labeled data ? ? ? ?
0 0.75 - 0.01 -
100 0.75 750 0.01 500
300 1 500 0.005 5000
1000 1 500 0.05 2500
3000 1.75 350 0.1 1000
10000 1.75 175 0.1 500
Table 2: The values for the weights ? and ?
that the semisupervised algorithm chose for differ-
ent amounts of labeled data when optimizing F1-
measure.
The semi-supervised extension could easily be
applied to the other versions and extensions of
Morfessor, such as Morfessor Categories-MAP
(Creutz and Lagus, 2007) and Allomorfessor (Vir-
pioja and Kohonen, 2009). Especially the model-
ing of allomorphy might benefit from even small
amounts of labeled data, because those allomorphs
that are hardest to find (affixes, stems with irregu-
lar orthographic changes) are often more common
than the easy cases, and thus likely to be found
even from a small labeled data set.
Even without labeling, it will be interesting
to see how well the semi-supervised morphology
learning works in applications such as information
retrieval. Compared to unsupervised learning, we
obtained much higher recall for reasonably good
levels of precision, which should be beneficial to
most applications.
Segmented Labeled
English, D = 1000
Precision 69.72% 69.30%
Recall 66.92% 72.21%
F-measure 68.29% 70.72%
English, D = 10 000
Precision 77.35% 77.07%
Recall 68.85% 77.78%
F-measure 72.86% 77.42%
Finnish, D = 1000
Precision 61.03% 58.96%
Recall 52.38% 66.55%
F-measure 56.38% 62.53%
Finnish, D = 10 000
Precision 69.14% 66.90%
Recall 53.40% 74.08%
F-measure 60.26% 70.31%
Table 3: Results of a simple morph labeling after
segmentation with semi-supervised Morfessor.
5 Conclusions
We have evaluated an extension of the Morfessor
Baseline method to semi-supervised morphologi-
cal segmentation. Even with our simple method,
the scores improve far beyond the best unsuper-
vised results. Moreover, already one hundred
known segmentations give significant gain over
the unsupervised method even with the optimized
data likelihood weight.
Acknowledgments
This work was funded by Academy of Finland and
Graduate School of Language Technology in Fin-
land. We thank Mikko Kurimo and Tiina Lindh-
Knuutila for comments on the manuscript, and
Nokia foundation for financial support.
References
Delphine Bernhard. 2006. Unsupervised morpholog-
ical segmentation based on segment predictability
and word segments alignment. In Proceedings of the
PASCAL Challenge Workshop on Unsupervised seg-
mentation of words into morphemes, Venice, Italy.
PASCAL European Network of Excellence.
Delphine Bernhard. 2008. Simple morpheme labelling
in unsupervised morpheme analysis. In Advances in
Multilingual and Multimodal Information Retrieval,
8th Workshop of the CLEF, volume 5152 of Lec-
ture Notes in Computer Science, pages 873?880.
Springer Berlin / Heidelberg.
85
Mathias Creutz and Krista Lagus. 2002. Unsuper-
vised discovery of morphemes. In Proceedings of
the Workshop on Morphological and Phonological
Learning of ACL?02, pages 21?30, Philadelphia,
Pennsylvania, USA.
Mathias Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0. Technical
Report A81, Publications in Computer and Informa-
tion Science, Helsinki University of Technology.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing, 4(1), January.
Mathias Creutz and Krister Linde?n. 2004. Morpheme
segmentation gold standards for Finnish and En-
glish. Technical Report A77, Publications in Com-
puter and Information Science, Helsinki University
of Technology.
Mathias Creutz, Teemu Hirsima?ki, Mikko Kurimo,
Antti Puurula, Janne Pylkko?nen, Vesa Siivola, Matti
Varjokallio, Ebru Arisoy, Murat Sarac?lar, and An-
dreas Stolcke. 2007. Morph-based speech recog-
nition and modeling of out-of-vocabulary words
across languages. ACM Transactions on Speech and
Language Processing, 5(1):1?29.
Sajib Dasgupta and Vincent Ng. 2007. High-
performance, language-independent morphological
segmentation. In the annual conference of the North
American Chapter of the ACL (NAACL-HLT).
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete
data via the em algorithm. Journal of the Royal Sta-
tistical Society, Series B (Methodological), 39(1):1?
38.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27(2):153?189.
Kimmo Koskenniemi. 1983. Two-level morphology: A
general computational model for word-form recog-
nition and production. Ph.D. thesis, University of
Helsinki.
Mikko Kurimo, Mathias Creutz, and Matti Varjokallio.
2008. Morpho Challenge evaluation using a linguis-
tic Gold Standard. In Advances in Multilingual and
MultiModal Information Retrieval, 8th Workshop of
the Cross-Language Evaluation Forum, CLEF 2007,
Budapest, Hungary, September 19-21, 2007, Re-
vised Selected Papers, Lecture Notes in Computer
Science , Vol. 5152, pages 864?873. Springer.
Mikko Kurimo, Sami Virpioja, Ville T. Turunen,
Graeme W. Blackwood, and William Byrne. 2009.
Overview and results of Morpho Challenge 2009. In
Working Notes for the CLEF 2009 Workshop, Corfu,
Greece, September.
Wei Li and Andrew McCallum. 2005. Semi-
supervised sequence modeling with syntactic topic
models. In AAAI?05: Proceedings of the 20th na-
tional conference on Artificial intelligence, pages
813?818. AAAI Press.
Christian Monson, Alon Lavie, Jaime Carbonell, and
Lori Levin. 2004. Unsupervised induction of natu-
ral language morphology inflection classes. In Pro-
ceedings of the Workshop of the ACL Special Interest
Group in Computational Phonology (SIGPHON).
Christian Monson, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. ParaMor: Finding paradigms
across morphology. In Advances in Multilingual
and MultiModal Information Retrieval, 8th Work-
shop of the Cross-Language Evaluation Forum,
CLEF 2007, Budapest, Hungary, September 19-21,
2007, Revised Selected Papers, Lecture Notes in
Computer Science , Vol. 5152. Springer.
Hoifung Poon, Colin Cherry, and Kristina Toutanova.
2009. Unsupervised morphological segmentation
with log-linear models. In NAACL ?09: Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 209?217. Association for Computational Lin-
guistics.
Jorma Rissanen. 1989. Stochastic Complexity in Sta-
tistical Inquiry, volume 15. World Scientific Series
in Computer Science, Singapore.
Benjamin Snyder and Regina Barzilay. 2008a. Cross-
lingual propagation for morphological analysis. In
AAAI?08: Proceedings of the 23rd national con-
ference on Artificial intelligence, pages 848?854.
AAAI Press.
Benjamin Snyder and Regina Barzilay. 2008b. Un-
supervised multilingual learning for morphological
segmentation. In Proceedings of ACL-08: HLT,
pages 737?745, Columbus, Ohio, June. Association
for Computational Linguistics.
Sami Virpioja and Oskar Kohonen. 2009. Unsuper-
vised morpheme analysis with Allomorfessor. In
Working notes for the CLEF 2009 Workshop, Corfu,
Greece.
Jia Xu, Jianfeng Gao, Kristina Toutanova, and Her-
mann Ney. 2008. Bayesian semi-supervised chinese
word segmentation for statistical machine transla-
tion. In COLING ?08: Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics, pages 1017?1024, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
Xiaojin Zhu. 2005. Semi-supervised Learning with
Graphs. Ph.D. thesis, CMU. Chapter 11, Semi-
supervised learning literature survey (updated online
version).
86
Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 29?37,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Supervised Morphological Segmentation in a Low-Resource Learning
Setting using Conditional Random Fields
Teemu Ruokolainena Oskar Kohonena Sami Virpiojaa Mikko Kurimob
a Department of Information and Computer Science, Aalto University
b Department of Signal Processing and Acoustics, Aalto University
firstname.lastname@aalto.fi
Abstract
We discuss data-driven morphological
segmentation, in which word forms are
segmented into morphs, the surface forms
of morphemes. Our focus is on a low-
resource learning setting, in which only a
small amount of annotated word forms are
available for model training, while unan-
notated word forms are available in abun-
dance. The current state-of-art methods
1) exploit both the annotated and unan-
notated data in a semi-supervised man-
ner, and 2) learn morph lexicons and sub-
sequently uncover segmentations by gen-
erating the most likely morph sequences.
In contrast, we discuss 1) employing only
the annotated data in a supervised man-
ner, while entirely ignoring the unanno-
tated data, and 2) directly learning to pre-
dict morph boundaries given their local
sub-string contexts instead of learning the
morph lexicons. Specifically, we em-
ploy conditional random fields, a popular
discriminative log-linear model for seg-
mentation. We present experiments on
two data sets comprising five diverse lan-
guages. We show that the fully super-
vised boundary prediction approach out-
performs the state-of-art semi-supervised
morph lexicon approaches on all lan-
guages when using the same annotated
data sets.
1 Introduction
Modern natural language processing (NLP) appli-
cations, such as speech recognition, information
retrieval and machine translation, perform their
tasks using statistical language models. For mor-
phologically rich languages, estimation of the lan-
guage models is problematic due to the high num-
ber of compound words and inflected word forms.
A successful means of alleviating this data sparsity
problem is to segment words into meaning-bearing
sub-word units (Hirsim?ki et al, 2006; Creutz et
al., 2007; Turunen and Kurimo, 2011). In lin-
guistics, the smallest meaning-bearing units of a
language are called morphemes and their surface
forms morphs. Thus, morphs are natural targets
for the segmentation.
For most languages, existing resources contain
large amounts of raw unannotated text data, only
small amounts of manually prepared annotated
training data, and no freely available rule-based
morphological analyzers. The focus of our work is
on performing morphological segmentation in this
low-resource scenario. Given this setting, the cur-
rent state-of-art methods approach the problem by
learning morph lexicons from both annotated and
unannotated data using semi-supervised machine
learning techniques (Poon et al, 2009; Kohonen
et al, 2010). Subsequent to model training, the
methods uncover morph boundaries for new word
forms by generating their most likely morph se-
quences according to the morph lexicons.
In contrast to learning morph lexicons (Poon et
al., 2009; Kohonen et al, 2010), we study mor-
phological segmentation by learning to directly
predict morph boundaries based on their local sub-
string contexts. Specifically, we apply the linear-
chain conditional random field model, a popular
discriminative log-linear model for segmentation
presented originally by Lafferty et al (2001). Im-
portantly, we learn the segmentation model from
solely the small annotated data in a supervised
manner, while entirely ignoring the unannotated
data. Despite not using the unannotated data, we
show that by discriminatively learning to predict
the morph boundaries, we are able to outperform
the previous state-of-art.
We present experiments on Arabic and Hebrew
using the data set presented originally by Snyder
and Barzilay (2008), and on English, Finnish and
29
Turkish using the Morpho Challenge 2009/2010
data sets (Kurimo et al, 2009; Kurimo et al,
2010). The results are compared against two state-
of-art techniques, namely the log-linear model-
ing approach presented by Poon et al (2009) and
the semi-supervised Morfessor algorithm (Koho-
nen et al, 2010). We show that when employ-
ing the same small amount of annotated train-
ing data, the CRF-based boundary prediction ap-
proach outperforms these reference methods on
all languages. Additionally, since the CRF model
learns from solely the small annotated data set, its
training is computationally much less demanding
compared to the semi-supervised methods, which
utilize both the annotated and the unannotated data
sets.
The rest of the paper is organized as follows. In
Section 2, we discuss related work in morpholog-
ical segmentation and methodology. In Section 3,
we describe our segmentation method. Our exper-
imental setup is described in Section 4, and the
obtained results are presented in Section 5. In Sec-
tion 6, we discuss the method and the results. Fi-
nally, we present conclusions on the work in Sec-
tion 7.
2 Related work
The CRF model has been widely used in NLP seg-
mentation tasks, such as shallow parsing (Sha and
Pereira, 2003), named entity recognition (McCal-
lum and Li, 2003), and word segmentation (Zhao
et al, 2006). Recently, CRFs were also employed
successfully in morphological segmentation for
Arabic by Green and DeNero (2012) as a com-
ponent of an English to Arabic machine trans-
lation system. While the segmentation method
of Green and DeNero (2012) and ours is very sim-
ilar, our focuses and contributions differ in sev-
eral ways. First, while in our work we consider
the low-resource learning setting, in which a small
annotated data set is available (up to 3,130 word
types), their model is trained on the Arabic Tree-
bank (Maamouri et al, 2004) constituting sev-
eral times larger training set (588,244 word to-
kens). Second, we present empirical comparison
between the CRF approach and two state-of-art
methods (Poon et al, 2009; Kohonen et al, 2010)
on five diverse languages. Third, due to being a
component of a larger system, their presentation
on the method and experiments is rather undersp-
eficied, while here we are able to provide a more
thorough description.
In the experimental section, we compare the
CRF-based segmentation approach with two state-
of-art methods, the log-linear modeling approach
presented by Poon et al (2009) and the semi-
supervised Morfessor algorithm (Kohonen et al,
2010). As stated previously, the CRF-based seg-
mentation approach differs from these methods in
that it learns to predict morph boundaries from
a small amount of annotated data, in contrast to
learning morph lexicons from both annotated and
large amounts of unannotated data.
Lastly, there exists ample work on varying un-
supervised (and semi-supervised) morphological
segmentation methods. A useful review is given
by Hammarstr?m and Borin (2011). The funda-
mental difference between our approach and these
techniques is that our method necessarily requires
manually annotated training data.
3 Methods
In this section, we describe in detail the CRF-
based approach for supervised morphological seg-
mentation.
3.1 Morphological segmentation as a
classification task
We represent the morphological segmentation task
as a structured classification problem by assign-
ing each character to one of four classes, namely
{beginning of a multi-character morph (B), mid-
dle of a multi-character morph (M), end of a multi-
character morph (E), single character morph (S)}.
For example, consider the English word form
drivers
with a corresponding segmentation
driv + er + s .
Using the classification notation, this segmenta-
tion is represented as
START B M M E B E S STOP
<w> d r i v e r s </w>
where we have assumed additional word start
and end markers <w> and </w> with respective
classes START and STOP. As another example,
consider the Finnish word form
autoilla (with cars)
with a corresponding segmentation
auto + i + lla .
Using the classification notation, this segmenta-
tion is represented as
30
START B M M E S B M E STOP
<w> a u t o i l l a </w>
Intuitively, instead of the four class set {B, M,
E, S}, a segmentation could be accomplished us-
ing only a set of two classes {B, M} as in (Green
and DeNero, 2012). However, similarly to Chi-
nese word segmentation (Zhao et al, 2006), our
preliminary experiments suggested that using the
more fine-grained four class set {B, M, E, S} per-
formed slightly better. This result indicates that
morph segments of differerent lengths behave dif-
ferently.
3.2 Linear-chain conditional random fields
We perform the above structured classification us-
ing linear-chain conditional random fields (CRFs),
a discriminative log-linear model for tagging and
segmentation (Lafferty et al, 2001). The central
idea of the linear-chain CRF is to exploit the de-
pendencies between the output variables using a
chain structured undirected graph, also referred to
as a Markov random field, while conditioning the
output globally on the observation.
Formally, the model for input x (characters in a
word) and output y (classes corresponding to char-
acters) is written as
p (y |x;w) ?
T?
t=2
exp
(
w>f(yt?1, yt,x, t)
)
,
(1)
where t indexes the characters, T denotes word
length, w the model parameter vector, and f the
vector-valued feature extracting function.
The purpose of the feature extraction function
f is to capture the co-occurrence behavior of the
tag transitions (yt?1, yt) and a set of features de-
scribing character position t of word form x. The
strength of the CRF model lies in its capability to
utilize arbitrary, non-independent features.
3.3 Feature extraction
The quality of the segmentation depends heavily
on the choice of features defined by the feature
extraction function f . We will next describe and
motivate the feature set used in the experiments.
Our feature set consists of binary indicator func-
tions describing the position t of word x using
all left and right substrings up to a maximum
length ?. For example, consider the problem
of deciding if the letter e in the word drivers
is preceded by a morph boundary. This deci-
sion is now based on the overlapping substrings
to the left and right of this potential bound-
ary position, that is {v, iv, riv, driv, <w>driv} and
{e, er, ers, ers</w>}, respectively. The substrings
to the left and right are considered indepen-
dently. Naturally, if the maximum allowed sub-
string length ? is less than five, the longest sub-
strings are discarded accordingly. In general, the
optimum ? depends on both the amount of avail-
able training data and the language.
In addition to the substring functions, we use a
bias function which returns value 1 independent
of the input x. The bias and substring features are
combined with all the possible tag transitions.
To motivate this choice of feature set, consider
formulating an intuitive segmentation rule for the
English words talked, played and speed with the
correct segmentations talk + ed, play + ed and
speed, respectively. Now, as a right context ed
is generally a strong indicator of a boundary, one
could first formulate a rule
position t is a segment boundary
if its right context is ed.
This rule would indeed correctly segment the
words talked and played, but would incorrectly
segment speed as spe + ed. This error can be re-
solved if the left contexts are utilized as inhibitors
by expanding the above rule as
position t is a segment boundary
if its right context is ed
and the left context is not spe.
Using the feature set defined above, the CRF
model can learn to perform segmentation in this
rule-like manner according to the training data.
For example, using the above example words and
segmentations for training, the CRFs could learn
to assign a high score for a boundary given that
the right context is ed and a high score for a non-
boundary given the left context spe. Subsequent to
training, making segmentation decisions for new
word forms can then be interpreted as voting based
on these scores.
3.4 Parameter estimation
The CRF model parameters w are estimated based
on an annotated training data set. Common train-
ing criteria include the maximum likelihood (Laf-
ferty et al, 2001; Peng et al, 2004; Zhao et al,
2006), averaged structured perceptron (Collins,
2002), and max-margin (Szummer et al, 2008).
In this work, we estimate the parameters using the
perceptron algorithm (Collins, 2002).
31
In perceptron training, the required graph infer-
ence can be efficiently performed using the stan-
dard Viterbi algorithm. Subsequent to training, the
segmentations for test instances are acquired again
using Viterbi search.
Compared to other training criteria, the struc-
tured perceptron has the advantage of employing
only a single hyperparameter, namely the number
of passes over training data, making model esti-
mation fast and straightforward. We optimize the
hyperparameter using a separate development set.
Lastly, we consider the longest substring length ?
a second hyperparameter optimized using the de-
velopment set.
4 Experimental setup
This section describes the data sets, evaluation
metrics, reference methods, and other details con-
cerning the evaluation of the methods.
4.1 Data sets
We evaluate the methods on two different data sets
comprising five languages in total.
S&B data. The first data set we use is the He-
brew Bible parallel corpus introduced by Snyder
and Barzilay (2008). It contains 6,192 parallel
phrases in Hebrew, Arabic, Aramaic, and English
and their frequencies (ranging from 5 to 3517).
The phrases have been extracted using automatic
word alignment. The Hebrew and Arabic phrases
have manually annotated morphological segmen-
tations, and they are used in our experiments. The
phrases are sorted according to frequency, and ev-
ery fifth phrase starting from the first phrase is
placed in the test set, every fifth starting from the
second phrase in the development set (up to 500
phrases), and the rest of the phrases in the train-
ing set. 1 The total numbers of word types in the
sets are shown in Table 1. Finally, the word forms
in the training set are randomly permuted, and the
first 25%, 50%, 75%, and 100% of them are se-
lected as subsets to study the effect of training data
size.
MC data. The second data set is based on the
Morpho Challenge 2010 (Kurimo et al, 2010).
It includes manually prepared morphological seg-
mentations in English, Finnish and Turkish. The
1We are grateful to Dr. Hoifung Poon for providing us
instructions for dividing of the data set.
Arabic Hebrew
Training 3,130 2,770
Development 472 450
Test 1,107 1,040
Table 1: The numbers of word types in S&B data
sets (Snyder and Barzilay, 2008).
English Finnish Turkish
Unannot. 384,903 2,206,719 617,298
Training 1,000 1,000 1,000
Develop. 694 835 763
Test 10?1,000 10?1,000 10?1,000
Table 2: The numbers of word types in the MC
data sets (Kurimo et al, 2009; Kurimo et al,
2010).
additional German corpus does not have segmen-
tation annotation and is therefore excluded. The
annotated data sets include training, development,
and test sets for each language. Following Virpi-
oja et al (2011), the test set results are based on
ten randomly selected 1,000 word sets. Moreover,
we divide the annotated training sets into ten par-
titions with respective sizes of 100, 200, . . . , 1000
words so that each partition is a subset of the all
larger partitions. The data is divided so that the
smallest set had every 10th word of the original
set, the second set every 10th word and the fol-
lowing word, and so forth. For reference methods
that require unannotated data, we use the English,
Finnish and Turkish corpora from Competition 1
of Morpho Challenge 2009 (Kurimo et al, 2009).
Table 2 shows the sizes of the MC data sets.
4.2 Evaluation measures
The word segmentations are evaluated by compar-
ison with linguistic morphs using precision, recall,
and F-measure. The F-measure equals the geo-
metric mean of precision (the percentage of cor-
rectly assigned boundaries with respect to all as-
signed boundaries) and recall (the percentage of
correctly assigned boundaries with respect to the
reference boundaries). While using F-measure is
a standard procedure, the prior work differ at least
in three details: (1) whether precision and recall
are calculated as micro-average over all segmenta-
tion points or as macro-average over all the word
forms, (2) whether the evaluation is based on word
types or word tokens in a corpus, and (3) if the
32
reference segmentations have alternative correct
choices for a single word type, and how to deal
with them.
For the experiments with the S&B data sets,
we follow Poon et al (2009) and apply token-
based micro-averages. For the experiments with
the MC data sets, we follow Virpioja et al (2011)
and use type-based macro-averages. However, dif-
fering from their boundary measure, we take the
best match over the alternative reference analyses
(separately for precision and recall), since none of
the methods considered here provide multiple seg-
mentations per word type. For the models trained
with the full training set, we also report the F-
measures of the boundary evaluation method by
Virpioja et al (2011) in order to compare to the
results reported in the Morpho Challenge website.
4.3 CRF feature extraction and training
The features included in the feature vector in the
CRF model (1) are described in Section 3.3. We
include all substring features which occur in the
training data.
The CRF model is trained using the averaged
perceptron algorithm as described in Section 3.4.
The algorithm initializes the model parameters
with zero vectors. The model performance, mea-
sured using F-measure, is evaluated on the devel-
opment set after each pass over the training set,
and the training is terminated when the perfor-
mance has not improved during last 5 passes. The
maximum length of substrings ? is optimized by
considering ? = 1, 2, 3, . . . , and the search is ter-
minated when the performance has not improved
during last 5 values. Finally, the algorithm returns
the parameters yielding the highest F-measure on
the development set.
For some words, the MC training sets include
several alternative segmentations. We resolve this
ambiguity by using the first given alternative and
discarding the rest. During evaluation, the alter-
native segmentations are taken into account as de-
scribed in Section 4.2.
The experiments are run on a standard desktop
computer using our own single-threaded Python-
based implementation2.
4.4 Reference methods
We compare our method?s performance on Arabic
and Hebrew data with semi-supervised Morfessor
2Available at http://users.ics.aalto.fi/
tpruokol/
(Kohonen et al, 2010) and the results reported by
Poon et al (2009). On Finnish, English and Turk-
ish data, we compare the method only with semi-
supervised Morfessor as we have no implementa-
tion of the model by Poon et al (2009).
We use a recently released Python implemen-
tation of semi-supervised Morfessor3. Semi-
supervised Morfessor was trained separately for
each training set size, always using the full unan-
notated data sets in addition to the annotated sets.
The hyperparameters, the unannotated data weight
? and the annotated data weight ?, were optimized
with a grid search on the development set. For the
S&B data, there are no separate unannotated sets.
When the annotated training set size is varied, the
remaining parts are utilized as unannotated data.
The log-linear model described in (Poon et al,
2009) and the semi-supervised Morfessor algo-
rithm are later referred to as POON-2009 and S-
MORFESSOR for brevity.
5 Results
Method performances for Arabic and Hebrew on
the S&B data are presented in Tables 3 and 4, re-
spectively. The results for the POON-2009 model
are extracted from (Poon et al, 2009). Perfor-
mances for English, Finnish and Turkish on the
MC data set are presented in Tables 5, 6 and 7,
respectively.
On the Arabic and Hebrew data sets, the CRFs
outperform POON-2009 and S-MORFESSOR
substantially on all the considered data set sizes.
On Finnish and Turkish data, the CRFs outper-
form S-MORFESSOR except for the smallest sets
of 100 instances. On English data, the CRFs out-
perform S-MORFESSOR when the training set is
500 instances or larger.
Using our implementation of the CRF model,
obtaining the results for Arabic, Hebrew, English,
Finnish, and Turkish consumed 10, 11, 22, 32,
and 28 minutes, respectively. These CPU times
include model training and hyperparameter opti-
mization. In comparison, S-MORFESSOR train-
ing is considerably slower. For Arabic and He-
brew, the S-MORFESSOR total training times
were 24 and 22 minutes, respectively, and for En-
glish, Finnish, and Turkish 4, 22, and 10 days,
respectively. The higher training times of S-
MORFESSOR are partly because of the larger
3Available at https://github.com/
aalto-speech/morfessor
33
grids in hyperparameter optimization. Further-
more, the S-MORFESSOR training time for each
grid point grows linearly with the size of the
unannotated data set, resulting in particularly slow
training on the MC data sets. All reported times
are total CPU times for single-threaded runs, while
in practice grid searches can be parallelized.
The perceptron algorithm typically converged
after 10 passes over the training set, and never re-
quired more than 40 passes to terminate. Depend-
ing on the size of the training data, the optimized
maximum lengths of substrings varied in ranges
{3,5}, {2,7}, {3,9}, {3,6}, {3,7}, for Arabic, He-
brew, English, Finnish and Turkish, respectively.
Method %Lbl. Prec. Rec. F1
CRF 25 95.5 93.1 94.3
S-MORFESSOR 25 78.7 79.7 79.2
POON-2009 25 84.9 85.5 85.2
CRF 50 96.5 94.6 95.5
S-MORFESSOR 50 87.5 91.5 89.4
POON-2009 50 88.2 86.2 87.5
CRF 75 97.2 96.1 96.6
S-MORFESSOR 75 92.8 83.0 87.6
POON-2009 75 89.6 86.4 87.9
CRF 100 98.1 97.5 97.8
S-MORFESSOR 100 91.4 91.8 91.6
POON-2009 100 91.7 88.5 90.0
Table 3: Results for Arabic on the S&B data
set (Snyder and Barzilay, 2008). The column ti-
tled %Lbl. denotes the percentage of the annotated
data used for training. In addition to the given per-
centages of annotated data, POON-2009 and S-
MORFESSOR utilized the remainder of the data
as an unannotated set.
Finally, Table 8 shows the results of the CRF
and S-MORFESSOR models trained with the full
English, Finnish, and Turkish MC data sets and
evaluated with the boundary evaluation method of
Virpioja et al (2011). That is, these numbers are
directly comparable to the BPR-F column in the
result tables presented at the Morpho Challenge
website4. For each of the three languages, CRF
clearly outperforms all the Morpho Challenge sub-
missions that have provided morphological seg-
mentations.
4http://research.ics.aalto.fi/events/
morphochallenge/
Method %Lbl. Prec. Rec. F1
CRF 25 90.5 90.6 90.6
S-MORFESSOR 25 71.5 85.3 77.8
POON-2009 25 78.7 73.3 75.9
CRF 50 94.0 91.5 92.7
S-MORFESSOR 50 82.1 81.8 81.9
POON-2009 50 82.8 74.6 78.4
CRF 75 94.0 92.7 93.4
S-MORFESSOR 75 84.0 88.1 86.0
POON-2009 75 83.1 77.3 80.1
CRF 100 94.9 94.0 94.5
S-MORFESSOR 100 85.3 91.1 88.1
POON-2009 100 83.0 78.9 80.9
Table 4: Results for Hebrew on the S&B data
set (Snyder and Barzilay, 2008). The column ti-
tled %Lbl. denotes the percentage of the annotated
data used for training. In addition to the given per-
centages of annotated data, POON-2009 and S-
MORFESSOR utilized the remainder of the data
as an unannotated set.
6 Discussion
Intuitively, the CRF-based supervised learning ap-
proach should yield high segmentation accuracy
when there are large amounts of annotated train-
ing data available. However, perhaps surprisingly,
the CRF model yields state-of-art results already
using very small amounts of training data. This
result is meaningful since for most languages it is
infeasible to acquire large amounts of annotated
training data.
The strength of the discriminatively trained
CRF model is that overlapping, non-independent
features can be naturally employed. Importantly,
we showed that simple, language-independent
substring features are sufficient for high perfor-
mance. However, adding new, task- and language-
dependent features is also easy. One might, for ex-
ample, explore features capturing vowel harmony
in Finnish and Turkish.
The CRFs was estimated using the structured
perceptron algorithm (Collins, 2002), which has
the benefit of being computationally efficient and
easy to implement. Other training criteria, such
as maximum likelihood (Lafferty et al, 2001)
or max-margin (Szummer et al, 2008), could
also be employed. Similarly, other classifiers,
such as the Maximum Entropy Markov Models
(MEMMs) (McCallum et al, 2000), are applica-
ble. However, as the amount of information in-
34
Method Train. Prec. Rec. F1
CRF 100 80.2 74.6 77.3
S-MORFESSOR 100 88.1 79.7 83.7
CRF 200 84.7 79.2 81.8
S-MORFESSOR 200 88.1 79.5 83.6
CRF 300 86.7 79.8 83.1
S-MORFESSOR 300 88.4 80.6 84.3
CRF 400 86.5 80.6 83.4
S-MORFESSOR 400 84.6 83.6 84.1
CRF 500 88.6 80.7 84.5
S-MORFESSOR 500 86.3 82.7 84.4
CRF 600 88.1 82.6 85.3
S-MORFESSOR 600 86.7 82.5 84.5
CRF 700 87.9 83.4 85.6
S-MORFESSOR 700 86.0 82.9 84.4
CRF 800 89.1 83.2 86.1
S-MORFESSOR 800 87.1 82.5 84.8
CRF 900 89.0 82.9 85.8
S-MORFESSOR 900 86.4 82.6 84.5
CRF 1000 89.8 83.5 86.5
S-MORFESSOR 1000 88.8 80.1 84.3
Table 5: Results for English on the Morpho Chal-
lenge 2009/2010 data set (Kurimo et al, 2009; Ku-
rimo et al, 2010). The column titled Train. de-
notes the number of annotated training instances.
In addition to the annotated data, S-MORFESSOR
utilized an unannotated set of 384,903 word types.
corporated in the model would be unchanged, the
choice of parameter estimation criterion and clas-
sifier is unlikely to have a dramatic effect on the
method performance.
In CRF training, we focused on the supervised
learning scenario, in which no unannotated data is
exploited in addition to the annotated training sets.
However, there does exist ample work on extend-
ing CRF training to the semi-supervised setting
(for example, see Mann and McCallum (2008)
and the references therein). Nevertheless, our re-
sults strongly suggest that it is crucial to use the
few available annotated training instances as ef-
ficiently as possible before turning model train-
ing burdensome by incorporating large amounts of
unannotated data.
Following previous work (Poon et al, 2009;
Kohonen et al, 2010; Virpioja et al, 2011), we
applied the boundary F-score evaluation measure,
while Green and DeNero (2012) reported charac-
ter accuracy. We consider the boundary F-score a
better measure than accuracy, since the boundary-
Method Train. Prec. Rec. F1
CRF 100 71.4 66.0 68.6
S-MORFESSOR 100 69.8 71.0 70.4
CRF 200 76.4 71.3 73.8
S-MORFESSOR 200 75.5 68.6 71.9
CRF 300 80.4 73.9 77.0
S-MORFESSOR 300 73.1 71.8 72.5
CRF 400 81.0 76.6 78.7
S-MORFESSOR 400 73.3 74.3 73.8
CRF 500 82.9 77.9 80.3
S-MORFESSOR 500 73.5 75.1 74.3
CRF 600 82.6 80.6 81.6
S-MORFESSOR 600 76.1 73.7 74.9
CRF 700 84.3 81.4 82.8
S-MORFESSOR 700 75.0 76.6 75.8
CRF 800 85.1 83.4 84.2
S-MORFESSOR 800 74.1 78.2 76.1
CRF 900 85.2 83.8 84.5
S-MORFESSOR 900 74.2 78.5 76.3
CRF 1000 86.0 84.7 85.3
S-MORFESSOR 1000 74.2 78.8 76.4
Table 6: Results for Finnish on the Morpho Chal-
lenge 2009/2010 data set (Kurimo et al, 2009; Ku-
rimo et al, 2010). The column titled Train. de-
notes the number of annotated training instances.
In addition to the annotated data, S-MORFESSOR
utilized an unannotated set of 2,206,719 word
types.
tag distribution is strongly skewed towards non-
boundaries. Nevertheless, for completeness, we
computed the character accuracy for our Arabic
data set, obtaining the accuracy 99.1%, which is
close to their reported accuracy of 98.6%. How-
ever, these values are not directly comparable due
to our use of the Bible corpus by Snyder and Barzi-
lay (2008) and their use of the Penn Arabic Tree-
bank (Maamouri et al, 2004).
7 Conclusions
We have presented an empirical study in data-
driven morphological segmentation employing
supervised boundary prediction methodology.
Specifically, we applied conditional random fields,
a discriminative log-linear model for segmentation
and tagging. From a methodological perspective,
this approach differs from the previous state-of-art
methods in two fundamental aspects. First, we uti-
lize a discriminative model estimated using only
annotated data. Second, we learn to predict morph
35
Method Train. Prec. Rec. F1
CRF 100 72.4 79.6 75.8
S-MORFESSOR 100 77.9 78.5 78.2
CRF 200 83.2 82.3 82.8
S-MORFESSOR 200 80.0 83.2 81.6
CRF 300 83.9 85.9 84.9
S-MORFESSOR 300 80.1 85.6 82.8
CRF 400 86.4 86.5 86.4
S-MORFESSOR 400 80.7 87.1 83.8
CRF 500 87.5 86.4 87.0
S-MORFESSOR 500 81.0 87.2 84.0
CRF 600 87.8 88.1 87.9
S-MORFESSOR 600 80.5 89.9 85.0
CRF 700 89.1 88.3 88.7
S-MORFESSOR 700 80.9 90.7 85.5
CRF 800 88.6 90.3 89.4
S-MORFESSOR 800 81.2 91.0 85.9
CRF 900 89.2 89.8 89.5
S-MORFESSOR 900 81.4 91.2 86.0
CRF 1000 89.9 90.4 90.2
S-MORFESSOR 1000 83.0 91.5 87.0
Table 7: Results for Turkish on the Morpho Chal-
lenge 2009/2010 data set (Kurimo et al, 2009; Ku-
rimo et al, 2010). The column titled Train. de-
notes the number of annotated training instances.
In addition to the annotated data, S-MORFESSOR
utilized an unannotated set of 617,298 word types.
boundaries based on their local character substring
contexts instead of learning a morph lexicon.
We showed that our supervised method yields
improved results compared to previous state-of-
art semi-supervised methods using the same small
amount of annotated data, while not utilizing the
unannotated data used by the reference methods.
This result has two implications. First, supervised
methods can provide excellent results in morpho-
logical segmentation already when there are only
a few annotated training instances available. This
is meaningful since for most languages it is infea-
sible to acquire large amounts of annotated train-
ing data. Second, performing morphological seg-
mentation by directly modeling segment bound-
aries can be advantageous compared to modeling
morph lexicons.
A potential direction for future work includes
evaluating the morphs obtained by our method in
real world applications, such as speech recognition
and information retrieval. We are also interested
in extending the method from fully supervised to
Method English Finnish Turkish
CRF 82.0 81.9 71.5
S-MORFESSOR 79.6 73.5 70.5
Table 8: F-measures of the Morpho Chal-
lenge boundary evaluation for CRF and S-
MORFESSOR using the full annotated training
data set.
semi-supervised learning.
Acknowledgements
This work was financially supported by Langnet
(Finnish doctoral programme in language studies)
and the Academy of Finland under the Finnish
Centre of Excellence Program 2012?2017 (grant
no. 251170), project Multimodally grounded lan-
guage technology (no. 254104), and LASTU Pro-
gramme (nos. 256887 and 259934).
References
M. Collins. 2002. Discriminative training methods
for hidden markov models: Theory and experiments
with perceptron algorithms. In Proceedings of the
2002 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2002), volume 10,
pages 1?8. Association for Computational Linguis-
tics.
M. Creutz, T. Hirsim?ki, M. Kurimo, A. Puurula,
J. Pylkk?nen, V. Siivola, M. Varjokallio, E. Arisoy,
M. Sara?lar, and A Stolcke. 2007. Morph-
based speech recognition and modeling of out-of-
vocabulary words across languages. ACM Transac-
tions on Speech and Language Processing, 5(1):3:1?
3:29, December.
S. Green and J. DeNero. 2012. A class-based
agreement model for generating accurately inflected
translations. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics: Long Papers-Volume 1, pages 146?155.
Association for Computational Linguistics.
H. Hammarstr?m and L. Borin. 2011. Unsupervised
learning of morphology. Computational Linguistics,
37(2):309?350, June.
T. Hirsim?ki, M. Creutz, V. Siivola, M. Kurimo, S. Vir-
pioja, and J. Pylkk?nen. 2006. Unlimited vocabu-
lary speech recognition with morph language mod-
els applied to Finnish. Computer Speech and Lan-
guage, 20(4):515?541, October.
O. Kohonen, S. Virpioja, and K. Lagus. 2010. Semi-
supervised learning of concatenative morphology.
In Proceedings of the 11th Meeting of the ACL Spe-
cial Interest Group on Computational Morphology
36
and Phonology, pages 78?86, Uppsala, Sweden,
July. Association for Computational Linguistics.
M. Kurimo, S. Virpioja, V. Turunen, G. W. Blackwood,
and W. Byrne. 2009. Overview and results of Mor-
pho Challenge 2009. In Working Notes for the CLEF
2009 Workshop, Corfu, Greece, September.
M. Kurimo, S. Virpioja, and V. Turunen. 2010.
Overview and results of Morpho Challenge 2010. In
Proceedings of the Morpho Challenge 2010 Work-
shop, pages 7?24, Espoo, Finland, September. Aalto
University School of Science and Technology, De-
partment of Information and Computer Science.
Technical Report TKK-ICS-R37.
J. Lafferty, A. McCallum, and F.C.N. Pereira. 2001.
Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proceed-
ings of the Eighteenth International Conference on
Machine Learning, pages 282?289.
M. Maamouri, A. Bies, T. Buckwalter, and W. Mekki.
2004. The penn arabic treebank: Building a large-
scale annotated arabic corpus. In NEMLAR Con-
ference on Arabic Language Resources and Tools,
pages 102?109.
G. Mann and A. McCallum. 2008. Generalized expec-
tation criteria for semi-supervised learning of con-
ditional random fields. In Proceedings of ACL-
08: HLT, pages 870?878. Association for Compu-
tational Linguistics.
A. McCallum and W. Li. 2003. Early results for
named entity recognition with conditional random
fields, feature induction and web-enhanced lexicons.
In Proceedings of the seventh conference on Natural
language learning at HLT-NAACL 2003-Volume 4,
pages 188?191. Association for Computational Lin-
guistics.
A. McCallum, D. Freitag, and F. Pereira. 2000. Max-
imum entropy Markov models for information ex-
traction and segmentation. In Pat Langley, editor,
Proceedings of the Seventeenth International Con-
ference on Machine Learning (ICML 2000), pages
591?598, Stanford, CA, USA. Morgan Kaufmann.
F. Peng, F. Feng, and A. McCallum. 2004. Chinese
segmentation and new word detection using condi-
tional random fields. In Proceedings of the 20th In-
ternational Conference on Computational Linguis-
tics (COLING 2004), page 562. Association for
Computational Linguistics.
H. Poon, C. Cherry, and K. Toutanova. 2009. Unsuper-
vised morphological segmentation with log-linear
models. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 209?217. Association for
Computational Linguistics.
F. Sha and F. Pereira. 2003. Shallow parsing with con-
ditional random fields. In Proceedings of the 2003
Conference of the North American Chapter of the
Association for Computational Linguistics on Hu-
man Language Technology-Volume 1, pages 134?
141. Association for Computational Linguistics.
B. Snyder and R. Barzilay. 2008. Crosslingual prop-
agation for morphological analysis. In Proceedings
of the AAAI, pages 848?854.
M. Szummer, P. Kohli, and D. Hoiem. 2008. Learn-
ing CRFs using graph cuts. Computer Vision?ECCV
2008, pages 582?595.
V. Turunen and M. Kurimo. 2011. Speech retrieval
from unsegmented Finnish audio using statistical
morpheme-like units for segmentation, recognition,
and retrieval. ACM Transactions on Speech and
Language Processing, 8(1):1:1?1:25, October.
S. Virpioja, V. Turunen, S. Spiegler, O. Kohonen, and
M. Kurimo. 2011. Empirical comparison of eval-
uation methods for unsupervised learning of mor-
phology. Traitement Automatique des Langues,
52(2):45?90.
H. Zhao, C.N. Huang, and M. Li. 2006. An improved
chinese word segmentation system with conditional
random field. In Proceedings of the Fifth SIGHAN
Workshop on Chinese Language Processing, volume
1082117. Sydney: July.
37
