XML and Multilingual Document Authoring: Convergent Trends 
Marc l )ymctman Veronika Lux  
Xerox  Research  Centre Europe 
6, chemin  de Maupertu is  
38240 Meylan,  France 
{ dymetman, lux  } @xrce .xerox .com 
Aarne Ranta  
Depar tment  of  Comput ing  Science 
Chahners  Univers i ty  of  Techno logy  
and GOteborg Univers i ty  
S-412 96 GOteborg,  Sweden 
aarne @ cs.chahners,  e 
Abstract 
Typical al)proaches to XML authoring view a XML doc- 
urnent as a mixture of structure (the tags) and surlhce 
(texl between the tags). We advoeale a radical approach 
where the surface disappears from lhe XML documenl 
altogether to be handled exclusively by rendering mech- 
anisms. This move is based on the view that the author's 
choices when authoring XML docutnciHs are best seen 
as language-i~eutral semantic decisions, that lhe SlftlC- 
lure can then be viewed as inlerlingual content, and that 
the textual oulpul  should be derived from this co)lien\[ by 
language-sl~ecific realization mechanisms, lhus assimi- 
lating XML aufllol'ing lo Mullilingual Document Amhof  
ing. However, slandard XMI, tools have imporlant lhni- 
tations when used for such a ptu'pose: (1) they are weak 
at propagating semanlic dependencies belween dil'ferenl 
parts of the st,'ucture, and, (2) current XMI. rendering 
tools are ill-suited for handling the grammatical combi- 
nation of lextual units. We present two relalcd proposals 
for overcoming these limitalions: one (GI:) origitmting 
in the Iradilion of malhemalical proof edilors and con- 
slruct ivc type lhcery,  the other  (IG), a special i?at ion o f  
l)elinite Clause (_\]ranllllars strongly inspired by (iF. 
1 Introduction 
The typical al3pl'oacll to XML authoring views an XML 
doctmlcnt as a mixture of wee-like strttctttre, expressed 
througll balanced labelled parentheses (tim lags), and 
of sul:face, expressed llu'ough free lexi interspersed be- 
tween lhe tags (PCI)ATA). A l)octunent Type l)elini- 
lion (DTD) is roughly similar to a coiitext-free gram- 
mar j with exactly one predelined terminal. It delines a 
set o1' well-formed structures, (hat is, a la,guage over 
trees, where each nonterminal node can dominate ither 
the empty string, or a sequence of occurrences of nonter- 
minal nodes and of 111o terminal node pcdata. The ter- 
minal pcdata  has a specM status: it can in turn dominate 
any characler string (subjecl to certain reslrictions on the 
characters allowed). Authoring is typically seen as a top- 
down interactive process of step-wise refinement of the 
root nonterminal (corresponding to the whole document) 
where the aulhor  ileratively chooses arule for expanding 
IBu( see (l'rescod, 1998) lbr an inleresfing discussion oflhe differ- 
enccs. 
a nonlerminal aheady present in the tree, 2 and where in 
addition the author can choose an arbitrary sequence of 
characters (roughly) for expanding lhe pcdata  node. 
One can observe the following trends in the XML 
world: 
A move towards more typing of the surface: 
Schemas (W3C, 1999a), which are an inlluemial 
proposal for the ieplacenlent of I)TD's, provide for 
types such as f loat ,  boolean, uri, etc., instead o\[" 
the single type pcdata; 
A move, aheady constitulive of the main lmlpose 
of XMl, its opposed l(1 HTML for instance, towards 
clearer separation between content and form, where 
the original XML document is responsible for con- 
lent, and powerful styling lnechanisms (e.g. XSI.T 
(W3C, 1999b)) are available for rendering 111o doc- 
tlll/en\[ \[o lhe end-user .  
We advocate an approach in which these two moves 
are radicali?cd in tile folk)wing ways: 
Strongly typed, surface-free XML documents. The 
whole content of the document is a trcc whore each node 
is labelled and typed. For inlernal nodes, lhe lype is just  
the usual nonierminal name (or category), and Ille label 
is a name for the expansion chosen for this nonlernfinal, 
lhat is, an identifier of which rule was chosen to expand 
ibis nonterminal. For leaves, lhe type is a semanlically 
specilic category such as Integer, Animal, etc., and lhe 
label is a specilic concept of this type, such as three or 
dog)  
Styling responsible for producing tim text itself. 
The styling mechanisnl is not only responsible for ren- 
dering the layout of the lext (typography, order and pre- 
sentation of lhe elements), but also for producing the text 
itse!ffrom 111o document content. 
What are (he motiw~tions behind this proposal? 
Autlmring choices carry language-independent 
meaning. First, let us note that lhe expansion choices 
2We arc ignoring here tl~e aspecls of lhis process relating to lhe 
regular ,mlure of Ihe righ(-halld sides of rules, but Ihese parliculars are 
uncssenlial lo the nlaill g:lfgtllllOnl. 
3Note Ihat lnlcgcr is of"logical type" e, whereas Animal is of log- 
ical lype (c, t): lhe,'c is no reslriction on lhe denotalional s alus of 
leaves. 
243 
<!ELEMENT R isk  (Caut ion  I Warn ing)  > r i sk - ru le l :  R i sk  --> Caut ion  
r i sk - ru le2 :  R i sk  --> Warn ing  
<!ELEMENT Caut ion  ( . . .  I . . .  I . . .  ) > caut ion - ru le l :  
caut ion - ru le2 :  
caut ion - ru le3 :  
Caut ion  --> .., 
Caut ion  --> ... 
Caut ion  --> ... 
Figure 1 : Context-flee rules (shown on the right) corresponding to the aircraft DTD (shown on the left); for illustration 
purposes, we have assumed that there are in turn three semantic varieties of cautious. The rule identitier on the left 
can be seen as a semantic label for each expansion choice (in practice, the rule identifiers are given mnemonic names 
directly related to their meauing). 
made during the authoring of an XML document gener- 
ally carry language-independent meaning. For instance, 
the DTD for an aircraft maintenance manual might be 
legally required to distinguish between risk instructions 
of two kinds: caut  ion (risk related to material damages) 
and warn ing (risk to the operator). Or a D~'I) describing 
a personal list of contacts might provide a choice of gen- 
der (male, female) ,  title (dr, p ro f ,  de fau l t ) ,  country 
(ger, fra,...), etc. Each such authoring choice, which 
formally consists in selecting among different rules for 
expanding the same nonterminal (see Figure 1), corre- 
sponds to a semantic decision which is independent of 
the language chosen for expressing the document. A 
given DTD has an associated expressive space of tree 
structures which fall under its explicit control, and the 
author is situating herself in this space through top-down 
expansion choices. There is then a tension between on 
the one hand these cxplicitely controlled choices, which 
should be rendered differently in different languages 
(thus ger  as Germany, Allemagne, Deutschland .... and 
Warning by a paragraph starting with Warnillg! ...; At- 
tention, Danger! ...; Achtung, Lebensgefahr! ...), and 
on the other hand the uncontrolled inclusion in the XML 
document of free PCDATA strings, which are written in 
a specific language. 
Surface-fi'ce XML documents. We propose to com- 
pletely remove these surface strings from the XML doc- 
ument, and replace them with explicit meaning labels. 4
The tree structure of the document then becomes the sole 
repository of content, and can be viewed as a kind of in- 
terlingua for describing a point in the expressive space 
of tile DTD (a strongly domain-dependent space); it is 
then the responsability of the language-specific rendering 
mechanisms to "display" such content in each individual 
language where the document is needed. 
XML and Multil ingual Document Authoring. In 
this conception, XML authoring has a strong connection 
to the enterprise of Multilingual Document Authoring in 
which the author is guided in the specilication of the 
document content, and where the system is responsible 
4There are autlmring situations in which it may be necessary for 
the user to introduce new selllalllic labels eorleSl)onding lo expres- 
sive needs not foreseen by lhe creator of the original I)TD. To handle 
such situations, it is useflfl to view the l)TI)'s as open-ended objecls 1o 
which new semantic labels and types can be added at authoring time. 
for generating from this content extual output in several 
languages imultaneously (see (Power and Scott, 1998; 
Hartley and Paris, 1997; Coch, 1996)). 
Now there are some obvious problems with this view, 
due to the current limitations of XML tools. 
Limitations of XML for multilingual document au- 
thoring. The first, possibly most serious, limitation 
originates in the fact that a standard DTD is severely re- 
stricted in the semantic dependencies it can express be- 
tween two subtrces in the document structure. Thus, if 
in the description of a contact, a city of residence is in- 
cluded, one may want to constrain such an information 
depending on the country of residence; or, in the air- 
craft maintenance manual example, one might want to 
automatically include some warning in case a dangerous 
chemical is mentioned somewhere lse in the document. 
Because DTD's are essentially ofcontcxt-fi'ce expressive 
power, the only communication between a subtree and its 
environment has to be mediated through the name of the 
nonterminal rooting this subtree (for instance the nonter- 
minal Country) ,  which presents a bottleneck to informa- 
tion ilow. 
The second limitation comes fi'om the fact that the cur- 
rent styling tools for rendering an XML document, such 
as CSS (Cascading Style Sheets), which arc a strictly 
layout-oriented language, or XSLT (XSL transformation 
language), which is a more generic tool for transforming 
an XML document into another one (such as a display- 
oriented HTML file) are poorly adapted to linguistic pro- 
cessing. In particulm, it seems difficult in such for- 
malisms to express uch basic grammatical facts as ntun- 
ber or gender agreement. But such problems become 
central as soon as semantic elements corresponding to 
textual units below the sentence level have to be com- 
bined and rendered linguistically. 
We will present two related proposals for overcom- 
ing these limitations. The first, the Grammatical Frame- 
work (GF)(Ranta, 2000), originates in constructive type- 
theory (Martin-L6f, 1984; Ranta, 1994) and in mathe- 
matical proof editors (Magnusson and Nordstr6m, 1994). 
The second, h~teraction Grammars (IG), is a specializa- 
tion of Definite Clause Grammars trongly inspired by 
GF. The two approaches present certain lk)rmal differ- 
ences that will not be examined in detail in this papeh 
244 
but they share a number of important assumptions: 
? The semantic representations are strrmgly O'ped 
trees, and rich dependencies between subtrees can 
be specilied; 
? The abstract tree is independe,lt of tile different ex- 
tual realization hmguages; 
? Tim surface realization in each language is obtained 
by a semalltics-driven compositional process; that 
is, the surface realizations are constructed by a 
bottom-up recursive process which associates ur- 
face realizations to abstract ree nodes by recur- 
sively combining the realizations of daugthcr nodes 
to obtain the realization of the mother node. 
? The grammars are revelwible, that is, can be used 
both for generation and for parsing; 
? The authoring process is an interactive process 
of repeatedly asking the author to further specify 
nodes in the absmlct ree of which only the type is 
known at the 1)oint of interacti(m (tyFe re/itlemeHt). 
This process is mediated througll text in the lan- 
guage of the author, showing the types t(5 be relined 
as specially highlighted textual units. 
2 GF  ~ the  Grammat ica l  F ramework  
The Grammatical Framework (GF; (Ranta, 2000)) is a 
special-purpose programming hmguage combining co~z- 
strttctive type thee O, with an annotation hmguage for 
concrete syntax. A grammar, in the sense of GF, delines, 
on one hand, an abstract s3,1ttax (a system of types and 
typed syntax trees), and on the other hand, a mapping {51 
tile abstract syntax into a co,icicle sy, tta.v. The abstract 
syntax has cotCtlot 3, declarations, uch as 
cat  Count ry  ; ca t  C i ty  ; 
and combinator (orfttnctiolO dechuations, uch as 
fun Get : Country ; fun Fra : Country ; 
fun Ham : C i ty  ; fun Par : C i ty  ; 
fun cap : Country -> C i ty  ; 
The type of a combinator can be either a basic type, such 
as the type C i ty  of the combinator Ham, or a function 
type, such as the type of the combinator cap. Syntax 
trees formed by combinators of functioll types are con> 
plex functional terlns, such as 
cap Fra 
of type City. 
"file concrete syntax part of a GF grammar gives lit~- 
earization rules, which assign strings (or, in general, 
more complex linguistic objects) to syntax trees. For the 
abstract syntax above, we may lmve 
fin Ger = "Germany" ; f in Fra = "France" ; 
l in Ham = "Hamburg" ; l in Par : "Paris" ; 
lin cap Co = "the capita l  of" ++ Co ; 
Thus tile linearization of cap Fra is 
the capital  of France 
2.1 GF inXMI ,  
Functional terms have a straightforward encoding in 
XML, l'el~resenting a term of tile forna 
.\[ (11  . . .  ( I ,~  
by the XML object 
<J'> ct', . . .  a',, < / f> 
where each e~ is tile encoding of a i. In this encoding, 
cap Fra is 
<cap> 
<Fra> 
</Fra> 
</cap> 
Tile simple encoding does not pay attention to the 
types (51' the objects, and has no interesting DTI). To 
express type distinctions, we will hence use a slightly 
more complicated representation, i  which the category 
and combinator declarations of GF are represented as 
DTDs in XML, so that GF type dlecking becomes equiv- 
alent ,a, itll XML validatiom The represelm~tion f the GF 
grallllllaf o1' tile previous ection is tile DTI) 
<!ELEMENT Country (Ger \[ Fra)  > 
<!ELEMENT Get EMPTY > 
<!ELEMENT Fra EMPTY > 
<!ELEMENT City (Ham I Par I (cap,Country))> 
<!ELEMENT Ham EMPTY > 
<!ELEMENT Par EMPTY > 
<!ELEMENT cap EMPTY > 
In this DTD, each category is represented as an EI,E- 
MENT dclinition, listing all combinators producing trees 
of that category. The combinators themselves are repre- 
sented as EMPTY elements. The XML representation f 
the capital (51' France is 
<City> 
<cap /> 
<Country> 
<Fra /> 
</Country> 
</City> 
which is a wdid XML object w.r.t, tile given DTD. 
The latter encoding of GF in XML enjoys two impor- 
tant properties: 
? All well-typed GF trees are represented by valid 
XML objects. 
? An XML represents a unique GF tree. 
The tirst property guarantees that type checking in the 
sense of GF (and type theory) can be used for validation 
of XML objects. The second property guarantees that GF 
objects can be stored in tim XML format. (The second 
property is already gt, aranteed by tile simpler encoding, 
which ignores types.) 
()ther prope,'ties one would desire are the followillg: 
245 
? All valid XML objects represent well-typed GF 
trees. 
? A DTD represents a unique GF abstract grammar. 
These properties cannot be satislied, in general. The rea- 
son is that GF grammars may contain dependent types, 
i.e. types depending on objects. We will retnrn to this 
notion shortly. But let us first consider the use of GF for 
nmltilingual generation. 
2.2 Multilingualgeneration i GF 
Multilingual generation i  GF is based on parallel gram- 
mars': two (or more) GF grammars are parallel, if they 
have the same abstract syntax. They may differ in con- 
crete syntax. A grammar parallel to the one above is de- 
fined by the concrete syntax 
param Case = hem \[ gen ; 
oper noml : Str -> Case => Str = 
ks -> tbl {{nom} => s, {gen} -> s+"n"} ; 
oper nom2 :S t r  -> Case => Str 
ks -> tbl 
{{nom} => s+"ki", {gen} -> s+"gin"} ; 
l incat Country = Case => Str ; 
l incat City = Case => St r ;  
lin Ger = noml "Saksa" ; 
lin Fra = noml "Ranska" ; 
lin Ham = noml "Hampuri" ; 
l in Par = noml "Pari isi" ; 
l in cap Co = 
tbl {c => Co!gen ++ 
nora2 "p~iikaupun" ! c} ; 
This grammar renders GF objects in Finnish. In addition 
to linearization rules, it has rules introducing parameters 
and operations, and rules detining the linearization O,pes" 
corresponding to basic types: the linearization type el' 
Country, for instance is not just string (Str), but a func- 
tion fl'om cases to strings. 
Not only the linearization rules proper, but also param- 
eters and linearization types wwy a lot fl'om one hmguage 
to another. In our example, we have the paralnetre of ease 
with two values (in larger granunars for Finnish, as many 
as 16 may be required!), and two patterns for inflecting 
Finnish nouns. The syntax tree cap Fra produces the 
strings 
Ranskan p~fikaupunki 
Ranskan p~kaupung in  
which are the nominative and the genitive form, respec- 
tively. 
2.3 Del)endent types 
DTDs in XML are capable of representing simple types, 
i.e. types without dependencies. Even a simple type sys- 
tem can contribute a lot to the semantic ontrol of doc- 
uments. For instance, the above grammar permits the 
formation of the English noun phrase 
the capital  of France 
but not of 
the capital  of Paris 
Both of these expressions would be well-formed w.r.t. 
an "ordinary" granunar, in which both France and Paris 
would be classitied simply as noun phrases. 
Dependent types are types depending on objects of 
other types. An example is the following alternative dec- 
laration of Country and City: 
cat Country ; cat City (Co:Country) ; 
Under tiffs definition, there are no objects of type City 
(which is no longer a well-formed type), but of types 
City Ger and City Fra. Tlms we define e.g. 
fun Ham : City Ger ; fun Par : City Fra ; 
fun cap : (Co:Country) -> City Co ; 
Observe the use of the variable Co in the type of the com- 
binator capital: the variable is bound to the argument 
type and then used in the value type. The capital of a 
country is by definition a city of the same country. This 
involves a generalization o1' function types with depen- 
dent types. 
Now consider a simplified format ()f postal addresses: 
an address is a pair of a country and a city. The GF rule 
is either 
fun addr : Country  -> C i ty  -> Address ; 
i i n  addr  Co C = C ++ " , "  ++ Co ; 
using simple types or 
fun addr : 
(Co:Country)  -> C?ty Co -> Address ; 
&in addr  Co C = C ++ " , "  ++ Co ; 
using dependent types. The invalid address 
Hamburg, France 
is well-typed by the former definition but not by the lat- 
ter. Using the laUer delinition gives a simple mechanism 
of semantic ontrol ot' addresses. The same idea can ob- 
viously be exlended to full addresses with street names 
and numbers. Such dependencies cannot, however, be 
expressed in DTDs: both of the address rules above cor- 
respond to one and the same ELEMENT definition, 
<!ELEMENT Address (addr, Country, City) > 
This example 
enoughlbr GF 
<Address> 
<addr /> 
<Country> 
<Fra /> 
</Country> 
<City> 
<Ham /> 
</City> 
</Address> 
also shows Illat XML validity is not 
well-formedness: the object 
246 
is valid w.r.t, the DTD, but the corresponding Ot-; object 
addr  Fra  ttam 
is not well-typed. 
2.4 Computation rules 
In addition to categories and cornbinators, GF grammars 
may contain definitions, uch as 
def  cap Fra  = Par ; 
Definitions belong to the abstract syntax. They define 
a normal form for syntax trees (recursively replace de- 
fienda by definientes), as well as a paraphrase relation 
(sameness of normal tbrm). These notions are, of course 
reflected in the concrete syntax: the addresses 
the capital of France, France 
Par i s ,  F rance  
are paraphrases, and the latter is the normal form of the 
former. 
= . . . .  - - , -  , - - -  1 
\[U"e m IE'~i ml~w ml?pu?i's ~lum= ~J II 
 Nll 
I\[ "''~ ~ ~ ~ I / l l  
I I ~h~1- ~ul~f  ~ / / 1 1  
I I  lt'~eore~. Fc? aH numbers ?, there e?ists a rtlOcer u ' such I / /11 
I I  ~hat ~.L~ ~,~n~ U~ ,,'. ~-o~f. C~-.id~. ~,~'bitr ,  a~u I / /  
11 nuliJer x. '?z3re<~? . Ik.nce, "for' a l l  r i J~2rs ~, there ex is ts  a I l l  II 
l i  ~-,4,c,r'e~. Pot  tous lore rBc~hoes ;4. i l  e~i~te ~.~mbre  ~: ' .~ \ [ / I1  
j \ [  x ,  ~ r~. ,  ~.111~\] (~  t~.: n~',-~, ~- ~ ~-ooql II//1/ 
I\[ m~oon L~,u:~oUil l  " " t~- (~-  n~, u =(~.'ql II j i l l  
I I  e t~oH lukux~ik4} l  . . . . . .  I . . . . . . . .  . v .  I I I l l / I t  
I \[ <Text > crh,ua~w,-o411 ~,~. (, ,:- \[~, r,, q I I I l l / I /  
I I <Pr*~> <E--:ist/> <0c~ll E~t , / i ' .  ~ -_ ~ , ,  ~-_ (~ =11 I I IM II 
</Prop> <~r'oo> </ @tEll _ . . 
I . . . .  ta ~ ~_l~m H 
, .................................... Ill.,,,  411Lt 
?~a ~ Proof (Exist  !lat (','..'>:' q l l?l . l  0:~s~ r,, s: ~" ~ ' ,~  tl I i i-\]1t 
-- ~iI1_:_'. ~ ,_ t%: t~:F??~) \ ] l l l~  
Figure 2: GF session for editing a mathematical proof 
text. 
2.5 GF editing tools 
An editing tool has been implemented for GF, using 
metavariables to represent yet undefined parts of expres- 
sions. The user can work on any metavariable, in various 
different ways, e.g. 
? by choosing a combinator f om a menu, 
? by entering a string that is parsed, 
? by reading a previously defined object from a file, 
? by using an automatic search of suitable instantia- 
tions. 
These functionalities and their metatheory have been 
used for about a decade in a number of syntax edi- 
tors for constructive type theory, usually known as proof 
editors (Magnusson and NordstrOm, 1994). From this 
point of view, the GF editor is essentially a proof edi- 
tor together with supplementary views, provided by the 
concrete syntax. The current implementation of GF 
is a plugin module of the proof editor Alfa (Hallgren, 
2000). The window dump in Figure 2 shows a GF ses- 
sion editing a mathematical proof. Five views are pro- 
vided: abstract syntax in type-theoretical notation, En- 
glish, French, Finnish, and XML. One metavariable is
seen, expecting the user to find a Proof  of the proposi- 
tion that there exists a number .r' such that a', is smaller 
than x', where x is an arbitrary number given in the con- 
text (for the sake of Universal Introduction). 
3 IG : Interaction Grammars 
We have just described an approach to solving the limita- 
tions of usual XML tools for multilingual document au- 
thoring which originates in the tradition of constructive 
type-theory and mathematical proof editors. We will now 
sketch an approach strongly inspired by GF but which 
formally is more in the tradition of logic-programming 
based unification grammars, and which is currently un-. 
der development at Xerox Research Centre Europe (see 
(Brun et al, 2000) for a more extended escription of 
this project). 
Definite Clause Grammars, or DCG's, (Pereira and 
Warren, 1980), are possibly the simplest unification- 
based extension of context-free grammars, and have 
good reversibility properties which make them adapted 
both to parsing and to generation. A typical view of what 
a DCG rule looks like is the following: 5
a(a l (B ,C  . . . .  )) ---> 
<text l> ,  
b(B), 
<text2>,  
e(c ) ,  
<text3>, 
{constraints (B,C,...)}. 
This rule expresses the fact that (1) some abstract 
structure a l  (B, C . . . .  ) is in category a if the structure 
B is in category b, the structure C in category c..... and 
furthermore a certain number of constraints are satisfied 
by the structures B, C .... ; (2) if the structures B, C .... can 
be "rendered" by character strings St r ingB,  Str ingC,  
.... then the structure a l (B ,C . . . .  ) can be rendered by 
the string obtained by concatenating the text <text:t> 
(that is, a certain constant sequence of terminals), then 
St r ingB,  then <text2>, then Str ingC,  etc. 
In this formalism, a grammar for generating English 
addresses (see preceding section) might look like: 
SReminder: according to the usual ogic programming conventions, 
lowercase letters denote predicates and functors, whereas uppercase 
letters denote metavariables that will be instantiated with terms. 
247 
address(addr(Co,C)) --> city(C), ",", 
country(Co). 
country(fra) --> "France". 
country(get) --> "Germany". 
city(par) --> "Paris" 
city(cap(Co)) --> "the capital of", 
country(Co). 
The analogies with the GF grammars of the previous 
section arc clear. What is traditionally called a cate- 
gory (or nonterminal, or predicate) in the logic program- 
ruing terminology, can also be seen as a type (address,  
country ,  c i ty )  and functors uch as get,  par,  addr, 
cap can be seen as combinators. 
If, in this DCG, we "forget" all the constant strings 
by replacing them with the empty string, we obtain the 
following "abstract grammar": 
address(addr(Co,C)) --> city(C), country(Co). 
country(fra) --> \[\]. 
country(ger) --> \[\]. 
city(par) --> \[\]. 
city(cap(Co)) --> country(Co). 
which is in fact equivalent to the definite clause pro- 
gram: 6 
address (addr (Co ,C) )  : -  c i ty (C) ,  count ry (Co) .  
count ry ( f ra ) .  
country(ger) . 
city(par) . 
city(cap(Co)) :- country(Co). 
This program is language-independent andrecursively 
dclines a set el' well-formed trees to which it assigns 
types (thus cap( f ra )  is a well-formed tree o1' type 
city). 
As they stand, such definite clause grammars and pro- 
grams, although suitable Ibr simple generation tasks, are 
not directly adapted for the process of interactive multi- 
lingual document authoring. In order to make them more 
appropriate for that task, we need to specialize and adapt 
DCGs in the way that we now describe. 
Parallel grammars.  The tirst move is to allow for 
parallel English, French ..... grammars, which all have 
the same underlying abstract gralnmar (program). So in 
addition to the Englisb grammar given above, we have 
tim French grammar: 
address(addr(Co,C)) --> city(C), ",", 
country(Co). 
country(fra) --> "la France". 
country(get) --> "l'Allemagne". 
city(par) --> "Paris". 
city(cap(Co)) --> "la capitale de", 
country(Co) . 
6hl the sense that rewriling the llOntCI'nlilull goal 
address  (addr (Co ,C) ) to the empty siring in lhe I)CG is equivalent 
|o proving the goal address  (addr (Co, C) ) in the program (l)cransart 
and Maluszynski, 1993). 
Dependent  Categor ies .  The grammars we have given 
arc delicient in one importaut respect: there is no de- 
pendency between the city and the country in the salne 
address. In order to remedy this problem, a stan- 
dard logic programming move would he to reformulate 
the abstract grammar (and similarly for the language- 
dependent ones) as: 
address (addr (Co ,C) )  - -> c i ty (C ,Co) ,  
count ry (Co) .  
count ry ( f ra )  - -> \ [ \ ] .  
count ry (ger )  - -> \ [ \ ] .  
c i ty (par , f ra )  - -> \ [ \ ] .  
c i ty (cap(Co) ,Co)  - -> count ry (Co) .  
The expression c i ty (C ,  Co) is usually read as the re- 
lation "C is a city of Co", which is line for computational 
purposes, but this reading obscures the notion that the 
object C is being typed as a c i ty ;  more precisely, it is 
being typed as a c i ty  of Co. In order to make this read- 
ing more apparent, we will write the grammar as: 
address(addr(Co,C)) --> cityc0(C), 
country(Co). 
country(fra) --> \[\]. 
country(ger) --> \[\]. 
cityf~(par) --> \[\]. 
cityco(cap(Co)) --> country(Co). 
That is, we allow the categories to be indexed by terms 
(a move which is a kind of "currying" ot' a relation into 
a type for its first argument). Dependent categories are 
similar to the dependent types of constructive type the- 
ory. 
Heterogeneous trees. Natural language authoring is 
different from natural language generation in one cru- 
cial respect. Whenever the abstract ree to be generated 
is incomplete (for instance the tree cap(Co)),  that is, 
has some leaves which are yet uninstantiated variables, 
the generation process should not proceed with noude- 
terministically enumerating texts for all the possible in- 
stantiations of the initial incomplete structure. Instead it 
should display to the author as much of the text as it can 
in its present "knowledge state", and enter into an inter- 
action with the author to allow her to further refine the 
incomplete structure, that is, to further instantiate some 
of the uninstantiated leaves. To this purpose, it is use- 
ful to introduce along with the usual combinators (addr, 
f ra ,  cap, etc.) new combinators of arity 0 called type- 
names, which are notated type, and are of type type.  
These combiuators are allowed to stand as leaves (e.g. in 
the tree cap(country) )  and the trees thus obtained are 
said to be heterogeneous. The typenames are treated by 
the text generation process as if they were standard se- 
mantic units, that is, they are associated with text trails 
which arc generated "at their proper place" in the gen- 
erated output. These text units are specially phrased and 
highlighted to indicate to the author that some choice has 
to be made to reline the underlying type (e.g. obtaining 
248 
the text "la capimle de PAYS"). This choice has the efl'ect 
of further instantiating the incomplete tree with "true" 
combinators, and the gmmration process is iterated. 
Extended senmntics-driven eompositionality. The 
simple DCG view presented at the beginning of this sec- 
tion sees the process of generating text from an abstract 
structure as basically a compositional process on strings, 
that is, a process where strings are recursively associated 
with subtrees and concatenated to l~roduce strings at the 
next subtree level. But such a direct process of construct- 
ing strings Ires well-known limitations when the seman- 
tic and syntactic levels do not have such a direct corre- 
spondence (simple example: ordering a list of modifiers 
around a noun). We are currently experimenting with a 
powerful extension of string compositionality where the 
objects compositionally associated with abstract subtrees 
are not strings, but syntactic representations with rich in- 
ternal structure. The text itself is obtained fiom the syn- 
tactic representation associated with the total tree by Siln- 
ply enumerating its leaves. 
The picture we get of an IG grammar is tinally the 
following: 
aD,. . (al(B,C . . . .  ) ) -Syn  - -> 
bE,...(B)-SynB, 
CF,...(C)-SynC, 
{const ra in ts (B ,C , . . . ,D ,E ,F , . . . )} ,  
{compose_engl ish(SynB,  SynC, Syn)}.  
The rule shown is a rule for English: the syntactic 
representations are hmguage dependent; Parallel rules 
for tim other hmguages are obtained by replacing the 
compose eng l ' i sh  constraint (which is tmique to this 
rule) by constraints appropriate to the other hmguages 
under consideration. 
4 Conclusion 
XML-based authoring tools are more and more widely 
used in the business community for supporting the pro- 
duction of technical documentation, controlling their 
quality and improving their reusability. In this paper, 
we have stressed the connections between these practices 
and current research in natural anguage genenttion and 
authoring. We have described two related fornmlisms 
which are proposals for removing some of the limitations 
of XML DTD's when used for tim production of multi- 
lingual texts. 
From a compt, tational inguist's point of view, there 
might be little which seems novel or exciting in XML 
representations. Still XML has a great potential as a lin- 
gua.franca and in driving a large community of users 
towards authoring practices where content is becoming 
more and more explicit. There may be a great opportu- 
nity here for researchers in natural hmguage generation 
to connect o a growing sot, rce of applications. 
Acknowledgements 
Thanks for contributions, discussions and comments to 
Ken Beesley, Caroline Brtm, Jean-Pierre Chanod, Marie- 
Hdl8ne Corrdard, Pierre Isabelle, Bengt Nordstr6m, Syl- 
vain Pogodalla nd Annie Zaenen. 
References 
C. Brun, M. l)ymetman, and V. Lux. 2000. l)ocument 
structure and multilinguat authoring. In Proceedings of 
First h~telwatiomd Natural lzmguage Generation Confer- 
ence (INLG '2000), Mitzpe P, amon, Israel, June. 
J. Coch. 1996. Evahmting and comparing three text production 
tech,fiqucs. In Proceedhtgs ofthe 16th huernational Confe.r- 
ettce on Conqmtational Linguistics. 
1: l)eransart and J. Maluszynski. 1993. A Gramntatical View 
of Logic Programming. MIT Press. 
Thonms llallgren. 2000. Alfa Home Page. Awfilable fi'om 
http ://wm~. cs. chalmers, se/~hallgren/Alfa/ 
A. ltartley and C. Paris. 1997. Multilingual document produc- 
tion: fiom support for translating to support for authoring. 
In Machine Translation, Special Issue on New 7bols.for Htt- 
man 7)'anslators, pages 109-128. 
L. Magnusson and B. NordslrOm. 1994. The ALF proof editor 
and its proof engine. In Lecture Notes in Conqmler Science 
806. SpringeL 
P. Martin-L6f. 1984. hmdlionistic 7\]ype 7heoo,. Bibliopolis, 
Naples. 
W. Pardi. 1999. XML in Action. Microsoft Press. 
Femando C. N. Pereira and David II. D. Warren. 1980. Deft- 
nite clause grammars for language analysis. Artificial huel- 
ligence, 13:231-278. 
P,. Power and D. Scott. 1998. Multilingual authoring using 
feedback texts. In ProceedhTgs of the 17th h~ternational 
Confelwnce on Comlmtatiom~l linguistics and 36th Annual 
Meeting of the Association for Computational Lhlguislics, 
pages 1053-1059. 
P. Prescod. 1998. Fornmlizing SGMI, and XML In- 
stances and Schemata with Forest Automata Theory. 
http : //m~w. prescod, net/f orest/shorttut/. 
A. Ranta. 1994. 7~vpe-Theorelical Grammar. Oxford Univer- 
sity Press. 
Aarne Ranm. 2000. GF Work Page. Awfilablc fi'om 
h'c t;p://m,m, cs.  chalmers, se/~aarne/(IF/ 
pub/work- index/ 
W3C, 1998. Exlensible Marktq~ Language (XML) 1.0, Febru- 
ary. W3C recommendation. 
W3C, 1999a. XML Schema - l'art h Strltctttres, Part 2 : 
Datatypes -, l)ecembe,. W3C Working draft. 
W3C, 1999b. XSL Transformations (XSLT), Novcmbe,; W3C 
recommendation. 
249 
Context-Free Grammar Rewriting and the Transfer of Packed Linguistic 
Representations 
Marc Dymetman 
Xerox Research Centre Europe 
6, chemin de Maupertuis 
38240 Meylan, France 
dymetman @ xrce.xerox.com 
Fr~dfiric Tendeau 
Lernout & Hauspie 
Koning Albert-I laan 64 
B- 1780 Wemmel, Belgium 
Frederic.Tendeau @ lhs.be 
Abstract 
We propose an algorithm for the trausfer of packed linguistic 
structures, that is, finite collections of labelled graphs which 
share certain subparts. A labelled graph is seen as a word over 
a vocabulary of description elements (nodes, arcs, labels), and 
a collection of graphs as a set of such words, that is, as a hm- 
guage over description elements. A packed representation for 
the collection of graphs is then viewed as a context-free gram- 
mar which generates such a language. We present an algorithm 
that uses a conventional set of transfer ules but is capable of 
rewriting the CFG representing the source packed structure into 
a CFG representing the target packed structure that preserves 
the compaction properties of the source CFG. 
1 Introduction 
There is currently much interest in translation models 
that support some amount of ambiguity preservation be- 
tween source and target exts, so as to minimize disam- 
biguation decisions that the system, or an interactive user, 
has to make during the translation process (Kay et al, 
1994).. 
An important aspect ol' such models is the ability to 
handle, during all the stages of the translation process, 
packed linguistic structures, that is, structures which fac- 
torize in a compact fashion all the different readings of 
a sentence and obviate the need to list and treat all these 
readings in isolation of each other (as is standard in more 
traditional models for machine translation). 
In the case of parsing, and more specifically, parsing 
with unification-based formalisms uch as LFG, tech- 
niques for producing packed structures have been in 
existence for some time (Maxwell and Kaplan, 1991; 
Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; 
D6rre, 1997; Dymetman, 1997). More recently, tech- 
niques have been appearing for the generation from 
packed structures (Shemtov, 1997), the transfer between 
packed structures (Emele and Dorna, 1998; Rayner and 
Bouillon, 1995), and the integration of such mechanisms 
into the whole translation process (Kay, 1999; Frank, 
1999). 
This paper focuses on the problem of transfer. The 
method proposed is related to those of (Emele and Dorna, 
1998) and (Kay, 1999). As in these approaches, we view 
packed representations a being descriptions of a finite 
collection of directed labelled graphs (similar to the func- 
tional structures of LFG), each representing a different 
non-ambiguous reading, which share certain subparts. 
The representations of (Emele and Dorna, 1998) and 
(Kay, 1999) arc based on a notion of propositional con- 
texts (see (Maxwell and Kaplan, 1991)), where each 
possible non-ambiguous reading included ill the packed 
source representation is extracted by selecting the value 
(true or false) of a certain number of propositional vari- 
ables that index elements of the labelled source graph. 
Transfer is then seen as a process of rewriting source 
graph elements (e.g, nodes labelled with French lexemes) 
into target graph elements (e.g. nodes labelled with En- 
glish lexemes), while preserving the propositional con- 
texts in which these graph elements were selected. 
In contrast, our approach, following (Dymetman, 
1997), views a packed representation as being a gram- 
mar (more specifically, a context-flee grammar) over the 
vocabulary of graph elements (labelled nodes and edges), 
where each word (in the sense of formal anguage theory) 
generated by the grammar represents one of the possible 
non-ambiguous readings of the packed representation. I  
other terms, the collection of non-ambiguous graphs be- 
longing to the packed representation is seen as a km- 
guage over a vocabulary of graph elements, and a packed 
representation is seen as a grammar which generates such 
a language. Packing comes fi'om the fact that a context- 
free grammar is an cMcicnt representation lbr the lan- 
guage it generates. Another essential feature of such a 
representation is that it is interaction-free, that is, each 
nondeterministic op-down traversal of the grammar suc- 
ceeds without ever backtracking and it results in a certain 
reading, without he need for checking the consistency of 
a set of associated propositional constraints: the repre- 
sentation for the collection of readings is as direct as can 
be while permitting a filctorization of common parts. 
Based on this notion, we present an algorithm for 
transfer which, starting fi'om a finite set of rewriting 
patterns (the transfer lexicon), associates with a given 
context-fi'ee grammar epresenting the source packed 
structure a context-free grammar epresenting the tat'- 
get packed structure. Therefore, the target representa- 
tion remains interaction-fi'ee and transparently encodes 
the target structures; furthermore, under certain natural 
"locality" conditions on the rewriting rules (the graph el- 
ements in their left-hand sides tend be be "close" from 
each other in the source grammar derivations), the target 
grmnmar preserves much of the factorization and com- 
paction properties of the sotu'ce grammar. 
The paper is structtu'ed in the following way. Sec- 
1016 
tion 2 explains how mnbiguous graphs can be seen as 
commutative hmguagcs over graph description elements, 
and how context-free grammars provide concise specili- 
cations for these languages. Section 3 extends the stan- 
dard notion of non-ambiguous transfer to that of am- 
biguous transfer. Section 4 presents the basic hmguagc- 
theoretic formalism needed and introduces ome opera- 
|ors on languages. Section 5 presents Ihe detailed rewrit- 
ing algorithm, which applies these operators not directly 
to hmguages, but to the context-free grammars pecify- 
ing them. Section 6 gives an example of the algorithm in 
operation. 
2 Ambiguous structures as languages 
O: see /sawz  . . . . . . . . . . . . .  - . _ _  
argl~- -'~ ~at 'g2- - - - - .  *nod " "  mod 
1: i 2: l ight z_ ~-Z - -\\- -. \ 
{ J l f  n l ( ) ( \ ] - -  ~ ~ , - -  -- I I lOd  \ 
7: g reen  I / g reen2 err'g2 ~ ~l 
J 
4: h i l l -  m(~d x t 
5 :  w i lh  
ar?,2 \[ 
(~: le lescope  
Figure 1 : An informal graphical representation f the 20 
possible analyses for "I saw the green light on the hill 
with a telescope". 
Let's consider the sentence "I saw the green light on 
the hill with a telescope". In Fig. I, we have repre- 
sented inlbnnally the set of possible analyses for this 
sentence. Labels on the nodes correspond to predicate 
names ('on', 'hill', etc). A slash is used to indicate dif- 
ferent possible readings for a node; for instance, we as- 
sume that the surface form "saw" can correspond to the 
verbs "to see" or "to saw", and that "green" is ambigu- 
ous between the color adjective "green l" and the noun 
"green2" (grassy lawn). Relations between odes are in- 
dicated by labels on the edges joining two nodes: 'argl '  
and 'arg2' for tirst and second argument, 'rood' for mod- 
ilier. The solid edges correspond to relations which are 
satistied in all the readings for |be sentence, dotted edges 
to relations that are satistied only for certain readings. 
Thus, the preprositional phrase "on the hill" can modify 
either "light" or "see/saw", the phrase "with a telescope" 
either "hill", "light", or "see/saw'. The informal picture 
of Fig. 1 does not make explicit exactly which structures 
are actually possible analyses of the sentence. For in- 
stance the two crossing edges modo3 and rood25 (where 
indices are used to denote the origin and destination of 
the edge) cannot appear together in a reading of the given 
sentence. As a consequence only five of the apparent 
2 x 3 prepositional ttachments combinations are possi- 
ble, which multiplied by the four possible lexical variants 
for "saw" and "green" gives 20 possible readings for tim 
sentence .  
Each of these readings is a graph where nodes 0 and 
7 now carry one label, and where one 'rood' edge has 
been selected for the attachment of nodes 3 and 5. One 
way to describe such a graph is by listing a collection of 
"description elenmnts" for it, where each such dement 
is either a labelled node such as scco or a labelled edge 
such as rood27. Using this format, the pragmatically pre- 
ferred analysis for our sentence is the set {SCCo, mglol, 
il, arg202, light2, mod27, gwenlT, mod.23, on3, arg234, 
hill4, modo5, with~,, zug2.~a, tclescope~ }.
If we consider the collection of all possible analyses, 
we then obtain a collection of sets of description ele- 
ments. It is convenient to view such a collection as a 
commutative language over the vocabulary of all possi- 
ble description elements; each word in such a hmguage 
corresponds to one analysis and is a list of description 
elements the order of which is considered irrelevant. 
The main advantage of taking this view of ambiguous 
structures is that fomml language theory provides stan- 
dard tools for representing languages compactly. Thus 
it is well-known in computational lexicography tlmt a 
large list of word strings can be represented efliciently by 
means of a tinite-stale atltoma|on which factorizes com- 
mon subs|rings. Such a representation is both compact 
and "explicit": accessing and using it is as direct as the 
flat list of words would be. 
Although one might think o1' using tinite-statc mod- 
els for representing compaclly the language associated 
with a collection of graphs, they do not seem as relevant 
as context-free models for our purposes. The reason is 
that the source packed representations are typically ob- 
tained as the results of chart-parsing processes. A chart 
used in the parsing of a context-fi'ee grammar can itself 
be viewed as a context-free grammar, which is a spe- 
cialization of the original granllllar l'or the string being 
parsed, and which directly generates tim deriwltion trees 
for this string relative to the ot t,q,," "'o'.aL grammar (Billot and 
Lang, 1989). 1 The generalization of this approach to uni- 
tication grammars (ot' the LFG or DCG type) proposed 
in (Dymemmn, 1997) shows that, in tt, rn, chart-parsing 
with these unilication grammars conducts naturally to 
packed representations for the parse results very close to 
the ones we are about to introduce. 
Let's consider the CFG Go: 
S~ SAW ()r~ Wnlt D3 
Saw -9 I)0 a.'gl01 i, arg2o:~ Lt<irr 
Lit;in' --4" O~H~n Inod27 light2 
Gi~lit~N --+ grcelll7 \[ green27 
O~ -9 on3 arg23a hill4 
W.ll -9 with5 a/g256 telcscope~i 
1)0 -9 seco\] sawo 
I)3 -9 modo3 D30 \[ mod.2a I)32 
D30 -4 modo5 \] mod4~ 
D32 -9 modo5 \] mod.2~ \] mod4~ 
Nontenninals of that grammar arc written in upper- 
case, terminals (which are graph description elements) in 
lowercase. It can be verified that the language generated 
by this grammar is the collection of commutative words 
IThis context-free grammar has polynomial size relative to the 
length of the string. While it is also possible in principle to use a linite- 
stale model for representing lhe sallle sel of derivation trees, it can be 
showll Ihal such at model may be exponential relative to string length 
(remark due to John Maxwell). 
1017 
corresponding precisely to all the possible analyses for 
the sentence. 
The fact that there are 20 such words can be es- 
tablished by a simple bottom-up computation i volving 
multiplications and sums. I1' we call ambiguity degree 
ad(N) of a nonterminal N tim ntunber of words it gen- 
erates, then it is obvious that, for instance, ad(D30) = 2, 
ad(D3) = 2+3, ad(S) = 4.1.1-5 = 20. In fact, it is the mul- 
tiplications which appear in such computations which are 
responsible for the compactness of the grammar as com- 
pared to the direct listing of the words: each time a mul- 
tiplication appears, a factorization is being cashed in. 2 
3 Transfer as language rewriting 
When working with non-ambiguous structures, transfer 
is a rewriting process which takes as input a source- 
language graph and constructs a target-language raph 
by applying transfer ules of the form lhs --4 rhs, where 
lhs and rhs are finite sets of description elements for 
source graph and target graph respectively. In outline, the 
"non-ambiguous" transfer process works in the Mlowing 
way: for each non-overlapping covering of the source 
graph with left-hand sides of transfer ules, the corre- 
sponding right-hand sides are produced and taken to- 
gether epresent a target graph (this is a non-deterministic 
ftmction as there can be several such coverings). 
In the case of ambigt, ous structures, the aim of transfer 
is to take as input a language of source graphs and to pro- 
duce a language of target graphs. The language of target 
graphs hould be equal to the union of all the graphs that 
would have obtained if one had enumerated one-by-one 
the source graphs, applied non-ambiguous transfer, and 
taken the collection of all target graphs obtained. The 
goal of ambiguous transfer is to perform the same task 
on the basis o1' a compact representation for the collec- 
tion of source graphs, yielding a compact representation 
for the collection of target graphs. 
For illustratkm purposes, we will consider the follow- 
ing collection of transfer ules: 
seeo --+ voitb, sawo -+ sciero, 
gl"eenl7 --+ Vel17, green27 -+ gazonT,  
light2, rood27, greenl7 --+ lcu2, rood'27, vcrlT, 
light2 --+ lumi&e2, etc. 
We have only listed a few rules, and have assumed that 
the remaining ones are straighlorward one-to-one corre- 
spondences (11 --+ jet, medea -+ mod'o3 \[we prime la- 
bels such as mod, argl .... in order to have disjointness of 
source and target vocabulary\], etc.)) 
2As the example shows, conlexl-flee representations of ambigu- 
ous slructures have the important properly (related to their inte,'aclion- 
freeness as described in the i,~troduction) of being easily "countable". 
This is to be contrasted with other possible representations forambigu- 
ous structures, uch as ones based on propositional xioms determining 
which desc,'iption elemenls can be jointly p,esent in a given analysis. 
In these representations, the problem of determining whether there ex- 
ists one structure satisfying the specification can be of high complexity, 
let alne the problem of counting such structures. 
3 In practice, real transfer rules are not specialized lbr specific nodes, 
but are panerns containing variables instead of imlnbers; in order to oh- 
4 Formal aspects 
The cotnmutative monoid over an alphabet A is denoted 
by C(~*),  and its words are represented by vectors of 
N A, indexed by ..4 and with entries ill N. For each w E 
N A, the c(mlponent indexed by a C ..4 is denoted by 
w\[,\] and tells how many a's occur in w. The product 
(concatenation) ofwl  and 'w2 in C(.A*) is the vector w E 
N A s.t. Vet C A: w\[,\] = wl \[,\] + "w2\[, 1. A language of 
the commutative monoid is a subset of C(A*). 
The subword relation is denoted by --<. For a language 
L, we write: v--<L iff there exists w E L s.t. v-<w. 
The rewriting is performed from a sourcc language ?s  
over an alphabet Es to a target language/27, over an al- 
Es)  w.r.t, a phabet ET (disjoint fi'om set of rewriting 
rules 7~ C P,s + x P'T* (rules have the form A-+p). We 
assume in the sequel that any a G ES appears at most 
once in any left-hand side of each rule of "R. and also at 
most once in any word of ?s .  This property is preserved 
by all the rewritings that we are going to int,'oduce. 
Let's deline LI tS(A-+p)  = A. For R C ~., we define 
L.,~&,(R) = {a E P's' \[ 3r e 17, s.t. et-e, LHS(, ' )  }. 
Tim rewriting is a l'unction qSre. taking ?,9 and yielding 
L;T, delined as: 
, / ,~(?s)  = {mp, ,  I ~,,  ~ ?s.,~,, = ,x~...%,/~ 
kl - -~'pl  G "J~ A ... A Ap'-q, flp G "R.}. 
5 Algorithm 
In order to implement he function ()n, it is useful to 
introduce rewriting functions q~--+t, and q~?r. They apply 
to any language L over C(E*), where E = Es, tO ET. 
They are detined as: 
~x-+,,(r) = {m" I aw C L} 
O~(L) = {w c L I ~v\[. 1 = 0}. 
The ~x-~p functions are applied so that source sym- 
bols are guaranteed to be removed one by one from ?.s': 
we consider E.s' is totally ordered by < and we write 
E.5' = \[(/,1, a2, ..., aN\], with ai < eti+l ; then consider the 
partition of 7~.: 7Zl, J~2 ..... T~N s.t.R.1 contains all ~. 
rules with al in LHS, "R.2 contains all 7? rules with a9 but 
not al in LHS, etc, "R.N contains all 7Z rules with only aN 
in LHS. Then we deline a third rewriting function q')7?~ : 
~l,,e, (L) = qSv(L) U U,.eT~, 4,.(c). 
Lemma. ?7' can be obtained l;'om ?s by applying the 
T~i iteratively in the following manner: 
~b~/~N ((/)'~N--I ( '" "{J)'\]~l (CS) ?" ")) = j~'\]'" 
PROOF SKETCII. For 1 _< j < N, we deline 
?'J = {p l ' ' 'ppx  \] ~*tJ E J~.S,z E ES*,p > O,w = 
At ' "  .Apa; ,Vk < p Ak-4 Ph. G Oi<_jT~i,Vi ~ j etiT~Z}. 
It is cleat" that ?N = ?T- Furthermore, we have L;1 = 
(/)'\]~1 (?S) ,  and it is easy to show that, for 2 _.5_ n < N, 
?n = ()'1?,~(/3,z-~). From this we have immediately 
CN = ~,~, (~,~_, (.. "~'~1 (Cs)-  . .) ) = Or.  
In order to obtain ?r ,  we will start from ?.s' and ac- 
tually apply the ~bTa~'s not on languages directly but on 
rain g,'otmd, rules, as the ones we are considering, a simple preproces,s ing, 
step is necessary. 
1018 
tim grmnnmrs that deline them. Tiffs computation is per- 
formed by the algorithm that we now present. 
Let/2~, be detined by the CFG Go = ()2, Ale, 7)o, So). 
For A G iV'o, the set o1' all rules having A as I.HS is no- 
tated A--> ~A-~a.<;% (t- This additive notation is a for- 
111111 represenlion of A-~cq I ct2 \] ... ltcnce A-+0 means 
that no rule delines A. 
First ()7,'.1 is @plied on Go, which builds G1 = 
(~l, Af:I, 791, ,91 ), Ihen ?-~= is applied on G1 to produce 
G:, and so forth. Each time, new non-terminals are in- 
troduced: of the form (A)-~,, (A),x-4o or (A)~r, where 
A ~ N' i -~, A G Ns +, p E NT*, and a G S,s. Each one 
is defined by a formal sum as we saw above. 
The order of symbols in the RHSs of grammar ules 
is irrelevant since we consider commutative languages. 
Hence the RHSs ot' grammar rt,les can be denoted by :c/3 
s.t. x ~ C(~*) and/':/ E C(N'*), where iV" is the set o1' 
all non-terminals considered. 
The algorithm consists of the procedure and functions 
described below and uses an agenda which contains Dew 
i~on-terminals to be defined in Gi. The agenda is handled 
with a table: each hen-terminal is treated once. 
procedure main is 
fo r i  G {1 , . . . ,N}  do 
Initialize 79i with 79i_~ ;
if "R,i # 0 then 
Initialize Agenda with (S i_  1 )7,LI ; 
repeat 
remove NonTerm l'ron~ Agenda; 
case NonTerm is 
when (A)7,,,~ : add to 79i 
when (A)x4t, :  add to "l~i 
(A )x -~.~ ~..~->,.:7,, , ,l~x-+~,(,~); 
when (A),: add to "Pi 
end case; 
until Agenda is empty 
Reduce Gi whose axiom is Si = (Si-~)n~ ; 
/:t:I'ClllOVC non-terminals that are non-praductive 
(? (A) = ~) or inaccessihle fi'om Si. */ 
end for; 
end procedure; 
flmction R'7,', (x{4) is// fl = At . . .Ak  
if ~j ~ {1, ..., k} s.t. Va E L,.,,&,('R.i), a-<?(Aj) 
/ / i f  all rewritings in "R.i can only q/.'/bct A.4 
then add (Aj)vv.i to Agenda; 
retnrn xAI"  ? "Aj-1 (Aj)vz~Aj+I ? ? .A~; 
el,;e return ,~(a ' f l )  + y~,,.~x., ~,,. (a'/~); 
end function; 
(1) 
(2) 
f lmction 'I,~(xfl) is//fl = At-.-A~. 
i f~j < {J,..., a:} s.t. a-<Z;(&) 
then/* j  is unique, see below*/add (Aj)~ t() Agenda; 
return :rA~-. "Aj-1 (Aj)~rAj+1-..A~.; (3) 
el,;e if a-qx then return O; 
else return xfl; 
end fimction; 
flmction ff'X-+p(a;fl) i~/ fl = A1. . .Ak 
//A is seamhed within a:AI. ? .-4k 
if ~j < {1, ..., k} s.t. Va-<k, a-<12(Aj) ~~if A falls 
//entirely within ?(  Aj ) then the rewriting applies only to A.i 
then add (Aj)>,--,,p to Agenda; 
return xA~. .  "Aj-1 (Aj), , ,~oAj+I ? - -Ak; (4) 
else//A is searched wilhin several symboLv 
Consider A = y,wa w.2.. "Wk s.t. 
- the longest common subword ot' x and ~ is y, 
-- V(t-d, Wj , (t...~?( A j  ) // wj is Aj contribution to A 
if such decomposition ofA exists//that is, it is 
//entirely covered by x and some Aj 's 
then/* it is mffque: see below */add to Agenda 
all (Aj)wj---}~ S.I. Wj ~ e; l/all those that contribute 
,-et,,,-,,.,./:j (FI,,,~#~ (Aj),~,-~) (Fiw,=, A;)/,;(5) 
//77te rewriting is actually cqqdied: y is deleted.fiom a:; 
//each contributing (i.e. non e) wj is to be deleted 
//(i.e. rewritten to e it, Aj); non-contributing Aj ' s  
//Jvntain tmtoudted; attd p is inserted. 
else//A cannot be pJvdtu'ed by xfl 
return O; ~~No Jvwriting is ~qqdicable 
end fnnctlon; 
Unicity o f j  in ffhr, and unicity of the sequence in ff,),+p: 
consider A-~a:XY7 C 79i-1 ; as each source symbol oc- 
curs at most once in every word of ?(S i -1) ,  the same 
holds for/_2(A) hence the sets of source symbols occur- 
ring in ?(X) an0 ?(Y)  are disioint. 
6 Example  
Consider ~2,s, = \[i~, green It, grccn27, seed .... \[ so that "R. 
is partitioned in ~.1 = {ij ~ je l  }, "R.2 = {green 17-+ VCl't7, 
grccnlr mod.27 light2-~lbu2 rood27 verl7}, etc. Each 
other "R.i contains a single rule. 
The lirst iteration of the algorithm computes the gram- 
mar Gt = ff"R., (Go). The resuh is: 
(So)?,h -+(S,xw)?q ()N Win, 1)3, 
(SAW)'p~, --+DO atglol ar, g2o2 L~,,r,.icl, 
gKillrl" ---)" Orl!,~N mod27 \]ight2, 
GRliI:N -+ gmen17 I gmcn2r, 
On --~ ona mg2a4 hill4, 
Wr,~ -+ with~, ar.g256 tclescopca, etc. 
We see that the only nonterminals which have been rede- 
fined are ,5' = ,5'o and Saw. The computation of (,5'o)~ 
has been done through step (I) in the algorithm. This is 
because the terminals in lefbhand skies of 77q, nmnely 
the single terminal i~, are all "concentrated" on the sin- 
gle nonterminal Saw on the right-hand side of St}. This 
leads in turn to a requirement for a definition of (Saw)hi, 
which is fulfilled by step (5) in the algorithm, at which 
time the rewriting of il intojel is performed. 
For any group of rules "R.i, as long as all terminals in 
the left-hand sides of rules ol"R.i a,'e thus concentrated on
at most one nonterminal in a right-hand side, no expan- 
sion of rules is necessary. It is only when the terminals 
start to be distributed on several RHS terminals or non- 
terminals that an expansion is required. 
This situatien is illustrated by the second iteration 
which maps G1 into (7, 2 = ,I,~,,. e((71). The result is: 
1019 
((S0)7~1)7?2 --+((Saw)rq )7?2 ON W,,'. D3, 
((SAw)~q)g2 -+DO argl01 rag202 (L,?;,r)r?2 jOh 
(L,t;,'r)~ 2 -+(GR,~,{N)~ mod.2r light.>, 
I (G'w.'~N)g,'ee,,tv-+,,e,',7 mod.2r light2, 
\[ (GR,~,~.Je,.ee,,tr-+, feu2 mo~gr vertr, 
(GRI~,!N)~ -+ green27 ON -+ o113 atg2a4 hill4, 
(Gl~l~N)gmenl7"-+ vertr -+ vertr W,,H -+ with~ arg256 telescope6, 
(GlmI{N)greenl7-+ e -+ e, etc. 
This time, the terminals in left-hand sides of T~2 are 
grcen l7, nlod27 and light> We first need to compute 
((S0)~)Tz=. Again, our three terminals are all con- 
centrated on (SAw)Tz~. We thus only have to definc 
((Saw)Tq)g2. Once again, the three terminals are con- 
centrated on L,~;,r,', and we have to define (L~.,)r?~. 
At this point, something interesting happens. It is not 
the case any more that one nonterminal on the right- 
hand side of the rule defining L~H.r concentrates all 
our terminals. In fact, G~H~ only "touches" grcen lT, 
but not the other two terminals. The algorithm then 
has recourse to step (2), which leads it to dctine three 
rules for (L~?;.,)r?=, involving recursive calls to ~I'gr~o,,~ ~ ,  
teenlT--f~ett7, ~} feet ~ , , The fi~st g. , . g ~lTmod271"gl t'2--+ feu2 mod27 vertT " ". 
of these calls involves step (3), the second, step (4), and 
the third, step (5), leading to the three exlmnsions shown 
for (L,?~.'r)Tz~, and eventually to the definitions for the 
three variants of the nonterminal GEN. 
The remaining iterations of the rewriting procedures 
arc of the same type as the first iteration. They lead fi- 
nally to a target grammar of the form: 
S'-+SAw' ON' Win( D3' SAw'-+D0' atgl{i 1 al~2to2 L,{m'/jel 
gIdlrr t -+aR,~*~d II10C~.27 \]tlllli~.rc2 
I GRH{N" I170~27 lumi&'e.2 
I f~lJ2 n\]0C~27 vert7 
Om:N' --+ gazon7 Wrm' ~ aVCC5 argO56 hmette6 
Gm.:I:N" --+ Vel't7 ON' --+ SUI'3 ~11"~'r'~34 colline4 
D30' -+ mo4.5 I mo4.5 D3' -+ ,no4a D30' \] mO4a D32' 
DO' -+ voiro I sciero D32' --+ mo~g~ I mo4~ I meal45 
which is only slightly less compact than the source gram- 
mar. It can be checked that this grammar enumerates 30 
target graphs, the difference of 10 with the source gram- 
mar being due to the addition of the French variant "feu 
vert" along with "lumi~re vcrte" for translating "green 
light". 
7 Conclusion 
We have presented a model and an algorithm for the 
transfer of packed linguistic representations based on 
the view that: (1) packed representations are best seen 
as context-free grammars over graph description ele- 
ments, an approach which permits factorization of com- 
mon parts while maintaining a transparent, easily com- 
putable, relationship to the set of structures represented 
(interaction-freeness, countability) 4, and (2) transfer is 
a rewriting process that takes as input such a context- 
free representation a d that outputs a target context-free 
4properties that we believe are essential to all such representations, 
whether they are made xplicit or not. 
representation which maintains these beneficial proper- 
tics. Although proofs have not been provided here, the 
algorithm can be shown to satisfy our initial formal def- 
inition of transfer as nondcterministic, exhaustive, non- 
overlapping replacement of description elements in the 
source structure by their counterparts as specilied in the 
rewriting rules. Tim method escribed in this paper bears 
some obvious analogy to the classical problem of map- 
ping a context-free language into another context-fi'ee 
language by way of a finite-state transducer (Harrison, 
1978). It would be an interesting research question to 
make this analogy formal, the main difference here be- 
ing the need to work with a commutative concatenation, 
as opposed to the standard non-commutative concatena- 
tion which is more directly connected with the automaton 
view of transductions. 
Acknowledgments 
Thanks to our colleagues Eric de la Clergerie, Max Copper- 
man, Andreas Eisele, Martin Emele, Anette Frank, Pierre Is- 
abelle, Ron Kaplan, Martin Kay, Berna~zl Lang, John Maxwell 
and Hadar Shemtov for extended iscussions and comments at 
various stages in the preparation of this paper. 
References 
S. Billet and B. Lang. 1989. The structure of shared forests in 
ambiguous parsing. In 27 th Meeting of the Association for 
Computational Lhlguistics. 
J. I)6rre. 1997. Efficient construction ofunderspecified seman- 
tics under massive ambiguity. In Prec. ACL, Madrid. 
M. Dymetman. 1997. Interaction-free grammars, chart- 
parsing, and the compact representation of ambiguity. In 
Prec. I.ICAI, Nagoya. 
Martin Emele and Michael l)orna. 1998. Ambiguity p,'eserv- 
ing machine translation using tracked representations. In
Proceedings of Coling-ACL '98, pages 365-371, Montreal, 
August. 
Anette Frank. 1999. From parallel grammar development to- 
wards machine translation. In Proceedings of MT Summit 
VII. MT hl the Great 7)'anslation Et:a, pages 134-142, Kent 
Ridge Digital Labs, Singapore, September. 
Michael A. ltarrison. 1978. hm-oduction to Formal Lcmguage 
Theoty. Addison-Wesley, Reading, MA. 
M. Kay, J.M. Gawron, and R Norvig. 1994. Verbmobih a 
translation system for face to fitce dialog. CSLI. 
Martin Kay. 1999. Chart translation. In Proceedings of MT 
Summit VII. MT in the Great 7)'anslation Era, pages 9-14, 
Kent Ridge Digital Labs, Singapore, September 
John Maxwell and Ronald Kaplan. 1991. A method for dis- 
junctive constraint satisfaction. In Masaru Tomita, editor, 
Current Issues in PatMng Technology. Kluwer, Dordrecht. 
John T. Maxwell and Ronald M. Kaplan. 1993. Tbe interface 
between phrasal and functional constraints. Computational 
Linguistics, 19(4):571-590, l)ecember. 
John T. Maxwell and Ronald M. Kaplan. 
1996. An efficient parser for LFG. In IO'twt 
LFG Colference, Grenoble, France, August. 
ht tp  : / /www-cs l i .  stanford ,  edu/user /mutt / .  
M. Rayner and P. Bouillon. 1995. Hybrid Transfer in an 
English-French Spoken Language Translator In Proceed- 
ings of lA '95, Montpellim, France, Jtme. 
H. Shemtov. 1997. Ambiguity Management hz Natural Lan- 
guage Generation. Ph.D. thesis, Stanford. 
1020 
Text Authoring, Knowledge Acquisition and Description Logics
Marc Dymetman
Xerox Research Centre Europe
6 chemin de Maupertuis
38240 Meylan
email: marc.dymetman@xrce.xerox.com
Abstract
We present a principled approach to the problem of con-
necting a controlled document authoring system with a
knowledge base. We start by describing closed-world au-
thoring situations, in which the knowledge base is used
for constraining the possible documents and orienting the
user?s selections. Then we move to open-world author-
ing situations in which, additionally, choices made dur-
ing authoring are echoed back to the knowledge base. In
this way the information implicitly encoded in a docu-
ment becomes explicit in the knowledge base and can be
re-exploited for simplifying the authoring of new doc-
uments. We show how a Datalog KB is sufficient for
the closed-world situation, while a Description Logic KB
is better-adapted to the more complex open-world situ-
ation. All along, we pay special attention to logically
sound solutions and to decidability issues in the different
processes.
Introduction
Recently there has been a surge of interest in interactive
natural language generation systems (Paris et al, 1995;
Power and Scott, 1998; Coch and Chevreau, 2001); such
systems rely on a capability of generating a natural lan-
guage text from an abstract content representation, but
? contrary to traditional NLG (Natural Language Gen-
eration) systems ? this representation is only partially
available at the beginning of the text production process;
it is then gradually completed by a human author, typ-
ically using content-selection menus correlated with re-
gions of the evolving generated text..
One such system, MDA (Multilingual Document Au-
thoring) (citation omitted) is based on a formal specifi-
cation ? using a variant of Definite Clause Grammars
(DCGs) (Pereira and Warren, 1980) ? of what counts
as a valid abstract content representation. The different
derivation trees in the grammar correspond to texts with
different contents, and at each step of the authoring pro-
cess the user is asked to make interactive choices on how
to expand the current partial derivation tree one step fur-
ther. There are important analogies between this process
and the process of authoring an XML document under
the control of a DTD or a Schema, but DCGs are more
expressive in terms of the contextual constraints that can
be expressed and also are more adapted to the production
of grammatical text.1
In published MDA work, all the knowledge about
what constitutes a valid document is provided in the
grammars, with no clear separation between (1) world
knowledge (the fact that a certain pharmaceutical drug
contains some molecule makes it dangerous for a certain
patient condition) and (2) constraints about document or-
ganization (if a certain drug is dangerous for a certain
condition, then a warning should be generated at a cer-
tain place in the document).
A more principled and modular solution is to leave
in the grammar all constraints pertaining to docu-
ment/textual organization, and to use an external logical
theory to express knowledge about the world described
by the documents. A document will then be constrained
to have a semantic interpretation that is compatible with
the external theory.
The aims of this paper are the following.
1. To provide a formally precise and computationally
tractable model for this approach. The logical the-
ory we will be using will take the form of a De-
scription Logic (DL) knowledge base (Donini et al,
1996); DLs are subsets of FOPC (First-Order Pred-
icate Calculus) which provide a trade-off between
expressivity and tractability (in particular decidabil-
ity) and have recently be given a lot of attention in
the knowledge representation community and in ac-
tivities around the Semantic Web. They are now
starting to attract attention in the computational lin-
guistics community as well (Gabsdil et al, 2001;
Striegnitz, 2001);
2. To show how this model can be used not only for
constraining the document during the authoring pro-
cess, but also to use the document as a source of new
knowledge to be added in a logically sound way to
the KB (knowledge acquisition);
3. To discuss conditions under which the whole pro-
cess of authoring is decidable.
1The grammars used in MDA are typically more ?semantically?
than ?syntactically? oriented, and a choice between two alternatives
for expanding a nonterminal in the grammar tends to correlate with a
clear distinction of meaning in the final text. A given grammar cov-
ers a semantically unified class of documents (e.g. employment offers,
drug package leaflets, etc.), in a way analogous to the customized XML
DTDs used for technical documentation.
The paper is organized as follows. We first describe
a class of situations, closed-world authoring, in which
the flow of information is strictly from the knowledge
base to the document. The MDA approach is briefly pre-
sented, and we show how the document specification can
be interfaced with an ?informationally complete? KB,
using a Datalog representation (Ceri et al, 1989); then
we present conditions on the specification which guar-
antee decidability of the closed-world authoring process,
that is, that guarantee that at each authoring step, the se-
lections presented to the author are ?real choices? which
will not result in dead-ends at a later stage of authoring.
We then move on to open-world authoring, in which the
flow of information is bi-directional between the KB and
the document. Now we start working with an ?informa-
tionally incomplete? KB, using a Description Logic rep-
resentation, which can be satisfied in several ?possible
worlds?; the document being authored has to be compat-
ible with at least one of these possible worlds. We give
conditions on the grammar which guarantee that, as long
as the DL on which the KB is built is intrinsically de-
cidable, then the authoring process as a whole is also de-
cidable. We introduce a notion of light semantics, which
corresponds to a restricted form of semantic interpreta-
tion for the document allowing exchange of information
between the document and the knowledge base and per-
mitting knowledge acquisition during the authoring pro-
cess. In particular the knowledge gained during the au-
thoring of a document can be re-used for simplifying the
authoring of other documents.
Closed-world authoring
MDA. We start by introducing briefly the MDA
framework through a simplified example. The focus of
this paper is on the document content aspects (as repre-
sented by what we call the abstract content tree) and not
on the textual realization aspects, which are handled in a
simplistic way here (see (citation omitted) for details on
MDA).
Grammar G1:
dfa1: dfa(D,F,A)  ?the drug?, drug(D),
?has the form of a?, dform(D,F),
?and is administered by?, dadm(D,A).
dform1: dform(D,F)  form(F), & df(D,F).
dadm1: dadm(D,A)  admin(A), comments(D,A).
coms1: comments(D,A)  ? ?, & da(D,A).
coms2: comments(D,A)  comments(D,A),
?;?, comment(D,A).
com1: comment(D,A)  ?strictly follow instructions?.
com2: comment(diprox,A)  ?take a glass of water?.
diprox: drug(diprox)  ?Diprox?.
xenor: drug(xenor)  ?Xenor?.
burpal: drug(burpal)  ?Burpal?.
tablet: form(tablet)  ?tablet?.
solution: form(solution)  ?solution?.
swallow: admin(swallow)  ?swallowing?.
chew: admin(chew)  ?chewing?.
drink: admin(drink)  ?drinking?.
Auxiliary clauses D1:
df(diprox,tablet).
df(xenor,tablet).
df(burpal,solution).
da(diprox,swallow).
da(xenor,chew).
da(burpal,drink).
The form of grammar G1 is a variant of the DCG for-
mat (Pereira and Warren, 1980): (1) each of the grammar
clauses is given a unique name (e.g. dfa1); (2) the nonter-
minals are notated in lowercase and are parameterized by
variable or ground terms; (3) the terminals are enclosed
in double quotes; (4) the auxiliary predicates (a.k.a. Pro-
log calls, usually enclosed in curly brackets) appear after
the ampersand sign.
Free generation. If we start from the initial nonter-
minal dfa(D,F,A) and expand it nondeterministically un-
til we get to terminal strings (so-called free generation
mode), we can obtain (among others) the texts:
(T1) ?the drug Diprox has the form of a tablet and is
administered by swallowing?,
(T2)?the drug Xenor has the form of a tablet and is
administered by chewing; strictly follow instructions?,
but not the text:
?the drug Burpal has the form of a tablet and is ad-
ministered by swallowing?.
Authoring. The authoring mode is different from
the free generation mode in that it gives the author the
responsibility of choosing expansions for nonterminals
rather than enumerating all possible expansions nonde-
terministically. Thus, after all the obligatory expan-
sions from dfa(D,F,A) (expansions for which there is only
one possibility in the grammar) have been done, the
frontier of the derivation tree contains some terminals
and the nonterminals drug(D), form(F), admin(A), com-
ments(D,A), and has to satisfy the constraint df(D,F). At
this point the user can freely choose which of these non-
terminals to expand next ? say form(F). There are two
possible ways to expand this nonterminal: through the
clause of name tablet or through the clause with name
solution, and the system displays to the user a menu list-
ing these two choices. Assume that the author chooses
tablet. The nonterminal form(F) is expanded into the ter-
minal ?tablet?, F is unified with tablet, and the process
is repeated until no more nonterminal needs to be ex-
panded.
At the end of this process, the collection of choices
that the user has made can be represented as a tree labeled
by names of clauses, for instance:
(AT1) dfa1(diprox, dform1(tablet), dadm1(swallow,coms1))
from which a complete derivation tree can be recon-
structed as well as the associated terminal string, which
in this case is seen to be equal to T1.
Such a tree of choices as AT1 will be called an ab-
stract content tree, or simply an abstract tree. Different
abstract trees correspond to different sets of choices of
content and also to different document instances in the
class of documents associated with the grammar. It is
then natural to see an abstract tree as a representation of
the content of a document belonging to that class.2
Life/death issues There is one important issue that
we did not discuss in the explanation just given, namely
how exactly the system determines which choices to pro-
pose to the user once he has selected a new nonterminal
to be expanded. One possibility is to present him with all
the possible names of clauses which are headed by the
nonterminal in question (as was done for form(F)), but
then it is possible that the author makes a choice that will
never lead to a complete valid document.
For instance, let us go back to the point just after
the author has chosen tablet as the clause for expand-
ing form(F); at this point the nonterminals on the fron-
tier of the derivation tree are: drug(D), admin(A), com-
ments(D,A), with the constraint df(D,tablet) in the back-
ground. Suppose the author next chooses to expand ad-
min(A); if the system was working in a naive fashion, it
would then display the choices swallow, chew, and drink.
However it is easy to see that drink is in fact ruled out as
a choice: any complete document would eventually have
to satisfy the constraints df(D,tablet) and da(D,drink), but
there is no drug in the database which is compatible with
both this form and this administration. We can say that
drink is a ?dead? choice in this context.
In order to prevent the author from entering a dead-
end, what is really needed is for the system to foresee
such possible clashes and to present to the author only
those choices which may eventually lead to a valid doc-
ument; in the case at hand, it should present the ?live?
choices swallow and chew.
Remark. When exactly one choice is possible, the
system should not even present any choice to the au-
thor, but make the only possible expansion decision on
its own: authoring should be done automatically at that
point. In these cases the authoring mode becomes closer
to the classical non-interactive NLG mode, and in the
limit, when knowledge-base inferences force all author-
ing choices, the two modes converge.
Finitely-parameterized grammars, Datalog, and
decidability of life/death In the current MDA system,
the method for determining whether a choice is live or
dead is incomplete. This is due to the fact that the non-
terminal parameters can be terms of arbitrary complex-
ity (built from variables, constants and functional sym-
bols) and then it is easy to simulate with a DCG an arbi-
trary Prolog program.3 Determining whether the initial
2This abstract tree approach to document content stems from the
work of Aarne Ranta on his ?Grammatical Framework (GF)? in which
he was inspired by the interactive proof editors in a higher-order
typed/functional setting such as ALF and COQ in which the user at-
tempts to build a proof of a formula through stepwise top-down refine-
ments of a partial proof (Ranta, 1999 ). In the present paper the abstract
trees can be seen as proofs of an initial goal in a logic programming set-
ting.
3Even without the use of auxiliary predicates: a pure Prolog pro-
gram is equivalent to a DCG generating empty strings.
nonterminal may lead to a complete valid document is
then undecidable in general. It is usually possible for the
grammar writer to exercise some care in designing the
grammars so that life/death problems do not hinder the
authoring process in practice, but a principled solution
would be preferable.
In order to tackle this problem, we will be making two
fundamental assumptions: (i) the nonterminal parame-
ters in the grammar clauses ? as well as the goal argu-
ments in the auxiliary program clauses ? are variables
or constants; (ii) all variables take their value in the fi-
nite set of constants present in the grammar and auxil-
iary clauses .
Under these assumptions, we are now dealing with a
DCG with finite-domainparameters both for its grammar
and for its auxiliary predicates components. The auxil-
iary predicate component is then formally the same as a
Datalog database (Ceri et al, 1989), as in our example
D1.4
We can then see the authoring model as consisting of
two components: a finitely parameterized DCG, and a
Datalog database.
Now, it is striking that, when working with finite-
domain DCGs, not only the auxiliary predicate compo-
nent, but also the grammar component, has formal simi-
larities to a Datalog base: in fact, if one ?forgets? in the
grammar G1 all the terminal strings, then one obtains a
Datalog program DP1:
DP1:
dfa1: dfa(D,F,A)  drug(D), dform(D,F), dadm(D,A).
dform1: dform(D,F)  form(F), & df(D,F).
dadm1: dadm(D,A)  admin(A), comments(D,A).
coms1: comments(D,A)  & da(D,A).
coms2: comments(D,A)  comments(D,A), com-
ment(D,A).
com1: comment(D,A).
com2: comment(diprox,A).
diprox: drug(diprox).
xenor: drug(xenor).
burpal: drug(burpal).
tablet: form(tablet).
solution: form(solution).
swallow: admin(swallow).
chew: admin(chew).
drink: admin(drink).
Deciding the productivity of a parameterized nonter-
minal in the combination G1+D1 is then formally equiv-
alent to proving it as a program goal in the combination
DP1+D1 (which is itself a global Datalog program), and
a derivation in G1 has a one-to-one correspondence to a
proof in DP1.
For instance, deciding the productivity of the nonter-
minal dfa(D,tablet,drink)is equivalent to proving the goal
dfa(D,tablet,drink) in the Datalog program DP1+D1: be-
4The database D1 only contains facts (Datalog?s EDB), but it could
also contain recursively defined predicates (Datalog?s IDB) without im-
pact on the discussion.
cause no such proof can be found, the nonterminal is not
productive.
Now, the interest of this translation is that provability
of a goal in a Datalog program is not only known to be
decidable, but also to be amenable to efficient implemen-
tation (Abiteboul et al, 1995).
Consider the situation discussed before, just after the
author has chosen the form tablet, and at the point where
the system needs to present him with a list of choices for
admin(A). At that point, the system is confronted with
the following question: what are the possible values for
A such that the following goal:
drug(D), admin(A), comments(D,A), df(D,tablet)
is satisfiable?
This question can be succinctly represented as the fol-
lowing conjunctive Datalog query:
answer(A)  drug(D), admin(A), com-
ments(D,A), df(D,tablet)
for which a number of optimization techniques exist
(see (Ceri et al, 1989; Abiteboul et al, 1995)), and
which returns as possible values for A the set fswallow,
chewg.5 The advantage for authoring is clear: at each
choice point, the system is capable to return a valid list
of choices more efficiently than by applying more naive
techniques. It is also worthy of note that some funda-
mental issues in authoring are so closely connected with
database query optimization.6 7
Open-world authoring
In an authoring context, some grammatically valid doc-
uments will never be authored because they do not cor-
respond to any possible state of affairs. Typically the
grammar specifies a much larger set of documents than
5In this case, the set of possible values for the parameterA coincides
with the set of possible values for the names of the expanding clauses
for admin(A). In general it is not the case, but it is simple to add a
parameter to each nonterminal that indexes its (finitely many) possible
expanding clauses.
6A DCG is nothing else than a context-free grammar with param-
eterized nonterminals and a unification mechanism between the pa-
rameters. Because of the analogy between DTD/Schemas and CFGs,
it seems likely that the same approach could be useful for extending
XML-based authoring through the use of finite-domain parameters and
unification.
7The fact that the program DP1 is equivalent to G1 as far as non-
terminal productivity is concerned does not mean that the two objects
are equivalent for authoring purposes. The grammar associates dif-
ferent texts with different derivations of the same ground nonterminal
(for instance, there are an infinite number of texts produced by com-
ments(diprox,tablet), corresponding to different combinations of
coms1, coms2, com1, com2.), whereas the program is of inter-
est to us here not in the different proofs of a given ground goal, but in
the fact that this goal is provable or not. Note that the clause of name
coms2 can be eliminated from the program DP1 without changing its
interpretation (because in order to provecomments(D,A) it requires
a proof of comments(D,A)), but making the program non-recursive
and therefore simplifying the check for productivity; eliminating the
same clause from G1 would however completely change the meaning
of the grammar.
the ones which are actually possible. If this were not the
case, then an author would not have to take the trouble to
direct the production process by making content choices
that he alone can make. That is to say, a document which
has actually been authored conveys more meaning than
just stating ?I am a valid document relative to the speci-
fication?. However, in a closed-world environment as we
have been discussing until now, that additional meaning
has no explicit counterpart in the knowledge-base; it is
only represented implicitly in the abstract content tree,
in a form which is not perspicuous and would be difficult
to re-use for the authoring of other documents or to share
with other processes.8
In a closed-world context, the KB constraints which
are tested during the authoring process are completely
passive: they are seen purely as validity checks against
the knowledge base.
By contrast, open-world authoring sees the KB con-
straints not only as checks, but also as conditions on the
world being described. When authoring a document, the
author is not neutrally picking out one of the documents
valid relative to the KB, but asserting that the constraints
do hold of the actual world.9
Let us illustrate this idea. We are now viewing the
formal specification of valid documents as consisting, as
before, of a grammar of the type previously described
(we will take again the grammar G1), but instead of a
Datalog database, we are now using an informationally
incomplete description logic knowledge base KB1:10
KB1:
TBOX:
TabletDrugs = df.ftabletg
SolutionDrugs = df.fsolutiong
SwallowDrugs = da.fswallowg
ChewDrugs = da.fchewg
DrinkDrugs = da.fdrinkg
Drugs = TabletDrugs  SolutionDrugs
Drugs = SwallowDrugs  ChewDrugs  DrinkDrugs
TabletDrugs = SwallowDrugs  ChewDrugs
SolutionDrugs = DrinkDrugs
ABOX :
df(burpal,solution)
da(burpal,drink)
This knowledge-base is written using a certain number
of DL constructors ? existential quantification, concept
8Note an analogy here with the Semantic Web perspective: tags
used in XML documents may convey implicit semantic information,
but in order to make this information sharable, it had better be repre-
sented explicitly in some formal knowledge representation.
9In the language of pragmatics, the author is then performing a
speech act by committing to the ?truth? of the document.
10An introduction to DLs would take us too far afield; let?s just say
that there is a whole family of DLs, which differ by the logical con-
structors they allow, and that most can be seen as decidable fragments
of first-order logic. An accessible recent introduction to DLs is avail-
able at http://www.cs.man.ac.uk/ horrocks/Slides/leipzig-jun-01.pdf .
enumeration, disjoint union (an abbreviation: A = BC
can be replaced by the two constraints A=BtC and BuC
= , and BCD is an abbreviation for (BC)D) ?,
and we are assuming the unique name convention (all
named individuals are different). The constructors which
are used place the knowledge base in the class ALCO
(Donini et al, 1996).
The TBOX can be glossed in the following way. The
TabletDrugs are those drugs D for which df(D,tablet), the
SolutionDrugs those drugs for which df(D,solution), ...,
the DrinkDrugs those drugs for which da(D,drink). The
drugs can come in either one of the two forms: tablet and
solution, and in either one of the three administrations
swallow, chew and drink. Finally TabletDrugs are either
swallow drugs or chew drugs, whereas SolutionDrugs are
always drink drugs. The ABOX says what we already
know about the form and administration of Burpal.
The list of relations in D1 is compatible with KB1:
indeed it is easy to see that one can obtain a model of
KB1 by taking the relations of D1 along with the facts:
diprox: TabletDrugs
xenor : TabletDrugs
burpal : SolutionDrugs
diprox: SwallowDrugs
xenor : ChewDrugs
burpal : DrinkDrugs
In a certain sense the TBOX of KB1 can be seen as
a conceptual schema for the database D1, which states
certain general relations about the forms and adminis-
trations of drugs, or about the uniqueness of form and
administration for a drug, but which does not say how
many drugs there are or what are the properties of these
drugs.
Valid abstract trees and incompleteKBs Let us re-
turn to our authoring example in this new context. We
now associate grammar G1 with KB1 instead of DB1.
We then make the assumption that all constant param-
eters appearing in the grammar (diprox, xenor, burpal,
tablet, etc.) are to be considered distinct named indi-
viduals for the KB, and that the constraint relations (da,
df) are all unary or binary and correspond to concepts or
roles in the KB.
Let?s now look again at the abstract tree AT1:
dfa1(diprox, dform1(tablet), dadm1(swallow,coms1))
This abstract tree is valid relative to G1 (it corresponds
to a possible complete derivation) but it is not necessarily
valid relative to the combination G1,KB1; this no-
tion is defined in the following way: because the abstract
tree uniquely determines the set of rules which have been
used for building the derivation, it also uniquely deter-
mines a set of associated KB constraints; thus AT1 is
associated with the set of constraints: fdf(diprox,tablet),
da(diprox,swallow)g.
Now we say that AT1 is valid relative to the combi-
nation G1,KB1 if and only if it is both valid rel-
ative to G1 and if its associated set of constraints is
compatible with KB1. In other words we need to show
that the addition of the two constraints df(diprox,tablet),
da(diprox,swallow) to the ABOX still leads to a satisfi-
able knowledge base. This can be shown by exhibiting
a model as we did a few paragraphs ago, and therefore
AT1 is a valid abstract tree relative to G1,KB1.
The informal reasoning by which we just showed the
satisfiability of KB1 extended with the two relations can
also be established by a computational proof, due to
the decidability of KB-consistency checking in ALCO
(Donini et al, 1996).
Open- vs. closed-world authoring, satisfiability vs.
deducibility Note that validity of an abstract tree in the
open-world authoring context involves the satisfiability
of a conjunction of constraints relative to the knowledge
base, whereas the notion of validity of an abstract tree in
the closed-world authoring context involves the dual no-
tion of deducibility of a conjunction of constraints rela-
tive to the knowledge-base (in the Datalog context, being
true in the minimal Herbrand model is the same as being
deducible from the Horn clauses constituting the base).
Decidability of the authoring process In order to
illustrate the process, let?s go back to the point in the au-
thoring after all obligatory expansions of dfa(D,F,A) have
been made, where the frontier of the derivation tree is
drug(D), form(F), admin(A), comments(D,A), and where
the user has chosen to expand form(F). There are appar-
ently two possible expansions: the clauses with names
tablet and solution. Before presenting these choices to the
user, the system must check that they are live, namely, as
before, that they may lead to a complete valid document.
Choosing the tablet expansion leads to the derivation
frontier drug(D), admin(A), comments(D,A) with con-
straint df(D,tablet). In order to decide whether the frontier
is live, the system needs to enumerate possible complete
derivations of this frontier until it finds one that is satis-
fiable relative to KB1 and then return a positive answer,
and if it does not find one, it should return a negative an-
swer. In principle, the enumeration could never stop, but
because of the finite parameter condition on the gram-
mar, the system has only to enumerate a finite number of
trees; this is because if a derivation tree is of the form
S(... A1(... A2(...) ...) ...) where S is a ground instan-
tiation of the initial nonterminal and A1 and A2 are the
same ground instantiation of a nonterminal (?repetitive
derivation?), then the satisfiability of S(... A1(... A2(...)
...) ...) relative to KB1 implies the satisfiability of S(...
A2(...) ...): a model of the larger derivation tree is again
a model of the smaller derivation tree. This means that
when checking life/death we do not ever need to consider
a repetitive derivation during the enumeration of deriva-
tions. In particular, because we are dealing with a finite
parameter domain, the derivations that we need to con-
sider have a bounded depth (otherwise we would neces-
sarily encounter repetitive situations), and the decidabil-
ity of the process follows.11
11The same reasoning could be made for proving decidability in the
In the case of choosing tablet, the abstract tree AT1 is
enumerated at some point in the process, and its satisfi-
ability relative to KB1 can be decidably checked: tablet
is then shown to be a live authoring choice. The same
process shows solution to be live.
Now, let?s go to the point where, after having chosen
tablet, the author decides to select an expansion for ad-
min(A). The derivation frontier is then drug(D), admin(A),
comments(D,A), with the constraint df(D,tablet), and the
apparently possible expansions are swallow, chew, and
drink. Both swallow and chew can be seen to be live
by a similar reasoning as before. In the case of drink,
we have to check whether the sequence drug(D), com-
ments(D,drink), with the constraint df(D,tablet) is live.
Let?s choose to expand comments(D,drink) first. The
expansion coms2 leads to a repetitive situation (com-
ments(D,drink) is above comments(D,drink) in the deriva-
tion path.) and is therefore discarded; the expansion
coms1 leads to the frontier drug(D), with the constraints
df(D,tablet) and da(D,drink). However the two constraints
cannot be simultaneously satisfied in KB1; This can be
shown computationally by using the satisfiability check
in KB1, but also by the following informal reasoning:
df(D,tablet) and da(D,drink) imply that D is both in Tablet-
Drugs and in DrinkDrugs; by the second fact it is in So-
lutionDrugs, but SolutionDrugs and TabletDrugs have an
empty intersection. Thus all expansions of comments
lead to invalidity; hence drink is not a live choice.
Open-World authoring and hybrid knowledge
bases The process that we have just described for find-
ing live selections, although decidable, is clearly not op-
timized. In the case of closed-world authoring that we
discussed at the beginning of this paper, we said that,
from the point of view of detecting life/death situations,
a Datalog program such as DP1 could be used in place of
the grammar G1, and that the combination of DP1 + D1
could be treated as a global Datalog database to which
standard query optimization techniques could be applied.
Is there some comparable possibility here? A clue comes
from the area of hybrid knowledge bases in the descrip-
tion logic community. Some researchers have shown that
by associating Description Logics with Datalog one can
significantly increase the expressive power of both for-
malisms, which have a nice complementarity (recursive
definitions can be easily expressed in Datalog, but not in
DLs; partial knowledge can be easily expressed in DLs,
but not in Datalog) (Levy and Rousset, 1996; Donini et
al., 1998). The open-authoring approach we propose has
strong connections with these hybrid knowledge-bases
(citation omitted) and it seems likely that optimization
techniques from that area may be transferred to our prob-
lem.
Light semantics and knowledge acquisition Let?s
step back and reconsider the rationale behind open-world
authoring. We are considering a situation in which there
is an ?actual world? which is not completely known ei-
closed-world case, instead of appealing there to the decidability of Dat-
alog queries.
ther to the knowledge base or to the author; however both
the KB and the author are supposed to have correct par-
tial knowledge about that world.
The system presents the author with a collection of
documents which, from its point of view, are compati-
ble with what it knows about the actual world. Among
these documents, the author picks (during the authoring
process) one document that, from his point of view, is
compatible with what he knows about the actual world.
So the author is not passively exploring the space of
document considered possible by the system (although
that could certainly be a nonstandard mode of operation
if the author takes a developer?s hat and wants to see what
the system believes is possible), but is actively commit-
ting to certain facts about the world.
What are these facts? What the author is produc-
ing is an abstract content tree, which corresponds to
a completely specific choice of expansion rules for the
nonterminals of the grammar. This means that the ab-
stract tree completely determines a set of associated
ground KB relations. For instance AT1 determines the
set fdf(diprox,tablet), da(diprox,swallow)g. These are the
facts that the author asserts to be true in the actual world.
Light semantics. Such facts are aspects of the doc-
ument content that the document ?exports? to the knowl-
edge base and thereby makes formally explicit. They
provide what we shall call a light semantics for the
document. In terms of light semantics, if we were
to build a standard logical form for the whole docu-
ment, for instance for AT1, that logical form would sim-
ply be the conjunction of the associated asserted facts
df(diprox,tablet) da(diprox,swallow). Light semantics
does not attempt to model the whole semantics of the
document (for instance, in our example, there is no ex-
plicit logical counterpart to the different choices for the
comment nonterminal), but focuses instead on model-
ing those parts of the document semantics that can be
tractably handled both by the knowledge representation
component and by the authoring process.12
Knowledge acquisition. Once the author has com-
mitted to a document, he has revealed a certain number
of facts that he knows about the actual world and that the
12When working in a more powerful framework for logical forms,
such as Montague semantics, the interpretation of a document may de-
pend in non-monotonic ways on the interpretations of its parts, as in
negated contexts: ?it is not the case that ...? or in opaque contexts:
?John believes that ...?. Predicting at authoring time which selections
are live relative to such a knowledge representation framework, while
possible in principle, seems to be a difficult research question. An-
other (orthogonal) argument in favor of light semantics is the fact that
if we consider the communicative role of a document inside a prede-
fined class of documents, then there is no point in formally representing
those parts of a document that are not contrastive between two docu-
ments in the class; for instance, there is no need to analyze the sentence
?Always ask your doctor?s advice in case of doubt? in any semantic de-
tail if it appears in all documents of the class: these semantic details are
irrelevant to the informational content of the document as opposed to
other documents of the class. A thorough discussion of this point, con-
nected to considerations of information theory, would bring us outside
the scope of this paper.
KB possibly did not ?know?. These facts (in our exam-
ple: df(diprox,tablet) and da(diprox,swallow)) can then be
added to the ABOX of the knowledge base, and can be
used either for their own sake (knowledge acquisition) or
in order to constrain the authoring of a new document.
So after the authoring of AT1, the ABOX of KB1 be-
comes:
ABOX :
df(burpal,solution)
da(burpal,drink)
df(diprox,tablet)
da(diprox,swallow)
Suppose now the user authors a new document, first
making a selection for drug(D), and choosing diprox.
Then the KB ?knows? that tablet is the only choice
for F and swallow the only choice for A. Indeed
they are possible choices (because df(diprox,tablet) and
da(diprox,swallow) are in the ABOX of the KB), but are
also the only choices, for diprox is now known to be in
TabletDrugs and in SwallowDrugs; it can therefore not
be in SolutionDrugs or in ChewDrugs or in DrinkDrugs,
which means that none of the facts df(dirprox,solution),
da(diprox,chew) or da(diprox,drink) may hold. After
the author?s choice of diprox, the derivation frontier
is form(F), admin(A), comments(diprox,A) with the con-
straint df(diprox,F). The author then chooses to ex-
pand form(F), and the system notices that the only
live choice is tablet, and performs this expansion with-
out asking the user. The frontier is now admin(A),
comments(diprox,A), with the constraint df(diprox,tablet).
Now the user can choose to expand admin(A), and
the only live choice is swallow. At that point the
frontier is comments(diprox,swallow) with the constraint
df(diprox,tablet). The author can then make choices
for comments(diprox,swallow) that lead to zero or sev-
eral instances of comment(diprox,swallow). At a certain
point he will choose the nonrecursive expansion com1,
which will lead to an empty frontier, with the constraints
df(diprox,tablet) and da(diprox,swallow).
We could obviously suppose here that rather than wait-
ing for the user to point to the nonterminal he wants to
expand next before finding the live choices for this non-
terminal, the system could find all the live choices for
all nonterminals on the frontier beforehand, and do the
obligatory expansions without any input from the user,
but at a slightly higher computational cost. In this way,
after the initial choice of diprox as the drug, the other
steps of the authoring process would be done automat-
ically, apart from the choice of how many (and which)
comments to make, which would still remain the respon-
sibility of the author.
Conclusion
In the course of the paper we have defined different no-
tions such as live-death issues in authoring processes,
closed-world versus open-world authoring, and light
document semantics. We have presented a formal ap-
proach to closed-world authoring that shows a correspon-
dence between life-death problems and conjunctive Dat-
alog queries, as well as a formal approach to open-world
document authoring based on Description Logics. We
have also sketched proofs of decidability for life/death is-
sues in these different processes. Finally we have shown
how an open-world authoring context can be used for
supporting a novel form of knowledge acquisition.
Acknowledgments
Many thanks to Jean-Marc Andre?oli, Caroline Brun, ?Eric
Fanchon, Pierre Isabelle, Aaron Kaplan, Aure?lien Max,
and Sylvain Pogodalla for discussions and comments,
and to the anonymous reviewers for suggestions on im-
proving the paper.
References
Serge Abiteboul, Richard Hull, and Victor Vianu. 1995. Foun-
dations of Databases. Addison-Wesley.
S. Ceri, G. Gottlob, and L. Tanca. 1989. Logic Programming
and Databases. Springer-Verlag.
Jose? Coch and Karine Chevreau. 2001. Interactive multi-
lingual generation. In A. Gelbukh, editor, Computational
Linguistics and Intelligent Text Processing, LNCS 2004.
Springer.
Francesco M. Donini, Maurizio Lenzerini, Daniele Nardi, and
Andrea Schaerf. 1996. Reasoning in description logics. In
Gerhard Brewka, editor, Principles of Knowledge Represen-
tation, pages 191?236. CSLI Publications, Stanford, Cali-
fornia.
Francesco M. Donini, Maurizio Lenzerini, Daniele Nardi, and
Andrea Schaerf. 1998. AL-log: Integrating datalog and de-
scription logics. Journal of Intelligent Information Systems,
10(3):227?252.
Marc Dymetman. 2002. Document content authoring and
hybrid knowledge bases. In Proceedings of the 9th In-
ternational Workshop on Knowledge Representation meets
Databases (KRDB-2002), Toulouse, April.
Malte Gabsdil, Alexander Koller, and Kristina Striegnitz.
2001. Building a text adventure on description logic. In
Proceedings of KI-2001 Workshop on Applications of De-
scription Logics, Vienna.
Alon Y. Levy and Marie-Christine Rousset. 1996. CARIN: A
representation language combining horn rules and descrip-
tion logics. In European Conference on Artificial Intelli-
gence, pages 323?327.
Ce?cile Paris, Keith Vander Linden, Markus Fischer, Anthony
Hartley, Lyn Pemberton, Richard Power, and Donia Scott.
1995. A Support Tool for Writing Multilingual Instruc-
tions. In Proceedings of the International Joint Conference
on Artificial Intelligence (IJCAI) 1995, pages 1398?1404,
Montre?al, Canada.
F. Pereira and D. Warren. 1980. Definite clauses for language
analysis. Artificial Intelligence, 13:231 ? 278, 1980.
Richard Power and Donia Scott. 1998. Multilingual authoring
using feedback texts. In COLING-ACL, pages 1053?1059.
Aarne Ranta. 1999?. Grammatical framework work page.
www.cs.chalmers.se/?aarne/GF/pub/work-index/index.html.
K. Striegnitz. 2001. Model checking for contextual reason-
ing in nlg. ICOS-3. Inference in Computational Semantics
Workshop. Siena.
195
196
197
198
Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 755?762, Vancouver, October 2005. c?2005 Association for Computational Linguistics
Translating with non-contiguous phrases
Michel Simard, Nicola Cancedda, Bruno Cavestro, Marc Dymetman,
Eric Gaussier, Cyril Goutte, Kenji Yamada
Xerox Research Centre Europe
FirstName.FamilyName@xrce.xerox.com
Philippe Langlais
RALI/DIRO Universite? de Montre?al
felipe@iro.umontreal.ca
Arne Mauser
RWTH Aachen University
arne.mauser@rwth-aachen.de
Abstract
This paper presents a phrase-based statis-
tical machine translation method, based
on non-contiguous phrases, i.e. phrases
with gaps. A method for producing such
phrases from a word-aligned corpora is
proposed. A statistical translation model
is also presented that deals such phrases,
as well as a training method based on the
maximization of translation accuracy, as
measured with the NIST evaluation met-
ric. Translations are produced by means of
a beam-search decoder. Experimental re-
sults are presented, that demonstrate how
the proposed method allows to better gen-
eralize from the training data.
1 Introduction
Possibly the most remarkable evolution of recent
years in statistical machine translation is the step
from word-based models to phrase-based models
(Och et al, 1999; Marcu and Wong, 2002; Yamada
and Knight, 2002; Tillmann and Xia, 2003). While
in traditional word-based statistical models (Brown
et al, 1993) the atomic unit that translation operates
on is the word, phrase-based methods acknowledge
the significant role played in language by multi-
word expressions, thus incorporating in a statistical
framework the insight behind Example-Based Ma-
chine Translation (Somers, 1999).
However, Phrase-based models proposed so far
only deal with multi-word units that are sequences
of contiguous words on both the source and the tar-
get side. We propose here a model designed to deal
with multi-word expressions that need not be con-
tiguous in either or both the source and the target
side.
The rest of this paper is organised as follows. Sec-
tion 2 provides motivations, definition and extrac-
tion procedure for non-contiguous phrases. The log-
linear conditional translation model we adopted is
the object of Section 3; the method used to train
its parameters is described in Section 4. Section 5
briefly describes the decoder. The experiments we
conducted to asses the effectiveness of using non-
contiguous phrases are presented in Section 6.
2 Non-contiguous phrases
Why should it be a good thing to use phrases
composed of possibly non-contiguous sequences of
words? In doing so we expect to improve trans-
lation quality by better accounting for additional
linguistic phenomena as well as by extending the
effect of contextual semantic disambiguation and
example-based translation inherent in phrase-based
MT. An example of a phenomenon best described
using non-contiguous units is provided by English
phrasal verbs. Consider the sentence ?Mary switches
her table lamp off?. Word-based statistical mod-
els would be at odds when selecting the appropri-
ate translation of the verb. If French were the target
language, for instance, corpus evidence would come
from both examples in which ?switch? is translated
as ?allumer? (to switch on) and as ?e?teindre? (to
switch off). If many-to-one word alignments are not
allowed from English to French, as it is usually the
755
2 31
Pierre
Pierre
ne mange pas
does not eat
Figure 1: An example of a complex alignment asso-
ciated with different syntax for negation in English
and French.
case, then the best thing a word-based model could
do in this case would be to align ?off? to the empty
word and hope to select the correct translation from
?switch? only, basically a 50-50 bet. While han-
dling inseparable phrasal verbs such as ?to run out?
correctly, previously proposed phrase-based models
would be helpless in this case. A comparable behav-
ior is displayed by German separable verbs. More-
over, non-contiguous linguistic units are not limited
to verbs. Negation is formed, in French, by inserting
the words ?ne? and ?pas? before and after a verb re-
spectively. So, the sentence ?Pierre ne mange pas?
and its English translation display a complex word-
level alignment (Figure 1) current models cannot ac-
count for.
Flexible idioms, allowing for the insertion of lin-
guistic material, are other phenomena best modeled
with non-contiguous units.
2.1 Definition and library construction
We define a bi-phrase as a pair comprising a source
phrase and a target phrase: b = ?s?, t??. Each of the
source and target phrases is a sequence of words and
gaps (indicated by the symbol ?); each gap acts as
a placeholder for exactly one unspecified word. For
example, w? = w1w2?w3?? w4 is a phrase of length
7, made up of two contiguous words w1 and w2, a
first gap, a third word w3, two consecutive gaps and
a final word w4. To avoid redundancy, phrases may
not begin or end with a gap. If a phrase does not
contain any gaps, we say it is contiguous; otherwise
it is non-contiguous. Likewise, a bi-phrase is said to
be contiguous if both its phrases are contiguous.
The translation of a source sentence s is produced
by combining together bi-phrases so as to cover the
source sentence, and produce a well-formed target-
language sentence (i.e. without gaps). A complete
translation for s can be described as an ordered se-
quence of bi-phrases b1...bK . When piecing together
the final translation, the target-language portion t?1
of the first bi-phrase b1 is first layed down, then each
subsequent t?k is positioned on the first ?free? posi-
tion in the target language sentence, i.e. either the
leftmost gap, or the right end of the sequence. Fig-
ure 2 illustrates this process with an example.
To produce translations, our approach therefore
relies on a collection of bi-phrases, what we call a
bi-phrase library. Such a library is constructed from
a corpus of existing translations, aligned at the word
level.
Two strategies come to mind to produce non-
contiguous bi-phrases for these libraries. The first is
to align the words using a ?standard? word aligne-
ment technique, such as the Refined Method de-
scribed in (Och and Ney, 2003) (the intersection of
two IBM Viterbi alignments, forward and reverse,
enriched with alignments from the union) and then
generate bi-phrases by combining together individ-
ual alignments that co-occur in the same pair of sen-
tences. This is the strategy that is usually adopted in
other phrase-based MT approaches (Zens and Ney,
2003; Och and Ney, 2004). Here, the difference is
that we are not restricted to combinations that pro-
duce strictly contiguous bi-phrases.
The second strategy is to rely on a word-
alignment method that naturally produces many-to-
many alignments between non-contiguous words,
such as the method described in (Goutte et al,
2004). By means of a matrix factorization, this
method produces a parallel partition of the two texts,
seen as sets of word tokens. Each token therefore
belongs to one, and only one, subset within this par-
tition, and corresponding subsets in the source and
target make up what are called cepts. For example,
in Figure 1, these cepts are represented by the circles
numbered 1, 2 and 3; each cept thus connects word
tokens in the source and the target, regardless of po-
sition or contiguity. These cepts naturally constitute
bi-phrases, and can be used directly to produce a bi-
phrase library.
Obviously, the two strategies can be combined,
and it is always possible to produce increasingly
large and complex bi-phrases by combining together
co-occurring bi-phrases, contiguous or not. One
problem with this approach, however, is that the re-
sulting libraries can become very large. With con-
756
danser le tango
to tango
I do not want to tango anymore
I do not want anymore
doI want
Je ne veux plus danser le tango
Je
I
ne plus
veux
wantdo
not anymore
I
source =
bi?phrase 1 =
bi?phrase 2 =
bi?phrase 3 =
bi?phrase 4 =
target =
Figure 2: Combining bi-phrases to produce a translation.
tiguous phrases, the number of bi-phrases that can
be extracted from a single pair of sentences typically
grows quadratically with the size of the sentences;
with non-contiguous phrases, however, this growth
is exponential. As it turns out, the number of avail-
able bi-phrases for the translation of a sentence has
a direct impact on the time required to compute the
translation; we will therefore typically rely on vari-
ous filtering techniques, aimed at keeping only those
bi-phrases that are more likely to be useful. For ex-
ample, we may retain only the most frequently ob-
served bi-phrases, or impose limits on the number of
cepts, the size of gaps, etc.
3 The Model
In statistical machine translation, we are given a
source language input sJ1 = s1...sJ , and seek the
target-language sentence tI1 = t1...tI that is its most
likely translation:
t?I1 = argmaxtI1Pr(t
I
1|s
J
1 ) (1)
Our approach is based on a direct approximation
of the posterior probability Pr(tI1|sJ1 ), using a log-
linear model:
Pr(tI1|s
J
1 ) =
1
ZsJ1
exp
(
M?
m=1
?mhm(t
I
1, s
J
1 )
)
In such a model, the contribution of each feature
function hm is determined by the corresponding
model parameter ?m; ZsJ1 denotes a normalization
constant. This type of model is now quite widely
used for machine translation (Tillmann and Xia,
2003; Zens and Ney, 2003)1.
Additional variables can be introduced in such a
model, so as to account for hidden characteristics,
and the feature functions can be extended accord-
ingly. For example, our model must take into ac-
count the actual set of bi-phrases that was used to
produce this translation:
Pr(tI1, b
K
1 |s
J
1 ) =
1
ZsJ1
exp
(
M?
m=1
?mhm(t
I
1, s
J
1 , b
K
1 )
)
Our model currently relies on seven feature func-
tions, which we describe here.
? The bi-phrase feature function hbp: it rep-
resents the probability of producing tI1 using
some set of bi-phrases, under the assump-
tion that each source phrase produces a target
phrase independently of the others:
hbp(t
I
1, s
J
1 , b
K
1 ) =
K?
k=1
logPr(t?k|s?k) (2)
Individual bi-phrase probabilities Pr(t?k|s?k)
are estimated based on occurrence counts in the
word-aligned training corpus.
? The compositional bi-phrase feature function
hcomp: this is introduced to compensate for
1Recent work from Chiang (Chiang, 2005) addresses simi-
lar concerns to those motivating our work by introducing a Syn-
chronous CFG for bi-phrases. If on one hand SCFGs allow to
better control the order of the material inserted in the gaps, on
the other gap size does not seem to be taken into account, and
phrase dovetailing such as the one involving ?do ?want? and
?not ???anymore? in Fig. 2 is disallowed.
757
hbp?s strong tendency to overestimate the prob-
ability of rare bi-phrases; it is computed as in
equation (2), except that bi-phrase probabilities
are computed based on individual word transla-
tion probabilities, somewhat as in IBM model
1 (Brown et al, 1993):
Pr(t?|s?) =
1
|s?||t?|
?
t?t?
?
s?s?
Pr(t|s)
? The target language feature function htl: this
is based on a N -gram language model of the
target language. As such, it ignores the source
language sentence and the decomposition of
the target into bi-phrases, to focus on the actual
sequence of target-language words produced
by the combination of bi-phrases:
htl(t
I
1, s
J
1 , b
K
1 ) =
I?
i=1
logPr(ti|t
i?1
i?N+1)
? The word-count and bi-phrase count feature
functions hwc and hbc: these control the length
of the translation and the number of bi-phrases
used to produce it:
hwc(tI1, s
J
1 , b
K
1 ) = I hbc(t
I
1, s
J
1 , b
K
1 ) = K
? The reordering feature function
hreord(tI1, s
J
1 , b
K
1 ): it measures the amount of
reordering between bi-phrases of the source
and target sentences.
? the gap count feature function hgc: It takes as
value the total number of gaps (source and tar-
get) within the bi-phrases of bK1 , thus allowing
the model some control over the nature of the
bi-phrases it uses, in terms of the discontigui-
ties they contain.
4 Parameter Estimation
The values of the ? parameters of the log-linear
model can be set so as to optimize a given crite-
rion. For instance, one can maximize the likely-
hood of some set of training sentences. Instead, and
as suggested by Och (2003), we chose to maximize
directly the quality of the translations produced by
the system, as measured with a machine translation
evaluation metric.
Say we have a set of source-language sentences
S. For a given value of ?, we can compute the set of
corresponding target-language translations T . Given
a set of reference (?gold-standard?) translations R
for S and a function E(T,R) which measures the
?error? in T relative to R, then we can formulate the
parameter estimation problem as2:
?? = argmin?E(T,R)
As pointed out by Och, one notable difficulty with
this approach is that, because the computation of T
is based on an argmax operation (see eq. 1), it is not
continuous with regard to ?, and standard gradient-
descent methods cannot be used to solve the opti-
mization. Och proposes two workarounds to this
problem: the first one relies on a direct optimiza-
tion method derived from Powell?s algorithm; the
second introduces a smoothed (continuous) version
of the error function E(T,R) and then relies on a
gradient-based optimization method.
We have opted for this last approach. Och shows
how to implement it when the error function can be
computed as the sum of errors on individual sen-
tences. Unfortunately, this is not the case for such
widely used MT evaluation metrics as BLEU (Pa-
pineni et al, 2002) and NIST (Doddington, 2002).
We show here how it can be done for NIST; a simi-
lar derivation is possible for BLEU.
The NIST evaluation metric computes a weighted
n-gram precision between T and R, multiplied by
a factor B(S, T,R) that penalizes short translations.
It can be formulated as:
B(S, T,R) ?
N?
n=1
?
s?S In(ts, rs)
?
s?S Cn(ts)
(3)
where N is the largest n-gram considered (usually
N = 4), In(ts, rs) is a weighted count of common
n-grams between the target (ts) and reference (rs)
translations of sentence s, and Cn(ts) is the total
number of n-grams in ts.
To derive a version of this formula that is a con-
tinuous function of ?, we will need multiple trans-
lations ts,1, ..., ts,K for each source sentence s. The
general idea is to weight each of these translations
2For the sake of simplicity, we consider a single reference
translation per source sentence, but the argument can easily be
extended to multiple references.
758
by a factor w(?, s, k), proportional to the score
m?(ts,k|s) that ts,k is assigned by the log-linear
model for a given ?:
w(?, s, k) =
[
m?(ts,k|s)
?
k? m?(ts,k? |s)
]?
where ? is the smoothing factor. Thus, in
the smoothed version of the NIST function, the
term In(ts, rs) in equation (3) is replaced by?
k w(?, s, k)In(ts,k, rs), and the term Cn(ts) is
replaced by
?
k w(?, s, k)Cn(ts,k). As for the
brevity penalty factor B(S, T,R), it depends on
the total length of translation T , i.e.
?
s |ts|. In
the smoothed version, this term is replaced by
?
s
?
k w(?, s, k)|ts,k|. Note that, when ? ? ?,
then w(?, s, k) ? 0 for all translations of s, except
the one for which the model gives the highest score,
and so the smooth and normal NIST functions pro-
duce the same value. In practice, we determine some
?good? value for ? by trial and error (5 works fine).
We thus obtain a scoring function for which we
can compute a derivative relative to ?, and which can
be optimized using gradient-based methods. In prac-
tice, we use the OPT++ implementation of a quasi-
Newton optimization (Meza, 1994). As observed by
Och, the smoothed error function is not convex, and
therefore this sort of minimum-error rate training is
quite sensitive to the initialization values for the ?
parameters. Our approach is to use a random set of
initializations for the parameters, perform the opti-
mization for each initialization, and select the model
which gives the overall best performance.
Globally, parameter estimation proceeds along
these steps:
1. Initialize the training set: using random pa-
rameter values ?0, for each source sentence of
some given set of sentences S, we compute
multiple translations. (In practice, we use the
M -best translations produced by our decoder;
see Section 5).
2. Optimize the parameters: using the method de-
scribed above, we find ? that produces the best
smoothed NIST score on the training set.
3. Iterate: we then re-translate the sentences of S
with this new ?, combine the resulting multiple
translations with those already in the training
set, and go back to step 2.
Steps 2 and 3 can be repeated until the smooothed
NIST score does not increase anymore3.
5 Decoder
We implemented a version of the beam-search stack
decoder described in (Koehn, 2003), extended to
cope with non-contiguous phrases. Each transla-
tion is the result of a sequence of decisions, each of
which involves the selection of a bi-phrase and of a
target position. The final result is obtained by com-
bining decisions, as in Figure 2. Hypotheses, cor-
responding to partial translations, are organised in a
sequence of priority stacks, one for each number of
source words covered. Hypotheses are extended by
filling the first available uncovered position in the
target sentence; each extended hypotheses is then
inserted in the stack corresponding to the updated
number of covered source words. Each hypothesis is
assigned a score which is obtained as a combination
of the actual feature function values and of admissi-
ble heuristics, adapted to deal with gaps in phrases,
estimating the future cost for completing a transla-
tion. Each stack undergoes both threshold and his-
togram pruning. Whenever two hypotheses are in-
distinguishable as far as the potential for further ex-
tension is concerned, they are merged and only the
highest-scoring is further extended. Complete trans-
lations are eventually recovered in the ?last? priority
stack, i.e. the one corresponding to the total num-
ber of source words: the best translation is the one
with the highest score, and that does not have any
remaining gaps in the target.
6 Evaluation
We have conducted a number of experiments to eval-
uate the potential of our approach. We were par-
ticularly interested in assessing the impact of non-
contiguous bi-phrases on translation quality, as well
as comparing the different bi-phrase library contruc-
tion strategies evoked in Section 2.1.
3It can be seen that, as the set of possible translations for
S stabilizes, we eventually reach a point where the procedure
converges to a maximum. In practice, however, we can usually
stop much earlier.
759
6.1 Experimental Setting
All our experiments focused exclusively on French
to English translation, and were conducted using the
Aligned Hansards of the 36th Parliament of Canada,
provided by the Natural Language Group of the USC
Information Sciences Institute, and edited by Ulrich
Germann. From this data, we extracted three dis-
tinct subcorpora, which we refer to as the bi-phrase-
building set, the training set and the test set. These
were extracted from the so-called training, test-1
and test-2 portions of the Aligned Hansard, respec-
tively. Because of efficiency issues, we limited our-
selves to source-language sentences of 30 words or
less. More details on the evaluation data is presented
in Table 14.
6.2 Bi-phrase Libraries
From the bi-phrase-building set, we built a number
of libraries. A first family of libraries was based on
a word alignment ?A?, produced using the Refined
method described in (Och and Ney, 2003) (com-
bination of two IBM-Viterbi alignments): we call
these the A libraries. A second family of libraries
was built using alignments ?B? produced with the
method in (Goutte et al, 2004): these are the B li-
braries. The most notable difference between these
two alignments is that B contains ?native? non-
contiguous bi-phrases, while A doesn?t.
Some libraries were built by simply extracting the
cepts from the alignments of the bi-phrase-building
corpus: these are the A1 and B1 libraries, and vari-
ants. Other libraries were obtained by combining
cepts that co-occur within the same pair of sen-
tences, to produce ?composite? bi-phrases. For in-
stance, the A2 libraries contain combinations of 1
or 2 cepts from alignment A; B3 contains combina-
tions of 1, 2 or 3 cepts, etc.
Some libraries were built using a ?gap-size? filter.
For instance library A2-g3 contains those bi-phrases
obtained by combining 1 or 2 cepts from alignment
A, and in which neither the source nor the target
phrase contains more than 3 gaps. In particular, li-
brary B1-g0 does not contain any non-contiguous
bi-phrases.
4Preliminary experiments on different data sets allowed us
to establish that 800 sentences constituted an acceptable size
for estimating model parameters. With such a corpus, the esti-
mation procedure converges after just 2 or 3 iterations.
Finally, all libraries were subjected to the same
two filtering procedures: the first excludes all bi-
phrases that occur only once in the training corpus;
the second, for any given source-language phrase,
retains only the 20 most frequent target-language
equivalents. While the first of these filters typically
eliminates a large number of entries, the second only
affects the most frequent source phrases, as most
phrases have less than 20 translations.
6.3 Experiments
The parameters of the model were optimized inde-
pendantly for each bi-phrase library. In all cases,
we performed only 2 iterations of the training proce-
dure, then measured the performance of the system
on the test set in terms of the NIST and BLEU scores
against one reference translation. As a point of com-
parison, we also trained an IBM-4 translation model
with the GIZA++ toolkit (Och and Ney, 2000), using
the combined bi-phrase building and training sets,
and translated the test set using the ReWrite decoder
(Germann et al, 2001)5.
Table 2 describes the various libraries that were
used for our experiments, and the results obtained
for each.
System/library bi-phrases NIST BLEU
ReWrite 6.6838 0.3324
A1 238 K 6.6695 0.3310
A2-g0 642 K 6.7675 0.3363
A2-g3 4.1 M 6.7068 0.3283
B1-g0 193 K 6.7898 0.3369
B1 267 K 6.9172 0.3407
B2-g0 499 K 6.7290 0.3391
B2-g3 3.3 M 6.9707 0.3552
B1-g1 206 K 6.8979 0.3441
B1-g2 213 K 6.9406 0.3454
B1-g3 218 K 6.9546 0.3518
B1-g4 222 K 6.9527 0.3423
Table 2: Bi-phrase libraries and results
The top part of the table presents the results for
the A libraries. As can be seen, library A1 achieves
approximately the same score as the baseline sys-
tem; this is expected, since this library is essentially
5Both the ReWrite and our own system relied on a trigram
language model trained on the English half of the bi-phrase
building set.
760
Subset sentences source words target words
bi-phrase-building set 931,000 17.2M 15.2M
training set 800 11,667 10,601
test set 500 6726 6041
Table 1: Data sets.
made up of one-to-one alignments computed using
IBM-4 translation models. Adding contiguous bi-
phrases obtained by combining pairs of alignments
does gain us some mileage (+0.1 NIST)6. Again, this
is consistent with results observed with other sys-
tems (Tillmann and Xia, 2003). However, the addi-
tion of non-contiguous bi-phrases (A2-g3) does not
seem to help.
The middle part of Table 2 presents analogous re-
sults for the corresponding B libraries, plus the B1-
g0 library, which contains only those cepts from the
B alignment that are contiguous. Interestingly, in
the experiments reported in (Goutte et al, 2004),
alignment method B did not compare favorably to A
under the widely used Alignment Error Rate (AER)
metric. Yet, the B1-g0 library performs better than
the analogous A1 library on the translation task.
This suggests that AER may not be an appropriate
metric to measure the potential of an alignment for
phrase-based translation.
Adding non-contiguous bi-phrases allows another
small gain. Again, this is interesting, as it sug-
gests that ?native? non-contiguous bi-phrases are in-
deed useful for the translation task, i.e. those non-
contiguous bi-phrases obtained directly as cepts in
the B alignment.
Surprisingly, however, combining cepts from the
B alignment to produce contiguous bi-phrases (B2-
G0) does not turn out to be fruitful. Why this
is so is not obvious and, certainly, more experi-
ments would be required to establish whether this
tendency continues with larger combinations (B3-
g0, B4-g0...). Composite non-contiguous bi-phrases
produced with the B alignments (B2-g3) seem
to bring improvements with regard to ?basic? bi-
phrases (B1), but it is not clear whether these are
significant.
6While the differences in scores in these and other experi-
ments are relatively small, we believe them to be significant, as
they have been confirmed systematically in other experiments
and, in our experience, by visual inspection of the translations.
Visual examination of the B1 library reveals
that many non-contiguous bi-phrases contain long-
spanning phrases (i.e. phrases containing long se-
quences of gaps). To verify whether or not these
were really useful, we tested a series of B1 libraries
with different gap-size filters. It must be noted that,
because of the final histogram filtering we apply on
libraries (retain only the 20 most frequent transla-
tions of any source phrase), library B1-g1 is not
a strict subset of B1-g2. Therefore, filtering on
gap-size usually represents a tradeoff between more
frequent long-spanning bi-phrases and less frequent
short-spanning ones.
The results of these experiments appear in the
lower part of Table 2. While the differences in score
are small, it seems that concentrating on bi-phrases
with 3 gaps or less affords the best compromise.
For small libraries such as those under consideration
here, this sort of filtering may not be very important.
However, for higher-order libraries (B2, B3, etc.) it
becomes crucial, because it allows to control the ex-
ponential growth of the libraries.
7 Conclusions
In this paper, we have proposed a phrase-based sta-
tistical machine translation method based on non-
contiguous phrases. We have also presented a esti-
mation procedure for the parameters of a log-linear
translation model, that maximizes a smooth version
of the NIST scoring function, and therefore lends
itself to standard gradient-based optimization tech-
niques.
From our experiments with these new methods,
we essentially draw two conclusions. The first and
most obvious is that non-contiguous bi-phrases can
indeed be fruitful in phrase-based statistical machine
translation. While we are not yet able to character-
ize which bi-phrases are most helpful, some of those
that we are currently capable of extracting are well
suited to cover some short-distance phenomena.
761
The second conclusion is that alignment quality is
crucial in producing good translations with phrase-
based methods. While this may sound obvious, our
experiments shed some light on two specific aspects
of this question. The first is that the alignment
method that produces the most useful bi-phrases
need not be the one with the best alignment error
rate (AER). The second is that, depending on the
alignments one starts with, constructing increasingly
large bi-phrases does not necessarily lead to better
translations. Some of our best results were obtained
with relatively small libraries (just over 200,000 en-
tries) of short bi-phrases. In other words, it?s not
how many bi-phrases you have, it?s how good they
are. This is the line of research that we intend to
pursue in the near future.
Acknowledgments
The authors are grateful to the anonymous reviewers
for their useful suggestions. 7
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The mathe-
matics of statistical machine translation: Parameter es-
timation. Computational Linguistics, 19(2):263?311.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the ACL, pages 263?270,
Ann Arbor, Michigan.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In Proc. ARPA Workshop on Human Lan-
guage Technology.
U. Germann, M. Jahr, K. Knight, D. Marcu, and K. Ya-
mada. 2001. Fast Decoding and Optimal Decoding
for Machine Translation. In Proceedings of ACL 2001,
Toulouse, France.
Cyril Goutte, Kenji Yamada, and Eric Gaussier. 2004.
Aligning words using matrix factorisation. In Proc.
ACL?04, pages 503?510.
Philipp Koehn. 2003. Noun Phrase Translation. Ph.D.
thesis, University of Southern California.
7This work was supported in part by the IST Programme
of the European Community, under the PASCAL Network of
Excellence, IST-2002-506778. This publication only reflects
the authors? views.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proc. of the Conf. on Empirical Methods in
Natural Language Processing (EMNLP 02), Philadel-
phia, PA.
J. C. Meza. 1994. OPT++: An Object-Oriented Class
Library for Nonlinear Optimization. Technical Report
SAND94-8225, Sandia National Laboratories, Albu-
querque, USA, March.
F. J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proceedings of ACL 2000, pages
440?447, Hongkong, China, October.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och and Hermann Ney. 2004. The Align-
ment Template Approach to Statistical Machine Trans-
lation. Computational Linguistics, 30(4):417?449.
Franz Josef Och, Christoph Tillmann, and Hermann Ney.
1999. Improved alignment models for statistical ma-
chine translation. In Proc. of the Joint Conf. on Em-
pirical Methods in Natural Language Processing and
Very Large Corpora (EMNLP/VCL 99), College Park,
MD.
Franz Och. 2003. Minimum error rate training in statis-
tical machine translation. In ACL?03: 41st Ann. Meet.
of the Assoc. for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
tion of machine translation. In Proceedings of the 40th
Annual Meeting of the ACL, pages 311?318, Philadel-
phia, USA.
Harold Somers. 1999. Review Article: Example-based
Machine Translation. Machine Translation, 14:113?
157.
Christoph Tillmann and Fei Xia. 2003. A phrase-based
unigram model for statistical machine translation. In
Proc. of the HLT-NAACL 2003 Conference, Edmonton,
Canada.
Kenji Yamada and Kevin Knight. 2002. A decoder for
syntax-based statistical MT. In Proc. of the 40th An-
nual Conf. of the Association for Computational Lin-
guistics (ACL 02), Philadelphia, PA.
Richard Zens and Hermann Ney. 2003. Improvements
in Phrase-Based Statistical Machine Translation. In
Proc. of the HLT-NAACL 2003 Conference, Edmonton,
Canada.
762
Towards Interactive Text Understanding 
Marc Dymetman* Aur?lien Max*+ Kenji Yamada* 
(*) Xerox Research Centre Europe, Grenoble  
(+) CLIPS-GETA, Universit? Joseph Fourier, Grenoble 
{marc.dymetman,aurelien.max,kenji.yamada@xrce.xerox.com} 
 
Abstract 
This position paper argues for an interactive 
approach to text understanding. The proposed 
model extends an existing semantics-based 
text authoring system by using the input text 
as a source of information to assist the user in 
re-authoring its content. The approach per-
mits a reliable deep semantic analysis by 
combining automatic information extraction 
with a minimal amount of human interven-
tion. 
1 Introduction 
Answering emails sent to a company by its cus-
tomers ? to take just one example among many 
similar text-processing tasks ? requires a reli-
able understanding of the content of incoming 
messages. This understanding can currently only 
be done by humans, and represents the main bot-
tleneck to a complete automation of the process-
ing chain: other aspects could be delegated to 
such procedures as database requests and text 
generation. Current technology in natural lan-
guage understanding or in information extraction 
is not at a stage where the understanding task can 
be accomplished reliably without human inter-
vention.  
In this paper, which aims at proposing a fresh 
outlook on the problem of text understanding 
rather than at describing a completed implemen-
tation, we advocate an interactive approach 
where:  
1. The building of the semantic representation 
is under the control of a human author;  
2. In order to build the semantic representa-
tion, the author interacts with an intuitive textual 
interface to that representation (obtained from it 
through an NLG process), where some ?active? 
regions of the text are associated with menus that 
display a number of semantic choices for incre-
menting the representation;  
3. The raw input text to be analyzed serves as 
a source of information to the authoring system 
and permits to associate likelihood levels with 
the various authoring choices; in each menu the 
choices are then ranked according to their likeli-
hood, allowing a speedier selection by the au-
thor; when the likelihood of a choice exceeds a 
certain threshold, this choice is performed auto-
matically by the system (but in a way that re-
mains revisable by the author).  
4. The system acts as a flexible understanding 
aid to the human operator: by tuning the thresh-
old at a low level, it can be used as a purely 
automatic, but somewhat unreliable, information 
extraction or understanding system; by tuning the 
threshold higher, it can be used as a powerful 
interactive guide to building a semantic interpre-
tation, with the advantage of a plain textual inter-
face to that representation that is easily 
accessible to general users. 
The paper is organized as follows. In section 
2, we present a document authoring system, 
MDA,  where the author constructs an internal 
semantic representation, but interacts with a tex-
tual realization of that representation. In section 
3, we explain how such a system may be ex-
tended into an Interactive Text Understanding 
(ITU) aid. A raw input document acts as an in-
formation source that serves to rank the choices 
proposed to the author according to their likeli-
hood of ?accounting? for information present in 
the input document. In section 4, we present cur-
rent work on using MDA for legacy-document 
normalization and show that this work can pro-
vide a first approach to an ITU implementation. 
In section 5, we indicate some links between 
these ideas and current work on interactive statis-
tical MT (TransType), showing directions to-
wards more efficient implementations of ITU. 
2 MDA: A semantics-based document au-
thoring system 
The MDA (Multilingual Document Authoring) 
system [Brun et al2000] is an instance (de-
scended from Ranta?s Grammatical Framework 
[Ranta 2002]) of a text-mediated interactive 
natural language generation system, a notion in-
troduced by [Power and Scott 1998] under the 
name of WYSIWYM. In such systems, an author 
gradually constructs a semantic representation, 
but rather than accessing the evolving representa-
tion directly, she actually interacts with a natural 
language text generated from the representation; 
some regions of the text are active, and corre-
spond to still unspecified parts of the representa-
tion; they are associated with menus presenting 
collections of choices for extending the semantic 
representation; the choices are semantically ex-
plicit and the resulting representation contains no 
ambiguities. The author thus has the feeling of 
only interacting with text, while in fact she is 
building a formal semantic object. One applica-
tion of this approach is in multilingual authoring: 
the author interacts with a text in her own lan-
guage, but the internal representation can be used 
to generate reliable translations in other lan-
guages. Fig. 1 gives an overview of the MDA 
architecture and Fig. 2 is a screenshot of the 
MDA interface. 
 
 
 
Fig. 1: Authoring in MDA. A ?semantic grammar? defines 
an enumerable collection of well-formed partial semantic 
structures, from which an output text containing active re-
gions is generated, with which the author interacts. 
 
 
 
 
Fig. 2: Snapshot of the MDA system applied to the author-
ing of drug leaflets.  
3 Interactive Text Understanding 
In the current MDA system, menu choices are 
ordered statically once and for all in the semantic 
grammar1. However, consider the situation of an 
author producing a certain text while using some 
input document as an informal reference source. 
It would be quite natural to assume that the au-
thoring system could use this document as a 
source of information in order to prime some of 
the menu choices.  
 
Thus, when authoring the description of a phar-
maceutical drug, the presence in the input docu-
ment of the words tablet and solution could serve 
to highlight corresponding choices in the menu 
corresponding to the pharmaceutical form of the 
drug. This would be relatively simple to do, but 
one could go further: rank menu choices and as-
sign them confidence weights according to tex-
tual and contextual hints found in the input 
document. When the confidence is sufficiently 
high, the choice could then be performed auto-
matically by the authoring system, which would 
produce a new portion of the output text, with the 
author retaining the ability of accepting or reject-
ing the system?s suggestion. In case the confi-
dence is not high enough, the author?s choice 
would still be sped up through displaying the 
most likely choices on top of the menu list. 
 
 
 
 
Fig. 3: Interactive Text Understanding. 
 
This kind of functionality is what we call a text-
mediated interactive text understanding system, 
or for short, an ITU system (see Fig. 3).2 
                                                          
1
 While the order between choices listed in a menu does not 
vary, certain choices may be filtered out depending on the 
current authoring context; this mechanism relies on unifica-
tion constraints in the semantic grammar.  
2
  Note that we do not demand that the semantic representa-
tion built with an ITU system be a complete representation 
of the input document, rather it can be a structured descrip-
tion of some thematic aspects of that document. Similarly, it 
is OK for the input document not to contain enough infor-
mation permitting the system or even the author to ?answer? 
certain menus: then some active regions of the output text 
remain unspecified. 
We will now consider some directions to im-
plement an ITU system.  
4 From document normalization to ITU 
A first route towards achieving an ITU system is 
through an extension of ongoing work on docu-
ment normalization [Max and Dymetman 2002, 
Max 2003]. The departure point is the following. 
Assume an MDA system is available for author-
ing a certain type of documents (for instance a 
certain class of drug leaflets), and suppose one is 
presented a ?legacy? document of the same type, 
that is, a document containing the same type of 
information, but produced independently of the 
MDA system; using the system, a human could 
attempt to ?re-author? the content of the input 
legacy document, thus obtaining a normalized 
version of it, as well as an associated semantic 
representation. 
An attempt to automate the re-authoring proc-
ess works as follows. Consider the virtual space 
of semantic representations enumerated by the 
MDA grammar. For each such representation, 
produce, through the standard MDA realization 
process3 a certain more or less rough ?descriptor? 
of what the input text should contain if its con-
tent should correspond to that semantic represen-
tation; then define a similarity measure between 
this descriptor and the input text; finally perform 
an admissible  heuristic search [Nilsson 1998] of 
the virtual space to find the semantics whose de-
scriptor has the best similarity with the input text. 
This architecture can accomodate more or less 
sophisticated descriptors: from bags of content-
words to be intersected with the input text, up to 
predicted ?top-down? predicate-argument tuples 
to be matched with ?bottom-up? tuples extracted 
from the input text through a rough information-
extraction process. 
Up to now the emphasis of this work has been 
more on automatic reconstruction of a legacy 
document than on interaction, but we have re-
cently started to think about adapting the ap-
proach to ITU. The heuristic search that we 
mentioned above associates with a menu choice 
an estimate of the best similarity score that could 
be obtained by some complete semantic structure 
extending that choice. It is then possible to rank 
choices according to that heuristic estimate (or 
some refinement of it obtained by deepening the 
                                                          
3
 Which was initially designed to produce parallel texts in 
several languages, but can be easily adapted to the produc-
tion of non-textual ?renderings? of the semantic representa-
tions. 
search a few steps down the line), and then to 
propose to the author a re-ranked menu. 
While we are currently pursuing this promis-
ing line of research because of its conceptual and 
algorithmic simplicity, it has some weaknesses. 
It relies on similarity scores between an input 
text and a descriptor that are defined in a some-
what ad hoc manner, it depends on parameters 
that are fixed a priori rather than by training, and 
it is difficult to associate with confidence levels 
having a clear interpretation.  
A way of solving these problems is to move 
towards a more probabilistic approach that com-
bines advantages of being built on accepted prin-
ciples and of having a well-developed learning 
theory. We finally turn our attention to existing 
work in this area that holds promise for improv-
ing ITU. 
5 Towards statistical ITU 
Recent research on the interactive statistical ma-
chine translation system TransType [Foster et al 
1997; Foster et al 2002] holds special interest in 
relation to ITU. This system, outlined in Fig. 4, 
aims at helping a translator type her (uncon-
strained) translation of a source text by predict-
ing sequences of characters that are likely to 
follow already typed characters in the target text; 
this prediction is done on the basis of informa-
tion present in the source text. The approach is 
similar to standard statistical MT4, but instead of 
producing one single best translation, the system 
ranks several completion proposals according to 
a probabilistic confidence measure and uses this 
measure to optimize the length of completions 
proposed to the translator for validation. Evalua-
tions of the first version of TransType have al-
ready shown significant gains in terms of the 
number of keystrokes needed for producing a 
translation, and work is continuing for making 
the approach effective in real translation envi-
ronments. 
 
If we now compare Fig. 3 and Fig. 4, we see 
strong parallels between TransType and ITU: 
language model enumerating word sequences vs 
                                                          
4
 Initially statistical MT used a noisy-channel approach 
[Brown et al 1993]; but recently [Och and Ney 2002] have 
introduced a more general framework based on the maxi-
mum-entropy principle, which shows nice prospects in 
terms of flexibility and learnability. An interesting research 
thread is to use more linguistic structure in a statistical 
translation model [Yamada and Knight 2001], which has 
some relevance to ITU since we need to handle structured 
semantic data. 
grammar enumerating semantic structures, 
source text vs input text as information sources, 
match between source text and target text vs 
match between input text and semantic structure. 
In TransType the interaction is directly with the 
target text, while in ITU the interaction with the 
semantic structure is mediated through an output 
text realization of that structure. We can thus 
hope to bring some of the techniques developed 
for TransType to ITU, but let us note that some 
of the challenges are different: for instance train-
ing the semantic grammars in ITU cannot be 
done on a directly observable corpus of texts.5  
 
 
 
Fig. 4: TransType. 
6 Conclusion 
We have introduced an interactive approach to 
text understanding, based on an extension to the 
MDA document authoring system. ITU at this 
point is more a research program than a com-
pleted realization. However we think it repre-
sents an exciting direction towards permitting a 
reliable deep semantic analysis of input docu-
ments by complementing automatic information 
                                                          
5
 Let us briefly mention that we are not the first to note for-
mal connections between natural language understanding 
and statistical MT. Thus, [Epstein 1996], working in a non-
interactive framework, draws the following parallel between 
the two tasks: while in MT, the aim is to produce a target 
text from a source text, in NLU, the aim is to produce a 
semantic representation from an input text. He then goes on 
to adapt the conventional noisy channel MT model of 
[Brown et al1993] to NLU, where extracting a semantic 
representation from an input text corresponds to finding: 
argmax(Sem) {p(Input|Sem) p(Sem)}, where p(Sem) is a 
model for generating semantic representations, and 
p(Input|Sem) is a model for the relation between semantic 
representations and corresponding texts. See also [Berger 
and Lafferty 1999] and [Knight and Marcu 2002] for paral-
lels between statistical MT and Information Retrieval and 
Summarization respectively. On a different plane, in the 
context of interactive NLG, [Nickerson 2003] has recently 
proposed to rank semantic choices according to probabilities 
estimated from a corpus; but here the purpose is not text 
understanding, but improving the speed of authoring a new 
document from scratch. 
extraction with a minimal amount of human in-
tervention for those aspects of understanding that 
presently resist automation. 
Acknowledgements 
Thanks for discussions and advice to C. Boitet, 
C. Brun, E. Fanchon, E. Gaussier, P. Isabelle, G. 
Lapalme, V. Lux and S. Pogodalla. 
References 
[Berger and Lafferty 1999] Information Retrieval as 
Statistical Translation, SIGIR-99 
[Brown, Della Pietra, Della Pietra and Mercer 1993] 
The Mathematics of Statistical Machine Transla-
tion: Parameter Estimation. Computational Linguis-
tics 19(2), 1993  
[Brun, Dymetman and Lux 2000]. Document Struc-
ture and Multilingual Text Authoring, INLG-2000 
[Epstein 1996] Statistical Source Channel Models for 
Natural Language Understanding, PhD Thesis, New 
York University, 1996.  
[Foster, Isabelle and Plamondon, 1997] Target-Text 
Mediated Interactive Machine Translation, Machine 
Translation, 12:1-2, 175-194, Dordrecht, Kluwer, 
1997. 
[Foster, Langlais and Lapalme, 2002] User-Friendly 
Text Prediction for Translators, EMNLP-02 
[Knight and Marcu 2002] Summarization beyond 
sentence extraction: A Probabilistic Approach to 
Sentence Compression, Artificial Intelligence, 
139(1), 2002.   
[Max and Dymetman 2002] Document Content 
Analysis through Fuzzy Inverted Generation, in 
AAAI 2002 Spring Symposium on Using (and Ac-
quiring) Linguistic (and World) Knowledge for In-
formation Access, 2002 
[Max 2003]. Reversing Controlled Document Author-
ing to Normalize Documents. In the proceedings of 
the EACL-03 Student Research Workshop, 2003 
[Nickerson 2003]. Statistical Models for Organizing 
Semantic Options in Knowledge Editing Interfaces. 
In AAAI Spring Symposium workshop on natural 
language generation in spoken and written dialogue, 
2003.  
[Nilsson 1998] Artificial Intelligence: a New Synthe-
sis. Morgan Kaufmann, 1998. 
[Och and Ney 2002] Discriminative Training and 
Maximum Entropy Models for Statistical Machine 
Translation, ACL02 
[Power and Scott 1998] Multilingual Authoring using 
Feedback Texts. COLING/ACL-98. 
[Ranta 2002] Grammatical Framework: A Type-
Theoretical Grammar Formalism, Journal of Func-
tional Programming, September 2002. 
[Yamada and Knight 2001] A Syntax-based Transla-
tion Model, ACL-01. 
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 333?341,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Phrase-Based Statistical Machine Translation as a Traveling Salesman
Problem
Mikhail Zaslavskiy? Marc Dymetman Nicola Cancedda
Mines ParisTech, Institut Curie Xerox Research Centre Europe
77305 Fontainebleau, France 38240 Meylan, France
mikhail.zaslavskiy@ensmp.fr {marc.dymetman,nicola.cancedda}@xrce.xerox.com
Abstract
An efficient decoding algorithm is a cru-
cial element of any statistical machine
translation system. Some researchers have
noted certain similarities between SMT
decoding and the famous Traveling Sales-
man Problem; in particular (Knight, 1999)
has shown that any TSP instance can be
mapped to a sub-case of a word-based
SMT model, demonstrating NP-hardness
of the decoding task. In this paper, we fo-
cus on the reverse mapping, showing that
any phrase-based SMT decoding problem
can be directly reformulated as a TSP. The
transformation is very natural, deepens our
understanding of the decoding problem,
and allows direct use of any of the pow-
erful existing TSP solvers for SMT de-
coding. We test our approach on three
datasets, and compare a TSP-based de-
coder to the popular beam-search algo-
rithm. In all cases, our method provides
competitive or better performance.
1 Introduction
Phrase-based systems (Koehn et al, 2003) are
probably the most widespread class of Statistical
Machine Translation systems, and arguably one of
the most successful. They use aligned sequences
of words, called biphrases, as building blocks for
translations, and score alternative candidate trans-
lations for the same source sentence based on a
log-linear model of the conditional probability of
target sentences given the source sentence:
p(T, a|S) = 1ZS
exp
?
k
?khk(S, a, T ) (1)
where the hk are features, that is, functions of the
source string S, of the target string T , and of the
? This work was conducted during an internship at
XRCE.
alignment a, where the alignment is a representa-
tion of the sequence of biphrases that where used
in order to build T from S; The ?k?s are weights
and ZS is a normalization factor that guarantees
that p is a proper conditional probability distri-
bution over the pairs (T,A). Some features are
local, i.e. decompose over biphrases and can be
precomputed and stored in advance. These typ-
ically include forward and reverse phrase condi-
tional probability features log p(t?|s?) as well as
log p(s?|t?), where s? is the source side of the
biphrase and t? the target side, and the so-called
?phrase penalty? and ?word penalty? features,
which count the number of phrases and words in
the alignment. Other features are non-local, i.e.
depend on the order in which biphrases appear in
the alignment. Typical non-local features include
one or more n-gram language models as well as
a distortion feature, measuring by how much the
order of biphrases in the candidate translation de-
viates from their order in the source sentence.
Given such a model, where the ?i?s have been
tuned on a development set in order to minimize
some error rate (see e.g. (Lopez, 2008)), together
with a library of biphrases extracted from some
large training corpus, a decoder implements the
actual search among alternative translations:
(a?, T ?) = arg max
(a,T )
P (T, a|S). (2)
The decoding problem (2) is a discrete optimiza-
tion problem. Usually, it is very hard to find the
exact optimum and, therefore, an approximate so-
lution is used. Currently, most decoders are based
on some variant of a heuristic left-to-right search,
that is, they attempt to build a candidate translation
(a, T ) incrementally, from left to right, extending
the current partial translation at each step with a
new biphrase, and computing a score composed of
two contributions: one for the known elements of
the partial translation so far, and one a heuristic
333
estimate of the remaining cost for completing the
translation. The variant which is mostly used is
a form of beam-search, where several partial can-
didates are maintained in parallel, and candidates
for which the current score is too low are pruned
in favor of candidates that are more promising.
We will see in the next section that some char-
acteristics of beam-search make it a suboptimal
choice for phrase-based decoding, and we will
propose an alternative. This alternative is based on
the observation that phrase-based decoding can be
very naturally cast as a Traveling Salesman Prob-
lem (TSP), one of the best studied problems in
combinatorial optimization. We will show that this
formulation is not only a powerful conceptual de-
vice for reasoning on decoding, but is also prac-
tically convenient: in the same amount of time,
off-the-shelf TSP solvers can find higher scoring
solutions than the state-of-the art beam-search de-
coder implemented in Moses (Hoang and Koehn,
2008).
2 Related work
Beam-search decoding
In beam-search decoding, candidate translation
prefixes are iteratively extended with new phrases.
In its most widespread variant, stack decoding,
prefixes obtained by consuming the same number
of source words, no matter which, are grouped to-
gether in the same stack1 and compete against one
another. Threshold and histogram pruning are ap-
plied: the former consists in dropping all prefixes
having a score lesser than the best score by more
than some fixed amount (a parameter of the algo-
rithm), the latter consists in dropping all prefixes
below a certain rank.
While quite successful in practice, stack decod-
ing presents some shortcomings. A first one is that
prefixes obtained by translating different subsets
of source words compete against one another. In
one early formulation of stack decoding for SMT
(Germann et al, 2001), the authors indeed pro-
posed to lazily create one stack for each subset
of source words, but acknowledged issues with
the potential combinatorial explosion in the num-
ber of stacks. This problem is reduced by the use
of heuristics for estimating the cost of translating
the remaining part of the source sentence. How-
1While commonly adopted in the speech and SMT com-
munities, this is a bit of a misnomer, since the used data struc-
tures are priority queues, not stacks.
ever, this solution is only partially satisfactory. On
the one hand, heuristics should be computationally
light, much lighter than computing the actual best
score itself, while, on the other hand, the heuris-
tics should be tight, as otherwise pruning errors
will ensue. There is no clear criterion to guide
in this trade-off. Even when good heuristics are
available, the decoder will show a bias towards
putting at the beginning the translation of a certain
portion of the source, either because this portion
is less ambiguous (i.e. its translation has larger
conditional probability) or because the associated
heuristics is less tight, hence more optimistic. Fi-
nally, since the translation is built left-to-right the
decoder cannot optimize the search by taking ad-
vantage of highly unambiguous and informative
portions that should be best translated far from the
beginning. All these reasons motivate considering
alternative decoding strategies.
Word-based SMT and the TSP
As already mentioned, the similarity between
SMT decoding and TSP was recognized in
(Knight, 1999), who focussed on showing that
any TSP can be reformulated as a sub-class of the
SMT decoding problem, proving that SMT decod-
ing is NP-hard. Following this work, the exis-
tence of many efficient TSP algorithms then in-
spired certain adaptations of the underlying tech-
niques to SMT decoding for word-based models.
Thus, (Germann et al, 2001) adapt a TSP sub-
tour elimination strategy to an IBM-4 model, us-
ing generic Integer Programming techniques. The
paper comes close to a TSP formulation of de-
coding with IBM-4 models, but does not pursue
this route to the end, stating that ?It is difficult
to convert decoding into straight TSP, but a wide
range of combinatorial optimization problems (in-
cluding TSP) can be expressed in the more gen-
eral framework of linear integer programming?.
By employing generic IP techniques, it is how-
ever impossible to rely on the variety of more
efficient both exact and approximate approaches
which have been designed specifically for the TSP.
In (Tillmann and Ney, 2003) and (Tillmann, 2006),
the authors modify a certain Dynamic Program-
ming technique used for TSP for use with an IBM-
4 word-based model and a phrase-based model re-
spectively. However, to our knowledge, none of
these works has proposed a direct reformulation
of these SMT models as TSP instances. We be-
lieve we are the first to do so, working in our case
334
with the mainstream phrase-based SMT models,
and therefore making it possible to directly apply
existing TSP solvers to SMT.
3 The Traveling Salesman Problem and
its variants
In this paper the Traveling Salesman Problem ap-
pears in four variants:
STSP. The most standard, and most studied,
variant is the Symmetric TSP: we are given a non-
directed graph G on N nodes, where the edges
carry real-valued costs. The STSP problem con-
sists in finding a tour of minimal total cost, where
a tour (also called Hamiltonian Circuit) is a ?cir-
cular? sequence of nodes visiting each node of the
graph exactly once;
ATSP. The Asymmetric TSP, or ATSP, is a vari-
ant where the underlying graph G is directed and
where, for i and j two nodes of the graph, the
edges (i,j) and (j,i) may carry different costs.
SGTSP. The Symmetric Generalized TSP, or
SGTSP: given a non-oriented graph G of |G|
nodes with edges carrying real-valued costs, given
a partition of these |G| nodes into m non-empty,
disjoint, subsets (called clusters), find a circular
sequence of m nodes of minimal total cost, where
each cluster is visited exactly once.
AGTSP. The Asymmetric Generalized TSP, or
AGTSP: similar to the SGTSP, but G is now a di-
rected graph.
The STSP is often simply denoted TSP in the
literature, and is known to be NP-hard (Applegate
et al, 2007); however there has been enormous
interest in developing efficient solvers for it, both
exact and approximate.
Most of existing algorithms are designed for
STSP, but ATSP, SGTSP and AGTSP may be re-
duced to STSP, and therefore solved by STSP al-
gorithms.
3.1 Reductions AGTSP?ATSP?STSP
The transformation of the AGTSP into the ATSP,
introduced by (Noon and Bean, 1993)), is illus-
trated in Figure (1). In this diagram, we assume
that Y1, . . . , YK are the nodes of a given cluster,
while X and Z are arbitrary nodes belonging to
other clusters. In the transformed graph, we in-
troduce edges between the Yi?s in order to form a
cycle as shown in the figure, where each edge has
a large negative cost ?K. We leave alone the in-
coming edge to Yi from X , but the outgoing edge
Figure 1: AGTSP?ATSP.
from Yi to X has its origin changed to Yi?1. A
feasible tour in the original AGTSP problem pass-
ing through X,Yi, Z will then be ?encoded? as a
tour of the transformed graph that first traverses
X , then traverses Yi, . . . , YK , . . . , Yi?1, then tra-
verses Z (this encoding will have the same cost as
the original cost, minus (k ? 1)K). Crucially, if
K is large enough, then the solver for the trans-
formed ATSP graph will tend to traverse as many
K edges as possible, meaning that it will traverse
exactly k ? 1 such edges in the cluster, that is, it
will produce an encoding of some feasible tour of
the AGTSP problem.
As for the transformation ATSP?STSP, several
variants are described in the literature, e.g. (Ap-
plegate et al, 2007, p. 126); the one we use is from
(Wikipedia, 2009) (not illustrated here for lack of
space).
3.2 TSP algorithms
TSP is one of the most studied problems in com-
binatorial optimization, and even a brief review of
existing approaches would take too much place.
Interested readers may consult (Applegate et al,
2007; Gutin, 2003) for good introductions.
One of the best existing TSP solvers is imple-
mented in the open source Concorde package (Ap-
plegate et al, 2005). Concorde includes the fastest
exact algorithm and one of the most efficient im-
plementations of the Lin-Kernighan (LK) heuris-
tic for finding an approximate solution. LK works
by generating an initial random feasible solution
for the TSP problem, and then repeatedly identi-
fying an ordered subset of k edges in the current
tour and an ordered subset of k edges not included
in the tour such that when they are swapped the
objective function is improved. This is somewhat
335
reminiscent of the Greedy decoding of (Germann
et al, 2001), but in LK several transformations can
be applied simultaneously, so that the risk of being
stuck in a local optimum is reduced (Applegate et
al., 2007, chapter 15).
As will be shown in the next section, phrase-
based SMT decoding can be directly reformulated
as an AGTSP. Here we use Concorde through
first transforming AGTSP into STSP, but it might
also be interesting in the future to use algorithms
specifically designed for AGTSP, which could im-
prove efficiency further (see Conclusion).
4 Phrase-based Decoding as TSP
In this section we reformulate the SMT decoding
problem as an AGTSP. We will illustrate the ap-
proach through a simple example: translating the
French sentence ?cette traduction automatique est
curieuse? into English. We assume that the rele-
vant biphrases for translating the sentence are as
follows:
ID source target
h cette this
t traduction translation
ht cette traduction this translation
mt traduction automatique machine translation
a automatique automatic
m automatique machine
i est is
s curieuse strange
c curieuse curious
Under this model, we can produce, among others,
the following translations:
h ? mt ? i ? s this machine translation is strange
h ? c ? t ? i ? a this curious translation is automatic
ht ? s ? i ? a this translation strange is automatic
where we have indicated on the left the ordered se-
quence of biphrases that leads to each translation.
We now formulate decoding as an AGTSP, in
the following way. The graph nodes are all the
possible pairs (w, b), where w is a source word in
the source sentence s and b is a biphrase contain-
ing this source word. The graph clusters are the
subsets of the graph nodes that share a common
source word w.
The costs of a transition between nodes M and
N of the graph are defined as follows:
(a) If M is of the form (w, b) and N of the form
(w?, b), in which b is a single biphrase, and w and
w? are consecutive words in b, then the transition
cost is 0: once we commit to using the first word
of b, there is no additional cost for traversing the
other source words covered by b.
(b) If M = (w, b), where w is the rightmost
source word in the biphrase b, and N = (w?, b?),
where w? 6= w is the leftmost source word in b?,
then the transition cost corresponds to the cost
of selecting b? just after b; this will correspond
to ?consuming? the source side of b? after having
consumed the source side of b (whatever their rel-
ative positions in the source sentence), and to pro-
ducing the target side of b? directly after the target
side of b; the transition cost is then the addition of
several contributions (weighted by their respective
? (not shown), as in equation 1):
? The cost associated with the features local to
b in the biphrase library;
? The ?distortion? cost of consuming the
source word w? just after the source word w:
|pos(w?) ? pos(w) ? 1|, where pos(w) and
pos(w?) are the positions of w and w? in the
source sentence.
? The language model cost of producing the
target words of b? right after the target words
of b; with a bigram language model, this cost
can be precomputed directly from b and b?.
This restriction to bigram models will be re-
moved in Section 4.1.
(c) In all other cases, the transition cost is infinite,
or, in other words, there is no edge in the graph
between M and N .
A special cluster containing a single node (de-
noted by $-$$ in the figures), and corresponding to
special beginning-of-sentence symbols must also
be included: the corresponding edges and weights
can be worked out easily. Figures 2 and 3 give
some illustrations of what we have just described.
4.1 From Bigram to N-gram LM
Successful phrase-based systems typically employ
language models of order higher than two. How-
ever, our models so far have the following impor-
tant ?Markovian? property: the cost of a path is
additive relative to the costs of transitions. For
example, in the example of Figure 3, the cost of
this ? machine translation ? is ? strange, can only
take into account the conditional probability of the
word strange relative to the word is, but not rela-
tive to the words translation and is. If we want to
extend the power of the model to general n-gram
language models, and in particular to the 3-gram
336
Figure 2: Transition graph for the source sentence
cette traduction automatique est curieuse. Only
edges entering or exiting the node traduction ? mt
are shown. The only successor to [traduction ?
mt] is [automatique ? mt], and [cette ? ht] is not a
predecessor of [traduction ? mt].
Figure 3: A GTSP tours is illustrated, correspond-
ing to the displayed output.
case (on which we concentrate here, but the tech-
niques can be easily extended to the general case),
the following approach can be applied.
Compiling Out for Trigram models
This approach consists in ?compiling out? all
biphrases with a target side of only one word.
We replace each biphrase b with single-word tar-
get side by ?extended? biphrases b1, . . . , br, which
are ?concatenations? of b and some other biphrase
b? in the library.2 To give an example, consider
that we: (1) remove from the biphrase library the
biphrase i, which has a single word target, and (2)
add to the library the extended biphrases mti, ti,
si, . . ., that is, all the extended biphrases consist-
ing of the concatenation of a biphrase in the library
with i, then it is clear that these extended biphrases
will provide enough context to compute a trigram
probability for the target word produced immedi-
ately next (in the examples, for the words strange,
2In the figures, such ?concatenations? are denoted by
[b? ? b] ; they are interpreted as encapsulations of first con-
suming the source side of b?, whether or not this source side
precedes the source side of b in the source sentence, produc-
ing the target side of b?, consuming the source side of b, and
producing the target side of b immediately after that of b?.
Figure 4: Compiling-out of biphrase i: (est,is).
automatic and automatic respectively). If we do
that exhaustively for all biphrases (relevant for the
source sentence at hand) that, like i, have a single-
word target, we will obtain a representation that
allows a trigram language model to be computed
at each point.
The situation becomes clearer by looking at Fig-
ure 4, where we have only eliminated the biphrase
i, and only shown some of the extended biphrases
that now encapsulate i, and where we show one
valid circuit. Note that we are now able to as-
sociate with the edge connecting the two nodes
(est,mti) and (curieuse, s) a trigram cost because
mti provides a large enough target context.
While this exhaustive ?compiling out? method
works in principle, it has a serious defect: if for
the sentence to be translated, there are m relevant
biphrases, among which k have single-word tar-
gets, then we will create on the order of km ex-
tended biphrases, which may represent a signif-
icant overhead for the TSP solver, as soon as k
is large relative to m, which is typically the case.
The problem becomes even worse if we extend the
compiling-out method to n-gram language models
with n > 3. In the Future Work section below,
we describe a powerful approach for circumvent-
ing this problem, but with which we have not ex-
perimented yet.
5 Experiments
5.1 Monolingual word re-ordering
In the first series of experiments we consider the
artificial task of reconstructing the original word
order of a given English sentence. First, we ran-
domly permute words in the sentence, and then
we try to reconstruct the original order by max-
337
100 102 104
?0.8
?0.6
?0.4
?0.2
0
0.2
Time (sec)
D
ec
od
er
 s
co
re
BEAM?SEARCH
TSP
100 102 104
?0.4
?0.3
?0.2
?0.1
0
0.1
Time (sec)
D
ec
od
er
 s
co
re
BEAM?SEARCH
TSP
(a) (b) (c) (d)
Figure 5: (a), (b): LM and BLEU scores as functions of time for a bigram LM; (c), (d): the same for
a trigram LM. The x axis corresponds to the cumulative time for processing the test set; for (a) and (c),
the y axis corresponds to the mean difference (over all sentences) between the lm score of the output
and the lm score of the reference normalized by the sentence length N: (LM(ref)-LM(true))/N. The solid
line with star marks corresponds to using beam-search with different pruning thresholds, which result in
different processing times and performances. The cross corresponds to using the exact-TSP decoder (in
this case the time to the optimal solution is not under the user?s control).
imizing the LM score over all possible permuta-
tions. The reconstruction procedure may be seen
as a translation problem from ?Bad English? to
?Good English?. Usually the LM score is used
as one component of a more complex decoder
score which also includes biphrase and distortion
scores. But in this particular ?translation task?
from bad to good English, we consider that all
?biphrases? are of the form e ? e, where e is an
English word, and we do not take into account
any distortion: we only consider the quality of
the permutation as it is measured by the LM com-
ponent. Since for each ?source word? e, there is
exactly one possible ?biphrase? e ? e each clus-
ter of the Generalized TSP representation of the
decoding problem contains exactly one node; in
other terms, the Generalized TSP in this situation
is simply a standard TSP. Since the decoding phase
is then equivalent to a word reordering, the LM
score may be used to compare the performance
of different decoding algorithms. Here, we com-
pare three different algorithms: classical beam-
search (Moses); a decoder based on an exact TSP
solver (Concorde); a decoder based on an approx-
imate TSP solver (Lin-Kernighan as implemented
in the Concorde solver) 3. In the Beam-search
and the LK-based TSP solver we can control the
trade-off between approximation quality and run-
ning time. To measure re-ordering quality, we use
two scores. The first one is just the ?internal? LM
score; since all three algorithms attempt to maxi-
mize this score, a natural evaluation procedure is
to plot its value versus the elapsed time. The sec-
3Both TSP decoders may be used with/or without a distor-
tion limit; in our experiments we do not use this parameter.
ond score is BLEU (Papineni et al, 2001), com-
puted between the reconstructed and the original
sentences, which allows us to check how well the
quality of reconstruction correlates with the inter-
nal score. The training dataset for learning the LM
consists of 50000 sentences from NewsCommen-
tary corpus (Callison-Burch et al, 2008), the test
dataset for word reordering consists of 170 sen-
tences, the average length of test sentences is equal
to 17 words.
Bigram based reordering. First we consider
a bigram Language Model and the algorithms try
to find the re-ordering that maximizes the LM
score. The TSP solver used here is exact, that is,
it actually finds the optimal tour. Figures 5(a,b)
present the performance of the TSP and Beam-
search based methods.
Trigram based reordering. Then we consider
a trigram based Language Model and the algo-
rithms again try to maximize the LM score. The
trigram model used is a variant of the exhaustive
compiling-out procedure described in Section 4.1.
Again, we use an exact TSP solver.
Looking at Figure 5a, we see a somewhat sur-
prising fact: the cross and some star points have
positive y coordinates! This means that, when us-
ing a bigram language model, it is often possible
to reorder the words of a randomly permuted ref-
erence sentence in such a way that the LM score
of the reordered sentence is larger than the LM of
the reference. A second notable point is that the
increase in the LM-score of the beam-search with
time is steady but very slow, and never reaches the
level of performance obtained with the exact-TSP
procedure, even when increasing the time by sev-
338
eral orders of magnitude. Also to be noted is that
the solution obtained by the exact-TSP is provably
the optimum, which is almost never the case of
the beam-search procedure. In Figure 5b, we re-
port the BLEU score of the reordered sentences
in the test set relative to the original reference
sentences. Here we see that the exact-TSP out-
puts are closer to the references in terms of BLEU
than the beam-search solutions. Although the TSP
output does not recover the reference sentences
(it produces sentences with a slightly higher LM
score than the references), it does reconstruct the
references better than the beam-search. The ex-
periments with trigram language models (Figures
5(c,d)) show similar trends to those with bigrams.
5.2 Translation experiments with a bigram
language model
In this section we consider two real translation
tasks, namely, translation from English to French,
trained on Europarl (Koehn et al, 2003) and trans-
lation from German to Spanish training on the
NewsCommentary corpus. For Europarl, the train-
ing set includes 2.81 million sentences, and the
test set 500. For NewsCommentary the training
set is smaller: around 63k sentences, with a test
set of 500 sentences. Figure 6 presents Decoder
and Bleu scores as functions of time for the two
corpuses.
Since in the real translation task, the size of the
TSP graph is much larger than in the artificial re-
ordering task (in our experiments the median size
of the TSP graph was around 400 nodes, some-
times growing up to 2000 nodes), directly apply-
ing the exact TSP solver would take too long; in-
stead we use the approximate LK algorithm and
compare it to Beam-Search. The efficiency of the
LK algorithm can be significantly increased by us-
ing a good initialization. To compare the quality of
the LK and Beam-Search methods we take a rough
initial solution produced by the Beam-Search al-
gorithm using a small value for the stack size and
then use it as initial point, both for the LK algo-
rithm and for further Beam-Search optimization
(where as before we vary the Beam-Search thresh-
olds in order to trade quality for time).
In the case of the Europarl corpus, we observe
that LK outperforms Beam-Search in terms of the
Decoder score as well as in terms of the BLEU
score. Note that the difference between the two al-
gorithms increases steeply at the beginning, which
means that we can significantly increase the qual-
ity of the Beam-Search solution by using the LK
algorithm at a very small price. In addition, it is
important to note that the BLEU scores obtained in
these experiments correspond to feature weights,
in the log-linear model (1), that have been opti-
mized for the Moses decoder, but not for the TSP
decoder: optimizing these parameters relatively to
the TSP decoder could improve its BLEU scores
still further.
On the News corpus, again, LK outperforms
Beam-Search in terms of the Decoder score. The
situation with the BLEU score is more confuse.
Both algorithms do not show any clear score im-
provement with increasing running time which
suggests that the decoder?s objective function is
not very well correlated with the BLEU score on
this corpus.
6 Future Work
In section 4.1, we described a general ?compiling
out? method for extending our TSP representation
to handling trigram and N-gram language models,
but we noted that the method may lead to combi-
natorial explosion of the TSP graph. While this
problem was manageable for the artificial mono-
lingual word re-ordering (which had only one pos-
sible translation for each source word), it be-
comes unwieldy for the real translation experi-
ments, which is why in this paper we only consid-
ered bigram LMs for these experiments. However,
we know how to handle this problem in principle,
and we now describe a method that we plan to ex-
periment with in the future.
To avoid the large number of artificial biphrases
as in 4.1, we perform an adaptive selection. Let us
suppose that (w, b) is a SMT decoding graph node,
where b is a biphrase containing only one word on
the target side. On the first step, when we evaluate
the traveling cost from (w, b) to (w?, b?), we take
the language model component equal to
min
b?? 6=b?,b
? log p(b?.v|b.e, b??.e),
where b?.v represents the first word of the b? tar-
get side, b.e is the only word of the b target
side, and b??.e is the last word of the b?? tar-
get size. This procedure underestimates the total
cost of tour passing through biphrases that have a
single-word target. Therefore if the optimal tour
passes only through biphrases with more than one
339
103 104 105
?273
?272.5
?272
?271.5
?271
Time (sec)
D
ec
od
er
 s
co
re
BEAM?SEARCH
TSP (LK)
103 104 105
0.18
0.185
0.19
Time (sec)
BL
EU
 s
co
re
BEAM?SEARCH
TSP (LK)
103 104
?414
?413.8
?413.6
?413.4
?413.2
?413
Time (sec)
D
ec
od
er
 s
co
re
TSP (LK)
BEAM?SEARCH
103 104
0.242
0.243
0.244
0.245
Time (sec)
BL
EU
 s
co
re
TSP (LK)
BEAM?SEARCH
(a) (b) (c) (d)
Figure 6: (a), (b): Europarl corpus, translation from English to French; (c),(d): NewsCommentary cor-
pus, translation from German to Spanish. Average value of the decoder and the BLEU scores (over 500
test sentences) as a function of time. The trade-off quality/time in the case of LK is controlled by the
number of iterations, and each point corresponds to a particular number of iterations, in our experiments
LK was run with a number of iterations varying between 2k and 170k. The same trade-off in the case of
Beam-Search is controlled by varying the beam thresholds.
word on their target side, then we are sure that
this tour is also optimal in terms of the tri-gram
language model. Otherwise, if the optimal tour
passes through (w, b), where b is a biphrase hav-
ing a single-word target, we add only the extended
biphrases related to b as we described in section
4.1, and then we recompute the optimal tour. Iter-
ating this procedure provably converges to an op-
timal solution.
This powerful method, which was proposed in
(Kam and Kopec, 1996; Popat et al, 2001) in the
context of a finite-state model (but not of TSP),
can be easily extended to N-gram situations, and
typically converges in a small number of itera-
tions.
7 Conclusion
The main contribution of this paper has been to
propose a transformation for an arbitrary phrase-
based SMT decoding instance into a TSP instance.
While certain similarities of SMT decoding and
TSP were already pointed out in (Knight, 1999),
where it was shown that any Traveling Salesman
Problem may be reformulated as an instance of
a (simplistic) SMT decoding task, and while cer-
tain techniques used for TSP were then adapted to
word-based SMT decoding (Germann et al, 2001;
Tillmann and Ney, 2003; Tillmann, 2006), we are
not aware of any previous work that shows that
SMT decoding can be directly reformulated as a
TSP. Beside the general interest of this transfor-
mation for understanding decoding, it also opens
the door to direct application of the variety of ex-
isting TSP algorithms to SMT. Our experiments
on synthetic and real data show that fast TSP al-
gorithms can handle selection and reordering in
SMT comparably or better than the state-of-the-
art beam-search strategy, converging on solutions
with higher objective function in a shorter time.
The proposed method proceeds by first con-
structing an AGTSP instance from the decoding
problem, and then converting this instance first
into ATSP and finally into STSP. At this point, a
direct application of the well known STSP solver
Concorde (with Lin-Kernighan heuristic) already
gives good results. We believe however that there
might exist even more efficient alternatives. In-
stead of converting the AGTSP instance into a
STSP instance, it might prove better to use di-
rectly algorithms expressly designed for ATSP
or AGTSP. For instance, some of the algorithms
tested in the context of the DIMACS implemen-
tation challenge for ATSP (Johnson et al, 2002)
might well prove superior. There is also active re-
search around AGTSP algorithms. Recently new
effective methods based on a ?memetic? strategy
(Buriol et al, 2004; Gutin et al, 2008) have been
put forward. These methods combined with our
proposed formulation provide ready-to-use SMT
decoders, which it will be interesting to compare.
Acknowledgments
Thanks to Vassilina Nikoulina for her advice about
running Moses on the test datasets.
340
References
David L. Applegate, Robert E. Bixby, Vasek Chvatal,
and William J. Cook. 2005. Concorde
tsp solver. http://www.tsp.gatech.edu/
concorde.html.
David L. Applegate, Robert E. Bixby, Vasek Chvatal,
and William J. Cook. 2007. The Traveling Sales-
man Problem: A Computational Study (Princeton
Series in Applied Mathematics). Princeton Univer-
sity Press, January.
Luciana Buriol, Paulo M. Franc?a, and Pablo Moscato.
2004. A new memetic algorithm for the asymmetric
traveling salesman problem. Journal of Heuristics,
10(5):483?506.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Josh Schroeder, and Cameron Shaw Fordyce, edi-
tors. 2008. Proceedings of the Third Workshop on
SMT. ACL, Columbus, Ohio, June.
Ulrich Germann, Michael Jahr, Kevin Knight, and
Daniel Marcu. 2001. Fast decoding and optimal
decoding for machine translation. In In Proceedings
of ACL 39, pages 228?235.
Gregory Gutin, Daniel Karapetyan, and Krasnogor Na-
talio. 2008. Memetic algorithm for the generalized
asymmetric traveling salesman problem. In NICSO
2007, pages 199?210. Springer Berlin.
G. Gutin. 2003. Travelling salesman and related prob-
lems. In Handbook of Graph Theory.
Hieu Hoang and Philipp Koehn. 2008. Design of the
Moses decoder for statistical machine translation. In
ACL 2008 Software workshop, pages 58?65, Colum-
bus, Ohio, June. ACL.
D.S. Johnson, G. Gutin, L.A. McGeoch, A. Yeo,
W. Zhang, and A. Zverovich. 2002. Experimen-
tal analysis of heuristics for the atsp. In The Trav-
elling Salesman Problem and Its Variations, pages
445?487.
Anthony C. Kam and Gary E. Kopec. 1996. Document
image decoding by heuristic search. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence,
18:945?950.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Computational
Linguistics, 25:607?615.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
NAACL 2003, pages 48?54, Morristown, NJ, USA.
Association for Computational Linguistics.
Adam Lopez. 2008. Statistical machine translation.
ACM Comput. Surv., 40(3):1?49.
C. Noon and J.C. Bean. 1993. An efficient transforma-
tion of the generalized traveling salesman problem.
INFOR, pages 39?44.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei J. Zhu. 2001. BLEU: a Method for Automatic
Evaluation of Machine Translation. IBM Research
Report, RC22176.
Kris Popat, Daniel H. Greene, Justin K. Romberg, and
Dan S. Bloomberg. 2001. Adding linguistic con-
straints to document image decoding: Comparing
the iterated complete path and stack algorithms.
Christoph Tillmann and Hermann Ney. 2003. Word re-
ordering and a dynamic programming beam search
algorithm for statistical machine translation. Com-
put. Linguist., 29(1):97?133.
Christoph Tillmann. 2006. Efficient Dynamic Pro-
gramming Search Algorithms For Phrase-Based
SMT. In Workshop On Computationally Hard Prob-
lems And Joint Inference In Speech And Language
Processing.
Wikipedia. 2009. Travelling Salesman Problem ?
Wikipedia, The Free Encyclopedia. [Online; ac-
cessed 5-May-2009].
341
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 791?799,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Source-Language Entailment Modeling for Translating Unknown Terms
Shachar Mirkin?, Lucia Specia?, Nicola Cancedda?, Ido Dagan?, Marc Dymetman?, Idan Szpektor?
? Computer Science Department, Bar-Ilan University
? Xerox Research Centre Europe
{mirkins,dagan,szpekti}@cs.biu.ac.il
{lucia.specia,nicola.cancedda,marc.dymetman}@xrce.xerox.com
Abstract
This paper addresses the task of handling
unknown terms in SMT. We propose us-
ing source-language monolingual models
and resources to paraphrase the source text
prior to translation. We further present a
conceptual extension to prior work by al-
lowing translations of entailed texts rather
than paraphrases only. A method for
performing this process efficiently is pre-
sented and applied to some 2500 sentences
with unknown terms. Our experiments
show that the proposed approach substan-
tially increases the number of properly
translated texts.
1 Introduction
Machine Translation systems frequently encounter
terms they are not able to translate due to some
missing knowledge. For instance, a Statistical Ma-
chine Translation (SMT) system translating the
sentence ?Cisco filed a lawsuit against Apple for
patent violation? may lack words like filed and
lawsuit in its phrase table. The problem is espe-
cially severe for languages for which parallel cor-
pora are scarce, or in the common scenario when
the SMT system is used to translate texts of a do-
main different from the one it was trained on.
A previously suggested solution (Callison-
Burch et al, 2006) is to learn paraphrases of
source terms from multilingual (parallel) corpora,
and expand the phrase table with these para-
phrases1. Such solutions could potentially yield a
paraphrased sentence like ?Cisco sued Apple for
patent violation?, although their dependence on
bilingual resources limits their utility.
In this paper we propose an approach that con-
sists in directly replacing unknown source terms,
1As common in the literature, we use the term para-
phrases to refer to texts of equivalent meaning, of any length
from single words (synonyms) up to complete sentences.
using source-language resources and models in or-
der to achieve two goals.
The first goal is coverage increase. The avail-
ability of bilingual corpora, from which para-
phrases can be learnt, is in many cases limited.
On the other hand, monolingual resources and
methods for extracting paraphrases from monolin-
gual corpora are more readily available. These
include manually constructed resources, such as
WordNet (Fellbaum, 1998), and automatic meth-
ods for paraphrases acquisition, such as DIRT (Lin
and Pantel, 2001). However, such resources have
not been applied yet to the problem of substitut-
ing unknown terms in SMT. We suggest that by
using such monolingual resources we could pro-
vide paraphrases for a larger number of texts with
unknown terms, thus increasing the overall cover-
age of the SMT system, i.e. the number of texts it
properly translates.
Even with larger paraphrase resources, we may
encounter texts in which not all unknown terms are
successfully handled through paraphrasing, which
often results in poor translations (see Section 2.1).
To further increase coverage, we therefore pro-
pose to generate and translate texts that convey a
somewhat more general meaning than the original
source text. For example, using such approach,
the following text could be generated: ?Cisco ac-
cused Apple of patent violation?. Although less in-
formative than the original, a translation for such
texts may be useful. Such non-symmetric relation-
ships (as between filed a lawsuit and accused) are
difficult to learn from parallel corpora and there-
fore monolingual resources are more appropriate
for this purpose.
The second goal we wish to accomplish by
employing source-language resources is to rank
the alternative generated texts. This goal can be
achieved by using context-models on the source
language prior to translation. This has two advan-
tages. First, the ranking allows us to prune some
791
candidates before supplying them to the transla-
tion engine, thus improving translation efficiency.
Second, the ranking may be combined with target
language information in order to choose the best
translation, thus improving translation quality.
We position the problem of generating alterna-
tive texts for translation within the Textual Entail-
ment (TE) framework (Giampiccolo et al, 2007).
TE provides a generic way for handling language
variability, identifying when the meaning of one
text is entailed by the other (i.e. the meaning of
the entailed text can be inferred from the mean-
ing of the entailing one). When the meanings of
two texts are equivalent (paraphrase), entailment
is mutual. Typically, a more general version of
a certain text is entailed by it. Hence, through TE
we can formalize the generation of both equivalent
and more general texts for the source text. When
possible, a paraphrase is used. Otherwise, an alter-
native text whose meaning is entailed by the orig-
inal source is generated and translated.
We assess our approach by applying an SMT
system to a text domain that is different from the
one used to train the system. We use WordNet
as a source language resource for entailment rela-
tionships and several common statistical context-
models for selecting the best generated texts to be
sent to translation. We show that the use of source
language resources, and in particular the extension
to non-symmetric textual entailment relationships,
is useful for substantially increasing the amount of
texts that are properly translated. This increase is
observed relative to both using paraphrases pro-
duced by the same resource (WordNet) and us-
ing paraphrases produced from multilingual paral-
lel corpora. We demonstrate that by using simple
context-models on the source, efficiency can be
improved, while translation quality is maintained.
We believe that with the use of more sophisticated
context-models further quality improvement can
be achieved.
2 Background
2.1 Unknown Terms
A very common problem faced by machine trans-
lation systems is the need to translate terms (words
or multi-word expressions) that are not found in
the system?s lexicon or phrase table. The reasons
for such unknown terms in SMT systems include
scarcity of training material and the application
of the system to text domains that differ from the
ones used for training.
In SMT, when unknown terms are found in the
source text, the systems usually omit or copy them
literally into the target. Though copying the source
words can be of some help to the reader if the
unknown word has a cognate in the target lan-
guage, this will not happen in the most general
scenario where, for instance, languages use dif-
ferent scripts. In addition, the presence of a sin-
gle unknown term often affects the translation of
wider portions of text, inducing errors in both lex-
ical selection and ordering. This phenomenon is
demonstrated in the following sentences, where
the translation of the English sentence (1) is ac-
ceptable only when the unknown word (in bold) is
replaced with a translatable paraphrase (3):
1. ?. . . , despite bearing the heavy burden of the
unemployed 10% or more of the labor force.?
2. ?. . . , malgre? la lourde charge de compte le
10% ou plus de cho?meurs labor la force .?
3. ?. . . , malgre? la lourde charge des cho?meurs
de 10% ou plus de la force du travail.?
Several approaches have been proposed to deal
with unknown terms in SMT systems, rather than
omitting or copying the terms. For example, (Eck
et al, 2008) replace the unknown terms in the
source text by their definition in a monolingual
dictionary, which can be useful for gisting. To
translate across languages with different alpha-
bets approaches such as (Knight and Graehl, 1997;
Habash, 2008) use transliteration techniques to
tackle proper nouns and technical terms. For trans-
lation from highly inflected languages, certain ap-
proaches rely on some form of lexical approx-
imation or morphological analysis (Koehn and
Knight, 2003; Yang and Kirchhoff, 2006; Langlais
and Patry, 2007; Arora et al, 2008). Although
these strategies yield gain in coverage and transla-
tion quality, they only account for unknown terms
that should be transliterated or are variations of
known ones.
2.2 Paraphrasing in MT
A recent strategy to broadly deal with the prob-
lem of unknown terms is to paraphrase the source
text with terms whose translation is known to
the system, using paraphrases learnt from multi-
lingual corpora, typically involving at least one
?pivot? language different from the target lan-
guage of immediate interest (Callison-Burch et
792
al., 2006; Cohn and Lapata, 2007; Zhao et al,
2008; Callison-Burch, 2008; Guzma?n and Gar-
rido, 2008). The procedure to extract paraphrases
in these approaches is similar to standard phrase
extraction in SMT systems, and therefore a large
amount of additional parallel corpus is required.
Moreover, as discussed in Section 5, when un-
known texts are not from the same domain as the
SMT training corpus, it is likely that paraphrases
found through such methods will yield misleading
translations.
Bond et al (2008) use grammars to paraphrase
the whole source sentence, covering aspects like
word order and minor lexical variations (tenses
etc.), but not content words. The paraphrases are
added to the source side of the corpus and the cor-
responding target sentences are duplicated. This,
however, may yield distorted probability estimates
in the phrase table, since these were not computed
from parallel data.
The main use of monolingual paraphrases in
MT to date has been for evaluation. For exam-
ple, (Kauchak and Barzilay, 2006) paraphrase ref-
erences to make them closer to the system transla-
tion in order to obtain more reliable results when
using automatic evaluation metrics like BLEU
(Papineni et al, 2002).
2.3 Textual Entailment and Entailment Rules
Textual Entailment (TE) has recently become a
prominent paradigm for modeling semantic infer-
ence, capturing the needs of a broad range of
text understanding applications (Giampiccolo et
al., 2007). Yet, its application to SMT has been so
far limited to MT evaluation (Pado et al, 2009).
TE defines a directional relation between two
texts, where the meaning of the entailed text (hy-
pothesis, h) can be inferred from the meaning of
the entailing text, t. Under this paradigm, para-
phrases are a special case of the entailment rela-
tion, when the relation is symmetric (the texts en-
tail each other). Otherwise, we say that one text
directionally entails the other.
A common practice for proving (or generating)
h from t is to apply entailment rules to t. An
entailment rule, denoted LHS ? RHS, specifies
an entailment relation between two text fragments
(the Left- and Right- Hand Sides), possibly with
variables (e.g. build X in Y ? X is completed
in Y ). A paraphrasing rule is denoted with ?.
When a rule is applied to a text, a new text is in-
ferred, where the matched LHS is replaced with the
RHS. For example, the rule skyscraper? building
is applied to ?The world?s tallest skyscraper was
completed in Taiwan? to infer ?The world?s tallest
building was completed in Taiwan?. In this work,
we employ lexical entailment rules, i.e. rules with-
out variables. Various resources for lexical rules
are available, and the prominent one is WordNet
(Fellbaum, 1998), which has been used in virtu-
ally all TE systems (Giampiccolo et al, 2007).
Typically, a rule application is valid only under
specific contexts. For example, mouse ? rodent
should not be applied to ?Use the mouse to mark
your answers?. Context-models can be exploited
to validate the application of a rule to a text. In
such models, an explicit Word Sense Disambigua-
tion (WSD) is not necessarily required; rather, an
implicit sense-match is sought after (Dagan et al,
2006). Within the scope of our paper, rule ap-
plication is handled similarly to Lexical Substitu-
tion (McCarthy and Navigli, 2007), considering
the contextual relationship between the text and
the rule. However, in general, entailment rule ap-
plication addresses other aspects of context match-
ing as well (Szpektor et al, 2008).
3 Textual Entailment for Statistical
Machine Translation
Previous solutions for handling unknown terms in
a source text s augment the SMT system?s phrase
table based on multilingual corpora. This allows
indirectly paraphrasing s, when the SMT system
chooses to use a paraphrase included in the table
and produces a translation with the corresponding
target phrase for the unknown term.
We propose using monolingual paraphrasing
methods and resources for this task to obtain a
more extensive set of rules for paraphrasing the
source. These rules are then applied to s directly
to produce alternative versions of the source text
prior to the translation step. Moreover, further
coverage increase can be achieved by employing
directional entailment rules, when paraphrasing is
not possible, to generate more general texts for
translation.
Our approach, based on the textual entailment
framework, considers the newly generated texts as
entailed from the original one. Monolingual se-
mantic resources such as WordNet can provide en-
tailment rules required for both these symmetric
and asymmetric entailment relations.
793
Input: A text t with one or more unknown terms;
a monolingual resource of entailment rules;
k - maximal number of source alternatives to produce
Output: A translation of either (in order of preference):
a paraphrase of t OR a text entailed by t OR t itself
1. For each unknown term - fetch entailment rules:
(a) Fetch rules for paraphrasing; disregard rules
whose RHS is not in the phrase table
(b) If the set of rules is empty: fetch directional en-
tailment rules; disregard rules whose RHS is not
in the phrase table
2. Apply a context-model to compute a score for each rule
application
3. Compute total source score for each entailed text as a
combination of individual rule scores
4. Generate and translate the top-k entailed texts
5. If k > 1
(a) Apply target model to score the translation
(b) Compute final source-target score
6. Pick highest scoring translation
Figure 1: Scheme for handling unknown terms by using
monolingual resources through textual entailment
Through the process of applying entailment
rules to the source text, multiple alternatives of
entailed texts are generated. To rank the candi-
date texts we employ monolingual context-models
to provide scores for rule applications over the
source sentence. This can be used to (a) directly
select the text with the highest score, which can
then be translated, or (b) to select a subset of top
candidates to be translated, which will then be
ranked using the target language information as
well. This pruning reduces the load of the SMT
system, and allows for potential improvements in
translation quality by considering both source- and
target-language information.
The general scheme through which we achieve
these goals, which can be implemented using dif-
ferent context-models and scoring techniques, is
detailed in Figure 1. Details of our concrete im-
plementation are given in Section 4.
Preliminary analysis confirmed (as expected)
that readers prefer translations of paraphrases,
when available, over translations of directional en-
tailments. This consideration is therefore taken
into account in the proposed method.
The input is a text unit to be translated, such as a
sentence or paragraph, with one or more unknown
terms. For each unknown term we first fetch a
list of candidate rules for paraphrasing (e.g. syn-
onyms), where the unknown term is the LHS. For
example, if our unknown term is dodge, a possi-
ble candidate might be dodge ? circumvent. We
inflect the RHS to keep the original morphologi-
cal information of the unknown term and filter out
rules where the inflected RHS does not appear in
the phrase table (step 1a in Figure 1).
When no applicable rules for paraphrasing are
available (1b), we fetch directional entailment
rules (e.g. hypernymy rules such as dodge ?
avoid), and filter them in the same way as for para-
phrasing rules. To each set of rules for a given un-
known term we add the ?identity-rule?, to allow
leaving the unknown term unchanged, the correct
choice in cases of proper names, for example.
Next, we apply a context-model to compute an
applicability score of each rule to the source text
(step 2). An entailed text?s total score is the com-
bination (e.g. product, see Section 4) of the scores
of the rules used to produce it (3). A set of the
top-k entailed texts is then generated and sent for
translation (4).
If more than one alternative is produced by the
source model (and k > 1), a target model is ap-
plied on the selected set of translated texts (5a).
The combined source-target model score is a com-
bination of the scores of the source and target
models (5b). The final translation is selected to be
the one that yields the highest combined source-
target score (6). Note that setting k = 1 is equiva-
lent to using the source-language model alone.
Our algorithm validates the application of the
entailment rules at two stages ? before and af-
ter translation, through context-models applied at
each end. As the experiments will show in Sec-
tion 4, a large number of possible combinations of
entailment rules is a common scenario, and there-
fore using the source context models to reduce this
number plays an important role.
4 Experimental Setting
To assess our approach, we conducted a series of
experiments; in each experiment we applied the
scheme described in 3, changing only the mod-
els being used for scoring the generated and trans-
lated texts. The setting of these experiments is de-
scribed in what follows.
SMT data To produce sentences for our experi-
ments, we use Matrax (Simard et al, 2005), a stan-
dard phrase-based SMT system, with the excep-
tion that it allows gaps in phrases. We use approxi-
mately 1M sentence pairs from the English-French
794
Europarl corpus for training, and then translate a
test set of 5,859 English sentences from the News
corpus into French. Both resources are taken
from the shared translation task in WMT-2008
(Callison-Burch et al, 2008). Hence, we compare
our method in a setting where the training and test
data are from different domains, a common sce-
nario in the practical use of MT systems.
Of the 5,859 translated sentences, 2,494 contain
unknown terms (considering only sequences with
alphabetic symbols), summing up to 4,255 occur-
rences of unknown terms. 39% of the 2,494 sen-
tences contain more than a single unknown term.
Entailment resource We use WordNet 3.0 as
a resource for entailment rules. Paraphrases are
generated using synonyms. Directionally entailed
texts are created using hypernyms, which typically
conform with entailment. We do not rely on sense
information in WordNet. Hence, any other seman-
tic resource for entailment rules can be utilized.
Each sentence is tagged using the OpenNLP
POS tagger2. Entailment rules are applied for un-
known terms tagged as nouns, verbs, adjectives
and adverbs. The use of relations from WordNet
results in 1,071 sentences with applicable rules
(with phrase table entries) for the unknown terms
when using synonyms, and 1,643 when using both
synonyms and hypernyms, accounting for 43%
and 66% of the test sentences, respectively.
The number of alternative sentences generated
for each source text varies from 1 to 960 when
paraphrasing rules were applied, and reaches very
large numbers, up to 89,700 at the ?worst case?,
when all TE rules are employed, an average of 456
alternatives per sentence.
Scoring source texts We test our proposed
method using several context-models shown to
perform reasonably well in previous work:
? FREQ: The first model we use is a context-
independent baseline. A common useful
heuristic to pick an entailment rule is to se-
lect the candidate with the highest frequency
in the corpus (Mccarthy et al, 2004). In this
model, a rule?s score is the normalized num-
ber of occurrences of its RHS in the training
corpus, ignoring the context of the LHS.
? LSA: Latent Semantic Analysis (Deerwester
et al, 1990) is a well-known method for rep-
2http://opennlp.sourceforge.net
resenting the contextual usage of words based
on corpus statistics. We represented each
term by a normalized vector of the top 100
SVD dimensions, as described in (Gliozzo,
2005). This model measures the similarity
between the sentence words and the RHS in
the LSA space.
? NB: We implemented the unsupervised
Na??ve Bayes model described in (Glickman
et al, 2006) to estimate the probability that
the unknown term entails the RHS in the
given context. The estimation is based on
corpus co-occurrence statistics of the context
words with the RHS.
? LMS: This model generates the Language
Model probability of the RHS in the source.
We use 3-grams probabilities as produced by
the SRILM toolkit (Stolcke, 2002).
Finally, as a simple baseline, we generated a ran-
dom score for each rule application, RAND.
The score of each rule application by any of
the above models is normalized to the range (0,1].
To combine individual rule applications in a given
sentence, we use the product of their scores. The
monolingual data used for the models above is the
source side of the training parallel corpus.
Target-language scores On the target side we
used either a standard 3-gram language-model, de-
noted LMT, or the score assigned by the com-
plete SMT log-linear model, which includes the
language model as one of its components (SMT).
A pair of a source:target models comprises a
complete model for selecting the best translated
sentence, where the overall score is the product of
the scores of the two models.
We also applied several combinations of source
models, such as LSA combined with LMS, to take
advantage of their complementary strengths. Ad-
ditionally, we assessed our method with source-
only models, by setting the number of sentences to
be selected by the source model to one (k = 1).
5 Results
5.1 Manual Evaluation
To evaluate the translations produced using the
various source and target models and the different
rule-sets, we rely mostly on manual assessment,
since automatic MT evaluation metrics like BLEU
do not capture well the type of semantic variations
795
Model
Precision (%) Coverage (%)
PARAPH. TE PARAPH. TE
1 ?:SMT 75.8 73.1 32.5 48.1
2 NB:SMT 75.2 71.5 32.3 47.1
3 LSA:SMT 74.9 72.4 32.1 47.7
4 NB:? 74.7 71.1 32.1 46.8
5 LMS:LMT 73.8 70.2 31.7 46.3
6 FREQ:? 72.5 68.0 31.2 44.8
7 RAND 57.2 63.4 24.6 41.8
Table 1: Translation acceptance when using only para-
phrases and when using all entailment rules. ?:? indicates
which model is applied to the source (left side) and which to
the target language (right side).
generated in our experiments, particularly at the
sentence level.
In the manual evaluation, two native speakers
of the target language judged whether each trans-
lation preserves the meaning of its reference sen-
tence, marking it as acceptable or unacceptable.
From the sentences for which rules were applica-
ble, we randomly selected a sample of sentences
for each annotator, allowing for some overlap-
ping for agreement analysis. In total, the transla-
tions of 1,014 unique source sentences were man-
ually annotated, of which 453 were produced us-
ing only hypernyms (no paraphrases were appli-
cable). When a sentence was annotated by both
annotators, one annotation was picked randomly.
Inter-annotator agreement was measured by the
percentage of sentences the annotators agreed on,
as well as via the Kappa measure (Cohen, 1960).
For different models, the agreement rate varied
from 67% to 78% (72% overall), and the Kappa
value ranged from 0.34 to 0.55, which is compa-
rable to figures reported for other standard SMT
evaluation metrics (Callison-Burch et al, 2008).
Translation with TE For each model m, we
measured Precisionm, the percentage of accept-
able translations out of all sampled translations.
Precisionm was measured both when using only
paraphrases (PARAPH.) and when using all entail-
ment rules (TE). We also measured Coveragem,
the percentage of sentences with acceptable trans-
lations, Am, out of all sentences (2,494). As
our annotators evaluated only a sample of sen-
tences, Am is estimated as the model?s total num-
ber of sentences with applicable rules, Sm, mul-
tiplied by the model?s Precision (Sm was 1,071
for paraphrases and 1,643 for entailment rules):
Coveragem = Sm?Precisionm2,494 .
Table 1 presents the results of several source-
target combinations when using only paraphrases
and when also using directional entailment rules.
When all rules are used, a substantial improve-
ment in coverage is consistently obtained across
all models, reaching a relative increase of 50%
over paraphrases only, while just a slight decrease
in precision is observed (see Section 5.3 for some
error analysis). This confirms our hypothesis that
directional entailment rules can be very useful for
replacing unknown terms.
For the combination of source-target models,
the value of k is set depending on which rule-set
is used. Preliminary analysis showed that k = 5
is sufficient when only paraphrases are used and
k = 20 when directional entailment rules are also
considered.
We measured statistical significance between
different models for precision of the TE re-
sults according to the Wilcoxon signed ranks test
(Wilcoxon, 1945). Models 1-6 in Table 1 are sig-
nificantly better than the RAND baseline (p <
0.03), and models 1-3 are significantly better than
model 6 (p < 0.05). The difference between
?:SMT and NB:SMT or LSA:SMT is not statisti-
cally significant.
The results in Table 1 therefore suggest that
taking a source model into account preserves the
quality of translation. Furthermore, the quality is
maintained even when source models? selections
are restricted to a rather small top-k ranks, at a
lower computational cost (for the models combin-
ing source and target, like NB:SMT or LSA:SMT).
This is particularly relevant for on-demand MT
systems, where time is an issue. For such systems,
using this source-language based pruning method-
ology will yield significant performance gains as
compared to target-only models.
We also evaluated the baseline strategy where
unknown terms are omitted from the translation,
resulting in 25% precision. Leaving unknown
words untranslated also yielded very poor transla-
tion quality in an analysis performed on a similar
dataset.
Comparison to related work We compared our
algorithm with an implementation of the algo-
rithm proposed by (Callison-Burch et al, 2006)
(see Section 2.2), henceforth CB, using the Span-
ish side of Europarl as the pivot language.
Out of the tested 2,494 sentences with unknown
terms, CB found paraphrases for 706 sentences
(28.3%), while with any of our models, including
796
Model Precision (%) Coverage (%) Better (%)
NB:SMT (TE) 85.3 56.2 72.7
CB 85.3 24.2 12.7
Table 2: Comparison between our top model and the
method by Callison-Burch et al (2006), showing the per-
centage of times translations were considered acceptable, the
model?s coverage and the percentage of times each model
scored better than the other (in the 14% remaining cases, both
models produced unacceptable translations).
NB:SMT , our algorithm found applicable entail-
ment rules for 1,643 sentences (66%).
The quality of the CB translations was manually
assessed for a sample of 150 sentences. Table 2
presents the precision and coverage on this sample
for both CB and NB:SMT , as well as the number
of times each model?s translation was preferred by
the annotators. While both models achieve equally
high precision scores on this sample, the NB:SMT
model?s translations were undoubtedly preferred
by the annotators, with a considerably higher cov-
erage.
With the CB method, given that many of the
phrases added to the phrase table are noisy, the
global quality of the sentences seem to have been
affected, explaining why the judges preferred the
NB:SMT translations. One reason for the lower
coverage of CB is the fact that paraphrases were
acquired from a corpus whose domain is differ-
ent from that of the test sentences. The entail-
ment rules in our models are not limited to para-
phrases and are derived from WordNet, which has
broader applicability. Hence, utilizing monolin-
gual resources has proven beneficial for the task.
5.2 Automatic MT Evaluation
Although automatic MT evaluation metrics are
less appropriate for capturing the variations gen-
erated by our method, to ensure that there was no
degradation in the system-level scores according
to such metrics we also measured the models? per-
formance using BLEU and METEOR (Agarwal
and Lavie, 2007). The version of METEOR we
used on the target language (French) considers the
stems of the words, instead of surface forms only,
but does not make use of WordNet synonyms.
We evaluated the performance of the top mod-
els of Table 1, as well as of a baseline SMT sys-
tem that left unknown terms untranslated, on the
sample of 1,014 manually annotated sentences. As
shown in Table 3, all models resulted in improve-
ment with respect to the original sentences (base-
Model BLEU (TE) METEOR (TE)
?:SMT 15.50 0.1325
NB:SMT 15.37 0.1316
LSA:SMT 15.51 0.1318
NB:? 15.37 0.1311
CB 15.33 0.1299
Baseline SMT 15.29 0.1294
Table 3: Performance of the best models according to auto-
matic MT evaluation metrics at the corpus level. The baseline
refers to translation of the text without applying any entail-
ment rules.
line). The difference in METEOR scores is statis-
tically significant (p < 0.05) for the three top mod-
els against the baseline. The generally low scores
may be attributed to the fact that training and test
sentences are from different domains.
5.3 Discussion
The use of entailed texts produced using our ap-
proach clearly improves the quality of translations,
as compared to leaving unknown terms untrans-
lated or omitting them altogether. While it is clear
that textual entailment is useful for increasing cov-
erage in translation, further research is required to
identify the amount of information loss incurred
when non-symmetric entailment relations are be-
ing used, and thus to identify the cases where such
relations are detrimental to translation.
Consider, for example, the sentence: ?Conven-
tional military models are geared to decapitate
something that, in this case, has no head.?. In this
sentence, the unknown term was replaced by kill,
which results in missing the point originally con-
veyed in the text. Accordingly, the produced trans-
lation does not preserve the meaning of the source,
and was considered unacceptable: ?Les mode`les
militaires visent a` faire quelque chose que, dans
ce cas, n?est pas responsable.?.
In other cases, the selected hypernyms were too
generic words, such as entity or attribute, which
also fail to preserve the sentence?s meaning. On
the other hand, when the unknown term was a
very specific word, hypernyms played an impor-
tant role. For example, ?Bulgaria is the most
sought-after east European real estate target, with
its low-cost ski chalets and oceanfront homes?.
Here, chalets are replaced by houses or units (de-
pending on the model), providing a translation that
would be acceptable by most readers.
Other incorrect translations occurred when the
unknown term was part of a phrase, for exam-
ple, troughs replaced with depressions in peaks
797
and troughs, a problem that also strongly affects
paraphrasing. In another case, movement was the
hypernym chosen to replace labor in labor move-
ment, yielding an awkward text for translation.
Many of the cases which involved ambiguity
were resolved by the applied context-models, and
can be further addressed, together with the above
mentioned problems, with better source-language
context models.
We suggest that other types of entailment rules
could be useful for the task beyond the straight-
forward generalization using hypernyms, which
was demonstrated in this work. This includes
other types of lexical entailment relations, such as
holonymy (e.g. Singapore ? Southeast Asia) as
well as lexical syntactic rules (X cure Y ? treat
Y with X). Even syntactic rules, such as clause re-
moval, can be recruited for the task: ?Obama, the
44th president, declared Monday . . . ?? ?Obama
declared Monday . . . ?. When the system is un-
able to translate a term found in the embedded
clause, the translation of the less informative sen-
tence may still be acceptable by readers.
6 Conclusions and Future Work
In this paper we propose a new entailment-based
approach for addressing the problem of unknown
terms in machine translation. Applying this ap-
proach with lexical entailment rules from Word-
Net, we show that using monolingual resources
and textual entailment relationships allows sub-
stantially increasing the quality of translations
produced by an SMT system. Our experiments
also show that it is possible to perform the process
efficiently by relying on source language context-
models as a filter prior to translation. This pipeline
maintains translation quality, as assessed by both
human annotators and standard automatic mea-
sures.
For future work we suggest generating entailed
texts with a more extensive set of rules, in particu-
lar lexical-syntactic ones. Combining rules from
monolingual and bilingual resources seems ap-
pealing as well. Developing better context-models
to be applied on the source is expected to further
improve our method?s performance. Specifically,
we suggest taking into account the prior likelihood
that a rule is correct as part of the model score.
Finally, some researchers have advocated re-
cently the use of shared structures such as parse
forests (Mi and Huang, 2008) or word lattices
(Dyer et al, 2008) in order to allow a compact rep-
resentation of alternative inputs to an SMT system.
This is an approach that we intend to explore in
future work, as a way to efficiently handle the dif-
ferent source language alternatives generated by
entailment rules. However, since most current MT
systems do not accept such type of inputs, we con-
sider the results on pruning by source-side context
models as broadly relevant.
Acknowledgments
This work was supported in part by the ICT Pro-
gramme of the European Community, under the
PASCAL 2 Network of Excellence, ICT-216886
and The Israel Science Foundation (grant No.
1112/08). We wish to thank Roy Bar-Haim and
the anonymous reviewers of this paper for their
useful feedback. This publication only reflects the
authors? views.
References
Abhaya Agarwal and Alon Lavie. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
Proceedings of WMT-08.
Karunesh Arora, Michael Paul, and Eiichiro Sumita.
2008. Translation of Unknown Words in Phrase-
Based Statistical Machine Translation for Lan-
guages of Rich Morphology. In Proceedings of
SLTU.
Francis Bond, Eric Nichols, Darren Scott Appling, and
Michael Paul. 2008. Improving Statistical Machine
Translation by Paraphrasing the Training Data. In
Proceedings of IWSLT.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine Trans-
lation Using Paraphrases. In Proceedings of HLT-
NAACL.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2008.
Further Meta-Evaluation of Machine Translation. In
Proceedings of WMT.
Chris Callison-Burch. 2008. Syntactic Constraints
on Paraphrases Extracted from Parallel Corpora. In
Proceedings of EMNLP.
Jacob Cohen. 1960. A Coefficient of Agreement for
Nominal Scales. Educational and Psychological
Measurement, 20(1):37?46.
Trevor Cohn and Mirella Lapata. 2007. Machine
Translation by Triangulation: Making Effective Use
of Multi-Parallel Corpora. In Proceedings of ACL.
798
Ido Dagan, Oren Glickman, Alfio Massimiliano
Gliozzo, Efrat Marmorshtein, and Carlo Strappar-
ava. 2006. Direct Word Sense Matching for Lexical
Substitution. In Proceedings of ACL.
Scott Deerwester, S.T. Dumais, G.W. Furnas, T.K. Lan-
dauer, and R.A. Harshman. 1990. Indexing by La-
tent Semantic Analysis. Journal of the American So-
ciety for Information Science, 41.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008. Generalizing Word Lattice Trans-
lation. In Proceedings of ACL-HLT.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2008.
Communicating Unknown Words in Machine Trans-
lation. In Proceedings of LREC.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and
Communication). The MIT Press.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The Third PASCAL Recog-
nising Textual Entailment Challenge. In Proceed-
ings of ACL-WTEP Workshop.
Oren Glickman, Ido Dagan, Mikaela Keller, Samy
Bengio, and Walter Daelemans. 2006. Investigat-
ing Lexical Substitution Scoring for Subtitle Gener-
ation. In Proceedings of CoNLL.
Alfio Massimiliano Gliozzo. 2005. Semantic Domains
in Computational Linguistics. Ph.D. thesis, Univer-
sity of Trento.
Francisco Guzma?n and Leonardo Garrido. 2008.
Translation Paraphrases in Phrase-Based Machine
Translation. In Proceedings of CICLing.
Nizar Habash. 2008. Four Techniques for Online
Handling of Out-of-Vocabulary Words in Arabic-
English Statistical Machine Translation. In Pro-
ceedings of ACL-HLT.
David Kauchak and Regina Barzilay. 2006. Paraphras-
ing for Automatic Evaluation. In Proceedings of
HLT-NAACL.
Kevin Knight and Jonathan Graehl. 1997. Machine
Transliteration. In Proceedings of ACL.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings
of EACL.
Philippe Langlais and Alexandre Patry. 2007. Trans-
lating Unknown Words by Analogical Learning. In
Proceedings of EMNLP-CoNLL.
Dekang Lin and Patrick Pantel. 2001. DIRT ? Discov-
ery of Inference Rules from Text. In Proceedings of
SIGKDD.
Diana McCarthy and Roberto Navigli. 2007.
SemEval-2007 Task 10: English Lexical Substitu-
tion Task. In Proceedings of SemEval.
Diana Mccarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding Predominant Word Senses
in Untagged Text. In Proceedings of ACL.
Haitao Mi and Liang Huang. 2008. Forest-based
Translation Rule Extraction. In Proceedings of
EMNLP.
Sebastian Pado, Michel Galley, Daniel Jurafsky, and
Christopher D. Manning. 2009. Textual Entail-
ment Features for Machine Translation Evaluation.
In Proceedings of WMT.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of ACL.
M. Simard, N. Cancedda, B. Cavestro, M. Dymet-
man, E. Gaussier, C. Goutte, and K. Yamada. 2005.
Translating with Non-contiguous Phrases. In Pro-
ceedings of HLT-EMNLP.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proceedings of ICSLP.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob
Goldberger. 2008. Contextual Preferences. In Pro-
ceedings of ACL-HLT.
Frank Wilcoxon. 1945. Individual Comparisons by
Ranking Methods. Biometrics Bulletin, 1(6):80?83.
Mei Yang and Katrin Kirchhoff. 2006. Phrase-Based
Backoff Models for Machine Translation of Highly
Inflected Languages. In Proceedings of EACL.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008. Pivot Approach for Extracting Paraphrase
Patterns from Bilingual Corpora. In Proceedings of
ACL-HLT.
799
Document Structure and Multilingual Authoring 
Carol ine Brun Marc Dymetman Veronika Lux  
Xerox  Research  Cent re  Europe  
6 chemin  de Mauper tu i s  
38240 Mey lan ,  F rance  
{brun ,  dymetman,  lux}?xrce ,  xerox ,  com 
Abst rac t  
The use of XML-based authoring tools is swiftly be- 
coming a standard in the world of technical docu- 
mentation. An XML document is a mixture of struc- 
ture (the tags) and surface (text between the tags). 
The structure reflects the choices made by the au- 
thor during the top-down stepwise refinement of the 
document under control of a DTD grammar. These 
choices are typically choices of meaning which are 
independent of the language in which the document 
is rendered, and can be seen as a kind of interlin- 
gua for the class of documents which is modeled by 
the DTD. Based on this remark, we advocate a rad- 
icalization of XML authoring, where the semantic 
content of the document is accounted for exclusively 
in terms of choice structures, and where appropri- 
ate rendering/realization mechanisms are responsi- 
ble for producing the surface, possibly in several lan- 
guages imultaneously. In this view, XML authoring 
has strong connections to natural language genera- 
tion and text authoring. We describe the IG (In- 
teraction Grammar) formalism, an extension of DT- 
D's which permits powerful inguistic manipulations, 
and show its application to the production of multi- 
lingual versions of a certain class of pharmaceutical 
documents. 
1 In t roduct ion  
The world of technical documentation is forcefully 
moving towards the use of authoring tools based 
on the XML markup language (W3C, 1998; Pardi, 
1999). This language is based on grammatical spec- 
ifications, called DTD's, which are roughly similar 
to context-free grammars 1 with an arbitrary num- 
ber of non-terminals and exactly one predefined ter- 
minal called pcdata. The pcdata  terminal has a 
special status: it can dominate any character st, ring 
(subject to certain restrictions on the characters al- 
lowed). Authoring is seen as a. top-down interactive 
process of step-wise refinement of the root nonter- 
minal (corresponding to the whole document) where 
the author iteratively selects a rule for expanding a
lBut see (Wood, 1995: Prescod, 1998) for discussions of 
the differences. 
nonterminal already present in the tree and where 
in addition s/he can choose an arbitrary sequence 
of characters (roughly) for expanding tile pcdata  
node. The resulting document is a mixture of tree- 
like structure (the context-free derivation tree cor- 
responding to the author's selections), represented 
through tags, and of surface, represented as free-text 
(PCDATA) between the tags. 
We see however a tension between the structure 
and surface aspects of an XML document: 
? While structural choices are under system con- 
trol (they have to be compatible with the DTD), 
surface choices are not. 2 
? Surface strings are treated as unanalysable 
chunks for the styling mechanisms that render 
the XML document o the reader. They can 
be displayed in a given font or moved around, 
but they lack the internal structure that would 
permit to "re-purpose" them for different ren- 
dering situations, such as displaying on mobile 
telephone screens, wording differently for a spe- 
cific audience, or producing prosodically ade- 
quate phonetic output. This situation stands 
in contrast with the underlying philosophy of 
XML, which emphasizes the separation between 
content specification and the multiple situations 
in which this content can be exploited. 
. Structural decisions tend t,o be associated wit, h 
choices of meaning which are independent of the 
language in which the document is rendered. 
Thus for instance the DTD for an aircraft main- 
tenance manual might distinguish between two 
kinds of risks: caut ion  (material damage risk) 
and warning (risk to the operator). By select- 
ing one of these options (a choice that will lead 
t,o further-t_owerdevel choices,), the::author takes 
a decision of a semantic nature, which is quite 
independent of the language in which the docu- 
ment is to be rendered, and which could be ex- 
ploited to produce multilingual versions of the 
2With  the emergenceof  schemas (W3C, 1999a), which per- 
mit some typing of the surface (float, boolean, string, etc.), 
some degree of control is becoming more feasible. 
24 
document. By contrast, a PCDATA string is 
language-specific.and ill-suited for multilingual 
applications. 
These remarks point to a possible radical view of 
XML authoring that advocates that surface strings 
be altogether eliminated from the document content, 
and that author choices be all under the explicit con- 
trol of the DTD and reflected in the document struc- 
ture. Such a view, which is argued for in a related 
paper (Dymetman et el., 2000), emphasizes the link 
application of MDA to a certain domain of pharma- 
ceutical documents. 
2 Our approach to Multilingual 
Document Authoring 
Our Multilingual Document Authoring system has 
the following main features: 
First, the authoring process is monolingual, but 
the results are multilingual. At each point of the pro- 
cess the author can view in his/her own language the 
..... . . . . . . . . . . .  between ~ML`d~cumeqt~a~a9ring`~aad;mu~ti~nguaL;~,~.~te~t:~s/h~hasa~u~h~rex~:~.~aa~a~d~rea~?where~he ..: 
text authoring/generation (Power and Scott, 1998; text still needs refinement are highlighted. Menus 
Hartley and Paris, 1997; Coch, 1996): the choices for selecting a refinement are also presented to the 
made by the author are treated as a kind of in- author is his/her own language. Thus, the author is 
terlingua (specific to the class of documents being always overtly working in the language s/he nows, 
modelled), and it is the responsibility of appropri- but is implicitly building a language-independent 
ate "rendering" mechanisms to produce actual text representation of the document content. From this 
from these choices ill tile different languages 3 under representation, the system builds multilingual texts 
consideration, in any of several anguages simultaneously. This ap- 
For such a program, existing XML tools suffer proach characterizes our system as belonging to an 
however from serious limitations. First, DTD's are emerging paradigm of"natural anguage authoring" 
too  poor in expressive power (they are close to (Power and Scott, 1998; Hartley and Paris, 1997), 
context-free grammars) for expressing dependencies which is distinguished from natural anguage gener- 
between different parts of the document, an aspect ation by the fact that the semantic input is provided 
which becomes central as soon as the document interactively by a person rather than by a program 
micro-structure (its fine-grained semantic structure) accessing digital knowledge representations. 
starts to play a prominent role, as opposed to simply Second, the system maintains strong control both 
its macro-structure (its organization i  large seman- over the semantics and the realizations of the docu- 
tic units, typically larger than a paragraph). Second, ment. At the semantic level, dependencies between 
current rendering mechanisms such as CSS (Cascad- different parts of the representation f the document 
ing Style Sheets) or XSLT (XLS transformation lan- content can be imposed: for instance the choice of 
guage) (W3C, 1999b) are ill-adapted for handling a certain chemical at a certain point in a mainte- 
even simple linguistic phenomena such as morpho- nance manual may lead to an obligatory warning 
logical variation or subject-verb agreement, at another point in the manual. At the realization 
In order to overcome these limitations, we are level, which is not directly manipulated by the au- 
using a formalism, Interaction Grammars (IG), a thor, the system can impose terminological choices 
specialization of Definite Clause Grammars (Pereira (e.g. company-specific nomenclature for a given con- 
and Warren, 1980) which originates in A. Ranta's cept) or stylistic choices (such as choosing between 
Grammatical Framework (GF) (Ranta; M~enp~igt using the infinitive or the imperative mode in French 
and Ranta, 1999; Dynaetman et el., 2000), a gram- to express an instruction to an operator). 
matical formalism based on Martin-LSf's Type The- Finally, and possibly most distinctively, the st- 
ory (Martin-L6f, 1984) and building on previous ex- mantle representation underlying the authoring pro- 
perience with interactive mathematical proof editors cess is strongly document-centric and geared towards 
(Magnusson and Nordstr6m, 1994). In this formal- directly expressing the choices which uniquely char- 
ism, the carrier of meaning is a choice tree (called aeterize a given document in an homoge~cous class 
"abstract ree" in GF), a strongly typed object in of documents belonging to the same domain. Our 
which dependencies between substructures can be view is document-centric in the sense that it takes 
easily stated using the notion of dependent types, as its point of departure the widespread practice of 
The remainder of this paper is organized as fol- using XML tools for authoring the macro-structure 
lows. In section 2,,,we give a'~,high.teveloverview .of ..... of doeuments,-oand--extends this-practice towards an 
the Multilingual Document Authoring (MDA) sys- account of their m.icro-structure. But the analysis 
tern that we have developed at XRCE. In section of the micro-structure is only pushed as far as is 
3, we present in some detail the formalism of In- necessary in order to account for the variability in- 
teraction Grammars. In section 4. we describe an side the class of documents considered, and not in 
terms of the ultimate meaning constituents of lan- 3The word "language" should be understood here in an 
extended sense tha! not only covers English. French. etc., but guage. This  nlicro-structure can in general be de- 
also different styles or modes of communication, ler ln iued by s tudy ing  a corpus of  documents  and by 
25 
exposing the structure of choices that distinguish a 
given document from other documents in this class. 
This structure of choices is represented in a choice 
tree, which is viewed as the semantic representation 
for the document. 4 One single choice may be asso- 
ciated with text realizations of drastically different 
granularities: while in a pharmaceutical document 
the choice of an ingredient may result in the produc- 
tion of a single word, the choice of a "responsability- 
waiver" may result in a long stereotypical paragraph 
of text, the further analysis of which would be totally 
.counter-productive. 
3 In teract ion  Grammars  
Let us now give some details about the formalism 
of Interaction Grammars. We start by explaining 
the notion of choice tree on the basis of a simple 
context-free grammar, analogous to a DTD. 
Context - f ree  grammars  and  choice trees 
Let's consider the following context-free grammar 
for describing simple "addresses" in English such as 
"Paris, France": s 
address --> city, " , " ,  
country. 
country --> "France". 
country --> "Germany". 
city --> "Paris". 
city --> "Hamburg". 
city --> "the capital of", 
country. 
What does it mean, remembering the XML anal- 
ogy, to author a "document" with such a CFG? It 
means that the author is iteratively presented with 
partial derivation trees relative to the grammar (par- 
tial in the sense that leaves can be terminals or non- 
terminals), and at each given authoring step both 
selects a certain nonterminal to "refine", and also a 
given rule to extend this non-terminal one step fur- 
ther: this action is repeated until the derivation tree 
is complete. 
If one conventionally uses the identifier 
nonterminal~ to name the i-th rule expanding 
the nonterminal nontermina l ,  then the collection 
of choices made by the author during a session can 
be represented by a choice tree labelled with rule 
identifiers, also called combinators. An example 
of such a tree is address l (c i ty2 ,count ry2)  
4This kind of semantic representation stands i-n contrast 
to some representations commonly used in NLP, which tend 
to emphasize the fine-grained predicate-argument structure of 
sentences independently of the productivity of such analyses 
.\[or a given class of documents. 
5For compatibil ity with the notacionsCo follow, we use low- 
ercase to denote nonlerminals, aml quoted strings to denote 
terminals,  ra ther  than  tile inore usna\[  ul)pot'case lowercase 
convent  ions. 
which corresponds to choices leading to the output 
"Hamburg, Germany". 6 In.practice, rather than 
using combinator names which strictly adhere to 
this numbering scheme, we prefer to use mnemonic 
names directly relating to the meaning of the 
choices. In the sequel we will use the names adr;  
f ra ,  ger ,  par ,  ham, cap for the six rules in the 
example grammar. The choice tree just described is 
thus written adr (ham,ger ) .  
Mak ing  choice t rees  exp l ic i t  As we have ar- 
gued previously, choices trees are in our view the cen- . 
tral repositoi-y of documentc0ntent and we Want to 
manipulate them explicitely. Definite Clause Gram- 
mars represent possibly the simplest extension of 
context-free grammars permitting such manipula- 
tion. Our context-free grammar can be extended 
straightforwardly into the DCG: 7 
address (adr (Co ,C) )  - -> c i ty (C) ,  " , "  
country(Co) .  
count ry ( f ra )  - -> "France" .  
count ry (ger )  - -> "Germany". 
city(par) --> "Paris". 
city(ham) --> "Hamburg". 
city(cap(Co)) --> "the capital of", 
country(Co). 
What these rules do is simply to construct choice 
trees recursively. Thus, the first rule says that if the 
author has described a city through the choice tree 
C and a country through the choice tree Co, then the 
choice tree adr(Co,C) represents the description of 
an address. 
If now, in this DCG, we "forget" all the terminals, 
which are language-specific, by replacing them with 
the empty string, we obtain the following "abstract 
gram mar' l :  
address(adr(Co,C)) --> city(C), country(Co). 
country(fra) --> \[\]. 
country(ger) --> \[\]. 
city(par) --> \[\]. 
city(ham) --> \[\]. 
city(cap(Co)) --> country(Co). 
which is in fact equivalent o the definite clause 
program: s
SSuch a choice tree can be projected into a derivation 
tree in a straightforward way, by mapping a combinator 
nonterminali into the monterminal name nontermin,:.l, and 
by 'introducing terminal material as required by the specific 
rules. 
7According to the usual logic programming conventions, 
lowercase letters denote predicates and functors, whereas up- 
percase letters denote metavariables that can be instauciated 
with terms. 
Sin the sense that rewriting the nonterminal goal 
address  (adr (Co ,C)) to the empty string in the DCG is equiv- 
alent to proving the goal address(adr (Co ,C) )  in the program, 
26 
address (adr (Co ,C) )  : -  c i ty (C) ,  count ry (Co) .  
count ry  ( f  ra ) .  
count ry  (ger ) .  
c i ty (par ) .  
city(ham). 
city(cap(Co)) :- country(Co). 
This abstract  g rammar  (or, equivalently, this logic 
program),  is language independent and recursively 
defines a set of well-formed choice trees of different 
categories, or types. Thus, the tree adr (ham,ger )  
is .well-formed "in".. the. :typ~/add.~:r~s, ,End the .lice 
cap( f ra )  well-formed in the type c i ty .  
Dependent  Types  In order to stress the type- 
related aspects of the previous tree specifications, 
we are actual ly using in our current implementa-  
tion the following notat ion for the previous abstract  
grammar :  
adr (Co ,C) : :address  - ->  C : :c i ty ,  
Co : : count ry .  
f ra :  : count ry  - -> \[\] . 
ger :  : count ry  - -> \[\] . 
par :  : c i ty  --> \[3 . 
ham: :city --> \[\]. 
cap(Co) : :c i ty  --> Co::country. 
The first rule is then read: "if C is a tree of 
type c i ty ,  and Co a tree of type count ry ,  then 
adr (Co ,C)  is a tree of type address" ,  and simi lar ly 
for the remaining rules. 
The grammars  we have given so far are deficient 
in one important  respect: there is no dependency 
between the city and the country in the same ad- 
dress, so that  the tree adr (ham, f ra )  is well-formed 
in the type address .  In order to remedy this prob- 
lena, dependent types (Ranta; Martin-L6f, 1984)can 
be used. From our point  of view, a dependent ype 
is s imply a type that can be parametr ized by objects 
of other types. We write: 
adr (Co ,C) : :address  - ->  C : :c i ty (Co) ,  
Co: : count ry .  
f ra :  : count ry  - -> \[\] . 
get :  : count ry  - -> \[\] .
par : : c i ty ( f ra )  - ->  \ [ \ ] .  
ham: :c i ty (ger )  - ->  \ [ \ ] .  
cap(Co) : : c i ty (Co)  - ->  Co: :count ry .  
in which the type c i ty  is now parametr ized by 
objects of type count ry ,  and where the notat ion 
par  : : c i ty ( f ra )  is read as " 'par is  at ree of the type: 
city of f ra ' .  9 
which is another way of stating the well-known duality be- 
tween the rewriting and the goal-proving approaches to the 
interpretation f Prolog. 
9In terms of the underlying Prolog implementation. "::" is 
simply an infix operator for a predicate ofarity 2 which relates 
an object and its type, and both simple and dependent types 
are handled st raighforwardly. 
Para l le l  Grammars  and  Semant ics -dr iven  
? Compos i t iona l i ty . fo r  . ;Text . ;Rea l izat6 ion We 
have just  explained how abstract  grammars  can be 
used for specifying well-formed typed trees repre- 
senting the content of a document.  
In order to produce actual  mult i l ingual documents  
from such specifications, a s imple approach is to al- 
low for parallel real ization English, French . . . . .  gram- 
mars, which all have the same underlying abstract. 
g rammar  (program),  but which introduce terminals  
specific, to ~the_ language -at. hand. Thus. the (ollow- 
ing French andEng l i sh  gi-annmkrs a/'e pai~allel to the ' : "  
previous abstract  g rammar : l ?  
adr(Co,C) : :address --> C::city(Co), ",", 
Co: :country. 
fra: :country --> "France". 
ger : : country --> "Germany". 
par: :c i ty(fra)  --> "Paris". 
ham: : city(ger) --> "Hamburg". 
cap(Co): :c i ty(Co) --> "the capital of", 
Co : : country. 
adr(Co,C): :address --> C::city(Co), ",", 
Co : : country. 
fra: : country --> "In France". 
ger : : country --> "i' Al lemagne". 
par: : city(fra) --> "Paris". 
ham: : city (get) -- > "Hambourg". 
cap(Co): :city(Co) --> "In capitale de", 
Co: :country. 
This view of real ization is essentially the one we 
have adopted in the prototype at the t ime of writ- 
ing, with some straighforward addit ions permit t ing  
the handl ing of agreement constraints and morpho- 
logical variants. This s imple approach has proven 
quite adequate for the class of documents we have 
been interested in. 
However, such an approach sees the activity of 
generat ing text from an abstract  structure as ba- 
sically a composit ional  process on strings, that  is, 
a process where strings are recursively associated 
with subtrees and concatenated to produce strings 
at the next subtree level. But such a direct proce- 
dure has well-known l imitat ions when the seinantic 
and syntact ic levels do not have a direct correspon- 
dence (simple example: ordering a list of modifiers 
around a noun). We are currently experimenting 
with.a, powerful extension~of.stri.ng compqsihonal i ty  - 
where tim objects  composit ional ly  associated with 
abstract  subtrees are not strings, but syntactic rep- 
resentations with rich internal structure. The text 
10Because the order of goals in the right-hand side of an ab- 
stract grammar rule is irrelevant, he goals on the right-hand 
sides of rule in two parallel realization grammars can appear 
in a different order, which permits certain reorganizations of 
the linguistic material (situation ot shown in the example). 
27 
itself is obtained from the syntactic representation 
associated with the .total tree .by simply enumerat- 
ing its leaves. 
In this extended view, realization grammars have 
rules of the following form: 
a l (B ,C  . . . .  ) : :a (D  . . . .  ) -Syn  - ->  
B: :b(E  . . . .  ) -SynB,  
C : :c (F , . . . ) -SynC,  
general public. Le VIDAL ? includes a collection of 
notices ,for .around? 5 5.00. dmgs..a~ailable .in France. 
As the publisher, OVP-t~ditions du Vidal has taken 
care of homogeneity across the notices, reformatting 
and reformulating source information. The main 
source are the New Drug Authorizations (Autori- 
sation de Mise sur le March~), regulatory docu- 
ments written by pharmaceutical laboratories and 
approved by legal authorities. 
Relative to multilingual document authoring, this 
{const ra in ts  (B, C . . . . .  D, E, F . . . .  ) }, corpus has three features whicli,~e, considered highly 
? ' {compose=engt.ish(~synB ;~.SynC, " :-;-.Syn.)~}-~.--:-desi-r~ble:;(l)-it-dea\[s.with ,a.res\[rlcted-~em~:tit d~2 
The rule shown is a rule for English: the syn- 
tactic representations are language dependent; par- 
allel rules for the other languages are obtained by 
replacing the compose_engl ish constraint (which is 
unique to this rule) by constraints appropriate to the 
other languages under consideration. 
Heterogeneous  Trees and  In teract iv i ty  Natu- 
ral language authoring is different from natural lan- 
guage generation i one crucial respect. Whenever 
the abstract ree to be generated is incomplete (for 
instance the tree cap(Co)), that is, has some leaves 
which are yet uninstanciated variables, the genera- 
tion process hould not proceed with nondeterminis- 
tically enumerating texts for all the possible instan- 
elations of the initial incomplete structure. Instead 
it should display to the author as much of the text as 
it can in its present "knowledge state", and enter into 
an interaction with the author to allow her to fur- 
thor refine the incomplete structure, that is, to fur- 
ther instanciate some of the uninstanciated leaves. 
To this purpose, it is useful to introduce along with 
the usual combinators (adr, fra, cap, etc.) new 
combinators of arity 0 called typenames, which are 
notated type,  and are of type "type. These combi- 
nators are allowed to stand as leaves (e.g. in the tree 
cap(count ry ) )  and the trees thus obtained are said 
to be heterogeneous. The typenames are treated by 
the text generation process as if they were standard 
semantic units, that is, they are associated with text 
units which are generated "at their proper place" in 
the generated output. These text units are specially 
phrased and highlighted to indicate to the author 
that some choice has to be made to refine the un- 
derlying type (e.g. obtaining the text "la capitale de 
PAYS"). This choice has the effect of further instan- 
elating the incomplete tree with "true" combinators, 
main (for which various terminological resources are 
available), (2) it is a homogeneous collection of docu- 
ments all complying to the same division in sections 
and sub-sections, (3) there is a strong trend in in- 
ternational bodies such as the EEC towards making 
drug package notices (which are similar to VIDAL 
notices) available in multilingual versions strictly 
aligned on a common model. 11 
4.2 Corpus  analys is  
An analysis of a large collection of notices from Le 
VIDAL ? de la famille, describing different drugs, 
from different laboratories was conducted in order 
to identify: 
* the structure of a notice, 
? the semantic dependencies between elements in 
the structure. 
For this task, all the recta-information available is 
useful, in particular: explanations provided by Le 
VIDAL ? de la famille and help of a domain expert. 
Corpus study was a necessary preliminary task be- 
fore modeling the notices in the IG formalism pre- 
sented in section 2. 
4.2.1 S t ructure  
Notices from Le VIDAL ? are all built on the same 
model, including a title (the name of the drug, plus 
some general information about it). followed by sec- 
tions describing the main characteristics of the cirug: 
general description, composition, indications, con- 
traindications, warnings, drug interactions, preg- 
nancy and breast-feeding, dosage and administra- 
tion, possible side effects. This initial knowledge 
? about the semantic ontent of the document is cap- 
tured with a first., simple context free rule, such as: 
and the generation process is iterated. 
4 An  App l i ca t ion  to  Pharmaceut ica l  
Documents  
4.1 Corpus  select ion 
Our corpus consists in drug notices extracted froln 
"'Le VIDAL?de la Famille" (Editions du Vidal. 
1998). a practical book about heahh made for the 
........ vidalNot.ice(T,D,C, I ,CI.~W,DI ~ PaBF,D~i-A,PSI) : :notice 
- ->  
T: :title, 
D: :description, 
C: :composition, 
I lA  similar but less extended corpus was previously built 
by the third author as the basis for a prototype ofmuhilingual 
ctocument authoring using G F. 
28 
I : : ind icat ions ,  
Cl::contraindications, 
W::warn ings ,  
D I : :d rugs In teract ion ,  
PaBF: :p regnancyAndBreastFeed ing ,  
DaA::dosageAndAdmin, 
PSI::possibleSideEffects. 
Each section is associated with context-bee rules 
that describe its internal structure: 
'vidalTitle(N,APi . . . ,  .~;>)~:-.:~d?1e-=:n ....... 
- ->  
N::name0fDrug, 
AP::activePrinciples . . . . .  
vidalDescription(N,PF,P...)::description 
- ->  
\['DESCRIPTION'\], 
N::nameOfDrug, 
PF::pharmaceutForm, 
P::package . . . . .  
vidalDosageAndAdmin(D,A)::dosageAndAdmin 
- ->  
\['DOSAGE AND ADMINISTRATION'\], 
D::dosage, 
A::administration. 
tablet::pharmaceutForm --> \['tablet'\]. 
eyeDrops:::pharmaceutForm --> \['eye drops'\]. 
At this point, we allow parallel realizations for 
French and English. So, in addition to the English 
grammar given above, we have the French grammar: 
vidalTitle(N, AP . . . . . . . .  )::title 
- ->  
N::name0fDrug, 
AP::activePrinciples, ... . 
vidalDescr(N,PF,P...)::description 
- ->  
\['PRESENTATION'\], 
N::nameOfDrug, 
PF::pharmaceutForm, 
P::package . . . . .  
vidalDosageAndAdmin(D,A)::dosageAndAdmin 
- ->  
\['MODE D'EMPLOI ET POSOLOGIE'\], 
D::dosage, 
A::administration. 
tab le t : :pharmaceutForm - -> \ [ ' compr im~' \ ] .  
eyeDrops : : :pharmaceutForm --> \ [ ' co l l y re ' \ ] .  
This first grammar is fully eq.ivalent o a XML 
I)TD that describes the structure of a notice, though 
it distinguishes finer-grained units 1hart traditional 
l)TI)s tends to do. 
4.2.2 Modeling dependencies 
, ,~ButHG :~ goes ?urt, her,:than XM-L DTDs ~it~h'regard 
to the semantic ontrol of documents: it enables us 
to express dependencies which may arise in differ- 
ent parts of a document, including tong-distance de- 
pendencies, through the use of dependent types pre: " 
sented in section 2. 
Identification of the dependencies to be modeled was 
done in a second stage of the corpus study. For ex- 
ample, we identified dependencies between: 
, ........ ,:.-.: ~-~ "the:--ghamaaeoa~tieal ,:forrrr;0t~ a :gi,#ed~dtfug :(.cbn:.- 
cept pharmaceutForm) and its packaging (con- 
cept package), 
? particular ingredients given in the section com- 
position and warning instructions given ill the 
section warnings, 
? categories of patients the drug is intended for in 
the section description and posology indicated 
for each category in the section indications. 
To illustrate the modeling task, we now give more 
details about one particular dependency identified. 
Intuitively, it appears that there is a strong link be- 
tween the pharmaceutical form of a given drug and 
the way it should be administered: tablets are swal- 
lowed, eye drops are put in the eyes, powder is di- 
luted in water etc. In our first grammar, the phar- 
maceutical form concept appears in the description 
section, since the administration way is described in 
the dosage and administration section. The use of 
dependent ypes permits to link these sections to- 
gether according to the pharmaceutical form. Tile 
parts of the (English) grammar involved become: 
vidalNotice(T,D,C,I,CI,W,DI,PaBF,DaA,PSI)::notice 
- ->  
T::title, 
D::description(PF), 
C::composition, 
I::indications, 
CI::contraindications, 
W::warnings, 
DI::drugslnteraction, 
PaBF::pregnancyAndBreastFeeding, 
DaA::dosageAndAdmin(PF), 
PSI::possibleSideEffects. 
vidalDescription(N,PF,P,...)::description(PF) 
- ->  
\['D~SCRIPTION'\], " ? 
N::nameOfDrug, 
PF::pharmaceutForm, 
P::package . . . . .  
vidalDosageAndAdmin(D,A)::dosageAndAdmin(PF) 
- ->  
\['DOSAGE AND ADMINISTRATION'\], 
D::dosage, 
29 
A : : administration (PF). 
The administration section should now be de-- .... 
scribed according to the pharmaceutical form it pre- 
supposes, several administration ways being compat- 
ible with each form: 
t ab le tsAdmin l  : : administrat  ion (Tablet) 
?O~I'~?-INDICAT%(~mS: ce ~id l?~ent  rm do|t  p~s ~tre ut~l~sb dlns les C~S sutvancs: 
----> a l le r~ le  au~ /~1SS nocu~ent t 'aset r lne  i 
\ [ 'Swal low the tab le ts  w i thout  "- l 
crunch ing  them. '\] . ar~n~: 
"'... -" . . . . .  _ . ~w=' ~ ' : "  : ~ ' , ' ~ . ~ ' % ' - ~ ~  -.-" . . . . . . . . . .  
? \[KTERACTZORS HI~DICAHENTEIJSES: Ce |~atc~ent  aeut tn ter lq t r  avec a'autres ~ed~ca~ents. tablet  sAdmin2 : :administrat ion (Tablet) ~,o~ .... ~ - ~-,~,. ,, .... t,,~ ,nt ,~n..,~to ,.~ .... t.,.,~ ,,~ 
augmentation des effets ~a~Is~r~bles. - le l t th tu~:  ~9uentat lon ~u taux de Hth iu |  
__> dam le sanq. 
\[ 'Let the tab le ts  mel t  under  c.oss~ss( ?TT AttAI~M~,T: 
the tongue. '\] . 
eyeDropsAdmin : :admin is t ra t ion(EyeDrops)  
- ->  
\ [~Pul l  the lower  eye l id  down wh i le  
look ing  up and squeeze  the eye drops,  
so that they fa l l  between the eye l id  
and the eyeba l l . ' \ ] .  
emacs: "prolo@ ? : 
I 
llOaOF?1t IbuDrofane 
P'R~\[NTATION: RUROFEN : ?ot~r|m~ C blanc ) : bQIte de Z? - ~ah &~ - 15.s F - 
? t@orat01 res Boots Healt.care 
?o,tposrrzoq: p cD 
Ibugrofene . . . . . . . . . . . . . .  20fl ig 
INDICATIONS: Ce |~d lcuent  est u,  gnc l - |n f lu la tO l?o  non stero~cHen {PISS). I \ ]  osc 
u t | l i s6  e, cas de aouIeurs diverses. 
.~OOE D'EHPtOI ET POSOLOCZE: i \ [~ l l l l l lm l lmlml  ~ . P~ologta 
Usuel t e: : ~ ?o.pr i mes . . . ,~ ;441 . i~   g/l 
The consequence of such a modeling is a better 
control of the semantic ontent of the document in 
the process of being authored: once the user chooses 
tablet as pharmaceutical form in the section descrip- 
tion, his choice is restricted between the two con- 
cepts tabletsAdminl and tabletsAdmin~ in the ad- 
ministration section. If he chooses eye drops as the 
pharmaceutical form, there is no choice left if the ad- 
ministration section: the text fragment correspond- 
ing to the concept eyeDropsAdmin will be generated 
automatically in the document. 
This example illustrates how dependencies are 
propagated into the macro-structure, but they can 
be propagated into the micro-structure as well: for 
example, in the description section, we can express 
that the packaging of the drugs is also dependent of 
their form: tablets are packaged in boxes, eye drops 
in flasks, powder in packets, etc.: 
v ida lDescr ip t ion(N ,P  . . . .  ) : :descr ipt ion(PF)  
- ->  
\ [ 'DESCRIPTIDN' \ ] ,  
N : :name0fDrug,  
PF : :pharmaceutForm,  
P : :package(PF)  . . . . .  
box:  :package(Tab le t )  . - ->  \ [ 'Box ' \ ] .  
f l ask : :package(EyeDrops)  - ->  \ [ ' F lask ' \ ] .  
This example shows that tile granularity degree of 
the linguistic realization cat\] vary from full text seg- 
ment (administration ways) to sing\[e words (forms 
like tablet, eye drops, powder, etc.). This is highly 
related to the reusability of the concept: references 
to specific forrns may appear it\] many parts of the 
Figure 1: A stage in the authoring of a notice, with 
French text shown. 
document, while the administration ways are more 
or less frozen segments. 12
The level of generality of dependencies encoded in 
the grammar needs to be paid attention to: one has 
to be sure that a given dependency is viable over a 
large collection of documents in the domain. If a 
choice made by the grammar writer is too specific, 
the risk is that it may be not relevant for other docu- 
ments. For this reason, an accurate knowledge of the 
corpus is necessary to ensure an adequate coverage 
of documents in the domain. 
4.3 An  Example  
Screen copies of the IG interface during an authoring 
process of a VIDAL notice are given on figures 1 and 
2. Figure 1 represents the notice authored in French 
at a given stage. The fields still to be refined by 
tile user appear ill dark. When the author wants to 
refine a given field, a pulldown menu presenting tile 
choices for this field appears on the screen. Here, the 
author chooses to refine the field avaler in the admin- 
istration (mode d'emploi et posologie ) section: the 
corresponding menu.proposes the list of.administra- 
tion ways corresponding to the pharmaceutical form 
tablet he has chosen before. Figure 2 shows the par- 
allel notice in English but one step further, i.e. once 
he has selected the administration way. 
12 For a discussion of some of the issues regarding the use of 
templates in nature\[ language generation systems, see (\[-leit er, 
1995). 
30 
I . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . .  ~ : ? - . . . .  aaa- . ;~o~}=:  . . . . . . . . . . . . . . . . . . .  . . 7~.  7 -~ i.. 
RUnOFE# I bupro fen  
OESERIPT|ON: HUROfEH : tab let  ( vh i te  ) ; box of 20 - G~ Rezab - X5.8 F - . Boots 
Real thcare Laborator ies 
?~?SFr IOH:  0 tb  
~buDrot en . . . . . . . . . . . . . .  200  i~ 
INDICATZC~S: This dru9 Is a ,on -~tero ld / I  anct - ln f lu la tc ry  (NSAIPS). I t  IS used to 
treat various pal~s 
COliTRA.\[KOIC&Tl~44S: This drug should not be used in  the fo l low ing  cases: a l l~rt ly  to 
NSAtOS l in  par t i cu la r  t~_~p_trtn i 
WA~I~INCS: . . . . . .  . ? 
~RU? I~TER~'I'ZONS: This clru9 can In teract  ~ l tb  other  drugs. In  ~art~cular:  - asp l r , ,  
aria the other non s tero ida l  ~t~- tn f l~ la tory  drugs: ~ncrea.se of side ef fec ts .  - 
Lithium: ~?reas l  of blood hth~ul  rate.  
I 
PRECNN(CV MD 8REAST-rE?DINC: 
VeDm~ 
DOSAGE AnD .~DMINISTRATI(~4: ~ tab le t  swallowed v i th  a lass of 
aye .  ~ . 
t 
PC~SIeLE SlO? EFFECTS: 
Figure 2: The parallel English notice one authoring 
step later. 
5 Conc lus ion  
XML-based authoring tools are more and more 
widely used in the business community for sup- 
porting the production of technical documentation, 
controlling their quality and improving their re- 
usability. In this paper, we have stressed the connec- 
tions between these practices and current research in 
natural anguage generation and authoring. We have 
described a formalism which removes ome of the 
limitations of DTD's when used for the production 
of multilingual texts and presented its application to 
a certain domain of pharmaceutical documents. 
Acknowledgements  Thanks to Jean-Pierre 
Chanod, Marie-H~_lb.ne Corr/mrd, Sylvain Pogodalla 
and Aarne Ranta for important contributions, 
discussions and comments. 
References  
a. Coch. 1996. Evaluating and comparing three text 
production techniques. In Proceedings of the 16th 
International Confe~vnce on Computational kin- 
guistics. 
OVP l~ditions du Vidal, editor. 1998. Le VIDAL de 
la famille. HACHETTE. 
M. Dymetman. V. Lux, and A. Ranta. 2000. XML 
and multilingual document authoring: Conver- 
gent trends. In Pro,'eedings Coling 2000, Saar- 
brficken. 
A. Hartley and ('. Paris. 1997. Muhilingual docu- 
ment production-: from supporl for translating to 
support for authoring. In Machine Translation, 
Special Issue. on New Tools for Huma n TranslaT,.. 
tots, pages 109-128. 
L. Magnusson and B. Nordstr6m. 1994. The ALF 
proofeditor and its proof engine. In Lecture Notes 
in Computer Science 806: Springer. 
P. Martin-L6f. 1984. Intuitionistic Type Theory. 
Bibliopolis, Naples. 
P. M/ienp/ii and A. Ranta. 1999. The type theory 
and type checker of GF. In Colloquium on Prin- 
ziples, .Logics, ..and Implementations .ofHigh-Level 
Progrdmm.ihg L~inTJages, Worl~shop: On-Logical 
Frameworks and Meta-languages, Paris, Septem- 
ber. Available at h t tp  : / /www. cs .  chalmers, se /  
~aarne/papers/Ifm 1999. ps. gz. 
W. Pardi. 1999. XML in Action. Microsoft Press. 
Fernando C. N. Pereira and David H. D. Warren. 
1980. Definite clause grammars for language anal- 
ysis. Artificial Intelligence, 13:231-278. 
R. Power and D. Scott. 1998. Multilingual au- 
thoring using feedback texts. In Proceedings of 
the 17th International Conference on Computa- 
tional Linguistics and 36th Annual Meeting of the 
Association for Computational Linguistics, pages 
1053-1059. 
P. Prescod. 1998. Formalizing SGML 
and XML instances and schemata 
with forest automata theory. 
http ://www. prescod, net/forest/shorttut/. 
A. Ranta. Grammatical Framework work 
page. h t tp  ://www. cs .  chalmers, se /  
aarne/GF/pub/work -  index/ index,  html. 
E. Reiter. 1995. NLG vs. templates. In Proceedings 
of the 5th European Workshop on Natural Lan- 
guage Generation (EWNLG '95), pages 95-106, 
Leiden. 
W3C, 1998. Extensible Markup Language (XML) 
1.0, February. W3C reconunendation. 
W3C, 1999a. XML Schema - Part 1: Structu~vs, 
Part 2 : Datatypes -, December. W3C Working 
draft. 
W3C, 1999b. XSL Transformations (XSLT), 
November. W3C recommendation. 
D. Wood. 1995. Standard Generalized Markup Lan- 
guage: Mathematical and philosophical issues. 
Lecture Notes in Computer Science. 1000:344-- 
365. 
31 
Proceedings of the Third Workshop on Statistical Machine Translation, pages 159?162,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Using syntactic coupling features for discriminating phrase-based
translations (WMT-08 Shared Translation Task)
Vassilina Nikoulina and Marc Dymetman
Xerox Research Centre Europe
Grenoble, France
{nikoulina,dymetman}@xrce.xerox.com
Abstract
Our participation in the shared translation task
at WMT-08 focusses on news translation from
English to French. Our main goal is to con-
trast a baseline version of the phrase-based
MATRAX system, with a version that incor-
porates syntactic ?coupling? features in order
to discriminate translations produced by the
baseline system. We report results comparing
different feature combinations.
1 Introduction
Our goal is to try to improve the fluency and ad-
equacy of a baseline phrase-based SMT system by
using a variety of ?syntactic coupling features?, ex-
tracted from parses for the source and target strings.
These features are used for reranking the n-best can-
didates of the baseline system.
The phrase-based SMT system MATRAX, devel-
oped at XRCE, is used as the baseline in the experi-
ments. MATRAX is based on a fairly standard log-
linear model, but one original aspect of the system
is the use of non-contiguous bi-phrases such as ne
... plus / not ... anymore, where words in the source
and target phrases may be separated by gaps, to be
filled at translation time by lexical material provided
by some other such pairs (Simard et al, 2005).
For parsing, we use the Xerox Incremental Parser
XIP (A??t-Mokhtar et al, 2002), which is a robust
dependency parser developed at the Xerox Research
Centre Europe. XIP is fast (around 2000 words per
second for English) and is well adapted to a situ-
ation, like the one we have here, were we need to
parse on the order of a few hundred target candi-
dates on the fly. Also of interest to us is the fact that
XIP produces labelled dependencies, a feature that
we use in some of our experiments.
1.1 Decoding and Training
We resort to a standard reranking approach in which
we produce an n-best list of MATRAX candidate
translations (with n = 100 in our experiments), and
then rerank this list with a linear combination of our
parse-dependent features. In order to train the fea-
ture weights, we use an averaged structured percep-
tron approach (Roark et al, 2004), where we try to
learn weights such that the first candidate to emerge
is equal to the ?oracle? candidate, that is, the candi-
date that is closest to the reference in terms of NIST
score.
1.2 Coupling Features
Our general approach to computing coupling fea-
tures between the dependency structure of the source
and that of a candidate translation produced by MA-
TRAX is the following: we start by aligning the
words between the source and the candidate trans-
lation, we parse both sides, and we count (possi-
bly according to a weighting scheme) the number of
configurations (?rectangles?) that are of the follow-
ing type: ((s1, s12, s2), (t1, t12, t2)), where s12 is an
edge between s1 and s2, t12 is an edge between t1
and t2, s1 is aligned with t1 and s2 is aligned with
t2. We implemented several variants of this basic
scheme.
We start by describing different ?generic? cou-
pling functions derived from the basic scheme, as-
159
suming that word alignments have been already de-
termined, then we describe the option of taking into
account specific dependency labels when counting
rectangles, and finally we describe two options for
computing the word alignments.
1.2.1 Generic features
The first measure of coupling is based on sim-
ple, non-weighted, word alignments. Here we sim-
ply consider that a word of the source and a word
of the target are aligned or not aligned, without any
intermediary degree, and consider that a rectangle
exists on the quadruple of words s1, s2, t1, t2 iff si
is aligned to ti, s1 and s2 have a dependency link
between them (in whatever direction) and similarly
for t1 and t2. The first feature that we introduce,
Coupling-Count, is simply the count of all such rect-
angles between the source and the target.
We note that the value of this feature tends to be
correlated with the size of the source and target de-
pendency trees. We therefore introduce some nor-
malized variants of the feature:
? Coupling-Recall. We compute the number of
source edges for which there exists a projec-
tion in the target. More formally, the number of
edges between two words s1, s2 such that there
exist two words t1, t2 with si aligned to ti and
such that t1, t2 have an edge between them. We
then divide this number by the total number of
edges in the source.
? Coupling-Precision. We do the same thing this
time starting from the target.
? Coupling-F-measure. This is defined as the
harmonic mean of the two previous features.
1.2.2 Label-specific features
The features previously defined do not take into
account the labels associated with edges in the de-
pendency trees. However, while rectangles of the
form ((s1, subj, s2), (t1, subj, t2)) may be rather sys-
tematic between such languages as English and
French, other rectangles may be much less so, due
on the one hand to actual linguistic divergences be-
tween the two languages, but also, as importantly
in practice, to different representational conventions
used by different grammar developers for the two
languages.1
In order to control this problem, we introduce a
collection of Label-Specific-Coupling features, each
for a specific pair of source label and target label.
The values of a label-specific feature are the num-
ber of occurrences for this specific label pair. We
use only label pairs that have been observed to be
aligned in the training corpus (that is, that partici-
pate in observed rectangles). In one version of that
approach, we use all such pairs found in the corpus,
in another version only the pairs above a certain fre-
quency threshold in the corpus.
1.2.3 Alignment
In order to compute the features described above,
a prerequisite is to be able to determine a word align-
ment between the source and a candidate translation.
Our first approach is to use GIZA++ (correspond-
ing roughly to IBM Model 4) to create these align-
ments, by producing for a given source and a given
candidate translation n-best alignment lists in both
directions and applying standard techniques of sym-
metrization to produce a bidirectional alignment.
Another way to find word alignments is to use the
information provided by the baseline system. Since
MATRAX is a phrase-based system, it has access to
the bi-phrases (aligned by definition) that are used in
order to generate a candidate translation. However
note that when we use a bi-phrase based alignment,
there will be differences from the word alignment
that we discussed before, and we need to adapt our
coupling functions.
1.2.4 Related approaches
There is a growing body of work on the use of
syntax for improving the quality of SMT systems.
Our approach is closest to the line taken in (Och
et al, 2003), where syntactic features are also used
for discriminating between candidates produced by
a phrase-based system, but here we introduce and
compare results for a wider variety of coupling fea-
tures, taking into account different combinations in-
volving normalization of the counts, symmetrized
features between the source and target, labelled de-
1Although the XIP formalism is shared between grammar
developers of French and English, the grammars do sometimes
follow different conventions.
160
pendencies, and also consider several ways for com-
puting the word alignment on the basis of which
edge couplings are determined.
2 Experiments
2.1 Description
Our participation concerns the English to French
News translation task. To train our baseline system
we used the News Commentary corpus, namely the
training (? 1M words) and development (1057 sen-
tences) sets proposed for the shared translation task.
The same development set was used for the MERT
training procedure of the baseline system, as well
as for learning the parameters of the reranking pro-
cedure. Note that the test data on which we report
our experimental results here is the one proposed as
development test set for the News translation task
(1064 sentences, nc-devtest2007).
Using MATRAX as the baseline system we gen-
erate 100-best lists of candidate translations for all
source sentences of the test set, we rerank these can-
didates using our features, and we output the top
candidate. We present our results in Table 1, distin-
guished according to the actual combination of fea-
tures used in each experiment.
? The Baseline entry in the table corresponds to
MATRAX results on the test set, without the
use of any of the coupling features.
? We distinguish two sub-tables, according to
whether Giza-based alignments or phrase-
based alignments were used.
? The Generic keyword corresponds to the cou-
pling features introduced in section 1.2.1, based
on rectangle counts, independent of the labels
of the edges.
? The Matrax keyword corresponds to using
MATRAX ?internal? features as reranking fea-
tures, along with the coupling features. These
MATRAX features are pretty standard phrase-
based features, apart from some features deal-
ing explicitly with gapped phrases, and are de-
scribed in detail in (Simard et al, 2005).
? The Labels and Frequent Labels keywords cor-
responds to using label-specific features. In
the first case (Labels) we extracted all of the
aligned label pairs (label pair associated with
a coupling rectangle) found in a training set,
while in the second case (Frequent Labels), we
only kept the most frequently observed among
these label pairs.
? When several keywords appear on a line, we
used the union of the corresponding features,
and in the last line of the table, we show a
combination involving at the same time some
features computed on the basis of Giza-based
alignments and of phrase-based alignments.
? Along with the NIST and BLEU scores of each
combination, we also conducted an informal
manual assessment of the quality of the re-
sults relative to the MATRAX baseline. We
took a random sample of 100 source sentences
from the test set and for each sentence, assessed
whether the first candidate produced by rerank-
ing was better, worse, or indistinguishable in
terms of quality relative to the baseline trans-
lation. We report the number of improvements
(+) and deteriorations (-) among these 100 sam-
ples as well as their difference.2
3 Discussion
While the overall results in terms of Bleu and Nist
do not show major improvements relative to the
baseline, there are several interesting observations
to make. First of all, if we focus on feature com-
binations in which MATRAX features are included
(shown in italics in the table), we see that there is a
general tendency for the results, both in terms of au-
tomatic and human evaluations, to be better than for
the same combination without the MATRAX fea-
tures; the explanation seems to be that if we do
not use the MATRAX features during reranking, but
consider the 100 candidates in the n-best list to be
equally valuable from the viewpoint of MATRAX
features, we lose essential information that cannot
2All the results reported here correspond to our own evalu-
ations, prior to the WMT evaluations. Given time constraints,
we focussed more on contrasting the baseline with the baseline
+ coupling features, than in tuning the baseline itself for the
task at hand. After the submission deadline, we were able to
improve the baseline for this task.
161
NIST BLEU - + Diff
Baseline 6.4093 0.2034 0 0 0
Giza-based alignments
Generic 6.3383 0.2043 15 17 2
Generic, Matrax 6.3782 0.2083 4 18 14
Labels 6.3483 0.1963 12 18 6
Labels, Generic 6.3514 0.2010 3 18 15
Labels, Generic, Matrax 6.4016 0.2075 3 20 17
Frequent Labels 6.3815 0.2054 7 11 4
Frequent Labels, Generic 6.3826 0.2044 6 18 12
Frequent Labels, Generic, Matrax 6.4177 0.2100 2 16 14
Phrase-based alignments
Generic 6.2869 0.1964 12 14 2
Generic, Matrax 6.3972 0.2031 4 11 7
Labels 6.3677 0.1995 16 15 -1
Labels, Generic 6.3567 0.1977 8 15 7
Labels, Generic, Matrax 6.4269 0.2049 4 17 13
Frequent Labels 6.3701 0.1998 3 15 12
Frequent Labels, Generic 6.3846 0.2013 7 16 9
Frequent Labels, Generic, Matrax 6.4160 0.2049 4 16 12
Giza Generic, Phrase Generic, Giza Labels, Matrax 6.4351 0.2060 7 22 15
Table 1: Reranking results.
be recovered simply by appeal to the syntactic cou-
pling features.
If we now concentrate on the lines which do in-
clude MATRAX features and compare their results
with the baseline, we see a trend for these results to
be better than the baseline, both in terms of auto-
matic measures as (more strongly) in terms of hu-
man evaluation. Taken individually, perhaps the im-
provements are not very clear, but collectively, a
trend does seem to appear in favor of syntactic cou-
pling features generally, although we have not con-
ducted formal statistical tests to validate this impres-
sion. A more detailed comparison between individ-
ual lines, inside the class of combinations that in-
clude MATRAX features, appears however difficult
to make on the basis of the reported experiments.
References
Salah A??t-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond shallowness: incre-
mental deep parsing. Natural Language Engineering,
8(3):121?144.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syn-
tax for Statistical Machine Translation: Final report of
John Hopkins 2003 Summer Workshop. Technical re-
port, John Hopkins University.
B. Roark, M. Saraclar, M. Collins, and M. Johnson.
2004. Discriminative language modeling with condi-
tional random fields and the perceptron algorithm. In
Proceedings of the 42nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL?04), July.
Michel Simard, Nicola Cancedda, Bruno Cavestro,
Marc Dymetman, ?Eric Gaussier, Cyril Goutte,
Kenji Yamada, Philippe Langlais, and Arne Mauser.
2005. Translating with non-contiguous phrases. In
HLT/EMNLP.
162
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 55?60,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Experiments in discriminating phrase-based translations on the basis of
syntactic coupling features
Vassilina Nikoulina and Marc Dymetman
Xerox Research Centre Europe
Grenoble, France
{nikoulina,dymetman}@xrce.xerox.com
Abstract
We describe experiments on discriminating
English to French phrase-based translations
through the use of syntactic ?coupling? fea-
tures. Using a robust rule-based dependency
parser, we parse both the English source and
the French translation candidates from the n-
best list returned by our phrase-based system;
we compute for each candidate a number of
coupling features, that is, values that depend
on the amount of alignment between edges in
the source and target structures, and discrim-
inatively train the weights of these coupling
features. We compare different feature combi-
nations. Although the improvements in terms
of automatic measures such as Bleu and Nist
are inconclusive, an initial human assessment
of the results appears to show certain qualita-
tive improvements.
1 Introduction
1.1 Motivation
When we use the phrase-based SMT system MA-
TRAX (Simard et al, 2005) to translate the sen-
tence Our declaration of rights is the first of this
millenium from English to French, the result re-
turned by the system is the erroneous translation
Notre de?claration des droits de la premie`re est de
ce mille?naire, while somewhere down the n-best list
of lesser-scored candidates we find a correct transla-
tion: Notre de?claration des droits est la premie`re de
ce mille?naire.
On closer inspection, the difference of scores be-
tween the two candidates is the following. In the
second (correct) case, the phrase of rights was trans-
lated into the phrase des droits, while in the first (in-
correct) case, the phrase of was translated into the
phrase de and the phrase rights into the phrase des
droits. However, while the two bi-phrases of/de and
rights/des droits independently make perfect sense,
the sequence de des droits in French is not possi-
ble, a situation which is easily detected by a stan-
dard ngram language model; the language model has
then a tendency to try to place the (in fact superflu-
ous) de at a further place in the target (just before
la premie`re), where it is more acceptable to it. The
overall consequence is a translation that while for-
mally possible from the viewpoint of a simple lan-
guage model, is not an adequate representation of
the meaning of the source.
Now suppose that we parse both the source and
the two candidates with a dependency parser. If we
compare the parses of the source and of the correct
translation, we find a close (in the current exam-
ple, very close) isomorphism between dependency
edges connecting pairs of aligned words (s1, s2) and
(t1, t2), where si is aligned to ti: the presence of
an edge between s1 and s2 often implies that of an
edge between t1 and t2. This is less the case if we
compare the parses of the source and of the incor-
rect translation; in this case, the word premie`re is
now linked to droits, while the word first was linked
to millenium.
While this is of course just one example, it does
help to motivate the approach we have taken: we
compute different measures of association strength
between edges in the source and target dependency
trees, and use these measures as features for rerank-
55
ing the n-best candidates of a baseline phrase-based
system. The hope is that by doing so, we will in-
crease the adequacy of translations, and possibly to
some extent, their fluency (at least their ?seman-
tic? fluency, which is influenced by their adequacy,
as opposed to their ?grammatical? fluency, which
would be better addressed by target-specific syntac-
tic features than by coupling syntactic features).
1.2 Related Work
There is a growing body of work on the use of syntax
for improving statistical machine translation, from
approaches such as (Chiang, 2007) that use ?formal
syntax?, that is syntactic structures for the source
and target that are discovered on the basis of a bilin-
gual corpus, but without resort to an externally mo-
tivated parser, to approaches such as (Yamada and
Knight, 2001) and (Marcu et al, 2006) that use an
external parser on the target only, or such as (Quirk
et al, 2005) on the source only, or such as (Cowan et
al., 2006) that use external parsers both on the source
and on the target.
Our approach is in this last category, but is distin-
guished from all the cited approaches by the fact that
it does not try to build a target structure (or string)
directly, but rather by using a baseline phrase-based
system as a generator of candidates, and then select-
ing between these candidates through a discrimina-
tive procedure. Some other researchers have taken a
similar line, for example (Hasan et al, 2006), which
only uses a parser on the target, and attempts to im-
prove the fluency of the translation produced, and es-
pecially (Och et al, 2003) that reports experiments
using a large number of syntactic features. In one
of the experiments briefly reported, a dependency
parser is used both for the source and for the tar-
get and a few features are introduced for counting
the number of edges that project from the source
to the target. This experiment, which as far as we
know was not followed up by deeper investigations,
is very similar to what we do. However we intro-
duce and compare results for a wider variety of cou-
pling features, taking into account different combi-
nations involving normalization of the counts, sym-
metrized features between the source and target, la-
belled dependencies, and also consider several ways
for computing the word alignment on the basis of
which edge couplings are determined.
2 The approach
2.1 Background
Matrax. The phrase-based SMT system Matrax
(Simard et al, 2005), developed at Xerox, was
used in the experiments. Matrax is based on a
fairly standard log-linear model, but one original as-
pect of the system is the use of non-contiguous bi-
phrases. Most existing phrase-based models depend
on phrases that are sequences of contiguous words
on either the source or the target side (e.g. pren-
dre feu / catch fire). By contrast, Matrax considers
pairs of non-contiguous phrases, such as ne ... plus /
not ... anymore, where words in the source and tar-
get phrases may be separated by gaps, to be filled
at translation time by lexical material provided by
some other such pairs. One motivation behind this
approach is that, basically, the fact that the source
expression ne ... plus is a good predictor of not
... anymore does not depend on the lexical material
appearing inside the source expression, an insight
which is generally unexploitable by models based
on contiguous phrases.1
XIP. For parsing, we used the Xerox Incremen-
tal Parser XIP (A??t-Mokhtar et al, 2002), which is
a robust dependency parser developed at the Xerox
Research Centre Europe. XIP is fast (around 2000
words per second for English) and is well adapted to
a situation, like the one we have here, were we need
to parse on the order of a few hundred target candi-
dates on the fly. Also of interest to us is the fact that
XIP produces labelled dependencies, a feature that
we use in some of our experiments.
2.2 Decoding and Training
Coupling features such as the ones we use require
access to the parses of candidate translations, and
these parses, at least for a parser such as XIP (and
for many similar parsers), can only be obtained once
the complete candidate translation is known. This is
why it is difficult to introduce them internally in the
Matrax stack-based decoder, which would require to
provide partial parses for prefixes of the target can-
didates and also associated heuristics to estimate the
syntactic structure of completions of these prefixes.
1The Hiero system (Chiang, 2007) is a well-known in-
stance of a structure-oriented system that also has a notion of
gapped phrases, but contrary to Hiero, Matrax is based on non-
hierarchical phrases.
56
Instead, we resort to a standard reranking approach
in which we produce an n-best list of Matrax candi-
date translations (with n = 100 in our experiments),
and then rerank this list with a linear combination
of our parse-dependent features. In order to train
the feature weights, we use an averaged structured
perceptron approach a` la Collins, where we try to
learn weights such that the first candidate to emerge
is equal to the ?oracle? candidate, that is, the candi-
date that is closest to the reference in terms of NIST
score.
2.3 Coupling Features
Our general approach to computing coupling fea-
tures between the dependency structure of the source
and that of a candidate translation produced by Ma-
trax is the following: we start by aligning the words
between the source and the candidate translation, we
parse both sides, and we count (possibly according
to a weighting scheme) the number of configura-
tions (?rectangles?) that are of the following type:
((s1, s12, s2), (t1, t12, t2)), where s12 is an edge be-
tween s1 and s2, t12 is an edge between t1 and t2,
s1 is aligned with t1 and s2 is aligned with t2. We
implemented several variants of this basic scheme.
We start by describing different ?generic? cou-
pling functions derived from the basic scheme, as-
suming that word alignments have been already de-
termined, then we describe the option of taking into
account specific dependency labels when counting
rectangles, and finally we describe two options for
computing the word alignments.
2.3.1 Generic features
The first measure of coupling is based on sim-
ple, non-weighted, word alignments. Here we sim-
ply consider that a word of the source and a word
of the target are aligned or not aligned, without any
intermediary degree, and consider that a rectangle
exists on the quadruple of words s1, s2, t1, t2 iff si
is aligned to ti, s1 and s2 have a dependency link
between them (in whatever direction) and similarly
for t1 and t2. The first feature that we introduce,
Coupling-Count, is simply the count of all such rect-
angles between the source and the target.
We note that the value of this feature tends to be
correlated with the size of the source and target de-
pendency trees. We therefore introduce some nor-
malized variants of the feature:
? Coupling-Recall. We compute the number of
source edges for which there exists a projec-
tion in the target. More formally, the number of
edges between two words s1, s2 such that there
exist two words t1, t2 with si aligned to ti and
such that t1, t2 have an edge between them. We
then divide this number by the total number of
edges in the source.
? Coupling-Precision. We do the same thing this
time starting from the target.
? Coupling-F-measure. In the case of perfectly
isomorphic dependency trees (a situation that
of course rarely occurs because of the linguis-
tic divergences between languages), we would
have precision and recall both equal to 1. In or-
der to measure divergence from this ideal case,
we introduce a feature that we call Coupling-
F-measure, which is defined as the harmonic
mean of the two previous features.
One deficiency of the previous measures is that
they rely a lot on ?hard? word alignments, but do not
take into account the probability of aligning a source
and a target word. We introduce another feature
Coupling-Lex that exploits lexical translation prob-
abilities: each rectangle found between the source
and target trees is weighted according to the prod-
uct of the translation probabilities associated with
(s1, t1) and (s2, t2).
2.3.2 Label-specific features
The features previously defined do not take into
account the labels associated with edges in the de-
pendency trees. However, while rectangles of the
form ((s1, subj, s2), (t1, subj, t2)) may be rather sys-
tematic between such languages as English and
French, other rectangles may be much less so, due
on the one hand to actual linguistic divergences be-
tween the two languages, but also, as importantly
in practice, to different representational conventions
used by different grammar developers for the two
languages.2
In order to control this problem, we introduce a
collection of Label-Specific-Coupling features, each
for a specific pair of source label and target label.
2Although the XIP formalism is shared between grammar
developers of French and English, the grammars do sometimes
follow slightly different conventions.
57
The values of a label-specific feature are the num-
ber of occurrences for this specific label pair. We
use only label pairs that have been observed to be
aligned in the training corpus (that is, that partici-
pate in observed rectangles). In one version of that
approach, we use all such pairs found in the corpus,
in another version only the pairs above a certain fre-
quency threshold in the corpus.
2.3.3 Giza-based alignment
In order to compute the features described above,
a prerequisite is to be able to determine a word align-
ment between the source and a candidate transla-
tion. Our first approach is to use GIZA++ to create
these alignments, by producing for a given source
and a given candidate translation n-best alignment
lists in both directions and applying standard tech-
niques of symmetrization to produce a bidirectional
alignment.
2.3.4 Phrase-based alignment
Another way to find word alignments is to use the
information provided by our baseline system. Since
Matrax is a phrase-based system, it has access to
the bi-phrases (aligned by definition) that are used
in order to generate a candidate translation. How-
ever note that if we use the bi-phrases directly we
are not able to establish the alignments on a word
level (since Matrax does not provide any informa-
tion about word alignments inside the bi-phrases),
but only on a phrase level, and we need to adapt the
coupling features accordingly.
To overcome this problem, we will transform the
dependencies between words into dependencies be-
tween phrases. Thus, two phrases c1, c2 will have a
dependency edge between them if there exists a de-
pendency edge between a word w1 ? c1 and a word
w2 ? c2. Once this transformation is done both
for the source and the target, we get dependency
graphs having phrases as nodes. We also know the
alignments between these phrases, implicit in the bi-
phrases used by Matrax. So, we can consider the
phrases as super-words, and introduce coupling fea-
tures of the same type as before, but operating on a
higher level (super-words) this time.
3 Experiments
3.1 Description
For all our experiments we use the training, develop-
ment and test sets provided for the English-French
News Commentary corpus in WMT-08. The num-
ber of sentences in these sets are respectively 55039,
1057 and 1064, and the average sentence length is 21
words (English) and 24.5 words (French).
We take Matrax as the baseline system. With this
system we generate 100-best lists of candidate trans-
lations for all source sentences of the test set, we
rerank these candidates using our features, and we
output the top candidate. We present our results in
Table 1, distinguished according to the actual com-
bination of features used in each experiment.
? The Baseline entry in the table corresponds to
Matrax results on the test set, without the use
of any of the coupling features.
? We distinguish two sub-tables, according to
whether Giza-based alignments or phrase-
based alignments were used.
? The Generic keyword corresponds to the cou-
pling features introduced in section 2.3.1, based
on rectangle counts, independent of the labels
of the edges.
? The Matrax keyword corresponds to using Ma-
trax ?internal? features as reranking features,
along with the coupling features. These Ma-
trax features are pretty standard phrase-based
features, apart from some features dealing ex-
plicitly with gapped phrases, and are described
in detail in (Simard et al, 2005).
? The Labels and Frequent Labels keywords cor-
responds to using label-specific features. In
the first case (Labels) we extracted all of the
aligned label pairs (label pair associated with a
coupling rectangle) found in a training set of
1000 source sentences along with their 100-
best Matrax translations (this set was chosen
to be different from the development set in or-
der to avoid overfitting effects when rerank-
ing on the development set); we then obtained
2053 features of this kind. In the second case
58
NIST BLEU - + Diff
Baseline 6.4093 0.2034 0 0 0
Giza-based alignments
Generic 6.3383 0.2043 15 17 2
Generic, Matrax 6.3782 0.2083 4 18 14
Labels 6.3483 0.1963 12 18 6
Labels, Generic 6.3514 0.2010 3 18 15
Labels, Generic, Matrax 6.4016 0.2075 3 20 17
Frequent Labels 6.3815 0.2054 7 11 4
Frequent Labels, Generic 6.3826 0.2044 6 18 12
Frequent Labels, Generic, Matrax 6.4177 0.2100 2 16 14
Phrase-based alignments
Generic 6.2869 0.1964 12 14 2
Generic, Matrax 6.3972 0.2031 4 11 7
Labels 6.3677 0.1995 16 15 -1
Labels, Generic 6.3567 0.1977 8 15 7
Labels, Generic, Matrax 6.4269 0.2049 4 17 13
Frequent Labels 6.3701 0.1998 3 15 12
Frequent Labels, Generic 6.3846 0.2013 7 16 9
Frequent Labels, Generic, Matrax 6.4160 0.2049 4 16 12
Giza Generic, Phrase Generic, Giza Labels, Matrax 6.4351 0.2060 7 22 15
Table 1: Reranking results.
(Frequent Labels), we only kept the most fre-
quently observed among these label pairs, re-
taining only 137 such features.
? When several keywords appear on a line, we
used the union of the corresponding features,
and in the last line of the table, we show a
combination involving at the same time some
features computed on the basis of Giza-based
alignments and of phrase-based alignments.
? Along with the NIST and BLEU scores of each
combination3, we also conducted an informal
manual assessment of the quality of the results
relative to the Matrax baseline. We took a ran-
dom sample of 100 source sentences from the
test set and for each sentence, assessed whether
the first candidate produced by reranking was
better, worse, or indistinguishable in terms of
quality relative to the baseline translation. We
report the number of improvements (+) and de-
teriorations (-) among these 100 samples as
well as their difference.
3These scores were computed on the basis of only one ref-
erence.
3.2 Discussion of the results
While the overall results in terms of Bleu and Nist
do not show major improvements relative to the
baseline, there are several interesting observations to
make. First of all, if we focus on feature combina-
tions in which Matrax features are included (shown
in italics in the table), we see that there is a gen-
eral tendency for the results, both in terms of auto-
matic and human evaluations, to be better than for
the same combination without the Matrax features;
the explanation seems to be that if we do not use the
Matrax features during reranking, but consider the
100 candidates in the n-best list to be equally valu-
able from the viewpoint of Matrax features, we lose
essential information that cannot be recovered sim-
ply by appeal to the syntactic coupling features.4
If we now concentrate on the lines which do in-
clude Matrax features and compare their results with
the baseline, we see a trend for these results to be
better than the baseline, both in terms of automatic
measures as (more strongly) in terms of human eval-
4This is not very surprising and probably on the basis of this
observation it would be useful in further experiments to intro-
duce as an additional feature the log-linear score given by the
Matrax baseline.
59
uation. Taken individually, perhaps the improve-
ments are not very clear, but collectively, a trend
does seem to appear in favor of syntactic coupling
features generally, although we have not conducted
formal statistical tests to validate this impression. A
more detailed comparison between individual lines,
inside the class of combinations that include Matrax
features, appears however difficult to make on the
basis of the current experiments.
4 Conclusion and Perspectives
Although there is some consensus that the future
of statistical machine translation lies in the use of
structural information, it is generally admitted that
it is currently difficult to significantly improve over
phrase-base systems in this way, at least in terms of
automatic evaluation measures. Our results do not
contradict that impression, although they are more
encouraging in terms of preliminary human asses-
ments than in terms of the automatic measures.
The reranking approach to using syntactic fea-
tures on top of a phrase-based system is attractive
because on the one hand it is easier to implement
than a full new syntax-aware decoder, and on the
other hand it guarantees at least as good perfor-
mance as the baseline phrase-based system, if some
precautions are taken. On the other hand, its main
limitations concern the size of the n-best list of can-
didates that is realistic in terms of decoding time.5
At least two approaches seem promising in order to
alleviate this problem: (1) find a way to capitalize
on the factorization of translation candidates in the
internal lattice used by the phrase-based decoder, in
order to produce factorized parses that would permit
comparison between more candidates than can be
seen through a final n-best list; (2) allow the reranker
to perform local transformations of the n-best candi-
dates, in the spirit of (Langlais et al, 2007), in order
to be able to explore a larger space of promising can-
didates than is provided by the static list.
Another interesting direction would be to learn
the feature weights by reranking towards another
type of oracle than the one we used, which is de-
fined as the closest candidate in the list in terms of
NIST score relative to the reference; instead it might
5It should be noted however that we could increase this size
from 100 to 1000 without incurring too much penalty, given the
speed of the XIP parser we use.
be worthwhile to use as an oracle the candidate in
the list which receives the best human assessment
in terms of fluency and adequacy, giving a better
chance to the syntactic features to show their worth;
but this would probably also require that these sys-
tems be mostly evaluated in terms of human assess-
ment, a trend which is more and more noticeable in
the SMT community.
References
Salah A??t-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond shallowness: incre-
mental deep parsing. Natural Language Engineering,
8(3):121?144.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Brooke Cowan, Ivona Kucerova, and Michael Collins.
2006. A discriminative model for tree-to-tree trans-
lation. In Proceedings EMNLP.
Sas?a Hasan, Oliver Bender, and Hermann Ney. 2006.
Reranking translation hypotheses using structural
properties. In Proceedings of the EACL Workshop on
Learning Structured Information in Natural Language
Applications.
Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.
2007. A greedy decoder for phrase-based statistical
machine translation. In Proceedings of the 11th Inter-
national Conference on Theoretical and Methodolog-
ical Issues in Machine Translation, pages 104?113,
Skvde, Sweden, Sept.
D. Marcu, W. Wang, A. Echihabi, and K. Knight.
2006. SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases. In Proceedings
EMNLP, pages 44?52.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syn-
tax for statistical machine translation: Final report of
john hopkins 2003 summer workshop. Technical re-
port, John Hopkins University.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In ACL05.
Michel Simard, Nicola Cancedda, Bruno Cavestro,
Marc Dymetman, E?ric Gaussier, Cyril Goutte,
Kenji Yamada, Philippe Langlais, and Arne Mauser.
2005. Translating with non-contiguous phrases. In
HLT/EMNLP.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proceedings ACL,
pages 531?538.
60
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1125?1134, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Exact Sampling and Decoding in High-Order Hidden Markov Models
Simon Carter?
ISLA, University of Amsterdam
Science Park 904, 1098 XH Amsterdam,
The Netherlands
s.c.carter@uva.nl
Marc Dymetman Guillaume Bouchard
Xerox Research Centre Europe
6, chemin de Maupertuis
38240 Meylan, France
{first.last}@xrce.xerox.com
Abstract
We present a method for exact optimization
and sampling from high order Hidden Markov
Models (HMMs), which are generally han-
dled by approximation techniques. Motivated
by adaptive rejection sampling and heuris-
tic search, we propose a strategy based on
sequentially refining a lower-order language
model that is an upper bound on the true
model we wish to decode and sample from.
This allows us to build tractable variable-order
HMMs. The ARPA format for language mod-
els is extended to enable an efficient use of the
max-backoff quantities required to compute
the upper bound. We evaluate our approach
on two problems: a SMS-retrieval task and a
POS tagging experiment using 5-gram mod-
els. Results show that the same approach can
be used for exact optimization and sampling,
while explicitly constructing only a fraction of
the total implicit state-space.
1 Introduction
In NLP, sampling is important for many real tasks,
such as: (i) diversity in language generation or
machine translation (proposing multiple alternatives
which are not clustered around a single maximum);
(ii) Bayes error minimization, for instance in Statis-
tical Machine Translation (Kumar and Byrne, 2004);
(iii) learning of parametric and non-parametric
Bayesian models (Teh, 2006).
However, most practical sampling algorithms are
based on MCMC, i.e. they are based on local moves
?This work was conducted during an internship at XRCE.
starting from an initial valid configuration. Often,
these algorithms are stuck in local minima, i.e. in
a basin of attraction close to the initialization, and
the method does not really sample the whole state
space. This is a problem when there are ambiguities
in the distribution we want to sample from: by hav-
ing a local approach such as MCMC, we might only
explore states that are close to a given configuration.
The necessity of exact sampling can be ques-
tioned in practice. Approximate sampling tech-
niques have been developed over the last century
and seem sufficient for most purposes. However,
the cases where one actually knows the quality of
a sampling algorithm are very rare, and it is com-
mon practice to forget about the approximation and
simply treat the result of a sampler as a set of i.i.d.
data. Exact sampling provides a de-facto guarantee
that the samples are truly independent. This is par-
ticularly relevant when one uses a cascade of algo-
rithms in complex NLP processing chains, as shown
by (Finkel et al 2006) in their work on linguistic
annotation pipelines.
In this paper, we present an approach for exact
decoding and sampling with an HMM whose hid-
den layer is a high-order language model (LM),
which innovates on existing techniques in the fol-
lowing ways. First, it is a joint approach to sam-
pling and optimization (i.e. decoding), which is
based on introducing a simplified, ?optimistic?, ver-
sion q(x) of the underlying language model p(x),
for which it is tractable to use standard dynamic pro-
gramming techniques both for sampling and opti-
mization. We then formulate the problem of sam-
pling/optimization with the original model p(x) in
1125
terms of a novel algorithm which can be viewed
as a form of adaptive rejection sampling (Gilks
and Wild, 1992; Gorur and Teh, 2008), in which
a low acceptance rate (in sampling) or a low ratio
p(x?)/q(x?) (in optimization, with x? the argmax
of q) leads to a refinement of q, i.e., a slightly more
complex and less optimistic q but with a higher ac-
ceptance rate or ratio.
Second, it is the first technique that we are aware
of which is able to perform exact samplingwith such
models. Known techniques for sampling in such
situations have to rely on approximation techniques
such as Gibbs or Beam sampling (see e.g. (Teh et
al., 2006; Van Gael et al 2008)). By contrast, our
technique produces exact samples from the start, al-
though in principle, the first sample may be obtained
only after a long series of rejections (and therefore
refinements). In practice, our experiments indicate
that a good acceptance rate is obtained after a rel-
atively small number of refinements. It should be
noted that, in the case of exact optimization, a sim-
ilar technique to ours has been proposed in an im-
age processing context (Kam and Kopec, 1996), but
without any connection to sampling. That paper,
written in the context of image processing, appears
to be little known in the NLP community.
Overall, our method is of particular interest be-
cause it allows for exact decoding and sampling
from HMMs where the applications of existing dy-
namic programming algorithms such as Viterbi de-
coding (Rabiner, 1989) or Forward-Backward sam-
pling (Scott, 2002) are not feasible, due to a large
state space.
In Section 2, we present our approach and
describe our joint algorithm for HMM sam-
pling/optimization, giving details about our exten-
sion of the ARPA format and refinement proce-
dure. In Section 3 we define our two experimental
tasks, SMS-retrieval and POS tagging, for which we
present the results of our joint algorithm. We finally
discuss perspectives and conclude in Section 4.
2 Adaptive rejection sampling and
heuristic search for high-order HMMs
Notation Let x = {x1, x2, ...x?} be a given hid-
den state sequence (e.g. each xi is an English word)
which takes values in X = {1, ? ? ? , N}? where ?
is the length of the sequence and N is the number
of latent symbols. Subsequences (xa, xa+1, ? ? ? , xb)
are denoted by xba, where 1 ? a ? b ? ?. Let
o = {o1, o2, ...o?} be the set of observations asso-
ciated to these words (e.g. oi is an acoustic realiza-
tion of xi). The notations p, q and q? refer to un-
normalized densities, i.e. non-negative measures on
X . Since only discrete spaces are considered, we
use for short p(x) = p({x}). When the context
is not ambiguous, sampling according to p means
sampling according to the distribution with density
p?(x) = p(x)p(X ) , where p(X ) =
?
X p(x)dx is the total
mass of the unnormalized distribution p.
Sampling The objective is to sample a se-
quence with density p?(x) proportional to p(x) =
plm(x)pobs(o|x) where plm is the probability of the
sequence x under a n-gram model and pobs(o|x)
is the probability of observing the noisy sequence
o given that the correct/latent sequence is x. As-
suming the observations depend only on the current
state, this probability becomes
p(x) =
??
i=1
plm(xi|x
i?1
i?n+1)pobs(oi|xi) . (1)
To find the most likely sequence given an ob-
servation, or to sample sequences from Equa-
tion 1, standard dynamic programming techniques
are used (Rabiner, 1989; Scott, 2002) by expand-
ing the state space at each position. However, as
the transition order n increases, or the number of la-
tent tokens N that can emit to each observation ol
increases, the dynamic programming approach be-
comes intractable, as the number of operations in-
creases exponentially in the order of O(?Nn).
If one can find a proposal distribution q which is
an upper bound of p ? i.e such that q(x) ? p(x) for
all sequences x ? X ? and which it is easy to sam-
ple from, the standard rejection sampling algorithm
can be used:
1. Sample x ? q/q(X ), with q(X ) =
?
X q(x)dx;
2. Accept x with probability p(x)/q(x), other-
wise reject x;
To obtain multiple samples, the algorithm is re-
peated several times. However, for simple bounds,
1126
!""#$%
&'(% )(*%!" #!$ % !" %$& %&+,% -#./,)%!" #'( % !" )*+,(% %
$% 0% 1% 2% 3%)(*4%!" %$&- %
(a)
!""#$%
$% &%
'()%
*)+%
*)+%
!" #!$ % !% &$'(#!$ %
!" &$' % #,-./*%'0/%
*)+1% !" &$') %
*)+1%!" &$') %2% 3%
4%
5%
!" #*+ % !" ,-./+& %
(b)
Figure 1: An example of an initial q-automaton (a), and the refined q-automaton (b) Each state corresponds
to a context (only state 6 has a non-empty context) and each edge represents the emission of a symbol.
Thick edges are representing the path for the sampling/decoding of two dog(s) barked, thin edges
corresponding to alternative symbols. By construction, w1(dog) ? w2(dog|two) so that the total weight
of (b) is smaller than the total weight of (a).
the average acceptance rate ? which is equal to
p(X )/q(X ) ? can be so large that rejection sam-
pling is not practical. In adaptive rejection sampling
(ARS), the initial bound q is incrementally improved
based on the values of the rejected elements. While
often based on log-concave distributions which are
easy to bound, ARS is valid for any type of bound,
and in particular can be applied to the upper bounds
on n-gram models introduced by (Kam and Kopec,
1996) in the context of optimization. When a sam-
ple is rejected, our algorithm assumes that a small
set of refined proposals is available, say q?1, ? ? ? , q
?
m,
where m is a small integer value. These refinements
are improved versions of the current proposal q in
the sense that they still upper-bound the target dis-
tribution p, but their mass is strictly smaller than the
mass of q, i.e. q?(X ) < q(X ). Thus, each such re-
finement q?, while still being optimistic relative to
the target distribution p, has higher average accep-
tance rate than the previous upper bound q. A bound
on the n-gram LM will be presented in Section 2.1.
Optimization In the case of optimization, the ob-
jective is to find the sequence maximizing p(x).
Viterbi on high-order HMMs is intractable but we
have access to an upper bound q, for which Viterbi
is tractable. Sampling from q is then replaced by
finding the maximum point x of q, looking at the ra-
tio r(x) = p(x)/q(x), and accepting x if this ratio is
equal to 1, otherwise refining q into q? exactly as in
the sampling case. This technique is able to find the
exact maximum of p, similarly to standard heuristic
search algorithms based on optimistic bounds. We
stop the process when q and p agree at the value
maximizing q which implies that we have found the
global maximum.
2.1 Upper bounds for n-gram models
To apply ARS on the target density given by
Equation 1 we need to define a random se-
quence of proposal distributions {q(t)}?t=1 such that
q(t)(x) ? p(x), ?x ? X , ?t ? {0, 1, ? ? ? }.
Each n-gram xi?n+1, ..., xi in the hidden layer con-
tributes an n-th order factor wn(xi|x
i?1
i?n+1) ?
plm(xi|x
i?1
i?n+1)pobs(oi|xi). The key idea is that
these n-th order factors can be upper bounded by
factors of order n? k by maximizing over the head
(i.e. prefix) of the context, as if part of the con-
text was ?forgotten?. Formally, we define the max-
backoff weights as:
wn?k(xi|x
i?1
i?n+1+k) ? max
xi?n+ki?n+1
wn(xi|x
i?1
i?n+1),
(2)
By construction, the max-backoff weights wn?k are
factors of order n? k and can be used as surrogates
to the original n-th order factors of Equation (1),
leading to a nested sequence of upper bounds until
reaching binary or unary factors:
p(x) = ??i=1wn(xi|x
i?1
i?n+1) (3)
? ??i=1wn?1(xi|x
i?1
i?n+2) (4)
? ? ?
? ??i=1w2(xi|xi?1) (5)
? ??i=1w1(xi) := q
(0)(x) . (6)
Now, one can see that the loosest bound (6) based
on unigrams corresponds to a completely factorized
distribution which is straightforward to sample and
optimize. The bigram bound (5) corresponds to a
standard HMM probability that can be efficiently de-
coded (using Viterbi algorithm) and sampled (using
backward filtering-forward sampling). 1 In the con-
text of ARS, our initial proposal q(0)(x) is set to
1Backward filtering-forward sampling (Scott, 2002) refers
to the process of running the Forward algorithm (Rabiner,
1127
the unigram bound (6). The bound is then incre-
mentally improved by adaptively refining the max-
backoff weights based on the values of the rejected
samples. Here, a refinement refers to the increase
of the order of some of the max-backoff weights in
the current proposal (thus most refinements consist
of n-grams with heterogeneous max-backoff orders,
not only those shown in equations (3)-(6)). This
operation tends to tighten the bound and therefore
increase the acceptance probability of the rejection
sampler, at the price of a higher sampling complex-
ity. The are several possible ways of choosing the
weights to refine; in Section 2.2 different refinement
strategies will be discussed, but the main technical
difficulty remains in the efficient exact optimization
and sampling of a HMM with n-grams of variable
orders. The construction of the refinement sequence
{q(t)}t?0 can be easily explained and implemented
through aWeighted Finite State Automaton (WFSA)
referred as a q-automaton, as illustrated in the fol-
lowing example.
Example We give now a high-level description of
the refinement process to give a better intuition of
our method. In Fig. 1(a), we show a WFSA rep-
resenting the initial proposal q(0) corresponding to
an example with an acoustic realization of the se-
quence of words (the, two, dogs, barked). The
weights on edges of this q-automaton correspond to
the unigram max-backoffs, so that the total weight
corresponds to Equation (6). Considering sampling,
we suppose that the first sample from q(0) produces
x1 = (the, two, dog, barked), marked
with bold edges in the drawing. Now, computing the
ratio p(x1)/q(0)(x1) gives a result much below 1,
because from the viewpoint of the full model p, the
trigram (the two dog) is very unlikely; in other
words the ratiow3(dog|the two)/w1(dog) (and,
in fact, already the ratio w2(dog|two)/w1(dog))
is very low. Thus, with high probability, x1 is re-
jected. When this is the case, we produce a re-
fined proposal q(1), represented by the WFSA in
Fig. 1(b), which takes into account the more real-
1989), which creates a lattice of forward probabilities that con-
tains the probability of ending in a latent state at a specific time
t, given the subsequence of previous observations ot1, for all the
previous latent sub-sequences xt?11 , and then recursively mov-
ing backwards, sampling a latent state based on these probabil-
ities.
Algorithm 1 ARS for HMM algorithm.
1: while not Stop(h) do
2: if Optimisation then
3: Viterbi x ? q
4: else
5: Sample x ? q
6: r ? p(x)/q(x)
7: Accept-or-Reject(x, r)
8: Update(h, x)
9: if Rejected(x) then
10: for all i ? {2, ? ? ? , ?} do
11: q ? UpdateHMM (q, x, i)
12: return q along with accepted x?s in h
Algorithm 2 UpdateHMM
Input: A triplet (q, x, i) where q is a WFSA, x is a se-
quence determining a unique path in the WFSA and
i is a position at which a refinement must be done.
1: n :=ORDERi(xi1) + 1 #implies x
i?1
i?n+2 ? Si?1
2: if xi?1i?n+1 /? Si?1 then
3: CREATE-STATE(xi?1i?n+1, i? 1)
4: #move incoming edges, keeping WFSA determin-
istic
5: for all s ? SUFi?2(xi?2i?n+1) do
6: e := EDGE(s, xi?1)
7: MOVE-EDGE-END(e,xi?1i?n+1)
8: #create outgoing edges
9: for all (s, l,?) ? Ti(xi?1i?n+2) do
10: CREATE-EDGE(xi?1i?n+1,s,l,?)
11: #update weights
12: for all s ? SUFi?1(xi?1i?n+1) do
13: weight of EDGE(s, xi) := wn(xi|x
i?1
i?n+1)
14: return
istic weight w2(dog|two) by adding a node (node
6) for the context two. We then perform a sampling
trial with q(1), which this time tends to avoid produc-
ing dog in the context of two; if the new sample
is rejected, the refinement process continues until
we start observing that the acceptance rate reaches
a fixed threshold value. The case of optimization is
similar. Suppose that with q(0) the maximum is x1,
then we observe that p(x1) is lower than q(0)(x1),
reject suboptimal x1 and refine q(0) into q(1).
2.2 Algorithm
We describe in detail the algorithm and procedure
for updating a q-automaton with a max-backoff of
longer context.
Algorithm 1 gives the pseudo-code of the sam-
1128
pling/optimization strategy. On line 1, h represents
the history of all trials so far, where the stopping cri-
terion for decoding is whether the last trial in the
history has been accepted, and for sampling whether
the ratio of accepted trials relative to all trials ex-
ceeds a certain threshold. The WFSA is initial-
ized so that all transitions only take into account
the w1(xi) max-backoffs, i.e. the initial optimistic-
bound ignores all contexts. Then depending on
whether we are sampling or decoding, in lines 2-5,
we draw an event from our automaton using either
the Viterbi algorithm or Forward-Backward sam-
pling. If the sequence is rejected at line 7, then the
q-automaton is updated in lines 10 and 11. This is
done by expanding all the factors involved in the
sampling/decoding of the rejected sequence x to a
higher order. That is, while sampling or decoding
the automaton using the current proposal q(t), the
contexts used in the path of the rejected sequence
are replaced with higher order contexts in the new
refined proposal qt+1(x).
The update process of the q-automaton repre-
sented as a WFSA is described in Algorithm 2. This
procedure guarantees that a lower, more realistic
weight is used in all paths containing the n-gram
xii?n+1 while decoding/sampling the q-automaton,
where n is the order at which xii?n+1 has been ex-
panded so far. The algorithm takes as input a max-
backoff function, and refines the WFSA such that
any paths that include this n-gram have a smaller
weight thanks to the fact that higher-order max-
backoff have automatically smaller weights.
The algorithm requires the following functions:
? ORDERi(x) returns the order at which the n-
gram has been expanded so far at position i.
? Si returns the states at a position i.
? Ti(s) returns end states, labels and weights of
all edges that originate from this state.
? SUFi(x) returns the states at iwhich have a suf-
fix matching the given context x. For empty
contexts, all states at i are returned.
? EDGE(s, l) returns the edge which originates
from s and has label l. Deterministic WFSA,
such as those used here, can only have a single
transition with a label l leaving from a state s.
? CREATE-STATE(s, i) creates a state
with name s at position i, CREATE-
EDGE(s1, s2, l,?) creates an edge (s1, s2)
between s1 and s2 with weight ? and label
l, and MOVE-EDGE-END(e, s) sets the end
of edge e to be the state s, keeping the same
starting state, weight and label.
At line 1, the expansion of the current n-gram is
increased by one so that we only need to expand con-
texts of size n ? 2. Line 2 checks whether the con-
text state exists. If it doesn?t it is created at lines 3-
10. Finally, the weight of the edges that could be in-
volved in the decoding of this n-gram are updated to
a smaller value given by a higher-order max-backoff
weight.
The creation of a new state in lines 3-10 is
straightforward: At lines 5-7, incoming edges are
moved from states at position i ? 2 with a match-
ing context to the newly created edge. At lines 9-
10 edges heading out of the context state are cre-
ated. They are simply copied over from all edges
that originate from the suffix of the context state, as
we know these will be legitimate transitions (i.e we
will always transition to a state of the same order or
lower).
Note that we can derive many other variants of
Algorithm 2 which also guarantee a smaller total
weight for the q-automaton. We chose to present this
version because it is relatively simple to implement,
and numerical experiments comparing different re-
finement approaches (including replacing the max-
backoffs with the highest-possible context, or pick-
ing a single ?culprit? to refine) showed that this ap-
proach gives a good trade-off between model com-
plexity and running time.
2.3 Computing Max-Backoff Factors
An interesting property of the max-backoff weights
is that they can be computed recursively; taking a
3-gram LM as an example, we have:
w1(xi) = max
xi?1
w2(xi|xi?1)
w2(xi|xi?1) = max
xi?2
w3(xi|x
i?1
i?2)
w3(xi|x
i?1
i?2) = p(xi|x
i?1
i?2) p(oi|xi).
The final w3(xi|x
i?1
i?2) upper bound function is sim-
ply equal to the true probability (multiplied by the
1129
conditional probability of the observation), as any
extra context is discarded by the 3-gram language
model. It?s easy to see that as we refine q(t) by
replacing existing max-backoff weights with more
specific contexts, the q(t) tends to p at t tends to in-
finity.
In the HMM formulation, we need to be able
to efficiently compute at run-time the max-backoffs
w1(the), w2(dog|the), ? ? ? , taking into account
smoothing. To do so, we present a novel method for
converting language models in the standard ARPA
format used by common toolkits such as (Stolcke,
2002) into a format that we can use. The ARPA file
format is a table T composed of three columns: (1)
an n-gram which has been observed in the training
corpus, (2) the log of the conditional probability of
the last word in the n-gram given the previous words
(log f(.)), and (3) a backoff weight (bow(.)) used
when unseen n?grams ?backoff? to this n-gram. 2
The probability of any n-gram xii?n (in the pre-
vious sense, i.e. writing p(xii?n) for p(xi|x
i?1
i?n)) is
then computed recursively as:
p(xii?n) =
?
f(xii?n) if x
i
i?n ? T
bow(xi?1i?n) p(x
i
i?n+1) otherwise.
(7)
Here, it is understood that if xi?1i?n is in T , then its
bow(.) is read from the table, otherwise it is taken to
be 1.
Different smoothing techniques will lead to dif-
ferent calculations of f(xii?n) and bow(x
i?1
i?n), how-
ever both backoff and linear-interpolation methods
can be formulated using the above equation.
Starting from the ARPA format, we pre-compute
a new table MAX-ARPA, which has the same lines
as ARPA, each corresponding to an n-gram xii?n ob-
served in the corpus, and the same f and bow, but
with two additional columns: (4) a max log prob-
ability (log mf(xii?n)), which is equal to the maxi-
mum log probability over all the n-grams extending
the context of xii?n, i.e. which have x
i
i?n as a suffix;
(5) a ?max backoff? weight (mbow(xii?n)), which is
a number used for computing the max log probabil-
ity of an n-gram not listed in the table. From the
MAX-ARPA table, the max probability w of any n-
2See www.speech.sri.com/projects/srilm/
manpages/ngram-format.5.html, last accessed at
1/3/2012, for further details.
gram xii?n, i.e the maximum of p(x
i
i?n?k) over all
n-grams extending the context of xii?n, can then be
computed recursively (again very quickly) as:
w(xii?n) =
?
mf(xii?n) if x
i
i?n ? T
mbow(xi?1i?n) p(x
i
i?n) otherwise.
(8)
Here, if xi?1i?n is in T , then its mbow(.) is read
from the table, otherwise it is taken to be 1. Also
note that the procedure calls p, which is computed
as described in Equation 7. 3
3 Experiments
In this section we empirically evaluate our joint, ex-
act decoder and sampler on two tasks; SMS-retrieval
(Section 3.1), and supervised POS tagging (Sec-
tion 3.2).
3.1 SMS-Retrieval
We evaluate our approach on an SMS-message re-
trieval task. A latent variable x ? {1, ? ? ? , N}?
represents a sentence represented as a sequence of
words: N is the number of possible words in the
vocabulary and ? is the number of words in the
sentence. Each word is converted into a sequence
of numbers based on a mobile phone numeric key-
pad. The standard character-to-numeric function
num : {a,b, ? ? ? ,z, ., ? ? ? , ?}?{1, 2, ? ? ? , 9, 0} is
used. For example, the words dog and fog
are represented by the sequence (3, 6, 4) because
num(d)=num(f)=3, num(o)=6 and num(g)=4.
Hence, observed sequences are sequences of nu-
meric strings separated by white spaces. To take
into account typing errors, we assume we observe
a noisy version of the correct numeric sequence
(num(xi1), ? ? ? , num(xi|xi|) that encodes the word
xi at the i-th position of the sentence x. The noise
model is:
p(oi|xi) ?
|xi|?
t=1
1
k ? d(oit, num(xit)) + 1
, (9)
where d(a, b) is the physical distance between the
numeric keys a and b and k is a user provided con-
3In this discussion of theMAX-ARPA table we have ignored
the contribution of the observation p(oi|xi), which is a constant
factor over the different max-backoffs for the same xi and does
not impact the computation of the table.
1130
 0 10 20 30 40
 50 60 70 80 90
 100
 1  2  3  4  5  6  7  8  9  10avg
 
#
i
t
e
r
a
t
i
o
n
s
input length3 4 5  0 50
 100 150 200 250 300
 350 400 450 500
 1  2  3  4  5  6  7  8  9 10av
g
 
#
s
t
a
t
e
s
input length
3 4 5
Figure 2: On the left we report the average #
of iterations taken to decode given different LMs
over input sentences of different lengths, and on the
right we show the average # of states in the final q-
automaton once decoding is completed.
stant that controls the ambiguity in the distribution;
we use 64 to obtain moderately noisy sequences.
We used the English side of the Europarl cor-
pus (Koehn, 2005). The language model was trained
using SRILM (Stolcke, 2002) on 90% of the sen-
tences. On the remaining 10%, we randomly se-
lected 100 sequences for lengths 1 to 10 to obtain
1000 sequences from which we removed the ones
containing numbers, obtaining a test set of size 926.
Decoding Algorithm 1 was run in the optimization
mode. In the left plot of Fig. 2, we show the number
of iterations (running Viterbi then updating q) that
the different n-gram models of size 3, 4 and 5 take
to do exact decoding of the test-set. For a fixed sen-
tence length, we can see that decoding with larger
n-gram models leads to a sub-linear increase w.r.t.
n in the number of iterations taken. In the right plot
of Fig. 2, we show the average number of states in
our variable-order HMMs.
To demonstrate the reduced nature of our q-
automaton, we show in Tab. 1 the distribution of
n-grams in our final model for a specific input sen-
tence of length 10. The number of n-grams in the
full model is?3.0?1015. Exact decoding here is not
tractable using existing techniques. Our HMM has
only 9008 n-grams in total, including 118 5-grams.
n: 1 2 3 4 5
q: 7868 615 231 176 118
Table 1: # of n-grams in our variable-order HMM.
Finally, we show in Tab. 2 an example run of
our algorithm in the optimization setting for a given
input. Note that the weight according to our q-
automaton for the first path returned by the Viterbi
algorithm is high in comparison to the true log prob-
ability according to p.
Sampling For the sampling experiments, we limit
the number of latent tokens to 100. We refine our q-
automaton until we reach a certain fixed cumulative
acceptance rate (AR). We also compute a rate based
only on the last 100 trials (AR-100), as this tends to
better reflect the current acceptance rate.
In Fig. 3a, we plot a running average of the ratio
at each iteration over the last 10 trials, for a single
sampling run using a 5-gram model for an example
input. The ratios start off at 10?20, but gradually in-
crease as we refine our HMM. After ? 500 trials,
we start accepting samples from p. In Fig. 3b, we
show the respective ARs (bottom and top curves re-
spectively), and the cumulative # of accepts (middle
curve), for the same input. Because the cumulative
accept ratio takes into account all trials, the final AR
of 17.7% is an underestimate of the true accept ra-
tio at the final iteration; this final accept ratio can be
better estimated on the basis of the last 100 trials, for
which we read AR-100 to be at around 60%.
We note that there is a trade-off between the time
needed to construct the forward probability lattice
needed for sampling, and the time it takes to adapt
the variable-order HMM. To resolve this, we pro-
pose to use batch-updates: making B trials from the
same q-automaton, and then updating our model in
one step. By doing this, we noted significant speed-
ups in sampling times. In Tab. 3, we show various
input: 3637 843 66639 39478 *
oracle: does the money exist ?
best: does the money exist .
Viterbi paths log q(x) log p(x)
q1 does the money exist ) -0.11 -17.42
q50 does the owned exist . -11.71 -23.54
q100 ends the money exist . -12.76 -17.09
q150 does vis money exist . -13.45 -23.74
q170 does the money exist . -13.70 -13.70
Table 2: Viterbi paths given different qt. Here, for
the given input, it took 170 iterations to find the best
sequence according to p, so we only show every 50th
path.
1131
 1e-20 1e-18 1e-16 1e-14 1e-12
 1e-10 1e-08 1e-06 0.0001 0.01
 1
 0  500 1000 1500 2000
r
a
t
i
o
iterations
(a)
 0 10 20
 30 40 50
 60
 0  500  1000 1500 2000  0 100
 200 300 400
 500 600
a
c
c
e
p
t
 
r
a
t
i
o
 
%
#
 
a
c
c
e
p
t
s
iterations
#ACCARAR 100
(b)
 100 200 300
 400 500 600
 700 800
 1  2  3  4  5  6  7  8  9  10avg
 
#
i
t
e
r
a
t
i
o
n
s
input length
543
(c)
 0 200 400 600
 800 1000 1200 1400
 1600 1800
 1  2  3  4  5  6  7  8  9 10av
g
 
#
s
t
a
t
e
s
input length
543
(d)
Figure 3: In 3a, we plot the running average over the last 10 trials of the ratio. In 3b, we plot the cumulative
# of accepts (middle curve), the accept rate (bottom curve), and the accept rate based on the last 100
samples (top curve). In 3c, we plot the average number of iterations needed to sample up to an AR of 20%
for sentences of different lengths in our test set, and in 3d, we show the average number of states in our
HMMs for the same experiment.
B: 1 10 20 30 40 50 100
time: 97.5 19.9 15.0 13.9 12.8 12.5 11.4
iter: 453 456 480 516 536 568 700
Table 3: In this table we show the average amount of
time in seconds and the average number of iterations
(iter) taken to sample sentences of length 10 given
different values of B.
statistics for sampling up to AR-100 = 20 given dif-
ferent values for B. We ran this experiment using
the set of sentences of length 10. A value of 1 means
that we refine our automaton after each rejected trial,
a value of 10 means we wait until rejecting 10 trials
before updating our automaton in one step. We can
see that while higher values of B lead to more iter-
ations, as we do not need to re-compute the forward
trellis needed for sampling, the time needed to reach
the specific AR threshold actually decreases, from
97.5 seconds to 11.4 seconds, an 8.5% speedup. Un-
less explicitly stated otherwise, further experiments
use a B = 100.
We now present the full sampling results on our
test-set in Fig. 3c and 3d, where we show the aver-
age number of iterations and states in the final mod-
els once refinements are finished (AR-100=20%) for
different orders n over different lengths. We note
a sub-linear increase in the average number of tri-
als and states when moving to higher n; thus, for
length=10, and for n = 3, 4, 5, # trials: 3-658.16,
4-683.3, 5-700.9, and # states: 3-1139.5, 4-1494.0,
5-1718.3.
Finally, we show in Tab. 4, the ranked samples
drawn from an input sentence, according to a 5-gram
LM. After refining our model up to AR-100 = 20%,
input: 3637 843 66639 39478 *
oracle: does the money exist ?
best: does the money exist .
samples # log q(x) log p(x)
does the money exist . 429 -13.70 -13.70
does the money exist ? 211 -14.51 -14.51
does the money exist ! 72 -15.49 -15.49
does the moody exist . 45 -15.70 -15.70
does the money exist : 25 -16.73 -16.73
Table 4: Top-5 ranked samples for an example in-
put. We highlight in bold the words which are differ-
ent to the Viterbi best of the model. The oracle and
best are not the same for this input.
we continued drawing samples until we had 1000
exact samples from p (out of ? 4.7k trials). We
show the count of each sequence in the 1000 sam-
ples, and the log probability according to p for that
event. We only present the top-five samples, though
in total there were 90 unique sequences sampled, 50
of which were only sampled once.
3.2 POS-tagging
Our HMM is the same as that used in (Brants, 2001);
the emission probability of a word given a POS
tag xi is calculated using maximum likelihood tech-
niques. That is, p(oi|xi) =
c(oi,xi)
c(xi)
. Unseen words
are handled by interpolating longer suffixes with
shorter, more general suffixes. To train our language
model, we use the SRILM toolkit (Stolcke, 2002)
We build LMs of up to size 9. We present results
on the WSJ Penn Treebank corpus (Marcus et al
1993). We use sections 0-18 to train our emission
and transitions probabilities, and report results on
1132
 95.6 95.65 95.7
 95.75 95.8 95.85
 95.9 95.95
 3  4  5  6  7  8  9ac
c
u
r
a
c
y
 
%
n-gram order
(a)
 0 2000 4000 6000
 8000 10000 12000 14000
 16000 18000
 3  4  5  6  7  8  9
t
i
m
e
n-gram order
ARSF
(b)
 50 60 70 80
 90 100 110 120
 130
 3  4  5  6  7  8  9avg
 
#
i
t
e
r
a
t
i
o
n
s
n-gram order
(c)
 100 200 300 400
 500 600 700 800
 900
 3  4  5  6  7  8  9av
g
 
#
s
t
a
t
e
s
n-gram order
(d)
Figure 4: In 4a, we report the accuracy results given different n-gram models on the WSJ test-set. In 4b, we
show the time taken (seconds) to decode the WSJ test-set given our method (ARS), and compare this to the
full model (F). In 4c, the average number of iterations needed to sample the test-set given different n-gram
language models is given, and 4d shows the average number of states in the variable-order HMMs.
sections 22-24.
We first present results for our decoding experi-
ments. In Fig. 4a we show the accuracy results of
our different models on the WSJ test-set. We see
that the best result is achieved with the 5-gram LM
giving an accuracy of 95.94%. After that, results
start to drop, most likely due to over-fitting of the
LM during training and an inability for the smooth-
ing technique to correctly handle this.
In Fig. 4b, we compare the time it takes in seconds
to decode the test-set with the full model at each n-
gram size; that is a WFSA with all context states
and weights representing the true language model
log probabilities. We can see that while increas-
ing the n-gram model size, our method (ARS) ex-
hibits a linear increase in decoding time, in contrast
to the exponential factor exhibited when running the
Viterbi algorithm over the full WFSA (F). Note for
n-gram models of order 7 and higher, we could not
decode the entire test set as creating the full WFSA
was taking too long.
Finally in both Figs 4c and 4d, we show the aver-
age number of iterations taken to sample from the
entire test-test, and the average number of states
in our variable-order HMMs, with AR-100=60%.
Again we note a linear increase in both Fig., in con-
trast to the exponential nature of standard techniques
applied to the full HMM.
4 Conclusion and Perspectives
We have presented a dual-purpose algorithm that can
be used for performing exact decoding and sampling
on high-order HMMs. We demonstrated the valid-
ity of our method on SMS-retrieval and POS exam-
ples, showing that the ?proposals? that we obtain re-
quire only a fraction of the space that would result
from explicitly representing the HMM. We believe
that this ability to support exact inference (both ap-
proximation and sampling) at a reasonable cost has
important applications, in particular when moving
from inference to learning tasks, which we see as a
natural extension of this work.
By proposing a common framework for sampling
and optimization our approach has the advantage
that we do not need separate skills or expertise to
solve the two problems. In several situations, we
might be interested not only in the most probable se-
quence, but also in the distribution of the sequences,
especially when diversity is important or in the pres-
ence of underlying ambiguities.
The interplay between optimization and sampling
is a fruitful area of research that can lead to state-
of-the art performances on inference and decod-
ing tasks in the special case of high-order HMM
decoding, but the method is generic enough to
be generalized to many others models of interest
for NLP applications. One family of models is
provided by agreement-based models, for example
HMM+PCFG, where distribution p takes the form
of a product: p(x) = pHMM(x)pPCFG(x). Even
if the factors pHMM(x) and pPCFG(x) can be de-
coded and sampled efficiently, the product of them
is intractable. Dual decomposition is a generic
method that has been proposed for handling decod-
ing (i.e. optimization) with such models, by decou-
pling the problem into two alternating steps that can
each be handled by dynamic programming or other
polynomial-time algorithms (Rush et al 2010), an
approach that has been applied to Statistical Ma-
chine Translation (phrase-based (Chang and Collins,
1133
2011) and hierarchical (Rush and Collins, 2011))
among others. However, sampling such distributions
remains a difficult problem. We are currently ex-
tending the approach described in this paper to han-
dle such applications. Again, using ARS on a se-
quence of upper bounds to the target distribution,
our idea is to express one of the two models as a con-
text free grammar and incrementally compute the
intersection with the second model, maintaining a
good trade-off between computational tractability of
the refinement and a reasonable acceptance rate.
References
Thorsten Brants. 2001. Tnt - a statistical part-of-speech
tagger. In Proceedings of the Sixth conference of
Applied Natural Language Processing (ANLP 2001),
pages 224?231.
Yin-Wen Chang and Michael Collins. 2011. Exact de-
coding of phrase-based translation models through la-
grangian relaxation. In Proceedings of the Conference
on Empirical Methods for Natural Language Process-
ing (EMNLP 2011).
Jenny Rose Finkel, Christopher D. Manning, and An-
drew Y. Ng. 2006. Solving the problem of cascading
errors: approximate bayesian inference for linguistic
annotation pipelines. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2006), pages 618?626.
W. R. Gilks and P. Wild. 1992. Adaptive rejec-
tion sampling for gibbs sampling. Applied Statistics,
42(2):337?348.
Dilan Gorur and Yee Whye Teh. 2008. Concave convex
adaptive rejection sampling. Technical report, Gatsby
Computational Neuroscience Unit.
Anthony C. Kam and Gary E. Kopec. 1996. Document
image decoding by heuristic search. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence,
18:945?950.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of Ma-
chine Translation Summit (MT-Summit 2005), pages
79?86.
Shankar Kumar and William Byrne. 2004. Minimum
bayes risk decoding for statistical machine translation.
In Joint Conference of Human Language Technologies
and the North American chapter of the Association for
Computational Linguistics (HLT-NAACL 2004).
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of english: the penn treebank. Computional Lin-
guistics, 19:313?330.
Lawrence R. Rabiner. 1989. A tutorial on hidden markov
models and selected applications in speech recogni-
tion. Proceedings of the IEEE, 77(2):257?286, Febru-
ary.
Alexander M. Rush and Michael Collins. 2011. Exact
decoding of syntactic translation models through la-
grangian relaxation. In Proceedings of the Conference
on Empirical Methods for Natural Language Process-
ing (EMNLP 2011), pages 26?37.
Alexander M. Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Proceedings of the Conference on
Empirical Methods for Natural Language Processing
(EMNLP 2010).
Steven L. Scott. 2002. Bayesian methods for hidden
markov models: Recursive computing in the 21st cen-
tury. Journal of the American Statistical Association,
97:337?351.
Andreas Stolcke. 2002. Srilm - an extensible language
modeling toolkit. In Proceedings of the International
Conference of Spoken Language Processing (INTER-
SPEECH 2002), pages 257?286.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and
David M. Blei. 2006. Hierarchical dirichlet pro-
cesses. Journal of the American Statistical Associa-
tion, 101(476):1566?1581.
Yee Whye Teh. 2006. A hierarchical bayesian language
model based on pitman-yor processes. In Proceedings
of the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the As-
sociation for Computational Linguistics (ACL 2006),
pages 985?992.
Jurgen Van Gael, Yunus Saatci, Yee Whye Teh, and
Zoubin Ghahramani. 2008. Beam sampling for the in-
finite hidden Markov model. In Proceedings of the In-
ternational Conference on Machine Learning (ICML
2008), volume 25.
1134
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1237?1249,
October 25-29, 2014, Doha, Qatar.
c
?2014 Association for Computational Linguistics
Exact Decoding for Phrase-Based Statistical Machine Translation
Wilker Aziz
?
Marc Dymetman
?
Lucia Specia
?
?
Department of Computer Science, University of Sheffield, UK
W.Aziz@sheffield.ac.uk
L.Specia@sheffield.ac.uk
?
Xerox Research Centre Europe, Grenoble, France
Marc.Dymetman@xrce.xerox.com
Abstract
The combinatorial space of translation
derivations in phrase-based statistical ma-
chine translation is given by the intersec-
tion between a translation lattice and a tar-
get language model. We replace this in-
tractable intersection by a tractable relax-
ation which incorporates a low-order up-
perbound on the language model. Exact
optimisation is achieved through a coarse-
to-fine strategy with connections to adap-
tive rejection sampling. We perform ex-
act optimisation with unpruned language
models of order 3 to 5 and show search-
error curves for beam search and cube
pruning on standard test sets. This is the
first work to tractably tackle exact opti-
misation with language models of orders
higher than 3.
1 Introduction
In Statistical Machine Translation (SMT), the task
of producing a translation for an input string x =
?x
1
, x
2
, . . . , x
I
? is typically associated with find-
ing the best derivation d
?
compatible with the in-
put under a linear model. In this view, a derivation
is a structured output that represents a sequence of
steps that covers the input producing a translation.
Equation 1 illustrates this decoding process.
d
?
= argmax
d?D(x)
f(d) (1)
The set D(x) is the space of all derivations com-
patible with x and supported by a model of trans-
lational equivalences (Lopez, 2008). The func-
tion f(d) = ? ? H(d) is a linear parameteri-
sation of the model (Och, 2003). It assigns a
real-valued score (or weight) to every derivation
d ? D(x), where ? ? R
m
assigns a relative
importance to different aspects of the derivation
independently captured by m feature functions
H(d) = ?H
1
(d), . . . ,H
m
(d)? ? R
m
.
The fully parameterised model can be seen as
a discrete weighted set such that feature func-
tions factorise over the steps in a derivation. That
is, H
k
(d) =
?
e?d
h
k
(e), where h
k
is a (local)
feature function that assesses steps independently
and d = ?e
1
, e
2
, . . . , e
l
? is a sequence of l steps.
Under this assumption, each step is assigned the
weightw(e) = ? ??h
1
(e), h
2
(e), . . . , h
m
(e)?. The
setD is typically finite, however, it contains a very
large number of structures ? exponential (or even
factorial, see ?2) with the size of x ? making
exhaustive enumeration prohibitively slow. Only
in very restricted cases combinatorial optimisation
techniques are directly applicable (Tillmann et al.,
1997; Och et al., 2001), thus it is common to resort
to heuristic techniques in order to find an approxi-
mation to d
?
(Koehn et al., 2003; Chiang, 2007).
Evaluation exercises indicate that approximate
search algorithms work well in practice (Bojar
et al., 2013). The most popular algorithms pro-
vide solutions with unbounded error, thus pre-
cisely quantifying their performance requires the
development of a tractable exact decoder. To
date, most attempts were limited to short sentences
and/or somewhat toy models trained with artifi-
cially small datasets (Germann et al., 2001; Igle-
sias et al., 2009; Aziz et al., 2013). Other work
has employed less common approximations to the
model reducing its search space complexity (Ku-
mar et al., 2006; Chang and Collins, 2011; Rush
and Collins, 2011). These do not answer whether
or not current decoding algorithms perform well at
real translation tasks with state-of-the-art models.
We propose an exact decoder for phrase-based
SMT based on a coarse-to-fine search strategy
(Dymetman et al., 2012). In a nutshell, we re-
lax the decoding problem with respect to the Lan-
guage Model (LM) component. This coarse view
is incrementally refined based on evidence col-
1237
lected via maximisation. A refinement increases
the complexity of the model only slightly, hence
dynamic programming remains feasible through-
out the search until convergence. We test our de-
coding strategy with realistic models using stan-
dard data sets. We also contribute with optimum
derivations which can be used to assess future im-
provements to approximate decoders. In the re-
maining sections we present the general model
(?2), survey contributions to exact optimisation
(?3), formalise our novel approach (?4), present
experiments (?5) and conclude (?6).
2 Phrase-based SMT
In phrase-based SMT (Koehn et al., 2003), the
building blocks of translation are pairs of phrases
(or biphrases). A translation derivation d is an
ordered sequence of non-overlapping biphrases
which covers the input text in arbitrary order gen-
erating the output from left to right.
1
f(d) = ?(y) +
l
?
i=1
?(e
i
) +
l?1
?
i=1
?(e
i
, e
i?1
) (2)
Equation 2 illustrates a standard phrase-based
model (Koehn et al., 2003): ? is a weighted tar-
get n-gram LM component, where y is the yield
of d; ? is a linear combination of features that
decompose over phrase pairs directly (e.g. back-
ward and forward translation probabilities, lexi-
cal smoothing, and word and phrase penalties);
and ? is an unlexicalised penalty on the num-
ber of skipped input words between two adjacent
biphrases. The weighted logic program in Figure
1 specifies the fully parameterised weighted set of
solutions, which we denote ?D(x), f(d)?.
2
A weighted logic program starts from its ax-
ioms and follows exhaustively deducing new items
by combination of existing ones and no deduction
happens twice. In Figure 1, a nonteminal item
summarises partial derivation (or hypotheses). It is
denoted by [C, r, ?] (also known as carry), where:
C is a coverage vector, necessary to impose the
non-overlapping constraint; r is the rightmost po-
sition most recently covered, necessary for the
computation of ?; and ? is the last n ? 1 words
1
Preventing phrases from overlapping requires an expo-
nential number of constraints (the powerset of x) rendering
the problem NP-complete (Knight, 1999).
2
Weighted logics have been extensively used to describe
weighted sets (Lopez, 2009), operations over weighted sets
(Chiang, 2007; Dyer and Resnik, 2010), and a variety of dy-
namic programming algorithms (Cohen et al., 2008).
ITEM
[
{0, 1}
I
, [0, I + 1],?
n?1
]
GOAL
[
1
I
, I + 1, EOS
]
AXIOM
?BOS? BOS?
[0
I
, 0, BOS] : ?(BOS)
EXPAND
[
C, r, y
j?1
j?n+1
] ?
x
i
?
i
?
r
??? y
j
?
j
?
[
C
?
, i
?
, y
j
?
j
?
?n+2
]
: w
?
i
?
k=i
c
k
=
?
0
where c
?
k
= c
k
if k < i or k > i
?
else
?
1
w = ?
r
? ?(r, i)? ?(y
j
?
j
|y
j?1
j?n+1
)
ACCEPT [
1
I
, r, ?
]
[1
I
, I + 1, EOS] : ?(r, I + 1)? ?(EOS|?)
r ? I
Figure 1: Specification for the weighted set of
translation derivations in phrase-based SMT with
unconstrained reordering.
in the yield, necessary for the LM component. The
program expands partial derivations by concatena-
tion with a translation rule
?
x
i
?
i
?
r
??? y
j
?
j
?
, that is, an
instantiated biphrase which covers the span x
i
?
i
and
yields y
j
?
j
with weight ?
r
. The side condition im-
poses the non-overlapping constraint (c
k
is the kth
bit in C). The antecedents are used to compute the
weight of the deduction, and the carry is updated
in the consequent (item below the horizontal line).
Finally, the rule ACCEPT incorporates the end-of-
sentence boundary to complete items.
3
It is perhaps illustrative to understand the set of
weighted translation derivations as the intersection
between two components. One that is only locally
parameterised and contains all translation deriva-
tions (a translation lattice or forest), and one that
re-ranks the first as a function of the interactions
between translation steps. The model of transla-
tional equivalences parameterised only with ? is
an instance of the former. An n-gram LM compo-
nent is an instance of the latter.
2.1 Hypergraphs
A backward-hypergraph, or simply hypergraph,
is a generalisation of a graph where edges have
multiple origins and one destination (Gallo et al.,
1993). They can represent both finite-state and
context-free weighted sets and they have been
widely used in SMT (Huang and Chiang, 2007).
A hypergraph is defined by a set of nodes (or ver-
3
Figure 1 can be seen as a specification for a weighted
acyclic finite-state automaton whose states are indexed by
[l, C, r] and transitions are labelled with biphrases. However,
for generality of representation, we opt for using acyclic hy-
pergraphs instead of automata (see ?2.1).
1238
tices) V and a weighted set of edges ?E,w?. An
edge e connects a sequence of nodes in its tail
t[e] ? V
?
under a head node h[e] ? V and has
weight w(e). A node v is a terminal node if it
has no incoming edges, otherwise it is a nontermi-
nal node. The node that has no outgoing edges,
is called root, with no loss of generality we can
assume hypergraphs to have a single root node.
Hypergraphs can be seen as instantiated logic
programs. In this view, an item is a template
for the creation of nodes, and a weighted deduc-
tion rule is a template for edges. The tail of
an edge is the sequence of nodes associated with
the antecedents, and the head is the node associ-
ated with the consequent. Even though the space
of weighted derivations in phrase-based SMT is
finite-state, using a hypergraph as opposed to a
finite-state automaton makes it natural to encode
multi-word phrases using tails. We opt for rep-
resenting the target side of the biphrase as a se-
quence of terminals nodes, each of which repre-
sents a target word.
3 Related Work
3.1 Beam filling algorithms
Beam search (Koehn et al., 2003) and cube prun-
ing (Chiang, 2007) are examples of state-of-the-art
approximate search algorithms. They approximate
the intersection between the translation forest and
the language model by expanding a limited beam
of hypotheses from each nonterminal node. Hy-
potheses are organised in priority queues accord-
ing to common traits and a fast-to-compute heuris-
tic view of outside weights (cheapest way to com-
plete a hypothesis) puts them to compete at a fairer
level. Beam search exhausts a node?s possible ex-
pansions, scores them, and discards all but the k
highest-scoring ones. This process is wasteful in
that k is typically much smaller than the number of
possible expansions. Cube pruning employs a pri-
ority queue at beam filling and computes k high-
scoring expansions directly in near best-first order.
The parameter k is known as beam size and it con-
trols the time-accuracy trade-off of the algorithm.
Heafield et al. (2013a) move away from us-
ing the language model as a black-box and build
a more involved beam filling algorithm. Even
though they target approximate search, some of
their ideas have interesting connections to ours
(see ?4). They group hypotheses that share partial
language model state (Li and Khudanpur, 2008)
reasoning over multiple hypotheses at once. They
fill a beam in best-first order by iteratively vis-
iting groups using a priority queue: if the top
group contains a single hypothesis, the hypothesis
is added to the beam, otherwise the group is parti-
tioned and the parts are pushed back to the queue.
More recently, Heafield et al. (2014) applied their
beam filling algorithm to phrase-based decoding.
3.2 Exact optimisation
Exact optimisation for monotone translation has
been done using A
?
search (Tillmann et al., 1997)
and finite-state operations (Kumar et al., 2006).
Och et al. (2001) design near-admissible heuris-
tics for A
?
and decode very short sentences (6-
14 words) for a word-based model (Brown et al.,
1993) with a maximum distortion strategy (d = 3).
Zaslavskiy et al. (2009) frame phrase-based de-
coding as an instance of a generalised Travel-
ling Salesman Problem (TSP) and rely on ro-
bust solvers to perform decoding. In this view,
a salesman graph encodes the translation options,
with each node representing a biphrase. Non-
overlapping constraints are imposed by the TSP
solver, rather than encoded directly in the sales-
man graph. They decode only short sentences
(17 words on average) using a 2-gram LM due to
salesman graphs growing too large.
4
Chang and Collins (2011) relax phrase-based
models w.r.t. the non-overlapping constraints,
which are replaced by soft penalties through La-
grangian multipliers, and intersect the LM com-
ponent exhaustively. They do employ a maximum
distortion limit (d = 4), thus the problem they
tackle is no longer NP-complete. Rush and Collins
(2011) relax a hierarchical phrase-based model
(Chiang, 2005)
5
w.r.t. the LM component. The
translation forest and the language model trade
their weights (through Lagrangian multipliers) so
as to ensure agreement on what each component
believes to be the maximum. In both approaches,
when the dual converges to a compliant solution,
the solution is guaranteed to be optimal. Other-
4
Exact decoding had been similarly addressed with Inte-
ger Linear Programming (ILP) in the context of word-based
models for very short sentences using a 2-gram LM (Ger-
mann et al., 2001). Riedel and Clarke (2009) revisit that for-
mulation and employ a cutting-plane algorithm (Dantzig et
al., 1954) reaching 30 words.
5
In hierarchical translation, reordering is governed by a
synchronous context-free grammar and the underlying prob-
lem is no longer NP-complete. Exact decoding remains in-
feasible because the intersection between the translation for-
est and the target LM is prohibitively slow.
1239
wise, a subset of the constraints is explicitly added
and the dual optimisation is repeated. They handle
sentences above average length, however, resort-
ing to compact rulesets (10 translation options per
input segment) and using only 3-gram LMs.
In the context of hierarchical models, Aziz et
al. (2013) work with unpruned forests using up-
perbounds. Their approach is the closest to ours.
They also employ a coarse-to-fine strategy with
the OS
?
framework (Dymetman et al., 2012), and
investigate unbiased sampling in addition to op-
timisation. However, they start from a coarser
upperbound with unigram probabilities, and their
refinement strategies are based on exhaustive in-
tersections with small n-gram matching automata.
These refinements make forests grow unmanage-
able too quickly. Because of that, they only deal
with very short sentences (up to 10 words) and
even then decoding is very slow. We design bet-
ter upperbounds and a more efficient refinement
strategy. Moreover, we decode long sentences us-
ing language models of order 3 to 5.
6
4 Approach
4.1 Exact optimisation with OS
?
Dymetman et al. (2012) introduced OS
?
, a unified
view of optimisation and sampling which can be
seen as a cross between adaptive rejection sam-
pling (Robert and Casella, 2004) and A
?
optimisa-
tion (Hart et al., 1968). In this framework, a com-
plex goal distribution is upperbounded by a sim-
pler proposal distribution for which optimisation
(and sampling) is feasible. This proposal is incre-
mentally refined to be closer to the goal until the
maximum is found (or until the sampling perfor-
mance exceeds a certain level).
Figure 2 illustrates exact optimisation with OS
?
.
Suppose f is a complex target goal distribution,
such that we cannot optimise f , but we can as-
sess f(d) for a given d. Let g
(0)
be an upper-
bound to f , i.e., g
(0)
(d) ? f(d) for all d ? D(x).
Moreover, suppose that g
(0)
is simple enough to
be optimised efficiently. The algorithm proceeds
by solving d
0
= argmax
d
g
(0)
(d) and comput-
6
The intuition that a full intersection is wasteful is also
present in (Petrov et al., 2008) in the context of approximate
search. They start from a coarse distribution based on au-
tomatic word clustering which is refined in multiple passes.
At each pass, hypotheses are pruned a posteriori on the basis
of their marginal probabilities, and word clusters are further
split. We work with upperbounds, rather than word clusters,
with unpruned distributions, and perform exact optimisation.
f
g
(0)
d
0
D(x)
g
(1)
d
1
d
*
f
1
f
0
f
*
Figure 2: Sequence of incrementally refined up-
perbound proposals.
ing the quantity r
0
=
f(d
0
)
/g
(0)
(d
0
). If r
0
were
sufficiently close to 1, then g
(0)
(d
0
) would be
sufficiently close to f(d
0
) and we would have
found the optimum. However, in the illustration
g
(0)
(d
0
)  f(d
0
), thus r
0
 1. At this point
the algorithm has concrete evidence to motivate
a refinement of g
(0)
that can lower its maximum,
bringing it closer to f
?
= max
d
f(d) at the cost
of some small increase in complexity. The re-
fined proposal must remain an upperbound to f .
To continue with the illustration, suppose g
(1)
is
obtained. The process is repeated until eventually
g
(t)
(d
t
) = f(d
t
), where d
t
= argmax
d
g
(t)
(d),
for some finite t. At which point d
t
is the opti-
mum derivation d
?
from f and the sequence of
upperbounds provides a proof of optimality.
7
4.2 Model
We work with phrase-based models in a standard
parameterisation (Equation 2). However, to avoid
having to deal with NP-completeness, we con-
strain reordering to happen only within a limited
window given by a notion of distortion limit. We
require that the last source word covered by any
biphrase must be within d words from the leftmost
uncovered source position (Lopez, 2009). This is
a widely used strategy and it is in use in the Moses
toolkit (Koehn et al., 2007).
8
Nevertheless, the problem of finding the best
7
If d is a maximum from g and g(d) = f(d), then it is
easy to show by contradiction that d is the actual maximum
from f : if there existed d
?
such that f(d
?
) > f(d), then it
follows that g(d
?
) ? f(d
?
) > f(d) = g(d), and hence d
would not be a maximum for g.
8
A distortion limit characterises a form of pruning that
acts directly in the generative capacity of the model leading
to induction errors (Auli et al., 2009). Limiting reordering
like that lowers complexity to a polynomial function of I and
an exponential function of the distortion limit.
1240
derivation under the model remains impractica-
ble due to nonlocal parameterisation (namely,
the n-gram LM component). The weighted set
?D(x), f(d)?, which represents the objective, is
a complex hypergraph which we cannot afford
to construct. We propose to construct instead a
simpler hypergraph for which optimisation by dy-
namic programming is feasible. This proxy rep-
resents the weighted set
?
D(x), g
(0)
(d)
?
, where
g
(0)
(d) ? f(d) for every d ? D(x). Note that
this proposal contains exactly the same translation
options as in the original decoding problem. The
simplification happens only with respect to the pa-
rameterisation. Instead of intersecting the com-
plete n-gram LM distribution explicitly, we im-
plicitly intersect a simpler upperbound view of it,
where by simpler we mean lower-order.
g
(0)
(d) =
l?
i=1
?(y[e
i
]) +
l?
i=1
?(e
i
) +
l?1?
i=1
?(e
i
, e
i?1
) (3)
Equation 3 shows the model we use as a proxy
to perform exact optimisation over f . In compar-
ison to Equation 2, the term
?
l
i=1
?(y[e
i
]) replaces
?(y) = ?
?
p
LM
(y). While ? weights the yield y
taking into account all n-grams (including those
crossing the boundaries of phrases), ? weights
edges in isolation. Particularly, ?(y[e
i
]) =
?
?
q
LM
(y[e
i
]), where y[e
i
] returns the sequence of
target words (a target phrase) associated with the
edge, and q
LM
(?) is an upperbound on the true LM
probability p
LM
(?) (see ?4.3). It is obvious from
Equation 3 that our proxy model is much simpler
than the original ? the only form of nonlocal pa-
rameterisation left is the distortion penalty, which
is simple enough to represent exactly.
The program in Figure 3 illustrates the con-
struction of
?
D(x), g
(0)
(d)
?
. A nonterminal item
[l, C, r] stores: the leftmost uncovered position l
and a truncated coverage vector C (together they
track d input positions); and the rightmost position
r most recently translated (necessary for the com-
putation of the distortion penalty). Observe how
nonterminal items do not store the LM state.
9
The
rule ADJACENT expands derivations by concate-
nation with a biphrase
?
x
i
?
i
? y
j
?
j
?
starting at the
leftmost uncovered position i = l. That causes
the coverage window to move ahead to the next
leftmost uncovered position: l
?
= l + ?
1
(C) + 1,
9
Drawing a parallel to (Heafield et al., 2013a), a nontermi-
nal node in our hypergraph groups derivations while exposing
only an empty LM state.
ITEM
[
[1, I + 1], {0, 1}
d?1
, [0, I + 1]
]
GOAL [I, ?, I + 1]
AXIOMS
?BOS? BOS?
[1, 0
d?1
, 0] : ?(BOS)
ADJACENT
[l, C, r]
?
x
i
?
i
?
r
??? y
j
?
j
?
[l
?
, C
?
, i
?
] : ?
r
? ?(r, i
?
)? ?(y
j
?
j
)
i = l
?
i
?
?l
k=i?l
c
k
=
?
0
where l
?
= l + ?
1
(C) + 1
C
?
 ?
1
(C) + 1
NON-ADJACENT
[l, C, r]
?
x
i
?
i
?
r
??? y
j
?
j
?
[l, C
?
, i
?
] : ?
r
? ?(r, i
?
)? ?(y
j
?
j
)
i > l
?
i
?
?l
k=i?l
c
k
=
?
0
|r ? i+ 1| ? d
|i
?
? l + 1| ? d
where c
?
k
= c
k
if k < i? l or k > i
?
? l else
?
1
ACCEPT
[I + 1, C, r]
[I + 1, ?, I + 1] : ?(r, I + 1)? ?(EOS)
r ? I
Figure 3: Specification of the initial proposal hy-
pergraph. This program allows the same reorder-
ings as (Lopez, 2009) (see logic WLd), however,
it does not store LM state information and it uses
the upperbound LM distribution ?(?).
where ?
1
(C) returns the number of leading 1s in
C, and C
?
 ?
1
(C) + 1 represents a left-shift.
The rule NON-ADJACENT handles the remaining
cases i > l provided that the expansion skips at
most d input words |r ? i+ 1| ? d. In the conse-
quent, the window C is simply updated to record
the translation of the input span i..i
?
. In the non-
adjacent case, a gap constraint imposes that the
resulting item will require skipping no more than
d positions before the leftmost uncovered word is
translated |i
?
? l + 1| ? d.
10
Finally, note that
deductions incorporate the weighted upperbound
?(?), rather than the true LM component ?(?).
11
4.3 LM upperbound and Max-ARPA
Following Carter et al. (2012) we compute an
upperbound on n-gram conditional probabilities
by precomputing max-backoff weights stored in
a ?Max-ARPA? table, an extension of the ARPA
format (Jurafsky and Martin, 2000).
A standard ARPA table T stores entries
10
This constraint prevents items from becoming dead-ends
where incomplete derivations require a reordering step larger
than d. This is known to prevent many search errors in beam
search (Chang and Collins, 2011).
11
Unlike Aziz et al. (2013), rather than unigrams only, we
score all n-grams within a translation rule (including incom-
plete ones).
1241
?Z,Z.p,Z.b?, where Z is an n-gram equal to the
concatenation Pz of a prefix P with a word z, Z.p
is the conditional probability p(z|P), and Z.b is
a so-called ?backoff? weight associated with Z.
The conditional probability of an arbitrary n-gram
p(z|P), whether listed or not, can then be recov-
ered from T by the simple recursive procedure
shown in Equation 4, where tail deletes the first
word of the string P.
p(z|P) =
?
?
?
p(z| tail(P)) Pz 6? T and P 6? T
p(z| tail(P))? P.b Pz 6? T and P ? T
Pz.p Pz ? T
(4)
The optimistic version (or ?max-backoff?) q of
p is defined as q(z|P) ? max
H
p(z|HP), where
H varies over all possible contexts extending the
prefix P to the left. The Max-ARPA table allows to
compute q(z|P) for arbitrary values of z and P. It
is constructed on the basis of the ARPA table T by
adding two columns to T : a column Z.q that stores
the value q(z|P) and a column Z.m that stores an
optimistic version of the backoff weight.
These columns are computed offline in two
passes by first sorting T in descending order of
n-gram length.
12
In the first pass (Algorithm 1),
we compute for every entry in the table an opti-
mistic backoff weight m. In the second pass (Algo-
rithm 2), we compute for every entry an optimistic
conditional probability q by maximising over 1-
word history extensions (whose .q fields are al-
ready known due to the sorting of T ).
The following Theorem holds (see proof be-
low): For an arbitrary n-gram Z = Pz, the prob-
ability q(z|P) can be recovered through the proce-
dure shown in Equation 5.
q(z|P) =
?
?
?
p(z|P) Pz 6? T and P 6? T
p(z|P)? P.m Pz 6? T and P ? T
Pz.q Pz ? T
(5)
Note that, if Z is listed in the table, we return its
upperbound probability q directly. When the n-
gram is unknown, but its prefix is known, we take
into account the optimistic backoff weight m of the
prefix. On the other hand, if both the n-gram and
its prefix are unknown, then no additional context
could change the score of the n-gram, in which
case q(z|P) = p(z|P).
In the sequel, we will need the following defini-
tions. Suppose ? = y
J
I
is a substring of y = y
M
1
.
12
If an n-gram is listed in T , then all its substrings must
also be listed. Certain pruning strategies may corrupt this
property, in which case we make missing substrings explicit.
Then p
LM
(?) ?
?
J
k=I
p(y
k
|y
k?1
1
) is the contribu-
tion of ? to the true LM score of y. We then ob-
tain an upperbound q
LM
(?) to this contribution by
defining q
LM
(?) ? q(y
I
|)
?
J
k=I+1
q(y
k
|y
k?1
I
).
Proof of Theorem. Let us first suppose that the length
of P is strictly larger than the order n of the language
model. Then for any H, p(z|HP) = p(z|P); this is be-
cause HP /? T and P /? T , along with all intermedi-
ary strings, hence, by (4), p(z|HP) = p(z| tail(HP)) =
p(z| tail(tail(HP))) = . . . = p(z|P). Hence q(z|P) =
p(z|P), and, because Pz /? T and P /? T , the theorem
is satisfied in this case.
Having established the theorem for |P| > n, we
now assume that it is true for |P| > m and prove by
induction that it is true for |P| = m. We use the
fact that, by the definition of q, we have q(z|P) =
max
x??
q(z|xP). We have three cases to consider.
First, suppose that Pz /? T and P /? T . Then
xPz /? T and xP /? T , hence by induction q(z|xP) =
p(z|xP) = p(z|P) for any x, therefore q(z|P) =
p(z|P). We have thus proven the first case.
Second, suppose that Pz /? T and P ? T . Then, for
any x, we have xPz /? T , and:
q(z|P) = max
x??
q(z|xP)
= max( max
x??, xP/?T
q(z|xP), max
x??, xP?T
q(z|xP)).
For xP /? T , by induction, q(z|xP) = p(z|xP) =
p(z|P), and therefore max
x??, xP/?T
q(z|xP) =
p(z|P). For xP ? T , we have q(z|xP) = p(z|xP) ?
xP.m = p(z|P)? xP.b? xP.m. Thus, we have:
max
x??, xP?T
q(z|xP) = p(z|P)? max
x??, xP?T
xP.b?xP.m.
But now, because of lines 3 and 4 of Algorithm
1, P.m = max
x??, xP?T
xP.b ? xP.m, hence
max
x??, xP?T
q(z|xP) = p(z|P) ? P.m. Therefore,
q(z|P) = max(p(z|P), p(z|P)?P.m) = p(z|P)?P.m,
where we have used the fact that P.m ? 1 due to line 1
of Algorithm 1. We have thus proven the second case.
Finally, suppose that Pz ? T . Then, again,
q(z|P) = max
x??
q(z|xP)
= max(
max
x??, xPz/?T, xP/?T
q(z|xP),
max
x??, xPz/?T, xP?T
q(z|xP),
max
x??, xPz?T
q(z|xP) ).
For xPz /? T, xP /? T , we have q(z|xP) =
p(z|xP) = p(z|P) = Pz.p, where the last equality is
due to the fact that Pz ? T . For xPz /? T, xP ? T , we
have q(z|xP) = p(z|xP)? xP.m = p(z|P)? xP.b?
xP.m = Pz.p? xP.b? xP.m. For xPz ? T , we have
q(z|xP) = xPz.q. Overall, we thus have:
q(z|P) = max( Pz.p,
max
x??, xPz/?T, xP?T
Pz.p? xP.b? xP.m,
max
x??, xPz?T
xPz.q ).
Note that xPz ? T ? xP ? T , and then one can
check that Algorithm 2 exactly computes Pz.q as this
maximum over three maxima, hence Pz.q = q(z|P).
1242
Algorithm 1 Max-ARPA: first pass
1: for Z ? T do
2: Z.m? 1
3: for x ? ? s.t xZ ? T do
4: Z.m? max(Z.m,xZ.b? xZ.m)
5: end for
6: end for
Algorithm 2 Max-ARPA: second pass
1: for Z = Pz ? T do
2: Pz.q? Pz.p
3: for x ? ? s.t xP ? T do
4: if xPz ? T then
5: Pz.q? max(Pz.q,xPz.q)
6: else
7: Pz.q? max(Pz.q,Pz.p? xP.b? xP.m)
8: end if
9: end for
10: end for
4.4 Search
The search for the true optimum derivation is il-
lustrated in Algorithm 3. The algorithm takes as
input the initial proposal distribution g
(0)
(d) (see
?4.2, Figure 3) and a maximum error  (which we
set to a small constant 0.001 rather than zero, to
avoid problems with floating point precision). In
line 3 we find the optimum derivation d in g
(0)
(see ?4.5). The variable g
?
stores the maximum
score w.r.t. the current proposal, while the vari-
able f
?
stores the maximum score observed thus
far w.r.t. the true model (note that in line 5 we as-
sess the true score of d). In line 6 we start a loop
that runs until the error falls below . This error is
the difference (in log-domain) between the proxy
maximum g
?
and the best true score observed thus
far f
?
.
13
In line 7, we refine the current proposal
using evidence from d (see ?4.6). In line 9, we
update the maximum derivation searching through
the refined proposal. In line 11, we keep track of
the best score so far according to the true model,
in order to compute the updated gap in line 6.
4.5 Dynamic Programming
Finding the best derivation in a proposal hyper-
graph is straightforward with standard dynamic
programming. We can compute inside weights
in the max-times semiring in time proportional
13
Because g
(t)
upperbounds f everywhere, in optimisation
we have a guarantee that the maximum of f must lie in the
interval [f
?
, g
?
) (see Figure 2) and the quantity g
?
? f
?
is
an upperbound on the error that we incur if we early-stop the
search at any given time t. This bound provides a principled
criterion in trading accuracy for performance (a direction that
we leave for future work). Note that most algorithms for ap-
proximate search produce solutions with unbounded error.
Algorithm 3 Exact decoding
1: function OPTIMISE(g
(0)
, )
2: t? 0 . step
3: d? argmax
d
g
(t)
(d)
4: g
?
? g
(t)
(d)
5: f
?
? f(d)
6: while (q
?
? f
?
? ) do .  is the maximum error
7: g
(t+1)
? refine(g
(t)
,d) . update proposal
8: t? t+ 1
9: d? argmax
d
g
(t)
(d) . update argmax
10: g
?
? g
(t)
(d)
11: f
?
? max(f
?
, f(d)) . update ?best so far?
12: end while
13: return g
(t)
, d
14: end function
to O(|V | + |E|) (Goodman, 1999). Once inside
weights have been computed, finding the Viterbi-
derivation starting from the root is straightforward.
A simple, though important, optimisation con-
cerns the computation of inside weights. The in-
side algorithm (Baker, 1979) requires a bottom-up
traverse of the nodes in V . To do that, we topolog-
ically sort the nodes in V at time t = 0 and main-
tain a sorted list of nodes as we refine g throughout
the search ? thus avoiding having to recompute the
partial ordering of the nodes at every iteration.
4.6 Refinement
If a derivation d = argmax
d
g
(t)
(d) is such that
g
(t)
(d) f(d), there must be in d at least one n-
gram whose upperbound LM weight is far above
its true LM weight. We then lower g
(t)
locally by
refining only nonterminal nodes that participate in
d. Nonterminal nodes are refined by having their
LM states extended one word at a time.
14
For an illustration, assume we are perform-
ing optimisation with a bigram LM. Suppose
that in the first iteration a derivation d
0
=
argmax
d
g
(0)
(d) is obtained. Now consider an
edge in d
0
[l, C, r, ] ?y
1
w
?? [l
0
, C
0
, r
0
, ]
where an empty LM state is made explicit (with an
empty string ) and ?y
1
represents a target phrase.
We refine the edge?s head [l
0
, C
0
, r
0
, ] by creating
a node based on it, however, with an extended LM
state, i.e., [l
0
, C
0
, r
0
, y
1
]. This motivates a split
of the set of incoming edges to the original node,
such that, if the target projection of an incoming
14
The refinement operation is a special case of a general
finite-state intersection. However, keeping its effect local to
derivations going through a specific node is non-trivial using
the general mechanism and justifies a tailored operation.
1243
edge ends in y
1
, that edge is reconnected to the
new node as below.
[l, C, r, ] ?y
1
w
?? [l
0
, C
0
, r
0
, y
1
]
The outgoing edges from the new node are
reweighted copies of those leaving the original
node. That is, outgoing edges such as
[l
0
, C
0
, r
0
, ] y
2
?
w
??
[
l
?
, C
?
, r
?
, ?
?
]
motivate edges such as
[l
0
, C
0
, r
0
, y
1
] y
2
?
w?w
?
????
[
l
?
, C
?
, r
?
, ?
?
]
where w
?
= ?
?
q
LM
(y
1
y
2
)
/q
LM
(y
2
) is a change in LM
probability due to an extended context.
Figure 4 is the logic program that constructs the
refined hypergraph in the general case. In com-
parison to Figure 3, items are now extended to
store an LM state. The input is the original hy-
pergraph G = ?V,E? and a node v
0
? V to be
refined by left-extending its LM state ?
0
with the
word y. In the program,
?
u?
w
?? v
?
with u,v ? V
and ? ? ?
?
represents an edge in E. An item
[l, C, r, ?]
v
(annotated with a state v ? V ) rep-
resents a node (in the refined hypergraph) whose
signature is equivalent to v (in the input hyper-
graph). We start with AXIOMS by copying the
nodes in G. In COPY, edges from G are copied
unless they are headed by v
0
and their target pro-
jections end in y?
0
(the extended context). Such
edges are processed by REFINE, which instead of
copying them, creates new ones headed by a re-
fined version of v
0
. Finally, REWEIGHT contin-
ues from the refined node with reweighted copies
of the edges leaving v
0
. The weight update repre-
sents a change in LM probability (w.r.t. the upper-
bound distribution) due to an extended context.
5 Experiments
We used the dataset made available by the Work-
shop on Statistical Machine Translation (WMT)
(Bojar et al., 2013) to train a German-English
phrase-based system using the Moses toolkit
(Koehn et al., 2007) in a standard setup. For
phrase extraction, we used both Europarl (Koehn,
2005) and News Commentaries (NC) totalling
about 2.2M sentences.
15
For language modelling,
in addition to the monolingual parts of Europarl
15
Pre-processing: tokenisation, truecasing and automatic
compound-splitting (German only). Following Durrani et al.
(2013), we set the maximum phrase length to 5.
INPUT
G = ?V,E?
v
0
= [l
0
, C
0
, r
0
, ?
0
] ? V where ?
0
? ?
?
y ? ?
ITEM [l, C, r, ? ? ?
?
]
AXIOMS
[l, C, r, ?]
v
v ? V
COPY
[l, C, r, ?]
u
?
u?
w
?? v
?
[l
?
, C
?
, r
?
, ?
?
]
v
: w
v 6= v
0
? ?? 6= ?y?
0
?, ?
?
, ?, ? ? ?
?
REFINE
[l, C,R, ?]
u
?
u?
w
?? v
0
?
[l
0
, C
0
, r
0
, y?
0
] : w
?? = ?y?
0
?, ?, ? ? ?
?
REWEIGHT
[l
0
, C
0
, r
0
, y?
0
]
?
v
0
?
w
?? v
?
[l, C, r, ?]
v
: w ? w
?
?, ? ? ?
?
where w
?
= ?
?
q
LM
(y?
0
)
q
LM
(?
0
)
Figure 4: Local intersection via LM right state re-
finement. The input is a hypergraph G = ?V,E?,
a node v
0
? V singly identified by its carry
[l
0
, C
0
, r
0
, ?
0
] and a left-extension y for its LM
context ?
0
. The program copies most of the edges?
u?
w
?? v
?
? E. If a derivation goes through v
0
and the string under v
0
ends in y?
0
, the program
refines and reweights it.
and NC, we added News-2013 totalling about 25M
sentences. We performed language model interpo-
lation and batch-mira tuning (Cherry and Foster,
2012) using newstest2010 (2,849 sentence pairs).
For tuning we used cube pruning with a large beam
size (k = 5000) and a distortion limit d = 4. Un-
pruned language models were trained using lmplz
(Heafield et al., 2013b) which employs modified
Kneser-Ney smoothing (Kneser and Ney, 1995).
We report results on newstest2012.
Our exact decoder produces optimal translation
derivations for all the 3,003 sentences in the test
set. Table 1 summarises the performance of our
novel decoder for language models of order n = 3
to n = 5. For 3-gram LMs we also varied the dis-
tortion limit d (from 4 to 6). We report the average
time (in seconds) to build the initial proposal, the
total run time of the algorithm, the number of it-
erations N before convergence, and the size of the
hypergraph in the end of the search (in thousands
of nodes and thousands of edges).
16
16
The size of the initial proposal does not depend on LM
order, but rather on distortion limit (see Figure 3): on aver-
age (in thousands) |V
0
| = 0.6 and |E
0
| = 27 with d = 4,
|V
0
| = 1.3 and |E
0
| = 70 with d = 5, and |V
0
| = 2.5 and
1244
n d build (s) total (s) N |V | |E|
3 4 1.5 21 190 2.5 159
3 5 3.5 55 303 4.4 343
3 6 10 162 484 8 725
4 4 1.5 50 350 4 288
5 4 1.5 106 555 6.1 450
Table 1: Performance of the exact decoder in
terms of: time to build g
(0)
, total decoding time in-
cluding build, number of iterations (N), and num-
ber of nodes and edges (in thousands) at the end of
the search.
It is insightful to understand how different as-
pects of the initial proposal impact on perfor-
mance. Increasing the translation option limit (tol)
leads to g
(0)
having more edges (this dependency
is linear with tol). In this case, the number of
nodes is only minimally affected ? due to the pos-
sibility of a few new segmentations. The maxi-
mum phrase length (mpl) introduces in g
(0)
more
configurations of reordering constraints ([l, C] in
Figure 3). However, not many more, due to C
being limited by the distortion limit d. In prac-
tice, we observe little impact on time performance.
Increasing d introduces many more permutations
of the input leading to exponentially many more
nodes and edges. Increasing the order n of the LM
has no impact on g
(0)
and its impact on the overall
search is expressed in terms of a higher number of
nodes being locally intersected.
An increased hypergraph, be it due to addi-
tional nodes or additional edges, necessarily leads
to slower iterations because at each iteration we
must compute inside weights in timeO(|V |+|E|).
The number of nodes has the larger impact on the
number of iterations. OS
?
is very efficient in ig-
noring hypotheses (edges) that cannot compete for
an optimum. For instance, we observe that run-
ning time depends linearly on tol only through the
computation of inside weights, while the number
of iterations is only minimally affected.
17
An in-
|E
0
| = 178 with d = 6. Observe the exponential depen-
dency on distortion limit, which also leads to exponentially
longer running times.
17
It is possible to reduce the size of the hypergraph
throughout the search using the upperbound on the search
error g
?
? f
?
to prune hypotheses that surely do not stand
a chance of competing for the optimum (Graehl, 2005). An-
other direction is to group edges connecting the same nonter-
minal nodes into one partial edge (Heafield et al., 2013a) ?
this is particularly convenient due to our method only visiting
the 1-best derivation from g(d) at each iteration.
n
Nodes at level m LM states at level m
0 1 2 3 4 1 2 3 4
3 0.4 1.2 0.5 - - 113 263 - -
4 0.4 1.6 1.4 0.3 - 132 544 212 -
5 0.4 2.1 2.4 0.7 0.1 142 790 479 103
Table 2: Average number of nodes (in thousands)
whose LM state encode an m-gram, and average
number of unique LM states of order m in the fi-
nal hypergraph for different n-gram LMs (d = 4
everywhere).
creased LM order, for a fixed distortion limit, im-
pacts much more on the number of iterations than
on the average running time of a single iteration.
Fixing d = 4, the average time per iteration is 0.1
(n = 3), 0.13 (n = 4) and 0.18 (n = 5). Fixing a
3-gram LM, we observe 0.1 (d = 4), 0.17 (d = 5)
and 0.31 (d = 6). Note the exponential growth
of the latter, due to a proposal encoding exponen-
tially many more permutations.
Table 2 shows the average degree of refine-
ment of the nodes in the final proposal. Nodes
are shown by level of refinement, where m indi-
cates that they store m words in their carry. The
table also shows the number of unique m-grams
ever incorporated to the proposal. This table il-
lustrates well how our decoding algorithm moves
from a coarse upperbound where every node stores
an empty string to a variable-order representation
which is sufficient to prove an optimum derivation.
In our approach a complete derivation is opti-
mised from the proxy model at each iteration. We
observe that over 99% of these derivations project
onto distinct strings. In addition, while the opti-
mum solution may be found early in the search, a
certificate of optimality requires refining the proxy
until convergence (see ?4.1). It turns out that most
of the solutions are first encountered as late as in
the last 6-10% of the iterations.
We use the optimum derivations obtained with
our exact decoder to measure the number of search
errors made by beam search and cube pruning with
increasing beam sizes (see Table 3). Beam search
reaches optimum derivations with beam sizes k ?
500 for all language models tested. Cube prun-
ing, on the other hand, still makes mistakes at
k = 1000. Table 4 shows translation quality
achieved with different beam sizes for cube prun-
ing and compares it to exact decoding. Note that
for k ? 10
4
cube pruning converges to optimum
1245
kBeam search Cube pruning
3 4 5 3 4 5
10 938 1294 1475 2168 2347 2377
10
2
19 60 112 613 999 1126
10
3
0 0 0 29 102 167
10
4
0 0 0 0 4 7
Table 3: Beam search and cube pruning search er-
rors (out of 3,003 test samples) by beam size using
LMs of order 3 to 5 (d = 4).
order 3 4 5
k d = 4 d = 5 d = 6 d = 4 d = 4
10 20.47 20.13 19.97 20.71 20.69
10
2
21.14 21.18 21.08 21.73 21.76
10
3
21.27 21.34 21.32 21.89 21.91
10
4
21.29 21.37 21.37 21.92 21.93
OS
?
21.29 21.37 21.37 21.92 21.93
Table 4: Translation quality in terms of BLEU as
a function of beam size in cube pruning with lan-
guage models of order 3 to 5. The bottom row
shows BLEU for our exact decoder.
derivations in the vast majority of the cases (100%
with a 3-gram LM) and translation quality in terms
of BLEU is no different from OS
?
. However, with
k < 10
4
both model scores and translation quality
can be improved. Figure 5 shows a finer view on
search errors as a function of beam size for LMs
of order 3 to 5 (fixed d = 4). In Figure 6, we fix
a 3-gram LM and vary the distortion limit (from 4
to 6). Dotted lines correspond to beam search and
dashed lines correspond to cube pruning.
6 Conclusions and Future Work
We have presented an approach to decoding with
unpruned hypergraphs using upperbounds on the
language model distribution. The algorithm is an
instance of a coarse-to-fine strategy with connec-
tions to A
?
and adaptive rejection sampling known
as OS
?
. We have tested our search algorithm us-
ing state-of-the-art phrase-based models employ-
ing robust language models. Our algorithm is able
to decode all sentences of a standard test set in
manageable time consuming very little memory.
We have performed an analysis of search errors
made by beam search and cube pruning and found
that both algorithms perform remarkably well for
phrase-based decoding. In the case of cube prun-
ing, we show that model score and translation
102 103 104[log] Beam size
100
101
102
103
104
[log
] Se
arch
 err
ors
Search errors in newstest2012
CP 3-gramCP 4-gramCP 5-gramBS 3-gramBS 4-gramBS 5-gram
Figure 5: Search errors made by beam search and
cube pruning as a function of beam-size.
102 103 104[log] Beam size
100
101
102
103
104
[log
] Se
arch
 err
ors
Search errors in newstest2012 (3-gram LM)
CP d=4CP d=5CP d=6BS d=4BS d=5BS d=6
Figure 6: Search errors made by beam search and
cube pruning as a function of the distortion limit
(decoding with a 3-gram LM).
quality can be improved for beams k < 10, 000.
There are a number of directions that we intend
to investigate to speed up our decoder, such as: (1)
error-safe pruning based on search error bounds;
(2) use of reinforcement learning to guide the de-
coder in choosing which n-gram contexts to ex-
tend; and (3) grouping edges into partial edges,
effectively reducing the size of the hypergraph and
ultimately computing inside weights in less time.
Acknowledgments
The work of Wilker Aziz and Lucia Specia was
supported by EPSRC (grant EP/K024272/1).
1246
References
Michael Auli, Adam Lopez, Hieu Hoang, and Philipp
Koehn. 2009. A systematic analysis of transla-
tion model search spaces. In Proceedings of the
Fourth Workshop on Statistical Machine Transla-
tion, StatMT ?09, pages 224?232, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Wilker Aziz, Marc Dymetman, and Sriram Venkatapa-
thy. 2013. Investigations in exact inference for hi-
erarchical translation. In Proceedings of the Eighth
Workshop on Statistical Machine Translation, pages
472?483, Sofia, Bulgaria, August. Association for
Computational Linguistics.
James K. Baker. 1979. Trainable grammars for speech
recognition. In Proceedings of the Spring Confer-
ence of the Acoustical Society of America, pages
547?550, Boston, MA, June.
Ond?rej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut, and
Lucia Specia. 2013. Findings of the 2013 Work-
shop on Statistical Machine Translation. In Pro-
ceedings of the Eighth Workshop on Statistical Ma-
chine Translation, pages 1?44, Sofia, Bulgaria, Au-
gust. Association for Computational Linguistics.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
parameter estimation. Computational Linguistics,
19(2):263?311, June.
Simon Carter, Marc Dymetman, and Guillaume
Bouchard. 2012. Exact sampling and decoding in
high-order hidden Markov models. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 1125?1134, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Yin-Wen Chang and Michael Collins. 2011. Exact de-
coding of phrase-based translation models through
Lagrangian relaxation. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP ?11, pages 26?37, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Colin Cherry and George Foster. 2012. Batch tun-
ing strategies for statistical machine translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ?12, pages 427?436, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, ACL ?05, pages 263?
270, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33:201?228.
Shay B. Cohen, Robert J. Simmons, and Noah A.
Smith. 2008. Dynamic programming algorithms as
products of weighted logic programs. In Maria Gar-
cia de la Banda and Enrico Pontelli, editors, Logic
Programming, volume 5366 of Lecture Notes in
Computer Science, pages 114?129. Springer Berlin
Heidelberg.
G Dantzig, R Fulkerson, and S Johnson. 1954. So-
lution of a large-scale traveling-salesman problem.
Operations Research, 2:393?410.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013. Edinburgh?s machine trans-
lation systems for European language pairs. In Pro-
ceedings of the Eighth Workshop on Statistical Ma-
chine Translation, pages 114?121, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Chris Dyer and Philip Resnik. 2010. Context-free
reordering, finite-state translation. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, HLT ?10, pages 858?
866, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Marc Dymetman, Guillaume Bouchard, and Simon
Carter. 2012. Optimization and sampling for NLP
from a unified viewpoint. In Proceedings of the
First International Workshop on Optimization Tech-
niques for Human Language Technology, pages 79?
94, Mumbai, India, December. The COLING 2012
Organizing Committee.
Giorgio Gallo, Giustino Longo, Stefano Pallottino, and
Sang Nguyen. 1993. Directed hypergraphs and
applications. Discrete Applied Mathematics, 42(2-
3):177?201, April.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Pro-
ceedings of the 39th Annual Meeting on Association
for Computational Linguistics, ACL ?01, pages 228?
235, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Joshua Goodman. 1999. Semiring parsing. Comput.
Linguist., 25(4):573?605, December.
Jonathan Graehl. 2005. Relatively useless pruning.
Technical report, USC Information Sciences Insti-
tute.
Peter E. Hart, Nils J. Nilsson, and Bertram Raphael.
1968. A formal basis for the heuristic determina-
tion of minimum cost paths. IEEE Transactions On
Systems Science And Cybernetics, 4(2):100?107.
Kenneth Heafield, Philipp Koehn, and Alon Lavie.
2013a. Grouping language model boundary words
1247
to speed k-best extraction from hypergraphs. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
958?968, Atlanta, Georgia, USA, June.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013b. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 690?696, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Kenneth Heafield, Michael Kayser, and Christopher D.
Manning. 2014. Faster Phrase-Based decoding by
refining feature state. In Proceedings of the Associa-
tion for Computational Linguistics, Baltimore, MD,
USA, June.
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
144?151, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Gonzalo Iglesias, Adri`a de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Rule filtering by pattern
for efficient hierarchical translation. In Proceed-
ings of the 12th Conference of the European Chapter
of the ACL (EACL 2009), pages 380?388, Athens,
Greece, March. Association for Computational Lin-
guistics.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Nat-
ural Language Processing, Computational Linguis-
tics and Speech Recognition. Series in Artificial In-
telligence. Prentice Hall, 1 edition.
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. Ac-
coustics, Speech, and Signal Processing, 1:181?184.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Comput. Linguist.,
25(4):607?615, December.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, NAACL ?03, pages 48?54, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 177?180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
of Machine Translation Summit, pages 79?86.
Shankar Kumar, Yonggang Deng, and William Byrne.
2006. A weighted finite state transducer transla-
tion template model for statistical machine transla-
tion. Natural Language Engineering, 12(1):35?75,
March.
Zhifei Li and Sanjeev Khudanpur. 2008. A scal-
able decoder for parsing-based machine translation
with equivalent language model state maintenance.
In Proceedings of the Second Workshop on Syntax
and Structure in Statistical Translation, SSST ?08,
pages 10?18, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Adam Lopez. 2008. Statistical machine translation.
ACM Computing Surveys, 40(3):8:1?8:49, August.
Adam Lopez. 2009. Translation as weighted de-
duction. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics, EACL ?09, pages 532?540,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Franz Josef Och, Nicola Ueffing, and Hermann Ney.
2001. An efficient A* search algorithm for statisti-
cal machine translation. In Proceedings of the work-
shop on Data-driven methods in machine translation
- Volume 14, DMMT ?01, pages 1?8, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics, volume 1 of ACL ?03, pages 160?
167, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Slav Petrov, Aria Haghighi, and Dan Klein. 2008.
Coarse-to-fine syntactic machine translation using
language projections. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP ?08, pages 108?116, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Sebastian Riedel and James Clarke. 2009. Revisit-
ing optimal decoding for machine translation IBM
model 4. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, Companion Volume: Short Pa-
pers, NAACL-Short ?09, pages 5?8, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
1248
Christian P. Robert and George Casella. 2004. Monte
Carlo Statistical Methods (Springer Texts in Statis-
tics). Springer-Verlag New York, Inc., Secaucus,
NJ, USA.
Alexander M. Rush and Michael Collins. 2011. Ex-
act decoding of syntactic translation models through
Lagrangian relaxation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies
- Volume 1, HLT ?11, pages 72?82, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Christoph Tillmann, Stephan Vogel, Hermann Ney,
and A. Zubiaga. 1997. A DP based search using
monotone alignments in statistical translation. In
Proceedings of the eighth conference on European
chapter of the Association for Computational Lin-
guistics, EACL ?97, pages 289?296, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Mikhail Zaslavskiy, Marc Dymetman, and Nicola Can-
cedda. 2009. Phrase-based statistical machine
translation as a traveling salesman problem. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP: Volume 1 - Volume 1, ACL ?09, pages 333?
341, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
1249
Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 49?52,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
A Lightweight Terminology Verification Service for External Machine
Translation Engines
Alessio Bosca
?
, Vassilina Nikoulina
?
, Marc Dymetman
?
?
CELI, Turin, Italy
?
Xerox Research Centre Europe, Grenoble, France
?
alessio.bosca@celi.it,
?
{first.last}@xrce.xerox.com
Abstract
We propose a demonstration of a domain-
specific terminology checking service
which works on top of any generic black-
box MT, and only requires access to a
bilingual terminology resource in the do-
main. In cases where an incorrect trans-
lation of a source term was proposed by
the generic MT service, our service locates
the wrong translation of the term in the tar-
get and suggests a terminologically correct
translation for this term.
1 Introduction
Today there exist generic MT services for a large
number of language pairs, which allow relatively
easily to make your domain-specific portal mul-
tilingual, and allow access to its documents for a
broad international public. However, applying a
generic MT service to domain-specific texts often
leads to wrong results, especially relative to the
translation of domain-specific terminology. Table
1 illustrates an example of a terminology inconsis-
tent translation provided by a generic MT system.
English Source: Farmers tend to implement a
broad non-focused weed-control strategy, on
the basis of broad spectrum products and mix-
tures of different products.
Bing
1
: Los agricultores tienden a aplicar una
estrategia amplia para control de malezas no
centrado, sobre la base de productos de am-
plio espectro y las mezclas de diferentes pro-
ductos.
Table 1: Example of the translation produced by
a generic MT model for a domain-specific docu-
ment. Source term : weed-control, official Span-
ish term translation: control de malas hierbas.
The importance of domain-specific terminology
for Machine Translation has been mentioned in
several previous works (eg. (Carl and Langlais,
2002; Skadins et al., 2013)). However, most of
these works handle the case where the terminology
is tightly integrated into the translation process.
This requires both a good expertise in SMT and
a large amount of both in-domain and generic par-
allel texts, which is often difficult, especially for
low-resourced languages like Turkish or Estonian.
Here, we are targeting the situation where the con-
tent provider is not willing to train a dedicated
translation system, for some reason such as lack of
technical skills or lack of necessary resources (par-
allel data or computational resources), but has at
his disposal a multilingual in-domain terminology
which could be helpful for improving the generic
translation provided by an external translation ser-
vice. We propose a demonstration of a multilin-
gual terminology verification/correction service,
which detects the wrongly translated terms and
suggests a better translation of these terms. This
service can be seen as an aid for machine transla-
tion post-editing focused on in-domain terminol-
ogy and as a tool for supporting the workflow of
practicing translators.
2 Related Work
There has recently been a growing interest for ter-
minology integration into MT models. Direct in-
tegration of terminology into the SMT model has
been considered, either by extending SMT train-
ing data (Carl and Langlais, 2002), or via adding
an additional term indicator feature (Pinnis and
Skadins, 2012; Skadins et al., 2013) into the trans-
lation model. However none of the above is possi-
ble when we deal with an external black-box MT
service.
(Itagaki and Aikawa, 2008) propose a post-
processing step for an MT engine, where a
wrongly translated term is replaced with a user-
provided term translation. The authors claim that
translating the term directly often gives a different
49
translation from the one obtained when translating
the term in context: for English-Japanese the out-
of-context term translation matches exactly the in
context term translation in 62% of cases only. In
order to address this problem the authors propose
15 simple context templates that induce the same
term translation as the one obtained in the initial
sentence context. Such templates include ?This
is TERM? or ?TERM is a ...?. The main prob-
lem with this approach is that these templates are
both language-pair and MT engine/model specific.
Thus a certain human expertise is required to de-
velop such templates when moving to a new lan-
guage pair or underlying MT engine.
Our approach is close to the (Itagaki and
Aikawa, 2008) approach, but instead of devel-
oping specific templates we propose a generic
method for wrong terminology translation detec-
tion. We do not aim at producing the final trans-
lation by directly replacing the wrongly translated
term ? which can be tricky?, but rather perform
the term correction in an interactive manner, where
the user is proposed a better term translation and
may choose to use it if the suggestion is correct.
3 Terminology-checking service
We assume that the provider of the terminology-
checking service has a bilingual domain-specific
terminology D at his disposal, which he wishes
to use to improve the translation produced by a
generic MT service MT . Our method verifies
whether the terminology was translated correctly
by the MT service (terminology verification), and
if not, locates the wrong translation of the term and
suggests a better translation for it.
3.1 Terminology checking
The basic terminology verification procedure ap-
plied to the source sentence s and to its translation
MT (s) by the generic service is done through the
following steps:
1. For each term T = (T
s
, T
t
) in D check
whether its source part T
s
is present in the
source sentence s.
2. If s contains T
s
, check whether the target
part of the term T
t
is present in the transla-
tion MT (s). If yes, and the number of oc-
currences of T
s
in s is equal to that of T
t
in MT (s) : the term translation is consis-
tent with terminological base. Otherwise, we
attempt to locate the wrong term translation
and suggest a better translation to the user.
Both steps require a sub-string matching algo-
rithm which is able to deal with term detection
problems such as morphological variants or dif-
ferent term variants. We describe the approach we
take for efficient sub-string matching in more de-
tail in section 3.3.
3.2 Terminology correction
Once we have detected that there is a source term
T
s
which has been incorrectly translated we would
like to suggest a better translation for this term.
This requires not only knowing a correct transla-
tion T
t
of the source term T
s
, but also its position
in the target sentence. To do that, we need to iden-
tify what was the incorrect translation proposed by
the MT engine for the term and to locate it in the
translation MT (s).
This can be seen as a sub-problem of the word-
alignment problem, which is usually solved us-
ing bilingual dictionaries or by learning statistical
alignment models out of bilingual corpora. How-
ever, in practice, these resources are not easily
available, especially for low-resourced language
pairs. In order to be able to locate the wrong term
translation in the target sentence without resort-
ing to such resources, our approach is to rely in-
stead on the same external MT engine that was
used for translating the whole source sentence in
the first place, an approach also taken in (Itagaki
and Aikawa, 2008).
To overcome the problem mentioned by (Ita-
gaki and Aikawa, 2008) of non-matching out-of-
context terms translations we propose to com-
bine out-of context term translation (MT (T
s
)) and
context-extended term translation, as follows:
? Translate the term T
s
extended with
its left and/or right n-gram context:
s
i?n
s
i?n+1
...T
s
...s
j+n?1
s
j+n
, where
T
s
= s
i
...s
j
;
? Find a fuzzy match in MT (s) for the
translation of the context-extended term
MT (s
i?n
...T
s
...s
j+n
) using the same sub-
string matching algorithm as in the terminol-
ogy verification step.
Various combinations of out-of-context term
translation (MT (T
s
)) and n-extended term trans-
lation (MT (s
i?n
...T
s
...s
j+n
)) are possible.
50
The term location is performed in a sequential
way: if the wrong term translation was not located
after the first step (out-of-context translation), at-
tempt the following step, extending size of the
context (n) until the term is located.
3.3 Implementation
The implementation of the terminology-checking
service that we demonstrate exploits Bing Trans-
lator
2
as SMT service, refers to the Agricul-
ture domain and supports two terminology re-
sources: the multilingual ontology from the Or-
ganic.Edunet portal
3
and Agrovoc, a multilingual
theasurus from FAO
4
. The presented prototype en-
ables terminology checking for all the language
pairs involving English, French, German, Italian,
Portoguese, Spanish and Turkish.
The component for matching the textual input
(i.e. either the source or the translation from the
SMT service) with elements from domain termi-
nologies is based on the open source search engine
Lucene
5
and exploits its built-in textual search ca-
pabilities and indexing facilities. We created a
search index for each of the supported languages,
containing the textual representations of the ter-
minology elements in that language along with
their URI (unique for each terminology element).
The terms expressions are indexed in their origi-
nal form as well as in their lemmatized and POS
tagged ones; for Turkish, resources for morpho-
logical analysis were not available therefore stem-
ming has been used instead of lemmatization.
In order to find the terminological entries within
a textual input in a given language a two-steps pro-
cedure is applied:
? In a first step, the text is used as a query over
the search index (in that language) in order
to find a list of all the terminology elements
containing a textual fragment present in the
query.
? In a second step, in order to retain only the
domain terms with a complete match (no par-
tial matches) and locate them in the text, a
new search index is built in memory, con-
taining a single document, namely the orig-
inal textual input (lemmatized or stemmed
according to the resources available for that
2
http://www.bing.com/translator
3
http://organic-edunet.eu/
4
http://aims.fao.org/standards/agrovoc/about
5
https://lucene.apache.org
specific language). Then the candidate ter-
minology elements found in the first step are
used as queries over the in-memory index and
the ?highlighter? component of the search en-
gine is exploited to locate them in the text
(when found). A longest match criterion is
used when the terminology elements found
refer to overlapping spans of text.
Following this procedure a list with terminology
elements (along with their URIs and the position
within the text) is generated for both the source
text and its translation. A matching strategy based
on the URI allows to pair domain terms from the
two collections. For domain terms in the source
text without a corresponding terminology element
in the translated text, the ?wrong? translation is
located in the text according to the approach de-
scribed in 3.2. The domain term is retranslated
with the same SMT (with context extension, if
needed) in order to obtain the ?wrong? translation
and the translated string is located within the trans-
lation text with the same approach used in the sec-
ond step of the procedure used for locating termi-
nological entries (with an in-memory search index
over the full text and the fragment used as query).
The service outputs two lists: one containing
the pairs of terminology elements found both in
the source and in the translation and another one
with the terminology elements without a ?correct?
translation (according to the domain terminology
used) and for each of those an alternative transla-
tion from the domain terminology is proposed. In
our demonstration a web interface allows users to
access and test the service.
4 Proof of concept evaluation
In order to evaluate the quality of locating the
wrong term translation, we applied the terminol-
ogy verification service to an SMT model trained
with Moses (Hoang et al., 2007) on the Europarl
(Koehn, 2005) corpus. This SMT model was used
for translating a test set in the Agricultural domain
from Spanish into English. In these settings we
have access to the internal sub-phrase alignment
provided by Moses, thus we know the exact loca-
tion of the wrong term translation, which allows
us to evaluate how good our locating technique is.
The test set consists of 100 abstracts in Spanish
from a bibliographical database of scientific publi-
cations in the Agriculture domain. These abstracts
were translated into English with our translation
51
model, and we then applied terminology verifi-
cation and terminology correction procedures to
these translations.
When applying terminology verification we de-
tected in total 171 terms in Spanish, 71 of them
being correctly translated into English (consistent
with terminology), and 100 being wrongly trans-
lated (not consistent with terminology).
We then attempted to locate these wrongly
translated terms in the system translation MT (s).
Matching the out-of-context term translation
with initial translation allowed to find a match for
82 wrongly translated terms (out of 100); Match-
ing 1 left/right word extended term translation
(MT (w
i?1
T
s
w
j+1
)) allowed to find a match for
16 more terms (out of 18 left).
Using the internal word alignments provided by
Moses, we also evaluated how precisely the bor-
ders of the wrongly translated term were recovered
by our term location procedure. This precision is
measured as follows:
? The target tokens identified by our procedure
(as described in 3) are: g
T
= t
1
, . . . , t
j
;
? We then identify the reference target tokens
corresponding to the translation of the term
T
s
using the Moses word alignment : r
T
=
{r
t
1
, . . . , r
t
k
}.
We define term location precision p as p =
|t
j
?r
T
?g
T
|
|g
T
|
. The precision of term location with
out-of-context term translation is of 0.92; the pre-
cision of term location with context-extended term
translation is 0.91.
Overall, our approach allows to match 98% of
the wrongly translated terms, with an overall lo-
cation precision of 0.91. Although these numbers
may vary for other language pairs and other MT
systems, this performance is encouraging.
5 Conclusion
We propose a demonstration of a terminology ver-
ification system that can be used as an aid for post-
editing machine translations explicitly focused on
bilingual terminology consistency. This system re-
lies on an external black-box generic MT engine
extended with available domain-specific terminol-
ogy. The location of the wrong term translation is
located via re-translation of the original term with
the same MT engine. We show that we partially
overcome the situation where the out-of-context
translation of the term differs from the original
translation of this term (in the full sentence) by
extending the term context with surrounding n-
grams. The terminology verification method is
both MT engine and language independent, does
not require any access to the internals of the MT
engine used, and is easily portable.
Acknowledgments
This work has been partially supported by
the Organic.Lingua project (http://www.organic-
lingua.eu/), funded by the European Commission
under the ICT Policy Support Programme.
References
Michael Carl and Philippe Langlais. 2002. An intel-
ligent terminology database as a pre-processor for
statistical machine translation. In COLING-02: Sec-
ond International Workshop on Computational Ter-
minology, pages 1?7.
Hieu Hoang, Alexandra Birch, Chris Callison-burch,
Richard Zens, Rwth Aachen, Alexandra Constantin,
Marcello Federico, Nicola Bertoldi, Chris Dyer,
Brooke Cowan, Wade Shen, Christine Moran, and
Ondej Bojar. 2007. Moses: Open source toolkit for
statistical machine translation. In ACL 2007 Demo
and Poster Sessions, pages 177?180.
Masaki Itagaki and Takako Aikawa. 2008. Post-mt
term swapper: Supplementing a statistical machine
translation system with a user dictionary. In LREC.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In MT Summit X,
pages 79?86, Phuket Thailand.
Marcis Pinnis and Raivis Skadins. 2012. Mt adapta-
tion for under-resourced domains - what works and
what not. In Baltic HLT, volume 247, pages 176?
184.
Raivis Skadins, Marcis Pinnis, Tatiana Gornostay, and
Andrejs Vasiljevs. 2013. Application of online ter-
minology services in statistical machine translation.
In MT Summit XIV, pages 281?286.
52
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 22?30,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Prediction of Learning Curves in Machine Translation
Prasanth Kolachina? Nicola Cancedda? Marc Dymetman? Sriram Venkatapathy?
? LTRC, IIIT-Hyderabad, Hyderabad, India
? Xerox Research Centre Europe, 6 chemin de Maupertuis, 38240 Meylan, France
Abstract
Parallel data in the domain of interest is the
key resource when training a statistical ma-
chine translation (SMT) system for a specific
purpose. Since ad-hoc manual translation can
represent a significant investment in time and
money, a prior assesment of the amount of
training data required to achieve a satisfac-
tory accuracy level can be very useful. In this
work, we show how to predict what the learn-
ing curve would look like if we were to manu-
ally translate increasing amounts of data.
We consider two scenarios, 1) Monolingual
samples in the source and target languages are
available and 2) An additional small amount
of parallel corpus is also available. We pro-
pose methods for predicting learning curves in
both these scenarios.
1 Introduction
Parallel data in the domain of interest is the key re-
source when training a statistical machine transla-
tion (SMT) system for a specific business purpose.
In many cases it is possible to allocate some budget
for manually translating a limited sample of relevant
documents, be it via professional translation services
or through increasingly fashionable crowdsourcing.
However, it is often difficult to predict how much
training data will be required to achieve satisfactory
translation accuracy, preventing sound provisional
budgetting. This prediction, or more generally the
prediction of the learning curve of an SMT system
as a function of available in-domain parallel data, is
the objective of this paper.
We consider two scenarios, representative of real-
istic situations.
1. In the first scenario (S1), the SMT developer is
given only monolingual source and target sam-
ples from the relevant domain, and a small test
parallel corpus.
?This research was carried out during an internship at Xerox
Research Centre Europe.
2. In the second scenario (S2), an additional small
seed parallel corpus is given that can be used
to train small in-domain models and measure
(with some variance) the evaluation score at a
few points on the initial portion of the learning
curve.
In both cases, the task consists in predicting an eval-
uation score (BLEU, throughout this work) on the
test corpus as a function of the size of a subset of
the source sample, assuming that we could have it
manually translated and use the resulting bilingual
corpus for training.
In this paper we provide the following contribu-
tions:
1. An extensive study across six parametric func-
tion families, empirically establishing that a
certain three-parameter power-law family is
well suited for modeling learning curves for the
Moses SMT system when the evaluation score
is BLEU. Our methodology can be easily gen-
eralized to other systems and evaluation scores
(Section 3);
2. A method for inferring learning curves based
on features computed from the resources avail-
able in scenario S1, suitable for both the sce-
narios described above (S1) and (S2) (Section
4);
3. A method for extrapolating the learning curve
from a few measurements, suitable for scenario
S2 (Section 5);
4. A method for combining the two approaches
above, achieving on S2 better prediction accu-
racy than either of the two in isolation (Section
6).
In this study we limit tuning to the mixing param-
eters of the Moses log-linear model through MERT,
keeping all meta-parameters (e.g. maximum phrase
length, maximum allowed distortion, etc.) at their
default values. One can expect further tweaking to
lead to performance improvements, but this was a
22
necessary simplification in order to execute the tests
on a sufficiently large scale.
Our experiments involve 30 distinct language pair
and domain combinations and 96 different learning
curves. They show that without any parallel data
we can predict the expected translation accuracy at
75K segments within an error of 6 BLEU points (Ta-
ble 4), while using a seed training corpus of 10K
segments narrows this error to within 1.5 points (Ta-
ble 6).
2 Related Work
Learning curves are routinely used to illustrate how
the performance of experimental methods depend
on the amount of training data used. In the SMT
area, Koehn et al (2003) used learning curves to
compare performance for various meta-parameter
settings such as maximum phrase length, while
Turchi et al (2008) extensively studied the be-
haviour of learning curves under a number of test
conditions on Spanish-English. In Birch et al
(2008), the authors examined corpus features that
contribute most to the machine translation perfor-
mance. Their results showed that the most predic-
tive features were the morphological complexity of
the languages, their linguistic relatedness and their
word-order divergence; in our work, we make use of
these features, among others, for predicting transla-
tion accuracy (Section 4).
In a Machine Learning context, Perlich et al
(2003) used learning curves for predicting maximum
performance bounds of learning algorithms and to
compare them. In Gu et al (2001), the learning
curves of two classification algorithms were mod-
elled for eight different large data sets. This work
uses similar a priori knowledge for restricting the
form of learning curves as ours (see Section 3), and
also similar empirical evaluation criteria for compar-
ing curve families with one another. While both ap-
plication and performance metric in our work are
different, we arrive at a similar conclusion that a
power law family of the form y = c ? a x?? is a
good model of the learning curves.
Learning curves are also frequently used for de-
termining empirically the number of iterations for
an incremental learning procedure.
The crucial difference in our work is that in the
previous cases, learning curves are plotted a poste-
riori i.e. once the labelled data has become avail-
able and the training has been performed, whereas
in our work the learning curve itself is the object of
the prediction. Our goal is to learn to predict what
the learning curve will be a priori without having to
label the data at all (S1), or through labelling only a
very small amount of it (S2).
In this respect, the academic field of Computa-
tional Learning Theory has a similar goal, since it
strives to identify bounds to performance measures1,
typically including a dependency on the training
sample size. We take a purely empirical approach
in this work, and obtain useful estimations for a case
like SMT, where the complexity of the mapping be-
tween the input and the output prevents tight theo-
retical analysis.
3 Selecting a parametric family of curves
The first step in our approach consists in selecting
a suitable family of shapes for the learning curves
that we want to produce in the two scenarios being
considered.
We formulate the problem as follows. For a cer-
tain bilingual test dataset d, we consider a set of
observations Od = {(x1, y1), (x2, y2)...(xn, yn)},
where yi is the performance on d (measured using
BLEU (Papineni et al, 2002)) of a translation model
trained on a parallel corpus of size xi. The corpus
size xi is measured in terms of the number of seg-
ments (sentences) present in the parallel corpus.
We consider such observations to be generated by
a regression model of the form:
yi = F (xi; ?) + i 1 ? i ? n (1)
where F is a function depending on a vector param-
eter ? which depends on d, and i is Gaussian noise
of constant variance.
Based on our prior knowledge of the problem,
we limit the search for a suitable F to families that
satisfies the following conditions- monotonically in-
creasing, concave and bounded. The first condition
just says that more training data is better. The sec-
ond condition expresses a notion of ?diminishing
returns?, namely that a given amount of additional
training data is more advantageous when added to
a small rather than to a big amount of initial data.
The last condition is related to our use of BLEU ?
which is bounded by 1 ? as a performance mea-
sure; It should be noted that some growth patterns
which are sometimes proposed, such as a logarith-
mic regime of the form y ' a + b log x, are not
1More often to a loss, which is equivalent.
23
compatible with this constraint.
We consider six possible families of functions sat-
isfying these conditions, which are listed in Table 1.
Preliminary experiments indicated that curves from
Model Formula
Exp3 y = c? e?ax+b
Exp4 y = c? e?ax
?+b
ExpP3 y = c? e(x?b)
?
Pow3 y = c? ax??
Pow4 y = c? (?ax+ b)??
ILog2 y = c? (a/ log x)
Table 1: Curve families.
the ?Power? and ?Exp? family with only two param-
eters underfitted, while those with five or more pa-
rameters led to overfitting and solution instability.
We decided to only select families with three or four
parameters.
Curve fitting technique Given a set of observa-
tions {(x1, y1), (x2, y2)...(xn, yn)} and a curve fam-
ily F (x; ?) from Table 1, we compute a best fit ??
where:
?? = argmin
?
n?
i=1
[yi ? F (xi; ?)]
2, (2)
through use of the Levenberg-Marquardt
method (More?, 1978) for non-linear regression.
For selecting a learning curve family, and for all
other experiments in this paper, we trained a large
number of systems on multiple configurations of
training sets and sample sizes, and tested each on
multiple test sets; these are listed in Table 2. All
experiments use Moses (Koehn et al, 2007). 2
Domain
Source Target # Test
Language Language sets
Europarl (Koehn, 2005)
Fr, De, Es En
4
En Fr, De, Es
KFTT (Neubig, 2011) Jp, En En, Jp 2
EMEA (Tiedemann, 2009) Da, De En 4
News (Callison-Burch et al, 2011) Cz,En,Fr,De,Es Cz,En,Fr,De,Es 3
Table 2: The translation systems used for the curve fit-
ting experiments, comprising 30 language-pair and do-
main combinations for a total of 96 learning curves.
Language codes: Cz=Czech, Da=Danish, En=English,
De=German, Fr=French, Jp=Japanese, Es=Spanish
The goodness of fit for each of the families is eval-
2The settings used in training the systems are those
described in http://www.statmt.org/wmt11/
baseline.html
uated based on their ability to i) fit over the entire set
of observations, ii) extrapolate to points beyond the
observed portion of the curve and iii) generalize well
over different datasets .
We use a recursive fitting procedure where the
curve obtained from fitting the first i points is used
to predict the observations at two points: xi+1, i.e.
the point to the immediate right of the currently ob-
served xi and xn, i.e. the largest point that has been
observed.
The following error measures quantify the good-
ness of fit of the curve families:
1. Average root mean-squared error (RMSE):
1
N
?
c?S
?
t?Tc
{
1
n
n?
i=1
[yi ? F (xi; ??)]
2
}1/2
ct
where S is the set of training datasets, Tc is the
set of test datasets for training configuration c,
?? is as defined in Eq. 2, N is the total number
of combinations of training configurations and
test datasets, and i ranges on a grid of training
subset sizes.The expressions n, xi, yi, ?? are all
local to the combination ct.
2. Average root mean squared residual at next
point X = xi+1 (NPR):
1
N
?
c?S
?
t?Tc
{
1
n? k ? 1
n?1?
i=k
[yi+1 ? F (xi+1; ??
i)]2
}1/2
ct
where ??i is obtained using only observations
up to xi in Eq. 2 and where k is the number of
parameters of the family.3
3. Average root mean squared residual at the last
point X = xn (LPR):
1
N
?
c?S
?
t?Tc
{
1
n? k ? 1
n?1?
i=k
[yn ? F (xn; ??
i)]2
}1/2
ct
Curve fitting evaluation The evaluation of the
goodness of fit for the curve families is presented
in Table 3. The average values of the root mean-
squared error and the average residuals across all the
learning curves used in our experiments are shown
in this table. The values are on the same scale as the
BLEU scores. Figure 1 shows the curve fits obtained
3We start the summation from i = k, because at least k
points are required for computing ??i.
24
Figure 1: Curve fits using different curve families on a
test dataset
for all the six families on a test dataset for English-
German language pair.
Curve Family RMSE NPR LPR
Exp3 0.0063 0.0094 0.0694
Exp4 0.0030 0.0036 0.0072
ExpP3 0.0040 0.0049 0.0145
Pow3 0.0029 0.0037 0.0091
Pow4 0.0026 0.0042 0.0102
ILog2 0.0050 0.0067 0.0146
Table 3: Evaluation of the goodness of fit for the six fam-
ilies.
Loooking at the values in Table 3, we decided to
use the Pow3 family as the best overall compromise.
While it is not systematically better than Exp4 and
Pow4, it is good overall and has the advantage of
requiring only 3 parameters.
4 Inferring a learning curve from mostly
monolingual data
In this section we address scenario S1: we have
access to a source-language monolingual collec-
tion (from which portions to be manually translated
could be sampled) and a target-language in-domain
monolingual corpus, to supplement the target side of
a parallel corpus while training a language model.
The only available parallel resource is a very small
test corpus. Our objective is to predict the evolution
of the BLEU score on the given test set as a function
of the size of a random subset of the training data
that we manually translate4. The intuition behind
this is that the source-side and target-side mono-
lingual data already convey significant information
about the difficulty of the translation task.
We proceed in the following way. We first train
models to predict the BLEU score at m anchor sizes
s1, . . . , sm, based on a set of features globally char-
acterizing the configuration of interest. We restrict
our attention to linear models:
?j = wj>?, j ? {1 . . .m}
where wj is a vector of feature weights specific to
predicting at anchor size j, and ? is a vector of size-
independent configuration features, detailed below.
We then perform inference using these models to
predict the BLEU score at each anchor, for the test
case of interest. We finally estimate the parameters
of the learning curve by weighted least squares re-
gression using the anchor predictions.
Anchor sizes can be chosen rather arbitrarily, but
must satisfy the following two constraints:
1. They must be three or more in number in order
to allow fitting the tri-parameter curve.
2. They should be spread as much as possible
along the range of sample size.
For our experiments, we take m = 3, with anchors
at 10K, 75K and 500K segments.
The feature vector? consists of the following fea-
tures:
1. General properties: number and average length
of sentences in the (source) test set.
2. Average length of tokens in the (source) test set
and in the monolingual source language corpus.
3. Lexical diversity features:
(a) type-token ratios for n-grams of order 1 to
5 in the monolingual corpus of both source
and target languages
(b) perplexity of language models of order 2
to 5 derived from the monolingual source
corpus computed on the source side of the
test corpus.
4We specify that it is a random sample as opposed to a subset
deliberately chosen to maximize learning effectiveness. While
there are clear ties between our present work and active learn-
ing, we prefer to keep these two aspects distinct at this stage,
and intend to explore this connection in future work.
25
4. Features capturing divergence between lan-
guages in the pair:
(a) average ratio of source/target sentence
lengths in the test set.
(b) ratio of type-token ratios of orders 1 to 5
in the monolingual corpus of both source
and target languages.
5. Word-order divergence: The divergence in the
word-order between the source and the target
languages can be captured using the part-of-
speech (pos) tag sequences across languages.
We use cross-entropy measure to capture sim-
ilarity between the n-gram distributions of the
pos tags in the monolingual corpora of the two
languages. The order of the n-grams ranges be-
tween n = 2, 4 . . . 12 in order to account for
long distance reordering between languages.
The pos tags for the languages are mapped to
a reduced set of twelve pos tags (Petrov et al,
2012) in order to account for differences in
tagsets used across languages.
These features capture our intuition that translation
is going to be harder if the language in the domain
is highly variable and if the source and target lan-
guages diverge more in terms of morphology and
word-order.
The weights wj are estimated from data. The
training data for fitting these linear models is ob-
tained in the following way. For each configuration
(combination of language pair and domain) c and
test set t in Table 2, a gold curve is fitted using the
selected tri-parameter power-law family using a fine
grid of corpus sizes. This is available as a byproduct
of the experiments for comparing different paramet-
ric families described in Section 3. We then compute
the value of the gold curves at the m anchor sizes:
we thus have m ?gold? vectors ?1, . . . ,?m with ac-
curate estimates of BLEU at the anchor sizes5. We
construct the design matrix ? with one column for
each feature vector ?ct corresponding to each com-
bination of training configuration c and test set t.
We then estimate weights wj using Ridge regres-
sion (L2 regularization):
wj = argmin
w
||?>w ? ?j ||2 + C||w||2 (3)
5Computing these values from the gold curve rather than di-
rectly from the observations has the advantage of smoothing the
observed values and also does not assume that observations at
the anchor sizes are always directly available.
where the regularization parameter C is chosen by
cross-validation. We also run experiments using
Lasso (L1) regularization (Tibshirani, 1994) instead
of Ridge. As baseline, we take a constant mean
model predicting, for each anchor size sj , the av-
erage of all the ?jct.
We do not assume the difficulty of predicting
BLEU at all anchor points to be the same. To allow
for this, we use (non-regularized) weighted least-
squares to fit a curve from our parametric family
through the m anchor points6. Following (Croarkin
and Tobias, 2006, Section 4.4.5.2), the anchor con-
fidence is set to be the inverse of the cross-validated
mean square residuals:
?j =
(
1
N
?
c?S
?
t?Tc
(?>ctw
\c
j ? ?jct)
2
)?1
(4)
where w\cj are the feature weights obtained by the
regression above on all training configurations ex-
cept c, ?jct is the gold value at anchor j for train-
ing/test combination c, t, and N is the total number
of such combinations7. In other words, we assign to
each anchor point a confidence inverse to the cross-
validated mean squared error of the model used to
predict it.
For a new unseen configuration with feature vec-
tor ?u, we determine the parameters ?u of the corre-
sponding learning curve as:
?u = argmin
?
?
j
?j
(
F (sj ; ?)? ?>uwj
)2
(5)
5 Extrapolating a learning curve fitted on
a small parallel corpus
Given a small ?seed? parallel corpus, the translation
system can be used to train small in-domain models
and the evaluation score can be measured at a few
initial sample sizes {(x1, y1), (x2, y2)...(xp, yp)}.
The performance of the system for these initial
points provides evidence for predicting its perfor-
mance for larger sample sizes.
In order to do so, a learning curve from the fam-
ily Pow3 is first fit through these initial points. We
6When the number of anchor points is the same as the num-
ber of parameters in the parametric family, the curve can be fit
exactly through all anchor points. However the general discus-
sion is relevant in case there are more anchor points than pa-
rameters, and also in view of the combination of inference and
extrapolation in Section 6.
7Curves on different test data for the same training configu-
ration are highly correlated and are therefore left out.
26
assume that p ? 3 for this operation to be well-
defined. The best fit ?? is computed using the same
curve fitting as in Eq. 2.
At each individual anchor size sj , the accuracy of
prediction is measured using the root mean-squared
error between the prediction of extrapolated curves
and the gold values:
(
1
N
?
c?S
?
t?Tc
[F (sj ; ??ct)? ?ctj ]
2
)1/2
(6)
where ??ct are the parameters of the curve fit using
the initial points for the combination ct.
In general, we observed that the extrapolated
curve tends to over-estimate BLEU for large sam-
ples.
6 Combining inference and extrapolation
In scenario S2, the models trained from the seed par-
allel corpus and the features used for inference (Sec-
tion 4) provide complementary information. In this
section we combine the two to see if this yields more
accurate learning curves.
For the inference method of Section 4, predictions
of models at anchor points are weighted by the in-
verse of the model empirical squared error (?j). We
extend this approach to the extrapolated curves. Let
u be a new configuration with seed parallel corpus of
size xu, and let xl be the largest point in our grid for
which xl ? xu. We first train translation models and
evaluate scores on samples of size x1, . . . , xl, fit pa-
rameters ??u through the scores, and then extrapolate
BLEU at the anchors sj : F (sj ; ??u), j ? {1, . . . ,m}.
Using the models trained for the experiments in Sec-
tion 3, we estimate the squared extrapolation error at
the anchors sj when using models trained on size up
to xl, and set the confidence in the extrapolations8
for u to its inverse:
?<lj =
(
1
N
?
c?S
?
t?Tc
(F (sj ; ?
<l
ct )? ?ctj)
2
)?1
(7)
where N , S, Tc and ?ctj have the same meaning as
in Eq. 4, and ?<lct are parameters fitted for config-
uration c and test t using only scores measured at
x1, . . . , xl. We finally estimate the parameters ?u of
8In some cases these can actually be interpolations.
the combined curve as:
?u = argmin
?
?
j
?j(F (sj ; ?)? ?
>
uwj)
2
+ ?<lj (F (sj ; ?)? F (sj ; ??u))
2
where ?u is the feature vector for u, and wj are the
weights we obtained from the regression in Eq. 3.
7 Experiments
In this section, we report the results of our experi-
ments on predicting the learning curves.
7.1 Inferred Learning Curves
Regression model 10K 75K 500K
Ridge 0.063 0.060 0.053
Lasso 0.054 0.060 0.062
Baseline 0.112 0.121 0.121
Table 4: Root mean squared error of the linear regression
models for each anchor size
In the case of inference from mostly monolingual
data, the accuracy of the predictions at each of the
anchor sizes is evaluated using root mean-squared
error over the predictions obtained in a leave-one-
out manner over the set of configurations from Ta-
ble 2. Table 4 shows these results for Ridge and
Lasso regression models at the three anchor sizes.
As an example, the model estimated using Lasso for
the 75K anchor size exhibits a root mean squared
error of 6 BLEU points. The errors we obtain are
lower than the error of the baseline consisting in tak-
ing, for each anchor size sj , the average of all the
?ctj . The Lasso regression model selected four fea-
tures from the entire feature set: i) Size of the test
set (sentences & tokens) ii) Perplexity of language
model (order 5) on the test set iii) Type-token ratio
of the target monolingual corpus . Feature correla-
tion measures such as Pearsons R showed that the
features corresponding to type-token ratios of both
source and target languages and size of test set have
a high correlation with the BLEU scores at the three
anchor sizes.
Figure 2 shows an instance of the inferred learn-
ing curves obtained using a weighted least squares
method on the predictions at the anchor sizes. Ta-
ble 7 presents the cumulative error of the inferred
learning curves with respect to the gold curves, mea-
sured as the average distance between the curves in
the range x ? [0.1K, 100K].
27
Figure 2: Inferred learning curve for English-Japanese
test set. The error-bars show the anchor confidence for
the predictions.
7.2 Extrapolated Learning Curves
As explained in Section 5, we evaluate the accuracy
of predictions from the extrapolated curve using the
root mean squared error (see Eq. 6) between the pre-
dictions of this curve and the gold values at the an-
chor points.
We conducted experiments for three sets of initial
points, 1) 1K-5K-10K, 2) 5K-10K-20K, and 3) 1K-
5K-10K-20K. For each of these sets, we show the
prediction accuracy at the anchor sizes, 10K9, 75K,
and 500K in Table 5.
Initial Points 10K 75K 500K
1K-5K-10K 0.005 0.017 0.042
5K-10K-20K 0.002 0.015 0.034
1K-5K-10K-20K 0.002 0.008 0.019
Table 5: Root mean squared error of the extrapolated
curves at the three anchor sizes
The root mean squared errors obtained by extrap-
olating the learning curve are much lower than those
obtained by prediction of translation accuracy using
the monolingual corpus only (see Table 4), which
is expected given that more direct evidence is avail-
able in the former case . In Table 5, one can also
see that the root mean squared error for the sets 1K-
5K-10K and 5K-10K-20K are quite close for anchor
9The 10K point is not an extrapolation point but lies within
the range of the set of initial points. However, it does give a
measure of the closeness of the curve fit using only the initial
points with the gold fit using all the points; the value of this gold
fit at 10K is not necessarily equal to the observation at 10K.
sizes 75K and 500K. However, when a configuration
of four initial points is used for the same amount of
?seed? parallel data, it outperforms both the config-
urations with three initial points.
7.3 Combined Learning Curves and Overall
Comparison
In Section 6, we presented a method for combin-
ing the predicted learning curves from inference and
extrapolation by using a weighted least squares ap-
proach. Table 6 reports the root mean squared error
at the three anchor sizes from the combined curves.
Initial Points Model 10K 75K 500K
1K-5K-10K
Ridge 0.005 0.015 0.038
Lasso 0.005 0.014 0.038
5K-10K-20K
Ridge 0.001 0.006 0.018
Lasso 0.001 0.006 0.018
1K-5K-10K-20K
Ridge 0.001 0.005 0.014
Lasso 0.001 0.005 0.014
Table 6: Root mean squared error of the combined curves
at the three anchor sizes
We also present an overall evaluation of all the
predicted learning curves. The evaluation metric is
the average distance between the predicted curves
and the gold curves, within the range of sample sizes
xmin=0.1K to xmax=500K segments; this metric is
defined as:
1
N
?
c?S
?
t?Tc
?xmax
x=xmin |F (x; ??ct)? F (x; ??ct)|
xmax ? xmin
where ??ct is the curve of interest, ??ct is the gold
curve, and x is in the range [xmin, xmax], with a step
size of 1. Table 7 presents the final evaluation.
Initial Points IR IL EC CR CL
1K-5K-10K 0.034 0.050 0.018 0.015 0.014
5K-10K-20K 0.036 0.048 0.011 0.010 0.009
1K-5K-10K-20K 0.032 0.049 0.008 0.007 0.007
Table 7: Average distance of different predicted
learning curves relative to the gold curve. Columns:
IR=?Inference using Ridge model?, IL=?Inference
using Lasso model?, EC=?Extrapolated curve?,
CR=?Combined curve using Ridge?, CL=?Combined
curve using Lasso?
We see that the combined curves (CR and CL)
perform slightly better than the inferred curves (IR
28
and IL) and the extrapolated curves (EC). The aver-
age distance is on the same scale as the BLEU score,
which suggests that our best curves can predict the
gold curve within 1.5 BLEU points on average (the
best result being 0.7 BLEU points when the initial
points are 1K-5K-10K-20K) which is a telling re-
sult. The distances between the predicted and the
gold curves for all the learning curves in our experi-
ments are shown in Figure 3.
Figure 3: Distances between the predicted and the gold
learning curves in our experiments across the range of
sample sizes. The dotted lines indicate the distance from
gold curve for each instance, while the bold line indi-
cates the 95th quantile of the distance between the curves.
IR=?Inference using Ridge model?, EC=?Extrapolated
curve?, CR=?Combined curve using Ridge?.
We also provide a comparison of the different pre-
dicted curves with respect to the gold curve as shown
in Figure 4.
Figure 4: Predicted curves in the three scenarios for
Czech-English test set using the Lasso model
8 Conclusion
The ability to predict the amount of parallel data
required to achieve a given level of quality is very
valuable in planning business deployments of statis-
tical machine translation; yet, we are not aware of
any rigorous proposal for addressing this need.
Here, we proposed methods that can be directly
applied to predicting learning curves in realistic sce-
narios. We identified a suitable parametric fam-
ily for modeling learning curves via an extensive
empirical comparison. We described an inference
method that requires a minimal initial investment in
the form of only a small parallel test dataset. For the
cases where a slightly larger in-domain ?seed? par-
allel corpus is available, we introduced an extrapola-
tion method and a combined method yielding high-
precision predictions: using models trained on up to
20K sentence pairs we can predict performance on a
given test set with a root mean squared error in the
order of 1 BLEU point at 75K sentence pairs, and
in the order of 2-4 BLEU points at 500K. Consider-
ing that variations in the order of 1 BLEU point on
a same test dataset can be observed simply due to
the instability of the standard MERT parameter tun-
ing algorithm (Foster and Kuhn, 2009; Clark et al,
2011), we believe our results to be close to what can
be achieved in principle. Note that by using gold
curves as labels instead of actual measures we im-
plicitly average across many rounds of MERT (14
for each curve), greatly attenuating the impact of the
instability in the optimization procedure due to ran-
domness.
For enabling this work we trained a multitude
of instances of the same phrase-based SMT sys-
tem on 30 distinct combinations of language-pair
and domain, each with fourteen distinct training
sets of increasing size and tested these instances on
multiple in-domain datasets, generating 96 learning
curves. BLEU measurements for all 96 learning
curves along with the gold curves and feature values
used for inferring the learning curves are available
as additional material to this submission.
We believe that it should be possible to use in-
sights from this paper in an active learning setting,
to select, from an available monolingual source, a
subset of a given size for manual translation, in such
a way at to yield the highest performance, and we
plan to extend our work in this direction.
29
References
Alexandra Birch, Miles Osborne, and Philipp Koehn.
2008. Predicting Success in Machine Translation.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages 745?
754, Honolulu, Hawaii, October. Association for Com-
putational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar Zaidan. 2011. Findings of the 2011 Work-
shop on Statistical Machine Translation. In Proceed-
ings of the Sixth Workshop on Statistical Machine
Translation, pages 22?64, Edinburgh, Scotland, July.
Association for Computational Linguistics.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.
Smith. 2011. Better Hypothesis Testing for Statis-
tical Machine Translation: Controlling for Optimizer
Instability. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 176?181, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Carroll Croarkin and Paul Tobias. 2006.
NIST/SEMATECH e-Handbook of Statistical Meth-
ods. NIST/SEMATECH, July. Available online:
http://www.itl.nist.gov/div898/handbook/.
George Foster and Roland Kuhn. 2009. Stabilizing
Minimum Error Rate Training. In Proceedings of the
Fourth Workshop on Statistical Machine Translation,
pages 242?249, Athens, Greece, March. Association
for Computational Linguistics.
Baohua Gu, Feifang Hu, and Huan Liu. 2001. Mod-
elling Classification Performance for Large Data Sets.
In Proceedings of the Second International Conference
on Advances in Web-Age Information Management,
WAIM ?01, pages 317?328, London, UK. Springer-
Verlag.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proceedings
of Human Language Technologies: The 2003 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 48?54,
Edmonton, Canada, May. Association for Computa-
tional Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics Companion Vol-
ume Proceedings of the Demo and Poster Sessions,
pages 177?180, Prague, Czech Republic, June. Asso-
ciation for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of the
10th Machine Translation Summit, Phuket, Thailand,
September.
Jorge J. More?. 1978. The Levenberg-Marquardt Algo-
rithm: Implementation and Theory. Numerical Anal-
ysis. Proceedings Biennial Conference Dundee 1977,
630:105?116.
Graham Neubig. 2011. The Kyoto Free Translation
Task. http://www.phontron.com/kftt.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311?318, Philadelphia, Pennsylva-
nia, USA, July. Association for Computational Lin-
guistics.
Claudia Perlich, Foster J. Provost, and Jeffrey S. Si-
monoff. 2003. Tree Induction vs. Logistic Regres-
sion: A Learning-Curve Analysis. Journal of Machine
Learning Research, 4:211?255.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A Universal Part-of-Speech Tagset. In Proceedings
of the Eighth conference on International Language
Resources and Evaluation (LREC?12), Istanbul, May.
European Language Resources Association (ELRA).
Robert Tibshirani. 1994. Regression Shrinkage and Se-
lection Via the Lasso. Journal of the Royal Statistical
Society, Series B, 58:267?288.
Jo?rg Tiedemann. 2009. News from OPUS - A Collection
of Multilingual Parallel Corpora with Tools and Inter-
faces. In Recent Advances in Natural Language Pro-
cessing, volume V, pages 237?248. John Benjamins,
Amsterdam/Philadelphia, Borovets, Bulgaria.
Marco Turchi, Tijl De Bie, and Nello Cristianini. 2008.
Learning Performance of a Machine Translation Sys-
tem: a Statistical and Computational Analysis. In Pro-
ceedings of the Third Workshop on Statistical Machine
Translation, pages 35?43, Columbus, Ohio, June. As-
sociation for Computational Linguistics.
30
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 85?90,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
SORT: An Interactive Source-Rewriting Tool for Improved Translation
Shachar Mirkin, Sriram Venkatapathy, Marc Dymetman, Ioan Calapodescu
Xerox Research Centre Europe
6 Chemin de Maupertuis
38240 Meylan, France
firstname.lastname@xrce.xerox.com
Abstract
The quality of automatic translation is af-
fected by many factors. One is the diver-
gence between the specific source and tar-
get languages. Another lies in the source
text itself, as some texts are more com-
plex than others. One way to handle such
texts is to modify them prior to transla-
tion. Yet, an important factor that is of-
ten overlooked is the source translatabil-
ity with respect to the specific translation
system and the specific model that are be-
ing used. In this paper we present an in-
teractive system where source modifica-
tions are induced by confidence estimates
that are derived from the translation model
in use. Modifications are automatically
generated and proposed for the user?s ap-
proval. Such a system can reduce post-
editing effort, replacing it by cost-effective
pre-editing that can be done by monolin-
guals.
1 Introduction
While Machine Translation (MT) systems are con-
stantly improving, they are still facing many dif-
ficulties, such as out-of-vocabulary words (i.e.
words unseen at training time), lack of sufficient
in-domain data, ambiguities that the MT model
cannot resolve, and the like. An important source
of problems lies in the source text itself ? some
texts are more complex to translate than others.
Consider the following English-to-French
translation by a popular service, BING TRANS-
LATOR:1 Head of Mali defense seeks more arms
? D?fense de la t?te du Mali cherche bras plus.
There, apart from syntactic problems, both head
and arms have been translated as if they were
1http://www.bing.com/translator, accessed
on 4/4/2013.
body parts (t?te and bras). However, suppose
that we express the same English meaning in the
following way: Chief of Mali defense wants more
weapons. Then BING produces a much better
translation: Chef d??tat-major de la d?fense du
Mali veut plus d?armes.
The fact that the formulation of the source can
strongly influence the quality of the translation has
long been known, and there have been studies in-
dicating that adherence to so-called ?Controlled
Language? guidelines, such as Simplified Techni-
cal English2 can reduce the MT post-edition ef-
fort. However, as one such study (O?Brien, 2006)
notes, it is unfortunately not sufficient to just ?ap-
ply the rules [i.e. guidelines] and press Translate.
We need to analyze the effect that rules are hav-
ing on different language pairs and MT systems,
and we need to tune our rule sets and texts ac-
cordingly?.
In the software system presented here, SORT
(SOurce Rewriting Tool), we build on the basic in-
sight that formulation of the source needs to be
geared to the specific MT model being used, and
propose the following approach. First, we assume
that the original source text in English (say) is not
necessarily under the user?s control, but may be
given to her. While she is a fluent English speaker,
she does not know at all the target language, but
uses an MT system; crucially, this system is able
to provide estimates of the quality of its transla-
tions (Specia et al, 2009). SORT then automati-
cally produces a number of rewritings of each En-
glish sentence, translates them with the MT sys-
tem, and displays to the user those rewritings for
which the translation quality estimates are higher
than the estimate for the original source. The user
then interactively selects one such rewriting per
sentence, checking that it does not distort the orig-
inal meaning, and finally the translations of these
2http://www.asd-ste100.org
85
reformulations are made available.
One advantage of this framework is that the
proposed rewritings are implicitly ?aware? of the
underlying strengths and limitations of the spe-
cific MT model. A good quality estimation3
component, for instance, will feel more confident
about the translation of an unambiguous word like
weapon than about that of an ambiguous one such
as arm, or about the translation of a known term
in its domain than about a term not seen during
training.
Such a tool is especially relevant for business
situations where post-edition costs are very high,
for instance because of lack of people both ex-
pert in the domain and competent in the target lan-
guage. Post-edition must be reserved for the most
difficult cases, while pre-edition may be easier to
organize. While the setup cannot fully guarantee
the accuracy of all translations, it can reduce the
number of sentences that need to go through post-
edition and the overall cost of this task.
2 The rewriting tool
In this section we describe SORT, our implemen-
tation of the aforementioned rewriting approach.
While the entire process can in principle be fully
automated, we focus here on an interactive pro-
cess where the user views and approves suggested
rewritings. The details of the rewriting methods
and of the quality estimation used in the current
implementation are described in Sections 3 and 4.
Figure 1 presents the system?s interface, which
is accessed as a web application. With this in-
terface, the user uploads the document that needs
to be translated. The translation confidence of
each sentence is computed and displayed next to
it. The confidence scores are color-coded to en-
able quickly focusing on the sentences that require
more attention. Green denotes sentences for which
the translation confidence is high, and are thus ex-
pected to produce good translations. Red marks
sentences that are estimated to be poorly trans-
lated, and all those in between are marked with
an orange label.
We attempt to suggest rewritings only for sen-
tences that are estimated to be not so well trans-
lated. When we are able to propose rewriting(s)
with higher translation confidence than the origi-
nal, a magnifying glass icon is displayed next to the
sentence. Clicking it displays, on the right side of
3Also known as confidence estimation.
the screen, an ordered list of the more confident
rewritings, along with their corresponding confi-
dence estimations. The first sentence on the list
is always the original one, to let it be edited, and
to make it easier to view the difference between
the original and the rewritings. An example is
shown on the right side of Figure 1, where we see
a rewriting suggestion for the fourth sentence in
the document. Here, the suggestion is simply to
replace the word captured with the word caught, a
rewriting that is estimated to improve the transla-
tion of the sentence.
The user can select one of the suggestions or
choose to edit either the original or one of the
rewritings. The current sentence which is being
examined is marked with a different color and the
alternative under focus is marked with a small icon
(the bidirectional arrows). The differences between
the alternatives and the original are highlighted.
After the user?s confirmation (with the check mark
icon), the display of the document on the left-hand
side is updated based on her selection, including
the updated confidence estimation. At any time,
the user (if she speaks the target language) can
click on the cogwheel icon and view the transla-
tion of the source or of its rewritten version. When
done, the user can save the edited text or its trans-
lation. Moses Release 1.0 of an English-Spanish
Europarl-trained model4 was used in this work to
obtain English-Spanish translations.
2.1 System and software architecture
SORT is implemented as a web application, using
an MVC (Model View Controller) software archi-
tecture. The Model part is formed by Java classes
representing the application state (user input, se-
lected text lines, associated rewriting propositions
and scores). The Controller consists of several
servlet components handling each user interaction
with the backend server (file uploads, SMT tools
calls via XML-RPC or use of the embedded Java
library that handles the actual rewritings). Finally,
the View is built with standard web technologies:
HTML5, JavaScript (AJAX) and CSS style sheets.
The application was developed and deployed on
Linux (CentOS release 6.4), with a Java Runtime
6 (Java HotSpot 64-Bit Server VM), within a Tom-
cat 7.0 Application Server, and tested with Firefox
as the web client both on Linux and Windows 7.
Figure 2 shows the system architecture of SORT,
4http://www.statmt.org/moses/RELEASE-1.0/model/
86
Figure 1: SORT?s interface
Figure 2: SORT?s system architecture. For simplicity, only
partial input-output details are shown.
with some details of the current implementation.
The entire process is performed via a client-server
architecture in order to provide responsiveness, as
required in an interactive system. The user com-
municates with the system through the interface
shown in Figure 1. When a document is loaded,
its sentences are translated in parallel by an SMT
Moses server (Koehn et al, 2007). Then, the
source and the target are sent to the confidence es-
timator, and the translation model information is
also made available to it. The confidence estima-
tor extracts features from that input and returns a
confidence score. Specifically, the language model
features are computed with two SRILM servers
(Stolcke, 2002), one for the source language and
one for the target language. Rewritings are pro-
duced by the rewriting modules (see Section 3 for
the implemented rewriting methods). For each
rewriting, the same process of translation and con-
fidence estimation is performed. Translations are
cached during the session; thus, when the user
wishes to view a translation or download the trans-
lations of the entire document, the response is im-
mediate.
3 Source rewriting
Various methods can be used to rewrite a source
text. In what follows we describe two rewriting
methods, based on Text Simplification techniques,
which we implemented and integrated in the cur-
rent version of SORT. Simplification operations
include the replacement of words by simpler ones,
removal of complicated syntactic structures, short-
ening of sentences etc. (Feng, 2008). Our assump-
tion is that simpler sentences are more likely to
yield higher quality translations. Clearly, this is
not always the case; yet, we leave this decision to
the confidence estimation component.
Sentence-level simplification (Specia, 2010)
has proposed to model text simplification as a Sta-
tistical Machine Translation (SMT) task where the
goal is to translate sentences to their simplified
version in the same language. In this approach, a
simplification model is learnt from a parallel cor-
pus of texts and their simplified versions. Apply-
87
ing this method, we train an SMT model from En-
glish to Simple English, based on the PWKP par-
allel corpus generated from Wikipedia (Zhu et al,
2010);5 we use only alignments involving a single
sentence on each side. This results in a phrase ta-
ble containing many entries where source and tar-
get phrases are identical, but also phrase-pairs that
are mapping complex phrases to their simplified
counterparts, such as the following:
? due to its location on? because it was on
? primarily dry and secondarily cold ? both
cold and dry
? the high mountainous alps? the alps
Also, the language model is trained with Simple
English sentences to encourage the generation of
simpler texts. Given a source text, it is translated
to its simpler version, and its n-best translations
are assessed by the confidence estimation compo-
nent.
Lexical simplification One of the primary oper-
ations for text-simplification is lexical substitution
(Table 2 in (Specia, 2010)). Hence, in addition to
rewriting a full sentence using the previous tech-
nique, we implemented a second method, address-
ing lexical simplification directly, and only modi-
fying local aspects of the source sentence. The ap-
proach here is to extract relevant synonyms from
our trained SMT model of English to Simplified
English, and use them as substitutions to simplify
new sentences. We extract all single token map-
pings from the phrase table of the trained model,
removing punctuations, numbers and stop-words.
We check whether their lemmas were synonyms
in WordNet (Fellbaum, 1998) (with all possible
parts-of-speech as this information was not avail-
able in the SMT model). Only those are left as
valid substitution pairs. When a match of an En-
glish word is found in the source sentence it is re-
placed with its simpler synonym to generate an al-
ternative for the source. For example, using this
rewriting method for the source sentence ?Why the
Galileo research program superseded rival pro-
grams,? three rewritings of the sentence are gen-
erated when rival is substituted by competitor or
superseded by replaced, and when both substitu-
tions occur together.
5Downloaded from:
http://www.ukp.tu-darmstadt.de/data/
sentence-simplification
In the current version of SORT, both sentence-
level and lexical simplification methods are used
in conjunction to suggest rewritings for sentences
with low confidence scores.
4 Confidence estimation
Our confidence estimator is based on the system
and data provided for the 2012 Quality estima-
tion shared task (Callison-Burch et al, 2012). In
this task, participants were required to estimate the
quality of automated translations. Their estimates
were compared to human scores of the translation
which referred to the suitability of the translation
for post-editing. The scores ranged from 1 to 5,
where 1 corresponded to translation that practi-
cally needs to be done from scratch, and 5 to trans-
lations that requires little to no editing.
The task?s training set consisted of approxi-
mately 1800 source sentences in English, their
Moses translations to Spanish and the scores given
to the translations by the three judges. With this
data we trained an SVM regression model using
SVMlight (Joachims, 1999). Features were ex-
tracted with the task?s feature-extraction baseline
module. Two types of features are used in this
module (i) black-box features, which do not as-
sume access to the translation system, such as
the length of the source and the target, number
of punctuation marks and language model prob-
abilities, and (ii) glass-box features, which are ex-
tracted from the translation model, such as the
average number of translations per source word
(Specia et al, 2009).
5 Initial evaluation and analysis
We performed an initial evaluation of our ap-
proach in an English to Spanish translation setting,
using the 2008 News Commentary data.6 First,
two annotators who speak English but not Spanish
used SORT to rewrite an English text. They re-
viewed the proposed rewritings for 960 sentences
and were instructed to ?trust the judgment? of the
confidence estimator; that is, reviewing the sug-
gestions from the most to the least confident one,
they accepted the first rewriting that was fluent and
preserved the meaning of the source document as
a whole. 440 pairs of the original sentence and
the selected alternative were then both translated
to Spanish and were presented as competitors to
6Available at http://www.statmt.org
88
three native Spanish speakers. The sentences were
placed within their context in the original docu-
ment, taken from the Spanish side of the corpus.
The order of presentation of the two competitors
was random. In this evaluation, the translation of
the original was preferred 20.6% of the cases, the
rewriting 30.4% of them, and for 49% of the sen-
tences, no clear winner was chosen.7 Among the
two rewriting methods, the sentence-level method
more often resulted in preferred translations.
These results suggest that rewriting is esti-
mated to improve translation quality. However,
the amount of preferred original translations indi-
cates that the confidence estimator is not always
discriminative enough: by construction, for every
rewriting that is displayed, the confidence compo-
nent estimates the translation of the original to be
less accurate than that of the rewriting; yet, this is
not always reflected in the preferences of the eval-
uators. On a different dimension than translation
quality, the large number of cases with no clear
winner, and the analysis we conducted, indicate
that the user?s cognitive effort would be decreased
if we only displayed those rewritings associated
with a substantial improvement in confidence; due
to the nature of our methods, frequently, identi-
cal or near-identical translations were generated,
with only marginal differences in confidence, e.g.,
when two source synonyms were translated to the
same target word. Also, often a wrong synonym
was suggested as a replacement for a word (e.g.
Christmas air for Christmas atmosphere). This
was somewhat surprising as we had expected the
language model features of the confidence estima-
tor to help removing these cases. While they were
filtered by the English-speaking users, and thus
did not present a problem for translation, they cre-
ated unnecessary workload. Putting more empha-
sis on context features in the confidence estimation
or explicitly verifying context-suitability of a lex-
ical substitutions could help addressing this issue.
6 Related work
Some related approaches focus on the authoring
process and control a priori the range of possible
texts, either by interactively enforcing lexical and
syntactic constraints on the source that simplify
the operations of a rule-based translation system
(Carbonell et al, 1997), or by semantically guid-
7One should consider these figures with caution, as the
numbers may be too small to be statistically meaningful.
ing a monolingual author in the generation of mul-
tilingual texts (Power and Scott, 1998; Dymetman
et al, 2000). A recent approach (Venkatapathy
and Mirkin, 2012) proposes an authoring tool that
consults the MT system itself to propose phrases
that should be used during composition to obtain
better translations. All these methods address the
authoring of the source text from scratch. This
is inherently different from the objective of our
work where an existing text is modified to improve
its translatability. Moving away from authoring
approaches, (Choumane et al, 2005) propose an
interactive system where the author helps a rule-
based translation system disambiguate a source
text inside a structured document editor. The
techniques are generic and are not automatically
adapted to a specific MT system or model. Closer
to our approach of modifying the source text, one
approach is to paraphrase the source or to gener-
ate sentences entailed by it (Callison-Burch et al,
2006; Mirkin et al, 2009; Marton et al, 2009;
Aziz et al, 2010). These works, however, fo-
cus on handling out-of-vocabulary (OOV) words,
do not assess the translatability of the source sen-
tence and are not interactive.8 The MonoTrans2
project (Hu et al, 2011) proposes monolingual-
based editing for translation. Monolingual speak-
ers of the source and target language collaborate
to improve the translation. Unlike our approach,
here both the feedback for poorly translated sen-
tences and the actual modification of the source
is done by humans. This contrasts with the auto-
matic handling (albeit less accurate) of both these
tasks in our work.
7 Conclusions and future work
We introduced a system for rewriting texts for
translation under the control of a confidence esti-
mator. While we focused on an interactive mode,
where a monolingual user is asked to check the
quality of the source reformulations, in an exten-
sion of this approach, the quality of the reformu-
lations could also be assessed automatically, re-
moving the interactive aspects at the cost of an in-
creased risk of rewriting errors. For future work
we wish to add more powerful rewriting tech-
niques that are able to explore a larger space of
possible reformulations, but compensate this ex-
8Another way to use paraphrases for improved translation
has been proposed by (Max, 2010) who uses paraphrasing of
the source text to increase the number of training examples
for the SMT system.
89
panded space by robust filtering methods. Based
on an evaluation of the quality of the generated al-
ternatives as well as on user selection decisions,
we may be able to learn a quality estimator for
the rewriting operations themselves. Such meth-
ods could be useful both in an interactive mode,
to minimize the effort of the monolingual source
user, as well as in an automatic mode, to avoid
misinterpretation. In this work we used an avail-
able baseline feature extraction module for confi-
dence estimation. A better estimator could bene-
fit our system significantly, as we argued above.
Lastly, we wish to further improve the user inter-
face of the tool, based on feedback from actual
users.
References
[Aziz et al2010] Wilker Aziz, Marc Dymetman,
Shachar Mirkin, Lucia Specia, Nicola Cancedda,
and Ido Dagan. 2010. Learning an expert from
human annotations in statistical machine translation:
the case of out-of-vocabularywords. In Proceedings
of EAMT.
[Callison-Burch et al2006] Chris Callison-Burch,
Philipp Koehn, and Miles Osborne. 2006. Improved
statistical machine translation using paraphrases. In
Proceedings of HLT-NAACL.
[Callison-Burch et al2012] Chris Callison-Burch,
Philipp Koehn, Christof Monz, Matt Post, Radu
Soricut, and Lucia Specia. 2012. Findings of the
2012 workshop on statistical machine translation.
In Proceedings of WMT.
[Carbonell et al1997] Jaime G Carbonell, Sharlene L
Gallup, Timothy J Harris, James W Higdon, Den-
nis A Hill, David C Hudson, David Nasjleti,
Mervin L Rennich, Peggy M Andersen, Michael M
Bauer, et al 1997. Integrated authoring and transla-
tion system. US Patent 5,677,835.
[Choumane et al2005] Ali Choumane, Herv? Blan-
chon, and C?cile Roisin. 2005. Integrating transla-
tion services within a structured editor. In Proceed-
ings of the ACM symposium on Document engineer-
ing. ACM.
[Dymetman et al2000] Marc Dymetman, Veronika
Lux, and Aarne Ranta. 2000. Xml and multilin-
gual document authoring: Convergent trends. In
Proceedings of COLING.
[Fellbaum1998] Christiane Fellbaum, editor. 1998.
WordNet: An Electronic Lexical Database (Lan-
guage, Speech, and Communication). The MIT
Press.
[Feng2008] Lijun Feng. 2008. Text simplification: A
survey. Technical report, CUNY.
[Hu et al2011] Chang Hu, Philip Resnik, Yakov Kro-
nrod, Vladimir Eidelman, Olivia Buzek, and Ben-
jamin B. Bederson. 2011. The value of monolingual
crowdsourcing in a real-world translation scenario:
simulation using haitian creole emergency sms mes-
sages. In Proceedings of WMT.
[Joachims1999] T. Joachims. 1999. Making large-
scale SVM learning practical. In B. Sch?lkopf,
C. Burges, and A. Smola, editors, Advances in Ker-
nel Methods - Support Vector Learning, chapter 11,
pages 169?184. MIT Press.
[Koehn et al2007] Philipp Koehn, Hieu Hoang,
Alexandra Birch, Chris Callison-Burch, Marcello
Federico, Nicola Bertoldi, Brooke Cowan, Wade
Shen, Christine Moran, Richard Zens, Chris Dyer,
Ondrej Bojar, Alexandra Constantin, and Evan
Herbst. 2007. Moses: Open source toolkit for
statistical machine translation. In Proceedings of
ACL, Demo and Poster Sessions.
[Marton et al2009] Yuval Marton, Chris Callison-
Burch, and Philip Resnik. 2009. Improved sta-
tistical machine translation using monolingually-
derived paraphrases. In Proceedings of EMNLP.
[Max2010] Aur?lien Max. 2010. Example-based para-
phrasing for improved phrase-based statistical ma-
chine translation. In Proceedings of EMNLP.
[Mirkin et al2009] Shachar Mirkin, Lucia Specia,
Nicola Cancedda, Ido Dagan, Marc Dymetman, and
Idan Szpektor. 2009. Source-language entailment
modeling for translating unknown terms. In Pro-
ceedings of ACL-IJCNLP.
[O?Brien2006] Sharon O?Brien. 2006. Controlled Lan-
guage and Post-Editing. Multilingual, 17(7):17?19.
[Power and Scott1998] Richard Power and Donia Scott.
1998. Multilingual authoring using feedback texts.
In Proceedings of ACL.
[Specia et al2009] Lucia Specia, Nicola Cancedda,
Marc Dymetman, Marco Turchi, and Nello Cristian-
ini. 2009. Estimating the sentence-level quality
of machine translation systems. In Proceedings of
EAMT.
[Specia2010] Lucia Specia. 2010. Translating from
complex to simplified sentences. In Proceedings of
PROPOR.
[Stolcke2002] Andreas Stolcke. 2002. SRILM - an
extensible language modeling toolkit. In INTER-
SPEECH.
[Venkatapathy and Mirkin2012] Sriram Venkatapathy
and Shachar Mirkin. 2012. An SMT-driven
authoring tool. In Proceedings of COLING 2012:
Demonstration Papers.
[Zhu et al2010] Zhemin Zhu, Delphine Bernhard, and
Iryna Gurevych. 2010. A monolingual tree-based
translation model for sentence simplification. In
Proceedings of COLING.
90
Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 1?9,
COLING 2010, Beijing, August 2010.
Intersecting Hierarchical and Phrase-Based Models of Translation:
Formal Aspects and Algorithms
Marc Dymetman Nicola Cancedda
Xerox Research Centre Europe
{marc.dymetman,nicola.cancedda}@xrce.xerox.com
Abstract
We address the problem of construct-
ing hybrid translation systems by inter-
secting a Hiero-style hierarchical sys-
tem with a phrase-based system and
present formal techniques for doing so.
We model the phrase-based component
by introducing a variant of weighted
finite-state automata, called ?-automata,
provide a self-contained description
of a general algorithm for intersect-
ing weighted synchronous context-free
grammars with finite-state automata, and
extend these constructs to ?-automata.
We end by briefly discussing complexity
properties of the presented algorithms.
1 Introduction
Phrase-based (Och and Ney, 2004; Koehn et
al., 2007) and Hierarchical (Hiero-style) (Chi-
ang, 2007) models are two mainstream ap-
proaches for building Statistical Machine Trans-
lation systems, with different characteristics.
While phrase-based systems allow a direct cap-
ture of correspondences between surface-level
lexical patterns, but at the cost of a simplistic
handling of re-ordering, hierarchical systems are
better able to constrain re-ordering, especially
for distant language pairs, but tend to produce
sparser rules and often lag behind phrase-based
systems for less distant language pairs. It might
therefore make sense to capitalize on the com-
plementary advantages of the two approaches by
combining them in some way.
This paper attempts to lay out the formal
prerequisites for doing so, by developing tech-
niques for intersecting a hierarchical model and
a phrase-based model. In order to do so, one first
difficulty has to be overcome: while hierarchical
systems are based on the mathematically well-
understood formalism of weighted synchronous
CFG?s, phrase-based systems do not correspond
to any classical formal model, although they are
loosely connected to weighted finite state trans-
ducers, but crucially go beyond these by allow-
ing phrase re-orderings.
One might try to address this issue by limiting
a priori the amount of re-ordering, in the spirit
of (Kumar and Byrne, 2005), which would allow
to approximate a phrase-based model by a stan-
dard transducer, but this would introduce further
issues. First, limiting the amount of reorder-
ing in the phrase-based model runs contrary to
the underlying intuitions behind the intersection,
namely that the hierarchical model should be
mainly responsible for controlling re-ordering,
and the phrase-based model mainly responsible
for lexical choice. Second, the transducer result-
ing from the operation could be large. Third,
even if we could represent the phrase-based
model through a finite-state transducer, intersect-
ing this transducer with the synchronous CFG
would actually be intractable in the general case,
as we indicate later.
We then take another route. For a fixed source
sentence x, we show how to construct an au-
tomaton that represents all the (weighted) tar-
get sentences that can be produced by apply-
ing the phrase based model to x. However, this
??-automaton? is non-standard in the sense that
each transition is decorated with a set of source
sentence tokens and that the only valid paths are
1
those that do not traverse two sets containing the
same token (in other words, valid paths cannot
?consume? the same source token twice).
The reason we are interested in ?-automata
is the following. First, it is known that inter-
secting a synchronous grammar simultaneously
with the source sentence x and a (standard) target
automaton results in another synchronous gram-
mar; we provide a self-contained description of
an algorithm for performing this intersection, in
the general weighted case, and where x is gener-
alized to an arbitrary source automaton. Second,
we extend this algorithm to ?-automata. The
resulting weighted synchronous grammar repre-
sents, as in Hiero, the ?parse forest? (or ?hy-
pergraph?) of all weighted derivations (that is
of all translations) that can be built over x, but
where the weights incorporate knowledge of the
phrase-based component; it can therefore form
the basis of a variety of dynamic programming
or sampling algorithms (Chiang, 2007; Blunsom
and Osborne, 2008), as is the case with standard
Hiero-type representations. While in the worst
case the intersected grammar can contain an ex-
ponential number of nonterminals, we argue that
such combinatorial explosion will not happen in
practice, and we also briefly indicate formal con-
ditions under which it will not be allowed to hap-
pen.
2 Intersecting weighted synchronous
CFG?s with weighted automata
We assume that the notions of weighted finite-
state automaton [W-FSA] and weighted syn-
chronous grammar [W-SCFG] are known (for
short descriptions see (Mohri et al, 1996) and
(Chiang, 2006)), and we consider:
1. A W-SCFG G, with associated source
grammar Gs (resp. target grammar Gt); the
terminals of Gs (resp. Gt) vary over the
source vocabulary Vs (resp. target vocab-
ulary Vt).
2. A W-FSA As over the source vocabulary
Vs, with initial state s# and final state s$.
3. A W-FSA At over the target vocabulary Vt,
with initial state t# and final state t$.
The grammar G defines a weighted synchronous
language LG over (Vs, Vt), the automaton As a
weighted language Ls over Vs, and the automa-
ton At a weighted language Lt over Vt. We
then define the intersection language L? between
these three languages as the synchronous lan-
guage denoted L? = Ls e LG e Lt over (Vs, Vt)
such that, for any pair (x, y) of a source and a
target sentence, the weight L?(x, y) is defined
by L?(x, y) ? Ls(x) ? LG(x, y) ? Lt(y), where
Ls(x), LG(x, y), Lt(y) are the weights associ-
ated to each of the component languages.
It is natural to ask whether there exists a syn-
chronous grammar G? generating the language
L?, which we will now show to be the case.1
Our approach is inspired by the construction in
(Bar-Hillel et al, 1961) for the intersection of a
CFG and an FSA and the observation in (Lang,
1994) relating this construction to parse forests,
and also partially from (Satta, 2008), although,
by contrast to that work, our construction, (i)
is done simultaneously rather than as the se-
quence of intersecting As with G, then the re-
sulting grammar with At, (ii) handles weighted
formalisms rather than non-weighted ones.
We will describe the construction of G? based
on an example, from which the general construc-
tion follows easily. Consider a W-SCFG gram-
mar G for translating between French and En-
glish, with initial nonterminal S, and containing
among others the following rule:
N? A manque a` B / B misses A : ?, (1)
where the source and target right-hand sides are
separated by a slash symbol, and where ? is a
non-negative real weight (interpreted multiplica-
tively) associated with the rule.
Now let?s consider the following ?rule
scheme?:
t0
s0Nt3s4 ? t2s0At3s1 s1manques2 s2 a`s3 t0s3Bt1s4 /
t0
s3Bt1s4 t1missest2 t2s0At3s1 (2)
1We will actually only need the application of this result
to the case where As is a ?degenerate? automaton describ-
ing a single source sentence x, but the general construction
is not harder to do than this special case and the resulting
format for G? is well-suited to our needs below.
2
This scheme consists in an ?indexed? version of
the original rule, where the bottom indices si
correspond to states of As (?source states?), and
the top indices ti to states of At (?target states?).
The nonterminals are associated with two source
and two target indices, and for the same nonter-
minal, these four indices have to match across
the source and the target RHS?s of the rule. As
for the original terminals, they are replaced by
?indexed terminals?, where source (resp. tar-
get) terminals have two source (resp. target) in-
dices. The source indices appear sequentially
on the source RHS of the rule, in the pattern
s0, s1, s1, s2, s2 . . . sm?1, sm, with the nonter-
minal on the LHS receiving source indices s0
and sm, and similarly the target indices appear
sequentially on the target RHS of the rule, in the
pattern t0, t1, t1, t2, t2 . . . tn?1, tn, with the non-
terminal on the LHS receiving target indices t0
and tn. To clarify, the operation of associating
indices to terminals and nonterminals can be de-
composed into three steps:
s0Ns4 ? s0As1 s1manques2 s2 a` s3 s3Bs4 /
B misses A
t0Nt3 ? A manque a` B /
t0Bt1 t1missest2 t2At3
t0
s0Nt3s4 ? t2s0At3s1 s1manques2 s2 a` s3 t0s3Bt1s4 /
t0
s3Bt1s4 t1missest2 t2s0At3s1
where the first two steps corresponds to handling
the source and target indices separately, and the
third step then assembles the indices in order to
get the same four indices on the two copies of
each RHS nonterminal. The rule scheme (2) now
generates a family of rules, each of which corre-
sponds to an arbitrary instantiation of the source
and target indices to states of the source and tar-
get automata respectively. With every such rule
instantiation, we associate a weight ?? which is
defined as:
?? ? ? ?
?
si s-termsi+1
?As(si, s-term, si+1)
?
?
tj t-termtj+1
?At(tj , t-term, tj+1), (3)
where the first product is over the indexed source
terminals sis-termsi+1 , the second product
over the indexed target terminals tj t-termtj+1 ;
?As(si, s-term, si+1) is the weight of the transi-
tion (si, s-term, si+1) according to As, and sim-
ilarly for ?At(tj , t-term, tj+1). In these prod-
ucts, it may happen that ?As(si, s-term, si+1) is
null (and similarly for At), and in such a case,
the corresponding rule instantiation is consid-
ered not to be realized. Let us consider the multi-
set of all the weighted rule instantiations for (1)
computed in this way, and for each rule in the
collection, let us ?forget? the indices associated
to the terminals. In this way, we obtain a col-
lection of weighted synchronous rules over the
vocabularies Vs and Vt, but where each nonter-
minal is now indexed by four states.2
When we apply this procedure to all the rules
of the grammar G, we obtain a new weighted
synchronous CFG G?, with start symbol t#s#St$s$ ,
for which we have the following Fact, of which
we omit the proof for lack of space.
Fact 1. The synchronous language LG? associ-
ated with G? is equal to L? = Ls e LG e Lt.
The grammar G? that we have just constructed
does fulfill the goal of representing the bilat-
eral intersection that we were looking for, but
it has a serious defect: most of its nontermi-
nals are improductive, that is, can never pro-
duce a bi-sentence. If a rule refers to such an
improductive nonterminal, it can be eliminated
from the grammar. This is the analogue for a
SCFG of the classical operation of reduction for
CFG?s; while, conceptually, we could start from
G? and perform the reduction by deleting the
many rules containing improductive nontermi-
nals, it is equivalent but much more efficient to
do the reverse, namely to incrementally add the
productive nonterminals and rules of G? starting
from an initially empty set of rules, and by pro-
ceeding bottom-up starting from the terminals.
We do not detail this process, which is relatively
2It is possible that the multiset obtained by this simpli-
fying operation contains duplicates of certain rules (pos-
sibly with different weights), due to the non-determinism
of the automata: for instance, two sequences such
as?s1manques2 s2 a`s3 ? and ?s1manques?2 s?2 a`s3 ? become in-distinguishable after the operation. Rather than producing
multiple instances of rules in this way, one can ?conflate?
them together and add their weights.
3
straightforward.3
A note on intersecting SCFGs with transduc-
ers Another way to write Ls e LG e Lt is as
the intersection (Ls ? Lt) ? LG. (Ls ? Lt) can
be seen as a rational language (language gener-
ated by a finite state transducer) of an especially
simple form over Vs ? Vt . It is then natural
to ask whether our previous construction can be
generalized to the intersection of G with an arbi-
trary finite-state transducer. However, this is not
the case. Deciding the emptiness problem for
the intersection between two finite state trans-
ducers is already undecidable, by reduction to
Post?s Correspondence problem (Berstel, 1979,
p. 90) and we have extended the proof of this fact
to show that intersection between a synchronous
CFG and a finite state transducer also has an un-
decidable emptiness problem (the proof relies on
the fact that a finite state transducer can be sim-
ulated by a synchronous grammar). A fortiori,
this intersection cannot be represented through
an (effectively constructed) synchronous CFG.
3 Phrase-based models and ?-automata
3.1 ?-automata: definition
Let Vs be a source vocabulary, Vt a target vocab-
ulary. Let x = x1, . . . , xM be a fixed sequence
of words over a certain source vocabulary Vs.
Let us denote by z a token in the sequence x,
and by Z the set of the M tokens in x. A ?-
automaton over x has the general form of a stan-
dard weighted automaton over the target vocabu-
lary, but where the edges are also decorated with
elements ofP(Z), the powerset ofZ (see Fig. 1).
An edge in the ?-automaton between two states
q and q? then carries a label of the form (?, ?),
where ? ? P(Z) and ? ? Vt (note that here we
do not allow ? to be the empty string ). A path
from the initial state of the automaton to its fi-
nal state is defined to be valid iff each token of x
appears in exactly one label of the path, but not
necessarily in the same order as in x. As usual,
the output associated with the path is the ordered
3This bottom-up process is analogous to chart-parsing,
but here we have decomposed the construction into first
building a semantics-preserving grammar and then reduc-
ing it, which we think is formally neater.
sequence of target labels on that path, and the
weight of the path is the product of the weights
on its edges.
?-automata and phrase-based translation
A mainstream phrase-based translation system
such as Moses (Koehn et al, 2007) can be ac-
counted for in terms of ?-automata in the follow-
ing way. To simplify exposition, we assume that
the language model used is a bigram model, but
any n-gram model can be accommodated. Then,
given a source sentence x, decoding works by at-
tempting to construct a sequence of phrase-pairs
of the form (x?1, y?1), ..., (x?k, y?k) such that each
x?i corresponds to a contiguous subsequence of
tokens of x, the x?i?s do not overlap and com-
pletely cover x, but may appear in a different
order than that of x; the output associated with
the sequence is simply the concatenation of all
the y?i?s in that sequence.4 The weight associ-
ated with the sequence of phrase-pairs is then
the product (when we work with probabilities
rather than log-probabilities) of the weight of
each (x?i+1, y?i+1) in the context of the previous
(x?i, y?i), which consists in the product of several
elements: (i) the ?out-of-context? weight of the
phrase-pair (x?i+1, y?i+1) as determined by its fea-
tures in the phrase table, (ii) the language model
probability of finding y?i+1 following y?i,5 (iii)
the contextual weight of (x?i+1, y?i+1) relative to
(x?i, y?i) corresponding to the distorsion cost of
?jumping? from the token sequence x?i to the to-
ken sequence x?i+1 when these two sequences
may not be consecutive in x.6
Such a model can be represented by a ?-
automaton, where each phrase-pair (x?, y?) ? for
4We assume here that the phrase-pairs (x?i, y?i) are such
that y?i is not the empty string (this constraint could be re-
moved by an adaptation of the -removal operation (Mohri,
2002) to ?-automata).
5This is where the bigram assumption is relevant: for
a trigram model, we may need to encode in the automaton
not only the immediately preceding phrase-pair, but also
the previous one, and so on for higher-order models. An
alternative is to keep the n-gram language model outside
the ?-automaton and intersect it later with the grammar G?
obtained in section 4, possibly using approximation tech-
niques such as cube-pruning (Chiang, 2007).
6Any distorsion model ? in particular ?lexicalized re-
ordering? ? that only depends on comparing two consec-
utive phrase-pairs can be implemented in this way.
4
# h
b a
r
k
$
tcl f
tcl1
tcl2
{ces}
these
{avocats, marrons}
totally
?
lawyers?
corrupt {cuits}
finished
{sont}
are
{avocats}
avocadoes
{sont}
are
{cuits}
cooked
{$}
$
{marrons}
brown
{$}
$
# h
b a
r
k
$
tcl f
tcl1
tcl2
these
totally
lawyers
corrupt
finishedare
avocadoes
are cooked $brown
$
Figure 1: On the top: a ?-automaton with two valid paths shown. Each box denotes a state corresponding to a phrase
pair, while states internal to a phrase pair (such as tcl1 and tcl2) are not boxed. Above each transition we have indicated
the corresponding target word, and below it the corresponding set of source tokens. We use a terminal symbol $ to denote
the end of sentence both on the source and on the target. The solid path corresponds to the output these totally corrupt
lawyers are finished, the dotted path to the output these brown avocadoes are cooked. Note that the source tokens are not
necessarily consumed in the order given by the source, and that, for example, there exists a valid path generating these
are totally corrupt lawyers finished and moving according to h ? r ? tcl1 ? tcl2 ? tcl ? f ; Note, however, that
this does not mean that if a biphrase such as (marrons avocats, avocado chestnuts) existed in the phrase
table, it would be applicable to the source sentence here: because the source words in this biphrase would not match the
order of the source tokens in the sentence, the biphrase would not be included in the ?-automaton at all. On the bottom:
The target W-FSA automaton At associated with the ?-automaton, where we are ignoring the source tokens (but keeping
the same weights).
x? a sequence of tokens in x and (x?, y?) an entry
in the global phrase table ? is identified with a
state of the automaton and where the fact that the
phrase-pair (x??, y??) = ((x1, ..., xk), (y1, ..., yl))
follows (x?, y?) in the decoding sequence is mod-
eled by introducing l ?internal? transitions with
labels (?, y1), (?, y2), ..., (?, yl), where ? =
{x1, ..., xk}, and where the first transition con-
nects the state (x?, y?) to some unique ?internal
state? q1, the second transition the state q1 to
some unique internal state q2, and the last tran-
sition qk to the state (x??, y??).7 Thus, a state
(x??, y??) essentially encodes the previous phrase-
pair used during decoding, and it is easy to see
that it is possible to account for the different
weights associated with the phrase-based model
by weights associated to the transitions of the ?-
automaton.8
7For simplicity, we have chosen to collect the set of all
the source tokens {x1, ..., xk} on the first transition, but we
could distribute it on the l transitions arbitrarily (but keep-
ing the subsets disjoint) without changing the semantics of
what we do. This is because once we have entered one of
the l internal transitions, we will always have to traverse
the remaining internal transitions and collect the full set of
source tokens.
8By creating states such as ((x?, y?), (x??, y??)) that en-
Example Let us consider the following French
source sentence x: ces avocats marrons sont
cuits (idiomatic expression for these totally cor-
rupt lawyers are finished). Let?s assume that the
phrase table contains the following phrase pairs:
h: (ces, these)
a: (avocats, avocados)
b: (marrons, brown)
tcl: (avocats marrons,
totally corrupt lawyers)
r: (sont, are)
k: (cuits, cooked)
f: (cuits, finished).
An illustration of the corresponding ?-
automaton SA is shown at the top of Figure 1,
with only a few transitions made explicit, and
with no weights shown.9
code the two previous phrase-pairs used during decoding,
it is possible in principle to account for a trigram language
model, and similarly for higher-order LMs. This is simi-
lar to implementing n-gram language models by automata
whose states encode the n? 1 words previously generated.
9Only two (valid) paths are shown. If we had shown the
full ?-automaton, then the graph would have been ?com-
plete? in the sense that for any two box states B,B?, we
would have shown a connection B ? B?1... ? B?k?1 ?
B?, where the B?i are internal states, and k is the length of
the target side of the biphrase B?.
5
4 Intersecting a synchronous grammar
with a ?-automaton
Intersection of a W-SCFG with a ?-
automaton If SA is a ?-automaton over
input x, with each valid path in SA we asso-
ciate a weight in the same way as we do for
a weighted automaton. For any target word
sequence in V ?t we can then associate the sum
of the weights of all valid paths outputting that
sequence. The weighted language LSA,x over
Vt obtained in this way is called the language
associated with SA. Let G be a W-SCFG over
Vs, Vt, and let us denote by LG,x the weighted
language over Vs, Vt corresponding to the
intersection {x} e G e V ?t , where {x} denotes
the language giving weight 1 to x and weight 0
to other sequences in V ?s , and V ?t denotes the
language giving weight 1 to all sequences in V ?t .
Note that non-null bi-sentences in LG,x have
their source projection equal to x and therefore
LG,x can be identified with a weighted language
over Vt. The intersection of the languages LSA,x
and LG,x is denoted by LSA,x e LG,x.
Example Let us consider the following W-
SCFG (where again, weights are not explicitly
shown, and where we use a terminal symbol $
to denote the end of a sentence, a technicality
needed for making the grammar compatible with
the SA automaton of Figure 1):
S ? NP VP $ / NP VP $
NP ? ces N A / these A N
VP ? sont A / are A
A ? marrons / brown
A ? marrons / totally corrupt
A ? cuits / cooked
A ? cuits / finished
N ? avocats / avocadoes
N ? avocats / lawyers
It is easy to see that, for instance, the sen-
tences: these brown avocadoes are cooked $,
these brown avocadoes are finished $, and these
totally corrupt lawyers are finished $ all belong
to the intersection LSA,x e LG,x, while the sen-
tences these avocadoes brown are cooked $, to-
tally corrupt lawyers are finished these $ belong
only to LSA,x.
Building the intersection We now describe
how to build a W-SCFG that represents the inter-
section LSA,x eLG,x. We base our explanations
on the example just given.
A Relaxation of the Intersection At the
bottom of Figure 1, we show how we can as-
sociate an automaton At with the ?-automaton
SA: we simply ?forget? the source-sides of the
labels carried by the transitions, and retain all the
weights. As before, note that we are only show-
ing a subset of the transitions here.
All valid paths for SAmap into valid paths for
At (with the same weights), but the reverse is not
true because some validAt paths can correspond
to traversals of SA that either consume several
time the same source token or do not consume all
source tokens. For instance, the sentence these
brown avocadoes brown are $ belongs to the
language of At, but cannot be produced by SA.
Let?s however consider the intersection {x} e
G e At, where, with a slight abuse of notation,
we have notated {x} the ?degenerate? automaton
representing the sentence x, namely the automa-
ton (with weights on all transitions equal to 1):
?
ces marronsavocats sont cuits $
0 1 2 3 4 5 6
This is a relaxation of the true intersection, but
one that we can represent through a W-SCFG, as
we know from section 2.10
This being noted, we now move to the con-
struction of the full intersection.
The full intersection We discussed in sec-
tion 2 how to modify a synchronous grammar
rule in order to produce the indexed rule scheme
(2) in order to represent the bilateral intersection
of the grammar with two automata. Let us redo
that construction here, in the case of our example
10Note that, in the case of our very simple example, any
target string that belongs to this relaxed intersection (which
consists of the eight sentences these {brown | totally cor-
rupt} {avocadoes | lawyers} are {cooked | finished}) actu-
ally belongs to the full intersection, as none of these sen-
tences corresponds to a path in SA that violates the token-
consumption constraint. More generally, it may often be
the case in practice that the W-SCFG, by itself, provides
enough ?control? of the possible target sentences to pre-
vent generation of sentences that would violate the token-
consumption constraints, so that there may be little differ-
ence in practice between performing the relaxed intersec-
tion {x} e G e At and performing the full intersection
{x} eG e LSA,x.
6
W-SCFG, of the target automaton represented on
the bottom of Figure 1, and of the source automa-
ton {x}.
The construction is then done in three steps:
s0NPs3 ? s0cess1 s1Ns2 s2As3 /
these A N
t0NPt3 ? ces N A /
t0theset1 t1At2 t2Nt3
t0
s0NPt3s3 ? s0cess1 t2s1Nt3s2 t1s2At2s3 /
t0theset1 t1s2At2s3 t2s1Nt3s2
In order to adapt that construction to the case
where we want the intersection to be with a ?-
automaton, what we need to do is to further spe-
cialize the nonterminals. Rather than specializ-
ing a nonterminal X in the form tsXt?s? , we spe-
cialize it in the form: tsXt
?,?
s? , where ? representsa set of source tokens that correspond to ?collect-
ing? the source tokens in the ?-automaton along
a path connecting the states t and t?.11
We then proceed to define a new rule scheme
associated to our rule, which is obtained as be-
fore in three steps, as follows.
s0NPs3 ? s0cess1 s1Ns2 s2As3 /
these A N
t0NPt3,?03 ? ces N A /
t0theset1,?01 t1At2,?12 t2Nt3,?23
t0
s0NPt3,?03s3 ? s0cess1 t2s1Nt3,?23s2 t1s2At2,?12s3 /
t0theset1,?01 t1s2At2,?12s3 t2s1Nt3,?23s2
The only difference with our previous tech-
nique is in the addition of the ??s to the top in-
dices. Let us focus on the second step of the an-
notation process:
t0NPt3,?03 ? ces N A /
t0theset1,?01 t1At2,?12 t2Nt3,?23
11To avoid a possible confusion, it is important to note
right away that ? is not necessarily related to the tokens
appearing between the positions s and s? in the source sen-
tence (that is, between these states in the associated source
automaton), but is defined solely in terms of the source to-
kens along the t, t? path. See example with ?persons? and
?people? below.
Conceptually, when instanciating this scheme,
the ti?s may range over all possible states of
the ?-automaton, and the ?ij over all subsets of
the source tokens, but under the following con-
straints: the RHS ??s (here ?01, ?12, ?23) must
be disjoint and their union must be equal to the ?
on the LHS (here ?03). Additionally, a ? associ-
ated with a target terminal (as ?01 here) must be
equal to the token set associated to the transition
that this terminal realizes between ?-automaton
states (here, this means that ?01 must be equal
to the token set {ces} associated with the transi-
tion between t0, t1 labelled with ?these?). If we
perform all these instantiations, compute their
weights according to equation (3), and finally re-
move the indices associated with terminals in the
rules (by adding the weights of the rules only dif-
fering by the indices of terminals, as done previ-
ously), we obtain a very large ?raw? grammar,
but one for which one can prove direct coun-
terpart of Fact 1. Let us call, as before G? the
raw W-SCFG obtained, its start symbol being
t#
s#S
t$,?alls$ , with ?all the set of all source tokens
in x.
Fact 2. The synchronous language LG? associ-
ated with G? is equal to ({x}, LSA,x e LG,x).
The grammar that is obtained this way, despite
correctly representing the intersection, contains
a lot of useless rules, this being due to the fact
that many nonterminals can not produce any out-
put. The situation is wholly similar to the case
of section 2, and the same bottom-up techniques
can be used for activating nonterminals and rules
bottom-up.
The algorithm is illustrated in Figure 2, where
we have shown the result of the process of acti-
vating in turn the nonterminals (abbreviated by)
N1, A1, A2, NP1, VP1, S1. As a consequence
of these activations, the original grammar rule
NP ? ces N A /these A N (for instance)
becomes instantiated as the rule:
#
0 NPtcl,{ces,avocats,marrons}3 ?
0ces1 tcl21 Ntcl,?2 h2Atcl2,{avocats,marrons}3 /
#theseh,{ces} h2Atcl2,{avocats,marrons}3 tcl21 Ntcl,?2
7
# h r $
tcl f
tcl1
tcl2
{ces}
these
{avocats, marrons}
totally
?
lawyers?
corrupt {cuits}
finished
{sont}
are
{$}
$
ces marronsavocats sont cuits $
S 1
S 1
N 1 A1 A2
VP1NP1
NP1 VP1
A2
A1
N 1
0 1 2 3 4 5 6
2 ,
1 2
2,{ , }
2 3
# ,{ , , }
0 3
,{ }
4 5
,{ , }
3 5
# ,{ , , , , ,$ $}
0 6
1:
1:
1:
2 :
1:
1:
tcl tcl
h tcl avocats marrons
tcl ces avocats marrons
r f cuits
tcl f sont cuits
ces avocats marrons sont cuits
N N
A A
NP NP
A A
VP VP
S S
?
Figure 2: Building the intersection. The bottom of the figure shows some active non-terminals associated with the source
sequence, at the top these same non-terminals associated with a sequence of transitions in the ?-automaton, corresponding
to the target sequence these totally corrupt lawyers are finished $. To avoid cluttering the drawing, we have used the
abbreviations shown on the right. Note that while A1 only spans marrons in the bottom chart, it is actually decorated with
the source token set {avocats,marrons}: such a ?disconnect? between the views that the W-SCFG and the ?-automaton
have of the source tokens is not ruled out.
that is, after removal of the indices on terminals:
#
0 NPtcl,{ces,avocats,marrons}3 ?
ces tcl21 Ntcl,?2 h2Atcl2,{avocats,marrons}3 /
these h2Atcl2,{avocats,marrons}3 tcl21 Ntcl,?2
Note that while the nonterminal tcl21 Ntcl,?2 by
itself consumes no source token (it is associated
with the empty token set), any actual use of this
nonterminal (in this specific rule or possibly in
some other rule using it) does require travers-
ing the internal node tcl2 and therefore all the
internal nodes ?belonging? to the biphrase tcl
(because otherwise the path from # to $ would
be disconnected); in particular this involves con-
suming all the tokens on the source side of tcl,
including ?avocats?.12
Complexity considerations The bilateral in-
tersection that we defined between a W-SCFG
12In particular there is no risk that a derivation relative
to the intersected grammar generates a target containing
two instances of ?lawyers?, one associated to the expansion
of tcl21 Ntcl,?2 and consuming no source token, and anotherone associated with a different nonterminal and consuming
the source token ?avocats?: this second instance would in-
volve not traversing tcl1, which is impossible as soon as
tcl2
1 Ntcl,?2 is used.
and two W-FSA?s in section 2 can be shown to
be of polynomial complexity in the sense that it
takes polynomial time and space relative to the
sum of the sizes of the two automata and of the
grammar to construct the (reduced) intersected
grammar G?, under the condition that the gram-
mar right-hand sides have length bounded by a
constant.13
The situation here is different, because the
construction of the intersection can in princi-
ple introduce nonterminals indexed not only by
states of the automata, but also by arbitrary sub-
sets of source tokens, and this may lead in ex-
treme cases to an exponential number of rules.
Such problems however can only happen in sit-
uations where, in a nonterminal tsXt
?,?
s? , the set
? is allowed to contain tokens that are ?unre-
lated? to the token set {personnes} appearing
between s and s? in the source automaton. An il-
lustration of such a situation is given by the fol-
lowing example. Suppose that the source sen-
13If this condition is removed, and for the simpler case
where the source (resp. target) automaton encodes a single
sentence x (resp. y), (Satta and Peserico, 2005) have shown
that the problem of deciding whether (x, y) is recognized
by G is NP-hard relative to the sum of the sizes. A conse-
quence is then that the grammar G? cannot be constructed
in polynomial time unless P = NP .
8
tence contains the two tokens personnes and
gens between positions i, i + 1 and j, j + 1 re-
spectively, with i and j far from each other, that
the phrase table contains the two phrase pairs
(personnes, persons) and (gens, people), but
that the synchronous grammar only contains the
two rules X ? personnes/people and Y ?
gens/persons, with these phrases and rules ex-
hausting the possibilities for translating gens
and personnes; Then the intersected grammar
will contain such nonterminals as tiXt
?,{gens}
i+1 and
r
jY
r?,{personnes}
j+1 , where in the first case the token
set {gens} in the first nonterminal is unrelated to
the tokens appearing between i, i + 1, and simi-
larly in the second case.
Without experimentation on real cases, it
is impossible to say whether such phenomena
would empirically lead to combinatorial explo-
sion or whether the synchronous grammar would
sufficiently constrain the phrase-base component
(whose re-ordering capabilities are responsible
in fine for the potential NP-hardness of the trans-
lation process) to avoid it. Another possible ap-
proach is to prevent a priori a possible combi-
natorial explosion by adding formal constraints
to the intersection mechanism. One such con-
straint is the following: disallow introduction of
t
iX
t?,?
j when the symmetric difference between
? and the set of tokens between positions i and
j in the source sentence has cardinality larger
than a small constant. Such a constraint could
be interpreted as keeping the SCFG and phrase-
base components ?in sync?, and would be better
adapted to the spirit of our approach than limit-
ing the amount of re-ordering permitted to the
phrase-based component, which would contra-
dict the reason for using a hierarchical compo-
nent in the first place.
5 Conclusion
Intersecting hierarchical and phrase-based mod-
els of translation could allow to capitalize on
complementarities between the two approaches.
Thus, one might train the hierarchical compo-
nent on corpora represented at the part-of-speech
level (or at a level where lexical units are ab-
stracted into some kind of classes) while the
phrase-based component would focus on transla-
tion of lexical material. The present paper does
not have the ambition to demonstrate that such
an approach would improve translation perfor-
mance, but only to provide some formal means
for advancing towards that goal.
References
Bar-Hillel, Y., M. Perles, and E. Shamir. 1961. On for-
mal properties of simple phrase structure grammars.
Zeitschrift fu?r Phonetik, Sprachwissenschaft und Kom-
municationsforschung, 14:143?172.
Berstel, Jean. 1979. Transductions and Context-Free Lan-
guages. Teubner, Stuttgart.
Blunsom, P. and M. Osborne. 2008. Probabilistic inference
for machine translation. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 215?223. Association for Computational
Linguistics. Slides downloaded.
Chiang, David. 2006. An introduction to synchronous
grammars. www.isi.edu/?chiang/papers/
synchtut.pdf, June.
Chiang, David. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33:201?228.
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin,
and Evan Herbst. 2007. Moses: Open source toolkit for
statistical machine translation. In ACL. The Association
for Computer Linguistics.
Kumar, Shankar and William Byrne. 2005. Local phrase
reordering models for statistical machine translation. In
Proc. HLT/EMNLP.
Lang, Bernard. 1994. Recognition can be harder than pars-
ing. Computational Intelligence, 10:486?494.
Mohri, Mehryar, Fernando Pereira, and Michael Riley.
1996. Weighted automata in text and speech processing.
In ECAI-96 Workshop on Extended Finite State Models
of Language.
Mohri, Mehryar. 2002. Generic epsilon-removal and input
epsilon-normalization algorithms for weighted trans-
ducers. International Journal of Foundations of Com-
puter Science, 13:129?143.
Och, Franz Josef and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Comput. Linguist., 30(4):417?449.
Satta, Giorgio and Enoch Peserico. 2005. Some compu-
tational complexity results for synchronous context-free
grammars. In HLT ?05: Proceedings of the conference
on Human Language Technology and Empirical Meth-
ods in Natural Language Processing, pages 803?810,
Morristown, NJ, USA. Association for Computational
Linguistics.
Satta, Giorgio. 2008. Translation algorithms by means of
language intersection. Submitted. www.dei.unipd.
it/?satta/publ/paper/inters.pdf.
9
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 472?483,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Investigations in Exact Inference for Hierarchical Translation
Wilker Aziz?, Marc Dymetman?, Sriram Venkatapathy?
?University of Wolverhampton, Wolverhampton, UK
?Xerox Research Centre Europe, Grenoble, France
?w.aziz@wlv.ac.uk, ?{first.last}@xrce.xerox.com
Abstract
We present a method for inference in hi-
erarchical phrase-based translation, where
both optimisation and sampling are per-
formed in a common exact inference
framework related to adaptive rejection
sampling. We also present a first imple-
mentation of that method along with ex-
perimental results shedding light on some
fundamental issues. In hierarchical transla-
tion, inference needs to be performed over
a high-complexity distribution defined by
the intersection of a translation hypergraph
and a target language model. We replace
this intractable distribution by a sequence
of tractable upper-bounds for which exact
optimisers and samplers are easy to obtain.
Our experiments show that exact inference
is then feasible using only a fraction of the
time and space that would be required by
the full intersection, without recourse to
pruning techniques that only provide ap-
proximate solutions. While the current im-
plementation is limited in the size of inputs
it can handle in reasonable time, our exper-
iments provide insights towards obtaining
future speedups, while staying in the same
general framework.
1 Introduction
In statistical machine translation (SMT), optimi-
sation ? the task of searching for an optimum
translation ? is performed over a high-complexity
distribution defined by the intersection between a
translation hypergraph and a target language model
(LM). This distribution is too complex to be repre-
sented exactly and one typically resorts to approx-
imation techniques such as beam-search (Koehn et
al., 2003) and cube-pruning (Chiang, 2007), where
maximisation is performed over a pruned represen-
tation of the full distribution.
Often, rather than finding a single optimum, one
is really interested in obtaining a set of proba-
bilistic samples from the distribution. This is the
case for minimum error rate training (Och, 2003;
Watanabe et al, 2007), minimum risk training
(Smith and Eisner, 2006) and minimum risk de-
coding (Kumar and Byrne, 2004). Due to the ad-
ditional computational challenges posed by sam-
pling, n-best lists, a by-product of optimisation, are
typically used as approximation to true probabilis-
tic samples. A known issue with n-best lists is that
they tend to be clustered around only one mode of
the distribution. A more direct procedure is to at-
tempt to directly draw samples from the underlying
distribution rather than rely on n-best list approxi-
mations (Arun et al, 2009; Blunsom and Osborne,
2008).
OS? (Dymetman et al, 2012a) is a recent ap-
proach that stresses a unified view between the two
types of inference, optimisation and sampling. In
this view, rather than resorting to pruning in or-
der to cope with the tractability issues, one upper-
bounds the complex goal distribution with a sim-
pler ?proposal? distribution for which dynamic
programming is feasible. This proposal is incre-
mentally refined to be closer to the goal until the
maximum is found, or until the sampling perfor-
mance exceeds a certain level.
This paper applies the OS? approach to the
problem of inference in hierarchical SMT (Chi-
ang, 2007). In a nutshell, the idea is to replace
the intractable problem of intersecting a context-
free grammar with a full language model by the
tractable problem of intersecting it with a simpli-
fied, optimistic version of this LM which ?forgets?
parts of n-gram contexts, and to incrementally add
more context based on evidence of the need to do
so. Evidence is gathered by optimising or sampling
from the tractable proxy distribution and focussing
on the most serious over-optimistic estimates rela-
tive to the goal distribution.
472
Our main contribution is to provide an exact op-
timiser/sampler for hierarchical SMT that is effi-
cient in exploring only a small fraction of the space
of n-grams involved in a full intersection. Al-
though at this stage our experiments are limited to
short sentences, they provide insights on the be-
havior of the technique and indicate directions to-
wards a more efficient implementation within the
same paradigm.
The paper is organized as follows: ?2 provides
background on OS? and hierarchical translation; ?3
describes our approach to exact inference in SMT;
in ?4 the experimental setup is presented and find-
ings are discussed; ?5 discusses related work, and
?6 concludes.
2 Background
2.1 OS?
The OS? approach (Dymetman et al, 2012a;
Dymetman et al, 2012b) proposes a unified view
of exact inference in sampling and optimisation,
where the two modalities are seen as extremes in a
continuum of inference tasks in Lp spaces (Rudin,
1987), with sampling associated with the L1 norm,
and optimisation with the L? norm.
The objective function p, over which inference
needs to be performed, is a complex non-negative
function over a discrete or continuous space X ,
which defines an unnormalised distribution over
X . The goal is to optimise or sample relative to
p ? where sampling is interpreted in terms of the
normalised distribution p?(.) = p(.)/ ?X p(x)dx.
Directly optimising or sampling from p is unfea-
sible; however, it is possible to define an (unnor-
malized) distribution q of lower complexity than
p, which upper-bounds p everywhere (ie. p(x) ?
q(x), ?x ? X), and from which it is feasible to
optimise or sample directly.
Sampling is performed through rejection sam-
pling: first a sample x is drawn from q, and then x
is accepted or rejected with probability given by the
ratio r = p(x)/q(x), which is less than 1 by con-
struction. Accepted x?s can be shown to produce
an exact sample from p (Robert and Casella, 2004).
When the sample x from q is rejected, it is used as
a basis for ?refining? q into a slightly more com-
plex q?, where p ? q? ? q is still an upper-bound to
p. This ?adaptive rejection sampling? technique in-
crementally improves the rate of acceptance, and is
pursued until some rate above a given threshold is
obtained, at which point one stops refining and uses
the current proposal to obtain further exact samples
from p.
In the case of optimisation, one finds the maxi-
mum x relative to q, and again computes the ratio
r = p(x)/q(x). If this ratio equals 1, then it is
easy to show that x is the actual maximum from
p.1 Otherwise we refine the proposal in a similar
way to the sampling case, continuing until we find
a ratio equal to 1 (or very close to 1 if we are will-
ing to accept an approximation to the maximum).
For finite spaces X , this optimisation technique is
argued to be a generalisation of A?.
An application of the OS? technique to sam-
pling/optimisation with High-Order HMM?s is de-
scribed in Carter et al (2012) and provides back-
ground for this paper. In that work, while the high-
order HMM corresponds to an intractable goal dis-
tribution, it can be upper-bounded by a sequence
of tractable distributions for which optimisers and
samplers can be obtained through standard dy-
namic programming techniques.
2.2 Hierarchical Translation
An abstract formulation of the decoding process
for hierarchical translation models such as that of
Chiang (2007) can be expressed as a sequence of
three steps. In a first step, a translation model
G, represented as a weighted synchronous context-
free grammar (SCFG) (Chiang, 2005), is applied to
(in other words, intersected with) the source sen-
tence f to produce a weighted context-free gram-
mar G(f) over the target language.2 In a second
step, G(f) is intersected with a weighted finite-
state automaton A representing the target language
model, resulting in a weighted context-free gram-
mar G?(f) = G(f) ? A. In a final step, a dynamic
programming procedure (see ?2.4) is applied to
find the maximum derivation x in G?(f), and the
sequence of leaves of yield(x) is the result transla-
tion.
While this formulation gives the general princi-
ple, already mentioned in Chiang (2007), most im-
plementations do not exactly follow these steps or
use this terminology. In practice, the closest ap-
proach to this abstract formulation is that of Dyer
(2010) and the related system cdec (Dyer et al,
2010); we follow a similar approach here.
1This is because if x? was such that p(x?) > p(x), then
q(x?) ? p(x?) > p(x) = q(x), and hence x would not be a
maximum for q, a contradiction.
2G(f) is thus a compact representation of a forest over
target sequences, and is equivalent to a hypergraph, using dif-
ferent terminology.
473
Whatever the actual implementation chosen, all
approaches face a common problem: the complex-
ity of the intersection G?(f) = G(f)?A increases
rapidly with the order of the language model, and
can become unwieldy for moderate-length input
sentences even with a bigram model. In order to
address this problem, most implementations em-
ploy variants of a technique called cube-pruning
(Chiang, 2007; Huang and Chiang, 2007), where
the cells constructed during the intersection pro-
cess retain only a k-best list of promising candi-
dates. This is an approximation technique, related
to beam-search, which performs well in practice,
but is not guaranteed to find the actual optimum.
In the approach presented here ? described in
detail in ?3 ? we do not prune the search space.
While we do construct the full initial grammar
G(f), we proceed by incrementally intersecting
it with simple automata associated with upper-
bounds ofA, for which the intersection is tractable.
2.3 Earley Intersection
In their classical paper Bar-Hillel et al (1961)
showed that the intersection of a CFG with a FSA is
a CFG, and Billot and Lang (1989) were possibly
the first to notice the connection of this construct
with chart-parsing. In general, parsing with a CFG
can be seen as a special case of intersection, with
the input sequence represented as a ?flat? (linear
chain) automaton, and this insight allows to gener-
alise various parsing algorithms to corresponding
intersection algorithms. One such algorithm, for
weighted context-free grammars and automata, in-
spired by the CKY parsing algorithm, is presented
in Nederhof and Satta (2008). The algorithm that
we are using is different; it is inspired by Earley
parsing, and was introduced in chapter 2 of Dyer
(2010). The advantage of Dyer?s ?Earley Intersec-
tion? algorithm is that it combines top-down pre-
dictions with bottom-up completions. The algo-
rithm thus avoids constructing many non-terminals
that may be justified from the bottom-up perspec-
tive, but can never be ?requested? by a top-down
derivation, and would need to be pruned in a sec-
ond pass. Our early experiments showed an impor-
tant gain in intermediary storage and in overall time
by using this Earley-based technique as opposed to
a CKY-based technique.
We do not describe the Earley Intersection algo-
rithm in detail here, but refer to Dyer (2010), which
we follow closely.
2.4 Optimisation and Sampling from a
WCFG
Optimisation in a weighted CFG (WCFG)3, that
is, finding the maximum derivation, is well stud-
ied and involves a dynamic programming proce-
dure that assigns in turn to each nonterminal, ac-
cording to a bottom-up traversal regime, a max-
imum derivation along with its weight, up to the
point where a maximum derivation is found for the
initial nonterminal in the grammar. This can be
seen as working in the max-times semiring, where
the weight of a derivation is obtained through the
product of the weights of its sub-derivations, and
where the weight associated with a nonterminal is
obtained by maximising over the different deriva-
tions rooted in that nonterminal.
The case of sampling can be handled in a very
similar way, by working in the sum-times instead
of the max-times semiring. Here, instead of max-
imising over the weights of the competing deriva-
tions rooted in the same nonterminal, one sums
over these weights. By proceeding in the same
bottom-up way, one ends with an accumulation of
all the weights on the initial nonterminal (this can
also be seen as the partition function associated
with the grammar). An efficient exact sampler is
then obtained by starting at the root nonterminal,
randomly selecting an expansion proportionally to
the weight of this expansion, and iterating in a top-
down way. This process is described in more detail
in section 4 of Johnson et al (2007), for instance.
3 Approach
The complexity of building the full intersection
G(f) ? A, when A represents a language model
of order n, is related to the fact that the number of
states of A grows exponentially with n, and that
each nonterminal N in G(f) tends to generate in
the grammar G?(f) many indexed nonterminals of
the form (i,N, j), where i, j are states of A and
the nonterminal (i,N, j) can be interpreted as an
N connecting an i state to a j state.
In our approach, instead of explicitly construct-
ing the full intersection G(f) ? A, which, using
the notation of ?2.1, is identified with the unnor-
malised goal distribution p(x), we incrementally
produce a sequence of ?proposal? grammars q(t),
which all upper-bound p, where q(0) = G(f) ?
A(0), ..., q(t+1) = q(t) ? A(t), etc. Here A(0) is
3Here the CFG is assumed to be acyclic, which is typically
the case in translation applications.
474
an optimistic, low complexity, ?unigram? version
of the automaton A, and each increment A(t) is a
small automaton that refines q(t) relative to some
specific k-gram context (i.e., sequence of k words)
not yet made explicit in the previous increments,
where k takes some value between 1 and n. This
process produces a sequence of grammars q(t) such
that q(0)(.) ? q(1)(.) ? q(2)(.) ? ... ? p(.).
In the limit ?Mt=0A(t) = A for some largeM , so
that we are in principle able to reconstruct the full
intersection p(.) = q(M) = G(f)?A(0)?...?A(M)
in finite time. In practice our actual process stops
much earlier: in optimisation, when the value of
the maximum derivation x?t relative to q(t) becomes
equal to its value according to the full language
model, in sampling when the acceptance rate of
samples from q(t) exceeds a certain threshold. The
process is detailed in what follows.
3.1 OS? for Hierarchical Translation
Our application of OS? to hierarchical translation is
illustrated in Algorithm 1, with the two modes, op-
timisation and sampling, made explicit and shown
side-by-side to stress the parallelism.
On line 1, we initialise the time step to 0, and
for sampling we also initialise the current accep-
tance rate (AR) to 0. On line 2, we initialise the
initial proposal grammar q(0), where A(0) is de-
tailed in ?3.2. On line 3, we start a loop: in op-
timisation we stop when we have found an x that
is accepted, meaning that the maximum has been
found; in sampling, we stop when the estimated
acceptance rate (AR) of the current proposal q(t)
exceeds a certain threshold (e.g. 20%) ? this AR
can be roughly estimated by observing how many
of the last (say) one hundred samples from the pro-
posal have been accepted, and tends to reflect the
actual acceptance rate obtained by using q(t) with-
out further refinements. On line 4, in optimisation,
we compute the argmax x from the proposal, and in
sampling we draw a sample x from the proposal.4
On line 5, we compute the ratio r = p(x)/q(t)(x);
by construction q(t) is an optimistic version of p,
thus r ? 1.
On line 6, in optimisation we accept x if the
ratio is equal to 1, in which case we have found
the maximum, and in sampling we accept x with
probability r, which is a form of adaptive rejec-
tion sampling and guarantees that accepted sam-
4Following the OS? approach, taking an argmax is actually
assimilated to an extreme form of sampling, with an L? space
taking the place of an L1 space.
ples form exact samples from p; see (Dymetman et
al., 2012a).
If x was rejected (line 7), we then (lines 8, 9)
refine q(t) into a q(t+1) such that p(.) ? q(t+1)(.) ?
q(t)(.) everywhere. This is done by defining the
incremental automatonA(t+1) on the basis of x and
q(t), as will be detailed below, and by intersecting
this automaton with q(t)
Finally, on line 11, in optimisation we return the
x which has been accepted, namely the maximum
of p, and in sampling we return the list of already
accepted x?s, which form an exact sample from p,
along with the current q(t), which can be used as a
sampler to produce further exact samples with an
acceptance rate performance above the predefined
threshold.
3.2 Incremental refinements
Initial automatonA(0) This deterministic au-
tomaton is an ?optimistic? version ofA which only
records unigram information. A(0) has only one
state q0, which is both initial and final. For each
word a of the target language it has a transition
(q0, a, q0) whose weight is denoted by w1(a). This
weight is called the ?max-backoff unigram weight?
(Carter et al, 2012) and it is defined as:
w1(a) ? maxh plm(a|h),
where plm(a|h) is the conditional language model
probability of a relative to the history h, and where
the maximum is taken over all possible histories,
that is, over all possible sequence of target words
that might precede a.
Max-backoffs Following Carter et al (2012),
for any language model of finite order, the unigram
max-backoff weights w1(a) can be precomputed in
a ?Max-ARPA? table, an extension of the ARPA
format (Jurafsky and Martin, 2000) for the target
language model, which can be precomputed on the
basis of the standard ARPA table.
From the Max-ARPA table one can also directly
compute the following ?max-backoff weights?:
w2(a|a?1), w3(a|a?2 a?1), ..., which are defined
by:
w2(a|a?1) ? maxh plm(a|h, a?1)
w3(a|a?2 a?1) ? maxh plm(a|h, a?2 a?1)
...
where the maximum is taken over the part of
the history which is not explicitely indicated.
475
Algorithm 1 OS? for Hierarchical Translation: Optimisation (left) and Sampling (right).
1: t? 0
2: q(0) ? G(f) ?A(0)
3: while not an x has been accepted do
4: Find maximum x in q(t)
5: r ? p(x)/q(t)(x)
6: Accept-or-Reject x according to r
7: if Rejected(x) then
8: define A(t+1) based on x and q(t)
9: q(t+1) ? q(t) ?A(t+1)
10: t? t + 1
11: return x
1: t? 0, AR? 0
2: q(0) ? G(f) ?A(0)
3: while not AR > threshold do
4: Sample x ? q(t)
5: r ? p(x)/q(t)(x)
6: Accept-or-Reject x according to r
7: if Rejected(x) then
8: define A(t+1) based on x and q(t)
9: q(t+1) ? q(t) ?A(t+1)
10: t? t + 1
11: return already accepted x?s along with q(t)
Note that: (i) if the underlying language model
is, say, a trigram model, then w3(a|a?2 a?1)
is simply plm(a|a?2 a?1), and similarly for an
underlying model of order k in general, and
(ii) w2(a|a?1) = maxa?2 w3(a|a?2 a?1) and
w1(a) = maxa?1 w2(a|a?1).
Incremental automata A(t) The weight
assigned to any target sentence by A(0) is larger or
equal to its weight according to A. Therefore, the
initial grammar q(0) = G(f) ? A(0) is optimistic
relative to the actual grammar p = G(f) ? A: for
any derivation x in p, we have p(x) ? q(0)(x).
We can then apply the OS? technique with q(0).
In the case of optimisation, this means that
we find the maximum derivation x from q(0).
By construction, with y = yield(x), we have
A(0)(y) ? A(y). If the two values are equal, we
have found the maximum,5 otherwise there must
be a word yi in the sequence ym1 = y for which
plm(yi|yi?11 ) is strictly smaller than w1(yi). Let us
take among such words the one for which the ratio
? = w2(yi|yi?1)/w1(yi) ? 1 is the smallest, and
for convenience let us rename b = yi?1, a = yi.
We then define the (deterministic) automaton A(1)
as illustrated in the following figure:
b:1 a:? 
else:1 
b:1 else:1 
0 1 
Here the state 0 is both initial and final, and the
state 1 is final; all edges carry a (multiplicative)
weight equal to 1, except edge (1, a, 0), which car-
ries the weight ?. We use the abbreviation ?else?
to refer to any label other than bwhen starting from
0, and other than b or a when starting from 1.
5This case is very unlikely with A(0), but helps introduce
the general case.
It is easy to check that this automaton assigns to
any word sequence y a weight equal to ?k, where k
is the number of occurrences of b a in y. In particu-
lar, if y is such that yi?1 = b, yi = a, then the tran-
sition in (the deterministic automaton) A(0) ?A(1)
that consumes yi carries the weight ? w1(a), in
other words, the weight w2(a|b). Thus the new
proposal grammar q(1) = q(0) ? A(1) has now
?incorporated? knowledge of the bigram a-in-the-
context-b, at the cost of some increase in its com-
plexity.6
The general procedure for choosing A(t+1) fol-
lows the same pattern. We find the max deriva-
tion x in q(t) along with its yield y; if p(x) =
q(t)(x), we stop and output x; otherwise we find
some subsequence yi?m?1, yi?m, ..., yi such that
the knowledge of the n-gram yi?m, ..., yi has al-
ready been registered in q(t), but not that of the
n-gram yi?m?1, yi?m, ..., yi, and we define an
automaton A(t+1) which assign to a sequence a
weight ?k, where
? = wm+1(yi|yi?m?1, yi?m, ..., yi?1)wm(yi|yi?m, ..., yi?1)
,
and where k is the number of occurrences of
yi?m?1, yi?m, ..., yi in the sequence.7
We note that we have p ? q(t+1) ? q(t) ev-
erywhere, and also that the number of possible re-
finement operations is bounded, because at some
point we would have expanded all contexts to their
maximum order, at which point we would have re-
produced p(.) on the whole space X of possible
6Note that without further increasing q(1)?s complexity one
can incorporate knowledge about all bigrams sharing the pre-
fix b. This is because A(1) does not need additional states
to account for different continuations of the context b, all we
need is to update the weights of the transitions leaving state 1
appropriately. More generally, it is not more costly to account
for all n-grams prefixed by the same context of n ? 1 words
than it is to account for only one of them.
7Building A(t+1) is a variant of the standard construction
for a ?substring-searching? automaton (Cormen et al, 2001)
and produces an automaton with n states (the order of the n-
gram). This construction is omitted for the sake of space.
476
derivations exactly. However, we typically stop
much earlier than that, without expanding contexts
in the regions of X which are not promising even
on optimistic assessments based on limited con-
texts.
Following the OS? methodology, the situation
with sampling is completely parallel to that of op-
timisation, the only difference being that, instead
of finding the maximum derivation x from q(t)(.),
we draw a sample x from the distribution asso-
ciated with q(t)(.), then accept it with probabil-
ity given by the ratio r = p(x)/q(t)(x) ? 1. In
the case of a reject, we identify a subsequence
yi?m?1, yi?m, ..., yi in yield(x) as in the optimi-
sation case, and similarly refine q(t) into q(t+1) =
q(t) ? A(t+1). The acceptance rate gradually in-
creases because q(t) comes closer and closer to p.
We stop the process at a point where the current ac-
ceptance rate, estimated on the basis of, say, the last
one hundred trials, exceeds a predefined threshold,
perhaps 20%.
3.3 Illustration
In this section, we present a small running example
of our approach. Consider the lowercased German
source sentence: eine letzte beobachtung .
Table 1 shows the translation associated with the
optimum derivation from each proposal q(i). The
n-gram whose cost, if extended by one word to the
left, would be increased by the largest factor is un-
derlined. The extended context selected for refine-
ment is highlighted in bold.
i Rules Optimum
0 311 <s> one last observation . </s>
1 454 <s> one last observation . </s>
2 628 <s> one last observation . </s>
3 839 <s> one final observation . </s>
4 1212 <s> one final observation . </s>
...
12 3000 <s> a final observation . </s>
13 3128 <s> one final observation . </s>
Table 1: Optimisation steps showing the iteration
(i), the number of rules in the grammar and the
translation associated to the optimum derivation.
Consider the very first iteration (i = 0), at which
point only unigram costs have been incorporated.
The sequence <s> one last observation . </s>
represents the translation associated to the best
derivation x in q(0). We proceed by choosing from
it one sequence to be the base for a refinement that
will lower q(0) bringing it closer to p. Amongst all
possible one-word (to the left) extensions, extend-
ing the unigram ?one? to the bigram ?<s> one? is
the operation that lowers q(0)(x) the most. It might
be helpful to understand it as the bigram ?<s> one?
being associated to the largest LM gap observed
in x. Therefore the context ?<s>? is selected for
refinement, which means that an automaton A(1)
is designed to down-weight derivations compatible
with bigrams prefixed by ?<s>?. The proposal q(0)
is intersected with A(1) producing q(1). We pro-
ceed like this iteratively, always selecting a con-
text not yet accounted for until q(i)(x) = p(x) for
the best derivation (13th iteration in our example),
when the true optimum is found with a certificate
of optimality.
Q Q Q Q Q Q Q Q Q Q Q Q Q Q
0 2 4 6 8 10 12
?
2
?
1
0
1
2
3
Iteration (i)
Scor
e (Q, 
P, B) ;
 Delta
 (C, M
) ; #st
ates (
R)
P P P
P P P P P P P P P P
PB B B B B B B B B B B B B B
C C C C C C C C C C C C C C
M M M M M M M M M M M M M M
R
R R R R
R
R
R R
R R
R
R
R
QPBCMR
QPBestCurrent gapMinimum gapRefinement
Figure 1: Certificate of optimality.
Figure 1 displays the progression of Q (score of
the best derivation) and P (that derivation?s true
score). As guaranteed by construction, Q is always
above P . B represents the score of the best deriva-
tion so far according to the true scoring function,
that is, B is a lower-bound on the true optimum8.
The optimal solution is achieved when P = Q.
Curve B in Figure 1 shows that the best scoring
solution was found quite early in the search (i = 3).
However, optimality could only be proven 10 itera-
tions later. Another way of stating the convergence
criterion Q = P is observing a zero gap (in the log
domain) between Q and P (see curve C ? current
gap), or a zero gap between Q and B (see curve M
? minimum gap). Observe how M drops quickly
from 1 to nearly 0, followed by a long tail whereM
8This observation allows for error-safe pruning in optimi-
sation: if x is a lower-bound on the true optimum, derivations
in q(i) that score lower than p(x) could be safely removed.
We have left that possibility for future work.
477
decreases much slower. Note that if we were will-
ing to accept an approximate solution, we could al-
ready stop the search if B remained unchanged for
a predetermined number of iterations or if changes
in B were smaller than some threshold, at the cost
of giving up on the optimality certificate.
Finally, curve R shows the number of states in
the automaton A(i) that refines the proposal at it-
eration i. Note how lower order n-grams (2-grams
in fact) are responsible for the largest drop in the
first iterations and higher-order n-grams (in fact 3-
grams) are refined later in the long tail.
Figure 2 illustrates the progression of the sam-
pler for the same German sentence. At each iter-
ation a batch of 500 samples is drawn from q(i).
The rejected samples in the batch are used to col-
lect statistics about overoptimistic n-grams and to
heuristically choose one context to be refined for
the next iteration, similar to the optimisation mode.
We start with a low acceptance rate which grows
up to 30% after 15 different contexts were incor-
porated. Note how the L1 norm of q (its partition
function) decreases after each refinement, that is,
q is gradually brought closer to p, resulting in the
increased number of exact samples and better ac-
ceptance rate.
Note that, starting from iteration one, all refine-
ments here correspond to 2-grams (i.e. one-word
contexts). This can be explained by the fact that,
in sampling, lower-order refinements are those that
mostly increase acceptance rate (rationale: high-
order n-grams are compatible with fewer grammar
rules).
Iteration (i)
1.0
1.5
2.0
0 5 10
l
l l l l l l l l l l l l lrefinement
0.1
0.2
0.3
l l
l l l l
l l l l l l l
laccrate
0
100
0
l l l l l
l l l
l l l
l l l
exact
9
10 l
l l l l l l l l l l l l l
L1
Figure 2: L1 norm of q, the number of exact sam-
ples drawn, the acceptance rate and the refinement
type at each iteration.
4 Experiments
We used the Moses toolkit (Koehn et al, 2007)
to extract a SCFG following Chiang (2005) from
the 6th version of the Europarl collection (Koehn,
2005) (German-English portion). We trained lan-
guage models using lmplz (Heafield et al, 2013)
and interpolated the models trained on the En-
glish monolingual data made available by the
WMT (Callison-Burch et al, 2012) (i.e. Eu-
roparl, newscommentaries, news-2012 and com-
moncrawl). Tuning was performed via MERT us-
ing newstest2010 as development set; test sen-
tences were extracted from newstest2011. Finally,
we restricted our SCFGs to having at most 10 tar-
get productions for a given source production.
Figure 3 shows some properties of the initial
grammar G(f) as a function of the input sentence
length (the quantities are averages over 20 sen-
tences for each class of input length). The number
of unigrams grows linearly with the input length,
while the number of unique bigrams compatible
with strings generated by G(f) appears to grow
quadratically9 and the size of the grammar in num-
ber of rules appears to be cubic ? a consequence
of having up to two nonterminals on the right-hand
side of a rule.
Figure 4 shows the number of refinement oper-
ations until convergence in optimisation and sam-
pling, as well as the total duration, as a function of
the input length.10 The plots will be discussed in
detail below.
4.1 Optimisation
In optimisation (Figures 4a and 4b), the number of
refinements up to convergence appears to be lin-
ear with the input length, while the total duration
grows much quicker. These findings are further
discussed in what follows.
Table 2 shows some important quantities regard-
ing optimisation with OS? using a 4-gram LM. The
first column shows how many sentences we are
considering, the second column shows the sentence
length, the third column m is the average num-
ber of refinements up to convergence. Column |A|
refers to the refinement type, which is the number
of states in the automaton A, that is, the order of
9The number of unique bigrams is an estimate obtained by
combining the terminals at the boundary of nonterminals that
may be adjacent in a derivation.
10The current implementation faces timeouts depending on
the length of the input sentence and the order of the language
model, explaining why certain curves are interrupted earlier
than others in Figure 4.
478
2 4 6 8 10
50
100
150
Input length
unigr
ams
l
l
l l
l
l
l l
l
l
(a) Unigrams in G(f)
2 4 6 8 10
0
2000
4000
6000
Input length
bigra
ms
l l
l l
l
l
l
l
l
l
(b) Bigrams compatible with G(f)
2 4 6 8 10
0
1000
2000
3000
4000
5000
Input length
R0
l l l
l
l
l
l
l
l
l
(c) Number of rules in G(f)
Figure 3: Properties of the initial grammar as function of input length
S Length m |A| count |Rf ||R0|9 4 45.0 2 20.3 74.6 ? 53.9
3 19.2
4 5.4
10 5 62.3 2 21.9 145.4 ? 162.6
3 32.9
4 7.5
9 6 102.8 2 34.7 535.8 ? 480.0
3 54.9
4 13.2
Table 2: Optimisation with a 4-gram LM.
the n-grams being re-weighted (e.g. |A| = 2 when
refining bigrams sharing a one-word context). Col-
umn count refers to the average number of refine-
ments that are due to each refinement type. Finally,
the last column compares the number of rules in the
final proposal to that of the initial one.
The first positive result concerns how much con-
text OS? needs to take into account for finding the
optimum derivation. Table 2 (column m) shows
that OS? explores a very reduced space of n-gram
contexts up to convergence. To illustrate that, con-
sider the last row in Table 2 (sentences with 6
words). On average, convergence requires incorpo-
rating only about 103 contexts of variable order, of
which 55 are bigram (2-word) contexts (remember
that |A| = 3 when accounting for a 2-word con-
text). According to Figure 3b, in sentences with
6 words, about 2,000 bigrams are compatible with
strings generated by G(f). This means that only
2.75% of these bigrams (55 out of 2,000) need to
be explicitly accounted for, illustrating how waste-
ful a full intersection would be.
A problem, however, is that the time until con-
vergence grows quickly with the length of the input
(Figure 4b). This can be explained as follows. At
each iteration the grammar is refined to account for
n-grams sharing a context of (n ? 1) words. That
S Input m |A| count |Rf ||R0|10 5 1.0 2 1.0 1.9 ? 1.0
10 6 6.6 2 6.3 17.6 ? 13.6
3 0.3
10 7 14.5 2 12.9 93.8 ? 68.9
3 1.5
4 0.1
Table 3: Sampling with a 4-gram LM and reaching
a 5% acceptance rate.
operation typically results in a larger grammar:
most rules are preserved, some rules are deleted,
but more importantly, some rules are added to ac-
count for the portion of the current grammar that
involves the selected n-grams. Enlarging the gram-
mar at each iteration means that successive refine-
ments become incrementally slower.
The histogram of refinement types of Table 2
highlights how efficient OS? is w.r.t. the space of
n-grams it needs to explore before convergence.
The problem is clearly not the number of refine-
ments, but rather the relation between the growth
of the grammar and the successive intersections.
Controlling for this growth and optimising the in-
tersection as to partially reuse previously computed
charts may be the key for a more generally tractable
solution.
4.2 Sampling
Figure 4c shows that sampling is more economi-
cal than optimisation in that it explicitly incorpo-
rates even fewer contexts. Note how OS? con-
verges to acceptance rates from 1% to 10% in much
fewer iterations than are necessary to find an opti-
mum11. Although the convergence in sampling is
11Currently we use MERT to train the model?s weight vec-
tor ? which is normalised by its L1 norm in the Moses im-
plementation. While optimisation is not sensitive to the scale
of the weights, in sampling the scale determines how flat or
479
2 2 2 2
2 2 2 2 2 2
2 4 6 8 10
0
20
40
60
80
100
Input length
Refi
nem
ents
3 3
3
3
3
3
3
4
4
4
4
4
4
234 2?gram LM3?gram LM4?gram LM
(a) Optimisation: number of refinements.
2 2 2 2 2 2 2 2
2 2
2 4 6 8 10
0
500
0
150
00
250
00
Input length
Tim
e (s)
3 3 3 3
3 3
3
4 4 4 4
4
4
234 2?gram LM3?gram LM4?gram LM
(b) Optimisation: time for convergence.
a a a a a a a a a a a a a a
2 4 6 8 10 12 14
0
5
10
15
20
25
Input length
Refin
emen
ts
b b b b b b b b b
b b b
b b
c c c c c c c
c
c c
c c
1 1 1 1 1 1 1
1
1
2 2 2 2 2 2
2
2
2
3 3 3 3 3
3 3
3
3
4 4 4 4
4
4
4
5 5 5
5
5
5
X X X X
X
X
Y Y Y
Y
Y
Y
abc12345XY
LM2 1%LM2 5%LM2 10%LM3 1%LM3 2%LM3 3%LM3 5%LM3 10%LM4 5%LM4 10%
(c) Sampling: number of refinements.
a a a a a a a a a a a a a
a
2 4 6 8 10 12 14
02
000
6000
1000
0
1400
0
Input length
Time
 (s)
b b b b b b b b b b b
b
b
b
c c c c c c c c c c
c
c
1 1 1 1 1 1 1 1
1
2 2 2 2 2 2 2 2
2
3 3 3 3 3 3 3
3
3
4 4 4 4 4 4
4
5 5 5 5 5 5X X X X X XY Y Y Y Y
Y
abc12345XY
LM2 1%LM2 5%LM2 10%LM3 1%LM3 2%LM3 3%LM3 5%LM3 10%LM4 5%LM4 10%
(d) Sampling: time for convergence.
Figure 4: Convergence for different LM order as function of the input length in optimisation (top) and
sampling (bottom). We show the number of refinements up to convergence on the left, and the convergence
time on the right. In optimisation we stop when the true optimum is found. In sampling we stop at different
acceptance rate levels: (a, b and c) use a 2-gram LM to reach 1, 5 and 10% AR; (1-4) use a 3-gram LM to
reach 2, 3, 5 and 10% AR; and (X, Y) use a 4-gram LM to reach 5 and 10% AR.
faster than in optimisation, the total duration is still
an issue (Figure 4b).
Table 3 shows the same quantities as Table 2, but
now for sampling. It is worth highlighting that even
though we are using an upper-bound over a 4-gram
LM (and aiming at a 5% acceptance rate), very few
contexts are selected for refinement, most of them
lower-order ones (one-word contexts ? rows with
|A| = 2).
Observe that an improved acceptance rate al-
ways leads to faster acquisition of exact samples
after we stop refining our proxy distribution. How-
ever, Figure 4d shows for example that moving
from 5% to 10% acceptance rate using a 4-gram
LM (curves X and Y) is time-consuming. Thus
there is a trade-off between how much time one
spends improving the acceptance rate and how
many exact samples one intends do draw. Figure
5 shows the average time to draw batches between
peaked the distribution is. Arun et al (2010) experiment with
scaling MERT-trained weights as to maximise BLEU on held-
out data, as well as with MBR training. A more adequate
training algorithm along similar lines is reserved for future
work.
1 1 1 1
1
1
1
1e+00 1e+02 1e+04 1e+06
200
500
1000
2000
5000
1000
0
Samples
Time
 (s)
2 2 2 2 2
2
212 5% AR10% AR
Figure 5: Average time to draw 1 to 1 million sam-
ples, for input sentences of length 6, using a 4-gram
LM at 5% (curve 1) and 10% (curve 2) acceptance
rate (including the time to produce the sampler).
one and one million samples from two exact sam-
plers that were refined up to 5% and 10% accep-
tance rate respectively. The sampler at 5% AR
(which is faster to obtain) turns out to be more effi-
cient if we aim at producing less than 10K samples.
Finally, note that samples are independently
480
drawn from the final proposal, making the ap-
proach an appealing candidate to parallelism in or-
der to increase the effective acceptance rate.
5 Related Work
Rush and Collins (2011) do not consider sampling,
but they address exact decoding for hierarchical
translation. They use a Dual Decomposition ap-
proach (a special case of Lagrangian Relaxation),
where the target CFG (hypergraph in their termi-
nology) component and the target language model
component ?trade-off? their weights so as to ensure
agreement on what each component believes to be
the maximum. In many cases, this technique is
able to detect the actual true maximum derivation.
When this is not the case, they use a finite-state-
based intersection mechanism to ?tighten? the first
component so that some constraints not satisfied by
the current solution are enforced, and iterate until
the true maximum is found or a time-out is met,
which results in a high proportion of finding the
true maximum.
Arun et al (2009, 2010) address the question
of sampling in a standard phrase-based transla-
tion model (Koehn et al, 2003). Contrarily to our
use of rejection sampling (a Monte-Carlo method),
they use a Gibbs sampler (a Markov-Chain Monte-
Carlo (MCMC) method). Samples are obtained
by iteratively re-sampling groups of well-designed
variables in such a way that (i) the sampler does not
tend to be trapped locally by high correlations be-
tween conditioning and conditioned variables, and
(ii) the combinatorial space of possibilities for the
next step is small enough so that conditional prob-
abilities can be computed explicitly. By contrast to
our exact approach, the samples obtained by Gibbs
sampling are not independent, but form a Markov
chain that only converges to the target distribution
in the limit, with convergence properties difficult
to assess. Also by contrast to us, these papers do
not address the question of finding the maximum
derivation directly, but only through finding a max-
imum among the derivations sampled so far, which
in principle can be quite different.
Blunsom and Osborne (2008) address proba-
bilistic inference, this time, as we do, in the context
of hierarchical translation, where sampling is used
both for the purposes of decoding and training the
model. When decoding in the presence of a lan-
guage model, an approximate sampling procedure
is performed in two stages. First, cube-pruning is
employed to construct a WCFG which generates
a subset of all the possible derivations that would
correspond to a full intersection with the target lan-
guage model. In a second step this grammar is
sampled through the same dynamic programming
procedure that we have described in ?2.4. By con-
trast to our approach, the paper does not attempt
to perform exact inference. However it does not
only address the question of decoding, but also that
of training the model, which requires, in addition
to sampling, an estimate of the model?s partition
function. In common with Arun et al (2010), the
authors stress the fact that a sampler of derivations
is also a sampler of translations as strings, while a
maximiser over derivations cannot be used to find
the maximum translation string.
6 Conclusions
The approach we have presented is, to our knowl-
edge, the first one to address the problem of ex-
act sampling for hierarchical translation and to do
that in a framework that also handles exact opti-
misation. Our experiments show that only a frac-
tion of the language model n-grams need to be in-
corporated in the target grammar in order to per-
form exact inference in this approach. However,
in the current implementation, we experience time-
outs for sentences of even moderate length. We are
working on improving this situation along three di-
mensions: (i) our implementation of the Earley In-
tersection rebuilds a grammar from scratch at each
intersection, while it could capitalise on the charts
built during the previous steps; (ii) the unigram-
level max-backoffs are not as tight as they could
be if one took into account more precisely the set
of contexts in which each word can appear rela-
tive to the grammar; (iii) most importantly, while
our refinements are ?local? in the sense of address-
ing one n-gram context at a time, they still affect
a large portion of the rules in the current grammar,
even rules that have very low probability of being
ever sampled by this grammar; by preventing re-
finement of such rules during the intersection pro-
cess, we may be able to make the intersection more
local and to produce much smaller grammars, with-
out losing the exactness properties of the approach.
Acknowledgements
The first author wishes to thank the PASCAL-2
Visit to Industry programme for partially funding
his visit to Xerox Research Centre Europe last Fall,
which initiated this collaboration.
481
References
Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blun-
som, Adam Lopez, and Philipp Koehn. 2009. Monte
carlo inference and maximization for phrase-based
translation. In Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learning,
CoNLL ?09, pages 102?110, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Abhishek Arun, Barry Haddow, Philipp Koehn, Adam
Lopez, Chris Dyer, and Phil Blunsom. 2010. Monte
carlo techniques for phrase-based translation. Ma-
chine Translation, 24(2):103?121, June.
Yehoshua Bar-Hillel, Micha A. Perles, and Eli Shamir.
1961. On formal properties of simple phrase struc-
ture grammars. Zeitschrift fu?r Phonetik, Sprachwis-
senschaft und Kommunikationsforschung, (14):143?
172.
Sylvie Billot and Bernard Lang. 1989. The structure
of shared forests in ambiguous parsing. In Proceed-
ings of the 27th Annual Meeting of the Association
for Computational Linguistics, pages 143?151, Van-
couver, British Columbia, Canada, June. Association
for Computational Linguistics.
Phil Blunsom and Miles Osborne. 2008. Probabilis-
tic inference for machine translation. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP ?08, pages 215?
223, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical machine
translation. In Proceedings of the Seventh Work-
shop on Statistical Machine Translation, pages 10?
51, Montre?al, Canada, June. Association for Compu-
tational Linguistics.
Simon Carter, Marc Dymetman, and Guillaume
Bouchard. 2012. Exact Sampling and Decoding in
High-Order Hidden Markov Models. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 1125?1134, Jeju
Island, Korea, July. Association for Computational
Linguistics.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, ACL ?05, pages 263?
270, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
David Chiang. 2007. Hierarchical Phrase-Based Trans-
lation. Computational Linguistics, 33:201?228.
Thomas H. Cormen, Clifford Stein, Ronald L. Rivest,
and Charles E. Leiserson. 2001. Introduction to Al-
gorithms. McGraw-Hill Higher Education, 2nd edi-
tion.
Chris Dyer, Jonathan Weese, Hendra Setiawan, Adam
Lopez, Ferhan Ture, Vladimir Eidelman, Juri Gan-
itkevitch, Phil Blunsom, and Philip Resnik. 2010.
cdec: a decoder, alignment, and learning framework
for finite-state and context-free translation models.
In Proceedings of the ACL 2010 System Demonstra-
tions, ACLDemos ?10, pages 7?12, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Christopher Dyer. 2010. A Formal Model of Ambiguity
and its Applications in Machine Translation. Ph.D.
thesis, University of Maryland.
M. Dymetman, G. Bouchard, and S. Carter. 2012a. The
OS* Algorithm: a Joint Approach to Exact Optimiza-
tion and Sampling. ArXiv e-prints, July.
Marc Dymetman, Guillaume Bouchard, and Simon
Carter. 2012b. Optimization and sampling for nlp
from a unified viewpoint. In Proceedings of the
First International Workshop on Optimization Tech-
niques for Human Language Technology, pages 79?
94, Mumbai, India, December. The COLING 2012
Organizing Committee.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modified
Kneser-Ney language model estimation. In Proceed-
ings of the 51st Annual Meeting of the Association for
Computational Linguistics, Sofia, Bulgaria, August.
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
144?151, Prague, Czech Republic, June. Association
for Computational Linguistics.
Mark Johnson, Thomas Griffiths, and Sharon Goldwa-
ter. 2007. Bayesian inference for PCFGs via Markov
chain Monte Carlo. In Human Language Technolo-
gies 2007: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics; Proceedings of the Main Conference, pages
139?146, Rochester, New York, April. Association
for Computational Linguistics.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Natu-
ral Language Processing, Computational Linguistics
and Speech Recognition (Prentice Hall Series in Ar-
tificial Intelligence). Prentice Hall, 1 edition.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, NAACL ?03, pages 48?54, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
482
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 177?180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings of
Machine Translation Summit, pages 79?86.
Shankar Kumar and William Byrne. 2004. Mini-
mum Bayes Risk Decoding for Statistical Machine
Translation. In Joint Conference of Human Lan-
guage Technologies and the North American chap-
ter of the Association for Computational Linguistics
(HLT-NAACL 2004).
Mark-Jan Nederhof and Giorgio Satta. 2008. Proba-
bilistic parsing. In M. Dolores Jimnez-Lpez G. Bel-
Enguix and C. Martn-Vide, editors, New Develop-
ments in Formal Languages and Applications, Stud-
ies in Computational Intelligence, volume 113, pages
229?258. Springer.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics, volume 1 of ACL ?03, pages 160?
167, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Christian P. Robert and George Casella. 2004. Monte
Carlo Statistical Methods (Springer Texts in Statis-
tics). Springer-Verlag New York, Inc., Secaucus, NJ,
USA.
Walter Rudin. 1987. Real and Complex Analysis.
McGraw-Hill.
Alexander M. Rush and Michael Collins. 2011. Exact
decoding of syntactic translation models through la-
grangian relaxation. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Vol-
ume 1, HLT ?11, pages 72?82, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David A. Smith and Jason Eisner. 2006. Minimum
risk annealing for training log-linear models. In Pro-
ceedings of the COLING/ACL on Main conference
poster sessions, COLING-ACL ?06, pages 787?794,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and
Hideki Isozaki. 2007. Online large-margin train-
ing for statistical machine translation. In Proceed-
ings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 764?773, Prague, Czech Republic,
June. Association for Computational Linguistics.
483
