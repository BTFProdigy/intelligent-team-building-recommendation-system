On Statistical Parameter Setting 
Damir ?AVAR, Joshua HERRING, 
Toshikazu IKUTA, Paul RODRIGUES 
Linguistics Dept., Indiana University  
Bloomington, IN, 46405 
dcavar@indiana.edu 
Giancarlo SCHREMENTI 
Computer Science, Indiana University 
Bloomington, IN, 47405 
gischrem@indiana.edu 
 
Abstract 
We present a model and an experimental 
platform of a bootstrapping approach to 
statistical induction of natural language 
properties that is constraint based with voting 
components. The system is incremental and 
unsupervised. In the following discussion we 
focus on the components for morphological 
induction. We show that the much harder 
problem of incremental unsupervised 
morphological induction can outperform 
comparable all-at-once algorithms with 
respect to precision. We discuss how we use 
such systems to identify cues for induction in 
a cross-level architecture. 
1 Introduction 
In recent years there has been a growing amount 
of work focusing on the computational modeling 
of language processing and acquisition, implying a 
cognitive and theoretical relevance both of the 
models as such, as well as of the language 
properties extracted from raw linguistic data.1 In 
the computational linguistic literature several 
attempts to induce grammar or linguistic 
knowledge from such data have shown that at 
different levels a high amount of information can 
be extracted, even with no or minimal supervision. 
Different approaches tried to show how various 
puzzles of language induction could be solved. 
From this perspective, language acquisition is the 
process of segmentation of non-discrete acoustic 
input, mapping of segments to symbolic 
representations, mapping representations on 
higher-level representations such as phonology, 
morphology and syntax, and even induction of 
semantic properties. Due to space restrictions, we 
cannot discuss all these approaches in detail. We 
will focus on the close domain of morphology. 
Approaches to the induction of morphology as 
presented in e.g. Schone and Jurafsky (2001) or 
Goldsmith (2001) show that the morphological 
                                                     
1 See Batchelder (1998) for a discussion of these 
aspects. 
properties of a small subset of languages can be 
induced with high accuracy, most of the existing 
approaches are motivated by applied or 
engineering concerns, and thus make assumptions 
that are less cognitively plausible: a. Large corpora 
are processed all at once, though unsupervised 
incremental induction of grammars is rather the 
approach that would be relevant from a 
psycholinguistic perspective; b. Arbitrary decisions 
about selections of sets of elements are made, 
based on frequency or frequency profile rank,2 
though such decisions should rather be derived or 
avoided in general. 
However, the most important aspects missing in 
these approaches, however, are the link to different 
linguistic levels and the support of a general 
learning model that makes predictions about how 
knowledge is induced on different linguistic levels 
and what the dependencies between information at 
these levels are. Further, there is no study focusing 
on the type of supervision that might be necessary 
for the guidance of different algorithm types 
towards grammars that resemble theoretical and 
empirical facts about language acquisition, and 
processing and the final knowledge of language. 
While many theoretical models of language 
acquisition use innateness as a crutch to avoid 
outstanding difficulties, both on the general and 
abstract level of I-language as well as the more 
detailed level of E-language, (see, among others,  
Lightfoot (1999) and Fodor and Teller (2000), 
there is also significant research being done which 
shows that children take advantage of statistical 
regularities in the input for use in the language-
learning task (see Batchelder (1997) and related 
references within). 
In language acquisition theories the dominant 
view is that knowledge of one linguistic level is 
bootstrapped from knowledge of one, or even 
several different levels. Just to mention such 
approaches: Grimshaw (1981), and Pinker (1984) 
                                                     
2 Just to mention some of the arbitrary decisions 
made in various approaches, e.g. Mintz (1996) selects a 
small set of all words, the most frequent words, to 
induce word types via clustering ; Schone and Jurafsky 
(2001) select words with frequency higher than 5 to 
induce morphological segmentation. 
9
assume that semantic properties are used to 
bootstrap syntactic knowledge, and Mazuka (1998) 
suggested that prosodic properties of language 
establish a bias for specific syntactic properties, 
e.g. headedness or branching direction of 
constituents. However, these approaches are based 
on conceptual considerations and psycholinguistc 
empirical grounds, the formal models and 
computational experiments are missing. It is 
unclear how the induction processes across 
linguistic domains might work algorithmically, and 
the quantitative experiments on large scale data are 
missing. 
As for algorithmic approaches to cross-level 
induction, the best example of an initial attempt to 
exploit cues from one level to induce properties of 
another is presented in D?jean (1998), where 
morphological cues are identified for induction of 
syntactic structure. Along these lines, we will 
argue for a model of statistical cue-based learning, 
introducing a view on bootstrapping as proposed in 
Elghamry (2004), and Elghamry and ?avar (2004), 
that relies on identification of elementary cues in 
the language input and incremental induction and 
further cue identification across all linguistic 
levels. 
1.1 Cue-based learning 
Presupposing input driven learning, it has been 
shown in the literature that initial segmenations 
into words (or word-like units) is possible with 
unsupervised methods (e.g. Brent and Cartwright 
(1996)), that induction of morphology is possible 
(e.g. Goldsmith (2001), Schone and Jurafsky 
(2001)) and even the induction of syntactic 
structures (e.g. Van Zaanen (2001)). As mentioned 
earlier, the main drawback of these approaches is 
the lack of incrementality, certain arbitrary 
decisions about the properties of elements taken 
into account, and the lack of integration into a 
general model of bootstrapping across linguistic 
levels. 
As proposed in Elghamry (2004), cues are 
elementary language units that can be identified at 
each linguistic level, dependent or independent of 
prior induction processes. That is, intrinsic 
properties of elements like segments, syllables, 
morphemes, words, phrases etc. are the ones 
available for induction procedures. Intrinsic 
properties are for example the frequency of these 
units, their size, and the number of other units they 
are build of. Extrinsic properties are taken into 
account as well, where extrinsic stands for 
distributional properties, the context, relations to 
other units of the same type on one, as well as 
across linguistic levels. In this model, extrinsic and 
intrinsic properties of elementary language units 
are the cues that are used for grammar induction 
only. 
As shown in Elghamry (2004) and Elghamry and 
?avar (2004), there are efficient ways to identify a 
kernel set of such units in an unsupervised fashion 
without any arbitrary decision where to cut the set 
of elements and on the basis of what kind of 
features. They present an algorithm that selects the 
set of kernel cues on the lexical and syntactic level, 
as the smallest set of words that co-occurs with all 
other words. Using this set of words it is possible 
to cluster the lexical inventory into open and 
closed class words, as well as to identify the 
subclasses of nouns and verbs in the open class. 
The direction of the selectional preferences of the 
language is derived as an average of point-wise 
Mutual Information on each side of the identified 
cues and types, which is a self-supervision aspect 
that biases the search direction for a specific 
language. This resulting information is understood 
as derivation of secondary cues, which then can be 
used to induce selectional properties of verbs 
(frames), as shown in Elghamry (2004). 
The general claim thus is: 
? Cues can be identified in an unsupervised 
fashion in the input. 
? These cues can be used to induce properties of 
the target grammar. 
? These properties represent cues that can be 
used to induce further cues, and so on. 
The hypothesis is that this snowball effect can 
reduce the search space of the target grammar 
incrementally. The main research questions are 
now, to what extend do different algorithms 
provide cues for other linguistic levels and what 
kind of information do they require as supervision 
in the system, in order to gain the highest accuracy 
at each linguistic level, and how does the linguistic 
information of one level contribute to the 
information on another. 
In the following, the architectural considerations 
of such a computational model are discussed, 
resulting in an example implementation that is 
applied to morphology induction, where 
morphological properties are understood to 
represent cues for lexical clustering as well as 
syntactic structure, and vice versa, similar to the 
ideas formulated in D?jean (1998), among others. 
1.2 Incremental Induction Architecture 
The basic architectural principle we presuppose 
is incrementality, where incrementally utterances 
are processed. The basic language unit is an 
utterance, with clear prosodic breaks before and 
after. The induction algorithm consumes such 
utterances and breaks them into basic linguistic 
units, generating for each step hypotheses about 
10
the linguistic structure of each utterance, based on 
the grammar built so far and statistical properties 
of the single linguistic units. Here we presuppose a 
successful segmentation into words, i.e. feeding 
the system utterances with unambiguous word 
boundaries. We implemented the following 
pipeline architecture: 
 
The GEN module consumes input and generates 
hypotheses about its structural descriptions (SD). 
EVAL consumes a set of SDs and selects the set of 
best SDs to be added to the knowledge base. The 
knowledge base is a component that not only stores 
SDs but also organizes them into optimal 
representations, here morphology grammars. 
All three modules are modular, containing a set 
of algorithms that are organized in a specific 
fashion. Our intention is to provide a general 
platform that can serve for the evaluation and 
comparison of different approaches at every level 
of the induction process. Thus, the system is 
designed to be more general, applicable to the 
problem of segmentation, as well as type and 
grammar induction. 
We assume for the input to consist of an 
alphabet: a non-empty set A of n symbols {s1, s2,... 
sn}. A word w is a non-empty list of symbols w = 
[s1,s2,... sn], with s?A. The corpus is a non-empty 
list C of words C = [w1,w2,... wn]. 
In the following, the individual modules for the 
morphology induction task are described in detail. 
1.2.1 GEN 
For the morphology task GEN is compiled from a 
set of basically two algorithms. One algorithm is a 
variant of Alignment Based Learning (ABL), as 
described in Van Zaanen (2001). 
The basic ideas in ABL go back to concepts of 
substitutability and/or complementarity, as 
discussed in Harris (1961). The concept of 
substitutability generally applies to central part of 
the induction procedure itself, i.e. substitutable 
elements (e.g. substrings, words, structures) are 
assumed to be of the same type (represented e.g. 
with the same symbol). 
The advantage of ABL for grammar induction is 
its constraining characteristics with respect to the 
set of hypotheses about potential structural 
properties of a given input. While a brute-force 
method would generate all possible structural 
representations for the input in a first order 
explosion and subsequently filter out irrelevant 
hypotheses, ABL reduces the set of possible SDs 
from the outset to the ones that are motivated by 
previous experience/input or a pre-existing 
grammar. 
Such constraining characteristics make ABL 
attractive from a cognitive point of view, both 
because hopefully the computational complexity is 
reduced on account of the smaller set of potential 
hypotheses, and also because learning of new 
items, rules, or structural properties is related to a 
general learning strategy and previous experience 
only. The approaches that are based on a brute-
force first order explosion of all possible 
hypotheses with subsequent filtering of relevant or 
irrelevant structures are both memory-intensive 
and require more computational effort. 
The algorithm is not supposed to make any 
assumptions about types of morphemes. There is 
no expectation, including use of notions like stem, 
prefix, or suffix. We assume only linear sequences. 
The properties of single morphemes, being stems 
or suffixes, should be a side effect of their 
statistical properties (including their frequency and 
co-occurrence patterns, as will be explained in the 
following), and their alignment in the corpus, or 
rather within words. 
There are no rules about language built-in, such 
as what a morpheme must contain or how frequent 
it should be. All of this knowledge is induced 
statistically. 
In the ABL Hypotheses Generation, a given 
word in the utterance is checked against 
morphemes in the grammar. If an existing 
morpheme LEX aligns with the input word INP, a 
hypothesis is generated suggesting a 
morphological boundary at the alignment 
positions: 
INP (speaks) + LEX (speak) = HYP [speak, s] 
Another design criterion for the algorithm is 
complete language independence. It should be able 
to identify morphological structures of Indo-
European type of languages, as well as 
agglutinative languages (e.g. Japanese and 
Turkish) and polysynthetic languages like some 
Bantu dialects or American Indian languages. In 
order to guarantee this behavior, we extended the 
Alignment Based hypothesis generation with a 
pattern identifier that extracts patterns of character 
sequences of the types: 
1. A ? B ? A 
2. A ? B ? A ? B 
3. A ? B ? A ? C 
This component is realized with cascaded 
regular expressions that are able to identify and 
11
return the substrings that correspond to the 
repeating sequences.3 
All possible alignments for the existing grammar 
at the current state, are collected in a hypothesis 
list and sent to the EVAL component, described in 
the following. A hypothesis is defined as a tuple: 
H = <w, f, g>, with w the input word, f its 
frequency in C, and g a list of substrings that 
represent a linear list of morphemes in w, g = [ 
m1, m2, ... mn ]. 
1.2.2 EVAL 
EVAL is a voting based algorithm that subsumes 
a set of independent algorithms that judge the list 
of SDs from the GEN component, using statistical 
and information theoretic criteria. The specific 
algorithms are grouped into memory and usability 
oriented constraints. 
Taken as a whole, the system assumes two (often 
competing) cognitive considerations. The first of 
these forms a class of what we term ?time-based? 
constraints on learning. These constraints are 
concerned with the processing time required of a 
system to make sense of items in an input stream, 
whereby ?time? is understood to mean the number 
of steps required to generate or parse SDs rather 
than the actual temporal duration of the process. 
To that end, they seek to minimize the amount of 
structure assigned to an utterance, which is to say 
they prefer to deal with as few rules as possible. 
The second of these cognitive considerations forms 
a class of ?memory-based? constraints. Here, we 
are talking about constraints that seek to minimize 
the amount of memory space required to store an 
utterance by maximizing the efficiency of the 
storage process. In the specific case of our model, 
which deals with morphological structure, this 
means that the memory-based constraints search 
the input string for regularities (in the form of 
repeated substrings) that then need only be stored 
once (as a pointer) rather than each time they are 
found. In the extreme case, the time-based 
constraints prefer storing the input ?as is?, without 
any processing at all, where the memory-based 
constraints prefer a rule for every character, as this 
would assign maximum structure to the input. 
Parsable information falls out of the tension 
between these two conflicting constraints, which 
can then be applied to organize the input into 
potential syntactic categories. These can then be 
                                                     
3 This addition might be understood to be a sort of 
supervision in the system. However, as shown in recent 
research on human cognitive abilities, and especially on 
the ability to identify patterns in the speech signal by 
very young infants (Marcus et al 1999) shows that we 
can assume such an ability to be part of the cognitive 
abilities, maybe not even language specific 
used to set the parameters for the internal adult 
parsing system. 
Each algorithm is weighted. In the current 
implementation these weights are set manually. In 
future studies we hope to use the weighting for 
self-supervision.4 Each algorithm assigns a 
numerical rank to each hypothesis multiplied with 
the corresponding weight, a real number between 0 
and 1. 
On the one hand, our main interest lies in the 
comparison of the different algorithms and a 
possible interaction or dependency between them. 
Also, we expect the different algorithms to be of 
varying importance for different types of 
languages. 
Mutual Information (MI) 
For the purpose of this experiment we use a 
variant of standard Mutual Information (MI), see 
e.g. MacKay (2003). Information theory tells us 
that the presence of a given morpheme restricts the 
possibilities of the occurrence of morphemes to the 
left and right, thus lowering the amount of bits 
needed to store its neighbors. Thus we should be 
able to calculate the amount of bits needed by a 
morpheme to predict its right and left neighbors 
respectively. To calculate this, we have designed a 
variant of mutual information that is concerned 
with a single direction of information. 
This is calculated in the following way. For 
every morpheme y that occurs to the right of x we 
sum the point-wise MI between x and y, but we 
relativize the point-wise MI by the probability that 
y follows x, given that x occurs. This then gives us 
the expectation of the amount of information that x 
tells us about which morpheme will be to its right. 
Note that p(<xy>) is the probability of the bigram 
<xy> occurring and is not equal to p(<yx>) which 
is the probability of the bigram <yx> occurring. 
We calculate the MI on the right side of x?G by: 
p(< xy >| x)lg p(< xy >)
p(x)p(y)y?{<xY >}
?  
and the MI on the left of x?G respectively by: 
p(< yx >| x)lg p(< yx >)
p(y) p(x)y?{<Yx>)
?  
One way we use this as a metric, is by summing 
up the left and right MI for each morpheme in a 
                                                     
4 One possible way to self-supervise the weights in 
this architecture is by taking into account the revisions 
subsequent components make when they optimize the 
grammar. If rules or hypotheses have to be removed 
from the grammar due to general optimization 
constraints on the grammars as such, the weight of the 
responsible algorithm can be lowered, decreasing its 
general value in the system on the long run. The 
relevant evaluations with this approach are not yet 
finished. 
12
hypothesis. We then look for the hypothesis that 
results in the maximal value of this sum. The 
tendency for this to favor hypotheses with many 
morphemes is countered by our criterion of 
favoring hypotheses that have fewer morphemes, 
discussed later. 
Another way to use the left and right MI is in 
judging the quality of morpheme boundaries. In a 
good boundary, the morpheme on the left side 
should have high right MI and the morpheme on 
the right should have high left MI. Unfortunately, 
MI is not reliable in the beginning because of the 
low frequency of morphemes. However, as the 
lexicon is extended during the induction procedure, 
reliable frequencies are bootstrapping this 
segmentation evaluation. 
Minimum Description Length (DL) 
The principle of Minimum Description Length 
(MDL), as used in recent work on grammar 
induction and unsupervised language acquisition, 
e.g. Goldsmith (2001) and De Marcken (1996), 
explains the grammar induction process as an 
iterative minimization procedure of the grammar 
size, where the smaller grammar corresponds to the 
best grammar for the given data/corpus. 
The description length metric, as we use it here, 
tells us how many bits of information would be 
required to store a word given a hypothesis of the 
morpheme boundaries, using the so far generated 
grammar. For each morpheme in the hypothesis 
that doesn't occur in the grammar we need to store 
the string representing the morpheme. For 
morphemes that do occur in our grammar we just 
need to store a pointer to that morphemes entry in 
the grammar. We use a simplified calculation, 
taken from Goldsmith (2001), of the cost of storing 
a string that takes the number of bits of 
information required to store a letter of the 
alphabet and multiply it by the length of the string. 
lg(len(alphabet))* len(morpheme) 
We have two different methods of calculating 
the cost of the pointer. The first assigns a variable 
the cost based on the frequency of the morpheme 
that it is pointing to. So first we calculate the 
frequency rank of the morpheme being pointed to, 
(e.g. the most frequent has rank 1, the second rank 
2, etc.). We then calculate: 
floor(lg( freq_ rank) ?1)  
to get a number of bits similar to the way Morse 
code assigns lengths to various letters. 
The second is simpler and only calculates the 
entropy of the grammar of morphemes and uses 
this as the cost of all pointers to the grammar. The 
entropy equation is as follows: 
p(x)lg
1
p(x)x?G
?  
The second equation doesn't give variable 
pointer lengths, but it is preferred since it doesn't 
carry the heavy computational burden of 
calculating the frequency rank. 
We calculate the description length for each GEN 
hypothesis only,5 by summing up the cost of each 
morpheme in the hypothesis. Those with low 
description lengths are favored. 
Relative Entropy (RE) 
We are using RE as a measure for the cost of 
adding a hypothesis to the existing grammar. We 
look for hypotheses that when added to the 
grammar will result in a low divergence from the 
original grammar. 
We calculate RE as a variant of the Kullback-
Leibler Divergence, see MacKay (2003). Given 
grammar G1, the grammar generated so far, and G2 
the grammar with the extension generated for the 
new input increment, P(X) is the probability mass 
function (pmf) for grammar G2, and Q(X) the pmf 
for grammar G1: 
P(x)lg
P(x)
Q(x)x?X
?  
Note that with every new iteration a new element 
can appear, that is not part of G1. Our variant of RE 
takes this into account by calculating the costs for 
such a new element x to be the point-wise entropy 
of this element in P(X), summing up over all new 
elements: 
P(x)lg
1
P(x)x?X
?  
These two sums then form the RE between the 
original grammar and the new grammar with the 
addition of the hypothesis. Hypotheses with low 
RE are favored. 
This metric behaves similarly to description 
length, that is discussed above, in that both are 
calculating the distance between our original 
grammar and the grammar with the inclusion of the 
new hypothesis. The primary difference is RE also 
takes into account how the pmf differs in the two 
grammars and that our variation punishes new 
morphemes based upon their frequency relative to 
the frequency of other morphemes. Our 
implementation of MDL does not consider 
frequency in this way, which is why we are 
including RE as an independent metric. 
Further Metrics 
In addition to the mentioned metric, we take into 
account the following criteria: a. Frequency of 
                                                     
5 We do not calculate the sizes of the grammars with 
and without the given hypothesis, just the amount each 
given hypothesis would add to the grammar, favoring 
the least increase of total grammar size. 
13
morpheme boundaries; b. Number of morpheme 
boundaries; c. Length of morphemes. 
The frequency of morpheme boundaries is given 
by the number of hypotheses that contain this 
boundary. The basic intuition is that the higher this 
number is, i.e. the more alignments are found at a 
certain position within a word, the more likely this 
position represents a morpheme boundary. We 
favor hypotheses with high values for this 
criterion. 
The number of morpheme boundaries indicates 
how many morphemes the word was split into. To 
prevent the algorithm from degenerating into the 
state where each letter is identified as a morpheme, 
we favor hypotheses with low number of 
morpheme boundaries. 
The length of the morphemes is also taken into 
account. We favor hypotheses with long 
morphemes to prevent the same degenerate state as 
the above criterion. 
1.2.3 Linguistic Knowledge 
The acquired lexicon is stored in a hypothesis 
space which keeps track of the words from the 
input and the corresponding hypotheses. The 
hypothesis space is defined as a list of hypotheses: 
Hypotheses space: S = [ H1, H2, ... Hn] 
Further, each morpheme that occurred in the SDs 
of words in the hypothesis space is kept with its 
frequency information, as well as bigrams that 
consist of morpheme pairs in the SDs and their 
frequency.6 
Similar to the specification of signatures in 
Goldsmith (2001), we list every morpheme with 
the set of morphemes it co-occurs. Signatures are 
lists of morphemes. Grammar construction is 
performed by replacement of morphemes with a 
symbol, if they have equal signatures. 
The hypothesis space is virtually divided into 
two sections, long term and short term storage. 
Long term storage is not revised further, in the 
current version of the algorithm. The short term 
storage is cyclically cleaned up by eliminating the 
signatures with a low likelihood, given the long 
term storage. 
2 The experimental setting 
In the following we discuss the experimental 
setting. We used the Brown corpus,7 the child-
                                                     
6 Due to space restrictions we do not formalize this 
further. A complete documentation and the source code 
is available at: http://jones.ling.indiana.edu/~abugi/. 
7 The Brown Corpus of Standard American English, 
consisting of 1,156,329 words from American texts 
printed in 1961 organized into 59,503 utterances and 
compiled by W.N. Francis and H. Kucera at Brown 
University. 
oriented speech portion of the CHILDES Peter 
corpus,8 and Caesar?s ?De Bello Gallico? in Latin.9 
From the Brown corpus we used the files ck01 ? 
ck09, with an average number of 2000 words per 
chapter. The total number of words in these files is 
18071. The randomly selected portion of ?De Bello 
Gallico? contained 8300 words. The randomly 
selected portion of the Peter corpus contains 58057 
words. 
The system reads in each file and dumps log 
information during runtime that contains the 
information for online and offline evaluation, as 
described below in detail. 
The gold standard for evaluation is based on 
human segmentation of the words in the respective 
corpora. We create for every word a manual 
segmentation for the given corpora, used for online 
evaluation of the system for accuracy of hypothesis 
generation during runtime. Due to complicated 
cases, where linguist are undecided about the 
accurate morphological segmentation, a team of 5 
linguists was cooperating with this task. 
The offline evaluation is based on the grammar 
that is generated and dumped during runtime after 
each input file is processed. The grammar is 
manually annotated by a team of linguists, 
indicating for each construction whether it was 
segmented correctly and exhaustively. An 
additional evaluation criterion was to mark 
undecided cases, where even linguists do not 
agree. This information was however not used in 
the final evaluation. 
2.1 Evaluation 
We used two methods to evaluate the 
performance of the algorithm. The first analyzes 
the accuracy of the morphological rules produced 
by the algorithm after an increment of n words. 
The second looks at how accurately the algorithm 
parsed each word that it encountered as it 
progressed through the corpus.  
The morphological rule analysis looks at each 
grammar rule generated by the algorithm and 
judges it on the correctness of the rule and the 
resulting parse. A grammar rule consists of a stem 
and the suffixes and prefixes that can be attached 
to it, similar to the signatures used in Goldsmith 
(2001). The grammar rule was then marked as to 
whether it consisted of legitimate suffixes and 
prefixes for that stem, and also as to whether the 
                                                     
8 Documented in L. Bloom (1970) and available at 
http://xml.talkbank.org:8888/talkbank/file/CHILDES/E
ng-USA/Bloom70/Peter/. 
9 This was taken from the Gutenberg archive at: 
http://www.gutenberg.net/etext/10657. The Gutenberg 
header and footer were removed for the experimental 
run. 
14
stem of the rule was a true stem, as opposed to a 
stem plus another morpheme that wasn't identified 
by the algorithm. The number of rules that were 
correct in these two categories were then summed, 
and precision and recall figures were calculated for 
the trial. The trials described in the graph below 
were run on three increasingly large portions of the 
general fiction section of the Brown Corpus. The 
first trial was run on one randomly chosen chapter, 
the second trial on two chapters, and the third on 
three chapters. The graph shows the harmonic 
average (F-score) of precision and recall. 
 
The second analysis is conducted as the 
algorithm is running and examines each parse the 
system produces. The algorithm's parses are 
compared with the ?correct? morphological parse 
of the word using the following method to derive a 
numerical score for a particular parse. The first 
part of the score is the distance in characters 
between each morphological boundary in the two 
parses, with a score of one point for each character 
space. The second part is a penalty of two points 
for each morphological boundary that occurs in 
one parse and not the other. These scores were 
examined within a moving window of words that 
progressed through the corpus as the algorithm ran. 
The average scores of words in each such window 
were calculated as the window advanced. The 
purpose of this method was to allow the 
performance of the algorithm to be judged at a 
given point without prior performance in the 
corpus affecting the analysis of the current 
window. The following graph shows how the 
average performance of the windows of analyzed 
words as the algorithm progresses through five 
randomly chosen chapters of general fiction in the 
Brown Corpus amounting to around 10,000 words. 
The window size for the following graph was set to 
40 words. 
 
The evaluations on Latin were based on the 
initial 4000 words of ?De Bello Gallico? in a 
pretest. In the very initial phase we reached a 
precision of 99.5% and a recall of 13.2%. This is 
however the preliminary result for the initial phase 
only. We expect that for a larger corpus the recall 
will increase much higher, given the rich 
morphology of Latin, potentially with negative 
consequences for precision. 
The results on the Peter corpus are shown in the 
following table: 
After file precision recall 
01 .9957 .8326 
01-03 .9968 .8121 
01-05 .9972 .8019 
01-07 .9911 .7710 
01-09 .9912 .7666 
We notice a more or less stable precision value 
with decreasing recall, due to a higher number of 
words. The Peter corpus contains also many very 
specific transcriptions and tokens that are indeed 
unique, thus it is rather surprising to get such 
results at all. The following graphics shows the F-
score for the Peter corpus: 
 
3 Conclusion 
The evaluations on two related morphology 
systems show that with a restrictive setting of the 
parameters in the described algorithm, approx 99% 
precision can be reached, with a recall higher than 
60% for the portion of the Brown corpus, and even 
higher for the Peter corpus. 
We are able to identify phases in the generation 
of rules that turn out to be for English: a. initially 
inflectional morphology on verbs, with the plural 
?s? on nouns, and b. subsequently other types of 
morphemes. We believe that this phenomenon is 
purely driven by the frequency of these 
morphemes in the corpora. In the manually 
segmented portion of the Brown corpus we 
identified on the token level 11.3% inflectional 
morphemes, 6.4% derivational morphemes, and 
82.1% stems. In average there are twice as many 
inflectional morphemes in the corpus, than 
derivational. 
Given a very strict parameters, focusing on the 
description length of the grammar, our system 
would need long time till it would discover 
prefixes, not to mention infixes. By relaxing the 
weight of description length we can inhibit the 
15
generation and identification of prefixing rules, 
however, to the cost of precision. 
Given these results, the inflectional paradigms 
can be claimed to be extractable even with an 
incremental approach. As such, this means that 
central parts of the lexicon can be induced very 
early along the time line. 
The existing signatures for each morpheme can 
be used as simple clustering criteria.10 Clustering 
will separate dependent (affixes) from independent 
morphemes (stems). Their basic distinction is that 
affixes will usually have a long signature, i.e. 
many elements they co-occur with, as well as a 
high frequency, while for stems the opposite is 
true.11 Along these lines, morphemes with a similar 
signature can be replaced by symbols, expressing 
the same type information and compressing the 
grammar further. This type information, especially 
for rare morphemes is essential in subsequent 
induction of syntactic structure. Due to space 
limitations, we cannot discuss in detail subsequent 
steps in the cross-level induction procedures. 
Nevertheless, the model presented here provides an 
important pointer to the mechanics of how 
grammatical parameters might come to be set. 
Additionally, we provide a method by which to 
test the roles different statistical algorithms play in 
this process. By adjusting the weights of the 
contributions made by various constraints, we can 
approach an understanding of the optimal ordering 
of algorithms that play a role in the computational 
framework of language acquisition. 
This is but a first step to what we hope will 
eventually finish a platform for a detailed study of 
various induction algorithms and evaluation 
metrics. 
References  
E. O. Batchelder. 1997. Computational evidence for the 
use of frequency information in discovery of the 
infant?s first lexicon. PhD dissertation, CUNY. 
E. O. Batchelder. 1998. Can a computer really model 
cognition? A case study of six computational models 
of infant word discovery. In M. A. Gernsbacher and 
S. J. Derry, editors, Proceedings of the 20th Annual 
Conference of the Cognitive Science Society, pages 
120?125. Lawrence Erlbaum, University of 
Wisconsin-Madison. 
L. Bloom, L. Hood, and P. Lightbown. 1974. Imitation 
in language development: If, when and why. 
Cognitive Psychology, 6, 380?420. 
                                                     
10 Length of the signature and frequency of each 
morpheme are mapped on a feature vector. 
11 This way, similar to the clustering of words into 
open and closed class on the basis of feature vectors, as 
described in Elghamry and ?avar (2004), the 
morphemes can be separated into open and closed class. 
M.R. Brent and T.A. Cartwright. 1996. Distributional 
regularity and phonotactic constraints are useful for 
segmentation. Cognition 61: 93-125. 
H. D?jean. 1998. Concepts et alorithmes pour la 
d?couverte des structures formelles des langues. 
Doctoral dissertation, Universit? de Caen Basse 
Normandie. 
K. Elghamry. 2004. A generalized cue-based approach 
to the automatic acquisition of subcategorization 
frames. Doctoral dissertation, Indiana University. 
K. Elghamry and D. ?avar. 2004. Bootstrapping cues 
for cue-based bootstrapping. Mscr. Indiana 
University. 
J. Fodor and V. Teller. 2000. Decoding syntactic 
parameters: The superparser as oracle. Proceedings of 
the Twenty-Second Annual Conference of the 
Cognitive Science Society, 136-141. 
J. Goldsmith. 2001. Unsupervised learning of the 
morphology of a natural language. Computational 
Linguistics 27(2): 153-198. 
Z.S. Harris. 1961. Structural linguistics. University of 
Chicago Press. Chicago. 
J. Grimshaw. 1981. Form, function, and the language 
acquisition device. In C.L. Baker and J.J. McCarthy 
(eds.), The Logical Problem of Language Acquisition. 
Cambridge, MA: MIT Press. 
D.J.C. MacKay. 2003. Information Theory, Inference, 
and Learning Algorithms. Cambridge: Cambridge 
University Press. 
C.G. de Marcken. 1996. Unsupervised Language 
Acquisition. Phd dissertation, MIT. 
G.F. Marcus, S. Vijayan, S. Bandi Rao, and P.M. 
Vishton. 1999. Rule-learning in seven-month-old 
infants. Science 283:77-80. 
R. Mazuka. 1998. The Development of Language 
Processing Strategies: A cross-linguistic study 
between Japanese and English. Lawrence Erlbaum. 
T.H. Mintz. 1996. The roles of linguistic input and 
innate mechanisms in children's acquisition of 
grammatical categories. Unpublished doctoral 
dissertation, University of Rochester. 
S. Pinker. 1984. Language Learnability and Language 
Development, Harvard University Press, Cambridge, 
MA. 
S. Pinker. 1994. The language instinct. New York, NY: 
W. Morrow and Co. 
P. Schone and D. Jurafsky. 2001. Knowledge-Free 
Induction of Inflectional Morphologies. In 
Proceedings of NAACL-2001. Pittsburgh, PA, June 
2001. 
M.M. Van Zaanen and Pieter Adriaans. 2001. 
Comparing two unsupervised grammar induction 
systems: Alignment-based learning vs. EMILE. Tech. 
Rep. TR2001.05, University of Leeds. 
M.M. Van Zaanen. 2001. Bootstrapping Structure into 
Language: Alignment-Based Learning. Doctoral 
dissertation, The University of Leeds. 
16
Proceedings of the Third ACL Workshop on Innovative Use of NLP for Building Educational Applications, pages 1?9,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Developing Online ICALL Exercises for Russian
Markus Dickinson
Department of Linguistics
Indiana University
md7@indiana.edu
Joshua Herring
Department of Linguistics
Indiana University
jwherrin@indiana.edu
Abstract
We outline a new ICALL system for learners
of Russian, focusing on the processing needed
for basic morphological errors. By setting out
an appropriate design for a lexicon and distin-
guishing the types of morphological errors to
be detected, we establish a foundation for er-
ror detection across exercises.
1 Introduction and Motivation
Intelligent computer-aided language learning
(ICALL) systems are ideal for language pedagogy,
aiding learners in the development of awareness of
language forms and rules (see, e.g., Amaral and
Meurers, 2006, and references therein) by providing
additional practice outside the classroom to enable
focus on grammatical form. But such utility comes
at a price, and the development of an ICALL system
takes a great deal of effort. For this reason, there
are only a few ICALL systems in existence today,
focusing on a limited range of languages.
In fact, current systems in use have specifically
been designed for three languages: German (Heift
and Nicholson, 2001), Portuguese (Amaral and
Meurers, 2006, 2007), and Japanese (Nagata, 1995).
Although techniques for processing ill-formed input
have been developed for particular languages (see
Vandeventer Faltin, 2003, ch. 2), many of them
are not currently in use or have not been integrated
into real systems. Given the vast array of languages
which are taught to adult learners, there is a great
need to develop systems for new languages and for
new types of languages.
There is also a need for re-usability. While there
will always be a significant amount of overhead in
developing an ICALL system, the effort involved in
producing such a system can be reduced by reusing
system architecture and by adapting existing natural
language processing (NLP) tools. ICALL systems
to date have been developed largely independently
of each other (though, see Felshin, 1995), employ-
ing system architectures and hand-crafted NLP tools
specific to the languages they target. Given the dif-
ficulty involved in producing systems this way for
even a single language, multilingual systems remain
a distant dream. Rather than inefficiently ?reinvent-
ing the wheel? each time we develop a new sys-
tem, however, a sensible strategy is to adapt exist-
ing systems for use with other languages, evaluating
and optimizing the architecture as needed, and open-
ing the door to eventual shared-component, multi-
lingual systems. Furthermore, rather than hand-
crafting NLP tools specific to the target language
of individual systems, it makes sense to explore the
possibility of adapting existing tools to the target
language of the system under construction, devel-
oping resource-light technology that can greatly re-
duce the effort needed to build new ICALL systems.
In this light, it is important to determine where and
how reuse of technology is appropriate.
In this spirit, we are developing an ICALL sys-
tem for beginning learners of Russian based on the
TAGARELA system for Portuguese, reusing many
significant components. The first priority is to deter-
mine how well and how much of the technology in
TAGARELA can be adapted for efficient and accu-
rate use with Russian, which we outline in section 2.
1
Focusing on Russian requires the development
of techniques to parse ill-formed input for a
morphologically-rich language. Compared with
other languages, a greater bulk of the work in pro-
cessing Russian is in the morphological analysis. As
there are relatively few natural language process-
ing tools freely available for Russian (though, see
Sharoff et al, 2008), we are somewhat limited in our
selection of components.
In terms of shaping an underlying NLP system,
though, the first question to ask for processing
learner input is, what types of constructions need
to be accounted for? This can be answered by
considering the particular context of the activities.
We therefore also need to outline the types of ex-
ercises used in our system, as done in section 3,
since constraining the exercises appropriately (i.e.,
in pedagogically and computationally sound ways)
can guide processing. Based on this design, we
can outline the types of errors we expect to find
for morphologically-rich languages, as done in sec-
tion 4. Once these pieces are in place, we can detail
the type of processing system(s) that we need and
determine whether and how existing resources can
be reused, as discussed in section 5.
2 System architecture
Our system is based on the TAGARELA system for
learners of Portuguese (Amaral and Meurers, 2006,
2007), predominantly in its overall system architec-
ture. As a starting point, we retain its modularity, in
particular the separation of activities from analysis.
Each type of activity has its own directory, which
reflects the fact that each type of activity loads dif-
ferent kinds of external files (e.g., sound files for lis-
tening activities), and that each type of activity could
require different processing (Amaral, 2007).
In addition to the modular design, we also retain
much of the web processing code - including the
programming code for handling things like user lo-
gins, and the design of user databases, for keeping
track of learner information. In this way, we min-
imize the amount of online overhead in our system
and are able to focus almost immediately on the lin-
guistic processing.
In addition to these more ?superficial? aspects of
TAGARELA, we also carry over the idea of using
annotation-based processing (cf. Amaral and Meur-
ers, 2007). Before any error detection or diagnosis
is performed, the first step is to annotate the learner
input with the linguistic properties which can be au-
tomatically determined. From this annotation and
from information about, e.g., the activity, a sepa-
rate error diagnosis module can determine the most
likely error.
Unfortunately, the ?annotator? (or the analysis
model) cannot be carried over, as it is designed
specifically for Portuguese, which differs greatly
from Russian in terms of how it encodes relevant
syntactic and morphological information. With an
annotation-based framework, the focus for process-
ing Russian is to determine which information can
provide the linguistic properties relevant to detecting
and diagnosing ill-formed input and thus which NLP
tools will provide analyses (full or partial) which
have a bearing on detecting the errors of interest.
3 Exercise design
A perennial question for ICALL systems in general
is what types of errors are learners allowed to make?
This is crucially dependent upon the design of the
activities. We want the processing of our system
to be general, but we also take as a priority mak-
ing the system usable, and so any analysis done in
an annotation-based framework must be relevant for
what learners are asked to do.
The goal of our system is to cover a range of ex-
ercises for students enrolled in an eight-week ?sur-
vival? Russian course. These students start the
course knowing nothing about Russian and finish it
comfortable enough to travel to Russia. The exer-
cises must therefore support the basics of grammar,
but also be contextualized with situations that a stu-
dent might encounter. To aid in contextualization,
we plan to incorporate both audio and video, in or-
der to provide additional ?real-life? listening (and
observing) practice outside of the classroom.
The exercises we plan to design include: listen-
ing exercises, video-based narrative exercises, read-
ing practice, exercises centered around maps and lo-
cations, as well as more standard fill-in-the-blank
(FIB) exercises. These exercises allow for variabil-
ity in difficulty and in learner input.
From the processing point of view, each will have
2
its own hurdles, but all require some morphosyntac-
tic analysis of Russian. To constrain the input for
development and testing purposes, we are starting
with an FIB exercise covering verbal morphology.
Although this is not the ideal type of exercise for dis-
playing the full range of ICALL benefits and capa-
bilities, it is indispensible from a pedagogical point
of view (given the high importance of rapid recog-
nition of verbal forms in a morphologically rich lan-
guage like Russian) and allows for rapid develop-
ment, testing, and perfection of the crucial morpho-
logical analysis component, as it deals with compli-
cated morphological processing in a suitably con-
strained environment. The successes and pitfalls of
this implementation are unlikely to differ radically
for morphological processing in other types of ex-
ercises; the techniques developed for this exercise
thus form the basis of a reusable framework for the
project as a whole.
A simple example of a Russian verbal exercise is
in (1), where the verb needs to be past tense and
agree with third person singular masculine noun.
(1) ?????
Yesterday
??
he
__
__
(??????)
(to see)
?????.
a film
4 Taxonomy for morphological errors
When considering the integration of NLP tools for
morphological error detection, we need to consider
the nature of learner language. In this context, an
analyzer cannot simply reject unrecognized or un-
grammatical strings, as does a typical spell-checker,
for example, but must additionally recognize what
was intended and provide meaningful feedback on
that basis. Formulating an error taxonomy delin-
eates what information from learner input must be
present in the linguistic analysis.
Our taxonomy is given in figure 1. As can be seen
at a glance, the errors become more complex and
require more information about the complete syntax
as we progress in the taxonomy.
To begin with, we have inappropriate verb stems.
For closed-form exercises, the only way that a
properly-spelled verb stem can be deemed appropri-
ate or inappropriate is by comparing it to the verb
that the student was asked to use. Thus, errors of
type #1b are straightforward to detect and to pro-
vide feedback on; all that needs to be consulted is
1. Inappropriate verb stem
(a) Always inappropriate
(b) Inappropriate for this context
2. Inappropriate verb affix
(a) Always inappropriate
(b) Always inappropriate for verbs
(c) Inappropriate for this verb
3. Inappropriate combination of stem and affix
4. Well-formed word in inappropriate context
(a) Inappropriate agreement features
(b) Inappropriate verb form (tense, perfec-
tive/imperfective, etc.)
Figure 1: Error taxonomy for Russian verbal morphology
the activity model.1 Errors of type #1a (and #2a) are
essentially misspellings and will thus require spell-
checking technology, which we do not focus on in
this paper, although we discuss it briefly in sec-
tion 5.3.
Secondly, there are inappropriate verb affixes,
which are largely suffixes in Russian. Other than
misspellings (#2a), there are two ways that affixes
can be incorrect, as shown in example (2). In exam-
ple (2a), we have the root for ?begin? (pronounced
nachina) followed by an ending (ev) which is never
an appropriate ending for any Russian verb, al-
though it is a legitimate nominal suffix (#2b). The
other subtype of error (#2c) involves affixes which
are appropriate for different stems within the same
POS category. In example (2b), a third person sin-
gular verb ending was used (it), but it is appropriate
for a different conjugation class. The appropriate
form for ?he/she/it begins? is ????????.
(2) a. *??????-??
begin-??
b. *??????-??
begin-3s
The third type of error is where the stem and affix
1Note that if one were allowing free input, this error type
could be the most difficult, in that the semantics of the sentence
would have to be known to determine if a verb was appropriate.
3
may both be correct, but they were put together in-
appropriately. In a sense, these are a specific type
of misspelling. For example, the infinitive ????
(moch, ?to be able to?) can be realized with different
stems, depending upon the ending, i.e., ???-? (mogu
?I can?) ???-?? (mozhem ?we can?). Thus, we
might expect to see errors such as *???-? (mozhu),
where both the stem and the affix are appropriate?
and appropriate for this verb?but are not combined
in a legitimate fashion. The technology needed to
detect these types of errors is no more than what is
needed for error type #2, as we discuss in section 5.
The final type of error is the one which requires
the most attention in terms of NLP processing. This
is the situation when we have a well-formed word
appearing in an inappropriate context. In other
words, there is a mismatch between the morpho-
logical properties of the verb and the morphological
properties dictated by the context for that verb.
There are of course different ways in which a verb
might display incorrect morphological features. In
the first case (#4a), there are inappropriate agree-
ment features. Verbs in Russian agree with the prop-
erties of their subject, as shown in example (3).
Thus, as before, we need to know the morphologi-
cal properties of the verb, but now we need not just
the possible analyses, but the best analysis in this
context. Furthermore, we need to know what the
morphological properties of the subject noun are, to
be able to check whether they agree. Access to the
subject is something which can generally be deter-
mined by short context, especially in relatively short
sentences.
(3) a. ?
I
?????
think-1sg
b. ??
He
??????
think-3sg
c. *?
I
??????
think-3sg
In the second case (#4b), the verb could be in an
inappropriate form: the tense could be inappropri-
ate; the verbal form (gerund, infinitive, etc.) could
be inappropriate; the distinction between perfective
and imperfective verbs could be mistakenly realized;
and so forth. Generally speaking, this kind of con-
textual information comes from two sources: 1) The
activity model can tell us, for example, whether a
perfective (generally, a completed action) or an im-
perfective verb is required. 2) The surrounding sen-
tence context can tell us, for example, whether an
infinitive verb is governed by a verb selecting for an
infinitive. Thus, we need the same tools that we need
for agreement error detection.
By breaking it down into this taxonomy, we can
more clearly delineate when we need external tech-
nology in dealing with morphological variation. For
error types #1 through #3, we make no use of context
and only need information from an activity model
and a lexicon to tell us whether the word is valid.
For these error types, the processing can proceed in a
relatively straightforward fashion, provided that we
have a lexicon, as outlined in section 5. Note also
that our error taxonomy is meant to range over the
space of logically possible error types for learners
from any language background of any language?s
morphological system. In this way, it differs from
the more heuristic approaches of earlier systems
such as Athena (Murray, 1995), which used tax-
onomies tailored to the native languages of the sys-
tem?s users.
That leaves category #4. These errors are mor-
phological in nature, but the words are well-formed,
and the errors have to do with properties conditioned
by the surrounding context. These are the kind for
which we need external technology, and we sketch a
proposed method of analysis in section 5.4.
Finally, we might have considered adding a fifth
type of error, as in the following:
5. Well-formed word appropriate to the sentence,
used inappropriately
(a) Inappropriate position
(b) Inappropriate argument structure
However, these issues of argument structure and
of pragmatically-conditioned word order variation
do not result in morphological errors of the verb,
but rather clearly syntactic errors. We are currently
only interested in morphological errors, given that
in certain exercises, as in the present cases, syntac-
tic errors are not even possible. With an FIB de-
sign, even though we might still generate a complete
analysis of the sentence, we know which word has
4
the potential for error. Even though we are not cur-
rently concerned with these types of errors, we can
note that argument structure errors can likely be han-
dled through the activity model and through a simi-
lar analysis to what described is in section 5.4 since
both context-dependent morphological errors (e.g.,
agreement errors) and argument structure errors rely
on relations between the verb and its arguments.
5 Linguistic analysis
Given the discussion of the previous section, we are
now in a position to discuss how to perform mor-
phological analysis in a way which supports error
diagnosis.
5.1 The nature of the lexicon
In much syntactic theory, sentences are built from
feature-rich lexical items, and grammatical sen-
tences are those in which the features of com-
ponent items agree in well-defined ways. In
morphologically-rich languages like Russian, the
heavy lifting of feature expression is done by overt
marking of words in the form of affixes (mainly pre-
fixes and suffixes in the case of Russian). To be able
to analyze words with morphological errors, then,
we need at least partially successful morphological
analysis of the word under analysis (as well as the
words in the context).
The representation of words, therefore, must be
such that we can readily obtain accurate partial in-
formation from both well-formed and ill-formed in-
put. A relatively straightforward approach for anal-
ysis is to structure a lexicon such that we can build
up partial (and competing) analyses of a word as the
word is processed. As more of the word is (incre-
mentally) processed, these analyses can be updated.
But how is this to be done exactly?
In our system, we plan to meet these criteria by
using a fully-specified lexicon, implemented as a Fi-
nite State Automaton (FSA) and indexed by both
word edges. Russian morphological information is
almost exclusively at word edges?i.e., is encoded
in the prefixes and suffixes?and thus an analysis
can proceed by working inwards, one character at
a time, beginning at each end of an input item.2
2See Roark and Sproat (2007) for a general overview
of implementational strategies for finite-state morphological
By fully-specified, we mean that each possible
form of a word is stored as a separate entity (path).
This is not as wasteful of memory as it may sound.
Since the lexicon is an FSA, sections shared across
forms need be stored only once with diversion rep-
resented by different paths from the point where the
shared segment ends. In fact, representing the lex-
icon as an FSA ensures that this process efficiently
encodes the word possibilities. Using an FSA over
all stored items, regular affixes need to be stored
only once, and stems which require such affixes sim-
ply point to them (Clemenceau, 1997). This gives
the analyzer the added advantage that it retains ex-
plicit knowledge of state, making it easy to simul-
taneously entertain competing analyses of a given
input string (C?avar, 2008), as well as to return to
previous points in an analysis to resolve ambiguities
(cf., e.g., Beesley and Karttunen, 2003).
We also need to represent hypothesized mor-
pheme boundaries within a word, allowing us to seg-
ment the word into its likely component parts and
to analyze each part independently of the others.
Such segmentation is crucial for obtaining accurate
information from each morpheme, i.e., being able
to ignore an erroneous morpheme while identifying
an adjoining correct morpheme. Note also that be-
cause an FSA encodes competing hypotheses, mul-
tiple segmentations can be easily maintained.
Consider example (4), for instance, for which the
correct analysis is the first person singular form of
the verb think. This only becomes clear at the point
where segmentation has been marked. Up to that
point, the word is identical to some form of ??-
?? (duma), ?parliament? (alternatively, ?thought?).
Once the system has seen ????, it automatically en-
tertains the competing hypotheses that the learner in-
tends ?parliament,? or any one of many forms of ?to
think,? as these are all legal continuations of what
it has seen so far. Any transition to ? after ????
carries with it the analysis that there is a morpheme
boundary here.
(4) ????|?
think-1sg
Obviously this bears non-trivial resemblance to
spell-checking technology. The crucial difference
analysis.
5
comes in the fact that an ICALL morphological an-
alyzer must be prepared to do more than simply re-
ject strings not found in the lexicon and thus must
be augmented with additional, morphological infor-
mation. Transitions in the lexicon FSA will need to
encode more information than just the next charac-
ter in the input; they also need to be marked with
possible morphological analyses at points where it
is possible that a morpheme boundary begins.
Maintaining hypothesized paths through a lexicon
based on erroneous input must obviously be con-
strained in some way (to prevent all possible paths
from being simultaneously entertained), and thus we
first developed the error taxonomy above. Knowing
what kinds of errors are possible is crucial to keep-
ing the whole process workable.
5.2 FSAs for error detection
But why not use an off-the-shelf morphological an-
alyzer which returns all possible analyses, or a more
traditional paradigm-based lexicon? There are a
number of reasons we prefer exploring an FSA im-
plementation to many other approaches to lexical
storage for the task of supporting error detection and
diagnosis.
First, traditional mophological analyzers gener-
ally assume well-formed input. And, unless they
segment a word, they do not seem to be well-
suited to providing information relevant to context-
independent errors.
Secondly, we need to readily have access to al-
ternative analyses, even for a legitimate word. With
phonetically similar forms used as different affixes,
learners can accidentally produce correct forms, and
thus multiple analyses are crucial. For example, -?
can be either a first person singular marker for cer-
tain verb classes or an accusative marker for certain
noun classes. Suppose a learner attempts to make a
verb out of the noun ??? (dush), meaning ?shower?
and thus forms the word ????. It so happens that
this incorrect form is identical to an actual Russian
word: the accusative form of the noun ?soul.? A
more traditional morphological analysis will likely
only find the attested form. Keeping track of the
history from left-to-right records that the ?shower?
reading is possible; keeping track of the history from
right-to-left records that a verbal ending is possible.
Compactly representing such ambiguity?especially
when the ambiguity is not in the language itself
but in the learner?s impression of how the language
works?is thus key to identifying errors.
Finally, and perhaps most importantly, morpho-
logical analysis over a FSA lexicon allows for easy
implementation of activity-specific heuristics. In the
current example, for instance, an activity might pri-
oritize a ?shower? reading over a ?soul? one. Since
entertained hypotheses are all those which represent
legal continuations (or slight alterations of legal con-
tinuations) through the lexicon from a given state in
the FSA, it is easy to bias the analyzer to return cer-
tain analyses through the use of weighted paths. Al-
ternatively, paths that we have strong reason to be-
lieve will not be needed can be ?disconnected.? In
the verbal morphology exercise, for example, suffix
paths for non-verbs can safely be ignored.
The crucial point about error detection in ICALL
morphological analysis is that the system must be
able to speculate, in some broadly-defined sense, on
what learners might have meant by their input, rather
than simply evaluating the input as correct or incor-
rect based on its (non)occurrence in a lexicon. For
this reason, we prefer to have a system where at least
one component of the analyzer has 100% recall, i.e.,
returns a set of all plausible analyses, one of which
can reasonbly be expected to be correct. Since an an-
alyzer based on an FSA lexicon has full access to the
lexicon at all stages of analysis, it efficiently meets
this requirement, and it does this without anticipat-
ing specific errors or being tailored to a specific type
of learner (cf., e.g., Felshin, 1995).
5.3 Error detection
Having established that an FSA lexicon supports er-
ror detection, let us outline how it will work. Anal-
ysis is a process of attempting to form independent
paths through the lexicon - one operating ?forward?
and the other operating ?backward.? For grammati-
cal input, there is generally one unique path through
the lexicon that joins both ends of the word. Mor-
phological analysis is found by reading information
from the transitions along the chain (cf. Beesley and
Karttunen, 2003). For ungrammatical input, the an-
alyzer works by trying to build a connecting path
based on the information it has.
Consider the case of the two ungrammatical verbs
in (5).
6
(5) a. *??????-??
begin-??
b. *??????-??
begin-3s
In (5a) (error type #2b) the analysis proceeding
from the end of the word would fail to detect that
the word is intended to be a verb. But it would, at
the point of reaching the ? in ??, recognize that it
had found a legitimate nominal suffix. The process-
ing from the beginning of the word, however, would
recognize that it has seen some form of begin. We
thus have enough information to know what the ver-
bal stem is and that there is probably a morpheme
boundary after ??????-. These two hypotheses do
not match up to form a legitimate word (thereby de-
tecting an error), but they provide crucial partial in-
formation to tell us how the word was misformed.
Detecting the error in (5b) (type #2c) works sim-
ilarly, and the diagnosis will be even easier. Again,
analyses proceeding from each end of the word will
agree on the location of the morpheme boundary and
that the type of suffix used (third person singular) is
a type appropriate to verbs, just not for this conjuga-
tion class. Having a higher-level rule recognize that
all features match, merely the form is wrong, is eas-
ily achieved in a system with an explicit taxonomy
of expected error types coded in.
Errors of type #3 are handled in exactly the same
fashion: information about which stem or which af-
fix is used is readily available, even if there is no
complete path to form a whole word.
Spelling errors within a stem or an affix (error
types #1a and #2a) require additional technology in
order to find the intended analysis?which we only
sketch here?but it is clear that such spell-checking
should be done separately on each morpheme.3 In
the above examples, if the stem had been misspelled,
that should not change the analysis of the suffix.
Integrating spell-checking by calculating edit dis-
tances between a realized string and a morpheme in
the lexicon should be relatively straightforward, as
that technology is well-understood (see, e.g., Mit-
ton, 1996) and since we are already analyzing sub-
parts of words.
3Clearly, we will be able to determine whether a word is
correctly spelled or not; the additional technology is needed to
determine the candidate corrections.
Obviously, in many cases there will be lingering
ambiguity, either because there are multiple gram-
matical analyses in the lexicon for a given input
form, or because the learner has entered an ungram-
matical form, the intention behind which cannot en-
tirely be determined from the input string alone. It
is for such cases that the morphological analyzer
we propose is most useful. Instead of returning
the most likely path through the analyzer (e.g., the
GPARS system of Loritz, 1992), our system pro-
poses to follow all plausible paths through the lexi-
con simultaneously?including those that are the re-
sult of string edit ?repair? operations.4 In short, we
intend a system that entertains competing hypothe-
ses ?online? as it processes input words.5
This results in a set of analyses, providing
sentence-level syntactic and semantic analysis mod-
ules quick access to competing hypotheses, from
which the the analysis most suitable to the context
can be chosen, including those which are misspelled.
The importance of this kind of functionality is espe-
cially well demonstrated in Pijls et al (1987), which
points out that in some languages?Dutch, in this
case?minor, phonologically vacuous spelling dif-
ferences are syntactically conditioned, making spell
checking and syntactic analysis mutually dependent.
Such cases are rarer in Russian, but the functionality
remains useful due to the considerable interdepen-
dence of morphological and syntactic analysis.
5.4 Morphological analysis in context
For the purposes of the FIB exercise currently un-
der development, the finite-state morphological ana-
lyzer we are building will of course be sufficient, but
as exercises grow in complexity, it will be necessary
to use it in conjunction with other tools. It is worth
briefly sketching how the components of this inte-
grated system will work together to provide useful
error feedback to our learners.
If the learner has formed a legitimate word, the
task becomes one of determining whether or not it
4These include transitions to states on no input symbol (IN-
SERTION), transitions to states on a different symbol from the
next input symbol (SUBSTITUTION), and consumption of an in-
put symbol without transition to a new state (DELETION).
5It is worth noting here that GPARS was actually a sentence-
level system; it is for the word-level morphological analysis dis-
cussed here that we expect the most gain from our approach.
7
is appropriate to the context. The FSA analyzer
will provide a list of possible analyses (i.e., aug-
mented POS tags) for each input item (ranked, if
need be). We can explore using a third-party tag-
ger to narrow down this output list to analyses that
make sense in context. We are considering both the
Hidden Markov Model tagger TnT (Brants, 2000)
and the Decision Tree Tagger (Schmid, 1997), with
parameter files from Sharoff et al (2008). Both of
these taggers use local context, but, as they provide
potentially different types of information, the final
system may use both in parallel, weighing the out-
put of each to the degree which each proves useful
in trial runs to make its decision.
Since POS tagging does not capture every syntac-
tic property that we might need access to, we are not
sure how accurate error detection can be. Thus, to
supplement its contextual information, we intend to
use shallow syntactic processing methods, perhaps
based on a small set of constraint grammar rules
(cf, e.g., Bick, 2004). This shallow syntactic recog-
nizer can operate over the string of now-annotated
tags to resolve any remaining ambiguities and point
out any mismatches between the items (for exam-
ple, a noun-adjective pair where the gender does not
match), thereby more accurately determining the re-
lations between words.
6 Summary and Outlook
We have outlined a system for Russian ICALL ex-
ercises, the first of its kind for a Slavic language,
and we have specifically delineated the types of
errors to which need to be analyzed for such a
morphologically-rich language. In that process, we
have proposed a method for analyzing the morphol-
ogy of learner language and noted where external
NLP tools will be useful, making it clear how all
these tools can be optimized for learning environ-
ments where the priority is to obtain a correct anal-
ysis, over obtaining any analysis.
The initial challenge is in creating the FSA lex-
icon, given that no such resource exists. However,
unsupervised approaches to calculating the mor-
phology of a language exist, and these can be di-
rectly connected to FSAs (Goldsmith and Hu, 2004).
Thus, by using a tool such as Linguistica6 on a cor-
6http://linguistica.uchicago.edu/
pus such as the freely available subset of the Russian
Internet Corpus (Sharoff et al, 2008),7 we can semi-
automatically construct an FSA lexicon, pruning it
by hand.
Once the lexicon is constructed?for even a small
subset of the language covering a few exercises?the
crucial steps will be in performing error detection
and error diagnosis on top of the linguistic analysis.
In our case, linguistic analysis is provided by sep-
arate (levels of) modules operating in parallel, and
error detection is largely a function of either notic-
ing where these modules disagree, or in recognizing
cases where ambiguity remains after one has been
used to constrain the output of the other.
We have also tried to advance the case that this
and future ICALL systems do better to build on ex-
isting technologies, rather than building from the
bottom up for each new language. We hope that the
approach we are taking to morphological analysis
will prove to be just such a general, scalable system,
one applicable?with some tweaking and to various
levels?to morphologically-rich languages and iso-
lating languages alike.
Acknowledgments We would like to thank Det-
mar Meurers and Luiz Amaral for providing us with
the TAGARELA sourcecode, as well as for valuable
insights into the workings of ICALL systems; and to
thank Anna Feldman and Jirka Hana for advice on
Russian resources. We also thank two anonymous
reviewers for insightful comments that have influ-
enced the final version of this paper. This research
was supported by grant P116S070001 through the
U.S. Department of Education?s Fund for the Im-
provement of Postsecondary Education.
References
Amaral, Luiz (2007). Designing Intelligent Lan-
guage Tutoring Systems: integrating Natural Lan-
guage Processing technology into foreign lan-
guage teaching. Ph.D. thesis, The Ohio State Uni-
versity.
Amaral, Luiz and Detmar Meurers (2006).
Where does ICALL Fit into Foreign Lan-
guage Teaching? Talk given at CALICO
Conference. University of Hawaii, http:
7http://corpus.leeds.ac.uk/mocky/
8
//purl.org/net/icall/handouts/
calico06-amaral-meurers.pdf.
Amaral, Luiz and Detmar Meurers (2007).
Putting activity models in the driver?s seat:
Towards a demand-driven NLP architecture
for ICALL. Talk given at EUROCALL. Uni-
versity of Ulster, Coleraine Campus, http:
//purl.org/net/icall/handouts/
eurocall07-amaral-meurers.pdf.
Beesley, Kenneth R. and Lauri Karttunen (2003). Fi-
nite State Morphology. CSLI Publications.
Bick, Eckhard (2004). PaNoLa: Integrating Con-
straint Grammar and CALL. In Henrik Holm-
boe (ed.), Nordic Language Technology, Copen-
haguen: Museum Tusculanum, pp. 183?190.
Brants, Thorsten (2000). TnT ? A Statistical Part-of-
Speech Tagger. In Proceedings of the Sixth Ap-
plied Natural Language Processing Conference
(ANLP 2000). Seattle, WA, pp. 224?231.
C?avar, Damir (2008). The Croatian Language
Repository: Quantitative and Qualitative Re-
sources for Linguistic Research and Language
Technologies. Invited talk, Indiana University
Department of Lingistics, January 2008.
Clemenceau, David (1997). Finite-State Morphol-
ogy: Inflections and Derivations in a Singl e
Framework Using Dictionaries and Rules. In Em-
manuel Roche and Yves Schabes (eds.), Finite
State Language Processing, The MIT Press.
Felshin, Sue (1995). The Athena Language Learn-
ing Project NLP System: A Multilingual Sys-
tem for Conversation-Based Language Learning.
In Intelligent Language Tutors: Theory Shap-
ing Technology, Lawrence Erlbaum Associates,
chap. 14, pp. 257?272.
Goldsmith, John and Yu Hu (2004). From Sig-
natures to Finite State Automata. In Midwest
Computational Linguistics Colloquium (MCLC-
04). Bloomington, IN.
Heift, Trude and Devlan Nicholson (2001). Web
delivery of adaptive and interactive language tu-
toring. International Journal of Artificial Intelli-
gence in Education 12(4), 310?325.
Loritz, D. (1992). Generalized Transition Network
Parsing for Language Study: the GPARS system
for English, Russian, Japanese and Chinese. CAL-
ICO Journal 10(1).
Mitton, Roger (1996). English Spelling and the
Computer. Longman.
Murray, Janet H. (1995). Lessons Learned from
the Athena Language Learning Project: Us-
ing Natural Language Processing, Graphics,
Speech Processing, and Interactive Video for
Communication-Based Language Learning. In
V. Melissa Holland, Michelle R. Sams and
Jonathan D. Kaplan (eds.), Intelligent Language
Tutors: Theory Shaping Technology, Lawrence
Erlbaum Associates, chap. 13, pp. 243?256.
Nagata, Noriko (1995). An Effective Application
of Natural Language Processing in Second Lan-
guage Instruction. CALICO Journal 13(1), 47?
67.
Pijls, Fieny, Walter Daelemans and Gerard Kempen
(1987). Artificial intelligence tools for grammar
and spelling instruction. Instructional Science 16,
319?336.
Roark, Brian and Richard Sproat (2007). Compu-
tational Approaches to Morphology and Syntax.
Oxford University Press.
Schmid, Helmut (1997). Probabilistic part-of-
speech tagging using decision trees. In D.H. Jones
and H.L. Somers (eds.), New Methods in Lan-
guage Processing, London: UCL Press, pp. 154?
164.
Sharoff, Serge, Mikhail Kopotev, Tomaz? Erjavec,
Anna Feldman and Dagmar Divjak (2008). De-
signing and evaluating Russian tagsets. In Pro-
ceedings of LREC 2008. Marrakech.
Vandeventer Faltin, Anne (2003). Syntactic error di-
agnosis in the context of computer assisted lan-
guage learning. The`se de doctorat, Universite? de
Gene`ve, Gene`ve.
9
