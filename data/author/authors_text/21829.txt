INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 17?21,
Utica, May 2012. c?2012 Association for Computational Linguistics
MinkApp: Generating Spatio-temporal Summaries for Nature Conservation
Volunteers
Nava Tintarev, Yolanda Melero, Somayajulu Sripada,
Elizabeth Tait, Rene Van Der Wal, Chris Mellish
University of Aberdeen
{n.tintarev, y.melero, yaji.sripada,
elizbeth.tait, r.vanderwal, c.mellish@abdn.ac.uk}@abdn.ac.uk
Abstract
We describe preliminary work on generat-
ing contextualized text for nature conservation
volunteers. This Natural Language Genera-
tion (NLG) differs from other ways of describ-
ing spatio-temporal data, in that it deals with
abstractions on data across large geographi-
cal spaces (total projected area 20,600 km2),
as well as temporal trends across longer time
frames (ranging from one week up to a year).
We identify challenges at all stages of the clas-
sical NLG pipeline.
1 Introduction
We describe preliminary work on summarizing
spatio-temporal data, with the aim to generate con-
textualized feedback for wildlife management vol-
unteers. The MinkApp project assesses the use
of NLG to assist volunteers working on the Scot-
tish Mink Initiative (SMI). This participatory initia-
tive aims to safeguard riverine species of economic
importance (e.g., salmon and trout) and species of
nature conservation interest including water voles,
ground nesting birds and other species that are ac-
tively preyed upon by an invasive non-native species
- the American mink (Bryce et al, 2011).
2 Background
Our test ground is one of the world?s largest
community-based invasive species management
programs, which uses volunteers to detect, and sub-
sequently remove, American mink from an area of
Scotland set to grow from 10,000 km2 in 2010 to
20,600 km2 by the end of 2013 (Bryce et al, 2011).
Such a geographical expansion means that an in-
creasing share of the monitoring and control work is
undertaken by volunteers supported by a fixed num-
ber of staff. An important contribution of volunteers
is to help collect data over a large spatial scale.
Involving members of the public in projects such
as this can play a crucial role in collecting observa-
tional data (Silvertown, 2009). High profile exam-
ples of data-gathering programmes, labelled as cit-
izen science, include Galaxy Zoo and Springwatch
(Raddick et al, Published online 2010; Underwood
et al, 2008). However, in such long-term and wide
ranging initiatives, maintaining volunteer engage-
ment can be challenging and volunteers must get
feedback on their contributions to remain motivated
to participate (Silvertown, 2009). NLG may serve
the function of supplying this feedback.
3 Related work
We are particularly interested in summarizing raw
geographical and temporal data whose semantics
need to be computed at run time ? so called spatio-
temporal NLG. Such extended techniques are stud-
ied in data-to-text NLG (Molina and Stent, 2010;
Portet et al, 2009; Reiter et al, 2005; Turner et
al., 2008; Thomas et al, Published online 2010).
Generating text from spatio-temporal data involves
not just finding data abstractions, but also determin-
ing appropriate descriptors for them (Turner et al,
2008). Turner et. al (2008) present a case study in
weather forecast generation where selection of spa-
tial descriptors is partly based on domain specific
(weather related) links between spatial descriptors
17
and weather phenomena. In the current project we
see an opportunity to investigate such domain spe-
cific constraints in the selection of descriptors over
larger temporal and spatial scales.
4 Current Status
Over 600 volunteers currently notify volunteer man-
agers of their ongoing mink recording efforts. Our
work is informed by in-depth discussions and inter-
views with the volunteer managers, as well as 58
(ground level) volunteers? responses to a question-
naire about their volunteering experience. The set of
volunteers involves different people, such as conser-
vation professionals, rangers, landowners and farm-
ers with the degree of volunteer involvement varying
among them. Most volunteers check for sightings:
footprints on a floating platform with a clay-based
tracking plate (raft hereafter) readily used by mink,
or visual sightings on land or water. Others set and
check traps, and (much fewer volunteers) dispatch
trapped mink.1 In terms of feedback, volunteers cur-
rently receive regional quarterly newsletters, but tai-
lored and contextualized feedback is limited to spo-
radic personal communication, mostly via email.2
4.1 Why NLG in this context?
Where the initiative has been successful, mink sight-
ings are sparse. Such a lack of sightings can be de-
motivating for volunteers and leads to a situation in
which negative records are seldom recorded (Beirne,
2011). As one volunteer stated: ?Nothing much hap-
pens on my raft so my enthusiasm wanes.? Also,
73% of the volunteers who completed the ques-
tionnaire said they checked their raft at the recom-
mended frequency of every two weeks. Similarly,
72% said that they got in touch with their manager
rarely or only every couple of months ? when they
needed more clay or saw footprints. NLG based
feedback could motivate volunteers by informing
them about the value of negative records. If they
were to stop because of a lack of interest, mink are
likely to reinvade the area.
1Traps are only placed once a sighting has occurred. Once
placed, by law a trap must be checked daily.
2In this project, we are using a corpus based on newsletters
from the North Scotland Mink Project and the Cairngorms Wa-
ter Vole Conversation Project.
In addition, volunteers who work alone can be
isolated and lack natural mechanisms for informa-
tion exchange with peers. We postulate that giving
the volunteers contextualized feedback for an area
gives them a better feeling for their contribution to
the project and a better sense of how the initiative is
going overall. A need for this has already been felt
by volunteers: ?Knowing even more about progress
in the catchment would be good - and knowing in de-
tail about water vole returning and latest mink sight-
ings. It would be helpful to learn about other neigh-
boring volunteers captures sightings in ?real time?.?
5 Approach
In this section we describe the generation of text in
terms of a classic NLG pipeline, (Reiter and Dale,
2000), while addressing the additional tasks of in-
terpreting the input data (from volunteers) to mean-
ingful messages that achieve the desired communi-
cation goals: providing information to, as well as
motivating volunteers. The NLG system which will
generate these texts is actively under development.
5.1 Gold standard
Our nearest comparison is a corpus of domain spe-
cific conservation newsletters containing text such
as the one below. These newsletters give us an idea
of the type of structure and lexical choice applied
when addressing volunteers, using both temporal
and spatial summaries. However, these texts are not
contextualized, or adapted to a particular volunteer.
?With an ever expanding project area, we
are progressing exceptionally well achiev-
ing and maintaining areas free of breed-
ing mink through-out the North of Scot-
land. Currently, the upper Spey, upper
Dee and Ythan appear to be free of breed-
ing mink, with only a few transients pass-
ing through...?
We would like to improve on these existing texts
and aim to generate texts that are tailored and con-
sider the context of the volunteer. The text below is
developed from a template supplied from a volunteer
manager in the process of corpus collection. In the
following sections we describe the steps and chal-
lenges involved in the process of generating such a
text.
18
?Thank you for your helpful contribution!
You may have not seen any signs this time,
but in the last week two people in the Spey
catchment have seen footprints on their
rafts. This means there might be a female
with a litter in your neighborhood ? please
be on the lookout in the coming weeks!
Capturing her could mean removing up to
6 mink at once!?
5.2 Example input
The data we receive from volunteers includes pos-
itive and negative records from raft checks (every
14 days), visual sightings, and mink captures. Each
record contains a geographical reference (x and y co-
ordinate) and a timestamp. In addition, for trapped
mink we may know the sex (male, female, or un-
known) and age (juvenile, adult, or unknown).
5.3 Data analysis and interpretation
Spatial trends. The current version of the system
can reason over geographical information, defin-
ing various notions of neighborhood.3 For a given
point the following attributes can be used to describe
its neighborhood: geographical region (catchment
and subcatchment), Euclidean distance from another
point, and relative cardinal direction to another point
(north, south, east, west). The system reasons about
sightings and captures using facts such as:
? This point (on land or water) is in the Dee
catchment.
? Three neighbors have seen footprints (within a
given time window).
? One neighbor has caught a mink (within a given
time window).
? The nearest mink footprint is 15 km north east
of this point.
The definition of neighborhood will differ accord-
ing to domain specific factors. Euclidean distance
appears to be the most likely candidate for use, be-
cause sightings may belong to different geographic
3The reasoning is performed using the opensource GIS
Java library Geotools, http://geotools.org, retrieved
Jan 2012
regions (catchments) but be very close to each other.
More importantly, the definition of neighborhood is
likely to depend on the geographic region (e.g. ar-
eas differ in terms of mink population density with
mountainous regions less likely to be utilized than
coastal regions).
Temporal trends. Aside from geographic trends,
the system will also be used to portray temporal
trends. These look at the change in sightings be-
tween two time intervals, identifying it as a falling,
rising or steady trend in mink numbers. We are
primarily observing trends between different years,
but also taking into consideration the ecology of the
mink including their behavior in different seasons
and for quantification. For example, we need to be
able to decide if an increase from 0 to 5 mink sight-
ings in an area during breeding is worth mentioning
? most likely it is, as this a common size for a litter.
Another example is the definition of a ?cleared? area
- Example 1 below describes a stable zero trend over
a longer period of time.
...Currently, the upper Spey, upper Dee and Ythan
appear to be free of breeding mink...
(1)
5.4 Document planning
Content determination While useful on its own,
the text that could be generated from the data analy-
sis and interpretation described above is much more
useful when domain specific rules are applied. Ex-
ample 2 describes a significant year-on-year increase
for a given definition of neighborhood, during breed-
ing season.
IF ( (month >= 6 AND month <9)
AND sightingsLastYear(area) == 0
AND sightingsThisYear >= 5 )
THEN feedback +=
?It looks like the area has been reinvaded.
We should get ready to trap them to keep this
area mink free.?
(2)
Example rule 2 is applied in the breeding season (ca
June-Aug.). It will be given a score which signi-
fies its relative importance compared to other de-
rived content to allow prioritization. For example,
19
if there are both female and male captures in a re-
gion, it would be more important to speak about the
female capture. This is because the capture of breed-
ing mink has a much larger positive impact on the
success of the initiative.4 This importance should
be reflected in texts such as: ...Capturing her could
mean removing up to 6 mink at once!...
Document structuring Since our goal is to moti-
vate as well as inform, the structure of the text will
be affected. If we consider the example text in Sec-
tion 5.1, we can roughly divide it into three summary
types:
? Personal - ?Thank you for your helpful contri-
bution! You may have not seen any signs this
time.?
? Neighbor - ?In the last week two people in the
Spey catchment have seen small footprints on
their rafts.?
? Biology - ?There might be a female with a litter
in your neighborhood ... Capturing her could
mean removing up to 6 mink at once!?
If, in contrast to the previous example, a volun-
teer would capture a mink, then the neighborhood
summary can be used to emphasize the importance
of rare captures.
?IF currentMonth == August AND
capture == true AND nCapturesInSummer == 0?
(3)
The feedback for rule 3 might read something
like: ?Well done! So far, this was the only mink cap-
tured during the breeding season in the Spey catch-
ment!?
5.5 Microplanning
Microplanning will need to consider the aggrega-
tion of spatio-temporal data that happens on a deeper
level e.g., for a given catchment and year. This ag-
gregation is likely to result in a surface aggregation
as well deeper data aggregation, such as the catch-
ments in Example 1. In terms of lexical choice, the
system will have to use domain appropriate vocabu-
lary. The latter example refers to ?breeding mink?,
4Established adult females with litters.
which informs the reader that their capture has a
large impact on population control. Another exam-
ple of lexical choice may be ?quieter autumn? to de-
note a decrease in mink for an area.
The best way to communicate neighborhood to
volunteers is still an open question. The texts in
our corpus describe neighborhoods in terms of geo-
graphic regions (catchments and subcatchments, e.g.
Spey). However, Euclidean distance may be more
informative, in particular close to catchment bound-
aries.
6 Challenges
There are several key challenges when generating
motivating text for nature conservation volunteers,
using spatio-temporal NLG.
One challenge is to tailor feedback texts to in-
dividuals according to their motivations and infor-
mation needs. In line with previous research in
affective NLG (de Rosis and Grasso, 2000; Belz,
2003; Sluis and Mellish, 2010; Tintarev and Mas-
thoff, 2012; Mahamood and Reiter, 2011), we con-
tinue to study the factors which are likely to have
an effect on volunteer motivation. So far we have
worked together with volunteer managers. We col-
lected a corpus of texts, written by the managers,
that are tailored to motivate different volunteer per-
sonas, and conducted interviews and a focus group
with them. While we found that the mink managers
tailored texts to different personas, interviews indi-
cated that the biggest factor to tailor for was the def-
inition of neighborhood. Some volunteers are inter-
ested in a local update, while others are interested in
a larger overview.
A second, related challenge, regards correctly
defining the reasoning over spatio-temporal facts
e.g., quantifying the magnitude of significant
changes (increases and decreases in sightings and
captures) for different seasons, regions, and the time
frames over which they occur. We believe this will
lead to generating text referring to more compound
abstractions such as mink free areas, or re-invasion.
A final challenge brought out by the interviews
is to supply varied feedback that helps volunteers to
continue to learn about mink and their habitat. This
is a challenge for both content determination and mi-
croplanning.
20
References
Christopher Beirne. 2011. Novel use of mark-recapture
framework to study volunteer retention probabilities
within an invasive non-native species management
project reveals vocational and temporal trends. Mas-
ter?s thesis, University of Aberdeen.
Anja Belz. 2003. And now with feeling: Developments
in emotional language generation. Technical Report
ITRI-03-21, Information Technology Research Insti-
tute, University of Brighton.
Rosalind Bryce, Matthew K. Oliver, Llinos Davies, He-
len Gray, Jamie Urquhart, and Xavier Lambin. 2011.
Turning back the tide of american mink invasion at an
unprecedented scale through community participation
and adaptive management. Biological Conservation,
144:575?583.
Fiorella de Rosis and Floriana Grasso, 2000. Affective
Interactions, volume 1814 of Lecture Notes in Artifi-
cial Intelligence, chapter Affective Natural Language
Generation. Springer-Verlag.
Saad Mahamood and Ehud Reiter. 2011. Generating af-
fective natural language for parents of neonatal infants.
In ENLG.
Martin Molina and Amanda Stent. 2010. A knowledge-
based method for generating summaries of spatial
movement in geographic areas. International Journal
on Artificial Intelligence Tools, 19(3):393?415.
Francois Portet, Ehud Reiter, Albert Gatt, Jim Hunter,
Somayajulu Sripada, Yvonne Freer, and Cindy Sykes.
2009. Automatic generation of textual summaries
from neonatal intensive care data. Artificial Intelli-
gence, 173:789?816.
M. Jordan Raddick, Georgia Bracey, Pamela L. Gay,
Chris J. Lintott, Phil Murray, Kevin Schawinski,
Alexander S. Szalay, and Jan Vandenberg. Published
online 2010. Galaxy zoo: Exploring the motivations
of citizen science volunteers. Astronomy Education
Review, 9(1), 010103, doi:10.3847/AER2009036.
Ehud Reiter and Robert Dale. 2000. Building natural
language generation systems. Cambridge University
Press.
Ehud Reiter, Somayajulu Sripada, Jim Hunter, Jin Yu,
and Ian Davy. 2005. Choosing words in computer-
generated weather forecasts. Artificial Intelligence,
167:137?169.
Jonathan Silvertown. 2009. A new dawn for citizen sci-
ence. Trends in Ecology & Evolution, 24:467?471.
Ielka Van der Sluis and Chris Mellish, 2010. Empiri-
cal Methods in Natural Language Generation, volume
5980 of Lecture Notes in Computer Science, chap-
ter Towards Empirical Evaluation of Affective Tactical
NLG. Springer, Berlin / Heidelberg.
Kavita E. Thomas, Somayajulu Sripada, and Matthijs L.
Noordzij. Published online 2010. Atlas.txt: Ex-
ploring linguistic grounding techniques for commu-
nicating spatial information to blind users. Journal
of Universal Access in the Information Society, DOI
10.1007/s10209-010-0217-5.
Nava Tintarev and Judith Masthoff. 2012. Evaluating
the effectiveness of explanations for recommender sys-
tems: Methodological issues and empirical studies on
the impact of personalization. User Modeling and
User-Adapted Interaction, (to appear).
Ross Turner, Somayajulu Sripada, Ehud Reiter, and Ian
Davy. 2008. Using spatial reference frames to gener-
ate grounded textual summaries of georeferenced data.
In INLG.
Joshua Underwood, Hilary Smith, Rosemary Luckin, and
Geraldine Fitzpatrick. 2008. E-science in the class-
room towards viability. Computers & Education,
50:535?546.
21
Proceedings of the 8th International Natural Language Generation Conference, pages 113?117,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
Determining Content for Unknown Users: Lessons from 
           the MinkApp Case Study 
Gemma Webster, Somayajulu G. Sripada, Chris Mellish, Yolanda Melero, Koen Arts, 
Xavier Lambin, Rene Van Der Wal  
University of Aberdeen 
{gwebster, yaji.sripada, c.mellish, y.melero, k.arts, x.lambin, r.vanderwal}@abdn.ac.uk  
 
Abstract 
If an NLG system needs to be put in 
place as soon as possible it is not always 
possible to know in advance who the us-
ers of a system are or what kind of in-
formation will interest them. This paper 
describes the development of a system 
and contextualized text for unknown us-
ers. We describe the development, design 
and initial findings with a system for un-
known users that allows the users to de-
sign their own contextualised text. 
1 Introduction 
Requirements of an NLG system are derived 
commonly by analysing a gold standard corpus. 
Other knowledge acquisition (KA) techniques 
such as interviewing experts and end-users are 
also frequently employed. However, when these 
KA studies result in only a partial specification 
of the system requirements or complications 
make carrying out a detailed user study in the 
time available difficult, an initial system for un-
known users may need to be developed. The ini-
tial system needs to fulfil the known require-
ments making a number of assumptions to fill the 
gaps in the requirements. In this paper, we con-
centrate on the content determination problem 
for such a system. 
 
We encountered this particular problem when 
producing an initial NLG system to give feed-
back to volunteers submitting information about 
signs of American Mink, an invasive species in 
Scotland. Our response can be viewed, on one 
hand, as that of exposing an early prototype for 
evaluation in real use. On the other hand, it can 
be viewed as an approach to allowing users to 
?design their own contextualised text?. We ex-
pected that this approach would have a number 
of advantages. In the paper, we draw our conclu-
sions about how this worked out in our example 
application. 
2 Background - MinkApp 
The Scottish Mink Initiative (SMI) project aims 
to protect native wildlife by removing breeding 
American Mink (an invasive species) from the 
North of Scotland. SMI in the form discussed 
here was launched in May 2011 and ran until 
August 2013, after which it continued but on a 
much smaller funding base. SMI?s success and 
future rely on an ongoing network of volunteers 
from across Scotland to monitor the American 
mink population. During the period from 2011 to 
2013, these volunteers were coordinated by 4 and 
later 3 full-time Mink Control officers (MCOs) 
who had 2.5 year fixed term contracts, had no 
communal offices and were geographically lo-
cated across Scotland.  
At present volunteers are provided with rafts to 
monitor American mink. Rafts are simple devic-
es that float on water and are monitored by vol-
unteers who regularly check a clay pad for mink 
footprints. In the past, volunteers in turn reported 
signs or lack of signs to their corresponding 
MCO. Now volunteers can do the same through 
the MinkApp website, introduced in 2012, 
though some choose to continue to use the previ-
ous reporting method. The data should ideally be 
entered roughly every 10 days; it concerns either 
positive or negative records from raft checks, or 
visual sightings of mink and actual mink cap-
tures. The records contain geographical infor-
mation and a timestamp. MinkApp checks 
whether this data is complete and then informs 
the respective mink officer for that volunteer?s 
area and enters the data into the database.  
 
Volunteers used to receive a quarterly newsletter 
that had some regional specific content but was 
not volunteer specific. They could receive spo-
radic contact from their mink control officer in 
the form of a phone call or email. MinkApp al-
lowed an infrastructure to be developed to pro-
vide volunteers with specific and immediate 
113
feedback upon submission of their observations 
by means of contextualised feedback text. 
 
SMI?s funding base was severely reduced in Au-
gust 2013 and MinkApp has proven central to its 
endurance. Volunteer activities of the SMI are 
now supported by staff from 10 local rivers and 
fisheries trusts (as one of their many activities). 
This limited amount of staff time available could 
make the development of automatic personalised 
feedback generation vital to allow volunteers to 
have tailored information on the progress of the 
project and to keep volunteers engaged. 
3 The Problem - SMI Volunteers: The 
Unknown Users 
The nearest to a gold standard for what infor-
mation to offer was the corpus of newsletters 
containing information on the project as a whole. 
However, we learned that these newsletters were 
often not read and we have no way of judging 
their level of success. These newsletters, along 
with emails and discussions conducted with SMI 
employees on their interactions with volunteers, 
however, gave us ideas about potential content 
that could be selected and indication of potential 
lexical structure and word use when addressing 
volunteers.  
Although some SMI volunteers monitor mink as 
part of their job (e.g. gamekeepers), they could in 
fact be anyone with a desire to contribute to na-
ture conservation. Volunteers are located in very 
disparate geographical locations across Scotland, 
with no set gender or age range and so volun-
teers? motivations, computer skills and profes-
sions are mostly unknown. Because of the range 
of types of people who could in principle be vol-
unteers, they can be expected to be very varied. 
It is extremely difficult to contact all volunteers 
as each SMI catchment is managed and orga-
nized in different ways and volunteers are con-
tacted using different media e.g. mail, email, tel-
ephone, face-to-face. SMI is also careful to avoid 
attempting to contact volunteers too often, con-
scious that they are providing their services for 
free and should not be bothered unnecessarily.  
There is also some uncertainty about which vol-
unteers are active, as records are often partial or 
out of date. It is known anecdotally from MCOs 
that many volunteers are unwilling to use any 
kind of computer system and so it is unclear 
what kind of people will be reached through 
MinkApp. Finally, most observations of mink 
signs that arise are ?null records?, i.e. records of 
observing no mink prints on rafts. It is not known 
which volunteers will be sufficiently motivated 
to submit ?null records? and which will remain 
apparently inactive because they have nothing 
positive to report. 
So, even though there was a need for automati-
cally generated feedback now, there was a real 
question of who the readers would be and how to 
select the content to include in the feedback. 
4 Related Work 
A standard approach to establish user require-
ments for NLG is to assemble a corpus of hu-
man-authored texts and their associated inputs 
(Reiter & Dale, 2000). This can be the basis of 
deriving rules by hand, or one can attempt to rep-
licate content selection rules from the corpus by 
machine learning (Duboue & McKeown, 2003; 
Konstas & Lapata, 2012). To produce a useful 
corpus, however, one has to know one?s users or 
have reliable expert authors. 
 
As first pointed out by Levine et al. (1991), an 
NLG system that produces hypertext, rather than 
straight text, can avoid some content selection 
decisions, as the user makes some of these deci-
sions by selecting links to follow. A similar ad-
vantage applies to other adaptive hypertext sys-
tems (Brusilovsky, 2001).  Another general pos-
sibility is to allow users to design aspects of the 
texts they receive. For instance, ICONOCLAST 
(Power, Scott, & Bouayad-Agha, 2003) allows 
users to make choices about text style. However, 
relatively little is known about how such ap-
proaches work ?in the wild?. 
 
Various previous work has attempted to build 
models of users through observing interactions 
with an interface (Fischer, 2001). Alternatively, 
it is possible to explicitly ask questions to the 
user about their interests (Tintarev & Masthoff, 
2008), though this requires the users to have the 
time and motivation to take part in an initial ac-
tivity with no direct reward. 
 
Our approach can be seen to have similarities 
with hypertext generation, in that we are offering 
alternative texts to users, and non-invasive ap-
proaches to user modelling. 
114
5 Approach to Content Selection 
To overcome the ?unknown? user and ?unknown? 
feedback problem it was decided to implement a 
relatively quick exploratory tool that could be 
used to help understand user requirements, pro-
vide initial evaluation of feedback content and 
build an understanding of user interests. To 
achieve these aims we developed a tool that al-
lows users to generate their own text, selecting 
content from a larger set of possibilities. The in-
formation on the type of feedback generated by 
the user would allow us to investigate user stere-
otypes, their detection and the automatic adapta-
tion of content based on their interests 
(Zancanaro, Kuflik, Boger, Goren-Bar, & 
Goldwasser, 2007). 
5.1 Exploratory Tool - The Feedback Form 
The feedback form (Figure 1) is displayed to us-
ers of the MinkApp system once they have sub-
mitted a raft check. The form allows the user to 
select which raft they wish to have their feedback 
generated on from a list of the rafts they manage. 
The users have four types of information they 
can select to have feedback generated on: Signs 
(information on signs of mink reported through 
raft checks), Captures (information on mink cap-
tures), My Rafts (information on their personal 
raft checks and submission record) and Mink 
Ecology (information on mink behaviour and 
seasonality).  
Two of the four options, Signs and Captures, 
allow the user to select to what geographic scale 
they would like their feedback based on: the 
whole of the SMI project area, their river or their 
catchment ? the geographical region that they 
report to e.g. Aberdeenshire, Tayside etc.  
 
Once the user has made their selection the per-
sonalised feedback based on their choices is gen-
erated and displayed along with an option to rank 
how interesting they found this feedback or any 
comments they wish to make. The user can gen-
erate multiple texts in one session. All data from 
each click of an option, the generated text and 
user comments on the text are recorded.  
5.2 Generation of the paragraphs 
The structure of the text is separated out into 
self-contained paragraphs to allow analysis of 
what volunteers regularly view. For each type, 
the structure of the generated paragraph is de-
termined by a simple schema: 
Signs:  
Neighbourhood (based on user selection) ? In the 
Don catchment there have been 6 signs of mink 
reported over the past 12 months which is higher 
than the previous 12 months 
Additional Information / Motivation ? Mink are 
coming into your area to replace captured mink. 
This shows your area has good ecology for mink 
and it is important to keep monitoring. 
Personal ? There have been no signs of mink (in 
the form of either footprints or scat) in the past 
30 days. No signs of mink recently does not mean 
they are gone - remain vigilant. 
  
Captures: 
Neighbourhood (based on user selection) ? In the 
Spey catchment we have trapped 5 mink over the 
past 12 months which is lower than the previous 
12 months. 
Additional Information / Motivation ? Infor-
mation available on this year's captures: An 
adult female mink was captured on: 2014-02-19. 
 
My Rafts: 
Personal ?You have been very active over the 
past 60 days with 7 'no mink signs' reported and 
2 signs of mink (in the form of either footprints 
or scat) reported, the last of which was logged 
on 14 Sep 2013 23:00:00 GMT. 
Additional Information / Motivation ? Please 
keep checking your raft as this evidence means 
there are mink in your area. 
 
Mink Ecology: 
Temporal - We are in the normal mink breeding 
season!  
Motivation ? During the breeding season female 
mink will defend an area covering approximately 
1.5 miles.  
Additional Information - Female mink are small 
enough to fit into water vole burrows which they 
explore in search of prey.Did you know there can 
be brown, black, purple, white and silver mink 
which reflects the colours bred for fur? 
115
 
To produce the actual content to fill the slots of 
the schemas, the system was designed to reason 
over geographical location to allow examination 
of the various notions of neighbourhood 
(Tintarev et al 2012). The system also looks at 
temporal trends when developing text based on 
the number of record submissions for a given 
time. The system initially looks at record sub-
missions in the past week then opens out to a 
month, season and finally activity between the 
same seasons on different years. This use of 
temporal trends ensures volunteers are supplied 
with the most relevant (recent) mink activity in-
formation first in busy periods such as the breed-
ing season but ensures ?cleared? areas with little 
mink activity are still provided with informative 
feedback.  
6 Evaluation of the Feedback Approach 
We were initially apprehensive about how much 
usage the feedback system would get. MinkApp 
was launched through the SMI newsletters, but 
we knew that volunteers were not always receiv-
ing or reading these. Also it turned out that the 
initial estimate of active volunteers was over-
inflated. Indeed, initially the usage of MinkApp 
in general was much lower than was expected. 
So we worked hard to promote the system, for 
instance asking the fisheries trusts to actively ask 
any volunteers they had contact with if they had 
heard of MinkApp and to try to use it. As a re-
sult, we did manage to increase the system usage 
to a level where some initial conclusions can be 
drawn. 
MinkApp and specifically the feedback form use 
were monitored for 50 days (7 weeks). During 
this time 308 raft checks were submitted by vol-
unteers for 98 different rafts by 44 unique users. 
The feedback system was used by volunteers to 
generate 113 different texts about 36 different 
rafts. 32 out of the 44 (72.7%) of all MinkApp 
users requested generated feedback at least once.  
 
In 47% of the feedback form use sessions multi-
ple texts were generated and there are some par-
ticularly interesting use patterns: 
? ?Regular explorer?: One user accessed 
MinkApp seven times and generated 
feedback text on every use: 1 text, 3 
texts, 5 texts, 5 texts, 4 texts, 2 texts and 
1 text 
? ?Periodic explorer?: One user accessed 
MinkApp six times and generated at 
least one feedback text on every second 
use 
? ?Try once only?: The user who accessed 
MinkApp the most with eleven different 
sessions only generated feedback text on 
their first use of MinkApp.  
These different patterns of use require further 
investigation as the number of users using 
MinkApp increases. The patterns can be affected 
by idiosyncratic factors. For instance, one volun-
teer informed the project coordinator that they 
continually selected Captures within their area as 
they had caught a mink and their capture had not 
yet been added to the system - the volunteer was 
using the feedback form to monitor how long it 
took for mink capture data to appear in 
MinkApp.  
 
Of the four types of information available to vol-
unteers Signs was the most viewed although 
Captures was what SMI staff had felt volunteers 
would be most interested in. Signs had 56.6% of 
the overall use and catchment was the most 
widely selected option for geographic area for 
both Signs and Captures. However there was no 
clearly predominant second choice for infor-
mation option with Captures and My Rafts hav-
ing only 2.7% of a difference within their use. 
Mink Ecology was the least used category, partly 
to do with the lack of clarity in the name ?Mink 
Ecology?. Signs on a local geographical scale 
were the most common selection for volunteers 
but the actual use was not clear enough to sup-
port a fixed text type or removing other options. 
7 Conclusions 
The results of this initial study did support the 
value of feedback to volunteers (more directly 
than we would have been able to determine in 
advance) with 73% of volunteers choosing to 
generate feedback. The feedback enabled us to 
offer contextualized information to volunteers 
quickly, without initial extensive user studies, 
which was very important for supporting the 
continuation of SMI. 
The fact that the volunteer population was rela-
tively unknown meant that there were some un-
pleasant surprises in terms of uptake and interest. 
It was necessary to make special efforts to en-
courage participation to get larger numbers. 
116
When our system gets used over longer periods 
we might observe more meaningful patterns of 
behaviour. 
The patterns of interest we observed were noisy 
and were influenced by many contextual factors 
meaning there was little potential yet for statisti-
cal analysis or machine learning.  
8 Future Work 
In-depth analysis is required as more volunteers 
use MinkApp and the feedback form to fully un-
derstand patterns of behaviour. Additionally 
qualitative studies such as interviews with volun-
teers could help explain use and preferences. 
These studies could help us improve the feed-
back system and text to better suit the user?s 
needs. In the meantime, we have a working sys-
tem that offers choices to users to ?generate their 
own text? even though we had hoped to be able 
to tailor to individual volunteer preferences 
sooner. 
9 Acknowledgments 
We would like to thank SMI for their on-going 
commitment to this research. This work is sup-
ported by the Rural Digital Economy Research 
Hub (EPSRC EP/G066051/1). 
Reference 
Arts, K., Webster, G. ., Sharma, N. ., Melero, Y. ., 
Mellish, C., Lambin, X., & Van der Wal, R. 
(2013). Capturing mink and data. Interacting with a 
small and dispersed environmental initiative over 
the introduction of digital innovation Uploader. 
Case study for the online platform ?Framework for 
Responsible Research and Innovation in ICT.? Re-
trieved from http://responsible-
innovation.org.uk/torrii/resource-detail/1059 
Beirne, C., & Lambin, X. (2013). Understanding the 
Determinants of Volunteer Retention Through 
Capture-Recapture Analysis: Answering Social 
Science Questions Using a Wildlife Ecology 
Toolkit. Conservation Letters, 6(6), 391?401. 
doi:10.1111/conl.12023 
Brusilovsky, P. (2001). Adaptive Hypermedia. User 
Modeling and User-Adapted Interaction, 11(1-2), 
87?110. doi:10.1023/A:1011143116306 
Bryce, R., Oliver, M. K., Davies, L., Gray, H., Ur-
quhart, J., & Lambin, X. (2011). Turning back the 
tide of American mink invasion at an unprecedent-
ed scale through community participation and 
adaptive management. Biological conservation, 
144(1), 575?583. Retrieved from 
http://cat.inist.fr/?aModele=afficheN&cpsidt=2377
9637 
Duboue, P. A., & McKeown, K. R. (2003). Statistical 
acquisition of content selection rules for natural 
language generation. In Proceedings of the 2003 
conference on Empirical methods in natural lan-
guage processing - (Vol. 10, pp. 121?128). Morris-
town, NJ, USA: Association for Computational 
Linguistics. doi:10.3115/1119355.1119371 
Fischer, G. (2001). User Modeling in Human?
Computer Interaction. User Modeling and User-
Adapted Interaction, 11(1-2), 65?86. 
doi:10.1023/A:1011145532042 
Konstas, I., & Lapata, M. (2012). Concept-to-text 
generation via discriminative reranking, 369?378. 
Retrieved from 
http://dl.acm.org/citation.cfm?id=2390524.239057
6 
Levine, J., Cawsey, A., Mellish, C., Poynter, L., 
Reiter, E., Tyson, P., & Walker, J. (1991). IDAS: 
Combining hypertext and natural language genera-
tion. In Procs of the Third European Workshop on 
NLG (pp. 55?62). Innsbruck, Austria. 
Power, R., Scott, D., & Bouayad-Agha, N. (2003). 
Generating texts with style, 444?452. Retrieved 
from 
http://dl.acm.org/citation.cfm?id=1791562.179161
9 
Reiter, E., & Dale, R. (2000). Building Applied Natu-
ral Language Generation Systems. clt.mq.edu.au 
(Vol. 33.). Cambridge: Cambridge university press. 
Retrieved from 
http://clt.mq.edu.au/~rdale/publications/papers/199
7/jnle97.pdf 
Tintarev, N., & Masthoff, J. (2008). Adaptive Hyper-
media and Adaptive Web-Based Systems. (W. 
Nejdl, J. Kay, P. Pu, & E. Herder, Eds.) (Vol. 
5149, pp. 204?213). Berlin, Heidelberg: Springer 
Berlin Heidelberg. doi:10.1007/978-3-540-70987-9 
Tintarev, N., Melero, Y., Sripada, S., Tait, E., Van 
Der Wal, R., & Mellish, C. (2012). MinkApp: gen-
erating spatio-temporal summaries for nature con-
servation volunteers, 17?21. Retrieved from 
http://dl.acm.org/citation.cfm?id=2392712.239272
0 
Zancanaro, M., Kuflik, T., Boger, Z., Goren-Bar, D., 
& Goldwasser, D. (2007). Analyzing museum vis-
itors? behavior patterns. In C. Conati, K. McCoy, 
& G. Paliouras (Eds.), 11th International Confer-
ence on User Modeling (Vol. 4511, pp. 238?246). 
Berlin, Heidelberg: Springer Berlin Heidelberg. 
doi:10.1007/978-3-540-73078-1 
117
