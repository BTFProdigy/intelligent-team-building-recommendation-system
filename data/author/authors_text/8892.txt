TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 9?16,
Rochester, April 2007 c?2007 Association for Computational Linguistics
Multi-level Association Graphs ?
A New Graph-Based Model for Information Retrieval
Hans Friedrich Witschel
NLP department
University of Leipzig
04009 Leipzig, P.O. Box 100920
witschel@informatik.uni-leipzig.de
Abstract
This paper introduces multi-level associa-
tion graphs (MLAGs), a new graph-based
framework for information retrieval (IR).
The goal of that framework is twofold:
First, it is meant to be a meta model of
IR, i.e. it subsumes various IR models
under one common representation. Sec-
ond, it allows to model different forms of
search, such as feedback, associative re-
trieval and browsing at the same time. It
is shown how the new integrated model
gives insights and stimulates new ideas for
IR algorithms. One of these new ideas is
presented and evaluated, yielding promis-
ing experimental results.
1 Introduction
Developing formal models for information retrieval
has a long history. A model of information retrieval
?predicts and explains what a user will find relevant
given the user query? (Hiemstra, 2001). Most IR
models are firmly grounded in mathematics and thus
provide a formalisation of ideas that facilitates dis-
cussion and makes sure that the ideas can be imple-
mented. More specifically, most IR models provide
a so-called retrieval function f(q, d) , which returns
? for given representations of a document d and of a
user information need q ? a so-called retrieval status
value by which documents can be ranked according
to their presumed relevance w.r.t. to the query q.
In order to understand the commonalities and dif-
ferences among IR models, this paper introduces the
notion of meta modeling. Since the word ?meta
model? is perhaps not standard terminology in IR,
it should be explained what is meant by it: a meta
model is a model or framework that subsumes other
IR models, such that they are derived by specifying
certain parameters of the meta model.
In terms of IR theory, such a framework conveys
what is common to all IR models by subsuming
them. At the same time, the differences between
models are highlighted in a conceptually simple
way by the different values of parameters that have
to be set in order to arrive at this subsumption. It
will be shown that a graph-based representation of
IR data is very well suited to this problem.
IR models concentrate on the matching process,
i.e. on measuring the degree of overlap between a
query q and a document representation d. On the
other hand, there are the problems of finding suit-
able representations for documents (indexing) and
for users? information needs (query formulation).
Since users are often not able to adequately state
their information need, some interactive and asso-
ciative procedures have been developed by IR re-
searchers that help to overcome this problem:
? Associative retrieval, i.e. retrieving informa-
tion which is associated to objects known or
suspected to be relevant to the user ? e.g. query
terms or documents that have been retrieved al-
ready.
? Feedback, another method for boosting recall,
either relies on relevance information given
by the user (relevance feedback) or assumes
9
top-ranked documents to be relevant (pseudo
feedback) and learns better query formulations
from this information.
? Browsing, i.e. exploring a document collec-
tion interactively by following links between
objects such as documents, terms or concepts.
Again, it will be shown that ? using a graph-based
representation ? these forms of search can be sub-
sumed easily.
2 Related work
2.1 Meta modeling
In the literal sense of the definition above, there is
a rather limited number of meta models for IR, the
most important of which will be described here very
shortly.
Most research about how to subsume various IR
models in a common framework has been done in
the context of Bayesian networks and probabilistic
inference (Turtle and Croft, 1990). In this approach,
models are subsumed by specifying certain proba-
bility distributions. In (Wong and Yao, 1995), the
authors elaborately show how all major IR models
known at that time can be subsumed using proba-
bilistic inference. Language modeling, which was
not known then was later added to the list by (Met-
zler and Croft, 2004).
Another graph-based meta modeling approach
uses the paradigm of spreading activation (SA) as a
simple unifying framework. Given semantic knowl-
edge in the form of a (directed) graph, the idea of
spreading activation is that a measure of relevance
? w.r.t. a current focus of attention ? is spread over
the graph?s edges in the form of activation energy,
yielding for each vertex in the graph a degree of re-
latedness with that focus (cf. (Anderson and Pirolli,
1984)). It is easy to see how this relates to IR: us-
ing a graph that contains vertices for both terms and
documents and appropriate links between the two,
we can interpret a query as a focus of attention and
spread that over the network in order to rank docu-
ments by their degree of relatedness to that focus.
A very general introduction of spreading activa-
tion as a meta model is given in the early work by
(Preece, 1981) All later models are hence special
cases of Preece?s work, including the multi-level as-
sociation graphs introduced in section 3. Preece?s
model subsumes the Boolean retrieval model, coor-
dination level matching and vector space processing.
Finally, an interesting meta model is described by
(van Rijsbergen, 2004) who uses a Hilbert space as
an information space and connects the geometry of
that space to probability and logics. In particular,
he manages to give the familiar dot product between
query and document vector a probabilistic interpre-
tation.
2.2 Graph-based models for associative
retrieval and browsing
The spreading activation paradigm is also often used
for associative retrieval. The idea is to reach vertices
in the graph that are not necessarily directly linked to
query nodes, but are reachable from query nodes via
a large number of short paths along highly weighted
edges.
Besides (Preece, 1981), much more work on SA
was done, a good survey of which can be found in
(Crestani, 1997). A renewed interest in SA was later
triggered with the advent of theWWWwhere hyper-
links form a directed graph. In particular, variants of
the PageRank (Brin and Page, 1998) algorithm that
bias a random searcher towards some starting nodes
(e.g. an initial result set of documents) bear close re-
semblance to SA (Richardson and Domingos, 2002;
White and Smyth, 2003).
Turning to browsing, we can distinguish three
types of browsing w.r.t. to the vertices of the graph:
index term browsing, which supports the user in for-
mulating his query by picking related terms (Doyle,
1961; Beaulieu, 1997), document browsing which
serves to expand result sets by allowing access to
similar documents or by supporting web browsing
(Smucker and Allan, 2006; Olston and Chi, 2003)
and combined approaches where both index terms
and documents are used simultaneously for brows-
ing.
In this last category, many different possibilities
arise for designing interfaces. A common guiding
principle of many graph-based browsing approahces
is that of interactive spreading activation (Oddy,
1977; Croft and Thompson, 1987). Another ap-
proach, which is very closely related to MLAGs,
is a multi-level hypertext (MLHT), as proposed in
10
(Agosti and Crestani, 1993) ? a data structure con-
sisting of three levels, for documents, index terms
and concepts. Each level contains objects and links
among them. There are also connections between
objects of two adjacent levels. An MLHT is meant
to be used for interactive query formulation, brows-
ing and search, although (Agosti and Crestani, 1993)
give no precise specification of the processing pro-
cedures.
2.3 Contribution of this work
Compared to Preece?s work, the MLAG framework
makes two sorts of modifications in order to reach
the goals formulated in the introduction: in order to
subsume more IR models, the flexibility and power
of Preece?s model is increased by adding real-valued
edge weights. On the other hand, a clearer distinc-
tion is made between local and global information
through the explicit introduction of ?level graphs?.
With the introduction of levels, the MLAG data
structure becomes very closely related to the MLHT
paradigm of (Agosti and Crestani, 1993), MLAGs,
however, generalise MLHTs by allowing arbitrary
types of levels, not only the three types proposed in
(Agosti and Crestani, 1993). Additionally, links in
MLAGs are weighted and the spreading activation
processing defined in the next section makes exten-
sive use of these weights.
All in all, the new model combines the data struc-
ture of multi-level hypertexts (Agosti and Crestani,
1993) with the processing paradigm of spreading ac-
tivation as proposed by Preece (Preece, 1981), re-
fining both with an adequate edge weighting. The
framework is an attempt to be as general as neces-
sary for subsuming all models and allowing for dif-
ferent forms of search, while at the same time being
as specific as possible about the things that are really
common to all IR models.
3 The MLAG model
3.1 Data structure
Formally, the basis of a multi-level association
graph (MLAG) is a union of n level graphs
L1, ..., Ln. Each of these n directed graphs Li =
G(V Li, ELi,WLi) consists of a set of vertices
V Li, a set ELi ? V Li ? V Li of edges and a func-
tion WLi : ELi ? R returning edge weights.
In order to connect the levels, there are n ?
1 connecting bipartite graphs (or inverted lists)
I1,2, ..., In?1,n where each inverted list Ij,j+1 con-
sists of vertices V Ij,j+1 = V Lj ? V Lj+1, edges
EIj,j+1 ? (V Lj ? V Lj+1) ? (V Lj+1 ? V Lj) and
weights WIj,j+1 : EIj,j+1 ? R. Figure 1 depicts
a simple example multi-level association graph with
two levels Ld and Lt for documents and terms.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Term level
Document level
Inverted list
t1
`
t2
`
t3` t4`t5`t6
`
t7`
t8`
t9`
aa
a


((  
  


%
@
E
E
E