An Evolutionary Approach to Referring Expression Generation and Aggregation
Raquel Herva?s and Pablo Gerva?s
Departamento de Sistemas Informa?ticos y Programacio?n
Universidad Complutense de Madrid, Spain
raquelhb@fdi.ucm.es,pgervas@sip.ucm.es
Abstract
The work presented here is intended as an evolu-
tionary task-specific module for referring expres-
sion generation and aggregation to be enclosed in a
generic flexible architecture. Appearances of con-
cepts are considered as genes, each one encoding
the type of reference used. Three genetic opera-
tors are used: classic crossover and mutation, plus
a specific operator dealing with aggregation. Fit-
ness functions are defined to achieve elementary
coherence and stylistic validity. Experiments are
described and discussed.
1 Introduction
In this paper we present a first approach to the idea of using
Natural Language Generation (NLG) and Evolutionary Algo-
rithms (EAs) together.
To test the feasibility of our idea, we decided to select only
some particular features of the text on which to put it to the
test. Given the complexity of all the changes that are pos-
sible to a text, at the levels of syntax, semantics, discourse
structure and pragmatics, it seemed impractical to tackle them
all at once. For the purpose of illustration, we decided that
the problems of the referring expressions and the aggregation
were the most suitable to be solved using EAs. Referring
Expression Generation involves deciding how each element
ocurring in the input is described in the output text. Aggre-
gation involves deciding how compact the presentation of in-
formation should be in a given text. It operates at several lin-
guistic levels, but we only consider it here with respect to con-
cepts and their attributes. For instance, the system must de-
cide between generating ?The princess is blonde. She sleeps.?
and generating ?The blonde princess sleeps.?. Aggregation is
generally desirable, but may result in adjective-heavy texts
when the information to impart becomes dense in terms of
attributes, as in ?The pretty blonde princess lived in a strong
fancy castle with her stern rich parents.?. It is necessary to
find the balance between the use of compound or single sen-
tences, or in the case of the modifiers of a concept between
the description of the attributes of the concept using only a
phrase or various.
We analysed the features of a human generated text from
the point of view of the referring expressions, and we found
five different features of simple texts that might be susceptible
of easy treatment by means of evolutionary techniques. They
are described below.
Correct Referent.
When writing a text, we cannot use a pronoun for something
that we have not mentioned before, or readers would get con-
fused. An example could be:
She lived in a castle. A princess was the daugh-
ter of parents.
In addition, if the full noun reference and the pronoun are
far, the reader can also get confused and be unable to link the
two occurrences of the same concept, as we can see in the
following text:
A princess lived in a castle. She was the daugh-
ter of parents. She loved a knight. She was pretty.
She was blonde. It had towers. It was strong. They
lived in it.
Redundant Attributes.
When describing a concept in an ?X is Y? sentence, people do
not use the attribute they are going to describe in the reference
to the concept. Sentences such as the one below are incorrect:
The blonde princess was blonde.
Reference Repetition.
Using always the same reference together with the same set of
attributes results in repetitive text. For example, it is accept-
able to use ?the princess? every time we refer to the princess
character, but it would be striking to use always ?the pretty
princess?, as in this example:
A pretty princess lived in a castle.
The pretty princess was the daughter of par-
ents. The pretty princess loved a knight.
The pretty princess was blonde.
To avoid that, repetitive use of references is penalized.
Coherence.
If we use different subsets of attributes in different references
to the same concept, the reader may mistakenly assume that
we are referring to different concepts. For example, if we use
?the pretty princess? and ?the blonde princess? in different
places, and we have not specified that the princess is both
pretty and blonde, it could seem that there are two princess, a
pretty one and a blonde one:
A princess lived in a castle. The pretty princess
was the daughter of parents. The blonde princess
loved a knight.
Overlooked Information.
When processing the conceptual representation of a given
input, some information about a concept may disappear from
the final text. This should be avoided.
This paper describe an evolutionary solution that guaran-
tees the satisfaction of these restrictions in the conceptual
rendition of a given input by means of shallow techniques
that rely on very little knowledge about the domain and no
reasoning or common sense capabilities.
2 Natural Language Generation Tasks and
Evolutionary Algorithms
This section outlines the elementary requirements of the two
generation tasks addressed in this paper, and sketches the ba-
sic principles of the evolutionary techniques that are used.
2.1 Referring Expression Generation and
Aggregation
The correct use of referring expressions to compete with hu-
man generated texts involves a certain difficulty. Possible
simple algorithms for deciding when to use a pronoun and
when to use the full noun produce poor results. Two occur-
rences of the same concept in a paragraph can be far apart,
and this may confuse the reader. Knowledge intensive ap-
proaches modelled on the way humans do it require a certain
measure of content understanding that is resource hungry.
As shown in [Reiter and Dale, 1992], a referring expression
must communicate enough information to be able to uniquely
identify the intended referent in the current discourse context,
but avoiding the presence of redundant or otherwise unneces-
sary modifiers. Therefore, it is essential to choose a reference
which matches these constraints. Taking into account these
features, Reiter and Dale proposed an algorithm to generate
definite noun phrases to identify objects in the current focus
of attention of the reader or the hearer. However, Krahmer
and Theune [Krahmer and Theune, 2000] argue that due to
the original motivation of the work of Reiter and Dale of mak-
ing distinguishing descriptions, various other aspects of the
generation of definites remained somewhat underdeveloped.
In particular they focus on the role of context-sensitivity for
referring expression generation.
Kibble and Power [Kibble and Power, 2000] propose a sys-
tem which uses Centering Theory [Walker et al, 1998] for
planning of coherent texts and choice of referring expres-
sions. They argue that text and sentence planning need to
be driven in part by the goal of maintaining referential con-
tinuity: obtaining a favourable ordering of clauses, and of
arguments within clauses, is likely to increase opportunities
for non-ambiguous pronoun use.
Aggregation can be seen as the NLG task that involves de-
ciding how compact the presentation of information should be
in a given text, although there is no exact definition in the lit-
erature about what aggregation is [Reape and Mellish, 1999].
It operates at several linguistic levels, and due to that Reape
and Mellish make a classification of the different types of ag-
gregation: conceptual, discourse, semantic, syntactic, lexical
and referential. However, the line between them is very nar-
row, and in some cases a specific example could be classified
as different types of aggregation.
2.2 Evolutionary Algorithms
We propose the use of evolutionary algorithms (EAs) [Hol-
land, 1992] to deal with the referring expression generation
and aggregation tasks. Evolutionary algorithms are an ex-
tended set of problem resolution techniques inspired by evo-
lutionary phenomena and natural evolution. They work on
a population of individuals (representations of possible solu-
tions for the problem we are solving) that evolve according to
selection rules and genetic operators like crossover and mu-
tation. The fitness function is a metric which allows the eval-
uation of each of the possible solutions, in such way that the
average adaptation of the population would increase in each
generation. Repeating this process hundreds or thousands of
times it is possible to find very good solutions for the prob-
lem.
Evolutionary algorithms combine random search, because
the genetic operators are applied randomly, with oriented
search, given by the fitness values. These algorithms find
generally good solutions, but not always the best ones. How-
ever, this is enough for simple applications. In the case under
consideration, the main advantage we can find in evolution-
ary algorithms is that they do not need specific rules to build
a solution, only measurements of its goodness.
Evolutionary techniques have been shown in the past to be
particularly well suited for the generation of verse. The work
of Manurung [Manurung, 2003] and Levy [Levy, 2001] pro-
posed different computational models of the composition of
verse based on evolutionary approaches. In both cases, the
main difficulty lay in the choice of a fitness function to guide
the process. Although Levy only addressed a simple model
concerned with syllabic information, his overall description
of the architecture in terms of a population of poem drafts that
evolve, with priority given to those drafts that are evaluated
more highly, is an important insight. Levy uses a neural net-
work, trained with examples of valid verse, to evaluate these
drafts. The work of Manurung addresses the complete task,
and it presents a set of evaluators that grade the candidates
solutions according to particular heuristics.
Evolutionary algorithms have been also used in text plan-
ning. In [Duboue and McKeown, 2002] the authors present
a technique to learn a tree-like structure for a content plan-
ner from an aligned corpus of semantic inputs and corre-
sponding, human produced, outputs. They apply a stochastic
search mechanism with a two-level fitness function to create
the structure of the planner. Genetic algorithms are also used
in [Mellish et al, 1998] where the authors state the problem
of given a set of facts to convey and a set of rhetorical re-
lations that can be used to link them together, how one can
arrange this material so as to yield the best possible text.
An important conclusion to draw from these efforts is the
suitability of evolutionary techniques for natural language
generation tasks in which the form plays a significant role,
to the extent of sometimes interfering with the intended con-
tent, such as is the case for lyrics generation.
3 An Evolutionary Submodule for a Simple
Generator
The work presented here is intended to be a module for the
tasks of referring expressions generation and aggregation en-
closed in the architecture of cFROGS [Garc??a et al, 2004].
cFROGS is a framework-like library of architectural classes
intended to facilitate the development of NLG applications.
cFROGS identifies three basic design decisions: what set of
modules to use, how control should flow between them, and
what data structures are used to communicate between the
modules.
We have tested the implementation of the module in an ex-
isting application: ProtoPropp [Gerva?s et al, 2004]. This
is a system for automatic story generation. The natural lan-
guage generator module of ProtoPropp ? implemented as a
pipeline architecture of cFROGS modules ? perform tasks
such as content determination - selecting the particular con-
cepts that are relevant - and discourse planning - organising
them in an orderly fashion. These tasks are currently carried
out in a traditional manner and simply provide the data for the
evolutionary stages. In the previous prototype of ProtoPropp
the referring expression to use for a concrete concept was de-
termined using a very simple heuristic: the first time that the
concept appears in the paragraph, the generator uses its full
noun, in all other cases it uses a pronoun. When using a full
noun reference, it is indefinite for the first appearance of the
concept in the text and definite for the rest.
The input of the evolutionary algorithm is a basic discourse
structure where each phrase is a message about a relation be-
tween two concepts or a description of some attribute of an
element. Additionally, this submodule has access to a knowl-
edge base of conceptual information about the discourse el-
ements that appear in the input (characters, locations, at-
tributes, relations).
In this simple evolutionary algorithm, the appearances of
the concepts are considered as the genes. The initial popu-
lation is generated randomly, using for each concept its full
noun or its pronoun. When using the full noun, a selection of
the attributes the concept has in the knowledge base is cho-
sen. These attributes will appear just before the noun of the
concept, as it is usual in English. The system works over
this population for a number of generations determined by
the user. In each generation three genetic operators are used:
crossover, mutation and aggregation. Finally, at the end of
each generation each tale is evaluated and a selection of the
population is passed to the next one, in such way that the tales
with a higher fitness have more possibilities of being chosen.
3.1 Data Representation and Genes
Within the context of the larger cFROGS architecture, data
are represented as complex data structures with generic inter-
faces to ensure easy connectivity between different modules
[Garc??a et al, 2004]. These data follow ideas from the RAGS
[Cahill et al, 2001] generic architecture. However, the no-
tation described here corresponds to a representation internal
to the module intended to facilitate the operation of the evo-
lutionary techniques.
Characters, locations and attributes are represented as
simple facts containing an unique identifier (to distinguish
each specific character and location from the others) and their
names. The identifier in attributes corresponds to the con-
cept that holds the attribute, and the name corresponds to the
attribute itself. The current prototype operates over simple
linguistic constructs: the description of a concept using an
attribute, or a relation between two concepts. Pronominal
reference is indicated by changing the name of the concept
for ?pron?, and definite and indefinite reference is indicated
by adding a fact ?ref? indicating if the reference is definite or
indefinite. Finally, the concepts may go along with some at-
tributes preceding the name of the concept, as in ?the pretty
blonde princess?. This list of attributes is represented be-
tween -> and <-.
A sample part of a draft for the evolutionary algorithm
would be the following:
[character(ch26,princess),
ref(ind),
->attribute(ch26,pretty)<-,
relation(ch26,l14,live),
location(l14,castle),
ref(ind)]
[character(ch26,pron),
relation(ch26,ch25,love),
character(ch25,knight),
ref(ind)]
[character(ch26,princess),
ref(def),
isa(),
attribute(ch26,blonde)]
In this example, the set of genes would be this:
Genes:
0: character(ch26,princess),
ref(ind),
->attribute(ch26,pretty)<-
1: location(l14,castle),
ref(ind)
2: character(ch26,pron)
3: character(ch25,knight),
ref(ind)
4: character(ch26,princess),
ref(def)
3.2 The Genetic Operators
Three genetic operators are used: crossover, mutation and ag-
gregation.
For the crossover operator, two drafts are selected ran-
domly and crossed by a random point of their structure. So,
each of the sons will have part of each of the parents.
In the case of the mutation operator, some of the genes are
chosen randomly to be mutated. If the gene is a pronoun -
as in ?she lived in a castle? -, it will change into the cor-
responding full noun, always associated with a subset of its
possible attributes - for example ?the princess lived in a cas-
tle? or ?the pretty princess lived in a castle? -. In case the
Correct Referent error1 =
?
pronominal references to a concept not referred in full in the two previous genes
Redundant Attributes error2 =
?
?<adj> X is <adj>? sentences
Reference Repetition error3 =
?
repeated use of same set of attributes ? att(geni) ? to refer to the concept in geni
Coherence error4 =
?N
i=1(att(geni) ? I) with I the set of attributes used before for the concept in geni
Overlooked Information error5 =
?
subset of attributes of concept i in the ontology not mentioned in the text
Table 1: Definition of fitness functions
gene was a full noun - as in ?the pretty princess? -, there are
two options: to change it into a pronoun - in this case ?she?
-, or to change the subset of attributes that appear with it -
for example ?the princess? or ?the pretty blonde princess? -.
One of these two options is chosen randomly.
The aggregation operator addresses the task of deciding on
the aggregation between concepts and their attributes. This
involves a certain modification of the structure of the text,
because sentences in the text may be deleted if the informa-
tion they impart becomes part of a previous sentence. The
aggregation operator acts only on genes corresponding to ex-
plicitly mentioned concepts: concepts referred by pronouns
are excluded. It can act in two directions:
? If the reference to the concept appears with one or more
attributes - as in ?A blonde princess lived in a castle.?
-, the operator disaggregates the attributes by eliminat-
ing their mention and adding a corresponding ?X is Y?
sentence - resulting in ?A princess lived in a castle. She
was blonde.?
? If the reference to X has no attributes - as in ?A princess
lived in a castle.? -, the algorithm looks for an ?X is Y?
sentence - such as ?The princess was blonde.? -, adds
the corresponding attributes to the reference, and deletes
the ?X is Y? sentence - resulting in ?A blonde princess
lived in a castle.?
The goal of this definition of the aggregation is to ensure
that the attributes of a concept are mentioned in the appear-
ance of a concept or in the correspondent ?X is Y? sentences,
but not in both. As the aggregation operator is used randomly,
the desired result is obtained only in some cases.
3.3 The Fitness Function
The key to the evolutionary algorithm lies in the choice of
fitness function. A simple approach would be to require that
in each generation the user reads all the texts and gives them
a fitness value. The number of generations and individuals in
the population for a simple experiment makes this approach
impractical.
We have defined five different fitness functions as shown in
Table 1. This definitions are the results of the analysis of the
features of human-generated text.
For the evaluation of each of the drafts that form the popu-
lation, we use the following formula:
fitness = 1/(
?
i
errori + k)
In this way, the fitness would be greater when the error is
smaller. The constant k is used to avoid divisions by zero. In
our experiments it was set with the value 1, so the maximum
possible fitness was 1.
4 Experiments and Results
To test the feasibility of the idea of using together NLG and
EAs, we have formalized five different fairy tales, mainly dif-
ferentiated by their lengths in number of genes, that is, in
appearances of concepts. We must take into account that the
number of genes shown below are not completely exact, be-
cause the aggregation operator can erase or add new sentences
to the tale. These are the tales formalized and used to do the
experiments:
? Cinderella: 102 genes
? Hansel and Gretel: 90 genes
? The Lioness: 50 genes
? The Dragon: 32 genes
? The Merchant: 31 genes
For each of these tales we have made several experiments
using different population sizes (10, 25, 50, 100, 200, 300,
500) and number of generations (10, 25, 50). The three ge-
netic operators mentioned before (crossover, mutation and
aggregation) are applied, and the five fitness functions used
for the evaluation of the tales.
Table 2: Table of numerical results
In Table 2 we can see the numerical results of the experi-
ments. For each combination of population size and number
Figure 1: Legend for the tales
of generations results shown have been averaged over a num-
ber of runs.
We can analyse these results taking into account the three
different number of generations used. The legend for the fol-
lowing graphics is shown in Figure 1.
4.1 10 Generations
As we can see in Figure 2, only 10 generations are not enough
for the bigger tales. However, in the case of the smaller ones,
the fitness values increase with the size of the population, and
at certain point they achieve the maximum value of 1.
Figure 2: Fitness values of the tales with 10 generations
4.2 25 Generations
In Figure 3 the fitness values for the bigger tales are higher
than in the case of 10 generations, but still not good enough.
For the smaller tales we achieve the maximum fitness value
of 1 quicker than with only 10 generations.
4.3 50 Generations
We can see in Figure 4 the best values achieved in the ex-
periments. For the smaller tales, we get the maximum fitness
value of 1 very quickly. In the case of the bigger ones, the
fitness values are higher than in the previous experiments, but
not very good yet, except in the case of ?The Lioness?, where
the maximum value of 1 is achieved with 50 generations and
500 individuals in the population.
5 Discussion
To start with, EAs seem to be a good approach to solve the
tasks addressed, and in all the experiments the results ob-
tained are better than the ones achieved using previous heuris-
tics. An example of generated text with the initial simple
heuristic is:
Figure 3: Fitness values of the tales with 25 generations
Figure 4: Fitness values of the tales with 50 generations
A princess lived in a castle. She loved a knight.
She was pretty. She was blonde. It had towers. It
was strong.
Using the evolutionary module the same piece of tale is
generated as follows:
A pretty princess lived in a strong castle. She
was blonde. The princess loved a brave knight. The
castle had towers.
The second example shows that the texts generated by the
evolutionary module are richer from the point of view of ad-
jectives and structure.
Note that depending on the number of genes you need a
certain number of individuals and generations to achieve a
good fitness value. For example, ?The Lioness?, with 50
genes, gets the maximum fitness with 50 generations and 500
individuals, as long as ?Hansel and Gretel? and ?Cinderella?
would need more generations and individuals to get the max-
imum fitness.
Another important point is that in a specific tale, with a
specific number of genes, you can achieve the same results
increasing the number of generations or the size of the popu-
lation. For instance, ?The Merchant?, with 31 genes, gets the
maximum fitness with both 25 or 50 generations with small
populations or 10 generations with populations of more than
100 individuals.
Finally, it is important to note that our approach presents
some differences respect to the one of Reiter and Dale [Re-
iter and Dale, 1992]. As we have already mentioned, we are
working in the field of the fairy tales, with the specific re-
quirements of story generation. An important point is that
these are not informative texts, and therefore we can relax
some constraints taken into account in other works in the area
of referring expressions.
6 Conclusions and future work
With respect to both of the tasks addressed, the output texts
respect the specific constraints required for the text to be ac-
ceptable, while at the same time showing reasonable variation
between the different options much as a human-generated text
would. We are working on extending the system to allow the
use of proper nouns to describe some concepts, as an addi-
tional option to pronouns and descriptive references, includ-
ing the revision of the genetic operators and the introduction
of new evaluation functions to estimate the correct applica-
tion of proper nouns.
In view of these results, in future work we want to apply
EA techniques to other tasks of NLG, such as content de-
termination and discourse planning. The particular advan-
tages of evolutionary techniques, combined stage by stage in
this manner, may be an extremely powerful method for solv-
ing natural language generation problems while also profiting
from classic NLG techniques.
It would be also interesting to compare our solution with
different approaches found in the literature, as for example
[Reiter and Dale, 1992] or [Krahmer and Theune, 2000] for
the referring expression generation, and the one of Dalianis
and Hovy [Dalianis and Hovy, 1996] for the aggregation.
Finally, an evaluation as the one proposed in [Callaway and
Lester, 2001] would be useful to estimate the goodness of the
generated texts. The authors describe the evaluation of STO-
RYBOOK, a narrative prose generation system that produces
original fairy tales in the Little Red Riding Hood domain.
They pretend to evaluate multiple versions of a single story
assuring that the content is identical across them. Five ver-
sions of two separate stories are produced, a pool of twenty
students in English compare them, and at last they are ana-
lyzed with an ANOVA test.
References
[Cahill et al, 2001] L. Cahill, R. Evans, C. Mellish,
D. Paiva, M. Reape, and D. Scott. The RAGS reference
manual. Technical Report ITRI-01-07, Information Tech-
nology Research Institute, University of Brighton, 2001.
[Callaway and Lester, 2001] C. Callaway and J. Lester.
Evaluating the effects of natural language generation tech-
niques on reader satisfaction. In Proceedings of the
Twenty-Third Annual Conference of the Cognitive Science
Society, Edinburgh, UK, 2001.
[Dalianis and Hovy, 1996] H. Dalianis and E. Hovy. Ag-
gregation in natural language generation. In G. Ardoni
and M. Zock, editors, Trends in Natural Language Gen-
eration: an Artificial Intelligence Perspective,EWNLG?93,
pages 88?105. Springer Verlag, 1996.
[Duboue and McKeown, 2002] P.A. Duboue and K.R. McK-
eown. Content planner construction via evolutionary algo-
rithms and a corpus-based fitness function. In Proceedings
of the Second International Natural Language Generation
Conference (INLG 2002), Ramapo Mountains, NY, 2002.
[Garc??a et al, 2004] C. Garc??a, R. Herva?s, and P. Gerva?s.
Una arquitectura software para el desarrollo de aplica-
ciones de generacio?n de lenguaje natural. Sociedad
Espan?ola para el Procesamiento del Lenguaje Natural,
Procesamiento de Lenguaje Natural, 33:111?118, 2004.
[Gerva?s et al, 2004] P. Gerva?s, B. D??az-Agudo, F. Peinado,
and R. Herva?s. Story plot generation based on CBR. In
Anne Macintosh, Richard Ellis, and Tony Allen, editors,
12th Conference on Applications and Innovations in In-
telligent Systems, Cambridge, UK, 2004. Springer, WICS
series.
[Holland, 1992] J.H. Holland. Adaptation in Natural and
Artificial Systems. An Introductory Analysis with Applica-
tions to Biology, Control and Artificial Intelligence. MIT
Press, Cambridge, Massachusetts, Second Edition, 1992.
[Kibble and Power, 2000] R. Kibble and R. Power. An inte-
grated framework for text planning and pronominalization.
In Proc. of the International Conference on Natural Lan-
guage Generation (INLG), Israel, 2000.
[Krahmer and Theune, 2000] E. Krahmer and M. Theune.
Efficient context-sensitive generation of referring expres-
sions, 2000.
[Levy, 2001] R. P. Levy. A computational model of poetic
creativity with neural network as measure of adaptive fit-
ness. In Proccedings of the ICCBR-01 Workshop on Cre-
ative Systems, 2001.
[Manurung, 2003] H.M. Manurung. An evolutionary algo-
rithm approach to poetry generation. PhD thesis, School
of Informatics, University of Edinburgh, 2003.
[Mellish et al, 1998] C. Mellish, A. Knott, J. Oberlander,
and M. O?Donnell. Experiments using stochastic search
for text planning. In Eduard Hovy, editor, Proceedings
of the Ninth International Workshop on Natural Language
Generation, pages 98?107. Association for Computational
Linguistics, New Brunswick, New Jersey, 1998.
[Reape and Mellish, 1999] M. Reape and C. Mellish. Just
what is aggregation anyway? In Proceedings of the
7th European Workshop on Natural Language Generation,
Toulouse, France, 1999.
[Reiter and Dale, 1992] E. Reiter and R. Dale. A fast algo-
rithm for the generation of referring expressions. In Pro-
ceedings of the 14th conference on Computational linguis-
tics, Nantes, France, 1992.
[Walker et al, 1998] M.A. Walker, A.K. Joshi, and E.F.
Prince. Centering Theory in Discourse. Clarendon Press,
Oxford, 1998.
Proceedings of the 12th European Workshop on Natural Language Generation, pages 66?73,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Model for Human Readable Instruction Generation Using Level-Based
Discourse Planning and Dynamic Inference of Attributes Disambiguation
Daniel Dionne, Salvador de la Puente, Carlos Leo?n, Raquel Herva?s, Pablo Gerva?s
Universidad Complutense de Madrid
Madrid, Spain
{dionnegonzalez,neo.salvador}@gmail.com,
{cleon,raquelhb}@fdi.ucm.es,pgervas@sip.ucm.es
Abstract
This paper shows a model of automatic in-
struction giving for guiding human users
in virtual 3D environments. A multilevel
model for choosing what instruction to
give in every state is presented, and so
are the different modules that compose the
whole generation system. How 3D in-
formation in the virtual world is used is
explained, and the final order generation
is detailed. This model has been imple-
mented as a solution for the GIVE Chal-
lenge, an instruction generation challenge.
1 Introduction
Recent technology advances have made it possi-
ble to use handheld devices, like mobile phones
or PDAs, to guide the user by issuing commands
or descriptions about the world the user is per-
ceiving in some sense (Muller, 2002). This pos-
sibility opens interesting avenues of research in
the shape of Natural Language Generation (NLG)
Systems that adapt to the user in order to provide
him with the most accurate expression. However,
fully operational systems applicable in real life sit-
uations are difficult and expensive to implement.
Under these circumstances, virtual environments
may be seen as an intermediate solution, suitable
for fast prototyping of experimental solutions. Vir-
tual environments permit experimenting in a re-
duced, closed world, where everything that is rel-
evant for the purpose at hand is explicitly repre-
sented in a graphical model and under the direct
control of the researcher. This allows fast set up of
experimental situations where the topography, the
position of landscape features, colour, light con-
ditions and visibility factors can be modified and
adapted to suit the best conditions for testing par-
ticular approaches (Blue et al, 2002) or challenges
(such as guidance for disabled users with different
disabilities, for instance). In view of these obser-
vations, our research is focused on developing an
interactive virtual guide (VG), based on NLG, to
give to a human user the required set of instruc-
tions to complete a specific task.
Such a set of instructions is called a plan. For-
mally, a plan is a sorted-in-time list of instructions
that the user must fulfill in order to reach some
goal. There are many planning algorithms that,
with the proper world representation and a list of
goals, can return a list like this (LaValle, 2006).
The VG can take this basic plan as the actual set
of instructions to convert into natural language to
explain what the user must do to complete the task.
However, these instructions are usually exhaustive
(step by step) and very simple because they are
based on basic world representations (and inter-
pretations) and are simple enough to perform com-
putational operations on them. A VG that gener-
ates this kind of simple instructions, from the point
of view of a human user, can be tedious, boring
and a time wasting. Consider the discourse ?Turn
right. Turn right. Go ahead. Turn left. Press
button-1. Turn around. Go ahead. Go ahead. Take
item-1. . . ? as an example. Instead, the VG should
take advantage of the environmental knowledge of
the user inferring higher level instructions (less de-
tailed and more human-like) from the basic plan
(something more along the lines of ?Go press the
buton in the far wall, come back and take item-1?).
The difference is shown graphically for a simple
example in Figure 1.
There are several aspects to be considered in
achieving this goal. First, a human guide would
phrase his or her instructions at different levels of
abstraction, to optimise the communicative effect
of his/her utterances in terms of striking balance
between sufficient informative content and econ-
omy of expression. Second, a human guide may
operate in a reactive manner, providing additional
feedback whenever the user requests help. But
66
7 instructions 1 instruction
Figure 1: A comparison of a step by step plan
versus a human readable plan like ?Walk out the
door?. Note the difference in the number of in-
structions given.
human guides are also likely to observe the per-
son that is being guided, and be ready to intervene
proactively if they notice the user seems lost or at
risk. These two points are elaborated below.
In order to build more human levels, a VG must
consider the virtual environment in a manner as
close as possible to the way a human being senses
the real world. To model the different levels of ab-
straction employed by human guides, a good solu-
tion may be to model the world as a hierarchy of
spatial levels. People tend to limit the area where
they do certain activities by some kind of logical
borders. Sometimes, these borders match physi-
cal borders such as the walls that define a room
or a corridor, the outside perimeter of a building,
the limits of a park, or a city boundary. In other
cases, such as outdoor settings, borders can be
more abstract, such as the line of horizon in all di-
rections from the observer?s current position. The
areas defined by these borders may be contained
inside one other, resulting in a tree-like structure
from the smallest spaces to greater areas, i.e. from
the room where the user is standing to the city he
lives in. Of course, the areas are connected in a
multigraph way where each edge is a connection
like a door or a natural transition. To build a us-
able model of this type of cognitive representation
of the world is far from trivial. We will describe
how we faced this point in Section 3.1 (Construct-
ing the World). Considering such a hierarchical
view of the environment when generating instruc-
tions, results in more natural and human-friendly
results. Instructing someone to ?exit the room?
works better than asking them to ?advance until
passing through the door?; ?leave the building
using the main entrance? is better than a set of
instructions refering to more specific spaces like
?exit this room, now go down the stairs, now go to
the elevator? and so on. We return to this matter
in Section 3.2 (Planning the Discourse).
The issue of abstractions in world modelling
also affects a different language generation task:
referring expression generation. In providing in-
structions, human guides often refer to abstract
concepts such as corners or ?the middle of the
room?. These are not usually represented explic-
itly in your run of the mill world representation,
which usually prevents NLG systems from em-
ploying them as means of optimising references.
In Section 3.4 (Hidden Reference Discovery), we
will see how, besides visible information, a natural
approach based on the inference of other ?hidden?
elements or references that can be extracted from
the environment helps to reduce the length of the
explanation needed, and to build better references.
These elements are hidden because they are not
visible or trivial, and they require a specific study
and calculation.
The second point to consider is reactive versus
proactive guidance. A reactive guidance system
may rely on feedback from the user to decide when
to intervene. Consider the following two represen-
tative examples: the user can say ?I did not un-
dertand last instruction? and the VG system can
answer by repeating the instruction or building a
new one phrased in a different way but with the
same meaning; or the user can say ?I am lost?
and the VG will ask the planning software to re-
calculate the plan considering the new user?s sit-
uation. However, there are situations where the
user may not realize that he is lost or that he is
about to perform a dangerous action (like walking
on a slippery surface, pressing an incorrect button,
going in the wrong direction or crossing a street
when the traffic light is red). A good guide will
warn the user before he does something wrong but
it should not oppress the user each time he decides
to explore another route to reach the goal. In other
words, the VG must watch the user actions and
take part when he is on the verge of commiting
a serious mistake. We will discuss about how to
warn the user in Section 3.3 (Warning the User).
2 Previous Work
Many NLG systems have considered generation
of instructions in the past. A good review is pro-
vided in (Bourne, 1999). However, most existing
instruction generating system focused on perform-
67
ing different types of static actions (actions that do
not involve changes of location of the user). The
present work is focused on the task of guiding the
user through virtual environments.
The GIVE (Generating Instructions in Virtual
Environments) Challenge (Byron et al, 2007) op-
erates on a scenario where a user has to solve a
particular task in a simulated 3D space. A gen-
eration module has to guide the human user using
natural language instructions. A software architec-
ture is provided that allows the generation module
to abstract away from the rest of the system, while
having access to world information from the 3D
environment, user feedback from the client mod-
ule, and plans generated by an off-the-shelf plan-
ner. The work presented in this paper arose from
the author?s participation in the GIVE Challenge,
and relies on the software architecture provided
for the challenge to implement all details of the
system other than the NLG module.
A fundamental task to be solved for correct in-
struction generation is the construction of appro-
priate referring expressions. This task has been
the object of many research efforts in the recent
past. To construct a reference to a particular en-
tity, the algorithm takes as input a symbol corre-
sponding to the intended referent and a list of sym-
bols corresponding to other entities in focus based
the intended referent, known as the contrast set.
The algorithm returns a list of attribute-value pairs
that correspond to the semantic content of the re-
ferring expression to be realized. The algorithm
operates by iterating over the list of available at-
tributes, looking for one that is known to the user
and rules out the largest number of elements of the
contrast set that have not already been ruled out.
Referring Expression Generation in physically
situated environments has been studied in (Kelle-
her and Kruijff, 2005). The goal of this work is to
develop embodied conversational robots that are
capable of natural, fluent visually situated dialog
with one or more interlocutors. In this kind of
situation a very important aspect to take into ac-
count is how to refer to objects located in the phys-
ical environment. The authors present in the paper
a computational framework for the generation of
spatial locative expressions in such contexts, rely-
ing on the Reiter and Dale (Reiter and Dale, 1992)
algorithm.
Another interesting work related to referring ex-
pression generation in spatial environments can be
found in (Varges, 2005). The author uses the maps
of the Map Task dialogue corpus as domain mod-
els, and treats spatial descriptions as referring ex-
pressions that distinguish particular points on the
map from all other points (considered as distrac-
tors).
Related research can be found in (Stoia et al,
2006), where a study of how humans give orders in
navigation environmnets and an algorithm imple-
menting the observed behaviour is shown. There
are many other approaches to instruction giving.
Directly related with this work, it is worth men-
tioning CORAL (Dale and Geldof, 2003), which
shows a full architecture for instruction giving,
and REAL (Muller, 2002), which shows a multi-
modal system (graphics and text) for communicat-
ing with the user, adapting them to user behaviour.
3 A Functional Model of a Virtual Guide
The model of a virtual guide presented here ad-
dresses four specific issues: how to construct a
representation of the world with higher levels of
representation, how to generate higher instructions
referring to the more abstract levels of represen-
tation, how the construction of references is im-
plemented in terms of reference agents. A brief
overview of the complete architecture of the mod-
ule is also included.
3.1 Constructing the World
In GIVE, the world is discretized as a set of tiles.
These tiles are the minimum portions of space and
the user can move around from tile to tile. Orienta-
tions are discretized: the user can only face North,
East, South or West. By default, the world consists
of an infinite area of adjacent and accesible tiles.
World representation assertations may state there
is a wall between two adjacent tiles, blocking ac-
cess from one to other. A 3D representation of this
basic world gives the user an illusion of rooms but,
from the point of view of the VG there is no data
structure that reflects a hierarchy of rooms. This
representation does not fit very well with the hu-
man sense of space, so a more abstract one had to
be built to provide the abstract referents (rooms,
corners, intersections, doors...) which we wanted
our guide to use.
The first problem we had was defining a room.
In architecture, a definition of room is ?any dis-
tinguishable space within a structure?, but distin-
guishable is too vague to be of use. Figure 2 illus-
68
A) One big room
B) Three smaller rooms
Figure 2: Defining a distinguishable space.
trates the problem of defining when two spaces are
distiguishable. Notice the only difference betwen
A and B is the width of the gaps in relation to the
size of the rooms. This problem has been exten-
sively studied in robotics. An interesting exam-
ple (Galindo et al, 2005) consists on identifying
interconected ?open spaces? in order to obtain an
adjacency graph. From that graph, another graph
can be calculated, grouping spaces to form rooms,
corridors, etc.
For practical purposes, we have decided to con-
sider that two spaces are distinguishable when the
user has to go through a door to get from one to the
other, with a door being a one-tile gap in a wall.
Based on this definition, we have developed an
algorithm to group adjacent tiles into rooms. The
idea is to follow a wall around the room until the
starting point is reached, thereby establishing the
perimeter of the room, then establish the set of
tiles corresponding to the room using a floodfill
algorithm. Breaks in walls are handled by check-
ing whether they are small enough to be consid-
ered doors into other rooms or not. If they are
doors, they are noted as entrances to other rooms
(which are stored in a room list for subsequent pro-
cessing). If they are not, the wall beyond the gap
is followed as part of the boundary of the current
room. A small practical example of the algorithm
in operation is shown in Figure 3.
Adjoining rooms stored in the room list are
recursively processed. Each new room discovered
is connected to its adjacent rooms to obtain a high
level map of the available space. An analyzer is
applied to each room to establish its type (room,
hall, corridor, etc) and additional properties such
as size or shape. This new world representation
A) First, nd anywall B) Not a door,the gap is too big
C) Was not a door,so go back. D) Small gap (door),so add it to DC.
Figure 3: Looking for rooms.
GOAL
A5
A3
H1 H2 H3 H5H4
A5
Time ow 
H7H6
Figure 4: Tree representation of the plan at several
levels.
allows the VG to refer to doors and rooms.
3.2 Planning the Discourse
Discourse planning must take place at two differ-
ent levels of detail. The VG must plan the dis-
course corresponding to the whole set of instruc-
tions to be imparted until the final goal is reached.
But it also needs to plan how much of that is to
be communicated to the user in the next turn of
the dialogue. We solve the first issue by build-
ing a multi-level representation of the expected
discourse for the whole of the plan to be carried
out by the user. This representation is structured
like a tree, with the set of low-level instructions as
leafs, and subsequent nodes of the tree represent-
ing higher level instructions that group together
the lower level instructions represented by their
subtrees. The solution to the second issue is de-
scribed below.
We define action as anything the user can do
69
Line of sightCheckpoint User?sroute
Figure 5: An n-shaped room does not let the user
see the exit of the room so VG can guide the user
from checkpoint to checkpoint.
that modifies the state of the world and instruc-
tion as an action that the user should perform in
order to advance in the plan. Instructions are de-
fined in terms of preconditions and postconditions.
Preconditions are conditions that must be satis-
fied for the instruction to be performed, and post-
conditions are the conditions that must be satisfied
to consider the instruction done. The instruction
tree representation of the plan is built by group-
ing together sets of low-level instructions into a
single high-level instruction. For instance, we
group all tile-by-tile steps inside the same room
to build a new instruction such as ?go from room1
to room2?. We do not discard any low-level in-
struction, we just group them under the new high-
level instruction, building a tree that represents the
plan at different levels of abstraction (see Figure
4). This allows the user to fall back on low-level
instructions at need (if, for instance, the light goes
out and the VG has to guide him step by step).
An additional abstraction has been introduced
to account for the tendency of humans to break
the description of a complex path (where not all
of the path is visible at the start) into segments
made of the portions of the path that are visible at
each particular point (see Figure 5). The concept
of checkpoint is introduced for the end of each of
these segments.
We have defined five types of high-level in-
structions: MovementInstruction (guides the
user from tile to tile), CheckPointInstruction
(guides the user from a his current position to
a checkpoint), Room2RoomInstruction (guides
the user from room to room), ActionInstruc-
tion (tells the user to interact with some ele-
ment) and GoalInstruction (subtype of ActionIn-
struction concerned with achieving the final goal).
Each of these high-level instructions has its own
preconditions and postconditions.
The issue of how much of the instruction tree
representation of the plan is addressed in terms of
two conditions: how far in the original plan the
user has advanced, and what level of abstraction is
required for the next instruction. The first condi-
tion is easily checked over the state of the world, to
establish what the current situation is. The second
condition is determined by checking for satisfac-
tion of preconditions and postconditions of the in-
structions at all possible levels that start from the
current situation. The check starts at the highest
possible level.
Instructions whose postconditions are already
satisfied are pruned from the tree, as there is no
longer any need to provide that instruction to the
user. If preconditions are met but postconditions
are not, the VG uses this instruction in the next
turn, and then waits for a user action. If neither
postconditions nor preconditions are satisfied for
this instruction, the next (lower) level of instruc-
tions in the instruction tree is considered instead
of this one. These decisions are handled by mod-
ules known as Guide Agents.
3.3 Warning the User
If the user is going to cross a street when the traffic
light is red, the VG will have to warn him about it.
If the warning information is more important than
the guiding, the VG will have to delay instruction
giving, and warn the user first. To decide about the
importance of the warning part of the discourse,
we defined agents as entities in charge of watch-
ing for special situations. Each agent takes care of
a specific kind of situation that may imply some
sort of hazardous or bad result. They are all inde-
pendent, and may differ depending on the kind of
environment, goals or even the kind of user.
Each agent has a weight that reflects its priority
when being considered. An agent always evalu-
ates its situation and returns a value in the [0, 1]
interval. A near zero value means there are low
probabilities for the situation to happen and a near
to one value means the situation is on the verge
to happening. All agents that exceed a threshold
value will be considered as contributors to the dis-
course. We sort them in descending order based
on the result of multiplying each return value by
the weight of the agent. If an agent is considered
70
as a contributor, its warning is introduced in the
discourse.
We defined three types of agents: information
agents watch for interesting hotspots in an area,
status agents watch over the user?s status, and
area agents watch over special areas, including
dangerous areas.
In our entry for the GIVE challenge there was
a status agent that checked how much time had
passed since the last user action to identify when
the user might be lost. There was one agent that
checked for booby traps the user might step on
(some of them resulted in loosing the game in-
mediately). Another one ensured the user re-
mained within a security area that abstracted all
possible common routes to reach the intended des-
tination. If a user leaves the security area, he is
going in the wrong direction.This security area is
dynamicaly updated attending to the current user?s
position. Finally, alarm agents watch for wrong
actions, controlling if user is on the verge of press-
ing the wrong button or leaving the room using
a wrong exit. We implemented no information
agents, but they would be interesting in real sit-
uations.
3.4 Hidden Reference Discovery
The center spot in a room is not a visible or tan-
gible object, and finding it requires a non-trivial
calculation of the room?s shape. Adding it to
the references container can help creating simpler
and richer sentences. A reference like ?the table
across the room? can be generated when the lis-
tener and the target are in line with the center spot
of the room, on opposite sides, independently of
where the user is facing. In an indoor environ-
ment, architectural elements usually make many
inferences possible. Two hallways that intersect
make an intersection, two walls make a corner, etc.
and though these elements might not be referenced
as they are in the given environment, they should
be taken into account. In a similar way, hidden
relations discovery can be accomplished. Object
alignments or arrangements can be revealed and
used for the same purpose. Sentences like ?the car
in line with these pillars? can be generated. All of
these additional high-level concepts and relations
between them and low-level world entities are ob-
tained by abstraction over the available represen-
tation. We create a family of reference agents,
each one specialized in identifying candidate dis-
Oppositethe green door
Room Center
Corner
Betweenthe bluedoors
Figure 6: Hidden references in a room.
ambiguating properties of a different kind. Some
of these properties are already explicit in the world
representation (colour) and some require a pro-
cess of abstraction (relations to corners, for in-
stance). Once obtained, they become available as
additional properties that may be used to disam-
biguate references.
The goal of our design is to leverage the sys-
tem?s ability to express itself using different com-
binations of the complete set of disambiguating
properties made available in this manner. This
gives system designers a choice between having
many simple agents or fewer more expressive,
complex agents. This choice should be considered
in terms of particular implementation details.
Reference agents rely on the Reiter and Dale al-
gorithm (Reiter and Dale, 1992). Considering a
list of distractors and the reference object, the goal
is to filter the distractors list, building a reference
that takes out all the distractors, so that the refer-
ence is good, not ambiguous. Each reference agent
has the ability of taking out a different set of dis-
tractors, using different properties that are trivial
or hidden, as explained above. Combining these
agents in different ways generates different refer-
ence sentences, some of them longer but more spe-
cific, others shorter but ambiguous. What we tried
to achieve is to find the right combination of refer-
ence agents that create the shortest non-ambiguous
sentence. This is not a natural approach, as some-
one could prefer to have an ambiguous (but more
human) spatial relation (Viethen and Dale, 2008)
in a reference sentence. Or for example, someone
could prefer having a longer reference like ?the big
red box that?s on the third shelf from the bottom?
than a perfectly specific (but not natural) reference
like ?the 3 kg box?.
71
REALWORLD
WORLDANALYSIS EXPANDEDWORLD
GOALS
DISAMBIGUATION
APPROXIMATION STAGE
ALERTS
INSTRUCTION TREE1
2
3
LEVELS
GUIDE MANAG
ERGUIDE AGENT 1GUIDE AGENT 2
G. 3.1G. 3.n ...
REFER
RER M
ANAGE
R ReferrerReferrerReferrer
Referrer
ReferrerReferrerALARM
 MANA
GERAlarm AgentAlarm AgentAlarm AgentAlarm Agent
Alarm Agent
Alarm Agent
GOAL SUBSETCURRENTINSTRUCTION
GOAL
PLANNER
generatedoutput
GENERATIONMANAGER
Figure 7: General design.
3.5 Guide architecture
The architecture design can be divided into two
main parts. The instruction tree, shown as three
interconnected lists in Figure 7, that contains all
the generated levels of instructions as explained
in section 3.2, and a set of components that per-
form the different guiding tasks. One input for the
system is the ?Real World?, as opposed to the Ex-
panded World that is generated after the analysis,
as explained in sections 3.1 and 3.4. The second
input is the set of goals to be achieved. After the
basic instruction set is generated by the planner
from the given set of goals, the instruction tree is
generated, level by level.
Figure 7 represents a state of the guiding pro-
cess where the user is trying to achieve some in-
termediate GOAL. The current instruction marker
represents the location of the instruction that is to
be given to the user to achieve the current GOAL
(the one on the upper level). Since at this point
the system has determined that level 2 instructions
should be used, the level 2 subset of instructions
are represented here as part of the current instruc-
tion. As explained in section 3.2, the algorithm
chooses what level should be used at each mo-
ment.
The Guide Manager makes use of the Alarm
Manager and Referrer Manager to create the
proper output. As explained in 3.3, the Alarm
Agents examine the environment, and tell the
Guide Manager if the user should be warned about
any hazardous situation. The Referrers help build-
ing the proper reference sentences, as explained
in sections 3.2 and 3.4, finally the different Guide
help building the proper guiding sentences. The
Guide Manager sends the output to the Genera-
tion Manager, which is in charge of generating the
final output.
4 Discussion
The layered, multilevel hierarchy tries to imitate
the way humans think about local plans, and the
agent based view attemps to make instruction giv-
ing proactive rather than reactive. The algorithm
first gives generalistic, global orders to get the
user near the particular objective. Then, once
the irrelevant information has been removed from
the user point of view and it can not confuse the
user, more specific orders are given. In this way,
the algorithm decides what to say the ?human
way?. Although the ?human? generation of in-
structions could have been obtained with different
algorithms, doing it the same way creates a more
maintainable, natural form of expressing the oper-
ation. It would be interesting to input real human
data, as done in (Stoia et al, 2006), in order to
guarantee this objective.
Traditionally, planning systems have certain
world representation based on discrete states
which are more or less useful for finding a good
solution (Chih-Wei Hsu and Chen, 2006). How-
ever, this representation is not necessarily useful
for creating a natural language representation of
each planning operator. For a good instruction
to be generated, plain operators like ?turn right?
usually do not contain much information. Instruc-
tion generation systems have to find a compromise
between planning efficiency and natural language
content. Creating the instruction tree depends di-
rectly on figuring out what elements to include in
the discourse.
The architecture shown in Section 3 has been
designed with adaptability in mind, following the
architecture presented in (Dale and Geldof, 2003).
This shows a module layout where the text plan-
72
ner and the surface realizer are independently con-
nected in the generation pipeline.
5 Conclusions and Future Work
The decisions to consider higher level of abstrac-
tion for both the representation of the world and
the granularity of instructions, and the introduc-
tion of alarms have shown very satisfactory results
over informal tests with users. Further evaluation
is in process as part of the GIVE Challenge (Koller
et al, 2007)1. The decisions presented in this pa-
per should be revised in view of these results. The
definition of a security area enables the system to
provide suitable warning when the user really goes
out of the way, but makes the system robust with
respect to minor variations with respect to the lit-
eral plan provided by the planner.
The GIVE challenge set up was a good starting
point to begin our experiments, but we are con-
sidering more complex environments to test ad-
vanced features. Extensions that promise interest-
ing challenges are: the consideration of a contin-
uous world representation (rather than discretised
in terms of tiles and four cardinal points), more re-
alistic test maps to extend the level of hierarchy to
buildings and urban areas, and new environments
designed to experiment with distorted representa-
tions of the scenary in order to simulate physical
impediments like blindness.
Acknowledgments
This research is funded by the Ministerio de In-
vestigacio?n, Ciencia e Innovacio?n (GALANTE:
TIN2006-14433-C02-01), and Universidad Com-
plutense de Madrid and Comunidad de Madrid
(MILU: CCG07-UCM/TIC 2803).
References
Russell S. Blue, Jeff Wampler, G. Bowden Wise,
Louis J. Hoebel, Boris Yamrom, Christopher R.
Volpe, Bruce Wilde, Pascale Rondot, Ann E. Kelly,
Anne Gilman, Wesley Turner, Steve Linthicum, and
George Ryon. 2002. An automated approach and
virtual environment for generating maintenance in-
structions. In CHI ?02: CHI ?02 extended abstracts
on Human factors in computing systems, pages 494?
495, New York, NY, USA. ACM.
Juliet C. Bourne. 1999. Generating Effective Natu-
ral Language Instructions based on Agent Expertise.
Ph.D. thesis, University of Pennsylvania.
1The results of this challenge will be made available as
part of the ENLG 2009 Workshop.
Donna Byron, Alexander Koller, Jon Oberlander, Laura
Stoia, and Kristina Striegnitz. 2007. Generating in-
structions in virtual environments (GIVE): A chal-
lenge and evaluation testbed for NLG. In Proceed-
ings of the Workshop on Shared Tasks and Compar-
ative Evaluation in Natural Language Generation,
Arlington.
Ruoyun Huang Chih-Wei Hsu, Benjamin W. Wah and
Yixin Chen. 2006. Handling soft constraints and
goals preferences in SGPlan. In ICAPS Workshop
on Preferences and Soft Constraints in Planning.
Robert Dale and Sabine Geldof. 2003. Coral: Using
natural language generation for navigational assis-
tance. In Proceedings of the 26th Australasian Com-
puter Science Conference.
C. Galindo, A. Saffiotti, S. Coradeschi, P. Buschka,
J.A. Fernandez-Madrigal, and J. Gonzalez. 2005.
Multi-hierarchical semantic maps for mobile
robotics. Intelligent Robots and Systems, 2005.
(IROS 2005). 2005 IEEE/RSJ International Confer-
ence on, pages 2278?2283, Aug.
John D. Kelleher and Geert-Jan M. Kruijff. 2005. A
context-dependent algorithm for generating locative
expressions in physically situated environments. In
Proceedings of ENLG-05, Aberdeen, Scotland.
Alexander Koller, Johanna Moore, Barbara di Eugenio,
James Lester, Laura Stoia, Donna Byron, Jon Ober-
lander, and Kristina Striegnitz. 2007. Shared task
proposal: Instruction giving in virtual worlds. In
Michael White and Robert Dale, editors, Working
group reports of the Workshop on Shared Tasks and
Comparative Evaluation in Natural Language Gen-
eration.
S. M. LaValle. 2006. Planning Algorithms. Cam-
bridge University Press, Cambridge, U.K. Available
at http://planning.cs.uiuc.edu/.
Christian Muller. 2002. Multimodal dialog in a mobile
pedestrian navigation system. IDS-2002.
E. Reiter and R. Dale. 1992. A fast algorithm for the
generation of referring expressions. In Proceedings
of the 14th conference on Computational linguistics,
Nantes, France.
Laura Stoia, Donna Byron, Darla Shockley, and Eric
Fosler-Lussier. 2006. Sentence planning for real-
time navigational instructions. In Proceedings of
the Human Language Technology Conference of the
North American Chapter of the ACL.
Sebastian Varges. 2005. Spatial descriptions as refer-
ring expressions in the maptask domain. In Proc. of
the 10th European Workshop on Natural Language
Generation.
Jett Viethen and Robert Dale. 2008. The use of spatial
relations in referring expression generation. In Fifth
International Natural Language Generation Confer-
ence.
73
Proceedings of the 12th European Workshop on Natural Language Generation, pages 187?188,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Evolutionary and Case-Based Approaches to REG: NIL-UCM-EvoTAP,
NIL-UCM-ValuesCBR and NIL-UCM-EvoCBR
Raquel Herva?s and Pablo Gerva?s
Natural Interaction based on Language (NIL)
Universidad Complutense de Madrid
raquelhb@fdi.ucm.es, pgervas@sip.ucm.es
1 Evolutionary Approach to Attribute
Selection
We propose the use of evolutionary algorithms
(EAs) (Holland, 1992) to deal with the attribute
selection task of referring expression generation.
Evolutionary algorithms operate over a population
of individuals (possible solutions for a problem)
that evolve according to selection rules and ge-
netic operators. The fitness function is a metric
that evaluates each of the possible solutions, en-
suring that the average adaptation of the popula-
tion increases each generation. Repeating this pro-
cess hundreds or thousands of times leads to very
good solutions for the problem.
We encode as a fitness function the specific con-
straints required for the reference to be acceptable.
The crossover and mutation genetic operators en-
sure a reasonable variation between the different
options much as a human-generated text would.
Each individual is represented by a set of genes
that are the list of possible attributes in the refer-
ence. Each gene has an associated value of 0 (if the
attribute is not included in the reference), or 1 (if
the attribute is included in the reference). The ini-
tial population should have a low number of genes
set to 1, because references tend to be short and the
use of all the possible attributes should be avoided.
For the crossover operator, two individuals are
selected randomly and crossed by a random point
of their structure. For the mutation operator, some
of the genes are chosen randomly to be mutated
from 1 to 0, or vice versa.
The fitness function must find a balance be-
tween the univocal identification of a referent, and
a natural use of attributes. The formula used as
fitness function is defined in Equation 1:
fitindi = fatti?weightatt+ident?weightid (1)
where ident represents whether the reference is
univocally identifying the target among the dis-
tractors, and fatti computes the role of attributes
as the normalised sum of the weight (depending
on its absolute frecuency in ATTRIBUTE-SET
elements in the corpus) of all attributes present
(gene=1), as defined by Equation 2:
fatti =
?
geneatti ? weightatti
#attsRef
(2)
2 Case-Based Reasoning for Realization
Template-based solutions for natural language
generation rely on reusing fragments of text ex-
tracted from typical texts in a given domain, apply-
ing a process of abstraction that identifies which
part of them is common to all uses, and leaving
certain gaps to be filled with details correspond-
ing to a new use. A case-based solution (Aamodt
and Plaza, 1994) to reference realization can ob-
tain the information needed to realize a reference
from the original examples of appropriate use that
originated the templates.
In our approach, a case consists of a de-
scription of the problem (ATTRIBUTE-SET) and
a solution (ANNOTATED-WORD-STRING inter-
preted as a template). Cases are stored in a
Case Retrieval Net (CRN) (Lenz and Burkhard,
1996), a memory model developed to improve
the efficiency of the retrieval tasks of the
CBR cycle. Each attribute-value pair from the
ATTRIBUTE-SET is a node in the net. Templates
in ANNOTATED-WORD-STRING are considered
as solutions to the cases. Similarities between the
nodes are established for the retrieval stage of the
CBR process. For example, we have considered
that ?back? and ?right? orientation values have a
higher similarity than ?back? and ?front? that are
exactly the opposite.
The attribute-value pairs of ATTRIBUTE-SET
that must be realized in a final string are used
to query the net, which returns the more similar
cases. Only one of them must be chosen to be
adapted for the solution. We consider four differ-
ent types of retrieved cases: preferred (cases with
exactly the same attributes than the query), more
(cases with the same attributes as the query and
187
String Edit Norm. Edit BLEU 1 BLEU 2 BLEU 3 BLEU 4
Acc. Dist. Distance Score Score Score Score
Furniture 0,08 4,87 0,51 0,44 0,33 0,24 0,18
EvoTAP People 0,03 6,04 0,59 0,39 0,25 0,15 0,00
Both 0,06 5,41 0,55 0,41 0,29 0,20 0,13
Furniture 0,01 5,91 0,55 0,44 0,31 0,20 0,13
ValuesCBR People 0,01 5,80 0,56 0,43 0,28 0,17 0,08
Both 0,01 5,86 0,55 0,44 0,30 0,19 0,11
Furniture 0,04 5,77 0,58 0,39 0,26 0,18 0,13
EvoCBR People 0,01 6,94 0,61 0,41 0,25 0,16 0,08
Both 0,03 6,31 0,59 0,41 0,26 0,17 0,11
Table 1: Results over development data for the three systems
some more), lessExtra (cases that lack some at-
tribute from the query but have some extra ones),
and lessNoExtra (cases that lack some attribute
from the query and have no extra ones). The or-
der given is the preferred order to chose the most
suitable case for the query.
Adaptation of the chosen case depends on its
type. The idea is to keep all the parts of the tem-
plate that correspond to attributes common to the
query and the case. Extra attributes in the case
that do not appear in the query are discarded. At-
tributes in the query not appearing in the case are
lost.
3 Results and Discussion
We have tested both solutions (evolutionary and
case-based) separately and together in three differ-
ent systems, relying on solutions presented in last
year?s challenge.
? NIL-UCM-EvoTAP. Selects attributes using
the evolutionary solution and realises using
the NIL-UCM-BSC solution (Gerva?s et al,
2008).
? NIL-UCM-ValuesCBR. Selects attributes
using the NIL-UCM-MFVF solution (Gerva?s
et al, 2008) and realizes using the case-based
approach.
? NIL-UCM-EvoCBR. Selects attributes us-
ing the evolutionary solution and realizes us-
ing the case-based approach.
The results obtained by the three systems over
development data are shown in Table 1.
The evolutionary approach performs poorly but
might be improved by using a more refined al-
gorithm for calculating attribute weights, such as
done in the last year NIL-UCM-MFVF solution.
The reported CBR results were obtained over
a case base built from a selection of the avail-
able training data (samples that relied on data
not available in the input were omitted). This
approach could be further refined by generating
style-specific subsets of the case base.
Acknowledgments
This research is funded by the Spanish Ministry of
Education and Science (TIN2006-14433-C02-01).
References
Aamodt, A. and Plaza, E.. 1994. Case-based reason-
ing: Foundational issues, methodological variations,
and system approaches AI Communications, 7(1).
Gerva?s, P. and Herva?s, R. and Leo?n, C. 2008. NIL-
UCM: Most-Frequent-Value-First Attribute Selec-
tion and Best-Scoring-Choice Realization. Refer-
ring Expression Generation Challenge 2008, INGL-
08, USA.
Holland, J.H. 1992. Adaptation in Natural and Arti-
ficial Systems. An Introductory Analysis with Ap-
plications to Biology, Control and Artificial Intelli-
gence. MIT Press, Cambridge, Massachusetts, Sec-
ond Edition.
M. Lenz and H. Burkhard 1996. Case Retrieval Nets:
Basic Ideas and Extensions. Kunstliche Intelligenz.
188
Proceedings of the ACL 2010 Conference Short Papers, pages 49?54,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
The Prevalence of Descriptive Referring Expressions
in News and Narrative
Raquel Herva?s
Departamento de Ingenieria
del Software e Inteligenc??a Artificial
Universidad Complutense de Madrid
Madrid, 28040 Spain
raquelhb@fdi.ucm.es
Mark Alan Finlayson
Computer Science and
Artificial Intelligence Laboratory
Massachusetts Institute of Technology
Cambridge, MA, 02139 USA
markaf@mit.edu
Abstract
Generating referring expressions is a key
step in Natural Language Generation. Re-
searchers have focused almost exclusively
on generating distinctive referring expres-
sions, that is, referring expressions that
uniquely identify their intended referent.
While undoubtedly one of their most im-
portant functions, referring expressions
can be more than distinctive. In particular,
descriptive referring expressions ? those
that provide additional information not re-
quired for distinction ? are critical to flu-
ent, efficient, well-written text. We present
a corpus analysis in which approximately
one-fifth of 7,207 referring expressions in
24,422 words of news and narrative are de-
scriptive. These data show that if we are
ever to fully master natural language gen-
eration, especially for the genres of news
and narrative, researchers will need to de-
vote more attention to understanding how
to generate descriptive, and not just dis-
tinctive, referring expressions.
1 A Distinctive Focus
Generating referring expressions is a key step in
Natural Language Generation (NLG). From early
treatments in seminal papers by Appelt (1985)
and Reiter and Dale (1992) to the recent set
of Referring Expression Generation (REG) Chal-
lenges (Gatt et al, 2009) through different corpora
available for the community (Eugenio et al, 1998;
van Deemter et al, 2006; Viethen and Dale, 2008),
generating referring expressions has become one
of the most studied areas of NLG.
Researchers studying this area have, almost
without exception, focused exclusively on how
to generate distinctive referring expressions, that
is, referring expressions that unambiguously iden-
tify their intended referent. Referring expres-
sions, however, may be more than distinctive. It
is widely acknowledged that they can be used to
achieve multiple goals, above and beyond distinc-
tion. Here we focus on descriptive referring ex-
pressions, that is, referring expressions that are not
only distinctive, but provide additional informa-
tion not required for identifying their intended ref-
erent. Consider the following text, in which some
of the referring expressions have been underlined:
Once upon a time there was a man, who had
three daughters. They lived in a house and
their dresses were made of fabric.
While a bit strange, the text is perfectly well-
formed. All the referring expressions are distinc-
tive, in that we can properly identify the referents
of each expression. But the real text, the opening
lines to the folktale The Beauty and the Beast, is
actually much more lyrical:
Once upon a time there was a rich merchant,
who had three daughters. They lived in a
very fine house and their gowns were made
of the richest fabric sewn with jewels.
All the boldfaced portions ? namely, the choice
of head nouns, the addition of adjectives, the use
of appositive phrases ? serve to perform a descrip-
tive function, and, importantly, are all unneces-
sary for distinction! In all of these cases, the au-
thor is using the referring expressions as a vehi-
cle for communicating information about the ref-
erents. This descriptive information is sometimes
new, sometimes necessary for understanding the
text, and sometimes just for added flavor. But
when the expression is descriptive, as opposed to
distinctive, this additional information is not re-
quired for identifying the referent of the expres-
sion, and it is these sorts of referring expressions
that we will be concerned with here.
49
Although these sorts of referring expression
have been mostly ignored by researchers in this
area1, we show in this corpus study that descrip-
tive expressions are in fact quite prevalent: nearly
one-fifth of referring expressions in news and nar-
rative are descriptive. In particular, our data,
the trained judgments of native English speakers,
show that 18% of all distinctive referring expres-
sions in news and 17% of those in narrative folk-
tales are descriptive. With this as motivation, we
argue that descriptive referring expressions must
be studied more carefully, especially as the field
progresses from referring in a physical, immedi-
ate context (like that in the REG Challenges) to
generating more literary forms of text.
2 Corpus Annotation
This is a corpus study; our procedure was there-
fore to define our annotation guidelines (Sec-
tion 2.1), select texts to annotate (2.2), create an
annotation tool for our annotators (2.3), and, fi-
nally, train annotators, have them annotate refer-
ring expressions? constituents and function, and
then adjudicate the double-annotated texts into a
gold standard (2.4).
2.1 Definitions
We wrote an annotation guide explaining the dif-
ference between distinctive and descriptive refer-
ring expressions. We used the guide when train-
ing annotators, and it was available to them while
annotating. With limited space here we can only
give an outline of what is contained in the guide;
for full details see (Finlayson and Herva?s, 2010a).
Referring Expressions We defined referring
expressions as referential noun phrases and their
coreferential expressions, e.g., ?John kissed Mary.
She blushed.?. This included referring expressions
to generics (e.g., ?Lions are fierce?), dates, times,
and numbers, as well as events if they were re-
ferred to using a noun phrase. We included in each
referring expression all the determiners, quan-
tifiers, adjectives, appositives, and prepositional
phrases that syntactically attached to that expres-
sion. When referring expressions were nested, all
the nested referring expressions were also marked
separately.
Nuclei vs. Modifiers In the only previous cor-
pus study of descriptive referring expressions, on
1With the exception of a small amount of work, discussed
in Section 4.
museum labels, Cheng et al (2001) noted that de-
scriptive information is often integrated into refer-
ring expressions using modifiers to the head noun.
To study this, and to allow our results to be more
closely compared with Cheng?s, we had our an-
notators split referring expressions into their con-
stituents, portions called either nuclei or modifiers.
The nuclei were the portions of the referring ex-
pression that performed the ?core? referring func-
tion; the modifiers were those portions that could
be varied, syntactically speaking, independently of
the nuclei. Annotators then assigned a distinctive
or descriptive function to each constituent, rather
than the referring expression as a whole.
Normally, the nuclei corresponded to the head
of the noun phrase. In (1), the nucleus is the token
king, which we have here surrounded with square
brackets. The modifiers, surrounded by parenthe-
ses, are The and old.
(1) (The) (old) [king] was wise.
Phrasal modifiers were marked as single modi-
fiers, for example, in (2).
(2) (The) [roof] (of the house) collapsed.
It is significant that we had our annotators mark
and tag the nuclei of referring expressions. Cheng
and colleagues only mentioned the possibility that
additional information could be introduced in the
modifiers. However, O?Donnell et al (1998) ob-
served that often the choice of head noun can also
influence the function of a referring expression.
Consider (3), in which the word villain is used to
refer to the King.
The King assumed the throne today.(3)
I don?t trust (that) [villain] one bit.
The speaker could have merely used him to re-
fer to the King?the choice of that particular head
noun villain gives us additional information about
the disposition of the speaker. Thus villain is de-
scriptive.
Function: Distinctive vs. Descriptive As al-
ready noted, instead of tagging the whole re-
ferring expression, annotators tagged each con-
stituent (nuclei and modifiers) as distinctive or de-
scriptive.
The two main tests for determining descriptive-
ness were (a) if presence of the constituent was
unnecessary for identifying the referent, or (b) if
50
the constituent was expressed using unusual or os-
tentatious word choice. If either was true, the con-
stituent was considered descriptive; otherwise, it
was tagged as distinctive. In cases where the con-
stituent was completely irrelevant to identifying
the referent, it was tagged as descriptive. For ex-
ample, in the folktale The Princess and the Pea,
from which (1) was extracted, there is only one
king in the entire story. Thus, in that story, the
king is sufficient for identification, and therefore
the modifier old is descriptive. This points out the
importance of context in determining distinctive-
ness or descriptiveness; if there had been a room-
ful of kings, the tags on those modifiers would
have been reversed.
There is some question as to whether copular
predicates, such as the plumber in (4), are actually
referring expressions.
(4) John is the plumber
Our annotators marked and tagged these construc-
tions as normal referring expressions, but they
added an additional flag to identify them as cop-
ular predicates. We then excluded these construc-
tions from our final analysis. Note that copular
predicates were treated differently from apposi-
tives: in appositives the predicate was included in
the referring expression, and in most cases (again,
depending on context) was marked descriptive
(e.g., John, the plumber, slept.).
2.2 Text Selection
Our corpus comprised 62 texts, all originally writ-
ten in English, from two different genres, news
and folktales. We began with 30 folktales of dif-
ferent sizes, totaling 12,050 words. These texts
were used in a previous work on the influence of
dialogues on anaphora resolution algorithms (Ag-
garwal et al, 2009); they were assembled with an
eye toward including different styles, different au-
thors, and different time periods. Following this,
we matched, approximately, the number of words
in the folktales by selecting 32 texts from Wall
Street Journal section of the Penn Treebank (Mar-
cus et al, 1993). These texts were selected at ran-
dom from the first 200 texts in the corpus.
2.3 The Story Workbench
We used the Story Workbench application (Fin-
layson, 2008) to actually perform the annotation.
The Story Workbench is a semantic annotation
program that, among other things, includes the
ability to annotate referring expressions and coref-
erential relationships. We added the ability to an-
notate nuclei, modifiers, and their functions by
writing a workbench ?plugin? in Java that could
be installed in the application.
The Story Workbench is not yet available to the
public at large, being in a limited distribution beta
testing phase. The developers plan to release it as
free software within the next year. At that time,
we also plan to release our plugin as free, down-
loadable software.
2.4 Annotation & Adjudication
The main task of the study was the annotation of
the constituents of each referring expression, as
well as the function (distinctive or descriptive) of
each constituent. The system generated a first pass
of constituent analysis, but did not mark functions.
We hired two native English annotators, neither of
whom had any linguistics background, who cor-
rected these automatically-generated constituent
analyses, and tagged each constituent as descrip-
tive or distinctive. Every text was annotated by
both annotators. Adjudication of the differences
was conducted by discussion between the two an-
notators; the second author moderated these dis-
cussions and settled irreconcilable disagreements.
We followed a ?train-as-you-go? paradigm, where
there was no distinct training period, but rather
adjudication proceeded in step with annotation,
and annotators received feedback during those ses-
sions.
We calculated two measures of inter-annotator
agreement: a kappa statistic and an f-measure,
shown in Table 1. All of our f-measures indicated
that annotators agreed almost perfectly on the lo-
cation of referring expressions and their break-
down into constituents. These agreement calcu-
lations were performed on the annotators? original
corrected texts.
All the kappa statistics were calculated for two
tags (nuclei vs. modifier for the constituents, and
distinctive vs. descriptive for the functions) over
both each token assigned to a nucleus or modifier
and each referring expression pair. Our kappas in-
dicate moderate to good agreement, especially for
the folktales. These results are expected because
of the inherent subjectivity of language. During
the adjudication sessions it became clear that dif-
ferent people do not consider the same information
51
as obvious or descriptive for the same concepts,
and even the contexts deduced by each annotators
from the texts were sometimes substantially dif-
ferent.
Tales Articles Total
Ref. Exp. (F1) 1.00 0.99 0.99
Constituents (F1) 0.99 0.98 0.98
Nuc./Mod. (?) 0.97 0.95 0.96
Const. Func. (?) 0.61 0.48 0.54
Ref. Exp. Func. (?) 0.65 0.54 0.59
Table 1: Inter-annotator agreement measures
3 Results
Table 2 lists the primary results of the study. We
considered a referring expression descriptive if
any of its constituents were descriptive. Thus,
18% of the referring expressions in the corpus
added additional information beyond what was re-
quired to unambiguously identify their referent.
The results were similar in both genres.
Tales Articles Total
Texts 30 32 62
Words 12,050 12,372 24,422
Sentences 904 571 1,475
Ref. Exp. 3,681 3,526 7,207
Dist. Ref. Exp. 3,057 2,830 5,887
Desc. Ref. Exp. 609 672 1,281
% Dist. Ref. 83% 81% 82%
% Desc. Ref. 17% 19% 18%
Table 2: Primary results.
Table 3 contains the percentages of descriptive
and distinctive tags broken down by constituent.
Like Cheng?s results, our analysis shows that de-
scriptive referring expressions make up a signif-
icant fraction of all referring expressions. Al-
though Cheng did not examine nuclei, our results
show that the use of descriptive nuclei is small but
not negligible.
4 Relation to the Field
Researchers working on generating referring ex-
pressions typically acknowledge that referring ex-
pressions can perform functions other than distinc-
tion. Despite this widespread acknowledgment,
researchers have, for the most part, explicitly ig-
nored these functions. Exceptions to this trend
Tales Articles Total
Nuclei 3,666 3,502 7,168
Max. Nuc/Ref 1 1 1
Dist. Nuc. 95% 97% 96%
Desc. Nuc. 5% 3% 4%
Modifiers 2,277 3,627 5,904
Avg. Mod/Ref 0.6 1.0 0.8
Max. Mod/Ref 4 6 6
Dist. Mod. 78% 81% 80%
Desc. Mod. 22% 19% 20%
Table 3: Breakdown of Constituent Tags
are three. First is the general study of aggregation
in the process of referring expression generation.
Second and third are corpus studies by Cheng et al
(2001) and Jordan (2000a) that bear on the preva-
lence of descriptive referring expressions.
The NLG subtask of aggregation can be used
to imbue referring expressions with a descriptive
function (Reiter and Dale, 2000, ?5.3). There is a
specific kind of aggregation called embedding that
moves information from one clause to another in-
side the structure of a separate noun phrase. This
type of aggregation can be used to transform two
sentences such as ?The princess lived in a castle.
She was pretty? into ?The pretty princess lived in
a castle?. The adjective pretty, previously a cop-
ular predicate, becomes a descriptive modifier of
the reference to the princess, making the second
text more natural and fluent. This kind of ag-
gregation is widely used by humans for making
the discourse more compact and efficient. In or-
der to create NLG systems with this ability, we
must take into account the caveat, noted by Cheng
(1998), that any non-distinctive information in a
referring expression must not lead to confusion
about the distinctive function of the referring ex-
pression. This is by no means a trivial problem
? this sort of aggregation interferes with refer-
ring and coherence planning at both a local and
global level (Cheng and Mellish, 2000; Cheng et
al., 2001). It is clear, from the current state of the
art of NLG, that we have not yet obtained a deep
enough understanding of aggregation to enable us
to handle these interactions. More research on the
topic is needed.
Two previous corpus studies have looked at
the use of descriptive referring expressions. The
first showed explicitly that people craft descrip-
tive referring expressions to accomplish different
52
goals. Jordan and colleagues (Jordan, 2000b; Jor-
dan, 2000a) examined the use of referring expres-
sions using the COCONUT corpus (Eugenio et
al., 1998). They tested how domain and discourse
goals can influence the content of non-pronominal
referring expressions in a dialogue context, check-
ing whether or not a subject?s goals led them to in-
clude non-referring information in a referring ex-
pression. Their results are intriguing because they
point toward heretofore unexamined constraints,
utilities and expectations (possibly genre- or style-
dependent) that may underlie the use of descriptive
information to perform different functions, and are
not yet captured by aggregation modules in partic-
ular or NLG systems in general.
In the other corpus study, which partially in-
spired this work, Cheng and colleagues analyzed
a set of museum descriptions, the GNOME cor-
pus (Poesio, 2004), for the pragmatic functions of
referring expressions. They had three functions
in their study, in contrast to our two. Their first
function (marked by their uniq tag) was equiv-
alent to our distinctive function. The other two
were specializations of our descriptive tag, where
they differentiated between additional information
that helped to understand the text (int), or ad-
ditional information not necessary for understand-
ing (attr). Despite their annotators seeming to
have trouble distinguishing between the latter two
tags, they did achieve good overall inter-annotator
agreement. They identified 1,863 modifiers to
referring expressions in their corpus, of which
47.3% fulfilled a descriptive (attr or int) func-
tion. This is supportive of our main assertion,
namely, that descriptive referring expressions, not
only crucial for efficient and fluent text, are ac-
tually a significant phenomenon. It is interest-
ing, though, that Cheng?s fraction of descriptive
referring expression was so much higher than ours
(47.3% versus our 18%). We attribute this sub-
stantial difference to genre, in that Cheng stud-
ied museum labels, in which the writer is space-
constrained, having to pack a lot of information
into a small label. The issue bears further study,
and perhaps will lead to insights into differences
in writing style that may be attributed to author or
genre.
5 Contributions
We make two contributions in this paper.
First, we assembled, double-annotated, and ad-
judicated into a gold-standard a corpus of 24,422
words. We marked all referring expressions,
coreferential relations, and referring expression
constituents, and tagged each constituent as hav-
ing a descriptive or distinctive function. We wrote
an annotation guide and created software that al-
lows the annotation of this information in free text.
The corpus and the guide are available on-line in a
permanent digital archive (Finlayson and Herva?s,
2010a; Finlayson and Herva?s, 2010b). The soft-
ware will also be released in the same archive
when the Story Workbench annotation application
is released to the public. This corpus will be useful
for the automatic generation and analysis of both
descriptive and distinctive referring expressions.
Any kind of system intended to generate text as
humans do must take into account that identifica-
tion is not the only function of referring expres-
sions. Many analysis applications would benefit
from the automatic recognition of descriptive re-
ferring expressions.
Second, we demonstrated that descriptive refer-
ring expressions comprise a substantial fraction
(18%) of the referring expressions in news and
narrative. Along with museum descriptions, stud-
ied by Cheng, it seems that news and narrative are
genres where authors naturally use a large num-
ber of descriptive referring expressions. Given that
so little work has been done on descriptive refer-
ring expressions, this indicates that the field would
be well served by focusing more attention on this
phenomenon.
Acknowledgments
This work was supported in part by the Air
Force Office of Scientific Research under grant
number A9550-05-1-0321, as well as by the
Office of Naval Research under award number
N00014091059. Any opinions, findings, and con-
clusions or recommendations expressed in this pa-
per are those of the authors and do not necessarily
reflect the views of the Office of Naval Research.
This research is also partially funded the Span-
ish Ministry of Education and Science (TIN2009-
14659-C03-01) and Universidad Complutense de
Madrid (GR58/08). We also thank Whitman
Richards, Ozlem Uzuner, Peter Szolovits, Patrick
Winston, Pablo Gerva?s, and Mark Seifter for their
helpful comments and discussion, and thank our
annotators Saam Batmanghelidj and Geneva Trot-
ter.
53
References
Alaukik Aggarwal, Pablo Gerva?s, and Raquel Herva?s.
2009. Measuring the influence of errors induced by
the presence of dialogues in reference clustering of
narrative text. In Proceedings of ICON-2009: 7th
International Conference on Natural Language Pro-
cessing, India. Macmillan Publishers.
Douglas E. Appelt. 1985. Planning English referring
expressions. Artificial Intelligence, 26:1?33.
Hua Cheng and Chris Mellish. 2000. Capturing the in-
teraction between aggregation and text planning in
two generation systems. In INLG ?00: First interna-
tional conference on Natural Language Generation
2000, pages 186?193, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Hua Cheng, Massimo Poesio, Renate Henschel, and
Chris Mellish. 2001. Corpus-based np modifier
generation. In NAACL ?01: Second meeting of
the North American Chapter of the Association for
Computational Linguistics on Language technolo-
gies 2001, pages 1?8, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Hua Cheng. 1998. Embedding new information into
referring expressions. In ACL-36: Proceedings of
the 36th Annual Meeting of the Association for Com-
putational Linguistics and 17th International Con-
ference on Computational Linguistics, pages 1478?
1480, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Barbara Di Eugenio, Johanna D. Moore, Pamela W.
Jordan, and Richmond H. Thomason. 1998. An
empirical investigation of proposals in collabora-
tive dialogues. In Proceedings of the 17th inter-
national conference on Computational linguistics,
pages 325?329, Morristown, NJ, USA. Association
for Computational Linguistics.
Mark A. Finlayson and Raquel Herva?s. 2010a. Anno-
tation guide for the UCM/MIT indications, referring
expressions, and coreference corpus (UMIREC cor-
pus). Technical Report MIT-CSAIL-TR-2010-025,
MIT Computer Science and Artificial Intelligence
Laboratory. http://hdl.handle.net/1721.1/54765.
Mark A. Finlayson and Raquel Herva?s. 2010b.
UCM/MIT indications, referring expres-
sions, and coreference corpus (UMIREC
corpus). Work product, MIT Computer Sci-
ence and Artificial Intelligence Laboratory.
http://hdl.handle.net/1721.1/54766.
Mark A. Finlayson. 2008. Collecting semantics in
the wild: The Story Workbench. In Proceedings of
the AAAI Fall Symposium on Naturally-Inspired Ar-
tificial Intelligence, pages 46?53, Menlo Park, CA,
USA. AAAI Press.
Albert Gatt, Anja Belz, and Eric Kow. 2009. The
TUNA-REG challenge 2009: overview and evalu-
ation results. In ENLG ?09: Proceedings of the 12th
European Workshop on Natural Language Genera-
tion, pages 174?182, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
Pamela W. Jordan. 2000a. Can nominal expressions
achieve multiple goals?: an empirical study. In ACL
?00: Proceedings of the 38th Annual Meeting on As-
sociation for Computational Linguistics, pages 142?
149, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Pamela W. Jordan. 2000b. Influences on attribute se-
lection in redescriptions: A corpus study. In Pro-
ceedings of CogSci2000, pages 250?255.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: the penn treebank. Compu-
tational Linguistics, 19(2):313?330.
Michael O?Donnell, Hua Cheng, and Janet Hitze-
man. 1998. Integrating referring and informing in
NP planning. In Proceedings of COLING-ACL?98
Workshop on the Computational Treatment of Nom-
inals, pages 46?56.
Massimo Poesio. 2004. Discourse annotation and
semantic annotation in the GNOME corpus. In
DiscAnnotation ?04: Proceedings of the 2004 ACL
Workshop on Discourse Annotation, pages 72?79,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Ehud Reiter and Robert Dale. 1992. A fast algorithm
for the generation of referring expressions. In Pro-
ceedings of the 14th conference on Computational
linguistics, Nantes, France.
Ehud Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. Cambridge Univer-
sity Press.
Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
2006. Building a semantically transparent corpus
for the generation of referring expressions. In Pro-
ceedings of the 4th International Conference on Nat-
ural Language Generation (Special Session on Data
Sharing and Evaluation), INLG-06.
Jette Viethen and Robert Dale. 2008. The use of spa-
tial relations in referring expressions. In Proceed-
ings of the 5th International Conference on Natural
Language Generation.
54
Degree of Abstraction in Referring Expression Generation and its Relation
with the Construction of the Contrast Set
Raquel Herva?s
Facultad de Informa?tica
Universidad Complutense de Madrid
Madrid, Spain
raquelhb@fdi.ucm.es
Pablo Gerva?s
Facultad de Informa?tica
Universidad Complutense de Madrid
Madrid, Spain
pgervas@sip.ucm.es
Abstract
Referring Expression Generation (REG) is the
task that deals with references to entities ap-
pearing in a spoken or written discourse. If
these referents are organized in terms of a tax-
onomy, there are two problems when estab-
lishing a reference that would distinguish an
intended referent from its possible distractors.
The first one is the choice of the set of possible
distractrors or contrast set in the given situa-
tion. The second is to identify at what level of
the taxonomy to phrase the reference so that
it unambiguously picks out only the intended
referent, leaving all possible distractors in dif-
ferent branches of the taxonomy. We discuss
the use of ontologies to deal with the REG
task, paying special attention to the choice of
the the contrast set and to the use of the in-
formation of the ontology to select the most
appropriate type to be used for the referent.
1 Introduction
Referring Expression Generation (REG) is the task
that deals with references of entities appearing in a
discourse. In a context where possible referents are
organized in terms of a taxonomy (or subsumption
hierarchy) and may additionally be differentiated by
their attributes, there are two possible ways of estab-
lishing a reference that will distinguish an intended
referent from its possible distractors.
One is to identify at what level of the taxonomy to
phrase the reference so that it unambiguously picks
out only the intended referent, leaving all possible
distractors in different branches of the taxonomy.
Another, applied once a particular level of reference
has been chosen, is to resort to mentioning addi-
tional attributes of the intended referents that distin-
guish it from any remaining distractors that share the
same branch of the taxonomy.
While the second task has been addressed often
in existing literature, the first one is often glossed
over by requiring that the levels to be used for each
element come specified in the input. However, if
this task is to be considered as a specific problem
to be solved computationally, it opens up an addi-
tional problem. If the elements in the universe are
classified in a taxonomy with a single root and the
reference was established at a high enough level in
the taxonomy, potentially everything in the universe
could be a distractor for any other element.
In this paper we will discuss the use of ontolo-
gies to deal with the referring expression generation
task. We will pay special attention to the choice of
the contrast set and the use of ontology information
to select the most appropriate type to be used for the
referent. This work has been centered in the gener-
ation of definite noun phrases where the type of an
element and a set of its properties are given to dis-
tinguish it from the other elements in focus. We are
also supposing that the situations in which the ref-
erence is produced are static, that is, the addressee?s
perception of the world does not change during the
process of reference generation.
2 Related Work
The appropriate use of referring expressions to com-
pete with human-generated texts involves a certain
difficulty. According to Reiter and Dale (2000), a re-
ferring expression must communicate enough infor-
161
mation to identify univocally the intended referent
within the context of the current discourse, but al-
ways avoiding unnecessary or redundant modifiers.
Reiter and Dale (1992) describe a fast algorithm
for generating referring expressions in the context
of a natural language generation system. Their al-
gorithm relies on the following set of assumptions
about the underlying knowledge base that must be
used: (1) every entity is characterized in terms of
a collection of attributes and their values, (2) every
entity has as one of its attributes a type, and (3) the
knowledge base may organize some attribute values
as a subsumption hierarchy. Additionally, each ob-
ject represented in the system should have an associ-
ated basic level value, which corresponds to the con-
cept which is preferred when referring to that object.
These assumptions are satisfied if a description
logic ontology is used for this purpose. Entities
would correspond to instances of concepts from the
ontology, the attribute corresponding to the type
would be the concept of which they are immediate
instances, and the taxonomical structure of the on-
tology of concepts would provide the subsumption
hierarchy. To construct a reference to a particular
entity, the algorithm takes as input a symbol corre-
sponding to the intended referent and a list of sym-
bols corresponding to other entities in focus, known
as the contrast set. The algorithm returns a list of
attribute-value pairs that correspond to the semantic
content of the referring expression.
3 Generating References Using Ontologies
A previously developed ontology about wines has
been used to test the ideas presented in this work.
This is a sample ontology implemented following
a version published by Brachman and colleagues
(Brachman et al, 1991) and distributed along with
the CLASSIC knowledge representation system.
We have focused on the taxonomy of wines pro-
vided by the ontology. Wines are divided in three
main categories: Red Wine, White Wine and
Rose Wine. Inside these main categories there is
a complex taxonomy of different kinds of wines.
In addition, the ontology also contains several in-
stances of the different concepts. Each of these
instances is described using features such as body,
color, flavor, producer, and so on.
The aim is to generate references for different in-
stances of wines which are together in a discourse.
The first step is to select the set of distractors or con-
trast set for the specific referent. Then, an algorithm
for deciding which is the best reference to use is ap-
plied. We have considered as the best reference pos-
sible the use of the type that distinguishes the refer-
ent from the distractors and at the same time is as
general as possible. For example, if we are referring
to an instance of Chardonnaywine (that is a white
one) in a situation where the rest of wines are all
red wines, the most suitable reference is ?the white
wine? and not ?the chardonnay?. On the contrary,
the more specific (but unnecessary) reference might
lead the addressee to infer that this information is
somehow relevant. If only white wines (as direct
type of the referent) are considered for the contrast
set, only the more specific (and inappropriate) refer-
ence may be generated. Therefore, a wide enough
contrast set must be considered in each case.
Finally, if the type chosen is not enough to dis-
tinguish the referent from the contrast set, attribute
selection is applied to select a subset of the element
properties that distinguish it.
3.1 Composing the Contrast Set
Information about type is generally used to deter-
mine which elements of the world must be consid-
ered in the contrast set. In this work, all the informa-
tion about the world is located in an ontology. Each
instance of the world contained in it has a direct type
(the most specific concept it belongs to) and a set of
undirect types that are all the types between the di-
rect type and the root of the ontology.
In the work developed we have used the whole
ontology as contrast set. We have considered it as
the most suitable option for most situations where
the elements involved can belong to quite different
types. As we will see later, this choice avoids the
use of references more specific than desired while at
the same time it allows the algorithm to choose the
type that is more suitable in a given situation.
3.2 An Appropriate Type for the Referent
Our approach takes as initial distinguishing attribute
the type of the elements appearing in the world. This
kind of solution is enough when the types defined for
each of the entities of the world are fixed and there is
162
not a close relation for different types. For example,
a solution that takes as type the strict one defined
in an element would not consider a doberman and a
chihuahua as being both of them dogs.
The algorithm we have implemented can be seen
in Figure 1. Here, r is the intended referent, C is
the contrast set, A is the list of attributes that the in-
stances of the ontology hold, typeValue is the type
that would be assigned to the referent by the algo-
rithm, and L is the list of attribute-value pairs re-
turned if the type is not enough to rule out all the
distractors. The rules-out function works as the
one used in the Incremental algorithm, and the func-
tion incremental-algorithm calls directly to
the original algorithm by Reiter and Dale.
The function find-best-value-type is the
one that delivers the most appropriate type for the
intended referent r taking into account the informa-
tion in the ontology. We have considered as basic
level value for the type the most specific of the com-
mon types of the instances of the ontology. From
this basic level type, the branch of concepts between
it and the direct type of the intended referent r is vis-
ited. The type that will be used in the reference is the
most general concept from this branch that discards
a bigger number of distractors.
3.3 Attribute Selection for Reference
Completion
In some cases the type would not be enough to dis-
tinguish a referent from the other elements of the
world. This situation is produced when they belong
to the same type. In this situation it will be necessary
to use their properties to distinguish between them.
The attribute selection carried out in the Incremental
algorithm from Reiter and Dale has been applied to
these situations.
4 Some Examples
We have tested the implemented algorithm over dif-
ferent situations in which a set of wines is presented.
For each of them, a distinguishing description is pro-
vided using the appropriate type found using the on-
tology and a set of attributes when they were re-
quired. The instances of the world we have con-
sidered are shown in Table 1 (the properties of the
wines that have not been used by the algorithm are
Figure 1: The Algorithm
not shown). The references generated for each of
the referents are (numbers correspond to examples
in the table):
1. ?The Riesling?. There is another white wine
but not a Dry Riesling one, so the most
general type discarding all the distractors is
Riesling.
2. ?The moderate Cabernet Sauvignon?. Here
the type is not enough to distinguish this
referent, so its attributes are used. The
property that distinguish it from the other
Cabernet Sauvignon is the flavor.
3. ?The strong Cabernet Sauvignon?. As in
the previous case the strong flavor is used
to distinguish the wine from the other
Cabernet Sauvignon.
4. ?The Rose Wine?. In this case there are no
more rose wines, so this generic type is enough
to distinguish the referent.
163
Table 1: Examples
5 Conclusions and Future Work
The main advantage of this approach is that the al-
gorithm always finds the most suitable value for the
type, taking into account the other entities of the
world. Since this solution is completely generic and
domain-independent, the algorithm would work in
the same way with more general ontologies. For
example, if the considered ontology contains infor-
mation not only about wines, but also about other
kinds of drinks, the values to be used as types of
the referents would also be chosen in the same way.
In this situation the referent could be the only wine
among other drinks, and the reference generated for
it would be the most appropriate one: ?the wine?.
In the Incremental algorithm, Reiter and Dale do
not address the question of how the contrast set is
constructed, stating that the contrast set is one of the
inputs of their algorithm. In our work, we have cho-
sen as contrast set al the instances that can be found
in the ontology. This solution allows the algorithm
to work with enough information to choose exactly
at which level of the ontology the discourse is being
displayed (more general or more specific). With this
information the generated references are adapted to
the level of specificity required in each case.
The Incremental algorithm also states that the ba-
sic level value is obtained from the knowledge base
or the user model. In this paper we have imple-
mented a dynamic way to obtain this value that only
depends on the knowledge available about the world.
However, the use of some kind of user model repre-
senting the expertise level of the addressee in a spe-
cific domain could be explored in the future.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2006-14433-C02-01
project) and the UCM and the Direccio?n General de
Universidades e Investigacio?n of the CAM (CCG07-
UCM/TIC-2803).
References
Brachman. Ronald J. and McGuiness, Deborah L. and
Patel-Schneider, Peter F. and Resnick, Lori A. 1991.
Living with CLASSIC: when and how to use a KL-
ONE-like language. Principles in Semantic Net-
works: Explorations in the Representation of Knowl-
edge, pages 401?456. Morgan Kaufmann, California.
Reiter, Ehud and Dale, Robert. 1992. A fast algorithm
for the generation of referring expressions. Proc. of
the 14th conference on Computational Linguistics, pp.
232-238. Association for Computational Linguistics.
Reiter, Ehud and Dale, Robert. 2000. Building Natural
Language Generation Systems. Cambridge University
Press.
164
NIL-UCM: Most-Frequent-Value-First Attribute Selection and
Best-Scoring-Choice Realization
Pablo Gerva?s, Raquel Herva?s, Carlos Leo?n
Natural Interaction based on Language (NIL)
Universidad Complutense de Madrid
c/ Profesor Jose? Garc??a Santesmases s/n, 28040 Madrid, Spain
pgervas@sip.ucm.es, raquelhb@fdi.ucm.es, cleon@fdi.ucm.es
1 Introduction
The NIL entry for the challenge has been con-
structed upon the general architecture for develop-
ing Natural Language Generation systems provided
by the TAP project (Gerva?s, 2007). TAP (Text Ar-
ranging Pipeline) is a set of interfaces that define
generic functionality for a pipeline of tasks oriented
toward natural language generation, from an initial
conceptual input to surface realization as a string,
with intervening stages of content planning and sen-
tence planning.
The TAP architecture considers three basic stages:
content planning, sentence planning and surface re-
alization. Of these, the first stage is not relevant to
the challenge tasks. The configuration choices ap-
plied to the other two stages to adapt them to the
challenge tasks are described below.
2 NIL-UCM-MFVF Entry for Task 1
The NIL-UCM-MFVF for Task 1 applies a Most-
Frequent-Value-First method for Attribute Selec-
tion. Of the five evaluation dimensions considered
in this challenge (Dice, MASI, accuracy, minimal-
ity and uniqueness), this method has been designed
to address explicitly only three: Dice, MASI and
uniqueness. Minimality was abandoned in view of
results in previous challenges (Herva?s and Gerva?s,
2007) that showed good minimality results tended to
produce low Dice scores. We have also opted for not
using accuracy evaluation to fit the performance of
our system, since the corpus contains a wide range
of style of reference and we are interested in pro-
viding our system with only a subset of these that
ensure correct identification.
2.1 Most-Frequent-Value-First Attribute
Selection
The selection algorithm employed is an adapta-
tion of the algorithm described in (Reiter and Dale,
1992). The original algorithm has been modified to
allow for a dynamically changing list of preferred
attributes, which determine the particular order in
which attributes are considered to generate the dis-
tinguishing expression. This list is constructed dy-
namically for each reference by computing the prob-
ability of occurrence in the corpus of the particu-
lar attribute-value pairs associated with the referent,
and using those probabilities to rank them into a spe-
cific list of preferred attributes. The idea is that at-
tributes should be considered in a particular order
depending highly on their values. For example, in
the people domain we have observed that almost
the 100% of the target entities that have beard (at-
tribute has value 1) are referred using the attribute
hasBeard, but when this attribute has value 0 it is
never used. For the hasHair attribute, the opposite
seems to be the case (mentioned only when lacking).
The training data was studied to obtain the prob-
ability of occurrence of an attribute given a certain
value for it. This probability was calculated using
Formula 1:
probvali =
?
appsV alueInAttSet
?
appsV alueInTarget (1)
For each possible value of each of the attributes
of the domains, the sum of the appearances of this
value in the ATTRIBUTE-SET elements (appsVal-
ueInAttSet) and the sum of the appearances of this
value in the attributes of all targets (appsValueInTar-
get) are calculated. The division of these two values
is the probability of mentioning an attribute when it
has a specific value.
215
Dice MASI Accuracy Uniqueness Minimality
Train. Furniture 79,18% 56,95% 41,69% 100% 0%
People 69,71% 42,41% 22,99% 100% 0%
Both 74,80% 50,23% 34,81% 100% 0%
Dev. Furniture 77,55% 53,97% 41,25% 100% 0%
People 70,86% 42,59% 22,06% 100% 0%
Both 74,48% 48,75% 32,43% 100% 0%
Table 1:Task 1 results for training and development data
Some examples of the results obtained are that the
attribute hasGlasses is mentioned in the 60% of
the situations when its value is 1, and in the 0% of
the situations when its value is 0. On the contrary,
the attribute hasShirt is almost never mentioned
(0.8% when its value is 1 and 0% with value 0).
The only exception in the algorithm is the type
attribute for the people domain. As every entity in
this domain is of type person, the attribute selector
does not choose this attribute because no distractor
is discarded by it. However, the experiments have
shown us that in the corpus a lot of descriptions in-
clude the type person even when it is redundant.
Following this idea, our algorithm always includes
the type in the list of chosen attributes for the peo-
ple domain.1
2.2 Obtained Results
Results obtained over the training and development
data are shown in Table 1. As can be seen com-
paring both tables there are no surprises in the final
results: the system gets similar results with both do-
mains and with both the training and development
data. These results confirm that the probability of
appearance of an attribute depending on its value is
more or less the same in the whole corpus.
3 NIL-UCM-BSC Entry for Task 2
The NIL-UCM-BSC for Task 2 applies a Best-
Scoring-Choice approach to Realization.
The realization tasks of the 2008 GRE challenge
required specific instantiations of the Referring Ex-
1We have only recently discovered that the surprising differ-
ence between NIL-UCM results for the people and the furniture
domains in the 2007 GRE challenge was the mostly due to our
not having taken this issue into account at the time. The effect
is noticeable only when the type attribute is redundant, as it is
in the people domain.
pression Generation, Syntactic Choice, and Lexical-
ization stages of the Sentence Planning module of
TAP, and it draws on the SurReal (Gerva?s, 2006) sur-
face realization module. SurReal provides a Java im-
plementation of the surface realization mechanisms
of FUF described in Elhadad (Elhadad, 1993), op-
erating over a grammar which follows the notational
conventions of the SURGE grammar in Elhadad (El-
hadad and Robin, 1996), but it is not systemic in na-
ture. It currently has much smaller coverage than the
original, but quite sufficient to deal with the kind of
realizations required for the challenge tasks.
3.1 Realization Choices in the Corpus
An analysis of the domain was carried out to ascer-
tain what the various alternatives required for real-
ization were for the given corpus, both in terms of
how to realize syntactically the different concepts
and what alternative lexicalizations should be con-
sidered. With respect to linguistic variation in the
form of expression we have distinguished between
choices that give rise to different syntactic struc-
tures (which we consider as syntactic choices) and
choices which give rise to the same syntactic struc-
tures but with different lexical items (which we con-
sider as lexical choices).
With respect to the Referring Expression Genera-
tion stage, the following issues required specific de-
cisions. The use of determiners is erratic. Some
examples in the corpus use indefinite article, some
use definite articles, and some omit the determin-
ers altogether. The corpus shows many cases where
spatial expressions describing the location of refer-
ents are used, many using different systems of refer-
ence (north-south vs. top-bottom). The use of par-
ticular features of the object in its description, as
in ?the desk with the drawers facing the viewer? or
?the chair with the seat facing away?. Comparison
216
with all or some of the distractors are also used, ei-
ther as adjuncts describing their position relative to
other distractors, as in ?the blue fan next to the green
fan?, or as comparative adjectives used for particu-
lar attributes, as in ?the largest red couch? (and even
combinations of the two as in ?the smaller of the two
blue fans?). Finally, there are samples in the corpus
of use of ellipsis and ungrammatical expressions.
The mention of particular features and the use of
comparison would involve operating on more data
than are generated in task 1, and the current sub-
mission is aimed to interconnection with task 2 for
addressing task 3. The issue of ungrammaticality is
important since it implies that there is an upper limit
to the possible scores that the system may achieve
over the corpus under the circumstances, totally un-
related with the correctness of the generated expres-
sions.
With respect to Syntactic Choice, some attributes
show more than one possible option for syntac-
tic realization. The number of alternatives varies
from color (?grey chair - chair that is gray?), through
beards (?with beard - with the beard - with whiskers
- the bearded man - with a beard - with facial hair?)
to orientation (12 different syntactic alternatives for
expressing orientation: back).
There are slight variations of Lexical Choice over
the corpus, as in ?sofa - couch - settee - loveseat?,
?ventilator - fan - windmill? or ?man - guy - bloke?
(for nouns) and ?large - big? or ?small - little? (for
adjectives). Because it has a significant impact on
the edit distance measure, it is also important to con-
sider the existence of a large number of misspellings
in the corpus. Finally, there are some conceptual
mismatches in annotation, between the attribute
set and the given realization in some cases (?purple
- blue?, ?black and white - grey?,...).
3.2 Best Scoring Choice Solution
The solution employed in the present submission
for selecting among the features described above
implements straight forward realization rather than
choice, in the sense in which (Cahill, 1998) uses the
terms for lexicalization. To implement real choice
the system would have to consider more than one al-
ternative for a specific feature and to select one of
them based on some criteria. This has not been done
in the present submission. Instead, a single alterna-
tive has been implemented for each feature, using
it consistently across all samples. The selection of
which particular alternative to implement has been
done empirically to ensure the best possible score
over the training corpus.
3.3 Results and Discussion
Results obtained over the training and development
data are shown in Table 2.
SE distance Accuracy
Train. Furniture 4,26 14,15%
People 5,43 9,12%
Both 4,8 11,82%
Dev. Furniture 4,21 15%
People 4,94 7,35%
Both 4,54 11,48%
Table 2:Task 2 results for training and development data
An important point to consider with respect to
the current submission is whether a solution im-
plementing real choice would have obtained bet-
ter results. Such a solution might have benefited
from the information that can be extracted from the
ANNOTATED-WORD-STRING to train a decision
procedure on the various features. This has not been
addressed in the present submission more for lack of
time than lack of conviction on its merit.
Addressing explicitly some of the possible con-
structions that are described in section 3.1 may also
have a positive effect on the results.
4 NIL-UCM-FVBS Entry for Task 3
The NIL-UCM-FVBS entry for Task 3 applies
a combination of the Most-Frequent-Value-First
method for Attribute Selection and the Best-
Scoring-Choice approach to Realization.
The modular architecture of TAP has allowed
easy integration for Task 3 of the solution for at-
tribute selection described in section 2, and the so-
lution for realization described in section 3.
4.1 Results and Discussion
Results obtained over the training and development
data are shown in Table 3. Comparing both sets of
results there are no surprises in the final results: the
system gets similar results with both domains and
217
with both the training and development data. These
results confirm that the probability of appearance of
an attribute depending on its value is more or less
the same in the whole corpus.
SE distance Accuracy
Train. Furniture 5,03 5,03%
People 6,11 5,47%
Both 5,53 5,24%
Dev. Furniture 5,06 3,75%
People 6,24 1,47%
Both 5,60 2,70%
Table 3:Task 3 results for training and development data
The results obtained are a bit lower than the ones
obtained by both the attribute selection and realiza-
tion submodules separately. This is not an unex-
pected result. Bad choices produced in the attribute
selection are propagated through the realization, re-
sulting in accumulated errors in the final evaluation.
However, there are additional shortcomings that
arise from considering the general goal of task 3
as a composition of task 2 over task 1. The re-
duction of the types of expression produced by hu-
man subjects to a set of attributes involves in some
cases a certain loss of information. This is par-
ticularly the case when the human-produced ex-
pressions involve attributes for which additional in-
formation is provided. This can be seen if the
ANNOTATED-WORD-STRING is compared with
the actual attribute set generated for some of the
human-produced expressions. For instance, the cor-
pus contains examples in which the hasBeard at-
tribute has a nested attribute that indicates the beard
is white. Other examples provide color information
on pieces of clothing worn. This information is lost
to the realization stage if the data have to go through
task 1, which reduces the available format to a set of
individual unstructured attributes.
Considering a version of task 3 that allowed full
realization directly from input data as considered for
task 1, with no requirements on the stages of inter-
mediate representation to be employed in the pro-
cess, may result in a richer range of realizations, and
possibly in improved performance with respect to
human evaluation.
In more general terms, it seems that the corpus
does contain adequate data for informing system
performance at the level of sentence planning sub-
tasks such as lexical choice or syntactic choice. Nev-
ertheless, some of the variations in the corpus, such
as the free use of determiners or the flexibility that
subjects exhibit in the way they refer to the images
do introduce a certain ?noise?. Instances of these oc-
cur when human-produced descriptions involve in-
tense forms of ellipsis, and agrammatical ordering
of attributes. Some of these might be reduced if a re-
fined version of the corpus were produced with more
control on the experimental settings, to ensure that
subjects either described the elements as images or
as the things represented in the images, for instance.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2006-14433-C02-01
project) and the UCM and the Direccio?n General de
Universidades e Investigacio?n of the CAM (CCG07-
UCM/TIC-2803).
References
Cahill, Lyne. 1998. Lexicalisation in applied NLG sys-
tems. Technical Report ITRI-99-04.
Elhadad, Michael. 1993. Technical Report CUCS-038-
91. Columbia University.
Elhadad, Michael and Robin, Jacques. 1996. Technical
Report 96-03. Department of Computer Science, Ben
Gurion University.
Gerva?s, Pablo. 2006. SurReal: a Surface Realiza-
tion module. Natural Interaction based on Language
Group Technical Report, Universidad Complutense de
Madrid, Spain.
Gerva?s, Pablo. 2007. TAP: a Text Arranging Pipeline.
Natural Interaction based on Language Group Tech-
nical Report, Universidad Complutense de Madrid,
Spain.
Herva?s, Raquel and Gerva?s, Pablo. 2007. NIL: Attribute
Selection for Matching the Task Corpus Using Rela-
tive Attribute Groupings Obtained from the Test Data.
First NLG Challenge on Attribute Selection for Gener-
ating Referring Expressions (ASGRE), UCNLG+MT
Workshop, Machine Translation Summit XI, Copen-
hagen.
Reiter, Ehud and Dale, Robert. 1992. A fast algorithm
for the generation of referring expressions. Proceed-
ings of the 14th conference on Computational Linguis-
tics, pp. 232-238. Association for Computational Lin-
guistics.
218
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 128?136,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Experimental Identification of the Use of Hedges in the Simplification of
Numerical Expressions
Susana Bautista and Raquel Herva?s and Pablo Gerva?s
Universidad Complutense de Madrid, Spain
{raquelhb,subautis}@fdi.ucm.es, pgervas@sip.ucm.es
Richard Power and Sandra Williams
Department of Computing, The Open University, Milton Keynes MK76AA, UK
{r.power,s.h.williams}@open.ac.uk
Abstract
Numerical information is very common in
all kinds of documents from newspapers and
magazines to household bills and wage slips.
However, many people find it difficult to un-
derstand, particularly people with poor educa-
tion and disabilities. Sometimes numerical in-
formation is presented with hedges that mod-
ify the meaning. A numerical hedge is a word
or phrase employed to indicate explicitly that
some loss of precision has taken place (e.g.,
?around?) and it may also indicate the di-
rection of approximation (e.g., ?more than?).
This paper presents a study of the use of nu-
merical hedges that is part of research inves-
tigating the process of rewriting difficult nu-
merical expressions in simpler ways. We car-
ried out a survey in which experts in numer-
acy were asked to simplify a range of pro-
portion expressions and analysed the results to
obtain guidelines for automating the simplifi-
cation task.
1 Introduction
All public information services and documents
should be accessible in such a way that makes them
easily understood by everybody, according to the
United Nations (1994). Nowadays, a large percent-
age of information expressed in daily news comes
in the form of numerical expressions (statistics of
economy, demography data, etc). But many people
have problems with understanding such expressions
-e.g., people with limited education or some kind of
mental disability.
Lack of ability to understand numerical informa-
tion is an even greater problem than poor literacy.
A U.K. Government Survey in 2003 estimated that
6.8 million adults had insufficient numeracy skills
to perform simple everyday tasks such as paying
house-hold bills and understanding wage slips, and
23.8 million adults would be unable to achieve grade
C in the GCSE maths examination for 16 year-old
school children (Williams et al, 2003).
A first possible approach to solve this impor-
tant social problem is making numerical informa-
tion accessible by rewriting difficult numerical ex-
pressions using alternative wordings that are easier
to understand. Some loss of precision could have
positive advantages for numerate people as well as
less numerate. Such an approach would require a
set of rewriting strategies yielding expressions that
are linguistically correct, easier to understand than
the original, and as close as possible to the original
meaning.
In rewriting, hedges play an important role. For
example,?50.9%? could be rewritten as ?just over
half? using the hedge ?just over?. In this kind of
simplification, hedges indicate that the original num-
ber has been approximated and, in some cases, also
the direction of approximation.
This paper presents a preliminary study of the use
of hedges when numerical expressions are simplified
to make them more accessible. We have carried out
a survey in which experts in numeracy were asked to
simplify a range of proportion expressions to obtain
guidelines for developing the numerical expressions
simplification task automatically. As a first step to-
wards more complex simplification strategies, we
128
are trying to simplify numerical expressions without
losing substantial information. Our study does not
have a particular kind of disability in mind. Rather,
we aim to simplify according to levels of difficulty
defined in the Mathematics Curriculum of the Quali-
fications and Curriculum Authority (1999). Adapta-
tion to particular types of users is beyond the scope
of this paper.
2 Background
Text simplification, a relative new task in Natu-
ral Language Processing, has been directed mainly
at syntactic constructions and lexical choices that
some readers find difficult, such as long sentences,
passives, coordinate and subordinate clauses, ab-
stract words, low frequency words, and abbrevia-
tions. Chandrasekar et al (1996) introduced a two-
stage process, first transforming from sentence to
syntactic tree, then from syntactic tree to new sen-
tence; Siddharthan (2002) instead proposed a three-
stage process comprising analysis, transformation
and generation. In 1998, the project PSET (Car-
roll et al, 1998) employed lexical as well as syn-
tactic simplifications. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007). There has been some previous
work on numerical expressions but more for experts
than for people who have difficulties with numer-
acy (Ellen Peters and Dieckmann, 2007), (Nathan
F. Dieckmann and Peters, 2009), (Ann M. Bisantz
and Munch, 2005), (Mishra H, 2011). However,
to our knowledge, there have been no previous at-
tempts to automatically simplify numerical informa-
tion in texts.
A corpus of numerical expressions was collected
for the NUMGEN project (Williams and Power,
2009). The corpus contains 10 sets of newspaper ar-
ticles and scientific papers (110 texts in total). Each
set is a collection of articles on the same topic ?
e.g., the increased risk of breast cancer in red meat
eaters, and the decline in the puffin population on
the Isle of May. Within each set, identical numeri-
cal facts are presented in a variety of linguistic and
mathematical forms.
3 Experiment
Our survey took the form of a questionnaire in
which participants were shown a sentence contain-
ing one or more numerical expressions which they
were asked to simplify using hedges if necessary.
3.1 Materials
Our simplification strategies are focused at two lev-
els: decimal percentages and whole-number per-
centages. For the survey we chose three sets of can-
didate sentences from the NUMGEN corpus: eight
sentences containing only decimal percentages and
two sets of eight sentences containing mixed whole-
number and decimal percentages. The number of
numerical expressions are more than eight because
some sentences contained more than one proportion
expression.
A wide spread of proportion values was present in
each set, including the two end points at nearly 0.0
and almost 1.0. We also included some numerical
expressions with hedges and sentences from differ-
ent topics in the corpus. In short, we included as
many variations in context, precision and different
wordings as possible.
3.2 Participants
We carried out the survey with primary or secondary
school mathematics teachers or adult basic numer-
acy tutors, all native English speakers. We found
them through personal contacts and posts to Inter-
net forums. The task of simplifying numerical ex-
pressions is difficult, but it is a task that this group
seemed well qualified to tackle since they are highly
numerate and accustomed to talking to people who
do not understand mathematical concepts very well.
Our experimental evaluation involved 34 partici-
pants who answered at least one question in our sur-
vey (some participants did not complete it).
3.3 Survey Design and Implementation
The survey was divided into three parts as follows:
1. Simplification of numerical expressions for a
person who can not understand percentages
2. Simplification of numerical expressions for a
person who can not understand decimals
129
3. Free simplification of numerical expressions
for a person with poor numeracy
Each part of the survey is considered as a differ-
ent kind of simplification: (1) simplification with no
percentages, (2) simplification with no decimals and
(3) free simplification.
For part (2), the set of sentences containing only
decimal percentages was used. One of the two
mixed sets of sentences with whole-number and
decimal percentages was used for part (1) and the
other for part (3). The experiment was presented on
SurveyMonkey1, a commonly-used provider of web
surveys. The survey was configured so that partic-
ipants could leave the questionnaire and later con-
tinue with it.
We asked participants to provide simplifications
for numerical expressions that were marked by
square brackets in each sentence. Below the sen-
tence, each bracketed number was shown beside a
text box in which the participant was asked to type
the simplified version. Our instructions said that nu-
merical expressions could be simplified using any
format: number words, digits, fractions, ratios, etc.
and that hedges such as ?more than?, ?almost? and
so on could be introduced if necessary. Participants
were also told that the meaning of the simplified ex-
pression should be as close to the original expres-
sion as possible and that, if necessary, they could
rewrite part of the original sentence. Figure 1 shows
a screenshot of part of the questionnaire.
3.4 Underlying assumptions
A numerical expression (NE) is considered to be a
phrase that represents a quantity, sometimes modi-
fied by a numerical hedge as in ?less than a quarter?
or ?about 20%?. We have restricted coverage to pro-
portions -i.e., fractions, ratios and percentages. We
had five hypotheses:
? H1: The use of hedges to accompany the sim-
plified numerical expression is influenced by
the simplification strategy selected. We con-
sider the use of fractions, ratios and percent-
ages like simplification strategies.
? H2: The use of hedges to simplify the numeri-
cal expression is influenced by the value of the
1www.surveymonkey.com
proportion, with values in the central range (say
0.2 to 0.8) and values at the extreme ranges (say
0.0-0.2 and 0.8-1.0) having a different use of
hedges.
? H3: The loss of precision allowed for the sim-
plified numerical expression is influenced by
the simplification strategy selected.
? H4: There is some kind of correlation between
the loss of precision and the use of hedges, in
such a way that the increase or decrease in the
former influences changes in the latter.
? H5: As an specific case of H4, when writers
choose numerical expressions for readers with
low numeracy, they do not tend to use hedges if
they are not losing precision.
4 Results
The results of the survey were carefully analyzed as
follows. First, within each block of questions, a set
of simplification strategies was identified for each
specific numerical expression. These strategies were
then grouped together according to the mathematical
forms and/or linguistic expressions employed (frac-
tions, ratios, percentages).
With a view to using these data to design an au-
tomated simplification system, these data have to be
analyzed in terms of pairs of a given input numeri-
cal expression and the simplified expression result-
ing from applying a specific simplification strategy.
For such pairings, three important features must be
considered as relevant to choosing a realization:
? Whether any numbers in the expression are re-
alized as one of the different types of available
expressions (fractions, ratios, percentages).
? The loss of precision involved in the simplifi-
cation.
? The possible use of a hedge to cover this loss
of precision explicitly in the simplified expres-
sion.
To calculate the loss of precision, we defined
Equation 1.
error =
(simplifiedNE ? originalNE)
originalNE
(1)
130
Figure 1: Screenshot of part of the questionnaire.
The set of pairings of input expression and ob-
served simplification strategies, loss of precision and
use of hedges as found in the results of the survey is
given in Tables 1, 2 and 3. For each input numer-
ical expression, the set of available simplification
strategies is represented as three lines in the table.
For each pairing, three columns are shown in the
table. Empty cells represent that the strategy was
not used. The first column presents the relative fre-
quency of usage with respect to the total set of possi-
ble simplification strategies used for that expression.
The second column captures the loss of precision in-
volved, represented in terms of the ratio between the
value of the difference between the original numer-
ical value in the input expression and the numerical
value that is conveyed by the corresponding simpli-
fied expression (using Equation 1). This ratio is also
expressed as a percentage. The third column indi-
cates the percentage of simplified numerical expres-
sions that contained a hedge. All of them are mean
values.
Each line represents one kind of simplification
strategy used to simplify the original numerical ex-
pression. Another point to explain is that frequen-
cies that belong to the same expression do not al-
ways add up to 100%. This is because a small num-
ber of others kinds of simplification strategies, like
deletions or rewriting of the whole sentence, are not
shown in the table. Moreover, we must keep in mind
that not all participants answered each question of
the survey.
Table 1 presents the relationships identified be-
tween the original numerical expressions and the
simplification strategies (presented as lines) for the
results of the first part of the survey (simplification
of numerical expressions for a person who can not
understand percentages). All the values are repre-
sented in percentages. Table 2 represents the same
data for the second part of the survey (simplification
of numerical expressions for a person who can not
understand decimals) and Table 3 for the third part
(free simplification of numerical expressions for a
person with poor numeracy).
In the three parts of the survey, the percentage of
simplifications that use hedges is slightly higher than
that of those not using hedges especially in the sec-
ond and third part of the survey. Adapting original
numerical expressions by inserting hedges accounts
for more than the 50% of cases. This reinforces
our assumption that simplifications involving loss of
precision may be better understood if an appropriate
hedge is used.
4.1 Analysis of the Use of Hedges in the
Simplified Numerical Expressions
In order to test hypothesis H1 (the use of hedges
in the simplified numerical expression is influenced
by the simplification strategy selected), we carried
out a series of two sample t-tests where statistical
significance was adjusted for multiple comparisons
by using the Bonferroni correction. Results are pre-
sented in Table 4. When considering the entire sur-
vey (Whole column), there is no significant differ-
ence in the use of hedges in fractions and percent-
ages. When analyzing the survey by parts we find
similar results. There is no significant difference in
the use of hedges in any strategy in the second (no
decimals) and the third (free simplification) parts of
131
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 18 0 67
more than 1% Ratios 6 0 100
Percentages 18 17 50
Fractions 6 0 50
2% Ratios 18 -1 17
Percentages 12 0 0
Fractions 26 1 67
16.8% Ratios 65 5 45
Percentages 9 -3 0
Fractions 82 -4 86
27% Ratios 12 8 75
Percentages 6 6 50
Fractions 41 0 93
at least 30% Ratios 35 13 67
Percentages 3 0 100
Fractions 53 12 50
40% Ratios 29 0 10
Percentages 6 0 0
Fractions 82 -13 82
56% Ratios
Percentages 6 -5 50
Fractions 74 -3 84
63% Ratios 24 0 75
Percentages 3 0 0
Fractions 32 0 0
75% Ratios 29 0 0
Percentages
Fractions 3 0 0
97.2% Ratios 38 -8 23
Percentages 18 1 50
Fractions 6 0 0
98% Ratios 12 0 0
Percentages 3 0 0
Fractions 39 -1 53
Average Ratios 24 2 41
Percentages 7 1 30
Table 1: Analysis of the data for 34 participants from the
first part of the survey (simplifications intended for peo-
ple who do not understand percentages). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
the survey, but in the first part (no percentages) we
find significant difference between fractions and ra-
tios (p<0.0006). These results do not support the
hypothesis, as there is not a direct relation between
the use of hedges and the selected strategy.
We performed another t-test adjusted by using the
Bonferroni correction on the simplification strate-
gies and central and peripheral values to test hypoth-
esis H2 (the use of hedges to simplify the numerical
expression is influenced by the value of the propor-
tion, with values in the central range (say 0.2 to 0.8)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) having a different use of hedges). In this
case there is also no significant difference. The re-
sults show that the use of hedges is not influenced by
central and peripheral values, rejecting our hypoth-
esis H2 with a p-value p=0.77 in the worst case for
the percentages strategy.
A new t-test adjusted by using the Bonferroni cor-
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 6 25 50
0.6% Ratios 9 22 33
Percentages 47 21 100
Fractions 3 -29 0
2.8% Ratios 24 6 63
Percentages 47 7 63
Fractions
6.1% Ratios 18 -4 50
Percentages 50 -3 82
Fractions 12 9 75
7.5% Ratios 12 -10 0
Percentages 50 7 41
Fractions 15 -1 80
15.5% Ratios 12 6 50
Percentages 44 2 33
Fractions 15 -3 100
25.9% Ratios 12 -3 75
Percentages 38 5 62
Fractions 3 0 0
29.1% Ratios 15 3 60
Percentages 50 2 71
Fractions 12 -5 100
35.4% Ratios 15 -4 60
Percentages 41 -1 71
Fractions 44 -2 93
50.8% Ratios 3 0 0
Percentages 21 0 43
Fractions 44 1 93
73.9% Ratios 6 1 50
Percentages 18 0 50
Fractions 3 0 0
87.8% Ratios 15 -1 60
Percentages 47 1 88
Fractions 3 0 0
96.9% Ratios 12 -2 75
Percentages 29 0 80
Fractions 6 0 50
96.9% Ratios 18 -1 67
Percentages 21 0 86
Fractions 3 0 0
97.2% Ratios 18 -1 67
Percentages 41 0 93
Fractions 3 0 0
97.2% Ratios 18 -1 83
Percentages 32 0 91
Fractions 3 0 0
98.2% Ratios 15 -2 40
Percentages 44 0 67
Fractions 11 0 43
Average Ratios 14 1 52
Percentages 39 2 70
Table 2: Analysis of the data for 34 participants from
the second part of the survey (simplifications intended for
people who do not understand decimals). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
rection was done to test hypothesis H3 (the loss of
precision allowed for the simplified numerical ex-
pression is influenced by the simplification strategy
selected). Table 5 shows significant differences be-
tween each simplification strategy and each kind of
simplification. In the Whole column we can observe
that the loss of precision in fractions is significantly
different to the one in ratios and percentages. In the
first part (no percentages) there is a significant dif-
ference between ratios and the rest of simplification
strategies. In the second part (no decimals) there is
132
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions
0.7% Ratios 6 43 100
Percentages 9 43 100
Fractions 6 -17 100
12% Ratios 21 -8 71
Percentages 21 -17 100
Fractions 41 -4 57
26% Ratios 12 -4 50
Percentages
Fractions 41 -8 86
36% Ratios 9 -2 67
Percentages
Fractions 41 -6 50
53% Ratios
Percentages 6 -6 50
Fractions 21 -5 100
65% Ratios 18 -1 33
Percentages 3 0 0
Fractions 15 0 20
75% Ratios 9 0 33
Percentages 3 0 0
Fractions
91% Ratios 29 -1 50
Percentages 6 -1 50
Fractions
above 97% Ratios 32 0 64
Percentages 6 2 100
Fractions 18 -7 69
Average Ratios 15 3 59
Percentages 6 3 57
Table 3: Analysis of the data for 34 participants from the
third part of the survey (free simplification intended for
people with poor literacy). All values are percentages.
The first column represents the frequencies of use for
each simplification strategy. The second column shows
the error as the loss of precision involved in the simplifi-
cation. And the last column displays the use of hedges in
the simplifications.
no significant difference between any strategy. And
in the last part (free simplification) there is only a
significant difference between fractions and ratios.
These results seem not to support the hypothesis,
as there is not a direct relation between the use of
hedges and the loss of precision in the simplified nu-
merical expression.
For hypothesis H4 (there is some kind of corre-
lation between the loss of precision and the use of
hedges), we looked for correlations between each
part of the survey and each kind of simplification
strategy. We carried out a non-parametric measure
of statistical dependence between the two variables
(loss of precision and use of hedges) calculated by
the Spearman?s rank correlation coefficient.
In general, the results show no correlation, so
there is no linear dependence between the loss of
precision in the strategy and use of hedges, rejecting
our hypothesis. For example, there are cases with
a weak correlation (e.g. in the second part of the
survey for fractions with r=0.49, N=17 and p=0.03),
and cases where there is a strong correlation (e.g.
in the third part of the survey, with r=1, N=18 and
p<.0001).
Finally, when we analyzed hypothesis H5 (when
writers choose numerical expressions for readers
with low numeracy, they do not tend to use hedges if
they are not losing precision), we worked with each
part of the survey to study the cases where the loss
of precision is zero and what is the tendency of use
of hedges.
? In the first part of the survey (simplification
of numerical expressions for a person who can
not understand percentages), considering our
34 participants, in a 46% of responses the loss
of precision is zero, and for these cases only
11% used hedges.
? For the second part (simplification of numeri-
cal expressions for a person who can not un-
derstand decimals), considering our 34 partici-
pants, in a 16% of responses the loss of preci-
sion is zero and for these cases only 7% used
hedges.
? And finally, in the last part (simplification of
numerical expressions for a person with poor
numeracy), considering the same participants,
in a 23% of cases the loss of precision is zero
in the simplification and for these cases only
6% used hedges.
With this data, it seems that we can accept hypoth-
esis H5, that is, we found evidence for our assump-
tion that when writers choose numerical expressions
for readers with poor numeracy, they tend to use
hedges when they round the original numerical ex-
pression, i.e when the loss of precision is not zero.
4.2 Original Numerical Expressions with
Hedges
In our survey there were a few cases where the orig-
inal numerical expression had a hedge. We have
observed that if the original numerical expression
has hedge almost always the simplified numerical
expression contained a hedge. There is a special
case, ?above 97%? where we do not count the use
of hedges because in this case the participants chose
non-numeric options mostly and they rewrote the
numerical expression with phrases like ?around all?.
133
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A B A A A
Ratios B A A B
Table 4: Results of t-test adjusted by Bonferroni correction for H1 (the use of hedges in simplified numerical ex-
pressions is influenced by the simplification strategy selected). Strategies which do not share a letter are significantly
different.
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A A A B B
Ratios B A B B
Table 5: Results of t-test adjusted by Bonferroni correction for H3 (the loss of precision allowed for the simplified
numerical expression is influenced by the simplification strategy selected). Strategies which do not share a letter are
significantly different.
In the remaining cases, the same hedge is nearly al-
way chosen to simplify the numerical expression.
4.3 Kinds of Hedges
With respect to the actual hedges used, we have
identified two different possible roles of hedge in-
gredients in a numerical expression. In some cases,
hedges are used to indicate that the actual numeri-
cal value given is an approximation to the intended
value. Uses of about or around are instances of this.
This kind of hedge is employed to indicate explic-
itly that some loss of precision has taken place dur-
ing simplification. In other cases, hedges are used to
indicate the direction in which the simplified value
diverges from the original value. Uses of under or
over are instances of this. In some cases more than
one hedge may be added to an expression to indi-
cate both approximation and direction, or to some-
how specify the precision involved in the simplifica-
tion, as in just under or a little less than.
In our analysis we studied which hedges were
the most frequent in each part of the survey. Only
hedges with more than ten appearances in total (in-
cluding simplification strategies not present in the
table) have been considered in Table 6. We observed
that the three parts of the survey have three hedges
in common: about, just over and over. They are
used in different strategies for each kind of simpli-
fication. In the second part of the survey, where
simplifications of numerical expressions for a per-
son who can not understand decimals are done, is
where more hedges are used, in special for percent-
ages strategy. In the last part of the survey, where
there is more freedom to decide how simplify the
original numerical expression, participants used less
hedges compare to the others parts.
No Percentages
Hedge Fractions Ratios Percent.
about 15 9 0
at least 8 5 1
just over 21 1 0
more than 9 3 0
over 6 3 2
Total 59 21 3
No Decimals
Hedges Fractions Ratios Percent.
about 8 12 6
almost 4 1 8
just over 13 3 39
just under 3 2 27
nearly 7 5 24
over 7 5 9
Total 42 28 113
Free Simplification
Hedges Fractions Ratios Percent.
about 6 5 1
just over 6 0 5
more than 4 5 0
nearly 4 0 2
over 11 2 3
Total 31 12 11
Table 6: Use of the most frequent hedges in each part of
the survey
134
5 Discussion
As can be seen in the results, the use of hedges to
simplify numerical expressions can be influenced by
three parameters. The first is the kind of simplifica-
tion. Our survey was divided in three parts depend-
ing on the mathematical knowledge of the final user.
The second is the simplification strategy for choos-
ing mathematical form (fractions, ratios, or percent-
ages). In our data we observed some differences in
the usage of hedges with ratios and their usage with
fractions and percentages (see Table 4). The last pa-
rameter is the loss of precision that occurs when the
numerical expression is rounded. We investigated
the use of hedges vs. loss of precision with different
tests hoping to define some dependencies, but there
was no clear correlation between them, and it was
only when we tried a deeper analysis of strategies
and kind of simplifications that we found some cor-
relations such as those we presented in Section 4.1.
When asked to simplify for people who do not
understand percentages, or for people with poor nu-
meracy, the participants use different simplification
strategies and sometimes they use hedges to simplify
the original numerical expression. As some partic-
ipants commented, not only are percentages mathe-
matically sophisticated forms, but they may be used
in sophisticated ways in the text, often for example
describing rising and falling values, for which in-
creases or decreases can themselves be described in
percentages terms. Such complex relationships are
likely to pose problems for people with poor numer-
acy even if a suitable strategy can be found for sim-
plifying the individual percentages. In some of the
examples with more than one numerical expression
being compared, some of the evaluators reported a
tendency to phrase them both according to a com-
parable base. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole, and the meaning of the text) in
establishing what simplifications must be used.
6 Conclusions and Future Work
Through a survey administered to experts on nu-
meracy, we have collected a wide range of exam-
ples of appropriate simplifications of percentage ex-
pressions. These examples of simplified expressions
give us information about the use of hedges that our
participants carry out to adapt the original numer-
ical expression to be understood by the final user.
We investigated the loss of precision that occurs with
each hedge and the relation between the simplifica-
tion strategy and the use of hedges.
Our aim is to use this data to guide the develop-
ment of a system for automatically simplifying per-
centages in texts. With the knowledge acquired from
our study we will improve our algorithm to simplify
numerical expressions. We could determinate from
the simplification strategy, kind of simplification and
the loss of precision allowed, which will be the best
option to adapt the original numerical expression to
the final user and if that option uses hedges to under-
stand better the original numerical expression. As a
part of our algorithm, we will have to look at inter-
rater agreements for identifying appropriate hedges.
As future work, we plan to carry out another study
to determine a ranking of simplification strategies
from collecting a repertoire of rewriting strategies
used to simplify. This data should allow us to deter-
mine whether common values are considered sim-
pler and whether the value of the original expression
influences the chosen simplification strategy. So,
given a numerical expression, we could choose what
simplification strategy to apply and whether to insert
a hedge. We could investigate whether the value of
the original proportion also influences choices, de-
pending on its correspondence with central or pe-
ripheral values.
We have also collected a parallel corpus of numer-
ical expressions (original vs. simplified version).
This corpus will be shared with other researches so
it can be used in different applications to improve
the readability of text. This could be a very use-
ful resource because simplification of percentages
remains an interesting and non-trivial problem.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
135
References
Stephanie Schinzing Marsiglio Ann M. Bisantz and Jes-
sica Munch. 2005. Displaying uncertainty: Inves-
tigating the effects of display format and specificity.
Human Factors: The Journal of the Human Factors
and Ergonomics Society, 47(4):777.
J. Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait.
1998. Practical simplification of English newspaper
text to assist aphasic readers. In AAAI-98 Workshop on
Integrating Artificial Intelligence and Assistive Tech-
nology, Madison, Wisconsin.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and Methods for Text
Simplification. In COLING, pages 1041?1044.
Paul Slovic Ellen Peters, Judith Hibbard and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Shiv B. Mishra H, Mishra A. 2011. In praise of vague-
ness: malleability of vague information as a perfor-
mance booster. Psychological Science, 22(6):733?8,
April.
Paul Slovic Nathan F. Dieckmann and Ellen M. Peters.
2009. The use of narrative evidence and explicit like-
lihood by decisionmakers varying in numeracy. Risk
Analysis, 29(10).
The United Nations. 1994. Normas uniformes sobre la
igualdad de oportunidades para las personas con dis-
capacidad. Technical report.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analy-
sis. Speech and Language Technology for Education
(SLaTE).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the national curriculum for england. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving Attachment and
Clause Boundary Amgiguities for Simplifying Rela-
tive Clause Constructs. In Proceedings of the Student
Research Workshop, 40th Meeting of the Association
for Computacional Linguistics.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proceedings of the 12th European Work-
shop on Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
136
Proceedings of the 2th Workshop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pages 39?48,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
A System for the Simplification of Numerical Expressions at Different Levels
of Understandability
Susana Bautista, Raquel Herva?s,
Pablo Gerva?s
Universidad Complutense de Madrid
Prof. Jose? Garc??a Santesmases
Madrid, Spain
{subautis,raquelhb}@fdi.ucm.es
pgervas@sip.ucm.es
Richard Power, Sandra Williams
Department of Computing,
The Open University
Milton Keynes,
MK76AA, UK
r.power@open.ac.uk
s.h.williams@open.ac.uk
Abstract
The purpose of this paper is to motivate and
describe a system that simplifies numerical
expression in texts, along with an evaluation
study in which experts in numeracy and liter-
acy assessed the outputs of this system. We
have worked with a collection of newspaper
articles with a significant number of numerical
expressions. The results are discussed in com-
parison to conclusions obtained from a prior
empirical survey.
1 Introduction
A surprisingly large number of people have limited
access to information because of poor literacy. The
most recent surveys of literacy in the United King-
dom reveal that 7 million adults in England can-
not locate the reference page for plumbers if given
the Yellow Pages alphabetical index. This means
that one in five adults has less literacy than the ex-
pected literacy in an 11-year-old child (Jama and
Dugdale, 2010; Williams et al, 2003a; Christina and
Jonathan, 2010). Additionally, almost 24 million
adults in the U.K. have insufficient numeracy skills
to perform simple everyday tasks such as paying
household bills and understanding wage slips. They
would be unable to achieve grade C in the GCSE
maths examination for 16-year-old school children
(Williams et al, 2003a).
?The Standard Rules on the Equalization of Op-
portunities for Persons with Disabilities? by United
Nations (1994) state that all public information ser-
vices and documents should be accessible in such
a way that they could be easily understood. If we
focus on numerical information, nowadays, a large
percentage of information expressed in daily news
or reports comes in the form of numerical expres-
sions (economic statistics, demography data, etc)
but many people have problems understanding the
more complex expressions. In the text simplification
process, different tasks are carried out: replacing
difficult words, splitting sentences, etc., and the sim-
plification of numerical expressions is one of them.
A possible approach to solve this important social
problem of making numerical information accessi-
ble is to rewrite difficult numerical expressions using
alternative wordings that are easier to understand.
For example, the original sentence, ?25.9% scored A
grades? could be rewritten by ?Around 26% scored
A grades?. In our study we define a ?numerical ex-
pression? as a phrase that presents a quantity, some-
times modified by a numerical hedge as in these ex-
amples: ?less than a quarter? or ?about 98%?. Such
an approach would require a set of rewriting strate-
gies yielding expressions that are linguistically cor-
rect, easier to understand than the original, and as
close as possible to the original meaning. Some loss
of precision could have positive advantages for nu-
merate people as well as less numerate. In rewrit-
ing, hedges play also an important role. For exam-
ple, ?50.9%? could be rewritten as ?about a half? us-
ing the hedge ?about?. In this kind of simplification,
hedges indicate that the original number has been
approximated and, in some cases, also the direction
of the approximation.
This paper presents a system developed for auto-
mated simplification of numerical expressions. Ex-
perts in simplification tasks are asked to validate the
39
simplifications done automatically. The system is
evaluated and the results are discussed against con-
clusions obtained from previous empirical survey.
2 Previous work
Text simplification, a relative new task in Natural
Language Processing, has been directed mainly at
syntactic constructions and lexical choices that some
readers find difficult, such as long sentences, pas-
sives, coordinate and subordinate clauses, abstract
words, low frequency words, and abbreviations.
The rule-based paradigm has been used in the
implementation of some systems for text simpli-
fication, each one focusing on a variety of read-
ers (with poor literacy, aphasia, etc) (Chandrasekar
et al, 1996; Siddharthan, 2003; Jr. et al, 2009;
Bautista et al, 2009).
The transformation of texts into easy-to-read ver-
sions can also be phrased as a translation problem
between two different subsets of language: the orig-
inal and the easy-to-read version. Corpus-based sys-
tems can learn from corpora the simplification oper-
ations and also the required degree of simplification
for a given task (Daelemans et al, 2004; Petersen
and Ostendorf, 2007; Gasperin et al, 2009).
A variety of simplification techniques have been
used, substituting common words for uncommon
words (Devlin and Tait, 1998), activating passive
sentences and resolving references (Canning, 2000),
reducing multiple-clause sentences to single-clause
sentences (Chandrasekar and Srinivas, 1997; Can-
ning, 2000; Siddharthan, 2002) and making appro-
priate choices at the discourse level (Williams et al,
2003b). Khan et at. (2008) studied the tradeoff be-
tween brevity and clarity in the context of generat-
ing referring expressions. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007).
Previous work on numerical expressions has stud-
ied the treatment of numerical information in differ-
ent areas like health (Peters et al, 2007), forecast
(Dieckmann et al, 2009), representation of proba-
bilistic information (Bisantz et al, 2005) or vague
information (Mishra et al, 2011). In the NUM-
GEN project (Williams and Power, 2009), a corpus
of numerical expressions was collected and a for-
mal model for planning specifications for propor-
tions (numbers between 0 and 1) was developed.
The underlying theory and the design of the work-
ing program are described in (Power and Williams,
2012).
3 Experimental identification of
simplification strategies for numerical
information
In order to analyze different simplification strategies
for numerical expressions, first we have to study the
mathematical complexity of the expressions. Ex-
pressions can be classified and a level of difficulty
can be assigned. A study about the simplification
strategies selected by experts to simplify numerical
expressions expressed as decimal percentages in a
corpus was carried out in Bautista et al (2011b).
Other important aspect of the simplification task is
the use of hedges to simplify numerical expressions
in the text. A study was performed in Bautista et
al. (2011a) to analyze the use of hedges in the sim-
plification process. This study was done with ex-
perts in simplification tasks. A set of sentences with
numerical expressions were presented and they had
to rewrite the numerical expressions following some
rules. Several hypotheses were expressed and an-
alyzed to understand experts? preferences on sim-
plification strategies and use of hedges to simplify
numerical expressions in the text. The main conclu-
sions from the study were:
Conclusion 1: When experts choose expressions
for readers with low numeracy, they tend to prefer
round or common values to precise values. For ex-
ample, halves, thirds and quarters are usually pre-
ferred to eighths or similar, and expressions like N
in 10 or N in 100 are chosen instead of N in 36.
Conclusion 2: The value of the original propor-
tion influences the choice of simplification strategies
(fractions, ratios, percentages). With values in the
central range (say 0.2 to 0.8 in a 0.0 to 1.0 scale)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) favoring different strategies.
Conclusion 3: When writers choose numerical
expressions for readers with low numeracy, they
only use hedges if they are losing precision.
40
4 A system for adapting numerical
expressions
In this first prototype, only numerical expressions
defined as percentages are adapted. From an in-
put text, the percentage numerical expressions are
detected, a target level of difficulty is chosen and
the simplified version of the text is generated by re-
placing the original numerical expression with the
adapted expression.
4.1 Numerical expression
A numerical expression consists of: (1) a numerical
value, a quantity which may be expressed with dig-
its or with words; (2) an optional unit accompanying
the quantity (euro, miles, . . . ); and (3) an optional
numerical hedge modifier (around, less than, . . . ).
Some examples of numerical expressions used in
our experiments are: ?more than a quarter?, ?around
98.2%?, ?just over 25 per cent? or ?less than 100 kilo-
metres?.
4.2 Levels of difficulty
The Mathematics Curriculum of the Qualifications
and Curriculum Authority (1999) describes a num-
ber of teaching levels and we assume that concepts
to be taught at lower levels will be simpler than ones
taught at higher levels. Following this idea a Scale of
Mathematic Concepts is defined to identify the dif-
ferent levels of difficulty to understand mathematic
concepts. The scale defined from less to greater dif-
ficulty is: numerical expression in numbers (600),
words (six), fractions (1/4), ratios (1 in 4), percent-
ages (25%) and decimal percentages (33.8%).
From the Scale of Mathematic Concepts defined,
different levels of difficulty are considered in our
system. There are three different levels (from eas-
iest to hardest):
1. Fractions Level: each percentage in the text is
adapted using fractions as mathematical form
for the quantity, and sometimes a hedge is used.
2. Percentages without decimals Level (PWD):
the system rounds the original percentage with
decimals and uses hedges if they are needed.
3. Percentages with decimals Level: This is the
most difficult level where no adaptation is per-
formed.
The system operates only on numerical expres-
sions at the highest levels of the scale (the most dif-
ficult levels), that is, numerical expression given in
percentages or decimal percentages, adapting them
to other levels of less difficulty. So, the user can
select the level to which adapt the original numeri-
cal expression from the text. Using the interface of
the system, the level of difficulty is chosen by the fi-
nal user and the numerical expressions from the text
with higher level of difficulty than the level chosen
are adapted following the rules defined.
4.3 Set of strategies
A set of strategies is defined so they can be applied to
adapt the original numerical expression. The quan-
tity of the expression is replaced with another ex-
pression and sometimes numerical hedges are added
to create the simplified numerical expression.
The use of hedges to simplify numerical expres-
sion can be influenced by three parameters. The first
is the type of simplification depending on the math-
ematical knowledge of the final user. The second is
the simplification strategy for the choice of the final
mathematical form. And the last is the loss of preci-
sion that occurs when the expression is simplified.
Out of the European Guidelines for the Produc-
tion of Easy-to-Read Information for People with
Learning Disability (Freyhoff et al, 1998), only one
involves the treatment of numbers: ?Be careful with
numbers. If you use small numbers, always use the
number and not the word?. For example, if the texts
says ?four?, the system adapts it by ?4? following this
European Guideline. This strategy is applied by the
system at all levels.
There are other strategies to adapt numerical ex-
pressions in the form of percentage to other levels of
difficulty: (1) replace decimal percentages with per-
centages without decimals; (2) replace decimal per-
centages with ratios; (3) replace percentages with ra-
tios; (4) replace decimal percentages with fractions;
(5) replace percentages with fractions; (6) replace
ratios with fractions; (7) replace numerical expres-
sions in words with numerical expressions in digits.
At each level of difficulty, a subset of the strate-
gies is applied to simplify the numerical expression.
For the Fractions Level the strategies 4, 5 and 7
are used. For the Percentages with decimals Level
the strategies 1 and 7 are applied. And for the last
41
level, Percentages without decimals Level only the
last strategy, number 7, is used.
4.4 System operation
The system takes as input the original text. The user
of the system has to choose the level of difficulty. A
set of numerical expressions are selected and a set
of transformations is applied to adapt them, generat-
ing as output of the system a text with the numerical
expressions simplified at the chosen level.
The system works through several phases to adapt
the numerical expressions in the input text. Some of
them are internal working phases (2, 4 and 5). The
rest of them (1, 3 and 6) are phases where the user
of the system plays a role. The phases considered in
the system are:
1. Input text: an original text is selected to adapt
its numerical expressions.
2. Mark Numerical Expressions: the numerical
expressions that can be adapted are marked.
3. Choose the level of difficulty: the user chooses
the desired level of difficulty for the numerical
expressions in the text.
4. Adapt the numerical expression from the
text: each numerical expression is adapted if
the level of the numerical expression is higher
than the level of difficulty chosen.
5. Replace numerical expression in the text:
adapted numerical expressions replace the orig-
inals in the text.
6. Output text: the final adapted version of the
text is presented to the user.
The next subsections presents how the system acts
in each phase and what kind of tools are used to
achieve the final text.
4.4.1 Phase 1: Input text
In this first phase, a plain text is chosen as input to
the system to adapt its numerical expressions. Using
a Graphical User Interface (GUI) in Java, the user
can upload an original text.
4.4.2 Phase 2: Mark numerical expressions
For the text chosen, the system executes the Nu-
merical Expression Parser1. Using this parser the
numerical quantities are annotated with their type
(cardinal, fraction, percentage, decimal percentage,
etc.), their format (words, digits), their value (Vg),
their units, and hedging phrases, such as ?more
than?. The input to the program is the plain text file
and the output is the text with sentences and numer-
ical expressions annotated in XML format. In the
following code we can see how a numerical quantity
is annotated in the parser.
Overall figures showed the national pass
rate soared
<numex hedge=?above? hedge-
sem=?greaterthan? type=?percentage?
format=?digits? Vg=?0.97?>
above 97% </numex>
The XML file is treated by the system and numer-
ical expressions are marked in the original text. So,
the user can see which numerical expressions are go-
ing to be adapted by the system (in the next phase)
depending on the level of difficulty chosen.
4.4.3 Phase 3: Choose the level of difficulty
The user of the system chooses the level of dif-
ficulty to adapt the original numerical expressions.
There are three levels: fractions, percentages with-
out decimals and percentages with decimals.
4.4.4 Phase 4: Adapt the Numerical
Expressions
After deciding the level of difficulty, the system
has to adapt each numerical expression to generate
the final version. The process of simplification has
two stages: obtaining the candidate and applying the
adaptation and hedge choice rules.
From the XML file produced by the parser the fol-
lowing information for a numerical expression is ob-
tained: (1) if there is or not hedge and the kind of
hedge; (2) the type (cardinal, fraction, percentage,
decimal percentage) and format (digits or words)
of the original numerical expression; (3) the given
value (Vg) translated from the original numerical ex-
pression value of the text; and (4) the units from the
1For more details see (Williams, 2010)
42
O
rig
in
al
 
Ex
pr
es
sio
n
Pa
rs
er
Vm
g
Pr
op
or
tio
n
Ap
pr
ox
.
Pr
og
ra
m
Vr
M
or
e 
th
an
 2
8%
0.
28
0.
28
1/
3
0.
33
Vg
Vc
[0
...
1]
[0
...
1]
1/
3
30
%
28
%
Figure 1: Obtaining the candidate for simplification. The original expression is annotated by the parser (Vg), and this
value is normalized (Vmg). A candidate substitute value (Vc) is chosen from the proportion approximation program
and normalized (Vr).
original expression (M, ins, grams). For example,
if in the text the original numerical expression is a
percentage like ?25.9%?, there is no hedge, the type
is ?decimal percentage?, the format is ?digits?, Vg is
0.259 and there are no units. In the expression, ?20
grams?, there is no hedge, the type is ?cardinal?, the
format is ?digits?, Vg is 20 and the parser annotates
the units with ?g?.
The given value Vg annotated by the parser is
transformed into a value between 0 to 1, referred
to as mapping given value (Vmg), which represents
the proportion under consideration. This value is
given as input to the proportion approximation pro-
gram (Power and Williams, 2012), which returns a
list of candidates for substitution. From this list,
the first option is taken as candidate substitute value
(Vc), because the program returns them in decreas-
ing order of precision. This means that the most
precise candidate at the required level of difficulty
is chosen. The program also might return the val-
ues ?none? and ?all? if the input value is close to
0 or 1, respectively. From the Vc we calculate the
rounded value (Vr) corresponding to the normaliza-
tion of the candidate value between 0 to 1. For ex-
ample, if Fraction level is chosen, for the original
expression ?more than 28%? with Vmg=0.28, the
system chooses Vc=1/3 with Vr=0.33. The whole
process can be seen in Figure 1.
An additional level of adaptation is required be-
yond simple replacement with the candidate substi-
tute value. If the original numerical expressions in
the text are difficult to understand, the system must
adapt them to the desired level of difficulty. For each
numerical expression, the system only applies the
adaptation rules if the difficulty level of the numer-
ical expression is higher than the level of difficulty
chosen by the user. This is captured by a set of three
adaptation rules:
? If the type of the numerical expression is ?car-
dinal? and the format is ?words? then the candi-
date to be used in the simplification is Vg. For
example, if the original numerical expression is
?six?, it will be replaced by ?6?.
? In a similar way, if the type is ?fraction? (the
lowest possible level of difficulty) and the for-
mat is also ?words? then the candidate is ob-
tained by applying the proportion approxima-
tion program. For example, if the original nu-
merical expression is ?a quarter?, it would be
replaced by ?1/4?.
? If the type is ?percentages? or ?decimal percent-
ages? and the format is ?digits? then the can-
didate is calculated by the proportion approxi-
mation program provided that the level of dif-
ficulty chosen in the GUI was lower than the
level of the calculated numerical expression.
In order to complete the simplification, the system
has to decide if a hedge should be used to achieve
the final version of the adapted numerical expres-
sion. This decision is taken based on the difference
in value between the value of the original expression
in the text (Vg) and the value of the candidate substi-
tute (Vc) (as given by the relative difference between
the normalized values Vr and Vmg calculated in the
first stage). The actual hedge used in the original
expression (if any) is also considered. The various
possible combinations of these values, and the corre-
sponding choice of final hedge, are described in Ta-
ble 1, which presents all possible options to decide
in each case, the hedge and the value corresponding
to the final numerical expression. For example, if
the original expression is ?more than 28%?, we have
Vc=1/3, Vmg=0.28 and Vr=0.33. Then Vr>Vmg so
the corresponding choice of the final hedge is in the
43
OriginalNumExp if Vr>Vmg if Vr=Vmg if Vr<Vmg
more than OrigValue around Vc more than Vc more than Vc
exactly OrigValue less than Vc exactly Vc more than Vc
less than OrigValue less than Vc less than Vc around Vc
OrigValue around Vc Vc around Vc
Table 1: Hedge Choice Rules. For each original expression (OrigValue), the normalized values (Vmg, Vr) are used to
determinate the hedge chosen for the simplified expression. The final version is composed by the hedge chosen and
the candidate value (Vc)
first column of Table 1 (?around?) and the simplified
expression is ?around 1/3?.
When the user chooses the Fraction Level in the
system, every numerical expression with difficulty
level greater than fraction level will be replaced by
a numerical expression expressed in fraction form.
Depending on the values Vr and Vmg, the appropri-
ate hedge will be chosen.
4.4.5 Phase 5: Replace numerical expressions
Once the system has applied its rules, an adapted
version is available for each original numerical ex-
pression which was more difficult than the target dif-
ficulty level. The output text is obtained by replac-
ing these difficult expressions with the correspond-
ing simplified version.
5 Evaluation of the system
This section presents the evaluation of the system,
describing the materials, experiment, participants
and results of the evaluation.
5.1 Materials
We selected for the experiment a set of eight can-
didate sentences from the NUMGEN corpus, but the
number of numerical expressions was larger as some
sentences contained more than one proportion ex-
pression. In total we had 13 numerical expressions.
We selected sentences with as many variations in
context, precision and different wordings as possi-
ble. The range of proportions values was from points
nearly 0.0 to almost 1.0, to give coverage to a wide
spread of proportion values. We considered values
in the central range (say 0.2 to 0.8) and values at the
extreme ranges (say 0.0-0.2 and 0.8-1.0). We also
classified as common values the well-known per-
centages and fractions like 25%, 50%, 1/4 and 1/2,
and as uncommon values the rest like 15% or 6/7.
5.2 Experiment
To evaluate the system a questionnaire was pre-
sented to a set of human evaluators. The experi-
ment was created and presented on SurveyMonkey2,
a commonly-used provider of web surveys. For each
original sentence, we presented two possible simpli-
fications generated by the system. Participants were
asked to use their judgement to decide whether they
agreed that the simplified sentences were acceptable
for the original sentence. A Likert scale of four val-
ues (Strongly Disagree, Disagree, Agree, Strongly
Agree) was used to collect the answers.
In the survey only two levels of adaptation from
the original sentence were presented. The first op-
tion generated by the system was for the Fractions
level. The second option generated by the system
was for the Percentages without decimals (PWD).
5.3 Participants
The task of simplifying numerical expressions is dif-
ficult, so we selected a group of 34 experts made up
of primary or secondary school mathematics teach-
ers or adult basic numeracy tutors, all native English
speakers. This group is well qualified to tackle the
task since they are highly numerate and accustomed
to talking to people who do not understand mathe-
matical concepts very well. We found participants
through personal contacts and posts to Internet fo-
rums for mathematics teachers and numeracy tutors.
5.4 Results
The answers from the participants were evaluated.
In total we collected 377 responses, 191 responses
for the Fraction level and 186 responses for the Per-
centage without decimals (PWD). Table 2 shows the
average from the collected responses, considering 1
2http://www.surveymonkey.com/s/WJ69L86
44
Level Total average Values Average Values Average
Fraction 2,44
Central 2,87 Common 2,59
Extreme 2,14 Uncommon 1,21
PWD 2,96
Central 3,00 Common 2,80
Extreme 2,96 Uncommon 3,22
Table 2: System Evaluation: Fraction Level and Percentages Without Decimals (PWD)
Opinion Fraction PWD
Level Level
Strongly Disagree 19% 6%
Disagree 27% 15%
Agree 43% 56%
Strongly Agree 11% 23%
Table 3: Opinion of the experts in percentages
to 4 for strongly disagree to strongly agree. In ad-
dition, Table 3 shows the distribution in percentages
of the opinion of the experts. At the Fraction level,
there is not too much difference between the average
of the answers of the experts that agree with the sys-
tem and those that disagree. Most experts are neu-
tral. But for the PWD level the average shows that
most experts agree with the simplification done.
We have also analyzed the answers considering
two different criteria from the original numerical ex-
pressions: when they are central (20% to 80%) or
extreme values (0% to 20% and 80% to 100%), and
when the original numerical expressions are com-
mon or uncommon values. In general terms, the ex-
perts think that the simplification done by the sys-
tem in the PWD level is better than the simplification
done in the Fraction level. They disagree specially
with the simplification using fractions in two cases.
One is the treatment of the extreme values where the
system obtains as possible candidates ?none? and
?all?3. Another case is when uncommon fractions
are used to simplify the numerical expression, like
for example 9/10. In these two cases the average is
lower than the rest of the average achieved.
5.5 Discussion
The system combines syntactic transformations (via
the introduction of hedges) and lexical substitu-
3See (Power and Williams, 2012) for a discussion of appro-
priate hedges for values near the extreme points of 0 and 1.
tions (by replacing actual values with substitution
candidates and transforming quantities expressed as
words into digits) to simplify the original numerical
expression. These kinds of transformations are dif-
ferent from those used by other systems, which rely
only on syntactic transformations or only on lexi-
cal substitutions. Rules are purpose-specific and fo-
cused on numerical expressions. With this kind of
transformations the readability of the text improves
in spite of the fact that the resulting syntactic struc-
ture of the numerical expression is more compli-
cated, due to the possible presence of hedges. For
example, for a original numerical expression like
?25.9%? the system generates the simplified ?more
than a quarter? which is easier to understand even
though longer and syntactically more complex.
With respect to coverage of different types of nu-
merical expressions, this system does not consider
ratios as a possible simplification strategy because
the proportion approximation program does not use
them as candidates to simplify a proportion. This
possibility should be explored in the future.
Another observation is that the system does not
consider the context of the sentence in which the
numerical expression occurs. For example, if the
sentence makes a comparison between two numer-
ical expressions that the system rounded to the same
value, the original meaning is lost. One example
of this case is the following sentence from the cor-
pus: ?One in four children were awarded A grades
(25.9%, up from 25.3% last year)?. Both percent-
ages ?25.9%? and ?25.3%? are simplified by the sys-
tem using ?around 1/4? and the meaning of the sen-
tence is lost. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole and the meaning of the text) in
establishing what simplifications must be used.
45
6 Conforming with conclusions of prior
surveys
The results presented for the system are evaluated
in this section for conformance with the conclusions
resulting from the empirical studies described in
(Bautista et al, 2011b) and (Bautista et al, 2011a).
With respect to the preference for round or com-
mon values in simplification (Conclusion 1), the sys-
tem presented conforms to this preference by virtue
of the way in which the list of candidate substitu-
tions is produced by the program. The candidates re-
turned by the program are already restricted to com-
mon values of percentages (rounded up) and frac-
tions, so the decision to consider as preferred candi-
date the one listed first implicitly applies the criteria
that leads to this behavior.
With respect to the need to treat differently values
in the extreme or central ranges of proportion (Con-
clusion 2), the system addresses this need by virtue
of the actual set of candidates produced by the pro-
gram in each case. For example, if the original ex-
pression is a extreme value like ?0.972?, the program
produces a different candidate substitution (?almost
all?) that in the central ranges is not considered.
With respect to restricting the use of hedges to
situations where loss of precision is incurred (Con-
clusion 3), the hedge choice rules applied by the
system (see Table 1) satisfy this restriction. When
Vr=Vmg hedges are included in the simplified ex-
pression only if they were already present in the
original expression.
In addition, the system rounds up any quantities
with decimal positions to the nearest whole num-
ber whenever the decimal positions are lost during
simplification. This functionality is provided im-
plicitly by the program, which presents the rounded
up version as the next option immediately follow-
ing the alternative which includes the decimal posi-
tions. For example, if the input proportion is ?0.198?,
some rounded candidate substitutions are calculated
as ?almost 20%? or ?less than 20%?.
Finally, the system follows the European guide-
lines for the production of easy to read information
in that it automatically replaces numerical quantities
expressed in words with the corresponding quantity
expressed in digits.
7 Conclusions and future work
The system described in this paper constitutes a first
approximation to the task of simplifying numerical
expressions in a text to varying degrees of difficulty.
The definition of an scale of difficulty of numeri-
cal expressions, the identification of rules governing
the selection of candidate substitution and the appli-
cation of hedges constitute important contributions.
The empirical evaluation of the system with human
experts results in acceptable rates of agreement. The
behavior of the system conforms to the conclusions
on simplification strategies as applied by humans re-
sulting from previous empirical surveys.
There are different aspects to improve the actual
system from the data collected, with a special atten-
tion to cases in which the experts disagree. As future
work, the syntactic context should be considered to
simplify numerical expression, extending the kind
of proportion to simplify and treating special cases
analyzed in this first version. At the syntactic level,
some transformation rules can be implemented from
a syntactic analysis. It is important that the meaning
of the sentences be preserved regardless of whether
part of the sentence is deleted or rewritten by the
adaptation rules. In addition, the numerical expres-
sion parser and the proportion approximation pro-
gram could also be studied in order to evaluate the
impact of their errors in the final performance.
Our final aim is to develop an automatic simplifi-
cation system in a broader sense, possibly including
more complex operations like syntactic transforma-
tions of the structure of the input text, or lexical sub-
stitution to reduce the complexity of the vocabulary
employed in the text. Additionally we hope to de-
velop versions of the simplification system for other
languages, starting with Spanish. Probably the sim-
plification strategies for numbers would be the same
but the use of hedge modifiers may be different.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
46
References
Susana Bautista, Pablo Gerva?s, and Ignacio Madrid.
2009. Feasibility Analysis for SemiAutomatic Con-
version of Text to Improve Readability. In Proceed-
ings of The Second International Conference on Infor-
mation and Communication Technologies and Acces-
sibility, Hammamet, Tunusia, May.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011a. Experimental
identification of the use of hedges in the simplifica-
tion of numerical expressions. In Proceedings of the
Second Workshop on Speech and Language Process-
ing for Assistive Technologies, pages 128?136, Edin-
burgh, Scotland, UK, July. Association for Computa-
tional Linguistics.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011b. How to
Make Numerical Information Accessible: Experimen-
tal Identification of Simplification Strategies. In Cam-
pos, Pedro and Graham, Nicholas and Jorge, Joaquim
and Nunes, Nuno and Palanque, Philippe and Winck-
ler, Marco, editor, Human-Computer Interaction IN-
TERACT 2011, volume 6946 of Lecture Notes in Com-
puter Science, pages 57?64. Springer Berlin / Heidel-
berg.
Ann M. Bisantz, Stephanie Schinzing, and Jessica
Munch. 2005. Displaying uncertainty: Investigating
the effects of display format and specificity. Human
Factors: The Journal of the Human Factors and Er-
gonomics Society, 47(4):777.
Yvonne Canning. 2000. Cohesive simplification of
newspaper text for aphasic readers. In 3rd annual
CLUK Doctoral Research Colloquium.
Raman Chandrasekar and Bangalore Srinivas. 1997.
Automatic induction of rules for text simplification.
Knowledge-Based Systems, 10.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and methods for text
simplification. In In Proceedings of the Sixteenth In-
ternational Conference on Computational Linguistics
(COLING ?96), pages 1041?1044.
Clark Christina and Douglas Jonathan. 2010. Young
people reading and writing today: Whether, what and
why. Technical report, London: National Literacy
Trust.
Walter Daelemans, Anja Hothker, and Erik Tjong Kim
Sang. 2004. Automatic Sentence Simplification for
Subtitling in Dutch and English. In Proceedings of the
4th Conference on Language Resources and Evalua-
tion, pages 1045?1048, Lisbon, Portugal.
Siobhan Devlin and John Tait. 1998. The use of a
Psycholinguistic database in the Simplification of Text
for Aphasic Readers. Lecture Notes. Stanford, USA:
CSLI.
Nathan Dieckmann, Paul Slovic, and Ellen Peters. 2009.
The use of narrative evidence and explicit likelihood
by decision makers varying in numeracy. Risk Analy-
sis, 29(10).
Geert Freyhoff, Gerhard Hess, Linda Kerr, Elizabeth
Menzel, Bror Tronbacke, and Kathy Van Der Veken.
1998. European guidelines for the production of easy-
to-read information.
Caroline Gasperin, Lucia Specia, Tiago F. Pereira, and
Sandra M. Aluisio. 2009. Learning when to simplify
sentences for natural text simplification. In Proceed-
ings of the Encontro Nacional de Inteligencia Artificial
(ENIA), pages 809?818, Bento Gonalves, Brazil.
Deeqa Jama and George Dugdale. 2010. Literacy: State
of the nation. Technical report, National Literacy
Trust.
Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin,
Thiago A. S. Pardo, Lucia Specia, and Sandra M.
Aluisio. 2009. Supporting the Adaptation of Texts
for Poor Literacy Readers: a Text Simplification Ed-
itor for Brazilian Portuguese. In Proceedings of the
NAACL/HLT Workshop on Innovative Use of NLP
for Building Educational Applications, pages 34?42,
Boulder, Colorado.
Imtiaz Hussain Khan, Kees Deemter, and Graeme
Ritchie. 2008. Generation of refering expressions:
managing structural ambiguities. In Proceedings of
the 22nd International Conference on Computational
Linguistics(COLING), pages 433?440, Manchester.
Himanshu Mishra, Arul Mishra, and Baba Shiv. 2011.
In praise of vagueness: malleability of vague informa-
tion as a performance booster. Psychological Science,
22(6):733?8, April.
Ellen Peters, Judith Hibbard, Paul Slovic, and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analysis.
In Proceedings of Workshop on Speech and Language
Technology for Education (SLaTE).
Richard Power and Sandra Williams. 2012. Generating
numerical approximations. Computational Linguis-
tics, 38(1).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the National Curriculum for England. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving attachment and
clause boundary amgiguities for simplifying relative
clause constructs. In Proceedings of the Student Re-
search Workshop, 40th Meeting of the Association for
Computacional Linguistics.
47
Advaith Siddharthan. 2003. Syntactic Simplification and
Text Cohesion. Ph.D. thesis, University of Cambridge.
United Nations. 1994. Standard Rules on the Equal-
ization of Opportunities for Persons with Disabilities.
Technical report.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proc. of the 12th European Workshop on
Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003a. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
Sandra Williams, Ehud Reiter, and Liesl Osman. 2003b.
Experiments with discourse-level choices and read-
ability. In In Proceedings of the European Natu-
ral Language Generation Workshop (ENLG) and 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL03), pages
127?134.
Sandra Williams. 2010. A Parser and Information
Extraction System for English Numerical Expres-
sions. Technical report, The Open University, Milton
Keynes, MK7 6AA, U.K.
48
