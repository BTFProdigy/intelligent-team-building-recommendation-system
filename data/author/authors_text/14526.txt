Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 362?365,
Prague, June 2007. c?2007 Association for Computational Linguistics
UC3M_13: Disambiguation of Person Names Based on the             
Composition of Simple Bags of Typed Terms 
David  
del Valle-Agudo 
C?sar  
de Pablo-S?nchez 
Mar?a Teresa  
Vicente-D?ez 
Universidad Carlos III de Madrid 
Escuela Polit?cnica Superior 
Av. de la Universidad, 30 ? 28911 
Legan?s (Madrid) Spain  
{dvalle, cdepablo, tvicente}@inf.uc3m.es 
 
 
Abstract 
This paper describes a system designed to 
disambiguate person names in a set of Web 
pages. In our approach Web documents are 
represented as different sets of features or 
terms of different types (bag of words, 
URLs, names and numbers). We apply Ag-
glomerative Vector Space clustering that 
uses the similarity between pairs of analo-
gous feature sets. This system achieved a 
value of 66% for F?=0.2 and a value of 48% 
for F?=0.5 in the Web People Search Task at 
SemEval-2007 (Artiles et al, 2007). 
1 Introduction 
Name queries account for a substantial part of Web 
queries in commercial search engines. Name que-
ries often aim at retrieving information about par-
ticular persons. Nevertheless, the same query or 
mention name usually recalls several people and 
the user is unaware of the potential ambiguity and 
expects to find the related person after skimming 
some results.  
Similar problems are also common for products, 
organizations and almost any other named object 
in real world. A related problem appears for differ-
ent kinds of objects receiving the same name. For 
example, Firebird can refer to a car, a guitar, a fic-
tion superhero or a database product among more 
than twenty different senses collected in Wikipe-
dia. In all these cases, the user could benefit from a 
structured representation that facilitates browsing 
results. Other applications like Question Answer-
ing would also benefit from name disambiguation 
and person names disambiguation, in particular. In 
this work we focus on the task of disambiguating 
Web pages retrieved for a person name query as 
proposed in the Web People Search Task at SemE-
val-2007.  
2 Background and Related Research 
In recent work in named entity disambiguation, 
Malin (2005) identifies two different dimensions to 
classify approaches to the task depending on the 
information type that is used and whether the 
method to train the system is supervised or unsu-
pervised. Regarding the information type, Malin 
(2006) identifies personal information like bio-
graphical facts (Bagga and Baldwin, 1998; Mann 
and Yarowsky, 2003) or relational information 
(Bekkerman and McCallum, 05), collocations with 
other entities.  
Personal name disambiguation has been studied 
in relation with citation analysis and record linkage 
and their use to improve Web search results have 
attracted more interest recently (Guha and Garg 
2004; Bollegala, 2006), but it is evaluated only at a 
small scale. In contrast Bekkerman and McCallum 
(2005) have focused on disambiguating complete 
social networks and not only results for one name. 
3 System description 
Web People Search proposes a task to find differ-
ent people sharing the same name referred in a set 
of Web pages and associate each of these pages to 
these people. To solve the task we added two sim-
plifying assumptions; each document refers only to 
one person, and every listed document refers to a 
person. 
362
Our approach is an unsupervised personal name 
disambiguation system according to the classifica-
tion proposed by Malin. In this system the method 
applied to solve ambiguity consists of extracting 
from each document a set of features, that we 
called document context and afterwards to cluster 
them according to their similarity  
3.1 Document representation 
In this task we do not have structured information 
to estimate similarity. For this reason, the first step 
of the system consists of extracting features from 
the documents. Since our goal is to develop tech-
niques that work for large amounts of documents, 
most of the features are based simply on words, 
HTML structure and simple patterns that aim to 
substitute more elaborated features based on in-
formation extraction.  Features might not have a 
direct correspondence with facts that help to iden-
tify a person like date of birth or telephone but, in 
some cases, dealing with them instead of with 
proper semantic information can be a good ap-
proach. On the other hand, some people features, 
as emails or related URLs, are detected through 
simple patterns. Other simple patterns like num-
bers can also provide information about some peo-
ple features.  
All terms identified by the same pattern are rep-
resented as a bag of terms. Document context is 
composed of a set of bags, each containing all the 
terms of the document that were captured with a 
fixed pattern.  
3.2 Types of Contexts 
The bags of terms used in document contexts are 
the following: 
a) emails, b) URLs, c) proper names, d) long 
numbers (more than four figures), e) short numbers 
(up to four figures), f) title terms, g) terms of the 
titles of related documents, h) terms contained in 
the ?meta? tag of the documents, i) terms of em-
phasized text fragments (bold, italic, etc.), j) terms 
of the document snippet, and k) terms of the re-
lated documents snippets. 
The bags b, f, g, j, and k have been extracted 
from the data files provided (snippets, rank, etc.), 
whereas a, c, d, e, h and i have been directly ex-
tracted from result pages.  
From all the bags of terms, we finally selected to 
compound the contexts b, c, d, e, f, g and j as in the 
training set they contributed to obtain the best re-
sult. 
3.3 Term normalization and filtering 
Each extracted term is normalized, filtered and 
weighted before being added to a bag of terms. A 
filter for stopwords is applied to every bag of 
words and they are represented in lowercase. Spu-
rious HTML tags and terms under three characters 
are also considered stopwords. Bag of numbers are 
normalized by removing blanks, hyphens and pa-
renthesis.  
 In addition to stopwords, terms with low fre-
quency, lower than 0.2 times the frequency of the 
more frequent term of each bag of words, are not 
considered. Finally the tf-idf value of every term is 
associated.   
Proper names are extracted with a robust rule 
based name recognizer based on surface feature 
and some trigger words. It should be emphasized 
that over the bag of proper names, a filtering is 
implemented to make the detection of co-referents 
proper names easier when comparing different ar-
rays. In this way, a similarity measure among 
proper names is considered (Camps and Daud?, 
2003) more flexible than the simple comparison of 
their strings of characters. This approach tolerates 
the omission, substitution or inclusion of words in 
the proper name, the alteration in the order of the 
words, or the substitution of words with initials, as 
well as the omission, substitution or inclusion of 
characters. First, all proper names that are in the 
set of documents are identified, and all similar 
proper names according to these relaxed rules are 
grouped by the same common term. In this way, 
arrays of proper names are rewritten, referencing 
each proper name through its common term and 
recalculating its frequency. 
3.4 Clustering algorithm 
Our system uses Agglomerative Vector Space 
Clustering to group and disambiguate pages. Given 
the nature of the problem, it does not need to indi-
cate the number of classes to be obtained in ad-
vance. To determine if two documents should be 
assigned to the same cluster, we evaluate the simi-
larity between each pair of bags of terms and, later, 
it is determined how many of these pairs have a 
similarity over a threshold. For a document to be in 
the same cluster we require a minimum number of 
similar pairs. 
363
In order to allow finer adjustments in the num-
ber of similar pairs needed, instead of requiring N 
similar pairs, the pairs are arranged in a decreasing 
order according to the obtained similarity and it is 
checked if the similarity of the nth pair is above or 
below the threshold. In this case, interpolation can 
be applied, so the number of necessary similar 
pairs is not limited to the natural numbers. The 
developed system uses linear interpolation to cal-
culate this function. 
We use the cosine vector similarity as similarity 
measurement.  
4 Results and Evaluation 
For the evaluation the system has been adjusted 
with a threshold of similarity of 0.001, 2.5 pairs of 
bags of terms above the threshold required for in-
cluding two documents in the same cluster and the 
following bags of terms: bags of URLs, proper 
names, long and short numbers, terms of titles, 
terms of the titles of the related documents and 
terms of the document snippets.  
With this adjustment it is noticed that some prob-
lems affect the results of the evaluation. The most 
important of these problems is the small number of 
clusters in which pages are classified. For instance, 
Mark Johnson refers to 70 different people in key, 
but our system classified his pages in only 14 clus-
ters. Due to this small number of clusters, each 
contains more than one person to search, but with a 
good recall of pages for each person. Table 1 
shows the results obtained for the test set, where P 
is the purity, R is the inverse purity, F?=0.5 repre-
sents the harmonic mean of purity and inverse pu-
rity, and F?=0.2 is the measure of F that considers 
more important inverse purity than purity. 
Although at a first sight set 1 shows better re-
sults than set 2 and 3, once we discard the people 
names ?Sharon Goldwater? and ?Dekang Lin? 
(whose results are above the mean), results are 
very similar for all groups. We consider that our 
system behaves in a homogenous way regardless 
of the proportion of the different types of names 
the sets are composed of: less frequent names (with 
lower ambiguity) and ?celebrity? names (with peo-
ple that dominate the set of pages). 
In the other hand, the assumptions considered to 
solve the problem (each page references at least 
one and only one person) were definitely too na?ve, 
as there is a lot of discarded pages (in some cases 
more than 50% of the pages are not taken into ac-
count) and some pages refer to several people. 
These facts also contribute to make lower purity. 
Table 1. Test results (in percentages) 
  P R F?=.5 F?=.2 
Mark Johnson 20 98 33 54 
Sharon Goldwater 99 99 99 99 
Robert Moore 26 94 40 61 
Leon Barrett 34 97 50 70 
Dekang Lin 100 98 99 98 
Stephen Clark 21 98 34 56 
Frank Keller 25 90 39 59 
Jerry Hobbs 52 92 67 80 
James Curran 24 98 39 61 
Se
t 1
 
Chris Brockett 68 97 80 89 
Thomas Fraser 33 96 49 70 
John Nelson 24 96 38 60 
James Hamilton 19 99 32 54 
William Dickson 20 99 33 55 
James Morehead 26 96 41 62 
Patrick Killen 55 99 71 86 
George Foster 35 94 51 70 
James Davidson 25 98 39 61 
Arthur Morgan 54 98 70 84 
Se
t 2
 
Thomas Kirk 11 98 20 39 
Harry Hughes 36 79 50 64 
Jude Brown 25 91 39 59 
Stephan Johnson 57 92 70 82 
Marcy Jackson 32 95 48 68 
Karen Peterson 12 99 21 40 
Neil Clark 46 98 62 80 
Jonathan Brooks 21 95 35 56 
Violet Howard 15 88 26 45 
Martha Edwards 11 96 20 38 
Se
t 3
 
Alvin Cooper 34 95 50 70 
 
Set 1 Average 47 96 58 73 
Set 2 Average 30 97 44 64 
Set 3 Average 29 93 42 60 
 
Global Average 35 95 48 66 
5 Conclusions and future works 
This system obtains a good result for inverse purity 
to the detriment of purity. This causes a difference 
of almost twenty points in the measures of F?=0.5 
and F?=0.2. In order to correct this weakness, in the 
future we will consider that any person can be 
mentioned in different pages, and that not all pages 
reference to any of the people to search. 
Also we will perform additional experiments   
regarding parameter tuning. Although the number 
of similar contexts considered in these experiments 
364
is 1.5 (value that maximizes the measure of F), 
results show that this value causes larger groups 
than those found in search results. Probably a 
smaller value for this parameter will divide pages 
in more clusters, improving the purity of the result. 
Finally, we would like to consider different 
methods to select relevant terms. 
References 
A. Bagga and B. Baldwin. 1998. Entity-based cross-
document coreferencing using the vector space 
model. In Proc 36th Annual Meeting of the Associa-
tion for Computational Linguistics. San Francisco, 
CA.; 79-85. 
Artiles, J., Gonzalo, J. and Sekine, S. (2007). Establish-
ing a benchmark for the Web People Search Task: 
The Semeval 2007 WePS Track. In Proceedings of 
Semeval 2007, Association for Computational Lin-
guistics. 
Bradley Malin. 2005. Unsupervised name disambigua-
tion via social network similarity. In Proceedings of 
the Workshop on Link Analysis, Counterterrorism, 
and Security, in conjunction with the SIAM Interna-
tional Conference on Data Mining. Newport Beach, 
CA; 93-102. 
Camps, R., Daud?, J. 2003. Improving the efficacy of 
aproximate personal name matching.  NLDB'03. 8th 
International Conference on Applications of Natural 
langage to Informations Systems. 
Danushka Bollegala, Yutaka Matsuo and Mitsuru Ishi-
zuka. 2006. Disambiguating Personal Names on the 
Web using Automatically Extracted Key Phrases. 
Proceedings of the European Community of Artifi-
cial Intelligence (ECAI 2006), Italy 
G. Mann and D. Yarowsky. 2003. Unsupervised per-
sonal name disambiguation. In Proc 7th Conference 
on Computational Natural Language Learning. Ed-
monton, Canada. 
Ramanathan V. Guha and A. Garg. 2004. Disambiguat-
ing people in search. In WWW2004. 
Ron Bekkerman, Andrew McCallum. 2005. Disambigu-
ating Web appearances of people in a social network. 
Proceedings of the 14th international conference on 
World Wide Web 2005. Pages 463 - 470. 
 
 
365
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 329?332,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
UC3M system: Determining the Extent, Type and Value of Time 
Expressions in TempEval-2 
 
 
Mar?a Teresa Vicente-D?ez, Juli?n Moreno Schneider, Paloma Mart?nez 
Department of Computer Science 
Universidad Carlos III de Madrid 
Avda. Universidad, 30 
Legan?s, 28911, Madrid, Spain. 
{tvicente, jmschnei, pmf}@inf.uc3m.es 
 
  
 
Abstract 
This paper describes the participation of 
Universidad Carlos III de Madrid in Task A of 
the TempEval-2 evaluation. The UC3M 
system was originally developed for the 
temporal expressions recognition and 
normalization (TERN task) in Spanish texts, 
according to the TIDES standard. Current 
version supposes an almost-total refactoring of 
the earliest system. Additionally, it has been 
adapted to the TimeML annotation schema 
and a considerable effort has been done with 
the aim of increasing its coverage. It takes a 
rule-based design both in the identification and 
the resolution phases. It adopts an inductive 
approach based on the empirical study of 
frequency of temporal expressions in Spanish 
corpora. Detecting the extent of the temporal 
expressions the system achieved a 
Precision/Recall of 0.90/0.87 whereas, in 
determining the TYPE and VALUE of those 
expressions, system results were 0.91 and 
0.83, respectively.  
1 Introduction 
The study of temporality in NLP is not a new 
task. However, in the last years it has witnessed a 
huge interest. Initiatives like TempEval task or 
the Automatic Context Extraction1 (ACE) TERN 
competitions have boosted research on the field 
and have promoted the development of new 
resources to the scientific community. 
There are two main advantages in 
participating in these evaluations. On the one 
                                                 
1
 Automatic Content Extraction Evaluation. National 
Institute of Standards and Technology (NIST) 
http://www.itl.nist.gov/iad/mig//tests/ace/ 
hand it is possible to measure the systems? 
performance under standardized metrics, sharing 
datasets and other resources. On the other hand, 
it is possible to make comparative evaluations 
among distinct participants looking forward the 
same objectives but using different approaches. 
Until recently, most of temporally annotated 
corpora, as well as temporal taggers, were 
available in English. Since languages as Spanish 
start to become prominent in the field it seems 
interesting the development of specific resources. 
Tempeval-2 has contributed to this target in a 
significant way thanks to the release of annotated 
corpora and the publication of specific guidelines 
(Sauri et al, 2009), (Saur? et al, 2010). 
This paper resumes the participation of the 
UC3M system in the task of determining the 
extent and resolving the value of time 
expressions in texts (Task A). This system was 
originally developed for the Spanish TERN task 
proposed in ACE 2007 evaluation (Vicente-D?ez 
et al, 2007), achieving encouraging results 
although it was in a early stage of development. 
The system follows a ruled-based approach 
whose knowledge base has been inducted from 
the study of annotated temporal corpora 
(Vicente-D?ez et al, 2008). A machine learning 
approach was initially discarded due to the 
limitation of annotated Spanish corpora. 
The aims of this work were to improve the 
coverage of the original system and test its 
performance against new available datasets with 
a view to its integration in future domains of 
application. Main challenges were to move to a 
new temporal model where interval is considered 
as the basic time unit as well as the isolation of 
the internal representation of temporal 
information from the annotation schema.  
329
This paper is organized as follows: Section 2 
describes the system operation; Section 3 
presents experimentation and results; conclusions 
and future work are discussed in Section 4. 
2 System Description 
The UC3M system recognizes and annotates 
temporal expressions in texts based on a 
linguistic rules engine for Spanish language. 
Our system is divided into three different 
parts: recognition of temporal expressions, 
normalization of the detections, and annotation 
of the temporal expressions according to the 
TimeML schema.  
Following the definition of the Task A, the 
system is able to determine not only the extent of 
the temporal expressions but also the value of the 
features TYPE and VAL. It differentiates among 
the four TYPE values (dates, durations, sets and 
times) thanks to the classification of the 
recognition rules. The system straightforwardly 
provides a VAL attribute that accomplishes the 
format defined by TIMEX2 and TIMEX3 
standards through its internal model for 
representing time.  
2.1 Recognition 
The recognizer detects temporal expressions by 
means of a set of linguistic rules, focusing on 
those which are most frequent in Spanish.  
We adopted an empirical inductive approach 
through the analysis of the different types of 
temporal expressions in news corpora, and we 
could outline a typology of most common time 
expressions in the language. The typology 
together with the patterns that define these 
expressions form up the knowledge base for a 
successful automatic identification and resolution 
of temporal expressions. 
The rule engine allows managing different sets 
of rules independently of the target. In this case, 
the rules have been created attending to each 
pattern that is likely to match a temporal 
expression. Each rule determines the set of 
tokens that form an expression, the normalization 
type to be applied and the expression type. 
In Table 1 an example of a rule to identify 
dates is shown. The first line represents the name 
of the rule. The second line specifies the 
normalization method that will be used once the 
expression is recognized. The third line specifies 
the type of the temporal expression and the 
annotation pattern. Finally, the fourth line shows 
the tokens that trigger the rule.  
1. TEMPORAL_RULE(r1.3) 
2. TEMPORAL_ANALYSIS_NORMALIZATION_ 
TYPE=(abs_dia_mes_anio_3) 
3. TEMPORAL_ANALYSIS_TYPE= 
(date:init:YYYY-MM-DD) 
4. RULE= 
[[el/_] [DIC(DIASEMANA)/_] [dia/_] DIC(DIA) de 
DIC(MES) DIC(PREP) METHOD(year)] 
Table 1 Rule definition example 
The operation of the system is described as 
follows: first, the text is parsed token by token. 
Then, for each token, every rule is checked to 
find out if it triggers through a given token and 
the following ones. 
This operation implies that the higher the 
number of rules, the slower the text processing. 
The disadvantage of the processing speed has 
been accepted as a design criterion for the sake 
of the simplicity of creating new rules.  
2.2 Normalization 
The temporal expression normalization is done 
as an intermediate step between recognition and 
annotation, isolating the extraction of semantics 
from the annotation schema while trying to 
facilitate the second step. 
Normalization is important since recognized 
time expressions are managed and returned in a 
standard format that avoids semantic 
ambiguities.  
UC3M system applies an interval-based 
temporal normalization. It means that every 
temporal expression is represented as an interval 
with two boundaries: an initial and a final date 
(including time). This approach is motivated by 
the belief that the use of intervals as a basic time 
unit leads to a lower loss of semantics. For 
instance, when an expression like ?en enero? (?in 
January?) is detected, current task proposes the 
annotation ?2010-01?. However, we think that 
for many applications that are likely to use this 
system it would be more useful to have the 
complete interval that the expression refers 
(?2010-01-01 - 2010-01-31?). Through a set of 
procedures (as getting the length of a given 
month), our system tries to define the interval 
boundaries as much as possible. Every 
normalized expression is made up of two dates 
although it refers to a concrete date or time. 
In the internal representation model 
normalized dates and times adopts the ISO-8601 
form, durations are captured as a length related 
to the unit of measure, and sets are managed in a 
similar way to durations, adding quantity and 
frequency modifiers. 
330
The normalization process is dependent on the 
rule used to recognize each expression. For each 
new rule added to the engine a new 
normalization clause is needed. 
In Table 2 some temporal expression 
normalization examples are presented: 
Expression Init Date Final Date 
18 de abril de 2005 
18th of April of 2005 20050418 20050418 
mayo de 1999 
May of 1999 19990501 19990531 
en 1975 
in 1975 19750101 19751231 
el pr?ximo mes 
next month 20100501 20100531 
Table 2 Interval-based normalization sample 
2.3 Annotation 
The annotation process starts from the 
normalized form of the temporal expression. The 
system implements a transformation procedure 
based on patterns. This transformation is 
dependent on the temporal expression type. 
Dates: when dealing with dates, the VAL 
value is extracted from the initial boundary of the 
interval in accordance with the annotation pattern 
defined in the corresponding rule (see Table 1). 
Some examples are shown in Table 3. 
Expression Norm. Init Date Pattern VAL 
mayo de 1999 
May of 1999 19990501 YYYY-MM 1999-05 
la semana  
pasada 
last week 
20100405 YYYY-WXX 2010-W14 
los a?os 80 
the 80?s 19800101 YYY 198 
Table 3 Annotation patterns for dates 
Durations: the model represents durations by 
capturing the length of action as a quantity. This 
quantity is stored in the position of the initial 
boundary whose granularity corresponds with the 
unit of measure. The annotation patterns indicate 
the granularity to be considered (Table 4). 
Expression Norm. Init Date Pattern VAL 
4 a?os 
4 a?os 00040000 PXY P4Y 
4 meses, 3 
d?as y 2 
horas 
4 moths,3 
days and 2 
hours 
00040003- 
02:00:00 COMBINED P4M3DT2H 
Table 4 Annotation patterns for durations 
Sets are managed similarly to durations. In this 
case also frequency and quantity modifiers are 
captured internally together with the interval 
representation, so that the transformation is 
immediate. 
Expression Norm. Init Date Pattern VAL FREQ QUANT 
cada 2 a?os 
each 2 
years 
00020000 
F1QEv PXY P2Y 1x EVERY 
2 veces al 
d?a 
twice a day 
00000001 
F2QEv PXD P1D 2x EVERY 
Table 5 Annotation patterns for sets 
Times: the representation model allows 
capturing hours, minutes, seconds and 
milliseconds if they are specified. Similarly to 
the annotation of dates, VAL value is obtained of 
the information in the initial boundary in the way 
the pattern determines (Table 6). 
Expression Norm. Init Date Pattern VAL 
a las 12:30 PM 
at 12:30 PM 
20100405 
12:30:00 THXMX 
2010-04-
05T12H30M 
por la tarde 
in the evening 
20100405 
12:00:00 TDP 2010-04-05TAF 
Table 6 Annotation patterns for times 
3 Experiments and Results 
Precision and recall and f-measure are used as 
evaluation metrics according to the evaluation 
methodology (Pustejovsky et al, 2009). To 
determine the quality of annotation, results are 
completed with figures concerning to the 
resolution of TYPE and VAL attributes. 
Before evaluation, the system was tested on 
the training corpus and, once the test datasets 
were released, it was tested on the corpus for 
relations detection (tasks C-F) since it contained 
both files "timex-extents.tab" and "timex-
attributes.tab". The results are shown in Table 7. 
Timex Extent Timex Attbs. Corpus P R F TYPE VAL 
Training 0.93 0.67 0.78 0.87 0.82 
Relation-Test 0.89 0.63 0.74 0.86 0.83 
Table 7 Results on training corpus 
In Table 8 results of final evaluation are 
presented and compared with the other 
participants? figures for the same task and 
language. Since the test corpora were not 
aligned, further comparisons for different 
languages have not been proposed. 
Our system achieved a precision rate of 90% 
and a recall of 87%, being the f-measure of 88%. 
Thus, it supposes a significant improvement over 
our earlier work. In more, determining the value 
of TIMEX3 attributes the system raises good 
331
figures, obtaining the best VAL score, what 
means that normalization is working well. 
Timex Extent Timex Attrbs. Team P R F TYPE VAL 
UC3M 0.90 0.87 0.88 0.91 0.83 
TIPSem 0.95 0.87 0.91 0.91 0.78 
TIPSem-B 0.97 0.81 0.88 0.99 0.75 
Table 8 Results on test corpus 
Analyzing the experimental errors several 
facts can be highlighted: 
The percentage of expressions completely and 
correctly recognized and normalized is good but 
there are some missing expressions, mainly due 
to their complexity (or fuzziness) and to the 
absence of a rule to manage them, i.e.: ?durante 
un largo periodo? (during a long period).  
Errors in determining the extent of the 
temporal expressions were mainly due to the 
inclusion of prepositions or articles that precede 
to the kernel of the expression, i.e.: ?a corto 
plazo? vs. ?corto plazo? (in short term). 
A number of false positives were due to some 
inconsistencies in the annotation of the corpus. 
An example has been observed in fuzzy time 
expressions that denotes a future reference: ?el 
pr?ximo t?cnico? (the next trainer) (not 
annotated) vs. ?el pr?ximo preparador? (the next 
coach) (FUTURE_REF)  
Although normalization figures are good, 
some annotations are incorrect if their resolution 
implies context-aware mechanisms. 
4 Conclusions and Future Work 
In this paper a rule based approach for 
automatically detecting and annotating temporal 
expressions according to TimeML TIMEX3 tag 
has been presented. It is based on an empirical 
study of temporal expressions frequencies in 
Spanish that provides the main recognition rules 
of the knowledge base. At the normalization 
stage, a representation model based on intervals 
has been adopted with the aim of capturing most 
semantics. The annotation process relies on 
patterns that distinguish among different types 
and granularities of the expressions to be tagged. 
Obtained results suppose a significant 
improvement over our previous work. Part of this 
success is due to the specific annotation 
guidelines for Spanish that have been released 
with occasion of the TempEval-2. It is a helpful 
tool to optimize the system performance, since 
each language has its own peculiarities that 
should be taken into account. The promotion of a 
common framework and the development of 
resources like specific corpora are also very 
interesting topics to boost research in the field, 
since both comparative and standardized 
evaluation of the systems are needed. 
Several aspects should be taken into account 
in future versions of the system. In order to 
improve the recall new knowledge must be 
incorporated to the rule engine. That supposes 
the addition of new rules and annotation patterns. 
This objective includes the implementation of 
dictionaries with a broader coverage of 
translatable temporal expressions, such as 
holidays, festivities, etc. 
We will also explore context extraction 
techniques that facilitate the resolution of 
context-aware temporal expressions. 
Another pending issue is the enlargement of 
the system to span the detection of events and the 
relations among events and time expressions. 
Finally, the system will be integrated into a 
NLP application that benefits from the temporal 
information management. We want to check the 
improvement that the extraction of temporal 
entities supposes on a traditional approach. 
 
Acknowledgments 
This work has been partially supported by the 
Research Network MAVIR (S-0505/TIC-0267), 
and project BRAVO (TIN2007-67407-C03-01). 
References  
James Pustejovsky, Marc Verhagen, Xue Nianwen, 
Robert Gaizauskas, Mark Hepple, Frank Schilder, 
Graham Katz, Roser Saur?, Estela Saquete, 
Tommaso Caselli, Nicoletta Calzolari, Kiyong Lee, 
and Seohyun Im. 2009. TempEval2: Evaluating 
Events, Time Expressions and Temporal Relations. 
SemEval Task Proposal. 
Mar?a Teresa Vicente-D?ez, Doaa Samy and Paloma 
Mart?nez. 2008. An empirical approach to a 
preliminary successful identification and resolution 
of temporal expressions in Spanish news corpora. 
In Proceedings of the LREC'08. 
Mar?a Teresa Vicente-D?ez, C?sar de Pablo-S?nchez 
and Paloma Mart?nez. Evaluaci?n de un Sistema de 
Reconocimiento y Normalizaci?n de Expresiones 
Temporales en Espa?ol. Procesamiento del 
lenguaje natural. N. 39 pp. 113-120, Sept. 2007. 
Roser Saur?, Estela Saquete and James Pustejovsky. 
2010. Annotating Time Expressions in Spanish. 
TimeML Annotation Guidelines. Version 
TempEval-2010.  
Roser Saur?, Olga Batiukova, James Pustejovsky. 
2009. Annotating Events in Spanish. TimeML 
Annotation Guidelines. Version TempEval-2010. 
332
