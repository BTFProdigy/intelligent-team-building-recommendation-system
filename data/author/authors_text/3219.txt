BioNLP 2007: Biological, translational, and clinical language processing, pages 25?32,
Prague, June 2007. c?2007 Association for Computational Linguistics
On the unification of syntactic annotations under the Stanford
dependency scheme: A case study on BioInfer and GENIA
Sampo Pyysalo, Filip Ginter, Katri Haverinen,
Juho Heimonen, Tapio Salakoski
Department of Information Technology
University of Turku,
Joukahaisenkatu 3-5
20014 Turku, Finland
first.last@utu.fi
Veronika Laippala
Department of French Studies
University of Turku,
Henrikinkatu 2
20014 Turku, Finland
veronika.laippala@utu.fi
Abstract
Several incompatible syntactic annotation
schemes are currently used by parsers and
corpora in biomedical information extrac-
tion. The recently introduced Stanford de-
pendency scheme has been suggested to be
a suitable unifying syntax formalism. In this
paper, we present a step towards such uni-
fication by creating a conversion from the
Link Grammar to the Stanford scheme. Fur-
ther, we create a version of the BioInfer cor-
pus with syntactic annotation in this scheme.
We present an application-oriented evalua-
tion of the transformation and assess the
suitability of the scheme and our conversion
to the unification of the syntactic annotations
of BioInfer and the GENIA Treebank.
We find that a highly reliable conversion is
both feasible to create and practical, increas-
ing the applicability of both the parser and
the corpus to information extraction.
1 Introduction
One of the main challenges in biomedical infor-
mation extraction (IE) targeting entity relationships
such as protein-protein interactions arises from the
complexity and variability of the natural language
statements used to express such relationships. To
address this complexity, many biomedical IE sys-
tems (Alphonse et al, 2004; Rinaldi et al, 2004;
Fundel et al, 2007) and annotated corpora (Kim et
al., 2003; Aubin, 2005; Pyysalo et al, 2007) incor-
porate full syntactic analysis. However, there are
significant differences between the syntactic anno-
tation schemes employed. This leads to difficulties
in sharing data between corpora and establishing the
relative performance of parsers as well as to a lack
of interchangeability of one parser for another in IE
systems, among other issues.
Syntax formalisms are broadly divided into con-
stituency and dependency. Constituency schemes
are dominant in many fields and are unified under
the established Penn Treebank (PTB) scheme (Bies
et al, 1995). However, dependency schemes have
been suggested to be preferable in IE, as they repre-
sent the semantic structure of the sentences more di-
rectly (see, e.g., de Marneffe et al (2006)). Further,
Lin (1998) argues for dependency-based evaluation
of both dependency and constituency parsers since
it allows evaluation metrics that are more relevant
to semantic interpretation as well as intuitively more
meaningful. Even though there is clearly a need for a
unifying scheme for dependency comparable to that
of PTB for constituency, no widely adopted standard
currently exists.
In this paper, we present a step towards unify-
ing the diverse syntax schemes in use in IE sys-
tems and corpora such as the GENIA Treebank1 and
the recently introduced BioInfer corpus (Pyysalo et
al., 2007). Clegg and Shepherd (2007) have re-
cently proposed to use the Stanford dependency
scheme (de Marneffe et al, 2006) as a common,
application-oriented syntax representation. To as-
sess this choice, we develop a set of conversion
rules for transforming the Link Grammar (LG) de-
pendency scheme (Sleator and Temperley, 1993) to
1http://www-tsujii.is.s.u-tokyo.ac.jp/ ?genia
25
the Stanford scheme and then create a version of
the BioInfer corpus in the Stanford scheme by ap-
plying the conversion rules and manually correcting
the errors. By making the BioInfer corpus available
in the Stanford scheme, we also increase the value
of the corpus for biomedical IE. The transforma-
tion has the further benefit of allowing Link Gram-
mar output to be normalized into a more application-
oriented form. Finally, to assess the practical value
of the conversion method and of the BioInfer syntac-
tic annotation in the Stanford scheme, we compare
the Charniak-Lease constituency parser2 (Charniak
and Lease, 2005) and BioLG,3 an adaptation of LG
(Pyysalo et al, 2006), on the newly unified dataset
combining the constituency-annotated GENIA Tree-
bank with the dependency-annotated BioInfer cor-
pus.
The transformation rules and software as well as
the Stanford annotation of the BioInfer corpus, the
main practical results of this work, are freely avail-
able at http://www.it.utu.fi/BioInfer.
2 Motivation
To support the development of IE systems, it is im-
portant for a corpus to provide three key types of
annotation capturing the named entities, their rela-
tionships and the syntax. To our knowledge, there
are only two corpora in the biomedical domain that
currently provide these three annotation types simul-
taneously, BioInfer and LLL (Aubin, 2005). In ad-
dition, GENIA, the de facto standard domain corpus
for named entity recognition and syntactic analysis,
is in the process of adding a relationship annota-
tion. The corpora have different strengths; BioInfer
provides a detailed relationship annotation, while
GENIA has a broader coverage of named entities
and a larger treebank. Unifying the syntactic anno-
tations of these two corpora allows these strengths
to be combined.
The BioInfer syntactic annotation follows the LG
dependency scheme, addressing the recent interest
in LG in the biomedical NLP community (Ding et
al., 2003; Alphonse et al, 2004; Aubin et al, 2005).
However, the LG scheme has been criticized for be-
ing oriented more towards structural than semantic
2http://nlp.stanford.edu/software/,
version 1.5.1
3http://www.it.utu.fi/BioLG, version 1.2.0
relations and having excessively detailed link types
whose functional meaning and value for semantic
analysis is questionable (Schneider, 1998; de Marn-
effe et al, 2006). Our experience with LG leads us
to largely agree with these criticisms.
De Marneffe et al (2006) have recently intro-
duced a transformation from PTB to the Stanford
scheme. Clegg and Shepherd (2007) have ap-
plied this transformation to perform a dependency-
based comparison of several statistical constituency
parsers on the GENIA Treebank and have argued for
the adoption of the Stanford scheme in biomedical
IE. Moreover, the IE system of Fundel et al (2007),
which employs the Stanford scheme, was shown to
notably outperform previously applied systems on
the LLL challenge dataset, finding an F-score of
72% against a previous best of 54%. This further
demonstrates the suitability of the Stanford scheme
to IE applications.
3 Dependency schemes
In this section, we present the Stanford and LG
dependency schemes and discuss their relative
strengths.
3.1 Stanford dependency scheme
A parse in the Stanford scheme (SF) is a directed
graph where the nodes correspond to the words and
the edges correspond to pairwise syntactic depen-
dencies between the words. The scheme defines
a hierarchy of 48 grammatical relations, or depen-
dency types. The most generic relation, dependent,
can be specialized as auxiliary, argument, or modi-
fier, which again have several subtypes (de Marneffe
et al, 2006).
The Stanford conversion transforms phrase struc-
ture parses into the Stanford scheme. First, the se-
mantic head of each constituent is identified using
head rules similar to those of Collins (1999) and un-
typed dependencies are then extracted and labeled
with the most specific grammatical relations possi-
ble using Tregex rules (Levy and Andrew, 2006).
The system additionally provides a set of collaps-
ing rules, suggested to be beneficial for IE appli-
cations (de Marneffe et al, 2006; Clegg and Shep-
herd, 2007). These rules collapse some dependen-
cies by incorporating certain parts of speech (mostly
26
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
A/ANPv Cs
Mp
Ss
A/AN PvDsuE
Js
MVsCC
Spx
CC
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
cc>
conj>
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det prep>
<nsubjpass
pobj>
<nmod
<nmod <auxpass
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
conj_and>
<nsubjpass
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det
prep_of>
<nsubjpass
<nmod
<nmod <auxpass
Figure 1: A sentence from the BioInfer corpus with its LG linkage (top), the Stanford parse (middle), and
the collapsed Stanford parse (bottom). The < and > symbols denote the direction of dependencies.
during incubation , actin suffered degradation
Jp
CO
Ss Os
actin suffered degradation during incubation
Jp
MVp
Ss Os
actin suffered degradation during incubation
JpMpSs Os
Figure 2: Variation in the link type connecting a
preposition: CO to the main noun in topicalized
prepositional phrases, MVp when modifying a verb,
and Mp when modifying a noun.
conjunctions and prepositions) in grammatical rela-
tions. This is realized by combining two relations
and denominating the resulting dependency with a
type based on the word to which the original two
relations were linked (see Figure 1).
In the LG-SF conversion, we target the uncol-
lapsed Stanford scheme, as the collapsing rules have
already been developed and reported by de Marn-
effe et al; reimplementing the collapsing would be
an unnecessary duplication of efforts. Also, the col-
lapsed relations can be easily created based on the
uncollapsed ones, whereas reversing the conversion
would be more complicated.
3.2 LG dependency scheme
Link Grammar (Sleator and Temperley, 1993) is
closely related to dependency formalisms. It is
based on the notion of typed links connecting words.
While links are not explicitly directional, the roles
of the words can be inferred from their left-to-right
order and the link type. An LG parse, termed link-
age, consists of a set of links that connect the words
so that no two links cross or connect the same two
words. When discussing LG, we will use the terms
dependency and link interchangeably.
Compared to the 48 dependency types of the Stan-
ford scheme, the LG English grammar defines over
100 main link types which are further divided into
400 subtypes. The unusually high number of dis-
tinct types is one of the properties of the LG English
grammar that complicate the application of LG in
information extraction. Consider, for instance, the
case of prepositional phrase attachment illustrated in
Figure 2, where all the alternative attachment struc-
tures receive different types. Arguably, this distinc-
tion is unimportant to current IE systems and there-
fore should be normalized. This normalization is in-
herent in the Stanford scheme, where the preposition
always attaches using a prep dependency.
In contrast to such unnecessarily detailed distinc-
tions, in certain cases LG types fail to make seman-
tically important distinctions. For instance, the CO
link type is used to mark almost all clause openers,
not distinguishing between, for example, adverbial
and prepositional openers.
4 Our contributions
In this section, we describe the LG-SF conversion
as well as SF BioInfer, the BioInfer corpus syntactic
27
annotation in the Stanford scheme. These are the
two primary contributions of this study.
4.1 LG-SF conversion
The LG-SF conversion transforms the undirected
LG links into directed dependencies that follow the
Stanford scheme. The transformation is based on
handwritten rules, each rule consisting of a pattern
that is matched in the LG linkage and generating a
single dependency in the Stanford parse. Since the
conversion rules only refer to the LG linkage, they
do not influence each other and are applied inde-
pendently in an arbitrary order. The pattern of each
rule is expressed as a set of positive or negative con-
straints on the presence of LG links. The constraints
typically restrict the link types and may also refer to
the lexical level, restricting only to links connecting
certain word forms. Since LG does not define link
directionality, the patterns refer to the left-to-right
order of tokens and the rules must explicitly specify
the directionality of the generated SF dependencies.
As an example, let us consider the rule
[X Pv? Y]? Y auxpass? X. The pattern matches two
tokens connected with an LG link of type Pv and
generates the corresponding directed auxpass de-
pendency. This rule applies twice in the linkage
in Figure 1. It is an example of a rare case of a
one-to-one correspondence between an LG and an
SF type. Many-to-many correspondences are much
more common: in these cases, rules specify multiple
restrictions and multiple rules are needed to gener-
ate all instances of a particular dependency type. As
a further example, we present the three rules below,
which together generate all left-to-right prep depen-
dencies. An exclamation mark in front of a restric-
tion denotes a negative restriction, i.e., the link must
not exist in order for the rule to apply. The link types
are specified as regular expressions.
[A Mp|MX[a-z]x? B]![B Cs? C]![A RS? D]? A prep? B
[A OF|MVx? B]![A RS? C]? A prep? B
[A MVp? B]![A RS? C]![C MVl? A]? A prep? B
The first of the above three rules generates the prep
dependency in the parse in Figure 1, with A=isoform
and B=of. The variables C and D are not bound to
any tokens in this sentence, as they only occur in
negative restrictions.
actin , profilin and cofilin
CC
CC CC
Figure 3: Example of a structure where the relative
order of the first two tokens cannot be resolved by
the rules.
To resolve coordination structures, it is crucial to
recognize the leftmost coordinated element, i.e. the
head of the coordination structure in the SF scheme.
However, the conversion rule patterns are unable to
capture general constraints on the relative order of
the tokens. For instance, in the linkage in Figure 3, it
is not possible to devise a pattern only matching one
of the tokens actin and profilin, while not matching
the other. Therefore, we perform a pre-processing
step to resolve the coordination structures prior to
the application of the conversion rules. After the
pre-processing, the conversion is performed with the
lp2lp software (Alphonse et al, 2004), previously
used to transform LG into the LLL competition for-
mat (Aubin, 2005).
In the development of the LG-SF conversion and
SF BioInfer, we make the following minor modifi-
cations to the Stanford scheme. The scheme dis-
tinguishes nominal and adjectival pre-modifiers of
nouns, a distinction that is not preserved in the
BioInfer corpus. Therefore, we merge the nom-
inal and adjectival pre-modifier grammatical rela-
tions into a single relation, nmod. For the same rea-
son, we do not distinguish between apposition and
abbreviation, and only use the appos dependency
type. Finally, we do not annotate punctuation.
Schneider (1998) has previously proposed a strat-
egy for identifying the head word for each LG link,
imposing directionality and thus obtaining a depen-
dency graph. Given the idiosyncrasies of the LG
linkage structures, this type of transformation into
dependency would clearly not have many of the nor-
malizing benefits of the LG-SF transformation.
4.2 SF BioInfer
For creating the BioInfer corpus syntactic annota-
tion in the Stanford scheme, the starting point of
the annotation process was the existing manual an-
notation of the corpus in the LG scheme to which
we applied the LG-SF conversion described in Sec-
tion 4.1. The resulting SF parses were then manu-
28
ally corrected by four annotators. In the manual cor-
rection phase, each sentence was double-annotated,
that is, two annotators corrected the converted out-
put independently. All disagreements were resolved
jointly by all annotators.
To estimate the annotation quality and the sta-
bility of the SF scheme, we determined annotator
agreement as precision and recall measured against
the final annotation. The average annotation preci-
sion and recall were 97.5% and 97.4%, respectively.
This high agreement rate suggests that the task was
well-defined and the annotation scheme is stable.
The BioInfer corpus consists of 1100 sentences
and, on average, the annotation consumed approxi-
mately 10 minutes per sentence in total.
5 Evaluation
In this section, we first evaluate the LG-SF conver-
sion. We then present an evaluation of the Charniak-
Lease constituency parser and the BioLG depen-
dency parser on BioInfer and GENIA.
5.1 Evaluation of the conversion rules
In the evaluation of the conversion rules against the
gold standard SF BioInfer annotation, we find a pre-
cision of 98.0% and a recall of 96.2%. Currently,
the LG-SF conversion consists of 114 rules, each
of which specifies, on average, 4.4 restrictions. Al-
together the rules currently generate 32 SF depen-
dency types, thus averaging 3.5 rules per SF type.
Only 9 of the SF types are generated by a single
rule, while the remaining require several rules. We
estimate that the current ruleset required about 100
hours to develop.
In Figure 4, we show the cumulative precision and
recall of the rules when added in the descending or-
der of their recall. Remarkably, we find that a recall
of 80% is reached with just 13 conversion rules, 90%
with 28 rules, and 95% with 56 rules. These fig-
ures demonstrate that while the SF and LG schemes
are substantially different, a high-recall conversion
can be obtained with approximately fifty carefully
crafted rules. Additionally, while precision is con-
sistently high, the highest-recall rules also have the
highest precision. This may be related to the fact
that the most common SF dependency types have a
straightforward correspondence in LG types.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0  20  40  60  80  100
Number of conversion rules
Recall
Precision
Figure 4: Cumulative precision and recall of the con-
version rules.
A common source of errors in the LG-SF conver-
sion are the Link Grammar idiomatic expressions,
which are analyzed as a chain of ID links (0.7% of
all links in the BioInfer corpus) and connected to
the linkage always through their last word. Some
examples of LG idiomatic expressions include each
other, no one, come of age, gotten rid of, for good,
and the like. These expressions are often problem-
atic in the SF conversion as well. We did not at-
tempt any wide-coverage systematic resolution of
the idiomatic expressions and, apart from the most
common cases such as in vitro, we preserve the LG
structure of connecting these expressions through
their last word. We note, however, that the list of
idiomatic LG expressions is closed and therefore a
case-by-case resolution leading to a full coverage is
possible, although not necessarily practical.
Similar to the LG idiomatic expressions are the
SF dep dependencies, generated when none of the
SF rules assigns a more specific type. In most cases,
dep is a result of a lack of coverage of the SF con-
version rules typically occurring in rare or idiomatic
expressions. We assume that many of the dep depen-
dencies will be resolved in the future, given that the
SF conversion and the SF dependency scheme itself
are presented by the authors as a work in progress.
Therefore, we do not attempt to replicate most of
the SF dep dependencies with the LG-SF conversion
rules; much of the effort would be obsoleted by the
progress of the SF conversion. The dep dependen-
cies account for 23% of the total 3.8% of dependen-
cies not recovered by the LG-SF conversion.
29
Charniak-Lease BioLG
corpus Prec. Rec. F Prec. Rec. F
GENIA 81.2 81.3 81.3 76.9 72.4 74.6
BioInfer 78.4 79.9 79.4 79.6 76.1 77.8
Table 1: Parser performance. Precision, recall and
F-measure for the two parsers on the two corpora.
5.2 Evaluated parsers and corpora
The Charniak-Lease parser is a statisti-
cal constituency parser developed by Char-
niak and Lease (2005). It is an adaptation of the
Charniak parser (Charniak, 1999) to the biomedical
domain. For example, it uses a POS-tagger trained
on the GENIA corpus, although the parser itself has
been trained on the Penn Treebank. The Charniak-
Lease parser is of particular interest, because in a
recent comparison performed by Clegg and Shep-
herd (2007) on the GENIA Treebank, it was the
best performing of several state-of-the-art statistical
constituency parsers.
The LG parser is a rule-based dependency parser
with a broad coverage grammar of newspaper-type
English. It has no probabilistic component and does
not perform pruning of ambiguous alternatives dur-
ing parsing. Instead, the parser generates all parses
accepted by the grammar. Simple heuristics are ap-
plied to rank the alternative parses.
Here, we evaluate a recently introduced adap-
tation of LG to the biomedical domain, BioLG
(Pyysalo et al, 2006), incorporating the GENIA
POS tagger (Tsuruoka et al, 2005) as well as a num-
ber of modifications to lexical processing and the
grammar.
To facilitate the comparison of results with those
of Clegg and Shepherd, we use their modified subset
of GENIA Treebank.4 As 600 of the 1100 BioInfer
sentences have previously been used in the develop-
ment of the BioLG parser, we only use the remaining
500 blind sentences of BioInfer in the evaluation.
5.3 Parser performance
To evaluate the performance of the parsers, we de-
termined the precision, recall and F-measure by
comparing the parser output against the corpus gold
4http://chomsky-ext.cryst.bbk.ac.uk/
andrew/downloads.html
BioLG
scheme Prec. Rec. F
LG 78.2 77.2 77.7
SF 79.6 76.1 77.8
Table 2: BioLG performance on the BioInfer corpus
with and without the LG-SF conversion.
standard dependencies. The matching criterion re-
quired that the correct words are connected and
that the direction and type of the dependency are
correct. The dependency-based evaluation results
for the Charniak-Lease and BioLG parsers on the
GENIA and BioInfer corpora are shown in Table 1.
We note that Clegg and Shepherd (2007) report
77% F-score performance of Charniak-Lease on the
GENIA corpus, using the collapsed variant of the SF
scheme. We replicated their experiment using the
uncollapsed variant and found an F-score of 80%.
Therefore, most of the approximately 4% difference
compared to our finding reported in Table 1 is due
to this difference in the use of collapsing, with our
modifications to the SF scheme having a lesser ef-
fect. The decrease in measured performance caused
by the collapsing is, however, mostly an artifact
caused by merging several dependencies into one; a
single mistake of the parser can have a larger effect
on the performance measurement.
We find that while the performance of the
Charniak-Lease parser is approximately 2 percent-
age units better on GENIA than on BioInfer, for
BioLG we find the opposite effect, with performance
approximately 3 percentage units better on BioInfer.
Thus, both parsers perform better on the corpora
closer to their native scheme. We estimate that this
total 5 percentage unit divergence represents an up-
per limit to the evaluation bias introduced by the two
sets of conversion rules. We discuss the possible
causes for this divergence in Section 5.4.
To determine whether the differences between the
two parsers on the two corpora were statistically
significant, we used the Wilcoxon signed-ranks test
for F-score performance using the Bonferroni cor-
rection for multiple comparisons (N = 2), follow-
ing the recent recommendation of Dems?ar (2006).
We find that the Charniak-Lease parser outperforms
BioLG statistically significantly on both the GENIA
corpus (p ? 0.01) and on the BioInfer corpus
30
  Z   protein  but  not  c-myb  protein 
<nmod <dep
cc>
<nmod
conj>
  Z   protein  but  not  c-myb  protein 
<nmod dep>
cc>
<nmod
conj>
Figure 5: Example of divergence on the interpreta-
tion of the Stanford scheme. Above: GENIA and
Stanford conversion interpretation. Below: BioInfer
and LG-SF rules interpretation.
(p < 0.01). Thus, the relative performance of the
parsers can, in this case, be established even in the
presence of opposing conversion biases on the two
corpora.
In Table 2, we present an evaluation of the BioLG
parser with and without the LG-SF conversion,
specifically evaluating the effect of the conversion
presented in this study. Here we find a substantially
more stable performance, including even an increase
in precision. This further validates the quality of the
conversion rules.
Finally, we note that the processing time required
to perform the conversions is insignificant compared
to the time consumed by the parsers.
5.4 Discussion
Evaluating BioLG on GENIA and the Charniak-
Lease parser on BioInfer includes multiple sources
of divergence. In addition to parser errors, differ-
ences can be created by the LG-SF conversion and
the Stanford conversion. Moreover, in examining
the outputs we identified that a further source of
divergence is due to differing interpretations of the
Stanford scheme. One such difference is illustrated
in Figure 5. Here the BioLG parser with the LG-
SF conversion produces an analysis that differs from
the result of converting the GENIA Treebank analy-
sis by the Stanford conversion. This is due to the
Stanford conversion producing an apparently flawed
analysis that is not replicated by the LG-SF con-
version. In certain cases of this type, the lack of a
detailed definition of the SF scheme prevents from
distinguishing between conversion errors and inten-
tional analyses. This will necessarily lead to differ-
ing interpretations, complicating precise evaluation.
6 Conclusions
We have presented a step towards unifying syntactic
annotations under the Stanford dependency scheme
and assessed the feasibility of this unification by
developing and evaluating a conversion from Link
Grammar to the Stanford scheme. We find that a
highly reliable transformation can be created, giv-
ing a precision and recall of 98.0% and 96.2%, re-
spectively, when compared against our manually an-
notated gold standard version of the BioInfer cor-
pus. We also find that the performance of the BioLG
parser is not adversely affected by the conversion.
Given the clear benefits that the Stanford scheme
has for domain analysis, the conversion increases the
overall suitability of the parser to IE applications.
Based on these results, we conclude that converting
to the Stanford scheme is both feasible and practical.
Further, we have developed a version of the
BioInfer corpus annotated with the Stanford scheme,
thereby increasing the usability of the corpus. We
applied the LG-SF conversion to the original LG
BioInfer annotation and manually corrected the er-
rors. The high annotator agreement of above 97%
precision and recall confirms the stability of the SF
scheme.
We have also demonstrated that the unification
permits direct parser comparison that was previously
impossible. However, we found that there is a cer-
tain accumulation of errors caused by the conver-
sion, particularly in a case when two distinct rule
sets are applied. In our case, we estimate this error
to be on the order of several percentage units, never-
theless, we were able to establish the relative perfor-
mance of the parses with a strong statistical signif-
icance. These results demonstrate the utility of the
Stanford scheme as a unifying representation of syn-
tax. We note that an authoritative definition of the
Stanford scheme would further increase its value.
Acknowledgments
We would like to thank Erick Alphonse, Sophie
Aubin and Adeline Nazarenko for providing us with
the lp2lp software and the LLL conversion rules. We
would also like to thank Andrew Brian Clegg and
Adrian Shepherd for making available the data and
evaluation tools used in their parser evaluation. This
work was supported by the Academy of Finland.
31
References
Erick Alphonse, Sophie Aubin, Philippe Bessie`res, Gilles
Bisson, Thierry Hamon, Sandrine Laguarigue, Ade-
line Nazarenko, Alain-Pierre Manine, Claire Ne?dellec,
Mohamed Ould Abdel Vetah, Thierry Poibeau, and
Davy Weissenbacher. 2004. Event-Based Information
Extraction for the biomedical domain: the Caderige
project. In N. Collier, P. Ruch, and A. Nazarenko, ed-
itors, COLING NLPBA/BioNLP Workshop, pages 43?
49, Geneva, Switzerland.
Sophie Aubin, Adeline Nazarenko, and Claire Ne?dellec.
2005. Adapting a general parser to a sublanguage. In
G. Angelova, K. Bontcheva, R. Mitkov, N. Nicolov,
and N. Nikolov, editors, Proceedings of the Interna-
tional Conference on Recent Advances in Natural Lan-
guage Processing (RANLP 05), Borovets, Bulgaria,
pages 89?93. Incoma, Bulgaria.
Sophie Aubin. 2005. LLL challenge - syntactic analysis
guidelines. Technical report, LIPN, Universite? Paris
Nord, Villetaneuse.
Ann Bies, Mark Ferguson, Karen Katz, and Robert Mac-
Intyre. 1995. Bracketing guidelines for treebank ii
style. Technical report, Penn Treebank Project, Uni-
versity of Pennsylvania.
Eugene Charniak and Matthew Lease. 2005. Parsing
biomedical literature. In R. Dale, K. F. Wong, J. Su,
and O. Y. Kwong, editors, Proceedings of the Sec-
ond International Joint Conference on Natural Lan-
gage Processing, Jeju Island, Korea, pages 58?69.
Eugene Charniak. 1999. A maximum-entropy-inspired
parser. Technical report, Brown University.
Andrew Brian Clegg and Adrian Shepherd. 2007.
Benchmarking natural-language parsers for biological
applications using dependency graphs. BMC Bioinfor-
matics, 8(1):24.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
N. Calzolari, K. Choukri, A. Gangemi, B. Maegaard,
J. Mariani, J. Odijk, and D. Tapias, editors, Proceed-
ings of the 5th International Conference on Language
Resources and Evaluation (LREC 2006), pages 449?
454.
Janez Dems?ar. 2006. Statistical comparisons of clas-
sifiers over multiple data sets. Journal of Machine
Learning Research, 7:1?30.
Jing Ding, Daniel Berleant, Jun Xu, and Andy W. Fulmer.
2003. Extracting biochemical interactions from med-
line using a link grammar parser. In B. Werner, editor,
Proceedings of the 15th IEEE International Confer-
ence on Tools with Artificial Intelligence, pages 467?
471. IEEE Computer Society, Los Alamitos, CA.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun?ichi
Tsujii. 2003. GENIA corpus?a semantically an-
notated corpus for bio-textmining. Bioinformatics,
19:i180?182.
Roger Levy and Galen Andrew. 2006. Tregex and Tsur-
geon: tools for querying and manipulating tree data
structures. In N. Calzolari, K. Choukri, A. Gangemi,
B. Maegaard, J. Mariani, J. Odijk, and D. Tapias, ed-
itors, Proceedings of the 5th International Conference
on Language Resources and Evaluation (LREC 2006),
pages 2231?2234.
Dekang Lin. 1998. A dependency-based method for
evaluating broad-coverage parsers. Natural Language
Engineering, 4(2):97?114.
Sampo Pyysalo, Tapio Salakoski, Sophie Aubin, and
Adeline Nazarenko. 2006. Lexical adaptation of link
grammar to the biomedical sublanguage: a compara-
tive evaluation of three approaches. BMC Bioinfor-
matics, 7(Suppl 3).
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Fabio Rinaldi, Gerold Schneider, Kaarel Kaljurand,
James Dowdall, Andreas Persidis, and Ourania Kon-
stanti. 2004. Mining relations in the genia corpus. In
Proceedings of the Workshop W9 on Data Mining and
Text Mining for Bioinformatics (ECML/PKDD?04),
pages 61?68, Pisa, Italy.
Gerold Schneider. 1998. A linguistic comparison of
constituency, dependency and link grammar. Master?s
thesis, University of Zu?rich.
Daniel D. Sleator and Davy Temperley. 1993. Parsing
English with a Link Grammar. In Third International
Workshop on Parsing Technologies.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun?ichi Tsujii. 2005. Developing a robust part-
of-speech tagger for biomedical text. In P. Bozanis and
E. N. Houstis, editors, 10th Panhellenic Conference on
Informatics, volume 3746, pages 382?392.
32
Proceedings of the Workshop on BioNLP: Shared Task, pages 10?18,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Extracting Complex Biological Events with Rich Graph-Based Feature Sets
Jari Bjo?rne,1 Juho Heimonen,1,2 Filip Ginter,1 Antti Airola,1,2
Tapio Pahikkala1 and Tapio Salakoski1,2
1Department of Information Technology, University of Turku
2Turku Centre for Computer Science (TUCS)
Joukahaisenkatu 3-5, 20520 Turku, Finland
firstname.lastname@utu.fi
Abstract
We describe a system for extracting com-
plex events among genes and proteins from
biomedical literature, developed in context of
the BioNLP?09 Shared Task on Event Extrac-
tion. For each event, its text trigger, class, and
arguments are extracted. In contrast to the pre-
vailing approaches in the domain, events can
be arguments of other events, resulting in a
nested structure that better captures the under-
lying biological statements. We divide the task
into independent steps which we approach as
machine learning problems. We define a wide
array of features and in particular make ex-
tensive use of dependency parse graphs. A
rule-based post-processing step is used to re-
fine the output in accordance with the restric-
tions of the extraction task. In the shared task
evaluation, the system achieved an F-score of
51.95% on the primary task, the best perfor-
mance among the participants.
1 Introduction
In this paper, we present the best-performing system
in the primary task of the BioNLP?09 Shared Task
on Event Extraction (Kim et al, 2009).1 The pur-
pose of this shared task was to competitively eval-
uate information extraction systems targeting com-
plex events in the biomedical domain. Such an eval-
uation helps to establish the relative merits of com-
peting approaches, allowing direct comparability of
results in a controlled setting. The shared task was
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/SharedTask
the first competitive evaluation of its kind in the
BioNLP field as the extraction of complex events
became possible only recently with the introduction
of corpora containing the necessary annotation: the
GENIA event corpus (Kim et al, 2008a) and the
BioInfer corpus (Pyysalo et al, 2007).
The objective of the primary task (Task 1) was
to detect biologically relevant events such as pro-
tein binding and phosphorylation, given only anno-
tation of named entities. For each event, its class,
trigger expression in the text, and arguments need to
be extracted. The task follows the recent movement
in BioNLP towards the extraction of semantically
typed, complex events the arguments of which can
also be other events. This results in a nested struc-
ture that captures the underlying biological state-
ments more accurately compared to the prevailing
approach of merely detecting binary interactions of
pairs of biological entities.
Our system is characterized by heavy reliance
on efficient, state-of-the-art machine learning tech-
niques and a wide array of features derived from
a full dependency analysis of each sentence. The
system is a pipeline of three major processing steps:
trigger recognition, argument detection and seman-
tic post-processing. By separating trigger recog-
nition from argument detection, we can use meth-
ods familiar from named entity recognition to tag
words as event triggers. Event argument detection
then becomes the task of predicting for each trigger?
trigger or trigger?named entity pair whether it cor-
responds to an actual instantiation of an event argu-
ment. Both steps can thus be approached as classi-
fication tasks. In contrast, semantic post-processing
10
Sentence?splitting
Tokenization
Parsing
Conversion?to?graph?
representation
Trigger?detection
(multi?class?SVM)
System?output
Semantic?post?processing
(rule?based)
Edge?detection
(multi?class?SVM)
Input?data
Figure 1: The main components of the system.
is rule-based, directly implementing argument type
constraints following from the definition of the task.
In the following sections, we present the imple-
mentation of the three stages of our information ex-
traction system in detail, and provide insights into
why we chose the approach we did. We also discuss
alternate directions we followed but that did not im-
prove performance. Finally, we analyze the overall
performance of our system in the shared task as well
as evaluate its components individually.
2 The system description
The overall architecture of the system is shown
in Figure 1. All steps in the system process one
sentence at a time. Since 95% of all annotated
events are fully contained within a single sentence,
this does not incur a large performance penalty but
greatly reduces the size and complexity of the ma-
chine learning problems.
2.1 Graph representation
We represent the extraction target in terms of seman-
tic networks, graphs where the nodes correspond
to named entities and events, and the edges corre-
spond to event arguments. The shared task can then
be viewed as the problem of finding the nodes and
edges of this graph. For instance, nested events are
naturally represented through edges connecting two
event nodes. The graph representation of an exam-
ple sentence is illustrated in Figure 2D.
We have previously used this graph representa-
tion for information extraction (Heimonen et al,
2008; Bjo?rne et al, 2009) as well as for establishing
the connection between events and syntactic depen-
dency parses in the Stanford scheme of de Marneffe
and Manning (2008) (Bjo?rne et al, 2008).
2.2 Trigger detection
We cast trigger detection as a token labeling prob-
lem, that is, each token is assigned to an event class,
or a negative class if it does not belong to a trig-
ger. Triggers are then formed based on the predicted
classes of the individual tokens. Since 92% of all
triggers in the data consist of a single token, adjacent
tokens with the same class prediction form a single
trigger only in case that the resulting string occurs
as a trigger in the training data. An event node is
created for each detected trigger (Figure 2B).
In rare cases, the triggers of events of different
class share a token, thus the token belongs to sev-
eral separate classes. To be able to approach trigger
detection as a multi-class classification task where
each token is given a single prediction, we intro-
duce combined classes as needed. For instance the
class gene expression/positive regulation denotes to-
kens that act as a trigger to two events of the two
respective classes. Note that this implies that the
trigger detection step produces at most one event
node per class for any detected trigger. In the shared
task, however, multiple events of the same class can
share the same trigger. For instance, the trigger in-
volves in Figure 2 corresponds to two separate regu-
lation events. A separate post-processing step is in-
troduced after event argument detection to duplicate
event nodes as necessary (see Section 2.4).
Due to the nature of the GENIA event annota-
tion principles, trigger detection cannot be easily re-
duced to a simple dictionary lookup of trigger ex-
pressions for two main reasons. First, a number of
common textual expressions act as event triggers in
some cases, but not in other cases. For example,
only 28% of the instances of the expression activates
are triggers for a positive regulation event while the
remaining 72% are not triggers for any event. Sec-
ond, a single expression may be associated with var-
ious event classes. For example, the instances of the
token overexpression are evenly distributed among
11
Regulation
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
<Theme <Theme Cause> Cause>
NN NN NN VBZ NN CC .
<nn conj_and><nn dobj><nsubj
NN
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
<Theme <Theme Cause>
Cause><Theme
node duplication
pars
e
T29   Regulation   regulationT30   Regulation   involvesE10   Regulation:T29   Theme:T7E11   Regulation:T30   Theme:E10   Cause:T9E12   Regulation:T30   Theme:E10   Cause:T8
equivalent
D
C
E
T7     Protein   IL-4T8     Protein   NFAT1T9     Protein   NFAT2
Protein
IL-4 gene
Regulation
regulation
Regulation
involves
Protein
NFAT1 and
Protein
NFAT2 .
Protein
IL-4 gene regulation involves
Protein
NFAT1 and
Protein
NFAT2 .
edge detection
trigger recognition
Trai
ning
 Dat
a Pr
epa
ratio
n
B
A
Eve
nt E
xtra
ction
dobj>
Figure 2: An example sentence from Shared Task document 10069428 (simplified). A) Named entities are given.
B) Triggers are detected and corresponding event nodes are created. C) Event argument edges are predicted between
nodes. The result is a sentence-level semantic network. D) One node may denote multiple events of the same class,
therefore nodes are duplicated in the semantic post-processing step. E) The resulting graph can be losslessly trans-
formed into the Shared Task event annotation. Training data for the trigger recognizer includes named entity annotation
(A) and for the edge detector the semantic network with no node duplication (C).
gene expression, positive regulation, and the nega-
tive class. In light of these properties, we address
trigger detection with a multi-class support vector
machine (SVM) classifier that assigns event classes
to individual tokens, one at a time. This is in con-
trast to sequence labeling problems such as named
entity recognition, where a sequential model is typ-
ically employed. The classifier is trained on gold-
standard triggers from the training data and incorpo-
rates a wide array of features capturing the proper-
ties of the token to be classified, both its linear and
dependency context, and the named entities within
the sentence.
Token features include binary tests for capital-
ization, presence of punctuation or numeric charac-
ters, stem using the Porter stemmer (Porter, 1980),
character bigrams and trigrams, and presence of the
token in a gazetteer of known trigger expressions
and their classes, extracted from the training data.
Token features are generated not only for the token
to be classified, but also for tokens in the immediate
linear context and dependency context (tokens that
govern or depend on the token to be classified).
Frequency features include the number of
named entities in the sentence and in a linear win-
dow around the token in question as well as bag-of-
word counts of token texts in the sentence.
Dependency chains up to depth of three are
constructed, starting from the token to be classified.
At each depth, both token features and dependency
type are included, as well as the sequence of depen-
dency types in the chain.
The trigger detector used in the shared task is
in fact a weighted combination of two indepen-
12
dent SVM trigger detectors, both based on the same
multi-class classification principle and somewhat
different feature sets.2 The predictions of the two
trigger detectors are combined as follows. For each
trigger detector and each token, the classifier confi-
dence scores of the top five classes are re-normalized
into the [0, 1] interval. The renormalized confidence
scores of the two detectors are then linearly inter-
polated using a parameter ?, 0 ? ? ? 1, whose
value is set experimentally on the development set,
as discussed below.
Setting the correct precision?recall trade-off in
trigger detection is very important. On one hand,
any trigger left undetected directly implies a false
negative event. On the other hand, the edge detec-
tor is trained on gold standard data where there are
no event nodes without arguments, which creates a
bias toward predicting edges for any event node the
edge detector is presented with. On the develop-
ment set, essentially all predicted event nodes are
given at least one argument edge. We optimize the
precision?recall trade-off explicitly by introducing a
parameter ?, 0 ? ?, that multiplies the classifier
confidence score given to the negative class, that is,
the ?no trigger? class. When ? < 1, the confidence
of the negative class is decreased, thus increasing
the possibility of a given token forming a trigger,
and consequently increasing the recall of the trigger
detector (naturally, at the expense of its precision).
Both trigger detection parameters, the interpola-
tion weight ? and the precision?recall trade-off pa-
rameter ?, are set experimentally using a grid search
to find the globally optimal performance of the en-
tire system on the development set, using the shared
task performance metric. The parameters are thus
not set to optimize the performance of trigger detec-
tion in isolation; they are rather set to optimize the
performance of the whole system.
2.3 Edge detection
After trigger detection, edge detection is used to pre-
dict the edges of the semantic graph, thus extracting
event arguments. Like the trigger detector, the edge
detector is based on a multi-class SVM classifier.
We generate examples for all potential edges, which
2This design should be considered an artifact of the time-
constrained, experiment-driven development of the system
rather than a principled design choice.
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
 50
0 1 2 3 4 5 6 7 8 9 10 >10
Pro
por
tion
 of 
edg
es [%
]
Edge length
dependency distancelinear distance
Figure 3: The distribution of event argument edge lengths
measured as the number of dependencies on the shortest
dependency path between the edge terminal nodes, con-
trasted with edge lengths measured as the linear token
distance.
are always directed from an event node to another
event node (event nesting) or from an event node to
a named entity node. Each example is then classified
as theme, cause, or a negative denoting the absence
of an edge between the two nodes in the given di-
rection. It should be noted that even though event
nodes often require multiple outgoing edges corre-
sponding to multiple event arguments, all edges are
predicted independently and are not affected by pos-
itive or negative classifications of other edges.
The feature set makes extensive use of syntac-
tic dependencies, in line with many recent stud-
ies in biomedical information extraction (see, e.g.
(Kim et al, 2008b; Miwa et al, 2008; Airola et al,
2008; Van Landeghem et al, 2008; Katrenko and
Adriaans, 2008)). The central concept in generat-
ing features of potential event argument edges is the
shortest undirected path of syntactic dependencies
in the Stanford scheme parse of the sentence which
we assume to accurately capture the relationship ex-
pressed by the edge. In Figure 3, we show that the
distances among event and named entity nodes in
terms of shortest dependency path length are con-
siderably shorter than in terms of their linear order in
the sentence. The end points of the path are the syn-
tactic head tokens of the two named entities or event
triggers. The head tokens are identified using a sim-
ple heuristic. Where multiple shortest paths exist,
all are considered. Most features are built by com-
bining the attributes of multiple tokens (token text,
13
POS tag and entity or event class, such as protein or
binding) or dependencies (type such as subject and
direction relative to surrounding tokens).
N-grams are generated by merging the at-
tributes of 2?4 consecutive tokens. N-grams are also
built for consecutive dependencies. Additional tri-
grams are built for each token and its two flank-
ing dependencies, as well as for each dependency
and its two flanking tokens. These N-grams are de-
fined in the direction of the potential event argument
edge. To take into account the varying directions
of the dependencies, each pair of consecutive tokens
forms an additional bigram defining their governor-
dependent relationship.
Individual component features are defined for
each token and edge in a path based on their
attributes which are also combined with the to-
ken/edge position at either the interior or the end of
the path. Edge attributes are combined with their di-
rection relative to the path.
Semantic node features are built by directly
combining the attributes of the two terminal
event/entity nodes of the potential event argument
edge. These features concatenate both the specific
types of the nodes (e.g. protein or binding) as well
as their categories (event or named entity). Finally,
if the events/entities have the same head token, this
self-loop is explicitly defined as a feature.
Frequency features include the length of the
shortest path as an integer-valued feature as well as
an explicit binary feature for each length. The num-
ber of named entities and event nodes, per type, in
the sentence are defined for each example.
We have used this type of edge detector with a
largely similar feature set previously (Bjo?rne et al,
2009). Also, many of these features are standard
in relation extraction studies (see, e.g., Buyko et al
(2008)).
2.4 Semantic post-processing
The semantic graph produced by the trigger and
edge detection steps is not final. In particular, it
may contain event nodes with an improper combi-
nation of arguments, or no arguments whatsoever.
Additionally, as discussed in Section 2.2, if there are
events of the same class with the same trigger, they
are represented by a single node. Therefore, we in-
troduce a rule-based post-processing step to refine
Figure 4: Example of event duplication. A) All theme?
cause combinations are generated for regulation events.
B) A heuristic is applied to decide how theme arguments
of binding events should be grouped.
the graph, using the restrictions on event argument
types and combinations defined in the shared task.
In Task 1, the allowed argument edges in the
graph are 1) theme from an event to a named en-
tity, 2) theme or cause from a regulation event (or its
subclasses) to an event or a named entity. Edges cor-
responding to invalid arguments are removed. Also,
directed cycles are broken by removing the edge
with the weakest classification confidence score.
After pruning invalid edges, event nodes are du-
plicated so that all events have a valid combination
of arguments. For example, the regulation event in-
volves in Figure 2C has two cause arguments and
therefore represents two distinct events. We thus
duplicate the event node, obtaining one regulation
event for each of the cause arguments (Figure 2D).
Events of type gene expression, transcription,
translation, protein catabolism, localization, and
phosphorylation must have exactly one theme argu-
ment, which makes the duplication process trivial:
duplicate events are created, one for each of the ar-
guments. Regulation events must have one theme
and can additionally have one cause argument. For
these classes we use a heuristic, generating a new
event for each theme?cause combination of outgo-
ing edges (Figure 4A). Binding is the only event
class that can have multiple theme arguments. There
is thus no simple way of determining how multi-
ple outgoing theme edges should be grouped (Fig-
ure 4B). We apply a heuristic that first groups the ar-
guments by their syntactic role, defined here as xthe
first dependency in the shortest path from the event
14
to the argument. It then generates an event for each
pair of arguments that are in different groups. In the
case of only one group, all single-argument events
are generated.
Finally, all events with no arguments as well as
regulation events without a theme argument are iter-
atively removed until no such event remains. The
resulting graph is the output of our event extrac-
tion system and can be losslessly converted into the
shared task format (Figure 2D&E).
2.5 Alternative directions
We now briefly describe some of the alternative di-
rections explored during the system development,
which however did not result in increased perfor-
mance, and were thus not included in the final sys-
tem. Whether the reason was due to the considered
approaches being inadequate for the extraction task,
or simply a result of the tight time constraints en-
forced by the shared task is a question only further
research can shed light on.
For the purpose of dividing the extraction prob-
lem into manageable subproblems, we make strong
independence assumptions. This is particularly the
case in the edge detection phase where each edge
is considered in isolation from other edges, some
of which may actually be associated with the same
event. Similar assumptions are made in the trigger
detection phase, where the classifications of individ-
ual tokens are independent.
A common way to relax independence assump-
tions is to use N -best re-ranking where N most-
likely candidates are re-ranked using global features
that model data dependencies that could not be mod-
elled in the candidate generation step. The best can-
didate with respect to this re-ranked order is then
the final prediction of the system. N -best re-ranking
has been successfully applied for example in statisti-
cal parsing (Charniak and Johnson, 2005). We gen-
erated the ten most likely candidate graphs, as de-
termined by the confidence scores of the individual
edges given by the multi-class SVM. A perfect re-
ranking of these ten candidates would lead to 11.5
percentage point improvement in the overall system
F-score on the development set. While we were un-
able to produce a re-ranker sufficiently accurate to
improve the system performance in the time given,
the large potential gain warrants further research.
In trigger word detection, we experimented with
a structural SVM incorporating Hidden Markov
Model type of sequential dependencies (Altun et al,
2003; Tsochantaridis et al, 2004), which allow con-
ditioning classification decisions on decisions made
for previous tokens as well as with a conditional ran-
dom field (CRF) sequence classifier (Lafferty et al,
2001). Neither of these experiments led to a perfor-
mance gain over the multiclass SVM classifier.
As discussed previously, 4.8% of all annotated
events cross sentence boundaries. This problem
could be approached using coreference resolution
techniques, however, the necessary explicit corefer-
ence annotation to train a coreference resolution sys-
tem is not present in the data. Instead, we attempted
to build a machine-learning based system to detect
cross-sentence event arguments directly, rather than
via their referring expression, but were unable to im-
prove the system performance.
3 Tools and resources
3.1 Multi-class SVM
We use a support vector machine (SVM) multi-class
classifier which has been shown to have state-of-
the-art classification performance (see e.g. (Cram-
mer and Singer, 2002; Tsochantaridis et al, 2004)).
Namely, we use the SVMmulticlass implementa-
tion3 which is one of the fastest multi-class SVM
implementations currently available. Analogously
to the binary SVMs, multi-class SVMs have a reg-
ularization parameter that determines the trade-off
between the training error and the complexity of the
learned concept. We select the value of the parame-
ter on the development set. Multi-class SVMs scale
linearly with respect to both the amount of training
data and the average number of nonzero features per
training example, making them an especially suit-
able learning method for our purposes. They also
provide a real-valued prediction for each example
to be classified which is used as a confidence score
in trigger detection precision?recall trade-off adjust-
ment and event argument edge cycle breaking in se-
mantic post-processing. We use the linear kernel,
the only practical choice to train the classifier with
the large training sets available. For example, the
3http://svmlight.joachims.org/svm_
multiclass.html
15
 0
 10
 20
 30
 40
 50
 60
 70
 80
 0  10  20  30  40  50  60  70  80
Re
cal
l [%
]
Precision [%]
Figure 5: Performance of the 24 systems that participated
in Task 1, together with an F-score contour plot for refer-
ence. Our system is marked with a full circle.
final training data of the edge detector (8932 sen-
tences) consists of 31792 training examples with
295034 unique features. Training with even this
amount of data is computationally feasible, typically
taking less than an hour.
All classifiers used in the system are trained as
follows. First we optimize the regularization param-
eter C by training on the shared task training set and
testing on the shared task development set. We then
re-train the final classifier on the union of the train-
ing and development sets, using the best value of C
in the previous step. The same protocol is followed
for the ? and ? parameters in trigger detection.
3.2 Dependency parses
Both trigger detection and edge prediction rely on
a wide array of features derived from full depen-
dency parses of the sentence. We use the McClosky-
Charniak domain-adapted parser (McClosky and
Charniak, 2008) which is among the best perform-
ing parsers trained on the GENIA Treebank corpus.
The native constituency output of the parser is trans-
formed to the ?collapsed? form of the Stanford de-
pendency scheme (de Marneffe and Manning, 2008)
using the Stanford parser tools.4 The parses were
provided by the shared task organizers.
4 Results and discussion
The final evaluation of the system was performed by
the shared task organizers using a test set whose an-
4http://nlp.stanford.edu/software/
notation was at no point available to the task partici-
pants. By the main criterion of Task 1, approximate
span matching with approximate recursive match-
ing, our system achieved an F-score of 51.95%. Fig-
ure 5 shows the performance of all systems partic-
ipating in Task 1. The per-class results in Table 1
show that regulation events (including positive and
negative regulation) as well as binding events are the
hardest to extract. These classes have F-scores in
the 31?44% range, while the other classes fall into
the 50?78% range. This is not particularly surpris-
ing since binding and regulation are the only classes
in which events can have multiple arguments, which
means that for an event to be detected correctly, the
edge detector often must make several correct pre-
dictions. Additionally, these classes have the lowest
trigger recognition performance on the development
set. It is interesting to note that the per-class perfor-
mance in Table 1 shows no clear correlation between
the number of events of a class and its F-score.
Table 2 shows the performance of the system us-
ing various other evaluation criteria defined in the
shared task. The most interesting of these is the
strict matching criterion, which, in order to consider
an event correctly extracted, requires exact trigger
span as well as all its nested events to be recursively
correct. The performance of the system with respect
to the strict criterion is 47.41% F-score, only 4.5 per-
centage points lower than the relaxed primary mea-
sure. As seen in Table 2, this difference is almost
exclusively due to triggers with incorrect span.
To evaluate the performance impact of each sys-
tem component individually, we report in Table 3
overall system performance on the development set,
obtained by progressively replacing the processing
steps with gold-standard data. The results show that
the errors of the system are almost evenly distributed
between the trigger and edge detectors. For instance,
a perfect trigger detector would decrease the overall
system error of 46.5% by 18.58 percentage points,
a relative decrease of 40%. A perfect edge detec-
tor would, in combination with a perfect trigger de-
tector, lead to system performance of 94.69%. The
improvement that could be gained by further devel-
opment of the semantic post-processing step is thus
limited, indicating that the strict argument combina-
tion restrictions of Task 1 are sufficient to resolve the
majority of post-processing cases.
16
Event Class # R P F
Protein catabolism 14 42.86 66.67 52.17
Phosphorylation 135 80.74 74.66 77.58
Transcription 137 39.42 69.23 50.23
Localization 174 49.43 81.90 61.65
Regulation 291 25.43 38.14 30.52
Binding 347 40.06 49.82 44.41
Negative regulation 379 35.36 43.46 38.99
Gene expression 722 69.81 78.50 73.90
Positive regulation 983 38.76 48.72 43.17
Total 3182 46.73 58.48 51.95
Table 1: Per-class performance in terms of Recall, Preci-
sion, and F-score on the test set (3182 events) using ap-
proximate span and recursive matching, the primary eval-
uation criterion of Task 1.
Matching R P F
Strict 42.65 53.38 47.41
Approx. Span 46.51 58.24 51.72
Approx. Span&Recursive 46.73 58.48 51.95
Table 2: Performance of our system on the test set (3182
events) with respect to other evaluation measures in the
shared task.
5 Conclusions
We have described a system for extracting complex,
typed events from biomedical literature, only assum-
ing named entities as given knowledge. The high
rank achieved in the BioNLP?09 Shared Task com-
petitive evaluation validates the approach taken in
building the system. While the performance is cur-
rently the highest achieved on this data, the F-score
of 51.95% indicates that there remains considerable
room for further development and improvement.
We use a unified graph representation of the data
in which the individual processing steps can be for-
mulated as simple graph transformations: adding or
removing nodes and edges. It is our experience that
such a representation makes handling the data fast,
easy and consistent. The choice of graph representa-
tion is further motivated by the close correlation of
these graphs with dependency parses. As we are go-
ing to explore the interpretation and applications of
these graphs in the future, the graph representation
will likely provide a flexible base to build on.
Dividing the task of event extraction into multi-
ple subtasks that can be approached by well-studied
Trig Edge PP R P F ?F
pred pred pred 51.54 55.62 53.50
GS pred pred 71.66 72.51 72.08 18.58
GS GS pred 97.21 92.30 94.69 22.61
GS GS GS 100.0 100.0 100.0 5.31
Table 3: Effect of the trigger detector (Trig), edge detec-
tor (Edge), and post-processing (PP) on performance on
the development set (1789 events). The ?F column in-
dicates the effect of replacing the predictions (pred) of
a component with the corresponding gold standard data
(GS), i.e. the maximal possible performance gain obtain-
able from further development of that component.
methods proved to be an effective approach in de-
veloping our system. We relied on state-of-the-art
machine learning techniques that scale up to the task
and allow the use of a considerable number of fea-
tures. We also carefully optimized the various pa-
rameters, a vital step when using machine learning
methods, to fine-tune the performance of the system.
In Section 2.5, we discussed alternative directions
pursued during the development of the current sys-
tem, indicating possible future research directions.
To support this future work as well as complement
the description of the system in this paper we intend
to publish our system under an open-source license.
This shared task represents the first competi-
tive evaluation of complex event extraction in the
biomedical domain. The prior research has largely
focused on binary interaction extraction, achieving
after a substantial research effort F-scores of slightly
over 60% (see, e.g., Miwa et al (2008)) on AIMed,
the de facto standard corpus for this task. Even if
a direct comparison of these results is difficult, they
suggest that 52% F-score in complex event extrac-
tion is a non-trivial achievement, especially consid-
ering the more detailed semantics of the extracted
events. Further, complex event extraction is still a
new problem ? relevant corpora having been avail-
able for only a few years.
Acknowledgments
This research was funded by the Academy of Fin-
land. Computational resources were provided by
CSC ? IT Center for Science Ltd. We thank the
shared task organizers for their efforts in data prepa-
ration and system evaluation.
17
References
Antti Airola, Sampo Pyysalo, Jari Bjo?rne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
All-paths graph kernel for protein-protein interaction
extraction with evaluation of cross-corpus learning.
BMC Bioinformatics, 9(Suppl 11):S2.
Yasemin Altun, Ioannis Tsochantaridis, and Thomas
Hofmann. 2003. Hidden Markov support vector ma-
chines. In Proceedings of the Twentieth International
Conference on Machine Learning (ICML?03), pages
3?10. AAAI Press.
Jari Bjo?rne, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. How complex are complex
protein-protein interactions? In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 125?128. TUCS.
Jari Bjo?rne, Filip Ginter, Juho Heimonen, Sampo
Pyysalo, and Tapio Salakoski. 2009. Learning to ex-
tract biological event and relation graphs. In Proceed-
ings of the 17th Nordic Conference on Computational
Linguistics (NODALIDA?09).
Ekaterina Buyko, Elena Beisswanger, and Udo Hahn.
2008. Testing different ACE-style feature sets for
the extraction of gene regulation relations from MED-
LINE abstracts. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 21?28. TUCS.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL?05),
pages 173?180. ACL.
Koby Crammer and Yoram Singer. 2002. On the al-
gorithmic implementation of multiclass kernel-based
vector machines. Journal of Machine Learning Re-
search, 2:265?292.
Marie-Catherine de Marneffe and Christopher Manning.
2008. Stanford typed hierarchies representation. In
Proceedings of the COLING?08 Workshop on Cross-
Framework and Cross-Domain Parser Evaluation,
pages 1?8.
Juho Heimonen, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. Complex-to-pairwise mapping of
biological relationships using a semantic network rep-
resentation. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 45?52. TUCS.
Sophia Katrenko and Pieter Adriaans. 2008. A local
alignment kernel in the context of NLP. In Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics (Coling?08).
Jin-Dong Kim, Tomoko Ohta, and Tsujii Jun?ichi. 2008a.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(1):10.
Seonho Kim, Juntae Yoon, and Jihoon Yang. 2008b.
Kernel approaches for genic interaction extraction.
Bioinformatics, 24(1):118?126.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 shared task on event extraction. In
Proceedings of the NAACL-HLT 2009 Workshop
on Natural Language Processing in Biomedicine
(BioNLP?09). ACL.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning (ICML?01), pages 282?289.
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In Proceedings of
ACL-08: HLT, Short Papers, pages 101?104. Associa-
tion for Computational Linguistics.
Makoto Miwa, Rune S?tre, Yusuke Miyao, Tomoko
Ohta, and Jun?ichi Tsujii. 2008. Combining
multiple layers of syntactic information for protein-
protein interaction extraction. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 101?108. TUCS.
Martin F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(1):50.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the Twenty-first Inter-
national Conference on Machine Learning (ICML?04),
pages 104?111. ACM.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2008. Extracting protein-
protein interactions from text using rich feature vec-
tors and feature selection. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM?08), pages 77?84. TUCS.
18
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 108?116,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Reconstruction of semantic relationships from their projections in
biomolecular domain
Juho Heimonen, Jari Bjo?rne, and Tapio Salakoski
University of Turku
Turku Centre for Computer Science and
Department of Information Technology
Joukahaisenkatu 3?5
20520 Turku, Finland
first.last@utu.fi
Abstract
The extraction of nested, semantically rich
relationships of biological entities has re-
cently gained popularity in the biomed-
ical text mining community. To move
toward this objective, a method is pro-
posed for reconstructing original seman-
tic relationship graphs from projections,
where each node and edge is mapped to
the representative of its equivalence class,
by determining the relationship argument
combinations that represent real relation-
ships. It generalises the limited postpro-
cessing step of the method of Bjo?rne et al
(2010) and hence extends this extraction
method to arbitrarily deep relationships
with unrestricted primary argument com-
binations. The viability of the method is
shown by successfully extracting nested
relationships in BioInfer and the corpus
of the BioNLP?09 Shared Task on Event
Extraction. The reported results, to the
best of our knowledge, are the first for the
nested relationships in BioInfer on a task
in which only named entities are given.
1 Introduction
A recent shared task in biomedical text mining,
the BioNLP?09 Shared Task on Event Extrac-
tion (Kim et al, 2009), showed that the biomed-
ical natural language processing (BioNLP) com-
munity is greatly interested in heading towards
the extraction of deep, semantically rich relation-
ships. The shared task focused on biomolecu-
lar events involving proteins and called for meth-
ods that are capable of identifying nested struc-
tures. Biomolecular events are a major cate-
gory of relationships in the biomedical domain in
which, among others, relationships involving non-
molecular entities such as diseases and static rela-
tions such as protein family memberships are also
of interest.
Earlier, well-studied extraction tasks typically
cast the problem in such a manner that relation-
ships can be considered as mutually independent
atomic units. However, as a nested semantic struc-
ture grows in its depth and in the total number
of relationship arguments, its simultaneous extrac-
tion becomes difficult, if not impossible. Systems
that bypass this problem by identifying atomic
units of nested structures in a mutually indepen-
dent manner must still decide which of the units
collectively comprise a complete structure.
Another problem arises from the fact that a sin-
gle syntactic token can refer to several, distinct re-
lationships each having a unique combination of
arguments. This is typically induced by coordi-
nations which are common in the biomedical do-
main (Pyysalo et al, 2007). As a result, aside
from the identification and classification of rela-
tionships and their potential arguments, extraction
systems have to make decisions about how many
relationships should be generated and how the ar-
guments should be distributed among them. For
example, the sentence ?the binding of A and B to
DNA regulates C and D, respectively? states that
there are two binding events (A?DNA and B?DNA)
the former of which regulates C and the latter D in-
stead of, for example, that both binding events reg-
ulate both C and D or that there is a single binding
event between A, B, and DNA.
This paper focuses on addressing the afore-
mentioned problems in the case of the extrac-
tion method developed by Bjo?rne et al (2010) for
the BioNLP?09 Shared Task and generalises this
method. Bjo?rne et al showed that deep depen-
108
NNP VBZ NNP CC .
conj_and>dobj><nsubj
Protein
Pp60
Phosphorylation
phosphorylates
Protein
CapG
Protein
profilin.
<Cause Theme>
Theme><Cause
pa
rse
A
dobj>
and
NNP
Phosphorylation
Protein
Pp60
Phosphorylation
phosphorylates
Protein
CapG
Protein
profilin.
<Cause Theme>
Theme>
and
B
C
Figure 1: A one-node-per-token constrained graph
(projected, B) cannot express the two distinct
phosphorylation events while an unrestricted se-
mantic graph (deprojected, A) can. A parse in the
SD scheme is illustrated in C.
dency analyses in the well-established Stanford
Dependency (SD) scheme (de Marneffe and Man-
ning, 2008) can successfully be utilised in extract-
ing graphs that express semantic entities as nodes
and relationship arguments as edges but are lim-
ited to one node per syntactic token. Nodes and
edges can be extracted in a mutually independent
manner but the resulting graph cannot necessarily
express all the real relationships. Rather, the graph
can be seen as a projection of the original graph:
each node and edge has been mapped to the rep-
resentative of its equivalence class which is deter-
mined by the node and edge types and the referred
tokens.
The research question of this paper is can the
original semantic graphs be reconstructed from
projected graphs with an independent step in an
information extraction (IE) process? The objec-
tive of deprojection is illustrated as a transforma-
tion of the graph B to the graph A in Figure 1.
To answer the question, the problem of re-
constructing complex, nested semantic structures
from their projections is formulated and a generic
deprojection method is proposed. The method
specifically addresses primary arguments, as de-
fined by the BioNLP?09 Shared Task, while leav-
ing the extension to secondary arguments as a fu-
ture work. The viability of the method is anal-
ysed with BioInfer (Pyysalo et al, 2007) and the
BioNLP?09 Shared Task corpus, both of which
containing nested structures, through an IE task
essentially identical to the BioNLP?09 Shared
Task. It is concluded that the proposed method
Figure 2: The deprojection process.
can successfully augment the method of Bjo?rne
et al (2010) and generalise it to arbitrary graphs
of nested biomolecular relationships without the
strict restrictions of the BioNLP?09 Shared Task
while retaining its performance level. Thus, the
method can improve IE systems that produce rela-
tionships on the one-per-token basis.
2 Method
The proposed approach to deproject semantic
graphs is outlined in Figure 2. In summary, the
first transformation (grouping) alters a projected
graph such that a minimal set of classes is suf-
ficient to describe the behaviour of the nodes
and the edges. Guided by predicted class labels,
the second transformation (deprojection) then pro-
duces a deprojected graph. In the presented
method, the classification problem is solved with
machine-learning (ML) methods. Finally, corpus-
specific constraints are enforced.
2.1 Definitions
The graph representation of semantic annotation
introduced by Heimonen et al (2008) is adopted
with some additional definitions. Semantic knowl-
edge is represented as a directed acyclic graph
(DAG) as follows.
Nodes and edges correspond to semantic en-
tities (such as protein and processes) and rela-
tionship arguments, respectively. The equality of
nodes is determined by the equality of their types
and of their references to text. Similarly, the equal-
ity of edges arises from the equality of their types
and of their end nodes.
Shallow and deep relationships consist of a
node, its outgoing edges, and its direct successors.
The latter also recursively include the successor
relationships. Nodes are equal as shallow relation-
ships if they as well as their outgoing edges are
109
equal. Node equality as a deep relationship im-
poses the further requirement that the successors
are equal as deep relationships.
A valid relationship is one which is valid in
the given corpus-specific annotation scheme. Es-
pecially, it has a valid combination of arguments.
A deprojected graph (see Figure 1A) is one
in which each node represents a valid, real rela-
tionship. Several equal nodes can exist provided
they have unique combinations of outgoing edges.
Note that there is one-to-one correspondence be-
tween nodes and real relationships but many-to-
one between nodes and syntactic tokens.
A projected graph (see Figure 1B) is one
generated by mapping each node and edge of a de-
projected graph to the representative of its equiv-
alence class. That is, each node represents a set
of equal nodes of the deprojected graph, and simi-
larly for edges. As a result, each token is referred
to by at most one node1 and there is a one-to-many
correspondence between nodes and valid, real re-
lationships. Also, the edges that are mapped to
from the outgoing edges of equal nodes of the de-
projected graph are the outgoing edges of a single
node of the projected graph.
The deprojection of a semantic graph is the
task of reproducing the original graph given a pro-
jected graph. This can also be seen as a task of
finding the sets of outgoing edges that represent
all the valid, real relationships.
2.2 Grouping
The objective of the first transformation is accom-
plished with a grouping algorithm: the direct suc-
cessors of each node are grouped by their syntac-
tic and semantic roles relative to the predecessor.
The groups are represented as additional nodes
in the graph. The rationale for this grouping is
that similar arguments tend to either be mutually
exclusive (and be associated with some other ar-
guments) or together form a single relationship.
This behaviour can easily be described with two
classes: distributive and collective. For example,
in the sentence ?A and B regulate C?, the entities A
and B share both the argument type (agent) and the
syntactic role (subject) relative to the relationship
regulate. They form a group and are mutually ex-
clusive (distributive) while this group forms a sin-
gle relationship (collective) together with C. As a
1given that, in the deprojected graph, a token can be re-
ferred to by multiple nodes only if they are of the same type
result, A?C and B?C pairs of regulation are gener-
ated. This approach relates to the collectivity and
distributivity of plurals which have been studied,
among others, by Scha and Stallard (1988) and
Brisson (2003).
Technically, the grouping is a series of trans-
formations in each of which a set of successors
is replaced with a single, newly-created succes-
sor and the original successors become the succes-
sors of this node. The successors are first trivially
grouped by the corresponding edge type. Finally,
they are recursively grouped by syntactic similar-
ity until they form a single group or multiple sin-
gleton groups. As a result, nested groups are gen-
erated.
The groups by syntax are determined by first
mapping both the predecessor and the successors
into the referred tokens in the syntactic graph.
Then, the tokens referred to by the predecessor
are removed if they are not also referred to by
any of the successors. This removal step is recur-
sively applied to the predecessors of the removed
tokens. As a result, the syntactic graph is decom-
posed into several connected components, each of
which representing a group. Thus, two successors
are grouped if their referred tokens belong to the
same connected component.
2.3 Deprojection
The second transformation is guided by node class
labels (Figure 3). A collective node remains un-
changed: its successors are kept together. In con-
trast, a distributive node is duplicated for each out-
going edge and the edges are distributed, one edge
per duplicate. These node classes are enough to
solve most of the cases in the analysed data sets.
However, especially in BioInfer, this is not suf-
ficient since the duplicates of a distributive node
may themselves be either collective or distributive
under their predecessor.
To adequately describe the behaviour of the du-
plicates generated by a single distributive node,
the incoming edges of each distributive node are
classified as collective or distributive (Figure 4).
The duplication of a node also duplicates its in-
coming edges which are then processed by the as-
signed class labels as follows. In the case of a col-
lective edge, the generated duplicates of the edge
share the predecessor and are thus arguments in
a single relationship. In contrast, a distributive
edge induces the duplication of the predecessor re-
110
Figure 3: The effect of assigning collective or dis-
tributive class labels (marked as <?>) to a node in
the deprojection process.
Figure 4: Correct node and edge class labels for
the projected graph of the phrase ?Coexpression
and subsequent DNA-binding of X and Y pro-
teins? (A) and the resulting deprojected graph (B).
lationships such that, as a result, the generated du-
plicate edges do not share any predecessors.
In Figure 4A, the node proteins is distributive
because it represents two distinct nodes: one per-
taining to X, another to Y. These two nodes are
involved in the same coexpression relationship but
in different binding relationships. Hence the in-
coming edges of the node proteins are collective
and distributive, respectively.
Since the two transformation steps do not en-
force corpus-specific constraints, a trivial algo-
rithm is utilised to decompose relationships with
invalid argument combinations into multiple valid
relationships. In an ideal situation, this step makes
no transformations. This is also used as a part of
the baseline method (see Section 3.3).
2.4 Machine-learning and features
For node and edge classifications, the C4.5 deci-
sion tree (Quinlan, 1993), and its J48 implemen-
tation in the Weka package, was utilised because
its models can easily be examined. This facili-
tates the analysis of the problem and the further
development of the solution. The default parame-
ters were used since no improvement was gained
with alternative parameters in preliminary experi-
ments. The applied feature set emphasises higher-
level features obtained from the semantic and syn-
tactic graphs. It consists of three main groups: se-
mantic, syntactic, and morphological.
Semantic features contain information gath-
ered from the semantic graph as well as from the
type hierarchies. For nodes, these features consists
of the node type as well as the presence, count and
combination of outgoing edge types. The count of
successor groups and the distance to the first non-
group predecessor are also included. For edges,
the node features are generated for both the suc-
cessor and the predecessor in addition to the type
of the edge.
Syntactic features include the minimum syn-
tactic distance2 from the predecessor to the suc-
cessors as well as between the successors. Also,
in the case of the unit distance, the corresponding
dependency type is included.
Morphological features consist of the Porter
stems (Porter, 1980) and the part-of-speech tags of
the referred tokens as well as the presence and the
Porter stems of the tokens that are shared between
the successors.
All features are also generated from the first
non-group predecessor (which may be the node it-
self) to capture the original relationship node when
processing a group node. The majority of the fea-
tures are Boolean-valued in order to allow several
values of a single property. This is utilised in fea-
tures representing hierarchical knowledge (such as
node and dependency types) as well as stem fea-
tures. For example, a node receives true for the
node type feature of its actual type as well as of its
supertypes in the hierarchy.
3 Resources and experiments
An array of experiments was performed to anal-
yse the deprojection problem and the proposed
solution. Firstly, the same experiments were
performed on two corpora, BioInfer and the
BioNLP?09 Shared Task corpus in order to eval-
uate the effect of the annotation scheme to the
properties of the problem. Secondly, the deprojec-
tion algorithm was applied to both projected gold-
standard graphs and to predicted graphs in order to
study the effect of the accuracy of the input graph.
Thirdly, the effect of the quality of the parse was
2semantic nodes mapped into the referred tokens
111
examined by employing various parses including
the BioInfer gold-standard annotation.
3.1 Data
BioInfer is a corpus of 1100 sentences selected
from 836 publication abstracts available through
PubMed. For this paper, the abstracts were ran-
domly sampled in the ratio 2:1:1 into the train-
ing, development, and test sets. In contrast, the
BioNLP?09 Shared Task corpus consists of the
training, development, and test sets of 800, 150,
and 260 abstracts, respectively. Since the anno-
tation of the test set is not publicly available and
the evaluation server does not provide the required
details for the analysis, the development set was
used as the test set and a random sample of 150
abstracts was cut from the training set to form the
development set.
In this study, the task 1 annotation with the pro-
tein equivalence relations removed was used as the
BioNLP?09 Shared Task data set. In this anno-
tation, relationships are positively asserted, have
only Theme and Cause arguments and are anno-
tated only for one of the equivalent proteins. Fur-
thermore, each node refers to at least one token
in the syntactic graph. The BioInfer semantic an-
notation was transformed into a similar form by
removing negation (NOT), equivalence (EQUAL),
and reference nodes (COREFER, REL-ENT). Fur-
thermore, to create a fully text-bound subset, fam-
ily memberships relations (MEMBER) were re-
solved into single edges and suitable references to
text were added for the remaining unbound nodes
when possible. In an extreme case, an unbound
relationship was discarded. As a result, the differ-
ences to the BioNLP?09 Shared Task data set were
minimised to additional node and edge types re-
flecting the wider selection of primary arguments.
All employed parses follow the SD scheme.
BioInfer contains uncollapsed gold-standard
parses while the BioNLP?09 Shared Task corpus
includes parses, in the collapsed representation,
generated by the parser of Charniak and Johnson
(2005) using the model of McClosky and Char-
niak (2008). For both corpora, additional parses
were produced with the improved version of the
aforementioned system created by McClosky
(2009). These parses were transformed into
both the collapsed and the conjunct dependency
propagated representations with the tools pro-
vided by de Marneffe et al (2006). All parses
were further augmented by splitting tokens at
non-alphanumeric characters that border named
entities and connecting the newly-created tokens
with dependencies denoting the character.
3.1.1 Predicted graphs
The predicted semantic graphs were obtained as
a result of an extraction task adopted from the
BioNLP?09 Shared Task. In this task, named en-
tities are given as gold-standard annotation and
their relationships are to be extracted by identify-
ing text spans, determining types, and assigning
arguments.
The predicted graphs were produced with the
system developed for the BioNLP?09 Shared Task
by Bjo?rne et al (2010). The system has two
machine-learning steps. First, relationship nodes
are predicted, one per token, based only on the
syntax and the given named entity nodes. Next,
outgoing edges are predicted for the relationship
nodes. As a result, a projected graph is obtained.
With the graph representation, the system can
transparently be trained for both the BioNLP?09
Shared Task corpus and BioInfer regardless of the
differences in their annotation schemes.
The two prediction steps utilise the
SVMmulticlass implementation of a multi-
class support vector machine (Crammer and
Singer, 2002; Tsochantaridis et al, 2004). In this
study, the steps were independently optimised
for model parameters and, in contrast to the
original training procedure, the recall boosting
optimisation was omitted due to limited resources
available. When training the edge prediction, the
gold-standard relationship nodes were used.
In the graph prediction, the conjunct depen-
dency propagated parses produced with the parser
of McClosky (2009) were systematically applied.
3.2 Experiments
Original gold-standard graphs were used in gen-
erating decision tree models as well as subjected
to projection. Predicted graphs and the projected
gold-standard graphs were deprojected with the
models. The evaluation of the deprojected graphs
was performed against the original graphs.
During the system development, the training
and development sets were available and the data
were thoroughly analysed. The progress was esti-
mated by training the system with the former and
testing against the latter. The final results were
obtained on the test sets by applying the system
112
trained on the combined training?development set.
For analysis, also the baseline method and the
method of Bjo?rne et al (2010) were evaluated on
the test sets.
3.3 Baselines
The baselines were designed to reflect an IE sys-
tem following the one-node-per-token principle
without an advanced postprocessing but still en-
forcing the annotation scheme constraints.
With the strict specifications of the BioNLP?09
Shared Task, a sound baseline is obtained sim-
ply by enforcing the constraints through a minimal
set of changes. Nodes with outgoing Cause and
Theme edges are duplicated into all Cause?Theme
pairs. Binding nodes remain unchanged since they
can have several Theme arguments while the oth-
ers are treated as distributive nodes with distribu-
tive incoming edges.
Although BioInfer is less restricted with respect
to valid argument combinations, a feasible base-
line can be obtained by adapting the BioNLP?09
Shared Task baseline algorithm. Cause?Theme is
replaced with agent?patient while Binding is ex-
tended to symmetric relationships (i.e. participant
arguments). In addition, relationships with sub
arguments are treated as collective which reflects
multiple components in a single complex. These
changes were also applied to the method of Bjo?rne
et al (2010) when analysing BioInfer.
3.4 Evaluation
The standard precision?recall?F1 metrics was
used in the evaluation. True/false positive/negative
instances were determined by the equality of the
nodes as relationships: pairs of equal nodes were
true positives while unique nodes in the depro-
jected and the original graph were false positives
and false negatives, respectively.
The equality of references to text was deter-
mined after removing the tokens found in a non-
exhaustive list of common stop-words including
prepositions, articles, and non-alphanumeric char-
acters. This relaxes an unnecessary requirement of
the node prediction step to find also those tokens
in the BioInfer annotation that do not contribute to
the semantics of the nodes. For example, preposi-
tions should be associated with edges rather than
nodes.
The F1-scores were further analysed with the
Wilcoxon signed-rank test (Wilcoxon, 1945), as
implemented in Scipy v. 0.7.0, by considering
BioInfer
gold predicted
method total symm. total symm.
baseline 88.26 63.62 29.38 18.64
Bjo?rne et al 89.15 72.35 29.14 20.37
proposed 92.42 78.79 30.79 24.47
BioNLP?09
gold predicted
method total symm. total symm.
baseline 92.52 64.15 43.70 21.05
Bjo?rne et al 94.51 83.37 45.13 35.21
proposed 95.08 84.32 45.32 36.63
Table 1: The F1-scores on the test sets. Total
is cumulative over all nodes with outgoing edges
while symm. refers to the symmetric types. Gold
and predicted refer to the experiments with gold-
standard and predicted graphs, respectively.
each document as an experiment and using the
95% confidence level.
4 Results and discussion
The following discussion focuses on the deep re-
lationship equality as the evaluation criterion be-
cause it reflects the relationships of interest by re-
quiring the identification of the pertaining named
entities. Also, the discussion only considers the
experiments performed with the conjunct depen-
dency propagated parses obtained with the parser
of McClosky (2009) because switching parses did
not produce statistically significant differences in
performance. Note that the results are not compa-
rable to those of Bjo?rne et al (2010) because the
graph prediction was not fully optimised.
With respect to the deprojection task, BioInfer
was found to be similar to the BioNLP?09 Shared
Task corpus: it contains symmetric relationships
(c.f. Binding), asymmetric relationships (c.f. Reg-
ulation), and single-argument relationships. Only
the symmetric relationships are a challenge in the
deprojection task because they can have an arbi-
trary number of arguments. In contrast, the base-
line F1-scores for the others are above 94% on the
gold-standard graphs.
Table 1 shows the F1-scores on the test sets
of BioInfer and the BioNLP?09 Shared Task cor-
pus for the overall performance as well as for
the symmetric relationships only. The proposed
method outperforms the two other methods in all
113
experiments and the ?F1 against the proposed
method are statistically significant with the ex-
ception of the method of Bjo?rne et al (2010) on
the BioNLP?09 Shared Task corpus. Although
not conclusively better than the earlier, specialised
method in its own task, the proposed method
successfully achieves the intended generalisation
without an adverse effect.
The observed improvement over the method of
Bjo?rne et al (2010) is likely due to two factors.
First, using machine-learning rather than a sim-
ple rule-based system allows for more accurate
modelling of the problem. Second, the proposed
method can handle a wider variety of cases due to
the classification of edges. For example, the graph
in Figure 4A can correctly be deprojected, which
is not possible for the earlier method. However,
the latter factor is only effective on BioInfer, the
more complex of the two corpora, which is con-
sistent with the observed statistical significances.
The proposed deprojection method is currently
limited to the phenomena encountered in the two
analysed corpora since the decision to use binary
classification was based on the experimental ob-
servation that neither class is appropriate only in
rare cases. More classes will be needed to further
generalise and improve the system. One such class
could be respective which denotes a selective pair-
ing of sibling nodes. For example, the sentence
?A and B binds C and D, respectively? currently
results in false positive pairs A?D and B?C. Sim-
ilarly, adding secondary arguments (e.g. location)
and relationship modifiers (e.g. negation) into con-
sideration is likely to necessitate new, more com-
plex transformations and their respective classes.
Also, to filter out incorrectly predicted edges will
require the introduction of additional classes. The
critical question is whether a reasonably small set
of classes with extensive enough a coverage can
be found.
Another limitation is that the approach expects
an annotation scheme in which relationship argu-
ments have the tendency of following syntactic
dependencies as observed for BioInfer by Bjo?rne
et al (2008). This expectation may deteriorate the
performance on highly refined schemes which do
not consider syntax. On the other hand, since it
relies more on the syntactic than on the biolog-
ical properties of the relationships, the proposed
approach should be applicable beyond the domain
of biomolecular events (e.g. to gene?disease rela-
tionships or static relations).
The F1-scores in Table 1 indicate that the
BioNLP?09 Shared Task corpus is easier to ex-
tract than BioInfer. This is likely due to the nar-
rower scope and the stricter constraints of the
former. In absolute terms, the proposed method
yields the largest improvement over the baseline
on the gold-standard graphs which suggests that
it is negatively affected by the presence of false
nodes/edges or that the predicted graphs contain
relatively more relationships that are trivially de-
projected. On the other hand, in relative terms, the
largest improvements are observed for symmetric
relationships in the BioNLP?09 Shared Task cor-
pus but overall in BioInfer. This is likely due to the
differences in the relationship type distributions.
The system recently developed by Miwa et al
(2010), based on the architecture of Bjo?rne et al
(2010), utilises a ML-based deprojection which
enumerates all possible argument combinations
and classifies them as positive or negative. While
this approach may be prohibitively expensive in
more complex schemes in which the number of
arguments and their types is higher, it should out-
perform the proposed method on the BioNLP?09
Shared Task corpus. Since Miwa et al do not
analyse the contribution of the deprojection to the
overall performance, a direct comparison of the
two methods is impossible. In any case, the sys-
tems of Bjo?rne et al (2010) and Miwa et al (2010)
demonstrate the success of the architecture using
deprojection and further motivate the investigation
of deprojection methods.
4.1 Future directions
In the future, the proposed method will be stud-
ied and further improved with two other corpora,
GENIA Event Annotation (Kim et al, 2008) and
Gene Regulation Event Corpus (Thompson et al,
2009), which are similar in their purpose com-
pared to the already-analysed corpora. The former
corpus is interesting because of the co-operativity
of event participants which relaxes the restrictions
on asymmetric relationships while the latter con-
tains an extensive annotation for non-primary ar-
guments. The method could also be examined
with the static relation extraction task recently in-
troduced by Pyysalo et al (2009).
In addition to improving the method and ex-
tending it to non-primary arguments, embedding
114
the presented approach to a joint inference system,
such as Markov Logic Network (MLN), will be
studied. Deprojection is likely to greatly benefit
methods based on Markov Logic which is ?not yet
able to deal with cases where the number and iden-
tity of entities is unknown, while relations/links
between known objects can be readily modelled?
(Riedel et al, 2009). The objective is to combine
the graph prediction and the deprojection steps
as well as to simultaneously enforce task-specific
constraints and adapt to the presence of false pos-
itive nodes and edges. This should be achiev-
able by extending the methods developed for the
BioNLP?09 Shared Task corpus by Riedel et al
(2009) or by Poon and Vanderwende (2010), both
of which determine the correct argument combi-
nations outside of the Markov Logic framework.
Semantic role labelling (SRL) is a task simi-
lar to the graph-based relationship extraction ap-
plied in this paper although the former typically
only concerns shallow predicate?argument struc-
tures (Hacioglu, 2004; Surdeanu et al, 2008). The
similarities between the tasks suggest that explor-
ing them jointly may benefit the development of
information extraction methods.
In the long term, semantic schemes should be
developed such that, ideally, all syntactic tokens
are considered for their semantics and semantic
relationships readily follow from their dependen-
cies. Such schemes, closely following the syn-
tax, could improve both the graph prediction and
the deprojection. In this research direction, graph-
based knowledge representations such as concep-
tual graphs (Sowa, 1976; Chein and Mugnier,
2008) or graphical logical forms such as the one
proposed by Allen et al (2008) could be adopted.
Given the frequency of coordinations in the
biomedical domain, deprojection may prove to
be useful in the development of deep semantic
parsing in the biomedical domain. For example,
with improved semantic schemes, it could provide
a means to generate complete, detailed semantic
graphs directly from deep dependency analyses in
a single-step by applying joint inference to achieve
simultaneous node/edge relabelling and graph de-
projection.
5 Conclusions
This study presents a method for reconstructing
the original semantic graphs from their projections
by determining the correct combinations of rela-
tionship arguments. It generalises the postprocess-
ing step of the system described by Bjo?rne et al
(2010) and extends the extraction capability of this
system to arbitrary graphs of nested biomolecular
relationships. The evaluation of the method on
BioInfer and the BioNLP?09 Shared Task corpus
indicates that the approach is viable for primary
relationship arguments. For BioInfer, the outcome
is, to the best of our knowledge, the first reported
result of the task of extracting the nested relation-
ships in its original version.
The presented method facilitates an IE approach
in which the identification of semantic entities is
performed on the one-entity-per-token basis and
relationship arguments are identified in a mutu-
ally independent manner disregarding the seman-
tics of the argument combinations. The method
handles the selection of the correct argument com-
binations, which is non-trivial particularly when
coordinations are involved, and generates the final
output in which a single token can refer to several
entities. This approach improves the utilisation of
deep dependency analyses by simplifying the cor-
relation between them and semantic graphs. Due
to its independent nature, the method can be cou-
pled to any system identifying relationships on the
one-per-token basis.
The implemented system will be available upon
request.
Acknowledgements
Thanks to Filip Ginter for his help with the
parses. This study was funded by Academy of Fin-
land. Computational resources were provided by
CSC ? IT Center for Science.
References
J. Allen, M. Swift, and W. de Beaumont. 2008. Deep
semantic analysis of text. In Proceedings of the
2008 Conference on Semantics in Text Processing
(STEP?08), pages 343?354.
J. Bjo?rne, S. Pyysalo, F. Ginter, and T. Salakoski. 2008.
How complex are complex protein-protein interac-
tions? In Proceedings of the Third International
Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 125?128.
J. Bjo?rne, J. Heimonen, F. Ginter, A. Airola,
T. Pahikkala, and T. Salakoski. 2010. Extract-
ing contextualized complex biological events with
rich graph-based feature sets. Computational Intel-
ligence. To appear.
115
C. Brisson. 2003. Plurals, all, and the nonuniformity
of collective predication. Linguistics and Philoso-
phy, 26:129?184.
E. Charniak and M. Johnson. 2005. Coarse-to-fine
n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics
(ACL?05), pages 173?180.
M. Chein and M.-L. Mugnier. 2008. Graph-based
Knowledge Representation: Computational Foun-
dations of Conceptual Graphs. Springer Publishing
Company Inc.
K. Crammer and Y. Singer. 2002. On the algorith-
mic implementation of multiclass kernel-based vec-
tor machines. Journal of Machine Learning Re-
search, 2:265?292.
M.-C. de Marneffe and C. Manning. 2008. The
stanford typed dependencies representation. In
Proceedings of the Coling?08 Workshop on Cross-
Framework and Cross-Domain Parser Evaluation,
pages 1?8.
M.-C. de Marneffe, B. MacCartney, and C. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proceedings of the Fifth
International Conference on Language Resources
and Evaluation (LREC?06), pages 449?454.
K. Hacioglu. 2004. Semantic role labeling using de-
pendency trees. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics
(COLING?04), pages 1273?1276.
J. Heimonen, S. Pyysalo, F. Ginter, and T. Salakoski.
2008. Complex-to-pairwise mapping of biologi-
cal relationships using a semantic network represen-
tation. In Proceedings of the Third International
Symposium on Semantic Mining in Biomedicine
(SMBM?08), pages 45?52.
J.-D. Kim, T. Ohta, and J. Tsujii. 2008. Corpus anno-
tation for mining biomedical events from literature.
BMC Bioinformatics, 9:10.
J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsu-
jii. 2009. Overview of bionlp?09 shared task on
event extraction. In Proceedings of the NAACL?
HLT?09 Workshop on BioNLP: Companion Volume
for Shared Task (BioNLP?09), pages 1?9.
D. McClosky and E. Charniak. 2008. Self-training for
biomedical parsing. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, Short
Papers (ACL?08: HLT), pages 101?104.
D. McClosky. 2009. Any Domain Parsing: Au-
tomatic Domain Adaptation for Natural Language
Parsing. Ph.D. thesis, Department of Computer Sci-
ence, Brown University, Providence, Rhode Island,
USA.
M. Miwa, R. Saetre, J.-D. Kim, and J. Tsujii. 2010.
Event extraction with complex event classification
using rich features. Journal of Bioinformatics and
Computational Biology, 8:131?146.
H. Poon and L. Vanderwende. 2010. Joint inference
for knowledge extraction from biomedical literature.
In Proceedings of Human Language Technologies:
The 11th Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL?HLT?10).
M. Porter. 1980. An algorithm for suffix stripping.
Program, 14:130?137.
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjo?rne,
J. Boberg, J. Ja?rvinen, and T. Salakoski. 2007.
BioInfer: a corpus for information extraction in the
biomedical domain. BMC Bioinformatics, 8:50.
S. Pyysalo, T. Ohta, J.-D. Kim, and J. Tsujii.
2009. Static relations: a piece in the biomed-
ical information extraction puzzle. In Proceed-
ings of the NAACL?HLT?09 Workshop on BioNLP
(BioNLP?09), pages 1?9.
J. Quinlan. 1993. C4.5: programs for machine learn-
ing. Morgan Kaufmann Publishers Inc.
S. Riedel, H.-W. Chun, T. Takagi, and J. Tsujii.
2009. A markov logic approach to bio-molecular
event extraction. In Proceedings of the NAACL?
HLT?09 Workshop on BioNLP: Companion Volume
for Shared Task (BioNLP?09), pages 41?49.
R. Scha and D. Stallard. 1988. Multi-level plurals
and distributivity. In Proceedings of the 26th An-
nual Meeting of the Association for Computational
Linguistics (ACL?88), pages 17?24.
J. Sowa. 1976. Conceptual graphs for a data base in-
terface. IBM Journal of Research and Development,
20:336?357.
M. Surdeanu, R. Johansson, A. Meyers, L. Ma`rquez,
and J. Nivre. 2008. The CoNLL 2008 shared
task on joint parsing of syntactic and semantic de-
pendencies. In Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning
(CoNLL?08), pages 159?177.
P. Thompson, S. Iqbal, J. McNaught, and S. Anani-
adou. 2009. Construction of an annotated corpus
to support biomedical information extraction. BMC
Bioinformatics, 10:349.
I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Al-
tun. 2004. Support vector machine learning for in-
terdependent and structured output spaces. In Pro-
ceedings of the 21st International Machine Learning
Conference (ICML?04), page 104.
F. Wilcoxon. 1945. Individual comparisons by ranking
methods. Biometrics Bulletin, 1:80?83.
116
