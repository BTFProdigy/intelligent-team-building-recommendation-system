Proceedings of the The 1st Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 21?28,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
Events are Not Simple: Identity, Non-Identity, and Quasi-Identity   Eduard Hovy Language Technology Institute Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA hovy@cmu.edu  
Teruko Mitamura Language Technology Institute Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA teruko@cs.cmu.edu  
Felisa Verdejo E.T.S.I. Inform?tica, UNED C/ Juan del Rosal, 16 (Ciudad Universitaria) 28040 Madrid, Spain felisa@lsi.uned.es                  Jun Araki Andrew Philpot                   Language Technology Institute Information Sciences Institute                   Carnegie Mellon University University of Southern California                 5000 Forbes Avenue                  Pittsburgh, PA 15213, USA 4676 Admiralty Way Marina del Rey, CA 90292, USA        junaraki@cs.cmu.edu philpot@isi.edu  Abstract1 Despite considerable theoretical and computa-tional work on coreference, deciding when two entities or events are identical is very difficult.  In a project to build corpora containing corefer-ence links between events, we have identified three levels of event identity (full, partial, and none). Event coreference annotation on two cor-pora was performed to validate the findings.    1 The Problem of Identity Last year we had HLT in Montreal, and this year we did it in Atlanta.   Does the ?did it? refer to the same conference or a different one?  The two conferences are not iden-tical, of course, but they are also not totally unre-lated?else the ?did it? would not be interpretable.   When creating text, we treat instances of entities and events as if they are fixed, well-described, and well-understood.  When we say ?that boat over there? or ?Mary?s wedding next month?, we as-sume the reader creates a mental representation of the referent, and we proceed to refer to it without further thought.   However, as has been often noted in theoretical studies of semantics, this assumption is very prob-lematic (Mill, 1872; Frege 1892; Guarino, 1999).  Entities and (even more so) events are complex composite phenomena in the world, and they un-dergo change.                                                              1 This work was supported by grants from DARPA and NSF, as well as by funding that supported Prof. M. Felisa Vedejo from UNED Madrid. 
Since nobody has complete knowledge, the au-thor?s mental image of the entity or event in ques-tion might differ from the reader?s, and from the truth.  Specifically, the properties the author as-sumes for the event or entity might not be the ones the reader assumes. This difference has deep con-sequences for the treatment of the semantic mean-ing of a text.  In particular, it fundamentally affects how one must perform coreference among entities or events.   As discussed in Section 6, events have been the focus of study in both Linguistics and NLP (Chen and Ji, 2009; Bejan and Harabagiu, 2008, 2010; Humphreys et al, 1997).  Determining when two event mentions in text corefer is, however, an un-solved problem2.  Past work in NLP has avoided some of the more complex problems by consider-ing only certain types of coreference, or by simply ignoring the major problems.  The results have been partial, or inconsistent, annotations.   In this paper we describe our approach to the problem of coreference among events.  In order to build a corpus containing event coreference links that is annotated with high enough inter-annotator agreement to be useful for machine learning, it has proven necessary to create a model of event identi-ty that is more elaborate than is usually assumed in the NLP literature, and to formulate quite specific definitions for its central concepts.                                                               2 In this work, we mean both events and states when we say ?event?.  A state refers to a fixed, or regularly changing, con-figuration of entities in the world, such as ?it is hot? or ?he is running?.  An event occurs when there is a change of state in the world, such as ?he stops running? or ?the plane took off?. 
21
 Event coreference is the problem of determin-ing when two mentions in a text refer to the ?same? event. Whether or not the event actually occurred in reality is a separate issue; a text can describe people flying around on dragons or broomsticks.  While the events might be actual occurrences, hy-pothesized or desired ones, etc., they exist in the text as Discourse Elements (DEs), and this is what we consider in this work. Each DE is referred to (explicitly or implicitly) in the text by a mention, for example ?destroy?, ?the attack?, ?that event?, or ?it?. But it is often unclear whether two mentions refer to the same DE or to closely related ones, or to something alto-gether different. The following example illustrates two principal problems of event coreference:  While Turkish troops have been fighting_E.1 a Kurdish faction in northern Iraq, two other Kurdish groups have been battling_E.2 each other. A radio station operated_E.3 by the Kurdistan Democratic Party said_E.4 the party's forces attacked_E.5 positions of the Patriotic Union of Kurdistan on Monday in the Kurdish re-gion's capital Irbil. The Voice of Iraqi Kurdistan radio, moni-tored_E.6 by the British Broadcasting Corp., said_E.7 more than 80 Patriotic Union fight-ers were killed_E.8 and at least 150 wound-ed_E.9. The fighting_E.10 was also reported_E.11 by a senior Patriotic Union official, Kusret Rasul Ali, who said_E.12 PUK forces re-pelled_E.13 a large KDP attack_E.14. ? Ali claimed_E.16 that 300 KDP fighters were killed_E.17 or wounded_E.18 and only 11 Patriotic Union members died_E.19. Problem 1: Partial event overlap.  Event E.2, ?battling each other?, refers to an ongoing series of skirmishes between two Kurdish groups, the KDP and the PUK.  Since one of these battles, where the KDP attacked positions of the PUK, is E.5, it is natural to say that E.2 and E.5 corefer.  However, E.2 clearly denotes other battles as well, and there-fore E.5 and E.2 cannot fully corefer.  In another example, event E.8 refers to the killing of a num-ber of soldiers as part of this fight E.5, and event E.9 to the wounding of others.  Both events E.8 
and E.9 constitute an intrinsic part of the attack E.5, and hence corefer to it, but are each only part of E.5, and hence neither can fully corefer to it.   Problem 2: Inconsistent reporting.  This news fragment contains two reports of the fight: E.5 and E.10.  Since E.10 describes E.5 from the perspec-tive of a senior PUK official, it should corefer to E.5.  But where the KDP?s report claims more than 80 PUK fighters killed (event E.8, part of E.5), the PUK official said that only 11 PUK members died (event E.19, part of E.10).  Without taking into account the fact that the two killing events are re-ports made by different speakers, it would not be possible to recognize them as coreferent.   Examples of partial event overlap and incon-sistent reporting are common in text, and occur as various types.  In our work, we formally recognize partial event overlap, calling it partial event identi-ty, which permits different degrees and types of event coreference.  This approach simplifies the coreference problem and highlights various inter-event relationships that facilitates grouping events into ?families? that support further analysis and combination with other NLP system components.   In this paper, we introduce the idea that there are three degrees of event identity: fully identical, qua-si-identical, and fully independent (not identical).  Full identity reflects in full coreference and quasi-identity in partial coreference.  Fully independent events are singletons.  Our claims in this paper are:  ? Events, being complex phenomena, can corefer fully (identity) or partially (quasi-identity).  ? Event coreference annotation is considera-bly clarified when partial coreference is allowed.  ? A relatively small fixed set of types of quasi-identity suffices to describe most of them.  ? Different domains and genres highlight different subsets of these quasi-identity types.   ? Different auxiliary knowledge sources and texts are relevant for different types. 2 Types of Full and Partial Identity Def: Two mentions fully corefer if their activi-ty/event/state DE is identical in all respects, as far as one can tell from their occurrence in the text.  (In particular, their agents, location, and time are identical or compatible.)  One can distinguish sev-eral types of identity, as spelled out below.  
22
Def: Two mentions partially corefer if activi-ty/event/state DE is quasi-identical: most aspects are the same, but some additional information is provided for one or the other that is not shared. There are two principal types of quasi-identity, as defined below.  Otherwise, two mentions do not corefer.  2.1 Full Identity  Mention1 is identical to mention2 iff there is no semantic (meaning) difference between them. Just one DE, and exactly the same aspects of the DE, are understood from both mentions in their con-texts. It is possible to replace the one mention with the other without any semantic change (though some small syntactic changes might be required to ensure grammaticality). Note that mention2 may contain less detail than mention1 and remain iden-tical, if it carries over information from mention1 that is understood / inherited from the context.  However, when mention2 provides more or new information not contained in mention1 or naturally inferred for it, then the two are no longer identical. Usually, exact identity is rare within a single text, but may occur more often across texts.  We identi-fy the following types:  1. Lexical identity: The two mentions use exactly the same senses of the same word(s), in-cluding derivational words (e.g., ?destroy?, ?de-struction?). 2. Synonym: One mention?s word is a syno-nym of the other?s word.  3. Wide-reading: One mention is a synonym of the wide reading of the other (defined below, under Quasi-identity:Scriptal).  For example, in ?the attack(E1) took place yesterday.  The bomb-ing(E2) killed four people?, E1 and E2 are fully coreferent only when ?bombing? is read in its wide sense that denotes the whole attack, not the narrow sense that denotes just the actual exploding of the bomb.   4. Paraphrase: One mention is a paraphrase of the other.  Here some syntactic differences may occur.  Some examples are active/passive trans-formation (?she gave him the book? / ?he was giv-en the book by her?), shifts of perspective that do not add or lose information (?he went to Boston? / ?he came to Boston?), etc.  No extra semantic in-formation is provided in one mention or the other.    
5. Pronoun: One mention refers deictically to the DE, as in (?the party? / ?that event?), (?the election [went well]? / ?it [went well]?).   2.2  Quasi-identity  Mention1 is quasi- (partially) identical to mention2 iff they refer to the ?same? DE but one mention includes information that is not contained in the other, not counting information understood/inhe-rited from the context.  They are semantically not fully identical, though the core part of the two mentions is.  One mention can replace the other, but some information will be changed, added, or lost.  (This is the typical case between possible coreferent mentions within a document.)   We distinguish between two core types of partial identity: Membership and Subevent.  The essential difference between the two is which aspects of the two events in question differ.  Member-of obtains when we have two instances of the same event that differ in some particulars, such as time and loca-tion and [some] participants (agents, patients, etc).  In contrast, Subevent obtains when we have differ-ent events that occur at more or less the same place and time with the same cast of participants.   Membership: Mention1 is a set of similar DEs (multiple instances of the same kind of event), like several birthday parties, and mention2 is one or more of them.  More precisely, we say that an event B is a member of A if: (i) A is a set of mul-tiple instances of the same type of event (and hence its mention usually pluralized); (ii) B?s DE(s) is one or more (but not all) of them; (iii) ei-ther or both the time and the place of B?s DE(s) and (some of) A?s DEs are different.  For example, in ?I attended three parties(E1) last month.  The first one(E2) was the best?, E2 is a member of E1.  The relation that links the single instance to the set is member-of.  Subevent: The DE of mention1 is a script (a ste-reotypical sequence of events, performed by an agent in pursuit of a given goal, such as eating at a restaurant, executing a bombing, running for elec-tion), and mention2 is one of the actions/events executed as part of that script (say, paying the waiter, or detonating the bomb, or making a cam-paign speech).  More precisely, we say that an event B is a subevent of an event A if: (i) A is a complex sequence of activities, mostly performed by the same (or compatible) agent; (ii) B is one of 
23
these activities; and (iii) B occurs at the same time and place as A.  Here A acts as a kind of collector event.  Often, the whole script is named by the key event of the script (for example, in ?he planned the explosion?, the ?explosion? signifies the whole script, including planning, planting the bomb, the detonation, etc.; but the actual detonation event itself can also be called ?the explosion?).  We call the interpretation of the mention that refers to the whole script its wide reading, and the interpreta-tion that refers to just the key subevent the narrow reading.  It is important not to confuse the two; a wide reading and a narrow reading of a word can-not corefer3. The relation that links the narrow reading DE to the wide one is sub-to.   Several aspects of the events in question provide key information to differentiate between members and subevents:   1. Time: When the time of occurrence of mention1 is temporally ?close enough? to the time of occurrence of mention2, then it is likely that one is a Subevent of the other.  More precisely, we say that an event B is a subevent of event A if: (i) A and B are both events; (ii) the mentions of A and B both refer to the same overall DE; and (iii) the time of occurrence of B is contained in the time of oc-currence of A. But if (i) and (ii) hold but not (iii), and A is a set of events (plural), then B is a mem-ber of A.  (In (Humphreys et al, 1997), any varia-tion in time automatically results in a decision of non-coreference.)   2. Space/location: The location of mention1 is spatially ?close enough? to the location of men-tion2.  More precisely, we say that an event B is a subevent of event A if: (i) A and B are both events; (ii) the mentions of A and B both refer to the same overall DE; and (iii) the location of oc-currence of B is contained in, or overlaps with, or abuts the location of occurrence of A.  But if (i) and (ii) hold but not (iii), and A is a set of events (plural), then B is a member of A. 
                                                            3 For example, in ?James perpetrated the shooting. He was arrested for the attack?, ?shooting? is used in its wide sense and here is coreferent with ?attack?, since it applies to a whole sequence of events.  In contrast, ?James perpetrated the shoot-ing.  He is the one who actually pulled the trigger?, ?shooting? is used in its narrow sense to mean just the single act.  Typi-cally, a word with two readings can corefer (i.e., be lexically or synonymically identical to) another in the same reading only. 
3.  Event participants: Mention1 and men-tion2 refer to the same DE but differ in the overall cast of participants involved.  In these cases, the member relation obtains, and can be differentiated into subtypes, since participants of events can dif-fer in several ways.  For example, if: (i) the men-tions of events A and B refer to the same overall DE; and (ii) the participants (agents, patients, etc.) of mention2 are a subset of the participants of mention1, as in ?the crowd demonstrated on the square. Susan and Mary were in it?, then event B is a participant-member of event A.  In another ex-ample, event B is a participant-instance-member of event A if: (i) the mentions of events A and B refer to the same overall DE; and (ii) one or more of the participants (agents, patients, etc.) of men-tion2 is/are an instance of the participants of men-tion1, as in ?a firebrand addressed the crowd on the square. Joe spoke for an hour?, where Joe is the firebrand.  There are other ways in which two mentions may refer to the same DE but differ from one an-other.  Usually these differences are not semantic but reflect an orientation or perspective difference.  For example, one mention may include the speak-er?s evaluation/opinion, while the other is neutral, as in ?He sang the silly song.  He embarrassed himself?, or the spatial orientation of the speaker, as in ?she went to New York? / ?she came to New York?.  We treat these cases as fully coreferent.   Sometimes it is very difficult to know whether two mentions are bidirectionally implied, meaning that the two must corefer, or whether they are only quasi-identical (i.e., one entails the other but not vice versa).  For example, in ?he had a heart at-tack? / ?he died?, the two mentions are not identi-cal because one can have a heart attack and not die from it. In contrast, ?he had a fatal heart attack? / ?he died from a heart attack? are identical.  In ?she was elected President? / ?she took office as Presi-dent?, it is more difficult to decide. Does being elected automatically entail taking office?  In some political systems it may, and in others it may not.  When in doubt, we treat the case as only quasi-identical.  Thus, comparing to examples from Full-Identity: Paraphrase, the following are only quasi-identical because of additional information: ?she sold the book? / ?she sold Peter the book?; ?she sold Peter the book? / ?Peter got [not bought] the book from her?. 
24
Quasi-identity has been considered in corefer-ence before in (Hasler et al, 2006) but not as ex-tensively, and in (Recasens and Hovy, 2010a; 2011) but applied only to entities.  When applied to events, the issue becomes more complex.  3 Two Problems  3.1 Domain and Reporting Events  As described above, inconsistent reporting occurs when a DE stated in reported text contains signifi-cant differences from the author?s description of the same DE.   To handle such cases we have found it necessary to additionally identify communication events, which we call Reportings, during annotation be-cause they provide a context in which a DE is stat-ed.  We identify two principal types of Reporting verbs: locutionary verbs ?say?, ?report?, ?an-nounce?, etc.) and Speech Acts (?condemn?, ?promise?, ?support?, ?blame?, etc.).  Where the former verbs signal merely a telling, the latter verbs both say and thereby do something.  For ex-ample in the following paragraph, ?admitted? and ?say? are communication events:  Memon admitted_R.7,in-sayR.3 his in-volvement in activities_E.8,in-sayR.3 in-volving an explosives-laden van near the president's motorcade, police said_R.3?.  Sometimes the same event can participate in-side two reporting events, as in   ?The LA Times lauded_R.1 the decision_E.2,in-sayR.1,in-sayR.3, which the NY Times lampooned_R.3. Though an added annotation burden, the link from a DE to a reporting event allows the analyst or learning system to discount apparent contradictory aspects of the DE and make more accurate identity decisions.     3.2 Unclear Semantics of Events  Sometimes it is difficult to determine the exact relationships between events since their semantics is unclear.  In the following, is E.45 coreferent to E.44, or only partially?  If so, how?  Amnesty International has accused both sides of violating_E.44 international humanitarian law by targeting_E.45 civilian areas, and ... 
We decided that E.44 is not fully coreferent with E.45, since violating is not the same as targeting.  Also, E.45 is not a subevent of E.44 since ?violat-ing? is not a script with a well-defined series of steps, does not trigger ?targeting?, and does not occur before ?targeting?.  Rather, targeting is a certain form or example of violation/violating. (It might be easier if the sentence were: ?... of violat-ing international humanitarian law by targeting civilian areas and the human rights group, by kill-ing civilians, and by....?.  As such E.45 could be interpreted as a member of E.44, interpreting the latter as a series of violations.)   4 Annotation  To validate these ideas we have been annotating newspaper texts within the context of a large pro-ject on automated deep reading of text. This pro-ject combines Information Extraction, parsing, and various forms of inference to analyze a small num-ber of texts and to then answer questions about them.  The inability of current text analysis engines to handle event coreference has been a stumbling block in the project.  By creating a corpus of texts annotated for coreference we are working to enable machine learning systems to learn which features are relevant for coreference and then ultimately to perform such coreference as well.  We are annotating two corpora: 1. The Intelligence Community (IC) Corpus contains texts in the Violent Events domain (bombings, killings, wars, etc.).  Given the relative scarcity of the partial coreference subtypes, we annotated only instances of full coreference, Subevent, and Member relations.  To handle Subevents one needs an unambiguous definition of the scripts in the domain.  Fortunately this domain offers a manageable set of events (our event ontol-ogy comprises approximately 50 terms) with a subevent structure that is not overly complex but still realistic.  We did not find the need to exceed three layers of scriptal granularity, as in  campaign > {bombing, attack} > {blast, kill, wound}.  2. The Biography (Bio) Corpus contains texts describing the lives of famous people. Typically, these texts are written when the person dies or has some notable achievement.  Given the complexi-ties of description of artistic and other creative achievements, we restrict our corpus to achieve-
25
ments in politics, science, sports, and other more factual endeavors.  More important than scriptal granularity in this domain is temporal sequencing.  We obtained and modified a version of the An-CoraPipe entity coreference annotation interface (Bertran et al, 2010) that was kindly given us by the AnCora team at the University of Barcelona.  We implemented criteria and an automated method for automatically identifying domain and reporting events.  We also created a tool to check and dis-play the results of annotation, and technology to deliver various agreement scores.  Using different sets of annotators (from 3 to 6 people per text), we have completed a corpus of 100 texts in the IC domain and are in process of annotating the Bio corpus. Our various types of full and partial coreference and the associated an-notation guidelines were developed and refined over the first third of these documents.   Table 1 shows statistics and inter-annotator agreement for the remaining 65 articles.  The aver-age number of domain and reporting events per article is 41.2.  We use Fleiss?s kappa since we have more than two annotators per article.  The (rather low) score for member coreference is not really reliable given the small number of instances.     Avg no per article Agreement (Fleiss?s kappa) Full coreference relations Member coreference relations Subevent coreference relations 19.5 0.620 2.7 0.213 7.2 0.467 Table 1: Annotation statistics and agreement. 5 Validation and Use To validate the conceptualization and definitions of full and partial identity relations, we report in (Araki et al, 2013) a study that determines correla-tions between the Member and Subevent relation instances and a variety of syntactic and lexico-semantic features.  The utility of these features to support automated event coreference is reported in the same paper.   We are now developing a flexible recursive pro-cedure that integrates coreference of events and of their pertinent participants (including locations and times).  This procedure employs inference in addi-tion to feature-based classification to compensate for the shortcomings of each method alone.   
6 Relevant Past Work The problem of identity has been addressed by scholars since antiquity.  In the intensional ap-proach (for example, De Saussure, 1896) a concept is defined as a set of attributes (differentiae), that serve to distinguish it from other concepts; two concepts are identical iff all their attributes and values are.  In the extensional approach (Frege, 1982) a concept can be defined as the set of all in-stances of that concept; two concepts are identical when their two extensional sets are.    Given the impossibility of either approach to support practical work, AI scholars have devoted some attention to so-called Identity Criteria.  Gua-rino (1999) outlines several ?dimensions? along which entities can remain identical or change un-der transformations; for example, a glass before and after it is crushed is identical with respect to its matter but not its shape; the ACL now and one hundred years hence is (probably) identical as an organization but not in its membership.   There has not been much theoretical work on semantic identity in the NLP community.  But there has been a considerable amount of work on the problem of coreference. Focusing on entity coreference are (McCarthy and Lehnert, 1995; Cu-lotta et al, 2007; Ng, 2007; Ng, 2009; Finkel and Manning, 2008; Ng, 2009).  Focusing on event coreference are (Humphries et al, 1997; Chen and Zi, 2009; Bejan and Harabagiu, 2008; 2010).   Anaphora and bridging reference are discussed in (Poesio and Artstein, 2005; 2007). Relevant to events is the TIME-ML corpus (Mani and Pustejovsky, 2004; Pustejovsky et al, 2003), which provides a specification notation for events and temporal expressions. Several corpora contain annotations for entity coreference, including the Prague Dependency Treebank (Ku?ov? and Haji?ov?. 2004), the ACE corpus (Walker et al, 2006), and OntoNotes (Pra-dhan et al, 2007).  Most similar to our work is that of (Hasler et al, 2006). In that study, coreferential events and their arguments (also coreference between the argu-ments) were annotated for the terrorism/security domain, considering five event categories (attack, defend, injure, die, contact), and five event clusters (Bukavu bombing, Peru hostages, Tajikistan hos-tages, Israel suicide bombing and China-Taiwan 
26
hijacking). They also annotated information about the kind of coreferential link, such as identity / synonymy / generalization / specialization / other.   Our work takes further the ideas of (Hasler et al, 2006) and (Recasens et al, 2011) in elaborating the types of full and partial identity, as they are manifest in event coreference.   7 Conclusion The problem of entity and event identity, and hence coreference, is challenging.  We provide a definition of identity and two principal types of quasi-identity, with differentiation based on differ-ences in location, time, and participants.  We hope that these ideas help to clarify the problem and im-prove inter-annotator agreement. Acknowledgments Our grateful thanks goes to Prof. Antonia Mart? and her team for their extensive work on the modi-fications of the AnCoraPipe annotation interface. References  Araki, J., T, Mitamura, and E.H. Hovy. 2013. Identity and Quasi-Identity Relations for Event Coreference. Unpublished manuscript. Bejan, C.A. and S. Harabagiu. 2008. A Linguistic Re-source for Discovering Event Structures and Resolv-ing Event Coreference. Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 08). Bejan, C.A. and S. Harabagiu. 2010. Unsupervised Event Coreference Resolution with Rich Linguistic Features. Proceedings of the 48th conference of the Association for Computational Linguistics (ACL 10). Bertran, M., O. Borrega, M.A. Mart?, and M. Taul?, 2010. AnCoraPipe: A New Tool for Corpora Annota-tion. Working paper 1: TEXT-MESS 2.0 (Text-Knowledge 2.0). Available at http://clic.ub.edu/files/AnCoraPipe_0.pdf  Chen, Z. and H. Ji. 2009. Graph-based Event Corefer-ence Resolution. Proceedings of the ACL-IJCNLP 09 workshop on TextGraphs-4: Graph-based Methods for Natural Language Processing. Culotta, A., M. Wick, and A. McCallum. 2007. First-order probabilistic models for coreference resolution. Proceedings of the HLT/NAACL conference.  
De Saussure, F. 1896. Course in General Linguistics. Open Court Classics. Finkel, J.R. and C.D. Manning. 2008. Enforcing transi-tivity in coreference resolution. Proceedings of the ACL-HLT conference, pp. 45?48.  Florian, R., J F Pitrelli, S Roukos, I Zitouni. 2010. Im-proving Mention Detection Robustness to Noisy In-put.  Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). Frege, G. 1892. On Sense and Reference. Reprinted in P. Geach and M. Black (eds.) Translations from the Philosophical Writings of Gottlob Frege. Oxford: Blackwell, 1960. Guarino, N. 1999. The Role of Identity Conditions in Ontology Design. In C. Freksa and D.M. Mark (eds.), Spatial Information Theory: Cognitive and Computa-tional Foundations of Geographic Information Sci-ence. Proceedings of International Conference COSIT '99.  Springer Verlag. Hasler, L., C. Orasan, and K. Naumann. 2006. NPs for Events: Experiments in Coreference Annotation. Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-06), pp. 1167?1172.  Hasler, L. and C. Orasan. 2009. Do Coreferential Ar-guments make Event Mentions Coreferential? Pro-ceedings of the 7th Discourse Anaphora and Anaphor Resolution Colloquium (DAARC 09), pp 151?163. Humphreys, K., R. Gaizauskas and S. Azzam. 1997.  Event Coreference for Information Extraction. Pro-ceedings of the ACL conference Workshop on Opera-tional Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts (ANARESOLU-TION 97).  Ku?ov?, L. and E. Haji?ov?. 2004. Coreferential rela-tions in the Prague Dependency Treebank. Proceed-ings of the DAARC workshop, pp. 97?102. Mani, I. and J. Pustejovsky. 2004. Temporal Discourse Models for Narrative Structure. Proceedings of the ACL 2004 Workshop on Discourse Annotation.  McCarthy, J.F. and W. Lehnert. 1995. Using Decision trees for Coreference Resolution. Proceedings of the IJCAI conference.  Mill, J.S. 1872. A System of Logic, definitive 8th edi-tion. 1949 reprint, London: Longmans, Green and Company. Ng, V. 2007. Shallow Semantics for Coreference Reso-lution. Proceedings of the IJCAI conference. 
27
Ng, V. 2009. Graph-cut-based Anaphoricity Determina- tion for Coreference Resolution. Proceedings of the NAACL-HLT conference, pp. 575?583. Poesio, M. and R. Artstein. 2005. The reliability of ana-phoric annotation, reconsidered: Taking ambiguity into account. Proceedings of the ACL Workshop on Frontiers in Corpus Annotation II. Poesio, M. and R. Artstein. 2008. Anaphoric annotation in the ARRAU corpus. Proceedings of the LREC conference. Pradhan, S., E.H. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and R. Weischedel 2007. OntoNotes: A Unified Relational Semantic Representation. Interna-tional Journal of Semantic Computing 1(4), pp. 405?420.  Pustejovsky, J., J. Casta?o, R. Ingria, R. Saur?, R. Gai-zauskas, A. Setzer and G. Katz. 2003. TimeML: Ro-bust Specification of Event and Temporal Expressions in Text. Proceedings of IWCS-5, Fifth International Workshop on Computational Seman-tics. Recasens, M. and E.H. Hovy. 2010a. Coreference Reso-lution across Corpora: Languages, Coding Schemes, and Preprocessing Information. Proceedings of the Association of Computational Linguistics conference (ACL 10).  Recasens, M. and E.H. Hovy. 2010b. BLANC: Imple-menting the Rand Index for Coreference Evaluation.  Journal of Natural Language Engineering 16(5).  Recasens, M., E.H. Hovy, and M.A. Mart?. 2011. Identi-ty, Non-identity, and Near-identity: Addressing the Complexity of Coreference.  Lingua.   Taul?, M., M.A. Mart?. and M. Recasens. 2008. An-Cora: Multilevel Annotated Corpora for Catalan and Spanish. Proceedings of the LREC 08 conference, pp. 96?101.  Walker, C., S. Strassel, J. Medero 2006. The ACE 2005 multilingual training corpus.  Linguistic Data Con-sortium, University of Pennsylvania, Philadelphia. 
28
Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 68?76,
Baltimore, Maryland, USA, June 22-27, 2014.
c
?2014 Association for Computational Linguistics
Evaluation for Partial Event Coreference
Jun Araki Eduard Hovy Teruko Mitamura
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
junaraki@cs.cmu.edu, hovy@cmu.edu, teruko@cs.cmu.edu
Abstract
This paper proposes an evaluation scheme
to measure the performance of a system
that detects hierarchical event structure for
event coreference resolution. We show
that each system output is represented as
a forest of unordered trees, and introduce
the notion of conceptual event hierarchy to
simplify the evaluation process. We enu-
merate the desiderata for a similarity met-
ric to measure the system performance.
We examine three metrics along with the
desiderata, and show that metrics extended
from MUC and BLANC are more ade-
quate than a metric based on Simple Tree
Matching.
1 Introduction
Event coreference resolution is the task to de-
termine whether two event mentions refer to the
same event. This task is important since resolved
event coreference is useful in various tasks such as
topic detection and tracking, information extrac-
tion, question answering, textual entailment, and
contradiction detection.
A key challenge for event coreference resolu-
tion is that one can define several relations be-
tween two events, where some of them exhibit
subtle deviation from perfect event identity. For
clarification, we refer to perfect event identity
as full (event) coreference in this paper. To ad-
dress the subtlety in event identity, Hovy et al.
(2013) focused on two types of partial event iden-
tity: subevent and membership. Subevent relations
form a stereotypical sequence of events, or a script
(Schank and Abelson, 1977; Chambers and Juraf-
sky, 2008). Membership relations represent in-
stances of an event collection. We refer to both
as partial (event) coreference in this paper. Fig-
ure 1 shows some examples of the subevent and
membership relations in the illustrative text be-
low, taken from the Intelligence Community do-
main of violent events. Unlike full coreference,
partial coreference is a directed relation, and forms
hierarchical event structure, as shown in Figure 1.
Detecting partial coreference itself is an important
task because the resulting event structures are ben-
eficial to text comprehension. In addition, such
structures are also useful as background knowl-
edge information to resolve event coreference.
A car bomb that police said was set by Shining Path
guerrillas ripped off(E4) the front of a Lima police
station before dawn Thursday, wounding(E5) 25 peo-
ple. The attack(E6) marked the return to the spotlight
of the feared Maoist group, recently overshadowed by
a smaller rival band of rebels. The pre-dawn bomb-
ing(E7) destroyed(E8) part of the police station and
a municipal office in Lima?s industrial suburb of Ate-
Vitarte, wounding(E9) 8 police officers, one seriously,
Interior Minister Cesar Saucedo told reporters. The
bomb collapsed(E11) the roof of a neighboring hospi-
tal, injuring(E12) 15, and blew out(E13) windows and
doors in a public market, wounding(E14) two guards.
Figure 1: Examples of subevent and member-
ship relations. Solid and dashed arrows represent
subevent and membership relations respectively,
with the direction from a parent to its subevent
or member. For example, we say that E4 is a
subevent of E6. Solid lines without any arrow
heads represent full coreference.
In this paper, we address the problem of evalu-
68
ating the performance of a system that detects par-
tial coreference in the context of event coreference
resolution. This problem is important because, as
with other tasks, a good evaluation method for par-
tial coreference will facilitate future research on
the task in a consistent and comparable manner.
When one introduces a certain evaluation metric
to such a new complex task as partial event coref-
erence, it is often unclear what metric is suitable
to what evaluation scheme for the task under what
assumptions. It is also obscure how effectively and
readily existing algorithms or tools, if any, can be
used in a practical setting of the evaluation. In or-
der to resolve these sub-problems for partial coref-
erence evaluation, we need to formulate an evalu-
ation scheme that defines assumptions to be made
regarding the evaluation, specifies some desider-
ata that an ideal metric should satisfy for the task,
and examines how adequately particular metrics
can satisfy them. For this purpose, we specifi-
cally investigate three existing algorithms MUC,
BLANC, and Simple Tree Matching (STM).
The contributions of this work are as follows:
? We introduce a conceptual tree hierarchy that
simplifies the evaluation process for partial
event coreference.
? We present a way to extend MUC, BLANC,
and STM for the case of unordered trees.
Those metrics are generic and flexible
enough to be used in evaluations involving
data structures based on unordered trees.
? Our experimental results indicate that the ex-
tended MUC and BLANC are better than
Simple Tree Matching for evaluating partial
coreference.
2 Related Work
Recent studies on both entity and event coref-
erence resolution use several metrics to evaluate
system performance (Bejan and Harabagiu, 2010;
Lee et al., 2012; Durrett et al., 2013; Lassalle and
Denis, 2013) since there is no agreement on a sin-
gle metric. Currently, five metrics are widely used:
MUC (Vilain et al., 1995), B-CUBED (Bagga and
Baldwin, 1998), two CEAF metrics CEAF-?
3
and
CEAF-?
4
(Luo, 2005), and BLANC (Recasens
and Hovy, 2011). We can divide these metrics
into two groups: cluster-based metrics, e.g., B-
CUBED and CEAF, and link-based metrics, e.g.,
MUC and BLANC. The former group is not ap-
plicable to evaluate partial coreference because it
is unclear how to define a cluster. The latter is
not readily applicable to the evaluation because it
is unclear how to penalize incorrect directions of
links. We discuss these aspects in Section 4.1 and
Section 4.2.
Tree Edit Distance (TED) is one of the tradi-
tional algorithms for measuring tree similarity. It
has a long history of theoretical studies (Tai, 1979;
Zhang and Shasha, 1989; Klein, 1998; Bille, 2005;
Demaine et al., 2009; Pawlik and Augsten, 2011).
It is also widely studied in many applications, in-
cluding Natural Language Processing (NLP) tasks
(Mehdad, 2009; Wang and Manning, 2010; Heil-
man and Smith, 2010; Yao et al., 2013). However,
TED has a disadvantage: we need to predefine ap-
propriate costs for basic tree-edit operations. In
addition, an implementation of TED for unordered
trees is fairly complex.
Another tree similarity metric is Simple Tree
Matching (STM) (Yang, 1991). STM measures
the similarity of two trees by counting the max-
imum match with dynamic programming. Al-
though this algorithm was also originally devel-
oped for ordered trees, the underlying idea of the
algorithm is simple, making it relatively easy to
extend the algorithm for unordered trees.
Tree kernels have been also widely studied and
applied to NLP tasks, more specifically, to cap-
ture the similarity between parse trees (Collins and
Duffy, 2001; Moschitti et al., 2008) or between
dependency trees (Croce et al., 2011; Srivastava
et al., 2013). This method is based on a super-
vised learning model with training data; hence we
need a number of pairs of trees and associated nu-
meric similarity values between these trees as in-
put. Thus, it is not appropriate for an evaluation
setting.
3 Evaluation Scheme
When one formulates an evaluation scheme for a
new task, it is important to define assumptions for
the evaluation and desiderata that an ideal metric
should satisfy. In this section, we first describe as-
sumptions for partial coreference evaluation, and
introduce the notion of conceptual event hierarchy
to address the challenge posed by one of the as-
sumptions. We then enumerate the desiderata for
a metric.
69
3.1 Assumptions on Partial Coreference
We make the following three assumptions to eval-
uate partial coreference.
Twinless mentions: Twinless mentions (Stoyanov
et al., 2009) are the mentions that exist in the gold
standard but do not in a system response, or vice
versa. In reality, twinless mentions often happen
since an end-to-end system might produce them in
the process of detecting mentions. The assump-
tion regarding twinless mentions has been inves-
tigated in research on entity coreference resolu-
tion. Cluster-based metrics such as B-CUBED and
CEAF assume that a system is given true men-
tions without any twinless mentions in the gold
standard, and then resolves full coreference on
them. Researchers have made different assump-
tions about this issue. Early work such as (Ji et
al., 2005) and (Bengtson and Roth, 2008) simply
ignored such mentions. Rahman and Ng (2009)
removed twinless mentions that are singletons in a
system response. Cai and Strube (2010) proposed
two variants of B-CUBED and CEAF that can deal
with twinless mentions in order to make the evalu-
ation of end-to-end coreference resolution system
consistent.
In evaluation of partial coreference where twin-
less mentions can also exist, we believe that the
value of making evaluation consistent and compa-
rable is the most important, and hypothesize that
it is possible to effectively create a metric to mea-
sure the performance of partial coreference while
dealing with twinless mentions. A potential prob-
lem of making a single metric handle twinless
mentions is that the metric would not be informa-
tive enough to show whether a system is good at
identifying coreference links but poor at identify-
ing mentions, or vice versa (Recasens and Hovy,
2011). However, our intuition is that the prob-
lem is avoidable by showing the performance of
mention identification with metrics such as pre-
cision, recall, and the F-measure simultaneously
with the performance of link identification. In this
work, therefore, we assume that a metric for par-
tial coreference should be able to handle twinless
mentions.
Intransitivity: As described earlier, partial coref-
erence is a directed relation. We assume that par-
tial coreference is not transitive. To illustrate the
intransitivity, let e
i
s
?? e
j
denote a subevent rela-
tion that e
j
is a subevent of e
i
. In Figure 1, we
have E7
s
?? E8 and E8
s
?? E9. In this case,
E9 is not a subevent of E7 due to the intransi-
tivity of subevent relations. One could argue that
the event ?wounding(E9)? is one of stereotypical
events triggered by the event ?bombing(E7)?, and
thus E7
s
?? E9. However, if we allow transitiv-
ity of partial coreference, then we have to measure
all implicit partial coreference links (e.g., the one
between E7 and E9) from hierarchical event struc-
tures. Consequently, this evaluation policy could
result in an unfair scoring scheme biased toward
large event hierarchy.
Link propagation: We assume that partial coref-
erence links can be propagated due to a combi-
nation of full coreference links with them. To il-
lustrate the phenomenon, let e
i
? e
j
denote full
coreference between e
i
and e
j
. In Figure 1, we
have E6 ? E7 and E7
s
?? E8. In this case, E8
is also a subevent of E6, i.e., E6
s
?? E8. The
rationale behind this assumption is that if a sys-
tem identifies E6
s
?? E8 instead of E7
s
?? E8,
then there is no reason to argue that the identified
subevent relation is incorrect given that E6? E7
and E7
s
?? E8. The discussion here also applies
to membership relations.
3.2 Conceptual Event Hierarchy
The assumption of link propagation poses a chal-
lenge in measuring the performance of partial
coreference. We illustrate the challenge with the
example in the discussion on link propagation
above. We focus only on subevent relations to de-
scribe our idea, but one can apply the same dis-
cussion to membership relations. Suppose that a
system detects a subevent link E7
s
?? E8, but not
E6
s
?? E8. Then, is it reasonable to give the
system a double reward for two links E7
s
?? E8
and E6
s
?? E8 due to link propagation, or should
one require a system to perform such link propa-
gation and detect E7
s
?? E8 as well for the system
to achieve the double reward? In the evaluation
scheme based on event trees whose nodes repre-
sent event mentions, we need to predefine how to
deal with link propagation of full and partial coref-
erence in evaluation. In particular, we must pay at-
tention to the potential risk of overcounting partial
corefrence links due to link propagation.
To address the complexity of link propagation,
we introduce a conceptual event tree where each
node represents a conceptual event rather than an
event mention. Figure 2 shows an example of
a conceptual subevent tree constructed from full
70
coreference and subevent relations in Figure 1.
Using set notation, each node of the tree represents
an abstract event. For instance, node {E6, E7}
represents an ?attacking? event which both event
mentions E6 and E7 refer to.
Figure 2: A conceptual subevent tree constructed
from the full coreference and subevent relations in
Figure 1.
The notion of a conceptual event tree obviates
the need to cope with link propagation, thereby
simplifying the evaluation for partial coreference.
Given a conceptual event tree, an evaluation met-
ric is basically just required to measure how many
links in the tree a system successfully detects.
When comparing two conceptual event trees, a
link in a tree is identical to one in the other tree
if there is at least one event mention shared in par-
ent nodes of those links and at least one shared
in child nodes of those links. For example, sup-
pose that system A identifies E6
s
?? E8, system
B E7
s
?? E8, system C both, and all the systems
identify E6 ? E7 in Figure 1. In this case, they
gain the same score since the subevent links that
they identify correspond to one correct subevent
link {E6, E7}
s
?? {E8} in Figure 2. It is pos-
sible to construct the conceptual event hierarchy
for membership relations in the same way as de-
scribed above. This means that the conceptual
event hierarchy allows us to show the performance
of a system on each type of partial coreference
separately, which leads to more informative evalu-
ation output.
One additional note is that the conceptual event
tree representing partial coreference is an un-
ordered tree, as illustrated in Figure 2. Although
we could represent a subevent tree with an or-
dered tree because of the stereotypical sequence of
subevents given by definition, partial coreference
is in general represented with a forest of unordered
trees
1
.
1
For example, it is impossible to intuitively define a se-
3.3 Desiderata for Metrics
In general, a system output of partial event coref-
erence in a document is represented not by a sin-
gle tree but by a forest, i.e., a set of disjoint trees
whose nodes are event mentions that appear in the
document. Let T be a tree, and let F be a forest
F = {T
i
}. Let sim(F
g
, F
r
) ? [0, 1] denote a sim-
ilarity score between the gold standard forest F
g
and a system response forest F
r
. We define the
following properties that an ideal evaluation met-
ric for partial event coreference should satisfy.
P1. Identity: sim(F
1
, F
1
) = 1.
P2. Symmetricity: sim(F
1
, F
2
) = sim(F
2
, F
1
).
P3. Zero: sim(F
1
, F
2
) = 0 if F
1
and F
2
are to-
tally different forests.
P4. Monotonicity: The metric score should in-
crease from 0 to 1 monotonically as two to-
tally different forests approach the identical
one.
P5. Linearity: The metric score should increase
linearly as each single individual correct
piece of information is added to a system re-
sponse.
The first three properties are relatively intuitive.
P4 is important because otherwise a higher score
by the metric does not necessarily mean higher
quality of partial event coreference output. In P5, a
correct piece of information is the addition of one
correct link or the deletion of one incorrect link.
This property is useful for tracking performance
progress over a certain period of time. If the met-
ric score increases nonlinearly, then it is difficult to
compare performance progress such as a 0.1 gain
last year and a 0.1 gain this year, for example.
In addition, one can think of another property
with respect to structural consistency. The moti-
vation for the property is that one might want to
give more reward to partial coreference links that
form hierarchical structures, since they implicitly
form sibling relations among child nodes. For in-
stance, suppose that system A detects two links
{E6, E7}
s
?? {E8} and {E6, E7}
s
?? {E11}, and
system B two links {E8}
s
?? {E9} and {E11}
s
??
{E12} in Figure 2. We can think that system A
performs better since the system successfully de-
tects an implicit subevent sibling relation between
{E8} and {E11} as well. Due to space limita-
tions, however, we do not explore the property in
this work, and leave it for future work.
quence of child nodes in a membership event tree in Figure 1.
71
4 Evaluation Metrics
In this section, we examine three evaluation met-
rics based on MUC, BLANC, and STM respec-
tively under the evaluation scheme described in
Section 3.
4.1 B-CUBED and CEAF
B-CUBED regards a coreference chain as a set of
mentions, and examines the presence and absence
of mentions in a system response that are relative
to each of their corresponding mentions in the gold
standard (Bagga and Baldwin, 1998). Let us call
such set a mention cluster. A problem in applying
B-CUBED to partial coreference is that it is diffi-
cult to properly form a mention cluster for partial
coreference. In Figure 2, for example, we could
form a gold standard cluster containing all nodes
in the tree. We could then form a system response
cluster, given a certain system output. The prob-
lem is that B-CUBED?s way of counting mentions
overlapped in those clusters cannot capture parent-
child relations between the mentions in a cluster.
It is also difficult to extend the counting algorithm
to incorporate such relations in an intuitive man-
ner. Therefore, we observe that B-CUBED is not
appropriate for evaluating partial coreference.
We see the basically same reason for the inade-
quacy of CEAF. It also regards a coreference chain
as a set of mentions, and measures how many men-
tions two clusters share using two similarity met-
rics ?
3
(R,S) = |R ? S| and ?
4
(R,S) =
2|R?S|
|R|+|S|
,
given two clustersR and S. One can extend CEAF
for partial coreference by selecting the most ap-
propriate tree similarity algorithm for ? that works
well with the algorithm to compute maximum bi-
partite matching in CEAF. However, that is an-
other line of work, and due to space limitations
we leave it for future work.
4.2 Extension to MUC and BLANC
MUC relies on the minimum number of links
needed when mapping a system response to the
gold standard (Vilain et al., 1995). Given a set of
key entitiesK and a set of response entitiesR, pre-
cision of MUC is defined as the number of com-
mon links between entities in K and R divided by
the number of links in R, whereas recall of MUC
is defined as the number of common links between
entities inK andR divided by the number of links
inK. After finding a set of mention clusters by re-
solving full coreference, we can compute the num-
ber of correct links by counting all links spanning
in those mention clusters that matched the gold
standard. It is possible to apply the idea of MUC
to the case of partial coreference simply by chang-
ing the definition of a correct link. In the partial
coreference case, we define a correct link as a link
matched with the gold standard including its di-
rection. Let MUC
p
denote such extension to MUC
for partial coreference.
Similarly, it is also possible to define an ex-
tension to BLANC. Let BLANC
p
denote the ex-
tension. BLANC computes precision, recall,
and F1 scores for both coreference and non-
coreference links, and average them for the final
score (Recasens and Hovy, 2011). As with MUC
p
,
BLANC
p
defines a correct link as a link matched
with the gold standard including its direction. An-
other difference between BLANC and BLANC
p
is
the total number of mention pairs, denoted asL. In
the original BLANC, L = N(N ? 1)/2 where N
is the total number of mentions in a document. We
use L
p
= N(N ? 1) instead for BLANC
p
since
we consider two directed links in partial corefer-
ence with respect to each undirected link in full
coreference.
4.3 Extension to Simple Tree Matching
The underlying idea of STM is that if two trees
have more node-matching, then they are more sim-
ilar. The original STM uses a dynamic program-
ming approach to perform recursive node-level
matching in a top-down fashion. In the case of
partial coreference, we cannot readily use the ap-
proach because partial coreference is represented
with unordered trees, and thus time complexity of
node-matching is the exponential order with re-
spect to the number of child nodes. However, par-
tial event coreference is normally given in a small
hierarchy with three levels or less. Taking ad-
vantage of this fact and assuming that each event
mention is uniquely identified in a tree, we ex-
tend STM for the case of unordered trees by using
greedy search. Algorithm 1 shows an extension to
the STM algorithm for unordered trees.
We can also naturally extend STM to take
forests as input. Figure 3 shows how one can con-
vert a forest into a single tree whose subtrees are
the trees in the forest by introducing an additional
dummy root node on top of those tree. The result-
ing tree is also an unordered tree, and thus we can
apply Algorithm 1 to that tree to measure the sim-
72
Algorithm 1 Extended simple tree matching for
unordered trees.
Input: two unordered trees A and B
Output: score
1: procedure SimpleTreeMatching(A, B)
2: if the roots of A and B have different elements then
3: return 0
4: else
5: s := 1 . The initial score for the root match.
6: m := the number of first-level sub-trees of A
7: n := the number of first-level sub-trees of B
8: for i = 1? m do
9: for j = 1? n do
10: if A
i
and B
j
have the same element then
11: s = s + SimpleTreeMatching(A
i
, B
j
)
Figure 3: Conversion from a forest to a single tree
with an additional dummy root.
ilarity of two forests comprising unordered trees.
Let STM
p
denote the extended STM. Finally, we
normalize STM
p
. Let NSTM
p
be a normalized
version of STM
p
as follows: NSTM
p
(F
1
, F
2
) =
STM
p
(F
1
, F
2
)/max(|F
1
|, |F
2
|) where |F | de-
notes the number of nodes in F .
4.4 Flexibility of Metrics
Making assumptions on evaluation for a particular
task and defining desiderata for a metric determine
what evaluation scheme we are going to formulate.
However, this kind of effort tends to make result-
ing evaluation metrics too restrictive to be reusable
in other tasks. Such metrics might be adequate
for that task, but we also value the flexibility of
a metric that can be directly used or be easily ex-
tended to other tasks. To investigate the flexibil-
ity of MUC
p
, BLANC
p
and STM
p
, we will exam-
ine these metrics without making the assumptions
of twinless mentions and intransitivity of partial
coreference against each metric. We consider that
the assumption of link propagation is more funda-
mental and regard it as a basic premise, and thus
we will continue to make that assumption.
MUC was originally designed to deal with re-
sponse links spanning mentions that even key links
do not reach. Thus, it is able to handle twinless
mentions. If we do not assume intransitivity of
partial coreference, we do not see any difficulty in
changing the definition of correct links in MUC
p
and making it capture transitive relations. There-
fore, MUC
p
does not require both assumptions of
twinless mentions and intransitivity.
In contrast, BLANC was originally designed to
handle true mentions in the gold standard. Since
BLANC
p
does not make any modifications on this
aspect, it cannot deal with twinless mentions ei-
ther. As for intransitivity, it is possible to easily
change the definition of correct and incorrect links
in BLANC
p
to detect transitive relations. Thus,
BLANC
p
does not require intransitivity but does
require the assumption of no twinless mentions.
Since STM
p
simply matches elements in nodes
as shown in Algorithm 1, it does not require the as-
sumption of twinless mentions. With respect to in-
transitivity, we can extend STM
p
by adding extra
edges from a parent to grandchild nodes or others
and applying Algorithm 1 to the modified trees.
Hence, it does not require the assumption of in-
transitivity.
5 Experiments
To empirically examine the three metrics de-
scribed in Section 4.2 and Section 4.3, we con-
ducted an experiment using the artificial data
shown in Table 1. Since BLANC
p
cannot han-
dle twinless mentions, we removed twinless men-
tions. We first created the gold standard shown in
the first row of the table. It contains fifty events,
twenty one singleton events, and seven event trees
with three levels or less. We believe this distri-
bution of partial coreference is representative of
that of real data. We then created several system
responses that are ordered toward two extremes.
One extreme is all singletons in which they do not
have correct links. The other is a single big tree
that merges all event trees including singletons in
the gold standard.
Figure 4 shows how the three metrics behave
in two cases: (a) we increase the number of cor-
rect links from all singletons to the perfect output
(equal to the gold standard), and (b) we increase
the incorrect links from the perfect output to a sin-
gle tree merging all trees in the gold standard. In
the former case, we started with System 3 in Ta-
ble 1. Next we added one correct link 28
s
?? 29
shown in System 2. This way, we added cor-
rect links up to the perfect output one by one in
a bottom-up fashion. In the latter case, we started
73
Response
Output
Gold standard
(1(2(6))(3(7))(4)(5)) (8(9(11)(12))(10)) (13(14)(15)(16)(17)(18)) (19(20(21))(22)) (23(24)(25))
(26(27)) (28(29)) (30) (31) (32) (33) (34) (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45) (46)
(47) (48) (49) (50)
System 1
(1(4)(5)(2(6))(3(7))) (8(9(11)(12))(10)) (13(18)(14)(15)(16)(17)) (19(22)(20(21))) (23(24)(25))
(26(27)) (28(29)) (30) (31) (32) (33) (34) (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45) (46)
(47) (48) (49(50))
System 2
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22) (23) (24)
(25) (26) (27) (28(29)) (30) (31) (32) (33) (34) (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45)
(46) (47) (48) (49) (50)
System 3
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22) (23) (24)
(25) (26) (27) (28) (29) (30) (31) (32) (33) (34) (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45)
(46) (47) (48) (49) (50)
Table 1: Examples of a system response against a gold standard partial coreference. Each event tree is
shown in the bold font and in the Newick standard format with parentheses.
with the perfect output, and then added one incor-
rect link 49
s
?? 50 shown in System 1. In a manner
similar to case (a), we added incorrect links up to
the merged tree one by one in a bottom-up fashion.
The results indicate that MUC
p
and BLANC
p
meet the desiderata defined in Section 3.3 more
adequately than NSTM
p
. The curve of MUC
p
and
BLANC
p
in Figure 4 are close to the linearity,
which is practically useful as a metric. In contrast,
NSTM
p
fails to meet P4 and P5 in case (a), and
fails to meet P5 in case (b). This is because STM
first checks whether root nodes of two trees have
the same element, and if the root nodes have dif-
ferent elements, STM stops searching the rest of
nodes in the trees.
6 Discussion
In Section 4.4, we observed that MUC
p
and STM
p
are more flexible than BLANC
p
because they can
measure the performance coreference in the case
of twinless mentions as well. The experimental re-
sults in Section 5 show that MUC
p
and BLANC
p
more adequate in terms of the five properties de-
fined in Section 3.3. Putting these together, MUC
p
seems the best metric for partial event coreference.
However, MUC has two disadvantages that (1) it
prefers systems that have more mentions per en-
tity (event), and (2) it ignores recall for singletons
(Pradhan et al., 2011). MUC
p
also has these disad-
vantages. Thus, BLANC
p
might be the best choice
for partial coreference if we could assume that a
system is given true mentions in the gold standard.
Although STM
p
fails to satisfy P4 and P5, it
has potential power to capture structural proper-
 0
 20
 40
 60
 80
 100
 0  20  40  60  80  100
Sc
ore
Ratio of correct links [%]
MUCpBLANCpNSTMp
(a) The number of correct links increases from singletons to
the perfect output (the gold standard) one by one.
 0
 20
 40
 60
 80
 100
 0  20  40  60  80  100
Sc
ore
Ratio of incorrect links [%]
MUCpBLANCpNSTMp
(b) The number of incorrect links increases from the perfect
output to a single tree merging all trees one by one.
Figure 4: Score comparison among MUC
p
,
BLANC
p
, and NSTM
p
.
74
ties of partial coreference described in Section 3.3.
This is because STM?s recursive fashion of node-
counting can be easily extend to counting the num-
ber of correct sibling relations.
7 Conclusion
We proposed an evaluation scheme for partial
event coreference with conceptual event hierar-
chy constructed from mention-based event trees.
We discussed possible assumptions that one can
make, and examined extensions to three existing
metrics. Our experimental results indicate that the
extensions to MUC and BLANC are more ade-
quate than the extension to STM. To our knowl-
edge, this is the first work to argue an evaluation
scheme for partial event coreference. Neverthe-
less, we believe that our scheme is generic and
flexible enough to be applicable to other directed
relations of events (e.g., causality and entailment)
or other related tasks to compare hierarchical data
based on unordered trees (e.g., ontology compari-
son). One future work is to improve the metrics
by incorporating structural consistency of event
trees as an additional property and implementing
the metrics from the perspective of broad contexts
beyond local evaluation by link-based counting.
8 Acknowledgements
This research was supported in part by DARPA
grant FA8750-12-2-0342 funded under the DEFT
program. Any opinions, findings, and conclusion
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the view of the DARPA or the US government. We
would like to thank anonymous reviewers for their
helpful comments.
References
Amit Bagga and Breck Baldwin. 1998. Algorithms
for Scoring Coreference Chains. In Proceedings of
LREC 1998 Workshop on Linguistics Coreference,
pages 563?566.
Cosmin Bejan and Sanda Harabagiu. 2010. Unsuper-
vised Event Coreference Resolution with Rich Lin-
guistic Features. In Proceedings of ACL 2010, pages
1412?1422.
Eric Bengtson and Dan Roth. 2008. Understanding
the Value of Features for Coreference Resolution. In
Proceedings of EMNLP 2008, pages 294?303.
Philip Bille. 2005. A Survey on Tree Edit Distance and
Related Problems. Theoretical Computer Science,
337(1-3):217?239.
Jie Cai and Michael Strube. 2010. Evaluation Metrics
For End-to-End Coreference Resolution Systems. In
Proceedings of SIGDIAL 2010, pages 28?36.
Nathanael Chambers and Dan Jurafsky. 2008. Un-
supervised Learning of Narrative Event Chains. In
Proceedings of ACL-HLT 2008, pages 789?797.
Michael Collins and Nigel Duffy. 2001. Convolution
Kernels for Natural Language. In Proceedings of
NIPS 2001, pages 625?632.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured Lexical Similarity via Con-
volution Kernels on Dependency Trees. In Proceed-
ings of EMNLP 2011, pages 1034?1046.
Erik D. Demaine, Shay Mozes, Benjamin Rossman,
and Oren Weimann. 2009. An Optimal Decomposi-
tion Algorithm for Tree Edit Distance. ACM Trans-
actions on Algorithms (TALG), 6(1):2:1?2:19.
Greg Durrett, David Hall, and Dan Klein. 2013. De-
centralized Entity-Level Modeling for Coreference
Resolution. In Proceedings of ACL 2013, pages
114?124.
Michael Heilman and Noah A. Smith. 2010. Tree Edit
Models for Recognizing Textual Entailments, Para-
phrases, and Answers to Questions. In Proceedings
of NAACL-HLT 2013, pages 1011?1019.
Eduard Hovy, Teruko Mitamura, Felisa Verdejo, Jun
Araki, and Andrew Philpot. 2013. Events are Not
Simple: Identity, Non-Identity, and Quasi-Identity.
In Proceedings of NAACL-HLT 2013 Workshop on
Events: Definition, Detection, Coreference, and
Representation, pages 21?28.
Heng Ji, David Westbrook, and Ralph Grishman. 2005.
Using Semantic Relations to Refine Coreference
Decisions. In Proceedings of EMNLP/HLT 2005,
pages 17?24.
Philip N. Klein. 1998. Computing the Edit-Distance
Between Unrooted Ordered Trees. In Proceed-
ings of the 6th European Symposium on Algorithms
(ESA), pages 91?102.
Emmanuel Lassalle and Pascal Denis. 2013. Im-
proving pairwise coreference models through fea-
ture space hierarchy learning. In Proceedings of
ACL 2013, pages 497?506.
Heeyoung Lee, Marta Recasens, Angel Chang, Mi-
hai Surdeanu, and Dan Jurafsky. 2012. Joint En-
tity and Event Coreference Resolution across Doc-
uments. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 489?500.
75
Xiaoqiang Luo. 2005. On Coreference Resolution Per-
formance Metrics. In Proceedings of EMNLP 2005,
pages 25?32.
Yashar Mehdad. 2009. Automatic Cost Estimation for
Tree Edit Distance Using Particle Swarm Optimiza-
tion. In Proceedings of ACL-IJCNLP 2009, pages
289?292.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree Kernels for Semantic Role La-
beling. Computational Linguistics, 34(2):193?224.
Mateusz Pawlik and Nikolaus Augsten. 2011. RTED:
A Robust Algorithm for the Tree Edit Distance.
Proceedings of the VLDB Endowment (PVLDB),
5(4):334?345.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen
Xue. 2011. CoNLL-2011 Shared Task: Modeling
Unrestricted Coreference in OntoNotes. In Proceed-
ings of CoNLL Shared Task 2011, pages 1?27.
Altaf Rahman and Vincent Ng. 2009. Supervised
Models for Coreference Resolution. In Proceedings
of EMNLP 2009, pages 968?977.
Marta Recasens and Eduard Hovy. 2011. BLANC:
Implementing the Rand index for coreference eval-
uation. Natural Language Engineering, 17(4):485?
510.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
Plans, Goals, and Understanding: An Inquiry into
Human Knowledge Structures. Lawrence Erlbaum
Associates.
Shashank Srivastava, Dirk Hovy, and Eduard Hovy.
2013. A Walk-Based Semantically Enriched Tree
Kernel Over Distributed Word Representations. In
Proceedings of EMNLP 2013, pages 1411?1416.
Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and
Ellen Riloff. 2009. Conundrums in Noun Phrase
Coreference Resolution: Making Sense of the State-
of-the-Art. In Proceedings of ACL/IJCNLP 2009,
pages 656?664.
Kuo-Chung Tai. 1979. The Tree-to-Tree Correction
Problem. Journal of the ACM (JACM), 26(3):422?
433.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A Model-
Theoretic Coreference Scoring Scheme. In Pro-
ceedings of the 6th Message Understanding Confer-
ence (MUC), pages 45?52.
Mengqiu Wang and Christopher D. Manning. 2010.
Probabilistic Tree-Edit Models with Structured La-
tent Variables for Textual Entailment and Question
Answering. In Proceedings of COLING 2010, pages
1164?1172.
Wuu Yang. 1991. Identifying Syntactic Differences
Between Two Programs. Software: Practice and
Experience, 21(7):739?755.
Xuchen Yao, Benjamin Van Durme, Chris Callison-
burch, and Peter Clark. 2013. Answer Extraction
as Sequence Tagging with Tree Edit Distance. In
Proceedings of NAACL-HLT 2013, pages 858?867.
Kaizhong Zhang and Dennis Shasha. 1989. Simple
Fast Algorithms for the Editing Distance Between
Trees and Related Problems. SIAM J. Comput.,
18(6):1245?1262.
76
