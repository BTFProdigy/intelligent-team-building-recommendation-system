Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 581?589,
Beijing, August 2010
Improving the Quality of Text Understanding by Delaying Ambiguity
Resolution
Doo Soon Kim
Dept. of Computer Science
University of Texas
onue5@cs.utexas.edu
Ken Barker
Dept. of Computer Science
University of Texas
kbarker@cs.utexas.edu
Bruce Porter
Dept. of Computer Science
University of Texas
porter@cs.utexas.edu
Abstract
Text Understanding systems often commit
to a single best interpretation of a sen-
tence before analyzing subsequent text.
This interpretation is chosen by resolv-
ing ambiguous alternatives to the one with
the highest confidence, given the context
available at the time of commitment. Sub-
sequent text, however, may contain infor-
mation that changes the confidence of al-
ternatives. This may especially be the
case with multiple redundant texts on the
same topic. Ideally, systems would de-
lay choosing among ambiguous alterna-
tives until more text has been read.
One solution is to maintain multiple can-
didate interpretations of each sentence un-
til the system acquires disambiguating ev-
idence. Unfortunately, the number of al-
ternatives explodes quickly. In this pa-
per, we propose a packed graphical (PG)
representation that can efficiently repre-
sent a large number of alternative interpre-
tations along with dependencies among
them. We also present an algorithm for
combining multiple PG representations to
help resolve ambiguity and prune alterna-
tives when the time comes to commit to a
single interpretation.
Our controlled experiments show that by
delaying ambiguity resolution until multi-
ple texts have been read, our prototype?s
accuracy is higher than when committing
to interpretations sentence-by-sentence.
1 Introduction
A typical text understanding system confronts am-
biguity while parsing, mapping words to concepts
and formal relations, resolving co-references, and
integrating knowledge derived from separate sen-
tences or texts. The system discards many candi-
date interpretations to avoid combinatorial explo-
sion. Commonly, after reading each sentence, a
system will commit to its top ranked interpreta-
tion of the sentence before reading the next.
If a text understanding system could postpone
committing to an interpretation without being
swamped by a combinatorial explosion of alterna-
tives, its accuracy would almost surely improve.
This intuition follows from the observation that
text is redundant in at least two ways. First, within
a single coherent text (about the same entities
and events), each sentence informs the interpre-
tation of its neighbors. Second, within a corpus of
texts on the same topic, the same information is
expressed in different surface forms, ambiguous
in different ways. Related fields, such as Infor-
mation Extraction, exploit textual redundancy to
good effect, and perhaps text understanding can
as well.
One approach is for the text understanding sys-
tem to maintain multiple complete candidate in-
terpretations. After reading each sentence, for ex-
ample, the system would retain a beam of the n-
best interpretations of the sentence. While this
approach avoids a combinatorial explosion (for
reasonable values of n), several problems remain.
First, because the beam width is limited, the sys-
tem may still discard correct interpretations before
benefiting from the extra context from related text.
Second, enumeration of the candidate interpreta-
581
tions does not represent the dependencies among
them. For example, there may be multiple candi-
date word senses and semantic roles for a given
sentence, but sense alternatives might be depen-
dent on role selection (and vice-versa). The set
of reasonable interpretations may be a subset of
all combinations. Finally, maintaining distinct in-
terpretations does not contribute to addressing the
problem of combining evidence to narrow down
alternatives and ultimately select a single best in-
terpretation of a text.
This paper addresses these three problems. We
propose an approach that postpones committing to
an interpretation of a text by representing ambi-
guities and the dependencies among them. There
may still be combinatorial growth in the set of al-
ternative interpretations, but they are represented
only intensionally, using a packed representation,
which maintains alternatives while avoiding enu-
merating them. We also propose an algorithm for
updating and pruning the packed representation as
more sentences and texts are read.
We evaluate our approach by comparing two
reading systems: a baseline system that commits
to its best interpretation after each sentence, and
our prototype system that uses a packed represen-
tation to maintain all interpretations until further
reading enables it to prune. For this initial proof of
concept, we use a small corpus of redundant texts.
The results indicate that our approach improves
the quality of text interpretation by preventing ag-
gressive pruning while avoiding combinatorial ex-
plosion.
In the following sections, we first describe our
target semantic representation of the interpreta-
tion of sentences. We then present the details
of our packed graphical representation (PG rep-
resentation) and our algorithm to resolve ambi-
guities in the PG representations as disambiguat-
ing evidence from subsequent text accrues. We
describe the architecture of a prototype that pro-
duces PG representations for text and implements
the disambiguating algorithm. Finally, we present
the results from controlled experiments designed
to compare the accuracy of the prototype to a
baseline system that prunes more aggressively.
Figure 1: The target semantic graph representa-
tion for S1
2 Target semantic representation
Our target representation is a semantic graph in
which nodes are words and the ontological types
to which they map. Edges are semantic relations
corresponding either to function words or syntac-
tic relations in the sentence?s parse.
Fig. 1 shows the target semantic representation
for the following simple sentence:
S1: An engine ignites gasoline with its spark plug.
3 PG representation
Alternative semantic interpretations for a sentence
can be captured with a single PG representation
with ambiguities represented as local alternatives.
Because candidate representations are often struc-
turally similar, a PG representation can signifi-
cantly compress the representation of alternatives.
Fig. 2 shows the PG representation of alternate
interpretations of S1 (PG1). The different types of
ambiguity captured by the PG representation are
as follows.
3.1 Word-Type ambiguity
In PG1, the node engine-2a corresponds to the
word ?engine? in S1. Its annotation [LIVING-
ENTITY .3 | DEVICE .7] captures the map-
ping to either LIVING-ENTITY (probability 0.3)
or DEVICE (probability 0.7). The PG repre-
sentation does not presume a particular uncer-
Figure 2: The PG representation for S1 (PG1)
582
tainty formalism. Any formalism, (Dempster-
Shafer theory (Pearl, 1988), Markov Logic Net-
works (Richardson and Domingos, 2006), etc.)
could be used.
3.2 Semantic Relation ambiguity
In PG1, the edge label <agent .6 | location .4>
from ignite-3a to engine-2a says that the engine is
either agent or location of the ignition.
3.3 Structural ambiguity
In PG1, edges D and E are alternatives corre-
sponding to the different prepositional phrase at-
tachments for ?with its spark plug? (to ignite-3a
or gasoline-4a). The annotation {D .3 | E .7} says
that the choices are mutually exclusive with prob-
abilities of 0.3 and 0.7.
3.4 Co-reference ambiguity
Co-reference of nodes in a PG representation is
captured using a ?co-reference? edge. In PG1, the
edge labeled <coref .7> represents the probabil-
ity that engine-2a and its-7a are co-referent.
In addition to storing ambiguities explicitly,
the PG representation also captures dependencies
among alternatives.
3.5 Simple dependency
The existence of one element in the graph de-
pends on the existence of another element. If
subsequent evidence suggests that an element is
incorrect, its dependents should be pruned. For
example, the dependency A ? C, means that if
LIVING-ENTITY is ultimately rejected as the type
for engine-2a, the agent relation should be pruned.
3.6 Mutual dependency
Elements of a mutual dependency set are mutually
confirming. Evidence confirming or rejecting an
element also confirms or rejects other elements in
the set. In the example, the box labeled B says that
(engine-2a type DEVICE) and (ignite-3a location
engine-2a) should both be confirmed or pruned
when either of them is confirmed or pruned.
Formally, the PG representation is a structure
consisting of (a) semantic triples ? e.g., (ignite-
3a type BURN), (b) macros ? e.g., the symbol A
refers to (ignite-3a agent engine-2a), and (c) con-
straints ? e.g., A depends on C.
4 Combining PG representations
Maintaining ambiguity within a PG representation
allows us to delay commitment to an interpreta-
tion until disambiguating evidence appears. For
any text fragment that results in a PG represen-
tation (PGa) containing ambiguity, there may ex-
ist other text fragments that are partly redundant,
but result in a less ambiguous (or differently am-
biguous) representation (PGb). PGb can be used
to adjust confidences in PGa. Enough such evi-
dence allows us to prune unlikely interpretations,
ultimately disambiguating the original representa-
tion.
For example, sentence S3 does not have suffi-
cient context to disambiguate between the MO-
TOR sense of ?engine? and the VEHICLE sense (as
in locomotive).
S3: General Electric announced plans this week
for their much anticipated new engine.
The PG3 representation for S3 (PG3) would
maintain the ambiguous representation (with con-
fidences for each sense based on prior probabil-
ities, for example). On subsequently encounter-
ing sentence S4, a Lesk-based word sense disam-
biguation module (as in our prototype) would pro-
duce a PG4 with a strong preference for the loco-
motive sense of ?engine?, given the more specific
context of S4.
S4: The announcement comes to the relief of many
in the railway industry looking to replace the en-
gines in their aging locomotive fleets.
To use PG4 to help disambiguate PG3, we need
to align PG3 and PG4 semantically and merge
their conflict sets. (In the simple example, the
conflict sets for the word ?engine? might be [MO-
TOR .5 | VEHICLE .5] in PG3 and [MOTOR .2 |
VEHICLE .8] in PG4).
Algorithm 1 describes how two PG representa-
tions can be combined to help resolve their ambi-
guities. The algorithm identifies their isomorphic
subgraphs (redundant portions of the interpreta-
tions) and uses the information to disambiguate
their ambiguities. For illustration, we will step
through Algorithm 1, merging PG1 (Fig. 2) with
583
Algorithm 1 Disambiguating PG representations
Input : PG1, PG2
Output: new PG representation
1. Identify semantically aligned parts between
PG1 and PG2. Use graph matching to identify
alignments (redundant portions) between PG1
and PG2: align nodes with the same base word
or with taxonomically related types; from the
node alignments, align identical types as type
alignments; align relations if the relations are
the same and their head and tail nodes have
been aligned.
2. Use alignments to disambiguate PG1 and
PG2. With the available information (the con-
fidence scores and the constraints in PG1 and
PG2 and the alignments between them), use
joint inference to calculate the confidence score
of each candidate interpretation. If the con-
fidence score of one interpretation becomes
much higher than competing ones, the interpre-
tation is chosen while the others are discarded.
3. Combine the disambiguated PG1 and PG2
into one PG representation using the align-
ments identified in the first step.
Figure 3: PG representation for S2, ?The engine?s
spark plug combusts gasoline.?
PG2 (Fig. 3).
1. The graph matcher identifies alignments
between PG1 and PG2. Type alignments include
(engine-2a[DEVICE], Engine-1b[DEVICE]),
(spark-plug-8a[LIVING-ENTITY], spark-plug-
3b[LIVING-ENTITY]). Relation alignments
include ((combust-5b instrument spark-plug-3b),
(ignite-3 instrument spark-plug-8)), ((ignite-3a
instrument spark-plug-8a) (combust-5b instru-
ment spark-plug-3b)).
2. In this example, when two interpreta-
tions are aligned, we simply add their confi-
dence scores. (We are currently incorporating
Alchemy (Richardson and Domingos, 2006) in the
prototype system to do the joint inference). For
example, aligning engine-2a with Engine-1b re-
sults in a score of 1.7 for DEVICE (1 + .7). The
confidence score of LIVING-ENTITY in engine-
2a is unchanged at .3. Since the resulting score
for DEVICE is much higher than 1 the score for
LIVING-ENTITY, LIVING-ENTITY is discarded.
Deleting LIVING-ENTITY causes deletion of the
agent edge between ignite-3a and engine-2a due
to the dependency constraint A ? C.
3. The disambiguated PG1 and PG2 are merged
into a single PG representation (PG1+2) based on
the alignments. Any remaining ambiguity persists
in PG1+2, possibly to be resolved with another
sentence.
5 Prototype system
5.1 Parser
Our prototype system uses the Stanford
Parser (Klein and Manning, 2003). To cap-
ture structural ambiguity for our experiments,
we manually edited the parser output by adding
corrections as alternatives wherever the parse
tree was incorrect. This gave a syntactic PG
representation with both incorrect and correct
alternatives. We gave the original, incorrect
alternatives high confidence scores and the added,
correct alternatives low scores, simulating a
parser pruning correct interpretations in favor
of incorrect ones with higher confidence scores.
The syntactic PG for S1 is shown in Fig. 4. We
have recently designed a modification to the
Stanford Parser to make it produce syntactic PG
representations natively, based on the complete
chart built during parsing.
5.2 Semantic Interpreter
The semantic interpreter assigns types to nodes in
the syntactic PG representation and semantic rela-
tions to the edges.
Type ambiguity. Types and confidence scores
are assigned to words using SenseRelate (Pat-
wardhan et al, 2005), WSD software based on the
1In our prototype, we set the pruning threshold at 13?the
score of the top-scored interpretation.
584
Lesk Algorithm (Lesk, 1986). Assigned senses
are then mapped to our Component Library ontol-
ogy (Barker et al, 2001) using its built-in Word-
Net mappings.
Relational ambiguity. Semantic relations are
assigned to the dependency relations in the syn-
tactic PG representation according to semantic in-
terpretation rules. Most rules consider the head
and tail types as well as the dependency relation,
but do not produce confidence scores. Our proto-
type scores candidates equally. We plan to incor-
porate a more sophisticated scoring method such
as (Punyakanok et al, 2005).
Structural ambiguity. Parse ambiguities (such
as PA vs. PB in Fig. 4) are converted directly to
structural ambiguity representations (D vs. E in
Fig. 2) in the semantic PG representation.
Simple Dependency. A dependency is in-
stalled between a type t for word w and a semantic
relation r when (1) r is produced by a rule based
on t and (2) r is dependent on no other candidate
type for w. In Fig. 2, a dependency relation is in-
stalled from A to C, because (1) LIVING-ENTITY
in engine-2a was used in the rule assigning agent
between ignite-3a and engine-2a and (2) the as-
signment of agent is not dependent on DEVICE,
the other candidate type of engine-2a.
Mutual dependency. If multiple interpreta-
tions depend on one another, a mutual dependency
set is created to include them.
5.3 PG Merger
The PG Merger implements Algorithm 1 to com-
bine PG representations. The PG representation
Figure 4: Syntactic PG representation for S1, cap-
turing the PP-attachment ambiguity of ?with its
spark plug?.
Original Text Hearts pump blood through the body.
Blood carries oxygen to organs throughout the body.
Blood leaves the heart, then goes to the lungs where
it is oxygenated. The oxygen given to the blood by the
lungs is then burned by organs throughout the body.
Eventually the blood returns to the heart, depleted of
oxygen.
Paraphrase The heart begins to pump blood into the
body. The blood first travels to the lungs, where it
picks up oxygen. The blood will then be deposited
into the organs, which burn the oxygen. The blood
will then return to the heart, where it will be lacking
oxygen, and start over again.
Figure 5: The original text and a paraphrase
for each sentence is merged with the cumulative
PG from previous sentences. The global PG repre-
sentation integrates sentence-level PG representa-
tions to the extent that they align semantically. In
the worst case (completely unrelated sentences),
the global PG representation would simply be the
union of individual PG representations. The ex-
tent to which the global PG is more coherent re-
flects redundancy and semantic overlap in the sen-
tences.
6 Experiment 1
We first wanted to evaluate our hypothesis that
Algorithm 1 can improve interpretation accuracy
over multiple redundant texts. We manually
generated ten redundant texts by having volun-
teers rewrite a short, tutorial text, using Amazon
Turk (http://mturk.com) 2 The volunteers had no
knowledge of the purpose of the task, and were
asked to rewrite the text using ?different? lan-
guage. Fig. 5 shows the original text and one vol-
unteer?s rewrite. The total number of sentences
over the ten texts was 37. Average sentence length
was 14.5 words.
6.1 Evaluation Procedure
We ran two systems over the ten texts. The base-
line system commits to the highest scoring consis-
tent interpretation after each sentence. The pro-
totype system produces an ambiguity-preserving
2We ultimately envision a system whose task is to develop
a model of a particular topic by interpreting multiple texts.
Such a system might be given a cluster of documents or use
its own information retrieval to find similar documents given
a tutorial text.
585
0 10 20 30 40
0.65
0.7
0.75
0.8
0.85
0.9
number of sentences
co
rr
e
ct
ne
ss
(%
)
type triples
 
 
0 10 20 30 40
0.65
0.7
0.75
0.8
0.85
0.9
content triples
0 10 20 30 40
0.65
0.7
0.75
0.8
0.85
0.9
all triples
prototype
baseline
Figure 6: Correctness scores for the prototype vs. baseline system on (a) type triples (word sense assignment), (b) content
triples (semantic relations) and (c) all triples (with standard deviation).
PG representation. For each sentence, the proto-
type?s PG Merger merges the PG of the sentence
with the merged PG of the previous sentences. Af-
ter N sentences (varying N from 1..37), the system
is forced to commit to the highest scoring con-
sistent interpretation in the merged PG. For N=1
(commit after the first sentence), both the base-
line and prototype produce the same result. For
N=2, the baseline produces the union of the high-
est scoring interpretations for each of the first two
sentences. The prototype produces a merged PG
for the first two sentences and then prunes to the
highest scoring alternatives.
At each value of N, we measured the cor-
rectness of the interpretations (the percentage
of correct semantic triples) for each system by
comparing the committed triples against human-
generated gold standard triples.
We repeated the experiment ten times with dif-
ferent random orderings of the 37 sentences, aver-
aging the results.
6.2 Evaluation result
Fig. 6 shows that both type assignment and se-
mantic relation assignment by the prototype im-
prove as the system reads more sentences. This
result confirms our hypothesis that delaying com-
mitment to an interpretation resolves ambiguities
better by avoiding overly aggressive pruning.
To determine an upper bound of correctness for
the prototype, we inspected the PG representa-
tions to see how many alternative sets contained
the correct interpretation even if not the highest
scoring alternative. This number is different from
the correctness score in Fig. 6, which is the per-
baseline prototype
nodes w/ the correct type 76 91
edges w/ the correct relation 74 88
Table 1: Percentage of nodes and edges containing the cor-
rect types and semantic relations in the baseline and the pro-
totype for all 37 sentences.
centage of gold standard triples that are the high-
est scoring alternatives in the merged PG.
Table. 1 shows that 91% of the nodes in the PG
contain the correct type (though not necessarily
the highest scoring). 88% of the edges contain the
correct semantic relations among the alternatives.
In contrast, the baseline has pruned away 24% of
the correct types and 26% of the correct semantic
relations.
7 Experiment 2
Our second experiment aims to evaluate the claim
that the prototype can efficiently manage a large
number of alternative interpretations. The top line
in Fig. 7 shows the number of triples in the PG
representations input to the prototype. This is the
total number of triples (including ambiguous al-
ternatives) in the PG for each sentence prior to in-
voking Algorithm 1. The middle line is the num-
ber of triples remaining after merging and pruning
by Algorithm 1. The bottom line is the number of
triples after pruning all but the highest scoring al-
ternatives (the baseline system). The results show
that Algorithm 1 achieves significant compression
over unmerged PG representations. The result-
ing size of the merged PG representations more
closely tracks the size of the aggressively pruned
586
0 5 10 15 20 25 30 35 40
0
200
400
600
800
1000
1200
bar: standard deviation
5 times repeated
sentences
n
u
m
be
r o
f t
rip
le
s
 
 
triples in input PG representations
triples in the PG representation after merging
triples in the baseline system
Figure 7: Total number of triples in individual sentence PG
representations (top); total number of triples in the PG rep-
resentation after merging in the prototype system (middle);
total number of triples after pruning to the highest scoring
alternative (bottom).
representations.
8 Experiment 3
Finally, we wanted to measure the sensitivity of
our approach to the quality of the natural language
interpretation. In this experiment, we artificially
varied the confidence scores for the correct inter-
pretations in the PG representations input to the
prototype and baseline systems by a fixed per-
centage. For example, consider a node heart-1
with multiple candidate types, including the cor-
rect sense for its context: INTERNAL-ORGAN
with confidence 0.8. We reran Experiment 1 vary-
ing the confidence in INTERNAL-ORGAN in in-
crements of +/-10%, while scaling the confidences
in the incorrect types equally. As the confidence
in correct interpretations is increased, all correct
interpretations become the highest scoring, so ag-
gressive pruning is justified and the baseline per-
formance approaches the prototype performance.
As the confidences in correct interpretations are
decreased, they are more likely to be pruned by
both systems.
Fig. 8 shows that Algorithm 1 is able to recover
at least some correct interpretations even when
their original scores (relative to incorrect alterna-
tives) is quite low.
9 Discussion and Future Work
Our controlled experiments suggest that it is both
desirable and feasible to delay ambiguity resolu-
bar: standard deviation
5 times repeated
0.4 0.5 0.6 0.7 0.8 0.9
0.4
0.5
0.6
0.7
0.8
0.9
the quality of the triples in the baseline system(%)
th
e 
qu
al
ity
 o
f t
he
 tr
ip
le
s 
in
 th
e 
pr
ot
ot
yp
e 
sy
st
em
 (%
)
 
 
prototype
baseline
Figure 8: Sensitivity of the prototype and baseline systems
to the quality of the NL system output. The quality of in-
put triples is perturbed affecting performance accuracy of the
two systems. For example, when the quality of input triples
is such that the baseline system performs at 70% accuracy,
the prototype system performs at 80%. The arrow indicates
unperturbed language interpreter performance.
tion beyond sentence and text boundaries. Im-
provements in the correctness of semantic inter-
pretation of sentences is possible without an ex-
plosion in size when maintaining multiple inter-
pretations.
Nevertheless, these experiments are proofs of
concept. The results confirm that it is worthwhile
to subject our prototype to a more real-world,
practical application. To do so, we need to address
several issues.
First, we manually simulated structural (parse)
ambiguities. We will complete modifications to
the Stanford Parser to produce PG representations
natively. This change will result in a significant
increase in the number of alternatives stored in
the PG representation over the current prototype.
Our initial investigations suggest that there is still
enough structural overlap among the candidate
parse trees to allow the PG representation to con-
trol explosion, but this is an empirical question
that will need to be confirmed.
We are modifying our semantic interpreter to
admit induced semantic interpretation rules which
will allow us to train the system in new domains.
The current prototype uses a naive heuristic for
identifying co-reference candidates. We are inves-
tigating the use of off-the-shelf co-reference sys-
tems.
Finally, we are incorporating the
Alchemy (Richardson and Domingos, 2006)
587
probabilistic inference engine to calculate the
probability that a candidate interpretation is
correct given the PG constraints and alignments,
in order to inform confirmation or pruning of
interpretations.
Once these updates are complete, we will per-
form more wide-scale evaluations. We will inves-
tigate the automatic construction of a test corpus
using text clustering to find redundant texts, and
we will conduct experiments in multiple domains.
10 Related Work
Succinctly representing multiple interpretations
has been explored by several researchers. The
packed representation (Maxwell III and Kaplan,
1981; Crouch, 2005) uses logical formulae to de-
note alternative interpretations and treats the dis-
ambiguation task as the propositional satisfiabil-
ity problem. Core Language Engine (Alshawi,
1992) introduces two types of packing mecha-
nism. First, a quasi logical form allows the under-
specification of several types of information, such
as anaphoric references, ellipsis and semantic re-
lations (Alshawi and Crouch, 1992). Second, a
packed quasi logical form (Alshawi, 1992) com-
pactly represents the derivations of alternative
quasi logical forms. In contrast, the PG repre-
sentation is (1) based on a graphical representa-
tion, (2) explicitly represents constraints and (3)
includes confidence scores.
These representations and the PG represen-
tation have one feature in common: they rep-
resent a set of complete alternative interpreta-
tions of a text. Another class of compact repre-
sentations, called ?underspecification?, has been
studied as a formal representation of ambigu-
ous sentences. These representations include
Hole Semantics (Bos, 2004), Underspecified Dis-
course Representation Semantics (Reyle, 1995),
Minimal Recursion Semantics (Copestake et al,
2005) and Dominance Constraints (Egg et al,
2001). These representations, rather than packing
fully-represented candidate interpretations, spec-
ify fragments of interpretations which are un-
ambiguously interpreted, along with constraints
on their combination (corresponding to different
interpretations). They generally focus on spe-
cific ambiguities such as scope ambiguity (Bos,
2004) (Egg et al, 2001) (Copestake et al, 2005)
or discourse relations (Schilder, 1998) (Regneri et
al., 2008).
Disambiguating compact representations has
received relatively less attention. (Riezler et al,
2002; Geman and Johnson, 2002) use a packed
representation to train parsers on a corpus and
uses the learned statistics to disambiguate packed
representations. (Clark and Harrison, 2010) uses
paraphrase databases and a hand-built knowledge
base to resolve underspecified representations.
Different architectures have been proposed to
improve the pipeline architecture. (Sutton and
McCallum, 2005; Wellner et al, 2004) maintain
a beam of n best interpretations in the pipeline
architecture. Their pipeline, however, consists of
only two components. (Finkel et al, 2006) uses
sampling over the distribution of alternative inter-
pretations at each stage of the pipeline and then
passes the sampled data to the next component.
The packed representation (Crouch, 2005) and
CLE (Alshawi, 1992) use packed representation in
the pipeline, though both, at some stages, unpack
them and re-pack the processed result. (Crouch
and King, 2006) later proposes a new method that
does not require unpacking and then repacking.
11 Conclusion
We have begun to address the challenge of effi-
ciently managing multiple alternative interpreta-
tions of text. We have presented (1) a packed
graphical representation that succinctly repre-
sents multiple alternative interpretations as well as
the constraints among them, and (2) an algorithm
for combining multiple PG representations to re-
inforce correct interpretations and discount im-
plausible interpretations. Controlled experiments
show that it is possible to improve the correctness
of semantic interpretations of text by delaying dis-
ambiguation, without incurring the cost of an ex-
ponentially expanding representation.
12 Acknowledgement
Support for this research was provided in part by
Air Force Contract FA8750-09-C-0172 under the
DARPA Machine Reading Program
588
References
Alshawi, Hiyan and Richard S. Crouch. 1992. Mono-
tonic semantic interpretation. In ACL, pages 32?39.
Alshawi, Hiyan, editor. 1992. The Core Language
Engine. MIT Press, Cambridge, Massachusetts.
Barker, Ken, Bruce Porter, and Peter Clark. 2001. A
library of generic concepts for composing knowl-
edge bases. In Proceedings of the international con-
ference on Knowledge capture, pages 14?21.
Bos, Johan. 2004. Computational semantics in dis-
course: Underspecification, resolution, and infer-
ence. Journal of Logic, Language, and Information,
13(2):139?157.
Clark, Peter and Phil Harrison. 2010. Exploiting para-
phrases and deferred sense commitment to interpret
questions more reliably. In To appear in Proceed-
ings of CoLing 2010.
Copestake, Ann, Dan Flickinger, Carl Pollard, and
Ivan Sag. 2005. Minimal recursion semantics: an
introduction. Research on Language and Computa-
tion, 3:281?332.
Crouch, Richard S. and Tracy Holloway King. 2006.
Semantics via f-struecture rewriting. In Proceed-
ings of LFG06 Conference.
Crouch, Dick. 2005. Packed rewriting for mapping se-
mantics to kr. In In Proceedings Sixth International
Workshop on Computational Semantics.
Egg, Markus, Alexander Koller, and Joachim Niehren.
2001. The constraint language for lambda struc-
tures. Journal of Logic, Language, and Information
Vol 10 (4), 2001, pp.457-485, 10:457?485.
Finkel, Jenny Rose, Christopher D. Manning, and An-
drew Y. Ng. 2006. Solving the problem of cas-
cading errors: approximate bayesian inference for
linguistic annotation pipelines. In EMNLP, pages
618?626, Morristown, NJ, USA.
Geman, Stuart and Mark Johnson. 2002. Dynamic
programming for parsing and estimation of stochas-
tic unification-based grammars. In ACL, pages 279?
286.
Klein, Dan and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In ACL, pages 423?430,
Morristown, NJ, USA.
Lesk, Michael. 1986. Automatic sense disambigua-
tion using machine readable dictionaries: how to
tell a pine cone from an ice cream cone. In SIG-
DOC ?86: Proceedings of the 5th annual interna-
tional conference on Systems documentation, pages
24?26, New York, NY, USA.
Maxwell III, John T. and Ronald M. Kaplan. 1981.
A method for disjunctive constraint satisfaction. In
Tomita, Masaru, editor, Current Issues in Pars-
ing Technology, pages 173?190. Kluwer Academic
Publishers, Dordrecht.
Patwardhan, Siddharth, Satanjeev Banerjee, and Ted
Pedersen. 2005. Senserelate:: Targetword-A gen-
eralized framework for word sense disambiguation.
In ACL.
Pearl, Judea. 1988. Probabilistic Reasoning in In-
telligent Systems: Networks of Plausible Inference.
Morgan-Kaufmann.
Punyakanok, Vasin, Dan Roth, and Wen tau Yih. 2005.
The necessity of syntactic parsing for semantic role
labeling. In Kaelbling, Leslie Pack and Alessandro
Saffiotti, editors, IJCAI, pages 1117?1123. Profes-
sional Book Center.
Regneri, Michaela, Markus Egg, and Alexander
Koller. 2008. Efficient processing of underspecified
discourse representations. In HLT, pages 245?248,
Morristown, NJ, USA.
Reyle, Uwe. 1995. Underspecified discourse repre-
sentation structures and their logic. Logic Journal
of the IGPL, 3(2-3):473?488.
Richardson, Matthew and Pedro Domingos. 2006.
Markov logic networks. Kluwer Academic Publish-
ers.
Riezler, Stefan, Tracy H. King, Ronald M. Kaplan,
Richard S. Crouch, John T. Maxwell III, and Mark
Johnson. 2002. Parsing the wall street journal us-
ing a lexical-functional grammar and discriminative
estimation techniques. In ACL, pages 271?278.
Schilder, Frank. 1998. An underspecified seg-
mented discourse representation theory (USDRT).
In COLING-ACL, pages 1188?1192.
Sutton, Charles and Andrew McCallum. 2005. Joint
parsing and semantic role labeling. In CONLL,
pages 225?228, Morristown, NJ, USA.
Wellner, Ben, Andrew McCallum, Fuchun Peng, and
Michael Hay. 2004. An integrated, conditional
model of information extraction and coreference
with application to citation matching. In UAI, pages
593?601, Arlington, Virginia, United States.
589
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 10?14,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Building an end-to-end text reading system based on a packed representation
Doo Soon Kim
Dept. of Computer Science
University of Texas
Austin, TX, 78712
onue5@cs.utexas.edu
Ken Barker
Dept. of Computer Science
University of Texas
Austin, TX, 78712
kbarker@cs.utexas.edu
Bruce Porter
Dept. of Computer Science
University of Texas
Austin, TX, 78712
porter@cs.utexas.edu
Abstract
We previously proposed a packed graphical
representation to succinctly represent a huge
number of alternative semantic representa-
tions of a given sentence. We also showed that
this representation could improve text inter-
pretation accuracy considerably because the
system could postpone resolving ambiguity
until more evidence accumulates. This paper
discusses our plan to build an end-to-end text
reading system based on our packed represen-
tation.
1 Introduction
Our goal is to build an end-to-end text understanding
system by assembling together existing components
for parsing, semantic interpretation, co-reference
resolution and so on. Commonly, these components
are combined in a pipeline in which each one passes
forward a single best interpretation (see (a) in fig. 1).
Although this approach is relatively straightforward,
it can suffer from overly aggressive pruning; a com-
ponent might prune those interpretations that down-
stream components might have been able to recog-
nize as correct. Similarly, a component might prune
an interpretation that would be validated by reading
subsequent texts. The system?s accuracy would al-
most certainly improve if it were able to delay prun-
ing until sufficient evidence accumulates to make a
principled commitment.
There is a na??ve way of delaying pruning deci-
sions in a pipelined architecture: each component
passes forward not just a single interpretation, but
multiple alternatives, thereby creating multiple in-
terpretation paths (see (b) in fig 1). Then, the system
might choose the best interpretation at the last step
of the pipeline. However, this approach is intractable
due to the combinatorial explosion in the number of
interpretation paths.
In previous work (Kim et al, 2010), we pro-
posed an alternative approach in which each compo-
nent passes forward multiple interpretations which
are compressed into an intensional representation
that we call a packed graphical (PG) representation
(see (c) in fig. 1). Our experiment showed that the
approach could improve the interpretation accuracy
considerably by delaying ambiguity resolution while
avoiding combinatorial explosion.
In this paper, we discuss our plan to build an end-
to-end text understanding system using the PG rep-
resentation. We first introduce the language inter-
pretation system we are currently building, which
produces a PG representation from the parse of each
sentence. Then, we propose an architecture for an
end-to-end reading system that is based on the PG
representation. The architecture allows the system
to improve as it acquires knowledge from reading
texts.
In the following sections, we briefly describe the
PG representation and its disambiguation algorithm
(see (Kim et al, 2010) for details). Then, we present
the plan and the current status in the development of
an end-to-end text understanding system.
2 Packed graphical representation
The PG representation compresses a huge number
of alternative interpretations by locally represent-
10
Parser WSD SI
(a) single interpretation, single component
Parser WSD SI
WSD
WSD
?
SI
SI
SI
SI
?
(b) single interpretation, multiple components
Parser WSD SI
(c) single PG representation, single component
    
	


	





 	




  













Figure 1: The three different architectures for text understanding system: In (a), each component passes forward a
single interpretation. (b) can improve (a) by considering multiple interpretation paths, but suffers from combinatorial
explosion. (c) is our approach in which the system considers multiple alternative interpretations (in contrast to (a))
while avoiding combinatorial explosion by packing the alternatives (in contrast to (b)).
ing common types of ambiguities and other types
of constraints among the interpretations. Section 2.1
presents these ambiguity and constraint representa-
tions. Section 2.2 introduces an algorithm which
aims to resolve the ambiguities captured in a PG rep-
resentation.
2.1 Representation
Fig. 2 shows a PG representation produced from the
interpretation of the following sentence:
S1 : The engine ignites the gasoline with its spark
plug.
With this example, we will explain the ambigu-
ity representations and the other types of constraints
expressed in the PG representation.
Type ambiguity. Ambiguity in the assignment of
a type for a word. In PG1, for example, the node
engine-2a (corresponding to the word ?engine?) has
type annotation [LIVING-ENTITY .3 | DEVICE .7].
It means that the two types are candidates for the
type of engine-2a and their probabilities are respec-
tively .3 (Living-Entity) and .7 (Device) .
Relational ambiguity. Ambiguity in the assign-
ment of semantic relation between nodes. The edge
from ignite-3 to engine-2a in PG1 has relation anno-
tation <agent .6 | location .4>. It means that engine-
2a is either agent (probability .6) or location (prob-
ability .4) of ignite-3.
Structural ambiguity. It represents structural al-
ternatives in different interpretations. In PG1, for
example, D and E represent an ambiguity of prepo-
sitional phrase attachment for ?with its spark plug?;
Figure 2: The PG representation for S1 (PG1)
the phrase can be attached to ?ignites? (D) or ?spark
plug? (E). The annotation {D .3 | E .7} means either
D or E (not both) is correct and the probability of
each choice is respectively .3 and .7.
Co-reference ambiguity. A ?co-reference? edge
represents a possibility of co-reference between two
nodes. For example, the edge labeled <coref .7>
represents that the probability of engine-2a and its-
7a being co-referent is .7.
Besides ambiguity representations above, the
PG representation can also represent dependencies
among different interpretations.
Simple dependency. It represents that the ex-
istence of one interpretation depends on the exis-
tence of another. For example, A ? C means that
if LIVING-ENTITY is found to be a wrong type for
engine-2a (by subsequent evidence), the agent rela-
tion should be discarded, too.
Mutual dependency. It represents that the in-
terpretations in a mutual dependency set depend
on one another ? if any interpretation in the set is
11
found to be wrong or correct (by subsequent evi-
dence), the others should also be rejected or con-
firmed. For example, the box labeled B means that
if either (engine-2a type DEVICE) or (ignite-3a lo-
cation engine-2a) is confirmed or rejected, the other
interpretation should be confirmed or rejected.
Formally, the PG representation can be repre-
sented as a list of
? semantic triples ? e.g., (ignite-3a type BURN),
(ignite-3a instrument spark-plug-9a)
? macros ? e.g., the symbol A refers to (ignite-3a
agent engine-2a)
? constraints ? e.g., A depends on C,
D (.3) is exclusive to E (.7)
2.2 Disambiguating ambiguities in a PG
representations
In this section, we briefly explain how our disam-
biguating algorithm resolves ambiguities in a PG
representation. For details, please see (Kim et al,
2010).
The PG representation allows the system to de-
lay commitment to an interpretation (by explicitly
representing ambiguities) until enough evidence ac-
crues to disambiguate. One source of such evidence
is the other texts with redundant content. For a sen-
tence which is hard to interpret, there may be other
texts which describe the same content, but in ways
that the system can better interpret. These new reli-
able interpretations can be used to disambiguate the
original unreliable interpretations. Our algorithm is
based on this approach of combining multiple PG
representations to resolve their ambiguities.
The disambiguation algorithm uses graph match-
ing. The algorithm aligns two PG representations to
identify their redundant subgraphs (redundant por-
tions of the interpretations), then increases the con-
fidence scores of these subgraphs because the same
interpretation was derived from two independent
sentences (on the same topic). When the confidence
scores reach a high or low threshold, the associated
interpretations are confirmed or pruned. Confirming
or pruning one interpretation may lead to confirming
or pruning others. For example, the dependents of a
pruned interpretation should also be pruned.
Figure 3: The PG representation for S2 (PG2), ?The en-
gine?s spark plug combusts gasoline?
To illustrate the algorithm, we will show how PG1
(fig. 2) is merged with PG2 (fig. 3) to resolve their
ambiguities.
1. engine-2 in PG1 is aligned with engine-1 in
PG2. This operation chooses Device as the type
of engine-2 (i.e., it discards Living-Entity) be-
cause Device is favored in both nodes
2. Deleting LIVING-ENTITY causes deletion of
the agent edge between ignite-3a and engine-
2a due to the dependency constraint A ? C,
(meaning agent (in A) depends on the existence
of LIVING-ENTITY (in C)).
3. Co-reference between engine-2a and its-7a is
greedily confirmed because merging the two
nodes enables the alignment of (its-7a has-part
spark-plug-8a) with (Engine-1b has-part spark-
plug-3b).
4. The algorithm aligns (ignite-3a instrument
spark-plug-8a) with (combust-5b instru-
ment spark-plug-3b), because ignite-3a and
combust-5b share the same type, [BURN].
This operation increases the score of D (the
structure corresponding to PP attachment of
?with its spark plug? to ?ignite?) over E (the
structure corresponding to attachment of ?with
its spark plug? to ?gasoline?).
3 Taking advantage of the PG
representation in an end-to-end system
Our experiment showed that, for ten texts with re-
dundant content, our approach improved the inter-
pretation accuracy by 10% (Kim et al, 2010). En-
couraged by this result, we present our on-going
work and future plans.
12
3.1 Producing PG representation
We are currently constructing a fully automated lan-
guage interpretation system to produce PG represen-
tations from English sentences. The system will be
able to maintain all possible interpretations gener-
ated at each step (including parsing, word sense dis-
ambiguation (WSD) and semantic relation assign-
ment) and represent them using the PG representa-
tion. This is straightforward for WSD and semantic
relation assignment because most off-the-shelf soft-
ware (e.g., (Patwardhan et al, 2005) (Punyakanok
et al, 2005)) outputs a list of candidate choices and
confidence scores for type and relational ambigui-
ties. (Kim et al, 2010) describes a prototype system
implemented with these WSD and semantic assign-
ment components.
However, ambiguities in parsing are more dif-
ficult because it is hard to efficiently identify
structural differences among various parses. We
are currently developing an algorithm (similar to
(Schiehlen, 1996)) which converts a parse forest (the
ambiguity-preserving chart built during PCFG pars-
ing) (Tomita, 1986) into the syntactic-level PG rep-
resentation (as shown in fig. 4). We plan to imple-
ment this algorithm in the Stanford Parser (Klein and
Manning, 2003) and to evaluate it along the follow-
ing dimensions.
First, we will measure the improvement in parsing
accuracy that results from delaying commitment to
a single best parse.
Second, even though the PG representation
achieves substantial compression, its size is still
bounded. The parser might generate more interpre-
tations than will fit within the bound. We plan to
handle this problem in the following way. When a
PG representation grows to the bound, the system
applies the components downstream of the parser to
the candidate parses. Because these components use
additional sources of knowledge, including knowl-
edge derived from previous reading (Clark and Har-
rison, 2009), they might be able to prune some can-
didate interpretations. In this way, a part of a sen-
tence may be processed early while the other parts
are left unprocessed, in contrast with the traditional
approach of fully processing each sentence before
starting with the next.
Figure 4: Syntactic-level PG representation for S1: the
structural ambiguity represents an ambiguity of attaching
the preposition, ?with its spark plug?.
3.2 System Architecture
The PG representation and its disambiguating algo-
rithm allow an interesting property in a text under-
standing system: the system?s interpretation capa-
bility could increase as it acquires knowledge from
texts. This property can be shown in two ways. First,
the ambiguities of the current text could be resolved
later when the system reads subsequent texts. Sec-
ond, the knowledge acquired from the prior texts
could be used to resolve the ambiguities of the cur-
rent text. Fig. 5 shows an architecture that exhibits
this property.
Given a text, or a set of texts on the same topic,
the language interpreter generates a PG representa-
tion. Then, the knowledge integration component
(KI) adds the PG representation into the knowledge
base. For a first text, the PG representation is simply
put into the knowledge base. For subsequent texts,
KI merges the subsequent PG representations with
the PG representation in the knowledge base. This
step may resolve ambiguities in the PG representa-
tion maintained in the knowledge base.
When the language interpreter confronts an ambi-
guity, it has two choices: it either (a) locally repre-
sents the ambiguity in the PG representation or (b)
asks the RESOLVER to resolve the ambiguity. When
the RESOLVER is called, it searches the knowledge
base for information to resolve the ambiguity. If
this is unsuccessful, it uses the information retrieval
module (TEXT MINER) to find relevant documents
from external sources which might resolve the am-
biguity. The documents are added in the Text Queue
to be read subsequently. In the near future, we plan
to evaluate the ability of the KI and Resolver mod-
ules to resolve ambiguities as the system reads more
texts.
13
Parser SemanticInterpreter
Knowledge 
Base
KI
Language Interpreter
Text 
Queue
Text Miner
Resolver
Figure 5: Architecture
4 Summary
In this paper, we discuss the development of an end-
to-end text understanding system based on a packed
representation. With this representation, the system
can delay ambiguity resolution while avoiding com-
binatorial explosion, thereby effectively improving
the accuracy of text interpretation.
References
Peter Clark and Philip Harrison. 2009. Large-scale ex-
traction and use of knowledge from text. In Yolanda
Gil and Natasha Fridman Noy, editors, K-CAP, pages
153?160. ACM.
Doo Soon Kim, Ken Barker, and Bruce Porter. 2010.
Improving the quality of text understanding by delay-
ing ambiguity resolution. Technical Report TR-10-12,
University of Texas at Austin.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proc. of ACL.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-
ersen. 2005. Senserelate:: Targetword-A generalized
framework for word sense disambiguation. In ACL.
Vasin Punyakanok, Dan Roth, and Wen tau Yih. 2005.
The necessity of syntactic parsing for semantic role la-
beling. In IJCAI.
Michael Schiehlen. 1996. Semantic construction from
parse forests. In COLING, pages 907?912.
Masaru Tomita. 1986. Efficient Parsing for Natural Lan-
guage ? A Fast Algorithm for Practical Systems. Int.
Series in Engineering and Computer Science. Kluwer,
Hingham, MA.
14
