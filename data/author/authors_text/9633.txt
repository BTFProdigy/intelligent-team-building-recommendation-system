Proceedings of the 12th Conference of the European Chapter of the ACL, pages 130?138,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Lexical Morphology in Machine Translation: a Feasibility Study 
 
Bruno Cartoni 
University of Geneva 
cartonib@gmail.com 
 
Abstract 
This paper presents a feasibility study for im-
plementing lexical morphology principles in a 
machine translation system in order to solve 
unknown words. Multilingual symbolic treat-
ment of word-formation is seducing but re-
quires an in-depth analysis of every step that 
has to be performed. The construction of a 
prototype is firstly presented, highlighting the 
methodological issues of such approach. Sec-
ondly, an evaluation is performed on a large 
set of data, showing the benefits and the limits 
of such approach. 
1 Introduction 
Formalising morphological information to deal 
with morphologically constructed unknown 
words in machine translation seems attractive, 
but raises many questions about the resources 
and the prerequisites (both theoretical and practi-
cal) that would make such symbolic treatment 
efficient and feasible. In this paper, we describe 
the prototype we built to evaluate the feasibility 
of such approach. We focus on the knowledge 
required to build such system and on its evalua-
tion. First, we delimit the issue of neologisms 
amongst the other unknown words (section 2), 
and we present the few related work done in 
NLP research (section 3). We then explain why 
implementing morphology in the context of ma-
chine translation (MT) is a real challenge and 
what kind of aspects need to be taken into ac-
count (section 4), and we show that translating 
constructed neologisms is not only a mechanical 
decomposition but requires more fine-grained 
analysis. We then describe the methodology de-
veloped to build up a prototyped translator of 
constructed neologisms (section 5) with all the 
extensions that have to be made, especially in 
terms of resources. Finally, we concentrate on 
the evaluation of each step of the process and on 
the global evaluation of the entire approach (sec-
tion 6). This last evaluation highlights a set of 
methodological criteria that are needed to exploit 
lexical morphology in machine translation. 
2 Issues 
Unknown words are a problematic issue in any 
NLP tool. Depending on the studies (Ren and  
Perrault 1992; Maurel 2004), it is estimated that 
between 5 and 10 % of the words of a text writ-
ten in ?standard? language are unknown to lexi-
cal resources. In a MT context (analysis-transfer-
generation), unknown words remain not only 
unanalysed but they cannot be translated, and 
sometimes they also stop the translation of the 
whole sentence. 
Usually, three main groups of unknown words 
are distinguished: proper names, errors, and ne-
ologisms, and the possible solution highly de-
pends on the type of unknown word to be solved. 
In this paper, we concentrate on neologisms 
which are constructed following a morphological 
process. 
The processing of unknown ?constructed ne-
ologisms? in NLP can be done by simple guess-
ing (based on the sequence of final letters). This 
option can be efficient enough when the task is 
only tagging, but in a multilingual context (like 
in MT), dealing with constructed neologisms 
implies a transfer and a generation process that 
require a more complex formalisation and im-
plementation. In the project presented in this pa-
per, we propose to implement lexical morphol-
ogy phenomena in MT. 
3 Related work 
Implementing lexical morphology in a MT con-
text has seldom been investigated in the past, 
probably because many researchers share the 
following view: ?Though the idea of providing 
rules for translating derived words may seem 
attractive, it raises many problems and so it is 
currently more of a research goal for MT than a 
practical possibility? (Arnold, Balkan et al 
1994). As far as we know, the only related pro-
ject is described in (Gdaniec, Manandise et al 
2001), where they describe a project of imple-
mentation of rules for dealing with constructed 
words in the IBM MT system. 
130
Even in monolingual contexts, lexical mor-
phology is not very often implemented in NLP. 
Morphological analyzers like the ones described 
in (Porter 1980; Byrd 1983; Byrd, Klavans et al 
1989; Namer 2005) propose more or less deeper 
lexical analyses, to exploit that dimension of the 
lexicon. 
4 Proposed solution 
Since morphological processes are regular and 
exist in many languages, we propose an approach 
where constructed neologisms in source lan-
guage (SL) can be analysed and their translation 
generated in a target language (TL) through the 
transfer of the constructional information. 
For example, a constructed neologism in one 
language (e.g. ricostruire in Italian) should 
firstly be analysed, i.e. find (i) the rule that pro-
duced it (in this case <reiteration rule>) and (ii) 
the lexeme-base which it is constructed on 
(costruire, with all morphosyntactic and transla-
tional information). Secondly, through a transfer 
mechanism (of both the rule and the base), a 
translation can be generated by rebuilding a con-
structed word, (in French reconstruire, Eng: to 
rebuild). On a theoretical side, the whole process 
is formalised into bilingual Lexeme Formation 
Rules (LFR), as explained below in section 4.3. 
Although this approach seems to be simple 
and attractive, feasibility studies and evaluation 
should be carefully performed. To do so, we built 
a system to translate neologisms from one lan-
guage into another. In order to delimit the project 
and to concentrate on methodological issues, we 
focused on the prefixation process and on two 
related languages (Italian and French). Prefixa-
tion is, after suffixation, the most productive 
process of neologism, and prefixes can be more 
easily processed in terms of character strings. 
Regarding the language, we choose to deal with 
the translation of Italian constructed neologisms 
into French. These two languages are historically 
and morphologically related and are conse-
quently more ?neighbours? in terms of neolo-
gism coinage. 
In the following, we firstly describe precisely 
the phenomena that have to be formalized and 
then the prototype built up for the experiment. 
4.1 Phenomena to be formalized 
Like in any MT project, the formalisation work 
has to face different issues of contrastivity, i.e. 
highlighting the divergences and the similarities 
between the two languages. 
In the two languages chosen for the experi-
ment, few divergences were found in the way 
they construct prefixed neologisms. However, in 
some cases, although the morphosemantic proc-
ess is similar, the item used to build it up (i.e. the 
affixes) is not always the same. For example, to 
coin nouns of the spatial location ?before?, 
where Italian uses the prefix retro, French uses 
r?tro and arri?re. A deeper analysis shows that 
Italian retro is used with all types of nouns, 
whereas in French, r?tro only forms processual 
nouns (derived from verbs, like r?trovision, 
r?troprojection). For the other type of nouns 
(generally locative nouns), arri?re is used (ar-
ri?re-cabine, arri?re-cour). 
Other problematic issues appear when there is 
more than one prefix for the same LFR. For ex-
ample, the rule for ?indeterminate plurality? pro-
vides in both languages a set of two prefixes 
(multi/pluri in Italian and multi/pluri in French) 
with no known restrictions for selecting one or 
the other (e.g. both pluridimensionnel and multi-
dimensionnel are acceptable in French). For 
these cases, further empirical research have to be 
performed to identify restrictions on the rule. 
Another important divergence is found in the 
prefixation of relational adjectives. Relational 
adjectives are derived from nouns and designate 
a relation between the entity denoted by the noun 
they are derived from and the entity denoted by 
the noun they modify. Consequently, in a pre-
fixation such as anticostituzionale, the formal 
base is a relational adjective (costituzionale), but 
the semantic base is the noun the adjective is de-
rived from (costituzione). The constructed word 
anticostituzionale can be paraphrased as ?against 
the constitution?. Moreover, when the relational 
adjective does not exist, prefixation is possible 
on a nominal base to create an adjective (squadra 
antidroga). In cases where the adjective does 
exist, both forms are possible and seem to be 
equally used, like in the Italian collaborazione 
interuniversit? / collaborazione interuniversi-
taria. From a contrastive point of view, the pre-
fixation of relational adjectives exists in both 
languages (Italian and French) and in both these 
languages prefixing a noun to create an adjective 
is also possible (anticostituzione (Adj)). But we 
notice an important discrepancy in the possibility 
of constructing relational adjectives (a rough es-
timation performed on a large bilingual diction-
ary (Garzanti IT-FR (2006)) shows that more 
than 1 000 Italian relational adjectives have no 
equivalent in French (and are generally translated 
with a prepositional phrase).  
131
All these divergences require an in-dept analy-
sis but can be overcome only if the formalism 
and the implementation process are done follow-
ing a rigorous methodology. 
4.2 The prototype 
In order to evaluate the approach described 
above and to concretely investigate the ins and 
outs of such implementation, we built up a proto-
type of a machine translation system specialized 
for constructed neologisms. This prototype is 
composed of two modules. The first one checks 
every unknown word to see if it is potentially 
constructed, and if so, performs a morphological 
analysis to individualise the lexeme-base and the 
rule that coined it. The second module is the ac-
tual translation module, which analyses the con-
structed neologism and generates a possible 
translation. 
 
Figure 1: Prototype 
The whole prototype relies on one hand on 
lexical resources (two monolingual and one bi-
lingual) and on a set of bilingual Lexeme Forma-
tion Rules (LFR). These two sets of information 
helps the analysis and the generation steps. When 
a neologism is looked-up, the system checks if it 
is constructed with one of the LFRs and if the 
lexeme-base is in the lexicon. If it is the case, the 
transfer brings the relevant morphological and 
lexical information in the target language. The 
generation step constructs the translation equiva-
lent, using the information provided by the LFR 
and the lexical resources. Consequently, the 
whole system relies on the quality of both the 
lexical resources and the LFR. 
4.3 Bilingual Lexeme Formation Rules  
The whole morphological process in the system 
is formalised through bilingual Lexeme Forma-
tion Rules. Their representation is inspired by 
(Fradin 2003) as shown in figure 2 in the rule of 
reiterativity. 
Such rules match together two monolingual 
rules (to be read in columns). Each monolingual 
rule describes a process that applies a series of 
instructions on the different sections of the lex-
eme : the surface section (G and F), the syntactic 
category (SX) and the semantic (S) sections. In 
this theoretical framework, affixation is only one 
of the instructions of the rule (the graphemic and 
phonological modification), and consequently, 
affixes are called ?exponent? of the rule. 
 Italian French 
 input input 
(G) Vit Vfr 
(F) /Vit/ /Vfr/ 
(SX) cat :v cat :v 
(S) Vit'(...) Vfr'(...) 
 
 ?  
 output output 
(G) riVit reVfr 
(F) /ri/?/Vit/ /??/?/Vfr/ 
(SX) cat :v cat :v  
(S) reiterativity (Vit'(...)) reiterativity (Vfr'(...)) 
where Vit' = Vfr', translation equivalent 
This formalisation is particularly useful in a 
bilingual context for rules that have more than 
one prefix in both languages: more than one affix 
can be declared in one single rule, the selection 
being made according to different constraints or 
restrictions. For example, the rule for ?indeter-
minate plurality? explained in section 4.1 can be 
formalised as follows: 
 Italian French 
 input input 
(G) Xit Xfr 
(F) /Xit/ /Xfr/ 
(SX) cat :n cat :n 
(S) Xit'(...) Xfr'(...) 
 
 ?  
 output output 
(G) multi/pluriXit multi/pluriXfr 
(F) /multi/pluri/?/Xit/ /m?lti/plyri/?/Xfr/ 
(SX) cat :n cat :n  
(S) indet. plur. (Xit'(...)) indet. plur. (Xfr'(...)) 
where Xit' = Xfr', translation equivalent 
Figure 3: Bilingual LFR of indeterminate plurality 
In this kind of rules with ?multiple expo-
nents?, the two possible prefixes are declared in 
the surface section (G and F). The selection is a 
monolingual issue and cannot be done at the 
theoretical level. 
Such rules have been formalised and imple-
mented for the 56 productive prefixes of Italian 
(Iacobini 2004)1, with their French translation 
equivalent. However, finding the translation 
equivalent for each rule requires specific studies 
                                                
1
 i.e. a, ad, anti, arci, auto, co, contro, de, dis, ex, extra, in, 
inter, intra, iper, ipo, macro, maxi, mega, meta, micro, mini, 
multi, neo, non, oltre, onni, para, pluri, poli, post, pre, pro, 
retro, ri,  s, semi, sopra, sotto, sovra, stra, sub, super, trans, 
ultra, vice, mono, uni, bi, di, tri, quasi, pseudo. 
 
IT neologism 
FR neologism 
analysis 
LFR 
generation 
Lexica 
Figure 2: Bilingual LFR of reiterativity 
132
of the morphological system of both languages in 
a contrastive perspective. 
The following section briefly summarises the 
contrastive analysis that has been performed to 
acquire this type of contrastive knowledge. 
4.4 Knowledge acquisition of bilingual LFR 
As in any MT system, the acquisition of bilin-
gual knowledge is an important issue. In mor-
phology, the method should be particularly accu-
rate to prevent any methodological bias. To for-
malise translation rules for prefixed neologisms, 
we adopt a meaning-to-form approach, i.e. dis-
covering how a constructed meaning is morpho-
logically realised in two languages. 
We build up a tertium comparationis (a neu-
tral platform, see (James 1980) for details) that 
constitute a semantic typology of prefixation 
processes. This typology aims to be universal 
and therefore applicable to all the languages con-
cerned. On a practical point of view, the typol-
ogy has been built up by summing up various 
descriptions of prefixation in various languages 
(Montermini 2002; Iacobini 2004; Amiot 2005). 
We end up with six main classes: location, 
evaluation, quantitative, modality, negation and 
ingressive. The classes are then subdivided ac-
cording to sub-meanings: for example, location 
is subdivided in temporal and spatial, and within 
spatial location, a distinction is made between 
different positions (before, above, below, in 
front, ?).  
Prefixes of both languages are then literally 
?projected? (or classified) onto the tertium. For 
each terminal sub-class, we have a clear picture 
of the prefixes involved in both languages. For 
example, the LFR presented in figure 1 is the 
result of the projection of the Italian prefix (ri) 
and the French one (re) on the sub-class reitera-
tivity, which is a sub-class of modality. 
At the end of the comparison, we end up with 
more than 100 LFRs (one rule can be reiterated 
according the different input and output catego-
ries). From a computing point of view, con-
straints have to be specified and the lexicon has 
to be adapted consequently. 
5 Implementation 
Implementation of the LFR is set up as a data-
base, from where the program takes the informa-
tion to perform the analysis, the transfer and the 
generation of the neologisms. In our approach, 
LFRs are simply declared in a tab format data-
base, easily accessible and modifiable by the 
user, as shown below: 
 
Figure 4: Implemented LFRs 
Implemented LFRs describe (i) the surface 
form of the Italian prefix to be analysed, (ii) the 
category of the base, (iii) the category of the de-
rived lexeme (the output), (iv) a reference to the 
rule implied and (v) the French prefix(es) for the 
generation. 
The surface form in (i) should sometimes take 
into account the different allomorphs of one pre-
fix. Consequently, the rule has to be reiterated in 
order to be able to recognize any forms (e.g. the 
prefix in has different forms according to the ini-
tial letter of the base, and four rules have to be 
implemented for the four allomorphs (in, il, im, 
ir)). In some other cases, the initial consonant is 
doubled, and the algorithm has to take this phe-
nomenon into account.  
In (ii), the information of the category of the 
base has been ?overspecified?, to differentiate 
qualitative and relational adjectives, and deverbal 
nouns and the other ones (a_rel/a or 
n_dev/n). These overspecifications have two 
objectives: optimizing the analysis performance 
(reducing the noise of homographic character 
strings that look like constructed neologisms but 
that are only misspellings - see below in the 
evaluation section), and refining the analysis, i.e. 
selecting the appropriate LFR and, consequently, 
the appropriate translation. 
To identify relational adjectives and deverbal 
nouns, the monolingual lexicon that supports the 
analysis step has to be extended. Thereafter, we 
present the symbolic method we used to perform 
such extension. 
5.1 Extension of the monolingual lexicon 
Our MT prototype relies on lexical resources: it 
aims at dealing with unknown words that are not 
in a Reference lexicon and these unknown words 
are analyzed with lexical material that is in this 
lexicon. 
From a practical point of view, our prototype 
is based on two very large monolingual data-
arci a a 2.1.2 archi 
arci n n 2.1.2 archi 
[?] 
pro a_rel a 1.1.10 pro 
pro n a 1.1.10 pro 
[?] 
ri v v 6.1 re 
ri n_dev n 6.1 re 
[?] 
 
133
bases (Mmorph (Bouillon, Lehmann et al 1998)) 
for Italian and French, that contain only morpho-
syntactic information, and on one bilingual lexi-
con that has been built semi-automatically for the 
use of the experiment. But the monolingual 
lexica have to be adapted to provide specific in-
formation necessary for dealing with morpho-
logical process. 
As stated above, identifying the prefix and the 
base is not enough to provide a proper analysis 
of constructed neologisms which is detailed 
enough to be translated. The main information 
that is essential for the achievement of the proc-
ess is the category of the base, which has to be 
sometimes ?overspecified?. Obviously, the Ital-
ian reference lexicon does not contain such in-
formation. Consequently, we looked for a simple 
way to automatically extend the Italian lexicon. 
For example, we looked for a way to automati-
cally link relational adjectives with their noun 
bases. 
Our approach tries to take advantage of only 
the lexicon, without the use of any larger re-
sources. To extend the Italian lexicon, we simply 
built a routine based on the typical suffixes of 
relational adjectives (in Italian:  -ale,  -are, -ario, 
-ano, -ico, -ile, -ino, -ivo, -orio, -esco, -asco, 
-iero, -izio, -aceo (Wandruszka 2004)). For every 
adjective ending with one of these suffixes, the 
routine looks up if the potential base corresponds 
to a noun in the rest of the lexicon (modulo some 
morphographemic variations). For example, the 
routine is able to find links between adjectives 
and base nouns such as ambientale and ambiente, 
aziendale and azienda, cortisonica and cortisone 
or contestuale and contesto. Unfortunately, this 
kind of automatic implementation does not find 
links between adjectives made from the learned 
root of the noun, (prandiale  pranzo, bellico 
 guerra). 
This automatic extension has been evaluated. 
Out of a total of more than 68 000 adjective 
forms in the lexicon, we identified 8 466 rela-
tional adjectives. From a ?recall? perspective, it 
is not easy to evaluate the coverage of this exten-
sion because of the small number of resources 
containing relational adjectives that could be 
used as a gold standard. 
A similar extension is performed for the 
deverbal aspect, for the lexicon should also dis-
tinguish deverbal noun. From a morphological 
point of view, deverbalisation can be done trough 
two main productive processes: conversion (a 
command  to command) and suffixation. If the 
first one is relatively difficult to implement, the 
second one can be easily captured using the typi-
cal suffixes of such processes. Consequently, we 
considere that any noun ending with suffixes like 
ione, aggio,or mento are deverbal. 
Thanks to this extended lexicon, overspecified 
input categories (like a_rel for relational ad-
jective or n_dev for deverbal noun) can be 
stated and exploited in the implemented LFR as 
shown in figure 4. 
5.2 Applying LFRs to translate neologisms 
Once the prototyped MT system was built and 
the lexicon adapted, it was applied to a set of 
neologisms (see section 6 for details). For exam-
ple, unknown Italian neologisms such as arci-
contento, ridescrizione, deitalianizzare, were 
automatically translated in French: archi-content, 
redescription, d?sitalianiser. 
The divergences existing in the LFR of <loca-
tive position before> are correctly dealt with, 
thanks to the correct analysis of the base. For 
example, in the neologism retrobottega, the lex-
eme-base is correctly identified as a locative 
noun, and the French equivalent is constructed 
with the appropriate prefix (arri?re-boutique), 
while in retrodiffusione, the base is analysed as 
deverbal, and the French equivalent is correctly 
generated (r?trodiffusion). 
For the analysis of relational adjectives, the 
overspecification of the LFRs and the extension 
of the lexicon are particularly useful when there 
is no French equivalent for Italian relational ad-
jectives because the corresponding construction 
is not possible in the French morphological sys-
tem. For example, the Italian relational adjective 
aziendale (from the noun azienda, Eng: com-
pany) has no adjectival equivalent in French. The 
Italian prefixed adjective interaziendale can only 
be translated in French by using a noun as the 
base (interentreprise). This translation equivalent 
can be found only if the base noun of the Italian 
adjective is found (interaziendale, in-
ter+aziendale  azienda, azienda = entreprise, 
 interentreprise). The same process has been 
applied for the translation of precongressuale, 
post-transfuzionale by pr?congr?s, post-
transfusion. 
Obviously, all the mechanisms formalised in 
this prototype should be carefully evaluated. 
6 Evaluation 
The advantages of this approach should be care-
fully evaluated from two points of view: the 
134
evaluation of the performance of each step and of 
the feasibility and portability of the system. 
6.1 corpus 
As previously stated, the system is intended to 
solve neologisms that are unknown from a lexi-
con with LFRs that exploit information contained 
in the lexicon. To evaluate the performance of 
our system, we built up a corpus of unknown 
words by confronting a large Italian corpus from 
journalistic domain (La Repubblica Online 
(Baroni, Bernardini et al 2004)) with our refer-
ence lexicon for this language (see section 4.1 
above). We obtained a set of unknown words 
that contains neologisms, but also proper names 
and erroneous items. This set is submitted to the 
various steps of the system, where constructed 
neologisms are recognised, analysed and trans-
lated.  
6.2 Evaluation of the performance of the 
analysis 
As we previously stated, the analysis step can 
actually be divided into two tasks. First of all, the 
program has to identify, among the unknown 
words, which of them are morphologically con-
structed (and so analysable by the LFRs); sec-
ondly, the program has to analyse the constructed 
neologisms, i.e matching them with the correct 
LFRs and isolating the correct base-words. 
For the first task, we obtain a list of 42 673 
potential constructed neologisms. Amongst 
those, there are a number of erroneous words that 
are homographic to a constructed neologism. For 
example, the item progesso, a misspelling of 
progresso (Eng: progress), is erroneously ana-
lysed as the prefixation of gesso (eng: plaster) 
with the LFR in pro. 
In the second part of the processing, LFRs are 
concretely applied to the potential neologisms 
(i.e. constraints on categories and on over-
specified category, phonological constraints). 
This stage retains 30 376 neologisms. A manual 
evaluation is then performed on these outputs. 
Globally, 71.18 % of the analysed words are ac-
tually neologisms. But the performance is not the 
same for every rule. Most of them are very effi-
cient: among all the rules for the 56 Italian pre-
fixes, only 7 cause too many erroneous analyses, 
and should be excluded - mainly rules with very 
short prefixes (like a, di, s), that cause mistakes 
due to homograph. 
As explained above, some of the rules are 
strongly specified, (i.e. very constrained), so we 
also evaluate the consequence of some con-
straints, not only in terms of improved perform-
ance but also in terms of loss of information. In-
deed, some of the constraints specified in the rule 
exclude some neologisms (false negatives). For 
example, the modality LFRs with co and ri have 
been overspecified, requiring deverbal base-noun 
(and not just a noun). Adding this constraint im-
proves the performance of the analysis (i.e. the 
number of correct lexemes analysed), respec-
tively from 69.48 % to 96 % and from 91.21 % 
to 99.65 %. Obviously, the number of false nega-
tives (i.e. correct neologisms excluded by the 
constraint) is very large (between 50 % and 75 % 
of the excluded items). 
In this situation, the question is to decide 
whether the gain obtained by the constraints (the 
improved performance) is more important than 
the un-analysed items. In this context, we prefer 
to keep the more constrained rule. Un-analysed 
items remain unknown words, and the output of 
the analysis is almost perfect, which is an impor-
tant condition for the rest of the process (i.e. 
transfer and generation). 
6.3 Evaluation of the performance of the 
generation 
Generation can also be evaluated according to 
two points of view: the correctness of the gener-
ated items, and the improvement brought by the 
solved words to the quality of the translated sen-
tence. 
To evaluate the first aspect, many procedures 
can be put in place. The correctness of con-
structed words could be evaluated by human 
judges, but this kind of approach would raise 
many questions and biases: people that are not 
expert of morphology would judge the correct-
ness according to their degree of acceptability 
which varies between judges and is particularly 
sensitive when neologism is concerned. Ques-
tions of homogeneity in terms of knowledge of 
the domain and of the language are also raised. 
Because of these difficulties, we prefer to cen-
tre the evaluation on the existence of the gener-
ated neologisms in a corpus. For neologisms, the 
most adequate corpus is the Internet, even if the 
use of such an uncontrolled resource requires 
some precautions (see (Fradin, Dal et al 2007) 
for a complete debate on the use of web re-
sources in morphology). 
Concretely, we use the robot Golf (Thomas 
2008) that sends each generated neologism auto-
matically as a request on a search engine (here 
Google?) and reports the number of occurrences 
as captured by Google. This robot can be param-
135
eterized, for instance by selecting the appropriate 
language. 
Because of the uncontrolled aspect of the re-
source, we distinguish three groups of reported 
frequencies: 0 occurrence, less than 5 occur-
rences and more than 5. The threshold of 5 helps 
to distinguish confirmed existence of neologism 
(> 5) from unstable appearances (< 5), that are 
closed to hapax phenomena. 
The table below summarizes some results for 
some prefixed neologisms. 
 
Prefix tested forms 0 occ.  < 5 occ. > 5 occ. 
ri  391 8.2 % 5.6 % 86.2 % 
anti 1120 8.6 % 19.9 % 71.5 % 
de 114 2.6 % 3.5 % 93.9 % 
super 951 28 % 30 % 42 % 
pro 166 6.6 % 29.5 % 63.9 % 
?     
Table 1 : Some evaluation results 
Globally, most of the generated prefixed ne-
ologisms have been found in corpus, and most of 
the time with more than 5 occurrences. Unfound 
items are very useful, because they help to point 
out difficulties or miss-formalised processes. 
Most of the unfound neologisms were ill-
analysed items in Italian. Others were due to 
misuses of hyphens in the generation. Indeed, in 
the program, we originally implemented the use 
of the hyphen in French following the estab-
lished norm (i.e. a hyphen is required when the 
prefix ends with a vowel and the base starts with 
a vowel). But following this ?norm?, some forms 
were not found in corpus (for example antibra-
connier (Eng: antipoacher) reports 0 occur-
rence). When re-generated with a hyphen, it re-
ports 63 occurrences. This last point shows that 
in neology, usage does not stick always to the 
norm. 
The other problem raised by unknown words 
is that they decrease the quality of the translation 
of the entire sentence. To evaluate the impact of 
the translated unknown words on the translated 
sentence, we built up a test-suite of sentences, 
each of them containing one prefixed neologism 
(in bold in table 2). We then submitted the sen-
tences to a commercial MT system (Systran?) 
and recorded the translation and counted the 
number of mistakes (FR1 in table 2 below). On a 
second step, we ?feed? the lexicon of the transla-
tion system with the neologisms and their trans-
lation (generated by our prototype) and resubmit 
the same sentences to the system (FR2 in table 
2). 
For the 60 sentences of the test-suit (21 with 
an unknown verb, 19 with an unknown adjective 
and 20 with a unknown noun), we then counted 
the number of errors before and after the intro-
duction of the neologisms in the lexicon, as 
shown below (errors are underlined). 
IT Le defiscalizzazioni logiche di 17 Euro 
sono previste 
 
FR1 Le defiscalizzazioni logiques de 17 Euro 
sont pr?vus 
2 
FR2 Les d?fiscalisations logiques de 17 Euro 
sont pr?vues 
0 
Table 2: Example of a tested sentence 
For a global view of the evaluation, we classi-
fied in the table below the number of sentences 
according to the number of errors ?removed? 
thanks to the resolution of the unknown word. 
 
 0 -1 -2 -3 
Nouns  10 8 2 
Adjectives  18 1  
Verbs 2 14 3 2 
Table 3: Reduction of the number of errors/sentence 
Most of the improvements concern only a re-
duction of 1, i.e. only the unknown word has 
been solved. But it should be noticed that im-
provement is more impressive when the un-
known words are nouns or verbs, probably be-
cause these categories influence much more 
items in the sentence in terms of agreement. 
In two cases (involving verbs), errors are cor-
rected because of the translation of the unknown 
words, but at the same time, two other errors are 
caused by it. This problem comes from the fact 
that adding new words in the lexicon of the sys-
tem requires sometimes more information (such 
as valency) to provide a proper syntaxctic gen-
eration of the sentence. 
6.4 Evaluation of feasibility and portability 
The relatively good results obtained by the proto-
type are very encouraging. They mainly show 
that if the analysis step is performed correctly, 
the rest of the process can be done with not much 
further work. But at the end of such a feasibility 
study, it is useful to look objectively for the con-
ditions that make such results possible. 
The good quality of the result can be ex-
plained by the important preliminary work done 
(i) in the extension/specialisation of the lexicon, 
and (ii) in the setting up of the LFRs. The acqui-
sition of the contrastive knowledge in a MT con-
text is indeed the most essential issue in this kind 
of approach. The methodology we proposed here 
for setting these LFR proves to be useful for the 
136
linguist to acquire this specific type of knowl-
edge. 
Lexical morphology is often considered as not 
regular enough to be exploited in NLP. The 
evaluation performed in this study shows that it 
is not the case, especially in neologism. But in 
some cases, it is no use to ask for the impossible, 
and simply give up implementing the most inef-
ficient rules. 
We also show that the efficient analysis step is 
probably the main condition to make the whole 
system work. This step should be implemented 
with as much constraints as possible, to provide 
an output without errors. Such implementation 
requires proper evaluation of the impact of every 
constraint. 
It should also be stated that such implementa-
tion (and especially knowledge acquisition) is 
time-consuming, and one can legitimately ask if 
machine-learning methods would do the job. The 
number of LFRs being relatively restrained in 
producing neologisms, we can say that the effort 
of manual formalisation is worthwhile for the 
benefits that should be valuable on the long term. 
Another aspect of the feasibility is closely related 
to questions of ?interoperability?, because such 
implementation should be done within existing 
MT programs, and not independently as it was 
for this feasibility study. 
Other questions of portability should also be 
considered. As we stated, we chose two morpho-
logically related languages on purpose: they pre-
sent less divergences to deal with and allow con-
centrating on the method. However, the proposed 
method (especially that contrastive knowledge 
acquisition) can clearly be ported to another pair 
of languages (at least inflexional languages). It 
should also be noticed that the same approach 
can be applied to other types of construction. We 
mainly think here of suffixation, but one can 
imagine to use LFRs with other elements of for-
mation (like combining forms, that tend to be 
very ?international?, and consequently the mate-
rial for many neologisms). Moreover, the way 
the rules are formalised and the algorithm de-
signed allow easy reversibility and modification. 
7 Conclusion 
This feasibility study presents the benefit of im-
plementing lexical morphology principles in a 
MT system. It presents all the issues raised by 
formalization and implementation, and shows in 
a quantitative manner how those principles are 
useful to partly solve unknown words in machine 
translation. 
From a broader perspective, we show the 
benefits of such implementation in a MT system, 
but also the method that should be used to for-
malise this special kind of information. We also 
emphasize the need for in-dept work of knowl-
edge acquisition before actually building up the 
system, especially because contrastive morpho-
logical data are not as obvious as other linguistic 
dimensions. 
Moreover, the evaluation step clearly states 
that the analysis module is the most important 
issue in dealing with lexical morphology in mul-
tilingual context. 
The multilingual approach of morphology also 
paves the way for other researches, either in rep-
resentation of word-formation or in exploitation 
of multilingual dimension in NLP systems. 
References  
(2006) Garzanti francese : francese-italiano, italiano-
francese. I grandi dizionari Garzanti. Milano, Gar-
zanti Linguistica. 
Amiot, D. (2005) Between compounding and deriva-
tion: elements of word formation corresponding to 
prepositions. Morphology and its Demarcations. W. 
U. Dressler, R. Dieter and F. Rainer. Amsterdam, 
John Benjamins Publishing Company: 183-195. 
Arnold, D., L. Balkan, R. L. Humphrey, S. Meijer and 
L. Sadler (1994) Machine Translation.  An Intro-
ductory Guide. Manchester, NCC Blackwell. 
Baroni, M., S. Bernardini, F. Comastri, L. Piccioni, A. 
Volpi, G. Aston and M. Mazzoleni (2004) Introduc-
ing the "la Repubblica" corpus: A large, annotated, 
TEI(XML)-compliant corpus of newspaper Italian. 
Proceedings of LREC 2004, Lisbon: 1771-1774. 
Bouillon, P., S. Lehmann, S. Manzi and D. Petitpierre 
(1998) D?veloppement de lexiques ? grande 
?chelle. Proceedings of Colloque des journ?es LTT 
de TUNIS, Tunis: 71-80. 
Byrd, R. J. (1983) Word Formation in Natural Lan-
guage Processing Systems. IJCAI: 704-706. 
Byrd, R. J., J. L. Klavans, M. Aronoff and F. Anshen 
(1989) Computer methods for morphological analy-
sis Proceedings of 24th annual meeting on Associa-
tion for Computational Linguistics, New York, 
New York Association for Computational Linguis-
tics: 120-127  
Fradin, B., G. Dal, N. Grabar, F. Namer, S. Lignon, 
D. Tribout and P. Zweigenbaum (2007) Remarques 
sur l'usage des corpus en morphologie. Langages 
167. 
Gdaniec, C., E. Manandise and M. C. McCord (2001) 
Derivational Morphology to the Rescue: How It 
Can Help Resolve Unfound Words in MT. Procee-
dings of MT Summit VIII, Santiago Di Compostel-
la: 127-131. 
137
Iacobini, C. (2004) I prefissi. La formazione delle 
parole in italiano. M. Grossmann and F. Rainer. 
T?bingen, Niemeyer: 99-163. 
James, C. (1980) Contrastive analysis. Burnt Mill, 
Longman. 
Maurel, D. (2004) Les mots inconnus sont-ils des 
noms propres? Proceedings of JADT 2004, Lou-
vain-la-Neuve 
Montermini, F. (2002) Le syst?me pr?fixal en italien 
contemporain, Universit? de Paris X-Nanterre, Uni-
versit? degli Studi di Bologna: 355. 
Namer, F. (2005) La morphologie constructionnelle 
du fran?ais et les propri?t?s s?mantiques du lexi-
que: traitement automatique et mod?lisation. UMR 
7118 ATILF. Nancy, Universit? de Nancy 2. 
Porter, M. (1980) An algorithm for suffix stripping. 
Program 14: 130-137. 
Ren, X. and F. Perrault (1992) The Typology of Un-
known Words: An experimental Study of Two Cor-
pora. Proceedings of Coling 92, Nantes: 408-414. 
Thomas, C. (2008) "Google Online Lexical Frequen-
cies User Manual (Version 0.9.0)."   Retrieved 
04.02.2008, from 
http://www.craigthomas.ca/docs/golf-0.9.0-
manual.pdf. 
Wandruszka, U. (2004) Derivazione aggettivale. La 
Formazione delle Parole in Italiano. M. Grossman 
and F. Rainer. T?bingen, Niemeyer. 
 
 
138
How Comparable are Parallel Corpora?  
Measuring the Distribution of General Vocabulary and Connectives  
 
Bruno Cartoni Sandrine Zufferey Thomas Meyer Andrei Popescu-Belis 
Linguistics Department 
University of Geneva 
2, rue de Candolle 
CH ? 1211 Geneva 4 
Linguistics Department 
University of Geneva 
2, rue de Candolle 
CH ? 1211 Geneva 4 
Idiap Research Institute 
Rue Marconi 19 
CH ? 1920 Martigny  
Idiap Research Institute 
Rue Marconi 19 
CH ? 1920 Martigny  
{bruno.cartoni|sandrine.zufferey}@unige.ch {thomas.meyer|andrei.popescu-
belis}@idiap.ch 
 
Abstract 
In this paper, we question the 
homogeneity of a large parallel corpus 
by measuring the similarity between 
various sub-parts. We compare results 
obtained using a general measure of 
lexical similarity based on ?2 and by 
counting the number of discourse 
connectives. We argue that discourse 
connectives provide a more sensitive 
measure, revealing differences that are 
not visible with the general measure. We 
also provide evidence for the existence 
of specific characteristics defining 
translated texts as opposed to non-
translated ones, due to a universal 
tendency for explicitation. 
1 Introduction 
Comparable corpora are often considered as a 
solution to compensate for the lack of parallel 
corpora. Indeed, parallel corpora are still 
perceived as the gold standard resource for many 
multilingual natural language processing 
applications, such as statistical machine 
translation.  
The aim of this paper is to assess the 
homogeneity of the widely used Europarl 
parallel corpus (Koehn 2005) by comparing a 
distributional measure of lexical similarity with 
results focused on a more specific measure, the 
frequency of use of discourse connectives. 
Various perspectives can be taken to assess the 
homogeneity of this corpus. First, we evaluate 
the (dis)similarities between translated and 
original language (Experiment 1) and then the 
(dis)similarities between texts translated from 
different source languages (Experiment 2). 
Analyzing the use of discourse connectives 
such as because and since in English highlights 
important differences between translated and 
original texts. The analysis also reveals 
important differences when comparing, for a 
given language, texts that have been translated 
from various source languages. The different 
distribution of connectives in original vs. 
translated French, as well as across varieties of 
French translated from various source languages 
(English, German, Italian and Spanish), are all 
the more intriguing that they are not matched by 
a distributional difference of the general 
vocabulary in these corpora. We will indeed 
show that a well-known method (Kilgarriff 
2001) designed to compare corpora finds that the 
original French and the various translated 
portions of Europarl are rather similar, 
regardless of their source language. 
The paper is structured as follows: we first 
present related work on the characterization of 
translated text (Section 2). In Section 3, we 
argue that analyzing discourse connectives sheds 
new light on text (dis)similarity. Section 4 
presents the Europarl parallel corpus and its sub-
parts that have been used in our studies, as well 
as the methodology and measures that have been 
applied to assess text similarities. Section 5 
presents our main findings and Section 6 
discusses our results, drawing methodological 
conclusions about the use of parallel corpora. 
78
Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 78?86,
49th Annual Meeting of the Association for Computational Linguistics,
Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguistics
2 Previous Work 
Existing studies on translated corpora are mainly 
designed to automatically identify the presence 
of so-called ?translationese? or ?third code?, in 
other words, a text style deemed to be specific to 
translated texts, as in (Baroni and Bernardini 
2005) or in (Ilisei et al 2010). In the literature, 
many possible characteristics of translationese 
have been identified, such as those listed in 
(Baker 1996): translations are simpler than 
original texts (Laviosa-Braithwaite 1996); 
translations are more explicit than original texts 
due to an increase of cohesion markers (Blum-
Kulka 1986); and the items that are unique in the 
target system (i.e. that do not have exact 
equivalents in the source language) are under-
represented in translations (Tirkkonen-Condit 
2000).  
In the field of natural language processing, 
several studies on parallel corpora have shown 
that when building a statistical machine 
translation system, knowing which texts have 
been originally written in a given language and 
which ones are translations has an impact on the 
quality of the system (Ozdowska 2009). A 
recent study using machine learning has 
confirmed the universal of simplification as a 
feature of translated texts (Ilisei et al 
2010).Corpora can be compared using similarity 
measures. Most of these measures are based on 
lexical frequency. Kilgariff (2001) provides a 
comprehensive review of the different methods 
for computing similarity. 
In this study, we chose to use the CBDF 
measure (Chi-by-degrees-of-freedom), as 
proposed in (Kilgariff 1997), to assess the 
similarity of our sub-corpora, as explained in 
Section 4.3. We compare this measure with 
another marker of text diversity (connectives), as 
explained in the following section. 
3 Discourse Connectives as Markers of 
Text Diversity 
Discourse connectives like but, because or while 
form a functional category of lexical items that 
are very frequently used to mark coherence 
relations such as explanation or contrast 
between units of text or discourse (e.g. Halliday 
& Hassan 1976; Mann & Thomson 1992; Knott 
& Dale 1994; Sanders 1997). One of the unique 
properties of discourse connectives is that the 
relation they convey can in many cases be 
inferred even when they are removed, as 
illustrated in (1) and (2):  
1 Max fell because Jack pushed him. 
2 Max fell. Jack pushed him.  
The causal relation conveyed by because in 
(1) is also inferable when the connective is 
absent by using world knowledge about the 
possible relation between the fact of pushing 
someone and this person?s fall in (2). In other 
words, contrary to most other lexical items, 
connectives can be used or left out without 
producing ungrammatical results or losing 
important aspects of meaning. At a macro-
textual level, it is however clear that a text 
containing no connective at all would become 
rather difficult to understand. Several psycho-
linguistic studies have indeed stressed the role of 
connectives for processing (Millis & Just 1994; 
Noordman & Blijzer 2000). But the point we 
want to make here is that in most texts or 
discourses, some coherence relations are 
conveyed by the use of connectives while others 
are not, depending on what the author/speaker 
feels necessary to mark explicitly. 
Another consequence of the fact that 
connectives are optional is that their use in 
translation can vary tremendously between the 
source and the target texts. Studies that have 
examined at the use of connectives in translation 
have indeed found that connectives were often 
removed or added in the target texts, and that the 
type of coherence relation conveyed was 
sometimes even modified due to the actual 
choice of connectives in the target system 
(Altenberg 1986; Baker 1993; Lamiroy 1994; 
Halverson 2004). For all these reasons, 
discourse connectives appear to be particularly 
interesting to investigate in relation to corpus 
homogeneity. 
In this study, we focus more particularly on 
the category of causal connectives, that is to say 
connectives such as because and since in 
English. This particular category seemed 
especially appropriate for our purposes for a 
number of reasons. First, causal connectives 
form a well-defined cluster in many languages 
and can be studied comprehensively. Second, 
causal relations are amongst the most basic ones 
79
for human cognition and in consequence causal 
connectives are widely used in almost all text 
types (Sanders & Sweetser 2009). Lastly, causal 
connectives have been found to be more volatile 
in translation than other categories, such as for 
example concessive connectives like but, 
however, etc. (Halverson 2004; Altenberg 1986). 
From a quantitative perspective, function 
words are usually very frequent whereas most 
content words tend to be in the tail of the 
distribution. This provides another reason to 
treat connectives as a key feature for assessing 
text similarities. 
4 Corpora and Methodology 
4.1 Corpora 
Our analysis is based on the Europarl corpus 
(Koehn 2005), a resource initially designed to 
train statistical machine translation systems. 
Europarl is a multilingual corpus that contains 
the minutes of the European Parliament. At the 
parliament, every deputy usually speaks in 
his/her own language, and all statements are 
transcribed, and then translated into the other 
official languages of the European Union (a total 
of 11 languages for this version of the corpus ? 
version 5). Based on this data, several parallel 
bilingual corpora can be extracted, but caution is 
necessary because the exact status of every text, 
original or translated, is not always clearly 
stated. However, for a number of statements, a 
specific tag provides this information.  
From this multilingual corpus, we extracted 
for our first experiment two parallel and 
?directional? corpora (En-Fr and Fr-En). By 
?directional? we mean that the original and 
translated texts are clearly identified in these 
corpora. Namely, in the English-French subset, 
the original speeches were made in English 
(presumably mostly by native speakers), and 
then translated into French, while the reverse is 
true for French-English. Still, for many 
applications, these would appear as two 
undifferentiated subsets of an English-French 
parallel corpus.  
Since language tags are scarcely present, we 
automatically gathered all the tag information in 
all the language-specific files, correcting all the 
tags and discarding texts with contradictory 
information. Therefore, these extracted 
directional corpora are made of discontinuous 
sentences, because of the very nature of this 
multilingual corpus. In one single debate, each 
speaker speaks in his/her own language, and 
when extracting statements of one particular 
language, discourse cohesion across speakers is 
lost. However, this has no incidence at the 
global level on the quantitative distribution of 
connectives.  
We have focused our investigation on the 
years 1996 to 1999 of the Europarl corpus. 
Indeed, statistical investigations and information 
gathered at the European Parliament revealed 
that the translation policy had changed over the 
years. The 1996-1999 period appeared to contain 
the most reliable translated data of the whole 
corpus. 
For Experiment 1, we extracted two parallel 
directional corpora made of two languages ? 
French and English ? in order to compare 
translated and original texts in both languages, 
as shown in Figure 1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 1 gives the number of tokens in the 
English-French and in the French-English 
parallel directional corpora. 
 
Parallel corpus Token in ST Token in TT 
English-French (EF) 1,412,316 1,583,775 
French-English (FE) 1,257,879 1,188,923 
Table 1: Number of tokens in Source Texts (ST) 
and Translated Texts (TT) of the parallel 
directional corpora. 
 
Following the same methodology, we extracted 
for Experiment 2 other parallel directional 
Figure 1: Parallel and comparable corpora 
extracted from Europarl 
Parallel directional corpora 
Comparable corpora 
Original 
English 
Original 
French 
Translated 
French 
Translated 
English 
80
corpora, again with French as a target language 
(also from the 1996-1999 period), as shown in 
Figure 2. Table 2 presents the sizes of these four 
additional comparable corpora.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Parallel corpus Token in ST Token in TT 
German-French (DF) 1,254,531 1,516,634 
Italian-French (IF) 552,242 624,534 
Spanish-French (SF) 597,607 633,918 
Table 2: Number of tokens in Source Texts (ST) 
and Translated Texts (TT) of the three additional 
parallel directional corpora of translated French. 
 
These parallel directional corpora have been 
used as comparable corpora in our study because 
they are written in the same language and are of 
the same genre, but do not have the same 
?status?, since some are original texts while 
others are translations, as shown in . Moreover, 
for comparison purposes, we have also used a 
sub-part of Europarl which was originally 
produced in French (noted OF), corresponding 
to the French part of the French-English corpus 
described in Table 1 
All the experiments described below are 
based on these comparable corpora, i.e. on the 
translated vs. original corpus (for French and 
English) and on the different corpora of 
translated French (with Italian, English, Spanish 
and German as source languages).  
4.2 First Measure: CBDF Measure 
Following a proposal by Kilgarriff (2001), who 
criticizes a number of simpler techniques, we 
have measured corpus similarity by computing 
the ?2 statistic over the 500 most frequent words 
from the two corpora to be compared, which 
were limited to 200,000 words each, so that 
comparison with the values given by Kilgarriff 
was possible. The value was normalized by the 
number of degrees of freedom, which is (500?
1) ? (2?1) = 499, hence its name. As shown by 
Kilgarriff with artificially designed corpora, for 
which the similarity level was known in 
advance, the ?2 statistic is a reliable indicator of 
similarity. Moreover, Kilgarriff (2001: Table 10, 
page 260) provides a table with the ?2 values for 
all 66 pairs of 200,000-word corpora selected 
from 12 English corpora, which we will use for 
comparison below. The table also lists internal 
homogeneity values for each corpus, obtained by 
averaging the ?2 statistic over each 200,000-
word corpus split several times in half. In fact, 
as the same method is used for computing both 
similarity and homogeneity, only 100,000-word 
fragments are used for similarity, as stated by 
Kilgarriff. 
The CBDF similarity values between 
100,000-word subsets of Original French (OF), 
French translated from English (EF), from 
Italian (IF), from German (DF), and from 
Spanish (SF) are shown in Table 4 below. 
Taking OF vs. EF as an example, these values 
are computed by summing up, for all of the most 
frequent 500 words in OF+EF, the difference 
between the observed and the expected number 
of occurrences in each of OF and EF, more 
precisely (o ? e)2 / e, and then dividing the sum 
by 499. The expected number is simply the 
average of OF and EF occurrences, which is the 
best guess given the observations. The lower the 
result, the closer the two corpora are considered 
to be, in terms of lexical distribution, as shown 
by Kilgarriff (2001). 
For measuring homogeneity, we sliced each 
corpus in 10 equal parts, and computed the score 
by randomly building 10 different corpus 
configurations and calculating the average of the 
values.  
4.3 Second Measure: Counting Connectives 
As explained above, we focused our experiments 
on comparing frequencies of causal connectives. 
For French, our list of items included parce que, 
puisque, car, and ?tant donn? que. For English, 
Figure 2: Parallel and comparable corpora 
for Translated French 
Parallel directional corpora 
Comparable corpora 
Original 
English 
Original 
Italian 
Trans-
lated 
French 
Original 
German 
Original 
Spanish 
Trans-
lated 
French 
Transl-
lated 
French 
Trans-
lated 
French 
81
we included because, since, and given that1. In 
the case of since, we manually annotated its two 
meanings in order to distinguish its causal uses 
from its temporal ones, and retained only its 
causal uses in our counts. 
To count the number of occurrences for each 
causal connective in each sub-part of the corpus, 
we first pre-processed the corpora to transform 
each connective as one word-form (e.g. ?tant 
donn? que became ?tantdonn?que, and puisqu? 
became puisque.). Then, we counted each 
connective, and normalized the figures to obtain 
a ratio of connectives per 100,000 tokens. 
Moreover, when comparing French sub-
corpora translated from different source 
languages, we also computed the rank of each 
connective in the frequency list extracted from 
each corpus. Comparing these ranks provided 
important information about their respective 
frequencies.  
We have found that the frequency of each 
connective does not vary significantly 
throughout the corpus (years 1996-1999), which 
tends to prove that the use of connectives does 
not depend crucially on the style of a particular 
speaker or translator.  
5 Results  
This section presents the results of the CBDF 
measure for each corpus (Section 5.1), and 
shows how the frequencies of connectives reveal 
differences between translated and original texts 
(Section 5.2) and between texts translated from 
various source languages (Section 5.3).   
5.1 Text Similarity according to CBDF 
For Experiment 1, we have compared the 
differences between original and translated texts, 
for English and French. The values of CBDF 
similarity resulting from this comparison are 
shown in Table 3. Compared to the different 
scores computed by Kilgarriff, these scores 
indicate that the two pairs of corpora are both 
quite similar.  
                                                          
1
  The English causal connective for is more 
difficult to address because of its ambiguity with the 
homographic preposition. However, on a sample of 500 
tokens of for randomly extracted from Europarl, we found 
only two occurrences of the connective for, leading us to 
exclude this connective from our investigation. 
 CBDF 
Original English ? Translated English 13.28 
Original French ? Translated French 12.28 
Table 3: CBDF between original and translated 
texts 
 
The similarities between sub-corpora of 
French translated from different source 
languages (Experiment 2) are shown in Table 4. 
The values comparing the same portion (e.g. 
OF/OF) indicate the homogeneity score of the 
respective sub-corpus. 
 
 OF EF DF IF SF 
OF 2.64     
EF 6.00 3.34    
DF 5.11 4.83 2.74   
IF 4.88 6.30 4.99 2.86  
SF 5.34 5.43 5.36 4.43 2.22 
Table 4: Values of CBDF (?2 statistic 
normalized by degrees of freedom) for all pairs 
of source-specific 200,000-word subsets from 
Europarl. The lower the value, the more similar 
the subsets.   
 
Looking at the values in Table 4, we can see 
that the similarity score between OF and EF is 
6.00, which, compared to Kilgarriff?s values for 
British corpora, is lower than all but two of the 
66 pairs of corpora he compared. Most of the 
values observed by Kilgarriff are in fact between 
20 and 40, and the similarity we found for OF 
vs. EF is, for instance, in the same range as the 
one for the journal The Face vs. The Daily 
Mirror, a tabloid, and higher than the similarity 
of two broadsheet newspapers (i.e., they get a 
lower CBDF value). Therefore, we can conclude 
that OF and EF are very similar from a word 
distribution point of view. 
As for the other pairs, they are all in the same 
range of similarity, again much more similar 
than the corpora cited in Kilgarriff?s Table 10. 
Regarding internal comparisons, OF/EF appears 
as the second most dissimilar pair, preceded 
only by IF/EF (French translated from Italian vs. 
from English). The most similar pair is Original 
French vs. French translated from Italian, which 
is not surprising given that the two languages are 
closely related. Also similar to OF/IF are the 
IF/SF and EF/DF pairs, reflecting the similarity 
of translations from related languages. 
82
Homogeneity values are higher than similarity 
values (the ?2 scores are lower). These values 
are again comparable, albeit clearly lower, than 
those found by Kilgarriff, and presumably 
account for the lower variety of parliamentary 
discourse. Still, these values are similar to those 
of the most homogeneous subset used by 
Kilgarriff, the Dictionary of National Biography 
(1.86) or the Computergram (2.20). 
Figures on the distribution of connectives, 
presented in the next section, tend to show that 
these sub-corpora are however not as similar as 
they may seem at a first view.  
5.2 Text Similarities Measured with the 
Use of Causal Connectives: 
Experiment 1 
In Experiment 1, we highlight the differences in 
the use of causal connectives between original 
English and translated English. Figure 3 shows 
the discrepancy between the use of the same 
connectives in original and translated texts. 
Among these connectives, since is the only truly 
ambiguous word. We have therefore also 
evaluated the proportion of causal uses of since 
among all the uses of the word since. In original 
English, this proportion is 31.8% and doubles in 
translated English to reach 67.7%. 
 
 
Figure 3: Ratio connectives/100,000 tokens in 
original and translated English. 
 
These figures show that original and 
translated texts differ, at least in terms of the 
number of causal connectives they contain. 
While because seems equally used in original 
and translated English, since and given that are 
used three times more frequently in translated 
than in original texts. This variability is also 
noticeable when comparing original and 
translated uses of French connectives, as shown 
in Figure 4.  
 
Figure 4: Ratio connectives/100?000 tokens in 
original and translated French. 
 
For French, while car seems to be equally 
used in both sub-parts of the corpus, parce que 
is used twice less frequently in translated than in 
original texts. This discrepancy is even bigger in 
the case of puisque, which is used five times less 
frequently in translated than in original texts. 
The reverse phenomenon is observed for ?tant 
donn? que, which is used four times more 
frequently in translated than in original texts.  
By looking at the translation of every 
connective, we were able to count the number of 
connectives inserted in the target language, that 
is to say when there was a connective in the 
target system but no connective in the original 
text. Conversely, we have also counted the 
number of connectives removed in the target 
text, when a connective in the source language 
was not translated at all. Overall, we found that 
connectives were inserted much more often than 
removed during the process of translation. In the 
case of English as a target language, 65 
connectives were inserted while 35 were 
83
removed. In the case of French, 46 connectives 
were inserted while 11 were removed.  
5.3 Text similarities measured by the use of 
causal connectives: Experiment 2 
When comparing the number of occurrences of 
French causal connectives across texts translated 
from different languages, the differences are 
striking. Indeed, every source language seems to 
increase the use of one specific connective in the 
French translations.  
Figure 5 presents the ratio of connectives per 
100?000 token. The data compares the use of 
connectives in French translated from English, 
Italian, Spanish and German.  
 
 
Figure 5: Connectives per 100,000 tokens in 
French texts translated from various source 
languages (for each connective, from left to right 
OF, EF, IF, DF, SF) 
 
Table 5 provides the rank of every connective 
in the word frequency list (sorted by decreasing 
frequency) computed for each sub-corpus. Grey 
cells indicate the most frequent connective in 
each sub-corpus. 
 
 
 
 
 OF EF IF DF SF 
parce que 115 292 99 159 87 
car 136 172 201 82 85 
puisque 235 1070 601 886 790 
?tant donn? que 3882 1368 2104 1450 459 
Table 5: Rank of the connectives in word 
frequency list for each corpus. Note that the 
order varies with the source language. 
 
These figures show that the distribution of 
every connective differs radically according to 
the source language. Every source language 
seems to increase the use of one specific 
connective. When German is the source 
language, car is used twice more often than 
when English or Italian are the source 
languages. When Italian is the source language, 
parce que is used twice as often and when 
English is the source language, ?tant donn? que 
is again used twice as often. Overall, puisque is 
the only connective that does not seem to be 
enhanced by any of the source languages, which 
confirms some prior linguistic analyses of this 
item, showing that puisque does not have exact 
equivalents in other close languages (Degand 
2004; Zufferey to appear).  
6 Discussion 
We have compared the use of discourse 
connectives in different sub-parts of the 
Europarl parallel corpus with the use of general 
vocabulary, as computed by a measure of lexical 
homogeneity. Our main finding is that even 
though the lexical measure showed the similarity 
of these sub-parts, the use of discourse 
connectives varied tremendously between the 
various sub-parts of our corpus. 
One of the reasons why connectives show 
more variability than many other lexical items is 
that they are almost always optional. In other 
words, as argued in Section 3, for every 
individual use of a connective, the translator has 
the option to use another connective in the target 
language or to leave the coherence relation it 
conveys implicit. Coherence marking is 
therefore a global rather than a local textual 
strategy. 
Given that connectives can be used or left out 
without producing ungrammatical results, 
studying their variability between comparable 
corpora provides interesting indications about 
84
their global homogeneity. The significant 
variability that we report between comparable 
(monolingual) sub-parts of the Europarl corpus 
indicates that they are not as homogeneous as 
global lexical measures like the CBDF tend to 
indicate. In other words, the various sub-parts of 
the corpus are not equivalents of one another for 
all purposes, and should not be used as such 
without caution. These differences were 
noticeable both by the different number of every 
connective used in every sub-part of the corpus, 
but also by the rather different frequency rank 
that was measured for every one of them in these 
same sub-parts. 
From a translation perspective, our study also 
provides some further confirmation for the 
existence of specific characteristics that define 
translated texts (i.e. ?translationese? or ?third 
code?). More specifically, our study 
corroborates the explicitation hypothesis (Blum-
Kulka 1986), positing that translated texts are 
more explicit than original ones due to an 
increase of cohesion markers. Connectives are 
part of the lexical markers that contribute to 
textual coherence, and we found that they are 
indeed more numerous in translated than in 
original texts. For English as a target language, 
translators have inserted twice as many 
connectives as they have removed. For French, 
this proportion raises to four times more 
insertions than omissions.  
However, our data also indicates that the 
source language has an important influence on 
the nature of its translation. Indeed, for the use 
of connectives, we report important variations 
between texts translated into French from 
various source languages. More interestingly 
still, every source language triggered the use of 
one specific connective over the others. This 
connective was always specific to one particular 
source language. 
It is also noteworthy that the similarity 
between texts translated into French, as 
measured with the CBDF, is greater when the 
source languages are typologically related. In 
our corpora of translated French, we found that 
texts were more similar when comparing the 
portion translated from Spanish and Italian 
(Romance languages) and when comparing texts 
translated from English and German (Germanic 
languages). This result makes intuitive sense and 
provides further confirmation of the reliability of 
this measure to assess global similarity between 
portions of texts. 
7 Conclusion 
The Europarl corpus is mostly used in NLP 
research without taking into account the 
direction of translation, in other words, without 
knowing which texts were originally produced 
in one language and which ones are translations. 
The experiments reported in this paper show that 
this status has a crucial influence of the nature of 
texts and should therefore be considered. 
Moreover, we have shown that translated texts 
from different source languages are not 
homogeneous either, therefore there is no unique 
translationese, and we identified some 
characteristics that vary according to the source 
language. 
Our study also indicates that global measures 
of corpus similarity are not always sensitive 
enough to detect all forms of lexical variation, 
notably in the use of discourse connectives. 
However, the variability observed in the use of 
these items should not be discarded, both 
because of their rather frequent use and because 
they form an important aspect of textual 
strategies involving cohesion. 
Acknowledgments 
This study was partially funded by the Swiss 
National Science Foundation through the 
COMTIS Sinergia project 
(www.idiap.ch/comtis). The authors would 
particularly like to thank Adam Kilgarriff for his 
explanations regarding the CBDF measure.  
References  
Altenberg Bengt. 1986. Contrastive linking in spoken 
and written English. In Tottie G. & B?cklund U. 
(Eds.), English in Speech and writing: a 
symposium. Uppsala, 13-40. 
Baker Mona. 1993. In Other Words. A coursebook on 
translation. Routledge, London/New York. 
Baker Mona. 1996. Corpus-based translation studies: 
The challenges that lie ahead. In Somers H. (Ed.) 
Terminology, LSP and Translation. Studies in 
language engineering in honour of Juan C. Sager. 
John Benjamins, Amsterdam, 175-186. 
85
Baroni Marco and Bernardini Silvia. 2006. A new 
approach to the study of translationese: Machine-
learning the difference between original and 
translated text. Literary and Linguistic Computing 
21(3). 259-274 
Degand Liesbeth. 2004. Contrastive analyses, 
translation and speaker involvement: the case of 
puisque and aangezien. In Achard, M. & Kemmer, 
S. (Eds.), Language, Culture and Mind. The 
University of Chicago Press, Chicago, 251-270. 
Halliday Michael and Hasan Ruqaiya. 1976. Cohesion 
in English. Longman, London 
Halverson Sandra. 2004. Connectives as a translation 
problem. In Kittel, H. et al (Eds.) An International 
Encyclopedia of Translation Studies. Walter de 
Gruyter, Berlin/New York, 562-572. 
Ilisei Iustina, Inkpen Diana, Corpas Pastor Gloria and 
Mitkov Russlan. 2010 Identification of 
Translationese: A Machine Learning Approach. In 
Gelbukh, A. (Ed), Computational Linguistics and 
Intelligent Text Processing Lecture Notes in 
Computer Science. Springer, Berlin / Heidelberg, 
503-511 
Kilgarriff Adam. 2001. Comparing Corpora. Intl. 
Journal of Corpus Linguistics 6(1): 1-37. 
Kilgariff Adam. 1997. Using word frequency lists to 
measure corpus homogeneity and similarity 
between corpora. In Fifth ACL Workshop on Very 
Large Corpora, Beijing. 
Knott Alistair and Dale Robert. 1994. Using 
linguistic phenomena to motivate a set of 
coherence relations. Discourse processes 18(1), 
35-62. 
Koehn Philipp. 2005. Europarl: A Parallel Corpus for 
Statistical Machine Translation, MT Summit 2005. 
Lamiroy Beatrice. 1994. Pragmatic connectives and 
L2 acquisition. The case of French and Dutch. 
Pragmatics 4(2), 183-201. 
Laviosa-Braithwaite Sara. 1996. The English 
Comparable Corpus (ECC): A Resource and a 
Methodology for the Empirical Study of 
Translation. PhD Thesis, Manchester, UMIST. 
 
Mann William and Thomson Sandra. 1992. 
Relational Discourse Structure: A Comparison of 
Approaches to Structuring Text by 'Contrast'. In 
Hwang S. & Merrifield W. (Eds.), Language in 
Context: Essays for Robert E. Longacre. SIL, 
Dallas, 19-45. 
Millis Keith & Just Marcel. 1994. The influence of 
connectives on sentence comprehension. Journal 
of Memory and Language 33 (1): 128-147. 
New Boris, Pallier Christophe, Brysbaert Marc, Ferr 
Ludovic and Holloway Royal. 2004. Lexique~2: A 
New French Lexical Database. Behavior Research 
Methods, Instruments, & Computers, 36 (3): 516-
524.  
Noordman Leo and de Blijzer Femke. 2000. On the 
processing of causal relations. In E. Couper-
Kuhlen & B. Kortmann (Eds.) Cause, Condition, 
Concession, Contrast. Mouton de Gruyter, Berlin. 
35-56. 
Ozdowska Sylvia. 2009. Donn?es bilingues pour la 
TAS fran?ais-anglais : impact de la langue source 
et direction de traduction originales sur la qualit? 
de la traduction. Proceedings of Traitement 
Automatique des Langues Naturelles, TALN'09, 
Senlis, France. 
Sanders Ted. 1997. Semantic and pragmatic sources 
of coherence: On the categorization of coherence 
relations in context. Discourse Processes 24: 119?
147. 
Sanders Ted and Sweetser Eve (Eds) 2009. Causal 
Categories in Discourse and Cognition. Mouton de 
Gruyter, Berlin. 
Tirkkonen-Condit Sonja. 2000. In search of 
translation universals: non-equivalence or 
? unique ? items in a corpus test. Paper presented 
at the UMIST/UCL Research Models in 
Translation Studies Conference, Manchester, UK, 
April 2000. 
Zufferey Sandrine to appear. ?Car, parce que, 
puisque? Revisited. Three empirical studies on 
French causal connectives. Journal of Pragmatics. 
 
 
 
86
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 194?203,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Multilingual Annotation and Disambiguation of Discourse Connectives for
Machine Translation
Thomas Meyer and Andrei Popescu-Belis
Idiap Research Institute
Rue Marconi 19, 1920 Martigny, Switzerland
Thomas.Meyer@idiap.ch, Andrei.Popescu-Belis@idiap.ch
Sandrine Zufferey and Bruno Cartoni
Department of Linguistics, University of Geneva
Rue de Candolle 2, 1211 Geneva 4, Switzerland
Sandrine.Zufferey@unige.ch, Bruno.Cartoni@unige.ch
Abstract
Many discourse connectives can signal several
types of relations between sentences. Their
automatic disambiguation, i.e. the labeling of
the correct sense of each occurrence, is impor-
tant for discourse parsing, but could also be
helpful to machine translation. We describe
new approaches for improving the accuracy
of manual annotation of three discourse con-
nectives (two English, one French) by using
parallel corpora. An appropriate set of labels
for each connective can be found using infor-
mation from their translations. Our results for
automatic disambiguation are state-of-the-art,
at up to 85% accuracy using surface features.
Using feature analysis, contextual features are
shown to be useful across languages and con-
nectives.
1 Introduction
Discourse connectives are generally considered as
indicators of discourse structure, relating two sen-
tences of a written or spoken text, and making ex-
plicit the rhetorical or coherence relation between
them. Leaving aside the cases when connectives are
only implicit, the presence of a connective does not
unambiguously signal a specific discourse relation.
In fact, many connectives can indicate several types
of relations between sentences, i.e. they have several
possible ?senses? in context.
This paper studies the manual and automated dis-
ambiguation of three ambiguous connectives in two
languages: alors que in French, since and while in
English. We will show how the multilingual per-
spective helps to improve the accuracy of annota-
tion, and how it helps to find appropriate labels for
automated processing and MT. Results from auto-
matic annotation experiments, which are close to the
state of the art, as well as feature analysis, help to as-
sess the usefulness of the proposed labels.
The paper is organized as follows. Section 2 ex-
plains the motivation of our experiments, and of-
fers a wider perspective on our research goals, illus-
trating them with examples of translation problems
which arise from ambiguous discourse connectives.
Current resources and methods for discourse anno-
tation are discussed in Section 3. Section 4 analyzes
our experiments in manual annotation and in partic-
ular the influence of the set of labels on the reliability
of annotation. The automatic disambiguation exper-
iments, the features used, the results and the analysis
of features are described in Section 5. Section 6 con-
cludes the paper and outlines future work.
2 Explicit Connectives and their
Translation
2.1 Three Multi-functional Connectives
Discourse connectives form a functional category of
lexical items that are used to mark coherence rela-
tions such as Cause or Contrast between units of
discourse. Along with other function words, many
connectives appear among the most frequent words,
as shown for instance by counts (Cartoni et al,
2011) over the Europarl corpus (Koehn, 2005). The
Penn Discourse Treebank (Prasad et al, 2008) (see
Section 3.1 below) includes around 100 connective
types, but the exact number varies across studies,
194
depending on the discourse theory used to classify
them. Among these types, Pitler et al(2008) have
shown that most of them are unambiguous and easy
to identify, but others, especially temporal ones, of-
ten signal multiple senses depending on their con-
text.
Following the terminology of Petukhova and
Bunt (2009, Section 2), we are interested here in
?sequential? multi-functionality, i.e. the fact that the
same connective can signal different relations in dif-
ferent contexts. We do not deal with ?simultane-
ous? multi-functionality, i.e. the possibility for a
single occurrence to signal several relations, which
has been less frequently studied for connectives (see
Petukhova and Bunt (2009) for the discourse usage
of and).
We identified the two English connectives while
and since, along with the French connective alors
que, as being particularly problematic because they
are highly multi-functional, i.e. they can signal mul-
tiple senses. For alors que, a French database of
connectives (LexConn (Roze et al, 2010), see Sec-
tion 3 below) contains examples of sentences where
alors que expresses either a Background or a Con-
trast relation. For the English connective since,
Miltsakaki et al (2005) identified three possible
meanings: Temporal, Causal, and simultaneously
Temporal/Causal. For while, even more senses are
observed: Comparison, Contrast, Concession, and
Opposition. In fact, in the Penn Discourse Tree-
bank, the connective while is annotated with more
than twenty different senses.
2.2 Wider Research Objectives
Our long-term goal is to identify automatically the
senses of connectives for an application to machine
translation (MT). Going beyond the labels provided
by discourse theories, the goal is thus to find the
most appropriate labels in a new multilingual, em-
pirical approach that makes use of parallel corpora to
annotate and then learn the various senses of connec-
tives. The disambiguation of such connectives in a
source text is crucial for its translation, because each
sense may be translated by a different connective
and/or syntactical construct in the target language.
More specifically, we hypothesize that correctly
labeled connectives are easier to learn and to trans-
late by statistical MT systems than unlabeled ones.
To support this hypothesis, we set up an experiment
(Meyer, 2011) in which we constrained the transla-
tion of the three senses of the discourse connective
while that were previously annotated as Temporal,
Contrast and Concession. The system was forced to
use predefined French translations known to be cor-
rect, by directly modifying the phrase table of the
trained MT system. This modification noticeably
helped to improve translation quality and rose the
BLEU score by 0.8 for a preliminary test set of 20
sentences.
2.3 Illustration of Mistranslations
Among the connectives that we plan to process in or-
der to improve MT, the three connectives we focus
on in this paper are frequent, ambiguous and there-
fore difficult to translate correctly by MT systems,
as illustrated in the following examples.
A first reason why machine translation of connec-
tives can be difficult is that there may be no direct
lexical correspondence for the explicit source lan-
guage connective in the target language, as shown
in the reference translation of the first example in
Table 1, taken from the Europarl corpus (Koehn,
2005).
EN It is also important that we should not leave these indica-
tors floating in the air while congratulating ourselves on
the fact that we have produced them.
FR Il est e?galement important de ne pas laisser ces indicateurs
flotter, en nous fe?licitant de les avoir instaure?s.
EN Finally, and in conclusion, Mr President, with the expiry of
the ECSC Treaty, the regulations will have to be reviewed
since [causal] I think that the aid system will have to con-
tinue beyond 2002 . . .
FR *Enfin, et en conclusion, Monsieur le pre?sident, a`
l?expiration du traite? ceca, la re?glementation devra e?tre
revu depuis que [temporal] je pense que le syste`me d?aides
devront continuer au-dela` de 2002 . . .
FR Oui, bien entendu, sauf que le de?veloppement ne se ne?gocie
pas, alors que [contrast] le commerce, lui, se ne?gocie.
EN *Yes, of course, but development cannot be negotiated, so
[causal] that trade can.
EN Between 1998 and 1999, loyalists assaulted and shot 123
people, while [contrast] republicans assaulted and shot 93
people.
FR *Entre 1998 et 1999, les loyalistes ont attaque? et abattu
123 personnes, ? 93 pour les re?publicains.
Table 1: Translation examples from Europarl. Discourse
connectives, their translations, and their senses are indi-
cated in bold. The first example is a reference transla-
tion from EN into FR, while the others are wrong transla-
tions generated by MT (EN/FR and respectively FR/EN),
hence marked with an asterisk.
195
When an ambiguous connective is explicitly
translated by another connective, the incorrect ren-
dering of its sense can lead to erroneous translations,
as in the second and third examples in Table 1, which
are translated by the Moses SMT decoder (Koehn et
al., 2007) trained on the Europarl corpus. The ref-
erence translation for the second example uses the
French connective car with a correct causal sense,
instead of the wrong depuis que generated by SMT,
which expresses a temporal relation. In the third ex-
ample, the French connective alors que, in its con-
trastive usage, is wrongly translated into the English
connective so, which has a causal meaning (the ref-
erence translation uses whereas to express contrast).
It may even occur that the system fails to translate a
connective at all, as in the fourth example where the
discourse information provided by while, namely a
Contrast relation, is lost in the French translation,
which is hardly coherent any longer.
3 Related Work
3.1 Annotated Resources
One of the very few available discourse annotated
corpora is the Penn Discourse Treebank (PDTB) in
English (Prasad et al, 2008). For this resource, one
hundred types of explicit discourse connectives were
manually annotated, as well as implicit relations not
signaled by a connective. The sense hierarchy used
for annotation consists of three levels, from four top-
level senses (Temporal, Contingency, Comparison,
and Expansion), to 16 subsenses on the second level,
and 23 further ones on the third level. The annota-
tors were allowed to assign more than one sense to
each occurrence, so 129 simple or complex labels
are observed, over more than 18,000 explicit con-
nectives. For French, the ANNODIS project (Pe?ry-
Woodley et al, 2009) will provide annotation of dis-
course on an original corpus. Resources for Czech
are also becoming available (Zika?nova? et al, 2010).
For German, a lexicon of discourse markers
named DiMLex exists since the 1990s (Stede and
Umbach, 1998). An equivalent, more recent
database for French is the LexConn lexicon of con-
nectives (Roze et al, 2010) containing a list of 328
explicit connectives. For each of them, LexConn
indicates and exemplifies the possible senses, cho-
sen from a list of 30 labels inspired from Rhetorical
Structure Theory (Mann and Thompson, 1988).
3.2 Automatic Disambiguation of Connectives
The release of the PDTB had quite an impact on
automatic disambiguation experiments. The state-
of-the-art for recognizing all types of explicit con-
nectives in English is therefore already high, at
97% accuracy for disambiguating discourse vs. non-
discourse uses (Lin et al, 2010) and 94% for disam-
biguating the four main senses from the PDTB hier-
archy (Pitler and Nenkova, 2009). Lin et al (2010)
recently built the first end-to-end PDTB discourse
parser, which is able to parse unrestricted text with
an F1 score of 38.18% for senses on the second level
of the PDTB hierarchy. Other important contribu-
tions to automatic discourse connective classifica-
tion and feature analysis has been provided by Well-
ner et al (2006) and Elwell and Baldrige (2008).
Fewer studies focus on the detailed analysis of
specific discourse connectives. In Section 5.3, we
will compare our results to Miltsakaki et al (2005)
who report classification results for the connectives
since, while and when. In their study, as in the
present one, the goal is to disambiguate senses from
the second level of the PDTB hierarchy, a level
which, as we will show, is appropriate for the trans-
lation of these connectives as well.
4 Connective Annotation in Parallel
Corpora
The resources mentioned above are either monolin-
gual only (PDTB, LexConn) and/or not yet publicly
available (ANNODIS, DiMLex). Moreover, our
overall goal is related to multilingualism and trans-
lation, as explained in Section 2.2 above. There-
fore, we performed manual annotation of connec-
tives in a multilingual, aligned resource: the Eu-
roparl corpus (Koehn, 2005). We extracted from Eu-
roparl two subcorpora for each translation direction,
EN/FR and FR/EN, to take into account the varying
distribution of connectives in translated vs. original
language, as explained in Cartoni et al (2011).
As the full PDTB hierarchy seemed too fine-
grained given current capabilities for automatic la-
beling and the needs for translating connectives,
we defined a simplified set of labels for the senses
of connectives, by considering their usefulness and
196
granularity with respect to translation, focusing on
those that may lead to different connectives or syn-
tactical constructs in the target language.
4.1 Method
There are two major ways to annotate explicit dis-
course connectives. The first approach is to label
each occurrence of a connective with a label for
its sense, similar to the PDTB or LexConn hierar-
chies of senses. However, as shown among others
by Zikanova et al (2010), this is a difficult and time-
consuming task even when the annotators are trained
over a long period of time. This is confirmed by the
rather low kappa scores resulting from the manual
sense annotations as can be seen for each connective
in detail below.
The second approach to annotation, which is the
one put forward in this paper, is based on translation
spotting. In a first step, human annotators work on
bilingual sentence pairs, and annotate the translation
of each connective in the target language. The trans-
lations are either a target language connective (sig-
naling in principle the same sense(s) as the source
one), or a reformulation, or a construct with no con-
nective at all. In a second step of the annotation,
all translations of a connective are manually clus-
tered by the experimenters to derive sense labels, by
grouping together similar translations.
As demonstrated in the following subsections, for
the three connectives under study, the second ap-
proach to connective annotation not only facilitates
the annotation task, but also helps to derive the ap-
propriate level of granularity for the sense labels.
4.2 Annotation of alors que
This first manual annotation involved two experi-
enced annotators who annotated alors que in 423
original French sentences. The two main senses
identified for alors que are Background (labeled B)
Contrast (labeled C), as in the LexConn database.
Annotators were also allowed to use the J label if
they did not know which label to assign, and a
D label for discarded sentences ? due to a non-
connective use of the two words which could not be
filtered out automatically (e.g. Alors, que fera-t-on?
). The annotators found 20 sentences labeled with
D, which were removed from the data. 15 sentences
were labeled with J by one annotator (but none by
both), and it was decided to assign to them the label
(either B or C) provided by the other annotator.
The inter-annotator agreement on the B vs. C la-
bels was quite low, showing the difficulty of the task:
kappa reached 0.43, quite below the 0.7 mark often
considered as indicating reliability. The following
example from Europarl illustrates the difficulty of
choosing between B and C. In particular, the refer-
ence translation into English also uses an ambiguous
connective, namely while.
FR La monnaie unique va entrer en vigueur au milieu
de la tourmente financie`re, alors que de nombreux
comple?ments, logiques, mais que les E?tats ne sem-
blaient pas avoir pre?vus, n?ont pas encore e?te? ap-
porte?s.
EN The single currency is going to come into force in the
midst of financial turmoil, while a great many ad-
ditional factors which were only to be expected, but
which the states do not seem to have anticipated, have
not been taken into consideration.
Two methods were applied to deal with diverg-
ing manual annotations. To prepare the datasets for
the automated disambiguation experiments, one so-
lution (named A1, see Table 2) is to use the double-
sense label B/C for sentences labeled differently by
annotators (B vs. C). This label reflects the diffi-
culty of manual annotation and preserves the am-
biguity which might be genuinely present in each
occurrence. The relevance of the B/C label is also
supported by results from automatic labeling in Sec-
tion 5.3 below.
For comparison purposes, a second dataset named
A2 was derived from translation spotting on the
same French sentences aligned to English ones, as
explained in Section 4.1. Alors que appeared to be
mainly translated by the following English equiv-
alents and constructs: although, whereas, while,
whilst, when, at a time when. Through this opera-
tion, inter-annotator disagreement can sometimes be
solved: when the translation is a clearly contrastive
English connective (whereas or although), then the
C label was assigned instead of B/C. Conversely,
when the English translation was still ambiguous
(while, whilst, or when), the experimenters made a
decision in favor of either B or C by re-examining
source and target sentences.
4.3 Annotation of since
For since, 30 sentences were annotated by four ex-
perimenters in a preliminary round, with a kappa
197
ID Connective Sent. Labels (nb. of occ.)
A1 alors que 403 B (92), C (191), B/C (120)
A2 alors que 403 B (126), C (277)
B1 since 727 T (375), C (341), T/C (11)
B2 since 727 T (375), C (352)
C1 while 299 T/C (92), CONC (134), C (43)
T/CAUSAL (19), T/DUR (7)
T/PUNCT (4)
C2 while 299 T (30), C (135), CONC (134)
Table 2: The six datasets resulting from the manual anno-
tation of the three connectives, with total number of sen-
tences, possible labels and their number of occurrences.
The explanations of the labels are given in Sections 4.2
through 4.4.
score of 0.77, indicating good agreement. Then,
each half of the entire dataset (727 sentences) was
annotated by another person with three possible
sense labels: T for Temporal, C for Causal and
T/C for a simultaneously Temporal/Causal meaning.
Two datasets were again derived from this manual
annotation. To study the effects of a supplementary
label, we kept the label T/C for dataset B1, but con-
densed it under label C in dataset B2, as shown in
Table 2.
4.4 Annotation of while
The English connective while is highly ambiguous.
In the PDTB, occurrences of while are annotated
with no less than 21 possible senses, ranging from
Conjunction to Contrast, Concession, or Synchrony.
We performed a pilot annotation of 30 sentences
containing while with five different experimenters,
resulting in a quite low inter-annotator agreement,
? = 0.56. We therefore decided to perform a
translation spotting task only, with two experienced
annotators fluent in English and French. The ob-
served translations into French confirm the ambigu-
ity of while, as they include several connectives and
constructs, quite evenly distributed in terms of fre-
quency: alors que, gerundive reformulations, other
reformulations, si, tandis que, me?me si, bien que,
etc.
The translations were manually clustered to de-
rive senses for while, in an empirical manner.
For example, alors que signals Temporal/Contrast,
which is also true for tandis que. Similarly, me?me si
and bien que are clustered under the label Conces-
sion, and so forth. The translation spotting shows
that at least Contrast, Concession, and several tem-
poral senses are necessary to account for a correct
translation. These distinctions are comparable to the
semantic granularity of the second PDTB hierarchy
level.
To generate training sets for automated classifica-
tion out of a total of 500 sentences, we discarded 201
sentences labeled by annotators with G (gerundive
constructions), P (reformulations) or Z (no transla-
tion at all) ? these cases could be reconsidered in fur-
ther work, as they represent valid translation prob-
lems. For the remaining 299 sentences, we created
the following six labels by clustering the spotted
translations: T/C (Temporal/Contrast), T/PUNCT
(Temporal/Punctual), T/DUR (Temporal/Duration),
T/CAUSAL (Temporal/Causal), CONC (Conces-
sion) and C (Contrast). These were used to tag the
remaining 299 sentences, forming dataset C1. A
second dataset (C2) with fewer senses was obtained
from C1 by merging T/C to C (Contrast only) and
all T/x to T (Temporal only).
5 Disambiguation Experiments
The features for connective classification, the re-
sults obtained and a detailed feature analysis are dis-
cussed in this section. We show that an automated
disambiguation system can be used to determine the
most appropriate set of labels, and thus to corrob-
orate the selection we made using translation spot-
ting.
5.1 Features
For feature extraction, all the datasets described in
Section 4 were processed as follows. The English
texts were parsed and POS-tagged by Charniak and
Johnson?s (2005) reranking parser. The French texts
were POS-tagged with the MElt tagger (Denis and
Sagot, 2009) and parsed with MaltParser (Nivre,
2003). As the English parser provides constituency
trees, and the parser for French generates depen-
dency trees, the features are slightly different in the
two languages. The other features below were ex-
tracted using elementary pre-processing of the sen-
tences.
For English sentences, we used the following fea-
tures: the sentence-initial character of the connec-
198
tive (yes/no); the POS tag of the first verb in the
sentence; the type of first auxiliary verb in the sen-
tence (if any); the word preceding the connective;
the word following the connective; the POS tag of
the first verb following the connective; the type of
the first auxiliary verb after the connective (if any).
For French sentences, the features were the fol-
lowing: the sentence-initial character of the connec-
tive (yes/no); the dependency tag of the connective;
the first verb in the sentence; its dependency tag; the
word preceding the connective; its POS tag; its de-
pendency tag; the word following the connective; its
POS tag; its dependency tag; the first verb after the
connective; its dependency tag.
The cased connective word forms from the cor-
pus were not lower-cased, thus keeping the implicit
indication of the sentence-initial character of the oc-
currence, i.e. whether it starts a sentence or not. The
output of the POS taggers was used for neighboring
words, but not for the connectives, which almost al-
ways received the same tag. Charniak?s parser for
English provides POS tags which differentiate the
verb tenses, such as VBD (past), VBG (gerund), and
so on. These were considered for the verb directly
preceding and the one directly following the connec-
tive. Tense was believed to be potentially relevant
because since and while can have temporal mean-
ings.
The occurrence of auxiliary verbs (be, have, do,
or need) may give additional indications about tem-
poral relations in the sentence. We therefore used
the types of auxiliary verbs as features, including
the elementary conjugations, represented for to be
as: be present, be past, be part, be inf, be gerund
? and similarly for the other auxiliary verbs, as in
(Miltsakaki et al, 2005).
As shown by Lin et al (2010), duVerle and
Prendinger (2009) or Wellner et al (2006), the con-
text of a connective is very important. We there-
fore extracted the words preceding and following
each connective, the verbs and the first and the last
word of the sentences. These may include numbers,
sometimes indicating a numerical comparison, time
expressions, or antonyms, which could indicate con-
trastive relations, such as rise vs. fall (e.g. It is inter-
esting to see the fundamental stock pickers scream
?foul? on program trading when the markets de-
cline, while hailing the great values still abounding
as the markets rise.).
For French, we likewise extracted the words im-
mediately preceding and following each connective,
supplemented by their POS tags. In contrast to con-
stituents, dependency structures contain information
about the grammatical function of each word (heads)
and link the dependents belonging to the same head.
However, as the dependency parser provides no dif-
ferentiated verb tags, we extracted the verb word
forms themselves and added their dependency tags.
The same applies to the connective itself, and pre-
ceding and following words and their dependency
tags.
The dependency tag of the non-connectives varies
between subj (subject), det (determiner), mod (mod-
ifier) and obj (object). The first verb in the sentence
often belongs to the root dependency while the verb
following the connective most often belongs to the
obj dependency. For alors que, the most frequent
dependency tags were mod mod and mod obj, indi-
cating the connective?s main function as a modifier
of its argument.
5.2 Experimental Setting
Our classification experiments made use of the
WEKA machine learning toolkit (Hall et al, 2009)
to run and compare several classification algorithms:
Random Forest (sets of decision trees), Naive Bayes,
and Support Vector Machine. The results are re-
ported with 10-fold cross validation on the entire
data for each connective, using all features.
Table 3 lists for each method ? including the ma-
jority classifier as a baseline ? the percentage of cor-
rectly classified instances (or accuracy, noted Acc.),
and the kappa values. Significance above the base-
line is computed using paired t-tests at 95% confi-
dence. When a score is significantly above the base-
line, it is shown in italics in Table 3. The best scores
for each dataset, across classifiers, are indicated in
boldface. When these scores were not significantly
above the baseline, at least they were never signifi-
cantly below either.
5.3 Results and Discussion
Overall, the SVM classifier performed best, which
may be due to the large number of textual features
(3 for EN data and 5 for FR data), as SVMs are
known to handle them well (Joachims, 1998; du-
199
ID Connective # Labels Baseline R. Forest N. Bayes SVM
Acc. Acc. ? Acc. ? Acc. ?
A1 alors que 403 B, C, B/C 46.9 53.1 0.2 55.7 0.3 54.2 0.3
A2 alors que B, C 68.7 69.2 0.1 68.3 0.2 64.7 0.1
B1 since 727 T, C, T/C 51.6 79.8 0.6 82.3 0.7 85.4 0.7
B2 since T, C 51.6 80.7 0.6 84.0 0.7 85.7 0.7
C1 while 299 T/C, T/PUNCT, T/DUR,
T/CAUSAL, CONC, C
44.8 43.2 0.1 49.9 0.2 52.2 0.2
C2 while T, C, CONC 43.5 60.5 0.3 59.9 0.3 60.9 0.3
Table 3: Disambiguation scores for three connectives (number of occurrences in the training sets), with two sets of
labels each, for various classification algorithms. Accuracy (Acc.) is in percentage (%), and kappa is zero for the
baseline method (majority class). The best scores for each data set are in boldface, and scores significantly above the
baseline (95% t-test) are in italics.
Verle and Prendinger, 2009). The maximum accu-
racy for alors que is 55.7%, for since it is 85.7%, and
for while it is 60.9%. While close to other reported
values, there is still potential for improvement in the
future.
The analysis of results for each data sets leads
to observations that are specific to each connective.
The high improvement of over the baseline for A1,
as opposed to no improvement for A2, confirms the
usefulness of the double-sense B/C label for alors
que, showing that in this case the three-way classi-
fication is probably better adapted to the linguistic
properties of alors que than a two-way classifica-
tion. Indeed, alors que, just as its frequently spot-
ted translation while, is linguistically ambiguous in
some contexts (see for instance the example in Sec-
tion 4.2), in which the temporal and the contrastive
meaning are likely to co-exist. In the case of A2,
where the labels were forced to B or C only, auto-
matic classifiers do not significantly outperform the
baseline. While more elaborate features might help,
these low scores can be related to the difficulties of
human annotators (Section 4.2), and make a strong
case against using a two-label schema for alors que.
The features used so far lead to high scores for
since in datasets B1 and B2. The results are com-
parable to those from Miltsakaki et al (2005), who
used similar features and labels, though with a Max-
imum Entropy classifier. Moreover, they provide re-
sults for individual connectives, and not, as most of
the related work for the PDTB, on the whole set
of ca. 100 discourse connective types. However,
Miltsakaki et al (2005) used their own datasets for
each connective, which are different from the PDTB,
because the PDTB was not available at that time.
Our SVM classifier outperforms considerably the
Maximum Entropy classifier on the three-way clas-
sification task (with T, C, T/C), with an accuracy
of 85.4% vs. 75.5%, obtained however on differ-
ent datasets. For the two-way classification (T, C),
again on different datasets, our accuracy of 85.7% is
slightly lower than the 89.5% given in Miltsakaki et
al. (2005).1
For while, when comparing C1 to C2, it appears
that reducing the number of labels from six to three
increases accuracy by 8-10%. This is probably
due to the small number of training instances for
the labels T/PUNCT and T/DUR in C1 for exam-
ple. However, even for the larger set of labels, the
scores are significantly above baseline (52.2% vs.
44.8%), which indicates that such a classifier might
still be useful as input to an MT system, possibly
improved thanks to a larger training set. The perfor-
mance obtained by Miltsakaki et al (2005) on while
is markedly better than ours, with an accuracy of
71.8% compared to ours of 60.9% with three labels.
5.4 Feature Analysis
The relevance of features can be measured using
WEKA by computing the information gain (IG)
brought by each feature to the classification task,
1In another experiment (Meyer, 2011), we also applied our
classifiers to the PDTB data, with less features however. The
results were in the same range as those from Miltsakaki et
al. (2005), i.e. 75.3% accuracy for since and 59.6% for while.
200
R Feature IG
A1 A2
1 preceding word 1.12 0.64
2 following verb 0.81 0.51
3 first verb 0.74 0.42
4 following word 0.68 0.23
5 preceding word?s POS tag 0.15 0.05
5 first verb?s dep. tag 0.14 0.06
5 following word?s POS tag 0.19 0.03
8 preceding word?s dep. tag 0.10 0.03
8 connective?s dep. tag 0.09 0.04
10 following word?s dep. tag 0.13 0.013
10 following verb?s dep. tag 0.04 0.03
12 sentence initial 0.05 0.001
Table 4: Information gain (IG) of features for French con-
nective alors que, ordered by decreasing average ranking
(R) in experiments A1 and A2. Features 1?4 are consid-
erably more relevant than the following ones.
R Feature IG
B1 B2
1 preceding word 0.83 0.75
2 following word 0.56 0.52
3 following verb?s POS tag 0.24 0.21
4 type of following aux. verb 0.13 0.12
5 type of first aux. verb 0.11 0.11
6 first verb?s POS tag 0.02 0.01
7 sentence initial 0.00 0.00
Table 5: Information gain (IG) of features for EN con-
nective since, ordered by decreasing average ranking (R)
in experiments B1 and B2.
i.e. the reduction in entropy with respect to desired
classes (Hall et al, 2009) ? the higher the IG, the
more relevant the feature. Features can be ranked
by decreasing IG, as shown in Tables 4, 5 and 6, in
which ranks were averaged over the first and the sec-
ond data set in each series.
The tables show that across all three connectives
and the two languages, the contextual features are
always in the first positions, thus confirming the im-
portance of the context of a connective. Following
these are verbal features, which are, for these con-
nectives, of importance because the temporal mean-
ings are additionally established by verbal tenses.
POS and dependency features seem the least help-
R Feature IG
C1 C2
1 preceding word 1.02 0.65
2 following word 0.83 0.55
3 type of first aux. verb 0.12 0.07
4 following verb?s POS tag 0.16 0.04
5 first verb?s POS tag 0.07 0.09
5 type of following aux. verb 0.12 0.05
7 sentence initial 0.08 0.07
Table 6: Information gain (IG) of features for EN con-
nective while, ordered by decreasing average ranking (R)
in experiments C1 and C2. The first two features are con-
siderably more relevant than the remaining ones.
ful for disambiguation.
6 Conclusion and Future Work
We have described a translation-oriented approach
to the manual and automatic annotation of discourse
connectives, with the goal of identifying their senses
automatically, prior to machine translation. The
manual annotation of the senses of connectives has
been enhanced through parallel corpora and transla-
tion spotting. This has lead to tag sets that improved
both inter-annotator agreement and automatic label-
ing, which reached state-of-the-art scores. The ana-
lysis of relevant features has shown the utility of
contextual information.
To improve over these initial results, we will use
more semantic information, such as relations found
in WordNet between words in the neighborhood of
connectives ? e.g. word similarity measures and se-
mantic relations such as antonymy. To generate
more training instances of the labels found, man-
ual annotation will continue in order to see whether
the senses found through translation spotting can im-
prove automatic disambiguation of many more con-
nectives. The annotation of a large parallel corpus
will then help to train disambiguation tools along
with statistical MT systems that use their output.
Acknowledgments
We are grateful for the funding of this work by the
Swiss National Science Foundation (SNSF) under
the COMTIS Sinergia Project, n. CRSI22 127510
(see www.idiap.ch/comtis/).
201
References
Bruno Cartoni, Sandrine Zufferey, Thomas Meyer, and
Andrei Popescu-Belis. 2011. How comparable are
parallel corpora? Measuring the distribution of gen-
eral vocabulary and connectives. In Proceedings of 4th
Workshop on Building and Using Comparable Cor-
pora, Portland, OR.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of ACL 2005 (43rd Annual Meet-
ing of the ACL), pages 173?180, Ann Arbor, MI.
Pascal Denis and Beno??t Sagot. 2009. Coupling an anno-
tated corpus and a morphosyntactic lexicon for state-
of-the-art POS tagging with less human effort. In
Proceedings of PACLIC 2009 (23rd Pacific Asia Con-
ference on Language, Information and Computation),
pages 110?119, Hong Kong, China.
David duVerle and Helmut Prendinger. 2009. A novel
discourse parser based on support vector machine clas-
sification. In Proceedings of ACL-IJCNLP 2009 (47th
Annual Meeting of the ACL and 4th International Joint
Conference on NLP of the AFNLP), pages 665?673,
Singapore.
Robert Elwell and Jason Baldridge. 2008. Discourse
connective argument identification with connective
specific rankers. In Proceedings of ICSC 2008 (2nd
IEEE International Conference on Semantic Comput-
ing), pages 198?205, Santa Clara, CA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
ACM SIGKDD Explorations Newsletter, 11:10?18.
Thorsten Joachims. 1998. Text categorization with sup-
port vector machines: Learning with many relevant
features. In Proceedings of ECML 1998 (10th Euro-
pean Conference on Machine Learning), pages 137?
142, Chemnitz, Germany.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbs. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of ACL 2007 (45th Annual Meeting of the
ACL), Demonstration Session, pages 177?180, Prague,
Czech Republic.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of MT
Summit X, pages 79?86, Phuket, Thailand.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2010. A
PDTB-styled end-to-end discourse parser. Technical
Report TRB8/10, School of Computing, National Uni-
versity of Singapore, Singapore.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical Structure Theory: towards a functional the-
ory of text organization. Text, 8(3):243?281.
Thomas Meyer. 2011. Disambiguating temporal-
contrastive discourse connectives for machine transla-
tion. In Proceedings of ACL-HLT 2011 (49th Annual
Meeting of the ACL: Human Language Technologies),
Student Session, Portland, OR.
Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Aravind
Joshi, and Bonnie Webber. 2005. Experiments on
sense annotations and sense disambiguation of dis-
course connectives. In Proceedings of the TLT 2005
(4th Workshop on Treebanks and Linguistic Theories),
Barcelona, Spain.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of IWPT
2008 (8th International Workshop on Parsing Tech-
nologies), pages 149?160, Tokyo, Japan.
Marie-Paule Pe?ry-Woodley, Nicholas Asher, Patrice
Enjalbert, Farah Benamara, Myriam Bras, Ce?cile
Fabre, Ste?phane Ferrari, Lydia-Mai Ho-Dac, Anne
Le Draoulec, Yann Mathet, Philippe Muller, Laurent
Pre?vot, Josette Rebeyrolle, Ludovic Tanguy, Marianne
Vergez-Couret, Laure Vieu, and Antoine Widlo?cher.
2009. Annodis: une approche outille?e de l?annotation
de structures discursives. In Proceedings of TALN
2009 (16e`me Confe?rence sur le Traitement Automa-
tique des Langues Naturelles), Paris, France.
Volha Petukhova and Harry Bunt. 2009. Towards a
multidimensional semantics of discourse markers in
spoken dialogue. In Proceedings of IWCS-8 (8th In-
ternational Conference on Computational Semantics),
pages 157?168, Tilburg, The Netherlands.
Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text. In
Proceedings of ACL-IJCNLP 2009 (47th Annual Meet-
ing of the ACL and 4th International Joint Conference
on NLP of the AFNLP), Short Papers, pages 13?16,
Singapore.
Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani
Nenkova, Alan Lee, and Aravind Joshi. 2008. Eas-
ily identifiable discourse relations. In Proceedings of
Coling 2008 (22nd International Conference on Com-
putational Linguistics), Companion Volume: Posters,
pages 87?90, Manchester, UK.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse Treebank 2.0. In
Proceedings of LREC 2008 (6th International Confer-
ence on Language Resources and Evaluation), pages
2961?2968, Marrakech, Morocco.
Charlotte Roze, Laurence Danlos, and Phillippe Muller.
2010. LEXCONN: a French lexicon of discourse con-
nectives. In Proceedings of MAD 2010 (Multidis-
202
ciplinary Approaches to Discourse), pages 114?125,
Moissac, France.
Manfred Stede and Carla Umbach. 1998. DiMLex: a
lexicon of discourse markers for text generation and
understanding. In Proceedings of ACL 1998 (36th An-
nual Meeting of the ACL), pages 1238?1242, Mon-
treal, Canada.
Ben Wellner, James Pustejovsky, Catherine Havasi,
Roser Sauri, and Anna Rumshisky. 2006. Classifica-
tion of discourse coherence relations: An exploratory
study using multiple knowledge sources. In Proceed-
ings of 7th SIGDIAL Workshop on Discourse and Di-
alogue, pages 117?125, Sydney, Australia.
Sa?rka Zika?nova?, Lucie Mladova?, Jir??? M??rovsky?, and
Pavlina J??nova?. 2010. Typical cases of annotators?
disagreement in discourse annotations in Prague De-
pendency Treebank. In Proceedings of LREC 2010
(7th International Conference on Language Resources
and Evaluation), pages 2002?2006, Valletta, Malta.
203
