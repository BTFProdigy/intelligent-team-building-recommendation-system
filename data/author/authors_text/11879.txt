Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 25?28,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Capturing Errors in Written Chinese Words 
Chao-Lin Liu1 Kan-Wen Tien2 Min-Hua Lai3 Yi-Hsuan Chuang4 Shih-Hung Wu5
1-4National Chengchi University, 5Chaoyang University of Technology, Taiwan 
{1chaolin, 296753027, 395753023, 494703036}@nccu.edu.tw, 5shwu@cyut.edu.tw 
 
Abstract 
A collection of 3208 reported errors of Chinese 
words were analyzed. Among which, 7.2% in-
volved rarely used character, and 98.4% were 
assigned common classifications of their causes 
by human subjects. In particular, 80% of the er-
rors observed in writings of middle school stu-
dents were related to the pronunciations and 
30% were related to the compositions of words. 
Experimental results show that using intuitive 
Web-based statistics helped us capture only 
about 75% of these errors. In a related task, the 
Web-based statistics are useful for recommend-
ing incorrect characters for composing test items 
for "incorrect character identification" tests 
about 93% of the time. 
1 Introduction 
Incorrect writings in Chinese are related to our under-
standing of the cognitive process of reading Chinese 
(e.g., Leck et al, 1995), to our understanding of why 
people produce incorrect characters and our offering 
corresponding remedies (e.g., Law et al, 2005), and 
to building an environment for assisting the prepara-
tion of test items for assessing students? knowledge of 
Chinese characters (e.g., Liu and Lin, 2008). 
Chinese characters are composed of smaller parts 
that can carry phonological and/or semantic informa-
tion. A Chinese word is formed by Chinese characters. 
For example, ??? (Singapore) is a word that con-
tains three Chinese characters. The left (?) and the 
right (?) part of ?, respectively, carry semantic and 
phonological information. Evidences show that pro-
duction of incorrect characters are related to either 
phonological or the semantic aspect of the characters. 
In this study, we investigate several issues that are 
related to incorrect characters in Chinese words. In 
Section 2, we present the sources of the reported er-
rors. In Section 3, we analyze the causes of the ob-
served errors. In Section 4, we explore the effective-
ness of relying on Web-based statistics to correct the 
errors. The current results are encouraging but de-
mand further improvements. In Section 5, we employ 
Web-based statistics in the process of assisting teach-
ers to prepare test items for assessing students? 
knowledge of Chinese characters. Experimental re-
sults showed that our method outperformed the one 
reported in (Liu and Lin, 2008), and captured the best 
candidates for incorrect characters 93% of the time. 
2 Data Sources 
We obtained data from three major sources. A list that 
contains 5401 characters that have been believed to be 
sufficient for everyday lives was obtained from the 
Ministry of Education (MOE) of Taiwan, and we call 
the first list the Clist, henceforth. We have two lists of 
words, and each word is accompanied by an incorrect 
way to write certain words. The first list is from a 
book published by MOE (MOE, 1996). The MOE 
provided the correct words and specified the incorrect 
characters which were mistakenly used to replace the 
correct characters in the correct words. The second 
list was collected, in 2008, from the written essays of 
students of the seventh and the eighth grades in a 
middle school in Taipei. The incorrect words were 
entered into computers based on students? writings, 
ignoring those characters that did not actually exist 
and could not be entered.  
We will call the first list of incorrect words the 
Elist, and the second the Jlist from now on. Elist and 
Jlist contain, respectively, 1490 and 1718 entries. 
Each of these entries contains a correct word and the 
incorrect character. Hence, we can reconstruct the 
incorrect words easily. Two or more different ways to 
incorrectly write the same words were listed in differ-
ent entries and considered as two entries for simplic-
ity of presentation. 
3 Error Analysis of Written Words 
Two subjects, who are native speakers of Chinese and 
are graduate students in Computer Science, examined 
Elist and Jlist and categorized the causes of errors. 
They compared the incorrect characters with the cor-
rect characters to determine whether the errors were 
pronunciation-related or semantic-related. Referring 
to an error as being ?semantic-related? is ambiguous. 
Two characters might not contain the same semantic 
part, but are still semantically related. In this study, 
we have not considered this factor. For this reason we 
refer to the errors that are related to the sharing of 
semantic parts in characters as composition-related. 
It is interesting to learn that native speakers had a 
high consensus about the causes for the observed er-
rors, but they did not always agree. Hence, we studied 
the errors that the two subjects had agreed categoriza-
tions. Among the 1490 and 1718 words in Elist and 
Jlist, respectively, the two human subjects had con-
sensus over causes of 1441 and 1583 errors.  
The statistics changed when we disregarded errors 
that involved characters not included in Clist. An er-
ror would be ignored if either the correct or the incor-
rect character did not belong to the Clist. It is possible 
for students to write such rarely used characters in an 
incorrect word just by coincidence. 
After ignoring the rare characters, there were 1333 
and 1645 words in Elist and Jlist, respectively. The 
subjects had consensus over the categories for 1285 
25
and 1515 errors in Elist and Jlist, respectively.  
Table 1 shows the percentages of five categories of 
errors: C for the composition-related errors, P for the 
pronunciation-related errors, C&P for the intersection 
of C and P, NE for those errors that belonged to nei-
ther C nor P, and D for those errors that the subjects 
disagreed on the error categories. There were, respec-
tively, 505 composition-related and 1314 pronuncia-
tion-related errors in Jlist, so we see 30.70% 
(=505/1645) and 79.88% (=1314/1645) in the table. 
Notice that C&P represents the intersection of C and 
P, so we have to deduct C&P from the sum of C, P, 
NE, and D to find the total probability, namely 1. 
It is worthwhile to discuss the implication of the 
statistics in Table 1. For the Jlist, similarity between 
pronunciations accounted for nearly 80% of the errors, 
and the ratio for the errors that are related to composi-
tions and pronunciations is 1:2.6. In contrast, for the 
Elist, the corresponding ratio is almost 1:1. The Jlist 
and Elist differed significantly in the ratios of the er-
ror types. It was assumed that the dominance of pro-
nunciation-related errors in electronic documents was 
a result of the popularity of entering Chinese with 
pronunciation-based methods. The ratio for the Jlist 
challenges this popular belief, and indicates that even 
though the errors occurred during a writing process, 
rather than typing on computers, students still pro-
duced more pronunciation-related errors than compo-
sition-related errors. Distribution over error types is 
not as related to input method as one may have be-
lieved. Nevertheless, the observation might still be a 
result of students being so used to entering Chinese 
text with pronunciation-based method that the organi-
zation of their mental lexicons is also pronunciation 
related. The ratio for the Elist suggests that editors of 
the MOE book may have chosen the examples with a 
special viewpoint in their minds ? balancing the errors 
due to pronunciation and composition. 
4 Reliability of Web-based Statistics  
In this section, we examine the effectiveness of using 
Web-based statistics to differentiate correct and incor-
rect characters. The abundant text material on the 
Internet gives people to treat the Web as a corpus (e.g., 
webascorpus.org). When we send a query to Google, 
we will be informed of the number of pages (NOPs) 
that possibly contain relevant information. If we put 
the query terms in quotation marks, we should find 
the web pages that literally contain the query terms. 
Hence, it is possible for us to compare the NOPs for 
two competing phrases for guessing the correct way 
of writing. At the time of this writing, Google found 
107000 and 3220 pages, respectively, for ?strong tea? 
and ?powerful tea?. (When conducting such advanced 
searches with Google, the quotation marks are needed 
to ensure the adjacency of individual words.) Hence, 
?strong? appears to be a better choice to go with ?tea?. 
How does this strategy serve for learners of Chinese? 
We verified this strategy by sending the words in 
both the Elist and the Jlist to Google to find the NOPs. 
We can retrieve the NOPs from the documents re-
turned by Google, and compare the NOPs for the cor-
rect and the incorrect words to evaluate the strategy. 
Again, we focused on those in the 5401 words that the 
human subjects had consensus about their error types. 
Recall that we have 1285 and 1515 such words in 
Elist and Jlist, respectively. As the information avail-
able on the Web changes all the time, we also have to 
note that our experiments were conducted during the 
first half of March 2009. The queries were submitted 
at reasonable time intervals to avoid Google?s treating 
our programs as malicious attackers. 
Table 2 shows the results of our investigation. We 
considered that we had a correct result when we found 
that the NOP for the correct word larger than the NOP 
for the incorrect word. If the NOPs were equal, we 
recorded an ambiguous result; and when the NOP for 
the incorrect word is larger, we recorded an incorrect 
event. We use ?C?, ?A?, and ?I? to denote ?correct?, 
?ambiguous?, and ?incorrect? events in Table 2.  
The column headings of Table 2 show the setting 
of the searches with Google and the set of words that 
were used in the experiments. We asked Google to 
look for information from web pages that were en-
coded in traditional Chinese (denoted Trad). We 
could add another restriction on the source of infor-
mation by asking Google to inspect web pages from 
machines in Taiwan (denoted Twn+Trad). We were 
not sure how Google determined the languages and 
locations of the information sources, but chose to trust 
Google. The headings ?Comp? and ?Pron? indicate 
whether the words whose error types were composi-
tion and pronunciation-related, respectively.  
Table 2 shows eight distributions, providing ex-
perimental results that we observed under different 
settings. The distribution printed in bold face showed 
that, when we gathered information from sources that 
were encoded in traditional Chinese, we found the 
correct words 73.12% of the time for words whose 
error types were related to composition in Elist. Under 
the same experimental setting, we could not judge the 
correct word 4.58% of the time, and would have cho-
sen an incorrect word 22.30% of the time. 
Statistics in Table 2 indicate that web statistics is 
not a very reliable factor to judge the correct words. 
The average of the eight numbers in the ?C? rows is 
only 71.54% and the best sample is 76.59%, suggest-
Table 2. Reliability of Web-based statistics 
Trad Twn+Trad  
Comp Pron Comp Pron 
C 73.12% 73.80% 69.92% 68.72%
A 4.58% 3.76% 3.83% 3.76%
E
list 
I 22.30% 22.44% 26.25% 27.52%
C 76.59% 74.98% 69.34% 65.87%
A 2.26% 3.97% 2.47% 5.01%
Jlist 
I 21.15% 21.05% 28.19% 29.12%
Table 1. Error analysis for Elist and Jlist 
 C P C&P NE D 
Elist 66.09% 67.21% 37.13% 0.23% 3.60%
Jlist 30.70% 79.88% 20.91% 2.43% 7.90%
26
ing that we did not find the correct words frequently. 
We would made incorrect judgments 24.75% of the 
time. The statistics also show that it is almost equally 
difficult to find correct words for errors that are com-
position and pronunciation related. In addition, the 
statistics reveal that choosing more features in the 
advanced search affected the final results. Using 
?Trad? offered better results in our experiments than 
using ?Twn+Trad?. This observation may arouse a 
perhaps controversial argument. Although Taiwan has 
proclaimed to be the major region to use traditional 
Chinese, their web pages might not have used as ac-
curate Chinese as web pages located in other regions. 
We have analyzed the reasons for why using Web-
based statistics did not find the correct words. Fre-
quencies might not have been a good factor to deter-
mine the correctness of Chinese. However, the myriad 
amount of data on the Web should have provided a 
better performance. Google?s rephrasing our submit-
ted queries is an important factor, and, in other cases, 
incorrect words were more commonly used. 
5 Facilitating Test Item Authoring 
Incorrect character correction is a very popular type of 
test in Taiwan. There are simple test items for young 
children, and there are very challenging test items for 
the competitions among adults. Finding an attractive 
incorrect character to replace a correct character to 
form a test item is a key step in authoring test items.  
We have been trying to build a software environ-
ment for assisting the authoring of test items for in-
correct character correction (Liu and Lin, 2008, Liu et 
al., 2009). It should be easy to find a lexicon that con-
tains pronunciation information about Chinese charac-
ters. In contrast, it might not be easy to find visually 
similar Chinese characters with computational meth-
ods. We expanded the original Cangjie codes (OCC), 
and employed the expanded Cangjie codes (ECC) to 
find visually similar characters (Liu and Lin, 2008).  
With a lexicon, we can find characters that can be 
pronounced in a particular way. However, this is not 
enough for our goal. We observed that there were 
different symptoms when people used incorrect char-
acters that are related to their pronunciations. They 
may use characters that could be pronounced exactly 
the same as the correct characters. They may also use 
characters that have the same pronunciation and dif-
ferent tones with the correct character. Although rela-
tively infrequently, people may use characters whose 
pronunciations are similar to but different from the 
pronunciation of the correct character.  
As Liu and Lin (2008) reported, replacing OCC 
with ECC to find visually similar characters could 
increase the chances to find similar characters. Yet, it 
was not clear as to which components of a character 
should use ECC. 
5.1 Formalizing the Extended Cangjie Codes 
We analyzed the OCCs for all the words in Clist to 
determine the list of basic components. We treated a 
Cangjie basic symbol as if it was a word, and com-
puted the number of occurrences of n-grams based on 
the OCCs of the words in Clist. Since the OCC for a 
character contains at most five symbols, the longest n-
grams are 5-grams. Because the reason to use ECC 
was to find common components in characters, we 
disregarded n-grams that repeated no more than three 
times. In addition, the n-grams that appeared more 
than three times might not represent an actual compo-
nent in Chinese characters. Hence, we also removed 
such n-grams from the list of our basic components. 
This process naturally made our list include radicals 
that are used to categorize Chinese characters in typi-
cal printed dictionaries. The current list contains 794 
components, and it is possible to revise the list of ba-
sic components in our work whenever necessary. 
After selecting the list of basic components with 
the above procedure, we encoded the words in Elist 
with our list of basic components. We adopted the 12 
ways that Liu and Lin (2008) employed to decompose 
Chinese characters. There are other methods for de-
composing Chinese characters into components. 
Juang et al (2005) and the research team at the Sinica 
Academia propose 13 different ways for decomposing 
characters. 
5.2 Recommending Incorrect Alternatives 
With a dictionary that provides the pronunciation of 
Chinese characters and the improved ECC encodings 
for words in the Elist, we can create lists of candidate 
characters for replacing a specific correct character in 
a given word to create a test item for incorrect charac-
ter correction.  
There are multiple strategies to create the candidate 
lists. We may propose the candidate characters be-
cause their pronunciations have the same sound and 
the same tone with those of the correct character (de-
noted SSST). Characters that have same sounds and 
different tones (SSDT), characters that have similar 
sounds and same tones (MSST), and characters that 
have similar sounds and different tones (MSDT) can 
be considered as candidates as well. It is easy to judge 
whether two Chinese characters have the same tone. 
In contrast, it is not trivial to define ?similar? sound. 
We adopted the list of similar sounds that was pro-
vided by a psycholinguistic researcher (Dr. Chia-Ying 
Lee) at the Sinica Academia. 
In addition, we may propose characters that look 
similar to the correct character. Two characters may 
look similar for two reasons. They may contain the 
same components, or they contain the same radical 
and have the same total number of strokes (RS). 
When two characters contain the same component, the 
shared component might or might not locate at the 
same position within the bounding boxes of characters.  
In an authoring tool, we could recommend a lim-
ited number of candidate characters for replacing the 
correct character. We tried two strategies to compare 
and choose the visually similar characters. The first 
strategy (denoted SC1) gave a higher score to the 
shared component that located at the same location in 
the two characters being compared. The second strat-
27
egy (SC2) gave the same score to any shared compo-
nent even if the component did not reside at the same 
location in the characters. When there were more than 
20 characters that receive nonzero scores, we chose to 
select at most 20 characters that had leading scores as 
the list of recommended characters. 
5.3 Evaluating the Recommendations 
We examined the usefulness of these seven categories 
of candidates with errors in Elist and Jlist. The first 
set of evaluation (the inclusion tests) checked only 
whether the lists of recommended characters con-
tained the incorrect character in our records. The sec-
ond set of evaluation (the ranking tests) was designed 
for practical application in computer assisted item 
generation. Only for those words whose actual incor-
rect characters were included in the recommended list, 
we replaced the correct characters in the words with 
the candidate incorrect characters, submitted the in-
correct words to Google, and ordered the candidate 
characters based on their NOPs. We then recorded the 
ranks of the incorrect characters among all recom-
mended characters.  
Since the same character may appear simultane-
ously in SC1, SC2, and RS, we computed the union of 
these three sets, and checked whether the incorrect 
characters were in the union. The inclusion rate is 
listed under Comp. Similarly, we computed the union 
for SSST, SSDT, MSST, and MSDT, checked whether 
the incorrect characters were in the union, and re-
corded the inclusion rate under Pron. Finally, we 
computed the union of the lists created by the seven 
strategies, and recorded the inclusion rate under Both. 
The second and the third rows of Table 3 show the 
results of the inclusion tests. The data show the per-
centage of the incorrect characters being included in 
the lists that were recommended by the seven strate-
gies. Notice that the percentages were calculated with 
different denominators. The number of composition-
related errors was used for SC1, SC2, RS, and Comp 
(e.g. 505 that we mentioned in Section 3 for the Jlist); 
the number of pronunciation-related errors for SSST, 
SSDT, MSST, MSDT, and Pron (e.g., 1314 mentioned 
in Section 3 for the Jlist); the number of either of 
these two errors for Both (e.g., 1475 for Jlist).  
The results recorded in Table 3 show that we were 
able to find the incorrect character quite effectively, 
achieving better than 93% for both Elist and Jlist. The 
statistics also show that it is easier to find incorrect 
characters that were used for pronunciation-related 
problems. Most of the pronunciation-related problems 
were misuses of characters that had exactly the same 
pronunciations with the correct characters. Unex-
pected confusions, e.g., those related to pronuncia-
tions in Chinese dialects, were the main for the failure 
to capture the pronunciation-related errors. SSDT is a 
crucial complement to SSST. There is still room to 
improve our methods to find confusing characters 
based on their compositions. We inspected the list 
generated by SC1 and SC2, and found that, although 
SC2 outperformed SC1 on the inclusion rate, SC1 and 
SC2 actually generated complementary lists and 
should be used together. The inclusion rate achieved 
by the RS strategy was surprisingly high.  
The fourth and the fifth rows of Table 3 show the 
effectiveness of relying on Google to rank the candi-
date characters for recommending an incorrect charac-
ter. The rows show the average ranks of the included 
cases. The statistics show that, with the help of 
Google, we were able to put the incorrect character on 
top of the recommended list when the incorrect char-
acter was included.  This allows us to build an envi-
ronment for assisting human teachers to efficiently 
prepare test items for incorrect character identification. 
6 Summary  
The analysis of the 1718 errors produced by real stu-
dents show that similarity between pronunciations of 
competing characters contributed most to the ob-
served errors. Evidences show that the Web statistics 
are not very reliable for differentiating correct and 
incorrect characters. In contrast, the Web statistics are 
good for comparing the attractiveness of incorrect 
characters for computer assisted item authoring.  
Acknowledgements 
This research has been funded in part by the National 
Science Council of Taiwan under the grant NSC-97-
2221-E-004-007-MY2. We thank the anonymous re-
viewers for invaluable comments, and more responses 
to the comments are available in (Liu et al 2009). 
References  
D. Juang, J.-H. Wang, C.-Y. Lai, C.-C. Hsieh, L.-F. Chien, 
J.-M. Ho. 2005. Resolving the unencoded character 
problem for Chinese digital libraries, Proc. of the 5th 
ACM/IEEE Joint Conf. on Digital Libraries, 311?319. 
S.-P. Law, W. Wong, K. M. Y. Chiu. 2005. Whole-word 
phonological representations of disyllabic words in the 
Chinese lexicon: Data from acquired dyslexia, Behav-
ioural Neurology, 16, 169?177. 
K. J. Leck, B. S. Weekes, M. J. Chen. 1995. Visual and 
phonological pathways to the lexicon: Evidence from 
Chinese readers, Memory & Cognition, 23(4), 468?476. 
C.-L. Liu et al 2009. Phonological and logographic influ-
ences on errors in written Chinese words, Proc. of the 7th 
Workshop on Asian Language Resources, 47th ACL. 
C.-L. Liu, J.-H. Lin. 2008. Using structural information for 
identifying similar Chinese characters, Proc. of the 46th 
ACL, short papers, 93?96. 
MOE. 1996. Common Errors in Chinese Writings (???
???), Ministry of Education, Taiwan. 
Table 3. Incorrect characters were contained and ranked high in the recommended lists 
 SC1 SC2 RS SSST SSDT MSST MSDT Comp Pron Both 
Elist 73.92% 76.08% 4.08% 91.64% 18.39% 3.01% 1.67% 81.97% 99.00% 93.37% 
Jlist 67.52% 74.65% 6.14% 92.16% 20.24% 4.19% 3.58% 77.62% 99.32% 97.29% 
Elist 3.25 2.91 1.89 2.30 1.85 2.00 1.58 
Jlist 2.82 2.64 2.19 3.72 2.24 2.77 1.16 
28
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 84?91,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Phonological and Logographic Influences on Errors in Written 
Chinese Words 
Chao-Lin Liu1 Kan-Wen Tien2 Min-Hua Lai3 Yi-Hsuan Chuang4 Shih-Hung Wu5
1-4National Chengchi University, 5Chaoyang University of Technology, Taiwan 
{1chaolin, 296753027, 395753023, 494703036}@nccu.edu.tw, 5shwu@cyut.edu.tw 
 
Abstract 
We analyze a collection of 3208 reported errors 
of Chinese words. Among these errors, 7.2% in-
volved rarely used character, and 98.4% were 
assigned common classifications of their causes 
by human subjects. In particular, 80% of the er-
rors observed in the writings of middle school 
students were related to the pronunciations and 
30% were related to the logographs of the words. 
We conducted experiments that shed light on us-
ing the Web-based statistics to correct the errors, 
and we designed a software environment for pre-
paring test items whose authors intentionally re-
place correct characters with wrong ones. Ex-
perimental results show that using Web-based 
statistics can help us correct only about 75% of 
these errors. In contrast, Web-based statistics are 
useful for recommending incorrect characters for 
composing test items for ?incorrect character 
identification? tests about 93% of the time. 
1 Introduction 
Incorrect writings in Chinese are related to our under-
standing of the cognitive process of reading Chinese 
(e.g., Leck et al, 1995), to our understanding of why 
people produce incorrect characters and our offering 
corresponding remedies (e.g., Law et al, 2005), and 
to building an environment for assisting the prepara-
tion of test items for assessing students? knowledge of 
Chinese characters (e.g., Liu and Lin, 2008). 
Chinese characters are composed of smaller parts 
that can carry phonological and/or semantic informa-
tion. A Chinese word is formed by Chinese characters. 
For example, ??? (Singapore) is a word that con-
tains three Chinese characters. The left (?) and the 
right (?) part of ?, respectively, carry semantic and 
phonological information. The semantic information, 
in turn, is often related to the logographs that form the 
Chinese characters. Evidences show that production 
of incorrect characters are related to phonological, 
logographic, or the semantic aspect of the characters. 
Although the logographs of Chinese characters can be 
related to the lexical semantics, not all errors that are 
related to semantics were caused by the similarity in 
logographs. Some were due to the context of the 
words and/or permissible interpretations of different 
words.  
In this study, we investigate issues that are related 
to the phonological and logographical influences on 
the occurrences of incorrect characters in Chinese 
words. In Section 2, we present the details about the 
sources of the reported errors. We have collected er-
rors from a published book and from a group of mid-
dle school students. In Section 3, we analyze the 
causes of the observed errors. Native speakers of Chi-
nese were asked to label whether the observed errors 
were related to the phonological or the logographic 
reasons. In Section 4, we explore the effectiveness of 
relying on Web-based statistics to correct the errors. 
We submitted an incorrect word and a correct word 
separately to Google to find the number of web pages 
that contained these words. The correct and incorrect 
words differed in just the incorrect character. We ex-
amine whether the number of web pages that con-
tained the words can help us find the correct way of 
writing. In Section 5, we employ Web-based statistics 
in the process of assisting teachers to prepare test 
items for assessing students? knowledge of Chinese 
characters. Experimental results showed that our 
method outperformed the one reported in (Liu and Lin, 
2008), and captured the incorrect characters better 
than 93% of the time. 
2 Data Sources 
We obtained data from three major sources. A list that 
contains 5401 characters that have been believed to be 
sufficient for everyday lives was obtained from the 
Ministry of Education (MOE) of Taiwan, and we call 
the first list the Clist, henceforth. The 5401 characters 
form the core basis for the BIG-5 code, and an official 
introduction of these 5401 characters is available at 
http://www.cns11643.gov.tw/AIDB/encodings.do#encode4.  
We have two lists of words, and each word is ac-
companied by an incorrect way to write the word. The 
first list is from a book published by MOE (1996). 
The MOE provided the correct words and specified 
the incorrect characters which were mistakenly used 
to replace the correct characters in the correct words. 
The second list was collected, in 2008, from the writ-
ten essays of students of the seventh and the eighth 
grades in a middle school in Taipei. The incorrect 
characters were entered into computers based on stu-
dents? writings, ignoring those characters that did not 
actually exist and could not be entered.  
We will call the first list of word the Elist, and the 
second the Jlist from now on. Elist and Jlist contain, 
respectively, 1490 and 1718 entries. Each of these 
entries contains a correct word and the incorrect char-
acter. Hence, we can reconstruct the incorrect words 
84
easily. Two or more different ways to incorrectly 
write the same words were listed in different entries 
and considered as two entries for simplicity of presen-
tation. 
3 Error Analysis of Written Words 
Two human subjects, who are native speakers of Chi-
nese and are graduate students in Computer Science, 
examined Elist and Jlist and categorized the causes of 
errors. They compared the incorrect characters with 
the correct characters to determine whether the errors 
were pronunciation-related or logographs-related. 
Referring to an error as being ?semantics-related? is 
ambiguous. Two characters might not contain the 
same semantic part, but are still semantically related, 
e.g., misusing ???(tou1) for ???(tou2) in ????
??. In this study, we have not considered this factor. 
For this reason we refer to the errors that are related to 
the sharing of logographic parts in characters as com-
position-related. 
Among the 1490 and 1718 words in Elist and Jlist, 
respectively, the two human subjects had consensus 
over causes of 1441 and 1583 errors. It is interesting 
to learn that native speakers had a high consensus 
about the causes for the observed errors, but they did 
not always agree. To have a common standard in 
comparison, we studied the errors that the two sub-
jects had agreed categorizations.  
The statistics changed when we disregarded errors 
that involved characters not included in Clist. An er-
ror would be ignored if either the correct or the incor-
rect character did not belong to the Clist. It is possible 
for students to write such rarely used characters in an 
incorrect word just by coincidence.  
After ignoring the rare characters, there were 1333 
and 1645 words in Elist and Jlist, respectively. The 
subjects had consensus over the causes of errors for 
1285 and 1515 errors in Elist and Jlist, respectively.  
Table 1 shows the percentages of five categories of 
errors: C for the composition-related errors, P for the 
pronunciation-related errors, C&P for the intersection 
of C and P, NE for those errors that belonged to nei-
ther C nor P, and D for those errors that the subjects 
disagreed on the error categories. There were, respec-
tively, 505 composition-related and 1314 pronuncia-
tion-related errors in Jlist, so we see 
505/1645=30.70% and 1314/1645=79.88% in the 
table. Notice that C&P represents the intersection of 
C and P, so we have to deduct C&P from the sum of 
C, P, NE, and D to find the total probability, namely 1. 
It is worthwhile to discuss the implication of the 
statistics in Table 1. For the Jlist, similarity between 
pronunciations accounted for nearly 80% of the errors, 
and the ratio for the errors that are related to composi-
tions and pronunciations is 1:2.6. In contrast, for the 
Elist, the corresponding ratio is almost 1:1. The Jlist 
and Elist differed significantly in the ratios of the er-
ror types. It was assumed that the dominance of pro-
nunciation-related errors in electronic documents was 
a result of the popularity of entering Chinese with 
pronunciation-based methods. The ratio for the Jlist 
challenges this popular belief, and indicates that even 
though the errors occurred during a writing process, 
rather than typing on computers, students still pro-
duced more pronunciation-related errors than compo-
sition-related errors. Distribution over error types is 
not as related to input method as one may have be-
lieved. Nevertheless, the observation might still be a 
result of students being so used to entering Chinese 
text with pronunciation-based method that the organi-
zation of their mental lexicons is also pronunciation 
related. The ratio for the Elist suggests that editors of 
the MOE book may have chosen the examples with a 
special viewpoint in their minds ? balancing pronun-
ciation and composition related errors. 
4 Reliability of Web-based Statistics  
In this section, we examine the effectiveness of using 
Web-based statistics to differentiate correct and incor-
rect characters. The abundant text material on the 
Internet gives people to treat the Web as a corpus (e.g., 
webascorpus.org). When we send a query to Google, 
we will be informed of the number of pages (NOPs) 
that possibly contain relevant information. If we put 
the query terms in quotation marks, we should find 
the web pages that literally contain the query terms. 
Hence, it is possible for us to compare the NOPs for 
two competing phrases for guessing the correct way 
of writing. At the time of this writing, Google found 
107000 and 3220 pages, respectively, for ?strong tea? 
and ?powerful tea?. (When conducting such advanced 
searches with Google, the quotation marks are needed 
to ensure the adjacency of individual words.) Hence, 
?strong? appears to be a better choice to go with ?tea?. 
This is an idea similar to the approach that compute 
collocations based on word frequencies (cf. Manning 
and Sch?tze, 1999). Although the idea may not work 
very well for small database, the size of the current 
Web should be considered large enough. 
Using the quotation marks for the query terms en-
forced the influences of the surrounding characters in 
Chinese words, and provides a better clue for judging 
correct usage of Chinese characters. For instance,  
without the context, ??? and ??? might be used 
incorrectly to replace each other because they have 
the same pronunciation, i.e., Mei3. It is relatively 
unlikely for one to replace ??? with ??? when we 
write ???? (every one), but these two characters can 
become admissible candidates when we write ???? 
(USA) and ???? (every country).  
Table 1. Error analysis for Elist and Jlist 
 C P C&P NE D 
Elist 66.09% 67.21% 37.13% 0.23% 3.60%
Jlist 30.70% 79.88% 20.91% 2.43% 7.90%
85
4.1 Field Tests 
We test this strategy by sending the words in Elist and 
Jlist to Google to find the NOPs. We can retrieve the 
NOPs from the documents returned by Google, and 
compare the NOPs for the correct and the incorrect 
words to evaluate the strategy. Again, we focused on 
those in the 5401 words that the human subjects had 
consensus about their error types. Recall that we have 
1285 and 1515 such words in Elist and Jlist, respec-
tively. As the information available on the Web 
changes all the time, we also have to note that our 
experiments were conducted during the first half of 
March 2009. The queries were submitted at reason-
able time intervals to avoid Google?s treating our pro-
grams as malicious attackers. 
Table 2 shows the results of our investigation. We 
considered that we had a correct result when we found 
that the NOP for the correct word was larger than the 
NOP for the incorrect word. If the NOPs were equal, 
we recorded an ambiguous result; and when the NOP 
for the incorrect word was larger, we recorded an in-
correct event. We use ?C?, ?A?, and ?I? to denote ?cor-
rect?, ?ambiguous?, and ?incorrect? events in Table 2.  
The column headings of Table 2 show the setting 
of the searches with Google and the set of words that 
were used in the experiments. We asked Google to 
look for information from web pages that were en-
coded in traditional Chinese (denoted Trad). We 
could add another restriction on the source of infor-
mation by asking Google to inspect web pages from 
machines in Taiwan (denoted Twn+Trad). We were 
not sure how Google determined the languages and 
locations of the information sources, but chose to trust 
Google. The headings ?Comp? and ?Pron? indicate 
whether the words whose error types were composi-
tion and pronunciation-related, respectively.  
Table 2 shows eight distributions, providing ex-
perimental results that we observed under different 
settings. The distribution printed in bold face showed 
that, when we gathered information from sources that 
were encoded in traditional Chinese, we found the 
correct words 73.12% of the time for words whose 
error types were related to composition in Elist. Under 
the same experimental setting, we could not judge the 
correct word 4.58% of the time, and would have cho-
sen an incorrect word 22.30% of the time. 
Statistics in Table 2 indicate that web statistics is 
not a very reliable factor to judge the correct words. 
The average of the eight numbers in the ?C? rows is 
only 71.54% and the best sample is 76.59%, suggest-
ing that we did not find the correct words frequently. 
We would made incorrect judgments 24.75% of the 
time. The statistics also show that it is almost equally 
difficult to find correct words for errors that are com-
position and pronunciation related. In addition, the 
statistics reveal that choosing more features in the 
advanced search affected the final results. Using 
?Trad? offered better results in our experiments than 
using ?Twn+Trad?. This observation may arouse a 
perhaps controversial argument. Although Taiwan is 
the main area to use traditional Chinese, their web 
pages might not have used as accurate Chinese as web 
pages located in other regions. 
4.2 An Error Analysis for the Field Tests 
We have analyzed the reasons for why using Web-
based statistics did not always find the correct words. 
Frequencies might not have been a good factor to de-
termine the correctness of Chinese. However, the 
myriad amount of data on the Web should have pro-
vided a better performance.  
The most common reason for errors is that some of 
the words are really confusing such that the majority 
of the Web pages actually used the incorrect words. 
Some of errors were so popular that even one of the 
Chinese input methods on Windows XP offered 
wrong words as possible choices, e.g., ????? (the 
correct one) vs. ?????. It is interesting to note that 
people may intentionally use incorrect words in some 
occasions; for instance, people may choose to write 
homophones in advertisements.  
Another popular reason is that whether a word is 
correct depends on a larger context. For instance, ??
?? is more popular than ???? because the former 
is a popular nickname. Unless we had provided more 
contextual information about the queried words, 
checking only the NOPs of ???? and ???? led us 
to choose ????, which happened to be an incorrect 
word when we meant to find the right way to write 
????. Another difficult pair of words to distinguish 
is ???? and ????. 
Yet another reason for having a large NOP of the 
incorrect words was due to errors in segmenting Chi-
nese character strings. Consider a correct character 
string ?WXYZ?, where ?WX? and ?YZ? are two cor-
rect words. It is possible that ?XY? happens to be an 
incorrect way to write a correct word. This is the case 
for having the counts for ?????? to contribute to 
the count for ???? which is an incorrect form of 
????. 
5 Facilitating Test Item Authoring 
Incorrect character correction is a very popular type of 
test in Taiwan. There are simple test items for young 
children, and there are very challenging test items for 
the competitions among adults. Finding an attractive 
incorrect character to replace a correct character to 
form a test item is a key step in authoring test items.  
Table 2. Reliability of Web-based statistics 
Trad Twn+Trad  
Comp Pron Comp Pron 
C 73.12% 73.80% 69.92% 68.72%
A 4.58% 3.76% 3.83% 3.76%
E
list 
I 22.30% 22.44% 26.25% 27.52%
C 76.59% 74.98% 69.34% 65.87%
A 2.26% 3.97% 2.47% 5.01%
Jlist 
I 21.15% 21.05% 28.19% 29.12%
86
We have been trying to build a software environ-
ment for assisting the authoring of test items for in-
correct character correction (Liu and Lin, 2008, Liu et 
al., 2009). It should be easy to find a lexicon that con-
tains pronunciation information about Chinese charac-
ters. In contrast, it might not be easy to find visually 
similar Chinese characters with computational meth-
ods. We expanded the original Cangjie codes (OCC), 
and employed the expanded Cangjie codes (ECC) to 
find visually similar characters (Liu and Lin, 2008). 
Cangjie encoding (Chu, 2009) is a special system 
for representing the formation of Chinese characters 
with a sequence of at most five basic symbols. For 
instance, ??? and ??? are represented by ????
?? and ??????, respectively. It is evident that 
the Cangjie codes are useful for finding visually simi-
lar characters. 
With a lexicon, we can find characters that can be 
pronounced in a particular way. However, this is not 
enough for our goal. We observed that there were 
different symptoms when people used incorrect char-
acters that are related to their pronunciations. They 
may use characters that could be pronounced exactly 
the same as the correct characters. They may also use 
characters that have the same pronunciation and dif-
ferent tones with the correct character. Although rela-
tively infrequently, people may use characters whose 
pronunciations are similar to but different from the 
pronunciation of the correct character.  
We reported that replacing OCCs with ECCs to 
find visually similar characters could increase the 
chances to find similar characters. Instead of saving 
?????? for ??? directly, we divide a Chinese 
character into subareas systematically, and save the 
Cangjie codes for each of the subareas. A Chinese 
character is stored with the information about how it 
is divided into subareas and the Cangjie sequences for 
each of its subareas.  The internal code for how we 
divide ??? is 2, and the ECC for ??? has two parts: 
??? and ?????. Yet, it was not clear as to which 
components of a character should use ECCs (Liu and 
Lin, 2008; Liu et al, 2009). 
5.1 Formalizing the Extended Cangjie Codes 
We analyzed the OCCs for all the characters in Clist 
to determine the list of basic components, with com-
puter programs. We treated a basic Cangjie symbol as 
if it was a word, and computed the number of occur-
rences of n-grams based on the OCCs of the charac-
ters in Clist. Since the OCC for a character contains at 
most five symbols, the longest n-grams are 5-grams. 
Because the reason to use ECCs was to find common 
components in characters, we saved n-grams that re-
peated no less than three times in a list. After obtain-
ing this initial list of n-grams, we removed those n-
grams that were substrings of longer n-grams in the 
list.  
In addition, the n-grams that appeared no less than 
three times might not represent an actual part in any 
Chinese characters. This may happen by chance be-
cause we considered only frequencies of n-grams 
when we generated the initial list at the previous step. 
For instance, the OCC codes for ??? (shai4), ??? 
(wu4), and ??? (chen2) are ??????, ??????, 
and ??????, respectively. Although the substring 
????? appears three times, it does represent an 
actual part of Chinese characters. Hence, we manually 
examined all of the n-grams in the initial list, and re-
moved such n-grams from the list.  
In addition to considering the frequencies of n-
grams formed by the basic Cangjie codes to determine 
the list of components, we also took advantage of 
radicals that are used to categorize Chinese characters 
in typical printed dictionaries. Radicals that are stand-
alone Chinese words were included in the list of com-
ponents.  
After selecting the list of basic components with 
the above procedure, we encoded the words in Elist 
with these basic components. We inherited the 12 
ways reported in a previous work (Liu and Lin, 2008) 
to decompose Chinese characters. There are other 
methods for decomposing Chinese characters into 
components. Juang et al (2005) and their team at the 
Sinica Academia propose 13 different ways for de-
composing characters. 
At the same time when we annotated individual 
characters with their ECCs, we may revise the list of 
basic components. If a character that actually con-
tained an intuitively ?common? part and that part had 
not been included in the list of basic component, we 
would add this part into the list to make it a basic 
component and revised the ECC for all characters 
accordingly.  The judgment of being ?common? is 
subjective, but we still maintained the rule that such 
common parts must appear in more than three charac-
ters. When defining the basic components, not all 
judgments are completely objectively yet, and this is 
also the case of defining the original Cangjie codes. 
We tried to be as systematic as possible, but intuition 
sometimes stepped in. 
We repeated the procedure described in the preced-
ing paragraph five times to make sure that we were 
satisfied with the ECCs for all of the 5401 characters. 
The current list contains 794 components, and we can 
revise the list of basic components in our work when-
ever necessary. 
5.2 Recommending Incorrect Alternatives 
With the pronunciation of Chinese characters in a 
dictionary and with our ECC encodings for words in 
the Elist, we can create lists of candidate characters 
for replacing a specific correct character in a given 
word to create a test item for incorrect character cor-
rection.  
There are multiple strategies to create the candidate 
lists. We may propose the candidate characters be-
cause their pronunciations have the same sound and 
the same tone with those of the correct character (de-
noted SSST). Characters that have same sounds and 
87
different tones (SSDT), characters that have similar 
sounds and same tones (MSST), and characters that 
have similar sounds and different tones (MSDT) can 
be considered as candidates as well. It is easy to judge 
whether two Chinese characters have the same tone. 
In contrast, it is not trivial to define ?similar? sound. 
We adopted the list of similar sounds that was pro-
vided by a psycholinguistic researcher (Dr. Chia-Ying 
Lee) at the Sinica Academia. ??? (po) and ??? (bo) 
and ???(fan4) and ???(huan4) are pairs that have 
similar sounds. It was observed that these are four 
possible reasons that people used incorrect characters 
in writing. 
Because a Chinese character might be pronounced 
in multiple ways, character lists generated based on 
these strategies may include the same characters. 
More specifically, the lists SSST and SSDT may over-
lap when a character that can be pronounced in multi-
ple ways, and these pronunciations share the same 
sound and have different tones. The characters ??? 
and ??? are such examples. ??? can be pronounced 
as ?dai1? or ?dai4?, and ??? can be pronounced as 
?hao3? or ?hao4?. Hence, characters that can be pro-
nounced as ?hao3? will be listed in both SSST and 
SSDT for ???.  
In addition, we may propose characters that look 
similar to the correct character. Two characters may 
look similar for many reasons (Liu et al, 2009). The 
most common reason is that they contain the same 
components, and the other is that they belong to the 
same radical category and have the same total number 
of strokes (RS), e.g., the pairs ??? and ???, ??? 
and ???, and ??? and ???. When two characters 
contain the same component, the shared component 
might or might not locate at the same position, e.g., 
??? and ???.  
In an authoring tool, we could recommend a se-
lected number of candidate characters for replacing 
the correct character. We tried two different strategies 
to compare and choose the visually similar characters. 
The similarity is computed based on the number and 
the locations of shared Cangjie symbols in the ECCs 
of the characters. The first strategy (denoted SC1) 
gave a higher score to the shared component that lo-
cated at the same location in the two characters being 
compared. The second strategy (SC2) gave the same 
score to any shared component even if the component 
did not reside at the same location in the characters. 
The characters ???, ???, and ??? share the same 
component ???. When computing the similarity be-
tween these characters with SC1, the contribution of 
??? will be the same for any pair. When computing 
with SC2, the contribution of ??? will be larger for 
the pair ??? and ??? than for the pair ??? and ???. 
In the former case, ??? appears at the same location 
in the characters. 
 When there were more than 20 characters that re-
ceive nonzero scores in the SC1 and SC2 categories, 
we chose to select at most 20 characters that had lead-
ing scores as the list of recommended characters. 
We had to set a bound on the number of candidate 
characters, i.e., 20, for strategies SC1 and SC2.  The 
number of candidates generated from these two 
strategies can be large and artificial, depending on our 
scoring functions for determining similarities between 
characters. We did not limit the sizes of candidate 
lists that were generated by other strategies because 
those lists were created based on more objective 
methods. The rules for determining ?similar? sounds 
were given by the domain experts, so we considered 
the rules objective in this research. 
For the experiments that we reported in the follow-
ing subsection, we submitted more than 300 thousand 
of queries to Google. As we mentioned in Section 4.1, 
a frequent continual submission of queries to Google 
will make Google treat our programs as malicious 
processes. (We are studying the Google API for a 
more civilized solution.) Without the bound, it is pos-
sible to offer a very long list of candidates. On the 
other hand, it is also possible that our program does 
not find any visually similar characters for some spe-
cial characters, and this is considered a possible phe-
nomenon.  
5.3 Evaluating the Recommendations 
We examined the usefulness of these seven categories 
of candidates with errors in Elist and Jlist. The first 
set of evaluation (the inclusion tests) checked whether 
the lists of recommended characters contained the 
incorrect character in our records. The second set of 
evaluation (the ranking tests) was designed for practi-
cal application in computer assisted item generation. 
Only for those words whose actual incorrect charac-
ters were included in the recommended list, we re-
placed the correct characters in the words with the 
candidate incorrect characters, submitted the incorrect 
words to Google, and ordered the candidate characters 
based on their NOPs. We then recorded the ranks of 
the incorrect characters among all recommended 
characters.  
Since the same character may appear simultane-
ously in SC1, SC2, and RS, we computed the union of 
these three sets, and checked whether the incorrect 
characters were in the union. The inclusion rate is 
listed under Comp, representing the inclusion rate 
when we consider only logographic influences. Simi-
larly, we computed the union for SSST, SSDT, MSST, 
and MSDT, checked whether the incorrect characters 
were in the union, and recorded the inclusion rate 
under Pron, representing the inclusion rate when we 
consider only phonological influences. Finally, we 
computed the union of the lists created by the seven 
strategies, and recorded the inclusion rate under Both. 
The second and the third rows of Table 3 show the 
results of the inclusion tests when we recommended 
candidate characters with the methods indicated in the 
column headings. The data show the percentage of the 
incorrect characters being included in the lists that 
88
were recommended by the seven strategies. Notice 
that the percentages were calculated with different 
denominators. The number of composition-related 
errors was used for SC1, SC2, RS, and Comp (e.g., 
505 that we mentioned in Section 3 for Jlist); the 
number of pronunciation-related errors for SSST, 
SSDT, MSST, MSDT, and Pron (e.g., 1314 mentioned 
in Section 3 for the Jlist); the number of either of 
these two  types of errors for Both (e.g., 1475 for Jlist).  
The results recorded in Table 3 show that we were 
able to find the incorrect character quite effectively, 
achieving better than 93% for both Elist and Jlist. The 
statistics also show that it is easier to find incorrect 
characters that were used for pronunciation-related 
problems. Most of the pronunciation-related problems 
were misuses of homophones. Unexpected confusions, 
e.g., those related to pronunciations in Chinese dia-
lects, were the main reason for the failure to capture 
the pronunciation-related errors. (Namely, few pro-
nunciation-related errors were not considered in the 
information that the psycholinguist provided.) SSDT 
is a crucial complement to SSST.  
There is still room to improve our methods to find 
confusing characters based on their compositions. We 
inspected the list generated by SC1 and SC2, and 
found that, although SC2 outperformed SC1 on the 
inclusion rate, SC1 and SC2 actually generated com-
plementary lists in many cases, and should be used 
together. The inclusion rate achieved by the RS strat-
egy was surprisingly high. We found that many of the 
errors that were captured by the RS strategy were also 
captured by the SSST strategy. 
The fourth and the fifth rows of Table 3 show the 
effectiveness of relying on Google to rank the candi-
date characters for recommending an incorrect charac-
ter. The rows show the average ranks of the included 
cases. The statistics show that, with the help of 
Google, we were able to put the incorrect character on 
top of the recommended list when the incorrect char-
acter was included.  This allows us to build an envi-
ronment for assisting human teachers to efficiently 
prepare test items for incorrect character identification. 
Note that we did not provide data for all columns 
in the fourth and the firth rows. Unlike that we show 
the inclusion rates in the second and the third rows, 
the fourth and the fifth rows show how the actual in-
correct characters were ranked in the recommended 
lists. Hence, we need to have a policy to order the 
characters of different lists to find the ranks of the 
incorrect characters in the integrated list.  
However, integrating the lists is not necessary and 
can be considered confusing to the teachers. The se-
lection of incorrect characters from different lists is 
related to the goals of the assessment, and it is better 
to leave the lists separated for the teachers to choose. 
The same phenomenon and explanation apply to the 
sixth and the seventh rows as well. 
The sixth and the seventh rows show the average 
numbers of candidate characters proposed by different 
methods. Statistics shown between the second and the 
fifth rows are related to the recall rates (cf. Manning 
and Sch?tz, 1999) achieved by our system. For these 
four rows, we calculated how well the recommended 
lists contained the reported errors and how the actual 
incorrect characters ranked in the recommended lists. 
The sixth and the seventh rows showed the costs for 
these achievements, measured by the number of rec-
ommended characters. The sum of the sixth and the 
seventh rows, i.e., 103.59 and 108.75, are, respec-
tively, the average numbers of candidate characters 
that our system recommended as possible errors re-
corded in Elist and Jlist. (Note that some of these 
characters were repeated.) 
There are two ways to interpret the statistics shown 
in the sixth and the seventh rows. Comparing the cor-
responding numbers on the fourth and the sixth rows, 
e.g., 3.25 and 19.27, show the effectiveness of using 
the NOPs to rank the candidate characters. The ranks 
of the actual errors were placed at very high places, 
considering the number of the originally recom-
mended lists. The other way to use the statistics in the 
sixth and the seventh rows is to compute the average 
precision. For instance, we recommended an average 
19.13 characters in SSST to achieve the 91.64 inclu-
sion rate. The recall rate is very high, but the averaged 
precision is very low. This, however, is not a very 
convincing interpretation of the results. Having as-
sumed that there was only one best candidate as in our 
experiments, it was hard to achieve high precision 
rates. The recall rates are more important than the 
precision rates, particularly when we have proved that 
the actual errors were ranked among the top five al-
ternatives. 
When designing a system for assisting the author-
ing of test items, it is not really necessary to propose 
all of the characters in the categories. In the reported 
experiments, choosing the top 5 or top 10 candidates 
will contain the most of the actual incorrect characters 
based on the statistics shown in the fourth and the 
fifth rows. Hence the precision rates can be signifi-
cantly increased practically. We do not have to merge 
the candidate characters among different categories 
Table 3. Incorrect characters were contained and ranked high in the recommended lists 
 SC1 SC2 RS SSST SSDT MSST MSDT Comp Pron Both 
Elist 73.92% 76.08% 4.08% 91.64% 18.39% 3.01% 1.67% 81.97% 99.00% 93.37% 
Jlist 67.52% 74.65% 6.14% 92.16% 20.24% 4.19% 3.58% 77.62% 99.32% 97.29% 
Elist 3.25 2.91 1.89 2.30 1.85 2.00 1.58 
Jlist 2.82 2.64 2.19 3.72 2.24 2.77 1.16 
Elist 19.27 17.39 11.34 19.13 8.29 19.02 9.15 
Jlist 17.58 16.24 12.52 22.85 9.75 22.11 7.68 
89
because choosing the categories of incorrect charac-
ters depends on the purpose of the assessment. Reduc-
ing the length of the candidate list increases the 
chances of reducing the recall rates. Achieving the 
best trade off between precision and recall rates relies 
on a more complete set of experiments that involve 
human subjects. 
Furthermore, in a more realistic situation, there can 
be more than one ?good? incorrect character, not just 
one and only gold standard as in the reported experi-
ments. It is therefore more reasonable the compute the 
precision rates based the percentage of ?acceptable? 
incorrect characters. Hence, the precision rates are 
likely to increase and become less disconcerting.  
We reported experimental results in which we 
asked 20 human subjects to choose an incorrect char-
acter for 20 test items (Liu et al, 2009). The best so-
lutions were provided by a book. The recommenda-
tions provided by our previous system and chosen by 
the human subjects achieved comparable qualities.  
Notice that the numbers do not directly show the 
actual number of queries that we had to submit to 
Google to receive the NOPs for ranking the characters. 
Because the lists might contain the same characters, 
the sum of the rows showed just the maximum num-
ber of queries that we submitted. Nevertheless, they 
still served as good estimations, and we actually sub-
mitted 103.59?1441(=149273) and 108.75?1583 
(=172151) queries to Google for Elist and Jlist in ex-
periments from which we obtained the data shown in 
the fourth and the fifth rows. These quantities ex-
plained why we had to be cautious about how we 
submitted queries to Google. When we run our pro-
gram for just a limited number of characters, the prob-
lems caused by intensive queries should not be very 
serious. 
5.4 Discussions 
Dividing characters into subareas proved to be crucial 
in our experiments (Liu and Lin, 2008; Liu et al, 
2009), but this strategy is not perfect, and could not 
solve all of the problems. The way we divided Chi-
nese characters into subareas like (Juang et al, 2005; 
Liu and Lin, 2008) sometimes contributed to the fail-
ure of our current implementation to capture all of the 
errors that were related to the composition of the 
words. The most eminent reason is that how we di-
vide characters into areas. Liu and Lin (2008) fol-
lowed the division of Cangjie (Chu, 2009), and Juang 
et al (2005) proposed an addition way to split the 
characters.   
The best divisions of characters appear to depend 
on the purpose of the applications. Recall that each 
part of the character is represented by a string of 
Cangjie codes in ECCs. The separation of Cangjie 
codes in ECCs was instrumental to find the similarity 
of ??? and ??? because ??? is a standalone subpart 
in both ??? and ???. The Cangjie system has a set 
of special rules to divide Chinese characters (Chu, 
2009; Lee, 2008). Take ??? and ??? for example. 
The component ??? is recorded as an standalone part 
in ???, but is divided into two parts in ???. Hence, 
??? is stored as one string, ?????, in ??? and as 
two strings, ???? and ???, in ???. The different 
ways of saving ??? in two different words made it 
harder to find the similarity between ??? and ???. 
An operation of concatenation is in need, but the 
problems are that it is not obvious to tell when the 
concatenation operations are useful and which of the 
parts should be rejoined. Hence, using the current 
methods to divide Chinese characters, it is easy to 
find the similar between ??? and ??? but difficult to 
find the similar between ??? and ???. In contrast, if 
we enforce a rule to save ??? as one string of Cang-
jie code, it will turn the situations around. Determin-
ing the similarity between ??? and ??? will be more 
difficult than finding the similarity between ??? and 
???. 
Due to this observation, we have come to believe 
that it is better to save the Chinese characters with 
more detailed ECCs. By saving all detailed informa-
tion about a character, our system can offer candidate 
characters based on users? preferences which can be 
provided via a good user interface. This flexibility can 
be very helpful when we are preparing text materials 
for experiments for psycholinguistics or cognitive 
sciences (e.g., Leck et al 1995; Yeh and Li, 2002).  
6 Summary  
The analysis of the 1718 errors produced by real stu-
dents show that similarity between pronunciations of 
competing characters contributed most to the ob-
served errors. Evidences show that the Web statistics 
are not very reliable for differentiating correct and 
incorrect characters. In contrast, the Web statistics are 
good for comparing the attractiveness of incorrect 
characters for computer assisted item authoring.  
Acknowledgments 
This research was supported in part by the National 
Science Council of Taiwan under grant NSC-97-
2221-E-004-007-MY2. We thank anonymous review-
ers for their invaluable comments. 
References  
B.-F. Chu. 2009. Handbook of the Fifth Generation of 
the Cangjie Input Method, available at 
http://www.cbflabs.com/book/ocj5/ocj5/index.html. 
Last visited on 30 April 2009. 
D. Juang, J.-H. Wang, C.-Y. Lai, C.-C. Hsieh, L.-F. 
Chien, J.-M. Ho. 2005. Resolving the unencoded 
character problem for Chinese digital libraries, 
Proc. of the 5th ACM/IEEE Joint Conf. on Digital 
Libraries, 311?319. 
S.-P. Law, W. Wong, K. M. Y. Chiu. 2005. Whole-
word phonological representations of disyllabic 
90
words in the Chinese lexicon: Data from acquired 
dyslexia, Behavioural Neurology, 16, 169?177. 
K. J. Leck, B. S. Weekes, M. J. Chen. 1995. Visual 
and phonological pathways to the lexicon: Evi-
dence from Chinese readers, Memory & Cognition, 
23(4), 468?476. 
H. Lee. 2008. Cangjie Input Methods in 30 Days, 
http://input.foruto.com/cjdict/Search_1.php, Foruto 
Company, Hong Kong. Last visited on 30 April 
2009. 
C.-L. Liu, K.-W. Tien, Y.-H. Chuang, C.-B. Huang, 
J.-Y. Weng. 2009. Two applications of lexical in-
formation to computer-assisted item authoring for 
elementary Chinese, Proc. of the 22nd Int?l Conf. 
on Industrial Engineering & Other Applications of 
Applied Intelligent Systems, 470?480. 
C.-L. Liu, J.-H. Lin. 2008. Using structural informa-
tion for identifying similar Chinese characters, 
Proc. of the 46th ACL, short papers, 93?96. 
C. D. Manning, H. Sch?tze. Foundations of Statistical 
Natural Language Processing. The MIT Press. 
1999. 
MOE. 1996. Common Errors in Chinese Writings (?
?????), Ministry of Education, Taiwan. 
S.-L. Yeh, J.-L. Li. 2002. Role of structure and com-
ponent in judgments of visual similarity of Chinese 
characters, Journal of Experimental Psychology: 
Human Perception and Performance, 28(4), 933?
947.
 
91
Coling 2010: Poster Volume, pages 739?747,
Beijing, August 2010
Visually and Phonologically Similar Characters in Incorrect 
Simplified Chinese Words 
Chao-Lin Liu? Min-Hua Lai? Yi-Hsuan Chuang? Chia-Ying Lee?
???Department of Computer Science; ??Center for Mind, Brain, and Learning 
National Chengchi University 
?Institute of Linguistics, Academia Sinica 
{?chaolin, ?g9523, ?g9804}@cs.nccu.edu.tw, ?chiaying@gate.sinica.edu.tw 
Abstract
Visually and phonologically similar cha-
racters are major contributing factors for 
errors in Chinese text. By defining ap-
propriate similarity measures that consid-
er extended Cangjie codes, we can identi-
fy visually similar characters within a 
fraction of a second. Relying on the pro-
nunciation information noted for individ-
ual characters in Chinese lexicons, we 
can compute a list of characters that are 
phonologically similar to a given charac-
ter. We collected 621 incorrect Chinese 
words reported on the Internet, and ana-
lyzed the causes of these errors. 83% of 
these errors were related to phonological 
similarity, and 48% of them were related 
to visual similarity between the involved 
characters. Generating the lists of phono-
logically and visually similar characters, 
our programs were able to contain more 
than 90% of the incorrect characters in 
the reported errors. 
1 Introduction 
In this paper, we report the experience of our 
studying the errors in simplified Chinese words. 
Chinese words consist of individual characters. 
Some words contain just one character, but most 
words comprise two or more characters. For in-
stance, ??? (mai4)1 has just one character, and 
???? (yu3 yan2) is formed by two characters. 
Two most common causes for writing or typing 
incorrect Chinese words are due to visual and 
phonological similarity between the correct and 
1 We show simplified Chinese characters followed by 
their Hanyu pinyin. The digit that follows the symbols 
for the sound is the tone for the character. 
the incorrect characters. For instance, one might 
use ??? (hwa2) in the place of ???(hwa4)  in 
?????? (ke1 hwa4 xing2 xiang4) partially 
because of phonological similarity; one might 
replace ??? (zhuo2) in ?????? (xin1 lao2 
li4 zhuo2) with ??? (chu4) partially due to visu-
al similarity. (We do not claim that the visual or 
phonological similarity alone can explain the 
observed errors.) 
Similar characters are important for under-
standing the errors in both traditional and simpli-
fied Chinese. Liu et al (2009a-c) applied tech-
niques for manipulating correctness of Chinese 
words to computer assisted test-item generation. 
Research in psycholinguistics has shown that the 
number of neighbor characters influences the 
timing of activating the mental lexicon during the 
process of understanding Chinese text (Kuo et al 
2004; Lee et al 2006).  Having a way to compute 
and find similar characters will facilitate the 
process of finding neighbor words, so can be in-
strumental for related studies in psycholinguistics. 
Algorithms for optical character recognition for 
Chinese and for recognizing written Chinese try 
to guess the input characters based on sets of 
confusing sets (Fan et al 1995; Liu et al, 2004). 
The confusing sets happen to be hand-crafted 
clusters of visually similar characters. 
It is relatively easy to judge whether two cha-
racters have similar pronunciations based on 
their records in a given Chinese lexicon. We will 
discuss more related issues shortly.  
To determine whether two characters are vi-
sually similar is not as easy. Image processing 
techniques may be useful but is not perfectly 
feasible, given that there are more than fifty 
thousand Chinese characters (HanDict, 2010) 
and that many of them are similar to each other 
in special ways.  Liu et al (2008) extend the 
Cangjie codes (Cangjie, 2010; Chu, 2010) to en-
code the layouts and details about traditional 
739
Chinese characters for computing visually simi-
lar characters. Evidence observed in psycholin-
guistic studies offers a cognition-based support 
for the design of Liu et al?s approach (Yeh and 
Li, 2002). In addition, the proposed method 
proves to be effective in capturing incorrect tra-
ditional Chinese words (Liu et al, 2009a-c). 
In this paper, we work on the errors in simpli-
fied Chinese words by extending the Cangjie 
codes for simplified Chinese. We obtain two lists 
of incorrect words that were reported on the In-
ternet, analyze the major reasons that contribute 
to the observed errors, and evaluate how the new 
Cangjie codes help us spot the incorrect charac-
ters. Results of our analysis show that phonolog-
ical and visual similarities contribute similar por-
tions of errors in simplified and traditional Chi-
nese. Experimental results also show that, we can 
catch more than 90% of the reported errors. 
We go over some issues about phonological 
similarity in Section 2, elaborate how we extend 
and apply Cangjie codes for simplified Chinese 
in Section 3, present details about our experi-
ments and observations in Section 4, and discuss 
some technical issues in Section 5.  
2 Phonologically Similar Characters 
The pronunciation of a Chinese character in-
volves a sound, which consists of the nucleus and 
an optional onset, and a tone. In Mandarin Chi-
nese, there are four tones. (Some researchers in-
clude the fifth tone.) 
In our work, we consider four categories of 
phonological similarity between two characters: 
same sound and same tone (SS), same sound and 
different tone (SD), similar sound and same tone 
(MS), and similar sound and different tone (MD).  
We rely on the information provided in a lex-
icon (Dict, 2010) to determine whether two cha-
racters have the same sound or the same tone. 
The judgment of whether two characters have 
similar sound should consider the language expe-
rience of an individual. One who live in the 
southern and one who live in the northern China 
may have quite different perceptions of ?similar? 
sound. In this work, we resort to the confusion 
sets observed in a psycholinguistic study con-
ducted at the Academic Sinica. 
Some Chinese characters are heteronyms. Let 
C1 and C2 be two characters that have multiple 
pronunciations. If C1 and C2 share one of their 
pronunciations, we consider that C1 and C2 be-
long to the SS category. This principle applies 
when we consider phonological similarity in oth-
er categories. 
One challenge in defining similarity between 
characters is that the pronunciations of a charac-
ter can depend on its context. The most common 
example of tone sandhi in Chinese (Chen, 2000) 
is that the first third-tone character in words 
formed by two adjacent third-tone characters will 
be pronounced in the second tone. At present, we 
ignore the influences of context when determin-
ing whether two characters are phonologically 
similar.  
Although we have confined our definition of 
phonological similarity to the context of the 
Mandarin Chinese, it is important to note the in-
fluence of sublanguages within the Chinese lan-
guage family will affect the perception of phono-
logical similarity. Sublanguages used in different 
areas in China, e.g., Shanghai, Min, and Canton 
share the same written forms with the Mandarin 
Chinese, but have quite different though related 
pronunciation systems. Hence, people living in 
different areas in China may perceive phonologi-
cal similarity in very different ways. The study in 
this direction is beyond the scope of the current 
study.  
3 Visually Similar Characters 
Figure 1 shows four groups of visually similar 
characters. Characters in group 1 and group 2 
differ subtly at the stroke level. Characters in 
group 3 share the components on their right sides. 
The shared component of the characters in group 
4 appears at different places within the characters. 
Radicals are used in Chinese dictionaries to 
organize characters, so are useful for finding vi-
sually similar characters. The characters in group 
1 and group 2 belong to the radicals ??? and ? ?,
respectively. Notice that, although the radical for 
group 2 is clear, the radical for group 1 is not 
obvious because ??? is not a standalone compo-
nent.
However, the shared components might not be 
the radicals of characters. The shared compo-
nents in groups 3 and 4 are not the radicals. In 
Figure 1. Examples of visually similar characters
740
many cases, radicals are semantic components of 
Chinese characters. In groups 3 and 4, the shared 
components carry information about the pronun-
ciations of the characters. Hence, those charac-
ters are listed under different radicals, though 
they do look similar in some ways.  
Hence, a mechanism other than just relying on 
information about characters in typical lexicons 
is necessary, and we will use the extended Cang-
jie codes for finding visually similar characters. 
3.1 Cangjie Codes for Simplified Chinese 
Table 1 shows the Cangjie codes for the 13 
characters listed in Figure 1 and five other 
characters. The ?ID? column shows the 
identification number for the characters, and we 
will refer to the ith character by ci, where i is the 
ID. The ?CC? column shows the Chinese 
characters, and the ?Cangjie? column shows the 
Cangjie codes. Each symbol in the Cangjie codes 
corresponds to a key on the keyboard, e.g. ???
and ? ? ? collocate with ?W? and ?L?, 
respectively. Information about the complete 
correspondence is available on the Wikipedia2.
Using the Cangjie codes saves us from using 
image processing methods to determine the de-
grees of similarity between characters. Take the 
Cangjie codes for the characters in group 2 (c5, c6,
and c7) for example. It is possible to find that the 
characters share a common component, based on 
the shared substrings of the Cangjie codes, i.e., 
????.  Using the common substring  (shown in 
black bold) of the Cangjie codes, we may also 
find the shared component ??? for characters in 
group 3 (c10, c11, and c12), the shared component 
??? in c13 and c14, the shared component ??? in 
c15 and c16, and the shared component ? ? in c16
and c17.
 Despite the perceivable advantages, these 
original Cangjie codes are not good enough. In 
order to maintain efficiency in inputting Chinese 
characters, the Cangjie codes have been limited 
to no more than five keys. Thus, users of the 
Cangjie input method must familiarize them-
selves with the principles for simplifying the 
Cangjie codes. While the simplified codes help 
the input efficiency, they also introduce difficul-
ties and ambiguities when we compare the Cang-
2en.wikipedia.org/wiki/Cangjie_input_method#Keyboard_la
yout ; last visited on 22 April 2010. 
jie codes for computing similar characters. The 
prefix ???? in c16 and c17 can represent ? ?, 
??? (e.g., c8), and ??? (e.g., c9). Characters 
whose Cangjie codes include ???? may con-
tain any of these three components, but they do 
not really look alike. 
Therefore, we augment the original Cangjie 
codes by using the complete Cangjie codes and 
annotate each Chinese character with a layout 
identification that encodes the overall contours of 
the characters. This is how Liu and his col-
leagues (2008) did for the Cangjie codes for tra-
ditional Chinese characters, and we employ a 
similar exploration for the simplified Chinese. 
3.2 Augmenting the Cangjie Codes 
Figure 2 shows the twelve possible layouts that 
are considered for the Cangjie codes for 
simplified Chinese characters. Some of the 
layouts contain smaller areas, and the rectangles 
show a subarea within a character. The smaller 
areas are assigned IDs between one and three. 
Notice that, to maintain read-ability of the 
figures, not all IDs for subareas are shown in 
Figure 2. An example character is provided 
below each layout. From left to right and from 
top to bottom, each layout is assigned an 
identification number from 1 to 12. For example, 
the layout ID of ??? is 8. ??? has two parts, i.e., 
??? and ???.
Researchers have come up with other ways to 
ID CC Cangjie ID CC Cangjie 
1 ? ?! 10 ?! ????!
2 ? ??! 11 ?! ???!
3 ? ??! 12 ?! ???!
4 ? ???! 13 ?! ???!
5 ? ????! 14 ?! ????!
6 ? ????! 15 ?! ????!
7 ? ???! 16 ?! ????!
8 ? ???? 17 ?! ?????!
9 ? ???? 18 ?! ?????!
Table 1. Examples of Cangjie codes 
Figure 2. Layouts of Chinese characters 
741
decompose individual Chinese characters. The 
Chinese Document Lab at the Academia Sinica 
proposed a system with 13 operators for describ-
ing the relationships among components in Chi-
nese characters (CDL, 2010). Lee (2010b) pro-
pose more than 30 possible layouts.  
The layout of a character affects how people 
perceive visual similarity between characters. 
For instance, c16 in Table 1 is more similar to c17
than to c18, although they share ? ?. We rely on 
the expertise in Cangjie codes reported in (Lee, 
2010a) to split the codes into parts. 
Table 2 shows the extended codes for some 
characters listed in Table 1. The ?ID? column 
provides links between the characters listed in 
both Table 1 and Table 2. The ?CC? column 
shows the Chinese characters. The ?LID? column 
shows the identifications for the layouts of the 
characters. The columns with headings ?P1?, 
?P2?, and ?P3? show the extended Cangjie codes, 
where ?Pi? shows the ith part of the Cangjie 
codes, as indicated in Figure 2. 
We decide the extended codes for the parts 
with the help of computer programs and subjec-
tive judgments. Starting from the original Cang-
jie codes, we can compute the most frequent sub-
strings just like we can compute the frequencies 
of n-grams in corpora (cf. Jurafsky and Martin, 
2009). Computing the most common substrings 
in the original codes is not a complex task be-
cause the longest original Cangjie codes contain 
just five symbols.   
Often, the frequent substrings are simplified 
codes for popular components in Chinese charac-
ters, e.g., ? ? and ? ?. The original codes for ? ?
and ? ? are ????? and ?????, but they are 
often simplified to ???? and ????, respec-
tively.  When simplified, ? ? have the same 
Cangjie code with ???, and ? ? have the same 
Cangjie code with ??? and ???.
After finding the frequent substrings, we veri-
fy whether these frequent substrings are simpli-
fied codes for meaningful components. For mea-
ningful components, we replace the simplified 
codes with complete codes. For instance the 
Cangjie codes for ??? and ??? are extended to 
include ??? in Table 2, where we indicate the 
extended keys that did not belong to the original 
Cangjie codes in boldface and with a surrounding 
box. Most of the non-meaningful frequent sub-
strings have two keys: one is the last key of a 
part, and the other is the first key of another part. 
They were by observed by coincidence. 
Although most of the examples provided in 
Table 2 indicate that we expand only the first 
part of the Cangjie codes, it is absolutely possible 
that the other parts, i.e., P2 and P3, may need to 
be extended too. c19 shows such an example. 
Replacing simplified codes with complete 
codes not only help us avoid incorrect matches 
but also help us find matches that would be 
missed due to simplification of Cangjie codes. 
Using just the original Cangjie codes in Table 1, 
it is not easy to determine that c18 (???) in Table 
1 shares a component (? ?) with c16 and c17 (???
and ???). In contrast, there is a chance to find 
the similarity with the extended Cangjie codes in 
Table 2, given that all of the three Cangjie codes 
include ?????.
We can see an application of the LIDs, using 
???, ??? and ??? as an example. Consider the 
case that we want to determine which of ???
and ??? is more similar to ???. Their extended 
Cangjie codes will indicate that ??? is the an-
swer to this question for two reasons. First, ???
and ??? belong to the same type of layout; and, 
second, the shared components reside at the same 
area in ??? and ???.
3.3 Similarity Measures 
The main differences between the original and 
the extended Cangjie codes are the degrees of 
details about the structures of the Chinese cha-
racters. By recovering the details that were ig-
nored in the original codes, our programs will be 
ID CC LID P1 P2 P3
5 ? 2 ???! ??! !
6 ? 2 ???! ??! !
7 ? 2 ???! ?! !
10 ? 10 ??! ?! ?!
11 ? 10 ?! ?! ?!
12 ? 10 ?! ?! ?!
13 ? 5 ?! ??! !
14 ? 9 ?! ?! ??!
15 ? 2 ???! ??! !
16 ? 2 ???! ??! !
17 ? 2 ???! ???! !
18 ? 3 ???! ??! ?!
19 ? 4 ?! ???! ??!
Table 2. Examples of extended Cangjie codes 
742
better equipped to find the similarity between 
characters.  
In the current study, we experiment with three 
different scoring methods to measure the visual 
similarity between two characters based on their 
extended Cangjie codes. Two of these methods 
had been tried by Liu and his colleagues? study 
for traditional Chinese characters (Liu et al, 
2009b-c). The first method, denoted SC1, con-
siders the total number of matched keys in the 
matched parts (without considering their part 
IDs). Let ci denote the i
th character listed in Table 
2. We have SC1(c15, c16) = 2 because of the 
matched ????. Analogously, we have SC1(c19,
c16) = 2.  
The second method, denoted SC2, includes 
the score of SC1 and considers the following 
conditions: (1) add one point if the matched parts 
locate at the same place in the characters and (2) 
if the first condition is met, an extra point will be 
added if the characters belong to the same layout.  
Hence, we have SC2(c15, c16) =SC1(c15,
c16)+1+1=4 because (1) the matched ???? lo-
cate at P2 in both characters and (2) c15 and c16
belong to the same layout. Assuming that c16 be-
longs to layout 5, than SC2(c15, c16) would be-
come 3. In contrast, we have SC2(c19, c16)=2. No 
extra weights for the matching ???? because it 
locates at different parts in the characters. The 
extra weight considers the spatial influences of 
the matched parts on the perception of similarity. 
While splitting the extended Cangjie codes in-
to parts allows us to tell that c15 is more similar 
to c16 than to c19, it also creates a new barrier in 
computing similarity scores. An example of this 
problem is that SC2(c17, c18)=0. This is because 
that ????? at P1 in c17 can match neither ??
?? at P2 nor ??? at P3 in c18.
To alleviate this problem, we consider SC3 
which computes the similarity in three steps. 
First, we concatenate the parts of a Cangjie code 
for a character. Then, we compute the longest 
common subsequence (LCS) (cf. Cormen et al, 
2009) of the concatenated codes of the two cha-
racters being compared, and compute a Dice?s 
coefficient (cf. Croft et al, 2010) as the similari-
ty. Let X and Y denote the concatenated, ex-
tended Cangjie codes for two characters, and let 
Z be the LCS of X and Y. The similarity is de-
fined by the following equation.  
S
YX
Z
DiceLCS stringoflength theisS where,
2

u
   (1) 
We compute another Dice?s coefficient be-
tween X and Y. The formula is the similar to (1), 
except that we set Z to the longest common con-
secutive subsequence. We call this score 
LCCSDice . Notice that LCSLCCS DiceDice d ,
1dLCCSDice , and 1dLCSDice  . Finally, SC3 of two 
characters is the sum of their SC2, LCCSDiceu10 ,
and LCSDiceu5 . We multiply the Dice?s coeffi-
cients with constants to make them as influential 
as the SC2 component in SC3. The constants 
were not scientifically chosen, but were selected 
heuristically. 
4 Error Analysis and Evaluation 
We evaluate the effectiveness of using the pho-
nologically and visually similar characters to 
captures errors in simplified Chinese words with 
two lists of reported errors that were collected 
from the Internet.  
4.1 Data Sources 
We need two types of data for the experiments. 
The information about the pronunciation and 
structures of the Chinese characters help us gen-
erate lists of similar characters. We also need 
reported errors so that we can evaluate whether 
the similar characters catch the reported errors. 
A lexicon that provides the pronunciation in-
formation about Chinese characters and a data-
base that contains the extended Cangjie codes are 
necessary for our programs to generate lists of 
characters that are phonologically and visually 
similar to a given character. 
It is not difficult to acquire lexicons that show 
standard pronunciations for Chinese characters. 
As we stated in Section 2, the main problem is 
that it is not easy to predict how people in differ-
ent areas in China actually pronounce the charac-
ters. Hence, we can only rely on the standards 
that are recorded in lexicons.  
With the procedure reported in Section 3.2, we 
built a database of extended Cangjie codes for 
the simplified Chinese. The database was de-
signed to contain 5401 common characters in the 
BIG5 encoding, which was originally designed 
for the traditional Chinese. After converting the 
traditional Chinese characters to the simplified 
counterparts, the database contained only 5170
743
different characters. 
We searched the Internet for reported errors 
that were collected in real-world scenarios, and 
obtained two lists of errors. The first list3 came 
from the entrance examinations for senior high 
schools in China, and the second list4 contained 
errors observed at senior high schools in China. 
We used 160 and 524 errors from the first and 
the second lists, respectively, and we refer to the 
combined list as the Ilist. An item of reported 
error contained two parts: the correct word and 
the mistaken character, both of which will be 
used in our experiments. 
4.2 Preliminary Data Analysis 
Since our programs can compare the similarity 
only between characters that are included in our 
lexicon, we have to exclude some reported errors 
from the Ilist. As a result, we used only 621 er-
rors in this section.  
Two native speakers subjectively classified the 
causes of these errors into three categories based 
on whether the errors were related to phonologi-
cal similarity, visual similarity, or neither. Since 
the annotators did not always agree on their clas-
sifications, the final results have five interesting 
categories: ?P?, ?V?, ?N?, ?D?, and ?B? in Table 
3. P and V indicate that the annotators agreed on 
the types of errors to be related to phonological 
and visual similarity, respectively. N indicates 
that the annotators believed that the errors were 
not due to phonological or visual similarity. D 
indicates that the annotators believed that the 
errors were due to phonological or visual similar-
ity, but they did not have a consensus. B indi-
cates the intersection of P and V.  
Table 3 shows the percentages of errors in 
these categories. To get 100% from the table, we 
can add up P, V, N, and D, and subtract B from 
the total. In reality there are errors of type N, and 
Liu and his colleagues (2009b) reported this type 
of errors. Errors in this category happened to be 
missing in the Ilist. Based on our and Liu?s ob-
3www.0668edu.com/soft/4/12/95/2008/2008091357140.htm
 ; last visited on 22 April 2010. 
4 gaozhong.kt5u.com/soft/2/38018.html; last visited on 22 
April 2010. 
servations, the percentages of phonological and 
visual similarities contribute to the errors in sim-
plified and traditional Chinese words with simi-
lar percentages.  
4.3 Experimental Procedure 
We design and employ the ICCEval procedure 
for the evaluation task. 
At step 1, given the correct word and the cor-
rect character to be intentionally replaced with 
incorrect characters, we created a list of charac-
ters based on the selection criterion. We may 
choose to evaluate phonologically or visually 
similar characters. For a given character, ICCEv-
al can generate characters that are in the SS, SD, 
MS, and MD categories for phonologically simi-
lar characters (cf. Section 2). For visually similar 
characters, ICCEval can select characters based 
on SC1, SC2, and SC3 (cf. Section 3.3). In addi-
tion, ICCEval can generate a list of characters 
that belong to the same radical and have the same 
number of strokes with the correct character. In 
the experimental results, we refer to this type of 
similar characters as RS.
At step 2, for a correct word that people origi-
nally wanted to write, we replaced the correct 
character with an incorrect character with the 
characters that were generated at step 1, submit-
ted the incorrect word to Google AJAX Search 
 P V N D B 
Ilist 83.1 48.3 0 3.7 35.1
Table 3. Percentages of types of errors
Procedure ICCEval
Input:
ccr: the correct character; cwd:
the correct word; crit: the selec-
tion criterion; num: number of re-
quested characters; rnk: the cri-
terion to rank the incorrect 
words;
Output: a list of ranked candidates 
for ccr 
Steps:
1. Generate a list, L, of charac-
ters for ccr with the specified 
criterion, crit. When using SC1, 
SC2, or SC3 to select visually 
similar characters, at most num
characters will be selected. 
2. For each c in L, replace ccr in 
cwd with c, submit the resulting 
incorrect word to Google, and 
record the ENOP. 
3. Rank the list of incorrect words 
generated at step 2, using the 
criterion specified by rnk.
4. Return the ranked list. 
744
API, and extracted the estimated numbers of 
pages (ENOP) 5  that contained the incorrect 
words. In an ordinary interaction with Google, an 
ENOP can be retrieved from the search results, 
and it typically follows the string ?Results 1-
10 of about? on the upper part of the browser 
window. Using the AJAX API, we just have to 
parse the returned results with a simple method.  
Larger ENOPs for incorrect words suggest 
that these words are incorrect words that people 
frequently used on their web pages. Hence, we 
ranked the similar characters based on their 
ENOPs at step 3, and return the list. 
Since the reported errors contained informa-
tion about the incorrect ways to write the correct 
words, we could check whether the real incorrect 
characters were among the similar characters that 
our programs generated at step 1 (inclusion tests). 
We could also check whether the actual incorrect 
characters were ranked higher in the ranked lists 
(ranking tests). 
Take the word ?????? as an example. In 
the collected data, it is reported that people wrote 
this word as ??????, i.e., the second charac-
ter was incorrect. Hoping to capture the error, 
ICCEval generated a list of possible substitutions 
for ??? at step 1. Depending on the categories 
of sources of errors, ICCEval generated a list of 
characters. When aiming to test the effectiveness 
of visually similar characters, we could ask IC-
CEval to apply SC3 to generate a list of alterna-
tives for ???, possibly including ???, ???, 
???, and other candidates. At step 2, we created 
and submitted query strings ??????, ???
???, and ?????? to obtain the ENOPs for 
the candidates. If the ENOPs were, respectively, 
410000, 26100, and 7940, these candidates 
would be returned in the order of ???, ???, and 
???. As a result, the returned list contained the 
actual incorrect character ???, and placed ???
on top of the ranked list. 
Notice that we considered the contexts in 
which the incorrect characters appeared to rank. 
We did not rank the incorrect characters with just 
the unigrams. In addition, although this running 
example shows that we ranked the characters 
directly with the ENOPs, we also ranked the list 
5According to (Croft et al, 2010), the ENOPs may not re-
flect the actual number of pages on the Internet. 
of alternatives with pointwise mutual information: 
 
)Pr()Pr(
)Pr(
,
XC
XC
XCPMI
u
?
 ,                 (2) 
where X is the candidate character to replace the 
correct character and C is the correct word ex-
cluding the correct character to be replaced. To 
compute the score of replacing ??? with ??? in 
??????, X = ???, C=??????, and (C?X)
is ??????. (?!denotes a character to be re-
placed.) PMI is a common tool for judging collo-
cations in natural language processing. (cf. Ju-
rafsky and Martin, 2009). 
It would demand very much computation ef-
fort to find Pr(C). Fortunately, we do not have to 
consider Pr(C) because it is a common denomi-
nator for all incorrect characters. Let X1 and X2
be two competing candidates for the correct cha-
racter. We can ignore Pr(C) because of the fol-
lowing relationship. 
   
)Pr(
)Pr(
)Pr(
)Pr(
,,
2
2
1
1
21 X
XC
X
XC
XCPMIXCPMI
?
t
?
?t
Hence, X1 prevails if  1, XCscore  is larger. 
 
)Pr(
)Pr(
,
X
XC
XCscore
?                    (3) 
In our work, we approximate the probabilities 
used in (3) by the corresponding frequencies that 
we can collect through Google, similar to the 
methods that we used to collect the ENOPs. 
4.4 Experimental Results: Inclusion Tests 
We ran ICCEval with 621 errors in the Ilist. The 
experiments were conducted for all categories of 
phonological and visual similarity. When using 
SS, SD, MS, MD, and RS as the selection crite-
rion, we did not limit the number of candidate 
characters. When using SC1, SC2, and SC3 as 
the criterion, we limited the number candidates 
to be no more than 30. We consider only words 
that the native speakers have consensus over the 
causes of errors. Hence, we dropped those 3.7% 
of words in Table 3, and had just 598 errors. The 
ENOPs were obtained during March and April 
2010. 
Table 4 shows the chances that the lists, gen-
SS SD MS MD Phone
Ilist 82.6 29.3 1.7 1.6 97.3 
SC1 SC2 SC3 RS Visual
Ilist 78.3 71.0 87.7 1.3 90.0 
Table 4. Chances of the recommended list con-
tains the incorrect character
745
erated with different crit at step 1, contained the 
incorrect character in the reported errors. In the 
Ilist, there were 516 and 3006  errors that were 
related to phonological and visual similarity, re-
spectively. Using the characters generated with 
the SS criterion, we captured 426 out of 516 
phone-related errors, so we showed 426/516 = 
82.6% in the table. 
Results in Table 4 show that we captured 
phone-related errors more effectively than visual-
ly-similar errors. With a simple method, we can 
compute the union of the characters that were 
generated with the SS, SD, MS, and MD criteria. 
This integrated list suggested how well we cap-
tured the errors that were related to phones, and 
we show its effectiveness under ?Phone?. Simi-
larly, we integrated the lists generated by SC1, 
SC2, SC3, and RS to explore the effectiveness of 
finding errors that are related to visual similarity, 
and the result is shown under ?Visual?. 
4.5 Experimental Results: Ranking Tests 
To put the generated characters into work, we 
wish to put the actual incorrect character high in 
the ranked list. This will help the efficiency in 
supporting computer assisted test-item writing. 
Having short lists that contain relatively more 
confusing characters may facilitate the data prep-
aration for psycholinguistic studies. 
At step 3, we ranked the candidate characters 
by forming incorrect words with other characters 
in the correct words as the context and submitted 
the words to Google for ENOPs. The results of 
ranking, shown in Table 5, indicate that we may 
just offer the leading five candidates to cover the 
actual incorrect characters in almost all cases.  
The ?Total? column shows the total number of 
errors that were captured by the selection crite-
rion. The column ?Ri? shows the percentage of 
all errors, due to phonological or visual similarity, 
that were re-created and ranked ith at step 3 in 
ICCEVAL. The row headings show the selection 
criteria that were used in the experiments. For 
instance, using SS as the criterion, 70.3% of ac-
tual phone-related errors were rank first, 7.4% of 
the phone-related errors were ranked second, etc. 
If we recommended only 5 leading incorrect cha-
6The sum of 516 and 300 is larger than 598 because 
some of the characters are similar both phonologically 
and visually.
racters only with SS, we would have captured the 
actual incorrect characters that were phone re-
lated 81.6% (the sum of R1 to R5) of the time. 
For errors that were related to visual similarity, 
recommending the top five candidates with SC3 
would capture the actual incorrect characters 
87.1% of the time. Since we do not show the 
complete distributions, the sums over the rows 
are not 100%. In the current experiments, the 
worst rank was 21. 
We also used PMI to rank the incorrect words. 
Due to page limits, we cannot show complete 
details about the results. The observed distribu-
tions in ranks were not very different from those 
shown in Table 5. 
5 Discussion 
Compared with Liu et al?s analysis (2009b-c) 
for the traditional Chinese, the proportions of 
errors related to phonological factors are almost 
the same, both at about 80%. The proportion of 
errors related to visual factors varied, but the av-
erages in both studies were about 48%. A larger 
scale of study is needed for how traditional and 
simplified characters affect the distributions of 
errors. Results shown in Table 4 suggest that it is 
relatively easy to capture errors related to visual 
factors in simplified Chinese. Although we can-
not elaborate, we note that Cangjie codes are not 
good for comparing characters that have few 
strokes, e.g., c1 to c4 in Table 1. In these cases, 
the coding method for Wubihua input method 
(Wubihua, 2010) should be applied. 
Acknowledgement 
This research was supported in part by the research 
contract NSC-97-2221-E-004-007-MY2 from the Na-
tional Science Council of Taiwan. We thank the ano-
nymous reviewers for constructive comments. Al-
though we are not able to respond to all the comments 
Total R1 R2 R3 R4 R5
SS 426 70.3 7.4 2.9 0.4 0.6
SD 151 25.6 2.7 0.6 0.0 0.4
MS 9 1.4 0.4 0.0 0.0 0.0
MD 8 1.6 0.0 0.0 0.0 0.0
SC1 235 61.3 10.3 4.3 2.0 0.3
SC2 213 53.7 11.0 3.7 2.3 0.3
SC3 263 66.7 12.7 5.7 1.7 0.3
RS 4 1.3 0.0 0.0 0.0 0.0
Table 5. Ranking the candidates 
746
in this paper, we have done so in an extended version 
of this paper. 
References 
Cangjie. 2010. Last visited on 22 April 2010: 
en.wikipedia.org/wiki/Cangjie_input_method. 
CDL. 2010. Chinese document laboratory, Academia 
Sinica. Last visited on 22 April, 2010; 
cdp.sinica.edu.tw/cdphanzi/. (in Chinese) 
Chen, Matthew. Y. 2000. Tone Sandhi: Patterns 
across Chinese Dialects, (Cambridge Studies in 
Linguistics 92). Cambridge University Press. 
Chu, Bong-Foo. 2010. Handbook of the Fifth Genera-
tion of the Cangjie Input Method. last visited on 22 
April 2010: www.cbflabs.com/book/5cjbook/. (in Chi-
nese) 
Cormen, Thomas H., Charles E. Leiserson, Ronald L. 
Rivest, and Clifford Stein. 2009. Introduction to 
Algorithms, third edition. MIT Press. 
Croft, W. Bruce, Donald Metzler, and Trevor Stroh-
man, 2010. Search Engines: Information Retrieval 
in Practice, Pearson. 
Dict. 2010. Last visited on 22 April 2010,
www.cns11643.gov.tw/AIDB/welcome.do 
Fan, Kuo-Chin, Chang-Keng Lin, and Kuo-Sen Chou. 
1995. Confusion set recognition of on-line Chinese 
characters by artificial intelligence technique. Pat-
tern Recognition, 28(3):303?313. 
HanDict. 2010. Last visit on 22 April 2010, 
www.zdic.net/appendix/f19.htm. 
Jurafsky, Daniel and James H. Martin. 2009. Speech 
and Language Processing, second edition, Pearson. 
Kuo, Wen-Jui, Tzu-Chen Yeh, Jun-Ren Lee, Li-Fen 
Chen, Po-Lei Lee, Shyan-Shiou Chen, Low-Tone 
Ho, Daisy L. Hung, Ovid J.-L. Tzeng, and Jen-
Chuen Hsieh. 2004. Orthographic and phonological 
processing of Chinese characters: An fMRI study. 
NeuroImage, 21(4):1721?1731. 
Lee, Chia-Ying, Jie-Li Tsai, Hsu-Wen Huang, Daisy 
L. Hung, Ovid J.-L. Tzeng. 2006. The temporal 
signatures of semantic and phonological activations 
for Chinese sublexical processing: An even-related 
potential study. Brain Research, 1121(1):150-159. 
Lee, Hsiang. 2010a. Cangjie Input Methods in 30 
Days 2. Foruto. Last visited on 22 April 2010:  in-
put.foruto.com/cccls/cjzd.html. 
Lee, Mu. 2010b. A quantitative study of the formation 
of Chinese characters. Last visited on 22 April 
2010: chinese.exponode.com/0_1.htm. (in Chinese) 
Liu, Chao-Lin, and Jen-Hsiang Lin. 2008. Using 
structural information for identifying similar Chi-
nese characters. Proc. of the 46th Annual Meeting 
of the Association for Computational Linguistics,
short papers, 93?96.
Liu, Chao-Lin, Kan-Wen Tien, Yi-Hsuan Chuang, 
Chih-Bin Huang, and Juei-Yu Weng. 2009a. Two 
applications of lexical information to computer-
assisted item authoring for elementary Chinese. 
Proc. of the 22nd Int?l Conf. on Industrial En-
gineering & Other Applications of Applied Intel-
ligent Systems, 470?480. 
Liu, Chao-Lin, Kan-Wen Tien, Min-Hua Lai, Yi-
Hsuan Chuang, and Shih-Hung Wu. 2009b. Cap-
turing errors in written Chinese words. Proc. of the 
47th Annual Meeting of the Association for Compu-
tational Linguistics, short papers, 25?28. 
Liu, Chao-Lin, Kan-Wen Tien, Min-Hua Lai, Yi-
Hsuan Chuang, and Shih-Hung Wu. 2009c. Phono-
logical and logographic influences on errors in 
written Chinese words. Proc. of the 7th Workshop 
on Asian Language Resources, the 47th Annual 
Meeting of the ACL, 84?91. 
Liu, Cheng-Lin, Stefan Jaeger, and Masaki Nakagawa. 
2004. Online recognition of Chinese characters: 
The state-of-the-art. IEEE Transaction on Pattern 
Analysis and Machine Intelligence, 26(2):198?213. 
Wubihua. 2010. Last visited on 22 April 2010: 
en.wikipedia.org/wiki/Wubihua_method. 
Yeh, Su-Ling, and Jing-Ling Li. 2002. Role of struc-
ture and component in judgments of visual simi-
larity of Chinese Characters. Journal of Expe-
rimental Psychology: Human Perception and Per-
formance, 28(4):933?947. 
747
