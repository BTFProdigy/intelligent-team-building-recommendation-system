Workshop on Humans and Computer-assisted Translation, pages 57?65,
Gothenburg, Sweden, 26 April 2014.
c?2014 Association for Computational Linguistics
Black-box integration of heterogeneous bilingual resources into an
interactive translation system
Juan Antonio P
?
erez-Ortiz
japerez@dlsi.ua.es
Daniel Torregrosa
dtr5@alu.ua.es
Departament de Llenguatges i Sistemes Inform`atics
Universitat d?Alacant, Spain
Mikel L. Forcada
mlf@dlsi.ua.es
Abstract
The objective of interactive translation
prediction (ITP) is to assist human trans-
lators in the translation of texts by making
context-based computer-generated sug-
gestions as they type. Most of the ITP
systems in literature are strongly coupled
with a statistical machine translation sys-
tem that is conveniently adapted to provide
the suggestions. In this paper, however,
we propose a resource-agnostic approach
in which the suggestions are obtained from
any bilingual resource (a machine transla-
tion system, a translation memory, a bilin-
gual dictionary, etc.) that provides target-
language equivalents for source-language
segments. These bilingual resources are
considered to be black boxes and do not
need to be adapted to the peculiarities of
the ITP system. Our evaluation shows
that savings of up to 85% can be theoreti-
cally achieved in the number of keystrokes
when using our novel approach. Prelim-
inary user trials indicate that these bene-
fits can be partly transferred to real-world
computer-assisted translation interfaces.
1 Introduction
Translation technologies are frequently used to
assist human translators. Common approaches
consider machine translation (MT) (Hutchins and
Somers, 1992) or translation memories (Somers,
2003) to be systems that produce a first (and usu-
ally incorrect) prototype of the translation which
is then edited by the human translator in order
to produce a target-language text that is adequate
for publishing. In both situations, the suggestion
may be considered as a source of inspiration by
the human translators, who will assemble the final
translation by on some occasions accepting and re-
arranging parts of the proposal, or on others in-
troducing their own words when an appropriate
equivalent is not included or is not found in the
suggestion. The whole process may be viewed as a
negotiation between the wordings that form in the
translator?s mind and wordings that already appear
in the suggestion. In both approaches the sugges-
tion is generated once, usually before starting to
manually translate every new sentence.
The approach introduced in this paper, however,
follows a different path, which is strongly con-
nected to the field of interactive translation pre-
diction
1
(ITP), a research field which explores a
kind of computer-assisted translation framework
whose aim is to interactively provide users with
suggestions at every step during the translation
process.
2
Most works in the field of ITP have fo-
cused on statistical MT systems as the only source
of translations considered to obtain the sugges-
tions, but our study aims to determine how bilin-
gual resources of any kind can be accommodated
into an interoperable ITP. To obtain the sugges-
tions, the source-language sentence to be trans-
lated is split up into many different (and possi-
bly overlapping) word segments of up to a given
length, and a translation for each segment is ob-
tained by using a bilingual resource which is able
to deliver one or more target-language equivalents
for a particular source-language segment. These
equivalents will be the source of the proposals
which will be offered to the human translator dur-
ing the translation process. In principle, the nature
of these bilingual resources is not restricted: in
1
The name interactive translation prediction has recently
been proposed (Alabau et al., 2013) for this research field,
which has historically been referred to as target-text medi-
ated interactive MT (Foster et al., 1997) or simply interactive
MT (Barrachina et al., 2009). Despite the traditional term, we
consider the recent one to be more suitable for our approach
since it is not exclusively based on MT.
2
The interaction can be compared to that of word comple-
tion mechanisms in input text boxes and word processors.
57
this paper we shall explore the use of an MT sys-
tem, but they may also consist of translation mem-
ories, dictionaries, catalogues of bilingual phrases,
or a combination of heterogeneous resources. As
stated above, MT or translation memories cannot
usually deliver appropriate translations at the sen-
tence level, but their proposals usually contain ac-
ceptable segments that do not cover the whole sen-
tence but which can be accepted by the user to as-
semble a good translation, thus saving keystrokes,
mouse actions
3
and, possibly, time.
The remainder of the paper is organised as fol-
lows. After reviewing the state-of-the-art in ITP
in Section 2, we outline the main differences be-
tween our proposal and those found in literature in
Section 3. Our method for generating translation
suggestions from bilingual resources is formally
presented in Section 4. We then introduce in Sec-
tion 5 our experimental set-up and show the results
of two evaluations: one that is fully automatic and
another consisting of a user trial involving human
evaluators. Finally, we discuss the results and pro-
pose future lines of research in Section 6.
2 Related work
The systems which have most significantly con-
tributed to the field of ITP are those built in the
pioneering TransType project (Foster et al., 1997;
Langlais et al., 2000), and its continuation, the
TransType2 project (Macklovitch, 2006). These
systems observe the current partial translation al-
ready typed by the user and, by exploiting an
embedded statistical MT engine, propose one or
more completions that are compatible with the
sentence prefix entered by the user. Various mod-
els were considered for the underlying MT system,
including alignment templates, phrase-based mod-
els, and stochastic finite-state transducers (Bar-
rachina et al., 2009). The proposals offered may
range from one or several words, to a comple-
tion of the remainder of the target sentence. An
automatic best-scenario evaluation with training
and evaluation corpora belonging to the same do-
main (Barrachina et al., 2009) showed that it might
theoretically be possible to use only 20?25% of
the keystrokes in comparison with the unassisted
translation for English?Spanish translation (both
directions) and around 45% for English?French
and English?German. The results of the user tri-
3
In the case of touch devices, other means of interaction
(such as gestures) may exist.
als (Macklovitch, 2006) showed gains in produc-
tivity (measured in number of words translated per
hour) of around 15?20%, but despite this, the hu-
man translators were not satisfied with the system,
principally because they had to correct the same
errors in the proposals over and over again (the
models in the underlying statistical MT system re-
mained unchanged during the translation process).
A number of projects continued the research
where TransType2 had left off. Caitra (Koehn,
2009) is an ITP tool which uses both the phrase
table and the decoder of a statistical MT sys-
tem to generate suggestions; although individ-
ual results vary, translators are generally fastest
with post-editing and obtain the highest trans-
lation performance when combining post-editing
and ITP in the same interface (Koehn and Haddow,
2009). Researchers at the Universitat Polit`ecnica
de Val`encia have also made significant improve-
ments to the TransType2 system such as online
learning techniques with which to adaptively gen-
erate better proposals from user feedback (Ortiz-
Mart??nez et al., 2011), phrase-table smoothing to
cope with segments in the partially typed transla-
tion which cannot be generated with the phrases
collected during training (Ortiz-Mart??nez, 2011),
or multimodal interfaces (Alabau et al., 2010).
The objective of the CASMACAT project (Alabau
et al., 2013), which is under active development,
is to develop new types of assistance along all
these lines. Finally, commercial translation mem-
ory systems have also recently started to introduce
ITP as one of their basic features (see, for exam-
ple, SDL Trados AutoSuggest
4
).
3 Innovative nature of our proposal
Common to most of the approaches discussed
above is the fact that the underlying translation en-
gine needs to be a glass-box resource, that is, a
resource whose behaviour is modified to meet the
ITP system needs. The approaches rely on a statis-
tical MT (Koehn, 2010) system which is adapted
to provide the list of n-best completions for the
remainder of the sentence, given the current sen-
tence prefix already introduced by the user; in or-
der to meet the resulting time constraints, the de-
coder of the statistical MT system cannot be exe-
cuted after each keystroke and techniques to com-
pute the search graph once and then reuse it have
been proposed (Bender et al., 2005). However, it
4
http://www.translationzone.com/
58
Figure 1: Screenshot of the web interface of our
ITP tool showing a translation in progress with
some suggestions being offered. The top text box
contains the source sentence, whereas users type
the translation into the bottom box.
may occur that an ITP system has access to bilin-
gual resources which cannot produce a comple-
tion for the rest of the target-language sentence
from a given sentence prefix, but are able to sup-
ply the translation of a particular source-language
segment. This may be owing to either intrinsic
reasons inherent to the type of resource being used
(for example, a bilingual dictionary can only trans-
late single words or short multi-word units) or ex-
trinsic reasons (for example, an MT system avail-
able through a third-party web service cannot be
instructed to continue a partial translation).
We propose a black-box treatment of the bilin-
gual resources in contrast to the glass-box ap-
proaches found in literature. Unlike them, ac-
cess to the inner details of the translation system
is not necessary; this maintains coupling between
the ITP tool and the underlying system to a mini-
mum and provides the opportunity to incorporate
additional sources of bilingual information beyond
purposely-designed statistical MT systems. More-
over, suggestions are computed once at the start
and not after each keystroke, which results in a
more effective interaction with the user in execu-
tion environments with limited resources.
In this paper, we shall focus on a black-box MT
system (Forcada et al., 2011), but we have also be-
gun to explore the integration of other bilingual re-
sources (such as translation memories, dictionar-
ies, catalogues of bilingual phrases, or even a com-
bination of heterogeneous resources). Our system
has a web interface similar to that in the projects
discussed in Section 2: users freely type the trans-
lation of the source sentence, and are offered sug-
gestions on the fly in a drop-down list with items
based on the current prefix, although this prefix
will correspond to the first characters of the word
currently being typed and not to the part of the
target sentence already entered; users may accept
these suggestions (using cursor keys, the mouse
or specific hot keys) or ignore them and continue
typing. A screenshot of the interface is shown in
Figure 1. Despite the cognitive load inherent to
any predictive interface, the interface is easy and
intuitive to use, even for inexperienced users.
4 Method
Our method starts by splitting the source-language
sentence S up into all the (possibly overlapping)
segments of length l ? [1, L], where L is the max-
imum source segment length measured in words.
The resulting segments are then translated by
means of a bilingual resource (or combinations
thereof). The set of potential proposals P
S
for
sentence S is made up of pairs comprising the
translation of each segment and the position in the
input sentence of the first word of the correspond-
ing source-language segment. See Table 1 for an
example of the set P
S
obtained in an English to
Spanish translation task when using L = 3. We
shall represent the i-th suggestion as p
i
, its target-
language segment as t(p
i
) and its corresponding
source-language word position as ?(p
i
). Suitable
values for L will depend on the bilingual resource:
on the one hand, we expect higher values of L
to be useful for high-quality MT systems, such
as those translating between closely related lan-
guages, since adequate translations may stretch to
a relatively large number of words; on the other
hand, L should be kept small for resources such
as dictionaries or low-quality MT systems whose
translations quickly deteriorate as the length of the
input segment increases.
Let P
S
C
(w?, j) be the subset of P
S
including the
compatible suggestions which can be offered to
the user after typing w? as the prefix of the j-th
word in the translated sentence T . The elements
of P
S
C
(w?, j) are determined by considering only
those suggestions in P
S
that have the already-
typed word prefix as their own prefix:
P
S
C
(w?, j) = {p
i
? P
S
: w? ? Prefix(t(p
i
))}
For example, in the case of the translation of the
English sentence in Table 1, if the user types an
M, the set of compatible suggestions P
S
C
(?M?, 1)
59
Start position Source segment Suggestion
1 My (Mi,1)
1 My tailor (Mi sastre,1)
1 My tailor is (Mi sastre es,1)
2 tailor (sastre,2)
2 tailor is (sastre es,2)
2 tailor is healthy (sastre est?a sano,2)
3 is (es,3)
3 is healthy (est?a sano,3)
4 healthy (sano,4)
Table 1: Source-language segments and potential
suggestions P
S
when translating the sentence S =
?My tailor is healthy? into Spanish with L = 3.
will contain the suggestions with target-language
segments Mi, Mi sastre and Mi sastre es, since
they are the only proposals in P
S
starting with
an M. The size of P
S
C
is dependent on the value
of L, but compatible proposals may also origi-
nate from translations of source segments start-
ing at different positions in the input sentence (for
example, the set P
S
C
after the user types an s in
the same translation will contain proposals starting
with sastre and sano). More elaborated strategies
are consequently necessary to further reduce the
number of proposals, since we do not expect users
to tolerate lists with more than a few suggestions.
In 4.1 we propose the use of a ranking strategy to
sort the elements of P
S
C
in such a way that it is pos-
sible to predict which of them are most suitable to
be offered to the user. However, we first elaborate
on the issue of compatible suggestions originating
from different source positions.
The number of source positions that generate
compatible suggestions also depends on the spe-
cific word prefix; for example, when users type
the letter d when translating a long sentence into
Spanish, they will probably obtain a significant
number of suggestions starting with de
5
originat-
ing from segments located in different source po-
sitions. We measured the number of different po-
sitions that provide compatible suggestions when
the first characters of the current word are typed
during an automatic evaluation of our system (see
Section 5); for instance, when translating from En-
glish to Spanish, the average is 1.46 after typing b,
whereas it is 4.73 after typing d. Figure 2 shows
the average number of different positions for all
the letters as users type longer prefixes. Obviously,
only suggestions originating from the part of the
source sentence currently being translated may be
5
The preposition de is notably frequent in Spanish texts.
 1
 1.5
 2
 2.5
 3
 3.5
 4
 1  2  3  4  5  6  7  8  9  10
Ave
rag
e n
um
ber
 of 
diff
ere
nt 
so
urc
e p
osi
tion
s
Word prefix length
ca?es
en?es
Figure 2: Average number, for all the letters in
the alphabet, of different source positions in the
source sentence providing compatible suggestions
versus length in characters of the typed prefix of
the current target word. A system with L = 4,
M = ? and no deletion of selected suggestions
(see Section 4) was used to obtain the points in
this graph. Data is shown for the English?Spanish
(en-es) and Catalan?Spanish (es-ca) corpora used
in the automatic experiments (see Section 5).
useful, but this position is difficult to determine
unambiguously. The degree of success that can be
achieved in this task will be explored in greater
depth in future work (see Section 6); a simple ap-
proximation is presented in the following section.
4.1 Ranking suggestions
In the absence of a strategy with which to rank
the suggestions in P
S
C
(w?, j) which we are cur-
rently working on, in this paper we explore a na??ve
distance-based approach which is based solely on
the position j: suggestions p
i
whose source posi-
tion ?(p
i
) is closer
6
to j are prioritised. For ex-
ample, in the case of the translation in Table 1, if
the user types Mi s, suggestions starting with sas-
tre will be ranked before those starting with sano.
This linearity assumption can be seen as a rough
attempt to determine the part of the input sentence
that is currently being translated; more sophisti-
cated approaches will be considered in future work
(see Section 6). However, notice that according to
Figure 2, the average number of different source
positions of the compatible segments quickly be-
comes closer to 1 when the length of the word
prefix is greater than 2; it is therefore expected
that the role played by the distance-based ranker
will soon decrease as the user continues typing the
6
Ties are broken at random.
60
 0
 5
 10
 15
 20
 25
0 1 2 3-4 5-7 8-10 11-20    21-300
Pe
rce
nta
ge 
of s
ugg
est
ion
s
Source-target distance
Figure 3: Distribution of the absolute differences
(measured in words) between source position of
accepted suggestions versus position in the target
sentence in which they were selected for the case
of Spanish?English translation. L = 4, M = ?
and no deletion of selected suggestions (see Sec-
tion 4) was used to obtain this graph.
current word (although the position of a valid sug-
gestion is far from j, it will probably be the only
compatible proposal, and will consequently be se-
lected to be offered).
Translation between closely related languages
is often monotonic and most reorderings are local;
our distance-based ranking is therefore expected
to produce good results for this kind of language
pairs. Nevertheless, we cannot in principle ex-
pect this ranker to work reasonably well on un-
related languages with different overall grammat-
ical structures (e.g., when translating a language
with a verb?subject?object order into another one
with a subject?verb?object typology). The graph
in Figure 3 represents the distribution of the dis-
tances between the source positions of all the
accepted suggestions in our automatic Spanish?
English evaluation (see Section 5) versus the po-
sition in the target sentence of the word for which
they were selected. The Pearson correlation coef-
ficient between both positions is very high (0.93),
which supports the idea that our na??ve distance-
based ranking may work reasonably well for the
languages used in our experiments.
7
Let M be the maximum number of sugges-
tions that will eventually be offered to the human
translator; the ordered list of suggestions offered
to the user P
S
O
(w?, j) is made up of a subset of
the elements in P
S
C
(w?, j) and restricted so that
7
Although not shown here, similar results are obtained for
the Catalan?Spanish pair.
|P
S
O
(w?, j)| ? M . Note that for the interface to
be friendly, the value of M should be kept small
and, as a result of this, it could easily occur that all
the suggestions offered are obtained starting at the
same source position (that closest to the current
target position) although better suggestions from
different positions exist. In order to mitigate the
impact of this, in this paper we propose to restrict
the number of proposals originating from a par-
ticular source position to two (the longest and the
shortest, in this order, which are compatible with
the typed word prefix) as long as different compat-
ible suggestions originating from a different posi-
tion exist. The longest is offered in the hope that
it will be correct and will contribute towards sav-
ing a lot of keystrokes; however, since the qual-
ity of machine translations usually degrades with
the length of the input segment (see Figure 4), the
shortest is also offered. This must, however, be
researched in more depth.
4.2 Deleting dispensable suggestions
Suggestions that have been accepted by the user
should not be proposed again. In this work, a
selected suggestion p
i
will be removed from P
S
if no other suggestion p
j
with the same target-
language text t(p
i
) and different source position
?(p
j
) exists in P
S
. In this case, those suggestions
obtained from the source position ?(p
i
) are also
removed from P
S
. Deleting dispensable sugges-
tions allows other useful suggestions to be selected
by the ranker in order to be offered.
5 Experimental setup and results
A fully automatic evaluation and a user trial in-
volving human evaluators were conducted. As
previously stated in Section 3, the only bilingual
resource considered in this paper is an MT system;
in particular, the Spanish to Catalan and English to
Spanish rule-based MT systems in the free/open-
source platform Apertium
8
(Forcada et al., 2011).
5.1 Evaluation metrics
The performance of our system has been measured
by using two metrics: keystroke ratio (KSR) and
acceptable suggestion ratio (ASR). On the one
hand, the KSR is the ratio between the number
of keystrokes and the length of the translated sen-
8
Revision 44632 of the Apertium repository at http://svn.
code.sf.net/p/apertium/svn/trunk/ was used for the engine and
linguistic data in these experiments.
61
tence (Langlais et al., 2000). A lower KSR repre-
sents a greater saving in keystrokes. In our exper-
iments, selecting a suggestion has the same cost
as pressing one key. On the other hand, the ASR
measures the percentage of times that at least one
of the suggestions in a non-empty P
S
O
is selected.
If users frequently receive suggestion lists contain-
ing no acceptable proposals, they will stop con-
sulting the list and translate without assistance; it
is therefore important to measure the number of
times the user is needlessly bothered.
5.2 Automatic evaluation
In order to determine optimal values for the dif-
ferent parameters of our system and to obtain an
idea of the best results attainable, a number of au-
tomatic tests were conducted. The approach fol-
lowed is identical to that described by Langlais et
al. (2000), in which a parallel corpus with pairs
of sentences was used, each pair consisting of a
sentence S in the source language and a reference
translation T in the target language. In the context
of our automatic evaluation, S is used as the input
sentence to be translated and T is considered as the
target output sentence a user is supposed to have in
mind and stick to while typing. The longest sug-
gestion in P
S
O
which concatenated to the already
typed text results in a new prefix of T is always
used. If P
S
O
contains no suggestions at a particular
point, then the system continues typing according
to T . As the algorithm proceeds in a left-to-right
longest-match greedy fashion, there is no guaran-
tee that the best possible results will be obtained,
but they will be a good approximation.
9
For exam-
ple, for T = Mi coche est?a averiado, partial output
translation Mi c, and P
S
O
(?c?, 2) = {coche, coche
es, coche est?a roto}, our automatic evaluation sys-
tem will proceed as follows: it will first discard
coche est?a roto, because Mi coche est?a roto is not
a prefix of T ; it will then discard coche es, be-
cause although Mi coche es is a prefix of T , it is
not a prefix when a blank is added after it; finally,
it will select coche, because Mi coche followed by
a blank is a prefix of T and no longer suggestion
that also satisfies these conditions exists.
Two different corpora were used for the au-
tomatic evaluation: for English?Spanish (en-es),
a combination of sentences from all the editions
of DGT-TM (Steinberger et al., 2012) released
9
Note that real users could also decide to select sugges-
tions with small errors and fix them, but neither this nor other
behaviours are considered in our automatic evaluation.
 0
 0.2
 0.4
 0.6
 0.8
 1
 1  2  3  4  5  6  7
KS
R/A
SR
l
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 4: Automatically evaluated KSR versus
exact length of the segments l. Longer sugges-
tions are much more useful for Spanish?Catalan
(closely related languages) than for English?
Spanish: the KSR for l = 7 is still a little better
than that for l = 1 for Catalan?Spanish, but no-
ticeably worse for English?Spanish. ASR quickly
degrades as l increases.
in 2004?2011 (15 250 sentences; 163 196 words
in English; 190 448 in Spanish) was used; for
Catalan?Spanish (ca-es), a collection of news
items from El Peri?odico de Catalunya
10
(15 000
sentences; 307 095 words in Catalan; 294 488 in
Spanish) was used.
5.3 Results of the automatic evaluation
The objective of the automatic evaluation was to
estimate the influence of the language pair and the
parameters L and M .
11
Maximum length of segments. We first tested
to what extent each different segment length l con-
tributes separately to the KSR. Note that l cor-
responds in this case to the exact length of the
source segments and not to the longest one (as rep-
resented by L). M = ? is used in all the ex-
periments in this section. Figure 4 shows that the
KSR becomes worse for greater values of l, which
can be explained by the fact that longer machine
translations often contain more errors than shorter
ones. In the case of Catalan?Spanish, the worst
KSR value is for l = 1 since adequate suggestions
will usually consist of few characters and selecting
them will barely contribute to keystroke reduction.
10
http://www.elperiodico.cat/ca/
11
95% confidence intervals of the average values presented
in this section were calculated using the Student?s t-test. The
size of the evaluation corpora signifies that the resulting con-
fidence intervals are so small that they would have been im-
perceptible on the graphs and have therefore been omitted.
62
 0
 0.2
 0.4
 0.6
 0.8
 1
 1  2  3  4  5  6  7
KS
R/A
SR
L
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 5: Automatically evaluated KSR/ASR ver-
sus maximum length of the segments L. As L in-
creases, the KSR improves, but the ASR is nega-
tively affected.
Combining different segment lengths up to length
L provides better values of KSR than using only
a fixed value l = L (compare Figures 4 and 5).
Figure 5 shows an estimation of the best results
our method could attain if all the compatible sug-
gestions in P
S
C
were included in P
S
O
: values be-
tween 0.3 and 0.4 for the Catalan?Spanish KSR
and between 0.7 and 0.8 for the English?Spanish
KSR. The notable difference may be explained
by the fact that Apertium performance is much
better (Forcada et al., 2011) for Catalan?Spanish
(word error rates of around 15%) than for English?
Spanish (word error rates of around 70%).
Maximum number of suggestions offered. We
evaluated the influence of the maximum size M
of the list of suggestions offered to the user and,
hence, the impact of the distance-based ranker.
L = 4 was used, as this value provides good re-
sults for both language pairs (see Figure 5). As
expected (see Figure 6), the distance-based rank-
ing strategy works remarkably well (values for
KSR and ASR from M = 4 are similar to those
obtained with M = ?) for closely related lan-
guages (Catalan?Spanish), in which translations
are usually monotonic and reorderings seldom oc-
cur. However, the empirical results also show (see
again Figure 6) that it also works well for language
pairs (English?Spanish) in which long-distance re-
orderings exist, at least when compared to the re-
sults without ranking (M =?).
5.4 Human evaluation
A preliminary evaluation of a real use of our sys-
tem involving 8 human non-professional trans-
 0
 0.2
 0.4
 0.6
 0.8
 1
? 1  2  3  4  5
KS
R/A
SR
M
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 6: Automatically evaluated KSR/ASR ver-
sus maximum number M of suggestions offered.
Although the results with M = 1 (only one sug-
gestion offered) are considerably worse, for higher
values of M they quickly approach the results ob-
tained when no ranker was used and all the com-
patible suggestions were offered (M =?).
lators (volunteer computer science students) was
also conducted. All the users were Spanish na-
tive speakers who understood Catalan, but with no
experience with ITP systems. As the results of the
automatic evaluation show that the performance of
the Apertium English?Spanish MT system nega-
tively affects our ITP system (see Section 5), we
decided to focus on the Catalan?Spanish scenario.
A set of 10 sentences in Catalan were randomly
extracted from the same corpus used in the auto-
matic evaluation. The test was designed to take
around 20 minutes. The evaluators were allowed
to practise with a couple of sentences before start-
ing the trial. After completing the test, they were
surveyed about the usefulness of the system. Our
ITP system was used with L = M = 4.
5.5 Results of the human evaluation
The users were divided into two groups: users
1?4 translated sentences 1?5 assisted by our ITP
tool and sentences 6?10 with no assistance, while
users 5?8 translated sentences 1?5 with no assis-
tance and sentences 6?10 assisted by the tool. The
KSR and translation times for each user are shown
in Table 2. This table also includes KSR
?
, which
is the value of KSR obtained by running our au-
tomatic evaluator (see Section 5.2) using the sen-
tences entered by each user as the reference trans-
lations T ; this can be considered as an approxi-
mation to the best result achievable with the ITP
tool. All users attained KSRs that were notice-
63
User Sentences 1?5 Sentences 6?10
KSR Time KSR
?
KSR Time KSR
?
#1 0.49 136 0.22 1.11 137 0.23
#2 0.64 144 0.15 1.21 86 0.22
#3 0.63 209 0.22 1.09 112 0.21
#4 0.37 189 0.22 1.22 199 0.18
#5 1.10 145 0.28 0.37 102 0.15
#6 1.24 150 0.27 0.51 154 0.17
#7 1.15 178 0.30 0.64 147 0.17
#8 1.18 118 0.39 0.58 93 0.15
Table 2: KSR, translation times (seconds) and
KSR
?
(see main text) for each of the users in the
evaluation. Values in bold correspond to the trans-
lations with assistance from our ITP system.
ably lower than 1 for the assisted translations and
slightly higher than 1 when translating without the
ITP system; the former, however, are often worse
than the KSR values obtained in the automatic
evaluation which are around 0.4 for L = M = 4
(see Figure 6). Moreover, the values for KSR
?
show that even better values for KSR could the-
oretically be attained for these sentences; note,
however, that the reference translations in this case
were precisely generated by accepting suggestions
generated by Apertium.
The users were surveyed to evaluate the follow-
ing statements in the range from 1 (complete dis-
agreement) to 5 (complete agreement): the inter-
face is easy to use; I would use a tool like this in
future translations; I have found the suggestions
useful; and the tool has allowed me to translate
faster. The median of the responses to the first two
questions was 5, whereas the median for the two
last questions was 4.5. It was evident that the eval-
uators perceived that the ITP system had helped
them to translate faster, although the time values
in Table 2 seem to suggest the opposite. Finally,
note that this was a small-scale human evaluation
and that sounder results will have to be collected
under different conditions by increasing the num-
ber of users, sentences and languages in the test.
6 Discussion and future work
The automatic evaluation of our ITP system has
provided an estimation of its potential for human
translators. Note, however, that this evaluation
strategy is based on a greedy algorithm which may
not adequately reproduce the way in which a hu-
man translator might usually perform the task. Ac-
cording to the best results of our automatic exper-
iments, when a maximum of M = 4 suggestions
are offered and the system selects the longest one
that matches the reference translation, 25?65%
keystrokes could be saved depending on the lan-
guage pair. Moreover, 30?55% of the times that
a list of suggestions is offered, at least one of the
suggestions matches the target sentence.
Our preliminary human tests can be used to dis-
cern how well our system could perform, but a
more extensive evaluation is needed to explore the
influence of parameters, different kinds of users,
heterogeneous bilingual resources, new language
pairs, particular domains, different interfaces, etc.
in greater depth. A comparison with similar tools
in literature will also be carried out.
We plan to improve the ranking strategy shown
in Section 4.1 by automatically detecting the part
of the input sentence being translated at each mo-
ment so that segments that originate in those posi-
tions are prioritised. We intend to achieve this by
combining word alignment and distortion models.
The former will be used to determine the align-
ments between the last words introduced by the
user and the words in the input sentence;
12
the lat-
ter will predict which source words will be trans-
lated next, partly by using information from the
alignment model.
The ITP system presented in this paper is im-
plemented in Java, except for the web interface,
which is written in HTML and JavaScript. The
Java code, however, has been designed in such a
way that it can be compiled into JavaScript with
the help of the Google Web Toolkit framework;
13
and the same code can therefore be executed either
on the browser in JavaScript when human transla-
tors interact with the tool, or locally in Java when
performing the automatic evaluation. The entire
code of the application is available
14
under a free
software license (GNU Affero General Public Li-
cense, version 3); this ensures the reproducibility
of the experiments and allows our ITP system to
be integrated into professional translation tools.
Acknowledgments. This work has been partly
funded by the Spanish Ministerio de Econom??a y
Competitividad through project TIN 2012-32615.
12
On-the-fly, light alignment models have been proposed
which do not require parallel corpora and are based on the
translation of all the possible segments of the sentence with
the help of black-box bilingual resources (Espl`a-Gomis et al.,
2012); these models would fit nicely into our ITP method.
13
http://www.gwtproject.org/
14
https://github.com/jaspock/forecat
64
References
Vicent Alabau, Daniel Ortiz-Mart??nez, Alberto San-
chis, and Francisco Casacuberta. 2010. Multimodal
interactive machine translation. In ICMI-MLMI ?10:
Proceedings of the 2010 International Conference
on Multimodal Interfaces.
Vicent Alabau, Ragnar Bonk, Christian Buck, Michael
Carl, Francisco Casacuberta, Mercedes Garc??a-
Mart??nez, Jes?us Gonz?alez-Rubio, Philipp Koehn,
Luis A. Leiva, Bartolom?e Mesa-Lao, Daniel Or-
tiz, Herve Saint-Amand, Germ?an Sanchis-Trilles,
and Chara Tsoukala. 2013. CASMACAT: An
open source workbench for advanced computer
aided translation. Prague Bull. Math. Linguistics,
100:101?112.
Sergio Barrachina, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,
Antonio Lagarda, Hermann Ney, Jes?us Tom?as, En-
rique Vidal, and Juan-Miguel Vilar. 2009. Sta-
tistical approaches to computer-assisted translation.
Computational Linguistics, 35(1):3?28.
Oliver Bender, David Vilar, Richard Zens, and Her-
mann Ney. 2005. Comparison of generation strate-
gies for interactive machine translation. In Pro-
ceedings of EAMT 2005 (10th Annual Conference of
the European Association for Machine Translation,
pages 30?40.
Miquel Espl`a-Gomis, Felipe S?anchez-Mart??nez, and
Mikel L. Forcada. 2012. Using external sources of
bilingual information for on-the-fly word alignment.
Technical report, Departament de Llenguatges i Sis-
temes Inform`atics, Universitat d?Alacant.
Mikel L Forcada, Mireia Ginest??-Rosell, Jacob Nord-
falk, Jim O?Regan, Sergio Ortiz-Rojas, Juan An-
tonio P?erez-Ortiz, Felipe S?anchez-Mart??nez, Gema
Ram??rez-S?anchez, and Francis M Tyers. 2011.
Apertium: a free/open-source platform for rule-
based machine translation. Machine Translation,
25(2):127?144.
George F. Foster, Pierre Isabelle, and Pierre Plam-
ondon. 1997. Target-text mediated interactive
machine translation. Machine Translation, 12(1-
2):175?194.
W. John Hutchins and Harold L. Somers. 1992. An in-
troduction to machine translation. Academic Press.
Philipp Koehn and Barry Haddow. 2009. Interactive
assistance to human translators using statistical ma-
chine translation methods. MT Summit XII.
Philipp Koehn. 2009. A web-based interactive com-
puter aided translation tool. In Proceedings of the
ACL-IJCNLP 2009 Software Demonstrations, pages
17?20.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Philippe Langlais, S?ebastien Sauv?e, George Foster, El-
liott Macklovitch, and Guy Lapalme. 2000. Eval-
uation of TransType, a computer-aided translation
typing system: a comparison of a theoretical-and a
user-oriented evaluation procedures. In Conference
on Language Resources and Evaluation (LREC),
page 8.
Elliott Macklovitch. 2006. TransType2: The last
word. In Proceedings of the 5th International Con-
ference on Languages Resources and Evaluation
(LREC 06), pages 167?172.
Daniel Ortiz-Mart??nez, Luis A. Leiva, Vicent Alabau,
Ismael Garc??a-Varea, and Francisco Casacuberta.
2011. An interactive machine translation system
with online learning. In Proceedings of the ACL-
HLT 2011 System Demonstrations, pages 68?73.
Daniel Ortiz-Mart??nez. 2011. Advances in Fully-
Automatic and Interactive Phrase-Based Statisti-
cal Machine Translation. Ph.D. thesis, Universitat
Polit`ecnica de Val`encia.
Harold L. Somers. 2003. Computers and Translation:
A Translator?s Guide. Benjamins translation library.
John Benjamins Publishing Company.
Ralf Steinberger, Andreas Eisele, Szymon Klocek,
Spyridon Pilos, and Patrick Schl?uter. 2012. DGT-
TM: a freely available Translation Memory in 22
languages. In Language Resources and Evaluation
Conference, pages 454?459.
65
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 178?185,
Baltimore, Maryland USA, June 26?27, 2014.
c
?2014 Association for Computational Linguistics
The UA-Prompsit hybrid machine translation system for the 2014
Workshop on Statistical Machine Translation
V??ctor M. S
?
anchez-Cartagena,
? ?
Juan Antonio P
?
erez-Ortiz,
?
Felipe S
?
anchez-Mart??nez
?
?
Dep. de Llenguatges i Sistemes Inform`atics,
Universitat d?Alacant, E-03071, Alacant, Spain
?
Prompsit Language Engineering,
Av. Universitat, s/n. Edifici Quorum III, E-03202, Elx, Spain
{vmsanchez,japerez,fsanchez}@dlsi.ua.es
Abstract
This paper describes the system jointly de-
veloped by members of the Departament
de Llenguatges i Sistemes Inform`atics
at Universitat d?Alacant and the Promp-
sit Language Engineering company for
the shared translation task of the 2014
Workshop on Statistical Machine Trans-
lation. We present a phrase-based sta-
tistical machine translation system whose
phrase table is enriched with information
obtained from dictionaries and shallow-
transfer rules like those used in rule-based
machine translation. The novelty of our
approach lies in the fact that the transfer
rules used were not written by humans, but
automatically inferred from a parallel cor-
pus.
1 Introduction
This paper describes the system jointly submitted
by the Departament de Llenguatges i Sistemes In-
form`atics at Universitat d?Alacant and the Promp-
sit Language Engineering company to the shared
translation task of the ACL 2014 Ninth Workshop
on Statistical Machine Translation (WMT 2014).
We participated in the English?French translation
task with a hybrid system that combines, in a
phrase-based statistical machine translation (PB-
SMT) system, bilingual phrases obtained from par-
allel corpora in the usual way (Koehn, 2010, ch.
5), and also bilingual phrases obtained from the
existing dictionaries in the Apertium rule-based
machine translation (RBMT) platform (Forcada et
al., 2011) and a number of shallow-transfer ma-
chine translation rules automatically inferred from
a small subset of the training corpus.
Among the different approaches for adding lin-
guistic information to SMT systems (Costa-Juss`a
and Farr?us, 2014), we followed the path we started
with our submission to the Spanish?English WMT
2011 shared translation task (S?anchez-Cartagena
et al., 2011b) which consisted of enriching the
phrase table of a PBSMT system with phrase pairs
generated using the dictionaries and rules in the
Apertium (Forcada et al., 2011) Spanish?English
RBMT system; our approach was one of the win-
ners
1
(together with two online SMT systems that
were not submitted for the task but were included
in the evaluation by the organisers and a system by
Systran) in the pairwise manual evaluation of the
English?Spanish translation task (Callison-Burch
et al., 2011). In this submission, however, we
only borrow the dictionaries from the Apertium
English?French RBMT system and use them to au-
tomatically infer the rules from a parallel corpus.
We therefore avoid the need for human-written
rules, which are usually written by trained experts,
and explore a novel way to add morphological
information to PBSMT. The rules inferred from
corpora and used to enlarge the phrase table are
shallow-transfer rules that build their output with
the help of the bilingual dictionary and work on
flat intermediate representations (see section 3.1);
no syntactic parsing is consequently required.
The rest of the paper is organised as follows.
The following section outlines related hybrid ap-
proaches. Section 3 formally defines the RBMT
paradigm and summarises the method followed
to automatically infer the shallow-transfer rules,
whereas the enrichment of the phrase table is de-
scribed in section 4. Sections 5 and 6 describe, re-
spectively, the resources we used to build our sub-
mission and the results achieved for the English?
French language pair. The paper ends with some
concluding remarks.
2 Related work
Linguistic data from RBMT systems have already
been used to enrich SMT systems (Tyers, 2009;
Schwenk et al., 2009; Eisele et al., 2008; S?anchez-
Cartagena et al., 2011a). We have already proved
1
No other system was found statistically significantly bet-
ter using the sign test at p ? 0.10.
178
that using hand-written rules and dictionaries from
RBMT yields better results than using only dictio-
naries (S?anchez-Cartagena et al., 2011a).
However, in the approach we present in this pa-
per, rules are automatically inferred from a paral-
lel corpus after converting it into the intermedi-
ate representation used by the Apertium RBMT
platform (see section 3.3). It can be therefore
seen as a novel method to add morphological in-
formation to SMT, as factored translation models
do (Koehn and Hoang, 2007; Graham and van
Genabith, 2010). Unlike factored models, we do
not estimate independent statistical models for the
translation of the different factors (lemmas, lexi-
cal categories, morphological inflection attributes,
etc.) and for the generation of the final surface
forms. Instead, we first infer a set of rules that deal
with the grammatical divergences between the lan-
guages involved by performing operations such as
reorderings, gender and number agreements, etc.
Afterwards, we add synthetic phrase pairs gener-
ated from these rules and the Apertium dictionar-
ies to the data from which the well-known, classi-
cal PBSMT models (Koehn, 2010) are estimated.
The rules in our approach operate on the source-
language (SL) morphological attributes of the in-
put words and on the target-language (TL) mor-
phological attributes of their translation according
to a bilingual dictionary. In addition, they do no
contain probabilities or scores, thus they increase
the predictability of the output and can be easily
corrected by humans. This fact also represents a
significant difference with the probabilistic rules
used by certain approaches that aim at improving
the grammaticality of the SMT output (Riezler and
Maxwell III, 2006; Bojar and Haji?c, 2008).
With respect to the rule inference approach,
other approaches such as those by S?anchez-
Mart??nez and Forcada (2009) and Caseli et al.
(2006) can be found in literature; however, our ap-
proach is the first strategy for shallow-transfer rule
inference which generalises to unseen combina-
tions of morphological inflection attributes in the
training corpus (S?anchez-Cartagena et al., 2014).
3 Inferring shallow-transfer rules from
parallel corpora
3.1 Shallow-transfer rule-based machine
translation
The RBMT process can be split into three different
steps (Hutchins and Somers, 1992): (i) analysis of
the SL text to build an SL intermediate represen-
tation; (ii) transfer from that SL intermediate rep-
resentation into a TL intermediate representation;
and (iii) generation of the final translation from the
TL intermediate representation.
Shallow-transfer RBMT systems use relatively
simple intermediate representations, which are
based on lexical forms consisting of lemma, part
of speech and morphological inflection informa-
tion of the words, and apply simple shallow-
transfer rules that operate on sequences of lexical
forms: this kind of systems do not perform full
parsing. For instance, for translating the English
sentence I like Pierre?s house into French with
the Apertium shallow-transfer RBMT platform we
have used to build our submission, the following
steps are carried out. First, the sentence is anal-
ysed as the following sequence of lexical forms:
I PRN-p:1.num:sg
like VB-t:pres.p:?:num:?
Pierre PN
?s POS
house N-gen:?.num:sg
This sequence is made up of a personal pronoun
(PRN) in first person (p:1) singular (num:sg)
with lemma I, the verb (VB) like in present tense
(t:pres), a proper noun (PN) with lemma Pierre,
the possessive ending (POS), and a noun (N) in sin-
gular with lemma house. Some morphological in-
flection attributes have an empty value ? because
they do not apply to the corresponding language.
Then, structural transfer rules are applied to ob-
tain the TL intermediate representation with the
help of the bilingual dictionary, which provides
the individual translation of each SL lexical form
(including its morphological information). In this
case, two rules are applied: the first one makes the
verb to agree with the personal pronoun, while the
second one translates the English possessive con-
struction into French. The resulting sequence of
TL lexical forms is:
Je PRN-p:1.num:sg
aime VB-t:pres.p:1:num:sg
le DT-gen:f.num:sg
maison N-gen:f.num:sg
de PR
Pierre PN
Note that a preposition (PR) with lemma de and a
determiner (DT) with lemma le and the same gen-
der and number as the common noun have been
added by the rule. Finally, the translation into TL
is generated from the TL lexical forms: J?aime la
maison de Pierre.
179
s1
: PN s
2
: POS s
3
: N-gen:
*
.num:
*
t
1
: le DT-gen:$
3
t
.num:$
3
s
t
2
: N-gen:$
3
t
.num:$
3
s
t
3
: de PR t
4
: PN
Figure 1: Shallow-transfer rule for the translation of the English Saxon genitive construction into French.
3.2 A rule formalism suitable for rule
inference
Figure 1 shows the second rule applied in the
example from the previous section encoded with
the formalism we have defined for rule infer-
ence (S?anchez-Cartagena et al., 2014). Each rule
contains a sequence of SL word classes (depicted
as the sequence of boxes at the top of the figure)
and TL word classes (the sequence of boxes be-
low them). The sequence of SL word classes de-
fines the set of sequences of lexical forms which
will match the rule. Each SL word class s
i
defines
the conditions that must be met by the i-th lexical
form matching the rule and contains an optional
lemma (no lemma means that any SL lemma is al-
lowed), a lexical category and a set of morpholog-
ical inflection attributes and their expected values.
A wildcard (asterisk) as the value of a morpholog-
ical inflection attribute means that it matches any
possible value. Thus, the rule from the example
matches any proper noun followed by a possessive
ending and a noun, regardless of its gender and
number.
As regards the TL word classes, they contain
the same elements as the SL word classes and de-
fine the output of the rule. An empty lemma in a
TL word class means that it is obtained by looking
up in the bilingual dictionary the SL lexical form
matching the aligned SL word class (alignments
are represented as lines connecting SL and TL
word classes). The reference value $
i
s
means that
the value of a morphological inflection attribute is
copied from the SL lexical form matching the i-th
SL word class, while the reference value $
i
t
means
that the value is taken from the TL lexical form ob-
tained after looking up in the bilingual dictionary
the aforementioned SL lexical form. The rule de-
picted in Figure 1 generates a sequence of four TL
lexical forms. The first one is a determiner whose
lemma is le, its gender is obtained from the gender
of the TL lexical form resulting after looking up in
the bilingual dictionary the third matching SL lex-
ical form ($
3
t
), that is, the common noun, while its
number is directly obtained from the same SL lexi-
cal form before dictionary look-up ($
3
s
). Although
they have not been used in this example, explicit
values can be used in the morphological inflection
attributes of the SL and TL word classes, thus re-
stricting the SL lexical forms to which the rule can
be applied to those having the values in the corre-
sponding SL word classes,
2
and explicitly stating
the value that the TL lexical forms produced by
the rule will have, respectively.
3.3 Rule inference algorithm
The set of rules that will be used to generate the
phrase pairs that will be integrated into the PB-
SMT system?s phrase table, encoded with the for-
malism presented in the previous section, are ob-
tained from the parallel corpus by applying the
steps described in this section. They are a subset
of the steps followed by S?anchez-Cartagena et al.
(2014) to infer shallow-transfer rules to be used in
Apertium from small parallel corpora.
First, both sides of the parallel corpus are mor-
phologically analysed and converted into the inter-
mediate representations used by Apertium. Word
alignments are then obtained by symmetrising
(using the refined intersection method proposed
by Och and Ney (2003)) the set of alignments
provided by GIZA++ (Och and Ney, 2003) when
it is run on both translations directions. After-
wards, the bilingual phrase pairs compatible with
the alignments are extracted as it is usually done
in SMT (Koehn, 2010, Sec. 5.2.3), and those that
are not compatible with the bilingual dictionary of
the Apertium English?French RBMT system
3
or
2
In addition to that criterion, our formalism also permits
restricting the application of a rule to the SL lexical forms
that, after being looked up in the bilingual dictionary, the
TL lexical forms obtained from them have specific morpho-
logical inflection attribute values (S?anchez-Cartagena et al.,
2014) although no restrictions of this type are imposed in the
rule depicted in Figure 1.
3
If the words that belong to open lexical categories (those
that carry the meaning of the sentence: nouns, verbs, adjec-
tives, etc.) are aligned with other words that do not match
the translation present in the bilingual dictionary, the rule in-
180
contain punctuation marks or unknown words are
discarded. Finally, from each bilingual phrase pair,
all the possible rules which correctly reproduce it
?when the rule is applied to the SL side of the
phrase pair, its TL side is obtained? are gener-
ated as follows. First, a very specific rule, which
matches only the SL phrase in the bilingual phrase
pair is generated; more general rules are then cre-
ated by modifying this initial rule. The modifica-
tions to the initial rule consist of removing lem-
mas from the SL and TL word classes, introduc-
ing wildcard values in the morphological inflec-
tion attributes of the SL word classes and adding
reference values in the morphological inflection at-
tributes of the TL word classes. The result of this
process is a huge set of rules with different levels
of generalisation. Obviously, not all the rules in
this set will be used: the best ones are automati-
cally selected by considering all the rules obtained
from the different bilingual phrase pairs extracted
from the corpus and finding the minimum set of
rules that meets the following two conditions:
1. Each bilingual phrase pair is correctly repro-
duced by at least one rule.
2. If a rule matches the SL side of bilingual
phrase pair but does not correctly reproduce
its TL side, there is another rule that is more
specific (i.e. less general) than it, and cor-
rectly reproduces its TL side.
This minimisation problem is formulated as an in-
teger linear programming
4
problem (Garfinkel and
Nemhauser, 1972) and solved using the branch
and cut algorithm (Xu et al., 2009).
From the small subset of the huge initial rules
obtained by solving the minimisation problem, the
rules whose effect can be achieved by combining
shorter rules or by translating all or some of the
words in isolation (i.e. word for word) are re-
moved. In this way, the number of rules is further
reduced and long rules, which are more prone to
overgeneralisation because they are inferred from
fewer bilingual phrase pairs, are discarded.
5
ference algorithm is likely to infer many very specific rules
that try to correct that lexical mismatch. Since the aim of
our approach is learning general rules that deal with the
grammatical divergences between languages, the bilingual
phrases that contain the aforementioned alignments are dis-
carded. Words from closed lexical categories, that usually
suffer deeper changes when the sentence is translated to a dif-
ferent language, are not subject to this restriction.
4
An integer linear programming problem involves the op-
timisation (maximisation or minimisation) of a linear objec-
tive function subject to linear inequality constraints.
5
Although longer rules contain more context information,
4 Enhancing phrase-based SMT with
shallow-transfer linguistic resources
The set of shallow-transfer rules inferred from the
parallel corpus are integrated in the PBSMT sys-
tem, together with the RBMT dictionaries, using
the same method we used for our WMT 2011
shared translation task subsmission (S?anchez-
Cartagena et al., 2011b). However, it is important
to stress that, until now, this strategy had only been
tested when the rules to be integrated were hand-
written and not automatically obtained from cor-
pora.
Our strategy involves adding to the phrase ta-
ble of the PBSMT system all the bilingual phrase
pairs which either match a shallow-transfer rule or
an entry in the bilingual dictionary. Generating the
set of bilingual phrase pairs which match bilingual
dictionary entries is straightforward. First, all the
SL surface forms that are recognised by Apertium
and their corresponding lexical forms are gener-
ated. Then, these SL lexical forms are translated
using the bilingual dictionary, and finally their TL
surface forms are generated.
Bilingual phrase pairs which match structural
transfer rules are generated in a similar way. First,
the SL sentences to be translated are analysed with
Apertium to get their SL lexical forms, and then
the sequences of lexical forms that match a struc-
tural transfer rule are translated with that rule and
passed through the rest of the Apertium pipeline
in order to get their translations. If a sequence
of SL lexical forms is matched by more than one
structural transfer rule, it will be used to generate
as many bilingual phrase pairs as different rules
it matches. This differs from the way in which
Apertium translates, as it only applies the longest
rule. Note also that the test set is used to guide the
phrase extraction in order to avoid the generation
of an unmanageable set of phrase pairs.
We add these bilingual phrase pairs directly to
the phrase table, rather than adding them to the
training corpus and relying on the phrase extrac-
tion algorithm (Koehn, 2010, sec. 5.2.3), in order
to avoid splitting the multi-word expressions pro-
vided by Apertium into smaller phrases (Schwenk
et al., 2009, sec. 2). The bilingual phrase pairs
are added only once to the list of corpus-extracted
phrase pairs, and then the phrase translation prob-
abilities are computed by relative frequency as
usual (Koehn, 2010, sec. 5.2.5). A boolean feature
for our rule inferring algorithm there are fewer bilingual
phrases from which to infer them, and consequently fewer
evidence from which to extract the right reference attributes.
181
function to flag bilingual phrase pairs obtained
from the RBMT resources is added to the phrase
table in order to conveniently weight the synthetic
RBMT phrase pairs.
5 System training
We built a baseline PBSMT Moses (Koehn et
al., 2007) system
6
from a subset of the paral-
lel corpora distributed as part of the WMT 2014
shared translation task, namely Europarl (Koehn,
2005), News Commentary and Common Crawl,
and a subset of the French monolingual corpora,
namely Common Crawl, Europarl, News Com-
mentary and News Crawl. The language model
was built with the KenLM language modelling
toolkit (Heafield et al., 2013), which was used
to train a 5-gram language model using inter-
polated Kneser-Ney discounting (Goodman and
Chen, 1998). Word alignments were computed
by means of GIZA++ (Och and Ney, 2003). The
weights of the different feature functions were op-
timised by means of minimum error rate train-
ing (Och, 2003) on the 2013 WMT test set.
7
The phrase table of this baseline system was
then enriched with phrase pairs generated from
rules automatically inferred from the concatena-
tion of the test corpora distributed for the WMT
2008?2012 shared translation tasks, and from the
English?French bilingual dictionary in the Aper-
tium platform.
8
Since the minimisation problem
which needs to be solved in order to obtain the
rules is very time-consuming, we chose a small
rule inference corpus similar to this year?s test set.
The bilingual dictionary, which contains mappings
between SL and TL lemmas, consists of 13 088 en-
tries and is quite small compared to the Spanish?
English bilingual dictionary we used in our sub-
mission to WMT 2011 (S?anchez-Cartagena et al.,
2011b), which consisted of 326 228 bilingual en-
tries. This is because the English?French Aper-
tium linguistic resources were automatically built
by crossing data from other existing language
pairs.
Table 1 summarises the data about the corpora
used to build our submission, both for the PBSMT
baseline system and for the rules used to enrich its
phrase table.
The corpus used to automatically infer the rules
6
No factored models were used.
7
The corpora can be downloaded from http://www.
statmt.org/wmt14/translation-task.html.
8
https://svn.code.sf.net/p/apertium/
svn/incubator/apertium-en-fr
Task Corpus Sentences
Translation model
Europarl 2 007 723
News Commentary 183 251
Common Crawl 3 244 152
Total 5 435 126
Total clean 4 196 987
Language model
Common Crawl 3 244 152
Europarl 2 190 579
News Commentary 227 013
News Crawl 30 451 749
Total 36 113 493
Rule inference newstest 2008?2012 13 071
Tuning newstest2013 3 000
Test newstest2014 3 003
Table 1: Size of the corpora used in the experi-
ments. The bilingual training corpora was cleaned
up to remove empty parallel sentences and those
containing more than 40 tokens.
was split into two parts: the larger one (4/5 of
the corpus) was used for actual rule inference as
described in section 3.3; the remaining corpus
was used as a development corpus as explained
next. For each rule z, first the proportion r(z) of
bilingual phrase pairs correctly reproduced by the
rule divided by the number of bilingual phrases
it matches is computed. Rules whose proportion
r(z) is lower than a threshold value ? are then
discarded before solving the minimisation prob-
lem. The value of ? is chosen so that it maximises,
on the development corpus, the BLEU score (Pap-
ineni et al., 2002) obtained by an Apertium-based
system which uses the inferred rules; in our sub-
mission ? = 0.15. In addition, rules that do not
correctly reproduce at least 100 bilingual phrase
pairs were also discarded in order to make the min-
imisation problem computationally feasible.
6 Results and discussion
Table 2 reports the translation performance as
measured by BLEU (Papineni et al., 2002),
TER (Snover et al., 2006) and METEOR (Baner-
jee and Lavie, 2005) achieved by the baseline PB-
SMT, our submission (UA-Prompsit), Apertium
when it uses the set of inferred rules, and Aper-
tium when it uses no rules at all (word-for-word
translation). The size of the phrase table and the
amount of unknown words in the test set are also
reported when applicable.
According to the three evaluation metrics, the
translation performance of our submission is very
close to that of the PBSMT baseline (slightly bet-
ter according to BLEU and TER, and slightly
worse according to METEOR). The difference be-
tween both systems computed by paired bootstrap
182
system BLEU TER METEOR # of unknown words phrase table size
baseline 0.3232 0.5807 0.5441 870 100 530 734
UA-Prompsit 0.3258 0.5781 0.5432 861 100 585 182
Apertium-rules 0.0995 0.7767 0.3168 4 743 -
Apertium-word-for-word 0.0631 0.8368 0.2617 4 743 -
Table 2: Case-insensitive BLEU, TER, and METEOR scores obtained, on the newstest2014 test set, by
the baseline PBSMT system (baseline), the hybrid system submitted to the WMT 2014 shared translation
task (UA-Prompsit), Apertium when it uses the set of inferred rules (Apertium-rules), and Apertium
when it uses no rules at all (Apertium-word-for-word). The number of unknown words and the size of
the phrase table are also reported when applicable.
resampling (Koehn, 2004) is not statistically sig-
nificant for any of the three evaluation metrics
(1 000 iterations, p = 0.05).
An inspection of the 86 rules inferred shows
that they encode some of the transformations that
one would expect from a set of English?French
rules, such as gender and number agreements be-
tween nouns, determiners and adjectives, prepo-
sition changes, and the introduction of the aux-
iliary verb avoir for the past tense. In addition,
the improvement over word-for-word translation
achieved when they are used by Apertium is statis-
tically significant for the three evaluation metrics.
One of the reasons for not improving the base-
line PBMT system might be the small coverage
of the Apertium dictionaries. As already men-
tioned in the previous section, the English?French
bilingual dictionary has a low number of entries
compared to more mature language pairs in Aper-
tium which have around 20 times more bilingual
entries. Table 1 shows some effects of such a
small dictionary: the number of unknown words
for the Apertium-based system is really high, and
with regards to UA-Prompsit, its coverage barely
increases when compared to the PBSMT baseline.
We plan to test the approach presented in this paper
with language pairs for which more mature dictio-
naries are available in the Apertium project.
In addition to this, due to the tight schedule, we
had to remove the rules not reproducing at least
100 bilingual phrase pairs in order to solve the min-
imisation problem in a short amount of time. This
has clearly reduced the amount of rules inferred
and prevented some useful information present in
the parallel corpus from being incorporated in the
form of rules. For instance, no rule matching a
sequence longer than 3 lexical forms has been ex-
tracted (long bilingual phrases are less frequent
than short ones). Future research directions for
alleviating this problem include setting the mini-
mum number of reproduced bilingual phrases in-
dependently for each sequence of SL lexical cate-
gories (S?anchez-Cartagena et al., 2014).
7 Concluding remarks
We have presented the MT system submitted
jointly by the Departament de Llenguatges i Sis-
temes Inform`atics at Universitat d?Alacant and
Prompsit Language Engineering to the WMT
2014 shared translation task. We developed a
hybrid system for the English?French language
pair which enriches the phrase table of a stan-
dard PBSMT system with phrase pairs generated
from the Apertium RBMT dictionaries and a set of
shallow-transfer rules automatically inferred from
a parallel corpus, also with the help of the dic-
tionaries. This submission aims at solving one
strong limitation of a previous submission of our
team (S?anchez-Cartagena et al., 2011b): the need
for a hand-crafted set of shallow-transfer rules,
which can only be written by people with a deep
knowledge of the languages involved. Our ap-
proach outperforms a standard PBSMT system
built from the same data by a small, non statisti-
cally significant margin, according to two of the
three evaluation metrics used. The low coverage
of the dictionaries used and the aggressive pruning
carried out when solving the minimisation prob-
lem needed to infer the rules are probably the rea-
sons behind such a small improvement over the
baseline.
Acknowledgements
Work funded by Universitat d?Alacant through
project GRE11-20, by the Spanish Ministry
of Economy and Competitiveness through
projects TIN2009-14009-C02-01 and TIN2012-
32615, by Generalitat Valenciana through grant
ACIF/2010/174 (VALi+d programme), and by
the European Union Seventh Framework Pro-
gramme FP7/2007-2013 under grant agreement
PIAP-GA-2012-324414 (Abu-MaTran).
183
References
S. Banerjee and A. Lavie. 2005. Meteor: An auto-
matic metric for mt evaluation with improved corre-
lation with human judgments. In Proceedings of the
ACL Workshop on Intrinsic and Extrinsic Evaluation
Measures for Machine Translation and/or Summa-
rization, pages 65?72.
O. Bojar and J. Haji?c. 2008. Phrase-based and deep
syntactic English-to-Czech statistical machine trans-
lation. In Proceedings of the third Workshop on Sta-
tistical Machine translation, pages 143?146. Associ-
ation for Computational Linguistics.
C. Callison-Burch, P. Koehn, C. Monz, and O. Zaidan.
2011. Findings of the 2011 workshop on statisti-
cal machine translation. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
22?64, Edinburgh, Scotland, July. Association for
Computational Linguistics.
H. M. Caseli, M. G. V. Nunes, andM. L. Forcada. 2006.
Automatic induction of bilingual resources from
aligned parallel corpora: application to shallow-
transfer machine translation. Machine Translation,
20(4):227?245. Published in 2008.
M. R. Costa-Juss`a and M. Farr?us. 2014. Statistical
machine translation enhancements through linguis-
tic levels: A survey. ACM Comput. Surv., 46(3).
A. Eisele, C. Federmann, H. Saint-Amand, M. Jelling-
haus, T. Herrmann, and Y. Chen. 2008. Us-
ing Moses to integrate multiple rule-based machine
translation engines into a hybrid system. In Proceed-
ings of the Third Workshop on Statistical Machine
Translation, pages 179?182, Columbus, Ohio.
M. L. Forcada, M. Ginest??-Rosell, J. Nordfalk,
J. O?Regan, S. Ortiz-Rojas, J. A. P?erez-Ortiz,
G. Ram??rez-S?anchez F. S?anchez-Mart??nez, and F. M.
Tyers. 2011. Apertium: a free/open-source platform
for rule-based machine translation. Machine Trans-
lation, 25(2):127?144. Special Issue: Free/Open-
Source Machine Translation.
R. S. Garfinkel and G. L. Nemhauser. 1972. Integer
programming, volume 4. Wiley New York.
J. Goodman and S. F. Chen. 1998. An empirical
study of smoothing techniques for language model-
ing. Technical Report TR-10-98, Harvard Univer-
sity, August.
Y. Graham and J. van Genabith. 2010. Factor tem-
plates for factored machine translation models. In
IWSLT 2010 : 7th International Workshop on Spo-
ken Language Translation, pages 275?283.
K. Heafield, I. Pouzyrevsky, J. H. Clark, and P. Koehn.
2013. Scalable modified Kneser-Ney language
model estimation. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics, pages 690?696, Sofia, Bulgaria, August.
W. J. Hutchins and H. L. Somers. 1992. An introduc-
tion to machine translation, volume 362. Academic
Press New York.
P. Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868?876,
Prague.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Annual Meeting of the Association for Computa-
tional Linguistics (ACL), demonstration session.
P. Koehn. 2004. Statistical significance tests for ma-
chine translation evaluation. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, volume 4, pages 388?395.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proceedings of the Tenth
Machine Translation Summit, pages 12?16, Phuket,
Thailand, September.
P. Koehn. 2010. Statistical Machine Translation. Cam-
bridge University Press.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29:19?51, March.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proceedings of the 41st
Annual Meeting on Association for Computational
Linguistics, pages 160?167, Sapporo, Japan.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing of the ACL, pages 311?318.
S. Riezler and J. T. Maxwell III. 2006. Grammati-
cal machine translation. In Proceedings of the main
conference on Human Language Technology Confer-
ence of the North American Chapter of the Associa-
tion of Computational Linguistics, pages 248?255.
Association for Computational Linguistics.
V. M. S?anchez-Cartagena, F. S?anchez-Mart??nez, and
J. A. P?erez-Ortiz. 2011a. Integrating shallow-
transfer rules into phrase-based statistical machine
translation. In Proceedings of the XIII Machine
Translation Summit, pages 562?569, Xiamen, China,
September.
V. M. S?anchez-Cartagena, F. S?anchez-Mart??nez, and
J. A. P?erez-Ortiz. 2011b. The Universitat d?Alacant
hybrid machine translation system for wmt 2011. In
Proceedings of the Sixth Workshop on Statistical Ma-
chine Translation, pages 457?463, Edinburgh, Scot-
land, July. Association for Computational Linguis-
tics.
184
V. M. S?anchez-Cartagena, J. A. P?erez-Ortiz, and
F. S?anchez-Mart??nez. 2014. A generalised align-
ment template formalism and its application to the
inference of shallow-transfer machine translation
rules from scarce bilingual corpora. Computer
Speech and Language. Submitted to the Special Is-
sue on Hybrid Machine Translation.
F. S?anchez-Mart??nez and M. L. Forcada. 2009. Infer-
ring shallow-transfer machine translation rules from
small parallel corpora. Journal of Artificial Intelli-
gence Research, 34(1):605?635.
H. Schwenk, S. Abdul-Rauf, L. Barrault, and J. Senel-
lart. 2009. SMT and SPE Machine Transla-
tion Systems for WMT?09. In Proceedings of the
Fourth Workshop on Statistical Machine Translation,
StatMT ?09, pages 130?134, Stroudsburg, PA, USA.
Association for Computational Linguistics.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and
J. Makhoul. 2006. A study of translation edit rate
with targeted human annotation. In In Proceedings
of Association for Machine Translation in the Amer-
icas, pages 223?231.
F. M. Tyers. 2009. Rule-based augmentation of train-
ing data in Breton?French statistical machine trans-
lation. In Proceedings of the 13th Annual Confer-
ence of the European Association of Machine Trans-
lation, pages 213?217.
Y. Xu, T. K. Ralphs, L. Lad?anyi, and M. J. Saltzman.
2009. Computational experience with a software
framework for parallel integer programming. IN-
FORMS Journal on Computing, 21(3):383?397.
185
