Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 85?88, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Two diverse systems built using
generic components for spoken dialogue
(Recent Progress on TRIPS)
James Allen, George Ferguson, Mary Swift, Amanda Stent, Scott Stoness, 
Lucian Galescu, Nathan Chambers, Ellen Campana, and Gregory Aist
University of Rochester
Computer Science Department
UR Comp Sci RC 270226
Rochester NY 14627 USA
{james, ferguson, swift, stoness,
campana, gaist}
@cs.rochester.edu
Institute for
Human and Machine Cognition
40 South Alcaniz St.
Pensacola FL 32502
{lgalescu,nchambers}@ihmc.us
State University of New York at
Stony Brook
1418 Computer Science
Stony Brook University
Stony Brook NY 11794 USA
stent@cs.sunysb.edu
Abstract
This  paper  describes  recent  progress  on  the
TRIPS architecture for developing spoken-lan-
guage dialogue systems.  The interactive poster
session will include demonstrations of two sys-
tems built using TRIPS: a computer purchas-
ing assistant, and an object placement (and ma-
nipulation) task.
1 Introduction
Building a robust spoken dialogue system for a new
task currently requires considerable effort,  includ-
ing  extensive  data  collection,  grammar  develop-
ment, and building a dialogue manager that drives
the  system using its  "back-end" application (e.g.
database query, planning and scheduling). We de-
scribe progress in an effort to build a generic dia-
logue system that  can be rapidly customized to a
wide range of different types of applications, pri-
marily  by  defining a  domain-specific  task  model
and the interfaces to the back-end systems. This is
achieved by  using generic  components  (i.e.,  ones
that apply in any practical domain) for all stages of
understanding  and developing techniques for rapid-
ly customizing the generic components to new do-
mains  (e.g.  Aist,  Allen,  and  Galescu  2004).  To
achieve this goal we have made several innovations,
including (1) developing domain independent mod-
els of  semantic and  contextual  interpretation,  (2)
developing generic  dialogue  management  compo-
nents based on an abstract  model of collaborative
problem solving, and (3) extensively using an ontol-
ogy-mapping system that connects the domain inde-
pendent representations to the representations/query
languages used by the back-end applications,  and
which is used to automatically optimize the perfor-
mance of the system in the specific domain.
2 Theoretical  Underpinnings:  The Prob-
lem-Solving Model of Dialogue
While many have observed that communication
is a specialized form of joint action that happens to
involve language and that dialogue can be viewed
as collaborative problem solving, very few imple-
mented systems have been explicitly based on these
ideas. Theories of speech act interpretation as inten-
tion recognition have been developed  (including ex-
tensive  prior  work  in  TRIPS'  predecessor,  the
TRAINS project), but have been generally consid-
ered impractical for actual systems.  Planning mod-
els  have been more successful  on the  generation
side, and some systems have used the notion of exe-
cuting explicit task models to track and drive the in-
teractions  (e.g.,  Sidner  and  Rich's  COLLAGEN
framework). But collaborative problem solving, and
dialogue in general, is much more general than exe-
cuting tasks. In our applications, in addition to exe-
cuting tasks, we see dialogue that is used to define
the task (i.e., collaborative planning), evaluate the
task (e.g., estimating how long it will take,  com-
paring options,  or  likely effects),    debug a  task
(e.g., identifying and discussing problems and how
to remedy them), learn new tasks (e.g., by demon-
stration and instruction).
85
In the remainder of the paper, we'll first discuss
the methods we've developed for building dialogue
systems using generic components.  We'll then de-
scribe two systems implemented using the TRIPS
architecture that we will demonstrate at the interac-
tive poster session.
3 Generic Methods:  Ontology Mappings
and Collaborative Problem Solving
The goal of our work is to develop generic spoken
dialogue technology that can be rapidly customized
to new applications, tasks and domains. To do this,
we have developed generic domain independent rep-
resentations not only of sentence meaning but also
of the collaborative actions that are performed by
the speech acts as one engages in dialogue. Further-
more, we need to be able to easily connect these
generic representations to a wide range of different
domain specific task models and applications, rang-
ing from data base query systems to state-of-the-art
planning and scheduling systems.  This  paper  de-
scribes  the  approach  we  have  developed  in  the
TRIPS system. TRIPS is now being used in a wide
range of diverse applications, from interactive plan-
ning (e.g., developing evacuation plans), advice giv-
ing  (e.g.,  a  medication  advisor  (Ferguson  et  al.
2002)),  controlling teams of robots,   collaborative
assistance (e.g., an assistant that can help you pur-
chase a computer, as described in this paper), sup-
porting human learning, and most recently having
the computer  learn (or  be  taught)  tasks,  such as
learning to perform tasks on the web.  Even though
the tasks and domains differ dramatically, these ap-
plications use the same set of core understanding
components. 
The key to supporting such a range of tasks and ap-
plications is the use of a general ontology-mapping
system. This allows the developer to express a set
of mapping rules that translate the generic knowl-
edge representation into the specific representations
used by the back-end applications (called the KR
representation).   In  order  to  support  generic dis-
course processing, we represent these mappings as
a chain of simpler transformations. These represen-
tations are thus transformed in several stages. The
first,  using the ontology mapping rules,  maps the
LF representation into an intermediary representa-
tion (AKRL - the abstract KR language) that has a
generic syntax  but  whose content is  expressed in
terms of the KR ontology. The second stage is a
syntactic transformation that occurs at the time that
calls to the back-end applications actually occur so
that  interactions  occur  in  the  representations  the
back-end expects.   In  addition to  using ontology
mapping to  deal  with the representational  issues,
TRIPS is unique in that it uses a generic model of
collaborative problem solving to drive the dialogue
itself  (e.g.  Allen,  Blaylock,  and  Ferguson 2002).
This model forms the basis of a generic component
(the collaboration manager) that supports both in-
tention recognition to identify the intended speech
acts and their content, planning the system's actions
to respond to the user (or that take initiative), and
providing utterance realization goals to the genera-
tion system. To develop this, we have been develop-
ing  a  generic  ontology  of  collaborative  problem
solving acts, which provide the framework for man-
aging  the  dialogue.  The  collaboration  manager
queries a domain-specific task component in order
to  make  decisions  about  interpretations  and  re-
sponses.
4 TRIPS  Spoken  Dialogue  Interface  to
the CALO Purchasing Assistant 
The CALO project is a large multisite effort which
aims  at  building  a  computerized  assistant  that
learns how to help you with day-to-day tasks. The
overarching goal of the CALO project is to 
... create cognitive software systems, that is,
systems that can reason, learn from experi-
ence, be told what to do, explain what they
are doing, reflect on their experience, and re-
spond robustly to surprise (Mark and Per-
rault 2004). 
Within this broad mandate, one of our current areas
of focus is user-system dialogue regarding the task
of purchasing - including eliciting user needs, de-
scribing possibilities, and reviewing & finalizing a
purchase  decision.  (Not  necessarily  as  discrete
stages; these elements may be interleaved as appro-
priate for the specific item(s) and setting.)  Within
the purchasing domain,  we began with computer
purchasing and have branched out to other equip-
ment such as projectors.
How to help with purchasing? The family of tasks
involving purchasing items online, regardless of the
type of item, have a  number of elements in com-
mon. The process of purchasing has some common
86
dialogue elements - reporting on the range of fea-
tures  available,  allowing the user  to specify con-
straints, and so forth.  Also, regarding the goal that
must be reached at the end of the task, the eventual
item must:
Meet requirements.  The item needs to meet some
sort of user expectations. This could be as arbitrary
as a specific part number, or as compositional - and
amenable to machine understanding -  as  a  set  of
physical  dimensions (length,  width,  height,  mass,
etc.) 
Be approved. Either the system will have the au-
thority to approve it (cf. Amazon's one-click order-
ing system), or more commonly the user will review
and confirm the purchase. In an office environment
the approval process may extend to include review
by a supervisor, such as might happen with an item
costing over (say) $1000. 
Be available. (At  one time a  certain  electronics
store in California had the habit of leaving out floor
models of laptops beyond the point where any were
actually available for sale.  (Perhaps to entice the
unwitting customer into an ?upsale?, that is, buying
a  similar  but  more  expensive  computer.))  On  a
more serious note, computer specifications change
rapidly, and so access to online information about
available  computers  (provided  by  other  research
within CALO) would be important in order to en-
sure that the user can actually order the machine he
or she has indicated a preference for.  
At  the interactive poster  session,  we will demon-
strate some of the current spoken dialogue capabili-
ty related to the CALO task of purchasing equip-
ment.  We will demonstrate a number of the aspects
of the system such as initiating a conversation, dis-
cussing specific requirements,  presenting possible
equipment to purchase,  system-initiated reminders
to ask for supervisor approval for large purchases,
and finalizing a decision to purchase. 
Figure 1. Fruit carts display.
87
5 TRIPS  Spoken  Dialogue  Interface  to
choosing,  placing,  painting,  rotating,
and filling (virtual) fruit carts
TRIPS is versatile in its applications, as we've said
previously.  We hope to also demonstrate an inter-
face to  a  system for  using spoken commands to
modifying, manipulating, and placing objects on a
computer-displayed map.  This  system (aka  ?fruit
carts?)  extends  the  TRIPS  architecture  into  the
realm of continuous understanding.  That is, when
state-of-the-art  dialogue systems listen,  they typi-
cally wait for the end of the utterance before decid-
ing what to do.  People on the other hand do not
wait in this way ? they can act on partial informa-
tion as  it  becomes available.   A classic example
comes  from  M.  Tanenhaus  and  colleagues  at
Rochester: when presented with several objects of
various colors and told to ?click on the yel-?, people
will already tend to be looking relatively more at the
yellow object(s) even before the word ?yellow? has
been completed.  To achieve this type of interactivi-
ty with a dialogue system ? at least at the level of
two or three words at a time, if not parts of words ?
imposes some interesting challenges. For example:
1. Information must flow asynchronously between
dialogue components, so that actions can be trig-
gered based on partial utterances even while the
understanding continues
2. There must be reasonable representations of in-
complete information ? not just ?incomplete sen-
tence?,  but  specifying what  is  present  already
and perhaps what may potentially follow
3. Speech  recognition,  utterance  segmentation,
parsing, interpretation, discourse reasoning, and
actions must all be able to happen in real time
The fruit carts system consists of two main compo-
nents:  first,  a  graphical  interface implemented on
Windows  2000  using  the  .NET  framework,  and
connected to  a  high-quality  eyetracker;  second,  a
TRIPS-driven spoken dialogue interface implement-
ed primarily in LISP.   The actions in this domain
are as follows:
1. Select an object (?take the large plain square?)
2. Move it (?move it to central park?)
3. Rotate  it  (?and then turn  it  left  a  bit  ?  that's
good?)
4. Paint it (?and that one needs to be purple?)
5. Fill it (?and there's a grapefruit inside it?)
Figure 1 shows an example screenshot from the
fruit carts visual display. The natural language in-
teraction  is  designed to  handle  various  ways  of
speaking,  including conventional  definite  descrip-
tions (?move the large square to central park?) and
more interactive language such as (?up towards the
flag pole ? right a bit ? more ? um- stop there.?)
6 Conclusion
In this brief paper,  we have described some of
the recent progress on the TRIPS platform.  In par-
ticular we have focused on two systems developed
in TRIPS: a spoken dialogue interface to a mixed-
initiative purchasing assistant, and a spoken inter-
face for exploring continuous understanding in an
object-placement task.  In  both  cases  the  systems
make use of reusable components ? for input and
output  such as  parsing and speech synthesis,  and
also for dialogue functionality such as mapping be-
tween language,  abstract  semantics,  and  specific
representations for each domain.
References 
Aist,  G.  2004.  Speech,  gaze,  and  mouse  data  from
choosing,  placing,  painting,  rotating,  and  filling
(virtual) vending carts. International Committee for
Co-ordination  and  Standardisation  of  Speech
Databases  (COCOSDA)  2004  Workshop,  Jeju  Is-
land, Korea, October 4, 2004. 
Aist, G.S., Allen, J., and Galescu, L. 2004. Expanding
the linguistic coverage of a spoken dialogue system
by mining human-human dialogue for new sentences
with familiar meanings. Member Abstract, 26th An-
nual  Meeting  of  the  Cognitive  Science  Society,
Chicago, August 5-7, 2004. 
James Allen, Nate Blaylock, and George Ferguson. A
problem-solving model for collaborative agents.  In
First International Joint Conference on Autonomous
Agents and Multiagent Systems, Bologna, Italy, July
15-19 2002. 
George  Ferguson,  James  F.  Allen,  Nate  J.  Blaylock,
Donna K. Byron, Nate W. Chambers, Myrsolava O.
Dzikovska, Lucian Galescu, Xipeng Shen, Robert S.
Swier, and Mary D. Swift.  The Medication Advisor
Project: Preliminary Report, Technical Report 776,
Computer  Science  Dept.,  University  of  Rochester,
May 2002. 
Mark,  B.,  and  Perrault,  R.  (principal  investigators).
2004.  Website for Cognitive Assistant  that  Learns
and Organizes. http://www.ai.sri.com/project/CALO
88
147
148
149
150
151
152
153
154
187
188
189
190
An Intelligent Procedure Assistant
Built Using REGULUS 2 and ALTERF
Manny Rayner, Beth Ann Hockey, Jim Hieronymus, John Dowding, Greg Aist
Research Institute for Advanced Computer Science (RIACS)
NASA Ames Research Center
Moffet Field, CA 94035
{mrayner,bahockey,jimh,jdowding,aist}@riacs.edu
Susana Early
DeAnza College/NASA Ames Research Center
searly@mail.arc.nasa.gov
Abstract
We will demonstrate the latest version of
an ongoing project to create an intelli-
gent procedure assistant for use by as-
tronauts on the International Space Sta-
tion (ISS). The system functionality in-
cludes spoken dialogue control of nav-
igation, coordinated display of the pro-
cedure text, display of related pictures,
alarms, and recording and playback of
voice notes. The demo also exempli-
fies several interesting component tech-
nologies. Speech recognition and lan-
guage understanding have been devel-
oped using the Open Source REGULUS
2 toolkit. This implements an approach
to portable grammar-based language mod-
elling in which all models are derived
from a single linguistically motivated uni-
fication grammar. Domain-specific CFG
language models are produced by first
specialising the grammar using an au-
tomatic corpus-based method, and then
compiling the resulting specialised gram-
mars into CFG form. Translation between
language centered and domain centered
semantic representations is carried out by
ALTERF, another Open Source toolkit,
which combines rule-based and corpus-
based processing in a transparent way.
1 Introduction
Astronauts aboard the ISS spend a great deal of their
time performing complex procedures. This often in-
volves having one crew member reading the proce-
dure aloud, while while the other crew member per-
forms the task, an extremely expensive use of as-
tronaut time. The Intelligent Procedure Assistant is
designed to provide a cheaper alternative, whereby a
voice-controlled system navigates through the pro-
cedure under the control of the astronaut perform-
ing the task. This project has several challenging
features including: starting the project with no tran-
scribed data for the actual target input language, and
rapidly changing coverage and functionality. We
are using REGULUS 2 and ALTERF to address these
challenges. Together, they provide an example-
based framework for constructing the portion of the
system from recognizer through intepretation that
allows us to make rapid changes and take advan-
tage of both rule-base and corpus-based information
sources. In this way, we have been able to extract
maximum utility out of the small amounts of data
initial available to the project and also smoothly ad-
just as more data has been accumulated in the course
of the project.
The following sections describe the procedure as-
sistant application and domain, REGULUS 2 and AL-
TERF.
2 Application and domain
The system, an early version of which was described
in (Aist et al, 2002), is a prototype intelligent voice
enabled personal assistant, intended to support astro-
nauts on the International Space Station in carrying
out complex procedures. The first production ver-
sion is tentatively scheduled for introduction some
time during 2004. The system reads out each pro-
cedure step as it reaches it, using a TTS engine, and
also shows the corresponding text and supplemen-
tary images in a visual display. Core functionality
consists of the following types of commands:
? Navigation: moving to the following step or
substep (?next?, ?next step?, ?next substep?),
going back to the preceding step or substep
(?previous?, ?previous substep?), moving to a
named step or substep (?go to step three?, ?go
to step ten point two?).
? Visiting non-current steps, either to preview fu-
ture steps or recall past ones (?read step four?,
?read note before step nine?). When this func-
tionality is invoked, the non-current step is dis-
played in a separate window, which is closed
on returning to the current step.
? Recording, playing and deleting voice notes
(?record voice note?, ?play voice note on step
three point one?, ?delete voice note on substep
two?).
? Setting and cancelling alarms (?set alrm for
five minutes from now?, ?cancel alarm at ten
twenty one?).
? Showing or hiding pictures (?show the small
waste water bag?, ?hide the picture?).
? Changing the TTS volume (?increase/decrease
volume?).
? Querying status (?where are we?, ?list voice
notes?, ?list alarms?).
? Undoing and correcting commands (?go back?,
?no I said increase volume?, ?I meant step
four?).
The system consists of a set of modules, written
in several different languages, which communicate
with each other through the SRI Open Agent Ar-
chitecture (Martin et al, 1998). Speech recogni-
tion is carried out using the Nuance Toolkit (Nuance,
2003).
3 REGULUS 2
REGULUS 2 (Rayner et al, 2003; Regulus, 2003)
is an Open Source environment that supports effi-
cient compilation of typed unification grammars into
speech recognisers. The basic intent is to provide
a set of tools to support rapid prototyping of spo-
ken dialogue applications in situations where little
or no corpus data exists. The environment has al-
ready been used to build over half a dozen appli-
cations with vocabularies of between 100 and 500
words.
The core functionality provided by the REGU-
LUS 2 environment is compilation of typed unifi-
cation grammars into annotated context-free gram-
mar language models expressed in Nuance Gram-
mar Specification Language (GSL) notation (Nu-
ance, 2003). GSL language models can be con-
verted into runnable speech recognisers by invoking
the Nuance Toolkit compiler utility, so the net result
is the ability to compile a unification grammar into
a speech recogniser.
Experience with grammar-based spoken dialogue
systems shows that there is usually a substantial
overlap between the structures of grammars for dif-
ferent domains. This is hardly surprising, since they
all ultimately have to model general facts about the
linguistic structure of English and other natural lan-
guages. It is consequently natural to consider strate-
gies which attempt to exploit the overlap between
domains by building a single, general grammar valid
for a wide variety of applications. A grammar of this
kind will probably offer more coverage (and hence
lower accuracy) than is desirable for any given spe-
cific application. It is however feasible to address
the problem using corpus-based techniques which
extract a specialised version of the original general
grammar.
REGULUS implements a version of the grammar
specialisation scheme which extends the Explana-
tion Based Learning method described in (Rayner
et al, 2002). There is a general unification gram-
mar, loosely based on the Core Language Engine
grammar for English (Pulman, 1992), which has
been developed over the course of about ten individ-
ual projects. The semantic representations produced
by the grammar are in a simplified version of the
Core Language Engine?s Quasi Logical Form nota-
tion (van Eijck and Moore, 1992).
A grammar built on top of the general grammar is
transformed into a specialised Nuance grammar in
the following processing stages:
1. The training corpus is converted into a ?tree-
bank? of parsed representations. This is done
using a left-corner parser representation of the
grammar.
2. The treebank is used to produce a specialised
grammar in REGULUS format, using the EBL
algorithm (van Harmelen and Bundy, 1988;
Rayner, 1988).
3. The final specialised grammar is compiled into
a Nuance GSL grammar.
4 ALTERF
ALTERF (Rayner and Hockey, 2003) is another Open
Source toolkit, whose purpose is to allow a clean
combination of rule-based and corpus-driven pro-
cessing in the semantic interpretation phase. There
is typically no corpus data available at the start
of a project, but considerable amounts at the end:
the intention behind ALTERF is to allow us to shift
smoothly from an initial version of the system which
is entirely rule-based, to a final version which is
largely data-driven.
ALTERF characterises semantic analysis as a task
slightly extending the ?decision-list? classification
algorithm (Yarowsky, 1994; Carter, 2000). We start
with a set of semantic atoms, each representing a
primitive domain concept, and define a semantic
representation to be a non-empty set of semantic
atoms. For example, in the procedure assistant do-
main we represent the utterances
please speak up
show me the sample syringe
set an alarm for five minutes from now
no i said go to the next step
respectively as
{increase volume}
{show, sample syringe}
{set alrm, 5, minutes}
{correction, next step}
where increase volume, show,
sample syringe, set alrm, 5, minutes,
correction and next step are semantic
atoms. As well as specifying the permitted semantic
atoms themselves, we also define a target model
which for each atom specifies the other atoms with
which it may legitimately combine. Thus here, for
example, correction may legitimately combine
with any atom, but minutes may only combine
with correction, set alrm or a number.1.
Training data consists of a set of utterances, in
either text or speech form, each tagged with its in-
tended semantic representation. We define a set of
feature extraction rules, each of which associates an
utterance with zero or more features. Feature ex-
traction rules can carry out any type of processing.
In particular, they may involve performing speech
recognition on speech data, parsing on text data, ap-
plication of hand-coded rules to the results of pars-
ing, or some combination of these. Statistics are
then compiled to estimate the probability p(a | f)
of each semantic atom a given each separate feature
f , using the standard formula
p(a | f) = (Naf + 1)/(Nf + 2)
where Nf is the number of occurrences in the train-
ing data of utterances with feature f , and N af is the
number of occurrences of utterances with both fea-
ture f and semantic atom a.
The decoding process follows (Yarowsky, 1994)
in assuming complete dependence between the fea-
tures. Note that this is in sharp contrast with the
Naive Bayes classifier (Duda et al, 2000), which as-
sumes complete independence. Of course, neither
assumption can be true in practice; however, as ar-
gued in (Carter, 2000), there are good reasons for
preferring the dependence alternative as the better
option in a situation where there are many features
extracted in ways that are likely to overlap.
We are given an utterance u, to which we wish to
assign a representation R(u) consisting of a set of
semantic atoms, together with a target model com-
prising a set of rules defining which sets of seman-
1The current system post-processes Alterf semantic atom
lists to represent domain dependancies between semantic
atoms more directly before passing on the result. e.g.
(correction, set alrm, 5, minutes) is repack-
aged as (correction(set alrm(time(0,5))))
tic atoms are consistent. The decoding process pro-
ceeds as follows:
1. Initialise R(u) to the empty set.
2. Use the feature extraction rules and the statis-
tics compiled during training to find the set of
all triples ?f, a, p? where f is a feature associ-
ated with u, a is a semantic atom, and p is the
probability p(a | f) estimated by the training
process.
3. Order the set of triples by the value of p, with
the largest probabilities first. Call the ordered
set T .
4. Remove the highest-ranked triple ?f, a, p? from
T . Add a to R(u) iff the following conditions
are fulfilled:
? p ? pt for some pre-specified threshold
value pt.
? Addition of a to R(u) results in a set
which is consistent with the target model.
5. Repeat step (4) until T is empty.
Intuitively, the process is very simple. We just
walk down the list of possible semantic atoms, start-
ing with the most probable ones, and add them to
the semantic representation we are building up when
this does not conflict with the consistency rules in
the target model. We stop when the atoms suggested
are too improbable, that is, they have probabilies be-
low a cut-off threshold.
5 Summary and structure of demo
We have described a non-trivial spoken language di-
alogue application built using generic Open Source
tools that combine rule-based and corpus-driven
processing. We intend to demo the system with par-
ticular reference to these tools, displaying intermedi-
ate results of processing and showing how the cover-
age can be rapidly reconfigured in an example-based
fashion.
References
G. Aist, J. Dowding, B.A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astro-
naut training and support. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics (demo track), Philadelphia, PA.
D. Carter. 2000. Choosing between interpretations. In
M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and
M. Wire?n, editors, The Spoken Language Translator.
Cambridge University Press.
R.O. Duda, P.E. Hart, and H.G. Stork. 2000. Pattern
Classification. Wiley, New York.
D. Martin, A. Cheyer, and D. Moran. 1998. Building
distributed software systems with the open agent ar-
chitecture. In Proceedings of the Third International
Conference on the Practical Application of Intelligent
Agents and Multi-Agent Technology, Blackpool, Lan-
cashire, UK.
Nuance, 2003. http://www.nuance.com. As of 25 Febru-
ary 2003.
S.G. Pulman. 1992. Syntactic and semantic process-
ing. In H. Alshawi, editor, The Core Language En-
gine, pages 129?148. MIT Press, Cambridge, Mas-
sachusetts.
M. Rayner and B.A. Hockey. 2003. Transparent com-
bination of rule-based and data-driven approaches in a
speech understanding architecture. In Proceedings of
the 10th EACL, Budapest, Hungary.
M. Rayner, B.A. Hockey, and J. Dowding. 2002. Gram-
mar specialisation meets language modelling. In Pro-
ceedings of the 7th International Conference on Spo-
ken Language Processing (ICSLP), Denver, CO.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner. 1988. Applying explanation-based general-
ization to natural-language processing. In Proceedings
of the International Conference on Fifth Generation
Computer Systems, pages 1267?1274, Tokyo, Japan.
Regulus, 2003. http://sourceforge.net/projects/regulus/.
As of 24 April 2003.
J. van Eijck and R. Moore. 1992. Semantic rules for
English. In H. Alshawi, editor, The Core Language
Engine, pages 83?116. MIT Press.
T. van Harmelen and A. Bundy. 1988. Explanation-
based generalization = partial evaluation (research
note). Artificial Intelligence, 36:401?412.
D. Yarowsky. 1994. Decision lists for lexical ambiguity
resolution. In Proceedings of the 32nd Annual Meet-
ing of the Association for Computational Linguistics,
pages 88?95, Las Cruces, New Mexico.
A procedure assistant for astronauts
in a functional programming architecture,
with step previewing and spoken correction of dialogue moves
Gregory Aist
1
, Manny Rayner
1
, John Dowding
1
,
Beth Ann Hockey
1
, Susana Early
2
, and Jim Hieronymus
3
1
Research Institute for Advanced Computer Science
2
Foothill/DeAnza College
3
NASA Ames Research Center
M/S T35B-1, Moffett Field CA 94035
{aist, mrayner, jdowding, bahockey, jimh}@riacs.edu; searly@mail.arc.nasa.gov
Abstract
We present a demonstration of a proto-
type system aimed at providing support
with procedural tasks for astronauts on
board the International Space Station.
Current functionality includes navigation
within the procedure, previewing steps,
requesting a list of images or a particular
image, recording voice notes and spoken
alarms, setting parameters such as audio
volume. Dialogue capabilities include
handling spoken corrections for an entire
dialogue move, reestablishing context in
response to a user request, responding to
user barge-in, and help on demand. The
current system has been partially reim-
plemented for better efficiency and in re-
sponse to feedback from astronauts and
astronaut training personnel. Added fea-
tures include visual and spoken step pre-
viewing, and spoken correction of
dialogue moves. The intention is to intro-
duce the system into astronaut training as
a prelude to flight on board the Interna-
tional Space Station.
1 Introduction
Astronauts on board the International Space Sta-
tion engage in a wide variety of tasks on orbit in-
cluding medical procedures, extra vehicular
activity (E V A), scientific payloads, and station
repair and maintenance. These human space flight
activities require extensive and thorough proce-
dures. These procedures are written down in the
form of a number of steps and, with various notes,
cautions, and warnings interspersed throughout the
procedure. Each step may have one or more sub
steps.  Procedures also include branch points, call-
outs to other procedures, and instructions to com-
municate with mission control.  Since December
2001, the RIALIST group has been developing a
spoken dialogue system for providing assistance
with space station procedures. Aist and Hockey
(2002) and Aist et al (2002) described the first
version of the system, which operated on a simpli-
fied (and invented) procedure for unpacking and
operating a digital camera and included speech
input and speech output only. Aist et al (2003)
described a second version of the system with an
XML-based display, and that included support for
not only procedures, but also voice notes and re-
corded alarms, and parameter settings such as in-
creasing and decreasing volume. In this paper, we
describe the third version of the system, with a
reimplemented architecture based on a functional
specification of the domain-specific aspects of the
system combined with an event-driven generic ar-
chitectural framework. We also describe two new
features: previewing of steps, and spoken correc-
tion of dialogue moves.
2 System Description
The March 2003 version of the Intelligent Proce-
dure Assistant is shown in Figure 1, just after
loading a procedure. The March 2003 version pro-
vides the following functions:
Loading a procedure by specifying its name, for
example, ?Load water procedure.?
Sequential navigation through individual steps, for
example, ?Next step? or ?Previous step.?
Navigation to arbitrary steps, for example, ?Go to
step two point one.?
Setting system parameters, such as ?Increase vol-
ume? or ?Decrease volume.?
Handling annotations, such as voice notes or
alarms (?Record a voice note?), or pictures (?Show
the small waste water bag.?).
Previewing steps; for example, ?Read step three?.
Issuing spoken corrections (of entire commands),
for example, ?I meant go to step two.?
We will discuss previewing steps and issuing spo-
ken corrections in turn.
2.1 Previewing steps (Reading mode)
Besides acting on the current step, astronauts indi-
cated that they would like a spoken preview of the
next step. Currently this functionality is imple-
mented as displaying a second procedure window
in the upper right corner of the screen. Further-
more, steps are prefixed with a spoken indication
of previewing, for example, ?Reading mode. Note
before step two?? To transition back into normal
(execution) mode, the user may say ?Stop read-
ing.? Figure 2 shows the resulting display for the
reading mode.  
2.2 Issuing spoken corrections
In the March 2003 version of the Checklist system,
the user may issue a spoken correction in the case
of an incorrectly given command, or in the case of
a speech recognition error (e.g. ?read me step
three? ? ?repeat step three?). The dialogue history
is represented as a list of the prior dialogue states.
Currently we model a correction as a change in the
information state, a rollback of the previous action
plan, and then an application of the new action
plan. Figure 3 shows the display after issuing a
correction, ?I meant the wash cloth?. Reading
mode has been exited, and a picture of the wash-
cloth is displayed.
Figure 1. Loading a procedure.
Figure 2. Preview mode, step three.
Figure 3. A subsequent correction, resulting in a
return to execution mode, and the implementation
of the other command.
Figure 4. Checklist dialogue system architecture.
3  Architecture, or, How to write
a dialogue system in three easy steps
There are three main sections to the dialogue han-
dling code: the input manager, dialogue manager,
and the output manager (Figure 4). These are
similar divisions to those proposed in Allen et al
(2000). Here, we also adopt a further division of
the code into application-specific code and generic
code. Application-specific code computes the fol-
lowing function for each component, as a compila-
tion step:
Input manager: Input ? Event
Dialogue manager: (Event, State)
? (Action, State)
Output manager: Action ? (Output, Inverse)
The Output and Inverse computed by the Input
manager are the multimodal output plans and their
multimodal inverses, respectively.  The multi-
modal inverses are used when applying a correc-
tion ? in conjunction with a return to a previous
state on the history list.
The generic code is an interpretation (or execu-
tion) step; the input manager?s code collects in-
coming events and dispatches the events to the
dialogue manager. The dialogue manager?s code
collects the incoming events, retrieves the previous
state, applies the application-specific function,
saves the new state, and then dispatches the new
action. The output manager takes the action, ap-
plies the application-specific function to compute
the output and its inverse, and then dispatches the
output plan one action at a time. Each action is rep-
resented as an OAA solvable, and dispatched se-
quentially to be handled by the appropriate agent
such as the text-to-speech agent.
The entire dialogue manager is side-effectfree.
(With the minor exception of loading a procedure
file, which causes a change in the ?last accessed?
time of the file.) In a more typical dialogue system
architecture such as that shown in Figure 5, the
side effects are represented separately. The inte-
gration of side effects into the output plan has
positive benefits for robustness, since they will be
represented in one place (and thus modified at the
same time when programming changes are made).
Figure 5.  A more typical dialogue system ar-
chitecture, with the side effects executed separately
from the spoken output.
4 Related Research and Future Work
Rudnicky, Reed, and Thayer (1996) describe a
system for supporting vehicle maintenance with
speech interfaces. Schreckenghost et al (2003)
describe a scenario involving similar tasks (life
Speech
Recognizer
Parser
Input
Manager
Output
Manager
Speech
Synthesizer
Visual
Display
Dialogue
Manager
I: input ? event
D: (event, state)
? (action, state)
O: action
? (output, inverse)
Speech
Recognizer
Parser Input
Manager
Output
Manager
Speech
Synthesizer
DB
Dialogue
Manager
support / maintenance related) but with the com-
puter in more control of the actual task. S & K
Electronics (n.d.) mention a procedure develop-
ment environment for rapidly developing and veri-
fying on-orbit procedures
(http://sk-web.sk-tech.com/proj.html).
Possible future work includes adding procedures
involving inventory management and robot arm
assistance, automating dialogue system construc-
tion from XML procedures, integrating with te-
lemetry to monitor execution of the procedure and
develop error recovery options, improving natural-
ness of the speech output, modeling dialogue to
include dialogue moves and expected user re-
sponses, and improving speech recognition to be
robust to ISS noise.
References
G. Aist. J. Dowding, B. A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astronaut
training and support. Proceedings of the 40
th
 Annual
Meeting of the Association for Computational Lin-
guistics, refereed demonstration track.
G. Aist and B. A. Hockey. 2002. Generating Training
and Assistive Dialogues for Astronauts from Interna-
tional Space Station Technical Documentation. ITS
2002 Workshop on Integrating Technical and Train-
ing Documentation. Presented along with system
demonstration.
G. Aist, J. Dowding, B. A. Hockey, M. Rayner, J. Hi-
eronymus, D. Bohus, B. Boven, N. Blaylock, E.
Campana, S. Early, G. Gorrell, and S. Phan. 2003.
European Association for Computational Linguistics
(EACL) 2003 meeting, Software Demonstration, Bu-
dapest, Hungary, April 2003.
J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L.
Galescu, and A. Stent. 2000. An architecture for a
generic dialogue shell. Natural Language Engineer-
ing, Special issue on Best Practice in Spoken Lan-
guage Dialogue Systems Engineering, pp. 323-340.
A. Rudnicky, S. Reed, and E. H. Thayer. 1996.
SpeechWear: A mobile speech system.
http://www.speech.cs.cmu.edu/air/papers/speechwear.ps
D. Schreckenghost, C. Thronesbery, P. Bonasso, D.
Kortenkamp and C. Martin, Intelligent Control of
Life Support for Space Missions, in IEEE Intelligent
Systems Magazine, September/October, 2002.
Portions of the dialogue systems described in this paper
were constructed with Rayner, Hockey, and Dowding?s
Regulus open source toolkit. Interested readers may find
the toolkit and supporting documentation online at:
http://sourceforge.net/projects/regulus/.
Squibs
Fruit Carts: A Domain and Corpus for Research in
Dialogue Systems and Psycholinguistics
Gregory Aist?
Iowa State University
Ellen Campana??
Arizona State University
James Allen?
University of Rochester
Mary Swift?
University of Rochester
Michael K. Tanenhaus?
University of Rochester
We describe a novel domain, Fruit Carts, aimed at eliciting human language production for the
twin purposes of (a) dialogue system research and development and (b) psycholinguistic research.
Fruit Carts contains five tasks: choosing a cart, placing it on a map, painting the cart, rotating
the cart, and filling the cart with fruit. Fruit Carts has been used for research in psycholinguistics
and in dialogue systems. Based on these experiences, we discuss how well the Fruit Carts
domain meets four desired features: unscripted, context-constrained, controllable difficulty, and
separability into semi-independent subdialogues. We describe the domain in sufficient detail to
allow others to replicate it; researchers interested in using the corpora themselves are encouraged
to contact the authors directly.
1. Introduction and Relation to Prior Work
Dialogue system research, like much else in computational linguistics, has greatly
benefited from corpora of natural speech. With notable exceptions (e.g. the Edinburgh
Maptask, Anderson et al [1991]), these corpora consist of samples annotated with
linguistic properties (e.g. POS, syntax, discourse status) setting aside the visual and
? 206 Ross Hall, Iowa State University, Ames, Iowa 50011. E-mail: gregory.aist@alumni.cmu.edu.
?? 240c Matthews Center, Arizona State University, Tempe, Arizona 85287. E-mail: ellen.campana@asu.edu.
? 721 CSB, University of Rochester, Rochester, New York 14627. Email: james@cs.rochester.edu.
? 732 CSB, University of Rochester, Rochester, New York 14627. E-mail: swift@cs.rochester.edu.
? 420 Meliora, University of Rochester, Rochester, New York 14627. E-mail: mtan@bcs.rochester.edu.
Submission received: 24 August 2009; revised submission received: 6 May 2010; accepted for publication:
20 September 2010.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 3
pragmatic aspects of the context in which they occurred. In recent years natural lan-
guage processing (NLP) researchers have been working to incorporate visual and other
context into their models and systems (DeVault and Stone 2004; Gabsdil and Lemon
2004; Schuler, Wu, and Schwartz 2009). This is consistent with the growing evidence in
psycholinguistics that human language production crucially depends on such aspects of
context. To take this NLP research further, there is a need for more corpora that include
both variation in, and annotation of, visual and pragmatic context.
There are still many open questions that span computational linguistics and
psycholinguistics concerning how natural language and context are related. One core
question at the intersection of these areas is how the inherent difficulty of describing an
end-goal (i.e., its codability) will affect the structure and content of referring expressions
and the referential strategy speakers adopt. Referential strategies are a topic of grow-
ing interest in natural language generation. In recent work, Viethen and Dale (2006)
demonstrated that even when describing simple grid layouts, people adopt different
referential strategies, due perhaps to proximity to landmarks (and hence codability):
the orange drawer below the two yellow drawers, in contrast to the yellow drawer in the third
column from the left second from the top. For systems to produce humanlike references in
these situations, existing methods of reference generation will need to be modified or
extended to include better models of the choice of referential strategies (Viethen and
Dale 2006). Such models can also be expected to improve reference resolution: If better
predictions can be made about what people will say in a given situation, automatic
speech recognition language models can be tighter, NLP grammars can be smaller, and
unlikely parses can be avoided, improving both speed and accuracy.
Recent psycholinguistic research suggests that codability does play a role in human
reference production (e.g., Cook, Jaeger, and Tanenhaus 2009). This work has largely
focused on timing, signals of production difficulty (e.g., disfluency, gesture), and the
content of referring expressions (e.g., adjectives, pronouns). There has been much
less consideration of how entire referential strategies might systematically vary with
codability. A corpus with the correct design and structure will allow for investigation
of the more well-studied aspects as well as higher-level factors such as strategy choice,
and possible interactions between them.
With these considerations in mind, we designed a domain, Fruit Carts, and a set
of corresponding tasks in order to elicit human language production for two pur-
poses: 1) the testing of psycholinguistic hypotheses, specifically that object complexity
modulates referential strategy, and more generally the exploration of the relationship
between visual context and human?human dialogue, and 2) research and development
of dialogue systems that understand language as it unfolds, taking pragmatic factors
into account early in the recognition process. By designing with both fields in mind
we hope to strengthen the long tradition of cross-fertilization between the disciplines
(e.g., Brennan 1991), particularly for task- or game-oriented systems and domains, with
a visual component.
We identified four important features to build into the domain. First, the language
produced should be completely unscripted: Participants should be able to perform the
task with a general description of what to do (e.g., Give instructions on how to make the
map on the screen look like the map in your hand) and zero prior examples of what to
say. For psycholinguistics, this makes the language natural speech rather than speech
that is restricted by the instructions or by prior examples. For dialogue systems, this
makes the language ?untrained? rather than the result of careful training, meaning that
systems will be processing language that is representative of what speakers are likely
to produce when they use the system, especially without extensive training. Second,
470
Aist et al Fruit Carts Domain and Corpus
the language should be fairly well constrained by context. For psycholinguistics, this
makes the language more straightforward to analyze and also more directly tied to the
visual context and thus amenable to ?visual world? studies that use eye movements to
examine real-time production (Griffin and Bock 2000) and comprehension (Tanenhaus
et al 1995). For dialogue systems, this makes the language more amenable to automatic
processing and also facilitates the integration of different types of knowledge into the
recognition process. Third, it should be possible to vary the difficulty of the tasks. For
psycholinguistics, this makes hypotheses about the effect of task difficulty on language
production amenable to study. For dialogue systems, this allows the resulting corpora
to have a combination of relatively easy tasks (?low-hanging fruit?) and more difficult
NLP challenges. Fourth, the domain should support the collection of dialogues that are
separable into partially or semi-independent subdialogues, with limited need for ref-
erence to previous subdialogues. For psycholinguistics, this makes each subdialogue a
separate trial, allowing for analyses where trials are treated as random effects in mixed-
effect regression models or repeated measures in ANOVAs. For dialogue systems, this
limits the likelihood that errors in processing one subdialogue will spill over and
affect processing of subsequent subdialogues. For both research areas, this separability
constraint enables within-subject experiments with each subdialogue as a trial.
In purpose and approach, Fruit Carts is most similar to the Map Task (Anderson
et al 1991); both are simultaneously a set of experiments on language and a corpus
used for developing language processing systems. Map Task dialogues ?are unscripted
[but] the corpus as a whole comprises a large, carefully controlled elicitation exercise?
(Anderson et al 1991, page 352) that has been used inmany computational endeavors as
well. Fruit Carts was guided by our twin goals of furthering the development of spoken
language systems, and providing a psycholinguistic test bed in which to test specific
hypotheses about human language production. Fruit Carts differs from Map Task in
terms of dynamic object properties and in terms of the information available to the
speaker and hearer. In the Map Task, objects have fixed properties that differ between
giver and follower, yet remain constant while the path is constructed. In Fruit Carts,
objects have properties that can be changed: position, angle, and color. This allows for
a wide variety of linguistic behavior which in turn supports detailed exploration of
continuous understanding by humans and machines. In the Map Task, the participants?
screens differ, whereas in Fruit Carts the speaker and hearer share the same visual
context, which simplifies the analysis and interpretation of results (Figure 1).
2. Fruit Carts Domain and Tasks
The Fruit Carts domain has three screen areas: amap, an object bin, and a controls panel.
Each area was designed in part to elicit the types of expressions that require continuous
understanding to approximate human behavior such as progressive restriction of a
reference set throughout the utterance.
The map contains named regions divided by solid lines, with three flags as land-
marks. The region names did not appear on the screen, to preclude use of spelling in
referring expressions (the C in Central Park). Names were chosen to be phonetically
distinct. To support progressive restriction of potential regions, regions whose initial
portions overlap are adjacent (Morn identifies Morningside and Morningside Heights)
and some regions have flags and others not (put the square on the flag in... identifies
the regions with flags.) No compass is displayed, in an attempt to limit the directions
elicited to up, down, left, and right and not north, south, and so on.
471
Computational Linguistics Volume 38, Number 3
Figure 1
Example initial and final configurations for Fruit Carts domain and corpus. The region names
were available to both director and actor (on paper) but were not shown on screen. The final
configuration shown is the actual screen after the five dialogues from the participant whose
third, fourth, and fifth dialogues are shown in Appendix A.
The object bin contains fruits and carts, by analogy with food vendor carts (e.g., hot
dog stands). The fruits are avocados, bananas, cucumbers, grapefruits, and tomatoes,
all botanically fruits. We chose fruits because they were nameable, especially with a
label, and visually different from the carts. The carts are either squares or triangles,
in two sizes, with an optional tag that for squares is either a diamond or a heart and
for triangles is either a star or a circle. Adjectives (e.g., large, small) are commonly
used in natural language descriptions and there is a growing body of psycholinguistic
research, mostly with scripted utterances, that has used adjectives to investigate real-
time language processing (Sedivy et al 1999; Brown-Schmidt, Campana, and Tanenhaus
2005). Here, to support progressive restriction of potential carts, each component is easy
to name but the entire shape requires a complex description rather than a prenominal
modifier?or at least strongly prefers one, as no examples to the contrary were observed
in the Fruit Carts corpus described later in this article. That is, whereas a square with
stripes could be either the square with stripes or the striped square, a square with a diamond
on the corner is the square with a diamond on the corner but not *the corner-diamonded square.
The controls panel contains left and right rotation arrows and six paint colors (black,
brown, orange, blue, pink, and purple) chosen to be distinct from the colors of the fruit.
Five tasks are included in Fruit Carts, all performed by using a mouse. To CHOOSE
a cart, the user clicks on it. To PLACE it on the map, the user drags it there. To PAINT
the cart, the user clicks on the desired color. Painting is a uniformly easy control task.
To ROTATE the cart, the user presses and holds down the left or right rotation button.
472
Aist et al Fruit Carts Domain and Corpus
The goal of the rotation tool was to allow arbitrary rotations and to elicit utterances
that were in response to visual feedback, such as rotate it a little to the right, more, stop.
Finally, to FILL the cart, the user drags fruit to it.
3. Fruit Carts Corpus
For the dual goals of gathering a corpus of utterances for dialogue system research, and
testing the hypothesis that object complexity modulates referential strategy in human
language production, we designed a set of goal maps that systematically manipulated:
POSITION. Each cart was in a high-codability ?easy? position, such as centered on a flag
or in a region; or a low-codability ?hard? position, such as off-center.
HEADING. Each cart was at an ?easy? angle, an integer multiple of 45 degrees from its
original orientation; or a ?hard? angle, a non-multiple of 45 degrees.
CONTENTS. Each cart contained an ?easy? set of objects, fruit of the same type, such as
three tomatoes; or a ?hard? set of objects, such as two bananas and a grapefruit.
COLOR. Each cart was painted a uniformly ?easy? color to provide a control condition.
One person (the director) gave directions to the other (the actor) on how to carry
out the task. The director wore a headset microphone that collected speech data; the
actor in this set-up wore a head-mounted eye-tracker that collected eye movements.
The director (a subject) sat just behind the actor (a confederate); both viewed the same
screen. Twelve subjects participated, each of whom specified twenty objects to place on
the map; thus, a total of 240 dialogues were collected. The recordings were transcribed
word-for-word by a professional transcription service that also provided sentence
boundaries. The corpus has been labeled for referential strategy at the utterance level
(Aist et al 2005) and subsequently with referring expressions, spatial relations, and
actions in order to support word-by-word incremental interpretation (Gallo et al 2007);
see Appendix A.
4. Analysis with Respect to Desired Features
How well does the Fruit Carts domain meet the desired features described earlier?
1. Unscripted. Subjects were generally able to complete the task with only the instruc-
tions to make the screen match their paper map, and no prior examples of what to say,
although one subject systematically did not issue instructions to paint the shapes.
2. Constrained. Generally speaking, subjects used the language we expected, such as
square, triangle, and so forth, or high-frequency synonyms such as box for a square cart
(from the first dialogue of the participant in Appendix A, omitted for space) or dot for
a circle tag (Appendix A, [D3]). There were examples of participants using unexpected
expressions, such as calling an avocado a lime, despite the on-screen label. Yet overall
the language was well constrained by the context.
3. Support for varying of task difficulty. As the Fruit Carts corpus showed, location,
heading, and contents of carts can be systematically varied; later corpora, outside
the scope of this article, have varied the number of carts placed together in order to
construct simple or compound objects, in order to test the hypothesis that higher-level
473
Computational Linguistics Volume 38, Number 3
task and goal knowledge (e.g. a tower is being built from several blocks) modulates
language production, and to support further dialogue system research.
4. Support for collection of semi-independent subdialogues. Here the Fruit Carts
domain excels. Due to the presence of multiple separate objects and regions, different
subdialogues can make use of different objects, regions, properties, and so forth. By
contrast, a domain revolving around construction of a single complex target, such as a
landscaping plan, would have licensed substantial amounts of reference to previously
placed objects including objects not in place at the time the dialogue began?making
subdialogues dependent on each other in terms of accuracy, correctness, and so forth.
As Appendix A illustrates, these Fruit Carts data contain relatively few such references.
This is analogous to the difference between a math exercise set that contains several
independent exercises, and a set where each exercise builds on previous answers.
5. Use in Research
For dialogue systems research, the Fruit Carts domain has already been useful in de-
veloping dialogue systems that understand language continuously while taking prag-
matics into account. For example, using Fruit Carts, incorporating pragmatic feedback
about the visual world early in the parsing process was shown to substantially improve
parsing efficiency as well as allowing parsing decisions to accurately reflect the visual
world (Aist et al 2006). Also using Fruit Carts, a dialogue system using continuous
understanding was shown to be faster than, and preferred to, a counterpart that used a
traditional pipeline architecture but was otherwise identical (Aist et al 2007).
For psycholinguistic research, Fruit Carts has also been used for studying the
relationship between bi-clausal structure and theme complexity (Gallo et al 2008) and
testing hypotheses regarding the relationship of information in a message, resource
limitations, and sentence production (Gallo, Jaeger, and Smyth 2008).
6. Discussion and Conclusions
Fruit Carts also has a number of other advantages as well as some limitations.
First, Fruit Carts provides ample temporary or local ambiguity in its utterances, a
central challenge for continuous understanding systems and a classic target of research
in psycholinguistics (for a review see Altmann [1998]). In a typical sequence such as okay
take a ... small triangle with a dot on the corner (Appendix A, [D3]), most of the content
words and some of the function words serve to resolve local ambiguity:
okay take... ? uniquely identifies an action
...a ... small... ? restricts (partially disambiguates) referential domain to half of the shapes
...triangle... ? further restricts the referential domain to the triangles
...with... ? further restricts the referential domain to carts with tags
...a dot... ? further restricts the referential domain to carts with circles
...on the corner ? uniquely identifes one of the twenty carts
Likewise, flag in right ... um ... side of the uh ... flag in pine tree mountain [D5] restricts
regions to flagged regions.
474
Aist et al Fruit Carts Domain and Corpus
Second, Fruit Carts also elicits substantial variation in referential strategy. Some
utterances could be grounded independent of context, up to pronominal reference. For
example, the hypothetical utterance Move a large plain square to the flag in Central Park
has a fully specified action, object, and goal, as do rotate it about 45 degrees (Appendix A,
[D4]), and and um make that orange [D5]. We labeled this category ?all-at-once.? For
other utterances, grounding relied on the surrounding context?dialogue and/or task.
For example, um a little to the left [D4] contains a direction (left) but might rely on the
last action to identify the intended action as rotation or movement, and on the selected
shape on the screen to identify the object. We labeled this category ?continuous.?
Some utterances exhibited ?both? all-at-once and continuous properties, or properties
of ?neither? category. The continuous utterances contained 21% fewer words (mean,
8.72 vs. 6.85) than the all-at-once and contained shorter words, too (mean, 3.95 letters
vs. 3.74). About one-third of the utterances were labeled as ?continuous?; speakers
produced more continuous utterances as task experience increased (Aist et al 2005).
Finally, Fruit Carts is relatively abstract: The carts are basic shapes such as squares
and triangles, and the fruit are chosen for language research purposes. On the one hand,
this is desirable because it reduces the possibility of confounding effects from prior
knowledge. On the other hand, it would be interesting for future work to extend Fruit
Carts-style domains to more realistic object construction and placement tasks.
Appendix A: Example Dialogues
Referential strategy. These dialogues [D3]?[D5] are the third, fourth, and fifth dia-
logues from one subject, screen one. For conciseness, ?...? concatenates some adjacent
utterances. All-at-once sections are marked in bold and continuous sections in italics.
[D3] okay take a ... small triangle with a dot on the corner
and ... um ... put it ... it should be in um ... kinda the uh ... center right side of morningside
heights
uh morningside heights ... oh ... um a little further in ... uh ... towards the um oh wait a little back
sorry ... uh that?s good
and then rotate it to the right until the l- hypotenuse is str- fa- yeah like that <laughter>
and then make that blue
and put a uh grapefruit in it so that
it ... it?s touching the left side but sticking out of the top
oh it should be inside the triangle and touching
um a little ... over ... or down and over a little bit ... uh yeah that?s good
um <breath> ... now ... uh
[D4] take a square ... and put it in um ... oceanview terrace
and pretty much in the center
um i don?t know which one it i- i guess the s- try the smaller one
um and then uh
rotate it about 45 degrees
um ... oh ... like one more turn ... yeah
um and make that ... pink
475
Computational Linguistics Volume 38, Number 3
and then put a uh tomato ... in the ... um a little to the left ...okay
good ... um ... it ... i?m not sure if it should be a bigger one that triangle or not
um you can try the bigger triangle ... i mean not the bigger triangle the bigger square ... i think
maybe it should be the ... yeah i think it should be the bigger square
<mumble> ... put the yeah right there
[D5] and then um ... and put ... um <breath> ... <mumble> ... then put uh get a uh ...
<mumble>
take the uh large triangle with the star
and um ... put that ... um to the ... right ... um ... side of the uh ... flag in pine tree mountain
er the right side
and ... <laughter> um down a little
um ... then rotate it so that ... the ... the hypotenuse is ... almost ... horizontal but ... tilted a
little sli- like one more rotat- yeah
and um make that orange
um maybe a little closer to the flag
and down ... yeah that should be good
kay um and then put a uh tomato in the right ... er in the left corner and then a cucumber in
the right corner of it
um ... the tomato should be a l- er um ... not ... quite ... in the corner th- yeah that?s good and the
cucumber should be a little down
a little more yeah um oh wait that?s a little too much ... uh that sh- um that?s good
okay ... that?s it <laughter> ... <laughter>
oh you wanna see this ... <laughter>
i think that?s good ... okay <laughter>
Incremental disambiguation. This example, adapted fromGallo et al (2007), shows
annotation to support disambiguation, here, in the small box in Morningside. These
are word-level annotations in the smallest possible semantic units, marked at the
point of disambiguation with no lookahead, and following the speaker?s intentions
(Gallo et al 2007).
the
anchor(A1)
definite(A1)
small
size(A1, small)
box
objectType(A1, square)
in
anchor(A2)
spatialRelation(A2, inside)
location(A1, A2)
476
Aist et al Fruit Carts Domain and Corpus
Morningside
anchor(A3)
name(A3)
objectReferent(A3, MorningsideRegion3)
ground(A2, A3)
Message structure. The following example, adapted from Gallo et al (2008), shows
annotation for the purpose of exploring the link between message structure and
complexity of the theme.
original: take a square with a ... square with a heart on the corner
clean: take a square with a heart on the corner
action: SELECT
verb: take
theme: a square with a heart on the corner
theme disfluency: Yes
theme pause: Yes
Acknowledgments
This material is based upon work supported
by the National Science Foundation under
grant 0328810. Any opinions, findings, and
conclusions or recommendations expressed
in this material are those of the author(s)
and do not necessarily reflect the views
of the National Science Foundation. This
publication was partially supported by
grant HD 27206 from the NIH. The contents
of this report are solely the responsibility
of the authors and do not necessarily
represent the official views of the NIH.
References
Aist, G. S., J. Allen, E. Campana,
L. Galescu, C. Go?mez Gallo, S. Stoness,
M. Swift, and M. K. Tanenhaus. 2006.
Software architectures for incremental
understanding of human speech.
In Proceedings of the 9th International
Conference on Spoken Language Processing,
pages 1922?1925, Pittsburgh, PA.
Aist, G. S., J. Allen, E. Campana,
C. Go?mez Gallo, S. Stoness, M. Swift,
and M. K. Tanenhaus. 2007. Incremental
dialogue system faster than and preferred
to its nonincremental counterpart.
In Proceedings of the 29th Annual
Meeting of the Cognitive Science Society,
pages 761?766, Nashville, TN.
Aist, G. S., E. Campana, J. Allen, M. Rotondo,
M. Swift, and M. K. Tanenhaus. 2005.
Variations along the contextual continuum
in task-oriented speech. In Proceedings of
the 27th Annual Meeting of the Cognitive
Science Society, pages 79?84, Stresa.
Altmann, G. T. M. 1998. Ambiguity in
sentence processing. Trends in Cognitive
Sciences, 2(4):146?152.
Anderson, A., M. Bader, E. Bard, E. Boyle,
G. M. Doherty, G. M. Garrod, S. Isard,
J. Kowtko, J. McAllister, J. Miller, C. Sotillo,
H. S. Thompson, and R. Weinert. 1991.
The HCRC map task corpus. Language
and Speech, 34:351?366.
Brennan, S. E. 1991. Conversation with and
through computers. User Modeling and
User-Adapted Interaction, 1:67?86.
Brown-Schmidt, S., E. Campana, and
M. K. Tanenhaus. 2005. Real-time
reference resolution in a referential
communication task. In J. C. Trueswell
and M. K. Tanenhaus, editors, Processing
World-situated Language: Bridging the
Language-as-action and Language-as-product
Traditions. MIT Press, Cambridge, MA,
pages 153?171.
Cook, S. W., T. F. Jaeger, andM. K. Tanenhaus.
2009. Producing less preferred structures:
More gestures, less fluency. In Proceedings
of the 31st Annual Meeting of the Cognitive
Science Society, pages 62?67, Amsterdam.
DeVault, D. and M. Stone. 2004. Interpreting
vague utterances in context. In Proceedings
of COLING, pages 1247?1253, Geneva.
Gabsdil, M. and O. Lemon. 2004. Combining
acoustic and pragmatic features to predict
477
Computational Linguistics Volume 38, Number 3
recognition performance in spoken
dialogue systems. In Proceedings of the
42nd Annual Meeting of the Association of
Computational Linguistics, pages 79?84,
Barcelona.
Gallo, C. Go?mez, G. Aist, J. Allen,
W. de Beaumont, S. Coria,
W. Gegg-Harrison, J. Paulo Pardal, and
M. Swift. 2007. Annotating continuous
understanding in a multimodal dialogue
corpus. In Proceedings of the 2007 Workshop
on the Semantics and Pragmatics of Dialogue,
pages 75?82, Rovereto.
Gallo, C. Go?mez, T. F. Jaeger, J. Allen, and
M. Swift. 2008. Production in a multimodal
corpus: How speakers communicate
complex actions. In Proceedings of the
Language Resources and Evaluation
Conference, pages 2917?2920, Marrakech.
Gallo, C. Go?mez, T. F. Jaeger, and R. Smyth.
2008. Incremental syntactic planning
across clauses. In Proceedings of the 30th
Annual Meeting of the Cognitive Science
Society, pages 845?850, Washington, DC.
Griffin, Z. M. and K. Bock. 2000. What the
eyes say about speaking. Psychological
Science, 11:274?279.
Schuler, W., S. Wu, and Lane Schwartz.
2009. A framework for fast incremental
interpretation during speech decoding.
Computational Linguistics, 35(3):313?343.
Sedivy, J. E., M. K. Tanenhaus, C. G.
Chambers, and G. N. Carlson. 1999.
Achieving incremental interpretation
through contextual representation:
Evidence from the processing of
adjectives. Cognition, 71:109?147.
Tanenhaus, M. K., M. J. Spivey-Knowlton,
K. M. Eberhard, and J. E. Sedivy. 1995.
Integration of visual and linguistic
information in spoken language
comprehension. Science, 268:1632?1634.
Viethen, J. and R. Dale. 2006. Algorithms
for generating referring expressions:
Do they do what people do? In Proceedings
of the 4th International Conference on
Natural Language Generation, pages 63?70,
Sydney.
478
