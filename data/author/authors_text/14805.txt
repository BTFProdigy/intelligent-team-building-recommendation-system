Finite-State Chart Constraints for Reduced
Complexity Context-Free Parsing Pipelines
Brian Roark?
Oregon Health & Science University
Kristy Hollingshead??
University of Maryland
Nathan Bodenstab?
Oregon Health & Science University
We present methods for reducing the worst-case and typical-case complexity of a context-free
parsing pipeline via hard constraints derived from finite-state pre-processing. We perform O(n)
predictions to determine if each word in the input sentence may begin or end a multi-word
constituent in chart cells spanning two or more words, or allow single-word constituents in
chart cells spanning the word itself. These pre-processing constraints prune the search space
for any chart-based parsing algorithm and significantly decrease decoding time. In many cases
cell population is reduced to zero, which we term chart cell ?closing.? We present methods for
closing a sufficient number of chart cells to ensure provably quadratic or even linear worst-case
complexity of context-free inference. In addition, we apply high precision constraints to achieve
large typical-case speedups and combine both high precision and worst-case bound constraints
to achieve superior performance on both short and long strings. These bounds on processing
are achieved without reducing the parsing accuracy, and in some cases accuracy improves.
We demonstrate that our method generalizes across multiple grammars and is complementary
to other pruning techniques by presenting empirical results for both exact and approximate
inference using the exhaustive CKY algorithm, the Charniak parser, and the Berkeley parser. We
also report results parsing Chinese, where we achieve the best reported results for an individual
model on the commonly reported data set.
1. Introduction
Although there have been great advances in the statistical modeling of hierarchical
syntactic structure over the past 15 years, exact inference with suchmodels remains very
costly andmost rich syntactic modeling approaches resort to heavy pruning, pipelining,
? Center for Spoken Language Understanding, Oregon Health & Science University, Beaverton, Oregon,
97006 USA. E-mails: roarkbr@gmail.com, bodenstab@gmail.com.
?? Some of the work in this paper was done while Kristy Hollingshead was at OHSU. She is currently at the
University of Maryland Institute for Advanced Computer Studies, College Park, Maryland, 20740 USA.
E-mail: hollingk@gmail.com.
Submission received: 9 August 2011; revised submission received: 30 November 2011; accepted for
publication: 4 January 2012.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 4
or both. Pipeline systems make use of simpler models with more efficient inference to
reduce the search space of the full model. For example, the well-known Ratnaparkhi
(1999) parser used a part-of-speech (POS)-tagger and a finite-state noun phrase (NP)
chunker as initial stages of a multi-stageMaximum Entropy parser. The Charniak (2000)
parser uses a simple probalistic context-free grammar (PCFG) to sparsely populate a
chart for a richer model, and Charniak and Johnson (2005) added a discriminatively
trained reranker to the end of that pipeline.
Finite-state pre-processing for context-free parsing is very common as a means
of reducing the amount of search required in the later stage. As mentioned earlier,
the Ratnaparkhi pipeline used a finite-state POS-tagger and a finite-state NP-chunker
to reduce the search space at the parsing stage, and achieved linear observed-time
performance. Other recent examples of the utility of finite-state constraints for parsing
pipelines include Glaysher and Moldovan (2006), Djordjevic, Curran, and Clark (2007),
and Hollingshead and Roark (2007). Similar hard constraints have been applied for
dependency parsing, as will be outlined in Section 2. Note that by making use of pre-
processing constraints, such approaches are no longer performing full exact inference?
these are approximate inference methods, as are the methods presented in this article.
Using finite-state chunkers early in a syntactic parsing pipeline has shown both an
efficiency (Glaysher and Moldovan 2006) and an accuracy (Hollingshead and Roark
2007) benefit for parsing systems. Glaysher and Moldovan (2006) demonstrated an
efficiency gain by explicitly disallowing constituents that cross chunk boundaries.
Hollingshead and Roark (2007) demonstrated that high-precision constraints on
early stages of the Charniak and Johnson (2005) pipeline (in the form of base phrase
constraints derived either from a chunker or from later stages of an earlier iteration
of the same pipeline) achieved significant accuracy improvements, by moving the
pipeline search away from unlikely areas of the search space. All of these approaches
(as with Ratnaparkhi earlier) achieve improvements by ruling out parts of the search
space, and the gain can either be realized in efficiency (same accuracy, less time) and/or
accuracy (same time, greater accuracy).
Rather than extracting constraints from taggers or chunkers built for different
purposes, in this study we have trained prediction models to more directly reduce the
number of entries stored in cells of a dynamic programming chart during parsing?even
to the point of ?closing? chart cells to all entries. We demonstrate results using three
finite-state taggers that assign each word position in the sequence with a binary class
label. The first tagger decides if the word can begin a constituent of span greater than
one word; the second tagger decides if the word can end a constituent of span greater
than oneword; and the third tagger decides if a chart cell spanning a single word should
contain phrase-level non-terminals, or only POS tags. Following the prediction of each
word, chart cells spanning multiple words can be completely closed as follows: Given a
chart cell (b, e) spanning words wb . . .we where b < e, we can ?close? cell (b, e) if the first
tagger decides that wb cannot be the first word of a multi-word constituent (MWC) or if
the second tagger decides thatwe cannot be the last word in aMWC. Completely closing
sufficient chart cells allows us to impose worst-case complexity bounds on the overall
pipeline, a bound that none of the other previously mentioned methods for finite-state
preprocessing can guarantee.
To complement closing multi-word constituent chart cells, our third tagger restricts
the population of span-1 chart cells. We note that all span-1 chart cells must contain
at least one POS tag and can therefore never be closed completely. Instead, our tagger
restricts unary productions with POS tags on their right-hand side that span a single
word. We term these single word constituents (SWCs). Disallowing SWCs alters span-1
720
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
cell population from potentially containing all non-terminals to just POS non-terminals.
In practice, this decreases the number of entries in span-1 chart cells by 70% during ex-
haustive parsing, significantly reducing the number of allowable constituents in larger
spans (Bodenstab, Hollingshead, and Roark 2011). Span-1 chart cells are also the most
frequently queried cells in the Cocke-Younger-Kasami (CKY) algorithm. The search over
possible midpoints will always include two cells spanning a single word?one as the
first left child and one as the last right child. It is therefore beneficial to minimize the
number of entries in these span-1 cells.
The pre-processing framework we have outlined is straightforward to incorporate
into most existing context-free constituent parsers, a task we have already done for sev-
eral state-of-the art parsers. In the following sections we formally define our approach
to finite-state chart constraints and analyze the accuracy of each of the three taggers
and their impact on parsing efficiency and accuracy when used to prune the search
space of a constituent parser. We apply our methods to exhaustive CYK parsing with
simple grammars, as well as to high-accuracy parsing approaches such as the Charniak
and Johnson (2005) parsing pipeline and the Berkeley parser (Petrov and Klein 2007a,
2007b). Various methods for applying finite-state chart constraints are investigated,
including methods that guarantee quadratic or linear complexity of the context-free
parser.
2. Related Work
Hard constraints are ubiquitous within parsing pipelines. One of the most basic and
standard techniques is the use of a POS-tag dictionary, whereby words are only allowed
to be assigned one of a subset of the POS-tag vocabulary, often based on what has been
observed in the training data. This will overly constrain polysemous word types that
happen not to have been observedwith one of their possible tags; yet the large efficiency
gain of so restricting the tags is typically seen as outweighing the loss in coverage. POS-
tag preprocessing has been used for both context-free constituent parsing (Ratnaparkhi
1999) and dependency parsing (McDonald et al 2005). Richer tag sets can also be used
to further constrain the parser, such as supertags (Bangalore and Joshi 1999), which
contain information about how the word will syntactically integrate with other words
in the sequence. Supertagging has been widely used to make parsing algorithms effi-
cient, particularly those making use of context-sensitive grammars (Clark and Curran
2004).
By applying finite-state chart constraints to constituent parsing, the approaches
pursued in this article constrain the possible shapes of unlabeled trees, eliminating from
consideration trees with constituents over specific spans. There is thus some similarity
with other tagging approaches (e.g., supertagging) that dictate how words combine
with the rest of the sentence via specific syntactic structures. Supertagging is generally
used to enumerate which sorts of structures are licensed, whereas the constraints in
this article indicate unlabeled tree structures that are proscribed. Along the same lines,
there is a very general similarity with coarse-to-fine search methods, such as those
used in the Berkeley (Petrov and Klein 2007a) and Charniak (2000) parsers, and more
general structured prediction cascades (Weiss, Sapp, and Taskar 2010; Weiss and Taskar
2010). Our approach also uses simpler models that reduce the search space for larger
downstream models.
Dependency parsing involves constructing a graph of head/dependent relations,
andmanymethods for constraining the space of possible dependency graphs have been
721
Computational Linguistics Volume 38, Number 4
investigated, such as requiring that each word have a single head or that the graph be
acyclic. Nivre (2006) investigated the impact of such constraints on coverage and the
number of candidate edges in the search space. Most interestingly, that paper found
that constraining the degree of non-projectivity that is allowed can greatly reduce the
number of arcs that must be considered during search, and, as long as some degree
of non-projectivity is allowed, coverage is minimally impacted. Of course, the total
absence of projectivity constraints allows for the use of spanning tree algorithms that
can be quadratic complexity for certain classes of statistical models (McDonald et al
2005), so the ultimate utility of such constraints varies depending on the model being
used.
Other hard constraints have been applied to dependency parsing, including con-
straints on the maximum length of dependencies (Eisner and Smith 2005; Dreyer, Smith,
and Smith 2006), which is known as vine parsing. Such vine parsers can be further
constrained using taggers to determine the directionality and distance of each word?s
head in a way similar to our use of taggers (Sogaard and Kuhn 2009). More general arc
filtering approaches, using a variety of features (including some inspired by previously
published results of methods presented in this article) have been proposed to reduce
the number of arcs considered for the dependency graph (Bergsma and Cherry 2010;
Cherry and Bergsma 2011), resulting in large parsing speedups.
In a context-free constituent parsing pipeline, constraints on the final parse struc-
ture can be made in stages preceding the CYK algorithm. For example, base phrase
chunking (Hollingshead and Roark 2007) involves identifying a span as a base phrase
of some category, often NP. A base phrase constituent has no children other than
pre-terminal POS-tags, which all have a single terminal child (i.e., there is no in-
ternal structure in the base phrase involving non-POS non-terminals). This has a
number of implications for the context-free parser. First, there is no need to build
internal structure within the identified base phrase constituent. Second, constituents
that cross brackets with the base phrase cannot be part of the final tree structure.
This second constraint on possible trees can be thought of as a constraint on chart
cells, as pointed out in Glaysher and Moldovan (2006): No multi-word constituent
can begin at a word falling within a base-phrase chunk, other than the first word
of that chunk. Similarly, no multi-word constituent can end at a word falling within
a base-phrase chunk, other than the last word of that chunk. These constraints rule
out many possible structures that the full context-free parser would have otherwise
considered.
These begin and end constraints can be extracted from the output of the chunker,
but the chunker is most often trained to optimize chunking accuracy, not parsing
accuracy (or parsing precision). Further, these constraints can apply even for words
that fall outside of typical chunks. For example, in English, verbs and prepositions tend
to occur before their arguments, hence are often unlikely to end constituents, yet verbs
and prepositions are rarely inside a typically defined base phrase. Instead of imposing
parsing constraints from NLP pre-processing steps such as chunking, we propose that
building specific prediction models to constrain the search space within the CYK chart
will more directly optimize efficiency within a parsing pipeline.
In this article, we focus on linear complexity finite-state methods for deriving
constraints on the chart. Recent work has also examined methods for constraining each
of theO(N2) chart cell independently (Bodenstab et al 2011), permitting a finer-grained
pruning (e.g., not just ?open? or ?closed? but an actual beam width prediction) and the
use of features beyond the scope of our tagger. We discuss this and other extensions of
the current methods in our concluding remarks.
722
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
3. Preliminaries
3.1 Dynamic Programming Chart
Dynamic programming for context-free inference generally makes use of a chart struc-
ture, as shown in Figure 1c for the left-binarized gold parse tree in Figure 1b. Each cell
in the chart represents a collection of possible constituents covering a substring, which
is identified by the indices of the first and last words of the substring. Let w1 . . .wn be
a string of n words to be parsed. The cell identified with (b, e) will contain possible
constituents spanning the substring wb . . .we, where the span of a constituent or a chart
cell is defined as the number of words it covers, or e? b+ 1. As an example, in this
Figure 1
Gold parse tree (a), left-binarized representation of the same tree (b), and corresponding
dynamic programming chart (c) for the sentence As usual, the real-estate market had overreacted.
(sentence 1094 in WSJ Section 24). Each cell in the chart spans a unique substring of the input
sentence. Non-terminals preceded with the symbol ?@? are created through binarization
(see Section 3.3).
723
Computational Linguistics Volume 38, Number 4
article we will occasionally refer to span-1 chart cells, meaning all chart cells covering a
single word.
Context-free inference using dynamic programming over a chart structure builds
longer-span constituents by combining smaller span constituents, guided by rules in a
context-free grammar. A context-free grammar G = (V,T,S?,P) consists of: a set of non-
terminal symbols V, including a special start symbol S?; a set of terminal symbols T;
and a set of rule productions P of the form A ? ? for A ? V and ? ? (V ? T)?, i.e., a
single non-terminal on the left-hand side of the rule production, and a sequence of 0 or
more terminals or non-terminals on the right-hand side of the rule. If we have a rule
production A ? B C ? P, a completed B entry in chart cell (b,m) and a completed C
entry in chart cell (m+1, e), we can place a completed A entry in chart cell (b, e). Such
a chart cell entry is sometimes called an ?edge? and can be represented by the tuple
(A ? B C, b,m, e).
Context-free inference has cubic complexity in the length of the string N, due to the
O(N2) number of chart cells and O(N) possible child configurations at each cell. As an
example, a cell spanning (b, e) must consider all possible configurations of two child
constituents (child cells) that span a proper prefix (b, m) and a proper suffix (m+1, e)
where b ? m < e, leading to O(N) possible midpoints.
3.2 The CYK Algorithm
Algorithm 1 contains pseudocode for the CYK algorithm (Kasami 1965; Younger 1967;
Cocke and Schwartz 1970), where the context-free grammar G is assumed to be bina-
rized. The function ? maps each grammar production in P to a probability. Lines 1?3
Algorithm 1 CYK
Pseudocode of the CYK algorithm using a binarized PCFG. Unary processing is sim-
plified to allow only chains of length one (excluding lexical unary productions). Back-
pointer storage is omitted.
Input:
w1 . . .wn: Input sentence
G: Left-binarized PCFG
Output:
?: Viterbi-max score for all non-terminals over every span
CYK(w1 . . .wn, G = (V,T,S
?,P,?))
1: for s = 1 to n do  Span width: bottom-up traversal
2: for b = 1 to n? s+ 1 do  Begin word position
3: e ? b+s?1
4: for Ai ? V do
5: if s = 1 then  Add lexical productions
6: ?i(b, e)? ?(Ai ? wb)
7: else
8: ?i(b, e)? max
b?m<e
(
max
j,k
?(Ai ? Aj Ak) ?j(b,m) ?k(m+ 1, e)
)
9: for Ai ? V do  Add unary productions
10: ?i(b, e)? max
(
?i(b, e) , max
j
?(Ai ? Aj) ?j(b, e)
)
11: ?(b, e)? ?(b, e)
12: return ?
724
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
iterate over all O(N2) chart cells in a bottom?up traversal. Line 6 initializes span-1 cells
with all possible part-of-speech tags, and line 8 introduces the cubic complexity of the
algorithm: maximization over all midpoints m, which is O(N). The variable ? stores the
Viterbi-max score for each non-terminalAi ? V at each cell (b, e), representing the span?s
most probable derivation rooted in Ai. Backpointers indicating which argument(s)
maximize each ?i(b, e) can be optionally recorded to efficiently extract the maximum
likelihood solution at the end of inference, but we omit these for clarity; they are easily
recoverable by storing the argmax for each max in lines 8 and 10.
We have also included pseudocode in Algorithm 1 to process unary productions in
lines 9 and 10. Unary processing is a necessary step to recover the gold-standard trees of
the Penn treebanks (Marcus, Marcinkiewicz, and Santorini 1993; Xue et al 2005), but is
often ignored in the presentation of the CYK algorithm. Because there is little discussion
about unary processing in the literature, implementation details often differ from parser
to parser. In Algorithm 1 we present a simplified version of unary processing that only
allows unary chains of length 1 per span (excluding lexical productions). This approach
is efficient and can be iterated as needed to represent the length of observed unary
chain in the treebank. Note that line 10 uses the temporary variable ? to store the
accumulated Viterbi-max scores ?. This temporary variable is necessary due to the
iterative nature in which we update ?. If we were to write the result of line 10 directly to
?i(b, e), then the subsequent maximization of ?i+1(b, e) would use an unstable version of
?, some of which would already be updated with unary productions, and some which
would not.
3.3 Incomplete Edges: Chomsky Normal Form and Dotted-Rules
A key feature to the efficiency of the CYK algorithm is that all productions in the
grammar G are assumed to have no more than two right-hand-side children. Rather
than trying to combine an arbitrary number of smaller substrings (child cells), the CYK
algorithm exploits shared structure between rules and only needs to consider pairwise
combination. To conform to this requirement, incomplete edges are needed to represent
that further combination is required to achieve a complete edge. This can either be
performed in advance, for example, by transforming a grammar into Chomsky Normal
Form resulting in ?incomplete? non-terminals created by the transform, or incomplete
edges can be represented through so-called dotted rules, as with the Earley (1970)
algorithm, in which transformation is essentially performed on the fly. For example,
if we have a rule production A ? B C D ? P, a completed B entry in chart cell (b,m1)
and a completed C entry in chart cell (m1+1,m2), then we can place an incomplete edge
A ? B C ?D in chart cell (b,m2). The dot signifies the division between what has already
been combined (left of the dot), and what remains to be combined. Then, if we have an
incomplete edge A ? B C ?D in chart cell (b,m2) and a complete D in cell (m2+1, e), we
can place a completed A entry in chart cell (b, e).
Transforming a grammar into ChomskyNormal Form (CNF) is an off-line operation
that converts rules with more than two children on the right-hand side into multiple
binary rules. To do this, composite non-terminals are created during the transformation,
which represent incomplete constituents (i.e., those edges that require further combina-
tion to be made complete).1 For example, if we have a rule production A ? B C D in
1 In this section we assume that edges are extended from left-to-right, which requires a left-binarization of
the grammar, but everything carries over straightforwardly to the right-binarized case.
725
Computational Linguistics Volume 38, Number 4
the context-free grammar G, then a new composite non-terminal would be created (e.g.,
@A:BC) and two binary rules would replace the previous ternary rule: A ? @A:BC D
and @A:BC ? B C. The @A:BC non-terminal represents part of a rule expansion that
needs to be combined with something else to produce a complete non-terminal from
the original set of non-terminals.2
In addition to binarization, one frequent modification to the grammar is to create
a Markov model of the dependencies on the right-hand side of the rule. One way to
do this is to reduce the number of children categories annotated on our new composite
non-terminals introduced by binarization. For example, if instead of @A:BC we assign
the label @A:C to our new non-terminal?with the semantics ?an incomplete A con-
stituent with rightmost child C??then the two rules that result from binarization are:
A ? @A:C D and @A:C ? B C. Probabilistically, the result of this is that the children
non-terminals B and D are conditionally independent of each other given A and C.
This approach will provide probability mass to combinations of children of the original
category A that may not have been observed together, hence it should be seen as a form
of smoothing. One can go further and remove all children categories from the new non-
terminals (i.e., replacing @A:BC with just @A). This is the binarization pursued in the
Berkeley parser, and is shown in Figure 1b.
In this article, we explicitly discuss unary productions of type A ? B where B is a
non-terminal, and include these productions in our grammar. These productions violate
the definition of a CNF grammar, and therefore we will use the term ?binarized gram-
mar? for the remainder of the article to indicate a grammar in CNF with the addition
of unary productions. We will assume that all of our grammars have been previously
binarized and we define V? to be the set of non-terminals that are created through
binarization, and denote edges where A ? V? as incomplete edges. Note that categories
A ? V? are only used in binary productions, not unary productions, a consideration that
will be used in our constrained parsing algorithm.
4. Finite-State Chart Constraints
In this section, we will explicitly define our chart constraints, and present methods for
using the constraints to constrain parsing. We begin with constraints on beginning or
ending multi-word constituents, then move to constraining span-1 chart cells.
4.1 Constituent Begin and End Constraints
Our task is to learn which words (in the appropriate context) can begin (B) or end (E)
multi-word constituents. We will treat this as a pre-processing step to parsing and use
these constraints to either completely or partially close chart cells during execution of
the CYK algorithm.
First, let us introduce notation. Given a set of labeled pairs (S,T) where S is a string
of n words w1 . . .wn and T is the target constituent parse tree for S, we say that word
wb ? B if there is a constituent spanning wb . . .we for some e > b and wb ? B otherwise.
Similarly, we say that word we ? E if there is a constituent spanning wb . . .we for some
b < e and we ? E otherwise. Recovery of these labels will be treated as two separate
binary tagging tasks (B/B and E/E).
2 In this example, the symbol ?@? indicates that the new non-terminal is incomplete, and the symbol ?:?
separates the original parent non-terminal from the children.
726
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Figure 2
Begin (a), End (b), Unary (c), and the combination of the three (d) type of constraints for the
dynamic programming chart used to parse As usual, the real-estate market had overreactedwith
a left-binarized grammar (see Figure 1). Black denotes ?closed? cells, white cells are ?open,?
and gray cells are only open to a restricted population (gray cells closed by E constraints only
allow incomplete edges; gray cells closed by U constraints only allow POS tags).
Although it may be obvious that we can rule out multi-word constituents with
particular begin and end positions, there may be incomplete structures within the parser
that should not be ruled out by these same constraints. Hence the notion of ?closing?
a chart cell is slightly more complicated than it may initially seem (which accounts
for our use of quotes around the term). Consider the chart representation in Figure 2
with the following constraints, where B is the set of words disallowed from beginning a
multi-word constituent and E is the set of words disallowed from ending a multi-word
constituent3
B : {?usual?, ?, ?, ?real-estate?, ?market?, ?overreacted?}
E : {?, ?, ?the?, ?real-estate?, ?had?}
Given our constraints, suppose that wb is in class B and we is in class E, for b < e.
We can ?close? all cells (b,m1) such that m1 > b and all cells (m2, e) such that m2 < e,
based on the fact that multi-word constituents cannot begin with word wb and cannot
end with we. In Figure 2 this is depicted by the black and gray diagonals through the
chart, ?closing? those chart cells.
3 In this example we list the actual words from the sentence for clarity with Figure 2, but in practice we
classify word positions as a specific word may occur multiple times in the same sentence with potentially
different B or E labels.
727
Computational Linguistics Volume 38, Number 4
If a chart cell (b, e) has been ?closed? due to begin or end constraints then it is clear
that complete edges should not be permitted in the cell since these represent precisely
the multi-word constituents that are being ruled out. But what about incomplete edges
that are introduced through grammar binarization or dotted rule parsing? To the extent
that an incomplete edge can be extended to a valid complete edge, it must be allowed.
There are two cases where this is possible. If wb ? B, then under the assumption that
incomplete edges are extended from left-to-right (see footnote 1), the incomplete edge
should be discarded, because any completed edges that could result from extending that
incomplete edge would have the same begin position. Stated another way, if wb ? B
for chart cell (b, e) then all chart cells (b, i) for i > b must also be closed. For example,
in Figure 2, the cell associated with the two-word substring real-estate market can be
closed to both complete and incomplete edges, since real-estate ? B, and any complete
edge built from entries in that cell would also have to start with the same word and
hence would be discarded. Thus, the whole diagonal is closed. If, however, wb ? B and
we ? E, such as the cell associated with the two-word substring the real-estate in Figure 2,
a complete edge?achieved by extending the incomplete edge?may end at wi for i > e,
and cell (b, i) may be open (the real-estate market), hence the incomplete edge should be
allowed in cell (b, e).
In Section 4.4 we discuss limitations on how such incomplete edges arise in closed
cells, which has consequences for the worst-case complexity under certain conditions.
4.2 Unary Constraints
In addition to begin and end constraints, we also introduce unary constraints in span-1
cells. Although we cannot close span-1 cells entirely because each of these cells must
contain at least one POS tag, we can reduce the population of these cells by restricting
the type of constituents they contain.We define a single-word constituent (SWC) as any
unary production A ? B in the grammar such that B is a non-terminal (not a lexicon
entry) and the production spans a single word. The productions ADJP ? JJ and VP ?
VBN in Figure 1a are examples of SWCs. Note that TOP ? S and JJ ?usual in Figure 1a
are also unary productions, but by definition they are not SWC unary productions. We
train a distinct tagger, as is done for B and E constraints, to label each word position as
either in U or U, indicating that the word position may or may not be extended by a
SWC, respectively.
Because the search over possible grammar extension from two child cells in the
CYK algorithm is analogous to a database JOIN operation, the efficiency of this cross-
product hinges on the population of the two child cells that are intersected. We focus on
constraining the population of span-1 chart cells for three reasons. First, the begin/end
constituent constraints only affect chart cells spanning more than one word and leave
span-1 chart cells completely unpruned. By pruning entries in these span-1 cells, we
complement multi-word constituent pruning so that all chart cells are now candidates
for finite-state tagging constraints. Second, span-1 chart cells are the most frequently
queried cells in the CYK algorithm. The search over possible midpoints will always
include two cells spanning a single word?one as the first left child and one as the
last right child. It is therefore important that the number of entries in these cells be
minimized to make bottom?up CYK processing efficient. Finally, as we will show in
Section 5, only 11.2% of words in the WSJ treebank are labeled with SWC productions.
With oracle unary constraints, the possibility of constraining nearly 90% of span-1 chart
cells has promising efficiency benefits to downstream processing.
728
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
To reiterate, unary constraints in span-1 chart cells never close the cell completely
because each span-1 cell must contain at least one POS non-terminal. Instead, if wi ? U
then we simply do not add phrase-level non-terminals to chart cell (i, i). Similar to chart
cells spanning multiple words that cannot be closed completely, these span-1 chart cells
partially restrict the population of the cell, which we will empirically show to reduce
processing time over unconstrained CYK parsing. These partially closed chart cells are
represented as gray in Figure 2.
4.3 The Constrained CYK Algorithm
Our discussion of cell closing in Section 4.1 highlighted different conditions for closing
cells for complete and incomplete edges. We will refer to specific conditions in the pseu-
docode, which we enumerate here. The constraints determine three possible conditions
for cell (b, e) spanning multiple words:
1. wb ? B: cell is closed to all constituents, both complete and incomplete
2. wb ? B and we ? E: cell is closed to complete constituents
3. wb ? B and we ? E: cell is open to all constituents
and two possible conditions for cell (i, i) spanning a single word:
4. wi ? U: cell is closed to unary phrase-level constituents
5. wi ? U: cell is open to all constituents
We will refer to a chart cell (b, e) that matches the above condition as ?case 1 cells,?
?case 2 cells,? and so on, throughout the remainder of this article. Figure 2 represents
these five cases pictorially, where case 1 cells are black, case 2 and 4 cells are gray, and
case 3 and 5 cells are white.
Algorithm 2 contains pseudocode of our modified CYK algorithm that takes into
account B, E, and U constraints. Line 4 of Algorithm 2 is the first modification from
the standard CYK processing of Algorithm 1: We now consider only words in set B to
begin multi-word constituents. Chart cells excluded from this criteria fall into case 1
and require no work. Line 5 determines if chart cell (b, e) is of case 2 (partially open)
or case 3 (completely open). If we ? E, then we skip to lines 16?17 and only incomplete
edges are permitted. Note that there is only one possible midpoint for case 2 chart cells,
which results in constant-time work (see proof in Section 4.4) and unary productions
are not considered because all entries in the cell are incomplete constituents, which only
participate in binary productions. Otherwise, if we ? E on Line 5, then the cell is open
to all constituents and processing occurs as in the standard CYK algorithm (lines 6?10
of Algorithm 2 are identical to lines 4?8 of Algorithm 1). Finally, unary productions are
added in lines 12?14, but restricted to multi-word spanning chart cells, or span-1 cells
where wb ? U.
4.4 Proofs to Bound Worst-Case Complexity
All of the proofs in this section rely on constraints imposed by B and E. Pruning
provided by the U constraints reduces decoding time in practice, but does not provide
additional reductions in complexity. Our proofs of complexity bounds will rest on
the number of cells that fall in cases 1?3 outlined in the Section 4.3, and the amount
729
Computational Linguistics Volume 38, Number 4
Algorithm 2 CONSTRAINEDCYK
Pseudocode of a modified CYK algorithm, with constituent begin/end and unary con-
straints. Unary processing is simplified to allow only chains of length one (excluding
lexical unary productions). Backpointer storage is omitted.
Input:
w1 . . .wn: Input sentence
G: Left-binarized PCFG
V?: Set of binarized non-terminals from V
B,E,U: Begin, End, and Unary chart constraints
Output:
?: Viterbi-max scores for all non-terminals over every span
CONSTRAINEDCYK(w1 . . .wn, G = (V,T, S
?,P,?),V?,B,E,U)
1: for s = 1 to n do  Span width: bottom-up traversal
2: for b = 1 to n?s+1 do  Begin word position
3: e ? b+s?1
4: if wb ? B or s = 1 then  Case 1 cells excluded
5: if we ? E or s = 1 then
6: for Ai ? V do
7: if s = 1 then  Add lexical productions
8: ?i(b, b)? ?(Ai ? wb)
9: else  Case 3: cell open
10: ?i(b, e)? max
b?m<e
(
max
j,k
?(Ai ? Aj Ak) ?j(b,m) ?k(m+ 1, e)
)
11: if s > 1 or wb ? U then  Case 5 for span-1 cells
12: for Ai ? V do  Add unary productions
13: ?i(b, e)? max
(
?i(b, e) , max
j
?(Ai ? Aj) ?j(b, e)
)
14: ?(b, e)? ?(b, e)
15: else  Case 2: closed to complete constituents
16: for Ai ? V? do  Only consider binarized non-terminals
17: ?i(b, e)? max
j,k
?(Ai ? Aj Ak) ?j(b, e? 1) ?k(e, e)
18: return ?
of work in each case. The amount of work for each case is related to how the CYK
and CONSTRAINEDCYK algorithms performs their search. Each cell (b, e) in the chart
spans the substring wb . . .we, and building non-terminal categories in that cell involves
combining non-terminal categories (via rules in the context-free grammar) found in cells
spanning adjacent substrings wb . . .wm and wm+1 . . .we. The substring wb . . .we can be
as large as the entire sentence, requiring a search overO(N) possiblemidpointwordswm.
This accounts for the linear amount of work in these case 3, open, cells.
More formally, we can define an upper bound on the work required in a chart cell
as W = |P| ? |M| where |P| is the number grammar productions bounded above by the
constant size of the grammar, and |M| is the number ofmidpoints considered.We denote
the upper bound on the amount of work done in case 1 cells byW1 and the total number
of case 1 cells considered by C1 (similarly for case 2 and 3). With this decomposition, the
complexity of the CONSTRAINEDCYK algorithm can be written as O(|C1|W1 + |C2|W2 +
|C3|W3). Because there is no work for case 1 cells (W1 = 0), these can be ignored. In fact,
we can reduce the complexity even further.
730
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Theorem 1
W2 is constant and CONSTRAINEDCYK has complexity O(|C2|+ |C3|W3).
Proof
Without loss of generality, we assume a left-binarized grammar. The upper bound on re-
quiredwork for cell (b, e) is defined asW = |P| ? |M|where |P| is the number of grammar
productions bounded above by the constant size of the grammar, and |M| is the num-
ber of midpoints considered. For some (b, e) where 1 ? b < e ? n, assume wb ? B and
we ? E, that is, (b, e) ? C2. The possible child cells of (b, e) are (b,m) and (m+ 1, e) where
b ? m < e. Because we assume a left-binarized grammar, the production?s right child
must be a complete non-terminal and (m+ 1, e) ? C3 must hold. But we ? E so (m+ 1, e)
cannot be in C3 unless m = e? 1 (span 1 cell). Therefore, the only valid midpoint is
m = e? 1 andW2 = |P|?1 is constant, hence O(|C2|W2 + |C3|W3) = O(|C2|+ |C3|W3). 
In summary, we find that case 2 chart cells (gray in Figure 2) are surprisingly cheap
to process because the right child cell must also be in case 2, resulting in only one
possible midpoint to consider. Next, we show that bounding the number of open cells
and applying Theorem 1 leads to quadratically bounded parsing.
Theorem 2
If |C3| < ?N for some constant ? then CONSTRAINEDCYK has complexity O(N2).
Proof
The total number of cells in the chart for a string of length N is N(N + 1)/2, therefore
|C2| < N2. Further, the number of midpoints for any cell is less than N, hence W3 < N.
If we bound |C3| < ?N, then it follows directly from Theorem 1 that CONSTRAINEDCYK
has complexity O(N2 + ?N ?N) = O(N2). 
We have just proved in Theorem 2 that we can reduce the complexity of constituent
parsing from O(N3) to O(N2) by restricting the number of open cells in the chart via
constraints B and E. Next, we will show that this bound can be reduced even further
to O(N) when the number of words in B is held constant. We call this approach ?linear
constraints.? There are two things to note when considering these constraints. First,
the proof relies only on the size of set B, leaving E potentially empty and limiting
the efficiency gains on short sentence compared to high-precision and quadratically
bounded constraints. Second, limiting the size of B to a constant value is a restrictive
criterion. When applied to a long sentence, this will over-constrain the search space and
impose a branching bias on possible trees. In Section 7.2 we show that if the branching
bias from linear constraints matches the branching bias of the treebank, then accuracy
is not severely affected and linear constraints can provide a useful bound on long
sentences that often dominate computational resources.
We first prove limits on the total number of open chart cells (case 3) and work
required in these cells, which directly leads to the proof bounding the complexity of
the algorithm.
Lemma 1
If |B| ? ? for some ?, thenW3 ? ?|P|.
731
Computational Linguistics Volume 38, Number 4
Proof
It has been defined thatW1 is zero and shown in Theorem 1 thatW2 is constant. For chart
cell (b, e) ? C3 there are e? b possiblemidpoints to consider. For somemidpointmwhere
b ? m < e, ifwm ? B then (m, e) ? C1 and contains no complete or incomplete constituent
entries. Therefore midpoint m is not a valid midpoint for cell (b, e). Because |B| ? ?,
there are at most ? midpoints to consider and the work required in (b, e) is bounded
above by the constant number of productions in the grammar (|P|) and ? midpoints,
thusW3 ? ?|P|. 
Lemma 2
If |B| ? ? for some ?, then |C2|+ |C3| ? ?N.
Proof
For a string of length N and some wb ? B, there are at most N substrings wb . . .we to
consider, hence O(N) chart cells for each word wb ? B. Because |B| ? ?, then there are
at most ?N cells (b, e) ? C1 and |C2|+ |C3| ? ?N. 
Theorem 3
If |B| ? ? for some ? then CONSTRAINEDCYK has complexity O(N).
Proof
From Theorem 1 we know that CONSTRAINEDCYK has complexity O(|C2|+ |C3|W3).
Given that |B| ? ?, it follows from Lemmas 1 and 2 that CONSTRAINEDCYK has com-
plexity O(?2N|P|) = O(N). 
In this section, we have been discussing worst-case complexity bounds, but there is
a strong expectation for large typical-case complexity savings that aren?t explicitly
accounted for here. To provide some intuition as to why this might be, consider again
the chart structure in Figure 2d. The black cells in the chart represent the cells that have
been closed when wj ? B (case 1 cells). Because there is no work required for these cells,
the total amount of work required to parse the sentence is reduced. The quadratic bound
does not include any potential reduction of work for the remaining open cells, however.
Thus the amount of work to parse the sentence will be less than the worst-case quadratic
bound because of this reduction in processing. In Section 7.2 we compute the empirical
complexity of each constraint method and compare that with its theoretical bound.
5. Tagging Chart Constraints
To better understand the proposed tagging tasks and their likely utility, we will first
look at the distribution of classes and our ability to automatically assign them correctly.
Note that we do not consider the first word w1 and the last word wN during the
begin-constituent and end-constituent prediction tasks because they are unambiguous
in terms of whether they begin or end constituents of span greater than one. The first
wordw1 must begin a constituent spanning the whole string, and the last wordwN must
end that same constituent. The first word w1 cannot end a constituent of length greater
than 1; similarly, the last word wN cannot begin a constituent of length greater than 1.
We therefore omit B and E at these two word positions from prediction, leading to
N ? 2 begin-constituent and N ? 2 end-constituent ambiguous predictions for a string
of length N.
732
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Table 1 displays word statistics from the training sections of the Penn English
treebank (Marcus, Marcinkiewicz, and Santorini 1993) and the Penn Chinese treebank
(Xue et al 2005), and the positive and negative class label frequency of all words in
the data.
From the nearly 1 million words in the English corpus, just over 870,000 are neither
the first nor the last word in the string, therefore possible members of the sets B or E (i.e.,
neither beginning a multi-word constituent (B) nor ending a multi-word constituent
(E)). Of these 870,000 words, over half (50.5%) do not begin multi-word constituents,
and nearly three quarters (74.3%) do not end multi-word constituents. The skewed dis-
tribution of E to E reflects the right-branching structure of English. Finally, almost 90%
of words are not labeled with a single-word constituent, demonstrating the infrequency
at which these productions occur in the English treebank.
The Chinese treebank is approximately half of the size of the English treebank
in terms of the number of sentences and word count. Again, we see a bias towards
right-branching trees (|B| > |E|), but the skew of the distributions is much smaller
than it is for English. The most significant difference between the two corpora is the
percentage of single-word constituents in Chinese compared with English. Due to the
annotation guidelines of the Chinese treebank, nearly 40% of words contain single-word
constituent unary productions. Because these occur with such high frequency, we can
assume that unary constraints may have a smaller impact on efficiency for Chinese than
for English, because an accurate tagger will constrain fewer cells. We still have the
expectation, though, that accurate tagging of SWC productions will increase parsing
accuracy for both English and Chinese.
To automatically predict the class of each word position, we train a binary predictor
from supervised data for each language/word-class pair, tuning performance on the
respective development sets (WSJ Section 24 for English and Penn Chinese Treebank
articles 301-325 for Chinese). Word classes are extracted from the treebank trees by
observing constituents beginning or ending at each word position, or by observing
single word constituents. We use the tagger from Hollingshead, Fisher, and Roark
(2005) to train six linear models (three for English, three for Chinese) with the averaged
perceptron algorithm (Collins 2002).
Table 2 summarizes the features implemented in our tagger for B, E, and U identifi-
cation. In the table, the? features are instantiated as POS-tags (provided by a separately
trained log-linear POS-tagger) and ? features are instantiated as constituent tags (B,
E, and U class labels). The feature set used in the tagger includes the n-grams of
surrounding words, the n-grams of surrounding POS-tags, and the constituent tags of
Table 1
Statistics on extracted word classes for English (Sections 2?21 of the Penn WSJ treebank) and
Chinese (articles 1?270 and 400?1151 of the Penn Chinese treebank).
Corpus totals Begin class End class Unary class
Strings Words B B E E U U
English
Count 39,832 950,028 430,841 439,558 223,544 646,855 105,973 844,055
Percent 49.5 50.5 25.7 74.3 11.2 88.8
Chinese
Count 18,086 493,708 188,612 269,000 165,591 292,021 196,732 296,976
Percent 41.2 58.8 36.2 63.8 39.9 60.1
733
Computational Linguistics Volume 38, Number 4
Table 2
Tagger features for B, E, and U.
LEX ORTHO POS
?i ?i,wi ?i,wi[0] ?i,?i
?i?1, ?i ?i,wi?1 ?i,wi[0..1] ?i,?i?1
?i?2, ?i ?i,wi+1 ?i,wi[0..2] ?i,?i?1,?i
?i?2, ?i?1, ?i ?i,wi?2 ?i,wi[0..3] ?i,?i+1
?i,wi+2 ?i,wi[n] ?i,?i,?i+1
?i,wi?1,wi ?i,wi[n-1..n] ?i,?i?1,?i,?i+1
?i,wi,wi+1 ?i,wi[n-2..n] ?i,?i?2
?i,wi[n-3..n] ?i,?i?2,?i?1
?i,wi ? Digit ?i,?i?2,?i?1,?i
?i,wi ? UpperCase ?i,?i+2
?i,wi ? Hyphen ?i,?i+1,?i+2
?i,?i,?i+1,?i+2
All lexical (LEX), orthographic (ORTHO), and part-of-speech (POS) features are duplicated to also occur
with ?i?1; e.g., {?i?1, ?i,wi} as a LEX feature.
the preceding words. The n-gram features are represented by the words within a three-
wordwindow of the current word. The tag features are represented as unigram, bigram,
and trigram tags (i.e., constituent tags from the current and two previous words). These
features are based on the feature set implemented by Sha and Pereira (2003) for NP
chunking. Additional orthographical features are used for unknown and rare words
(words that occur fewer than five times in the training data), such as the prefixes and
suffixes of the word (up to the first and last four characters of the word), and the pres-
ence of a hyphen, a digit, or a capitalized letter, following the features implemented by
Ratnaparkhi (1999). Note that the orthographic feature templates, including the prefix
(e.g., wi[0..1]) and suffix (e.g., wi[n-2..n]) templates, are only activated for unknown and
rare words. When applying our tagging model to Chinese data, all feature functions
were left in the model as-is, and not tailored to the specifics of the language.
We ran various tagging experiments on the development set and report accuracy
results in Table 3 for all three predictions tasks, using Viterbi decoding. We trained
Table 3
Tagging accuracy on the respective development sets (WSJ Section 24 for English and Penn
Chinese Treebank articles 301?325 for Chinese) for binary classes B, E, and U, for various
Markov orders.
Tagging Task Markov order
0 1 2
English
B (no multi-word constituent begin) 96.7 96.9 96.9
E (no multi-word constituent end) 97.3 97.3 97.3
U (no span-1 unary constituent) 98.3 98.3 98.3
Chinese
B (no multi-word constituent begin) 94.8 95.4 95.2
E (no multi-word constituent end) 96.2 96.4 96.6
U (no span-1 unary constituent) 95.9 96.2 96.3
734
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
models with Markov order-0 (constituent tags predicted for each word independently),
order-1 (features with constituent tag pairs), and order-2 (features with constituent tag
triples). In general, tagging accuracy for English is higher than for Chinese, especially
for the U and B tasks. Given the consistent improvement from Markov order-0 to
Markov order-1 (particularly on the Chinese data), and for the sake of consistency, we
have chosen to perform Markov order-1 prediction for all results in the remainder of
this article.
6. Experimental Set-up
In the sections that follow, we present empirical trials to examine the behavior of chart
constraints under a variety of conditions. First, we detail the data, evaluation, and
parsers used in these experiments.
6.1 Data Sets and Evaluation
For English, all stochastic grammars are induced from the Penn WSJ Treebank (Marcus,
Marcinkiewicz, and Santorini 1993). Sections 2?21 of the treebank are used as training,
Section 00 as held-out (for determining stopping criteria during training and some
parameter tuning), Section 24 as development, and Section 23 as test set. For Chinese,
we use the Penn Chinese Treebank (Xue et al 2005). Articles 1?270 and 400?1151 are
used for training, articles 301?325 for both held-out and development, and articles 271?
300 for testing. Supervised class labels are extracted from the non-binarized treebank
trees for B, E, and U (as well as their complements).
All results report F-measure labeled bracketing accuracy (harmonic mean of labeled
precision and labeled recall) for all sentences in the data set (Black et al 1991), and
timing is reported using an Intel 3.00GHz processor with 6MB of cache and 16GB of
memory. Timing results include both the pre-processing time to tag the chart constraints
as well as the subsequent context-free inference, but tagging time is relatively negligible
as it takes less than three seconds to tag the entire development corpus.
6.2 Tagging Methods and Closing Chart Cells
We have three separate tagging tasks, each with two possible tags for every word wi in
the input string: (1) B or B; (2) E or E; and (3) U or U. Our taggers are as described in
Section 5.
Within a pipeline system that leverages hard constraints, one may want to choose
a tagger operating point that favors precision of constraints over recall to avoid over-
constraining the downstream parser. We have two methods for trading recall for preci-
sion that will be detailed later in this section, both relying on calculating the cumulative
score Si for each of the binary tags at each word position wi. That is, (using B as the
example tag):
Si(B | w1 . . .wn) = log
?
?1...?n
?(?i,B) e
?(w1...wn,?1...?n )?w (1)
where
?
sums over all possible tag sequences for sentence w1 . . .wn; ?(?i,B) = 1 if ?i =
B and 0 otherwise; ?(w1 . . .wn, ?1 . . . ?n) maps the word string and particular tag string
to a d-dimensional (global) feature vector; andw is the d-dimensional parameter vector
735
Computational Linguistics Volume 38, Number 4
estimated by the averaged perceptron algorithm. Note that this cumulative score over
all tag sequences that have B in position i can be calculated efficiently using the forward?
backward algorithm. We can compare the cumulative scores Si(B) and Si(B) to decide
how to tag word wi, and define the cumulative score ratio (CSR) as follows:
CSR(wi) = Si(B)? Si(B) (2)
If we want to tag Bwith high precision, and thus avoid over-constraining the parser, we
can change our decision criterion to produce fewer such tags. We present two different
selection criteria in the next two subsections.
To show the effect of precision-oriented decision criteria, Figure 3 shows the preci-
sion/recall tradeoff at various operating points, using the global high-precision method
detailed herein, for all three tags on both the English and the Chinese development
sets. As expected, we see that the English B curve is significantly lower than the
English E and U curves. This is due to the near-uniform prior on B in the data (E and
U are much higher-frequency classes). Still, we can achieve 99% precision for B with
recall above 70%. We do much better with E and U and see that when precision is 99%
for these two tags, recall does not drop below 90%. For the Chinese tagging task, B, E,
and U all have similar performance as we trade precision for recall. Here, as with the
English B tag, we achieve 99% precision with recall still above 70%.
We can see from these results that our finite-state tagging approach yields very
high accuracy on these tasks, as well as the ability to provide high precision (above
99%) operating points with a tolerable loss in recall. In what follows, we present two
approaches to adjusting precision: first by adjusting the overall precision and recall of
the tagger directly, as shown here; and second, by adjusting the precision and recall
of tagging results on a per-sentence basis. We then discuss how complexity-bounded
constraints are implemented in our experiments. In Section 7.1 we discuss empirical
results showing how adjusting the tagger in these ways affects parsing performance.
Figure 3
Tagger precision/recall tradeoff of B, E, and U on the development set for English (a) and
Chinese (b).
736
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
6.2.1 Global High Precision. Global high precision constraints (GHP) are implemented
using the cumulative score ratios directly to determine if wb ? B or B.4 Given the
cumulative score ratio as defined herein, we define the set B under global high precision
constraints as:
GHP?(wi . . .wN ) = {wi ? B : CSR(wi) > ?} (3)
The default decision boundary ? = 0 provides high tagging accuracy, but as men-
tioned in Section 6.2 we may want to increase the precision of the tagger so that
the subsequent parser is not over constrained. To do this, we increase the threshold
parameter ? towards positive infinity, potentially moving some words in the corpus
from B to B. The same procedure is applied to E and U tags.
6.2.2 Sentence-Level High Precision. Global high precision constraints, as defined here,
affect the precision of the tagger over the entire corpus, but may or may not affect
individual sentences. Because parsing operates on a sentence-by-sentence basis, it may
be beneficial to modify the precision of the tagger based on the current sentence being
processed. We call this approach sentence-level high precision (HP).5
To increase tagging precision at the sentence level, we compute the cumulative
scores Si and the cumulative scores ratio (CSR) at all word positions as described in
this article. We next tag all word positions with a CSR(wi) score less than zero with
B, and rank the remaining word positions according to their CSR score. The lowest-
ranking ? fraction of this sorted list are tagged as B, and the rest default to B. When
? = 0, zero percent of words are tagged with B (i.e., no constraints are applied); and
when ? = 1, 100 percent of the words with CSR(wi) > 0 are tagged with B. This ensures
that the high-precision threshold is adapted to each sentence, even if its absolute CSR
scores are not similar to others in the corpus.
6.2.3 Quadratic Bounds.We impose quadratic bounds on context-free parsing by restrict-
ing the number of open cells (case 3 in Section 4.3) to be less than or equal to ?N for some
tuning parameter ? and sentence lengthN. This only involves the sets B and E, as unary
constraints are restricted to span-1 cells. Given gold parse trees t? and a function T(B,E)
to generate the set of all valid parse trees satisfying constraints B and E, the optimal
quadratically bounded constraints would be:
Quad?(wi . . .wN ) = argmax
B,E
( max
t?T(B,E)
F1(t
?, t) s.t. |C3| ? ?N) (4)
that is, the set of constraints that provides the optimal F-score of the best remaining
candidate in the chart while still imposing the required bound on the number of C3
cells. This equation is an instance of combinatorial optimization and solving it exactly
is NP-complete. Furthermore, we do not have access to gold parse trees t? during
parsing and must rely on the posterior scores of the tagger.
We instead use a greedy approach to approximate Equation (4). To accomplish this,
at every sentence we first sort both the B and E CSR scores for each word position
4 In our experiments these scores are in the range ?103.
5 As a historical note, we referred to this approach as simply ?high precision constraints? in Roark and
Hollingshead (2008) and Roark and Hollingshead (2009).
737
Computational Linguistics Volume 38, Number 4
into a single list. Next, we assume all word positions are in B and E, then starting
from the top of the sorted list (highest posterior probability for set inclusion), we
continue to add word positions to their respective open set and compute the number
of open cells with the given constraints while |C3| < ?N. By doing this, we guarantee
that only a linear number of case 3 cells are open in the chart, which leads to quadratic
worst-case parsing complexity.
6.2.4 Linear Bounds. Imposing O(N) complexity bounds requires constraining the
size of the set B such that |B| ? ? for some constant ?. As with quadratic complexity
bounds, we wish to find the optimal set B to fulfill these requirements:
Linear?(wi . . .wN ) = argmax
B
( max
t?T(B)
F1(t
?, t) such that |B| ? ?) (5)
We again resort to a greedy method to determine the set B, as this optimization
problem is still NP-complete and gold trees are not available. B is constructed by sorting
all word positions by their CSR scores for B, and then adding only the highest-scoring
? entries to the inclusion set. All other word positions are closed and in the set B.
Because this method does not consider the set E to impose limits on processing,
it will be shown in Section 7.2 that O(N) complexity bounding is not as effective as
a stand-alone method when compared to the quadratic complexity or high precision
constraints presented here.
6.3 Parsers
We will present results constraining several different parsers. We first present results
for exhaustive parsing using both the CYK and the CONSTRAINEDCYK algorithms. We
use a basic CYK exhaustive parser, termed the BUBS parser,6 to parse with a simple
PCFG model that uses non-terminal node-labels as provided by the Penn Treebank,
after removing empty nodes, node indices, and function tags. The results presented
here replicate and extend the results presented in Roark and Hollingshead (2009), using
a different CYK parser.7 The BUBS parser is an open-source high-efficiency parser
that is grammar agnostic and can be run in either exhaustive mode or with various
approximate inference options (detailed more fully in Section 8.1). It has been shown to
parse exhaustively with very competitive or superior efficiency compared with other
highly optimized CYK parsers (Dunlop, Bodenstab, and Roark 2011). In contrast to
the results in Roark and Hollingshead (2009), here we present results with both left-
and right-binarized PCFGs induced using a Markov order-2 transform, as detailed in
Section 3.3, and also present results for parsing Chinese.
We will then present results applying finite-state chart constraints to state-of-the-
art parsers, and evaluate the additional efficiency gains these constraints provide, even
when these parsers are already heavily pruned. To simplify the presentation of these
6 http://code.google.com/p/bubs-parser.
7 Note that there are several differences between the two parsers, including the way in which grammars
are induced, leading to different baseline accuracies and parsing times. Most notably, the parser from
Roark and Hollingshead (2009) relied upon POS-tagger output, and collapsed unary productions in a
way that effectively led to parent annotation in certain unary chain constructions. The current results
do not exploit those additional annotations, hence the baseline F-measure accuracy is a couple of
percentage points lower.
738
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
results, we concentrate in Section 7.1 on parsing with the simple Markov order-2
grammars, and then move to higher accuracy parsers in Section 8.
7. CYK Parsing with Finite-State Chart Constraints
7.1 High-Precision Constraints
As mentioned in Section 6.2, we can adjust the severity of pruning to favor preci-
sion over recall. Figure 4a shows parse time versus F-measure labeled parse accuracy
on the English development set for the baseline (unconstrained) exact-inference CYK
parser, and for various parameterizations of global high precision (GHP), sentence-level
high precision (HP), and unary constraints. Note that we see accuracy increasing over
the baseline in Figure 4a with the imposition of these constraints at some operating
points. This is not surprising, though, as the finite-state tagger makes use of lexical
Figure 4
English development set results (WSJ Section 24) applying global high precision (GHP),
sentence-level high precision (HP), and unary constraints with the CONSTRAINEDCYK
algorithm. We sweep over multiple values of ? in (a) and plot results in (b), (c), and (d) with the
optimal value for each constraint found in (a). F-measure accuracy in (b) is computed over
binned sentence lengths. Figure (d) plots the same data as (c), but zoomed in.
739
Computational Linguistics Volume 38, Number 4
information that the simple PCFG does not, hence there is complementary information
added that improves the model. The best operating points?fast parsing and relatively
high accuracy?are achieved for GHP constraints at ? = 40, for sentence-level HP at
? = 0.95, and for unary constraints at ? = 40. These high-precision parameterizations
achieve roughly an order of magnitude speed-up and between 0.2 absolute (for unary
constraints) and 3.7 absolute (for high-precision constraints) F-measure improvement
over the baseline unconstrained parser.
In order to analyze how these constraints affect accuracy with respect to sentence
length, we turn to Figure 4b. In this plot, F-measure accuracy is computed over binned
sentence lengths in increments of ten. All sentences of length greater than 60 are in-
cluded in the final bin. As one might expect, accuracy declines with sentence length
for all models because the number of possible trees is exponential in the sentence length
and errors in one portion of the tree can adversely affect prediction of other constituents
in nearby structures. We see that all constraints provide accuracy gains over the baseline
at all sentence lengths, but point out that the gains by GHP B and E constraints are larger
for longer sentences. As stated earlier, this is due to themodel-correcting behavior of cell
constraints: Lexical features are leveraged to prune trees that the PCFG may favor but
are not syntactically correct with respect to the entire sentence. Because longer sentences
are poorly modeled by the PCFG, cell constraints play a larger role in restricting the
space of possible trees considered and correcting modeling errors.
We can get a different perspective of how these constraints affect parsing time by
considering the scatter plots in Figures 4c and 4d, which plot each sentence according
to its length and parsing time at four operating points: baseline (unconstrained); global
high precision at ? = 40; sentence-level high precision at ? = 0.95; and unary at ? =
40. Figure 4c shows data points with up to 80 words and 400 msec of parsing time.
Figure 4d zooms in to under 200 msec and up to 40 words. It can be seen in each graph
that unconstrained CYK parsing quickly leaves the plotted area via a steep cubic curve
(least-squares fit is N2.9). Unary constraints operate at the same cubic complexity as
the baseline, but with a constant factor decrease in parsing time (least-squares fit is
also N2.9). The plots for GHP and HP show dramatic decreases in typical-case runtime
compared with the baseline. We again run a least-squares fit to the data and find that
both GHP and HP constraints follow a N2.5 trajectory.
The empirical complexity and run-time performance of GHP and HP are nearly
identical relative to all other chart constraints. But looking a little closer, we see in
Figures 4c and 4d that that GHP constraints are slightly faster than HP for some
sentences, and accumulated over the entire development set, this leads to both higher
accuracy (75.1 vs. 74.6 F-measure) and faster parsing time (46 vs. 50 seconds).8 This
leads to the conclusion that when optimizing parameters for high-precision constraints,
we can better tune the overall pipeline by choosing an operating point based on the
corpus-level tagger performance as opposed to tuning for sentence-specific precision
goals. Consequently, other than Table 4, we only apply GHP constraints on test set
results in the remainder of this section.
Although Figure 4a displays the constrained F-measure parse accuracy as a function
of parsing time, one may also be interested in how tagger precision directly affects parse
accuracy. To answer this question, we apply high precision constraints to sets B and E in
isolation and plot results in Figure 5. Note that when only constraints on E are applied,
no chart cells can be completely closed and parsing time does not significantly decrease.
8 See Table 4 for additional performance comparisons.
740
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Likewise, when we apply constraints on B, a chart cell is either open to all constituents
(case 3) or closed to all constituents (case 1). When constraining either B or E, we are
predicting the structure of the final parse tree, which (as can be seen in Figure 5) has
large effects on parse F-measure.
We point out in Figure 5 that to achieve optimal parsing F-measure, tagger precision
must be above 97% for both English and Chinese. For both languages, B constraints
are more forgiving and do not adversely affect parsing F-measure as quickly as E con-
straints. These results may lead one to tune two separate high-precision parameters?
one to constrain B and one to constrain E. We ran such experiments but found no
significant gains compared to tying these parameters together.
7.2 Complexity-Bounded Constraints
Figure 6a plots F-measure accuracy versus time to parse the entire development set for
two complexity bounded constraints: O(N2) and O(N). We also include the previously
plotted global high-precision constraints for comparison. The large asterisk in the plot
depicts the baseline accuracy and efficiency of standard CYK parsing without con-
straints. We sweep over various parameterizations for each method, from very lightly
constrained to very heavily constrained. The complexity-bounded constraints are not
combined with the high-precision constraints for this plot (but are later in the article).
As can be seen in Figure 6a, the linear-bounded method does not, as applied,
achieve a favorable accuracy/efficiency tradeoff curve compared with the quadratic
bound or high-precision constraints. This is not surprising, given that no words are
excluded from the set E for this method, hence far fewer constraints overall are applied
with the linear-bounded constraints.
In addition, we see in Figure 6b that unlike high precision and quadratic constraints,
the linear method hurts accuracy on longer sentences over the baseline unconstrained
algorithm, notably for sentences greater than 50 words. We attribute this to the fact
that for longer sentences, say length 65, only ? = 16 words are allowed in B for linear
Figure 5
The effects of tagger precision on parsing F-measure. B and E constraints are applied in isolation;
no other constraints are used during parsing. Results on the English development set in (a) and
Chinese in (b). Baseline unconstrained F-measure accuracy is indicated with the horizontal
black line.
741
Computational Linguistics Volume 38, Number 4
Figure 6
English development set results (WSJ Section 24), applying complexity-bounding constraints
with the CONSTRAINEDCYK algorithm. We sweep over multiple values of ? in (a) and plot
results in (b), (c), and (d) with the optimal value for each constraint found in (a). F-measure
accuracy in (b) is computed over binned sentence lengths. Figure (d) plots the same data as (c),
but zoomed in.
constraints, which severely limits the search space for these sentences to the point of
pruning gold constituents and decreasing overall accuracy.
Next we turn to the scatter plots of Figures 6c and 6d. Fitting an exponential curve
to the data for each constraint via least-squares, we find that global high-precision
constraints follow a N2.5 trajectory, quadratic at N1.6, and linear at N1.4. It is interesting
that quadratic constraints actually perform at sub-quadratic run-time complexity. This
is because the quadric complexity proof in Section 4.4 assumes that the linear number
of open cells each process O(N) midpoints. But in practice, many midpoints are not
considered due to the heavily constrained chart, decreasing the average-case runtime
of CONSTRAINEDCYK with quadratically bounded constraints.
Also interesting is that linear constraints perform worse than O(N) at N1.4. We
attribute this to the nature of the data set. When parsing with linear constraints, we
see that for short sentences parsing complexity is actually cubic. Because we allow
a constant number of word positions in the open set B, sentences with length less
742
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
than ? are completely unconstrained and all chart cells remain open. In Figure 6d it
looks as if parsing becomes linear after the sentence length notably exceeds ?, around
N = 20. Assuming our corpus contained a disproportionate number of long sentences,
empirical complexity of linear constraints should approach O(N), but due to the large
number of short sentences, we see an empirical complexity greater than O(N).
Three important points can be taken away from Figure 6. First, although we can
provably constrain parsing to linear speeds, in practice this method is inferior to
both quadratically bounded constraints and high-precision constraints. Second, high-
precision constraints are more accurate (see Figure 6b) and more efficient (see Fig-
ure 6d) for shorter strings than the quadratically bound constraints; yet with longer
strings the quadratic constraints better control parsing time than the high-precision
constraints (see Figure 6c). Finally, at the ?crossover? point, where quadratic constraints
start becoming more efficient than high-precision constraints (roughly 50?60 words,
see Figure 4c), there is a larger variance in the parsing time with high-precision con-
straints versus those with quadratic bounds. This illustrates the difference between
the two methods of selecting constraints: High-precision constraints can provide very
strong typical-case gains, but there is no guarantee of worst-case performance. In this
way, the high-precision constraints are similar to other tagging-derived constraints like
POS-tags or chunks.
7.3 Combining Constraints
Depending on the length of the string, the complexity-bound constraints may close
more or fewer chart cells than the high-precision constraints?more for long strings,
fewer for short strings. We can achieve worst-case bounds along with superior typical-
case speed-ups by combining both methods. This is accomplished by taking the union
of high-precision B, E, andU constraints with their respective complexity-bounded sets.
When combining complexity-bound constraints with high-precision constraints, we
first chose operating parameters for each complexity-bounded method at the point
where efficiency is greatest and accuracy has yet to decline. These operating points can
be seen as the ?knee? of the curves in Figure 6a. For the quadratic complexity method,
we set ? = 4, limiting the number of open cells to 4N. For the linear complexity method,
we set ? = 12, limiting the number of word positions in B to a maximum of 12 members.
Table 4 displays F-measure accuracy and parsing time (in seconds) for many indi-
vidual and combined constraints on the development set: unconstrained CYK parsing;
unary constraints; global high-precision (GHP) and sentence-level high-precision (HP)
constraints; and O(N2) and O(N) complexity-bounded constraints (Quad and Linear,
respectively). We present all parsing results in Table 4 using both a left- and right-
binarized Markov order-2 grammar so that the effects of grammar binarization on
finite-state constraints can be evaluated. Pre-processing the grammar with a right or
left binarization alters the nature and distribution of child non-terminals for grammar
productions. Because B and E constraints prune the chart differently depending on the
grammar binarization, we suspect that one method may outperform the other due to
the branching bias of the language being parsed.
We find three general trends in Table 4. First, the efficiency benefits of combin-
ing constraints are relatively small. We suspect this is because the data set contains
mostly shorter sentences. Global high-precision constraints outperform the complexity
bounded constraints on sentences of length 10 to 50, which makes up the majority of
the development set. It is not until we parse longer sentences that the trends start to
differ and exhibit characteristics of the complexity bounds. Thus by combining high-
743
Computational Linguistics Volume 38, Number 4
Table 4
English development set results (WSJ Section 24) for the CONSTRAINEDCYK algorithm with both
left- and right-binarized Markov order-2 grammars under various individual and combined
constraints.
Constraints F1 Precision Recall Seconds Speed-up
R
ig
h
t-
b
in
a
ri
z
e
d
g
ra
m
m
a
r
None (baseline CYK) 71.5 74.5 68.8 451
GHP(40) 75.3 78.6 72.3 46 9.8x
HP(0.95) 74.6 77.8 71.7 50 8.9x
Quad(4) 73.8 77.0 70.9 70 6.4x
Linear(12) 72.4 75.4 69.6 106 4.3x
Unary(40) 72.0 75.4 68.9 386 1.2x
HP(0.95) + Quad(4) 74.6 77.8 71.7 48 9.5x
HP(0.95) + Linear(12) 74.4 77.6 71.5 48 9.5x
GHP(40) + Quad(4) 75.3 78.5 72.3 45 10.0x
GHP(40) + Linear(12) 75.1 78.4 72.1 44 10.2x
GHP(40) + Unary(40) 75.7 79.4 72.4 34 13.4x
GHP(40) + Unary(40) + Quad(4) 75.8 79.5 72.4 33 13.9x
L
e
ft
-b
in
a
ri
z
e
d
g
ra
m
m
a
r
None (baseline CYK) 71.7 74.5 69.1 774
GHP(40) 75.4 78.5 72.5 66 11.2x
HP(0.95) 74.9 77.9 72.1 75 10.3x
Quad(4) 74.0 77.0 71.2 99 7.8x
Linear(24) 71.7 74.5 69.1 448 1.7x
Unary(40) 71.9 75.2 69.0 607 1.3x
HP(0.95) + Quad(4) 74.9 78.0 72.1 69 11.2x
HP(0.95) + Linear(24) 74.7 77.8 71.9 71 11.0x
GHP(40) + Quad(4) 75.4 78.5 72.5 62 12.6x
GHP(40) + Linear(24) 75.2 78.4 72.3 62 12.6x
GHP(40) + Unary(40) 75.7 79.3 72.5 37 20.9x
GHP(40) + Unary(40) + Quad(4) 75.7 79.3 72.5 37 20.9x
precision and complexity constraints, we attain the typical-case efficiency benefits of
high-precision constraints with worst-case complexity bounds.
Second, we see that the efficiency gain combining unary and high-precision con-
straints is more than additive. Unary constraints alone for the right-binarized grammar
decreased parsing time by 1.3x, but in conjunction with high-precision constraints,
parsing time is decreased from 66 seconds to 37 seconds, an additional 1.8x speed-up.
We suspect that this additional gain comes from cache efficiencies (due to the heavily
pruned nature of the chart, the population of commonly-queried span-1 chart cells have
a higher likelihood of remaining in high-speed cache, decreasing overall parsing time),
but we leave empirical verification of this theory to future work.
The third trend we see in Table 4 is that there are significant efficiency differences
when parsing with a right- or left-binarized grammar. The difference in baseline per-
formance has been previously studied (Song, Ding, and Lin 2008; Dunlop, Bodenstab,
and Roark 2010), and our results confirm that a right-binarized grammar is superior for
parsing the WSJ treebank due to the right-branching bias of parse trees in this corpus.
Furthermore, linear constraints were far less effective with a left-binarized grammar,
744
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Table 5
English test set results (WSJ Section 23) for the CONSTRAINEDCYK algorithm with both left- and
right-binarized Markov order-2 grammars.
Constraints F1 Precision Recall Seconds Speed-up
R
ig
h
t None (baseline CYK) 71.7 74.6 69.0 628
Unary(40) 72.1 75.5 69.0 525 1.2x
GHP(40) 75.8 79.0 72.8 75 8.4x
GHP(40) + Unary(40) 76.1 79.8 72.7 57 11.0x
L
e
ft
None (baseline CYK) 72.0 74.8 69.4 1,063
Unary(40) 72.4 75.8 69.4 910 1.2x
GHP(40) 76.1 79.3 73.2 106 10.1x
GHP(40) + Unary(40) 76.4 80.0 73.1 60 17.9x
Table 6
Chinese test set results (PCTB Sections 271?300) for the CONSTRAINEDCYK algorithm with both
left- and right-binarized Markov order-2 grammars.
Constraints F1 Precision Recall Seconds Speed-up
R
ig
h
t None (baseline CYK) 60.5 64.6 56.9 157
Unary(20) 62.3 67.6 57.8 141 1.1x
GHP(20) 66.9 71.4 63.0 17 9.1x
GHP(20) + Unary(20) 68.9 74.4 64.1 15 10.2x
L
e
ft
None (baseline CYK) 60.4 64.5 56.9 269
Unary(20) 62.1 67.2 57.8 234 1.2x
GHP(20) 66.0 70.5 62.1 33 8.2x
GHP(20) + Unary(20) 68.0 73.5 63.2 23 11.7x
requiring a tuning parameter of ? = 24 such that accuracy was not adversely affected
(compare with ? = 12 for right-binarized results). This is also caused by the branching
bias inherent in the treebank. For example, consider a left-binarized grammar and
linear constraints; in the extreme case where ? = 0, only w1 will be in the open set B,
forcing all constituents in the final tree to start at w1. This results in a completely left-
branching tree. With a right-binarized grammar, only the last word position will be in
E, resulting in a completely right-branching tree. Thus, an overly constrained linear-
bounded parse will favor one branching direction over the other. Because the treebank
is biased towards right-branching trees, a right-binarized grammar is more favorable
when linear constraints are applied.
Finally, we note that after all constraints have been applied, the accuracy and
efficiency differences between the two binarization strategies nearly disappear.
To validate the selected operating points on unseen data, we present results on the
test sets for English in Table 5 and Chinese in Table 6.9 We parse individually with global
high-precision and unary constraints, then present the combined result as this gave the
best performance on the development set. In all cases, we see efficiency improvements
greater than 10-fold and accuracy improvements of 4.4 absolute F-measure for English,
9 We used the development set (articles 301?325 of the Penn Chinese treebank) to tune chart constraint
parameters for Chinese, exactly as was done for English.
745
Computational Linguistics Volume 38, Number 4
and 8.4 absolute F-measure for Chinese. Note that these efficiency improvements are
achieved with no additional techniques for speeding up search; modulo the cell closing
mechanism, the CYK parsing is exhaustive?it explores all possible category combina-
tions from all open child cells. Techniques such as coarse-to-fine, A? parsing, or beam-
search are all orthogonal to the current approach, and could be applied in conjunction
to achieve additional speedups.
In the next section, we investigate the use of chart constraints with a number of
high-accuracy parsers, and empirically evaluate the combination of our chart constraint
methods with popular heuristic search methods for parsing. These parsers include the
Charniak parser, the Berkeley parser, and an in-house beam-search parser.
8. High-Accuracy Parsing with Finite-State Chart Constraints
In this section we evaluate the additive efficiency gains provided by finite-state con-
straints to state-of-the-art parsers. We apply B, E, and U constraints to three parsers, all
of which already prune the search space to make decoding time with large grammars
more practical. Each high-accuracy parser that we evaluate also prunes the search space
in a different way?agenda-based search, coarse-to-fine pruning, and beam-search.
Applying finite-state constraints to these three distinct parsers demonstrates how our
constraints interact with other well-known pruning algorithms. In what follows we
describe the pruning inherent in the three parsers and how we apply finite-state con-
straints within each framework.
8.1 Parsers
8.1.1 Charniak Parser. The Charniak (2000) parser is a multi-stage, agenda-driven parser
that can be constrained by pruning edges before they are placed on the agenda. The first
stage of the Charniak parser uses an agenda and a simple PCFG to build a sparse chart,
which is used to limit the search in later stages with the full model. We focus on this
first stage, because it is here that we will be constraining the parser. The edges on the
agenda and in the chart are dotted rules, as described in Section 3.3. When edges are
created, they are pushed onto the agenda. Edges that are popped from the agenda are
placed in the chart, and then combined with other chart entries to create new edges that
are pushed onto the agenda. Once a complete edge spanning the whole string is placed
in the chart, at least one full solution must exist. Instead of terminating the initial chart
population at this point, a technique called ?over-parsing? is used that continues adding
edges to the chart (and agenda) until a parameterized number of additional edges have
been added. A small over-parsing value will heavily constrain the search space of the
later stages within the pipeline, and a large value will often increase accuracy at the
expense of efficiency. Upon reaching the desired number of edges, the next stage of
the pipeline receives the chart as input and any edges remaining on the agenda are
discarded.
We constrain the first stage of the Charniak parser by restricting agenda edges.
When an edge is created for cell (b, e), where b < e, it is not placed on the agenda if
either of the following two conditions hold: 1) wb ? B; or 2) the edge is complete and
we ? E. With these constraints, a large number of edges that would have previously
been considered in the first stage of this pipeline will now be ignored. This allows us
to either reduce the amount of over-parsing, which will increase efficiency, or maintain
the over-parsing threshold and expand the search space in more promising directions
according to the chart constraints. In this article, we have chosen to do the latter. Note
that speed-ups are still observed, presumably due to the parser finding a complete edge
746
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
spanning the whole sentence more quickly, thus leading to slight reductions in total
edges added to the chart.
8.1.2 Berkeley Parser. The Berkeley parser (Petrov and Klein 2007a) is a multi-level coarse-
to-fine parser that operates over a set of coarse-to-fine grammars, G1 . . .Gt. At each
grammar level, the inside and outside constituent probabilities are computed with
coarse grammarGi and used to prune the subsequent search withinGi+1. This continues
until the sentence is parsed with the target grammar Gt. The initial grammar G1 is
a Markov order-0 grammar, and the target grammar Gt is a latent-variable grammar
induced through multiple iterations of splitting and merging non-terminals to maxi-
mize the likelihood of the training data (Petrov and Klein 2007b). This explicit target
grammar is very large, consisting of 4.3 million productions, 2.4 million of which are
lexical productions. We refer to Gt as the Berkeley grammar.
We apply chart constraints to the Berkeley parser during the initial inside pass
with grammar G1. Inside scores are computed via the CONSTRAINEDCYK algorithm
of Algorithm 2 modulo the fact that the standard inside/outside sum over scores is
used in lines 10, 13, and 17 instead of the Viterbi-max. It is unnecessary to constrain
either the subsequent outside pass or the search with the following grammars G2 . . .Gt,
as the coarse-to-fine algorithm only considers constituents remaining in the chart from
the previous coarse grammar. Reducing the population of chart cells during the initial
G1 inside pass consequently prunes the search space for all levels of the coarse-to-fine
search. We also note that even though there are t = 6 grammar levels in our experiments
with the Berkeley parser, exhaustive parsing with G1 consumes nearly 50% of the total
parse time (Petrov, personal communication). Applying chart constraints during this
initial pass is where we see the largest efficiency gain?much more than when chart
constraints supplement coarse-to-fine pruning in subsequent passes.
8.1.3 BUBS Parser. The bottom?up beam-search parser (BUBS) is a variation of the CYK
algorithm where, at each chart cell, all possible edges are sorted by a Figure-of-Merit
(FOM) and only the k-best edges are retained (Bodenstab et al 2011). We follow this set-
up and use the Boundary FOM (Caraballo and Charniak 1997), but do not apply beam-
width prediction in these experiments as chart constraints and beam-width prediction
prune the search space in similar ways (see Bodenstab et al [2011] for a comparison of
the two methods). The BUBS parser is grammar agnostic, so to achieve high accuracy
we parse with the Berkeley latent variable grammar (Gt described in the previous
subsection), yet only require a single pass over the chart. The BUBS parser performs
Viterbi decoding and does not marginalize over the latent variables or compute the
max-rule solution as is done in the Berkeley parser. This leads to a lower F-measure
score in the final results even though both parsers use the same grammar.
In this article, we apply finite-state constraints to the BUBS parser in a fashion
almost identical to the CONSTRAINEDCYK algorithm. Because the BUBS parser is a
beam-search parser, the difference is that instead of retaining the max score for all non-
terminals Ai at each chart cell, we only retain the max score for the k-best non-terminals.
Otherwise, B, E, and U constraints are used to prune the search space in the same way.
8.2 High-Accuracy Parsing Results
Figure 7 displays accuracy and efficiency results of applying three independent
constraints to the three parsers: high precision, quadratically bounded, and unary
constraints. We sweep over possible tuning parameters from unconstrained (baseline
747
Computational Linguistics Volume 38, Number 4
Figure 7
English accuracy and efficiency results of applying high precision, quadratic, and unary
constraints at multiple values of ? to the Charniak, Berkeley, and BUBS parsers, all of which
already heavily prune the search space.
asterisk) to overly constrained such that accuracy is adversely affected. We also plot the
optimal combination of high precision and quadratic constraints (diamond) and the
combination of all three constraints (circle) for each parser which was computed via a
grid search over the joint parameter space.
There are many interesting patterns in Figure 7. First, all three constraints inde-
pendently improve the accuracy and efficiency of all three parsers, with the exception
of accuracy in the Berkeley parser. This is a powerful result considering each of these
parsers is simultaneously performing various alternative forms of pruning, which were
(presumably) tuned for optimal accuracy and efficiency on this same data set. We also
note that the efficiency gains from all three constraints are not identical. In particular,
high precision and quadratic constraints outperforms unary constraints in isolation. But
this should be expected as unary constraints only partially closeO(n) chart cells whereas
both high precision and quadratic constraints affect O(n2) chart cells. Nevertheless,
looking at the optimal point combining all three constraints, we see that adding unary
constraints to begin/end constraints does provide additional gains (in both accuracy
and efficiency) for the BUBS and Charniak parsers.
The Berkeley parser appears to benefit from B and E constraints, but sees almost
no gain from unary constraints. The reason for this has to do with the implementation
details of combining (joining) two child cells within the inner loop of the CYK algorithm
(line 8 in Algorithm 1). In bottom?up CYK parsing, to extend derivations of adjacent
substrings into new constituents spanning the combined string, one can either iterate
over all binary productions in the grammar and test if the new derivation is valid (we
call this ?grammar loop?), or one can take the cross-product of active entries in the cells
spanning the substrings and poll the grammar for possible derivations (we call this
?cross-product?). With the cross-product approach, fewer active entries in either child
cell leads to fewer grammar access operations. Thus, pruning constituents in smaller-
span cells directly affects the overall efficiency of parsing. On the other hand, with the
748
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
grammar loop method there is a constant number of grammar access operations (i.e.,
the number of grammar productions) and the number of active entries in each child
cell has little impact on efficiency. Therefore, with the grammar loop implementation
of the CYK algorithm, pruning techniques such as unary constraints will have very
little impact on the final run-time efficiency of the parser unless the list of grammar
productions is modified given the constraints. For example, alternate iterators over
grammar productions could be created such that they only consider a subset of all
possible productions. If the left child is a span-1 chart cell in U, then only grammar
productions with a POS tag as the left child need to be considered. Looping over
this smaller list, opposed to all possible grammar productions, can reduce the overall
runtime. The Berkeley parser contains the grammar-loop implementation of the CYK
algorithm. Although all grammar productions are iterated over at each cell, the parser
maintains meta-information indicating where non-terminals have been placed in the
chart, allowing it to quickly skip over a subset of the productions that are incompatible
with state of the chart. This optimization improves efficiency, but does not take full
advantage of restricted cell population imposed by unary constraints, and thus does
not benefit as greatly when compared to the BUBS or Charniak parsers.
The second trend we see in Figure 7 is that accuracy actually improves with ad-
ditional constraints. This is expected with the Charniak parser as we keep the amount
of search space fixed in hopes of pursuing more accurate global paths, but both the
Berkeley and BUBS parsers are simply eliminating search paths they would have
otherwise considered. Although it is unusual that pruning leads to higher accuracy
during search, it is not wholly unexpected here as our finite-state tagger makes use of
lexical relationships that the PCFG does not (i.e., lexical relationships based on the linear
string rather than over the syntactic structure). By leveraging this new information to
constrain the search space, we are indirectly improving the quality of the model. We
also suspect that the Berkeley parser sees less of an accuracy improvement than the
BUBS parsers because the coarse-to-fine pruning within the Berkeley parser is more
?globally informed? than the beam-search within the BUBS parser. By leveraging the
coarse-grained inside/outside distribution of trees over the input sentence, the Berkeley
parser can more intelligently prune the search space with respect to the target grammar
and may not benefit from the additional information inherent in the finite-state tagging
model.
The third observation we point out in Figure 7 is that we see no additional gains
from combining high-precision constraints with quadratic complexity constraints. With
all three parsers, high-precision constraints are empirically superior to quadratic con-
straints, even though high-precision constraints come with no guarantee on worst-case
complexity reduction. It is our hypothesis that the additional pruning provided by
quadratic constraints for exhaustive CYK parsing is already removed by the internal
pruning of each of the three high-accuracy parsers. We therefore report testing results
using only high-precision and unary constraints for these high-accuracy parsers.
We apply models tuned on the development set to unseen English test data (WSJ
Section 23) in Table 7, and Chinese test data (PCTB articles 271?300) in Table 8. For
English, we see similar trends as we did on the development set results: Decoding time
is nearly halved when chart constraints are applied to these already heavily constrained
parsers, without any loss in accuracy. We also see independent gains from both unary
and high-precision constraints, and additive efficiency gains when combined.
Applying chart constraints to Chinese parsing in Table 8 gives substantially larger
accuracy and efficiency gains than English for both the BUBS and Berkeley parser. In
particular, the accuracy of the BUBS parser increases by 2.3 points absolute (p = 0.0002),
749
Computational Linguistics Volume 38, Number 4
Table 7
English test set results (WSJ Section 23) applying sentence-level high precision and unary
constraints to three parsers with parameter settings tuned on development data.
Parser F1 Precision Recall Seconds Speed-up
BUBS (2010) 88.4 88.5 88.3 586
+ Unary(100) 88.5 88.7 88.3 486 1.2x
+ HP(0.9) 88.7 88.9 88.6 349 1.7x
+ HP(0.9) + Unary(100) 88.7 89.0 88.4 283 2.1x
Charniak (2000) 89.7 89.7 89.6 1,116
+ Unary(100) 89.8 89.8 89.7 900 1.2x
+ HP(0.8) 89.8 90.0 89.6 716 1.6x
+ HP(0.8) + Unary(100) 89.7 90.0 89.5 679 1.6x
Berkeley (2007) 90.2 90.3 90.0 564
+ Unary(125) 90.1 90.3 89.9 495 1.1x
+ HP(0.7) 90.2 90.4 90.0 320 1.8x
+ HP(0.7) + Unary(125) 90.2 90.4 89.9 289 2.0x
Table 8
Chinese test set results (PCTB articles 271?300) applying sentence-level high-precision and unary
constraints to two parsers with parameter settings tuned on development data.
Parser F1 Precision Recall Seconds Speed-up
BUBS (2010) 79.5 79.5 79.1 169
+ Unary(50) 80.7 82.1 79.4 153 1.1x
+ HP(0.8) 81.1 81.5 80.7 75 2.3x
+ HP(0.8) + Unary(50) 81.8 83.1 80.5 44 3.8x
Berkeley (2007) 83.9 84.5 83.3 141
+ Unary(50) 84.5 85.9 83.0 125 1.1x
+ HP(0.7) 84.5 85.1 83.8 64 2.2x
+ HP(0.7) + Unary(50) 84.7 86.1 83.4 57 2.5x
and the Berkeley parser increases by 0.8 points absolute to 84.7 (p = 0.0119), the highest
accuracy we are aware of for an individual model on this data set.10,11 These increases
relative to English may be surprising as chart constraint tagging accuracy for Chinese
is worse than English (see Table 3). We attribute this large gain to the lower baseline
accuracy of parsing with the Chinese treebank, allowing our method to contribute
additional syntactic constraints that were otherwise unmodeled by the PCFG.
9. Conclusion and Future Work
We have presented finite-state pre-processing methods to constrain context-free
parsing that reduce both the worst-case complexity and overall run time. Four unique
10 Significance was tested using stratified shuffling.
11 Zhang et al (2009) report an F-measure of 85.5 with a k-best combination of parsers, and Burkett, Blitzer,
and Klein (2010) report an F-measure of 86.0 by leveraging parallel English data for training, but our
model is trained from the Chinese treebank alone and is integrated into the Berkeley parser, making it
very efficient.
750
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
bounding methods were presented, with high-precision constraints showing superior
performance in empirical trials. Applying these constraints to context-free parsing
increased efficiency by over 20 times for exhaustive CYK parsing, and nearly doubled
the speed of the Charniak and Berkeley parsers?both of which have been previously
tuned for optimal accuracy/efficiency performance. We have shown that our method
generalizes across multiple grammars and languages, and that constraining both
multi-word chart cells and single-word chart cells produces additive efficiency gains.
In future work we plan to investigate additional methods to make context-free
parsing more efficient. In particular, we believe the dynamic programming chart could
be constrained even further if we take into account the population and structure of
chart cells at a finer level. For example, the B and E constraints we have presented here
do not take into account the height of the constituent they are predicting. Instead, they
simply open or close the entire diagonal in the chart. Refining this structured prediction
to bins, as is done in Zhang et al (2010), or classifying chart cells directly, as is done
in Bodenstab et al (2011), has shown promise, but we believe that further research in
this area would yield addition efficiency gains. In particular, those two papers do not
differentiate between non-terminals when opening or closing cells, and we hypothesize
that learning separate finite-state classifiers for automatically derived clusters of non-
terminals may increase performance.
Acknowledgments
Portions of this paper have appeared in
conference papers: Roark and Hollingshead
(2008), Roark and Hollingshead (2009), and
Bodenstab, Hollingshead, and Roark (2011).
We thank three anonymous reviewers for
their insightful comments and suggestions.
Also thanks to Aaron Dunlop for being so
swell. This research was supported in part
by NSF grants IIS-0447214 and IIS-0811745,
and DARPA grant HR0011-09-1-0041.
Any opinions, findings, conclusions,
or recommendations expressed in this
publication are those of the authors and
do not necessarily reflect the views of the
NSF or DARPA.
References
Bangalore, Srinivas and Aravind K. Joshi.
1999. Supertagging: an approach to
almost parsing. Computational Linguistics,
25:237?265.
Bergsma, Shane and Colin Cherry. 2010.
Fast and accurate arc filtering for
dependency parsing. In Proceedings
of the 23rd International Conference on
Computational Linguistics (Coling 2010),
pages 53?61, Beijing.
Black, E., S. Abney, S. Flickenger,
C. Gdaniec, C. Grishman, P. Harrison,
D. Hindle, R. Ingria, F. Jelinek, J. Klavans,
M. Liberman, M. Marcus, S. Roukos,
B. Santorini, and T. Strzalkowski. 1991.
Procedure for quantitatively comparing
the syntactic coverage of English
grammars. In Proceedings of the Workshop
on Speech and Natural Language, HLT ?91,
pages 306?311, Pacific Grove, CA.
Bodenstab, Nathan, Aaron Dunlop, Keith
Hall, and Brian Roark. 2011. Beam-width
prediction for efficient context-free
parsing. In Proceedings of the 49th Annual
Meeting of the Association for Computational
Linguistics, pages 440?449, Portland, OR.
Bodenstab, Nathan, Kristy Hollingshead,
and Brian Roark. 2011. Unary constraints
for efficient context-free parsing. In
Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics,
pages 676?681, Portland, OR.
Burkett, David, John Blitzer, and Dan Klein.
2010. Joint parsing and alignment with
weakly synchronized grammars. In Human
Language Technologies: The 2010 Annual
Conference of the North American Chapter
of the Association for Computational
Linguistics, HLT ?10, pages 127?135,
Los Angeles, CA.
Caraballo, Sharon A. and Eugene Charniak.
1997. New figures of merit for best-first
probabilistic chart parsing. Computational
Linguistics, 24:275?298.
Charniak, Eugene. 2000. A maximum-
entropy-inspired parser. In Proceedings of
the 1st Conference of the North American
Chapter of the Association for Computational
Linguistics, pages 132?139, Seattle, WA.
Charniak, Eugene and Mark Johnson. 2005.
Coarse-to-fine n-best parsing and MaxEnt
751
Computational Linguistics Volume 38, Number 4
discriminative reranking. In Proceedings of
the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 173?180, Sydney.
Cherry, Colin and Shane Bergsma. 2011.
Joint training of dependency parsing
filters through latent support vector
machines. In Proceedings of the 49th Annual
Meeting of the Association for Computational
Linguistics: Human Language Technologies,
pages 200?205, Toulouse.
Clark, Stephen and James R. Curran.
2004. The importance of supertagging
for wide-coverage CCG parsing. In
Proceedings of COLING, pages 282?288,
Geneva.
Cocke, John and Jacob T. Schwartz. 1970.
Programming languages and their
compilers: Preliminary notes. Courant
Institute of Mathematical Sciences,
New York University.
Collins, Michael. 2002. Discriminative
training methods for hidden Markov
models: Theory and experiments with
perceptron algorithms. In Proceedings
of the Conference on Empirical Methods in
Natural Language Processing (EMNLP),
pages 1?8, Philadelphia, PA.
Djordjevic, Bojan, James R. Curran, and
Stephen Clark. 2007. Improving the
efficiency of a wide-coverage CCG parser.
In Proceedings of the 10th International
Conference on Parsing Technologies,
IWPT ?07, pages 39?47, Prague.
Dreyer, Markus, David A. Smith, and
Noah A. Smith. 2006. Vine parsing and
minimum risk reranking for speed and
precision. In Proceedings of the Tenth
Conference on Computational Natural
Language Learning (CoNLL-X),
pages 201?205, New York, NY.
Dunlop, Aaron, Nathan Bodenstab, and
Brian Roark. 2010. Reducing the grammar
constant: an analysis of CYK parsing
efficiency. Technical report CSLU-2010-02,
Oregon Health & Science University,
Beaverton, OR.
Dunlop, Aaron, Nathan Bodenstab,
and Brian Roark. 2011. Efficient
matrix-encoded grammars and low
latency parallelization strategies for CYK.
In Proceedings of the 12th International
Conference on Parsing Technologies (IWPT),
pages 163?174, Dublin.
Earley, Jay. 1970. An efficient context-free
parsing algorithm. Communications of the
ACM, 6(8):451?455.
Eisner, Jason and Noah A. Smith. 2005.
Parsing with soft and hard constraints on
dependency length. In Proceedings of the
Ninth International Workshop on Parsing
Technology (IWPT), pages 30?41,
Vancouver.
Glaysher, Elliot and Dan Moldovan. 2006.
Speeding up full syntactic parsing by
leveraging partial parsing decisions. In
Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions, pages 295?300,
Sydney.
Hollingshead, Kristy, Seeger Fisher, and
Brian Roark. 2005. Comparing and
combining finite-state and context-free
parsers. In Proceedings of the Human
Language Technology Conference and the
Conference on Empirical Methods in Natural
Language Processing (HLT/EMNLP),
pages 787?794, Vancouver.
Hollingshead, Kristy and Brian Roark.
2007. Pipeline iteration. In Proceedings
of the 45th Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 952?959, Prague.
Kasami, Tadao. 1965. An efficient
recognition and syntax analysis
algorithm for context-free languages.
Technical report AFCRL-65-758, Air Force
Cambridge Research Lab, Bedford, MA.
Marcus, Mitchell P., Mary Ann
Marcinkiewicz, and Beatrice Santorini.
1993. Building a large annotated corpus of
English: The Penn treebank. Computational
Linguistics, 19:313?330.
McDonald, Ryan, Fernando Pereira,
Kiril Ribarov, and Jan Hajic. 2005.
Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of
Human Language Technology Conference and
Conference on Empirical Methods in Natural
Language Processing (HLT/EMNLP),
pages 523?530, Vancouver.
Nivre, Joakim. 2006. Constraints on
non-projective dependency parsing.
In Proceedings of the 11th Conference of the
European Chapter of the Association for
Computational Linguistics (EACL),
pages 73?80, Trento.
Petrov, Slav and Dan Klein. 2007a. Improved
inference for unlexicalized parsing. In
Proceedings of Human Language Technologies
2007: The Conference of the North American
Chapter of the Association for Computational
Linguistics (HLT-NAACL), pages 404?411,
Rochester, NY.
Petrov, Slav and Dan Klein. 2007b. Learning
and inference for hierarchically split
PCFGs. In Proceedings of the 22nd National
Conference on Artificial Intelligence -
Volume 2, pages 1663?1666, Vancouver.
752
Roark, Hollingshead, and Bodenstab Chart Constraints for Reduced Complexity Parsing
Ratnaparkhi, Adwait. 1999. Learning to
parse natural language with maximum
entropy models.Machine Learning,
34(1-3):151?175.
Roark, Brian and Kristy Hollingshead.
2008. Classifying chart cells for quadratic
complexity context-free inference. In
Proceedings of the 22nd International
Conference on Computational Linguistics
(COLING), pages 745?752, Manchester.
Roark, Brian and Kristy Hollingshead. 2009.
Linear complexity context-free parsing
pipelines via chart constraints. In
Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North
American Chapter of the Association for
Computational Linguistics (HLT-NAACL),
pages 647?655, Boulder, CO.
Sha, Fei and Fernando Pereira. 2003. Shallow
parsing with conditional random fields. In
Proceedings of HLT-NAACL, pages 134?141,
Edmonton.
Sogaard, Anders and Jonas Kuhn. 2009.
Using a maximum entropy-based tagger
to improve a very fast vine parser.
In Proceedings of the 11th International
Conference on Parsing Technologies,
IWPT ?09, pages 206?209, Paris.
Song, Xinying, Shilin Ding, and Chin-Yew
Lin. 2008. Better binarization for the CKY
parsing. In Proceedings of the Conference on
Empirical Methods in Natural Language
Processing, EMNLP ?08, pages 167?176,
Honolulu, HI.
Weiss, David, Benjamin Sapp, and Ben
Taskar. 2010. Sidestepping intractable
inference with structured ensemble
cascades. In Proceedings of NIPS,
pages 2415?2423, Vancouver.
Weiss, David and Benjamin Taskar. 2010.
Structured prediction cascades. Journal of
Machine Learning Research - Proceedings
Track, 9:916?923.
Xue, Naiwen, Fei Xia, Fu-dong Chiou, and
Marta Palmer. 2005. The Penn Chinese
treebank: Phrase structure annotation
of a large corpus. Natural Language
Engingeering, 11:207?238.
Younger, Daniel H. 1967. Recognition and
parsing of context-free languages in time
n3. Information and Control, 10(2):189?208.
Zhang, Hui, Min Zhang, Chew Lim Tan, and
Haizhou Li. 2009. K-best combination of
syntactic parsers. In Proceedings of the 2009
Conference on Empirical Methods in Natural
Language Processing: Volume 3, EMNLP ?09,
pages 1552?1560, Singapore.
Zhang, Yue, Byung Gyu Ahn, Stephen Clark,
Curt Van Wyk, James R. Curran, and
Laura Rimell. 2010. Chart pruning for
fast lexicalised-grammar parsing. In
Proceedings of the 23rd International
Conference on Computational Linguistics,
pages 1472?1479, Beijing.
753

Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 440?449,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Beam-Width Prediction for Efficient Context-Free Parsing
Nathan Bodenstab? Aaron Dunlop? Keith Hall? and Brian Roark?
? Center for Spoken Language Understanding, Oregon Health & Science University, Portland, OR
?Google, Inc., Zurich, Switzerland
{bodensta,dunlopa,roark}@cslu.ogi.edu kbhall@google.com
Abstract
Efficient decoding for syntactic parsing has
become a necessary research area as statisti-
cal grammars grow in accuracy and size and
as more NLP applications leverage syntac-
tic analyses. We review prior methods for
pruning and then present a new framework
that unifies their strengths into a single ap-
proach. Using a log linear model, we learn
the optimal beam-search pruning parameters
for each CYK chart cell, effectively predicting
the most promising areas of the model space
to explore. We demonstrate that our method
is faster than coarse-to-fine pruning, exempli-
fied in both the Charniak and Berkeley parsers,
by empirically comparing our parser to the
Berkeley parser using the same grammar and
under identical operating conditions.
1 Introduction
Statistical constituent parsers have gradually in-
creased in accuracy over the past ten years. This
accuracy increase has opened the door to automati-
cally derived syntactic information within a number
of NLP tasks. Prior work incorporating parse struc-
ture into machine translation (Chiang, 2010) and Se-
mantic Role Labeling (Tsai et al, 2005; Punyakanok
et al, 2008) indicate that such hierarchical structure
can have great benefit over shallow labeling tech-
niques like chunking and part-of-speech tagging.
Although syntax is becoming increasingly impor-
tant for large-scale NLP applications, constituent
parsing is slow ? too slow to scale to the size of
many potential consumer applications. The exhaus-
tive CYK algorithm has computational complexity
O(n3|G|) where n is the length of the sentence and
|G| is the number of grammar productions, a non-
negligible constant. Increases in accuracy have pri-
marily been accomplished through an increase in
the size of the grammar, allowing individual gram-
mar rules to be more sensitive to their surround-
ing context, at a considerable cost in efficiency.
Grammar transformation techniques such as linguis-
tically inspired non-terminal annotations (Johnson,
1998; Klein and Manning, 2003b) and latent vari-
able grammars (Matsuzaki et al, 2005; Petrov et al,
2006) have increased the grammar size |G| from a
few thousand rules to several million in an explic-
itly enumerable grammar, or even more in an im-
plicit grammar. Exhaustive search for the maximum
likelihood parse tree with a state-of-the-art grammar
can require over a minute of processing for a sin-
gle sentence of 25 words, an unacceptable amount
of time for real-time applications or when process-
ing millions of sentences. Deterministic algorithms
for dependency parsing exist that can extract syntac-
tic dependency structure very quickly (Nivre, 2008),
but this approach is often undesirable as constituent
parsers are more accurate and more adaptable to new
domains (Petrov et al, 2010).
The most accurate constituent parsers, e.g., Char-
niak (2000), Petrov and Klein (2007a), make use
of approximate inference, limiting their search to
a fraction of the total search space and achieving
speeds of between one and four newspaper sen-
tences per second. The paradigm for building state-
of-the-art parsing models is to first design a model
structure that can achieve high accuracy and then,
after the model has been built, design effective ap-
proximate inference methods around that particu-
lar model; e.g., coarse-to-fine non-terminal hierar-
chies for a given model, or agenda-based methods
440
that are empirically tuned to achieve acceptable ef-
ficiency/accuracy operating points. While both of
the above mentioned papers use the CYK dynamic
programming algorithm to search through possible
solutions, their particular methods of approximate
inference are quite distinct.
In this paper, we examine a general approach to
approximate inference in constituent parsing that
learns cell-specific thresholds for arbitrary gram-
mars. For each cell in the CYK chart, we sort all
potential constituents in a local agenda, ordered by
an estimate of their posterior probability. Given fea-
tures extracted from the chart cell context ? e.g.,
span width; POS-tags and words surrounding the
boundary of the cell ? we train a log linear model
to predict how many constituents should be popped
from the local agenda and added to the chart. As
a special case of this approach, we simply pre-
dict whether the number to add should be zero or
greater than zero, in which case the method can be
seen as a cell-by-cell generalization of Roark and
Hollingshead?s (2008; 2009) tagger-derived Chart
Constraints. More generally, instead of a binary
classification decision, we can also use this method
to predict the desired cell population directly and
get cell closure for free when the classifier predicts
a beam-width of zero. In addition, we use a non-
symmetric loss function during optimization to ac-
count for the imbalance between over-predicting or
under-predicting the beam-width.
A key feature of our approach is that it does
not rely upon reference syntactic annotations when
learning to search. Rather, the beam-width predic-
tion model is trained to learn the rank of constituents
in the maximum likelihood trees.1 We will illus-
trate this by presenting results using a latent-variable
grammar, for which there is no ?true? reference la-
tent variable parse. We simply parse sections 2-21
of the WSJ treebank and train our search models
from the output of these trees, with no prior knowl-
edge of the non-terminal set or other grammar char-
acteristics to guide the process. Hence, this ap-
1Note that we do not call this method ?unsupervised? be-
cause all grammars used in this paper are induced from super-
vised data, although our framework can also accommodate un-
supervised grammars. We emphasize that we are learning to
search using only maximum likelihood trees, not that we are
doing unsupervised parsing.
Figure 1: Inside (grey) and outside (white) representations of
an example chart edge Ni,j .
proach is broadly applicable to a wide range of sce-
narios, including tuning the search to new domains
where domain mismatch may yield very different ef-
ficiency/accuracy operating points.
In the next section, we present prior work on
approximate inference in parsing, and discuss how
our method to learn optimal beam-search param-
eters unite many of their strengths into a single
framework. We then explore using our approach to
open or close cells in the chart as an alternative to
Roark and Hollingshead (2008; 2009). Finally, we
present results which combine cell closure and adap-
tive beam-width prediction to achieve the most effi-
cient parser.
2 Background
2.1 Preliminaries and notation
Let S = w1 . . . w|S| represent an input string of
|S| words. Let wi,j denote the substring from word
wi+1 to wj ; i.e., S = w0,|S|. We use the term chart
edge to refer to a non-terminal spanning a specific
substring of the input sentence. Let Ni,j denote the
edge labeled with non-terminalN spanning wi,j , for
example NP3,7. We define an edge?s figure-of-merit
(FOM) as an estimate of the product of its inside
(?) and outside (?) scores, conceptually the relative
merit the edge has to participate in the final parse
tree (see Figure 1). More formally:
?(Ni,j) = P (w0,i, Ni,j , wj,n)
?(Ni,j) = P (wi,j |N)
FOM(Ni,j) = ??(Ni,j)??(Ni,j)
441
With bottom-up parsing, the true inside probability
is accumulated and ?(Ni,j) does not need to be esti-
mated, improving the FOMs ability to represent the
true inside/outside distribution.
In this paper, we use a modified version of the
Caraballo and Charniak Boundary FOM (1998)
for local edge comparison, which computes ??(Ni,j)
using POS forward-backward scores and POS-to-
nonterminal constituent boundary transition proba-
bilities. Details can be found in (?).
We also note that in this paper we only use
the FOM scoring function to rank constituents in
a local agenda. Alternative approaches to rank-
ing competitors are also possible, such as Learning
as Search Optimization (Daume? and Marcu, 2005).
The method we present in this paper to learn the op-
timal beam-search parameters is applicable to any
ranking function, and we demonstrate this by com-
puting results with both the Boundary FOM and
only the inside probability in Section 6.
2.2 Agenda-based parsing
Agenda-based parsers maintain a global agenda of
edges, ranked by FOM score. At each iteration, the
highest-scoring edge is popped off of the agenda,
added to the chart, and combined with other edges
already in the chart. The agenda-based approach
includes best-first parsing (Bobrow, 1990) and A*
parsing (Klein and Manning, 2003a), which differ
in whether an admissible FOM estimate ??(Ni,j) is
required. A* uses an admissible FOM, and thus
guarantees finding the maximum likelihood parse,
whereas an inadmissible heuristic (best-first) may
require less exploration of the search space. Much
work has been pursued in both admissible and in-
admissible heuristics for agenda parsing (Caraballo
and Charniak, 1998; Klein and Manning, 2003a;
Pauls et al, 2010).
In this paper, we also make use of agendas, but
at a local rather than a global level. We maintain an
agenda for each cell, which has two significant ben-
efits: 1) Competing edges can be compared directly,
avoiding the difficulty inherent in agenda-based ap-
proaches of comparing edges of radically differ-
ent span lengths and characteristics; and 2) Since
the agendas are very small, the overhead of agenda
maintenance ? a large component of agenda-based
parse time ? is minimal.
2.3 Beam-search parsing
CYK parsing with a beam-search is a local pruning
strategy, comparing edges within the same chart cell.
The beam-width can be defined in terms of a thresh-
old in the number of edges allowed, or in terms of
a threshold on the difference in probability relative
to the highest scoring edge (Collins, 1999; Zhang et
al., 2010). For the current paper, we use both kinds
of thresholds, avoiding pathological cases that each
individual criteria is prone to encounter. Further, un-
like most beam-search approaches we will make use
of a FOM estimate of the posterior probability of an
edge, defined above, as our ranking function. Fi-
nally, we will learn log linear models to assign cell-
specific thresholds, rather than relying on a single
search parameter.
2.4 Coarse-to-Fine Parsing
Coarse-to-fine parsing, also known as multiple pass
parsing (Goodman, 1997; Charniak, 2000; Char-
niak and Johnson, 2005), first parses the input sen-
tence with a simplified (coarse) version of the tar-
get (fine) grammar in which multiple non-terminals
are merged into a single state. Since the coarse
grammar is quite small, parsing is much faster than
with the fine grammar, and can quickly yield an es-
timate of the outside probability ?(?) for use in sub-
sequent agenda or beam-search parsing with the fine
grammar. This approach can also be used iteratively
with grammars of increasing complexity (Petrov and
Klein, 2007a).
Building a coarse grammar from a fine gram-
mar is a non-trivial problem, and most often ap-
proached with detailed knowledge of the fine gram-
mar being used. For example, Goodman (1997)
suggests using a coarse grammar consisting of reg-
ular non-terminals, such as NP and VP, and then
non-terminals augmented with head-word informa-
tion for the more accurate second-pass grammar.
Such an approach is followed by Charniak (2000) as
well. Petrov and Klein (2007a) derive coarse gram-
mars in a more statistically principled way, although
the technique is closely tied to their latent variable
grammar representation.
To the extent that our cell-specific threshold clas-
sifier predicts that a chart cell should contain zero
edges or more than zero edges, it is making coarse
442
predictions about the unlabeled constituent structure
of the target parse tree. This aspect of our work is
can be viewed as a coarse-to-fine process, though
without considering specific grammatical categories
or rule productions.
2.5 Chart Constraints
Roark and Hollingshead (2008; 2009) introduced
a pruning technique that ignores entire chart cells
based on lexical and POS features of the input sen-
tence. They train two finite-state binary taggers:
one that allows multi-word constituents to start at
a word, and one that allows constituents to end at a
word. Given these tags, it is straightforward to com-
pletely skip many chart cells during processing.
In this paper, instead of tagging word positions to
infer valid constituent spans, we classify chart cells
directly. We further generalize this cell classification
to predict the beam-width of the chart cell, where a
beam-width of zero indicates that the cell is com-
pletely closed. We discuss this in detail in the next
section.
3 Open/Closed Cell Classification
3.1 Constituent Closure
We first look at the binary classification of chart cells
as either open or closed to full constituents, and pre-
dict this value from the input sentence alone. This
is the same problem that Roark and Hollingshead
(2008; 2009) solve with Chart Constraints; however,
where they classify lexical items as either beginning
or ending a constituent, we classify individual chart
cells as open or closed, an approach we call Con-
stituent Closure. Although the number of classifi-
cations scales quadratically with our approach, the
total parse time is still dominated by the O(n3|G|)
parsing complexity and we find that the added level
of specificity reduces the search space significantly.
To learn to classify a chart cell spanning words
wi+1 . . . wj of a sentence S as open or closed to full
constituents, we first map cells in the training corpus
to tuples:
?(S, i, j) = (x, y) (1)
where x is a feature-vector representation of the
chart cell and y is the target class 1 if the cell con-
tains an edge from the maximum likelihood parse
tree, 0 otherwise. The feature vector x is encoded
with the chart cell?s absolute and relative span width,
as well as unigram and bigram lexical and part-of-
speech tag items from wi?1 . . . wj+2.
Given feature/target tuples (x, y) for every chart
cell in every sentence of a training corpus ? , we train
a weight vector ? using the averaged perceptron al-
gorithm (Collins, 2002) to learn an open/closed bi-
nary decision boundary:
?? = argmin
?
?
(x,y)??(?)
L?(H(? ? x), y) (2)
where H(?) is the unit step function: 1 if the inner
product ? ?x > 0, and 0 otherwise; and L?(?, ?) is an
asymmetric loss function, defined below.
When predicting cell closure, all misclassifica-
tions are not equal. If we leave open a cell which
contains no edges in the maximum likelihood (ML)
parse, we incur the cost of additional processing, but
are still able to recover the ML tree. However, if we
close a chart cell which contains an ML edge, search
errors occur. To deal with this imbalance, we intro-
duce an asymmetric loss functionL?(?, ?) to penalize
false-negatives more severely during training.
L?(h, y) =
?
??
??
0 if h = y
1 if h > y
? if h < y
(3)
We found the value ? = 102 to give the best per-
formance on our development set, and we use this
value in all of our experiments.
Figures 2a and 2b compare the pruned charts of
Chart Constraints and Constituent Closure for a sin-
gle sentence in the development set. Note that both
of these methods are predicting where a complete
constituent may be located in the chart, not partial
constituents headed by factored nonterminals within
a binarized grammar. Depending on the grammar
factorization (right or left) we can infer chart cells
that are restricted to only edges with a factored left-
hand-side non-terminal. In Figure 2 these chart cells
are colored gray. Note that Constituent Closure re-
duces the number of completely open cells consider-
ably vs. Chart Constraints, and the number of cells
open to factored categories somewhat.
443
3.2 Complete Closure
Alternatively, we can predict whether a chart cell
contains any edge, either a partial or a full con-
stituent, an approach we call Complete Closure.
This is a more difficult classification problem as par-
tial constituents occur in a variety of contexts. Nev-
ertheless, learning this directly allows us to remove a
large number of internal chart cells from considera-
tion, since no additional cells need to be left open to
partial constituents. The learning algorithm is iden-
tical to Equation 2, but training examples are now
assigned a positive label if the chart cell contains any
edge from the binarized maximum likelihood tree.
Figure 2c gives a visual representation of Complete
Closure for the same sentence; the number of com-
pletely open cells increases somewhat, but the total
number of open cells (including those open to fac-
tored categories) is greatly reduced.
We compare the effectiveness of Constituent Clo-
sure, Complete Closure, and Chart Constraints, by
decreasing the percentage of chart cells closed un-
til accuracy over all sentences in our development
set start to decline. For Constituent and Complete
Closure, we also vary the loss function, adjusting
the relative penalty between a false-negative (clos-
ing off a chart cell that contains a maximum like-
lihood edge) and a false-positive. Results show that
using Chart Constrains as a baseline, we prune (skip)
33% of the total chart cells. Constituent Closure im-
proves on this baseline only slightly (36%), but we
see our biggest gains with Complete Closure, which
prunes 56% of all chart cells in the development set.
All of these open/closed cell classification meth-
ods can improve the efficiency of the exhaustive
CYK algorithm, or any of the approximate infer-
ence methods mentioned in Section 2. We empir-
ically evaluate them when applied to CYK parsing
and beam-search parsing in Section 6.
4 Beam-Width Prediction
The cell-closing approaches discussed in Section 3
make binary decisions to either allow or completely
block all edges in each cell. This all-on/all-off tactic
ignores the characteristics of the local cell popula-
tion, which, given a large statistical grammar, may
contain hundred of edges, even if very improbable.
Retaining all of these partial derivations forces the
(a) Chart Constraints (Roark and Hollingshead, 2009)
(b) Constituent Closure (this paper)
(c) Complete Closure (this paper)
Figure 2: Comparison of Chart Constraints (Roark and
Hollingshead, 2009) to Constituent and Complete Closure for a
single example sentence. Black cells are open to all edges while
grey cells only allow factored edges (incomplete constituents).
search in larger spans to continue down improbable
paths, adversely affecting efficiency. We can further
improve parsing speed in these open cells by lever-
aging local pruning methods, such as beam-search.
When parsing with a beam-search, finding the op-
timal beam-width threshold(s) to balance speed and
accuracy is a necessary step. As mentioned in Sec-
444
tion 2.3, two variations of the beam-width are of-
ten considered: a fixed number of allowed edges,
or a relative probability difference from the highest
scoring local edge. For the remainder of this pa-
per we fix the relative probability threshold for all
experiments and focus on adapting the number of
allowed edges per cell. We will refer to this number-
of-allowed-edges value as the beam-width, notated
by b, and leave adaptation of the relative probability
difference to future work.
The standard way to tune the beam-width is a sim-
ple sweep over possible values until accuracy on
a heldout data set starts to decline. The optimal
point will necessarily be very conservative, allowing
outliers (sentences or sub-phrases with above aver-
age ambiguity) to stay within the beam and produce
valid parse trees. The majority of chart cells will
require much fewer than b entries to find the max-
imum likelihood (ML) edge, yet, constrained by a
constant beam-width, the cell will continue to be
filled with unfruitful edges, exponentially increasing
downstream computation.
For example, when parsing with the Berkeley
latent-variable grammar and Boundary FOM, we
find we can reduce the global beam-width b to 15
edges in each cell before accuracy starts to decline.
However we find that 73% of the ML edges are
ranked first in their cell and 96% are ranked in the
top three. Thus, in 24 of every 25 cells, 80% of the
edges are unnecessary (12 of the top 15). Clearly,
it would be advantageous to adapt the beam-width
such that it is restrictive when we are confident in
the FOM ranking and more forgiving in ambiguous
contexts.
To address this problem, we learn the optimal
beam-width for each chart cell directly. We define
Ri,j as the rank of the ML edge in the chart cell
spanning wi+1 . . . wj . If no ML edge exists in the
cell, then Ri,j = 0. Given a global maximum beam-
width b, we train b different binary classifiers, each
using separate mapping functions ?k, where the tar-
get value y produced by ?k is 1 if Ri,j > k and 0
otherwise.
The same asymmetry noted in Section 3 applies
in this task as well. When in doubt, we prefer to
over-predict the beam-width and risk an increase in
processing time opposed to under-predicting at the
expense of accuracy. Thus we use the same loss
function L?, this time training several classifiers:
??k = argmin
?
?
(x,y)??k(?)
L?(H(? ? x), y) (4)
Note that in Equation 4 when k = 0, we re-
cover the open/closed cell classification of Equa-
tion 2, since a beam width of 0 indicates that the
chart cell is completely closed.
During decoding, we assign the beam-width
for chart cell spanning wi+1 . . . wj given models
?0, ?1, ...?b?1 by finding the lowest value k such that
the binary classifier ?k classifiesRi,j ? k. If no such
k exists, R?i,j is set to the maximum beam-width
value b:
R?i,j = argmin
k
?k ? xi ? 0 (5)
In Equation 5 we assume there are b unique clas-
sifiers, one for each possible beam-width value be-
tween 0 and b? 1, but this level of granularity is not
required. Choosing the number of classification bins
to minimize total parsing time is dependent on the
FOM function and how it ranks ML edges. With the
Boundary FOM we use in this paper, 97.8% of ML
edges have a local rank less than five and we find that
the added cost of computing b decision boundaries
for each cell is not worth the added specificity. We
searched over possible classification bins and found
that training four classifiers with beam-width deci-
sion boundaries at 0, 1, 2, and 4 is faster than 15 in-
dividual classifiers and more memory efficient, since
each model ?k has over 800,000 parameters. All
beam-width prediction results reported in this paper
use these settings.
Figure 3 is a visual representation of beam-width
prediction on a single sentence of the development
set using the Berkeley latent-variable grammar and
Boundary FOM. In this figure, the gray scale repre-
sents the relative size of the beam-width, black being
the maximum beam-width value, b, and the lightest
gray being a beam-width of size one. We can see
from this figure that very few chart cells are classi-
fied as needing the full 15 edges, apart from span-1
cells which we do not classify.
445
Figure 3: Visualization of Beam-Width Prediction for a single example sentence. The grey scale represents the size of the predicted
beam-width: white is 0 (cell is skipped) and black is the maximum value b (b=15 in this example).
5 Experimental Setup
We run all experiments on the WSJ treebank (Mar-
cus et al, 1999) using the standard splits: section
2-21 for training, section 22 for development, and
section 23 for testing. We preprocess the treebank
by removing empty nodes, temporal labels, and spu-
rious unary productions (X?X), as is standard in
published works on syntactic parsing.
The pruning methods we present in this paper can
be used to parse with any grammar. To achieve state-
of-the-art accuracy levels, we parse with the Berke-
ley SM6 latent-variable grammar (Petrov and Klein,
2007b) where the original treebank non-terminals
are automatically split into subclasses to optimize
parsing accuracy. This is an explicit grammar con-
sisting of 4.3 million productions, 2.4 million of
which are lexical productions. Exhaustive CYK
parsing with the grammar takes more than a minute
per sentence.
Accuracy is computed from the 1-best Viterbi
(max) tree extracted from the chart. Alternative de-
coding methods, such as marginalizing over the la-
tent variables in the grammar or MaxRule decod-
ing (Petrov and Klein, 2007a) are certainly possible
in our framework, but it is unknown how effective
these methods will be given the heavily pruned na-
ture of the chart. We leave investigation of this to
future work. We compute the precision and recall
of constituents from the 1-best Viterbi trees using
the standard EVALB script (?), which ignores punc-
tuation and the root symbol. Accuracy results are
reported as F-measure (F1), the harmonic mean be-
tween precision and recall.
We ran all timing tests on an Intel 3.00GHz pro-
cessor with 6MB of cache and 16GB of memory.
Our parser is written in Java and publicly available
at http://nlp.csee.ogi.edu.
6 Results
We empirically demonstrate the advantages of our
pruning methods by comparing the total parse time
of each system, including FOM initialization, chart
cell classification, and beam-width prediction. The
parse times reported for Chart Constraints do not in-
clude tagging times as we were provided with this
pre-tagged data, but tagging all of Section 22 takes
less than three seconds and we choose to ignore this
contribution for simplicity.
Figure 4 contains a timing comparison of the three
components of our final parser: Boundary FOM ini-
tialization (which includes the forward-backward al-
gorithm over ambiguous part-of-speech tags), beam-
446
Figure 4: Timing breakdown by sentence length for major
components of our parser.
width prediction, and the final beam-search, includ-
ing 1-best extraction. We bin these relative times
with respect to sentence length to see how each com-
ponent scales with the number of input words. As
expected, theO(n3|G|) beam-search begins to dom-
inate as the sentence length grows, but Boundary
FOM initialization is not cheap, and absorbs, on
average, 20% of the total parse time. Beam-width
prediction, on the other hand, is almost negligible
in terms of processing time even though it scales
quadratically with the length of the sentence.
We compare the accuracy degradation of beam-
width prediction and Chart Constraints in Figure 5
as we incrementally tighten their respective prun-
ing parameters. We also include the baseline beam-
search parser with Boundary FOM in this figure
to demonstrate the accuracy/speed trade-off of ad-
justing a global beam-width alone. In this figure
we see that the knee of the beam-width prediction
curve (Beam-Predict) extends substantially further
to the left before accuracy declines, indicating that
our pruning method is intelligently removing a sig-
nificant portion of the search space that remains un-
pruned with Chart Constraints.
In Table 1 we present the accuracy and parse time
for three baseline parsers on the development set:
exhaustive CYK parsing, beam-search parsing using
only the inside score ?(?), and beam-search parsing
using the Boundary FOM. We then apply our two
cell-closing methods, Constituent Closure and Com-
plete Closure, to all three baselines. As expected,
the relative speedup of these methods across the var-
ious baselines is similar since the open/closed cell
classification does not change across parsers. We
Figure 5: Time vs. accuracy curves comparing beam-width
prediction (Beam-Predict) and Chart Constraints.
also see that Complete Closure is between 22% and
31% faster than Constituent Closure, indicating that
the greater number of cells closed translates directly
into a reduction in parse time. We can further apply
beam-width prediction to the two beam-search base-
line parsers in Table 1. Dynamically adjusting the
beam-width for the remaining open cells decreases
parse time by an additional 25% when using the In-
side FOM, and 28% with the boundary FOM.
We apply our best model to the test set and report
results in Table 2. Beam-width prediction, again,
outperforms the baseline of a constant beam-width
by 65% and the open/closed classification of Chart
Constraints by 49%. We also compare beam-width
prediction to the Berkeley Coarse-to-Fine parser.
Both our parser and the Berkeley parser are written
in Java, both are run with Viterbi decoding, and both
parse with the same grammar, so a direct compari-
son of speed and accuracy is fair.2
7 Conclusion and Future Work
We have introduced three new pruning methods, the
best of which unites figure-of-merit estimation from
agenda-based parsing, local pruning from beam-
search parsing, and unlabeled constituent structure
2We run the Berkeley parser with the default search param-
eterization to achieve the fastest possible parsing time. We note
that 3 of 2416 sentences fail to parse under these settings. Using
the ?-accurate? option provides a valid parse for all sentences,
but increases parsing time of section 23 to 0.293 seconds per
sentence with no increase in F-score. We assume a back-off
strategy for failed parses could be implemented to parse all sen-
tences with a parsing time close to the default parameterization.
447
Parser Sec/Sent F1
CYK 70.383 89.4
CYK + Constituent Closure 47.870 89.3
CYK + Complete Closure 32.619 89.3
Beam + Inside FOM (BI) 3.977 89.2
BI + Constituent Closure 2.033 89.2
BI + Complete Closure 1.575 89.3
BI + Beam-Predict 1.180 89.3
Beam + Boundary FOM (BB) 0.326 89.2
BB + Constituent Closure 0.279 89.2
BB + Complete Closure 0.199 89.3
BB + Beam-Predict 0.143 89.3
Table 1: Section 22 development set results for CYK and
Beam-Search (Beam) parsing using the Berkeley latent-variable
grammar.
prediction from coarse-to-fine parsing and Chart
Constraints. Furthermore, our pruning method is
trained using only maximum likelihood trees, allow-
ing it to be tuned to specific domains without labeled
data. Using this framework, we have shown that we
can decrease parsing time by 65% over a standard
beam-search without any loss in accuracy, and parse
significantly faster than both the Berkeley parser and
Chart Constraints.
We plan to explore a number of remaining ques-
tions in future work. First, we will try combin-
ing our approach with constituent-level Coarse-to-
Fine pruning. The two methods prune the search
space in very different ways and may prove to be
complementary. On the other hand, our parser cur-
rently spends 20% of the total parse time initializing
the FOM, and adding additional preprocessing costs,
such as parsing with a coarse grammar, may not out-
weigh the benefits gained in the final search.
Second, as with Chart Constraints we do not
prune lexical or unary edges in the span-1 chart cells
(i.e., chart cells that span a single word). We ex-
pect pruning entries in these cells would notably re-
duce parse time since they cause exponentially many
chart edges to be built in larger spans. Initial work
constraining span-1 chart cells has promising results
(Bodenstab et al, 2011) and we hope to investigate
its interaction with beam-width prediction even fur-
ther.
Parser Sec/Sent F1
CYK 64.610 88.7
Berkeley CTF MaxRule 0.213 90.2
Berkeley CTF Viterbi 0.208 88.8
Beam + Boundary FOM (BB) 0.334 88.6
BB + Chart Constraints 0.244 88.7
BB + Beam-Predict (this paper) 0.125 88.7
Table 2: Section 23 test set results for multiple parsers using
the Berkeley latent-variable grammar.
Finally, the size and structure of the grammar is
the single largest contributor to parse efficiency. In
contrast to the current paradigm, we plan to inves-
tigate new algorithms that jointly optimize accuracy
and efficiency during grammar induction, leading to
more efficient decoding.
Acknowledgments
We would like to thank Kristy Hollingshead for
her valuable discussions, as well as the anony-
mous reviewers who gave very helpful feedback.
This research was supported in part by NSF Grants
#IIS-0447214, #IIS-0811745 and DARPA grant
#HR0011-09-1-0041. Any opinions, findings, con-
clusions or recommendations expressed in this pub-
lication are those of the authors and do not necessar-
ily reflect the views of the NSF or DARPA.
References
Robert J. Bobrow. 1990. Statistical agenda parsing. In
DARPA Speech and Language Workshop, pages 222?
224.
Nathan Bodenstab, Kristy Hollingshead, and Brian
Roark. 2011. Unary constraints for efficient context-
free parsing. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics,
Portland, Oregon.
Sharon A Caraballo and Eugene Charniak. 1998. New
figures of merit for best-first probabilistic chart pars-
ing. Computational Linguistics, 24:275?298.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting on As-
sociation for Computational Linguistics, pages 173?
180, Ann Arbor, Michigan.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st North American
448
chapter of the Association for Computational Linguis-
tics conference, pages 132?139, Seattle, Washington.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of the 48rd An-
nual Meeting on Association for Computational Lin-
guistics, pages 1443?1452.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. PhD dissertation, Uni-
versity of Pennsylvania.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical Methods in
Natural Language Processing, volume 10, pages 1?8,
Philadelphia.
Hal Daume?, III and Daniel Marcu. 2005. Learning as
search optimization: approximate large margin meth-
ods for structured prediction. In Proceedings of the
22nd international conference on Machine learning,
ICML ?05, pages 169?176, New York, NY, USA.
Joshua Goodman. 1997. Global thresholding and
Multiple-Pass parsing. Proceedings of the Second
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 11?25.
Mark Johnson. 1998. PCFG models of linguis-
tic tree representations. Computational Linguistics,
24(4):613?632.
Dan Klein and Christopher D. Manning. 2003a. A* pars-
ing. In Proceedings of the 2003 Conference of the
North American Chapter of the Association for Com-
putational Linguistics on Human Language Technol-
ogy (NAACL ?03), pages 40?47, Edmonton, Canada.
Dan Klein and Christopher D. Manning. 2003b. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 423?430, Sap-
poro, Japan.
Mitchell P Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, and Ann Taylor. 1999. Treebank-3,
Philadelphia.
Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
Proceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics - ACL ?05, pages
75?82, Ann Arbor, Michigan.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Comput. Linguist.,
34:513?553.
Adam Pauls, Dan Klein, and Chris Quirk. 2010. Top-
down k-best a* parsing. In In proceedings of the An-
nual Meeting on Association for Computational Lin-
guistics Short Papers, ACLShort ?10, pages 200?204,
Morristown, NJ, USA.
Slav Petrov and Dan Klein. 2007a. Improved inference
for unlexicalized parsing. In Human Language Tech-
nologies 2007: The Conference of the North American
Chapter of the Association for Computational Linguis-
tics; Proceedings of the Main Conference, pages 404?
411, Rochester, New York.
Slav Petrov and Dan Klein. 2007b. Learning and in-
ference for hierarchically split PCFGs. In AAAI 2007
(Nectar Track).
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association
for Computational Linguistics, pages 433?440, Syd-
ney, Australia.
Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, and
Hiyan Alshawi. 2010. Uptraining for accurate deter-
ministic question parsing. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 705?713, Cambridge, MA,
October.
Vasin Punyakanok, Dan Roth, and Wen tau Yih. 2008.
The importance of syntactic parsing and inference in
semantic role labeling. Computational Linguistics,
34(2):257?287.
Brian Roark and Kristy Hollingshead. 2008. Classify-
ing chart cells for quadratic complexity context-free
inference. In Donia Scott and Hans Uszkoreit, editors,
Proceedings of the 22nd International Conference on
Computational Linguistics (Coling 2008), pages 745?
752, Manchester, UK.
Brian Roark and Kristy Hollingshead. 2009. Linear
complexity Context-Free parsing pipelines via chart
constraints. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 647?655, Boulder, Colorado.
Tzong-Han Tsai, Chia-Wei Wu, Yu-Chun Lin, and Wen-
Lian Hsu. 2005. Exploiting full parsing information
to label semantic roles using an ensemble of ME and
SVM via integer linear programming. In Proceed-
ings of the Ninth Conference on Computational Natu-
ral Language Learning, CONLL ?05, pages 233?236,
Morristown, NJ, USA.
Yue Zhang, Byung gyu Ahn, Stephen Clark, Curt Van
Wyk, James R. Curran, and Laura Rimell. 2010.
Chart pruning for fast Lexicalised-Grammar parsing.
In Proceedings of the 23rd International Conference
on Computational Linguistics, pages 1472?1479, Bei-
jing, China.
449
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 676?681,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Unary Constraints for Efficient Context-Free Parsing
Nathan Bodenstab? Kristy Hollingshead? and Brian Roark?
? Center for Spoken Language Understanding, Oregon Health & Science University, Portland, OR
?University of Maryland Institute for Advanced Computer Studies, College Park, MD
{bodensta,roark}@cslu.ogi.edu hollingk@umiacs.umd.edu
Abstract
We present a novel pruning method for
context-free parsing that increases efficiency
by disallowing phrase-level unary productions
in CKY chart cells spanning a single word.
Our work is orthogonal to recent work on
?closing? chart cells, which has focused on
multi-word constituents, leaving span-1 chart
cells unpruned. We show that a simple dis-
criminative classifier can learn with high ac-
curacy which span-1 chart cells to close to
phrase-level unary productions. Eliminating
these unary productions from the search can
have a large impact on downstream process-
ing, depending on implementation details of
the search. We apply our method to four pars-
ing architectures and demonstrate how it is
complementary to the cell-closing paradigm,
as well as other pruning methods such as
coarse-to-fine, agenda, and beam-search prun-
ing.
1 Introduction
While there have been great advances in the statis-
tical modeling of hierarchical syntactic structure in
the past 15 years, exact inference with such models
remains very costly and most rich syntactic mod-
eling approaches resort to heavy pruning, pipelin-
ing, or both. Graph-based pruning methods such
as best-first and beam-search have both be used
within context-free parsers to increase their effi-
ciency. Pipeline systems make use of simpler mod-
els to reduce the search space of the full model. For
example, the well-known Charniak parser (Char-
niak, 2000) uses a simple grammar to prune the
search space for a richer model in a second pass.
Roark and Hollingshead (2008; 2009) have re-
cently shown that using a finite-state tagger to close
cells within the CKY chart can reduce the worst-case
and average-case complexity of context-free pars-
ing, without reducing accuracy. In their work, word
positions are classified as beginning and/or ending
multi-word constituents, and all chart cells not con-
forming to these constraints can be pruned. Zhang
et al (2010) and Bodenstab et al (2011) both ex-
tend this approach by classifying chart cells with a
finer granularity. Pruning based on constituent span
is straightforwardly applicable to all parsing archi-
tectures, yet the methods mentioned above only con-
sider spans of length two or greater. Lexical and
unary productions spanning a single word are never
pruned, and these can, in many cases, contribute sig-
nificantly to the parsing effort.
In this paper, we investigate complementary
methods to prune chart cells with finite-state pre-
processing. Informally, we use a tagger to re-
strict the number of unary productions with non-
terminals on the right-hand side that can be included
in cells spanning a single word. We term these sin-
gle word constituents (SWCs) (see Section 2 for a
formal definition). Disallowing SWCs alters span-1
cell population from potentially containing all non-
terminals to just pre-terminal part-of-speech (POS)
non-terminals. In practice, this decreases the num-
ber of active states in span-1 chart cells by 70%,
significantly reducing the number of allowable con-
stituents in larger spans. Span-1 chart cells are also
the most frequently queried cells in the CKY algo-
rithm. The search over possible midpoints will al-
ways include two cells spanning a single word ? one
as the first left child and one as the last right child. It
is therefore critical that the number of active states
676
(a) Original tree (b) Transformed tree (c) Dynamic programming chart
Figure 1: Example parse structure in (a) the original Penn treebank format and (b) after standard transformations have been
applied. The black cells in (c) indicate CKY chart cells containing a single-word constituent from the transformed tree.
in these cells be minimized so that the number of
grammar access requests is also minimized. Note,
however, that some methods of grammar access ?
such as scanning through the rules of a grammar and
looking for matches in the chart ? achieve less of a
speedup from diminished cell population than oth-
ers, something we investigate in this paper.
Importantly, our method is orthogonal to prior
work on tagging chart constraints and we expect ef-
ficiency gains to be additive. In what follows, we
will demonstrate that a finite-state tagger can learn,
with high accuracy, which span-1 chart cells can be
closed to SWCs, and how such pruning can increase
the efficiency of context-free parsing.
2 Grammar and Parsing Preliminaries
Given a probabilistic context-free grammar (PCFG)
defined as the tuple (V, T, S?, P, ?) where V is the
set of non-terminals, T is the set of terminals, S? is a
special start symbol, P is the set of grammar produc-
tions, and ? is a mapping of grammar productions to
probabilities, we divide the set of non-terminals V
into two disjoint subsets VPOS and VPHR such that
VPOS contains all pre-terminal part-of-speech tags
and VPHR contains all phrase-level non-terminals.
We define a single word constituent (SWC) unary
production as any production A?B ? P such that
A ? VPHR and A spans (derives) a single word. An
example SWC unary production, VP? VBP, can be
seen in Figure 1b. Note that ROOT ? SBAR and
RB ? ?quickly? in Figure 1b are also unary pro-
ductions, but by definition they are not SWC unary
productions.
One implementation detail necessary to leverage
the benefits of sparsely populated chart cells is the
grammar access method used by the inner loop of
the CKY algorithm.1 In bottom-up CKY parsing,
to extend derivations of adjacent substrings into new
constituents spanning the combined string, one can
either iterate over all binary productions in the gram-
mar and test if the new derivation is valid (gram-
mar loop), or one can take the cross-product of ac-
tive states in the cells spanning the substrings and
poll the grammar for possible derivations (cross-
product). With the cross-product approach, fewer
active states in either child cell leads to fewer gram-
mar access operations. Thus, pruning constituents
in lower cells directly affects the overall efficiency
of parsing. On the other hand, with the grammar
loop method there is a constant number of gram-
mar access operations (i.e., the number of grammar
rules) and the number of active states in each child
cell has no impact on efficiency. Therefore, with
the grammar loop implementation of the CYK algo-
rithm, pruning techniques such as unary constraints
will have very little impact on the final run-time effi-
ciency of the parser. We will report results in Section
5 with parsers using both approaches.
3 Treebank Unary Productions
In this section, we discuss the use of unary produc-
tions both in the Penn WSJ treebank (Marcus et al,
1999) and during parsing by analyzing their func-
tion and frequency. All statistics reported here are
computed from sections 2-21 of the treebank.
A common pre-processing step in treebank pars-
ing is to transform the original WSJ treebank be-
fore training and evaluation. There is some flex-
1Some familiarity with the CKY algorithm is assumed. For
details on the algorithm, see Roark and Sproat (2007).
677
Orig. Trans.
Empty nodes 48,895 0
Multi-Word Const. unaries 1,225 36,608
SWC unaries 98,467 105,973
Lexical unaries 950,028 950,028
Pct words with SWC unary 10.4% 11.2%
Table 1: Unary production counts from sections 2-21 of the
original and transformed WSJ treebank. All multisets are dis-
joint. Lexical unary count is identical to word count.
ibility in this process, but most pre-processing ef-
forts include (1) affixing a ROOT unary production
to the root symbol of the original tree, (2) removal
of empty nodes, and (3) striping functional tags and
cross-referencing annotations. See Figure 1 for an
example. Additional transforms include (4) remov-
ing X? X unary productions for all non-terminals
X, (5) collapsing unary chains to a single (possibly
composite) unary production (Klein and Manning,
2001), (6) introducing new categories such as AUX
(Charniak, 1997), and (7) collapsing of categories
such as PRT and ADVP (Collins, 1997). For this
paper we only apply transforms 1-3 and otherwise
leave the treebank in its original form. We also note
that ROOT unaries are a special case that do not af-
fect search, and we choose to ignore them for the
remainder of this paper.
These tree transformations have a large impact
on the number and type of unary productions in
the treebank. Table 1 displays the absolute counts
of unaries in the treebank before and after process-
ing. Multi-word constituent unary productions in the
original treebank are rare and used primarily to mark
quantifier phrases as noun phrases. But due to the
removal of empty nodes, the transformed treebank
contains many more unary productions that span
multiple words, such as S ? VP, where the noun
phrase was left unspecified in the original clause.
The number of SWC unaries is relatively un-
changed after processing the original treebank, but
note that only 11.2% of words in the transformed
treebank are covered by SWCs. This implies that
we are unnecessarily adding SWC productions to al-
most 90% of span-1 chart cells during search. One
may argue that an unsmoothed grammar will nat-
urally disallow most SWC productions since they
are never observed in the training data, for example
Mk2 Mk2+S Latent
|VPOS| 45 45 582
|VPHR| 26 26 275
SWC grammar rules 159 1,170 91,858
Active VPOS states 2.5 45 75
Active VPHR states 5.9 26 152
Table 2: Grammar statistics and averaged span-1 active state
counts for exhaustive parsing of section 24 using a Markov
order-2 (Mk2), a smoothed Markov order-2 (Mk2+S), and the
Berkeley latent variable (Latent) grammars.
VP ? DT. This is true to some extent, but gram-
mars induced from the WSJ treebank are notorious
for over-generation. In addition, state-of-the-art ac-
curacy in context-free parsing is often achieved by
smoothing the grammar, so that rewrites from any
one non-terminal to another are permissible, albeit
with low probability.
To empirically evaluate the impact of SWCs on
span-1 chart cells, we parse the development set
(section 24) with three different grammars induced
from sections 2-21. Table 2 lists averaged counts
of active Viterbi states (derivations with probabil-
ity greater than zero) from span-1 cells within the
dynamic programming chart, as well as relevant
grammar statistics. Note that these counts are ex-
tracted from exhaustive parsing ? no pruning has
been applied. We notice two points of interest.
First, although |VPOS| > |VPHR|, for the unsmoothed
grammars more phrase-level states are active within
the span-1 cells than states derived from POS tags.
When parsing with the Markov order-2 grammar,
70% of active states are non-terminals from VPHR,
and with the latent-variable grammar, 67% (152 of
227). This is due to the highly generative nature
of SWC productions. Second, although using a
smoothed grammar maximizes the number of active
states, the unsmoothed grammars still provide many
possible derivations per word.
Given the infrequent use of SWCs in the treebank,
and the search-space explosion incurred by includ-
ing them in exhaustive search, it is clear that restrict-
ing SWCs in contexts where they are unlikely to oc-
cur has the potential for large efficiency gains. In the
next section, we discuss how to learn such contexts
via a finite-state tagger.
678
4 Tagging Unary Constraints
To automatically predict if word wi from sentence
w can be spanned by an SWC production, we train a
binary classifier from supervised data using sections
2-21 of the Penn WSJ Treebank for training, section
00 as heldout, and section 24 as development. The
class labels of all words in the training data are ex-
tracted from the treebank, where wi ? U if wi is
observed with a SWC production and wi ? U other-
wise. We train a log linear model with the averaged
perceptron algorithm (Collins, 2002) using unigram
word and POS-tag2 features from a five word win-
dow. We also trained models with bi-gram and tri-
gram features, but tagging accuracy did not improve.
Because the classifier output is imposing hard
constraints on the search space of the parser, we
may want to choose a tagger operating point that fa-
vors precision over recall to avoid over-constraining
the downstream parser. To compare the tradeoff be-
tween possible precision/recall values, we apply the
softmax activation function to the perceptron output
to obtain the posterior probability of wi ? U :
P (U |wi, ?) = (1 + exp(?f(wi) ? ?))
?1 (1)
where ? is a vector of model parameters and f(?) is a
feature function. The threshold 0.5 simply chooses
the most likely class, but to increase precision we
can move this threshold to favor U over U . To tune
this value on a per-sentence basis, we follow meth-
ods similar to Roark & Hollingshead (2009) and
rank each word position with respect to its poste-
rior probability. If the total number of words wi
with P (U |wi, ?) < 0.5 is k, we decrease the thresh-
old value from 0.5 until ?k words have been moved
from class U to U , where ? is a tuning parameter be-
tween 0 and 1. Although the threshold 0.5 produces
tagging precision and recall of 98.7% and 99.4%
respectively, we can adjust ? to increase precision
as high as 99.7%, while recall drops to a tolerable
82.1%. Similar methods are used to replicate cell-
closing constraints, which are combined with unary
constraints in the next section.
2POS-tags were provided by a separately trained tagger.
5 Experiments and Results
To evaluate the effectiveness of unary constraints,
we apply our technique to four parsers: an exhaus-
tive CKY chart parser (Cocke and Schwartz, 1970);
the Charniak parser (Charniak, 2000), which uses
agenda-based two-level coarse-to-fine pruning; the
Berkeley parser (Petrov and Klein, 2007a), a multi-
level coarse-to-fine parser; and the BUBS parser
(Bodenstab et al, 2011), a single-pass beam-search
parser with a figure-of-merit constituent ranking
function. The Berkeley and BUBS parsers both
parse with the Berkeley latent-variable grammar
(Petrov and Klein, 2007b), while the Charniak
parser uses a lexicalized grammar, and the exhaus-
tive CKY algorithm is run with a simple Markov
order-2 grammar. All grammars are induced from
the same data: sections 2-21 of the WSJ treebank.
Figure 2 contrasts the merit of unary constraints
on the three high-accuracy parsers, and several inter-
esting comparisons emerge. First, as recall is traded
for precision within the tagger, each parser reacts
quite differently to the imposed constraints. We ap-
ply constraints to the Berkeley parser during the ini-
tial coarse-pass search, which is simply an exhaus-
tive CKY search with a coarse grammar. Applying
unary and cell-closing constraints at this point in the
coarse-to-fine pipeline speeds up the initial coarse-
pass significantly, which accounted for almost half
of the total parse time in the Berkeley parser. In ad-
dition, all subsequent fine-pass searches also bene-
fit from additional pruning as their search is guided
by the remaining constituents of the previous pass,
which is the intersection of standard coarse-to-fine
pruning and our imposed constraints.
We apply constraints to the Charniak parser dur-
ing the first-pass agenda-based search. Because an
agenda-based search operates at a constituent level
instead of a cell/span level, applying unary con-
straints alters the search frontier instead of reduc-
ing the absolute number of constituents placed in the
chart. We jointly tune lambda and the internal search
parameters of the Charniak parser until accuracy de-
grades.
Application of constraints to the CKY and BUBS
parsers is straightforward as they are both single
pass parsers ? any constituent violating the con-
straints is pruned. We also note that the CKY and
679
Figure 2: Development set results applying unary constraints
at multiple values of ? to three parsers.
BUBS parsers both employ the cross-product gram-
mar access method discussed in Section 2, while
the Berkeley parser uses the grammar loop method.
This grammar access difference dampens the benefit
of unary constraints for the Berkeley parser.3
Referring back to Figure 2, we see that both speed
and accuracy increase in all but the Berkeley parser.
Although it is unusual that pruning leads to higher
accuracy during search, it is not unexpected here as
our finite-state tagger makes use of lexical relation-
ships that the PCFG does not. By leveraging this
new information to constrain the search space, we
are indirectly improving the quality of the model.
Finally, there is an obvious operating point for
each parser at which the unary constraints are too
severe and accuracy deteriorates rapidly. For test
conditions, we set the tuning parameter ? based on
the development set results to prune as much of the
search space as possible before reaching this degra-
dation point.
Using lambda-values optimized for each parser,
we parse the unseen section 23 test data and present
results in Table 3. We see that in all cases, unary
constraints improve the efficiency of parsing without
significant accuracy loss. As one might expect, ex-
haustive CKY parsing benefits the most from unary
constraints since no other pruning is applied. But
even heavily pruned parsers using graph-based and
pipelining techniques still see substantial speedups
3The Berkeley parser does maintain meta-information about
where non-terminals have been placed in the chart, giving it
some of the advantages of cross-product grammar access.
Parser F-score Seconds Speedup
CKY 72.2 1,358
+ UC (?=0.2) 72.6 1,125 1.2x
+ CC 74.3 380 3.6x
+ CC + UC 74.6 249 5.5x
BUBS 88.4 586
+ UC (?=0.2) 88.5 486 1.2x
+ CC 88.7 349 1.7x
+ CC + UC 88.7 283 2.1x
Charniak 89.7 1,116
+ UC (?=0.2) 89.7 900 1.2x
+ CC 89.7 716 1.6x
+ CC + UC 89.6 679 1.6x
Berkeley 90.2 564
+ UC (?=0.4) 90.1 495 1.1x
+ CC 90.2 320 1.8x
+ CC + UC 90.2 289 2.0x
Table 3: Test set results applying unary constraints (UC) and
cell-closing (CC) constraints (Roark and Hollingshead, 2008)
to various parsers.
with the additional application of unary constraints.
Furthermore, unary constraints consistently provide
an additive efficiency gain when combined with cell-
closing constraints.
6 Conclusion
We have presented a new method to constrain
context-free chart parsing and have shown it to be or-
thogonal to many forms of graph-based and pipeline
pruning methods. In addition, our method parallels
the cell closing paradigm and is an elegant com-
plement to recent work, providing a finite-state tag-
ging framework to potentially constrain all areas of
the search space ? both multi-word and single-word
constituents.
Acknowledgments
We would like to thank Aaron Dunlop for his valu-
able discussions, as well as the anonymous review-
ers who gave very helpful feedback. This research
was supported in part by NSF Grants #IIS-0447214,
#IIS-0811745 and DARPA grant #HR0011-09-1-
0041. Any opinions, findings, conclusions or recom-
mendations expressed in this publication are those of
the authors and do not necessarily reflect the views
of the NSF or DARPA.
680
References
Nathan Bodenstab, Aaron Dunlop, Keith Hall, and Brian
Roark. 2011. Beam-width prediction for efficient
context-free parsing. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics, Portland, Oregon. Association for Com-
putational Linguistics.
Eugene Charniak. 1997. Statistical parsing with a
context-free grammar and word statistics. In Proceed-
ings of the Fourteenth National Conference on Arti-
ficial Intelligence, pages 598?603, Menlo Park, CA.
AAAI Press/MIT Press.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st North American
chapter of the Association for Computational Linguis-
tics conference, pages 132?139, Seattle, Washington.
Morgan Kaufmann Publishers Inc.
John Cocke and Jacob T. Schwartz. 1970. Programming
languages and their compilers. Technical report Pre-
liminary notes, Courant Institute of Mathematical Sci-
ences, NYU.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of the
eighth conference on European chapter of the Associ-
ation for Computational Linguistics, page 1623, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: theory and experi-
ments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical Methods in
Natural Language Processing, volume 10, pages 1?
8, Philadelphia, July. Association for Computational
Linguistics.
Dan Klein and Christopher D. Manning. 2001. Parsing
with treebank grammars: Empirical bounds, theoret-
ical models, and the structure of the Penn treebank.
In Proceedings of 39th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 338?345,
Toulouse, France, July. Association for Computational
Linguistics.
Mitchell P Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, and Ann Taylor. 1999. Treebank-3.
Linguistic Data Consortium, Philadelphia.
Slav Petrov and Dan Klein. 2007a. Improved inference
for unlexicalized parsing. In Human Language Tech-
nologies 2007: The Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics; Proceedings of the Main Conference, pages
404?411, Rochester, New York, April. Association for
Computational Linguistics.
Slav Petrov and Dan Klein. 2007b. Learning and in-
ference for hierarchically split PCFGs. In AAAI 2007
(Nectar Track).
Brian Roark and Kristy Hollingshead. 2008. Classify-
ing chart cells for quadratic complexity context-free
inference. In Donia Scott and Hans Uszkoreit, ed-
itors, Proceedings of the 22nd International Confer-
ence on Computational Linguistics (COLING 2008),
pages 745?752, Manchester, UK, August. Association
for Computational Linguistics.
Brian Roark and Kristy Hollingshead. 2009. Linear
complexity context-free parsing pipelines via chart
constraints. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 647?655, Boulder, Colorado,
June. Association for Computational Linguistics.
Brian Roark and Richard W Sproat. 2007. Computa-
tional Approaches to Morphology and Syntax. Oxford
University Press, New York.
Yue Zhang, Byung gyu Ahn, Stephen Clark, Curt Van
Wyk, James R. Curran, and Laura Rimell. 2010.
Chart pruning for fast lexicalised-grammar parsing. In
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 1472?1479, Beijing,
China, June.
681
