Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1270?1279,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
Finding Short Definitions of Terms on Web Pages
Gerasimos Lampouras
?
and Ion Androutsopoulos
?+
?
Department of Informatics, Athens University of Economics and Business, Greece
+
Digital Curation Unit, Research Centre ?Athena?, Athens, Greece
Abstract
We present a system that finds short def-
initions of terms on Web pages. It em-
ploys a Maximum Entropy classifier, but it
is trained on automatically generated ex-
amples; hence, it is in effect unsupervised.
We use ROUGE-W to generate training ex-
amples from encyclopedias and Web snip-
pets, a method that outperforms an alter-
native centroid-based one. After training,
our system can be used to find definitions
of terms that are not covered by encyclo-
pedias. The system outperforms a compa-
rable publicly available system, as well as
a previously published form of our system.
1 Introduction
Definitions of terms are among the most com-
mon types of information users search for on the
Web. In the TREC 2001 QA track (Voorhees,
2001), where the distribution of question types re-
flected that of real user logs, 27% of the ques-
tions were requests for definitions (e.g., ?What is
gasohol??, ?Who was Duke Ellington??). Conse-
quently, some Web search engines provide special
facilities (e.g., Google?s ?define:? query prefix)
that seek definitions of user-specified terms in on-
line encyclopedias or glossaries; to save space, we
call both ?encyclopedias?. There are, however, of-
ten terms that are too recent, too old, or less widely
used to be included in encyclopedias. Their defi-
nitions may be present on other Web pages (e.g.,
newspaper articles), but they may be provided in-
directly (e.g., ?He said that gasohol, a mixture of
gasoline and ethanol, has been great for his busi-
ness.?) and they may be difficult to locate with
generic search engines that may return dozens of
pages containing, but not defining the terms.
We present a system to find short definitions
of user-specified terms on Web pages. It can be
used as an add-on to generic search engines, when
no definitions can be found in on-line encyclope-
dias. The system first invokes a search engine us-
ing the (possibly multi-word) term whose defini-
tion is sought, the target term, as the query. It
then scans the top pages returned by the search
engine to locate 250-character snippets with the
target term at their centers; we call these snippets
windows. The windows are candidate definitions
of the target term, and they are then classified as
acceptable (positive class) or unacceptable (nega-
tive class) using supervised machine learning. The
system reports the windows for which it is most
confident that they belong in the positive class. Ta-
ble 1 shows examples of short definitions found by
our system. In our experiments, we allow the sys-
tem to return up to five windows per target term,
and the system?s response is counted as correct if
any of the returned windows contains an accept-
able short definition of the target. This is similar
to the treatment of definition questions in TREC
2000 and 2001 (Voorhees, 2000; Voorhees, 2001),
but the answer is sought on the Web, not in a given
document collection of a particular genre.
More recent TREC QA tracks required definition
questions to be answered by lists of complemen-
tary text snippets, jointly providing required or op-
tional information nuggets (Voorhees, 2003). In
contrast, we focus on locating single snippets that
include self-contained short definitions. Despite
its simpler nature, we believe the task we address
is of practical use: a list of single-snippet defini-
tions from Web pages accompanied by the source
URLs is a good starting point for users seeking
definitions of terms not covered by encyclopedias.
We also note that evaluating multi-snippet defini-
tions can be problematic, because it is often dif-
ficult to agree which information nuggets should
be treated as required, or even optional (Hilde-
brandt et al, 2004). In contrast, earlier experimen-
tal results we have reported (Androutsopoulos and
Galanis, 2005) show strong inter-assessor agree-
ment (K > 0.8) for single-snippet definitions (Eu-
genio and Glass, 2004). The task we address also
differs from DUC?s query focused summarization
(Dang, 2005; Dang, 2006). Our queries are sin-
gle terms, whereas DUC queries are longer topic
1270
Target term: Babesiosis
(...) Babesiosis is a rare, severe and sometimes fatal tick-
borne disease caused by various types of Babesia, a micro-
scopic parasite that infects red blood cells. In New York
state, the causative parasite is babesia microti. Who gets
Babesiosis? Babesiosis (...)
Target term: anorexia nervosa
(...) anorexia nervosa is an illness that usually occurs in
teenage girls, but it can also occur in teenage boys, and adult
women and men. People with anorexia are obsessed with
being thin. They lose a lot of weight and are terrified of
gaining weight. The (...)
Target term: Kinabalu
(...) one hundred and thirty eight kilometers from Kota Kin-
abalu, the capital of the Malaysian state of Sabah, rises the
majestic mount Kinabalu. With its peak at 4,101 meters
(and growing), mount Kinabalu is the highest mountain in
south-east Asia. This (...)
Target term: Pythagoras
(...) Pythagoras of Samos about 569 BC - about 475
BC click the picture above to see eleven larger pictures
Pythagoras was a Greek philosopher who made important
developments in mathematics, astronomy, and the theory of
music. The theorem now known as (...)
Target term: Sacajawea
(...) Sacajawea was a Shoshone Indian princess. The
Shoshone lived from the rocky mountains to the plains.
They lived primarily on buffalo meat. The shoshone trav-
eled for many days searching for buffalo. They hunted on
horseback using the buffalo for food (...)
Target term: tale of Genji
(...) the tale of Genji This site aims to promote a wider
understanding and appreciation of the tale of Genji - the
11th century Japanese classic written by a Heian court lady
known asMurasaki Shikibu. It also serves as a kind of travel
guide to the world (...)
Target term: Jacques Lacan
(...) who is Jacques Lacan? John Haber in New York
city a primer for pre-post-structuralists Jacques Lacan is a
Parisian psychoanalyst who has influenced literary criticism
and feminism. He began work in the 1950s, in the Freudian
society there. It was a (...)
Table 1: Definitions found by our system.
descriptions, often entire paragraphs; furthermore,
we do not attempt to compose coherent and cohe-
sive summaries from several snippets.
The system we present is based on our ear-
lier work (Miliaraki and Androutsopoulos, 2004),
where an SVM classifier (Cristianini and Shawe-
Taylor, 2000) was used to separate acceptable win-
dows from unacceptable ones; the SVM also re-
turned confidence scores, which were used to rank
the acceptable windows. On datasets from the
TREC 2000 and 2001 QA tracks, our earlier sys-
tem clearly outperformed the methods of Joho and
Sanderson (2000; 2001) and Prager et al (2001;
2002), as reported in previous work (Miliaraki
and Androutsopoulos, 2004). To train the SVM,
however, thousands of training windows were re-
quired, each tagged as a positive or negative exam-
ple. Obtaining large numbers of training windows
is easy, but manually tagging them is very time-
consuming. In the TREC 2000 and 2001 datasets,
it was possible to tag the training windows auto-
matically by using training target terms and ac-
companying regular expression patterns provided
by the TREC organizers. The regular expressions
covered all the known acceptable definitions of the
corresponding terms that can be extracted from the
datasets. When the training windows, however,
are obtained from the Web, it is impossible to con-
struct manually regular expressions for all the pos-
sible phrasings of the acceptable definitions in the
training windows.
In subsequent work (Androutsopoulos and
Galanis, 2005), we developed ATTW (automatic
tagging of training windows), a technique that pro-
duces arbitrarily large collections of training win-
dows from the Web with practically no manual
effort, in effect making our overall system unsu-
pervised. ATTW uses training terms for which
several encyclopedia definitions are available, and
compares each Web training window (each win-
dow extracted from the pages the search engine
returned for a training term) to the corresponding
encyclopedia definitions. Web training windows
that are very similar (or dissimilar) to the corre-
sponding encyclopedia definitions are tagged as
positive (or negative) examples; if the similarity is
neither too high nor too low, the window is not in-
cluded in the classifier?s training data. Previously
reported experiments (Androutsopoulos and Gala-
nis, 2005) showed that ATTW leads to significantly
better results, compared to training the classifier
on all the available TREC windows, for which reg-
ular expressions are available, and then using it to
classify Web windows.
Note that in ATTW the encyclopedia definitions
are used only during training. Once the classifier
has been trained, it can be used to discover defini-
tions on arbitrary Web pages. In fact, during test-
ing we discard windows originating from on-line
encyclopedias, simulating the case where we seek
definitions of terms not covered by encyclopedias;
we also ignore windows from on-line encyclope-
dias during training. Also, note that the classifier
is trained on Web windows, not directly on ency-
clopedia definitions, which allows it to avoid rely-
ing excessively on phrasings that are common in
encyclopedia definitions, but uncommon in more
indirect definitions of arbitrary Web pages. Fur-
1271
thermore, training the classifier directly on ency-
clopedia definitions would not provide negative
examples.
In our previous work with ATTW (Androut-
sopoulos and Galanis, 2005) we used a mea-
sure constructed by ourselves to assess the sim-
ilarity between Web windows and encyclopedia
definitions. Here, we use the more established
ROUGE-W measure (Lin, 2004) instead. ROUGE-
W and other versions of ROUGE have been used in
summarization to measure how close a machine-
authored summary is to multiple human sum-
maries of the same input. We use ROUGE-W in
a similar setting, to measure how close a training
window is to multiple encyclopedia definitions of
the same term. A further difference from our pre-
vious work is that we also use ROUGE-W when
computing the features of the windows to be clas-
sified. Previously, the SVM relied, among others,
on Boolean features indicating if the target term
was preceded or followed in the window to be
classified by a particular phrase indicating a def-
inition (e.g., ?target, a kind of?, ?such as target?).
The indicative phrases are selected automatically
during training, but now the corresponding fea-
tures are not Boolean; their values are the ROUGE-
W similarity scores between an indicative phrase
and the context of the target term in the window.
This allows the system to soft-match the phrases
to the windows (e.g., encountering ?target, another
kind of?, instead of ?target, a kind of?).
1
In our new system we also use a Maximum En-
tropy (MAXENT) classifier (Ratnaparkhi, 1997) in-
stead of an SVM, because much faster implemen-
tations of the former are available.
2
We present
experimental results showing that our new sys-
tem significantly outperforms our previously pub-
lished one. The use of the MAXENT classifier by it-
self improved slightly our results, but the improve-
ments come mostly from using ROUGE-W.
Apart from presenting an improved version of
our system, the main contribution of this paper is a
detailed experimental comparison of our new sys-
tem against Cui et al?s (2004; 2005; 2006; 2007).
The latter is particularly interesting, because it
is well published, it includes both an alterna-
tive, centroid-based technique to automatically tag
training examples and a soft-matching classifier,
1
We also experimented with other similarity measures
(e.g., edit distance) and ROUGE variants, but we obtained the
best results with ROUGE-W.
2
We use Stanford?s classifier; see http://nlp.stanford.edu/.
and it is publicly available.
3
We show that ATTW
outperforms Cui et al?s centroid-based technique,
and that our overall system is also clearly better
than Cui et al?s in the task we address.
Section 2 discusses ATTW with ROUGE-W, Cui
et al?s centroid-based method to tag training ex-
amples, and experiments showing that ATTW is
better. Section 3 describes our new overall system,
the system of Cui et al, and the baselines. Sec-
tion 4 reports experimental results showing that
our system is better than Cui et al?s, and better
than our previously published system. Section 5
discusses related work; and section 6 concludes.
2 Tagging training windows
During both training and testing, for each tar-
get term we keep the r most highly ranked Web
pages the search engine returns. We then extract
the first f windows of the target term from each
page, since early occurrences of the target terms
on pages are more likely to be definitions. We,
thus, obtain r ? f windows per term.
4
When test-
ing, we return the k windows of the target term
that the classifier is most certain they belong in the
positive class. In our experiments, r = 10, f = 5,
k = 5. During training, we train the classifier on
the q ? r ? f windows we obtain for q training tar-
get terms; in our experiments, q ranged from 50 to
1500. Training requires tagging first the training
windows as positive or negative, possibly discard-
ing windows that cannot be tagged automatically.
2.1 ATTW with ROUGE-W similarity
To tag a training window w of a training term t
with ATTW and ROUGE-W, we obtain a set C
t
of
definitions of t from encyclopedias.
5
Stop-words,
punctuation, and non-alphanumeric characters are
removed from C
t
and w, and a stemmer is ap-
plied; the testing windows undergo the same pre-
processing.
6
For each definition d ? C
t
, we find
the longest common word subsequence of w and
d. If w is the word sequence ?A,B, F,C,D,E?
3
See http://www.cuihang.com/software.html. The soft-
ware and a demo of our system, and the datasets we used
are also freely available; see http://nlp.cs.aueb.gr/.
4
We used Altavista in our experiments. We remove HTML
tags and retain only the plain text of the pages.
5
The training terms were randomly selected from the in-
dex of http://www.encyclopedia.com/. We used Google?s
?define:? to obtain definitions from other encyclopedias.
6
We use the 100 most frequent words of the BNC corpus
(http://www.natcorp.ox.ac.uk/) as the stop-list, and Porter?s
stemmer (http://tartarus.org/?martin/PorterStemmer/).
1272
and d = ?A,B,E,C,G,D?, the longest com-
mon subsequence is ?A,B,C,D?. The longest
common subsequence is divided into consecutive
matches, producing in our example ?A,B|C|D?.
We then compute the following score (weighted
longest common subsequence), where m is the
number of consecutive matches, k
i
is the length
of the i-th consecutive match, and f is a weight-
ing function. We use f(k) = k
a
, where a > 1 is a
parameter we tune experimentally.
WLCS (w, d) =
?
m
i=0
f(k
i
)
We then compute the following quantities, where
|?| is word length, and f
?1
is the inverse of f .
P (w, d) = f
?1
(
WLCS(w,d)
f(|w|)
)
R(w, d) = f
?1
(
WLCS(w,d)
f(|d|)
)
F (w, d) =
(1+?
2
)?R(w,d)?P (w,d)
R(w,d)+?
2
?P (w,d)
In effect, P (w, d) examines how close the
longest common substring is to w and R(w, d)
how close it is to d. Following Lin (2004), we use
? = 8, assigning greater importance toR(w, d). If
R(w, d) is high, the longest common substring is
very similar to d; then w (which also includes the
longest common substring) intuitively contains al-
most all the information of d, i.e., all the informa-
tion of a known acceptable definition (high recall).
If P (w, d) is high, the longest common substring
is very similar to w; then d (which also includes
the longest common substring) contains almost all
the information of w, i.e., w does not contain any
(redundant) information not included in a known
acceptable definition, something we care less for.
The ROUGE-W similarity sim(w,C
t
) between
w and C
t
is the maximum F (w, d), for all d ?
C
t
. Training windows with sim(w,C
t
) > T
+
are
tagged as positive; if sim(w,C
t
) < T
?
, they are
tagged as negative; and if T
?
? sim(w,C
t
) ?
T
+
, they are discarded. We tune the thresholds T
+
and T
?
experimentally, as discussed below.
2.2 The centroid-based tagging approach
This method is used in the system of Cui et al
(2004; 2005; 2006; 2007). For each training target
term, we construct a ?centroid? pseudo-text con-
taining the words that co-occur most frequently
with the target term. We then compute the similar-
ity between each training window and the centroid
of its target term. If it exceeds a threshold, the win-
dow is tagged as positive; Cui et al produce only
positive examples.
The centroid of a training target term t is con-
structed as follows. For each word u in t?s training
windows, we compute the centrality score defined
below, where SF
t
is the number of t?s training
windows, SF
u
is the number of u?s windows that
can be extracted from the retained Web pages the
search engine returned for t, SF
t?u
is the number
of windows on the same pages that contain both
t and u, and idf(u) is the inverse document fre-
quency of w.
7
Centrality scores are pointwise mu-
tual information with an extra idf (u) factor.
centrality(u) = ?log(
SF
t?u
SF
t
+SF
u
) ? idf (u)
The words u whose centrality scores exceed the
mean by at least a standard deviation are added
to the centroid of t. Before computing the cen-
trality scores, stop-words, punctuation, and non-
alphanumeric characters are removed, and a stem-
mer is applied, as in ATTW. The similarities be-
tween training windows and centroids are then
computed using cosine similarity, after turning the
centroids and windows into binary vectors that
show which words they contain.
2.3 Comparing the tagging approaches
To evaluate the two methods that tag training win-
dows, we selected randomly q = 200 target terms,
different from those used for training and testing.
We collected the q ? r ? f = 200 ? 10 ? 5 windows
from the corresponding Web pages, we selected
randomly 400 from the collected 10,000 windows,
and tagged them manually as positive or negative.
Figure 1 plots the positive precision of the two
methods against their positive recall, and figure 2
shows negative precision against negative recall.
For different values of T
+
, we obtain a different
point in figure 1; similarly for T
?
and figure 2.
Positive precision is TP/(TP +FP), positive re-
call is TP/(TP + FN ), and likewise for nega-
tive precision and recall; TP (true positives) are
the positive training windows the method has cor-
rectly tagged as positive, FP are the negative win-
dows the method has tagged as positives etc.
For very high (strict) T
+
values, the methods tag
very few (or none) training windows as positive;
hence, both TP and TP + FP approach (or be-
come) zero; we take positive precision to be zero
in that case. Positive recall also approaches (or be-
comes) zero, which is why both positive recall and
7
We obtained idf (u) from BNC. Cui et al use sentences
instead of windows, reducing the risk of truncating defini-
tions. We used windows in all systems, to compare fairly.
1273
Figure 1: Results of generating positive examples.
Figure 2: Results of generating negative examples.
precision reach zero in the left of figure 1. Simi-
lar comments apply to figure 2, though both meth-
ods always tagged correctly at least a few training
windows as negative, for the T
?
values we tried;
hence, negative precision was never zero.
Positive precision shows how certain we can be
that training windows tagged as positive are in-
deed positive; whereas positive recall is the per-
centage of true positive examples that we manage
to tag as such. Figure 1 shows that when using
ATTW, we need to settle for a low positive recall,
i.e., miss out many positive examples, in order to
obtain a reasonably high precision. It also shows
that the centroid method is clearly worse when tag-
ging positive examples; its positive precision is al-
most always less than 0.3. Figure 2 shows that
both methods achieve high negative precision and
recall; they manage to assign trustworthy nega-
tive labels without missing many negative exam-
ples. However, ATTW is significantly better when
tagging positive examples, as shown in figure 1;
hence, it is better than the centroid method.
8
8
We tried different values of ROUGE-W?s a parameter in
When using ATTW in practice, we need to se-
lect T
+
and T
?
. We assign more importance to
selecting a T
+
(a point of ATTW?s curve in figure
1) that yields high positive precision; the choice of
T
?
(point in figure 2) is less important, because
ATTW?s negative precision is always reasonably
high. Based on figure 1, we set T
+
to 0.58, which
corresponds to positive precision 0.66 and posi-
tive recall 0.16. By tuning the two thresholds we
can control the number of positively or negatively
tagged examples we produce (and their ratio), and
the number of examples we discard. Having set
T
+
, we set T
?
to 0.30, a value that maintains the
ratio of truly positive to truly negative windows
of the 400 manually tagged windows (0.2 to 1),
since this is approximately the ratio the classifier
will confront during testing; we also experimented
with a 1 to 1 ratio, but the results were worse. This
T
?
value corresponds negative precision 0.70 and
negative recall 0.02. Thus, both positive and neg-
ative precision is approximately 0.7, which means
that approximately 30% of the tags we assign to
the examples are incorrect. Our experiments, how-
ever, indicate that the classifier is able to general-
ize well over this noise.
3 Finding new definitions
We now present our overall system, the system of
Cui et al, and the baselines.
3.1 Our system
Given a target term, our system extracts r ? f =
10 ? 5 windows from the pages returned by the
search engine, and uses the MAXENT classifier to
separate them into acceptable and unacceptable
definitions.
9
It then returns the k = 5 windows
the classifier is most confident they are acceptable.
The classifier is trained on windows tagged as pos-
itive or negative using ATTW. It views each win-
dow as a vector of the following features:
10
SN: The ordinal number of the window on the
page it originates from (e.g., second window of the
target term from the beginning of the page). Early
mentions of a term are more likely to define it.
RK: The ranking of the Web page the window
originates from, as returned by the search engine.
the interval (1, 2]. We use a = 1.4, which was the value with
the best results on the 400 windows. We did not try a > 2, as
the results were declining as a approached 2.
9
We do not discuss MAXENT classifiers, since they are a
well documented in the literature.
10
SN andWC originate from Joho and Sanderson (2000).
1274
WC: We create a simple centroid of the window?s
target term, much as in section 2.2. The centroid?s
words are chosen based on their frequency in the r?
f windows of the target term; the 20 most frequent
words are chosen. WC is the percentage of the 20
words that appear in the vector?s window.
Manual patterns: 13 Boolean features, each sig-
naling if the window matches a different manually
constructed lexical pattern (e.g., ?target, a/an/the?,
as in ?Tony Blair, the British prime minister?).
The patterns are those used by Joho and Sander-
son (2000), and four more introduced in our pre-
vious work (Androutsopoulos and Galanis, 2005)
and (Miliaraki and Androutsopoulos, 2004). They
are intended to perform well across text genres.
Automatic patterns: m numeric features, each
showing the degree to which the window matches
a different automatically acquired lexical pattern.
The patterns are word n-grams (n ? {1, 2, 3}) that
must occur directly before or after the target term
(e.g., ?target which is?). The patterns are acquired
as follows. First, all the n-grams directly before
or after any target term in the training windows
are collected. The n-grams that have been en-
countered at least 10 times are candidate patterns.
From those, the m patterns with the highest pre-
cision scores are retained, where precision is the
number of positive training windows the pattern
matches over the total number of training windows
it matches; we use m = 300 in our experiments,
based on the results of our previous work. The au-
tomatically acquired patterns allow the system to
detect definition contexts that are not captured by
the manual patterns, including genre-specific con-
texts. The value of each feature is the ROUGE-W
score between a pattern and the left or right con-
text of the target term in the window.
3.2 Cui et al?s system
Given a target term t, Cui et al (2004; 2005; 2006;
2007) initially locate sentences containing t in rel-
evant documents. We use the r?f = 10?5windows
from the pages returned by the search engine, in-
stead of sentences. Cui et al then construct the
centroid of t, and compute the cosine similarity of
each one of the r ? f windows to the centroid, as
in section 2.2. The 10 windows that are closer to
the centroid are considered candidate answers. All
candidate answers are then processed by a part-of-
speech (POS) tagger and a chunker. The words
of the centroid are replaced in all the candidate
answers by their POS tags; the target term, noun
phrases, forms of the verb ?to be?, and articles
are replaced by special tags (e.g., TARGET, NP),
while adjectives and adverbs are removed. The
candidate answers are then cropped to L tokens
to the left and right of the target term, producing
two subsequences (left and right) per candidate an-
swer; we set L = 3, which is Cui et al?s default.
Cui et al experimented with two approaches to
rank the candidate answers, called Bigram Model
and Profile Hidden Markov Model (PHMM). Both
are learning components that produce soft pat-
terns, though PHMM is much more complicated. In
their earlier work, Cui et al (2005) found the Bi-
gramModel to perform better than PHMM; in more
recent experiments with more data (Cui, 2006; Cui
et al, 2007) they found PHMM to perform better,
but the difference was not statistically significant.
Given these results and the complexity of PHMM,
we experimented only with the Bigram Model.
In the Bigram Model, the left and right subse-
quences of each candidate answer are considered
separately. Below S
1
, . . . , S
L
refer to the slots
(word positions) of a (left or right) subsequence,
and t
1
, . . . , t
L
to the particular words in the slots.
For each subsequence ?S
1
= t
1
, . . . , S
L
= t
L
? of
a candidate answer, we first estimate:
P (t
i
|S
i
) =
|S
i
(t
i
)| + ?
?
t
?
|S
i
(t
i
)| + ? ?N
P (t
i
|t
i?1
) =
|S
i
(t
i
) ? S
i?1
(t
i?1
)|
|S
i
(t
i
)|
P (t
i
|S
i
) is the probability that t
i
will appear in
slot S
i
of a left or right subsequence (depending on
the subsequence considered) of an acceptable can-
didate answer. P (t
i
|t
i?1
) is the probability that
t
i
will follow t
i?1
in a (left or right) subsequence
of an acceptable candidate answer. Cui et al use
only positive training examples, generated by the
centroid-based approach of section 2.2. |S
i
(t
i
)| is
the number of times t
i
appeared in S
i
in the (left
or right) subsequences of the training examples.
t
?
ranges over all the words that occurred in S
i
in
the training examples. |S
i
(t
i
) ? S
i?1
(t
i?1
)| is the
number of times t
i
and t
i?1
co-occurred in the cor-
responding slots in the training examples. N is the
number of different words that occurred in the (left
or right) training subsequences, and ? is a constant
set to 2, as in Cui et al?s experiments. Following
Cui et al, if t
i
is a POS or other special tag then
the probabilities above are estimated by counting
1275
only the tags of the training examples. Similarly,
if t
i
is an actual word, only the actual words (not
tags) of the training examples are considered.
The probability of each subsequence could then
be estimated as:
P (t
1
, . . . , t
L
) = P (t
1
|S
1
) ?
L
?
i=2
(? ? P (t
i
|t
i?1
) + (1 ? ?) ? P (t
i
|S
i
))
Instead, Cui et al use the following scoring mea-
sure, which also accounts for the fact that some
subsequences may have length l < L. They tune
? by Expectation Maximization.
P
norm
(t
1
, . . . , t
L
) =
1
l
? [logP (t
1
|S
1
) +
L
?
i=2
log(? ? P (t
i
|t
i?1
) + (1 ? ?) ? P (t
i
|S
i
))]
The overall score of a candidate answer is then:
P = (1 ? ?) ? P
norm
(left) + ? ? P
norm
(right)
Again, Cui et al tune a by Expectation Maximiza-
tion. Instead, we tuned ? and ? by a grid search
in [0, 1] ? [0, 1], with step 0.1 for both parame-
ters. For the tuning, we trained Cui et al?s system
on 2,000 randomly selected target terms, exclud-
ing terms used for other purposes. We used 160
manually tagged windows to evaluate the system?s
performance with the different values of ? and ?;
the 160 windows were selected randomly from the
10,000 windows of section 2.3, after excluding the
400 manually tagged windows of that section. The
resulting values for ? and ? were 0.7 and 0.6, re-
spectively. Apart from the modifications we men-
tioned, we use Cui et al?s original implementation.
3.3 Baseline methods
The first baseline selects the first window of each
one of the five highest ranked Web pages, as re-
turned by the search engine, and returns the five
windows. The second baseline returns five win-
dows chosen randomly from the r ? f = 10 ? 5
available ones. The third baseline (centroid base-
line) creates a centroid of the r ? f windows, as in
section 2.2, and returns the five windows with the
highest cosine similarity to the centroid.
11
11
We also reimplemented the definitions component of
Chu-Carroll et al (2004; 2005), but its performance was
worse than our centroid baseline.
Figure 3: Correct responses, 5 answers/question.
4 Evaluation of systems
We used q training target terms in the experi-
ments of this section, with q ranging from 50 to
1500, and 200 testing terms, with no overlap be-
tween training and testing terms, and excluding
terms that had been used for other purpose.
12
We
had to use testing terms for which encyclopedia
definitions were also available, to judge the ac-
ceptability of the systems? responses, since many
terms are highly technical. We discarded, how-
ever, windows extracted from encyclopedia pages
when testing, simulating the case where the target
terms are not covered by encyclopedias.
As already mentioned, for each target term we
extract r ? f = 10 ? 5 windows (or fewer, if fewer
are available) from the pages the search engine re-
turns. We then provide these windows to each of
the systems, allowing them to return up to k = 5
windows, ordered by decreasing confidence. If
any of the k windows contains an acceptable short
definition of the target term, as judged by a hu-
man evaluator, the system?s response is counted as
correct. We also calculate the Mean Reciprocal
Rank (MRR) of each system?s responses, as in the
TREC QA track: if the first acceptable definition of
a response is in the j-th position (1 ? j ? k), the
response?s score is 1/j; MRR is the mean of the re-
sponses? scores, i.e., it rewards systems that return
acceptable definitions higher in their responses.
Figures 3 and 4 show the results of our experi-
ments as percentage of correct responses and MRR,
respectively; the error bars of figure 3 correspond
to 95% confidence intervals. Our system clearly
outperforms Cui et al?s, despite the fact that the
12
The reader is reminded that all terms were selected ran-
domly from the index of an on-line encyclopedia.
1276
Figure 4: MRR scores, 5 answers per question.
latter uses more linguistic resources (a POS tag-
ger and a chunker). Both systems outperform the
baselines, of which the centroid baseline is the
best, and both systems perform better as the size
of the training set increases. The baselines con-
tain no learning components; hence, their curves
are flat. We also show the results (Base-Attrs)
of our system when the features that correspond
to automatically acquired patterns are excluded.
Clearly, these patterns help our system achieve
significantly better results; however, our system
outperforms Cui et al?s even without them. With-
out the automatic patterns, our system also shows
signs of saturation as the training data increase.
Figures 5 and 6 show the performance of our
new system against our previously published one
(Androutsopoulos and Galanis, 2005); the new
system clearly outperforms the old one. Addi-
tional experiments we conducted with the old sys-
tem replacing the SVM by the MAXENT classifier
(without using ROUGE-W) indicate that the use of
MAXENT by itself also improved slightly the re-
sults, but the differences are too minor to show; the
improvement is mostly due to the use of ROUGE-
W instead of our previous measure.
5 Related work
Xu et al (2004) use an information extraction en-
gine to extract linguistic features from documents
relevant to the target term. The features are mostly
phrases, such as appositives, and phrases express-
ing relations. The features are then ranked by their
type and similarity to a centroid, and the most
highly ranked ones are returned. Xu et al seem
to aim at generating multi-snippet definitions, un-
like the single-snippet definitions we seek.
Blair-Goldensohn et al (2003; 2004) extract
sentences that may provide definitional informa-
Figure 5: Correct responses of our new and previ-
ous system, allowing 5 answers per question.
Figure 6: MRR of our new and previous system.
tion from documents retrieved for the target term;
a decision tree learner and manually tagged train-
ing data are used. The sentences are then matched
against manually constructed patterns, which op-
erate on syntax trees, to detect sentences ex-
pressing the target term?s genus, species, or both
(genus+species). The system composes its an-
swer by placing first the genus+species sentence
that is closer to the centroid of the extracted sen-
tences. The remaining sentences are ranked by
their distance from the centroid, and the most
highly ranked ones are clustered. The system then
selects iteratively the cluster that is closer to the
centroid of the extracted sentences and the most
recently used cluster. The cluster?s most repre-
sentative sentence, i.e., the sentence closest to the
centroid of the cluster?s sentences, is added to the
response. The iterations stop when a maximum re-
sponse length is reached. Multi-snippet definitions
are generated.
Han et al (2004; 2006) parse a definition ques-
tion to locate the head word of the target term.
They also use a named entity recognizer to deter-
mine the target term?s type (person, organization,
1277
etc.). They then extract from documents relevant
to the target term sentences containing its head
word, as well as sentences the extracted ones refer
to (e.g., via pronouns). The resulting sentences are
matched against manually constructed syntactic
patterns to detect phrases conveying definitional
information. The resulting phrases are ranked by
criteria like the degree to which the phrase con-
tains words common in definitions of the target
term?s type, and the highest ranked phrases are in-
cluded in a multi-snippet summary. Other mecha-
nisms discard phrases duplicating information.
Xu et al (2005) aim to extract all the definitions
in a document collection. They parse the docu-
ments to detect base noun phrases (without em-
bedded noun phrases). Base noun phrases are pos-
sible target terms; the paragraphs containing them
are matched against manually constructed patterns
that look for definitions. An SVM then separates
the remaining paragraphs into good, indifferent,
and bad definitions. Redundant paragraphs, iden-
tified by edit distance similarity, are removed.
6 Conclusions and future work
We presented a freely available system that finds
short definitions of user-specified terms on Web
pages. It employs a MAXENT classifier, which
is trained on automatically generated examples;
hence, the system is in effect unsupervised. We
use ROUGE-W to generate training examples from
Web snippets and encyclopedias, a method that
outperforms an alternative centroid-based one.
Once our system has been trained, it can find short
definitions of terms that are not covered by ency-
clopedias. Experiments show our system outper-
forms a comparable well-published system and a
previously published form of our system.
Our system does not require linguistic process-
ing tools, such as named entity recognizers, POS
taggers, chunkers, parsers; hence, it can be easily
used in languages where such tools are unavail-
able. It could be improved by exploiting the HTML
markup of Web pages and the Web?s hyperlinks.
For example, the target term is sometimes written
in italics in definitions, and some definitions are
provided on pages (e.g., pop-up windows) that oc-
currences of the target term link to.
The work reported here was conducted in the
context of project INDIGO, where an autonomous
robotic guide for museum collections is being de-
veloped (Galanis et al, 2009). The guide engages
the museum?s visitors in spoken dialogues, and it
describes the exhibits the visitors select by gen-
erating spoken natural language descriptions from
an ontology. Among other requests, the visitors
can ask follow up questions, and we have found
that the most common kind of follow up questions
are requests to define terms (e.g., names of per-
sons, events, architectural terms, etc.) mentioned
in the generated exhibit descriptions. Some of
these definition requests can be handled by gener-
ating new texts from the ontology, but some times
the ontology contains no information for the target
terms. We are, thus, experimenting with the possi-
bility of obtaining short definitions from the Web,
using the system we presented.
Acknowledgements
This work was carried out in INDIGO, an FP6 IST
project funded by the European Union, with addi-
tional funding provided by the Greek General Sec-
retariat of Research and Technology.
13
References
Androutsopoulos, I., and Galanis, D. 2005. A Prac-
tically Unsupervised Learning Method to Identify
Single-Snippet Answers to Definition Questions on
the Web. In HLT/EMNLP, Vancouver, Canada, 323?
330.
Blair-Goldensohn, S., McKeown, K., Schlaikjer, A.H.
2003. A Hybrid Approach for QA Track Definitional
Questions. In TREC 2003, Gaithersburg, MD, USA.
Blair-Goldensohn, S., McKeown, K.R., and Schlaikjer,
A.H. 2004. Answering Definitional Questions: A
Hybrid Approach. In Maybury, M. (Ed.), New Di-
rections in Question answering, AAAI Press.
Chu-Carroll, J., Czuba, K., Prager, J., Ittycheriah, A.,
Blair-Goldensohn, S. 2004. IBM?s PIQUANT II in
TREC 2004. In TREC 2004, Gaithersburg, MD, USA.
Chu-Carroll, J., Czuba, K., Duboue, P., and Prager, J.
2005. IBM?s PIQUANT II in TREC 2005. In TREC
2005, Gaithersburg, MD, USA.
Cristianini, N. and Shawe-Taylor, J. 2000. An Intro-
duction to SVMs. Cambridge University Press.
Cui, H., Kan, M.-Y., Chua, T.-S., and Xiao, J. 2004. A
Comparative Study on Sentence Retrieval for Defi-
nitional Question Answering. In SIGIR workshop on
Information Retrieval for Question Answering, Sal-
vador, Brazil.
13
Consult http://www.ics.forth.gr/indigo/.
1278
Cui, H., Kan, M.Y., Chua, T.S. 2004. Unsupervised
Learning of Soft Patterns for Generating Definitions
from Online News. In WWW, New York, NY, USA.
Cui, H., Kan, M.Y., Chua, T.S. 2005. Generic Soft Pat-
tern Models for Definitional Question Answering. In
ACM SIGIR, Salvador, Brazil.
Cui, H. 2006. Soft Matching for Question Answering.
Ph.D. thesis, National University of Singapore.
Cui, H., Kan, M., and Chua, T. 2007. Soft Pattern
Matching Models for Definitional Question Answer-
ing. ACM Transactions on Information Systems,
25(2):1?30.
Dang, H. T. 2005. Overview of DUC 2005. In DUC at
HLT-EMNLP, Vancouver, Canada.
Dang, H. T. 2006. Overview of DUC 2006. In DUC at
HLT-NAACL, New York, NY, USA.
Eugenio, B. D., Glass, M. 2004. The Kappa Statis-
tic: a Second Look. Computational Linguistics,
301(1):95-101.
Galanis, D., Karakatsiotis, G., Lampouras, G., and An-
droutsopoulos, I. 2009. An Open-Source Natu-
ral Language Generator for OWL Ontologies and
its Use in Protege and Second Life. EACL system
demonstration, Athens, Greece.
Han, K.S., Chung, H., Kim, S.B., Song, Y.I., Lee, J.Y.,
Rim, H.C. 2004. Korea University QA System at
TREC 2004. In TREC 2004, Gaithersburg, MD, USA.
Han, K.S., Song, Y.I., Kim, S.B., and Rim, H.C. 2006.
A Definitional Question Answering System Based on
Phrase Extraction Using Syntactic Patterns. IEICE
Transactions on Information and Systems, vol. E89-
D, No. 4, 1601?1605.
Hildebrandt, W., Katz, B., and Lin, J. 2004. Answer-
ing Definition Questions Using Multiple Knowledge
Sources. In HLT-NAACL, Boston, MA, USA, 49?56.
Joho, H. and Sanderson, M. 2000. Retrieving Descrip-
tive Phrases from Large Amounts of Free Text. Inter-
national Conference on Information and Knowledge
Management, McLean, VA, USA, 180?186.
Joho, H. and Sanderson, M. 2001. Large Scale Testing
of a Descriptive Phrase Finder. In HLT-NAACL, San
Diego, CA, USA, 219?221.
Lin, C.Y. 2004. ROUGE: A Package for Automatic
Evaluation of Summaries. In ACL workshop ?Text
Summarization Branches Out?, Barcelona, Spain.
Miliaraki, S. and Androutsopoulos, I. 2004. Learn-
ing to Identify Single-Snippet Answers to Definition
Questions. In COLING, Geneva, Switzerland, 1360?
1366.
Prager, J., Radev, D., and Czuba, K. 2001. Answering
What-Is Questions by Virtual Annotation. In HLT-
NAACL, San Diego, CA, USA, 26?30.
Prager, J., Chu-Carroll, J., and Czuba, K. 2002. Use of
WordNet Hypernyms for Answering What-Is Ques-
tions. In TREC 2001, Gaithersburg, MD, USA.
Ratnaparkhi A. 1997. A Simple Introduction to Max-
imum Entropy Models for Natural Language Pro-
cessing. Technical Report 97-08, Institute for Re-
search in Cognitive Science, University of Pennsyl-
vania, 1997.
Voorhees, E.M. 2000. Overview of the TREC-9 Ques-
tion Answering Track. NIST, USA.
Voorhees, E.M. 2001. Overview of the TREC 2001
Question Answering Track. NIST, USA.
Voorhees, E.M. 2001. The TREC QA Track. Natural
Language Engineering, 7(4):361?378.
Voorhees, E.M. 2003. Evaluating Answers to Defini-
tion Questions. In HLT-NAACL, Edmonton, Canada.
Xu, J., Weischedel, R., Licuanan, A. 2004. Evaluation
of an Extraction-based Approach to Answering Def-
initional Questions. In ACM SIGIR, Sheffield, UK.
Xu, J., Cao, Y., Li, H., Zhao, M. 2005. Ranking Defini-
tions with Supervised Learning Methods. In WWW,
Chiba, Japan, 811?819.
1279
Proceedings of the EACL 2009 Demonstrations Session, pages 17?20,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
An Open-Source Natural Language Generator for OWL Ontologies and
its Use in Prote?ge? and Second Life
Dimitrios Galanis?, George Karakatsiotis?, Gerasimos Lampouras?, Ion Androutsopoulos?+
?Department of Informatics, Athens University of Economics and Business, Athens, Greece
+Digital Curation Unit, Research Centre ?Athena?, Athens, Greece
Abstract
We demonstrate an open-source natural
language generation engine that produces
descriptions of entities and classes in En-
glish and Greek from OWL ontologies that
have been annotated with linguistic and
user modeling information expressed in
RDF. We also demonstrate an accompany-
ing plug-in for the Prote?ge? ontology editor,
which can be used to create the ontology?s
annotations and generate previews of the
resulting texts by invoking the generation
engine. The engine has been embedded in
robots acting as museum tour guides in the
physical world and in Second Life; here
we demonstrate the latter application.
1 Introduction
NaturalOWL (Galanis and Androutsopoulos, 2007;
Androutsopoulos and Galanis, 2008) is a natu-
ral language generation engine that produces de-
scriptions of entitities (e.g., items for sale, mu-
seum exhibits) and classes (e.g., types of exhibits)
in English and Greek from OWL DL ontologies;
the ontologies must have been annotated with lin-
guistic and user modeling annotations expressed
in RDF.1 An accompanying plug-in for the well
known Prote?ge? ontology editor is available, which
can be used to create the linguistic and user model-
ing annotations while editing an ontology, as well
as to generate previews of the resulting texts by
invoking the generation engine.2
NaturalOWL is based on ideas from ILEX
(O?Donnell et al, 2001) and M-PIRO (Isard et al,
2003; Androutsopoulos et al, 2007), but it uses
1See http://www.w3.org/TR/owl-features/
for information on OWL and its versions. For information
on RDF, consult http://www.w3.org/RDF/.
2M-PIRO?s authoring tool (Androutsopoulos et al, 2007),
now called ELEON (Bilidas et al, 2007), can also be used; see
http://www.iit.demokritos.gr/skel/.
Figure 1: Generating texts in Second Life.
templates instead of systemic grammars, it is pub-
licly available as open-source software, it is writ-
ten entirely in Java, and it provides native support
for OWL ontologies, making it particularly useful
for Semantic Web applications (Antoniou and van
Harmelen, 2004).3 Well known advantages of nat-
ural language generation (Reiter and Dale, 2000)
include the ability to generate texts in multiple lan-
guages from the same ontology; and the ability to
tailor the semantic content and language expres-
sions of the texts to the user type (e.g., child vs.
adult) and the interaction history (e.g., by avoiding
repetitions, or by comparing to previous objects).
In project XENIOS (Vogiatzis et al, 2008), Nat-
uralOWL was embedded in a mobile robot acting
as a museum guide, and in project INDIGO it is
being integrated in a more advanced robotic guide
that includes a multimodal dialogue manager, fa-
cial animation, and mechanisms to recognize and
express emotions (Konstantopoulos et al, 2009).
Here, we demonstrate a similar application, where
NaturalOWL is embedded in a robotic avatar acting
3NaturalOWL comes with a GNU General Public Li-
cense (GPL). The software can be downloaded from
http://nlp.cs.aueb.gr/.
17
as a museum guide in Second Life (Oberlander et
al., 2008), as shown in figure 1. We also demon-
strate how the underlying ontology of the museum
and its linguistic and user modeling annotations
can be edited in Prote?ge?.
2 NaturalOWL?s architecture
NaturalOWL adopts a typical natural language
generation pipeline (Reiter and Dale, 2000). It
produces texts in three stages: document planning,
microplanning, and surface realization.
In document planning, the system first selects
from the ontology the logical facts (OWL triples)
that will be conveyed to the user, taking into ac-
count interest scores manually assigned to the
facts via the annotations of the ontology, as well
as a dynamcally updated user model that shows
what information has already been conveyed to the
user. Logical facts that report similarities or differ-
ences to previously encountered entities may also
be included in the output of content selection, giv-
ing rise to comparisons like the one in figure 1.
The selected facts are then ordered using a man-
ually specified partial order, which is also part of
the ontology?s annotations.
In micro-planning, the system turns each se-
lected fact into a sentence by using micro-plans, in
effect patterns that leave referring expressions un-
derspecified. Figure 2 shows a micro-plan being
edited with NaturalOWL?s Prote?ge? plug-in. The
micro-plan specifies that to express a fact that in-
volves the made-of property, the system should
concatenate an automatically generated referring
expression (e.g., name, pronoun, definite noun
phrase) in nominative case for the owner of the
fact (semantic subject of the triple), the verb form
?is made? (or ?are made?, if the subject is in plu-
ral), the preposition ?of?, and then another au-
tomatically generated referring expression in ac-
cusative case for the filler of the property (seman-
tic object). The referring expressions are gener-
ated by taking into account the context of each
sentence, attempting to avoid repetitions without
introducing ambiguities. Domain-independent ag-
gregation rules are then employed to combine the
resulting sentences into longer ones.
In surface realization, the final form of the text
is produced; it can be marked up automatically
with tags that indicate punctuation symbols, gram-
matical categories, the logical facts expressed by
the sentences, the interest (Int) of each sen-
tence?s information, the degree (Assim) to which
the information is taken to be assimilated by the
user etc., as shown below. In INDIGO, compar-
isons are also marked up with angles that guide
the robot to turn to the object(s) it compares to.
<Period>
<Sentence Property=".../#type"
Int="3" Assim="0">
<Demonstrative ref=".../#exhibit1"
role="owner">
This</Demonstrative>
<Verb>is</Verb>
<NP ref=".../#Amphora" role="filler">
an amphora</NP>
</Sentence>
<Punct>,</Punct>
<Sentence Property=".../#subtype
Int="3" Assim="1">
<EmptyRef ref=".../#Amphora"
role="owner"/>
<NP ref=".../#Vessel" role="filler">
a type of vessel</NP>
</Sentence>
<Punct>;</Punct>
<Sentence Property=".../#paintedBy"
Int="2" Assim="0">
<Pronoun ref=".../#exhibit1"
role="owner">
it</Pronoun>
<Verb>was painted</Verb>
<Preposition>by</Preposition>
<Name ref=".../#pKleo" role="filler">
the painter of Kleophrades</Name>
</Sentence>
<Punct>.</Punct>
</Period>
2.1 Using NaturalOWL?s Prote?ge? plug-in
NaturalOWL?s plug-in for Prote?ge? can be used to
specify all the linguistic and user modeling an-
notations of the ontologies that NaturalOWL re-
quires. The annotations in effect establish a
domain-dependent lexicon, whose entries are as-
sociated with classes or entities of the ontology;
micro-plans, which are associated with proper-
ties of the ontology; a partial order of proper-
ties, which is used in document planning; interest
scores, indicating how interesting the various facts
of the ontology are to each user type; parameters
that control, for example, the desired length of the
generated texts. The plug-in can also be used to
generate previews of the resulting texts, for differ-
ent types of users, with or without comparisons,
etc., as illustrated in figure 3. The resulting anno-
tations are then saved in RDF.
2.2 Using NaturalOWL in Second Life
In Second Life, each user controls an avatar, which
can, among other actions, move in the virtual
world, touch objects, or communicate with other
18
Figure 2: Specifying a micro-plan with NaturalOWL?s Prote?ge? plug-in.
Figure 3: Generating a text preview with NaturalOWL?s Prote?ge? plug-in.
19
avatars; in the latter case, the user types text on the
keyboard. In the Second Life application that we
demonstrate, the robot is an avatar that is not con-
trolled by a human, but by our own Second Life
client software.4 The client software includes a
navigation component, which controls the robot?s
movement, and it allows the robot to ?utter? texts
generated by NaturalOWL, instead of expecting
keyboard input. Whenever a visitor near the robot
touches an exhibit, an appropriate event is sent to
the robot, which then goes near the exhibit and
starts describing it.5
3 Conclusions and further work
The demonstration presents an open-source nat-
ural language generation engine for OWL ontolo-
gies, which generates descriptions of entities and
classes in English and Greek. The engine is ac-
companied by a Prote?ge? plug-in, which can be
used to annotate the ontologies with linguistic and
user modeling information required by the gener-
ation engine. The demonstration includes an ap-
plication in Second Life, where the generation en-
gine is embedded in a robotic avatar acting as a
museum guide. We are currently extending Natu-
ralOWL to handle follow up questions about enti-
ties or classes mentioned in the generated texts.
Acknowledgments
NaturalOWL was developed in project XENIOS,
which was funded by the Greek General Secre-
tariat of Research and Technology and the Euro-
pean Union.6 NaturalOWL is now being extended
in project INDIGO, which is funded by the Euro-
pean Union; our work in INDIGO is also supported
by additional funding from the Greek General Sec-
retariat of Research and Technology.7
References
I. Androutsopoulos and D. Galanis. 2008. Generating
natural language descriptions fromOWL ontologies:
experience from the NaturalOWL system. Technical
report, Department of Informatics, Athens Univer-
sity of Economics and Business, Greece.
4Our client was built using the libsecondlife li-
brary; see http://www.libsecondlife.org/. More
precisly, the robot is an object controlled by an invisible
robotic avatar, which is in turn controlled by our client.
5A video showing the robotic avatar in action is available
at http://www.vimeo.com/801099.
6See http://www.ics.forth.gr/xenios/.
7See http://www.ics.forth.gr/indigo/.
I. Androutsopoulos, J. Oberlander, and V. Karkaletsis.
2007. Source authoring for multilingual generation
of personalised object descriptions. Natural Lan-
guage Engineering, 13(3):191?233.
G. Antoniou and F. van Harmelen. 2004. A Semantic
Web primer. MIT Press.
D. Bilidas, M. Theologou, and V. Karkaletsis. 2007.
Enriching OWL ontologies with linguistic and user-
related annotations: the ELEON system. In Proceed-
ings of the 19th IEEE International Conference on
Tools with Artificial Intelligence, Patras, Greece.
D. Galanis and I. Androutsopoulos. 2007. Generat-
ing multilingual descriptions from linguistically an-
notated OWL ontologies: the NATURALOWL sys-
tem. In Proceedings of the 11th European Workshop
on Natural Language Generation, pages 143?146,
Schloss Dagstuhl, Germany.
A. Isard, J. Oberlander, I. Androutsopoulos, and
C. Matheson. 2003. Speaking the users? languages.
IEEE Intelligent Systems, 18(1):40?45.
S. Konstantopoulos, A. Tegos, D. Bilidas, I. Androut-
sopoulos, G. Lampouras, P. Malakasiotis, C. Math-
eson, and O. Deroo. 2009. Adaptive natural-
language interaction. In Proceedings of 12th Con-
ference of the European Chapter of the Association
for Computational Linguistics (system demonstra-
tions), Athens, Greece.
J. Oberlander, G. Karakatsiotis, A. Isard, and I. An-
droutsopoulos. 2008. Building an adaptive museum
gallery in Second Life. In Proceedings of Museums
and the Web, Montreal, Quebec, Canada.
M. O?Donnell, C. Mellish, J. Oberlander, and A. Knott.
2001. ILEX: an architecture for a dynamic hypertext
generation system. Natural Language Engineering,
7(3):225?250.
E. Reiter and R. Dale. 2000. Building natural lan-
guage generation systems. Cambridge University
Press.
D. Vogiatzis, D. Galanis, V. Karkaletsis, I. Androut-
sopoulos, and C.D. Spyropoulos. 2008. A conver-
sant robotic guide to art collections. In Proceedings
of the 2nd Workshop on Language Technology for
Cultural Heritage Data, Language Resources and
Evaluation Conference, Marrakech, Morocco.
20
Proceedings of the EACL 2009 Demonstrations Session, pages 37?40,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
Adaptive Natural Language Interaction
Stasinos Konstantopoulos
Athanasios Tegos
Dimitris Bilidas
NCSR ?Demokritos?, Athens, Greece
Colin Matheson
Human Communication Research Centre
Edinburgh University, U.K.
Ion Androutsopoulos
Gerasimos Lampouras
Prodromos Malakasiotis
Athens Univ. of Economics and Business
Greece
Olivier Deroo
Acapela Group, Belgium
Abstract
The subject of this demonstration is natu-
ral language interaction, focusing on adap-
tivity and profiling of the dialogue man-
agement and the generated output (text
and speech). These are demonstrated in
a museum guide use-case, operating in a
simulated environment. The main techni-
cal innovations presented are the profiling
model, the dialogue and action manage-
ment system, and the text generation and
speech synthesis systems.
1 Introduction
In this demonstration we present a number of
state-of-the art language technology tools, imple-
menting and integrating the latest discourse and
knowledge representation theories into a complete
application suite, including:
? dialogue management, natural language gen-
eration, and speech synthesis, all modulated
by a flexible and highly adaptable profiling
mechanism;
? robust speech recognition and language inter-
pretation; and,
? an authoring environment for developing the
representation of the domain of discourse as
well as the associated linguistic and adaptiv-
ity resources.
The system demonstration is based on a use
case of a virtual-tour guide in a museum domain.
Demonstration visitors interact with the guide us-
ing headsets and are able to experiment with load-
ing different interaction profiles and observing the
differences in the guide?s behaviour. The demon-
stration also includes the screening of videos from
an embodied instantiation of the system as a robot
guiding visitors in a museum.
2 Technical Content
The demonstration integrates a number of state-of-
the-art language components into a highly adap-
tive natural language interaction system. Adap-
tivity here refers to using interaction profiles that
modulate dialogue management as well as text
generation and speech synthesis. Interaction pro-
files are semantic models that extend the objective
ontological model of the domain of discourse with
subjective information, such as how ?interesting?
or ?important? an entity or statement of the objec-
tive domain model is.
Advanced multimodal dialogue management
capabilities involving and combining input and
output from various interaction modalities and
technologies, such as speech recognition and syn-
thesis, natural language interpretation and gener-
ation, and recognition of/response to user actions,
gestures, and facial expressions.
State-of-the art natural language generation
technology, capable of producing multi-sentence,
coherent natural language descriptions of objects
based on their abstract semantic representation.
The resulting descriptions vary dynamically in
terms of content as well as surface language ex-
pressions used to realize each description, depend-
ing on the interaction history (e.g., comparing
to previously given information) and the adaptiv-
ity parameters (exhibiting system personality and
adapting to user background and interests).
3 System Description
The system is capable of interacting in a vari-
ety of modalities, including non-verbal ones such
as gesture and face-expression recognition, but in
this demonstration we focus on the system?s lan-
guage interaction components. In this modality,
abstract, language-independent system actions are
first planned by the dialogue and action manager
(DAM), then realized into language-specific text
37
by the natural language generation engine, and fi-
nally synthesized into speech. All three layers are
parametrized by a profiling and adaptivity module.
3.1 Profiling and Adaptation
Profiling and adaptation modulates the output of
dialogue management, generation, and speech
synthesis so that the system exhibits a synthetic
personality, while at the same time adapting to
user background and interests.
User stereotypes (e.g., ?expert? or ?child?) pro-
vide generation parameters (such as maximum de-
scription length) and also initialize the dynamic
user model with interest rates for all the ontologi-
cal entities (individuals and properties) of the do-
main of discourse. This same information is also
provided in system profiles reflecting the system?s
(as opposed to the users?) preferences; one can,
for example, define a profile that favours using
the architectural attributes to describe a building
where another profile would choose to concentrate
on historical facts regarding the same building.
Stereotypes and profiles are combined into a
single set of parameters by means of personal-
ity models. Personality models are many-valued
Description Logic definitions of the overall pref-
erence, grounded in stereotype and profile data.
These definitions model recognizable personality
traits so that, for example, an open personality will
attend more to the user?s requests than its own
interests in deriving overall preference (Konstan-
topoulos et al, 2008).
Furthermore, the system dynamically adapts
overall preference according to both interaction
history and the current dialogue state. So, for one,
the initial (static model) interest factor of an ontol-
ogy entity is reduced each time this entity is used
in a description in order to avoid repetitions. On
the other hand, preference will increase if, for ex-
ample, in the current state the user has explicitly
asked about an entity.
3.2 Dialogue and Action Management
The DAM is built around the information-state
update dialogue paradigm of the TRINDIKIT
dialogue-engine toolkit (Cooper and Larsson,
1998) and takes into account the combined user-
robot interest factor when determining informa-
tion state updates.
The DAM combines various interaction modal-
ities and technologies in both interpretation/fusion
and generation/fission. In interpreting user ac-
tions the system recognizes spoken utterances,
simple gestures, and touch-screen input, all of
which may be combined into a representation of
a multi-modal user action. Similarly, when plan-
ning robotic actions the DAM coordinates a num-
ber of available output modalities, including spo-
ken language, text (on the touchscreen), the move-
ment and configuration of the robotic platform, fa-
cial expressions, and simple head gestures.1
To handle multimodal input, the DAM uses a fu-
sion module which combines messages from the
language interpretation, gesture, and touchscreen
modules into a single XML structure. Schemati-
cally, this can be represented as:
<userAction>
<userUtterance>hello</userUtterance>
<userButton content="13"/>
</userAction>
This structure represents a user pressing some-
thing on the touchscreen and saying hello at the
same time.2
The representation is passed essentially un-
changed to the DAM, to be processed by its up-
date rules, where the ID of button press is inter-
preted in context and matched with the speech.
In most circumstances, the natural language pro-
cessing component (see 3.3) produces a seman-
tic representation of the input which appears in
the userUtterance element; the use of ?hello?
above is for illustration. An example update rule
which will fire in the context of a greeting from
the user is (in schematic form):
if
in(/latest_utterance/moves, hello)
then
output(start)
Update rules contain a list of conditions and a
list of effects. Here there is one condition (that the
latest moves from the user includes ?hello?), and
one effect (the ?start? procedure). The latter initi-
ates the dialogue by, among other things, having
the system utter a standardised greeting.
As noted above, the DAM is also multimodal
on the output side. An XML representation is
created which can contain robot utterances and
robot movements (both head movements and mo-
bile platform moves). Information can also be pre-
sented on the touchscreen.
1Expressions and gestures will not be demonstrated, as
they can not be materialized in the simulated robot.
2The precise meaning of ?at the same time? is determined
by the fusion module.
38
3.3 Natural Language Processing
The NATURALOWL natural language generation
(NLG) engine (Galanis et al 2009) produces
multi-sentence, coherent natural language descrip-
tions of objects in multiple languages from a sin-
gle semantic representation; the resulting descrip-
tions are annotated with prosodic markup for driv-
ing the speech synthesisers.
The generated descriptions vary dynamically, in
both content and language expressions, depending
on the interaction profile as well as the dynamic
interaction history. The dynamic preference factor
of the item itself is used to decide the level of de-
tail of the description being generated. The prefer-
ence factors of the properties are used to order the
contents of the descriptions to ensure that, in cases
where not all possible facts are to be presented in
a single turn, the most relevant ones are chosen.
The interaction history is used to check previously
given information to avoid repeating the same in-
formation in different contexts and to create com-
parisons with earlier objects.
NaturalOWL demonstrates the benefits of
adopting NLG on the Semantic Web. Organiza-
tions that need to publish information about ob-
jects, such as exhibits or products, can publish
OWL ontologies instead of texts. NLG engines,
embedded in browsers or Web servers, can then
render the ontologies in natural language, whereas
computer programs may access the ontologies, in
effect logical statements, directly. The descrip-
tions can be very simple and brief, relying on
question answering to provide more information
if such is requested. This way, machine-readable
information can be more naturally inspected and
consulted by users.
In order to generate a list of possible follow
up questions that the system can handle, we ini-
tially construct a list of the particular individuals
or classes that are mentioned in the generated de-
scription; the follow up questions will most likely
refer to them. Only individuals and classes for
which there is further information in the ontology
are extracted.
After identifying the referred individuals and
classes, we proceed to predict definition (e.g.,
?Who was Ares??) and property questions (e.g.,
?Where is Mount Penteli??) about them that
could be answered by the information in the on-
tology. We avoid generating questions that cannot
be answered. The expected definition questions
are constructed by inserting the names of the re-
ferred individuals and classes into templates such
as ?who is/was person X?? or ?what do you know
about class or entity Y??.
In the case of referred individuals, we also gen-
erate expected property questions using the pat-
terns NaturalOWL generates the descriptions with.
These patterns, called microplans, show how to
express the properties of the ontology as sentences
of the target languages. For example, if the indi-
vidual templeOfAres has the property excavate-
dIn, and that property has a microplan of the form
?resource was excavated in period?, we anticipate
questions such as ?when was the Temple of Ares
excavated?? and ?which period was the Temple of
Ares excavated in??.
Whenever a description (e.g., of a monument)
is generated, the expected follow up questions for
that description (e.g., about the monument?s ar-
chitect) are dynamically included in the rules of
the speech recognizer?s grammar, to increase word
recognition accuracy. The rules include compo-
nents that extract entities, classes, and properties
from the recognized questions, thus allowing the
dialogue and action manager to figure out what the
user wishes to know.
3.4 Speech Synthesis and Recognition
The natural language interface demonstrates ro-
bust speech recognition technology, capable of
recognizing spoken phrases in noisy environ-
ments, and advanced speech synthesis, capable of
producing spoken output of very high quality. The
main challenge that the automatic speech recogni-
tion (ASR) module needs to address is background
noise, especially in the robot-embodied use case.
A common technique used in order to handle this
is training acoustic models with the anticipated
background noise, but that is not always possi-
ble. The demonstrated ASR module can be trained
on noise-contaminated data where available, but
also incorporates multi-band acoustic modelling
(Dupont, 2003) for robust recognition under noisy
conditions. Speech recognition rates are also sub-
stantially improved by using the predictions made
by NATURALOWL and the DAM to dynamically
restrict the lexical and phrasal expectations at each
dialogue turn.
The speech synthesis module of the demon-
strated system is based on unit selection technol-
ogy, generally recognized as producing more nat-
39
ural output that previous technologies such as di-
phone concatenation or formant synthesis. The
main innovation that is demonstrated is support for
emotion, a key aspect of increasing the naturalness
of synthetic speech. This is achieved by combin-
ing emotional unit recordings with run-time trans-
formations. With respect to the former, a complete
?voice? now comprises three sub-voices (neutral,
happy, and sad), based on recordings of the same
speaker. The recording time needed is substan-
tially decreased by prior linguistic analysis that se-
lects appropriate text covering all phonetic units
needed by the unit selection system. In addition to
the statically defined sub-voices, the speech syn-
thesis module implements dynamic transforma-
tions (e.g., emphasis), pauses, and variable speech
speed. The system combines all these capabilities
in order to dynamically modulate the synthesised
speech to convey the impression of emotionally
modulated speech.
3.5 Authoring
The interaction system is complemented by
ELEON (Bilidas et al, 2007), an authoring tool for
annotating domain ontologies with the generation
and adaptivity resources described above. The do-
main ontology can be authored in ELEON, but any
existing OWL ontology can also annotated.
More specifically, ELEON supports author-
ing linguistic resources, including a domain-
dependent lexicon, which associates classes and
individuals of the ontology with nouns and proper
names of the target natural languages; microplans,
which provide the NLG with patterns for realizing
property instances as sentences; and a partial or-
dering of properties, which allows the system to
order the resulting sentences as a coherent text.
The adaptivity and profiling resources include
interest rates, indicating how interesting the enti-
ties of the ontology are in any given profile; and
stereotype parameters that control generation as-
pects such as the number of facts to include in a
description or the maximum sentence length.
Furthermore, ELEON supports the author with
immediate previews, so that the effect of any
change in either the ontology or the associated re-
sources can be directly reviewed. The actual gen-
eration of the preview is relegated to external gen-
eration engines.
4 Conclusions
The demonstrated system combines semantic rep-
resentation and reasoning technologies with lan-
guage technology into a human-computer interac-
tion system that exhibits a large degree of adapt-
ability to audiences and circumstances and is able
to take advantage of existing domain model cre-
ated independently of the need to build a natural
language interface. Furthermore by clearly sepa-
rating the abstract, semantic layer from that of the
linguistic realization, it allows the re-use of lin-
guistic resources across domains and the domain
model and adaptivity resources across languages.
Acknowledgements
The demonstrated system is being developed by
the European (FP6-IST) project INDIGO.3 IN-
DIGO develops and advances human-robot inter-
action technology, enabling robots to perceive nat-
ural human behaviour, as well as making them
act in ways that are more familiar to humans. To
achieve its goals, INDIGO advances various tech-
nologies, which it integrates in a robotic platform.
References
Dimitris Bilidas, Maria Theologou, and Vangelis
Karkaletsis. 2007. Enriching OWL ontologies
with linguistic and user-related annotations: the
ELEON system. In Proc. 19th Intl. Conf. on
Tools with Artificial Intelligence (ICTAI-2007).
Robin Cooper and Staffan Larsson. 1998. Dia-
logue Moves and Information States. In: Pro-
ceedings of the 3rd Intl. Workshop on Computa-
tional Semantics (IWCS-3).
Ste?phane Dupont. 2003. Robust parameters
for noisy speech recognition. U.S. Patent
2003182114.
Dimitrios Galanis, George Karakatsiotis, Gerasi-
mos Lampouras and Ion Androutsopoulos.
2009. An open-source natural language gener-
ator for OWL ontologies and its use in Prote?ge?
and Second Life. In this volume.
Stasinos Konstantopoulos, Vangelis Karkaletsis,
and Colin Matheson. 2008. Robot personality:
Representation and externalization. In Proc.
Computational Aspects of Affective and Emo-
tional Interaction (CAFFEi 08), Patras, Greece.
3http://www.ics.forth.gr/indigo/
40
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 561?566,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Using Integer Linear Programming in Concept-to-Text Generation to
Produce More Compact Texts
Gerasimos Lampouras and Ion Androutsopoulos
Department of Informatics
Athens University of Economics and Business
Patission 76, GR-104 34 Athens, Greece
http://nlp.cs.aueb.gr/
Abstract
We present an ILP model of concept-to-
text generation. Unlike pipeline archi-
tectures, our model jointly considers the
choices in content selection, lexicaliza-
tion, and aggregation to avoid greedy de-
cisions and produce more compact texts.
1 Introduction
Concept-to-text natural language generation
(NLG) generates texts from formal knowledge
representations (Reiter and Dale, 2000). With the
emergence of the Semantic Web (Antoniou and
van Harmelen, 2008), interest in concept-to-text
NLG has been revived and several methods
have been proposed to express axioms of OWL
ontologies (Grau et al, 2008) in natural language
(Bontcheva, 2005; Mellish and Sun, 2006; Gala-
nis and Androutsopoulos, 2007; Mellish and Pan,
2008; Schwitter et al, 2008; Schwitter, 2010;
Liang et al, 2011; Williams et al, 2011).
NLG systems typically employ a pipeline archi-
tecture. They usually start by selecting the logi-
cal facts to express. The next stage, text planning,
ranges from simply ordering the selected facts to
complex decisions about the rhetorical structure
of the text. Lexicalization then selects the words
and syntactic structures that will realize each fact,
specifying how each fact can be expressed as a
single sentence. Sentence aggregation then com-
bines sentences into longer ones. Another compo-
nent generates appropriate referring expressions,
and surface realization produces the final text.
Each stage of the pipeline is treated as a lo-
cal optimization problem, where the decisions of
the previous stages cannot be modified. This ar-
rangement produces texts that may not be optimal,
since the decisions of the stages have been shown
to be co-dependent (Danlos, 1984; Marciniak and
Strube, 2005; Belz, 2008). For example, content
selection and lexicalization may lead to more or
fewer sentence aggregation opportunities.
We present an Integer Linear Programming
(ILP) model that combines content selection, lex-
icalization, and sentence aggregation. Our model
does not consider text planning, nor referring ex-
pression generation, which we hope to include in
future work, but it is combined with an external
simple text planner and a referring expression gen-
eration component; we also do not discuss sur-
face realization. Unlike pipeline architectures, our
model jointly examines the possible choices in the
three NLG stages it considers, to avoid greedy local
decisions. Given an individual (entity) or class of
an OWL ontology and a set of facts (OWL axioms)
about the individual or class, we aim to produce a
text that expresses as many of the facts in as few
words as possible. This is important when space is
limited or expensive (e.g., product descriptions on
smartphones, advertisements in search engines).
Although the search space of our model is very
large and ILP problems are in general NP-hard, ILP
solvers can be used, they are very fast in practice,
and they guarantee finding a global optimum. Ex-
periments show that our ILP model outperforms,
in terms of compression, an NLG system that uses
the same components, but connected in a pipeline,
with no deterioration in fluency and clarity.
2 Related work
Marciniak and Strube (2005) propose a general
ILP approach for language processing applications
where the decisions of classifiers that consider
particular, but co-dependent, subtasks need to be
combined. They also show how their approach
can be used to generate multi-sentence route di-
rections, in a setting with very different inputs and
processing stages than the ones we consider.
Barzilay and Lapata (2005) treat content selec-
tion as an optimization problem. Given a pool of
facts and scores indicating the importance of each
561
fact or pair of facts, they select the facts to express
by formulating an optimization problem similar
to energy minimization. In other work, Barzilay
and Lapata (2006) consider sentence aggregation.
Given a set of facts that a content selection stage
has produced, aggregation is viewed as the prob-
lem of partitioning the facts into optimal subsets.
Sentences expressing facts that are placed in the
same subset are aggregated to form a longer sen-
tence. An ILP model is used to find the partitioning
that maximizes the pairwise similarity of the facts
in each subset, subject to constraints limiting the
number of subsets and the facts in each subset.
Althaus et al (2004) show that ordering a set
of sentences to maximize sentence-to-sentence co-
herence is equivalent to the traveling salesman
problem and, hence, NP-complete. They also show
how an ILP solver can be used in practice.
Joint optimization ILP models have also been
used in multi-document text summarization and
sentence compression (McDonald, 2007; Clarke
and Lapata, 2008; Berg-Kirkpatrick et al, 2011;
Galanis et al, 2012; Woodsend and Lapata, 2012),
where the input is text, not formal knowledge rep-
resetations. Statistical methods to jointly perform
content selection, lexicalization, and surface real-
ization have also been proposed in NLG (Liang et
al., 2009; Konstas and Lapata, 2012a; Konstas and
Lapata, 2012b), but they are currently limited to
generating single sentences from flat records.
To the best of our knowledge, this article is the
first one to consider content selection, lexicaliza-
tion, and sentence aggregation as an ILP joint opti-
mization problem in the context of multi-sentence
concept-to-text generation. It is also the first arti-
cle to consider ILP in NLG from OWL ontologies.
3 Our ILP model of NLG
Let F = {f1, . . . , fn} be the set of all the facts fi
(OWL axioms) about the individual or class to be
described. OWL axioms can be represented as sets
of RDF triples of the form ?S,R,O?, where S is an
individual or class, O is another individual, class,
or datatype value, and R is a relation (property)
that connects S to O. Hence, we can assume that
each fact fi is a triple ?Si, Ri, Oi?.1
For each fact fi, a set Pi = {pi1, pi2, . . . }
of alternative sentence plans is available. Each
1We actually convert the RDF triples to simpler message
triples, so that each message triple can be easily expressed by
a simple sentence, but we do not discuss this conversion here.
sentence plan pik specifies how to express fi =
?Si, Ri, Oi? as an alternative single sentence. In
our work, a sentence plan is a sequence of slots,
along with instructions specifying how to fill the
slots in; and each sentence plan is associated
with the relations it can express. For example,
?exhibit12,foundIn,athens? could be ex-
pressed using a sentence plan like ?[ref (S)]
[findpast] [in] [ref (O)]?, where square brackets
denote slots, ref (S) and ref (O) are instructions
requiring referring expressions for S and O in
the corresponding slots, and ?findpast? requires the
simple past form of ?find?. In our example, the
sentence plan would lead to a sentence like ?Ex-
hibit 12 was found in Athens?. We call elements
the slots with their instructions, but with ?S?
and ?O? accompanied by the individuals, classes,
or datatype values they refer to; in our exam-
ple, the elements are ?[ref (S: exhibit12)]?,
?[findpast]?, ?[in]?, ?[ref (O: athens)]?. Dif-
ferent sentence plans may lead to more or fewer
aggregation opportunities; for example, sentences
with the same verb are easier to aggregate. We use
aggregation rules (Dalianis, 1999) that operate on
sentence plans and usually lead to shorter texts.
Let s1, . . . , sm be disjoint subsets of F , each
containing 0 to n facts, with m < n. A single
sentence is generated for each subset sj by aggre-
gating the sentences (more precisely, the sentence
plans) expressing the facts of sj .2 An empty sj
generates no sentence, i.e., the resulting text can
be at most m sentences long. Let us also define:
ai =
{
1, if fact fi is selected
0, otherwise (1)
likj =
?
?
?
1, if sentence plan pik is used to express
fact fi, and fi is in subset sj
0, otherwise
(2)
btj =
{
1, if element et is used in subset sj
0, otherwise (3)
and let B be the set of all the distinct elements (no
duplicates) from all the available sentence plans
that can express the facts of F . The length of an
aggregated sentence resulting from a subset sj can
be roughly estimated by counting the distinct el-
ements of the sentence plans that have been cho-
sen to express the facts of sj ; elements that occur
more than once in the chosen sentence plans of sj
2All the sentences of every possible subset sj can be ag-
gregated, because all the sentences share the same subject,
the class or individual being described. If multiple aggrega-
tion rules apply, we use the one that leads to a shorter text.
562
are counted only once, because they will probably
be expressed only once, due to aggregation.
Our objective function (4) maximizes the num-
ber of selected facts fi and minimizes the number
of distinct elements in each subset sj , i.e., the ap-
proximate length of the corresponding aggregated
sentence; an alternative explanation is that by min-
imizing the number of distinct elements in each sj ,
we favor subsets that aggregate well. By a and b
we jointly denote all the ai and btj variables. The
two parts (sums) of the objective function are nor-
malized to [0, 1] by dividing by the total number
of available facts |F | and the number of subsets m
times the total number of distinct elements |B|. In
the first part of the objective, we treat all the facts
as equally important; if importance scores are also
available for the facts, they can be added as mul-
tipliers of ?i. The parameters ?1 and ?2 are used
to tune the priority given to expressing many facts
vs. generating shorter texts; we set ?1 + ?2 = 1.
max
a,b
?1 ?
|F |?
i=1
ai
|F | ? ?2 ?
m?
j=1
|B|?
t=1
btj
m ? |B| (4)
subject to:
ai =
m?
j=1
|Pi|?
k=1
likj , for i = 1, . . . , n (5)
?
et?Bik
btj ? |Bik| ? likj , for
i = 1, . . . , n
j = 1, . . . ,m
k = 1, . . . , |Pi|
(6)
?
pik?P (et)
likj ? btj , for t = 1, . . . , |B|j = 1, . . . ,m (7)
|B|?
t=1
btj ? Bmax, for j = 1, . . . ,m (8)
|Pi|?
k=1
likj +
|Pi? |?
k?=1
li?k?j ? 1, for
j = 1, . . . ,m, i = 2, . . . , n
i? = 1, . . . , n? 1; i 6= i?
section(fi) 6= section(f ?i)
(9)
Constraint 5 ensures that for each selected fact,
only one sentence plan in only one subset is se-
lected; if a fact is not selected, no sentence plan
for the fact is selected either. |?| denotes the car-
dinality of a set ?. In constraint 6, Bik is the set of
distinct elements et of the sentence plan pik. This
constraint ensures that if pik is selected in a subset
sj , then all the elements of pik are also present in
sj . If pik is not selected in sj , then some of its el-
ements may still be present in sj , if they appear in
another selected sentence plan of sj .
In constraint 7, P (et) is the set of sentence plans
that contain element et. If et is used in a subset sj ,
then at least one of the sentence plans of P (et)
must also be selected in sj . If et is not used in sj ,
then no sentence plan of P (et) may be selected in
sj . Lastly, constraint 8 limits the number of ele-
ments that a subset sj can contain to a maximum
allowed number Bmax, in effect limiting the max-
imum length of an aggregated sentence.
We assume that each relation R has been man-
ually mapped to a single topical section; e.g., re-
lations expressing the color, body, and flavor of
a wine may be grouped in one section, and rela-
tions about the wine?s producer in another. The
section of a fact fi = ?Si, Ri, Oi? is the section
of its relation Ri. Constraint 9 ensures that facts
from different sections will not be placed in the
same subset sj , to avoid unnatural aggregations.
4 Experiments
We used NaturalOWL (Galanis and Androutsopou-
los, 2007; Galanis et al, 2009; Androutsopoulos
et al, 2013), an NLG system for OWL ontologies
that relies on a pipeline of content selection, text
planning, lexicalization, aggregation, referring ex-
pression generation, and surface realization.3 We
modified content selection, lexicalization, and ag-
gregation to use our ILP model, maintaining the
aggregation rules of the original system.4 For re-
ferring expression generation and surface realiza-
tion, the new system, called ILPNLG, invokes the
corresponding components of NaturalOWL.
The original system, called PIPELINE, assumes
that each relation has been mapped to a topical
section, as in ILPNLG. It also assumes that a man-
ually specified order of the sections and the rela-
tions of each section is available, which is used
by the text planner to order the selected facts (by
their relations). The subsequent components of the
pipeline are not allowed to change the order of the
facts, and aggregation operates only on sentence
plans of adjacent facts from the same section. In
ILPNLG, the manually specified order of sections
and relations is used to order the sentences of each
subset sj (before aggregating them), the aggre-
gated sentences in each section (each aggregated
sentence inherits the minimum order of its con-
stituents), and the sections (with their sentences).
We used the Wine Ontology, which had been
3All the software and data we used are freely available
from http://nlp.cs.aueb.gr/software.html.
We use version 2 of NaturalOWL.
4We use the Branch and Cut implementation of GLPK; see
sourceforge.net/projects/winglpk/.
563
used in previous experiments with PIPELINE.5 We
kept the 2 topical sections, the ordering of sec-
tions and relations, and the sentence plans that
had been used in the previous experiments, but we
added more sentence plans to ensure that 3 sen-
tence plans were available per fact. We gener-
ated texts for the 52 wine individuals of the on-
tology; we did not experiment with texts describ-
ing classes of wines, because we could not think
of multiple alternative sentence plans for many of
their axioms. For each individual, there were 5
facts on average and a maximum of 6 facts.
PIPELINE has a parameter M specifying the
maximum number of facts it is allowed to report
per text. When M is smaller than the number of
available facts |F | and all the facts are treated as
equally important, as in our experiments, it se-
lects randomly M of the available facts. We re-
peated the generation of PIPELINE?s texts for the
52 individuals for M = 2, 3, 4, 5, 6. For each M ,
the texts of PIPELINE for the 52 individuals were
generated three times, each time using one of the
different alternative sentence plans of each rela-
tion. We also generated the texts using a variant of
PIPELINE, dubbed PIPELINESHORT, which always
selects the shortest (in elements) sentence plan
among the available ones. In all cases, PIPELINE
and PIPELINESHORT were allowed to form ag-
gregated sentences containing up to Bmax = 22
distinct elements, which was the number of dis-
tinct elements of the longest aggregated sentence
in the previous experiments, where PIPELINE was
allowed to aggregate up to 3 original sentences.
With ILPNLG, we repeated the generation of the
texts of the 52 individuals using different values
of ?1 (?2 = 1 ? ?1), which led to texts express-
ing from zero to all of the available facts. We set
the maximum number of fact subsets to m = 3,
which was the maximum number of aggregated
sentences observed in the texts of PIPELINE and
PIPELINESHORT. Again, we set Bmax = 22.
We compared ILPNLG to PIPELINE and PIPELI-
NESHORT by measuring the average number of
facts they reported divided by the average text
length (in words). Figure 1 shows this ratio as a
function of the average number of reported facts,
along with 95% confidence intervals (of sample
means). PIPELINESHORT achieved better results
than PIPELINE, but the differences were small.
For ?1 < 0.2, ILPNLG produces empty texts,
5See www.w3.org/TR/owl-guide/wine.rdf.
Figure 1: Facts/words ratio of the generated texts.
since it focuses on minimizing the number of dis-
tinct elements of each text. For ?1 ? 0.225, it per-
forms better than the other systems. For ?1 ? 0.3,
it obtains the highest fact/words ratio by select-
ing the facts and sentence plans that lead to the
most compressive aggregations. For greater val-
ues of ?1, it selects additional facts whose sen-
tence plans do not aggregate that well, which is
why the ratio declines. For small numbers of facts,
the two pipeline systems select facts and sentence
plans that offer very few aggregation opportuni-
ties; as the number of selected facts increases,
some more aggregation opportunities arise, which
is why the facts/words ratio of the two systems
improves. In all the experiments, the ILP solver
was very fast (average: 0.08 sec, worst: 0.14 sec).
Experiments with human judges also showed that
the texts of ILPNLG cannot be distinguished from
those of PIPELINESHORT in terms of fluency and
text clarity. Hence, the highest compactness of the
texts of ILPNLG does not come at the expense of
lower text quality. Space does not permit a more
detailed description of these experiments.
We show below texts produced by PIPELINE
(M = 4) and ILPNLG (?1 = 0.3).
PIPELINE: This is a strong Sauternes. It is made from Semil-
lon grapes and it is produced by Chateau D?ychem.
ILPNLG: This is a strong Sauternes. It is made from Semillon
grapes by Chateau D?ychem.
PIPELINE: This is a full Riesling and it has moderate flavor.
It is produced by Volrad.
ILPNLG: This is a full sweet moderate Riesling.
In the first pair, PIPELINE uses different verbs for
the grapes and producer, whereas ILPNLG uses the
same verb, which leads to a more compressive ag-
gregation; both texts describe the same wine and
report 4 facts. In the second pair, ILPNLG has cho-
sen to express the sweetness instead of the pro-
ducer, and uses the same verb (?be?) for all the
facts, leading to a shorter sentence; again both
texts describe the same wine and report 4 facts.
564
In both examples, some facts are not aggregated
because they belong in different sections.
5 Conclusions
We presented an ILP model for NLG that jointly
considers the choices in content selection, lexical-
ization, and aggregation to avoid greedy local de-
cisions and produce more compact texts. Exper-
iments verified that our model can express more
facts per word, compared to a pipeline, which is
important when space is scarce. An off-the-shelf
ILP solver took approximately 0.1 sec for each
text. We plan to extend our model to include text
planning and referring expressions generation.
Acknowledgments
This research has been co-financed by the Euro-
pean Union (European Social Fund ? ESF) and
Greek national funds through the Operational Pro-
gram ?Education and Lifelong Learning? of the
National Strategic Reference Framework (NSRF)
? Research Funding Program: Heracleitus II. In-
vesting in knowledge society through the Euro-
pean Social Fund.
References
E. Althaus, N. Karamanis, and A. Koller. 2004. Com-
puting locally coherent discourses. In 42nd Annual
Meeting of ACL, pages 399?406, Barcelona, Spain.
I. Androutsopoulos, G. Lampouras, and D. Gala-
nis. 2013. Generating natural language descrip-
tions from OWL ontologies: the NaturalOWL sys-
tem. Technical report, Natural Language Processing
Group, Department of Informatics, Athens Univer-
sity of Economics and Business.
G. Antoniou and F. van Harmelen. 2008. A Semantic
Web primer. MIT Press, 2nd edition.
R. Barzilay and M. Lapata. 2005. Collective content
selection for concept-to-text generation. In HLT-
EMNLP, pages 331?338, Vancouver, BC, Canada.
R. Barzilay and M. Lapata. 2006. Aggregation via
set partitioning for natural language generation. In
HLT-NAACL, pages 359?366, New York, NY.
A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engi-
neering, 14(4):431?455.
T. Berg-Kirkpatrick, D. Gillick, and D. Klein. 2011.
Jointly learning to extract and compress. In 49th
Annual Meeting of ACL, pages 481?490, Portland,
OR.
K. Bontcheva. 2005. Generating tailored textual sum-
maries from ontologies. In 2nd European Semantic
Web Conf., pages 531?545, Heraklion, Greece.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear program-
ming approach. Journal of Artificial Intelligence Re-
search, 1(31):399?429.
H. Dalianis. 1999. Aggregation in natural language
generation. Comput. Intelligence, 15(4):384?414.
L. Danlos. 1984. Conceptual and linguistic decisions
in generation. In 10th COLING, pages 501?504,
Stanford, CA.
D. Galanis and I. Androutsopoulos. 2007. Generating
multilingual descriptions from linguistically anno-
tated OWL ontologies: the NaturalOWL system. In
11th European Workshop on Natural Lang. Genera-
tion, pages 143?146, Schloss Dagstuhl, Germany.
D. Galanis, G. Karakatsiotis, G. Lampouras, and I. An-
droutsopoulos. 2009. An open-source natural lan-
guage generator for OWL ontologies and its use in
Prote?ge? and Second Life. In 12th Conf. of the Euro-
pean Chapter of ACL (demos), Athens, Greece.
D. Galanis, G. Lampouras, and I. Androutsopoulos.
2012. Extractive multi-document summarization
with Integer Linear Programming and Support Vec-
tor Regression. In COLING, pages 911?926, Mum-
bai, India.
B.C. Grau, I. Horrocks, B. Motik, B. Parsia, P. Patel-
Schneider, and U. Sattler. 2008. OWL 2: The next
step for OWL. Web Semantics, 6:309?322.
I. Konstas and M. Lapata. 2012a. Concept-to-text gen-
eration via discriminative reranking. In 50th Annual
Meeting of ACL, pages 369?378, Jeju Island, Korea.
I. Konstas and M. Lapata. 2012b. Unsupervised
concept-to-text generation with hypergraphs. In
HLT-NAACL, pages 752?761, Montre?al, Canada.
P. Liang, M. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
47th Meeting of ACL and 4th AFNLP, pages 91?99,
Suntec, Singapore.
S.F. Liang, R. Stevens, D. Scott, and A. Rector. 2011.
Automatic verbalisation of SNOMED classes using
OntoVerbal. In 13th Conf. AI in Medicine, pages
338?342, Bled, Slovenia.
T. Marciniak and M. Strube. 2005. Beyond the
pipeline: Discrete optimization in NLP. In 9th Con-
ference on Computational Natural Language Learn-
ing, pages 136?143, Ann Arbor, MI.
R. McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Eu-
ropean Conference on Information Retrieval, pages
557?564, Rome, Italy.
565
C. Mellish and J.Z. Pan. 2008. Natural language di-
rected inference from ontologies. Artificial Intelli-
gence, 172:1285?1315.
C. Mellish and X. Sun. 2006. The Semantic Web as a
linguistic resource: opportunities for nat. lang. gen-
eration. Knowledge Based Systems, 19:298?303.
E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge Univ. Press.
R. Schwitter, K. Kaljurand, A. Cregan, C. Dolbear, and
G. Hart. 2008. A comparison of three controlled
nat. languages for OWL 1.1. In 4th OWL Experi-
ences and Directions Workshop, Washington DC.
R. Schwitter. 2010. Controlled natural languages for
knowledge representation. In 23rd COLING, pages
1113?1121, Beijing, China.
S. Williams, A. Third, and R. Power. 2011. Levels
of organization in ontology verbalization. In 13th
European Workshop on Natural Lang. Generation,
pages 158?163, Nancy, France.
K. Woodsend and M. Lapata. 2012. Multiple aspect
summarization using integer linear programming. In
EMNLP-CoNLL, pages 233?243, Jesu Island, Ko-
rea.
566
Proceedings of the 14th European Workshop on Natural Language Generation, pages 51?60,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Using Integer Linear Programming for Content Selection, Lexicalization,
and Aggregation to Produce Compact Texts from OWL Ontologies
Gerasimos Lampouras and Ion Androutsopoulos
Department of Informatics
Athens University of Economics and Business
Patission 76, GR-104 34 Athens, Greece
http://nlp.cs.aueb.gr/
Abstract
We present an Integer Linear Program-
ming model of content selection, lexical-
ization, and aggregation that we devel-
oped for a system that generates texts from
OWL ontologies. Unlike pipeline archi-
tectures, our model jointly considers the
available choices in these three text gen-
eration stages, to avoid greedy decisions
and produce more compact texts. Experi-
ments with two ontologies confirm that it
leads to more compact texts, compared to
a pipeline with the same components, with
no deterioration in the perceived quality of
the generated texts. We also present an ap-
proximation of our model, which allows
longer texts to be generated efficiently.
1 Introduction
Concept-to-text natural language generation
(NLG) generates texts from formal knowledge
representations (Reiter and Dale, 2000). With the
emergence of the Semantic Web (Berners-Lee et
al., 2001; Shadbolt et al, 2006; Antoniou and
van Harmelen, 2008), interest in concept-to-text
NLG has been revived and several methods have
been proposed to express axioms of OWL ontolo-
gies (Grau et al, 2008), a form of description
logic (Baader et al, 2002), in natural language
(Bontcheva, 2005; Mellish and Sun, 2006; Gala-
nis and Androutsopoulos, 2007; Mellish and Pan,
2008; Schwitter et al, 2008; Schwitter, 2010;
Liang et al, 2011; Williams et al, 2011).
NLG systems typically employ a pipeline archi-
tecture. They usually start by selecting the logical
facts (axioms, in the case of an OWL ontology) to
be expressed. The purpose of the next stage, text
planning, ranges from simply ordering the facts to
be expressed to making more complex decisions
about the rhetorical structure of the text. Lexical-
ization then selects the words and syntactic struc-
tures that will realize each fact, specifying how
each fact can be expressed as a single sentence.
Sentence aggregation may then combine shorter
sentences to form longer ones. Another compo-
nent generates appropriate referring expressions,
and surface realization produces the final text.
Each stage of the pipeline is treated as a lo-
cal optimization problem, where the decisions of
the previous stages cannot be modified. This ar-
rangement produces texts that may not be optimal,
since the decisions of the stages have been shown
to be co-dependent (Danlos, 1984; Marciniak and
Strube, 2005; Belz, 2008). For example, deci-
sions made during content selection may maxi-
mize importance measures, but may produce facts
that are difficult to turn into a coherent text; also,
content selection and lexicalization may lead to
more or fewer sentence aggregation opportunities.
Some of these problems can be addressed by over-
generating at each stage (e.g., producing several
alternative sets of facts at the end of content selec-
tion, several alternative lexicalizations etc.) and
employing a final ranking component to select the
best combination (Walker et al, 2001). This over-
generate and rank approach, however, may also
fail to find an optimal solution, and it generates an
exponentially large number of candidate solutions
when several components are pipelined.
In this paper, we present an Integer Linear Pro-
gramming (ILP) model that combines content se-
lection, lexicalization, and sentence aggregation.
Our model does not consider directly text plan-
ning, nor referring expression generation, which
we hope to include in future work, but it is com-
bined with an external simple text planner and an
external referring expression generation compo-
nent; we also do not discuss surface realization.
Unlike pipeline architectures, our model jointly
examines the possible choices in the three NLG
stages it considers, to avoid greedy local decisions.
51
Given an individual (entity) or class of an OWL
ontology and a set of facts (axioms) about the in-
dividual or class, we aim to produce a compact
text that expresses as many facts in as few words
as possible. This is desirable when space is lim-
ited or expensive, e.g., when displaying product
descriptions on smartphones, or when including
advertisements in Web search results. If an impor-
tance score is available for each fact, our model
can take it into account to prefer expressing im-
portant facts, again using as few words as possi-
ble. The model itself, however, does not produce
importance scores, i.e., we assume that the scores
are produced by a separate process (Barzilay and
Lapata, 2005; Demir et al, 2010), not included in
our content selection. In the experiments of this
article, we treat all the facts as equally important.
Although the search space of our model is very
large and ILP problems are in general NP-hard, off-
the-shelf ILP solvers can be used, which can be
very fast in practice and guarantee finding a global
optimum. Experiments with two ontologies show
that our ILP model outperforms, in terms of ex-
pressed facts per word, an NLG system that uses
the same components connected in a pipeline, with
no deterioration in perceived text quality; the ILP
model may actually lead to texts of higher quality,
compared to those of the pipeline, when there are
many facts to express. We also present an approx-
imation of our ILP model, which is more efficient
when larger numbers of facts need to be expressed.
Section 2 discusses previous related work. Sec-
tion 3 defines our ILP model. Section 4 presents
our experimentals. Section 5 concludes.
2 Related work
Marciniak and Strube (2005) propose a general
ILP approach for language processing applications
where the decisions of classifiers that consider
particular, but co-dependent, subtasks need to be
combined. They also show how their approach
can be used to generate multi-sentence route di-
rections, in a setting with very different inputs and
processing stages than the ones we consider.
Barzilay and Lapata (2005) treat content selec-
tion as an optimization problem. Given a pool of
facts and scores indicating their importance, they
select the facts to express by formulating an op-
timization problem similar to energy minimiza-
tion. The problem is solved by applying a minimal
cut partition algorithm to a graph representing the
pool of facts and the importance scores. The im-
portance scores of the facts are obtained via super-
vised machine learning (AdaBoost) from a dataset
of (sports) facts and news articles expressing them.
In other work, Barzilay and Lapata (2006) con-
sider sentence aggregation. Given a set of facts
that a content selection stage has produced, aggre-
gation is viewed as the problem of partitioning the
facts into optimal subsets. Sentences expressing
facts of the same subset are aggregated to form a
longer sentence. The optimal partitioning maxi-
mizes the pairwise similarity of the facts in each
subset, subject to constraints that limit the number
of subsets and the number of facts in each sub-
set. A Maximum Entropy classifier predicts the
semantic similarity of each pair of facts, and an
ILP model is used to find the optimal partitioning.
Althaus et al (2004) show that ordering a set of
sentences to maximize local coherence is equiva-
lent to the traveling salesman problem and, hence,
NP-complete. They also show an ILP formulation
of the problem, which can be solved efficiently in
practice using branch-and-cut with cutting planes.
Kuznetsova et al (2012) use ILP to generate im-
age captions. They train classifiers to detect the
objects in each image. Having identified the ob-
jects of a given image, they retrieve phrases from
the captions of a corpus of images, focusing on
the captions of objects that are similar (color, tex-
ture, shape) to the ones in the given image. To
select which objects of the image to report and
in what order, Kuznetsova et al maximize (via
ILP) the mean of the confidence scores of the ob-
ject detection classifiers and the sum of the co-
occurrence probabilities of the objects that will be
reported in adjacent positions in the caption. Hav-
ing decided which objects to report and their order,
Kuznetsova et al use a second ILP model to decide
which phrases to use for each object and to order
the phrases. The second ILP model maximizes the
confidence of the phrase retrieval algorithm and
the local cohesion between subsequent phrases.
Joint optimization ILP models have also been
used in multi-document text summarization and
sentence compression (McDonald, 2007; Clarke
and Lapata, 2008; Berg-Kirkpatrick et al, 2011;
Galanis et al, 2012; Woodsend and Lapata, 2012),
where the input is text, not formal knowledge rep-
resetations. Statistical methods to jointly perform
content selection, lexicalization, and surface real-
ization have also been proposed in NLG (Liang et
52
al., 2009; Konstas and Lapata, 2012a; Konstas and
Lapata, 2012b), but they are currently limited to
generating single sentences from flat records, as
opposed to ontologies. Our method is the first one
to consider content selection, lexicalization, and
sentence aggregation as an ILP joint optimization
problem in the context of multi-sentence concept-
to-text generation.
3 Our ILP model of NLG
Let F = {f1, . . . , fn} be the set of all the facts fi
(OWL axioms) about the individual or class to be
described. OWL axioms can be represented as sets
of RDF triples of the form ?S,R,O?, where S is an
individual or class, O is another individual, class,
or datatype value, and R is a relation (property)
that connects S to O.1 Hence, we can assume that
each fact fi is a triple ?Si, Ri, Oi?.2
For each fact fi, a set Pi = {pi1, pi2, . . . }
of alternative sentence plans is available. Each
sentence plan pik specifies how to express fi =
?Si, Ri, Oi? as an alternative single sentence. In
our work, a sentence plan is a sequence of slots,
along with instructions specifying how to fill the
slots in; and each sentence plan is associated
with the relations it can express. For example,
?exhibit12,foundIn,athens? could be ex-
pressed using a sentence plan like ?[ref (S)]
[findpast] [in] [ref (O)]?, where square brackets
denote slots, ref (S) and ref (O) are instructions
requiring referring expressions for S and O in
the corresponding slots, and ?findpast? requires the
simple past form of ?find?. In our example, the
sentence plan would lead to a sentence like ?Ex-
hibit 12 was found in Athens?. We call elements
the slots with their instructions, but with ?S?
and ?O? accompanied by the individuals, classes,
or datatype values they refer to; in our exam-
ple, the elements are ?[ref (S: exhibit12)]?,
?[findpast]?, ?[in]?, ?[ref (O: athens)]?.
Different sentence plans may lead to more or
fewer aggregation opportunities; e.g., sentences
with the same verb are easier to aggregate. We
use aggregation rules similar to those of Dalianis
(1999), which operate on sentence plans and usu-
ally lead to shorter texts, as in the example below.
Bancroft Chardonnay is a kind of Chardonnay. It is
1See www.w3.org/TR/owl2-mapping-to-rdf/.
2We actually convert the RDF triples to simpler message
triples, so that each message triple can be easily expressed by
a simple sentence, but we do not discuss this conversion here.
made in Bancroft. ? Bancroft Chardonnay is a kind
of Chardonnay made in Bancroft.
Let s1, . . . , sm be disjoint subsets of F , each
containing 0 to n facts, with m < n. A single
sentence is generated for each subset sj by aggre-
gating the sentences (more precisely, the sentence
plans) expressing the facts of sj .3 An empty sj
generates no sentence, i.e., the resulting text can
be at most m sentences long. Let us also define:
ai =
{
1, if fact fi is selected
0, otherwise (1)
likj =
?
?
?
1, if sentence plan pik is used to express
fact fi, and fi is in subset sj
0, otherwise
(2)
btj =
{
1, if element et is used in subset sj
0, otherwise (3)
and let B be the set of all the distinct elements (no
duplicates) from all the available sentence plans
that can express the facts of F . The length of an
aggregated sentence resulting from a subset sj can
be roughly estimated by counting the distinct el-
ements of the sentence plans that have been cho-
sen to express the facts of sj ; elements that occur
more than once in the chosen sentence plans of sj
are counted only once, because they will probably
be expressed only once, due to aggregation.
Our objective function (4) maximizes the to-
tal importance of the selected facts (or simply the
number of selected facts, if all facts are equally
important), and minimizes the number of distinct
elements in each subset sj , i.e., the approximate
length of the corresponding aggregated sentence;
an alternative explanation is that by minimizing
the number of distinct elements in each sj , we fa-
vor subsets that aggregate well. By a and b we
jointly denote all the ai and btj variables. The
two parts of the objective function are normalized
to [0, 1] by dividing by the total number of avail-
able facts |F | and the number of subsets m times
the total number of distinct elements |B|. We as-
sume that the importance scores imp(fi) are pro-
vided by a separate component (Barzilay and La-
pata, 2005; Demir et al, 2010) and range in [0, 1].
The parameters ?1, ?2 are used to tune the prior-
ity given to expressing many important facts vs.
3All the sentences of every possible subset sj can be ag-
gregated, because all the sentences share the same subject,
the class or individual being described. If multiple aggrega-
tion rules apply, we use the one that leads to a shorter text.
53
generating shorter texts; we set ?1 + ?2 = 1.
max
a,b
?1 ?
|F |?
i=1
ai ? imp(fi)
|F |
? ?2 ?
m?
j=1
|B|?
t=1
btj
m ? |B|
(4)
subject to:
ai =
m?
j=1
|Pi|?
k=1
likj , for i = 1, . . . , n (5)
?
et?Bik
btj ? |Bik| ? likj , for
i = 1, . . . , n
j = 1, . . . ,m
k = 1, . . . , |Pi|
(6)
?
pik?P (et)
likj ? btj , for
t = 1, . . . , |B|
j = 1, . . . ,m (7)
|B|?
t=1
btj ? Bmax, for j = 1, . . . ,m (8)
|Pi|?
k=1
likj +
|Pi? |?
k?=1
li?k?j ? 1, for
j = 1, . . . ,m, i = 2, . . . , n
i? = 1, . . . , n? 1; i 6= i?
section(fi) 6= section(f ?i)
(9)
Constraint 5 ensures that for each selected fact,
only one sentence plan in only one subset is se-
lected; if a fact is not selected, no sentence plan
for the fact is selected either. |?| denotes the car-
dinality of a set ?. In constraint 6, Bik is the set of
distinct elements et of the sentence plan pik. This
constraint ensures that if pik is selected in a subset
sj , then all the elements of pik are also present in
sj . If pik is not selected in sj , then some of its el-
ements may still be present in sj , if they appear in
another selected sentence plan of sj .
In constraint 7, P (et) is the set of sentence plans
that contain element et. If et is used in a subset sj ,
then at least one of the sentence plans of P (et)
must also be selected in sj . If et is not used in sj ,
then no sentence plan of P (et) may be selected in
sj . Lastly, constraint 8 limits the number of ele-
ments that a subset sj can contain to a maximum
allowed number Bmax, in effect limiting the max-
imum length of an aggregated sentence.
We assume that each relation R has been man-
ually mapped to a single topical section; e.g., re-
lations expressing the color, body, and flavor of
a wine may be grouped in one section, and rela-
tions about the wine?s producer in another. The
section of a fact fi = ?Si, Ri, Oi? is the section
of its relation Ri. Constraint 9 ensures that facts
from different sections will not be placed in the
same subset sj , to avoid unnatural aggregations.
4 Experiments
We used NaturalOWL (Galanis and Androutsopou-
los, 2007; Galanis et al, 2009; Androutsopou-
los et al, 2013), an NLG system for OWL on-
tologies that relies on a pipeline of content selec-
tion, text planning, lexicalization, aggregation, re-
ferring expression generation, and surface realiza-
tion components.4 We modified the content selec-
tion, lexicalization, and aggregation components
to use our ILP model, maintaining the aggrega-
tion rules of the original system. For referring ex-
pressions and surface realization, the new system,
called ILPNLG, invokes the corresponding compo-
nents of the original system. We use branch-and-
cut to solve the ILP problems.5
The original system, hereafter called PIPELINE,
assumes that each relation has been mapped to a
topical section, as in ILPNLG. It also assumes that
a manually specified order of the sections and the
relations of each section is available, which is used
by the text planner to order the selected facts (by
their relations). The subsequent components of the
pipeline are not allowed to change the order of the
facts, and aggregation operates only on sentence
plans of adjacent facts from the same section. In
ILPNLG, the manually specified order of sections
and relations is used to order the sentences of each
subset sj (before aggregating them), the aggre-
gated sentences in each section (each aggregated
sentence inherits the minimum order of its con-
stituents), and the sections (with their sentences).
4.1 Experiments with the Wine Ontology
In a first set of experiments, we used the Wine On-
tology, which had also been used in previous ex-
periments with PIPELINE (Androutsopoulos et al,
2013). The ontology contains 63 wine classes, 52
wine individuals, a total of 238 classes and indi-
viduals (including wineries, regions, etc.), and 14
properties.6 We kept the 2 topical sections, the
ordering of sections and relations, and the sen-
tence plans of the previous experiments, but we
added more sentence plans to ensure that 3 sen-
tence plans were available per relation. We gen-
erated English texts for the 52 wine individuals
4All the software and data that we used will be
freely available from http://nlp.cs.aueb.gr/
software.html. We use version 2 of NaturalOWL.
5We use the branch-and-cut implementation of GLPK with
mixed integer rounding, mixed cover, and clique cuts; see
sourceforge.net/projects/winglpk/.
6See www.w3.org/TR/owl-guide/wine.rdf.
54
of the ontology; we did not experiment with texts
describing classes, because we could not think of
multiple alternative sentence plans for many of
their axioms. For each wine individual, there were
5 facts on average and a maximum of 6 facts. We
set the importance scores imp(fi) of all the facts
fi to 1, to make the decisions of PIPELINE and
ILPNLG easier to understand; both systems use the
same importance scores. PIPELINE does not pro-
vide any mechanism to estimate the importance
scores, assuming that they are provided manually.
PIPELINE has a parameter M specifying the
maximum number of facts it is allowed to report
per text. When M is smaller than the number of
available facts (|F |) and all the facts are treated
as equally important, as in our experiments, it se-
lects randomly M of the available facts. We re-
peated the generation of PIPELINE?s texts for the
52 individuals for M = 2, 3, 4, 5, 6. For each M ,
the texts of PIPELINE for the 52 individuals were
generated three times, each time using one of the
different alternative sentence plans of each rela-
tion. We also generated the texts using a variant of
PIPELINE, dubbed PIPELINESHORT, which always
selects the shortest (in elements) sentence plan
among the available ones. In all cases, PIPELINE
and PIPELINESHORT were allowed to form ag-
gregated sentences containing up to Bmax = 22
distinct elements, which was the number of dis-
tinct elements of the longest aggregated sentence
in the previous experiments (Androutsopoulos et
al., 2013), where PIPELINE was allowed to aggre-
gate up to 3 original sentences.7
With ILPNLG, we repeated the generation of the
texts of the 52 individuals using different values
of ?1 (?2 = 1 ? ?1), which led to texts express-
ing from zero to all of the available facts. We set
the maximum number of fact subsets to m = 3,
which was the maximum number of (aggregated)
sentences in the texts of PIPELINE and PIPELI-
NESHORT. Again, we set Bmax = 22.
We compared ILPNLG to PIPELINE and PIPELI-
NESHORT by measuring the average number of
facts they reported divided by the average text
length (in words). Figure 1 shows this ratio as a
function of the average number of reported facts,
along with 95% confidence intervals (of sample
means). PIPELINESHORT achieved better results
than PIPELINE, but the differences were small.
For ?1 < 0.2, ILPNLG produces empty texts,
7We modified the two pipeline systems to count elements.
Figure 1: Facts/words of Wine Ontology texts.
because it focuses on minimizing the number of
distinct elements of each text. For ?1 ? 0.225,
it performs better than the other systems. For
?1 ? 0.3, it obtains the highest fact/words ratio
by selecting the facts and sentence plans that lead
to the most compressive aggregations. For greater
values of ?1, it selects additional facts whose sen-
tence plans do not aggregate that well, which is
why the ratio declines. For small numbers of facts,
the two pipeline systems select facts and sentence
plans that offer few aggregation opportunities; as
the number of selected facts increases, some more
aggregation opportunities arise, which is why the
facts/words ratio of the two systems improves. In
all the experiments, the ILP solver was very fast
(average: 0.08 sec, worst: 0.14 sec per text).
We show below texts produced by PIPELINE
(M = 4) and ILPNLG (?1 = 0.3).
PIPELINE: This is a strong Sauternes. It is made from Semil-
lon grapes and it is produced by Chateau D?ychem.
ILPNLG: This is a strong Sauternes. It is made from Semillon
grapes by Chateau D?ychem.
PIPELINE: This is a full Riesling and it has moderate flavor.
It is produced by Volrad.
ILPNLG: This is a full sweet moderate Riesling.
In the first pair, PIPELINE uses different verbs for
the grapes and producer, whereas ILPNLG uses the
same verb, which leads to a more compressive ag-
gregation; both texts describe the same wine and
report 4 facts. In the second pair, ILPNLG has cho-
sen to express the sweetness instead of the pro-
ducer, and uses the same verb (?be?) for all the
facts, leading to a shorter sentence; again both
texts describe the same wine and report 4 facts.
In both examples, some facts are not aggregated
because they belong in different sections.
We also wanted to investigate the effect that the
higher facts/words ratio of ILPNLG has on the per-
ceived quality of the generated texts, compared
to the texts of the pipeline. We were concerned
that the more compressive aggregations of ILPNLG
55
Criteria PIPELINESHORT ILPNLG
Sentence fluency 4.75 ? 0.21 4.85 ? 0.10
Text structure 4.94 ? 0.06 4.88 ? 0.14
Clarity 4.77 ? 0.18 4.75 ? 0.15
Overall 4.52 ? 0.20 4.60 ? 0.18
Table 1: Human scores for Wine Ontology texts.
might lead to sentences that sound less fluent or
unnatural, though aggregation often helps produce
more natural texts. We were also concerned that
the more compact texts of ILPNLG might be per-
ceived as being more difficult to understand (less
clear) or less well-structured. To investigate these
issues, we showed the 52 ? 2 = 104 texts of
PIPELINESHORT (M = 4) and ILPNLG (?1 = 0.3)
to 6 computer science students not involved in the
work of this article; they were all fluent, though
not native, English speakers. Each one of the 104
texts was given to exactly one student. Each stu-
dent was given approximately 9 randomly selected
texts of each system. The OWL statements that the
texts were generated from were not shown, and the
students did not know which system had generated
each text. Each student was shown all of his/her
texts in random order, regardless of the system that
generated them. The students were asked to score
each text by stating how strongly they agreed or
disagreed with statements S1?S3 below. A scale
from 1 to 5 was used (1: strong disagreement, 3:
ambivalent, 5: strong agreement).
(S1) Sentence fluency: The sentences of the text are fluent,
i.e., each sentence on its own is grammatical and sounds nat-
ural. When two or more smaller sentences are combined to
form a single, longer sentence, the resulting longer sentence
is also grammatical and sounds natural.
(S2) Text structure: The order of the sentences is appro-
priate. The text presents information by moving reasonably
from one topic to another.
(S3) Clarity: The text is easy to understand, provided that
the reader is familiar with basic wine terms.
The students were also asked to provide an over-
all score (1?5) per text. We did not score referring
expressions, since both systems use the same com-
ponent to generate them.
Table 1 shows the average scores of the two
systems with 95% confidence intervals (of sam-
ple means). For each criterion, the best score is
shown in bold. The sentence fluency and over-
all scores of ILPNLG are slightly higher than those
of PIPELINESHORT, whereas PIPELINESHORT ob-
tained a slightly higher score for text structure and
clarity. The differences, however, are very small,
especially in clarity, and there is no statistically
significant difference between the two systems in
any of the criteria.8 Hence, there was no evidence
in these experiments that the highest facts/words
ratio of ILPNLG comes at the expense of lower per-
ceived text quality. We investigated these issues
further in a second set of experiments, discussed
next, where the generated texts were longer.
4.2 Consumer Electronics experiments
In the second set of experiments, we used the
Consumer Electronics Ontology, which had also
been used in previous work with PIPELINE. The
ontology comprises 54 classes and 441 individ-
uals (e.g., printer types, paper sizes), but no in-
formation about particular products.9 In previ-
ous work, 30 individuals (10 digital cameras, 10
camcorders, 10 printers) were added to the ontol-
ogy; they were randomly selected from a publicly
available dataset of 286 digital cameras, 613 cam-
corders, and 58 printers, whose instances comply
with the Consumer Electronics Ontology.10 We
kept the 6 topical sections, the ordering of sec-
tions and relations, and the sentence plans of the
previous work, but we added more sentence plans
to ensure that 3 sentence plans were available for
almost every relation; for some relations we could
not think of enough sentence plans. Again, we set
the importance scores of all the facts to 1.
We generated texts with PIPELINE and PIPELI-
NESHORT for the 30 individuals, for M =
3, 6, 9, . . . , 21. Again for each M , the texts of
PIPELINE were generated three times, each time
using one of the different alternative sentence
plans of each relation. PIPELINE and PIPELI-
NESHORT were allowed to form aggregated sen-
tences containing up to Bmax = 39 distinct ele-
ments, which was the number of distinct elements
of the longest aggregated sentence in the previous
work with this ontology, where PIPELINE was al-
lowed to aggregate up to 3 original sentences. We
also set Bmax = 39 in ILPNLG.
There are 14 facts (F ) on average and a max-
imum of 21 facts for each one of the 30 individ-
uals, compared to the 5 facts on average and the
maximum of 6 facts of the experiments with the
Wine Ontology. Hence, the texts of the Consumer
8The confidence intervals do not overlap, and we also per-
formed paired two-tailed t-tests (? = 0.05) to check for sta-
tistical significance. In previous work, where judges were
asked to score texts using the same criteria, inter-annotator
agreement was strong (sample Pearson correlation r ? 0.91).
9Ontology available from www.ebusiness-unibw.
org/ontologies/consumerelectronics/v1.
10See rdf4ecommerce.esolda.com/.
56
Figure 2: Average solver times for ILPNLG for dif-
ferent maximum numbers of fact subsets (m).
Electronics Ontology are much longer, when they
report all the available facts. To generate texts for
the 30 individuals with ILPNLG, we would have
to set the maximum number of fact subsets to
m = 10, which was the maximum number of (ag-
gregated) sentences in the texts of PIPELINE and
PIPELINESHORT. The number of variables of our
ILP model, however, grows exponentially tom and
the number of available facts |F |. Figure 2 shows
the average time the ILP solver took for different
values ofm in the experiments with the Consumer
Electronics ontology; the results are also averaged
for ?1 = 0.4, 0.5, 0.6 (?2 = 1 ? ?1). For m = 4,
the solver took 1 minute and 47 seconds on av-
erage per text; recall that |F | is also much larger
now, compared to the experiments of the previous
section. Form = 5, the solver was so slow that we
aborted the experiment. Figure 3 shows the aver-
age solver time for different numbers of available
facts |F |, for m = 3; in this case, we modified
the set of available facts (F ) of every individual
to contain 3, 6, 9, 12, 15, 18, 21 facts; the results
are averaged for ?1 = 0.4, 0.5, 0.6. Although
the times of Fig. 3 also grow exponentially, they
remain under 4 seconds, showing that the main
problem for ILPNLG is m, the number of fact sub-
sets, which is also the maximum allowed number
of (aggregated) sentences of each text.
To be able to efficiently generate texts with
larger m values, we use a variant of ILPNLG,
called ILPNLGAPPROX, which considers each fact
subset separately. ILPNLGAPPROX starts with the
full set of available facts (F ) and uses our ILP
model (Section 3) with m = 1 to produce the first
(aggregated) sentence of the text. It then removes
the facts expressed by the first (aggregated) sen-
tence from F , and uses the ILP model, again with
Figure 3: Average solver times for ILPNLG for dif-
ferent numbers of available facts (|F |) andm = 3.
Figure 4: Avg. solver times for ILPNLGAPPROX
for different max. numbers of fact subsets (m).
m = 1, to produce the second (aggregated) sen-
tence etc. This process is repeated until we pro-
duce the maximum number of allowed aggregated
sentences, or until we run out of facts. ILPNLGAP-
PROX is an approximation of ILPNLG, in the sense
that it does not consider all the fact subsets jointly
and, hence, does not guarantee finding a globally
optimal solution for the entire text. Figures 4?5
show the average solver times of ILPNLGAPPROX
for different values of m and |F |; all the other set-
tings are as in Figures 2?3. The solver times of
ILPNLGAPPROX grow approximately linearly tom
and |F | and are under 0.3 seconds in all cases.
Figure 6 shows the average facts/words ratio of
ILPNLGAPPROX (m = 10), PIPELINE and PIPELI-
NESHORT, along with 95% confidence intervals
(of sample means), for the texts of the 30 individu-
als. Again, PIPELINESHORT achieves slightly bet-
ter results than PIPELINE, but the differences are
now smaller (cf. Fig. 1). ILPNLGAPPROX behaves
very similarly to ILPNLG in the Wine Ontology ex-
periments (cf. Fig. 1); for ?1 ? 0.35, it produces
empty texts, while for ?1 ? 0.4 it performs better
than the other systems. ILPNLGAPPROX obtains
57
Figure 5: Avg. solver times for ILPNLGAPPROX
for different |F | values and m = 3.
Figure 6: Facts/words for Consumer Electronics.
the highest facts/words ratio for ?1 = 0.45, where
it selects the facts and sentence plans that lead to
the most compressive aggregations. For greater
values of ?1, it selects additional facts whose sen-
tence plans do not aggregate that well, which is
why the ratio declines. The two pipeline systems
select facts and sentence plans that offer very few
aggregation opportunities; as the number of se-
lected facts increases, some more aggregation op-
portunities arise, which is why the facts/words ra-
tio of the two systems improves slightly, though
the improvement is now hardly noticeable.
We show below two example texts produced by
PIPELINE (M = 6) and ILPNLGAPPROX (?1 =
0.45). Both texts report 6 facts, but ILPNLGAP-
PROX has selected facts and sentence plans that
allow more compressive aggregations. Recall that
we treat all the facts as equally important.
PIPELINE: Sony DCR-TRV270 requires minimum illumina-
tion of 4.0 lux and its display is 2.5 in. It features a sports
scene mode, it includes a microphone and an IR remote con-
trol. Its weight is 780.0 grm.
ILPNLGAPPROX: Sony DCR-TRV270 has a microphone and
an IR remote control. It is 98.0 mm high, 85.0 mm wide,
151.0 mm deep and it weighs 780.0 grm.
We showed the 30 ? 2 = 60 texts of PIPELI-
NESHORT (M = 6) and ILPNLGAPPROX (?1 =
Criteria PIPELINESHORT ILPNLGAPPROX
Sentence fluency 4.50 ? 0.30 4.87 ? 0.12
Text structure 4.33 ? 0.36 4.73 ? 0.22
Clarity 4.53 ? 0.29 4.97 ? 0.06
Overall 4.10 ? 0.31 4.73 ? 0.16
Table 2: Human scores for Consumer Electronics.
0.45) to the same 6 students, as in Section 4.1.
Again, each text was given to exactly one student.
Each student was given approximately 5 randomly
selected texts of each system. The OWL statements
that the texts were generated from were not shown,
and the students did not know which system had
generated each text. Each student was shown all
of his/her texts in random order, regardless of the
system that generated them. The students were
asked to score each text by stating how strongly
they agreed or disagreed with statements S1?S3,
as in Section 4.1. They were also asked to provide
an overall score (1?5) per text.
Table 2 shows the average scores of the two
systems with 95% confidence intervals (of sam-
ple means). For each criterion, the best score is
shown in bold; the confidence interval of the best
score is also shown in bold, if it does not overlap
with the confidence interval of the other system.
Unlike the Wine Ontology experiments, the scores
of our ILP approach are now higher than those of
the pipeline in all of the criteria, and the differ-
ences are also larger, though the differences are
statistically significant only for clarity and over-
all quality.11 We attribute these differences to the
fact that the texts are now longer and the sentence
plans more varied, which often makes the texts of
the pipeline sound verbose and, hence, more diffi-
cult to follow, compared to the more compact texts
of ILPNLGAPPROX, which sound more concise.
Overall, the human scores of the experiments
with the two ontologies suggest that the higher
facts/words ratio of our ILP approach does not
come at the expense of lower perceived text qual-
ity. On the contrary, the texts of the ILP approach
may be perceived as clearer and overall better than
those of the pipeline, when the texts are longer.
5 Conclusions
We presented an ILP model of content selection,
lexicalization, and aggregation that jointly con-
siders the possible choices in the three stages, to
11When two confidence intervals do not overlap, the dif-
ference is statistically significant. When they overlap, the
difference may still be statistically significant; we performed
additional paired two-tailed t-tests (? = 0.05) in those cases.
58
avoid greedy local decisions and produce more
compact texts. The model has been embedded in
NaturalOWL, a NLG system for OWL ontologies,
which used a pipeline architecture in its original
form. Experiments with two ontologies confirmed
that our approach leads to expressing more facts
per word, with no deterioration in the perceived
text quality; the ILP approach may actually lead to
texts perceived as clearer and overall better, com-
pared to the pipeline, when there are many facts
to express. We also presented an approximation
of our ILP model, which allows longer texts to
be generated efficiently. We plan to extend our
model to include text planning, referring expres-
sion generation, and mechanisms to obtain impor-
tance scores.
Acknowledgments
This research has been co-financed by the Euro-
pean Union (European Social Fund ? ESF) and
Greek national funds through the Operational Pro-
gram ?Education and Lifelong Learning? of the
National Strategic Reference Framework (NSRF)
? Research Funding Program: Heracleitus II. In-
vesting in knowledge society through the Euro-
pean Social Fund.
References
E. Althaus, N. Karamanis, and A. Koller. 2004. Com-
puting locally coherent discourses. In 42nd Annual
Meeting of ACL, pages 399?406, Barcelona, Spain.
I. Androutsopoulos, G. Lampouras, and D. Gala-
nis. 2013. Generating natural language descrip-
tions from OWL ontologies: the NaturalOWL sys-
tem. Technical report, Natural Language Processing
Group, Department of Informatics, Athens Univer-
sity of Economics and Business.
G. Antoniou and F. van Harmelen. 2008. A Semantic
Web primer. MIT Press, 2nd edition.
F. Baader, D. Calvanese, D.L. McGuinness, D. Nardi,
and P.F. Patel-Schneider, editors. 2002. The De-
scription Logic Handbook. Cambridge Univ. Press.
R. Barzilay and M. Lapata. 2005. Collective content
selection for concept-to-text generation. In HLT-
EMNLP, pages 331?338, Vancouver, BC, Canada.
R. Barzilay and M. Lapata. 2006. Aggregation via
set partitioning for natural language generation. In
HLT-NAACL, pages 359?366, New York, NY.
A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engi-
neering, 14(4):431?455.
T. Berg-Kirkpatrick, D. Gillick, and D. Klein. 2011.
Jointly learning to extract and compress. In 49th
Meeting of ACL, pages 481?490, Portland, OR.
T. Berners-Lee, J. Hendler, and O. Lassila. 2001. The
Semantic Web. Scientific American, May:34?43.
K. Bontcheva. 2005. Generating tailored textual sum-
maries from ontologies. In 2nd European Semantic
Web Conf., pages 531?545, Heraklion, Greece.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear program-
ming approach. Journal of Artificial Intelligence Re-
search, 1(31):399?429.
H. Dalianis. 1999. Aggregation in natural language
generation. Comput. Intelligence, 15(4):384?414.
L. Danlos. 1984. Conceptual and linguistic decisions
in generation. In 10th COLING, pages 501?504,
Stanford, CA.
S. Demir, S. Carberry, and K.F. McCoy. 2010.
A discourse-aware graph-based content-selection
framework. In 6th Int. Nat. Lang. Generation Con-
ference, pages 17?25, Trim, Co. Meath, Ireland.
D. Galanis and I. Androutsopoulos. 2007. Generating
multilingual descriptions from linguistically anno-
tated OWL ontologies: the NaturalOWL system. In
11th European Workshop on Natural Lang. Genera-
tion, pages 143?146, Schloss Dagstuhl, Germany.
D. Galanis, G. Karakatsiotis, G. Lampouras, and I. An-
droutsopoulos. 2009. An open-source natural lan-
guage generator for OWL ontologies and its use in
Prote?ge? and Second Life. In 12th Conf. of the Euro-
pean Chapter of ACL (demos), Athens, Greece.
D. Galanis, G. Lampouras, and I. Androutsopoulos.
2012. Extractive multi-document summarization
with ILP and Support Vector Regression. In COL-
ING, pages 911?926, Mumbai, India.
B.C. Grau, I. Horrocks, B. Motik, B. Parsia, P. Patel-
Schneider, and U. Sattler. 2008. OWL 2: The next
step for OWL. Web Semantics, 6:309?322.
I. Konstas and M. Lapata. 2012a. Concept-to-text gen-
eration via discriminative reranking. In 50th Annual
Meeting of ACL, pages 369?378, Jeju Island, Korea.
I. Konstas and M. Lapata. 2012b. Unsupervised
concept-to-text generation with hypergraphs. In
HLT-NAACL, pages 752?761, Montre?al, Canada.
P. Kuznetsova, V. Ordonez, A. Berg, T. Berg, and
Y. Choi. 2012. Collective generation of natural im-
age descriptions. In 50th Annual Meeting of ACL,
pages 359?368, Jeju Island, Korea.
59
P. Liang, M. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
47th Meeting of ACL and 4th AFNLP, pages 91?99,
Suntec, Singapore.
S.F. Liang, R. Stevens, D. Scott, and A. Rector. 2011.
Automatic verbalisation of SNOMED classes using
OntoVerbal. In 13th Conf. AI in Medicine, pages
338?342, Bled, Slovenia.
T. Marciniak and M. Strube. 2005. Beyond the
pipeline: Discrete optimization in NLP. In 9th Con-
ference on Computational Natural Language Learn-
ing, pages 136?143, Ann Arbor, MI.
R. McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Eu-
ropean Conference on Information Retrieval, pages
557?564, Rome, Italy.
C. Mellish and J.Z. Pan. 2008. Natural language di-
rected inference from ontologies. Artificial Intelli-
gence, 172:1285?1315.
C. Mellish and X. Sun. 2006. The Semantic Web as a
linguistic resource: opportunities for nat. lang. gen-
eration. Knowledge Based Systems, 19:298?303.
E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge Univ. Press.
R. Schwitter, K. Kaljurand, A. Cregan, C. Dolbear, and
G. Hart. 2008. A comparison of three controlled
nat. languages for OWL 1.1. In 4th OWL Experi-
ences and Directions Workshop, Washington DC.
R. Schwitter. 2010. Controlled natural languages for
knowledge representation. In 23rd COLING, pages
1113?1121, Beijing, China.
N. Shadbolt, T. Berners-Lee, and W. Hall. 2006.
The Semantic Web revisited. IEEE Intell. Systems,
21:96?101.
M.A. Walker, O. Rambow, and M. Rogati. 2001. Spot:
A trainable sentence planner. In 2nd Annual Meet-
ing of NAACL, pages 17?24, Pittsburgh, PA.
S. Williams, A. Third, and R. Power. 2011. Levels
of organization in ontology verbalization. In 13th
European Workshop on Natural Lang. Generation,
pages 158?163, Nancy, France.
K. Woodsend and M. Lapata. 2012. Multiple as-
pect summarization using ILP. In EMNLP-CoNLL,
pages 233?243, Jesu Island, Korea.
60
