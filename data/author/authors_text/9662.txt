Proceedings of the EACL 2009 Demonstrations Session, pages 13?16,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
GOSSIP GALORE
A Self-Learning Agent for Exchanging Pop Trivia
Xiwen Cheng, Peter Adolphs, Feiyu Xu, Hans Uszkoreit, Hong Li
DFKI GmbH, Language Technology Lab
Stuhlsatzenhausweg 3, D-66123 Saarbru?cken, Germany
{xiwen.cheng,peter.adolphs,feiyu,uszkoreit,lihong}@domain.com
Abstract
This paper describes a self-learning soft-
ware agent who collects and learns knowl-
edge from the web and also exchanges her
knowledge via dialogues with the users.
The agent is built on top of information
extraction, web mining, question answer-
ing and dialogue system technologies, and
users can freely formulate their questions
within the gossip domain and obtain the
answers in multiple ways: textual re-
sponse, graph-based visualization of the
related concepts and speech output.
1 Introduction
The system presented here is developed within the
project Responsive Artificial Situated Cognitive
Agents Living and Learning on the Internet (RAS-
CALLI) supported by the European Commission
Cognitive Systems Programme (IST-27596-2004).
The goal of the project is to develop and imple-
ment cognitively enhanced artificial agents, using
technologies in natural language processing, ques-
tion answering, web-based information extraction,
semantic web and interaction driven profiling with
cognitive modelling (Krenn, 2008).
This paper describes a conversational agent
?Gossip Galore?, an active self-learning system
that can learn, update and interpret information
from the web, and can make conversations with
users and provide answers to their questions in the
domain of celebrity gossip. In more detail, by
applying a minimally supervised relation extrac-
tion system (Xu et al, 2007; Xu et al, 2008), the
agent automatically collects the knowledge from
relevant websites, and also communicates with the
users using a question-answering engine via a 3D
graphic interface.
This paper is organized as follows. Section 2
gives an overview of the system architecture and
Figure 1: Gossip Galore responding to ?Tell me
something about Carla Bruni!?
presents the design and functionalities of the com-
ponents. Section 3 explains the system setup and
discusses implementation details, and finally Sec-
tion 4 draws conclusions.
2 System Overview
Figure 1 shows a use case of the system. Given a
query ?Tell me something about Carla Bruni?, the
application would trigger a series of background
actions and respond with: ?Here, have a look at
the personal profile of Carla Bruni?. Meanwhile,
the personal profile of Carla Bruni, would be dis-
played on the screen. The design of the interface
reflects the domain of celebrity gossip: the agent
is depicted as a young lady in 3D graphics, who
communicates with users. As an additional fea-
ture, users can access the dialogue memory of the
system, which simulates the human memory in di-
alogues. An example of the dialogue memory is
sketched in Figure 2.
As shown in Figure 3, the system consists of a
number of components. In principle, first, a user?s
query is linguistically analyzed, and then inter-
13
Dialogue
State
Dialogue
Memory
MM GeneratorResponseHandler
NE RecognizerSpellChecker Parser
Anaphora
Resolver
Knowledge
Base
Web
Miner
Input
Interpreter
Input
Analyzer
Relation
Extractor
Information
Wrapper
NL Generator
Conversational
Agent
Figure 3: Agent architecture and interaction of components
Figure 2: Representation of Social Network in Di-
alogue Memory
preted with respect to the context of the dialogue.
A Response Handler will then consult the knowl-
edge base pre-constructed by extracting relevant
information from the Web, and pass the answer, in
an abstract representation, to a Multimodal Gener-
ator, which realizes and presents the answer to the
user in multiple ways. The main components are
described in the following sections.
2.1 Knowledge Base
The knowledge base is automatically built by the
Web Miner. It contains knowledge regarding prop-
erties of persons or groups and their social rela-
tionships. The persons and groups that we concern
are celebrities in the entertainment industry (e.g.,
singers, bands, or movie stars) and their relatives
(e.g., partners) and friends. Typical properties of a
person include name, gender, birthday, etc., and
profiles of celebrities contain additional proper-
ties such as sexual orientation, home pages, stage
names, genres of their work, albums, and prizes.
Social relationships between the persons/groups
such as parent-child, partner, sibling, influenc-
ing/influenced and group-member, are also stored.
2.2 Web Miner
The Web Miner fetches relevant concepts and their
relations by means of two technologies: a) infor-
mation wrapping for exaction of personal profiles
from structured and semi-structured web content,
and b) a minimally supervised machine learning
method provided by DARE (Xu et al, 2007; Xu
et al, 2008) to acquire relations from free texts.
DARE learns linguistic patterns indicating the tar-
get semantic relations by taking some relation in-
stances as initial seed. For example, assume that
the following seed for a parent-child relationship
is given to the DARE system:
(1) Seed: ?Angelina Jolie, Shiloh Nouvel Jolie-Pitt,
daughter?
One sentence that matches the entities men-
tioned in the seed above could be (2), and from
which the DARE system can derive a linguistic
pattern as shown in 3.
(2) Matched sentence: Angelina Jolie and Brad Pitt
welcome their new daughter Shiloh Nouvel Jolie-Pitt.
(3) Extracted pattern: ?subject: celebrity? welcome
?mod: ?new daughter?? ?object: person?
Given the learned pattern, new instances of the
?parent-child? relationship can be automatically
discovered, e.g.:
(4) New acquired instances: ?Adam Sandler, Sunny
Madeline? ?Cynthia Rodriguez, Ella Alexander?
Given the discovered relations among the
celebrities and other people, the system constructs
a social network, which is the basis for providing
answers to users? questions regarding celebrities?
relationships. The network also serves as a re-
source for the active dialogue memory of the agent
as shown in Figure 2.
14
2.3 Input Analyzer and Input Interpreter
The Input Analyzer is designed as both domain
and dialogue context independent. It relies on sev-
eral linguistic analysis tools: 1) a spell checker, 2)
a named entity recognizer SProUT (Drozdzynski
et al, 2004), and 3) a syntactic parsing component
for which we currently employ a fuzzy paraphrase
matcher to approximate the output of a deep syn-
tactic/semantic parser.
In contrast to the Input Analyzer, the Input In-
terpreter analyzes the input with respect to the
context of the dialogue. It contains two major
components: 1) anaphoric resolution, which refers
pronouns to previously mentioned entities with the
help of the dialogue memory, and 2) domain clas-
sification, which determines whether the entities
contained in a user query can be found in the gos-
sip knowledge base (cf. ?Carla Bruni? vs. ?Nico-
las Sarkozy?) and whether the answer focus be-
longs to the domain (cf. ?stage name? vs ?body
guard?). For example, a simple factoid query such
as ?Who is Madonna?, an embedded questions
like ?I wonder who Madonna is?, and expressions
of requests and wishes such as ?I?m interested in
Madonna?, would share the same answer focus,
i.e., the ?personal profile? of ?Madonna?. In ad-
dition to the simple answer types such as ?person
name?, ?location? and ?date/time?, our system can
also deal with complex answer focus types such as
?personal profile?, ?social network? and ?relation
path?, as well as domain-relevant concepts such as
?party affiliation? or ?sexual orientation?.
Finally, the analysis of each query is associated
with a meaning representation, an answer focus
and an expected answer type.
2.4 Response Handler
This component executes the planned action based
on the properties of the answer focus and the en-
tities in a query. In cases where the answer focus
or the entities cannot be found in the knowledge
base, the system would still attempt to provide a
constructive answer. For instance, if a question
contains a domain-specific answer focus but en-
tities unknown to the knowledge base, the agent
will automatically look for alternative knowledge
resources, e.g., Wikipedia. For example, given
the question ?Tell me something about Nicolas
Sarkozy!?, the agent would attempt a Web search
and return the corresponding page on Wikipedia
about ?Nicolas Sarkozy?, even if the knowledge
base does not contain his information since he is a
politician rather than an entertainer.
In addition, specific strategies have been devel-
oped to deal with negative answers. For instance,
the agent would answer the question: When did
Madonna die?, with ?As far as I know, Madonna
is still alive.?, as it cannot find any information re-
garding Madonna?s death.
2.5 Multimodal Generator
The agent (i.e., the young lady in Figure 1) is
equipped with multimodal capabilities to inter-
act with users. It can show the results in tex-
tual and speech forms, using body gestures, fa-
cial expressions, and finally via multimedia out-
put to an embedded screen. We currently employ
template-based generators for producing both the
natural language utterances and the instructions to
the agent that controls the multimodal communi-
cation with the user.
2.6 Dialogue State
The responsibility of this component is to keep
track of the current state of the dialogue between a
user and the agent. It models the system?s expec-
tation of the user?s next action and the system?s re-
actions. For example, if a user misspelled a name
as in the question ?Who is Roby Williams??, the
system would answer with a clarification question:
?Did you mean Robbie Williams?? The user is
then expected to react to the question with either
?yes? or ?no?, which would not be interpretable in
other dialogue contexts where the user is expected
to ask a question. The fact that the system asks a
clarification question and expects a yes/no answer
as well as the repaired question are stored in the
Dialogue State component.
2.7 Dialogue Memory
This component aims to simulate the cognitive ca-
pacity of the memory of a human being: con-
struction of a short-time memory and activation
of long-time memory (our Knowledge Base). It
records the sequence of all entities mentioned dur-
ing the conversation and their respective target
foci. Simultaneously, it retrieves all the related in-
formation from the Knowledge Base. In figure 2,
the dialogue memory for the three questions ?Tell
me something about Carla Bruni.?, ?Can you tell
me some news about her??, ?How many kids does
Brad Pitt have?? is shown. Green and yellow bub-
bles are entities mentioned in the dialogue context,
15
where the yellow one is the last mentioned entity.
White bubbles indicate the newest records which
are acquired in the last process of online QA.
3 Implementation
The system uses a client-server architecture. The
server is responsible for accepting new connec-
tions, managing accounts, processing conversa-
tions and passing responses to the clients. All
the server-side functions are implemented in Java
1.6. We use Jetty as a web server to deliver mul-
timedia representations of an answer and to pro-
vide selected functionalities of the system as web
services to our partners. The knowledge base is
stored in a MySQL database whose size is 11MB,
and contains information of 38,758 persons in-
cluding 16,532 artists and 1,407 music groups. As
for the social connection data, there are 14,909
parent-child, 16,886 partner, 4,214 sibling, 308
influence/influenced and 9,657 group-member re-
lational pairs. The social network is visualized
in JGraph, and speech output is generated by the
open-source speech synthesis system OpenMary
(Schro?der and Hunecke, 2007).
There are two interfaces realizing the client-
side of the system: a 3D software application and
a web interface. The software application uses
a 3D computer game engine, and communicates
with the server by messages in an XML format
based on BML and SSML. In addition, we provide
a web interface1, implemented using HTML and
Javascript on the browser side, and Java Servlets
on the server side, offering the same core func-
tionality as the 3D client.
Both the server and the web client are platform
independent. The 3D client runs on Windows with
a dedicated 3D graphics card. The recommended
memory for the server is 1GB.
4 Conclusions
This paper describes a fully implemented software
application, which discovers and learns informa-
tion and knowledge from the Web, and communi-
cates with users and exchanges gossip trivia with
them. The system uses many novel technologies
in order to achieve the goal of vividly chatting and
interacting with the users in a fun way. The tech-
nologies include information extraction, question
answering, dialogue modeling, response planning
and multimodal presentation generation. Please
1http://rascalli.dfki.de/live/dialogue.page
refer to (Xu et al, 2009) for additional details
about the ?Gossip Galore? system.
The planned future extensions include the in-
tegration of deeper language processing methods
to discover more precise linguistic patterns. A
prime candidate for this extension is our own deep
syntactic/semantic parser. Another plan concerns
the required temporal aspects of relations together
with credibility checking. Finally, we plan to ex-
ploit the dialogue memory for moving more of the
dialogue initiative to the agent. In cases of miss-
ing or negative answers or in cases of pauses on
the user side, the agent can use the active parts
of the dialogue memory to propose additional rel-
evant information or to guide the user to fruitful
requests within the range of user?s interests.
References
Witold Drozdzynski, Hans-Ulrich Krieger, Jakub Piskorski,
Ulrich Scha?fer, and Feiyu Xu. 2004. Shallow processing
with unification and typed feature structures ? foundations
and applications. Ku?nstliche Intelligenz, 1:17?23.
Brigitte Krenn. 2008. Responsive artificial situated cognitive
agents living and learning on the internet, April. Poster
presented at CogSys 2008.
Marc Schro?der and Anna Hunecke. 2007. Mary tts partici-
pation in the Blizzard Challenge 2007. In Proceedings of
the Blizzard Challenge 2007, Bonn, Germany.
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2007. A seed-
driven bottom-up machine learning framework for extract-
ing relations of various complexity. Proceedings of ACL-
2007, pages 584?591.
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2008. Task driven
coreference resolution for relation extraction. In Proceed-
ings of ECAI 2008, Patras, Greece.
Feiyu Xu, Peter Adolphs, Hans Uszkoreit, Xiwen Cheng, and
Hong Li. 2009. Gossip galore: A conversational web
agent for collecting and sharing pop trivia. In Joaquim
Filipe, Ana Fred, and Bernadette Sharp (eds). Proceed-
ings of ICAART 2009, Porto, Portugal.
16
Proceedings of the ACL 2010 System Demonstrations, pages 36?41,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Talking NPCs in a Virtual Game World
Tina Klu?wer, Peter Adolphs, Feiyu Xu, Hans Uszkoreit, Xiwen Cheng
Deutsches Forschungszentrum fu?r Ku?nstliche Intelligenz (DFKI)
Projektbu?ro Berlin
Alt-Moabit 91c
10559 Berlin
Germany
{tina.kluewer,peter.adolphs,feiyu,uszkoreit,xiwen.cheng}@dfki.de
Abstract
This paper describes the KomParse sys-
tem, a natural-language dialog system
in the three-dimensional virtual world
Twinity. In order to fulfill the various
communication demands between non-
player characters (NPCs) and users in
such an online virtual world, the system
realizes a flexible and hybrid approach
combining knowledge-intensive domain-
specific question answering, task-specific
and domain-specific dialog with robust
chatbot-like chitchat.
1 Introduction
In recent years multi-user online games in virtual
worlds such as Second Life or World of Warcraft
have attracted large user communities. Such vir-
tual online game worlds provide new social and
economic platforms for people to work and inter-
act in. Furthermore, virtual worlds open new per-
spectives for research in the social, behavioral, and
economic sciences, as well as in human-centered
computer science (Bainbridge, 2007). Depending
on the game type, non-player characters (NPCs)
are often essential for supporting the game plot,
for making the artificial world more vivid and ulti-
mately for making it more immersive. In addition,
NPCs are useful to populate new worlds by carry-
ing out jobs the user-led characters come in touch
with. The range of functions to be filled by NPCs
is currently still strongly restricted by their limited
capabilities in autonomous acting and communi-
cation. This shortcoming creates a strong need for
progress in areas such as AI and NLP, especially
their planning and dialog systems.
The KomParse system, described in this paper,
provides NPCs for a virtual online world named
Twinity, a product of the Berlin startup company
Metaversum1. The KomParse NPCs offer vari-
ous services through conversation with game users
using question-answering and dialog functional-
ity. The utilization of Semantic Web technology
with RDF-encoded generic and domain-specific
ontologies furthermore enables semantic search
and inference.
This paper is organized as follows: Section 2
presents the NPC modelling and explains the ap-
plication scenarios. Section 3 details the knowl-
edge representation and semantic inference in our
system. Section 4 explains the system architecture
and its key components. Section 5 describes the
KomParse dialog system. Section 7 gives a con-
clusion and closes off with our future work.
2 Application Scenario and NPC
Modelling
The online game Twinity extends the Second Life
idea by mirroring an urban part of the real world.
At the time of this writing, the simulated section of
reality already contains 3D models of the cities of
Berlin, Singapore and London and it keeps grow-
ing. Users can log into the virtual world, where
they can meet other users and communicate with
them using the integrated chat function or talk
to each other via Voice-over-IP. They can style
their virtual appearance, can rent or buy their own
flats and decorate them as to their preferences and
tastes.
Out of many types of NPCs useful for this appli-
cation such as pedestrians, city guides and person-
nel in stores, restaurants and bars, we start with
two specific characters: a female furniture sales
agent and a male bartender. The furniture seller
is designed for helping users furnish their virtual
apartments. Users can buy pieces of furniture and
room decoration from the NPC by describing their
demands and wishes in a text chat. During the di-
1http://www.metaversum.com/
36
Figure 1: The furniture sales NPC selling a sofa
alog with the NPC, the preferred objects are then
selected and directly put into a location in the
apartment, which can be further refined with the
user interfaces that Twinity provides.
In the second scenario, the bartender sells vir-
tual drinks. He can talk about cocktails with users,
but moreover, he can also entertain his guests by
providing trivia-type information about popular
celebrities and various relations among them.
We chose these two characters not only because
of their value for the Twinity application but also
for our research goals. They differ in many in-
teresting aspects. First of all, the furniture sales
agent is controlled by a complex task model in-
cluding ontology-driven and data-driven compo-
nents to guide the conversation. This agent also
possesses a much more fine-grained action model,
which allows several different actions to cover
the potential conversation situations for the sell-
ing task. The bartender agent on the other hand is
designed not to fulfill one strict task because his
clients do not follow a specific goal except order-
ing drinks. Our bartender has the role of a conver-
sation companion and is able to entertain clients
with his broad knowledge. Thus, he is allowed to
access to several knowledge bases and is able to
handle questions (and later conversations) about
a much larger domain called the ?gossip domain?
which enables conversation about pop stars, movie
actors and other celebrities as well as the relations
between these people. In order to achieve a high
robustness, we integrate a chatbot into the bar-
tender agent to catch chitchat utterances we cannot
handle.
Figure 2: Our bartender NPC in his bar in Twinity
3 Knowledge Representation and
Semantic Inference
Semantic Web technology is employed for mod-
elling the knowledge of the NPCs. The Resource
Description Format (RDF) serves as the base for
the actual encoding. An RDF statement is a binary
relation instance between two individuals, that is a
triple of a predicate and two arguments, called the
subject and the object, and written as subj pred obj
(e.g. f:Sofa Alatea f:hasMainColour
f:Burgundy).
All objects and properties the NPC can talk
about are modelled in this way. Therefore the
knowledge base has to reflect the physical prop-
erties of the virtual objects in Twinity as faithfully
as possible. For instance, specific pieces of furni-
ture are described by their main color, material or
style, whereas cocktails are characterized by their
ingredients, color, consistence and taste. Further-
more, references to the 3D models of the objects
are stored in order to create, find and remove such
objects in the virtual world.
The concepts and individuals of the particular
domain are structured and organized in domain-
specific ontologies. These ontologies are mod-
elled in the Web Ontology Language (OWL).
OWL allows us to define concept hierarchies, re-
lations between concepts, domains and ranges of
these relations, as well as specific relation in-
stances between instances of a concept. Our on-
tologies are defined by the freely available ontol-
ogy editor Prote?ge? 4.02. The advantage of using an
ontology for structuring the domain knowledge is
2http://protege.stanford.edu/, as accessed
27 Oct 2009
37
Twinity
Server
KomParse
Server
Twinity
Client
Conversational
AgentConversational
AgentConversational
Agent
Twinity
ClientTwinity
Client
Figure 3: Overall System Architecture ? Server/Client Architecture for NPC Control
the modular non-redundant encoding. When com-
bined with a reasoner, only a few statements about
an individual have to be asserted explicitely, while
the rest can be inferred from the ontology. We em-
ploy several ontologies, among which the follow-
ing are relevant for modelling the specific domains
of our NPCs:
? An extensive furniture ontology, created by
our project partner ZAS Berlin, defining
kinds of furniture, room parts, colors and
styles as well as the specific instances of fur-
niture in Twinity. This knowledge base con-
tains 95,258 triples, 123 furniture classes, 20
color classes, 243 color instances and various
classes defining styles and similar concepts.
? A cocktail ontology, defining 13 cocktail
classes with ingredients and tastes in 21,880
triples.
? A biographical ontology, the ?gossip on-
tology?, defining biographical and career-
specific concepts for people. This ontology is
accompanied by a huge database of celebri-
ties, which has been automatically acquired
from the Web and covers nearly 600,000 per-
sons and relations between these people like
family relationships, marriages and profes-
sional relations. (Adolphs et al, 2010)
The furniture ontology is the only knowledge
base for the furniture sales agent, whereas the bar-
tender NPC has access to both the cocktail as well
as the gossip knowledge base.
We use SwiftOwlim3 for storing and querying
the data. SwiftOwlim is a ?triple store?, a kind
of database which is specifically built for storing
and querying RDF data. It provides a forward-
chaining inference engine which evaluates the
domain definitions when loading the knowledge
repository, and makes implicit knowledge explicit
by asserting triples that must also hold true accord-
ing to the ontology. Once the reasoner is finished,
the triple store can be queried directly using the
RDF query language SPARQL.
3http://www.ontotext.com/owlim/
4 Overall System Architecture
Figure 3 shows the overall system architecture.
Twinity is a server/client application, in which the
server hosts the virtual world and coordinates the
user interactions. In order to use Twinity, users
have to download the Twinity client. The client
allows the user to control the physical represen-
tation of the user?s character in the virtual world,
also called the ?avatar?. Thus the client is respon-
sible for displaying the graphics, calculating the
effects of physical interactions, handling the user?s
input and synchronizing the 3D data and user ac-
tions with the Twinity server.
Each NPC comprises two major parts: whereas
its avatar is the physical appearance of the NPC in
the virtual world, the ?conversational agent? pro-
vides the actual control logic which controls the
avatar autonomously. It is in particular able to hold
a conversation with Twinity users in that it reacts
to a user?s presence, interprets user?s utterances in
dialog context and generates adequate responses.
The KomParse server is a multi-client, multi-
threaded server written in Java that hosts the con-
versational agents for the NPCs (section 5). The
NPC?s avatar, on the other hand, is realized by a
modified Twinity client. We utilize the Python in-
terface provided by the Twinity client to call our
own plugin which opens a bidirectional socket
connection to the KomParse server. The plugin is
started together with the Twinity client and serves
as a mediator between the Twinity server and the
KomParse server from then on (fig. 3). It sends all
in-game events relevant to our system to the server
and translates the commands sent by the server
into Twinity-specific actions.
The integration architecture allows us to be
maximally independent of the specific game plat-
form. Rather than using the particular program-
ming language and development environment of
the platform for realizing the conversational agent
or reimplementing a whole client/server proto-
col for connecting the avatar to the corresponding
agent, we use an interface tailored to the specific
needs of our system. Thus the KomParse system
38
can be naturally extended to other platforms since
only the avatar interfaces have to be adapted.
The integration architecture also has the advan-
tage that the necessary services can be easily dis-
tributed in a networked multi-platform environ-
ment. The Twinity clients require aMicrosoftWin-
dows machine with a 3D graphics card supporting
DirectX 9.0c or higher, 1 GB RAM and a CPU
core per instance. The KomParse server requires
roughly 1 GB RAM. The triple store is run as
a separate server process and is accessed by an
XML-RPC interface. Roughly 1.2 GB RAM are
required for loading our current knowledge base.
5 Conversational Agent: KomParse
Dialog System
Figure 4: Dialog System: Conversational Agent
The KomParse dialog system, the main func-
tionality of the conversational agent, consists of
the following three major components: input ana-
lyzer, dialog manager and output generator (fig.4).
The input analyzer is responsible for the lin-
guistic analysis of the user?s textual input includ-
ing preprocessing such as string cleaning, part-of-
speech tagging, named entity recognition, parsing
and semantic interpretation. It yields a semantic
representation which is the input for the dialog
manager.
The dialog manager takes the result of the input
analyzer and delivers an interpretation based on
the dialog context and the available knowledge. It
also controls the task conversation chain and han-
dles user requests. The dialog manager determines
the next system action based on the interpreted pa-
rameters.
The output generator realizes the action defined
by the dialog manager with its multimodal gener-
ation competence. The generated results can be
verbal, gestural or a combination of both.
As mentioned above, our dialog system has to
deal with two different scenarios. While the fo-
cal point of the bartender agent lies in the question
answering functionality, the furniture sales agent
is driven by a complex dialog task model based on
a dialog graph. Thus, the bartender agent relies
mainly on question answering technology, in that
it needs to understand questions and extract the
right answer from our knowledge bases, whereas
the sales agent has to accommodate various dialog
situations with respect to a sales scenario. It there-
fore has to understand the dialog acts intended
by the user and trigger the corresponding reac-
tions, such as presenting an object, memorizing
user preferences, negotiating further sales goals,
etc.
The task model for sales conversations is in-
spired by a corpus resulting from the annotation of
a Wizard-of-Oz experiment in the furniture sales
agent scenario carried out by our project partner at
ZAS (Bertomeu and Benz, 2009). In these exper-
iments, 18 users spent one hour each on furnish-
ing a virtual living room in a Twinity apartment by
talking to a human wizard controlling the virtual
sales agent. The final corpus consists of 18 di-
alogs containing 3,171 turns with 4,313 utterances
and 23,015 alpha-numerical strings (words). The
following example shows a typical part of such a
conversation:
USR.1: And do we have a little side table for the TV?
NPC.1: I could offer you another small table or a sideboard.
USR.2: Then I?ll take a sideboard thats similar to my shelf.
NPC.2: Let me check if we have something like that.
Table 1: Example Conversation from the Wizard-
of-Oz Experiment
The flow of the task-based conversation is con-
trolled by a data-driven finite-state model, which
is the backbone of the dialog manager. During
a sales conversation, objects and features of ob-
jects mentioned by the NPC and the user are ex-
tracted from the knowledge bases and added into
the underspecified graph nodes and egdes at run-
time. This strategy keeps the finite-state graph as
small as possible. Discussed objects and their fea-
tures are stored in a frame-based sub-component
named ?form?. The form contains entries which
correspond to ontological concepts in the furni-
39
ture ontology. During conversation, these entries
will be specified with the values of the properties
of the discussed objects. This frame-based ap-
proach increases the flexibility of the dialog man-
ager (McTear, 2002) and is particularly useful for
a task-driven dialog system. As long as the negoti-
ated object is not yet fully specified, the form rep-
resents the underspecified object description ac-
cording to the ontology concept. Every time the
user states a new preference or request, the form
is enriched with additional features until the set of
objects is small enough to be presented to the user
for final selection. Thus the actual flow of dia-
log according to the task model does not have to
be expressed by the graph but can be derived on
demand from the knowledge and handled by the
form which in turn activates the appropriate dia-
log subgraphs. This combination of graph-based
dialog models and form-based task modelling ef-
fectively accounts for the interaction of sequential
dialog strategies and the non-sequential nature of
complex dialog goals.
Given a resolved semantic representation, the
dialog manager triggers either a semantic search
in the knowledge bases to deliver factual answers
as needed in a gossip conversation or a further di-
alog response for example providing choices for
the user in a sales domain. The semantic search is
needed in both domains. In case that the semantic
representation can neither be resolved in the task
domain nor in the gossip domain, it gets passed to
the embedded A.L.I.C.E. chatbot that uses its own
understanding and generation components (Wal-
lace and Bush, 2001).
5.1 Semantic Representation
The input understanding of the system is imple-
mented as one single understanding pipeline.The
understanding pipeline delivers a semantic repre-
sentation which is the basis for the decision of the
dialog manager which action to perform next.
This semantic representation can be extracted
from the user input by our understanding com-
ponent via a robust hybrid approach: either via a
number of surface patterns containing regular ex-
pressions or via patterns reflecting the syntactic
analysis of a dependency parser (de Marneffe and
Manning, 2008).
The representation?s structure is inspired by our
knowledge representation design described in sec-
tion 3 as well as by predicate logic. The core of the
representation is a predicate-argument structure
limited to two arguments including message type
and the whole syntactic information found by the
analysis pipeline. The field ?Message Type? can
have one of the following values: wh-question,
yes/no-question, declarative. Predicates can often
be instantiated with the lemmatized matrix verb of
the successfully analysed piece of the input. If the
input contains a wh-question, the questioned fact
is marked as an unfilled argument slot. The gen-
eral structure can be simplified described as:
<PREDICATE, ARG1, ARG2, [message-type]>
The following examples show the structure used
for different input:
? ?Who is the boyfriend of Madonna??
<hasBoyfriend, Madonna, ?, [wh]>
? ?I want to buy a sofa.?
<buy, I, "a sofa", [declarative]>
5.2 Information Extraction
Both scenarios make use of state-of-the-art infor-
mation extraction approaches to extract the impor-
tant pieces from the user input. While the bar-
tender depends on relation extraction to detect the
fact or relation questioned by the user (Xu et al,
2007), the sales agent uses information extraction
methods to recognize user wishes and demands.
As a result, the questioned fact or the demanded
object feature equals the ontology structure con-
taining the knowledge needed to handle the user
input. The input ?Do you have any red couches??
for example needs to get processed by the system
in such a way that the information regarding the
sofa with red color is extracted.
This is done by the system in a data-driven way.
The input analysis first tries to find a demanded
object in the input via asking the ontology: Every
object which can be discussed in the scenario is
encoded in the sales agents knowledge base. This
can be seen as a Named Entity Recognition step.
In case of success, the system tries to detect one
of the possible relations of the object found in the
input. This is achieved by querying the ontology
about what kind of relations the identified object
can satisfy. Possible relations are encoded in the
class description of the given object. As a result
the system can detect a relation ?hasColour? for
the found object ?sofa? and the color value ?red?.
The found information gets inserted into the form
which gets more and more similar or if possible
equal to a search query via RDF.
40
Figure 5: Comparison of Input, Extracted Information and Knowledge Base
6 Conclusion and Future Work
The KomParse system demonstrates an attractive
application area for dialog systems that bears great
future potential. Natural language dialog with
NPCs is an important factor in making virtual
worlds more interesting, interactive and immer-
sive. Virtual worlds with conversing characters
will also find many additional applications in edu-
cation, marketing, and entertainment.
KomParse is an ambitious and nevertheless
pragmatic attempt to bring NLP into the world of
virtual games. We develop a new strategy to inte-
grate task models and domain ontologies into dia-
log models. This strategy is useful for task-driven
NPCs such as furniture sellers. With the chatty
bartender, a combination of task-specific dialog
and domain-specific question answering enables a
smart wide-domain off-task conversation. Since
the online game employs bubble-chat as a mode
of communication in addition to Voice-over-IP, we
are able to test our dialog system in a real-time
application without being hindered by imperfect
speech recognition.
The system presented here is still work in
progress. The next goals will include various eval-
uation steps. On the one hand we will focus on
single components like hybrid parsing of input ut-
terances and dialog interpretation in terms of pre-
cision and recall. On the other hand an evaluation
of the two different scenarios regarding the us-
ability are planned in experiments with end users.
Moreover we will integrate some opinion mining
and sentiment analysis functionality which can be
helpful to better detect and understand the user?s
preferences in the furniture sales agents scenario.
Acknowledgements
The project KomParse is funded by the ProFIT
programme of the Federal State of Berlin, co-
funded by the EFRE programme of the Euro-
pean Union. The research presented here is ad-
ditionally supported through a grant to the project
TAKE, funded by the German Ministry for Edu-
cation and Research (BMBF, FKZ: 01IW08003).
Many thanks go to our project partners at the Cen-
tre for General Linguistics (ZAS) in Berlin as well
as to the supporting company Metaversum.
References
Peter Adolphs, Xiwen Cheng, Tina Klu?wer, Hans
Uszkoreit, and Feiyu Xu. 2010. Question answering
biographic information and social network powered
by the semantic web. In Proceedings of LREC 2010,
Valletta, Malta.
William Sims Bainbridge. 2007. The scientific re-
search potential of virtual worlds. Science, 317.
Nuria Bertomeu and Anton Benz. 2009. Annotation of
joint projects and information states in human-npc
dialogues. In Proceedings of the First International
Conference on Corpus Linguistics (CILC-09), Mur-
cia, Spain.
Marie C. de Marneffe and Christopher D. Manning.
2008. The Stanford typed dependencies repre-
sentation. In Coling 2008: Proceedings of the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation, Manchester, UK.
Michael F. McTear. 2002. Spoken dialogue tech-
nology: enabling the conversational user interface.
ACM Comput. Surv., 34(1).
Richard Wallace and Noel Bush. 2001. Artificial
intelligence markup language (aiml) version 1.0.1
(2001). Unpublished A.L.I.C.E. AI Foundation
Working Draft (rev 006).
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2007. A
seed-driven bottom-up machine learning framework
for extracting relations of various complexity. In
Proceedings of the 45th Annual Meeting of the As-
sociation of Computational Linguistics, pages 584?
591, Prague, Czech Republic, June. Association for
Computational Linguistics.
41
