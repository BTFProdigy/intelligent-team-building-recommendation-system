Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 43?49,
Dublin, Ireland, August 23-29 2014.
A hybrid approach for automatic clause boundary identification in Hindi
Rahul Sharma, Soma Paul
Language Technology Research Centre, IIIT-Hyderabad, India
rahul.sharma@research.iiit.ac.in, soma@iiit.ac.in
Abstract
A complex sentence, divided into clauses, can be analyzed more easily than the complex sen-
tence itself. We present here, the task of clauses identification in Hindi text. To the best of our
knowledge, not much work has been done on clause boundary identification for Hindi, which
makes this task more important. We have built a Hybrid system which gives 90.804% F1-scores
and 94.697% F1-scores for identification of clauses? start and end respectively.
1 Introduction
Clause is the minimal grammatical unit which can express a proposition. It is a sequential group of
words, containing a verb or a verb group(verb and its auxiliary), and its arguments which can be explicit
or implicit in nature (Ram and Devi, 2008) . This makes clause an important unit in language grammars
and emphasis the need to identify and classify them as part of linguistic studies.
Analysis and processing of complex sentences is a far more challenging task as compared to a simple
sentence. NLP applications often perform poorly as the complexity of the sentence increases. ?It is im-
possible, to process a complex sentence if its clauses are not properly identified and classified according
to their syntactic function in the sentence? (Leffa, 1998). Further, identifying clauses, and processing
them separately are known to do better in many NLP tasks. The performance of many NLP systems like
Machine Translation, Parallel corpora alignment, Information Extraction, Syntactic parsing, automatic
summarization and speech applications etc improves by introducing clause boundaries in a sentence (e.g.,
Ejerhed, 1988; Abney, 1990; Leffa, 1998; Papageorgiou, 1997; Gadde et al., 2010).
We present a hybrid method which comprises of Conditional random fields(CRFs) (Lafferty et al., 2001)
based statistical learning followed by some rules to automatically determine ?clause? boundaries (be-
ginnings and ends) in complex or compound sentences. CRFs is a framework for building undirected
probabilistic graphical models to segment and label sequence data (Lafferty et al., 2001). In past, this
framework has proved to be successful for sequence labeling task (Sha and Pereira, 2003; McCallum and
Li, 2003). Van Nguyen et al. (2007) used CRFs for clause splitting task with some linguistic information
giving 84.09% F1-score.
Our system has minimum dependency on linguistic resources,only part of speech (POS) and chunk
information of lexical items is used with a fair performance of the system. As far as we know, not much
work has been done on clause boundary identification for Hindi and this makes this task more significant.
This paper is structured as follows: In Section 2, we discuss the related works that has been done earlier
on clause identification. Section 3 describes the creation of dataset for various system use. In Section
4, we talk about methodology of our system. Section 5 outlines the system performance. In section 6,
some issues related clause identification are discussed. In Section 7, we conclude and talk about future
works in this area.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
43
2 Related works
Studies in identifying clauses date back to (Ejerhed, 1988) work, where they showed how automatic
clause boundary identification in discourse can benefit a parser?s performance. However her experiments
could detect only basic clauses. Later (Abney, 1990) used clause filter as part of his CASS parser.
(Papageorgiou, 1997) used hand crafted rules to identify clause boundaries in a text. (Leffa, 1998) is
another rule based method which was implemented in an English-Portuguese MT system.
Some more recent works in this area are: (Puscasu, 2004), in which she proposed a multilingual
method of combining language independent ML techniques with language specific rules to detect
clause boundaries in unrestricted texts. The rules identify the finite verbs and clause boundaries not
included in learning process. (Ram and Devi, 2008) proposed a hybrid based approach for detecting
clause boundaries in a sentence. They have used a CRF based system which uses different linguistic
cues. After identifying the clause boundaries they run an error analyzer module to find false boundary
markings, which are then corrected by the rule based system, built using linguistic clues. (Ghosh et
al., 2010) is another rule based system for clause boundary identification for Bengali, where they use
machine learning approach for clause classification and dependency relations between verb and its
argument to find clause boundaries. Dhivya et al. (2012) use dependency trees from maltparser and
the dependency tag-set with 11 tags to identify clause boundaries. Similar to (Dhivya et al., 2012),
Sharma et al. (2013) showed how implicit clause information present in dependency trees can be used to
extract clauses in sentences. Their system have reported 94.44% accuracy for Hindi.Gadde et al. (2010)
reported improvement in parser performance by introducing automatic clause information in a sentence
for Hindi in ?Improving data driven dependency parsing using clausal information?. However their ap-
proach for identifying clause information has not been discussed. Thus a comparison is not possible here.
3 Dataset
In Hindi, We don?t have any data available annotated with clause boundary, So to generate clause anno-
tated corpora we have used (Sharma et al., 2013) technique where they have showed how implicit clause
information present in dependency trees can be used to extract clauses in sentences. By this technique
we have automatically generated 16000 sentences of Hindi treebank (Palmer et al., 2009) marked with
clause boudaries. Out of which, 14500 sentences were taken as training set, 500 for development set
and remaining 1000 sentences for testing set. As these sentences were generated automatically there are
chances of noises in form of wrongly marked clause boundaries, so for proper evaluation of the system,
we have manually corrected the wrongly marked clauses in development and testing sets.
4 Methodology
We propose a hybrid system which identifies the clause(s) in the input sentence and marks the ?clause
start position? (CSP) and ?clause end position? (CEP) with brackets.
Hindi usually follows the SOV word order, so ends of the clauses can be found by just using verb infor-
mation, in most of the cases. The language also has explicit relative pronouns, subordinating conjuncts,
coordinate conjunctions etc. which serve as cues that help to identify clause boundaries of the clauses.
Apart from the lexical cues we have also used POS tag and chunk information to built our system.
Our system comprise of two main modules; first modules is stochastic model which have been trained
on 14500 sentences, and second module which is built using hand crafted rules.
4.1 Stochastic Models
We have used two techniques to built two different models; 1) step-by-step model and 2) merged model,
using CRF machine learning approach. Both the models take word, word?s POS tag and its suffix as
word?s features for training. Table (1) shows the common features used for training models. These
feature are syntactic in nature, and relative pronoun, verb, conjunctions etc. plays important role in
identifying boundaries. suffixes help to learn morphological feature of the word.
44
Present word?s Lexicon, POS tag, last character, last two character, and last three character
Previous four words? Lexicon and POS tags
Next four words? Lexicon and POS tags
Next three words? last character, last two character, last three character
Table 1: Features
4.1.1 step-by-step model
This model comprises of two models; end model and start model. First one identifies the end of a clause
and then later one takes the output of former model as input and identifies the start of the clause. In this
technique we can notice that both models have to only mark whether a word is a boundary of a clause or
not. For example ?end model? has to check whether a given word is a end(boundary) of a clause or not.
Below example (1) explains this further.
(1) raam
Ram
jisne
who
khaanaa
food
khaayaa
eat+past
ghar
home
gayaaa
go+past
?Raam who ate food, went home?
In example (1), end model first marks ?gayaa? and ?khaayaa? as the end of clause. Then start model takes
this additional information also as the feature, and marks ?raam? and ?jisne? as the start of clause.
4.1.2 Merged Model
This model marks the clauses? start and end in one go. Unlike the step-by-step model, it check whether
a word is clause?s start, clause?s end or none. For above example (1), it will mark ?gayaa? and ?khaayaa?
as the end of clause, and ?raam? and ?jisne? as the start of clause respectively in one go.
-- Keeping post-processing module(discussed below) same, we have evaluated our system using both
stochastic models separately, and observed, system with step-by-step model gives high F1-score value
than the system with merged model.
4.2 Post-processing Module
This module processes the output from stochastic model, and mark the boundaries of clauses in sen-
tences. As we know, in a sentence CSPs should always be equal to CEPs. So on the basis of difference
between CSPs and CEPs, we have formalized our rules. Below is the description of rules used in this
module.
1. Rules, when CSPs are greater than CEPs are:
(a) Check for ?ki? complement clause: The verb in a sentence which contain ?ki? compliment
clause is not the end of its clause whereas its end is same as of end of ?ki? complement clause.
Below example (2) will make this rule more clearer.
(2) raam ne
Ram+arg
kahaa
say+past
ki
that
vaha
he
ghar
home
gayaa
go+past
?Raam said that he went home?
In this example (2), Stochastic models will mark ?raam? and ?ki? as the start of clause, and
?gayaa? as the end of clause, making CSPs more than the CEPs. We can notice that ?gayaa?
is the end for both the clauses in a sentence, so using this rule, we will add one more end of
clause to ?gayaa? word. The resultant sentence with clauses marked will be:
( raam ne kahaa ( ki vaha ghar gayaa ) )
(b) Check for finite verb: If a verb is finite and does not have any ?ki? complement clause in it
then that verb should be marked as the end of clause. So if this type verb is unmarked by the
stochastic model then this rule will handle this.
(c) Check for non-finite verb: If a non-finite verb is present in a sentence and word next to it does
not mark start of another clause then this rule will mark that word as the start of that clause.
45
?It should be noted that rules are applied in specific order, and once the number of CSPs and CEPs
become same at any point of rule we stop applying more rules from this type where CSPs and CEPs
are not same.
2. Rules, When CEPs are greater than CSPs are:
(a) If there is a ?non-finite? verb in a sentence then we check for its start and mark them using
regular expressions if not marked by stochastic models. for example:
(3) raam
Ram+arg
khaanaa
food
khakara
having eaten
ghar
home
gayaa
go+past
?having eaten food, Ram wen home?
In example (3), if stochastic models does not able to mark ?khaanaa? as the start of non-finite
clause ?khaanaa khakara?. Then this rules will capture these type of situations and add a new
CSP in a sentence.
(b) If a word before conjunction, not a verb, is marked as end of a clause then this rule will remove
that end, reducing number of CEP.
3. Rules, when CSPs and CEPs are same:
(a) If there are more than one clauses in one single ?ki? complement clause than this rules marks
one bigger boundary as clause which will contain all the embedded clauses. For example:
(4) raam ne
Ram+arg
kahaa
say+past
ki
that
shaam ne
Shaam+arg
khaanaa
food
khaayaa
eat+past
aur
and
paani
water
piyaa
drink+past
?Raam said that Shaam ate food and drank water?
The situation discussed in this rule can be observed in example (4). The system output before
this rule may be,
?( raam ne kahaa ( ki shaam ne khaanaa khaayaa ) aur ( paani piyaa ) )?, Which this rule will
convert to
?( raam ne kahaa ( ki ( shaam ne khaanaa khaayaa ) aur ( paani piyaa ) ) )?
? Having these rules applied, the output sentence will contain start and end of clauses in a sentence.
5 Evaluation and Results
As mentioned earlier we have used (Sharma et al., 2013) technique to automatically generate 16000
sentences of Hindi treebank marked with clause boundaries. Out of these 16000 sentences, a set of 1500
sentences with average length of 16 words was randomly selected. This set was then manually corrected
at the level of clause boundary for accurate evaluation of the system. It should be noted that this set
was not used in training of the models. Further we have divided this set into two set; development set
which consist of 500 sentences and testing set which consist of 1000 sentences. We have evaluated the
system with both models (step-by-step and merged) along with post-processing module, and we have
noticed system with step-by-step model performs better than the system with merged model. Table (2)
and Table (3) show the results on development set and testing set respectively.
Model Type Start of clause End of clause
Precision Recall F1-measure Precision Recall F1-measure
Step-by-step model 91.493 89.816 90.646 95.129 93.482 94.298
Merged Model 92.171 89.918 91.030 90.927 92.871 91.888
Table 2: Results on development set.
46
Model Type Start of clause End of clause
Precision Recall F1-measure Precision Recall F1-measure
Step-by-step model 92.051 89.590 90.804 95.969 93.458 94.697
Merged Model 91.779 88.907 90.320 90.919 92.263 91.586
Table 3: Results on testing set.
6 Error Analysis and Discussion
While evaluating our both systems (system with step-by-step model and system with merged model), we
come across some constructions which were not handled by them. which are:
1. Ellipses of verb: when a verb is omitted in a sentence then it is not possible for our system to mark
boundaries correctly. For example:
(5) raam ne
Ram+erg
kitaab
book
<V>
<read+past>
aur
and
maine
I+erg
kavitaa
poem
padhii
read+past
?Ram read a book and I read a poem?
In example (5), there is an ellipses of the verb ?padhi? in the clause ?raam ne kitaab?. Thus, though
the sentence has two clauses??raam ne kitaab? and ?maine kavitaa padhii?, our system incorrectly
identifies the whole sentence as one clause due to the ellipses of the verb (denoted by <V>).
2. Scrambling in the usual word order, which is SOV in Hindi, is likely to induce incorrect identifica-
tion of the clauses in our system. For Example:
(6) ghar
home
gayaa
go+past
raam,
Ram,
vaha
he
bolaa.
say+past
?He said Ram went home?
In example (6), Our system is unable to identify the clause boundaries correctly for any of the two
clauses, ?ghar gayaa raam? and ?ghar gayaa raam,vaha bolaa?, due to scrambling in the word order.
Its output for the sentence is ?(ghar) (gayaa raam, vaha bolaa)?, though the output should be ?( (ghar
(gayaa raam,) vaha bolaa)?.
3. Missing subordinate conjunction ?ki? in a sentence also leads to incorrect identification of clause
boundaries by our system. For example:
(7) raam ne
Ram+erg
kahaa
say+past
tum
you
ghar
home
jaao
go
?Ram said you go home?
The missing subordinate conjunction ?ki? in example (7) leads to incorrect marking of the clause
boundaries as: ?(raam ne kahaa ) ( tum ghar jaao)?. The correct clause boundaries for the sentence
are ?(raam ne kahaa ( tum ghar jaao) )?.
4. Start of non-finite clause: As we don?t find any syntactic cues for start of non-finite clause, our
systems does not perform much efficiently in finding start of non-finite clauses. For example:
(8) ab
now
hum
we
alag
different
maslon
matters/topics
para
on
khulkara
openly
baatchit
discussion
kar rahe hain
do+conti+present
?Now we are discussing openly on different matters?
47
Both system marks ?khulkara? and ?kar rahe hain? verbs as the end of clauses accurately but start of
non-finite clause which is ?alag? is not identified correctly. Output by the systems is, ?( ab hum alag
maslon para khulkara) (baatchit kar rahe hain )? , where as the correct output is, ?( ab hum ( alag
maslon para khulkara) baatchit kar rahe hain )?
-- Overall we observed that the system with step-by-step model which statistically first identifies end and
then start, followed by rules performs better than the system with merged model.
7 Conclusion and Future Work
We have discussed our work on clause boundary identification in Hindi and the issues pertaining to them,
in the course of this paper. Clausal information in a sentence is known to improve the performance of
many NLP systems, thus the need for this task. We observed that the system with step-by-step model
which statistically, first identifies end and then start of clauses, followed by rules, performs better than the
system with merged model. The step-by-step model system, showing a satisfactory performance in terms
of F1 scores of 91.53% for clause boundary identification, and the merged model system showing 80.63%
for the same. Since this task is a promising resource for NLP systems such as Machine Translation, Text-
to-Speech and so on, and can contribute to their better performance, applying this system for betterment
of NLP tools seems quite a favorable prospect as a future work. (Gadde et al., 2010) report that even
minimal clause boundary identification information leverages the performance of their system. We would
like to test the performance of our system in terms of leveraging the performance of other NLP systems
References
Steven Abney. 1990. Rapid incremental parsing with repair. pages 1?9.
R Dhivya, V Dhanalakshmi, M Anand Kumar, and KP Soman. 2012. Clause boundary identification for tamil
language using dependency parsing. pages 195?197. Springer.
Eva I Ejerhed. 1988. Finding clauses in unrestricted text by finitary and stochastic methods. pages 219?227.
Association for Computational Linguistics.
Phani Gadde, Karan Jindal, Samar Husain, Dipti Misra Sharma, and Rajeev Sangal. 2010. Improving data driven
dependency parsing using clausal information. pages 657?660. Association for Computational Linguistics.
Aniruddha Ghosh, Amitava Das, and Sivaji Bandyopadhyay. 2010. Clause identification and classification in
bengali. In 23rd International Conference on Computational Linguistics, page 17.
John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic
models for segmenting and labeling sequence data.
Vilson J Leffa. 1998. Clause processing in complex sentences. volume 1, pages 937?943.
Andrew McCallum and Wei Li. 2003. Early results for named entity recognition with conditional random fields,
feature induction and web-enhanced lexicons. In Proceedings of the seventh conference on Natural language
learning at HLT-NAACL 2003-Volume 4, pages 188?191. Association for Computational Linguistics.
Martha Palmer, Rajesh Bhatt, Bhuvana Narasimhan, Owen Rambow, Dipti Misra Sharma, and Fei Xia. 2009.
Hindi syntax: Annotating dependency, lexical predicate-argument structure, and phrase structure. pages 14?17.
Harris V Papageorgiou. 1997. Clause recognition in the framework of alignment. pages 417?426.
Georgiana Puscasu. 2004. A multilingual method for clause splitting.
R Vijay Sundar Ram and Sobha Lalitha Devi. 2008. Clause boundary identification using conditional random
fields. In Computational Linguistics and Intelligent Text Processing, pages 140?150. Springer.
Fei Sha and Fernando Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of the
2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human
Language Technology-Volume 1, pages 134?141. Association for Computational Linguistics.
48
Rahul Sharma, Soma Paul, Riyaz Ahmad Bhat, and Sambhav Jain. 2013. Automatic clause boundary annotation
in the hindi treebank.
Vinh Van Nguyen, Minh Le Nguyen, and Akira Shimazu. 2007. Using conditional random fields for clause split-
ting. Proceedings of The Pacific Association for Computational Linguistics, University of Melbourne Australia.
49
Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 102?111,
Dublin, Ireland, August 23-29 2014.
A rule based approach for automatic clause boundary detection and
classification in Hindi
Rahul Sharma, Soma Paul
Language Technology Research Centre, IIIT-Hyderabad, India
rahul.sharma@research.iiit.ac.in, soma@iiit.ac.in
Abstract
A complex sentence, divided into clauses, can be analyzed more easily than the complex sentence
itself. We present here, the task of identification and classification of clauses in Hindi text. To
the best of our knowledge, not much work has been done on clause boundary identification for
Hindi, which makes this task more important. We have built a rule based system using linguistic
cues such as coordinating conjunct, subordinating conjunct etc. Our system gives 91.53% and
80.63% F1-scores for identification and classification for finite clauses respectively, and 60.57%
accuracy for non-finite clauses.
1 Introduction
A Clause is the minimal grammatical unit which can express a proposition. It is a sequential group of
words, containing a verb or a verb group(verb and its auxiliary), and its arguments which can be explicit
or implicit in nature (Ram and Devi, 2008). This makes a clause an important unit in language grammars
and emphasis the need to identify and classify them as part of linguistic studies.
Analysis and processing of complex sentences is a far more challenging task as compared to a simple
sentence. NLP applications often perform poorly as the complexity of the sentence increases. ?It is im-
possible, to process a complex sentence if its clauses are not properly identified and classified according
to their syntactic function in the sentence? (Leffa, 1998). The performance of many NLP systems like
Machine Translation, Parallel corpora alignment, Information Extraction, Syntactic parsing, automatic
summarization and speech applications etc improves by introducing clause boundaries in a sentence (e.g.,
Ejerhed, 1988; Abney, 1990; Leffa, 1998; Papageorgiou, 1997; Gadde et al., 2010).
We present a rule based method to automatically determine ?clause? boundaries (beginnings and ends) in
complex or compound sentences, and further categorize the identified clauses according to their types.
Thus our system is made up of two parts, the first determines the boundaries of the clauses (clause iden-
tification) and the second part determines the type of the clause (Clause Classification). Rules for the
system were framed by thoroughly analyzing the Hindi-Urdu treebank (Palmer et al., 2009). This pro-
vides significant insights for the task as clause boundaries can be inferred from the dependency relations
marked in dependency trees. The rules devised for our system have minimum dependency on linguistic
resources, only part of speech (POS) and chunk information of lexical items is used with a fair perfor-
mance of the system. As far as we know, not much work has been done on clause boundary identification
for Hindi and this makes this task more significant.
This paper is structured as follows: In Section 2, we talk about clause and its types. In Section 3, we
discuss the related works that has been done earlier on clause identification and classification. Section 4
describes the data flow of our system and rules for identifying and classification of a clause. Section 5
outlines the system performance. In section 6, some issues related clause identification are discussed. In
Section 7, we conclude and talk about future works in this area.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
102
2 Clause and its Types
As defined in introduction, a clause is a group of words consisting of a verb (or a verb group) and its
arguments(explicit and implicit ), and forms part of a sentence. Depending on the type of the verb,
a clause is classified as a finite clause that contains a finite verb and non-finite clause that contains a
non-finite verb. For example:
(1) raam
Ram
khaanaa
food
khaakar
having+eaten
soyaa
sleep+past
?Having eaten food, Ram slept.?
In example (1), ?raam soyaa? is a finite clause; contains ?soyaa? finite verb, and ?khaanaa khaakar? is a
non-finite clause; contains ?khaakar? non-finite verb.
We come across two types of clauses in a complex sentence:
1. Main clause, which is an independent clause, is also called Superordinate clause. It is always a
finite clause in a sentence.
2. Subordinate clause, which is dependent on the main clause. It can be both finite and non-finite in a
sentence.
For our task we have divided subordinate clause into five different types, which are complement clause,
adverbial clause, relative clause, coordinate clause and non-finite clause (discussed shortly). Subordinate
clauses can be nested or non-nested depending on a sentence. Nested here means one clause is embedded
in another clause. For example,
(2) raam
Ram
jo
who
khela
play+past
,
,
ghar gayaa
home go+past
?Ram who played , went home.?
In example (2) the two clauses are: 1) raam ghar gayaa 2) jo khela. The second clause is embedded in
?raam ghar gayaa?.
Various kinds of subordinate clauses are discussed below:
(a) Complement Clause: These clauses are introduced by the subordinator ?ki? (that) and generally
follow the verb of main clause (Koul, 2009) and occur as a finite clause in a sentence. For example:
(3) yaha
It
sach
true
hai
is
ki
that
mohan
Mohan
bimaara
sick
hai
is
?It is true that Mohan is sick?
?ki mohan bimaar hai? is a Complement Clause and ?ki? is a complementizer in example (3). It must
be noted that ?complement clause? is also an argument of the main clause verb. So, in example (3),
the main clause is ?yaha sach hai ki mohan bimaara hai?, which contains the complement clause
?ki mohan bimaara hai?, in it. This is considered to be a special case where a clause comes as an
argument of a verb and becomes a part of that verb clause. We have handled this type of construction
separately (discussed in section 4).
(b) Relative Clause: Relative clauses which are also finite in nature occur as a modifier of verb?s argu-
ment and contain a relative pronoun (Koul, 2009). Such clause can be either nested or non-nested.
(4) vaha
that
ladkaa
boy
jo
who
khel rahaa thaa
play+past+conti.
ghar
home
gayaa
go+past
?That boy who was playing went home?
In example (4), the nested relative clause is ?jo khel rahaa thaa? (who was playing ) with ?jo? as a
relative marker. ?jo? modifies ?vo?, the argument of the verb ?gayaa?.
Another example of this, is:
(5) raam
Ram
ghar
home
gayaa
go+past
jo
who
khel rahaa thaa
play+past+conti
?Raam who was playing went home?
103
In example (5) relative clause ?jo khel rahaa thaa? is a non-nested one.
(c) Adverbial Clause: These clauses are determined based on their adverbial markers/function in a
sentence (Koul, 2009). Manner, purpose, cause, condition etc. form the types of adverbial clauses.
We take this type of clauses as the modifier of the verb?s modifier. These clauses are present as a
finite clause in sentence. For example:
(6) jaise
the way
vaha
he
jaaegaa
go+fut.
waise
that way
main
I
jaaungaa
go+fut
?I will go the way he will go?
In example (6) ?jaise vaha jaaegaa? is an Adverbial Clause with ?jaise? as the (manner) Adverbial
Marker. Here ?waise? is the modifier of the verb ?jaaungaa? and ?jaise vaha jaaegaa? modifies it.
It may be noted that we consider clauses that are modifiers of verb?s modifiers as adverbial clauses
and clauses that are modify arguments of verbs as relative clauses.
(d) Coordinate Clause: It is one of the independent finite clauses in a sentence that has the same status
as the other clauses, and is introduced by a coordinating conjunction (Koul, 2009). For example:
(7) main
I
ghar
home
jaaungaa
go+fut.
aur raam
and Ram delhi
dillii
go+fut
jaayegaa
?I will go home and Raam will go to Delhi?
?mai ghar jaaungaa? and ?raam dillii jaayegaa? are two independent clauses with the same status in
example (7). And for our work we consider both clause as coordinate clauses, and the coordinating
conjunct is not taken to be part of any of the two clauses. There is thus no hierarchy in these clauses.
When there are more than one coordinating conjunct in a sentence, clause boundary identification
becomes more complex because of nesting of the coordinate clause. This is illustrated using example
(8).
(8) raam ne
Ram+erg
kaam
work
kiyaa
do+past
aur
and
khaanaa
food
khaayaa
eat+past
lekin
but
siitaa
Sita
khelii
play+past
?Ram did the work and ate food but Sita played?
In such examples there is more than one way to mark the coordinate clauses:
- ( (raam ne kaam kiyaa ) aur (khaanaa khaayaa) ) lekin (siitaa khelii )
- (raam ne kaam kiyaa ) aur ( (khaanaa khaayaa) lekin (siitaa khelii ) )
- ( (raam ne kaam kiyaa ) aur (khaanaa khaayaa) lekin (siitaa khelii ) )
?(? and ?)? are symbols to denote the start and end of the clause. As we can see there is more than
one output possible for the given example. Our system only marks the linear boundary of the clause
in a sentence. Nesting in more than two coordinate clauses is not handled by it. So for the example
(8), our output is: (raam ne kaam kiyaa ) aur (khaanaa khaayaa) lekin (siitaa khelii )
- -It must be noted that we do not take coordinating conjuncts as part of any of the clauses, it is
conjoining. However subordinate marker are taken to be part of clause.
(e) Non-finite Clause: These clauses are dependent clause in a sentence which contain non-finite verb.
(9) raam
Ram
khaanaa
food
khaakar
eat
aur
and
paani
water
peekar
drink
ghar
home
gayaaa
go+past
?Raam after eating food and drinking water, went home?
In above example (9), two clauses, ?khaanaa khaakar? and ?paani peekar? are non-finite as they
contain non-finite verbs.
- -In Hindi, We come across some complex cases where one type of clause is embedded in another type
clause. For example:
(10) raam
Ram
jisne
who
khaanaa
food
khaayaa
eat+past
aur
and
paani
water
piyaa,
drink+past
ghar
home
gayaaa
go+past
?Raam who ate food and drank water, went home?
104
In example (10) relative clause and coordinate clause overlap with each other. The coordinate clauses
are: (jisne khaanaa khaayaa) and ( paani piyaa ), and relative clause is : (jisne khaanaa khaayaa aur paani
piyaa). So our system will mark the clause boundaries as: ( raam ( ( jisne khaanaa khaayaa ) aur ( paani
piyaa ) ) ghar gayaaa ).
3 Related works
Studies in identifying clauses date back to (Ejerhed, 1988) work, where they showed how automatic
clause boundary identification in discourse can benefit a parser?s performance. However her experiments
could detect only basic clauses. Later (Abney, 1990) used clause filter as part of his CASS parser. Papa-
georgiou (1997) used hand crafted rules to identify clause boundaries in a text. (Leffa, 1998) is another
rule based method which was implemented in an English-Portuguese MT system.
Some more recent works in this area are: (Puscasu, 2004), in which she proposed a multilingual method
of combining language independent ML techniques with language specific rules to detect clause bound-
aries in unrestricted texts. The rules identify the finite verbs and clause boundaries not included in learn-
ing process. Ram and Devi (2008) proposed a hybrid based approach for detecting clause boundaries in
a sentence. They have used a CRF based system which uses different linguistic cues. After identifying
the clause boundaries they run an error analyzer module to find false boundary markings, which are then
corrected by the rule based system, built using linguistic clues. (Ghosh et al., 2010) is another rule based
system for clause boundary identification for Bengali, where they use machine learning approach for
clause classification and dependency relations between verb and its argument to find clause boundaries.
Dhivya et al. (2012) use dependency trees from maltparser and the dependency tag-set with 11 tags to
identify clause boundaries. Similar to (Dhivya et al., 2012), Sharma et al. (2013) showed how implicit
clause information present in dependency trees can be used to extract clauses in sentences. Their system
have reported 94.44% accuracy for Hindi.Gadde et al. (2010) reported improvement in parser perfor-
mance by introducing automatic clause information in a sentence for Hindi in ?Improving data driven
dependency parsing using clausal information?. However their approach for identifying clause informa-
tion has not been discussed. Thus a comparison is not possible here.
Our work is similar to that of (Leffa, 1998) in that both first mark clause boundaries and then classify
the clauses into various types. Both use linguistic cues such as coordinating conjuncts, subordinating
conjunction, surrounding context, however , while (Leffa, 1998) use POS information and valency of the
verbs , we use POS tags and chunks as the only linguistic information.
4 Methodology
We propose a rule based system which first identifies the clause(s) in the input sentence and marks the
?clause start position? (CSP) and ?clause end position? (CEP) with brackets and then it classifies the
identified clauses into one of the proposed types mentioned in section 2. Hindi usually follows the SOV
word order, so ends of the clauses can be found by just using verb information, in most of the cases.
The language also has explicit relative pronouns, subordinating conjuncts, coordinate conjunctions etc.
which serve as cues that help to identify clause boundaries and the type of the clauses. Thus our system
uses lists of coordinate conjunctions, relative markers and adverbial clause markers (see Appendix A
and Appendix B for the lists). These lists were created using (Kachru, 2006). Further, the rules for our
system have been framed based on our in depth analysis of a section of the Hindi treebank (Palmer et
al., 2009). Apart from the lexical cues we have also used POS tag and chunk information to frame these
rules.
4.1 Algorithm
Our system consists of two parts, the first part determines the boundaries of the clauses (clause
identification) and the second part determines the type of the clause (clause classification). Identification
of clause boundaries is further divided into two tasks, i.e. to find the beginnings and the ends of clauses.
Then, the sentences with the clause boundaries marked are processed by the clause classification
component, and are assigned to one of the clause types--main clause, complement clause, adverbial
105
clause, relative clause, coordinate clause and non-finite clause. Figures 1 shows the data flow of our
system, components of which have been discussed in detail, further in this section.
Input
Sentence
preprocessing
CEP Identification
CSP Identification
is E
equal to
S?
Sanity
Checker
?ki? subordinating handler
Coordination handler
Clause Classification
Output
no
yes
In this Data flow of our system, E represents number of
?clause end position? and S represents number of ?clause
start position? marked by our system.
Figure 1: Data Flow
4.1.1 Preprocessing
In this module, input sentences are processed and each lexical item is assigned a POS tag, and chunk
information . For example:
Input sentence:
(11) raam
Ram
soyaa.
sleep+past
?Ram slept.?
Output:
1 (( NP
1.1 raam NNP
))
2 (( VGF
2.1 soyaa VM
2.2 . SYM
))
- -Here ?NP? and ?VGF? are the chunk tags, and POS tags ?NNP? and ?VM? stand for Noun and Verb
respectively (Bharati et al., 2007; Bharati et al., 2009) .
4.1.2 CEP Identification
The unmarked word order of Hindi mainly being SOV, the verb is taken to be the end of the clause. In
cases where a sentence does not end with a verb , the end of sentence is taken as end of the clause. This
helps to handle instances of scrambling and ellipses. For example:
(12) siitaa
Sita
ghar
home
jaa rahii hai
go+present+cont
aur
and
giitaa
Gita
bhii.
also
?Sita is going home and so does Gita.?
In example (12), there is an ellipses of the verb ?jaa rahii hai? in the second clause ?giitaa bhii?. In
cases like this, our system marks the verb as end of the first clause and sentence end as end of the second
106
clause. The marked boundaries in the sentence after this module will be: ?siitaa ghar jaa rahii hai ) aur
gitaa bhi )?.
4.1.3 CSP Identification
We have made two modules to find the start of the clauses; one identifies the start of finite clauses and
the other identifies the start of non-finite clauses. As we have mentioned a clause is a finite or non-finite,
depending on the verb in that clause. So we have used chunk information which gives the verb type
(finite or non-finite). Both these modules are independent of each other, so running them parallel will
not affect the system, and this helps to speed up the system processing.
4.1.3.1 CSP for finite clause
This module uses linguistic cues such as relative markers (jo ?that/who?, jisane ?who?), coordinating
conjuncts (aur ?and?, lekin ?but?) and so on, to identify the start of clauses. It may be noted that the
immediate context of cues is also taken into account at times. For instance, a coordinating conjunct
?aur? (and) in a sentence marks the start of the clause only if it is preceded by a verb, whereas the
subordinating conjunct ?ki? (that) always marks the start of a clause. After the start/s of clause/s in a
sentence are identified, the module checks whether the beginning of the sentence is marked as a clause
start, and marks it as clause beginning if it is not already marked. For example:
(13) raam
Ram
jo
who
khel rahaa tha
play+past+conti.
nahii
not
aayaa.
come+present
?Ram who was playing did not come.?
In example (13), first our module identifies ?jo? relative marker and marks it as a start of the clause ?jo
khel rahaa tha?, and then, marks the beginning of the sentence as the start of the other clause ?raam nahii
aayaa?. After this, the boundaries marked in example (12) will be : ( raam ( jo khel rahaa tha ) nahii
aayaa. )
It needs a mention here that the boundaries marked in the previous module are also included in the current
module?s output.
4.1.3.2 CSP for non-finite clause
Non-finite verbs do not have Tense-Aspect-Mood(TAM) information, they take optional arguments
which are not specific in number. In Hindi, we don?t find any cues to detect where a non-finite clause
starts. So to identify the start of a non-finite clause, we have built templates/regular expressions on
chunks in a sentence, and whenever a pattern in a sentence matches the template, we mark that as a start
of the clause. Following example shows the working of this module:
(14) raam
Ram
ghar para
home
jaakar
to
khaanaa
after going
khaayega.
food eat+future
?After going to home, Ram will eat food.?
In the example (14), ?ghar para? and ?raam? are two separate chunks that precede the non-finite verb
?jaakar?. As per the template, if a ?para? marked NP chunk follows the nominative NP and immediately
precedes the ?jaakar? type non-finite verb, the NP chunk marks the start of the ?jaakar? non-finite clause.
4.1.4 Sanity Checker
In case the number of CSPs is not equal to the number of CEPs in a sentence, the Sanity Checker module
comes into play. It iterates through the CSP identifier?s output for the sentence and marks the omitted
CSPs. For example:
(15) raam
Ram
ghar
home
gayaa,
go+past,
shyaam
Shyam
nahii
not
gayaa.
go+past.
?Ram went home, Shyam did not go.?
The absence of a coordinator between the two clauses ?raam ghar gayaa? and ?shyaam nahii gayaa?,
in Example (15) can lead to potential error of ommision of the CSP for the second clause ?shyaam nahii
gayaa?. The output of such a sentence would be:
?(raam ghar gayaa) shyaam nahii gayaa.)?
As we can see here, the CSP for the clause ?shyaam nahii gayaa? is omitted. On detecting such an error,
the sanity checker would iterate the sentence and mark the omitted CSP, and the output would then be:
?(raam ghar gayaa) (shyaam nahii gayaa.)?
107
4.1.5 ?ki? complementizer handler
As mentioned earlier, ?ki? complement clause is an argument of the main verb and part of its main verb
clause. Thus this modules executes, and identifies ?ki? complementizer and its clause in the sentence,
and modifies the CEP of its parent clause. Example (16) explains this further.
(16) raam ne
ram+erg
kahaa
say+past
ki
that
tum
you
ghar
home
jaao
go
?Ram said that you go home.?
The input for the sentence ?raam ne kahaa ki tum ghar jaao? that this module receives would be:
?(raam ne kahaa) (ki tum ghar jaao)?
The ?ki? complementizer module iterates this input and identifies the ?ki? complement clause and its CEP.
It then modifies this input by moving the CEP, immediate before ?ki? complementizer to the position
immediate after the CEP of ?ki? complement clause. The modified sentence will be:
?(raam ne kahaa (ki tum ghar jaao) )?
4.1.6 Coordination handler
This module handles embedded coordinated clauses in complex sentence where they fall within the scope
of a complementizer, a relative marker or an adverbial marker. It makes a new CSP for these clauses
immediately before the complementizer, relative marker or adverbial marker and a new CEP after the
CEP of the last embedded coordinate clause. For example:
(17) raam
Ram
jisne
who+rel.
khaanaa
food
khaayaa
eat+past
aur
and
khel
game
khelaa
play+past
ghar
home
gayaa
go+past
?Ram who ate food and played a game, went home.?
Given the output for the example (17), this module identifies the ?jisne? the relative marker and inserts
a new CSP immediately before it. It also inserts the CEP for their coordinate clauses after the CEP of the
last embedded coordinate clause ?khel khelaa?. The output would be:
(raam ( (jisne khaanaa khaayaa) aur (khel khelaa) ) ghar gayaa.)
4.1.7 Clause Classification
Once the clause boundaries are identified, the output is passed on to the clause classifier where it assign
them to one of the clause classes--main clause, complement clause, adverbial clause, relative clause,
coordinate clause and non-finite clause. If a sentence has only one clause, it is classified as the main
clause. However given more than one clause in a sentence, it iterates the sentence and assign classes to
the clauses based on cues such as relative markers, coordinating conjuncts etc. Verb type also helps to
deduce whether a clause is non-finite or not. It then checks for potential omission and marks the omitted
clauses as main clause, since they fail to fall under any of the other five classes.
In example (17) ,conjunction ?aur? helps to mark the two adjacent clauses--?jisne khaanaa khaayaa? and
?khel khelaa? as coordinate clauses. Relative marker ?jisne? helps to identify ?jisne khaanaa khaayaa aur
khel khelaa? as a relative clause and the clause that remained ?raam ghar gayaa? is taken as main clause.
5 Evaluation and Results
As mentioned earlier identification of clause boundary for finite and non-finite clauses are independent,
we have evaluated them separately. Finite clause mainly have 5 types; Main clause, Complement Clause,
Adverbial Clause, Relative Clause and Coordinate clause and evaluation has been done on them.
5.1 Results for Finite Clause
A fresh set of 100 sentences average length of 16 words is randomly selected from a section of the Hindi
treebank. This section is different from the section from which the sentences were chosen for analysis.
The selected sentences have 217 clauses. An analysis of the category of these clauses is presented in
Table 1. This evaluation set was annotated manually at the level of clause boundary and their type, to
evaluate performance of the system. As mentioned earlier, five types of tags ; Main clause, Complement
Clause, Adverbial Clause, Relative Clause and Coordinate clause, were used to annotate them.
108
Clause Type %
Main Clause 33.79
Coordinate Clause 31.48
Complement Cl ause 24.07
Relative Clause 9.72
Adverbial Clause 0.9
Table 1: Clause distribution table.
5.1.1 Results of Clause Boundary Identification
For the evaluation of Clause Boundary identification, a clause is taken to be marked correctly iff its
CSP and CEP are marked correctly. A sentence with more than one clause may have correctly marked
clauses as well as incorrectly marked clauses. We evaluate the task at clause level, not at sentence level.
The precision and Recall for clause boundary identification are 91.30% and 91.78% respectively.
5.1.2 Results of Clause Classification
For the evaluation of Clause Classification, we take a clause to be correctly classified if its boundaries as
well as type is marked correctly. So, clauses with incorrectly marked boundaries are considered wrongly
classified. The precision and Recall for clause classification are 80.28% and 81.04% respectively. Table
(2) shows the results for different clause categories.
Clause Type Precision% Recall% F1 score%
Main Clause 77.90 91.78 84.27
Coordiante Clasue 80.00 70.58 74.99
Complement Clause 92.30 92.30 92.30
Relative Clause 93.33 66.66 77.77
Adverbial Clause 100 50 66.66
Table 2: Results of Clause Classification
5.2 Results for Non-finite Clause
A set of 96 sentences containing 104 non-finite clauses was taken for the evaluation. It was found that end
of all non-finite clause were identified but there were 63 clauses whose start boundary were identified.
The accuracy of the system in identifying non-finite clauses is 60.57%.
6 Error Analysis and Discussion
While evaluating our system, we come across some constructions which were not handled by it. which
are:
1. Ellipses of verb: when a verb is omitted in a sentence then it is not possible for our system to mark
boundaries correctly. For example:
(18) raam ne
Ram+erg
kitaab
book
<V>
<read+past>
aur
and
maine
I+erg
kavitaa
poem
padhii
read+past
?Ram read a book and I read a poem?
In example (18), there is an ellipses of the verb ?padhi? in the clause ?raam ne kitaab?. Thus, though
the sentence has two clauses??raam ne kitaab? and ?maine kavitaa padhii?, our system incorrectly
identifies the whole sentence as one clause due to the ellipses of the verb (denoted by <V>).
2. Scrambling in the usual word order, which is SOV in Hindi, is likely to induce incorrect identifica-
tion of the clauses in our system. For Example:
(19) ghar
home
gayaa
go+past
raam,
Ram,
vaha
he
bolaa.
say+past
?He said Ram went home?
109
In example (19), Our system is unable to identify the clause boundaries correctly for any of the two
clauses, ?ghar gayaa raam? and ?ghar gayaa raam,vaha bolaa?, due to scrambling in the word order.
Its output for the sentence is ?(ghar) (gayaa raam, vaha bolaa)?, though the output should be ?( (ghar
(gayaa raam,) vaha bolaa)?.
3. Missing subordinate conjunction ?ki? in a sentence also leads to incorrect identification of clause
boundaries by our system. For example:
(20) raam ne
Ram+erg
kahaa
say+past
tum
you
ghar
home
jaao
go
?Ram said you go home?
The missing subordinate conjunction ?ki? in example (20) leads to incorrect marking of the clause
boundaries as: ?(raam ne kahaa ) ( tum ghar jaao)?. The correct clause boundaries for the sentence
are ?(raam ne kahaa ( tum ghar jaao) )?.
4. Templates used for identification of non-finite clauses are not much efficient. They are more specific
and need to be more general.
7 Conclusion and Future Work
We have discussed our work on clause boundary identification and classification in Hindi and the issues
pertaining to them, in the course of this paper. Clausal information in a sentence is known to improve
the performance of many NLP systems, thus the need for this task. While a larger section of the Hindi
dependency treebank from the HUTB project was analyzed to formulate the rules for the task. The
system, showing a satisfactory performance for finite clauses in terms of F1 scores of 91.53% for clause
boundary identification and 80.63% for clause Classification, while giving inadequate results for non-
finite clauses with 60.57% accuracy. We would like to mention that at present our system doesn?t handle
classification of different instances of ?to? (else, then, or etc.) and of coordination where a punctuation
serves as a coordinator. In the future we intend to incorporate this in our system. Further, since this task
is a promising resource for NLP systems such as Machine Translation, Text-to-Speech and so on, and
can contribute to their better performance, adopting an ML approach for this task seems quite a favorable
prospect as a future work. (Gadde et al., 2010) report that even minimal clause boundary identification
information leverages the performance of their system. We would like to test the performance of our
system in terms of leveraging the performance of other NLP systems.
References
Steven Abney. 1990. Rapid incremental parsing with repair. pages 1?9.
Akshar Bharati, Rajeev Sangal, and Dipti M Sharma. 2007. Ssf: Shakti standard format guide. pages 1?25.
Akshara Bharati, Dipti Misra Sharma, Samar Husain, Lakshmi Bai, Rafiya Begam, and Rajeev Sangal. 2009.
Anncorra: Treebanks for indian languages, guidelines for annotating hindi treebank.
R Dhivya, V Dhanalakshmi, M Anand Kumar, and KP Soman. 2012. Clause boundary identification for tamil
language using dependency parsing. pages 195?197. Springer.
Eva I Ejerhed. 1988. Finding clauses in unrestricted text by finitary and stochastic methods. pages 219?227.
Association for Computational Linguistics.
Phani Gadde, Karan Jindal, Samar Husain, Dipti Misra Sharma, and Rajeev Sangal. 2010. Improving data driven
dependency parsing using clausal information. pages 657?660. Association for Computational Linguistics.
Aniruddha Ghosh, Amitava Das, and Sivaji Bandyopadhyay. 2010. Clause identification and classification in
bengali. In 23rd International Conference on Computational Linguistics, page 17.
Yamuna Kachru. 2006. Hindi, volume 12. John Benjamins Publishing Company.
110
Omkar Nath Koul. 2009. Modern Hindi Grammar. Indian Institute of Language Studies.
Vilson J Leffa. 1998. Clause processing in complex sentences. volume 1, pages 937?943.
Martha Palmer, Rajesh Bhatt, Bhuvana Narasimhan, Owen Rambow, Dipti Misra Sharma, and Fei Xia. 2009.
Hindi syntax: Annotating dependency, lexical predicate-argument structure, and phrase structure. pages 14?17.
Harris V Papageorgiou. 1997. Clause recognition in the framework of alignment. pages 417?426.
Georgiana Puscasu. 2004. A multilingual method for clause splitting.
R Vijay Sundar Ram and Sobha Lalitha Devi. 2008. Clause boundary identification using conditional random
fields. In Computational Linguistics and Intelligent Text Processing, pages 140?150. Springer.
Rahul Sharma, Soma Paul, Riyaz Ahmad Bhat, and Sambhav Jain. 2013. Automatic clause boundary annotation
in the hindi treebank.
Appendix A : Conjuction List
aur ?and? athwaa ?or? yaa ?or? evam ?and? para ?but? magar ?but?
lekin ?but? kintu ?but? parantu ?but? tathaa ?and? jabki ?eventhough? va ?and?
isalie ?therfore? kyunki ?because?
Appendix B : List of Relative ( and Coorelative) Markers
jo ?who? jiskaa ?whose? jiske ?whose? jiski ?whose? jisko ?whose?
jisse ?from which? jise ?who? jinse ?from whom? jinhen ?to whom? jinhone ?who?
jinmen ?where? jaba ?when? jisse ?from which? jise ?who?
111
Proceedings of the Workshop on Automatic Text Simplification: Methods and Applications in the Multilingual Society, pages 21?29,
Dublin, Ireland, August 24th 2014.
Exploring the effects of Sentence Simplification on Hindi to English
Machine Translation System
Kshitij Mishra Ankush Soni Rahul Sharma Dipti Misra Sharma
Language Technologies Research Centre
IIIT Hyderabad
{kshitij.mishra,ankush.soni,rahul.sharma}@research.iiit.ac.in,
dipti@iiit.ac.in
Abstract
Even though, a lot of research has already been done on Machine Translation, translating com-
plex sentences has been a stumbling block in the process. To improve the performance of ma-
chine translation on complex sentences, simplifying the sentences becomes imperative. In this
paper, we present a rule based approach to address this problem by simplifying complex sen-
tences in Hindi into multiple simple sentences. The sentence is split using clause boundaries and
dependency parsing which identifies different arguments of verbs, thus changing the grammatical
structure in a way that the semantic information of the original sentence stay preserved.
1 Introduction
Cognitive and psychological studies on ?human reading? state that the effort in reading and understand-
ing a text increases with the sentence complexity. Sentence complexity can be primarily classified
into ?lexical complexity? and ?syntactic complexity?. Lexical complexity deals with the vocabulary
practiced in the sentence while syntactic complexity is governed by the linguistic competence of
native speakers of a particular language. In this respect, the modern machine translation systems are
similar to humans. Processing complex sentences with high accuracy has always been a challenge in
machine translation. This calls for automatic techniques aiming at simplification of complex sentences
both lexically and syntactically. In context of natural language applications, lexical complexity can
be handled significantly by utilizing various resources like lexicons, dictionary, thesaurus etc. and
substituting infrequent words with their frequent counterparts. However, syntactic complexity requires
mature endeavors and techniques.
Machine Translation systems when dealing with highly diverges language pairs face difficulty in trans-
lation. It seems intuitive to break down the sentence into simplified sentences and use them for the task.
Phrase based translation systems exercise a similar approach where system divides the sentences into
phrases and translates each phrase independently, later reordering and concatenating them into a single
sentence. However, the focus of translation is not on producing a single sentence but to preserve the
semantics of the source sentence, with a decent readability at the target side.
We present a rule based approach which is basically an improvement on the work done by (Soni et al.,
2013) for sentence simplification in Hindi. The approach adapted by them has some limitations since it
uses verb frames to extract the core arguments of verb; there is no way to identify information like time,
place, manner etc. of the event expressed by the verb which could be crucial for sentence simplification.
A parse tree of a sentence could potentially address this problem. We use a dependency parser of Hindi
for this purpose. (Soni et al., 2013) didn?t consider breaking the sentences at finite verbs while we split
the sentences on finite verbs also.
This paper is structured as follows: In Section 2, we discuss the related work that has been done earlier
on sentence simplification. Section 3 addresses criteria for classification of complex sentences. In section
4, we discuss the algorithm used for splitting the sentences. Section 5 outlines evaluation of the systems
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
21
using both BLEU scores and human readability . In Section 6, we conclude and talk about future work
in this area.
2 Related Work
Siddharthan (2002) presents a three stage pipelined approach for text simplification. He has also looked
into the discourse level problems arising from syntactic text simplification and proposed solutions to
overcome them. In his later works (Siddharthan, 2006), he discussed syntactic simplification of sen-
tences. He has formulated the interactions between discourse and syntax during the process of sentence
simplification. Chandrasekar et al. (1996) proposed Finite state grammar and Dependency based ap-
proach for sentence simplification. They first build a stuctural representation of the sentence and then
apply a sequence of rules for extracting the elements that could be simplified. Chandrasekar and Srinivas
(1997) have put forward an approach to automatically induce rules for sentence simplification. In their
approach all the dependency information of a words is localized to a single structure which provides a
local domain of influence to the induced rules.
Sudoh et al. (2010) proposed divide and translate technique to address the issue of long distance re-
ordering for machine translation. They have used clauses as segments for splitting. In their approach,
clauses are translated separately with non-terminals using SMT method and then sentences are recon-
structed based on the non-terminals. Doi and Sumita (2003) used splitting techniques for simplifying
sentences and then utilizing the output for machine translation. Leffa (1998) has shown that simplifying
a sentence into clauses can help machine translation. They have built a rule based clause identifier to
enhance the performance of MT system.
Though the field of sentence simplification has been explored for enhancing machine translation for
English as source language, we don?t find significant work for Hindi. Poornima et al. (2011) has reported
a rule based technique to simplify complex sentences based on connectives like subordinating conjunc-
tion, relative pronouns etc. The MT system used by them performs better for simplified sentences as
compared to original complex sentences.
3 Complex Sentence
In this section we try to identify the definition of sentence complexity in the context of machine trans-
lation. In general, complex sentences have more than one clause (Kachru, 2006) and these clauses are
combined using connectives. In the context of machine translation, the performance of system generally
decreases with increase in the length of the sentence (Chandrasekar et al., 1996). Soni et al. (2013) has
also mentioned that the number of verb chunks increases with the length of sentence. They have also
mentioned the criteria for defining complexity of a sentence and the same criteria is apt for our purpose
also. We consider a sentence to be complex based on the following criteria:
? Criterion1 : Length of the sentence is greater than 5.
? Criterion2 : Number of verb chunks in the sentence is more than 1.
? Criterion3 : Number of conjuncts in the sentence is greater than 0.
Table 1 shows classification of a sentence based on the possible combinations of 3 criteria mentioned
above.
4 Sentence Simplification Algorithm
We propose a rule based system for sentence simplification, which first identifies the clause boundaries
in the input sentence, and then splits the sentence using those clause boundaries. Once different clauses
are identified, they are further processed to find shared argument for non-finite verbs. Then, the Tense-
Aspect-Modality(TAM) information of the non-finite verbs is changed. Below example (12) illustrates
the same,
22
Table 1: Classification of a sentence as simple or complex
Criterion1 Criterion2 Criterion3 Category
No No No Simple
No No Yes Simple
No Yes No Simple
No Yes Yes Simple
Yes No No Simple
Yes No Yes Complex
Yes Yes No Complex
Yes Yes Yes Complex
(1) raam
Ram
ne khaanaa
food
khaakara
after+eating
pani
water
piya
drink+past
?Ram drank water after eating.?
We first mark the boundaries of clauses for example (12). ?raam? and ?khaanaa? are starts, and ?khaakara?
and ?piya? are ends of two different clauses respectively. Once the start and end of clauses are identified
we break the sentence into those clauses. So for above example, the two clauses are:
1. ?raam ne pani piya?
2. ?khaanaa khaakara?
Once we have the clauses, we post process those clauses which contain non-finite verbs, and add the
shared argument and TAM information for these non-finite clauses. After post-processing, the two
simplified clauses are:
1. ?raam ne pani piya.?
2. ?raam ne khaanaa khaayaa.?
4.1 Algorithm
Our system comprises of a pipeline incorporating various modules. The first module determines the
boundaries of clauses (clause identification) and splits the sentence on the basis of those boundaries.
Then, the clauses are processed by a gerund handler - which finds the arguments of gerunds, shared
argument adder which fetches the shared arguments between verbs, TAM(Tense Aspect Modality)
generator which changes the TAM of other verbs on the basis of main verb. The figure 4.1 shows the
data flow of our system, components of which have been discussed in further detail in this section.
23
Input
Sentence
Preprocessing
Clause boundary
identification
and splitting
of sentences
Gerunds Handler
Shared
Argument
Adder
TAM
generator
Output
Figure 1: Data Flow
4.1.1 Preprocessing
In this module, raw input sentences are processed and each lexical item is assigned a POS tag, chunk and
dependency relations information in SSF format(Bharati et al., 2007; Bharati et al., 2009). We have used
(Jain et al., 2012) dependency parser for preprocessing. Example (2) shows the output of this step.
Input sentence:
(2) raam ne
Ram+erg
khaanaa
food
khaayaa
eat+past
aur
and
paani
water
piyaa.
drink+past
?Raam ate food and drank water?
Output: Figure (1) shows the different linguistic information in SSF format. Tag contains the Chunk
and POS information of the sentence, and drel in feature structure stores different dependency relations
in a sentence.
Offset Token Tag Feature structure
1 (( NP <fs name=?NP? drel=?k1:VGF?>
1.1 raama NNP <fs af=?raama,n,m,sg,3,d,0,0?>
1.2 ne PSP <fs af=?ne,psp,,,,,,?>
))
1 2 (( NP <fs name=?NP2? drel=?k2:VGF?>
2.1 khaanaa NN <fs af=?khaanaa,n,m,sg,3,d,0,0? name=?khaanaa?>
))
3 (( VGF <fs name=?VGF? drel=?ccof:CCP?>
3.1 khaayaa VM <fs af=?KA,v,m,sg,any,,yA,yA? name=?khaayaa?>
))
4 (( CCP <fs name=?CCP?>
4.1 aur CC <fs af=?Ora,avy,,,,,,? name=?aur?>
))
5 (( NP <fs name=?NP3? drel=?k2:VGF2?>
5.1 paani NN <fs af=?pAnI,n,m,sg,3,d,0,0? name=?paani?>
))
6 (( VGF <fs name=?VGF2? drel=?ccof:CCP?>
6.1 piyaa VM <fs af=?pIyA,unk,,,,,,? name=?piyaa?>
))
Figure 1: SSF representation for example 2
24
4.1.2 Clause boundary Identification and splitting of sentences
This module takes the input from preprocessing module and identifies the clause boundaries in the sen-
tence. Once clause boundaries are identified, the sentence is divided into different clauses. We have
used the technique mentioned in Sharma et al. (2013) which has shown how implicit clause information
present in dependency trees/relations can be used to extract clauses from a sentence. Once we mark the
clause boundaries using this approach, we break the sentence into different simple clauses along those
clause boundaries. The example(3) given below illustrates the same.
(3) raam
Ram
jisne
who+rel.
khaanaa
food
khaayaa
eat+past
ghar
home
gayaa
go+past
?Ram who ate food, went home?
Example(3) with clause boundaries marked is, ( raam ( jisne khaanaa khaayaa ) ghar gayaa). Once
the clause boundaries are marked, we break the sentence using those boundaries. So for Example(3),
split clauses are,
1. raam ghar gayaa.
2. jisne khaanaa khaayaa.
4.1.3 Gerunds Handler
Since, Sharma et al. (2013) identifies clause boundary for non-finite and finite verb only, gerunds are not
handled in the previous module. This module is used to handle gerunds in the given sentence. In this
module, the gerund chunks are first indentified and then further processed after getting the arguments.
Consider an example:
(4) logon ko
people
sambodhit
address
karne ke baad
doing after
dono
both
netaon ne
leaders
pradhanmantri
Prime minister
ko
to
istifa
resignation
saunpa
gave
?After addressing people, both leaders gave resignation to the prime minister?
In the above example, the clause boundary identifier module marks the entire sentence as a clause but
karne ke baad is a gerund chunk (verb chunk) here, which is marked as VGNN according to the tagset
of the POS tagger used. According to definition of complex sentence given in section 3 gerunds also
introduce complexity in a sentence. Therefore, in order to simplify such sentences, we use dependency
parsing information for extracting the arguments of gerund and splitting the sentence.
Here logon ko and sambodhit are the arguments of verb chunk karne ke baad. Here ke baad is postpo-
sition of verb karne so, ke baad is splitted from karne and it has been used with the pronoun is to make
the sentence more readable.
1. logon ko sambodhit karne
2. iske baad dono netaon ne pradhanmantri ko istifa saunpa
4.1.4 Shared Argument Adder
After identifying clauses and handling gerunds, the shared arguments are identified between the verbs
and sentences are formed accordingly. For example:
(5) (ram
(ram
(chai
(tea
aur
and
paani
water
peekar)
after drinking)
soyaa)
slept)
?ram slept after drinking tea and water?
25
Here ram is the shared argument(k1-karta) of both the verbs peekar and soyaa . The dependency
parser used, marks the inverse dependencies for shared arguments which helps in . So the output of this
module is:
1. ram chai aur paani peekar.
2. ram soyaa.
4.1.5 TAM generator
The split sentences given by the above module are converted into more readable sentences using this
module. The form of other verbs is changed using TAM information of the main verb provided by the
morph, as shown in Figure 1. For example:
INPUT:
1. ram chai aur paani peekar.
2. ram soyaa.
OUTPUT:
1. ram chai aur paani peeyaa.
2. ram soyaa.
Here soyaa is the main verb having yaa as TAM. Word generator
1
has been used to generate the
final verb given root form of the verb and TAM of the verb. Here pee is the root form of peekar and
yaa is given as the TAM. Word generator generates peeyaa as the final word which is used in the sentence.
5 Evaluation
We have taken a corpus of 100 complex sentences for the evaluation of our tool. These sentences
were taken from the Hindi treebank (Bhatt et al., 2009; Palmer et al., 2009). Evaluation of both sen-
tence simplification and its effects on google MT system for Hindi to English(google translate) was
performed. The evaluation of sentence simplification is a subjective task which considers both readabil-
ity and preservation of semantic information. Hence both manual as well as automatic evaluations have
been performed.
5.1 Automatic Evaluation
We have used BLEU score (Papineni et al., 2002) for automatic evaluation of both tasks; sentence sim-
plification and enhancing MT system. Higher the BLEU score, closer the target set is to the reference set.
The maximum attainable value is 1 while minimum possible value is 0. For our Automatic evaluation
we adopted the same technique as Specia (2010) using BLEU metric. We have achieved 0.6949 BLEU
score for sentence simplification task. For MT system, we have evaluated the system with and without
sentence simplification tool. It was observed that the system with sentence simplification tool achieved
0.4986 BLEU score whereas the system without sentence simplification gave BLEU score of 0.4541.
5.2 Human Evaluation
To ensure the simplification quality, manual evaluation was also done. 20 sentences were randomly
selected from the testing data-set of 100 sentences. Output of these 20 sentences, from the target set were
manually evaluated by 2 subjects, who have done basic courses in linguistics, for judging ?Readability?
and ?Simplification? quality on the scale of 0? 3, 0 being the worst and 3 being the best.
For Simplification performance, scores were given according to following criteria :
1
Taken from the ILMT pipeline.
26
? 0 = None of the expected simplifications performed.
? 1 = Some of the expected simplifications performed.
? 2 = Most of the expected simplifications performed.
? 3 = Complete Simplification.
After taking input from all the participants the results averaged out to be 2.5.
For Human evaluation of MT system, the subjects had to select the better translation between system with
sentence simplification tool and system without it. The subjects reportedly observed a better translation
of the system with sentence simplification tool. It was reported that 12 out of 20 sentences were translated
better after being simplified, and quality of 3 remained unchanged.
Translation quality of 5 was reported to be better before simplification. This happened because the
system breaks the sentences at every verb chunk it encounters, which in some cases makes the sentence
lose its semantic information.
For example the sentence below contains five verb chunks. The system breaks the sentence into five
sentences.:
(6) yah
this
poochne
ask
par
on
ki
that
kya
what
we
he
dobaara
again
congress
Congress
mein
in
lautenge
return
sangama
Sangama
ne kaha
told
ki
that
na
neither
to
then
iski
its
zarurat
requirement
hai
is
aur
and
na
nor
hi peeche
back
lautane
return
ka sawal
question
hi uthta
raises
hai
is
?On asking whether he would return again in Congress, Sangma replied that neither there is need
of this nor there is the question of reverting back.?
System?s Output
1. (7) kya
what
we
he
dobaara
again
congress
Congress
mein
in
lautenge
return
?Would they return again in Congress ??
2. (8) yah
this
poochane
ask
par
on
sangama
Sangama
ne kaha
told
?On asking this, Sangama said.?
3. (9) na
neither
to iski
its
zarurat
requirement
hai
is told
?Neither it is needed.?
4. (10) na
neither
hee peeche
back
lautana
return
hai
is
?Neither he will return.?
5. (11) iska
its
sawal
question
uthta
raises
hai
is
?The question arises.?
It is clearly observable that the simplified sentences failed to preserve the meaning of the original sen-
tence. Further, the system does not change the vibhakti (Bharati et al., 1995) of the simplified sentences
which, in some cases makes the sentence lose its meaning. For example
(12) machharon
Mosquitoes
ke
of
katne
bite
ke
of
baad
after
wo
they
beemar
sick
hue
became
?They became sick after being bitten by the mosquitoes.?
System?s Output:
27
1. (13) machharon
Mosquitoes
ke
of
kata
bite
?Not a valid sentence?
2. (14) is
this
ke
of
baad
after
wo
they
beemar
sick
hue
became
?After this they became sick.?
In the first simplified sentence the vibhakti ?ke? should have been changed to ?ne? for the formation of
a valid sentence.
6 Conclusion and Future Work
As shown in the results, after simplifying the sentences, BLEU score of the translation increases by 4.45.
The manual evaluation also got encouraging results in simplification and readability with a score of 2.5 on
a scale of 0?3. There is a clear indication that our tool can enhance the performance of MT for complex
sentences by simplifying them. Future work will include minimizing the lose of semantic information
while splitting the sentences and making simplified sentences more readable and grammatically correct.
In addition to extending the system, evaluating the impact of our tool on other NLP tasks like parsing,
dialog systems, summarisation, question-answering systems etc. is also a future goal.
Acknowledgements
We would like to thank Riyaz Ahmad Bhat, Rishabh Shrivastava and Prateek Saxena for their useful
comments and feedback which helped us to improve this paper and Anshul Bhargava, Arpita Batra,
Abhijat Sharma, Gaurav Kakkar, Jyoti Jha and Urmi Ghosh for helping us in annotation.
References
Akshar Bharati, Vineet Chaitanya, Rajeev Sangal, and KV Ramakrishnamacharyulu. 1995. Natural language
processing: a Paninian perspective. Prentice-Hall of India New Delhi.
Akshar Bharati, Rajeev Sangal, and Dipti M Sharma. 2007. Ssf: Shakti standard format guide. pages 1?25.
Akshara Bharati, Dipti Misra Sharma, Samar Husain, Lakshmi Bai, Rafiya Begam, and Rajeev Sangal. 2009.
Anncorra: Treebanks for indian languages, guidelines for annotating hindi treebank.
R. Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.M. Sharma, and F. Xia. 2009. A multi-representational
and multi-layered treebank for hindi/urdu. In Proceedings of the Third Linguistic Annotation Workshop, pages
186?189. Association for Computational Linguistics.
Raman Chandrasekar and Bangalore Srinivas. 1997. Automatic induction of rules for text simplification.
Knowledge-Based Systems, 10(3):183?190.
Raman Chandrasekar, Christine Doran, and Bangalore Srinivas. 1996. Motivations and methods for text sim-
plification. In Proceedings of the 16th conference on Computational linguistics-Volume 2, pages 1041?1044.
Association for Computational Linguistics.
Takao Doi and Eiichiro Sumita. 2003. Input sentence splitting and translating. In Proc. of Workshop on Building
and Using Parallel Texts, HLT-NAACL 2003, pages 104?110.
Naman Jain, Karan Singla, Aniruddha Tammewar, and Sambhav Jain, 2012. Proceedings of the Workshop on
Machine Translation and Parsing in Indian Languages, chapter Two-stage Approach for Hindi Dependency
Parsing Using MaltParser, pages 163?170. The COLING 2012 Organizing Committee.
Yamuna Kachru. 2006. Hindi, volume 12. John Benjamins Publishing.
Vilson J Leffa. 1998. Clause processing in complex sentences. In Proceedings of the First International Confer-
ence on Language Resources and Evaluation, volume 1, pages 937?943.
28
M. Palmer, R. Bhatt, B. Narasimhan, O. Rambow, D.M. Sharma, and F. Xia. 2009. Hindi Syntax: Annotating
Dependency, Lexical Predicate-Argument Structure, and Phrase Structure. In The 7th International Conference
on Natural Language Processing, pages 14?17.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation
of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics,
pages 311?318. Association for Computational Linguistics.
C Poornima, V Dhanalakshmi, Anand M Kumar, and KP Soman. 2011. Rule based sentence simplification for
english to tamil machine translation system. International Journal of Computer Applications, 25(8):38?42.
Rahul Sharma, Soma Paul, Riyaz Ahmad Bhat, and Sambhav Jain. 2013. Automatic clause boundary annotation
in the hindi treebank.
Advaith Siddharthan. 2002. An architecture for a text simplification system. In Language Engineering Confer-
ence, 2002. Proceedings, pages 64?71. IEEE.
Advaith Siddharthan. 2006. Syntactic simplification and text cohesion. Research on Language and Computation,
4(1):77?109.
Ankush Soni, Sambhav Jain, and Dipti Misra Sharma. 2013. Exploring verb frames for sentence simplification in
hindi. Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1082?
1086. Asian Federation of Natural Language Processing.
Lucia Specia. 2010. Translating from complex to simplified sentences. In Computational Processing of the
Portuguese Language, pages 30?39. Springer.
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, Tsutomu Hirao, and Masaaki Nagata. 2010. Divide and translate:
improving long distance reordering in statistical machine translation. In Proceedings of the Joint Fifth Work-
shop on Statistical Machine Translation and MetricsMATR, pages 418?427. Association for Computational
Linguistics.
29
