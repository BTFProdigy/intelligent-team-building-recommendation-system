Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 223?229,
Dublin, Ireland, August 23-24, 2014.
DCU: Aspect-based Polarity Classification for SemEval Task 4
Joachim Wagner, Piyush Arora, Santiago Cortes, Utsab Barman
Dasha Bogdanova, Jennifer Foster and Lamia Tounsi
CNGL Centre for Global Intelligent Content
National Centre for Language Technology
School of Computing
Dublin City University
Dublin, Ireland
{jwagner,parora,scortes,ubarman}@computing.dcu.ie
{dbogdanova,jfoster,ltounsi}@computing.dcu.ie
Abstract
We describe the work carried out by DCU
on the Aspect Based Sentiment Analysis
task at SemEval 2014. Our team submit-
ted one constrained run for the restaurant
domain and one for the laptop domain for
sub-task B (aspect term polarity predic-
tion), ranking highest out of 36 systems on
the restaurant test set and joint highest out
of 32 systems on the laptop test set.
1 Introduction
This paper describes DCU?s participation in the
Aspect Term Polarity sub-task of the Aspect Based
Sentiment Analysis task at SemEval 2014, which
focuses on predicting the sentiment polarity of as-
pect terms for a restaurant and a laptop dataset.
Given, for example, the sentence I have had so
many problems with the computer and the aspect
term the computer, the task is to predict whether
the sentiment expressed towards the aspect term is
positive, negative, neutral or conflict.
Our polarity classification system uses super-
vised machine learning with support vector ma-
chines (SVM) (Boser et al., 1992) to classify an
aspect term into one of the four classes. The fea-
tures we employ are word n-grams (with n rang-
ing from 1 to 5) in a window around the aspect
term, as well as features derived from scores as-
signed by a sentiment lexicon. Furthermore, to
reduce data sparsity, we experiment with replacing
sentiment-bearing words in our n-gram feature set
with their polarity scores according to the lexicon
and/or their part-of-speech tag.
This work is licensed under a Creative Commons Attribution
4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http:
//creativecommons.org/licenses/by/4.0/
The paper is organised as follows: in Section 2,
we describe the sentiment lexicons used in this
work and detail the process by which they are
combined, filtered and extended; in Section 3, we
describe our baseline method, a heuristic approach
which makes use of the sentiment lexicon, fol-
lowed by our machine learning method which in-
corporates the rule-based method as features in ad-
dition to word n-gram features; in Section 4, we
present the results of both methods on the training
and test data, and perform an error analysis on the
test set; in Section 5, we compare our approach to
previous research in sentiment classification; Sec-
tion 6 discusses efficiency of our system and on-
going work to improve its speed; finally, in Sec-
tion 7, we conclude and provide suggestions as to
how this research could be fruitfully extended.
2 Sentiment Lexicons
The following four lexicons are employed:
1. MPQA
1
(Wilson et al., 2005) classifies a
word or a stem and its part of speech tag
into positive, negative, both or neutral with
a strong or weak subjectivity.
2. SentiWordNet
2
(Baccianella et al., 2010)
specifies the positive, negative and objective
scores of a synset and its part of speech tag.
3. General Inquirer
3
indicates whether a word
expresses positive or negative sentiment.
4. Bing Liu?s Opinion Lexicon
4
(Hu and Liu,
1
http://mpqa.cs.pitt.edu/lexicons/
subj_lexicon/
2
http://sentiwordnet.isti.cnr.it/
3
http://www.wjh.harvard.edu/
?
inquirer/
inqtabs.txt
4
http://www.cs.uic.edu/
?
liub/FBS/
sentiment-analysis.html#lexicon
223
2004) indicates whether a word expresses
positive or negative sentiment.
2.1 Lexicon Combination
Since the four lexicons differ in their level of detail
and in how they present information, it is neces-
sary, when combining them, to consolidate the in-
formation and present it in a uniform manner. Our
combination strategy assigns a sentiment score to
a word as follows:
? MPQA: 1 for strong positive subjectivity, -1
for strong negative subjectivity, 0.5 for weak
positive subjectivity, -0.5 for weak negative
subjectivity, and 0 otherwise
? SentiWordNet: The positive score if the pos-
itive score is greater than the negative and ob-
jective scores, the negative score if the nega-
tive score is greater than the positive and the
objective scores, and 0 otherwise
? General Inquirer and Bing Liu?s Opinion
Lexicon: 1 for positive and -1 for negative
The above four scores are summed to arrive at a
final score between -4 and 4 for a word.
5
2.2 Lexicon Filtering
Initial experiments with our sentiment lexicon and
the training data led us to believe that there were
many irrelevant entries that, although capable of
conveying sentiment in some other context, were
not contributing to the sentiment of aspect terms
in the two domains of the task. Therefore, these
words are manually filtered from the lexicon. Ex-
amples of deleted words are just, clearly, indi-
rectly, really and back.
2.3 Adding Domain-Specific Words
A manual inspection of the training data revealed
words missing from the merged sentiment lexicon
but which do express sentiment in these domains.
Examples are mouthwatering, watery and better-
configured. We add these to the lexicon with a
score of either 1 or -1 (depending on their polarity
in the training data). We also add words (e.g. zesty,
acrid) from an online list of culinary terms.
6
5
We also tried to vote over the four lexicon scores but this
did not improve over summing.
6
http://world-food-and-wine.com/
describing-food
2.4 Handling Variation
In order to ensure that all inflected forms of a
word are covered, we lemmatise the words in the
training data using the IMS TreeTagger (Schmid,
1994) and we construct new possibilities using a
suffix list. To correct misspelled words, we con-
sider the corrected form of a misspelled word to be
the form with the highest frequency in a reference
corpus
7
among all the forms within an edit dis-
tance of 1 and 2 from the misspelled word (Norvig,
2012). Multi-word expressions of the form x-y
are added with the polarity of xy or x, as in laid-
back/laidback and well-shaped/well. Expressions
x y, are added with the polarity of x-y, as in so
so/so-so.
3 Methodology
We first build a rule-based system which classi-
fies the polarity of an aspect term based solely on
the scores assigned by the sentiment lexicon. We
then explore different ways of converting the rule-
based system into features which can then be com-
bined with bag-of-n-gram features in a supervised
machine learning set-up.
3.1 Rule-Based Approach
In order to predict the polarity of an aspect term,
we sum the polarity scores of all the words in the
surrounding sentence according to our sentiment
lexicon. Since not all the sentiment words occur-
ring in a sentence influence the polarity of the as-
pect term to the same extent, it is important to
weight the score of each sentiment word by its dis-
tance to the aspect term. Therefore, for each word
in the sentence which is found in our lexicon we
take the score from the lexicon and divide it by its
distance to the aspect term. The distance is calcu-
lated using the sum of the following three distance
functions:
? Token Distance: This function calculates the
difference in the position of the sentiment
word and the aspect term by counting the to-
kens between them.
7
The reference corpus consists of about a million
words retrieved from several public domain books from
Project Gutenberg (http://www.gutenberg.org/),
lists of most frequent words from Wiktionary (http:
//en.wiktionary.org/wiki/Wiktionary:
Frequency_lists) and the British National Corpus
(http://www.kilgarriff.co.uk/bnc-readme.
html) and two thousand laptop reviews crawled from CNET
(http://www.cnet.com/).
224
? Discourse Chunk Distance: This function
counts the discourse chunks that must be
crossed in order to get from the sentiment
word to the aspect term. If the sentiment
word and the aspect term are in the same
discourse chunk, then the distance is zero.
We use the discourse segmenter described in
(Tofiloski et al., 2009).
? Dependency Path Distance: This function
calculates the shortest path between the sen-
timent word and the aspect term in a syntac-
tic dependency graph for the sentence, pro-
duced by parsing the sentence with a PCFG-
LA parser (Attia et al., 2010) trained on con-
sumer review data (Le Roux et al., 2012)
8
,
and converting the resulting phrase-structure
tree into a dependency graph using the Stan-
ford converter (de Marneffe and Manning,
2008) (version 3.3.1).
Since our lexicon also contains multi-word ex-
pressions such as finger licking, we also look up
bigrams and trigrams from the input sentence in
our lexicon. Negation is handled by reversing the
polarity of sentiment words that appear within a
window of three words of the following negators:
not, n?t, no and never.
For each aspect term, we use the distance-
weighted sum of the polarity scores to predict one
of the three classes positive, negative and neutral.
9
After experimenting with various thresholds we
settled on the following simple strategy: if the po-
larity score for an aspect term is greater than zero
then it is classified as positive, if the score is less
than zero, then it is classified as negative, other-
wise it is classified as neutral.
3.2 Machine Learning Approach
We train a four-way SVM classifier for each do-
main (laptop and restaurant), using Weka?s SMO
implementation (Platt, 1998; Hall et al., 2009).
10
8
To facilitate parsing, the data was normalised using the
process described in (Le Roux et al., 2012) with minor mod-
ifications, e. g. treatment of non-breakable space characters,
abbreviations and emoticons. The normalised version of the
data was used for all experiments.
9
We also experimented with classifying aspect terms as
conflict when the individual scores for positive and negative
sentiment were both relatively high. However, this proved
unsuccessful.
10
We also experimented with logistic regression, random
forests, k-nearest neighbour, naive Bayes and multi-layer per-
ceptron in Weka, but did not match performance of an SVM
trained with default parameters.
Transf. n c n-gram Freq.
-L? 2 2 cord with 1
AL? 2 2 <aspect> with 56
ALS? 1 4 <negu080> 595
ALSR- 1 4 <negu080> 502
AL? 2 4 and skip 1
ALSR- 2 4 and <negu080> 25
ALSRP 1 4 <negu080>/vb 308
Table 1: 7 of the 2,640 bag-of-n-gram features
extracted for the aspect term cord from the lap-
top training sentence I charge it at night and skip
taking the cord with me because of the good bat-
tery life. The last column shows the frequency of
the feature in the training data. Transformations:
A=aspect, L=lowercase, S=score, R=restricted to
certain POS, P=POS annotation
Our system submission uses bag-of-n-gram fea-
tures and features derived from the rule-based ap-
proach. Decisions about parameters are made in 5-
fold cross-validation on the training data provided
for the task.
3.2.1 Bag-of-N-gram Features
We extract features encoding the presence of spe-
cific lower-cased n-grams (L) (n = 1, ..., 5) in
the context of the aspect term to be classified (c
words to the left and c words to the right with
c = 1, ..., 5, inf) for 10 combinations of trans-
formations: replacement of the aspect term with
<ASPECT> (A), replacement of sentiment words
with a discretised score (S), restriction (R) of the
sentiment word replacement to certain parts-of-
speech, and annotation of the discretised score
with the POS (P) of the sentiment word. An ex-
ample is shown in Table 1.
3.2.2 Adding Rule-Based Score Features
We explore two approaches for incorporating in-
formation from the rule-based approach (Sec-
tion 3.1) into our SVM classifier. The first ap-
proach is to encode polarity scores directly as the
following four features:
1. distance-weighted sum of scores of positive
words in the sentence
2. distance-weighted sum of scores of negative
words in the sentence
3. number of positive words in the sentence
225
4. number of negative words in the sentence
The second approach is less direct: for each do-
main, we train J48 decision trees with minimum
leaf size 60 using the four rule-based features de-
scribed above. We then use the decision rules
and the conjunctions leading from the root node
to each leaf node to binarise the above four basic
score features, producing 122 features. Further-
more, we add normalised absolute values, rank of
values and interval indicators, producing 48 fea-
tures.
3.2.3 Submitted Runs
We eliminate features that have redundant value
columns for the training data, and we apply fre-
quency thresholds (13, 18, 25 and 35) to further
reduce the number of features. We perform a grid-
search to optimise the parameters C and ? of the
SVM RBF kernel. We choose the system to sub-
mit based on average cross-validation accuracy.
We experiment with combinations of the three fea-
ture sets described above. We choose the bina-
rised features over the raw rule-based scores be-
cause cross-validation results are inferior for the
rule-based scores in initial experiments with fea-
ture frequency threshold 35: 70.26 vs. 71.36 for
laptop and 72.06 vs. 72.15 for restaurant. There-
fore, we decide to focus on systems with binarised
score features for lower feature frequency thresh-
olds, which are more CPU-intensive to train. For
both domains, the system we end up submitting
is a combination of the n-gram features and the
binarised features with parameters C = 3.981,
? = 0.003311 for the laptop data, C = 1.445,
? = 0.003311 for the restaurant data, and a fre-
quency threshold of 13.
4 Results and Analysis
Table 2 shows the training and test accuracy of
the task baseline system (Pontiki et al., 2014), a
majority baseline classifying everything as posi-
tive, our rule-based system and our submitted sys-
tem. The restaurant domain has a higher accuracy
than the laptop domain for all systems, the SVM
system outperforms the rule-based system on both
domains, and the test accuracy is higher than the
training accuracy for all systems in the restaurant
domain.
We observe that the majority of our systems? er-
rors fall into the following categories:
Dataset System Training Test
Laptop Baseline ? 51.1%
Laptop All positive 41.9% 52.1%
Laptop Rule-based 65.4% 67.7%
Laptop SVM 72.3% 70.5%
Restaurant Baseline ? 64.3%
Restaurant All positive 58.6% 64.2%
Restaurant Rule-based 69.5% 77.8%
Restaurant SVM 72.7% 81.0%
Table 2: Accuracy of the task baseline system, a
system classifying everything as positive, our rule-
based system and our submitted SVM-based sys-
tem on train (5-fold cross-validation) and test sets
? Sentiment not expressed explicitly: The
sentiment cannot be inferred from local lexi-
cal and syntactic information, e. g. The sushi
is cut in blocks bigger than my cell phone.
? Non-obvious expression of negation: For
example, The Management was less than ac-
comodating [sic]. The rule-based approach
does not capture such cases and there are
not enough similar training examples for the
SVM to learn to correctly classify them.
? Conflict cases: The training data contains
too few examples of conflict sentences for the
system to learn to detect them.
11
For the restaurant domain, there are more than
fifty cases where the rule-based approach fails to
detect sentiment, but the machine learning ap-
proach classifies it correctly. Most of these cases
contain no sentiment lexicon words, thus the rule-
based system marks them as being neutral. How-
ever, the machine learning system was able to fig-
ure out the correct polarity. Examples of such
cases include Try the rose roll (not on menu) and
The gnocchi literally melts in your mouth!. Fur-
thermore, in the laptop domain, a number of the
errors made by the rule-based system arise from
the ambiguous nature of some lexicon words. For
example, the sentence Only 2 usb ports ... seems
kind of ... limited is misclassified because the
word kind is considered to be positive.
There are a few cases where the rule-based sys-
tem outperforms the machine learning one. It hap-
pens when a sentence contains a rare word with
strong polarity, e. g. the word heavenly in The
11
We only classify one test instance as conflict.
226
chocolate raspberry cake is heavenly - not too
sweet, but full of flavor.
5 Related Work
The use of supervised machine learning with bag-
of-word or bag-of-n-gram feature sets has been
a standard approach to the problem of sentiment
polarity classification since the seminal work by
Pang et al. (2002) on movie review polarity pre-
diction. Heuristic methods which rely on a lexi-
con of sentiment words have also been widespread
and much of the research in this area has been
devoted to the unsupervised induction of good
quality sentiment indicators (see, for example,
Hatzivassiloglou and McKeown (1997) and Tur-
ney (2002), and Liu (2010) for an overview). The
integration of sentiment lexicon scores as fea-
tures in supervised machine learning to supple-
ment standard bag-of-n-gram features has also
been employed before (see, for example, Bak-
liwal et al. (2013)). The replacement of train-
ing/test words with scores/labels from sentiment
lexicons has also been used by Baccianella et
al. (2009), who supplement n-grams such as hor-
rible location with generalised expressions such
as NEGATIVE location. Linguistic features which
capture generalisations at the level of syntax (Mat-
sumoto et al., 2005), semantics (Johansson and
Moschitti, 2010) and discourse (Lazaridou et al.,
2013) have also been widely applied. In using bi-
narised features derived from the nodes of a deci-
sion tree, we are following our recent work which
uses the same technique in a different task: quality
estimation for machine translation (Rubino et al.,
2012; Rubino et al., 2013).
The main novelty in our system lies not in the
individual techniques but rather in they way they
are combined and integrated. For example, our
combination of token/chunk/dependency path dis-
tance used to weight the relationship between a
sentiment word and the aspect term has ? to the
best of our knowledge ? not been applied before.
6 Efficiency
Building a system for a shared task, we focus
solely on the accuracy of the system in all our deci-
sions. For example, we parse all training and test
data multiple times using different grammars to
increase sentence coverage from 99.87% to 100%.
To offer a more practical system, we work on
implementing a simplified, fully automated sys-
tem that is more efficient. So far, we replaced
time-consuming parsing with POS tagging. The
system accepts as input and generates as output
valid SemEval ABSA XML documents.
12
After
extracting the text and the aspect terms from the
input, the text is normalised using the process de-
scribed in Footnote 8. The feature extraction is
performed as described in Section 3 with the fol-
lowing modifications:
? The POS information used by the n-gram
feature extractor is obtained using the IMS
TreeTagger (Schmid, 1994) instead of using
the PCFG-LA parser (Attia et al., 2010).
? The distance used by the rule-based approach
is the token distance only, instead of a com-
bination of three distance functions.
The sentiment lexicon and the classification mod-
els used are described in Sections 2 and 3 respec-
tively.
The test sets containing 800 sentences are POS
tagged in less than half a second each. Surpris-
ingly, accuracy of aspect term polarity prediction
increases to 71.4% (from 70.5% for the submitted
system) on the laptop test set, using the same SVM
parameters as for the submitted system. However,
we see a degradation to 78.8% (from 81.0% for the
submitted system) for the restaurant test set. This
is an encouraging result as the SVM parameters
are not yet fully optimised for the slightly different
information and as the remaining modifications to
be implemented should not change accuracy any
further.
The next bottleneck that needs to be addressed
before the system can be used in applications re-
quiring quick responses is the current implementa-
tion of the n-gram feature extractor: It enumerates
all n-grams (for all context window sizes and n-
gram transformations) only to then intersect these
features with the list of selected features. For the
shared task, this made sense as we initially need
all features to make our selection of features, and
as we only need to run the feature extractor a few
times. For a practical system that has to process
new test sets frequently, however, it will be more
efficient to check for each selected feature whether
the respective event occurs in the input.
12
We validate documents using the XML schema defini-
tion provided on the shared task website.
227
7 Conclusion
We have described our aspect term polarity predic-
tion system, which employs supervised machine
learning using a combination of n-grams and sen-
timent lexicon features. Although our submitted
system performs very well, it is interesting to note
that our rule-based system is not that far behind.
This suggests that a state-of-the-art system can be
build without machine learning and that careful
design of the other system components is impor-
tant. However, the very good performance of our
machine-learning-based system also suggests that
word n-gram features do provide useful informa-
tion that is missed by a sentiment lexicon alone,
and that it is always worthwhile to perform careful
parameter tuning to eke out as much as possible
from such an approach.
Future work should investigate how much each
system component contributes to the overall per-
formance, e. g. lexicon combination, lemmatisa-
tion, spelling correction, other normalisations,
negation handling, distance function and n-gram
feature transformations. There is also room for
improvements in most of these components, e. g.
our handling of complex negations. Detection of
conflicts also needs more attention. Features in-
dicating the presence of trigger words for negation
and conflicts that are currently used only internally
in the rule-based component could be added to the
SVM feature set. It would also be interesting to
see how the compositional approach described by
Socher et al. (2013) handles these difficult cases.
The score features could be easily augmented by
breaking down scores by the four employed lexi-
cons. This way, the SVM can choose to combine
the information from these scores differently than
just summing them, allowing it to learn more com-
plex relations. Lexicon filtering and addition of
domain-specific entries could be automated to re-
duce the time needed to adjust to a new domain.
Finally, machine learning methods that can effi-
ciently handle large feature sets such as logistic
regression should be tried with the full feature set
(not applying frequency thresholds).
Acknowledgements
This research is supported by the Science Foun-
dation Ireland (Grant 12/CE/I2267) as part of
CNGL (www.cngl.ie) at Dublin City University.
The authors wish to acknowledge the DJEI/DES/
SFI/HEA Irish Centre for High-End Computing
(ICHEC) for the provision of computational facil-
ities and support. We are grateful to Qun Liu and
Josef van Genabith for their helpful comments.
References
Mohammed Attia, Jennifer Foster, Deirdre Hogan,
Joseph Le Roux, Lamia Tounsi, and Josef van Gen-
abith. 2010. Handling unknown words in statis-
tical latent-variable parsing models for arabic, en-
glish and french. In Proceedings of the NAACL
HLT 2010 First Workshop on Statistical Parsing of
Morphologically-Rich Languages, pages 67?75.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2009. Multi-facet rating of product reviews.
In Proceedings of ECIR, pages 461?472.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SentiWordNet 3.0: An Enhanced Lex-
ical Resource for Sentiment Analysis and Opinion
Mining. In Proceedings of the Seventh Conference
on International Language Resources and Evalua-
tion (LREC?10).
Akshat Bakliwal, Jennifer Foster, Jennifer van der Puil,
Ron O?Brien, Lamia Tounsi, and Mark Hughes.
2013. Sentiment analysis of political tweets: To-
wards an accurate classifier. In Proceedings of the
NAACL Workshop on Language Analysis in Social
Media, pages 49?58.
Bernhard E. Boser, Isabelle M. Guyon, and
Vladimir N. Vapnik. 1992. A training algo-
rithm for optimal margin classifiers. In Proceedings
of the Fifth Annual Workshop on Computational
Learning Theory, pages 144?152.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The stanford typed dependencies rep-
resentation. In COLING 2008 Workshop on Cross-
framework and Cross-domain Parser Evaluation.,
pages 1?8.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an update.
ACM SIGKDD Explorations Newsletter, 11(1):10?
18.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the 35th Annual Meeting
of the ACL and the 8th Conference of the European
Chapter of the ACL, pages 174?181.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ?04, pages
168?177.
228
Richard Johansson and Alessandro Moschitti. 2010.
Syntactic and semantic structure for opinion ex-
pression detection. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning, pages 67?76.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A bayesian model for joint
unsupervised induction of sentiment, aspect and
discourse representations. In Proceedings of
the 51th Annual Meeting of the Association for
Computational Linguistics, pages 1630?1639.
Joseph Le Roux, Jennifer Foster, Joachim Wagner, Ra-
sul Samad Zadeh Kaljahi, and Anton Bryl. 2012.
DCU-Paris13 systems for the SANCL 2012 shared
task. Notes of the First Workshop on Syntactic
Analysis of Non-Canonical Language (SANCL).
Bing Liu. 2010. Sentiment analysis and subjectivity.
In Handbook of Natural Language Processing.
Shotaro Matsumoto, Hiroya Takamura, and Manubu
Okumura, 2005. Advances in Knowledge Discovery
and Data Mining, volume 3518 of Lecture Notes in
Computer Science, chapter Sentiment Classification
Using Word Sub-sequences and Dependency Sub-
trees, pages 301?311.
Peter Norvig. 2012. How to write a spelling corrector.
http://norvig.com/spell-correct.
html. [Online; accessed 2014-03-19].
Po Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification us-
ing machine learning techniques. In Proceedings of
EMNLP, pages 79?86.
John C. Platt. 1998. Fast training of support vec-
tor machines using sequential minimal optimization.
In B. Schoelkopf, C. Burges, and A. Smola, edi-
tors, Advances in Kernel Methods - Support Vector
Learning, pages 185?208.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect based sentiment analysis. In Proceedings of
the International Workshop on Semantic Evaluation
(SemEval).
Raphael Rubino, Jennifer Foster, Joachim Wagner, Jo-
hann Roturier, Rasul Samad Zadeh Kaljahi, and Fred
Hollowood. 2012. Dcu-symantec submission for
the wmt 2012 quality estimation task. In Proceed-
ings of the Seventh Workshop on Statistical Machine
Translation, pages 138?144.
Raphael Rubino, Joachim Wagner, Jennifer Foster, Jo-
hann Roturier, Rasoul Samad Zadeh Kaljahi, and
Fred Hollowood. 2013. DCU-Symantec at the
WMT 2013 quality estimation shared task. In Pro-
ceedings of the Eighth Workshop on Statistical Ma-
chine Translation, pages 392?397.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44?49.
Richard Socher, Alex Perelygin, Jean Y. Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of EMNLP, pages 1631?
1642.
Milan Tofiloski, Julian Brooke, and Maite Taboada.
2009. A syntactic and lexical-based discourse seg-
menter. In Proceedings of the ACL-IJCNLP 2009
Conference Short Papers, ACLShort ?09, pages 77?
80.
Peter Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised classi-
cation of reviews. In Proceedings of the ACL, pages
417?424.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the Con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
HLT ?05, pages 347?354.
229
Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 86?90,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Modelling Fixated Discourse in Chats with Cyberpedophiles
Dasha Bogdanova
University of
Saint Petersburg
dasha.bogdanova
@gmail.com
Paolo Rosso
NLE Lab. - ELiRF,
Univ. Polite?cnica de Valencia
prosso@dsic.upv.es
Thamar Solorio
University of
Alabama at Birmingham
solorio@cis.uab.edu
Abstract
The ability to detect deceptive statements in
predatory communications can help in the iden-
tification of sexual predators, a type of deception
that is recently attracting the attention of the re-
search community. Due to the intention of a pe-
dophile of hiding his/her true identity (name, age,
gender and location) its detection is a challenge.
According to previous research, fixated discourse
is one of the main characteristics inherent to the
language of online sexual predation. In this pa-
per we approach this problem by computing sex-
related lexical chains spanning over the conversa-
tion. Our study shows a considerable variation in
the length of sex-related lexical chains according
to the nature of the corpus, which supports our
belief that this could be a valuable feature in an
automated pedophile detection system.
1 Introduction
Child sexual abuse is not a rare problem. The statisti-
cal analysis by the National Incident-Based Reporting
System data (FBI, 1995) revealed that in the majority
of all sexual assaults (67%) the victims were under-
age (Snyder, 2000). Child sexual abuse and pedophilia
are related to each other and both are of great social
concern. On the one hand, law enforcement is work-
ing on prosecuting and preventing child sexual abuse.
On the other hand, psychologists and mental special-
ists are investigating the phenomenon of pedophilia.
Even though pedophilia has been studied from differ-
ent research perspectives, it remains to be a very im-
portant problem that requires further research.
The widespread availability of the Internet, and the
anonymity enabled by it has brought about new forms
of crime. According to the research conducted by
Mitchell (2001), 19% of children have been sexually
approached over the Internet. However, only 10% of
such cases were reported to the police. Attempts to so-
licit children have become common in chat rooms, but
manual monitoring of each conversation is impossible,
due to the massive amount of data and privacy issues.
Therefore, development of reliable tools for detecting
pedophilia in social media is of great importance.
Another related issue is that Internet makes it very
easy to provide false personal information. There-
fore, many online sexual predators create false profiles
where they hide their identity and age. Thus, detec-
tion of online sexual predation also involves age and
gender detection in chats.
From the Natural Language Processing (NLP) per-
spective, there are additional challenges to this prob-
lem because of the chat data specificity. Chat conver-
sations are very different, not only from the written
text, but also from other types of Internet communi-
cation, such as blogs and forums. Since online chat-
ting usually involves very fast typing, mistakes, mis-
spellings, and abbreviations occur frequently in chats.
Moreover, specific slang (e.g. ?kewl? is used instead
of ?cool? and ?asl? stands for ?age/sex/location?) and
character flooding (e.g. greeeeeat!) are used. There-
fore, modern NLP tools often fail to provide accurate
processing of chat language.
Previous research on cyberpedophiles reports that
they often copy juveniles? behavior (Egan et al, 2011),
in particular, they often use colloquialisms and emoti-
cons. Other important characteristics reported previ-
ously include the unwillingness of the predator to step
out of the sex-related conversation, even if the poten-
tial victim wants to change the topic. This is called
fixated discourse (Egan et al, 2011). In this paper
we present preliminary experiments on modelling this
phenomenon. To approach the problem we apply lex-
ical chaining techniques. The experiments show the
difference in the length of sex-related lexical chains
between different datasets. We believe this fact could
be then utilized in detecting pedophiles.
The following section overviews related work on the
topic. Section 3 briefly describes previous research
on pedophiles, the language of online sexual preda-
tion and the fixated discourse phenomenon in partic-
ular. Our approach to modelling fixated discourse is
presented in Section 4. We describe the data set used
in the experiments in Section 5, followed by prelim-
inary experiments presented in Section 6. We finally
draw some conclusions and plans for future work in
Section 7.
86
2 Related Work
The problem of detecting pedophiles in social media
is difficult and relatively novel. New ways of meet-
ing new friends are offered: chatting with webcam
(http://chatroulette.com/) or picking another user at
random and let you have a one-on-one chat with each
other (http://omegle.com/) in a completely anonymous
way.
Some chat conversations with online sexual preda-
tors are available at www.perverted-justice.com. The
site is run by adult volunteers who enter chat rooms
as juveniles (usually 12-15 year old) and if they are
sexually solicited by adults, they work with the po-
lice to prosecute this. Related to the problem of pe-
dophile detection in social media, a study of Perverted
Justice Foundation revealed that since 2007, they have
been working on identifying sex offenders on Myspace
and in 2008, they expanded that effort to Facebook.
The results are sadly staggering in terms of sex of-
fenders that have misused the two social media: Mys-
pace (period 2007- 2010) and Facebook (2008-2010)
deleted respectively 10,746 and 2,800 known sex of-
fenders. Although both social media have been helpful
and responsive towards removing danger users from
their communities, an automatic identification of sex
offenders would certainly help and make the process
faster.
Only few attempts to automatic detection of on-
line sexual predation have been done. Pendar (2007)
proved that it is possible to distinguish between preda-
tor and pseudo-victim with quite high accuracy. The
experiments were conducted on perverted-justice data.
The authors used a kNN classifier to distinguish be-
tween lines written by predators and the lines posted
by pseudo-victims. As features they used word uni-
grams, bigrams and trigrams.
Another attempt has been done by McGhee et al
(2011). They manually annotated the chat lines from
perverted-justice.com with the following labels:
1. Exchange of personal information
2. Grooming
3. Approach
4. None of the above listed classes
In order to distinguish between these types of lines
they used both a rule-based and a machine learn-
ing (kNN) classification approach. Their experiments
showed that the machine learning approach provides
better results and achieves up to 83% accuracy.
Another research work closely related to detection
of cyberpedophilia has been carried by Peersman et
al. (?). As it was already mentioned, pedophiles often
create false profiles and pretend to be younger or of
another gender. Moreover, they try to copy children?s
behaviour. Therefore, there is a need to detect age and
gender in chat conversation. Peersman et al (?) have
analyzed chats from Belgium Netlog social network.
Discrimination between those who are older than 16
from those who are younger based on Support Vector
Machine classification yields 71.3% accuracy. The ac-
curacy is even higher with increasing the gap between
the age groups (e.g. the accuracy of classifying those
who are less than 16 from those who are older than
25 is 88.2%). They have also investigated the issues of
the minimum required dataset. Their experiments have
shown that with 50% of the original dataset the accu-
racy remains almost the same and with only 10% it is
still much better than random baseline performance.
3 Profiling the Pedophile
Pedophilia is a ?disorder of adult personality and be-
haviour? which is characterized by sexual interest in
prepubescent children (International statistical classifi-
cation of diseases and related health problems, 1988).
Even though solicitation of children is not a medi-
cal diagnosis, Abel and Harlow (2001) reported that
88% of child sexual abuse cases are committed by pe-
dophiles. Therefore, we believe that understanding be-
haviour of pedophiles could help detecting and pre-
venting online sexual predation. Even though online
sexual offender is not always a pedophile, in this paper
we use these terms as synonyms.
3.1 Predator?s Linguistic Behavior
The language sexual offenders use was analyzed by
Egan et al (2011). The authors considered the chats
published at www.perverted-justice.com. The analysis
of the chats revealed several characteristics of preda-
tors? language:
? Fixated discourse. Predators impose a sex-related
topic on the conversation and dismiss attempts
from the pseudo-victim to switch topics.
? Implicit/explicit content. On the one hand, preda-
tors shift gradually to the sexual conversation,
starting with more ordinary compliments. On the
other hand, conversation then becomes overtly re-
lated to sex. They do not hide their intentions.
? Offenders often understand that what they are do-
ing is not moral.
? They transfer responsibility to the victim.
? Predators often behave as children, copying the
language: colloquialisms often appear in their
messages.
? They try to minimize the risk of being prosecuted:
they ask to delete chat logs and warn victims not
to tell anyone about the talk, though they finally
stop being cautious and insist on meeting offline.
87
In this paper we consider only the first charac-
teristic: fixated discourse. The conversation below,
taken from perverted-justice.com, illustrates fixated
discourse: the predator almost ignores what the victim
says and comes back to the sex-related conversation:
Predator: licking dont hurt
Predator: its like u lick ice cream
Pseudo-victim: do u care that im 13 in march
and not yet? i lied a little bit b4
Predator: its all cool
Predator: i can lick hard
4 Our Approach
We believe that lexical chains are appropriate to model
the fixated discourse of the predators chats.
4.1 Lexical Chains
A lexical chain is a sequence of semantically related
terms (Morris and Hirst, 1991). It has applications
in many tasks including Word Sense Disambiguation
(WSD) (Galley and McKeown, 2003) and Text Sum-
marization (Barzilay and Elhadad, 1997).
To estimate semantic similarity we used
two metrics: the similarity of Leacock and
Chodorow (Leacock and Chodorow, 2003), and that
of Resnik (Resnik, 1995). Leacock and Chodorow?s
semantic similarity measure is defined as:
SimL&Ch(c1, c2) = ?log
length(c1, c2)
2 ? depth
where length(c1, c2) is the length of the shortest path
between the concepts c1 and c2 and depth is depth of
the taxonomy.
The semantic similarity measure that was proposed
by Resnik (Resnik, 1995) relies on the Information
Content concept:
IC(c) = ?logP (c)
where P(c) is the probability of encountering the
concept c in a large corpus. Thus, Resnik?s similarity
measure is defined as follows:
SimResnik(c1, c2) = IC(lcs(c1, c2))
where lcs(c1, c2) is the least common subsumer of
c1 and c2.
4.2 Modelling Fixated Discourse
To model the fixated discourse phenomenon, we esti-
mate the length of the longest sex-related lexical chain
in a text. In particular, we start the construction of a
chain with an anchor word ?sex? in the first WordNet
meaning: ?sexual activity, sexual practice, sex, sex ac-
tivity (activities associated with sexual intercourse)?.
Then we continue the chain construction process until
the end of the text. We compare the relative lengths (in
percentage to the total number of words) of the con-
structed chains: we believe that the presence of a long
sex-related lexical chain in a text indicates fixated dis-
course.
5 Data
Pendar (2007) has summarized the possible types of
chat interactions with sexually explicit content:
1. Predator/Other
(a) Predator/Victim (victim is underage)
(b) Predator/Volunteer posing as a children
(c) Predator/Law enforcement officer posing as
a child
2. Adult/Adult (consensual relationship)
The most interesting from our research point of view
is data of the type 1(a), but obtaining such data is not
easy. However, the data of type 1(b) is freely avail-
able at the web site www.perverted-justice.com (PJ).
For our study, we have extracted chat logs from the
perverted-justice website. Since the victim is not real,
we considered only the chat lines written by predators.
As the negative dataset, we need data of type 2.
Therefore, we have downloaded cybersex chat logs
available at www.oocities.org/urgrl21f/. The archive
contains 34 one-on-one cybersex logs. We have sep-
arated lines of different authors, thereby obtaining 68
files.
We have also used a subset of the NPS chat cor-
pus (Forsythand and Martell, 2007), though it is not
of type 2, we believe it will make a good comparison.
We have extracted chat lines only for those adult au-
thors who had more than 30 lines written. Finally the
NPS dataset consisted of 65 authors.
6 Experiments
We carried out preliminary experiments on estimating
the length of lexical chains with sexually related con-
tent in PJ chats, and compare our results with the cor-
pora described above. Our goal is to explore the fea-
sibility of including fixated discourse as a feature in
pedophile detection.
We used Java WordNet Similarity library (Hope,
2008), which is a Java implementation of Perl Word-
net:Similarity (Pedersen et al, 2008). The average
length of the longest lexical chains (with respect to the
total number of words in a document) found for dif-
ferent corpora are presented in Table 1 and Table 2.
As we expected, sex-related lexical chains in the NPS
corpus are much shorter regardless of the similarity
metric used. The chains in the cybersex corpus are
even longer than in PJ corpus. This is probably due
88
Threshold
0.5 0.7
mean st.dev. mean st.dev.
PJ 12.21 3.63 9.3 5.68
Cybersex 18.28 16.8 9.98 12.76
NPS 5.66 5.9 2.42 4.77
Table 1: Average length of the longest lexical chain (percent-
age in the total number of words) computed with Leacock
and Chodorow semantic similarity.
Threshold
0.5 0.7
mean st.dev. mean st.dev.
PJ 8.24 4.51 6.68 5.06
Cybersex 12.04 15.86 9.13 11.64
NPS 0.67 0.96 0.41 0.66
Table 2: Average length of the longest lexical chain (per-
centage in the total number of words) computed with Resnik
semantic similarity.
to the fact that whilst both corpora contain conver-
sations about sex, cyberpedophiles are switching to
this topic gradually, whereas cybersex logs are entirely
sex-related.
7 Conclusions and Future Work
Detection of online sexual predation is a problem of
great importance. In this small scale study we have
focused on modelling fixated discourse using lexical
chains as a potential feature in the automated detec-
tion of online sex predators. The preliminary experi-
ments revealed that the lengths of sex-related lexical
chains vary with the nature of the corpus, with the pe-
dophiles logs having longer lexical chains than chat
logs not related to sex, while the cybersex chat logs
had the longest sex-related lexical chains of the three
corpora.
As it was mentioned in Section 1, chat language
is very informal and has a lot of abbreviations, slang
words, mistakes etc. Hence a fair amount of words
used there do not appear in WordNet and, therefore,
can not be included into the lexical chains. For exam-
ple, the word ?ssex? is obviously related and should
appear in the chain, though because of the different
spelling it is not found in WordNet and, therefore, is
not included into the chain. We plan to add a normal-
ization step prior to computing lexical chains. We have
used only one anchor word (?sex?) to start the lexical
chain. But several other words could also be good can-
didate for this.
Fixated discourse is not only about keeping the sex-
ual topic throughout all the conversation, it is also
about unwillingness to step out of the sexual conver-
sation and ignoring victim?s attempts to do it. There-
fore, the chat lines of the pseudo-victim should be an-
Figure 1: Average length of lexical chains calculated with
Leacock and Chodorow semantic similarity
Figure 2: Average length of lexical chains calculated with
Resnik semantic similarity
alyzed as well in order to find out if there were failed
attempts to switch the topic. This may also help to dis-
tinguish predation from cybersex conversation, since
in the cybersex conversation both participants want to
follow the topic. However, during this preliminary ex-
periments we have not yet considered this. Moreover,
perverted-justice is run by volunteers posing as poten-
tial victims. It is then possible that the volunteers? be-
havior differ from the responses of real children (Egan
et al, 2011). Their goal is to build a legal case against
the pedophile and, therefore, they are more willing to
provoke the predator than to avoid sex-related conver-
sation.
Another way to distinguish cybersex fixed topic
from the predator?s unwillingness to step out of it is
could be to use emotion classification based on the
Leary Rose model proposed by Vaassen and Daele-
mans (Vaassen and Daelemans, 2011). Their approach
is based on Interpersonal Circumplex suggested by
Leary (Leary, 1957). This is a model of interpersonal
communication that reflects whether one of the par-
ticipants is dominant and whether the participants are
cooperative. It was already mentioned that cyberpe-
dophiles tend to be dominant. Therefore, we believe
that the Leary Rose model can be useful in detecting
online sexual predation.
89
Once the model of fixated discourse is improved,
we plan to use it as an additional feature to detect pe-
dophiles in social media.
Acknowledgements
The first author was partially supported by a Google
Research Award and by a scholarship from the Uni-
versity of St. Petersburg. The second author
was supported by WIQ-EI IRSES project (grant no.
269180) from the European Commission, within the
FP 7 Marie Curie People, the MICINN research
project TEXT-ENTERPRISE 2.0 TIN2009-13391-
C04-03(Plan I+D+i), and the VLC/CAMPUS Micro-
cluster on Multimodal Interaction in Intelligent Sys-
tems. The last author was partially supported by the
UPV program PAID-02-11, award no. 1932.
References
Gene G. Abel and Nora Harlow. The Abel and Harlow
child molestation prevention study. Philadelphia, Xlibris,
2001.
Regina Barzilay and Michael Elhadad. Using lexical chains
for text summarization. In Proceedings of the Intelligent
Scalable Text Summarization Workshop, 1997.
Vincent Egan, James Hoskinson, and David Shewan. Per-
verted justice: A content analysis of the language used by
offenders detected attempting to solicit children for sex.
Antisocial Behavior: Causes, Correlations and Treat-
ments, 2011.
Eric N Forsythand and Craig H Martell. Lexical and dis-
course analysis of online chat dialog. International Con-
ference on Semantic Computing ICSC 2007, pages 19?26,
2007.
Michel Galley and Kathleen McKeown. Improving word
sense disambiguation in lexical chaining. In Proceedings
of IJCAI-2003, 2003.
David Hope. Java wordnet similarity library.
http://www.cogs.susx.ac.uk/users/drh21.
Claudia Leacock and Martin Chodorow. C-rater: Automated
scoring of short-answer questions. Computers and the
Humanities, 37(4):389?405, 2003.
Timothy Leary. Interpersonal diagnosis of personality; a
functional theory and methodology for personality evalu-
ation. Oxford, England: Ronald Press, 1957.
India McGhee, Jennifer Bayzick, April Kontostathis, Lynne
Edwards, Alexandra McBride and Emma Jakubowski.
Learning to identify Internet sexual predation. Interna-
tional Journal on Electronic Commerce 2011.
Kimberly J. Mitchell, David Finkelhor, and Janis Wolak.
Risk factors for and impact of online sexual solicitation
of youth. Journal of the American Medical Association,
285:3011?3014, 2001.
Jane Morris and Graeme Hirst. Lexical cohesion computed
by thesaural relations as an indicator of the structure of
text. Computational Linguistics, 17(1):21?43, 1991.
Federal Bureau of Investigation. Nibrs flatfile tape master
record descriptions. 1995.
Ted Pedersen, Siddharth Patwardhan, Jason Michelizzi,
and Satanjeev Banerjee. Wordnet:similarity. http://wn-
similarity.sourceforge.net/.
Nick Pendar. Toward spotting the pedophile: Telling vic-
tim from predator in text chats. pages 235?241, Irvine,
California, 2007.
Philip Resnik. Using information content to evaluate seman-
tic similarity in a taxonomy. In IJCAI, pages 448?453,
1995.
Howard N. Snyder. Sexual assault of young children as re-
ported to law enforcement: Victim, incident, and offender
characteristics. a nibrs statistical report. Bureau of Justice
Statistics Clearinghouse, 2000.
Frederik Vaassen and Walter Daelemans. Automatic emo-
tion classification for interpersonal communication. In
Proceedings of the 2nd Workshop on Computational Ap-
proaches to Subjectivity and Sentiment Analysis (WASSA
2.011), pages 104?110. Association for Computational
Linguistics, 2011.
World health organization, international statistical classi-
fication of diseases and related health problems: Icd-10
section f65.4: Paedophilia. 1988.
90
Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 110?118,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
On the Impact of Sentiment and Emotion Based Features in
Detecting Online Sexual Predators
Dasha Bogdanova
University of
Saint Petersburg
dasha.bogdanova
@gmail.com
Paolo Rosso
NLE Lab - ELiRF
Universitat
Polite`cnica de Vale`ncia
prosso@dsic.upv.es
Thamar Solorio
CoRAL Lab
University of
Alabama at Birmingham
solorio@cis.uab.edu
Abstract
According to previous work on pedophile psy-
chology and cyberpedophilia, sentiments and
emotions in texts could be a good clue to de-
tect online sexual predation. In this paper, we
have suggested a list of high-level features, in-
cluding sentiment and emotion based ones, for
detection of online sexual predation. In partic-
ular, since pedophiles are known to be emo-
tionally unstable, we were interested in inves-
tigating if emotion-based features could help
in their detection. We have used a corpus of
predators? chats with pseudo-victims down-
loaded from www.perverted-justice.com and
two negative datasets of different nature: cy-
bersex logs available online and the NPS chat
corpus. Naive Bayes classification based on
the proposed features achieves accuracies of
up to 94% while baseline systems of word and
character n-grams can only reach up to 72%.
1 Introduction
Child sexual abuse and pedophilia are both problems
of great social concern. On the one hand, law en-
forcement is working on prosecuting and preventing
child sexual abuse. On the other hand, psycholo-
gists and mental specialists are investigating the phe-
nomenon of pedophilia. Even though the pedophilia
has been studied from different research points, it re-
mains to be a very important problem which requires
further research, especially from the automatic de-
tection point of view.
Previous studies report that in the majority of
cases of sexual assaults the victims are under-
aged (Snyder, 2000). On the Internet, attempts
to solicit children have become common as well.
Mitchell (2001) found out that 19% of children have
been sexually approached online. However, manual
monitoring of each conversation is impossible, due
to the massive amount of data and privacy issues. A
good alternative is the development of reliable tools
for detecting pedophilia in online social media is of
great importance.
In this paper, we address the problem of detecting
pedophiles with natural language processing (NLP)
techniques. This problem becomes even more chal-
lenging because of the chat data specificity. Chat
conversations are very different not only from the
written text but also from other types of social media
interactions, such as blogs and forums, since chat-
ting in the Internet usually involves very fast typing.
The data usually contains a large amount of mis-
takes, misspellings, specific slang, character flood-
ing etc. Therefore, accurate processing of this data
with automated syntactic analyzers is rather chal-
lenging.
Previous research on pedophilia reports that the
expression of certain emotions in text could be help-
ful to detect pedophiles in social media (Egan et al,
2011). Following these insights we suggest a list
of features, including sentiments as well as other
content-based features. We investigate the impact
of these features on the problem of automatic detec-
tion of online sexual predation. Our experimental
results show that classification based on such fea-
tures discriminates pedophiles from non-pedophiles
with high accuracy.
The remainder of the paper is structured as fol-
lows: Section 2 overviews related work on the topic,
110
Section 3 outlines the profile of a pedophile based on
the previous research. Our approach to the problem
of detecting pedophiles in social media on the ba-
sis of high-level features is presented in Section 4.
Experimental data is described in Section 5. We
show the results of the conducted experiments in
Section 6; they are followed by discussion and plans
for future research in Section 7. We finally draw
some conclusions in Section 8.
2 Related Research
The problem of automatic detection of pedophiles
in social media has been rarely addressed so far. In
part, this is due to the difficulties involved in hav-
ing access to useful data. There is an American
foundation called Perverted Justice (PJ). It investi-
gates cases of online sexual predation: adult volun-
teers enter chat rooms as juveniles (usually 12-15
year old) and if they are sexually solicited by adults,
they work with the police to prosecute the offenders.
Some chat conversations with online sexual preda-
tors are available at www.perverted-justice.com and
they have been the subject of analysis of recent re-
search on this topic.
Pendar (2007) experimented with PJ data. He sep-
arated the lines written by pedophiles from those
written by pseudo-victims and used a kNN classi-
fier based on word n-grams to distinguish between
them.
Another related research has been carried out by
McGhee et al (2011). The chat lines from PJ were
manually classified into the following categories:
1. Exchange of personal information
2. Grooming
3. Approach
4. None of the listed above classes
Their experiments have shown that kNN classifi-
cation achieves up to 83% accuracy and outperforms
a rule-based approach.
As it was already mentioned, pedophiles often
create false profiles and pretend to be younger or
of another gender. Moreover, they try to copy
children?s behavior. Automatically detecting age
and gender in chat conversations could then be the
first step in detecting online predators. Peersman
et al (2011) have analyzed chats from the Bel-
gium Netlog social network. Discrimination be-
tween those who are older than 16 from those who
are younger based on a Support Vector Machine
classification yields 71.3% accuracy. The accuracy
is even higher when the age gap is increased (e.g.
the accuracy of classifying those who are less than
16 from those who are older than 25 is 88.2%). They
have also investigated the issues of the minimum
amount of training data needed. Their experiments
have shown that with 50% of the original dataset the
accuracy remains almost the same, and with only
10% it is still much better than the random baseline
performance.
NLP techniques were as well applied to capture
child sexual abuse data in P2P networks (Panchenko
et al, 2012). The proposed text classification system
is able to predict with high accuracy if a file contains
child pornography by analyzing its name and textual
description.
Our work neither aims at classification of chat
lines into categories as it was done by McGhee et
al. (2011) nor at discriminating between victim and
predator as it was done by Pendar (2007), but at dis-
tinguishing between pedophile?s and not pedophile?s
chats, in particular, by utilizing clues provided by
psychology and sentiment analysis.
3 Profiling the Pedophile
Pedophilia is a ?disorder of adult personality and be-
havior? which is characterized by sexual interest in
prepubescent children (International statistical clas-
sification of diseases and related health problems,
1988). Even though solicitation of children is not a
medical diagnosis, Abel and Harlow (2001) reported
that 88% of child sexual abuse cases are commit-
ted by pedophiles. Therefore, we believe that under-
standing behavior of pedophiles could help to detect
and prevent online sexual predation. Even though an
online sexual offender is not always a pedophile, in
this paper we use these terms as synonyms.
Previous research reports that about 94% of sex-
ual offenders are males. With respect to female sex-
ual molesters, it is reported, that they tend to be
young and, in these cases, men are often involved
as well (Vandiver and Kercher, 2004). Sexual as-
111
sault offenders are more often adults (77%), though
in 23% of cases children are solicited by other juve-
niles.
Analysis of pedophiles? personality characterizes
them with feelings of inferiority, isolation, lone-
liness, low self-esteem and emotional immaturity.
Moreover, 60%-80% of them suffer from other psy-
chiatric illnesses (Hall and Hall, 2007). In general,
pedophiles are less emotionally stable than mentally
healthy people.
3.1 Profile of the Online Sexual Predator
Hall and Hall (2007) noticed that five main types
of computer-based sexual offenders can be distin-
guished: (1) the stalkers, who approach children in
chat rooms in order to get physical access to them;
(2) the cruisers, who are interested in online sexual
molestation and not willing to meet children offline;
(3) the masturbators, who watch child pornography;
(4) the networkers or swappers, who trade informa-
tion, pornography, and children; and (5) a combi-
nation of the four types. In this study we are in-
terested in detecting stalkers (type (1)) and cruisers
(type (2)).
The language sexual offenders use was analyzed
by Egan et al (2011). The authors considered the
chats available from PJ. The analysis of the chats
revealed several characteristics of predators? lan-
guage:
? Implicit/explicit content. On the one hand,
predators shift gradually to the sexual conversa-
tion, starting with more ordinary compliments:
Predator: hey you are really cute
Predator: u are pretty
Predator: hi sexy
On the other hand, the conversa-
tion then becomes overtly related to
sex. They do not hide their intentions:
Predator: can we have sex?
Predator: you ok with sex with me and
drinking?
? Fixated discourse. Predators are not willing to
step aside from the sexual conversation. For
example, in this conversation the predator al-
most ignores the question of pseudo-victim and
comes back to the sex-related conversation:
Predator: licking dont hurt
Predator: its like u lick ice cream
Pseudo-victim: do u care that im 13 in
march and not yet? i lied a little bit b4
Predator: its all cool
Predator: i can lick hard
? Offenders often understand that what they are
doing is not moral:
Predator: i would help but its not moral
? They transfer responsibility to the victim:
Pseudo-victim: what ya wanta do when u
come over
Predator: whatever?movies, games, drink,
play around?it?s up to you?what would you
like to do?
Pseudo-victim: that all sounds good
Pseudo-victim: lol
Predator: maybe get some sexy pics of you
:-P
Predator: would you let me take pictures of
you? of you naked? of me and you playing?
:-D
? Predators often behave as children, copying
their linguistic style. Colloquialisms appear of-
ten in their messages:
Predator: howwwww dy
...
Predator: i know PITY MEEEE
? They try to minimize the risk of being prose-
cuted: they ask to delete chat logs and warn
victims not to tell anyone about the talk:
112
Predator: don?t tell anyone we have been
talking
Pseudo-victim: k
Pseudo-victim: lol who would i tell? no
one?s here.
Predator: well I want it to be our secret
? Though they finally stop being cautious and in-
sist on meeting offline:
Predator: well let me come see you
Pseudo-victim: why u want 2 come
over so bad?
Predator: i wanna see you
In general Egan et al (Egan et al, 2011) have
found online solicitation to be more direct, while in
real life children seduction is more deceitful.
4 Our Approach
We address the problem of automatic detection of
online sexual predation. While previous studies
were focused on classifying chat lines into differ-
ent categories (McGheeet al, 2011) or distinguish-
ing between offender and victim (Pendar, 2007), in
this work we address the problem of detecting sex-
ual predators.
We formulate the problem of detecting pedophiles
in social media as the task of binary text categoriza-
tion: given a text (a set of chat lines), the aim is to
predict whether it is a case of cyberpedophilia or not.
4.1 Features
On the basis of previous analysis of pedophiles? per-
sonality (described in previous section), we consider
as features those emotional markers that could un-
veil a certain degree of emotional instability, such
as feelings of inferiority, isolation, loneliness, low
self-esteem and emotional immaturity.
On the one hand, pedophiles try to be nice with a
victim and make compliments, at least in the begin-
ning of a conversation. Therefore, the use of posi-
tive words is expected. On the other hand, as it was
described earlier, pedophiles tend to be emotionally
unstable and prone to lose temper, hence they might
start using words expressing anger and negative lex-
icon. Other emotions can be as well a clue to detect
pedophiles. For example, offenders often demon-
strate fear, especially with respect to being prose-
cuted, and they often lose temper and express anger:
Pseudo-victim: u sad didnt car if im 13. now u car.
Predator: well, I am just scared about being in
trouble or going to jail
Pseudo-victim: u sad run away now u say no. i
gues i dont no what u doin
Predator: I got scared
Predator: we would get caugth sometime
In this example pseudo-victim is not answering:
Predator: hello
Predator: r u there
Predator:
Predator: thnx a lot
Predator: thanx a lot
Predator:
Predator: u just wast my time
Predator: drive down there
Predator: can u not im any more
Here the offender is angry because the pseudo-
victim did not call him:
Predator: u didnt call
Predator: i m angry with u
Therefore, we have decided to use markers of
basic emotions as features. At the SemEval 2007
task on ?Affective Text? (Strapparava and Mihal-
cea, 2007) the problem of fine-grained emotion an-
notation was defined: given a set of news titles,
the system is to label each title with the appropri-
ate emotion out of the following list: ANGER, DIS-
GUST, FEAR, JOY, SADNESS, SURPRISE. In this
research work we only use the percentages of the
markers of each emotion.
We have also borrowed several features from
McGhee et al (2011):
? Percentage of approach words. Approach
words include verbs such as come and meet and
such nouns as car and hotel.
? Percentage of relationship words. These words
refer to dating (e.g. boyfriend, date).
113
? Percentage of family words. These words are
the names of family members (e.g. mum, dad,
brother).
? Percentage of communicative desensitization
words. These are explicit sexual terms offend-
ers use in order to desensitize the victim (e.g.
penis, sex).
? Percentage of words expressing sharing infor-
mation. This implies sharing basic information,
such as age, gender and location, and sending
photos. The words include asl, pic.
Since pedophiles are known to be emotionally un-
stable and suffer from psychological problems, we
consider features reported to be helpful to detect
neuroticism level by Argamon et al (2009). In par-
ticular, the features include percentages of personal
and reflexive pronouns and modal obligation verbs
(have to, has to, had to, must, should, mustn?t, and
shouldn?t).
We consider the use of imperative sentences and
emoticons to capture the predators tendencies to
be dominant and copy childrens? behaviour respec-
tively.
The study of Egan et al (Egan et al, 2011) has
revealed several recurrent themes that appear in PJ
chats. Among them, fixated discourse: the unwill-
ingness of the predator to change the topic. In (Bog-
danova et al, 2012) we present experiments on mod-
eling the fixated discourse. We have constructed lex-
ical chains (Morris and Hirst, 1991) starting with
the anchor word ?sex? in the first WordNet mean-
ing: ?sexual activity, sexual practice, sex, sex activ-
ity (activities associated with sexual intercourse)?.
We have finally used as a feature the length of the
lexical chain constructed with the Resnik similarity
measure (Resnik, 1995) with the threshold = 0.7.
The full list of features is presented in Table 1.
5 Datasets
Pendar (2007) has summarized the possible types of
chat interactions with sexually explicit content:
1. Predator/Other
(a) Predator/Victim (victim is underaged)
(b) Predator/Volunteer posing as a children
(c) Predator/Law enforcement officer posing
as a child
2. Adult/Adult (consensual relationship)
The most interesting from our research point of
view is data of the type 1a, but obtaining such
data is not easy. However, the data of the type 1b
is freely available at the web site www.perverted-
justice.com. For our study, we have extracted chat
logs from the perverted-justice website. Since the
victim is not real, we considered only the chat lines
written by predators.
Since our goal is to distinguish sex related chat
conversations where one of the parties involved is a
pedophile, the ideal negative dataset would be chat
conversations of type 2 (consensual relations among
adults) and the PJ data will not meet this condition
for the negative instances. We need additional chat
logs to build the negative dataset. We used two neg-
ative datasets in our experiments: cybersex chat logs
and the NPS chat corpus.
We downloaded the cybersex chat logs available
at www.oocities.org/urgrl21f/. The archive contains
34 one-on-one cybersex logs. We have separated
lines of different authors, thereby obtaining 68 files.
We have also used the subset the of NPS chat cor-
pus (Forsythand and Martell, 2007), though it is not
of type 2. We have extracted chat lines only for those
adult authors who had more than 30 lines written.
Finally the dataset consisted of 65 authors. From
each dataset we have left 20 files for testing.
6 Experiments
To distinguish between predators and not predators
we used a Naive Bayes classifier, already success-
fully utilized for analyzing chats by previous re-
search (Lin, 2007). To extract positive and nega-
tive words, we used SentiWordNet (Baccianella et
al., 2010). The features borrowed from McGhee et
al. (2011), were detected with the list of words au-
thors made available for us. Imperative sentences
were detected as affirmative sentences starting with
verbs. Emoticons were captured with simple regular
expressions.
Our dataset is imbalanced, the majority of the chat
logs are from PJ. To make the experimental data
more balanced, we have created 5 subsets of PJ cor-
114
Feature Class Feature Example Resource
Emotional Positive Words cute, pretty SentiWordNet
Markers Negative Words dangerous, annoying (Baccianella et al, 2010)
JOY words happy, cheer WordNet-Affect
SADNESS words bored, sad (Strapparava and
ANGER words annoying, furious Valitutti, 2004)
SURPRISE words astonished, wonder
DISGUST words yucky, nausea
FEAR words scared, panic
Features borrowed Approach words meet, car McGhee et al (2011)
from McGhee Relationship nouns boyfriend, date
et al (2011) Family words mum, dad
Communicative desensitization words sex. penis
Information words asl, home
Features helpful Personal pronouns I, you Argamon et al (2009)
to detect Reflexive pronouns myself, yourself
neuroticism level Obligation verbs must, have to
Features derived Fixated Discourse see in Section 3.1 Bogdanova et al (2012)
from pedophile?s
psychological profile
Other Emoticons 8), :(
Imperative sentences Do it!
Table 1: Features used in the experiments.
pus, each of which contained chat lines from 60 ran-
domly selected predators.
For the cybersex logs, half of the chat sessions
belong to the same author. We used this author for
training, and the rest for testing, in order to prevent
the classification algorithm from learning to distin-
guish this author from pedophiles.
For comparison purposes, we experimented with
several baseline systems using low-level features
based on n-grams at the word and character level,
which were reported as useful features by related re-
search (Peersman et al, 2011). We trained naive
Bayes classifiers using word level unigrams, bi-
grams and trigrams. We also trained naive Bayes
classifiers using character level bigrams and tri-
grams.
The classification results are presented in Tables 2
and 3. The high-level features outperform all the
low-level ones in both the cybersex logs and the NPS
chat datasets and achieve 94% and 90% accuracy on
these datasets respectively.
Cybersex chat logs are data of type 2 (see previ-
ous section), they contain sexual content and, there-
fore, share same of the same vocabulary with the
perverted-justice data, whilst the NPS data gener-
ally is not sex-related. Therefore, we expected low-
level features to provide better results on the NPS
data. The experiments have shown that, except for
the character bigrams, all low-level features consid-
ered indeed work worse in case of cybersex logs
(see the average rows in both tables). The aver-
age accuracy in this case varies between 48% and
58%. Surprisingly, low-level features do not work
as good as we expected in case of the NPS chat
dataset: bag of words provides only 61% accuracy.
Among other low-level features, character trigrams
provide the highest accuracy of 72%, which is still
much lower than the one of the high-level features
(90%). The high-level features yield a lower accu-
racy (90% accuracy) on the PJ-NPS dataset than in
the case of PJ-cybersex logs (94% accuracy). This is
probably due to the data diversity: cybersex chat is
a very particular type of a conversation, though NPS
chat corpora can contain any type of conversations
up to sexual predation.
115
Accuracy
High-level Bag of Term Term Character Character
features words bigrams trigrams bigrams trigrams
Run 1 0.93 0.38 0.55 0.60 0.73 0.78
Run 2 0.95 0.40 0.50 0.53 0.75 0.45
Run 3 0.95 0.70 0.45 0.53 0.48 0.50
Run 4 0.98 0.43 0.53 0.53 0.50 0.38
Run 5 0.90 0.50 0.48 0.53 0.45 0.50
Average 0.94 0.48 0.50 0.54 0.58 0.52
Table 2: Results of Naive Bayes classification applied to perverted-justice data and cybersex chat logs.
Accuracy
High-level Bag of Term Term Character Character
features words bigrams trigrams bigrams trigrams
Run 1 0.93 0.73 0.60 0.60 0.68 0.75
Run 2 0.95 0.68 0.53 0.53 0.48 0.45
Run 3 0.95 0.58 0.53 0.53 0.48 0.85
Run 4 0.98 0.53 0.53 0.53 0.23 0.80
Run 5 0.90 0.53 0.53 0.53 0.25 0.75
Average 0.92 0.61 0.54 0.54 0.42 0.72
Table 3: Results of Naive Bayes classification applied to perverted-justice data and NPS chats.
7 Discussion and Future Work
We have conducted experiments on detecting pe-
dophiles in social media with a binary classification
algorithm. In the experiments we used two negative
datasets of different nature: the first one is more ap-
propriate, it contains one-on-one cybersex conversa-
tions, while the second dataset is extracted from the
NPS chat corpus and contains logs from chat rooms,
and, therefore, is less appropriate since the conver-
sations are not even one on one.
It is reasonable to expect that in the case of the
negative data consisting of cybersex logs, distin-
guishing cyberpedophiles is a harder task, than in the
case of the NPS data. The results obtained with the
baseline systems support this assumption: we obtain
higher accuracy for the NPS chats in all but character
bi-grams. The interesting insight from these results
is that our proposed higher-level features are able to
boost accuracy to 94% on the seemingly more chal-
lenging task.
Our error analysis showed that the NPS logs mis-
classified with the high-level features are also mis-
classified by the baseline systems. These instances
either share the same lexicon or are about the same
topics. Therefore they are more similar to cyberpe-
dophiles training data than the training data of the
NPS corpus, which is very diverse. These examples
are taken from misclassified NPS chat logs:
User: love me like a bomb baby come on get it on
...
User: ryaon so sexy
User: you are so anal
User: obviously i didn?t get it
User: just loosen up babe
...
User: i want to make love to him
User: right field wrong park lol j/k
User: not me i put them in the jail lol
User: or at least tell the cops where to go to get the
bad guys lol
In the future we plan to further investigate the
misclassified data. The feature extraction we have
implemented does not use any word sense disam-
biguation. This can as well cause mistakes since
the markers are not just lemmas but words in par-
ticular senses, since for example the lemma ?fit?
can be either a positive marker (?a fit candidate?)
or negative (?a fit of epilepsy?), depending on the
116
context. Therefore we plan to employ word sense
disambiguation techniques during the feature extrac-
tion phase.
So far we have only seen that the list of fea-
tures we have suggested provides good results.
They outperform all thelow-level features consid-
ered. Among those low-level features, character tri-
grams provide the best results on the NPS data (72%
accuracy), though on the cybersex logs they achieve
only 54%. We plan to merge low-level and high-
level features in order to see if this could improve
the results.
In the future we plan also to explore the impact of
each high-level feature. To better understand which
ones carry more discriminative power and if we can
reduce the number of features. All these experi-
ments will be done employing naive Bayes as well
as Support Vector Machines as classifiers.
8 Conclusions
This paper presents some results of an ongoing re-
search project on the detection of online sexual pre-
dation, a problem the research community is inter-
ested in, as the PAN task on Sexual Predator Identi-
fication1 suggests.
Following the clues given by psychological re-
search, we have suggested a list of high-level fea-
tures that should take into account the level of emo-
tional instability of pedophiles, as well as their feel-
ings of inferiority, isolation, loneliness, low self-
esteem etc. We have considered as well such low-
level features as character bigrams and trigrams and
word unigrams, bigrams and trigrams. The Naive
Bayes classification based on high-level features
achieves 90% and 94% accuracy when using NPS
chat corpus and the cybersex chat logs as a nega-
tive dataset respectively, whereas low-level features
achieve only 42%-72% and 48%-58% accuracy on
the same data.
Acknowledgements
The research of Dasha Bogdanova was carried out
during the 3-month internship at the Universitat
Polite`cnica de Vale`ncia (scholarship of the Univer-
sity of St.Petersburg). Her research was partially
1http://pan.webis.de/
supported by Google Research Award. The collab-
oration with Thamar Solorio was possible thanks
to her one-month research visit at the Universi-
tat Polite`cnica de Vale`ncia (program PAID-PAID-
02-11 award n. 1932). The research work of
Paolo Rosso was done in the framework of the Eu-
ropean Commission WIQ-EI IRSES project (grant
no. 269180) within the FP 7 Marie Curie People,
the MICINN research project TEXT-ENTERPRISE
2.0 TIN2009-13391-C04-03(Plan I+D+i), and the
VLC/CAMPUS Microcluster on Multimodal Inter-
action in Intelligent Systems.
References
Gene G. Abel and Nora Harlow. The Abel and Har-
low child molestation prevention study. Philadelphia,
Xlibris, 2001.
Shlomo Argamon, Moshe Koppel, James Pennebaker,
and Jonathan Schler. Automatically profiling the au-
thor of an anonymous text. Communications of the
ACM, 52 (2):119?123, 2009.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. Sentiwordnet 3.0: An enhanced lexical resource
for sentiment analysis and opinion mining. the Sev-
enth International conference on Language Resources
and Evaluation, 2010.
Regina Barzilay and Michael Elhadad. Using lexical
chains for text summarization. In Proceedings of
the Intelligent Scalable Text Summarization Workshop,
1997.
Dasha Bogdanova, Paolo Rosso, Thamar Solorio. Mod-
elling Fixated Discourse in Chats with Cyberpe-
dophiles. Proceedings of the Workshop on Compu-
tational Approaches to Deception Detection, EACL,
2012.
Vincent Egan, James Hoskinson, and David Shewan.
Perverted justice: A content analysis of the language
used by offenders detected attempting to solicit chil-
dren for sex. Antisocial Behavior: Causes, Correla-
tions and Treatments, 2011.
Eric N Forsythand and Craig H Martell. Lexical and dis-
course analysis of online chat dialog. International
Conference on Semantic Computing ICSC 2007, pages
19?26, 2007.
Michel Galley and Kathleen McKeown. Improving word
sense disambiguation in lexical chaining. In Proceed-
ings of IJCAI-2003, 2003.
Ryan C. W. Hall and Richard C. W. Hall. A profile
of pedophilia: Definition, characteristics of offenders,
recidivism, treatment outcomes, and forensic issues.
Mayo Clinic Proceedings, 2007.
117
David Hope. Java wordnet similarity library.
http://www.cogs.susx.ac.uk/users/drh21.
Claudia Leacock and Martin Chodorow. C-rater: Auto-
mated scoring of short-answer questions. Computers
and the Humanities, 37(4):389?405, 2003.
Timothy Leary. Interpersonal diagnosis of personality;
a functional theory and methodology for personality
evaluation. Oxford, England: Ronald Press, 1957.
Jane Lin. Automatic author profiling of online chat logs.
PhD thesis, 2007.
India McGhee, Jennifer Bayzick, April Kontostathis,
Lynne Edwards, Alexandra McBride and Emma
Jakubowski. Learning to identify Internet sexual pre-
dation. International Journal on Electronic Commerce
2011.
Kimberly J. Mitchell, David Finkelhor, and Janis Wolak.
Risk factors for and impact of online sexual solicita-
tion of youth. Journal of the American Medical Asso-
ciation, 285:3011?3014, 2001.
Jane Morris and Graeme Hirst. Lexical cohesion com-
puted by thesaural relations as an indicator of the struc-
ture of text. Computational Linguistics, 17(1):21?43,
1991.
Ted Pedersen, Siddharth Patwardhan, Jason Miche-
lizzi, and Satanjeev Banerjee. Wordnet:similarity.
http://wn-similarity.sourceforge.net/.
Claudia Peersman, Walter Daelemans, and Leona Van
Vaerenbergh. Predicting age and gender in online so-
cial networks. In Proceedings of the 3rd Workshop on
Search and Mining User-Generated Contents, 2011.
Nick Pendar. Toward spotting the pedophile: Telling vic-
tim from predator in text chats. In Proceedings of
the International Conference on Semantic Computing,
pages 235?241, Irvine, California, 2007.
Alexander Panchenko, Richard Beaufort, Cedrick Fairon.
Detection of Child Sexual Abuse Media on P2P Net-
works: Normalization and Classification of Associated
Filenames. In Proceedings of the LREC Workshop on
Language Resources for Public Security Applications,
2012.
Philip Resnik. Using information content to evaluate se-
mantic similarity in a taxonomy. In IJCAI, pages 448?
453, 1995.
Howard N. Snyder. Sexual assault of young children as
reported to law enforcement: Victim, incident, and of-
fender characteristics. a nibrs statistical report. Bureau
of Justice Statistics Clearinghouse, 2000.
Carlo Strapparava and Rada Mihalcea. Semeval-2007
task 14: affective text. In Proceedings of the 4th In-
ternational Workshop on Semantic Evaluations, Se-
mEval?07, pages 70?74, 2007.
Carlo Strapparava and Alessandro Valitutti. Wordnet-
affect: an affective extension of wordnet. In Proceed-
ings of the 4th International Conference on Language
Re-sources and Evaluation, 2004.
Frederik Vaassen and Walter Daelemans. Automatic
emotion classification for interpersonal communica-
tion. In Proceedings of the 2nd Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis (WASSA 2.011), pages 104?110. Association
for Computational Linguistics, 2011.
Donna M. Vandiver and Glen Kercher. Offender and vic-
tim characteristics of registered female sexual offend-
ers in Texas: A proposed typology of female sexual
offenders. Sex Abuse, 16:121?137, 2004
World health organization, international statistical clas-
sification of diseases and related health problems: Icd-
10 section f65.4: Paedophilia. 1988.
118
