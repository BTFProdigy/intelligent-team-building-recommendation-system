Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 29?32,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Jane: Open Source Machine Translation System Combination
Markus Freitag
1
and Matthias Huck
2
and Hermann Ney
1
1
Lehrstuhl f?ur Informatik 6
2
School of Informatics
Computer Science Department University of Edinburgh
RWTH Aachen University 10 Crichton Street
D-52056 Aachen, Germany Edinburgh EH8 9AB, UK
{freitag,ney}@cs.rwth-aachen.de mhuck@inf.ed.ac.uk
Abstract
Different machine translation engines can
be remarkably dissimilar not only with re-
spect to their technical paradigm, but also
with respect to the translation output they
yield. System combination is a method for
combining the output of multiple machine
translation engines in order to take benefit
of the strengths of each of the individual
engines.
In this work we introduce a novel system
combination implementation which is in-
tegrated into Jane, RWTH?s open source
statistical machine translation toolkit. On
the most recent Workshop on Statisti-
cal Machine Translation system combi-
nation shared task, we achieve improve-
ments of up to 0.7 points in BLEU over
the best system combination hypotheses
which were submitted for the official eval-
uation. Moreover, we enhance our sys-
tem combination pipeline with additional
n-gram language models and lexical trans-
lation models.
1 Introduction
We present a novel machine translation system
combination framework which has been imple-
mented and released as part of the most recent ver-
sion of the Jane toolkit.
1
Our system combina-
tion framework has already been applied success-
fully for joining the outputs of different individual
machine translation engines from several project
partners within large-scale projects like Quaero
(Peitz and others, 2013), EU-BRIDGE (Freitag
and others, 2013), and DARPA BOLT. The com-
bined translation is typically of better quality than
1
Jane is publicly available under an open source non-
commercial license and can be downloaded from http://
www.hltpr.rwth-aachen.de/jane/ .
any of the individual hypotheses. The source code
of our framework has now been released to the
public.
We focus on system combination via confusion
network decoding. This basically means that we
align all input hypotheses from individual machine
translation (MT) engines together and extract a
combination as a new output. For our baseline
algorithm we only need the first best translation
from each of the different MT engines, without
any additional information. Supplementary to the
baseline models integrated into our framework, we
optionally allow for utilization of n-gram language
models and IBM-1 lexicon models (Brown et al.,
1993), both trained on additional training corpora
that might be at hand.
We evaluate the Jane system combination
framework on the latest official Workshop on
Statistical Machine Translation (WMT) system
combination shared task (Callison-Burch et al.,
2011). Many state-of-the-art MT system combi-
nation toolkits have been evaluated on this task,
which allows us to directly compare the results ob-
tained with our novel Jane system combination
framework with the best known results obtained
with other toolkits.
The paper is structured as follows: We com-
mence with giving a brief outline of some related
work (Section 2). In Section 3 we describe the
techniques which are implemented in the Jane
MT system combination framework. The exper-
imental results are presented and analyzed in Sec-
tion 4. We conclude the paper in Section 5.
2 Related Work
The first application of system combination to MT
has been presented by Bangalore et al. (2001).
They used a multiple string alignment (MSA) ap-
proach to align the hypotheses together and built
a confusion network from which the system com-
bination output is determined using majority vot-
29
0
1
w
ill
:w
ill
/-0
.3
*E
PS
*:
*E
PS
*/
-0
.7
2
co
nt
ai
n:
co
nt
ai
n/
-0
.2
co
m
pr
ise
:c
om
pr
ise
/-0
.1
*E
PS
*:
*E
PS
*/
-0
.7
3
*E
PS
*:
*E
PS
*/
-0
.3
th
e:
th
e/
-0
.6
co
m
pr
isi
ng
:c
om
pr
isi
ng
/-0
.1
4
*E
PS
*:
*E
PS
*/
-0
.9
an
:a
n/
-0
.1
5
iso
la
te
d:
iso
la
te
d/
-0
.8
*E
PS
*:
*E
PS
*/
-0
.2
6
cd
na
:c
dn
a/
-1
7
*E
PS
*:
*E
PS
*/
-0
.4
lib
ra
ry
:li
br
ar
y/
-0
.6
Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path.
ing and an additional language model. Matusov
et al. (2006) proposed an alignment based on the
GIZA
++
toolkit which introduced word reordering
not present in MSA, and Sim et al. (2007) used
alignments produced by TER scoring (Snover et
al., 2006). Extensions of the last two are based on
hidden Markov models (He et al., 2008), inversion
transduction grammars (Karakos et al., 2008), or
METEOR (Heafield and Lavie, 2010).
3 The Jane MT System Combination
Framework
In this section we describe the techniques for MT
system combination which we implemented in the
Jane toolkit.
2
We first address the generation of a
confusion network from the input translations. For
that we need a pairwise alignment between all in-
put hypotheses. We then present word reordering
mechanisms, the baseline models, and additional
advanced models which can be applied for system
combination using Jane. The system combina-
tion decoding step basically involves determining
the shortest path through the confusion network
based on several model scores from this network.
3.1 Confusion Network
A confusion network represents all different com-
bined translations we can generate from the set of
provided input hypotheses. Figure 1 depicts an ex-
ample of a confusion network. A word alignment
between all pairs of input hypotheses is required
for generating a confusion network. For conve-
nience, we first select one of the input hypotheses
as the primary hypothesis. The primary hypothesis
then determines the word order and all remaining
hypotheses are word-to-word aligned to the given
word order.
To generate a meaningful confusion network,
we should adopt an alignment which only al-
lows to switch between words which are syn-
onyms, misspellings, morphological variants or
on a higher level paraphrases of the words from
the primary hypothesis. In this work we use
METEOR alignments. METEOR (Denkowski
2
Practical usage aspects are explained in the man-
ual: http://www.hltpr.rwth-aachen.de/jane/
manual.pdf
and Lavie, 2011) was originally designed to re-
order a translation for scoring and has a high pre-
cision. The recall is lower because synonyms
which are not in the METEOR database or punc-
tuation marks like ?!? and ??? are not aligned
to each other. For our purposes, we augment the
METEOR paraphrase table with entries like ?.|!?,
?.|??, or ?the|a?.
Figure 2 shows an example METEOR hypothe-
sis alignment. The primary hypothesis ?isolated
cdna lib? determines the word order. An entry
?a|b? means that word ?a? from a secondary hy-
pothesis has been aligned to word ?b? from the
primary one. ?*EPS*? is the empty word and
thus an entry ?*EPS*|b? means that no word could
be aligned to the primary hypothesis word ?b?.
?a|*EPS*? means that the word ?a? has not been
aligned to any word from the primary hypothesis.
After producing the alignment information, we
can build the confusion network. Now, we are able
to not only extract the original primary hypoth-
esis from the confusion network but also switch
words from the primary hypothesis to words from
any secondary hypothesis (also the empty word)
or insert words or sequences of words.
In the final confusion network, we do not stick
to one hypothesis as the primary system. For m in-
put hypotheses we build m different confusion net-
works, each having a different system as primary
system. The final confusion network is a union of
all m networks.
3
The most straightforward way to obtain a com-
bined hypothesis from a confusion network is to
extract it via majority voting. For example, in
the first column in Figure 3, ?the? has been seen
three times, but the translation options ?a? and
?an? have each been seen only once. By means
of a straight majority vote we would extract ?the?.
As the different single system translations are of
varying utility for system combination, we assign
a system weight to each input hypothesis. The sys-
tem weights are set by optimizing scaling factors
for binary system voting features (cf. Section 3.3).
We employ some more weighted baseline features
3
Jane?s implementation for building confusion networks
is based on the OpenFST library (Allauzen et al., 2007).
30
the|*EPS* isolated|isolated cdna|cdna *EPS*|lib
a|*EPS* isolated|isolated cdna|cdna lib|lib
an|*EPS* isolated|isolated cdna|cdna lib|lib
the|*EPS* *EPS*|isolated cdna|cdna *EPS*|lib
the|*EPS* *EPS*|isolated cdna|cdna lib|lib
Figure 2: Alignment result after running
METEOR. *EPS* denotes the empty word.
*EPS* isolated cdna lib
the isolated cdna *EPS*
a isolated cdna lib
an isolated cdna lib
the *EPS* cdna lib
the *EPS* cdna *EPS*
the isolated cdna lib
Figure 3: Majority vote on aligned words. The last
line is the system combination output.
and additional models (cf. Section 3.4) in the deci-
sion process. In Figure 1 we scored the confusion
network with some system weights and used the
shortest path algorithm to find the hypothesis with
the highest score (the hypothesis along the path
highlighted in red).
3.2 Word Reordering
Many words from secondary hypotheses can be
unaligned as they have no connection to any words
of the primary hypothesis. However, words from
different secondary systems could be related to
each other. In order to account for these relations
and to give the words from the secondary hypothe-
ses a higher chance to be present in the combined
output, we introduce some simple word reordering
mechanisms.
We rank the hypotheses according to a language
model trained on all input hypotheses. We initial-
ize the confusion network with the sentence from
the primary system. During the generation of the
confusion network we align the hypotheses con-
secutively into the confusion network via the fol-
lowing procedure:
? If a word w
i
from hypothesis A has a relation
to a word v
j
of the primary hypothesis, we
insert it as a new translation alternative to v
j
.
? If w
i
has no relation to the primary, but to
a word u
k
from a secondary hypothesis in
the confusion network, we insert w
i
as a new
translation alternative to u
k
.
? Otherwise we insert w
i
in front of the previ-
ous inserted word w
i?1
of hypothesis A. The
new position gets an epsilon arc for the pri-
mary and all unrelated secondary systems.
3.3 Baseline Models
Once we have the final confusion network, we
want to adopt models which are valuable features
to score the different translation options. In our
implementation we use the following set of stan-
dard models:
m binary system voting features For each word
the voting feature for system i (1? i?m) is 1
iff the word is from system i, otherwise 0.
Binary primary system feature A feature that
marks the primary hypothesis.
LM feature 3-gram language model trained on
the input hypotheses.
Word penalty Counts the number of words.
3.4 Additional Models
The Jane system combination toolkit also pro-
vides the possibility to utilize some additional
models for system combination. For the current
release we integrated the optional usage of the fol-
lowing additional models:
Big LM A big language model trained on larger
monolingual target-side corpora.
IBM-1 Source-to-target and target-to-source
IBM-1 lexical translation models obtained
from bilingual training data.
4 Experimental Results
All experiments are conducted on the latest offi-
cial WMT system combination shared task.
4
We
exclusively employ resources which were permit-
ted for the constrained track of the task in all our
setups. The big LM was trained on News Com-
mentary and Europarl data. As tuning set we
used newssyscombtune2011, as test set we used
newssyscombtest2011. Feature weights have been
optimized with MERT (Och, 2003). Table 1 con-
tains the empirical results (truecase). For all four
language pairs we achieve improvements over the
best 2011 evaluation system combination submis-
sion either in BLEU or TER. We get the highest
improvement of 0.7 points in BLEU for es?en
when adding both the big LM and IBM-1 features.
Adding the big LM over the baseline enhances
the translation quality for all four language pairs.
Adding IBM-1 lexicon models on top of the big
LM is of marginal or no benefit for most language
4
The most recent system combination shared task that
has been organized as part of the WMT evaluation cam-
paign took place in 2011. http://www.statmt.org/
wmt11/system-combination-task.html
31
Table 1: Experimental results on the WMT system combination tasks (newssyscombtest2011).
system cz?en de?en es?en fr?en
BLEU TER BLEU TER BLEU TER BLEU TER
best single system 28.7 53.4 23.0 59.5 28.9 51.2 29.4 52.0
best 2011 evaluation syscomb 28.8 55.2 25.1 57.4 32.4 49.9 31.3 50.1
Jane syscomb baseline 28.8 53.6 24.7 57.6 32.7 50.3 31.3 50.3
Jane syscomb + big LM 29.0 54.5 25.0 57.3 32.9 50.3 31.4 50.0
Jane syscomb + big LM + IBM-1 29.0 54.5 25.0 57.3 33.1 50.0 31.5 50.1
pairs, but at least provides slight improvements for
es?en.
5 Conclusion
RWTH?s open source machine translation toolkit
Jane now includes a state-of-the-art system com-
bination framework. We found that the Jane sys-
tem combination performs on a similar level or
better than the best evaluation system combina-
tion submissions on all WMT 2011 system com-
bination shared task language pairs (with English
as target language). We furthermore presented the
effects of integrating a big n-gram language model
and of lexical features from IBM-1 models.
Acknowledgements
This material is based upon work supported by
the DARPA BOLT project under Contract No.
HR0011- 12-C-0015. Any opinions, findings and
conclusions or recommendations expressed in this
material are those of the authors and do not neces-
sarily reflect the views of DARPA.
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreement n
o
287658.
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut, and Mehryar Mohri. 2007. OpenFst: A
General and Efficient Weighted Finite-State Trans-
ducer Library. In Jan Holub and Jan Zd?arek, edi-
tors, Implementation and Application of Automata,
volume 4783 of Lecture Notes in Computer Science,
pages 11?23. Springer Berlin Heidelberg.
Srinivas Bangalore, German Bordel, and Giuseppe Ric-
cardi. 2001. Computing Consensus Translation
from Multiple Machine Translation Systems. In
Proc. of ASRU, pages 351?354.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263?311.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar F. Zaidan. 2011. Findings of the 2011
Workshop on Statistical Machine Translation. In
Proc. of WMT, pages 22?64.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic Metric for Reliable Optimization
and Evaluation of Machine Translation Systems. In
Proc. of WMT, pages 85?91.
Markus Freitag et al. 2013. EU-BRIDGE MT: Text
Translation of Talks in the EU-BRIDGE Project. In
Proc. of IWSLT.
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore. 2008. Indirect-
HMM-based Hypothesis Alignment for Combining
Outputs from Machine Translation Systems. In
Proc. of EMNLP, pages 98?107.
Kenneth Heafield and Alon Lavie. 2010. Combining
Machine Translation Output with Open Source: The
Carnegie Mellon Multi-Engine Machine Translation
Scheme. The Prague Bulletin of Mathematical Lin-
guistics, 93:27?36.
Damianos Karakos, Jason Eisner, Sanjeev Khudanpur,
and Markus Dreyer. 2008. Machine translation sys-
tem combination using ITG-based alignments. In
Proc. of ACL: Short Papers, pages 81?84.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing Consensus Translation from Mul-
tiple Machine Translation Systems Using Enhanced
Hypotheses Alignment. In Proc. of EACL, pages
33?40.
Franz J. Och. 2003. Minimum Error Rate Training for
Statistical Machine Translation. In Proc. of ACL,
pages 160?167.
Stephan Peitz et al. 2013. Joint WMT 2013 Submis-
sion of the QUAERO Project. In Proc. of WMT,
pages 185?192.
Khe Chai Sim, William J. Byrne, Mark J.F. Gales,
Hichem Sahbi, and Phil C. Woodland. 2007.
Consensus Network Decoding for Statistical Ma-
chine Translation System Combination. In
Proc. of ICASSP, volume 4, pages 105?108.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciula, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proc. of AMTA, pages 223?231.
32
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 347?351,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Insertion and Deletion Models for Statistical Machine Translation
Matthias Huck and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
{huck,ney}@cs.rwth-aachen.de
Abstract
We investigate insertion and deletion models
for hierarchical phrase-based statistical ma-
chine translation. Insertion and deletion mod-
els are designed as a means to avoid the omis-
sion of content words in the hypotheses. In
our case, they are implemented as phrase-level
feature functions which count the number of
inserted or deleted words. An English word is
considered inserted or deleted based on lex-
ical probabilities with the words on the for-
eign language side of the phrase. Related tech-
niques have been employed before by Och et
al. (2003) in an n-best reranking framework
and by Mauser et al (2006) and Zens (2008)
in a standard phrase-based translation system.
We propose novel thresholding methods in
this work and study insertion and deletion fea-
tures which are based on two different types of
lexicon models. We give an extensive exper-
imental evaluation of all these variants on the
NIST Chinese?English translation task.
1 Insertion and Deletion Models
In hierarchical phrase-based translation (Chiang,
2005), we deal with rules X ? ??, ?,? ? where
??, ?? is a bilingual phrase pair that may contain
symbols from a non-terminal set, i.e. ? ? (N ?
VF )+ and ? ? (N ?VE)+, where VF and VE are the
source and target vocabulary, respectively, and N is
a non-terminal set which is shared by source and tar-
get. The left-hand side of the rule is a non-terminal
symbol X ? N , and the ? relation denotes a one-
to-one correspondence between the non-terminals in
? and in ?. Let J? denote the number of terminal
symbols in ? and I? the number of terminal sym-
bols in ?. Indexing ? with j, i.e. the symbol ?j ,
1 ? j ? J?, denotes the j-th terminal symbol on
the source side of the phrase pair ??, ??, and analo-
gous with ?i, 1 ? i ? I? , on the target side.
With these notational conventions, we now de-
fine our insertion and deletion models, each in both
source-to-target and target-to-source direction. We
give phrase-level scoring functions for the four fea-
tures. In our implementation, the feature values are
precomputed and written to the phrase table. The
features are then incorporated directly into the log-
linear model combination of the decoder.
Our insertion model in source-to-target direction
ts2tIns(?) counts the number of inserted words on the
target side ? of a hierarchical rule with respect to the
source side ? of the rule:
ts2tIns(?, ?) =
I??
i=1
J??
j=1
[
p(?i|?j) < ??j
]
(1)
Here, [?] denotes a true or false statement: The result
is 1 if the condition is true and 0 if the condition is
false. The model considers an occurrence of a tar-
get word e an insertion iff no source word f exists
within the phrase where the lexical translation prob-
ability p(e|f) is greater than a corresponding thresh-
old ?f . We employ lexical translation probabilities
from two different types of lexicon models, a model
which is extracted from word-aligned training data
and?given the word alignment matrix?relies on
pure relative frequencies, and the IBM model 1 lex-
icon (cf. Section 2). For ?f , previous authors have
used a fixed heuristic value which was equal for all
347
f ? Vf . In Section 3, we describe how such a global
threshold can be computed and set in a reasonable
way based on the characteristics of the model. We
also propose several novel thresholding techniques
with distinct thresholds ?f for each source word f .
In an analogous manner to the source-to-target di-
rection, the insertion model in target-to-source di-
rection tt2sIns(?) counts the number of inserted words
on the source side ? of a hierarchical rule with re-
spect to the target side ? of the rule:
tt2sIns(?, ?) =
J??
j=1
I??
i=1
[p(?j |?i) < ??i ] (2)
Target-to-source lexical translation probabilities
p(f |e) are thresholded with values ?e which may be
distinct for each target word e. The model consid-
ers an occurrence of a source word f an insertion iff
no target word e exists within the phrase with p(f |e)
greater than or equal to ?e.
Our deletion model, compared to the insertion
model, interchanges the connection of the direction
of the lexical probabilities and the order of source
and target in the sum and product of the term. The
source-to-target deletion model thus differs from the
target-to-source insertion model in that it employs a
source-to-target word-based lexicon model.
The deletion model in source-to-target direction
ts2tDel(?) counts the number of deleted words on the
source side ? of a hierarchical rule with respect to
the target side ? of the rule:
ts2tDel(?, ?) =
J??
j=1
I??
i=1
[
p(?i|?j) < ??j
]
(3)
It considers an occurrence of a source word f a dele-
tion iff no target word e exists within the phrase with
p(e|f) greater than or equal to ?f .
The target-to-source deletion model tt2sDel(?) cor-
respondingly considers an occurrence of a target
word e a deletion iff no source word f exists within
the phrase with p(f |e) greater than or equal to ?e:
tt2sDel(?, ?) =
I??
i=1
J??
j=1
[p(?j |?i) < ??i ] (4)
2 Lexicon Models
We restrict ourselves to the description of the
source-to-target direction of the models.
2.1 Word Lexicon from Word-Aligned Data
Given a word-aligned parallel training corpus, we
are able to estimate single-word based translation
probabilities pRF(e|f) by relative frequency (Koehn
et al, 2003). With N(e, f) denoting counts of
aligned cooccurrences of target word e and source
word f , we can compute
pRF(e|f) =
N(e, f)
?
e? N(e
?, f)
. (5)
If an occurrence of e has multiple aligned source
words, each of the alignment links contributes with
a fractional count.
We denote this model as relative frequency (RF)
word lexicon.
2.2 IBM Model 1
The IBM model 1 lexicon (IBM-1) is the first and
most basic one in a sequence of probabilistic genera-
tive models (Brown et al, 1993). For IBM-1, several
simplifying assumptions are made, so that the proba-
bility of a target sentence eI1 given a source sentence
fJ0 (with f0 = NULL) can be modeled as
Pr(eI1|f
J
1 ) =
1
(J + 1)I
I?
i=1
J?
j=0
pibm1(ei|fj) . (6)
The parameters of IBM-1 are estimated iteratively
by means of the Expectation-Maximization algo-
rithm with maximum likelihood as training criterion.
3 Thresholding Methods
We introduce thresholding methods for insertion and
deletion models which set thresholds based on the
characteristics of the lexicon model that is applied.
For all the following thresholding methods, we dis-
regard entries in the lexicon model with probabilities
that are below a fixed floor value of 10?6. Again, we
restrict ourselves to the description of the source-to-
target direction.
individual ?f is a distinct value for each f , com-
puted as the arithmetic average of all entries
p(e|f) of any e with the given f in the lexicon
model.
348
MT06 (Dev) MT08 (Test)
NIST Chinese?English BLEU [%] TER [%] BLEU [%] TER [%]
Baseline (with s2t+t2s RF word lexicons) 32.6 61.2 25.2 66.6
+ s2t+t2s insertion model (RF, individual) 32.9 61.4 25.7 66.2
+ s2t+t2s insertion model (RF, global) 32.8 61.8 25.7 66.7
+ s2t+t2s insertion model (RF, histogram 10) 32.9 61.7 25.5 66.5
+ s2t+t2s insertion model (RF, all) 32.8 62.0 26.1 66.7
+ s2t+t2s insertion model (RF, median) 32.9 62.1 25.7 67.1
+ s2t+t2s deletion model (RF, individual) 32.7 61.4 25.6 66.5
+ s2t+t2s deletion model (RF, global) 33.0 61.3 25.8 66.1
+ s2t+t2s deletion model (RF, histogram 10) 32.9 61.4 26.0 66.1
+ s2t+t2s deletion model (RF, all) 33.0 61.4 25.9 66.4
+ s2t+t2s deletion model (RF, median) 32.9 61.5 25.8 66.7
+ s2t+t2s insertion model (IBM-1, individual) 33.0 61.4 26.1 66.4
+ s2t+t2s insertion model (IBM-1, global) 33.0 61.6 25.9 66.5
+ s2t+t2s insertion model (IBM-1, histogram 10) 33.7 61.3 26.2 66.5
+ s2t+t2s insertion model (IBM-1, median) 33.0 61.3 26.0 66.4
+ s2t+t2s deletion model (IBM-1, individual) 32.8 61.5 26.0 66.2
+ s2t+t2s deletion model (IBM-1, global) 32.9 61.3 25.9 66.1
+ s2t+t2s deletion model (IBM-1, histogram 10) 32.8 61.2 25.7 66.0
+ s2t+t2s deletion model (IBM-1, median) 32.8 61.6 25.6 66.7
+ s2t insertion + s2t deletion model (IBM-1, individual) 32.7 62.3 25.7 67.1
+ s2t insertion + t2s deletion model (IBM-1, individual) 32.7 62.2 25.9 66.8
+ t2s insertion + s2t deletion model (IBM-1, individual) 33.1 61.3 25.9 66.2
+ t2s insertion + t2s deletion model (IBM-1, individual) 33.0 61.3 26.1 66.0
+ source+target unaligned word count 32.3 61.8 25.6 66.7
+ phrase-level s2t+t2s IBM-1 word lexicons 33.8 60.5 26.9 65.4
+ source+target unaligned word count 34.0 60.4 26.7 65.8
+ s2t+t2s insertion model (IBM-1, histogram 10) 34.0 60.3 26.8 65.2
+ phrase-level s2t+t2s DWL + triplets + discrim. RO 34.8 59.8 27.7 64.7
+ s2t+t2s insertion model (RF, individual) 35.0 59.5 27.8 64.4
Table 1: Experimental results for the NIST Chinese?English translation task (truecase). s2t denotes source-to-target
scoring, t2s target-to-source scoring. Bold font indicates results that are significantly better than the baseline (p < .1).
global The same value ?f = ? is used for all f .
We compute this global threshold by averaging
over the individual thresholds.1
histogram n ?f is a distinct value for each f . ?f is
set to the value of the n+1-th largest probabil-
ity p(e|f) of any e with the given f .
1Concrete values from our experiments are: 0.395847 for
the source-to-target RF lexicon, 0.48127 for the target-to-source
RF lexicon. 0.0512856 for the source-to-target IBM-1, and
0.0453709 for the target-to-source IBM-1. Mauser et al (2006)
mention that they chose their heuristic thresholds for use with
IBM-1 between 10?1 and 10?4.
all All entries with probabilities larger than the floor
value are not thresholded. This variant may be
considered as histogram ?. We only apply it
with RF lexicons.
median ?f is a median-based distinct value for each
f , i.e. it is set to the value that separates the
higher half of the entries from the lower half of
the entries p(e|f) for the given f .
4 Experimental Evaluation
We present empirical results obtained with the dif-
ferent insertion and deletion model variants on the
349
Chinese?English 2008 NIST task.2
4.1 Experimental Setup
To set up our systems, we employ the open source
statistical machine translation toolkit Jane (Vilar et
al., 2010; Vilar et al, 2012), which is freely avail-
able for non-commercial use. Jane provides efficient
C++ implementations for hierarchical phrase extrac-
tion, optimization of log-linear feature weights, and
parsing-based decoding algorithms. In our experi-
ments, we use the cube pruning algorithm (Huang
and Chiang, 2007) to carry out the search.
We work with a parallel training corpus of 3.0M
Chinese-English sentence pairs (77.5M Chinese /
81.0M English running words). The counts for
the RF lexicon models are computed from a sym-
metrized word alignment (Och and Ney, 2003), the
IBM-1 models are produced with GIZA++. When
extracting phrases, we apply several restrictions, in
particular a maximum length of 10 on source and
target side for lexical phrases, a length limit of five
(including non-terminal symbols) for hierarchical
phrases, and no more than two gaps per phrase.
The models integrated into the baseline are: phrase
translation probabilities and RF lexical translation
probabilities on phrase level, each for both transla-
tion directions, length penalties on word and phrase
level, binary features marking hierarchical phrases,
glue rule, and rules with non-terminals at the bound-
aries, source-to-target and target-to-source phrase
length ratios, four binary features marking phrases
that have been seen more than one, two, three or
five times, respectively, and an n-gram language
model. The language model is a 4-gram with modi-
fied Kneser-Ney smoothing which was trained with
the SRILM toolkit (Stolcke, 2002) on a large collec-
tion of English data including the target side of the
parallel corpus and the LDC Gigaword v3.
Model weights are optimized against BLEU (Pa-
pineni et al, 2002) with standard Minimum Error
Rate Training (Och, 2003), performance is measured
with BLEU and TER (Snover et al, 2006). We em-
ploy MT06 as development set, MT08 is used as un-
seen test set. The empirical evaluation of all our se-
tups is presented in Table 1.
2http://www.itl.nist.gov/iad/mig/tests/
mt/2008/
4.2 Experimental Results
With the best model variant, we obtain a significant
improvement (90% confidence) of +1.0 points BLEU
over the baseline on MT08. A consistent trend to-
wards one of the variants cannot be observed. The
results on the test set with RF lexicons or IBM-1, in-
sertion or deletion models, and (in most of the cases)
with all of the thresholding methods are roughly at
the same level. For comparison we also give a result
with an unaligned word count model (+0.4 BLEU).
Huck et al (2011) recently reported substantial
improvements over typical hierarchical baseline se-
tups by just including phrase-level IBM-1 scores.
When we add the IBM-1 models directly, our base-
line is outperformed by +1.7 BLEU. We tried to
get improvements with insertion and deletion mod-
els over this setup again, but the positive effect was
largely diminished. In one of our strongest setups,
which includes discriminative word lexicon models
(DWL), triplet lexicon models and a discriminative
reordering model (discrim. RO) (Huck et al, 2012),
insertion models still yield a minimal gain, though.
5 Conclusion
Our results with insertion and deletion models for
Chinese?English hierarchical machine translation
are twofold. On the one hand, we achieved sig-
nificant improvements over a standard hierarchical
baseline. We were also able to report a slight gain
by adding the models to a very strong setup with
discriminative word lexicons, triplet lexicon mod-
els and a discriminative reordering model. On the
other hand, the positive impact of the models was
mainly noticeable when we exclusively applied lex-
ical smoothing with word lexicons which are simply
extracted from word-aligned training data, which
is however the standard technique in most state-of-
the-art systems. If we included phrase-level lexical
scores with IBM model 1 as well, the systems barely
benefited from our insertion and deletion models.
Compared to an unaligned word count model, inser-
tion and deletion models perform well.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
350
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The Mathemat-
ics of Statistical Machine Translation: Parameter Es-
timation. Computational Linguistics, 19(2):263?311,
June.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc. of
the 43rd Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 263?270, Ann Arbor,
MI, USA, June.
Liang Huang and David Chiang. 2007. Forest Rescoring:
Faster Decoding with Integrated Language Models. In
Proc. of the Annual Meeting of the Assoc. for Com-
putational Linguistics (ACL), pages 144?151, Prague,
Czech Republic, June.
Matthias Huck, Saab Mansour, Simon Wiesler, and Her-
mann Ney. 2011. Lexicon Models for Hierarchi-
cal Phrase-Based Machine Translation. In Proc. of
the Int. Workshop on Spoken Language Translation
(IWSLT), pages 191?198, San Francisco, CA, USA,
December.
Matthias Huck, Stephan Peitz, Markus Freitag, and Her-
mann Ney. 2012. Discriminative Reordering Exten-
sions for Hierarchical Phrase-Based Machine Transla-
tion. In Proc. of the 16th Annual Conference of the Eu-
ropean Association for Machine Translation (EAMT),
Trento, Italy, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmonton,
Canada, May/June.
Arne Mauser, Richard Zens, Evgeny Matusov, Sas?a
Hasan, and Hermann Ney. 2006. The RWTH Statisti-
cal Machine Translation System for the IWSLT 2006
Evaluation. In Proc. of the Int. Workshop on Spoken
Language Translation (IWSLT), pages 103?110, Ky-
oto, Japan, November.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syn-
tax for Statistical Machine Translation. Technical re-
port, Johns Hopkins University 2003 Summer Work-
shop on Language Engineering, Center for Language
and Speech Processing, Baltimore, MD, USA, August.
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proc. of the An-
nual Meeting of the Assoc. for Computational Linguis-
tics (ACL), pages 160?167, Sapporo, Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Evalu-
ation of Machine Translation. In Proc. of the 40th An-
nual Meeting of the Assoc. for Computational Linguis-
tics (ACL), pages 311?318, Philadelphia, PA, USA,
July.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), pages 223?231, Cambridge,
MA, USA, August.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open Source Hierarchical Transla-
tion, Extended with Reordering and Lexicon Models.
In ACL 2010 Joint Fifth Workshop on Statistical Ma-
chine Translation and Metrics MATR, pages 262?270,
Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2012. Jane: an advanced freely available hier-
archical machine translation toolkit. Machine Trans-
lation, pages 1?20. http://dx.doi.org/10.1007/s10590-
011-9120-y.
Richard Zens. 2008. Phrase-based Statistical Machine
Translation: Models, Search, Training. Ph.D. thesis,
RWTH Aachen University, Aachen, Germany, Febru-
ary.
351
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 93?97,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2010
Carmen Heger, Joern Wuebker, Matthias Huck, Gregor Leusch,
Saab Mansour, Daniel Stein and Hermann Ney
RWTH Aachen University
Aachen, Germany
surname@cs.rwth-aachen.de
Abstract
In this paper we describe the statisti-
cal machine translation system of the
RWTH Aachen University developed for
the translation task of the Fifth Workshop
on Statistical Machine Translation. State-
of-the-art phrase-based and hierarchical
statistical MT systems are augmented
with appropriate morpho-syntactic en-
hancements, as well as alternative phrase
training methods and extended lexicon
models. For some tasks, a system combi-
nation of the best systems was used to gen-
erate a final hypothesis. We participated
in the constrained condition of German-
English and French-English in each trans-
lation direction.
1 Introduction
This paper describes the statistical MT system
used for our participation in the WMT 2010 shared
translation task. We used it as an opportunity to in-
corporate novel methods which have been investi-
gated at RWTH over the last year and which have
proven to be successful in other evaluations.
For all tasks we used standard alignment and
training tools as well as our in-house phrase-
based and hierarchical statistical MT decoders.
When German was involved, morpho-syntactic
preprocessing was applied. An alternative phrase-
training method and additional models were tested
and investigated with respect to their effect for the
different language pairs. For two of the language
pairs we could improve performance by system
combination.
An overview of the systems and models will fol-
low in Section 2 and 3, which describe the base-
line architecture, followed by descriptions of the
additional system components. Morpho-syntactic
analysis and other preprocessing issues are cov-
ered by Section 4. Finally, translation results for
the different languages and system variants are
presented in Section 5.
2 Translation Systems
For the WMT 2010 Evaluation we used stan-
dard phrase-based and hierarchical translation sys-
tems. Alignments were trained with a variant of
GIZA++. Target language models are 4-gram lan-
guage models trained with the SRI toolkit, using
Kneser-Ney discounting with interpolation.
2.1 Phrase-Based System
Our phrase-based translation system is similar to
the one described in (Zens and Ney, 2008). Phrase
pairs are extracted from a word-aligned bilingual
corpus and their translation probability in both di-
rections is estimated by relative frequencies. Ad-
ditional models include a standard n-gram lan-
guage model, phrase-level IBM1, word-, phrase-
and distortion-penalties and a discriminative re-
ordering model as described in (Zens and Ney,
2006).
2.2 Hierarchical System
Our hierarchical phrase-based system is similar to
the one described in (Chiang, 2007). It allows for
gaps in the phrases by employing a context-free
grammar and a CYK-like parsing during the de-
coding step. It has similar features as the phrase-
based system mentioned above. For some sys-
tems, we only allowed the non-terminals in hierar-
chical phrases to be substituted with initial phrases
as in (Iglesias et al, 2009), which gave better re-
sults on some language pairs. We will refer to this
as ?shallow rules?.
2.3 System Combination
The RWTH approach to MT system combination
of the French?English systems as well as the
German?English systems is a refined version of
the ROVER approach in ASR (Fiscus, 1997) with
93
German?English French?English English?French
BLEU # Phrases BLEU # Phrases BLEU # Phrases
Standard 19.7 128M 25.5 225M 23.7 261M
FA 20.0 12M 25.9 35M 24.0 33M
Table 1: BLEU scores on Test and phrase table sizes with and without forced alignment (FA). For
German?English and English?French phrase table interpolation was applied.
additional steps to cope with reordering between
different hypotheses, and to use true casing infor-
mation from the input hypotheses. The basic con-
cept of the approach has been described by Ma-
tusov et al (2006). Several improvements have
been added later (Matusov et al, 2008). This ap-
proach includes an enhanced alignment and re-
ordering framework. Alignments between the sys-
tems are learned by GIZA++, a one-to-one align-
ment is generated from the learned state occupa-
tion probabilities.
From these alignments, a confusion network
(CN) is then built using one of the hypotheses as
?skeleton? or ?primary? hypothesis. We do not
make a hard decision on which of the hypothe-
ses to use for that, but instead combine all pos-
sible CNs into a single lattice. Majority voting on
the generated lattice is performed using the prior
probabilities for each system as well as other sta-
tistical models such as a special trigram language
model. This language model is also learned on
the input hypotheses. The intention is to favor
longer phrases contained in individual hypotheses.
The translation with the best total score within this
lattice is selected as consensus translation. Scal-
ing factors of these models are optimized similar
to MERT using the Downhill Simplex algorithm.
As the objective function for this optimization, we
selected a linear combination of BLEU and TER
with a weight of 2 on the former; a combination
that has proven to deliver stable results on sev-
eral MT evaluation measures in preceding experi-
ments.
In contrast to previous years, we now include a
separate consensus true casing step to exploit the
true casing capabilities of some of the input sys-
tems: After generating a (lower cased) consensus
translation from the CN, we sum up the counts of
different casing variants of each word in a sen-
tence over the input hypotheses, and use the ma-
jority casing over those. In previous experiments,
this showed to work significantly better than us-
ing a fixed non-consensus true caser, and main-
tains flexibility on the input systems.
3 New Additional Models
3.1 Forced Alignment
For the German?English, French?English and
English?French language tasks we applied a
forced alignment procedure to train the phrase
translation model with the EM algorithm, sim-
ilar to the one described in (DeNero et al,
2006). Here, the phrase translation probabil-
ities are estimated from their relative frequen-
cies in the phrase-aligned training data. The
phrase alignment is produced by a modified
version of the translation decoder. In addi-
tion to providing a statistically well-founded
phrase model, this has the benefit of produc-
ing smaller phrase tables and thus allowing
more rapid experiments. For the language pairs
German?English and English?French the best
results were achieved by log-linear interpolation
of the standard phrase table with the generative
model. For French?English we directly used the
model trained by forced alignment. A detailed
description of the training procedure is given in
(Wuebker et al, 2010). Table 1 shows the system
performances and phrase table sizes with the stan-
dard phrase table and the one trained with forced
alignment after the first EM iteration. We can see
that the generative model reduces the phrase table
size by 85-90% while increasing performance by
0.3% to 0.4% BLEU.
3.2 Extended Lexicon Models
In previous work, RWTH was able to show the
positive impact of extended lexicon models that
cope with lexical context beyond the limited hori-
zon of phrase pairs and n-gram language models.
Mauser et al (2009) report improvements of
up to +1% in BLEU on large-scale systems for
Chinese?English and Arabic?English by incor-
porating discriminative and trigger-based lexicon
models into a state-of-the-art phrase-based de-
coder. They discuss how the two types of lexicon
94
models help to select content words by capturing
long-distance effects.
The triplet model is a straightforward extension
of the IBM model 1 with a second trigger, and like
the former is trained iteratively using the EM al-
gorithm. In search, the triggers are usually on the
source side, i.e., p(e|f, f ?) is modeled. The path-
constrained triplet model restricts the first source
trigger to the aligned target word, whereas the sec-
ond trigger can move along the whole source sen-
tence. See (Hasan et al, 2008) for a detailed de-
scription and variants of the model and its training.
For the WMT 2010 evaluation, triplets mod-
eling p(e|f, f ?) were trained and applied di-
rectly in search for all relevant language pairs.
Path-constrained models were trained on the in-
domain news-commentary data only and on the
news-commentary plus the Europarl data. Al-
though experience from similar setups indicates
that triplet lexicon models can be beneficial for
machine translation between the languages En-
glish, French, and German, on this year?s WMT
translation tasks slight improvements on the devel-
opment sets did not or only partially carry over to
the held-out test sets. Nevertheless, systems with
triplets were used for system combination, as ex-
tended lexicon models often help to predict con-
tent words and to capture long-range dependen-
cies. Thus they can help to find a strong consensus
hypothesis.
3.3 Unsupervised Training
Due to the small size of the English?German re-
sources available for language modeling as well as
for lexicon extraction, we decided to apply the un-
supervised adaptation suggested in (Schwenk and
Senellart, 2009). We use a baseline SMT system to
translate in-domain monolingual source data, fil-
ter the translations according to a decoder score
normalized by sentence length, add this synthetic
bilingual data to the original one and rebuild the
SMT system from scratch.
The motivation behind the method is that the
phrase table will adapt to the genre, and thus
let phrases which are domain related have higher
probabilities. Two phenomena are observed from
phrase tables and the corresponding translations:
? Phrase translation probabilities are changed,
making the system choose better phrase
translation candidates.
Running Words
English German
Bilingual 44.3M 43.4M
Dict. 1.4M 1.2M
AFP 610.7M
AFP unsup. 152.0M 157.3M
Table 2: Overview on data for unsupervised train-
ing.
BLEU
Dev Test
baseline 15.0 14.7
+dict. 15.1 14.6
+unsup.+dict 15.4 14.9
Table 3: Results for unsupervised training method.
? Phrases which appear repeatedly in the do-
main get higher probabilities, so that the de-
coder can better segment the sentence.
To implement this idea, we translate the AFP part
of the English LDC Gigaword v4.0 and obtain the
synthetic data.
To decrease the number of OOV words, we use
dictionaries from the stardict directory as addi-
tional bilingual data to translate the AFP corpus.
We filter sentences with OOV words and sentences
longer than 100 tokens. A summary of the addi-
tional data used is shown in Table 2.
We tried to use the best 10%, 20% and 40% of
the synthetic data, where the 40% option worked
best. A summary of the results is given in Table 3.
Although this is our best result for the
English?German task, it was not submitted, be-
cause the use of the dictionary is not allowed in
the constrained track.
4 Preprocessing
4.1 Large Parallel Data
In addition to the provided parallel Europarl and
news-commentary corpora, also the large French-
English news corpus (about 22.5 Mio. sentence
pairs) and the French-English UN corpus (about
7.2 Mio. sentence pairs) were available. Since
model training and tuning with such large cor-
pora takes a very long time, we extracted about
2 Mio. sentence pairs of both of these corpora. We
filter sentences with the following properties:
95
? Only sentences of minimum length of 4 to-
kens were considered.
? At least 92% of the vocabulary of each sen-
tence occur in the development set.
? The ratio of the vocabulary size of a sen-
tence and the number of its tokens is mini-
mum 80%.
4.2 Morpho-Syntactic Analysis
German, as a flexible and morphologically rich
language, raises a couple of problems in machine
translation. We picked two major problems and
tackled them with morpho-syntactic pre- and post-
processing: compound splitting and long-range
verb reordering.
For the translation from German into English,
German compound words were split using the
frequency-based method described in (Koehn and
Knight, 2003). Thereby, we forbid certain words
and syllables to be split. For the other trans-
lation direction, the English text was first trans-
lated into the modified German language with
split compounds. The generated output was then
postprocessed by re-merging the previously gen-
erated components using the method described in
(Popovic? et al, 2006).
Additionally, for the German?English phrase-
based system, the long-range POS-based reorder-
ing rules described in (Popovic? and Ney, 2006)
were applied on the training and test corpora as a
preprocessing step. Thereby, German verbs which
occur at the end of a clause, like infinitives and
past participles, are moved towards the beginning
of that clause. With this, we improved our baseline
phrase-based system by 0.6% BLEU.
5 Experimental Results
For all translation directions, we used the provided
parallel corpora (Europarl, news) to train the trans-
lation models and the monolingual corpora to train
BLEU
Dev Test
phrase-based baseline 19.9 19.2
phrase-based (+POS+mero+giga) 21.0 20.3
hierarchical baseline 20.2 19.6
hierarchical (+giga) 20.5 20.1
system combination 21.4 20.4
Table 4: Results for the German?English task.
the language models. We improved the French-
English systems by enriching the data with parts of
the large addional data, extracted with the method
described in Section 4.1. Depending on the sys-
tem this gave an improvement of 0.2-0.7% BLEU.
We also made use of the large giga-news as well
as the LDC Gigaword corpora for the French and
English language models. All systems were opti-
mized for BLEU score on the development data,
newstest2008. The newstest2009 data is
used as a blind test set.
In the following, we will give the BLEU scores
for all language tasks of the baseline system and
the best setup for both, the phrase-based and the
hierarchical system. We will use the following
notations to indicate the several methods we used:
(+POS) POS-based verb reordering
(+mero) maximum entropy reordering
(+giga) including giga-news and
LDC Gigaword in LM
(fa) trained by forced alignment
(shallow) allow only shallow rules
We applied system combination of up to 6 sys-
tems with several setups. The submitted systems
are marked in tables 4-7.
6 Conclusion
For the participation in the WMT 2010 shared
translation task, RWTH used state-of-the-art
phrase-based and hierarchical translation systems.
To deal with the rich morphology and word or-
der differences in German, compound splitting
and long range verb reordering were applied in a
preprocessing step. For the French-English lan-
guage pairs, RWTH extracted parts of the large
news corpus and the UN corpus as additional
training data. Further, training the phrase trans-
lation model with forced alignment yielded im-
provements in BLEU. To obtain the final hypothe-
sis for the French?English and German?English
BLEU
Dev Test
phrase-based baseline 14.8 14.5
phrase-based (+mero) 15.0 14.7
hierarchical baseline 14.2 13.9
hierarchical (shallow) 14.5 14.3
Table 5: Results for the English?German task.
96
BLEU
Dev Test
phrase-based baseline 21.8 25.1
phrase-based (fa+giga) 23.0 26.1
hierarchical baseline 21.9 25.0
hierarchical (shallow+giga) 22.7 25.6
system combination 23.1 26.1
Table 6: Results for the French?English task.
BLEU
Dev Test
phrase-based baseline 20.9 23.2
phrase-based (fa+mero+giga) 23.0 24.6
hierarchical baseline 20.6 22.5
hierarchical (shallow,+giga) 22.4 24.3
Table 7: Results for the English?French task.
language pairs, RWTH applied system combina-
tion. Altogether, by application of these meth-
ods RWTH was able to increase performance in
BLEU by 0.8% for German?English, 0.2% for
English?German, 1.0% for French?English and
1.4% for English?French on the test set over the
respective baseline systems.
Acknowledgments
This work was realized as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J. DeNero, D. Gillick, J. Zhang, and D. Klein. 2006.
Why Generative Phrase Models Underperform Sur-
face Heuristics. In Proceedings of the Workshop on
Statistical Machine Translation, pages 31?38.
J.G. Fiscus. 1997. A Post-Processing System to Yield
Reduced Word Error Rates: Recognizer Output Vot-
ing Error Reduction (ROVER). In IEEE Workshop
on Automatic Speech Recognition and Understand-
ing.
S. Hasan, J. Ganitkevitch, H. Ney, and J. Andre?s-
Ferrer. 2008. Triplet Lexicon Models for Statisti-
cal Machine Translation. In Proceedings of Emperi-
cal Methods of Natural Language Processing, pages
372?381.
G. Iglesias, A. de Gispert, E.R. Banga, and W. Byrne.
2009. Rule Filtering by Pattern for Efficient Hierar-
chical Translation. In Proceedings of the 12th Con-
ference of the European Chapter of the ACL (EACL
2009), pages 380?388.
P. Koehn and K. Knight. 2003. Empirical Methods for
Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
consensus translation from multiple machine trans-
lation systems using enhanced hypotheses align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Marino, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
A. Mauser, S. Hasan, and H. Ney. 2009. Extend-
ing Statistical Machine Translation with Discrimi-
native and Trigger-Based Lexicon Models. In Con-
ference on Empirical Methods in Natural Language
Processing, pages 210?217.
M. Popovic? and H. Ney. 2006. POS-based Word Re-
orderings for Statistical Machine Translation. In In-
ternational Conference on Language Resources and
Evaluation, pages 1278?1283.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Nat-
ural Language Processing, Springer Verlag, LNCS,
pages 616?624.
H. Schwenk and J. Senellart. 2009. Translation Model
Adaptation for an Arabic/French News Translation
System by Lightly-Supervised Training. In MT
Summit XII.
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
Phrase Translation Models with Leaving-One-Out.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics. To ap-
pear.
R. Zens and H. Ney. 2006. Discriminative Reorder-
ing Models for Statistical Machine Translation. In
Workshop on Statistical Machine Translation, pages
55?63.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statis-
tical Machine Translation. In International Work-
shop on Spoken Language Translation.
97
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 262?270,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Jane: Open Source Hierarchical Translation, Extended with Reordering
and Lexicon Models
David Vilar, Daniel Stein, Matthias Huck and Hermann Ney
Lehrstuhl fu?r Informatik 6
RWTH Aachen University
Aachen, Germany
{vilar,stein,huck,ney}@cs.rwth-aachen.de
Abstract
We present Jane, RWTH?s hierarchical
phrase-based translation system, which
has been open sourced for the scientific
community. This system has been in de-
velopment at RWTH for the last two years
and has been successfully applied in dif-
ferent machine translation evaluations. It
includes extensions to the hierarchical ap-
proach developed by RWTH as well as
other research institutions. In this paper
we give an overview of its main features.
We also introduce a novel reordering
model for the hierarchical phrase-based
approach which further enhances transla-
tion performance, and analyze the effect
some recent extended lexicon models have
on the performance of the system.
1 Introduction
We present a new open source toolkit for hi-
erarchical phrase-based translation, as described
in (Chiang, 2007). The hierarchical phrase model
is an extension of the standard phrase model,
where the phrases are allowed to have ?gaps?. In
this way, long-distance dependencies and reorder-
ings can be modelled in a consistent way. As in
nearly all current statistical approaches to machine
translation, this model is embedded in a log-linear
model combination.
RWTH has been developing this tool during
the last two years and it was used success-
fully in numerous machine translation evalua-
tions. It is developed in C++ with special at-
tention to clean code, extensibility and efficiency.
The toolkit is available under an open source
non-commercial license and downloadable from
http://www.hltpr.rwth-aachen.de/jane.
In this paper we give an overview of the main
features of the toolkit and introduce two new ex-
tensions to the hierarchical model. The first one
is an additional reordering model inspired by the
reordering widely used in phrase-based transla-
tion systems and the second one comprises two
extended lexicon models which further improve
translation performance.
2 Related Work
Jane implements many features presented in pre-
vious work developed both at RWTH and other
groups. As we go over the features of the system
we will provide the corresponding references.
Jane is not the first system of its kind, al-
though it provides some unique features. There
are other open source hierarchical decoders avail-
able. These include
? SAMT (Zollmann and Venugopal, 2006):
The original version is not maintained any
more and we had problems working on big
corpora. A new version which requires
Hadoop has just been released, however the
documentation is still missing.
? Joshua (Li et al, 2009): A decoder written
in Java by the John Hopkins University. This
project is the most similar to our own, how-
ever both were developed independently and
each one has some unique features. A brief
comparison between these two systems is in-
cluded in Section 5.1.
? Moses (Koehn et al, 2007): The de-facto
standard phrase-based translation decoder
has now been extended to support hierarchi-
cal translation. This is still in an experimental
branch, however.
3 Features
In this section we will only give a brief overview
of the features implemented in Jane. For de-
tailed explanation of previously published algo-
262
rithms and methods, we refer to the given litera-
ture.
3.1 Search Algorithms
The search for the best translation proceeds in two
steps. First, a monolingual parsing of the input
sentence is carried out using the CYK+ algorithm
(Chappelier and Rajman, 1998), a generalization
of the CYK algorithm which relaxes the require-
ment for the grammar to be in Chomsky normal
form. From the CYK+ chart we extract a hyper-
graph representing the parsing space.
In a second step the translations are generated,
computing the language model scores in an inte-
grated fashion. Both the cube pruning and cube
growing algorithms (Huang and Chiang, 2007) are
implemented. For the latter case, the extensions
concerning the language model heuristics similar
to (Vilar and Ney, 2009) have also been included.
3.2 Language Models
Jane supports four formats for n-gram language
models:
? The ARPA format for language models. We
use the SRI toolkit (Stolcke, 2002) to support
this format.
? The binary language model format supported
by the SRI toolkit. This format allows for a
more efficient language model storage, which
reduces loading times. In order to reduce
memory consumption, the language model
can be reloaded for every sentence, filtering
the n-grams that will be needed for scoring
the possible translations. This format is spe-
cially useful for this case.
? Randomized LMs as described in (Talbot and
Osborne, 2007), using the open source im-
plementation made available by the authors
of the paper. This approach uses a space ef-
ficient but approximate representation of the
set of n-grams in the language model. In
particular the probability for unseen n-grams
may be overestimated.
? An in-house, exact representation format
with on-demand loading of n-grams, using
the internal prefix-tree implementation which
is also used for phrase storage (see also Sec-
tion 3.9).
Several language models (also of mixed formats)
can be used during search. Their scores are com-
bined in the log-linear framework.
3.3 Syntactic Features
Soft syntactic features comparable to (Vilar et al,
2008) are implemented in the extraction step of
the toolkit. In search, they are considered as ad-
ditional feature functions of the translation rules.
The decoder is able to handle an arbitrary num-
ber of non-terminal symbols. The extraction has
been extended so that the extraction of SAMT-
rules is included (Zollmann and Venugopal, 2006)
but this approach is not fully supported (there
may be empty parses due to the extended num-
ber of non-terminals). We instead opted to sup-
port the generalization presented in (Venugopal et
al., 2009), where the information about the new
non-terminals is included as an additional feature
in the log-linear model.
In addition, dependency information in the
spirit of (Shen et al, 2008) is included. Jane fea-
tures models for string-to-dependency language
models and computes various scores based on the
well-formedness of the resulting dependency tree.
Jane supports the Stanford parsing format,1 but
can be easily extended to other parsers.
3.4 Additional Reordering Models
In the standard formulation of the hierarchical
phrase-based translation model two additional
rules are added:
S ? ?S?0X?1, S?0X?1?
S ? ?X?0, X?0?
(1)
This allows for a monotonic concatenation of
phrases, very much in the way monotonic phrase-
based translation is carried out.
It is a well-known fact that for phrase-based
translation, the use of additional reordering mod-
els is a key component, essential for achieving
good translation quality. In the hierarchical model,
the reordering is already integrated in the transla-
tion formalism, but there are still cases where the
required reorderings are not captured by the hier-
archical phrases alone.
The flexibility of the grammar formalism allows
us to add additional reordering models without the
need to explicitely modify the code for supporting
them. The most straightforward example would
1http://nlp.stanford.edu/software/lex-parser.shtml
263
be to include the ITG-Reorderings (Wu, 1997), by
adding following rule
S ? ?S?0S?1, S?1S?0? (2)
We can also model other reordering constraints.
As an example, phrase-level IBM reordering con-
straints with a window length of 1 can be included
substituting the rules in Equation (1) with follow-
ing rules
S ? ?M?0,M?0?
S ? ?M?0S?1,M?0S?1?
S ? ?B?0M?1,M?1B?0?
M ? ?X?0, X?0?
M ? ?M?0X?1,M?0X?1?
B ? ?X?0, X?0?
B ? ?B?0X?1, X?1B?0?
(3)
In these rules we have added two additional non-
terminals. The M non-terminal denotes a mono-
tonic block and the B non-terminal a back jump.
Actually both of them represent monotonic trans-
lations and the grammar could be simplified by
using only one of them. Separating them allows
for more flexibility, e.g. when restricting the jump
width, where we only have to restrict the maxi-
mum span width of the non-terminal B. These
rules can be generalized for other reordering con-
straints or window lengths.
Additionally distance-based costs can be com-
puted for these reorderings. To the best of our
knowledge, this is the first time such additional
reorderings have been applied to the hierarchical
phrase-based approach.
3.5 Extended Lexicon Models
We enriched Jane with the ability to score hy-
potheses with discriminative and trigger-based
lexicon models that use global source sentence
context and are capable of predicting context-
specific target words. This approach has recently
been shown to improve the translation results of
conventional phrase-based systems. In this sec-
tion, we briefly review the basic aspects of these
extended lexicon models. They are similar to
(Mauser et al, 2009), and we refer there for a more
detailed exposition on the training procedures and
results in conventional phrase-based decoding.
Note that the training for these models is not
distributed together with Jane.
3.5.1 Discriminative Word Lexicon
The first of the two lexicon models is denoted as
discriminative word lexicon (DWL) and acts as a
statistical classifier that decides whether a word
from the target vocabulary should be included in
a translation hypothesis. For that purpose, it con-
siders all the words from the source sentence, but
does not take any position information into ac-
count, i.e. it operates on sets, not on sequences or
even trees. The probability of a word being part
of the target sentence, given a set of source words,
are decomposed into binary features, one for each
source vocabulary entry. These binary features are
combined in a log-linear fashion with correspond-
ing feature weights. The discriminative word lex-
icon is trained independently for each target word
using the L-BFGS (Byrd et al, 1995) algorithm.
For regularization, Gaussian priors are utilized.
DWL model probabilities are computed as
p(e|f) =
?
e?VE
p(e?|f) ?
?
e?e
p(e+|f)
p(e?|f)
(4)
with VE being the target vocabulary, e the set of
target words in a sentence, and f the set of source
words, respectively. Here, the event e+ is used
when the target word e is included in the target
sentence and e? if not. As the left part of the prod-
uct in Equation (4) is constant given a source sen-
tence, it can be dropped, which enables us to score
partial hypotheses during search.
3.5.2 Triplet Lexicon
The second lexicon model we employ in Jane,
the triplet lexicon model, is in many aspects re-
lated to IBM model 1 (Brown et al, 1993), but
extends it with an additional word in the con-
ditioning part of the lexical probabilities. This
introduces a means for an improved representa-
tion of long-range dependencies in the data. Like
IBM model 1, the triplets are trained iteratively
with the Expectation-Maximization (EM) algo-
rithm (Dempster et al, 1977). Jane implements
the so-called inverse triplet model p(e|f, f ?).
The triplet lexicon model score t(?) of the ap-
plication of a rule X ? ??, ?? where (?, ?) is
a bilingual phrase pair that may contain symbols
from the non-terminal set is computed as
t(?, ?, fJ0 ) = (5)
?
?
e
log
?
?
2
J ? (J + 1)
?
j
?
j?>j
p(e|fj , fj?)
?
?
264
with e ranging over all terminal symbols in the tar-
get part ? of the rule. The second sum selects all
words from the source sentence fJ0 (including the
empty word that is denoted as f0 here). The third
sum incorporates the rest of the source sentence
right of the first triggering word. The order of
the triggers is not relevant because per definition
p(e|f, f ?) = p(e|f ?, f), i.e. the model is symmet-
ric. Non-terminals in ? have to be skipped when
the rule is scored.
In Jane, we also implemented scoring for a vari-
ant of the triplet lexicon model called the path-
constrained (or path-aligned) triplet model. The
characteristic of path-constrained triplets is that
the first trigger f is restricted to the aligned target
word e. The second trigger f ? is allowed to move
along the whole remaining source sentence. For
the training of the model, we use word alignment
information obtained by GIZA++ (Och and Ney,
2003). To be able to apply the model in search,
Jane has to be run with a phrase table that con-
tains word alignment for each phrase, too, with the
exception of phrases which are composed purely
of non-terminals. Jane?s phrase extraction can op-
tionally supply this information from the training
data.
(Hasan et al, 2008) and (Hasan and Ney, 2009)
employ similar techniques and provide some more
discussion on the path-aligned variant of the
model and other possible restrictions.
3.6 Forced Alignments
Jane has also preliminary support for forced align-
ments between a given source and target sentence.
Given a sentence in the source language and its
translation in the target language, we find the best
way the source sentence can be translated into
the given target sentence, using the available in-
ventory of phrases. This is needed for more ad-
vanced training approaches like the ones presented
in (Blunsom et al, 2008) or (Cmejrek et al, 2009).
As reported in these papers, due to the restrictions
in the phrase extraction process, not all sentences
in the training corpus can be aligned in this way.
3.7 Optimization Methods
Two method based on n-best for minimum error
rate training (MERT) of the parameters of the log-
linear model are included in Jane. The first one
is the procedure described in (Och, 2003), which
has become a standard in the machine translation
community. We use an in-house implementation
of the method.
The second one is the MIRA algorithm, first
applied for machine translation in (Chiang et al,
2009). This algorithm is more adequate when the
number of parameters to optimize is large.
If the Numerical Recipes library (Press et al,
2002) is available, an additional general purpose
optimization tool is also compiled. Using this
tool a single-best optimization procedure based on
the downhill simplex method (Nelder and Mead,
1965) is included. This method, however, can be
considered deprecated in favour of the above men-
tioned methods.
3.8 Parallelized operation
If the Sun Grid Engine2 is available, all operations
of Jane can be parallelized. For the extraction pro-
cess, the corpus is split into chunks (the granular-
ity being user-controlled) which are distributed in
the computer cluster. Count collection, marginal
computation and count normalization all happens
in an automatic and parallel manner.
For the translation process a batch job is started
on a number of computers. A server distributes the
sentences to translate to the computers that have
been made available to the translation job.
The optimization process also benefits from
the parallelized optimization. Additionally, for
the minimum error rate training methods, random
restarts may be performed on different computers
in a parallel fashion.
The same client-server infrastructure used for
parallel translation may also be reused for inter-
active systems. Although no code in this direction
is provided, one would only need to implement a
corresponding frontend which communicates with
the translation server (which may be located on an-
other machine).
3.9 Extensibility
One of the goals when implementing the toolkit
was to make it easy to extend it with new features.
For this, an abstract class was created which we
called secondary model. New models need only to
derive from this class and implement the abstract
methods for data reading and costs computation.
This allows for an encapsulation of the computa-
tions, which can be activated and deactivated on
demand. The models described in Sections 3.3
2http://www.sun.com/software/sge/
265
through 3.5 are implemented in this way. We thus
try to achieve loose coupling in the implementa-
tion.
In addition a flexible prefix tree implementation
with on-demand loading capabilities is included as
part of the code. This class has been used for im-
plementing on-demand loading of phrases in the
spirit of (Zens and Ney, 2007) and the on-demand
n-gram format described in Section 3.2, in addi-
tion to some intermediate steps in the phrase ex-
traction process. The code may also be reused in
other, independent projects.
3.10 Code
The main core of Jane has been implemented in
C++. Our guideline was to write code that was
correct, maintainable and efficient. We tried to
achieve correctness by means of unit tests inte-
grated in the source as well as regression tests. We
also defined a set of coding guidelines, which we
try to enforce in order to have readable and main-
tainable code. Examples include using descriptive
variable names, appending an underscore to pri-
vate members of classes or having each class name
start with an uppercase letter while variable names
start with lowercase letters.
The code is documented at great length using
the doxygen system,3 and the filling up of the
missing parts is an ongoing effort. Every tool
comes with an extensive help functionality, and
the main tools also have their own man pages.
As for efficiency we always try to speed up the
code and reduce memory consumption by imple-
menting better algorithms. We try to avoid ?dark
magic programming methods? and hard to follow
optimizations are only applied in critical parts of
the code. We try to document every such occur-
rence.
4 Experimental Results
In this section we will present some experimental
results obtained using Jane. We will pay special
attention to the performance of the new reordering
and lexicon models presented in this paper. We
will present results on three different large-scale
tasks and language pairs.
Additionally RWTH participated in this year?s
WMT evaluation, where Jane was one of the sub-
mitted systems. We refer to the system description
for supplementary experimental results.
3http://www.doxygen.org
dev test
System BLEU TER BLEU TER
Jane baseline 24.2 59.5 25.4 57.4
+ reordering 25.2 58.2 26.5 56.1
Table 1: Results for Europarl German-English
data. BLEU and TER results are in percentage.
4.1 Europarl Data
The first task is the Europarl as defined in the
Quaero project. The main part of the corpus in
this task consists of the Europarl corpus as used in
the WMT evaluation (Callison-Burch et al, 2009),
with some additional data collected in the scope of
the project.
We tried the reordering approach presented in
Section 3.4 on the German-English language pair.
The results are shown in Table 1. As can be seen
from these results, the additional reorderings ob-
tain nearly 1% improvement both in BLEU and
TER scores. Regrettably for this corpus the ex-
tended lexicon models did not bring any improve-
ments.
Table 2 shows the results for the French-English
language pair of the Europarl task. On this task
the extended lexicon models yield an improve-
ment over the baseline system of 0.9% in BLEU
and 0.9% in TER on the test set.
4.2 NIST Arabic-English
We also show results on the Arabic-English
NIST?08 task, using the NIST?06 set as develop-
ment set. It has been reported in other work that
the hierarchical system is not competitive with a
phrase-based system for this language pair (Birch
et al, 2009). We report the figures of our state-
of-the-art phrase-based system as comparison (de-
noted as PBT).
As can be seen from Table 3, the baseline
Jane system is in fact 0.6% worse in BLEU and
1.0% worse in TER than the baseline PBT sys-
tem. When we include the extended lexicon mod-
els we see that the difference in performance is re-
duced. For Jane the extended lexicon models give
an improvement of up to 1.9% in BLEU and 1.7%
in TER, respectively, bringing the system on par
with the PBT system extended with the same lex-
icon models, and obtaining an even slightly better
BLEU score.
266
dev test
BLEU TER BLEU TER
Baseline 30.0 52.6 31.1 50.0
DWL 30.4 52.2 31.4 49.6
Triplets 30.4 52.0 31.7 49.4
path-constrained Triplets 30.3 52.1 31.6 49.3
DWL + Triplets 30.7 52.0 32.0 49.1
DWL + path-constrained Triplets 30.8 51.7 31.6 49.3
Table 2: Results for the French-English task. BLEU and TER results are in percentage.
dev (MT?06) test (MT?08)
Jane PBT Jane PBT
BLEU TER BLEU TER BLEU TER BLEU TER
Baseline 43.2 50.8 44.1 49.4 44.1 50.1 44.7 49.1
DWL 45.3 48.7 45.1 48.4 45.6 48.4 45.6 48.4
Triplets 44.4 49.1 44.6 49.2 45.3 48.8 44.9 49.0
path-constrained Triplets 44.3 49.4 44.7 49.1 44.9 49.3 45.3 48.7
DWL + Triplets 45.0 48.9 45.1 48.5 45.3 48.6 45.5 48.5
DWL + path-constrained Triplets 45.2 48.8 45.1 48.6 46.0 48.5 45.8 48.3
Table 3: Results for the Arabic-English task. BLEU and TER results are in percentage.
5 Discussion
We feel that the hierarchical phrase-based transla-
tion approach still shares some shortcomings con-
cerning lexical selection with conventional phrase-
based translation. Bilingual lexical context be-
yond the phrase boundaries is barely taken into
account by the base model. In particular, if only
one generic non-terminal is used, the selection of
a sub-phrase that fills the gap of a hierarchical
phrase is not affected by the words composing the
phrase it is embedded in ? except for the language
model score. This shortcoming is one of the issues
syntactically motivated models try to address.
The extended lexicon models analyzed in this
work also try to address this issue. One can con-
sider that they complement the efforts that are be-
ing made on a deep structural level within the hi-
erarchical approach. Though they are trained on
surface forms only, without any syntactic informa-
tion, they still operate at a scope that exceeds the
capability of common feature sets of standard hi-
erarchical phrase-based SMT systems.
As the experiments in Section 4 show, the ef-
fect of these extended lexicon models is more im-
portant for the hierarchical phrase-based approach
than for the phrase-based approach. In our opinion
this is probably mainly due to the higher flexibil-
ity of the hierarchical system, both because of its
intrinsic nature and because of the higher number
of phrases extracted by the system. The scoring
of the phrases is still carried out by simple relative
frequencies, which seem to be insufficient. The
additional lexicon models seem to help in this re-
spect.
5.1 Short Comparison with Joshua
As mentioned in Section 2, Joshua is the most
similar decoder to our own. It was developed in
parallel at the Johns Hopkins University and it is
267
System words/sec
Joshua 11.6
Jane cube prune 15.9
Jane cube grow 60.3
Table 4: Speed comparison Jane vs. Joshua. We
measure the translated words per second.
currently used by a number of groups around the
world.
Jane was started separately and independently.
In their basic working mode, both systems imple-
ment parsing using a synchronous grammar and
include language model information. Each of the
projects then progressed independently, most of
the features described in Section 3 being only
available in Jane.
Efficiency is one of the points where we think
Jane outperforms Joshua. One of the reasons can
well be the fact that it is written in C++ while
Joshua is written in Java. In order to compare run-
ning times we converted a grammar extracted by
Jane to Joshua?s format and adapted the parame-
ters accordingly. To the best of our knowledge we
configured both decoders to perform the same task
(cube pruning, 300-best generation, same pruning
parameters). Except for some minor differences4
the results were equal.
We tried this setup on the IWSLT?08 Arabic to
English translation task. The speed results (mea-
sured in translated words per second) can be seen
in Table 4. Jane operating with cube prune is
nearly 50% faster than Joshua, at the same level
of translation performance. If we switch to cube
grow, the speed difference is even bigger, with
a speedup of nearly 4 times. However this usu-
ally comes with a penalty in BLEU score (nor-
mally under 0.5% BLEU in our experience). This
increased speed can be specially interesting for
applications like interactive machine translation
or online translation services, where the response
time is critical and sometimes even more impor-
tant than a small (and often hardly noticeable) loss
in translation quality.
Another important point concerning efficiency
is the startup time. Thanks to the binary format
described in Section 3.9, there is virtually no delay
4E.g. the OOVs seem to be handled in a slightly different
way, as the placement was sometimes different.
in the loading of the phrase table in Jane.5 In fact
Joshua?s long phrase table loading times were the
main reason the performance measures were done
on a small corpus like IWSLT instead of one of the
large tasks described in Section 4.
We want to make clear that we did not go into
great depth in the workings of Joshua, just stayed
at the basic level described in the manual. This
tool is used also for large-scale evaluations and
hence there certainly are settings for dealing with
these big tasks. Therefore this comparison has to
be taken with a grain of salt.
We also want to stress that we explicitly chose
to leave translation results out of this comparison.
Several different components have great impact
on translation quality, including phrase extraction,
minimum error training and additional parameter
settings of the decoder. As we pointed out we
do not have the expertise in Joshua to perform all
these tasks in an optimal way, and for that reason
we did not include such a comparison. However,
both JHU and RWTH participated in this year?s
WMT evaluation, where the systems, applied by
their respective authors, can be directly compared.
And in no way do we see Joshua and Jane as
?competing? systems. Having different systems
is always enriching, and particularly as system
combination shows great improvements in trans-
lation quality, having several alternative systems
can only be considered a positive situation.
6 Licensing
Jane is distributed under a custom open source
license. This includes free usage for non-
commercial purposes as long as any changes made
to the original software are published under the
terms of the same license. The exact formulation
is available at the download page for Jane.
7 Conclusion
With Jane, we release a state-of-the-art hi-
erarchical toolkit to the scientific community
and hope to provide a good starting point for
fellow researchers, allowing them to have a
solid system even if the research field is new
to them. It is available for download from
http://www.hltpr.rwth-aachen.de/jane. The
system in its current state is stable and efficient
enough to handle even large-scale tasks such as
5There is, however, still some delay when loading the lan-
guage model for some of the supported formats.
268
the WMT and NIST evaluations, while producing
highly competitive results.
Moreover, we presented additional reordering
and lexicon models that further enhance the per-
formance of the system.
And in case you are wondering, Jane is Just an
Acronym, Nothing Else. The name comes from
the character in the Ender?s Game series (Card,
1986).
Acknowledgments
Special thanks to the people who have contributed
code to Jane: Markus Freitag, Stephan Peitz, Car-
men Heger, Arne Mauser and Niklas Hoppe.
This work was partly realized as part of the
Quaero Programme, funded by OSEO, French
State agency for innovation, and also partly based
upon work supported by the Defense Advanced
Research Projects Agency (DARPA) under Con-
tract No. HR001-06-C-0023. Any opinions,
findings and conclusions or recommendations ex-
pressed in this material are those of the authors and
do not necessarily reflect the views of the DARPA.
References
Alexandra Birch, Phil Blunsom, and Miles Osborne.
2009. A Quantitative Analysis of Reordering Phe-
nomena. In Proc. of the Workshop on Statistical Ma-
chine Translation, pages 197?205, Athens, Greece,
March.
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A Discriminative Latent Variable Model for Statis-
tical Machine Translation. In Proc. of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 200?208, Columbus, Ohio,
June.
Peter F. Brown, Stephan A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263?311, June.
Richard H. Byrd, Peihuang Lu, Jorge Nocedal, and
Ciyou Zhu. 1995. A Limited Memory Algorithm
for Bound Constrained Optimization. SIAM Journal
on Scientific Computing, 16(5):1190?1208.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In
Proc. of the Workshop on Statistical Machine Trans-
lation, pages 1?28, Athens, Greece, March.
Orson Scott Card. 1986. Speaker for the Dead. Tor
Books.
Jean-Ce?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new Features for Statistical Machine Trans-
lation. In Proc. of the Human Language Technology
Conference / North American Chapter of the Associ-
ation for Computational Linguistics (HLT-NAACL),
pages 218?226, Boulder, Colorado, June.
David Chiang. 2007. Hierarchical Phrase-based
Translation. Computational Linguistics, 33(2):201?
228, June.
Martin Cmejrek, Bowen Zhou, and Bing Xiang. 2009.
Enriching SCFG Rules Directly From Efficient
Bilingual Chart Parsing. In Proc. of the Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 136?143, Tokyo, Japan.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum Likelihood from Incomplete
Data via the EM Algorithm. Journal of the Royal
Statistical Society Series B, 39(1):1?22.
Sas?a Hasan and Hermann Ney. 2009. Comparison of
Extended Lexicon Models in Search and Rescoring
for SMT. In Proc. of the Annual Meeting of the As-
sociation for Computational Linguistics (ACL), vol-
ume short papers, pages 17?20, Boulder, CO, USA,
June.
Sas?a Hasan, Juri Ganitkevitch, Hermann Ney, and
Jesu?s Andre?s-Ferrer. 2008. Triplet Lexicon Mod-
els for Statistical Machine Translation. In Proc. of
the Conference on Empirical Methods for Natural
Language Processing (EMNLP), pages 372?381.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proc. of the Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
144?151, Prague, Czech Republic, June.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proc. of the Annual Meeting of the Association for
Computational Linguistics (ACL), pages 177?180,
Prague, Czech Republic, June.
Zhifei Li, Chris Callison-Burch, Chris Dyer, San-
jeev Khudanpur, Lane Schwartz, Wren Thornton,
Jonathan Weese, and Omar Zaidan. 2009. Joshua:
An Open Source Toolkit for Parsing-Based Machine
Translation. In Proc. of the Workshop on Statisti-
cal Machine Translation, pages 135?139, Athens,
Greece, March.
269
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Proc. of the Conference on Empirical Methods
for Natural Language Processing (EMNLP), pages
210?218, Singapore, August.
John A. Nelder and Roger Mead. 1965. The Downhill
Simplex Method. Computer Journal, 7:308.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing for Statistical Machine Translation. In Proc. of
the Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
William H. Press, Saul A. Teukolsky, William T. Vet-
terling, and Brian P. Flannery. 2002. Numerical
Recipes in C++. Cambridge University Press, Cam-
bridge, UK.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008.
A New String-to-Dependency Machine Translation
Algorithm with a Target Dependency Language
Model. In Proc. of the Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
577?585, Columbus, Ohio, June.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Interna-
tional Conference on Spoken Language Processing
(ICSLP), volume 3, pages 901?904, Denver, Col-
orado, September.
David Talbot and Miles Osborne. 2007. Smoothed
Bloom Filter Language Models: Tera-scale LMs on
the Cheap. In Proc. of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 468?476, Prague, Czech
Republic, June.
Ashish Venugopal, Andreas Zollmann, N.A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Human
Language Technology Conference / North Ameri-
can Chapter of the Association for Computational
Linguistics (HLT-NAACL), pages 236?244, Boulder,
Colorado, June.
David Vilar and Hermann Ney. 2009. On LM Heuris-
tics for the Cube Growing Algorithm. In Proc. of
the Annual Conference of the European Association
for Machine Translation (EAMT), pages 242?249,
Barcelona, Spain, May.
David Vilar, Daniel Stein, and Hermann Ney. 2008.
Analysing Soft Syntax Features and Heuristics for
Hierarchical Phrase Based Machine Translation.
In Proc. of the International Workshop on Spo-
ken Language Translation (IWSLT), pages 190?197,
Waikiki, Hawaii, October.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Richard Zens and Hermann Ney. 2007. Efficient
Phrase-Table Representation for Machine Transla-
tion with Applications to Online MT and Speech
Translation. In Proc. of the Annual Meeting of the
Association for Computational Linguistics (ACL),
pages 492?499, Rochester, New York, April.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax Augmented Machine Translation via Chart Pars-
ing. In Proc. of the Human Language Technology
Conference / North American Chapter of the Associ-
ation for Computational Linguistics (HLT-NAACL),
pages 138?141, New York, June.
270
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405?412,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2011
Matthias Huck, Joern Wuebker, Christoph Schmidt, Markus Freitag, Stephan Peitz,
Daniel Stein, Arnaud Dagnelies, Saab Mansour, Gregor Leusch and Hermann Ney
RWTH Aachen University
Aachen, Germany
surname@cs.rwth-aachen.de
Abstract
This paper describes the statistical machine
translation (SMT) systems developed by
RWTH Aachen University for the translation
task of the EMNLP 2011 Sixth Workshop on
Statistical Machine Translation. Both phrase-
based and hierarchical SMT systems were
trained for the constrained German-English
and French-English tasks in all directions. Ex-
periments were conducted to compare differ-
ent training data sets, training methods and op-
timization criteria, as well as additional mod-
els on dependency structure and phrase re-
ordering. Further, we applied a system com-
bination technique to create a consensus hy-
pothesis from several different systems.
1 Overview
We sketch the baseline architecture of RWTH?s se-
tups for the WMT 2011 shared translation task by
providing an overview of our translation systems in
Section 2. In addition to the baseline features, we
adopted several novel methods, which will be pre-
sented in Section 3. Details on the respective se-
tups and translation results for the French-English
and German-English language pairs (in both trans-
lation directions) are given in Sections 4 and 5. We
finally conclude the paper in Section 6.
2 Translation Systems
For the WMT 2011 evaluation we utilized RWTH?s
state-of-the-art phrase-based and hierarchical trans-
lation systems as well as our in-house system com-
bination framework. GIZA++ (Och and Ney, 2003)
was employed to train word alignments, language
models have been created with the SRILM toolkit
(Stolcke, 2002).
2.1 Phrase-Based System
We applied a phrase-based translation (PBT) system
similar to the one described in (Zens and Ney, 2008).
Phrase pairs are extracted from a word-aligned bilin-
gual corpus and their translation probability in both
directions is estimated by relative frequencies. The
standard feature set moreover includes an n-gram
language model, phrase-level single-word lexicons
and word-, phrase- and distortion-penalties. To lexi-
calize reordering, a discriminative reordering model
(Zens and Ney, 2006a) is used. Parameters are opti-
mized with the Downhill-Simplex algorithm (Nelder
and Mead, 1965) on the word graph.
2.2 Hierarchical System
For the hierarchical setups described in this paper,
the open source Jane toolkit (Vilar et al, 2010) was
employed. Jane has been developed at RWTH and
implements the hierarchical approach as introduced
by Chiang (2007) with some state-of-the-art exten-
sions. In hierarchical phrase-based translation, a
weighted synchronous context-free grammar is in-
duced from parallel text. In addition to contiguous
lexical phrases, hierarchical phrases with up to two
gaps are extracted. The search is typically carried
out using the cube pruning algorithm (Huang and
Chiang, 2007). The standard models integrated into
our Jane systems are: phrase translation probabil-
ities and lexical translation probabilities on phrase
level, each for both translation directions, length
405
penalties on word and phrase level, three binary fea-
tures marking hierarchical phrases, glue rule, and
rules with non-terminals at the boundaries, source-
to-target and target-to-source phrase length ratios,
four binary count features and an n-gram language
model. The model weights are optimized with stan-
dard MERT (Och, 2003) on 100-best lists.
2.3 System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (Matusov et al, 2006;
Matusov et al, 2008). This approach includes an
enhanced alignment and reordering framework. A
lattice is built from the input hypotheses. The trans-
lation with the best score within the lattice according
to a couple of statistical models is selected as con-
sensus translation.
3 Translation Modeling
We incorporated several novel methods into our sys-
tems for the WMT 2011 evaluation. This section
provides a short survey of three of the methods
which we suppose to be of particular interest.
3.1 Language Model Data Selection
For the English and German language models,
we applied the data selection method proposed in
(Moore and Lewis, 2010). Each sentence is scored
by the difference in cross-entropy between a lan-
guage model trained from in-domain data and a lan-
guage model trained from a similar-sized sample of
the out-of-domain data. As in-domain data we used
the news-commentary corpus. The out-of-domain
data from which the data was selected are the news
crawl corpus for both languages and for English the
109 corpus and the LDC Gigaword data. We used a
3-gram trained with the SRI toolkit to compute the
cross-entropy. For the news crawl corpus, only 1/8
of the sentences were discarded. Of the 109 corpus
we retained 1/2 and of the LDC Gigaword data we
retained 1/4 of the sentences to train the language
models.
3.2 Phrase Model Training
For the German?English and French?English
translation tasks we applied a forced alignment pro-
cedure to train the phrase translation model with the
EM algorithm, similar to the one described in (DeN-
ero et al, 2006). Here, the phrase translation prob-
abilities are estimated from their relative frequen-
cies in the phrase-aligned training data. The phrase
alignment is produced by a modified version of the
translation decoder. In addition to providing a statis-
tically well-founded phrase model, this has the ben-
efit of producing smaller phrase tables and thus al-
lowing more rapid experiments. A detailed descrip-
tion of the training procedure is given in (Wuebker
et al, 2010).
3.3 Soft String-to-Dependency
Given a dependency tree of the target language,
we are able to introduce language models that span
over longer distances than the usual n-grams, as in
(Shen et al, 2008). To obtain dependency structures,
we apply the Stanford parser (Klein and Manning,
2003) on the target side of the training material.
RWTH?s open source hierarchical translation toolkit
Jane has been extended to include dependency infor-
mation in the phrase table and to build dependency
trees on the output hypotheses at decoding time from
this information.
Shen et al (2008) use only phrases that meet cer-
tain restrictions. The first possibility is what the au-
thors call a fixed dependency structure. With the
exception of one word within this phrase, called
the head, no outside word may have a dependency
within this phrase. Also, all inner words may only
depend on each other or on the head. For a second
structure, called a floating dependency structure, the
head dependency word may also exist outside the
phrase. If the dependency structure of a phrase con-
forms to these restrictions, it is denoted as valid.
In our phrase table, we mark those phrases that
possess a valid dependency structure with a binary
feature, but all phrases are retained as translation op-
tions. In addition to storing the dependency informa-
tion, we also memorize for all hierarchical phrases
if the content of gaps has been dependent on the left
or on the right side. We utilize the dependency in-
formation during the search process by adding three
406
French English
Sentences 3 710 985
Running Words 98 352 916 87 689 253
Vocabulary 179 548 216 765
Table 1: Corpus statistics of the preprocessed high-
quality training data (Europarl, news-commentary, and
selected parts of the 109 and UN corpora) for the
RWTH systems for the WMT 2011 French?English and
English?French translation tasks. Numerical quantities
are replaced by a single category symbol.
features to the log-linear model: merging errors to
the left, merging errors to the right, and the ratio of
valid vs. non-valid dependency structures. The de-
coder computes the corresponding costs when it tries
to construct a dependency tree of a (partial) hypothe-
sis on-the-fly by merging the dependency structures
of the used phrase pairs.
In an n-best reranking step, we compute depen-
dency language model scores on the dependencies
which were assembled on the hypotheses by the
search procedure. We apply one language model
for left-side dependencies and one for right-side de-
pendencies. For head structures, we also compute
their scores by exploiting a simple unigram language
model. We furthermore include a language count
feature that is incremented each time we compute
a dependency language model score. As trees with
few dependencies have less individual costs to be
computed, they tend to obtain lower overall costs
than trees with more complex structures in other
sentences. The intention behind this feature is thus
comparable to the word penalty in combination with
a normal n-gram language model.
4 French-English Setups
We set up both hierarchical and standard phrase-
based systems for the constrained condition of the
WMT 2011 French?English and English?French
translation tasks. The English?French RWTH pri-
mary submission was produced with a single hierar-
chical system, while a system combination of three
systems was used to generate a final hypothesis for
the French?English primary submission.
Besides the Europarl and news-commentary cor-
pora, the provided parallel data also comprehends
French English
Sentences 29 996 228
Running Words 916 347 538 778 544 843
Vocabulary 1 568 089 1 585 093
Table 2: Corpus statistics of the preprocessed full training
data for the RWTH primary system for the WMT 2011
English?French translation task. Numerical quantities
are replaced by a single category symbol.
the large French-English 109 corpus and the French-
English UN corpus. Since model training with
such a huge amount of data requires a consider-
able computational effort, RWTH decided to select
a high-quality part of altogether about 2 Mio. sen-
tence pairs from the latter two corpora. The selec-
tion of parallel sentences was carried out according
to three criteria: (1) Only sentences of minimum
length of 4 tokens are considered, (2) at least 92%
of the vocabulary of each sentence occurs in new-
stest2008, and (3) the ratio of the vocabulary size
of a sentence and the number of its tokens is mini-
mum 80%. Word alignments in both directions were
trained with GIZA++ and symmetrized according to
the refined method that was proposed in (Och and
Ney, 2003). The phrase tables of the translation
systems are extracted from the Europarl and news-
commentary parallel training data as well as the se-
lected high-quality parts the 109 and UN corpora
only. The only exception is the hierarchical system
used for the English?French RWTH primary sub-
mission which comprehends a second phrase table
with lexical (i.e. non-hierarchical) phrases extracted
from the full parallel data (approximately 30 Mio.
sentence pairs).
Detailed statistics of the high-quality parallel
training data (Europarl, news-commentary, and the
selected parts of the 109 and UN corpora) are given
in Table 1, the corpus statistics of the full parallel
data from which the second phrase table with lexi-
cal phrases for the English?French RWTH primary
system was created are presented in Table 2.
The translation systems use large 4-gram lan-
guage models with modified Kneser-Ney smooth-
ing. The French language model was trained on
most of the provided French data including the
monolingual LDC Gigaword corpora, the English
407
newstest2009 newstest2010
French?English BLEU TER BLEU TER
System combination of ? systems (primary) 26.7 56.0 27.4 54.9
PBT with triplet lexicon, no forced alignment (contrastive) ? 26.2 56.7 27.2 55.3
Jane as below + improved LM (contrastive) 26.3 57.4 26.7 56.2
Jane with parse match + syntactic labels + dependency ? 26.2 57.5 26.5 56.4
PBT with forced alignment phrase training ? 26.0 57.1 26.3 56.0
Table 3: RWTH systems for the WMT 2011 French?English translation task (truecase). BLEU and TER results are
in percentage.
newstest2009 newstest2010
English?French BLEU TER BLEU TER
Jane shallow + in-domain TM + lexical phrases from full data 25.3 60.1 27.1 57.2
Jane shallow + in-domain TM + triplets + DWL + parse match 24.8 60.5 26.6 57.5
PBT with triplets, DWL, sentence-level word lexicon, discrim. reord. 24.8 60.1 26.5 57.3
Table 4: RWTH systems for the WMT 2011 English?French translation task (truecase). BLEU and TER results are
in percentage.
language model was trained on automatically se-
lected English data (cf. Section 3.1) from the pro-
vided resources including the 109 corpus and LDC
Gigaword.
The scaling factors of the log-linear model com-
bination are optimized towards BLEU on new-
stest2009, newstest2010 is used as an unseen test set.
4.1 Experimental Results French?English
The results for the French?English task are given in
Table 3. RWTH?s three submissions ? one primary
and two contrastive ? are labeled accordingly in the
table. The first contrastive submission is a phrase-
based system with a standard feature set plus an ad-
ditional triplet lexicon model (Mauser et al, 2009).
The triplet lexicon model was trained on in-domain
news commentary data only. The second contrastive
submission is a hierarchical Jane system with three
syntax-based extensions: A parse match model (Vi-
lar et al, 2008), soft syntactic labels (Stein et al,
2010), and the soft string-to-dependency extension
as described in Section 3.3. The primary submis-
sion combines the phrase-based contrastive system,
a hierarchical system that is very similar to the Jane
contrastive submission but with a slightly worse lan-
guage model, and an additional PBT system that has
been trained with forced alignment (Wuebker et al,
2010) on WMT 2010 data only.
4.2 Experimental Results English?French
The results for the English?French task are given
in Table 4. We likewise submitted two contrastive
systems for this translation direction. The first con-
trastive submission is a phrase-based system, en-
hanced with a triplet lexicon model and a discrim-
inative word lexicon model (Mauser et al, 2009) ?
both trained on in-domain news commentary data
only ? as well as a sentence-level single-word lex-
icon model and a discriminative reordering model
(Zens and Ney, 2006a). The second contrastive sub-
mission is a hierarchical Jane system with shallow
rules (Iglesias et al, 2009), a triplet lexicon model, a
discriminative word lexicon, the parse match model,
and a second phrase table extracted from in-domain
data only. Our primary submission is very similar
to the latter Jane setup. It does not comprise the ex-
tended lexicon models and the parse match exten-
sion, but instead includes lexical phrases from the
full 30 Mio. sentence corpus as described above.
5 German-English Setups
We trained phrase-based and hierarchical transla-
tion systems for both translation directions of the
German-English language pair. The corpus statis-
408
German English
Sentences 1 857 745
Running Words 48 449 977 50 559 217
Vocabulary 387 593 123 470
Table 5: Corpus statistics of the preprocessed train-
ing data for the WMT 2011 German?English and
English?German translation tasks. Numerical quantities
are replaced by a single category symbol.
tics can be found in Table 5. Word alignments were
generated with GIZA++ and symmetrized as for the
French-English setups.
The language models are 4-grams trained on the
bilingual data as well as the provided News crawl
corpus. For the English language model the 109
French-English and LDC Gigaword corpora were
used additionally. For the 109 French-English and
LDC Gigaword corpora RWTH applied the data se-
lection technique described in Section 3.1. We ex-
amined two different language models, one with
LDC data and one without.
Systems were optimized on the newstest2009 data
set, newstest2008 was used as test set. The scores
for newstest2010 are included for completeness.
5.1 Morpho-Syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the source side
was preprocessed by splitting German compound
words with the frequency-based method described
in (Koehn and Knight, 2003). To further reduce
translation complexity, we performed the long-range
part-of-speech based reordering rules proposed by
(Popovic? et al, 2006). For additional experiments
we used the TreeTagger (Schmid, 1995) to produce
a lemmatized version of the German source.
5.2 Optimization Criterion
We studied the impact of different optimization cri-
teria on tranlsation performance. The usual prac-
tice is to optimize the scaling factors to maximize
BLEU. We also experimented with two different
combinations of BLEU and Translation Edit Rate
(TER): TER?BLEU and TER?4BLEU. The first
denotes the equally weighted combination, while for
the latter BLEU is weighted 4 times as strong as
TER.
5.3 Experimental Results German?English
For the German?English task we conducted ex-
periments comparing the standard phrase extraction
with the phrase training technique described in Sec-
tion 3.2. For the latter we applied log-linear phrase-
table interpolation as proposed in (Wuebker et al,
2010). Further experiments included the use of addi-
tional language model training data, reranking of n-
best lists generated by the phrase-based system, and
different optimization criteria. We also carried out
a system combination of several systems, including
phrase-based systems on lemmatized German and
on source data without compound splitting and two
hierarchical systems optimized for different criteria.
The results are given in Table 6.
A considerable increase in translation quality can
be achieved by application of German compound
splitting. The system that operates on German
surface forms without compound splitting (SUR)
clearly underperforms the baseline system with mor-
phological preprocessing. The system on lemma-
tized German (LEM) is at about the same level as
the system on surface forms.
In comparison to the standard heuristic phrase ex-
traction technique, performing phrase training (FA)
gives an improvement in BLEU on newstest2008
and newstest2009, but a degradation in TER. The
addition of LDC Gigaword corpora (+GW) to the
language model training data shows improvements
in both BLEU and TER. Reranking was done on
1000-best lists generated by the the best available
system (PBT (FA)+GW). Following models were
applied: n-gram posteriors (Zens and Ney, 2006b),
sentence length model, a 6-gram LM and single-
word lexicon models in both normal and inverse di-
rection. These models are combined in a log-linear
fashion and the scaling factors are tuned in the same
manner as the baseline system (using TER?4BLEU
on newstest2009).
The table includes three identical Jane systems
which are optimized for different criteria. The one
optimized for TER?4BLEU offers the best balance
between BLEU and TER, but was not finished in
time for submission. As primary submission we
chose the reranked PBT system, as secondary the
system combination.
409
newstest2008 newstest2009 newstest2010
German?English opt criterion BLEU TER BLEU TER BLEU TER
Syscombi of ? (secondary) TER?BLEU 21.1 62.1 20.8 61.2 23.7 59.2
Jane +GW ? BLEU 21.5 63.9 21.0 63.3 22.9 61.7
Jane +GW TER?4BLEU 21.4 62.6 21.1 62.0 23.5 60.3
PBT (FA) rerank +GW (primary) ? TER?4BLEU 21.4 62.8 21.1 61.9 23.4 60.1
PBT (FA) +GW ? TER?4BLEU 21.1 63.0 21.1 62.2 23.3 60.3
Jane +GW ? TER?BLEU 20.9 61.1 20.4 60.5 23.4 58.3
PBT (FA) TER?4BLEU 21.1 63.2 20.6 62.4 23.2 60.4
PBT TER?4BLEU 20.6 62.7 20.3 61.9 23.3 59.7
PBT (SUR) ? TER?4BLEU 19.5 66.5 18.9 65.8 21.0 64.9
PBT (LEM) ? TER?4BLEU 19.2 66.1 18.9 65.4 21.0 63.5
Table 6: RWTH systems for the WMT 2011 German?English translation task (truecase). BLEU and TER results
are in percentage. FA denotes systems with phrase training, +GW the use of LDC data for the language model.
SUR and LEM denote the systems without compound splitting and on the lemmatized source, respectively. The three
hierarchical Jane systems are identical, but used different parameter optimization criterea.
newstest2008 newstest2009 newstest2010
English?German opt criterion BLEU TER BLEU TER BLEU TER
PBT + discrim. reord. (primary) TER?4BLEU 15.3 70.2 15.1 69.8 16.2 65.6
PBT + discrim. reord. BLEU 15.2 70.6 15.2 70.1 16.2 66.0
PBT TER?4BLEU 15.2 70.7 15.2 70.2 16.2 66.1
Jane BLEU 15.1 72.1 15.4 71.2 16.4 67.4
Jane TER?4BLEU 15.1 68.4 14.6 69.5 14.6 65.9
Table 7: RWTH systems for the WMT 2011 English?German translation task (truecase). BLEU and TER results are
in percentage.
5.4 Experimental Results English?German
We likewise studied the effect of using BLEU only
versus using TER?4BLEU as optimization crite-
rion in the English?German translation direction.
Moreover, we tested the impact of the discriminative
reordering model (Zens and Ney, 2006a). The re-
sults can be found in Table 7. For the phrase-based
system, optimizing towards TER?4BLEU leads to
slightly better results both in BLEU and TER than
optimizing towards BLEU. Using the discriminative
reordering model yields some improvements both on
newstest2008 and newstest2010. In the case of the
hierarchical system, the effect of the optimization
criterion is more pronounced than for the phrase-
based system. However, in this case it clearly leads
to a tradeoff between BLEU and TER, as the choice
of TER?4BLEU harms the translation results of
test2010 with respect to BLEU.
6 Conclusion
For the participation in the WMT 2011 shared trans-
lation task, RWTH experimented with both phrase-
based and hierarchical translation systems. We used
all bilingual and monolingual data provided for the
constrained track. To limit the size of the lan-
guage model, a data selection technique was applied.
Several techniques yielded improvements over the
baseline, including three syntactic models, extended
lexicon models, a discriminative reordering model,
forced alignment training, reranking methods and
different optimization criteria.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
410
References
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J. DeNero, D. Gillick, J. Zhang, and D. Klein. 2006.
Why Generative Phrase Models Underperform Surface
Heuristics. In Proceedings of the Workshop on Statis-
tical Machine Translation, pages 31?38.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
G. Iglesias, A. de Gispert, E.R. Banga, and W. Byrne.
2009. Rule Filtering by Pattern for Efficient Hierar-
chical Translation. In Proceedings of the 12th Con-
ference of the European Chapter of the ACL (EACL
2009), pages 380?388.
D. Klein and C.D. Manning. 2003. Accurate Unlexi-
calized Parsing. In Proceedings of the 41st Annual
Meeting on Association for Computational Linguistics
- Volume 1, ACL ?03, pages 423?430.
P. Koehn and K. Knight. 2003. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Marino, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
A. Mauser, S. Hasan, and H. Ney. 2009. Extending Sta-
tistical Machine Translation with Discriminative and
Trigger-Based Lexicon Models. In Conference on
Empirical Methods in Natural Language Processing,
pages 210?217.
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short Pa-
pers), pages 220?224, Uppsala, Sweden, July.
J.A. Nelder and R. Mead. 1965. The Downhill Simplex
Method. Computer Journal, 7:308.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Natural
Language Processing, Springer Verlag, LNCS, pages
616?624.
H. Schmid. 1995. Improvements in Part-of-Speech Tag-
ging with an Application to German. In Proceedings
of the ACL SIGDAT-Workshop, pages 47?50, Dublin,
Ireland, March.
L. Shen, J. Xu, and R. Weischedel. 2008. A New String-
to-Dependency Machine Translation Algorithm with a
Target Dependency Language Model. In Proceedings
of ACL-08: HLT. Association for Computational Lin-
guistics, pages 577?585, June.
D. Stein, S. Peitz, D. Vilar, and H. Ney. 2010. A Cocktail
of Deep Syntactic Features for Hierarchical Machine
Translation. In Conference of the Association for Ma-
chine Translation in the Americas 2010, page 9, Den-
ver, USA, October.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901 ? 904, Denver, Col-
orado, USA, September.
D. Vilar, D. Stein, and H. Ney. 2008. Analysing Soft
Syntax Features and Heuristics for Hierarchical Phrase
Based Machine Translation. In Proc. of the Int. Work-
shop on Spoken Language Translation (IWSLT), pages
190?197, Waikiki, Hawaii, October.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
Phrase Translation Models with Leaving-One-Out. In
Proceedings of the 48th Annual Meeting of the Assoc.
for Computational Linguistics, pages 475?484, Upp-
sala, Sweden, July.
R. Zens and H. Ney. 2006a. Discriminative Reordering
Models for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 55?63, New York City, June.
R. Zens and H. Ney. 2006b. N-gram Posterior Proba-
bilities for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 72?77, New York City, June.
411
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
412
Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 91?96,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Lightly-Supervised Training for Hierarchical Phrase-Based Machine
Translation
Matthias Huck1 and David Vilar1,2 and Daniel Stein1 and Hermann Ney1
1 Human Language Technology and Pattern 2 DFKI GmbH
Recognition Group, RWTH Aachen University Berlin, Germany
<surname>@cs.rwth-aachen.de david.vilar@dfki.de
Abstract
In this paper we apply lightly-supervised
training to a hierarchical phrase-based statis-
tical machine translation system. We employ
bitexts that have been built by automatically
translating large amounts of monolingual data
as additional parallel training corpora. We ex-
plore different ways of using this additional
data to improve our system.
Our results show that integrating a second
translation model with only non-hierarchical
phrases extracted from the automatically gen-
erated bitexts is a reasonable approach. The
translation performance matches the result we
achieve with a joint extraction on all train-
ing bitexts while the system is kept smaller
due to a considerably lower overall number of
phrases.
1 Introduction
We investigate the impact of an employment of large
amounts of unsupervised parallel data as training
data for a statistical machine translation (SMT) sys-
tem. The unsupervised parallel data is created by au-
tomatically translating monolingual source language
corpora. This approach is called lightly-supervised
training in the literature and has been introduced by
Schwenk (2008). In contrast to Schwenk, we do not
apply lightly-supervised training to a conventional
phrase-based system (Och et al, 1999; Koehn et al,
2003) but to a hierarchical phrase-based translation
(HPBT) system.
In hierarchical phrase-based translation (Chiang,
2005) a weighted synchronous context-free gram-
mar is induced from parallel text, the search is
based on CYK+ parsing (Chappelier and Rajman,
1998) and typically carried out using the cube prun-
ing algorithm (Huang and Chiang, 2007). In addi-
tion to the contiguous lexical phrases as in standard
phrase-based translation, the hierarchical phrase-
based paradigm also allows for phrases with gaps
which are called hierarchical phrases. A generic
non-terminal symbol serves as a placeholder that
marks the gaps.
In this paper we study several different ways
of incorporating unsupervised training data into
a hierarchical system. The basic techniques we
employ are the use of multiple translation mod-
els and a distinction of the hierarchical and the
non-hierarchical (i.e. lexical) part of the transla-
tion model. We report experimental results on
the large-scale NIST Arabic-English translation task
and show that lightly-supervised training yields sig-
nificant gains over the baseline.
2 Related Work
Large-scale lightly-supervised training for SMT as
we define it in this paper has been first carried out
by Schwenk (2008). Schwenk translates a large
amount of monolingual French data with an initial
Moses (Koehn et al, 2007) baseline system into En-
glish. In Schwenk?s original work, an additional
bilingual dictionary is added to the baseline. With
lightly-supervised training, Schwenk achieves im-
provements of around one BLEU point over the
baseline. In a later work (Schwenk and Senellart,
2009) he applies the same method for translation
model adaptation on an Arabic-French task with
91
gains of up to 3.5 points BLEU. 1
Hierarchical phrase-based translation has been pi-
oneered by David Chiang (Chiang, 2005; Chiang,
2007) with his Hiero system. The hierarchical
paradigm has been implemented and extended by
several groups since, some have published their soft-
ware as open source (Li et al, 2009; Hoang et al,
2009; Vilar et al, 2010).
Combining multiple translation models has been
investigated for domain adaptation by Foster and
Kuhn (2007) and Koehn and Schroeder (2007) be-
fore. Heger et al (2010) exploit the distinction be-
tween hierarchical and lexical phrases in a similar
way as we do. They train phrase translation proba-
bilities with forced alignment using a conventional
phrase-based system (Wuebker et al, 2010) and em-
ploy them for the lexical phrases while the hierarchi-
cal phrases stay untouched.
3 Using the Unsupervised Data
The most straightforward way of trying to improve
the baseline with lightly-supervised training would
be to concatenate the human-generated parallel data
and the unsupervised data and to jointly extract
phrases from the unified parallel data (after having
trained word alignments for the unsupervised bitexts
as well). This method is simple and expected to
be effective usually. There may however be two
drawbacks: First, the reliability and the amount of
parallel sentences may differ between the human-
generated and the unsupervised part of the training
data. It might be desirable to run separate extrac-
tions on the two corpora in order to be able to dis-
tinguish and weight phrases (or rather their scores)
according to their origin during decoding. Second, if
we incorporate large amounts of additional unsuper-
vised data, the amount of phrases that are extracted
may become much larger. We would want to avoid
blowing up our phrase table sizes without an appro-
1Schwenk names the method lightly-supervised training be-
cause the topics that are covered in the monolingual source lan-
guage data that is being translated may potentially also be cov-
ered by parts of the language model training data of the system
which is used to translate them. This can be considered as a
form of light supervision. We loosely apply the term lightly-
supervised training if we mean the process of utilizing a ma-
chine translation system to produce additional bitexts that are
used as training data, but still refer to the automatically pro-
duced bilingual corpora as unsupervised data.
Arabic English
Sentences 2 514 413
Running words 54 324 372 55 348 390
Vocabulary 264 528 207 780
Singletons 115 171 91 390
Table 1: Data statistics for the preprocessed Arabic-
English parallel training corpus. In the corpus, numer-
ical quantities have been replaced by a special category
symbol.
dev (MT06) test (MT08)
Sentences 1 797 1 360
Running words 49 677 45 095
Vocabulary 9 274 9 387
OOV [%] 0.5 0.4
Table 2: Data statistics for the preprocessed Arabic part
of the dev and test corpora. In the corpus, numerical
quantities have been replaced by a special category sym-
bol.
priate effect on translation quality. This holds in par-
ticular in the case of hierarchical phrases. Phrase-
based machine translation systems are usually able
to correctly handle local context dependencies, but
often have problems in producing a fluent sentence
structure across long distances. It is thus an intuitive
supposition that using hierarchical phrases extracted
from unsupervised data in addition to the hierar-
chical phrases extracted from the presumably more
reliable human-generated bitexts does not increase
translation quality. We will compare a joint extrac-
tion to the usage of two separate translation mod-
els (either without separate weighting, with a binary
feature, or as a log-linear mixture). We will further
check if including hierarchical phrases from the un-
supervised data is beneficial or not.
4 Experiments
We use the open source Jane toolkit (Vilar et al,
2010) for our experiments, a hierarchical phrase-
based translation software written in C++.
4.1 Baseline System
The baseline system has been trained using a
human-generated parallel corpus of 2.5M Arabic-
English sentence pairs. Word alignments in both
92
directions were produced with GIZA++ and sym-
metrized according to the refined method that was
suggested by Och and Ney (2003).
The models integrated into our baseline system
are: phrase translation probabilities and lexical
translation probabilities for both translation direc-
tions, length penalties on word and phrase level,
three binary features marking hierarchical phrases,
glue rule, and rules with non-terminals at the bound-
aries, four simple additional count- and length-
based binary features, and a large 4-gram language
model with modified Kneser-Ney smoothing that
was trained with the SRILM toolkit (Stolcke, 2002).
We ran the cube pruning algorithm, the depth of
the hierarchical recursion was restricted to one by
using shallow rules as proposed by Iglesias et al
(2009).
The scaling factors of the log-linear model com-
bination have been optimized towards BLEU with
MERT (Och, 2003) on the MT06 NIST test corpus.
MT08 was employed as held-out test data. Detailed
statistics for the parallel training data are given in
Table 1, for the development and the test corpus in
Table 2.
4.2 Unsupervised Data
The unsupervised data that we integrate has been
created by automatic translations of parts of the
Arabic LDC Gigaword corpus (mostly from the
HYT collection) with a standard phrase-based sys-
tem (Koehn et al, 2003). We thus in fact conduct a
cross-system and cross-paradigm variant of lightly-
supervised training. Translating the monolingual
Arabic data has been performed by LIUM, Le Mans,
France. We thank Holger Schwenk for kindly pro-
viding the translations.
The score computed by the decoder for each
translation has been normalized with respect to the
sentence length and used to select the most reliable
sentence pairs. Word alignments for the unsuper-
vised data have been produced in the same way as
for the baseline bilingual training data. We report
the statistics of the unsupervised data in Table 3.
4.3 Translation Models
We extracted three different phrase tables, one from
the baseline human-generated parallel data only,
one from the unsupervised data only, and one joint
Arabic English
Sentences 4 743 763
Running words 121 478 207 134 227 697
Vocabulary 306 152 237 645
Singletons 130 981 102 251
Table 3: Data statistics for the Arabic-English unsuper-
vised training corpus after selection of the most reliable
sentence pairs. In the corpus, numerical quantities have
been replaced by a special category symbol.
phrase table from the concatenation of the baseline
data and the unsupervised data. We will denote the
different extractions as baseline, unsupervised, and
joint, respectively.
The conventional restrictions have been applied
for phrase extraction in all conditions, i.e. a maxi-
mum length of ten words on source and target side
for lexical phrases, a length limit of five (including
non-terminal symbols) on source side and ten on tar-
get side for hierarchical phrases, and at most two
non-terminals per rule which are not allowed to be
adjacent on the source side. To limit the number of
hierarchical phrases, a minimum count cutoff of one
and an extraction pruning threshold of 0.1 have been
applied to them. Note that we did not prune lexical
phrases.
Statistics on the phrase table sizes are presented
in Table 4.2 In total the joint extraction results in
almost three times as many phrases as the baseline
extraction. The extraction from the unsupervised
data exclusively results in more than two times as
many hierarchical phrases as from the baseline data.
The sum of the number of hierarchical phrases from
baseline and unsupervised extraction is very close
to the number of hierarchical phrases from the joint
extraction. If we discard the hierarchical phrases ex-
tracted from the unsupervised data and use the lex-
ical part of the unsupervised phrase table (27.3M
phrases) as a second translation model in addition to
the baseline phrase table (67.0M phrases), the over-
all number of phrases is increased by only 41% com-
pared to the baseline system.
2The phrase tables have been filtered towards the phrases
needed for the translation of a given collection of test corpora.
93
number of phrases
lexical hierarchical total
extraction from baseline data 19.8M 47.2M 67.0M
extraction from unsupervised data 27.3M 115.6M 142.9M
phrases present in both tables 15.0M 40.1M 55.1M
joint extraction baseline + unsupervised 32.1M 166.5M 198.6M
Table 4: Phrase table sizes. The phrase tables have been filtered towards a larger set of test corpora containing a total
of 2.3 million running words.
dev (MT06) test (MT08)
BLEU TER BLEU TER
[%] [%] [%] [%]
HPBT baseline 44.1 49.9 44.4?0.9 49.4?0.8
HPBT unsupervised only 45.3 48.8 45.2 49.1
joint extraction baseline + unsupervised 45.6 48.7 45.4?0.9 49.1?0.8
baseline hierarchical phrases + unsupervised lexical phrases 45.1 49.1 45.2 49.2
baseline hierarchical phrases + joint extraction lexical phrases 45.3 48.7 45.3 49.1
baseline + unsupervised lexical phrases 45.3 48.9 45.3 49.0
baseline + unsupervised lexical phrases (with binary feature) 45.3 48.8 45.4 49.0
baseline + unsupervised lexical phrases (separate scaling factors) 45.3 48.9 45.0 49.3
baseline + unsupervised full table 45.6 48.6 45.1 48.9
baseline + unsupervised full table (with binary feature) 45.5 48.6 45.2 48.8
baseline + unsupervised full table (separate scaling factors) 45.5 48.7 45.3 49.0
Table 5: Results for the NIST Arabic-English translation task (truecase). The 90% confidence interval is given for the
baseline system as well as for the system with joint phrase extraction. Results in bold are significantly better than the
baseline.
4.4 Experimental Results
The empirical evaluation of all our systems on the
two standard metrics BLEU (Papineni et al, 2002)
and TER (Snover et al, 2006) is presented in Ta-
ble 5. We have also checked the results for statistical
significance over the baseline. The confidence in-
tervals have been computed using bootstrapping for
BLEU and Cochran?s approximate ratio variance for
TER (Leusch and Ney, 2009).
When we combine the full baseline phrase ta-
ble with the unsupervised phrase table or the lexi-
cal part of it, we either use common scaling factors
for their source-to-target and target-to-source trans-
lation costs, or we use common scaling factors but
mark entries from the unsupervised table with a bi-
nary feature, or we optimize the four translation fea-
tures separately for each of the two tables as part of
the log-linear model combination.
Including the unsupervised data leads to a sub-
stantial gain on the unseen test set of up to +1.0%
BLEU absolute. The different ways of combining
the manually produced data with the unsupervised
have little impact on translation quality. This holds
specifically for the combination with only the lexical
phrases, which, when marked with a binary feature,
is able to obtain the same results as the full (joint
extraction) system but with much less phrases. We
compared the decoding speed of these two setups
and observed that the system with less phrases is
clearly faster (5.5 vs. 2.6 words per second, mea-
sured on MT08). The memory requirements of the
systems do not differ greatly as we are using a bi-
narized representation of the phrase table with on-
demand loading. All setups consume slightly less
than 16 gigabytes of RAM.
94
5 Conclusion
We presented several approaches of applying
lightly-supervised training to hierarchical phrase-
based machine translation. Using the additional au-
tomatically produced bitexts we have been able to
obtain considerable gains compared to the baseline
on the large-scale NIST Arabic-to-English transla-
tion task. We showed that a joint phrase extraction
from human-generated and automatically generated
parallel training data is not required to achieve sig-
nificant improvements. The same translation qual-
ity can be achieved by adding a second translation
model with only lexical phrases extracted from the
automatically created bitexts. The overall amount of
phrases can thus be kept much smaller.
Acknowledgments
The authors would like to thank Holger Schwenk
from LIUM, Le Mans, France, for making the au-
tomatic translations of the Arabic LDC Gigaword
corpus available. This work was partly supported
by the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-08-C-0110.
Any opinions, findings and conclusions or recom-
mendations expressed in this material are those of
the authors and do not necessarily reflect the views
of the DARPA.
References
Jean-Ce?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochastic
CFG. In Proc. of the First Workshop on Tabulation
in Parsing and Deduction, pages 133?137, April.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc. of
the 43rd Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 263?270, Ann Arbor,
MI, June.
David Chiang. 2007. Hierarchical Phrase-Based Trans-
lation. Computational Linguistics, 33(2):201?228,
June.
George Foster and Roland Kuhn. 2007. Mixture-model
adaptation for SMT. In Proc. of the Second Work-
shop on Statistical Machine Translation, pages 128?
135, Prague, Czech Republic, June.
Carmen Heger, Joern Wuebker, David Vilar, and Her-
mann Ney. 2010. A Combination of Hierarchical Sys-
tems with Forced Alignments from Phrase-Based Sys-
tems. In Proc. of the Int. Workshop on Spoken Lan-
guage Translation (IWSLT), Paris, France, December.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchical,
and Syntax-Based Statistical Machine Translation. In
Proc. of the Int. Workshop on Spoken Language Trans-
lation (IWSLT), pages 152?159, Tokyo, Japan.
Liang Huang and David Chiang. 2007. Forest Rescoring:
Faster Decoding with Integrated Language Models. In
Proc. of the Annual Meeting of the Assoc. for Com-
putational Linguistics (ACL), pages 144?151, Prague,
Czech Republic, June.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Rule Filtering by Pattern
for Efficient Hierarchical Translation. In Proc. of the
12th Conf. of the Europ. Chapter of the Assoc. for
Computational Linguistics (EACL), pages 380?388,
Athens, Greece, March.
Philipp Koehn and Josh Schroeder. 2007. Experiments
in domain adaptation for statistical machine transla-
tion. In Proc. of the Second Workshop on Statistical
Machine Translation, pages 224?227, Prague, Czech
Republic, June.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc. of
the Human Language Technology Conf. / North Amer-
ican Chapter of the Assoc. for Computational Lin-
guistics (HLT-NAACL), pages 127?133, Edmonton,
Canada, May/June.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 177?180, Prague, Czech Re-
public, June.
Gregor Leusch and Hermann Ney. 2009. Edit distances
with block movements and error rate confidence esti-
mates. Machine Translation, December.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Sanjeev
Khudanpur, Lane Schwartz, Wren Thornton, Jonathan
Weese, and Omar Zaidan. 2009. Joshua: An Open
Source Toolkit for Parsing-Based Machine Transla-
tion. In Proc. of the Workshop on Statistical Machine
Translation, pages 135?139, Athens, Greece, March.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och, Christoph Tillmann, and Hermann Ney.
1999. Improved Alignment Models for Statistical Ma-
chine Translation. In Proc. of the Joint SIGDAT Conf.
on Empirical Methods in Natural Language Process-
ing and Very Large Corpora (EMNLP99), pages 20?
28, University of Maryland, College Park, MD, June.
95
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proc. of the An-
nual Meeting of the Assoc. for Computational Linguis-
tics (ACL), pages 160?167, Sapporo, Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proc. of the 40th
Annual Meeting of the Assoc. for Computational Lin-
guistics (ACL), pages 311?318, Philadelphia, PA, July.
Holger Schwenk and Jean Senellart. 2009. Translation
Model Adaptation for an Arabic/French News Trans-
lation System by Lightly-Supervised Training. In MT
Summit XII, Ottawa, Ontario, Canada, August.
Holger Schwenk. 2008. Investigations on Large-Scale
Lightly-Supervised Training for Statistical Machine
Translation. In Proc. of the Int. Workshop on Spo-
ken Language Translation (IWSLT), pages 182?189,
Waikiki, Hawaii, October.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), pages 223?231, Cambridge,
MA, August.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open Source Hierarchical Transla-
tion, Extended with Reordering and Lexicon Models.
In ACL 2010 Joint Fifth Workshop on Statistical Ma-
chine Translation and Metrics MATR, pages 262?270,
Uppsala, Sweden, July.
Joern Wuebker, Arne Mauser, and Hermann Ney. 2010.
Training Phrase Translation Models with Leaving-
One-Out. In Proc. of the Annual Meeting of the As-
soc. for Computational Linguistics (ACL), pages 475?
484, Uppsala, Sweden, July.
96
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 304?311,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2012
Matthias Huck, Stephan Peitz, Markus Freitag, Malte Nuhn and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
This paper describes the statistical ma-
chine translation (SMT) systems developed at
RWTH Aachen University for the translation
task of the NAACL 2012 Seventh Workshop on
Statistical Machine Translation (WMT 2012).
We participated in the evaluation campaign
for the French-English and German-English
language pairs in both translation directions.
Both hierarchical and phrase-based SMT sys-
tems are applied. A number of different tech-
niques are evaluated, including an insertion
model, different lexical smoothing methods,
a discriminative reordering extension for the
hierarchical system, reverse translation, and
system combination. By application of these
methods we achieve considerable improve-
ments over the respective baseline systems.
1 Introduction
For the WMT 2012 shared translation task1 RWTH
utilized state-of-the-art phrase-based and hierarchi-
cal translation systems as well as an in-house sys-
tem combination framework. We give a survey of
these systems and the basic methods they implement
in Section 2. For both the French-English (Sec-
tion 3) and the German-English (Section 4) language
pair, we investigate several different advanced tech-
niques. We concentrate on specific research direc-
tions for each of the translation tasks and present the
respective techniques along with the empirical re-
sults they yield: For the French?English task (Sec-
tion 3.1), we apply a standard phrase-based system.
1http://www.statmt.org/wmt12/
translation-task.html
For the English?French task (Section 3.2), we aug-
ment a hierarchical phrase-based setup with a num-
ber of enhancements like an insertion model, dif-
ferent lexical smoothing methods, and a discrimina-
tive reordering extension. For the German?English
(Section 4.3) and English?German (Section 4.4)
tasks, we utilize morpho-syntactic analysis to pre-
process the data (Section 4.1) and employ sys-
tem combination to produce a consensus hypothesis
from normal and reverse translations (Section 4.2) of
phrase-based and hierarchical phrase-based setups.
2 Translation Systems
2.1 Phrase-Based System
The phrase-based translation (PBT) system used
in this work is an in-house implementation of the
state-of-the-art decoder described in (Zens and Ney,
2008). We use the standard set of models with
phrase translation probabilities and lexical smooth-
ing in both directions, word and phrase penalty,
distance-based distortion model, an n-gram target
language model and three binary count features. The
parameter weights are optimized with minimum er-
ror rate training (MERT) (Och, 2003).
2.2 Hierarchical Phrase-Based System
For our hierarchical phrase-based translation
(HPBT) setups, we employ the open source trans-
lation toolkit Jane (Vilar et al, 2010; Stein et
al., 2011; Vilar et al, 2012), which has been
developed at RWTH and is freely available for
non-commercial use. In hierarchical phrase-based
translation (Chiang, 2007), a weighted synchronous
context-free grammar is induced from parallel text.
304
In addition to contiguous lexical phrases, hierar-
chical phrases with up to two gaps are extracted.
The search is carried out with a parsing-based
procedure. The standard models integrated into our
Jane systems are: phrase translation probabilities
and lexical smoothing probabilities in both trans-
lation directions, word and phrase penalty, binary
features marking hierarchical phrases, glue rule,
and rules with non-terminals at the boundaries,
four binary count features, and an n-gram language
model. Optional additional models comprise IBM
model 1 (Brown et al, 1993), discriminative word
lexicon (DWL) models and triplet lexicon models
(Mauser et al, 2009), discriminative reordering ex-
tensions (Huck et al, 2011a), insertion and deletion
models (Huck and Ney, 2012), and several syntactic
enhancements like preference grammars (Stein
et al, 2010) and string-to-dependency features
(Peter et al, 2011). We utilize the cube pruning
algorithm (Huang and Chiang, 2007) for decoding
and optimize the model weights with MERT.
2.3 System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses generated
with different translation engines. The basic concept
of RWTH?s approach to machine translation system
combination is described in (Matusov et al, 2006;
Matusov et al, 2008). This approach includes an
enhanced alignment and reordering framework. A
lattice is built from the input hypotheses. The trans-
lation with the best score within the lattice according
to a couple of statistical models is selected as con-
sensus translation.
2.4 Other Tools and Techniques
We employ GIZA++ (Och and Ney, 2003) to train
word alignments. The two trained alignments are
heuristically merged to obtain a symmetrized word
alignment for phrase extraction. All language mod-
els (LMs) are created with the SRILM toolkit (Stol-
cke, 2002) and are standard 4-gram LMs with in-
terpolated modified Kneser-Ney smoothing (Kneser
and Ney, 1995; Chen and Goodman, 1998). We
evaluate in truecase, using the BLEU (Papineni et al,
2002) and TER (Snover et al, 2006) measures.
French English
EP + NC Sentences 2.1M
Running Words 63.3M 57.6M
Vocabulary 147.8K 128.5K
Singletons 5.4K 5.1K
+ 109 Sentences 22.9M
Running Words 728.6M 624.0M
Vocabulary 1.7M 1.7M
Singletons 0.8M 0.8M
+ UN Sentences 35.4M
Running Words 1 113.5M 956.4M
Vocabulary 1.9M 2.0M
Singletons 0.9M 1.0M
Table 1: Corpus statistics of the preprocessed French-
English parallel training data. EP denotes Europarl, NC
denotes News Commentary. In the data, numerical quan-
tities have been replaced by a single category symbol.
3 French-English Setups
We trained phrase-based translation systems for
French?English and hierarchical phrase-based
translation systems for English?French. Corpus
statistics for the French-English parallel data are
given in Table 1. The LMs are 4-grams trained on
the provided resources for the respective language
(Europarl, News Commentary, UN, 109, and mono-
lingual News Crawl language model training data).2
For French?English we also investigate a smaller
English LM on Europarl and News Commentary
data only. For English?French we experiment with
additional target-side data from the LDC French Gi-
gaword Second Edition (LDC2009T28), which is an
archive of newswire text data that has been acquired
over several years by the LDC.3 The LDC French
Gigaword v2 is permitted for constrained submis-
sions in the WMT shared translation task. As a de-
velopment set for MERT, we use newstest2009 in all
setups.
3.1 Experimental Results French?English
For the French?English task, the phrase-based
SMT system (PBT) is set up using the standard mod-
els listed in Section 2.1. We vary the training data
we use to train the system and compare the results.
2The parallel 109 corpus is often also referred to as WMT
Giga French-English release 2.
3http://www.ldc.upenn.edu
305
newstest2008 newstest2009 newstest2010 newstest2011
French?English BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 20.3 63.8 23.0 60.0 23.2 59.1 24.7 57.3
+ LM: +109+UN 22.5 61.4 26.2 57.3 26.6 56.1 27.7 54.5
+ TM: +109 23.3 60.8 27.6 56.2 27.6 55.4 29.1 53.4
Table 2: Results for the French?English task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011
English?French BLEU TER BLEU TER BLEU TER BLEU TER
HPBT 20.9 66.0 23.6 62.5 25.1 60.2 27.4 57.6
+ 109 and UN 22.5 63.2 25.4 59.8 27.0 57.1 29.9 53.9
+ LDC Gigaword v2 23.0 63.0 25.9 59.4 27.3 56.9 29.6 54.1
+ insertion model 23.0 62.9 26.1 59.2 27.2 56.8 30.0 53.7
+ noisy-or lexical scores 23.2 62.5 26.1 59.0 27.6 56.4 30.2 53.4
+ DWL 23.3 62.5 26.2 58.9 27.9 55.9 30.4 53.2
+ IBM-1 23.4 62.3 26.2 58.8 28.0 55.7 30.4 53.1
+ discrim. RO 23.5 62.2 26.7 58.5 28.1 55.9 30.8 52.8
Table 3: Results for the English?French task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
It should be noted that these setups do not use any
English LDC Gigaword data for LM training at all.
Our baseline system uses the Europarl and News
Commentary data for training LM and phrase table.
Corpus statistics are shown in the ?EP+NC? section
of Table 1. This results in a performance of 24.7
points BLEU on newstest2011. Then we add the 109
as well as UN data and more monolingual English
data from the News Crawl corpus to the data used
for training the language model. This system ob-
tains a score of 27.7 points BLEU on newstest2011.
Our final system uses Europarl, News Commentary,
109 and UN data and News Crawl monolingual data
for LM training and the Europarl, News Commen-
tary and 109 data (Table 1) for phrase table training.
Using these data sets the system reaches 29.1 points
BLEU.
The experimental results are summarized in Ta-
ble 2.
3.2 Experimental Results English?French
For the English?French task, the baseline system is
a hierarchical phrase-based setup including the stan-
dard models as listed in Section 2.2, apart from the
binary count features. We limit the recursion depth
for hierarchical rules with a shallow-1 grammar (de
Gispert et al, 2010).
In a shallow-1 grammar, the generic non-terminal
X of the standard hierarchical approach is replaced
by two distinct non-terminals XH and XP . By
changing the left-hand sides of the rules, lexical
phrases are allowed to be derived from XP only, hi-
erarchical phrases from XH only. On all right-hand
sides of hierarchical rules, the X is replaced by XP .
Gaps within hierarchical phrases can thus solely be
filled with purely lexicalized phrases, but not a sec-
ond time with hierarchical phrases. The initial rule
is substituted with
S ? ?XP?0,XP?0?
S ? ?XH?0,XH?0? ,
(1)
and the glue rule is substituted with
S ? ?S?0XP?1, S?0XP?1?
S ? ?S?0XH?1, S?0XH?1? .
(2)
The main benefit of a restriction of the recursion
depth is a gain in decoding efficiency, thus allow-
ing us to set up systems more rapidly and to explore
more model combinations and more system config-
urations.
306
The experimental results for English?French are
given in Table 3. Starting from the shallow hi-
erarchical baseline setup on Europarl and News
Commentary parallel data only (but Europarl, News
Commentary, 109, UN, and News Crawl data for LM
training), we are able to improve translation qual-
ity considerably by first adopting more parallel (109
and UN) and monolingual (French LDC Gigaword
v2) training resources and then employing several
different models that are not included in the baseline
already. We proceed with individual descriptions of
the methods we use and report their respective effect
in BLEU on the test sets.
109 and UN (up to +2.5 points BLEU) While the
amount of provided parallel data from Europarl
and News Commentary sources is rather lim-
ited (around 2M sentence pairs in total), the
UN and the 109 corpus each provide a substan-
tial collection of further training material. By
appending both corpora, we end up at roughly
35M parallel sentences (cf. Table 1). We utilize
this full amount of data in our system, but ex-
tract a phrase table with only lexical (i.e. non-
hierarchical) phrases from the full parallel data.
We add it as a second phrase table to the base-
line system, with a binary feature that enables
the system to reward or penalize the application
of phrases from this table.
LDC Gigaword v2 (up to +0.5 points BLEU)
The LDC French Gigaword Second Edition
(LDC2009T28) provides some more monolin-
gual French resources. We include a total of
28.2M sentences from both the AFP and APW
collections in our LM training data.
insertion model (up to +0.4 points BLEU) We add
an insertion model to the log-linear model com-
bination. This model is designed as a means to
avoid the omission of content words in the hy-
potheses. It is implemented as a phrase-level
feature function which counts the number of in-
serted words. We apply the model in source-to-
target and target-to-source direction. A target-
side word is considered inserted based on lexi-
cal probabilities with the words on the foreign
language side of the phrase, and vice versa for
a source-side word. As thresholds, we compute
individual arithmetic averages for each word
from the vocabulary (Huck and Ney, 2012).
noisy-or lexical scores (up to +0.4 points BLEU) In
our baseline system, the tNorm(?) lexical scor-
ing variant as described in (Huck et al, 2011a)
is employed with a relative frequency (RF) lex-
icon model for phrase table smoothing. The
single-word based translation probabilities of
the RF lexicon model are extracted from word-
aligned parallel training data, in the fashion
of (Koehn et al, 2003). We exchange the base-
line lexical scoring with a noisy-or (Zens and
Ney, 2004) lexical scoring variant tNoisyOr(?).
DWL (up to +0.3 points BLEU) We augment
our system with phrase-level lexical scores
from discriminative word lexicon (DWL) mod-
els (Mauser et al, 2009; Huck et al, 2011a)
in both source-to-target and target-to-source di-
rection. The DWLs are trained on News Com-
mentary data only.
IBM-1 (up to +0.1 points BLEU) On News Com-
mentary and Europarl data, we train IBM
model-1 (Brown et al, 1993) lexicons in both
translation directions and also use them to com-
pute phrase-level scores.
discrim. RO (up to +0.4 points BLEU) The modi-
fication of the grammar to a shallow-1 version
restricts the search space of the decoder and is
convenient to prevent overgeneration. In order
not to be too restrictive, we reintroduce more
flexibility into the search process by extending
the grammar with specific reordering rules
XP ? ?XP?0XP?1,XP?1XP?0?
XP ? ?XP?0XP?1,XP?0XP?1? .
(3)
The upper rule in Equation (3) is a swap rule
that allows adjacent lexical phrases to be trans-
posed, the lower rule is added for symmetry
reasons, in particular because sequences as-
sembled with these rules are allowed to fill gaps
within hierarchical phrases. Note that we apply
a length constraint of 10 to the number of ter-
minals spanned by an XP . We introduce two
binary indicator features, one for each of the
two rules in Equation (3). In addition to adding
307
German English
Sentences 2.0M
Running Words 55.3M 55.7M
Vocabulary 191.6K 129.0K
Singletons 75.5K 51.8K
Table 4: Corpus statistics of the preprocessed German-
English parallel training data (Europarl and News Com-
mentary). In the data, numerical quantities have been re-
placed by a single category symbol.
these rules, a discriminatively trained lexical-
ized reordering model is applied (Huck et al,
2012).
4 German-English Setups
We trained phrase-based and hierarchical transla-
tion systems for both translation directions of the
German-English language pair. Corpus statistics for
German-English can be found in Table 4. The lan-
guage models are 4-grams trained on the respective
target side of the bilingual data as well as on the pro-
vided News Crawl corpus. For the English language
model the 109 French-English, UN and LDC Giga-
word Fourth Edition corpora are used additionally.
For the 109 French-English, UN and LDC Gigaword
corpora we apply the data selection technique de-
scribed in (Moore and Lewis, 2010). We examine
two different language models, one with LDC data
and one without. All German?English systems are
optimized on newstest2010. For English?German,
we use newstest2009 as development set. The news-
test2011 set is used as test set and the scores for new-
stest2008 are included for completeness.
4.1 Morpho-Syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the German text
is preprocessed by splitting German compound
words with the frequency-based method described in
(Koehn and Knight, 2003). To further reduce trans-
lation complexity of PBT, we employ the long-range
part-of-speech based reordering rules proposed by
Popovic? and Ney (2006).
4.2 Reverse Translation
For reverse translations we need to change the word
order of the bilingual corpus. For example, if we re-
verse both source and target language, the original
training example ?der Hund mag die Katze . ? the
dog likes the cat .? is converted into a new training
example ?. Katze die mag Hund der? . cat the likes
dog the?. We call this type of modification of source
or target language reversion. A system trained of
this data is called reverse. This modification changes
the corpora and hence the language model and align-
ment training produce different results.
4.3 Experimental Results German?English
Our results for the German?English task are shown
in Table 5. For this task, we apply the idea of reverse
translation for both the phrase-based and the hierar-
chical approach. It seems that the reversed systems
perform slightly worse. However, when we em-
ploy system combination using both reverse trans-
lation setups (PBT reverse and HPBT reverse) and
both baseline setups (PBT baseline and HPBT base-
line), the translation quality is improved by up to 0.4
points in BLEU and 1.0 points TER compared to the
best single system.
The addition of LDC Gigaword corpora (+GW)
to the language model training data of the baseline
setups shows improvements in both BLEU and TER.
Furthermore, with the system combination including
these setups, we are able to report an improvement
of up to 0.7 points BLEU and 1.0 points TER over the
best single setup. Compared to the system combina-
tion based on systems which are not using the LDC
Gigaword corpora, we gain 0.3 points in BLEU and
0.4 points in TER.
4.4 Experimental Results English?German
Our results for the English?German task are shown
in Table 6. For this task, we first compare sys-
tems using one, two or three language models of
different parts of the data. The language model
for systems with only one language model is cre-
ated with all monolingual and parallel data. A lan-
guage model with all monolingual data and a lan-
guage model with all parallel data is created for the
systems with two language models. For the systems
with three language models, we also split the parallel
data in two parts consisting of either only Europarl
data or only News Commentary data. For PBT the
system with two language models performs best for
all test sets. Further, we apply the idea of reverse
308
newstest2008 newstest2009 newstest2010 newstest2011
German?English BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 21.1 62.3 20.8 61.4 23.7 59.3 21.3 61.3
PBT reverse 20.8 62.4 20.6 61.5 23.6 59.2 21.2 61.2
HPBT baseline 21.3 62.5 20.9 61.7 23.9 59.4 21.3 61.6
HPBT reverse 21.2 63.5 20.9 62.0 23.6 59.2 21.4 61.9
system combination (secondary) 21.5 61.6 21.2 60.6 24.3 58.3 21.7 60.3
PBT baseline +GW 21.5 61.9 21.2 61.1 24.0 59.0 21.3 61.4
PBT reverse 20.8 62.4 20.6 61.5 23.6 59.2 21.2 61.2
HPBT baseline +GW 21.6 62.3 21.3 61.3 24.0 59.4 21.6 61.5
HPBT reverse 21.2 63.5 20.9 62.0 23.6 59.2 21.4 61.9
system combination (primary) 21.9 61.2 21.4 60.5 24.7 58.0 21.9 60.2
Table 5: Results for the German?English task (truecase). +GW denotes the usage of LDC Gigaword data for the
language model, newstest2010 serves as development set. BLEU and TER are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011
English?German BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 1 LM 14.6 71.7 14.8 70.8 15.8 66.9 15.3 70.0
PBT baseline 2 LM (*) 14.9 70.9 14.9 70.4 16.0 66.3 15.4 69.5
PBT baseline 3 LM 14.8 71.5 14.9 70.5 16.0 66.7 15.1 70.1
PBT reverse 2 LM (*) 14.9 71.4 15.1 70.2 15.9 66.5 15.0 69.7
HPBT baseline 2 LM (*) 15.1 71.8 15.3 71.1 16.2 67.4 15.4 70.3
HPBT baseline 2 LM opt on 4bleu-ter 15.2 68.4 15.0 67.7 15.9 64.6 15.1 67.1
HPBT reverse 2 LM (*) 15.4 71.3 15.3 70.7 16.7 66.9 15.5 70.1
syscombi of (*) 15.6 69.2 15.4 68.9 16.5 65.0 15.6 68.0
Table 6: Results for the English?German task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
translation for both the phrase-based and the hier-
archical approach. The PBT reverse 2 LM systems
perform slightly worse compared to PBT baseline 2
LM. The HPBT reverse 2 LM performs better com-
pared to HPBT baseline 2 LM. When we employ
system combination using both reverse translation
setups (PBT reverse 2 LM and HPBT reverse 2 LM)
and both baseline setups (PBT baseline 2 LM and
HPBT baseline 2 LM), the translation quality is im-
proved by up to 0.2 points in BLEU and 2.1 points in
TER compared to the best single system.
5 Conclusion
For the participation in the WMT 2012 shared trans-
lation task, RWTH experimented with both phrase-
based and hierarchical translation systems. Several
different techniques were evaluated and yielded con-
siderable improvements over the respective base-
line systems as well as over our last year?s setups
(Huck et al, 2011b). Among these techniques are
an insertion model, the noisy-or lexical scoring vari-
ant, additional phrase-level lexical scores from IBM
model 1 and discriminative word lexicon models, a
discriminative reordering extension for hierarchical
translation, reverse translation, and system combi-
nation.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The Mathemat-
309
ics of Statistical Machine Translation: Parameter Es-
timation. Computational Linguistics, 19(2):263?311,
June.
Stanley F. Chen and Joshua Goodman. 1998. An Em-
pirical Study of Smoothing Techniques for Language
Modeling. Technical Report TR-10-98, Computer
Science Group, Harvard University, Cambridge, Mas-
sachusetts, USA, August.
David Chiang. 2007. Hierarchical Phrase-Based Trans-
lation. Computational Linguistics, 33(2):201?228.
Adria` de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. Compu-
tational Linguistics, 36(3):505?533.
Liang Huang and David Chiang. 2007. Forest Rescoring:
Faster Decoding with Integrated Language Models. In
Proceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 144?151,
Prague, Czech Republic, June.
Matthias Huck and Hermann Ney. 2012. Insertion
and Deletion Models for Statistical Machine Trans-
lation. In Proceedings of the North American Chap-
ter of the Association for Computational Linguistics -
Human Language Technologies conference, Montreal,
Canada, June.
Matthias Huck, Saab Mansour, Simon Wiesler, and Her-
mann Ney. 2011a. Lexicon Models for Hierarchical
Phrase-Based Machine Translation. In International
Workshop on Spoken Language Translation, pages
191?198, San Francisco, California, USA, December.
Matthias Huck, Joern Wuebker, Christoph Schmidt,
Markus Freitag, Stephan Peitz, Daniel Stein, Arnaud
Dagnelies, Saab Mansour, Gregor Leusch, and Her-
mann Ney. 2011b. The RWTH Aachen Machine
Translation System for WMT 2011. In EMNLP 2011
Sixth Workshop on Statistical Machine Translation,
pages 405?412, Edinburgh, UK, July.
Matthias Huck, Stephan Peitz, Markus Freitag, and Her-
mann Ney. 2012. Discriminative Reordering Exten-
sions for Hierarchical Phrase-Based Machine Transla-
tion. In 16th Annual Conference of the European As-
sociation for Machine Translation, Trento, Italy, May.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In Pro-
ceedings of the International Conference on Acoustics,
Speech, and Signal Processing, volume 1, pages 181?
184, May.
Philipp Koehn and Kevin Knight. 2003. Empirical Meth-
ods for Compound Splitting. In Proceedings of Euro-
pean Chapter of the ACL (EACL 2009), pages 187?
194.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
Proc. of the Human Language Technology Conf.
(HLT-NAACL), pages 127?133, Edmonton, Canada,
May/June.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing Consensus Translation from Multi-
ple Machine Translation Systems Using Enhanced Hy-
potheses Alignment. In Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL), pages 33?40, Trento, Italy, April.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Marino, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrimi-
native and Trigger-Based Lexicon Models. In Proc. of
the Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 210?218, Singapore, Au-
gust.
Robert C. Moore and William Lewis. 2010. Intelli-
gent Selection of Language Model Training Data. In
ACL (Short Papers), pages 220?224, Uppsala, Swe-
den, July.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, Penn-
sylvania, USA, July.
Jan-Thorsten Peter, Matthias Huck, Hermann Ney, and
Daniel Stein. 2011. Soft String-to-Dependency Hier-
archical Machine Translation. In International Work-
shop on Spoken Language Translation, pages 246?
253, San Francisco, California, USA, December.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Translation.
In International Conference on Language Resources
and Evaluation, pages 1278?1283, Genoa, Italy, May.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human Anno-
tation. In Proceedings of the 7th Conference of the
310
Association for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA, Au-
gust.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Features
for Hierarchical Machine Translation. In Conf. of the
Association for Machine Translation in the Americas
(AMTA), Denver, Colorado, USA, October/November.
Daniel Stein, David Vilar, Stephan Peitz, Markus Fre-
itag, Matthias Huck, and Hermann Ney. 2011. A
Guide to Jane, an Open Source Hierarchical Trans-
lation Toolkit. The Prague Bulletin of Mathematical
Linguistics, (95):5?18, April.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf. on
Speech and Language Processing (ICSLP), volume 2,
pages 901?904, Denver, Colorado, USA, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open source hierarchical transla-
tion, extended with reordering and lexicon models. In
ACL 2010 Joint Fifth Workshop on Statistical Machine
Translation and Metrics MATR, pages 262?270, Upp-
sala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2012. Jane: an advanced freely available hier-
archical machine translation toolkit. Machine Trans-
lation, pages 1?20. http://dx.doi.org/10.1007/s10590-
011-9120-y.
Richard Zens and Hermann Ney. 2004. Improve-
ments in Phrase-Based Statistical Machine Transla-
tion. In Proc. Human Language Technology Conf. /
North American Chapter of the Association for Com-
putational Linguistics Annual Meeting (HLT-NAACL),
pages 257?264, Boston, Massachusetts, USA, May.
Richard Zens and Hermann Ney. 2008. Improvements
in Dynamic Programming Beam Search for Phrase-
based Statistical Machine Translation. In Interna-
tional Workshop on Spoken Language Translation,
pages 195?205, Honolulu, Hawaii, USA, October.
311
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322?329,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
Joint WMT 2012 Submission of the QUAERO Project
?Markus Freitag, ?Stephan Peitz, ?Matthias Huck, ?Hermann Ney,
?Jan Niehues, ?Teresa Herrmann, ?Alex Waibel,
?Le Hai-son, ?Thomas Lavergne, ?Alexandre Allauzen,
?Bianka Buschbeck, ?Josep Maria Crego, ?Jean Senellart
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint QUAERO sub-
mission to the WMT 2012 machine transla-
tion evaluation. Four groups (RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy, LIMSI-CNRS, and SYSTRAN) of the
QUAERO project submitted a joint translation
for the WMT German?English task. Each
group translated the data sets with their own
systems and finally the RWTH system combi-
nation combined these translations in our final
submission. Experimental results show im-
provements of up to 1.7 points in BLEU and
3.4 points in TER compared to the best single
system.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in machine
translation is mainly assigned to the four groups
participating in this joint submission. The aim of
this WMT submission was to show the quality of a
joint translation by combining the knowledge of the
four project partners. Each group develop and main-
tain their own different machine translation system.
These single systems differ not only in their general
approach, but also in the preprocessing of training
and test data. To take the advantage of these dif-
ferences of each translation system, we combined
all hypotheses of the different systems, using the
RWTH system combination approach.
This paper is structured as follows. In Section
2, the different engines of all four groups are in-
troduced. In Section 3, the RWTH Aachen system
combination approach is presented. Experiments
with different system selections for system combi-
nation are described in Section 4. Finally in Section
5, we discuss the results.
2 Translation Systems
For WMT 2012 each QUAERO partner trained their
systems on the parallel Europarl and News Com-
mentary corpora. All single systems were tuned
on the newstest2009 or newstest2010 development
set. The newstest2011 dev set was used to train
the system combination parameters. Finally, the
newstest2008-newstest2010 dev sets were used to
compare the results of the different system combina-
tion settings. In this Section all four different system
engines are presented.
2.1 RWTH Aachen Single Systems
For the WMT 2012 evaluation the RWTH utilized
RWTH?s state-of-the-art phrase-based and hierar-
chical translation systems. GIZA++ (Och and Ney,
2003) was employed to train word alignments, lan-
guage models have been created with the SRILM
toolkit (Stolcke, 2002).
2.1.1 Phrase-Based System
The phrase-based translation (PBT) system is
similar to the one described in Zens and Ney (2008).
After phrase pair extraction from the word-aligned
parallel corpus, the translation probabilities are esti-
mated by relative frequencies. The standard feature
322
set alo includes an n-gram language model, phrase-
level IBM-1 and word-, phrase- and distortion-
penalties, which are combined in log-linear fash-
ion. The model weights are optimized with standard
Mert (Och, 2003) on 200-best lists. The optimiza-
tion criterium is BLEU.
2.1.2 Hierarchical System
For the hierarchical setups (HPBT) described in
this paper, the open source Jane toolkit (Vilar et
al., 2010) is employed. Jane has been developed at
RWTH and implements the hierarchical approach as
introduced by Chiang (2007) with some state-of-the-
art extensions. In hierarchical phrase-based transla-
tion, a weighted synchronous context-free grammar
is induced from parallel text. In addition to contigu-
ous lexical phrases, hierarchical phrases with up to
two gaps are extracted. The search is typically car-
ried out using the cube pruning algorithm (Huang
and Chiang, 2007). The model weights are opti-
mized with standard Mert (Och, 2003) on 100-best
lists. The optimization criterium is 4BLEU ?TER.
2.1.3 Preprocessing
In order to reduce the source vocabulary size
translation, the German text was preprocessed
by splitting German compound words with the
frequency-based method described in (Koehn and
Knight, 2003a). To further reduce translation com-
plexity for the phrase-based approach, we performed
the long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.4 Language Model
For both decoders a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl, the
109 French-English, UN and LDC Gigaword Fourth
Edition corpora. For the 109 French-English, UN
and LDC Gigaword corpora RWTH applied the data
selection technique described in (Moore and Lewis,
2010).
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
We preprocess the training data prior to training
the system, first by normalizing symbols such as
quotes, dashes and apostrophes. Then smart-casing
of the first words of each sentence is performed. For
the German part of the training corpus we use the
hunspell1 lexicon to learn a mapping from old Ger-
man spelling to new German spelling to obtain a cor-
pus with homogenous spelling. In addition, we per-
form compound splitting as described in (Koehn and
Knight, 2003b). Finally, we remove very long sen-
tences, empty lines, and sentences that probably are
not parallel due to length mismatch.
2.2.2 System Overview
The KIT system uses an in-house phrase-based
decoder (Vogel, 2003) to perform translation and op-
timization with regard to the BLEU score is done us-
ing Minimum Error Rate Training as described in
Venugopal et al (2005).
2.2.3 Translation Models
The translation model is trained on the Europarl
and News Commentary Corpus and the phrase ta-
ble is based on a discriminative word alignment
(Niehues and Vogel, 2008).
In addition, the system applies a bilingual lan-
guage model (Niehues et al, 2011) to extend the
context of source language words available for trans-
lation.
Furthermore, we use a discriminative word lexi-
con as introduced in (Mauser et al, 2009). The lex-
icon was trained and integrated into our system as
described in (Mediani et al, 2011).
At last, we tried to find translations for
out-of-vocabulary (OOV) words by using quasi-
morphological operations as described in Niehues
and Waibel (2011). For each OOV word, we try to
find a related word that we can translate. We modify
the ending letters of the OOV word and learn quasi-
morphological operations to be performed on the
known translation of the related word to synthesize
a translation for the OOV word. By this approach
we were for example able to translate Kaminen into
chimneys using the known translation Kamin # chim-
ney.
2.2.4 Language Models
We use two 4-gram SRI language models, one
trained on the News Shuffle corpus and one trained
1http://hunspell.sourceforge.net/
323
on the Gigaword corpus. Furthermore, we use a 5-
gram cluster-based language model trained on the
News Shuffle corpus. The word clusters were cre-
ated using the MKCLS algorithm. We used 100
word clusters.
2.2.5 Reordering Model
Reordering is performed based on part-of-speech
tags obtained using the TreeTagger (Schmid, 1994).
Based on these tags we learn probabilistic continu-
ous (Rottmann and Vogel, 2007) and discontinuous
(Niehues and Kolss, 2009) rules to cover short and
long-range reorderings. The rules are learned from
the training corpus and the alignment. In addition,
we learned tree-based reordering rules. Therefore,
the training corpus was parsed by the Stanford parser
(Rafferty and Manning, 2008). The tree-based rules
consist of the head node of a subtree and all its
children as well as the new order and a probability.
These rules were applied recursively. The reordering
rules are applied to the source sentences and the re-
ordered sentence variants as well as the original se-
quence are encoded in a word lattice which is used
as input to the decoder. For the test sentences, the
reordering based on parts-of-speech and trees allows
us to change the word order in the source sentence
so that the sentence can be translated more easily.
In addition, we build reordering lattices for all train-
ing sentences and then extract phrase pairs from the
monotone source path as well as from the reordered
paths.
2.3 LIMSI-CNRS Single System
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine translation
system based on bilingual n-gram2. In this approach,
the translation model relies on a specific decomposi-
tion of the joint probability of a sentence pair P(s, t)
using the n-gram assumption: a sentence pair is de-
composed into a sequence of bilingual units called
tuples, defining a joint segmentation of the source
and target. In the approach of (Marin?o et al, 2006),
this segmentation is a by-product of source reorder-
ing which ultimately derives from initial word and
phrase alignments.
2http://ncode.limsi.fr/
2.3.1 An Overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using a
n-gram model of (source,target) pairs (Casacuberta
and Vidal, 2004). Training this model requires to
reorder source sentences so as to match the target
word order. This is performed by a stochastic finite-
state reordering model, which uses part-of-speech
information3 to generalize reordering patterns be-
yond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized reorder-
ing models (Tillmann, 2004) aiming at predicting
the orientation of the next translation unit; a ?weak?
distance-based distortion model; and finally a word-
bonus model and a tuple-bonus model which com-
pensate for the system preference for short transla-
tions. The four lexicon models are similar to the ones
used in a standard phrase based system: two scores
correspond to the relative frequencies of the tuples
and two lexical weights estimated from the automat-
ically generated word alignments. The weights asso-
ciated to feature functions are optimally combined
using a discriminative training framework (Och,
2003), using the newstest2009 development set.
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the tu-
ple extraction process. The resulting reordering hy-
potheses are passed to the decoder in the form of
word lattices (Crego and Marin?o, 2007).
2.3.2 Continuous Space Translation Models
One critical issue with standard n-gram transla-
tion models is that the elementary units are bilingual
pairs, which means that the underlying vocabulary
can be quite large. Unfortunately, the parallel data
available to train these models are typically smaller
than the corresponding monolingual corpora used to
train target language models. It is very likely then,
that such models should face severe estimation prob-
lems. In such setting, using neural network language
3Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
324
model techniques seem all the more appropriate. For
this study, we follow the recommendations of Le et
al. (2012), who propose to factor the joint proba-
bility of a sentence pair by decomposing tuples in
two (source and target) parts, and further each part
in words. This yields a word factored translation
model that can be estimated in a continuous space
using the SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the computa-
tional cost of computing n-gram probabilities. The
solution used here was to resort to a two pass ap-
proach: the first pass uses a conventional back-off
n-gram model to produce a k-best list; in the second
pass, the k-best list is reordered using the probabil-
ities of m-gram SOUL translation models. In the
following experiments, we used a fixed context size
for SOUL of m = 10, and used k = 300.
2.3.3 Corpora and Data Preprocessing
The parallel data is word-aligned using
MGIZA++4 with default settings. For the En-
glish monolingual training data, we used the same
setup as last year5 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we took advantage of our in-house
text processing tools for tokenization and detok-
enization steps (De?chelotte et al, 2008) and our sys-
tem was built in ?true-case?. As German is mor-
phologically more complex than English, the default
policy which consists in treating each word form
independently is plagued with data sparsity, which
is detrimental both at training and decoding time.
Thus, the German side was normalized using a spe-
cific pre-processing scheme (Allauzen et al, 2010;
Durgar El-Kahlout and Yvon, 2010), which notably
aims at reducing the lexical redundancy by (i) nor-
malizing the orthography, (ii) neutralizing most in-
flections and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
The data submitted by SYSTRAN were obtained by
a system composed of the standard SYSTRAN MT
engine in combination with a statistical post editing
(SPE) component.
4http://geek.kyloo.net/software
5The fifth edition of the English Gigaword (LDC2011T07)
was not used.
The SYSTRAN system is traditionally classi-
fied as a rule-based system. However, over the
decades, its development has always been driven by
pragmatic considerations, progressively integrating
many of the most efficient MT approaches and tech-
niques. Nowadays, the baseline engine can be con-
sidered as a linguistic-oriented system making use of
dependency analysis, general transfer rules as well
as of large manually encoded dictionaries (100k -
800k entries per language pair).
The SYSTRAN phrase-based SPE component
views the output of the rule-based system as the
source language, and the (human) reference trans-
lation as the target language, see (L. Dugast and
Koehn, 2007). It performs corrections and adaptions
learned from the 5-gram language model trained on
the parallel target-to-target corpus. Moreover, the
following measures - limiting unwanted statistical
effects - were applied:
? Named entities, time and numeric expressions
are replaced by special tokens on both sides.
This usually improves word alignment, since
the vocabulary size is significantly reduced. In
addition, entity translation is handled more re-
liably by the rule-based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the ref-
erence translation) is used to produce an addi-
tional parallel corpus to help to improve word
alignment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side are
also discarded.
The SPE language model was trained on 2M bilin-
gual phrases from the news/Europarl corpora, pro-
vided as training data for WMT 2012. An addi-
tional language model built from 15M phrases of
the English LDC Gigaword corpus using Kneser-
Ney (Kneser and Ney, 1995) smoothing was added.
Weights for these separate models were tuned by
the Mert algorithm provided in the Moses toolkit
(P. Koehn et al, 2007), using the provided news de-
velopment set.
325
3 RWTH Aachen System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (2006; 2008). This ap-
proach includes an enhanced alignment and reorder-
ing framework. A lattice is built from the input hy-
potheses. The translation with the best score within
the lattice according to a couple of statistical models
is selected as consensus translation.
4 Experiments
This year, we tried different sets of single systems
for system combination. As RWTH has two dif-
ferent translation systems, we put the output of
both systems into system combination. Although
both systems have the same preprocessing and lan-
guage model, their hypotheses differ because of
their different decoding approach. Compared to
the other systems, the system by SYSTRAN has a
completely different approach (see section 2.4). It
is mainly based on a rule-based system. For the
German?English pair, SYSTRAN achieves a lower
BLEU score in each test set compared to the other
groups. However, since the SYSTRAN system is
very different to the others, we still obtain an im-
provement when we add it also to system combina-
tion.
We did experiments with different optimization
criteria for the system combination optimization.
All results are listed in Table 1 (unoptimized), Table
2 (optimized on BLEU) and Table 3 (optimized on
TER-BLEU). Further, we investigated, whether we
will loose performance, if a single system is dropped
from the system combination. The results show that
for each optimization criteria we need all systems to
achieve the best results.
For the BLEU optimized system combination, we
obtain an improvement compared to the best sin-
gle systems for all dev sets. For newstest2008, we
get an improvement of 1.5 points in BLEU and 1.5
points in TER compared to the best single system of
Karlsruhe Institute of Technology. For newstest2009
we get an improvement of 1.9 points in BLEU and
1.5 points in TER compared to the best single sys-
tem. The system combination of all systems outper-
forms the best single system with 1.9 points in BLEU
and 1.9 points in TER for newstest2010. For new-
stest2011 the improvement is 1.3 points in BLEU
and 2.9 points in TER.
For the TER-BLEU optimized system combina-
tion, we achieved more improvement in TER com-
pared to the BLEU optimized system combination.
For newstest2008, we get an improvement of 0.8
points in BLEU and 3.0 points in TER compared to
the best single system of Karlsruhe Institute of Tech-
nology. The system combinations performs better
on newstest2009 with 1.3 points in BLEU and 2.7
points in TER. For newstest2010, we get an im-
provement of 1.7 points in BLEU and 3.4 points in
TER and for newstest2011 we get an improvement
of 0.7 points in BLEU and 2.5 points in TER.
5 Conclusion
The four statistical machine translation systems of
Karlsruhe Institute of Technology, RWTH Aachen
and LIMSI and the very structural approach of SYS-
TRAN produce hypotheses with a huge variability
compared to the others. Finally, the RWTH Aachen
system combination combined all single system hy-
potheses to one hypothesis with a higher BLEU and
a lower TER score compared to each single sys-
tem. For each optimization criteria the system com-
binations using all single systems outperforms the
system combinations using one less single system.
Although the single system of SYSTRAN has the
worst error scores and the RWTH single systems are
similar, we achieved the best result in using all single
systems. For the WMT 12 evaluation, we submitted
the system combination of all systems optimized on
BLEU.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Francois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of the
326
Table 1: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are unoptimized.
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
KIT 22.2 61.8 21.3 61.0 24.1 59.0 22.4 60.2 37.9
RWTH.PBT 21.4 62.0 21.3 61.1 23.9 59.1 21.4 61.2 39.7
Limsi 22.2 63.0 22.0 61.8 23.9 59.9 21.8 62.0 40.2
RWTH.HPBT 21.5 62.6 21.5 61.6 23.6 60.2 21.5 61.8 40.4
SYSTRAN 18.3 64.6 17.9 63.4 21.1 60.5 18.3 63.1 44.8
sc-withAllSystems 23.4 59.7 22.9 59.0 26.2 56.5 23.3 58.8 35.5
sc-without-RWTH.PBT 23.2 59.8 22.8 59.0 25.9 56.6 23.1 58.7 35.6
sc-without-RWTH.HPBT 23.2 59.6 22.7 58.9 26.1 56.2 23.1 58.7 35.6
sc-without-Limsi 22.7 60.1 22.4 59.2 25.5 56.7 22.8 58.8 36.0
sc-without-SYSTRAN 23.0 60.3 22.5 59.5 25.7 57.2 23.1 59.2 36.1
sc-without-KIT 23.0 59.9 22.5 59.1 25.9 56.6 22.9 59.1 36.3
Table 2: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.7 60.3 23.2 59.5 26.0 57.1 23.7 59.2 35.6
sc-without-RWTH.PBT 23.4 61.1 23.1 59.8 25.5 57.6 23.5 59.5 36.1
sc-without-SYSTRAN 23.3 61.1 22.6 60.5 25.3 58.1 23.5 60.0 36.5
sc-without-Limsi 23.1 60.7 22.6 59.7 25.4 57.5 23.3 59.4 36.2
sc-without-KIT 23.4 60.7 23.0 59.7 25.6 57.7 23.3 59.8 36.5
sc-without-RWTH.HPBT 23.3 59.4 22.8 58.6 26.1 56.0 23.1 58.4 35.2
Table 3: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on TER-BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.0 58.8 22.4 58.3 25.8 55.6 23.1 57.7 34.6
sc-without-RWTH.PBT 23.0 59.3 22.5 58.5 25.6 56.0 23.1 58.0 34.9
sc-without-RWTH.HPBT 23.1 59.0 22.6 58.3 25.8 55.6 23.0 58.0 35.0
sc-without-SYSTRAN 22.9 59.7 22.4 59.1 25.6 56.7 23.2 58.5 35.3
sc-without-Limsi 22.7 59.4 22.2 58.7 25.3 56.1 22.7 58.1 35.5
sc-without-KIT 22.9 59.3 22.4 58.5 25.7 55.8 22.7 58.1 35.4
327
Joint Workshop on Statistical Machine Translation and
MetricsMATR, pages 54?59, Uppsala, Sweden.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien Max,
Adrien Lardilleux, Thomas Lavergne, Artem Sokolov,
Guillaume Wisniewski, and Franc?ois Yvon. 2011.
LIMSI @ WMT11. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, pages 309?
315, Edinburgh, Scotland, July. Association for Com-
putational Linguistics.
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(3):205?225.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J.M. Crego and J.B. Marin?o. 2007. Improving statistical
MT by coupling reordering and decoding. Machine
Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics,
96:49?58.
D. De?chelotte, O. Galibert G. Adda, A. Allauzen, J. Gau-
vain, H. Meynard, and F. Yvon. 2008. LIMSI?s statis-
tical translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010. The
pay-offs of preprocessing for German-English Statis-
tical Machine Translation. In Marcello Federico, Ian
Lane, Michael Paul, and Franois Yvon, editors, Pro-
ceedings of the seventh International Workshop on
Spoken Language Translation (IWSLT), pages 251?
258.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
R. Kneser and H. Ney. 1995. Improved backing-off for
m-gram language modeling. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing, ICASSP?95, pages 181?184, Detroit,
MI.
P. Koehn and K. Knight. 2003a. Empirical Methods for
Compound Splitting. In EACL, Budapest, Hungary.
P. Koehn and K. Knight. 2003b. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
post-editing on systran?s rule-based translation system.
In Proceedings of the Second Workshop on Statisti-
cal Machine Translation, StatMT ?07, pages 220?223,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-Luc
Gauvain, and Franc?ois Yvon. 2011. Structured output
layer neural network language model. In Proceedings
of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with neu-
ral networks. In NAACL ?12: Proceedings of the
2012 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology.
Jose? B. Marin?o, R. Banchs, J.M. Crego, A. de Gispert,
P. Lambert, J.A.R. Fonollosa, and M.R. Costa-jussa`.
2006. N-gram-based machine translation. Computa-
tional Linguistics, 32(4).
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Mari no, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrim-
inative and Trigger-based Lexicon Models. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 1 - Vol-
ume 1, EMNLP ?09, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT English-
French Translation Systems for IWSLT 2011. In Pro-
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT).
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short Pa-
pers), pages 220?224, Uppsala, Sweden, July.
J. Niehues and M. Kolss. 2009. A POS-Based Model for
Long-Range Reorderings in SMT. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
J. Niehues and S. Vogel. 2008. Discriminative Word
Alignment via Alignment Matrix Modeling. In Proc.
of Third ACL Workshop on Statistical Machine Trans-
lation, Columbus, USA.
Jan Niehues and Alex Waibel. 2011. Using Wikipedia
to Translate Domain-specific Terms in SMT. In Pro-
328
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT), San Francisco,
CA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex
Waibel. 2011. Wider Context by Using Bilingual Lan-
guage Models in Machine Translation. In Sixth Work-
shop on Statistical Machine Translation (WMT 2011),
Edinburgh, UK.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
A. Birch P. Koehn, H. Hoang, C. Callison-Burch, M. Fed-
erico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,
R. Zens, C. Dyer, O. Bojar, A. Constantin, and
E. Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Natural
Language Processing, Springer Verlag, LNCS, pages
616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Workshop
on Parsing German.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based Dis-
tortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In International Conference
on NewMethods in Language Processing, Manchester,
UK.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Evelyne
Tzoukermann and SusanEditors Armstrong, editors,
Proceedings of the ACL SIGDATWorkshop, pages 47?
50. Kluwer Academic Publishers.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901?904, Denver, Col-
orado, USA, September.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004, pages 101?104. Association for Com-
putational Linguistics.
A. Venugopal, A. Zollman, and A. Waibel. 2005. Train-
ing and Evaluation Error Minimization Rules for Sta-
tistical Machine Translation. In Workshop on Data-
drive Machine Translation and Beyond (WPT-05), Ann
Arbor, MI.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Int. Conf. on Natural Language Process-
ing and Knowledge Engineering, Beijing, China.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
329
Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 29?38,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
A Performance Study of Cube Pruning for Large-Scale Hierarchical
Machine Translation
Matthias Huck1 and David Vilar2 and Markus Freitag1 and Hermann Ney1
1 Human Language Technology and Pattern 2 DFKI GmbH
Recognition Group, RWTH Aachen University Alt-Moabit 91c
D-52056 Aachen, Germany D-10559 Berlin, Germany
<surname>@cs.rwth-aachen.de david.vilar@dfki.de
Abstract
In this paper, we empirically investigate the
impact of critical configuration parameters in
the popular cube pruning algorithm for decod-
ing in hierarchical statistical machine transla-
tion. Specifically, we study how the choice
of the k-best generation size affects trans-
lation quality and resource requirements in
hierarchical search. We furthermore exam-
ine the influence of two different granular-
ities of hypothesis recombination. Our ex-
periments are conducted on the large-scale
Chinese?English and Arabic?English NIST
translation tasks. Besides standard hierarchi-
cal grammars, we also explore search with re-
stricted recursion depth of hierarchical rules
based on shallow-1 grammars.
1 Introduction
Cube pruning (Chiang, 2007) is a widely used
search strategy in state-of-the-art hierarchical de-
coders. Some alternatives and extensions to the
classical algorithm as proposed by David Chiang
have been presented in the literature since, e.g. cube
growing (Huang and Chiang, 2007), lattice-based
hierarchical translation (Iglesias et al, 2009b; de
Gispert et al, 2010), and source cardinality syn-
chronous cube pruning (Vilar and Ney, 2012). Stan-
dard cube pruning remains the commonly adopted
decoding procedure in hierarchical machine transla-
tion research at the moment, though. The algorithm
has meanwhile been implemented in many publicly
available toolkits, as for example in Moses (Koehn
et al, 2007; Hoang et al, 2009), Joshua (Li et
al., 2009a), Jane (Vilar et al, 2010), cdec (Dyer et
al., 2010), Kriya (Sankaran et al, 2012), and Niu-
Trans (Xiao et al, 2012). While the plain hierar-
chical approach to machine translation (MT) is only
formally syntax-based, cube pruning can also be uti-
lized for decoding with syntactically or semantically
enhanced models, for instance those by Venugopal
et al (2009), Shen et al (2010), Xie et al (2011),
Almaghout et al (2012), Li et al (2012), Williams
and Koehn (2012), or Baker et al (2010).
Here, we look into the following key aspects of hi-
erarchical phrase-based translation with cube prun-
ing:
? Deep vs. shallow grammar.
? k-best generation size.
? Hypothesis recombination scheme.
We conduct a comparative study of all combinations
of these three factors in hierarchical decoding and
present detailed experimental analyses with respect
to translation quality and search efficiency. We fo-
cus on two tasks which are of particular interest to
the research community: the Chinese?English and
Arabic?English NIST OpenMT translation tasks.
The paper is structured as follows: We briefly out-
line some important related work in the following
section. We subsequently give a summary of the
grammars used in hierarchical phrase-based trans-
lation, including a presentation of the difference be-
tween a deep and a shallow-1 grammar (Section 3).
Essential aspects of hierarchical search with the
cube pruning algorithm are explained in Section 4.
We show how the k-best generation size is defined
(we apply the limit without counting recombined
29
candidates), and we present the two different hy-
pothesis recombination schemes (recombination T
and recombination LM). Our empirical investiga-
tions and findings constitute the major part of this
work: In Section 5, we first accurately describe our
setup, then conduct a number of comparative exper-
iments with varied parameters on the two translation
tasks, and finally analyze and discuss the results. We
conclude the paper in Section 6.
2 Related Work
Hierarchical phrase-based translation (HPBT) was
first proposed by Chiang (2005). Chiang also in-
troduced the cube pruning algorithm for hierarchical
search (Chiang, 2007). It is basically an adaptation
of one of the k-best parsing algorithms by Huang
and Chiang (2005). Good descriptions of the cube
pruning implementation in the Joshua decoder have
been provided by Li and Khudanpur (2008) and Li
et al (2009b). Xu and Koehn (2012) implemented
hierarchical search with the cube growing algorithm
in Moses and compared its performance to Moses?
cube pruning implementation. Heafield et al re-
cently developed techniques to speed up hierarchical
search by means of an improved language model in-
tegration (Heafield et al, 2011; Heafield et al, 2012;
Heafield et al, 2013).
3 Probabilistic SCFGs for HPBT
In hierarchical phrase-based translation, a proba-
bilistic synchronous context-free grammar (SCFG)
is induced from a bilingual text. In addition to con-
tinuous lexical phrases, hierarchical phrases with
usually up to two gaps are extracted from the word-
aligned parallel training data.
Deep grammar. The non-terminal set of a stan-
dard hierarchical grammar comprises two symbols
which are shared by source and target: the initial
symbol S and one generic non-terminal symbol X .
Extracted rules of a standard hierarchical grammar
are of the form X ? ??, ?,? ? where ??, ?? is a
bilingual phrase pair that may contain X , i.e. ? ?
({X } ? VF )+ and ? ? ({X } ? VE)+, where VF
and VE are the source and target vocabulary, respec-
tively. The ? relation denotes a one-to-one corre-
spondence between the non-terminals in ? and in ?.
A non-lexicalized initial rule and a special glue rule
complete the grammar. We denote standard hierar-
chical grammars as deep grammars here.
Shallow-1 grammar. Iglesias et al (2009a) pro-
pose a limitation of the recursion depth for hierar-
chical rules with shallow grammars. In a shallow-1
grammar, the generic non-terminal X of the stan-
dard hierarchical approach is replaced by two dis-
tinct non-terminals XH and XP . By changing the
left-hand sides of the rules, lexical phrases are al-
lowed to be derived from XP only, hierarchical
phrases from XH only. On all right-hand sides of
hierarchical rules, the X is replaced by XP . Gaps
within hierarchical phrases can thus be filled with
continuous lexical phrases only, not with hierarchi-
cal phrases. The initial and glue rules are adjusted
accordingly.
4 Hierarchical Search with Cube Pruning
Hierarchical search is typically carried out with a
parsing-based procedure. The parsing algorithm is
extended to handle translation candidates and to in-
corporate language model scores via cube pruning.
The cube pruning algorithm. Cube pruning op-
erates on a hypergraph which represents the whole
parsing space. This hypergraph is built employ-
ing a customized version of the CYK+ parsing al-
gorithm (Chappelier and Rajman, 1998). Given
the hypergraph, cube pruning expands at most k
derivations at each hypernode.1 The pseudocode
of the k-best generation step of the cube pruning
algorithm is shown in Figure 1. This function is
called in bottom-up topological order for all hy-
pernodes. A heap of active derivations A is main-
tained. A initially contains the first-best derivations
for each incoming hyperedge (line 1). Active deriva-
tions are processed in a loop (line 3) until a limit k
is reached or A is empty. If a candidate deriva-
tion d is recombinable, the RECOMBINE auxiliary
function recombines it and returns true; otherwise
(for non-recombinable candidates) RECOMBINE re-
turns false. Non-recombinable candidates are ap-
pended to the list D of k-best derivations (line 6).
This list will be sorted before the function terminates
1The hypergraph on which cube pruning operates can be
constructed based on other techniques, such as tree automata,
but CYK+ parsing is the dominant approach.
30
(line 8). The PUSHSUCC auxiliary function (line 7)
updates A with the next best derivations following d
along the hyperedge. PUSHSUCC determines the
cube order by processing adjacent derivations in a
specific sequence (of predecessor hypernodes along
the hyperedge and phrase translation options).2
k-best generation size. Candidate derivations are
generated by cube pruning best-first along the in-
coming hyperedges. A problem results from the lan-
guage model integration, though: As soon as lan-
guage model context is considered, monotonicity
properties of the derivation cost can no longer be
guaranteed. Thus, even for single-best translation,
k-best derivations are collected to a buffer in a beam
search manner and finally sorted according to their
cost. The k-best generation size is consequently a
crucial parameter to the cube pruning algorithm.
Hypothesis recombination. Partial hypotheses
with states that are indistinguishable from each other
are recombined during search. We define two no-
tions of when to consider two derivations as indis-
tinguishable, and thus when to recombine them:
Recombination T. The T recombination scheme
recombines derivations that produce identical
translations.
Recombination LM. The LM recombination
scheme recombines derivations with identical
language model context.
Recombination is conducted within the loop of
the k-best generation step of cube pruning. Re-
combined derivations do not increment the gener-
ation count; the k-best generation limit is thus ef-
fectively applied after recombination.3 In general,
more phrase translation candidates per hypernode
are being considered (and need to be rated with the
language model) in the recombination LM scheme
compared to the recombination T scheme. The more
partial hypotheses can be recombined, the more it-
erations of the inner code block of the k-best gen-
eration loop are possible. The same internal k-best
2See Vilar (2011) for the pseudocode of the PUSHSUCC
function and other details which are omitted here.
3Whether recombined derivations contribute to the genera-
tion count or not is a configuration decision (or implementa-
tion decision). Please note that some publicly available toolkits
count recombined derivations by default.
Input: a hypernode and the size k of the k-best list
Output: D, a list with the k-best derivations
1 let A? heap({(e,1|e|) | e ? incoming edges)})
2 let D ? [ ]
3 while |A| > 0 ? |D| < k do
4 d? pop(A)
5 if not RECOMBINE(D, d) then
6 D ? D ++ [d]
7 PUSHSUCC(d,A)
8 sort D
Figure 1: k-best generation with the cube pruning al-
gorithm.
generation size results in a larger search space for re-
combination LM. We will examine how the overall
number of loop iterations relates to the k-best gener-
ation limit. By measuring the number of derivations
as well as the number of recombination operations
on our test sets, we will be able to give an insight
into how large the fraction of recombinable candi-
dates is for different configurations.
5 Experiments
We conduct experiments which evaluate perfor-
mance in terms of both translation quality and
computational efficiency, i.e. translation speed and
memory consumption, for combinations of deep
or shallow-1 grammars with the two hypothesis
recombination schemes and an exhaustive range
of k-best generation size settings. Empirical re-
sults are presented on the Chinese?English and
Arabic?English 2008 NIST tasks (NIST, 2008).
5.1 Experimental Setup
We work with parallel training corpora of 3.0 M
Chinese?English sentence pairs (77.5 M Chinese /
81.0 M English running words after preprocessing)
and 2.5 M Arabic?English sentence pairs (54.3 M
Arabic / 55.3 M English running words after prepro-
cessing), respectively. Word alignments are created
by aligning the data in both directions with GIZA++
and symmetrizing the two trained alignments (Och
and Ney, 2003). When extracting phrases, we apply
several restrictions, in particular a maximum length
of ten on source and target side for lexical phrases,
a length limit of five on source and ten on target
side for hierarchical phrases (including non-terminal
symbols), and no more than two gaps per phrase.
31
Table 1: Data statistics for the test sets. Numbers have
been replaced by a special category symbol.
Chinese MT08 Arabic MT08
Sentences 1 357 1 360
Running words 34 463 45 095
Vocabulary 6 209 9 387
The decoder loads only the best translation options
per distinct source side with respect to the weighted
phrase-level model scores (100 for Chinese, 50 for
Arabic). The language models are 4-grams with
modified Kneser-Ney smoothing (Kneser and Ney,
1995; Chen and Goodman, 1998) which have been
trained with the SRILM toolkit (Stolcke, 2002).
During decoding, a maximum length constraint
of ten is applied to all non-terminals except the ini-
tial symbol S . Model weights are optimized with
MERT (Och, 2003) on 100-best lists. The op-
timized weights are obtained (separately for deep
and for shallow-1 grammars) with a k-best gen-
eration size of 1 000 for Chinese?English and of
500 for Arabic?English and kept for all setups.
We employ MT06 as development sets. Trans-
lation quality is measured in truecase with BLEU
(Papineni et al, 2002) on the MT08 test sets.
Data statistics for the preprocessed source sides of
both the Chinese?English MT08 test set and the
Arabic?English MT08 test set are given in Table 1.
Our translation experiments are conducted with
the open source translation toolkit Jane (Vilar et
al., 2010; Vilar et al, 2012). The core imple-
mentation of the toolkit is written in C++. We
compiled with GCC version 4.4.3 using its -O2
optimization flag. We employ the SRILM li-
braries to perform language model scoring in the
decoder. In binarized version, the language mod-
els have a size of 3.6G (Chinese?English) and 6.2G
(Arabic?English). Language models and phrase ta-
bles have been copied to the local hard disks of the
machines. In all experiments, the language model
is completely loaded beforehand. Loading time of
the language model and any other initialization steps
are not included in the measured translation time.
Phrase tables are in the Jane toolkit?s binarized for-
mat. The decoder initializes the prefix tree struc-
ture, required nodes get loaded from secondary stor-
age into main memory on demand, and the loaded
content is being cleared each time a new input sen-
tence is to be parsed. There is nearly no overhead
due to unused data in main memory. We do not
rely on memory mapping. Memory statistics are
with respect to virtual memory. The hardware was
equipped with RAM well beyond the requirements
of the tasks, and sufficient memory has been re-
served for the processes.
5.2 Experimental Results
Figures 2 and 3 depict how the Chinese?English
and Arabic?English setups behave in terms of
translation quality. The k-best generation size in
cube pruning is varied between 10 and 10 000.
The four graphs in each plot illustrate the results
with combinations of deep grammar and recombi-
nation scheme T, deep grammar and recombination
scheme LM, shallow grammar and recombination
scheme T, as well as shallow grammar and recom-
bination scheme LM. Figures 4 and 5 show the cor-
responding translation speed in words per second for
these settings. The maximum memory requirements
in gigabytes are given in Figures 6 and 7. In order
to visualize the trade-offs between translation qual-
ity and resource consumption somewhat better, we
plotted translation quality against time requirements
in Figures 8 and 9 and translation quality against
memory requirements in Figures 10 and 11. Transla-
tion quality and model score (averaged over all sen-
tences; higher is better) are nicely correlated for all
configurations, as can be concluded from Figures 12
through 15.
5.3 Discussion
Chinese?English. For Chinese?English trans-
lation, the system with deep grammar performs gen-
erally a bit better with respect to quality than the
shallow one, which accords with the findings of
other groups (de Gispert et al, 2010; Sankaran et
al., 2012). The LM recombination scheme yields
slightly better quality than the T scheme, and with
the shallow-1 grammar it outperforms the T scheme
at any given fixed amount of time or memory allo-
cation (Figures 8 and 10).
Shallow-1 translation is up to roughly 2.5 times
faster than translation with the deep grammar. How-
ever, the shallow-1 setups are considerably slowed
down at higher k-best sizes as well, while the ef-
fort pays off only very moderately. Overall, the
32
 23
 23.5
 24
 24.5
 25
 25.5
 10  100  1000  10000
BLE
U [%
]
k-best generation size
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 2: Chinese?English translation quality (truecase).
 42.5
 43
 43.5
 44
 44.5
 45
 10  100  1000  10000
BLE
U [%
]
k-best generation size
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 3: Arabic?English translation quality (truecase).
 0
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10  100  1000  10000
wo
rds
 pe
r se
con
d
k-best generation size
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 4: Chinese?English translation speed.
 0
 2
 4
 6
 8
 10
 12
 14
 16
 18
 10  100  1000  10000
wo
rds
 pe
r se
con
d
k-best generation size
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 5: Arabic?English translation speed.
 0
 8
 16
 24
 32
 40
 10  100  1000  10000
giga
byte
s
k-best generation size
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 6: Chinese?English memory requirements.
 0
 8
 16
 24
 32
 40
 10  100  1000  10000
giga
byte
s
k-best generation size
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 7: Arabic?English memory requirements.
33
 23
 23.5
 24
 24.5
 25
 25.5
 0.125 0.25  0.5  1  2  4  8  16  32
BLE
U [%
]
seconds per word
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 8: Trade-off between translation quality and speed
for Chinese?English.
 42.5
 43
 43.5
 44
 44.5
 45
 0.125 0.25  0.5  1  2  4  8  16  32
BLE
U [%
]
seconds per word
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 9: Trade-off between translation quality and speed
for Arabic?English.
 23
 23.5
 24
 24.5
 25
 25.5
 8  16  32  64
BLE
U [%
]
gigabytes
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 10: Trade-off between translation quality and mem-
ory requirements for Chinese?English.
 42.5
 43
 43.5
 44
 44.5
 45
 16  32  64  128
BLE
U [%
]
gigabytes
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
shallow-1, recombination T
shallow-1, recombination LM
Figure 11: Trade-off between translation quality and mem-
ory requirements for Arabic?English.
shallow-1 grammar at a k-best size between 100 and
1 000 seems to offer a good compromise of quality
and efficiency. Deep translation with k = 2000 and
the LM recombination scheme promises high qual-
ity translation, but note the rapid memory consump-
tion increase beyond k = 1000 with the deep gram-
mar. At k ? 1 000, memory consumption is not an
issue in both deep and shallow systems, but transla-
tion speed starts to drop at k > 100 already.
Arabic?English. Shallow-1 translation produces
competitive quality for Arabic?English translation
(de Gispert et al, 2010; Huck et al, 2011). The
LM recombination scheme boosts the BLEU scores
slightly. The systems with deep grammar are slowed
down strongly with every increase of the k-best size.
Their memory consumption likewise inflates early.
We actually stopped running experiments with deep
grammars for Arabic?English at k = 7000 for the
T recombination scheme, and at k = 700 for the LM
recombination scheme because 124G of memory did
not suffice any more for higher k-best sizes. The
memory consumption of the shallow systems stays
nearly constant across a large range of the surveyed
k-best sizes, but Figure 11 reveals a plateau where
more resources do not improve translation quality.
Increasing k from 100 to 2 000 in the shallow setup
with LM recombination provides half a BLEU point,
but reduces speed by a factor of more than 10.
34
 23
 23.5
 24
 24.5
 25
 25.5
-8.7 -8.65 -8.6 -8.55 -8.5 -8.45 -8.4
BLE
U [%
]
average model score
NIST Chinese-to-English (MT08)
deep, recombination Tdeep, recombination LM
Figure 12: Relation of translation quality and average
model score for Chinese?English (deep grammar).
 42.5
 43
 43.5
 44
 44.5
 45
-6.6 -6.5 -6.4 -6.3 -6.2 -6.1
BLE
U [%
]
average model score
NIST Arabic-to-English (MT08)
deep, recombination Tdeep, recombination LM
Figure 13: Relation of translation quality and average
model score for Arabic?English (deep grammar).
 23
 23.5
 24
 24.5
 25
 25.5
-9.4 -9.35 -9.3 -9.25 -9.2 -9.15 -9.1
BLE
U [%
]
average model score
NIST Chinese-to-English (MT08)
shallow-1, recombination T
shallow-1, recombination LM
Figure 14: Relation of translation quality and average
model score for Chinese?English (shallow-1 grammar).
 42.5
 43
 43.5
 44
 44.5
 45
-12.1 -12 -11.9 -11.8 -11.7 -11.6
BLE
U [%
]
average model score
NIST Arabic-to-English (MT08)
shallow-1, recombination T
shallow-1, recombination LM
Figure 15: Relation of translation quality and average
model score for Arabic?English (shallow-1 grammar).
Actual amount of derivations. We measured the
amount of hypernodes (Table 2), the amount of actu-
ally generated derivations after recombination, and
the amount of generated candidate derivations in-
cluding recombined ones?or, equivalently, loop it-
erations in the algorithm from Figure 1?for se-
lected limits k (Tables 3 and 4). The ratio of the
average amount of derivations per hypernode after
and before recombination remains consistently at
low values for all recombination T setups. For the
setups with LM recombination scheme, this recom-
bination factor rises with larger k, i.e. the fraction
of recombinable candidates increases. The increase
is remarkably pronounced for Arabic?English with
deep grammar. The steep slope of the recombina-
tion factor may be interpreted as an indicator for un-
desired overgeneration of the deep grammar on the
Arabic?English task.
6 Conclusion
We systematically studied three key aspects of hier-
archical phrase-based translation with cube pruning:
Deep vs. shallow-1 grammars, the k-best generation
size, and the hypothesis recombination scheme. In
a series of empirical experiments, we revealed the
trade-offs between translation quality and resource
requirements to a more fine-grained degree than this
is typically done in the literature.
35
Table 2: Average amount of hypernodes per sentence and average length of the preprocessed input sentences on the
NIST Chinese?English (MT08) and Arabic?English (MT08) tasks.
Chinese?English Arabic?English
deep shallow-1 deep shallow-1
avg. #hypernodes per sentence 480.5 200.7 896.4 308.4
avg. source sentence length 25.4 33.2
Table 3: Detailed statistics about the actual amount of derivations on the NIST Chinese?English task (MT08).
deep
recombination T recombination LM
avg. #derivations avg. #derivations avg. #derivations avg. #derivations
per hypernode per hypernode per hypernode per hypernode
k (after recombination) (incl. recombined) factor (after recombination) (incl. recombined) factor
10 10.0 11.7 1.17 10.0 18.2 1.82
100 99.9 120.1 1.20 99.9 275.8 2.76
1000 950.1 1142.3 1.20 950.1 4246.9 4.47
10000 9429.8 11262.8 1.19 9418.1 72008.4 7.65
shallow-1
recombination T recombination LM
avg. #derivations avg. #derivations avg. #derivations avg. #derivations
per hypernode per hypernode per hypernode per hypernode
k (after recombination) (incl. recombined) factor (after recombination) (incl. recombined) factor
10 9.7 11.3 1.17 9.6 13.6 1.41
100 90.8 105.2 1.16 90.4 168.6 1.86
1000 707.3 811.3 1.15 697.4 2143.4 3.07
10000 6478.1 7170.4 1.11 6202.8 34165.6 5.51
Table 4: Detailed statistics about the actual amount of derivations on the NIST Arabic?English task (MT08).
deep
recombination T recombination LM
avg. #derivations avg. #derivations avg. #derivations avg. #derivations
per hypernode per hypernode per hypernode per hypernode
k (after recombination) (incl. recombined) factor (after recombination) (incl. recombined) factor
10 10.0 18.3 1.83 10.0 71.5 7.15
100 98.0 177.4 1.81 98.0 1726.0 17.62
500 482.1 849.0 1.76 482.1 14622.1 30.33
1000 961.8 1675.0 1.74 ? ? ?
shallow-1
recombination T recombination LM
avg. #derivations avg. #derivations avg. #derivations avg. #derivations
per hypernode per hypernode per hypernode per hypernode
k (after recombination) (incl. recombined) factor (after recombination) (incl. recombined) factor
10 9.6 12.1 1.26 9.6 16.6 1.73
100 80.9 105.2 1.30 80.2 193.8 2.42
1000 690.1 902.1 1.31 672.1 2413.0 3.59
10000 5638.6 7149.5 1.27 5275.1 31283.6 5.93
36
Acknowledgments
This work was partly achieved as part of the Quaero
Programme, funded by OSEO, French State agency
for innovation. This material is also partly based
upon work supported by the DARPA BOLT project
under Contract No. HR0011-12-C-0015. Any opin-
ions, findings and conclusions or recommendations
expressed in this material are those of the authors
and do not necessarily reflect the views of the
DARPA. The research leading to these results has
received funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreement no 287658.
References
Hala Almaghout, Jie Jiang, and Andy Way. 2012. Ex-
tending CCG-based Syntactic Constraints in Hierar-
chical Phrase-Based SMT. In Proc. of the Annual
Conf. of the European Assoc. for Machine Translation
(EAMT), pages 193?200, Trento, Italy, May.
Kathryn Baker, Michael Bloodgood, Chris Callison-
Burch, Bonnie Dorr, Nathaniel Filardo, Lori
Levin, Scott Miller, and Christine Piatko. 2010.
Semantically-Informed Syntactic Machine Transla-
tion: A Tree-Grafting Approach. In Proc. of the Conf.
of the Assoc. for Machine Translation in the Americas
(AMTA), Denver, CO, USA, October/November.
Jean-Ce?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochastic
CFG. In Proc. of the First Workshop on Tabulation in
Parsing and Deduction, pages 133?137, Paris, France,
April.
Stanley F. Chen and Joshua Goodman. 1998. An Em-
pirical Study of Smoothing Techniques for Language
Modeling. Technical Report TR-10-98, Computer
Science Group, Harvard University, Cambridge, MA,
USA, August.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc. of
the Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 263?270, Ann Arbor, MI,
USA, June.
David Chiang. 2007. Hierarchical Phrase-Based Trans-
lation. Computational Linguistics, 33(2):201?228,
June.
Adria` de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. Compu-
tational Linguistics, 36(3):505?533.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,
Vladimir Eidelman, and Philip Resnik. 2010. cdec:
A Decoder, Alignment, and Learning framework for
finite-state and context-free translation models. In
Proc. of the ACL 2010 System Demonstrations, pages
7?12, Uppsala, Sweden, July.
Kenneth Heafield, Hieu Hoang, Philipp Koehn, Tetsuo
Kiso, and Marcello Federico. 2011. Left Language
Model State for Syntactic Machine Translation. In
Proc. of the Int. Workshop on Spoken Language Trans-
lation (IWSLT), pages 183?190, San Francisco, CA,
USA, December.
Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2012.
Language Model Rest Costs and Space-Efficient Stor-
age. In Proc. of the 2012 Joint Conf. on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, EMNLP-
CoNLL ?12, pages 1169?1178, Jeju Island, Korea,
July.
Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2013.
Grouping Language Model Boundary Words to Speed
K-Best Extraction from Hypergraphs. In Proc. of the
Human Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), Atlanta, GA, USA, June.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchical,
and Syntax-Based Statistical Machine Translation. In
Proc. of the Int. Workshop on Spoken Language Trans-
lation (IWSLT), pages 152?159, Tokyo, Japan, Decem-
ber.
Liang Huang and David Chiang. 2005. Better k-best
Parsing. In Proc. of the 9th Int. Workshop on Parsing
Technologies, pages 53?64, October.
Liang Huang and David Chiang. 2007. Forest Rescoring:
Faster Decoding with Integrated Language Models. In
Proc. of the Annual Meeting of the Assoc. for Com-
putational Linguistics (ACL), pages 144?151, Prague,
Czech Republic, June.
Matthias Huck, David Vilar, Daniel Stein, and Hermann
Ney. 2011. Advancements in Arabic-to-English Hier-
archical Machine Translation. In 15th Annual Confer-
ence of the European Association for Machine Trans-
lation, pages 273?280, Leuven, Belgium, May.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009a. Rule Filtering by Pat-
tern for Efficient Hierarchical Translation. In Proc. of
the 12th Conf. of the Europ. Chapter of the Assoc. for
Computational Linguistics (EACL), pages 380?388,
Athens, Greece, March.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009b. Hierarchical Phrase-
Based Translation with Weighted Finite State Trans-
37
ducers. In Proc. of the Human Language Technology
Conf. / North American Chapter of the Assoc. for Com-
putational Linguistics (HLT-NAACL), pages 433?441,
Boulder, CO, USA, June.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In
Proc. of the International Conf. on Acoustics, Speech,
and Signal Processing, volume 1, pages 181?184, De-
troit, MI, USA, May.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit for
Statistical Machine Translation. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 177?180, Prague, Czech Republic, June.
Zhifei Li and Sanjeev Khudanpur. 2008. A Scalable
Decoder for Parsing-Based Machine Translation with
Equivalent Language Model State Maintenance. In
Proceedings of the Second Workshop on Syntax and
Structure in Statistical Translation, SSST ?08, pages
10?18, Columbus, OH, USA, June.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Sanjeev
Khudanpur, Lane Schwartz, Wren Thornton, Jonathan
Weese, and Omar Zaidan. 2009a. Joshua: An Open
Source Toolkit for Parsing-Based Machine Transla-
tion. In Proc. of the Workshop on Statistical Machine
Translation (WMT), pages 135?139, Athens, Greece,
March.
Zhifei Li, Chris Callison-Burch, Sanjeev Khudanpur, and
Wren Thornton. 2009b. Decoding in Joshua: Open
Source, Parsing-Based Machine Translation. The
Prague Bulletin of Mathematical Linguistics, (91):47?
56, January.
Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josef van
Genabith. 2012. Using Syntactic Head Information in
Hierarchical Phrase-Based Translation. In Proc. of the
Workshop on Statistical Machine Translation (WMT),
pages 232?242, Montre?al, Canada, June.
NIST. 2008. Open Machine Translation 2008 Evalua-
tion. http://www.itl.nist.gov/iad/mig/
tests/mt/2008/.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proc. of the An-
nual Meeting of the Assoc. for Computational Linguis-
tics (ACL), pages 160?167, Sapporo, Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 311?318, Philadelphia, PA, USA, July.
Baskaran Sankaran, Majid Razmara, and Anoop Sarkar.
2012. Kriya - An end-to-end Hierarchical Phrase-
based MT System. The Prague Bulletin of Mathemat-
ical Linguistics, (97):83?98, April.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2010.
String-to-Dependency Statistical Machine Translation.
Computational Linguistics, 36(4):649?671, Decem-
ber.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statisti-
cal Machine Translation. In Proc. of the Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics (HLT-
NAACL), pages 236?244, Boulder, CO, USA, June.
David Vilar and Hermann Ney. 2012. Cardinality
pruning and language model heuristics for hierarchi-
cal phrase-based translation. Machine Translation,
26(3):217?254, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open Source Hierarchical Transla-
tion, Extended with Reordering and Lexicon Models.
In Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 262?270, Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2012. Jane: an advanced freely available hierar-
chical machine translation toolkit. Machine Transla-
tion, 26(3):197?216, September.
David Vilar. 2011. Investigations on Hierarchi-
cal Phrase-Based Machine Translation. Ph.D. the-
sis, RWTH Aachen University, Aachen, Germany,
November.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proc. of the Workshop on Statistical Machine Transla-
tion (WMT), pages 388?394, Montre?al, Canada, June.
Tong Xiao, Jingbo Zhu, Hao Zhang, and Qiang Li. 2012.
NiuTrans: An Open Source Toolkit for Phrase-based
and Syntax-based Machine Translation. In Proc. of
the ACL 2012 System Demonstrations, pages 19?24,
Jeju, Republic of Korea, July.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A Novel
Dependency-to-String Model for Statistical Machine
Translation. In Proc. of the Conf. on Empirical Meth-
ods for Natural Language Processing (EMNLP), pages
216?226, Edinburgh, Scotland, UK, July.
Wenduan Xu and Philipp Koehn. 2012. Extending Hiero
Decoding in Moses with Cube Growing. The Prague
Bulletin of Mathematical Linguistics, (98):133?142,
October.
38
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 185?192,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Joint WMT 2013 Submission of the QUAERO Project
?Stephan Peitz, ?Saab Mansour, ?Matthias Huck, ?Markus Freitag, ?Hermann Ney,
?Eunah Cho, ?Teresa Herrmann, ?Mohammed Mediani, ?Jan Niehues, ?Alex Waibel,
?Alexandre Allauzen, ?Quoc Khanh Do,
?Bianka Buschbeck, ?Tonio Wandmacher
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint submis-
sion of the QUAERO project for the
German?English translation task of the
ACL 2013 Eighth Workshop on Statisti-
cal Machine Translation (WMT 2013).
The submission was a system combina-
tion of the output of four different transla-
tion systems provided by RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy (KIT), LIMSI-CNRS and SYSTRAN
Software, Inc. The translations were
joined using the RWTH?s system com-
bination approach. Experimental results
show improvements of up to 1.2 points in
BLEU and 1.2 points in TER compared to
the best single translation.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in ma-
chine translation is mainly assigned to the four
groups participating in this joint submission. The
aim of this submission was to show the quality of
a joint translation by combining the knowledge of
the four project partners. Each group develop and
maintain their own different machine translation
system. These single systems differ not only in
their general approach, but also in the preprocess-
ing of training and test data. To take advantage
of these differences of each translation system, we
combined all hypotheses of the different systems,
using the RWTH system combination approach.
This paper is structured as follows. First, the
different engines of all four groups are introduced.
In Section 3, the RWTH Aachen system combina-
tion approach is presented. Experiments with dif-
ferent system selections for system combination
are described in Section 4. This paper is concluded
in Section 5.
2 Translation Systems
For WMT 2013, each QUAERO partner trained
their systems on the parallel Europarl (EPPS),
News Commentary (NC) corpora and the web-
crawled corpus. All single systems were tuned on
the newstest2009 and newstest2010 development
set. The newstest2011 development set was used
to tune the system combination parameters. Fi-
nally, on newstest2012 the results of the different
system combination settings are compared. In this
Section, all four different translation engines are
presented.
2.1 RWTH Aachen Single System
For the WMT 2013 evaluation, RWTH utilized a
phrase-based decoder based on (Wuebker et al,
2012) which is part of RWTH?s open-source SMT
toolkit Jane 2.1 1. GIZA++ (Och and Ney, 2003)
was employed to train a word alignment, language
models have been created with the SRILM toolkit
(Stolcke, 2002).
After phrase pair extraction from the word-
aligned parallel corpus, the translation probabil-
ities are estimated by relative frequencies. The
standard feature set alo includes an n-gram lan-
guage model, phrase-level IBM-1 and word-,
phrase- and distortion-penalties, which are com-
bined in log-linear fashion. Furthermore, we used
an additional reordering model as described in
(Galley and Manning, 2008). By this model six
1http://www-i6.informatik.rwth-aachen.
de/jane/
185
additional feature are added to the log-linear com-
bination. The model weights are optimized with
standard Mert (Och, 2003a) on 200-best lists. The
optimization criterion is BLEU.
2.1.1 Preprocessing
In order to reduce the source vocabulary size trans-
lation, the German text was preprocessed by split-
ting German compound words with the frequency-
based method described in (Koehn and Knight,
2003). To further reduce translation complexity
for the phrase-based approach, we performed the
long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.2 Translation Model
We applied filtering and weighting for domain-
adaptation similarly to (Mansour et al, 2011) and
(Mansour and Ney, 2012). For filtering the bilin-
gual data, a combination of LM and IBM Model
1 scores was used. In addition, we performed
weighted phrase extraction by using a combined
LM and IBM Model 1 weight.
2.1.3 Language Model
During decoding a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl,
the 109 French-English, UN and LDC Gigaword
Fourth Edition corpora.
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
The training data was preprocessed prior to the
training. Symbols such as quotes, dashes and
apostrophes are normalized. Then the first words
of each sentence are smart-cased. For the Ger-
man part of the training corpus, the hunspell2 lex-
icon was used, in order to learn a mapping from
old German spelling to new German writing rules.
Compound-splitting was also performed as de-
scribed in Koehn and Knight (2003). We also re-
moved very long sentences, empty lines, and sen-
tences which show big mismatch on the length.
2.2.2 Filtering
The web-crawled corpus was filtered using an
SVM classifier as described in (Mediani et al,
2011). The lexica used in this filtering task were
obtained from Giza alignments trained on the
2http://hunspell.sourceforge.net/
cleaner corpora, EPPS and NC. Assuming that this
corpus is very noisy, we biased our classifier more
towards precision than recall. This was realized
by giving higher number of false examples (80%
of the training data).
This filtering technique ruled out more than
38% of the corpus (the unfiltered corpus contains
around 2.4M pairs, 0.9M of which were rejected
in the filtering task).
2.2.3 System Overview
The in-house phrase-based decoder (Vogel, 2003)
is used to perform decoding. Optimization with
regard to the BLEU score is done using Minimum
Error Rate Training (MERT) as described in Venu-
gopal et al (2005).
2.2.4 Reordering Model
We applied part-of-speech (POS) based reordering
using probabilistic continuous (Rottmann and Vo-
gel, 2007) and discontinuous (Niehues and Kolss,
2009) rules. This was learned using POS tags gen-
erated by the TreeTagger (Schmid, 1994) for short
and long range reorderings respectively.
In addition to this POS-based reordering, we
also used tree-based reordering rules. Syntactic
parse trees of the whole training corpus and the
word alignment between source and target lan-
guage are used to learn rules on how to reorder the
constituents in a German source sentence to make
it match the English target sentence word order
better (Herrmann et al, 2013). The training corpus
was parsed by the Stanford parser (Rafferty and
Manning, 2008). The reordering rules are applied
to the source sentences and the reordered sentence
variants as well as the original sequence are en-
coded in a word lattice which is used as input to
the decoder.
Moreover, our reordering model was extended
so that it could include the features of lexicalized
reordering model. The reordering probabilities for
each phrase pair are stored as well as the origi-
nal position of each word in the lattice. During
the decoding, the reordering origin of the words
is checked along with its probability added as an
additional score.
2.2.5 Translation Models
The translation model uses the parallel data of
EPPS, NC, and the filtered web-crawled data. As
word alignment, we used the Discriminative Word
Alignment (DWA) as shown in (Niehues and Vo-
186
gel, 2008). The phrase pairs were extracted using
different source word order suggested by the POS-
based reordering models presented previously as
described in (Niehues et al, 2009).
In order to extend the context of source lan-
guage words, we applied a bilingual language
model (Niehues et al, 2011). A Discriminative
Word Lexicon (DWL) introduced in (Mauser et
al., 2009) was extended so that it could take the
source context also into the account. For this,
we used a bag-of-ngrams instead of representing
the source sentence as a bag-of-words. Filtering
based on counts was then applied to the features
for higher order n-grams. In addition to this, the
training examples were created differently so that
we only used the words that occur in the n-best list
but not in the reference as negative example.
2.2.6 Language Models
We build separate language models and combined
them prior to decoding. As word-token based
language models, one language model is built on
EPPS, NC, and giga corpus, while another one is
built using crawled data. We combined the LMs
linearly by minimizing the perplexity on the de-
velopment data. As a bilingual language model we
used the EPPS, NC, and the web-crawled data and
combined them. Furthermore, we use a 5-gram
cluster-based language model with 1,000 word
clusters, which was trained on the EPPS and NC
corpus. The word clusters were created using the
MKCLS algorithm.
2.3 LIMSI-CNRS Single System
2.3.1 System overview
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine transla-
tion system based on bilingual n-gram3. In this
approach, the translation model relies on a spe-
cific decomposition of the joint probability of a
sentence pair using the n-gram assumption: a sen-
tence pair is decomposed into a sequence of bilin-
gual units called tuples, defining a joint segmen-
tation of the source and target. In the approach of
(Marin?o et al, 2006), this segmentation is a by-
product of source reordering which ultimately de-
rives from initial word and phrase alignments.
2.3.2 An overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using
3http://ncode.limsi.fr/
a n-gram model of (source,target) pairs (Casacu-
berta and Vidal, 2004). Training this model re-
quires to reorder source sentences so as to match
the target word order. This is performed by
a stochastic finite-state reordering model, which
uses part-of-speech information4 to generalize re-
ordering patterns beyond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized re-
ordering models (Tillmann, 2004) aiming at pre-
dicting the orientation of the next translation unit;
a ?weak? distance-based distortion model; and
finally a word-bonus model and a tuple-bonus
model which compensate for the system prefer-
ence for short translations. The four lexicon mod-
els are similar to the ones use in a standard phrase
based system: two scores correspond to the rel-
ative frequencies of the tuples and two lexical
weights estimated from the automatically gener-
ated word alignments. The weights associated to
feature functions are optimally combined using a
discriminative training framework (Och, 2003b).
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the
tuple extraction process. The resulting reordering
hypotheses are passed to the decoder in the form
of word lattices (Crego and Mario, 2006).
2.3.3 Continuous space translation models
One critical issue with standard n-gram translation
models is that the elementary units are bilingual
pairs, which means that the underlying vocabu-
lary can be quite large, even for small translation
tasks. Unfortunately, the parallel data available to
train these models are typically order of magni-
tudes smaller than the corresponding monolingual
corpora used to train target language models. It is
very likely then, that such models should face se-
vere estimation problems. In such setting, using
neural network language model techniques seem
all the more appropriate. For this study, we fol-
low the recommendations of Le et al (2012), who
propose to factor the joint probability of a sen-
tence pair by decomposing tuples in two (source
and target) parts, and further each part in words.
This yields a word factored translation model that
4Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
187
can be estimated in a continuous space using the
SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the com-
putational cost of computing n-gram probabilities.
The solution used here was to resort to a two pass
approach: the first pass uses a conventional back-
off n-gram model to produce a k-best list; in the
second pass, the k-best list is reordered using the
probabilities of m-gram SOUL translation models.
In the following experiments, we used a fixed con-
text size for SOUL of m= 10, and used k = 300.
2.3.4 Corpora and data pre-processing
All the parallel data allowed in the constrained
task are pooled together to create a single par-
allel corpus. This corpus is word-aligned using
MGIZA++5 with default settings. For the English
monolingual training data, we used the same setup
as last year6 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we also took advantage of our in-
house text processing tools for the tokenization
and detokenization steps (Dchelotte et al, 2008)
and our system is built in ?true-case?. As Ger-
man is morphologically more complex than En-
glish, the default policy which consists in treat-
ing each word form independently is plagued with
data sparsity, which is detrimental both at training
and decoding time. Thus, the German side was
normalized using a specific pre-processing scheme
(described in (Allauzen et al, 2010; Durgar El-
Kahlout and Yvon, 2010)), which notably aims at
reducing the lexical redundancy by (i) normalizing
the orthography, (ii) neutralizing most inflections
and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
In the past few years, SYSTRAN has been focus-
ing on the introduction of statistical approaches
to its rule-based backbone, leading to Hybrid Ma-
chine Translation.
The technique of Statistical Post-Editing
(Dugast et al, 2007) is used to automatically edit
the output of the rule-based system. A Statistical
Post-Editing (SPE) module is generated from a
bilingual corpus. It is basically a translation mod-
ule by itself, however it is trained on rule-based
5http://geek.kyloo.net/software
6The fifth edition of the English Gigaword
(LDC2011T07) was not used.
translations and reference data. It applies correc-
tions and adaptations learned from a phrase-based
5-gram language model. Using this two-step
process will implicitly keep long distance re-
lations and other constraints determined by the
rule-based system while significantly improving
phrasal fluency. It has the advantage that quality
improvements can be achieved with very little
but targeted bilingual data, thus significantly
reducing training time and increasing translation
performance.
The basic setup of the SPE component is identi-
cal to the one described in (Dugast et al, 2007).
A statistical translation model is trained on the
rule-based translation of the source and the target
side of the parallel corpus. Language models are
trained on each target half of the parallel corpora
and also on additional in-domain corpora. More-
over, the following measures - limiting unwanted
statistical effects - were applied:
? Named entities are replaced by special tokens
on both sides. This usually improves word
alignment, since the vocabulary size is sig-
nificantly reduced. In addition, entity trans-
lation is handled more reliably by the rule-
based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the
reference translation) is used to produce an
additional parallel corpus (whose target is
identical to the source). This was added to the
parallel text in order to improve word align-
ment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side
are also discarded.
? Phrase pairs appearing less than 2 times were
pruned.
The SPE language model was trained on 2M
phrases from the news/europarl and Common-
Crawl corpora, provided as training data for WMT
2013. Weights for these separate models were
tuned by the Mert algorithm provided in the Moses
toolkit (Koehn et al, 2007), using the provided
news development set.
188
0
1
5:
th
at
/1
7:
th
is/
3
2
3:
is/
3
8:
w
as
/1
3
0:
*E
PS
*/
3
4:
it/
1
4
0:
*E
PS
*/
3
2:
in
/1
5
0:
*E
PS
*/
3
6:
th
e/
1
6
0:
*E
PS
*/
1
1:
fu
tu
re
/3
Figure 1: Confusion network of four different hypotheses.
3 RWTH Aachen System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses gener-
ated with different translation engines. First, a
word to word alignment for the given single sys-
tem hypotheses is produced. In a second step a
confusion network is constructed. Then, the hy-
pothesis with the highest probability is extracted
from this confusion network. For the alignment
procedure, each of the given single systems gen-
erates one confusion network with its own as pri-
mary system. To this primary system all other hy-
potheses are aligned using the METEOR (Lavie
and Agarwal, 2007) alignment and thus the pri-
mary system defines the word order. Once the
alignment is given, the corresponding confusion
network is constructed. An example is given in
Figure 1. The final network for one source sen-
tence is the union of all confusion networks gen-
erated from the different primary systems. That
allows the system combination to select the word
order from different system outputs.
Before performing system combination, each
translation output was normalized by tokenization
and lowercasing. The output of the combination
was then truecased based on the original truecased
output.
The model weights of the system combination
are optimized with standard Mert (Och, 2003a)
on 100-best lists. We add one voting feature for
each single system to the log-linear framework of
the system combination. The voting feature fires
for each word the single system agrees on. More-
over, a word penalty, a language model trained on
the input hypotheses, a binary feature which pe-
nalizes word deletions in the confusion network
and a primary feature which marks the system
which provides the word order are combined in
this log-linear model. The optimization criterion
is 4BLEU-TER.
4 Experimental Results
In this year?s experiments, we tried to improve the
result of the system combination further by com-
bining single systems tuned on different develop-
Table 1: Comparison of single systems tuned on
newstest2009 and newstest2010. The results are
reported on newstest2012.
single systems tuned on newstest2012
newstest BLEU TER
KIT 2009 24.6 58.4
2010 24.6 58.6
LIMSI 2009 22.5 61.5
2010 22.6 59.8
SYSTRAN 2009 20.9 63.3
2010 21.2 62.2
RWTH 2009 23.7 60.8
2010 24.4 58.8
ment sets. The idea is to achieve a more stable
performance in terms of translation quality, if the
single systems are not optimized on the same data
set. In Table 1, the results of each provided single
system tuned on newstest2009 and newstest2010
are shown. For RWTH, LIMSI and SYSTRAN,
it seems that the performance of the single system
depends on the chosen tuning set. However, the
translation quality of the single systems provided
by KIT is stable.
As initial approach and for the final submis-
sion, we grouped single systems with dissimilar
approaches. Thus, KIT (phrase-based SMT) and
SYSTRAN (rule-based MT) tuned their system on
newstest2010, while RWTH (phrase-based SMT)
and LIMSI (n-gram) optimized on newstest2009.
To compare the impact of this approach, all pos-
sible combinations were checked (Table 2). How-
ever, it seems that the translation quality can not be
improved by this approach. For the test set (new-
stest2012), BLEU is steady around 25.6 points.
Even if the single system with lowest BLEU are
combined (KIT 2010, LIMSI 2009, SYSTRAN
2010, RWTH 2009), the translation quality in
terms of BLEU is comparable with the combina-
tion of the best single systems (KIT 2009, LIMSI
2010, SYSTRAN 2010, RWTH 2010). However,
we could gain 1.0 point in TER.
Due to the fact, that for the final submission the
initial grouping was available only, we kept this
189
Table 2: Comparison of different system combination settings. For each possible combination of systems
tuned on different tuning sets, a system combination was set up, re-tuned on newstest2011 and evaluated
on newstest2012. The setting used for further experiments is set in boldface.
single systems system combinations
KIT LIMSI SYSTRAN RWTH newstest2011 newstest2012
tuned on newstest BLEU TER BLEU TER
2009 2009 2009 2009 24.6 58.0 25.6 56.8
2010 2010 2010 2010 24.2 58.1 25.6 57.7
2010 2009 2009 2009 24.5 57.9 25.7 57.4
2009 2010 2009 2009 24.4 58.3 25.7 57.0
2009 2009 2010 2009 24.5 57.9 25.6 57.0
2009 2009 2009 2010 24.5 58.0 25.6 56.8
2009 2010 2010 2010 24.1 57.5 25.4 56.4
2010 2009 2010 2010 24.3 57.6 25.6 56.9
2010 2010 2009 2010 24.2 58.0 25.6 57.3
2010 2010 2010 2009 24.3 57.9 25.5 57.6
2010 2010 2009 2009 24.4 58.1 25.6 57.5
2009 2009 2010 2010 24.4 57.8 25.5 56.6
2009 2010 2010 2009 24.4 58.2 25.5 57.0
2009 2010 2009 2010 24.2 57.8 25.5 56.8
2010 2009 2009 2010 24.4 57.9 25.6 57.4
2010 2009 2010 2009 24.4 57.7 25.6 57.4
Table 3: Results of the final submission (bold-
face) compared with best single system on new-
stest2012.
newstest2011 newstest2012
BLEU TER BLEU TER
best single 23.2 60.9 24.6 58.4
system comb. 24.4 57.7 25.6 57.4
+ IBM-1 24.6 58.1 25.6 57.6
+ bigLM 24.6 57.9 25.8 57.2
combination. To improve this baseline further, two
additional models were added. We applied lexi-
cal smoothing (IBM-1) and an additional language
model (bigLM) trained on the English side of the
parallel data and the News shuffle corpus. The re-
sults are presented in Table 3.
The baseline was slightly improved by 0.2
points in BLEU and TER. Note, this system com-
bination was the final submission.
5 Conclusion
For the participation in the WMT 2013 shared
translation task, the partners of the QUAERO
project (Karlsruhe Institute of Technology, RWTH
Aachen University, LIMSI-CNRS and SYSTRAN
Software, Inc.) provided a joint submission. By
joining the output of four different translation sys-
tems with RWTH?s system combination, we re-
ported an improvement of up to 1.2 points in
BLEU and TER.
Combining systems optimized on different tun-
ing sets does not seem to improve the translation
quality. However, by adding additional model, the
baseline was slightly improved.
All in all, we conclude that the variability in
terms of BLEU does not influence the final result.
It seems that using different approaches of MT in
a system combination is more important (Freitag
et al, 2012).
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Franc?ois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of
190
the Joint Workshop on Statistical Machine Transla-
tion and MetricsMATR, pages 54?59, Uppsala, Swe-
den.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien
Max, Adrien Lardilleux, Thomas Lavergne, Artem
Sokolov, Guillaume Wisniewski, and Franc?ois
Yvon. 2011. LIMSI @ WMT11. In Proceedings of
the Sixth Workshop on Statistical Machine Transla-
tion, pages 309?315, Edinburgh, Scotland, July. As-
sociation for Computational Linguistics.
Francesco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(3):205?
225.
Josep M. Crego and Jose? B. Mario. 2006. Improving
statistical MT by coupling reordering and decoding.
Machine Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram
SMT Toolkit. Prague Bulletin of Mathematical Lin-
guistics, 96:49?58.
Lo??c Dugast, Jean Senellart, and Philipp Koehn. 2007.
Statistical post-editing on systran?s rule-based trans-
lation system. In Proceedings of the Second Work-
shop on Statistical Machine Translation, StatMT
?07, pages 220?223, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010.
The pay-offs of preprocessing for German-English
Statistical Machine Translation. In Marcello Fed-
erico, Ian Lane, Michael Paul, and Franois Yvon, ed-
itors, Proceedings of the seventh International Work-
shop on Spoken Language Translation (IWSLT),
pages 251?258.
Daniel Dchelotte, Gilles Adda, Alexandre Allauzen,
Olivier Galibert, Jean-Luc Gauvain, Hlne Maynard,
and Franois Yvon. 2008. LIMSI?s statistical
translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Markus Freitag, Stephan Peitz, Matthias Huck, Her-
mann Ney, Teresa Herrmann, Jan Niehues, Alex
Waibel, Alexandre Allauzen, Gilles Adda, Bianka
Buschbeck, Josep Maria Crego, and Jean Senellart.
2012. Joint wmt 2012 submission of the quaero
project. In NAACL 2012 Seventh Workshop on Sta-
tistical Machine Translation, pages 322?329, Mon-
treal, Canada, June.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 847?855, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantine, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
pages 177?180, Prague, Czech Republic, June.
Alon Lavie and Abhaya Agarwal. 2007. ME-
TEOR: An Automatic Metric for MT Evaluation
with High Levels of Correlation with Human Judg-
ments. pages 228?231, Prague, Czech Republic,
June.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-
Luc Gauvain, and Franc?ois Yvon. 2011. Structured
output layer neural network language model. In Pro-
ceedings of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with
neural networks. In NAACL ?12: Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics
on Human Language Technology.
Saab Mansour and Hermann Ney. 2012. A sim-
ple and effective weighted phrase extraction for ma-
chine translation adaptation. In International Work-
shop on Spoken Language Translation, pages 193?
200, Hong Kong, December.
Sab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), San Francisco, CA,
December.
Jose? B. Marin?o, Rafael E. Banchs, Josep M. Crego,
Adria` de Gispert, Patrick Lambert, Jose? A.R. Fonol-
losa, and Marta R. Costa-Jussa`. 2006. N-gram-
based machine translation. Computational Linguis-
tics, 32(4):527?549.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-based Lexicon Models. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1 - Volume 1, EMNLP ?09, Singapore.
191
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation Systems for IWSLT
2011. In Proceedings of the Eighth Interna-
tional Workshop on Spoken Language Translation
(IWSLT).
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and
Alex Waibel. 2009. The Universita?t Karlsruhe
Translation System for the EACL-WMT 2009. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003a. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of
the 41th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 160?167, Sap-
poro, Japan, July.
Franz Josef Och. 2003b. Minimum error rate training
in statistical machine translation. In ACL ?03: Proc.
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160?167.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Nat-
ural Language Processing, Springer Verlag, LNCS,
pages 616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Work-
shop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to German.
In Evelyne Tzoukermann and SusanEditors Arm-
strong, editors, Proceedings of the ACL SIGDAT-
Workshop, pages 47?50. Kluwer Academic Publish-
ers.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. Int. Conf. on Spo-
ken Language Processing, volume 2, pages 901?
904, Denver, Colorado, USA.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In Pro-
ceedings of HLT-NAACL 2004, pages 101?104. As-
sociation for Computational Linguistics.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, pages 483?491, Mum-
bai, India, December.
192
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 193?199,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2013
Stephan Peitz, Saab Mansour, Jan-Thorsten Peter, Christoph Schmidt,
Joern Wuebker, Matthias Huck, Markus Freitag and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
This paper describes the statistical ma-
chine translation (SMT) systems devel-
oped at RWTH Aachen University for
the translation task of the ACL 2013
Eighth Workshop on Statistical Machine
Translation (WMT 2013). We partici-
pated in the evaluation campaign for the
French-English and German-English lan-
guage pairs in both translation directions.
Both hierarchical and phrase-based SMT
systems are applied. A number of dif-
ferent techniques are evaluated, including
hierarchical phrase reordering, translation
model interpolation, domain adaptation
techniques, weighted phrase extraction,
word class language model, continuous
space language model and system combi-
nation. By application of these methods
we achieve considerable improvements
over the respective baseline systems.
1 Introduction
For the WMT 2013 shared translation task1
RWTH utilized state-of-the-art phrase-based and
hierarchical translation systems as well as an in-
house system combination framework. We give
a survey of these systems and the basic meth-
ods they implement in Section 2. For both
the French-English (Section 3) and the German-
English (Section 4) language pair, we investigate
several different advanced techniques. We con-
centrate on specific research directions for each
of the translation tasks and present the respec-
tive techniques along with the empirical results
they yield: For the French?English task (Sec-
tion 3.2), we apply a standard phrase-based sys-
tem with up to five language models including a
1http://www.statmt.org/wmt13/
translation-task.html
word class language model. In addition, we em-
ploy translation model interpolation and hierarchi-
cal phrase reordering. For the English?French
task (Section 3.1), we train translation mod-
els on different training data sets and augment
the phrase-based system with a hierarchical re-
ordering model, a word class language model,
a discriminative word lexicon and a insertion
and deletion model. For the German?English
(Section 4.3) and English?German (Section 4.4)
tasks, we utilize morpho-syntactic analysis to pre-
process the data (Section 4.1), domain-adaptation
(Section 4.2) and a hierarchical reordering model.
For the German?English task, an augmented hi-
erarchical phrase-based system is set up and we
rescore the phrase-based baseline with a continu-
ous space language model. Finally, we perform a
system combination.
2 Translation Systems
In this evaluation, we employ phrase-based trans-
lation and hierarchical phrase-based translation.
Both approaches are implemented in Jane (Vilar et
al., 2012; Wuebker et al, 2012), a statistical ma-
chine translation toolkit which has been developed
at RWTH Aachen University and is freely avail-
able for non-commercial use.2
2.1 Phrase-based System
In the phrase-based decoder (source cardinality
synchronous search, SCSS), we use the standard
set of models with phrase translation probabilities
and lexical smoothing in both directions, word and
phrase penalty, distance-based distortion model,
an n-gram target language model and three bi-
nary count features. Optional additional models
used in this evaluation are the hierarchical reorder-
ing model (HRM) (Galley and Manning, 2008), a
word class language model (WCLM) (Wuebker et
2http://www.hltpr.rwth-aachen.de/jane/
193
al., 2012), a discriminative word lexicon (DWL)
(Mauser et al, 2009), and insertion and deletion
models (IDM) (Huck and Ney, 2012). The param-
eter weights are optimized with minimum error
rate training (MERT) (Och, 2003). The optimiza-
tion criterion is BLEU.
2.2 Hierarchical Phrase-based System
In hierarchical phrase-based translation (Chiang,
2007), a weighted synchronous context-free gram-
mar is induced from parallel text. In addition to
continuous lexical phrases, hierarchical phrases
with up to two gaps are extracted. The search is
carried out with a parsing-based procedure. The
standard models integrated into our Jane hierar-
chical systems (Vilar et al, 2010; Huck et al,
2012c) are: phrase translation probabilities and
lexical smoothing probabilities in both translation
directions, word and phrase penalty, binary fea-
tures marking hierarchical phrases, glue rule, and
rules with non-terminals at the boundaries, four
binary count features, and an n-gram language
model. Optional additional models comprise IBM
model 1 (Brown et al, 1993), discriminative word
lexicon and triplet lexicon models (Mauser et al,
2009; Huck et al, 2011), discriminative reordering
extensions (Huck et al, 2012a), insertion and dele-
tion models (Huck and Ney, 2012), and several
syntactic enhancements like preference grammars
(Stein et al, 2010) and soft string-to-dependency
features (Peter et al, 2011). We utilize the cube
pruning algorithm for decoding (Huck et al, 2013)
and optimize the model weights with MERT. The
optimization criterion is BLEU.
2.3 System Combination
System combination is used to produce consensus
translations from multiple hypotheses generated
with different translation engines. First, a word
to word alignment for the given single system hy-
potheses is produced. In a second step a confusion
network is constructed. Then, the hypothesis with
the highest probability is extracted from this con-
fusion network. For the alignment procedure, one
of the given single system hypotheses is chosen as
primary system. To this primary system all other
hypotheses are aligned using the METEOR (Lavie
and Agarwal, 2007) alignment and thus the pri-
mary system defines the word order. Once the
alignment is given, the corresponding confusion
network is constructed. An example is given in
Figure 1.
The model weights of the system combination
are optimized with standard MERT on 100-best
lists. For each single system, a factor is added to
the log-linear framework of the system combina-
tion. Moreover, this log-linear model includes a
word penalty, a language model trained on the in-
put hypotheses, a binary feature which penalizes
word deletions in the confusion network and a pri-
mary feature which marks the system which pro-
vides the word order. The optimization criterion is
4BLEU-TER.
2.4 Other Tools and Techniques
We employ GIZA++ (Och and Ney, 2003) to train
word alignments. The two trained alignments are
heuristically merged to obtain a symmetrized word
alignment for phrase extraction. All language
models (LMs) are created with the SRILM toolkit
(Stolcke, 2002) and are standard 4-gram LMs
with interpolated modified Kneser-Ney smooth-
ing (Kneser and Ney, 1995; Chen and Goodman,
1998). The Stanford Parser (Klein and Manning,
2003) is used to obtain parses of the training data
for the syntactic extensions of the hierarchical sys-
tem. We evaluate in truecase with BLEU (Papineni
et al, 2002) and TER (Snover et al, 2006).
2.5 Filtering of the Common Crawl Corpus
The new Common Crawl corpora contain a large
number of sentences that are not in the labelled
language. To clean these corpora, we first ex-
tracted a vocabulary from the other provided cor-
pora. Then, only sentences containing at least
70% word from the known vocabulary were kept.
In addition, we discarded sentences that contain
more words from target vocabulary than source
vocabulary on the source side. These heuristics
reduced the French-English Common Crawl cor-
pus by 5,1%. This filtering technique was also ap-
plied on the German-English version of the Com-
mon Crawl corpus.
3 French?English Setups
We trained phrase-based translation systems for
French?English and for English?French. Cor-
pus statistics for the French-English parallel data
are given in Table 1. The LMs are 4-grams trained
on the provided resources for the respective lan-
guage (Europarl, News Commentary, UN, 109,
Common Crawl, and monolingual News Crawl
194
0
1
5:
th
at
/1
7:
th
is/
3
2
3:
is/
3
8:
w
as
/1
3
0:
*E
PS
*/
3
4:
it/
1
4
0:
*E
PS
*/
3
2:
in
/1
5
0:
*E
PS
*/
3
6:
th
e/
1
6
0:
*E
PS
*/
1
1:
fu
tu
re
/3
Figure 1: Confusion network of four different hypotheses.
Table 1: Corpus statistics of the preprocessed
French-English parallel training data. EPPS de-
notes Europarl, NC denotes News Commentary,
CC denotes Common Crawl. In the data, numeri-
cal quantities have been replaced by a single cate-
gory symbol.
French English
EPPS Sentences 2.2M
+ NC Running Words 64.7M 59.7M
Vocabulary 153.4K 132.2K
CC Sentences 3.2M
Running Words 88.1M 80.9.0M
Vocabulary 954.8K 908.0K
UN Sentences 12.9M
Running Words 413.3M 362.3M
Vocabulary 487.1K 508.3K
109 Sentences 22.5M
Running Words 771.7M 661.1M
Vocabulary 1 974.0K 1 947.2K
All Sentences 40.8M
Running Words 1 337.7M 1 163.9M
Vocabulary 2 749.8K 2 730.1K
language model training data).3
3.1 Experimental Results English?French
For the English?French task, separate translation
models (TMs) were trained for each of the five
data sets and fed to the decoder. Four additional
indicator features are introduced to distinguish the
different TMs. Further, we applied the hierar-
chical reordering model, the word class language
model, the discriminative word lexicon, and the
insertion and deletion model. Table 2 shows the
results of our experiments.
As a development set for MERT, we use new-
stest2010 in all setups.
3.2 Experimental Results French?English
For the French?English task, a translation model
(TM) was trained on all available parallel data.
For the baseline, we interpolated this TM with
3The parallel 109 corpus is often also referred to as WMT
Giga French-English release 2.
an in-domain TM trained on EPPS+NC and em-
ployed the hierarchical reordering model. More-
over, three language models were used: The first
language model was trained on the English side
of all available parallel data, the second one on
EPPS and NC and the third LM on the News Shuf-
fled data. The baseline was improved by adding a
fourth LM trained on the Gigaword corpus (Ver-
sion 5) and a 5-gram word class language model
trained on News Shuffled data. For the WCLM,
we used 50 word classes clustered with the tool
mkcls (Och, 2000). All results are presented in Ta-
ble 3.
4 German?English Setups
For both translation directions of the German-
English language pair, we trained phrase-based
translation systems. Corpus statistics for German-
English can be found in Table 4. The language
models are 4-grams trained on the respective tar-
get side of the bilingual data as well as on the
provided News Crawl corpus. For the English
language model the 109 French-English, UN and
LDC Gigaword Fifth Edition corpora are used ad-
ditionally.
4.1 Morpho-syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the German text
is preprocessed by splitting German compound
words with the frequency-based method described
in (Koehn and Knight, 2003). To further reduce
translation complexity, we employ the long-range
part-of-speech based reordering rules proposed by
Popovic? and Ney (2006).
4.2 Domain Adaptation
This year, we experimented with filtering and
weighting for domain-adaptation for the German-
English task. To perform adaptation, we define a
general-domain (GD) corpus composed from the
news-commentary, europarl and Common Crawl
corpora, and an in-domain (ID) corpus using
a concatenation of the test sets (newstest{2008,
2009, 2010, 2011, 2012}) with the correspond-
ing references. We use the test sets as in-domain
195
Table 2: Results for the English?French task (truecase). newstest2010 is used as development set.
BLEU and TER are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011 newstest2012
English?French BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
TM:EPPS + HRM 22.9 63.0 25.0 60.0 27.8 56.7 28.9 54.4 27.2 57.1
TM:UN + HRM 22.7 63.4 25.0 60.0 28.3 56.4 29.5 54.2 27.3 57.1
TM:109 + HRM 23.5 62.3 26.0 59.2 29.6 55.2 30.3 53.3 28.0 56.4
TM:CC + HRM 23.5 62.3 26.2 58.8 29.2 55.3 30.3 53.3 28.2 56.0
TM:NC 21.0 64.8 22.3 61.6 25.6 58.7 26.9 56.6 25.7 58.5
+ HRM 21.5 64.3 22.6 61.2 26.1 58.4 27.3 56.1 26.0 58.2
+ TM:EPPS,CC,UN 23.9 61.8 26.4 58.6 29.9 54.7 31.0 52.7 28.6 55.6
+ TM:109 24.0 61.5 26.5 58.4 30.2 54.2 31.1 52.3 28.7 55.3
+ WCLM, DWL, IDM 24.0 61.6 26.5 58.3 30.4 54.0 31.4 52.1 28.8 55.2
Table 3: Results for the French?English task (truecase). newstest2010 is used as development set.
BLEU and TER are given in percentage.
newstest2010 newstest2011 newstest2012
French?English BLEU TER BLEU TER BLEU TER
SCSS baseline 28.1 54.6 29.1 53.3 - -
+ GigaWord.v5 LM 28.6 54.2 29.6 52.9 29.6 53.3
+ WCLM 29.1 53.8 30.1 52.5 29.8 53.1
(newswire) as the other corpora are coming from
differing domains (news commentary, parliamen-
tary discussions and various web sources), and on
initial experiments, the other corpora did not per-
form well when used as an in-domain representa-
tive for adaptation. To check whether over-fitting
occurs, we measure the results of the adapted
systems on the evaluation set of this year (new-
stest2013) which was not used as part of the in-
domain set.
The filtering experiments are done similarly to
(Mansour et al, 2011), where we compare filtering
using LM and a combined LM and IBM Model 1
(LM+M1) based scores. The scores for each sen-
tence pair in the general-domain corpus are based
on the bilingual cross-entropy difference of the
in-domain and general-domain models. Denoting
HLM (x) as the cross entropy of sentence x ac-
cording to LM , then the cross entropy difference
DHLM (x) can be written as:
DHLM (x) = HLMID(x)?HLMGD(x)
The bilingual cross entropy difference for a sen-
tence pair (s, t) in the GD corpus is then defined
by:
DHLM (s) + DHLM (t)
For IBM Model 1 (M1), the cross-entropy
HM1(s|t) is defined similarly to the LM cross-
entropy, and the resulting bilingual cross-entropy
difference will be of the form:
DHM1(s|t) + DHM1(t|s)
The combined LM+M1 score is obtained by
summing the LM and M1 bilingual cross-entropy
difference scores. To perform filtering, the GD
corpus sentence pairs are scored by the appropri-
ate method, sorted by the score, and the n-best sen-
tences are then used to build an adapted system.
In addition to adaptation using filtering, we ex-
periment with weighted phrase extraction similar
to (Mansour and Ney, 2012). We differ from their
work by using a combined LM+M1 weight to per-
form the phrase extraction instead of an LM based
weight. We use a combined LM+M1 weight as
this worked best in the filtering experiments, mak-
ing scoring with LM+M1 more reliable than LM
scores only.
4.3 Experimental Results German?English
For the German?English task, the baseline is
trained on all available parallel data and includes
the hierarchical reordering model. The results of
the various filtering and weighting experiments are
summarized in Table 5.
196
Table 5: German-English results (truecase). BLEU and TER are given in percentage. Corresponding
development set is marked with *. ? labels the single systems selected for the system combination.
newstest2009 newstest2010 newstest2011 newstest2012 newstest2013
German?English BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
SCSS baseline 21.7 61.1 24.8* 58.9* 22.0 61.1 23.4 60.0 26.1 56.4
LM 800K-best 21.6 60.5 24.7* 58.3* 22.0 60.5 23.6 59.7 - -
LM+M1 800K-best 21.4 60.5 24.7* 58.1* 22.0 60.4 23.7 59.2 - -
(LM+M1)*TM 22.1 60.2 25.4* 57.8* 22.5 60.1 24.0 59.1 - -
(LM+M1)*TM+GW 22.8 59.5 25.7* 57.2* 23.1 59.5 24.4 58.6 26.6 55.5
(LM+M1)*TM+GW? 22.9* 61.1* 25.2 59.3 22.8 61.5 23.7 60.8 26.4 57.1
SCSS baseline 22.6* 61.6* 24.1 60.1 22.1 62.0 23.1 61.2 - -
CSLM rescoring? 22.0 60.4 25.1* 58.3* 22.4 60.2 23.9 59.3 26.0 56.0
HPBT? 21.9 60.4 24.9* 58.2* 22.3 60.3 23.6 59.6 25.9 56.3
system combination - - - - 23.4* 59.3* 24.7 58.5 27.1 55.3
Table 6: English-German results (truecase). newstest2009 was used as development set. BLEU and TER
are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011 newstest2012
English?German BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
SCSS baseline 14.9 70.9 14.9 70.4 16.0 66.3 15.4 69.5 15.7 67.5
LM 800K-best 15.1 70.9 15.1 70.3 16.2 66.3 15.6 69.4 15.9 67.4
(LM+M1) 800K-best 15.8 70.8 15.4 70.0 16.2 66.2 16.0 69.3 16.1 67.4
(LM+M1) ifelse 16.1 70.6 15.7 69.9 16.5 66.0 16.2 69.2 16.3 67.2
Table 4: Corpus statistics of the preprocessed
German-English parallel training data (Europarl,
News Commentary and Common Crawl). In the
data, numerical quantities have been replaced by a
single category symbol.
German English
Sentences 4.1M
Running Words 104M 104M
Vocabulary 717K 750K
For filtering, we use the 800K best sentences
from the whole training corpora, as this se-
lection performed best on the dev set among
100K,200K,400K,800K,1600K setups. Filtering
seems to mainly improve on the TER scores, BLEU
scores are virtually unchanged in comparison to
the baseline. LM+M1 filtering improves further
on TER in comparison to LM-based filtering.
The weighted phrase extraction performs best
in our experiments, where the weights from the
LM+M1 scoring method are used. Improvements
in both BLEU and TER are achieved, with BLEU
improvements ranging from +0.4% up-to +0.6%
and TER improvements from -0.9% and up-to -
1.1%.
As a final step, we added the English Gigaword
corpus to the LM (+GW). This resulted in further
improvements of the systems.
In addition, the system as described above was
tuned on newstest2009. Using this development
set results in worse translation quality.
Furthermore, we rescored the SCSS baseline
tuned on newstest2009 with a continuous space
language model (CSLM) as described in (Schwenk
et al, 2012). The CSLM was trained on the eu-
roparl and news-commentary corpora. For rescor-
ing, we used the newstest2011 set as tuning set and
re-optimized the parameters with MERT on 1000-
best lists. This results in an improvement of up to
0.8 points in BLEU compared to the baseline.
We compared the phrase-based setups with a
hierarchical translation system, which was aug-
mented with preference grammars, soft string-
to-dependency features, discriminative reordering
extensions, DWL, IDM, and discriminative re-
197
ordering extensions. The phrase table of the hier-
archical setup has been extracted from News Com-
mentary and Europarl parallel data only (not from
Common Crawl).
Finally, three setups were joined in a system
combination and we gained an improvement of up
to 0.5 points in BLEU compared to the best single
system.
4.4 Experimental Results English?German
The results for the English?German task are
shown in Table 6. While the LM-based filter-
ing led to almost no improvement over the base-
line, the LM+M1 filtering brought some improve-
ments in BLEU. In addition to the sentence fil-
tering, we tried to combine the translation model
trained on NC+EPPS with a TM trained on Com-
mon Crawl using the ifelse combination (Mansour
and Ney, 2012). This combination scheme con-
catenates both TMs and assigns the probabilities
of the in-domain TM if it contains the phrase,
else it uses the probabilities of the out-of-domain
TM. Appling this method, we achieved further im-
provements.
5 Conclusion
For the participation in the WMT 2013 shared
translation task, RWTH experimented with both
phrase-based and hierarchical translation systems.
Several different techniques were evaluated and
yielded considerable improvements over the re-
spective baseline systems as well as over our last
year?s setups (Huck et al, 2012b). Among these
techniques are a hierarchical phrase reordering
model, translation model interpolation, domain
adaptation techniques, weighted phrase extraction,
a word class language model, a continuous space
language model and system combination.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263?311, June.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, Massachusetts, USA, August.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 847?855, Honolulu, Hawaii, USA,
October.
Matthias Huck and Hermann Ney. 2012. Insertion and
Deletion Models for Statistical Machine Translation.
In Proceedings of the North American Chapter of the
Association for Computational Linguistics - Human
Language Technologies conference, pages 347?351,
Montre?al, Canada, June.
Matthias Huck, Saab Mansour, Simon Wiesler, and
Hermann Ney. 2011. Lexicon Models for Hierar-
chical Phrase-Based Machine Translation. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 191?198, San
Francisco, California, USA, December.
Matthias Huck, Stephan Peitz, Markus Freitag, and
Hermann Ney. 2012a. Discriminative Reordering
Extensions for Hierarchical Phrase-Based Machine
Translation. In 16th Annual Conference of the Eu-
ropean Association for Machine Translation, pages
313?320, Trento, Italy, May.
Matthias Huck, Stephan Peitz, Markus Freitag, Malte
Nuhn, and Hermann Ney. 2012b. The RWTH
Aachen Machine Translation System for WMT
2012. In NAACL 2012 Seventh Workshop on
Statistical Machine Translation, pages 304?311,
Montre?al, Canada, June.
Matthias Huck, Jan-Thorsten Peter, Markus Freitag,
Stephan Peitz, and Hermann Ney. 2012c. Hierar-
chical Phrase-Based Translation with Jane 2. The
Prague Bulletin of Mathematical Linguistics, 98:37?
50, October.
Matthias Huck, David Vilar, Markus Freitag, and
Hermann Ney. 2013. A Performance Study of
Cube Pruning for Large-Scale Hierarchical Machine
Translation. In Proceedings of the NAACL 7thWork-
shop on Syntax, Semantics and Structure in Statis-
tical Translation, pages 29?38, Atlanta, Georgia,
USA, June.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proc. of the 41th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 423?430, Sapporo, Japan,
July.
198
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-gram Language Model-
ing. In Proceedings of the International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 181?184, May.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings of
European Chapter of the ACL (EACL 2009), pages
187?194.
Alon Lavie and Abhaya Agarwal. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
ACL 2007 Second Workshop on Statistical Machine
Translation, pages 228?231, Prague, Czech Repub-
lic, June.
Saab Mansour and Hermann Ney. 2012. A Simple and
Effective Weighted Phrase Extraction for Machine
Translation Adaptation. In Proceedings of the Inter-
national Workshop on Spoken Language Translation
(IWSLT), pages 193?200, Hong Kong, December.
Saab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 222?229, San
Francisco, California, USA, December.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Proc. of the Conf. on Empirical Methods for Natu-
ral Language Processing (EMNLP), pages 210?218,
Singapore, August.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2000. mkcls: Training
of word classes for language modeling.
http://www.hltpr.rwth-aachen.de/
web/Software/mkcls.html.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proceed-
ings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 311?318,
Philadelphia, Pennsylvania, USA, July.
Jan-Thorsten Peter, Matthias Huck, Hermann Ney, and
Daniel Stein. 2011. Soft String-to-Dependency
Hierarchical Machine Translation. In International
Workshop on Spoken Language Translation, pages
246?253, San Francisco, California, USA, Decem-
ber.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Transla-
tion. In International Conference on Language Re-
sources and Evaluation, pages 1278?1283, Genoa,
Italy, May.
Holger Schwenk, Anthony Rousseau, and Mohammed
Attik. 2012. Large, Pruned or Continuous Space
Language Models on a GPU for Statistical Machine
Translation. In NAACL-HLT 2012 Workshop: Will
We Ever Really Replace the N-gram Model? On the
Future of Language Modeling for HLT, pages 11?
19, Montre?al, Canada, June.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA,
August.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Conf.
of the Association for Machine Translation in the
Americas (AMTA), Denver, Colorado, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, Colorado, USA,
September.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchi-
cal Translation, Extended with Reordering and Lex-
icon Models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197?216, September.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2:
Open Source Phrase-based and Hierarchical Statis-
tical Machine Translation. In International Confer-
ence on Computational Linguistics, pages 483?491,
Mumbai, India, December.
199
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452?463,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
A Phrase Orientation Model for Hierarchical Machine Translation
Matthias Huck and Joern Wuebker and Felix Rietig and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
{huck,wuebker,rietig,ney}@i6.informatik.rwth-aachen.de
Abstract
We introduce a lexicalized reordering
model for hierarchical phrase-based ma-
chine translation. The model scores mono-
tone, swap, and discontinuous phrase ori-
entations in the manner of the one pre-
sented by Tillmann (2004). While this
type of lexicalized reordering model is a
valuable and widely-used component of
standard phrase-based statistical machine
translation systems (Koehn et al, 2007), it
is however commonly not employed in hi-
erarchical decoders.
We describe how phrase orientation prob-
abilities can be extracted from word-
aligned training data for use with hierar-
chical phrase inventories, and show how
orientations can be scored in hierarchi-
cal decoding. The model is empirically
evaluated on the NIST Chinese?English
translation task. We achieve a signifi-
cant improvement of +1.2 %BLEU over
a typical hierarchical baseline setup and
an improvement of +0.7 %BLEU over a
syntax-augmented hierarchical setup. On
a French?German translation task, we
obtain a gain of up to +0.4 %BLEU.
1 Introduction
In hierarchical phrase-based translation (Chiang,
2005), a probabilistic synchronous context-free
grammar (SCFG) is induced from bilingual train-
ing corpora. In addition to continuous lexical
phrases as in standard phrase-based translation,
hierarchical phrases with usually up to two non-
terminals are extracted from the word-aligned par-
allel training data.
Hierarchical decoding is typically carried out
with a parsing-based procedure. The parsing al-
gorithm is extended to handle translation candi-
dates and to incorporate language model scores
via cube pruning (Chiang, 2007). During decod-
ing, a hierarchical translation rule implicitly spec-
ifies the placement of the target part of a sub-
derivation which is substituting one of its non-
terminals in a partial hypothesis. The hierarchical
phrase-based model thus provides an integrated re-
ordering mechanism. The reorderings which are
being conducted by the hierarchical decoder are
a result of the application of SCFG rules, which
generally means that there must have been some
evidence in the training data for each reordering
operation. At first glance one might be tempted to
believe that any additional designated phrase ori-
entation modeling would be futile in hierarchical
translation as a consequence of this. We argue
that such a conclusion is false, and we will pro-
vide empirical evidence in this work that lexical-
ized phrase orientation scoring can be highly ben-
eficial not only in standard phrase-based systems,
but also in hierarchical ones.
The purpose of a phrase orientation model is
to assess the adequacy of phrase reordering dur-
ing search. In standard phrase-based translation
with continuous phrases only and left-to-right hy-
pothesis generation (Koehn et al, 2003; Zens and
Ney, 2008), phrase reordering is implemented by
jumps within the input sentence. The choice of the
best order for the target sequence is made based
on the language model score of this sequence and
a distortion cost that is computed from the source-
side jump distances. Though the space of admis-
sible reorderings is in most cases contrained by a
maximum jump width or coverage-based restric-
tions (Zens et al, 2004) for efficiency reasons,
the basic approach of arbitrarily jumping to un-
covered positions on source side is still very per-
missive. Lexicalized reordering models assist the
decoder in taking a good decision. Phrase-based
decoding allows for a straightforward integration
of lexicalized reordering models which assign
452
different scores depending on how a currently
translated phrase has been reordered with respect
to its context. Popular lexicalized reordering mod-
els for phrase-based translation distinguish three
orientation classes: monotone, swap, and discon-
tinuous (Tillmann, 2004; Koehn et al, 2007; Gal-
ley and Manning, 2008). To obtain such a model,
scores for the three classes are calculated from the
counts of the respective orientation occurrences in
the word-aligned training data for each extracted
phrase. The left-to-right orientation of phrases
during phrase-based search can be easily deter-
mined from the start and end positions of con-
tinuous phrases. Approximations may need to be
adopted for the right-to-left scoring direction.
The utility of phrase orientation models in stan-
dard phrase-based translation is plausible and has
been empirically established in practice. In hierar-
chical phrase-based translation, some other types
of lexicalized reordering models have been inves-
tigated recently (He et al, 2010a; He et al, 2010b;
Hayashi et al, 2010; Huck et al, 2012a), but
in none of them are the orientation scores condi-
tioned on the lexical identity of each phrase in-
dividually. These models are rather word-based
and applied on block boundaries. Experimental
results obtained with these other types of lexical-
ized reordering models have been very encourag-
ing, though.
There are certain reasons why assessing the ad-
equacy of phrase reordering should be useful in
hierarchical search:
? Albeit phrase reorderings are always a result
of the application of SCFG rules, the decoder
is still able to choose from many different
parses of the input sentence.
? The decoder can furthermore choose from
many translation options for each given
parse, which result in different reorderings
and different phrases being embedded in the
reordering non-terminals.
? All other models only weakly connect an em-
bedded phrase with the hierarchical phrase it
is placed into, in particular as the set of non-
terminals of the hierarchical grammar only
contains two generic non-terminal symbols.
We therefore investigate phrase orientation mod-
eling for hierarchical translation in this work.
2 Outline
The remainder of the paper is structured as fol-
lows: We briefly outline important related pub-
lications in the following section. We subse-
quently give a summary of some essential aspects
of the hierarchical phrase-based translation ap-
proach (Section 4). Phrase orientation modeling
and a way in which a phrase orientation model can
be trained for hierarchical phrase inventories are
explained in Section 5. In Section 6 we introduce
an extension of hierarchical search which enables
the decoder to score phrase orientations. Empiri-
cal results are presented in Section 7. We conclude
the paper in Section 8.
3 Related Work
Hierarchical phrase-based translation was pro-
posed by Chiang (2005). He et al (2010a) inte-
grated a maximum entropy based lexicalized re-
ordering model with word- and class-based fea-
tures. Different classifiers for different rule pat-
terns are trained for their model (He et al,
2010b). A comparable discriminatively trained
model which applies a single classifier for all types
of rules was developed by Huck et al (2012a).
Hayashi et al (2010) explored the word-based re-
ordering model by Tromble and Eisner (2009) in
hierarchical translation.
For standard phrase-based translation, Galley
and Manning (2008) introduced a hierarchical
phrase orientation model. Similar to previous ap-
proaches (Tillmann, 2004; Koehn et al, 2007), it
distinguishes the three orientation classes mono-
tone, swap, and discontinuous. However, it differs
in that it is not limited to model local reordering
phenomena, but allows for phrases to be hierarchi-
cally combined into blocks in order to determine
the orientation class. This has the advantage that
probability mass is shifted from the rather uninfor-
mative default category discontinuous to the other
two orientation classes, which model the location
of a phrase more specifically. In this work, we
transfer this concept to a hierarchical phrase-based
machine translation system.
4 Hierarchical Phrase-Based Translation
The non-terminal set of a standard hierarchical
grammar comprises two symbols which are shared
by source and target: the initial symbol S and one
generic non-terminal symbol X . The generic non-
terminal X is used as a placeholder for the gaps
453
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(a) Monotone phrase orientation.
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(b) Swap phrase orientation.
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(c) Discontinuous phrase orientation.
Figure 1: Extraction of the orientation classes monotone, swap, and discontinuous from word-aligned
training samples. The examples show the left-to-right orientation of the shaded phrases. The dashed
rectangles indicate how the predecessor words are merged into blocks with regard to their word align-
ment.
within the right-hand side of hierarchical transla-
tion rules as well as on all left-hand sides of the
translation rules that are extracted from the paral-
lel training corpus.
Extracted rules of a standard hierarchical gram-
mar are of the form X ? ??, ?,? ? where ??, ??
is a bilingual phrase pair that may contain X , i.e.
? ? ({X } ? VF )+ and ? ? ({X } ? VE)+, where
VF and VE are the source and target vocabulary,
respectively. The non-terminals on the source side
and on the target side of hierarchical rules are
linked in a one-to-one correspondence. The ? re-
lation defines this one-to-one correspondence. In
addition to the extracted rules, a non-lexicalized
initial rule
S ? ?X?0, X?0? (1)
is engrafted into the hierarchical grammar, as well
as a special glue rule
S ? ?S?0X?1, S?0X?1? (2)
that the system can use for serial concatenation
of phrases as in monotonic phrase-based transla-
tion. The initial symbol S is the start symbol of
the grammar.
Hierarchical search is conducted with a cus-
tomized version of the CYK+ parsing algo-
rithm (Chappelier and Rajman, 1998) and cube
pruning (Chiang, 2007). A hypergraph which rep-
resents the whole parsing space is built employing
CYK+. Cube pruning operates in bottom-up topo-
logical order on this hypergraph and expands at
most k derivations at each hypernode.
5 Modeling Phrase Orientation for
Hierarchical Machine Translation
The phrase orientation model we are using was
introduced by Galley and Manning (2008). To
model the sequential order of phrases within the
global translation context, the three orientation
classes monotone (M), swap (S) and discontinu-
ous (D) are distinguished, each in both left-to-
right and right-to-left direction. In order to cap-
ture the global rather than the local context, previ-
ous phrases can be merged into blocks if they are
consistent with respect to the word alignment. A
phrase is in monotone orientation if a consistent
monotone predecessor block exists, and in swap
orientation if a consistent swap predecessor block
exists. Otherwise it is in discontinuous orientation.
Given a sequence of source words fJ1 and a se-
quence of target words eI1, a block ?f j2j1 , ei2i1? (with
1 ? j1 ? j2 ? J and 1 ? i1 ? i2 ? I)
is consistent with respect to the word alignment
A ? {1, ..., I} ? {1, ..., J} iff
?(i, j) ? A : i1 ? i ? i2 ? j1 ? j ? j2
? ?(i, j) ? A : i1 ? i ? i2 ? j1 ? j ? j2.
(3)
Consistency is based upon two conditions in this
definition: (1.) At least one source and target po-
sition within the block must be aligned, and (2.)
words from inside the source interval may only
be aligned to words from inside the target inter-
val and vice versa. These are the same condi-
tions as those that are applied for the extraction of
454
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(a) A monotone orientation.
Left-to-right orientation counts:
N(M |f2X?0f4, e2X?0e4) = 1
N(S|f2X?0f4, e2X?0e4) = 0
N(D|f2X?0f4, e2X?0e4) = 0
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(b) Another monotone orientation.
Left-to-right orientation counts:
N(M |f2X?0f4, e2X?0e4) = 2
N(S|f2X?0f4, e2X?0e4) = 0
N(D|f2X?0f4, e2X?0e4) = 0
f1
f2
f3
f4
f5
e1 e2 e3 e4 e5
target
so
ur
ce
(c) A swap orientation.
Left-to-right orientation counts:
N(M |f2X?0f4, e2X?0e4) = 2
N(S|f2X?0f4, e2X?0e4) = 1
N(D|f2X?0f4, e2X?0e4) = 0
Figure 2: Accumulation of orientation counts for hierarchical phrases during extraction. The hierarchical
phrase ?f2X?0f4, e2X?0e4? (dark shaded) can be extracted from all the three training samples. Its
orientation is identical to the orientation of the continuous phrase (lightly shaded) which the sub-phrase
is cut out of, respectively. Note that the actual lexical content of the sub-phrase may differ. For instance,
the sub-phrase ?f3, e3? is being cut out in Fig. 2a, and the sub-phrase ?f6, e6? is being cut out in Fig. 2b.
standard continuous phrases. The only difference
is that length constraints are applied to phrases, but
not to blocks.
Figure 1 illustrates the extraction of monotone,
swap, and discontinuous orientation classes in
left-to-right direction from word-aligned bilingual
training samples. The right-to-left direction works
analogously.
We found that this concept can be neatly
plugged into the hierarchical phrase-based trans-
lation paradigm, without having to resort to ap-
proximations in decoding, which is necessary to
determine the right-to-left orientation in a standard
phrase-based system (Cherry et al, 2012). To train
the orientations, the extraction procedure from the
standard phrase-based version of the reordering
model can be used with a minor extension. The
model is trained on the same word-aligned data
from which the translation rules are extracted. For
each training sentence, we extract all phrases of
unlimited length that are consistent with the word
alignment, and store their corners in a matrix. The
corners are distinguished by their location: top-
left, top-right, bottom-left, and bottom-right. For
each bilingual phrase, we determine its left-to-
right and right-to-left orientation by checking for
adjacent corners.
The lexicalized orientation probability for the
orientation O ? {M,S,D} and the phrase pair
??, ?? is estimated as its smoothed relative fre-
quency:
p(O) = N(O)?
O??{M,S,D}N(O?)
(4)
p(O|?, ?) = ? ? p(O) +N(O|?, ?)
? +
?
O??{M,S,D}N(O?|f? , e?)
.
(5)
Here, N(O) denotes the global count and
N(O|?, ?) the lexicalized count for the orienta-
tion O. ? is a smoothing constant.
To determine the orientation frequency for a hi-
erarchical phrase with non-terminal symbols, the
orientation counts of all those phrases are accu-
mulated from which a sub-phrase is cut out and
replaced by a non-terminal symbol to obtain this
hierarchical phrase. Figure 2 gives an example.
Negative logarithms of the values are used as
costs in the log-linear model combination (Och
and Ney, 2002). Cost 0 for all orientations is as-
signed to the special rules which are not extracted
from the training data (initial and glue rule).
455
f1
f2
f3
45e
f
	1 	2 	3 45e	
target
so
ur
ce
(a) Monotone non-terminal orientation.
f1
234
f5
fe
f
	1 	5 	e 234	
target
so
ur
ce
(b) Swap non-terminal orientation.
f1
f2
345
fe
f
	1 	2 345 	
target
so
ur
ce
	e
(c) Discontinuous non-terminal orienta-
tion.
Figure 3: Scoring with the orientation classes monotone, swap, and discontinuous. Each picture shows
exactly one hierarchical phrase. The block which replaces the non-terminalX during decoding is embed-
ded with the orientation of this non-terminal X within the hierarchical phrase. The examples show the
left-to-right orientation of the non-terminal. The left-to-right orientation can be detected from the word
alignment of the hierarchical phrase, except for cases where the non-terminal is in boundary position on
target side.
6 Phrase Orientation Scoring in
Hierarchical Decoding
Our implementation of phrase orientation scoring
in hierarchical decoding is based on the observa-
tion that hierarchical rule applications, i.e. the us-
age of rules with non-terminals within their right-
hand sides, settle the target sequence order. Mono-
tone, swap, or discontinuous orientations of blocks
are each due to monotone, swap, or discontinuous
placement of non-terminals which are being sub-
stituted by these blocks.
The problem of phrase orientation scoring can
thus be mostly reduced to three steps which need
to be carried out whenever a hierarchical rule is
applied:
1. Determining the orientations of the non-
terminals in the rule.
2. Retrieving the proper orientation cost of the
topmost rule application in the sub-derivation
which corresponds to the embedded block for
the respective non-terminal.
3. Applying the orientation cost to the log-linear
model combination for the current derivation.
The orientation of a non-terminal in a hierarchi-
cal rule is dependent on the word alignments in
its context. Figure 3 depicts three examples.1 We
however need to deal with special cases where a
non-terminal orientation cannot be established at
the moment when the hierarchical rule is consid-
ered. We first describe the non-degenerate case
(Section 6.1). Afterwards we briefly discuss our
strategy in the special situation of boundary non-
terminals where the non-terminal orientation can-
not be determined from information which is in-
herent to the hierarchical rule under consideration
(Section 6.3).
We focus on left-to-right orientation scoring;
right-to-left scoring is symmetric.
6.1 Determining Orientations
In order to determine the orientation class of a
non-terminal, we rely on the word alignments
within the phrases. With each phrase, we store
the alignment matrix that has been seen most fre-
quently during phrase extraction. Non-terminal
symbols on target side are assumed to be aligned
to the respective non-terminal symbols on source
1Note that even maximal consecutive lexical intervals (ei-
ther on source or target side) are not necessarily aligned in
a way which makes them consistent bilingual blocks. In
Fig. 3a, e4 is for instance aligned both below and above
the non-terminal. In Fig. 3c, neither ?f1f2, e1e2? nor
?f1f2, e3e4? would be valid continuous phrases (the same
holds for ?f3f4, e1e2? and ?f3f4, e3e4?). We actually need
the generalization of the phrase orientation model to hierar-
chical phrases as described in Section 5 for this reason. Oth-
erwise we would be able to just score neighboring consistent
sub-blocks with a model that does not account for hierarchi-
cal phrases with non-terminals.
456
f1
f2
f3
45e
f
	1 	2 	3 45e	
f

		

target
so
ur
ce
(a) Last previous aligned target position.
f1
f2
f3
45e
f
	1 	2 	3 45e	
f

		

target
so
ur
ce
(b) Initial box.
f1
f2
f3
45e
f
	1 	2 	3 45e	
f

		

target
so
ur
ce
(c) Expansion of the initial box.
f1
f2
f3
45e
f
	1 	2 	3 45e	
f

		

target
so
ur
ce
(d) The final box is a consistent left-to-right mono-
tone predecessor block of the non-terminal.
Figure 4: Determining the orientation class during decoding. Starting from the last previous aligned
target position, a box is spanned across the relevant alignment links onto the corner of the non-terminal.
The box is then checked for consistency.
side according to the ? relation. In the alignment
matrix, the rows and columns of non-terminals can
obviously contain only exactly this one alignment
link.
Starting from the last previous aligned target po-
sition to the left of the non-terminal, the algorithm
expands a box that spans across the other rele-
vant alignment links onto the corner of the non-
terminal. Afterwards it checks whether the areas
on the opposite sides of the non-terminal position
are non-aligned in the source and target intervals
of this box. The non-terminal is in discontinu-
ous orientation if the box is not a consistent block.
If the box is a consistent block, the non-terminal
is in monotone orientation if its source-side posi-
tion is larger than the maximum of the source-side
interval of the box, and in swap orientation if its
source-side position is smaller than the minimum
of the source-side interval of the box.
Figure 4 illustrates how the procedure operates.
In left-to-right direction, an initial box is spanned
from the last previous aligned target position to
the lower (monotone) or upper (swap) left cor-
ner of the non-terminal. In the example, starting
from ?f3, e5? (Fig. 4a), this initial box is spanned
to the lower left corner by iterating from f3 to
f4 and expanding its target interval to the mini-
mum aligned target position within these two rows
of the alignment matrix. The initial box cov-
ers ?f3f4, e3e4e5? (Fig. 4b). The procedure then
repeatedly checks whether the box needs to be
expanded?alternating to the bottom (monotone)
or top (swap) and to the left?until no alignment
links below or to the left of the box break the
consistency. Two box expansion are conducted
in the example: the first one expands the ini-
tial box below, resulting in a larger box which
covers ?f1f2f3f4, e3e4e5? (Fig. 4c); the second
457
f1
f2
345
e1345
target
so
ur
ce
(a) Left boundary non-
terminal that can be placed
in left-to-right monotone or
discontinuous orientation
when the phrase is embedded
into another one.
f1
f2
345
e1345
target
so
ur
ce
(b) Left boundary non-
terminal that can be placed
in left-to-right discontinuous
or swap orientation when
the phrase is embedded into
another one.
f1
f2345
e1 345
target
so
ur
ce
(c) Left boundary non-
terminal that can be placed in
left-to-right monotone, swap,
or discontinuous orientation
when the phrase is embedded
into another one.
f1
f2345
e1345
target
so
ur
ce
(d) Left boundary non-
terminal that can only be
placed in left-to-right dis-
continuous orientation when
the phrase is embedded into
another one.
Figure 5: Left boundary non-terminal symbols. Orientations the non-terminal can eventually turn out to
get placed in differ depending on existing alignment links in the rest of the phrase. Delayed left-to-right
scoring is not required in cases as in Fig. 5d. Fractional costs for the possible orientations are temporarily
applied in the other cases and recursively corrected as soon as an orientation is constituted in an upper
hypernode.
one expands this new box to the left, resulting in
a final box which covers ?f1f2f3f4, e1e2e3e4e5?
(Fig. 4d) and does not need to be expanded to-
wards the lower left corner any more. Afterwards
the procedure examines whether the final box is
a consistent block by inspecting whether the ar-
eas on the opposite side of the non-terminal po-
sition are non-aligned in the intervals of the box
(areas with waved lines in the Fig. 4d). These ar-
eas do not contain alignment links in the example:
the orientation class of the non-terminal is mono-
tone as it has a consistent left-to-right monotone
predecessor block. (Suppose an alignment link
?f5, e2? would break the consistency: the orienta-
tion class would then be discontinuous as the final
box would not be a consistent block.)
Orientations of non-terminals could basically be
precomputed and stored in the translation table.
We however compute them on demand during de-
coding. The computational overhead did not seem
to be too severe in our experiments.
6.2 Scoring Orientations
Once the orientation is determined, the proper ori-
entation cost of the embedded block needs to be
retrieved. We access the topmost rule application
in the sub-derivation which corresponds to the em-
bedded block for the respective non-terminal and
read the orientation model costs for this rule. The
special case of delayed scoring for boundary non-
terminals as described in the subsequent section is
recursively processed if necessary. The retrieved
orientation costs of the embedded blocks of all
non-terminals are finally added to the log-linear
model combination for the current derivation.
6.3 Boundary Non-Terminals
Cases where a non-terminal orientation cannot be
established at the moment when the hierarchi-
cal rule is considered arise when a non-terminal
symbol is in a boundary position on target side.
We define a non-terminal to be in (left or right)
boundary position iff no symbols are aligned be-
tween the phrase-internal target-side index of the
non-terminal and the (left or right) phrase bound-
ary. Left boundary positions of non-terminals
are critical for left-to-right orientation scoring,
right boundary positions for right-to-left orienta-
tion scoring. We denote non-terminals in bound-
ary position as boundary non-terminals.
The procedure as described in Section 6.1 is not
applicable to boundary non-terminals because a
last previous aligned target position does not ex-
ist. If it is impossible to determine the final non-
terminal orientation in the hypothesis from infor-
mation which is inherent to the phrase, we are
forced to delay the orientation scoring of the em-
bedded block. Our solution in these cases is to
heuristically add fractional costs of all orientations
the non-terminal can still eventually turn out to get
placed in (cf. Figure 5). We do so because not
adding an orientation cost to the derivation would
give it an unjustified advantage over other ones.
As soon as an orientation is constituted in an up-
458
per hypernode, any heuristic and actual orientation
costs can be collected by means of a recursive call.
Note that monotone or swap orientations in upper
hypernodes can top-down transition into discon-
tinuous orientations for boundary non-terminals,
depending on existing phrase-internal alignment
links in the context of the respective boundary
non-terminal. In the derivation at the upper hyper-
node, the heuristic costs are subtracted and the cor-
rect actual costs added. Delayed scoring can lead
to search errors; in order to keep them confined,
the delayed scoring needs to be done separately
for all derivations, not just for the first-best sub-
derivations along the incoming hyperedges.
7 Experiments
We evaluate the effect of phrase orienta-
tion scoring in hierarchical translation on the
Chinese?English 2008 NIST task2 and on the
French?German language pair using the standard
WMT3 newstest sets for development and testing.
7.1 Experimental Setup
We work with a Chinese?English parallel train-
ing corpus of 3.0 M sentence pairs (77.5 M Chi-
nese / 81.0 M English running words). To train the
German?French baseline system, we use 2.0 M
sentence pairs (53.1 M French / 45.8 M German
running words) that are partly taken from the
Europarl corpus (Koehn, 2005) and have partly
been collected within the Quaero project.4
Word alignments are created by aligning the
data in both directions with GIZA++5 and sym-
metrizing the two trained alignments (Och and
Ney, 2003). When extracting phrases, we ap-
ply several restrictions, in particular a maximum
length of ten on source and target side for lexi-
cal phrases, a length limit of five on source and
ten on target side for hierarchical phrases (includ-
ing non-terminal symbols), and no more than two
non-terminals per phrase.
A standard set of models is used in the base-
lines, comprising phrase translation probabilities
and lexical translation probabilities in both direc-
tions, word and phrase penalty, binary features
marking hierarchical rules, glue rule, and rules
2http://www.itl.nist.gov/iad/mig/
tests/mt/2008/
3http://www.statmt.org/wmt13/
translation-task.html
4http://www.quaero.org
5http://code.google.com/p/giza-pp/
with non-terminals at the boundaries, three sim-
ple count-based binary features, phrase length ra-
tios, and a language model. The language models
are 4-grams with modified Kneser-Ney smooth-
ing (Kneser and Ney, 1995; Chen and Goodman,
1998) which have been trained with the SRILM
toolkit (Stolcke, 2002).
Model weights are optimized against BLEU (Pa-
pineni et al, 2002) with MERT (Och, 2003) on
100-best lists. For Chinese?English we employ
MT06 as development set, MT08 is used as unseen
test set. For German?French we employ news-
test2009 as development set, newstest2008, news-
test2010, and newstest2011 are used as unseen test
sets. During decoding, a maximum length con-
straint of ten is applied to all non-terminals except
the initial symbol S . Translation quality is mea-
sured in truecase with BLEU and TER (Snover et
al., 2006). The results on MT08 are checked for
statistical significance over the baseline. Confi-
dence intervals have been computed using boot-
strapping for BLEU and Cochran?s approximate
ratio variance for TER (Leusch and Ney, 2009).
7.2 Chinese?English Experimental Results
Table 1 comprises all results of our empirical eval-
uation on the Chinese?English task.
We first compare the performance of the phrase
orientation model in left-to-right direction only
with the performance of the phrase orientation
model in left-to-right and right-to-left direction
(bidirectional). In all experiments, monotone,
swap, and discontinuous orientation costs are
treated as being from different feature functions
in the log-linear model combination: we assign
a separate scaling factor to each of the orienta-
tions. We have three more scaling factors than in
the baseline for left-to-right direction only, and six
more scaling factors for bidirectional phrase ori-
entation scoring. As can be seen from the results
table, the left-to-right model already yields a gain
of 1.1 %BLEU over the baseline on the unseen test
set (MT08). The bidirectional model performs just
slightly better (+1.2 %BLEU over the baseline).
With both models, the TER is reduced significantly
as well (-1.1 / -1.3 compared to the baseline). We
adopted the discriminative lexicalized reordering
model (discrim. RO) that has been suggested by
Huck et al (2012a) for comparison purposes. The
phrase orientation model provides clearly better
translation quality in our experiments.
459
MT06 (Dev) MT08 (Test)
NIST Chinese?English BLEU [%] TER [%] BLEU [%] TER [%]
HPBT Baseline 32.6 61.2 25.2 66.6
+ discrim. RO 33.0 61.3 25.8 66.0
+ phrase orientation (left-to-right) 33.3 60.7 26.3 65.5
+ phrase orientation (bidirectional) 33.2 60.6 26.4 65.3
+ swap rule 32.8 61.7 25.8 66.6
+ discrim. RO 33.1 61.2 26.0 66.1
+ phrase orientation (bidirectional) 33.3 60.7 26.5 65.3
+ binary swap feature 33.2 61.0 25.9 66.2
+ discrim. RO 33.2 61.3 26.2 66.1
+ phrase orientation (bidirectional) 33.6 60.5 26.6 65.1
+ soft syntactic labels 33.4 60.8 26.1 66.4
+ phrase orientation (bidirectional) 33.7 60.1 26.8 65.1
+ phrase-level s2t+t2s DWL + triplets 34.3 60.1 27.7 65.0
+ discrim. RO 34.8 59.8 27.7 64.7
+ phrase orientation (bidirectional) 35.3 59.0 28.4 63.7
Table 1: Experimental results for the NIST Chinese?English translation task (truecase). On the test set,
bold font indicates results that are significantly better than the baseline (p < .05).
As a next experiment, we bring in more re-
ordering capabilities by augmenting the hierarchi-
cal grammar with a single swap rule
X ? ?X?0X?1,X?1X?0? (6)
supplementary to the initial rule and glue rule.
The swap rule allows adjacent phrases to be trans-
posed. The setup with swap rule and bidirectional
phrase orientation model is about as good as the
setup with just the bidirectional phrase orienta-
tion model and no swap rule. If we furthermore
mark the swap rule with a binary feature (binary
swap feature), we end up at an improvement of
+1.4 %BLEU over the baseline. The phrase ori-
entation model again provides higher translation
quality than the discriminative reordering model.
In a third experiment, we investigate whether
the phrase orientation model also has a positive in-
fluence when integrated into a syntax-augmented
hierarchical system. We configured a hierarchi-
cal setup with soft syntactic labels (Stein et al,
2010), a syntactic enhancement in the manner of
preference grammars (Venugopal et al, 2009). On
MT08, the syntax-augmented system performs 0.9
%BLEU above the baseline setup. We achieve an
additional improvement of +0.7 %BLEU and -1.3
TER by including the bidirectional phrase orien-
tation model. Interestingly, the translation quality
of the setup with soft syntactic labels (but with-
out phrase orientation model) is worse than of the
setup with phrase orientation model (but without
soft syntactic labels) on MT08. The combination
of both extensions provides the best result, though.
In a last experiment, we finally took a very
strong setup which improves over the baseline by
2.5 %BLEU through the integration of phrase-level
discriminative word lexicon (DWL) models and
triplet lexicon models in source-to-target (s2t) and
target-to-source (t2s) direction. The models have
been presented by Hasan et al (2008), Bangalore
et al (2007), and Mauser et al (2009). We apply
them in a similar manner as proposed by Huck et
al. (2011). In this strong setup, the discriminative
reordering model gives gains on the development
set which barely carry over to the test set. Adding
the bidirectional phrase orientation model, in con-
trast, results in a nice gain of +0.7 %BLEU and a
reduction of 1.3 points in TER on the test set, even
on top of the DWL and triplet lexicon models.
7.3 French?German Experimental Results
Table 2 comprises the results of our empirical eval-
uation on the French?German task.
The left-to-right phrase orientation model
boosts the translation quality by up to 0.3 %BLEU.
The reduction in TER is in a similar order of
magnitude. The bidirectional model performs a
bit better again, with an advancement of up to
0.4 %BLEU and a maximal reduction in TER of
0.6 points.
460
newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER
French?German [%] [%] [%] [%] [%] [%] [%] [%]
HPBT Baseline 15.2 71.7 15.0 71.7 15.7 69.5 14.2 72.2
+ phrase orientation (left-to-right) 15.1 71.4 15.3 71.4 15.9 69.2 14.5 71.8
+ phrase orientation (bidirectional) 15.4 71.1 15.4 71.3 15.9 69.1 14.6 71.6
Table 2: Experimental results for the French?German translation task (truecase). newstest2009 is used
as development set.
8 Conclusion
In this paper, we introduced a phrase orientation
model for hierarchical machine translation. The
training of a lexicalized reordering model which
assigns probabilities for monotone, swap, and dis-
continuous orientation of phrases was generalized
from standard continuous phrases to hierarchical
phrases. We explained how phrase orientation
scoring can be implemented in hierarchical decod-
ing and conducted a number of experiments on a
Chinese?English and a French?German transla-
tion task. The results indicate that phrase orienta-
tion modeling is a very suitable enhancement of
the hierarchical paradigm.
Our implementation will be released as part of
Jane (Vilar et al, 2010; Vilar et al, 2012; Huck
et al, 2012b), the RWTH Aachen University open
source statistical machine translation toolkit.6
Acknowledgments
This work was partly achieved as part of the
Quaero Programme, funded by OSEO, French
State agency for innovation. This material is also
partly based upon work supported by the DARPA
BOLT project under Contract No. HR0011-12-
C-0015. Any opinions, findings and conclu-
sions or recommendations expressed in this ma-
terial are those of the authors and do not neces-
sarily reflect the views of the DARPA. The re-
search leading to these results has received fund-
ing from the European Union Seventh Framework
Programme (FP7/2007-2013) under grant agree-
ment no 287658.
References
Srinivas Bangalore, Patrick Haffner, and Stephan Kan-
thak. 2007. Statistical Machine Translation through
6http://www.hltpr.rwth-aachen.de/jane/
Global Lexical Selection and Sentence Reconstruc-
tion. In Proc. of the Annual Meeting of the Assoc. for
Computational Linguistics (ACL), pages 152?159,
Prague, Czech Republic, June.
Jean-Ce?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, USA, August.
Colin Cherry, Robert C. Moore, and Chris Quirk.
2012. On Hierarchical Re-ordering and Permuta-
tion Parsing for Phrase-based Decoding. In Proc. of
the Workshop on Statistical Machine Translation
(WMT), pages 200?209, Montre?al, Canada, June.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 263?270, Ann Ar-
bor, MI, USA, June.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228, June.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proc. of the Conf. on Empirical Meth-
ods for Natural Language Processing (EMNLP),
pages 847?855, Honolulu, HI, USA, October.
Sas?a Hasan, Juri Ganitkevitch, Hermann Ney, and
Jesu?s Andre?s-Ferrer. 2008. Triplet Lexicon Mod-
els for Statistical Machine Translation. In Proc. of
the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), pages 372?381, Hon-
olulu, HI, USA, October.
Katsuhiko Hayashi, Hajime Tsukada, Katsuhito Sudoh,
Kevin Duh, and Seiichi Yamamoto. 2010. Hi-
erarchical Phrase-based Machine Translation with
Word-based Reordering Model. In Proc. of the
Int. Conf. on Computational Linguistics (COLING),
pages 439?446, Beijing, China, August.
461
Zhongjun He, Yao Meng, and Hao Yu. 2010a. Extend-
ing the Hierarchical Phrase Based Model with Max-
imum Entropy Based BTG. In Proc. of the Conf. of
the Assoc. for Machine Translation in the Americas
(AMTA), Denver, CO, USA, October/November.
Zhongjun He, Yao Meng, and Hao Yu. 2010b. Max-
imum Entropy Based Phrase Reordering for Hier-
archical Phrase-based Translation. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 555?563, Cambridge,
MA, USA, October.
Matthias Huck, Saab Mansour, Simon Wiesler, and
Hermann Ney. 2011. Lexicon Models for Hierar-
chical Phrase-Based Machine Translation. In Proc.
of the Int. Workshop on Spoken Language Transla-
tion (IWSLT), pages 191?198, San Francisco, CA,
USA, December.
Matthias Huck, Stephan Peitz, Markus Freitag, and
Hermann Ney. 2012a. Discriminative Reordering
Extensions for Hierarchical Phrase-Based Machine
Translation. In Proc. of the Annual Conf. of the
European Assoc. for Machine Translation (EAMT),
pages 313?320, Trento, Italy, May.
Matthias Huck, Jan-Thorsten Peter, Markus Freitag,
Stephan Peitz, and Hermann Ney. 2012b. Hierar-
chical Phrase-Based Translation with Jane 2. The
Prague Bulletin of Mathematical Linguistics, 98:37?
50, October.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In
Proc. of the Int. Conf. on Acoustics, Speech, and Sig-
nal Processing (ICASSP), volume 1, pages 181?184,
Detroit, MI, USA, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmon-
ton, Canada, May/June.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proc. of the Annual Meeting of the Assoc. for
Computational Linguistics (ACL), Demo and Poster
Sessions, pages 177?180, Prague, Czech Republic.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proc. of the MT
Summit X, Phuket, Thailand, September.
Gregor Leusch and Hermann Ney. 2009. Edit dis-
tances with block movements and error rate confi-
dence estimates. Machine Translation, 23(2):129?
140, December.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Proc. of the Conf. on Empirical Methods for Natu-
ral Language Processing (EMNLP), pages 210?218,
Singapore, August.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive Training and Maximum Entropy Models for Sta-
tistical Machine Translation. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 295?302, Philadelphia, PA, USA, July.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing for Statistical Machine Translation. In Proc. of
the Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 160?167, Sapporo, Japan,
July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. of the
Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 311?318, Philadelphia, PA,
USA, July.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), pages
223?231, Cambridge, MA, USA, August.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Proc.
of the Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), Denver, CO, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 2,
pages 901?904, Denver, CO, USA, September.
Christoph Tillmann. 2004. A Unigram Orientation
Model for Statistical Machine Translation. In Pro-
ceedings of HLT-NAACL 2004: Short Papers, HLT-
NAACL-Short ?04, pages 101?104, Boston, MA,
USA.
Roy Tromble and Jason Eisner. 2009. Learning Linear
Ordering Problems for Better Translation. In Proc.
of the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), pages 1007?1016, Sin-
gapore, August.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
462
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Hu-
man Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), pages 236?244, Boulder, CO, USA,
June.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchical
Translation, Extended with Reordering and Lexicon
Models. In Proc. of the Workshop on Statistical Ma-
chine Translation (WMT), pages 262?270, Uppsala,
Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197?216, September.
Richard Zens and Hermann Ney. 2008. Improvements
in Dynamic Programming Beam Search for Phrase-
Based Statistical Machine Translation. In Proc. of
the Int. Workshop on Spoken Language Translation
(IWSLT), pages 195?205, Waikiki, HI, USA, Octo-
ber.
Richard Zens, Hermann Ney, Taro Watanabe, and Ei-
ichiro Sumita. 2004. Reordering Constraints for
Phrase-Based Statistical Machine Translation. In
Proc. of the Int. Conf. on Computational Linguis-
tics (COLING), pages 205?211, Geneva, Switzer-
land, August.
463
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105?113,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
EU-BRIDGE MT: Combined Machine Translation
?
Markus Freitag,
?
Stephan Peitz,
?
Joern Wuebker,
?
Hermann Ney,
?
Matthias Huck,
?
Rico Sennrich,
?
Nadir Durrani,
?
Maria Nadejde,
?
Philip Williams,
?
Philipp Koehn,
?
Teresa Herrmann,
?
Eunah Cho,
?
Alex Waibel
?
RWTH Aachen University, Aachen, Germany
?
University of Edinburgh, Edinburgh, Scotland
?
Karlsruhe Institute of Technology, Karlsruhe, Germany
?
{freitag,peitz,wuebker,ney}@cs.rwth-aachen.de
?
{mhuck,ndurrani,pkoehn}@inf.ed.ac.uk
?
v1rsennr@staffmail.ed.ac.uk
?
maria.nadejde@gmail.com,p.j.williams-2@sms.ed.ac.uk
?
{teresa.herrmann,eunah.cho,alex.waibel}@kit.edu
Abstract
This paper describes one of the col-
laborative efforts within EU-BRIDGE to
further advance the state of the art in
machine translation between two Euro-
pean language pairs, German?English
and English?German. Three research
institutes involved in the EU-BRIDGE
project combined their individual machine
translation systems and participated with a
joint setup in the shared translation task of
the evaluation campaign at the ACL 2014
Eighth Workshop on Statistical Machine
Translation (WMT 2014).
We combined up to nine different machine
translation engines via system combina-
tion. RWTH Aachen University, the Uni-
versity of Edinburgh, and Karlsruhe In-
stitute of Technology developed several
individual systems which serve as sys-
tem combination input. We devoted spe-
cial attention to building syntax-based sys-
tems and combining them with the phrase-
based ones. The joint setups yield em-
pirical gains of up to 1.6 points in BLEU
and 1.0 points in TER on the WMT news-
test2013 test set compared to the best sin-
gle systems.
1 Introduction
EU-BRIDGE
1
is a European research project
which is aimed at developing innovative speech
translation technology. This paper describes a
1
http://www.eu-bridge.eu
joint WMT submission of three EU-BRIDGE
project partners. RWTH Aachen University
(RWTH), the University of Edinburgh (UEDIN)
and Karlsruhe Institute of Technology (KIT) all
provided several individual systems which were
combined by means of the RWTH Aachen system
combination approach (Freitag et al., 2014). As
distinguished from our EU-BRIDGE joint submis-
sion to the IWSLT 2013 evaluation campaign (Fre-
itag et al., 2013), we particularly focused on trans-
lation of news text (instead of talks) for WMT. Be-
sides, we put an emphasis on engineering syntax-
based systems in order to combine them with our
more established phrase-based engines. We built
combined system setups for translation from Ger-
man to English as well as from English to Ger-
man. This paper gives some insight into the tech-
nology behind the system combination framework
and the combined engines which have been used
to produce the joint EU-BRIDGE submission to
the WMT 2014 translation task.
The remainder of the paper is structured as fol-
lows: We first describe the individual systems by
RWTH Aachen University (Section 2), the Uni-
versity of Edinburgh (Section 3), and Karlsruhe
Institute of Technology (Section 4). We then
present the techniques for machine translation sys-
tem combination in Section 5. Experimental re-
sults are given in Section 6. We finally conclude
the paper with Section 7.
2 RWTH Aachen University
RWTH (Peitz et al., 2014) employs both the
phrase-based (RWTH scss) and the hierarchical
(RWTH hiero) decoder implemented in RWTH?s
publicly available translation toolkit Jane (Vilar
105
et al., 2010; Wuebker et al., 2012). The model
weights of all systems have been tuned with stan-
dard Minimum Error Rate Training (Och, 2003)
on a concatenation of the newstest2011 and news-
test2012 sets. RWTH used BLEU as optimiza-
tion objective. Both for language model estima-
tion and querying at decoding, the KenLM toolkit
(Heafield et al., 2013) is used. All RWTH sys-
tems include the standard set of models provided
by Jane. Both systems have been augmented with
a hierarchical orientation model (Galley and Man-
ning, 2008; Huck et al., 2013) and a cluster lan-
guage model (Wuebker et al., 2013). The phrase-
based system (RWTH scss) has been further im-
proved by maximum expected BLEU training sim-
ilar to (He and Deng, 2012). The latter has been
performed on a selection from the News Commen-
tary, Europarl and Common Crawl corpora based
on language and translation model cross-entropies
(Mansour et al., 2011).
3 University of Edinburgh
UEDIN contributed phrase-based and syntax-
based systems to both the German?English and
the English?German joint submission.
3.1 Phrase-based Systems
UEDIN?s phrase-based systems (Durrani et al.,
2014) have been trained using the Moses toolkit
(Koehn et al., 2007), replicating the settings de-
scribed in (Durrani et al., 2013b). The features
include: a maximum sentence length of 80, grow-
diag-final-and symmetrization of GIZA
++
align-
ments, an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, a lexically-driven 5-gram
operation sequence model (OSM) (Durrani et al.,
2013a), msd-bidirectional-fe lexicalized reorder-
ing, sparse lexical and domain features (Hasler
et al., 2012), a distortion limit of 6, a maxi-
mum phrase length of 5, 100-best translation op-
tions, Minimum Bayes Risk decoding (Kumar and
Byrne, 2004), cube pruning (Huang and Chiang,
2007), with a stack size of 1000 during tuning and
5000 during testing and the no-reordering-over-
punctuation heuristic. UEDIN uses POS and mor-
phological target sequence models built on the in-
domain subset of the parallel corpus using Kneser-
Ney smoothed 7-gram models as additional factors
in phrase translation models (Koehn and Hoang,
2007). UEDIN has furthermore built OSM mod-
els over POS and morph sequences following
Durrani et al. (2013c). The English?German
system additionally comprises a target-side LM
over automatically built word classes (Birch et
al., 2013). UEDIN has applied syntactic pre-
reordering (Collins et al., 2005) and compound
splitting (Koehn and Knight, 2003) of the source
side for the German?English system. The sys-
tems have been tuned on a very large tuning set
consisting of the test sets from 2008-2012, with
a total of 13,071 sentences. UEDIN used news-
test2013 as held-out test set. On top of UEDIN
phrase-based 1 system, UEDIN phrase-based 2
augments word classes as additional factor and
learns an interpolated target sequence model over
cluster IDs. Furthermore, it learns OSM models
over POS, morph and word classes.
3.2 Syntax-based Systems
UEDIN?s syntax-based systems (Williams et al.,
2014) follow the GHKM syntax approach as pro-
posed by Galley, Hopkins, Knight, and Marcu
(Galley et al., 2004). The open source Moses
implementation has been employed to extract
GHKM rules (Williams and Koehn, 2012). Com-
posed rules (Galley et al., 2006) are extracted in
addition to minimal rules, but only up to the fol-
lowing limits: at most twenty tree nodes per rule,
a maximum depth of five, and a maximum size of
five. Singleton hierarchical rules are dropped.
The features for the syntax-based systems com-
prise Good-Turing-smoothed phrase translation
probabilities, lexical translation probabilities in
both directions, word and phrase penalty, a rule
rareness penalty, a monolingual PCFG probability,
and a 5-gram language model. UEDIN has used
the SRILM toolkit (Stolcke, 2002) to train the lan-
guage model and relies on KenLM for language
model scoring during decoding. Model weights
are optimized to maximize BLEU. 2000 sentences
from the newstest2008-2012 sets have been se-
lected as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and each contain less than 30 words
for more rapid tuning. Decoding for the syntax-
based systems is carried out with cube pruning
using Moses? hierarchical decoder (Hoang et al.,
2009).
UEDIN?s German?English syntax-based setup
is a string-to-tree system with compound splitting
106
on the German source-language side and syntactic
annotation from the Berkeley Parser (Petrov et al.,
2006) on the English target-language side.
For English?German, UEDIN has trained var-
ious string-to-tree GHKM syntax systems which
differ with respect to the syntactic annotation. A
tree-to-string system and a string-to-string system
(with rules that are not syntactically decorated)
have been trained as well. The English?German
UEDIN GHKM system names in Table 3 denote:
UEDIN GHKM S2T (ParZu): A string-to-tree
system trained with target-side syntactic an-
notation obtained with ParZu (Sennrich et
al., 2013). It uses a modified syntactic label
set, target-side compound splitting, and addi-
tional syntactic constraints.
UEDIN GHKM S2T (BitPar): A string-to-tree
system trained with target-side syntactic
annotation obtained with BitPar (Schmid,
2004).
UEDIN GHKM S2T (Stanford): A string-to-
tree system trained with target-side syntactic
annotation obtained with the German Stan-
ford Parser (Rafferty and Manning, 2008a).
UEDIN GHKM S2T (Berkeley): A string-to-
tree system trained with target-side syntactic
annotation obtained with the German Berke-
ley Parser (Petrov and Klein, 2007; Petrov
and Klein, 2008).
UEDIN GHKM T2S (Berkeley): A tree-to-
string system trained with source-side syn-
tactic annotation obtained with the English
Berkeley Parser (Petrov et al., 2006).
UEDIN GHKM S2S (Berkeley): A string-to-
string system. The extraction is GHKM-
based with syntactic target-side annotation
from the German Berkeley Parser, but we
strip off the syntactic labels. The final gram-
mar contains rules with a single generic non-
terminal instead of syntactic ones, plus rules
that have been added from plain phrase-based
extraction (Huck et al., 2014).
4 Karlsruhe Institute of Technology
The KIT translations (Herrmann et al., 2014) are
generated by an in-house phrase-based transla-
tions system (Vogel, 2003). The provided News
Commentary, Europarl, and Common Crawl par-
allel corpora are used for training the translation
model. The monolingual part of those parallel
corpora, the News Shuffle corpus for both direc-
tions and additionally the Gigaword corpus for
German?English are used as monolingual train-
ing data for the different language models. Opti-
mization is done with Minimum Error Rate Train-
ing as described in (Venugopal et al., 2005), using
newstest2012 and newstest2013 as development
and test data respectively.
Compound splitting (Koehn and Knight, 2003)
is performed on the source side of the corpus for
German?English translation before training. In
order to improve the quality of the web-crawled
Common Crawl corpus, noisy sentence pairs are
filtered out using an SVM classifier as described
by Mediani et al. (2011).
The word alignment for German?English is
generated using the GIZA
++
toolkit (Och and Ney,
2003). For English?German, KIT uses discrimi-
native word alignment (Niehues and Vogel, 2008).
Phrase extraction and scoring is done using the
Moses toolkit (Koehn et al., 2007). Phrase pair
probabilities are computed using modified Kneser-
Ney smoothing as in (Foster et al., 2006).
In both systems KIT applies short-range re-
orderings (Rottmann and Vogel, 2007) and long-
range reorderings (Niehues and Kolss, 2009)
based on POS tags (Schmid, 1994) to perform
source sentence reordering according to the target
language word order. The long-range reordering
rules are applied to the training corpus to create
reordering lattices to extract the phrases for the
translation model. In addition, a tree-based re-
ordering model (Herrmann et al., 2013) trained
on syntactic parse trees (Rafferty and Manning,
2008b; Klein and Manning, 2003) as well as a lex-
icalized reordering model (Koehn et al., 2005) are
applied.
Language models are trained with the SRILM
toolkit (Stolcke, 2002) and use modified Kneser-
Ney smoothing. Both systems utilize a lan-
guage model based on automatically learned
word classes using the MKCLS algorithm (Och,
1999). The English?German system comprises
language models based on fine-grained part-of-
speech tags (Schmid and Laws, 2008). In addi-
tion, a bilingual language model (Niehues et al.,
2011) is used as well as a discriminative word lex-
icon (Mauser et al., 2009) using source context to
guide the word choices in the target sentence.
107
In total, the English?German system uses the
following language models: two 4-gram word-
based language models trained on the parallel data
and the filtered Common Crawl data separately,
two 5-gram POS-based language models trained
on the same data as the word-based language mod-
els, and a 4-gram cluster-based language model
trained on 1,000 MKCLS word classes.
The German?English system uses a 4-gram
word-based language model trained on all mono-
lingual data and an additional language model
trained on automatically selected data (Moore and
Lewis, 2010). Again, a 4-gram cluster-based
language model trained on 1000 MKCLS word
classes is applied.
5 System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses which
are outputs of different translation engines. The
consensus translations can be better in terms of
translation quality than any of the individual hy-
potheses. To combine the engines of the project
partners for the EU-BRIDGE joint setups, we ap-
ply a system combination implementation that has
been developed at RWTH Aachen University.
The implementation of RWTH?s approach to
machine translation system combination is de-
scribed in (Freitag et al., 2014). This approach
includes an enhanced alignment and reordering
framework. Alignments between the system out-
puts are learned using METEOR (Banerjee and
Lavie, 2005). A confusion network is then built
using one of the hypotheses as ?primary? hypoth-
esis. We do not make a hard decision on which
of the hypotheses to use for that, but instead com-
bine all possible confusion networks into a single
lattice. Majority voting on the generated lattice
is performed using the prior probabilities for each
system as well as other statistical models, e.g. a
special n-gram language model which is learned
on the input hypotheses. Scaling factors of the
models are optimized using the Minimum Error
Rate Training algorithm. The translation with the
best total score within the lattice is selected as con-
sensus translation.
6 Results
In this section, we present our experimental results
on the two translation tasks, German?English
and English?German. The weights of the in-
dividual system engines have been optimized on
different test sets which partially or fully include
newstest2011 or newstest2012. System combina-
tion weights are either optimized on newstest2011
or newstest2012. We kept newstest2013 as an un-
seen test set which has not been used for tuning
the system combination or any of the individual
systems.
6.1 German?English
The automatic scores of all individual systems
as well as of our final system combination sub-
mission are given in Table 1. KIT, UEDIN and
RWTH are each providing one individual phrase-
based system output. RWTH (hiero) and UEDIN
(GHKM) are providing additional systems based
on the hierarchical translation model and a string-
to-tree syntax model. The pairwise difference
of the single system performances is up to 1.3
points in BLEU and 2.5 points in TER. For
German?English, our system combination pa-
rameters are optimized on newstest2012. System
combination gives us a gain of 1.6 points in BLEU
and 1.0 points in TER for newstest2013 compared
to the best single system.
In Table 2 the pairwise BLEU scores for all in-
dividual systems as well as for the system combi-
nation output are given. The pairwise BLEU score
of both RWTH systems (taking one as hypothesis
and the other one as reference) is the highest for all
pairs of individual system outputs. A high BLEU
score means similar hypotheses. The syntax-based
system of UEDIN and RWTH scss differ mostly,
which can be observed from the fact of the low-
est pairwise BLEU score. Furthermore, we can
see that better performing individual systems have
higher BLEU scores when evaluating against the
system combination output.
In Figure 1 system combination output is com-
pared to the best single system KIT. We distribute
the sentence-level BLEU scores of all sentences of
newstest2013. To allow for sentence-wise evalu-
ation, all bi-, tri-, and four-gram counts are ini-
tialized with 1 instead of 0. Many sentences have
been improved by system combination. Neverthe-
less, some sentences fall off in quality compared
to the individual system output of KIT.
6.2 English?German
The results of all English?German system setups
are given in Table 3. For the English?German
translation task, only UEDIN and KIT are con-
108
system newstest2011 newstest2012 newstest2013
BLEU TER BLEU TER BLEU TER
KIT 25.0 57.6 25.2 57.4 27.5 54.4
UEDIN 23.9 59.2 24.7 58.3 27.4 55.0
RWTH scss 23.6 59.5 24.2 58.5 27.0 55.0
RWTH hiero 23.3 59.9 24.1 59.0 26.7 55.9
UEDIN GHKM S2T (Berkeley) 23.0 60.1 23.2 60.8 26.2 56.9
syscom 25.6 57.1 26.4 56.5 29.1 53.4
Table 1: Results for the German?English translation task. The system combination is tuned on news-
test2012, newstest2013 is used as held-out test set for all individual systems and system combination.
Bold font indicates system combination results that are significantly better than the best single system
with p < 0.05.
KIT UEDIN RWTH scss RWTH hiero UEDIN S2T syscom
KIT 59.07 57.60 57.91 55.62 77.68
UEDIN 59.17 56.96 57.84 59.89 72.89
RWTH scss 57.64 56.90 64.94 53.10 71.16
RWTH hiero 57.98 57.80 64.97 55.73 70.87
UEDIN S2T 55.75 59.95 53.19 55.82 65.35
syscom 77.76 72.83 71.17 70.85 65.24
Table 2: Cross BLEU scores for the German?English newstest2013 test set. (Pairwise BLEU scores:
each entry is taking the horizontal system as hypothesis and the other one as reference.)
system newstest2011 newstest2012 newstest2013
BLEU TER BLEU TER BLEU TER
UEDIN phrase-based 1 17.5 67.3 18.2 65.0 20.5 62.7
UEDIN phrase-based 2 17.8 66.9 18.5 64.6 20.8 62.3
UEDIN GHKM S2T (ParZu) 17.2 67.6 18.0 65.5 20.2 62.8
UEDIN GHKM S2T (BitPar) 16.3 69.0 17.3 66.6 19.5 63.9
UEDIN GHKM S2T (Stanford) 16.1 69.2 17.2 67.0 19.0 64.2
UEDIN GHKM S2T (Berkeley) 16.3 68.9 17.2 66.7 19.3 63.8
UEDIN GHKM T2S (Berkeley) 16.7 68.9 17.5 66.9 19.5 63.8
UEDIN GHKM S2S (Berkeley) 16.3 69.2 17.3 66.8 19.1 64.3
KIT 17.1 67.0 17.8 64.8 20.2 62.2
syscom 18.4 65.0 18.7 63.4 21.3 60.6
Table 3: Results for the English?German translation task. The system combination is tuned on news-
test2011, newstest2013 is used as held-out test set for all individual systems and system combination.
Bold font indicates system combination results that are significantly (Bisani and Ney, 2004) better than
the best single system with p< 0.05. Italic font indicates system combination results that are significantly
better than the best single system with p < 0.1.
tributing individual systems. KIT is providing a
phrase-based system output, UEDIN is providing
two phrase-based system outputs and six syntax-
based ones (GHKM). For English?German, our
system combination parameters are optimized on
newstest2011. Combining all nine different sys-
tem outputs yields an improvement of 0.5 points
in BLEU and 1.7 points in TER over the best sin-
gle system performance.
In Table 4 the cross BLEU scores for all
English?German systems are given. The individ-
ual system of KIT and the syntax-based ParZu sys-
tem of UEDIN have the lowest BLEU score when
scored against each other. Both approaches are
quite different and both are coming from differ-
ent institutes. In contrast, both phrase-based sys-
tems pbt 1 and pbt 2 from UEDIN are very sim-
ilar and hence have a high pairwise BLEU score.
109
pbt 1 pbt 2 ParZu BitPar Stanford S2T T2S S2S KIT syscom
pbt 1 75.84 51.61 53.93 55.32 54.79 54.52 60.92 54.80 70.12
pbt 2 75.84 51.96 53.39 53.93 53.97 53.10 57.32 54.04 73.75
ParZu 51.57 51.91 56.67 55.11 56.05 52.13 51.22 48.14 68.39
BitPar 54.00 53.45 56.78 64.59 65.67 56.33 56.62 49.23 62.08
Stanford 55.37 53.98 55.19 64.56 69.22 58.81 61.19 50.50 61.51
S2T 54.83 54.02 56.14 65.64 69.21 59.32 60.16 50.07 62.81
T2S 54.57 53.15 52.21 56.30 58.81 59.32 59.34 50.01 63.13
S2S 60.96 57.36 51.29 56.59 61.18 60.15 59.33 53.68 60.46
KIT 54.75 53.98 48.13 49.13 50.41 49.98 49.93 53.59 63.33
syscom 70.01 73.63 68.32 61.92 61.37 62.67 62.99 60.32 63.27
Table 4: Cross BLEU scores for the German?English newstest2013 test set. (Pairwise BLEU scores:
each entry is taking the horizontal system as reference and the other one as hypothesis.)
 0
 50
 100
 150
 200
 250
 300
 350
 400
 0  20  40  60  80  100
amo
unt 
sent
ence
s
sBLEU
bettersameworse
Figure 1: Sentence distribution for the
German?English newstest2013 test set compar-
ing system combination output against the best
individual system.
As for the German?English translation direction,
the best performing individual system outputs are
also having the highest BLEU scores when evalu-
ated against the final system combination output.
In Figure 2 system combination output is com-
pared to the best single system pbt 2. We distribute
the sentence-level BLEU scores of all sentences
of newstest2013. Many sentences have been im-
proved by system combination. But there is still
room for improvement as some sentences are still
better in terms of sentence-level BLEU in the indi-
vidual best system pbt 2.
7 Conclusion
We achieved significantly better translation perfor-
mance with gains of up to +1.6 points in BLEU
and -1.0 points in TER by combining up to nine
different machine translation systems. Three dif-
ferent research institutes (RWTH Aachen Univer-
sity, University of Edinburgh, Karlsruhe Institute
of Technology) provided machine translation en-
gines based on different approaches like phrase-
 0
 50
 100
 150
 200
 250
 300
 350
 400
 0  20  40  60  80  100
amo
unt 
sent
ence
s
sBLEU
bettersameworse
Figure 2: Sentence distribution for the
English?German newstest2013 test set compar-
ing system combination output against the best
individual system.
based, hierarchical phrase-based, and syntax-
based. For English?German, we included six
different syntax-based systems, which were com-
bined to our final combined translation. The au-
tomatic scores of all submitted system outputs for
the actual 2014 evaluation set are presented on the
WMT submission page.
2
Our joint submission is
the best submission in terms of BLEU and TER for
both translation directions German?English and
English?German without adding any new data.
Acknowledgements
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
o
287658.
Rico Sennrich has received funding from the
Swiss National Science Foundation under grant
P2ZHP1 148717.
2
http://matrix.statmt.org/
110
References
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. In 43rd
Annual Meeting of the Assoc. for Computational
Linguistics: Proc. Workshop on Intrinsic and Extrin-
sic Evaluation Measures for MT and/or Summariza-
tion, pages 65?72, Ann Arbor, MI, USA, June.
Alexandra Birch, Nadir Durrani, and Philipp Koehn.
2013. Edinburgh SLT and MT System Description
for the IWSLT 2013 Evaluation. In Proceedings
of the 10th International Workshop on Spoken Lan-
guage Translation, pages 40?48, Heidelberg, Ger-
many, December.
Maximilian Bisani and Hermann Ney. 2004. Bootstrap
Estimates for Confidence Intervals in ASR Perfor-
mance Evaluation. In IEEE International Confer-
ence on Acoustics, Speech, and Signal Processing,
volume 1, pages 409?412, Montr?eal, Canada, May.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause Restructuring for Statistical Ma-
chine Translation. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL?05), pages 531?540, Ann Arbor,
Michigan, June.
Nadir Durrani, Alexander Fraser, Helmut Schmid,
Hieu Hoang, and Philipp Koehn. 2013a. Can
Markov Models Over Minimal Translation Units
Help Phrase-Based SMT? In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, Sofia, Bulgaria, August.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013b. Edinburgh?s Machine Trans-
lation Systems for European Language Pairs. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria, August.
Nadir Durrani, Helmut Schmid, Alexander Fraser, Has-
san Sajjad, and Richard Farkas. 2013c. Munich-
Edinburgh-Stuttgart Submissions of OSM Systems
at WMT13. In Proceedings of the Eighth Workshop
on Statistical Machine Translation, Sofia, Bulgaria.
Nadir Durrani, Barry Haddow, Philipp Koehn, and
Kenneth Heafield. 2014. Edinburgh?s Phrase-based
Machine Translation Systems for WMT-14. In Pro-
ceedings of the ACL 2014 Ninth Workshop on Sta-
tistical Machine Translation, Baltimore, MD, USA,
June.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In EMNLP, pages 53?61.
M. Freitag, S. Peitz, J. Wuebker, H. Ney, N. Dur-
rani, M. Huck, P. Koehn, T.-L. Ha, J. Niehues,
M. Mediani, T. Herrmann, A. Waibel, N. Bertoldi,
M. Cettolo, and M. Federico. 2013. EU-BRIDGE
MT: Text Translation of Talks in the EU-BRIDGE
Project. In International Workshop on Spoken Lan-
guage Translation, Heidelberg, Germany, Decem-
ber.
Markus Freitag, Matthias Huck, and Hermann Ney.
2014. Jane: Open Source Machine Translation Sys-
tem Combination. In Conference of the European
Chapter of the Association for Computational Lin-
guistics, Gothenburg, Sweden, April.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 847?855, Honolulu, HI, USA, Octo-
ber.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st International Conf. on Computa-
tional Linguistics and 44th Annual Meeting of the
Assoc. for Computational Linguistics, pages 961?
968, Sydney, Australia, July.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268?275.
Xiaodong He and Li Deng. 2012. Maximum Expected
BLEU Training of Phrase and Lexicon Translation
Models. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL), pages 292?301, Jeju, Republic of Korea,
July.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690?696,
Sofia, Bulgaria, August.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187?197, Edinburgh, Scotland, UK, July.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Atlanta, GA, USA, June.
111
Teresa Herrmann, Mohammed Mediani, Eunah Cho,
Thanh-Le Ha, Jan Niehues, Isabel Slawik, Yuqi
Zhang, and Alex Waibel. 2014. The Karlsruhe In-
stitute of Technology Translation Systems for the
WMT 2014. In Proceedings of the ACL 2014 Ninth
Workshop on Statistical Machine Translation, Balti-
more, MD, USA, June.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. pages 152?159, Tokyo, Japan, December.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144?151, Prague, Czech Republic, June.
Matthias Huck, Joern Wuebker, Felix Rietig, and Her-
mann Ney. 2013. A Phrase Orientation Model
for Hierarchical Machine Translation. In ACL 2013
Eighth Workshop on Statistical Machine Transla-
tion, pages 452?463, Sofia, Bulgaria, August.
Matthias Huck, Hieu Hoang, and Philipp Koehn.
2014. Augmenting String-to-Tree and Tree-to-
String Translation with Non-Syntactic Phrases. In
Proceedings of the ACL 2014 Ninth Workshop on
Statistical Machine Translation, Baltimore, MD,
USA, June.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proceedings of ACL
2003.
Philipp Koehn and Hieu Hoang. 2007. Factored Trans-
lation Models. In EMNLP-CoNLL, pages 868?876,
Prague, Czech Republic, June.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Amittai Axelrod, Alexandra B. Mayne,
Chris Callison-Burch, Miles Osborne, and David
Talbot. 2005. Edinburgh System Description for
the 2005 IWSLT Speech Translation Evaluation. In
Proceedings of the International Workshop on Spo-
ken Language Translation (IWSLT), Pittsburgh, PA,
USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceedings
of the 45th Annual Meeting of the ACL on Interactive
Poster and Demonstration Sessions, pages 177?180,
Prague, Czech Republic, June.
Shankar Kumar and William Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In Proc. Human Language Technol-
ogy Conf. / North American Chapter of the Associa-
tion for Computational Linguistics Annual Meeting
(HLT-NAACL), pages 169?176, Boston, MA, USA,
May.
Saab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 222?229, San
Francisco, CA, USA, December.
Arne Mauser, Sa?sa Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 210?217, Singapore, Au-
gust.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation systems for IWSLT
2011. In Proceedings of the Eight Interna-
tional Workshop on Spoken Language Translation
(IWSLT), San Francisco, CA, USA.
Robert C. Moore and William Lewis. 2010. Intelligent
selection of language model training data. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 220?224, Uppsala, Sweden, July.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proceedings of Third ACL Workshop on Statisti-
cal Machine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 1999. An Efficient Method for De-
termining Bilingual Word Classes. In EACL?99.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Stephan Peitz, Joern Wuebker, Markus Freitag, and
Hermann Ney. 2014. The RWTH Aachen German-
English Machine Translation System for WMT
2014. In Proceedings of the ACL 2014 Ninth Work-
shop on Statistical Machine Translation, Baltimore,
MD, USA, June.
112
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404?411, Rochester, New York, April.
Slav Petrov and Dan Klein. 2008. Parsing German
with Latent Variable Grammars. In Proceedings of
the Workshop on Parsing German at ACL ?08, pages
33?39, Columbus, OH, USA, June.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 433?440, Sydney,
Australia, July.
Anna N. Rafferty and Christopher D. Manning. 2008a.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German at ACL ?08, pages 40?
46, Columbus, OH, USA, June.
Anna N. Rafferty and Christopher D. Manning. 2008b.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In Proceedings of
the 11th International Conference on Theoretical
and Methodological Issues in Machine Translation
(TMI), Sk?ovde, Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation
of Conditional Probabilities with Decision Trees and
an Application to Fine-Grained POS Tagging. In
COLING 2008, Manchester, UK.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Rico Sennrich, Martin Volk, and Gerold Schneider.
2013. Exploiting Synergies Between Open Re-
sources for German Dependency Parsing, POS-
tagging, and Morphological Analysis. In Proceed-
ings of the International Conference Recent Ad-
vances in Natural Language Processing 2013, pages
601?609, Hissar, Bulgaria.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, CO, USA, Septem-
ber.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, Michigan, USA.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchi-
cal Translation, Extended with Reordering and Lex-
icon Models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In International Conference on Natural
Language Processing and Knowledge Engineering,
Beijing, China.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation (WMT), pages 388?394,
Montr?eal, Canada, June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proceedings of the ACL 2014 Ninth
Workshop on Statistical Machine Translation, Balti-
more, MD, USA, June.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2:
Open Source Phrase-based and Hierarchical Statisti-
cal Machine Translation. In COLING ?12: The 24th
Int. Conf. on Computational Linguistics, pages 483?
491, Mumbai, India, December.
Joern Wuebker, Stephan Peitz, Felix Rietig, and Her-
mann Ney. 2013. Improving Statistical Machine
Translation with Word Class Models. In Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1377?1381, Seattle, WA, USA, Oc-
tober.
113
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 207?214,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
Edinburgh?s Syntax-Based Systems at WMT 2014
Philip Williams
1
, Rico Sennrich
1
, Maria Nadejde
1
,
Matthias Huck
1
, Eva Hasler
1
, Philipp Koehn
1,2
1
School of Informatics, University of Edinburgh
2
Center for Speech and Language Processing, The Johns Hopkins University
Abstract
This paper describes the string-to-tree sys-
tems built at the University of Edin-
burgh for the WMT 2014 shared trans-
lation task. We developed systems for
English-German, Czech-English, French-
English, German-English, Hindi-English,
and Russian-English. This year we
improved our English-German system
through target-side compound splitting,
morphosyntactic constraints, and refine-
ments to parse tree annotation; we ad-
dressed the out-of-vocabulary problem us-
ing transliteration for Hindi and Rus-
sian and using morphological reduction
for Russian; we improved our German-
English system through tree binarization;
and we reduced system development time
by filtering the tuning sets.
1 Introduction
For this year?s WMT shared translation task we
built syntax-based systems for six language pairs:
? English-German ? German-English
? Czech-English ? Hindi-English
? French-English ? Russian-English
As last year (Nadejde et al., 2013), our systems are
based on the string-to-tree pipeline implemented
in the Moses toolkit (Koehn et al., 2007).
We paid particular attention to the production of
grammatical German, trying various parsers and
incorporating target-side compound splitting and
morphosyntactic constraints; for Hindi and Rus-
sian, we employed the new Moses transliteration
model to handle out-of-vocabulary words; and for
German to English, we experimented with tree bi-
narization, obtaining good results from right bina-
rization.
We also present our first syntax-based results
for French-English, the scale of which defeated us
last year. This year we were able to train a sys-
tem using all available training data, a task that
was made considerably easier through principled
filtering of the tuning set. Although our system
was not ready in time for human evaluation, we
present BLEU scores in this paper.
In addition to the five single-system submis-
sions described here, we also contributed our
English-German and German-English systems for
use in the collaborative EU-BRIDGE system com-
bination effort (Freitag et al., 2014).
This paper is organised as follows. In Sec-
tion 2 we describe the core setup that is com-
mon to all systems. In subsequent sections we de-
scribe language-pair specific variations and exten-
sions. For each language pair, we present results
for both the development test set (newstest2013
in most cases) and for the filtered test set (new-
stest2014) that was provided after the system sub-
mission deadline. We refer to these as ?devtest?
and ?test?, respectively.
2 System Overview
2.1 Pre-processing
The training data was normalized using the WMT
normalize-punctuation.perl script then
tokenized and truecased. Where the target lan-
guage was English, we used the Moses tokenizer?s
-penn option, which uses a tokenization scheme
that more closely matches that of the parser. For
the English-German system we used the default
Moses tokenization scheme, which is similar to
that of the German parsers.
For the systems that translate into English, we
used the Berkeley parser (Petrov et al., 2006;
Petrov and Klein, 2007) to parse the target-side of
the training corpus. As we will describe in Sec-
tion 3, we tried a variety of parsers for German.
We did not perform any corpus filtering other
than the standard Moses method, which removes
207
sentence pairs with dubious length ratios and sen-
tence pairs where parsing fails for the target-side
sentence.
2.2 Translation Model
Our translation grammar is a synchronous context-
free grammar (SCFG) with phrase-structure labels
on the target side and the generic non-terminal la-
bel X on the source side.
The grammar was extracted from the word-
aligned parallel data using the Moses implemen-
tation (Williams and Koehn, 2012) of the GHKM
algorithm (Galley et al., 2004; Galley et al., 2006).
For word alignment we used MGIZA++ (Gao and
Vogel, 2008), a multi-threaded implementation of
GIZA++ (Och and Ney, 2003).
Minimal GHKM rules were composed into
larger rules subject to parameterized restrictions
on size defined in terms of the resulting target tree
fragment. A good choice of parameter settings
depends on the annotation style of the target-side
parse trees. We used the settings shown in Table 1,
which were chosen empirically during the devel-
opment of last years? systems:
Parameter Value
Rule depth 5
Node count 20
Rule size 5
Table 1: Parameter settings for rule composition.
Further to the restrictions on rule composition,
fully non-lexical unary rules were eliminated us-
ing the method described in Chung et al. (2011)
and rules with scope greater than 3 (Hopkins and
Langmead, 2010) were pruned from the trans-
lation grammar. Scope pruning makes parsing
tractable without the need for grammar binariza-
tion.
2.3 Language Model
We used all available monolingual data to train
5-gram language models. Language models
for each monolingual corpus were trained using
the SRILM toolkit (Stolcke, 2002) with modi-
fied Kneser-Ney smoothing (Chen and Goodman,
1998) and then interpolated using weights tuned to
minimize perplexity on the development set.
2.4 Feature Functions
Our feature functions are unchanged from the pre-
vious two years. They include the n-gram lan-
guage model probability of the derivation?s target
yield, its word count, and various scores for the
synchronous derivation.
Each grammar rule has a number of pre-
computed scores. For a grammar rule r of the form
C ? ??, ?,??
where C is a target-side non-terminal label, ? is a
string of source terminals and non-terminals, ? is
a string of target terminals and non-terminals, and
? is a one-to-one correspondence between source
and target non-terminals, we score the rule accord-
ing to the following functions:
? p (C, ? | ?,?) and p (? | C, ?,?), the direct
and indirect translation probabilities.
? p
lex
(? | ?) and p
lex
(? | ?), the direct and
indirect lexical weights (Koehn et al., 2003).
? p
pcfg
(pi), the monolingual PCFG probability
of the tree fragment pi from which the rule
was extracted.
? exp(?1/count(r)), a rule rareness penalty.
? exp(1), a rule penalty. The main grammar
and glue grammars have distinct penalty fea-
tures.
2.5 Tuning
The feature weights were tuned using the Moses
implementation of MERT (Och, 2003) for all sys-
tems except English-to-German, for which we
used k-best MIRA (Cherry and Foster, 2012) due
to the larger number of features.
We used tuning sentences drawn from all of
the previous years? test sets (except newstest2013,
which was used as the development test set). In
order to speed up the tuning process, we used sub-
sets of the full tuning sets with sentence pairs up
to length 30 (Max-30) and further applied a fil-
tering technique to reduce the tuning set size to
2,000 sentence pairs for the language pairs involv-
ing German, French and Czech
1
. We also experi-
mented with random subsets of size 2,000.
For the filtering technique, we make the as-
sumption that finding suitable weights for all the
feature functions requires the optimizer to see a
range of feature values and to see hypotheses that
can partially match the reference translations in
order to rank the hypotheses. For example, if a
1
For Russian and Hindi, the development sets are smaller
and no filtering was applied.
208
tuning example contains many out-of-vocabulary
words or is difficult to translate for other reasons,
this will result in low quality translation hypothe-
ses and provide the system with little evidence for
which features are useful to produce good transla-
tions. Therefore, we select high quality examples
using a smooth version of sentence-BLEU com-
puted on the 1-best output of a single decoder run
on the development set. Standard sentence-BLEU
tends to select short examples because they are
more likely to have perfect n-gram matches with
the reference translation. Very short sentence pairs
are less informative for tuning but also tend to have
more extreme source-target length ratios which
can affect the weight of the word penalty. Thus,
we penalize short examples by padding the de-
coder output with a fixed number of non-matching
tokens
2
to the left and right before computing
sentence-BLEU. This has the effect of reducing
the precision of short sentences against the refer-
ence translation while affecting longer sentences
proportionally less. Experiments on phrase-based
systems have shown that the resulting tuning sets
are of comparable diversity as randomly selected
sets in terms of their feature vectors and maintain
BLEU scores in comparison with tuning on the en-
tire development set.
Table 2 shows the size of the full tuning sets
and the size of the subsets with up to length 30,
Table 3 shows the results of tuning with different
sets. Reducing the tuning sets to Max-30 results
in a speed-up in tuning time but affects the per-
formance on some of the devtest/test sets (mostly
for Czech-English). However, tuning on the full
set took more than 18 days using 12 cores for
German-English which is not feasible when try-
ing out several model variations. Further filter-
ing these subsets to a size of 2,000 sentence pairs
as described above maintains the BLEU scores in
most cases and even improves the scores in some
cases. This indicates that the quality of the se-
lected examples is more important than the total
number of tuning examples. However, the exper-
iments with random subsets from Max-30 show
that random selection also yields results which im-
prove over the results with Max-30 in most cases,
though are not always as good as with the filtered
sets.
3
The filtered tuning sets yield reasonable per-
2
These can be arbitrary tokens that do not match any ref-
erence token.
3
For random subsets from the full tuning set the perfor-
mance was similar but resulted in standard deviations of up
formance compared to the full tuning sets except
for the German-English devtest set where perfor-
mance drops by 0.5 BLEU
4
.
Tuning set Cs-En En-De De-En
Full 13,055 13,071 13,071
Max-30 10,392 9,151 10,610
Table 2: Size of full tuning sets and with sentence
length up to 30.
devtest
Tuning set Cs-En En-De De-En
Full 25.1 19.9 26.7
Max-30 24.7 19.8 26.2
Filtered 24.9 19.8 26.2
Random 24.8 19.7 26.4
test
Tuning set Cs-En En-De De-En
Full 27.5 19.2 26.9
Max-30 27.2 19.2 27.0
Filtered 27.5 19.1 27.2
Random 27.3 19.4 27.0
Table 3: BLEU results on devtest and test sets with
different tuning sets: Full, Max-30, filtered subsets
of Max-30 and average of three random subsets of
Max-30 (size of filtered/random subsets: 2,000).
3 English to German
We use the projective output of the dependency
parser ParZu (Sennrich et al., 2013) for the syn-
tactic annotation of our primary submission. Con-
trastive systems were built with other parsers: Bit-
Par (Schmid, 2004), the German Stanford Parser
(Rafferty and Manning, 2008), and the German
Berkeley Parser (Petrov and Klein, 2007; Petrov
and Klein, 2008).
The set of syntactic labels provided by ParZu
has been refined to reduce overgeneralization phe-
nomena. Specifically, we disambiguate the labels
ROOT (used for the root of a sentence, but also
commas, punctuation marks, and sentence frag-
ments), KON and CJ (coordinations of different
constituents), and GMOD (pre- or postmodifying
genitive modifier).
to 0.36 across three random sets.
4
Note however that due to the long tuning times, we are
reporting single tuning runs.
209
NN
SEGMENT
gericht
COMP
JUNC
@s@
SEGMENT
berufung
COMP
JUNC
@es@
SEGMENT
Bund
Figure 1: Syntactic representation of split com-
pound Bundesberufungsgericht (Engl: federal ap-
peals court).
We discriminatively learn non-terminal labels
for unknown words using sparse features, rather
than estimating a probability distribution of non-
terminal labels from singleton statistics in the
training corpus.
We perform target-side compound splitting, us-
ing a hybrid method described by Fritzinger and
Fraser (2010) that combines a finite-state mor-
phology and corpus statistics. As finite-state mor-
phology analyzer, we use Zmorge (Sennrich and
Kunz, 2014). An original contribution of our
experiments is a syntactic representation of split
compounds which eliminates typical problems
with target-side compound splitting, namely er-
roneous reorderings and compound merging. We
represent split compounds as a syntactic tree with
the last segment as head, preceded by a modifier.
A modifier consists of an optional modifier, a seg-
ment and a (possibly empty) joining element. An
example is shown in Figure 1. This hierarchical
representation ensures that compounds can be eas-
ily merged in post-processing (by removing the
spaces and special characters around joining ele-
ments), and that no segments are placed outside of
a compound in the translation.
We use unification-based constraints to model
morphological agreement within German noun
phrases, and between subjects and verbs (Williams
and Koehn, 2011). Additionally, we add con-
straints that operate on the internal tree structure of
the translation hypotheses, to enforce several syn-
tactic constraints that were frequently violated in
the baseline system:
? correct subcategorization of auxiliary/modal
verbs in regards to the inflection of the full
verb.
? passive clauses are not allowed to have ac-
cusative objects.
system
BLEU
devtest test
Stanford Parser 19.0 18.3
Berkeley Parser 19.3 18.6
BitPar 19.5 18.6
ParZu 19.6 19.1
+ modified label set 19.8 19.1
+ discriminative UNK weights 19.9 19.2
+ German compound splitting 20.0 19.8
+ grammatical constraints 20.2 20.1
Table 4: English to German translation results
on devtest (newstest2013) and test (newstest2014)
sets.
? relative clauses must contain a relative (or in-
terrogative) pronoun in their first constituent.
Table 4 shows BLEU scores with systems
trained with different parsers, and for our exten-
sions of the baseline system.
4 Czech to English
For Czech to English we used the core setup de-
scribed in Section 2 without modification. Table 5
shows the BLEU scores.
BLEU
system devtest test
baseline 24.8 27.0
Table 5: Czech to English results on the devtest
(newstest2013) and test (newstest2014) sets.
5 French to English
For French to English, alignment of the parallel
corpus was performed using fast_align (Dyer et
al., 2013) instead of MGIZA++ due to the large
volume of parallel data.
Table 6 shows BLEU scores for the system and
Table 7 shows the resulting grammar sizes after
filtering for the evaluation sets.
BLEU
system devtest test
baseline 29.4 32.3
Table 6: French to English results on the devtest
(newsdev2013) and test (newstest2014) sets.
210
system devtest test
baseline 86,341,766 88,657,327
Table 7: Grammar sizes of the French to En-
glish system after filtering for the devtest (new-
stest2013) and test (newstest2014) sets.
6 German to English
German compounds were split using the script
provided with Moses.
For training the primary system, the target parse
trees were restructured before rule extraction by
right binarization. Since binarization strategies
increase the tree depth and number of nodes by
adding virtual non-terminals, we increased the ex-
traction parameters to: Rule Depth = 7, Node
Count = 100, Rule Size = 7. A thorough in-
vestigation of binarization methods for restructur-
ing Penn Treebank style trees was carried out by
Wang et al. (2007).
Table 8 shows BLEU scores for the baseline
system and two systems employing different bi-
narization strategies. Table 9 shows the result-
ing grammar sizes after filtering for the evaluation
sets. Results on the development set showed no
improvement when left binarization was used for
restructuring the trees, although the grammar size
increased significantly.
BLEU
system devtest test
baseline 26.2 27.2
+ right binarization (primary) 26.8 28.2
+ left binarization 26.3 -
Table 8: German to English results on the devtest
(newsdev2013) and test (newstest2014) sets.
system devtest test
baseline 11,462,976 13,811,304
+ right binarization 24,851,982 29,133,910
+ left binarization 21,387,976 -
Table 9: Grammar sizes of the German to En-
glish systems after filtering for the devtest (new-
stest2013) and test (newstest2014) sets.
7 Hindi to English
English-Hindi has the least parallel training data
of this year?s language pairs. Out-of-vocabulary
(OOV) input words are therefore a comparatively
large source of translation error: in the devtest set
(newsdev2014) and filtered test set (newstest2014)
the average OOV rates are 1.08 and 1.16 unknown
words per sentence, respectively.
Assuming a significant fraction of OOV words
to be named entities and thus amenable to translit-
eration, we applied the post-processing translitera-
tion method described in Durrani et al. (2014) and
implemented in Moses. In brief, this is an unsuper-
vised method that i) uses EM to induce a corpus of
transliteration examples from the parallel training
data; ii) learns a monotone character-level phrase-
based SMT model from the transliteration corpus;
and iii) substitutes transliterations for OOVs in the
system output by using the monolingual language
model and other features to select between translit-
eration candidates.
5
Table 10 shows BLEU scores with and without
transliteration on the devtest and filtered test sets.
Due to a bug in the submitted system, the language
model trained on the HindEnCorp corpus was used
for transliteration candidate selection rather than
the full interpolated language model. This was
fixed subsequent to submission.
BLEU
system devtest test
baseline 12.9 14.7
+ transliteration (submission) 13.3 15.1
+ transliteration (fixed) 13.6 15.5
Table 10: Hindi to English results with and with-
out transliteration on the devtest (newsdev2014)
and test (newstest2014) sets.
Transliteration increased 1-gram precision from
48.1% to 49.4% for devtest and from 49.1% to
50.6% for test. Of the 2,913 OOV words in test,
938 (32.2%) of transliterations exactly match the
reference. Manual inspection reveals that there are
also many near matches. For instance, translitera-
tion produces Bernat Jackie where the reference is
Jacqui Barnat.
8 Russian to English
Compared to Hindi-English, the Russian-English
language pair has over six times as much parallel
data. Nonetheless, OOVs remain a problem: the
average OOV rates are approximately half those
5
This is the variant referred to as Method 2 in Dur-
rani et al. (2014).
211
of Hindi-English, at 0.47 and 0.51 unknown words
per sentence for the devtest (newstest2013) and fil-
tered test (newstest2014) sets, respectively. We
address this in part using the same transliteration
method as for Hindi-English.
Data sparsity issues for this language pair are
exacerbated by the rich inflectional morphology of
Russian. Many Russian word forms express gram-
matical distinctions that are either absent from En-
glish translations (like grammatical gender) or are
expressed by different means (like grammatical
function being expressed through syntactic config-
uration rather than case). We adopt the widely-
used approach of simplifying morphologically-
complex source forms to remove distinctions that
we believe to be redundant. Our method is simi-
lar to that of Weller et al. (2013) except that ours
is much more conservative (in their experiments,
Weller et al. (2013) found morphological reduc-
tion to harm translation indicating that useful in-
formation was likely to have been discarded).
We used TreeTagger (Schmid, 1994) to obtain
a lemma-tag pair for each Russian word. The tag
specifies the word class and various morphosyn-
tactic feature values. For example, the adjective
??????????????? (?republican?) gets the lemma-
tag pair ??????????????? + Afpfsnf, where
the code A indicates the word class and the re-
maining codes indicate values for the type, degree,
gender, number, case, and definiteness features.
Like Weller et al. (2013), we selectively re-
placed surface forms with their lemmas and re-
duced tags, reducing tags through feature dele-
tion. We restricted morphological reduction to ad-
jectives and verbs, leaving all other word forms
unchanged. Table 11 shows the features that
were deleted. We focused on contextual inflec-
tion, making the assumption that inflectional dis-
tinctions required by agreement alone were the
least likely to be useful for translation (since the
same information was marked elsewhere in the
sentence) and also the most likely to be the source
of ?spurious? variation.
Table 12 shows the BLEU scores for Russian-
English with transliteration and morphological re-
duction. The effect of transliteration was smaller
than for Hindi-English, as might be expected from
the lower baseline OOV rate. 1-gram precision in-
creased from 57.1% to 57.6% for devtest and from
62.9% to 63.6% for test. Morphological reduction
decreased the initial OOV rates by 3.5% and 4.1%
Adjective Verb
Type 7 Type 7
Degree 3 VForm 3
Gender 7 Tense 3
Number 7 Person 3
Case 7 Number 3
Definiteness 7 Gender 7
Voice 3
Definiteness 7
Aspect 3
Case 3
Table 11: Feature values that are retained (3)
or deleted (7) during morphological reduction of
Russian.
BLEU
system devtest test
baseline 23.3 29.7
+ transliteration 23.7 30.3
+ morphological reduction 23.8 30.3
Table 12: Russian to English results on the devtest
(newstest2013) and test (newstest2014) sets.
on the devtest and filtered test sets. After both
morphological and transliteration the 1-gram pre-
cisions for devtest and test were 57.7% and 63.8%.
9 Conclusion
We have described Edinburgh?s syntax-based sys-
tems in the WMT 2014 shared translation task.
Building upon the already-strong string-to-tree
systems developed for previous years? shared
translation tasks, we have achieved substantial im-
provements over our baseline setup: we improved
translation into German through target-side com-
pound splitting, morphosyntactic constraints, and
refinements to parse tree annotation; we have ad-
dressed unknown words using transliteration (for
Hindi and Russian) and morphological reduction
(for Russian); and we have improved our German-
English system through tree binarization.
Acknowledgements
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
o
287658 (EU-BRIDGE).
Rico Sennrich has received funding from the
Swiss National Science Foundation under grant
P2ZHP1_148717.
212
References
Stanley F. Chen and Joshua Goodman. 1998. An em-
pirical study of smoothing techniques for language
modeling. Technical report, Harvard University.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
427?436, Montr?al, Canada, June. Association for
Computational Linguistics.
Tagyoung Chung, Licheng Fang, and Daniel Gildea.
2011. Issues concerning decoding with synchronous
context-free grammar. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 413?417, Portland, Oregon, USA, June.
Nadir Durrani, Hassan Sajjad, Hieu Hoang, and Philipp
Koehn. 2014. Integrating an Unsupervised Translit-
eration Model into Statistical Machine Translation.
In Proceedings of the 15th Conference of the Euro-
pean Chapter of the ACL (EACL 2014), Gothenburg,
Sweden, April. To appear.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In In Proc. NAACL/HLT 2013,
pages 644?648.
Markus Freitag, Stephan Peitz, Joern Wuebker, Her-
mann Ney, Matthias Huck, Rico Sennrich, Nadir
Durrani, Maria Nadejde, Philip Williams, Philipp
Koehn, Teresa Herrmann, Eunah Cho, and Alex
Waibel. 2014. EU-BRIDGE MT: Combined Ma-
chine Translation. In Proceedings of the ACL 2014
Ninth Workshop on Statistical Machine Translation,
Baltimore, MD, USA, June.
Fabienne Fritzinger and Alexander Fraser. 2010. How
to Avoid Burning Ducks: Combining Linguistic
Analysis and Corpus Statistics for German Com-
pound Processing. In Proceedings of the Joint Fifth
Workshop on Statistical Machine Translation and
MetricsMATR, WMT ?10, pages 224?234, Uppsala,
Sweden.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a Translation Rule?
In HLT-NAACL ?04.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In ACL-
44: Proceedings of the 21st International Confer-
ence on Computational Linguistics and the 44th an-
nual meeting of the Association for Computational
Linguistics, pages 961?968, Morristown, NJ, USA.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Stroudsburg, PA, USA.
Mark Hopkins and Greg Langmead. 2010. SCFG de-
coding without binarization. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 646?655, Cambridge,
MA, October.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
NAACL ?03: Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology, pages 48?54, Morristown, NJ, USA.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 177?180, Morristown, NJ, USA.
Association for Computational Linguistics.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s Syntax-Based Machine Transla-
tion Systems. In Proceedings of the Eighth Work-
shop on Statistical Machine Translation, pages 170?
176, Sofia, Bulgaria, August.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Comput. Linguist., 29(1):19?51, March.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Com-
putational Linguistics - Volume 1, ACL ?03, pages
160?167, Morristown, NJ, USA.
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404?411, Rochester, New York, April.
Slav Petrov and Dan Klein. 2008. Parsing German
with Latent Variable Grammars. In Proceedings of
the Workshop on Parsing German at ACL ?08, pages
33?39, Columbus, OH, USA, June.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the As-
sociation for Computational Linguistics, ACL-44,
pages 433?440.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
213
Workshop on Parsing German at ACL ?08, pages 40?
46, Columbus, OH, USA, June.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In International Con-
ference on New Methods in Language Processing,
pages 44?49, Manchester, UK.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Rico Sennrich and Beat Kunz. 2014. Zmorge: A Ger-
man Morphological Lexicon Extracted from Wik-
tionary. In Proceedings of the 9th International
Conference on Language Resources and Evaluation
(LREC 2014), Reykjavik, Iceland, May.
Rico Sennrich, Martin Volk, and Gerold Schneider.
2013. Exploiting Synergies Between Open Re-
sources for German Dependency Parsing, POS-
tagging, and Morphological Analysis. In Proceed-
ings of the International Conference Recent Ad-
vances in Natural Language Processing 2013, pages
601?609, Hissar, Bulgaria.
Andreas Stolcke. 2002. SRILM - an extensible
language modeling toolkit. In Intl. Conf. Spoken
Language Processing, Denver, Colorado, September
2002.
Wei Wang, Kevin Knight, Daniel Marcu, and Marina
Rey. 2007. Binarizing Syntax Trees to Improve
Syntax-Based Machine Translation Accuracy. In
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, pages 746?754.
Marion Weller, Max Kisselew, Svetlana Smekalova,
Alexander Fraser, Helmut Schmid, Nadir Durrani,
Hassan Sajjad, and Rich?rd Farkas. 2013. Munich-
Edinburgh-Stuttgart submissions at WMT13: Mor-
phological and syntactic processing for SMT. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, pages 232?239, Sofia, Bul-
garia, August.
Philip Williams and Philipp Koehn. 2011. Agreement
Constraints for Statistical Machine Translation into
German. In Proceedings of the Sixth Workshop on
Statistical Machine Translation, pages 217?226, Ed-
inburgh, Scotland, July.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 388?394, Montr?al,
Canada, June.
214
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 486?498,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
Augmenting String-to-Tree and Tree-to-String Translation with
Non-Syntactic Phrases
Matthias Huck and Hieu Hoang and Philipp Koehn
School of Informatics
University of Edinburgh
10 Crichton Street
Edinburgh EH8 9AB, UK
{mhuck,hhoang,pkoehn}@inf.ed.ac.uk
Abstract
We present an effective technique to easily
augment GHKM-style syntax-based ma-
chine translation systems (Galley et al.,
2006) with phrase pairs that do not comply
with any syntactic well-formedness con-
straints. Non-syntactic phrase pairs are
distinguished from syntactic ones in or-
der to avoid harming effects. We apply
our technique in state-of-the-art string-to-
tree and tree-to-string setups. For tree-to-
string translation, we furthermore investi-
gate novel approaches for translating with
source-syntax GHKM rules in association
with input tree constraints and input tree
features.
1 Introduction
Syntax-based statistical machine translation sys-
tems utilize linguistic information that is obtained
by parsing the training data. In tree-to-string
translation, source-side syntactic tree annotation is
employed, while string-to-tree translation exploits
target-side syntax. The syntactic parse tree an-
notation constrains phrase extraction to syntacti-
cally well-formed phrase pairs: spans of syntactic
phrases must match constituents in the parse tree.
Standard phrase-based and hierarchical phrase-
based statistical machine translation systems, in
contrast, allow all phrase pairs that are consistent
with the word alignment (Koehn et al., 2003; Chi-
ang, 2005).
A restriction of the phrase inventory to syntac-
tically well-formed phrase pairs entails that possi-
bly valuable information from the training data re-
mains disregarded. While we would expect phrase
pairs that are not linguistically motivated to be less
reliable, discarding them altogether might be an
overly harsh decision. The quality of an inventory
of syntactic phrases depends heavily on the tree
annotation scheme and the quality of the syntac-
tic parses of the training data. Phrase pairs that
do not span constituents in the tree annotation ob-
tained from syntactic parses can provide reason-
able alternative segmentations or alternative trans-
lation options which prove to be valuable to the
decoder.
In this work, we augment the phrase invento-
ries of string-to-tree and tree-to-string translation
systems with phrase pairs that are not induced in
the syntax-based extraction. We extract continu-
ous phrases that are consistent with the word align-
ment, without enforcing any constraints with re-
spect to syntactic tree annotation. Non-syntactic
phrases are added as rules to the baseline syntactic
grammar with a fill-up technique. New rules are
only added if their right-hand side does not exist
yet. We extend the glue grammar with a special
glue rule to allow for application of non-syntactic
phrases during decoding. A feature in the log-
linear model combination serves to distinguish
non-syntactic phrases from syntactic ones. During
decoding, the decoder can draw on both syntactic
and non-syntactic phrase table entries and produce
derivations which resort to both types of phrases.
Such derivations yield hypotheses that make use of
the alternative segmentations and translation op-
tions provided through non-syntactic phrases. The
search space is more diverse, and in some cases
all hypotheses from purely syntax-based deriva-
tions score worse than a translation that applies
one or more non-syntactic phrases. We empiri-
cally demonstrate that this technique can lead to
substantial gains in translation quality.
Our syntactic translation models conform to the
GHKM syntax approach as proposed by Galley,
Hopkins, Knight, and Marcu (Galley et al.,
2004) with composed rules as in (Galley et al.,
2006) and (DeNeefe et al., 2007). State-of-the-
art GHKM string-to-tree systems have recently
shown very competitive performance in public
486
evaluation campaigns (Nadejde et al., 2013; Bo-
jar et al., 2013). We apply the GHKM approach
not only in a string-to-tree setting as in previous
work, but employ it to build tree-to-string sys-
tems as well. We conduct tree-to-string translation
with text input and additionally adopt translation
with tree input and input tree constraints as sug-
gested for hierarchical translation by Hoang and
Koehn (2010). We also implement translation with
tree input and feature-driven soft tree matching.
The effect of augmenting the systems with non-
syntactic phrases is evaluated for all variants.
2 Outline
The remainder of the paper is structured as fol-
lows: We review some of the basics of syntax-
based translation in the next section (Section 3)
and sketch the characteristics of our GHKM
string-to-tree and tree-to-string translation frame-
works.
In Section 4, we describe our technique to
augment GHKM-style syntax-based systems with
phrase pairs that do not comply with any syntactic
well-formedness constraints.
Section 5 contains the empirical part of the pa-
per. We first describe our experimental setup (5.1),
followed by a presentation of the translation re-
sults (5.2). We also include a few translation ex-
amples (5.3) in order to illustrate the differences
between the syntax-based baseline systems and
the setups augmented with non-syntactic phrases.
The empirical part is concluded with a brief dis-
cussion (5.4).
In the final part of the paper (Section 6), we
give a survey of previous work that has dealt
with problems related to overly restrictive syntac-
tic grammars for statistical machine translation,
inadequate syntactic parses, and insufficient cov-
erage of syntactic phrase inventories. A broad
spectrum of diverse methods has been proposed in
the literature, many of which are quite dissimilar
from ours but nevertheless related. We conclude
the paper in Section 7.
3 Syntax-based Translation
In syntax-based translation, a probabilistic syn-
chronous context-free grammar (SCFG) is in-
duced from bilingual training corpora. The par-
allel training data is word-aligned and annotated
with syntactic parses on either target side (string-
to-tree), source side (tree-to-string), or both (tree-
to-tree). A syntactic phrase extraction procedure
extracts rules which are consistent with the word-
alignment and conform with certain syntactic va-
lidity constraints.
Extracted rules are of the form A,B???,? ,
?
?.
The right-hand side of the rule ??,? ? is a bilingual
phrase pair that may contain non-terminal sym-
bols, i.e. ? ? (V
F
? N
F
)
+
and ? ? (V
E
? N
E
)
+
,
where V
F
and V
E
denote the source and target
terminal vocabulary, and N
F
and N
E
denote the
source and target non-terminal vocabulary, respec-
tively. The non-terminals on the source side and
on the target side of rules are linked in a one-to-
one correspondence. The
?
relation defines this
one-to-one correspondence. The left-hand side
of the rule is a pair of source and target non-
terminals, A ? N
F
and B ? N
E
.
Decoding is typically carried out with a parsing-
based algorithm, in our case a customized version
of CYK
+
(Chappelier and Rajman, 1998). The
parsing algorithm is extended to handle transla-
tion candidates and to incorporate language model
scores via cube pruning (Chiang, 2007).
3.1 GHKM String-to-Tree Translation
In GHKM string-to-tree translation (Galley et al.,
2004; Galley et al., 2006; DeNeefe et al., 2007),
rules are extracted from training instances which
consist of a source sentence, a target sentence
along with its constituent parse tree, and a word
alignment matrix. This tuple is interpreted as a
directed graph (the alignment graph), with edges
pointing away from the root of the tree, and word
alignment links being edges as well. A set of
nodes (the frontier set) is determined that con-
tains only nodes with non-overlapping closure of
their spans.
1
By computing frontier graph frag-
ments?fragments of the alignment graph such
that their root and all sinks are in the frontier set?
the GHKM extractor is able to induce a minimal
set of rules which explain the training instance.
The internal tree structure can be discarded to ob-
tain flat SCFG rules. Minimal rules can be assem-
bled to build larger composed rules.
Non-terminals on target sides of string-to-tree
rules are syntactified. The target non-terminal vo-
cabulary of the SCFG contains the set of labels
of the frontier nodes, which is in turn a subset
1
The span of a node in the alignment graph is defined
as the set of source-side words that are reachable from this
node. The closure of a span is the smallest interval of source
sentence positions that covers the span.
487
TOP
PUNC.
.
CS-TOP
S-TOP
NP-OA
NN
Autonomie
ADJA
politische
ART
die
ADV
auch
VMFIN
wollten
NP-SB
PPER
sie
PUNC,
,
S-TOP
ADV
. . .leider
unfortunately , . . . , they also wanted political autonomy .
Figure 1: Word-aligned training sentence pair with target-side syntactic annotation.
of (or equal to) the set of constituent labels in
the parse tree. It furthermore contains an initial
non-terminal symbol Q. Source sides of the rules
are not decorated with syntactic annotation. The
source non-terminal vocabulary contains a single
generic non-terminal symbol X.
In addition to the extracted grammar, the trans-
lation system makes use of a special glue grammar
with an initial rule, glue rules, a final rule, and top
rules. The glue rules provide a fall back method
to just monotonically concatenate partial deriva-
tions during decoding. As we add tokens which
mark the sentence start (?<s>?) and the sentence
end (?</s>?), the rules in the glue grammar are of
the following form:
Initial rule:
X,Q? ?<s> X
?0
,<s> Q
?0
?
Glue rules:
X,Q? ?X
?0
X
?1
,Q
?0
B
?1
?
for all B ? N
E
Final rule:
X,Q? ?X
?0
</s>,Q
?0
</s>?
Top rules:
X,Q? ?<s> X
?0
</s>,<s> B
?0
</s>?
for all B ? N
E
3.2 GHKM Tree-to-String Translation
The described techniques for GHKM string-to-
tree translation can be adjusted for tree-to-string
translation in a straightforward manner. Rules are
extracted from training instances which consist of
a source sentence along with its constituent parse
tree, a target sentence, and a word alignment ma-
trix. We omit the details.
For GHKM tree-to-string translation, we inves-
tigate three decoding variants:
Tree-to-string translation with text input. The
decoder can construct any source-side syn-
tactic analysis that the grammar permits, very
similar to string-to-tree translation.
Tree-to-string translation with tree input and
input tree constraints. Syntactic annotation
over the input data is provided to the decoder.
The source-side syntactic non-terminals of a
tree-to-string translation rule need to match
the constituent span in the input sentence,
otherwise the rule cannot be applied. This
variant follows the method that was sug-
gested for hierarchical translation by Hoang
and Koehn (2010).
Tree-to-string translation with tree input and
input tree features. Syntactic annotation
over the input data is provided to the decoder.
No hard matching constraints are imposed,
but the decoder is informed about matches
and mismatches of the syntactic annotation in
the rules and in the input tree. It takes them
into account for the score computation.
4 Non-Syntactic Phrases for GHKM
Translation
The syntactic constraints in GHKM extraction can
unfortunately prevent useful phrase pairs from be-
ing included in the phrase inventory. Consider the
example in Figure 1: the highlighted phrase pair
?also wanted,wollten auch? cannot be extracted
from this training instance for string-to-tree trans-
lation.
488
In the standard phrase-based approach, in con-
trast, all continuous phrases that are consistent
with the word alignment are extracted (Och et al.,
1999; Och, 2002). The set of continuous bilingual
phrases BP( f
J
1
,e
I
1
,A), given a training instance
comprising a source sentence f
J
1
, a target sentence
e
I
1
, and a word alignment A?{1, ..., I}?{1, ...,J},
is defined as follows:
BP( f
J
1
,e
I
1
,A) =
{
? f
j
2
j
1
,e
i
2
i
1
? : ?(i, j) ? A : i
1
? i? i
2
? j
1
? j ? j
2
??(i, j) ? A : i
1
? i? i
2
? j
1
? j ? j
2
}
Consistency for continuous phrases is based upon
merely two constraints in this definition: (1.) At
least one source and target position within the
phrase must be aligned, and (2.) words from inside
the source phrase may only be aligned to words
from inside the target phrase and vice versa. The
highlighted phrase pair from the example does not
violate these constraints.
In order to augment our GHKM syntax-based
systems with non-syntactic phrases, we obey the
following procedure:
? The setBP is extracted from all training in-
stances, and phrase translation probabilities
are computed separately from those in the
syntactic phrase inventory.
? Non-syntactic phrases are converted to rules
by providing a special left-hand side non-
terminal X.
? A phrase table fill-up method is applied to
enhance the syntactic phrase inventory with
entries from the non-syntactic phrase inven-
tory. Non-syntactic rules are only added to
the final grammar if no syntactic rule with
the same (source and target) right-hand side
is present. This method is inspired by pre-
vious work in domain adaptation (Bisazza et
al., 2011).
? The glue grammar is extended with a new
glue rule
X,Q? ?X
?0
X
?1
,Q
?0
X
?1
?
that enables the system to make use of non-
syntactic rules in decoding.
? A binary feature is added to the log-linear
model (Och and Ney, 2002) to distinguish
non-syntactic rules from syntactic ones, and
to be able to assign a tuned weight to the non-
syntactic part of the grammar.
5 Empirical Evaluation
We evaluate the effect of augmenting GHKM
syntax-based translation systems?both string-to-
tree and tree-to-string?with non-syntactic phrase
pairs on the English?German language pair using
the standard newstest sets of the Workshop on Sta-
tistical Machine Translation (WMT) for testing.
2
The experiments are conducted with the open-
source Moses implementations of GHKM rule ex-
traction (Williams and Koehn, 2012) and decoding
with CYK
+
parsing and cube pruning (Hoang et al.,
2009).
5.1 Experimental Setup
We work with an English?German parallel train-
ing corpus of around 4.5 M sentence pairs (af-
ter corpus cleaning). The parallel data origi-
nates from three different sources which have
been eligible for the constrained track of the
ACL 2014 Ninth Workshop on Statistical Ma-
chine Translation shared translation task: Europarl
(Koehn, 2005), News Commentary, and the Com-
mon Crawl corpus as provided on the WMT web-
site. Word alignments are created by aligning the
data in both directions with MGIZA
++
(Gao and
Vogel, 2008) and symmetrizing the two trained
alignments (Och and Ney, 2003; Koehn et al.,
2003). For string-to-tree translation, we parse the
German target side with BitPar (Schmid, 2004).
3
For tree-to-string translation, we parse the English
source side of the parallel data with the English
Berkeley Parser (Petrov et al., 2006).
When extracting syntactic phrases, we impose
several restrictions for composed rules, in partic-
ular a maximum number of twenty tree nodes per
rule, a maximum depth of five, and a maximum
size of five. We discard rules with non-terminals
on their right-hand side if they are singletons in the
training data.
Only the 100 best translation options per dis-
tinct source side with respect to the weighted
phrase-level model scores are loaded by the de-
coder. The decoder is configured with a maximum
chart span of 25 and a rule limit of 100.
A standard set of models is used in the base-
lines, comprising phrase translation probabilities
and lexical translation probabilities in both direc-
2
http://www.statmt.org/wmt14/
translation-task.html
3
We remove grammatical case and function information
from the annotation obtained with BitPar.
489
system dev newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
phrase-based 33.0 48.8 18.8 64.5 18.2 66.9
+ lexicalized reordering 34.2 48.1 19.2 64.5 18.3 67.1
string-to-string (syntax-directed extraction) 32.6 49.4 18.2
}
+0.5
65.4
}
?0.4
17.8
}
+0.5
68.0
}
?0.4
+ non-syntactic phrases 33.4 49.0 18.7 65.0 18.3 67.6
string-to-tree 33.6 48.7 19.5
}
+0.3
63.9
}
?0.3
18.6
}
+0.5
66.9
}
?0.7
+ non-syntactic phrases 34.3 48.0 19.8 63.6 19.1 66.2
tree-to-string 34.0 48.5 19.5
}
?0.2
63.8
}
+0.2
18.5
}
+0.2
67.0
}
?0.4
+ non-syntactic phrases 33.9 48.4 19.3 64.0 18.7 66.6
+ input tree constraints 33.7 48.4 19.3
}
+0.4
63.9
}
?0.3
18.3
}
+0.3
67.0
}
?0.5
+ non-syntactic phrases 34.2 48.2 19.7 63.6 18.7 66.5
+ input tree features 34.3 48.3 19.6
}
+0.3
63.7
}
?0.3
18.6
}
+0.2
67.0
}
?0.5
+ non-syntactic phrases 34.4 48.1 19.9 63.4 18.8 66.5
Table 1: English?German experimental results (truecase). BLEU scores are given in percentage.
tions, word and phrase penalty, an n-gram lan-
guage model, a rule rareness penalty, and the
monolingual PCFG probability of the tree frag-
ment from which the rule was extracted (Williams
et al., 2014). Phrase translation probabilities are
smoothed via Good-Turing smoothing.
The language model (LM) is a large inter-
polated 5-gram LM with modified Kneser-Ney
smoothing (Kneser and Ney, 1995; Chen and
Goodman, 1998). The target side of the parallel
corpus and the monolingual German News Crawl
corpora are employed as training data. We use
the SRILM toolkit (Stolcke, 2002) to train the LM
and rely on KenLM (Heafield, 2011) for language
model scoring during decoding.
Model weights are optimized to maximize
BLEU (Papineni et al., 2002) with batch MIRA
(Cherry and Foster, 2012) on 1000-best lists. We
selected 2000 sentences from the newstest2008-
2012 sets as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and do each contain less than
30 words for more rapid tuning. newstest2013 and
newstest2014 are used as unseen test sets. Trans-
lation quality is measured in truecase with BLEU
and TER (Snover et al., 2006).
4
We apply a phrase length limit of five when
extracting non-syntactic phrases for the fill-up of
syntactic phrase tables.
4
TER scores are computed with tercom version 0.7.25
and parameters -N -s.
5.2 Translation Results
Table 1 comprises the results of our empirical eval-
uation of the translation quality achieved by the
different systems.
5.2.1 Phrase-based Baselines
We set up two phrase-based baselines for com-
parison. Their set of models is the same as for
the syntax-based baselines, with the exception of
the PCFG probability. One of the phrase-based
systems moreover utilizes a lexicalized reorder-
ing model (Galley and Manning, 2008). No non-
standard advanced features (like an operation se-
quence model or class-based LMs) are engrafted.
The maximum phrase length is five, search is car-
ried out with cube pruning at a k-best limit of
1000. A maximum number of 100 translation op-
tions per source side are taken into account.
5.2.2 String-to-String Contrastive System
A further contrastive experiment is done with a
string-to-string system. The extraction method
for this string-to-string system is GHKM syntax-
directed with syntactic target-side annotation from
BitPar, as in the string-to-tree setup. We actually
extract the same rules but strip off the syntactic la-
bels. The final grammar contains rules with a sin-
gle generic non-terminal instead of syntactic ones.
Note that a side effect of this is that the phrase
inventory of the string-to-string system contains
490
a larger amount of hierarchical phrases
5
than the
string-to-tree system, though the same rules are
extracted. The reason is that we discard single-
ton hierarchical rules when we normalize the fre-
quencies after extraction. Many rules that are sin-
gletons when the syntax decoration is taken into
account have in fact been seen multiple times if
syntactic labels are not distinguished, due to pool-
ing of counts.
The string-to-string system is on newstest2013
1.0 points BLEU worse than the phrase-based
system with lexicalized reordering and on news-
test2014 0.5 points BLEU. We gain 0.5 points
BLEU on both of the test sets if we augment the
string-to-string system with non-syntactic phrases
from the standard phrase-based extractor accord-
ing to our procedure from Section 4.
5.2.3 String-to-Tree System
The translation quality of the string-to-tree sys-
tem surpasses the translation quality of the bet-
ter phrase-based baseline slightly (by 0.3 points
BLEU on both test sets). The string-to-tree system
is clearly superior to the string-to-string system,
which verifies that syntactic non-terminals are in-
deed vital. We get a nice gain of 0.5 points BLEU
and 0.7 points TER on newstest2014 if we aug-
ment the string-to-tree system with non-syntactic
phrases. The phrase-based system is outperformed
by 0.8 points BLEU.
5.2.4 Tree-to-String Systems
The tree-to-string baseline with text input per-
forms at the level of the string-to-tree baseline, but
augmenting it with non-syntactic phrases yields
only a small improvement or even harms a little
(on newstest2013).
Decoding with tree input and input tree con-
straints causes a minor loss in translation qual-
ity. We however observed a decoding speed-up. If
we employ non-syntactic phrases to augment the
tree-to-string setup with input tree constraints, we
provide the new non-syntactic rules in the gram-
mar with a particular property: their left-hand side
non-terminal X can match any constituent span in
the input sentence. The decoder would not be
able to utilize non-syntactic phrases without this
relaxation. Syntactic phrases amount to an in-
crease of up to 0.4 points BLEU (newstest2013)
5
We define hierarchical phrases as rules with non-
terminals on their right-hand side, in contrast to lexical
phrases which are continuous rules with right-hand sides that
contain terminal symbols only.
and 0.5 points TER (newstest2014) in the tree-
constrained setup.
Our best tree-to-string setup takes tree input, but
involves soft matching features instead of hard in-
put tree constraints. We incorporate two features,
one that fires for matches and another one that fires
for mismatches. The motivation for not relying on
just one feature which would penalize mismatches
is that the number of syntactic non-terminals in
the derivation can differ between hypotheses. Not
all constituent spans need to be matched (or mis-
matched) by non-terminals, some can be over-
laid through larger rules.
6
Tree-to-string transla-
tion with input tree features benefits from being
augmented with non-syntactic phrases by 0.2 to
0.3 points BLEU. The resulting system is mini-
mally better than the best string-to-tree system on
newstest2013, and slightly worse than it on news-
test2014.
5.3 Translation Examples
We illustrate the differences between the syntax-
based baseline systems and the setups augmented
with non-syntactic phrases by means of two trans-
lation examples from newstest2014. Both exam-
ples are string-to-tree translations.
Figures 2 and 3 depict an example that cor-
responds well to the word-aligned training sen-
tence pair with target-side syntactic annotation
from Figure 1. Figure 2 shows the translation, seg-
mentation, and parse tree derived by the string-
to-tree baseline system as single-best output for
the preprocessed input sentence: ?the lessees were
against this and also wanted longer terms .? The
reference translation is: ?Die P?chter waren dage-
gen und wollten zudem l?ngere Laufzeiten.? Fig-
ure 3 shows the translation, segmentation, and
parse tree derived by the string-to-tree system aug-
mented with non-syntactic phrases. There are
two word substitutions with respect to the ref-
erence in the latter translation, but they convey
the same meaning. The baseline translation fails
to convey the meaning, mostly because ?terms?
is translated to the verb ?gesehen?, which is a
wrong syntactic analysis in the given context. In-
terestingly, the segmentation applied by the two
systems is rather similar, apart from the interval
?also wanted? which cannot be translated en bloc
by the baseline. All rules in the baseline gram-
6
Also remember that we discarded the internal tree struc-
ture to obtain flat SCFG rules.
491
Q</s>
Q
TOP
.
VP-OC
VVPP
gesehenmehr
ADV
auch
VMFIN
wollteund
S-TOP
dagegen
VAFIN
waren
NP-SB
Mieter
Q
ART
die
Q
<s>
<s> the lessees were against this and also wanted longer terms . </s>
Reference: Die P?chter waren dagegen und wollten zudem l?ngere Laufzeiten.
Figure 2: Translation and parse tree from the string-to-tree system.
Q
</s>
Q
PUNC.
.
Q
NP-OA
NN
Laufzeitenl?ngere
Q
X
auchwollten
Q
KON
und
Q
S-TOP
dagegen
VAFIN
waren
NP-SB
Mieter
Q
ART
die
Q
<s>
<s> the lessees were against this and also wanted longer terms . </s>
Reference: Die P?chter waren dagegen und wollten zudem l?ngere Laufzeiten.
Figure 3: Translation and parse tree from the string-to-tree system augmented with non-syntactic phrases.
mar that contain ?also wanted? as part of their
source side imply a larger source-side lexical con-
text that is not present in the given sentence. None
of those rules matches the input. The baseline
has to translate ?also? and ?wanted? separately
and fails to translate the verb to a plural form
German verb. The next rule in bottom-up order
is already involved in the incorrect choice of a
verb for ?terms?. The string-to-tree system aug-
mented with non-syntactic phrases applies more
glue rules, but this is beneficial in the present
example, as it breaks apart the faulty syntactic
derivation.
Figures 4 and 5 depict a second example. Com-
pared to the baseline, filling up the phrase table
with non-syntactic phrases had the effect of disas-
sembling the originally nicely built syntactic tree
structure over the translation nearly completely.
Four non-syntactic phrases are applied, three of
them span over target-side punctuation marks. The
baseline translation is more literal and conveys
the meaning, but the system augmented with non-
syntactic phrases produces a more fluent output.
Its translation seems more natural and happens to
match the reference in this case.
492
Q</s>
TOP
.
S-TOP
AP-PD
beeindruckendist,
NP-SB
S-RC
VVFIN
spielt
NP-SB
Teamdasderin,WeiseundArtdie,
S-TOP
allenvon
AA-MO
meistenam<s>
<s> most of all , the manner in which the team is playing is impressive . </s>
Reference: Vor allem die Art und Weise, wie die Mannschaft spielt, ist beeindruckend.
Figure 4: Translation and parse tree from the string-to-tree system.
Q
</s>
Q
X
.beeindruckendist
Q
X
,spielt
Q
NP-SB
Mannschaftdie
Q
X
wie,WeiseundArt
Q
ART
die
Q
X
allemvor
Q
<s>
<s> most of all , the manner in which the team is playing is impressive . </s>
Reference: Vor allem die Art und Weise, wie die Mannschaft spielt, ist beeindruckend.
Figure 5: Translation and parse tree from the string-to-tree system augmented with non-syntactic phrases.
phrase table entries unfiltered dev newstest2013 newstest2014
hier. lexical hier. lexical hier. lexical hier. lexical
phrase-based ? 184.9 M ? 25.3 M ? 29.0 M ? 28.0 M
string-to-string 58.3 M 19.9 M 4.3 M 2.9 M 5.7 M 3.3 M 5.3 M 3.3 M
+ non-syntactic phrases 58.3 M 191.1 M 4.3. M 25.4 M 5.7 M 29.1 M 5.3 M 28.1 M
string-to-tree 39.7 M 21.2 M 4.9 M 3.4 M 5.7 M 3.8 M 5.5 M 3.7 M
+ non-syntactic phrases 39.7 M 192.4 M 4.9 M 25.8 M 5.7 M 29.6 M 5.5 M 28.6 M
tree-to-string 29.5 M 21.1 M 7.7 M 2.8 M 9.0 M 3.3 M 8.7 M 3.2 M
+ non-syntactic phrases 29.5 M 192.6 M 7.7 M 26.1 M 9.0 M 29.9 M 8.7 M 28.9 M
Table 2: Phrase inventory statistics for the different English?German translation systems. ?hier.? de-
notes hierarchical phrases, i.e. rules with non-terminals on their right-hand side, ?lexical? denotes con-
tinuous phrases.
493
5.4 Discussion
A drawback of our method is that it increases
the size of the synchronous context-free gram-
mar massively. Most phrase pairs from standard
phrase-based extraction are actually not present in
the GHKM rule set, even with composed rules.
A large fraction of the extracted non-syntactic
phrases is such added to the phrase inventory
through phrase table fill-up. Table 2 shows the
phrase inventory statistics for the different sys-
tems.
Another question relates to the glue rule appli-
cations. The application of a non-syntactic rule
is always accompanied with a respective glue rule
application in our implementation. The string-
to-tree baseline utilizes glue rules on average 3.0
times in each single-best translation (measured
on newstest2014), the string-to-tree system aug-
mented with non-syntactic phrases utilizes glue
rules on average 7.0 times. We considered an im-
plementation that allows for embedding of non-
syntactic rules into hierarchical rules (other than
the glue rules) but did not see improvements with
it as yet. Furthermore, efficiency concerns become
more relevant in such an implementation.
6 Related Work
Issues with overly restrictive syntactic grammars
for statistical machine translation, inadequate syn-
tactic parses, and insufficient coverage have been
tackled from several different directions in the lit-
erature.
A proposed approach to attain better syntac-
tic phrase inventories is to restructure the syntac-
tic parse trees in a preprocessing step (Wang et
al., 2007; Wang et al., 2010; Burkett and Klein,
2012). This line of research aims at rearranging
parse trees in a way that makes them a better fit
for the requirements of the bilingual downstream
application. Conversely, Fossum et al. (2008) re-
tain the structure of the parse trees and modify the
word alignments.
Marcu et al. (2006) relax syntactic phrase ex-
traction constraints in their SPMT Model 2 to al-
low for phrases that do not match the span of one
single constituent in the parse tree. SPMT Model 2
rules are created from spans that are consistent
with the word alignment and covered by multiple
constituents such that the union of the constituents
matches the span. Pseudo non-syntactic non-
terminals are introduced for the left-hand sides of
SPMT Model 2 rules. Special additional rules al-
low for combination of those non-syntactic left-
hand side non-terminals with genuine syntactic
non-terminals on the right-hand sides of other
rules during decoding.
Another line of research took the hierarchical
phrase-based model (Chiang, 2005; Chiang, 2007)
as a starting point and extended it with syntactic
enhancements. In their SAMT system, Zollmann
and Venugopal (2006) labeled the non-terminals
of the hierarchical model with composite symbols
derived from the syntactic tree annotation. Similar
methods have been applied with CCG labels (Al-
maghout et al., 2012). Venugopal et al. (2009)
and Stein et al. (2010) keep the grammar of the
non-terminals of the hierarchical model unlabeled
and apply the syntactic information in a separate
model. Other authors added features which fire
for phrases complying with certain syntactic prop-
erties while retaining all phrase pairs of the hier-
archical model (Marton and Resnik, 2008; Vilar et
al., 2008).
In a tree-to-tree translation setting, Chiang
(2010) proposed techniques to soften the syntac-
tic constraints. A fuzzy approach with complex
non-terminal symbols as in SAMT is employed
to overcome the limitations during phrase extrac-
tion. In decoding, substitutions of non-terminals
are not restricted to matching ones. Any left-
hand side non-terminal can substitute any right-
hand side non-terminal. The decoder decides on
the best derivation based on the tuned weights of a
large number of binary features.
Joining phrase inventories that come from mul-
tiple origins is a common method in domain adap-
tation (Bertoldi and Federico, 2009; Niehues and
Waibel, 2012) but has also been applied in the
contexts of lightly-supervised training (Schwenk,
2008; Huck et al., 2011) and of forced alignment
training (Wuebker et al., 2010). For our purposes,
we apply a fill-up method in the manner of the one
that has been shown to perform well for domain
adaptation in earlier work (Bisazza et al., 2011).
Previous research that resembles our work most
has been presented by Liu et al. (2006) and by
Hanneman and Lavie (2009).
Liu et al. (2006) allow for application of non-
syntactic phrase pairs in their tree-to-string align-
ment template (TAT) system. The translation
probabilities for the non-syntactic phrases are ob-
tained from a standard phrase-based extraction
494
pipeline. A non-syntactic phrase pair can how-
ever only be applied if its source side matches
a subtree in the parsed input sentence. Syn-
tactic and non-syntactic phrases are not distin-
guished, and overlap between the syntactic and
non-syntactic part of the phrase inventory is not
avoided. The decoder picks the entry with the
higher phrase translation probability, which means
that non-syntactic phrase table entries can super-
sede syntactic entries. The authors report im-
provements of 0.6 points BLEU on the 2005 NIST
Chinese?English task with four reference trans-
lations.
Hanneman and Lavie (2009) examine non-
syntactic phrases for tree-to-tree translation with
the Stat-XFER framework as developed at
Carnegie Mellon University (Lavie, 2008). They
combine syntactic and non-syntactic phrase in-
ventories and reestimate the probabilities for both
types of phrase pairs by adding up the observed
absolute frequencies. Two combination schemes
are evaluated: combination with all extractable
valid non-syntactic phrases (?direct combination?)
and combination with only those non-syntactic
phrases whose source sides are not equal to the
source side of any syntactic phrase (?syntax-
prioritized combination?). On a French?English
translation task, Hanneman and Lavie (2009) re-
port improvements of around 2.6 points BLEU by
adding non-syntactic phrases on top of their Stat-
XFER syntactic baselines. Their best setup how-
ever does not reach the performance of a stan-
dard phrase-based system, which is still 1.6 points
BLEU better.
Apart from the differences in the underly-
ing syntax-based translation technology (string-
to-tree/tree-to-string GHKM vs. TAT vs. Stat-
XFER), our work also constitutes a novel contri-
bution as compared to the previous approaches by
Liu et al. (2006) and Hanneman and Lavie (2009)
with respect to the following:
? The phrase inventory is augmented with non-
syntactic phrases by means of a fill-up tech-
nique. Overlap is prevented, whereas not
only new source sides, but also new target-
side translation options can be added.
? The probabilities of syntactic phrase pairs are
the same as in the syntax-based baseline, and
the probabilities of the non-syntactic phrase
pairs are the same as in a phrase-based sys-
tem. Counts of syntactic and non-syntactic
phrases are not summed up to obtain new es-
timates.
? Non-syntactic phrase pairs are distinguished
from syntactic ones with an additional fea-
ture.
7 Conclusions
String-to-tree and tree-to-string translation sys-
tems can easily be augmented with non-syntactic
phrases by means of phrase table fill-up, a special
non-terminal symbol for left-hand sides of non-
syntactic rules in the grammar, and an additional
glue rule. A binary feature enables the system to
distinguish non-syntactic phrases from syntactic
ones and?on the basis of the respective feature
weight?to favor syntactically motivated phrases
during decoding.
Our results on an English?German translation
task demonstrate the beneficial effect of augment-
ing GHKM translation systems with non-syntactic
phrase pairs. Empirical gains in translation qual-
ity are up to 0.5 points BLEU and 0.7 points TER
over the baseline on the recent test set of the shared
translation task of the ACL 2014 Ninth Workshop
on Statistical Machine Translation.
While GHKM-style syntactic translation has
typically been utilized in string-to-tree settings in
previous research, we have also adopted it to build
tree-to-string systems in this work. Source syn-
tax establishes interesting further directions for
GHKM systems. We investigated two of them: in-
put tree constraints and input tree features.
String-to-tree and tree-to-string GHKM sys-
tems perform roughly at the same level in terms
of translation quality. Our best string-to-tree
setup outperforms a phrase-based baseline by up
to 0.8 points BLEU and 0.9 points TER (on
newstest2014), our best tree-to-string setup out-
performs the phrase-based baseline by up to
0.7 points BLEU and 1.1 points TER (on news-
test2013).
Acknowledgements
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreements n
o
287658 (EU-BRIDGE)
and n
o
288487 (MosesCore).
495
References
Hala Almaghout, Jie Jiang, and Andy Way. 2012. Ex-
tending CCG-based Syntactic Constraints in Hierar-
chical Phrase-Based SMT. In Proc. of the Annual
Conf. of the European Assoc. for Machine Transla-
tion (EAMT), pages 193?200, Trento, Italy, May.
Nicola Bertoldi and Marcello Federico. 2009. Domain
Adaptation for Statistical Machine Translation with
Monolingual Resources. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
182?189, Athens, Greece, March.
Arianna Bisazza, Nick Ruiz, and Marcello Federico.
2011. Fill-up versus Interpolation Methods for
Phrase-based SMT Adaptation. In Proc. of the
Int. Workshop on Spoken Language Translation
(IWSLT), pages 136?143, San Francisco, CA, USA,
December.
Ond?rej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut,
and Lucia Specia. 2013. Findings of the 2013
Workshop on Statistical Machine Translation. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 1?44, Sofia, Bulgaria, August.
David Burkett and Dan Klein. 2012. Transforming
Trees to Improve Syntactic Convergence. In Proc.
of the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), Jeju Island, South Ko-
rea, July.
Jean-C?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, USA, August.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proc. of the Human Language Technology Conf. /
North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 427?436,
Montr?al, Canada, June.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 263?270, Ann Ar-
bor, MI, USA, June.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228, June.
David Chiang. 2010. Learning to Translate with
Source and Target Syntax. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 1443?1452, Uppsala, Sweden, July.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What Can Syntax-Based MT Learn
from Phrase-Based MT? In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 755?763,
Prague, Czech Republic, June.
Victoria Fossum, Kevin Knight, and Steven Abney.
2008. Using Syntax to Improve Word Alignment
Precision for Syntax-Based Machine Translation. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 44?52, Columbus, OH, USA,
June.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proc. of the Conf. on Empirical Meth-
ods for Natural Language Processing (EMNLP),
pages 847?855, Honolulu, HI, USA, October.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st International Conf. on Computa-
tional Linguistics and 44th Annual Meeting of the
Assoc. for Computational Linguistics, pages 961?
968, Sydney, Australia, July.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Columbus, OH, USA, June.
Greg Hanneman and Alon Lavie. 2009. Decoding with
Syntactic and Non-syntactic Phrases in a Syntax-
based Machine Translation System. In Proceedings
of the Third Workshop on Syntax and Structure in
Statistical Translation, SSST ?09, pages 1?9, Boul-
der, CO, USA, June.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
187?197, Edinburgh, Scotland, UK, July.
Hieu Hoang and Philipp Koehn. 2010. Improved
Translation with Source Syntax Labels. In Proc. of
the Workshop on Statistical Machine Translation
(WMT), pages 409?417, Uppsala, Sweden, July.
496
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. In Proc. of the Int. Workshop on Spoken Lan-
guage Translation (IWSLT), pages 152?159, Tokyo,
Japan, December.
Matthias Huck, David Vilar, Daniel Stein, and Her-
mann Ney. 2011. Lightly-Supervised Training for
Hierarchical Phrase-Based Machine Translation. In
Proc. of the EMNLP 2011 Workshop on Unsuper-
vised Learning in NLP, pages 91?96, Edinburgh,
Scotland, UK, July.
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-gram Language Model-
ing. In Proceedings of the International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 181?184, Detroit, MI, USA, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmon-
ton, Canada, May/June.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of the MT
Summit X, Phuket, Thailand, September.
Alon Lavie. 2008. Stat-XFER: A General
Search-Based Syntax-Driven Framework for Ma-
chine Translation. In Alexander Gelbukh, editor,
Computational Linguistics and Intelligent Text Pro-
cessing, volume 4919 of Lecture Notes in Computer
Science, pages 362?375. Springer Berlin Heidel-
berg.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string Alignment Template for Statistical Machine
Translation. In Proc. of the 21st International Conf.
on Computational Linguistics and the 44th Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 609?616, Sydney, Australia, July.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proc. of the Conf. on Empirical Methods
for Natural Language Processing (EMNLP), pages
44?52, Sydney, Australia.
Yuval Marton and Philip Resnik. 2008. Soft Syn-
tactic Constraints for Hierarchical Phrased-Based
Translation. In Proc. of the Annual Meeting of the
Assoc. for Computational Linguistics (ACL), pages
1003?1011, Columbus, OH, USA, June.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s Syntax-Based Machine Transla-
tion Systems. In Proc. of the Workshop on Statistical
Machine Translation (WMT), pages 170?176, Sofia,
Bulgaria, August.
Jan Niehues and Alex Waibel. 2012. Detailed Analy-
sis of Different Strategies for Phrase Table Adapta-
tion in SMT. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), San
Diego, CA, USA, October/November.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive Training and Maximum Entropy Models for Sta-
tistical Machine Translation. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 295?302, Philadelphia, PA, USA, July.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved Alignment Models for
Statistical Machine Translation. In Proc. of the
Joint SIGDAT Conf. on Empirical Methods in Nat-
ural Language Processing and Very Large Corpora
(EMNLP99), pages 20?28, University of Maryland,
College Park, MD, USA, June.
Franz Josef Och. 2002. Statistical Machine Transla-
tion: From Single-Word Models to Alignment Tem-
plates. Ph.D. thesis, RWTH Aachen University,
Aachen, Germany, October.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. of the
Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 311?318, Philadelphia, PA,
USA, July.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 433?440, Sydney,
Australia, July.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Holger Schwenk. 2008. Investigations on Large-Scale
Lightly-Supervised Training for Statistical Machine
Translation. In Proc. of the Int. Workshop on Spo-
ken Language Translation (IWSLT), pages 182?189,
Waikiki, HI, USA, October.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), pages
223?231, Cambridge, MA, USA, August.
497
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Proc.
of the Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), Denver, CO, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Hu-
man Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), pages 236?244, Boulder, CO, USA,
June.
David Vilar, Daniel Stein, and Hermann Ney. 2008.
Analysing Soft Syntax Features and Heuristics for
Hierarchical Phrase Based Machine Translation. In
Proc. of the Int. Workshop on Spoken Language
Translation (IWSLT), pages 190?197, Waikiki, HI,
USA, October.
Wei Wang, Kevin Knight, and Daniel Marcu. 2007.
Binarizing Syntax Trees to Improve Syntax-Based
Machine Translation Accuracy. In Proceedings
of the 2007 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 746?754, Prague, Czech Republic,
June.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, Re-labeling, and
Re-aligning for Syntax-based Machine Translation.
Computational Linguistics, 36(2):247?277, June.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 388?394, Montr?al, Canada,
June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proc. of the Workshop on Statistical
Machine Translation (WMT), Baltimore, MD, USA,
June.
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training Phrase Translation Models with
Leaving-One-Out. In Proc. of the Annual Meeting
of the Assoc. for Computational Linguistics (ACL),
pages 475?484, Uppsala, Sweden, July.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax Augmented Machine Translation via Chart Pars-
ing. In Proc. of the Workshop on Statistical Machine
Translation (WMT), pages 138?141, New York City,
NY, USA, June.
498
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 148?156,
October 25, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Preference Grammars and Soft Syntactic Constraints
for GHKM Syntax-based Statistical Machine Translation
Matthias Huck and Hieu Hoang and Philipp Koehn
School of Informatics
University of Edinburgh
10 Crichton Street
Edinburgh EH8 9AB, UK
{mhuck,hhoang,pkoehn}@inf.ed.ac.uk
Abstract
In this work, we investigate the effec-
tiveness of two techniques for a feature-
based integration of syntactic information
into GHKM string-to-tree statistical ma-
chine translation (Galley et al., 2004):
(1.) Preference grammars on the tar-
get language side promote syntactic well-
formedness during decoding while also al-
lowing for derivations that are not linguis-
tically motivated (as in hierarchical trans-
lation). (2.) Soft syntactic constraints aug-
ment the system with additional source-
side syntax features while not modifying
the set of string-to-tree translation rules or
the baseline feature scores.
We conduct experiments with a state-
of-the-art setup on an English?German
translation task. Our results suggest that
preference grammars for GHKM trans-
lation are inferior to the plain target-
syntactified model, whereas the enhance-
ment with soft source syntactic constraints
provides consistent gains. By employ-
ing soft source syntactic constraints with
sparse features, we are able to achieve im-
provements of up to 0.7 points BLEU and
1.0 points TER.
1 Introduction
Previous research in both formally syntax-based
(i.e., hierarchical) and linguistically syntax-based
statistical machine translation has demonstrated
that significant quality gains can be achieved via
integration of syntactic information as features in
a non-obtrusive manner, rather than as hard con-
straints.
We implemented two feature-based extensions
for a GHKM-style string-to-tree translation sys-
tem (Galley et al., 2004):
? Preference grammars to soften the hard
target-side syntactic constraints that are im-
posed by the target non-terminal labels.
? Soft source-side syntactic constraints that
enhance the string-to-tree translation model
with input tree features based on source syn-
tax labels.
The empirical results on an English?German
translation task are twofold. Target-side prefer-
ence grammars do not show an improvement over
the string-to-tree baseline with syntactified trans-
lation rules. Source-side syntactic constraints, on
the other hand, yield consistent moderate gains if
applied as supplementary features in the string-to-
tree setup.
2 Outline
The paper is structured as follows: First we give an
overview of important related publications (Sec-
tion 3). In Section 4, we review the fundamentals
of syntax-based translation in general, and in par-
ticular those of GHKM string-to-tree translation.
We present preference grammars for GHKM
translation in Section 5. Our technique for ap-
plying soft source syntactic constraints in GHKM
string-to-tree translation is described in Section 6.
Section 7 contains the empirical part of the pa-
per. We first describe our experimental setup (7.1),
followed by a presentation and discussion of the
translation results (7.2). We conclude the paper in
Section 8.
3 Related Work
Our syntactic translation model conforms to the
GHKM syntax approach as proposed by Galley,
Hopkins, Knight, and Marcu (Galley et al., 2004)
with composed rules as in (Galley et al., 2006)
and (DeNeefe et al., 2007). Systems based on
148
this paradigm have recently been among the top-
ranked submissions to public evaluation cam-
paigns (Williams et al., 2014; Bojar et al., 2014).
Our soft source syntactic constraints features
borrow ideas from Marton and Resnik (2008) who
proposed a comparable approach for hierarchical
machine translation. The major difference is that
the features of Marton and Resnik (2008) are only
based on the labels from the input trees as seen in
tuning and decoding. They penalize violations of
constituent boundaries but do not employ syntactic
parse annotation of the source side of the training
data. We, in contrast, equip the rules with latent
source label properties, allowing for features that
can check for conformance of input tree labels and
source labels that have been seen in training.
Other groups have applied similar techniques
to a string-to-dependency system (Huang et al.,
2013) and?like in our work?a GHKM string-
to-tree system (Zhang et al., 2011). Both Huang
et al. (2013) and Zhang et al. (2011) store source
labels as additional information with the rules.
They however investigate somewhat different fea-
ture functions than we do.
Marton and Resnik (2008) evaluated their
method on the NIST Chinese?English and
Arabic?English tasks. Huang et al. (2013) and
Zhang et al. (2011) present results on the NIST
Chinese?English task. We focus our attention on
a very different task: English?German.
4 Syntax-based Translation
In syntax-based translation, a probabilistic syn-
chronous context-free grammar (SCFG) is in-
duced from bilingual training corpora. The par-
allel training data is word-aligned and annotated
with syntactic parses on either target side (string-
to-tree), source side (tree-to-string), or both (tree-
to-tree). A syntactic rule extraction procedure ex-
tracts rules which are consistent with the word-
alignment and comply with certain syntactic va-
lidity constraints.
Extracted rules are of the form A,B???,? ,
?
?.
The right-hand side of the rule ??,? ? is a bilingual
phrase pair that may contain non-terminal sym-
bols, i.e. ? ? (V
F
? N
F
)
+
and ? ? (V
E
? N
E
)
+
,
where V
F
and V
E
denote the source and target
terminal vocabulary, and N
F
and N
E
denote the
source and target non-terminal vocabulary, respec-
tively. The non-terminals on the source side and
on the target side of rules are linked in a one-to-
one correspondence. The
?
relation defines this
one-to-one correspondence. The left-hand side
of the rule is a pair of source and target non-
terminals, A ? N
F
and B ? N
E
.
Decoding is typically carried out with a parsing-
based algorithm, in our case a customized version
of CYK
+
(Chappelier and Rajman, 1998). The
parsing algorithm is extended to handle transla-
tion candidates and to incorporate language model
scores via cube pruning (Chiang, 2007).
4.1 GHKM String-to-Tree Translation
In GHKM string-to-tree translation (Galley et al.,
2004; Galley et al., 2006; DeNeefe et al., 2007),
rules are extracted from training instances which
consist of a source sentence, a target sentence
along with its constituent parse tree, and a word
alignment matrix. This tuple is interpreted as a
directed graph (the alignment graph), with edges
pointing away from the root of the tree, and word
alignment links being edges as well. A set of
nodes (the frontier set) is determined that con-
tains only nodes with non-overlapping closure of
their spans.
1
By computing frontier graph frag-
ments?fragments of the alignment graph such
that their root and all sinks are in the frontier set?
the GHKM extractor is able to induce a minimal
set of rules which explain the training instance.
The internal tree structure can be discarded to ob-
tain flat SCFG rules. Minimal rules can be assem-
bled to build larger composed rules.
Non-terminals on target sides of string-to-tree
rules are syntactified. The target non-terminal vo-
cabulary of the SCFG contains the set of labels of
the frontier nodes, which is in turn a subset of (or
equal to) the set of constituent labels in the parse
tree. The target non-terminal vocabulary further-
more contains an initial non-terminal symbol Q.
Source sides of the rules are not decorated with
syntactic annotation. The source non-terminal vo-
cabulary contains a single generic non-terminal
symbol X.
In addition to the extracted grammar, the trans-
lation system makes use of a special glue grammar
with an initial rule, glue rules, a final rule, and top
rules. The glue rules provide a fall back method
to just monotonically concatenate partial deriva-
tions during decoding. As we add tokens which
1
The span of a node in the alignment graph is defined
as the set of source-side words that are reachable from this
node. The closure of a span is the smallest interval of source
sentence positions that covers the span.
149
mark the sentence start (?<s>?) and the sentence
end (?</s>?), the rules in the glue grammar are of
the following form:
Initial rule:
X,Q? ?<s> X
?0
,<s> Q
?0
?
Glue rules:
X,Q? ?X
?0
X
?1
,Q
?0
B
?1
?
for all B ? N
E
Final rule:
X,Q? ?X
?0
</s>,Q
?0
</s>?
Top rules:
X,Q? ?<s> X
?0
</s>,<s> B
?0
</s>?
for all B ? N
E
5 Preference Grammars
Preference grammars store a set of implicit label
vectors as additional information with each SCFG
rule, along with their relative frequencies given
the rule. Venugopal et al. (2009) have introduced
this technique for hierarchical phrase-based trans-
lation. The implicit label set refines the label set
of the underlying synchronous context-free gram-
mar.
We apply this idea to GHKM translation by
not decorating the target-side non-terminals of the
extracted GHKM rules with syntactic labels, but
with a single generic label. The (explicit) tar-
get non-terminal vocabulary N
E
thus also con-
tains only the generic non-terminal symbol X, just
like the source non-terminal vocabulary N
F
. The
extraction method remains syntax-directed and is
still guided by the syntactic annotation over the
target side of the data, but the syntactic labels are
stripped off from the SCFG rules. Rules which
differ only with respect to their non-terminal la-
bels are collapsed to a single entry in the rule ta-
ble, and their rule counts are pooled. However,
the syntactic label vectors that have been seen with
this rule during extraction are stored as implicit la-
bel vectors of the rule.
5.1 Feature Computation
Two features are added to the log-linear model
combination in order to rate the syntactic well-
formedness of derivations. The first feature is
similar to the one suggested by Venugopal et al.
(2009) and computes a score based on the relative
frequencies of implicit label vectors of those rules
which are involved in the derivation. The second
feature is a simple binary feature which supple-
ments the first one by penalizing a rule application
if none of the implicit label vectors match.
We will now formally specify the first feature.
2
We give a recursive definition of the feature score
h
syn
(d) for a derivation d.
Let r be the top rule in derivation d, with n
right-hand side non-terminals. Let d
j
denote the
sub-derivation of d at the j-th right-hand side non-
terminal of r, 1 ? j ? n. h
syn
(d) is recursively
defined as
h
syn
(d) =
?
t
syn
(d)+
n
?
j=1
h
syn
(d
j
) . (1)
In this equation,
?
t
syn
(d) is a simple auxiliary
function:
?
t
syn
(d) =
{
log t
syn
(d) if t
syn
(d) 6= 0
0 otherwise
(2)
Denoting with S the implicit label set of the
preference grammar, we define t
syn
(d) as a func-
tion that assesses the degree of agreement of
the preferences of the current rule with the sub-
derivations:
t
syn
(d) =
?
s?S
n+1
(
p(s|r) ?
n+1
?
k=2
?
t
h
(s[k]|d
k?1
)
)
(3)
We use the notation [?] to address the elements of a
vector. The first element of an n+ 1-dimensional
vector s of implicit labels is an implicit label bind-
ing of the left-hand side non-terminal of the rule r.
p(s|r) is the preference distribution of the rule.
Here,
?
t
h
(Y |d) is another auxiliary function that
renormalizes the values of t
h
(Y |d):
?
t
h
(Y |d) =
t
h
(Y |d)
?
Y
?
?S
t
h
(Y
?
|d)
(4)
It provides us with a probability that the derivation
d has the implicit label Y ? S as its root. Finally,
the function t
h
(Y |d) is defined as
t
h
(Y |d) =
?
s?S
n+1
:s[1]=Y
(
p(s|r) ?
n+1
?
k=2
p
h
(s[k]|d
k?1
)
)
.
(5)
Note that the denominator in Equation (4) thus
equals t
syn
(d).
2
Our notational conventions roughly follow the ones by
Stein et al. (2010).
150
This concludes the formal specification of the
first features. The second feature h
auxSyn
(d) penal-
izes rule applications in cases where t
syn
(d) evalu-
ates to 0:
h
auxSyn
(d) =
{
0 if t
syn
(d) 6= 0
1 otherwise
(6)
Its intuition is that rule applications that do not
contribute to h
syn
(d) should be punished. Deriva-
tions with t
syn
(d) = 0 could alternatively be
dropped completely, but our approach is to avoid
hard constraints. We will later demonstrate empir-
ically that discarding such derivations harms trans-
lation quality.
6 Soft Source Syntactic Constraints
Similar to the implicit target-side label vectors
which we store in preference grammars, we can
likewise memorize sets of source-side syntactic la-
bel vectors with GHKM rules. In contrast to pref-
erence grammars, the rule inventory of the string-
to-tree system remains untouched. The target non-
terminals of the SCFG stay syntactified, and the
source non-terminal vocabulary is not extended
beyond the single generic non-terminal.
Source-side syntactic labels are an additional la-
tent property of the rules. We obtain this property
by parsing the source side of the training data and
collecting the source labels that cover the source-
side span of non-terminals during GHKM rule ex-
traction. As the source-side span is frequently not
covered by a constituent in the syntactic parse tree,
we employ the composite symbols as suggested
by Zollmann and Venugopal (2006) for the SAMT
system.
3
In cases where a span is still not covered
by a symbol, we nevertheless memorize a source-
side syntactic label vector but indicate the failure
for the uncovered non-terminal with a special la-
bel. The set of source label vectors that are seen
with a rule during extraction is stored with it in the
rule table as an additional property. This informa-
tion can be used to implement feature-based soft
source syntactic constraints.
Table 1 shows an example of a set of source
label vectors stored with a grammar rule. The
first element of each vector is an implicit source-
syntactic label for the left-hand side non-terminal
of the rule, the remaining elements are implicit
3
Specifically, we apply relax-parse --SAMT 2 as
implemented in the Moses toolkit (Koehn et al., 2007).
source label vector frequency
(IN+NP,NN,NN) 7
(IN+NP,NNP,NNP) 3
(IN++NP,NNS,NNS) 2
(IN+NP,NP,NP) 2
(PP//SBAR,NP,NP) 1
Table 1: The set of source label vec-
tors (along with their frequencies in the
training data) for the rule X,PP-MO ?
?between X
?1
and X
?0
,zwischen NN
?0
und NN
?1
?.
The overall rule frequency is 15.
source-syntactic labels for the right-hand side
source non-terminals.
The basic idea for soft source syntactic con-
straints features is to also parse the input data in
a preprocessing step and try to match input labels
and source label vectors that are associated with
SCFG rules.
6.1 Feature Computation
Upon application of an SCFG rule, each of the
non-terminals of the rule covers a distinct span of
the input sentence. An input label from the input
parse may be available for this span. We say that
a non-terminal has a match in a given source la-
bel vector of the rule if its label in the vector is the
same as a corresponding input label over the span.
We define three simple features to score
matches and mismatches of the impicit source syn-
tactic labels with the labels from the input data:
? A binary feature that fires if a rule is applied
which possesses a source syntactic label vec-
tor that fully matches the input labels. This
feature rewards exact source label matches of
complete rules, i.e., the existance of a vector
in which all non-terminals of the rule have
matches.
? A binary feature that fires if a rule is applied
which does not possess any source syntactic
label vector with a match of the label for the
left-hand side non-terminal. This feature pe-
nalizes left-hand side mismatches.
? A count feature that for each rule application
adds a cost equal to the number of right-hand
side non-terminals that do not have a match
with a corresponding input label in any of the
source syntactic label vectors. This feature
penalizes right-hand side mismatches.
151
The second and third feature are less strict than the
first one and give the system a more detailed clue
about the magnitude of mismatch.
6.2 Sparse Features
We can optionally add a larger number of sparse
features that depend on the identity of the source-
side syntactic label:
? Sparse features which fire if a specific input
label is matched. We say that the input la-
bel is matched in case the corresponding non-
terminal that covers the span has a match in
any of the source syntactic label vectors of
the applied rule. We distinguish input label
matches via left-hand side and via right-hand
side non-terminals.
? Sparse features which fire if the span of a spe-
cific input label is covered by a non-terminal
of an applied rule, but the input label is not
matched.
The first set of sparse features rewards matches,
the second set of sparse features penalizes mis-
matches.
All sparse features have individual scaling fac-
tors in the log-linear model combination. We how-
ever implemented a means of restricting the num-
ber of sparse features by providing a core set of
source labels. If such a core set is specified, then
only those sparse features are active that depend
on the identity of labels within this set. All sparse
features for source labels outside of the core set
are inactive.
7 Experiments
We empirically evaluate the effectiveness of
preference grammars and soft source syntac-
tic constraints for GHKM translation on the
English?German language pair using the stan-
dard newstest sets of the Workshop on Statisti-
cal Machine Translation (WMT) for testing.
4
The
experiments are conducted with the open-source
Moses implementations of GHKM rule extraction
(Williams and Koehn, 2012) and decoding with
CYK
+
parsing and cube pruning (Hoang et al.,
2009).
4
http://www.statmt.org/wmt14/
translation-task.html
7.1 Experimental Setup
We work with an English?German parallel train-
ing corpus of around 4.5 M sentence pairs (af-
ter corpus cleaning). The parallel data origi-
nates from three different sources which have
been eligible for the constrained track of the
ACL 2014 Ninth Workshop on Statistical Ma-
chine Translation shared translation task: Europarl
(Koehn, 2005), News Commentary, and the Com-
mon Crawl corpus as provided on the WMT web-
site. Word alignments are created by aligning the
data in both directions with MGIZA
++
(Gao and
Vogel, 2008) and symmetrizing the two trained
alignments (Och and Ney, 2003; Koehn et al.,
2003). The German target side training data is
parsed with BitPar (Schmid, 2004). We remove
grammatical case and function information from
the annotation obtained with BitPar and apply
right binarization of the German parse trees prior
to rule extraction (Wang et al., 2007; Wang et al.,
2010; Nadejde et al., 2013). For the soft source
syntactic constraints, we parse the English source
side of the parallel data with the English Berkeley
Parser (Petrov et al., 2006) and produce composite
SAMT-style labels as discussed in Section 6.
When extracting syntactic rules, we impose sev-
eral restrictions for composed rules, in particular
a maximum number of 100 tree nodes per rule,
a maximum depth of seven, and a maximum size
of seven. We discard rules with non-terminals on
their right-hand side if they are singletons in the
training data.
For efficiency reasons, we also enforce a limit
on the number of label vectors that are stored
as additional properties. Label vectors are only
stored if they occur at least as often as the 50th
most frequent label vector of the given rule. This
limit is applied separately for both source-side la-
bel vectors (which are used by the soft syntactic
contraints) and target-side label vectors (which are
used by the preference grammar).
Only the 200 best translation options per dis-
tinct rule source side with respect to the weighted
rule-level model scores are loaded by the decoder.
Search is carried out with a maximum chart span
of 25, a rule limit of 500, a stack limit of 200, and
a k-best limit of 1000 for cube pruning.
A standard set of models is used in the base-
line, comprising rule translation probabilities and
lexical translation probabilities in both directions,
word penalty and rule penalty, an n-gram language
152
system dev newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
GHKM string-to-tree baseline 34.7 47.3 20.0 63.3 19.4 65.6
+ soft source syntactic constraints 35.1 47.0 20.3 62.7 19.7 64.9
+ sparse features 35.8 46.5 20.3 62.8 19.6 65.1
+ sparse features (core = non-composite) 35.4 46.8 20.2 62.9 19.6 65.1
+ sparse features (core = dev-min-occ100) 35.6 46.7 20.2 62.9 19.6 65.2
+ sparse features (core = dev-min-occ1000) 35.4 46.9 20.3 62.8 19.6 65.2
+ hard source syntactic constraints 34.6 47.4 19.9 63.4 19.4 65.6
string-to-string (GHKM syntax-directed rule extraction) 33.8 48.0 19.3 63.8 18.7 66.2
+ preference grammar 33.9 47.7 19.3 63.7 18.8 66.0
+ soft source syntactic constraints 34.6 47.0 19.8 62.9 19.5 65.2
+ drop derivations with t
syn
(d) = 0 34.0 47.5 19.7 63.0 18.8 65.8
Table 2: English?German experimental results (truecase). BLEU scores are given in percentage.
A selection of 2000 sentences from the newstest2008-2012 sets is used as development set.
model, a rule rareness penalty, and the monolin-
gual PCFG probability of the tree fragment from
which the rule was extracted (Williams et al.,
2014). Rule translation probabilities are smoothed
via Good-Turing smoothing.
The language model (LM) is a large inter-
polated 5-gram LM with modified Kneser-Ney
smoothing (Kneser and Ney, 1995; Chen and
Goodman, 1998). The target side of the parallel
corpus and the monolingual German News Crawl
corpora are employed as training data. We use
the SRILM toolkit (Stolcke, 2002) to train the LM
and rely on KenLM (Heafield, 2011) for language
model scoring during decoding.
Model weights are optimized to maximize
BLEU (Papineni et al., 2002) with batch MIRA
(Cherry and Foster, 2012) on 1000-best lists. We
selected 2000 sentences from the newstest2008-
2012 sets as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and do each contain less than
30 words for more rapid tuning. newstest2013 and
newstest2014 are used as unseen test sets. Trans-
lation quality is measured in truecase with BLEU
and TER (Snover et al., 2006).
5
7.2 Translation Results
The results of the empirical evaluation are given in
Table 2. Our GHKM string-to-tree system attains
state-of-the-art performance on newstest2013 and
newstest2014.
5
TER scores are computed with tercom version 0.7.25
and parameters -N -s.
7.2.1 Soft Source Syntactic Constraints
Adding the three dense soft source syntactic con-
straints features from Section 6.1 improves the
baseline scores by 0.3 points BLEU and 0.6 points
TER on newstest2013 and by 0.3 points BLEU and
0.7 points TER on newstest2014.
Somewhat surprisingly, the sparse features from
Section 6.2 do not boost translation quality further
on any of the two test sets. We observe a consid-
erable improvement on the development set, but it
does not carry over to the test sets. We attributed
this to an overfitting effect. Our source-side soft
syntactic label set of composite SAMT-style la-
bels comprises 8504 different labels that appear on
the source-side of the parallel training data. Four
times the amount of sparse features are possible
(left-hand side/right-hand side matches and mis-
matches for each label), though not all of them fire
on the development set. 3989 sparse weights are
tuned to non-zero values in the experiment. Due to
the sparse nature of the features, overfitting cannot
be ruled out.
We attempted to take measures in order to avoid
overfitting by specifying a core set of source la-
bels and deactivating all sparse features for source
labels outside of the core set (cf. Section 6.2).
First we specified the core label set as all non-
composite labels. Non-composite labels are the
plain constituent labels as given by the syntactic
parser. Complex SAMT-style labels are not in-
cluded. The size of this set is 71 (non-composite
labels that have been observed during rule extrac-
tion). Translation performance on the develop-
ment set drops in the sparse features (core = non-
153
system (tuned on newstest2012) newstest2012 newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
GHKM string-to-tree baseline 17.9 65.7 19.9 63.2 19.4 65.3
+ soft source syntactic constraints 18.2 65.3 20.3 62.6 19.7 64.7
+ sparse features 18.6 64.9 20.4 62.5 19.8 64.7
+ sparse features (core = non-composite) 18.4 65.1 20.3 62.7 19.8 64.7
+ sparse features (core = dev-min-occ100) 18.4 64.8 20.6 62.2 19.9 64.4
Table 3: English?German experimental results (truecase). BLEU scores are given in percentage.
newstest2012 is used as development set.
composite) setup, but performance does not in-
crease on the test sets.
Next we specified the core label set in another
way: We counted how often each source label oc-
curs in the input data on the development set. We
then applied a minimum occurrence count thresh-
old and added labels to the core set if they did not
appear more rarely than the threshold. We tried
values of 100 and 1000 for the minimum occur-
rence, resulting in 277 and 37 labels being in the
core label set, respectively. Neither the sparse fea-
tures (core = dev-min-occ100) experiment nor the
sparse features (core = dev-min-occ1000) experi-
ment yields better translation quality than what we
see in the setup without sparse features.
We eventually conjectured that the choice of our
development set might be a reason for the ineffec-
tiveness of the sparse features, as on a fine-grained
level it could possibly be too different from the
test sets with respect to its syntactic properties.
We therefore repeated some of the experiments
with scaling factors optimized on newstest2012
(Table 3). The sparse features (core = dev-min-
occ100) setup indeed performs better when tuned
on newstest2012, with improvements of 0.7 points
BLEU and 1.0 points TER on newstest2013 and
of 0.5 points BLEU and 0.9 points TER on news-
test2014 over the baseline tuned on the same set.
Finally, we were interested in demonstrating
that soft source syntactic constraints are superior
to hard source syntactic constraints. We built a
setup that forces the decoder to match source-side
syntactic label vectors in the rules with input la-
bels.
6
Hard source syntactic constraints are in-
deed worse than soft source syntactic constraints
(by 0.4 BLEU on newstest2013 and 0.3 BLEU on
newstest2014). The setup with hard source syntac-
tic constraints performs almost exactly at the level
of the baseline.
6
Glue rules are an exception. They do not need to match
the input labels.
7.2.2 Preference Grammar
In the series of experiments with a preference
grammar, we first evaluated a setup with the un-
derlying SCFG of the preference grammar sys-
tem, but without preference grammar. We de-
note this setup as string-to-string (GHKM syntax-
directed rule extraction) in Table 2. The ex-
traction method for this string-to-string system is
GHKM syntax-directed with right-binarized syn-
tactic target-side parses from BitPar, as in the
string-to-tree setup. The constituent labels from
the syntactic parses are however not used to dec-
orate non-terminals. The grammar contains rules
with a single generic non-terminal instead of syn-
tactic ones. The string-to-string (GHKM syntax-
directed rule extraction) setup is on newstest2013
0.7 BLEU (0.5 TER) worse and on newstest2014
0.7 BLEU (0.6 TER) worse than the standard
GHKM string-to-tree baseline.
We then activated the preference grammar as
described in Section 5. GHKM translation with a
preference grammar instead of a syntactified target
non-terminal vocabulary in the SCFG is consider-
ably worse than the standard GHKM string-to-tree
baseline and barely improves over the string-to-
string setup.
We added soft source syntactic constraints on
top of the preference grammar system, thus com-
bining the two techniques. Soft source syntactic
constraints give a nice gain over the preference
grammar system, but the best setup without a pref-
erence grammar is not outperformed. In another
experiment, we investigated the effect of dropping
derivations with t
syn
(d) = 0 (cf. Section 5.1). Note
that the second feature h
auxSyn
(d) is not useful in
this setup, as the system is forced to discard all
derivations that would be penalized by that fea-
ture. We deactivated h
auxSyn
(d) for the experi-
ment. The hard decision of dropping derivations
with t
syn
(d) = 0 leads to a performance loss of
154
0.1 BLEU on newstest2013 and a more severe de-
terioration of 0.7 BLEU on newstest2014.
8 Conclusions
We investigated two soft syntactic extensions for
GHKM translation: Target-side preference gram-
mars and soft source syntactic constraints.
Soft source syntactic constraints proved to be
suitable for advancing the translation quality over
a strong string-to-tree baseline. Sparse features
are beneficial beyond just three dense features, but
they require the utilization of an appropriate devel-
opment set. We also showed that the soft integra-
tion of source syntactic constraints is crucial: Hard
constraints do not yield gains over the baseline.
Preference grammars did not perform well in
our experiments, suggesting that translation mod-
els with syntactic target non-terminal vocabular-
ies are a better choice when building string-to-tree
systems.
Acknowledgements
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreements n
o
287658 (EU-BRIDGE)
and n
o
288487 (MosesCore).
References
Ondrej Bojar, Christian Buck, Christian Federmann,
Barry Haddow, Philipp Koehn, Johannes Leveling,
Christof Monz, Pavel Pecina, Matt Post, Herve
Saint-Amand, Radu Soricut, Lucia Specia, and Ale?
Tamchyna. 2014. Findings of the 2014 Work-
shop on Statistical Machine Translation. In Proc. of
the Workshop on Statistical Machine Translation
(WMT), pages 12?58, Baltimore, MD, USA, June.
Jean-C?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, USA, August.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proc. of the Human Language Technology Conf. /
North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 427?436,
Montr?al, Canada, June.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228, June.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What Can Syntax-Based MT Learn
from Phrase-Based MT? In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 755?763,
Prague, Czech Republic, June.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st Int. Conf. on Computational Lin-
guistics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 961?968, Sydney,
Australia, July.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Columbus, OH, USA, June.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
187?197, Edinburgh, Scotland, UK, July.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. In Proc. of the Int. Workshop on Spoken Lan-
guage Translation (IWSLT), pages 152?159, Tokyo,
Japan, December.
Zhongqiang Huang, Jacob Devlin, and Rabih Zbib.
2013. Factored Soft Source Syntactic Constraints
for Hierarchical Machine Translation. In Proc. of
the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), pages 556?566, Seat-
tle, WA, USA, October.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In
Proceedings of the Int. Conf. on Acoustics, Speech,
and Signal Processing, volume 1, pages 181?184,
Detroit, MI, USA, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmon-
ton, Canada, May/June.
155
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 177?180, Prague,
Czech Republic, June.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of the MT
Summit X, Phuket, Thailand, September.
Yuval Marton and Philip Resnik. 2008. Soft Syn-
tactic Constraints for Hierarchical Phrased-Based
Translation. In Proc. of the Annual Meeting of the
Assoc. for Computational Linguistics (ACL), pages
1003?1011, Columbus, OH, USA, June.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s Syntax-Based Machine Transla-
tion Systems. In Proc. of the Workshop on Statistical
Machine Translation (WMT), pages 170?176, Sofia,
Bulgaria, August.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. of the
Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 311?318, Philadelphia, PA,
USA, July.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st Int.
Conf. on Computational Linguistics and 44th An-
nual Meeting of the Assoc. for Computational Lin-
guistics, pages 433?440, Sydney, Australia, July.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), pages
223?231, Cambridge, MA, USA, August.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Proc.
of the Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), Denver, CO, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Hu-
man Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), pages 236?244, Boulder, CO, USA,
June.
Wei Wang, Kevin Knight, and Daniel Marcu. 2007.
Binarizing Syntax Trees to Improve Syntax-Based
Machine Translation Accuracy. In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 746?754,
Prague, Czech Republic, June.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, Re-labeling, and
Re-aligning for Syntax-based Machine Translation.
Computational Linguistics, 36(2):247?277, June.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 388?394, Montr?al, Canada,
June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proc. of the Workshop on Statis-
tical Machine Translation (WMT), pages 207?214,
Baltimore, MD, USA, June.
Jiajun Zhang, Feifei Zhai, and Chengqing Zong. 2011.
Augmenting String-to-Tree Translation Models with
Fuzzy Use of Source-side Syntax. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 204?215, Edinburgh,
Scotland, UK, July.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax Augmented Machine Translation via Chart Pars-
ing. In Proc. of the Workshop on Statistical Machine
Translation (WMT), pages 138?141, New York City,
NY, USA, June.
156
