Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1?11,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
On Dual Decomposition and Linear Programming Relaxations
for Natural Language Processing
Alexander M. Rush David Sontag Michael Collins Tommi Jaakkola
MIT CSAIL, Cambridge, MA 02139, USA
{srush,dsontag,mcollins,tommi}@csail.mit.edu
Abstract
This paper introduces dual decomposition as a
framework for deriving inference algorithms
for NLP problems. The approach relies on
standard dynamic-programming algorithms as
oracle solvers for sub-problems, together with
a simple method for forcing agreement be-
tween the different oracles. The approach
provably solves a linear programming (LP) re-
laxation of the global inference problem. It
leads to algorithms that are simple, in that they
use existing decoding algorithms; efficient, in
that they avoid exact algorithms for the full
model; and often exact, in that empirically
they often recover the correct solution in spite
of using an LP relaxation. We give experimen-
tal results on two problems: 1) the combina-
tion of two lexicalized parsing models; and
2) the combination of a lexicalized parsing
model and a trigram part-of-speech tagger.
1 Introduction
Dynamic programming algorithms have been re-
markably useful for inference in many NLP prob-
lems. Unfortunately, as models become more com-
plex, for example through the addition of new fea-
tures or components, dynamic programming algo-
rithms can quickly explode in terms of computa-
tional or implementational complexity.1 As a re-
sult, efficiency of inference is a critical bottleneck
for many problems in statistical NLP.
This paper introduces dual decomposition
(Dantzig and Wolfe, 1960; Komodakis et al, 2007)
as a framework for deriving inference algorithms in
NLP. Dual decomposition leverages the observation
that complex inference problems can often be
decomposed into efficiently solvable sub-problems.
The approach leads to inference algorithms with the
following properties:
1The same is true for NLP inference algorithms based on
other exact combinatorial methods, for example methods based
on minimum-weight spanning trees (McDonald et al, 2005), or
graph cuts (Pang and Lee, 2004).
? The resulting algorithms are simple and efficient,
building on standard dynamic-programming algo-
rithms as oracle solvers for sub-problems,2 to-
gether with a method for forcing agreement be-
tween the oracles.
? The algorithms provably solve a linear program-
ming (LP) relaxation of the original inference
problem.
? Empirically, the LP relaxation often leads to an
exact solution to the original problem.
The approach is very general, and should be appli-
cable to a wide range of problems in NLP. The con-
nection to linear programming ensures that the algo-
rithms provide a certificate of optimality when they
recover the exact solution, and also opens up the
possibility of methods that incrementally tighten the
LP relaxation until it is exact (Sherali and Adams,
1994; Sontag et al, 2008).
The structure of this paper is as follows. We
first give two examples as an illustration of the ap-
proach: 1) integrated parsing and trigram part-of-
speech (POS) tagging; and 2) combined phrase-
structure and dependency parsing. In both settings,
it is possible to solve the integrated problem through
an ?intersected? dynamic program (e.g., for integra-
tion of parsing and tagging, the construction from
Bar-Hillel et al (1964) can be used). However,
these methods, although polynomial time, are sub-
stantially less efficient than our algorithms, and are
considerably more complex to implement.
Next, we describe exact polyhedral formula-
tions for the two problems, building on connec-
tions between dynamic programming algorithms
and marginal polytopes, as described in Martin et al
(1990). These allow us to precisely characterize the
relationship between the exact formulations and the
2More generally, other exact inference methods can be
used as oracles, for example spanning tree algorithms for non-
projective dependency structures.
1
LP relaxations that we solve. We then give guaran-
tees of convergence for our algorithms by showing
that they are instantiations of Lagrangian relaxation,
a general method for solving linear programs of a
particular form.
Finally, we describe experiments that demonstrate
the effectiveness of our approach. First, we con-
sider the integration of the generative model for
phrase-structure parsing of Collins (2003), with the
second-order discriminative dependency parser of
Koo et al (2008). This is an interesting problem
in its own right: the goal is to inject the high per-
formance of discriminative dependency models into
phrase-structure parsing. The method uses off-the-
shelf decoders for the two models. We find three
main results: 1) in spite of solving an LP relax-
ation, empirically the method finds an exact solution
on over 99% of the examples; 2) the method con-
verges quickly, typically requiring fewer than 10 it-
erations of decoding; 3) the method gives gains over
a baseline method that forces the phrase-structure
parser to produce the same dependencies as the first-
best output from the dependency parser (the Collins
(2003) model has an F1 score of 88.1%; the base-
line method has an F1 score of 89.7%; and the dual
decomposition method has an F1 score of 90.7%).
In a second set of experiments, we use dual de-
composition to integrate the trigram POS tagger of
Toutanova and Manning (2000) with the parser of
Collins (2003). We again find that the method finds
an exact solution in almost all cases, with conver-
gence in just a few iterations of decoding.
Although the focus of this paper is on dynamic
programming algorithms?both in the experiments,
and also in the formal results concerning marginal
polytopes?it is straightforward to use other com-
binatorial algorithms within the approach. For ex-
ample, Koo et al (2010) describe a dual decompo-
sition approach for non-projective dependency pars-
ing, which makes use of both dynamic programming
and spanning tree inference algorithms.
2 Related Work
Dual decomposition is a classical method for solv-
ing optimization problems that can be decomposed
into efficiently solvable sub-problems. Our work is
inspired by dual decomposition methods for infer-
ence in Markov random fields (MRFs) (Wainwright
et al, 2005a; Komodakis et al, 2007; Globerson and
Jaakkola, 2007). In this approach, the MRF is de-
composed into sub-problems corresponding to tree-
structured subgraphs that together cover all edges
of the original graph. The resulting inference algo-
rithms provably solve an LP relaxation of the MRF
inference problem, often significantly faster than
commercial LP solvers (Yanover et al, 2006).
Our work is also related to methods that incorpo-
rate combinatorial solvers within loopy belief prop-
agation (LBP), either for MAP inference (Duchi et
al., 2007) or for computing marginals (Smith and
Eisner, 2008). Our approach similarly makes use
of combinatorial algorithms to efficiently solve sub-
problems of the global inference problem. However,
unlike LBP, our algorithms have strong theoretical
guarantees, such as guaranteed convergence and the
possibility of a certificate of optimality. These guar-
antees are possible because our algorithms directly
solve an LP relaxation.
Other work has considered LP or integer lin-
ear programming (ILP) formulations of inference in
NLP (Martins et al, 2009; Riedel and Clarke, 2006;
Roth and Yih, 2005). These approaches typically
use general-purpose LP or ILP solvers. Our method
has the advantage that it leverages underlying struc-
ture arising in LP formulations of NLP problems.
We will see that dynamic programming algorithms
such as CKY can be considered to be very effi-
cient solvers for particular LPs. In dual decomposi-
tion, these LPs?and their efficient solvers?can be
embedded within larger LPs corresponding to more
complex inference problems.
3 Background: Structured Models for NLP
We now describe the type of models used throughout
the paper. We take some care to set up notation that
will allow us to make a clear connection between
inference problems and linear programming.
Our first example is weighted CFG parsing. We
assume a context-free grammar, in Chomsky normal
form, with a set of non-terminals N . The grammar
contains all rules of the form A ? B C and A ?
w where A,B,C ? N and w ? V (it is simple
to relax this assumption to give a more constrained
grammar). For rules of the form A ? w we refer
to A as the part-of-speech tag for w. We allow any
non-terminal to be at the root of the tree.
2
Given a sentence with n words, w1, w2, . . . wn, a
parse tree is a set of rule productions of the form
?A ? B C, i, k, j? where A,B,C ? N , and
1 ? i ? k < j ? n. Each rule production rep-
resents the use of CFG rule A ? B C where non-
terminal A spans words wi . . . wj , non-terminal B
spans words wi . . . wk, and non-terminal C spans
words wk+1 . . . wj . There are O(|N |3n3) such rule
productions. Each parse tree corresponds to a subset
of these rule productions, of size n? 1, that forms a
well-formed parse tree.3
We now define the index set for CFG parsing as
I = {?A? B C, i, k, j?: A,B,C ? N ,
1 ? i ? k < j ? n}
Each parse tree is a vector y = {yr : r ? I},
with yr = 1 if rule r is in the parse tree, and yr =
0 otherwise. Hence each parse tree is represented
as a vector in {0, 1}m, where m = |I|. We use Y
to denote the set of all valid parse-tree vectors; the
set Y is a subset of {0, 1}m (not all binary vectors
correspond to valid parse trees).
In addition, we assume a vector ? = {?r : r ?
I} that specifies a weight for each rule production.4
Each ?r can take any value in the reals. The optimal
parse tree is y? = arg maxy?Y y ? ? where y ? ? =?
r yr?r is the inner product between y and ?.
We use yr and y(r) interchangeably (similarly for
?r and ?(r)) to refer to the r?th component of the
vector y. For example ?(A ? B C, i, k, j) is a
weight for the rule ?A? B C, i, k, j?.
We will use similar notation for other problems.
As a second example, in POS tagging the task is to
map a sentence of n words w1 . . . wn to a tag se-
quence t1 . . . tn, where each ti is chosen from a set
T of possible tags. We assume a trigram tagger,
where a tag sequence is represented through deci-
sions ?(A,B) ? C, i? where A,B,C ? T , and
i ? {3 . . . n}. Each production represents a tran-
sition where C is the tag of word wi, and (A,B) are
3We do not require rules of the form A ? wi in this repre-
sentation, as they are redundant: specifically, a rule production
?A ? B C, i, k, j? implies a rule B ? wi iff i = k, and
C ? wj iff j = k + 1.
4We do not require parameters for rules of the formA? w,
as they can be folded into rule production parameters. E.g.,
under a PCFG we define ?(A ? B C, i, k, j) = logP (A ?
B C | A) + ?i,k logP (B ? wi|B) + ?k+1,j logP (C ?
wj |C) where ?x,y = 1 if x = y, 0 otherwise.
the previous two tags. The index set for tagging is
Itag = {?(A,B)? C, i? : A,B,C ? T , 3 ? i ? n}
Note that we do not need transitions for i = 1 or i =
2, because the transition ?(A,B) ? C, 3? specifies
the first three tags in the sentence.5
Each tag sequence is represented as a vector z =
{zr : r ? Itag}, and we denote the set of valid tag
sequences, a subset of {0, 1}|Itag|, as Z . Given a
parameter vector ? = {?r : r ? Itag}, the optimal
tag sequence is arg maxz?Z z ? ?.
As a modification to the above approach, we will
find it convenient to introduce extended index sets
for both the CFG and POS tagging examples. For
the CFG case we define the extended index set to be
I ? = I ? Iuni where
Iuni = {(i, t) : i ? {1 . . . n}, t ? T}
Here each pair (i, t) represents word wi being as-
signed the tag t. Thus each parse-tree vector y will
have additional (binary) components y(i, t) spec-
ifying whether or not word i is assigned tag t.
(Throughout this paper we will assume that the tag-
set used by the tagger, T , is a subset of the set of non-
terminals considered by the parser, N .) Note that
this representation is over-complete, since a parse
tree determines a unique tagging for a sentence:
more explicitly, for any i ? {1 . . . n}, Y ? T , the
following linear constraint holds:
y(i, Y ) =
n?
k=i+1
?
X,Z?N
y(X ? Y Z, i, i, k) +
i?1?
k=1
?
X,Z?N
y(X ? Z Y, k, i? 1, i)
We apply the same extension to the tagging index
set, effectively mapping trigrams down to unigram
assignments, again giving an over-complete repre-
sentation. The extended index set for tagging is re-
ferred to as I ?tag.
From here on we will make exclusive use of ex-
tended index sets for CFG parsing and trigram tag-
ging. We use the set Y to refer to the set of valid
parse structures under the extended representation;
5As one example, in an HMM, the parameter ?((A,B) ?
C, 3) would be logP (A|??)+logP (B|?A)+logP (C|AB)+
logP (w1|A) + logP (w2|B) + logP (w3|C), where ? is the
start symbol.
3
each y ? Y is a binary vector of length |I ?|. We
similarly use Z to refer to the set of valid tag struc-
tures under the extended representation. We assume
parameter vectors for the two problems, ?cfg ? R|I
?|
and ?tag ? R|I
?
tag|.
4 Two Examples
This section describes the dual decomposition ap-
proach for two inference problems in NLP.
4.1 Integrated Parsing and Trigram Tagging
We now describe the dual decomposition approach
for integrated parsing and trigram tagging. First, de-
fine the set Q as follows:
Q = {(y, z) : y ? Y, z ? Z,
y(i, t) = z(i, t) for all (i, t) ? Iuni} (1)
Hence Q is the set of all (y, z) pairs that agree
on their part-of-speech assignments. The integrated
parsing and trigram tagging problem is then to solve
max
(y,z)?Q
(
y ? ?cfg + z ? ?tag
)
(2)
This problem is equivalent to
max
y?Y
(
y ? ?cfg + g(y) ? ?tag
)
where g : Y ? Z is a function that maps a parse
tree y to its set of trigrams z = g(y). The benefit of
the formulation in Eq. 2 is that it makes explicit the
idea of maximizing over all pairs (y, z) under a set
of agreement constraints y(i, t) = z(i, t)?this con-
cept will be central to the algorithms in this paper.
With this in mind, we note that we have effi-
cient methods for the inference problems of tagging
and parsing alone, and that our combined objective
almost separates into these two independent prob-
lems. In fact, if we drop the y(i, t) = z(i, t) con-
straints from the optimization problem, the problem
splits into two parts, each of which can be efficiently
solved using dynamic programming:
(y?, z?) = (arg max
y?Y
y ? ?cfg, arg max
z?Z
z ? ?tag)
Dual decomposition exploits this idea; it results in
the algorithm given in figure 1. The algorithm opti-
mizes the combined objective by repeatedly solving
the two sub-problems separately?that is, it directly
Set u(1)(i, t)? 0 for all (i, t) ? Iuni
for k = 1 to K do
y(k) ? arg max
y?Y
(y ? ?cfg ?
?
(i,t)?Iuni
u(k)(i, t)y(i, t))
z(k) ? arg max
z?Z
(z ? ?tag +
?
(i,t)?Iuni
u(k)(i, t)z(i, t))
if y(k)(i, t) = z(k)(i, t) for all (i, t) ? Iuni then
return (y(k), z(k))
for all (i, t) ? Iuni,
u(k+1)(i, t)? u(k)(i, t)+?k(y(k)(i, t)?z(k)(i, t))
return (y(K), z(K))
Figure 1: The algorithm for integrated parsing and tag-
ging. The parameters ?k > 0 for k = 1 . . .K specify
step sizes for each iteration, and are discussed further in
the Appendix. The two arg max problems can be solved
using dynamic programming.
solves the harder optimization problem using an ex-
isting CFG parser and trigram tagger. After each
iteration the algorithm adjusts the weights u(i, t);
these updates modify the objective functions for the
two models, encouraging them to agree on the same
POS sequence. In section 6.1 we will show that the
variables u(i, t) are Lagrange multipliers enforcing
agreement constraints, and that the algorithm corre-
sponds to a (sub)gradient method for optimization
of a dual function. The algorithm is easy to imple-
ment: all that is required is a decoding algorithm for
each of the two models, and simple additive updates
to the Lagrange multipliers enforcing agreement be-
tween the two models.
4.2 Integrating Two Lexicalized Parsers
Our second example problem is the integration of
a phrase-structure parser with a higher-order depen-
dency parser. The goal is to add higher-order fea-
tures to phrase-structure parsing without greatly in-
creasing the complexity of inference.
First, we define an index set for second-order un-
labeled projective dependency parsing. The second-
order parser considers first-order dependencies, as
well as grandparent and sibling second-order depen-
dencies (e.g., see Carreras (2007)). We assume that
Idep is an index set containing all such dependen-
cies (for brevity we omit the details of this index
set). For convenience we define an extended index
set that makes explicit use of first-order dependen-
4
cies, I ?dep = Idep ? Ifirst, where
Ifirst = {(i, j) : i ? {0 . . . n}, j ? {1 . . . n}, i 6= j}
Here (i, j) represents a dependency with head wi
and modifier wj (i = 0 corresponds to the root sym-
bol in the parse). We use D ? {0, 1}|I
?
dep| to denote
the set of valid projective dependency parses.
The second model we use is a lexicalized CFG.
Each symbol in the grammar takes the form A(h)
where A ? N is a non-terminal, and h ? {1 . . . n}
is an index specifying that wh is the head of the con-
stituent. Rule productions take the form ?A(a) ?
B(b) C(c), i, k, j? where b ? {i . . . k}, c ? {(k +
1) . . . j}, and a is equal to b or c, depending on
whether A receives its head-word from its left or
right child. Each such rule implies a dependency
(a, b) if a = c, or (a, c) if a = b. We take Ihead
to be the index set of all such rules, and I ?head =
Ihead?Ifirst to be the extended index set. We define
H ? {0, 1}|I
?
head| to be the set of valid parse trees.
The integrated parsing problem is then to find
(y?, d?) = arg max
(y,d)?R
(
y ? ?head + d ? ?dep
)
(3)
where R = {(y, d) : y ? H, d ? D,
y(i, j) = d(i, j) for all (i, j) ? Ifirst}
This problem has a very similar structure to the
problem of integrated parsing and tagging, and we
can derive a similar dual decomposition algorithm.
The Lagrange multipliers u are a vector in R|Ifirst|
enforcing agreement between dependency assign-
ments. The algorithm (omitted for brevity) is identi-
cal to the algorithm in figure 1, but with Iuni, Y , Z ,
?cfg, and ?tag replaced with Ifirst, H, D, ?head, and
?dep respectively. The algorithm only requires de-
coding algorithms for the two models, together with
simple updates to the Lagrange multipliers.
5 Marginal Polytopes and LP Relaxations
We now give formal guarantees for the algorithms
in the previous section, showing that they solve LP
relaxations of the problems in Eqs. 2 and 3.
To make the connection to linear programming,
we first introduce the idea of marginal polytopes in
section 5.1. In section 5.2, we give a precise state-
ment of the LP relaxations that are being solved
by the example algorithms, making direct use of
marginal polytopes. In section 6 we will prove that
the example algorithms solve these LP relaxations.
5.1 Marginal Polytopes
For a finite set Y , define the set of all distributions
over elements in Y as ? = {? ? R|Y| : ?y ?
0,
?
y?Y ?y = 1}. Each ? ? ? gives a vector of
marginals, ? =
?
y?Y ?yy, where ?r can be inter-
preted as the probability that yr = 1 for a y selected
at random from the distribution ?.
The set of all possible marginal vectors, known as
the marginal polytope, is defined as follows:
M = {? ? Rm : ?? ? ? such that ? =
?
y?Y
?yy}
M is also frequently referred to as the convex hull of
Y , written as conv(Y). We use the notation conv(Y)
in the remainder of this paper, instead ofM.
For an arbitrary set Y , the marginal polytope
conv(Y) can be complex to describe.6 However,
Martin et al (1990) show that for a very general
class of dynamic programming problems, the cor-
responding marginal polytope can be expressed as
conv(Y) = {? ? Rm : A? = b, ? ? 0} (4)
where A is a p?m matrix, b is vector in Rp, and the
value p is linear in the size of a hypergraph repre-
sentation of the dynamic program. Note that A and
b specify a set of p linear constraints.
We now give an explicit description of the re-
sulting constraints for CFG parsing:7 similar con-
straints arise for other dynamic programming algo-
rithms for parsing, for example the algorithms of
Eisner (2000). The exact form of the constraints, and
the fact that they are polynomial in number, is not
essential for the formal results in this paper. How-
ever, a description of the constraints gives valuable
intuition for the structure of the marginal polytope.
The constraints are given in figure 2. To develop
some intuition, consider the case where the variables
?r are restricted to be binary: hence each binary
vector ? specifies a parse tree. The second con-
straint in Eq. 5 specifies that exactly one rule must
be used at the top of the tree. The set of constraints
in Eq. 6 specify that for each production of the form
6For any finite set Y , conv(Y) can be expressed as {? ?
Rm : A? ? b} where A is a matrix of dimension p ?m, and
b ? Rp (see, e.g., Korte and Vygen (2008), pg. 65). The value
for p depends on the set Y , and can be exponential in size.
7Taskar et al (2004) describe the same set of constraints, but
without proof of correctness or reference to Martin et al (1990).
5
?r ? I?, ?r ? 0 ;
X
X,Y,Z?N
k=1...(n?1)
?(X ? Y Z, 1, k, n) = 1 (5)
?X ? N , ?(i, j) such that 1 ? i < j ? n and (i, j) 6= (1, n):
X
Y,Z?N
k=i...(j?1)
?(X ? Y Z, i, k, j) =
X
Y,Z?N
k=1...(i?1)
?(Y ? Z X, k, i? 1, j)
+
X
Y,Z?N
k=(j+1)...n
?(Y ? X Z, i, j, k) (6)
?Y ? T, ?i ? {1 . . . n} : ?(i, Y ) =
X
X,Z?N
k=(i+1)...n
?(X ? Y Z, i, i, k) +
X
X,Z?N
k=1...(i?1)
?(X ? Z Y, k, i? 1, i) (7)
Figure 2: The linear constraints defining the marginal
polytope for CFG parsing.
?X ? Y Z, i, k, j? in a parse tree, there must be
exactly one production higher in the tree that gener-
ates (X, i, j) as one of its children. The constraints
in Eq. 7 enforce consistency between the ?(i, Y )
variables and rule variables higher in the tree. Note
that the constraints in Eqs.(5?7) can be written in the
form A? = b, ? ? 0, as in Eq. 4.
Under these definitions, we have the following:
Theorem 5.1 Define Y to be the set of all CFG
parses, as defined in section 4. Then
conv(Y) = {? ? Rm : ? satisifies Eqs.(5?7)}
Proof: This theorem is a special case of Martin et al
(1990), theorem 2.
The marginal polytope for tagging, conv(Z), can
also be expressed using linear constraints as in Eq. 4;
see figure 3. These constraints follow from re-
sults for graphical models (Wainwright and Jordan,
2008), or from the Martin et al (1990) construction.
As a final point, the following theorem gives an
important property of marginal polytopes, which we
will use at several points in this paper:
Theorem 5.2 (Korte and Vygen (2008), page 66.)
For any set Y ? {0, 1}k, and for any vector ? ? Rk,
max
y?Y
y ? ? = max
??conv(Y)
? ? ? (8)
The theorem states that for a linear objective func-
tion, maximization over a discrete set Y can be
replaced by maximization over the convex hull
?r ? I?tag, ?r ? 0 ;
X
X,Y,Z?T
?((X,Y )? Z, 3) = 1
?X ? T , ?i ? {3 . . . n? 1}:
X
Y,Z?T
?((Y,Z)? X, i) =
X
Y,Z?T
?((Y,X)? Z, i+ 1)
?X ? T , ?i ? {3 . . . n? 2}:
X
Y,Z?T
?((Y,Z)? X, i) =
X
Y,Z?T
?((X,Y )? Z, i+ 2)
?X ? T,?i ? {3 . . . n} : ?(i,X) =
X
Y,Z?T
?((Y,Z)? X, i)
?X ? T : ?(1, X) =
X
Y,Z?T
?((X,Y )? Z, 3)
?X ? T : ?(2, X) =
X
Y,Z?T
?((Y,X)? Z, 3)
Figure 3: The linear constraints defining the marginal
polytope for trigram POS tagging.
conv(Y). The problem max??conv(Y) ? ?? is a linear
programming problem.
For parsing, this theorem implies that:
1. Weighted CFG parsing can be framed as a linear
programming problem, of the form max??conv(Y) ??
?, where conv(Y) is specified by a polynomial num-
ber of linear constraints.
2. Conversely, dynamic programming algorithms
such as the CKY algorithm can be considered to
be oracles that efficiently solve LPs of the form
max??conv(Y) ? ? ?.
Similar results apply for the POS tagging case.
5.2 Linear Programming Relaxations
We now describe the LP relaxations that are solved
by the example algorithms in section 4. We begin
with the algorithm in Figure 1.
The original optimization problem was to find
max(y,z)?Q
(
y ? ?cfg + z ? ?tag
)
(see Eq. 2). By the-
orem 5.2, this is equivalent to solving
max
(?,?)?conv(Q)
(
? ? ?cfg + ? ? ?tag
)
(9)
To formulate our approximation, we first define:
Q? = {(?, ?) : ? ? conv(Y), ? ? conv(Z),
?(i, t) = ?(i, t) for all (i, t) ? Iuni}
6
The definition of Q? is very similar to the definition
of Q (see Eq. 1), the only difference being that Y
and Z are replaced by conv(Y) and conv(Z) re-
spectively. Hence any point inQ is also inQ?. It fol-
lows that any point in conv(Q) is also inQ?, because
Q? is a convex set defined by linear constraints.
The LP relaxation then corresponds to the follow-
ing optimization problem:
max
(?,?)?Q?
(
? ? ?cfg + ? ? ?tag
)
(10)
Q? is defined by linear constraints, making this a
linear program. Since Q? is an outer bound on
conv(Q), i.e. conv(Q) ? Q?, we obtain the guaran-
tee that the value of Eq. 10 always upper bounds the
value of Eq. 9.
In Appendix A we give an example showing
that in general Q? includes points that are not in
conv(Q). These points exist because the agreement
between the two parts is now enforced in expecta-
tion (?(i, t) = ?(i, t) for (i, t) ? Iuni) rather than
based on actual assignments. This agreement con-
straint is weaker since different distributions over
assignments can still result in the same first order
expectations. Thus, the solution to Eq. 10 may be
in Q? but not in conv(Q). It can be shown that
all such solutions will be fractional, making them
easy to distinguish from Q. In many applications of
LP relaxations?including the examples discussed
in this paper?the relaxation in Eq. 10 turns out to
be tight, in that the solution is often integral (i.e., it
is in Q). In these cases, solving the LP relaxation
exactly solves the original problem of interest.
In the next section we prove that the algorithm
in Figure 1 solves the problem in Eq 10. A similar
result holds for the algorithm in section 4.2: it solves
a relaxation of Eq. 3, whereR is replaced by
R? = {(?, ?) : ? ? conv(H), ? ? conv(D),
?(i, j) = ?(i, j) for all (i, j) ? Ifirst}
6 Convergence Guarantees
6.1 Lagrangian Relaxation
We now show that the example algorithms solve
their respective LP relaxations given in the previ-
ous section. We do this by first introducing a gen-
eral class of linear programs, together with an op-
timization method, Lagrangian relaxation, for solv-
ing these LPs. We then show that the algorithms in
section 4 are special cases of the general algorithm.
The linear programs we consider take the form
max
x1?X1,x2?X2
(?1 ? x1 + ?2 ? x2) such that Ex1 = Fx2
The matricesE ? Rq?m andF ? Rq?l specify q lin-
ear ?agreement? constraints between x1 ? Rm and
x2 ? Rl. The setsX1,X2 are also specified by linear
constraints, X1 = {x1 ? Rm : Ax1 = b, x1 ? 0}
and X2 =
{
x2 ? Rl : Cx2 = d, x2 ? 0
}
, hence the
problem is an LP.
Note that if we set X1 = conv(Y), X2 =
conv(Z), and define E and F to specify the agree-
ment constraints ?(i, t) = ?(i, t), then we have the
LP relaxation in Eq. 10.
It is natural to apply Lagrangian relaxation in
cases where the sub-problems maxx1?X1 ?1 ?x1 and
maxx2?X2 ?2 ? x2 can be efficiently solved by com-
binatorial algorithms for any values of ?1, ?2, but
where the constraints Ex1 = Fx2 ?complicate? the
problem. We introduce Lagrange multipliers u ? Rq
that enforce the latter set of constraints, giving the
Lagrangian:
L(u, x1, x2) = ?1 ? x1 + ?2 ? x2 + u ? (Ex1 ? Fx2)
The dual objective function is
L(u) = max
x1?X1,x2?X2
L(u, x1, x2)
and the dual problem is to find minu?Rq L(u).
Because X1 and X2 are defined by linear con-
straints, by strong duality we have
min
u?Rq
L(u) = max
x1?X1,x2?X2:Ex1=Fx2
(?1 ? x1 + ?2 ? x2)
Hence minimizing L(u) will recover the maximum
value of the original problem. This leaves open the
question of how to recover the LP solution (i.e., the
pair (x?1, x
?
2) that achieves this maximum); we dis-
cuss this point in section 6.2.
The dual L(u) is convex. However, L(u) is
not differentiable, so we cannot use gradient-based
methods to optimize it. Instead, a standard approach
is to use a subgradient method. Subgradients are tan-
gent lines that lower bound a function even at points
of non-differentiability: formally, a subgradient of a
convex function L : Rn ? R at a point u is a vector
gu such that for all v, L(v) ? L(u) + gu ? (v ? u).
7
u(1) ? 0
for k = 1 to K do
x(k)1 ? arg maxx1?X1(?1 + (u
(k))TE) ? x1
x(k)2 ? arg maxx2?X2(?2 ? (u
(k))TF ) ? x2
if Ex(k)1 = Fx
(k)
2 return u
(k)
u(k+1) ? u(k) ? ?k(Ex
(k)
1 ? Fx
(k)
2 )
return u(K)
Figure 4: The Lagrangian relaxation algorithm.
By standard results, the subgradient for L at a point
u takes a simple form, gu = Ex?1 ? Fx
?
2, where
x?1 = arg max
x1?X1
(?1 + (u
(k))TE) ? x1
x?2 = arg max
x2?X2
(?2 ? (u
(k))TF ) ? x2
The beauty of this result is that the values of x?1 and
x?2, and by implication the value of the subgradient,
can be computed using oracles for the two arg max
sub-problems.
Subgradient algorithms perform updates that are
similar to gradient descent:
u(k+1) ? u(k) ? ?kg
(k)
where g(k) is the subgradient ofL at u(k) and ?k > 0
is the step size of the update. The complete sub-
gradient algorithm is given in figure 4. The follow-
ing convergence theorem is well-known (e.g., see
page 120 of Korte and Vygen (2008)):
Theorem 6.1 If limk?? ?k = 0 and
??
k=1 ?k =
?, then limk?? L(u(k)) = minu L(u).
The following proposition is easily verified:
Proposition 6.1 The algorithm in figure 1 is an in-
stantiation of the algorithm in figure 4,8 with X1 =
conv(Y), X2 = conv(Z), and the matrices E and
F defined to be binary matrices specifying the con-
straints ?(i, t) = ?(i, t) for all (i, t) ? Iuni.
Under an appropriate definition of the step sizes ?k,
it follows that the algorithm in figure 1 defines a
sequence of Lagrange multiplers u(k) minimizing a
dual of the LP relaxation in Eq. 10. A similar result
holds for the algorithm in section 4.2.
8with the caveat that it returns (x(k)1 , x
(k)
2 ) rather than u
(k).
6.2 Recovering the LP Solution
The previous section described how the method in
figure 4 can be used to minimize the dualL(u) of the
original linear program. We now turn to the problem
of recovering a primal solution (x?1, x
?
2) of the LP.
The method we propose considers two cases:
(Case 1) If Ex(k)1 = Fx
(k)
2 at any stage during
the algorithm, then simply take (x(k)1 , x
(k)
2 ) to be the
primal solution. In this case the pair (x(k)1 , x
(k)
2 ) ex-
actly solves the original LP.9 If this case arises in the
algorithm in figure 1, then the resulting solution is
binary (i.e., it is a member of Q), and the solution
exactly solves the original inference problem.
(Case 2) If case 1 does not arise, then a couple of
strategies are possible. (This situation could arise
in cases where the LP is not tight?i.e., it has a
fractional solution?or where K is not large enough
for convergence.) The first is to define the pri-
mal solution to be the average of the solutions en-
countered during the algorithm: x?1 =
?
k x
(k)
1 /K,
x?2 =
?
k x
(k)
2 /K. Results from Nedic? and Ozdaglar
(2009) show that as K ? ?, these averaged solu-
tions converge to the optimal primal solution.10 A
second strategy (as given in figure 1) is to simply
take (x(K)1 , x
(K)
2 ) as an approximation to the primal
solution. This method is a heuristic, but previous
work (e.g., Komodakis et al (2007)) has shown that
it is effective in practice; we use it in this paper.
In our experiments we found that in the vast ma-
jority of cases, case 1 applies, after a small number
of iterations; see the next section for more details.
7 Experiments
7.1 Integrated Phrase-Structure and
Dependency Parsing
Our first set of experiments considers the integration
of Model 1 of Collins (2003) (a lexicalized phrase-
structure parser, from here on referred to as Model
9We have that ?1 ? x
(k)
1 + ?2 ? x
(k)
2 = L(u
(k), x(k)1 , x
(k)
2 ) =
L(u(k)), where the last equality is because x(k)1 and x
(k)
2 are de-
fined by the respective argmax?s. Thus, (x(k)1 , x
(k)
2 ) and u
(k)
are primal and dual optimal.
10The resulting fractional solution can be projected back to
the setQ, see (Smith and Eisner, 2008; Martins et al, 2009).
8
Itn. 1 2 3 4 5-10 11-20 20-50 **
Dep 43.5 20.1 10.2 4.9 14.0 5.7 1.4 0.4
POS 58.7 15.4 6.3 3.6 10.3 3.8 0.8 1.1
Table 1: Convergence results for Section 23 of the WSJ
Treebank for the dependency parsing and POS experi-
ments. Each column gives the percentage of sentences
whose exact solutions were found in a given range of sub-
gradient iterations. ** is the percentage of sentences that
did not converge by the iteration limit (K=50).
1),11 and the 2nd order discriminative dependency
parser of Koo et al (2008). The inference problem
for a sentence x is to find
y? = arg max
y?Y
(f1(y) + ?f2(y)) (11)
where Y is the set of all lexicalized phrase-structure
trees for the sentence x; f1(y) is the score (log prob-
ability) under Model 1; f2(y) is the score under Koo
et al (2008) for the dependency structure implied
by y; and ? > 0 is a parameter dictating the relative
weight of the two models.12 This problem is simi-
lar to the second example in section 4; a very sim-
ilar dual decomposition algorithm to that described
in section 4.2 can be derived.
We used the Penn Wall Street Treebank (Marcus
et al, 1994) for the experiments, with sections 2-21
for training, section 22 for development, and section
23 for testing. The parameter ? was chosen to opti-
mize performance on the development set.
We ran the dual decomposition algorithm with a
limit of K = 50 iterations. The dual decomposi-
tion algorithm returns an exact solution if case 1 oc-
curs as defined in section 6.2; we found that of 2416
sentences in section 23, case 1 occurred for 2407
(99.6%) sentences. Table 1 gives statistics showing
the number of iterations required for convergence.
Over 80% of the examples converge in 5 iterations or
fewer; over 90% converge in 10 iterations or fewer.
We compare the accuracy of the dual decomposi-
tion approach to two baselines: first, Model 1; and
second, a naive integration method that enforces the
hard constraint that Model 1 must only consider de-
11We use a reimplementation that is a slight modification of
Collins Model 1, with very similar performance, and which uses
the TAG formalism of Carreras et al (2008).
12Note that the models f1 and f2 were trained separately,
using the methods described by Collins (2003) and Koo et al
(2008) respectively.
Precision Recall F1 Dep
Model 1 88.4 87.8 88.1 91.4
Koo08 Baseline 89.9 89.6 89.7 93.3
DD Combination 91.0 90.4 90.7 93.8
Table 2: Performance results for Section 23 of the WSJ
Treebank. Model 1: a reimplementation of the genera-
tive parser of (Collins, 2002). Koo08 Baseline: Model 1
with a hard restriction to dependencies predicted by the
discriminative dependency parser of (Koo et al, 2008).
DD Combination: a model that maximizes the joint score
of the two parsers. Dep shows the unlabeled dependency
accuracy of each system.
 50
 60
 70
 80
 90
 100
 0  10  20  30  40  50
Per
cen
tage
Maximum Number of Dual Decomposition Iterations
f score% certificates% match K=50
Figure 5: Performance on the parsing task assuming a
fixed number of iterations K. f-score: accuracy of the
method. % certificates: percentage of examples for which
a certificate of optimality is provided. % match: percent-
age of cases where the output from the method is identical
to the output when using K = 50.
pendencies seen in the first-best output from the de-
pendency parser. Table 2 shows all three results. The
dual decomposition method gives a significant gain
in precision and recall over the naive combination
method, and boosts the performance of Model 1 to
a level that is close to some of the best single-pass
parsers on the Penn treebank test set. Dependency
accuracy is also improved over the Koo et al (2008)
model, in spite of the relatively low dependency ac-
curacy of Model 1 alone.
Figure 5 shows performance of the approach as a
function ofK, the maximum number of iterations of
dual decomposition. For this experiment, for cases
where the method has not converged for k ? K,
the output from the algorithm is chosen to be the
y(k) for k ? K that maximizes the objective func-
tion in Eq. 11. The graphs show that values of K
less than 50 produce almost identical performance to
K = 50, but with fewer cases giving certificates of
optimality (with K = 10, the f-score of the method
is 90.69%; with K = 5 it is 90.63%).
9
Precision Recall F1 POS Acc
Fixed Tags 88.1 87.6 87.9 96.7
DD Combination 88.7 88.0 88.3 97.1
Table 3: Performance results for Section 23 of the WSJ.
Model 1 (Fixed Tags): a baseline parser initialized to the
best tag sequence of from the tagger of Toutanova and
Manning (2000). DD Combination: a model that maxi-
mizes the joint score of parse and tag selection.
7.2 Integrated Phrase-Structure Parsing and
Trigram POS tagging
In a second experiment, we used dual decomposi-
tion to integrate the Model 1 parser with the Stan-
ford max-ent trigram POS tagger (Toutanova and
Manning, 2000), using a very similar algorithm to
that described in section 4.1. We use the same train-
ing/dev/test split as in section 7.1. The two models
were again trained separately.
We ran the algorithm with a limit of K = 50 it-
erations. Out of 2416 test examples, the algorithm
found an exact solution in 98.9% of the cases. Ta-
ble 1 gives statistics showing the speed of conver-
gence for different examples: over 94% of the exam-
ples converge to an exact solution in 10 iterations or
fewer. In terms of accuracy, we compare to a base-
line approach of using the first-best tag sequence
as input to the parser. The dual decomposition ap-
proach gives 88.3 F1 measure in recovering parse-
tree constituents, compared to 87.9 for the baseline.
8 Conclusions
We have introduced dual-decomposition algorithms
for inference in NLP, given formal properties of the
algorithms in terms of LP relaxations, and demon-
strated their effectiveness on problems that would
traditionally be solved using intersections of dy-
namic programs (Bar-Hillel et al, 1964). Given the
widespread use of dynamic programming in NLP,
there should be many applications for the approach.
There are several possible extensions of the
method we have described. We have focused on
cases where two models are being combined; the
extension to more than two models is straightfor-
ward (e.g., see Komodakis et al (2007)). This paper
has considered approaches for MAP inference; for
closely related methods that compute approximate
marginals, see Wainwright et al (2005b).
A Fractional Solutions
We now give an example of a point (?, ?) ? Q?\conv(Q)
that demonstrates that the relaxation Q? is strictly larger
than conv(Q). Fractional points such as this one can arise
as solutions of the LP relaxation for worst case instances,
preventing us from finding an exact solution.
Recall that the constraints for Q? specify that ? ?
conv(Y), ? ? conv(Z), and ?(i, t) = ?(i, t) for all
(i, t) ? Iuni. Since ? ? conv(Y), ? must be a con-
vex combination of 1 or more members of Y; a similar
property holds for ?. The example is as follows. There
are two possible parts of speech, A and B, and an addi-
tional non-terminal symbol X . The sentence is of length
3, w1 w2 w3. Let ? be the convex combination of the
following two tag sequences, each with probability 0.5:
w1/A w2/A w3/A and w1/A w2/B w3/B. Let ? be
the convex combination of the following two parses, each
with probability 0.5: (X(A w1)(X(A w2)(B w3))) and
(X(A w1)(X(B w2)(A w3))). It can be verified that
?(i, t) = ?(i, t) for all (i, t), i.e., the marginals for single
tags for ? and ? agree. Thus, (?, ?) ? Q?.
To demonstrate that this fractional point is not in
conv(Q), we give parameter values such that this frac-
tional point is optimal and all integral points (i.e., ac-
tual parses) are suboptimal. For the tagging model, set
?(AA? A, 3) = ?(AB ? B, 3) = 0, with all other pa-
rameters having a negative value. For the parsing model,
set ?(X ? A X, 1, 1, 3) = ?(X ? A B, 2, 2, 3) =
?(X ? B A, 2, 2, 3) = 0, with all other rule parameters
being negative. For this objective, the fractional solution
has value 0, while all integral points (i.e., all points inQ)
have a negative value. By Theorem 5.2, the maximum of
any linear objective over conv(Q) is equal to the maxi-
mum over Q. Thus, (?, ?) 6? conv(Q).
B Step Size
We used the following step size in our experiments. First,
we initialized ?0 to equal 0.5, a relatively large value.
Then we defined ?k = ?0 ? 2??k , where ?k is the num-
ber of times that L(u(k
?)) > L(u(k
??1)) for k? ? k. This
learning rate drops at a rate of 1/2t, where t is the num-
ber of times that the dual increases from one iteration to
the next. See Koo et al (2010) for a similar, but less ag-
gressive step size used to solve a different task.
Acknowledgments MIT gratefully acknowledges the
support of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-C-0181.
Any opinions, findings, and conclusion or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reflect the view of the DARPA, AFRL, or the US
government. Alexander Rush was supported under the GALE
program of the Defense Advanced Research Projects Agency,
Contract No. HR0011-06-C-0022. David Sontag was supported
by a Google PhD Fellowship.
10
References
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal
properties of simple phrase structure grammars. In
Language and Information: Selected Essays on their
Theory and Application, pages 116?150.
X. Carreras, M. Collins, and T. Koo. 2008. TAG, dy-
namic programming, and the perceptron for efficient,
feature-rich parsing. In Proc CONLL, pages 9?16.
X. Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proc. CoNLL, pages
957?961.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. EMNLP, page 8.
M. Collins. 2003. Head-driven statistical models for nat-
ural language parsing. In Computational linguistics,
volume 29, pages 589?637.
G.B. Dantzig and P. Wolfe. 1960. Decomposition princi-
ple for linear programs. In Operations research, vol-
ume 8, pages 101?111.
J. Duchi, D. Tarlow, G. Elidan, and D. Koller. 2007.
Using combinatorial optimization within max-product
belief propagation. In NIPS, volume 19.
J. Eisner. 2000. Bilexical grammars and their cubic-time
parsing algorithms. In Advances in Probabilistic and
Other Parsing Technologies, pages 29?62.
A. Globerson and T. Jaakkola. 2007. Fixing max-
product: Convergent message passing algorithms for
MAP LP-relaxations. In NIPS, volume 21.
N. Komodakis, N. Paragios, and G. Tziritas. 2007.
MRF optimization via dual decomposition: Message-
passing revisited. In International Conference on
Computer Vision.
T. Koo, X. Carreras, and M. Collins. 2008. Simple semi-
supervised dependency parsing. In Proc. ACL/HLT.
T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Son-
tag. 2010. Dual Decomposition for Parsing with Non-
Projective Head Automata. In Proc. EMNLP, pages
63?70.
B.H. Korte and J. Vygen. 2008. Combinatorial optimiza-
tion: theory and algorithms. Springer Verlag.
M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1994. Building a large annotated corpus of English:
The Penn Treebank. In Computational linguistics, vol-
ume 19, pages 313?330.
R.K. Martin, R.L. Rardin, and B.A. Campbell. 1990.
Polyhedral characterization of discrete dynamic pro-
gramming. Operations research, 38(1):127?138.
A.F.T. Martins, N.A. Smith, and E.P. Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proc. ACL.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005.
Non-projective dependency parsing using spanning
tree algorithms. In Proc. HLT/EMNLP, pages 523?
530.
Angelia Nedic? and Asuman Ozdaglar. 2009. Approxi-
mate primal solutions and rate analysis for dual sub-
gradient methods. SIAM Journal on Optimization,
19(4):1757?1780.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In Proc. ACL.
S. Riedel and J. Clarke. 2006. Incremental integer linear
programming for non-projective dependency parsing.
In Proc. EMNLP, pages 129?137.
D. Roth and W. Yih. 2005. Integer linear program-
ming inference for conditional random fields. In Proc.
ICML, pages 737?744.
Hanif D. Sherali and Warren P. Adams. 1994. A hi-
erarchy of relaxations and convex hull characteriza-
tions for mixed-integer zero?one programming prob-
lems. Discrete Applied Mathematics, 52(1):83 ? 106.
D.A. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In Proc. EMNLP, pages 145?156.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP relaxations for MAP
using message passing. In Proc. UAI.
B. Taskar, D. Klein, M. Collins, D. Koller, and C. Man-
ning. 2004. Max-margin parsing. In Proc. EMNLP,
pages 1?8.
K. Toutanova and C.D. Manning. 2000. Enriching the
knowledge sources used in a maximum entropy part-
of-speech tagger. In Proc. EMNLP, pages 63?70.
M. Wainwright and M. I. Jordan. 2008. Graphical Mod-
els, Exponential Families, and Variational Inference.
Now Publishers Inc., Hanover, MA, USA.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005a.
MAP estimation via agreement on trees: message-
passing and linear programming. In IEEE Transac-
tions on Information Theory, volume 51, pages 3697?
3717.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005b. A
new class of upper bounds on the log partition func-
tion. In IEEE Transactions on Information Theory,
volume 51, pages 2313?2335.
C. Yanover, T. Meltzer, and Y. Weiss. 2006. Linear
Programming Relaxations and Belief Propagation?An
Empirical Study. In The Journal of Machine Learning
Research, volume 7, page 1907. MIT Press.
11
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1288?1298,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Dual Decomposition for Parsing with Non-Projective Head Automata
Terry Koo Alexander M. Rush Michael Collins Tommi Jaakkola David Sontag
MIT CSAIL, Cambridge, MA 02139, USA
{maestro,srush,mcollins,tommi,dsontag}@csail.mit.edu
Abstract
This paper introduces algorithms for non-
projective parsing based on dual decomposi-
tion. We focus on parsing algorithms for non-
projective head automata, a generalization of
head-automata models to non-projective struc-
tures. The dual decomposition algorithms are
simple and efficient, relying on standard dy-
namic programming and minimum spanning
tree algorithms. They provably solve an LP
relaxation of the non-projective parsing prob-
lem. Empirically the LP relaxation is very of-
ten tight: for many languages, exact solutions
are achieved on over 98% of test sentences.
The accuracy of our models is higher than pre-
vious work on a broad range of datasets.
1 Introduction
Non-projective dependency parsing is useful for
many languages that exhibit non-projective syntactic
structures. Unfortunately, the non-projective parsing
problem is known to be NP-hard for all but the sim-
plest models (McDonald and Satta, 2007). There has
been a long history in combinatorial optimization of
methods that exploit structure in complex problems,
using methods such as dual decomposition or La-
grangian relaxation (Lemare?chal, 2001). Thus far,
however, these methods are not widely used in NLP.
This paper introduces algorithms for non-
projective parsing based on dual decomposition. We
focus on parsing algorithms for non-projective head
automata, a generalization of the head-automata
models of Eisner (2000) and Alshawi (1996) to non-
projective structures. These models include non-
projective dependency parsing models with higher-
order (e.g., sibling and/or grandparent) dependency
relations as a special case. Although decoding of full
parse structures with non-projective head automata
is intractable, we leverage the observation that key
components of the decoding can be efficiently com-
puted using combinatorial algorithms. In particular,
1. Decoding for individual head-words can be ac-
complished using dynamic programming.
2. Decoding for arc-factored models can be ac-
complished using directed minimum-weight
spanning tree (MST) algorithms.
The resulting parsing algorithms have the following
properties:
? They are efficient and easy to implement, relying
on standard dynamic programming and MST al-
gorithms.
? They provably solve a linear programming (LP)
relaxation of the original decoding problem.
? Empirically the algorithms very often give an ex-
act solution to the decoding problem, in which
case they also provide a certificate of optimality.
In this paper we first give the definition for non-
projective head automata, and describe the parsing
algorithm. The algorithm can be viewed as an in-
stance of Lagrangian relaxation; we describe this
connection, and give convergence guarantees for the
method. We describe a generalization to models
that include grandparent dependencies. We then in-
troduce a perceptron-driven training algorithm that
makes use of point 1 above.
We describe experiments on non-projective pars-
ing for a number of languages, and in particu-
lar compare the dual decomposition algorithm to
approaches based on general-purpose linear pro-
gramming (LP) or integer linear programming (ILP)
solvers (Martins et al, 2009). The accuracy of our
models is higher than previous work on a broad
range of datasets. The method gives exact solutions
to the decoding problem, together with a certificate
of optimality, on over 98% of test examples for many
of the test languages, with parsing times ranging be-
tween 0.021 seconds/sentence for the most simple
languages/models, to 0.295 seconds/sentence for the
1288
most complex settings. The method compares favor-
ably to previous work using LP/ILP formulations,
both in terms of efficiency, and also in terms of the
percentage of exact solutions returned.
While the focus of the current paper is on non-
projective dependency parsing, the approach opens
up new ways of thinking about parsing algorithms
for lexicalized formalisms such as TAG (Joshi and
Schabes, 1997), CCG (Steedman, 2000), and pro-
jective head automata.
2 Related Work
McDonald et al (2005) describe MST-based parsing
for non-projective dependency parsing models with
arc-factored decompositions; McDonald and Pereira
(2006) make use of an approximate (hill-climbing)
algorithm for parsing with more complex models.
McDonald and Pereira (2006) and McDonald and
Satta (2007) describe complexity results for non-
projective parsing, showing that parsing for a variety
of models is NP-hard. Riedel and Clarke (2006) de-
scribe ILP methods for the problem; Martins et al
(2009) recently introduced alternative LP and ILP
formulations. Our algorithm differs in that we do not
use general-purpose LP or ILP solvers, instead using
an MST solver in combination with dynamic pro-
gramming; thus we leverage the underlying struc-
ture of the problem, thereby deriving more efficient
decoding algorithms.
Both dual decomposition and Lagrangian relax-
ation have a long history in combinatorial optimiza-
tion. Our work was originally inspired by recent
work on dual decomposition for inference in graph-
ical models (Wainwright et al, 2005; Komodakis
et al, 2007). However, the non-projective parsing
problem has a very different structure from these
models, and the decomposition we use is very dif-
ferent in nature from those used in graphical mod-
els. Other work has made extensive use of de-
composition approaches for efficiently solving LP
relaxations for graphical models (e.g., Sontag et
al. (2008)). Methods that incorporate combinato-
rial solvers within loopy belief propagation (LBP)
(Duchi et al, 2007; Smith and Eisner, 2008) are
also closely related to our approach. Unlike LBP,
our method has strong theoretical guarantees, such
as guaranteed convergence and the possibility of a
certificate of optimality.
Finally, in other recent work, Rush et al (2010)
describe dual decomposition approaches for other
NLP problems.
3 Sibling Models
This section describes a particular class of models,
sibling models; the next section describes a dual-
decomposition algorithm for decoding these models.
Consider the dependency parsing problem for a
sentence with n words. We define the index set
for dependency parsing to be I = {(i, j) : i ?
{0 . . . n}, j ? {1 . . . n}, i 6= j}. A dependency
parse is a vector y = {y(i, j) : (i, j) ? I}, where
y(i, j) = 1 if a dependency with head word i and
modifier j is in the parse, 0 otherwise. We use i = 0
for the root symbol. We define Y to be the set of all
well-formed non-projective dependency parses (i.e.,
the set of directed spanning trees rooted at node 0).
Given a function f : Y 7? R that assigns scores to
parse trees, the optimal parse is
y? = argmax
y?Y
f(y) (1)
A particularly simple definition of f(y) is f(y) =
?
(i,j)?I y(i, j)?(i, j) where ?(i, j) is the score for
dependency (i, j). Models with this form are often
referred to as arc-factored models. In this case the
optimal parse tree y? can be found efficiently using
MST algorithms (McDonald et al, 2005).
This paper describes algorithms that compute y?
for more complex definitions of f(y); in this sec-
tion, we focus on algorithms for models that capture
interactions between sibling dependencies. To this
end, we will find it convenient to define the follow-
ing notation. Given a vector y, define
y|i = {y(i, j) : j = 1 . . . n, j 6= i}
Hence y|i specifies the set of modifiers to word i;
note that the vectors y|i for i = 0 . . . n form a parti-
tion of the full set of variables.
We then assume that f(y) takes the form
f(y) =
n?
i=0
fi(y|i) (2)
Thus f(y) decomposes into a sum of terms, where
each fi considers modifiers to the i?th word alone.
In the general case, finding y? =
argmaxy?Y f(y) under this definition of f(y)
is an NP-hard problem. However for certain
1289
definitions of fi, it is possible to efficiently compute
argmaxy|i?Zi fi(y|i) for any value of i, typically
using dynamic programming. (Here we use Zi to
refer to the set of all possible values for y|i: specifi-
cally, Z0 = {0, 1}n and for i 6= 0, Zi = {0, 1}n?1.)
In these cases we can efficiently compute
z? = argmax
z?Z
f(z) = argmax
z?Z
?
i
fi(z|i) (3)
where Z = {z : z|i ? Zi for i = 0 . . . n} by
simply computing z?|i = argmaxz|i?Zi fi(z|i) for
i = 0 . . . n. Eq. 3 can be considered to be an approx-
imation to Eq. 1, where we have replaced Y with
Z . We will make direct use of this approximation
in the dual decomposition parsing algorithm. Note
that Y ? Z , and in all but trivial cases, Y is a strict
subset of Z . For example, a structure z ? Z could
have z(i, j) = z(j, i) = 1 for some (i, j); it could
contain longer cycles; or it could contain words that
do not modify exactly one head. Nevertheless, with
suitably powerful functions fi?for example func-
tions based on discriminative models?z? may be a
good approximation to y?. Later we will see that
dual decomposition can effectively use MST infer-
ence to rule out ill-formed structures.
We now give the main assumption underlying sib-
ling models:
Assumption 1 (Sibling Decompositions) A model
f(y) satisfies the sibling-decomposition assumption
if: 1) f(y) =
?n
i=0 fi(y|i) for some set of functions
f0 . . . fn. 2) For any i ? {0 . . . n}, for any value
of the variables u(i, j) ? R for j = 1 . . . n, it is
possible to compute
argmax
y|i?Zi
?
?fi(y|i)?
?
j
u(i, j)y(i, j)
?
?
in polynomial time.
The second condition includes additional terms in-
volving u(i, j) variables that modify the scores of
individual dependencies. These terms are benign for
most definitions of fi, in that they do not alter de-
coding complexity. They will be of direct use in the
dual decomposition parsing algorithm.
Example 1: Bigram Sibling Models. Recall that
y|i is a binary vector specifying which words are
modifiers to the head-word i. Define l1 . . . lp to be
the sequence of left modifiers to word i under y|i,
and r1 . . . rq to be the set of right modifiers (e.g.,
consider the case where n = 5, i = 3, and we have
y(3, 1) = y(3, 5) = 0, and y(3, 2) = y(3, 4) = 1:
in this case p = 1, l1 = 2, and q = 1, r1 = 4). In
bigram sibling models, we have
fi(y|i) =
p+1?
k=1
gL(i, lk?1, lk) +
q+1?
k=1
gR(i, rk?1, rk)
where l0 = r0 = START is the initial state, and
lp+1 = rq+1 = END is the end state. The functions
gL and gR assign scores to bigram dependencies to
the left and right of the head. Under this model cal-
culating argmaxy|i?Zi
(
fi(y|i)?
?
j u(i, j)y(i, j)
)
takes O(n2) time using dynamic programming,
hence the model satisfies Assumption 1.
Example 2: Head Automata Head-automata
models constitute a second important model type
that satisfy the sibling-decomposition assumption
(bigram sibling models are a special case of head
automata). These models make use of functions
gR(i, s, s?, r) where s ? S, s? ? S are variables in a
set of possible states S, and r is an index of a word
in the sentence such that i < r ? n. The function
gR returns a cost for taking word r as the next depen-
dency, and transitioning from state s to s?. A similar
function gL is defined for left modifiers. We define
fi(y|i, s0 . . . sq, t0 . . . tp) =
q?
k=1
gR(i, sk?1, sk, rk) +
p?
k=1
gL(i, tk?1, tk, ll)
to be the joint score for dependencies y|i, and left
and right state sequences s0 . . . sq and t0 . . . tp. We
specify that s0 = t0 = START and sq = tp = END.
In this case we define
fi(y|i) = maxs0...sq ,t0...tp
fi(y|i, s0 . . . sq, t0 . . . tp)
and it follows that argmaxy|i?Zi fi(y|i) can be com-
puted inO(n|S|2) time using a variant of the Viterbi
algorithm, hence the model satisfies the sibling-
decomposition assumption.
4 The Parsing Algorithm
We now describe the dual decomposition parsing al-
gorithm for models that satisfy Assumption 1. Con-
sider the following generalization of the decoding
1290
Set u(1)(i, j)? 0 for all (i, j) ? I
for k = 1 to K do
y(k) ? argmax
y?Y
?
(i,j)?I
(
?(i, j) + u(k)(i, j)
)
y(i, j)
for i ? {0 . . . n},
z(k)|i ? argmax
z|i?Zi
(fi(z|i)?
?
j
u(k)(i, j)z(i, j))
if y(k)(i, j) = z(k)(i, j) for all (i, j) ? I then
return (y(k), z(k))
for all (i, j) ? I,
u(k+1)(i, j)? u(k)(i, j)+?k(z(k)(i, j)?y(k)(i, j))
return (y(K), z(K))
Figure 1: The parsing algorithm for sibling decompos-
able models. ?k ? 0 for k = 1 . . .K are step sizes, see
Appendix A for details.
problem from Eq. 1, where f(y) =
?
i fi(y|i),
h(y) =
?
(i,j)?I ?(i, j)y(i, j), and ?(i, j) ? R for
all (i, j):1
argmax
z?Z,y?Y
f(z) + h(y) (4)
such that z(i, j) = y(i, j) for all (i, j) ? I (5)
Although the maximization w.r.t. z is taken over the
set Z , the constraints in Eq. 5 ensure that z = y for
some y ? Y , and hence that z ? Y .
Without the z(i, j) = y(i, j) constraints, the
objective would decompose into the separate max-
imizations z? = argmaxz?Z f(z), and y
? =
argmaxy?Y h(y), which can be easily solved us-
ing dynamic programming and MST, respectively.
Thus, it is these constraints that complicate the op-
timization. Our approach gets around this difficulty
by introducing new variables, u(i, j), that serve to
enforce agreement between the y(i, j) and z(i, j)
variables. In the next section we will show that these
u(i, j) variables are actually Lagrange multipliers
for the z(i, j) = y(i, j) constraints.
Our parsing algorithm is shown in Figure 1. At
each iteration k, the algorithm finds y(k) ? Y us-
ing an MST algorithm, and z(k) ? Z through sep-
arate decoding of the (n + 1) sibling models. The
u(k) variables are updated if y(k)(i, j) 6= z(k)(i, j)
1This is equivalent to Eq. 1 when ?(i, j) = 0 for all (i, j).
In some cases, however, it is convenient to have a model with
non-zero values for the ? variables; see the Appendix. Note that
this definition of h(y) allows argmaxy?Y h(y) to be calculated
efficiently, using MST inference.
for some (i, j); these updates modify the objective
functions for the two decoding steps, and intuitively
encourage the y(k) and z(k) variables to be equal.
4.1 Lagrangian Relaxation
Recall that the main difficulty in solving Eq. 4 was
the z = y constraints. We deal with these con-
straints using Lagrangian relaxation (Lemare?chal,
2001). We first introduce Lagrange multipliers u =
{u(i, j) : (i, j) ? I}, and define the Lagrangian
L(u, y, z) = (6)
f(z) + h(y) +
?
(i,j)?I
u(i, j)
(
y(i, j)? z(i, j)
)
If L? is the optimal value of Eq. 4 subject to the
constraints in Eq. 5, then for any value of u,
L? = max
z?Z,y?Y,y=z
L(u, y, z) (7)
This follows because if y = z, the right term in Eq. 6
is zero for any value of u. The dual objective L(u)
is obtained by omitting the y = z constraint:
L(u) = max
z?Z,y?Y
L(u, y, z)
= max
z?Z
(
f(z)?
?
i,j
u(i, j)z(i, j)
)
+max
y?Y
(
h(y) +
?
i,j
u(i, j)y(i, j)
)
.
Since L(u) maximizes over a larger space (y may
not equal z), we have that L? ? L(u) (compare this
to Eq. 7). The dual problem, which our algorithm
optimizes, is to obtain the tightest such upper bound,
(Dual problem) min
u?R|I|
L(u). (8)
The dual objective L(u) is convex, but not differen-
tiable. However, we can use a subgradient method
to derive an algorithm that is similar to gradient de-
scent, and which minimizes L(u). A subgradient of
a convex function L(u) at u is a vector du such that
for all v ? R|I|, L(v) ? L(u) + du ? (v ? u). By
standard results,
du(k) = y
(k) ? z(k)
is a subgradient for L(u) at u = u(k), where z(k) =
argmaxz?Z f(z)?
?
i,j u
(k)(i, j)z(i, j) and y(k) =
1291
argmaxy?Y h(y) +
?
i,j u
(k)(i, j)y(i, j). Subgra-
dient optimization methods are iterative algorithms
with updates that are similar to gradient descent:
u(k+1) = u(k) ? ?kdu(k) = u
(k) ? ?k(y
(k) ? z(k)),
where ?k is a step size. It is easily verified that the
algorithm in Figure 1 uses precisely these updates.
4.2 Formal Guarantees
With an appropriate choice of the step sizes ?k, the
subgradient method can be shown to solve the dual
problem, i.e.
lim
k??
L(u(k)) = min
u
L(u).
See Korte and Vygen (2008), page 120, for details.
As mentioned before, the dual provides an up-
per bound on the optimum of the primal problem
(Eq. 4),
max
z?Z,y?Y,y=z
f(z) + h(y) ? min
u?R|I|
L(u). (9)
However, we do not necessarily have strong
duality?i.e., equality in the above equation?
because the sets Z and Y are discrete sets. That
said, for some functions h(y) and f(z) strong du-
ality does hold, as stated in the following:
Theorem 1 If for some k ? {1 . . .K} in the al-
gorithm in Figure 1, y(k)(i, j) = z(k)(i, j) for all
(i, j) ? I, then (y(k), z(k)) is a solution to the max-
imization problem in Eq. 4.
Proof. We have that f(z(k)) + h(y(k)) =
L(u(k), z(k), y(k)) = L(u(k)), where the last equal-
ity is because y(k), z(k) are defined as the respective
argmax?s. Thus, the inequality in Eq. 9 is tight, and
(y(k), z(k)) and u(k) are primal and dual optimal.
Although the algorithm is not guaranteed to sat-
isfy y(k) = z(k) for some k, by Theorem 1 if it does
reach such a state, then we have the guarantee of an
exact solution to Eq. 4, with the dual solution u pro-
viding a certificate of optimality. We show in the
experiments that this occurs very frequently, in spite
of the parsing problem being NP-hard.
It can be shown that Eq. 8 is the dual of an LP
relaxation of the original problem. When the con-
ditions of Theorem 1 are satisfied, it means that the
LP relaxation is tight for this instance. For brevity
we omit the details, except to note that when the LP
relaxation is not tight, the optimal primal solution to
the LP relaxation could be recovered by averaging
methods (Nedic? and Ozdaglar, 2009).
5 Grandparent Dependency Models
In this section we extend the approach to consider
grandparent relations. In grandparent models each
parse tree y is represented as a vector
y = {y(i, j) : (i, j) ? I} ? {y?(i, j) : (i, j) ? I}
where we have added a second set of duplicate vari-
ables, y?(i, j) for all (i, j) ? I. The set of all valid
parse trees is then defined as
Y = {y : y(i, j) variables form a directed tree,
y?(i, j) = y(i, j) for all (i, j) ? I}
We again partition the variables into n + 1 subsets,
y|0 . . . y|n, by (re)defining
y|i = {y(i, j) : j = 1 . . . n, j 6= i}
?{y?(k, i) : k = 0 . . . n, k 6= i}
So as before y|i contains variables y(i, j) which in-
dicate which words modify the i?th word. In addi-
tion, y|i includes y?(k, i) variables that indicate the
word that word i itself modifies.
The set of all possible values of y|i is now
Zi = {y|i : y(i, j) ? {0, 1} for j = 1 . . . n, j 6= i;
y?(k, i) ? {0, 1} for k = 0 . . . n, k 6= i;
?
k
y?(k, i) = 1}
Hence the y(i, j) variables can take any values, but
only one of the y?(k, i) variables can be equal to 1
(as only one word can be a parent of word i). As be-
fore, we define Z = {y : y|i ? Zi for i = 0 . . . n}.
We introduce the following assumption:
Assumption 2 (GS Decompositions)
A model f(y) satisfies the grandparent/sibling-
decomposition (GSD) assumption if: 1) f(z) =
?n
i=0 fi(z|i) for some set of functions f0 . . . fn. 2)
For any i ? {0 . . . n}, for any value of the variables
u(i, j) ? R for j = 1 . . . n, and v(k, i) ? R for
k = 0 . . . n, it is possible to compute
argmax
z|i?Zi
(fi(z|i)?
?
j
u(i, j)z(i, j)?
?
k
v(k, i)z?(k, i))
in polynomial time.
1292
Again, it follows that we can approxi-
mate y? = argmaxy?Y
?n
i=0 fi(y|i) by
z? = argmaxz?Z
?n
i=0 fi(z|i), by defining
z?|i = argmaxz|i?Zi fi(z|i) for i = 0 . . . n. The
resulting vector z? may be deficient in two respects.
First, the variables z?(i, j) may not form a well-
formed directed spanning tree. Second, we may
have z??(i, j) 6= z
?(i, j) for some values of (i, j).
Example 3: Grandparent/Sibling Models An
important class of models that satisfy Assumption 2
are defined as follows. Again, for a vector y|i de-
fine l1 . . . lp to be the sequence of left modifiers to
word i under y|i, and r1 . . . rq to be the set of right
modifiers. Define k? to the value for k such that
y?(k, i) = 1. Then the model is defined as follows:
fi(y|i) =
p+1?
j=1
gL(i, k
?, lj?1, lj)+
q+1?
j=1
gR(i, k
?, rj?1, rj)
This is very similar to the bigram-sibling model, but
with the modification that the gL and gR functions
depend in addition on the value for k?. This al-
lows these functions to model grandparent depen-
dencies such as (k?, i, lj) and sibling dependencies
such as (i, lj?1, lj). Finding z?|i under the definition
can be accomplished inO(n3) time, by decoding the
model using dynamic programming separately for
each of the O(n) possible values of k?, and pick-
ing the value for k? that gives the maximum value
under these decodings.
A dual-decomposition algorithm for models that
satisfy the GSD assumption is shown in Figure 2.
The algorithm can be justified as an instance of La-
grangian relaxation applied to the problem
argmax
z?Z,y?Y
f(z) + h(y) (10)
with constraints
z(i, j) = y(i, j) for all (i, j) ? I (11)
z?(i, j) = y(i, j) for all (i, j) ? I (12)
The algorithm employs two sets of Lagrange mul-
tipliers, u(i, j) and v(i, j), corresponding to con-
straints in Eqs. 11 and 12. As in Theorem 1, if at any
point in the algorithm z(k) = y(k), then (z(k), y(k))
is an exact solution to the problem in Eq. 10.
Set u(1)(i, j)? 0, v(1)(i, j)? 0 for all (i, j) ? I
for k = 1 to K do
y(k) ? argmax
y?Y
?
(i,j)?I
y(i, j)?(i, j)
where ?(i, j) = ?(i, j) + u(k)(i, j) + v(k)(i, j).
for i ? {0 . . . n},
z(k)|i ? argmax
z|i?Zi
(fi(z|i) ?
?
j
u(k)(i, j)z(i, j)
?
?
j
v(k)(j, i)z?(j, i))
if y(k)(i, j) = z(k)(i, j) = z(k)? (i, j) for all (i, j) ? I
then
return (y(k), z(k))
for all (i, j) ? I,
u(k+1)(i, j)? u(k)(i, j)+?k(z(k)(i, j)?y(k)(i, j))
v(k+1)(i, j)? v(k)(i, j)+?k(z
(k)
? (i, j)?y
(k)(i, j))
return (y(K), z(K))
Figure 2: The parsing algorithm for grandparent/sibling-
decomposable models.
6 The Training Algorithm
In our experiments we make use of discriminative
linear models, where for an input sentence x, the
score for a parse y is f(y) = w ? ?(x, y) where
w ? Rd is a parameter vector, and ?(x, y) ? Rd
is a feature-vector representing parse tree y in con-
junction with sentence x. We will assume that the
features decompose in the same way as the sibling-
decomposable or grandparent/sibling-decomposable
models, that is ?(x, y) =
?n
i=0 ?(x, y|i) for some
feature vector definition ?(x, y|i). In the bigram sib-
ling models in our experiments, we assume that
?(x, y|i) =
p+1?
k=1
?L(x, i, lk?1, lk) +
q+1?
k=1
?R(x, i, rk?1, rk)
where as before l1 . . . lp and r1 . . . rq are left and
right modifiers under y|i, and where ?L and ?R
are feature vector definitions. In the grandparent
models in our experiments, we use a similar defi-
nition with feature vectors ?L(x, i, k?, lk?1, lk) and
?R(x, i, k?, rk?1, rk), where k? is the parent for
word i under y|i.
We train the model using the averaged perceptron
for structured problems (Collins, 2002). Given the
i?th example in the training set, (x(i), y(i)), the per-
ceptron updates are as follows:
? z? = argmaxy?Z w ? ?(x
(i), y)
? If z? 6= y(i), w = w+?(x(i), y(i))??(x(i), z?)
1293
The first step involves inference over the set Z ,
rather than Y as would be standard in the percep-
tron. Thus, decoding during training can be achieved
by dynamic programming over head automata alone,
which is very efficient.
Our training approach is closely related to local
training methods (Punyakanok et al, 2005). We
have found this method to be effective, very likely
because Z is a superset of Y . Our training algo-
rithm is also related to recent work on training using
outer bounds (see, e.g., (Taskar et al, 2003; Fin-
ley and Joachims, 2008; Kulesza and Pereira, 2008;
Martins et al, 2009)). Note, however, that the LP re-
laxation optimized by dual decomposition is signifi-
cantly tighter than Z . Thus, an alternative approach
would be to use the dual decomposition algorithm
for inference during training.
7 Experiments
We report results on a number of data sets. For
comparison to Martins et al (2009), we perform ex-
periments for Danish, Dutch, Portuguese, Slovene,
Swedish and Turkish data from the CoNLL-X
shared task (Buchholz and Marsi, 2006), and En-
glish data from the CoNLL-2008 shared task (Sur-
deanu et al, 2008). We use the official training/test
splits for these data sets, and the same evaluation
methodology as Martins et al (2009). For com-
parison to Smith and Eisner (2008), we also re-
port results on Danish and Dutch using their alter-
nate training/test split. Finally, we report results on
the English WSJ treebank, and the Prague treebank.
We use feature sets that are very similar to those
described in Carreras (2007). We use marginal-
based pruning, using marginals calculated from an
arc-factored spanning tree model using the matrix-
tree theorem (McDonald and Satta, 2007; Smith and
Smith, 2007; Koo et al, 2007).
In all of our experiments we set the value K, the
maximum number of iterations of dual decompo-
sition in Figures 1 and 2, to be 5,000. If the al-
gorithm does not terminate?i.e., it does not return
(y(k), z(k)) within 5,000 iterations?we simply take
the parse y(k) with the maximum value of f(y(k)) as
the output from the algorithm. At first sight 5,000
might appear to be a large number, but decoding is
still fast?see Sections 7.3 and 7.4 for discussion.2
2Note also that the feature vectors ? and inner productsw ??
The strategy for choosing step sizes ?k is described
in Appendix A, along with other details.
We first discuss performance in terms of accu-
racy, success in recovering an exact solution, and
parsing speed. We then describe additional experi-
ments examining various aspects of the algorithm.
7.1 Accuracy
Table 1 shows results for previous work on the var-
ious data sets, and results for an arc-factored model
with pure MST decoding with our features. (We use
the acronym UAS (unlabeled attachment score) for
dependency accuracy.) We also show results for the
bigram-sibling and grandparent/sibling (G+S) mod-
els under dual decomposition. Both the bigram-
sibling and G+S models show large improvements
over the arc-factored approach; they also compare
favorably to previous work?for example the G+S
model gives better results than all results reported in
the CoNLL-X shared task, on all languages. Note
that we use different feature sets from both Martins
et al (2009) and Smith and Eisner (2008).
7.2 Success in Recovering Exact Solutions
Next, we consider how often our algorithms return
an exact solution to the original optimization prob-
lem, with a certificate?i.e., how often the algo-
rithms in Figures 1 and 2 terminate with y(k) = z(k)
for some value of k < 5000 (and are thus optimal,
by Theorem 1). The CertS and CertG columns in Ta-
ble 1 give the results for the sibling and G+S models
respectively. For all but one setting3 over 95% of the
test sentences are decoded exactly, with 99% exact-
ness in many cases.
For comparison, we also ran both the single-
commodity flow and multiple-commodity flow LP
relaxations of Martins et al (2009) with our mod-
els and features. We measure how often these re-
laxations terminate with an exact solution. The re-
sults in Table 2 show that our method gives exact
solutions more often than both of these relaxations.4
In computing the accuracy figures for Martins et al
only need to be computed once, thus saving computation.
3The exception is Slovene, which has the smallest training
set at only 1534 sentences.
4Note, however, that it is possible that the Martins et al re-
laxations would have given a higher proportion of integral solu-
tions if their relaxation was used during training.
1294
Ma09 MST Sib G+S Best CertS CertG TimeS TimeG TrainS TrainG
Dan 91.18 89.74 91.08 91.78 91.54 99.07 98.45 0.053 0.169 0.051 0.109
Dut 85.57 82.33 84.81 85.81 85.57 98.19 97.93 0.035 0.120 0.046 0.048
Por 92.11 90.68 92.57 93.03 92.11 99.65 99.31 0.047 0.257 0.077 0.103
Slo 85.61 82.39 84.89 86.21 85.61 90.55 95.27 0.158 0.295 0.054 0.130
Swe 90.60 88.79 90.10 91.36 90.60 98.71 98.97 0.035 0.141 0.036 0.055
Tur 76.34 75.66 77.14 77.55 76.36 98.72 99.04 0.021 0.047 0.016 0.036
Eng1 91.16 89.20 91.18 91.59 ? 98.65 99.18 0.082 0.200 0.032 0.076
Eng2 ? 90.29 92.03 92.57 ? 98.96 99.12 0.081 0.168 0.032 0.076
Sm08 MST Sib G+S ? CertS CertG TimeS TimeG TrainS TrainG
Dan 86.5 87.89 89.58 91.00 ? 98.50 98.50 0.043 0.120 0.053 0.065
Dut 88.5 88.86 90.87 91.76 ? 98.00 99.50 0.036 0.046 0.050 0.054
Mc06 MST Sib G+S ? CertS CertG TimeS TimeG TrainS TrainG
PTB 91.5 90.10 91.96 92.46 ? 98.89 98.63 0.062 0.210 0.028 0.078
PDT 85.2 84.36 86.44 87.32 ? 96.67 96.43 0.063 0.221 0.019 0.051
Table 1: A comparison of non-projective automaton-based parsers with results from previous work. MST: Our first-
order baseline. Sib/G+S: Non-projective head automata with sibling or grandparent/sibling interactions, decoded via
dual decomposition. Ma09: The best UAS of the LP/ILP-based parsers introduced in Martins et al (2009). Sm08:
The best UAS of any LBP-based parser in Smith and Eisner (2008). Mc06: The best UAS reported by McDonald
and Pereira (2006). Best: For the CoNLL-X languages only, the best UAS for any parser in the original shared task
(Buchholz and Marsi, 2006) or in any column of Martins et al (2009, Table 1); note that the latter includes McDonald
and Pereira (2006), Nivre and McDonald (2008), and Martins et al (2008). CertS/CertG: Percent of test examples
for which dual decomposition produced a certificate of optimality, for Sib/G+S. TimeS/TimeG: Seconds/sentence for
test decoding, for Sib/G+S. TrainS/TrainG: Seconds/sentence during training, for Sib/G+S. For consistency of timing,
test decoding was carried out on identical machines with zero additional load; however, training was conducted on
machines with varying hardware and load. We ran two tests on the CoNLL-08 corpus. Eng1: UAS when testing on
the CoNLL-08 validation set, following Martins et al (2009). Eng2: UAS when testing on the CoNLL-08 test set.
(2009), we project fractional solutions to a well-
formed spanning tree, as described in that paper.
Finally, to better compare the tightness of our
LP relaxation to that of earlier work, we consider
randomly-generated instances. Table 2 gives results
for our model and the LP relaxations of Martins et al
(2009) with randomly generated scores on automata
transitions. We again recover exact solutions more
often than the Martins et al relaxations. Note that
with random parameters the percentage of exact so-
lutions is significantly lower, suggesting that the ex-
actness of decoding of the trained models is a special
case. We speculate that this is due to the high perfor-
mance of approximate decoding with Z in place of
Y under the trained models for fi; the training algo-
rithm described in section 6 may have the tendency
to make the LP relaxation tight.
7.3 Speed
Table 1, columns TimeS and TimeG, shows decod-
ing times for the dual decomposition algorithms.
Table 2 gives speed comparisons to Martins et al
(2009). Our method gives significant speed-ups over
 0
 5
 10
 15
 20
 25
 30
 0  1000  2000  3000  4000  5000%
 of 
He
ad 
Au
tom
ata
 Re
com
put
ed
Iterations of Dual Decomposition
% recomputed, g+s% recomputed, sib
Figure 3: The average percentage of head automata that
must be recomputed on each iteration of dual decompo-
sition on the PTB validation set.
the Martins et al (2009) method, presumably be-
cause it leverages the underlying structure of the
problem, rather than using a generic solver.
7.4 Lazy Decoding
Here we describe an important optimization in the
dual decomposition algorithms. Consider the algo-
rithm in Figure 1. At each iteration we must find
z(k)|i = argmax
z|i?Zi
(fi(z|i)?
?
j
u(k)(i, j)z(i, j))
1295
Sib Acc Int Time Rand
LP(S) 92.14 88.29 0.14 11.7
LP(M) 92.17 93.18 0.58 30.6
ILP 92.19 100.0 1.44 100.0
DD-5000 92.19 98.82 0.08 35.6
DD-250 92.23 89.29 0.03 10.2
G+S Acc Int Time Rand
LP(S) 92.60 91.64 0.23 0.0
LP(M) 92.58 94.41 0.75 0.0
ILP 92.70 100.0 1.79 100.0
DD-5000 92.71 98.76 0.23 6.8
DD-250 92.66 85.47 0.12 0.0
Table 2: A comparison of dual decomposition with lin-
ear programs described by Martins et al (2009). LP(S):
Linear Program relaxation based on single-commodity
flow. LP(M): Linear Program relaxation based on
multi-commodity flow. ILP: Exact Integer Linear Pro-
gram. DD-5000/DD-250: Dual decomposition with non-
projective head automata, with K = 5000/250. Upper
results are for the sibling model, lower results are G+S.
Columns give scores for UAS accuracy, percentage of so-
lutions which are integral, and solution speed in seconds
per sentence. These results are for Section 22 of the PTB.
The last column is the percentage of integral solutions on
a random problem of length 10 words. The (I)LP experi-
ments were carried out using Gurobi, a high-performance
commercial-grade solver.
for i = 0 . . . n. However, if for some i, u(k)(i, j) =
u(k?1)(i, j) for all j, then z(k)|i = z
(k?1)
|i . In
lazy decoding we immediately set z(k)|i = z
(k?1)
|i if
u(k)(i, j) = u(k?1)(i, j) for all j; this check takes
O(n) time, and saves us from decoding with the i?th
automaton. In practice, the updates to u are very
sparse, and this condition occurs very often in prac-
tice. Figure 3 demonstrates the utility of this method
for both sibling automata and G+S automata.
7.5 Early Stopping
We also ran experiments varying the value of K?
the maximum number of iterations?in the dual de-
composition algorithms. As before, if we do not find
y(k) = z(k) for some value of k ? K, we choose
the y(k) with optimal value for f(y(k)) as the final
solution. Figure 4 shows three graphs: 1) the accu-
racy of the parser on PTB validation data versus the
value for K; 2) the percentage of examples where
y(k) = z(k) at some point during the algorithm,
hence the algorithm returns a certificate of optimal-
ity; 3) the percentage of examples where the solution
 50
 60
 70
 80
 90
 100
 0  200  400  600  800  1000
Pe
rce
nta
ge
Maximum Number of Dual Decomposition Iterations
% validation UAS% certificates% match K=5000
Figure 4: The behavior of the dual-decomposition parser
with sibling automata as the value of K is varied.
Sib P-Sib G+S P-G+S
PTB 92.19 92.34 92.71 92.70
PDT 86.41 85.67 87.40 86.43
Table 3: UAS of projective and non-projective decoding
for the English (PTB) and Czech (PDT) validation sets.
Sib/G+S: as in Table 1. P-Sib/P-G+S: Projective versions
of Sib/G+S, where the MST component has been re-
placed with the Eisner (2000) first-order projective parser.
returned is the same as the solution for the algorithm
with K = 5000 (our original setting). It can be seen
for K as small as 250 we get very similar accuracy
to K = 5000 (see Table 2). In fact, for this set-
ting the algorithm returns the same solution as for
K = 5000 on 99.59% of the examples. However
only 89.29% of these solutions are produced with a
certificate of optimality (y(k) = z(k)).
7.6 How Good is the Approximation z??
We ran experiments measuring the quality of z? =
argmaxz?Z f(z), where f(z) is given by the
perceptron-trained bigram-sibling model. Because
z? may not be a well-formed tree with n dependen-
cies, we report precision and recall rather than con-
ventional dependency accuracy. Results on the PTB
validation set were 91.11%/88.95% precision/recall,
which is accurate considering the unconstrained na-
ture of the predictions. Thus the z? approximation is
clearly a good one; we suspect that this is one reason
for the good convergence results for the method.
7.7 Importance of Non-Projective Decoding
It is simple to adapt the dual-decomposition algo-
rithms in figures 1 and 2 to give projective depen-
dency structures: the set Y is redefined to be the set
1296
of all projective structures, with the argmax over Y
being calculated using a projective first-order parser
(Eisner, 2000). Table 3 shows results for projec-
tive and non-projective parsing using the dual de-
composition approach. For Czech data, where non-
projective structures are common, non-projective
decoding has clear benefits. In contrast, there is little
difference in accuracy between projective and non-
projective decoding on English.
8 Conclusions
We have described dual decomposition algorithms
for non-projective parsing, which leverage existing
dynamic programming and MST algorithms. There
are a number of possible areas for future work. As
described in section 7.7, the algorithms can be easily
modified to consider projective structures by replac-
ing Y with the set of projective trees, and then using
first-order dependency parsing algorithms in place
of MST decoding. This method could be used to
derive parsing algorithms that include higher-order
features, as an alternative to specialized dynamic
programming algorithms. Eisner (2000) describes
extensions of head automata to include word senses;
we have not discussed this issue in the current pa-
per, but it is simple to develop dual decomposition
algorithms for this case, using similar methods to
those used for the grandparent models. The gen-
eral approach should be applicable to other lexical-
ized syntactic formalisms, and potentially also to de-
coding in syntax-driven translation. In addition, our
dual decomposition approach is well-suited to paral-
lelization. For example, each of the head-automata
could be optimized independently in a multi-core or
GPU architecture. Finally, our approach could be
used with other structured learning algorithms, e.g.
Meshi et al (2010).
A Implementation Details
This appendix describes details of the algorithm,
specifically choice of the step sizes ?k, and use of
the ?(i, j) parameters.
A.1 Choice of Step Sizes
We have found the following method to be effec-
tive. First, define ? = f(z(1)) ? f(y(1)), where
(z(1), y(1)) is the output of the algorithm on the first
iteration (note that we always have ? ? 0 since
f(z(1)) = L(u(1))). Then define ?k = ?/(1 + ?k),
where ?k is the number of times that L(u(k
?)) >
L(u(k
??1)) for k? ? k. Hence the learning rate drops
at a rate of 1/(1+ t), where t is the number of times
that the dual increases from one iteration to the next.
A.2 Use of the ?(i, j) Parameters
The parsing algorithms both consider a general-
ized problem that includes ?(i, j) parameters. We
now describe how these can be useful. Re-
call that the optimization problem is to solve
argmaxz?Z,y?Y f(z) + h(y), subject to a set of
agreement constraints. In our models, f(z) can
be written as f ?(z) +
?
i,j ?(i, j)z(i, j) where
f ?(z) includes only terms depending on higher-
order (non arc-factored features), and ?(i, j) are
weights that consider the dependency between i
and j alone. For any value of 0 ? ? ?
1, the problem argmaxz?Z,y?Y f2(z) + h2(y) is
equivalent to the original problem, if f2(z) =
f ?(z) + (1 ? ?)
?
i,j ?(i, j)z(i, j) and h2(y) =
?
?
i,j ?(i, j)y(i, j). We have simply shifted the
?(i, j) weights from one model to the other. While
the optimization problem remains the same, the al-
gorithms in Figure 1 and 2 will converge at differ-
ent rates depending on the value for ?. In our ex-
periments we set ? = 0.001, which puts almost
all the weight in the head-automata models, but al-
lows weights on spanning tree edges to break ties in
MST inference in a sensible way. We suspect this is
important in early iterations of the algorithm, when
many values for u(i, j) or v(i, j) will be zero, and
where with ? = 0 many spanning tree solutions y(k)
would be essentially random, leading to very noisy
updates to the u(i, j) and v(i, j) values. We have
not tested other values for ?.
Acknowledgments MIT gratefully acknowledges the
support of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-C-0181.
Any opinions, findings, and conclusion or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reflect the view of the DARPA, AFRL, or the US
government. A. Rush was supported by the GALE program of
the DARPA, Contract No. HR0011-06-C-0022. D. Sontag was
supported by a Google PhD Fellowship.
1297
References
H. Alshawi. 1996. Head Automata and Bilingual Tiling:
Translation with Minimal Representations. In Proc.
ACL, pages 167?176.
S. Buchholz and E. Marsi. 2006. CoNLL-X Shared
Task on Multilingual Dependency Parsing. In Proc.
CoNLL, pages 149?164.
X. Carreras. 2007. Experiments with a Higher-Order
Projective Dependency Parser. In Proc. EMNLP-
CoNLL, pages 957?961.
M. Collins. 2002. Discriminative Training Methods
for Hidden Markov Models: Theory and Experiments
with Perceptron Algorithms. In Proc. EMNLP, pages
1?8.
J. Duchi, D. Tarlow, G. Elidan, and D. Koller. 2007. Us-
ing Combinatorial Optimization within Max-Product
Belief Propagation. In NIPS, pages 369?376.
J. Eisner. 2000. Bilexical grammars and their cubic-
time parsing algorithms. Advances in Probabilistic
and Other Parsing Technologies, pages 29?62.
T. Finley and T. Joachims. 2008. Training structural
svms when exact inference is intractable. In ICML,
pages 304?311.
A.K. Joshi and Y. Schabes. 1997. Tree-Adjoining
Grammars. Handbook of Formal Languages: Beyond
Words, 3:69?123.
N. Komodakis, N. Paragios, and G. Tziritas. 2007. MRF
Optimization via Dual Decomposition: Message-
Passing Revisited. In Proc. ICCV.
T. Koo, A. Globerson, X. Carreras, and M. Collins. 2007.
Structured Prediction Models via the Matrix-Tree The-
orem. In Proc. EMNLP-CoNLL, pages 141?150.
B.H. Korte and J. Vygen. 2008. Combinatorial Opti-
mization: Theory and Algorithms. Springer Verlag.
A. Kulesza and F. Pereira. 2008. Structured learning
with approximate inference. In NIPS.
C. Lemare?chal. 2001. Lagrangian Relaxation. In Com-
putational Combinatorial Optimization, Optimal or
Provably Near-Optimal Solutions [based on a Spring
School], pages 112?156, London, UK. Springer-
Verlag.
A.F.T. Martins, D. Das, N.A. Smith, and E.P. Xing. 2008.
Stacking Dependency Parsers. In Proc. EMNLP,
pages 157?166.
A.F.T. Martins, N.A. Smith., and E.P. Xing. 2009. Con-
cise Integer Linear Programming Formulations for De-
pendency Parsing. In Proc. ACL, pages 342?350.
R. McDonald and F. Pereira. 2006. Online Learning
of Approximate Dependency Parsing Algorithms. In
Proc. EACL, pages 81?88.
R. McDonald and G. Satta. 2007. On the Complexity of
Non-Projective Data-Driven Dependency Parsing. In
Proc. IWPT.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic?. 2005.
Non-Projective Dependency Parsing using Spanning
Tree Algorithms. In Proc. HLT-EMNLP, pages 523?
530.
O. Meshi, D. Sontag, T. Jaakkola, and A. Globerson.
2010. Learning Efficiently with Approximate Infer-
ence via Dual Losses. In Proc. ICML.
A. Nedic? and A. Ozdaglar. 2009. Approximate
Primal Solutions and Rate Analysis for Dual Sub-
gradient Methods. SIAM Journal on Optimization,
19(4):1757?1780.
J. Nivre and R. McDonald. 2008. Integrating Graph-
Based and Transition-Based Dependency Parsers. In
Proc. ACL, pages 950?958.
V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2005.
Learning and Inference over Constrained Output. In
Proc. IJCAI, pages 1124?1129.
S. Riedel and J. Clarke. 2006. Incremental Integer Linear
Programming for Non-projective Dependency Parsing.
In Proc. EMNLP, pages 129?137.
A.M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On Dual Decomposition and Linear Program-
ming Relaxations for Natural Language Processing. In
Proc. EMNLP.
D.A. Smith and J. Eisner. 2008. Dependency Parsing by
Belief Propagation. In Proc. EMNLP, pages 145?156.
D.A. Smith and N.A. Smith. 2007. Probabilistic Mod-
els of Nonprojective Dependency Trees. In Proc.
EMNLP-CoNLL, pages 132?140.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP Relaxations for MAP
using Message Passing. In Proc. UAI.
M. Steedman. 2000. The Syntactic Process. MIT Press.
M. Surdeanu, R. Johansson, A. Meyers, L. Ma`rquez, and
J. Nivre. 2008. The CoNLL-2008 Shared Task on
Joint Parsing of Syntactic and Semantic Dependencies.
In Proc. CoNLL.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
Markov networks. In NIPS.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005. MAP
estimation via agreement on trees: message-passing
and linear programming. In IEEE Transactions on In-
formation Theory, volume 51, pages 3697?3717.
1298
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1434?1444, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Improved Parsing and POS Tagging Using Inter-Sentence
Consistency Constraints
Alexander M. Rush1? Roi Reichart1? Michael Collins2 Amir Globerson3
1MIT CSAIL, Cambridge, MA, 02139, USA
{srush|roiri}@csail.mit.edu
2Department of Computer Science, Columbia University, New-York, NY 10027, USA
mcollins@cs.columbia.edu
3School of Computer Science and Engineering, The Hebrew University, Jerusalem, 91904, Israel
gamir@cs.huji.ac.il
Abstract
State-of-the-art statistical parsers and POS
taggers perform very well when trained with
large amounts of in-domain data. When train-
ing data is out-of-domain or limited, accuracy
degrades. In this paper, we aim to compen-
sate for the lack of available training data by
exploiting similarities between test set sen-
tences. We show how to augment sentence-
level models for parsing and POS tagging with
inter-sentence consistency constraints. To deal
with the resulting global objective, we present
an efficient and exact dual decomposition de-
coding algorithm. In experiments, we add
consistency constraints to the MST parser
and the Stanford part-of-speech tagger and
demonstrate significant error reduction in the
domain adaptation and the lightly supervised
settings across five languages.
1 Introduction
State-of-the-art statistical parsers and POS taggers
perform very well when trained with large amounts
of data from their test domain. When training data is
out-of-domain or limited, the performance of the re-
sulting model often degrades. In this paper, we aim
to compensate for the lack of available training data
by exploiting similarities between test set sentences.
Most parsing and tagging models are defined at the
sentence-level, which makes such inter-sentence in-
formation sharing difficult. We show how to aug-
ment sentence-level models with inter-sentence con-
straints to encourage consistent descisions in similar
? Both authors contributed equally to this work.
contexts, and we give an efficient algorithm with for-
mal guarantees for decoding such models.
In POS tagging, most taggers perform very well
on word types that they have observed in training
data, but they perform poorly on unknown words.
With a global objective, we can include constraints
that encourage a consistent tag across all occur-
rences of an unknown word type to improve accu-
racy. In dependency parsing, the parser can benefit
from surface-level features of the sentence, but with
sparse or out-of-domain training data these features
are very noisy. Using a global objective, we can add
constraints that encourage similar surface-level con-
texts to exhibit similar syntactic behaviour.
The first contribution of this work is the use of
Markov random fields (MRFs) to model global con-
straints between sentences in dependency parsing
and POS tagging. We represent each word as a node,
the tagging or parse decision as its label, and add
constraints through edges. MRFs allow us to include
global constraints tailored to these problems, and to
reason about inference in the corresponding global
models.
The second contribution is an efficient dual de-
composition algorithm for decoding a global ob-
jective with inter-sentence constraints. These con-
straints generally make direct inference challenging
since they tie together the entire test corpus. To alle-
viate this issue, our algorithm splits the global infer-
ence problem into subproblems - decoding of indi-
vidual sentences, and decoding of the global MRF.
These subproblems can be solved efficiently through
known methods. We show empirically that by iter-
atively solving these subproblems, we can find the
1434
exact solution to the global model.
We experiment with domain adaptation and
lightly supervised training. We demonstrate that
global models with consistency constraints can im-
prove upon sentence-level models for dependency
parsing and part-of-speech tagging. For domain
adaptation, we show an error reduction of up to 7.7%
when adapting the second-order projective MST
parser (McDonald et al 2005) from newswire to
the QuestionBank domain. For lightly supervised
learning, we show an error reduction of up to 12.8%
over the same parser for five languages and an error
reduction of up to 10.3% over the Stanford trigram
tagger (Toutanova et al 2003) for English POS tag-
ging. The algorithm requires, on average, only 1.7
times the costs of sentence-level inference and finds
the exact solution on the vast majority of sentences.
2 Related Work
Methods that combine inter-sentence information
with sentence-level algorithms have been applied to
a number of NLP tasks. The most similar models to
our work are skip-chain CRFs (Sutton and Mccal-
lum, 2004), relational markov networks (Taskar et
al., 2002), and collective inference with symmetric
clique potentials (Gupta et al 2010). These mod-
els use a linear-chain CRF or MRF objective mod-
ified by potentials defined over pairs of nodes or
clique templates. The latter model makes use of La-
grangian relaxation. Skip-chain CRFs and collective
inference have been applied to problems in IE, and
RMNs to named entity recognition (NER) (Bunescu
and Mooney, 2004). Finkel et al(2005) also inte-
grated non-local information into entity annotation
algorithms using Gibbs sampling.
Our model can be applied to a variety of off-the-
shelf structured prediction models. In particular, we
focus on dependency parsing which is characterized
by a more complicated structure compared to the IE
tasks addressed by previous work.
Another line of work that integrates corpus-level
declarative information into sentence-level models
includes the posterior regularization (Ganchev et al
2010; Gillenwater et al 2010), generalized expec-
tation (Mann and McCallum, 2007; Mann and Mc-
Callum, ), and Bayesian measurements (Liang et al
2009) frameworks. The power of these methods has
been demonstrated for a variety of NLP tasks, such
as unsupervised and semi-supervised POS tagging
and parsing. The constraints used by these works
differ from ours in that they encourage the posterior
label distribution to have desired properties such as
sparsity (e.g. a given word can take a small number
of labels with a high probability). In addition, these
methods use global information during training as
opposed to our approach which applies test-time in-
ference global constraints.
The application of dual decomposition for infer-
ence in MRFs has been explored by Wainwright et
al. (2005), Komodakis et al(2007), and Globerson
and Jaakkola (2007). In NLP, Rush et al(2010)
and Koo et al(2010) applied dual decomposition to
enforce agreement between different sentence-level
algorithms for parsing and POS tagging. Work on
dual decomposition for NLP is related to the work
of Smith and Eisner (2008) who apply belief prop-
agation to inference in dependency parsing, and to
constrained conditional models (CCM) (Roth and
Yih, 2005) that impose inference-time constraints
through an ILP formulation.
Several works have addressed semi-supervised
learning for structured prediction, suggesting objec-
tives based on the max-margin principles (Altun and
Mcallester, 2005), manifold regularization (Belkin
et al 2005), a structured version of co-training
(Brefeld and Scheffer, 2006) and an entropy-based
regularizer for CRFs (Wang et al 2009). The com-
plete literature on domain adaptation is beyond the
scope of this paper, but we refer the reader to Blitzer
and Daume (2010) for a recent survey.
Specifically for parsing and POS tagging, self-
training (Reichart and Rappoport, 2007), co-training
(Steedman et al 2003) and active learning (Hwa,
2004) have been shown useful in the lightly su-
pervised setup. For parser adaptation, self-training
(McClosky et al 2006; McClosky and Charniak,
2008), using weakly annotated data from the tar-
get domain (Lease and Charniak, 2005; Rimell and
Clark, 2008), ensemble learning (McClosky et al
2010), hierarchical bayesian models (Finkel and
Manning, 2009) and co-training (Sagae and Tsujii,
2007) achieve substantial performance gains. For a
recent survey see Plank (2011). Constraints simi-
lar to those we use for POS tagging were used by
Subramanya et al(2010) for POS tagger adaptation.
1435
Their work, however, does not show how to decode
a global, corpus-level, objective that enforces these
constraints, which is a major contribution of this pa-
per.
Inter-sentence syntactic consistency has been ex-
plored in the psycholinguistics and NLP literature.
Phenomena such as parallelism and syntactic prim-
ing ? the tendency to repeat recently used syntactic
structures ? have been demonstrated in human lan-
guage corpora (e.g. WSJ and Brown) (Dubey et al
2009) and were shown useful in generative and dis-
criminative parsers (e.g. (Cheung and Penn, 2010)).
We complement these works, which focus on con-
sistency between consecutive sentences, and explore
corpus level consistency.
3 Structured Models
We begin by introducing notation for sentence-
level dependency parsing as a structured prediction
problem. The goal of dependency parsing is to
find the best parse y for a tagged sentence x =
(w1/t1, . . . , wn/tn) with words w and POS tags t.
Define the index set for dependency parsing as
I(x) = {(m,h) : m ? {1 . . . n},
h ? {0 . . . n},m 6= h}
where h = 0 represents the root word. A depen-
dency parse is a vector y = {y(m,h) : (m,h) ?
I(x)} where y(m,h) = 1 if m is a modifier of the
head word h. We define the set Y(x) ? {0, 1}|I(x)|
to be the set of all valid dependency parses for a sen-
tence x. In this work, we use projective dependency
parses, but the method also applies to the set of non-
projective parse trees.
Additionally, we have a scoring function f :
Y(x)? R. The optimal parse y? for a sentence x is
given by, y? = argmaxy?Y(x) f(y). This sentence-
level decoding problem can often be solved effi-
ciently. For example in commonly used projec-
tive dependency parsing models (McDonald et al
2005), we can compute y? efficiently using variants
of the Viterbi algorithm.
For this work, we make the assumption that we
have an efficient algorithm to find the argmax of
f(y) +
?
(m,h)?I(x)
u(m,h)y(m,h) = f(y) + u ? y
where u is a vector in R|I(x)|. In practice, u will be
a vector of Lagrange multipliers associated with the
dependencies of y in our dual decomposition algo-
rithm given in Section 6.
We can construct a very similar setting for POS
tagging where the goal is to find the best tagging
y for a sentence x = (w1, . . . , wn). We skip the
formal details here.
We next introduce notation for Markov random
fields (MRFs) (Koller and Friedman, 2009). An
MRF consists of an undirected graph G = (V,E),
a set of possible labels for each node Li for i ?
{1, . . . , |V |}, and a scoring function g. The index
set for MRFs is
IMRF = {(i, l) : i ? {1 . . . |V |}, l ? Li}
? {((i, j), li, lj) : (i, j) ? E, li ? Li, lj ? Lj}
A label assignment in the MRF is a binary vector
z with z(i, l) = 1 if the label l is selected at node i
and z((i, j), li, lj) = 1 if the labels li, lj are selected
for the nodes i, j.
In applications such as parsing and POS tagging,
some of the label assignments are not allowed. For
example, in dependency parsing the resulting struc-
ture must be a tree. Consequently, if every node
in the MRF corresponds to a word in a document
and its label corresponds to the index of its head
word, the resulting dependency structure for each
sentence must be acyclic. The set of all valid la-
bel assignments (one label per node) is given by
Z ? {0, 1}|IMRF|.
We score label assignments in the MRF with a
scoring function g : Z ? R. The best assignment
z? in an MRF is given by, z? = argmaxz?Z g(z).
We focus on pairwise MRFs where this function g is
a linear function of z whose parameters are denoted
by ?
g(z) = z ? ? =
?
(i,l)?IMRF
z(i, l)?(i, l) +
?
((i,j),li,lj)?IMRF
z((i, j), li, lj)?((i, j), li, lj)
As in parsing, we make the assumption that we
have an efficient algorithm to find the argmax of
g(z) +
?
(i,l)?IMRF(x)
u(i, l)z(i, l)
1436
He/PRP saw/VBD an/DT American/JJ man/NN
The/DT smart/JJ girls/NNS stood/VBD outside/RB
Danny/DT walks/VBZ a/DT long/JJ distance/NN
NN
Figure 1: An example constraint from dependency pars-
ing. The black nodes are modifiers observed in the train-
ing data. Each gray node corresponds to a possible mod-
ifier in the test corpus. The constraint applies to all mod-
ifiers in the context DT JJ. The white node corresponds
to the consensus POS tag of the head word of these mod-
ifiers.
4 A Parsing Example
In this section we give a detailed example of global
constraints for dependency parsing. The aim is to
construct a global objective that encourages similar
contexts across the corpus to exhibit similar syntac-
tic behaviour. We implement this objective using an
MRF with a node for each word in the test set. The
label of each node is the index of the word it mod-
ifies. We add edges to this MRF to reward consis-
tency among similar contexts. Furthermore, we add
nodes with a fixed label to incorporate contexts seen
in the training data.
Specifically, we say that the context of a word is
its POS tag and the POS tags of some set of the
words around it. We expand on this notion of con-
text in Section 8; for simplicity we assume here that
the context includes only the previous word?s POS
tag. Our constraints are designed to bias words in
the same context to modify words with similar POS
tags.
Figure 1 shows a global MRF over a small parsing
example with one training sentence and two test sen-
tences. The MRF contains a node associated with
each word instance, where the label of the node is
the index of the word it modifies. In this corpus, the
context DT JJ appears once in training and twice in
testing. We hope to choose head words with similar
POS tags for these two test contexts biased by the
observed training context.
More concretely, for each context c ?
{1, . . . , C}, we have a set Sc of associated
word indices (s,m) that appear in the context,
where s is a sentence index and m is a position
in that sentence. For instance, in our example
S1 = {(1, 2), (2, 4)} consists of all positions in
the test set where we see JJ preceded by DT.
Futhermore, we have a set Oc of indices (s,m,TR)
of observed instances of the context in the training
data where TR denotes a training index. In our
example O1 = {(1, 4,TR)} consists of the one
training instance. We associate each word instance
with a single context c.
We then define our MRF to include one consensus
node for each set Sc as well as a word node for each
instance in the set Sc ?Oc. Thus the set of variables
corresponds to V = {1, . . . , C} ? (
?C
c=1 Sc ? Oc).
Additionally, we include an edge from each node
i ? Sc?Oc to its consensus node c,E = {(i, c) : c ?
{1, . . . , C}, i ? Sc ?Oc}. The word nodes from Sc
have the label set of possible head indices L(s,m) =
{0, . . . , ns} where ns is the length of the sentence s.
The observed nodes from Oc have a singleton label
set L(s,m,TR) with the observed index. The consen-
sus nodes have the label set Lc = T ? {NULL}
where T is the set of POS tags and the NULL sym-
bol represents the constraint being turned off.
We can now define the scoring function g for this
MRF. The scoring function aims to reward consis-
tency among the head POS tag at each word and the
consensus node
?((i, c), li, lc) =
?
???
???
?1 if pos(li) = lc
?2 if pos(li) is close to lc
?3 lc = NULL
0 otherwise
where posmaps a word index to its POS tag. The pa-
rameters ?1 ? ?2 ? ?3 ? 0 determine the bonus for
identical POS tags, similar POS tags, and for turning
off the constraint .
We construct a similar model for POS tagging.
We choose sets Tc corresponding to the c?th un-
known word type in the corpus. The MRF graph
is identical to the parsing case with Tc replacing Sc
and we no longer have Oc. The label sets for the
word nodes are now L(s,m) = T where the label is
1437
the POS tag chosen at that word, and the label set for
the consensus node is Lc = T ? {NULL}. We use
the same scoring function as in parsing to enforce
consistency between word nodes and the consensus
node.
5 Global Objective
Recall the definition of sentence-level parsing,
where the optimal parse y? for a single sentence
x under a scoring function f is given by: y? =
argmaxy?Y(x) f(y). We apply this objective to
a set of sentences, specified by the tuple X =
(x1, ..., xr), and the product of possible parses
Y(X) = Y(x1) ? . . . ? Y(xr). The sentence-level
decoding problem is to find the optimal dependency
parses Y ? = (Y ?1 , ..., Y ?r ) ? Y(X) under a global
objective
Y ? = argmax
Y ?Y(X)
F (Y ) = argmax
Y ?Y(X)
r?
s=1
f(Ys)
where F : Y(X) ? R is the global scoring func-
tion.
We now consider scoring functions where the
global objective includes inter-sentence constraints.
Objectives of this form will not factor directly
into individual parsing problems; however, we can
choose to write them as the sum of two convenient
terms: (1) A simple sum of sentence-level objec-
tives; and (2) A global MRF that connects the local
structures.
For convenience, we define the following index
set.
J (X) = {(s,m, h) : s ? {1, . . . , r},
(m,h) ? I(xs)}
This set enumerates all possible dependencies at
each sentence in the corpus. We say the parses Ys
are consistent with a label assignment z if for all
(s,m, h) ? J (X) we have that z((s,m), h) =
Ys(m,h). In other words, the labels in z match the
head words chosen in parse Ys.
With this notation we can write the full global de-
coding objective as
(Y ?, z?) = argmax
Y ?Y(X), z?Z
F (Y ) + g(z) (1)
s.t. ?(s,m, h) ? J (X), z((s,m), h) = Ys(m,h)
Set u(1)(s,m, h)? 0 for all (s,m, h) ? J (X)
for k = 1 to K do
z(k) ? argmax
z?Z
(g(z) +
?
(s,m,h)?J (X)
u(k)(s,m, h)z((s,m), h))
Y (k) ? argmax
Y ?Y(X)
(F (Y ) ?
?
(s,m,h)?J (X)
u(k)(s,m, h)Ys(m,h))
if Y (k)s (m,h) = z(k)((s,m), h)
for all (s,m, h) ? J (X) then
return (Y (k), z(k))
for all (s,m, h) ? J (X),
u(k+1)(s,m, h)? u(k)(s,m, h) +
?k(z(k)((s,m), h)? Y (k)s (m,h))
return (Y (K), z(K))
Figure 2: The global decoding algorithm for dependency
parsing models.
The solution to this objective maximizes the local
models as well as the global MRF, while maintain-
ing consistency among the models. Specifically, the
MRF we use in the experiments has a simple naive
Bayes structure with the consensus node connected
to all relevant word nodes.
The global objective for POS tagging has a similar
form. As before we add a node to the MRF for each
word in the corpus. We use the POS tag set as our
labels for each of these nodes. The index set con-
tains an element for each possible tag at each word
instance in the corpus.
6 A Global Decoding Algorithm
We now consider the decoding question: how to
find the structure Y ? that maximizes the global ob-
jective. We aim for an efficient solution that makes
use of the individual solvers at the sentence-level.
For this work, we make the assumption that the
graph chosen for the MRF has small tree-width, e.g.
our naive Bayes constraints, and can be solved effi-
ciently using dynamic programming.
Before we describe our dual decomposition al-
gorithm, we consider the difficulty of solving the
global objective directly. We have an efficient dy-
namic programming algorithm for solving depen-
dency parsing at the sentence-level, and efficient al-
gorithms for solving the MRF. It follows that we
1438
could construct an intersected dynamic program-
ming algorithm that maintains the product of states
over both models. This algorithm is exact, but it
is very inefficient. Solving the intersected dynamic
program requires decoding simultaneously over the
entire corpus, with an additional multiplicative fac-
tor for solving the MRF. On top of this cost, we need
to alter the internal structure of the sentence-level
models.
In contrast, we can construct a dual decomposi-
tion algorithm which is efficient, produces a certifi-
cate when it finds an exact solution, and directly
uses the sentence-level parsing models. Considering
again the global objective of equation 1, we note that
the difficulty in decoding this objective comes en-
tirely from the constraints z((s,m), h) = Ys(m,h).
If these were not there, the problem would factor
into two parts, an optimization of F over the test
corpus Y(X) and an optimization of g over possible
MRF assignments Z . The first problem factors nat-
urally into sentence-level parsing problems and the
second can be solved efficiently given our assump-
tions on the MRF topology G.
Recent work has shown that a relaxation based
on dual decomposition often produces an exact so-
lution for such problems (Koo et al 2010). To
apply dual decomposition, we introduce Lagrange
multipliers u(s,m, h) for the agreement constraints
between the sentence-level models and the global
MRF. The Lagrangian dual is the function L(u) =
maxz g(z, u) + maxy F (y, u) where
g(z, u) = g(z) +
?
(s,m,h)?J (X)
u(s,m, h)z((s,m), h)),
F (y, u) = F (Y ) ?
?
(s,m,h)?J (X)
u(s,m, h)Ys(m,h)
In order to find minu L(u), we use subgradient de-
scent. This requires computing g(z, u) and F (y, u)
for fixed values of u, which by our assumptions from
Section 3 are efficient to calculate.
The full algorithm is given in Figure 2. We start
with the values of u initialized to 0. At each itera-
tion k, we find the best set of parses Y (k) over the
entire corpus and the best MRF assignment z(k). We
then update the value of u based on the difference
between Y (k) and z(k) and a rate parameter ?. On
the next iteration, we solve the same decoding prob-
? 0.7 ?0.8 ? 0.9 1.0
All Contexts 66.8 57.9 46.8 33.3
Head in Context 76.0 67.9 57.2 42.3
Table 1: Exploratory statistics for constraint selection.
The table shows the percentage of context types for which
the probability of the most frequent head tag is at least p.
Head in Context refers to the subset of contexts where the
most frequent head is within the context itself. Numbers
are based on Section 22 of the Wall Street Journal and are
given for contexts that appear at least 10 times.
lems modified by the new value of u. If at any point
the current solutions Y (k) and z(k) satisfy the con-
sistency constraint, we return their current values.
Otherwise, we stop at a max iteration K and return
the values from the last iteration.
We now give a theorem for the formal guarantees
of this algorithm.
Theorem 1 If for some k ? {1 . . .K} in the algo-
rithm in Figure 2, Y (k)s (m,h) = z(k)(s,m, h) for
all (s,m, h) ? J , then (Y (k), z(k)) is a solution to
the maximization problem in equation 1.
We omit the proof for brevity. It is a slight variation
of the proof given by Rush et al(2010).
7 Consistency Constraints
In this section we describe the consistency con-
straints used for the global models of parsing and
tagging.
Parsing Constraints. Recall from Section 4 that
we choose parsing constraints based on the word
context. We encourage words in similar contexts to
choose head words with similar POS tags.
We use a simple procedure to select which con-
straints to add. First define a context template to
be a set of offsets {r, . . . , s} with r ? 0 ? s that
specify the neighboring words to include in a con-
text. In the example of Figure 1, the context tem-
plate {?1, 0, 1, 2} applied to the word girls/NNS
would produce the context JJ NNS VBD RB. For
each word in the corpus, we consider all possible
templates with s? r < 4. We use only contexts that
predict the head POS of the context in the training
data with probability 1 and prefer long over short
contexts. Once we select the context of each word,
we add a consensus node for each context type in
1439
the corpus. We connect each word node to its corre-
sponding consensus node.
Local context does not fully determine the POS
tag of the head word, but for certain contexts it pro-
vides a strong signal. Table 1 shows context statis-
tics for English. For 46.8% of the contexts, the most
frequent head tag is chosen ? 90% of the time. The
pattern is even stronger for contexts where the most
frequent head tag is within the context itself. In
this case, for 57.2% of the contexts the most fre-
quent head tag is chosen ? 90% of the time. Con-
sequently, if more than one context can be selected
for a word, we favor the contexts where the most
frequent head POS is inside the context.
POS Tagging Constraints. For POS tagging, our
constraints focus on words not observed in the train-
ing data. It is well-known that each word type ap-
pears only with a small number of POS tags. In Sec-
tion 22 of the WSJ corpus, 96.35% of word types
appear with a single POS tag.
In most test sets we are unlikely to see an un-
known word more than once or twice. To fix this
sparsity issue, we import additional unannotated
sentences for each unknown word from the New
York Times Section of the NANC corpus (Graff,
1995). These sentences give additional information
for unknown word types.
Additionally, we note that morphologically re-
lated words often have similar POS tags. We can
exploit this relationship by connecting related word
types to the same consensus node. We experimented
with various morphological variants and found that
connecting a word type with the type generated by
appending the suffix ?s? was most beneficial. For
each unknown word type, we also import sentences
for its morphologically related words.
8 Experiments and Results
We experiment in two common scenarios where
parsing performance is reduced from the fully su-
pervised, in-domain case. In domain adaptation, we
train our model completely in one source domain
and test it on a different target domain. In lightly su-
pervised training, we simulate the case where only
a limited amount of annotated data is available for a
language.
Base ST Model ER
WSJ? QTB 89.63 89.99 90.43 7.7
QTB?WSJ 74.89 74.97 75.76 3.5
Table 2: Dependency parsing UAS for domain adapta-
tion. WSJ is the Penn TreeBank. QTB is the Question-
Bank. ER is error reduction. Results are significant using
the sign test with p ? 0.05.
Data for Domain Adaptation We perform do-
main adaptation experiments in English using the
WSJ PennTreebank (Marcus et al 1993) and the
QuestionBank (QTB) (Judge et al 2006). In the
WSJ ? QTB scenario, we train on sections 2-21
of the WSJ and test on the entire QTB (4000 ques-
tions). In the QTB?WSJ scenario, we train on the
entire QTB and test on section 23 of the WSJ.
Data for Lightly Supervised Training For all
English experiments, our data was taken from the
WSJ PennTreebank: training sentences from Sec-
tion 0, development sentences from Section 22, and
test sentences from Section 23. For experiments
in Bulgarian, German, Japanese, and Spanish, we
use the CONLL-X data set (Buchholz and Marsi,
2006) with training data taken from the official train-
ing files. We trained the sentence-level models with
50-500 sentences. To verify the robustness of our
results, our test sets consist of the official test sets
augmented with additional sentences from the offi-
cial training files such that each test file consists of
25,000 words. Our results on the official test sets are
very similar to the results we report and are omitted
for brevity.
Parameters The model parameters, ?1, ?2, and ?3
of the scoring function (Section 4) and ? of the
Lagrange multipliers update rule (Section 6), were
tuned on the English development data. In our dual
decomposition inference algorithm, we use K =
200 maximum iterations and tune the decay rate fol-
lowing the protocol described by Koo et al(2010).
Sentence-Level Models For dependency parsing
we utilize the second-order projective MST parser
(McDonald et al 2005)1 with the gold-standard
POS tags of the corpus. For POS tagging we use
the Stanford POS tagger (Toutanova et al 2003)2.
1http://sourceforge.net/projects/mstparser/
2http://nlp.stanford.edu/software/tagger.shtml
1440
50 100 200 500
Base ST Model (ER) Base ST Model (ER) Base ST Model (ER) Base ST Model (ER)
Jap 79.10 80.19 81.78 (12.82) 81.53 81.59 83.09 (8.45) 84.84 85.05 85.50 (4.35) 87.14 87.24 87.44 (2.33)
Eng 69.60 69.73 71.62 (6.64) 73.97 74.01 75.27 (4.99) 77.67 77.68 78.69 (4.57) 81.83 81.90 82.18 (1.93)
Spa 71.67 71.72 73.19 (5.37) 74.53 74.63 75.41 (3.46) 77.11 77.09 77.44 (1.44) 79.97 79.88 80.04 (0.35)
Bul 71.10 70.59 72.13 (3.56) 73.35 72.96 74.61 (4.73) 75.38 75.54 76.17 (3.21) 81.95 81.75 82.18 (1.27)
Ger 68.21 68.28 68.83 (1.95) 72.19 72.29 72.76 (2.05) 74.34 74.45 74.95 (2.4) 77.20 77.09 77.51 (1.4)
Table 3: Dependency parsing UAS by size of training set and language. English data is from the WSJ. Bulgarian,
German, Japanese, and Spanish data is from the CONLL-X data sets. Base is the second-order, projective dependency
parser of McDonald et al(2005). ST is a self-training model based on Reichart and Rappoport (2007). Model is the
same parser augmented with inter-sentence constraints. ER is error reduction. Using the sign test with p ? 0.05, all
50, 100, and 200 results are significant, as are Eng and Ger 500.
50 100 200 500
Base Model (ER) Base Model (ER) Base Model (ER) Base Model (ER)
Acc 79.67 81.77 (10.33) 85.42 86.37 (6.52) 88.63 89.37 (6.51) 91.59 91.98 (4.64)
Unk 62.88 67.16 (11.53) 71.10 73.32 (7.68) 75.82 78.07 (9.31) 80.67 82.28 (8.33)
Table 4: POS tagging accuracy. Stanford POS tagger refers to the maximum entropy trigram tagger of Toutanova et
al. (2003). Our inter-sentence POS tagger augments this baseline with global constraints. ER is error reduction. All
results are significant using the sign test with p ? 0.05.
Evaluation and Baselines To measure parsing
performance, we use unlabeled attachment score
(UAS) given by the CONLL-X dependency parsing
shared task evaluation script (Buchholz and Marsi,
2006). We compare the accuracy of dependency
parsing with global constraints to the sentence-level
dependency parser of McDonald et al(2005) and to
a self-training baseline (Steedman et al 2003; Re-
ichart and Rappoport, 2007). The parsing baseline is
equivalent to a single round of dual decomposition.
For the self-training baseline, we parse the test cor-
pus, append the labeled test sentences to the training
corpus, train a new parser, and then re-parse the test
set. We run this procedure for a single iteration.
For POS tagging we measure token level POS ac-
curacy for all the words in the corpus and also for
unknown words (words not observed in the train-
ing data). We compare the accuracy of POS tagging
with global constraints to the accuracy of the Stan-
ford POS tagger 3.
Domain Adaptation Accuracy Results are pre-
sented in Table 2. The constrained model reduces
the error of the baseline on both cases. Note that
when the base parser is trained on the WSJ corpus its
UAS performance on the QTB is 89.63%. Yet, the
constrained model is still able to reduce the baseline
error by 7.7%.
3We do not run self-training for POS tagging as it has been
shown unuseful for this application (Clark et al 2003).
Lightly Supervised Accuracy The parsing results
are given in Table 3. Our model improves over
the baseline parser and self-training across all lan-
guages and training set sizes. The best results are
for Japanese and English with error reductions of
2.33 ? 12.82% and 1.93 ? 6.64% respectively. The
self-training baseline achieves small gains on some
languages, but generally performs similarly to the
standard parser.
The POS tagging results are given in Table 4. Our
model improves over the baseline tagger for the en-
tire training size range. For 50 training sentences
we reduce 10.33% of the overall error, and 11.53%
of the error on unknown words. Although the tagger
performance substantially improves when the train-
ing set grows to 500 sentences, our model still pro-
vides an overall error reduction of 4.64% and of
8.33% for unknown words.
9 Discussion
Efficiency Since dual decomposition often re-
quires hundreds of iterations to converge, a naive im-
plementation would be orders of magnitude slower
than the underlying sentence-level model. We use
two techniques to speed-up the algorithm.
First, we follow Koo et al(2010) and use lazy
decoding as part of dual decomposition. At each it-
eration k, we cache the result of the MRF z(k) and
set of parse tree Y (k). In the next iteration, we only
1441
50 100 150 200iteration0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
percen
tage of
 parsin
g time
englishgermanjapanese
Figure 3: Efficiency of dependency parsing decoding for
three languages. The plot shows the speed of each iter-
ation of the subgradient algorithm relative to a round of
unconstrained parsing.
Most Effective Contexts
WSJ? QTB QTB?WSJ
WRB VBP VBD NN NN ,
DT JJS NN IN IN PRP VBZ
VBP PRP VB JJ JJ NN ,
DT NN NN VB IN JJ JJ NN
RBS JJ NN IN NN POS NN NN
Table 5: The five most effective constraint contexts from
the domain adaptation experiments. The bold POS tag
indicates the modifier word of the context.
Where/
WRB
VBN
are/
VBP
diamonds/
NNS
mined/
VBN
?
How/
WRB
VBP
do/
VBP
you/
PRP
measure/
VB
earthquakes/
NNS
?
Why/
WRB
VBP
do/
VBP
people/
NNS
get/
VB
calluses/
NNS
?
VBP
Figure 4: Subset of sentences with the context WRB VBP
from WSJ? QTB domain adaptation. In the first round,
the parser chooses VBN for the first sentence, which is in-
consistent with similar contexts. The constraints correct
this choice in later rounds.
recompute the solution Y ?s for a sentence s if the
weight u(s,m, h) for some m,h was updated. A
similar technique is applied to the MRF.
Second, during the first iteration of the algorithm
we apply max-marginal based pruning using the
threshold defined by Weiss and Taskar (2010). This
produces a pruned hypergraph for each sentence,
which allows us to avoid recomputing parse features
and to solve a simplified search problem.
To measure efficiency, we compare the time spent
in dual decomposition to the speed of unconstrained
inference. Across experiments, the mean dual de-
composition time is 1.71 times the cost of uncon-
strained inference. Figure 3 shows how this time is
spent after the first iteration. The early iterations are
around 1% of the total cost, and because of lazy de-
coding this quickly drops to almost nothing.
Exactness To measure exactness, we count the
number of sentences for which we should remove
the constraints in order for the model to reach con-
vergence. For dependency parsing, across languages
removing constraints on 0.6% of sentences yields
exact convergence. Removing these constraints has
very little effect on the final outcome of the model.
For POS tagging, the algorithm finds an exact so-
lution after removing constraints from 0.2% of the
sentences.
Constraint Analysis We can also look at the num-
ber, size, and outcome of the constraints chosen in
the experiments. In the lightly supervised experi-
ments, the average number of constraints is 3298 for
25000 tokens, where the median constraint connects
19 different tokens. Of these constraints around 70%
are active (non-NULL). The domain adaptation ex-
periments have a similar number of constraints with
around 75% of constraints active. In both experi-
ments many of the constraints are found to be con-
sistent after the first iteration, but as Figure 3 im-
plies, other constraints take multiple iterations to
converge.
Qualitative Analysis In order to understand why
these simple consistency constraints are effective,
we take a qualitative look at the the domain adap-
tation experiments on the QuestionBank. Table 5
ranks the five most effective contextual constraints
from both experiments. For the WSJ? QTB exper-
iment, the most effective constraint relates the inital
question word with an adjacent verb. Figure 4 shows
1442
sentences where this constraint applies in the Ques-
tionBank. For the QTB?WSJ experiment, the ef-
fective contexts are mostly long base noun phrases.
These occur often in the WSJ but are rare in the sim-
pler QuestionBank sentences.
10 Conclusion
In this work we experiment with inter-sentence
consistency constraints for dependency parsing and
POS tagging. We have proposed a corpus-level ob-
jective that augments sentence-level models with
such constraints and described an exact and effi-
cient dual decomposition algorithm for its decod-
ing. In future work, we intend to explore efficient
techniques for joint parameter learning for both the
global MRF and the local models.
Acknowledgments Columbia University gratefully
acknowledges the support of the Defense Advanced Re-
search Projects Agency (DARPA) Machine Reading Pro-
gram under Air Force Research Laboratory (AFRL)
prime contract no. FA8750-09-C-0181. Any opinions,
findings, and conclusions or recommendations expressed
in this material are those of the author(s) and do not
necessarily reflect the view of DARPA, AFRL, or the
US government. Alexander Rush was supported by a
National Science Foundation Graduate Research Fellow-
ship.
References
Y. Altun and D. Mcallester. 2005. Maximum margin
semi-supervised learning for structured variables. In
NIPS.
M. Belkin, P. Niyogi, and V. Sindhwani. 2005. On man-
ifold regularization. In AISTATS.
John Blitzer and Hal Daume. 2010. Icml 2010 tutorial
on domain adaptation. In ICML.
U. Brefeld and T. Scheffer. 2006. Semi-supervised learn-
ing for structured output variables. In ICML.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared task
on multilingual dependency parsing. In CoNLL.
R.C. Bunescu and R.J. Mooney. 2004. Collective infor-
mation extraction with relational markov networks. In
ACL.
J.C.K Cheung and G. Penn. 2010. Utilizing extra-
sentential context for parsing. In EMNLP.
Stephen Clark, James Curran, and Miles Osborne. 2003.
Bootstrapping pos taggers using unlabelled data. In
CoNLL.
A. Dubey, F. Keller, and P. Sturt. 2009. A proba-
bilistic corpus-based model of parallelism. Cognition,
109(2):193?210.
Jenny Rose Finkel and Christopher Manning. 2009. Hi-
erarchical bayesian domain adaptation. In NAACL.
J.R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information ex-
traction systems by gibbs sampling. In ACL.
K. Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.
2010. Posterior Regularization for Structured Latent
Variable Models. Journal of Machine Learning Re-
search, 11:2001?2049.
J. Gillenwater, K. Ganchev, J. Grac?a, F. Pereira, and
B. Taskar. 2010. Sparsity in dependency grammar in-
duction. In Proceedings of the ACL Conference Short
Papers.
A. Globerson and T. Jaakkola. 2007. Fixing max-
product: Convergent message passing algorithms for
map lp-relaxations. In NIPS.
D. Graff. 1995. North american news text corpus. Lin-
guistic Data Consortium, LDC95T21.
Rahul Gupta, Sunita Sarawagi, and Ajit A. Diwan. 2010.
Collective inference for extraction mrfs coupled with
symmetric clique potentials. JMLR.
R. Hwa. 2004. Sample selection for statistical parsing.
Computational Linguistics, 30(3):253?276.
John Judge, Aoife Cahill, and Josef van Genabith. 2006.
Questionbank: Creating a corpus of parse-annotated
questions. In ACL-COLING.
D. Koller and N. Friedman. 2009. Probabilistic Graphi-
cal Models: Principles and Techniques. MIT Press.
N. Komodakis, N. Paragios, and G. Tziritas. 2007.
MRF optimization via dual decomposition: Message-
passing revisited. In ICCV.
T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Son-
tag. 2010. Dual decomposition for parsing with non-
projective head automata. In EMNLP.
Matthew Lease and Eugene Charniak. 2005. Parsing
biomedical literature. In IJCNLP.
P. Liang, M. I. Jordan, and D. Klein. 2009. Learning
from measurements in exponential families. In ICML.
G.S. Mann and A. McCallum. Generalized expectation
criteria for semi-supervised learning with weakly la-
beled data. Journal of Machine Learning Research,
11:955?984.
G.S. Mann and A. McCallum. 2007. Simple, robust,
scalable semi-supervised learning via expectation reg-
ularization. In ICML.
M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of en-
glish: The penn treebank. Computational linguistics,
19(2):313?330.
1443
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In ACL, sort papers.
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Reranking and self-training for parser adapta-
tion. In ACL.
David McClosky, Eugene Charniak, and Mark Johnson.
2010. Automatic domain adapatation for parsing. In
NAACL.
R.T. McDonald, F. Pereira, K. Ribarov, and J. Hajic.
2005. Non-projective dependency parsing using span-
ning tree algorithms. In HLT/EMNLP.
Barbara Plank. 2011. Domain Adaptation for Parsing.
Ph.d. thesis, University of Groningen.
R. Reichart and A. Rappoport. 2007. Self-training
for enhancement and domain adaptation of statistical
parsers trained on small datasets. In ACL.
Laura Rimell and Stephen Clark. 2008. Adapting a
lexicalized-grammar parser to contrasting domains. In
EMNLP.
D. Roth and W. Yih. 2005. Integer linear programming
inference for conditional random fields. In ICML.
A.M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On dual decomposition and linear program-
ming relaxations for natural language processing. In
EMNLP.
Kenji Sagae and Junichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with lr models and parser
ensembles. In EMNLP-CoNLL.
D.A. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In EMNLP.
M. Steedman, M. Osborne, A. Sarkar, S. Clark, R. Hwa,
J. Hockenmaier, P. Ruhlen, S. Baker, and J. Crim.
2003. Bootstrapping statistical parsers from small
datasets. In EACL.
Amarnag Subramanya, Slav Petrov, and Fernando
Pereira. 2010. Efficient graph-based semi-supervised
learning of structured tagging models. In EMNLP.
C. Sutton and A. Mccallum. 2004. Collective segmen-
tation and labeling of distant entities in information
extraction. In In ICML Workshop on Statistical Re-
lational Learning and Its Connections.
B. Taskar, P. Abbeel, and d. Koller. 2002. Discriminative
probabilistic models for relational data. In UAI.
K. Toutanova, D. Klein, C.D. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In HLT-NAACL.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005. MAP
estimation via agreement on trees: message-passing
and linear programming. In IEEE Transactions on In-
formation Theory, volume 51, pages 3697?3717.
Y. Wang, G. Haffari, S. Wang, and G. Mori. 2009.
A rate distortion approach for semi-supervised condi-
tional random fields. In NIPS.
D. Weiss and B. Taskar. 2010. Structured prediction cas-
cades. In Proc. of AISTATS, volume 1284.
1444
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 210?221,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Optimal Beam Search for Machine Translation
Alexander M. Rush Yin-Wen Chang
MIT CSAIL,
Cambridge, MA 02139, USA
{srush, yinwen}@csail.mit.edu
Michael Collins
Department of Computer Science,
Columbia University,
New York, NY 10027, USA
mcollins@cs.columbia.edu
Abstract
Beam search is a fast and empirically effective
method for translation decoding, but it lacks
formal guarantees about search error. We de-
velop a new decoding algorithm that combines
the speed of beam search with the optimal cer-
tificate property of Lagrangian relaxation, and
apply it to phrase- and syntax-based transla-
tion decoding. The new method is efficient,
utilizes standard MT algorithms, and returns
an exact solution on the majority of transla-
tion examples in our test data. The algorithm
is 3.5 times faster than an optimized incremen-
tal constraint-based decoder for phrase-based
translation and 4 times faster for syntax-based
translation.
1 Introduction
Beam search (Koehn et al, 2003) and cube prun-
ing (Chiang, 2007) have become the de facto decod-
ing algorithms for phrase- and syntax-based trans-
lation. The algorithms are central to large-scale
machine translation systems due to their efficiency
and tendency to produce high-quality translations
(Koehn, 2004; Koehn et al, 2007; Dyer et al, 2010).
However despite practical effectiveness, neither al-
gorithm provides any bound on possible decoding
error.
In this work we present a variant of beam search
decoding for phrase- and syntax-based translation.
The motivation is to exploit the effectiveness and ef-
ficiency of beam search, but still maintain formal
guarantees. The algorithm has the following bene-
fits:
? In theory, it can provide a certificate of optimal-
ity; in practice, we show that it produces opti-
mal hypotheses, with certificates of optimality,
on the vast majority of examples.
? It utilizes well-studied algorithms and extends
off-the-shelf beam search decoders.
? Empirically it is very fast, results show that it is
3.5 times faster than an optimized incremental
constraint-based solver.
While our focus is on fast decoding for machine
translation, the algorithm we present can be applied
to a variety of dynamic programming-based decod-
ing problems. The method only relies on having a
constrained beam search algorithm and a fast uncon-
strained search algorithm. Similar algorithms exist
for many NLP tasks.
We begin in Section 2 by describing constrained
hypergraph search and showing how it generalizes
translation decoding. Section 3 introduces a variant
of beam search that is, in theory, able to produce
a certificate of optimality. Section 4 shows how to
improve the effectiveness of beam search by using
weights derived from Lagrangian relaxation. Sec-
tion 5 puts everything together to derive a fast beam
search algorithm that is often optimal in practice.
Experiments compare the new algorithm with
several variants of beam search, cube pruning, A?
search, and relaxation-based decoders on two trans-
lation tasks. The optimal beam search algorithm is
able to find exact solutions with certificates of opti-
mality on 99% of translation examples, significantly
more than other baselines. Additionally the optimal
210
beam search algorithm is much faster than other ex-
act methods.
2 Background
The focus of this work is decoding for statistical ma-
chine translation. Given a source sentence, the goal
is to find the target sentence that maximizes a com-
bination of translation model and language model
scores. In order to analyze this decoding problem,
we first abstract away from the specifics of transla-
tion into a general form, known as a hypergraph. In
this section, we describe the hypergraph formalism
and its relation to machine translation.
2.1 Notation
Throughout the paper, scalars and vectors are writ-
ten in lowercase, matrices are written in uppercase,
and sets are written in script-case, e.g. X . All vec-
tors are assumed to be column vectors. The function
?(j) yields an indicator vector with ?(j)j = 1 and
?(j)i = 0 for all i 6= j.
2.2 Hypergraphs and Search
A directed hypergraph is a pair (V, E) where V =
{1 . . . |V|} is a set of vertices, and E is a set of di-
rected hyperedges. Each hyperedge e ? E is a tuple?
?v2, . . . , v|v|?, v1
?
where vi ? V for i ? {1 . . . |v|}.
The head of the hyperedge is h(e) = v1. The tail
of the hyperedge is the ordered sequence t(e) =
?v2, . . . , v|v|?. The size of the tail |t(e)| may vary
across different hyperedges, but |t(e)| ? 1 for all
edges and is bounded by a constant. A directed
graph is a directed hypergraph with |t(e)| = 1 for
all edges e ? E .
Each vertex v ? V is either a non-terminal or a
terminal in the hypergraph. The set of non-terminals
is N = {v ? V : h(e) = v for some e ? E}. Con-
versely, the set of terminals is defined as T = V\N .
All directed hypergraphs used in this work are
acyclic: informally this implies that no hyperpath (as
defined below) contains the same vertex more than
once (see Martin et al (1990) for a full definition).
Acyclicity implies a partial topological ordering of
the vertices. We also assume there is a distinguished
root vertex 1 where for all e ? E , 1 6? t(e).
Next we define a hyperpath as x ? {0, 1}|E| where
x(e) = 1 if hyperedge e is used in the hyperpath,
procedure BESTPATHSCORE(?, ? )
pi[v]? 0 for all v ? T
for e ? E in topological order do
??v2, . . . , v|v|?, v1? ? e
s? ?(e) +
|v|?
i=2
pi[vi]
if s > pi[v1] then pi[v1]? s
return pi[1] + ?
Figure 1: Dynamic programming algorithm for uncon-
strained hypergraph search. Note that this version only
returns the highest score: maxx?X ?>x+ ? . The optimal
hyperpath can be found by including back-pointers.
x(e) = 0 otherwise. The set of valid hyperpaths is
defined as
X =
?
?????
?????
x :
?
e?E:h(e)=1
x(e) = 1,
?
e:h(e)=v
x(e) =
?
e:v?t(e)
x(e) ? v ? N \ {1}
?
?????
?????
The first problem we consider is unconstrained hy-
pergraph search. Let ? ? R|E| be the weight vector
for the hypergraph and let ? ? R be a weight offset.1
The unconstrained search problem is to find
max
x?X
?
e?E
?(e)x(e) + ? = max
x?X
?>x+ ?
This maximization can be computed for any
weights and directed acyclic hypergraph in time
O(|E|) using dynamic programming. Figure 1
shows this algorithm which is simply a version of
the CKY algorithm.
Next consider a variant of this problem: con-
strained hypergraph search. Constraints will be nec-
essary for both phrase- and syntax-based decoding.
In phrase-based models, the constraints will ensure
that each source word is translated exactly once. In
syntax-based models, the constraints will be used to
intersect a translation forest with a language model.
In the constrained hypergraph problem, hyper-
paths must fulfill additional linear hyperedge con-
straints. Define the set of constrained hyperpaths as
X ? = {x ? X : Ax = b}
1The purpose of the offset will be clear in later sections. For
this section, the value of ? can be taken as 0.
211
where we have a constraint matrix A ? R|b|?|E|
and vector b ? R|b| encoding |b| constraints.
The optimal constrained hyperpath is x? =
arg maxx?X ? ?>x+ ? .
Note that the constrained hypergraph search prob-
lem may be NP-Hard. Crucially this is true even
when the corresponding unconstrained search prob-
lem is solvable in polynomial time. For instance,
phrase-based decoding is known to be NP-Hard
(Knight, 1999), but we will see that it can be ex-
pressed as a polynomial-sized hypergraph with con-
straints.
Example: Phrase-Based Machine Translation
Consider translating a source sentencew1 . . . w|w| to
a target sentence in a language with vocabulary ?. A
simple phrase-based translation model consists of a
tuple (P, ?, ?) with
? P; a set of pairs (q, r) where q1 . . . q|q| is a se-
quence of source-language words and r1 . . . r|r|
is a sequence of target-language words drawn
from the target vocabulary ?.
? ? : R|P|; parameters for the translation model
mapping each pair in P to a real-valued score.
? ? : R|???|; parameters of the language model
mapping a bigram of target-language words to
a real-valued score.
The translation decoding problem is to find the
best derivation for a given source sentence. A
derivation consists of a sequence of phrases p =
p1 . . . pn. Define a phrase as a tuple (q, r, j, k)
consisting of a span in the source sentence q =
wj . . . wk and a sequence of target words r1 . . . r|r|,
with (q, r) ? P . We say the source words wj . . . wk
are translated to r.
The score of a derivation, f(p), is the sum of the
translation score of each phrase plus the language
model score of the target sentence
f(p) =
n?
i=1
?(q(pi), r(pi)) +
|u|+1?
i=0
?(ui?1, ui)
where u is the sequence of words in ? formed
by concatenating the phrases r(p1) . . . r(pn), with
boundary cases u0 = <s> and u|u|+1 = </s>.
Crucially for a derivation to be valid it must sat-
isfy an additional condition: it must translate every
source word exactly once. The decoding problem
for phrase-based translation is to find the highest-
scoring derivation satisfying this property.
We can represent this decoding problem as a con-
strained hypergraph using the construction of Chang
and Collins (2011). The hypergraph weights en-
code the translation and language model scores, and
its structure ensures that the count of source words
translated is |w|, i.e. the length of the source sen-
tence. Each vertex will remember the preceding
target-language word and the count of source words
translated so far.
The hypergraph, which for this problem is also a
directed graph, takes the following form.
? Vertices v ? V are labeled (c, u) where c ?
{1 . . . |w|} is the count of source words trans-
lated and u ? ? is the last target-language word
produced by a partial hypothesis at this vertex.
Additionally there is an initial terminal vertex
labeled (0,<s>).
? There is a hyperedge e ? E with head (c?, u?)
and tail ?(c, u)? if there is a valid corresponding
phrase (q, r, j, k) such that c? = c + |q| and
u? = r|r|, i.e. c
? is the count of words translated
and u? is the last word of target phrase r. We
call this phrase p(e).
The weight of this hyperedge, ?(e), is the trans-
lation model score of the pair plus its language
model score
?(e) = ?(q, r)+
?
?
|r|?
i=2
?(ri?1, ri)
?
?+?(u, r1)
? To handle the end boundary, there are hyper-
edges with head 1 and tail ?(|w|, u)? for all
u ? ?. The weight of these edges is the cost of
the stop bigram following u, i.e. ?(u,</s>).
While any valid derivation corresponds to a hy-
perpath in this graph, a hyperpath may not corre-
spond to a valid derivation. For instance, a hyper-
path may translate some source words more than
once or not at all.
212
Figure 2: Hypergraph for translating the sentence w = les1 pauvres2 sont3 demunis4 with set of pairs P =
{(les, the), (pauvres, poor), (sont demunis, don?t have any money)}. Hyperedges are color-coded
by source words translated: orange for les1, green for pauvres2, and red for sont3 demunis4. The dotted lines
show an invalid hyperpath x that has signature Ax = ?0, 0, 2, 2? 6= ?1, 1, 1, 1? .
We handle this problem by adding additional con-
straints. For all source words i ? {1 . . . |w|}, define
? as the set of hyperedges that translate wi
?(i) = {e ? E : j(p(e)) ? i ? k(p(e))}
Next define |w| constraints enforcing that each word
in the source sentence is translated exactly once
?
e??(i)
x(e) = 1 ? i ? {1 . . . |w|}
These linear constraints can be represented with
a matrix A ? {0, 1}|w|?|E| where the rows corre-
spond to source indices and the columns correspond
to edges. We call the product Ax the signature,
where in this case (Ax)i is the number of times word
i has been translated. The full set of constrained hy-
perpaths is X ? = {x ? X : Ax = 1 }, and the best
derivation under this phrase-based translation model
has score maxx?X ? ?>x+ ? .
Figure 2.2 shows an example hypergraph
with constraints for translating the sentence les
pauvres sont demunis into English using
a simple set of phrases. Even in this small exam-
ple, many of the possible hyperpaths violate the
constraints and correspond to invalid derivations.
Example: Syntax-Based Machine Translation
Syntax-based machine translation with a language
model can also be expressed as a constrained hyper-
graph problem. For the sake of space, we omit the
definition. See Rush and Collins (2011) for an in-
depth description of the constraint matrix used for
syntax-based translation.
3 A Variant of Beam Search
This section describes a variant of the beam
search algorithm for finding the highest-scoring con-
strained hyperpath. The algorithm uses three main
techniques: (1) dynamic programming with ad-
ditional signature information to satisfy the con-
straints, (2) beam pruning where some, possibly op-
timal, hypotheses are discarded, and (3) branch-and-
bound-style application of upper and lower bounds
to discard provably non-optimal hypotheses.
Any solution returned by the algorithm will be a
valid constrained hyperpath and a member of X ?.
Additionally the algorithm returns a certificate flag
opt that, if true, indicates that no beam pruning
was used, implying the solution returned is opti-
mal. Generally it will be hard to produce a certificate
even by reducing the amount of beam pruning; how-
ever in the next section we will introduce a method
based on Lagrangian relaxation to tighten the upper
bounds. These bounds will help eliminate most so-
lutions before they trigger pruning.
3.1 Algorithm
Figure 3 shows the complete beam search algorithm.
At its core it is a dynamic programming algorithm
filling in the chart pi. The beam search chart indexes
hypotheses by vertex v ? V as well as a signature
sig ? R|b| where |b| is the number of constraints. A
new hypothesis is constructed from each hyperedge
and all possible signatures of tail nodes. We define
the function SIGS to take the tail of an edge and re-
213
turn the set of possible signature combinations
SIGS(v2, . . . v|v|) =
|v|?
i=2
{sig : pi[vi, sig] 6= ??}
where the product is the Cartesian product over sets.
Line 8 loops over this entire set.2 For hypothesis x,
the algorithm ensures that its signature sig is equal
to Ax. This property is updated on line 9.
The signature provides proof that a hypothesis is
still valid. Let the function CHECK(sig) return true
if the hypothesis can still fulfill the constraints. For
example, in phrase-based decoding, we will define
CHECK(sig) = (sig ? 1); this ensures that each
word has been translated 0 or 1 times. This check is
applied on line 11.
Unfortunately maintaining all signatures is inef-
ficient. For example we will see that in phrase-
based decoding the signature is a bit-string recording
which source words have been translated; the num-
ber of possible bit-strings is exponential in the length
of the sentence. The algorithm includes two meth-
ods for removing hypotheses, bounding and prun-
ing.
Bounding allows us to discard provably non-
optimal solutions. The algorithm takes as arguments
a lower bound on the optimal score lb ? ?>x? + ? ,
and computes upper bounds on the outside score
for all vertices v: ubs[v], i.e. an overestimate of
the score for completing the hyperpath from v. If
a hypothesis has score s, it can only be optimal if
s+ ubs[v] ? lb. This bound check is performed on
line 11.
Pruning removes weak partial solutions based on
problem-specific checks. The algorithm invokes the
black-box function, PRUNE, on line 13, passing it
a pruning parameter ? and a vertex-signature pair.
The parameter ? controls a threshold for pruning.
For instance for phrase-based translation, it specifies
a hard-limit on the number of hypotheses to retain.
The function returns true if it prunes from the chart.
Note that pruning may remove optimal hypotheses,
so we set the certificate flag opt to false if the chart
is modified.
2For simplicity we write this loop over the entire set. In
practice it is important to use data structures to optimize look-
up. See Tillmann (2006) and Huang and Chiang (2005).
1: procedure BEAMSEARCH(?, ?, lb, ?)
2: ubs? OUTSIDE(?, ?)
3: opt? true
4: pi[v, sig]? ?? for all v ? V, sig ? R|b|
5: pi[v, 0]? 0 for all v ? T
6: for e ? E in topological order do
7: ??v2, . . . , v|v|?, v1? ? e
8: for sig(2) . . . sig(|v|) ? SIGS(v2, . . . , v|v|) do
9: sig ? A?(e) +
|v|?
i=2
sig(i)
10: s? ?(e) +
|v|?
i=2
pi[vi, sig
(i)]
11: if
?
?
s > pi[v1, sig] ?
CHECK(sig) ?
s+ ubs[v1] ? lb
?
? then
12: pi[v1, sig]? s
13: if PRUNE(pi, v1, sig, ?) then opt? false
14: lb? ? pi[1, c] + ?
15: return lb?, opt
Input:
?
?
?
?
(V, E , ?, ?) hypergraph with weights
(A, b) matrix and vector for constraints
lb ? R lower bound
? a pruning parameter
Output:
[
lb? resulting lower bound score
opt certificate of optimality
Figure 3: A variant of the beam search algorithm. Uses
dynamic programming to produce a lower bound on the
optimal constrained solution and, possibly, a certificate of
optimality. Function OUTSIDE computes upper bounds
on outside scores. Function SIGS enumerates all possi-
ble tail signatures. Function CHECK identifies signatures
that do not violate constraints. Bounds lb and ubs are
used to remove provably non-optimal solutions. Func-
tion PRUNE, taking parameter ?, returns true if it prunes
hypotheses from pi that could be optimal.
This variant on beam search satisfies the follow-
ing two properties (recall x? is the optimal con-
strained solution)
Property 3.1 (Primal Feasibility). The returned
score lb? lower bounds the optimal constrained
score, that is lb? ? ?>x? + ? .
Property 3.2 (Dual Certificate). If beam search re-
turns with opt = true, then the returned score is
optimal, i.e. lb? = ?>x? + ? .
An immediate consequence of Property 3.1 is that
the output of beam search, lb?, can be used as the in-
put lb for future runs of the algorithm. Furthermore,
214
procedure PRUNE(pi, v, sig, ?)
C ? {(v?, sig?) : ||sig?||1 = ||sig||1,
pi[v?, sig?] 6= ??}
D ? C \mBEST(?, C, pi)
pi[v?, sig?]? ?? for all v?, sig? ? D
if D = ? then return true
else return false
Input:
[
(v, sig) the last hypothesis added to the chart
? ? Z # of hypotheses to retain
Output: true, if pi is modified
Figure 4: Pruning function for phrase-based translation.
Set C contains all hypotheses with ||sig||1 source words
translated. The function prunes all but the top-? scoring
hypotheses in this set.
if we loosen the amount of beam pruning by adjust-
ing the pruning parameter ? we can produce tighter
lower bounds and discard more hypotheses. We can
then iteratively apply this idea with a sequence of
parameters ?1 . . . ?K producing lower bounds lb(1)
through lb(K). We return to this idea in Section 5.
Example: Phrase-based Beam Search. Recall
that the constraints for phrase-based translation con-
sist of a binary matrix A ? {0, 1}|w|?|E| and vec-
tor b = 1. The value sigi is therefore the num-
ber of times source word i has been translated in
the hypothesis. We define the predicate CHECK as
CHECK(sig) = (sig ? 1) in order to remove hy-
potheses that already translate a source word more
than once, and are therefore invalid. For this reason,
phrase-based signatures are called bit-strings.
A common beam pruning strategy is to group
together items into a set C and retain a (possibly
complete) subset. An example phrase-based beam
pruner is given in Figure 4. It groups together
hypotheses based on ||sigi||1, i.e. the number of
source words translated, and applies a hard pruning
filter that retains only the ? highest-scoring items
(v, sig) ? C based on pi[v, sig].
3.2 Computing Upper Bounds
Define the setO(v, x) to contain all outside edges of
vertex v in hyperpath x (informally, hyperedges that
do not have v as an ancestor). For all v ? V , we set
the upper bounds, ubs, to be the best unconstrained
outside score
ubs[v] = max
x?X :v?x
?
e?O(v,x)
?(e) + ?
This upper bound can be efficiently computed for
all vertices using the standard outside dynamic pro-
gramming algorithm. We will refer to this algorithm
as OUTSIDE(?, ? ).
Unfortunately, as we will see, these upper bounds
are often quite loose. The issue is that unconstrained
outside paths are able to violate the constraints with-
out being penalized, and therefore greatly overesti-
mate the score.
4 Finding Tighter Bounds with
Lagrangian Relaxation
Beam search produces a certificate only if beam
pruning is never used. In the case of phrase-based
translation, the certificate is dependent on all groups
C having ? or less hypotheses. The only way to en-
sure this is to bound out enough hypotheses to avoid
pruning. The effectiveness of the bounding inequal-
ity, s + ubs[v] < lb, in removing hypotheses is di-
rectly dependent on the tightness of the bounds.
In this section we propose using Lagrangian re-
laxation to improve these bounds. We first give a
brief overview of the method and then apply it to
computing bounds. Our experiments show that this
approach is very effective at finding certificates.
4.1 Algorithm
In Lagrangian relaxation, instead of solving the con-
strained search problem, we relax the constraints
and solve an unconstrained hypergraph problem
with modified weights. Recall the constrained hy-
pergraph problem: max
x?X :Ax=b
?>x + ? . The La-
grangian dual of this optimization problem is
L(?) = max
x?X
?>x+ ? ? ?>(Ax? b)
=
(
max
x?X
(? ?A>?)>x
)
+ ? + ?>b
= max
x?X
??>x+ ? ?
where ? ? R|b| is a vector of dual variables and
define ?? = ? ? A>? and ? ? = ? + ?>b. This
maximization is over X , so for any value of ?, L(?)
can be calculated as BestPathScore(??, ? ?).
Note that for all valid constrained hyperpaths x ?
X ? the termAx?b equals 0, which implies that these
hyperpaths have the same score under the modified
weights as under the original weights, ?>x + ? =
??>x+? ?. This leads to the following two properties,
215
procedure LRROUND(?k, ?)
x? arg max
x?X
?>x+ ? ? ?>(Ax? b)
?? ? ?? ?k(Ax? b)
opt? Ax = b
ub? ?>x+ ?
return ??,ub, opt
procedure LAGRANGIANRELAXATION(?)
?(0) ? 0
for k in 1 . . .K do
?(k),ub, opt? LRROUND(?k, ?(k?1))
if opt then return ?(k),ub, opt
return ?(K),ub, opt
Input: ?1 . . . ?K sequence of subgradient rates
Output:
?
?
? final dual vector
ub upper bound on optimal constrained solution
opt certificate of optimality
Figure 5: Lagrangian relaxation algorithm. The algo-
rithm repeatedly calls LRROUND to compute the subgra-
dient, update the dual vector, and check for a certificate.
where x ? X is the hyperpath computed within the
max,
Property 4.1 (Dual Feasibility). The valueL(?) up-
per bounds the optimal solution, that is L(?) ?
?>x? + ?
Property 4.2 (Primal Certificate). If the hyperpath
x is a member of X ?, i.e. Ax = b, then L(?) =
?>x? + ? .
Property 4.1 states that L(?) always produces
some upper bound; however, to help beam search,
we want as tight a bound as possible: min? L(?).
The Lagrangian relaxation algorithm, shown in
Figure 5, uses subgradient descent to find this min-
imum. The subgradient of L(?) is Ax ? b where
x is the argmax of the modified objective x =
arg maxx?X ??>x + ? ?. Subgradient descent itera-
tively solves unconstrained hypergraph search prob-
lems to compute these subgradients and updates ?.
See Rush and Collins (2012) for an extensive discus-
sion of this style of optimization in natural language
processing.
Example: Phrase-based Relaxation. For phrase-
based translation, we expand out the Lagrangian to
L(?) = max
x?X
?>x+ ? ? ?>(Ax? b) =
max
x?X
?
e?E
?
??(e)?
k(p(e))?
i=j(p(e))
?i
?
?x(e) + ? +
|s|?
i=1
?i
The weight of each edge ?(e) is modified by the
dual variables ?i for each source word translated by
the edge, i.e. if (q, r, j, k) = p(e), then the score
is modified by
?k
i=j ?i. A solution under these
weights may use source words multiple times or not
at all. However if the solution uses each source word
exactly once (Ax = 1), then we have a certificate
and the solution is optimal.
4.2 Utilizing Upper Bounds in Beam Search
For many problems, it may not be possible to satisfy
Property 4.2 by running the subgradient algorithm
alone. Yet even for these problems, applying sub-
gradient descent will produce an improved estimate
of the upper bound, min? L(?).
To utilize these improved bounds, we simply re-
place the weights in beam search and the outside al-
gorithm with the modified weights from Lagrangian
relaxation, ?? and ? ?. Since the result of beam search
must be a valid constrained hyperpath x ? X ?, and
for all x ? X ?, ?>x + ? = ??>x + ? ?, this sub-
stitution does not alter the necessary properties of
the algorithm; i.e. if the algorithm returns with opt
equal to true, then the solution is optimal.
Additionally the computation of upper bounds
now becomes
ubs[v] = max
x?X :v?x
?
e?O(v,x)
??(e) + ? ?
These outside paths may still violate constraints, but
the modified weights now include penalty terms to
discourage common violations.
5 Optimal Beam Search
The optimality of the beam search algorithm is de-
pendent on the tightness of the upper and lower
bounds. We can produce better lower bounds by
varying the pruning parameter ?; we can produce
better upper bounds by running Lagrangian relax-
ation. In this section we combine these two ideas
and present a complete optimal beam search algo-
rithm.
Our general strategy will be to use Lagrangian
relaxation to compute modified weights and to use
beam search over these modified weights to attempt
to find an optimal solution. One simple method for
doing this, shown at the top of Figure 6, is to run
216
in stages. The algorithm first runs Lagrangian relax-
ation to compute the best ? vector. The algorithm
then iteratively runs beam search using the parame-
ter sequence ?k. These parameters allow the algo-
rithm to loosen the amount of beam pruning. For
example in phrase based pruning, we would raise
the number of hypotheses stored per group until no
beam pruning occurs.
A clear disadvantage of the staged approach is
that it needs to wait until Lagrangian relaxation is
completed before even running beam search. Of-
ten beam search will be able to quickly find an opti-
mal solution even with good but non-optimal ?. In
other cases, beam search may still improve the lower
bound lb.
This motivates the alternating algorithm OPT-
BEAM shown Figure 6. In each round, the algo-
rithm alternates between computing subgradients to
tighten ubs and running beam search to maximize
lb. In early rounds we set ? for aggressive beam
pruning, and as the upper bounds get tighter, we
loosen pruning to try to get a certificate. If at any
point either a primal or dual certificate is found, the
algorithm returns the optimal solution.
6 Related Work
Approximate methods based on beam search and
cube-pruning have been widely studied for phrase-
based (Koehn et al, 2003; Tillmann and Ney, 2003;
Tillmann, 2006) and syntax-based translation mod-
els (Chiang, 2007; Huang and Chiang, 2007; Watan-
abe et al, 2006; Huang and Mi, 2010).
There is a line of work proposing exact algorithms
for machine translation decoding. Exact decoders
are often slow in practice, but help quantify the er-
rors made by other methods. Exact algorithms pro-
posed for IBM model 4 include ILP (Germann et al,
2001), cutting plane (Riedel and Clarke, 2009), and
multi-pass A* search (Och et al, 2001). Zaslavskiy
et al (2009) formulate phrase-based decoding as a
traveling salesman problem (TSP) and use a TSP
decoder. Exact decoding algorithms based on finite
state transducers (FST) (Iglesias et al, 2009) have
been studied on phrase-based models with limited
reordering (Kumar and Byrne, 2005). Exact decod-
ing based on FST is also feasible for certain hier-
archical grammars (de Gispert et al, 2010). Chang
procedure OPTBEAMSTAGED(?, ?)
?,ub, opt?LAGRANGIANRELAXATION(?)
if opt then return ub
?? ? ? ?A>?
? ? ? ? + ?>b
lb(0) ? ??
for k in 1 . . .K do
lb(k), opt? BEAMSEARCH(??, ? ?, lb(k?1), ?k)
if opt then return lb(k)
return maxk?{1...K} lb
(k)
procedure OPTBEAM(?, ?)
?(0) ? 0
lb(0) ? ??
for k in 1 . . .K do
?(k),ub(k), opt? LRROUND(?k, ?(k?1))
if opt then return ub(k)
?? ? ? ?A>?(k)
? ? ? ? + ?(k)>b
lb(k), opt? BEAMSEARCH(??, ? ?, lb(k?1), ?k)
if opt then return lb(k)
return maxk?{1...K} lb
(k)
Input:
[
?1 . . . ?K sequence of subgradient rates
?1 . . . ?K sequence of pruning parameters
Output: optimal constrained score or lower bound
Figure 6: Two versions of optimal beam search: staged
and alternating. Staged runs Lagrangian relaxation to
find the optimal ?, uses ? to compute upper bounds, and
then repeatedly runs beam search with pruning sequence
?1 . . . ?k. Alternating switches between running a round
of Lagrangian relaxation and a round of beam search with
the updated ?. If either produces a certificate it returns the
result.
and Collins (2011) and Rush and Collins (2011) de-
velop Lagrangian relaxation-based approaches for
exact machine translation.
Apart from translation decoding, this paper is
closely related to work on column generation for
NLP. Riedel et al (2012) and Belanger et al (2012)
relate column generation to beam search and pro-
duce exact solutions for parsing and tagging prob-
lems. The latter work also gives conditions for when
beam search-style decoding is optimal.
7 Results
To evaluate the effectiveness of optimal beam search
for translation decoding, we implemented decoders
for phrase- and syntax-based models. In this sec-
tion we compare the speed and optimality of these
217
decoders to several baseline methods.
7.1 Setup and Implementation
For phrase-based translation we used a German-to-
English data set taken from Europarl (Koehn, 2005).
We tested on 1,824 sentences of length at most 50
words. For experiments the phrase-based systems
uses a trigram language model and includes standard
distortion penalties. Additionally the unconstrained
hypergraph includes further derivation information
similar to the graph described in Chang and Collins
(2011).
For syntax-based translation we used a Chinese-
to-English data set. The model and hypergraphs
come from the work of Huang and Mi (2010). We
tested on 691 sentences from the newswire portion
of the 2008 NIST MT evaluation test set. For ex-
periments, the syntax-based model uses a trigram
language model. The translation model is tree-to-
string syntax-based model with a standard context-
free translation forest. The constraint matrix A
is based on the constraints described by Rush and
Collins (2011).
Our decoders use a two-pass architecture. The
first pass sets up the hypergraph in memory, and the
second pass runs search. When possible the base-
lines share optimized construction and search code.
The performance of optimal beam search is de-
pendent on the sequences ? and ?. For the step-
size ? we used a variant of Polyak?s rule (Polyak,
1987; Boyd and Mutapcic, 2007), substituting the
unknown optimal score for the last computed lower
bound: ?k ? ub
(k)?lb(k)
||Ax(k)?b||22
. We adjust the order of
the pruning parameter ? based on a function ? of
the current gap: ?k ? 10?(ub
(k)?lb(k)).
Previous work on these data sets has shown that
exact algorithms do not result in a significant in-
crease in translation accuracy. We focus on the effi-
ciency and model score of the algorithms.
7.2 Baseline Methods
The experiments compare optimal beam search
(OPTBEAM) to several different decoding meth-
ods. For both systems we compare to: BEAM, the
beam search decoder from Figure 3 using the orig-
inal weights ? and ? , and ? ? {100, 1000}; LR-
TIGHT, Lagrangian relaxation followed by incre-
Figure 7: Two graphs from phrase-based decoding.
Graph (a) shows the duality gap distribution for 1,824
sentences after 0, 5, and 10 rounds of LR. Graph (b)
shows the % of certificates found for sentences with dif-
fering gap sizes and beam search parameters ?. Duality
gap is defined as, ub - (?>x? + ? ).
mental tightening constraints, which is a reimple-
mentation of Chang and Collins (2011) and Rush
and Collins (2011).
For phrase-based translation we compare with:
MOSES-GC, the standard Moses beam search de-
coder with ? ? {100, 1000} (Koehn et al, 2007);
MOSES, a version of Moses without gap constraints
more similar to BEAM (see Chang and Collins
(2011)); ASTAR, an implementation of A? search
using original outside scores, i.e. OUTSIDE(?, ?),
and capped at 20,000,000 queue pops.
For syntax-based translation we compare with:
ILP, a general-purpose integer linear program-
ming solver (Gurobi Optimization, 2013) and
CUBEPRUNING, an approximate decoding method
similar to beam search (Chiang, 2007), tested with
? ? {100, 1000}.
7.3 Experiments
Table 1 shows the main results. For phrase-based
translation, OPTBEAM decodes the optimal trans-
lation with certificate in 99% of sentences with an
average time of 17.27 seconds per sentence. This
218
11-20 (558) 21-30 (566) 31-40 (347) 41-50 (168) all (1824)
Phrase-Based time cert exact time cert exact time cert exact time cert exact time cert exact
BEAM (100) 2.33 19.5 38.0 8.37 1.6 7.2 24.12 0.3 1.4 71.35 0.0 0.0 14.50 15.3 23.2
BEAM (1000) 2.33 37.8 66.3 8.42 3.4 18.9 21.60 0.6 3.2 53.99 0.6 1.2 12.44 22.6 36.9
BEAM (100000) 3.34 83.9 96.2 18.53 22.4 60.4 46.65 2.0 18.1 83.53 1.2 6.5 23.39 43.2 62.4
MOSES (100) 0.18 0.0 81.0 0.36 0.0 45.6 0.53 0.0 14.1 0.74 0.0 6.0 0.34 0.0 52.3
MOSES (1000) 2.29 0.0 97.8 4.39 0.0 78.8 6.52 0.0 43.5 9.00 0.0 19.6 4.20 0.0 74.6
ASTAR (cap) 11.11 99.3 99.3 91.39 53.9 53.9 122.67 7.8 7.8 139.61 1.2 1.2 67.99 58.8 58.8
LR-TIGHT 4.20 100.0 100.0 23.25 100.0 100.0 88.16 99.7 99.7 377.9 97.0 97.0 60.11 99.7 99.7
OPTBEAM 2.85 100.0 100.0 10.33 100.0 100.0 28.29 100.0 100.0 84.34 97.0 97.0 17.27 99.7 99.7
ChangCollins 10.90 100.0 100.0 57.20 100.0 100.0 203.4 99.7 99.7 679.9 97.0 97.0 120.9 99.7 99.7
MOSES-GC (100) 0.14 0.0 89.4 0.27 0.0 84.1 0.41 0.0 75.8 0.58 0.0 78.6 0.26 0.0 84.9
MOSES-GC (1000) 1.33 0.0 89.4 2.62 0.0 84.3 4.15 0.0 75.8 6.19 0.0 79.2 2.61 0.0 85.0
11-20 (192) 21-30 (159) 31-40 (136) 41-100 (123) all (691)
Syntax-Based time cert exact time cert exact time cert exact time cert exact time cert exact
BEAM (100) 0.40 4.7 75.9 0.40 0.0 66.0 0.75 0.0 43.4 1.66 0.0 25.8 0.68 5.72 58.7
BEAM (1000) 0.78 16.9 79.4 2.65 0.6 67.1 6.20 0.0 47.5 15.5 0.0 36.4 4.16 12.5 65.5
CUBE (100) 0.08 0.0 77.6 0.16 0.0 66.7 0.23 0.0 43.9 0.41 0.0 26.3 0.19 0.0 59.0
CUBE (1000) 1.76 0.0 91.7 4.06 0.0 95.0 5.71 0.0 82.9 10.69 0.0 60.9 4.66 0.0 85.0
LR-TIGHT 0.37 100.0 100.0 1.76 100.0 100.0 4.79 100.0 100.0 30.85 94.5 94.5 7.25 99.0 99.0
OPTBEAM 0.23 100.0 100.0 0.50 100.0 100.0 1.42 100.0 100.0 7.14 93.6 93.6 1.75 98.8 98.8
ILP 9.15 100.0 100.0 32.35 100.0 100.0 49.6 100.0 100.0 108.6 100.0 100.0 40.1 100.0 100.0
Table 1: Experimental results for translation experiments. Column time is the mean time per sentence in seconds,
cert is the percentage of sentences solved with a certificate of optimality, exact is the percentage of sentences solved
exactly, i.e. ?>x+ ? = ?>x? + ? . Results are grouped by sentence length (group 1-10 is omitted for space).
is seven times faster than the decoder of Chang and
Collins (2011) and 3.5 times faster then our reim-
plementation, LR-TIGHT. ASTAR performs poorly,
taking lots of time on difficult sentences. BEAM runs
quickly, but rarely finds an exact solution. MOSES
without gap constraints is also fast, but less exact
than OPTBEAM and unable to produce certificates.
For syntax-based translation. OPTBEAM finds a
certificate on 98.8% of solutions with an average
time of 1.75 seconds per sentence, and is four times
faster than LR-TIGHT. CUBE (100) is an order
of magnitude faster, but is rarely exact on longer
sentences. CUBE (1000) finds more exact solu-
tions, but is comparable in speed to optimal beam
search. BEAM performs better than in the phrase-
based model, but is not much faster than OPTBEAM.
Figure 7.2 shows the relationship between beam
search optimality and duality gap. Graph (a) shows
how a handful of LR rounds can significantly tighten
the upper bound score of many sentences. Graph (b)
shows how beam search is more likely to find opti-
mal solutions with tighter bounds. BEAM effectively
uses 0 rounds of LR, which may explain why it finds
so few optimal solutions compared to OPTBEAM.
Table 2 breaks down the time spent in each part
of the algorithm. For both methods, beam search has
the most time variance and uses more time on longer
sentences. For phrase-based sentences, Lagrangian
relaxation is fast, and hypergraph construction dom-
? 30 all
mean median mean median
Hypergraph 56.6% 69.8% 59.6% 69.6%
PB Lag. Relaxation 10.0% 5.5% 9.4% 7.6%
Beam Search 33.4% 24.6% 30.9% 22.8%
Hypergraph 0.5% 1.6% 0.8% 2.4%
SB Lag. Relaxation 15.0% 35.2% 17.3% 41.4%
Beam Search 84.4% 63.1% 81.9 % 56.1%
Table 2: Distribution of time within optimal beam search,
including: hypergraph construction, Lagrangian relax-
ation, and beam search. Mean is the percentage of total
time. Median is the distribution over the median values
for each row.
inates. If not for this cost, OPTBEAM might be com-
parable in speed to MOSES (1000).
8 Conclusion
In this work we develop an optimal variant of beam
search and apply it to machine translation decod-
ing. The algorithm uses beam search to produce
constrained solutions and bounds from Lagrangian
relaxation to eliminate non-optimal solutions. Re-
sults show that this method can efficiently find exact
solutions for two important styles of machine trans-
lation.
Acknowledgments Alexander Rush, Yin-Wen
Chang and Michael Collins were all supported by
NSF grant IIS-1161814. Alexander Rush was partially
supported by an NSF Graduate Research Fellowship.
219
References
David Belanger, Alexandre Passos, Sebastian Riedel, and
Andrew McCallum. 2012. Map inference in chains
using column generation. In NIPS, pages 1853?1861.
Stephen Boyd and Almir Mutapcic. 2007. Subgradient
methods.
Yin-Wen Chang and Michael Collins. 2011. Exact de-
coding of phrase-based translation models through la-
grangian relaxation. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pages 26?37. Association for Computational Lin-
guistics.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. computational linguistics, 33(2):201?228.
Adria de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. In Com-
putational linguistics, volume 36, pages 505?533.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathen
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,
Vlad Eidelman, and Philip Resnik. 2010. cdec: A
decoder, alignment, and learning framework for finite-
state and context-free translation models.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proceed-
ings of the 39th Annual Meeting on Association for
Computational Linguistics, ACL ?01, pages 228?235.
Inc. Gurobi Optimization. 2013. Gurobi optimizer refer-
ence manual.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proceedings of the Ninth International
Workshop on Parsing Technology, pages 53?64. As-
sociation for Computational Linguistics.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pages 144?151,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 273?283, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Rule filtering by pattern
for efficient hierarchical translation. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 380?388, Athens, Greece,
March. Association for Computational Linguistics.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607?615.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology, NAACL ?03,
pages 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ?07,
pages 177?180.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. Machine translation: From real users to research,
pages 115?124.
Shankar Kumar and William Byrne. 2005. Local phrase
reordering models for statistical machine translation.
In Proceedings of Human Language Technology Con-
ference and Conference on Empirical Methods in Nat-
ural Language Processing, pages 161?168, Vancou-
ver, British Columbia, Canada, October. Association
for Computational Linguistics.
R. Kipp Martin, Rardin L. Rardin, and Brian A. Camp-
bell. 1990. Polyhedral characterization of dis-
crete dynamic programming. Operations research,
38(1):127?138.
Franz Josef Och, Nicola Ueffing, and Hermann Ney.
2001. An efficient A* search algorithm for statisti-
cal machine translation. In Proceedings of the work-
shop on Data-driven methods in machine translation -
Volume 14, DMMT ?01, pages 1?8, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Boris Polyak. 1987. Introduction to Optimization. Opti-
mization Software, Inc.
Sebastian Riedel and James Clarke. 2009. Revisiting
optimal decoding for machine translation IBM model
4. In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics, Companion Volume: Short Papers, pages 5?8. As-
sociation for Computational Linguistics.
Sebastian Riedel, David Smith, and Andrew McCallum.
2012. Parse, price and cut: delayed column and row
generation for graph based parsers. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
220
Natural Language Learning, pages 732?743. Associa-
tion for Computational Linguistics.
Alexander M Rush and Michael Collins. 2011. Exact
decoding of syntactic translation models through la-
grangian relaxation. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, vol-
ume 1, pages 72?82.
Alexander M Rush and Michael Collins. 2012. A tutorial
on dual decomposition and lagrangian relaxation for
inference in natural language processing. Journal of
Artificial Intelligence Research, 45:305?362.
Christoph Tillmann and Hermann Ney. 2003. Word re-
ordering and a dynamic programming beam search al-
gorithm for statistical machine translation. Computa-
tional Linguistics, 29(1):97?133.
Christoph Tillmann. 2006. Efficient dynamic pro-
gramming search algorithms for phrase-based SMT.
In Proceedings of the Workshop on Computationally
Hard Problems and Joint Inference in Speech and Lan-
guage Processing, CHSLP ?06, pages 9?16.
Taro Watanabe, Hajime Tsukada, and Hideki Isozaki.
2006. Left-to-right target generation for hierarchical
phrase-based translation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association for
Computational Linguistics, ACL-44, pages 777?784,
Morristown, NJ, USA. Association for Computational
Linguistics.
Mikhail Zaslavskiy, Marc Dymetman, and Nicola Can-
cedda. 2009. Phrase-based statistical machine transla-
tion as a traveling salesman problem. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
1 - Volume 1, ACL ?09, pages 333?341, Stroudsburg,
PA, USA. Association for Computational Linguistics.
221
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 498?507,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Vine Pruning for Efficient Multi-Pass Dependency Parsing
Alexander M. Rush?
MIT CSAIL
Cambridge, MA 02139, USA
srush@csail.mit.edu
Slav Petrov
Google
New York, NY 10027, USA
slav@google.com
Abstract
Coarse-to-fine inference has been shown to be
a robust approximate method for improving
the efficiency of structured prediction models
while preserving their accuracy. We propose
a multi-pass coarse-to-fine architecture for de-
pendency parsing using linear-time vine prun-
ing and structured prediction cascades. Our
first-, second-, and third-order models achieve
accuracies comparable to those of their un-
pruned counterparts, while exploring only a
fraction of the search space. We observe
speed-ups of up to two orders of magnitude
compared to exhaustive search. Our pruned
third-order model is twice as fast as an un-
pruned first-order model and also compares
favorably to a state-of-the-art transition-based
parser for multiple languages.
1 Introduction
Coarse-to-fine inference has been extensively used
to speed up structured prediction models. The gen-
eral idea is simple: use a coarse model where in-
ference is cheap to prune the search space for more
complex models. In this work, we present a multi-
pass coarse-to-fine architecture for graph-based de-
pendency parsing. We start with a linear-time vine
pruning pass and build up to higher-order models,
achieving speed-ups of two orders of magnitude
while maintaining state-of-the-art accuracies.
In constituency parsing, exhaustive inference for
all but the simplest grammars tends to be pro-
hibitively slow. Consequently, most high-accuracy
constituency parsers routinely employ a coarse
grammar to prune dynamic programming chart cells
? Research conducted at Google.
of the final grammar of interest (Charniak et al,
2006; Carreras et al, 2008; Petrov, 2009). While
there are no strong theoretical guarantees for these
approaches,1 in practice one can obtain significant
speed improvements with minimal loss in accuracy.
This benefit comes primarily from reducing the large
grammar constant |G| that can dominate the runtime
of the cubic-time CKY inference algorithm. De-
pendency parsers on the other hand do not have a
multiplicative grammar factor |G|, and until recently
were considered efficient enough for exhaustive in-
ference. However, the increased model complex-
ity of a third-order parser forced Koo and Collins
(2010) to prune with a first-order model in order to
make inference practical. While fairly effective, all
these approaches are limited by the fact that infer-
ence in the coarse model remains cubic in the sen-
tence length. The desire to parse vast amounts of
text necessitates more efficient dependency parsing
algorithms.
We thus propose a multi-pass coarse-to-fine ap-
proach where the initial pass is a linear-time sweep,
which tries to resolve local ambiguities, but leaves
arcs beyond a fixed length b unspecified (Section
3). The dynamic program is a form of vine parsing
(Eisner and Smith, 2005), which we use to compute
parse max-marginals, rather than for finding the 1-
best parse tree. To reduce pruning errors, the param-
eters of the vine parser (and all subsequent pruning
models) are trained using the structured prediction
cascades of Weiss and Taskar (2010) to optimize
for pruning efficiency, and not for 1-best prediction
(Section 4). Despite a limited scope of b = 3, the
1This is in contrast to optimality preserving methods such as
A* search, which typically do not provide sufficient speed-ups
(Pauls and Klein, 2009).
498
vine pruning pass is able to preserve >98% of the
correct arcs, while ruling out ?86% of all possible
arcs. Subsequent i-th order passes introduce larger
scope features, while further constraining the search
space. In Section 5 we present experiments in multi-
ple languages. Our coarse-to-fine first-, second-, and
third-order parsers preserve the accuracy of the un-
pruned models, but are faster by up to two orders of
magnitude. Our pruned third-order model is faster
than an unpruned first-order model, and compares
favorably in speed to the state-of-the-art transition-
based parser of Zhang and Nivre (2011).
It is worth noting the relationship to greedy
transition-based dependency parsers that are also
linear-time (Nivre et al, 2004) or quadratic-time
(Yamada and Matsumoto, 2003). It is their success
that motivates building explicitly trained, linear-time
pruning models. However, while a greedy solu-
tion for arc-standard transition-based parsers can be
computed in linear-time, Kuhlmann et al (2011)
recently showed that computing exact solutions or
(max-)marginals has time complexity O(n4), mak-
ing these models inappropriate for coarse-to-fine
style pruning. As an alternative, Roark and Holling-
shead (2008) and Bergsma and Cherry (2010)
present approaches where individual classifiers are
used to prune chart cells. Such approaches have the
drawback that pruning decisions are made locally
and therefore can rule out all valid structures, despite
explicitly evaluating O(n2) chart cells. In contrast,
we make pruning decisions based on global parse
max-marginals using a vine pruning pass, which is
linear in the sentence length, but nonetheless guar-
antees to preserve a valid parse structure.
2 Motivation & Overview
The goal of this work is fast, high-order, graph-
based dependency parsing. Previous work on con-
stituency parsing demonstrates that performing sev-
eral passes with increasingly more complex mod-
els results in faster inference (Charniak et al, 2006;
Petrov and Klein, 2007). The same technique ap-
plies to dependency parsing with a cascade of mod-
els of increasing order; however, this strategy is
limited by the speed of the simplest model. The
algorithm for first-order dependency parsing (Eis-
ner, 2000) already requires O(n3) time, which Lee
1 2 3 4 5 6 7 8 9
modifier index
0
1
2
3
4
5
6
7
8
9
hea
din
dex
(a)
dependency length
freq
uen
cy
1 2 3 4 5 60.00.1
0.20.30.4
0.5 ADJNOUNVERB
(b)
Figure 1: (a) Heat map indicating how likely a par-
ticular head position is for each modifier position.
Greener/darker is likelier. (b) Arc length frequency for
three common modifier tags. Both charts are computed
from all sentences in Section 22 of the PTB.
(2002) shows is a practical lower bound for parsing
of context-free grammars. This bound implies that
it is unlikely that there can be an exhaustive pars-
ing algorithm that is asymptotically faster than the
standard approach.
We thus need to leverage domain knowledge to
obtain faster parsing algorithms. It is well-known
that natural language is fairly linear, and most head-
modifier dependencies tend to be short. This prop-
erty is exploited by transition-based dependency
parsers (Yamada and Matsumoto, 2003; Nivre et
al., 2004) and empirically demonstrated in Figure 1.
The heat map on the left shows that most of the
probability mass of modifiers is concentrated among
nearby words, corresponding to a diagonal band in
the matrix representation. On the right we show the
frequency of arc lengths for different modifier part-
of-speech tags. As one can expect, almost all arcs
involving adjectives (ADJ) are very short (length 3
or less), but even arcs involving verbs and nouns are
often short. This structure suggests that it may be
possible to disambiguate most dependencies by con-
sidering only the ?banded? portion of the sentence.
We exploit this linear structure by employing a
variant of vine parsing (Eisner and Smith, 2005).2
Vine parsing is a dependency parsing algorithm that
considers only close words as modifiers. Because of
this assumption it runs in linear time. Of course, any
parse tree with hard limits on dependency lengths
will contain major parse errors. We therefore use the
2The term vine parsing is a slight misnomer, since the un-
derlying vine models are as expressive as finite-state automata.
However, this allows them to circumvent the cubic-time bound.
499
As McGwire neared , fans went wild* As McGwire neared , fans went wild* As McGwire neared , fans went wild*
modifiers
heads
As McGwire
neared
, fans went wild
*AsMcGwireneared,
fanswentwild
modifiers
heads
As McGwire
neared
, fans went wild
*AsMcGwireneared,
fanswentwild
modifiers
heads
As McGwire
neared
, fans went wild
*AsMcGwireneared,
fanswentwild
Figure 2: Multi-pass pruning with a vine, first-order, and second-order model shown as dependencies and filtered
index sets after each pass. Darker cells have higher max-marginal values, while empty cells represent pruned arcs.
vine parser only for pruning and augment it to allow
arcs to remain unspecified (by including so called
outer arcs). The vine parser can thereby eliminate
a possibly quadratic number of arcs, while having
the flexibility to defer some decisions and preserve
ambiguity to be resolved by later passes. In Figure 2
for example, the vine pass correctly determined the
head-word of McGwire as neared, limited the head-
word candidates for fans to neared and went, and
decided that the head-word for went falls outside the
band by proposing an outer arc. A subsequent first-
order pass needs to score only a small fraction of all
possible arcs and can be used to further restrict the
search space for the following higher-order passes.
3 Graph-Based Dependency Parsing
Graph-based dependency parsing models factor all
valid parse trees for a given sentence into smaller
units, which can be scored independently. For in-
stance, in a first-order factorization, the units are just
dependency arcs. We represent these units by an in-
dex set I and use binary vectors Y ? {0, 1}|I| to
specify a parse tree y ? Y such that y(i) = 1 iff the
index i exists in the tree. The index sets of higher-
order models can be constructed out of the index sets
of lower-order models, thus forming a hierarchy that
we will exploit in our coarse-to-fine cascade.
The inference problem is to find the 1-best parse
tree arg maxy?Y y ? w, where w ? R|I| is a weight
vector that assigns a score to each index i (we dis-
cuss how w is learned in Section 4). A general-
ization of the 1-best inference problem is to find
the max-marginal score for each index i. Max-
marginals are given by the function M : I ? Y de-
fined as M(i;Y, w) = arg maxy?Y:y(i)=1 y ?w. For
first-order parsing, this corresponds to the best parse
utilizing a given dependency arc. Clearly there are
exponentially many possible parse tree structures,
but fortunately there exist well-known dynamic pro-
gramming algorithms for searching over all possible
structures. We review these below, starting with the
first-order factorization for ease of exposition.
Throughout the paper we make use of some ba-
sic mathematical notation. We write [c] for the enu-
meration {1, . . . , c} and [c]a for {a, . . . , c}. We use
1[c] for the indicator function, equal to 1 if con-
dition c is true and 0 otherwise. Finally we use
[c]+ = max{0, c} for the positive part of c.
3.1 First-Order Parsing
The simplest way to index a dependency parse struc-
ture is by the individual arcs of the parse tree. This
model is known as first-order or arc-factored. For a
sentence of length n the index set is:
I1 = {(h,m) : h ? [n]0,m ? [n]}
Each dependency tree has y(h,m) = 1 iff it includes
an arc from head h to modifier m. We follow com-
mon practice and use position 0 as the pseudo-root
(?) of the sentence. The full set I1 has cardinality
|I1| = O(n2).
500
(a)
h m
?I
h r
+C
mr + 1
C
(b)
h e
?C
h m
+I
m e
C
Figure 3: Parsing rules for first-order dependency pars-
ing. The complete items C are represented by triangles
and the incomplete items I are represented by trapezoids.
Symmetric left-facing versions are also included.
The first-order bilexical parsing algorithm of Eis-
ner (2000) can be used to find the best parse tree
and max-marginals. The algorithm defines a dy-
namic program over two types of items: incom-
plete items I(h,m) that denote the span between
a modifier m and its head h, and complete items
C(h, e) that contain a full subtree spanning from the
head h and to the word e on one side. The algo-
rithm builds larger items by applying the composi-
tion rules shown in Figure 3. Rule 3(a) builds an
incomplete item I(h,m) by attaching m as a modi-
fier to h. This rule has the effect that y(h,m) = 1 in
the final parse. Rule 3(b) completes item I(h,m) by
attaching item C(m, e). The existence of I(h,m)
implies that m modifies h, so this rule enforces that
the constituents of m are also constituents of h.
We can find the best derivation for each item
by adapting the standard CKY parsing algorithm
to these rules. Since both rule types contain three
variables that can range over the entire sentence
(h,m, e ? [n]0), the bottom-up, inside dynamic pro-
gramming algorithm requires O(n3) time. Further-
more, we can find max-marginals with an additional
top-down outside pass also requiring cubic time. To
speed up search, we need to filter indices from I1
and reduce possible applications of Rule 3(a).
3.2 Higher-Order Parsing
Higher-order models generalize the index set by us-
ing siblings s (modifiers that previously attached to
a head word) and grandparents g (head words above
the current head word). For compactness, we use g1
for the head word and sk+1 for the modifier and pa-
rameterize the index set to capture arbitrary higher-
(c) V?
0 e
? C
0 e? 1
+
ee? 1
C
(d)
0 e
?V?
0 m
+V?
em
I
(e)
0 e
?V?
0 e
V?
(f)
0 e
?V?
0 m
+V?
em
I
(g)
0 e
?C
0 e? 1
+V?
e? 1 e
C
Figure 4: Additional rules for vine parsing. Vine left
(V?) items are pictured as right-facing triangles and vine
right (V?) items are marked trapezoids. Each new item
is anchored at the root and grows to the right.
order decisions in both directions:
Ik,l = {(g, s) : g ? [n]l+10 , s ? [n]k+1}
where k + 1 is the sibling order, l + 1 is the par-
ent order, and k + l + 1 is the model order. The
canonical second-order model uses I1,0, which has
a cardinality of O(n3). Although there are several
possibilities for higher-order models, we use I1,1 as
our third-order model. Generally, the parsing index
set has cardinality |Ik,l| = O(n2+k+l). Inference
in higher-order models uses variants of the dynamic
program for first-order parsing, and we refer to pre-
vious work for the full set of rules. For second-order
models with index set I1,0, parsing can be done in
O(n3) time (McDonald and Pereira, 2006) and for
third-order models in O(n4) time (Koo and Collins,
2010). Even though second-order parsing has the
same asymptotic time complexity as first-order pars-
ing, inference is significantly slower due to the cost
of scoring the larger index set.
We aim to prune the index set, by mapping each
higher-order index down to a set of small set indices
501
that can be pruned using a coarse pruning model.
For example, to use a first-order model for pruning,
we would map the higher-order index to the individ-
ual indices for its arc, grandparents, and siblings:
pk,l?1(g, s) = {(g1, sj) : j ? [k + 1]}
? {(gj+1, gj) : j ? [l]}
The first-order pruning model can then be used
to score these indices, and to produce a filtered in-
dex set F (I1) by removing low-scoring indices (see
Section 4). We retain only the higher-order indices
that are supported by the filtered index set:
{(g, s) ? Ik,l : pk,l?1(g, s) ? F (I1)}
3.3 Vine Parsing
To further reduce the cost of parsing and produce
faster pruning models, we need a model with less
structure than the first-order model. A natural
choice, following Section 2, is to only consider
?short? arcs:
S = {(h,m) ? I1 : |h?m| ? b}
where b is a small constant. This constraint reduces
the size of the set to |S| = O(nb).
Clearly, this index set is severely limited; it is nec-
essary to have some long arcs for even short sen-
tences. We therefore augment the index set to in-
clude outer arcs:
I0 = S ? {(d,m) : d ? {?,?},m ? [n]}
? {(h, d) : h ? [n]0, d ? {?,?}}
The first set lets modifiers choose an outer head-
word and the second set lets head words accept outer
modifiers, and both sets distinguish the direction of
the arc. Figure 5 shows a right outer arc. The size of
I0 is linear in the sentence length. To parse the in-
dex set I0, we can modify the parse rules in Figure 3
to enforce additional length constraints (|h? e| ? b
for I(h, e) and |h?m| ? b for C(h,m)). This way,
only indices in S are explored. Unfortunately, this is
not sufficient since the constraints also prevent the
algorithm from producing a full derivation, since no
item can expand beyond length b.
Eisner and Smith (2005) therefore introduce vine
parsing, which includes two new items, vine left,
As McGwire neared , fans went wild*
Figure 5: An outer arc (1,?) from the word ?As? to pos-
sible right modifiers.
V?(e), and vine right, V?(e). Unlike the previous
items, these new items are left-anchored at the root
and grow only towards the right. The items V?(e)
and V?(e) encode the fact that a word e has not
taken a close (within b) head word to its left or right.
We incorporate these items by adding the five new
parsing rules shown in Figure 4.
The major addition is Rule 4(e) which converts a
vine left item V?(e) to a vine right item V?(e). This
implies that word e has no close head to either side,
and the parse has outer head arcs, y(?, e) = 1 or
y(?, e) = 1. The other rules are structural and dic-
tate creation and extension of vine items. Rules 4(c)
and 4(d) create vine left items from items that can-
not find a head word to their left. Rules 4(f) and
4(g) extend and finish vine right items. Rules 4(d)
and 4(f) each leave a head word incomplete, so they
may set y(e,?) = 1 or y(m,?) = 1 respec-
tively. Note that for all the new parse rules, e ? [n]0
and m ? {e ? b . . . n}, so parsing time of this so
called vine parsing algorithm is linear in the sen-
tence length O(nb2).
Alone, vine parsing is a poor model of syntax - it
does not even score most dependency pairs. How-
ever, it can act as a pruning model for other parsers.
We prune a first-order model by mapping first-order
indices to indices in I0.
p1?0(h,m) =
?
?
?
{(h,m)} if |h?m| ? b
{(?,m), (h,?)} if h < m
{(?,m), (h,?)} if h > m
The remaining first-order indices are then given by:
{(h,m) ? I1 : p1?0(h,m) ? F (I0)}
Figure 2 depicts a coarse-to-fine cascade, incor-
porating vine and first-order pruning passes and fin-
ishing with a higher-order parse model.
502
4 Training Methods
Our coarse-to-fine parsing architecture consists of
multiple pruning passes followed by a final pass
of 1-best parsing. The training objective for the
pruning models comes from the prediction cascade
framework of Weiss and Taskar (2010), which ex-
plicitly trades off pruning efficiency versus accuracy.
The models used in the final pass on the other hand
are trained for 1-best prediction.
4.1 Max-Marginal Filtering
At each pass of coarse-to-fine pruning, we apply an
index filter function F to trim the index set:
F (I) = {i ? I : f(i) = 1}
Several types of filters have been proposed in the
literature, with most work in coarse-to-fine pars-
ing focusing on predicates that threshold the poste-
rior probabilities. In structured prediction cascades,
we use a non-probabilistic filter, based on the max-
marginal value of the index:
f(i;Y, w) = 1[ M(i;Y, w) ? w < t?(Y, w) ]
where t?(Y, w) is a sentence-specific threshold
value. To counteract the fact that the max-marginals
are not normalized, the threshold t?(Y, w) is set as
a convex combination of the 1-best parse score and
the average max-marginal value:
t?(Y, w) = ?max
y?Y
(y ? w)
+ (1? ?) 1|I|
?
i?I
M(i;Y, w) ? w
where the model-specific parameter 0 ? ? ? 1 is
the tradeoff between ? = 1, pruning all indices i not
in the best parse, and ? = 0, pruning all indices with
max-marginal value below the mean.
The threshold function has the important property
that for any parse y, if y ?w ? t?(Y, w) then y(i) =
1 implies f(i) = 0, i.e. if the parse score is above
the threshold, then none of its indices will be pruned.
4.2 Filter Loss Training
The aim of our pruning models is to filter as many
indices as possible without losing the gold parse. In
structured prediction cascades, we incorporate this
pruning goal into our training objective.
Let y be the gold output for a sentence. We define
filter loss to be an indicator of whether any i with
y(i) = 1 is filtered:
?(y,Y, w) = 1[?i ? y,M(i;Y, w) ?w < t?(Y, w)]
During training we minimize the expected filter loss
using a standard structured SVM setup (Tsochan-
taridis et al, 2006). First we form a convex, con-
tinuous upper-bound of our loss function:
?(y,Y, w) ? 1[y ? w < t?(Y, w)]
? [1? y ? w + t?(Y, w)]+
where the first inequality comes from the proper-
ties of max-marginals and the second is the standard
hinge-loss upper-bound on an indicator.
Now assume that we have a corpus of P train-
ing sentences. Let the sequence (y(1), . . . , y(P )) be
the gold parses for each sentences and the sequence
(Y(1), . . . ,Y(P )) be the set of possible output struc-
tures. We can form the regularized risk minimiza-
tion for this upper bound of filter loss:
min
w
??w?2 + 1
P
P?
p=1
[1? y(p) ? w + t?(Y(p), w)]+
This objective is convex and non-differentiable, due
to the max inside t. We optimize using stochastic
subgradient descent (Shalev-Shwartz et al, 2007).
The stochastic subgradient at example p, H(w, p) is
0 if y(p) ? 1 ? t?(Y, w) otherwise,
H(w, p) =
2?w
P
? y(p) + ? arg max
y?Y(p)
y ? w
+ (1? ?) 1|I(p)|
?
i?I(p)
M(i;Y(p), w)
Each step of the algorithm has an update of the form:
wk = wk?1 ? ?kH(w, p)
where ? is an appropriate update rate for subgradi-
ent convergence. If ? = 1 the objective is identical
to structured SVM with 0/1 hinge loss. For other
values of ?, the subgradient includes a term from
the features of all max-marginal structures at each
index. These feature counts can be computed using
dynamic programming.
503
First-order Second-order Third-order
Setup Speed PE Oracle UAS Speed PE Oracle UAS Speed PE Oracle UAS
NOPRUNE 1.00 0.00 100 91.4 0.32 0.00 100 92.7 0.01 0.00 100 93.3
LENGTHDICTIONARY 1.94 43.9 99.9 91.5 0.76 43.9 99.9 92.8 0.05 43.9 99.9 93.3
LOCALSHORT 3.08 76.6 99.1 91.4 1.71 76.4 99.1 92.6 0.31 77.5 99.0 93.1
LOCAL 4.59 89.9 98.8 91.5 2.88 83.2 99.5 92.6 1.41 89.5 98.8 93.1
FIRSTONLY 3.10 95.5 95.9 91.5 2.83 92.5 98.4 92.6 1.61 92.2 98.5 93.1
FIRSTANDSECOND - - 1.80 97.6 97.7 93.1
VINEPOSTERIOR 3.92 94.6 96.5 91.5 3.66 93.2 97.7 92.6 1.67 96.5 97.9 93.1
VINECASCADE 5.24 95.0 95.7 91.5 3.99 91.8 98.7 92.6 2.22 97.8 97.4 93.1
k=8 k=16 k=64
ZHANGNIVRE 4.32 - - 92.4 2.39 - - 92.5 0.64 - - 92.7
Table 1: Results comparing pruning methods on PTB Section 22. Oracle is the max achievable UAS after pruning.
Pruning efficiency (PE) is the percentage of non-gold first-order dependency arcs pruned. Speed is parsing time relative
to the unpruned first-order model (around 2000 tokens/sec). UAS is the unlabeled attachment score of the final parses.
4.3 1-Best Training
For the final pass, we want to train the model for 1-
best output. Several different learning methods are
available for structured prediction models including
structured perceptron (Collins, 2002), max-margin
models (Taskar et al, 2003), and log-linear mod-
els (Lafferty et al, 2001). In this work, we use the
margin infused relaxed algorithm (MIRA) (Cram-
mer and Singer, 2003; Crammer et al, 2006) with
a hamming-loss margin. MIRA is an online algo-
rithm with similar benefits as structured perceptron
in terms of simplicity and fast training time. In prac-
tice, we found that MIRA with hamming-loss mar-
gin gives a performance improvement over struc-
tured perceptron and structured SVM.
5 Parsing Experiments
To empirically demonstrate the effectiveness of our
approach, we compare our vine pruning cascade
with a wide range of common pruning methods on
the Penn WSJ Treebank (PTB) (Marcus et al, 1993).
We then also show that vine pruning is effective
across a variety of different languages.
For English, we convert the PTB constituency
trees to dependencies using the Stanford dependency
framework (De Marneffe et al, 2006). We then
train on the standard PTB split with sections 2-21
as training, section 22 as validation, and section 23
as test. Results are similar using the Yamada and
Matsumoto (2003) conversion. We additionally se-
lected six languages from the CoNLL-X shared task
(Buchholz and Marsi, 2006) that cover a number
of different language families: Bulgarian, Chinese,
Japanese, German, Portuguese, and Swedish. We
use the standard CoNLL-X training/test split and
tune parameters with cross-validation.
All experiments use unlabeled dependencies for
training and test. Accuracy is reported as unlabeled
attachment score (UAS), the percentage of tokens
with the correct head word. For English, UAS ig-
nores punctuation tokens and the test set uses pre-
dicted POS tags. For the other languages we fol-
low the CoNLL-X setup and include punctuation in
UAS and use gold POS tags on the set set. Speed-
ups are given in terms of time relative to a highly
optimized C++ implementation. Our unpruned first-
order baseline can process roughly two thousand to-
kens a second and is comparable in speed to the
greedy shift-reduce parser of Nivre et al (2004).
5.1 Models
Our parsers perform multiple passes over each sen-
tence. In each pass we first construct a (pruned) hy-
pergraph (Klein and Manning, 2005) and then per-
form feature computation and inference. We choose
the highest ? that produces a pruning error of no
more than 0.2 on the validation set (typically ? ?
0.6) to filter indices for subsequent rounds (similar
to Weiss and Taskar (2010)). We compare a variety
of pruning models:
LENGTHDICTIONARY a deterministic prun-
ing method that eliminates all arcs longer
than the maximum length observed for each
504
head-modifier POS pair.
LOCAL an unstructured arc classifier that chooses
indices from I1 directly without enforcing
parse constraints. Similar to the quadratic-time
filter from Bergsma and Cherry (2010).
LOCALSHORT an unstructured arc classifier that
chooses indices from I0 directly without en-
forcing parse constraints. Similar to the linear-
time filter from Bergsma and Cherry (2010).
FIRSTONLY a structured first-order model trained
with filter loss for pruning.
FIRSTANDSECOND a structured cascade with
first- and second-order pruning models.
VINECASCADE the full cascade with vine, first-
and second-order pruning models.
VINEPOSTERIOR the vine parsing cascade trained
as a CRF with L-BFGS (Nocedal and Wright,
1999) and using posterior probabilities for fil-
tering instead of max-marginals.
ZHANGNIVRE an unlabeled reimplementation of
the linear-time, k-best, transition-based parser
of Zhang and Nivre (2011). This parser uses
composite features up to third-order with a
greedy decoding algorithm. The reimplemen-
tation is about twice as fast as their reported
speed, but scores slightly lower.
We found LENGTHDICTIONARY pruning to give
significant speed-ups in all settings and therefore al-
ways use it as an initial pass. The maximum number
of passes in a cascade is five: dictionary, vine, first-,
and second-order pruning, and a final third-order 1-
best pass.3 We tune the pruning thresholds for each
round and each cascade separately. This is because
we might be willing to do a more aggressive vine
pruning pass if the final model is a first-order model,
since these two models tend to often agree.
5.2 Features
For the non-pruning models, we use a standard set
of features proposed in the discriminative graph-
based dependency parsing literature (McDonald et
al., 2005; Carreras, 2007; Koo and Collins, 2010).
3For the first-order parser, we found it beneficial to employ a
reduced feature first-order pruner before the final model, i.e. the
cascade has four rounds: dictionary, vine, first-order pruning,
and first-order 1-best.
sentence length
10 20 30 40 50
No Prune [2.8]Length [1.9]Cascade [1.4]
me
an
tim
e
first-order
sentence length
10 20 30 40 50
No Prune [2.8]Length [2.0]Cascade [1.8]
me
an
tim
e
second-order
sentence length
10 20 30 40 50
No Prune [3.8]Length [2.4]Cascade [1.9]
me
an
tim
e
third-order
sentence length
10 20 30 40 50
Length [1.9]Local [1.8]Cascade [1.4]
me
an
tim
e
pruning methods
Figure 6: Mean parsing speed by sentence length for
first-, second-, and third-order parsers as well as differ-
ent pruning methods for first-order parsing. [b] indicates
the empirical complexity obtained from fitting axb.
Included are lexical features, part-of-speech fea-
tures, features on in-between tokens, as well as fea-
ture conjunctions, surrounding part-of-speech tags,
and back-off features. In addition, we replicate each
part-of-speech (POS) feature with an additional fea-
ture using coarse POS representations (Petrov et al,
2012). Our baseline parsing models replicate and,
for some experiments, surpass previous best results.
The first- and second-order pruning models have
the same structure, but for efficiency use only the
basic features from McDonald et al (2005). As fea-
ture computation is quite costly, future work may
investigate whether this set can be reduced further.
VINEPRUNE and LOCALSHORT use the same fea-
ture sets for short arcs. Outer arcs have features of
the unary head or modifier token, as well as features
for the POS tag bordering the cutoff and the direc-
tion of the arc.
5.3 Results
A comparison between the pruning methods is
shown in Table 1. The table gives relative speed-
ups, compared to the unpruned first-order baseline,
as well as accuracy, pruning efficiency, and ora-
cle scores. Note particularly that the third-order
cascade is twice as fast as an unpruned first-order
model and >200 times faster than the unpruned
third-order baseline. The comparison with poste-
505
1-Best Model
Round First Second Third
Vine 37% 27% 16%
First 63% 30% 17%
Second - 43% 18%
Third - - 49%
Table 2: Relative speed of pruning models in a multi-pass
cascade. Note that the 1-best models use richer features
than the corresponding pruning models.
rior pruning is less pronounced. Filter loss train-
ing is faster than VINEPOSTERIOR for first- and
third-order parsing, but the two models have similar
second-order speeds. It is also noteworthy that ora-
cle scores are consistently high even after multiple
pruning rounds: the oracle score of our third-order
model for example is 97.4%.
Vine pruning is particularly effective. The vine
pass is faster than both LOCAL and FIRSTONLY
and prunes more effectively than LOCALSHORT.
Vine pruning benefits from having a fast, linear-time
model, but still maintaining enough structure for
pruning. While our pruning approach does not pro-
vide any asymptotic guarantees, Figure 6 shows that
in practice our multi-pass parser scales well even
for long sentences: Our first-order cascade scales
almost linearly with the sentence length, while the
third-order cascade scales better than quadratic. Ta-
ble 2 shows that the final pass dominates the compu-
tational cost, while each of the pruning passes takes
up roughly the same amount of time.
Our second- and third-order cascades also signif-
icantly outperform ZHANGNIVRE. The transition-
based model with k = 8 is very efficient and effec-
tive, but increasing the k-best list size scales much
worse than employing multi-pass pruning. We also
note that while direct speed comparison are difficult,
our parser is significantly faster than the published
results for other high accuracy parsers, e.g. Huang
and Sagae (2010) and Koo et al (2010).
Table 3 shows our results across a subset of the
CoNLL-X datasets, focusing on languages that dif-
fer greatly in structure. The unpruned models per-
form well across datasets, scoring comparably to the
top results from the CoNLL-X competition. We see
speed increases for our cascades with almost no loss
in accuracy across all languages, even for languages
with fairly free word order like German. This is
First-order Second-order Third-order
Setup Speed UAS Speed UAS Speed UAS
BG B 1.90 90.7 0.67 92.0 0.05 92.1V 6.17 90.5 5.30 91.6 1.99 91.9
DE B 1.40 89.2 0.48 90.3 0.02 90.8V 4.72 89.0 3.54 90.1 1.44 90.8
JA B 1.77 92.0 0.58 92.1 0.04 92.4V 8.14 91.7 8.64 92.0 4.30 92.3
PT B 0.89 90.1 0.28 91.2 0.01 91.7V 3.98 90.0 3.45 90.9 1.45 91.5
SW B 1.37 88.5 0.45 89.7 0.01 90.4V 6.35 88.3 6.25 89.4 2.66 90.1
ZH B 7.32 89.5 3.30 90.5 0.67 90.8V 7.45 89.3 6.71 90.3 3.90 90.9
EN B 1.0 91.2 0.33 92.4 0.01 93.0V 5.24 91.0 3.92 92.2 2.23 92.7
Table 3: Speed and accuracy results for the vine prun-
ing cascade across various languages. B is the un-
pruned baseline model, and V is the vine pruning cas-
cade. The first section of the table gives results for
the CoNLL-X test datasets for Bulgarian (BG), German
(DE), Japanese (JA), Portuguese (PT), Swedish (SW),
and Chinese (ZH). The second section gives the result
for the English (EN) test set, PTB Section 23.
encouraging and suggests that the outer arcs of the
vine-pruning model are able to cope with languages
that are not as linear as English.
6 Conclusion
We presented a multi-pass architecture for depen-
dency parsing that leverages vine parsing and struc-
tured prediction cascades. The resulting 200-fold
speed-up leads to a third-order model that is twice
as fast as an unpruned first-order model for a vari-
ety of languages, and that also compares favorably
to a state-of-the-art transition-based parser. Possible
future work includes experiments using cascades to
explore much higher-order models.
Acknowledgments
We would like to thank the members of the Google
NLP Parsing Team for comments, suggestions, bug-
fixes and help in general: Ryan McDonald, Hao
Zhang, Michael Ringgaard, Terry Koo, Keith Hall,
Kuzman Ganchev and Yoav Goldberg. We would
also like to thank Andre Martins for showing that
MIRA with hamming-loss margin performs better
than other 1-best training algorithms.
506
References
S. Bergsma and C. Cherry. 2010. Fast and accurate arc
filtering for dependency parsing. In Proc. of COLING,
pages 53?61.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared task
on multilingual dependency parsing. In CoNLL.
X. Carreras, M. Collins, and T. Koo. 2008. Tag, dynamic
programming, and the perceptron for efficient, feature-
rich parsing. In Proc. of CoNLL, pages 9?16.
X. Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proc. of CoNLL
Shared Task Session of EMNLP-CoNLL, volume 7,
pages 957?961.
E. Charniak, M. Johnson, M. Elsner, J. Austerweil,
D. Ellis, I. Haxton, C. Hill, R. Shrivaths, J. Moore,
M. Pozar, et al 2006. Multilevel coarse-to-fine PCFG
parsing. In Proc. of NAACL/HLT, pages 168?175.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. of EMNLP, pages 1?8.
K. Crammer and Y. Singer. 2003. Ultraconservative on-
line algorithms for multiclass problems. The Journal
of Machine Learning Research, 3:951?991.
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive algo-
rithms. The Journal of Machine Learning Research,
7:551?585.
M.C. De Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proc. of LREC, volume 6,
pages 449?454.
J. Eisner and N.A. Smith. 2005. Parsing with soft and
hard constraints on dependency length. In Proc. of
IWPT, pages 30?41.
J. Eisner. 2000. Bilexical grammars and their cubic-
time parsing algorithms. Advances in Probabilistic
and Other Parsing Technologies, pages 29?62.
L. Huang and K. Sagae. 2010. Dynamic programming
for linear-time incremental parsing. In Proc. of ACL,
pages 1077?1086.
D. Klein and C.D. Manning. 2005. Parsing and hy-
pergraphs. New developments in parsing technology,
pages 351?372.
T. Koo and M. Collins. 2010. Efficient third-order de-
pendency parsers. In Proc. of ACL, pages 1?11.
T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Son-
tag. 2010. Dual decomposition for parsing with non-
projective head automata. In Proc. of EMNLP, pages
1288?1298.
M. Kuhlmann, C. Go?mez-Rodr??guez, and G. Satta. 2011.
Dynamic programming algorithms for transition-
based dependency parsers. In Proc. of ACL/HLT,
pages 673?682.
J. Lafferty, A. McCallum, and F.C.N. Pereira. 2001.
Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proc. of
ICML, pages 282?289.
L. Lee. 2002. Fast context-free grammar parsing re-
quires fast boolean matrix multiplication. Journal of
the ACM, 49(1):1?15.
M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of en-
glish: The penn treebank. Computational linguistics,
19(2):313?330.
R. McDonald and F. Pereira. 2006. Online learning of
approximate dependency parsing algorithms. In Proc.
of EACL, volume 6, pages 81?88.
R. McDonald, K. Crammer, and F. Pereira. 2005. Online
large-margin training of dependency parsers. In Proc.
of ACL, pages 91?98.
J. Nivre, J. Hall, and J. Nilsson. 2004. Memory-based
dependency parsing. In Proc. of CoNLL, pages 49?56.
J. Nocedal and S. J. Wright. 1999. Numerical Optimiza-
tion. Springer.
A. Pauls and D. Klein. 2009. Hierarchical search for
parsing. In Proc. of NAACL/HLT, pages 557?565.
S. Petrov and D. Klein. 2007. Improved inference for
unlexicalized parsing. In Proc. of NAACL/HLT, pages
404?411.
S. Petrov, D. Das, and R. McDonald. 2012. A universal
part-of-speech tagset. In LREC.
S. Petrov. 2009. Coarse-to-Fine Natural Language
Processing. Ph.D. thesis, University of California at
Bekeley, Berkeley, CA, USA.
B. Roark and K. Hollingshead. 2008. Classifying chart
cells for quadratic complexity context-free inference.
In Proc. of COLING, pages 745?751.
S. Shalev-Shwartz, Y. Singer, and N. Srebro. 2007. Pe-
gasos: Primal estimated sub-gradient solver for svm.
In Proc. of ICML, pages 807?814.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
markov networks. Advances in neural information
processing systems, 16:25?32.
I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Al-
tun. 2006. Large margin methods for structured and
interdependent output variables. Journal of Machine
Learning Research, 6(2):1453.
D. Weiss and B. Taskar. 2010. Structured prediction cas-
cades. In Proc. of AISTATS, volume 1284, pages 916?
923.
H. Yamada and Y. Matsumoto. 2003. Statistical depen-
dency analysis with support vector machines. In Proc.
of IWPT, volume 3, pages 195?206.
Y. Zhang and J. Nivre. 2011. Transition-based depen-
dency parsing with rich non-local features. In Proc. of
ACL, pages 188?193.
507
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 72?82,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Exact Decoding of Syntactic Translation Models
through Lagrangian Relaxation
Alexander M. Rush
MIT CSAIL,
Cambridge, MA 02139, USA
srush@csail.mit.edu
Michael Collins
Department of Computer Science,
Columbia University,
New York, NY 10027, USA
mcollins@cs.columbia.edu
Abstract
We describe an exact decoding algorithm for
syntax-based statistical translation. The ap-
proach uses Lagrangian relaxation to decom-
pose the decoding problem into tractable sub-
problems, thereby avoiding exhaustive dy-
namic programming. The method recovers ex-
act solutions, with certificates of optimality,
on over 97% of test examples; it has compa-
rable speed to state-of-the-art decoders.
1 Introduction
Recent work has seen widespread use of syn-
chronous probabilistic grammars in statistical ma-
chine translation (SMT). The decoding problem for
a broad range of these systems (e.g., (Chiang, 2005;
Marcu et al, 2006; Shen et al, 2008)) corresponds
to the intersection of a (weighted) hypergraph with
an n-gram language model.1 The hypergraph rep-
resents a large set of possible translations, and is
created by applying a synchronous grammar to the
source language string. The language model is then
used to rescore the translations in the hypergraph.
Decoding with these models is challenging,
largely because of the cost of integrating an n-gram
language model into the search process. Exact dy-
namic programming algorithms for the problem are
well known (Bar-Hillel et al, 1964), but are too ex-
pensive to be used in practice.2 Previous work on
decoding for syntax-based SMT has therefore been
focused primarily on approximate search methods.
This paper describes an efficient algorithm for ex-
act decoding of synchronous grammar models for
translation. We avoid the construction of (Bar-Hillel
1This problem is also relevant to other areas of statistical
NLP, for example NL generation (Langkilde, 2000).
2E.g., with a trigram language model they run in O(|E|w6)
time, where |E| is the number of edges in the hypergraph, and
w is the number of distinct lexical items in the hypergraph.
et al, 1964) by using Lagrangian relaxation to de-
compose the decoding problem into the following
sub-problems:
1. Dynamic programming over the weighted hy-
pergraph. This step does not require language
model integration, and hence is highly efficient.
2. Application of an all-pairs shortest path al-
gorithm to a directed graph derived from the
weighted hypergraph. The size of the derived
directed graph is linear in the size of the hyper-
graph, hence this step is again efficient.
Informally, the first decoding algorithm incorporates
the weights and hard constraints on translations from
the synchronous grammar, while the second decod-
ing algorithm is used to integrate language model
scores. Lagrange multipliers are used to enforce
agreement between the structures produced by the
two decoding algorithms.
In this paper we first give background on hyper-
graphs and the decoding problem. We then describe
our decoding algorithm. The algorithm uses a sub-
gradient method to minimize a dual function. The
dual corresponds to a particular linear programming
(LP) relaxation of the original decoding problem.
The method will recover an exact solution, with a
certificate of optimality, if the underlying LP relax-
ation has an integral solution. In some cases, how-
ever, the underlying LP will have a fractional solu-
tion, in which case the method will not be exact. The
second technical contribution of this paper is to de-
scribe a method that iteratively tightens the underly-
ing LP relaxation until an exact solution is produced.
We do this by gradually introducing constraints to
step 1 (dynamic programming over the hypergraph),
while still maintaining efficiency.
72
We report experiments using the tree-to-string
model of (Huang and Mi, 2010). Our method gives
exact solutions on over 97% of test examples. The
method is comparable in speed to state-of-the-art de-
coding algorithms; for example, over 70% of the test
examples are decoded in 2 seconds or less. We com-
pare our method to cube pruning (Chiang, 2007),
and find that our method gives improved model
scores on a significant number of examples. One
consequence of our work is that we give accurate
estimates of the number of search errors for cube
pruning.
2 Related Work
A variety of approximate decoding algorithms have
been explored for syntax-based translation systems,
including cube-pruning (Chiang, 2007; Huang and
Chiang, 2007), left-to-right decoding with beam
search (Watanabe et al, 2006; Huang and Mi, 2010),
and coarse-to-fine methods (Petrov et al, 2008).
Recent work has developed decoding algorithms
based on finite state transducers (FSTs). Iglesias et
al. (2009) show that exact FST decoding is feasible
for a phrase-based system with limited reordering
(the MJ1 model (Kumar and Byrne, 2005)), and de
Gispert et al (2010) show that exact FST decoding
is feasible for a specific class of hierarchical gram-
mars (shallow-1 grammars). Approximate search
methods are used for more complex reordering mod-
els or grammars. The FST algorithms are shown to
produce higher scoring solutions than cube-pruning
on a large proportion of examples.
Lagrangian relaxation is a classical technique
in combinatorial optimization (Korte and Vygen,
2008). Lagrange multipliers are used to add lin-
ear constraints to an existing problem that can be
solved using a combinatorial algorithm; the result-
ing dual function is then minimized, for example
using subgradient methods. In recent work, dual
decomposition?a special case of Lagrangian relax-
ation, where the linear constraints enforce agree-
ment between two or more models?has been ap-
plied to inference in Markov random fields (Wain-
wright et al, 2005; Komodakis et al, 2007; Sontag
et al, 2008), and also to inference problems in NLP
(Rush et al, 2010; Koo et al, 2010). There are close
connections between dual decomposition and work
on belief propagation (Smith and Eisner, 2008).
3 Background: Hypergraphs
Translation with many syntax-based systems (e.g.,
(Chiang, 2005; Marcu et al, 2006; Shen et al, 2008;
Huang and Mi, 2010)) can be implemented as a
two-step process. The first step is to take an in-
put sentence in the source language, and from this
to create a hypergraph (sometimes called a transla-
tion forest) that represents the set of possible trans-
lations (strings in the target language) and deriva-
tions under the grammar. The second step is to
integrate an n-gram language model with this hy-
pergraph. For example, in the system of (Chiang,
2005), the hypergraph is created as follows: first, the
source side of the synchronous grammar is used to
create a parse forest over the source language string.
Second, transduction operations derived from syn-
chronous rules in the grammar are used to create the
target-language hypergraph. Chiang?s method uses
a synchronous context-free grammar, but the hyper-
graph formalism is applicable to a broad range of
other grammatical formalisms, for example depen-
dency grammars (e.g., (Shen et al, 2008)).
A hypergraph is a pair (V,E) where V =
{1, 2, . . . , |V |} is a set of vertices, and E is a set of
hyperedges. A single distinguished vertex is taken
as the root of the hypergraph; without loss of gener-
ality we take this vertex to be v = 1. Each hyper-
edge e ? E is a tuple ??v1, v2, . . . , vk?, v0? where
v0 ? V , and vi ? {2 . . . |V |} for i = 1 . . . k. The
vertex v0 is referred to as the head of the edge. The
ordered sequence ?v1, v2, . . . , vk? is referred to as
the tail of the edge; in addition, we sometimes refer
to v1, v2, . . . vk as the children in the edge. The num-
ber of children k may vary across different edges,
but k ? 1 for all edges (i.e., each edge has at least
one child). We will use h(e) to refer to the head of
an edge e, and t(e) to refer to the tail.
We will assume that the hypergraph is acyclic: in-
tuitively this will mean that no derivation (as defined
below) contains the same vertex more than once (see
(Martin et al, 1990) for a formal definition).
Each vertex v ? V is either a non-terminal in the
hypergraph, or a leaf. The set of non-terminals is
VN = {v ? V : ?e ? E such that h(e) = v}
Conversely, the set of leaves is defined as
VL = {v ? V : 6 ?e ? E such that h(e) = v}
73
Finally, we assume that each v ? V has a label
l(v). The labels for leaves will be words, and will
be important in defining strings and language model
scores for those strings. The labels for non-terminal
nodes will not be important for results in this paper.3
We now turn to derivations. Define an index set
I = V ? E. A derivation is represented by a vector
y = {yr : r ? I} where yv = 1 if vertex v is used in
the derivation, yv = 0 otherwise (similarly ye = 1 if
edge e is used in the derivation, ye = 0 otherwise).
Thus y is a vector in {0, 1}|I|. A valid derivation
satisfies the following constraints:
? y1 = 1 (the root must be in the derivation).
? For all v ? VN , yv =
?
e:h(e)=v ye.
? For all v ? 2 . . . |V |, yv =
?
e:v?t(e) ye.
We use Y to refer to the set of valid derivations.
The set Y is a subset of {0, 1}|I| (not all members of
{0, 1}|I| will correspond to valid derivations).
Each derivation y in the hypergraph will imply an
ordered sequence of leaves v1 . . . vn. We use s(y) to
refer to this sequence. The sentence associated with
the derivation is then l(v1) . . . l(vn).
In a weighted hypergraph problem, we assume a
parameter vector ? = {?r : r ? I}. The score for
any derivation is f(y) = ? ? y = ?r?I ?ryr. Sim-
ple bottom-up dynamic programming?essentially
the CKY algorithm?can be used to find y? =
argmaxy?Y f(y) under these definitions.
The focus of this paper will be to solve problems
involving the integration of a k?th order language
model with a hypergraph. In these problems, the
score for a derivation is modified to be
f(y) =
?
r?I
?ryr +
n
?
i=k
?(vi?k+1, vi?k+2, . . . , vi) (1)
where v1 . . . vn = s(y). The ?(vi?k+1, . . . , vi)
parameters score n-grams of length k. These
parameters are typically defined by a language
model, for example with k = 3 we would have
?(vi?2, vi?1, vi) = log p(l(vi)|l(vi?2), l(vi?1)).
The problem is then to find y? = argmaxy?Y f(y)
under this definition.
Throughout this paper we make the following as-
sumption when using a bigram language model:
3They might for example be non-terminal symbols from the
grammar used to generate the hypergraph.
Assumption 3.1 (Bigram start/end assump-
tion.) For any derivation y, with leaves
s(y) = v1, v2, . . . , vn, it is the case that: (1)
v1 = 2 and vn = 3; (2) the leaves 2 and 3 cannot
appear at any other position in the strings s(y) for
y ? Y; (3) l(2) = <s> where <s> is the start
symbol in the language model; (4) l(3) = </s>
where </s> is the end symbol.
This assumption allows us to incorporate lan-
guage model terms that depend on the start and end
symbols. It also allows a clean solution for boundary
conditions (the start/end of strings).4
4 A Simple Lagrangian Relaxation
Algorithm
We now give a Lagrangian relaxation algorithm for
integration of a hypergraph with a bigram language
model, in cases where the hypergraph satisfies the
following simplifying assumption:
Assumption 4.1 (The strict ordering assumption.)
For any two leaves v and w, it is either the case
that: 1) for all derivations y such that v and w are
both in the sequence l(y), v precedes w; or 2) for all
derivations y such that v and w are both in l(y), w
precedes v.
Thus under this assumption, the relative ordering
of any two leaves is fixed. This assumption is overly
restrictive:5 the next section describes an algorithm
that does not require this assumption. However de-
riving the simple algorithm will be useful in devel-
oping intuition, and will lead directly to the algo-
rithm for the unrestricted case.
4.1 A Sketch of the Algorithm
At a high level, the algorithm is as follows. We in-
troduce Lagrange multipliers u(v) for all v ? VL,
with initial values set to zero. The algorithm then
involves the following steps: (1) For each leaf v,
find the previous leaf w that maximizes the score
?(w, v) ? u(w) (call this leaf ??(v), and define
?v = ?(??(v), v) ? u(??(v))). (2) find the high-
est scoring derivation using dynamic programming
4The assumption generalizes in the obvious way to k?th or-
der language models: e.g., for trigram models we assume that
v1 = 2, v2 = 3, vn = 4, l(2) = l(3) = <s>, l(4) = </s>.
5It is easy to come up with examples that violate this as-
sumption: for example a hypergraph with edges ??4, 5?, 1? and
??5, 4?, 1? violates the assumption. The hypergraphs found in
translation frequently contain alternative orderings such as this.
74
over the original (non-intersected) hypergraph, with
leaf nodes having weights ?v + ?v + u(v). (3) If
the output derivation from step 2 has the same set of
bigrams as those from step 1, then we have an exact
solution to the problem. Otherwise, the Lagrange
multipliers u(v) are modified in a way that encour-
ages agreement of the two steps, and we return to
step 1.
Steps 1 and 2 can be performed efficiently; in par-
ticular, we avoid the classical dynamic programming
intersection, instead relying on dynamic program-
ming over the original, simple hypergraph.
4.2 A Formal Description
We now give a formal description of the algorithm.
Define B ? VL?VL to be the set of all ordered pairs
?v, w? such that there is at least one derivation y with
v directly preceding w in s(y). Extend the bit-vector
y to include variables y(v, w) for ?v, w? ? B where
y(v, w) = 1 if leaf v is followed by w in s(y), 0
otherwise. We redefine the index set to be I = V ?
E ? B, and define Y ? {0, 1}|I| to be the set of all
possible derivations. Under assumptions 3.1 and 4.1
above, Y = {y : y satisfies constraints C0, C1, C2}
where the constraint definitions are:
? (C0) The yv and ye variables form a derivation
in the hypergraph, as defined in section 3.
? (C1) For all v ? VL such that v 6= 2, yv =
?
w:?w,v??B y(w, v).
? (C2) For all v ? VL such that v 6= 3, yv =
?
w:?v,w??B y(v, w).
C1 states that each leaf in a derivation has exactly
one in-coming bigram, and that each leaf not in the
derivation has 0 incoming bigrams; C2 states that
each leaf in a derivation has exactly one out-going
bigram, and that each leaf not in the derivation has 0
outgoing bigrams.6
The score of a derivation is now f(y) = ? ? y, i.e.,
f(y) =
?
v
?vyv+
?
e
?eye+
?
?v,w??B
?(v, w)y(v, w)
where ?(v, w) are scores from the language model.
Our goal is to compute y? = argmaxy?Y f(y).
6Recall that according to the bigram start/end assumption
the leaves 2/3 are reserved for the start/end of the sequence
s(y), and hence do not have an incoming/outgoing bigram.
Initialization: Set u0(v) = 0 for all v ? VL
Algorithm: For t = 1 . . . T :
? yt = argmaxy?Y? L(ut?1, y)
? If yt satisfies constraints C2, return yt,
Else ?v ? VL, ut(v) =
ut?1(v)? ?t
(
yt(v)??w:?v,w??B yt(v, w)
)
.
Figure 1: A simple Lagrangian relaxation algorithm.
?t > 0 is the step size at iteration t.
Next, define Y ? as
Y ? = {y : y satisfies constraints C0 and C1}
In this definition we have dropped the C2 con-
straints. To incorporate these constraints, we use
Lagrangian relaxation, with one Lagrange multiplier
u(v) for each constraint in C2. The Lagrangian is
L(u, y) = f(y) +
?
v
u(v)(y(v)?
?
w:?v,w??B
y(v, w))
= ? ? y
where ?v = ?v + u(v), ?e = ?e, and ?(v, w) =
?(v, w)? u(v).
The dual problem is to find minu L(u) where
L(u) = max
y?Y ?
L(u, y)
Figure 1 shows a subgradient method for solving
this problem. At each point the algorithm finds
yt = argmaxy?Y ? L(ut?1, y), where ut?1 are the
Lagrange multipliers from the previous iteration. If
yt satisfies the C2 constraints in addition to C0 and
C1, then it is returned as the output from the algo-
rithm. Otherwise, the multipliers u(v) are updated.
Intuitively, these updates encourage the values of yv
and
?
w:?v,w??B y(v, w) to be equal; formally, these
updates correspond to subgradient steps.
The main computational step at each iteration is to
compute argmaxy?Y ? L(ut?1, y) This step is easily
solved, as follows (we again use ?v, ?e and ?(v1, v2)
to refer to the parameter values that incorporate La-
grange multipliers):
? For all v ? VL, define ??(v) =
argmaxw:?w,v??B ?(w, v) and ?v =
?(??(v), v). For all v ? VN define ?v = 0.
75
? Using dynamic programming, find values for
the yv and ye variables that form a valid deriva-
tion, and that maximize
f ?(y) =
?
v(?v + ?v)yv +
?
e ?eye.
? Set y(v, w) = 1 iff y(w) = 1 and ??(w) = v.
The critical point here is that through our definition
of Y ?, which ignores the C2 constraints, we are able
to do efficient search as just described. In the first
step we compute the highest scoring incoming bi-
gram for each leaf v. In the second step we use
conventional dynamic programming over the hyper-
graph to find an optimal derivation that incorporates
weights from the first step. Finally, we fill in the
y(v, w) values. Each iteration of the algorithm runs
in O(|E|+ |B|) time.
There are close connections between Lagrangian
relaxation and linear programming relaxations. The
most important formal results are: 1) for any value
of u, L(u) ? f(y?) (hence the dual value provides
an upper bound on the optimal primal value); 2) un-
der an appropriate choice of the step sizes ?t, the
subgradient algorithm is guaranteed to converge to
the minimum of L(u) (i.e., we will minimize the
upper bound, making it as tight as possible); 3) if
at any point the algorithm in figure 1 finds a yt that
satisfies the C2 constraints, then this is guaranteed
to be the optimal primal solution.
Unfortunately, this algorithm may fail to produce
a good solution for hypergraphs where the strict or-
dering constraint does not hold. In this case it is
possible to find derivations y that satisfy constraints
C0, C1, C2, but which are invalid. As one exam-
ple, consider a derivation with s(y) = 2, 4, 5, 3 and
y(2, 3) = y(4, 5) = y(5, 4) = 1. The constraints
are all satisfied in this case, but the bigram variables
are invalid (e.g., they contain a cycle).
5 The Full Algorithm
We now describe our full algorithm, which does not
require the strict ordering constraint. In addition, the
full algorithm allows a trigram language model. We
first give a sketch, and then give a formal definition.
5.1 A Sketch of the Algorithm
A crucial idea in the new algorithm is that of
paths between leaves in hypergraph derivations.
Previously, for each derivation y, we had de-
fined s(y) = v1, v2, . . . , vn to be the sequence
of leaves in y. In addition, we will define
g(y) = p0, v1, p1, v2, p2, v3, p3, . . . , pn?1, vn, pn
where each pi is a path in the derivation between
leaves vi and vi+1. The path traces through the non-
terminals that are between the two leaves in the tree.
As an example, consider the following derivation
(with hyperedges ??2, 5?, 1? and ??3, 4?, 2?):
1
2
3 4
5
For this example g(y) is ?1 ?, 2 ?? ?2 ?, 3 ??
?3 ??, 3, ?3 ?? ?3 ?, 4 ?? ?4 ??, 4, ?4 ?? ?4 ?, 2 ??
?2 ?, 5 ?? ?5 ??, 5, ?5 ?? ?5 ?, 1 ??. States of the
form ?a ?? and ?a ?? where a is a leaf appear in
the paths respectively before/after the leaf a. States
of the form ?a, b? correspond to the steps taken in a
top-down, left-to-right, traversal of the tree, where
down and up arrows indicate whether a node is be-
ing visited for the first or second time (the traversal
in this case would be 1, 2, 3, 4, 2, 5, 1).
The mapping from a derivation y to a path g(y)
can be performed using the algorithm in figure 2.
For a given derivation y, define E(y) = {y : ye =
1}, and use E(y) as the set of input edges to this
algorithm. The output from the algorithm will be a
set of states S, and a set of directed edges T , which
together fully define the path g(y).
In the simple algorithm, the first step was to
predict the previous leaf for each leaf v, under
a score that combined a language model score
with a Lagrange multiplier score (i.e., compute
argmaxw ?(w, v) where ?(w, v) = ?(w, v) +
u(w)). In this section we describe an algorithm that
for each leaf v again predicts the previous leaf, but in
addition predicts the full path back to that leaf. For
example, rather than making a prediction for leaf 5
that it should be preceded by leaf 4, we would also
predict the path ?4 ???4 ?, 2 ?? ?2 ?, 5 ???5 ?? be-
tween these two leaves. Lagrange multipliers will
be used to enforce consistency between these pre-
dictions (both paths and previous words) and a valid
derivation.
76
Input: A set E of hyperedges. Output: A directed graph
S, T where S is a set of vertices, and T is a set of edges.
Step 1: Creating S: Define S = ?e?ES(e) where S(e)
is defined as follows. Assume e = ??v1, v2, . . . , vk?, v0?.
Include the following states in S(e): (1) ?v0 ?, v1 ?? and
?vk?, v0??. (2) ?vj ?, vj+1?? for j = 1 . . . k ? 1 (if k = 1
then there are no such states). (3) In addition, for any vj
for j = 1 . . . k such that vj ? VL, add the states ?vj ??
and ?vj ??.
Step 2: Creating T : T is formed by including the fol-
lowing directed arcs: (1) Add an arc from ?a, b? ? S
to ?c, d? ? S whenever b = c. (2) Add an arc from
?a, b ?? ? S to ?c ?? ? S whenever b = c. (3) Add
an arc from ?a ?? ? S to ?b ?, c? ? S whenever a = b.
Figure 2: Algorithm for constructing a directed graph
(S, T ) from a set of hyperedges E.
5.2 A Formal Description
We first use the algorithm in figure 2 with the en-
tire set of hyperedges, E, as its input. The result
is a directed graph (S, T ) that contains all possible
paths for valid derivations in V,E (it also contains
additional, ill-formed paths). We then introduce the
following definition:
Definition 5.1 A trigram path p is p =
?v1, p1, v2, p2, v3? where: a) v1, v2, v3 ? VL;
b) p1 is a path (sequence of states) between nodes
?v1 ?? and ?v2 ?? in the graph (S, T ); c) p2 is a
path between nodes ?v2 ?? and ?v3 ?? in the graph
(S, T ). We define P to be the set of all trigram paths
in (S, T ).
The set P of trigram paths plays an analogous role
to the set B of bigrams in our previous algorithm.
We use v1(p), p1(p), v2(p), p2(p), v3(p) to refer
to the individual components of a path p. In addi-
tion, define SN to be the set of states in S of the
form ?a, b? (as opposed to the form ?c ?? or ?c ??
where c ? VL).
We now define a new index set, I = V ? E ?
SN ? P , adding variables ys for s ? SN , and yp for
p ? P . If we take Y ? {0, 1}|I| to be the set of
valid derivations, the optimization problem is to find
y? = argmaxy?Y f(y), where f(y) = ? ? y, that is,
f(y) =
?
v
?vyv +
?
e
?eye +
?
s
?sys +
?
p
?pyp
In particular, we might define ?s = 0 for all s,
and ?p = log p(l(v3(p))|l(v1(p)), l(v2(p))) where
? D0. The yv and ye variables form a valid derivation
in the original hypergraph.
? D1. For all s ? SN , ys =
?
e:s?S(e) ye (see figure 2
for the definition of S(e)).
? D2. For all v ? VL, yv =
?
p:v3(p)=v yp
? D3. For all v ? VL, yv =
?
p:v2(p)=v yp
? D4. For all v ? VL, yv =
?
p:v1(p)=v yp
? D5. For all s ? SN , ys =
?
p:s?p1(p) yp
? D6. For all s ? SN , ys =
?
p:s?p2(p) yp
? Lagrangian with Lagrange multipliers for D3?D6:
L(y, ?, ?, u, v) = ? ? y
+
?
v ?v
(
yv ?
?
p:v2(p)=v yp
)
+
?
v ?v
(
yv ?
?
p:v1(p)=v yp
)
+
?
s us
(
ys ?
?
p:s?p1(p) yp
)
+
?
s vs
(
ys ?
?
p:s?p2(p) yp
)
.
Figure 3: Constraints D0?D6, and the Lagrangian.
p(w3|w1, w2) is a trigram probability.
The set P is large (typically exponential in size):
however, we will see that we do not need to represent
the yp variables explicitly. Instead we will be able
to leverage the underlying structure of a path as a
sequence of states.
The set of valid derivations is Y = {y :
y satisfies constraints D0?D6} where the constraints
are shown in figure 3. D1 simply states that ys = 1
iff there is exactly one edge e in the derivation such
that s ? S(e). Constraints D2?D4 enforce consis-
tency between leaves in the trigram paths, and the yv
values. Constraints D5 and D6 enforce consistency
between states seen in the paths, and the ys values.
The Lagrangian relaxation algorithm is then de-
rived in a similar way to before. Define
Y ? = {y : y satisfies constraints D0?D2}
We have dropped the D3?D6 constraints, but these
will be introduced using Lagrange multipliers. The
resulting Lagrangian is shown in figure 3, and can
be written as L(y, ?, ?, u, v) = ? ? y where ?v =
?v+?v+?v, ?s = ?s+us+vs, ?p = ?p??(v2(p))?
?(v1(p))?
?
s?p1(p) u(s)?
?
s?p2(p) v(s).
The dual is L(?, ?, u, v) =
maxy?Y ? L(y, ?, ?, u, v); figure 4 shows a sub-
gradient method that minimizes this dual. The key
step in the algorithm at each iteration is to compute
77
Initialization: Set ?0 = 0, ?0 = 0, u0 = 0, v0 = 0
Algorithm: For t = 1 . . . T :
? yt = argmaxy?Y? L(y, ?t?1, ?t?1, ut?1, vt?1)
? If yt satisfies the constraints D3?D6, return yt, else:
- ?v ? VL, ?tv = ?t?1v ? ?t(ytv ?
?
p:v2(p)=v y
t
p)
- ?v ? VL, ?tv = ?t?1v ? ?t(ytv ?
?
p:v1(p)=v y
t
p)
- ?s ? SN , uts = ut?1s ? ?t(yts ?
?
p:s?p1(p) y
t
p)
- ?s ? SN , vts = vt?1s ? ?t(yts ?
?
p:s?p2(p) y
t
p)
Figure 4: The full Lagrangian relaxation algortihm. ?t >
0 is the step size at iteration t.
argmaxy?Y ? L(y, ?, ?, u, v) = argmaxy?Y ? ? ? y
where ? is defined above. Again, our definition
of Y ? allows this maximization to be performed
efficiently, as follows:
1. For each v ? VL, define ??v =
argmaxp:v3(p)=v ?(p), and ?v = ?(??v).
(i.e., for each v, compute the highest scoring
trigram path ending in v.)
2. Find values for the yv, ye and ys variables that
form a valid derivation, and that maximize
f ?(y) =
?
v(?v+?v)yv+
?
e ?eye+
?
s ?sys
3. Set yp = 1 iff yv3(p) = 1 and p = ??v3(p).
The first step involves finding the highest scoring in-
coming trigram path for each leaf v. This step can be
performed efficiently using the Floyd-Warshall all-
pairs shortest path algorithm (Floyd, 1962) over the
graph (S, T ); the details are given in the appendix.
The second step involves simple dynamic program-
ming over the hypergraph (V,E) (it is simple to in-
tegrate the ?s terms into this algorithm). In the third
step, the path variables yp are filled in.
5.3 Properties
We now describe some important properties of the
algorithm:
Efficiency. The main steps of the algorithm are:
1) construction of the graph (S, T ); 2) at each it-
eration, dynamic programming over the hypergraph
(V,E); 3) at each iteration, all-pairs shortest path al-
gorithms over the graph (S, T ). Each of these steps
is vastly more efficient than computing an exact in-
tersection of the hypergraph with a language model.
Exact solutions. By usual guarantees for La-
grangian relaxation, if at any point the algorithm re-
turns a solution yt that satisfies constraints D3?D6,
then yt exactly solves the problem in Eq. 1.
Upper bounds. At each point in the algorithm,
L(?t, ?t, ut, vt) is an upper bound on the score of
the optimal primal solution, f(y?). Upper bounds
can be useful in evaluating the quality of primal so-
lutions from either our algorithm or other methods
such as cube pruning.
Simplicity of implementation. Construction of
the (S, T ) graph is straightforward. The other
steps?hypergraph dynamic programming, and all-
pairs shortest path?are widely known algorithms
that are simple to implement.
6 Tightening the Relaxation
The algorithm that we have described minimizes
the dual function L(?, ?, u, v). By usual results for
Lagrangian relaxation (e.g., see (Korte and Vygen,
2008)), L is the dual function for a particular LP re-
laxation arising from the definition of Y ? and the ad-
ditional constaints D3?D6. In some cases the LP
relaxation has an integral solution, in which case
the algorithm will return an optimal solution yt.7
In other cases, when the LP relaxation has a frac-
tional solution, the subgradient algorithm will still
converge to the minimum of L, but the primal solu-
tions yt will move between a number of solutions.
We now describe a method that incrementally
adds hard constraints to the set Y ?, until the method
returns an exact solution. For a given y ? Y ?,
for any v with yv = 1, we can recover the previ-
ous two leaves (the trigram ending in v) from ei-
ther the path variables yp, or the hypergraph vari-
ables ye. Specifically, define v?1(v, y) to be the leaf
preceding v in the trigram path p with yp = 1 and
v3(p) = v, and v?2(v, y) to be the leaf two posi-
tions before v in the trigram path p with yp = 1 and
v3(p) = v. Similarly, define v??1(v, y) and v??2(v, y)
to be the preceding two leaves under the ye vari-
ables. If the method has not converged, these two
trigram definitions may not be consistent. For a con-
7Provided that the algorithm is run for enough iterations for
convergence.
78
sistent solution, we require v?1(v, y) = v??1(v, y)
and v?2(v, y) = v??2(v, y) for all v with yv = 1.
Unfortunately, explicitly enforcing all of these con-
straints would require exhaustive dynamic program-
ming over the hypergraph using the (Bar-Hillel et
al., 1964) method, something we wish to avoid.
Instead, we enforce a weaker set of constraints,
which require far less computation. Assume some
function pi : VL ? {1, 2, . . . q} that partitions the
set of leaves into q different partitions. Then we will
add the following constraints to Y ?:
pi(v?1(v, y)) = pi(v??1(v, y))
pi(v?2(v, y)) = pi(v??2(v, y))
for all v such that yv = 1. Finding argmaxy?Y ? ? ?
y under this new definition of Y ? can be performed
using the construction of (Bar-Hillel et al, 1964),
with q different lexical items (for brevity we omit
the details). This is efficient if q is small.8
The remaining question concerns how to choose
a partition pi that is effective in tightening the relax-
ation. To do this we implement the following steps:
1) run the subgradient algorithm until L is close to
convergence; 2) then run the subgradient algorithm
for m further iterations, keeping track of all pairs
of leaf nodes that violate the constraints (i.e., pairs
a = v?1(v, y)/b = v??1(v, y) or a = v?2(v, y)/b =
v??2(v, y) such that a 6= b); 3) use a graph color-
ing algorithm to find a small partition that places all
pairs ?a, b? into separate partitions; 4) continue run-
ning Lagrangian relaxation, with the new constraints
added. We expand pi at each iteration to take into ac-
count new pairs ?a, b? that violate the constraints.
In related work, Sontag et al (2008) describe
a method for inference in Markov random fields
where additional constraints are chosen to tighten
an underlying relaxation. Other relevant work in
NLP includes (Tromble and Eisner, 2006; Riedel
and Clarke, 2006). Our use of partitions pi is related
to previous work on coarse-to-fine inference for ma-
chine translation (Petrov et al, 2008).
7 Experiments
We report experiments on translation from Chinese
to English, using the tree-to-string model described
8In fact in our experiments we use the original hypergraph
to compute admissible outside scores for an exact A* search
algorithm for this problem. We have found the resulting search
algorithm to be very efficient.
Time %age %age %age %age
(LR) (DP) (ILP) (LP)
0.5s 37.5 10.2 8.8 21.0
1.0s 57.0 11.6 13.9 31.1
2.0s 72.2 15.1 21.1 45.9
4.0s 82.5 20.7 30.7 63.7
8.0s 88.9 25.2 41.8 78.3
16.0s 94.4 33.3 54.6 88.9
32.0s 97.8 42.8 68.5 95.2
Median time 0.79s 77.5s 12.1s 2.4s
Figure 5: Results showing percentage of examples that are de-
coded in less than t seconds, for t = 0.5, 1.0, 2.0, . . . , 32.0. LR
= Lagrangian relaxation; DP = exhaustive dynamic program-
ming; ILP = integer linear programming; LP = linear program-
ming (LP does not recover an exact solution). The (I)LP ex-
periments were carried out using Gurobi, a high-performance
commercial-grade solver.
in (Huang and Mi, 2010). We use an identical
model, and identical development and test data, to
that used by Huang and Mi.9 The translation model
is trained on 1.5M sentence pairs of Chinese-English
data; a trigram language model is used. The de-
velopment data is the newswire portion of the 2006
NIST MT evaluation test set (616 sentences). The
test set is the newswire portion of the 2008 NIST
MT evaluation test set (691 sentences).
We ran the full algorithm with the tightening
method described in section 6. We ran the method
for a limit of 200 iterations, hence some exam-
ples may not terminate with an exact solution. Our
method gives exact solutions on 598/616 develop-
ment set sentences (97.1%), and 675/691 test set
sentences (97.7%).
In cases where the method does not converge
within 200 iterations, we can return the best primal
solution yt found by the algorithm during those it-
erations. We can also get an upper bound on the
difference f(y?)?f(yt) using mint L(ut) as an up-
per bound on f(y?). Of the examples that did not
converge, the worst example had a bound that was
1.4% of f(yt) (more specifically, f(yt) was -24.74,
and the upper bound on f(y?)? f(yt) was 0.34).
Figure 5 gives information on decoding time for
our method and two other exact decoding methods:
integer linear programming (using constraints D0?
D6), and exhaustive dynamic programming using
the construction of (Bar-Hillel et al, 1964). Our
9We thank Liang Huang and Haitao Mi for providing us with
their model and data.
79
method is clearly the most efficient, and is compara-
ble in speed to state-of-the-art decoding algorithms.
We also compare our method to cube pruning
(Chiang, 2007; Huang and Chiang, 2007). We reim-
plemented cube pruning in C++, to give a fair com-
parison to our method. Cube pruning has a parame-
ter, b, dictating the maximum number of items stored
at each chart entry. With b = 50, our decoder
finds higher scoring solutions on 50.5% of all exam-
ples (349 examples), the cube-pruning method gets a
strictly higher score on only 1 example (this was one
of the examples that did not converge within 200 it-
erations). With b = 500, our decoder finds better so-
lutions on 18.5% of the examples (128 cases), cube-
pruning finds a better solution on 3 examples. The
median decoding time for our method is 0.79 sec-
onds; the median times for cube pruning with b = 50
and b = 500 are 0.06 and 1.2 seconds respectively.
Our results give a very good estimate of the per-
centage of search errors for cube pruning. A natural
question is how large b must be before exact solu-
tions are returned on almost all examples. Even at
b = 1000, we find that our method gives a better
solution on 95 test examples (13.7%).
Figure 5 also gives a speed comparison of our
method to a linear programming (LP) solver that
solves the LP relaxation defined by constraints D0?
D6. We still see speed-ups, in spite of the fact
that our method is solving a harder problem (it pro-
vides integral solutions). The Lagrangian relaxation
method, when run without the tightening method
of section 6, is solving a dual of the problem be-
ing solved by the LP solver. Hence we can mea-
sure how often the tightening procedure is abso-
lutely necessary, by seeing how often the LP solver
provides a fractional solution. We find that this is
the case on 54.0% of the test examples: the tighten-
ing procedure is clearly important. Inspection of the
tightening procedure shows that the number of par-
titions required (the parameter q) is generally quite
small: 59% of examples that require tightening re-
quire q ? 6; 97.2% require q ? 10.
8 Conclusion
We have described a Lagrangian relaxation algo-
rithm for exact decoding of syntactic translation
models, and shown that it is significantly more effi-
cient than other exact algorithms for decoding tree-
to-string models. There are a number of possible
ways to extend this work. Our experiments have
focused on tree-to-string models, but the method
should also apply to Hiero-style syntactic transla-
tion models (Chiang, 2007). Additionally, our ex-
periments used a trigram language model, however
the constraints in figure 3 generalize to higher-order
language models. Finally, our algorithm recovers
the 1-best translation for a given input sentence; it
should be possible to extend the method to find k-
best solutions.
A Computing the Optimal Trigram Paths
For each v ? VL, define ?v = maxp:v3(p)=v ?(p), where
?(p) = h(v1(p), v2(p), v3(p))??1(v1(p))??2(v2(p))?
?
s?p1(p) u(s)?
?
s?p2(p) v(s). Here h is a function that
computes language model scores, and the other terms in-
volve Lagrange mulipliers. Our task is to compute ??v for
all v ? VL.
It is straightforward to show that the S, T graph is
acyclic. This will allow us to apply shortest path algo-
rithms to the graph, even though the weights u(s) and
v(s) can be positive or negative.
For any pair v1, v2 ? VL, define P(v1, v2) to be the
set of paths between ?v1 ?? and ?v2 ?? in the graph S, T .
Each path p gets a score scoreu(p) = ?
?
s?p u(s).
Next, define p?u(v1, v2) = argmaxp?P(v1,v2) scoreu(p),
and score?u(v1, v2) = scoreu(p?). We assume similar
definitions for p?v(v1, v2) and score?v(v1, v2). The p?u and
score?u values can be calculated using an all-pairs short-
est path algorithm, with weights u(s) on nodes in the
graph. Similarly, p?v and score?v can be computed using
all-pairs shortest path with weights v(s) on the nodes.
Having calculated these values, define T (v) for any
leaf v to be the set of trigrams (x, y, v) such that: 1)
x, y ? VL; 2) there is a path from ?x ?? to ?y ?? and from
?y ?? to ?v ?? in the graph S, T . Then we can calculate
?v = max
(x,y,v)?T (v)
(h(x, y, v)? ?1(x)? ?2(y)
+p?u(x, y) + p?v(y, v))
in O(|T (v)|) time, by brute force search through the set
T (v).
Acknowledgments Alexander Rush and Michael
Collins were supported under the GALE program of the
Defense Advanced Research Projects Agency, Contract
No. HR0011-06-C-0022. Michael Collins was also sup-
ported by NSF grant IIS-0915176. We also thank the
anonymous reviewers for very helpful comments; we
hope to fully address these in an extended version of the
paper.
80
References
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal
properties of simple phrase structure grammars. In
Language and Information: Selected Essays on their
Theory and Application, pages 116?150.
D. Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting on Association for Compu-
tational Linguistics, pages 263?270. Association for
Computational Linguistics.
D. Chiang. 2007. Hierarchical phrase-based translation.
computational linguistics, 33(2):201?228.
Adria de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. In Com-
putational linguistics, volume 36, pages 505?533.
Robert W. Floyd. 1962. Algorithm 97: Shortest path.
Commun. ACM, 5:345.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pages 144?151,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 273?283, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Rule filtering by pattern
for efficient hierarchical translation. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 380?388, Athens, Greece,
March. Association for Computational Linguistics.
N. Komodakis, N. Paragios, and G. Tziritas. 2007.
MRF optimization via dual decomposition: Message-
passing revisited. In International Conference on
Computer Vision.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decompo-
sition for parsing with non-projective head automata.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1288?1298, Cambridge, MA, October. Association for
Computational Linguistics.
B.H. Korte and J. Vygen. 2008. Combinatorial optimiza-
tion: theory and algorithms. Springer Verlag.
Shankar Kumar and William Byrne. 2005. Local phrase
reordering models for statistical machine translation.
In Proceedings of Human Language Technology Con-
ference and Conference on Empirical Methods in Nat-
ural Language Processing, pages 161?168, Vancou-
ver, British Columbia, Canada, October. Association
for Computational Linguistics.
I. Langkilde. 2000. Forest-based statistical sentence gen-
eration. In Proceedings of the 1st North American
chapter of the Association for Computational Linguis-
tics conference, pages 170?177. Morgan Kaufmann
Publishers Inc.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. Spmt: Statistical machine
translation with syntactified target language phrases.
In Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing, pages 44?
52, Sydney, Australia, July. Association for Computa-
tional Linguistics.
R.K. Martin, R.L. Rardin, and B.A. Campbell. 1990.
Polyhedral characterization of discrete dynamic pro-
gramming. Operations research, 38(1):127?138.
Slav Petrov, Aria Haghighi, and Dan Klein. 2008.
Coarse-to-fine syntactic machine translation using lan-
guage projections. In Proceedings of the 2008 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 108?116, Honolulu, Hawaii, October.
Association for Computational Linguistics.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP ?06, pages 129?137, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Alexander M Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
pages 1?11, Cambridge, MA, October. Association for
Computational Linguistics.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings of ACL-08: HLT, pages 577?585, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
D.A. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In Proc. EMNLP, pages 145?156.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP relaxations for MAP
using message passing. In Proc. UAI.
Roy W. Tromble and Jason Eisner. 2006. A fast
finite-state relaxation method for enforcing global con-
straints on sequence decoding. In Proceedings of
81
the main conference on Human Language Technology
Conference of the North American Chapter of the As-
sociation of Computational Linguistics, HLT-NAACL
?06, pages 423?430, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005. MAP
estimation via agreement on trees: message-passing
and linear programming. In IEEE Transactions on In-
formation Theory, volume 51, pages 3697?3717.
Taro Watanabe, Hajime Tsukada, and Hideki Isozaki.
2006. Left-to-right target generation for hierarchical
phrase-based translation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association for
Computational Linguistics, ACL-44, pages 777?784,
Morristown, NJ, USA. Association for Computational
Linguistics.
82
Dual Decomposition
for Natural Language Processing
Alexander M. Rush and Michael Collins
Decoding complexity
focus: decoding problem for natural language tasks
y
?
= arg max
y
f (y)
motivation:
? richer model structure often leads to improved accuracy
? exact decoding for complex models tends to be intractable
Decoding tasks
many common problems are intractable to decode exactly
high complexity
? combined parsing and part-of-speech tagging (Rush et al,
2010)
? ?loopy? HMM part-of-speech tagging
? syntactic machine translation (Rush and Collins, 2011)
NP-Hard
? symmetric HMM alignment (DeNero and Macherey, 2011)
? phrase-based translation
? higher-order non-projective dependency parsing (Koo et al,
2010)
in practice:
? approximate decoding methods (coarse-to-fine, beam search,
cube pruning, gibbs sampling, belief propagation)
? approximate models (mean field, variational models)
Motivation
cannot hope to find exact algorithms (particularly when NP-Hard)
aim: develop decoding algorithms with formal guarantees
method:
? derive fast algorithms that provide certificates of optimality
? show that for practical instances, these algorithms often yield
exact solutions
? provide strategies for improving solutions or finding
approximate solutions when no certificate is found
dual decomposition helps us develop algorithms of this form
Dual Decomposition (Komodakis et al, 2010; Lemare?chal, 2001)
goal: solve complicated optimization problem
y
?
= arg max
y
f (y)
method: decompose into subproblems, solve iteratively
benefit: can choose decomposition to provide ?easy? subproblems
aim for simple and efficient combinatorial algorithms
? dynamic programming
? minimum spanning tree
? shortest path
? min-cut
? bipartite match
? etc.
Related work
there are related methods used NLP with similar motivation
related methods:
? belief propagation (particularly max-product) (Smith and
Eisner, 2008)
? factored A* search (Klein and Manning, 2003)
? exact coarse-to-fine (Raphael, 2001)
aim to find exact solutions without exploring the full search space
Tutorial outline
focus:
? developing dual decomposition algorithms for new NLP tasks
? understanding formal guarantees of the algorithms
? extensions to improve exactness and select solutions
outline:
1. worked algorithm for combined parsing and tagging
2. important theorems and formal derivation
3. more examples from parsing, sequence labeling, MT
4. practical considerations for implementing dual decomposition
5. relationship to linear programming relaxations
6. further variations and advanced examples
1. Worked example
aim: walk through a dual decomposition algorithm for combined
parsing and part-of-speech tagging
? introduce formal notation for parsing and tagging
? give assumptions necessary for decoding
? step through a run of the dual decomposition algorithm
Combined parsing and part-of-speech tagging
S
NP
N
United
VP
V
flies
NP
D
some
A
large
N
jet
goal: find parse tree that optimizes
score(S ? NP VP) + score(VP ? V NP) +
...+ score(United1,N) + score(V,N) + ...
Constituency parsing
notation:
? Y is set of constituency parses for input
? y ? Y is a valid parse
? f (y) scores a parse tree
goal:
arg max
y?Y
f (y)
example: a context-free grammar for constituency parsing
S
NP
N
United
VP
V
flies
NP
D
some
A
large
N
jet
Part-of-speech tagging
notation:
? Z is set of tag sequences for input
? z ? Z is a valid tag sequence
? g(z) scores of a tag sequence
goal:
arg max
z?Z
g(z)
example: an HMM for part-of speech tagging
United1 flies2 some3 large4 jet5
N V D A N
Identifying tags
notation: identify the tag labels selected by each model
? y(i , t) = 1 when parse y selects tag t at position i
? z(i , t) = 1 when tag sequence z selects tag t at position i
example: a parse and tagging with y(4,A) = 1 and z(4,A) = 1
S
NP
N
United
VP
V
flies
NP
D
some
A
large
N
jet
y
United1 flies2 some3 large4 jet5
N V D A N
z
Combined optimization
goal:
arg max
y?Y,z?Z
f (y) + g(z)
such that for all i = 1 . . . n, t ? T ,
y(i , t) = z(i , t)
i.e. find the best parse and tagging pair that agree on tag labels
equivalent formulation:
arg max
y?Y
f (y) + g(l(y))
where l : Y ? Z extracts the tag sequence from a parse tree
Dynamic programming intersection
can solve by solving the product of the two models
example:
? parsing model is a context-free grammar
? tagging model is a first-order HMM
? can solve as CFG and finite-state automata intersection
replace S ? NP VP with
SN,N ? NPN,V VPV ,N
S
NP
N
United
VP
V
flies
NP
D
some
A
large
N
jet
Parsing assumption
the structure of Y is open (could be CFG, TAG, etc.)
assumption: optimization with u can be solved efficiently
arg max
y?Y
f (y) +
?
i ,t
u(i , t)y(i , t)
generally benign since u can be incorporated into the structure of f
example: CFG with rule scoring function h
f (y) =
?
X?Y Z?y
h(X ? Y Z ) +
?
(i ,X )?y
h(X ? wi )
where
arg maxy?Y f (y) +
?
i ,t
u(i , t)y(i , t) =
arg maxy?Y
?
X?Y Z?y
h(X ? Y Z ) +
?
(i ,X )?y
(h(X ? wi ) + u(i ,X ))
Tagging assumption
we make a similar assumption for the set Z
assumption: optimization with u can be solved efficiently
arg max
z?Z
g(z)?
?
i ,t
u(i , t)z(i , t)
example: HMM with scores for transitions T and observations O
g(z) =
?
t?t??z
T (t ? t ?) +
?
(i ,t)?z
O(t ? wi )
where
arg maxz?Z g(z)?
?
i ,t
u(i , t)z(i , t) =
arg maxz?Z
?
t?t??z
T (t ? t ?) +
?
(i ,t)?z
(O(t ? wi )? u(i , t))
Dual decomposition algorithm
Set u
(1)
(i , t) = 0 for all i , t ? T
For k = 1 to K
y
(k) ? arg max
y?Y
f (y) +
?
i ,t
u
(k)
(i , t)y(i , t) [Parsing]
z
(k) ? arg max
z?Z
g(z)?
?
i ,t
u
(k)
(i , t)z(i , t) [Tagging]
If y (k)(i , t) = z(k)(i , t) for all i , t Return (y (k), z(k))
Else u(k+1)(i , t)? u(k)(i , t)? ?k(y
(k)
(i , t)? z(k)(i , t))
Algorithm step-by-step
[Animation]
Main theorem
theorem: if at any iteration, for all i , t ? T
y
(k)
(i , t) = z(k)(i , t)
then (y
(k), z(k)) is the global optimum
proof: focus of the next section
2. Formal properties
aim: formal derivation of the algorithm given in the previous
section
? derive Lagrangian dual
? prove three properties
I upper bound
I convergence
I optimality
? describe subgradient method
Lagrangian
goal:
arg max
y?Y,z?Z
f (y) + g(z) such that y(i , t) = z(i , t)
Lagrangian:
L(u, y , z) = f (y) + g(z) +
?
i ,t
u(i , t) (y(i , t)? z(i , t))
redistribute terms
L(u, y , z) =
?
?f (y) +
?
i ,t
u(i , t)y(i , t)
?
?+
?
?g(z)?
?
i ,t
u(i , t)z(i , t)
?
?
Lagrangian dual
Lagrangian:
L(u, y , z) =
?
?f (y) +
?
i ,t
u(i , t)y(i , t)
?
?+
?
?g(z)?
?
i ,t
u(i , t)z(i , t)
?
?
Lagrangian dual:
L(u) = max
y?Y,z?Z
L(u, y , z)
= max
y?Y
?
?f (y) +
?
i ,t
u(i , t)y(i , t)
?
?+
max
z?Z
?
?g(z)?
?
i ,t
u(i , t)z(i , t)
?
?
Theorem 1. Upper bound
define:
? y
?, z? is the optimal combined parsing and tagging solution
with y
?
(i , t) = z?(i , t) for all i , t
theorem: for any value of u
L(u) ? f (y?) + g(z?)
L(u) provides an upper bound on the score of the optimal solution
note: upper bound may be useful as input to branch and bound or
A* search
Theorem 1. Upper bound (proof)
theorem: for any value of u, L(u) ? f (y?) + g(z?)
proof:
L(u) = max
y?Y,z?Z
L(u, y , z) (1)
? max
y?Y,z?Z:y=z
L(u, y , z) (2)
= max
y?Y,z?Z:y=z
f (y) + g(z) (3)
= f (y
?
) + g(z
?
) (4)
Formal algorithm (reminder)
Set u
(1)
(i , t) = 0 for all i , t ? T
For k = 1 to K
y
(k) ? arg max
y?Y
f (y) +
?
i ,t
u
(k)
(i , t)y(i , t) [Parsing]
z
(k) ? arg max
z?Z
g(z)?
?
i ,t
u
(k)
(i , t)z(i , t) [Tagging]
If y (k)(i , t) = z(k)(i , t) for all i , t Return (y (k), z(k))
Else u(k+1)(i , t)? u(k)(i , t)? ?k(y
(k)
(i , t)? z(k)(i , t))
Theorem 2. Convergence
notation:
? u
(k+1)
(i , t)? u(k)(i , t) + ?k(y
(k)
(i , t)? z(k)(i , t)) is update
? u
(k)
is the penalty vector at iteration k
? ?k is the update rate at iteration k
theorem: for any sequence ?1, ?2, ?3, . . . such that
lim
t??
?t = 0 and
??
t=1
?t =?,
we have
lim
t??
L(u
t
) = min
u
L(u)
i.e. the algorithm converges to the tightest possible upper bound
proof: by subgradient convergence (next section)
Dual solutions
define:
? for any value of u
yu = arg max
y?Y
?
?f (y) +
?
i ,t
u(i , t)y(i , t)
?
?
and
zu = arg max
z?Z
?
?g(z)?
?
i ,t
u(i , t)z(i , t)
?
?
? yu and zu are the dual solutions for a given u
Theorem 3. Optimality
theorem: if there exists u such that
yu(i , t) = zu(i , t)
for all i , t then
f (yu) + g(zu) = f (y
?
) + g(z
?
)
i.e. if the dual solutions agree, we have an optimal solution
(yu, zu)
Theorem 3. Optimality (proof)
theorem: if u such that yu(i , t) = zu(i , t) for all i , t then
f (yu) + g(zu) = f (y
?
) + g(z
?
)
proof: by the definitions of yu and zu
L(u) = f (yu) + g(zu) +
?
i ,t
u(i , t)(yu(i , t)? zu(i , t))
= f (yu) + g(zu)
since L(u) ? f (y?) + g(z?) for all values of u
f (yu) + g(zu) ? f (y
?
) + g(z
?
)
but y
?
and z
?
are optimal
f (yu) + g(zu) ? f (y
?
) + g(z
?
)
Dual optimization
Lagrangian dual:
L(u) = max
y?Y,z?Z
L(u, y , z)
= max
y?Y
?
?f (y) +
?
i ,t
u(i , t)y(i , t)
?
?+
max
z?Z
?
?g(z)?
?
i ,t
u(i , t)z(i , t)
?
?
goal: dual problem is to find the tightest upper bound
min
u
L(u)
Dual subgradient
L(u) = max
y?Y
?
?f (y) +
?
i,t
u(i , t)y(i , t)
?
?+ max
z?Z
?
?g(z)?
?
i,t
u(i , t)z(i , t)
?
?
properties:
? L(u) is convex in u (no local minima)
? L(u) is not differentiable (because of max operator)
handle non-differentiability by using subgradient descent
define: a subgradient of L(u) at u is a vector gu such that for all v
L(v) ? L(u) + gu ? (v ? u)
Subgradient algorithm
L(u) = max
y?Y
?
?f (y) +
?
i,t
u(i , t)y(i , t)
?
?+ max
z?Z
?
?g(z)?
?
i,j
u(i , t)z(i , t)
?
?
recall, yu and zu are the argmax?s of the two terms
subgradient:
gu(i , t) = yu(i , t)? zu(i , t)
subgradient descent: move along the subgradient
u
?
(i , t) = u(i , t)? ? (yu(i , t)? zu(i , t))
guaranteed to find a minimum with conditions given earlier for ?
3. More examples
aim: demonstrate similar algorithms that can be applied to other
decoding applications
? context-free parsing combined with dependency parsing
? corpus-level part-of-speech tagging
? combined translation alignment
Combined constituency and dependency parsing
setup: assume separate models trained for constituency and
dependency parsing
problem: find constituency parse that maximizes the sum of the
two models
example:
? combine lexicalized CFG with second-order dependency parser
Lexicalized constituency parsing
notation:
? Y is set of lexicalized constituency parses for input
? y ? Y is a valid parse
? f (y) scores a parse tree
goal:
arg max
y?Y
f (y)
example: a lexicalized context-free grammar
S(flies)
NP(United)
N
United
VP(flies)
V
flies
NP(jet)
D
some
A
large
N
jet
Dependency parsing
define:
? Z is set of dependency parses for input
? z ? Z is a valid dependency parse
? g(z) scores a dependency parse
example:
*0 United1 flies2 some3 large4 jet5
Identifying dependencies
notation: identify the dependencies selected by each model
? y(i , j) = 1 when constituency parse y selects word i as a
modifier of word j
? z(i , j) = 1 when dependency parse z selects word i as a
modifier of word j
example: a constituency and dependency parse with y(3, 5) = 1
and z(3, 5) = 1
S(flies)
NP(United)
N
United
VP(flies)
V
flies
NP(jet)
D
some
A
large
N
jet
y
*0 United1 flies2 some3 large4 jet5
z
Combined optimization
goal:
arg max
y?Y,z?Z
f (y) + g(z)
such that for all i = 1 . . . n, j = 0 . . . n,
y(i , j) = z(i , j)
Algorithm step-by-step
[Animation]
Corpus-level tagging
setup: given a corpus of sentences and a trained sentence-level
tagging model
problem: find best tagging for each sentence, while at the same
time enforcing inter-sentence soft constraints
example:
? test-time decoding with a trigram tagger
? constraint that each word type prefer a single POS tag
Corpus-level tagging
full model for corpus-level tagging
He saw an American man
The smart man stood outside
Man is the best measure
N
Sentence-level decoding
notation:
? Yi is set of tag sequences for input sentence i
? Y = Y1? . . .?Ym is set of tag sequences for the input corpus
? Y ? Y is a valid tag sequence for the corpus
? F (Y ) =
?
i
f (Yi ) is the score for tagging the whole corpus
goal:
arg max
Y?Y
F (Y )
example: decode each sentence with a trigram tagger
He
P
saw
V
an
D
American
A
man
N
The
D
smart
A
man
N
stood
V
outside
R
Inter-sentence constraints
notation:
? Z is set of possible assignments of tags to word types
? z ? Z is a valid tag assignment
? g(z) is a scoring function for assignments to word types
(e.g. a hard constraint - all word types only have one tag)
example: an MRF model that encourages words of the same type
to choose the same tag
z1
man
N
man
N
man
N
N
z2
man
N
man
N
man
A
N
g(z1) > g(z2)
Identifying word tags
notation: identify the tag labels selected by each model
? Ys(i , t) = 1 when the tagger for sentence s at position i
selects tag t
? z(s, i , t) = 1 when the constraint assigns at sentence s
position i the tag t
example: a parse and tagging with Y1(5,N) = 1 and
z(1, 5,N) = 1
He saw an American man
The smart man stood outside
Y
man man man
z
Combined optimization
goal:
arg max
Y?Y,z?Z
F (Y ) + g(z)
such that for all s = 1 . . .m, i = 1 . . . n, t ? T ,
Ys(i , t) = z(s, i , t)
Algorithm step-by-step
[Animation]
Combined alignment (DeNero and Macherey, 2011)
setup: assume separate models trained for English-to-French and
French-to-English alignment
problem: find an alignment that maximizes the score of both
models with soft agreement
example:
? HMM models for both directional alignments (assume correct
alignment is one-to-one for simplicity)
English-to-French alignment
define:
? Y is set of all possible English-to-French alignments
? y ? Y is a valid alignment
? f (y) scores of the alignment
example: HMM alignment
The1 ugly2 dog3 has4 red5 fur6
1 3 2 4 6 5
French-to-English alignment
define:
? Z is set of all possible French-to-English alignments
? z ? Z is a valid alignment
? g(z) scores of an alignment
example: HMM alignment
Le1 chien2 laid3 a4 fourrure5 rouge6
1 2 3 4 6 5
Identifying word alignments
notation: identify the tag labels selected by each model
? y(i , j) = 1 when e-to-f alignment y selects French word i to
align with English word j
? z(i , j) = 1 when f-to-e alignment z selects French word i to
align with English word j
example: two HMM alignment models with y(6, 5) = 1 and
z(6, 5) = 1
The1 ugly2 dog3 has4 red5 fur6
1 3 2 4 6 5
y
Le1 chien2 laid3 a4 fourrure5 rouge6
1 2 3 4 6 5
z
Combined optimization
goal:
arg max
y?Y,z?Z
f (y) + g(z)
such that for all i = 1 . . . n, j = 1 . . . n,
y(i , j) = z(i , j)
Algorithm step-by-step
[Animation]
4. Practical issues
aim: overview of practical dual decomposition techniques
? tracking the progress of the algorithm
? extracting solutions if algorithm does not converge
? lazy update of dual solutions
Tracking progress
at each stage of the algorithm there are several useful values
track:
? y
(k)
, z
(k)
are current dual solutions
? L(u
(k)
) is the current dual value
? y
(k)
, l(y
(k)
) is a potential primal feasible solution
? f (y
(k)
) + g(l(y
(k)
)) is the potential primal value
useful signals:
? L(u
(k)
)? L(u(k?1)) is the dual change (may be positive)
? min
k
L(u
(k)
) is the best dual value (tightest upper bound)
? max
k
f (y
(k)
) + g(l(y
(k)
)) is the best primal value
the optimal value must be between the best dual and primal values
Approximate solution
upon agreement the solution is exact, but this may not occur
otherwise, there is an easy way to find an approximate solution
choose: the structure y (k
?)
where
k
?
= arg max
k
f (y
(k)
) + g(l(y
(k)
))
is the iteration with the best primal score
guarantee: the solution yk
?
is non-optimal by at most
(min
t
L(u
t
))? (f (y (k
?)
) + g(l(y
(k ?)
)))
there are other methods to estimate solutions, for instance by
averaging solutions (see Nedic? and Ozdaglar (2009))
Lazy decoding
idea: don?t recompute y (k) or z(k) from scratch each iteration
lazy decoding: if subgradient u(k) is sparse, then y (k) may be
very easy to compute from y
(k?1)
use:
? very helpful if y or z factors naturally into several parts
? decompositions with this property are very fast in practice
example:
? in corpus-level tagging, only need to recompute sentences
with a word type that received an update
5. Linear programming
aim: explore the connections between dual decomposition and
linear programming
? basic optimization over the simplex
? formal properties of linear programming
? full example with fractional optimal solutions
? tightening linear program relaxations
Simplex
define:
? ?y is the simplex over Y where ? ? ?y implies
?y ? 0 and
?
y
?y = 1
? ?z is the simplex over Z
? ?y : Y ? ?y maps elements to the simplex
example:
Y = {y1, y2, y3}
vertices
? ?y (y1) = (1, 0, 0)
? ?y (y2) = (0, 1, 0)
? ?y (y3) = (0, 0, 1)
?y (y1)
?y (y2) ?y (y3)
?y
Linear programming
optimize over the simplices ?y and ?z instead of the discrete sets
Y and Z
goal: optimize linear program
max
???y ,???z
?
y
?y f (y) +
?
z
?zg(z)
such that for all i , t
?
y
?yy(i , t) =
?
z
?zz(i , t)
Lagrangian
Lagrangian:
M(u, ?, ?) =
?
y
?y f (y) +
?
z
?zg(z) +
?
i,t
u(i , t)
(
?
y
?yy(i , t)?
?
z
?zz(i , t)
)
=
(
?
y
?y f (y) +
?
i,t
u(i , t)
?
y
?yy(i , t)
)
+
(
?
z
?zg(z)?
?
i,t
u(i , t)
?
z
?zz(i , t)
)
Lagrangian dual:
M(u) = max
???y ,???z
M(u, ?, ?)
Strong duality
define:
? ??, ?? is the optimal assignment to ?, ? in the linear program
theorem:
min
u
M(u) =
?
y
??y f (y) +
?
z
??zg(z)
proof: by linear programming duality
Dual relationship
theorem: for any value of u,
M(u) = L(u)
note: solving the original Lagrangian dual also solves dual of the
linear program
Primal relationship
define:
? Q ? ?y ??z corresponds to feasible solutions of the original
problem
Q = {(?y (y), ?z(z)): y ? Y, z ? Z,
y(i , t) = z(i , t) for all (i , t)}
? Q? ? ?y ??z is the set of feasible solutions to the LP
Q? = {(?, ?): ? ? ?Y , ? ? ?Z ,
?
y ?yy(i , t) =
?
z ?zz(i , t) for all (i , t)}
? Q ? Q?
solutions:
max
q?Q
h(q) ? max
q?Q?
h(q) for any h
Concrete example
? Y = {y1, y2, y3}
? Z = {z1, z2, z3}
? ?y ? R
3
, ?z ? R
3
Y
x
a
He
a
is
y1
x
b
He
b
is
y2
x
c
He
c
is
y3
Z a
He
b
is
z1
b
He
a
is
z2
c
He
c
is
z3
Simple solution
Y
x
a
He
a
is
y1
x
b
He
b
is
y2
x
c
He
c
is
y3
Z a
He
b
is
z1
b
He
a
is
z2
c
He
c
is
z3
choose:
? ?(1) = (0, 0, 1) ? ?y is representation of y3
? ?(1) = (0, 0, 1) ? ?z is representation of z3
confirm: ?
y
?(1)y y(i , t) =
?
z
?(1)z z(i , t)
?(1) and ?(1) satisfy agreement constraint
Fractional solution
Y
x
a
He
a
is
y1
x
b
He
b
is
y2
x
c
He
c
is
y3
Z a
He
b
is
z1
b
He
a
is
z2
c
He
c
is
z3
choose:
? ?(2) = (0.5, 0.5, 0) ? ?y is combination of y1 and y2
? ?(2) = (0.5, 0.5, 0) ? ?z is combination of z1 and z2
confirm: ?
y
?(2)y y(i , t) =
?
z
?(2)z z(i , t)
?(2) and ?(2) satisfy agreement constraint, but not integral
Optimal solution
weights:
? the choice of f and g determines the optimal solution
? if (f , g) favors (?(2), ?(2)), the optimal solution is fractional
example: f = [1 1 2] and g = [1 1 ? 2]
? f ? ?(1) + g ? ?(1) = 0 vs f ? ?(2) + g ? ?(2) = 2
? ?(2), ?(2) is optimal, even though it is fractional
Algorithm run
[Animation]
Tightening (Sherali and Adams, 1994; Sontag et al, 2008)
modify:
? extend Y, Z to identify bigrams of part-of-speech tags
? y(i , t1, t2) = 1 ? y(i , t1) = 1 and y(i + 1, t2) = 1
? z(i , t1, t2) = 1 ? z(i , t1) = 1 and z(i + 1, t2) = 1
all bigram constraints: valid to add for all i , t1, t2 ? T
?
y
?yy(i , t1, t2) =
?
z
?zz(i , t1, t2)
however this would make decoding expensive
single bigram constraint: cheaper to implement
?
y
?yy(1, a, b) =
?
z
?zz(1, a, b)
the solution ?(1), ?(1) trivially passes this constraint, while
?(2), ?(2) violates it
Dual decomposition with tightening
tightened decomposition includes an additional Lagrange multiplier
yu,v = arg max
y?Y
f (y) +
?
i ,t
u(i , t)y(i , t) + v(1, a, b)y(1, a, b)
zu,v = arg max
z?Z
g(z)?
?
i ,t
u(i , t)z(i , t)? v(1, a, b)z(1, a, b)
in general, this term can make the decoding problem more difficult
example:
? for small examples, these penalties are easy to compute
? for CFG parsing, need to include extra states that maintain
tag bigrams (still faster than full intersection)
Tightening step-by-step
[Animation]
6. Advanced examples
aim: demonstrate some different relaxation techniques
? higher-order non-projective dependency parsing
? syntactic machine translation
Higher-order non-projective dependency parsing
setup: given a model for higher-order non-projective dependency
parsing (sibling features)
problem: find non-projective dependency parse that maximizes the
score of this model
difficulty:
? model is NP-hard to decode
? complexity of the model comes from enforcing combinatorial
constraints
strategy: design a decomposition that separates combinatorial
constraints from direct implementation of the scoring function
Non-projective dependency parsing
structure:
? starts at the root symbol *
? each word has a exactly one parent word
? produces a tree structure (no cycles)
? dependencies can cross
example:
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
Arc-Factored
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
f (y) = score(head =?0,mod =saw2) +score(saw2, John1)
+score(saw2,movie4) +score(saw2, today5)
+score(movie4, a3) + ...
e.g. score(?0, saw2) = log p(saw2|?0) (generative model)
or score(?0, saw2) = w ? ?(saw2, ?0) (CRF/perceptron model)
y
?
= arg max
y
f (y) ? Minimum Spanning Tree Algorithm
Sibling models
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
f (y) = score(head = ?0, prev = NULL,mod = saw2)
+score(saw2,NULL, John1)+score(saw2,NULL,movie4)
+score(saw2,movie4, today5) + ...
e.g. score(saw2,movie4, today5) = log p(today5|saw2,movie4)
or score(saw2,movie4, today5) = w ? ?(saw2,movie4, today5)
y
?
= arg max
y
f (y) ? NP-Hard
Thought experiment: individual decoding
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
score(saw2,NULL, John1) + score(saw2,NULL,movie4)
+score(saw2,movie4, today5)
score(saw2,NULL, John1) + score(saw2,NULL, that6)
score(saw2,NULL, a3) + score(saw2, a3,he7)
2
n?1
possibilities
under sibling model, can solve for each word with Viterbi decoding.
Thought experiment continued
*0 John1 saw2 a3 movie4 today5 that6 he7 liked8
idea: do individual decoding for each head word using dynamic
programming
if we?re lucky, we?ll end up with a valid final tree
but we might violate some constraints
Dual decomposition structure
goal:
y
?
= arg max
y?Y
f (y)
rewrite:
arg max
y? Y z? Z,
f (y) + g(z)
such that for all i , j
y(i , j) = z(i , j)
Algorithm step-by-step
[Animation]
Syntactic translation decoding
setup: assume a trained model for syntactic machine translation
problem: find best derivation that maximizes the score of this
model
difficulty:
? need to incorporate language model in decoding
? empirically, relaxation is often not tight, so dual
decomposition does not always converge
strategy:
? use a different relaxation to handle language model
? incrementally add constraints to find exact solution
Syntactic translation example
[Animation]
Summary
presented dual decomposition as a method for decoding in NLP
formal guarantees
? gives certificate or approximate solution
? can improve approximate solutions by tightening relaxation
efficient algorithms
? uses fast combinatorial algorithms
? can improve speed with lazy decoding
widely applicable
? demonstrated algorithms for a wide range of NLP tasks
(parsing, tagging, alignment, mt decoding)
References I
J. DeNero and K. Macherey. Model-Based Aligner Combination
Using Dual Decomposition. In Proc. ACL, 2011.
D. Klein and C.D. Manning. Factored A* Search for Models over
Sequences and Trees. In Proc IJCAI, volume 18, pages
1246?1251. Citeseer, 2003.
N. Komodakis, N. Paragios, and G. Tziritas. Mrf energy
minimization and beyond via dual decomposition. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
2010. ISSN 0162-8828.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola,
and David Sontag. Dual decomposition for parsing with
non-projective head automata. In EMNLP, 2010. URL
http://www.aclweb.org/anthology/D10-1125.
B.H. Korte and J. Vygen. Combinatorial Optimization: Theory and
Algorithms. Springer Verlag, 2008.
References II
C. Lemare?chal. Lagrangian Relaxation. In Computational
Combinatorial Optimization, Optimal or Provably Near-Optimal
Solutions [based on a Spring School], pages 112?156, London,
UK, 2001. Springer-Verlag. ISBN 3-540-42877-1.
Angelia Nedic? and Asuman Ozdaglar. Approximate primal
solutions and rate analysis for dual subgradient methods. SIAM
Journal on Optimization, 19(4):1757?1780, 2009.
Christopher Raphael. Coarse-to-fine dynamic programming. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 23:
1379?1390, 2001.
A.M. Rush and M. Collins. Exact Decoding of Syntactic
Translation Models through Lagrangian Relaxation. In Proc.
ACL, 2011.
A.M. Rush, D. Sontag, M. Collins, and T. Jaakkola. On Dual
Decomposition and Linear Programming Relaxations for Natural
Language Processing. In Proc. EMNLP, 2010.
References III
Hanif D. Sherali and Warren P. Adams. A hierarchy of relaxations
and convex hull characterizations for mixed-integer zero?one
programming problems. Discrete Applied Mathematics, 52(1):83
? 106, 1994.
D.A. Smith and J. Eisner. Dependency Parsing by Belief
Propagation. In Proc. EMNLP, pages 145?156, 2008. URL
http://www.aclweb.org/anthology/D08-1016.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss.
Tightening LP relaxations for MAP using message passing. In
Proc. UAI, 2008.
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1481?1490,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
A Constrained Viterbi Relaxation for Bidirectional Word Alignment
Yin-Wen Chang Alexander M. Rush
MIT CSAIL,
Cambridge, MA 02139
{yinwen,srush}@
csail.mit.edu
John DeNero
UC Berkeley,
Berkeley, CA 94720
denero@
cs.berkeley.edu
Michael Collins
Columbia University,
New York, NY 10027
mcollins@
cs.columbia.edu
Abstract
Bidirectional models of word alignment
are an appealing alternative to post-hoc
combinations of directional word align-
ers. Unfortunately, most bidirectional
formulations are NP-Hard to solve, and
a previous attempt to use a relaxation-
based decoder yielded few exact solu-
tions (6%). We present a novel relax-
ation for decoding the bidirectional model
of DeNero and Macherey (2011). The
relaxation can be solved with a mod-
ified version of the Viterbi algorithm.
To find optimal solutions on difficult
instances, we alternate between incre-
mentally adding constraints and applying
optimality-preserving coarse-to-fine prun-
ing. The algorithm finds provably ex-
act solutions on 86% of sentence pairs
and shows improvements over directional
models.
1 Introduction
Word alignment is a critical first step for build-
ing statistical machine translation systems. In or-
der to ensure accurate word alignments, most sys-
tems employ a post-hoc symmetrization step to
combine directional word aligners, such as IBM
Model 4 (Brown et al, 1993) or hidden Markov
model (HMM) based aligners (Vogel et al, 1996).
Several authors have proposed bidirectional mod-
els that incorporate this step directly, but decoding
under many bidirectional models is NP-Hard and
finding exact solutions has proven difficult.
In this paper, we describe a novel Lagrangian-
relaxation based decoder for the bidirectional
model proposed by DeNero and Macherey (2011),
with the goal of improving search accuracy.
In that work, the authors implement a dual
decomposition-based decoder for the problem, but
are only able to find exact solutions for around 6%
of instances.
Our decoder uses a simple variant of the Viterbi
algorithm for solving a relaxed version of this
model. The algorithm makes it easy to re-
introduce constraints for difficult instances, at the
cost of increasing run-time complexity. To offset
this cost, we employ optimality-preserving coarse-
to-fine pruning to reduce the search space. The
pruning method utilizes lower bounds on the cost
of valid bidirectional alignments, which we obtain
from a fast, greedy decoder.
The method has the following properties:
? It is based on a novel relaxation for the model
of DeNero and Macherey (2011), solvable
with a variant of the Viterbi algorithm.
? To find optimal solutions, it employs an effi-
cient strategy that alternates between adding
constraints and applying pruning.
? Empirically, it is able to find exact solutions
on 86% of sentence pairs and is significantly
faster than general-purpose solvers.
We begin in Section 2 by formally describing
the directional word alignment problem. Section 3
describes a preliminary bidirectional model us-
ing full agreement constraints and a Lagrangian
relaxation-based solver. Section 4 modifies this
model to include adjacency constraints. Section 5
describes an extension to the relaxed algorithm to
explicitly enforce constraints, and Section 6 gives
a pruning method for improving the efficiency of
the algorithm.
Experiments compare the search error and accu-
racy of the new bidirectional algorithm to several
directional combiners and other bidirectional al-
gorithms. Results show that the new relaxation is
much more effective at finding exact solutions and
is able to produce comparable alignment accuracy.
1481
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
Figure 1: An example e?f directional alignment for the sen-
tences let us see the documents and montrez -
nous les documents, with I = 5 and J = 5. The in-
dices i ? [I]
0
are rows, and the indices j ? [J ]
0
are columns.
The HMM alignment shown has transitions x(0, 1, 1) =
x(1, 2, 3) = x(3, 3, 1) = x(1, 4, 4) = x(4, 5, 5) = 1.
Notation We use lower- and upper-case letters
for scalars and vectors, and script-case for sets
e.g. X . For vectors, such as v ? {0, 1}
(I?J )?J
,
where I and J are finite sets, we use the notation
v(i, j) and v(j) to represent elements of the vec-
tor. Define d = ?(i) to be the indicator vector with
d(i) = 1 and d(i
?
) = 0 for all i
?
6= i. Finally de-
fine the notation [J ] to refer to {1 . . . J} and [J ]
0
to refer to {0 . . . J}.
2 Background
The focus of this work is on the word alignment
decoding problem. Given a sentence e of length
|e| = I and a sentence f of length |f | = J , our
goal is to find the best bidirectional alignment be-
tween the two sentences under a given objective
function. Before turning to the model of interest,
we first introduce directional word alignment.
2.1 Word Alignment
In the e?f word alignment problem, each word
in e is aligned to a word in f or to the null word .
This alignment is a mapping from each index i ?
[I] to an index j ? [J ]
0
(where j = 0 represents
alignment to ). We refer to a single word align-
ment as a link.
A first-order HMM alignment model (Vogel et
al., 1996) is an HMM of length I + 1 where the
hidden state at position i ? [I]
0
is the aligned in-
dex j ? [J ]
0
, and the transition score takes into
account the previously aligned index j
?
? [J ]
0
.
1
Formally, define the set of possible HMM align-
ments as X ? {0, 1}
([I]
0
?[J ]
0
)?([I]?[J ]
0
?[J ]
0
)
with
1
Our definition differs slightly from other HMM-based
aligners in that it does not track the last  alignment.
X =
?
?
?
?
?
?
?
?
?
x : x(0, 0) = 1,
x(i, j) =
J?
j
?
=0
x(j
?
, i, j) ?i ? [I], j ? [J ]
0
,
x(i, j) =
J?
j
?
=0
x(j, i+ 1, j
?
) ?i ? [I ? 1]
0
, j ? [J ]
0
where x(i, j) = 1 indicates that there is a link
between index i and index j, and x(j
?
, i, j) = 1
indicates that index i ? 1 aligns to index j
?
and
index i aligns to j. Figure 1 shows an example
member of X .
The constraints of X enforce backward and for-
ward consistency respectively. If x(i, j) = 1,
backward consistency enforces that there is a tran-
sition from (i? 1, j
?
) to (i, j) for some j
?
? [J ]
0
,
whereas forward consistency enforces a transition
from (i, j) to (i+ 1, j
?
) for some j
?
? [J ]
0
. Infor-
mally the constraints ?chain? together the links.
The HMM objective function f : X ? R can
be written as a linear function of x
f(x; ?) =
I
?
i=1
J
?
j=0
J
?
j
?
=0
?(j
?
, i, j)x(j
?
, i, j)
where the vector ? ? R
[I]?[J ]
0
?[J ]
0
includes the
transition and alignment scores. For a generative
model of alignment, we might define ?(j
?
, i, j) =
log(p(e
i
|f
j
)p(j|j
?
)). For a discriminative model
of alignment, we might define ?(j
?
, i, j) = w ?
?(i, j
?
, j, f , e) for a feature function ? and weights
w (Moore, 2005; Lacoste-Julien et al, 2006).
Now reverse the direction of the model and
consider the f?e alignment problem. An f?e
alignment is a binary vector y ? Y where for
each j ? [J ], y(i, j) = 1 for exactly one i ?
[I]
0
. Define the set of HMM alignments Y ?
{0, 1}
([I]
0
?[J ]
0
)?([I]
0
?[I]
0
?[J ])
as
Y =
?
?
?
?
?
?
?
?
?
y : y(0, 0) = 1,
y(i, j) =
I?
i
?
=0
y(i
?
, i, j) ?i ? [I]
0
, j ? [J ],
y(i, j) =
I?
i
?
=0
y(i, i
?
, j + 1) ?i ? [I]
0
, j ? [J ? 1]
0
Similarly define the objective function
g(y;?) =
J
?
j=1
I
?
i=0
I
?
i
?
=0
?(i
?
, i, j)y(i
?
, i, j)
with vector ? ? R
[I]
0
?[I]
0
?[J ]
.
1482
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(a)
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(b)
Figure 2: (a) An example alignment pair (x, y) satisfying the
full agreement conditions. The x alignment is represented
with circles and the y alignment with triangles. (b) An exam-
ple f?e alignment y ? Y
?
with relaxed forward constraints.
Note that unlike an alignment from Y multiple words may
be aligned in a column and words may transition from non-
aligned positions.
Note that for both of these models we can solve
the optimization problem exactly using the stan-
dard Viterbi algorithm for HMM decoding. The
first can be solved in O(IJ
2
) time and the second
in O(I
2
J) time.
3 Bidirectional Alignment
The directional bias of the e?f and f?e align-
ment models may cause them to produce differing
alignments. To obtain the best single alignment,
it is common practice to use a post-hoc algorithm
to merge these directional alignments (Och et al,
1999). First, a directional alignment is found from
each word in e to a word f . Next an alignment is
produced in the reverse direction from f to e. Fi-
nally, these alignments are merged, either through
intersection, union, or with an interpolation algo-
rithm such as grow-diag-final (Koehn et al, 2003).
In this work, we instead consider a bidirectional
alignment model that jointly considers both direc-
tional models. We begin in this section by in-
troducing a simple bidirectional model that en-
forces full agreement between directional models
and giving a relaxation for decoding. Section 4
loosens this model to adjacent agreement.
3.1 Enforcing Full Agreement
Perhaps the simplest post-hoc merging strategy is
to retain the intersection of the two directional
models. The analogous bidirectional model en-
forces full agreement to ensure the two alignments
select the same non-null links i.e.
x
?
, y
?
= argmax
x?X ,y?Y
f(x) + g(y) s.t.
x(i, j) = y(i, j) ?i ? [I], j ? [J ]
We refer to the optimal alignments for this prob-
lem as x
?
and y
?
.
Unfortunately this bidirectional decoding
model is NP-Hard (a proof is given in Ap-
pendix A). As it is common for alignment pairs to
have |f | or |e| over 40, exact decoding algorithms
are intractable in the worst-case.
Instead we will use Lagrangian relaxation for
this model. At a high level, we will remove a
subset of the constraints from the original problem
and replace them with Lagrange multipliers. If we
can solve this new problem efficiently, we may be
able to get optimal solutions to the original prob-
lem. (See the tutorial by Rush and Collins (2012)
describing the method.)
There are many possible subsets of constraints
to consider relaxing. The relaxation we use pre-
serves the agreement constraints while relaxing
the Markov structure of the f?e alignment. This
relaxation will make it simple to later re-introduce
constraints in Section 5.
We relax the forward constraints of set Y . With-
out these constraints the y links are no longer
chained together. This has two consequences: (1)
for index j there may be any number of indices i,
such that y(i, j) = 1, (2) if y(i
?
, i, j) = 1 it is no
longer required that y(i
?
, j ? 1) = 1. This gives a
set Y
?
which is a superset of Y
Y
?
=
{
y : y(0, 0) = 1,
y(i, j) =
?
I
i
?
=0
y(i
?
, i, j) ?i ? [I]
0
, j ? [J ]
Figure 2(b) shows a possible y ? Y
?
and a valid
unchained structure.
To form the Lagrangian dual with relaxed for-
ward constraints, we introduce a vector of La-
grange multipliers, ? ? R
[I?1]
0
?[J ]
0
, with one
multiplier for each original constraint. The La-
grangian dual L(?) is defined as
max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
I?
i
?
=0
y(i
?
, i, j)?(i
?
, i, j) (1)
?
I?
i=0
J?1?
j=0
?(i, j)
(
y(i, j)?
I?
i
?
=0
y(i, i
?
, j + 1)
)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
I?
i
?
=0
y(i
?
, i, j)?
?
(i
?
, i, j)(2)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
y(i, j) max
i
?
?[I]
0
?
?
(i
?
, i, j)(3)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) + g
?
(y;?, ?) (4)
1483
Line 2 distributes the ??s and introduces a modi-
fied potential vector ?
?
defined as
?
?
(i
?
, i, j) = ?(i
?
, i, j)? ?(i, j) + ?(i
?
, j ? 1)
for all i
?
? [I]
0
, i ? [I]
0
, j ? [J ]. Line 3 uti-
lizes the relaxed set Y
?
which allows each y(i, j)
to select the best possible previous link (i
?
, j ? 1).
Line 4 introduces the modified directional objec-
tive
g
?
(y;?, ?) =
I
?
i=1
J
?
j=0
y(i, j) max
i
?
?[I]
0
?
?
(i
?
, i, j)
The Lagrangian dual is guaranteed to be an up-
per bound on the optimal solution, i.e. for all ?,
L(?) ? f(x
?
) + g(y
?
). Lagrangian relaxation
attempts to find the tighest possible upper bound
by minimizing the Lagrangian dual, min
?
L(?),
using subgradient descent. Briefly, subgradient
descent is an iterative algorithm, with two steps.
Starting with ? = 0, we iteratively
1. Set (x, y) to the argmax of L(?).
2. Update ?(i, j) for all i ? [I ? 1]
0
, j ? [J ]
0
,
?(i, j)? ?(i, j)? ?
t
(
y(i, j)?
I?
i
?
=0
y(i, i
?
, j + 1)
)
.
where ?
t
> 0 is a step size for the t?th update. If
at any iteration of the algorithm the forward con-
straints are satisfied for (x, y), then f(x)+g(y) =
f(x
?
) + g(x
?
) and we say this gives a certificate
of optimality for the underlying problem.
To run this algorithm, we need to be able to effi-
ciently compute the (x, y) pair that is the argmax
of L(?) for any value of ?. Fortunately, since the y
alignments are no longer constrained to valid tran-
sitions, we can compute these alignments by first
picking the best f?e transitions for each possible
link, and then running an e?f Viterbi-style algo-
rithm to find the bidirectional alignment.
The max version of this algorithm is shown in
Figure 3. It consists of two steps. We first compute
the score for each y(i, j) variable. We then use the
standard Viterbi update for computing the x vari-
ables, adding in the score of the y(i, j) necessary
to satisfy the constraints.
procedure VITERBIFULL(?, ?
?
)
Let pi, ? be dynamic programming charts.
?[i, j]? max
i
?
?[I]
0
?
?
(i
?
, i, j) ? i ? [I], j ? [J ]
0
pi[0, 0]?
?
J
j=1
max{0, ?[0, j]}
for i ? [I], j ? [J ]
0
in order do
pi[i, j]? max
j
?
?[J]
0
?(j
?
, i, j) + pi[i? 1, j
?
]
if j 6= 0 then pi[i, j]? pi[i, j] + ?[i, j]
return max
j?[J]
0
pi[I, j]
Figure 3: Viterbi-style algorithm for computing L(?). For
simplicity the algorithm shows the max version of the algo-
rithm, argmax can be computed with back-pointers.
4 Adjacent Agreement
Enforcing full agreement can be too strict an align-
ment criteria. DeNero and Macherey (2011) in-
stead propose a model that allows near matches,
which we call adjacent agreement. Adjacent
agreement allows links from one direction to agree
with adjacent links from the reverse alignment for
a small penalty. Figure 4(a) shows an example
of a valid bidirectional alignment under adjacent
agreement.
In this section we formally introduce adjacent
agreement, and propose a relaxation algorithm for
this model. The key algorithmic idea is to extend
the Viterbi algorithm in order to consider possible
adjacent links in the reverse direction.
4.1 Enforcing Adjacency
Define the adjacency set K = {?1, 0, 1}. A bidi-
rectional alignment satisfies adjacency if for all
i ? [I], j ? [J ],
? If x(i, j) = 1, it is required that y(i+k, j) =
1 for exactly one k ? K (i.e. either above,
center, or below). We indicate which position
with variables z
l
i,j
? {0, 1}
K
? If x(i, j) = 1, it is allowed that y(i, j + k) =
1 for any k ? K (i.e. either left, center, or
right) and all other y(i, j
?
) = 0. We indicate
which positions with variables z
?
i,j
? {0, 1}
K
Formally for x ? X and y ? Y , the pair (x, y) is
feasible if there exists a z from the set Z(x, y) ?
{0, 1}
K
2
?[I]?[J ]
defined as
Z(x, y) =
?
?
?
?
?
?
?
?
?
z : ?i ? [I], j ? [J ]
z
l
i,j
? {0, 1}
K
, z
?
i,j
? {0, 1}
K
x(i, j) =
?
k?K
z
l
i,j
(k),
?
k?K
z
?
i,j
(k) = y(i, j),
z
l
i,j
(k) ? y(i+ k, j) ?k ? K : i+ k > 0,
x(i, j) ? z
?
i,j?k
(k) ?k ? K : j + k > 0
1484
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(a)
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(b)
Figure 4: (a) An alignment satisfying the adjacency con-
straints. Note that x(2, 1) = 1 is allowed because of
y(1, 1) = 1, x(4, 3) = 1 because of y(3, 3), and y(3, 1)
because of x(3, 2). (b) An adjacent bidirectional alignment
in progress. Currently x(2, 2) = 1 with z
l
(?1) = 1 and
z
?
(?1) = 1. The last transition was from x(1, 3) with
z
??
(?1) = 1, z
??
(0) = 1, z
l?
(0) = 1.
Additionally adjacent, non-overlapping
matches are assessed a penalty ? calculated as
h(z) =
I
?
i=1
J
?
j=1
?
k?K
?|k|(z
l
i,j
(k) + z
?
i,j
(k))
where ? ? 0 is a parameter of the model. The
example in Figure 4(a) includes a 3? penalty.
Adding these penalties gives the complete adja-
cent agreement problem
argmax
z?Z(x,y)
x?X ,y?Y
f(x) + g(y) + h(z)
Next, apply the same relaxation from Sec-
tion 3.1, i.e. we relax the forward constraints of
the f?e set. This yields the following Lagrangian
dual
L(?) = max
z?Z(x,y)
x?X ,y?Y
?
f(x) + g
?
(y;?, ?) + h(z)
Despite the new constraints, we can still com-
pute L(?) in O(IJ(I + J)) time using a variant
of the Viterbi algorithm. The main idea will be to
consider possible adjacent settings for each link.
Since each z
l
i,j
and z
?
i,j
only have a constant num-
ber of settings, this does not increase the asymp-
totic complexity of the algorithm.
Figure 5 shows the algorithm for computing
L(?). The main loop of the algorithm is similar to
Figure 3. It proceeds row-by-row, picking the best
alignment x(i, j) = 1. The major change is that
the chart pi also stores a value z ? {0, 1}
K?K
rep-
resenting a possible z
l
i,j
, z
?
i,j
pair. Since we have
procedure VITERBIADJ(?, ?
?
)
?[i, j]? max
i
?
?[I]
0
?
?
(i
?
, i, j) ? i ? [I], j ? [J ]
0
pi[0, 0]?
?
J
j=1
max{0, ?[0, j]}
for i ? [I], j ? [J ]
0
, z
l
, z
?
? {0, 1}
|K|
do
pi[i, j, z]?
max
j
?
?[J]
0
,
z
?
?N (z,j?j
?
)
?(j
?
, i, j) + pi[i? 1, j
?
, z
?
]
+
?
k?K
z
?
(k)(?[i, j + k] + ?|k|)
+z
l
(k)?|k|
return max
j?[J]
0
,z?{0,1}
|K?K|
pi[I, j, z]
Figure 5: Modified Viterbi algorithm for computing the adja-
cent agreement L(?).
the proposed z
i,j
in the inner loop, we can include
the scores of the adjacent y alignments that are
in neighboring columns, as well as the possible
penalty for matching x(i, j) to a y(i + k, j) in a
different row. Figure 4(b) gives an example set-
ting of z.
In the dynamic program, we need to ensure that
the transitions between the z?s are consistent. The
vector z
?
indicates the y links adjacent to x(i ?
1, j
?
). If j
?
is near to j, z
?
may overlap with z
and vice-versa. The transition setN ensures these
indicators match up
N (z, k
?
) =
?
?
?
z
?
: (z
l
(?1) ? k
?
? K)? z
??
(k
?
),
(z
l?
(1) ? k
?
? K)? z
?
(?k
?
),
?
k?K
z
l
(k) = 1
5 Adding Back Constraints
In general, it can be shown that Lagrangian relax-
ation is only guaranteed to solve a linear program-
ming relaxation of the underlying combinatorial
problem. For difficult instances, we will see that
this relaxation often does not yield provably exact
solutions. However, it is possible to ?tighten? the
relaxation by re-introducing constraints from the
original problem.
In this section, we extend the algorithm to al-
low incrementally re-introducing constraints. In
particular we track which constraints are most of-
ten violated in order to explicitly enforce them in
the algorithm.
Define a binary vector p ? {0, 1}
[I?1]
0
?[J ]
0
where p(i, j) = 1 indicates a previously re-
laxed constraint on link y(i, j) that should be re-
introduced into the problem. Let the new partially
1485
constrained Lagrangian dual be defined as
L(?; p) = max
z?Z(x,y)
x?X ,y?Y
?
f(x) + g
?
(y;?, ?) + h(z)
y(i, j) =
?
i
?
y(i, i
?
, j + 1) ?i, j : p(i, j) = 1
If p =
~
1, the problem includes all of the original
constraints, whereas p =
~
0 gives our original La-
grangian dual. In between we have progressively
more constrained variants.
In order to compute the argmax of this op-
timization problem, we need to satisfy the con-
straints within the Viterbi algorithm. We augment
the Viterbi chart with a count vector d ? D where
D ? Z
||p||
1
and d(i, j) is a count for the (i, j)?th
constraint, i.e. d(i, j) = y(i, j) ?
?
i
?
y(i
?
, i, j).
Only solutions with count 0 at the final position
satisfy the active constraints. Additionally de-
fine a helper function [?]
D
as the projection from
Z
[I?1]
0
?[J ]
? D, which truncates dimensions
without constraints.
Figure 6 shows this constrained Viterbi relax-
ation approach. It takes p as an argument and en-
forces the active constraints. For simplicity, we
show the full agreement version, but the adjacent
agreement version is similar. The main new addi-
tion is that the inner loop of the algorithm ensures
that the count vector d is the sum of the counts of
its children d
?
and d? d
?
.
Since each additional constraint adds a dimen-
sion to d, adding constraints has a multiplicative
impact on running time. Asymptotically the new
algorithm requires O(2
||p||
1
IJ(I + J)) time. This
is a problem in practice as even adding a few con-
straints can make the problem intractable. We ad-
dress this issue in the next section.
6 Pruning
Re-introducing constraints can lead to an expo-
nential blow-up in the search space of the Viterbi
algorithm. In practice though, many alignments
in this space are far from optimal, e.g. align-
ing a common word like the to nous instead
of les. Since Lagrangian relaxation re-computes
the alignment many times, it would be preferable
to skip these links in later rounds, particularly after
re-introducing constraints.
In this section we describe an optimality pre-
serving coarse-to-fine algorithm for pruning. Ap-
proximate coarse-to-fine pruning algorithms are
procedure CONSVITERBIFULL(?, ?
?
, p)
for i ? [I], j ? [J ]
0
, i
?
? [I] do
d? |?(i, j)? ?(i
?
, j ? 1)|
D
?[i, j, d]? ?
?
(i
?
, i, j)
for j ? [J ], d ? D do
pi[0, 0, d]? max
d
?
?D
pi[0, 0, d
?
] + ?[0, j, d? d
?
]
for i ? [I], j ? [J ]
0
, d ? D do
if j = 0 then
pi[i, j, d]? max
j
?
?[J]
0
?(j
?
, i, j) + pi[i? 1, j
?
, d]
else
pi[i, j, d]?
max
j
?
?[J]
0
,d
?
?D
?(j
?
, i, j) + pi[i? 1, j
?
, d
?
]
+?[i, j, d? d
?
]
return max
j?[J]
0
pi[I, j,0]
Figure 6: Constrained Viterbi algorithm for finding partially-
constrained, full-agreement alignments. The argument p in-
dicates which constraints to enforce.
widely used within NLP, but exact pruning is
less common. Our method differs in that it
only eliminates non-optimal transitions based on
a lower-bound score. After introducing the prun-
ing method, we present an algorithm to make this
method effective in practice by producing high-
scoring lower bounds for adjacent agreement.
6.1 Thresholding Max-Marginals
Our pruning method is based on removing transi-
tions with low max-marginal values. Define the
max-marginal value of an e?f transition in our
Lagrangian dual as
M(j
?
, i, j;?) = max
z?Z(x,y),
x?X ,y?Y
?
f(x) + g
?
(y;?) + h(z)
s.t. x(j
?
, i, j) = 1
where M gives the value of the best dual align-
ment that transitions from (i ? 1, j
?
) to (i, j).
These max-marginals can be computed by running
a forward-backward variant of any of the algo-
rithms described thus far.
We make the following claim about max-
marginal values and any lower-bound score
Lemma 1 (Safe Pruning). For any valid con-
strained alignment x ? X , y ? Y, z ? Z(x, y)
and for any dual vector ? ? R
[I?1]
0
?[J ]
0
, if there
exists a transition j
?
, i, j with max-marginal value
M(j
?
, i, j;?) < f(x)+g(y)+h(z) then the tran-
sition will not be in the optimal alignment, i.e.
x
?
(j
?
, i, j) = 0.
This lemma tells us that we can prune transi-
tions whose dual max-marginal value falls below
1486
a threshold without pruning possibly optimal tran-
sitions. Pruning these transitions can speed up La-
grangian relaxation without altering its properties.
Furthermore, the threshold is determined by any
feasible lower bound on the optimal score, which
means that better bounds can lead to more pruning.
6.2 Finding Lower Bounds
Since the effectiveness of pruning is dependent on
the lower bound, it is crucial to be able to produce
high-scoring alignments that satisfy the agreement
constraints. Unfortunately, this problem is non-
trivial. For instance, taking the union of direc-
tional alignments does not guarantee a feasible so-
lution; whereas taking the intersection is trivially
feasible but often not high-scoring.
To produce higher-scoring feasible bidirectional
alignments we introduce a greedy heuristic al-
gorithm. The algorithm starts with any feasible
alignment (x, y, z). It runs the following greedy
loop:
1. Repeat until there exists no x(i, 0) = 1 or
y(0, j) = 1, or there is no score increase.
(a) For each i ? [I], j ? [J ]
0
, k ? K :
x(i, 0) = 1, check if x(i, j) ? 1 and
y(i, j + k) ? 1 is feasible, remember
score.
(b) For each i ? [I]
0
, j ? [J ], k ? K :
y(0, j) = 1, check if y(i, j) ? 1 and
x(i + k, j) ? 1 is feasible, remember
score.
(c) Let (x, y, z) be the highest-scoring fea-
sible solution produced.
This algorithm produces feasible alignments with
monotonically increasing score, starting from the
intersection of the alignments. It has run-time of
O(IJ(I + J)) since each inner loop enumerates
IJ possible updates and assigns at least one index
a non-zero value, limiting the outer loop to I + J
iterations.
In practice we initialize the heuristic based on
the intersection of x and y at the current round
of Lagrangian relaxation. Experiments show that
running this algorithm significantly improves the
lower bound compared to just taking the intersec-
tion, and consequently helps pruning significantly.
7 Related Work
The most common techniques for bidirectional
alignment are post-hoc combinations, such as
union or intersection, of directional models, (Och
et al, 1999), or more complex heuristic combiners
such as grow-diag-final (Koehn et al, 2003).
Several authors have explored explicit bidirec-
tional models in the literature. Cromieres and
Kurohashi (2009) use belief propagation on a fac-
tor graph to train and decode a one-to-one word
alignment problem. Qualitatively this method is
similar to ours, although the model and decoding
algorithm are different, and their method is not
able to provide certificates of optimality.
A series of papers by Ganchev et al (2010),
Graca et al (2008), and Ganchev et al (2008) use
posterior regularization to constrain the posterior
probability of the word alignment problem to be
symmetric and bijective. This work acheives state-
of-the-art performance for alignment. Instead of
utilizing posteriors our model tries to decode a sin-
gle best one-to-one word alignment.
A different approach is to use constraints at
training time to obtain models that favor bidi-
rectional properties. Liang et al (2006) propose
agreement-based learning, which jointly learns
probabilities by maximizing a combination of
likelihood and agreement between two directional
models.
General linear programming approaches have
also been applied to word alignment problems.
Lacoste-Julien et al (2006) formulate the word
alignment problem as quadratic assignment prob-
lem and solve it using an integer linear program-
ming solver.
Our work is most similar to DeNero and
Macherey (2011), which uses dual decomposition
to encourage agreement between two directional
HMM aligners during decoding time.
8 Experiments
Our experimental results compare the accuracy
and optimality of our decoding algorithm to direc-
tional alignment models and previous work on this
bidirectional model.
Data and Setup The experimental setup is iden-
tical to DeNero and Macherey (2011). Evalu-
ation is performed on a hand-aligned subset of
the NIST 2002 Chinese-English dataset (Ayan and
Dorr, 2006). Following past work, the first 150
sentence pairs of the training section are used for
evaluation. The potential parameters ? and ? are
set based on unsupervised HMM models trained
on the LDC FBIS corpus (6.2 million words).
1487
1-20 (28%) 21-40 (45%) 41-60 (27%) all
time cert exact time cert exact time cert exact time cert exact
ILP 15.12 100.0 100.0 364.94 100.0 100.0 2,829.64 100.0 100.0 924.24 100.0 100.0
LR 0.55 97.6 97.6 4.76 55.9 55.9 15.06 7.5 7.5 6.33 54.7 54.7
CONS 0.43 100.0 100.0 9.86 95.6 95.6 61.86 55.0 62.5 21.08 86.0 88.0
D&M - 6.2 - - 0.0 - - 0.0 - - 6.2 -
Table 1: Experimental results for model accuracy of bilingual alignment. Column time is the mean time per sentence pair in
seconds; cert is the percentage of sentence pairs solved with a certificate of optimality; exact is the percentage of sentence pairs
solved exactly. Results are grouped by sentence length. The percentage of sentence pairs in each group is shown in parentheses.
Training is performed using the agreement-based
learning method which encourages the directional
models to overlap (Liang et al, 2006). This direc-
tional model has been shown produce state-of-the-
art results with this setup (Haghighi et al, 2009).
Baselines We compare the algorithm described
in this paper with several baseline methods. DIR
includes post-hoc combinations of the e?f and
f?e HMM-based aligners. Variants include
union, intersection, and grow-diag-final. D&M is
the dual decomposition algorithm for bidirectional
alignment as presented by DeNero and Macherey
(2011) with different final combinations. LR is the
Lagrangian relaxation algorithm applied to the ad-
jacent agreement problem without the additional
constraints described in Section 5. CONS is our
full Lagrangian relaxation algorithm including in-
cremental constraint addition. ILP uses a highly-
optimized general-purpose integer linear program-
ming solver to solve the lattice with the constraints
described (Gurobi Optimization, 2013).
Implementation The main task of the decoder
is to repeatedly compute the argmax of L(?).
To speed up decoding, our implementation fully
instantiates the Viterbi lattice for a problem in-
stance. This approach has several benefits: each
iteration can reuse the same lattice structure; max-
marginals can be easily computed with a gen-
eral forward-backward algorithm; pruning corre-
sponds to removing lattice edges; and adding con-
straints can be done through lattice intersection.
For consistency, we implement each baseline (ex-
cept for D&M) through the same lattice.
Parameter Settings We run 400 iterations of
the subgradient algorithm using the rate schedule
?
t
= 0.95
t
?
where t
?
is the count of updates for
which the dual value did not improve. Every 10
iterations we run the greedy decoder to compute
a lower bound. If the gap between our current
dual value L(?) and the lower bound improves
significantly we run coarse-to-fine pruning as de-
scribed in Section 6 with the best lower bound. For
Model Combiner
alignment phrase pair
Prec Rec AER Prec Rec F1
DIR
union 57.6 80.0 33.4 75.1 33.5 46.3
intersection 86.2 62.9 27.0 64.3 43.5 51.9
grow-diag 59.7 79.5 32.1 70.1 36.9 48.4
D&M
union 63.3 81.5 29.1 63.2 44.9 52.5
intersection 77.5 75.1 23.6 57.1 53.6 55.3
grow-diag 65.6 80.6 28.0 60.2 47.4 53.0
CONS 72.5 74.9 26.4 53.0 52.4 52.7
Table 2: Alignment accuracy and phrase pair extraction ac-
curacy for directional and bidirectional models. Prec is the
precision. Rec is the recall. AER is alignment error rate and
F1 is the phrase pair extraction F1 score.
CONS, if the algorithm does not find an optimal
solution we run 400 more iterations and incremen-
tally add the 5 most violated constraints every 25
iterations.
Results Our first set of experiments looks at the
model accuracy and the decoding time of various
methods that can produce optimal solutions. Re-
sults are shown in Table 1. D&M is only able to
find the optimal solution with certificate on 6% of
instances. The relaxation algorithm used in this
work is able to increase that number to 54.7%.
With incremental constraints and pruning, we are
able to solve over 86% of sentence pairs includ-
ing many longer and more difficult pairs. Addi-
tionally the method finds these solutions with only
a small increase in running time over Lagrangian
relaxation, and is significantly faster than using an
ILP solver.
Next we compare the models in terms of align-
ment accuracy. Table 2 shows the precision, recall
and alignment error rate (AER) for word align-
ment. We consider union, intersection and grow-
diag-final as combination procedures. The com-
bination procedures are applied to D&M in the
case when the algorithm does not converge. For
CONS, we use the optimal solution for the 86%
of instances that converge and the highest-scoring
greedy solution for those that do not. The pro-
posed method has an AER of 26.4, which outper-
forms each of the directional models. However,
although CONS achieves a higher model score
than D&M, it performs worse in accuracy. Ta-
1488
1-20 21-40 41-60 all
# cons. 20.0 32.1 39.5 35.9
Table 3: The average number of constraints added for sen-
tence pairs where Lagrangian relaxation is not able to find an
exact solution.
ble 2 also compares the models in terms of phrase-
extraction accuracy (Ayan and Dorr, 2006). We
use the phrase extraction algorithm described by
DeNero and Klein (2010), accounting for possi-
ble links and  alignments. CONS performs bet-
ter than each of the directional models, but worse
than the best D&M model.
Finally we consider the impact of constraint ad-
dition, pruning, and use of a lower bound. Table 3
gives the average number of constraints added for
sentence pairs for which Lagrangian relaxation
alone does not produce a certificate. Figure 7(a)
shows the average over all sentence pairs of the
best dual and best primal scores. The graph com-
pares the use of the greedy algorithm from Sec-
tion 6.2 with the simple intersection of x and y.
The difference between these curves illustrates the
benefit of the greedy algorithm. This is reflected
in Figure 7(b) which shows the effectiveness of
coarse-to-fine pruning over time. On average, the
pruning reduces the search space of each sentence
pair to 20% of the initial search space after 200
iterations.
9 Conclusion
We have introduced a novel Lagrangian relaxation
algorithm for a bidirectional alignment model that
uses incremental constraint addition and coarse-
to-fine pruning to find exact solutions. The algo-
rithm increases the number of exact solution found
on the model of DeNero and Macherey (2011)
from 6% to 86%.
Unfortunately despite achieving higher model
score, this approach does not produce more accu-
rate alignments than the previous algorithm. This
suggests that the adjacent agreement model may
still be too constrained for this underlying task.
Implicitly, an approach with fewer exact solu-
tions may allow for useful violations of these con-
straints. In future work, we hope to explore bidi-
rectional models with soft-penalties to explicitly
permit these violations.
A Proof of NP-Hardness
We can show that the bidirectional alignment
problem is NP-hard by reduction from the trav-
0 50 100 150 200 250 300 350 400iteration
100
50
0
50
100
sco
re 
rel
ati
ve 
to 
opt
ima
l best dualbest primal
intersection
(a) The best dual and the best primal score, relative to the
optimal score, averaged over all sentence pairs. The best
primal curve uses a feasible greedy algorithm, whereas the
intersection curve is calculated by taking the intersec-
tion of x and y.
0 50 100 150 200 250 300 350 400number of iterations
0.0
0.2
0.4
0.6
0.8
1.0
rel
ati
ve 
sea
rch
 sp
ace
 siz
e
(b) A graph showing the effectiveness of coarse-to-fine prun-
ing. Relative search space size is the size of the pruned lattice
compared to the initial size. The plot shows an average over
all sentence pairs.
Figure 7
eling salesman problem (TSP). A TSP instance
with N cities has distance c(i
?
, i) for each (i
?
, i) ?
[N ]
2
. We can construct a sentence pair in which
I = J = N and -alignments have infinite cost.
?(i
?
, i, j) = ?c(i
?
, i) ?i
?
? [N ]
0
, i ? [N ], j ? [N ]
?(j
?
, i, j) = 0 ?j
?
? [N ]
0
, i ? [N ], j ? [N ]
?(i
?
, 0, j) = ?? ?i
?
? [N ]
0
, j ? [N ]
?(j
?
, i, 0) = ?? ?j
?
? [N ]
0
, i ? [N ]
Every bidirectional alignment with finite objec-
tive score must align exactly one word in e to each
word in f, encoding a permutation a. Moreover,
each possible permutation has a finite score: the
negation of the total distance to traverse the N
cities in order a under distance c. Therefore, solv-
ing such a bidirectional alignment problem would
find a minimal Hamiltonian path of the TSP en-
coded in this way, concluding the reduction.
Acknowledgments Alexander Rush, Yin-Wen
Chang and Michael Collins were all supported
by NSF grant IIS-1161814. Alexander Rush was
partially supported by an NSF Graduate Research
Fellowship.
1489
References
Necip Fazil Ayan and Bonnie J Dorr. 2006. Going
beyond aer: An extensive analysis of word align-
ments and their impact on mt. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 9?16.
Association for Computational Linguistics.
Peter F Brown, Vincent J Della Pietra, Stephen A Della
Pietra, and Robert L Mercer. 1993. The mathemat-
ics of statistical machine translation: Parameter esti-
mation. Computational linguistics, 19(2):263?311.
Fabien Cromieres and Sadao Kurohashi. 2009. An
alignment algorithm using belief propagation and a
structure-based distortion model. In Proceedings
of the 12th Conference of the European Chapter
of the Association for Computational Linguistics,
pages 166?174. Association for Computational Lin-
guistics.
John DeNero and Dan Klein. 2010. Discriminative
modeling of extraction sets for machine translation.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics, pages
1453?1463. Association for Computational Linguis-
tics.
John DeNero and Klaus Macherey. 2011. Model-
based aligner combination using dual decomposi-
tion. In ACL, pages 420?429.
Kuzman Ganchev, Jo?ao V. Grac?a, and Ben Taskar.
2008. Better alignments = better translations?
In Proceedings of ACL-08: HLT, pages 986?993,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
K. Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.
2010. Posterior Regularization for Structured La-
tent Variable Models. Journal of Machine Learning
Research, 11:2001?2049.
Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008.
Expectation maximization and posterior constraints.
In J.C. Platt, D. Koller, Y. Singer, and S. Roweis,
editors, Advances in Neural Information Processing
Systems 20, pages 569?576. MIT Press, Cambridge,
MA.
Inc. Gurobi Optimization. 2013. Gurobi optimizer ref-
erence manual.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with su-
pervised itg models. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2-
Volume 2, pages 923?931. Association for Compu-
tational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 48?54. Association for Computa-
tional Linguistics.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael I Jordan. 2006. Word alignment via
quadratic assignment. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics, pages 112?
119. Association for Computational Linguistics.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics, pages 104?
111. Association for Computational Linguistics.
Robert C Moore. 2005. A discriminative framework
for bilingual word alignment. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Process-
ing, pages 81?88. Association for Computational
Linguistics.
Franz Josef Och, Christoph Tillmann, Hermann Ney,
et al 1999. Improved alignment models for statis-
tical machine translation. In Proc. of the Joint SIG-
DAT Conf. on Empirical Methods in Natural Lan-
guage Processing and Very Large Corpora, pages
20?28.
Alexander M Rush and Michael Collins. 2012. A tuto-
rial on dual decomposition and lagrangian relaxation
for inference in natural language processing. Jour-
nal of Artificial Intelligence Research, 45:305?362.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. Hmm-based word alignment in statistical
translation. In Proceedings of the 16th conference
on Computational linguistics-Volume 2, pages 836?
841. Association for Computational Linguistics.
1490
Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 56?64,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Spectral Learning of Refinement HMMs
Karl Stratos1 Alexander M. Rush2 Shay B. Cohen1 Michael Collins1
1Department of Computer Science, Columbia University, New-York, NY 10027, USA
2MIT CSAIL, Cambridge, MA, 02139, USA
{stratos,scohen,mcollins}@cs.columbia.edu, srush@csail.mit.edu
Abstract
We derive a spectral algorithm for learn-
ing the parameters of a refinement HMM.
This method is simple, efficient, and can
be applied to a wide range of supervised
sequence labeling tasks. Like other spec-
tral methods, it avoids the problem of lo-
cal optima and provides a consistent esti-
mate of the parameters. Our experiments
on a phoneme recognition task show that
when equipped with informative feature
functions, it performs significantly better
than a supervised HMM and competitively
with EM.
1 Introduction
Consider the task of supervised sequence label-
ing. We are given a training set where the j?th
training example consists of a sequence of ob-
servations x(j)1 ...x(j)N paired with a sequence of
labels a(j)1 ...a(j)N and asked to predict the cor-
rect labels on a test set of observations. A
common approach is to learn a joint distribu-
tion over sequences p(a1 . . . aN , x1 . . . xN ) as a
hidden Markov model (HMM). The downside of
HMMs is that they assume each label ai is inde-
pendent of labels before the previous label ai?1.
This independence assumption can be limiting,
particularly when the label space is small. To re-
lax this assumption we can refine each label ai
with a hidden state hi, which is not observed in
the training data, and model the joint distribu-
tion p(a1 . . . aN , x1 . . . xN , h1 . . . hN ). This re-
finement HMM (R-HMM), illustrated in figure 1,
is able to propagate information forward through
the hidden state as well as the label.
Unfortunately, estimating the parameters of an
R-HMM is complicated by the unobserved hid-
den variables. A standard approach is to use the
expectation-maximization (EM) algorithm which
a1, h1 a2, h2 aN , hN
x1 x2 xN
(a)
a1 a2 aN
h1 h2 hN
x1 x2 xN
(b)
Figure 1: (a) An R-HMM chain. (b) An equivalent
representation where labels and hidden states are
intertwined.
has no guarantee of finding the global optimum of
its objective function. The problem of local op-
tima prevents EM from yielding statistically con-
sistent parameter estimates: even with very large
amounts of data, EM is not guaranteed to estimate
parameters which are close to the ?correct? model
parameters.
In this paper, we derive a spectral algorithm for
learning the parameters of R-HMMs. Unlike EM,
this technique is guaranteed to find the true param-
eters of the underlying model under mild condi-
tions on the singular values of the model. The al-
gorithm we derive is simple and efficient, relying
on singular value decomposition followed by stan-
dard matrix operations.
We also describe the connection of R-HMMs
to L-PCFGs. Cohen et al (2012) present a spec-
tral algorithm for L-PCFG estimation, but the
na??ve transformation of the L-PCFG model and
its spectral algorithm to R-HMMs is awkward and
opaque. We therefore work through the non-trivial
derivation the spectral algorithm for R-HMMs.
We note that much of the prior work on spec-
tral algorithms for discrete structures in NLP has
shown limited experimental success for this fam-
ily of algorithms (see, for example, Luque et al,
2012). Our experiments demonstrate empirical
56
success for the R-HMM spectral algorithm. The
spectral algorithm performs competitively with
EM on a phoneme recognition task, and is more
stable with respect to the number of hidden states.
Cohen et al (2013) present experiments with a
parsing algorithm and also demonstrate it is com-
petitive with EM. Our set of experiments comes as
an additional piece of evidence that spectral algo-
rithms can function as a viable, efficient and more
principled alternative to the EM algorithm.
2 Related Work
Recently, there has been a surge of interest in spec-
tral methods for learning HMMs (Hsu et al, 2012;
Foster et al, 2012; Jaeger, 2000; Siddiqi et al,
2010; Song et al, 2010). Like these previous
works, our method produces consistent parameter
estimates; however, we estimate parameters for a
supervised learning task. Balle et al (2011) also
consider a supervised problem, but our model is
quite different since we estimate a joint distribu-
tion p(a1 . . . aN , x1 . . . xN , h1 . . . hN ) as opposed
to a conditional distribution and use feature func-
tions over both the labels and observations of the
training data. These feature functions also go be-
yond those previously employed in other spectral
work (Siddiqi et al, 2010; Song et al, 2010). Ex-
periments show that features of this type are cru-
cial for performance.
Spectral learning has been applied to related
models beyond HMMs including: head automata
for dependency parsing (Luque et al, 2012),
tree-structured directed Bayes nets (Parikh et al,
2011), finite-state transducers (Balle et al, 2011),
and mixture models (Anandkumar et al, 2012a;
Anandkumar et al, 2012b).
Of special interest is Cohen et al (2012), who
describe a derivation for a spectral algorithm for
L-PCFGs. This derivation is the main driving
force behind the derivation of our R-HMM spec-
tral algorithm. For work on L-PCFGs estimated
with EM, see Petrov et al (2006), Matsuzaki et al
(2005), and Pereira and Schabes (1992). Petrov
et al (2007) proposes a split-merge EM procedure
for phoneme recognition analogous to that used in
latent-variable parsing.
3 The R-HMM Model
We decribe in this section the notation used
throughout the paper and the formal details of R-
HMMs.
3.1 Notation
We distinguish row vectors from column vectors
when such distinction is necessary. We use a
superscript > to denote the transpose operation.
We write [n] to denote the set {1, 2, . . . , n} for
any integer n ? 1. For any vector v ? Rm,
diag(v) ? Rm?m is a diagonal matrix with en-
tries v1 . . . vm. For any statement S , we use [[S]]
to refer to the indicator function that returns 1 if S
is true and 0 otherwise. For a random variable X ,
we use E[X] to denote its expected value.
A tensor C ? Rm?m?m is a set of m3 val-
ues Ci,j,k for i, j, k ? [m]. Given a vector v ?
Rm, we define C(v) to be the m ? m matrix
with [C(v)]i,j = ?k?[m]Ci,j,kvk. Given vectors
x, y, z ? Rm, C = xy>z> is anm?m?m tensor
with [C]i,j,k = xiyjzk.
3.2 Definition of an R-HMM
An R-HMM is a 7-tuple ?l,m, n, pi, o, t, f? for in-
tegers l,m, n ? 1 and functions pi, o, t, f where
? [l] is a set of labels.
? [m] is a set of hidden states.
? [n] is a set of observations.
? pi(a, h) is the probability of generating a ?
[l] and h ? [m] in the first position in the
labeled sequence.
? o(x|a, h) is the probability of generating x ?
[n], given a ? [l] and h ? [m].
? t(b, h?|a, h) is the probability of generating
b ? [l] and h? ? [m], given a ? [l] and
h ? [m].
? f(?|a, h) is the probability of generating the
stop symbol ?, given a ? [l] and h ? [m].
See figure 1(b) for an illustration. At any time step
of a sequence, a label a is associated with a hidden
state h. By convention, the end of an R-HMM
sequence is signaled by the symbol ?.
For the subsequent illustration, let N be the
length of the sequence we consider. A full se-
quence consists of labels a1 . . . aN , observations
x1 . . . xN , and hidden states h1 . . . hN . The model
assumes
p(a1 . . . aN , x1 . . . xN , h1 . . . hN ) = pi(a1, h1)?
N?
i=1
o(xi|ai, hi)?
N?1?
i=1
t(ai+1, hi+1|ai, hi)? f(?|aN , hN )
57
Input: a sequence of observations x1 . . . xN ; operators?
Cb|a, C?|a, c1a, cax
?
Output: ?(a, i) for all a ? [l] and i ? [N ]
[Forward case]
? ?1a ? c1a for all a ? [l].
? For i = 1 . . . N ? 1
?i+1b ?
?
a?[l]
Cb|a(caxi)? ?
i
a for all b ? [l]
[Backward case]
? ?N+1a ? C?|a(caxN ) for all a ? [l]
? For i = N . . . 1
?ia ?
?
b?[l]
?i+1b ? Cb|a(caxi) for all a ? [l]
[Marginals]
? ?(a, i)? ?ia ? ?ia for all a ? [l], i ? [N ]
Figure 2: The forward-backward algorithm
A skeletal sequence consists of labels a1 . . . aN
and observations x1 . . . xN without hidden states.
Under the model, it has probability
p(a1 . . . aN , x1 . . . xN )
=
?
h1...hN
p(a1 . . . aN , x1 . . . xN , h1 . . . hN )
An equivalent definition of an R-HMM is
given by organizing the parameters in matrix
form. Specifically, an R-HMM has parameters?
pia, oax, T b|a, fa
? where pia ? Rm is a column
vector, oax is a row vector, T b|a ? Rm?m is a ma-
trix, and fa ? Rm is a row vector, defined for all
a, b ? [l] and x ? [n]. Their entries are set to
? [pia]h = pi(a, h) for h ? [m]
? [oax]h = o(x|a, h) for h ? [m]
? [T b|a]h?,h = t(b, h?|a, h) for h, h? ? [m]
? [fa]h = f(?|a, h) for h ? [m]
4 The Forward-Backward Algorithm
Given an observation sequence x1 . . . xN , we want
to infer the associated sequence of labels under
an R-HMM. This can be done by computing the
marginals of x1 . . . xN
?(a, i) =
?
a1...aN : ai=a
p(a1 . . . aN , x1 . . . xN )
for all labels a ? [l] and positions i ? [N ]. Then
the most likely label at each position i is given by
a?i = arg maxa?[l] ?(a, i)
The marginals can be computed using a tensor
variant of the forward-backward algorithm, shown
in figure 2. The algorithm takes additional quanti-
ties ?Cb|a, C?|a, c1a, cax
? called the operators:
? Tensors Cb|a ? Rm?m?m for a, b ? [l]
? Tensors C?|a ? R1?m?m for a ? [l]
? Column vectors c1a ? Rm for a ? [l]
? Row vectors cax ? Rm for a ? [l] and x ? [n]
The following proposition states that these opera-
tors can be defined in terms of the R-HMM param-
eters to guarantee the correctness of the algorithm.
Proposition 4.1. Given an R-HMM with param-
eters ?pia, oax, T b|a, fa
?, for any vector v ? Rm
define the operators:
Cb|a(v) = T b|adiag(v) c1a = pia
C?|a(v) = fadiag(v) cax = oax
Then the algorithm in figure 2 correctly computes
marginals ?(a, i) under the R-HMM.
The proof is an algebraic verification and deferred
to the appendix. Note that the running time of the
algorithm as written is O(l2m3N).1
Proposition 4.1 can be generalized to the fol-
lowing theorem. This theorem implies that the op-
erators can be linearly transformed by some invert-
ible matrices as long as the transformation leaves
the embedded R-HMM parameters intact. This
observation is central to the derivation of the spec-
tral algorithm which estimates the linearly trans-
formed operators but not the actual R-HMM pa-
rameters.
Theorem 4.1. Given an R-HMM with parameters?
pia, oax, T b|a, fa
?, assume that for each a ? [l] we
have invertible m ?m matrices Ga and Ha. For
any vector v ? Rm define the operators:
Cb|a(v) = GbT b|adiag(vHa)(Ga)?1 c1a = Gapia
C?|a(v) = fadiag(vHa)(Ga)?1 cax = oax(Ha)?1
Then the algorithm in figure 2 correctly computes
marginals ?(a, i) under the R-HMM.
The proof is similar to that of Cohen et al (2012).
1We can reduce the complexity to O(l2m2N) by pre-
computing the matricesCb|a(cax) for all a, b ? [l] and x ? [n]
after parameter estimation.
58
5 Spectral Estimation of R-HMMs
In this section, we derive a consistent estimator for
the operators ?Cb|a, C?|a, c1a, cax
? in theorem 4.1
through the use of singular-value decomposition
(SVD) followed by the method of moments.
Section 5.1 describes the decomposition of the
R-HMM model into random variables which are
used in the final algorithm. Section 5.2 can be
skimmed through on the first reading, especially
if the reader is familiar with other spectral algo-
rithms. It includes a detailed account of the deriva-
tion of the R-HMM algorithm.
For a first reading, note that an R-HMM se-
quence can be seen as a right-branching L-PCFG
tree. Thus, in principle, one can convert a se-
quence into a tree and run the inside-outside algo-
rithm of Cohen et al (2012) to learn the parame-
ters of an R-HMM. However, projecting this trans-
formation into the spectral algorithm for L-PCFGs
is cumbersome and unintuitive. This is analo-
gous to the case of the Baum-Welch algorithm for
HMMs (Rabiner, 1989), which is a special case of
the inside-outside algorithm for PCFGs (Lari and
Young, 1990).
5.1 Random Variables
We first introduce the random variables un-
derlying the approach then describe the opera-
tors based on these random variables. From
p(a1 . . . aN , x1 . . . xN , h1 . . . hN ), we draw an R-
HMM sequence (a1 . . . aN , x1 . . . xN , h1 . . . hN )
and choose a time step i uniformly at random from
[N ]. The random variables are then defined as
X = xi
A1 = ai and A2 = ai+1 (if i = N , A2 = ?)
H1 = hi and H2 = hi+1
F1 = (ai . . . aN , xi . . . xN ) (future)
F2 = (ai+1 . . . aN , xi+1 . . . xN ) (skip-future)
P = (a1 . . . ai, x1 . . . xi?1) (past)
R = (ai, xi) (present)
D = (a1 . . . aN , x1 . . . xi?1, xi+1 . . . xN ) (destiny)
B = [[i = 1]]
Figure 3 shows the relationship between the ran-
dom variables. They are defined in such a way
that the future is independent of the past and the
present is independent of the destiny conditioning
on the current node?s label and hidden state.
Next, we require a set of feature functions over
the random variables.
? ? maps F1, F2 to ?(F1), ?(F2) ? Rd1 .
a1 ai?1 ai ai+1 aN
x1 xi?1 xi xi+1 xN
P
F1
F2
(a)
a1 ai?1 ai ai+1 aN
x1 xi?1 xi xi+1 xN
D R
(b)
Figure 3: Given an R-HMM sequence, we define
random variables over observed quantities so that
conditioning on the current node, (a) the future F1
is independent of the past P and (b) the present R
is independent of the density D.
? ? maps P to ?(P ) ? Rd2 .
? ? maps R to ?(R) ? Rd3 .
? ? maps D to ?(D) ? Rd4 .
We will see that the feature functions should be
chosen to capture the influence of the hidden
states. For instance, they might track the next la-
bel, the previous observation, or important combi-
nations of labels and observations.
Finally, we require projection matrices
?a ? Rm?d1 ?a ? Rm?d2
?a ? Rm?d3 ?a ? Rm?d4
defined for all labels a ? [l]. These matrices
will project the feature vectors of ?, ?, ?, and ?
from (d1, d2, d3, d4)-dimensional spaces to an m-
dimensional space. We refer to this reduced di-
mensional representation by the following random
variables:
F 1 = ?A1?(F1) (projected future)
F 2 = ?A2?(F2) (projected skip-future: if i = N , F 2 = 1)
P = ?A1?(P ) (projected past)
R = ?A1?(R) (projected present)
D = ?A1?(D) (projected destiny)
Note that they are all vectors in Rm.
59
5.2 Estimation of the Operators
Since F 1, F 2, P , R, and D do not involve hid-
den variables, the following quantities can be di-
rectly estimated from the training data of skeletal
sequences. For this reason, they are called observ-
able blocks:
?a = E[F 1P>|A1 = a] ?a ? [l]
?a = E[R D>|A1 = a] ?a ? [l]
Db|a = E[[[A2 = b]]F 2P>R>|A1 = a] ?a, b ? [l]
dax = E[[[X = x]]D>|A1 = a] ?a ? [l], x ? [n]
The main result of this paper is that under cer-
tain conditions, matrices ?a and ?a are invert-
ible and the operators ?Cb|a, C?|a, c1a, cax
? in the-
orem 4.1 can be expressed in terms of these ob-
servable blocks.
Cb|a(v) = Db|a(v)(?a)?1 (1)
C?|a(v) = D?|a(v)(?a)?1 (2)
cax = dax(?a)?1 (3)
c1a = E[[[A1 = a]]F 1|B = 1] (4)
To derive this result, we use the following defini-
tion to help specify the conditions on the expecta-
tions of the feature functions.
Definition. For each a ? [l], define matrices
Ia ? Rd1?m, Ja ? Rd2?m, Ka ? Rd3?m,W a ?
Rd4?m by
[Ia]k,h = E[[?(F1)]k|A1 = a,H1 = h]
[Ja]k,h = E[[?(P )]k|A1 = a,H1 = h]
[Ka]k,h = E[[?(R)]k|A1 = a,H1 = h]
[W a]k,h = E[[?(D)]k|A1 = a,H1 = h]
In addition, let ?a ? Rm?m be a diagonal matrix
with [?a]h,h = P (H1 = h|A1 = a).
We now state the conditions for the correctness of
Eq. (1-4). For each label a ? [l], we require that
Condition 6.1 Ia, Ja,Ka,W a have rank m.
Condition 6.2 [?a]h,h > 0 for all h ? [m].
The conditions lead to the following proposition.
Proposition 5.1. Assume Condition 6.1 and 6.2
hold. For all a ? [l], define matrices
?a1 = E[?(F1)?(P )>|A1 = a] ? Rd1?d2
?a2 = E[?(R)?(D)>|A1 = a] ? Rd3?d4
Let ua1 . . . uam ? Rd1 and va1 . . . vam ? Rd2 be the
top m left and right singular vectors of ?a. Sim-
ilarly, let la1 . . . lam ? Rd3 and ra1 . . . ram ? Rd4 be
the top m left and right singular vectors of ?a.
Define projection matrices
?a = [ua1 . . . uam]> ?a = [va1 . . . vam]>
?a = [la1 . . . lam]> ?a = [ra1 . . . ram]>
Then the following m?m matrices
Ga = ?aIa Ga = ?aJa
Ha = ?aKa Ha = ?aW a
are invertible.
The proof resembles that of lemma 2 of Hsu et al
(2012). Finally, we state the main result that shows?
Cb|a, C?|a, c1a, cax
? in Eq. (1-4) using the projec-
tions from proposition 5.1 satisfy theorem 4.1. A
sketch of the proof is deferred to the appendix.
Theorem 5.1. Assume conditions 6.1 and 6.2
hold. Let ??a,?a,?a,?a? be the projection ma-
trices from proposition 5.1. Then the operators in
Eq. (1-4) satisfy theorem 4.1.
In summary, these results show that with the
proper selection of feature functions, we can con-
struct projection matrices ??a,?a,?a,?a? to ob-
tain operators ?Cb|a, C?|a, c1a, cax
? which satisfy
the conditions of theorem 4.1.
6 The Spectral Estimation Algorithm
In this section, we give an algorithm to estimate
the operators ?Cb|a, C?|a, c1a, cax
? from samples of
skeletal sequences. Suppose the training set con-
sists of M skeletal sequences (a(j), x(j)) for j ?
[M ]. ThenM samples of the random variables can
be derived from this training set as follows
? At each j ? [M ], choose a position
ij uniformly at random from the positions
in (a(j), x(j)). Sample the random vari-
ables (X,A1, A2, F1, F2, P,R,D,B) using
the procedure defined in section 5.1.
This process yields M samples
(x(j), a(j)1 , a
(j)
2 , f
(j)
1 , f
(j)
2 , p(j), r(j), d(j), b(j)) for j ? [M ]
Assuming (a(j), x(j)) are i.i.d. draws from
the PMF p(a1 . . . aN , x1 . . . xN ) over skeletal se-
quences under an R-HMM, the tuples obtained
through this process are i.i.d. draws from the joint
PMF over (X,A1, A2, F1, F2, P,R,D,B).
60
Input: samples of (X,A1, A2, F1, F2, P,R,D,B); feature
functions ?, ?, ?, and ?; number of hidden states m
Output: estimates
?
C?b|a, C??|a, c?1a, c?ax
?
of the operators
used in algorithm 2
[Singular Value Decomposition]
? For each label a ? [l], compute empirical estimates of
?a1 = E[?(F1)?(P )>|A1 = a]
?a2 = E[?(R)?(D)>|A1 = a]
and obtain their singular vectors via an SVD. Use
the top m singular vectors to construct projections?
??a, ??a, ??a, ??a
?
.
[Sample Projection]
? Project (d1, d2, d3, d4)-dimensional samples of
(?(F1), ?(F2), ?(P ), ?(R), ?(D))
with matrices
?
??a, ??a, ??a, ??a
?
to obtain m-
dimensional samples of
(F 1, F 2, P ,R,D)
[Method of Moments]
? For each a, b ? [l] and x ? [n], compute empirical
estimates
?
??a, ??a, D?b|a, d?ax
?
of the observable blocks
?a = E[F 1P>|A1 = a]
?a = E[R D>|A1 = a]
Db|a = E[[[A2 = b]]F 2P>R>|A1 = a]
dax = E[[[X = x]]D>|A1 = a]
and also c?1a = E[[[A1 = a]]F 1|B = 1]. Finally, set
C?b|a(v)? D?b|a(v)(??a)?1
C??|a(v)? D??|a(v)(??a)?1
c?ax ? d?ax(??a)?1
Figure 4: The spectral estimation algorithm
The algorithm in figure 4 shows how to derive
estimates of the observable representations from
these samples. It first computes the projection
matrices ??a,?a,?a,?a? for each label a ? [l]
by computing empirical estimates of ?a1 and ?a2
in proposition 5.1, calculating their singular vec-
tors via an SVD, and setting the projections in
terms of these singular vectors. These projection
matrices are then used to project (d1, d2, d3, d4)-
0 5 10 15 20 25 30hidden states (m)54.0
54.555.0
55.556.0
56.557.0
57.5
accur
acy
SpectralEM
Figure 5: Accuracy of the spectral algorithm and
EM on TIMIT development data for varying num-
bers of hidden states m. For EM, the highest scor-
ing iteration is shown.
dimensional feature vectors
(
?(f (j)1 ), ?(f
(j)
2 ), ?(p(j)), ?(r(j)), ?(d(j))
)
down to m-dimensional vectors
(
f (j)1 , f
(j)
2 , p
(j), r(j), d(j)
)
for all j ? [M ]. It then computes correlation
between these vectors in this lower dimensional
space to estimate the observable blocks which are
used to obtain the operators as in Eq. (1-4). These
operators can be used in algorithm 2 to compute
marginals.
As in other spectral methods, this estimation al-
gorithm is consistent, i.e., the marginals ??(a, i)
computed with the estimated operators approach
the true marginal values given more data. For
details, see Cohen et al (2012) and Foster et al
(2012).
7 Experiments
We apply the spectral algorithm for learning
R-HMMs to the task of phoneme recognition.
The goal is to predict the correct sequence of
phonemes a1 . . . aN for a given a set of speech
frames x1 . . . xN . Phoneme recognition is often
modeled with a fixed-structure HMM trained with
EM, which makes it a natural application for spec-
tral training.
We train and test on the TIMIT corpus of spoken
language utterances (Garofolo and others, 1988).
The label set consists of l = 39 English phonemes
following a standard phoneme set (Lee and Hon,
1989). For training, we use the sx and si utter-
ances of the TIMIT training section made up of
61
?(F1) ai+1 ? xi, ai+1, xi, np(ai . . . aN )
?(P ) (ai?1, xi?1), ai?1, xi?1, pp(a1 . . . ai)
?(R) xi
?(D) ai?1 ? xi?1, ai?1, xi?1, pp(a1 . . . ai),
pos(a1 . . . aN )
iy r r r r r r ow . . .. . .
pp b m e np
Figure 6: The feature templates for phoneme
recognition. The simplest features look only at the
current label and observation. Other features in-
dicate the previous phoneme type used before ai
(pp), the next phoneme type used after ai (np),
and the relative position (beginning, middle, or
end) of ai within the current phoneme (pos). The
figure gives a typical segment of the phoneme se-
quence a1 . . . aN
M = 3696 utterances. The parameter estimate is
smoothed using the method of Cohen et al (2013).
Each utterance consists of a speech signal
aligned with phoneme labels. As preprocessing,
we divide the signal into a sequence of N over-
lapping frames, 25ms in length with a 10ms step
size. Each frame is converted to a feature repre-
sentation using MFCC with its first and second
derivatives for a total of 39 continuous features.
To discretize the problem, we apply vector quanti-
zation using euclidean k-means to map each frame
into n = 10000 observation classes. After pre-
processing, we have 3696 skeletal sequence with
a1 . . . aN as the frame-aligned phoneme labels and
x1 . . . xN as the observation classes.
For testing, we use the core test portion of
TIMIT, consisting of 192 utterances, and for de-
velopment we use 200 additional utterances. Ac-
curacy is measured by the percentage of frames
labeled with the correct phoneme. During infer-
ence, we calculate marginals ? for each label at
each position i and choose the one with the highest
marginal probability, a?i = arg maxa?[l] ?(a, i).
The spectral method requires defining feature
functions ?, ?, ?, and ?. We use binary-valued
feature vectors which we specify through features
templates, for instance the template ai ? xi corre-
sponds to binary values for each possible label and
output pair (ln binary dimensions).
Figure 6 gives the full set of templates. These
feature functions are specially for the phoneme
labeling task. We note that the HTK baseline
explicitly models the position within the current
Method Accuracy
EM(4) 56.80
EM(24) 56.23
SPECTRAL(24), no np, pp, pos 55.45
SPECTRAL(24), no pos 56.56
SPECTRAL(24) 56.94
Figure 7: Feature ablation experiments on TIMIT
development data for the best spectral model (m =
24) with comparisons to the best EM model (m =
4) and EM with m = 24.
Method Accuracy
UNIGRAM 48.04
HMM 54.08
EM(4) 55.49
SPECTRAL(24) 55.82
HTK 55.70
Figure 8: Performance of baselines and spectral
R-HMM on TIMIT test data. Number of hidden
states m optimized on development data (see fig-
ure 5). The improvement of the spectral method
over the EM baseline is significant at the p ? 0.05
level (and very close to significant at p ? 0.01,
with a precise value of p ? 0.0104).
phoneme as part of the HMM structure. The spec-
tral method is able to encode similar information
naturally through the feature functions.
We implement several baseline for phoneme
recognition: UNIGRAM chooses the most likely
label, arg maxa?[l] p(a|xi), at each position;
HMM is a standard HMM trained with maximum-
likelihood estimation; EM(m) is an R-HMM
with m hidden states estimated using EM; and
SPECTRAL(m) is an R-HMM with m hidden
states estimated with the spectral method de-
scribed in this paper. We also compare to HTK,
a fixed-structure HMM with three segments per
phoneme estimated using EM with the HTK
speech toolkit. See Young et al (2006) for more
details on this method.
An important consideration for both EM and the
spectral method is the number of hidden states m
in the R-HMM. More states allow for greater label
refinement, with the downside of possible overfit-
ting and, in the case of EM, more local optima.
To determine the best number of hidden states, we
optimize both methods on the development set for
a range of m values between 1 to 32. For EM,
62
we run 200 training iterations on each value of m
and choose the iteration that scores best on the de-
velopment set. As the spectral algorithm is non-
iterative, we only need to evaluate the develop-
ment set once per m value. Figure 5 shows the
development accuracy of the two method as we
adjust the value of m. EM accuracy peaks at 4
hidden states and then starts degrading, whereas
the spectral method continues to improve until 24
hidden states.
Another important consideration for the spectral
method is the feature functions. The analysis sug-
gests that the best feature functions are highly in-
formative of the underlying hidden states. To test
this empirically we run spectral estimation with a
reduced set of features by ablating the templates
indicating adjacent phonemes and relative posi-
tion. Figure 7 shows that removing these features
does have a significant effect on development ac-
curacy. Without either type of feature, develop-
ment accuracy drops by 1.5%.
We can interpret the effect of the features in
a more principled manner. Informative features
yield greater singular values for the matrices ?a1
and ?a2, and these singular values directly affect
the sample complexity of the algorithm; see Cohen
et al (2012) for details. In sum, good feature func-
tions lead to well-conditioned ?a1 and ?a2, which in
turn require fewer samples for convergence.
Figure 8 gives the final performance for the
baselines and the spectral method on the TIMIT
test set. For EM and the spectral method, we
use best performing model from the develop-
ment data, 4 hidden states for EM and 24 for
the spectral method. The experiments show that
R-HMM models score significantly better than a
standard HMM and comparatively to the fixed-
structure HMM. In training the R-HMM models,
the spectral method performs competitively with
EM while avoiding the problems of local optima.
8 Conclusion
This paper derives a spectral algorithm for the
task of supervised sequence labeling using an R-
HMM. Unlike EM, the spectral method is guar-
anteed to provide a consistent estimate of the pa-
rameters of the model. In addition, the algorithm
is simple to implement, requiring only an SVD
of the observed counts and other standard ma-
trix operations. We show empirically that when
equipped with informative feature functions, the
spectral method performs competitively with EM
on the task of phoneme recognition.
Appendix
Proof of proposition 4.1. At any time step i ? [N ] in the al-
gorithm in figure 2, for all label a ? [l] we have a column
vector ?ia ? Rm and a row vector ?ia ? Rm. The value of
these vectors at each index h ? [m] can be verified as
[?ia]h =
?
a1...ai,h1...hi:
ai=a,hi=h
p(a1 . . . ai, x1 . . . xi?1, h1 . . . hi)
[?ia]h =?
ai...aN ,hi...hN :
ai=a,hi=h
p(ai+1 . . . aN , xi . . . xN , hi+1 . . . hN |ai, hi)
Thus ?ia?ia is a scalar equal to
?
a1...aN ,h1...hN :ai=a
p(a1 . . . aN , x1 . . . xN , h1 . . . hN )
which is the value of the marginal ?(a, i).
Proof of theorem 5.1. It can be verified that c1a = Gapia. For
the others, under the conditional independence illustrated in
figure 3 we can decompose the observable blocks in terms of
the R-HMM parameters and invertible matrices
?a = Ga?a(Ga)> ?a = Ha?a(Ha)>
Db|a(v) = GbT b|adiag(vHa)?a(Ga)>
D?|a(v) = fadiag(vHa)?a(Ga)> dax = oax?a(Ha)>
using techniques similar to those sketched in Cohen et al
(2012). By proposition 5.1, ?a and ?a are invertible, and
these observable blocks yield the operators that satisfy theo-
rem 4.1 when placed in Eq. (1-3).
References
A. Anandkumar, D. P. Foster, D. Hsu, S.M. Kakade, and Y.K.
Liu. 2012a. Two svds suffice: Spectral decompositions
for probabilistic topic modeling and latent dirichlet alo-
cation. Arxiv preprint arXiv:1204.6703.
A. Anandkumar, D. Hsu, and S.M. Kakade. 2012b. A
method of moments for mixture models and hidden
markov models. Arxiv preprint arXiv:1203.0683.
B. Balle, A. Quattoni, and X. Carreras. 2011. A spectral
learning algorithm for finite state transducers. Machine
Learning and Knowledge Discovery in Databases, pages
156?171.
S. B. Cohen, K. Stratos, M. Collins, D. P. Foster, and L. Un-
gar. 2012. Spectral learning of latent-variable PCFGs. In
Proceedings of the 50th Annual Meeting of the Association
for Computational Linguistics. Association for Computa-
tional Linguistics.
S. B. Cohen, K. Stratos, M. Collins, D. P. Foster, and L. Un-
gar. 2013. Experiments with spectral learning of latent-
variable pcfgs. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for Com-
putational Linguistics: Human Language Technologies.
63
D. P. Foster, J. Rodu, and L.H. Ungar. 2012. Spec-
tral dimensionality reduction for hmms. Arxiv preprint
arXiv:1203.6130.
J. S. Garofolo et al 1988. Getting started with the darpa
timit cd-rom: An acoustic phonetic continuous speech
database. National Institute of Standards and Technology
(NIST), Gaithersburgh, MD, 107.
D. Hsu, S.M. Kakade, and T. Zhang. 2012. A spectral al-
gorithm for learning hidden markov models. Journal of
Computer and System Sciences.
H. Jaeger. 2000. Observable operator models for discrete
stochastic time series. Neural Computation, 12(6):1371?
1398.
K. Lari and S. J. Young. 1990. The estimation of stochastic
context-free grammars using the inside-outside algorithm.
Computer speech & language, 4(1):35?56.
K.F. Lee and H.W. Hon. 1989. Speaker-independent phone
recognition using hidden markov models. Acoustics,
Speech and Signal Processing, IEEE Transactions on,
37(11):1641?1648.
F. M. Luque, A. Quattoni, B. Balle, and X. Carreras. 2012.
Spectral learning for non-deterministic dependency pars-
ing. In EACL, pages 409?419.
T. Matsuzaki, Y. Miyao, and J. Tsujii. 2005. Probabilistic cfg
with latent annotations. In Proceedings of the 43rd An-
nual Meeting on Association for Computational Linguis-
tics, pages 75?82. Association for Computational Linguis-
tics.
A. Parikh, L. Song, and E.P. Xing. 2011. A spectral algo-
rithm for latent tree graphical models. In Proceedings of
the 28th International Conference on Machine Learning.
F. Pereira and Y. Schabes. 1992. Inside-outside reestima-
tion from partially bracketed corpora. In Proceedings
of the 30th annual meeting on Association for Computa-
tional Linguistics, pages 128?135. Association for Com-
putational Linguistics.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006. Learn-
ing accurate, compact, and interpretable tree annotation.
In Proceedings of the 21st International Conference on
Computational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics, pages
433?440. Association for Computational Linguistics.
Slav Petrov, Adam Pauls, and Dan Klein. 2007. Learn-
ing structured models for phone recognition. In Proc. of
EMNLP-CoNLL.
L. R. Rabiner. 1989. A tutorial on hidden markov models
and selected applications in speech recognition. Proceed-
ings of the IEEE, 77(2):257?286.
S. Siddiqi, B. Boots, and G. J. Gordon. 2010. Reduced-
rank hidden Markov models. In Proceedings of the Thir-
teenth International Conference on Artificial Intelligence
and Statistics (AISTATS-2010).
L. Song, B. Boots, S. Siddiqi, G. Gordon, and A. Smola.
2010. Hilbert space embeddings of hidden markov mod-
els. In Proceedings of the 27th International Conference
on Machine Learning. Citeseer.
S. Young, G. Evermann, M. Gales, T. Hain, D. Kershaw,
XA Liu, G. Moore, J. Odell, D. Ollason, D. Povey, et al
2006. The htk book (for htk version 3.4).
64
