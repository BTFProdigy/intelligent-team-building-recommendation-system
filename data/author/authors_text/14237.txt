Chinese Sketch Engine and 
the Extraction of Grammatical Collocations
Chu-Ren Huang  
Inst. of Linguistics  
Academia Sinica  
churen@sinica.edu.tw
Adam Kilgarriff 
Lexicography MasterClass 
Information Technology  
adam@lexmasterclass.com 
Yiching Wu 
Inst. of Linguistics 
Tsing Hua University 
d898702@oz.nthu.edu.tw 
Chih-Ming Chiu 
Inst. of Information Science 
Academia Sinica 
henning@hp.iis.sinica.edu.tw 
Simon Smith 
Dept. of Applied English 
Ming Chuan University 
ssmith@mcu.edu.tw 
Pavel Rychly 
Faculty of Informatics 
Masaryk University. 
pary@textforge.cz 
Ming-Hong Bai 
Inst. of Information Science 
Academia Sinica 
mhbai@sinica.edu.tw 
Keh-Jiann Chen 
Inst. of Information Science 
Academia Sinica 
kchen@iis.sinica.edu.tw
Abstract. This paper introduces a new 
technology for collocation extraction in Chinese. 
Sketch Engine (Kilgarriff et al, 2004) has 
proven to be a very effective tool for automatic 
description of lexical information, including 
collocation extraction, based on large-scale 
corpus. The original work of Sketch Engine was 
based on BNC. We extend Sketch Engine to 
Chinese based on Gigaword corpus from LDC. 
We discuss the available functions of the 
prototype Chinese Sketch Engine (CSE) as well 
as the robustness of language-independent 
adaptation of Sketch Engine. We conclude by 
discussing how Chinese-specific linguistic 
information can be incorporated to improve the 
CSE prototype.  
1. Introduction 
The accessibility to large scale corpora, at 
one billion words or above, has become both a 
blessing and a challenge for NLP research. How 
to efficiently use a gargantuan corpus is an 
urgent issue concerned by both users and corpora 
designers. Adam Kilgarriff et al (2004) 
developed the Sketch Engine to facilitate 
efficient use of corpora. Their claims are two 
folded: that genuine linguistic generalizations 
can be automatically extracted from a corpus 
with simple collocation information provided 
that the corpus is large enough; and that such a 
methodology is easily adaptable for a new 
language. The first claim was fully substantiated 
with their work on BNC. The current paper deals 
with the second claim by adapting the Sketch 
Engine to Chinese.  
2. Online Chinese Corpora: The State of 
the Arts 
2.1 Chinese Corpora 
The first online tagged Chinese corpus is 
Academia Sinica Balanced Corpus of Modern 
Chinese (Sinica Corpus), which has been 
web-accessible since November, 1996. The 
current version contains 5.2028 million words 
(7.8927 million characters). The corpus data was 
collected between 1990 and 1996 (CKIP, 
1995/1998). Two additional Chinese corpora 
were made available on line in 2003. The first is 
the Sinorama Chinese-English Parallel Text 
Corpus (Sinorama Corpus). The Sinorama 
Corpus is composed of 2,373 parallel texts in 
both Chinese and English that were published 
between 1976 and 2000. There are 103,252 pairs 
of sentences, composed of roughly 3.2 million 
48
English words and 5.3 million Chinese 
characters 1 . The second one is the modern 
Chinese corpus developed by the Center for 
Chinese Linguistics (CCL Corpus) at Peking 
University. It contains eighty-five million 
(85,398,433) simplified Chinese characters 
which were published after 1919 A.D. 
2.2 Extracting Linguistic Information from 
Online Chinese Corpora: Tools and Interfaces 
The Chinese corpora discussed above are 
all equipped with an online interface to allow 
users to extract linguistic generalizations. Both 
Sinica Corpus and CCL Corpus offer 
KWIC-based functions, while Sinorama Corpus 
gives sentence and paragraph aligned output. 
2.2.1 String Matching or Word Matching 
The basic unit of query that a corpus allows 
defines the set of information that can be 
extracted from that corpus. While there is no 
doubt that segmented corpus allows more precise 
linguistic generalizations, string-based 
collocation still afford a corpus of the robustness 
that is not restricted by an arbitrary word-list or 
segmentation algorithm. This robustness is of 
greatest value when extracting neologism or 
sub-lexical collocations. Since CCL Corpus is 
not segmented and tagged, string-based KWIC is 
its main tool for extracting generalizations. This 
comes with the familiar pitfall of word boundary 
ambiguity. For instance, a query of ci.yao ??
?secondary? may yield the intended result (la), as 
well as noise (1b). 
1a. ??????
dan zhe shi ci.yao de 
but this is secondary DE
1http://cio.nist.gov/esd/emaildir/lists/mt_list/msg0003
3.html 
?But this is secondary? 
 b. ????????!
ta ji ci yao.qiu ta da.fu 
he several time ask her answer 
?He had asked her to answer for several times? 
 Sinica Corpus, on the other hand, is fully 
segmented and allows word-based 
generalizations. In addition, Sinica Corpus also 
allows wildcards in its search. Users specify a 
wildcard of arbitrary length (*), or fixed length 
(?). This allows search of a class of words 
sharing some character strings.
2.2.2 Display of Extracted Data 
Formal restriction on the display of 
extracted data also constraints the type of 
information that can be obtained from that 
corpus. Sinica Corpus allows users to change 
window size from about 25 to 57 Chinese 
characters. However, since a Chinese sentence 
may be longer than 57 characters, Sinica Corpus 
cannot guarantee that a full sentence is displayed. 
CCL Corpus, on the other hand, is able to show a 
full output sentence, which may be up to 200 
Chinese characters. However, it does not display 
more than a full sentence. Thus it cannot show 
discourse information. Sinorama Corpus with 
TOTALrecall interface is most versatile in this 
respect. Aligned bilingual full sentences are 
shown with an easy link to the full text. 
In terms of size and completeness of 
extracted data, Sinica Corpus returns all matched 
examples. However, cut and paste must be 
performed for the user to build his/her dataset. 
CCL Corpus, on the other hand, limits data to 
500 lines per page, but allows easy download of 
output data. Lastly, Sinorama/TOTALrecall 
provides choices of 5 to 100 sentences per page. 
49
2.2.3 Refining Extracted Information: Filter 
and Sorter 
Both Sinica Corpus and CCL corpus allows 
users to process extracted information, using 
linguistic and contextual filter or sorter. The CCL 
corpus requires users to remember the rules, 
while Sinica Corpus allows users to fill in blanks 
and/or choose from pull-down menu. In 
particular, Sinica Corpus allows users to refine 
their generalization by quantitatively 
characterizing the left and right contexts. The 
quantitative sorting functions allowed include 
both word and POS frequency, as well as word 
mutual information.  
2.2.4 Extracting Grammatical Information 
Availability of grammatical information 
depends on corpus annotation. CCL and 
Sinorama Corpus do not have POS tags. Sinica 
Corpus is the only Chinese corpus allowing users 
to access an overview of a keyword?s syntactic 
behavior. Users can obtain a list of types and 
distribution of the keyword?s syntactic category. 
In addition, users can find possible collocations 
of the keyword from the output of Mutual 
Information (MI).  
The most salient grammatical information, 
such as grammatical functions (subject, object, 
adjunct etc.) is beyond the scope of the 
traditional corpus interface tools. Traditional 
corpora rely on the human users to arrive at these 
kinds of generalizations.
3. Sketch Engine: A New Corpus-based 
approach to Grammatical Information  
Several existing linguistically annotated 
corpus of Chinese, e.g. Penn Chinese Tree Bank 
(Xia et al, 2000), Sinica Treebank (Chen et al, 
2003), Proposition Bank (Xue and Palmer, 2003, 
2005) and Mandarin VerbNet (Wu and Liu, 
2003), suffer from the same problem. They are 
all extremely labor-intensive to build and 
typically have a narrow coverage. In addition, 
since structural assignment is theory-dependent 
and abstract, inter-annotator consistency is 
difficult to achieve. Since there is also no general 
consensus on the annotation scheme in Chinese 
NLP and linguistics, building an effective 
interface for public use is almost impossible. 
The Sketch Engine offers an answer to the 
above issues.
3.1 Initial Implementation and Design of the 
Sketch Engine 
The Sketch Engine is a corpus processing 
system developed in 2002 (Kilgarriff and 
Tugwell, 2002; Kilgarriff et al, 2004). The main 
components of the Sketch Engine are KWIC 
concordances, word sketches, grammatical 
relations, and a distributional thesaurus. In its 
first implementation, it takes as input basic BNC 
(British National Corpus, (Leech, 1992)) data: 
the annotated corpus, as well as list of lemmas 
with frequencies. In other words, the Sketch 
Engine has a relatively low threshold for the 
complexity of input corpus. 
The Sketch Engine has a versatile query 
system. Users can restrict their query in any 
sub-corpus of BNC. A query string may be a 
word (with or without POS specification), or a 
phrasal segment. A query can also be performed 
using Corpus Query Language (CQL). The 
output display format can be adjusted, and the 
displayed window of a specific item can be 
freely expanded left and right. Most of all, the 
Sketch Engine produces a Word Sketch 
(Kilgarriff and Tugwell, 2002) that is an 
automatically generated grammatical description 
of a lemma in terms of corpus collocations. All 
items in each collocation are linked back to the 
original corpus data. Hence it is similar to a 
50
Linguistic Knowledge Net anchored by a lexicon 
(Huang et al, 2001). 
 A Word Sketch is a one-page list of a 
keyword?s functional distribution and collocation 
in the corpus. The functional distribution 
includes: subject, object, prepositional object, 
and modifier. Its collocations are described by a 
list of linguistically significant patterns in the 
language. Word Sketch uses regular expressions 
over POS-tags to formalize rules of collocation 
patterns, e.g. (2) is used to retrieve the 
verb-object relation in English:
2. 1:?V? ?(DET|NUM|ADJ|ADV|N)?* 2:?N? 
The expression in (2) says: extract the data 
containing a verb followed by a noun regardless 
of how many determiners, numerals, adjectives, 
adverbs and nouns preceding the noun. It can 
extract data containing cook meals and cooking a 
five-course gala dinner, and cooked the/his/two 
surprisingly good meals etc.
The Sketch Engine also produces thesaurus 
lists, for an adjective, a noun or a verb, the other 
words most similar to it in their use in the 
language (Kilgarriff et al 2004). For instance, 
the top five synonym candidates for the verb kill
are shoot (0.249), murder (0.23), injure (0.229), 
attack (0.223), and die (0.212).2 It also provides 
direct links to the Sketch Difference which lists 
the similar and different patterns between a 
keyword and its similar word. For example, both 
kill and murder can occur with objects such as 
people and wife, but murder usually occurs with 
personal proper names and seldom selects animal 
nouns as complement whereas kill can take fox,
whale, dolphin, and guerrilla, etc. as its object. 
 The Sketch Engine adopts Mutual 
2 The similarity is measured and ranked adopting 
Lin?s (1998) mathematics. 
Information (MI) to measure the salience of a 
collocation. Salience data are shown against each 
collocation in Word Sketches and other Sketch 
Engine output. MI provides a measure of the 
degree of association of a given segment with 
others. Pointwise MI, calculated by Equation 3, 
is what is used in lexical processing to return the 
degree of association of two words x and y (a 
collocation).
3. 
)(
)|(log);(
xP
yxPyxI  
3.2 Application to Chinese Corpus 
In order to show the cross-lingual 
robustness of the Sketch Engine as well as to 
propose a powerful tool for collocation 
extraction based on a large scale corpus with 
minimal pre-processing; we constructed Chinese 
Sketch Engine (CSE) by loading the Chinese 
Gigaword to the Sketch Engine (Kilgarriff et al, 
2005). The Chinese Gigaword contains about 
1.12 billion Chinese characters, including 735 
million characters from Taiwan?s Central News 
Agency, and 380 million characters from China?s 
Xinhua News Agency3. Before loading Chinese 
Gigaword into Sketch Engine, all the simplified 
characters were converted into traditional 
characters, and the texts were segmented and 
POS tagged using the Academia Sinica 
segmentation and tagging system (Huang et al, 
1997). An array of machine was used to process 
the 1.12 million characters, which took over 3 
days to perform. All components of the Sketch 
Engine were implemented, including 
Concordance, Word Sketch, Thesaurus and 
Sketch Difference.  
 In our initial in-house testing of this 
prototype of the Chinese Sketch Engine, it does 
3http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2003T09 
51
produce the expected results with an easy to use 
interface. For instance, the Chinese Word Sketch 
correctly shows that the most common and 
salient object of dai.bu ??  ?to arrest? is
xian.fan ??  ?suspect?; the most common 
subject jing.fang ??!?police?; and the most 
common modifier dang.chang??.
 The output data of Thesaurus correctly 
verify the following set of synonyms from the 
Chinese VerbNet Project: that ren.wei ???to
think? behaves most like biao.shi ??  ?to 
express, to state? (salience 0.451), while yi.wei?
? ?to take somebody/something as? is more like 
jue.de?? ?to feel, think? (salience 0.488). The 
synonymous relation can be illustrated by (4) and 
(5).
4a. ????????????????????
?????????????????
ta ren.wei dao hai.wai tou.zi you yi ge guan.nian 
hen zhong.yao, jiu shi yao zhi.dao dang.di de 
you.xi gui.ze 
?He believes that for those investing overseas, 
there is a very important principle-one must know 
the local rules of the game, and accept them.? 
 b. ????????????????????
?????!
zhi.zheng.dang ye biao.shi, you.yu gong.shi 
zheng.yi tai da, kong.pa wu.fa quan.li zhi.chi 
?The KMT also commented that due to the many 
controversies surrounding PTV, it could not 
wholeheartedly support it either.? 
5a. ?????????????????????
????????
he.jia.ju jiu ren.wei??dian.shi you ji.ben yu.yan 
he wen.fa, yao jiang.jiu mai.dian he shi.chang??
?Ho Chia-chu says, "Television has its own 
fundamental language and grammar. You must 
consider selling points and the market."? 
b. ?????????????????????
???????????
ta biao.shi??wo xi.wang fuo.jiao.tu neng liao.jie, 
fu.quan she.hui yu jue.wu de she.hui shi bu 
xiang.he de??
?She says "I hope that followers of Buddhism can 
realize that a patriarchal society is incompatible 
with an enlightened society."? 
The above examples show that ren.wei and 
biao.shi can take both direct and indirect 
quotation. Yi.wei and jue.de, on the other hand, 
can only be used in reportage and cannot 
introduce direct quotation. 
Distinction between near synonymous pairs 
can be obtained from Sketch Difference. This 
function is verified with results from Tsai et al?s 
study on gao.xing?? ?glad? and kuai.le??!
?happy? (Tsai et al, 1998). Gao.xing ?glad? 
specific patterns include the negative imperative 
bie? ?don?t?. It also has a dominant collocation 
with the potentiality complement marker de?
(e.g. ta gao.xing de you jiao you tiao ????
???? ?she was so happy that she cried and 
danced?). In contrast, kuai.le ?happy? has the 
specific collocation with holiday nouns such as 
qiu.jie ??  ?Autumn Festival?. The Sketch 
Difference result is consistent with the account 
that gao.xing/kuai.le contrast is that inchoative 
state vs. homogeneous state. 
4. Evaluation and Future Developments 
An important feature of the prototype of the 
Chinese Sketch Engine is that, in order to test the 
robustness of the Sketch Engine design, the 
original regular expression patterns were adopted 
with minimal modification for Chinese. Even 
though both are SVO languages with similar 
surface word order, it is obvious that they differ 
substantially in terms of assignment of 
grammatical functions. In addition, the Sinica 
tagset is different from the BNC tagset and 
52
actually has much richer functional information. 
These are the two main directions that we will 
pursue in modification and improvement of the 
Chinese Sketch Engine. 
4.1 Word Boundary Representation 
Word breaks are not conventionalized in 
Chinese texts. This poses a challenge in Chinese 
language processing. The Chinese Sketch Engine 
inserted space after segmentation, which helps to 
visualize words. In the future, it will be trivial to 
allow the conventional alternative of no word 
boundary markups. However, it will not be trivial 
to implement fuzzy function to allow searches 
for non-canonical lemmas (i.e. lemmas that are 
segmented differently from the standard corpus). 
4.2 Sub-Corpora Comparison  
The Chinese Gigaword corpus is marked 
with two different genres, story and non-story. A 
still more salient sub-corpus demarcation is the 
one between Mainland China corpus and Taiwan 
corpus. Sketch Difference between lemmas form 
two sub-corpora is being planned. This would 
allow future comparative studies and would have 
wide applications in the localization adaptations 
of language related applications.  
4.3 Collating Frequency Information with 
POS
One of the convenient features of Sketch 
Engine that a frequency ranked word list is 
linked to all major components. This allows a 
very easy and informative reference. Since 
cross-categorical derivation with zero 
morphology is dominant in Chinese, it would 
help the processing greatly if POS information is 
added to the word list. Adding such information 
would also open the possibility of accessing the 
POS ranked frequency information. 
4.5 Fine-tuning Collocation Patterns  
The Sketch Engine relies on collocation 
patterns, such as (2) above, to extract 
collocations. The regular expression format 
allows fast processing of large scale corpora with 
good results. However, these patterns can be 
fine-tuned for better results. We give VN 
collocates with object function as example here. 
In (6), verbs are underlined with a single line, 
and the collocated nouns identified by English 
Word Sketch are underlined with double lines. 
Other nominal objects that the Sketch Engine 
misses are marked with a dotted line. 
6.a. In addition to encouraging kids to ask, think and 
do, parents need to be tolerant and appreciative to 
avoid killing a child's creative sense.
b. Children are taught to love their parents,
classmates, animals, nature . . . . in fact they are 
taught to love just about everything except to 
love China, their mother country. 
c. For example, the government deliberately chose 
not to teach Chinese history and culture, nor 
civics, in the schools. 
d. At the game there will be a lottery drawing for a 
motorcycle! And perhaps you'll catch a foul ball
or a home run.
The sentences in (6) show that the current Sketch 
Engine tend to only identify the first object when 
there are multiple objects. The resultant 
distributional information thus obtained will be 
valid given a sufficiently large corpus. However, 
if the collocation patterns are fine-tuned to allow 
treatment of coordination, richer and more 
precise information can be extracted. 
 A regular expression collocation pattern 
also runs the risk of mis-classification. For 
instance, speech act verbs often allow subject to 
occur in post-verbal positions, and intransitive 
53
verbs can often take temporal nouns in 
post-verbal positions too.  
7. a. ?you can say goodbye to your competitive 
career. 
b. `No,' said Scarlet, `but then I don't notice much.'
8. a. Where did you sleep last night?
  b. ?it arrived Thursday morning.
  c. From Arty's room came the sound of an 
accordion.
9. `I'll look forward to that.' `So will I.' 
Such non-canonical word orders are even more 
prevalent in Chinese. Chinese objects often occur 
in pre-verbal positions in various pre-posing 
constructions, such as topicalization. 
10. ???????????
quan.gu mian.bao, chi le hen jian.kang 
whole-grain bread, eat LE very healthy 
?Eating whole-grain bread is very healthy.? 
11a. ??????????????????
you ren chang.shi yao jiang zhe he.hua fen.lei,
que yue fen yue lei 
someone try to JIANG the lotus classify, but more 
classify more tired 
?People have tried to decide what category the 
lotus belongs in, but have found the effort 
taxing.? 
b. ??????????
wo yi.ding yao ba lao.da chu.diao
I must want BA the oldest (son) get rid of
?I really want to get rid of the older son.?
When objects are pre-posed, they tend to stay 
closer to the verb than the subject. Adding object 
marking information, such as ba?, jiang?, lian
?  would help correctly identify collocating 
pre-posed objects. However, for those unmarked 
pre-posed structures, closeness to the verb may 
not provide sufficient information. Several rules 
will need to be implemented jointly.  
 The above example underlines a critical 
issue. That is, whether relative position alone is 
enough to identify positional information. The 
Sketch Engine is in essence a powerful tool 
extracting generalizations from annotated corpus 
data. We have shown that it can extract useful 
grammatical information with POS tag alone. If 
the corpus is tagged with richer annotation, the 
Sketch Engine should be able to extract even 
richer information. 
 The Sinica Corpus tagset adapts to the fact 
that Chinese has a freer word order than English 
by incorporating semantic information with the 
grammatical category. For instance, locational 
and temporal nouns, proper nouns, and common 
nouns each are assigned a different tag. Verbs are 
sub-categorized according to activity and 
transitivity. Such information is not available in 
the BNC tagset and hence not used in the 
original Sketch Engine design. We will enrich the 
collocation patterns with the annotated linguistic 
information from the Sinica Corpus tagset. In 
particular, we are converting ICG lexical 
subcategorization frames (Chen and Huang 1990) 
to Sketch Engine collocation patters. These ICG 
frames, called Basic Patterns and Adjunct 
Patterns, have already been fully annotated 
lexically and tested on the Sinica Corpus. We 
expect their incorporation to improve Chinese 
Sketch Engine results markedly. 
6. Conclusion 
In this paper, we introduce a powerful tool 
for extraction of collocation information from 
large scale corpora. Our adaptation proved the 
cross-lingual robustness of the Sketch Engine. In 
particular, we show the robustness of the Sketch 
Engine by achieving better results through 
fine-tuning of the collocation patterns via 
integrating available grammatical knowledge. 
54
References 
Chen, Keh-Jiann and Huang, Chu-Ren. 1990.  
Information-based Case Grammar.  
Proceedings of the 13th COLING. Helsinki, 
Finland. 2:54-59. 
Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, 
Chi-Ching Luo, Ming-Chung Chang, and 
Chao-Jan Chen. 2003. Sinica Treebank: 
Design Criteria, Representational Issues and 
Implementation. In Anne Abeill?e, (ed.): 
Building and Using Parsed Corpora. Text, 
Speech and Language Technology,
20:231-248. Dordrecht: Kluwer.  
CKIP (Chinese Knowledge Information Processing 
Group). 1995/1998. The Content and 
Illustration of Academica Sinica Corpus.
(Technical Report no 95-02/98-04). Taipei: 
Academia Sinica  
Huang, Chu-Ren, Feng-Ju Lo, Hui-Jun Hsiao, 
Chiu-Jung Lu, and Ching-chun Hsieh. 2001. 
From Language Archives to Digital 
Museums: Synergizing Linguistic Databases. 
Presented at the IRCS workshop on linguistic 
Databases. University of Pennsylvania. 
Huang, Chu-Ren, Keh-Jiann Chen, and Lili Chang. 
1997. Segmentation Standard for Chinese 
Natural Language Processing. 
Computational Linguistics and Chinese 
Language Processing. 2(2):47-62.  
Kilgarriff, Adam and Tugwell, David. Sketching 
Words. 2002. In Marie-H?l?ne Corr?ard (ed.): 
Lexicography and Natural Language 
Processing. A Festschrift in Honour of B.T.S. 
Atkins. 125-137. Euralex.  
Kilgarriff, Adam, Chu-Ren Huang, Pavel Rychl?, 
Simon Smith, and David Tugwell. 2005. 
Chinese Word Sketches. ASIALEX 2005: 
Words in Asian Cultural Context. Singapore.  
Kilgarriff, Adam, Pavel Rychl?, Pavel Smrz and 
David Tugwell. 2004. The Sketch Engine. 
Proceedings of EURALEX, Lorient, France. 
(http://www.sketchengine.co.uk/) 
Leech, Geoffrey. 1992. 100 million words of 
English: the British National Corpus (BNC). 
Language Research 28(1):1-13 
Lin, Dekang. 1998. An Information-Theoretic 
Definition of Similarity. Proceedings of 
International Conference on Machine 
Learning. Madison, Wisconsin. 
(http://www.cs.umanitoba.ca/~lindek/publica
tion.htm) 
Tsai, Mei-Chih, Chu-Ren Huang, Keh-Jiann Chen, 
and Kathleen Ahrens. 1998. Towards a 
Representation of Verbal Semantics--An 
Approach Based on Near Synonyms. 
Computational Linguistics and Chinese 
Language Processing. 3(1): 61-74. 
Wu, Yiching and Liu, Mei-Chun. 2003. The 
Construction and Application of Mandarin 
Verbnet. Proceedings of the Third 
International Conference of Internet Chinese 
Education. 39-48. Taipei, Taiwan. 
Xia, Fei, Martha Palmer, Nianwen Xue, Mary Ellen 
Okurowski, John Kovarik, Fu-Dong Chiou, 
Shizhe Huang, Tony Kroch, and Mitch 
Marcus. 2000. Developing Guidelines and 
Ensuring Consistency for Chinese Text 
Annotation. Proceedings of the second 
International Conference on Language 
Resources and Evaluation (LREC 2000), 
Athens, Greece.  
    (http://www.cis.upenn.edu/~chinese/ctb.html)
Xue, Nianwen and Palmer, Martha. 2003. 
Annotating Propositions in the Penn Chinese 
Treebank. Proceedings of the Second Sighan 
Workshop. Sapporo, Japan. 
     (http://www.cis.upenn.edu/~xueniwen/) 
Xue, Nianwen and Palmer, Martha. 2005. 
Automatic Semantic Role Labeling for 
Chinese Verbs. Proceedings of the 19th 
International Joint Conference on Artificial 
Intelligence. Edinburgh, Scotland. 
     (http://www.cis.upenn.edu/~xueniwen/) 
Websites
Sinica Corpus.  
http://www.sinica.edu.tw/SinicaCorpus/  
British National Corpus (BNC). 
http://www.natcorp.ox.ac.uk/  
Center for Chinese Linguistics, PKU.  
http://ccl.pku.edu.cn/#  
Corpora And NLP (Natural Language Processing) 
for Digital Learning of English (CANDLE). 
http://candle.cs.nthu.edu.tw/candle/     
FrameNet.  
http://www.icsi.berkeley.edu/~framenet/  
Penn Chinese Treebank. 
http://www.cis.upenn.edu/~chinese/ctb.html  
Proposition Bank.  
http://www.cis.upenn.edu/~ace/  
Sinica Treebank.   
http://treebank.sinica.edu.tw/  
Sketch Engine (English).  
http://www.sketchengine.co.uk/     
Sketch Engine (Chinese).  
http://corpora.fi.muni.cz/chinese/  
Sou Wen Jie Zi-A Linguistic KnowledgeNet. 
http://words.sinica.edu.tw/ 
55
Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 41?44,
Prague, June 2007. c?2007 Association for Computational Linguistics
An efficient algorithm for building a distributional thesaurus (and other
Sketch Engine developments)
Pavel Rychly?
Masaryk University
Brno, Czech Republic
pary@fi.muni.cz
Adam Kilgarriff
Lexical Computing Ltd
Brighton, UK
adam@lexmasterclass.com
Abstract
Gorman and Curran (2006) argue that the-
saurus generation for billion+-word corpora
is problematic as the full computation takes
many days. We present an algorithm with
which the computation takes under two
hours. We have created, and made pub-
licly available, thesauruses based on large
corpora for (at time of writing) seven major
world languages. The development is imple-
mented in the Sketch Engine (Kilgarriff et
al., 2004).
Another innovative development in the same
tool is the presentation of the grammatical
behaviour of a word against the background
of how all other words of the same word
class behave. Thus, the English noun con-
straint occurs 75% in the plural. Is this
a salient lexical fact? To form a judge-
ment, we need to know the distribution for
all nouns. We use histograms to present the
distribution in a way that is easy to grasp.
1 Thesaurus creation
Over the last ten years, interest has been growing
in distributional thesauruses (hereafter simply ?the-
sauruses?). Following initial work by (Spa?rck Jones,
1964) and (Grefenstette, 1994), an early, online dis-
tributional thesaurus presented in (Lin, 1998) has
been widely used and cited, and numerous authors
since have explored thesaurus properties and param-
eters: see survey component of (Weeds and Weir,
2005).
A thesaurus is created by
? taking a corpus
? identifying contexts for each word
? identifying which words share contexts.
For each word, the words that share most contexts
(according to some statistic which also takes account
of their frequency) are its nearest neighbours.
Thesauruses generally improve in accuracy with
corpus size. The larger the corpus, the more clearly
the signal (of similar words) will be distinguished
from the noise (of words that just happen to share
a few contexts). Lin?s was based on around 300M
words and (Curran, 2004) used 2B (billion).
A direct approach to thesaurus computation looks
at each word and compares it with each other word,
checking all contexts to see if they are shared. Thus,
complexity is O(n2m) where n in the number of
types and m is the size of the context vector. The
number of types increases with the corpus size, and
(Ravichandran et al, 2005) propose heuristics for
thesaurus building without undertaking the complete
calculation. The line of reasoning is explored further
by (Gorman and Curran, 2006), who argue that the
complete calculation is not realistic given large cor-
pora. They estimate that, given a 2B corpus and its
184,494-word vocabulary comprising all words oc-
curring over five times, the full calculation will take
nearly 300 days. With the vocabulary limited to the
75,800 words occuring over 100 times, the calcula-
tion took 18 days.
The naive algorithm has complexity O(n2m) but
this is not the complexity of the problem. Most of
41
the n2 word pairs have nothing in common so there
is no reason to check them. We proceed by working
only with those word pairs that do have something in
common. This allows us to create thesauruses from
1B corpora in under 2 hours.
1.1 Algorithm
We prepare the corpus by lemmatizing and then
shallow parsing to identify grammatical relation in-
stances with the form ?w1, r, w??, where r is a
grammatical relation, w1 and w? are words. We
count the frequency of each triple and sort all
?w1, r, w?, score? 4-tuples by ?contexts? where a
context is a ?r, w?? pair. Only 4-tuples with positive
score are included.
The algorithm then loops over each context
(CONTEXTS is the set of all contexts):
for ?r, w?? in CONTEXTS:
WLIST = set of all w where ?w, r,w?? exists
for w1 in WLIST:
for w2 in WLIST:
sim(w1, w2)+ = f(frequencies)1
The outer loop is linear in the number of contexts.
The inner loop is quadratic in the number of words
in WLIST, that is, the number of words sharing a
particular context ?r, w??. This list is usually small
(less than 1000), so the quadratic complexity is man-
ageable.
We use a heuristic at this point. If WLIST has
more than 10,000 members, the context is skipped.
Any such general context is very unlikely to make
a substantial difference to the similarity score, since
similarity scores are weighted according to how spe-
cific they are. The computational work avoided can
be substantial.
The next issue is how to store the whole
sim(w1, w2) matrix. Most of the values are very
small or zero. These values are not stored in the
final thesaurus but they are needed during the com-
putation. A strategy for this problem is to gener-
ate, sort and sum in sequential scan. That means
that instead of incrementing the sim(w1, w2) score
as we go along, we produce ?w1, w2, x? triples in
a very long list, running, for a billion-word corpus,
1In this paper we do not discuss the nature of this function
as it is does not impact on the complexity. It is explored exten-
sively in (Curran, 2004; Weeds and Weir, 2005).
into hundreds of GB. For such huge data, a variant
of TPMMS (Two Phase Multi-way Merge Sort) is
used. First we fill the whole available memory with
a part of the data, sort in memory (summing where
we have multiple instances of the same ?w1, w2? as
we proceed) and output the sorted stream. Then we
merge sorted streams, again summing as we pro-
ceed.
Another technique we use is partitioning. The
outer loop of the algorithm is fast and can be run
several times with a limit on which words to process
and output. For example, the first run processes only
word pairs ?w1, w2? where the ID of w1 is between
0 and 99, the next, where it is between 100 and 199,
etc. In such limited runs there is a high probability
that most of the summing is done in memory. We es-
tablish a good partitioning with a dry run in which a
plan is computed such that all runs produce approxi-
mately the number of items which can be sorted and
summed in memory.
1.2 Experiments
We experimented with the 100M-word BNC2, 1B-
word Oxford English Corpus3 (OEC), and 1.9B-
word Itwac (Baroni and Kilgarriff, 2006).
All experiments were carried out on a machine
with AMD Opteron quad-processor. The machine
has 32 GB of RAM but each process used only
1GB (and changing this limit produced no signifi-
cant speedup). Data files were on a Promise disk
array running Disk RAID5.
Parameters for the computation include:
? hits threshold MIN: only words entering into a
number of triples greater than MIN will have
thesaurus entries, or will be candidates for be-
ing in other words? thesaurus entries. (Note
that words not passing this threshold can still
be in contexts, so may contribute to the simi-
larity of two other words: cf Daelemans et al?s
title (1999).)
? the number of words (WDS) above the thresh-
old
2http://www.natcorp.ox.ac.uk
3http://www.askoxford.com/oec/ We are grateful to Oxford
University Press for permission to use the OEC.
42
Corp MIN WDS TYP CTX TIME
BNC 1 152k 5.7m 608k 13m 9s
BNC 20 68k 5.6m 588k 9m 30s
OEC 2 269k 27.5m 994k 1hr 40m
OEC 20 128k 27.3m 981k 1hr 27m
OEC 200 48k 26.7m 965k 1hr 10m
Itwac 20 137k 24.8m 1.1m 1hr 16m
Table 1: Thesaurus creation jobs and timings
? the number of triples (types) that these words
occur in (TYP)
? the number of contexts (types) that these words
occur in (CTX)
We have made a number of runs with different
values of MIN for BNC, OEC and Itwac and present
details for some representative ones in Table 1.
For the BNC, the number of partitions that the TP-
MMS process was divided into was usually between
ten and twenty; for the OEC and ITwac it was around
200.
For the OEC, the heuristic came into play and, in
a typical run, 25 high-frequency, low-salience con-
texts did not play a role in the theasurus compu-
tation. They included: modifier?more; modifier?
not; object-of?have; subject-of?have. In Gorman
and Curran, increases in speed were made at sub-
stantial cost to accuracy. Here, data from these high-
frequency contexts makes negligible impact on the-
saurus entries.
1.3 Available thesauruses
Thesauruses of the kind described are pub-
licly available on the Sketch Engine server
(http://www.sketchengine.co.uk) based on corpora
of between 50M and 2B words for, at time of writ-
ing, Chinese, English, French, Italian, Japanese,
Portuguese, Slovene and Spanish.
2 Histograms for presenting statistical
facts about a word?s grammar
75% of the occurrences of the English noun con-
straint in the BNC are in the plural. Many dictio-
naries note that some nouns are usually plural: the
question here is, how salient is the fact about con-
Figure 1: Distribution of nouns with respect to pro-
portion of instances in plural, from 0 to 1 in 10 steps,
with the class that constraint is in, in white.
straint?45
To address it we need to know not only the propor-
tion for constraint but also the proportion for nouns
in general. If the average, across nouns, is 50% then
it is probably not noteworthy. But if the average is
2%, it is. If it is 30%, we may want to ask a more
specific question: for what proportion of nouns is the
percentage higher than 75%. We need to view ?75%
plural? in the context of the whole distribution.
All the information is available. We can deter-
mine, in a large corpus such as the BNC, for each
noun lemma with more than (say) fifty occurrences,
what percentage is plural. We present the data in a
histogram: we count the nouns for which the propor-
tion is between 0 and 0.1, 0.1 and 0.2, . . . , 0.9 and
1. The histogram is shown in Fig 1, based on the
14,576 nouns with fifty or more occurrences in the
BNC. (The first column corresponds to 6113 items.)
We mark the category containing the item of inter-
est, in red (white in this paper). We believe this is
an intuitive and easy-to-interpret way of presenting
a word?s relative frequency in a particular grammat-
ical context, against the background of how other
words of the same word class behave.
We have implemented histograms like these in the
Sketch Engine for a range of word classes and gram-
matical contexts. The histograms are integrated into
4Other 75% plural nouns which might have served as the
example include: activist bean convulsion ember feminist intri-
cacy joist mechanic relative sandbag shutter siding teabag tes-
ticle trinket tusk. The list immediately suggests a typology of
usually-plural nouns, indicating how this kind of analysis pro-
vokes new questions.
5Of course plurals may be salient for one sense but not oth-
ers.
43
the word sketch6 for each word. (Up until now the
information has been available but hard to interpret.)
In accordance with the word sketch principle of not
wasting screen space, or user time, on uninteresting
facts, histograms are only presented where a word is
in the top (or bottom) percentile for a grammatical
pattern or construction.
Similar diagrams have been used for similar pur-
poses by (Lieber and Baayen, 1997). This is, we
believe, the first time that they have been offered as
part of a corpus query tool.
3 Text type, subcorpora and keywords
Where a corpus has components of different text
types, users often ask: ?what words are distinctive of
a particular text type?, ?what are the keywords??.7
Computations of this kind often give unhelpful re-
sults because of the ?lumpiness? of word distribu-
tions: a word will often appear many times in an
individual text, so statistics designed to find words
which are distinctively different between text types
will give high values for words which happen to be
the topic of just one particular text (Church, 2000).
(Hlava?c?ova? and Rychly?, 1999) address the prob-
lem through defining ?average reduced frequency?
(ARF), a modified frequency count in which the
count is reduced according to the extent to which
occurrences of a word are bunched together.
The Sketch Engine now allows the user to prepare
keyword lists for any subcorpus, either in relation to
the full corpus or in relation to another subcorpus,
using a statistic of the user?s choosing and basing
the result either on raw frequency or on ARF.
Acknowledgements
This work has been partly supported by the
Academy of Sciences of Czech Republic under the
project T100300419, by the Ministry of Education
of Czech Republic within the Center of basic re-
search LC536 and in the National Research Pro-
gramme II project 2C06009.
6A word sketch is a one-page corpus-derived account of a
word?s grammatical and collocation behaviour.
7The well-established WordSmith corpus tool
(http://www.lexically.net/wordsmith) has a keywords function
which has been very widely used, see e.g., (Berber Sardinha,
2000).
References
Marco Baroni and Adam Kilgarriff. 2006. Large
linguistically-processed web corpora for multiple lan-
guages. In EACL.
Tony Berber Sardinha. 2000. Comparing corpora with
wordsmith tools: how large must the reference corpus
be? In Proceedings of the ACL Workshop on Compar-
ing Corpora, pages 7?13.
Kenneth Ward Church. 2000. Empirical estimates of
adaptation: The chance of two noriegas is closer to
p/2 than p2. In COLING, pages 180?186.
James Curran. 2004. From Distributional to Semantic
Similarity. Ph.D. thesis, Edinburgh Univesity.
Walter Daelemans, Antal van den Bosch, and Jakub Za-
vrel. 1999. Forgetting exceptions is harmful in lan-
guage learning. Machine Learning, 34(1-3).
James Gorman and James R. Curran. 2006. Scaling dis-
tributional similarity to large corpora. In ACL.
Gregory Grefenstette. 1994. Explorations in Automatic
Thesaurus Discovery. Kluwer.
Jaroslava Hlava?c?ova? and Pavel Rychly?. 1999. Dispersion
of words in a language corpus. In Proc. TSD (Text
Speech Dialogue), pages 321?324.
Adam Kilgarriff, Pavel Rychly?, Pavel Smrz?, and David
Tugwell. 2004. The sketch engine. In Proc. EU-
RALEX, pages 105?116.
Rochelle Lieber and Harald Baayen. 1997. Word fre-
quency distributions and lexical semantics. Computers
in the Humanities, 30:281?291.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In COLING-ACL, pages 768?774.
Deepak Ravichandran, Patrick Pantel, and Eduard H.
Hovy. 2005. Randomized algorithms and nlp: Using
locality sensitive hash functions for high speed noun
clustering. In ACL.
Karen Spa?rck Jones. 1964. Synonymy and Semantic
Classificiation. Ph.D. thesis, Edinburgh University.
Julie Weeds and David J. Weir. 2005. Co-occurrence re-
trieval: A flexible framework for lexical distributional
similarity. Computational Linguistics, 31(4):439?475.
44
