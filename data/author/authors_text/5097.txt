Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 17?24,
New York City, June 2006. c?2006 Association for Computational Linguistics
Understanding Complex Natural Language Explanations in Tutorial
Applications?
Pamela W. Jordan, Maxim Makatchev and Umarani Pappuswamy
Learning Research and Development Center
University of Pittsburgh
Pittsburgh PA, 15260
{pjordan,maxim,umarani}@pitt.edu
Abstract
We describe the WHY2-ATLAS intelligent
tutoring system for qualitative physics that
interacts with students via natural lan-
guage dialogue. We focus on the is-
sue of analyzing and responding to multi-
sentential explanations. We explore an ap-
proach that combines a statistical classi-
fier, multiple semantic parsers and a for-
mal reasoner for achieving a deeper under-
standing of these explanations in order to
provide appropriate feedback on them.
1 Introduction
Most natural language tutorial applications have fo-
cused on coaching either problem solving or proce-
dural knowledge (e.g. Steve (Johnson and Rickel,
1997), Circsim-tutor (Evens and Michael, 2006),
Atlas (Rose? et al, 2001), BEETLE (Zinn et al,
2002), SCoT (Peters et al, 2004), inter alia). When
coaching problem solving, simple short answer anal-
ysis techniques are frequently sufficient because the
primary goal is to lead a trainee step-by-step through
problem solving. There is a narrow range of possi-
ble responses and the context of the previous dia-
logue and questions invite short answers. But when
the instructional objectives shift and a tutorial sys-
tem attempts to explore a student?s chain of reason-
ing behind an answer or decision, deeper analysis
techniques can begin to pay off. Having the student
?This research was supported by ONR Grant No. N00014-
00-1-0600 and by NSF Grant No. 9720359.
construct more on his own is important for learning
perhaps in part because it reveals what the student
does and does not understand (Chi et al, 2001).
When the student is invited to provide a longer
chain of reasoning, the explanations become multi-
sentential. Compare the short explanation in Fig-
ure 1 to the longer ones in Figures 2 and 3. The ex-
planation in Figure 2 is part of an actual initial stu-
dent response and Figure 3 shows the explanation
from the same student after a follow-up dialogue
with the WHY2-ATLAS tutoring system.
WHY2-ATLAS: Fine. Using this principle, what is the value
of the horizontal component of the acceleration of the egg?
Please explain your reasoning.
Student: zero because there is no horizontal force acting on
the egg [3 propositions expressed]
Figure 1: Eliciting a one sentence explanation from
a student.
WHY2-ATLAS: Suppose a man is in an elevator that is
falling without anything touching it (ignore the air, too). He
holds his keys motionless right in front of his face and then
just releases his grip on them. What will happen to them?
Explain.
Student: [omitted 15 correct propositions]... Yet the gravita-
tional pull on the man and the elevator is greater because they
are of a greater weight and therefore they will fall faster then
the keys. I believe that the keys will float up to the cieling as
the elevator continues falling.
Figure 2: An initial elicitation of a multi-sentence
explanation from a student.
The only previous tutoring system that has at-
tempted to address longer explanations is AUTOTU-
TOR (Graesser et al, 2004). It uses a latent semantic
17
[omitted 16 correct propositions]... Since <Net force
= mass * acceleration> and <F= mass*g> therefore
<mass*acceleration= mass*g> and acceleration and grav-
itational force end up being equal. So mass does not ef-
fect anything in this problem and the acceleration of both the
keys and the man are the same. [omitted 46 correct proposi-
tions]...we can say that the keys will remain right in front of
the man?s face.
Figure 3: A subsequent response from the same stu-
dent in Figure 2 after some interaction with WHY2-
ATLAS.
analysis (LSA) approach where the structure of sen-
tences is not considered. Thus the degree to which
details of the explanation are understood is limited.
As can be seen from the examples, a student?s ex-
planation about a formal domain such as qualitative
physics may involve a number of phenomena: al-
gebraic formulas, NL renderings of formulas, vari-
ous degrees of formality, and conveying the logical
structure of an argument (Makatchev et al, 2005).
Tutoring goals involve eliciting correct statements
of the appropriate degree of formality and their jus-
tifications to address possible gaps and errors in the
explanation. To achieve these goals the NL under-
standing is required to answer the following ques-
tions:
? Does the student explanation contain errors? If
yes, what are the likely buggy assumptions that
have led the student to these errors?
? What required statements have not been cov-
ered by the student? Does the explanation con-
tain statements that are logically close to the
required statements?
These requirements imply that a logical structure
needs to be imposed on the space of possible do-
main statements. Considering such a structure to
be a model of the student?s reasoning about the do-
main, the two requirements correspond to a solution
of a model-based diagnosis problem (Forbus and de
Kleer, 1993).
How does one build such a model? A desire to
make the process scalable and feasible necessitates
an automated procedure. The difficulty is that this
automated reasoner has to deal with the NL phe-
nomena that are relevant for our application. In turn,
this means that the knowledge representation (KR)
would have to be able to express these phenomena
(e.g. NL renderings of formulas, various degrees of
formality). The reasoner has to account for common
reasoning fallacies, have flexible consistency con-
straints and perform within the tight requirements of
a real-time dialogue application.
In this paper, we present a hybrid of symbolic
and statistical approaches that attempts to robustly
provide a model-based diagnosis of a student?s ex-
planation. In the next section, we provide a brief
sketch of the KR used in WHY2-ATLAS. Section 3
describes our hybrid approach for analyzing student
explanations while section 4 covers our most recent
evaluations of the system and its explanation analy-
sis components. Section 5 presents our conclusions
along with future directions.
2 Knowledge representation
We selected an order-sorted first-order predicate
logic (FOPL) as a base KR for our domain since
it is expressive enough to reflect the hierarchy of
concepts from the qualitative mechanics ontology
(Ploetzner and VanLehn, 1997) and has a straight-
forward proof theory (Walther, 1987). Follow-
ing the representation used in the abductive rea-
soner Tacitus-lite (Thomason et al, 1996), our KR
is function-free, does not have quantifiers, Skolem
constants or explicit negation. Instead all variables
in facts or goals are assumed to be existentially
quantified, and all variables in rules are either uni-
versally quantified (if they appear in premises) or ex-
istentially quantified (if they appear in conclusions
only).
Although our KR has no explicit negation, some
types of negative statements are represented by us-
ing (a) complimentary sorts, for example constant
and nonconstant; (b) the value nonequal as a filler
of the respective argument of comparison predicates.
Instead of parsing arbitrary algebraic expressions,
an equation identifier module attempts shallow pars-
ing of equation candidates and maps them into a fi-
nite set of anticipated equation labels (Makatchev et
al., 2005).
NL understanding needs to distinguish formal
versus informal physics expressions so that the tu-
toring system can coach on proper use of terminol-
ogy. Many qualitative mechanics phenomena may
18
be described informally, for example ?speed up? in-
stead of ?accelerate? and ?push? instead of ?apply
a force.? The relevant informal expressions fall into
the following categories:
? relative position: ?keys are behind (in front of,
above, under, close, far from, etc.) man?
? motion: ?move slower,? ?slow down,? ?moves
along a straight line?
? dependency: ?horizontal speed will not depend
on the force?
? direction: ?the force is downward?
? interaction: ?the man pushes the keys,? ?the
gravity pulls the keys?
Each of these categories (except for the last one)
has a dedicated representation. While represent-
ing push and pull expressions via a dedicated predi-
cate seems straightforward, we are still assessing the
utility of distinguishing ?man pushes the keys? and
?man applies a force on the keys? for our tutoring
application and currently represent both expressions
as a nonzero force applied by the man to the keys.
One of the tutoring objectives of WHY2-ATLAS
is to encourage students to provide argumentative
support for their conclusions. This requires recog-
nizing and representing the justification-conclusion
clauses in student explanations. Recognizing such
clauses is a challenging NLP problem due to the is-
sue of quantifier and causality scoping. It is also dif-
ficult to achieve a compromise between two compet-
ing requirements for a suitable representation. First,
the KR should be flexible enough to account for a
variable number of justifications. Second, reasoning
with the KR should be computationally feasible. We
leave representing the logical structure of explana-
tions for future work.
3 Analyzing Student Explanations
When analyzing a student explanation, first an equa-
tion identifier tags any physics equations in the stu-
dent?s response and then the explanation is classified
to complete the assessment. Explanation classifica-
tion is done by using either (a) a statistical classi-
fier that maps the explanation directly into a set of
known facts, principles and misconceptions, or (b)
two competing semantic parsers that each generate
an FOPL representation that is then matched against
known facts, principles or misconceptions, as well
as against pre-computed correct and buggy chains
of reasoning. We present the approaches at a high-
level in order to focus on how the approaches work
when combined and our evaluation results.
3.1 Statistical classifier
RAINBOW is a tool for developing bag of words
(BOW) text classifiers (McCallum and Nigam,
1998). The classes of interest must first be identified
and then a text corpus annotated for example sen-
tences for each class. From this training data a bag
of words representation is derived for each class and
a number of algorithms can be tried for measuring
similarity of a new input segment?s BOW represen-
tation to each class.
For WHY2-ATLAS, the classes are a subset of
nodes in the correct and buggy chains of reason-
ing. Limiting the number of classes allows us to
alleviate the problem of sparseness of training data,
but the side-effect is that there are many misclassi-
fications of sentences due to overlap in the classes;
that is, words that discriminate between classes are
shared by many other classes (Pappuswamy et al,
2005). We alleviate this problem some by aggre-
gating classes and building three tiers of BOW text
classifiers that use a kNN measure. By doing so, we
obtain a 13% improvement in classification accuracy
over a single classifier approach (Pappuswamy et al,
2005). The upper two tiers of classification describe
the topic of discussion and the lower tier describes
the specific principle or misconception related to the
topic and subtopic. The first tier classifier identifies
which second tier classifier to use and so on. The
third tier then identifies which node (if any) in the
chain of reasoning a sentence expresses.
But because the number of classes is limited,
BOW has problems dealing with many of the NL
phenomena we described earlier. For example, al-
though it can deal with some informal language use
(i.e. ?push the container? maps to ?apply force on
the container?), it cannot provide accurate syntactic-
semantic mappings between informal and formal
language on the fly. This is because the informal
language use is so varied that it is difficult to cap-
ture representative training data in sufficient quanti-
ties. Hence, a large portion of student statements ei-
ther cannot be classified with high confidence or are
19
erroneously classified. We use a post-classification
heuristic to try to filter out the latter cases. The filter-
ing heuristic depends on the system?s representation
language and not on the classification technique.
Given a classification of which node in the chain
of reasoning the sentence represents, the heuris-
tic estimates whether the node?s FOPL representa-
tion either over- or under-represents the sentence by
matching the root forms of the words in the natural
language sentence to the constants in the system?s
representation language.
For those statements BOW cannot classify or that
the heuristic filters out, we attempt classification us-
ing an FOPL representation derived from semantic
parsing, as described in the next two subsections.
3.2 Converting NL to FOPL
Two competing methods of sentence analysis each
generate a FOPL candidate. The two candidates
are then passed to a heuristic selection process that
chooses the best one (Jordan et al, 2004). The ra-
tionale for using competing approaches is that the
techniques available vary considerably in accuracy,
processing time and whether they tend to be brittle
and produce no analysis vs. a partial one. There
is also a trade-off between these performance mea-
sures and the amount of domain specific setup re-
quired for each technique.
The first method, CARMEL, provides combined
syntactic and semantic analysis using the LCFlex
syntactic parser along with semantic constructor
functions (Rose?, 2000). Given a specification of
the desired representation language, it then maps the
analysis to this language. Then discourse level pro-
cessing attempts to resolve nominal and temporal
anaphora and ellipsis to produce the candidate FOPL
representation for a sentence (Jordan and VanLehn,
2002).
The second method, RAPPEL, uses MINIPAR (Lin
and Pantel, 2001) to parse the sentence. It then ex-
tracts syntactic dependency features from the parse
to use in mapping the sentence to its FOPL repre-
sentation (Jordan et al, 2004). Each predicate in
the KR language is assigned a predicate template
and a separate classifier is trained for each predicate
template. For example, there is a classifier that spe-
cializes in predicate instantiations (atoms) involving
the velocity predicate and another for instantiations
of the acceleration predicate. Classes for each tem-
plate represent combinations of constants that can
fill a predicate template?s slots to cover all possible
instantiations of that predicate. Each predicate tem-
plate classifier returns either a nil which indicates
that there is no instantiation involving that predicate
or a class label that corresponds to an instantiation
of that predicate. The candidate FOPL representa-
tion for a statement is the union of the output of all
the predicate template classifiers.
Finally, either the CARMEL or RAPPEL candidate
FOPL output is selected using the same heuristic as
for the BOW filtering. The surviving FOPL repre-
sentation is then assessed for correctness and com-
pleteness, as described next.
3.3 Analyzing correctness and completeness
As the final step in analyzing a student?s explana-
tion, an assessment of correctness and complete-
ness is performed by matching the FOPL represen-
tations of the student?s response to nodes of an aug-
mented assumption-based truth maintenance system
(ATMS) (Makatchev and VanLehn, 2005).
An ATMS for each physics problem is generated
off-line. The ATMS compactly represents the de-
ductive closure of a problem?s givens with respect
to a set of both good and buggy physics rules. That
is, each node in the ATMS corresponds to a propo-
sition that follows from a problem statement. Each
anticipated student misconception is treated as an as-
sumption (in the ATMS sense), and all conclusions
that follow from it are tagged with a label that in-
cludes it as well as any other assumptions needed
to derive that conclusion. This labeling allows the
ATMS to represent many interwoven deductive clo-
sures, each depending on different misconceptions,
without inconsistency. The labels allow recovery of
how a conclusion was reached. Thus a match with
a node containing a buggy assumption indicates the
student has a common error or misconception and
which error or misconception it is.
The completeness of an explanation is relative to
a two-column proof generated by a domain expert.
A human creates the proof that is used for check-
ing completeness since it is probably less work for
a person to write an acceptable proof than to find
one in the ATMS. Part of the proof for the prob-
lem in Figure 2 is shown in Figure 4 where facts
20
Step Fact Justification
1 The only force on the keys and the man is the force of
gravity
Forces are either contact forces or the gravitational force
... ... ...
12 The keys and the man have the same displacements at all
times
<Average velocity = displacement / elapsed time>, so if av-
erage velocity and time are the same, so is displacement.
13 The keys and the man have the same initial vertical po-
sition
given
14 The keys and the man have the same vertical position at
all times
<Displacement = difference in position>, so if the initial
positions of two objects are the same and their displacements
are the same, then so is their final position
15 The keys stay in front of the man?s face at all times
Figure 4: Part of the proof used in WHY2-ATLAS for the Elevator problem in Figure 2.
appear in the left column and justifications that are
physics principles appear in the right column. Justi-
fications are further categorized as vector equations
(e.g. <Average velocity = displacement / elapsed
time>, in step (12) of the proof), or qualitative rules
(e.g. ?so if average velocity and time are the same,
so is displacement? in step (12)). A two-column
proof is represented in the system as a directed graph
in which nodes are facts, vector equations, or qual-
itative rules that have been translated to the FOPL
representation language off-line. The edges of the
graph represent the inference relations between the
premise and conclusion of modus ponens.
Matches of an FOPL input against the ATMS and
the two-column proof (we collectively referred to
these earlier as the correct and buggy chains of rea-
soning) do not have to be exact. In addition, fur-
ther flexibility in the matching process is provided
by examining a neighborhood of radius N (in terms
of graph distance) from matched nodes in the ATMS
to determine whether it contains any of the nodes of
the two-column proof. This provides an estimate of
the proximity of a student?s utterance to the facts that
are of interest.
Although matching against the ATMS deductive
closure has been implemented, the current version of
the system does not yet fully utilize this capability.
Instead, the correctness and completeness of expla-
nations is evaluated by flexibly matching the FOPL
input against targeted relevant facts, principles and
misconceptions in the chains of reasoning, using a
radius of 0. This kind of matching is referred to as
direct matching in Section 4.2.
4 Evaluations
WHY2-ATLAS, as we?ve just described it, has been
fully implemented and was evaluated in the context
of testing the hypothesis that even when content is
equivalent, students who engage in more interac-
tive forms of instruction learn more. To test this
hypothesis we compared students who received hu-
man tutoring with students who read a short text.
WHY2-ATLAS and WHY2-AUTOTUTOR provided a
third type of condition that served as an interactive
form of instruction where the content is better con-
trolled than with human tutoring in that only some
subset of the content covered in the text condition
can be presented. In all conditions the students had
to solve four problems that require multi-sentential
explanations, one of which is shown in Figure 2.
In earlier evaluations, we found that overall stu-
dents learn and learn equally well in all three types
of conditions when the content is appropriate to the
level of the student (VanLehn et al, 2005), i.e. the
learning gains for human tutoring and the content
controlled text were the same. For the latest eval-
uation of WHY2-ATLAS, which excluded a human
tutoring condition, the learning gains on multiple-
choice and essay post-tests were the same as for
the other conditions. However, on fill-in-the-blank
post-tests, the WHY2-ATLAS students scored higher
than the text students (p=0.010; F(1,74)=6.33), and
this advantage persisted when the scores were ad-
justed by factoring out pre-test scores in an AN-
COVA (p=0.018; F(1,72)=5.83). Although this dif-
ference was in the expected direction, it was not ac-
companied by similar differences for the other two
post-tests.
These learning measures show that, relative to the
21
text, the two systems? overall performance at se-
lecting content is good. A system could perform
worse than the text condition if it too frequently
misinterprets multi-sentential answers and skips ma-
terial covered in the text that a student may need.
But since the dialogue strategies in the two systems
are different and selected relative to the understand-
ing techniques used, we next need to do a detailed
corpus analysis of the language data collected to
track successes and failures of understanding and di-
alogue strategy selection relative to knowledge com-
ponents in the post-test. Next we will describe some
component-level evaluations that focus on the parts
of the system we just described.
4.1 Evaluating the Benefit of Combining Single
Sentence Approaches
This first component-level evaluation focuses on the
benefits of heuristically choosing between the re-
sults of BOW, CARMEL and RAPPEL. This partic-
ular evaluation used a prior version of the system
which used BOW without tiers and hand-crafted
pattern-matching rules instead of the ATMS ap-
proach to assessment. But this evaluation still re-
flects the potential benefits of combining single sen-
tence approaches.
We used a test suite of 35 held-out multi-sentence
student explanations (235 sentences total) that are
annotated for the elicitation topics that are to be dis-
cussed with the student. We computed recall (R),
precision (P) and false alarm rate (FAR) against the
full corpus instead of averaging these measures for
each explanation. Since F-measure does not allow
error skewing as can be done with ROC areas (Flach,
2003) we instead look for cases of high recall with a
low false alarm rate.
The top part of Table 1 compares the baseline of
tutoring all possible topics and the individual perfor-
mances of the three approaches when each is used
in isolation from the others. We see that only the
statistical approach lowers the false alarm rate but
does so by sacrificing recall. The rest are not signif-
icantly different from tutoring all topics. The poor
performances of CARMEL and RAPPEL is not totally
unexpected because there are three potential failure
points for these classification approaches; the syn-
tactic analysis, the semantic mapping and the hand-
crafted pattern matching rules for assessing correct-
ness and completeness. While the syntactic anal-
ysis results for both approaches are good, the se-
mantic mapping and assessment of correctness and
completeness are still big challenges. The results of
BOW, while better than that of the other two ap-
proaches, are clearly not good enough.
Table 1: Performance of NL to FOPL for actions
taken in WHY2-ATLAS system.
Approach R P FAR
tutor all topics 1.0 .61 1.0
CARMEL 1.0 .61 1.0
BOW without tiers .60 .93 .07
RAPPEL .94 .59 1.0
satisficing heuristic .67 .80 .26
highest ranked heuristic .73 .76 .36
The bottom part of Table 1, shows the results of
combining the approaches and choosing one output
heuristically. The satisficing1 version of the heuris-
tic checks each output in the order 1) CARMEL 2)
BOW 3) RAPPEL, and stops with the first repre-
sentation that is acceptable according to the filtering
heuristic. This heuristic selection process modestly
improves recall but at the sacrifice of a higher false
alarm rate. The highest ranking heuristic scores each
output and selects the best one. It provides the most
balanced results of the combined or individual ap-
proaches. It provides the largest increase in recall
and the false alarm rate is still modest compared to
the baseline of tutoring all possible topics. It is clear,
that a combined approach has a positive impact.
4.2 Completeness and Correctness Evaluation
The component-level evaluation for completeness
and correctness was completed after the student
learning evaluation. It focuses on the performance
of just the direct matching procedure. Figure 5
shows the results of classifying 62 student utterances
for one physics problem with respect to 46 stored
statement representations using only direct match-
ing. To generate these results, the data is manually
divided into 7 groups based on the quality of the NL
1According to Newell & Simon (1972), satisficing is the
process by which an individual sets an acceptable level as the
final criterion and simply takes the first acceptable move instead
of seeking an optimal one.
22
1 2 3 4 5 6 7
0
10
20
30
40
50
60
70
80
90
100
Recall
Precision
Baseline1 recall
Baseline1 precision
Baseline2 recall
Baseline2 precision
Size of the dataset
Quality of representation
%
Figure 5: Average recall and precision of utterance
classification. The size of a group of entries is shown
relative to the size of the overall data set. Average
processing time is 0.011 seconds per entry on a 1.8
GHz Pentium 4 machine with 2Gb of RAM.
to FOPL conversion, such that group 7 consists only
of perfectly formalized entries, and for 1 ? n ? 6
group n includes entries of group n+1 and addition-
ally entries of somewhat lesser representation qual-
ity, so that group 1 includes all the entries of the
data set. The flexibility of the direct matching al-
gorithm even allows classification of utterances that
have mediocre representations, resulting in 70% av-
erage recall and 82.9% average precision for 56.5%
of all entries (group 4). However, large numbers
of inadequately represented utterances (38.7% of all
entries did not make it into group 3 of the data set)
result in 53.2% average recall and 59.7% average
precision for the whole data set (group 1). These
results are still significantly better compared to the
two baseline classifiers the best of which peaks at
22.2% average recall and precision. The first base-
line classifier always assigns the single label that is
dominant in the training set (average number of la-
bels per entry of the training set is 1.36). The sec-
ond baseline classifier independently and randomly
picks labels according to their distributions in the
training set. The most frequent label in the training
set corresponds to the answer to the problem. Since
in the test set the answer always appears as a sepa-
rate utterance (sentence), recall and precision rates
for the first baseline classifier are the same.
Although the current evaluation did not involve
matching against the ATMS, we did evaluate the
time required for such a match in order to make a
rough comparison with our earlier approach. Match-
ing a 12 atom input representation against a 128
node ATMS that covers 55% of relevant problem
facts takes around 30 seconds, which is a consid-
erable improvement over the 170 seconds required
for the on-the-fly analysis performed by the Tacitus-
lite+ abductive reasoner (Makatchev et al, 2004)?
the technique used in the previous version of WHY2-
ATLAS. The matching is done by a version of
a largest common subgraph-based graph-matching
algorithm (due to the need to account for cross-
referencing atoms via shared variables) proposed
in (Shearer et al, 2001), that has a time complex-
ity O(2nn3), where n is the size of an input graph.
The efficiency can be further improved by using an
approximation of the largest common subgraph in
order to evaluate the match.
5 Conclusion
In this paper, we discussed an application that in-
tegrates a hybrid of semantic parsers and a sym-
bolic reasoner with a statistical classifier to analyze
student explanations. We attempted to address the
problem that the leap made by statistical classifiers
from NL to a feasible classification is too big since
too many details of what was actually said by the
student are lost. On the other hand, we showed
that the hybrid semantic parsers allow for a slightly
smaller leap by mapping to a symbolic representa-
tion that is sufficient for domain reasoning. Using
deductive closure of problem givens and buggy as-
sumptions, the correctness and completeness ana-
lyzer allows us to reason about the correctness of
student statements that cannot be confidently clas-
sified statistically. Although formal and informal
language expressions have unique underlying se-
mantics, we attempt to paraphrase informal NL into
formal NL by using the forward-chaining rules in-
volved in creating the deductive closure for a prob-
lem from its givens. Our current symbolic represen-
tation is still too coarse to distinguish some fine nu-
ances allowed by the domain of mechanics. We con-
jecture that extending our knowledge representation
with more language-specific predicates would allow
us to represent more fine-grained differences in stu-
dent statements while still allowing feasible reason-
ing with the ATMS.
23
References
Michelene T. H. Chi, Stephanie A. Siler, Heisawn Jeong,
Takashi Yamauchi, and Robert G. Hausmann. 2001.
Learning from human tutoring. Cognitive Science,
25(4):471?533.
M. Evens and J. Michael. 2006. One-on-One Tutoring
by Humans and Computers. Lawrence Erlbaum Asso-
ciates, Inc.
P. Flach. 2003. The geometry of ROC space: Under-
standing machine learning metrics through ROC iso-
metrics. In Proceedings of 20th International Confer-
ence on Machine Learning.
Kenneth D. Forbus and Johan de Kleer. 1993. Build-
ing Problem Solvers. MIT Press, Cambridge, Mas-
sachusetts; London, England.
A.C. Graesser, S. Lu, G.T. Jackson, H. Mitchell, M. Ven-
tura, A. Olney, and M.M. Louwerse. 2004. Autotu-
tor: A tutor with dialogue in natural language. Behav-
ioral Research Methods, Instruments, and Computers,
36:180?193.
W. Lewis Johnson and Jeff Rickel. 1997. Steve: An
animated pedagogical agent for procedural training in
virtual environments. SIGART Bulletin, pages 16?21,
Fall.
Pamela Jordan and Kurt VanLehn. 2002. Discourse pro-
cessing for explanatory essays in tutorial applications.
In Proceedings of the 3rd SIGdial Workshop on Dis-
course and Dialogue, July.
Pamela W. Jordan, Maxim Makatchev, and Kurt Van-
Lehn. 2004. Combining competing language un-
derstanding approaches in an intelligent tutoring sys-
tem. In Proceedings of the Intelligent Tutoring Sys-
tems Conference.
D. Lin and P. Pantel. 2001. Discovery of inference rules
for question answering. Journal of Natural Language
Engineering, 7(4):343?360.
Maxim Makatchev and Kurt VanLehn. 2005. Analyzing
completeness and correctness of utterances using an
ATMS. In Proceedings of Int. Conference on Artificial
Intelligence in Education, AIED2005. IOS Press, July.
Maxim Makatchev, Pamela W. Jordan, and Kurt Van-
Lehn. 2004. Abductive theorem proving for analyzing
student explanations to guide feedback in intelligent
tutoring systems. Journal of Automated Reasoning,
Special issue on Automated Reasoning and Theorem
Proving in Education, 32:187?226.
Maxim Makatchev, Brian S. Hall, Pamela W. Jordan,
Umarani Pappuswamy, and Kurt VanLehn. 2005.
Mixed language processing in the Why2-Atlas tu-
toring system. In Proceedings of the Workshop on
Mixed Language Explanations in Learning Environ-
ments, AIED2005, pages 35?42, July.
Andrew McCallum and Kamal Nigam. 1998. A compar-
ison of event models for naive bayes text classification.
In Proceeding of AAAI/ICML-98 Workshop on Learn-
ing for Text Categorization. AAAI Press.
A. Newell and H.A. Simon. 1972. Human Problem Solv-
ing. Prentice-Hall, Englewood Cliffs, NJ.
Umarani Pappuswamy, Dumisizwe Bhembe, Pamela W.
Jordan, and Kurt VanLehn. 2005. A multi-tier NL-
knowledge clustering for classifying students? essays.
In Proceedings of 18th International FLAIRS Confer-
ence.
S. Peters, E. Bratt, B. Clark, H. Pon-Barry, and
K. Schultz. 2004. Intelligent systems for training
damage control assistants. In In the Proceedings of
I/ITSEC 2004, Orlando, Florida.
Rolf Ploetzner and Kurt VanLehn. 1997. The acquisi-
tion of qualitative physics knowledge during textbook-
based physics training. Cognition and Instruction,
15(2):169?205.
Carolyn Rose?, Pamela Jordan, Michael Ringenberg,
Stephanie Siler, Kurt VanLehn, and Anders Weinstein.
2001. Interactive conceptual tutoring in atlas-andes.
In Proceedings of AI in Education 2001 Conference.
Carolyn P. Rose?. 2000. A framework for robust seman-
tic interpretation. In Proceedings of the First Meeting
of the North American Chapter of the Association for
Computational Linguistics, pages 311?318.
Kim Shearer, Horst Bunke, and Svetha Venkatesh. 2001.
Video indexing and similarity retrieval by largest com-
mon subgraph detection using decision trees. Pattern
Recognition, 34(5):1075?1091.
Richmond H. Thomason, Jerry Hobbs, and Johanna D.
Moore. 1996. Communicative goals. In K. Jokinen,
M. Maybury, M. Zock, and I. Zukerman, editors, Pro-
ceedings of the ECAI 96 Workshop Gaps and Bridges:
New Directions in Planning and Natural Language
Generation.
K. VanLehn, A. Graesser, G. T. Jackson, P. Jordan, A. Ol-
ney, and C. P. Rose?. 2005. When is reading just as ef-
fective as one-on-one interactive human tutoring? In
Proceedings of CogSci2005.
Christof Walther. 1987. A many-sorted calculus based
on resolution and paramodulation. Morgan Kauf-
mann, Los Altos, California.
Claus Zinn, Johanna D. Moore, and Mark G. Core. 2002.
A 3-tier planning architecture for managing tutorial di-
alogue. In Proceedings of Intelligent Tutoring Systems
Conference (ITS 2002), pages 574?584.
24
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 286?293,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Perception of Personality and Naturalness through Dialogues by
Native Speakers of American English and Arabic
Maxim Makatchev
Robotics Institute
Carnegie Mellon University
Pittsburgh, PA, USA
mmakatch@cs.cmu.edu
Reid Simmons
Robotics Institute
Carnegie Mellon University
Pittsburgh, PA, USA
reids@cs.cmu.edu
Abstract
Linguistic markers of personality traits have
been studied extensively, but few cross-
cultural studies exist. In this paper, we eval-
uate how native speakers of American English
and Arabic perceive personality traits and nat-
uralness of English utterances that vary along
the dimensions of verbosity, hedging, lexical
and syntactic alignment, and formality. The
utterances are the turns within dialogue frag-
ments that are presented as text transcripts to
the workers of Amazon?s Mechanical Turk.
The results of the study suggest that all four di-
mensions can be used as linguistic markers of
all personality traits by both language commu-
nities. A further comparative analysis shows
cross-cultural differences for some combina-
tions of measures of personality traits and nat-
uralness, the dimensions of linguistic variabil-
ity and dialogue acts.
1 Introduction
English has been used as a lingua franca across the
world, but the usage differs. The variabilities in En-
glish introduced by dialects, cultures, and non-native
speakers result in different syntax and words ex-
pressing similar meanings and in different meanings
attributed to similar expressions. These differences
are a source of pragmatic failures (Thomas, 1983):
situations when listeners perceive meanings and af-
fective attitudes unintended by speakers. For exam-
ple, Thomas (1984) reports that usage of Illocution-
ary Force Indicating Devices (IFIDs, such as ?I warn
you?, (Searle, 1969)) in English by native speak-
ers of Russian causes the speakers to sometimes
appear ?inappropriately domineering in interactions
with English-speaking equals.? Dialogue systems,
just like humans, may misattribute attitudes and mis-
interpret intent of user?s utterances. Conversely, they
may also cause misattributions and misinterpreta-
tions on the user?s part. Hence, taking into account
the user?s dialect, culture, or native language may
help reduce pragmatic failures.
This kind of adaptation requires a mapping from
utterances, or more generally, their linguistic fea-
tures, to meanings and affective attributions for each
of the target language communities. In this paper
we present an exploratory study that evaluates such
a mapping from the linguistic features of verbosity,
hedging, alignment, and formality (as defined in
Section 3.1) to the perceived personality traits and
naturalness across the populations of native speak-
ers of American English and Arabic.
Estimating the relationship between linguistic
features and their perception across language com-
munities faces a number of methodological difficul-
ties. First, language communities shall be outlined,
in a way that will afford generalizing within their
populations. Defining language communities is a
hard problem, even if it is based on the ?mother
tongue? (McPherson et al, 2000). Next, linguistic
features that are potentially important for the adap-
tation must be selected. These are, for example,
the linguistic devices that contribute to realization of
rich points (Agar, 1994), i.e. the behaviors that sig-
nal differences between language communities. To
be useful for dialogue system research, the selected
linguistic features should be feasible to implement in
natural language generation and interpretation mod-
286
ules. Then, a corpus of stimuli that span the variabil-
ity of the linguistic features must be created. The
stimuli should reflect the context where the dialogue
system is intended to be used. For example, in case
of an information-giving dialogue system, the stim-
uli should include some question-answer adjacency
pairs (Schegloff and Sacks, 1973). Finally, scales
should be chosen to allow for scoring of the stimuli
with respect to the metrics of interest. These scales
should be robust to be applied within each of the lan-
guage communities.
In the remainder of this paper, we describe each of
these steps in the context of an exploratory study that
evaluates perception of English utterances by native
speakers of American English and Arabic. Our ap-
plication is an information-giving dialogue system
that is used by the robot receptionists (roboception-
ists) in Qatar and the United States (Makatchev et
al., 2009; Makatchev et al, 2010). In the next sec-
tion, we continue with an overview of the related
work. Section 3 introduces the experiment, includ-
ing the selection of stimuli, measures, design, and
describes the recruitment of participants via Ama-
zon?s Mechanical Turk (MTurk). We discuss results
in Section 4 and provide a conclusion in Section 5.
2 Related work
2.1 Cross-cultural variability in English
Language is tightly connected with culture (Agar,
1994). As a result, even native speakers of a lan-
guage use it differently across dialects (e.g. African
American Vernacular English and Standard Amer-
ican English), genders (see, for example, (Lakoff,
1973)) and social statuses (e.g. (Huspek, 1989)),
among other dimensions.
Speakers of English as a second language display
variabilities in language use that are consistent with
their native languages and backgrounds. For exam-
ple, Nelson et al (1996) reports that Syrian speakers
of Arabic tend to use different compliment response
strategies as compared with Americans. Aguilar
(1998) reviews types of pragmatic failures that are
influenced by native language and culture. In partic-
ular, he cites Davies (1987) on a pragmatic failure
due to non-equivalence of formulas: native speakers
of Moroccan Arabic use a spoken formulaic expres-
sion to wish a sick person quick recovery, whereas in
English the formula ?get well soon? is not generally
used in speech. Feghali (1997) reviews features of
Arabic communicative style, including indirectness
(concealment of wants, needs or goals (Gudykunst
and Ting-Toomey, 1988)), elaborateness (rich and
expressive language use, e.g. involving rhetorical
patterns of exaggeration and assertion (Patai, 1983))
and affectiveness (i.e. ?intuitive-affective style of
emotional appeal? (Glenn et al, 1977), related to
the patterns of organization and presentation of ar-
guments).
In this paper, we are concerned with English us-
age by native speakers of American English and na-
tive speakers of Arabic. We have used the features
of the Arabic communicative style outlined above
as a guide in selecting the dimensions of linguistic
variability that are presented in Section 3.1.
2.2 Measuring pragmatic variation
Perception of pragmatic variation of spoken lan-
guage and text has been shown to vary across
cultures along the dimensions of personality
(e.g. (Scherer, 1972)), emotion (e.g. (Burkhardt et
al., 2006)), deception (e.g. (Bond et al, 1990)),
among others. Within a culture, personality traits
such as extraversion, have been shown to have
consistent markers in language (see overview in
(Mairesse et al, 2007)). For example, Furnham
(1990) notes that in conversation, extraverts are less
formal and use more verbs, adverbs and pronouns.
However, the authors are not aware of any quantita-
tive studies that compare linguistic markers of per-
sonality across cultures. The present study aims to
help fill this gap.
A mapping between linguistic dimensions and
personality has been evaluated by grading es-
says and conversation extracts (Mairesse et al,
2007), and by grading utterances generated automat-
ically with a random setting of linguistic parame-
ters (Mairesse and Walker, 2008). In the exploratory
study presented in this paper, we ask our participants
to grade dialogue fragments that were manually cre-
ated to vary along each of the four linguistic dimen-
sions (see Section 3.1).
287
3 Experiment
In the review of related work, we presented some ev-
idence supporting the claim that linguistic markers
of personality may differ across cultures. In this sec-
tion, we describe a study that evaluates perception
of personality traits and naturalness of utterances by
native speakers of American English and Arabic.
3.1 Stimuli
The selection of stimuli attempts to satisfy three ob-
jectives. First, our application: our dialogue system
is intended to be used on a robot receptionist. Hence,
the stimuli are snippets of dialogue that include four
dialogue acts that are typical in this kind of em-
bodied information-giving dialogue (Makatchev et
al., 2009): a greeting, a question-answer pair, a dis-
agreement (with the user?s guess of an answer), and
an apology (for the robot not knowing the answer to
the question).
Second, we would like to vary our stimuli along
the linguistic dimensions that are potentially strong
indicators of personality traits. Extraverts, for exam-
ple, are reported to be more verbose (use more words
per utterances and more dialogue turns to achieve
the same communicative goal), less formal (Furn-
ham, 1990) (in choice of address terms, for exam-
ple), and less likely to hedge (use expressions such
as ?perhaps? and ?maybe?) (Nass et al, 1995). Lex-
ical and syntactic alignment, namely, the tendency
of a speaker to use the same lexical and syntactic
choices as their interlocutor, is considered, at least
in part, to reflect the speaker?s co-operation and will-
ingness to adopt the interlocutor?s perspective (Hay-
wood et al, 2003). There is some evidence that the
degree of alignment is associated with personality
traits of the speakers (Gill et al, 2004).
Third, we would like to select linguistic dimen-
sions that potentially expose cross-cultural differ-
ences in perception of personality and naturalness.
In particular, we are interested in the linguistic de-
vices that help realize rich points (the behaviors that
signal differences) between the native speakers of
American English and Arabic. We choose to real-
ize indirectness and elaborateness, characteristic of
Arabic spoken language (Feghali, 1997), by vary-
ing the dimensions of verbosity and hedging. High
power distance, or influence of relative social status
on the language (Feghali, 1997), can be realized by
the degrees of formality and alignment.
In summary, the stimuli are dialogue fragments
where utterances of one of the interlocutors vary
across (1) dialogue acts: a greeting, question-answer
pair, disagreement, apology, and (2) four linguistic
dimensions: verbosity, hedging, alignment, and for-
mality. Each of the linguistic dimensions is parame-
terized by 3 values of valence: negative, neutral and
positive. Within each of the four dialogue acts, stim-
uli corresponding to the neutral valences are repre-
sented by the same dialogue across all four linguistic
dimensions. The four linguistic dimensions are real-
ized as follows:
? Verbosity is realized as number of words within
each turn of the dialogue. In the case of the
greeting, positive verbosity is realized by in-
creased number of dialogue turns.1
? Positive valence of hedging implies more ten-
tative words (?maybe,? ?perhaps,? etc.) or ex-
pressions of uncertainty (?I think,? ?if I am
not mistaken?). Conversely, negative valence
of hedging is realized via words ?sure,? ?defi-
nitely,? etc.
? Positive valence of alignment corresponds to
preference towards the lexical and syntactic
choices of the interlocutor. Conversely, neg-
ative alignment implies less overlap in lexical
and syntactic choices between the interlocu-
tors.
? Our model of formality deploys the follow-
ing linguistic devices: in-group identity mark-
ers that target positive face (Brown and Levin-
son, 1987) such as address forms, jargon and
slang, and deference markers that target nega-
tive face, such as ?kindly?, terms of address,
hedges. These devices are used in Arabic po-
liteness phenomena (Farahat, 2009), and there
is an evidence of their pragmatic transfer from
Arabic to English (e.g. (Bardovi-Harlig et al,
2007) and (Ghawi, 1993)). The set of stimuli
that vary along the formality are presented in
Table 2.
Each dialogue fragment is presented as a text on
1The multi-stage greeting dialogue was developed via
ethnographic studies conducted at Alelo by Dr. Suzanne
Wertheim. Used with permission from Alelo, Inc.
288
an individual web page. On each page, the partici-
pant is asked to imagine that he or she is one of the
interlocutors and the other interlocutor is described
as ?a female receptionist in her early 20s and of
the same ethnic background? as that of the partici-
pant. The description of the occupation, age, gender
and ethnicity of the interlocutor whose utterances
the participant is asked to evaluate should provide
minimal context and help avoid variability due to the
implicit assumptions that subjects may make.
3.2 Measures
In order to avoid a possible interference of scales,
we ran two versions of the study in parallel. In
one version, participants were asked to evaluate the
receptionist?s utterances with respect to measures
of the Big Five personality traits (John and Srivas-
tava, 1999), namely the traits of extraversion, agree-
ableness, conscientiousness, emotional stability, and
openness, using the ten-item personality question-
naire (TIPI, see (Gosling et al, 2003)). In the other
version, participants were asked to evaluate the re-
ceptionist?s utterances with respect to their natu-
ralness on a 7-point Likert scale by answering the
question ?Do you agree that the receptionist?s utter-
ances were natural?? The variants of such a natural-
ness scale were used by Burkhardt et al (2006) and
Mairesse and Walker (2008).
3.3 Experimental design
The experiment used a crossed design with the fol-
lowing factors: dimensions of linguistic variability
(verbosity, hedging, alignment, or formality), va-
lence (negative, neutral, or positive), dialogue acts
(greeting, question-answer, disagreement, or apol-
ogy), native language (American English or Arabic)
and gender (male or female).
In an attempt to balance the workload of the par-
ticipants, depending on whether the participant was
assigned to the study that used personality or nat-
uralness scales, the experimental sessions consisted
of one or two linguistic variability conditions?12
or 24 dialogues respectively. Hence valence and dia-
logue act were within-subject factors, while linguis-
tic variability dimension were treated as an across-
subject factor, as well as native language and gen-
der. Within each session the items were presented in
Language Country N
Arabic Algeria 1
Bahrain 1
Egypt 56
Jordan 32
Morocco 45
Palestinian Territory 1
Qatar 1
Saudi Arabia 5
United Arab Emirates 13
Total 155
American English United States 166
Table 1: Distribution of study participants by country.
a random order to minimize possible carryover ef-
fects.
3.4 Participants
We used Amazon?s Mechanical Turk (MTurk) to re-
cruit native speakers of American English from the
United States and native speakers of Arabic from
any of the set of predominantly Arabic-speaking
countries (according to the IP address).
Upon completion of each task, participants re-
ceive monetary reward as a credit to their MTurk ac-
count. Special measures were taken to prevent mul-
tiple participation of one person in the same study
condition: the study website access would be re-
fused for such a user based on the IP address, and
MTurk logs were checked for repeated MTurk user
names to detect logging into the same MTurk ac-
count from different IP addresses. Hidden questions
were planted within the study to verify the fluency
in the participant?s reported native language.
The distribution of the participants across coun-
tries is shown in Table 1. We observed a regional
gender bias similar to the one reported by Ross et al
(2010): there were 100 male and 55 female partici-
pants in the Arabic condition, and 63 male and 103
female participants in the American English condi-
tion.
4 Results
We analyzed the data by fitting linear mixed-effects
(LME) models (Pinheiro and Bates, 2000) and per-
forming model selection using ANOVA. The com-
parison of models fitted to explain the personality
289
and naturalness scores (controlling for language and
gender), shows significant main effects of valence
and dialogue acts for all pairs of personality traits
(and naturalness) and linguistic features. The results
also show that for every personality trait (and nat-
uralness) there is a linguistic feature that results in
a significant three-way interaction between its va-
lence, the native language, and the dialogue act.
These results suggest that (a) for both language com-
munities, every linguistic dimension is associated
with every personality trait and naturalness, for at
least some of the dialogue acts, (b) there are differ-
ences in the perception of every personality trait and
naturalness between the two language communities.
To further explore the latter finding, we conducted
a post-hoc analysis consisting of paired t-tests that
were performed pairwise between the three values of
valence for each combination of language, linguis-
tic feature, and personality trait (and naturalness).
Note, that comparing raw scores between the lan-
guage conditions would be prone to find spurious
differences due to potential culture-specific tenden-
cies in scoring on the Likert scale: (a) perception
of magnitudes and (b) appropriateness of the inten-
sity of agreeing or disagreeing. Instead, we compare
the language conditions with respect to (a) the rela-
tive order of the three valences and (b) the binarized
scores, namely whether the score is above 4 or be-
low 4 (with scores that are not significantly different
from 4 excluded from comparison), where 4 is the
neutral point of the 7-point Likert scale.
The selected results of the post-hoc analysis are
shown in Figure 1. The most prominent cross-
cultural differences were found in the scoring of
naturalness across the valences of the formality di-
mension. Speakers of American English, unlike the
speakers of Arabic, find formal utterances unnatu-
ral in greetings, question-answer and disagreement
dialogue acts. Formal utterances tend to also be
perceived as indicators of openness (omitted from
the plot) and conscientiousness by Arabic speakers,
and not by American English speakers, in disagree-
ments and apologies respectively. Finally, hedging
in apologies is perceived as an indicator of agree-
ableness by American English speakers, but not by
speakers of Arabic.
Interestingly, no qualitative differences across
language conditions were found in the perception
of extraversion and stability. It is possible that this
cross-cultural consistency confirms the view of the
extraversion, in particular, as one of most consis-
tently identified dimensions (see, for example, (Gill
and Oberlander, 2002)). It could also be possi-
ble that our stimuli were unable to pinpoint the
extraversion-related rich points due to a choice of
the linguistic dimensions or particular wording cho-
sen. A larger variety of stimuli per condition, and an
ethnography to identify potentially culture-specific
linguistic devices of extraversion, could shed the
light on this issue.
5 Conclusion
We presented an exploratory study to evaluate a set
of linguistic markers of Big Five personality traits
and naturalness across two language communities:
native speakers of American English living in the
US, and native speakers of Arabic living in one
of the predominantly Arabic-speaking countries of
North Africa and Middle East. The results suggest
that the four dimensions of linguistic variability are
recognized as markers of all five personality traits by
both language communities. A comparison across
language communities uncovered some qualitative
differences in the perception of openness, conscien-
tiousness, agreeableness, and naturalness.
The results of the study can be used to adapt nat-
ural language generation and interpretation to native
speakers of American English or Arabic. This ex-
ploratory study also supports the feasibility of the
crowdsourcing approach to validate the linguistic
devices that realize rich points?behaviors that sig-
nal differences across languages and cultures.
Future work shall evaluate effects of regional di-
alects and address the issue of particular wording
choices by using multiple stimuli per condition.
Acknowledgments
This publication was made possible by the support
of an NPRP grant from the Qatar National Research
Fund. The statements made herein are solely the re-
sponsibility of the authors.
The authors are grateful to Ameer Ayman Abdul-
salam, Michael Agar, Hatem Alismail, Justine Cas-
sell, Majd Sakr, Nik Melchior, and Candace Sidner
for their comments on the study.
290
References
Michael Agar. 1994. Language shock: Understanding
the culture of conversation. William Morrow, New
York.
Maria Jose Coperias Aguilar. 1998. Intercultural
(mis)communication: The influence of L1 and C1
on L2 and C2. A tentative approach to textbooks.
Cuadernos de Filolog??a Inglesa, 7(1):99?113.
Kathleen Bardovi-Harlig, Marda Rose, and Edelmira L.
Nickels. 2007. The use of conventional expressions of
thanking, apologizing, and refusing. In Proceedings
of the 2007 Second Language Research Forum, pages
113?130.
Charles F. Bond, Adnan Omar, Adnan Mahmoud, and
Richard Neal Bonser. 1990. Lie detection across cul-
tures. Journal of Nonverbal Behavior, 14:189?204.
P. Brown and S. C. Levinson. 1987. Politeness: Some
universals in language usage. Cambridge University
Press, Cambridge.
F. Burkhardt, N. Audibert, L. Malatesta, O. Trk, Arslan,
L., and V Auberge. 2006. Emotional prosody?does
culture make a difference? In Proc. Speech Prosody.
Eirlys E. Davies. 1987. A contrastive approach to the
analysis of politeness formulas. Applied Linguistics,
8(1):75?88.
Said Hassan Farahat. 2009. Politeness phenomena in
Palestinian Arabic and Australian English: A cross-
cultural study of selected contemporary plays (PhD
thesis). Australian Catholic University, Australia.
Ellen Feghali. 1997. Arab cultural communication pat-
terns. International Journal of Intercultural Relations,
21(3):345?378.
A. Furnham. 1990. Language and personality. In
H. Giles and W. Robinson, editors, Handbook of Lan-
guage and Social Psychology, pages 73?95. Wiley.
Mohammed Ghawi. 1993. Pragmatic transfer in Arabic
learners of English. El Two Talk, 1(1):39?52.
A. Gill and J. Oberlander. 2002. aking care of the lin-
guistic features of extraversion. In Proceedings of the
24th Annual Conference of the Cognitive Science So-
ciety, pages 363?368.
A. Gill, A. Harrison, and J. Oberlander. 2004. Inter-
personality: Individual differences and interpersonal
priming. In Proceedings of the 26th Annual Confer-
ence of the Cognitive Science Society, pages 464?469.
E. S. Glenn, D. Witmeyer, and K. A. Stevenson. 1977.
Cultural styles of persuasion. International Journal of
Intercultural Relations, 1(3):52?66.
Samuel D. Gosling, Peter J. Rentfrow, and Jr. William
B. Swann. 2003. A very brief measure of the Big-Five
personality domains. Journal of Research in Person-
ality, 37:504?528.
W. B. Gudykunst and S. Ting-Toomey. 1988. Culture
and interpersonal communication. Sage, Newbury
Park, CA.
S. Haywood, M. Pickering, and H. Branigan. 2003. Co-
operation and co-ordination in the production of noun
phrases. In Proceedings of the 25th Annual Confer-
ence of the Cognitive Science Society, pages 533?538.
Michael Huspek. 1989. Linguistic variability and power:
An analysis of you know/I think variation in working-
class speech. Journal of Pragmatics, 13(5):661 ? 683.
Oliver P. John and Sanjay Srivastava. 1999. The Big Five
trait taxonomy: History, measurement, and theoreti-
cal perspectives. In Lawrence A. Pervin and Oliver P.
John, editors, Handbook of Personality: Theory and
Research, pages 102?138.
Robin Lakoff. 1973. Language and woman?s place. Lan-
guage in Society, 2(1):45?80.
Francois Mairesse and Marilyn Walker. 2008. Trainable
generation of big-five personality styles through data-
driven parameter estimation. In Proc. of 46th Annual
Meeting of the Association for Computational Linguis-
tics (ACL).
F. Mairesse, M. A. Walker, M. R. Mehl, and R. K. Moore.
2007. Using linguistic cues for the automatic recogni-
tion of personality in conversation and text. Journal of
Artificial Intelligence Research, 30:457?500.
Maxim Makatchev, Min Kyung Lee, and Reid Simmons.
2009. Relating initial turns of human-robot dialogues
to discourse. In Proc. of the Int. Conf. on Human-
Robot Interaction (HRI), pages 321?322. ACM.
Maxim Makatchev, Imran Aslam Fanaswala, Ameer Ay-
man Abdulsalam, Brett Browning, Wael Mahmoud
Gazzawi, Majd Sakr, and Reid Simmons. 2010. Dia-
logue patterns of an arabic robot receptionist. In Proc.
of the Int. Conf. on Human-Robot Interaction (HRI),
pages 167?168. ACM.
M. McPherson, L. Smith-Lovin, and J. M. Cook. 2000.
What is a language community? American Journal of
Political Science, 44(1):142?155.
Clifford Nass, Y. Moon, B. Fogg, and B. Reeves. 1995.
Can computer personalities be human personalities?
Journal of Human-Computer Studies, 43:223?239.
Gaylel Nelson, Mahmoud Al-Batal, and Erin Echols.
1996. Arabic and english compliment responses:
Potential for pragmatic failure. Applied Linguistics,
17(4):411?432.
R. Patai. 1983. The Arab mind. Charles Scribner?s Sons,
New York.
J. C. Pinheiro and D. M. Bates. 2000. Mixed-Effects
Models in S and S-PLUS. Springer.
Joel Ross, Lilly Irani, M. Six Silberman, Andrew Zal-
divar, and Bill Tomlinson. 2010. Who are the crowd-
workers?: shifting demographics in mechanical turk.
291
In Proceedings of the 28th of the international con-
ference extended abstracts on Human factors in com-
puting systems, CHI EA ?10, pages 2863?2872, New
York, NY, USA. ACM.
Emanuel A. Schegloff and Harvey Sacks. 1973. Opening
up closings. Semiotica, 8(4):289?327.
Klaus R. Scherer. 1972. Judging personality from voice:
A cross-cultural approach to an old issue in interper-
sonal perception. Journal of Personality, 40:191?210.
John Searle. 1969. Speech acts: An essay in the philoso-
phy of language. Cambridge University Press.
Jenny Thomas. 1983. Cross-cultural pragmatic failure.
Applied Linguistics, 4(2):91?112.
Jenny Thomas. 1984. Cross-cultural discourse as ?un-
equal encounter?: Towards a pragmatic analysis. Ap-
plied Linguistics, 5(3):226?235.
292
Greeting Question-Answer Disagreement Apology
A: Good morning.
B: What?s up? Need
anything?
A: Could you tell me where
the library is?
B: Just go to the end of the
hallway, you can?t miss it.
A: Could you tell me where the library is?
B: Go to the second floor.
A: I thought it was on the first floor.
B: No, honey, there is none on the first floor.
A: Could you tell me
where the library is?
B: Sorry about that, I have
no idea.
A: Good morning.
B: Good morning. How
may I help you?
A: Could you tell me where
the library is?
B: It?s at the end of the hall-
way on your left.
A: Could you tell me where the library is?
B: It?s on the second floor.
A: I thought it was on the first floor.
B: No, there is no library on the first floor.
A: Could you tell me
where the library is?
B: Sorry, I don?t know.
A: Good morning.
B: Good morning, sir
(madam). Would you
allow me to help you
with anything?
A: Could you tell me where
the library is?
B: Kindly follow this hallway
and you will encounter the
entrance on your left.
A: Could you tell me where the library is?
B: Yes, you may find the library on the second floor.
A: I thought it was on the first floor.
B: I am afraid that is not correct, there is no library on
the first floor.
A: Could you tell me
where the library is?
B: I have to apologize, but
I don?t know.
Table 2: Stimuli that correspond to negative (top row), neutral (middle row), and positive (bottom row) formality.
greeting qa disagree apology
American English, formality, naturalness
1
2
3
4
5
6
7 ** ** **
**
** ** ** **
greeting qa disagree apology
Arabic, formality, naturalness
1
2
3
4
5
6
7 ** *
**
**
**
greeting qa disagree apology
American English, formality, conscienciousness
1
2
3
4
5
6
7 ** *
** * *
greeting qa disagree apology
Arabic, formality, conscienciousness
1
2
3
4
5
6
7 *
*
**
*
greeting qa disagree apology
American English, hedging, agreeableness
1
2
3
4
5
6
7 * **
**
**
** **
**
**
greeting qa disagree apology
Arabic, hedging, agreeableness
1
2
3
4
5
6
7
**
**
Figure 1: A subset of data comparing scores on the Big Five personality traits and naturalness as given by native
speakers of American English (left half of the page) and Arabic (right half of the page). Blue, white, and pink bars
correspond to negative, neutral, and positive valences of the linguistic features respectively. Dialogue acts listed along
the horizontal axis are a greeting, question-answer pair, disagreement, and apology. Error bars the 95% confidence
intervals, brackets above the plots correspond to p-values of paired t-tests at significance levels of 0.05 (?) and 0.01
(??) after Bonferroni correction.
293
