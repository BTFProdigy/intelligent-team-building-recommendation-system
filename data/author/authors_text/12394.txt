Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 628?637,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
A Comparison of Windowless and Window-Based Computational
Association Measures as Predictors of Syntagmatic Human Associations
Justin Washtell
School of Computing
University of Leeds
washtell@comp.leeds.ac.uk
Katja Markert
School of Computing
University of Leeds
markert@comp.leeds.ac.uk
Abstract
Distance-based (windowless) word asso-
cation measures have only very recently
appeared in the NLP literature and their
performance compared to existing win-
dowed or frequency-based measures is
largely unknown. We conduct a large-
scale empirical comparison of a variety of
distance-based and frequency-based mea-
sures for the reproduction of syntagmatic
human assocation norms. Overall, our
results show an improvement in the pre-
dictive power of windowless over win-
dowed measures. This provides support
to some of the previously published the-
oretical advantages and makes window-
less approaches a promising avenue to
explore further. This study also serves
as a first comparison of windowed meth-
ods across numerous human association
datasets. During this comparison we
also introduce some novel variations of
window-based measures which perform as
well as or better in the human association
norm task than established measures.
1 Introduction
Automatic discovery of semantically associated
words has attracted a large amount of attention in
the last decades and a host of computational asso-
ciation measures have been proposed to deal with
this task (see Section 2). These measures tradi-
tionally rely on the co-ocurrence frequency of two
words in a corpus to estimate a relatedness score.
There has been a recent emergence of distance-
based language modelling techiques in NLP (Sav-
icki and Hlavacova, 2002; Terra and Clarke, 2004)
in which the number of tokens separating words
is the essential quantity. While some of this work
has considered distance-based alternatives to con-
ventional association measures (Hardcastle, 2005;
Washtell, 2009), there has been no principled em-
pirical evaluation of these measures as predictors
of human association. We remedy this by conduct-
ing a thorough comparison of a wide variety of
frequency-based and distance-based measures as
predictors of human association scores as elicited
in several different free word association tasks.
In this work we focus on first-order associ-
ation measures as predictors of syntagmatic as-
sociations. This is in contrast to second and
higher-order measures which are better predictors
of paradigmatic associations, or word similarity.
The distinction between syntagmatic and paradig-
matic relationship types is neither exact nor mu-
tually exclusive, and many paradigmatic relation-
ships can be observed syntagmatically in the text.
Roughly in keeping with (Rapp, 2002), we hereby
regard paradigmatic assocations as those based
largely on word similarity (i.e. including those
typically classed as synonyms, antonyms, hyper-
nyms, hyponyms etc), whereas syntagmatic as-
sociations are all those words which strongly in-
voke one another yet which cannot readily be
said to be similar. Typically these will have an
identifiable semantic or grammatical relationship
(meronym/holonym: stem ? flower, verb/object:
eat ? food etc), or may have harder-to-classify top-
ical or idiomatic relationships (family ? Christmas,
rock ? roll).
We will show in Section 3.2 that syntagmatic
relations by themselves constitute a substantial
25-40% of the strongest human responses to cue
words. Although the automatic detection of these
assocations in text has received less attention
than that of paradigmatic associations, they are
nonetheless important in applications such as the
resolution of bridging anaphora (Vieira and Poe-
sio, 2000).
1
Furthermore, first-order associations
1
where for example resolving my house ? the windows to
the windows of my house can be aided by the knowledge that
windows are often (syntagmatically) associated with houses.
628
are often the basis of higher-order vector word-
space models used for predicting paradigmatic
relationships: i.e. through the observation of
words which share similar sets of syntagmatic as-
sociations. Therefore improvements made at the
level we are concerned with may reasonably be
expected to carry through to applications which
hinge on the identification of paradigmatic rela-
tionships.
After a discussion of previous work in Sec-
tion 2, we formulate the exact association mea-
sures and parameter settings which we compare
in Section 3, where we also introduce the corpora
and human association sets used. Then, by using
evaluations similar to those described in (Baroni
et al, 2008) and by Rapp (2002), we show that
the best distance-based measures correlate better
overall with human association scores than do the
best window based configurations (see Section 4),
and that they also serve as better predictors of the
strongest human associations (see Section 5).
2 Related Work
Measures based on co-ocurrence frequency.
The standard way of estimating the syntagmatic
association of word pairs in a corpus is to ex-
amine the frequency of their co-occurence, and
then usually to compare this to some expected fre-
quency. There are a host of measures which ex-
ist for this purpose. After raw co-occurrence fre-
quency, the simplest and most prevalent in the
literature is Pointwise Mutual Information, fa-
mously used by Church (1989) (as the associa-
tion ratio). This is defined as the log of the ra-
tio of the observed co-occurrence frequency to the
frequency expected under independence. More
sophisticated and statistically-informed measures
include t-Score, z-Score, Chi-Squared and Log-
Likelihood (see Evert (2005) for a thorough re-
view).
All of these measures have in common that they
require co-occurrence frequency to be specified,
and therefore require some definition of a region
within which to count co-occurrences. This re-
gion might be the entirety of a document at one
extreme, or a bigram at the other. A versatile and
hugely popular generalised approach is therefore
to consider a ??window?? of w words, where w can
be varied to suit the application. Unsurprisingly,
it has been found that this is a parameter which
can have a significant impact upon performance
(Yarowsky and Florian, 2002; Lamjiri et al, 2004;
Wang, 2005). While choosing an optimum win-
dow size for an application is often subject to
trial and error, there are some generally recog-
nized trade-offs between small versus large win-
dows, such as the impact of data-sparseness, and
the nature of the associations retrieved (Church
and Hanks, 1989; Church and Hanks, 1991; Rapp,
2002)
Measures based on distance between words in
the text. The idea of using distance as an al-
ternative to frequency for modelling language has
been touched upon in recent literature (Savicki and
Hlavacova, 2002; Terra and Clarke, 2004; Hard-
castle, 2005). Washtell (2009) showed that it is
possible to build distance-based analogues of ex-
isting syntagmatic association measures, by using
the notions of mean and expected distance rather
than of frequency. These measures have certain
theoretical qualities - notably scale-independence
and relative resilience to data-sparseness - which
might be expected to provide gains in tasks such
as the reproduction of human association norms
from corpus data. The specific measure introduced
by Washtell, called Co-Dispersion, is based upon
an established biogeographic dispersion measure
(Clark and Evans, 1954). We provide a thor-
ough empirical investigation of Co-Dispersion and
some of its derivatives herein.
Measures based on syntactic relations. Sev-
eral researchers (Lin, 1998; Curran, 2003; Pado
and Lapata, 2007) have used word space models
based on grammatical relationships for detecting
and quantifying (mostly paradigmatic) word asso-
ciations. In this paper, we will not use syntactic
relation measures for two main reasons. Firstly
these depend on the availability of parsers, which
is not a given for many languages. Secondly, this
may not be the most pertinent approach for pre-
dicting human free associations, in which certain
observed relationsips can be hard to express in
terms of syntactic relationships.
3 Methodology
Similar to (Rapp, 2002; Baroni et al, 2008, among
others), we use comparison to human assocation
datasets as a test bed for the scores produced by
computational association measures. An alterna-
tive might be to validate scores against those de-
rived from a structured resource such as WordNet.
629
Table 1: Human association datasets
Name Origin Cues Respondents
Kent Kent & Rosanoff (1910) 100 ? 1000
Minnesota Russell & Jenkins (1954) 100 ? 1000
EAT Kiss et al(1973) 8400 100
Florida Nelson et al(1980) 5019 ? 140
However, relatedness measures for WordNet are
many and varied and are themselves the subject of
evaluation (Pedersen et al, 2004). Although hu-
man association datasets have their own peculiari-
ties, they do at least provide some kind of definite
Gold Standard. Yet another alternative might be to
incorporate our computational association scores
into an application (such as anaphora resolution),
and measure the performance of that, but noise
from other submodules would complicate evalu-
ation. We leave such extensions to possible future
work.
We use evaluations similar to those used before
(Rapp, 2002; Pado and Lapata, 2007; Baroni et
al., 2008, among others). However, whereas most
existing studies use only one dataset, or hand-
selected parts thereof, we aim to evaluate mea-
sures across four different human datasets. In this
way we hope to get as unbiased a picture as possi-
ble.
3.1 Association data
The datasets used are listed in Table 1. While
the exact experimental conditions may differ, the
datasets used were all elicited using the same ba-
sic methodology: by presenting individual words
(cues) to a number of healthy human subjects and
asking in each case for the word that is most imme-
diately or strongly evoked. An association score
can then be derived for each cue/response pair in a
dataset by dividing the number of participants pro-
viding a given response by the number who were
presented with the cue word. In Table 1, respon-
dents refers to the number of people from whom
a response was solicited for each cue word in a
study (this is not to be confused with the number
of unique responses).
Of these four datasets, one (Kent & Rosanoff)
appears not to have been previously used in any
peer-reviewed study of corpus-derived lexical as-
sociation. It is worth noting that some of these
datasets are quite dated, which might affect corre-
lations with corpus-derived scores, as culture and
contemporary language have a fundamental im-
pact upon the associations humans form (White
and Abrams, 2004).
3.2 Frequency of Syntagmatic Associations
To verify that strong human associations do in-
clude a large number of syntagmatic associations,
we manually annotated all pairs consisting of
a cue and its strongest human response in the
Minnesota and Kent datasets as expressing ei-
ther a syntagmatic or a paradigmatic relationship.
The overall set to be annotated consisted of 200
pairs.
Annotators were given short (half-page) guide-
lines on syntagmatic and paradigmatic assoca-
tions, stating that very similar items (including
hyponyms/hypernyms) as well as antonyms were
to be judged as paradigmatic whereas words that
do not fulfil this criterion are to be judged as
syntagmatic. The two annotators were the au-
thors of this paper (one native and one near-native
speaker). After independent annotation, agree-
ment was measured at a percentage agreement of
91/93% and a kappa of 0.80/0.82 for Minnesota
and Kent, respectively. Therefore, the distinction
can be made with high reliability.
Overall, 27/39% of the human responses
were syntagmatic in the Kent/Minnesota datasets,
showing that syntagmatic relations make up a
large proportion of even the strongest human as-
sociations.
3.3 Corpora
We use two randomized subsets of the British Na-
tional Corpus (BNC), a representative 100 million
word corpus of British English (Burnard, 1995):
one 10 million word sample, and a 1 million word
sample. A vocabulary of approximately 33,000
word types was used. The selected words included
approximately 24,000 word types comprising all
cue and target words from the multiple sets of hu-
man association norms to be used in this study. To
these were added a top-cut of the most frequent
words in the BNC, until the total of 33,000 word
types was reached. The resultant set included ap-
630
proximately the 24,000 most common word types
in the BNC, with the remaining 9000 words types
therefore comprising relatively uncommon words
taken from the human associative responses.
The words included in the vocabulary ac-
counted for over 94.5% of tokens in the corpus.
Although statistics for the remaining word types
in the BNC were not gathered, their correspond-
ing tokens were left in the corpus so that these
could be properly accounted for when calculating
distances and window spans.
In order to maximize matching between word
types in the corpus and association norms, all
words in both were normalized by converting to
lower-case and removing hyphens and periods.
Words consisting entirely of numerals, or numer-
als and punctuation, and all ?phrasal? associa-
tive responses (those containing spaces) were dis-
carded. The 33,000 word count was satisfied after
making these normalizations.
In order to maximize the variety of the language
in the samples, the subsets were built from ap-
proximately the first 2000 words only of each ran-
domly selected document from the BNC (a similar
strategy to that used in constructing the 1 million
word Brown Corpus). Both a 10 million word and
a 1 million word sample were constructed in this
fashion, allowing us to also examine the effects of
varying corpus size and content.
3.4 Association measures used
3.4.1 Frequency-based measures
In the following, x is the cue word and y a (possi-
ble) response word. Therefore p(x) is the proba-
bility of observing x, and p(x?) refers to the prob-
ability of not observing x.
Pointwise Mutual Information (hereonin PMI)
was introduced in Section 2. For ranking word
pairs, we can neglect the usual logarithm.
PMI =
p(x, y)
p(x)p(y)
PMI is infamous for its tendency to attribute very
high association scores to pairs involving low fre-
quency words, as the denominator is small in such
cases, even though the evidence for association in
such cases is also small. This can result in some
unlikely associations. There exist a number of al-
ternative measures which factor in the amount of
evidence to give an estimate of the significance of
association. One popular and statistically appeal-
ing such measure is Log-Likelihood (LL) (Dun-
ning, 1993). LL works on a similar principle to
PMI but considers the ratio of the observed to ex-
pected co-occurrence frequencies for all contin-
gencies (i.e. including those where the words do
not co-occur). LL, as it most frequently appears in
the literature, is not actually a measure of positive
association: it also responds to significant negative
association. Therefore LL is arguably not suited to
the task in hand. Krenn & Evert (2001) experiment
with one-tailed variants of LL and Chi-Squared
measures, although they do not define these vari-
ants. Here, we construct a one-tailed variant of LL
by simply reversing the signs of the terms which
respond to negative association.
LL
1tail
= p(x, y) log
p(x, y)
p(x)p(y)
? p(x, y?) log
p(x, y?)
p(x)p(y?)
? p(x?, y) log
p(x?, y)
p(x?)p(y)
+ p(x?, y?) log
p(x?, y?)
p(x?)p(y?)
LL does not have a clear analogue amongst
the distance-based measures (introduced in Sec-
tion 3.4.2), whereas PMI for instance does. We
therefore construct variants of PMI and other mea-
sures which take the amount of evidence into ac-
count in a way which can be directly reproduced
in the distance domain. For this we borrow from
Sackett (2001) who asserts that, all other things
being equal, statistical significance is proportional
to the square root of the sample size. There are a
number of ways one might quantify sample size.
We take a consistent approach across the various
distance-based and frequency-based measures: we
assume sample size to be equivalent to the lesser of
the frequencies of the two words as this represents
the total number of words available for pairing,
with fewer observed pairs therefore being consid-
ered to constitute negative evidence.
PMI
sig
=
?
min(p(x), p(y))
p(x, y)
p(x)p(y)
All of the above measures are symmetric. Human
associative responses however are not (Michel-
bacher et al, 2007): a person?s tendency to give
the response because to the cue why does not nec-
essarily reflect their tendency to give the response
why to the cue because.
2
A simple asymmetric as-
sociation measure is conditional probability (CP)
2
This notion of assymmetry is not to be confused with
631
- the probability of observing the response, given
that the cue has already occurred.
CP = p(y|x) =
p(x, y)
p(x)
CP suffers from the fact that it does not account
at all for the general frequency of the response
word. It therefore tends to favour very frequent
words, such as function words. An obvious so-
lution would be to divide CP by the frequency of
the response word, however this merely results in
PMI which is symmetric. By multiplying CP with
PMI (and taking the root, to simplify) we obtain a
measure which is asymmetric yet does not overtly
favour frequent response words.
3
We refer to this
herein as Semi-Conditional Information (SCI).
SCI =
p(x, y)
p(x)
?
p(y)
We also explore variants of both CP and SCI with
the additional significance correction presented for
PMI
sig
. These can be easily inferred from the for-
mulae above.
3.4.2 Distance-based Measures
Co-Dispersion (herein CD), introduced by
Washtell (2009), is defined as the ratio of the
mean observed distance to the expected distance,
where the expected distance is derived from
the frequency of the more frequent word type.
Distance refers to the number of tokens separat-
ing an occurrence of one word and the nearest
occurrence of another word. Pairs spanning an
intervening occurrence of either word type or a
document boundary are not considered. Note that
here we specify only the generalised mean M , as
we wish to keep the specific choice of mean as a
parameter to be explored,
CD =
1/max(p(x), p(y))
M(dist
xy1
. . . dist
xyn
)
that of direction in the text. While the two may correlate, one
can find ample counter-examples: jerky triggers beef more
strongly than beef triggers jerky.
3
Note that Wettler & Rapp (1993) introduced a more gen-
eral asymmetric measure for predicting human associations,
by employing an exponent parameter to p(y). Our formuli-
sation is equivalent to their measure with an exponent of 0.5,
whereas they found an exponent of 0.66 to be most effective
in their empirical study. Exponents of 0 and 1 result in CP
and PMI respectively.
where dist
xyi
is i
th
observed distance between
some occurrence of word type x and its nearest
preceding or following occurrence of word type
y, and n is the total number of such distances ob-
served (being at most equal to the frequency of the
rarer word).
In cases where many occurrences of the less
frequent word were not able to be paired, raw
CD gives midleading results. This is because un-
pairable words themselves provide useful nega-
tive evidence which CD ignores. A more ap-
propriate measure can be formed in which the
mean distance is calculated using the frequency of
the less frequent word, regardless of whether this
many distances were actually observed. This gives
us Neutrally-Weighted Co-Dispersion (NWCD).
Note that for convenience, we keep the standard
definition of the mean and introduce a correction
factor instead.
NWCD =
n
min(p(x), p(y))
1/max(p(x), p(y))
M(dist
xy1
. . . dist
xyn
)
An asymmetric association measure can be
formed in a similar manner. Instead of calculat-
ing the mean using the frequency of the less fre-
quent word as described above, we explicitly use
the frequency of the cue word (which in some
cases may actually exceed the number of dis-
tances observed). This gives us Cue-Weighted Co-
Dispersion (CWCD).
CWCD =
n
p(x)
1/max(p(x), p(y))
M(dist
xy1
. . . dist
xyn
)
(1)
In addition to these measures, we also ex-
plore significance-corrected forms NWCD
sig
and
CWCD
sig
, by introducing the same sample size
term employed by PMI
sig
, CP
sig
and SCI
sig
.
Again, these can readily be inferred from the ex-
isting formulae in the above two sections.
3.5 Co-occurrence Parameters
For frequency-based co-occurrence statistics, the
principle parameter is the window size. We will
use five window sizes separated by a constant scal-
ing factor, chosen so as to span those most com-
monly encountered in the literature, with some ex-
tension towards the upper end. We use w to rep-
resent this parameter, with w = 2 implying a win-
dow size of +/-2. The parameter values explored
632
are w = 2, w = 10, w = 50, w = 250 and
w = 1250. We examine such large window sizes
so as to give a fairer comparison with the distance
approach which is not bounded by a window, and
in acknowledgement of the fact that the entire doc-
ument as context has been used with some success
in other application areas (most notably informa-
tion retrieval).
For distance-based statistics, the principle pa-
rameter is the function via which the various ob-
served distances between tokens are reduced to a
single mean value. In this investigation we will ex-
plore five means. These are the power means with
exponents (which herein we refer to as m) rang-
ing from -2 to +2. These give us the quadratic
mean or RMS (m = 2), the arithmetic mean
(m = 1), the geometric mean (m = 0), the har-
monic mean (m = ?1), and the inverse quadratic
mean (m = ?2).
4 Task I: Correlations on word pairs
One of the ESSLLI Workshop shared tasks (Ba-
roni et al, 2008) required the evaluation of cor-
relation between a small, manually selected sub-
set of human cue-response scores from the EAT
dataset and automatic scores for the same word
pairs. Here, tather than focusing on word pairs
which meet certain grammatical and frequency
criteria we test on all pairs. For the EAT and
Florida datasets, this amounts to many tens of
thousands of cue-response pairs. Although this
makes the task of correlation harder, it means we
can attribute a great deal of statistical significance
to the results and make our observations as general
as possible.
4.1 Evaluation Measures, Upper Bounds and
Baselines
For evaluating agreement between corpus-derived
associations and human associations, we use
Spearman?s Rank correlation. This is appropri-
ate because we are primarily interested in the rel-
ative ranking of word pair associations (in order
to predict particularly strong responses, for exam-
ple). Although some studies have used Pearson?s
correlation, the various association measures ex-
plored here are not linear within each another and
it would be inappropriate to evaluate them under
the assumption of a linear relationship with the hu-
man norms.
Two of the human datasets, Kent and
Minnesota, though collected independently, are
based on the same set of 100 cue words established
by Kent (1910). Therefore by performing a rank
correlation of these two datasets with one another,
(each of which was produced by pooling the re-
sponses of some 1000 people) we can get a useful
upper-bound for correlations: if a computer-based
system were to exceed this upper-bound in corre-
lations with either dataset, then we would need to
suspect it of over-fitting.
As a baseline, we use the corpus frequency of
the response word. The simple assumption is that
the more frequent a word is, the more likely it is
to appear as a human response independent of the
cue given. This is also the simplest formulation
which does not assign equal scores to the various
possible responses, and which is therefore capable
of producing a rank-list of predictions.
4.2 Task I Results
Figure 1 shows the Spearman?s rank correlation
co-efficients across all paramaterisations of all as-
sociation measures (frequency-based on the left,
and distance-based on the right), with each human
dataset, for the 10 million word corpus. Embold-
ened are the best performing windowed and win-
dowless configurations for each dataset. The dif-
ference of these figures over the baseline is highly
significant (p < 0.0001 in most cases). The panels
to the right show summary statistics for these fig-
ures, and for the 1 million word corpus (for which
full figures are not included owing to space limita-
tions). These statistics include the performance of
the baseline, where relevant the estimated upper-
bound (see Section 4.1), and the difference in per-
formance of the distance-based method over the
window-based. The accuracy and error figures are
based on the co-efficients of determination (r
2
)
and are expressed both as a relative improvement
in accuracy (how much closer (r
2
) is to 1 under the
distance-based approach) and reduction in error
(how much further r
2
is from zero). Also the sig-
nificance of the difference in the r values is given.
4.3 Discussion
The two-way Spearman?s rank correlations be-
tween the Kent and Minesota datasets sug-
gested an upper bound of r = 0.4. In theory,
a large proportion of this agreement is accounted
for by paradigmatic associations which we are
not likely to fully reproduce with these first-order
measures. By this standard, the general levels of
633
Figure 1: Correlations for window-based and windowless measures on a 10 million word corpus
correlation seen here (for these datasets r = 0.235
and r = 0.239 respectively) seem very reasonable.
What is immediately clear from Figure 1 is that,
for the range of parameters tested here, we see
a relatively small but statistically significant im-
provement across four of the five datasets when
adopting the distance-based approach.
The correlations are unsurprisingly lower across
the board for the much smaller 1 million word cor-
pus. Here, the best distance-based measure statis-
tically significantly outperforms the best window-
based one (with a significance level of p <
0.0001) on one out of four datasets, while the dif-
ferences are not great enough to be considered sta-
tistically significant on the other three datasets.
There is therefore some evidence that the bene-
fits observed with the larger corpus hold in the
presence of limited data, which is in support of
the general theory that distance-based methods
capture more information from the corpus at the
co-occurrence level (Washtell, 2009). It remains
clear, however, that no method is presently a sub-
stitute for using a larger corpus.
In terms of optimum configurations, we find
that for the frequency-based approach with the
larger corpus, a window size of around +/-10 to
+/-50 words more or less consistently produces the
best results, irrespective of association the mea-
sure. Interestingly on the small corpus the ten-
dency appears to be towards a somewhat larger
window size than with the larger corpus. This
may be related to the larger windows? increased
resilience to data-sparseness. Somewhat surpris-
ingly, we also see that our assymmetric associa-
tion measures SCI and SCI
sig
perform the best
overall amongst the windowed measures, largely
irrespective of the window or corpus, size.
In the large corpus, the best distance-based
measure is the asymmetric CWCD, with the sig-
nificance corrected measure CWCD
sig
showing
greater strength in the small corpus: perhaps,
again, for its improved reliability in the presence
of very low-frequency data. The optimum mean
for the distance-based parameterisations is some-
where around m = ?1 (the harmonic) to m = 0
(the geometric). We find this unsurprising as the
typical distribution of inter-word distances in a
corpus is heavily skewed towards the smaller dis-
tances - indeed even a random corpus exhibits this
characteristic with the distances following a geo-
metric distribution.
5 Task II: Agreement with strongest
human associations
The correlation evalation presented considers all
word pairs present in the human datasets. How-
ever, human association norms tend to contain
a very long tail of hapax legomena - responses
which were given by only one individual. Such
responses are extremely difficult for corpus-based
634
association measures to predict, and given that
there is so little consensus amongst human respon-
dents over these items, it is probably not partic-
ularly useful to do so. Rather, it might be most
useful to predict common or majority human re-
sponses.
5.1 Evaluation measure and Upper Bound
For the strongest human response to each cue
in the human datasets, its rank was calculated
amongst all 33, 000 possible responses to that
cue, according to each association measure and
parameterisation. Where there were tied scores
for various responses, a median rank was assigned.
As a rough upper bound, we would be impressed
by a computer system which was able to predict
the most popular human response as often as a
randomly selected individual in the human exper-
iments happened to chose the most popular re-
sponse.
5.2 Task II Results
Figure 2 illustrates the range of computational as-
sociation scores attributed to only the strongest
human responses. The position of the strongest
human response to each cue word, within the
computationally-ranked lists of all possible re-
sponses, is plotted on the y-axis. For each asso-
ciation measure the points are ordered from best
to worst along the x-axis. In the ideal case there-
fore, the most popular human response for ev-
ery cue word would appear at rank 1 amongst the
computer-generated responses, resulting in a hori-
zonal line at y=1. Generally speaking therefore,
the smaller the area above a line the better the per-
formance of a measure.
Three summary statistics can be derived from
Figure 2:
1) The number of most popular human re-
sponses that are correctly predicted by a measure
is indicated by the x-position at which its line de-
parts from y=1. This can be seen to be around 11%
for CWCD
sig
and is zero for the two best PMI
parameterizations, with other illustrated measures
performing intermediately.
2) The width of the flat horizontal tails at the op-
posite corner of the figure indicate the proportion
of the cue words for which a measure was unable
to differentiate the strongest human response from
the large contingent of zero association scores re-
sulting from unobservable co-occurrences. This
tail is non-existent for CWCD
sig
, but afflicts some
25% and 62% of cue words under the two best
PMI parameterizations, again with other illus-
trated measures performing intermediately.
3) The median rank of the most popular human
response for each measure can be read of on the
y-axis at the horizontal mid-point (indicated by a
feint vertical line).
Figure 2: Agreement of computational measures
with strongest human responses
Figure 3: Relative agreement of computational
measures with strongest human responses
The results shown are for the Kent dataset, and
are highly typical. Included in the figure are
the three frequency-based configurations with the
highest median rank: SCI
sig
at window sizes w =
10 and w = 50, and standard LL at w = 10. Three
635
other frequency-based configurations are included
for contrast. Also included is the single window-
less configuration with the highest median rank -
in this case CWCD
sig
using the harmonic mean.
Several other windowless configurations (notably
CWCD and the nearby means) and had very simi-
lar profiles.
Figure 3 shows the magnitude of the difference
in the ranking of each of the same 100 strong hu-
man cue/response pairs, between the best window-
less versus best windowed method. Points above
the axis represent those cue/response pairs which
the windowless method ranked more highly, and
vice-versa. The points have been ordered on the
x-axis according the the cue word frequency.
5.3 Discussion
Noteworthy, studying Figure 2, is the great sen-
sitivity of the frequency-based measures to the
window size parameter. There exists a cut-off
point, linked to window size, beyond which the
frequency-based measures are unable to make
any differentiation between the desired human re-
sponse and a large portion of the 33, 000 candidate
responses. This is almost certainly due to a lack
of evidence in the presence of very low frequency
words. Log-Likelihood performs somewhat better
in this respect, as it takes negative information into
account.
Although the distance-based approach follows
the same general trend as the other measures, it
is nonetheless able to generate a distinct non-zero
association score for every strong human response
and overall it aptly ranks them more highly. A
larger number these responses are actually ranked
first (i.e. successfully predicted) by the distance-
based approach. In fact this number is compara-
ble to, and sometimes exceeds, the upper-bound
of 10% implied by taking the average proportion
of human respondents who give the most popular
response to a given cue.
Whilst Figure 2 showed that overall the win-
dowless method fairs better, on a per-cue basis
(Figure 3) things are a little more interesting: For
a little over a third of cue-words the windowed
method actually appears to perform somewhat bet-
ter. For the majority however, the windowless ap-
proach performs considerably better (note that the
y-axis scale is logarithmic). It can also be seen
that the difference between the methods is most
pronounced for low frequency cue words, with re-
sponses to some cues exhibiting a relative ranking
of around one-hundred times lower for the win-
dowed method. This further supports the theory
that the windowless methods are better able to ex-
ploit sparse data.
6 Conclusions and Future work
This paper presented the first empirical compar-
ison of window-based and the relatively recently
introduced windowless association measures, us-
ing their ability to reproduce human association
scores as a testbed. We show that the best win-
dowless measures are always at least as good as
the best window-based measures, both when it
comes to overall correlation with human associ-
ation scores and predicting the strongest human
response. In addition, for several human associ-
ation sets, they perform significantly better. Al-
though not all parameter settings and corpus sizes
could be explored, we conclude that it is worth-
while investigating windowless association mea-
sures further. As a side-benefit, we have also in-
troduced new variants of existing frequency-based
association measures and shown them to perform
as well as or better than their existing counterparts.
Although these measures were semi-principled in
their construction, a deeper understanding of why
they work so well is needed. This may in turn lead
to the construction of superior windowless mea-
sures.
In our own future work, we are especially in-
terested in using higher-order windowless associa-
tion measures for retrieving paradigmatic relations
as well as exploring their use in various NLP ap-
plications.
7 Acknowledgements
We would like to extend sincere thanks to Rein-
hard Rapp for providing us with the Minnesota
dataset in digital form, and additional thanks to
Eric Atwell for his support.
References
M. Baroni, S. Evert, and A. Lenci, editors. 2008. Esslli
Workshop on Distributional Lexical Semantics.
L. Burnard, 1995. Users? Reference Guide, British Na-
tional Corpus. British National Corpus Consortium,
Oxford, England.
K. Church and P. Hanks. 1989. Word association
norms, mutual information, and lexicography. In
Proc. of ACL-89, pages 76?83.
636
K. Church and P. Hanks. 1991. Word association
norms, mutual information and lexicography. Com-
putational Linguistics, 16(1):22?29.
P. Clark and F.C. Evans. 1954. Distance to near-
est neighbor as a measure of spatial relationships in
populations. Ecology, 35:445?453.
J. Curran. 2003. From distributional to semantic simi-
larity. Ph.D. thesis, University of Edinburgh.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19:61?74.
S. Evert. 2005. The Statistics of Word Cooccurrences:
Word Pairs and Collocations. Ph.D. thesis, Insti-
tut fr maschinelle Sprachverarbeitung, University of
Stuttgart.
D. Hardcastle. 2005. Using the distributional hypothe-
sis to derive coocurrence scores from the British Na-
tional Corpus. In Proc. of Corpus Linguistics.
J. Jenkins. 1970. The 1952 Minnesota word associa-
tion norms. In L. Postman and G. Keppel, editors,
Norms of word associations, pages 1?38. Academic
press.
G. Kent and A. Rosanoff. 1910. A study of association
in insanity. Amer. J. of Insanity, pages 317?390.
G. Kiss, C. Armstrong, R. Milroy, and J. Piper. 1973.
An associative thesaurus of English and its computer
analysis. In A. Aitken, R. Bailey, and N. Hamilton-
Smith, editors, The Computer and Literary Studies.
Edinburgh University Press.
B. Krenn and S. Evert. 2001. Cam we do better than
frequency? a case study on extracting pp-verb collo-
cations. In Proc. of the ACL Workshop on Colloca-
tions.
A. Lamjiri, O. El Demerdash, and L. Kosseim. 2004.
Simple features for statistical word sense disam-
biguation. In Proc. of SENSEVAL-2004.
D. Lin. 1998. Automatic retrieval and clustering of
similar words. In Proc. of COLING-ACL-98.
Lukas Michelbacher, Stefan Evert, and Hinrich
Sch?utze. 2007. Asymmetric association measures.
In Proc. of RANLP-2007.
D. Nelson, C. McEvoy, J. Walling, and J. Wheeler.
1980. The University of South Florida homograph
norms. Behaviour Research Methods and Instru-
mentation, 12:16?37.
S. Pado and M. Lapata. 2007. Dependency-based con-
struction of semantic space models. Computational
Linguistics, 33(2):161?199.
T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004.
Wordnet::similarity - measuring the relatedness of
concepts. In Proc. of the 21
st
National Conference
on Artificial Intelligence; 2004.
R. Rapp. 2002. The computation of word associa-
tions: comparing syntagmatic and paradigmatic ap-
proaches. In Proc of COLING 2002.
D.L. Sackett. 2001. Why randomized controlled tri-
als fail but needn?t: 2. failure to employ physiolog-
ical statistics, or the only formula a clinician-trialist
is every likely to need (or understand). Canadian
Medical Association Journal, 165(9):1226?1237.
P. Savicki and J. Hlavacova. 2002. Measures of word
commonness. Journal of Quantitative Linguistcs,
9(3):215?231.
E. Terra and C. Clarke. 2004. Fast computation of
lexical affinity models. In Proc of COLING 2004.
Renata Vieira and Massimo Poesio. 2000. An
empirically-based system for processing definite de-
scriptions. Computational Linguistics, 26(4), De-
cember.
X. Wang, 2005. Robust Utilization of Context in Word
Sense Disambiguation, chapter Modeling and Using
Context, pages 529?541. Springer Lecture Notes in
Computer Science.
J. Washtell. 2009. Co-dispersion: A windowless ap-
proach to lexical association. In Proc. of EACL-
2009.
M. Wettler and R. Rapp. 1993. Computation of word
associations based on the co-ocurrences of words in
large corpora. In Proc. of the First Workshop on Very
Large Corpora.
K. White and L. Abrams. 2004. Free associations and
dominance ratings of homophones for young and
older adults. Behaviour Research Methods, Instru-
ments and Computers, 36:408?420.
D. Yarowsky and R Florian. 2002. Evaluating sense
disambiguation across diverse parameter spaces.
Natural Language Engineering, 8(4):293?310.
637
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 861?869,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Co-dispersion: A Windowless Approach to Lexical Association 
 
 
Justin Washtell 
University of Leeds 
Leeds, UK 
washtell@comp.leeds.ac.uk 
 
  
Abstract 
We introduce an alternative approach to ex-
tracting word pair associations from corpora, 
based purely on surface distances in the text. 
We contrast it with the prevailing window-
based co-occurrence model and show it to be 
more statistically robust and to disclose a 
broader selection of significant associative re-
lationships - owing largely to the property of 
scale-independence. In the process we provide 
insights into the limiting characteristics of 
window-based methods which complement the 
sometimes conflicting application-oriented lit-
erature in this area. 
1 Introduction 
The principle of using statistical measures of co-
occurrence from corpora as a proxy for word 
association - by comparing observed frequencies 
of co-occurrence with expected frequencies - is 
relatively young. One of the most well known 
computational studies is that of Church & Hanks 
(1989). The method by which co-occurrences are 
counted, now as then, is based on a device which 
dates back at least to Weaver (1949): the context 
window. While variations on the specific notion 
of context have been explored (separation of 
content and function words, asymmetrical and 
non-contiguous contexts, the sentence or the 
document as context) and increasingly sophisti-
cated association measures have been proposed 
(see Evert, 2007, for a thorough review) the basic 
principle ? that of counting token frequencies 
within a context region ? remains ubiquitous. 
Herein we discuss some of the intrinsic limi-
tations of this approach, as are being felt in re-
cent research, and present a principled solution  
which does not rely on co-occurrence windows 
at all, but instead on measurements of the surface 
distance between words. 
2 The impact of window size 
The issue of how to determine appropriate win-
dow size (and shape) has often been glossed over 
in the literature, with such parameters being de-
termined arbitrarily, or empirically on a per-
application basis, and often receiving little more 
than a cursory mention under the description of 
method. For reasons that we will discuss how-
ever, the issue has been receiving increasing at-
tention. Some have attempted to address it intrin-
sically (Sahlgren 2006; Schulte im Walde & 
Melinger, 2008; Hung et al 2001); others no less 
earnestly in the interests of specific applications 
(Lamjiri, 2003; Edmonds, 1997; Wang 2005; 
Choueka & Lusignan, 1985) (note that this di-
vide is sometimes subtle). 
The 2008 Workshop on Distributional Lexi-
cal Semantics, held in conjunction with the 
European Summer School on Logic, Language 
and Learning (ESSLLI) ? hereafter the ESSLLI 
Workshop - saw this issue (along with other 
?problem? parameters in distributional lexical 
semantics) as one of its central themes, and wit-
nessed many different takes upon it. Interest-
ingly, there was little consensus, with some stud-
ies appearing on the surface to starkly contradict 
one-another. It is now generally recognized that 
window size is, like the choice of corpus or spe-
cific association measure, a parameter which can 
have a potentially profound impact upon the per-
formance of applications which aim to exploit 
co-occurrence counts. 
One widely held (and upheld) intuition - ex-
pressed throughout the literature, and echoed by 
various presenters at the ESSLLI Workshop - is 
that whereas small windows are well suited to 
the detection of syntactico-semantic associations, 
larger windows have the capacity to detect 
broader ?topical? associations. More specifically, 
we can observe that small windows are unavoid-
ably limited to detecting associations manifest at 
very close distances in the text. For example, a 
861
window size of two words can only ever observe 
bigrams, and cannot detect associations resulting 
from larger constructs, however ingrained in the 
language (e.g. ?if ? then?, ?ne ? pas?, ?dear ... 
yours?). This is not the full story however. As, 
Rapp (2002) observes, choosing a window size 
involves making a trade-off between various 
qualities. So conversely for example, frequency 
counts within large windows, though able to de-
tect longer-range associations, are not readily 
able to distinguish them from bigram style co-
occurrences, and so some discriminatory power, 
and sensitivity to the latter, is lost. Rapp (2002) 
calls this trade-off ?specificity?; equivalent ob-
servations were made by Church & Hanks 
(1989) and Church et al(1991), who refer to the 
tendency for large windows to ?wash out?, 
?smear? or ?defocus? those associations exhib-
ited at smaller scales. 
In the following two sections, we present 
two important and scarcely discussed facets of 
this general trade-off related to window size: that 
of scale-dependence, and that concerning the 
specific way in which the data sparseness prob-
lem is manifest. 
2.1 Scale-dependence 
It has been shown that varying the size of the 
context considered for a word can impact upon 
the performance of applications (Rapp, 2002; 
Yarowsky & Florian, 2002), there being no ideal 
window size for all applications. This is an ines-
capable symptom of the fact that varying win-
dow size fundamentally affects what is being 
measured (both in the raw data sense and linguis-
tically speaking) and so impacts upon the output 
qualitatively. As Church et al(1991) postulated, 
?It is probably necessary that the lexicographer 
adjust the window size to match the scale of phe-
nomena that he is interested in?. 
In the case of inferential lexical semantics, 
this puts strict limits on the interpretation of as-
sociation scores derived from co-occurrence 
counts and, therefore, on higher-level features 
such as context vectors and similarity measures. 
As Wang (2005) eloquently observes, with re-
spect to the application of word sense disam-
biguation, ?window size is an inherent parame-
ter which is necessary for the observer to imple-
ment an observation ? [the result] has no mean-
ing if a window size does not accompany?. More 
precisely, we can say that window-based co-
occurrence counts (and any word-space models 
we may derive from them) are scale-dependent. 
It follows that one cannot guarantee there to 
be an ?ideal? window size within even a single 
application. Distributional lexical semantics of-
ten defers to human association norms for 
evaluation. Schulte im Walde & Melinger (2008) 
found that the correlation between co-occurrence 
derived association scores and human association 
norms were weakly dependent upon the window 
size used to calculate the former, but that certain 
associations tended to be represented at certain 
window sizes, by virtue of the fact that the best 
overall correlation was found by combining evi-
dence from all window sizes. By identifying a 
single window size (whether arbitrary or appar-
ently optimum) and treating other evidence as 
extraneous, it follows that studies may tend to 
distance their findings from one another. 
As Church et al(1991) allude, in certain 
situations the ability to tune analysis to a specific 
scale in this way may be desirable (for example, 
when explicitly searching for statistically signifi-
cant bigrams, only a 2-token window will do). In 
other scenarios however, especially where a 
trade-off in aspects of performance is found be-
tween scales, it can clearly be seen as a limita-
tion. And after all, is Church et als notional 
lexicographer really interested in those features 
manifest at a specific scale, or is he interested in 
a specific linguistic category of features? Not-
withstanding grammatical notions of scale (the 
clause, the sentence etc), there is as yet little evi-
dence to suggest how the two are linked. 
The existence of these trade-offs has led 
some authors towards creative solutions: looking 
for ways of varying window size dynamically in 
response to some performance measure, or si-
multaneously exploiting more than one window 
size in order to maximize the pertinent informa-
tion captured (Wang, 2005; Quasthoff, 2007; 
Lamjiri et al 2003). When the scales at which an 
association is manifest are the quantity of interest 
and the subject of systematic study, we have 
what is known in scale-aware disciplines as 
multi-scalar analysis, of which fractal analysis is 
a variant. Although a certain amount has been 
written about the fractal or hierarchical nature of 
language, approaches to co-occurrence in lexical 
semantics remain almost exclusively mono-
scalar, with the recent work of Quasthoff (2007) 
being a rare exception. 
2.2 Data sparseness 
Another facet of the general trade-off identified 
by Rapp (2002) pertains to how limitations in-
862
herent in the combination of data and co-
occurrence retrieval method are manifest. 
When applying a small window, the number 
of window positions which can be expected to 
contain a specific pair of words will tend to be 
low in comparison to the number of instances of 
each word type. In some cases, no co-occurrence 
may be observed at all between certain word 
pairs, and zero or negative association may be 
inferred (even though we might reasonably ex-
pect such co-occurrences to be feasible within 
the window, or know that a logical association 
exists). This is one manifestation of what is 
commonly referred to as the data sparseness 
problem, and was discussed by Rapp (2002) as a 
side-effect of specificity. It would of course be 
inaccurate to suggest that data sparseness itself is 
a response to window size; a larger window su-
perficially lessens the sparseness problem by 
inviting more co-occurrences, but encounters the 
same underlying paucity of information in a dif-
ferent guise: as both the size and overlap be-
tween the windows grow, the available informa-
tion is increasingly diluted both within and 
amongst the windows, resulting in an over-
smoothing of the data. This phenomenon is well 
illustrated in the extreme case of a single corpus-
sized window where - in the absence of any ex-
ternal information - observed and expected co-
occurrence frequencies are equivalent, and it is 
not possible to infer any associations at all. 
Addressing the sparseness problem with re-
spect to corpus data has received considerable 
attention in recent years. It is usually tackled by 
applying explicit smoothing methods so as to 
allow the estimation of frequencies of unseen co-
occurrences. This may involve applying insights 
on the statistical limitations of working from a 
finite sample (add-? smoothing, Good-Turing 
smoothing), making inferences from words with 
similar co-occurrence patterns, or ?backing off? 
to a more general language model based on indi-
vidual word frequencies, or even another corpus; 
for example, Keller & Lapata (2003) use the 
Web. All of these approaches attempt to mitigate 
the data sparseness manifest in the observed co-
occurrence frequencies; they do not presume to 
reduce data sparseness by improving the method 
of observation. Indeed, the general assumption 
would seem to be that the only way to minimize 
data sparseness is to use more data. However, we 
will show that, similarly to Wang?s (2005) ob-
servation concerning windowed measurements in 
general, apparent data sparseness is as much a 
manifestation of the observation method as it is 
of the data itself; there may exist much pertinent 
information in the corpus which yet remains un-
exploited. 
 
3 Proximity as association 
Comprehensive multi-scalar analyses (such as 
applied by Quasthoff, 2007; and Schulte im 
Walde & Melinger, 2008) can be laborious and 
computationally expensive, and it is not yet clear 
how to derive simple association scores and 
suchlike from the dense data they generate (typi-
cally a separate set of statistics for each window 
size examined). There do exist however rela-
tively efficient naturally scale-independent tools 
which are amenable to the detection of linguisti-
cally interesting features in text. In some do-
mains the concept of proximity (or distance ? we 
will use the terms somewhat interchangeably 
here) has been used as the basis for straightfor-
ward alternatives to various frequency-based 
measures. In biogeography, for example, the dis-
persion or ?clumpiness? of a population of indi-
viduals can be accurately estimated by sampling 
the distances between them (Clark & Evans, 
1954): a task more conventionally carried out by 
?quadrat? sampling, which is directly analogous 
to the window-based methods typically used to 
measure dispersion or co-occurrence in a corpus 
(see Gries, 2008, for an overview of dispersion in 
a linguistic setting). Such techniques are also 
been used in archeology. Washtell (2006) found 
evidence to suggest that distance-based ap-
proaches within the geographic domain can be 
both more accurate and more efficient than their 
window-based alternatives. 
In the present domain, the notion of prox-
imity has been applied by Savick? & Hlav?cov? 
(2002) and Washtell (2007) - both in Gries 
(2008) - as an alternative to approaches based on 
corpus division, for quantifying the dispersion of 
words within the text. Hardcastle (2005) and 
Washtell (2007) apply this same concept to 
measuring word pair associations, the former via 
a somewhat ad-hoc approach, the latter through 
an extension of Clark-Evans (1954) dispersion 
metric to the concept of co-dispersion: the ten-
dency of unlike words to gravitate (or be simi-
larly dispersed) in the text. Terra & Clarke 
(2004) use a very similar approach in order to 
generate a probabilistic language model, where 
previously n-gram models have been used, 
The allusion to proximity as a fundamental 
indicator of lexical association does in fact per-
863
meate the literature. Halliday (1966), for exam-
ple, in Church et al(1991) talked not explicitly 
of frequencies within windows, but of identify-
ing lexical associates via ?some measure of sig-
nificant proximity, either a scale or at least a 
cut-off point?. For one (possibly practical) rea-
son or another, the ?cut-off point? has been 
adopted and the intuition of proximity has since 
become entrained within a distinctly frequency-
oriented model. By way of example, the notion 
of proximity has been somewhat more directly 
courted in some window-based studies through 
the use of ?ramped? or ?weighted? windows 
(Lamjiri et al 2003; Bullinaria & Levy, 2007), in 
which co-occurrences appearing towards the ex-
tremities of the window are discounted in some 
way. As with window size however, the specific 
implementations and resultant performances of 
this approach have been inconsistent in the litera-
ture, with different profiles (even including those 
where words are discounted towards the centre 
of the window) seeming to prove optimum under 
varying experimental conditions (compare, for 
instance, Bullinaria, 2008, and Shaol & West-
bury, 2008, from the ESSLLI Workshop). 
Performance considerations aside, a problem 
arising from mixing the metaphors of frequency 
and distance in this way is that the resultant 
measures become difficult to interpret; in the 
present case of association, it is not trivially ob-
vious how one might establish an expected value 
for a window with a given profile, or apply and 
interpret conditional probabilities and other well-
understood association measures.1 At the very 
least, Wang?s (2005) observation is exacerbated.  
3.1 Co-dispersion 
By doing away with the notion of a window en-
tirely and focusing purely upon distance informa-
tion, Halliday?s (1966) intuitions concerning 
proximity can be more naturally realized. Under 
the frequency regime, co-occurrence scores cor-
respond directly to probabilities, which are well 
understood (providing, as Wang, 2005, observes, 
that a window size is specified as a reference-
frame for their interpretation). It happens that 
similarly intuitive mechanics apply within a 
purely distance-oriented regime - a fact realised 
by Clark & Evans (1954), but not exploited by 
Hardcastle (2005). Co-dispersion, which is de-
rived from the Clark-Evans metric (and more 
descriptively entitled ?co-dispersion by nearest 
                                                          
1
 Existing works do not go into detail on method, so it 
is possible that this is one source of discrepancies. 
neighbour? - as there exist many ways to meas-
ure dispersion), can be generalised as follows: 
 
)dist,,M(dist
)freq,(freqnm
=CoDisp
n1 abab
ba
ab
...
)1(max +?
 
 
Where, in the denominator, distabi is the in-
ter-word distance (the number of intervening 
tokens plus one) between the ith occurrence of 
word-type a in the corpus, and the nearest pre-
ceding or following occurrence of word-type b 
(if one exists before encountering (1) another 
occurrence of a or (2) the edge of the containing 
document). M is the generalized mean. In the 
numerator, freqi is the total number of occur-
rences of word-type i, n is the number of tokens 
in the corpus, and m is a constant based on the 
expected value of the mean (e.g. for the arithme-
tic mean ? as used by Clark & Evans - this is 
0.5). Note that the implementation considered 
here does not distinguish word order; owing to 
this, and the constraint (1), the measure is sym-
metric.2 
Plainly put, co-dispersion calculates the ratio 
of the mean observed distance to the expected 
distance between word type pairs in the text; or 
how much closer the word types occur, on aver-
age, than would expected according to chance3. 
In this sense it is conceptually equivalent to 
Pointwise Mutual Information (PMI) and related 
association measures which are concerned with 
gauging how more frequently two words occur 
together (in a window), than would be expected 
by chance. 
Like many of its frequency-oriented cousins, 
co-dispersion can be used directly as a measure 
of association, with values in the range 
0>=CoDisp<=? (with a value of 1 representing 
no discernible association); and as with these 
measures, the logarithm can be taken in order to 
present the values on a scale that more meaning-
fully represents relative associations (as is the 
default with PMI). Also as with PMI et al co-
dispersion can have a tendency to give inflated 
estimates where infrequent words are involved. 
To address this problem, a simple significance-
                                                          
2
 This constraint, which was independently adopted 
by Terra & Clarke (2004), has significant computa-
tional advantages as it effectively limits the search 
distance for frequent words. 
3
 The expected distance of an independent word-type 
pair is assumed to be half the distance between 
neighbouring occurrences of the more frequent word-
type, were it uniformly distributed within the corpus. 
864
corrected measure, more akin to a Z-Score or T-
Score (Dennis, 1965; Church et al 1991) can be 
formed by taking (the root of) the number of 
word-type occurrences into account (Sackett, 
2001). The same principal can be applied to PMI, 
although in practice more precise significance 
measures such as Log-Likelihood are favoured.4 
These similarities aside, co-dispersion has 
the somewhat abstract distinction of being effec-
tively based on degrees rather than probabilities. 
Although it is windowless (and therefore, as we 
will show, scale-independent), it is not without 
analogous constraints. Just as the concept of 
mean frequency employed by co-occurrence re-
quires a definition of distance (window size), the 
concept of distance employed by co-dispersion 
requires a definition of frequency. In the case 
presented here, this frequency is 1 (the nearest 
neighbour). Thus, whereas the assumption with 
co-occurrence is that the linguistically pertinent 
words are those that fall within a fixed-sized 
window of the word of interest, the assumption 
underpinning co-dispersion is that the relevant 
information lies (if at all) with the closest 
neighbouring occurrence of each word type. 
Among other things, this naturally favours the 
consideration of nearby function words, whereas 
(generally less frequent) content words are con-
sidered to be of potential relevance at some dis-
tance. That this may be a desirable property - or 
at least a workable constraint - is borne out by 
the fact that other studies have experienced suc-
cess by treating these two broad classes of words 
with separately sized windows (Lamjiri et al 
2003). 
4 Analyses 
4.1 Scale-independence 
Table 1 shows a matrix of agreement between 
word-pair association scores produced by co-
occurrence and co-dispersion as applied to the 
unlemmatised, untagged, Brown Corpus. For co-
occurrence, window sizes of ?1, ?3, ?10, ?32, 
and ?100 words were used (based on to a - 
somewhat arbitrary - scaling factor of ?10). 
The words used were a cross-section of 
stimulus-response pairs from human association 
experiments (Kiss et al 1973), selected to give a 
uniform spread of association scores, as used in 
the ESSLLI Workshop shared task.  It is not our 
purpose in the current work to demonstrate com-
                                                          
4
 Although the heuristically derived MI2 and MI3 
(Daille, 1994) have gained some popularity. 
petitive correlations with human association 
norms (which is quite a specific research area) 
and we are making no cognitive claims here. 
Their use lends convenience and a (limited) de-
gree of relevance, by allowing us to perform our 
comparison across a set of word-pairs which are 
deigned to represent a broad spread of associa-
tions according to some independent measure. 
Nonetheless, correlations with the association 
norms are presented as this was a straightforward 
step, and grounds the findings presented here in a 
more tangible context. 
Because the human stimulus-response rela-
tionship is generally asymmetric (favouring 
cases where the stimulus word evokes the re-
sponse word, but not necessarily vice-versa), the 
conditional probability of the response word was 
used, rather than PMI which is symmetric. For 
the windowless method, co-dispersion was 
adapted equivalently - by multiplying the resul-
tant association score by the number of word 
pairings divided by the number of occurrences of 
the cue word. These association scores were also 
corrected for statistical significance, as per Sack-
ett (2001). Both of these adjustments were found 
to improve correlations with human scores across 
the board, but neither impacts directly upon the 
comparative analyses performed herein. It is also 
worth mentioning that many human association 
reproduction experiments employ higher-order 
paradigmatic associations, whereas we use only 
syntagmatic associations.5 This is appropriate as 
our focus here is on the information captured at 
the base level (from which higher order features 
? paradigmatic associations, semantic categories 
etc - are invariably derived). It can be seen in the 
rightmost column of table 1 that, despite the lack 
of sophistication in our approach, all window 
sizes and the windowless approach generated 
statistically significant (if somewhat less than 
state-of-the-art) correlations with the subset of 
human association norms used. 
Owing to the relatively small size of the cor-
pus, and the removal of stop-words, a large por-
tion of the human stimulus-response pairs used 
as our basis generated no association (no 
smoothing was used as we are concerned at this 
level in raw evidence captured from the corpus). 
All correlations presented herein therefore con-
sider only those word pairs for which there was 
some evidence under the methods being com-
                                                          
5
 Though interestingly, work done by Wettler et al
(2005) suggests that paradigmatic associations may 
not be necessary for cognitive association models. 
865
pared from which to generate a non-zero associa-
tion score (however statistically insignificant). 
This number of word pairs, shown in square 
brackets in the leftmost column of table 1, natu-
rally increases with window size, and is highest 
for the windowless methods. 
 
 
 
Table 1: Matrix of agreement (corrected r2) between 
association retrieval methods; and correlations with 
sample association norms (r, and p-value). 
 
The coefficients of determination (corrected 
r
2
 values) in the main part of table 1 show clearly 
that, as window sizes diverge, their agreement 
over the apparent association of word pairs in the 
corpus diminishes - to the point where there is 
almost as much disagreement as there is agree-
ment between windows whose size differs by a 
decimal order of magnitude. While relatively 
small, the fact that there remains a degree of in-
formation overlap between the smallest and larg-
est windows in this study (18%), illustrates that 
some word pairs exhibit associative tendencies 
which markedly transcend scale. It would follow 
that single window sizes are particularly impo-
tent where such features are of holistic interest. 
The figures in the bottom row of table 1 
show, in contrast, that there is a more-or-less 
constant level of agreement between the win-
dowless and windowed approaches, regardless 
of the window size chosen for the latter. 
Figure 1 gives a good two-dimensional sche-
matic approximation of these various relation-
ships (in the style of a Venn diagram). Analysis 
of partial correlations would give a more accu-
rate picture, but is probably unnecessary in this 
case as the areas of overlap between methods are 
large enough to leave marginal room for misrep-
resentation. It is interesting to observe that co-
dispersion appears to have a slightly higher af-
finity for the associations best detected by small 
windows in this case. Reassuringly nonetheless, 
the relative correlations with association norms 
here - and the fact that we see such significant 
overlap ? do indeed suggest that co-dispersion is 
sensitive to useful information present in each of 
the various windowed methods. Note that the 
regions in Figure 1 necessarily have similar ar-
eas, as a correlation coefficient describes a sym-
metric relationship. The diagram therefore says 
nothing about the amount of information cap-
tured by each of these methods. It is this issue 
which we will look at next. 
 
 
 
Figure 1: Approximate Venn representation of agree-
ment between windowed and windowless association 
retrieval methods. 
4.2 Statistical power 
To paraphrase Kilgariff (2005), language is any-
thing but random. A good language model is one 
which best captures the non-random structure of 
language. A good measuring device for any lin-
guistic feature is therefore one which strongly 
differentiates real language from random data. 
The solid lines in figures 2a and 2b give an indi-
cation of the relative confidence levels (p-values) 
attributable to a given association score derived 
from windowed co-occurrence data. Figure 2a is 
based on a window size of ?10 words, and 2b 
?100 words. The data was generated, Monte 
Carlo style, from a 1 million word randomly 
generated corpus. For the sake of statistical con-
venience and realism, the symbols in the corpus 
were given a Zipf frequency distribution roughly 
matching that of words found in the Brown cor-
pus (and most English corpora). Unlike with the 
previous experiment, all possible word pairings 
were considered. PMI was used for measuring 
association, owing to its convenience and simi-
larity to co-dispersion, but it should be noted that 
the specific formulation of the association meas-
ure is more-or-less irrelevant in the present con-
text, where we are using relative association lev-
els between a real and random corpus as a proxy 
for how much structural information is captured 
from the corpus.  
866
  
Figure 2a: Co-occurrence significances for a moderate 
(?10 words) window. 
 
 
 
Figure 2b: Co-occurrence significances for a large 
(?100 words) window. 
 
Precisely put, the figures show the percentage 
of times a given association score or lower was 
measured between word types in a corpus which 
is known to be devoid of any actual syntagmatic 
association. The closer to the origin these lines, 
the fewer word instances were required to be 
present in the random corpus before high levels 
of apparent association became unlikely, and so 
the fewer would be required in a real corpus be-
fore we could be confident of the import of a 
measured level of association. Consequently, if 
word pairs in a real corpus exceed these levels, 
we say that they show significant association. 
The shaded regions in figures 2a and 2b show 
the typical range of apparent association scores 
found in a real corpus ? in this case the Brown 
corpus. The first thing to observe is that both the 
spread of raw association scores and their sig-
nificances are relatively constant across word 
frequencies, up to a frequency threshold which is 
linked to the window size. This constancy exists 
in spite of a remarkable variation in the raw as-
sociation scores, which are increasingly inflated 
towards the lower frequencies (indeed illustrat-
ing the importance of taking statistical signifi-
cance into account). This observed constancy is 
intuitive where long-range associations between 
words prevail: very infrequent words will tend to 
co-occur within the window less often than mod-
erately frequent words - by simple virtue of their 
number - yet when they do co-occur, the evi-
dence for association is that much stronger ow-
ing to the small size of the window relative to 
their frequency. Beyond the threshold governed 
by window size, there can be seen a sharp level-
ling out in apparent association, accompanied by 
an attendant drop in overall significance. This is 
a manifestation of Rapp?s specificity: as words 
become much more frequent than window size, 
the kinds of tight idiomatic co-occurrences and 
compound forms which would otherwise imply 
an uncommonly strong association can no longer 
be detected as such. 
A related observation is that, in spite of the 
lower random baseline exhibited by the larger 
window size, the actual significance of the asso-
ciations it reports in a real corpus are, for all 
word frequencies, lower than those reported by 
the smaller window: i.e. quantitatively speaking, 
larger windows seem to observe less! Evidently, 
apparent association is as much a function of 
window size as it is of actual syntagmatic asso-
ciation; it would be very tempting to interpret the 
association profiles in figures 2a or 2b, in isola-
tion of each other or their baseline plots, as indi-
cating some interesting scale-varying associative 
structure in the corpus, where in fact they do not. 
 
 
 
Figure 3: Significances for windowless co-dispersion. 
 
60% 
867
Figure 3 is identical to figures 2a and 2b (the 
same random and real world corpora were used) 
but it represents the windowless co-dispersion 
method presented herein. It can be seen that the 
random corpus baseline comprises a smooth 
power curve which gives low initial association 
levels, rapidly settling towards the expected 
value of zero as the number of token instances 
increases. Notably, the bulk of apparent associa-
tion scores reported from the Brown Corpus are, 
while not necessarily greater, orders of magni-
tude more significant than with the windowed 
examples for all but the most frequent words 
(ranging well into the 99%+ confidence levels). 
This gain can only follow from the fact that more 
information is being taken into account: not only 
do we now consider relationships that occur at all 
scales, as previously demonstrated, but we con-
sider the exact distance between word tokens, as 
opposed to low-range ordinal values linked to 
window-averaged frequencies. There is no ob-
servable threshold effect, and without a window 
there is no reason to expect one. Accordingly, 
there is no specificity trade-off: while word pairs 
interacting at very large distances are captured 
(as per the largest of windows), very close occur-
rences are still rewarded appropriately (as per the 
smallest of window). 
 
5 Conclusions and future direction 
We have presented a novel alternative to co-
occurrence for measuring lexical association 
which, while based on similar underlying lin-
guistic intuitions, uses a very different apparatus. 
We have shown this method to gather more in-
formation from the corpus overall, and to be par-
ticularly unfettered by issues of scale. While the 
information gathered is, by definition, linguisti-
cally relevant, relevance to a given task (such as 
reproducing human association norms or per-
forming word-sense disambiguation), or superior 
performance with small corpora, does not neces-
sarily follow. Further work is to be conducted in 
applying the method to a range of linguistic 
tasks, with an initial focus on lexical semantics. 
In particular, properties of resultant word-space 
models and similarity measures beg a thorough 
investigation: while we would expect to gain 
denser higher-precision vectors, there might 
prove to be overriding qualitative differences. 
The relationship to grammatical dependency-
based contexts which often out-perform contigu-
ous contexts also begs investigation. 
It is also pertinent to explore the more fun-
damental parameters associated with the win-
dowless approach; the formulation of co-
dispersion presented herein is but one interpreta-
tion of the specific case of association. In these 
senses there is much catching-up to do. 
At the present time, given the key role of win-
dow size in determining the selection and appar-
ent strength of associations under the conven-
tional co-occurrence model - highlighted here 
and in the works of Church et al(1991), Rapp 
(2002), Wang (2005), and Schulte im Walde & 
Melinger (2008) - we would urge that this is an 
issue which window-driven studies continue to 
conscientiously address; at the very least, scale is 
a parameter which findings dependent on distri-
butional phenomena must be qualified in light of. 
Acknowledgements 
Kind thanks go to Reinhard Rapp, Stefan Gries, 
Katja Markert, Serge Sharoff and Eric Atwell for 
their helpful feedback and positive support. 
 
References 
  
John A. Bullinaria. 2008. Semantic Categorization 
Using Simple Word Co-occurrence Statistics. In: 
M. Baroni, S. Evert & A. Lenci (Eds), Proceedings 
of the ESSLLI Workshop on Distributional Lexical 
Semantics: 1 - 8 
John A. Bullinaria  and Joe P. Levy. 2007. Extracting 
Semantic Representations from Word Co-
occurrence Statistics: A Computational Study. Be-
havior Research Methods, 39:510 - 526. 
Yaacov Choueka and Serge Lusignan. 1985. Disam-
biguation by short contexts. Computers and the 
Humanities. 19(3):147 - 157 
Kenneth W. Church and Patrick Hanks. 1989. Word 
association norms, mutual information, and lexi-
cography. In Proceedings of the 27th Annual Meet-
ing on Association For Computational Linguistics: 
76 - 83 
Kenneth W. Church, William A. Gale, Patrick Hanks 
and Donald Hindle. 1991. Using statistics in lexi-
cal analysis. In: Lexical Acquisition: Using On-
line Resources to Build a Lexicon, Lawrence Erl-
baum: 115 - 164. 
P. J. Clark and F. C. Evans. 1954. Distance to nearest 
neighbor as a measure of spatial relationships in 
populations.Ecology. 35: 445 - 453. 
B?atrice Daille. 1994. Approche mixte pour l'extrac-
tion automatique de terminologie: statistiques lexi-
cales et filtres linguistiques. PhD thesis, Universit? 
Paris. 
868
Sally F. Dennis. 1965. The construction of a thesau-
rus automatically from a sample of text. In Pro-
ceedings of the Symposium on Statistical Associa-
tion Methods For Mechanized Documentation, 
Washington, DC: 61 - 148. 
Philip Edmonds. 1997. Choosing the word most typi-
cal in context using a lexical co-occurrence net-
work. In Proceedings of the Eighth Conference on 
European Chapter of the Association For Computa-
tional Linguistics: 507 - 509 
Stefan Evert. 2007. Computational Approaches to 
Collocations: Association Measures,  Institute of 
Cognitive Science, University of Osnabruck, 
<http://www.collocations.de>. 
Manfred Wettler, Reinhard Rapp and Peter Sedlmeier. 
2005. Free word associations correspond to conti-
guities between words in texts. Journal of Quantita-
tive Linguistics, 12:111 - 122. 
Michael K. Halliday. 1966 Lexis as a Linguistic 
Level, in Bazell, C., Catford, J., Halliday, M., and 
Robins, R. (eds.), In Memory of J. R. Firth, Long-
man, London. 
David Hardcastle. 2005. Using the distributional hy-
pothesis to derive cooccurrence scores from the 
British National Corpus. Proceedings of Corpus 
Linguistics. Birmingham, UK 
Kei Yuen Hung, Robert Luk, Daniel Yeung, Korris 
Chung and Wenhuo Shu. 2001. Determination of 
Context Window Size, International Journal of 
Computer Processing of Oriental Languages, 
14(1): 71 - 80 
Stefan Gries. 2008. Dispersions and Adjusted Fre-
quencies in Corpora. International Journal of Cor-
pus Linguistics, 13(4)  
Frank Keller and Mirella Lapata. 2003. Using the web 
to obtain frequencies for unseen bigrams, Compu-
tational Limguistics, 29:459 ? 484 
Adam Kilgarriff. 2005. Language is never ever ever 
random. Corpus Linguistics and Linguistic Theory 
1: 263 - 276. 
George Kiss, Christine Armstrong, Robert Milroy and 
James Piper. 1973. An associative thesaurus of 
English and its computer analysis. In Aitken, A.J., 
Bailey, R.W. and Hamilton-Smith, N. (Eds.), The 
Computer and Literary Studies. Edinburgh Univer-
sity Press. 
Abolfazl K. Lamjiri, Osama El Demerdash and Leila 
Kosseim. 2003. Simple Features for Statistical 
Word Sense Disambiguation, Proceedings of Sen-
seval-3:3rd International Workshop on the Evalua-
tion of Systems for the Semantic Analysis of Text: 
133 - 136. 
Uwe Quasthoff. 2007. Fraktale Dimension von 
W?rtern. Unpublished manuscript.  
Reinhard Rapp. 2002. The computation of word asso-
ciations: comparing syntagmatic and paradigmatic 
approaches. In Proceedings of the 19th interna-
tional Conference on Computational Linguistics. 
D. L. Sackett. 2001. Why randomized controlled trials 
fail but needn't: 2. Failure to employ physiological 
statistics, or the only formula a clinician-trialist is 
ever likely to need (or understand!). CMAJ, 
165(9):1226 - 37. 
Magnus Sahlgren. 2006. The Word-Space Model: 
using distributional analysis to represent syntag-
matic and paradigmatic relations between words in 
high-dimensional vector space, PhD Thesis, 
Stockholm University. 
Petr Savick? and Jana Hlav?cov?. 2002. Measures of 
word commonness. Journal of Quantitative 
Luiguistics, 9(3): 215 ? 31. 
Cyrus Shaoul, Chris Westbury. 2008. Performance of 
HAL-like word space models on semantic cluster-
ing. In: M. Baroni, S. Evert & A. Lenci (Eds), Pro-
ceedings of the ESSLLI Workshop on Distribu-
tional Lexical Semantics: 1 ? 8. 
Sabine Schulte im Walde and Alissa Melinger, A. 
2008. An In-Depth Look into the Co-Occurrence 
Distribution of Semantic Associates, Italian Journal 
of Linguistics, Special Issue on From Context to 
Meaning: Distributional Models of the Lexicon in 
Linguistics and Cognitive Science. 
Egidio Terra and Charles L. A. Clarke. 2004. Fast 
Computation of Lexical Affinity Models, Proceed-
ings of the 20th International Conference on Com-
putational Linguistics, Geneva, Switzerland. 
Xiaojie Wang. 2005. Robust Utilization of Context in 
Word Sense Disambiguation, Modeling and Using 
Context, Lecture Notes in Computer Science, 
Springer: 529-541. 
Justin Washtell. 2006. Estimating Habitat Area & 
Related Ecological Metrics: From Theory Towards 
Best Practice, BSc Dissertation, University of 
Leeds. 
Justin Washtell. 2007. Co-Dispersion by Nearest 
Neighbour: Adapting a Spatial Statistic for the De-
velopment of Domain-Independent Language Tools 
and Metrics, MSc Thesis, University of Leeds. 
Warren Weaver. 1949 Translation. Repr. in: Locke, 
W.N. and Booth, A.D. (eds.) Machine translation 
of languages: fourteen essays (Cambridge, Mass.: 
Technology Press of the Massachusetts Institute of 
Technology, 1955), 15-23. Association for Com-
puting Machinery, 28(1):114-133.  
David Yarowsky and Radu Florian. 2002. Evaluating 
Sense Disambiguation Performance Across Di-
verse Parameter Spaces. Journal of Natural Lan-
guage Engineering, 8(4). 
869
Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 45?50,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Expectation Vectors: A Semiotics Inspired Approach
to Geometric Lexical-Semantic Representation
Justin Washtell
University of Leeds
Leeds, UK
washtell  @ comp.leeds.ac.uk  
 Abstract
 
We  introduce  a  new  family  of  geometric 
models  of  meaning,  inspired  by  principles 
from  semiotics  and  information  theory, 
based on what we call Expectation Vectors. 
We present theoretical arguments in support 
of  these  representations  over  traditional 
context-feature  vectors:  primarily that  they 
provide  a  more  intuitive  representation  of 
meaning,  and  detach  vector  representation 
from  the  specific  context  features  thereby 
allowing  arbitrarily  sophisticated  language 
models  to  be  leveraged.  We  present  a 
preliminary  evaluation  of  an  expectation 
vector  based  word  sense  disambiguation 
system  using  the  SemEval-2007  task  2 
dataset,  with  very  encouraging  results, 
particularly with respect to ambiguous verbs.
 
1 Introduction
 
It  is  a  cornerstone  assumption  of  distributional 
lexical semantics that the distribution of words in a 
corpus  reflects their  meaning.  Common 
interpretations  of  this  include  the  Distributional 
Hypothesis  (Harris,  1954)  and  the  Contextual 
Hypotheses (Miller & Charles, 1991), which state 
that  there  is  a  relationship  between  a  word's 
meaning, and the context(s) in which it appears. In 
recent  years  this  insight  has  been  borne  out  by 
correlations  between  human  judgements  and 
distributional  models  of  word  similarity  (Rapp, 
2002), and steady advances in tasks such as word 
sense  disambiguation  (Sch?tze,  1998)  and 
information  retrieval.  The  workhorse  of  these 
approaches  are  wordspace  models:  vectors  built 
from context  features  which  serve  as  geometric 
analogues  of  meaning.  Despite  many  advances, 
substantial  problems  exist  with  this  approach  to 
modelling  meaning.  Amongst  these  are  the 
problems of data sparseness and of how to model 
compositional meaning.
In this short paper, we introduce a new family 
of  wordspace models,  based on insights  gleaned 
from  semiotics  and  information  theory,  called 
Expectation Vectors.  These retain the  convenient 
vector-based  paradigm  whilst  encouraging  the 
exploitation  of  advances  in  language  modelling 
from other areas of NLP. We finish by outlining 
some  present  efforts  to  evaluate  expectation 
vectors in the area of word sense disambiguation.
2 Modelling meaning from context
 
Perhaps  one  of  the  most  prominent  application 
areas to exploit  context-based wordspace models 
is that of word sense induction and disambiguation 
(WSI/WSD).  The  prevailing  approach  to  this 
problem is based on a fairly literal interpretation of 
the Distributional Hypothesis: that is to cluster or 
classify instances of  ambiguous words according 
to  certain  features  of  the  context  in  which  they 
appear ? invariably other words. It is not difficult 
to see why this approach is limiting: as Pedersen 
(2008) observes,  ?the unifying thread that  binds  
together  many  short  context  applications  and 
methods is the fact that similarity decisions must  
be made between contexts that share few (if any)  
words  in  common.?  This  is  a  manifestation  of 
what  is  commonly  referred  to  at  the  data 
sparseness problem, and it pervades all of corpus-
based  NLP.  This  problem  is  exacerbated  as 
available examples of  a word sense decrease,  or 
finer sense granularities are sought. For supervised 
tasks  this  implies  that  a  large  training  set  is 
required,  which  is  often  expensive.  For 
unsupervised tasks,  such as WSI,  it  has negative 
implications for cluster quality and rule learning. 
Consequently,  Leacock  et  al (1996)  observe that 
WSD systems which operate directly upon context 
are: ?plagued  with  the  same  problem,  excellent  
precision but low recall?.
?Backing off? to more general feature classes 
through  say  lemmatization  or  part-of-speech 
tagging affords one way of alleviating sparseness 
(Joshi  &  Penstein-Ros?,  2009),  assuming  these 
features are pertinent to the task. Similar strategies 
include  the  use  of  dual-context  models  where 
immediate lexical features are backed up by more 
general  topical  ones  garnered  from  the  wider 
context  of  the  ambiguous  word  (Leacock  et  al, 
1996; Yarowsky, 1993).
Others have tackled the problem of sparseness 
without  recourse  to  generalized  feature  classes, 
45
through  the  exploitation  of  higher-order 
distributional  information.  Sch?tze  (1998) 
popularised  this  approach  within  the  WSD/WSI 
task. Rather than comparing contexts directly, it is 
the  distributional  similarity of  those features  (in 
the  corpus)  which  are  compared.  Specifically, 
Sch?tze  composed  context  vectors  by  summing 
the  vectors  for  every word  in  a  context,  where 
those  vectors  were  themselves  formed  from the 
total  of  word co-occurrence counts pertaining to 
every  instance  of  that  word  in  the  corpus.  The 
resultant  context  vectors  are  therefore 
comparatively  dense,  and  carry  second-order 
information  which  makes  otherwise  unlike 
contexts  more  amenable  to  comparison.  One 
contention  of  this  model  is  that  it  conflates  co-
occurrence information from all occurrences of a 
word in the corpus, regardless of their sense. The 
defence is  that  because the  actual  senses  of  the 
term instances which appear in the context of the 
ambiguous word will tend to be pertinent to that 
word?s  own  specific  sense,  it  is  that  common 
aspect of their respective conflated-sense vectors - 
when summed - which will dominant the resultant 
context  vector.  Purandare  &  Pedersen  (2001) 
performed a comparative study of disambiguation 
approaches  based  on  first-order  context,  and  on 
second order context as per Sch?tze (1998). They 
found  that  while  Sch?tze's  approach  provided 
gains  when data  was  limited,  when  the  training 
corpus was large enough that sufficient examples 
existed,  clustering  on  first  order  context  was 
actually  a  better  approach.  This  suggests  that 
while alleviating the data-sparseness problem, the 
practice of expanding context vectors in this way 
introduces a certain amount of noise, presumably 
by inappropriately over-smoothing the data.
Another  approach  to  the  sparse  data  problem 
which  was  also  part  of  Sch?tze's  framework  is 
dimensionality  reduction  by  Singular  Value 
Decomposition (SVD). In SVD the set of context 
features are analytically combined and reduced in 
a  manner  that  exploits  their  latent  similarities, 
whereafter  traditional  vector  measures  can  be 
used. Very similar techniques to both of those used 
by Sch?tze have been used for query expansion 
and  document  representation  in  information 
retrieval (Qiu & Frei, 1993; Xu et al 2007).
Several variations upon Sch?tze?s approach to 
WSD have been explored. Dagan et al(1995) and 
Karov & Edelman (1996)  both apply what  they 
call  ?similarity-based?  methods  which,  while 
markedly  different  on  the  surface  to  that  of 
Sch?tze, are similar in spirit and intent. Karov & 
Edelman,  for  example,  use  machine-readable 
dictionary glosses  as  opposed  to  corpus-derived 
co-occurrences,  and  apply  an  iterative 
bootstrapping approach to augment the available 
data, rather than strict second-order information.
Typically,  context  vectors  comprise  a 
component  (dimension)  for  each  designated 
feature  in  a word?s  context.  In a simple bag-of-
words  model  this  might  equate  to  one  vector 
component for each potential word that can appear 
in the context. For more sophisticated n-gram or 
dependency-based models, which attempt to better 
capture the structure inherent in the language, this 
number of vector components must be increased. 
The  more  sophisticated  the  language  model 
becomes therefore, the more acute the sparse data 
problem.  Techniques  like  SVD  can  reduce  this 
sparseness, but other issues remain. How does one 
weight  heterogeneous  features  when  forming  a 
vector?  How does  one interpret  vectors  reduced 
by SVD? Looking at the variety of approaches to 
tackling  the  problem,  we  might  be  forgiven  for 
questioning  whether  representing  meaning  as  a 
vector  of  context  features  is  in  fact  an  ideal 
starting point for semantic tasks such as WSD.
In the following section we describe a means of 
entirely detaching context  feature selection from 
vector  representation,  such  that  an  arbitrarily 
sophisticated  language  model  can  be  used  to 
generate  dense,  comparable vectors.  Necessarily, 
we  also  present  a  prototype  distributional 
language model that will serve as the basis of our 
investigations into this approach.
3 System & approach
 
3.1 Lexical Expectation Vectors
 
Theoretical  motivation.  The  motivation  behind 
the method presented herein comes both from the 
fields of semiotics and information theory. It is the 
notion that the ?meaning? of an utterance is not in 
the utterance itself, nor in its individual or typical 
context;  it  is  in  the  disparity between  our 
expectations  based  on  that  context,  and  the 
utterance (Noth, 1990; Chandler, 2002). Meaning 
in this sense can be seen as related to information 
(Attneave,  1959;  Shannon,  1948):  an  utterance 
which is entirely expected under a regime where 
speaker  and  interpreter  have  identical  frames  of 
reference  communicates  nothing;  conversely  an 
extremely  creative  utterance  is  laden  with 
information, and may have multiple non-obvious 
interpretations  (poetry  being  a  case  in  point  - 
Riffaterre,  1978).  This  idea  is  also  lent  some 
weight  by  psycholinguistic  experiments  which 
have  revealed  correlations  between  a  word's 
disparity  from  its  preceding  context,  and 
processing  times  in  human  subjects.  Similar 
insights have been employed in some very recent 
46
attempts  to  model  compositional  word  meaning 
Erk & Pad? (2008) and Thater et al(2009). These 
models augment word and context representations 
with  additional  vectors  encoding  the  selectional 
preferences  (expectations)  pertaining  to  the 
specific  syntactic/semantic  roles  of  the 
participating words. So far these systems rely upon 
parsed  corpora  and  have  been  tested  only  with 
very limited contexts (e.g. pairs of words having 
specific dependency relations).
Lexical  expectation  vectors  are  based  on  a 
similar  and  very  simple  premise:  rather  than 
building a vector for  a context by conflating the 
features which comprise the various context words 
(as per Schutze, 1998), we instead conflate all the 
words which might be expected to appear  within 
the  context (i.e.  in  the  headword  position). 
Consider  the  following short  context  taken from 
the SemEval-2007 task 2 dataset:
 Mr. Meador takes responsibility 
for <?> and property management .
 
The  strongest  twenty  elements  of  its 
expectation  vector  (as  generated  by  the  system 
described below) are shown in table 1. The figures 
represent some measure of confidence that a given 
word will be found in the headword position <?>. 
0.42 education 0.31 chancellor
0.38 forms 0.31 routine
0.36 housing 0.31 health
0.35 counselling 0.31 research
0.35 these 0.31 assessment
0.35 herself 0.3 detailed
0.34 database 0.3 management
0.33 injuries 0.3 many
0.32 advice 0.3 training
0.31 this 0.3 what
 
Table 1: An example of an expectation vector.
We make  the  supposition  that  when  the  vectors 
implied by the respective likelihoods of  all words 
implied by two contexts are identical, the contexts 
can be considered semantically equivalent.1 Note 
that the actual headword appearing in the context 
is not taken into consideration for the purposes of 
calculating expectation. In this example it occur at 
rank 62 out of  ~650,000, implying that its use in 
this context is not atypical.
Formal approach. For the purpose of our present 
research,  we  adopt  the  following  formal 
framework  for  generating  an  expectation  vector. 
1 Equivalent with respect to the head of the context. 
This is not the same as saying the passages have the same 
meaning, which requires recourse to compositionality.
Given  a  context  c,  each  component  of  the 
expectation vector  e arising from that  context  is 
estimated thusly:
  
 
Where j is a given word type in the lexicon, Oj 
is  the  set  of  all  observed contexts  of  that  word 
type in some corpus, ojk is the kth observed context 
of that word type, and sim(o,c) is some similarity 
measure between two contexts.
The process of generating an expectation vector 
can  be  thought  of  as  a  kind  of  transform from 
syntagmatic space, into  paradigmatic space. This 
mapping need not be trivial: items which are close 
in the syntagmatic space need not be close in the 
paradigmatic  space  and  vice-versa  (although  in 
practice we expect some considerable correlation 
by virtue  of  the  distributional  hypothesis). Note 
that although our work herein assumes a popular 
vector representation of context, the nature of the 
contexts and the similarity measure which operates 
upon them are not constrained in any way by the 
framework  given  above.  For  example  they  may 
equally well be dependency trees.
In the following section we outline a distance-
based language model comprising a context model 
and  a  similarity  metric  which  operates  upon  it. 
This  choice  of  model  allows  us  to  maintain  a 
purely  distributional  approach  without  suffering 
the  data-sparseness  associated  with  n-gram 
models.
3.2 Language model
 
Theoretical motivation. The precise relationship 
between  syntagmatic  and  paradigmatic  spaces 
implied  by  the  expectation  transform  depends 
upon  the  language  model  employed.  In  a  naive 
language  model  which  assumes  independence 
between  features,  this  mapping  can  be  fully 
represented by a square matrix over word types. 
Although such models are the mainstay of many 
systems  in  NLP,  adopting  the  toolset  of  an 
expection transform in such a case gains us little. 
Therefore  the  relevance  of  the  approach  to  the 
present  task  depends  wholly  upon  having  a 
suitably sophisticated language model.
Building on the work of Washtell  (2009) and 
Terra & Clarke (2004), a distance-based language 
model  is  used  in  the  present  work.  This  is  in 
contrast to the bag-of-words, n-gram, or syntactic 
dependency models more commonly described in 
the  NLP literature.  There  are  two  hypothesised 
advantages to this approach. Firstly, this avoids the 
issue  of  immediate  context  versus  wider  topical 
47
context.  While  immediate  context  is  generally 
accepted to  play a  dominant  role  in  WSD, both 
near and far context have been shown to be useful 
- the specific balance being somewhat dependent 
on  the  ambiguous  word  in  question  (Yarowsky, 
1993; Gale et al 1992; Leacock  et al  1996). As 
Ide & Veronis (1998) astutely observe, ?although 
a distinction is made between micro-context and  
topical  context  in  current  WSD  work,  it  is  not  
clear that this distinction is meaningful. It may be  
more  useful  to  regard  the  two as  lying  along a  
continuum,  and  to  consider  the  role  and  
importance of contextual information as a function 
of distance from the target.? This is precisely the 
assumption adopted herein.  Secondly,  the  use  of 
distance-based  information  alleviates  data 
sparseness. This is simply by virtue of the fact that 
all  words  types  in  a  document  form  part  of  a 
token's context (barring document boundaries, no 
cut-off  distance  is  imposed).  Moreover,  as  it  is 
specific  distance  information  which  is  being 
recorded,  rather  than  (usually  low)  frequency 
counts,  context  vector  components  and  the 
similarity  measurements  which  arise  from  them 
exhibit  good  precision.  Washtell  (2009)  showed 
that these properties of distance-based metrics lead 
to measurable gains in information extracted from 
a  corpus.  In  the  context  of  modelling  human 
notions  of  association  this  also  led  to  improved 
predictive power (Washtell & Markert, 2009).
 
Formal  approach. We  do  not  pre-compute  any 
statistical  representation  of  the  data  upon which 
our  language  model  draws.  With  available 
approaches  this  would  either  require  throwing 
away  a  large  number  of  potentially  relevant 
higher-order dependencies, or would otherwise be 
intractable.  Our  intuition  is  that  the  truest 
representation  of  the  language  encoded  in  the 
corpus  is  the  corpus  itself.  We  therefore  use  an 
indexed corpus directly for all queries.
We use the following as a prototype measure of 
structural  similarity  (see  section  3.1),  although 
note that others are by all means possible.
 
  
Where  o and  c are  context  vectors  whose  j 
components each specify the position in the text of 
the nearest occurrence (to the head of the context) 
of  a  given  word  type.  O and  C are  the  set  of 
indices of all non-zero (i.e. observed) components 
in o and c respectively. The head of the context is 
represented by an additional component in vectors 
o and  c, and is always treated as observed.  f is a 
further function of the positions of words p and q 
in both contexts. It returns a similarity score in the 
unit  range  designating  how similar  the  distance 
op?oq is to that of cp?cq.
The  more  consistent  the  relative  positions  of 
the various symbols comprising two contexts, the 
stronger their similarity. Note that the measure is 
additive:  symbols  which  occur  at  all  in  both 
contexts result in positive score contributions. We 
assume that  a context  is  usually incomplete  (i.e. 
that that which lies outside it is unknown, rather 
than non-existent).  The minimum operator in the 
denominator  (the  normalization  factor)  therefore 
ensures  that  words  present  only in  the  larger  of 
two contexts do not constitute negative evidence.
This  formulation  allows  for  considerable 
leeway in how word distances are represented and 
compared.  In  this  work  we  choose  to  treat 
distances  proportionately,  so  small  variations  in 
word  position  between  distant  (presumably 
topically related words)  are  tolerated better  than 
similar  distance variations  between neighbouring 
(more syntactico-semantically related) words.
4 Word Sense Disambiguation
 
A WSD system based on expectation vectors was 
ineligible in the SemEval-2010 WSI/WSD task by 
virtue  of  restrictions  disallowing  the  use  of  a 
corpus-based  language  model.  Instead,  this  task 
implicitly  encouraged  participants  to  focus  on 
context  feature  selection  and  clustering 
approaches.  It  seems  unlikely  to  us  that  these 
stages are where the major bottlenecks for WSD 
(or WSI) lie;  performing WSD on short contexts 
without  any  extra-contextual  information  (i.e. 
general  linguistic  or  domain  experience)  is 
arguably not a task which even humans could be 
expected to perform well. For this reason we have 
chosen  to  focus  initially  on  the  well  explored 
SemEval-2007 task 2 dataset.
4.1 Preliminary Evaluation
 
An  expectation  vector  was  produced  for  each 
training and test instance in the SemEval dataset 
by matching the headword?s context against that of 
each word position in the British National Corpus 
using  an  implementation  of  the  distance  based 
similarity  measure  outlined  in  section  3.2.  For 
matters of convenience, independent forwards and 
backwards  expectation  vectors  were  produced 
from the context preceding the headword and that 
following it,  and  their  elements  were  multiplied 
together  to  produce  the  final  vector.  No 
lemmatization  or  part-of-speech  tagging  was 
48
employed.  Neither  was  any  dimensionality 
reduction, each vector therefore having  ~650,000 
elements: one for each word type in the corpus.
Each test sample's vector was compared against 
all  corresponding  training  sample  vectors  using 
both cosine similarity and Euclidean distance2. In 
the MAX setups (see Table 2), each test case was 
assigned the  sense  of  the  single  nearest  training 
example according to the metric being used. In the 
CosOR  setup,  sense  scores  were  generated  by 
applying  a  probabilistic  OR  operation  over  the 
squared Cosine similarities of all relevant training 
examples3.  The  BaseMFS  setup  is  a  popular 
baseline in which the most frequent sense in the 
training  set  for  a  given  ambiguous  word  is 
attributed to every test case.
Nouns Verbs All
CosMAX 83.6 ?6.1 ?22.8 70.5?7.6 ?14.4 79.5 ?6.7 ?19.5
EucMAX 78.9 67.0 75.1
CosOR 83.5 66.1 78.0
BaseMFS 78.8 65.5 74.5
 
Table  2:  Recall  on  SemEval  WSD  task,  including 
relative performance gain (?)  and error reduction (?) 
over baseline for best setup (preliminary based on first 
25% of test cases).
 
Nouns Verbs All
BEST 86.8 ?7.3 ?30.9 76.2 ?0.0 ?0.0 81.6 ?3.7 ?13.6
BaseMFS 80.9 76.2 78.7
 
Table 3: Recall of best official SemEval WSD systems 
(Agirre & Soroa, 2007), showing relative performance 
gain and error reduction over baseline.
Table 2 shows the results for each test case in 
terms of recall,  for  all  words and for nouns and 
verbs separately. Also shown in table 3 are the best 
and baseline  figures for  the  official  entries from 
the Semeval workshop. Note that figures are not 
directly  comparable  between  tables  because  our 
preliminary results represent only the first 25% of 
the  SemEval  dataset  (hence  the  different 
baselines).  To  aid  some  comparison,  figures  are 
included  in  both  tables  indicating  the  relative 
increases in recall over the baseline, and relative 
2 Cosine Similarity captures the similarity between the 
relative  proportions  of  features  present  in  each  of  two 
vectors.  By  contrast,  Euclidean  Distance  compares  the 
actual values of corresponding features.
 
3 Although encountered rarely in the literature, squared 
Cosine Similarity is a pertinent quantity for tasks that go 
beyond simple ranking. As with Pearson's R2, it represents 
the degree  or  proportion  of  similarity  (consider  that  the 
square of an angle's cosine and that of its sine total 1).
reduction in error.  Note that the system employed 
here is not a word sense induction system as were 
most of those participating in the official SemEval 
task.  The setup of  the  tasks  however  allows for 
systems which perform poorly under the induction 
evaluation  to  perform  competitively  as 
disambiguation systems, so we are not precluded 
from making meaningful comparisons here.
5 Discussion and Future Direction
 
We have  presented  a  new type  of  wordspace 
model  based  on  vectors  derived  from  the 
predictions  of  a  language  model  applied  to  a 
context, rather than directly from the features of a 
context  itself.  We  have  conducted  a  preliminary 
investigation of the semantic modelling power of 
such vectors in the setting of a popular WSD task. 
The results  are  very encouraging.  Although it  is 
too  early  to  draw  hard  conclusions,  preliminary 
results suggest a performance at least comparable 
the present  state of  the art  on this  task.  What  is 
particularly noteworthy is that the approach taken 
here  seems  to  perform  equally  well  at 
discriminating  verbs  and  nouns.  Verbs  have 
traditionally proven very problematic: none of the 
six SemEval systems were able to improve upon 
the  verb  baseline.  More  recent  studies  have 
focused on discriminating nouns (Brody & Lapata, 
2009; Klapaftis & Manandhar, 2007).
Further gains might be expected by employing 
a  corpus  which  is  more  closely  matched  to  the 
material  being  disambiguated,  such  as  the  Wall 
Street Journal in the present case.
It is also worth noting that the system presented 
here  was  aided  only  by  an  untagged  un-
lemmatised  corpus,  without  the  use  of  any 
structured  knowledge  sources. While  we  expect 
that judicious use of lemmatization could improve 
these results, we believe the key to the quality of 
expectation  vectors  is  in  the  specific  predictive 
language  model  employed.  We  have  scarcely 
experimented  with  this,  opting  for  a  relatively 
untested  distance-based  model  throughout,  and 
choosing  instead  to  experiment  with  the 
application of different vector similarity measures. 
While  the  nature  of  the  language  model  used 
enables  it  to  capture  complex  interdependencies, 
and long-range dependencies, it is based on direct 
querying of a corpus and therefore does not scale 
at  all  well.  This  makes  its  use  in the  context  of 
most applications or with larger corpora untenable. 
Exploring  alternative  language  models  (drawing 
upon the copious research in this field) is therefore 
a focus for future research; the ability to do this 
highlights  one  of  the  major  advantages  of  this 
approach to modelling meaning.
49
References
Eneko Agirre, Airotr Soroa, 2007, SemEval-2007 
Task  02:  Evaluating  Word  Sense  Induction  and 
Discrimination Systems
Fred  Attneave,  Applications  of  Information 
Theory  to  Psychology:  A  Summary  of  Basic  
Concepts, Methods, and Results, Holt, New York
Samuel  Brody,  Mirella  Lapata,  2009,  Bayesian 
Word Sense Induction, Proceedings of EACL 2009, 
pages 103-111
Daniel  Chandler,  2002,  Semiotics:  The  Basics, 
p88, Routleadge
Ido  Dagan,  Shaul  Marcus,  Shaul  Markovitch, 
1995,  Contextual  Word  Similarity  and  Estimation 
from Sparse Data,  Proceedings of 31st ACL, pages 
164-171
Katrin  Erk,  Sebastian  Pad?,  2008,  A Structured 
Vector Space Model for  Word Meaning in Context, 
Proceedings on EMNLP 2008
William  Gale,  Kenneth  Church,  ,  David 
Yarowsky, 1992, A Method for Disambiguating Word 
Senses  in  a  Large  Corpus,  Computers  and  the  
Humanities, 26, 415-429
Zellig  Harris,  1954,  Distributional  structure. 
Word, 10(23), pages 146-162
Nancy  Ide,  Jean  Veronis,  1998,  Word  Sense 
Disambiguation: The State of The Art,
Mahesh  Joshi,  Carolyn  Penstein-Ros?,  2009, 
Generalizing  Dependency  Features  for  Opinion  
Mining,  Proceeding  of  the  ACL-IJCNLP  2009 
Conference Short Papers, pages 313-316
Yael  Karov, Shimon  Edelman,  1996,  Learning 
Similarity-Based  Word Sense  Disambiguation  from 
Sparse Data
Ioannis Klapaftis, Suresh Manandhar, 2008, Word 
Sense  Induction  using  Graphs  of  Collocations,  
Proceedings of ECAI 2008, pages 298-302
Claudia  Leacock,  Geoffrey  Towell,  Ellen  M. 
Voorhees,  1996,  Towards  Building  Contextual 
Representations  of  Word  Senses  Using  Statistical  
Models. In  B.  Boguraev  and  H.Pustejovsky  (eds) 
Corpus  Processing  for  Lexical  Acquisition.  MIT 
Press, pages 97-113
G.  A.  Miller,  W.  G  Charles,  1991.  Contextual 
correlates  of  semantic  similarity. Language  and 
Cognitive Processes, 6, 1-28.
Winfried  Noth,  1990,  Handbook  of  Semiotics, 
Indiana University Press,  p 142
Reinhard Rapp. 2002.  The computation of word 
associations:  comparing  syntagmatic  and 
paradigmatic approaches. In Proceedings of the 19th 
international  Conference  on  Computational 
Linguistics.
Hinrich Sch?tze,  1998,  Automatic  Word  Sense 
Discrimination,  Computational  Linguistics,  24(1), 
pages 97-123
Ted Pedersen, 2008,  Computational Approaches  
to  Measuring  the  Similarity  of  Short  Contexts:  A 
Review of Applications and Methods, to appear
Amruta  Purandare,  Ted  Pederson,  2004, Word 
sense discrimination by clustering contexts in vector  
and similarity spaces. Proceeding of the Conference 
on Computational Natural Language Learning, pages 
41-48
Yonggang  Qiu,  Hans-Peter  Frei,  1993, 
Proceedings of  the 16th annual  international  ACM 
SIGIR conference on Research and development in 
information retrieval table of contents, 160-169
Miachael  Riffaterre,  1978,  Semiotics  Of  Poetry, 
Methuen
Hae Jong Seo, Peyman Milanfar, 2009, Training-
free,  Generic  Object  Detection  using  Locally  
Adaptive Regression Kernels, IEEE Transactions on 
Pattern Analysis and Machine Intelligence, 99
Claude E Shannon, 1948, A Mathematical Theory 
of  Communication,  Bell  System Technical  Journal, 
vol. 27, pages 379-423, 623-656, 
Egidio  Terra,  Charles  L.  A.  Clarke,  2004, Fast  
computation of lexical affinity models , Proceedings 
of  the  20th  international  conference  on 
Computational Linguistics
Stefan Thater, Georgiana Dinu, Manfred Pinkal, 
2009, Ranking Paraphrases in Context, Proceedings 
of the 2009 Workshop on Applied Textual Inference, 
pages 44-47
Justin  Washtell.  2009.  Co-dispersion:  A 
windowless  approach  to  lexical  association. In 
Proceedings of EACL-2009.
Justin Washtell, Katja Markert. 2009. Comparing  
windowless  and  window-based  computational 
association  measures  as  predictors  of  syntagmatic  
human  associations. In  Proceedings  of  EMNLP-
2009, pages 628-637.
Xuheng Xu, Xiaodan Zhang, Xiaohua Hu, 2007, 
Using  Two-Stage  Concept-Based  Singular  Value  
Decomposition  Technique  as  a  Query  Expansion  
Strategy, AINAW'07
David  Yarowsky,  1993,  One  Sense  Per 
Collocation, Proceedings  on  the  Workshop  on 
Human Language Technology, pages 266-271
50
	ABCDEF	BBEAB	ABEAB