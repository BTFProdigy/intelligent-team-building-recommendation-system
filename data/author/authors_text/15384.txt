Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 196?197,
Vancouver, October 2005. c?2005 Association for Computational Linguistics
Generic parsing for multi-domain semantic interpretation
Myroslava Dzikovska?, Mary Swift?, James Allen?, William de Beaumont?
? Human Communication Research Centre
University of Edinburgh, 2 Buccleuch Place, Edinburgh EH8 9LW, United Kingdom
m.dzikovska@ed.ac.uk
? Department of Computer Science University of Rochester, Rochester, NY 14627-0226
{swift, james, wdebeaum}@cs.rochester.edu
1 Introduction
Producing detailed syntactic and semantic represen-
tations of natural language is essential for prac-
tical dialog systems such as plan-based assistants
and tutorial systems. Development of such systems
is time-consuming and costly as they are typically
hand-crafted for each application, and dialog corpus
data is more difcult to obtain than text. The TRIPS
parser and grammar addresses these issues by pro-
viding broad coverage of common constructions in
practical dialog and producing semantic representa-
tions suitable for dialog processing across domains.
Our system bootstraps dialog system development
in new domains and helps build parsed corpora.1
Evaluating deep parsers is a challenge (e.g., (Ka-
plan et al, 2004)). Although common bracketing
accuracy metrics may provide a baseline, they are
insufcient for applications such as ours that require
complete and correct semantic representations pro-
duced by the parser. We evaluate our parser on
bracketing accuracy against a statistical parser as a
baseline, then on a word sense disambiguation task,
and nally on full sentence syntactic and semantic
accuracy in multiple domains as a realistic measure
of system performance and portability.
2 The TRIPS Parser and Logical Form
The TRIPS grammar is a linguistically motivated
unication formalism using attribute-value struc-
1We thank 4 anonymous reviewers for comments.
This material is based on work supported by grants from
ONR #N000149910165, NSF #IIS-0328811, DARPA
#NBCHD030010 via subcontract to SRI #03-000223 and
NSF #E1A-0080124.
(SPEECHACT sa1 SA REQUEST :content e123)
(F e123 (:* LF::Fill-Container Load)
:Agent pro1 :Theme v1 :Goal v2)
(IMPRO pro1 LF::Person :context-rel *YOU*)
(THE v1 (SET-OF (:* LF::Fruit Orange)))
(THE v2 (:* LF::Vehicle Truck))
Figure 1: LF for Load the oranges into the truck.
tures. An unscoped neo-Davidsonian semantic rep-
resentation is built in parallel with the syntactic
representation. A sample logical form (LF) rep-
resentation for Load the oranges into the truck is
shown above. The TRIPS LF provides the neces-
sary information for reference resolution, surface
speech act analysis, and interpretations for a wide
variety of fragmentary utterances and conventional
phrases typical in dialog. The LF content comes
from a domain-independent ontology adapted from
FrameNet (Johnson and Fillmore, 2000; Dzikovska
et al, 2004) and linked to a domain-independent lex-
icon (Dzikovska, 2004).
The parser uses a bottom-up chart algorithm with
beam search. Alternative parses are scored with fac-
tors assigned to grammar rules and lexical entries by
hand, because due to the limited amount of corpus
data we have not yet been able to train a statistical
model that outperforms our hand-tuned factors.
3 Evaluation
As a rough baseline, we compared the bracketing
accuracy of our parser to that of a statistical parser
(Bikel, 2002), Bikel-M, trained on 4294 TRIPS
196
parse trees from the Monroe corpus (Stent, 2001),
task-oriented human dialogs in an emergency res-
cue domain. 100 randomly selected utterances were
held out for testing. The gold standard for evalu-
ation is created with the help of the parser (Swift
et al, 2004). Corpus utterances are parsed, and the
parsed output is checked by trained annotators for
full-sentence syntactic and semantic accuracy, reli-
able with a kappa score 0.79. For test utterances
for which TRIPS failed to produce a correct parse,
gold standard trees were manually constructed inde-
pendently by two linguists and reconciled. Table 1
shows results for the 100 test utterances and for the
subset for which TRIPS nds a spanning parse (74).
Bikel-M performs somewhat better on the bracket-
ing task for the entire test set, which includes utter-
ances for which TRIPS failed to nd a parse, but it
is lower on complete matches, which are crucial for
semantic interpretation.
All test utts (100) Spanning parse utts (74)
R P CM R P CM
BIKEL-M 79 79 42 89 88 54
TRIPS 77 79 65 95 95 86
Table 1: Bracketing results for Monroe test sets (R:
recall, P: precision, CM: complete match).
Word senses are an important part of the LF rep-
resentation, so we also evaluated TRIPS on word
sense tagging against a baseline of the most common
word senses in Monroe. There were 546 instances of
ambiguous words in the 100 test utterances. TRIPS
tagged 90.3% (493) of these correctly, compared to
the baseline model of 75.3% (411) correct.
To evaluate portability to new domains, we com-
pared TRIPS full sentence accuracy on a subset
of Monroe that underwent a fair amount of devel-
opment (Tetreault et al, 2004) to corpora of key-
board tutorial session transcripts from new domains
in basic electronics (BEETLE) and differentiation
(LAM) (Table 2). The only development for these
domains was addition of missing lexical items and
two grammar rules. TRIPS full accuracy requires
correct speech act, word sense and thematic role as-
signment as well as complete constituent match.
Error analysis shows that certain senses and sub-
categorization frames for existing words are still
Domain Utts Acc. Cov. Prec.
Monroe 1576 70% 1301 84.1%
BEETLE 192 50% 129 75%
LAM 934 42% 579 68%
Table 2: TRIPS full sentence syntactic and semantic
accuracy in 3 domains (Acc: full accuracy; Cov.: #
spanning parses; Prec: full acc. on spanning parses).
needed in the new domains, which can be rectied
fairly quickly. Finding and addressing such gaps is
part of bootstrapping a system in a new domain.
4 Conclusion
Our wide-coverage grammar, together with a
domain-independent ontology and lexicon, produces
semantic representations applicable across domains
that are detailed enough for practical dialog applica-
tions. Our generic components reduce development
effort when porting to new dialog domains where
corpus data is difcult to obtain.
References
D. Bikel. 2002. Design of a multi-lingual, parallel-
processing statistical parsing engine. In HLT-2002.
M. O. Dzikovska, M. D. Swift, and J. F. Allen. 2004.
Building a computational lexicon and ontology with
framenet. In LREC workshop on Building Lexical Re-
sources from Semantically Annotated Corpora.
M. O. Dzikovska. 2004. A Practical Semantic Represen-
tation For Natural Language Parsing. Ph.D. thesis,
University of Rochester.
C. Johnson and C. J. Fillmore. 2000. The FrameNet
tagset for frame-semantic and syntactic coding of
predicate-argument structure. In ANLP-NAACL 2000.
R. M. Kaplan, S. Riezler, T. H. King, J. T. Maxwell III,
A. Vasserman, and R. S. Crouch. 2004. Speed and
accuracy in shallow and deep stochastic parsing. In
HLT-NAACL 2004.
A. J. Stent. 2001. Dialogue Systems as Conversational
Partners. Ph.D. thesis, University of Rochester.
M. D. Swift, M. O. Dzikovska, J. R. Tetreault, and J. F.
Allen. 2004. Semi-automatic syntactic and semantic
corpus annotation with a deep parser. In LREC-2004.
J. Tetreault, M. Swift, P. Prithviraj, M. Dzikovska, and
J. Allen. 2004. Discourse annotation in the Monroe
corpus. In ACL workshop on Discourse Annotation.
197
Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 25?32,
New York City, June 2006. c?2006 Association for Computational Linguistics
Increasing the coverage of a domain independent dialogue lexicon with
VERBNET
Benoit Crabbe??, Myroslava O. Dzikovska?, William de Beaumont?, Mary Swift?
? ICCS-HCRC, University of Edinburgh, 2 Buccleuch Place, EH8 9LW, Edinburgh, UK
{bcrabbe,mdzikovs}@inf.ed.ac.uk
?Department of Computer Science, University of Rochester, Rochester NY, USA
{wdebeaum,swift}@cs.rochester.edu
Abstract
This paper investigates how to extend cov-
erage of a domain independent lexicon tai-
lored for natural language understanding.
We introduce two algorithms for adding
lexical entries from VERBNET to the lexi-
con of the TRIPS spoken dialogue system.
We report results on the efficiency of the
method, discussing in particular precision
versus coverage issues and implications
for mapping to other lexical databases.
1 Introduction
This paper explores how different lexicons can be
integrated with the goal of extending coverage of
a deep parser and semantic interpreter. Lexical
semantic databases (Kipper et al, 2000; Johnson
and Fillmore, 2000; Dorr, 1997) use a frame-based
model of lexical semantics. Each database groups
words in classes where predicative words and their
arguments are described. The classes are generally
organised in an inheritance structure. Each such
database can be used, among other things, to per-
form semantic interpretation. However, their actual
structures are quite different, reflecting different un-
derlying methodological approaches to lexical de-
scription, and this results in representation that are
not directly compatible. Since no such database has
full coverage of English, it is worth combining them
in order to get a lexicon with better coverage and a
unified representation for English.
We explore the issues related to merging verb
descriptions from two lexical databases, which
have both syntactic and semantic incompatibilities,
and compare two techniques for aligning semantic
classes and the syntax-semantics mappings between
them. The resulting lexicon is to be used in precise
interpretation tasks, so its consistency and accuracy
are a high priority. Thus, though it is possible to gen-
erate lexical entries automatically (Kwon and Hovy,
2006; Swift, 2005), we use a semi-automatic method
in which an expert hand-checks the automatically
generated entries before adding them to the lexicon.
Therefore, our goal is to maximise the number of
new useful entries added to the lexicon while min-
imising the number of entries that are discarded or
hand-edited.
We take the mapping between the TRIPS lexicon
and the VERBNET lexical database as a case study
for our experiment. The TRIPS lexicon is used to-
gether with a parser to provide a natural language
understanding component for several dialogue ap-
plications in different domains. It outputs highly de-
tailed semantic representations suitable for complex
dialogue tasks such as problem-solving and tutoring
dialogue, inter alia. An essential feature of TRIPS
is the integration of a detailed lexical semantic rep-
resentation, semantic classes and theta role assign-
ments in the parsing process.
Semantic types and role labelling are helpful in
both deep (Tetreault, 2005) and shallow interpreta-
tion tasks (Narayanan and Harabagiu, 2004). TRIPS
provides a convenient test case because its grammar
is already equipped with the formal devices required
to build up a frame-based semantic representation
including this information.1
1While wide coverage grammars such as the English Re-
25
We chose VERBNET to extend the TRIPS lexicon
because it includes a detailed syntax-semantic map-
pings, thus providing a more convenient interface to
the syntactic component of the grammar than lexi-
cons where this connection is left unclear, such as
FRAMENET. However the methods described here
are designed to be reusable for merging other lexi-
cal databases, in particular we intend to experiment
with FRAMENET in the near future.
The plan of the paper is as follows: we first de-
scribe the target lexicon (Section 2) and the source
lexicon (Section 3) for our experiment before de-
scribing the methodology for integration (Section 4).
We finally present an evaluation of the techniques in
Section 5.
2 The TRIPS Lexicon
The TRIPS lexicon (Dzikovska, 2004) is the target
of the mapping procedure we describe in Section
4. It includes syntactic and semantic information
necessary to build semantic representations usable
in dialogue systems. The TRIPS parser is equipped
with a fairly detailed grammar, but a major restric-
tion on coverage in new domains is often lack of
lexical information. The lexicon used in our eval-
uation comprised approximately 700 verb lemmas
with 1010 senses (out of approximately 2500 total
word senses, covering both open- and closed-class
words). The lexicon is designed for incremental
growth, since the lexical representation is domain-
independent and the added words are then re-used
in new domains.
A graphical representation of the information
stored in the TRIPS lexicon and used in parsing is
shown in Figure 1. The lexicon is a list of canon-
ical word entries each of which is made of a set
of sense definitions comprised of a LF type and a
syntax-semantic template.
Semantic classes (LF types) in the TRIPS lexi-
con are organised in a domain-independent ontol-
ogy (the LF ontology). The LF Ontology was orig-
inally based on a simplified version of FRAMENET
source Grammar (Copestake and Flickinger, 2000) build deep
semantic representations which account for scoping and tempo-
ral structure, their lexicons do not provide information related
to word senses and role labels, in part due to the additional dif-
ficulty involved building a wide coverage lexicon with the nec-
essary lexical semantic information.
The tourists admired the paintings
LSUBJ LOBJ
LF::Experiencer-Emotion
LF::Experiencer LF::Theme
Figure 1: Information in the TRIPS word sense def-
inition for mapping between syntactic and semantic
roles.
(Baker et al, 1998; Dzikovska et al, 2004), with
each LF type describing a particular situation, object
or event and its participants. Syntax-Semantics Tem-
plates (or templates) capture the linking between the
syntax and semantics (LF type and semantic roles)
of a word. The semantic properties of an argument
are described by means of a semantic role assigned
to it and selectional restrictions.2
The TRIPS grammar contains a set of indepen-
dently described lexical rules, such as the passive or
dative shift rules, which are designed to create non-
canonical lexical entries automatically, while pre-
serving the linking properties defined in the canoni-
cal entry.
In this context adding an entry to the lexicon re-
quires determining both the list of LF types and
the list of templates for canonical contexts, that is,
the list of mappings between a logical frame and a
canonical subcategorization frame.
3 VERBNET
VERBNET (Kipper et al, 2000) provides an actual
implementation of the descriptive work carried out
by Levin (1993), which has been extended to cover
prepositional constructions and corpus-based sub-
categorization frames (Kipper et al, 2004; Kipper
et al, 2006).
VERBNET is a hierarchical verb lexicon in which
verbs are organised in classes. The fundamental
assumption underlying the classification is that the
members of a given class share a similar syntactic
2The selectional restrictions are domain independent and
specified using features derived from EuroWordNet (Vossen,
1997; Dzikovska et al, to appear).
26
behaviour, that is, they pattern in the same set of al-
ternations, and are further assumed to share common
semantic properties.3
VERBNET classes are organised in an inheritance
hierarchy. Each class includes a set of members
(verbs), a set of (subcategorization) frames and a set
of semantic descriptions. Frames are descriptions of
the linking between syntax and semantics for that
class. Each frame argument contains a syntactic cat-
egory augmented with syntactic features, and a cor-
responding thematic role. Each class also specifies
a set of additional selectional restriction features.
VERBNET further includes for each class a semantic
description stated in terms of event semantics, that
we ignore in this paper.
4 Methodology
The methodology used in the mapping process con-
sists of two steps. First we translate the source,
VERBNET, to an intermediate representation best
suited for parsing purposes. Second this interme-
diate representation is translated to a specific tar-
get, here the TRIPS lexicon. At this stage of our
work, the translation from VERBNET to the inter-
mediate representation mainly concerns normalising
syntactic information coded in VERBNET to make
them easier to handle for parsing purposes, and the
translation from the intermediate representation to
the TRIPS lexicon focuses on translating semantic
information. This architecture is best understood
as a cross compilation scheme: we further expect
to reuse this intermediate representation for produc-
ing outputs for different parsers and to accept inputs
from other lexical databases such as FRAMENET.
4.1 The intermediate representation
The intermediate representation is a lexical repre-
sentation scheme mainly tailored for parsing: in this
context, a lexicon is thus made of a set of words,
each of which consists of a lemma, a syntactic cate-
gory and a list of sense definitions. Each sense def-
inition has a name and a frame. The name of the
sense definition is actually the name of the VERB-
NET class it derives from. The frame of the sense
definition has a list of arguments, each of which con-
3In practice, it turns out that there are exceptions to that hy-
pothesis (Kipper, 2005).
sists of a syntactic category, a syntactic function, a
thematic role and possibly a set of prepositions and
syntactic feature structures.
The content of the intermediate representation
uses the following data categories. Syntactic cate-
gories, thematic roles and features are those used in
VERBNET. We further add the syntactic functions
described in (Carroll et al, 1998). Specifically, two
categories left implicit in VERBNET by the use of
feature structures are made explicit here: preposi-
tional phrases (PP) and sentential arguments (S).
Each argument described in a sense definition
frame is marked with respect to its coreness status.
The coreness status aims to provide the lexicon with
an operational account for common discrepancies
between syntax and semantics descriptions. This
status may be valued as core, non-core or non-sem
and reflects the status of the argument with respect
to the syntax-semantics interface.
Indeed, there is a methodological pitfall concern-
ing the mapping between thematic roles and syntac-
tic arguments: semantic arguments are not defined
following criteria identical to those for syntactic ar-
guments. The main criterion for describing semantic
arguments is their participation in the event, situa-
tion, object described by the frame whereas the cri-
terion for describing syntactic arguments is based on
the obligatoriness or the specificity of the argument
with respect to the verb. The following example il-
lustrates such conflicts:
(1) a. It is raining
b. I am walking to the store
The It in example (1a) plays no role in the seman-
tic representation, but is obligatory in syntax since
it fills a subject position. The locative PP in exam-
ple (1b) is traditionally not treated as an argument
in syntax, rather as a modifier, hence it does not fill
a complement position. Such phrases are, however,
classified in VERBNET as part of the frames. Fol-
lowing this, we distinguish three kinds of arguments:
non-sem as in (1a) are syntactic-only arguments with
no semantic contribution. non-core as in (1b) con-
tribute to the semantics but are not subcategorized.
27
4.2 From VERBNET to the intermediate
representation
Given VERBNET as described in Section 3 and the
intermediate representation we described above, the
translation process requires mainly (1) to turn the
class based representation of VERBNET into a list-
of-word based representation (2) to mark arguments
for coreness (3) to merge some arguments and (4) to
annotate arguments with syntactic functions.
The first step is quite straightforward. Every
member m of every VERBNET class C is associated
with every frame of C yielding a new sense defini-
tion in the intermediate representation for m.
In the second step, each argument receives a core-
ness mark. Arguments marked as non-core are ad-
verbs, and prepositional phrases introduced by a
large class of prepositions (e.g. spatial preposi-
tions). The arguments marked as non-sem are those
with an impersonal it, typically members of the
weather class. All other arguments listed in VERB-
NET frames are marked as core.
In the third step, syntactic arguments are merged
to correspond better to phrase-based syntax.4 For
example, the VERBNET encoding of subcategoriza-
tion frames splits prepositional frames on two slots:
one for the preposition and one for the noun phrase.
We have merged the two arguments, to become a
PP, also merging their syntactic and semantic fea-
tures. Other merges at this stage include merging
possessive arguments such as John?s brother which
are described with three argument slots in VERB-
NET frames. We merged them as a single NP.
The last step in the translation is the inference of
syntactic functions. It is possible to reasonably infer
syntactic functions from positional arguments and
syntactic categories by (a) considering the follow-
ing oblicity order over the set of syntactic functions
used in the intermediate representation:5
(2) NCSUBJ < DOBJ < OBJ2 < {IOBJ, XCOMP,CCOMP}
4We also relabel some categories for convenience without
affecting the process. For instance, VERBNET labels both
clausal arguments and noun phrases with the category NP. The
difference is made with syntactic features. We take advantage
of the features to relabel clausal arguments with the category S.
5This order is partial, such that the 3 last functions are un-
ordered wrt to each other. These functions are the subset of the
functions described in (Carroll et al, 1998) relevant for han-
dling VERBNET data.
and by (b) considering this problem as a transduc-
tion problem over two tapes. One tape being the tape
of syntactic categories and the second the tape of
syntactic functions. Given that, we designed a trans-
ducer that implements a category to function map-
ping. It implements the above oblicity order together
with an additional mapping constraint: nouns can
only map to NCSUBJ, DOBJ, prepositional phrases
can only map to OBJ2, IOBJ, infinitival clauses can
only map to XCOMP and finite clauses to CCOMP.
We further added refinements to account for
frames that do not encode their arguments follow-
ing the canonical oblicity order: for dealing with
dative shift encoded in VERBNET with two differ-
ent frames and for dealing with impersonal contexts,
so that we eventually used the transducer in Figure
2. All states except 0 are meant to be final. The
transduction operates only on core and non-sem ar-
guments, non-core arguments are systematically as-
sociated with an adjunct function. This transducer is
capable of correctly handling the majority of VERB-
NET frames, finding a functional assignment for
more than 99% of the instances.
0 1
2
NP:ncSubj
NP:
? 3
PP: Dobj, Iobj
PP:Iobj
PP:Iobj
S[inf]: Xcomp
S[fin]:Ccomp
S[inf]: Dobj, Xcomp
S[fin]: Dobj, Ccomp
S[fin
]:Cc
omp
S[in
f]:Xc
omp
it[+be]:SUBJ
NP: Iobj,Obj2
4
?:Dobj
Adj:Adj
Adj:Adj
Adj:Adj
Figure 2: A transducer for assigning syntactic func-
tions to ordered subcategorization frames
4.3 From Intermediate representation to TRIPS
Recall that a TRIPS lexical entry is comprised of an
LF type with a set of semantic roles and a template
representing the mappings from syntactic functions
to semantic roles. Converting from our intermedi-
ate representation to the TRIPS format involves two
steps:
28
? For every word sense, determine the appropri-
ate TRIPS LF type
? Establish the correspondence between VERB-
NET and TRIPS syntactic and semantic argu-
ments, and generate the appropriate mapping in
the TRIPS format.
We investigated two strategies to align semantic
classes (VERBNET classes and TRIPS LFs). Both
use a class intersection algorithm as a basis for deci-
sion: two semantic classes are considered a match if
they are associated with the same lexical items.
The intersection algorithm takes advantage of the
fact that both VERBNET and TRIPS contain lexical
sets. A lexical set for VERBNET is a class name
and the set of its members, for TRIPS it is an LF
type and the set of words that are associated with it
in the lexicon. Our intersection algorithm computes
the intersection between every VERBNET lexical set
and every TRIPS lexical set. The sets which intersect
are then considered as candidate mappings from a
VERBNET class to a TRIPS class.
However, this technique produces many 1-word
class intersections, and leads to spurious entries. We
considered two ways of improving precision: first
by requiring a significantly large intersection, sec-
ond by using syntactic structure as a filter. We dis-
cuss them in turn.
4.4 Direct Mapping Between Semantic
Representations
The first technique which we tried for mapping
between TRIPS and VERBNET semantic represen-
tations is to map the classes directly. We con-
sider all candidate mappings between the TRIPS
and VERBNET classes, and take the match with the
largest intersection. We then align the semantic roles
between the two classes and produce all possible
syntax-semantics mappings specified by VERBNET.
This technique has the advantage of providing the
most complete set of syntactic frames and syntax-
semantics mappings which can be retrieved from
VERBNET. However, since VERBNET lists many
possible subcategorization frames for every word,
guessing the class incorrectly is very expensive, re-
sulting in many spurious senses generated. We use a
class intersection threshold to improve reliability.
VERBNET ROLE TRIPS ROLES
Theme LF::THEME, LF::ADDRESSEE,
LF::ALONG, LF::ENTITY
Cause LF::CAUSE, LF::THEME
Experiencer LF::EXPERIENCER, LF::COGNIZER
Source LF::FROM-LOC, LF::SOURCE,
LF::PATH
Destination LF::GOAL, LF::TO-LOC
Recipient LF::RECIPIENT, LF::ADDRESSEE,
LF::GOAL
Instrument LF::INSTRUMENT
Table 1: Sample VERBNET to TRIPS role mappings
At present, we count an LF type match as suc-
cessfully guessed if there is an intersection in lex-
ical entries above the threshold (we determined 3
words as a best value by finding an optimal balance
of precision/recall figures over a small gold-standard
mapping set). Since the classes contain closely re-
lated items, larger intersection means a more reliable
mapping. If the VERBNET class is not successfully
mapped to an LF type then no TRIPS lexical entry is
generated.
Once the correspondence between the LF type
and the VERBNET class has been established, se-
mantic arguments have to be aligned between the
two classes. We established a role mapping table
(a sample is shown in Table 1), which is an extended
version of the mapping from Swift (2005). The role
mapping is one to many (each VERBNET role maps
to 1 to 8 TRIPS roles), however, since the appropriate
LF type has been identified prior to argument map-
ping, we usually have a unique mapping based on
the roles defined by the LF type.6
Once the classes and semantic roles have been
aligned, the mapping of syntactic functions between
the intermediate representation and TRIPS syntax
is quite straightforward. Functional and category
mappings are one to one and do not raise specific
problems. Syntactic features are also translated into
TRIPS representation.
To illustrate the results obtained by the automatic
mapping process, two of the sense definitions gener-
ated for the verb relish are shown in Figure 3. The
TRIPS entries contain references to the class descrip-
tion in the TRIPS LF ontology (line introduced by
6In rare cases where more than 1 correspondence is possible,
we are using the first value in the intersection as the default.
29
;; entries
(relish
(SENSES
((EXAMPLE "The tourists admired the paintings")
(LF-PARENT LF::EXPERIENCER-EMOTION)
(TEMPL VN-EXPERIENCER-THEME-TEMPL-84))
((EXAMPLE "The children liked that the clown had a red nose")
(LF-PARENT LF::EXPERIENCER-EMOTION)
(TEMPL VN-EXPERIENCER-THEME-XP-TEMPL-87))
))
;;Templates
(VN-EXPERIENCER-THEME-TEMPL-84
(ARGUMENTS
(LSUBJ (% NP) LF::EXPERIENCER)
(LOBJ (% NP) LF::THEME)
))
(VN-EXPERIENCER-THEME-XP-TEMPL-87
(ARGUMENTS
(LSUBJ (% NP) LF::EXPERIENCER)
(LCOMP (% CP (vform fin) (ctype s-finite)) LF::THEME)
))
Figure 3: Sample TRIPS generated entries
LF-PARENT) and to a template (line introduced by
TEMPL) generated on the fly by our syntactic con-
version algorithm. The first sense definition and
template in Figure 3 represent the same information
shown graphically in Figure 1. Each argument in a
template is assigned a syntactic function, a feature
structure describing its syntactic properties, and a
mapping to a semantic role defined in the LF type
definition (not depicted here).
4.5 Filtering with syntactic structure
The approach described in the previous section pro-
vides a fairly complete set of subcategorization
frames for each word, provided that the class corre-
spondence has been established successfully. How-
ever, it misses classes with small intersections and
classes for which some but not all members match
(see Section 5 for discussion). To address these is-
sues we tried another approach that automatically
generates all possible class matches between TRIPS
and VERBNET, again using class member intersec-
tion, but using the a TRIPS syntactic template as an
additional filter on the class match. For each poten-
tial match, a human evaluator is presented with the
following:
{confidence score
{verbs in TRIPS-VN class intersection}/
LF-type TRIPS-template
=> VN-class: {VN class members}}
The confidence score is based on the number of
verbs in the intersection, weighted by taking into ac-
count the number of verbs remaining in the respec-
tive TRIPS and VERBNET classes. The template
used for filtering is taken from all templates that oc-
cur with the TRIPS words in this intersection (one
match per template is generated for inspection). For
example:
93.271%
{clutch,grip,clasp,hold,wield,grasp}/
lf::body-manipulation agent-theme-xp-templ
=> hold-15.1-1: {handle}
This gives the evaluator additional syntactic in-
formation to make the judgement on class intersec-
tions. The evaluator can reject entire class matches,
or just individual verbs from the VERBNET class
which don?t quite fit an otherwise good match. We
only used the templates already in TRIPS (those cor-
responding to each of the word senses in the inter-
section) to avoid overwhelming the evaluator with a
large number of possibly spurious template matches
resulting from an incorrect class match. This tech-
nique allows us to pick up class matches based on a
single member intersection, such as:
7.814%
{swallow}/
lf::consume agent-theme-xp-templ
=> gobble-39.3-2: {gulp,guzzle,quaff,swig}
However, the entries obtained are not guaranteed
to cover all frames in VERBNET because if a given
alternation is not already covered in TRIPS, it is not
derived from VERBNET with this method.
5 Evaluation and discussion
Since our goal in this evaluation is to balance the
coverage of VERBNET with precision, we corre-
spondingly evaluate along those two dimensions.
For both techniques, we evaluate how many word
senses were added, and the number of different
words defined and VERBNET classes covered. As a
measure of precision we use, for those entries which
were retrieved, the percentage of those which could
be taken ?as is? (good entries) and the percentage of
entries which could be taken with minor edits (for
example, changing an LF type to a more specific
subclass, or changing a semantic role in a template).
The results of evaluation are shown in Table 2.7
Since for mapping with syntax filtering we con-
sidered all possible TRIPS-VERBNET intersections,
it in effect presents an upper bound the number of
words shared between the two databases. Further
7
?nocos? table rows exclude the other cos VERBNET class,
which is exceptionally broad and skews evaluation results.
30
Class mapping Mapping with syntax filtering
Type Total Good Edit Bad %usable Total Good Edit Bad %usable
Sense 3075 1000 196 1879 0.39 11036 1688 87 9261 0.16
Word 744 274 98 372 0.5 2138 1211 153 714 0.64
Class 15 10 1 4 0.73 198 129 2 67 0.66
Sense-nocos 1136 654 196 286 0.75 7989 1493 87 6409 0.20
Word-nocos 422 218 98 106 0.75 1763 1059 153 491 0.69
Class-nocos 14 9 1 4 0.71 197 128 2 67 0.65
Table 2: Evaluation results for different acquisition techniques. %usable = (good + editable) / bad?.
extension would require extending the TRIPS LF
Ontology with additional types to cover the miss-
ing classes. As can be seen from this table, 65%
of VERBNET classes have an analogous class in
TRIPS. At the same time, there is a very large num-
ber of class intersections possible, so if all possible
intersections are generated, only a very small per-
centage of generated word senses (16%) is usable in
the combined system. Thus developing techniques
to filter out the irrelevant senses and class matches
is important for successful hand-checking.
Our evaluation also shows that while class inter-
section with thresholding provides higher precision,
it does not capture many words and verb senses. One
reason for this is data sparsity. TRIPS is relatively
small, and both TRIPS and VERBNET contain a
number of 1-word classes, which cannot be reliably
mapped without human intervention. This problem
can be alleviated in part as the size of the database
grows. We expect this technique to have better recall
when the combined lexicon is used to merge with a
different lexical database such as FRAMENET.
However, a more difficult issue to resolve is dif-
ferences in class structure. VERBNET was built
around the theory of syntactic alternations, while
TRIPS used FRAMENET structure as a starting point,
simplifying the role structure to make connection
to parsing more straightforward (Dzikovska et al,
2004). Therefore TRIPS does not require that all
words associated with the same LF type share syn-
tactic behaviour, so there are a number of VERB-
NET classes with members which have to be split
between different TRIPS classes based on additional
semantic properties. 70% of all good matches in the
filtering technique were such partial matches. This
significantly disadvantages the thresholding tech-
nique, which provides the mappings on class level,
not allowing for splitting word entries between the
classes.
We believe that the best solution can be found
by combining these two techniques. The thresh-
olding technique could be used to establish reliable
class mappings, providing classes where many en-
tries could be transferred ?as is?. The mapping can
then be examined to determine incorrect class map-
pings as well as the cases where classes should be
split based on individual words. For those entries
judged reliable in the first pass, the syntactic struc-
ture can be transferred fully and quickly, while the
syntactic filtering technique, which requires more
manual checking, can be used to transfer other en-
tries in the intersections where class mapping could
not be established reliably.
Establishing class and member correspondence is
a general problem with merging any two semantic
lexicons. Similar issues have been noted in compar-
ing FRAMENET and VERBNET (Baker and Ruppen-
hofer, 2002). A method recently proposed by Kwon
and Hovy (2006) aligns words in different seman-
tic lexicons to WordNet senses, and then aligns se-
mantic roles based on those matches. Since we are
designing a lexicon for semantic interpretation, it is
important for us that all words should be associated
with frames in a shared hierarchy, to be used in fur-
ther interpretation tasks. We are considering using
this alignment technique to further align semantic
classes, in order to produce a shared database for in-
terpretation covering words from multiple sources.
6 Conclusion
In this paper, we presented a methodology for merg-
ing lexicons including syntactic and lexical semantic
31
information. We developed a model based on cross-
compilation ideas to provide an intermediate repre-
sentation which could be used to generate entries
for different parsing formalisms. Mapping semantic
properties is the most difficult part of the process,
and we evaluated two different techniques for estab-
lishing correspondence between classes and lexical
entries, using TRIPS and VERBNET lexicons as a
case study. We showed that a thresholding technique
has a high precision, but low recall due to inconsis-
tencies in semantic structure, and data sparsity. We
can increase recall by partitioning class intersections
more finely by filtering with syntactic structure. Fur-
ther refining the mapping technique, and using it
to add mappings to other lexical databases such as
FRAMENET is part of our ongoing work.
Acknowledgements
We thank Karin Kipper for providing us useful doc-
umentation on the VERBNET feature system, and
Charles Callaway for technical help with the final
version. This material is based on work supported
by grants from the Office of Naval Research un-
der numbers N000140510048 and N000140510043,
from NSF #IIS-0328811, DARPA #NBCHD030010
via subcontract to SRI #03-000223 and NSF #E1A-
0080124.
References
C. F. Baker and J. Ruppenhofer. 2002. Framenet?s
frames vs. Levin?s verb classes. In Proceedings of the
28th Annual Meeting of the Berkeley Linguistics Soci-
ety, pages 27?38.
C. F. Baker, C. Fillmore, and J. B. Lowe. 1998. The
Berkeley Framenet project. In Proceedings of CoLing-
ACL, Montreal.
J. Carroll, E. Briscoe, and A. Sanfilippo. 1998. Parser
evaluation: A survey and a new proposal. In Proceed-
ings of LREC-98.
A. Copestake and D. Flickinger. 2000. An open
source grammar development environment and broad-
coverage English grammar using HPSG. In Proceed-
ings of LREC-2000, Athens, Greece.
B. Dorr. 1997. Large-scale dictionary construction
for foreign language tutoring and interlingual machine
translation. Machine Translation, 12(4):271?375.
M. O. Dzikovska, M. D. Swift, and J. F. Allen. 2004.
Building a computational lexicon and ontology with
FrameNet. In Proceedings of LREC workshop on
Building Lexical Resources from Semantically Anno-
tated Corpora, Lisbon.
M. O. Dzikovska, M. D. Swift, and J. F. Allen. to ap-
pear. Customizing meaning: Building domain-specific
semantic representations from a generic lexicon. In
H. Bunt, editor, Computing Meaning, Volume 3, Stud-
ies in Linguistics and Philosophy. Kluwer.
M. O. Dzikovska. 2004. A Practical Semantic Repre-
sentation for Natural Language Parsing. Ph.D. thesis,
University of Rochester, Rochester NY.
C. Johnson and C. J. Fillmore. 2000. The FrameNet
tagset for frame-semantic and syntactic coding of
predicate-argument structure. In Proceedings ANLP-
NAACL 2000, Seattle, WA.
K. Kipper, H. T. Dang, and M. Palmer. 2000. Class-
based construction of a verb lexicon. In Proceedings
of AAAI, Austin.
K. Kipper, B. Snyder, and M. Palmer. 2004. Us-
ing prepositions to extend a verb lexicon. In Pro-
ceedings of HLT-NAACL 2004 Workshop on Compu-
tational Lexical Semantics, pages 23?29, Boston, MA.
K. Kipper, A. Korhonen, N. Ryant, and M. Palmer. 2006.
Extending Verbnet with novel verb classes. In Pro-
ceedings of LREC-2006.
K. Kipper. 2005. Verbnet: A broad coverage, compre-
hensive verb lexicon. Ph.D. thesis, University of Penn-
sylvania.
N. Kwon and E. H. Hovy. 2006. Integrating semantic
frames from multiple sources. In A. F. Gelbukh, edi-
tor, CICLing, volume 3878 of Lecture Notes in Com-
puter Science, pages 1?12. Springer.
B. Levin. 1993. English Verb Classes and Alternations.
The University of Chicago Press.
S. Narayanan and S. Harabagiu. 2004. Question answer-
ing based on semantic structures. In Proceedings of
International Conference on Computational Linguis-
tics (COLING 2004), Geneva, Switzerland.
M. Swift. 2005. Towards automatic verb acquisition
from Verbnet for spoken dialog processing. In Pro-
ceedings of Interdisciplinary Workshop on the Identi-
fication and Representation of Verb Features and Verb
Classes, Saarbruecken, Germany.
J. Tetreault. 2005. Empirical Evaluations of Pronoun
Resolution. Ph.D. thesis, University of Rochester.
P. Vossen. 1997. Eurowordnet: A multilingual database
for information retrieval. In Proceedings of the Delos
workshop on Cross-language Information Retrieval.
32
Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 146?154,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
Building Timelines from Narrative Clinical Records: Initial Results 
Based-on Deep Natural Language Understanding
Hyuckchul Jung, James Allen, Nate Blaylock, Will de Beaumont, 
Lucian Galescu, Mary Swift
Florida Institute for Human and Machine Cognition
40 South Alcaniz Street, Pensacola, Florida, USA
{hjung,blaylock,jallen,wbeaumont,lgalescu,mswift}@ihmc.us
Abstract
We present an end-to-end system that proc-
esses narrative clinical records, constructs 
timelines for the medical histories of pa-
tients, and visualizes the results. This work 
is motivated by real clinical records and 
our general approach is based on deep se-
mantic natural language understanding.
1 Introduction
It is critical for physicians and other healthcare 
providers to have complete and accurate knowl-
edge of the medical history of patients that  in-
cludes disease/symptom progression over time and 
related tests/treatments in chronological order. 
While various types of clinical records (e.g., dis-
charge summaries, consultation notes, etc.) contain 
comprehensive medical history information, it  can 
be often challenging and time-consuming to com-
prehend the medical history of patients when the 
information is stored in multiple documents in dif-
ferent  formats and the relations among various 
pieces of information is not explicit.
For decades, researchers have investigated tem-
poral information extraction and reasoning in the 
medical domain (Zhou and Hripcsak, 2007). How-
ever, information extraction in the medical domain 
typically relies on shallow NLP techniques (e.g., 
pattern matching, chunking, templates, etc.),  and 
most temporal reasoning techniques are based on 
structured data with temporal tags (Augusto, 2005; 
Stacey and McGregor, 2007).
In this paper, we present our work on develop-
ing an end-to-end system that  (i) extracts interest-
ing medical concepts (e.g., medical conditions/
tests/treatments), related events and temporal ex-
pressions from raw clinical text records, (ii) con-
structs timelines of the extracted information; and 
(iii) visualizes the timelines, all using deep seman-
tic natural language understanding (NLU). 
Our deep NLU system extracts rich semantic 
information from narrative text records and builds 
logical forms that  contain ontology types as well as 
linguistic features. Ontology- and pattern-based 
extraction rules are used on the logical forms to 
retrieve time points/intervals, medical concepts/
events and their temporal/causal relations that are 
pieced together by our system?s temporal reasoning 
component to create comprehensive timelines.
Our system is an extension to a well-proven 
general-purpose NLP system (Allen et  al., 2000) 
rather than a system specialized to the clinical do-
main, and the temporal reasoning in our system is 
tightly integrated into the NLP system?s deep se-
mantic analysis. We believe this approach will al-
low us to process a broader variety of documents 
and complex forms of temporal expressions.
In the coming sections, we first present a moti-
vating example, a real clinical record of a cancer 
patient. Next, we give an overview of our NLU 
system including how medical ontology is inte-
grated into our system. The overview section is 
followed by detailed description of our information 
extraction and temporal reasoning approach. Then, 
we discuss our results and conclude.
2 Motivating Example
Our work is carried out as a collaboration with the 
Moffitt  Cancer Center (part of the NCI Compre-
hensive Cancer Centers), who have provided us 
with access to clinical records for over 1500 pa-
tients. Figure 1 shows a (de-identified) ?History of 
Present Illness? (HPI) section of a Thoracic Con-
sultation Note from this data set. 
146
The text of this section provides a very detailed 
description of what  problems/tests/treatments an 
anonymous cancer patient went  through over a pe-
riod. Such narrative text is common in clinical 
notes and, because such notes are carefully created 
by physicians, they tend to have only relevant in-
formation about patient medical history. 
Nonetheless, there are lots of challenges in con-
structing complete and accurate medical history 
because of complex temporal expressions/
relations, medical language specific grammar/
jargons, implicit  information and domain-specific 
medical knowledge (Zhou and Hripcsak, 2007).
In this paper, as an initial step towards con-
structing complete timelines from narrative text, 
we focus on sentences with explicit  temporal ex-
pressions listed below (tagged as Line 1 ~ 11) plus 
a sentence in the present tense (Line 12):
1
?
Line 1: She had a left radical nephrectomy in  09/
2007; pathological stage at that time  was a T3 
NX MX. 
?
Line 2: Prior to her surgery CT scan in 08/2007 
showed lung nodules. 
?
Line 3: She was placed on Nexavar in 11/2007. 
?
Line 4: She was started on Afinitor on 03/05/08. 
?
Line 5: She states that prior to starting the Afini-
tor she had no shortness of breath or dyspnea on 
exertion and she was quite active. 
?
Line 6: Unfortunately 4 weeks after starting the 
Afinitor she developed a dry cough and progres-
sive shortness of breath with dyspnea on exer-
tion. 
?
Line 7: She received a 5 day dose pack of 
prednisone and was treated with Augmentin in 
05/2008. 
?
Line 8: She subsequently had a CT scan of the 
chest  done on 05/14/08 that  showed interval de-
velopment of bilateral lower lobe infiltrates that 
were not present on the 02/19/08 scan. 
?
Line 9: Because of her respiratory symptoms, the 
Afinitor was stopped on 05/18/2008. 
?
Line 10: Prior to  the Afinitor she was able to 
walk, do gardening, and swim without any 
shortness of breath.  
?
Line 11: She has had a 140 pound weight  since 
10/2007.
?
Line 12: She denies fevers, chills, hemoptysis or 
chest pain. 
In these 12 sentences, there are instances of 10 
treatments (e.g., procedures such as ?nephrectomy? 
and drugs such as ?Nexavar?), 3 tests (e.g., CT-
scan), 13 problems/symptoms (e.g., lung nodules) 
and 2 other types of clinical findings (e.g., the can-
cer stage level ?T3 NX MX?). There are also 23 
events of various types represented with verbs such 
as  ?had?, ?was?, ?showed?, and ?was started?.
While there are simple expressions such as ?on 
03/05/08? in Line 3, there are also temporal ex-
pressions in more complex forms with time rela-
tions (e.g., ?prior to?), time references (e.g., ?at 
that time?) or event references (e.g., ?4 weeks after 
starting Afinitor?). Throughout  this paper, we will 
use Line 1 ~ 12 as a concrete example based on 
which we develop general techniques to construct 
timelines.
1
 For privacy, identities of patients/physicians were concealed and the dates/time-spans in the original sources were 
altered while maintaining their chronological order. Some measurements and geographic names were also modified.
Figure 1: A sample medical record -- Thoracic 
Consultation Note
1
PAST MEDICAL HISTORY: 
1. History of melanoma of the left arm.  She had excision of 3 sentinel lymph nodes in the left axilla 
that were negative.  This was in 07/2007.
2. Status post right hip replacement.
3. Status post cholecystectomy.
4. Status post renal stone removal.
5. Fracture of the right hip and left wrist in a motor vehicle accident.
6. Diabetes.
7. Elevated cholesterol.
8. Hypertension.
9. Spinal stenosis. 
ALLERGIES:
She has no known drug allergies.  She is allergic to IVP dye which causes shortness of breath.  She 
tolerates IV dye when she is pre treated.  
SOCIAL HISTORY: 
She is born and raised in California and she lived in Florida for 30 years.  She has worked as a 
medical billing analyst.  She has never smoked. She does not use alcoholic beverages.
FAMILY HISTORY:
Her father died at age 69 of prostate cancer.  Her mother died at age 72 of emphysema.  She had 1 
sister who died from melanoma.  
REVIEW OF SYSTEMS: 
A complete review of systems was performed.  See the questionnaire.  She has hypothyroidism.  
She has some back pain related to her spinal stenosis.  She suffers from mild depression.  
CURRENT MEDICATIONS:
1. Carvedilol 6.25 mg p.o. daily.
2. Darvocet N100, 1 tablet as needed.
3. Fish oil, 1000 mg three times a day.
4. Glimepiride 4 mg daily in the morning and 2 mg at bedtime.
5. Lipitor 20 mg daily.
6. Metformin 1000 mg twice daily.
7. Paroxetine 20 mg daily.
8. Synthroid 0.112 mg daily.
9. Tylenol as needed.
10. Vitamin B12, 2500 mcg p.o. twice daily.
XXX X XX-XX-XX 
CONSULTATION DATE: 07/06/2008
RE: XXX BIRTH DATE: XX/XX/XXXX
UR#: XX-XX-XX AGE: 75
THORACIC CONSULTATION NOTE
REQUESTING PHYSICIAN:
XXXXXXXXXX, MD.
REASON FOR CONSULTATION:
Shortness of breath and abnormal chest x ray.
HISTORY OF PRESENT ILLNESS:
Ms. XXX is a 75 year old woman who has a history of metastatic renal cancer.  She had a left radical 
nephrectomy in 09/2007; pathological stage at that time was a T3 NX MX.  Prior to her surgery CT 
scan in 08/2007 showed lung nodules.  These nodules have progressed with time.  She was placed 
on Nexavar in 11/2007.  She subsequently was found to have a new mass in her left nephrectomy 
bed.  She was continued on the Nexavar, however, she showed radiographic progression and the 
Nexavar was discontinued.  She was started on Afinitor on 03/05/08.  She states that prior to starting 
the Afinitor she had no shortness of breath or dyspnea on exertion and she was quite active.  
Unfortunately 4 weeks after starting the Afinitor she developed a dry cough and progressive 
shortness of breath with dyspnea on exertion.  She received a 5 day dose pack of prednisone and 
was treated with Augmentin in 05/2008.  This had no impact on her cough or shortness of breath.  
She subsequently had a CT scan of the chest done on 05/14/08 that showed interval development 
of bilateral lower lobe infiltrates that were not present on the 02/19/08 scan.  She had mediastinal 
and right hilar adenopathy that had increased.  She had multiple lung nodules and there was 
recurrent tumor noted in the left renal bed which was thought to be larger.  Because of her 
respiratory symptoms, the Afinitor was stopped on 05/18/08.  She still has a dry cough.  She is short 
of breath after walking 15 to 20 feet.  She has no shortness of breath at rest.  She denies PND or 
orthopnea.  Prior to the Afinitor she was able to walk, do gardening, and swim without any shortness 
of breath.  She has had a 140 pound weight since 10/2007.  She notices anorexia.  She has no 
travel history.
She denies fevers, chills, hemoptysis or chest pain.  She has never smoked.  She denies 
pneumonia, asthma, wheezing, or myocardial infarction, congestion heart failure or heart murmur.  
She has dogs and cats at home and has had them for a long time and this never caused her 
respiratory problems. 
PHYSICAL EXAMINATION: 
VITAL SIGNS:   Blood pressure 131/74, pulse 106, respiratory rate 20, temperature 97.3, weight 
64.0 kg.
HEENT:   Pupils equal, round, reactive to light.  Extraocular muscles were intact.  Nose and mouth 
were clear. 
NECK:  Trachea midline.  Carotids were 2 plus.  No masses, thyromegaly or adenopathy.  
LUNGS:   Respirations were unlabored.  There is no dullness to percussion or tenderness to 
palpation.  She has some bibasilar dry rales.
HEART:   Regular rate and rhythm without murmur.
ABDOMEN:  Soft, positive bowel sounds, nontender. 
EXTREMITIES:   No clubbing or cyanosis.  She had some mild pedal edema. 
DATABASE:
Chest x ray from 06/01/08 was reviewed.  She had bilateral lower lobe patchy densities.  She had 
some nodular densities bilaterally as well.  There is widening of the mediastinum on the right.  CT 
scan of the chest from 05/14/08 also was reviewed.  She had bilateral lower lobe infiltrates that were 
new.  She had mediastinal and right hilar adenopathy.  She had multiple lung nodules.  There is 
recurrent tumor in the left renal bed that was thought to be larger. 
IMPRESSION:
1. Metastatic renal cancer with multiple lung nodules with mediastinal and hilar adenopathy.  
2. Bilateral lower lobe infiltrates.  These infiltrates had developed after starting the Afinitor, as did 
her shortness of breath and dyspnea on exertion.  She recently started on oxygen by her primary 
care physician when she was found to have exercise O2 saturations of 86%.  She is currently taking 
2 liters of oxygen.  I would be concerned that the infiltrates may be related to pneumonitis from the 
Afinitor.  I also think her shortness of breath, cough and hypoxemia are related to the infiltrates as 
well.  
RECOMMENDATIONS:
1. I reviewed my impressions with the patient.
2. I am going to schedule her for a bronchoscopy and bronchoalveolar lavage.  I am going to get 
baseline pulmonary function tests on her. 
3. She will be seen by Dr. XXX on 08/12/08.  I will call and discuss the case with him pending the 
above results.  The options are likely going to be observation off Afinitor or may consider placing her 
on prednisone, if the bronchoalveolar lavage is unremarkable.  
4. Further recommendations will be made after the above.
Do not type or edit below this line. This will cause format damage.
  
Dictated by XXXX, MD
Electronically Signed
FXXXXXXX, MD 07/10/2008 10:15
________________________
XXXXX, MD
DD: 07/10/2008  9:24 A
DT: 07/13/2008 11:46 A
ID: XXXXXXX.LML
CS: XXXXXX
cc: 
??
HISTORY OF PRESENT ILLNESS:
Ms. XXX is a 75 year ld woman who has a history of metastatic renal 
cancer. She had a left adi al nephrectomy in 09/2007; pathological stage 
at that time was a T3 NX MX. Prior to her surgery CT scan in 08/2007 
showed lung nodules. These nodules have progressed with time. She was 
placed on Nexavar in 11/2007. She subsequently was found to have a 
new mass in her left nephrectomy bed. She was continued on the 
N xavar, owever, she showed radiographic progression and the Nexavar 
was disc ntinued. She was started on Afinitor on 03/05/08. She states 
that p i r to starting the Afinitor she had no shortness of breath or 
dys n a on exe tion and she was quite active. Unfortunately 4 weeks 
after starting the Afinitor she developed a dry cough and progressive 
tness f br th with dyspnea on exertion. She received a 5 day dose 
pack of prednisone and was treated with Augmentin in 05/2008. This had 
no impact on her cough or shortness of breath. She subsequently had a 
CT scan of the chest done on 05/14/08 that showed interval development 
of bilateral lower lobe infiltrates that were not present on the 02/19/08 
scan. She had mediastinal and right hilar adenopathy that had increased. 
She had multiple lung nodules and there was recurrent tumor noted in the 
left renal bed which was thought to be larger. Because of her respiratory 
symptoms, the Afinitor was stopped on 05/18/2008. She still has a dry 
cough. She is short of breath after walking 15 to 20 feet. She has no 
shortness of breath at rest. She denies PND or orthopnea. Prior to the 
Afinitor she was able to walk, do gardening, and swim without any 
shortness of breath. She has had a 140 pound weight since 10/2007. She 
notices anorexia. She has no travel history. She denies fevers, chills, 
hemoptysis or chest pain. She has never smoked. She denies pneumonia, 
asthma, wheezing, or myocardial infarction, congestion heart failure or 
heart murmur. She has dogs and cats at home and has had them for a long 
time and this never caused her respiratory problems.
147
3 Natural Language Understanding 
(NLU) System
Our system is an extension to an existing NLU sys-
tem that is the result of a decade-long research ef-
fort  in developing generic natural language tech-
nology. The system uses a ?deep? understanding 
approach, attempting to find a linked, overall 
meaning for all the words in a paragraph. An archi-
tectural view of the system is shown in Figure 2.
3.1 Core NLU Components
At the core of the system is a packed-forest  chart 
parser which builds constituents bottom-up using a 
best-first search strategy. The core grammar is a 
hand-built, lexicalized context-free grammar, aug-
mented with feature structures and feature unifica-
tion. The parser draws on a general purpose seman-
tic lexicon and ontology which define a range of 
word senses and lexical semantic relations. The 
core semantic lexicon was constructed by hand and 
contains more than 7000 lemmas. It  can be also 
dynamically augmented for unknown words by 
consulting WordNet (Miller, 1995). 
To support  more robust processing as well as 
domain configurability, the core system is in-
formed by a variety of statistical and symbolic pre-
processors. These include several off-the-shelf sta-
tisical NLP tools such as the Stanford POS tagger 
(Toutanova and Manning, 2000), the Stanford 
named-entity recognizer (NER) (Finkel et al, 
2005) and the Stanford Parser (Klein and Manning, 
2003). The output of these and other specialized 
preprocessors (such as a street address recognizer) 
are sent  to the parser as advice. The parser then can 
include or not include this advice (e.g., that a cer-
tain phrase is a named entity) as it searches for the 
optimal parse of the sentence.
The result  of parsing is a frame-like semantic 
representation that we call the Logical Form (LF). 
The LF representation includes semantic types, 
semantic roles for predicate arguments, and de-
pendency relations. Figure 3 shows an LF example 
for the sentence ?She had a left radical nephrec-
tomy in 09/2007?. In the representation, elements 
that start  with colons (e.g., :THEME) are semantic 
roles of ontological concepts, and role values can 
be a variable to refer to another LF term.
3.2 UMLS Integration
By far the most  critical aspect  of porting our ge-
neric NLU components to the task of understand-
ing clinical text  is the need for domain-specific 
lexical and ontologic information. One widely used 
comprehensive resource that  can provide both is 
the National Library of Medicine?s Unified Medi-
cal Language System (UMLS) (Bodenreider, 
2004). UMLS was integrated into or system via 
MetaMap (Aronson and Lang, 2010), a tool also 
developed by NLM, that  can identify and rank 
UMLS concepts in text.
Specifically, we added MetaMap as a special 
kind of named entity recognizer feeding advice 
into the Parser?s input chart (see Figure 2). We run 
MetaMap twice on the input  text  to obtain UMLS 
information both for the maximal constituents, and 
for individual words in those constituents (e.g., 
?lung cancer?, as well as ?lung? and ?cancer?).
The lexicon constructs representations for the 
new words and phrases on the fly. Our general ap-
proach for dealing with how the corresponding 
concepts fit  in our system ontology uses an ontol-
Core Lexicon
& Semantic Ontology
Grammar
Parser
Wordnet
Unknown Word 
Processing
New Lexical Entries
Output
Chart
Input
Chart
Statistical Parser
Bracketing Preferences
Input
Named Entity 
Recognizer
Name 
Hypotheses
POS 
Tagging
POS
Hypotheses
Word Hypotheses
MetaMap UMLS
UMLS
POS/sense 
Hypotheses
LF Semantic 
Representation 
for reasoners
Figure 2: Front-end language processing components with MetaMap and UMLS
148
ogy specialization mechanism which we call on-
tology grafting, whereby new branches are created 
from third party ontological sources, and attached 
to appropriate leaf nodes in our ontology.
The UMLS Semantic Network and certain vo-
cabularies included in the UMLS Metathesaurus 
define concept hierarchies along multiple axes. 
First, we established links between the 15 UMLS 
semantic groups and corresponding concepts in our 
ontology. Second, we selected a list of nodes from 
the SNOMED-CT and NCI hierarchies (27 and 11 
nodes, respectively) and formed ontological 
branches rooted in these nodes that  we grafted onto 
our ontology. 
Based on these processes, UMLS information 
gets integrated into our LF representation. In Fig-
ure 3, the 3rd term has a role called :domain-info 
and, in fact, its value is (UMLS :CUI C2222800 
:CONCEPT "left nephrectomy" :PREFERRED 
"nephrectomy of left kidney (treatment)" 
:SEMANTIC-TYPES (TOPP) :SEMANTIC-
GROUPS (PROC) :SOURCES (MEDCIN MTH)) 
that provides detailed UMLS concept information. 
Here, the semantic type ?TOPP? is a UMLS abbre-
viation for ?Therapeutic or Preventive Procedure?. 
More details about complex issues surrounding 
UMLS integration into our system can be found in 
(Swift et al, 2010).
4 Information Extraction (IE) from Clinical 
Text Records
In this section, we describe how to extract basic 
elements that will be used as a foundation to con-
struct timelines. We first describe our general ap-
proach to extracting information from LF graphs. 
Then we give details specific to the various types 
of information we extract in our system: various 
clinical concepts, temporal concepts (points as well 
as intervals), events and temporal relations.
4.1 LF Pattern-based Extraction
Given LF outputs from the NLU system described 
in Section 3, we use LF pattern-based rules for in-
formation extraction. The basic structure of an ex-
traction rule is a list  of LF patterns followed by a 
unique rule ID and the output specification.
Each LF-pattern specifies a pattern against  an 
LF. Variables can appear anywhere except as role 
names in different formats:
?
?x - (unconstrained) match anything 
?
?!x - match any non-null value
?
(? x V1 V2 ...) - (constrained) match one of the 
specified values V1,  V2, ...
As an example, the extraction rule in Figure 4 
will match LFs that mean a person had a treatment 
or a medical-diagnostic with explicit  UMLS in-
formation (i.e., part of LFs in Figure 3 matches). 
The output specification records critical informa-
tion from the extraction to be used by other rea-
soners. 
The extraction rules have all been developed by 
hand. Nevertheless, they are quite general, since a) 
LF patterns abstract away from lexical and syntac-
tic variability in the broad class of expressions of 
interest (however, lexical and syntactic features 
may be used if needed); and b) LF patterns make 
heavy use of ontological categories, which pro-
vides abstraction at the semantic level.
4.2 Clinical Concept Extraction
Among various types of concepts included in clini-
cal records, we focus on concepts related to 
problems/tests/treatments to build a medical his-
(F V1 (:* ONT::HAVE W::HAVE) :AFFECTED V2 :THEME V3 :MOD V4 :TENSE W::PAST) 
(PRO V2 (:* ONT::PERSON W::SHE) :PROFORM ONT::SHE :CO-REFERENCE V0) 
(A V3 (:* ONT::TREATMENT W::LEFT-RADICAL-NEPHRECTOMY) :DOMAIN-INFO (UMLS .....)
(F V4 (:* ONT::TIME-SPAN-REL W::IN) :OF V1 :VAL V5)
(THE V5 ONT::TIME-LOC :YEAR 2007 :MONTH 9)
Figure 3: LF semantic representation for ?She had a left radical nephrectomy in 09/2007?
(?x1 ?y2 (? type1 ONT::HAVE) :AFFECTED ?y2 :THEME ?y3 :MOD ?y4)
(?x2 ?y2 (? type2 ONT::PERSON)))
(?x3 ?y3 (? type3 ONT::TREATMENT ONT::MEDICAL-DIAGNOSTIC) :DOMAIN-INFO ?!info)
List of LF patterns
-extract-person-has-treatment-or-medical-diagnostic>
(EVENT :type ?type1 :class occurrence :subject ?y2 :object ?y3)
Unique rule ID
Output Specification
Figure 4: An example extraction rule
149
tory and extract  them using extraction rules as de-
scribed above. Figure 5 shows a rule to extract 
substances by matching any LF with a substance 
concept (as mentioned already, subclasses such as 
pharmacologic substances, would also match).
The rule in Figure 5 checks the :quantifier role 
and its value (e.g., none) is used to infer the pres-
ence or the absence of concepts. Using similar 
rules, we extract  additional concepts such as 
medical-disorders-and-conditions, physical-
symptom, treatment, medical-diagnostic, medical-
action and clinical-finding. Here, medical-action 
and clinical-finding are to extract concepts in a 
broader sense.
2
 To cover additional concepts, we 
can straightforwardly update extraction rules.
4.3 Temporal Expression Extraction
Temporal expressions are also extracted in the 
same way but using different  LF patterns. We have 
14 rules to extract  dates and time-spans of varying 
levels of complexity; for the example in Figure 1 
six of these rules were applied. Figure 6 shows LF 
patterns for a rule to extract temporal expressions 
of the form ?until X days/months/years ago?; for 
example, here is what the rule extracts for ?until 3 
days ago?:
(extraction :type time-span :context-rel (:* 
ont::event-time-rel w::until) :reference (time-position 
:context-rel (:* ont::event-time-rel w::ago) :amount 3 
:unit (:* ont::time-unit ont::day))) 
From this type of output, other reasoners can 
easily access necessary information about given 
temporal expressions without investigating the 
whole LF representation on their own.
4.4 Event Extraction
To construct timelines, the concepts of interest 
(Section 4.2) and the temporal expressions (Sec-
tion 4.3) should be pieced together. For that pur-
pose, it  is critical to extract events because they not 
only describe situations that  happen or occur but 
also represent states or circumstances where some-
thing holds. Furthermore, event features provide 
useful cues to reason about  situations surrounding 
extracted clinical concepts.
Here, we do not formally define events, but  refer 
to (Sauri et  al., 2006) for detailed discussion about 
events. While events can be expressed by multiple 
means (e.g., verbs, nominalizations, and adjec-
tives), our extraction rules for events focus on 
verbs and their features such as class, tense, aspect, 
and polarity. Figure 7 shows a rule to extract  an 
event  with the verb ?start? like the one in Line 4, 
?She was started on Afinitor on 03/05/08?. The 
output specification from this rule for Line 4 will 
have the :class, :tense, and :passive roles as (aspec-
tual initiation), past, and true respectively.
These event  features play a critical role in con-
structing timelines (Section 5). For instance, the 
event  class (aspectual initiation) from applying the 
rule in Figure 7 to Line 4 implies that  the concept 
?Afinitor? (a pharmacologic-substance) is not  just 
something tried on the given date, 03/05/08,  but 
something that continued from that date.
4.5 Relation Information Extraction
The relations among extracted concepts (namely, 
conjoined relations between events and set rela-
tions between clinical concepts) also play a key 
role in our approach. When events or clinical con-
cepts are closely linked with such relations, heuris-
tically, they tend to share similar properties that are 
exploited in constructing timelines as described in 
Section 5.
5 Building Timelines from Extracted Results
Extracted clinical concepts, temporal expressions, 
events, and relations (Section 4) are used as a 
2
 While concept classification into certain categories is a very important task in the medical domain, sophisticated 
concept categorization like the one specified in the 2010 i2b2/VA Challenge (https://www.i2b2.org/NLP/Relations/) 
is not the primary goal of this paper. We rather focus on how to associate extracted concepts with other events and 
temporal expressions to build timelines.
(?x1 ?y1 (:* ont::event-time-rel w::until) :val ?val) 
(?x2 ?val (? type2 ont::time-loc) :mod ?mod) 
(?x3 ?mod (? type3 ont::event-time-rel) :displacement 
?displacement) 
(?x4 ?displacement (? type4 ont::quantity) :unit ?unit 
:amount ?amount) 
(?x5 ?amount ont::number :value ?num)
Figure 6: LF patterns to extract a time-span
((?x1 ?y1 (? type1 ONT::SUBSTANCE) :domain-info 
?info :quantifier ?quan)
-extract-substance>
(extraction :type substance :concept ?type1 :umlsinfo 
?info :ont-term ?y1 :quantifier ?quan))
Figure 5: A rule to extract substances
150
foundation to construct timelines that  represent 
patients? medical history. In this section, we pre-
sent  timeline construction processes (as shown in 
Figure 8), using example sentences from Section 2.
Step 1: We first  make connections between events 
and clinical concepts. In the current system, events 
and clinical concepts are extracted in separate rules 
and their relations are not always explicit  in the 
output specification of the rules applied. For in-
stance, Figure 9 shows LFs for the sentence in Line 
7 in a graph format, using simplified LF terms for 
illustration. The clinical concept ?prednisone? and 
the event  ?received? get  extracted by different 
rules and the relation between them is not explicit 
in their output specifications.
To address such a case, for a pair of an event 
and a clinical concept, we traverse LF graphs and 
decide that a relation between them exists if there 
is a path that  goes through certain pre-defined con-
cepts that  do not separate them semantically and 
syntactically (e.g., concepts of measure-units, 
evidence/history, development, and some proposi-
tions).
Step 2: Second, we find temporal expressions as-
sociated with events. This step is relatively 
straightforward. While temporal expressions and 
events get  extracted separately, by investigating 
their LFs, we can decide if a given temporal ex-
pression is a modifier of an event. In Figure 9, the 
time-span-relation (i.e., ?in?) in the dotted-line box 
is a direct modifier of the event ?was treated?.
Step 3: Next, we propagate the association be-
tween events and temporal expressions. That is, 
when the relation between an event and a temporal 
expression is found, we check if the temporal ex-
pression can be associated with additional events 
related to the event  (esp. when the related events 
do not have any associated temporal expression). 
In Figure 9, the event  ?received? does not have a 
temporal expression as a modifier. However, it  is 
conjoined with the event  ?was treated? in the same 
past  tense under the same speech act. Thus, we let 
the event  ?received? share the same temporal ex-
pression with its conjoined event. Here, the con-
joined relation was extracted with relation rules 
described in Section 4.5, which allows us to focus 
on only related events.
Step 4: When temporal expressions do not have 
concrete time values within the expressions, we 
need to designate times for them by looking into 
information in their LFs:
?
Event references: The system needs to find the 
referred event  and gets its time value. For in-
stance, in ?4 weeks after starting Afinitor? (Line 
6),  ?starting Afinitor? refers to a previous event 
in Line 4. The system investigates all events with 
a verb with the same- or sub-type of ont::start 
and Afinitor as its object  (active verbs) or its 
subject (passive verbs). After resolving event 
references, additional time reference or relation 
computation may be required (e.g., computation 
for ?4 weeks after?).
?
Time references: Concrete times for expressions 
like the above example ?N weeks after 
<reference-time>? can be easily computed by 
checking the time displacement  information in 
LFs with the reference time. However, expres-
sions such as ?N days ago?  are based on the 
context of clinical records (e.g., record creation 
(?x1 ?ev (? type1 ont::start) :affected ?affected :tense ?tense :passive ?passive :progressive ?progresive 
  :perfective ?perfective :negation ?negation)
-extract-start-event>
(EVENT :type ?type1 :class (aspectual initiation) :subject ?affected :object null :tense ?tense :passive
   ?passive :progressive ?progresive :perfective ?perfective :negation ?negation :ont-term ?ev)
Figure 7: An event extraction rule example
Inputs: Clinical concepts, Temporal 
Expressions, Events, Relations, LFs
Outputs: Clinical concepts with associated dates 
or timespans.
Steps: 
1. Build links between events and clinical 
concepts
2. Find associated temporal expressions for 
events
3. Propagate temporal expressions through 
relations between events when applicable
4. Compute concrete time values for temporal 
expressions, taking into account the context of 
clinical records
5. Compute time values for clinical concepts 
based on their associated events
Figure 8: Pseudocode for Timeline Construction
151
time). Document creation time is usually repre-
sented as metadata attached to the document  it-
self, or it could be retrieved from a database 
where clinical records are stored. In addition, 
previously mentioned dates or time-spans can be 
referred to using pronouns (e.g., ?at  that/this 
time?). For such expressions, we heuristically 
decide that it refers to the most  recent  temporal 
expression.
?
Time relation: Some temporal expressions have 
directional time relations (e.g., ?until?, ?prior 
to?, and ?after?) specifying intervals with open 
ends. When the ending time of a time span is not 
specified (e.g., ?since 10/2007? in Line 10). We 
heuristically set it from the context of the clinical 
record such as the document creation time.
Step 5: Finally, we designate or compute times on 
or during which the presence or the absence of 
each clinical concept is asserted. Since temporal 
expressions are associated with events, to find time 
values for clinical concepts, we first check the rela-
tions between events and clinical concepts. When 
an event with a concrete time is found for a clinical 
concept, the event?s class is examined. For classes 
such as state and occurrence, the concrete time 
value of the event  is used. In contrast, for an aspec-
tual event, we check its feature (e.g., initiation or 
termination) and look for other aspectual events 
related to the clinical concept and compute a time 
span. For instance, regarding ?Afinitor?, Line 4 
and Line 9 have events with classes (aspectual ini-
tiation) and (aspectual termination) respectively, 
which leads to a time span between the two dates 
in Line 4 and Line 9. Currently, we do not resolve 
conflicting hypotheses. 
Assertion of Presence  or Absence  of Clinical 
Concepts: To check if a certain concept is present 
or not, we take into account quantifier information 
(e.g., none), the negation role values of events, and 
the verb types of events (e.g., ?deny? indicates the 
absence assertion). In addition to such information 
readily available in the output  specifications of the 
clinical concept- and event-extraction rules, we 
also check the path (as in Step 1) that relates the 
clinical concepts and the events, and the quantifiers 
of the concepts in the path are used to compute 
negation values. For instance, given ?The scan 
shows no evidence of lung nodules?, the quantifier 
of the concept  ?evidence? indicates the absence of 
the clinical finding ?lung nodules?.
6 Timeline Results and Discussion 
For the example in Section 2 (Line 1 ~ 12), we ex-
tract all the instances of the clinical concepts and 
the temporal expressions. Out of 23 events, 17 
were extracted. While we missed events such as 
state/was (Line 5), done (Line 8), and walk/do/
swim  (Line 10), our event  extraction rules can be 
extended to cover them if need be.
Figure 10 visualizes the extraction results of the 
example. We use a web widget tool called Simile 
Timeline (www.simile-widgets.org/timeline/). 
Some property values (that  were also extracted by 
rules) are shown alongside some concepts (e.g., 
weight  measurement). Note that not  all extracted 
clinical findings are displayed in Figure 10 because 
we visualize clinical concepts only when they are 
associated with temporal expressions in our LFs. 
For instance, the CT-scan on 05/14/08 in Line 8 is 
not shown because the date was not  associated 
with it due to fragmented LFs from the Parser. 
Figure 9: Graph format LFs of the sentence in Line 7 -- ?She received a 5 day dose pack of 
                  prednisone and was treated with Augmentin in 05/2008.?
152
However, we were still able to extract ?no infil-
trates? and ?scan? from a meaningful fragment.
In addition to the fragmented LF issue, we plan 
to work on temporal reasoning for concepts in the 
sentences without explicit temporal expressions, 
and the current limited event reference resolution 
will be improved. We are also working on evalua-
tion with 48 clinical records from 10 patients. An-
notated results will be created as a gold-standard 
and precision/recall will be measured.
7 Related Work
Temporal information is of crucial importance in 
clinical applications, which is why it  has attracted 
a lot  interest over the last  two decades or more 
(Augusto, 2005). Since so much clinical informa-
tion is still residing in unstructured form, in par-
ticular as text  in the patient?s health record, the last 
decade has seen a number of serious efforts in 
medical NLP  in general (Meystre et  al., 2008) and 
in extracting temporal information from clinical 
text in particular. 
Some of this surge in interest  has been spurred 
by dedicated competitions on extraction of con-
cepts and events from clinical text (such as the 
i2b2 NLP challenges). At the same time, the evolu-
tion of temporal markup languages such as Ti-
meML (Sauri et al, 2006), and temporal 
extraction/inference competitions (such as the two 
TempEval challenges,  Verhagen et  al., 2009) in the 
general area of NLP have led to the development 
of tools such as TARSQI (Verhagen et  al., 2005) 
that could be adapted to the clinical domain.
Although the prevailing paradigm in this area is 
to use superficial methods for extracting and clas-
sifying temporal expressions, it has long been rec-
ognized that higher level semantic processing, in-
cluding discourse-level analysis, would have to be 
performed to get  past the limits of the current  ap-
proaches (cf. Zhou and Hripcsak, 2007). 
Recent attempts to use deeper linguistic features 
include the work of  Bethard et  al. (2007), who 
used syntactic structure in addition to lexical and 
some minor semantic features to classify temporal 
relations of the type we discussed in Section 4.3. 
Savova and her team have also expressed interest 
in testing off-the-shelf deep parsers and semantic 
role labelers for aiding in temporal relation identi-
fication and classification (Savova et al, 2009); 
although we are not  aware of any temporal extrac-
tion results yet, we appreciate their effort in ex-
panding the TimeML annotation schema for the 
clinical domain, as well as their efforts in develop-
ing corpora of clinical text  annotated with temporal 
information.
The work of Mulkar-Mehta et  al. (2009) also 
deserves a mention, even though they apply their 
techniques to biomedical text rather than clinical 
text. They obtain a shallow logical form that repre-
sents predicate-argument relations implicit  in the 
syntax by post-processing the results of a statistical 
parser. Temporal relations are obtained from the 
shallow LF based on a set  of hand-built rules by an 
abductive inference engine.
To our knowledge, however, our system is the 
first  general-purpose NLU system that produces a 
full, deep syntactic and semantic analysis of the 
text as a prerequisite to the extraction and analysis 
of relevant clinical and temporal information.
8 Conclusion
In this paper, we presented a prototype deep natu-
ral language understanding system to construct 
timelines for the medical histories of patients. Our 
approach is generic and extensible to cover a vari-
ety of narrative clinical text  records. The results 
from our system are promising and they can be 
used to support medical decision making.
9 Acknowledgement
This work was supported by the National Cancer 
Institute and the H. Lee Moffitt  Cancer Center and 
Research Institute (Award # RC2CA1488332).
Figure 10: Visualization of timeline results
153
References 
James Allen, Donna Byron, Myroslava Dzikovska, 
George Ferguson, Lucian  Galescu, and Amanda 
Stent.  2000. An architecture for a generic dialogue 
shell. Journal of Natural Language Engineering 
6(3):1?16.
Mary Swift, Nate Blaylock, James Allen, Will de 
Beaumont, Lucian Galescu, and Hyuckchul Jung. 
2010. Augmenting a Deep Natural Language Proc-
essing System with UMLS. Proceedings of the 
Fourth International Symposium on Semantic Mining 
in Biomedicine (poster abstract)
Alan R. Aronson and Fran?ois-Michel Lang.  2010. An 
overview of MetaMap: historical perspective and 
recent advances.  Journal of the American Medical 
Informatics Association. 17:229-236.
Juan C. Augusto. 2005.  Temporal reasoning for decision 
support in medicine. Artificial Intelligence in Medi-
cine, 33(1): 1-24.
Steven Bethard, James H.  Martin, and Sara Klingen-
stein. 2007. Timelines from Text: Identification of 
Syntactic Temporal Relations. In Proceedings of the 
International Conference on Semantic Computing 
(ICSC '07), 11-18.
Olivier Bodenreider. 2004. The Unified Medical Lan-
guage System (UMLS): integrating biomedical ter-
minology. Nucleic Acids Research, Vol. 32.
Jenny Rose Finkel, Trond Grenager, and Christopher 
Manning. 2005. Incorporating Non-local Information 
into Information Extraction Systems by Gibbs Sam-
pling.  Proceedings of the Annual Meeting of the As-
sociation for Computational Linguistics.
Dan Klein and Christopher D. Manning.  2003. Fast Ex-
act Inference with a Factored Model for Natural Lan-
guage Parsing. In Advances in Neural Information 
Processing Systems 15 (NIPS 2002), Cambridge, 
MA: MIT Press.
S.  M. Meystre, G. K. Savova, K. C. Kipper-Schuler, J. 
F. Hurdle. 2008. Extracting information from textual 
documents in the electronic health record: a review 
of recent research. IMIA Yearbook of Medical Infor-
matics.
George A. Miller. 1995. WordNet: A lexical database for 
English. Communications of the ACM, 38(5).
R. Mulkar-Mehta, J.R. Hobbs, C.-C. Liu, and X.J. Zhou. 
2009. Discovering causal and temporal relations in 
biomedical texts. In AAAI Spring Symposium, 74-
80.
Roser Sauri, Jessica Littman, Bob Knippen, Robert Gai-
zauskas, Andrea Setzer, and James Pustejovsky. 
2006. TimeML annotation guidelines. (available at 
http://www.timeml.org/site/publications/time 
MLdocs/annguide_1.2.1.pdf)
G. Savova, S. Bethard, W. Styler, J. Martin, M. Palmer, 
J. Masanz, and W. Ward. 2009. Towards temporal 
relation discovery from the clinical narrative. Pro-
ceedings of the Annual AMIA Symposium, 568-572.
Michael Stacey and Carolyn McGregor. 2007.  Temporal 
abstraction in intelligent clinical data analysis: A sur-
vey. Artificial Intelligence in Medicine, 39.
Kristina Toutanova and Christopher D. Manning. 2000. 
Enriching the Knowledge Sources Used in a Maxi-
mum Entropy Part-of-Speech Tagger. In Proceedings 
of the Joint SIGDAT Conference on Empirical Meth-
ods in Natural Language Processing and Very Large 
Corpora (EMNLP/VLC-2000).
M. Verhagen, I. Mani, R. Sauri, R. Knippen, S.B. Jang, 
J. Littman, A. Rumshisky, J. Phillips, and 
J. Pustejovsky. 2005. Automating temporal annota-
tion with TARSQI. In Proceedings of the ACL 2005 
on Interactive poster and demonstration sessions 
(ACLdemo '05), 81-84. 
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple, 
J. Moszkowicz, and J. Pustejovsky. 2009. The Tem-
pEval challenge: identifying temporal relations in 
text . Language Resources and Evaluation 
 43(2):161-179.
Li Zhou, Carol Friedman, Simon Parsons and George 
Hripcsak. 2005. System Architecture for Temporal 
Information Extraction,  Representation and Reason-
ing in Clinical Narrative Reports. Proceedings of the 
Annual AMIA Symposium.
Li Zhou and George Hripcsak. 2007. Temporal reason-
ing with medical data - A review with emphasis on 
medical natural language processing. Journal of 
Biomedical Informatics, 40.
154
