Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 174?177,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
A general scheme for broad-coverage multimodal annotation
Philippe Blache
Laboratoire Parole et Langage
CNRS & Aix-Marseille Universite?s
blache@lpl-aix.fr
Abstract
We present in this paper a formal and
computational scheme in the perspective
of broad-coverage multimodal annotation.
We propose in particular to introduce
the notion of annotation hypergraphs in
which primary and secondary data are rep-
resented by means of the same structure.
This paper addresses the question of resources
and corpora for natural human-human interaction,
in other words broad-coverage annotation of natu-
ral data. In this kind of study, most of domains
have do be taken into consideration: prosody,
pragmatics, syntax, gestures, etc. All these dif-
ferent domains interact in order to build an un-
derstandable message. We need then large mul-
timodal annotated corpora of real data, precisely
annotated for all domains. Building this kind of
resource is a relatively new, but very active re-
search domain, illustrated by the number of work-
shops (cf. (Martin, 2008)), international initia-
tives, such as MUMIN (Allwood, 2005), anno-
tation tools such as NITE NXT (Carletta, 2003),
Anvil (Kipp, 2001), etc.
1 A characterization of primary data
Different types of primary data constitute the basis
of an annotation: speech signal, video input, word
strings, images, etc. But other kinds of primary
data also can be used, for example in the perspec-
tive of semantic annotations such as concepts, ref-
erences, types, etc. Such data are considered to be
atomic in the sense that they are not built on top
of lower level data. When looking more closely at
these kinds of data, several characteristics can be
identified:
- Location: primary data is usually localized with
respect to a timeline or a position: gestures can
be localized into the video signal, phonemes into
the speech one, words into the string or objects
into a scene or a context. Two different kinds of
localisation are used: temporal and spatial. In the
first case, a data is situated by means of a time
interval whereas spatial data are localised in terms
of relative or absolute positions.
- Realization: primary data usually refer to con-
crete (or physical) objects: phonemes, gestures,
referential elements into a scene, etc. However,
other kinds of primary data can be abstract such
as concepts, ideas, emotions, etc.
- Medium: The W3C recommendation EMMA
(Extensible Multi-Modal Annotations) proposes to
distinguish different medium: acoustic, tactile and
visual. This classification is only relevant for data
corresponding to concrete objects.
- Production: the study of information structure
shows the necessity to take into account accessi-
bility of the objects: some data are directly acces-
sible from the signal or the discourse, they have an
existence or have already been mentioned. In this
case, they are said to be ?produced?. For example,
gestures, sounds, physical objects fall in this cate-
gory. On the other hand, other kinds of data are de-
duced from the context, typically the abstract ones.
They are considered as ?accessible?.
In the remaining of the paper, we propose the
following definition:
Primary data: atomic objects that cannot be de-
composed. They represent possible constituent on
top of which higher level objects can be built. Pri-
mary data does not require any interpretation to
be identified, they are of direct access.
This primary data typology is given in fig-
ure (1). It shows a repartition between concrete
vs. abstract objects. Concrete objects are usu-
ally those taken into account in corpus annotation.
As a consequence, annotation usually focuses on
speech and gestures, which narrows down the set
of data to those with a temporal localization. How-
ever, other kinds of data cannot be situated in the
174
Phonemes Words Gestures Discourse referents Synsets Physical objects
Produced + + + +/- - +
Accessible - - - +/- + -
Concrete + + + +/- - +
Abstract - - - +/- - +
Temporal + + + +/- - -
Spatial - - +/- +/- - +
Acoustic + +/- - - - -
Visual - - + +/- - +
Tactile - - +/- +/- - +
Figure 1: Primary data description
timeline (e.g. objects in the environment of the
scene) nor spatially (e.g. abstract data).
We need to propose a more general approach
of data indexing that has to distinguish on the
one hand between temporal and spatial localiza-
tion and on the other hand between data that can
be located and data that cannot.
2 Graph representation: nodes and
edges semantics
One of the most popular linguistic annotation rep-
resentation is annotation graphs (Bird, 2001) in
which nodes are positions whereas edges bear lin-
guistic information. This representation is elabo-
rated on the basis of a temporal anchoring, even
though it is also possible to represent other kinds
of anchoring. Several generic annotation format
has been proposed on top of this representation,
such as LAF and its extension GrAF (cf. (Ide,
2007)). In these approaches, edges to their turn
can be interpreted as nodes in order to build higher
level information. One can consider the result as
an hypergraph, in which nodes can be subgraphs.
In order to explore farther this direction, we pro-
pose a more general interpretation for nodes that
are not only positions in the input: nodes are com-
plex objects that can be referred at different lev-
els of the representation, they encode all annota-
tions. In order to obtain an homogeneous repre-
sentations, the two node types used in hypergraphs
(nodes and hypernodes) share the same informa-
tion structure which relies on the following points:
- Index: using an index renders possible to repre-
sent any kind of graphs, not only trees. They give
to nodes the possibility of encoding any kind of
information.
- Domain: prosody, semantics, syntax, gesture,
pragmatics, etc. It is important to indicate as pre-
cisely as possible this information, eventually by
means of sub-domains
- Location: annotations generally have a spatial or
a temporal situation. This information is optional.
- Features: nodes have to bear specific linguistic
indications, describing its properties.
Hypernodes bear, on top of this information,
the specification of the subgraph represented by
its constituents and their relations. We propose to
add another kind of information in the hypernode
structure:
? Relations: secondary data are built on top
of primary one. They can be represented by
means of a set of properties (constituency,
linearity, coreference, etc.) implemented as
edges plus the basic characteristics of a node.
A secondary data is then graph with a label,
these two elements composing an hypernode.
The distinction between node and hypernodes
makes it possible to give a homogeneous repre-
sentation of primary and secondary data.
3 An XML representation of annotation
hypergraphs
We propose in this section an XML encoding of
the scheme presented above.
3.1 Atomic nodes
The first example of the figure (2) illustrates the
representation of a phoneme. The node is indexed,
making its reference possible in higher level struc-
tures. Its label corresponds to the tag that would be
indicated in the annotation. Other elements com-
plete the description: the linguistic domain (speci-
fied by the attributes type and sub-type), the speci-
fication of the medium, the object localization (by
means of anchors). In this example, a phoneme
being part of the acoustic signal, the anchor is tem-
poral and use an explicit timeline reference.
The same kind of representation can be given
for transcription tokens (see node n21 in figure
(2)). The value of the node is the orthographic
form. It is potentially aligned on the signal, and
then represented with a temporal anchoring. Such
175
<node ID="n1" label="u">
<domain type="phonetics" subtype="phoneme"
medium="acoustic"/>
<anchor type="temporal" start="285" end="312"/>
</node>
<node ID="n21" label="book">
<domain type="transcription" subtype="token"/>
<anchor type="temporal" start="242" end="422"/>
</node>
<node ID="n24" label="N">
<domain type=" morphosyntax" subtype="word"/>
<anchor type="temporal" start="242" end="422"/>
<features ms="ncms---"/>
</node>
<node ID="n3" label="deictic">
<domain type="gestures" subtype="hand"/>
<anchor type="temporal" start="200" end="422"/>
<features hand="right" deictic type="space"
object="ref object"/>
</node>
<node ID="n4" label="discourse-referent">
<domain type="semantics" subtype="discourse universe"
medium="visual"/>
<anchoring type="spatial" x="242" y="422" z="312"/>
<features isa="book" color="red" />
</node>
Figure 2: XML encoding of atomic nodes
anchoring makes it possible to align the ortho-
graphic transcription with the phonetic one. In the
case of written texts, temporal bounds would be
replaced by the positions in the texts, which could
be interpreted as an implicit temporal anchoring.
The next example presented in node n24 illus-
trates the representation of part-of-speech nodes.
The domain in this case is morphosyntax, its sub-
type is ?word?. In this case too, the anchoring is
temporal, with same bounds as the corresponding
token. In this node, a feature element is added,
bearing the morpho-syntactic description.
The atomic node described in node n3 repre-
sents another physical object: a deictic gesture. Its
domain is gesture and its subtype, as proposed for
example in the MUMIN scheme (see (Allwood,
2005)) is the part of the body. The anchoring is
also temporal and we can observe in this exam-
ple a synchronization of the gesture with the token
?book?.
The last example (node n4) presents an atomic
node describing a physical object present in the
scene (a book on a shelf of a library). It belongs to
the semantics domain as a discourse referent and is
anchored spatially by its spatial coordinates. One
can note that anchoring can be absolute (as in the
examples presented here) or relative (situating the
object with respect to other ones).
3.2 Relations
Relations are represented in the same way as
nodes. They are of different types, such as con-
stituency, linearity, syntactic dependency, seman-
tic specification, etc. and correspond to a certain
domain. The example r1 in figure (3) illustrates a
specification relation between a noun (node
n21, described above) and its determiner (node
n20). Non-oriented binary relations also occur,
for example cooccurrency. Relations can be ex-
pressed in order to represent a set of objects. The
next example (relation r2) presents the case of
three constituents of an higher-level object (the
complete description of which being given in the
next section).
Finally, the alignment between objects is speci-
fied by two different values: strict when they have
exactly the same temporal or spatial marks; fuzzy
otherwize.
3.3 Hypernodes
Hypernodes encode subgraphs with the possibility
of being themselves considered as nodes. Their
structure completes the atomic node with a set of
relations. Hypernodes encode different kinds of
objects such as phrases, constructions, referential
expressions, etc. The first example represents a
NP. The node is indexed, bears a tag, a domain, an
anchoring and features. The set of relations spec-
ifies two types of information. First, the NP node
has three constituents: n20 (for example a deter-
miner), n22 (for example an adjective) and n24
(the noun described in the previous section). The
alignment is said to be strict which means that the
right border of the first element and the left border
of the last one have to be the same. The resulting
structure is an hypernode describing the different
characteristics of the NP by means of features and
relations.
The second example illustrates the case of a ref-
erential expression. Let?s imagine the situation
where a person points out at a book on a shelf,
saying ?The book will fall down?. In terms of in-
formation structure, the use of a definite NP is pos-
sible because the referent is accessible from the
physical context: the alignment of the NP (n50)
and the deictic gesture (n3, see previous section)
makes the coreference possible. This construc-
tion results in a discourse referent bringing to-
gether all the properties of the physical object (n3)
and that of the object described in the discourse
176
<relation id="r1" label="specification">
<domain type="syntax" subtype="oriented rel"/>
<edge from="n20" to="n24">
</relation>
<relation id="r2" label="constituency">
<domain type="syntax" subtype="set rel"/>
<node list>
<node id="n20"/> <node id="n22"/> <node id="n24"/>
</node list>
<alignment type="strict"/>
</relation>
Figure 3: XML encoding of relations
<node ID="n50" label="NP">
<domain type="syntax" subtype="phrase"/>
<anchor type="temporal" start="200" end="422"/>
<features cat="NP" agr="ms" sem type="ref"/>
<relations>
<relation id="r1" type="constituency">
<domain type="syntax" subtype="set rel"/>
<node list>
<node id="n20"/> <node id="n22"/> <node id="n24"/>
</node list>
<alignment type="strict"/>
</relation>
<relation id="r2" type="specification">
<domain type="syntax" subtype="oriented rel"/>
<edge from="n20" to="n24">
</relation>
</relations>
</node>
<node ID="n51" label="ref expression">
<domain type="semantics" subtype="discourse referent"/>
<features referent="book?" color="red" />
<relations>
<relation id="r3" type="constituency">
<domain type="semantics" type="set rel"/>
<node list>
<node id="n50"/> <node id="n3"/> <node id="n4"/>
</node list>
<alignment type="fuzzy"/>
</relation>
<relation id="r4" type="pointing">
<domain type="gesture" type="oriented rel"/>
<edge from="n3" to="n4">
<alignment type="strict"/>
</relation>
</relations>
</node>
Figure 4: XML encoding of hypernodes
(n50). In this expression, the alignment between
the objects is fuzzy, which is the normal situation
when different modalities interact. The second re-
lation describes the pointing action, implementing
the coreference between the noun phrase and the
physical object. This representation indicates the
three nodes as constituents.
4 Conclusion
Understanding the mechanisms of natural interac-
tion requires to explain how the different modal-
ities interact. We need for this to acquire multi-
modal data and to annotate them as precisely as
possible for all modalities. Such resources have
to be large enough both for theoretical and com-
putational reasons: we need to cover as broadly
as possible the different phenomena and give the
possibility to use machine learning techniques in
order to produce a new generation of multimodal
annotation tools. However, neither such resource,
and a fortiori such tools, already exist. One reason,
besides the cost of the annotation task itself which
is still mainly manual for multimodal information,
is the lack of a general and homogeneous anno-
tation scheme capable of representing all kinds of
information, whatever its origin.
We have presented in this paper the basis of
such a scheme, proposing the notion of annota-
tion hypergraphs in which primary as well as sec-
ondary data are represented by means of the same
node structure. This homogeneous representation
is made possible thanks to a generic description
of primary data, identifying four types of basic in-
formation (index, domain, location, features). We
have shown that this scheme can be directly repre-
sented in XML, resulting in a generic multimodal
coding scheme.
References
Allwood J., L. Cerrato, L. Dybkjaer, & al. (2005) ?The
MUMIN Multimodal Coding Scheme?, NorFA
yearbook
Bird S., M. Liberman (2001) ?A formal framework
for linguistic annotation? Speech Communication,
Elsevier
Carletta, J., J. Kilgour, and T. O?Donnell (2003) ?The
NITE Object Model Library for Handling Structured
Linguistic Annotation on Multimodal Data Sets? in
procs of the EACL Workshop on Language Technol-
ogy and the Semantic Web
Ide N. & K. Suderman (2007) ?GrAF: A Graph-based
Format for Linguistic Annotations?, in proceed-
ings of the Linguistic Annotation Workshop at the
ACL?07 (LAW-07)
Kipp M. (2001) ?Anvil-a generic annotation tool for
multimodal dialogue? in procs of 7th European
Conference on Speech Communication and Tech-
nology
Martin, J.-C., Paggio, P., Kipp, M., Heylen, D. (2008)
Proceedings of the Workshop on Multimodal Cor-
pora : From Models of Natural Interaction to Sys-
tems and Applications (LREC?2008)
177
From Shallow to Deep Parsing Using Constraint Satisfaction 
Jean-Marie BALFOURIER, Philippe BLACHE & Tristan VAN RULLEN 
Laboratoire Parole et Langage  
29,  Avenue Robert Schuman 
13621 Aix-en-Provence, France 
{balfourier, blache, tristan.vanrullen}@lpl.univ-aix.fr 
 
Abstract  
We present in this paper a technique allowing to 
choose the parsing granularity within the same 
approach relying on a constraint-based formalism. 
Its main advantage lies in the fact that the same 
linguistic resources are used whatever the 
granularity. Such a method is useful in particular 
for systems such as text-to-speech that usually need 
a simple bracketing, but in some cases requires a 
precise syntactic structure. We illustrate this 
method in comparing the results for three different 
granularity levels and give some figures about 
their respective performance in parsing a tagged 
corpus. 
Introduction 
Some NLP applications make use of shallow 
parsing techniques (typically the ones treating 
large data), some others rely on deep analysis 
(e.g. machine translation). The respective 
techniques are quite different: the former usually 
relies on stochastic methods where the later uses 
symbolic ones. However, this can constitute a 
problem for applications relying on shallow 
parsing techniques and needing in some 
occasions deep analysis. This is typically the 
case for text-to-speech systems. Such 
applications usually rely on shallow parsers in 
order to calculate intonative groups on the basis 
of syntactic units (or more precisely on chunks). 
But in some cases, such a superficial syntactic 
information is not precise enough. One solution 
would then consist in using a deep analysis for 
some constructions. No system exists 
implementing such an approach. This is in 
particular due to the fact that this would require 
two different treatments, the second one redoing  
the entire job. More precisely, it is difficult to 
imagine in the generative framework how to 
implement a parsing technique capable of 
calculating chunks and, in some cases, phrases 
with a possible embedded organization.  
 
We present in this paper a formalism relying on 
constraints that constitutes a possible answer to 
this problem. This approach allows the use of a 
same linguistic resource (i.e. a unique grammar) 
that can be used fully or partially by the parser. 
This approach relies on the fact that (1) all 
linguistic information is represented by means of 
constraints and (2) the constraints are of regular 
types. The idea consists then in implementing a 
technique that can make use of some constraints 
in the case of shallow parsing, and the entire set 
of them for deep analysis. In our formalism, 
constraints are organized into different types. 
Tuning the granularity of the parse consists then 
in selecting the types of constraints to be 
verified.  
In the first part of this paper, we present the 
property grammar formalism, its main 
advantages both in terms of representation and 
implementation. In the second part, we describe 
the parsing technique and the different 
approaches used for shallow and deep parsing. 
We address in particular in this section some 
complexity aspects illustrating the properties of 
the parsing techniques and we propose an 
evaluation over a corpus. In the third part, we 
illustrate the respective characteristics of the 
different approaches in describing for the same 
example the consequences of tuning the parse 
granularity. We conclude in presenting some 
perspectives for such a technique.  
1 Property Grammars 
The notion of constraints is of deep importance 
in linguistics, see for example Maruyama 
(1990), Pollard (1994), Sag (1999). Recent 
theories (from the constraint-based paradigm to 
the principle and parameters one) rely on this 
notion. One of the main interests in using 
constraints comes from the fact that it becomes 
possible to represent any kind of information 
(very general as well as local or contextual one) 
by means of a unique device. We present in this 
section a formalism, called Property Grammars, 
described in B?s (1999) or Blache (2001), that 
makes it possible to conceive and represent all 
linguistic information in terms of constraints 
over linguistic objects. In this approach, 
constraints are seen as relations between two (or 
more) objects: it is then possible to represent 
information in a flat manner. The first step in 
this work consists in identifying the relations 
usually used in syntax.  
 
This can be done empirically and we suggest, 
adapting a proposal from B?s (1999), the  set of 
following constraints: linearity, dependency, 
obligation, exclusion, requirement and  
uniqueness. In a phrase-structure perspective all 
these constraints participate to the description of 
a phrase. The following figure roughly sketches 
their respective roles, illustrated with some 
examples for the NP. 
 
Constraint Definition 
Linearity (<) Linear precedence constraints 
Dependency (?) Dependency relations between 
categories 
Obligation (Oblig) Set of compulsory and unique 
categories. One of these categories 
(and only one) has to be realized in a 
phrase. 
Exclusion () Restriction of cooccurrence between 
sets of categories 
Requirement (?) Mandatory cooccurrence between 
sets of categories 
Uniqueness (Uniq) Set of categories which cannot be 
repeated in a phrase 
 
In this approach, describing a phrase  consists in 
specifying a set of constraints over some 
categories that can constitute it. A constraint is 
specified as follows. Let R a symbol 
representing a constraint relation between two 
(sets of) categories. A constraint of the form a R 
b stipulates that if a and b are realized, then the 
constraint a R b must be satisfied. The set of 
constraints describing a phrase can be 
represented as a graph connecting several 
categories. 
 
The following example illustrates some 
constraints for the NP. 
 
Linearity Det <  N;  Det <  AP;   
AP <  N; N < PP 
Requirement N[com] ? Det 
Exclusion N  Pro; N[prop]  Det 
Dependency Det ?  N; AP ? N; PP ?  N 
Obligation Oblig(NP) = {N, Pro, AP} 
 
In this description, one can notice for example a 
requirement relation between the common noun 
and the determiner (such a constraint 
implements the complementation relation) or 
some exclusion that indicate cooccurrency 
restriction between a noun and a pronoun or a 
proper noun and a determiner. One can notice 
the use of sub-typing: as it is usually the case in 
linguistic theories, a category has several 
properties that can be inherited when the 
description of the category is refined (in our 
example, the type noun has two sub-types, 
proper and common represented in feature based 
notation). All constraints involving a noun also 
hold for its sub-types. Finally, the dependency 
relation, which is a semantic one, indicates that 
the dependent must combine its semantic 
features with the governor. In the same way as 
HPSG does now with the DEPS feature as 
described in Bouma (2001), this relation 
concerns any category, not necessarily the 
governed ones. In this way, the difference 
between a complement and an adjunct is that 
only the complement is selected by a 
requirement constraint, both of them being 
constrained with a dependency relation. This 
also means that a difference can be done 
between the syntactic head (indicated by the 
oblig constraint) and the semantic one (the 
governor of the dependency relation), even if in 
most of the cases, these categories are the same. 
Moreover, one can imagine the specification of 
dependencies within a phrase between two 
categories other than the head. 
 
One of the main advantages in this approach is 
that constraints form a system and all constraints 
are at the same level. At the difference of other 
approaches as Optimality Theory, presented in 
Prince (1993), there exists no hierarchy between 
them and one can choose, according to the 
needs, to verify the entire set of constraints or a 
subpart of it. In this perspective, using a 
constraint satisfaction technique as basis for the 
parsing strategy makes it possible to implement 
the possibility of verifying only a subpart of this 
constraint system. What is interesting is that 
some constraints like linearity provide 
indications in terms of boundaries, as described 
for example in Blache (1990). It follows that 
verifying this subset of constraints can constitute 
a bracketing technique. The verification of more 
constraints in addition to linearity allows to 
refine the parse. In the end, the same parsing 
technique (constraint satisfaction) can be used 
both for shallow and deep parsing. More 
precisely, using the same linguistic resources 
(lexicon and grammar), we propose a technique 
allowing to choose the granularity of the parse. 
2 Two techniques for parsing 
Property Grammars 
We describe in this paper different parsing 
techniques, from shallow to deep one, with this 
originality that they rely on the same formalism, 
described in the previous section. In other 
words, in our approach, one can choose the 
granularity level of the parse without modifying  
linguistic resources 
2.1 Shallow parsing 
In this technique, we get hierarchical and 
grammatical information while preserving 
robustness and efficiency of the processing. In 
this perspective, we make use of a grammar 
represented in the Property Grammar formalism 
described above. One of the main interests of 
this formalism is that it doesn't actually make 
use of the grammaticality notion, replacing it 
with a more general concept of characterization. 
A characterization simply consists in the set of 
the constraint system after evaluation (in other 
words the set of properties that are satisfied and 
the set of properties that are not satisfied). A 
characterization only formed with satisfied 
properties specifies a grammatical structure. In 
this sense, characterization subsumes 
grammaticality. It becomes then possible to 
propose a description in terms of syntactic 
properties for any kind of input (grammatical or 
not). Opening and closing chunks relies here on 
information compiled from the grammar. This 
information consists in the set of left and right 
potential corners, together with the potential 
constituents of chunks. It is obtained in 
compiling linear precedence, requirement and 
exclusion properties described in the previous 
sections together with, indirectly, that of 
constituency.  
The result is a compiled grammar which is used 
by the parser. Two stacks, one of opened 
categories and a second of closed categories, are  
completed after the parse of each new word: we 
can open new categories or close already opened 
ones, following some rules. This algorithm 
being recursive, the actions opening, continuing 
and closing are recursive too. This is the reason 
why rules must have a strict definition in order 
to be sure that the algorithm is deterministic and 
always terminates. This shallow parsing  
technique can be seen as a set of 
production/reduction/cutting rules. 
? Rule 1: Open a phrase p for the current 
category c if c can be the left corner of p. 
? Rule 2: Do not open an already opened 
category if it belongs to the current phrase or is 
its right corner. Otherwise, we can reopen it if 
the current word can only be its left corner. 
? Rule 3: Close the opened phrases if the more 
recently opened phrase can neither continue 
one of them nor be one of their right corner. 
? Rule 4: When closing a phrase, apply rules 1, 2 
and 3. This may close or open new phrases 
taking into consideration all phrase-level 
categories.  
2.2 Deep parsing  
Deep analysis is directly based on property 
grammars. It consists, for a given sentence, in 
building all the possible subsets of juxtaposed 
elements that can describe a syntactic category. 
A subset is positively characterized if it satisfies 
the constraints of a grammar. These subsets are 
called edges, they describe a segment of the 
sentence between two positions.  
At the first step, each lexical category is 
considered as an edge of level 0. The next phase 
consists in producing all the possible subsets of 
edges at level 0. The result is a set of edges of 
level 1. The next steps work in the same way 
and produce all the possible subsets of edges, 
each step corresponding to a level. The 
algorithm ends when no new edge can be built. 
 
An edge is characterized by: 
? an initial and a final position in the sentence, 
? a syntactic category, 
? a set of syntactic features  
? a set of constituents: a unique lexical 
constituent at the level 0, and one or several 
edges at the other levels. 
 
After parsing, a sentence is considered as 
grammatical if at least one edge covering 
completely the sentence and labelled by the 
category S is produce. But even for 
ungrammatical cases, the set of edges represents 
all possible interpretations of the sentence: the 
set of edges contains the set of constraints that 
describe the input. By another way, in case of 
ambiguity, the parser generates several edges 
covering the same part and labelled with the 
same category. Such similar edges are distinct 
by their syntactical features (in the case of an 
ambiguity of features) or by their different 
constituents (typically an ambiguity of 
attachment). 
Several heuristics allow to control the algorithm. 
For example, an edge at level n must contain at 
least an edge at level n-1. Indeed, if it would 
contain only edges at levels lower than n-1, it 
should have been already produced at the level 
n-1. 
 
The parse ends in a finite number of steps at the 
following conditions: 
? if the number of syntactic categories of the 
grammar is finite, 
? if the grammar does not contain a loop of 
production. We call loop of production, the 
eventuality that a category c1 can be 
constituted by an unique category c2, itself 
constituted by an unique category c3 and so 
until cn and that one of category c2 to cn can be 
constituted by the unique category c1. 
3 Compared complexity  
Of course, the difference of granularity of these 
algorithms does have a cost which has to be 
known when choosing a technique. 
In order to study their complexity, we parsed a 
french corpus of 13,236 sentences (from the 
newspaper Le Monde), tagged by linguists (the 
CLIF project, headed by Talana). 
 
3.1 Shallow parsing with Chinks and 
Chunks 
With the aim of comparing our techniques, we 
first built a simple robust chunker. This quick 
program gives an idea of a bottom complexity 
for the two techniques based on property 
grammars. This algorithm relies on the 
Liberman and Church?s Chink&Chunk 
technique (see Liberman & Church (1992)) and 
on Di Cristo?s chunker (see Di Cristo (1998) and 
DiCristo & al (2000)). Its mechanism consists in 
segmenting the input into chunks, by means of a 
finite-state automaton making use of function 
words as block borders. An improvement of the 
notion of chunk is implemented, using 
conjunctions as neutral elements for chunks 
being built. This algorithm constitutes an 
interesting (and robust) tool for example as basis 
for calculating prosodic units in a Text-to-
Speech Synthesizer. Chink/Chunk algorithm is a 
simple but efficient way to detect syntactic 
boundaries. In the average, best and worst cases, 
for M sentences, each sentence consisting of Nw 
words, its complexity has an order of 
M*Nw*Constant. That is to say a linear 
complexity. 
Instructions / number of words 
for Chink & Chunk (logarithmic scale) 
 
3.2 Shallow parsing with PG 
With the shallow parser algorithm, we can detect 
and label more syntactic and hierarchic data: in 
the average, worst and best cases, for M 
sentences, each sentence consisting of Nw 
words; for a set of C precompiled categories, its 
complexity has an order of 
M*C*(Nw?+Nw)*Constant. That is to say a 
polynomial complexity. 
10
0
10
00
10
00
0
0 20 40 60 80 100 120 140
 Instructions / number of words 
for Shallow Parser (logarithmic scale) 
 
3.3 Deep parsing with PG 
For the evaluation of the deep parser algorithm, 
we parsed a corpora of 620 sentences of the 
same corpus. Unlike the two previous 
algorithms, the dispersal of results is much more 
important. 
Million instructions / number of words 
for Deep Parser (logarithmic scale) 
 
In the theory, the algorithm is of exponential 
type but its progress is permanently constrained 
by the grammar. This control being heavily 
dependent from the grammatical context, the 
number of instructions necessary to parse two 
same size sentences can be very different. 
Nevertheless, in the reality of a corpus, the 
average complexity observed is of polynomial 
type. So, if Nw is the number of words of a 
sentence, the best estimate complexity of its 
parse corresponds to a polynomial of order 2.4 
(Nw2.4*Constant).  
 
3.4 Remarks on complexity 
Our study considers the parser complexity as a 
function of two parameters: 
- the size of the parsed sentence, 
- the number of grammatical categories. 
This complexity is relies on the number of 
?simple instructions? treated by the programs. 
Comparing the average complexity of each 
parser is then a good way to know which one is 
faster. Ranking techniques can then be extracted 
from the results. It would have been interesting 
to compare them in terms of maximal 
complexity, but this is not actually possible 
because of an important difference between the 
two first parsers which are deterministic, and the 
last one which is not: 
- for the first two techniques, the minimal, 
average and maximal complexities are 
polynomial, 
- the deep parser has an exponential maximal 
complexity and polynomial minimal and 
average complexities. 
 
Moreover, the study of the maximal complexity 
of the deep parser has to be treated as another 
problem. Usually, such a study must have to be 
done taking care of the size of the grammar. But 
with property grammars, other parameters have 
to be used: a property grammar is a set of 
constraints (Linearity, Dependency, Obligation, 
Exclusion, Requirement, Uniqueness) belonging 
to two different groups. In a formal terminology, 
these groups are ?reduction constraints? and 
?increasing constraints?. These groups 
characterize the behavior of the parser, as a 
formal system would do for a recognition 
problem. ?Increasing constraints? allow the 
instanciation of the search space, where 
?reduction constraints? allow pruning this space. 
Most of the sentences are fastly parsed because 
of their well-formedness: the reduction 
constraints are more frequently used than 
increasing ones in such sentences. Ambiguous 
and ill-formed sentences require a greater use of 
increasing constraints. 
 
Thus, the size of the grammar is less informative 
about the theoretical complexity than the relative 
importance of increasing and reduction 
constraints: for instance a greater grammar, with 
0,1
  
1,0
  
10
,0 
 
10
0,0
  
1 0
00
,0 
 
0 10 20 30 40 50 60 70 80 90 100
10
00
10
00
0
10
00
00
10
00
00
0
0 20 40 60 80 100 120 140
more reduction constraints would have a lower 
theoretical complexity. The study of such a 
problem does not belong to this study because it 
would lead us to a different experimentation. 
4 Different results  
Our parsers demonstrate the possibility of a 
variable granularity within a same approach. We 
illustrate in this section the lacks and assets of 
the different techniques with the example below 
(in French): 
 
"Le compositeur et son librettiste ont su 
cr?er un ?quilibre dramatique astucieux en 
mariant la com?die espi?gle voire ?grillarde 
et le drame le plus profond au c?ur des 
m?mes personnages." 
?The composer and his librettist successfully 
introduced an astute dramatic balance in marrying 
the mischievous, ribald comedy with the deepest 
drama for the same characters.? 
 
4.1 Chink/chunk approach 
[(sentence) 
 [(chunk)Le compositeur et son librettiste 
ont su cr?er] 
 [(chunk)un ?quilibre dramatique astucieux] 
 [(chunk)en mariant] 
 [(chunk)la com?die espi?gle] 
 [(chunk)voire ?grillarde] 
 [(chunk)et le drame] 
 [(chunk)le plus profond] 
 [(chunk)au coeur des m?mes personnages]] 
 
This first example shows a non-hierarchical 
representation of the sentence, divided into 
chunks. No linguistic information is given. 
4.2 Shallow parsing approach 
[(sentence) 
 [(NP)Le compositeur 
  [(AP) et] 
  son librettiste] 
 [(VP)ont su cr?er] 
 [(NP) un ?quilibre 
  [(AP)dramatique astucieux]] 
 [(Compl)en 
  [(VP)mariant]] 
 [(NP)la com?die 
  [(AP)espi?gle voire ?grillarde et] 
  le drame 
  [(Sup)le plus profond]] 
 [(PP)au c?ur de 
  [(NP)les 
   [(AP)m?mes] 
   personnages]]] 
 
This second example gives a hierarchical 
representation of the sentence, divided into 
grammatically tagged chunks. Because we used 
a precompiled version of the grammar 
(shortened) and because we forced some 
syntactic choices in order to keep a determinist 
and finishing parsing, it appears that some errors 
have been made by the shallow parser: 
Conjunctions are (badly) distinguished as 
Adverbial Phrases. In spite of these gaps, cutting 
is improved and most of the categories are 
detected correctly. 
4.3 Deep parsing approach 
The last example (next figure) presents two of 
the maximum coverages produced by the deep 
parser. This figure, which illustrates the PP 
attachment ambiguity, only presents for 
readabiulity reasons the hierarchical structure. 
However, remind the fact that each label 
represents in fact a description which the state of 
the constraint system after evaluation. 
 
 
Le compositeur et son librettiste ont su cr?er un ?quilibre dramatique astucieux en mariant la com?die espi?gle voire ?grillarde et le drame le plus profond au_c?ur des m?mes personnages
                             
                            S                             
    NP                          VP                         
      NP conj     NP V V V         NP                    
det N  det N    det N adj adj                  
                             
                        PP                 PP   
            prep VP                NP             prep     NP 
             V             NP     conj     NP      det adj N 
              det N   AP    det N   Sup       
                AP conj AP    det adv adj     
                adj  adj           
                             
                              PP               
            prep VP                 NP             
             V             NP     conj           NP       
              det N   AP    det N   Sup       PP   
                AP conj AP    det adv adj prep     NP 
                adj  adj        det adj N 
 
 
 5 Conclusion 
The experiments presented in this paper show 
that it is possible to calculate efficiently the 
different kind of syntactic structures of a 
sentence using the same linguistic resources. 
Moreover, the constraint-based framework 
proposed here makes it possible to choose the 
granularity, from a rough boundary detection to 
a deep non-deterministic analysis, via a shallow 
and deterministic one. The possibility of 
selecting a granularity level according to the 
data to be parsed or to the targetted application 
is then very useful. 
 
An interesting result for further studies lies in 
the perspective of combining or multiplexing 
different approaches. It is for example 
interesting to notice that common boundaries 
obtained by these algorithms eliminates ill-
formed and least remarkable boundaries. At the 
same time, it increases the size of the blocks 
while maintaining the linguistic information 
available (this remains one of the most important 
problems for text-to-speech systems). Finally, it 
allows to propose a parameterized granularity in 
balancing the relative importance of different 
competing approaches. 
References  
Abney, S. (1991) "Parsing by chunks"., in Berwick, 
R., Abney, S., Tenny, C. (eds.). Principle-based 
Parsing, Kluwer Academic Publishers, 257-278. 
Abney S. (1996) "Partial Parsing via Finite-State 
Calculus'', in proceedings of ESSLLI'96 Robust 
Parsing Workshop. 
Abney, S. (1997) "Part-of-speech tagging and partial 
parsing", in Young, S., Bloothooft, G. Corpus-
Based Methods in Language and Speech 
Processing, Kluwer Academic Publishers, 118-
136. 
Allen, J., Hunnincutt, S., Carlson, R., Granstr?m, B. 
(1979) "MITalk-79 : The 1979 MIT text-to-speech 
system", in Wolf and Klatt (eds.), Speech  
Communications, Papers Presented at the 97th 
Meeting of the ASA: 507-510. 
Allen, J., Hunnincutt, S., Klatt, D. (1987) "From text 
to speech: The MITalk system", Cambridge 
University Press. 
B?s G. & P. Blache (1999) "Propri?t?s et analyse 
d'un langage'', in proceedings of  TALN'99. 
Blache P. & J.-Y. Morin (1990) "Bottom-up 
Filtering: a Parsing Strategy for GPSG", in 
proceedings of COLING'90. 
Blache P. & J.-M. Balfourier (2001) "Property 
Grammars: a Flexible Constraint-Based Approach 
to Parsing'', in proceedings of IWPT-2001. 
Bouma G., R. Malouf & I. Sag (2001) "Satisfying 
Constraints on Extraction and Adjunction'', in 
Natural Language and Linguistic Theory, 19:1, 
Kluwer. 
Chanod J.-P. (2000) "Robust Parsing and Beyond'', in  
Robustness in Language Technology, Kluwer. 
Di Cristo P, (1998). G?n?ration automatique de la 
prosodie pour la synth?se ? partir du texte. Ph.D. 
thesis, Universit? de Provence, France. 
Di Cristo A., Di Cristo P., Campione E, Veronis J, 
(2000). A prosodic model for text to speech 
synthesis in French. 
Duchier D. & R. Debusmann (2001) "Topological 
Dependency Trees: A Constraint-Based Account of 
Linear Precedence'', in proceedings of  ACL. 
Grinberg D., J. Lafferty & D. Sleator (1995), A 
robust parsing algorithm for link grammars, CMU-
CS-95-125, Carnegie Mellon University. 
K?bler S. & E. Hinrichs (2001) "From Chunks to 
Function-Argument Structure: A similarity-Based 
Approach'', in proceedings of ACL-01. 
Liberman, M., Church, K. (1992) "Text analysis and 
word pronunciation in text-to- speech synthesis", in 
Furui, S., Sondhi, M.M. (eds), Advances in Speech 
Signal Processing, Dekker, 791-831. 
Maruyama H. (1990), "Structural Disambiguation 
with Constraint Propagation'', in proceedings of  
ACL'90. 
Pollard C. & I. Sag (1994), Head-driven Phrase 
Structure Grammars, CSLI, Chicago University 
Press. 
Prince A. & P. Smolensky (1993) Optimality Theory: 
Constraint Interaction in Generative Grammars, 
Technical Report RUCCS TR2, Rutgers Center for 
Cognitive Science.s 
Sag I. & T. Wasow (1999), Syntactic Theory. A 
Formal Introduction, CSLI 
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 57?64,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Acceptability Prediction by Means of Grammaticality Quantification
Philippe Blache, Barbara Hemforth & Ste?phane Rauzy
Laboratoire Parole & Langage
CNRS - Universite? de Provence
29 Avenue Robert Schuman
13621 Aix-en-Provence, France
{blache,hemforth,rauzy}@lpl.univ-aix.fr
Abstract
We propose in this paper a method for
quantifying sentence grammaticality. The
approach based on Property Grammars,
a constraint-based syntactic formalism,
makes it possible to evaluate a grammat-
icality index for any kind of sentence, in-
cluding ill-formed ones. We compare on
a sample of sentences the grammaticality
indices obtained from PG formalism and
the acceptability judgements measured by
means of a psycholinguistic analysis. The
results show that the derived grammatical-
ity index is a fairly good tracer of accept-
ability scores.
1 Introduction
Syntactic formalisms make it possible to describe
precisely the question of grammaticality. When
a syntactic structure can be associated to a sen-
tence, according to a given grammar, we can de-
cide whether or not the sentence is grammatical.
In this conception, a language (be it natural or not)
is produced (or generated) by a grammar by means
of a specific mechanism, for example derivation.
However, when no structure can be built, nothing
can be said about the input to be parsed except,
eventually, the origin of the failure. This is a prob-
lem when dealing with non canonical inputs such
as spoken language, e-mails, non-native speaker
productions, etc. From this perspective, we need
robust approaches that are at the same time ca-
pable of describing precisely the form of the in-
put, the source of the problem and to continue the
parse. Such capabilities render it possible to arrive
at a precise evaluation of the grammaticality of the
input. In other words, instead of deciding on the
grammaticality of the input, we can give an indica-
tion of its grammaticality, quantified on the basis
of the description of the properties of the input.
This paper addresses the problem of ranking the
grammaticality of different sentences. This ques-
tion is of central importance for the understanding
of language processing, both from an automatic
and from a cognitive perspective. As for NLP,
ranking grammaticality makes it possible to con-
trol dynamically the parsing process (in choosing
the most adequate structures) or to find the best
structure among a set of solutions (in case of non-
deterministic approaches). Likewise the descrip-
tion of cognitive processes involved in language
processing by human has to explain how things
work when faced with unexpected or non canoni-
cal material. In this case too, we have to explain
why some productions are more acceptable and
easier to process than others.
The question of ranking grammaticality has
been addressed from time to time in linguistics,
without being a central concern. Chomsky, for
example, mentioned this problem quite regularly
(see for example (Chomsky75)). However he
rephrases it in terms of ?degrees of ?belonging-
ness? to the language?, a somewhat fuzzy notion
both formally and linguistically. More recently,
several approaches have been proposed illustrat-
ing the interest of describing these mechanisms
in terms of constraint violations. The idea con-
sists in associating weights to syntactic constraints
and to evaluate, either during or after the parse,
the weight of violated constraints. This approach
is at the basis of Linear Optimality Theory (see
(Keller00), and (Sorace05) for a more general per-
spective) in which grammaticality is judged on the
basis of the total weights of violated constraints. It
is then possible to rank different candidate struc-
57
tures. A similar idea is proposed in the framework
of Constraint Dependency Grammar (see (Men-
zel98), (Schro?der02)). In this case too, acceptabil-
ity is function of the violated constraints weights.
However, constraint violation cannot in itself
constitute a measure of grammaticality without
taking into account other parameters as well. The
type and the number of constraints that are sat-
isfied are of central importance in acceptability
judgment: a construction violating 1 constraint
and satisfying 15 of them is more acceptable than
one violating the same constraint but satisfying
only 5 others. In the same way, other informa-
tions such as the position of the violation in the
structure (whether it occurs in a deeply embedded
constituent or higher one in the structure) plays an
important role as well.
In this paper, we propose an approach over-
coming such limitations. It takes advantage of a
fully constraint-based syntactic formalism (called
Property Grammars, cf. (Blache05b)) that of-
fers the possibility of calculating a grammatical-
ity index, taking into account automatically de-
rived parameters as well as empirically determined
weights. This index is evaluated automatically and
we present a psycholinguistic study showing how
the parser predictions converge with acceptability
judgments.
2 Constraint-based parsing
Constraints are generally used in linguistics as a
control process, verifying that a syntactic struc-
ture (e.g. a tree) verifies some well-formedness
conditions. They can however play a more general
role, making it possible to express syntactic infor-
mation without using other mechanism (such as a
generation function). Property Grammars (noted
hereafter PG) are such a fully constraint-based for-
malism. In this approach, constraints stipulate dif-
ferent kinds of relation between categories such as
linear precedence, imperative co-occurrence, de-
pendency, repetition, etc. Each of these syntactic
relations corresponds to a type of constraint (also
called property):
? Linear precedence: Det ? N (a determiner
precedes the noun)
? Dependency: AP ; N (an adjectival phrase
depends on the noun)
? Requirement: V[inf] ? to (an infinitive
comes with to)
? Exclusion: seems < ThatClause[subj] (the
verb seems cannot have That clause subjects)
? Uniqueness : UniqNP {Det} (the determiner
is unique in a NP)
? Obligation : ObligNP {N, Pro} (a pronoun or
a noun is mandatory in a NP)
? Constituency : ConstNP {Det, AP, N, Pro}
(set of possible constituents of NP)
In PG, each category of the grammar is de-
scribed with a set of properties. A grammar is then
made of a set of properties. Parsing an input con-
sists in verifying for each category of description
the set of corresponding properties in the gram-
mar. More precisely, the idea consists in verifying,
for each subset of constituents, the properties for
which they are relevant (i.e. the constraints that
can be evaluated). Some of these properties are
satisfied, some others possibly violated. The re-
sult of a parse, for a given category, is the set of its
relevant properties together with their evaluation.
This result is called characterization and is formed
by the subset of the satisfied properties, noted P+,
and the set of the violated ones, noted P?.
For example, the characterizations associated to
theNPs ?the book? and ?book the? are respectively
of the form:
P+={Det ? N; Det ; N; N < Pro; Uniq(Det),
Oblig(N), etc.}, P?=?
P+={Det ; N; N < Pro; Uniq(Det), Oblig(N),
etc.}, P?={Det ? N}
This approach allows to characterize any kind
of syntactic object. In PG, following the pro-
posal made in Construction Grammar (see (Fill-
more98), (Kay99)), all such objects are called
constructions. They correspond to a phrase (NP,
PP, etc.) as well as a syntactic turn (cleft, wh-
questions, etc.). All these objects are described by
means of a set of properties (see (Blache05b)).
In terms of parsing, the mechanism consists
in exhibiting the potential constituents of a given
construction. This stage corresponds, in constraint
solving techniques, to the search of an assignment
satisfying the constraint system. The particular-
ity in PG comes from constraint relaxation. Here,
the goal is not to find the assignment satisfying
the constraint system, but the best assignment (i.e.
the one satisfying as much as possible the system).
In this way, the PG approach permits to deal with
more or less grammatical sentences. Provided that
58
some control mechanisms are added to the pro-
cess, PG parsing can be robust and efficient (see
(Blache06)) and parse different material, includ-
ing spoken language corpora.
Using a constraint-based approach such as the
one proposed here offers several advantages. First,
constraint relaxation techniques make it possi-
ble to process any kind of input. When pars-
ing non canonical sentences, the system identi-
fies precisely, for each constituent, the satisfied
constraints as well as those which are violated.
It furnishes the possibility of parsing any kind
of input, which is a pre-requisite for identifying
a graded scale of grammaticality. The second
important interest of constraints lies in the fact
that syntactic information is represented in a non-
holistic manner or, in other words, in a decentral-
ized way. This characteristic allows to evaluate
precisely the syntactic description associated with
the input. As shown above, such a description is
made of sets of satisfied and violated constraints.
The idea is to take advantage of such a represen-
tation for proposing a quantitative evaluation of
these descriptions, elaborated from different indi-
cators such as the number of satisfied or violated
constraints or the number of evaluated constraints.
The hypothesis, in the perspective of a gradi-
ence account, is to exhibit a relation between a
quantitative evaluation and the level of grammat-
icality: the higher the evaluation value, the more
grammatical the construction. The value is then
an indication of the quality of the input, according
to a given grammar. In the next section we propose
a method for computing this value.
3 Characterization evaluation
The first idea that comes to mind when trying to
quantify the quality of a characterization is to cal-
culate the ratio of satisfied properties with respect
to the total set of evaluated properties. This infor-
mation is computed as follows:
Let C a construction defined in the grammar by
means of a set of properties SC , let AC an assign-
ment for the construction C,
? P+ = set of satisfied properties for AC
? P? = set of violated properties for AC
? N+ : number of satisfied properties N+ =
card(P+)
? N? : number of violated properties N? =
card(P?)
? Satisfaction ratio (SR): the number of satis-
fied properties divided by the number of eval-
uated properties SR = N
+
E
The SR value varies between 0 and 1, the two
extreme values indicating that no properties are
satisfied (SR=0) or none of them are violated
(SR=1). However, SR only relies on the evalu-
ated properties. It is also necessary to indicate
whether a characterization uses a small or a large
subpart of the properties describing the construc-
tion in the grammar. For example, the VP in our
grammar is described by means of 25 constraints
whereas the PP only uses 7 of them. Let?s imag-
ine the case where 7 constraints can be evaluated
for both constructions, with an equal SR. However,
the two constructions do not have the same qual-
ity: one relies on the evaluation of all the possible
constraints (in the PP) whereas the other only uses
a few of them (in the VP). The following formula
takes these differences into account :
? E : number of relevant (i.e. evaluated) prop-
erties E = N+ +N?
? T= number of properties specifying con-
struction C = card(SC)
? Completeness coefficient (CC) : the number
of evaluated properties divided by the num-
ber of properties describing the construction
in the grammar CC = ET
These purely quantitative aspects have to be
contrasted according to the constraint types. Intu-
itively, some constraints, for a given construction,
play a more important role than some others. For
example, linear precedence in languages with poor
morphology such as English or French may have a
greater importance than obligation (i.e. the neces-
sity of realizing the head). To its turn, obligation
may be more important than uniqueness (i.e. im-
possible repetition). In this case, violating a prop-
erty would have different consequences according
to its relative importance. The following examples
illustrate this aspect:
(1) a. The the man who spoke with me is my brother.
b. The who spoke with me man is my brother.
In (1a), the determiner is repeated, violating
a uniqueness constraint of the first NP, whereas
(1c) violates a linearity constraint of the same NP.
59
Clearly, (1a) seems to be more grammatical than
(1b) whereas in both cases, only one constraint is
violated. This contrast has to be taken into account
in the evaluation. Before detailing this aspect, it is
important to note that this intuition does not mean
that constraints have to be organized into a rank-
ing scheme, as with the Optimality Theory (see
(Prince93)). The parsing mechanism remains the
same with or without this information and the hi-
erarchization only plays the role of a process con-
trol.
Identifying a relative importance of the types of
constraints comes to associate them with a weight.
Note that at this stage, we assign weights to con-
straint types, not directly to the constraints, dif-
ferently from other approaches (cf. (Menzel98),
(Foth05)). The experiment described in the next
section will show that this weighting level seems
to be efficient enough. However, in case of neces-
sity, it remains possible to weight directly some
constraints into a given construction, overriding
thus the default weight assigned to the constraint
types.
The notations presented hereafter are used to
describe constraint weighting. Remind that P+
and P? indicate the set of satisfied and violated
properties of a given construction.
? p+i : property belonging to P
+
? p?i : property belonging to P
?
? w(p) : weight of the property of type p
? W+ : sum of the satisfied properties weights
W+ =
N+?
i=1
w(p+i )
? W? : sum of the violated properties weights
W? =
N??
i=1
w(p?i )
One indication of the relative importance of the
constraints involved in the characterization of a
construction is given by the following formula:
? QI: the quality index of a construction
QI =
W+ ?W?
W+ +W?
The QI index varies then between -1 and 1.
A negative value indicates that the set of violated
constraints has a greater importance than the set of
satisfied one. This does not mean that more con-
straints are violated than satisfied, but indicates the
importance of the violated ones.
We now have three different indicators that can
be used in the evaluation of the characterization:
the satisfaction ratio (noted SR) indicating the ra-
tio of satisfied constraints, the completeness coef-
ficient (noted CC) specifying the ratio of evalu-
ated constraints, and the quality index (noted QI)
associated to the quality of the characterization ac-
cording to the respective degree of importance of
evaluated constraints. These three indices are used
to form a global precision index (noted PI). These
three indicators do not have the same impact in the
evaluation of the characterization, they are then
balanced with coefficients in the normalized for-
mula:
? PI = (k?QI)+(l?SR)+(m?CC)3
As such, PI constitutes an evaluation of the
characterization for a given construction. How-
ever, it is necessary to take into account the ?qual-
ity? of the constituents of the construction as well.
A construction can satisfy all the constraints de-
scribing it, but can be made of embedded con-
stituents more or less well formed. The overall
indication of the quality of a construction has then
to integrate in its evaluation the quality of each of
its constituents. This evaluation depends finally
on the presence or not of embedded constructions.
In the case of a construction made of lexical con-
stituents, no embedded construction is present and
the final evaluation is the precision index PI as de-
scribed above. We will call hereafter the evalua-
tion of the quality of the construction the ?gram-
maticality index? (noted GI). It is calculated as
follows:
? Let d the number of embedded constructions
? If d = 0 then GI = PI , else
GI = PI ?
?d
i=1GI(Ci)
d
In this formula, we note GI(Ci) the grammat-
icality index of the construction Ci. The general
formula for a construction C is then a function of
its precision index and of the sum of the grammat-
icality indices of its embedded constituents. This
60
formula implements the propagation of the quality
of each constituent. This means that the grammati-
cality index of a construction can be lowered when
its constituents violate some properties. Recipro-
cally, this also means that violating a property at
an embedded level can be partially compensated at
the upper levels (provided they have a good gram-
maticality index).
4 Grammaticality index from PG
We describe in the remainder of the paper predic-
tions of the model as well as the results of a psy-
cholinguistic evaluation of these predictions. The
idea is to evaluate for a given set of sentences on
the one hand the grammaticality index (done auto-
matically), on the basis of a PG grammar, and on
the other hand the acceptability judgment given by
a set of subjects. This experiment has been done
for French, a presentation of the data and the ex-
periment itself will be given in the next section.
We present in this section the evaluation of gram-
maticality index.
Before describing the calculation of the differ-
ent indicators, we have to specify the constraints
weights and the balancing coefficients used in PI.
These values are language-dependent, they are
chosen intuitively and partly based on earlier anal-
ysis, this choice being evaluated by the experiment
as described in the next section. In the remainder,
the following values are used:
Constraint type Weight
Exclusion, Uniqueness, Requirement 2
Obligation 3
Linearity, Constituency 5
Concerning the balancing coefficients, we give
a greater importance to the quality index (coeffi-
cient k=2), which seems to have important conse-
quences on the acceptability, as shown in the pre-
vious section. The two other coefficients are signi-
ficatively less important, the satisfaction ratio be-
ing at the middle position (coefficient l=1) and the
completeness at the lowest (coefficient m=0,5).
Let?s start with a first example, illustrating the
process in the case of a sentence satisfying all con-
straints.
(2)
Marie a emprunte? un tre`s long chemin
pour le retour.
Mary took a very long way for the return.
The first NP contains one lexical constituent,
Mary. Three constraints, among the 14 describing
the NP, are evaluated and all satisfied: Oblig(N),
stipulating that the head is realized, Const(N), in-
dicating the category N as a possible constituent,
and Excl(N, Pro), verifying that N is not realized
together with a pronoun. The following values
come from this characterization:
N+ N- E T W+ W- QI SR CC PI GI
3 0 3 14 10 0 1 1 0.21 1.04 1.04
We can see that, according to the fact that
all evaluated constraints are satisfied, QI and SR
equal 1. However, the fact that only 3 constraints
among 14 are evaluated lowers down the gram-
matical index. This last value, insofar as no con-
stituents are embedded, is the same as PI.
These results can be compared with another
constituent of the same sentence, the VP. This
construction also only contains satisfied prop-
erties. Its characterization is the following :
Char(VP)=Const(Aux, V, NP, PP) ; Oblig(V) ;
Uniq(V) ; Uniq(NP) ; Uniq(PP) ; Aux?V[part]
; V?NP ; Aux?V ; V?PP. On top of this set
of evaluated constraints (9 among the possible
25), the VP includes two embedded constructions
: a PP and a NP. A grammaticality index has
been calculated for each of them: GI(PP) = 1.24
GI(NP)=1.23. The following table indicates the
different values involved in the calculation of the
GI.
N+ N- E T W+ W- QI SR CC PI
9 0 9 25 31 0 1 1 0.36 1.06
GI Emb Const GI
1.23 1.31
The final GI of the VP reaches a high value. It
benefits on the one hand from its own quality (in-
dicated by PI) and on another hand from that of
its embedded constituents. In the end, the final GI
obtained at the sentence level is function of its own
PI (very good) and the NP and VP GIs, as shown
in the table:
N+ N- E T W+ W- QI SR CC PI
5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
1.17 1.28
Let?s compare now these evaluations with those
obtained for sentences with violated constraints,
as in the following examples:
(3) a.
Marie a emprunte? tre`s long chemin un
pour le retour.
Mary took very long way a for the return.
b. Marie a emprunte? un tre`s chemin pour le retour.
Mary took a very way for the return.
In (2a), 2 linear constraints are violated: a de-
terminer follows a noun and an AP in ?tre`s long
chemin un?. Here are the figures calculated for
this NP:
N+ N- E T W+ W- QI SR CC PI GI
8 2 10 14 23 10 0.39 0.80 0.71 0.65 0.71
61
The QI indicator is very low, the violated con-
straints being of heavy weight. The grammatical-
ity index is a little bit higher because a lot of con-
straints are also satisfied. The NP GI is then prop-
agated to its dominating construction, the VP. This
phrase is well formed and also contains a well-
formed construction (PP) as sister of the NP. Note
that in the following table summarizing the VP
indicators, the GI product of the embedded con-
stituents is higher than the GI of the NP. This is
due to the well-formed PP constituent. In the end,
the GI index of the VP is better than that of the
ill-formed NP:
N+ N- E T W+ W- QI SR CC PI
9 0 9 25 31 0 1 1 0.36 1.06
GI Emb Const GI
0.97 1.03
For the same reasons, the higher level construc-
tion S also compensates the bad score of the NP.
However, in the end, the final GI of the sentence
is much lower than that of the corresponding well-
formed sentence (see above).
N+ N- E T W+ W- QI SR CC PI
5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
1.03 1.13
The different figures of the sentence (2b) show
that the violation of a unique constraint (in this
case the Oblig(Adj) indicating the absence of the
head in the AP) can lead to a global lower GI than
the violation of two heavy constraints as for (2a).
In this case, this is due to the fact that the AP only
contains one constituent (a modifier) that does not
suffice to compensate the violated constraint. The
following table indicates the indices of the differ-
ent phrases. Note that in this table, each phrase is
a constituent of the following (i.e. AP belongs to
NP itself belonging to VP, and so on).
N+ N- E T W+ W- QI SR CC PI
AP 2 1 3 7 7 3 0.40 0.67 0.43 0.56
NP 10 0 10 14 33 0 1 1 0.71 1.12
VP 9 0 9 25 31 0 1 1 0.36 1.06
S 5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
AP 1 0.56
NP 0.56 0.63
VP 0.93 0.99
S 1.01 1.11
5 Judging acceptability of violations
We ran a questionnaire study presenting partic-
ipants with 60 experimental sentences like (11)
to (55) below. 44 native speakers of French
completed the questionnaire giving acceptability
judgements following the Magnitude Estimation
technique. 20 counterbalanced forms of the ques-
tionnaire were constructed. Three of the 60 ex-
perimental sentences appeared in each version in
each form of the questionnaire, and across the 20
forms, each experimental sentence appeared once
in each condition. Each sentence was followed
by a question concerning its acceptability. These
60 sentences were combined with 36 sentences of
various forms varying in complexity (simple main
clauses, simple embeddings and doubly nested
embeddings) and plausibility (from fully plausible
to fairly implausible according to the intuitions of
the experimenters). One randomization was made
of each form.
Procedure: The rating technique used was mag-
nitude estimation (ME, see (Bard96)). Partici-
pants were instructed to provide a numeric score
that indicates how much better (or worse) the cur-
rent sentence was compared to a given reference
sentence (Example: If the reference sentence was
given the reference score of 100, judging a tar-
get sentence five times better would result in 500,
judging it five times worse in 20). Judging the ac-
ceptability ratio of a sentence in this way results in
a scale which is open-ended on both sides. It has
been demonstrated that ME is therefore more sen-
sitive than fixed rating-scales, especially for scores
that would approach the ends of such rating scales
(cf. (Bard96)). Each questionnaire began with a
written instruction where the subject was made fa-
miliar with the task based on two examples. After
that subjects were presented with a reference sen-
tence for which they had to provide a reference
score. All following sentences had to be judged
in relation to the reference sentence. Individual
judgements were logarithmized (to arrive at a lin-
ear scale) and normed (z-standardized) before sta-
tistical analyses.
Global mean scores are presented figure 1. We
tested the reliability of results for different ran-
domly chosen subsets of the materials. Construc-
tions for which the judgements remain highly sta-
ble across subsets of sentences are marked by an
asterisk (rs > 0.90; p < 0.001). The mean relia-
bility across subsets is rs > 0.65 (p < 0.001).
What we can see in these data is that in par-
ticular violations within prepositional phrases are
not judged in a very stable way. The way they
are judged appears to be highly dependent on the
preposition used and the syntactic/semantic con-
text. This is actually a very plausible result, given
that heads of prepositional phrases are closed class
items that are much more predictable in many syn-
tactic and semantic environments than heads of
62
noun phrases and verb phrases. We will there-
fore base our further analyses mainly on violations
within noun phrases, verb phrases, and adjectival
phrases. Results including prepositional phrases
will be given in parentheses. Since the constraints
described above do not make any predictions for
semantic violations, we excluded examples 25, 34,
45, and 55 from further analyses.
6 Acceptability versus grammaticality
index
We compare in this section the results coming
from the acceptability measurements described in
section 5 and the values of grammaticality indices
obtained as proposed section 4.
From the sample of 20 sentences presented in fig-
ure 1, we have discarded 4 sentences, namely sen-
tence 25, 34, 45 and 55, for which the property
violation is of semantic order (see above). We are
left with 16 sentences, the reference sentence sat-
isfying all the constraints and 15 sentences violat-
ing one of the syntactic constraints. The results
are presented figure 2. Acceptability judgment
(ordinate) versus grammaticality index (abscissa)
is plotted for each sentence. We observe a high
coefficient of correlation (? = 0.76) between the
two distributions, indicating that the grammatical-
ity index derived from PG is a fairly good tracer of
the observed acceptability measurements.
The main contribution to the grammaticality in-
dex comes from the quality index QI (? = 0.69)
while the satisfaction ratio SR and the complete-
No violations
11. Marie a emprunte? un tre`s long chemin pour le retour 0.465
NP-violations
21. Marie a emprunte? tre`s long chemin un pour le retour -0.643 *
22. Marie a emprunte? un tre`s long chemin chemin pour le retour -0.161 *
23. Marie a emprunte? un tre`s long pour le retour -0.871 *
24. Marie a emprunte? tre`s long chemin pour le retour -0.028 *
25. Marie a emprunte? un tre`s heureux chemin pour le retour -0.196 *
AP-violations
31. Marie a emprunte? un long tre`s chemin pour le retour -0.41 *
32. Marie a emprunte? un tre`s long long chemin pour le retour -0.216 -
33. Marie a emprunte? un tre`s chemin pour le retour -0.619 -
34. Marie a emprunte? un grossie`rement long chemin pour le retour -0.058 *
PP-violations
41. Marie a emprunte? un tre`s long chemin le retour pour -0.581 -
42. Marie a emprunte? un tre`s long chemin pour pour le retour -0.078 -
43. Marie a emprunte? un tre`s long chemin le retour -0.213 -
44. Marie a emprunte? un tre`s long chemin pour -0.385 -
45. Marie a emprunte? un tre`s long chemin dans le retour -0.415 -
VP-violations
51. Marie un tre`s long chemin a emprunte? pour le retour -0.56 *
52.Marie a emprunte? emprunte? un tre`s long chemin pour le retour -0.194 *
53.Marie un tre`s long chemin pour le retour -0.905 *
54. Marie emprunte? un tre`s long chemin pour le retour -0.322 *
55. Marie a persuade? un tre`s long chemin pour le retour -0.394 *
Figure 1: Acceptability results
ness coefficient CC contributions, although signif-
icant, are more modest (? = 0.18 and ? = 0.17
respectively).
We present in figure 3 the correlation between
acceptability judgements and grammaticality in-
dices after the removal of the 4 sentences pre-
senting PP violations. The analysis of the experi-
ment described in section 5 shows indeed that ac-
ceptability measurements of the PP-violation sen-
tences is less reliable than for others phrases. We
thus expect that removing these data from the sam-
ple will strengthen the correlation between the two
distributions. The coefficient of correlation of the
12 remaining data jumps to ? = 0.87, as expected.
Figure 2: Correlation between acceptability judgement and
grammaticality index
Figure 3: Correlation between acceptability judgement and
grammaticality index removing PP violations
Finally, the adequacy of the PG grammatical-
ity indices to the measurements was investigated
by means of resultant analysis. We adapted the
parameters of the model in order to arrive at a
good fit based on half of the sentences materials
(randomly chosen from the full set), with a cor-
relation of ? = 0.85 (? = 0.76 including PPs)
between the grammaticality index and acceptabil-
ity judgements. Surprisingly, we arrived at the
best fit with only two different weights: A weight
of 2 for Exclusion, Uniqueness, and Requirement,
and a weight of 5 for Obligation, Linearity, and
Constituency. This result converges with the hard
63
and soft constraint repartition idea as proposed by
(Keller00).
The fact that the grammaticality index is based
on these properties as well as on the number of
constraints to be evaluated, the number of con-
straints to the satisfied, and the goodness of em-
bedded constituents apparently results in a fined
grained and highly adequate prediction even with
this very basic distinction of constraints.
Fixing these parameters, we validated the pre-
dictions of the model for the remaining half of the
materials. Here we arrived at a highly reliable cor-
relation of ? = 0.86 (? = 0.67 including PPs) be-
tween PG grammaticality indices and acceptabil-
ity judgements.
7 Conclusion
The method described in this paper makes it pos-
sible to give a quantified indication of sentence
grammaticality. This approach is direct and takes
advantage of a constraint-based representation of
syntactic information, making it possible to repre-
sent precisely the syntactic characteristics of an in-
put in terms of satisfied and (if any) violated con-
straints. The notion of grammaticality index we
have proposed here integrates different kind of in-
formation: the quality of the description (in terms
of well-formedness degree), the density of infor-
mation (the quantity of constraints describing an
element) as well as the structure itself. These three
parameters are the basic indicators of the gram-
maticality index.
The relevance of this method has been ex-
perimentally shown, and the results described in
this paper illustrate the correlation existing be-
tween the prediction (automatically calculated)
expressed in terms of GI and the acceptability
judgment given by subjects.
This approach also presents a practical interest:
it can be directly implemented into a parser. The
next step of our work will be its validation on large
corpora. Our parser will associate a grammatical
index to each sentence. This information will be
validated by means of acceptability judgments ac-
quired on the basis of a sparse sampling strategy.
References
Bard E., D. Robertson & A. Sorace (1996) ?Magnitude
Estimation of Linguistic Acceptability?, Language
72:1.
Blache P. & J.-P. Prost (2005) ?Gradience, Construc-
tions and Constraint Systems?, in H. Christiansen &
al. (eds), Constraint Solving and NLP, Lecture Notes
in Computer Science, Springer.
Blache P. (2005) ?Property Grammars: A Fully
Constraint-Based Theory?, in H. Christiansen & al.
(eds), Constraint Solving and NLP, Lecture Notes in
Computer Science, Springer.
Blache P. (2006) ?A Robust and Efficient Parser for
Non-Canonical Inputs?, in proceedings of Robust
Methods in Analysis of Natural Language Data,
EACL workshop.
Chomsky N.. (1975) The Logical Structure of Linguis-
tic Theory, Plenum Press
Croft W. & D. Cruse (2003) Cognitive Linguistics,
Cambridge University Press.
Foth K., M. Daum & W. Menzel (2005) ?Parsing Unre-
stricted German Text with Defeasible Constraints?,
in H. Christiansen & al. (eds), Constraint Solv-
ing and NLP, Lecture Notes in Computer Science,
Springer.
Fillmore C. (1998) ?Inversion and Contructional In-
heritance?, in Lexical and Constructional Aspects of
Linguistic Explanation, Stanford University.
Kay P. & C. Fillmore (1999) ?Grammatical Construc-
tions and Linguistic Generalizations: the what?s x
doing y construction?, Language.
Keller F. (2000) Gradience in Grammar. Experimental
and Computational Aspects of Degrees of Grammat-
icality, Phd Thesis, University of Edinburgh.
Keller F. (2003) ?A probabilistic Parser as a Model
of Global Processing Difficulty?, in proceedings of
ACCSS-03
Menzel W. & I. Schroder (1998) ?Decision procedures
for dependency parsing using graded constraints?,
in S. Kahane & A. Polgue`re (eds), Proc. Colin-
gACL Workshop on Processing of Dependency-
based Grammars.
Prince A. & Smolensky P. (1993) Optimality The-
ory: Constraint Interaction in Generative Gram-
mars, Technical Report RUCCS TR-2, Rutgers Cen-
ter for Cognitive Science.
Sag I., T. Wasow & E. Bender (2003) Syntactic Theory.
A Formal Introduction, CSLI.
Schro?der I. (2002) Natural Language Parsing with
Graded Constraints. PhD Thesis, University of
Hamburg.
Sorace A. & F. Keller (2005) ?Gradience in Linguistic
Data?, in Lingua, 115.
64
A Robust and Efficient Parser for Non-Canonical Inputs 
 
 
Philippe Blache 
CNRS & Universit? de Provence 
29, Avenue Robert Schuman 
13621 Aix-en-Provence, France 
pb@lpl.univ-aix.fr
 
  
 
Abstract 
We present in this paper a parser relying 
on a constraint-based formalism called 
Property Grammar. We show how con-
straints constitute an efficient solution in 
parsing non canonical material such as 
spoken language transcription or e-mails. 
This technique, provided that it is imple-
mented with some control mechanisms, 
is very efficient. Some results are pre-
sented, from the French parsing evalua-
tion campaign EASy. 
1 Introduction 
Parsing spoken languages and non canonical in-
puts remains a challenge for NLP systems. Many 
different solutions have been experimented, de-
pending on the kind of material to be parsed or 
the kind of application: in some cases, superficial 
information such as bracketing is enough 
whereas in other situations, the system needs 
more details. The question of robustness, and 
more generally the parsing strategy, is addressed 
differently according to these parameters. Classi-
cally, three families of solutions are proposed: 
 
- Reducing the complexity of the output 
- Controlling the parsing strategy 
- Training and adapting the system to the 
type of input 
 
In the first case, the idea consists in building 
structures with little information, even under-
specified (which means the possibility of build-
ing partial structures). We find in this family the 
different shallow parsing techniques (see for ex-
ample [Hindle83], [Abney96]). Unsurprisingly, 
the use of statistical methods is very frequent and 
efficient in this kind of application (see [Tjong 
Kim Sang00] for some results of a comparison 
between different shallow parsers). Generally, 
such parsers (being them symbolic or not) are 
deterministic and build non recursive units. In 
some cases, they can also determine relations 
between units.  
 
The second family contains many different tech-
niques. The goal is to control a given parsing 
strategy by means of different mechanisms. 
Among them, we can underline three proposals: 
 
- Implementing recovering mechanisms, 
triggering specific treatments in case of 
error (cf. [Boulier05]) 
- Controlling the parsing process by 
means of probabilistic information (cf. 
[Johnson98]) 
- Controlling deep parsers by means of 
shallow parsing techniques (cf. [Crys-
mann02], [UszKoreit02], [Marimon02]) 
 
The last kind of control mechanism consists in 
adapting the system to the material to be parsed. 
This can be done in different ways: 
 
- Adding specific information in order to 
reduce the search space of the parsing 
process. This kind of information can 
appear under the form of ad hoc rules or 
information depending on the kind of 
data to be treated. 
- Adapting the resources (lexicon, gram-
mars) to the linguistic material 
 
These different strategies offer several advan-
tages and some of them can be used together. 
Their interest is that the related questions of ro-
bustness and efficiency are both taken into ac-
count. However, they do not constitute a generic 
19
solution in the sense that something has to be 
modified either in the goal, in the formalism or in 
the process. In other words, they constitute an 
additional mechanism to be plugged into a given 
framework. 
 
We propose in this paper a parsing technique 
relying on a constraint-based framework being 
both efficient and robust without need to modify 
the underlying formalism or the process. The 
notion of constraints is used in many different 
ways in NLP systems. They can be a very basic 
filtering process as proposed by Constraint 
Grammars (see [Karlsson90]) or can be part to 
an actual theory as with HPSG (see [Sag03]), the 
Optimality Theory (see [Prince03]) or Constraint 
Dependency Grammars (cf. [Maruyama90]). Our 
approach is very different: all information is rep-
resented by means of constraints; they do not 
stipulate requirements on the syntactic structure 
(as in the above cited approaches) but represent 
directly syntactic knowledge. In this approach, 
robustness is intrinsic to the formalism in the 
sense that what is built is not a structure of the 
input (for example under the form of a tree) but a 
description of its properties. The parsing mecha-
nism can then be seen as a satisfaction process 
instead of a derivational one. Moreover, it be-
comes possible, whatever the form of the input, 
to give its characterization. The technique relies 
on constraint relaxation and is controlled by 
means of a simple left-corner strategy. One of its 
interests is that, on top of its efficiency, the same 
resources and the same parsing technique is used 
whatever the input.  
 
After a presentation of the formalism and the 
parsing scheme, we describe an evaluation of the 
system for the treatment of spoken language. 
This evaluation has been done for French during 
the evaluation campaign Easy.  
 
2 Property Grammars: a constraint-
based formalism 
 
We present in this section the formalism of Prop-
erty Grammars (see [B?s99] for preliminary 
ideas, and [Blache00], [Blache05] for a presenta-
tion). The main characteristics of Property 
Grammars (noted hereafter PG), is that all infor-
mation is represented by means of constraints. 
Moreover, grammaticality does not constitute the 
core question but become a side effect of a more 
general notion called characterization: an input is 
not associated to a syntactic structure, but de-
scribed with its syntactic properties.  
 
PG makes it possible to represent syntactic in-
formation in a decentralized way and at different 
levels. Instead of using sub-trees as with classical 
generative approaches, PG specifies directly con-
straints on features, categories or set of catego-
ries, independently of the structure to which they 
are supposed to belong. This characteristic is 
fundamental in dealing with partial, underspeci-
fied or non canonical data. It is then possible to 
stipulate relations between two objects, inde-
pendently from their position in the input or into 
a structure. The description of the syntactic prop-
erties of an input can then be done very pre-
cisely, including the case of non canonical or non 
grammatical input. We give in the remaining of 
the section a brief overview of GP characteristics 
 
All syntactic information is represented in PG by 
means of constraints (also called properties). 
They stipulate different kinds of relation between 
categories such as linear precedence, imperative 
co-occurrence, dependency, repetition, etc. There 
is a limited number of types of properties. In the 
technique described here, we use the following 
ones: 
 
- Linear precedence: Det < N (a determiner 
precedes the noun) 
- Dependency: AP ? N (an adjectival phrase 
depends on the noun) 
- Requirement: V[inf] ? to (an infinitive 
comes with to) 
- Exclusion: seems ? ThatClause[subj] (the 
verb seems cannot have That clause subjects) 
- Uniqueness : UniqNP{Det}(the determiner is 
unique in a NP) 
- Obligation : ObligNP{N, Pro}(a pronoun or a 
noun is mandatory in a NP) 
 
This list can be completed according to the needs 
or the language to be parsed. In this formalism, a 
category, whatever its level is described with a 
set of properties, all of them being at the same 
level and none having to be verified before an-
other.  
 
Parsing a sentence in PG consists in verifying for 
each category the set of corresponding properties 
in the grammar. More precisely, the idea consists 
in verifying for each constituent subset its rele-
vant constraints (i.e. the one applying to the ele-
20
ments of the subset). Some of these properties 
can be satisfied, some other can be violated. The 
result of this evaluation, for a category, is a set of 
properties together with their evaluation. We call 
such set the characterization of the category. 
Such an approach makes it possible to describe 
any kind of input. 
 
Such flexibility has however a cost: parsing in 
PG is exponential (cf. [VanRullen05]). This 
complexity comes from several sources. First, 
this approach offers the possibility to consider all 
categories, independently from its corresponding 
position in the input, as possible constituent for 
another category. This makes it possible for ex-
ample to take into account long distance or non 
projective dependencies between two units. 
Moreover, parsing non canonical utterances re-
lies on the possibility of building characteriza-
tions with satisfied and violated constraints. In 
terms of implementation, a property being a con-
straint, this means the necessity to propose a 
constraint relaxation technique. Constraint re-
laxation and discontinuity are the main complex-
ity factors of the PG parsing problem. The tech-
nique describe in the next section propose to con-
trol these aspects.  
 
3 Parsing in PG 
 
Before a description of the controlled parsing 
technique proposed here, we first present the 
general parsing schemata in PG. The process 
consists in building the list of all possible sets of 
categories that are potentially constituents of a 
syntactic unit (also called constructions). A char-
acterization is built for each of this set. Insofar as 
constructions can be discontinuous, it is neces-
sary to build all possible combinations of catego-
ries, in other words, the subsets set of the catego-
ries corresponding to the input to be parsed, 
starting from the lexical categories. We call as-
signment such a subset. All assignments have 
then, theoretically, to be evaluated with respect 
to the grammar. This means, for each assign-
ment, traversing the constraint system and evalu-
ating all relevant constraints (i.e. constraints in-
volving categories belonging to the assignment). 
For some assignments, no property is relevant 
and the corresponding characterization is the 
empty set: we say in this case that the assignment 
in non productive. In other cases, the characteri-
zation is formed with all the evaluated properties, 
whatever their status (satisfied or not). At the 
first stage, all constructions contain only lexical 
categories, as in the following example: 
 
Construction Assignment Characterization 
AP  {Adv, Adj} {Adv < Adj; Adv ? Adj; 
...} 
NP {Det, N} {Det < N; Det ? N; N ? 
Pro; ...} 
  
An assignment with a productive characteriza-
tion entails the instantiation of the construction 
as a new category; added to the set of categories. 
In the previous examples, AP and NP are then 
added to the initial set of lexical categories. A 
new set of assignments is then built, including 
these new categories as possible constituents, 
making it possible to identify new constructions. 
This general mechanism can be summarized as 
follows: 
 
Initialization
? word at a position i:
create the set ci of its possible 
categories
 K ?  {ci | 1<i<number of words}
 S ?  set of subsets of K 
Repeat
? Si ? S
     if Si  is a productive assignment 
    add ki the characterization 
   label to K 
 S ?  set of subsets of K 
Until new characterization are built 
 
This parsing process underlines the complexity 
coming from the number of assignments to be 
taken into account: this set has to be rebuilt at 
each step (i.e. when a new construction is 
added).  
 
As explained above, each assignment has to be 
evaluated. This process comes to build a charac-
terization formed by the set of its relevant prop-
erties. A property p is relevant for an assignment 
A when A contains categories involved in the 
evaluation of p. In the case of unary properties 
constraining a category c, the relevance is di-
rectly known. In the case of n-ary properties, the 
situation is different for positive or negative 
properties. The former (e.g. cooccurrence con-
straints) concern two realized categories. In this 
case, c1 and c2 being these categories, we have 
{c1, c2} ? A.  In the case of negative properties 
(e.g. cooccurrence restriction), we need to have 
either c1 ?A or c2 ?A.  
 
When a property is relevant for a given A, its 
satisfiability is evaluated, according to the prop-
21
erty semantics, each property being associated to 
a solver. The general process is described as fol-
lows:  
 
Let G the set of properties in the gram-
mar, let A an assignment 
? pi ? G, if pi is relevant 
 Evaluate the satisfiability of pi
  
for A
 Add pi and its evaluation to the
  characterization C of A
Check whether C is productive 
 
In this process, for all assignments, all properties 
have to be checked to verify their relevance and 
eventually their satisfiability.  
 
The last aspect of this general process concerns 
the evaluation of the productivity of the charac-
terization or an assignment. A productive as-
signment makes it possible to instantiate the cor-
responding category and to consider it as real-
ized. A characterization is obviously productive 
when all properties are satisfied. But it is also 
possible to consider an assignment as productive 
when it contains violated properties. It is then 
possible to build categories, or more generally 
constructions, even for non canonical forms. In 
this case, the characterization is not entirely posi-
tive. This process has to be controlled. The basic 
control consists in deciding a threshold of vio-
lated constraints. It is also possible to be more 
precise and propose a hierarchization of the con-
straint system: some types of constraints or some 
constraints can play a more important role than 
others (cf. [Blache05b]).  
 
A controlled version of this parsing schema, im-
plemented in the experimentation described in 
the next section, takes advantage of the general 
framework, in particular in terms of robustness 
implemented as constraint relaxation. The proc-
ess is however controlled for the construction of 
the assignment. 
 
This control process relies on a left-corner strat-
egy, adapted to the PG parsing schema. This 
strategy consists in identifying whether a cate-
gory can start a new phrase. It makes it possible 
to drastically reduce the number of assignments 
and then control ambiguity. Moreover, the left 
corner suggests a construction label. The set of 
properties taken into consideration when build-
ing the characterization is then reduced to the set 
of properties corresponding to the label. These 
two controls, plus a disambiguation of the lexical 
level by means of an adapted POS tagger, render 
the parsing process very efficient.  
 
The left corner process relies on a precedence 
table, calculated for each category according to 
the precedence properties in the grammar. This 
table is built automatically in verifying for each 
category whether, according to a given construc-
tion, it can precede all the other categories. The 
process consists in verifying that the category is 
not a left member of a precedence property of the 
construction. If so, the category is said to be a 
possible left corner of the construction. The 
precedence table contains then for each category 
the label of the construction for which it can be 
left corner. 
 
During the process, when a category is a poten-
tial left corner of a construction C, we verify that 
the C is not the last construction opened by a left 
corner. If so, a new left corner is identified, and 
C is added to the set of possible constituents (us-
able by other assignments). Moreover, the char-
acterization of the assignment beginning with ci 
is built in verifying the subset of properties de-
scribing C.  
 
The generation of the assignments can also be 
controlled by means of a co-constituency table. 
This table consists for each category, in indicat-
ing all the categories with which it belongs to a 
positive property. This table is easily built with a 
simple traversal of the constraint system. Adding 
a new category ci  to an assignment A is possible 
only when ci appears as a co-constituent of a 
category belonging to A. 
 
S initial set of lexical categories 
Identification all the left corners 
For all C, construction opened by a left
  corner ci with G? the set of
  properties describing C 
 Build assignments beginning by ci
 Build characterizations verifying G? 
  
The parsing mechanism described here takes ad-
vantage of the robustness of PG. All kind of in-
put, whatever its form, can be parsed because if 
the possibility of relaxing constraints. Moreover, 
the control technique makes it possible to reduce 
the complexity of the process without modifying 
its philosophy. 
 
4 Evaluation  
 
22
We experimented this approach during the 
French evaluation campaign EASy (cf. 
[Paroubek05]). The test consisted in parsing sev-
eral files containing various kinds of material: 
literature, newspaper, technical texts, questions, 
e-mails and spoken language. The total size of 
this corpus is one million words. Part of this cor-
pus was annotated with morpho-syntactic (POS 
tags) and syntactic annotations. The last one pro-
vides bracketing as well as syntactic relations 
between units. The annotated part of the corpus 
represents 60,000 words and constitutes the gold 
standard.  
 
The campaign consisted for the participants to 
parse the entire corpus (without knowing what 
part of the corpus constituted the reference). The 
results of the campaign are not yet available con-
cerning the evaluation of the relations. The fig-
ures presented in this section concern constituent 
bracketing. The task consisted in identifying 
minimal non recursive constituents described by 
annotation guidelines given to the participants. 
The different categories to be built are: GA (ad-
jective group: adjective or passed participle), GN 
(nominal group: determiner, noun adjective and 
its modifiers), GP (prepositional group), GR (ad-
verb), NV (verbal nucleus: verb, clitics) and PV 
(verbal propositional group). 
 
Our system parses the entire corpus (1 million 
words) in 4 minutes on a PC. It presents then a 
very good efficiency.  
 
We have grouped the different corpora into three 
different categories: written texts (including 
newspapers, technical texts and literature), spo-
ken language (orthographic transcription of 
spontaneous speech) and e-mails. The results are 
the following: 
 
  Precision Recall F-mesure
Written texts 77.78 82.96 79.84 
Spoken lan-
guage 75.13 78.89 76.37 
E-Mails 71.86 79.06 74.42 
 
These figures show then very stable results in 
precision and recall, with only little loss of effi-
ciency for non-canonical material. When study-
ing more closely the results, some elements of 
explanation can be given. The e-mail corpus is to 
be analyzed separately: many POS tagging er-
rors, due to the specificity of this kind of input 
explain the difference. Our POS-tagger was not 
tuned for this kind of lexical material.  
 
The interpretation of the difference between writ-
ten and oral corpora can have some linguistic 
basis. The following figures give quantitative 
indications on the categories built by the parser. 
The first remark is that the repartition between 
the different categories is the same. The only 
main difference concerns the higher number of 
nucleus VP in the case of written texts. This 
seems to support the classical idea that spoken 
language seems to use more nominal construc-
tions than the written one.  
 
Constituents for Written Corpora
7847
18693
10706
4605
17599
1012
0
2000
4000
6000
8000
10000
12000
14000
16000
18000
20000
GA GN GP GR NV PV
Constituants
 
 
Constituents for Oral Corpora
5460
16726
9608
4992
13020
1001
0
2000
4000
6000
8000
10000
12000
14000
16000
18000
GA GN GP GR NV PV
Constituants
 
 
The problem is that our parser encounters some 
difficulties in the identification of the NP bor-
ders. It very often also includes some material 
belonging in the grammar given during the cam-
paign to AP or VP. The higher proportion of NPs 
in spoken corpora is an element of explanation 
for the difference in the results. 
 
23
5 Conclusion 
The first results obtained during the evaluation 
campaign described in this paper are very inter-
esting. They illustrate the relevance of using 
symbolic approaches for parsing non-canonical 
material. The technique described here makes it 
possible to use the same method and the same 
resources whatever the kind of input and offers 
the possibility to do chunking as well as deep 
analysis. Moreover, such techniques, provided 
that they are implemented with some control 
mechanisms, can be very efficient: our parser 
treat more than 4,000 words per second. It con-
stitutes then an efficient tool capable of dealing 
with large amount of data. On top of this effi-
ciency, the parser has good results in terms of 
bracketing, whatever the kind of material parsed. 
This second characteristics also shows that the 
system can be used in real life applications. 
 
In terms of theoretical results, such experimenta-
tion shows the interest of using constraints. First, 
they makes it possible to represent very fine-
level information and offers a variety of control 
mechanisms, relying for example on the possibil-
ity of weighting them. Moreover, constraint re-
laxation techniques offer the possibility of build-
ing categories violating part of syntactic descrip-
tion of the grammar. They are then particularly 
well adapted to the treatment of non canonical 
texts. The formalism of Property Grammars be-
ing a fully constraint-based approach, it consti-
tutes an efficient solution for the description of 
any kind of inputs. 
Reference 
[Abney 96] Abney S. (1996) ?Partial Parsing via Fi-
nite-State Calculus?, in proceedings of ESSLLI'96 
Robust Parsing Workshop 
[B?s99] B?s G. (1999) ?La phrase verbale noyau en 
fran?ais?, in Recherches sur le fran?ais parl?, 15, 
Universit? de Provence. 
[Blache00] Blache P. (2000) ?Constraints, Linguistic 
Theories and Natural Language Processing?, in 
Natural Language Processing, D. Christodoulakis 
(ed), LNAI 1835, Springer-Verlag 
[Blache05a] Blache P. (2005) ?Property Grammars: A 
Fully Constraint-Based Theory?, in Constraint 
Solving and Language Processing, H. Christiansen 
& al. (eds), LNAI 3438, Springer 
[Boullier 05] Boullier P. & B. Sagot (2005) ?Efficient 
and robust LFG parsing: SxLfg?, in Proceedings of 
IWPT '05. 
[Crysmann02] Crysmann B. A. Frank, B. Kiefer, S. 
M?ller, G. Neumann, J. Piskorski, U. Sch?fer, M. 
Siegel, H. Uszkoreit, F. Xu, M. Becker & H. 
Krieger (2002) ?An Integrated Architecture for 
Shallow and Deep Processing?, in proceedings of 
ACL-02. 
[Frank03] Frank A., M. Becker, B. Crysmann, B. 
Kiefer & U. Sch?fer (2003) ?Integrated Shallow 
and Deep Parsing: TopP meets HPSG?, in proceed-
ings of ACL-03. 
 [Hindle83] Hindle D. (1983) User manual for Fid-
ditch, a deterministic parser, Technical memoran-
dum 7590-142, Naval Research Laboratory.  
[Johnson98] Johnson M. (1998) ?PCFG Models of 
Linguistic Tree Representations'?, in Computa-
tional Linguistics, 24:4. 
[Karlsson90] Karlsson F. (1990) ?Constraint grammar 
as a framework for parsing running texts?, in pro-
ceedings of ACL-90. 
[Marimon02] Marimon M. (2002) ?Integrating Shal-
low Linguistic Processing into a Unification-Based 
Spanish Grammar?, in proceedings of COLING-02. 
[Maruyama90] Maruyama H. (1990) ?Structural Dis-
ambiguation with Constraint Propagation'?, in pro-
ceedings of ACL'90. 
 [Paroubek05] Paroubek P., L. Pouillot, I. Robba & A. 
Vilnat (2005) ?EASy : campagne d??valuation  des 
analyseurs syntaxiques?, in proceedings of the 
workshop EASy, TALN-2005. 
[Prince93] Prince A. & Smolensky P. (1993) ?Opti-
mality Theory: Constraint Interaction in Generative 
Grammars?, Technical Report RUCCS TR-2, Rut-
gers Center for Cognitive Science. 
[Tjong Kim Sang00] Tjong Kim Sang E. & S 
Buchholz (2000) ?Introduction do the CoNLL-
2000 Shared Task: Chunking?, in proceedings of 
CoNLL-2000. 
[Uszkoreit02] Uszkoreit H. (2002) ?New Chances for 
Deep Linguistic Processing?, in proceedings of 
COLING-02. 
[VanRullen05] Van Rullen T. (2005), Vers une ana-
lyse syntaxique ? granularit? variable, PhD Thesis, 
Universit? de Provence. 
24
Coling 2010: Poster Volume, pages 63?71,
Beijing, August 2010
A Formal Scheme for Multimodal Grammars
Philippe Blache & Laurent Pr?vot
LPL-CNRS, Universit? de Provence
blache@lpl-aix.fr
Abstract
We present in this paper a formal approach
for the representation of multimodal in-
formation. This approach, thanks to the
to use of typed feature structures and hy-
pergraphs, generalizes existing ones (typ-
ically annotation graphs) in several ways.
It first proposes an homogenous represen-
tation of different types of information
(nodes and relations) coming from differ-
ent domains (speech, gestures). Second,
it makes it possible to specify constraints
representing the interaction between the
different modalities, in the perspective of
developing multimodal grammars.
1 Introduction
Multimodality became in the last decade an im-
portant challenge for natural language processing.
Among the problems we are faced with in this do-
main, one important is the understanding of how
does the different modalities interact in order to
produce meaning. Addressing this question re-
quires to collect data (building corpora), to de-
scribe them (enriching corpora with annotations)
and to organize systematically this information
into a homogeneous framework in order to pro-
duce, ideally, multimodal grammars.
Many international projects address this ques-
tion from different perspectives: data represen-
tation and coding schemes (cf. ISLE (Dybk-
jaer, 2001), MUMIN (Allwood, 2005), etc.), cor-
pus annotation (cf. LUNA (Rodriguez, 2007) or
DIME (Pineda, 2000), etc.), annotation and edit-
ing tools (such as NITE NXT (Carletta, 2003),
Anvil (Kipp, 2001), Elan (Wittenburg, 2006),
Praat (Boersma, 2009), etc.).
We propose in this paper a generic approach
addressing both formal representation and con-
crete annotation of multimodal data, that relies on
typed-feature structure (TFS), used as a descrip-
tion language on graphs. This approach is generic
in the sense that it answers to different needs: it
provides at the same time a formalism directly us-
able for corpus annotation and a description lan-
guage making it possible to specify constraints
that constitute the core of a multimodal grammar.
In the first section, we motivate the use of TFS
and present how to concretely implement them for
multimodal annotation. We address in the second
section one of the most problematic question for
multimodal studies: how to represent and imple-
ment the relations between the different domains
and modalities (a simple answer in terms of time
alignment being not powerful enough). In the last
section, we describe how to make use of this rep-
resentation in order to specify multimodal gram-
mars.
2 Typed-feature structures modeling
Information representation is organized in two di-
mensions: type hierarchies and constituency re-
lations (typically, a prosodic unit is a set of syl-
lables, which in turn are sets of phonemes). The
former corresponds to an is-a relation, the latter to
a part-of one. For example intonational phrase is
a subtype of prosodic phrase, and phonemes are
constituents of syllables.
Such an organization is directly represented by
means of typed feature structures. They can be
considered as a formal annotation schema, used as
63
a preliminary step before the definition of the con-
crete coding scheme1. This step is necessary when
bringing together information (and experts) from
different fields: it constitutes a common represen-
tation framework, homogenizing information rep-
resentation. Moreover, it allows to clearly distin-
guish between knowledge representation and an-
notation. The coding scheme, at the annotation
level (labels, features, values), is deduced from
this formal level.
The remaining of the section illustrates how
to represent objects from different domains by
means of TFS. The Figure 1 presents the type hi-
erarchy and the constituency structure of objects
taken here as example.
2.1 Phonetics
The phoneme is used as primary data: this object
is at the lowest level of the constituent hierarchy
(most of the objects are set of phonemes). The fol-
lowing feature structure proposes a precise encod-
ing of the main properties describing a phoneme,
including articulatory gestures.
phon
?
???????????????????
SAMPA_LABEL sampa_unit
CAT
{
vowel, consonant
}
TYPE
{
occlusive, fricative, nasal, etc.
}
ARTICULATION
?
?????????
LIP
[
PROTUSION string
APERTURE aperture
]
TONGUE
?
??
TIP
[
LOCATION string
DEGREE string
]
BODY
[
LOCATION string
DEGREE string
]
?
??
VELUM aperture
GLOTTIS aperture
?
?????????
ROLE
[
EPENTHETIC boolean
LIAISON boolean
]
?
???????????????????
Phonemes being at the lowest level, they do not
have any constituents. They are not organized
into precise subtypes. The feature structure rep-
resent then the total information associated with
this type.
2.2 Prosody
As seen above, prosodic phrases are of two differ-
ent subtypes: ap (accentual phrases) and ip (into-
national phrases). The prosodic type hierarchy is
represented as follows:
1This approach has been first defined and experimented
in the XXXX project, not cited for anonymity reasons.
pros_phr


HHH
H
ap[
LABEL AP
CONSTS list(syl)
] ip?
???
LABEL IP
CONSTS list(ap)
CONTOUR
[
DIRECTION string
POSITION string
FUNCTION string
]
?
???
Accentual phrases have two appropriate fea-
tures: the label which is simply the name of the
corresponding type, and the list of constituents, in
this case a list of syllables. The objects of type ip
contain the list of its constituents (a set of aps) as
well as the description of its contour. A contour is
a prosodic event, situated at the end of the ip and
is usually associated to an ap.
The prosodic phrases are defined as set of syl-
lables. They are described by several appropriate
features: the syllable structure, its position in the
word, its possibility to be accented or prominent:
syl
?
??????
STRUCT syl_struct
POSITION
[
RANK
{
integer
}
SYL_NUMBER
{
integer
}
]
ACCENTUABLE boolean
PROMINENCE boolean
CONSTITUENTS list(const_syl)
?
??????
Syllable constituents (objects of type const_syl)
are described by two different features: the set of
phonemes (syllable constituents), and the type of
the constituent (onset, nucleus and coda). Note
that each syllable constituent can contain a set of
phonemes.
const_syl
[
PHON list(phon)
CONST_TYPE
{
onset, nucleus, coda
}
]
2.3 Disfluencies
We can distinguish two kinds of disfluencies: non
lexicalized (without any lexical material, such as
lengthening, silent pauses or filled pauses) and
lexicalized (non-voluntary break in the phrasal
flow, generating a word or a phrase fragment).
Lexicalized disfluencies have a particular organi-
zation with three subparts (or constituents):
? Reparandum: the word or phrase fragment,
in which the break occurs
? Break: a point or an interval that can eventu-
ally be filled by a fragment repetition, paren-
thetical elements, etc.
64
object



  
 
@@
@
PPPP
PPPP
PP
pros_phr
 Hip ap
phono
 HHsyllable phoneme
disfluence
 Hlex non-lex
gest
 HHHhand head ...
IP ::= AP?
AP ::= SYL+
SYL ::= CONST_SYL+
CONST_SYL ::= PHON+
DISF ::= REPRANDUM BREAK REPRANS
Figure 1: Type and constituent hierarchies
? Reparans: all that follow the break and
recovers the reparandum (in modifying or
completing it) or simply left it uncompleted.
The general disfluency type hierarchy, with the
appropriate features at each level is given in the
following figure:
disfluency


HHH
HH
lex[
REPRANDUM frag
BREAK_INT break
]


HHH
H
repaired[
TYPE rep
REPRANS change
] incomplete[
DIS_TYPE inc
]
non_lex
 HHfilled[
TYPE fill
] silent[
TYPE sil
]
2.4 Gestures
Besides verbal communication, gestures consti-
tute the main aspect of multimodality. In multi-
modal annotation, this is probably the most dif-
ficult and time-consuming task. Moreover, only
few works really focus on a precise description of
all the different domains of verbal and non verbal
modalities. The TFS-based approach proposed
here answers to the first need in such a perspec-
tive: a common representation framework.
We give in this section a brief illustration of
the representation of one gesture (hands). It re-
lies on adaptation of different proposals, espe-
cially (Kipp03) or MUMIN (Allwood, 2005), both
integrating McNeill?s gesture description (Mc-
Neill05).
The following structure encodes the description
of gesture phases, phrases (representing different
semiotic types), the hand shape as well as its ori-
entation, the gesture space, and the possible con-
tact with bodies or objects. A last feature also
describes the movement itself: trajectory, qual-
ity (fast, normal or slow) and amplitude (small,
medium and large).
hands_type
?
?????????????????????????
SYMMETRY boolean
PHASE Phase_Type
PHRASE
?
??????
SEMIOTIC Type Semiotic_Type
EMBLEM Emblem_Type
DEICTIC Deictic_Type
METAPHORIC Metaphoric_Type
PASSIVE_HAND boolean
ACTIVE_HAND boolean
ICONIC Iconic_Type
?
??????
HANDSHAPE
[SHAPE HandShape_Type
LAX boolean
]
GESTURESPACE Space_Type
ORIENTATION Orientation_Type
CONTACT
[ADAPTOR Adaptor_Type
CONTACT PART Contact_Type
]
MOVEMENT
[TRAJECTORY Trajectory_Type
AMPLITUDE Amplitude_Type
QUALITY quality_Type
]
?
?????????????????????????
2.5 Application
We have experimented this modeling in the com-
plete annotation of a multimodal corpus (see
(Blache, 2010)). In this project, a complete TFS
model has been first designed, covering all the
different domains (prosody, syntax, gestures, dis-
course, etc.). From this model, the annotations
have been created, leading to a 3-hours corpus of
narrative dialogs, fully transcribed. The corpus
is fully annotated for some domains (phonetics,
prosody and syntax) and partly for others (ges-
tures, discourse, disfluencies, specific phenom-
ena). The result is one of the first large annotated
multimodal corpus.
3 Graphs for Multimodal Annotation
Graphs are frequently used in the representation
of complex information, which is the case with
multimodality. As for linguistic annotation, one
of the most popular representations is Annotation
Graphs (Bird, 2001). They have been proposed
in particular in the perspective of anchoring dif-
ferent kinds of information in the same reference,
65
making it possible to align them2. In AGs, nodes
represent positions in the signal while edges bear
linguistic information. Two edges connecting the
same nodes are aligned: they specify different in-
formation on the same part of the input. Implic-
itly, this means that these edges bear different fea-
tures of the same object.
Such a representation constitutes the basis of
different approaches aiming at elaborating generic
annotation formats, for example LAF (and its ex-
tension GrAF (Ide, 2007)). In this proposal, edge
labels can be considered as nodes in order to build
higher level information. One can consider the re-
sult as an hypergraph, in which nodes can be sub-
graphs.
We propose in this section a more generalized
representation in which nodes are not positions in
the signal, but represent directly objects (or set of
objects). All nodes have here the same structure,
being them nodes or hypernodes. The main inter-
est of this proposal, on top of having an homoge-
neous representation, is the possibility to anchor
information in different references (temporal, spa-
tial or semantic).
3.1 Nodes
As seen above, multimodal annotation requires
the representation of different kinds of informa-
tion (speech signal, video input, word strings, im-
ages, etc.). The objects3 that will be used in the
description (or the annotation) of the input are of
different nature: temporal or spatial, concrete or
abstract, visual or acoustic, etc. A generic de-
scription requires first a unique way of locating
(or indexing) all objects, whatever their domain.
In this perspective, an index (in the HPSG sense)
can be specified, relying on different information:
? LOCATION: objects can in most of the cases
be localized in reference to a temporal or
a spatial situation. For example, phonemes
have a temporal reference into the speech
2Another important interest of AGs is that they can
constitute the basis for an exchange format, when think-
ing on annotation tools interoperability (a proposal is cur-
rently elaborated under auspices of the MITRE program, see
http://www.mitre.org/).
3We call object any annotation that participates to the de-
scription: phoneme, words, gestures, but also phrases, emo-
tions, etc.
signal, physical objects have spatial local-
ization that can be absolute (spatial coordi-
nates), or relative (with respect to other ob-
jects).
? REALIZATION: data can either refer to con-
crete or physical objects (phonemes, ges-
tures, referential elements, etc.) as well as
abstract ones (concepts, emotions, etc.).
? MEDIUM: specification of the different
modalities: acoustic, tactile and visual.4
? ACCESSIBILITY: some data are directly ac-
cessible from the signal or the discourse, they
have a physical existence or have already
been mentioned. In this case, they are said
to be ?given? (e.g. gestures, sounds, physical
objects). Some other kinds of data are de-
duced from the context, typically the abstract
ones. They are considered as ?accessible".
A generic structure node can be given, gather-
ing the index and the some other object properties.
node
?
?????????????
ID
DOMAIN
{
prosody, syntax, pragmatics, ...
}
INDEX
?
???????
LOCATION
{
TEMPORAL
[
START value
END value
]
SPATIAL coord
}
REALIZATION
{
concrete, abstract
}
MEDIUM
{
acoustic, tactile, visual
}
ACCESSIBILITY
{
given, accessible
}
?
???????
FEATURES object_type
?
?????????????
This structure relies on the different informa-
tion. Besides INDEX, some other features com-
plete the description:
? ID: using an absolute ID is useful in the per-
spective of graph representation, in which
nodes can encode any kind of information
(atomic or complex, including subgraphs).
? DOMAIN: specification of the domain to
which the information belongs. This feature
is useful in the specification of generic inter-
action constraints between domains.
? FEATURES: nodes have to bear specific lin-
guistic indications, describing object proper-
ties. This field encodes the type of informa-
tion presented in the first section.
4See the W3C EMMA recommenda-
tion (Extensible Multi-Modal Annotations,
http://www.w3.org/2002/mmi/.
66
The following examples illustrate the represen-
tation of atomic nodes from different domains: a
phoneme (node n1) and a gesture (node n2), that
are temporally anchored, and a physical object
(node n3) which is spatially situated. This last ob-
ject can be used as a referent, for example by a
deictic gesture.?
????????????
ID n1
DOMAIN phonetics
INDEX
?
???
TEMP
[
START 285
END 312
]
REALIZATION concrete
MEDIUM acoustic
ACCESSIBILITY given
?
???
FEATURES
phoneme
[
LABEL /u/
CAT vowel
...
]
?
????????????
?
?????????
ID n2
DOMAIN gesture
INDEX
[
TEMP
[
START 200
END 422
]
...
]
FEAT
hand
[
PHRASE deictic
ORIENTATION front
...
]
?
?????????
?
??????
ID n3
DOMAIN context
INDEX
[
LOC | SPATIAL <x=242, y=422, z=312 >
]
FEATURES
discourse_referent
[
SEM book?
COLOR red
...
]
?
??????
3.2 Relations
Linguistic information is usually defined in terms
of relations between (sets of) objects, which can
be atomic or complex. For example, a phrase is
defined by syntactic relations (government, agree-
ment, linearity, etc.) between its constituents. In
some cases, these relations can concern objects
from the same domain (e.g. syntax in the previous
example). In other cases, different domains can
be involved. For example, a long break (greater
than 200ms) usually precedes a left corner of a
new phrase.
The nature of the relation can also be differ-
ent according to the kind of information to be en-
coded. Many relations are binary and oriented
(precedence, dependency, etc.). Some others only
consists in gathering different objects. A con-
struction (in the sense of Construction Grammars,
see (Fillmore96)) is precisely that: a set of ob-
ject or properties that, put together, form a spe-
cific phenomenon. It is then useful in our rep-
resentation to distinguish between oriented rela-
tions and set relations. Oriented relations (for ex-
ample precedence) connect a source and a target,
that can be eventually formed with set of objects.
Set relations are used to gather a set of objects,
without orientation or order (e.g. the constituency
relation).
On top of this distinction, it is also necessary
to give an index to the relations, in order to make
their reference possible by other objects. As for
nodes, an index is used, even though its form is
simple and does not need a complex anchor. Fi-
nally, for the same reasons as for nodes, the speci-
fication of the domain is necessary. The following
feature structure gives a first view of this organi-
zation:
relation
?
?????
INDEX
DOMAIN
{
prosody, syntax, pragmatics, ...
}
REL_TYPE
?
?
?
?
?
ORIENTED_REL
[
SOURCE index
TARGET index
]
SET_REL
?
node list
?
?
?
?
?
?
?
?????
Besides these information, a relation descrip-
tion has to be completed with other information:
? TYPE: different types of relations can be
implemented in such representation, such
as dependency, precedence, constituency,
anaphore, etc.
? SCOPE: a relation can be specific to a con-
struction or at the opposite valid whatever
the context. For example, the precedence
relation [V ? Clit[nom]] is only valid
in the context of interrogative constructions
whereas the relation exluding the realization
of a backchannel5 after a connective is valid
whatever the context. We distinguish then
between local and global scopes.
? POLARITY: a relation can be negated, imple-
menting the impossibility of a relation in a
given context.
? CONSTRUCTION: in the case of a local rela-
tion, it is necessary to specify the construc-
tion to which it belongs.
? STRENGTH: some relation are mandatory,
some other optional. As for constraints, we
distinguish then between hard and soft rela-
tions, depending on their status.
Finally, a last property has to be precisely de-
fined: the synchronization between two objects
5A backchannel is a reaction, verbal or gestual, of the
adressee during a conversation.
67
coming from different domains (for example ges-
tures and words). In some cases, both objects
have to be strictly aligned, with same boundaries.
For example, a syllable has to be strictly aligned
with its set of phonemes: the left syllable bound-
ary (resp. the right) has to be the same as that
of the first syllable phoneme (resp. the last). In
other cases, the synchronization must not be strict.
For example, a deictic gesture is not necessarily
strictly aligned with a referential pronoun. In this
case, boundaries of both objects only have to be
roughly in the same part of the signal.
We propose the definition of alignment opera-
tors adapted from (Allen, 1985) as follows:
= same boundaries have to be equal
<? before b1 <? b2 means b1 value is lowerthan b2, with b2 ? b1 ? ?
>? after b1 >? b2 means that the boundaryb1 follows b2, with b1 ? b2 ? ?
?? almost boundaries are neighbors, withoutorder relation, with | b1 ? b2 |? ?
This set of operators allow to specify alignment
equations between different objects. The advan-
tage of this mechanism is that an equation system
can describe complex cases of synchronization.
For example, a construction can involve several
objects from different domains. Some of these ob-
jects can be strictly aligned, some others not.
The final TFS representation is as follows:
relation
?
??????????????????
INDEX
DOMAIN
{
prosody, syntax, pragmatics, ...
}
REL_TYPE
?
?
?
?
?
ORIENTED_REL
[
SOURCE index
TARGET index
]
SET_REL
?
node list
?
?
?
?
?
?
TYPE
{
dependency, precedence, etc.
}
SCOPE
{
global, local
}
POLARITY
{
plus, minus
}
CONSTRUCTION contruction_type
STRENGTH
{
hard, soft
}
ALIGNMENT
?
alignment_equations
?
?
??????????????????
The following feature structure shows an exam-
ple of a global relation indicating that a verbal nu-
cleus usually comes with a minor raising of the
intonation (only main features are indicated here).
This information is represented by an implica-
tion relation, which is oriented from the syntac-
tic category to the prosodic phenomenon. Align-
ment equations stipulate a strict synchronization
between object.
relation
?
???????
INDEX
REL_TYPE | ORIENTED_REL
[
SOURCE VN1
TARGET mr2
]
TYPE
{
implication
}
STRENGTH
{
soft
}
ALIGNMENT
?
lb1=lb2; rb1=rb2
?
?
???????
4 Representation with Hypergraphs
Nodes and relations can be combined and form
higher level nodes, representing constructions
which are a set of objects (the constituents) plus
a set of relations between them. Such nodes are
in fact hypernodes and bear two kinds of informa-
tion: the properties characterizing the object plus
a set of relations between the constituents (repre-
senting a subgraph). In the syntactic domain, for
example, they represent phrases, as follows:
?
???????????????????
DOMAIN syntax
INDEX | LOCATION | TEMPORAL
[
START 122
END 584
]
FEATURES
[
CAT VP
]
RELATIONS
?
???????????
???????????
?
??
INDEX r1
REL_TYPE | SET_REL
?
V, NP, Adv
?
TYPE constituency
STRENGTH hard
?
??;
?
???
INDEX r2
REL_TYPE | ORIENTED_REL
[
SOURCE NP
TARGET V
]
TYPE dependency
STRENGTH hard
?
???
?
???????????
???????????
?
???????????????????
In the same way, the interaction between dif-
ferent objects from different domains can involve
several relations. For example, a deictic con-
struction can be made of the conjunction of an
anaphoric pronoun, a deictic gesture and a physi-
cal object (for example a book on a shelf). Such
a construction can be described by the following
structure:
?
????????????????
INDEX | LOCATION | TEMPORAL
[
START 841
END 1520
]
FEATURES
[
SEM book?
]
RELATIONS
?
??????????
??????????
?
???
INDEX r3
SET_REL
?
Pro1, Dx_gest2, Ph_object3
?
TYPE constituency
ALIGNMENT
?
lb1 ??lb2; rb1 ??rb2
?
?
???;
?
??
INDEX r4
ORIENTED_REL
[
SOURCE Pro1
TARGET Ph_object3
]
TYPE reference
?
??
?
??????????
??????????
?
????????????????
This construction indicates some properties
(limited here to the semantic value) and two re-
68
lations between the different objects: one con-
stituency, indicating the different objects involved
in the construction and their (fuzzy) alignment
and a reference relation between the pronoun and
a physical object (here, a book).
This structure represents an hypergraph: it is
a graph connecting different nodes, each of them
being to its turn described by another graph, as
shown above. The main interest of such a repre-
sentation is its flexibility: all kinds of information
can be described, at any level. Graphs being less
constrained than trees, and edges (or relations) be-
ing typed, we can gather different levels, different
domains and different granularities. For example,
an agreement relation can be specified thanks to
the deictic construction, besides the constituency
one, making it possible to instanciate the agree-
ment value of the pronoun.
Note that hypergraphs are also investigated in
other knowledge representation, their properties
are well known (Hayes, 2004) and the implemen-
tation of specific hypergraphs as the one presented
here could be done in RDF graphs for example as
suggested in (Cassidy, 2010).
5 Constraints for Multimodal
Grammars
In the same way as typed feature structures can
implement constraints and constitute a description
language on linguistic structures (cf. HPSG, ),
the same approach can be generalized to multi-
modal information. SOme recent works have been
done in this direction (see (Alahverdzhieva, 2010;
?)). The representation we propose can implement
generic information about multimodal construc-
tions. We illustrate in the following this aspect
with two phenomena: backchannels and disloca-
tion.
Several studies on conversational data (see for
example (Bertrand09)) have described backchan-
nels (that can be vocal or gestual) and their con-
text. They have in particular underline some reg-
ularities on the left context:
? backchannels usually follow: major intona-
tive phrases (IP), flat contours, end of conver-
sational turn (i.e. saturated from a semantic,
syntactic and pragmatic point of view)
? backchannels never appear after connectives
These constraints can be implemented by
means of a feature structure (representing an hy-
pernode) with a set of precedence relations. The
different objects involved in the description of the
phenomenon (IP, flat contour, conversational turn,
connective) are indicated with an indexed ID, re-
ferring to their complete feature structure, not pre-
sented here.
?
???????????????????????????????????
ID 1
DOMAIN pragmatics
FEATURES
[
TYPE 2
]
RELATIONS
?
??????????????????????????????
??????????????????????????????
?
??
INDEX r5
SET_REL
?
IP 3 , FLAT_CONTOUR 4 ,
CONV_TURN 5 , CONNECTIVE 6
?
TYPE constituency
?
??;
?
??
INDEX r6
ORIENTED_REL
[
SOURCE
?
3 , 4 , 5
?
TARGET 1
]
TYPE precedence
?
??;
?
????
INDEX r7
ORIENTED_REL
[
SOURCE 6
TARGET 1
]
TYPE precedence
POLARITY minus
?
????
?
????
INDEX r8
ORIENTED_REL
[
SOURCE 3
TARGET vocal_ 2
]
TYPE precedence
STRENGTH hard
?
????
?
??????????????????????????????
??????????????????????????????
?
???????????????????????????????????
Figure 2: Backchannel Constraint
This structure (cf. Figure 2) represents a con-
straint that backchannels have to satisfy. The
first relation specifies the constituents and their
indexes, with which the different precedence con-
straints are represented. The relation r6 indicates
all kinds of object that should precede a backchan-
nel. This constraint subsumes the most specific
relation r8 stipulating that a vocal backchannel is
always preceded with an IP (this is a hard con-
straint). The relation r7 excludes the possibility
for a backchannel to be preceded with a connec-
tive.
The second example (cf. Figure 3) proposes a
constraint system describing dislocated structures.
We propose in this description to distinguish two
syntactic constituents that form the two parts of
the dislocation: the dislocated phrase (called S1)
and the sentence from which the phrase has been
69
extracted (called S2). Usually (even if not al-
ways), S2 contains a clitic referring to S1. We
note in the following this clitic with the notation
S2//Clit. For readability reasons, we only present
in this structure the relations.
This structure describes the case of a left dislo-
cation (with S1 preceding S2, the constraint being
hard). In such cases, S1 is usually realized with
a minor raising contour. The constraint r13 im-
plements the anaphoric relation between the clitic
and the dislocated element. Finally, the relation
r14 indicates an agreement relation between the
clitic and S1 and in particular the fact that the case
has to be the same for both objects.
?
????????????????????????????
DOMAIN syntax
RELATIONS
?
??????????????????????????
??????????????????????????
?
??
INDEX r11
SET_REL
?
S1 1 , S2 2 , MINOR_RAISING 3 ,
S2//CLIT 4
?
TYPE constituency
?
??;
?
??
INDEX r12
ORIENTED_REL
[
SOURCE 1
TARGET 2
]
TYPE precedence
?
??;
?
??
INDEX r13
ORIENTED_REL
[
SOURCE 1
TARGET 4
]
TYPE anaphor
?
??
?
??
INDEX r14
ORIENTED_REL
[
SOURCE 1 [CASE 3 ]
TARGET 4 [CASE 3 ]
]
TYPE agreement
?
??
?
??????????????????????????
??????????????????????????
?
????????????????????????????
Figure 3: Dislocation Constraint
6 Conclusion
Linguistic annotation in general, and multimodal-
ity in particular, requires high level annotation
schemes making it possible to represent in an ho-
mogeneous way information coming from the dif-
ferent domains and modalities involved in human
communication.
The approach presented in this paper general-
izes previous methods (in particular annotation
graphs) thanks to two proposals: first in providing
a way to index objects without strict order relation
between nodes and second in specifying a precise
and homogeneous representation of the objects
and their relations. This approach has been devel-
oped into a formal scheme, typed feature struc-
tures, in which all the different domains can be
represented, and making it possible to implement
directly hypergraphs. TFS and hypergraphs are
particularly well adapted for the specification of
interaction constraints, describing interaction re-
lations between modalities. Such constraints con-
stitute the core of the definition of future multi-
modal grammars.
From a practical point of view, the proposal
described in this paper is currently under exper-
imentation within the OTIM project (see (Blache,
2010)). An XML scheme has been automatically
generated starting from TFS formal scheme. The
existing multimodal annotations, created with ad
hoc annotation schemes, are to their turn automat-
ically translated following this format. We obtain
then, for the first time, a large annotated multi-
modal corpus, using an XML schema based on a
formal specification.
References
Alahverdzhieva, K. and A. Lascarides (2010)
?Analysing Language and Co-verbal Gesture and
Constraint-based Grammars?, in Proceedings of
the 17th International Conference on Head-Driven
Phase Structure Grammar.
Allen F. and P. J. Hayes (1985) ?A common-sense the-
ory of time?, in 9th International Joint Conference
on Artificial Intelligence.
Allwood J., L. Cerrato, L. Dybkjaer and al. (2005)
The MUMIN Multimodal Coding Scheme, NorFA
yearbook 2005
Bertrand R., M. Ader, P. Blache, G. Ferr?, R. Es-
pesser, S. Rauzy (2009) ?Repr?sentation, ?dition et
exploitation de donn?es multimodales : le cas des
backchannels du corpus CID?, in Cahiers de lin-
guistique fran?aise, 33:2.
Blache P., R. Bertrand, and G. Ferr? (2009) ?Creat-
ing and Exploiting Multimodal Annotated Corpora:
The ToMA Project?. in Kipp, Martin, Paggio and
Heylen (eds.) Multimodal Corpora: From Models
of Natural Interaction to Systems and Applications,
LNAI 5509, Springer.
Blache P. et al (2010) ?Multimodal Annotation of
Conversational Data?, in proceedings of LAW-IV -
The Linguistic Annotation Workshop
Bird S., Day D., Garofolo J., Henderson J., Laprun C.
& Liberman M. (2000) ?ATLAS : A Flexible and
Extensible Architecture for Linguistic Annotation",
in procs of LREC00
70
Bird S., M. Liberman (2001) ?A formal framework
for linguistic annotation" Speech Communication,
Elsevier
Boersma P. & D. Weenink (2009) Praat: doing pho-
netics by computer, http://www.praat.org/
Carletta, J., J. Kilgour, and T. O?Donnell (2003) ?The
NITE Object Model Library for Handling Struc-
tured Linguistic Annotation on Multimodal Data
Sets" in procs of the EACL Workshop on Language
Technology and the Semantic Web
Carpenter B. (1992) The Logic of Typed Feature
Structures. Cambridge University Press.
Cassidy S. (2010) An RDF Realisation of LAF in the
DADA Annotation Server. Proceedings of ISA-5,
Hong Kong, January 2010.
Dipper S., M. Goetze and S. Skopeteas (eds.) (2007)
Information Structure in Cross-Linguistic Corpora:
Annotation Guidelines for Phonology, Morphol-
ogy, Syntax, Semantics and Information Structure,
Working Papers of the SFB 632, 7:07
Dybkjaer L., S. Berman, M. Kipp, M. Wegener Olsen,
V. Pirrelli, N .Reithinger, C. Soria (2001) ?Sur-
vey of Existing Tools, Standards and User Needs for
Annotation of Natural Interaction and Multimodal
Data", ISLE Natural Interactivity and Multimodal-
ity Working Group Deliverable D11.1
Fillmore C. & P. Kay (1996) Construction Grammar,
Manuscript, University of California at Berkeley
Department of linguistics.
Gruenstein A., J. Niekrasz, and M. Purver. (2008)
?Meeting structure annotation: Annotations col-
lected with a general purpose toolkit?. In L. Dybk-
jaer and W. Minker, editors, Recent Trends in Dis-
course and Dialogue, Springer-Verlag.
Hayes J. and Gutierrez C. (2004) Bipartite graphs as
intermediate model for RDF. Proceedings of ISWC
2004, 3rd International Semantic Web Conference
(ISWC2004), Japan.
Ide N. and K. Suderman (2007) ?GrAF: A Graph-
based Format for Linguistic Annotations? in pro-
ceedings of the Linguistic Annotation Workshop
(LAW-07)
Ide N. and Suderman K. (2009) Bridging the Gaps:
Interoperability for GrAF, GATE, and UIMA. Pro-
ceedings of the Third Linguistic Annotation Work-
shop, held in conjunction with ACL 2009, Singa-
pore.
Kipp M. (2001) ?Anvil-a generic annotation tool for
multimodal dialogue" in procs of 7th European
Conference on Speech Communication and Tech-
nology
Kipp, M. (2003) Gesture Generation by Immitation:
From Human Behavior to Computer Character An-
imation, PhD Thesis, Saarland University.
Lascarides, A. and M. Stone (2009) ?A Formal Se-
mantic Analysis of Gesture?, in Journal of Seman-
tics, 26(4).
McNeill, D. (2005) Gesture and Thought, The Univer-
sity of Chicago Press.
Pineda, L., and G. Garza (2000) ?A Model for Mul-
timodal Reference Resolution", in Computational
Linguistics, Vol. 26 no. 2
Rodriguez K., Stefan, K. J., Dipper, S., Goetze,
M., Poesio, M., Riccardi, G., Raymond, C., Wis-
niewska, J. (2007) ?Standoff Coordination for
Multi-Tool Annotation in a Dialogue Corpus", in
procs of the Linguistic Annotation Workshop at the
ACL?07 (LAW-07)
Wegener Knudsen M.and al. (2002) Survey of Multi-
modal Coding Schemes and Best Practice, ISLE
Wittenburg, P.; Brugman, H.; Russel, A.; Klassmann,
A. and Sloetjes, H. (2006) ?ELAN: a Professional
Framework for Multimodality Research?. In pro-
ceedings of LREC 2006
71
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 186?191,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Multimodal Annotation of Conversational Data
P. Blache1, R. Bertrand1, B. Bigi1, E. Bruno3, E. Cela6, R. Espesser1, G. Ferr?4, M. Guardiola1, D. Hirst1,
E.-P. Magro6, J.-C. Martin2, C. Meunier1, M.-A. Morel6, E. Murisasco3, I Nesterenko1, P. Nocera5,
B. Pallaud1, L. Pr?vot1, B. Priego-Valverde1, J. Seinturier3, N. Tan2, M. Tellier1, S. Rauzy1
(1) LPL-CNRS-Universit? de Provence (2) LIMSI-CNRS-Universit? Paris Sud
(3) LSIS-CNRS-Universit? de Toulon (4) LLING-Universit? de Nantes
(5) LIA-Universit? d?Avignon (6) RFC-Universit? Paris 3
blache@lpl-aix.fr
Abstract
We propose in this paper a broad-coverage
approach for multimodal annotation of
conversational data. Large annotation pro-
jects addressing the question of multimo-
dal annotation bring together many dif-
ferent kinds of information from different
domains, with different levels of granula-
rity. We present in this paper the first re-
sults of the OTIM project aiming at deve-
loping conventions and tools for multimo-
dal annotation.
1 Introduction
We present in this paper the first results of the
OTIM1 project aiming at developing conventions
and tools for multimodal annotation. We show
here how such an approach can be applied in the
annotation of a large conversational speech cor-
pus.
Before entering into more details, let us men-
tion that our data, tools and conventions are des-
cribed and freely downlodable from our website
(http ://www.lpl-aix.fr/ otim/).
The annotation process relies on several tools
and conventions, most of them elaborated within
the framework of the project. In particular, we pro-
pose a generic transcription convention, called En-
riched Orthographic Trancription, making it pos-
sible to annotate all specific pronunciation and
speech event, facilitating signal alignment. Dif-
ferent tools have been used in order to prepare
or directly annotate the transcription : grapheme-
phoneme converter, signal alignment, syllabifica-
tion, prosodic analysis, morpho-syntactic analysis,
chunking, etc. Our ambition is to propose a large
corpus, providing rich annotations in all the dif-
1OTIM stands for Outils pour le Traitement de l?Informa-
tion Multimodale (Tools for Multimodal Annotation). This
project in funded by the French ANR agency.
ferent linguistic domains, from prosody to gesture.
We describe in the following our first results.
2 Annotations
We present in this section some of the annota-
tions of a large conversational corpus, called CID
(Corpus of Interactional Data, see (Bertrand08)),
consisting in 8 dialogues, with audio and video si-
gnal, each lasting 1 hour.
Transcription : The transcription process is
done following specific conventions derived from
that of the GARS (Blanche-Benveniste87). The
result is what we call an enriched orthographic
construction, from which two derived transcrip-
tions are generated automatically : the standard or-
thographic transcription (the list of orthographic
tokens) and a specific transcription from which
the phonetic tokens are obtained to be used by the
grapheme-phoneme converter.
From the phoneme sequence and the audio si-
gnal, the aligner outputs for each phoneme its
time localization. This aligner (Brun04) is HMM-
based, it uses a set of 10 macro-classes of vowel
(7 oral and 3 nasal), 2 semi-vowels and 15 conso-
nants. Finally, from the time aligned phoneme se-
quence plus the EOT, the orthographic tokens is
time-aligned.
Syllables : The corpus was automatically seg-
mented in syllables. Sub-syllabic constituents (on-
set, nucleus and coda) are then identified as well
as the syllable structure (V, CV, CCV, etc.). Sylla-
bic position is specified in the case of polysyllabic
words.
Prosodic phrasing : Prosodic phrasing refers
to the structuring of speech material in terms of
boundaries and groupings. Our annotation scheme
supposes the distinction between two levels of
phrasing : the level of accentual phrases (AP, (Jun,
2002)) and the higher level of intonational phrases
186
(IP). Mean annotation time for IPs and APs was
30 minutes per minute.
Prominence : The prominence status of a syl-
lable distinguishes between accentuability (the
possibility for syllable to be prominent) and pro-
minence (at the perception level). In French the
first and last full syllables (not containing a
schwa) of a polysyllabic word can be prominent,
though this actual realization depends on spea-
kers choices. Accentuability annotation is auto-
matic while prominence annotation is manual and
perceptually based.
Tonal layer : Given a lack of consensus on the
inventory of tonal accents in French, we choose to
integrate in our annotation scheme three types of
tonal events : a/ underlying tones (for an eventual
FrenchToBI annotation) ; b/ surface tones (anno-
tated in terms of MOMel-Intsint protocol Hirst et
al 2000) ; c/ melodic contours (perceptually anno-
tated pitch movements in terms of their form and
function). The interest to have both manual and
automatic INTSINT annotations is that it allows
the study of their links.
Hand gestures : The formal model we use for
the annotation of hand gestures is adapted from
the specification files created by Kipp (2004) and
from the MUMIN coding scheme (Allwood et al,
2005). Among the main gesture types, we anno-
tate iconics, metaphoric, deictics, beats, emblems,
butterworths or adaptors.
We used the Anvil tool (Kipp, 2004) for the ma-
nual annotations. We created a specification files
taking into account the different information types
and the addition of new values adapted to the
CID corpus description (e.g. we added a separate
track Symmetry). For each hand, the scheme has 10
tracks. We allowed the possibility of a gesture per-
taining to several semiotic types using a boolean
notation. A gesture phrase (i.e. the whole gesture)
can be decomposed into several gesture phases i.e.
the different parts of a gesture such as the prepara-
tion, the stroke (the climax of the gesture), the hold
and the retraction (when the hands return to their
rest position) (McNeill, 1992). The scheme also
enables to annotate gesture lemmas (Kipp, 2004),
the shape and orientation of the hand during the
stroke, the gesture space, and contact. We added
the three tracks to code the hand trajectory, ges-
ture velocity and gesture amplitude.
Discourse and Interaction : Our discourse an-
notation scheme relies on multidimensional fra-
meworks such as DIT++ (Bunt, 2009) and is com-
patible with the guidelines defined by the Semantic
Annotation Framework (Dialogue Act) working
group of ISO TC37/4.
Discourse units include information about their
producer, have a form (clause, fragment, dis-
fluency, non-verbal), a content and a communi-
cative function. The same span of raw data may
be covered by several discourse units playing dif-
ferent communicative functions. Two discourse
units may even have exactly the same temporal ex-
tension, due to the multifonctionality that cannot
be avoided (Bunt, 2009).
Compared to standard dialogue act annotation
frameworks, three main additions are proposed :
rhetorical function, reported speech and humor.
Our rhetorical layer is an adaptation of an exis-
ting schema developed for monologic written data
in the context of the ANNODIS project.
Disfluencies : Disfluencies are organized
around an interruption point, which can occur al-
most anywhere in the production. Disfluencies can
be prosodic (lenghtenings, silent and filled pauses,
etc.), or lexicalized. In this case, they appear as a
word or a phrase truncation, that can be comple-
ted. We distinguish three parts in a disfluency (see
(Shriberg, 1994), (Blanche-Benveniste87)) :
? Reparandum : what precedes the interruption
point. This part is mandatory in all disfluen-
cies. We indicate there the nature of the inter-
rupted unit (word or phrase), and the type of
the truncated word (lexical or grammatical) ;
? Break interval. It is optional, some disfluen-
cies do not bear any specific event there.
? Reparans : the part following the break, repai-
ring the reparandum. We indicate there type
of the repair (no restart, word restart, determi-
ner restart, phrase restart, etc.), and its func-
tion (continuation, repair without change, re-
pair with change, etc.).
3 Quantitative information
We give in this section some indication about
the state of development of the CID annotation.
Hand gestures : 75 minutes involving 6 spea-
kers have been annotated, yielding a total number
of 1477 gestures. The onset and offset of gestures
correspond to the video frames, starting from and
187
going back to a rest position.
Face and gaze : At the present time, head move-
ments, gaze directions and facial expressions have
been coded in 15 minutes of speech yielding a to-
tal number of 1144 movements, directions and ex-
pressions, to the exclusion of gesture phases. The
onset and offset of each tag are determined in the
way as for hand gestures.
Body Posture : Our annotation scheme consi-
ders, on top of chest movements at trunk level,
attributes relevant to sitting positions (due to the
specificity of our corpus). It is based on the Pos-
ture Scoring System (Bull, 1987) and the Annota-
tion Scheme for Conversational Gestures (Kipp et
al., 2007). Our scheme covers four body parts :
arms, shoulders, trunk and legs. Seven dimensions
at arm level and six dimensions at leg level, as well
as their related reference points we take in fixing
the spatial location, are encoded.
Moreover, we added two dimensions to describe
respectively the arm posture in the sagittal plane
and the palm orientation of the forearm and the
hand. Finally, we added three dimensions for leg
posture : height, orientation and the way in which
the legs are crossed in sitting position.
We annotated postures on 15 minutes of the cor-
pus involving one pair of speakers, leading to 855
tags with respect to 15 different spatial location
dimensions of arms, shoulder, trunk and legs.
Annotation Time (min.) Units
Transcript 480 -
Hands 75 1477
Face 15 634
Gaze 15 510
Posture 15 855
R. Speech 180
Com. Function 6 229
Disfluencies At the moment, this annotation is
fully manual (we just developed a tool helping the
process in identifying disfluencies, but it has not
yet been evaluated). Annotating this phenomenon
requires 15mns for 1 minute of the corpus. The
following table illustrates the fact that disfluen-
cies are speaker-dependent in terms of quantity
and type. These figures also shows that disfluen-
cies affect lexicalized words as well as grammati-
cal ones.
Speaker_1 Speaker_1
Total number of words 1,434 1,304
Disfluent grammatical words 17 54
Disfluent lexicalized words 18 92
Truncated words 7 12
Truncated phrases 26 134
Transcription and phonemes The following
table recaps the main figures about the different
specific phenomena annotated in the EOT. To the
best of our knowledge, these data are the first of
this type obtained on a large corpus. This informa-
tion is still to be analyzed.
Phenomenon Number
Elision 11,058
Word truncation 1,732
Standard liaison missing 160
Unusual liaison 49
Non-standard phonetic realization 2,812
Laugh seq. 2,111
Laughing speech seq. 367
Single laugh IPU 844
Overlaps > 150 ms 4,150
Syntax We used the stochastic parser developed
at the LPL (Blache&Rauzy, 2008) to automaticaly
generate morppho-syntactic and syntactic annota-
tions. The parser has been adapted it in order to ac-
count for the specificities of speech analysis. First,
the system implements a segmentation technique,
identifying large syntactic units that can be consi-
dered as the equivalent of sentences in written
texts. This technique distinguishes between strong
and weak or soft punctuation marks. A second mo-
dification concerns the lexical frequencies used by
the parser model in order to capture phenomena
proper to conversational data.
The categories and chunks counts for the whole
corpus are summarized in the following figure :
Category Count Group Count
adverb 15123 AP 3634
adjective 4585 NP 13107
auxiliary 3057 PP 7041
determiner 9427 AdvP 15040
conjunction 9390 VPn 22925
interjection 5068 VP 1323
preposition 8693 Total 63070
pronoun 25199
noun 13419 Soft Pct 9689
verb 20436 Strong Pct 14459
Total 114397 Total 24148
4 Evaluations
Prosodic annotation : Prosodic annotation of
1 dialogue has been done by 2 experts. The
annotators worked separately using Praat. Inter-
transcriber agreement studies were done for the
annotation of higher prosodic units. First anno-
tator marked 3,159 and second annotator 2,855
188
Intonational Phrases. Mean percentage of inter-
transcriber agreement was 91.4% and mean
kappa-statistics 0.79, which stands for a quite sub-
stantial agreement.
Gesture : We performed a measure of inter-
reliability for three independent coders for Gesture
Space. The measure is based on Cohen?s correc-
ted kappa coefficient for the validation of coding
schemes (Carletta96).
Three coders have annotated three minutes for
GestureSpace including GestureRegion and Ges-
tureCoordinates. The kappa values indicated that
the agreement is high for GestureRegion of right
hand (kappa = 0.649) and left hand (kappa =
0.674). However it is low for GestureCoordinates
of right hand (k= 0.257) and left hand (k= 0.592).
Such low agreement of GestureCoordinates might
be due to several factors. First, the number of ca-
tegorical values is important.
Second, three minutes might be limited in terms
of data to run a kappa measure. Third, GestureRe-
gion affects GestureCoordinates : if the coders di-
sagree about GestureRegion, they are likely to also
annotate GestureCoordinates in a different way.
For instance, it was decided that no coordinate
would be selected for a gesture in the center-center
region, whereas there is a coordinate value for ges-
tures occurring in other parts of the GestureRe-
gion. This means that whenever coders disagree
between the center-center or center region, the an-
notation of the coordinates cannot be congruent.
5 Information representation
5.1 XML encoding
Our approach consists in first precisely define
the organization of annotations in terms of typed-
feature structures. We obtain an abstract descrip-
tion from which we automatically generate a for-
mal schema in XML. All the annotations are then
encoded following this schema.
Our XML schema, besides a basic encoding of
data following AIF, encode all information concer-
ning the organization as well as the constraints on
the structures. In the same way as TFS are used
as a tree description language in theories such as
HPSG, the XML schema generated from our TFS
representation also plays the same role with res-
pect to the XML annotation data file. On the one
hand, basic data are encoded with AIF, on the
other hand, the XML schema encode all higher
level information. Both components (basic data +
structural constraints) guarantee against informa-
tion loss that otherwise occurs when translating
from one coding format to another (for example
from Anvil to Praat).
5.2 Querying
To ease the multimodal exploitation of the data,
our objective is to provide a set of operators dedi-
cated to concurrent querying on hierarchical an-
notation. Concurrent querying consists in que-
rying annotations belonging to two or more mo-
dalities or even in querying the relationships bet-
ween modalities. For instance, we want to be able
to express queries over gestures and intonation
contours (what kind of intonational contour does
the speaker use when he looks at the listener ?).
We also want to be able to query temporal relation-
ships (in terms of anticipation, synchronization or
delay) between both gesture strokes and lexical af-
filiates.
Our proposal is to define these operators as an
extension of XQuery. From the XML encoding
and the temporal alignment of annotated data, it
will possible to express queries to find patterns and
to navigate in the structure. We also want to en-
able a user to check predicates on parts of the cor-
pus using classical criteria on values, annotations
and existing relationships (temporal or structural
ones corresponding to inclusions or overlaps bet-
ween annotations). First, we shall rely on one of
our previous proposal called MSXD (MultiStruc-
tured XML Document). It is a XML-compatible
model designed to describe and query concurrent
hierarchical structures defined over the same tex-
tual data which supports Allen?s relations.
6 Conclusion
Multimodal annotation is often reduced to
the encoding of gesture, eventually accompa-
nied with another level of linguistic information
(e.g. morpho-syntax). We reported in this paper a
broad-coverage approach, aiming at encoding all
the linguistic domains into a unique framework.
We developed for this a set of conventions and
tools making it possible to bring together and align
all these different pieces of information. The result
is the CID (Corpus of Interactional Data), the first
large corpus of conversational data bearing rich
annotations on all the linguistic domains.
189
References
Allen J. (1999) Time and time again : The many way to re-
present time. International Journal of Intelligent Systems,
6(4)
Allwood, J., Cerrato, L., Dybkjaer, L., Jokinen, K., Navar-
retta, C., Paggio, P. (2005) The MUMIN Multimodal Co-
ding Scheme, NorFA yearbook 2005.
Baader F., D. Calvanese, D. L. McGuinness, D. Nardi, P.
F. Patel-Schneider (2003) The Description Logic Hand-
book : Theory, Implementation, Applications. Cambridge
University Press.
Bertrand, R., Blache, P., Espesser, R., Ferr?, G., Meunier, C.,
Priego-Valverde, B., Rauzy, S. (2008) ?Le CID - Corpus
of Interactional Data - Annotation et Exploitation Multi-
modale de Parole Conversationnelle?, in revue Traitement
Automatique des Langues, 49 :3.
Bigi, C. Meunier, I. Nesterenko, R. Bertrand 2010. ?Syllable
Boundaries Automatic Detection in Spontaneous Speech?,
in proceedings of LREC 2010.
Blache P. and Rauzy S. 2008. ?Influence de la qualit? de
l??tiquetage sur le chunking : une corr?lation d?pendant de
la taille des chunks?. in proceedings of TALN 2008 (Avi-
gnon, France), pp. 290-299.
Blache P., R. Bertrand, and G. Ferr? 2009. ?Creating and
Exploiting Multimodal Annotated Corpora : The ToMA
Project?. In Multimodal Corpora : From Models of Natu-
ral Interaction to Systems and Applications, Springer.
Blanche-Benveniste C. & C. Jeanjean (1987) Le fran?ais
parl?. Transcription et ?dition, Didier Erudition.
Blanche-Benveniste C. 1987. ?Syntaxe, choix du lexique et
lieux de bafouillage?, in DRLAV 36-37
Browman C. P. and L. Goldstein. 1989. ?Articulatory ges-
tures as phonological units?. In Phonology 6, 201-252
Brun A., Cerisara C., Fohr D., Illina I., Langlois D., Mella O.
& Smaili K. (2004- ?Ants : Le syst?l?me de transcription
automatique du Loria?, Actes des XXV Journ?es d?Etudes
sur la Parole, F?s.
E. Bruno, E. Murisasco (2006) Describing and Querying hie-
rarchical structures defined over the same textual data, in
Proceedings of the ACM Symposium on Document Engi-
neering (DocEng 2006).
Bull, P. (1987) Posture and Gesture, Pergamon Press.
Bunt H. 2009. ?Multifunctionality and multidimensional
dialogue semantics.? In Proceedings of DiaHolmia?09,
SEMDIAL.
B?rki A., C. Gendrot, G. Gravier & al.(2008) ?Alignement
automatique et analyse phon?tique : comparaison de dif-
f?rents syst?mes pour l?analyse du schwa?, in revue TAL
,49 :3
Carletta, J. (1996) ?Assessing agreement on classification
tasks : The kappa statistic?, in Computational Linguistics
22.
Corlett, E. N., Wilson,John R. Manenica. I. (1986) ?Influence
Parameters and Assessment Methods for Evaluating Body
Postures?, in Ergonomics of Working Postures : Models,
Methods and Cases , Proceedings of the First International
Occupational Ergonomics Symposium.
Di Cristo & Hirst D. (1996) ?Vers une typologie des unites in-
tonatives du fran?ais?, XXI?me JEP, 219-222, 1996, Avi-
gnon, France
Di Cristo A. & Di Cristo P. (2001) ?Syntaix, une approche
m?trique-autosegmentale de la prosodie?, in revue Traite-
ment Automatique des Langues, 42 :1.
Dipper S., M. Goetze and S. Skopeteas (eds.) 2007. Informa-
tion Structure in Cross-Linguistic Corpora : Annotation
Guidelines, Working Papers of the SFB 632, 7 :07
FGNet Second Foresight Report (2004) Face
and Gesture Recognition Working Group.
http ://www.mmk.ei.tum.de/ waf/fgnet-intern/3rd-
fgnet-foresight-workshop.pdf
Gendner V. et al 2003. ?PEAS, the first instantiation of a
comparative framework for evaluating parsers of French?.
in Research Notes of EACL 2003 (Budapest, Hungaria).
Hawkins S. and N. Nguyen 2003. ?Effects on word re-
cognition of syllable-onset cues to syllable-coda voicing?,
in Papers in Laboratory Phonology VI. Cambridge Univ.
Press.
Hirst, D., Di Cristo, A., Espesser, R. 2000. ?Levels of des-
cription and levels of representation in the analysis of in-
tonation?, in Prosody : Theory and Experiment, Kluwer.
Hirst, D.J. (2005) ?Form and function in the representation
of speech prosody?, in K.Hirose, D.J.Hirst & Y.Sagisaka
(eds) Quantitative prosody modeling for natural speech
description and generation (Speech Communication 46 :3-
4.
Hirst, D.J. (2007) ?A Praat plugin for Momel and INTSINT
with improved algorithms for modelling and coding into-
nation?, in Proceedings of the XVIth International Confe-
rence of Phonetic Sciences.
Hirst, D. (2007), Plugin Momel-Intsint. Inter-
net : http ://uk.groups.yahoo.com/group/praat-
users/files/Daniel_Hirst/plugin_momel-intsint.zip,
Boersma, Weenink, 2007.
Jun, S.-A., Fougeron, C. 2002. ?Realizations of accentual
phrase in French intonation?, in Probus 14.
Kendon, A. (1980) ?Gesticulation and Speech : Two Aspects
of the Porcess of Utterance?, in M.R. Key (ed.), The Re-
lationship of Verbal and Nonverbal Communication, The
Hague : Mouton.
Kita, S., Ozyurek, A. (2003) ?What does cross-linguistic va-
riation in semantic coordination of speech and gesture re-
veal ? Evidence for an interface representation of spatial
thinking and speaking?, in Journal of Memory and Lan-
guage, 48.
Kipp, M. (2004). Gesture Generation by Imitation - From
Human Behavior to Computer Character Animation. Boca
Raton, Florida, Dissertation.com.
Kipp, M., Neff, M., Albrecht, I. (2007). An annotation
scheme for conversational gestures : how to economically
capture timing and form. Language Resources and Eva-
luation, 41(3).
Koiso H., Horiuchi Y., Ichikawa A. & Den Y.(1998) ?An ana-
lysis of turn-taking and backchannels based on prosodic
and syntactic features in Japanese map task dialogs?, in
Language and Speech, 41.
McNeill, D. (1992). Hand and Mind. What Gestures Re-
veal about Thought, Chicago : The University of Chicago
Press.
McNeill, D. (2005). Gesture and Thought, Chicago, London :
The University of Chicago Press.
Milborrow S., F. Nicolls. (2008). Locating Facial Features
with an Extended Active Shape Model. ECCV (4).
Nesterenko I. (2006) ?Corpus du parler russe spontan? : an-
notations et observations sur la distribution des fronti?res
prosodiques?, in revue TIPA, 25.
190
Paroubek P. et al 2006. ?Data Annotations and Measures in
EASY the Evaluation Campaign for Parsers in French?. in
proceedings of the 5th international Conference on Lan-
guage Resources and Evaluation 2006 (Genoa, Italy), pp.
314-320.
Pierrehumbert & Beckman (1988) Japanese Tone Structure.
Coll. Linguistic Inquiry Monographs, 15. Cambridge,
MA, USA : The MIT Press.
Platzer, W., Kahle W. (2004) Color Atlas and Textbook of
Human Anatomy, Thieme. Project MuDis. Technische
Universitat Munchen. http ://www9.cs.tum.edu/research
Scherer, K.R., Ekman, P. (1982) Handbook of methods in
nonverbal behavior research. Cambridge University Press.
Shriberg E. 1994. Preliminaries to a theory of speech dis-
fluencies. PhD Thesis, University of California, Berkeley
Wallhoff F., M. Ablassmeier, and G. Rigoll. (2006) ?Mul-
timodal Face Detection, Head Orientation and Eye Gaze
Tracking?, in proceedings of International Conference on
Multisensor Fusion and Integration (MFI).
White, T. D., Folkens, P. A. (1991) Human Osteology. San
Diego : Academic Press, Inc.
191
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 1?2,
Gothenburg, Sweden, April 26 2014.
c?2014 Association for Computational Linguistics
Challenging incrementality in human language processing: two
operations for a cognitive architecture
Philippe Blache
Aix-Marseille Universit?e & CNRS
LPL (UMR7309), 13100, Aix-en-Provence, France
blache@blri.fr
The description of language complexity and the
cognitive load related to the different linguistic
phenomena is a key issue for the understanding
of language processing. Many studies have fo-
cused on the identification of specific parameters
that can lead to a simplification or on the con-
trary to a complexification of the processing (e.g.
the different difficulty models proposed in (Gib-
son, 2000), (Warren and Gibson, 2002), (Hawkins,
2001) ). Similarly, different simplification fac-
tors can be identified, such as the notion of activa-
tion, relying on syntactic priming effects making it
possible to predict (or activate) a word (Vasishth,
2003). Several studies have shown that complex-
ity factors are cumulative (Keller, 2005), but can
be offset by simplification (Blache et al., 2006). It
is therefore necessary to adopt a global point of
view of language processing, explaining the inter-
play between positive and negative cumulativity,
in other words compensation effects.
From the computational point of view, some
models can account more or less explicitly for
these phenomena. This is the case of the Surprisal
index (Hale, 2001), offering for each word an as-
sessment of its integration costs into the syntactic
structure. This evaluation is done starting from the
probability of the possible solutions. On their side,
symbolic approaches also provide an estimation
of the activation degree, depending on the num-
ber and weight of syntactic relations to the current
word (Blache et al., 2006); (Blache, 2013).
These approaches are based on the classical idea
that language processing is incremental and oc-
curs word by word. There are however several ex-
perimental evidences showing that a higher level
of processing is used by human subjects. Eye-
tracking data show for example that fixations are
done by chunks, not by words (Rauzy and Blache,
2012). Similarly, EEG experiments have shown
that processing multiword expressions (for exam-
ple idioms) relies on global mechanisms (Vespig-
nani et al., 2010); (Rommers et al., 2013).
Starting from the question of complexity and its
estimation, I will address in this presentation the
problem of language processing and its organiza-
tion. I propose more precisely, using computa-
tional complexity models, to define a cohesion in-
dex between words. Such an index makes it possi-
ble to define chunks (or more generally units) that
are built directly, by aggregation, instead of syn-
tactic analysis. In this hypothesis, parsing consists
in two different processes: aggregation and inte-
gration.
Acknowledgments
This work, carried out within the Labex BLRI
(ANR-11-LABX-0036), has benefited from sup-
port from the French government, managed by
the French National Agency for Research (ANR),
under the project title Investments of the Future
A*MIDEX (ANR-11-IDEX-0001-02).
Short biography
Philipe Blache is Senior Researcher at CNRS
(Aix-Marseille University, France). He is the
Director of the BLRI (Brain and Language Re-
search Institute), federating 6 research laborato-
ries in Linguistics, Computer Science, Psychology
and Neurosciences.
Philippe Blache earned an MA in Linguistics
from Universit?e de Provence and a MSc in Com-
puter Science from Universit?e de la M?editerran?ee,
where he received in 1990 his PhD in Artificial In-
telligence.
During his career, Philippe Blache has focused
on Natural Language Processing and Formal Lin-
guistics, with a special interest in spoken language
analysis. He has proposed a linguistic theory,
called Property Grammars, suitable for describ-
ing language in its different uses, and explaining
linguistic domains interaction. His current aca-
1
demic works address the question of human lan-
guage processing and its complexity.
Philippe Blache has been director of two CNRS
laboratories in France (2LC and LPL). He has
served on numerous boards (European Chapter
of the ACL, ESSLLI standing committee, CSLP,
etc.). He is currently member of the Scien-
tific Council of Aix-Marseille Universit?e, mem-
ber of the ?Comit?e National de la Recherche Sci-
entifique? in computer science and he chairs the
TALN conference standing committee.
References
Philippe Blache, Barbara Hemforth, and St?ephane
Rauzy. 2006. Acceptability prediction by means of
grammaticality quantification. In ACL-44: Proceed-
ings of the 21st International Conference on Compu-
tational Linguistics and the 44th annual meeting of
the Association for Computational Linguistics. As-
sociation for Computational Linguistics, July.
Philippe Blache. 2013. Chunks et activation : un
mod`ele de facilitation du traitement linguistique. In
Proceedings of TALN-2014.
Edward Gibson. 2000. The Dependency Locality The-
ory: A Distance-Based Theory of Linguistic Com-
plexity. In Alec Marantz, Yasushi Miyashita, and
Wayne O?Neil, editors, Image, Language, Brain,
pages 95?126. Cambridge, Massachussetts, MIT
Press.
John Hale. 2001. A probabilistic earley parser as a
psycholinguistic model. In Proceeding of 2nd Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics, Pittsburgh,
PA.
John Hawkins. 2001. Why are categories adjacent.
Journal of Linguistics, 37.
Frank Keller. 2005. Linear Optimality Theory as a
Model of Gradience in Grammar. In Gradience in
Grammar: Generative Perspectives. Oxford Univer-
sity Press.
St?ephane Rauzy and Philippe Blache. 2012. Robust-
ness and processing difficulty models. a pilot study
for eye-tracking data on the french treebank. In
Proceedings of the 1st Eye-Tracking and NLP work-
shop.
Joost Rommers, Antje S Meyer, Peter Praamstra, and
Falk Huettig. 2013. Neuropsychologia. Neuropsy-
chologia, 51(3):437?447, February.
Shravan Vasishth. 2003. Quantifying processing dif-
ficulty in human sentence parsing: The role of de-
cay, activation, and similarity-based interference.
In Proceedings of the European Cognitive Science
Conference 2003.
Francesco Vespignani, Paolo Canal, Nicola Molinaro,
Sergio Fonda, and Cristina Cacciari. 2010. Predic-
tive mechanisms in idiom comprehension. Journal
of Cognitive Neuroscience, 22(8):1682?1700.
Tessa Warren and Ted Gibson. 2002. The influence of
referential processing on sentence complexity. Cog-
nition, 85:79?112.
2
