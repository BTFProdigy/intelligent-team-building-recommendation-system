Dec is ion -Tree  based Error  Cor rec t ion  for Stat is t ica l  Phrase  Break  
Pred ic t ion  in Korean  * 
Byeongchang K im and Geunbae Lee 
Del)artment of Computer  Science & Engineering 
Pohang University of Science & Technology 
Pohang, 790-784, South Korea 
{bckim, gblee}((~postech.ac.kr 
Abst ract  
tn this paper, we present a new 1)hrase break 
prediction architecture that integrates proba- 
bilistic apt)roach with decision-tree based error 
correction. The probabilistic method alone usu- 
ally sufl'crs fronl performance degradation due 
to inherent data sparseness l)rolflems and it only 
covers a limited range of contextual informa- 
tion. Moreover, the module can not utilize the 
selective morpheme tag and relative distance 
to the other phrase breaks. The decision-tree 
based error correction was tightly integrated to 
overt:ohm these limitations. 
The initially phrase break tagged morphcnm se- 
quence is corrected with the error correcting de- 
cision tree which was induced by C4.5 fl'om the 
correctly tagged corpus with the outtmt of the 
15mbabilistic predictor. The decision tree-based 
post error correction l)rovided improved results 
even with the phrase break predictor that has 
l)oor initial performance. Moreover, tim system 
can be flexibly tamed to new corI)uS without 
massive retraining. 
1 I n t roduct ion  
During 1;15(; past thw years, there has l)een a 
great deal of interest in high quality text-to- 
speech (TTS) systelns (van Santen et al, 1997). 
One of the essential prolflenlS ill developing high 
quality TTS systems is to predict phrase breaks 
flora texts. Phrase breaks are especially es- 
sential fbr subsequent processing in the TTS 
systems uch as grapheme-to-iflloneme conver- 
sion and prosodic feature generation. More- 
over, gral)helnes in the phrase,-break bound- 
aries are not phonologically changed and should 
be i)ronommed as their original corresponding 
p honenles. 
There have been two apln'oaches to predict 
phrase breaks (Taylor and Black, 1998). The 
* This paper was supported by the University Research 
Program of the Ministry of Intbrmation & Communica- 
tion in South Korea through the IITA(1998.7-2000.6). 
first: uses some sort of syntactic information to 
In:edict prosodic boundaries based on the fact 
that syntactic structure and prosodic structure 
are co-related. This method needs a reliable 
parser and syntax-to-prosody 1nodule. These 
modules are usnally implemented in rule-driven 
methods, consequently, they are difficult to 
write, modi(y, maintain and adapt to new do- 
mains and languages. Ill addition, a greater use 
of syntactic information will require, more con> 
lmtation for finding n more detailed syntactic 
parse. Considering these shortcomings, the sec- 
ond approach uses some probabilistic methods 
on the crude POS sequence of the text:, and this 
lnethod will be fln:ther developed in this paper. 
However, t:he. probabilistic method alone usu- 
ally sufl'ers front pertbrmance degradation due 
to inherent data sparseness problems. 
So we adopted decision tree-based error COl'- 
re, ction to overconm these training data limi- 
tations. Decision tree induction iv 1;t5(; most 
widely used \]calming reel;hod. Espcci~flly in lla~l;- 
m:al language and speech processing, decision 
tree learning has been apt)lied to many prob- 
h,.nls including stress acquisition fl'om texts, 
gralflmme to phonenm conversion and prosodic 
phrase, modeling (Daelemans et al, 1994) (van 
Santen et al, 1997) (Lee and Oh, 1999). 
In the next section, linguistic fb, atures of Ko- 
rean relevant o phrase break prediction are de- 
scribed. Section 3 presents the probabilistic 
phrase break prediction method and the tree- 
based error correction method. Section 4 shows 
experimental results to demonstrate he t>erfor - 
mam:e of the method and section 5 draws st)me 
conclusions. 
2 Features  o f  Korean  
This section brMly explains the linguistic char- 
acterists of spoken Korean before describing the 
phrase break prediction. 
1) A Korean word consists of more than 
one morpheme with clear-cut morphenm bound- 
aries (Korean is all agglutinative language). 
1051 
2) Korean is a postpositional language with 
many kinds of noun-endings, verb-endings, and 
prefinal verb-endings. These functional mor- 
phemes determine a noun's case roles, a verb's 
tenses, modals, and modification relations be- 
twcen words. 3) Korean is basically an SOV 
language but has relatively free word order 
compared to other rigid word-order languages 
such as English ,except br the constraints that 
the verb must appear in a sentence-final posi- 
tion. However, in Korean, some word-order con- 
straints actually do exist such that the auxiliary 
verbs representing modalities must follow the 
main verb, and modifiers must be placed betbre 
the word (called head) they modify. 4) Phono- 
logical changes can occur in a morpheme, be- 
tween morphemes in a word, and even between 
words in a phrase, but not between phrases. 
3 Hybr id  Phrase  Break  Detect ion  
Part-of speech (POS) tagging is a basic step 
to phrase break prediction. POS tagging sys- 
tems have to handle out-of vocabulary (OOV) 
words for an unlimited vocabulary TTS sys- 
tem. Figure 1 shows the architecture of our 
phrase break predictor integrated with the POS 
tagging system. The POS tagging system era- 
ploys generalized OOV word handling mecha- 
nisms in the morphological analysis and cas- 
cades statistical and rule-based approaches in 
the two-phase training architecture tbr POS dis- 
ambiguation. 
Morphological !;i 
I analyzc r~ 
{M~pl me ..... ~se~i~ ': 
~, :  . / Protmbilistlc I rtgram ~z'~*t  $ 
I 
Figure 1: Architecture of the hybrid phrase 
break prediction. 
Tire probabilistic phrase break predictor seg- 
ments the POS sequences into several phrases 
according to word trigram probabilities. Tire 
irdtial phrase break tagged morpheme sequence 
is corrected with the error correcting tree 
learned by the C4.5 (Quinlan, 1983). 
Tire next two subsections will give detailed 
descriptions of the probabilistic phrase predic- 
tion and error correcting tree learning. The hy- 
brid POS tagging system will not l)e explained 
in this paper, and the interested readers can see 
(Cha et al, 1998) tbr further reference. 
3.1 Probabi l i s t ie  Phrase Break 
Detect ion  
3.1.1 Probabi l l s t ie  Models  
For phrase break prediction, we develop tire 
word POS tag trigrmn model. Some experi- 
ments are performed on all the possible trigram 
sequences and 'word-tag word-tag break word- 
tag' sequence turns out to be the most fl'uitful 
of any others, which are the same results as the 
previous tudies in English (Sanders, 1995). 
The probability of a phrase break bi appear- 
ing after the second word POS tag is given by 
P(bilt?,2ta) = C(tlt2bit3) 
Ej=o,~,2 C(ht2b j t3)  '
where C is a frequency count flmction and b0, 
bl and b2 mean no break, minor break and ma- 
jor break, respectively. Even with a large num- 
ber of training patterns it is very clear that 
there will be a number of word POS tag se- 
quences that never occur or occur only once in 
the training corpus. One solution to this data 
sparseness problem is to smooth the probabili- 
ties by using the bigram and unigram probabil- 
ities, which adjusts the fl'equency counts of rare 
or non-occurring POS tag sequences. We use 
the smoothed probabilities: 
P(biltlt,2ta) = )q C(trt2bit3) 
~j=o,l,2 C(t~ t2bjt3) 
C(t2bita) 
q- A2 ~j=0,1,2 C(t2bjt3) 
+ C(t2bi) 
)t3 j=_0,1,2 C( 2bj) ' 
where )~1, A2 and ),a are three nommgative con- 
stants such that h I q- ~2 Jr- ~3 = 1. In some 
experiments, we can get the weights ~1, ~2 and 
A3 as 0.2, 0.7 and 0.1, respectively. 
3.1.2 Adjust ing the POS Tag 
Sequences of  Words 
Previous researchers of phrase break predic- 
tion used mainly content-flnmtion word rule, 
wherel)y a phrase break is placed before every 
flmction word that follows a content word (Allen 
and Hmmicut, 1987) (Taylor et al, 1991). The 
1052 
researchers used tag set size of only 3, including 
function, content ~md t)lmctuation i  the rule. 
However, Korean is a post-positional aggln- 
tinative language. If the eontent-t'unction word 
rule is to be adapted in Korean, the rule nmst 
be changed so that a phrase break is placed 
before every content mort/henm that R)llows a 
fimction morl)heme. Unfortunately this rule 
is very inet\[icient in Korean since it tends to 
create too many pauses. In our works, only 
the POS tags of Nnction mort)heroes are used 
be, cause the function morphelnes constrain the 
classes of precedent n:orpheanes and t)b\y impor- 
tant roles in syntactic relation. So, each word 
is represented by the I?OS tag of its fimction 
morpheme. In the case of the word which has 
no function mort)heine , simplified POS tags of 
content mort)henms are used. The nmnber of 
POS tags use, d in this rese, m'ch is a2. 
3.2 Dec is ion -Tree  Based  Error  
Correct ion  
The t)robabilistic phrase break prediction only 
covers a limited range of contextual infornm- 
tion, i.e. two preceding words and one. follow- 
ing word. Moreove, r the module can not utilize 
the morl)heme tag se.lectively and relative dis- 
tance to the other phrase breaks. For this rea- 
son we designed error correcting tree to con> 
pensate for |;tie limitations of the. probal)ilistic 
phrase break prediction. However, designing er- 
ror corre, cting rules with knowledge ngineering 
is te, dious and error-prone,, lTnstead, we, adopte, d 
decision tree learning ai)proa(:h to auton~atically 
learn the error correcting rules froln a correctly 
t:,hrase break tagged eorlms. 
Most algorithms th:~t have t)een develope, d 
for lmilding decision trees employ a top-down, 
greedy search through the space of possible deci- 
sion trees (Mitchell, 1997). The 04.5 (Quinlan, 
1983) is adequate to buiht a decision tree easily 
for successively dividing the regions of feature 
vector to minimize the prediction error. It also 
uses intbrmation gain which lneasures how well 
a given attril)ute separates the training vectors 
according to their target classification in order 
to select he most critical attrilmtes at each step 
while growing |;tit tree (hence the nmne is IG- 
~l'ree). Now, we utilize it for correcting the ini- 
tially phrase break tagged POS tag sequences 
generated by probabilistic predictor. 
However, wc invented novel way of using the 
decision tree as trmlsibrmation-t)ased rule in- 
duction (Brill, 1992). l?igure, 2 shows the tree 
learning architecture tbr phrase break error cor- 
rection. The initial phrase break tagged POS 
tag sequences upport the ti;ature vectors tbr 
attributes which are used tbr decision mak- 
ing. Because the ii;atm'e vectors include phrase 
break sequences as well as POS tag sequences, 
a learned decision tree can check |;lie morphenm 
tag selectively and utilize |;lie relative distanee 
to the other phrase breaks. The correctly phrase 
break tagged POS tag sequences upport the 
classes into which the feature vectors are classi- 
fied. C4.5 lmilds a decision tree fl'om the t)airs 
which consist of the feature vectors and their 
classes. 
. . . .  I Prol,al,ilislic 11 
l'I,rase l,reak ta~ged 
POS tag seque nee 
. . . . .  Correctly plmlse break tagged 
~-~\ ] : :  ........ ...... POS tag sequence  
ErrOr Correcting decision tree 
Figure 2: Architecture of the error correcting 
decision tree learner. 
4 Exper imenta l  Resu l ts  
4.1 Corpus  
The, experiments are t)ertbrmed on a Korean 
news story database,, called MBCNF, WS\])I~, of 
spoken Korean directly recorded f rom broad- 
casting news. The size of th(; database is now 
6,111 sentences (75,647 words) and it is eontin- 
nously growing. '12) lm used in the phrase break 
prediction experiments, |;tie database has been 
POS tagged and break-b~beled with major and 
minor phrase breaks. 
4.2 Phrase  Break  Detect ion  and Error  
Correct ion  
We, I)eribrmed three experiments o show syner- 
gistic results of probabilistic method and tree- 
based error correction method. First, only prob- 
abilistic method was used to predict phrase 
breaks. %'igrams, bigrams and unigrams for 
phrase break prediction were trained fl:om the 
break-labeled an(1 POS tagged 5,492 sentences 
of the MBCNEWSDB by adjusting the POS 
sequences of words as described in sut)section 
3.1.2. The other 619 sentences are used to 
test the t)ertbrnum(:e of the probabilistic I)hrase 
break predictor. In the second experiment, we 
made a decision tree, which can be used only 
to predict phrase breaks and cannot be used to 
1053 
correct phrase breaks, from the 5,429 sentences. 
Also the 619 sentences were used to test the 
performance of the decision tree-based phrase 
break predictor. The size of feature vector (the 
size of the window) is w~ried fi'om 7 (the POS 
tag of current word, preceding 3 words and fol- 
lowing 3 words) to 15 (the POS tag of current 
word, preceding 7 words and following 7 words). 
The third experiment utilized a decision tree as 
post error corrector as presented in this paper. 
We trained trigrams, bigrams and unigrams us- 
ing 60% of totM sentences, and learned the deci- 
sion tree using 3(1% of total sentences. For the 
other experiment, 50% aim 40% of total sen- 
fences are used tbr probability training and tbr 
decision tree learning, respectively. Tim other 
10% of total sentences were used to test as in 
the prevkms ext)eriments(Figure 3). For the de- 
cision tree in the tlfird experiment, hough the 
size of the window is also varied from 7 words 
to 15 words, the size of feature vector is varied 
from 14 to 30 because phrase breaks tagged by 
probabilistic predictor are include in the feature 
vector. 
El I :oI  prababililies trai,ling D For decision Iree induction \[3 I:(!r lest 
(}9; . . . . .  
PI ol~:lbilislic Iil~,lhod 
only 
\[ 
\]GITtee mlly Prolmbilisfic ii~01\]lod Pmballilistic iii0thod 
lind post error ~tlltl IX)st ?IlOl 
cDrl ocliOll(6:3 ) t'olteclJoll(4:5 ) 
Fignre 3: The number of sentences for the prob- 
ability training, the decision tree learning and 
the test in the experiments. 
Tit(; performance is assessed with reference to 
N, the total number of junctures (spaces in text 
including any type of phrase breaks), and B, the 
total number of phrase breaks (only minor(b1) 
and major(b,)) breaks) in the test set. The er- 
rors can be divided into insertions, deletions and 
substitutions. An insertion (I) is a break in- 
serted in the test sentence, where there is not a 
break in the reference sentence. A deletion (D) 
occurs when a break is marked in the rethrence 
sentence but not in the test sentence. A substi- 
tution (S) is an error between major break and 
minor break or vice versa. Since there is no sin- 
gle way to measure the performance of phrase 
break prediction, we use the following peribr- 
mance measures (Taylor and Black, 1998). 
Break_Cor rect  - 
B -D-S  
B 
x 100%, 
N - D - S - I  
Juncture_Cor rect  = x 100% 
N 
We use another pertbrmance nmasure, cMled 
adjusted score, which refer to the prediction ac- 
curacy in proportion to the total nmnber of 
phrase breaks as following performance measure 
proposed by Sanders (Sanders, 1995). 
Adjus ted_Score  -
, IC  - NB 
1-N I3  ' 
where NB 1 means the proportion of no 
breaks to the number of interword spaces and 
, lC  means the Juncture_Correct / lO0.  
Table 1. shows the experimental results of our 
phrase break prediction and error con:ection 
method on the 619 open test sentences (10% 
of the total corpus). In the table, W means the 
thature vector size tbr the decision tree, and 6:3 
and 4:5 mean ratio of the number of sentences 
used in the probabilistic train and the decision 
tree induction. 
The performance of probabilistic method is 
better than that of IG-tree method with any 
window size in U'reak_Cor'rect.  However, as the 
ti;ature vector size is growing in IO-tree method, 
.lv, nctv, re_Co'rrect  and Ad j , ( s led_Score  become 
better than those of the l)robM)ilitic method. 
From the fact that the attribute located in the 
first level of the decision trees is the POS tag of 
preceding word, we can see that the POS tag of 
preceding word iv the most useful attribute for 
predicting phrase breaks. 
The pertbrmance before the error correction 
in hyl)rid experiments iv worse ttlan that of the 
original 1)robabilistic method because the size of 
training corlms for probabilistic method is only 
66.6% and 44.4:% of that of the original one, re- 
spectively. However, the performance sets im- 
proved by the post error correction tree, and be- 
corns finally higher than that of both the prob- 
abilistic nmthod and the IG-tree method. The 
attribute located in the first level of the decision 
tree is the phrase break that was predicted in 
the probatfilistic method phase. Although the 
initial pertbrmmme (beibre error correction) of 
the exImriment using 4:5 corpus ratio is worse 
than that of the experiment using 6:3 corlms 
ratio, the final perfbrmance gets impressively 
improved as the decision tree induction corpus 
1NB _ N- I~ 
N 
1054 
'li~l)l( ~, 1: 1)hrase break t)\]e{ti(:tion ~md error eorr{',ction results. 
\]3r(;~k_Correet 
1}rol)al)ilis|;ic method only 
IG-Tree only 
Prol)al)ilisl;ie 
mel;ho(t 6:3 
~I~15(I 
l)ost error 
eorr(~,e|; iol l  
4:5 
W=7 
W- 11 
W= 15 
l)efore error eorre{;t;iol~ 
W=7 
W=l l  
W= 15 
1)~;~, ore, error con'e(;tion 
W=7 
W- - l l  
W- -15  
52.17% 
5O.58% 
51.66% 
51.77% 
52.03% 
57.34{~) 
59.8O% 
60.75% 
51.30% 
59.O4% 
61.83% 
62.7/1% 
J un{:l;{~re_CorreeI; 
81.39% 
81.39% 
81.65% 
81.71.% 
81.29~/~0 
83.67% 
84.69% 
85.O6% 
80.85'~ 
84.42% 
85.16% 
85.57% 
Adj us te ( l _ -~ 
0.48O 
0.480 
0,487 
0.488 
0.477 
0.543 
0.572 
0.582 
0.465 
0.564: 
0.585 
0.597 
incre,~ses from 30% 1;o 50% of the to|;al (:()rims. 
~l)his result; shows t;h~t |;he prol)osed ~rehilx~e- 
ture c~m 1)rovi(te, improved results evell with the 
phrase 1)re~k \])re(tie|:or |:h~l; h~s I)oor |nit|a,1 per- 
f()z'51 I~L51(;(~,. 
5 Conc lus ion 
This t)~l)er l)r{;s(:nts ;~ new 1)hr;tse t)rea.k predic- 
|;ion ~rt:hil;eel;ure l;h~l; inl;egr~tes the t}rob~bilis- 
tie ;~t)t)ro~eh wii;h the (le(:ision-tree 1)~s{'(t ~tl)- 
t)ro~teh in ;~ synergistic w~y. Our m~in contl'it)u- 
|,ions include presenl;ing (leeision |;ree-1);~se(1 r-
ror correction for 1)hr~se t)re~k prediel;ion. Also, 
i)rol)~fl)ilistic t)hrase break prediction w~ts im- 
t)leme, nt;e(l a.s ;I,51 inil:i~tl am~ot~l;or f the (tet:i- 
si()n tree-t)~tse(t e, rror (:orre('tiolL The m:ehite,('- 
ture ('~m t)rovi(te imt)l"ove(t results even with l;he 
1)\]u:;~se t)re;~k l)redi{:tor |;h;t|; ha,s l)o{)r inil;i~d t}er- 
t'orm~mee. Moreover, I;he, syslxun (:~m 1)e ttexit)ly 
t;u, ned t;o new eort)us wil;houl; nmssive rel;r;~ining 
which is necess~ry in the t)rol}~bilisti(: metho(t. 
As shown in the result, t)erli)rmamce, of the hy- 
t)rid t)hr~se 1)re~k t)redietion is dctermilmd t)y 
how well the error eorre('|;or ( ; t in  (;Ollll)ellS;~l;e 
i;he defi(:iencies of the 1)rol)~d)ilistie t)hrase 1)re~k 
predict;ion. 
The next sl;el) will 1)e to :m~lyze the le~rned 
de(:ision trees eareflflly I;() exi;r;~(:l; more desir~t)le 
ti',~tl;ur(', veel;ors. W(', ~re now working 055 in(:or- 
l)or~|;ing this i)hl'~se, break 1)redi('tion 5he|hod 
into the ext)erimenl;~l Korean 'I?'\]?S sysl;em. 
References  
J. Alle, n ~md S. Humli{'ut. 1987. l'"ro~tt !l'ext to 
St)eech: the: MITalk  Systcnt. Cmnl)ridge Uni- 
versity Press. 
IB. \]\]rill. 1992. A simple rule-based p~rl;-ot/- 
speech t~gg{'r. In \]}roccediT~,.qs of the co~:fer- 
c'~tcc o~, applied ~,at'u,r'rd la~zg'aage processi~zg. 
.\]eos\]gwon Ch~, Oeunbae \]~(;e, ~md Jong-Hyeok 
Lee. :1998. Ge, nc, r~dized mlknown morphelne 
guessing for hybrid P()S l;~tgging of Kor(';m. 
In P'lw('ecdi'l~,gs of th.(: Sizth, Wo'r~:.sh, op o'l~, l&-"cq 
ha'rqc Co'rpora, t}~g('s 85 93. 
Dvr~llx'r l)a(;lem~ms, St;ev{'n Gills, ~md Gerl; 
\])urieux. 1994. 'l'he ~cquisil;ion of sl;ress: A 
d~l;a-orienl;ed ~l)l)ro~{:h. Co~tI)~tl, al, io'l~,al Liw,- 
g'ltil, ics, 20(3):421 451. 
Sangho Lee ;rod Yung-Itw~m O15. 1999. ~.lS:ee- 
t)~rse(t mo(l(;ling of 1)roso(tie 1)hr,(sing ~1~(t 
segmei~l;~tl ( m:a.t;ion for kore~m |.t.q ,qy,qJ;elll,q. 
,~peech, Co'll~,~n,'w~,icatio~,, 28(4):283 300. 
q'om M. Mil;ehell. 1!)97. Mach, i~,c Lea'~"H,i~,g. 
MeGr~w-Ilill. 
J. l/,. {~uinDm. 1.983. C~.5: l'ro!tr(~ms fo'~" M(z- 
ch, i'~,e Lea'r'~,i'~ 9. Morgan K~mflnlmn. 
\]Brie S~mtlers. 1.9!t5. Using prot}al)ilistic mel:h- 
()<Is |;o t)re(lict phr~se t)oundaries for ~t text- 
to-sl)eeeh system. Master's thesis, University 
of Nijmegen. 
P~ml T~,ylor ;md Alum W. BD~t:k. 1!)98. As- 
signing phrase l)rc,~ks kom 1)ar|;-of-st)e, eeh sc,- 
qllelIces. Cotlt\])'lttcr Speech (t~td La~tg'~t(,,gc, 
12(2):9!} 1~7. 
lhml A. 'l?aylor, I. A. N~irn, A. M. fiutherl;md, 
~md M. A..l~ck. 1991. A re~l time speech 
synthesis ystem. 1151 l~rot:ce, dirt.q.s of th, c \]~'~t- 
rospecch, '9.l. 
,l~m P.II. wm Santen, l/.iehard W. Sl)roat, 
3osel)h P. Olive, ~md .luli~ Hirsehl)erg. 
1997. l}rog'r(;ss in Speech Sy~,th, esis. Springer- 
VerLzg. 
1055 
 
	Using Higher-level Linguistic Knowledge for Speech Recognition Error
Correction in a Spoken Q/A Dialog
Minwoo Jeong
Department of Computer
Science and Engineering,
POSTECH, Pohang, Korea
stardust@postech.ac.kr
Byeongchang Kim
Division of Computer and
Multimedia Engineering,
Uiduk University,
Gyeongju, Korea
bckim@uiduk.ac.kr
Gary Geunbae Lee
Department of Computer
Science and Engineering,
POSTECH, Pohang, Korea
gblee@postech.ac.kr
Abstract
Speech interface is often required in many
application environments such as telephone-
based information retrieval, car navigation sys-
tems, and user-friendly interfaces, but the low
speech recognition rate makes it difficult to ex-
tend its application to new fields. Several ap-
proaches to increase the accuracy of the recog-
nition rate have been researched by error cor-
rection of the recognition results, but previ-
ous approaches were mainly lexical-oriented
ones in post error correction. We suggest
an improved syllable-based model and a new
semantic-oriented approach to correct both se-
mantic and lexical errors, which is also more
accurate for especially domain-specific speech
error correction. Through extensive experi-
ments using a speech-driven in-vehicle telem-
atics information retrieval, we demonstrate
the superior performance of our approach and
some advantages over previous lexical-oriented
approaches.
1 Introduction
New application environments such as telephone-based
retrieval, car navigation systems, and mobile information
retrieval, often require speech interface to conveniently
process user queries. In these environments, keyboard
input is inconvenient or sometimes impossible because
of spatial limitation on mobile devices and instability in
manipulating the devices.
However, because of the low recognition rate in current
speech recognition systems, the performance of speech
applications such as speech-driven information retrieval
(IR) and question answering (QA), and speech dialogue
systems is very low. The performance of the serially con-
nected spoken QA system, based on the QA system from
text input which has 76% performance and the output of
the ASR which operated at a 30% WER, was only 7%
(Harabagiu et al, 2002). (Harabagiu et al, 2002) ex-
poses several fundamental flaws of this simple combina-
tion of an automatic speech recognition (ASR) and QA
system, including the importance of named entity infor-
mation, and the inadequacies of current speech recogni-
tion technology based on n-gram language models.
The major problem of speech-driven IR and QA is the
decreasing of the performance due to the recognition er-
rors in ASR systems. Erroneously recognized spoken
queries drop the precision and recall of IR and QA sys-
tem. Some authors investigated the relation of ASR er-
rors and precision of IR (Barnett et al, 1997; Crestani,
2000). They evaluated the effectiveness of the IR systems
through various error rates using 35 queries of TREC.
Their researches show that the increasing word error rate
(WER) quickly decreases the precision of IR. Another
group investigated the performance of spoken queries in
NTCIR collections (Fujii et al, 2002A). They evaluated
a variety of speakers, and calculated the error rate with
respect to a query term, which is a keyword used for the
retrieval. They showed that the WER of the query terms
was generally higher than that of the general words ir-
respective of the speakers. In other words, recognition
of content words related to the IR and QA performance
was more difficult than that of normal words. So, they
introduced a method to improve the precision of speech-
driven IR by suggesting a new type of IR system tightly-
integrated with a speech input interface (Fujii et al,
2002B). In their system, document collection provides an
adaptation of the language model of the ASR, which re-
sults in a drop of the word error rate.
For this reason, some appropriate adaptation tech-
niques are required for overcoming speech recognition
errors such as post error correction. ASR error correc-
tion can be one of the domain adaptation techniques to
improve the recognition accuracy, and the primary advan-
Figure 1: Adaptation via Post Error Correction
tage of the error correction approach is its independence
of the specific speech recognizer. If the speech recog-
nizer can be regarded as a black-box, we can perform ro-
bust and flexible domain adaptation through the post error
correction process. Figure 1 shows the paradigm of this
post error correction approach.
One approach in post error correction, which is a
straightforward and intuitive method to robustly handle
many kinds of recognition errors, was rule-based ap-
proach (Kaki et al, 1998). (Kaki et al, 1998) collected
many lexical error patterns that occurred in a speech
translation system in Japanese. They could correct any
type of errors by matching the strings in the transcription
with lexical error patterns in the database. However, their
approach has a disadvantage in that the correction is only
feasible to the trained (or collected) lexical error patterns.
Another approach has been based on a statistical
method utilizing the probabilistic information of words
in a spoken dialogue situation and the language models
adapted to the application domain (Ringger and Allen,
1996). (Ringger and Allen, 1996) applied the noisy chan-
nel model to the correction of the errors in speech recog-
nition. They simplified a statistical machine translation
(MT) model called an IBM model (Brown et al, 1990),
and tried to construct a general post-processor that can
correct errors generated by any speech recognizer. The
model consists of two parts: a channel model, which ac-
counts for errors made by the ASR, and the language
model, which accounts for the likelihood of a sequence of
words being uttered. They trained the channel model and
the language model both using some transcriptions from
TRAINS-95 dialogue system which is a train traveling
planning system (Allen et al, 1996). Here, the channel
model has the distribution that an original word may be
recognized as an erroneous word. They use the proba-
bility of mistakenly recognized words, the co-occurrence
information extracted from the words and their neighbor-
ing words, and the tagged word bi-grams, which are all
lexical clues in error strings.
Such approaches based on lexical information of words
have shown some successful results, but they still have
major drawbacks; The performance of such systems de-
pends on the size and the quality of speech recognition
result, or on the database of collected error strings since
they are directly dependent on lexical items. The error
patterns constructed are available but not enough, be-
cause it is expensive to collect them; so in many cases,
they fail to recover the original strings from the lexical
specific error patterns. Also, since they are sensitive to
the error patterns, they occasionally mis-identify a cor-
rect word as an error word.
We suggest a more improved and robust semantic-
oriented error correction approach, which can be in-
tegrated into previous fragile lexical-based approaches.
In our approach, in addition to lexical information, we
use high level syntactic and semantic information of the
words in a speech transcription. We obtain semantic in-
formation from a knowledge base such as general the-
sauri and a special domain dictionary that we construct
by ourselves to contain some domain specific knowledge
to the target application.
In the next section, we first describe a general noisy
channel model for ASR error correction and discuss some
problems with them. We then introduce our improved
channel model especially for Korean language in section
3. We also propose a new high-level error correction
model using syntactic and semantic knowledge in section
4. We prove the feasibility of our approach through some
experiments in section 5, and draw some conclusions in
section 6.
2 Noisy Channel Error Correction Model
The noisy channel error correction framework has been
applied to a wide range of problems, such as spelling
correction, statistical machine translation, and ASR error
correction (Brill and Moore, 2000; Brown et al, 1990;
Ringger and Allen, 1996). The key idea of noisy chan-
nel model is that we can model some channel properties
through estimating the posterior probabilities.
The problem of ASR error correction can be stated
in this model as follows: For an input sentence, O =
o1, o2, . . . , on produced as the output sequence of ASR,
find the best word sequence,W? = w1, w2, . . . , wn, that
maximizes the posterior probability P (W |O). Then, ap-
plying Bayes? rule and dropping the constant denomina-
tor, we can rewrite as:
W? = arg max
W
P (W |O) = arg max
W
P (W )P (O|W ) (1)
Now, we have a noisy channel model for ASR er-
ror correction, with two components, the source model
P (W ) and the channel model P (O|W ). The probability
P(W) is given by the language model and can be decom-
posed as:
P (W ) =
?
i
P (wi|w1,i?1) (2)
Figure 2: Example of Word-based Channel Model
The distribution P (W ) can be defined using n-grams,
structured language model (Chelba, 1997), or any other
tool in the statistical language modeling.
Next, the conditional probability, P (O|W ) reflects the
channel characteristics of the ASR environment. If we as-
sume that the output word sequence produced under ASR
are independent of one another, we have the following
formula:
P (O|W ) =
?
i
P (o1,i|w1,i) =
?
i
P (oi|wi) (3)
So,
W? = arg max
W
P (W )P (O|W )
= arg max
W
(
?
i
P (wi|w1,i?1)
?
i
P (oi|wi))(4)
However, this simple one-to-one model is not suitable
to handling split or merged errors, which frequently ap-
pear in an ASR output, because we assume that the out-
put word sequence are independent of one another. For
example, 1figure 2 shows a split or a merged error prob-
lem. To solve this problem, Ringger and Allen used the
fertility of pre-channel word (Ringger and Allen, 1996).
Following (Brown et al, 1990), we refer to the num-
ber of post-channel words oi produced by a pre-channel
word wi as a fertility. They simplified the fertility model
of IBM statistical MT model-4, and permitted the fer-
tility within 2 windows such as P (oi?1, oi|wi) for two-
to-one channel probability, and P (oi|wi, wi+1) for one-
to-two channel probability. So, the fertility model can
deal with (TO LEAVE, TOLEDO) substitution. But this
improved fertility model only slightly increased the ac-
curacy in experiments (Ringger and Allen, 1996), and
we think the major reason is due to the data-sparseness
problem. Because substitution probability is based on the
whole word-level, this fertility model requires enormous
training data. We call the model a word-based channel
model, because this model is based on the word-to-word
transformation. The word-based model focused on inter-
word substitutions, so it requires enough results of ASR
and transcription pairs. Considering the cost of building
the enough amount of correction pairs, we need a smaller
unit than a word for overcoming the data-sparseness.
1This example is from (Ringger and Allen, 1996).
3 Syllable-based Channel Model
We suggest an improved channel model for smaller train-
ing data. If we can use smaller unit such as letter,
phoneme or syllable than word, relatively smaller training
set is needed. For dealing with intra-word transformation,
we suggest a syllable-based channel model, which can
deal with syllable-to-syllable transformation. This model
is especially reasonable for Korean. In some agglutina-
tive languages such as Korean, syllable is a basic unit of
written form like a Chinese character. In Korean, the av-
erage number of syllables in one word is about three or
four.
3.1 The Model
Suppose S = s1, s2, . . . , sn is a syllable sequence of
ASR output and W = w1, w2, . . . , wm is a source word
sequence, then our purpose is to find the best word se-
quence W? as follows:
W? = arg max
W
P (W |S) (5)
We can apply the same Bayes? rule and decompose the
syllable-to-word channel model into syllable-to-syllable
channel model.
P (w|s) = P (s|w)P (w)P (s) ? P (s|w)P (w)
? P (s|x)P (x|w)P (w) (6)
So, final formula can be written as:
W? = arg max
W
(P (W )P (X|W )P (S|X)) (7)
Here, P (S|X) is the probability of a syllable-to-
syllable transformation, where X = x1, x2, . . . , xn is
a source syllable sequence. P (X|W ) is a word model,
which can convert syllable lattice into word lattice. The
conversion can be done efficiently by dictionary look-up.
This model is similar to a standard hidden markov
model (HMM) of continuous speech recognition. In
speech recognition system, P (S|X) can be an acoustic
model in signal-to-phoneme level, and P (X|W ) can be
a pronunciation dictionary. Then, we applied the fertility
into our syllable-to-syllable channel model. We set the
maximum 2-fertility of syllable, which was determined
experimentally.
3.2 Training the Model
To train the model, we need a training data consisting
of {X,S} pairs which are manually transcribed strings
and ASR outputs. And, we align the pair based on mini-
mizing the edit distance between xi and si by dynamic
Figure 3: Example of Syllable-based Channel Model
programming. 2Figure 3 shows an alignment for the
syllable-model (For understanding, we use an English ex-
ample and a letter-to-letter alignment. In Korean, each
syllable is clearly distinguished much like a letter in En-
glish.). For example, (TO LEAVE, TOLEDO) pair in pre-
vious section can be divided into (TO, TO), (L, L), (EA,
E), and (VE, DO) with fertility 2.
We can then calculate the probability of each sub-
stitution P (si|xi) by Maximum-Likelihood Estimation
(MLE). Let C(xi) be the frequency of source syllable,
and C(xi, si) be the frequency of events where xi substi-
tute si. Then,
PMLE(si|xi) =
C(xi, si)
C(xi)
(8)
The total number of theoretical unique syllables is
about ten thousands in Korean, but the number of syl-
lables, which appeared at least one time, is about 2,300
in a corpus which has about 3 billion syllables. Thus, we
used Witten-Bell method for smoothing unseen substitu-
tions (Witten and Bell, 1991). Let T (xi) be the number
of substitution types, and N be the number of syllables in
a training data. For Witten-Bell discounting, we should
define Z(xi), which is the number of syllable xi with
count zero. Then, we can write as follows:
PWB(si|xi) =
T (xi)
Z(xi)(N + T (xi))
, if C(xi, si) = 0 (9)
3.3 Decoding the Model
Given a syllable sequence S, we want to find
arg maxW (P (W )P (X|W )P (S|X)). This will be to re-
turn an N-best list of candidates according to the models,
and then rescore these candidates by taking into account
the language model probabilities. To rescore the candi-
dates, we used Viterbi search algorithm to find the best
sequence. For implementation of candidate generation,
we store the syllable channel probabilities P (si|xi) as a
hash-table to pop them easily and fast. The system can
generate a candidate word sequence network using sylla-
ble channel model and a lexicon. And then, we can find
optimal sequence which has the best probability through
Viterbi decoding by including a language model.
2We omitted detail character-level match lines to simplify.
The whole word match is depicted in bold lines, while no-line
means character-level match errors.
Figure 4: Common semantic category values
4 Using Syntactic and Semantic
Knowledge
In some similar areas such as spelling error correction
or optical character recognition (OCR) error correction,
NLP researchers traditionally identified five levels of er-
rors in a text: (1) a lexical level, (2) a syntactic level,
(3) a semantic level, (4) a discourse structure level, and
(5) a pragmatic level (Kukich, 1992). In spelling cor-
rection and OCR error correction problem, correction
schemes mainly have focused on non-word errors at the
lexical level, which is an isolated word correction prob-
lem. However, errors of speech recognition tend to be
continuous word errors which should be better classi-
fied into syntactic and semantic level errors, because the
recognizer only produces word sequences existing in a
lexicon. So, this section presents a more syntax and
semantic-oriented approach to correct erroneous outputs
of a speech recognizer using a domain knowledge which
provides syntactic and semantic information. We fo-
cus on continuous word error detection and correction,
using syntactic and semantic knowledge, and pipeline
this high-level error correction method with the syllable-
based channel model.
4.1 Lexico-Semantic Pattern
A lexico-semantic pattern (LSP) is a structure where lin-
guistic entries and semantic types are used in combina-
tion to abstract certain sequences of the words in a text.
It has been used in the area of natural language interface
for database (NLIDB) (Jung et al, 2003) and a TREC
QA system for the purpose of matching the user query
with the appropriate answer types at syntax/semantic
level (Kim et al, 2001; Lee et al, 2001). In an LSP,
linguistic entries consist of words, phrases and part-of-
speech (POS) tags, such as ?YMCA,? ?Young Men?s
Christian Association,? and ?NNP.?3 Semantic types con-
3Part-of-speech tag denoting a proper noun which is used in
Penn TreeBank (Marcus et al, 1994).
Phrases LSP
Reading trainer
Fairy tale trainer %hobby @position
Recreation coach
Table 1: Example of a template abstracted by LSP
sist of common semantic classes and domain-specific (or
user-defined) semantic classes. The common semantic
tags again include attribute-values in databases, such as
?@corp? for a company name like ?IBM,? and pre-define
83 semantic category values, such as ?@location? for lo-
cation names like ?New York? (Jung et al, 2003). Fig-
ure 4 shows an example of predefined common semantic
category values which will be used in an ontology dictio-
nary.
In domain-specific application, well defined semantic
concepts are required, and the domain-specific seman-
tic classes represent these requirements. The domain-
specific semantic classes include special attribute names
in databases, such as ?%action? for ?active? and ?inac-
tive,? and semantic category names, such as ?%hobby? for
?reading? and ?recreation,? for which the user wants a spe-
cific meaning in the application domain. Moreover, we
used the classes to abstract out several synonyms into a
single concept. For example, a domain-specific semantic
class ?%question? represents some words, such as ?ques-
tion?, ?query?, ?asking?, and ?answer.?
The domain dictionary is a subset of the general se-
mantic category dictionary, and focuses only on the nar-
row extent of the knowledge it concerns, since it is im-
possible to cover all the knowledge of the world in imple-
menting an application. On the other hand, the ontology
dictionary for common semantic classes reflects the pure
general knowledge of the world; hence it performs a sup-
plementary role to extract semantic information. The do-
main dictionary provides the specific vocabulary which is
used in semantic representation tasks of a user query and
the template database.
4.2 Construction of a Domain Knowledge
For semantic-oriented error correction, we constructed a
domain knowledge, which consists of a domain dictio-
nary, an ontology dictionary, and template queries that
are similar to question types in a QA system (Lee et
al., 2001). Query sentences are semantically abstracted
by LSP?s and are automatically collected for the template
database.
Because Fujii et al (Fujii et al, 2002B) have shown
the importance of the language model which well de-
scribes the domain knowledge, we reflect the domain
information with a template database: database of tem-
plate queries of the source statements which are used
Figure 5: Process of Semantic-oriented Error Correction
for the actual error detection and correction task after
speech recognition. The template queries are automati-
cally acquired by the Query-to-LSP translation from the
source statements using two semantic category dictionar-
ies: domain dictionary and an ontology dictionary. As-
suming that some speech statements for a specific target
domain are predefined, a record of the template database
is composed of a fixed number of LSP elements, such as
POS tags, semantic tags, and domain-specific semantic
classes. Table 1 shows an example of template abstracted
by LSP conversion in a predefined domain of ?on-line ed-
ucation.?
Query-to-LSP translation transforms a given query into
a corresponding LSP, and the LSP?s enhance the cov-
erage of extraction by information abstraction through
many-to-one mapping between queries and an LSP. The
words in a query sentence are converted into the LSP
through several steps. First, a morphological analysis is
performed, which segments a sentence of words into mor-
phemes, and adds POS tags to the morphemes (Lee et al,
2002). NE recognition discovers all the possible seman-
tic types for each word by consulting a domain dictionary
and an ontology dictionary. NE tagging selects a seman-
tic type for each word so that a sentence can be mapped
into a suitable LSP sequence by searching several types
in the semantic dictionaries (An et al, 2003).
4.3 Semantic-oriented Error Correction Process
Now, we will show the working mechanism of post error
correction of a speech recognition result using the domain
knowledge of template database and domain-specific dic-
tionary. Figure 5 is a schematic diagram of the post error
correction process.
The overall process is divided into two stages: a syn-
tactic/semantic recovery and a lexical recovery stage. In
the semantic error detection stage, a recognized query is
converted into the corresponding LSP. The converted LSP
may be ill-formed depending on the errors in the rec-
ognized query. Semantic error correction is performed
by replacing these syntactic and/or semantic errors us-
ing a semantic confusion table. We used a pre-collected
template database to recover the semantic level errors,
and the technique for searching most similar templates
are based on a minimum edit distance dynamic program-
ming search, which has been used as a similarity search
in many areas such as spelling correction, OCR post cor-
rection, and DNA sequence analysis (Wagner and Fis-
cher, 1974). The semantic confusion table provides the
matching cost, which can be semantic similarity, to the
dynamic programming search process. The ?minimum
edit distance? between two words is originally defined as
the minimum number of deletions, insertions, and sub-
stitutions required to transform one word into the other.
We compute the minimum edit distances between the er-
roneous LSP?s and the template LSP?s in the template
database using the similarity cost functions at the seman-
tic level, and select, as the final template query, the one
which has the minimum distance among them. At this
stage, replaced LSP elements can provide some clues of
the recognition errors and the original query?s meaning
to the next lexical recovery stage. Moreover, candidate
error boundary can also be detected by this procedure.
After this procedure, lexical recovery is performed in
the next stage. Recovered semantic tags and the erro-
neous queries produced by ASR are the clues of lexi-
cal recovery. Erroneous query and recovered template
query are aligned by dynamic programming again, after
which some lexical candidates are generated by our im-
proved syllable-based channel model. Figure 6 4 shows
an example of semantic error correction process using the
same data in TRAIN-95 (Allen et al, 1996).
5 Experiments
5.1 Experimental Setup
We performed several experiments on the domain of in-
vehicle telematics IR related to navigation question an-
swering services. The speech transcripts used in the ex-
periments were composed of 462 queries, which were
collected by 1 male speaker in a real application. We
also used two Korean speech recognizers: a speech rec-
ognizer made by LG-Elite (LG Electronics Institute of
Technology) and a Korean commercial speech recog-
nizer, ByVoice (refer to http://www.voicetech.co.kr). For
4In corrected sentence, note that word ?A? is not recovered
because this word is meaningless functional word.
Figure 6: Example of Semantic-oriented Error Correction
our semantic-oriented error correction, we constructed a
domain knowledge for our target domain. We constructed
3,195 entries of domain dictionary, 13,154 entries of on-
tology dictionary, and 436 semantic templates generated
automatically using domain dictionary and ontology dic-
tionary.
We implemented both word-based and syllable-based
model for comparison, and combined the system of
syllable-based lexical correction with the LSP-based se-
mantic error correction. For experiments, we use trigrams
language model generated by SRILM toolkit (Stolcke,
2002), and a training program for channel model made
by ourselves. And, we divided the 462 queries into 6 dif-
ferent sets, and evaluated the results of 6-fold cross vali-
dation for each model.
5.2 Results
To measure error correction performance, we use word
error rate (WER) and term error rate (TER):
WER = |Sw| + |Iw| + |Dw||Wtruth|
(10)
TER = |St| + |It| + |Dt||Ttruth|
(11)
|Wtruth| is the number of original words, and |Ttruth|
is the number of query term (or keyword) in original
words, that is, an error rate of content words directly re-
lated to the performance of IR and QA system (Fujii et
al., 2002A).
Table 2, 3 present the experiments results of WER of
baseline ASR, word-based channel model, our syllable-
based channel model and combined syllable-based chan-
nel model with the LSP semantic correction model. The
performances of baseline systems were about 79% ?
81% on the utterances in in-vehicle telematics IR domain.
This result shows that the semantic error correction of
Test set 1 2 3 4 5 6 AVG.
Baseline 18.1% 21.6% 19.4% 22.8% 19.9% 19.2% 20.17%
Word-based 12.8% 20.3% 15.5% 17.5% 16.7% 17.7% 16.75%
Syllable-based 10.6% 16.0% 11.5% 16.1% 14.0% 10.6% 13.13%
Syllable + LSP 9.7% 14.9% 10.4% 15.3% 13.0% 10.7% 12.33%
Table 2: Result of LG-Elite Recognizer
Test set 1 2 3 4 5 6 AVG.
Baseline 20.5% 18.8% 19.8% 17.0% 16.9% 17.8% 18.47%
Word-based 19.9% 14.8% 18.4% 16.2% 15.3% 15.1% 16.75%
Syllable-based 16.7% 13.8% 17.0% 13.3% 12.7% 12.2% 14.28%
Syllable + LSP 15.3% 13.4% 15.8% 12.9% 11.3% 11.8% 13.42%
Table 3: Result of ByVoice
speech recognition result is a viable approach to improve
the performance.
Using both baseline ASR systems, we achieved 39%
and 27% of error reduction rate. In comparison with the
previous word-based model, our new approaches have
more accurate error correction performance in this do-
main. Table 4 shows the result of the experiments for
TER. The result of TER shows that baseline ASR systems
alone are not appropriate to process the user?s queries in
speech-driven IR, QA or dialog understanding system.
However, with a post error correction, the error reduc-
tion rate of TER is much higher than that of WER. And
we achieved better performance than word-based model.
With this result, our methods are considered to be more
appropriate in speech-driven IR and QA applications.
Compared with the word-based noisy channel model that
has been the best approach in the error correction so far,
our semantic-oriented error correction suggests alterna-
tive more successful methods for speech recognition error
correction.
Baseline Word-
based
Syllable-
based
Syllable
+ LSP
LG-Elite 56.4 % 31.5% 30.1% 26.7%
ByVoice 64.1% 34.1% 32.8% 27.6%
Table 4: Result of Term Error Rate
6 Conclusion and Future Works
We proposed an improved syllable-based noisy channel
model and combined higher level linguistic knowledge
for semantic-oriented approach in a speech recognition
error correction, which shows a superior performance in
domain-specific IR applications.
The previous works only focused on inter-word level
error correction, commonly depending on a large amount
of training corpus for the error correction model and the
language model. So, previous approaches require enor-
mous results of ASR and are dependent on specific speak-
ers and environments. On the other hand, our method
takes in far smaller training corpus, and it is possible to
implement the method easily and in a short time to ob-
tain the better error correction rate because it utilizes the
semantic information of the application domain.
And our semantic-oriented approach has more advan-
tages over lexical based ones, since it is less sensitive to
each error pattern. Also, the approach has a broader cov-
erage of error patterns, since several similar common er-
ror strings in the semantic ground can be reduced to one
semantic error pattern, which enables us to improve the
probability of recovering from erroneous recognition re-
sults.
And, because the LSP scheme transforms pure lexical
entries into abstract semantic categories, the size of the
error pattern database can be reduced remarkably, and
it also increases the coverage and robustness compared
with the previous pure lexical entries that can only deal
with the morphological variants.
With all these facts, the LSP correction has a high
possibility of generating semantically correct correction
due to the massive use of semantic contexts. Hence, it
shows a high performance, especially when combined
with domain-specific speech-driven natural language IR
and QA systems.
Future work should include the end-performance ex-
periments with IR or QA application for our error correc-
tion model.
7 Acknowledgements
This work was partly supported by Jungki KeoJeom
Project (MOCIE, ITEP), and by 21C Frontier Project
(MOST).
References
James F. Allen, Bradford W. Miller, Eric K. Ringger, and
Teresa Sikorski. 1996. A Robust System for Natural
Spoken Dialogue. In Proceedings of the 34th Annual
Meeting of the ACL
Juhui An, Seungwoo Lee, and Gary Geunbae Lee. 2003.
Automatic acquisition of Named Entity tagged corpus
from World Wide Web. In Proceedings of the 41st an-
nual meeting of the ACL (poster presentation).
J. Barnett, S. Anderson, J. Broglio, M. Singh, R. Hud-
son, and S.W. Kuo. 1997. Experiments in spoken
queries for documents retrieval. In Proceedings of Eu-
rospeech, (3):1323-1326.
Eric Brill and Robert C. Moore. 2000. An Improved
Error Model for Noisy Channel Spelling Correction.
ACL2000, 286-293.
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P.
S. Roossin. 1990. A Statistical Approach to Machine
Translation. Computational Linguistics, 16(2):79-85
Ciprian Chelba. 1997. A Structured Language Model. In
Proceedings of the Thirty-Fifth Annual Meeting of the
ACL and Eighth Conference of the European Chapter
of the ACL, 498-503.
F. Crestani. 2000. Word recognition errors and relevance
feedback in spoken query processing In Proceedings
of the 2000 Flexible Query Answering Systems Confer-
ence, 267-281.
Atsushi Fujii, Katunobu Itou, and Tetsuya Ishikawa.
2002A. Speech-driven Text Retrieval: Using Target
IR Collections for Statistical Language Model Adapta-
tion in Speech Recognition. Anni R. Coden and Eric
W. Brown and Savitha Srinivasan (Eds.) Information
Retrieval Techniques for Speech Application (LNCS
2273), 94-104.
Atsushi Fujii, Katunobu Itou, and Tetsuya Ishikawa.
2002B. A method for open-vocabulary speech-driven
text retrieval. In Proceedings of the 2002 conference
on Empirical Methods in Natural Language Process-
ing, 188-195.
Sanda Harabagiu, Dan Moldovan, and Joe Picone. 2002.
Open-Domain Voice-Activated Question Answering.
COLING2002, (1):321-327, Taipei.
Hanmin Jung, Gary Geunbae Lee, Wonseug Choi,
KyungKoo Min, and Jungyun Seo. 2003. Multi-
lingual question answering with high portability on re-
lational databases. IEICE transactions on information
and systems, E-86D(2):306-315.
Satoshi Kaki, Eiichiro Sumita, and Hitoshi Iida. 1998.
A Method for Correcting Speech Recognition Using
the Statistical features of Character Co-occurrence.
COLING-ACL?98, 653-657.
Haksoo Kim, Kyungsun Kim, Gary Geunbae Lee, and
Jungyun Seo. 2001. MAYA: A Fast Question-
Answering System Based on a Predictive Answer In-
dexer. In Proceedings of the 39th Annual Meet-
ing of the Association for Computational Linguistics
(ACL?01), Workshop on Open-Domain Question An-
swering
K. Kukich. 1992. Techniques for automatically cor-
recting words in text. ACM Computing Surveys,
24(4):377-439.
Geunbae Lee, Jungyun Seo, Seungwoo Lee, Hanmin
Jung, Bong-Hyun Cho, Changki Lee, Byung-Kwan
Kwak, Jeongwon Cha, Dongseok Kim, JooHui An,
Harksoo Kim, and Kyungsun Kim. 2001. SiteQ: Engi-
neering High Performance QA System Using Lexico-
Semantic Pattern Matching and Shallow NLP. In Pro-
ceedings of the 10th Text Retrieval Conference (TREC-
10), Washington D.C.
Gary Geunbae Lee, Jeongwon Cha, and Jong-Hyeok
Lee. 2002. Syllable pattern-based unknown mor-
pheme segmentation and estimation for hybrid part-of-
speech tagging of Korean. Computational Linguistics,
28(1):53-70.
Mitchell P. Marcus and Beatrice Santorini and Mary Ann
Marcinkiewicz. 1994. Building a Large Annotated
Corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313-330.
Eric K. Ringger and James F. Allen. 1996. A fertility
model for post correction of continuous speech recog-
nition ICSLP?96, 897-900.
Andreas Stolcke 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings of Intl. Conf.
on Spoken Language Processing, (2):901-904, Denver,
Co. (http://www.speech.sri.com/projects/srilm/)
Robert A. Wagner and Michae J. Fischer. 1974. The
String-to-String Correction Problem. Journal of the
ACM, 21(1):168-173.
I. Witten and T. Bell. 1991. The Zero-Frequency Prob-
lem: Estimating the Probabilities of Novel Events in
Adaptive Text Compression. In IEEE Transactions on
Information Theory, 37(4).
