Coling 2010: Poster Volume, pages 1068?1076,
Beijing, August 2010
Argument Optionality in the LinGO Grammar Matrix
Safiyyah Saleem
University of Washington
ssaleem@u.washington.edu
Emily M. Bender
University of Washington
ebender@u.washington.edu
Abstract
We present a library of implemented
HPSG analyses for argument optional-
ity based on typological studies of this
phenomenon in the world?s languages,
developed in the context of a grammar
customization system that pairs a cross-
linguistic core grammar with extensions
for non-universal phenomena on the ba-
sis of user input of typological proper-
ties. Our analyses are compatible with
multiple intersecting phenomena, includ-
ing person, number, gender, tense, aspect
and morphological rule formulation. We
achieve 80-100% coverage on test suites
from 10 natural languages.
1 Introduction
The LinGO Grammar Matrix customization sys-
tem (Bender et al, 2002; 2010) is a web-based
tool that creates starter grammars based on users?
input to a questionnaire. The system comprises a
core grammar covering linguistic phenomena that
are posited to be universal (e.g. semantic compo-
sitionality) and a set of libraries providing anal-
yses for phenomena that vary across languages
(e.g. case). These resources are developed in the
context of HPSG (Pollard and Sag, 1994), Mini-
mal Recursion Semantics (Copestake et al, 2005),
and the LKB grammar development environment
(Copestake, 2002).
Previous to the work reported here, the Gram-
mar Matrix customization system did not handle
argument optionality?the possibility of leaving
arguments unexpressed in lieu of overt pronouns.
This phenomenon, also called pro-drop, argument
drop, or null instantiation, is extremely common:
according to Dryer (2008), 79% of the 674 lan-
guages sampled cannot or do not normally use in-
dependent pronouns in subject position. Accord-
ingly, adding it to the customization system im-
proves the system?s ability to handle a large class
of core sentences in many languages.
For example, in Modern Standard Arabic [arb]
(Semitic), overt pronominal subjects are dropped
in non-emphatic contexts. Previously, the system
was able to model only the longer variant of (1).
(1) (hiyya)
(3.FEM.SG)
naama-t
sleep.PAST-3.FEM.SG
She slept. [arb]
Furthermore, there was no way to adequately ac-
count for languages such as Hausa [hau] (Chadic)
which do not allow overt simple pronominal sub-
jects and prohibit overt objects after certain verb
forms. The grammar would predict the opposite
grammaticality for the examples in (2).
(2) (*n??)
(*1.SG)
na?-san
1.SG.COMP-know
amsa?
answer
I know the answer. [hau]
It might seem that these facts could be han-
dled by adding a rule that allows arguments to
be dropped if an appropriate option is checked in
the customization system. However, the data from
Arabic and Hausa suggest that such an approach
would be insufficient, as languages place different
constraints on the contexts in which overt argu-
ments are required or prohibited.
In ?2 we discuss the broad range of typological
variation in argument optionality in the world?s
languages. In ?3 we offer a set of HPSG analy-
ses for these patterns. ?4 explains how these anal-
yses were incorporated into the Grammar Matrix
1068
customization system and integrated with the ex-
isting libraries. We then present the results of a
three-tiered evaluation of the implemented system
in ?5. The results demonstrate that the system is
capable of accurately modeling the attested syn-
tactic argument optionality patterns exhibited by
a typologically diverse group of languages as well
as the currently unattested but logically possible
co-occurrence restrictions on affixes and overt ar-
guments. To our knowledge, this is the first such
system. The paper closes with a brief look at how
the library could be extended even further to cap-
ture the range of semantic distinctions.
2 Typological Patterns
The typological literature shows that argument
optionality is extremely common: Dryer (2008)
found that of 674 geographically and genetically
diverse languages, only 141 normally or obli-
gatorily used independent pronominal subjects.
Dryer distinguishes 4 categories in the remaining
533 languages, corresponding to how information
about the person, number, and gender (PNG) of
the subject is encoded: affixation on the verb, cl-
itics on variable hosts, no encoding, or a mixed
strategy. In addition, there are other dimensions
in which languages vary, e.g., constraints on con-
texts in which dropping is done (see (1)?(2)).
Although we were unable to find a similar com-
prehensive survey of unexpressed objects, there
is evidence to suggest that it too may be very
widespread. In particular, lexically-licensed ob-
ject dropping seems to be very common. Even En-
glish, which has a very strong preference for overt
subjects, can be analyzed as licensing lexically-
based object dropping (Fillmore, 1986). As with
subject dropping, we also found a number of dif-
ferent co-occurrence restrictions on the presence
of verbal affixes and overt objects. Some lan-
guages always encode the PNG of an object on the
verb, others optionally do so if an overt object is
present and obligatorily do so if one is not, while
still others do not encode this information at all.
Drawing on work by Dryer and others, Table 1
summarizes the 6 major dimensions along which
the rules licensing argument dropping differ. The
first constraint is syntactic context. Most lan-
guages that license argument dropping do so re-
gardless of tense/aspect, mood, or person. Finnish
[fin] and Hebrew [heb] are two notable exceptions
(Vainikka and Levy, 1999).
The second constraint, lexically-based licens-
ing, is most commonly found in object dropping.
For example, while English usually prohibits ar-
gument dropping, it arguably licenses it with
verbs such as ?found out?, ?agree?, and ?promise?
(Fillmore, 1986). Lexically-based subject drop
is found in Tamil [tam], which generally licenses
subject dropping aside from some weather related
verbs (Asher, 1985).
The third constraint, noun phrase type, captures
the difference between a language such as Hausa
which generally prohibits independent pronouns
from appearing as subjects and other languages,
which allow pronouns in subject position (possi-
bly with emphatic interpretations).
The fourth constraint concerns the position of
PNG markers. Of the languages with subject PNG
markers and subject dropping, many encode sub-
ject PNG as a verbal affix. This pattern is ex-
hibited by such geographically and genetically di-
verse languages as Spanish [spa], Arabic [arb],
West Greenlandic [kal], Tamil [tam], and Nkore-
Kiga [nyn]. Other languages such as Chemehuevi
[ute], Polish [pol], and Warlpiri [wbp] make use
of a clitic which can attach to different types of
hosts (Dryer, 2008).
The final two constraints concern co-
occurrence restrictions between PNG markers
and overt objects. In some Bantu languages such
as Nkore-Kiga, a verbal affix is not used unless
the object precedes the verb or is pronominal.
Object markers are not used when a full NP
follows the verb (Taylor, 1985). In written French
[fra], verbal affixes1 are required if an object is
dropped and not permitted if it is overt. In Arabic,
for most transitive verbs, an object marker is
required if an object is dropped and is optional
if it is present. Hausa exhibits a more complex
pattern: for tenses in which the verbal affix
denoting PNG is morphologically separable from
the tense marker, the PNG affix is optional if an
overt noun phrase is present and required if it is
not (Newman, 2000).
1See (Miller and Sag, 1997) for convincing arguments
that so-called ?clitics? in French are actually affixes.
1069
Constraint (GF) Possible Values
Syntactic context (SUBJ) { All, select } tenses/aspects/moods/persons
Lexically-based (SUBJ, OBJ) { All, select } verbs
Noun phrase type (SUBJ, OBJ) Independent pronouns { allowed, prohibited }
Placement of PNG marker (SUBJ) { Verb, variable host }
PNG marking w/ dropped argument (OBJ) { Required, optional, not permitted }
PNG marking w/ overt argument (OBJ) { Required, optional, not permitted }
Table 1: Typological variation in licensing argument dropping
Noting these differences led us to posit that
when an argument is dropped, there are three pos-
sibilities. A verbal affix can be: not permitted,
optional, or required. The same three possibilities
exist for overt objects as well. Combining what
happens when an argument is dropped with what
happens when it is present, gives us nine logically
possible co-occurrence patterns.
Our review of the typological literature has
shown that languages place different constraints
on argument dropping. These constraints can
be lexical, syntactic, or related to affixation and
affix/overt-argument co-occurrence restrictions.
3 Analysis
This section presents HPSG analyses modeling
the six dimensions of variation described in ?2.
HPSG models natural language by positing lex-
ical entries, lexical rules, and phrase structure
rules, all described in terms of feature struc-
tures. A central idea, inspired by earlier work
in Categorial Grammar (Ajdukiewicz, 1935; Bar-
Hillel, 1953), is the notion of valence features.
These list-valued features (including SUBJ and
COMPS) contain information about the dependents
required by a head. The valence lists are projected
up the tree within the domain of each head, but
shortened as the dependents are realized. A sen-
tence is thus a verbal projection with empty SUBJ
and COMPS lists.
In this context, argument dropping is the short-
ening of a valence list without the overt realiza-
tion of the argument. Formally, this can be ac-
complished in at least three different ways: (1) In
the mapping of arguments from the ARG-ST (ar-
gument structure) feature to the valence lists, one
or more arguments can be suppressed, (2) lexical
rules can operate on the valence lists, shortening
them, or (3) unary (non-branching) phrase struc-
ture rules can cancel off valence elements. In this
work, we take the third approach, as we find it
affords us the most flexibility to deal with varia-
tions across languages in constraints on argument
optionality, while promoting similarity of analy-
ses across languages.
We control the applicability of the unary-
branching rules with the boolean feature OPT,
marked on elements of valence lists.2 For lan-
guages which allow subject/object dropping, we
instantiate new phrase structure rules: head-opt-
subj-phrase and/or head-opt-comp-phrase. These
rules allow the head verb to satisfy a valence re-
quirement without combining with another ex-
pression. To undergo these rules, the head daugh-
ter (the verb) must specify that the argument that
is to be dropped is compatible with [OPT +]. This
is sufficient to account for many languages. How-
ever, to ensure that languages which have lexical,
syntactic context, and affix co-occurrence restric-
tions do not overgenerate, further additions to the
grammar are necessary.
For lexical and affix-co-occurrence restrictions,
we prevent overgeneration by manipulating the
OPT feature. In languages which only license
argument dropping for certain lexical items, we
force those verbs which do not allow argument
dropping to have arguments that are constrained
to be [OPT ?]. This prevents them from under-
going the subject/object dropping rules. Verbs
are then classified into four different types based
on whether or not they allow subject and/or ob-
ject dropping. Individual lexical items instantiate
these types. For those verbs which do not allow
a particular argument to be dropped, the only way
to satisfy the valence requirement is to combine
with an overt argument.
2This feature was provided by the core Matrix but was not
previously used in the customization system. To our knowl-
edge it is not commonly used within HPSG analyses aside
from in grammars that were derived from the Matrix.
1070
Dropped/Overt Argument Affix Overt Arg Rule No-Marker-Rule Marker-Rule Transitive Verb Lex
required/required underspecified none underspecified needs lex rule
optional/optional underspecified none underspecified underspecified
not permitted/not permitted underspecified none none underspecified
required/optional OPT ? OPT ? underspecified needs lex rule
optional/not permitted OPT ? none OPT + underspecified
not permitted/required OPT ? OPT + OPT ? needs lex rule
required/not permitted OPT ? OPT ? OPT + needs lex rule
optional/required OPT ? OPT + underspecified needs lex rule
not permitted/optional OPT ? none OPT ? underspecified
Table 2: Constraints associated with logically possible affix co-occurrence
Languages with complex affix co-occurrence
restrictions are modeled by manipulating the OPT
feature in a different way: Constraints are placed
on lexical and phrase structure rules, as well as
on lexical types. In particular, we constrain the
rules which combine verbs with overt arguments
to check that that argument position is compati-
ble with [OPT ?]. This allows the lexical rules
attaching the affixes to constrain the optionality
of the corresponding argument position. In some
of the nine logical possibilities, enforcing these
constraints requires sending the verb through ?no-
marker? lexical rules so that constraints associ-
ated with markerless verbs can be enforced. Ta-
ble 2 summarizes the constraints on the OPT fea-
ture on lexical and phrase structure rules, as well
as the constraints on lexical types. The first col-
umn of this table lists the nine logically possible
combinations described in ?2. For example, the
row labeled ?required/required? gives the analysis
for a language like West Greenlandic, which al-
lows object dropping and always requires an ob-
ject marker on the verb regardless of whether or
not an overt object is present. In such a language,
neither the lexical rules nor the overt-complement
phrase structure rule constrain OPT, but the tran-
sitive verb lex type is required to undergo some
object marking lexical rule.
For licensing that is based on syntactic context
(subject dropping only) such as the Finnish and
Hebrew examples presented in ?2, we place con-
straints on the daughter of the unary subject drop
rule which restrict its application to the right con-
texts. For example, to account for the argument
optionality pattern present in Finnish, we con-
strain the head-opt-subj-phrase rule to require that
the item on the head daughter?s SUBJ list be spec-
?
?
head-opt-subj
subj ? ?
obj ? ?
?
?
?
?
head-comp
subj ? NP[3sg.m] ?
obj ? ?
?
?
?
?
no-marker-lex-rule
subj ? NP[3sg.m] ?
obj ? NP[OPT ?] ?
?
?
?
?
3sgm-subj-lex-rule
subj ? NP[3sg.m] ?
obj ? NP ?
?
?
?
?
trans-verb-lex
subj ? NP ?
obj ? NP ?
?
?
ishtaraa
acc-lex-rule
noun-lex
kitaab-an
Figure 1: Parse structure for (3)
ified as non-third-person ([PER non-third]). Verbs
not meeting this constraint are only allowed to
empty their SUBJ lists by combining with an overt
subject via the standard, binary head-subj-phrase
rule. We have not seen a language which licenses
subject dropping in syntactic contexts which do
not form a natural class according to our feature
system. However, our analysis easily lends it-
self to modeling this type of pattern if it exists by
creating multiple different subtypes of the subject
drop rule.
We close this section by illustrating our analysis
with an example from Arabic. The sentence in (3)
involves subject drop and an overt object. Since
the object is overt, the verb bears only marking of
subject PNG. The grammar that our system gener-
ates for Arabic assigns (3) the structure sketched
in Figure 1.
(3) ishtaraa
3ms.buy.past
kitaab-an
book-acc
He bought a book
1071
4 Customized Grammar Creation
Before the addition of the argument optionality
library, the phenomena covered in the Grammar
Matrix customization system included word order,
person, number, gender, case, tense/aspect, coor-
dination, matrix yes-no questions, and sentential
negation. The user is also allowed to specify lex-
ical items and the morphological rules associated
with each of them. Each of the phenomena corre-
spond to a page of the questionnaire.
As the user answers questions, the choices are
saved in a ?choices? file. The questionnaire is dy-
namic and the answers contained in the ?choices?
file affect the types of features that the user is
able to choose from on subsequent pages. For
example, if the user describes the language as
having 1st, 2nd, and 3rd persons on the Person
page, then on the lexicon page, the user can cre-
ate separate noun types for each person. Once
the ?choices? file contains responses to required
sections, the user is able to create the customized
starter grammar by clicking on the ?create gram-
mar? button. This invokes the customization script
which uses the responses contained in the file to
create a grammar that is compatible with the LKB
grammar development environment.
Our implementation entailed additions to two
major components of the system: the web-based
questionnaire and the customization script. To de-
termine which, if any, of the analyses presented
in ?3 should be included in the customized gram-
mar, we needed to elicit the type of argument op-
tionality pattern the language exhibited. Thus, we
added an Argument Optionality page to the ques-
tionnaire. The page is divided into two sections?
one for subject dropping and one for object drop-
ping. In the section on subject dropping, the user
is asked whether subject dropping exists and if
so, whether it is context-dependent. For context-
dependent subject dropping, the user is allowed
to specify the syntactic contexts in which subject
dropping is licensed by choosing from a multi-
select list of features. There is the option to create
multiple contexts. The features that appear in the
list are drawn from those that the user chose on
previous pages in the questionnaire. The user is
also directed to select whether subject dropping
is lexically-based, whether affixes are required,
optional or not permitted with overt arguments
and whether affixes are required, optional or not
permitted with dropped arguments. The ques-
tions presented in the object dropping section are
identical to those in the subject dropping section
with the exception that there is no question about
context-dependent object dropping.
Since some of the constraints must be placed on
individual lexical items and morphological rules,
the page also includes instructions to the user on
additional steps that need to be taken when com-
pleting the Lexicon page. For example, when de-
scribing a language where affixes are optional if
an argument is dropped and not permitted if an
overt argument is present, users are instructed to
select ?overt-arg-not-permitted? for those affixes
on the Lexicon page.
The changes to the customization script in-
cluded adding each of the analyses described in
?3 along with a mechanism for determining which
of the analyses should be included in the gram-
mar depending on the choices related to argu-
ment optionality, lexical items, and morphological
rules contained in the ?choices? file. The result-
ing customized grammars include the rules and
constraints necessary to allow and prohibit strings
that do not contain overt arguments based upon
the facts of a particular language as described by
the user in the questionnaire.
5 Evaluation
The evaluation was conducted in a three stage pro-
cess. Each stage involves constructing a set of test
suites containing grammatical and ungrammatical
strings representing the argument optionality pat-
tern of a set of languages, generating grammars
for the languages by answering the Grammar Ma-
trix questionnaire, using the grammars to parse the
sentences in the test suite, and hand-verifying the
results. The three stages differed in the nature of
the languages, the method by which the languages
were selected, and the breadth of the customized
grammars. The test suites are small, as they are
specifically targeted at the phenomenon of argu-
ment optionality, but representative in the sense
that they cover the space of relevant contrasts in
each language.
1072
5.1 Set 1: Pseudo-Languages
In the first stage, we tested the analyses presented
in ?3 by creating and then using the Grammar Ma-
trix customization system to generate grammars
for 38 pseudo-languages (sets of strings with as-
sociated grammaticality assignments) which col-
lectively exhaustively exhibit each of the lexical,
syntactic context or affix co-occurrence restric-
tion patterns described in Table 1 (?2). All of
the possible values identified for these given pat-
terns are present in at least one language, as well
as cross-classifications of different dimensions of
constraints where appropriate. For example, there
are pseudo-languages which share the property
of always requiring object markers but differ in
that one has lexically licensed object dropping and
the other general object dropping. These pseudo-
languages test the argument optionality analyses
in isolation in that argument optionality is not con-
strained by other phenomena such as word order.
The customized grammars were able to accu-
rately parse grammatical strings and rule out un-
grammatical ones. Coverage on this set of 38
pseudo-languages was 100% with 0% overgener-
ation and no spurious ambiguity, thus validating
the functioning of our analyses across the known
typological space.
5.2 Set 2: Illustrative Languages
Next, we tested the system?s performance in mod-
eling part of a natural language. For this stage
we deliberately chose several languages which ex-
emplified interesting licensing and co-occurrence
restriction patterns, including some which were
considered during the development of the system.
Each test suite included examples of grammatical
and ungrammatical strings that were constructed
based on the descriptions of the language given
in the following sources: Suleiman 1990 (Ara-
bic), Sulkala and Merja 1992 (Finnish), Newman
2000 (Hausa), and Asher 1985 (Tamil). As the
test suites were designed to evaluate argument op-
tionality, we restricted the test items to this phe-
nomenon only. Other syntactic phenomena were
only included if they affected the argument op-
tionality pattern in the language. For example,
gender distinctions were considered only for lan-
guages in which this was relevant to affix mark-
ing. A brief description of the argument optional-
ity patterns found in these languages follows.
Arabic [arb] (Semitic) Pronominal subjects
and objects are generally dropped. Subject affixes
are always required whether or not an overt noun
phrases is present. Affixes marking object per-
son, number, and gender are required for strictly
transitive verbs when an overt noun phrase is not
present. Other transitive verbs appear to allow ob-
ject drop without the object affix.
Finnish [fin] (Uralic) First and second person
subjects are freely dropped and markers appear
on the verb whether or not an overt noun phrase
is present. Third person subjects are not allowed
to be dropped with a referential interpretation;
however, third person pronouns are obligatorily
dropped for what Sulkala and Merja (1992) de-
scribe as a generic impersonal meaning. This de-
scription fits into what some linguists refer to as
the fourth person?a non-referential impersonal
syntactic/semantic distinction that is often real-
ized in English as the impersonal pronoun one.
Since Finnish shows evidence of further syntac-
tic distinctions between generic and referential
use of the third person marker, we have analyzed
this marker as actually corresponding to two ho-
mophonous morphemes. One requires an overt
subject and the other requires a dropped subject.
There are no verbal affixes for PNG of the object.
Hausa [hau] (Chadic) Hausa generally re-
quires pronominal subjects to be dropped. Simple,
unmodified, uncoordinated independent pronouns
are ungrammatical in subject position. Subject
PNG is marked in a person aspect complex (PAC)
along with tense and aspect information. The
PAC precedes the lexical verb. When the PNG
marker is morphologically segmentable from the
tense/aspect, the PNG marker can be omitted if an
overt noun phrase is present and is required if the
noun phrase is not present. PNG is not marked for
objects; however the verb form changes depend-
ing on whether a full noun phrase, pronoun, or no
object immediately follows the verb.
Tamil [tam] (Dravidian) Subjects and objects
can be freely dropped aside from a special class
of weather verbs requiring overt subjects. Subject
1073
PNG markers are always required whether a sub-
ject is overt or not. PNG is not marked for objects.
Lg. Items Gram- Ungram- Coverage/
matical matical Over-
generation (%)
Arabic 13 10 3 90/0
Finnish 11 9 3 100/0
Hausa 20 8 12 100/0
Tamil 7 5 2 100/0
Table 3: Illustrative Languages Results
As shown in Table 3 we achieved 100% cov-
erage over every test suite in this set except for
Arabic. In addition, there was no overgeneration
or spurious ambiguity. One Arabic item did not
parse because the current implementation of our
analyses does not elegantly account for obligatory
object marking (with object drop) on some tran-
sitive verbs and optional object marking on oth-
ers. We could have customized a grammar that
included another, parallel set of lexical rules that
would account for this item. Improvements to this
aspect of the argument optionality library depend
on upgrades to the morphotactic system.
5.3 Set 3: Held-out Languages
Finally, we tested a set of ?held out? languages
not considered during development and chosen for
their geographic and genetic diversity without re-
gard for argument dropping patterns. We had pre-
viously created the non-argument optionality por-
tions of these test suites and choices files to test
the coverage of other libraries in the customiza-
tion system and thus they include a wider variety
of linguistic phenomena than Sets 1 or 2. As be-
fore, the construction and grammaticality judge-
ments of the strings were based on descriptive
grammars: Chirikba 2003 (Abkhaz), Press 1979
(Chemehuevi), Smirnova 1982 and Newman 2000
(Hausa), Pensalfini 2003 (Jingulu), Asher and
Kumari 1997 (Malayalam), Taylor 1985 (Nkore-
Kiga), and Fortescue 2003 (W. Greenlandic).
Due to space constraints, we provide only a
summary of the argument optionality patterns in
these languages (Table 4). All the languages li-
censed both subject and object dropping and in
two of the six, dropping pronominal arguments
was strongly preferred. Three languages have
word order constraints on how argument option-
ality is realized: Abkhaz restricts the appearance
of one of the third person affixes depending on
verb-object order. Nkore-Kiga requires and pro-
hibits the appearance of an object marker depend-
ing on where the overt object occurs. Chemehuevi
requires that the clitic which is used to mark the
subject appear in second position. It is also the
only language that has lexical constraints on ob-
ject dropping. Malayalam was the only language
which did not mark person, number, and gender
information for the subject.
The customized grammars were able to account
for the majority of the patterns demonstrated in
these languages (Table 5). We achieved 100%
coverage on four languages with zero (Jingulu,
Malayalam, West Greenlandic) or moderate (Abk-
haz) overgeneration. The main source of errors
found in the results is the handling of word or-
der constraints: The grammars were unable to li-
cense (Chemehuevi) or restrict (Nkore-Kiga and
Abkhaz) argument optionality based on the verb?s
and argument?s positions in the sentence. Once
the Grammar Matrix word order library has been
improved and is able to account for second po-
sition clitics and fine-grained head-complement
word order constraints, it will be a simple pro-
cess to add the new feature(s) to existing lexical
rules to account for these patterns. Incorporating
the new functionality will not require any major
changes to the argument optionality library aside
from modifying the questionnaire to elicit the new
information from the user.
Language Items Gram- Un- Coverage/
mat- gram- Overgen-
ical matical eration (%)
Abkhaz 10 6 4 100/10
Chemehuevi 8 6 2 83.3/0
Jingulu 9 6 3 100/0
Malayalam 4 4 0 100/0
Nkore-Kiga 10 4 6 100/83.3
W. Greenlandic 5 3 2 100/0
Table 5: Held-out Language Results
In addition, we verified that the addition of ar-
gument optionality didn?t reduce coverage on any
other portion of these testsuites. This indicates
that the new argument optionality library is inter-
acting properly with existing libraries. Additional
interactions will be tested as we add new libraries
to the customization system.
1074
Object Dropping Subject Dropping Word Order Constraints Lexical Constraints
Abkhaz opt opt yes none
Chemehuevi opt opt yes yes
Jingulu opt opt none none
Malayalam opt opt no none
Nkore-Kiga pref pref yes none
W. Greenlandic pref pref none none
Table 4: Existence of and constraints on argument optionality in six languages
6 Related Work
Subject dropping has been studied extensively
within theoretical linguistics under many differ-
ent frameworks (Rizzi, 1986; Bresnan, 2001;
Ackema et al, 2006; Ginzburg and Sag, 2000).
Within the context of HPSG, our analysis is simi-
lar to the one in the Grammar Matrix-derived Por-
tuguese grammar (Branco and Costa, 2008) and to
Mu?ller?s (2009) treatment of subject dropping in
Maltese. These analyses differ from Ginzburg and
Sag?s (2000) HPSG analysis which uses language
specific variations on the Argument Realization
Principle to control whether the subject/object is
placed onto the COMPS and/or SUBJ lists.
Language specific analyses have been imple-
mented in deep, broad-coverage grammars for
languages such as Japanese (Masuichi et al
(2003), Siegel and Bender (2002)) and Portuguese
(Branco and Costa (2008)). Within the ParGram
project (Butt et al, 2002), Kim et al (2003) were
able to directly port the argument optionality re-
lated rules from a Japanese grammar to Korean.
However, to our knowledge, no one has imple-
mented an analysis that has been applied to a large
number of typologically, geographically, and ge-
netically diverse languages.
7 Conclusion
Our current work has focused on modeling the
variation in syntactic constraints on the licens-
ing and restriction of argument dropping. To our
knowledge, this is the first analysis of argument
optionality that combines typological breadth
with precision analyses that have been imple-
mented and tested on a number of geographically
and genetically diverse languages. Although we
have tried to account for the patterns found in the
typological literature, there may be variants that
we are unaware of. We hope to learn of more pat-
terns as the Grammar Matrix customization sys-
tem is applied to an ever wider set languages.
While the current work focuses on syntactic
variation, we intend to expand the argument op-
tionality library to include semantic distinctions
as well. A likely starting point would be the pro-
posal given by Bender and Goss-Grubbs (2008)
who present a way to model the discourse status
(Prince, 1981) of an NP taking into account the
differences between definite and indefinite null in-
stantiation described by Fillmore (1986). In addi-
tion, ongoing work to improve the word order li-
brary may eventually allow us to more accurately
model word-order based constraints.
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant No.
0644097. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the National Science Foundation.
References
Ackema, Peter, Patrick Brandt, Maaike Schoorlemmer,
and Fred Weerman, editors. 2006. Arguments and
Agreement. Oxford University Press, Oxford.
Ajdukiewicz, Kazimierz. 1935. Die syntaktische kon-
nexita?t. Studia Philosophica, 1:1?27.
Asher, R.E. and T.C. Kumari. 1997. Malayalam.
Routledge, NY.
Asher, R.E. 1985. Tamil. Croom Helm, London.
Bar-Hillel, Yehoshua. 1953. A quasi-arithmetical no-
tation for syntactic description. Language, 29:47?
58.
Bender, Emily M. and David Goss-Grubbs. 2008. Se-
mantic representations of syntactically marked dis-
course status in crosslinguistic perspective. In Proc.
2008 Conference on Semantics in Text Processing,
pages 17?29.
1075
Bender, Emily M., Dan Flickinger, and Stephan
Oepen. 2002. The grammar matrix: An open-
source starter-kit for the rapid development of cross-
linguistically consistent broad-coverage precision
grammars. In Proc. Workshop on Grammar Engi-
neering and Evaluation at COLING 2002, pages 8?
14.
Bender, Emily M., Scott Drellishak, Antske Fokkens,
Michael Wayne Goodman, Daniel P. Mills, Laurie
Poulson, and Safiyyah Saleem. 2010. Grammar
prototyping and testing with the LinGO Grammar
Matrix customization system. In Proc. ACL 2010
Software Demonstrations.
Branco, Anto?nio and Francisco Costa. 2008. A com-
putational grammar for deep linguistic processing of
Portuguese: LXGram, version a.4.1. Technical re-
port, University of Lisbon, Dept. of Informatics.
Bresnan, Joan. 2001. Lexical Functional Syntax.
Blackwell, Boston.
Butt, Miriam, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
parallel grammar project. In Proc. Workshop on
Grammar Engineering and Evaluation at COLING
2002, pages 1?7.
Chirikba, Viachesiav. 2003. Abkhaz. LINCOM, Mu-
nich.
Copestake, Ann, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal recursion semantics:
An introduction. Research on Language & Compu-
tation, 3(4):281?332.
Copestake, Ann. 2002. Implementing Typed Feature
Structure Grammars. CSLI, Stanford.
Dryer, Matthew. 2008. Expression of proniminal
subjects. In Haspelmath, Martin, Matthew Dryer,
David Gil, and Bernard Comrie, editors, The World
Atlas of Language Structures Online, chapter 101.
Max Planck Digital Library.
Fillmore, Charles. 1986. Pragmatically controlled
zero anaphora. In Proc. 12th annual meeting of the
Berkeley Linguistics Society, pages 95?107.
Fortescue, Michael. 2003. West Greenlandic. Croom
Helm, London.
Ginzburg, Johnathan and Ivan Sag. 2000. Interroga-
tive Investigations. CSLI, Stanford.
Kim, Roger, Mary Dalrymple, Ronald M. Kaplan,
Tracy Holloway King, Hiroshi Masuichi, and
Tomoko Ohkuma. 2003. Multilingual grammar de-
velopment via grammar porting. In ESSLLI 2003
Workshop on Ideas and Strategies for Multilingual
Grammar Development, pages 49?56.
Masuichi, Hiroshi, Tomoko Ohkuma, Hiroki
Yoshimura, and Yasunari Harada. 2003. Japanese
parser on the basis of the lexical-functional gram-
mar formalism and its evaluation. In Dong Hong Ji,
Kim Teng Lua, editor, Proc. PACLIC17, pages
298?309.
Miller, Philip H. and Ivan A. Sag. 1997. French clitic
movement without clitics or movement. Natural
Language & Linguistic Theory, 15(3):573?639.
Mu?ller, Stefan. 2009. Towards an HPSG analysis of
Maltese. In et al Bernard Comrie, editor, Introduc-
ing Maltese linguistics. Papers from the 1st Inter-
national Conference on Maltese Linguistics, pages
83?112. Benjamins, Amsterdam.
Newman, Paul. 2000. The Hausa Language: An ency-
clopedic reference grammar. Yale University Press,
New Haven.
Pensalfini, Rob. 2003. A Grammar of Jingulu: An
Aboriginal language of the Northern Territory. Pa-
cific Linguistics, Canberra.
Pollard, Carl and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago, IL.
Press, Margaret. 1979. Chemehuevi: A grammar and
lexicon. University of California Press, Berkeley.
Prince, Ellen. 1981. Toward a taxonomy of given-new
information. In Cole, P., editor, Radical Pragmat-
ics, pages 223?255. Academic Press, NY.
Rizzi, Luigi. 1986. Null objects in Italian and the the-
ory of pro. Linguistic Inquiry, 17(3):501?557.
Siegel, Melanie and Emily M. Bender. 2002. Ef-
ficient deep processing of Japanese. In Proc. 3rd
Workshop on Asian Language Resources and Inter-
national Standardization at COLING 2002.
Smirnova, Mirra A. 1982. The Hausa Language: A
Descriptive Grammar. Routledge, Boston.
Suleiman, Saleh M. 1990. The semantic functions of
object deletion in classical arabic. Language Sci-
ences, 12(2-3):255 ? 266.
Sulkala, Helena and Karjalaninen Merja. 1992.
Finnish. Routledge, NY.
Taylor, Charles. 1985. Nkore-Kiga. Croom Helm,
London.
Vainikka, Anne and Yonata Levy. 1999. Empty sub-
jects in Finnish and Hebrew. Natural Language and
Linguistic Theory, 17:613?671.
1076
Proceedings of the ACL 2010 System Demonstrations, pages 1?6,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Grammar Prototyping and Testing with the
LinGO Grammar Matrix Customization System
Emily M. Bender, Scott Drellishak, Antske Fokkens, Michael Wayne Goodman,
Daniel P. Mills, Laurie Poulson, and Safiyyah Saleem
University of Washington, Seattle, Washington, USA
{ebender,sfd,goodmami,dpmills,lpoulson,ssaleem}@uw.edu,
afokkens@coli.uni-saarland.de
Abstract
This demonstration presents the LinGO
Grammar Matrix grammar customization
system: a repository of distilled linguis-
tic knowledge and a web-based service
which elicits a typological description of
a language from the user and yields a cus-
tomized grammar fragment ready for sus-
tained development into a broad-coverage
grammar. We describe the implementation
of this repository with an emphasis on how
the information is made available to users,
including in-browser testing capabilities.
1 Introduction
This demonstration presents the LinGO Gram-
mar Matrix grammar customization system1 and
its functionality for rapidly prototyping grammars.
The LinGO Grammar Matrix project (Bender et
al., 2002) is situated within the DELPH-IN2 col-
laboration and is both a repository of reusable
linguistic knowledge and a method of delivering
this knowledge to a user in the form of an ex-
tensible precision implemented grammar. The
stored knowledge includes both a cross-linguistic
core grammar and a series of ?libraries? contain-
ing analyses of cross-linguistically variable phe-
nomena. The core grammar handles basic phrase
types, semantic compositionality, and general in-
frastructure such as the feature geometry, while
the current set of libraries includes analyses of
word order, person/number/gender, tense/aspect,
case, coordination, pro-drop, sentential negation,
yes/no questions, and direct-inverse marking, as
well as facilities for defining classes (types) of lex-
ical entries and lexical rules which apply to those
types. The grammars produced are compatible
with both the grammar development tools and the
1
http://www.delph-in.net/matrix/customize/
2
http://www.delph-in.net
grammar-based applications produced by DELPH-
IN. The grammar framework used is Head-driven
Phrase Structure Grammar (HPSG) (Pollard and
Sag, 1994) and the grammars map bidirectionally
between surface strings and semantic representa-
tions in the format of Minimal Recursion Seman-
tics (Copestake et al, 2005).
The Grammar Matrix project has three goals?
one engineering and two scientific. The engineer-
ing goal is to reduce the cost of creating gram-
mars by distilling the solutions developed in exist-
ing DELPH-IN grammars and making them easily
available for new projects. The first scientific goal
is to support grammar engineering for linguistic
hypothesis testing, allowing users to quickly cus-
tomize a basic grammar and use it as a medium in
which to develop and test analyses of more inter-
esting phenomena.3 The second scientific goal is
to use computational methods to combine the re-
sults of typological research and formal syntactic
analysis into a single resource that achieves both
typological breadth (handling the known range of
realizations of the phenomena analyzed) and ana-
lytical depth (producing analyses which work to-
gether to map surface strings to semantic represen-
tations) (Drellishak, 2009).
2 System Overview
Grammar customization with the LinGO Gram-
mar Matrix consists of three primary activities:
filling out the questionnaire, preliminary testing of
the grammar fragment, and grammar creation.
2.1 Questionnaire
Most of the linguistic phenomena supported by the
questionnaire vary across languages along multi-
ple dimensions. It is not enough, for example,
3Research of this type based on the Grammar Matrix
includes (Crysmann, 2009) (tone change in Hausa) and
(Fokkens et al, 2009) (Turkish suspended affixation).
1
simply to know that the target language has coor-
dination. It is also necessary to know, among other
things, what types of phrases can be coordinated,
how those phrases are marked, and what patterns
of marking appear in the language. Supporting a
linguistic phenomenon, therefore, requires elicit-
ing the answers to such questions from the user.
The customization system elicits these answers us-
ing a detailed, web-based, typological question-
naire, then interprets the answers without human
intervention and produces a grammar in the format
expected by the LKB (Copestake, 2002), namely
TDL (type description language).
The questionnaire is designed for linguists who
want to create computational grammars of natu-
ral languages, and therefore it freely uses techni-
cal linguistic terminology, but avoids, when possi-
ble, mentioning the internals of the grammar that
will be produced, although a user who intends to
extend the grammar will need to become familiar
with HPSG and TDL before doing so.
The questionnaire is presented to the user as a
series of connected web pages. The first page the
user sees (the ?main page?) contains some intro-
ductory text and hyperlinks to direct the user to
other sections of the questionnaire (?subpages?).
Each subpage contains a set of related questions
that (with some exceptions) covers the range of
a single Matrix library. The actual questions in
the questionnaire are represented by HTML form
fields, including: text fields, check boxes, ra-
dio buttons, drop-downs, and multi-select drop-
downs. The values of these form fields are stored
in a ?choices file?, which is the object passed on
to the grammar customization stage.
2.1.1 Unbounded Content
Early versions of the customization system (Ben-
der and Flickinger, 2005; Drellishak and Bender,
2005) only allowed a finite (and small) number
of entries for things like lexical types. For in-
stance, users were required to provide exactly one
transitive verb type and one intransitive verb type.
The current system has an iterator mechanism in
the questionnaire that allows for repeated sections,
and thus unlimited entries. These repeated sec-
tions can also be nested, which allows for much
more richly structured information.
The utility of the iterator mechanism is most
apparent when filling out the Lexicon subpage.
Users can create an arbitrary number of lexical
rule ?slots?, each with an arbitrary number of
morphemes which each in turn bear any num-
ber of feature constraints. For example, the
user could create a tense-agreement morpholog-
ical slot, which contains multiple portmanteau
morphemes each expressing some combination of
tense, subject person and subject number values
(e.g., French -ez expresses 2nd person plural sub-
ject agreement together with present tense).
The ability provided by the iterators to create
unbounded content facilitates the creation of sub-
stantial grammars through the customization sys-
tem. Furthermore, the system allows users to ex-
pand on some iterators while leaving others un-
specified, thus modeling complex rule interactions
even when it cannot cover features provided by
these rules. A user can correctly model the mor-
photactic framework of the language using ?skele-
tal? lexical rules?those that specify morphemes?
forms and their co-occurrence restrictions, but per-
haps not their morphosyntactic features. The user
can then, post-customization, augment these rules
with the missing information.
2.1.2 Dynamic Content
In earlier versions of the customization system, the
questionnaire was static. Not only was the num-
ber of form fields static, but the questions were
the same, regardless of user input. The current
questionnaire is more dynamic. When the user
loads the customization system?s main page or
subpages, appropriate HTML is created on the fly
on the basis of the information already collected
from the user as well as language-independent in-
formation provided by the system.
The questionnaire has two kinds of dynamic
content: expandable lists for unbounded entry
fields, and the population of drop-down selec-
tors. The lists in an iterated section can be ex-
panded or shortened with ?Add? and ?Delete? but-
tons near the items in question. Drop-down selec-
tors can be automatically populated in several dif-
ferent ways.4 These dynamic drop-downs greatly
lessen the amount of information the user must
remember while filling out the questionnaire and
can prevent the user from trying to enter an invalid
value. Both of these operations occur without re-
freshing the page, saving time for the user.
4These include: the names of currently-defined features,
the currently-defined values of a feature, or the values of vari-
ables that match a particular regular expression.
2
2.2 Validation
It makes no sense to attempt to create a consis-
tent grammar from an empty questionnaire, an in-
complete questionnaire, or a questionnaire con-
taining contradictory answers, so the customiza-
tion system first sends a user?s answers through
?form validation?. This component places a set
of arbitrarily complex constraints on the answers
provided. The system insists, for example, that
the user not state the language contains no deter-
miners but then provide one in the Lexicon sub-
page. When a question fails form validation, it
is marked with a red asterisk in the questionnaire,
and if the user hovers the mouse cursor over the as-
terisk, a pop-up message appears describing how
form validation failed. The validation component
can also produce warnings (marked with red ques-
tion marks) in cases where the system can gen-
erate a grammar from the user?s answers, but we
have reason to believe the grammar won?t behave
as expected. This occurs, for example, when there
are no verbal lexical entries provided, yielding a
grammar that cannot parse any sentences.
2.3 Creating a Grammar
After the questionnaire has passed validation, the
system enables two more buttons on the main
page: ?Test by Generation? and ?Create Gram-
mar?. ?Test by Generation? allows the user to test
the performance of the current state of the gram-
mar without leaving the browser, and is described
in ?3. ?Create Grammar? causes the customiza-
tion system to output an LKB-compatible grammar
that includes all the types in the core Matrix, along
with the types from each library, tailored appropri-
ately, according to the specific answers provided
for the language described in the questionnaire.
2.4 Summary
This section has briefly presented the structure
of the customization system. While we antici-
pate some future improvements (e.g., visualiza-
tion tools to assist with designing type hierarchies
and morphotactic dependencies), we believe that
this system is sufficiently general to support the
addition of analyses of many different linguistic
phenomena. The system has been used to create
starter grammars for more than 40 languages in the
context of a graduate grammar engineering course.
To give sense of the size of the grammars
produced by the customization system, Table 1
compares the English Resource Grammar (ERG)
(Flickinger, 2000), a broad-coverage precision
grammar in the same framework under develop-
ment since 1994, to 11 grammars produced with
the customization system by graduate students in
a grammar engineering class at the University of
Washington. The students developed these gram-
mars over three weeks using reference materials
and the customization system. We compare the
grammars in terms of the number types they de-
fine, as well as the number of lexical rule and
phrase structure rule instances.5 We separate
types defined in the Matrix core grammar from
language-specific types defined by the customiza-
tion system. Not all of the Matrix-provided types
are used in the definition of the language-specific
rules, but they are nonetheless an important part of
the grammar, serving as the foundation for further
hand-development. The Matrix core grammar in-
cludes a larger number of types whose function is
to provide disjunctions of parts of speech. These
are given in Table 1, as ?head types?. The final col-
umn in the table gives the number of ?choices? or
specifications that the users gave to the customiza-
tion system in order to derive these grammars.
3 Test-by-generation
The purpose of the test-by-generation feature is to
provide a quick method for testing the grammar
compiled from a choices file. It accomplishes this
by generating sentences the grammar deems gram-
matical. This is useful to the user in two main
ways: it quickly shows whether any ungrammat-
ical sentences are being licensed by the grammar
and, by providing an exhaustive list of licensed
sentences for an input template, allows users to see
if an expected sentence is not being produced.
It is worth emphasizing that this feature of the
customization system relies on the bidirectional-
ity of the grammars; that is, the fact that the same
grammar can be used for both parsing and genera-
tion. Our experience has shown that grammar de-
velopers quickly find generation provides a more
stringent test than parsing, especially for the abil-
ity of a grammar to model ungrammaticality.
3.1 Underspecified MRS
Testing by generation takes advantage of the gen-
eration algorithm include in the LKB (Carroll et al,
5Serious lexicon development is taken as a separate task
and thus lexicon size is not included in the table.
3
Language Family Lg-specific types Matrix types Head types Lex rules Phrasal rules Choices
ERG Germanic 3654 N/A N/A 71 226 N/A
Breton Celtic 220 413 510 57 49 1692
Cherokee Iroquoian 182 413 510 95 27 985
French Romance 137 413 510 29 22 740
Jamamad?? Arauan 188 413 510 87 11 1151
Lushootseed Salish 95 413 510 20 8 391
Nishnaabemwin Algonquian 289 413 510 124 50 1754
Pashto Iranian 234 413 510 86 19 1839
Pali Indo-Aryan 237 413 510 92 55 1310
Russian Slavic 190 413 510 56 35 993
Shona Bantu 136 413 510 51 9 591
Vietnamese Austro-Asiatic 105 413 510 2 26 362
Average 182.9 413 510 63.5 28.3 1073.5
Table 1: Grammar sizes in comparison to ERG
1999). This algorithm takes input in the form of
Minimal Recursion Semantics (MRS) (Copestake
et al, 2005): a bag of elementary predications,
each bearing features encoding a predicate string,
a label, and one or more argument positions that
can be filled with variables or with labels of other
elementary predications.6 Each variable can fur-
ther bear features encoding ?variable properties?
such as tense, aspect, mood, sentential force, per-
son, number or gender.
In order to test our starter grammars by gen-
eration, therefore, we must provide input MRSs.
The shared core grammar ensures that all of
the grammars produce and interpret valid MRSs,
but there are still language-specific properties in
these semantic representations. Most notably, the
predicate strings are user-defined (and language-
specific), as are the variable properties. In addi-
tion, some coarser-grained typological properties
(such as the presence or absence of determiners)
lead to differences in the semantic representations.
Therefore, we cannot simply store a set of MRSs
from one grammar to use as input to the generator.
Instead, we take a set of stored template MRSs
and generalize them by removing all variable
properties (allowing the generator to explore all
possible values), leaving only the predicate strings
and links between the elementary predications.
We then replace the stored predicate strings with
ones selected from among those provided by the
user. Figure 1a shows an MRS produced by a
grammar fragment for English. Figure 1b shows
the MRS with the variable properties removed
and the predicate strings replaced with generic
place-holders. One such template is needed for
every sentence type (e.g., intransitive, transitive,
6This latter type of argument encodes scopal dependen-
cies. We abstract away here from the MRS approach to scope
underspecification which is nonetheless critical for its com-
putational tractability.
a. ? h1,e2, {h7: cat n rel(x4:SG:THIRD),
h3:exist q rel(x4, h5, h6),
h1: sleep v rel(e2:PRES, x4)},
{h5 qeq h7} ?
b. ? h1,e2, {h7:#NOUN1#(x4),
h3:#DET1#(x4, h5, h6),
h1:#VERB#(e2, x4)},
{h5 qeq h7} ?
Figure 1: Original and underspecified MRS
negated-intransitive, etc.). In order to ensure that
the generated strings are maximally informative to
the user testing a grammar, we take advantage of
the lexical type system. Because words in lexical
types as defined by the customization system dif-
fer only in orthography and predicate string, and
not in syntactic behavior, we need only consider
one word of each type. This allows us to focus the
range of variation produced by the generator on
(a) the differences between lexical types and (b)
the variable properties.
3.2 Test by generation process
The first step of the test-by-generation process is
to compile the choices file into a grammar. Next,
a copy of the LKB is initialized on the web server
that is hosting the Matrix system, and the newly-
created grammar is loaded into this LKB session.
We then construct the underspecified MRSs in
order to generate from them. To do this, the pro-
cess needs to find the proper predicates to use for
verbs, nouns, determiners, and any other parts of
speech that a given MRS template may require. For
nouns and determiners, the choices file is searched
for the predicate for one noun of each lexical noun
type, all of the determiner predicates, and whether
or not each noun type needs a determiner or not.
For verbs, the process is more complicated, re-
quiring valence information as well as predicate
strings in order to select the correct MRS template.
In order to get this information, the process tra-
verses the type hierarchy above the verbal lexical
4
types until it finds a type that gives valence infor-
mation about the verb. Once the process has all
of this information, it matches verbs to MRS tem-
plates and fills in appropriate predicates.
The test-by-generation process then sends these
constructed MRSs to the LKB process and displays
the generation results, along with a brief explana-
tion of the input semantics that gave rise to them,
in HTML for the user.7
4 Related Work
As stated above, the engineering goal of the Gram-
mar Matrix is to facilitate the rapid development
of large-scale precision grammars. The starter
grammars output by the customization system are
compatible in format and semantic representations
with existing DELPH-IN tools, including software
for grammar development and for applications in-
cluding machine translation (Oepen et al, 2007)
and robust textual entailment (Bergmair, 2008).
More broadly, the Grammar Matrix is situated
in the field of multilingual grammar engineer-
ing, or the practice of developing linguistically-
motivated grammars for multiple languages within
a consistent framework. Other projects in this
field include ParGram (Butt et al, 2002; King
et al, 2005) (LFG), the CoreGram project8 (e.g.,
(Mu?ller, 2009)) (HPSG), and the MetaGrammar
project (de la Clergerie, 2005) (TAG).
To our knowledge, however, there is only one
other system that elicits typological information
about a language and outputs an appropriately cus-
tomized implemented grammar. The system, de-
scribed in (Black, 2004) and (Black and Black,
2009), is called PAWS (Parser And Writer for
Syntax) and is available for download online.9
PAWS is being developed by SIL in the context
of both descriptive (prose) grammar writing and
?computer-assisted related language adaptation?,
the practice of writing a text in a target language
by starting with a translation of that text in a
related source language and mapping the words
from target to source. Accordingly, the output of
PAWS consists of both a prose descriptive grammar
7This set-up scales well to multiple users, as the user?s in-
teraction with the LKB is done once per customized grammar,
providing output for the user to peruse as his or her leisure.
The LKB process does not persist, but can be started again
by reinvoking test-by-generation, such as when the user has
updated the grammar definition.
8
http://hpsg.fu-berlin.de/Projects/core.html
9
http://www.sil.org/computing/catalog/show_
software.asp?id=85
and an implemented grammar. The latter is in the
format required by PC-PATR (McConnel, 1995),
and is used primarily to disambiguate morpholog-
ical analyses of lexical items in the input string.
Other systems that attempt to elicit linguistic in-
formation from a user include the Expedition (Mc-
Shane and Nirenburg, 2003) and Avenue projects
(Monson et al, 2008), which are specifically tar-
geted at developing machine translation for low-
density languages. These projects differ from the
Grammar Matrix customization system in elic-
iting information from native speakers (such as
paradigms or translations of specifically tailored
corpora), rather than linguists. Further, unlike the
Grammar Matrix customization system, they do
not produce resources meant to sustain further de-
velopment by a linguist.
5 Demonstration Plan
Our demonstration illustrates how the customiza-
tion system can be used to create starter gram-
mars and test them by invoking test-by-generation.
We first walk through the questionnaire to illus-
trate the functionality of libraries and the way that
the user interacts with the system to enter infor-
mation. Then, using a sample grammar for En-
glish, we demonstrate how test-by-generation can
expose both overgeneration (ungrammatical gen-
erated strings) and undergeneration (gaps in gen-
erated paradigms). Finally, we return to the ques-
tionnaire to address the bugs in the sample gram-
mar and retest to show the result.
6 Conclusion
This paper has presented an overview of the
LinGO Grammar Matrix Customization System,
highlighting the ways in which it provides ac-
cess to its repository of linguistic knowledge. The
current customization system covers a sufficiently
wide range of phenomena that the grammars it
produces are non-trivial. In addition, it is not al-
ways apparent to a user what the implications will
be of selecting various options in the question-
naire, nor how analyses of different phenomena
will interact. The test-by-generation methodology
allows users to interactively explore the conse-
quences of different linguistic analyses within the
platform. We anticipate that it will, as a result, en-
courage users to develop more complex grammars
within the customization system (before moving
on to hand-editing) and thereby gain more benefit.
5
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant No.
0644097. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the National Science Foundation.
References
Emily M. Bender and Dan Flickinger. 2005. Rapid
prototyping of scalable grammars: Towards modu-
larity in extensions to a language-independent core.
In Proc. of IJCNLP-05 (Posters/Demos).
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2002. The grammar matrix: An open-source starter-
kit for the rapid development of cross-linguistically
consistent broad-coverage precision grammars. In
Proc. of the Workshop on Grammar Engineering
and Evaluation at COLING 2002, pages 8?14.
Richard Bergmair. 2008. Monte Carlo semantics:
McPIET at RTE4. In Text Analysis Conference (TAC
2008) Workshop-RTE-4 Track. National Institute of
Standards and Technology, pages 17?19.
Cheryl A. Black and H. Andrew Black. 2009. PAWS:
Parser and writer for syntax: Drafting syntactic
grammars in the third wave. In SIL Forum for Lan-
guage Fieldwork, volume 2.
Cheryl A. Black. 2004. Parser and writer for syn-
tax. Paper presented at the International Confer-
ence on Translation with Computer-Assisted Tech-
nology: Changes in Research, Teaching, Evaluation,
and Practice, University of Rome ?La Sapienza?,
April 2004.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
parallel grammar project. In Proc. of the Workshop
on Grammar Engineering and Evaluation at COL-
ING 2002, pages 1?7.
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Poznan?ski. 1999. An efficient chart generator
for (semi-) lexicalist grammars. In Proc. of the 7th
European workshop on natural language generation
(EWNLG99), pages 86?95.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal recursion semantics:
An introduction. Research on Language & Compu-
tation, 3(4):281?332.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI, Stanford.
Berthold Crysmann. 2009. Autosegmental representa-
tions in an HPSG for Hausa. In Proc. of the Work-
shop on Grammar Engineering Across Frameworks
2009.
E?ric Villemonte de la Clergerie. 2005. From meta-
grammars to factorized TAG/TIG parsers. In Proc.
of IWPT?05, pages 190?191.
Scott Drellishak and Emily M. Bender. 2005. A co-
ordination module for a crosslinguistic grammar re-
source. In Stefan Mu?ller, editor, Proc. of HPSG
2005, pages 108?128, Stanford. CSLI.
Scott Drellishak. 2009. Widespread But Not Uni-
versal: Improving the Typological Coverage of the
Grammar Matrix. Ph.D. thesis, University of Wash-
ington.
Dan Flickinger. 2000. On building a more efficient
grammar by exploiting types. Natural Language
Engineering, 6:15 ? 28.
Antske Fokkens, Laurie Poulson, and Emily M. Ben-
der. 2009. Inflectional morphology in Turkish VP-
coordination. In Stefan Mu?ller, editor, Proc. of
HPSG 2009, pages 110?130, Stanford. CSLI.
Tracy Holloway King, Martin Forst, Jonas Kuhn, and
Miriam Butt. 2005. The feature space in parallel
grammar writing. Research on Language & Com-
putation, 3(2):139?163.
Stephen McConnel. 1995. PC-PATR Refer-
ence Manual. Summer Institute for Linguistics.
http://www.sil.org/pcpatr/manual/pcpatr.html.
Marjorie McShane and Sergei Nirenburg. 2003. Pa-
rameterizing and eliciting text elements across lan-
guages for use in natural language processing sys-
tems. Machine Translation, 18:129?165.
Christian Monson, Ariadna Font Llitjs, Vamshi Am-
bati, Lori Levin, Alon Lavie, Alison Alvarez,
Roberto Aranovich, Jaime Carbonell, Robert Fred-
erking, Erik Peterson, and Katharina Probst. 2008.
Linguistic structure and bilingual informants help
induce machine translation of lesser-resourced lan-
guages. In LREC?08.
Stefan Mu?ller. 2009. Towards an HPSG analysis of
Maltese. In Bernard Comrie, Ray Fabri, Beth Hume,
Manwel Mifsud, Thomas Stolz, and Martine Van-
hove, editors, Introducing Maltese linguistics. Pa-
pers from the 1st International Conference on Mal-
tese Linguistics, pages 83?112. Benjamins, Amster-
dam.
Stephan Oepen, Erik Velldal, Jan Tore Lnning, Paul
Meurer, Victoria Rosn, and Dan Flickinger. 2007.
Towards hybrid quality-oriented machine transla-
tion. On linguistics and probabilities in MT. In
11th International Conference on Theoretical and
Methodological Issues in Machine Translation.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago, IL.
6
