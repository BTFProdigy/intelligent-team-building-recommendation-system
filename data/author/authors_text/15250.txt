Coling 2008: Companion volume ? Posters and Demonstrations, pages 149?152
Manchester, August 2008
A Grammar Checking System for Punjabi 
Mandeep Singh Gill 
Department of Computer Science 
Punjabi University 
Patiala ? 147002, India 
msgill_in@yahoo.com 
Gurpreet Singh Lehal 
Department of Computer Science 
Punjabi University 
Patiala ? 147002, India 
gslehal@yahoo.com 
 
 Abstract 
This article provides description about the 
grammar checking system developed for 
detecting various grammatical errors in 
Punjabi texts. This system utilizes a full-
form lexicon for morphological analysis, 
and applies rule-based approaches for 
part-of-speech tagging and phrase 
chunking. The system follows a novel 
approach of performing agreement 
checks at phrase and clause levels using 
the grammatical information exhibited by 
POS tags in the form of feature value 
pairs. The system can detect and suggest 
rectifications for a number of 
grammatical errors, resulting from the 
lack of agreement, order of words in 
various phrases etc., in literary style 
Punjabi texts. To the best of our 
knowledge, this grammar checking 
system is the first such system reported 
for Indian languages. 
1 Introduction 
Grammar checking is one of the most widely 
used tools within natural language engineering 
applications. Most of the word processing 
systems available in the market incorporate 
spelling, grammar, and style-checking systems 
for English and other widely used languages. 
Naber (2003) discussed one such rule-based 
grammar checking system for English. However, 
when it comes to the smaller languages, 
specifically the Indian languages, most of such 
advanced tools have been lacking. Although, 
                                                        
? 2008. Licensed under the Creative Commons 
Attribution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
spell checking has been addressed for most of the 
Indian languages, still grammar and style 
checking systems are lacking. In this article, a 
grammar checking system for Punjabi has been 
provided. Punjabi is a member of the Modern 
Indo-Aryan family of languages. 
There is an n-gram based grammar checking 
system for Bangla (Alam et al, 2006). However, 
the authors admit that its accuracy is very low 
and there is no description about whether the 
system provides any suggestions to correct errors 
or not. However, the system that we discuss here 
for Punjabi detects errors and suggests 
corrections as well. While doing so, it provides 
enough information for the user to understand the 
error reason and the suggestions provided, if any. 
2 Purpose 
The purpose of the system is to find various 
grammatical mistakes in the formal texts written 
in Punjabi language. While detecting 
grammatical mistakes, the focus is on keeping the 
false alarms to minimum. For every detected 
error, system provides enough information for 
the user to understand why the error is being 
marked. It also provides suggestions, if possible, 
to rectify those errors. 
3 Potential Applications 
This system as a whole and its subsystems will 
find numerous applications in natural language 
processing of Punjabi. Following are some of the 
application areas of this system as a whole or its 
subsystems: 
? It can be used with various information 
processing systems for Punjabi, where the 
input needs to be corrected grammatically 
before processing.  
149
? Parts of this system like morphological 
analyzer, morphological generator, part-of-
speech tagger, phrase chunker etc., will 
find use in almost every natural language 
processing application like machine 
translation, text to speech synthesis, and 
search engines etc., for Punjabi.  
? This system as a whole can be used as a 
post editor for a number of applications for 
Punjabi like machine translation, optical 
character recognition etc., where the 
output needs to be corrected grammatically 
before providing the end results. 
? Second language learners of Punjabi can 
use this system as a writing aid to learn 
grammatical categories operating in 
Punjabi sentences, and thus improve their 
writings by learning from their mistakes. 
? In the word processing field, this system 
can be used for checking essays, formal 
reports, and letters written in Punjabi. 
4 System Design & Implementation 
The design of this grammar checking is provided 
below in figure 1. A sketchy idea of this 
proposed design is provided below in terms of 
how the input text is processed to find potential 
grammatical errors.  
For grammar checking, the input text is first 
given to a preprocessor, which breaks the input 
text into sentences and then into words. It also 
performs filtering, i.e. marks any phrases, fixed 
expressions etc. in the text. Then the tokenized 
text is passed on to a morphological analyzer, 
which uses a full form lexicon to assign each 
word its all possible part-of-speech (POS) 
information (i.e. POS tags). Then the text along 
with the POS tags moves on to a POS tagger, 
which attempts to disambiguate the information 
using hand-written disambiguation rules. Then 
this POS tagged text is passed on to a phrase 
chunker, which builds phrases using hand-written 
phrase chunking rules targeted at the POS tag 
information. Phrase chunker also marks clause 
boundaries and headwords in noun phrases and 
clauses. Then in the last stage, syntax/agreement 
checks are performed based on the grammatical 
information (exhibited by POS tags) at the phrase 
level and then at the clause level, using the 
marked headwords. Any discrepancy found is 
reported to the user along with the suggested 
corrections and detailed error information. 
All the sub activities of this grammar checking 
system are fully automated and have been 
designed exclusively from scratch as part of this 
work. No such sub system was available for 
Punjabi for our use. All the sub activities have 
been implemented in Microsoft Visual C# 2005 
and the databases are in XML format with 
Punjabi text in Unicode. 
 
 
Figure 1. Punjabi Grammar Checking System 
Design 
 
 For the purpose of morphological analysis, 
we have divided the Punjabi words into 22 word 
classes depending on the grammatical 
information required for the words of these word 
classes. The information that is in the database 
depends upon the word class, like for noun and 
inflected adjective, it is gender, number, and 
case. As mentioned earlier, all the word forms of 
the commonly used Punjabi words are kept in the 
lexicon along with their root and other 
grammatical information. 
 For part-of-speech tagging, we have devised 
a tag set keeping into mind all the grammatical 
categories that can be helpful for agreement 
checking. The tag set is very user friendly and 
while choosing tag names existing tag sets for 
English and other such languages were taken into 
consideration, like NNMSD ?  masculine, 
singular, and direct case noun, PNPMPOF ? 
Preprocessing 
Morphological Analysis 
Part-of-speech Tagging 
Phrase Chunking 
Error Checking  
Output text with suggestions 
Grammatically incorrect text 
150
masculine, plural, oblique case, and first person 
personal pronoun. The approach followed for 
part-of-speech tagging is rule-based, as there is 
no tagged corpus for Punjabi available at present. 
The part-of-speech tagging rules take into 
account the potential grammatical agreement 
errors. 
 For phrase chunking, again a rule-based 
approach was selected. The tag set that is being 
used for phrase chunking includes tags like NPD 
? noun phrase in direct case, NPNE ? noun 
phrase followed by ? ne etc. The rules for phrase 
chunking take into account the potential errors in 
the text, like lack of agreement in words of a 
potential phrase.  
 In the last phase i.e. error checking, there are 
manually designed error detection rules to detect 
potential errors in the text and provide 
corrections to resolve those errors. For example, 
rule to check modifier and noun agreement, will 
go through all the noun phrases in a sentence to 
check if the modifiers of those sentences agree 
with their respective headwords (noun/pronoun) 
in terms of gender, number, and case or not. For 
this matching, the grammatical information from 
the tags of modifiers and headwords is used. In 
simple terms, it will compare the grammatical 
information (gender, number, and case) of 
modifier with the headword (noun/pronoun) and 
displays an error message if some grammatical 
information fails to match. To resolve this error, 
the error checking module will use 
morphological generator to generate the correct 
form (based on headword?s gender, number, and 
case) for that modifier from its root word. 
For example, consider the grammatically 
incorrect sentence  	
   sohne larka 
janda hai ?handsome boy goes?. In this sentence, 
in the noun phrase  	
 sohne larka 
?handsome boy?, the modifier  sohne 
?handsome? (root word ?  sohna 
?handsome?), with masculine gender, plural 
number, and direct case, is not in accordance 
with the gender, number, and case of its 
headword 	
 larka ?boy?. It should be in 
singular number instead of plural. The grammar 
checking module will detect this as an error as 
?number? for modifier and headword is not same, 
then it will use morphological generator to 
generate the ?singular number form? from its root 
word, which is same as root form i.e.  sohna 
?handsome? (masculine gender, singular number, 
and direct case). So, the input sentence will be 
corrected as  	
   sohna larka janda 
hai ?handsome boy goes?. 
5 Sample Input and Output 
This section provides some sample Punjabi 
sentences that were given as input to the Punjabi 
grammar checking system along with the output 
generated by this system. Input/Output specify 
the input Punjabi sentence and the output 
produced by this grammar checking system 
respectively. 
 
Sentence 1 
This sentence shows the grammatical errors 
related to ?Modifier and noun agreement? and 
?Order of the modifiers of a noun in noun 
phrase?. In this sentence noun is 	
 larka ?boy? 
and its modifiers are     sohni ek 
bhajji janda ?handsome one running?. 
 
Input:     	
  
Input1: sohni ek bhajji janda larka aaeya 
Input2: Handsome one running boy came 
 
Output:     	
  
Output1: ek bhajjia janda sohna larka aaeya 
Output2: One running handsome boy came 
 
Sentence 2 
This sentence covers the grammatical error 
related to ?Subject and verb agreement?. Subject 
is  barish ?rain? and verb phrase is    
ho riha han ?is raining?.  
 
Input:      
Input1: bahr barish ho riha han 
Input2: It is raining outside 
 
Output:      
Output1: bahr barish ho rahi hai 
Output2: It is raining outside 
6 Testing & Evaluation 
The evaluation results for our morphological 
analyzer shows that it provides correct analysis 
for 87.64% words. This evaluation was 
performed on a corpus of 8 million Punjabi 
words. The part-of-speech tagger reports an 
accuracy of 80.29% when applied on a randomly 
selected corpus of 25,000 words. This accuracy 
improves to 88.86% if we exclude unknown 
151
words from evaluation results, the reason being 
the absence of an unknown word guesser in our 
part-of-speech tagger. The phrase chunker reports 
average precision of 81.18%, recall of 85.07%, 
and F-measure of 83.07%. These results include 
evaluation performed on 100 sentences for noun, 
adjective, and verb phrases. On randomly 
selected 1,000 sentences, this grammar checking 
system reports precision of 76.79%, recall of 
87.08%, and F-measure of 81.61%.  
The grammatical errors covered by this system 
includes ? modifier and noun agreement, 
subject/object and verb agreement, order of 
modifiers in a noun phrase, order of words in a 
verb phrase, use of contractions etc. In its present 
state, the system may generate some false alarms 
for complex and compound sentences. We will 
work to reduce these false alarms in the future.  
 
Comparison with existing systems 
Our system covers a different class of errors and 
results for grammar checking systems for 
English, Swedish etc. are reported for different 
error sets, with only some errors covered being 
common. Some of the systems that are to some 
extent close to our system in terms of errors 
covered are provided here for comparison. A 
grammar checker for German (Schmidt-Wigger, 
1998) using pattern matching rules reports 81% 
precision and 57%. A system for Korean (Young-
Soog, 1998) reports 99.05% precision and 
95.98% recall. Another system for German 
(Fliedner, 2002) reports precision and recall of 
67% for only noun phrase agreement. A grammar 
checker for Bangla (Alam et al, 2006) reports 
accuracy of 53.7% using manual POS tagging 
and 38% for automated POS tagging. When 
compared with these systems, 76.79% precision 
and 87.08% recall of our grammar checker seams 
reasonably good. 
7 Conclusions 
This article presented design and implementation 
details of the grammar checking system for 
Punjabi. This grammar checking system is 
capable of detecting various grammatical errors 
in formal Punjabi texts. To the best of our 
knowledge, this is the first such system for 
Punjabi and other Indian languages. We hope that 
this research work will attempt to narrow down 
the gap that exists between Punjabi and other 
natural languages in the natural language 
processing field. We are confident that this 
research work will motivate future researchers in 
developing various advanced resources for 
Punjabi. This article presented a novel approach 
for performing grammar checking using phrase 
and clause level information coupled with 
grammatical information (POS information) in 
the form of feature values. This approach can be 
applied for languages that lack advanced 
resources like full parser, and pattern-matching 
approaches are not competent enough to detect 
different agreement errors. 
The web-based version of this grammar 
checking is available for free use along with three 
other resources for the Punjabi language ? 
morphological analyzer, part-of-speech tagger, 
and phrase chunker. Morphological analyzer is 
also available as free download for non-
commercial use. 
References 
Alam, Md. Jahangir, Naushad UzZaman, and Mumit 
Khan. 2006. N-gram based Statistical Grammar 
Checker for Bangla and English. In Proc. of ninth 
International Conference on Computer and 
Information Technology (ICCIT 2006), Dhaka, 
Bangladesh. 
Chander, Duni. 1964. Punjabi Bhasha da Viakaran 
(Punjabi). Punjab University Publication Bureau, 
Chandigarh, India. 
Fliedner, Gerhard. 2002. A System for Checking NP 
Agreements in German Texts. In Proceedings of the 
ACL Student Research Workshop, pages 12-17, 
Philadelphia, US. 
Gill, Harjeet S. and Henry A. Gleason, Jr. 1986. A 
Reference Grammar of Punjabi. Publication 
Bureau, Punjabi University, Patiala, India. 
Naber, Daniel. 2003. A Rule-Based Style and 
Grammar Checker. Diplomarbeit Technische 
Fakult?t, Universit?t Bielefeld, Germany.  
Puar, Joginder S. 1990. The Punjabi verb form and 
function. Publication Bureau, Punjabi University, 
Patiala, India. 
Schmidt-Wigger, Anje. 1998. Grammar and Style 
Checking for German. In Proceedings of the Second 
International Workshop on Control Language 
Applications (CLAW-1998), pages 76-86, 
Pittsburgh, PA. 
Young-Soog, Chae. 1998. Improvement of Korean 
Proofreading System Using Corpus and Collocation 
Rules. In Proceedings of the 12th Pacific Asia 
Conference on Language, Information and 
Computation, pages 328-333, National University 
of Singapore, Singapore.  
152
Coling 2008: Companion volume ? Posters and Demonstrations, pages 157?160
Manchester, August 2008
A Punjabi To Hindi Machine Translation System 
Gurpreet Singh Josan 
Lecturer, Yadvindra College of 
Engineering, Talwandi Sabo Bathinda. 
josangurpreet@rediffmail.com
Gurpreet Singh Lehal 
Professor, Dept. of Comp. Sci., 
Punjabi University Patiala. 
gslehal@gmail.com 
 Abstract 
Punjabi and Hindi are two closely related 
languages as both originated from the 
same origin and having lot of syntactic 
and semantic similarities. These 
similarities make direct translation 
methodology an obvious choice for 
Punjabi-Hindi language pair. The 
purposed system for Punjabi to Hindi 
translation has been implemented with 
various research techniques based on 
Direct MT architecture and language 
corpus. The output is evaluated by 
already prescribed methods in order to 
get the suitability of the system for the 
Punjabi Hindi language pair. 
1. Introduction 
The Direct MT system is based upon exploitation 
of syntactic similarities between more or less 
related natural languages. Although its 
deficiencies soon became apparent, it remains 
popular in certain situations due to its usefulness, 
robustness and relative simplicity. One of such 
situation is machine translation of closely related 
languages. The general opinion is that it is easier 
to create an MT system for a pair of related 
languages (Hajic et.al. 2000). In the last decade, 
some of the systems utilizing this approach for 
translating between similar languages have 
confirmed this concept. In this paper, our attempt 
to use the same concept for language pair of 
Punjabi-Hindi is described.  
Punjabi and Hindi both are classified as 
Indo-Iranian languages. Although they are in the 
same family, but still they have lot of differences 
in order to make them not mutually intelligible. 
Punjabi and Hindi are not mutually intelligible in 
written form. As far as spoken form is 
                                                 
? 2008. Licensed under the Creative Commons 
Attribution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
concerned, Punjabi and Hindi are mutually 
intelligible to certain degree. This relation is 
further asymmetric with the speakers of Punjabi 
more able to understand Hindi but reverse is not 
true.   
1.1 Punjabi Language 
Punjabi is the official language of the Indian 
state of Punjab and also one of the official 
languages of Delhi. It is used in government, 
education, commerce, art, mass media and in 
every day communication. A good deal of Sikh 
religious literature is written in Punjabi language. 
According to SIL Ethnologue, Punjabi is the 
language of about 57 million people and ranked 
20th among the total languages of the world. It is 
written in Gurmukhy, Shahmukhy and roman 
scripts.  
1.2 Hindi Language 
Hindi on the other hand has been one of the two 
official languages of all of India. Hindi is a 
language of about 577 million peoples all over 
the world and is ranked as 5th most widely 
spoken language by SIL Ethnologue.  
2. The Need 
India being a large and multilingual society, and 
in the interest of the regional languages, the 
government of India has allowed to use regional 
languages as the official language of respective 
region and adopt bilingual form (Hindi/English) 
as the official language of Union Government. 
Most of the state governments work in their 
respective regional languages whereas the union 
government?s official documents and reports are 
in bilingual form (Hindi/English). In order to 
have a proper communication there is a need to 
translate these reports and documents in the 
respective regional languages and vice versa. 
Some other applications of Punjabi to Hindi MT 
system are Text Translation, Website 
Translation, Message Translation (Email), Cross 
Language Information Retrieval and Web 
Service. 
157
Existing system: Keeping in view the 
importance of MT system among Indian 
languages, an MT system called ?Anusaarka? has 
been developed at IIIT Hyderabad covering all 
the major Indian languages. It is a language 
accessor and produces an image of source 
language in target language. Output will have to 
be post-edited by a person, to make it 
grammatically correct, stylistically proper, etc. 
Moreover, some amount of training will be 
needed on the part of the reader to read and 
understand the output. Our system is more 
practical in nature than Anusaarka and it produce 
more grammatical and stylistic output. No 
training is needed on the part of reader. 
3. System description 
To start with, a direct translation system is 
created on windows platform, in which words 
from source language are chosen, their 
equivalents in target language are found out from 
the lexicon and are replaced to get target 
language. The source text is passed through 
various pre processing phase and out put is also 
passed through a post processing phase.  
3.1 Lexical Resources 
In this research work, we have developed and 
used various resources as follow: 
Root word Lexicon: It is a bilingual dictionary 
that contains Punjabi language word, its lexical 
category like whether it is noun, verb or adjective 
etc and corresponding Hindi word. It also 
contains the gender information in case of nouns 
and type information (i.e. transitive or 
intransitive) in case of verb. This dictionary 
contains about 33000 entries covering almost all 
the root words of Punjabi language.  
inflectional form lexicon: It contains all the 
inflectional forms, root word and corresponding 
Hindi word. Ambiguous words has the entry 
?amb? in the Hindi word field. It contains about 
90,000 entries. 
Ambiguous word lexicon: It contains about 
1000 entries covering all the ambiguous words 
with their most frequent meaning. 
Bigram Table: Used for resolving ambiguity, 
this table contains Punjabi bigrams along with 
Hindi meaning. Bigrams are created from a 
corpus of 7 million words. 
Trigram Table: Same as Bigram, but contain 
Punjabi trigrams used for resolving ambiguity. 
Created from 7 million words corpus. 
3.2 System Architecture  
The system architecture, as shown in figure 3.1, 
has the following stages through which the 
source text is passed.  
Text normalization 
There are number of ASCII based fonts to 
represent Punjabi text and each font has 
variations in assigning ASCII code to Punjabi 
Alphabets. This cause a problem while scanning 
a text. Therefore, the first step is to normalize the 
source text by converting it into Unicode format. 
It gives us three fold advantages; first it will 
reduce the text scanning complexity. Secondly it 
also helps in internationalizing the system as if 
the output is in Unicode format then it can be 
used in various applications in various ways. 
Thirdly, it eases the transliteration task. 
Tokenization 
The system is designed to do sentence level 
translation in order to have a track about the 
context of a word. Once the whole text is 
scanned, next step is to break up the data into 
sentences. Individual words or tokens are 
extracted out from the sentence and processed to 
find out its equivalent in the target language. 
Tokens are separated by using break characters 
like space, comma, question mark etc.  
Translation Engine 
The translation engine is responsible for 
translation of each token obtained from the 
previous step. It uses various lexical resources 
for finding the match of a given token in target 
language. It involves different modules like 
Named Entity Recognition, Repetitive construct 
handler, Word Mapping, Ambiguity Resolution, 
and Transliteration. 
The token obtained in the previous stage is 
passed through following stages: 
1. The token is checked for proper names of 
persons as they need to be transliterated.  
2. If token is not a proper name then it is 
checked for repetitive units like 
{ghar?? ghar}(home to home) by 
comparing the word and its root with next or 
previous words and their roots. A limited 
morph analysis is required for this step. The 
repetitive construct handling involves two 
stages. First, detection of repetitive construct 
and second, handling of such construct. 
Detection: For detection of repetitive 
construct, we check the next and previous 
word. If the next and previous words are 
same or the roots of next and previous words 
are same as that of current word, then we 
158
 
Figure 3.1 System Architecture 
mark it as a repetitive construct. The root of 
the words will be obtained from the database 
discussed earlier.  
Handling: If repetitive construct is found 
then the next step is to get the lexical 
information of the token. This information is 
again obtained from the database. The lexical 
information of token is used to trigger the 
handling process. If the token is noun then 
the token is replaced by its root and then 
passed to the next step.  E.g. in case of 
{ghar?? ghar}(home to home) we 
check the token and its root i.e.  with 
the next token which in this case is again . 
Thus, system marks it as repetitive 
constructs. Then the lexical category of  
is checked from the database which comes 
out to be noun. So we replace the  with 
its root  and pass the replaced token to the 
next step. 
3. Then the token is looked into the database 
for a match. The Database contains various 
types of tables. First of all token is checked 
in the root database and inflectional form 
database. It gives two types of output if 
match occurs. Either the corresponding Hindi 
word is produced or ?amb? is appeared 
which shows that word is ambiguous.  
4. For the ambiguous words, we call ?resolver? 
module that resolve the ambiguity with the 
help of n-gram language modeling. The 
system uses trigram table in the first place, 
which contains the two words in the vicinity 
of an ambiguous word and corresponding 
meaning for that particular context. If it fails 
to resolve the ambiguity then bigram table is 
searched. Bigram table is similar to trigram 
table except it contains only one word in the 
vicinity of ambiguous words. If both trigram 
and bigram fails to resolve then module will 
use most frequently used meaning.  
5. If token is not matched in inflectional form 
database, then word may be a foreign word 
i.e. word of other language like English. 
Such words and all those tokens, for which 
no entry is found in database, are 
transliterated. Transliteration is performed in 
three stages as follow: 
a. Direct Mapping 
b. Rule Based Improvement 
c. Soundex technique Based improvement. 
6. The system uses Direct mapping approach at 
first stage and then applies some rules to 
make the spellings of output similar to target 
language. In the third stage soundex 
technique is used to deal with the special 
cases like occurrence of half characters and 
other symbols not present in Punjabi. 
7. All these steps are repeated for all the 
sentences in the source text. 
Target Language Generation 
After converting all source text to target text, 
there are some discrepancies as discussed 
previously and need to be solved. For removing 
these discrepancies a rule base is used. This 
database gives the rules to make the text 
grammatically correct. 
4. Implementation 
The system is implemented in ASP.net at front 
end and MSAccess at back end. A class is 
created whose object will accept a string in 
Punjabi language and returns its corresponding 
Hindi string. Based on this class, various online 
applications are created. A web site is created 
with interface that enables a user to write his 
input sentence in Punjabi and system will 
produce the output in Hindi. Another application 
enables the user to translate a webpage in 
Punjabi to Hindi on the fly. The user has to 
Normalized Source 
Text 
Tokenization 
Named Entity Recognition 
Repetitive Construct Handling 
Lexicon Look up 
Ambiguity Resolution
Transliteration 
Hit? 
Ambiguous? 
Target language 
 generation 
Target Text
N
N
o
Y
Y
Root word & 
Inflectional 
Form DB 
Bigram & 
Trigram DB 
Ambiguous 
Word DB 
Append in Output and retrieve next token 
     If token 
      present 
Y
N
Pre Processing 
Translation 
 Engine 
Post 
Processing 
Rule 
Base 
159
mention the URL of webpage to be translated. In 
another application, an online interface for cross 
language information retrieval system has been 
created whereby a user can enter his key word in 
Punjabi. These keywords are translated in Hindi 
and result is posted to Google search engine. The 
user is presented with the results returned by 
Google from Hindi web pages. Another interface 
enables the users to write E-mail in Punjabi. This 
message is translated to Hindi and send to the 
target email address. The receiver get the mail in 
Hindi. For the developers who want to use this 
Punjabi To Hindi MT module, a web service is 
also created.  
5. Results 
5.1 Subjective test analysis 
The overall rating grade for Intelligibility of the 
translated text came out to be 2.76 on a 3 point 
scale. About 94% sentences are intelligible.  
The overall rating grade for fidelity of the 
translated text came out to be 2.72 on 3 point 
scale. Similarly, the accuracy percentage for the 
system is found out to be 90.67%. The accuracy 
score is comparable with other similar systems 
(Hajic J. et.al. 2000; Hric J. et.al. 2000; Homola 
et.al. 2005) as shown in table 5.1. 
MT SYSTEM Accuracy 
RUSLAN 40% correct 40% with 
minor errors. 20% with 
major error. 
CESILKO  
(Czech-to-Slovak) 
90% 
Czech-to-Polish 71.4% 
Czech-to-Lithuanian 87.6% 
Our System 90.67% 
Table 5.1 Comparative analysis of %age accuracy 
5.2 Error Analysis 
Word Error rate, which is the percentage of 
erroneous words from all words, is found out to 
be 2.34%. It is comparably lower than that of the 
general systems like Salt, Incyta, Internostrum, 
where it ranges from 3.0 to 4.9 (Tomas J. et.al., 
2003). The Sentence Error rate is found out to be 
24.26%.  
6. Conclusion 
The accuracy of the translation achieved by our 
system justifies the hypothesis that the simple 
word-for-word translation along with statistical 
and rule based approach provides a high 
accuracy and simple solution for language pair of 
Punjabi and Hindi especially when the objective 
is just to have a rough idea on the subject matter.  
References 
Altintas K., Cicekli I., "A Machine Translation 
System Between a Pair of Closely Related 
Languages", In Proceedings of ISCIS 2002, 
October 2002, Orlando, Florida. 
Anusaarka-overcoming the language barrier in India, 
http://www.iiit.net/ltrc/Publications/anuvad.html 
Bemova A., Oliva K. Panevova J.," Some Problems of 
Machine translation between closely related 
languages", In Proceedings of the 12th conference 
on Computational linguistics - Volume 1, 
Budapest, Hungry, 1988 pp 46 - 48  
HAJIC J, HRIC J, KUBON V., "CESILKO? an MT 
system for closely related languages", In ACL2000, 
Tutorial Abstracts and Demonstration Notes, pp. 7-
8. ACL, Washington. 
Hajic J., "Ruslan-An MT System between closely 
related languages", In Proceedings of the 3rd 
Conference of The European Chapter of the 
Association for Computational Linguistics, 
Copenhagen, Denmark, 1987, pp.113-117. 
HRIC J, HAJIC J, KUBON V., "Machine Translation 
of Very Close Languages", proceedings of the 6th 
Applied Natural Language Processing Conference, 
April 29--May 4, 2000, Seattle, Washington, USA. 
pp 7-12. 
Homola P., Kubon V., "A Machine Translationn 
System into a Minority Language?, In Proceddings 
of the Workshop on Modern Approaches in 
Translation Technologies 2005 - Borovets, 
Bulgaria, pp 31-35. 
Marote R. C, Guillen E., Alenda A.G., Savall M.I.G., 
Bellver A.I., Buendia S.M., Rozas S.O., Pina H.P., 
Anton P.M.P., Forcada M.L., ?The Spanish-
Catalan machine translation system 
interNOSTRM?, In proceedings of MT Summit 
VIII, 18-22 Sept. 2001, Santiago de Compostela, 
Galicia, Spain. 
Scannell K.P.,"Machine Translation for Closely 
Related language Pair", Proceedings of the 
Workshop on Strategies for developing machine 
translation for minority languages at LREC 2006, 
Genoa, Italy, May 2006, pp103-107. 
Slype V., 1979. "Critical Methods for Evaluating the 
Quality of Machine Translation," Prepared for the 
European Commission Directorate General 
Scientific and Technical Information and 
Information Management. Report BR-19142. 
Bureau Marcel van Dijk. 
160
Coling 2008: Companion volume ? Posters and Demonstrations, pages 177?180
Manchester, August 2008
Shahmukhi to Gurmukhi Transliteration System 
Tejinder Singh Saini 
ACTDPL, Punjabi University,  
Patiala 147 002, India 
tej@pbi.ac.in 
Gurpreet Singh Lehal 
DCS, Punjabi University, 
Patiala 147 002, India 
gslehal@yahoo.com
Virinder S Kalra 
Sociology, SOSS 
University of Manchester 
kalra@manchester.uk 
 
 
Abstract 
The existence of two scripts for Punjabi 
language has created a script barrier be-
tween the Punjabi literature written in In-
dia and Pakistan. This research has de-
veloped a new system for the first time of 
its kind for Shahmukhi text without dia-
critical marks. The purposed system for 
Shahmukhi to Gurmukhi transliteration 
has been implemented with various re-
search techniques based on language cor-
pus. The corpus analysis of both scripts is 
performed for generating statistical data 
of different types like character and word 
frequencies and bi-gram frequencies. 
This statistical analysis is used in differ-
ent phases of transliteration. Potentially, 
all members of the substantial Punjabi 
community will benefit vastly from this 
transliteration system. 
1 Introduction 
One of the great challenges before Information 
Technology is to overcome language barriers 
across the whole humanity so that everyone can 
communicate with everyone else on the planet in 
real time. South Asia is one of those unique parts 
of the world where a single language is written in 
different scripts. This is the case, for example, 
with Punjabi language, spoken by tens of mil-
lions of people, but written in Indian East Punjab 
(20 million) in Gurmukhi script (a Left to Right 
script based on Devanagari) and in Pakistani 
West Punjab (80 million), written in Shahmukhi 
script (a Right to Left script based on Arabic), 
and by growing number of Punjabis (2 million) 
in the EU and the US in the Roman script. Whilst 
in speech Punjabi spoken in the Eastern and the 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
Western parts is mutually comprehensible, in the 
written form it is not so. The existence of two 
scripts for Punjabi has created a script barrier 
between the Punjabi literature written in India 
and Pakistan. More than 60 per cent of Punjabi 
literature of medieval period (500-1450 AD) is 
available in Shahmukhi script only, while most 
of the modern Punjabi writings are in Gurmukhi. 
Potentially, all members of the substantial Pun-
jabi community will benefit vastly from this 
transliteration system. 
1.1 Gurmukhi Script 
The Gurmukhi script, derived from the Sharada 
script and standardised by Guru Angad Dev in 
the 16th century, was designed to write the Pun-
jabi language. The meaning of "Gurmukhi" is 
literally ?from the mouth of the Guru". The 
Gurmukhi script has forty one letters, including 
thirty eight consonants and three basic vowel 
sign bearers. There are five nasal consonants (?, 
?, ?, ?, ?) and two additional nasalization signs, 
bindi ?? [?] and tippi ?? [?]. In addition to this, 
there are nine dependent vowel signs (??[?], ?? 
[u], ??[o], ??[?], ??[?], ??[i], ??[e], ??[?], ??[?]) 
used to create ten independent vowels with three 
bearer characters: Ura ?[?], Aira ? [?] and Iri 
?[?]. 
1.2 Shahmukhi Script  
The meaning of "Shahmukhi" is literally 
?from the King's mouth". Shahmukhi is a local 
variant of the Urdu script used to record the Pun-
jabi language. It is based on right to left 
Nastalique style of the Persian and Arabic script. 
It has thirty seven simple consonants, eleven fre-
quently used aspirated consonants, four long 
vowels and three short vowel symbols (Malik 
2006). 
177
2 Comparison with the Existing System 
In actual practice, Shahmukhi script is written 
without short vowels and other diacritical marks. 
The PMT system discussed by Malik A. (2006) 
claims 98% accuracy only when the input text  
Input text (right to left) 
 ?? ?? ?? ???? ???? ???? ???????? ??? ?????? ??? ???
 ?????? ???? ???? ?? ???? ?? ??????? ????? ?????? ???????
 ??? ?? ??? ??? ????? ?????? ???? ???? ??? ??? ????
???? ??? ?? ???? ???? ??? ????? ?????   ???????? ??
 ???? ?? ?? ??? ??? ??? ???? ???? ?? ?? ????? ?? ??
 ??? ???? ???? ???? ???? ??????? ??? ??? ????? ??
????? ???? ????????? ????  ???? ??? ??????? ???? ????
 ?????? ?? ???? ???? ?? ??? ???? ???? ???? ????
? ???? ???? ?? ???? ???? ??? ?? ????? ??? ????? ?? ??
?? ???  ??????? ??? ?? ?? ??? ????? ?? ?????? ????
?? ???? ???? ????? ?????? ?? ????? ???? 
Output-A of PMT system (left to right) 
?? ?? ?? ??? ??? ??? ????????? ??  ???? ???? ?? ??????? 
???? ??? ?? ??? ?? ?????? ????? ????? ??????? ??? ?? 
??? ??? ????? ????? ? ???? ??? ??? ??  ???? ??? ?? 
???? ??? ??? ??? ???? ??? ???  ????? ???? ???? ?? ?? ?? ?? 
??? ???? ??? ? ??? ???? ?? ?? ?? ??? ???? ????? ???? 
?????? ??? ??? ????? ?? ???? ??? ??????? ????? ???? 
????, ???? ???????, ???? ????? ?? ???? ??? ? ?? ??? 
???? ???? ???? ???? ???? ?? ??? ???? ???? ?? ???? ???? 
??? ?? ????? ??? ?????? ??? ?? ?? ?? ????? ?? ?????? ??? ?
?? ??? ?? ???? ???? ???? ??????? ?? ???? ????? 
Output-B of proposed system (left to right) 
?? ??? ??? ??? ??? ????? ???????? ??? ????? ?? ???? ????????? 
???? ???? ?? ??? ??? ??????? ???? ?????? ?????? ??? 
?? ????? ??? ?????? ??????? ???? ??? ??? ??? ???? ??? ?? 
???? ???? ?? ??? ???? ???? ??? ????? ???? ???? ?? ?? ?? ?? 
???? ???? ?? ? ??? ???? ?? ?? ?? ????? ???? ???? ???? 
?????? ??? ?? ?????? ?? ???? ??? ??????? ???? ???? 
????, ???? ???????, ???? ?????? ?? ???? ????? ? ?
??? ???? ???? ???? ???? ???? ?? ??? ???? ???? ?? ???? 
???? ??? ?? ?????? ??? ??????? ?? ?? ?? ?? ????? ??? 
?????? ???? ?? ??? ??? ???? ???? ?????? ?????? ?? ?????? ???? 
Table 1. I/O of PMT and Proposed Systems 
Transliteration Tokens Output 
Type Total Wrong Right 
Accuracy 
% 
A 116 64 52 44.8275 
B 116 02 114 98.2758 
Table 2. Comparison of Output-A & B 
has all necessary diacritical marks for removing 
ambiguities. But this process of putting missing 
diacritical marks is not practically possible due to 
many reasons like large input size, manual inter-
vention, person having knowledge of both the 
scripts and so on. We have manually evaluated 
PMT system against the following Shahmukhi 
input published on a web site and the output text 
is shown as output-A in Table 1.The output of 
proposed system on the same input is shown as 
output-B. The wrong transliteration of Gurmukhi 
tokens is shown in bold and italic and the com-
parison of both outputs is shown in Table 
2.Clearly, our system is more practical in nature 
than PMT and we got good transliteration with 
different inputs having missing diacritical marks. 
3 The Complexity 
The Shahmukhi script has many complexities by 
its nature and the major two of them are: 
3.1 Recognition of Shahmukhi Text without 
Diacritical Marks 
Shahmukhi script is usually written without short 
vowels and other diacritical marks, often leading 
to potential ambiguity. Arabic orthography does 
not provide full vocalization of the text, and the 
reader is expected to infer short vowels from the 
context of the sentence. In the written Shah-
mukhi script it is not mandatory to put short 
vowels below or above the Shahmukhi character 
to clear its sound. These special signs are called 
"Aerab" in Urdu. It is a big challenge in the 
process of machine transliteration to recognize 
the right word from the written text.  
3.2 Multiple Mappings 
It is observed that there is multiple possible 
mapping in Gurmukhi script corresponding to a 
single character in the Shahmukhi script as 
shown in Table 3. 
Name Shahmukhi Character Gurmukhi Mapping 
Vav ? [v] 
? [v], ?? [o], ?? [?], ?? [?], ?? [u],  
? [o] 
Yeh  
 ?[j] 
? [j], ?? [?], ?? [e], ??[?], ??[i],  
? [i] 
Table 3. Multiple Mapping into Gurmukhi Script 
4 Transliteration System 
The transliteration system as shown in figure 1 
is virtually divided into two phases. The first 
phase performs pre-processing on the input 
Shahmukhi token by performing dictionary 
lookup. If the dictionary lookup fails then the 
token will go for rule based transliteration and 
ultimately this phase will generate best possible 
Gurmukhi token(s). The second phase performs 
178
the task of post-processing. Unicode Alignment 
component performs context analysis of input 
Gurmukhi token(s). All Forms generator (AFG) 
component will perform critical task of handling 
missing diacritical marks. This component will 
suggest similar possible forms of a Gurmukhi 
token which is not most frequent one. The queue 
manager of post-processing phase is designed to 
work on bi-gram language model. This will se-
lect the best possible unigram for final output by 
consulting bi-gram weights of the current token 
with its neighboring tokens 
Figure 1. System Overview 
5 Lexical Resources Used 
 Shahmukhi Corpus: 3.3 million words. 
 Gurmukhi Corpus: 7 million words. 
 Shahmukhi-Gurmukhi Dictionary  
 Unigram and Bi-gram Table 
 All Forms Generator (AFG) 
6 Example 
Here we show the internal working of the system 
through an example. Suppose we observe a 
Shahmukhi string as shown in figure 2. First, we 
pass this through the pre-processing and translit-
eration phase where the input string has been 
tokenized into eleven Shahmukhi tokens. Every 
input token has been searched in the dictionary 
for their existence. This status result is shown in 
table 4 where the tokens 1st, 2nd, 4th, 5th, 6th, 7th, 
8th, 10th and 11th are found in dictionary and their 
intermediate Weighted Gurmukhi Forms (WGF) 
have been generated. These tokens directly jump 
to bi-gram queue manager for bi-gram analysis in 
post-processing phase. 
 
Figure 2. Shahmukhi Gurmukhi Tokens 
Token Shahmukhi 
Token 
Found in 
Dictionary 
WGF 
token{weight} 
1 a??? ?  Yes ???{4513}; ???{8714} 
2 ?b?? Yes ???{14054}; ???{18} 
3 k~?a??? ?  No ??????{524} 
4 Qr??  Yes ??{59998}; ??{1186} 
5 ?b?5 Yes ????{107} 
6 ?>mb?? ?  Yes ??? ??{7699} 
7 ?? Yes ?{7927}; ?{3600} 
8 l??  Yes ??{295}; ??{9791} 
9 j? ???  No ????{4} 
10 ^M Yes ???{447};??{47};????{9} ???{5};????{5} 
11 ?A: Yes ???{21582};???{174}; ????{159} 
 Table 4. Pre-Processing Transliteration Status 
On the other hand, the input tokens 3rd and 9th are 
not found in dictionary. Therefore, in this phase 
they will pass through transliteration component 
and then in post-processing phase they will pass 
through Unicode formatting. After that they will 
test for Most Frequent (MF) check by comparing 
their weights with a predefined threshold value2 
                                                 
2 Threshold value is minimum probability of occur-
rence among most frequent tokens in target script cor-
pus. 
??? ??? ?????? ?? ???? ??? ?? ? ?? ????? ??? ???
Input 11 Shahmukhi tokens (Right to Left) 
????a?  ?b?  ???~?ak??  rQ?>mb?  ?b?   ? ? 5?? ?  l?  ??  ?? ?j?A:  ^M  
11      10   9       8   7         6        5 4       3      2    1 
1    2        3          4        5       6     7   8        9        10      11 
Transliterated 11 Gurmukhi tokens (Left to Right)
Unicode Encoded Shahmukhi Text 
Rule Based Transliteration  
Component 
All Forms Generator 
(AFG) 
Bi-Gram  
Queue 
Manager 
Gurmukhi Token(s) 
Shahmukhi Token 
Shahmukhi Tokenizer
Dictionary Component 
Unicode Alignment 
Pre-Processing &Transliteration 
Post-Processing 
Unicode Encoded Gurmukhi Text 
Transliteration 
System 
Out Put Text Generator 
179
(100 in this case). As shown in table 5 the WGF 
of 3rd token ??????{524} is most frequent one and 
will move to bi-gram queue whereas the WGF of 
9th token ????{4} is not a most frequent token 
and will reach at bi-gram queue manager only 
after passing  through all forms generator (AFG).  
Token MF AFG Status Bi-gram Found Output 
1 - - hold ???;??? - 
2 - - ???-???,12;  ???-???, 20; ??? 
3 Yes - hold ??? ??? 
4 - - ??????-??,10; ?????? 
5 - - hold ?? ?? 
6 - - ??-???? ,45; ???? 
7 - - ??? ??-?,86; ??? ??-?,125; ??? ?? 
8 - - hold ? ? 
9 No 
?????{310} 
?????{1486} 
????{4} 
?-??,22;  
??-?????,13; ?? 
18 Yes - hold ????? ????? 
11 - - 
?????-???,38; 
???-???,179; 
??-???,18; 
??? 
 EOS - hold ??? ??? 
Table 5. Post-Processing Status and output 
Here, we see that the AFG has generated two 
additional forms ?????{310}  ?????{1486} (table 5) 
for this token. These new forms are having addi-
tional diacritical marks of short vowels those are 
missing in the original form. Clearly, AFG has 
supplied the best possible forms. Next, we show 
how bi-gram manager will work on WGF tokens 
to generate final Gurmukhi token. In this model 
the next token will decide the selection of its 
previous one. Consider the case of second WFG 
token ???{14054} having bi-gram combinations 
with previous one as ???-??? with weight 12 and 
???-??? with weight 20. Clearly, the token ??? will 
produce as output not ??? because ???-??? combi-
nation has higher weight than ???-???. Similarly, 
this table shows found bi-gram weights and cor-
respondingly decided Gurmukhi token as output.  
7 Results and Discussion 
The transliteration system was tested on a small 
set of poetry, article and story. The results are 
tabulated in Table 6.  
As we can observe an average transliteration ac-
curacy of 91.37% has been obtained. We got 
good transliteration with different inputs. The 
main source of error is the existence of vowel-
consonant mapping between the two scripts. The 
Shahmukhi vowel characters Vav(?) and Yeh(?) 
have mapping into Gurmukhi consonants 
Vava(?) and Ya(?) respectively. This kind of 
vowel-consonant mapping can not be resolved 
fully with dependency rules but can be mini-
mized by refining the dictionary and phonetic 
code generation rules of AFG component. In 
other cases, system makes errors showing defi-
ciency in handling those tokens which are not 
belonging to common vocabulary domain. 
Type Transliterated Tokens Accuracy % 
Poetry 3,301 90.63769 
Article 584 92.60274 
Story 3,981 90.88043 
Total 7,866 91.37362 
Table 6. Transliteration Results 
8 References 
Arbabi, Mansur, Scott M. Fischthal, Vincent C. 
Cheng and Elizabeth Bar. 1994. Algorithms for 
Arabic name transliteration. IBM Journal of re-
search and Development, pp 183-193. 
 
Haizhou Li, Min Zhang and Jian Su. 2004. A Joint 
Source-Channel Model for Machine Transliteration. 
Proceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics, pp 159-
166. 
 
Malik, M. G. Abbas. 2006. Punjabi Machine 
Transliteration. Proceedings of the 21st Interna-
tional Conference on Computational Linguistics 
and 44th Annual Meeting of the ACL, pp 1137-
1144. 
 
Y. Gal, 2002. An HMM Approach to Vowel 
Restoration in Arabic and Hebrew. Proceedings of 
ACL Workshop on Computational Approaches to 
Semitic Languages, pp 27-33. 
 
Youngim Jung, Donghun Lee, Aesun Yoon, Hyuk 
Chul Kwon. 2004.  Transliteration System for 
Arabic-Numeral Expressions using Decision Tree 
for Intelligent Korean TTS, volume 1. 30th Annual 
Conference of IEEE, pp 657-662. 
180
A Punjabi Grammar Checker 
 
 
Abstract 
This article provides description about the 
grammar checking software developed for 
detecting the grammatical errors in Punjabi 
texts and providing suggestions wherever 
appropriate to rectify those errors. This 
system utilizes a full-form lexicon for 
morphology analysis and rule-based 
systems for part of speech tagging and 
phrase chunking. The system supported by 
a set of carefully devised error detection 
rules can detect and suggest rectifications 
for a number of grammatical errors, 
resulting from lack of agreement, order of 
words in various phrases etc., in literary 
style Punjabi texts.  
1 Introduction 
Grammar checking is one of the most widely used 
tools within natural language engineering 
applications. Most of the word processing systems 
available in the market incorporate spelling, 
grammar, and style-checking systems for English 
and other foreign languages, one such rule-based 
grammar checking system for English is discussed 
in (Naber, 2003). However, when it comes to the 
smaller languages, specifically the Indian 
languages, most of such advanced tools have been 
lacking. Spell checking has been addressed for 
most of the Indian languages but still grammar and 
style checking systems are lacking. In this article a 
grammar checking system for Punjabi, a member 
of the Modern Indo-Aryan family of languages, is 
provided. The grammar checker uses a rule-based 
system to detect grammatical errors in the text and 
if possible generates suggestions to correct those 
errors.  
To the best of our knowledge the grammar 
checking provided here will be the first such 
system for Indian languages. There is n-gram 
based grammar checking system for Bangla (Alam 
et al 2006). The authors admit its accuracy is very 
low and there is no description about whether the 
system provides any suggestions to correct errors 
or not. It is mentioned that it was tested to identify 
correct sentences from the set of sentences 
provided as input but nothing is mentioned as far 
as correcting those errors is concerned. However, 
the system that we discuss here for Punjabi detects 
errors and suggests corrections as well. In doing 
so, provides enough information for the user to 
understand the error reason and supports the 
suggestions provided, if any. 
2 System Overview 
The input Punjabi text is given to the preprocessing 
system that performs tokenization and detects any 
phrases etc. After that morphological analysis is 
performed, this returns possible tags for all the 
words in the given text, based on the full-form 
lexicon that it is using. Then a rule-based part of 
speech tagger is engaged to disambiguate the tags 
based on the context information. After that, the 
text is grouped into various phrases accordingly to 
the pre-defined phrase chunking rules. In the final 
phase, rules to check for various grammatical 
errors internal to phrases and agreement on the 
sentence level, are applied. If any error is found in 
a sentence then based on the context information 
corrections are suggested (generated) for that.  
Mandeep Singh Gill 
Department of Computer 
Science 
Punjabi University 
 Patiala -147002, India 
msgill_in@yahoo.com 
Tel.: +91-9888165971 
Gurpreet Singh Lehal 
Department of Computer 
Science 
Punjabi University  
Patiala -147002, India 
gslehal@yahoo.com 
Tel.: +91-175-3046171 
Shiv Sharma Joshi 
Department of 
Anthropological Linguistics 
& Punjabi Lexicography 
Punjabi University 
Patiala -147002, India 
Tel.: +91-175-3046292 
940
 For the purpose of morphological analysis we 
have divided the Punjabi words into 22 word 
classes like noun, adjective (inflected and 
uninflected), pronoun (personal, demonstrative, 
reflexive, interrogative, relative, and indefinite), 
verb (main verb, operator verb, and auxiliary verb), 
cardinals, ordinals, adverb, postposition, 
conjunction, interjection etc., depending on the 
grammatical information required for the words of 
these word classes. The information that is in the 
database depends upon the word class, like for 
noun and inflected adjective, it is gender, number, 
and case. For personal pronouns, person is also 
required. For main verbs gender, number, person, 
tense, phase, transitivity etc. is required. As 
mentioned earlier the lexicon of this morphological 
analyzer is full form based i.e. all the word forms 
of all the commonly used Punjabi words are kept 
in the lexicon along with their root and other 
grammatical information. 
 For part of speech tagging, we have devised a 
tag set keeping into mind all the grammatical 
categories that can be helpful for agreement 
checking. At present, there are more than 600 tags 
in the tag set. In addition to this, some word-
specific tags are also there. The tag set is very user 
friendly and while choosing tag names existing tag 
sets for English and other such languages were 
taken into consideration, like NNMSD ?  
masculine, singular, and direct case noun, 
PNPMPOF ? masculine, plural, oblique case, and 
first person personal pronoun. The approach 
followed for part of speech tagging is rule-based, 
as there is no tagged corpus for Punjabi available 
at present. As the text we are processing may have 
grammatical agreement errors, so the part of 
speech tagging rules are devised considering this. 
The rules are applied in sequential order with each 
rule having an attached priority to control its order 
in this sequence. 
 For phrase chunking, again a rule-based 
approach was selected mainly due to the similar 
reasons as for part of speech tagging. The tag set 
that is being used for phrase chunking includes 
tags like NPD ? noun phrase in direct case, NPNE 
? noun phrase followed by ? ne etc. The rules for 
phrase chunking also take into account the 
potential errors in the text, like lack of agreement 
in words of a potential phrase. However, as would 
be expected there is no way to take the misplaced 
words of a phrase into account, like if words of a 
phrase are separated (having some other phrase in 
between) then that cannot be taken as a single 
phrase, even though this may be a potential error. 
 In the last phase i.e. grammar checking, there 
are again manually designed error detection rules 
to detect potential errors in the text and provide 
corrections to resolve those errors. For example, 
rule to check modifier and noun agreement, will go 
through all the noun phrases in a sentence to check 
if the modifiers of those sentences agree with their 
respective head words (noun/pronoun) in terms of 
gender, number, and case or not. For this matching, 
the grammatical information from the tags of those 
words is used. In simple terms, it will compare the 
grammatical information (gender, number, and 
case) of modifier with the headword 
(noun/pronoun) and displays an error message if 
some grammatical information fails to match. To 
resolve this error, the grammar checking module 
will use morphological generator, to generate the 
correct form (based on headword?s gender, 
number, and case) for that modifier from its root 
word.  
 For example, consider the grammatically 
incorrect sentence  	
   sohne larka 
janda hai ?handsome boy goes?. In this sentence in 
the noun phrase,  	
 sohne larka ?handsome 
boy?, the modifier  sohne ?handsome? (root 
word ?  sohna ?handsome?), with masculine 
gender, plural number, and direct case, is not in 
accordance with the gender, number, case of its 
head word. It should be in singular number instead 
of plural. The grammar checking module will 
detect this as an error as ?number? for modifier and 
headword is not same, then it will use 
morphological generator to generate the ?singular 
number form? from its root word, which is same as 
root form i.e.  sohna ?handsome? (masculine 
gender, singular number, and direct case). So, the 
input sentence will be corrected as  	
  
 sohna larka janda hai ?handsome boy goes?. 
 The error detection rules in grammar checking 
module are again applied in sequential order with 
priority field to control the sequence. This is done 
to resolve phrase level errors before going on to 
the clause level errors, and then to sentence level 
agreement errors. 
941
3 Grammar Errors 
At present, this grammar checking system for 
Punjabi detects and provides corrections for 
following grammatical errors, based on the study 
of Punjabi grammar related texts (Chander, 1964; 
Gill and Gleason, 1986; Puar, 1990): 
Modifier and noun agreement 
The modifier of a noun must agree with the noun 
in terms of gender, number, and case. Modifiers of 
a noun include adjectives, pronouns, cardinals, 
ordinals, some forms of verbs etc. 
 
Subject and verb agreement 
In Punjabi text, the verb must agree with the 
subject of the sentence in terms of gender, number, 
and person. There are some special forms of verbs 
like transitive past tense verbs, which need some 
specific postpositions with their subject, like the 
use of ? ne with transitive verbs in perfect form 
etc. 
 
Noun and adjective (in attributive form) 
agreement 
This is different from ?modifier and noun 
agreement? as described above in the sense that 
adjective is not preceding noun but can be virtually 
anywhere in the sentence, usually preceding verb 
phrase acting as a complement for it. It must still 
agree with the noun for which it is used in that 
sentence. 
 
Order of the modifiers of a noun in noun phrase 
If a noun has more than one modifier, then those 
modifiers should be in a certain order such that 
phrase modifiers precede single word modifiers but 
pronouns and numerals precede all other. 
 
Order of the words in a verb phrase 
There are certain future tense forms of Punjabi 
verbs that should occur towards the end of verb 
phrase without any auxiliary. In addition, if 
negative and emphatic particles are used in a verb 
phrase then the latter must precede the former. 
 
 da postposition and following noun phrase 
agreement 
All the forms of  da postposition must agree in 
terms of gender, number, and case with the 
following noun phrase that it is connecting with the 
preceding noun phrase. 
 
Some other options covered include noun phrase 
must be in oblique form before a postposition, all 
the noun phrases joined by connectives must have 
same case, main verb should be in root form if 
preceding  ke etc. 
4 Sample Input and Output 
This section provides some sample Punjabi 
sentences that were given as input to the Punjabi 
grammar checking system along with the output 
generated by this system. 
 
Sentence 1 
Shows the grammatical errors related to ?Modifier 
and noun agreement? and ?Order of the modifiers 
of a noun in noun phrase?. In this sentence noun is 
	
 larka ?boy? and its modifiers are   
  sohni ek bhajji janda ?handsome one 
running?. 
Input:     	
  
Input1: sohni ek bhajji janda larka aaeya 
Input2: Handsome one running boy came 
Output:     	
  
Output1: ek bhajjia janda sohna larka aaeya 
Output2: One running handsome boy came 
 
Sentence 2 
Covers the grammatical error related to ?Subject 
and verb agreement?. Subject is  barish ?rain? 
and verb phrase is    ho riha han ?is 
raining?.  
Input:      
Input1: bahr barish ho riha han 
Input2: It is raining outside 
Output:      
Output1: bahr barish ho rahi hai 
Output2: It is raining outside 
 
Sentence 3 
For grammatical errors related to ? da 
postposition and following noun phrase agreement? 
and ?Noun phrase in oblique form before a post 
position?. Noun phrase preceding  dee 
942
(possessive marker) is Proceedings of the ACL-HLT 2011 System Demonstrations, pages 1?6,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
 
 
 
HINDI TO PUNJABI MACHINE TRANSLATION 
SYSTEM 
 
Vishal Goyal Gurpreet Singh Lehal 
Department of Computer Science Department of Computer Science 
Punjabi University, Patiala,India Punjabi University, Patiala,India 
vishal.pup@gmail.com gslehal@gmail.com 
 
 
Abstract 
 
Hindi-Punjabi being closely related language 
pair (Goyal V. and Lehal G.S., 2008) , Hybrid 
Machine Translation approach has been used 
for developing Hindi to Punjabi Machine 
Translation System. Non-availability of lexical 
resources, spelling variations in the source 
language text, source text ambiguous words, 
named entity recognition and collocations are 
the major challenges faced while developing 
this syetm. The key activities involved during 
translation process are preprocessing, 
translation engine and post processing. Lookup 
algorithms, pattern matching algorithms etc 
formed the basis for solving these issues. The 
system accuracy has been evaluated using 
intelligibility test, accuracy test and BLEU 
score. The hybrid syatem is found to perform 
better than the constituent systems. 
 
Keywords: Machine Translation, Computational 
Linguistics, Natural Language Processing, Hindi, 
Punjabi. Translate Hindi to Punjabi, Closely 
related languages. 
 
1 Introduction 
Machine Translation system is a software 
designed that essentially takes a text in one 
language (called the source language), and 
translates it into another language (called the 
target language). There are number of 
approaches for MT like Direct based, 
Transform based, Interlingua based, Statistical 
etc. But the choice of approach depends upon 
the available resources and the kind of 
languages involved. In general, if the two 
languages are structurally similar, in particular 
as regards lexical correspondences, 
morphology and word order, the case for 
abstract syntactic analysis seems less 
convincing. Since the present research work 
deals with a pair of closely related language 
i.e. Hindi-Punjabi , thus direct word-to-word 
translation approach is the obvious choice. As 
some rule based approach has also been used, 
thus, Hybrid approach has been adopted for 
developing the system. An exhaustive survey 
has already been given for existing machine 
translations systems developed so far 
mentioning their accuracies and limitations. 
(Goyal V. and Lehal G.S., 2009). 
 
2 System Architecture 
 
2.1 Pre Processing Phase 
The preprocessing stage is a collection of 
operations that are applied on input data to 
make it processable by the translation engine. 
In the first phase of Machine Translation 
system, various activities incorporated include 
text normalization, replacing collocations and 
replacing proper nouns.  
2.2 Text Normalization  
The variety in the alphabet, different dialects 
and influence of foreign languages has resulted 
in spelling variations of the same word. Such 
variations sometimes can be treated as errors in 
writing. (Goyal V. and Lehal G.S., 2010).  
2.3 Replacing Collocations  
After passing the input text through text 
normalization, the text passes through this 
Collocation replacement sub phase of Pre-
processing phase. Collocation is two or more 
consecutive words with a special behavior. 
(Choueka :1988). For example, the collocation 
??? ???? (uttar prad?sh) if translated word to 
word, will be translated as ???? ??? (jav?b r?j) 
but it must be translated as ???? ????? (uttar 
prad?sh). The accuracy of the results for 
collocation extraction using t-test is not 
accurate and includes number of such bigrams 
and trigrams that are not actually collocations. 
Thus, manually such entries were removed and 
actual collocations were further extracted. The 
1
  
 
P
ost P
rocessing 
Translation E
ngine 
P
re P
rocessing 
 
 
 
1. Identifying Surnames 
2. Identifying Titles 
3. Hindi Morph Analyzer 
4. Lexicon Lookup 
5. Ambiguity Resolution 
6. Handling Unkown Words 
Text Normalization 
Replacing Proper Nouns 
Replacing Collocations
 Agreement
Tokenizer 
Token Analyzer 
Punjabi Text 
correct corresponding Punjabi translation for 
each extracted collocation is stored in the 
collocation table of the database. The 
collocation table of the database consists of 
5000 such entries. In this sub phase, the 
normalized input text is analyzed. Each 
collocation in the database found in the input 
text will be replaced with the Punjabi 
translation of the corresponding collocation. It 
is found that when tested on a corpus 
containing about 1,00,000 words, only 0.001% 
collocations were found and replaced during 
the translation. 
 
 
Hindi Text 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1 : Overview of Hindi-Punjabi Machine Translation System 
 
2.4 Replacing Proper Nouns 
A great proposition of unseen words includes 
proper nouns like personal, days of month, 
days of week, country names, city names, bank 
names, organization names, ocean names, river 
names, university names etc. and if translated 
word to word, their meaning is changed. If the 
meaning is not affected, even though this step 
fastens the translation process. Once these 
words are recognized and stored into the 
proper noun database, there is no need to 
decide about their translation or transliteration 
every time in the case of presence of such 
words in input text for translation. This 
gazetteer makes the translation accurate and 
fast. This list is self growing during each 
Collocations database 
Proper Nouns database 
Proper Noun 
recognition Rules 
Surnames database 
Surnanes recognition 
Rules 
Titles database Titles recognition 
Rules 
Hindi Morphological 
Rules 
Hindi-Punjabi Root Words 
Bigrams and Trigrams 
Ambiguos Words 
Transliteration Rules 
Transliteration Mappings 
Text Normalization Rules 
Agreement Rules 
2
  
 
translation. Thus, to process this sub phase, the 
system requires a proper noun gazetteer that 
has been complied offline. For this task, we 
have developed an offline module to extract 
proper nouns from the corpus based on some 
rules. Also, Named Entity recognition module 
has been developed based on the CRF 
approach (Sharma R. and Goyal V., 2011b). 
2.5 Tokenizer  
Tokenizers (also known as lexical analyzers or 
word segmenters) segment a stream of 
characters into meaningful units called tokens. 
The tokenizer takes the text generated by pre 
processing phase as input. Individual words or 
tokens are extracted and processed to generate 
its equivalent in the target language. This 
module, using space, a punctuation mark, as 
delimiter, extracts tokens (word) one by one 
from the text and gives it to translation engine 
for analysis till the complete input text is read 
and processed.  
 
2.6 Translation Engine 
The translation engine is the main component 
of our Machine Translation system. It takes 
token generated by the tokenizer as input and 
outputs the translated token in the target 
language. These translated tokens are 
concatenated one after another along with the 
delimiter. Modules included in this phase are 
explained below one by one.  
2.6.1 Identifying Titles and Surnames 
Title may be defined as a formal appellation 
attached to the name of a person or family by 
virtue of office, rank, hereditary privilege, 
noble birth, or attainment or used as a mark of 
respect. Thus word next to title and word 
previous to surname is usually a proper noun. 
And sometimes, a word used as proper name 
of a person has its own meaning in target 
language. Similarly, Surname may be defined 
as a name shared in common to identify the 
members of a family, as distinguished from 
each member's given name. It is also called 
family name or last name. When either title or 
surname is passed through the translation 
engine, it is translated by the system. This 
cause the system failure as these proper names 
should be transliterated instead of translation. 
For example consider the Hindi sentence 
????? ??? ?? ????? ???? ?????? (shr?m?n harsh j? 
ham?r? yah?? padh?r?). In this sentence, ??? 
(harsh) has the meaning ?joy?. The equivalent 
translation of ??? (harsh) in target language is 
???? (khush?).  Similarly, consider the Hindi 
sentence ???? ??? ????? ???? ??????. (prak?sh 
si?h ham?r? yah?? padh?r?). Here, ???? 
(prak?sh) word is acting as proper noun and it 
must be transliterated and not translated 
because ??? (si?h) is surname and word 
previous to it is proper noun. 
Thus, a small module has been developed for 
locating such proper nouns to consider them as 
title or surname. There is one special character 
??? in Devanagari script to mark the symbols 
like ???, ???. If this module found this symbol 
to be title or surname, the word next and 
previous to this token as the case may be for 
title or surname respectively, will be 
transliterated not translated. The title and 
surname database consists of 14 and 654 
entries respectively.  These databases can be 
extended at any time to allow new titles and 
surnames to be added. This module was tested 
on a large Hindi corpus and showed that about 
2-5 % text of the input text depending upon its 
domain is proper noun. Thus, this module 
plays an important role in translation.  
2.6.2 Hindi Morphological analyzer 
This module finds the root word for the token 
and its morphological features.Morphological 
analyzer developed by IIT-H has been ported 
for Windows platform for making it usable for 
this system. (Goyal V. and Lehal G.S.,2008a) 
2.6.3 Word-to-Word translation using 
lexicon lookup 
If token is not a title or a surname, it is looked 
up in the HPDictionary database containing 
Hindi to Punjabi direct word to word 
translation. If it is found, it is used for 
translation. If no entry is found in 
HPDictionary database, it is sent to next sub 
phase for processing. The HPDictionary 
database consists of 54,127 entries.This 
database can be extended at any time to allow 
new entries in the dictionary to be added. 
2.6.4 Resolving Ambiguity 
3
  
 
Among number of approaches for 
disambiguation, the most appropriate approach 
to determine the correct meaning of a Hindi 
word in a particular usage for our Machine 
Translation system is to examine its context 
using N-gram approach. After analyzing the 
past experiences of various authors, we have 
chosen the value of n to be 3 and 2 i.e. trigram 
and bigram approaches respectively for our 
system. Trigrams are further categorized into 
three different types. First category of trigram 
consists of context one word previous to and 
one word next to the ambiguous word. Second 
category of trigram consists of context of two 
adjacent previous words to the ambiguous 
word. Third category of the trigram consists of 
context of two adjacent next words to the 
ambiguous word. Bigrams are also categorized 
into two categories. First category of the 
bigrams consists of context of one previous 
word to ambiguous word and second category 
of the bigrams consists of one context word 
next to ambiguous word. For this purpose, the 
Hindi corpus consisting of about 2 million 
words was collected from different sources 
like online newspaper daily news, blogs, Prem 
Chand stories, Yashwant jain stories, articles 
etc. The most common list of ambiguous 
words was found. We have found a list of 75 
ambiguous words out of which the most 
frequent are ?? s? and ?? aur. (Goyal V. and 
Lehal G.S., 2011) 
2.6.5 Handling Unknown Words 
2.6.5.1 Word Inflectional Analysis and 
generation 
In linguistics, a suffix (also sometimes called a 
postfix or ending) is an affix which is placed 
after the stem of a word. Common examples 
are case endings, which indicate the 
grammatical case of nouns or adjectives, and 
verb endings. Hindi is a (relatively) free word-
order and highly inflectional language. 
Because of same origin, both languages have 
very similar structure and grammar. The 
difference is only in words and in 
pronunciation e.g. in Hindi it is ???? and in 
Punjabi the word for boy is ????? and even 
sometimes that is also not there like ?? (ghar) 
and ?? (ghar). The inflection forms of both 
these words in Hindi and Punjabi are also 
similar. In this activity, inflectional analysis 
without using morphology has been performed 
for all those tokens that are not processed by 
morphological analysis module. Thus, for 
performing inflectional analysis, rule based 
approach has been followed. When the token is 
passed to this sub phase for inflectional 
analysis, If any pattern of the regular 
expression (inflection rule) matches with this 
token, that rule is applied on the token and its 
equivalent translation in Punjabi is generated 
based on the matched rule(s). There is also a 
check on the generated word for its 
correctness. We are using correct Punjabi 
words database for testing the correctness of 
the generated word.  
2.6.5.2 Transliteration 
This module is beneficial for handling out-of-
vocabulary words. For example the word 
????? (vish?l) is transliterated as ????? 
(vish?l) whereas translated as ????. There must 
be some method in every Machine Translation 
system for words like technical terms and 
proper names of persons, places, objects etc. 
that cannot be found in translation resources 
such as Hindi-Punjabi bilingual dictionary, 
surnames database, titles database etc and 
transliteration is an obvious choice for such 
words. (Goyal V. and Lehal G.S., 2009a). 
2.7 Post-Processing 
2.7.1 Agreement Corrections 
In spite of the great similarity between Hindi 
and Punjabi, there are still a number of 
important agreement divergences in gender 
and number. The output generated by the 
translation engine phase becomes the input for 
post-processing phase. This phase will correct 
the agreement errors based on the rules 
implemented in the form of regular 
expressions. (Goyal V. and Lehal G.S., 2011) 
 
3 Evaluation and Results 
The evaluation document set consisted of 
documents from various online newspapers 
news, articles, blogs, biographies etc. This test 
bed consisted of 35500 words and was 
translated using our Machine Translation 
system.  
 
3.1 Test Document 
 
4
  
 
For our Machine Translation system 
evaluation, we have used benchmark sampling 
method for selecting the set of sentences. Input 
sentences are selected from randomly selected 
news (sports, politics, world, regional, 
entertainment, travel etc.), articles (published 
by various writers, philosophers etc.), literature 
(stories by Prem Chand, Yashwant jain etc.), 
Official language for office letters (The 
Language Officially used on the files in 
Government offices) and blogs (Posted by 
general public in forums etc.). Care has been 
taken to ensure that sentences use a variety of 
constructs. All possible constructs including 
simple as well as complex ones are 
incorporated in the set. The sentence set alo 
contains all types of sentences such as 
declarative, interrogative, imperative and 
exclamatory. Sentence length is not restricted 
although care has been taken that single 
sentences do not become too long. Following 
table shows the test data set: 
 
Table 1: Test data set for the evaluation of 
Hindi to Punjabi Machine Translation 
System 
 Daily 
News 
 
Articles 
 
Official 
Language 
Quotes 
Blog 
 
Literature 
 
Total 
Documents 
100 50 01 50 20 
Total 
Sentences 
10,000 3,500 8,595 3,300 10,045 
Total 
Words 
93,400 21,674 36,431 15,650 95,580 
 
 
3.2 Experiments 
It is also important to choose appropriate 
evaluators for our experiments. Thus, 
depending upon the requirements and need of 
the above mentioned tests, 50 People of 
different professions were selected for 
performing experiments. 20 Persons were from 
villages that only knew Punjabi and did not 
know Hindi and 30 persons were from 
different professions having knowledge of both 
Hindi and Punjabi. Average ratings for the 
sentences of the individual translations were 
then summed up (separately according to 
intelligibility and accuracy) to get the average 
scores. Percentage of accurate sentences and 
intelligent sentences was also calculated 
separately by counting the number of 
sentences. 
 
3.2.1 Intelligibility Evaluation 
The evaluators do not have any clue about the 
source language i.e. Hindi. They judge each 
sentence (in target language i.e. Punjabi) on 
the basis of its comprehensibility. The target 
user is a layman who is interested only in the 
comprehensibility of translations. Intelligibility 
is effected by grammatical errors, mis-
translations, and un-translated words. 
 
3.2.1.1 Results 
The response by the evaluators were analysed 
and following are the results: 
? 70.3 % sentences got the score 3 i.e. they 
were perfectly clear and intelligible. 
? 25.1 % sentences got the score 2 i.e. they 
were generally clear and intelligible. 
? 3.5 % sentences got the score 1 i.e. they were 
hard to understand. 
? 1.1 % sentences got the score 0 i.e. they were 
not understandable. 
So we can say that about 95.40 % sentences 
are intelligible. These sentences are those 
which have score 2 or above. Thus, we can say 
that the direct approach can translate Hindi text 
to Punjabi Text with a consideably good 
accuracy. 
 
3.2.2 Accuracy Evaluation / Fidelity 
Measure 
The evaluators are provided with source text 
along with translated text. A highly intelligible 
output sentence need not be a correct 
translation of the source sentence. It is 
important to check whether the meaning of the 
source language sentence is preserved in the 
translation. This property is called accuracy.  
 
3.2.2.1 Results 
Initially Null Hypothesis is assumed i.e. the 
system?s performance is NULL. The author 
assumes that system is dumb and does not 
produce any valuable output. By the 
intelligibility of the analysis and Accuracy 
analysis, it has been proved wrong. 
The accuracy percentage for the system is 
found out to be 87.60% 
Further investigations reveal that out of 
13.40%: 
? 80.6 % sentences achieve a match 
between 50 to 99% 
? 17.2 % of remaining sentences were 
marked with less than 50% match 
against the correct sentences. 
5
  
 
? Only 2.2 % sentences are those which 
are found unfaithful. 
A match of lower 50% does not mean that the 
sentences are not usable. After some post 
editing, they can fit properly in the translated 
text. (Goyal, V., Lehal, G.S., 2009b) 
  
3.2.2 BLEU Score:  
As there is no Hindi ?Parallel Corpus was 
available, thus for testing the system 
automatically, we generated Hindi-Parallel 
Corpus of about 10K Sentences. The BLEU 
score comes out to be 0.7801. 
 
5 Conclusion 
In this paper, a hybrid translation approach 
for translating the text from Hindi to 
Punjabi has been presented. The proposed 
architecture has shown extremely good 
results and if found to be appropriate for 
MT systems between closely related 
language pairs. 
 
Copyright 
The developed system has already been 
copyrighted with The Registrar, Punjabi University, 
Patiala with authors same as the authors of the 
publication. 
 
Acknowlegement 
We are thankful to Dr. Amba Kulkarni, University 
of Hyderabad for her support in providing technical 
assistance for developing this system. 
 
References 
Bharati, Akshar, Chaitanya, Vineet, Kulkarni, 
Amba P., Sangal, Rajeev. 1997. Anusaaraka: 
Machine Translation in stages. Vivek, A Quarterly 
in Artificial Intelligence, Vol. 10, No. 3. ,NCST, 
Banglore. India, pp. 22-25. 
Goyal V., Lehal G.S. 2008. Comparative Study of 
Hindi and Punjabi Language Scripts, Napalese 
Linguistics, Journal of the Linguistics Society of 
Nepal, Volume 23, November Issue, pp 67-82. 
Goyal V., Lehal, G. S. 2008a. Hindi Morphological 
Analyzer and Generator. In Proc.: 1st International 
Conference on Emerging Trends in Engineering 
and Technology, Nagpur,  G.H.Raisoni College of 
Engineering, Nagpur, July16-19, 2008, pp. 1156-
1159, IEEE Computer Society Press, California, 
USA. 
Goyal V., Lehal G.S. 2009. Advances in Machine 
Translation Systems, Language In India, Volume 9, 
November Issue, pp. 138-150. 
Goyal V., Lehal G.S. 2009a. A Machine 
Transliteration System for Machine Translation 
System: An Application on Hindi-Punjabi 
Language Pair. Atti Della Fondazione Giorgio 
Ronchi (Italy), Volume LXIV, No. 1, pp. 27-35. 
Goyal V., Lehal G.S. 2009b. Evaluation of Hindi to 
Punjabi Machine Translation System. International 
Journal of Computer Science Issues, France, Vol. 4, 
No. 1, pp. 36-39. 
Goyal V., Lehal G.S. 2010. Automatic Spelling 
Standardization for Hindi Text. In : 1st International 
Conference on Computer & Communication 
Technology,  Moti Lal Nehru National Institute of 
technology, Allhabad, Sepetember 17-19, 2010, pp. 
764-767, IEEE Computer Society Press, California. 
Goyal V., Lehal G.S. 2011. N-Grams Based Word 
Sense Disambiguation: A Case Study of Hindi to 
Punjabi Machine Translation System. International 
Journal of Translation. (Accepted, In Print). 
Goyal V., Lehal G.S. 2011a. Hindi to Punjabi 
Machine Translation System. In Proc.: International 
Conference for Information Systems for Indian 
Languages,  Department of Computer Science, 
Punjabi University, Patiala, March 9-11, 2011, pp. 
236-241, Springer CCIS 139, Germany. 
Sharma R., Goyal V. 2011b. Named Entity 
Recognition Systems for Hindi using CRF 
Approach. In Proc.: International Conference for 
Information Systems for Indian Languages,  
Department of Computer Science, Punjabi 
University, Patiala, March 9-11, 2011, pp. 31-35, 
Springer CCIS 139, Germany. 
 
6
Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 43?50,
the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010
A Word Segmentation System for Handling Space Omission Problem 
in Urdu Script 
 
Gurpreet Singh Lehal 
Department of Computer Science 
Punjabi University, Patiala 
gslehal@gmail.com 
 
  
Abstract 
Word Segmentation is the foremost 
obligatory task in almost all the NLP 
applications, where the initial phase requires 
tokenization of input into words. Like other 
Asian languages such as Chinese, Thai and 
Myanmar, Urdu also faces word 
segmentation challenges. Though the Urdu 
word segmentation problem is not as severe 
as the other Asian language, since space is 
used for word delimitation, but the space is 
not consistently used, which gives rise to 
both space omission and space insertion 
errors in Urdu. In this paper we present a 
word segmentation system for handling 
space omission problem in Urdu script with 
application to Urdu-Devnagri Transliteration 
system. Instead of using manually 
segmented monolingual corpora to train 
segmenters, we make use of bilingual 
corpora and statistical word disambiguation  
techniques. Though our approach is adapted 
for the specific transliteration task at hand by 
taking the corresponding target (Hindi) 
language into account, the techniques 
suggested can  be adapted to  independently 
solve the space omission Urdu word 
segmentation problems. The two major 
components of our system are : 
identification of merged words for 
segmentation and proper segmentation of the 
merged words. The system was tested on 
1.61 million word Urdu test data. The recall 
and precision for the merged word 
recognition component were found to be  
99.29% and 99.38% respectively. The 
words are correctly segmented with 99.15% 
accuracy. 
1 Introduction 
Word segmentation is the foremost obligatory 
task in all NLP application, where the initial 
phase requires tokenization of input into words.  
For languages like English, French and Spanish 
etc. tokenization is considered trivial because the 
white space or punctuation marks between 
words is a good approximation of where a word 
boundary is. Whilst in various Asian languages 
such as Chinese, Thai and Myanmar, white 
spaces is rarely or never used to determine the 
word boundaries, so one must resort to higher 
levels of information such as: information of 
morphology, syntax and statistical analysis to 
reconstruct the word boundary information 
(Papageorgiou, 1994; Nie et al  1995;  Wang et 
al,  2000;  Xu et al 2005). 
 Though the Urdu word segmentation problem is 
not as severe as some of the  other Asian 
language, since space is used for word 
delimitation, but the space is not consistently 
used, which gives rise to both space omission 
and space insertion errors in Urdu. 
Durrani(2007) and Durrani and Hussain(2010) 
have discussed in detail the various Urdu word 
segmentation issues while Jawaid and 
Ahmed(2009) and Abbas et al2009) have 
discussed the Hindi-Urdu transliteration issues. 
A word segmentation system for handling space 
insertion problem in Urdu script has been 
presented by Lehal(2009).  
Hindi and Urdu are variants of the same 
language characterized by extreme digraphia: 
Hindi is written in the Devanagari script from 
left to right, Urdu in a script derived from a 
Persian modification of Arabic script written 
from right to left. Hindi and Urdu share 
grammar, morphology, vocabulary, history, 
classical literature etc. Because of their identical 
grammar and nearly identical core vocabularies, 
43
most linguists do not distinguish between Urdu 
and Hindi as separate languages. The difference 
in the two scripts has created a script wedge as 
majority of Urdu speaking people in Pakistan 
cannot read Devnagri, and similarly the majority 
of Hindi speaking people in India cannot 
comprehend Urdu script. To break this script 
barrier an Urdu-Devnagri transliteration system 
has been developed. The transliteration system 
faced many problems related to word 
segmentation of Urdu script as discussed above.  
In this paper we present a word segmentation 
system for handling space omission problem in 
Urdu script with application to Urdu-Devnagri 
Transliteration system. Instead of using 
manually segmented monolingual corpora to 
train segmenters, we make use of bilingual 
corpora and statistical word disambiguation  
techniques. Though our approach is adapted for 
the specific transliteration task at hand by taking 
the corresponding target (Hindi) language into 
account, the techniques suggested can be 
adapted to independently solve the space 
omission Urdu word segmentation problems. 
 
2 Urdu script: a brief overview 
Urdu is a Central Indo-Aryan language of the 
Indo-Iranian branch, belonging to the Indo-
European family of languages. It is the national 
language of Pakistan. It is also one of the 22 
scheduled languages of India and is an official 
language of five Indian states.  
Urdu script has 35 simple consonants, 15 
aspirated consonants, one character for nasal 
sound and 15 diacritical marks. Urdu characters 
change their shapes depending upon neighboring 
context. But generally they acquire one of these 
four shapes, namely isolated, initial, medial and 
final. Urdu characters can be divided into two 
groups, non-joiners and joiners. The non-joiners 
can acquire only isolated and final shape and do 
not join with the next character. On contrary 
joiners can acquire all the four shapes and get 
merged with the following character. A group of 
joiners and/or non-joiner joined  together form a 
ligature. A word in Urdu is a collection of one or 
more ligatures.  The isolated form of joiners and 
non-joiners is shown in figures 1-2. 
 
 ? ? ? ? ? ? ? ? ? ??  
Figure 1.  Non-Joiners in Urdu 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ? ? ? 
Figure 2.  Joiners in Urdu 
The space character is used in Urdu both to 
generate correct shaping and also to separate 
words. Though for words ending with non-
joiners correct shaping is generated even when 
space is not typed and thus, many times a user 
omits the space. The sequence of Urdu words 
written together without space is still readable 
because of the character joining property in 
Urdu. As for example, consider the word cluster 
???????????? , which is composed of four words 
??? , ?? ,?????  and ??. The Urdu readers can very 
easily segment and read the four words 
separately, but the computer will read them as a 
single word since there is no space in between. 
Similarly, the word cluster ????????????? is 
composed of five words(??? ,??? ,??? ,?? and ?? ), 
which can be easily read as five separate words 
by Urdu readers but will be considered as a 
single word by the computer.  
Another unique feature of Urdu is that the 
Urdu words are usually written without short 
vowels or diacritic symbols. Any machine 
transliteration or text to speech synthesis system 
has to automatically guess and insert these 
missing symbols. This is a non-trivial problem 
and requires an in-depth statistical analysis.  
An Urdu word is a combination of ligatures 
(characters which join together) and isolated 
characters. For example ?????  is composed of 
isolated characters ? and ? and ligature  ??? . A 
ligature or isolated character will be called as 
Urdu character cluster (UCC) in this paper. A 
Urdu word is thus a combination of UCCs . As 
for example, the word ?????  is composed of three 
UCCs ??? , ? and ? . We borrow the term, 
Orthographic Word used by Durrani and 
Hussain(2010) to define our segmentation 
process. An Orthographic Word (OW) is a 
combination of  UCCs separated by spaces or 
punctuation marks. An OW may contain single 
or multiple Urdu words. Our task is to identify if 
an OW contains multiple words and in that case 
properly segment the words. 
As for example, consider the sentence: 
?????? ??? ?? ???? ?? ??? ???? ?? ????????????????? 
44
It contains nine OWs 
1. ?????? 
2. ??? 
3. ?? 
4. ???? 
5. ??  
6. ??? 
7. ???? 
8. ?? 
9. ????????????????? 
The first eight OWs contain single Urdu 
words, while the last OW contains 5 Urdu 
words(??? ,????? ,?? ,???? and ???)  
3 Segmentation Model for Urdu 
There are three major issues in the automatic 
Urdu word segmentation. The first problem is to 
decide if the orthographic word represents a 
single word or a multiple word cluster. The 
second is the ambiguity issue. Since a word 
cluster can be segmented into words in multiple 
ways, the correct word boundary detection 
becomes a challenge. As for example the OW  
???????  can be segmented as ??? + ???? or ?? + ??? 
+ ??. The third problem is the segmentation of 
unknown word. Unknown word refers to word 
that does not exist in the dictionary or corpus. 
Unknown words can be categorized into the 
different types such as error words, abbreviation, 
proper names, derived words, foreign words, 
compounds etc. The unknown word causes 
segmentation error since the word does not exist 
in the dictionary, it could be incorrectly 
segmented into shorter words. For example, the 
word, ??????????   , which is a foreign word, gets 
segmented into four words (?? , ???? , ?? and ?? ) 
after dictionary look-up as the word ?????????? is 
not present in the corpus.  
The input is an Urdu Orthographic Word and 
the system first makes the decision if the OW 
contains single or multiple Urdu words. In case 
the OW contains multiple words, the individual 
Urdu words are extracted from the OW. These 
different stages are discussed in detail in 
following sections. As can be seen from the 
figure, at each stage we make use of lexical 
resources both from Urdu and Hindi languages. 
The details of the resources used are in Table 1. 
 
The system architecture is shown in Fig. 3. 
 
Figure 3.  System Architecture 
Table 1. Lexical resources used in system 
Resource Count 
 
Urdu Word Frequency 
List 
 
121,367 words 
Hindi Word Frequency 
List 
 
159,426 words 
Hindi Word Bigram List  2,382,511 
bigrams 
 
  
4 Decision Stage 
 
In the decision stage, the system decides if the 
OW contains single or multiple Urdu words.  It 
could so happen that the OW contains single 
word only and we may break up into smaller 
words. The decision is based on Urdu and Hindi, 
word frequency lists analysis as well as 
Urdu/English/Hindi Morphological rules. To 
decide if the word cluster is containing multiple 
words, we first search for OW in the Urdu word 
list. If it is found then it means that the OW is a 
valid Urdu word and does not need any further 
segmentation and quit over there.  
It could happen that the OW could be an 
inflection, whose root form maybe present in the 
45
Urdu word list. Even though the Urdu word list 
contains inflected forms, but for many words all 
the inflections may not be present. This problem 
is more pronounced for English terms, which 
have become part of Urdu language. For such 
words, the inflections could follow both rules of 
English and Urdu. For example plural of 
????????? (university) could be both universitiyon 
??????????????  as well as universities ??????????. 
The first form follows the Urdu infection rules 
while the second form follows the English 
inflection rules. Similarly we found both the 
Urdu and English inflections for the English 
word secretary in Urdu  text (????????? and 
????????) . Thus if the OW is not found in the 
Urdu word list, we use both Urdu and English 
morphological rules to generate its root form and 
search for the root form in the Urdu word list. If 
the root form is found, we assume the word to be 
a valid Urdu word and quit there.  
It is widely reported in word segmentation 
papers, that the greatest barrier to accurate word 
Segmentation is in recognizing words that are 
not in the lexicon of the segmenter. Thus if a 
word or its root form is not present in the Urdu 
word list it will be wrongly presumed to be a 
multi word cluster. To alleviate this problem, the 
Urdu corpus has been supplemented with Hindi 
corpus, which has helped in increasing the word 
segmentation as well as multi-word recognition 
accuracy. It was found many times that the Urdu 
word may be a proper noun, foreign word or 
some valid out of vocabulary word, which is not 
present in Urdu corpus but present in the Hindi 
word list. Another advantage of checking in the 
Hindi corpus is that many of the Hindi words, 
which are written as single word are usually 
written as two words in Urdu. For example, 
????? (?????), ?????? (????)?, ????????? 
(????????), ??????? (???????) etc. These Urdu 
words are many times written as a single word 
and in that case if passed to Hindi word list 
would still report as correct. For checking the 
OW in Hindi word list, we first transliterate it to 
Hindi and then search for it in the Hindi 
wordlist. If the transliterated word is found, then 
the OW is not considered for segmentation. Like 
Urdu, it may also happen that the root word of 
OW may be present in the Hindi word list. So 
like Urdu, we use both Urdu and English 
morphological rules to generate its root form and 
search for the root form in the Hindi word list. If 
the root form is found, we assume the word to be 
a valid Urdu word and quit there. If the OW 
passes all the above stages, then it is considered 
a candidate for segmentation. 
The steps in brief are : 
? Search for OW in Urdu List. If OW is 
present in the list then quit. example : 
????? 
? Determine the root form of OW using 
Urdu Morphological rules and search for 
the root form in Urdu List. If found then 
quit. example : ????????? 
? Determine the root form of OW using 
English Morphological rules and search 
for the root form in Urdu List. If found 
then quit. example : ????????? 
? Let HW = Transliteration of OW in 
Hindi. Search for HW in the Hindi Word 
List. If HW is present in the list then 
quit. example : ????????? 
? Determine the root form of HW using 
Hindi Morphological rules and search 
for the root form in the Hindi List. If 
found then quit.  example : ????????? 
? Determine the root form of HW using 
English Morphological rules and search 
for the root form in the Hindi List. If 
found then quit. example : ?????? 
? Go to the segmentation stage. example : 
????? 
5 Segmenting the Orthographic Word 
The Urdu orthographic word is next broken into 
Urdu Character Combinations (UCC) using 
Urdu orthographic rules. Unlike word 
segmentation that is a difficult task, segmenting 
a text into UCCs is easily achieved by applying 
the set of rules. These adjacent UCCs are then 
combined to form a sequence of Urdu words. 
We need to list all possible segmentations and 
design a strategy to select the most probable 
correct segmentation from them. 
As for example, consider the OW ??????: It is 
segmented into four UCCs : ? .?? ,?? and ? . The 
adjacent clusters can be combined to form 6 
word segmentations: 
? ???? + ?? 
? ?? + ???? 
46
? ? + ????? 
? ?? + ?? + ?? 
? ?  + ? +  ???? 
? ? + ? + ?? + ?? 
 
5.1 Longest Matching  
The method scans an input sentence from left to 
right, and select the longest match with a 
dictionary entry at each point. In case that the 
selected match cannot lead the algorithm to find 
the rest of the words in the sentence, the 
algorithm will backtrack to find the next longest 
one and continue finding the rest and so on. This 
algorithm fails to find the correct segmentation 
in many cases because of its greedy 
characteristic. 
5.2 Maximum Matching  
This method first generates all possible 
segmentations for a sentence and then selects the 
one that contain the fewest words, which can be 
done efficiently by using dynamic programming 
technique. When the alternatives have the same 
number of words, the algorithm cannot 
determine the best candidate and some other 
heuristics have to be applied.  
We tried both longest matching and maximum 
matching and the smallest unit taken for 
combining is UCC. But we found shortcomings 
in both the matchings. For example the OW 
???????? gets segmented as ??+?? +???? using 
longest matching, while it should be ??+???+??? . 
Similarly the OW ????????????? gets segmented 
as ????+?????+???? using maximum matching 
while it should be ??+??+?????+????.  
Thus we see that both longest string match and 
smallest words fail sometimes. If these 
algorithms are supplemented by statistical 
information such as frequency analysis and n-
grams then these failures can be avoided. So in 
our present work, we apply maximal matching 
algorithm along with these statistics. Initially we 
used unigram frequency of occurrence for 
deciding the best word combination. Each Urdu 
word in the combination is formed by joining 
adjacent UCCs. In each of the combination, we 
first convert each of the Urdu word to Hindi. 
The combination with highest combined product 
of the unigram frequency of occurrences is 
finally selected. Thus in the above example, the 
OW ??????: will be segmented as ???? + ??, as 
shown in Table 2. 
 
Table 2.  Product of Frequency of Occurrence 
 
Urdu 
Combination
Hindi 
Combination 
(Frequency 
of 
occurrence) 
Frequency 
Product 
??  
???? 
 
??   
(0.005161) 
????   
(0.00026) 
1.34221E-06 
 
????  
?? 
????   
(4.16E-07) 
??   
(0.001623) 
6.75557E-10 
 
?????  
? 
?????   (0) 
?   (4.48E-
05) 
0 
??  
??  
?? 
??   
(0.005161) 
??   
(0.002602) 
??   
(0.001623) 
2.18028E-08 
 
???? 
?  
? 
????   
(4.16E-07) 
?   (3.6E-05) 
?   (4.48E-
05) 
6.69866E-16 
 
?? 
??  
?  
? 
??   
(0.005161) 
??   
(0.002602) 
?   (3.6E-05) 
?   (4.48E-
05) 
2.16191E-14 
 
It is interesting to see that for segmentation of 
Urdu words, we used Hindi language statistical 
analysis instead of Urdu language statistical 
analysis. Since the current system is part of 
47
Urdu-Hindi transliteration system, we prefer the 
output to be segmented according to Hindi rules. 
There are many words which are otherwise 
joined in Hindi but written as separate words in 
Urdu. So if we use the Urdu language modeling 
for segmentation, the word gets broken. Some of 
the examples are: 
??????? is written as combination of two words 
??? +???? in Urdu but its equivalent Hindi word 
??????? is written as a single word. Similarly, 
in Hindi text the verbs are concatenated with the 
future auxiliaries ?gaa?, ?gii? and ?ge?, while 
they are written separately in Urdu. Thus ???? 
+?? are written separately, but their equivalent 
Hindi form ?????  is written as single word. So 
the advantage of using Hindi training data is that 
the words get segmented according to the 
desired Hindi rules. Another problem with Urdu 
training data was that  the Urdu training itself 
contains merged words. So the words had to be 
manually separated, though fortunately the Urdu 
corpus compiled by CRULP (www.crulp.org) 
has been quite clean, but many words were 
missing particularly English ones. Another 
problem is that the words are broken even in the 
cleaned Urdu corpus. On the other hand when 
we used the Hindi training data for word 
segmentation, the problems of merged or broken 
words in the training text were not encountered. 
Also the Hindi corpus compiled by us had much 
larger vocabulary coverage, while the Urdu 
corpus we used for training purpose had many 
common words such as  ??????  , ???? ,??????, 
????? etc. missing. Thus the word segmentation 
algorithm which used the Hindi training set had 
much better segmentation accuracy as compared 
to the Urdu training set. 
We observed that though the above scheme 
worked fine in majority of the cases, but in a few 
cases it failed to segment properly as it did not 
take care of the context or adjacent words. As 
for example consider the OW : ?????????. It 
contains six CCs: ? ,?? ,?? ,? ,?? and ?. The word 
combination selected by above methodology is : 
???? + ??? + ?? , though the correct 
combination is ???? + ?? + ???. It was observed 
that as we did not take care about adjacent 
words, thus wrong combination was selected. If 
the bigram information is added, then such 
problems were reduced.  
We thus use both unigram and bigram 
frequency analysis for deciding the best word 
combination. Each Urdu word in the 
combination is formed by joining adjacent 
UCCs. In each of the combination, we first 
convert each of the Urdu word to Hindi. Next we 
find the unigram and bigram frequency of 
occurrence of each Hindi word and Hindi word 
pair in the combination. The bigram frequencies 
are normalized to avoid multiplication by zero. 
The combination with highest combined product 
of the unigram and bigram frequencies of 
occurrences is finally selected.  Using this 
methodology we were able to generate the 
sequence combination is ???? + ?? + ??? in 
above example. 
As we are using Hindi training data, it was 
observed that sometimes we had merged words 
which did not had equivalent transliterated 
words in our Hindi frequency list. As example, 
the OW ????????? had to be segmented as ???? + 
?????, but the equivalent transliterated Hindi 
terms of ???? and ?????, were not found in the 
Hindi frequency list. As a result, the OW is not 
segmented. To take care of such situations, if we 
cannot segment using the Hindi frequency list, 
our system then goes for maximal matching 
using the Urdu training data. Thus in above 
example, after search fails in Hindi training set, 
the system searches for the minimum word 
combination and on finding the above two words 
in the Urdu training set segments the OW into 
these words. 
6 Over Segmentation 
For wrongly spelled or OOV (out of vocabulary) 
Urdu words, the system may forcibly break the 
word into smaller words. As for example, our 
system forcibly broke the OW ?????? into ?? + ?? 
+?? . This problem proved difficult to tackle, 
though we were able to partially solve it. It was 
found that usually the OOV words were broken 
into small unrelated words. So we put the 
condition on the system to accept only those 
word segments which contained at least one 
word of length greater than three or at least one 
bigram pair was present in the Hindi bigram list. 
The presence of at least one bigram pair ensured 
that all the words were not unrelated. Thus in the 
48
above example, the OW gets split into three 
words, all of length two. These words when 
transliterated to Hindi get converted to ??? + ?? 
+ ??. On searching the bigram list, it was found 
that neither of the bigram pair < ???, ?? >  and < 
?? , ?? > was present and thus this word 
segmentation was rejected. 
7 Experiments 
We tested our system on a test data of 1,613,991 
Urdu words. In the decision stage, it was found 
that 116,078  words, which make  7.19%  of 
original text were not found in the Urdu corpus 
and were considered candidates for 
segmentation. After morphological analysis of 
these words, 2851 Urdu words were found to be 
valid Uru words and were removed from the 
segmentation candidate list. After converting the 
remaining Urdu words to Hindi and checking 
them in Hindi corpus, only 35,226 words were 
left which were not present in Hindi corpus. 
Therefore from original 16,13,991 only 35,226 
(2.19%)  were passed onto segmentation stage 
for checking for merged words. 
In the segmentation stage it was found that out 
of 35,226 words, 24,001 words (68.13%) had 
merged words. The number of merged words 
varied from 2 to 6. Table 3 show the frequency 
of number of merged words found in word 
clusters. As can be seen from the table 96.71% 
of merged word clusters had two merged words.  
Table 3. Frequency of Merged Words 
Number of merged 
words  
Frequency 
Percentage 
 
2 96.71% 
3 2.99% 
4 0.25% 
5 0.037% 
6 0.004% 
  
The recall and precision for the decision 
stage, which decides if the OW needs to be 
segmented, were found to be  99.29% and 
99.38% respectively. 
The word segmentation algorithm was able to 
correctly segment the words with 99.15% 
accuracy. 
8 Conclusions 
In this paper, we have presented a system for 
solving the space omission problem in Urdu text. 
This system is part of the larger system designed 
for transliteration of Urdu text to Hindi. We 
have combined statistical language modeling of 
both Urdu and Hindi languages in development 
of the system. We have presented a new scheme 
of using Hindi for segmenting Urdu text after 
transliteration, because Hindi uses spaces 
consistently versus Urdu which has both space 
omission and insertion problems. This is the first 
time such a segmentation scheme for handling 
Urdu space omission problem has been 
presented. The word segmentation algorithm 
was able to correctly segment the words with 
99.15% accuracy.  
 
Acknowledgements 
The author will like to acknowledge the support 
provided by ISIF grants for carrying out this 
research. 
 
References 
 
Durrani N. 2007. Typology of Word and Automatic 
Word Segmentation in Urdu Text Corpus. National 
University of Computer and Emerging Sciences, 
Lahore, Pakistan. 
 
Durrani N. and Hussain Sarmad. 2010. Urdu Word 
Segmentation.http://www.crulp.org/Publication/pa
pers/2010/Urdu Word Segmentation NAACL.pdf 
(accessed on 5th July 2010). 
Jawaid Bushra and Ahmed Tafseer. 2009.  Hindi to 
Urdu Conversion: Beyond Simple Transliteration. 
Proceedings of the Conference on Language & 
Technology, Lahore,.Pakistan, 24-31. 
Lehal G. S. 2009. A Two Stage Word Segmentation 
System For Handling Space Insertion Problem In 
Urdu Script. Proceedings of World Academy of 
Science, Engineering and Technology, Bangkok, 
Thailand,  60: 321-324.  
Malik Abbas, Besacier Laurent, Boitet Christian and 
Bhattacharyya Pushpak. 2009. A hybrid Model for 
Urdu Hindi Transliteration. Proceedings of the 
49
2009 Named Entities Workshop, ACL-IJCNLP 
2009, Singapore, 177-185. 
Nie, J.Y., Hannan, M.L. & Jin, W. 1995. Combining 
dictionary, rules and statistical information in 
segmentation of Chinese. Computer Processing of 
Chinese and Oriental Languages, 9(2): 125-143. 
Papageorgiou Constantine P. 1994. Japanese word 
segmentation by hidden Markov model. Proc. of 
the HLT Workshop, 283?288. 
Wang Xiaolong, , Fu Guohong, Yeung Danial S., Liu 
James N.K., and Luk Robert. 2000. Models and 
algorithms of Chinese word segmentation. 
Proceedings of the International Conference on 
Artificial Intelligence (IC-AI?2000), Las Vegas, 
Nevada, USA, 1279-1284.  
Xu Jia, Matusov Evgeny, Zens Richard, and Ney. 
2005. Hermann.Integrated Chinese word 
segmentation in statistical machine translation. 
Proceedings of the International Workshop on 
Spoken Language Translation, Pittsburgh, PA, 
141-147. 
50
