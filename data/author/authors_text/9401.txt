Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 102?107,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Broadcast Audio and Video Bimodal Corpus Exploitation and 
Application 
 
 
Zou Yu, Hou Min, Chen Yudong, Hu Fengguo, Fu Li 
Dept. of Applied Linguistics, Presentation Art School 
Communication University of China 
Beijing 100024, P. R. China 
{zouiy;byhoumin;bychenyudong;bushiwoshishui;red_fuli}@cuc.edu.cn
 
  
 
Abstract 
The main purpose of this paper is the ex-
ploitation and application of an audio and 
video bimodal corpus of the Chinese lan-
guage in broadcasting. It deals with the 
designation of the size and structure of 
speech samples according to radio and 
television program features. Secondly, it 
discusses annotation method of broadcast 
speech with achievements made and sug-
gested future improvements. Finally, it 
presents an attempt to describe the distri-
bution of annotated items in our corpus. 
1 Introduction 
Since the year of 2002, we?ve been engaged in 
setting up the Media Language Corpus aimed to 
provide the language resources for the research-
ers who are interested in broadcasting and televi-
sion media language, for teachers and for re-
searchers of presentation art. Up till now, we 
have established a 50 million word text corpus 
involving 40 million word television program 
text corpora and 10 million word radio program 
text corpora with 10 million annotated word cor-
pora. The work of this paper is to introduce a 
ten-hour segmented and prosodic labeled broad-
cast audio & video bimodal corpus that we built 
just now. 
Section 2 of this paper describes a method for 
selection of radio and television programs to re-
cord according to program features on radio and 
television stations. Recording conditions are pro-
posed to record a quality spoken language corpus. 
Section 3 is dedicated to annotation methods. 
Section 4 shows the distribution of syllables, ini-
tials, finals and tones etc. Finally, section 5 con-
tains the conclusion and outlines of our future 
work in this field. 
2 Corpus Information 
2.1 Corpus metadata 
First of all, we have to select radio and television 
programs to record. Since a broadcast bimodal 
corpus should represent the real life usages of 
spoken language in radio and television, the dif-
ferences between radio and television, the differ-
ences between central and local televisions, and 
the categories of programs should all together be 
taken into account during the process of collect-
ing. The followings are the framework (.wav 
files & .mpeg files matched with .txt files) of 
head information (metadata) of broadcast audio 
& video bimodal corpus that has been collected: 
 
----------------------------------------------------------- 
No.: ... 
Level: central, local, Hong Kong and Taiwan 
Station: CCTV, CNR, Phoenix Television... 
Style: monologue, dialogue, multi-style 
Register: (hypogyny of monologue) presentation,  
explanation, 
reading, talk 
(hypogyny of dialogue) two person talk show, 
three person talk show, 
multi-person talk show 
Content: news, literature, service 
Audiences: woman, children, elder... 
Program: News probe, The first time... 
Sub-program: ... 
Announcer: ... 
Gender: Male /female 
Recording condition: Pinnacle PCTV pro card... 
Sample rate/Resolution: 22 KHz/16bit... 
Topic: ... 
Time: xxxx-xx-xx 
----------------------------------------------------------- 
102
 2.2 Corpus structure 
The purpose of building the broadcast spoken 
language corpus is to provide the service for the 
research of broadcast spoken language, esp. for 
the contrastive studies of the prosodic features of 
different genres of broadcast language. Hence, 
the selections of samples of the corpus mainly 
involve monologues, dialogues or both. As the 
performing forms of radio and television pro-
grams are getting more and more diverse, it is 
very difficult to decide whether a program is a 
monologue or dialogue, because these two gen-
res of programs often co-occur in one program. 
Furthermore, these kinds of programs are in-
creasing their share of radio and television pro-
grams. Consequently, this kind of program is 
most frequent in the corpus. Table 1 displays the 
structural framework of the broadcast audio and 
video bimodal corpus. 
 
Table 1 the structure of broadcast bimodal corpus 
Style Example 
two person talk 
show / interview Face to face...etc. 
three person talk 
show / interview 
Behind the Headlines 
with Wen Tao...etc. Dialogue 
multi-person talk 
show / interview Utterly challenge... 
presentation News...etc. 
explanation Music story... etc. 
reading Reading and enjoy-ing... etc. 
Mono-
logue 
talk Tonight, Weather forecast... etc. 
Multi-style News probe, The first time...etc. 
 
2.3 Recording & management information 
All the recorded data are over the programs on 
radio and TV, that is, it is recorded directly from 
radio and TV programs by Pinnacle PCTV pro 
card to connect cable TV with our recording 
computers. The recorded speech data are saved 
as 22 kHz and 16bit, Windows PCM waveform, 
the video data are saved as MPEG or WMV for-
mat file by Ulead VideoStudio in a post-
processing step. Every program or segment of 
programs is composed of three parts: *.wav 
data, *.txt data, and *.mpeg/.wmv data. 
Zhao Shixia et al(2000) pointed out that the 
structure of a speech corpus consists of synchro-
nized objects (text files, wav files, and annotated 
prosodic files), arranged in deep hierarchies (re-
cording environment), and labeled with speaker-
attribute metadata. Therefore, the managed ob-
jects of our broadcast bimodal corpus are inte-
grated programs or segments of programs. All 
data are stored separately but have complex logi-
cal inter-relations. These inter-relations can be 
obtained through the description of the programs. 
Figure 1 displays the logical structure of the 
broadcast bimodal corpus.  
 
Database 
Describing file 
of program 1
Describing file 
of program 2 
Describing file 
of program n
Audio & 
video data
Text data Labeled data
? 
Figure 1 the logic structure of broadcast audio 
and video bimodal corpus 
3 Annotation 
Why should we annotate a corpus? An annota-
tion is the fundamental act of associating some 
content to a region in a signal. The annotation 
quality and depth have a direct impact on the 
utility and possible applications of the corpus 
(Ding Xinshan 1998). The annotation of our cor-
pus consists of transcription, segmental annota-
tion, and prosodic annotation. 
3.1 Transcription and segmentation 
Transcription is primarily composed of pinyin 
transcription of Chinese characters. Besides, 
tones are annotated ?1?, ?2?, ?3?, and  ?4? after 
the syllable, the neutral tone is labeled ?0?; final 
??? annotated as ?v?, and ??e? annotated as ?ue?, 
for example, ?? (l?)? annotated as ?lv3?, ?? 
(n??)? annotated as ?nue4?. 
In the utterance, compared with broken sylla-
bles, successive speech alters greatly, due to the 
influence of co-articulation, semantics and pros-
ody. The purpose of segmental annotating is to 
annotate the altered phonemes in the syllables 
amidst the utterance. For instances, the voicing 
of some plosives (e.g. b, d, g); labial?s influence 
on alveolar nasal (e.g. ?-n? in ?renmin? affected 
by the initial of ?min? gradually change into 
?labionasal??demonstrating the similarities be-
tween alveolar nasal and labionasal initial in the 
frequency spectrum). In the places of unapparent 
pauses, the stop in the front of plosives esp. af-
103
fricates often vanishes, which are called the in-
existence of silence.  
We transcription and segmentation we used 
BSCA (Broadcasting Speech Corpus Annotator) 
which was designed by ourselves (Hu Fengguo 
and Zou Yu 2005). An annotated example is 
shown in Figure 2: 
 
 
Figure 2 BSCA: a tool for annotation 
3.2 Prosodic annotation tiers 
Prosodic annotation increases the utility of a 
speech corpus. An annotated speech corpus can 
not only offer us a database for the research and 
exploration of speech information but can also 
enlarge our knowledge of speech and prosodic 
features through a visual and scientific method. 
Prosodic annotation is a categorical descrip-
tion for the prosodic features with linguistic 
functions, in other words, annotation of the 
changes of tone, the patterns of stress, and the 
prosodic structure with linguistic functions. The 
prosodic labeling conventions are a set of ma-
chine-readable codes for transforming speech 
prosodies and rule conventions. Based on ToBI   
(Kim Silverman et al 1992, John F. Pitrelli et al 
1994) and C-ToBI Conventions (Li Aijun 2002), 
according to the practical needs of broadcast 
speech language, the prosodic annotation mainly 
involves labeling the following parallel tiers: 
break index, stress index, and intonation con-
struction tier (Chen Yudong 2004, Zou Yu 2004). 
 
3.2.1 Break indices tier 
 
Based on Cao Jianfen?s (1999, 2001) categories 
of prosodic hierarchy structure combined with 
the practical needs of broadcast speech, we iden-
tified five break levels (0-4): 0 indicates the si-
lence or the boundary of default internal sylla-
bles amidst the prosodic words. 1 stands for the 
boundaries of the prosodic words including the 
short breaks with silent pause and breaks with 
filled pause. The prosodic words are the funda-
mental prosodic units in broadcast speech. Sim-
ple prosodic words are composed of 1~3 sylla-
bles. Complex prosodic words normally contain 
5~9 syllables, e.g., ?Shang4hai3 he2zuo4 
zu3zhi1? (i.e. the Shanghai Cooperation Organi-
zation). Break level 2 designates the boundaries 
of the prosodic phrases, most of which are ap-
parent breaks with silent pause, and their patterns 
of pitch have also changed. Break level 3 repre-
sent the boundaries of intonational phrases, or 
the boundaries of sentences. Break level 4 stands 
for the boundaries of intonation groups, similar 
to the boundary of the entire piece of news in a 
news broadcast, or of a talker turn in dialogue. 
At indefinite boundaries, the code ?-? is added 
after the numbers. The labels of the break tier 
occurring times are shown in table 2: 
 
Table 2 the labels of the break tier occurring in 4 
hours annotated corpora 
Break index Occurrence 
1 1512 
2 2998 
3 1986 
4 740 
 
3.2.2 Stress indices tier 
 
Stress is a significant prosodic feature. In train-
ing materials for broadcast announcers, emphasis 
is laid on labeling the stress on the basis of the 
purpose of the utterance, the pattern and rhythm 
of stresses, and the changes of emotions. Zhang 
Song?s (1983) classification of nuclear stresses 
can be the guideline for broadcasting production 
and practice. However, there are some shortcom-
ings in his classifications, for instances, the 
vague hierarchies between the sentences and dis-
courses. This gets in the way of the formal de-
scription of the stresses by the computers. Never-
theless, his theories on the judgment of primary 
and minor stresses (i.e. non-stresses, minor 
stresses, primary stresses etc.) have some refer-
ence value for stress annotations, because distin-
guishing the hierarchies of stress is a crucial 
practical problem for annotation. 
As to the problems with the hierarchies of 
stress, most of the experimental phonetics and 
speech processing researchers adopt Lin Mao-
can?s (2001, 2002) classifications of stress hier-
archies or some similar classifications. That is to 
say, the levels of stress include prosodic word 
stress, prosodic phrase stress, and sentence stress 
(or nuclear stress) in Chinese. According to real 
life broadcasting productions, this paper identi-
104
fies four categories of stresses in broadcast 
speech: the rhythm unit, the cross rhythm unit, 
the clause, and the discourse. Among them, the 
discourse stress often occurs at the place of an 
accented syllable, but they are relatively more 
important than the other sentence stresses. The 
labeling methods of all the ranks are listed as 
follows (Chen Yudong 2004): 
 
Table 3 the stress levels in the stress indices tier 
Ranks Labels 
Rhythm unit 1 
Cross rhythm unit 2 
Clause  3 
Discourse 4 
 
Table 4 the stress levels? mean of duration in 4 
hours annotated corpora 
Stress 
indices 
Mean of dura-
tion. (seconds) Variance
1 .585 .09628
2 .790 .19405
3 .728 .24882
4 .821 .29456
 
Furthermore, Zhang Song's (1983) other crite-
ria for stress annotation (utterance purpose and 
emotion change), while perceptually important, 
are meta-linguistic or para-linguistic in character, 
and will therefore not be addressed in this paper. 
 
3.2.3 Intonation construction tier 
 
In line with Shen Jiong?s view about intonation 
(Shen Jiong 1994), we found that the intonation 
construction tier is an important component of 
the annotation of discourses (Chen Yudong 
2004). It can display the changes of sentence in-
tonation structures. The annotation of the intona-
tion construction is mainly to label the relation-
ship of other syllables to the nuclear stress apart 
from prehead, dissociation etc. For example: 
 
Table 5 the labels of the intonation construction 
tier occurring in 4 hours annotated corpora 
Labels Description Occurrence 
P Prehead 794 
H Head 2980 
N Nucleus 2400 
T Tail 1600 
W Weak in stress 2321 
D Dissociation 527 
Top Topic 269 
Conj Conjunction 87 
 
A sentence can have one nuclear stress, or 
multiple nuclear stresses. 
Single nuclear stress: representing the fore-
and-aft places of the nuclear stress, the steepness 
of nuclear stress, and the length of nuclear stress. 
Examples are listed as follows: 
P-H-N-T;  
P-H-H-N;  
... ... 
Among the above examples, long nuclear 
splitting type ?H-N-T-H-N?-T?, with the features 
of multi-nuclear ?H-N1-T-H-N2-T? is greatly 
similar to multi-nuclear. However, ?H-N-T-H-
N?-T? differs from multi-nuclear in its dependent 
grammar unit.  
Multi-nuclear stress: The two or more nuclear 
stresses in a multi-nuclear sentence take the pat-
terns of like independent sentence intonation 
constructions, each with its own nucleus, pre-
ceded by a head and optional prehead, and fol-
lowed by a tail. In other words, these relatively 
independent patterns already have the features of 
relatively independent intonation constructions, 
with the apparent features of ?prehead, head, and 
nuclear ending?. This kind of nuclear stress often 
occurs in relatively longer and more complex 
constructions. Intonation constructions can be 
labeled separately. A case in point is the contras-
tive sentence ?zai4 wen3 ding4 de0 ji1 chu3 
shang0, qu3 de2 bi3 jiao4 gao1 su4 de0 fa1 
zhan3? (i.e. It got a comparative high-speed de-
velopment on the stable conditions) that can be 
annotated as ?H-N1-T, H-N2-T?. For example: 
 
 
Figure 3 the contrastive sentence ?zai4 wen3 
ding4 de0 ji1 chu3 shang0, qu3 de2 bi3 jiao4 
gao1 su4 de0 fa1 zhan3?(?????????
????????) 
 
3.3 Other items of annotation 
Some spoken language corpus can have some 
additional annotation information. For example, 
turn talking, paralinguistic and non-linguistic 
105
information (e.g. spot, background music, cough-
ing, sobbing and sneezing) and some hosts? ac-
cents (e.g. Shanghai accent) can be annotated in 
talk show corpus. There are 82 times of spot and 
31 times of background music in 4 hours anno-
tated data. Furthermore, some .wav files, .mpeg 
files can be annotated together for discourse 
analysis. 
4 Distribution of annotated items 
We conducted a statistic analysis of some an-
notated items using 4 hours of annotated data in 
our corpus. 
The syllables (initials and finals) of the 20 top 
frequent occurring are given in Table 6. In addi-
tion to this, the duration and variance distribution 
for them are calculation shown as follows. 
 
Table 6 the mean of duration and variance of the 
top 20 frequent occurring syllables 
Syllable Occurrence 
Mean of 
duration. 
(seconds) 
Variance
de0 1993 .1167 .00232 
shi4 912 .2051 .00572 
shi2 626 .2054 .00625 
zai4 602 .1889 .00341 
le0 540 .1325 .00334 
ta1 442 .1765 .00461 
bu4 423 .1492 .00267 
guo2 404 .1673 .00328 
yi4 398 .1656 .00350 
zhong1 395 .1996 .00390 
ren2 394 .1959 .00625 
zhe4 386 .1499 .00317 
you3 380 .1841 .00480 
yi1 357 .1475 .00295 
dao4 335 .1778 .00367 
he2 309 .2078 .00687 
wo3 287 .1704 .00755 
men0 287 .1568 .00426 
yi2 274 .1555 .00320 
jiu4 250 .1724 .00332 
 
Table 7 Distribution of initials (4 hours data) 
Initials Times Initials Times
b 1076 j 3136
p 443 q 1464
m 1636 x 2146
f 972 zh 2953
d 4635 ch 1112
t 1561 sh 3406
n 1085 r 895
l 2569 z 1705
g 2162 c 512
k 879 s 700
h 2071 ? 6099
 
Table 8 Distribution of finals (4 hours data) 
Finals Times Finals Times Finals Times
a 1653 ian 1767 ua 229
ai 1909 iang 919 uai 136
an 1425 iao 773 uan 632
ang 1192 ie 838 uang 389
ao 1205 in 1175 uei 1317
e 5074 ing 1480 uen 368
ei 807 iong 128 ueng 3
en 1515 iou 1144 uo 1760
eng 1237 o 176 v 932
er 353 ong 1658 van 432
i 6856 ou 831 ve 474
ia 586 u 2533 vn 209
 
Table 9 Distribution of tones (4 hours data) 
Tones 1 2 3 4 0 
Occur-
rence 8948 9194 7401 14683 6134
 
The occurrence distribution of initial, final, 
and tone are calculated. These are shown in table 
7, 8 and 9 respectively. 
We also measured the mean duration and F0 
of each tone in three speaking styles are listed in 
Table 10 and 11. 
 
Table 10 Mean duration of tones in various 
speaking styles (seconds)  
 T1 T2 T3 T4 T0 
Presen-
tation .189 .199 .192 .180 .129
Reading .338 .337 .324 .335 .277
Talk .167 .173 .163 .163 .154
 
Table 11 F0 of tones in various speaking styles (Hz) 
 Presentation Reading Talk 
T1 162.78 158.86 207.37
min. of T2 126.39 134.46 168.73
max. of T2 147.27 155.34 180.94
range of T2 79.12 20.88 12.21
min. of T3 101.94 119.12 151.21
max. of T4 163.96 170.07 209.86
min. of T4 113.39 120.98 175.49
range of T4 50.57 49.09 34.37
 
To summarize, we conclude that the mean du-
ration of tones of reading style is longer than that 
of presentation style; that of talk style is the 
shortest among three styles. As for the F0 of each 
106
tone, the F0 and pitch range of presentation style 
is high and has big fluctuation; that of talk style 
is high and has small fluctuation. However, the 
F0 of tone 3 of presentation style is lower than 
that of reading and talk styles. 
5 Further study 
The broadcast audio and video bimodal corpus1 
is a presentation art-oriented corpus with radio 
and television news as its basis. This paper 
probes the development and compilation of 
broadcast audio and video bimodal corpus. 
Firstly, on the collection of the corpus, what 
sort of audio and video corpus can represent the 
features of radio and television speech language? 
How can we auto-annotate the audio and video 
corpus? ...These are the problems that have al-
ways been bothering us. 
Secondly, this corpus can be a platform for 
further research into non-accented or accented 
syllables, intonation construction, the prosodic 
functions of paragraphs and discourses, the emo-
tions of speech, and genre styles. 
Finally, we can statistically analyze the spec-
tral and prosodic characteristics of various speak-
ing styles by the corpora, such as presentation, 
reading and talk. All speaking styles would be 
synthesized based on the analysis results. This is 
also work for the future. 
6 Acknowledgements 
We would like to thank Prof. Wolfgang Teu-
bert for his guidance and comments on this paper. 
I would also like to thank Mr. Daniel Zhang, Jan 
Van der Ven for their kind help. 
References 
Cao Jianfen. 1999. Acoustic-phonetic Characteristics 
of the Rhythm of Standard Chinese, In Proceedings 
of 4th National Conference on Modern Phonetics, 
Beijing, pp.155~159. 
Cao Jianfen. 2001. Phonetic and Linguistic Cues in 
Chinese Prosodic Segmentation and Grouping, In 
Proceedings of 5th National Conference on Mod-
ern Phonetics, Beijing, pp.176~179. 
Chen Yudong. 2004. The Utterance Construction and 
Adjustment in Media Spoken Language, PhD thesis, 
Peking University. 
                                                 
1 This research was supported by the National Working 
Committee on Language and Characters, project no. 
YB105-61A and Communication University of China, pro-
ject no. BBU211-15. 
Ding Xinshan.1998. Development and Research of 
Corpus Linguistics, Contemporary Linguistics, 1: 
4~12. 
Hu Fengguo, Zou Yu. 2005. The Design and Exploi-
tation of Broadcasting Speech Corpus System, 
In  Proceedings of the Eighth Joint Seminar of 
Computational Linguistics (JSCL-2005), Nanjing, 
China, pp.521~527. 
John F. Pitrelli, Mary E. Beckman, and Julia 
Hirschberg. 1994. Evaluation of Prosodic Tran-
scription Labeling reliability in the ToBI Frame-
work, In Proceedings of the 1994 International 
Conference on Spoken Language Process-
ing(ICSLP), Yokohama, Japan, pp.123-126. 
Kim Silverman, Mary Beckman, John Pitrelli, Mari 
Ostendorf, Colin Wightman, Patti Price, Janet Pier-
rehumbert, and Julia Hirschberg. 1992. ToBI: A 
Standard for Labeling English Prosody, In Pro-
ceedings of the 1992 International Conference on 
Spoken Language Processing(ICSLP), Banff, Al-
berta, Canada, vol.2, pp.867-870. 
Li Aijun. 2002. Chinese Prosody and Prosodic Label-
ing of Spontaneous Speech, In Speech Prosody 
2002 An International Conference, Aix-en-
Provence, France. 
Lin Maocan. 2001. Prosodic Structure and F0 Decli-
nation in Sentence of Standard Chinese, In Pro-
ceedings of 5th National Conference on Modern 
Phonetics, Beijing, pp.180~184. 
Lin Maocan. 2002. Prosodic Structure and Construc-
tion of F0 Top-Line and Bottom-Line in Utterances 
of Standard Chinese, Contemporary Linguistics, 4: 
254~265. 
Shen Jiong. 1994. Chinese Intonation structure and 
category, Dialect, 4: 221~228. 
Zhang Song. 1983. Recitation, Changsha: Hunan Edu-
cation Press. 
Zhao Shixia, Cai Lianhong, Chang Xiaolei. 2000. 
Construction of Mandarin Corpus for Chinese 
Speech Synthesis, Mini-Micro System, Vol.21 (3): 
295~297. 
Zou Yu. 2004. Primary Research on Prosodic Label-
ing in Chinese News Broadcasting Speech, In Pro-
ceedings of the 2nd Student Workshop on Compu-
tational Linguistics (SWCL2004), Beijing, pp.1-7. 
107
CMDMC: A Diachronic Digital Museum of Chinese Mandarin
Hou Min1, Zou Yu1, Teng Yonglin1, He Wei
Wang Yan
1
1,2, Liu Jun1,2, and Wu Jiyuan1,2
1
Monitoring and Research Center at Communication University of China
Broadcast Media Language Branch, National Language Resources
2
Beijing 100024, China
School of Literature, Communication University of China
{houmin, zouiy, tengyonglin, hewei}@cuc.edu.cn?
forget1812@sina.com, {aaa_0119, wjy__00}@163.com
Abstract
Modern Chinese Mandarin has gone 
through near a hundred years, it is very 
important to store its representative 
sample in digital form permanently. In 
this paper, we propose a Chinese Man-
darin Digital Multi-modal Corpus 
(CMDMC), which is a digital speech 
museum with diachronic, opened, cross-
media and sharable features. It has over 
3460 hours video and audio files with 
metadata tagging. The materials, which 
were generated by the authoritative 
speakers (e.g. announcers at TV or radio 
station) with normality, are required 
samples if we can get them. Based on 
this resource, we also intend to analyze 
the syntactic correlations of prosodic 
phrase in broadcasting news speech, and 
compare the phonetic and prosodic fea-
tures in movie dialogues among several 
same-name movies in different histori-
cal eras.
1 Introduction
Modern Chinese Mandarin has gone through 
near a hundred years. As language changes as 
society develops, Mandarin must be periodically 
marked with the different features of different 
historical eras. It is very important to design and 
construct a Chinese Mandarin Digital Multi-
modal Corpus (CMDMC), and store its repre-
sentative sample in digital form permanently.
It?s international trend to establish large-scale 
natural language corpus, and many countries 
pay more attention to research and preserve 
their national language. For instance, the Lin-
guistic Data Consortium (LDC) is an open con-
sortium of universities, companies and govern-
ment research laboratories. It creates, collects 
and distributes speech and text databases, lex-
icons, and other resources for research and de-
velopment purposes1. Since its foundation, the 
LDC has delivered data to 197 member institu-
tions and 458 non-member institutions. Moreo-
ver, European Language Resources Association 
(ELRA)2
The paper is organized as follows: Section 2 
describes the resources and data processing of 
our CMDMC. The experiment and evaluation is 
designed and carried out in section 3. Section 4 
is dedicated to analyze the syntactic correlations 
of prosodic phrase in broadcast news speech on 
CNR (China National Radio), and compare the 
is the driving force to make available 
the language resources for language engineering 
and to evaluate language engineering technolo-
gies. In order to achieve this goal, ELRA is ac-
tive in identification, distribution, collection, 
validation, standardization, improvement, in 
promoting the production of language resources, 
in supporting the infrastructure to perform eval-
uation campaigns and in developing a scientific 
field of language resources and evaluation. In
this paper, we intend to establish the CMDMC 
with the goal of showing the history of the de-
velopment of Chinese Mandarin, and represen-
tation the real character in different historical 
eras.
1 The Linguistic Data Consortium (LDC),
http://www.ldc.upenn.edu.
2 European Language Resources Association (EL-
RA), http://www.elra.info/.
phonetic and prosodic features in movie dialo-
gues. Finally, some conclusions and outlines of 
our future work are given in section 5.
2 General Description of CMDMC
In order to show the history of the development 
of Chinese Mandarin, and representation the 
real character in different historical periods, the 
CMDMC, which is a dynamic miniature model 
(or speech museum) with diachronic, opened, 
cross-media and sharable features, is designed
and constructed by Broadcast Media Language 
Branch of National Language Resources 
Monitor & Research Center at Communication 
University of China.
In China, announcers in Radio & TV stations, 
as well as movie or stage actors, are the authori-
ty of the national language standardization. 
Therefore, the speech in radio, television and 
movie can be taken as the paradigm and repre-
sentative of Mandarin. They can reflect the 
phonetic situation of that era. All of these are 
the source of the sample data for CMDMC.
2.1 Description of Resources
In order to fully demonstrate the development 
of Chinese Mandarin by the past 100 years, we 
try to collect all the video or audio materials in 
different periods. Therefore, a state-of-the-art 
classification is defined based on the corpora 
that we got.
Language styles: According to characteristic 
speaking styles of different media, there are 
three categories was defined, such as broadcast 
media language, movie or drama dialogue, and 
the dialogue in folk art (e.g. xiangsheng, ping-
shu etc.) and so on. To sum up, the three speak-
ing styles accounted for about 64.9%, 27.2%
and 7.9% of total corpora, respectively.
Mediums: The materials can be divided into 
audio, video, text and image/picture. The audio 
or video files are the main materials in our cor-
pus, and the aligned texts are transcribed based 
on the audio or video. The documents of image 
are subsidiary corpora.
Historical eras: Based on the characteristics 
of social and language changes, we also define 
six historical stages of Chinese Mandarin: 1) 
Before1949 (or 1919-1949), it is a theoretical
stage for corpora collection. In fact, the earliest 
speech materials, which we can collect, is re-
leased in 1932; 2) 1949-1965; 3) 1966-1977; 4) 
1978-1989; 5) 1990-1999; 6) 2000 to today.
Table 1 shows the distribution of detailed data
in different eras.
Eras
Broadcast 
media
(hours)
Movie 
/drama
(hours)
Folk 
art
(hours)
Percent
of total
(%)
1932-49 39.3 1.1 
1949-65 5.2 191.4 20 6.2 
1966-77 17.5 93.0 3.2 
1978-89 52.4 145.9 75.5 7.9 
1990-99 43.5 137.5 11.5 5.6 
2000-- 2131.5 337.0 167.1 76.0 
Total 2250.1 944.1 274.1
Table 1: The distribution of video and audio 
materials in different eras.
2.2 Data Processing
The data processing includes metadata tagging, 
text transcription and aligning, phonetic and 
prosodic annotation, POS and syntactic tagging
and so on.
As for labeling prosodic phrase boundaries, 
we strictly dependent on the prosodic criteria 
and perception by using the wave files and their 
transcriptions, which use many prosodic fea-
tures such as F0 contour, energy contour etc. At 
the same time, some spoken phenomena are 
considered.
3 Experiment and Evaluation
Firstly, in order to investigate the correlations 
between prosody and syntax, about 13 hours 
speech materials were selected to segment and 
label, including break index, stress index and 
summary of emotional tendentiousness etc.
Before the real annotation, six transcribers have 
been trained in accordance with the prosodic 
labeling conventions, until a high consistency of 
prosodic annotation can be carried out.
According to above experiment and annota-
tion, the number of occurrences of the various 
boundaries was calculated in table 2.
Secondly, we also designed a perception ex-
periment to determine phonetic diversification
for elimination as much as possible the subjec-
tivity which could be caused by the different 
personal intuition of language. Ten people at-
tended the perception experiment of this study:
3 men and 7 women. The average age is 25 
years. Nearly all of them were graduates major-
ing in linguistics. During the experiment, the 
participants were asked to discriminate 12 para-
graphs of random materials and judge the natu-
ralness, pitch, and speech rate of the sentences 
produced in each paragraph. These 12 para-
graphs consisted of 4 from 21 paragraphs of the 
1995 version, 4 from 21 paragraphs of the 1975 
version and 4 from modern materials. 
Boundaries
Types Index Marker Frequency
PW 1 /1, /1+ 55237
PP 2 /2 28867
C-PP 2 /2* 5976
IP 3 /3 7147
IG 4 /4 2781
MEC 5 /5 1770
Table 2: Distribution of all boundaries. The PW, 
PP, C-PP, IP, IG and MEC are the abbreviation of 
prosodic word, normal prosodic phrase, complex 
prosodic phrase, intonational phrase, intonational 
group and meaning expression cluster respectively.
In the perceptive procedure, we disordered all 
these materials for experiment, and three choic-
es were given to these ten people: 1) natural, in 
conformity with the standard of modern Manda-
rin; 2) fairly natural, close to the standard of 
modern Mandarin; 3) unnatural, a little stagy. 
Every paragraph was released twice with an 
interval of 10 seconds. After one hour of conti-
nuous work, a 10-minute break was given.
Only the results with at least a 90% agree-
ment rate were considered for analysis. 
4 Related Works
Based on this resource, we intend to analyze the 
syntactic correlations of prosodic phrase in 
broadcasting news speech on CNR, and com-
pare the phonetic and prosodic features in 
movie dialogues among several same-name 
movies in different historical eras.
4.1 Correlation between Syntax & Prosody
In English, there is a strong correlation between 
prosodic phrase boundaries and syntactic phrase 
boundaries (Price et al 1991). That is to say, 
prosodic phrase boundaries can play an impor-
tant role in understanding utterance as punctua-
tion marks do in written language. An investiga-
tion propose that boundary strength according to 
the measure, which the boundary strength is 
applied to syntactic structures and the phrase 
structure is viewed as an immediate constituen-
cy tree exclusively, corresponds much more 
closely to empirical prosodic boundary strength 
than does syntactic boundary strength according 
to a standard measure (Abney, 1992). In Greek, 
some study indicated that prosodic phrasing has 
a 95% identification rate, and a major effect on 
final tonal boundaries (Botinis et al 2004).
In Chinese, some researchers also proposed a 
statistical model to predict prosodic words from 
lexical words. In their model, both length of the 
word and the tagging from POS are two essen-
tial features to predict prosodic words, and the 
results showed approximately 90% of prediction 
for prosodic words (Chen at el. 2004).
What the correlation between syntax and 
prosody is in Chinese broadcasting news speech?
In order to investigate the syntactic correlations 
of prosodic phrase in real read speech on radio, 
we chose the representative speech materials 
from Xinwen he Baozhi Zhaiyao (News and 
Newspapers Summary) from CMDMC, which is 
a very famous broadcast news program of CNR.
This news program contains more syntactic, 
semantic and prosodic information, speaking
styles and high quality voice in real context. 
Therefore, 908 programs, which contain 454 
hours speech data from January 2006 to June 
2008, were selected for pre-processing. After 
the pre-processing step, we selected two fe-
male?s 13 hours speech materials (one female 
announcer?s material forms the main data, and 
another one?s is supplemented for comparable 
data) as a core database, which segmentation, 
transcription and prosodic annotation (including 
break index, stress index and summary of emo-
tional tendentiousness etc) was made by six 
transcribers. 
According to the characteristic of broadcast-
ing news speech, a new prosodic hierarchical 
structure (Zou et al 2009) and two different 
types of prosodic phrase (i.e. the normal prosod-
ic phrase and the complex prosodic phrase) 
boundaries were defined and used in our data 
labeling.
Top pitch value Bottom pitch value
Categories Location N SD Mean N SD Mean
PW Left 3478 3.917 16.1 3253 4.761 8.5
Right 3701 4.894 14.7 3165 5.457 9.9
PP Left 1741 3.891 14.7 1718 4.302 6.2
Right 627 3.481 16.5 492 5.077 9.3
C-PP Left 314 4.085 13.5 317 4.135 4.8
Right 361 3.616 17.9 285 5.092 10.0
IP Left 536 4.817 12.9 456 5.575 3.9
Right 531 3.019 18.8 473 3.720 13.8
IG Left 211 4.363 11.4 203 6.055 4.7
Right 229 2.377 19.4 185 2.927 15.0
MEC Left 104 4.238 8.1 95 4.937 2.6
Right 22 2.178 18.7 12 2.893 16.2
Table 3: The distribution of pitch on different boundaries. The phonetic acoustic data of each 
syllable was extracted by Praat script, and the foundational frequency was normalized by semi-
tones, the normalization formula is ST=12*log (F0/Fref)/log2 (the female?s reference frequency 
is 100Hz). (?top? is the mean of the highest pitch value at the first tone and the fourth tone; 
?bottom? is the mean of the lowest pitch value at the third tone and the fourth tone; ?N? refers 
the number of samples; ?SD? is the abbreviation of standard deviation)
In the further step, we selected 100 minutes 
speech materials from core annotated data, and 
investigated its features of pitch and duration at 
boundary (Zou et al 2010). The detailed data 
are shown in table 3 and 4 respectively.
Boundaries
Types Marker N Mean SD
PW /1 or/1+ 118 65.2 61.714
PP /2 659 97.6 84.140
C-PP /2* 193 108.7 82.483
IP /3 877 343.2 138.906
IG /4 375 699.2 254.287
MEC /5 31 771.0 208.580
Table 4: The mean of silent pause duration at
boundaries.
There are two ways of representation to pitch 
feature at prosodic boundary: Firstly, the pitch 
contour is un-continuity; secondly, the pitch 
resetting of the declination contour (de Pijper et 
al 1994). According to Table 3, we can find that 
there is a few resetting of bottom pitch value at 
PW boundary, that is to say, the bottom of the
PW boundary right is 1.4 semitones higher than 
that of its left. At other boundaries, the bottom 
pitch values at right side are much higher than 
that at left side, for instance, there is 3.1, 5.2, 
9.9, 11.3 and 13.6 semitones resetting from PP 
to MEC boundary successively. Especially, at 
the IP boundary its resetting has about two 
times than that of C-PP boundary. This shows 
that there are very obvious prosodic feature at 
various boundaries in broadcasting news speech.
Generally, we know that 90ms is the floor of 
threshold for perceiving the silent pause. From 
Table 4, the mean of silent pause duration from 
long to short followed by MEC > IG > IP > C-
PP > PP > PW. Except there is no perceived 
silent pause at PW boundary, the other bounda-
ries have obvious silent pause that can be per-
ceived. The length of silent pause at PP and C-
PP are 97.6ms and 108.7ms respectively, and 
the length at IP has over three times longer than 
that at C-PP. According to this, we propose that 
the PP and C-PP lie in the same position at the 
prosodic hierarchical structure, and the C-PP is 
a special prosodic phrase.
From our core data we got 6728 C-PPs. Ac-
cording to the C-PP that contains the number of 
PW, we divided them into four categories, such 
as three-PW, four-PW, five-PW and six-PW. 
The distribution of them is shown in Table 5.
After preliminary analysis we found that the 
C-PP, which contains three PWs, has a simple 
syntactic structure although it is absolute major-
ity in the number, and that is compose of four 
PWs should be done for correlations of prosody 
and syntax. There are about 6 types of prosodic 
structure if the C-PP contains four PWs. The 
detail data of this type C-PP followed in table 6.
From the data, we know that the fourth type, 
which is (A+B) +(C+D), is the most, and that is 
composed by (A+B) +C+D is the least in all of 
the six types. Although there are just six types 
of prosodic structure that can be found, there are 
more than 985 syntactic categories in this 1835 
C-PPs. There are 23 types which occur more 
than 10 times, and most of them occur only one 
time. To some extent, it can explain that the 
syntactic structure is more complex than the 
prosodic one.
An example of prosodic and syntactic struc-
tures in the utterance, which is ou1 yang2 yu3 
hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 
ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand), is given in 
figure 1. The left side of figure is the prosodic 
structure, and the syntactic one lies at the right 
side.
In figure 1, there is a little difference of jin3 
jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (???
??????) between its prosodic structure 
?A+(B+C+D)? and its syntactic structure ?[VP 
[VP jin3jin0/adv bao4zhu4/v] [NP [AP 
lou2ti1/n de0/u] [NP lan2gan1/n]]]?, but the 
differences between its prosodic and syntactic 
structure are obvious because the jin3 jin0 is 
stressed in speech for semantic expression.
Categories Example Num.
Three-PW ??/1+ ??/1 ??/2* 4433
Four-PW ???/1+ ??/1 ??/1 ??/2* 1835
Five-PW ??/1 ??/2 ??/1 ??/1 ??/2* 414
Six-PW ?/1+ ??/1 ??/2 ??/1 ??/2 ??/2* 46
Total 6728
Table 5: The distribution of four kinds of C-PP
Types Example Num. Percent (%)
A+(B+C)+D ?/1+ ??/1 ??/2 ??/2* 441 24.03
A+(B+C+D) ??/1+ ?/1 ?/1 ???/2* 495 26.98
A+B+(C+D) ??/1+ ??/1+ ??/1 ??/2* 97 5.29
(A+B)+(C+D) ?/1 ??/2 ??/1 ??/2* 529 28.83
(A+B+C)+D ??/1 ??/1 ??/2 ??/2* 259 14.11
(A+B)+C+D ?/1 ??/2 ??/2 ??/2* 14 0.76
Total 1835 100
Table 6: The distribution of prosodic type in C-PP of four-PW
Figure 1: An example of (a) prosodic structure vs. (b) syntactic structure in an utterance: ou1 yang2 
yu3 hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand).
Figure 2: The pitch contour of the same utterance.
Figure 2 shows the pitch contour of the same 
utterance. In this utterance, there is a nesting 
structure at jin3 jin0 bao4 zhu4 lou2 ti1 de0 
lan2 gan1 (held fast to the staircase railing)
based on the length of perceived silent pause. 
Furthermore, the pitch declination trend within 
the C-PP is obvious despite small resetting be-
tween zhu4 and lou2. So we suggest that there is 
a stable prosodic pattern within a C-PP in 
broadcasting news speech.
Conversely, what is the correlation between 
the prosody and syntax? From above analysis, 
we know that the conjunction and particle, such
as?(de0), ?(deng3),?(he2), ?(dan4) and so 
on, more likely attached to the end of left struc-
ture or the beginning of right one and form a 
prosodic word. If it has just four lexical words 
including the conjunction or particle they form a 
prosodic word by itself. That is to say, it has 
very great flexibility in prosodic structures for 
conjunctions and particles, such as ? ?
(zhan4)/1+ ??(quan2guo2)/1 ??(shi1di4)/1 
???(mian4ji1 de0)/2* (occupy/1+ country-
wide/1everglade/1 acreage/2*)?, ??(he2)/1 ?
? (she4hui4)/2 ? ? (jiu4zhu4)/1 ? ?
(zhi4du4)/2* (and/1 social/2 assistance/1 sys-
tem/2*)? and so on.
4.2 Diachronic Comparative Phonetic and 
Prosodic Analysis in Movie Dialogues
Which diachronic phonetic changes happened in 
Mandarin by the past 100 years? We also ana-
lyze and compare the phonetic features of Chi-
nese Mandarin among several same-name mov-
ies in different historical eras from CMDMC
(Wang et al 2010). In order to minimize the 
divergence of the variables and maximize the 
reliability of conclusions, we chose two pairs of 
same-name movies screened in different histori-
cal periods. These movies are: Pingyuan Youji-
dui (The Plains Guerrillas) shot in 1955 and 
1975, Dujiang Zhencha Ji (Reconnaissance 
across the Yangtze River) shot in 1954 and 1974 
respectively.
Pitch Feature: In the analysis of pitch, we 
put aside the stresses and the neutral tone syl-
lables, and make the statistical investigations on 
the top pitch value and the bottom pitch value of 
the syllables.
Figure 3: The pitch data of 1955 and 1975 ver-
sion in the Plains Guerrillas. The fundamental 
frequency also was normalized by semitones;
the male?s reference frequency is 50Hz.
Figure 3 shows that the mean of the top pitch 
value in the 1950s? materials is lower than that 
of 1970s?. In the 1955 version, the leading cha-
racter, Speaker A, possesses a mean value of the 
top pitch value which is 20.9 semitones. This 
value is lower than that of 1975s? by a differ-
ence of 0.9 semitones. The negative character, 
Speaker B, has a mean value of the top pitch 
value which is 24.5 semitones in the 1955 ver-
sion. The value in the 1975 version is 27 semi-
tones, with a difference of 2.5 semitones left, 
also showing that the value in the 1975 version 
is comparatively high. Comparing the data of 
the bottom pitch value in the 1955 version with 
that in the 1975 version, we know that these 
data seem closer than the top pitch value, but 
still the higher ones belong to the 1975 version. 
That the bottom pitch value is higher tells us 
that the whole pitch register is raised.
Furthermore, we can easily see from Figure 3
that the pitch range of the same character in the 
1975 version is wider. Speaker A of the 1955 
version has a pitch range of 4.8 semitones. In 
contrast, the same character in the 1975 version 
has a pitch range of 6 semitones. Speaker C of
the 1955 version has 4 semitones pitch range, 
but in the 1975 version, he has 5.9 semitones 
pitch range. The gap between them is 1.9 semi-
tones. Through this comparison, we find that the 
pitch range in the 1975 version is wider than 
that in the 1955 version in the whole. 
To some extent, the speaking, both the top
pitch value and the bottom pitch value in the 
1975 version are higher. This proves that, on the 
whole, the pitch of the 1970s? materials is high-
er and more unnatural than that of 50s? because 
of the effect by the Cultural Revolution era.
And this also proves the feeling of the partici-
pants in the perceptional experiment at section 3 
about the 1970s? materials, that is, the 1970s?
Mandarin has a loud and sonorous voice; the 
characters pronounce harder; the general pitch is 
higher.
Duration feature: In the respect of duration, 
we also compared and analyzed the presenters?
speech on TV in 20053
According to table 7, there is a little differ-
ence of the durations mean among them (fol-
lowing four tones), especially it?s very closely 
between the 1975 and the 2005, and those of the 
1975 version are a few longer than those of the 
1955 version. But, except the first tone (Sig. 
=.077), the differences of the duration means 
between the others, which is in the 1955, the 
with the materials ex-
tracted from the movie dialogues the 1955 and 
the 1975. Table 7 is the relevant data.
3 In this work, we just chose the male?s speech data 
from Zou (2007).
1975 and the 2005, are significant (Sig. 
=.000, .000, .002?.05 respectively).
mean SD N
Movie:1955 T1 153.6 69.5 243
T2 136.8 58.1 242
T3 132.8 58.7 321
T4 133.5 52.0 539
Movie:1975 T1 177.8 72.1 258
T2 155.5 52.0 263
T3 152.5 57.6 289
T4 156.7 59.9 505
TV: 2005 T1 163.1 65.7 1471
T2 156.0 66.5 1743
T3 156.8 67.6 1054
T4 145.9 62.3 2652
Table 7: The duration mean of four tones in 
movie dialogues (1955 and 1975) vs. that of
presenters? spoken language on TV in 2005(ms).
Demonstrations of the four-syllable pro-
sodic words: The comparative pitch contour of 
two four-syllable prosodic words, which are 
?bu2 yao4 lu4 mian4? (don?t appear) and ?gan4
shen2 me0 de0? (What are you doing?), are 
shown in Figure 4 and 5, respectively.
Figure 4: The pitch contour of ?bu2 yao4 lu4
mian4? (don?t appear)
Figure 5: The pitch contour of ?gan4 shen2 me0
de0? (What are you doing?)
By observing the above two figures, we find 
that the pitch contour of the 1975 and that of the 
1955 are almost identical except the latter is 
always lower than the former. This may explain 
that although the Mandarin has gone through a 
hundred years, the pitch pattern is relatively 
stable.
5 Conclusions and Future Work
This paper proposes to design a Chinese 
Mandarin Digital Multi-modal Corpus
(CMDMC). Through this corpus, the historical 
trace of Mandarin development can be followed;
the fresh and alive data and material resources 
can be drawn up for the modern researchers and 
successors. We also intend to analyze the syn-
tactic correlations of prosodic phrase in broad-
casting news speech, and compare the phonetic 
and prosodic features in movie dialogues among 
several same-name movies in different histori-
cal eras. The contributions are as follows.
Firstly, the syntactic structure is more com-
plex than the prosodic structure, some conjunc-
tion and particle, such as de0, deng3, he2, dan4
and so on, more likely attached to the end of left 
structure or the beginning of right one and form 
a prosodic word, if the number of lexical words 
mismatch the prosodic words. Otherwise, they 
have almost similar structure.
Secondly, the speech of 1970s in last century 
is greatly influenced by the special era. People 
usually use exaggerated voice, pronounce hard 
and raise the pitch unnaturally, giving others a 
taste of lecturing and ordering. In contrast, the 
speech of Mandarin in 1950s is more natural 
and close to the daily life pronunciation and 
intonation. Even so, the pitch patterns have no 
big changes, and this may explain that the pitch
patterns are comparatively stable in Chinese 
Mandarin.
Future research will include treatment of cor-
relation between syntax and prosody within IP
or IG, ideally comparing the diachronic phonet-
ic or prosodic changes in Mandarin by the past 
100 years. Additionally, we would like to tackle 
the problem of data management, update and 
periodical increasing as time passes.
6 Acknowledgements
This work was supported by the Department of 
Science and Technology at Ministry of Educa-
tion (No. 107118), and ?211? Key Projects of 
Communication University of China (No. 
21103010105, 21103010106). We would like to 
thank the anonymous reviewers for their in-
sightful comments.
References
Abney, S. 1992. Prosodic Structure, Performance 
Structure and Phrase Structure. Proceedings of 5th 
Darpa Workshop on Speech & Natural Language.
Botinis, A., Ganetsou, S., Griva, M., and Bizani, H.
2004. Prosodic Phrasing and Syntactic Structure 
in Greek. Proceedings of FONETIK 2004, Dept. 
of Linguistics, Stockholm University.
Chen, Keh-jiann, Tseng, Chiu-yu, Peng, Hua-jiu and 
Chen, Chi-ching. 2004. Predicting Prosodic 
Words from Lexical Words -- A First Step to-
wards Predicting Prosody from Text . Proceed-
ings of the 4th International Symposium on Chi-
nese Spoken Language Processing (ISCSLP 2004).
Hong Kong, 173-176.
de Pijper, J. R., and Sanderman, A. A. 1994. On the 
Perceptual Strength of Prosodic Boundaries and 
its Relation to Suprasegmental Cues. Journal of 
the Acoustical Society of America, 96(4), 2037-
2047.
Price, P., Ostendorf, M., Shattuck-Hufnagel, S., and 
Fong, C. 1991. The Use of Prosody in Syntactic 
Disambiguation. Journal of the Acoustic Society 
of American, 90, 2956-2970.
Wang Yan, Liu Jun, Kan Minggang, Hou Min, Zou 
Yu. 2010. Phonetic Diachronic Diversification in 
Mandarin: A Case of the Same Movie?s Dialogue 
in 1950s and 1970s. Proc. of YWCL 2010, Wuhan, 
Hubei, Oct 10-13. (Accepted)
Zou Yu. 2007. A Formal Study on Prosody of Pre-
senter's Spoken Language Based on Broadcast 
Speech Corpus. PhD thesis, Communication Uni-
versity of China.
Zou Yu, He Wei, Zhang Yuqiang, Hou Min and Zhu 
Weibin. 2009. A Special Prosodic Phrasing in 
Broadcasting News Programs. Computational 
Sciences and Optimization: Theory, Simulation 
and Experiment (Vol. 2), Sanya, Hainan, China, 
24-26 April, 406-408.
Zou Yu, Wu Jiyuan, He Wei, Hou Min, Teng Yon-
glin. 2010. Syntactic Correlations of Prosodic 
Phrase in Broadcasting News Speech. The 6th 
IEEE International Conference on Natural Lan-
guage Processing and Knowledge Engineering 
(NLP-KE 2010), Beijing, China, Aug. 21-23.
