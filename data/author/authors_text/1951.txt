Dialogue Interaction with the DARPA Communicator
Infrastructure: The
Development of Useful Software
Samuel Bayer
The MITRE Corporation
 202 Burlington Rd.
Bedford, MA 01730
sam@mitre.org
Christine Doran
The MITRE Corporation
 202 Burlington Rd.
Bedford, MA 01730
cdoran@mitre.org
Bryan George
The MITRE Corporation
11493 Sunset Hills Rd.
Reston, VA 20190
bgeorge@mitre.org
ABSTRACT
To support engaging human users in robust, mixed-initiative
speech dialogue interactions which reach beyond current
capabilities in dialogue systems, the DARPA Communicator
program [1] is  funding the development of a distributed
message-passing infrastructure for dialogue systems which all
Communicator participants are using. In this presentation, we
describe the features of and requirements for a genuinely
useful software infrastructure for this purpose.
Keywords
Spoken dialogue, speech interfaces
1. INTRODUCTION
Over the last five years, three technological advances have
cooperated to push speech-enabled dialogue systems back
into the limelight: the availability of robust real-time speech
recognition tools, the explosion of Internet-accessible
information sources, and the proliferation of mobile
information access devices such as cell phones. However, the
systems being fielded, and the standards arising from these
efforts, represent only a limited set of capabilities for robust
voice-enabled interaction with knowledge sources. The most
prominent indication of these limitations is the fact that these
systems are overwhelmingly system-directed; the system asks
a question, and the user responds. While this type of
interactions sidesteps a number of problems in speech
recognition and dialogue tracking, it is overwhelmingly likely
that these restrictions are not manageable in the long term.
The DARPA Communicator program [1] is exploring how to
engage human users in robust, mixed-initiative speech
dialogue interactions which reach beyond current capabilities
in dialogue systems. To support this exploration, the
Communicator program has funded the development of a
distributed message-passing infrastructure for dialogue
systems which all Communicator participants are using. In
this presentation, we describe the features of and requirements
for a genuinely useful software infrastructure for this purpose.
2. BUILDING USEFUL SOFTWARE
The Galaxy Communicator software infrastructure (GCSI) is an
elaboration and extension of MIT's Galaxy-II distributed
infrastructure for dialogue interaction [3]. The fact that all
program participants are required to use the GCSI imposes a
somewhat more severe set of requirements on the infrastructure
than usual, and these requirements range far beyond the
straightforward considerations of functionality.
? Flexibility: the infrastructure should be flexible enough
to encompass the range of interaction strategies that the
various Communicator sites might experiment with
? Obtainability: the infrastructure should be easy to get
and to install
? Learnability: the infrastructure should be easy to learn to
use
? Embeddability: the infrastructure should be easy to
embed into other software programs
? Maintenance: the infrastructure should be supported and
maintained for the Communicator program
? Leverage: the infrastructure should support longer-term
program and research goals for distributed dialogue
systems
3. FLEXIBILITY
The GCSI is a distributed hub-and-spoke architecture based on
message-passing. The hub of the GCSI incorporates a scripting
mechanism that allows the programmer to take control of the
message traffic by implementing "hub programs" in a simple
scripting language. The benefits of this sort of infrastructure
are considerable in the context of exploring different
interaction and control strategies for dialogue. For example:
? Because the infrastructure is based on message-passing
instead of APIs, there's no need for the hub to have any
compile-time knowledge of the functional properties of
the servers it communicates with (in contrast to, for
instance, a CORBA infrastructure).
? Because the hub scripting allows the programmer to alter
the flow of control of messages, it's possible to integrate
servers with a variety of implicit interaction paradigms
(e.g., synchronous vs. asynchronous) without modifying
the servers themselves
? Because the hub scripting allows the programmer to alter
the flow of control of messages, it's possible to insert
simple tools and filters to convert data among formats
without modifying the servers themselves.
? Because the hub scripting language fires rules based on
aspects of the hub state, it's easy to write programs which
modify the message flow of control in real time.
4. OBTAINABILITY
We believe that the simplest licensing and distribution model
for software like the GCSI is an open source model. With the
appropriate open source licensing properties, there are no
barriers to freely distributing and redistributing the GCSI, or
to distributing dialogue systems created using the GCSI, or to
building commercial products based on it. The GCSI i s
distributed under a modified version of the MIT X Consortium
license, and we are reasonably certain that the license
simplifies all these tasks. In particular, two Communicator
sites are planning to distribute their entire dialogue systems
as open source, which would not be possible without
appropriate licensing of the GCSI.
It's also important to address the level of complexity of
installing the software once it's obtained. Research software i s
notoriously hard to install, and it's far more useful to ensure
that the software can be used straightforwardly on a small
number of common platforms and operating systems than to
try to make it run on as many platforms as possible. We've
targeted the three platforms which the program participants
were developing on: Windows NT, Intel Linux, and Sparc
Solaris. The GCSI is known to work or to have worked on other
configurations (HP-UX and SGI IRIX, for instance), but these
configurations are not supported in any meaningful way. The
open source model can help here, too: if someone wants to port
the infrastructure to a BSD OS, for instance, they have all the
source (and will hopefully contribute their modifications to
the open source code base).
5. LEARNABILITY
Once the software is installed, it's important to know where to
start and how to proceed. We have offered a series of two-day
intensive training courses on the Communicator infrastructure
which have been attended by the majority of Communicator
participants. In addition, the GCSI comes with extensive
documentation and examples, including a toy end-to-end
dialogue system example which illustrates one possible
configuration of Communicator-compliant servers. Our goal i s
to ensure that it's possible to learn to use the Communicator
infrastructure from the documentation alone, and at least two
sites have succeeded in creating dialogue systems using the
GCSI in a short period of time without attending our training
course.
6. EMBEDDABILITY
The GCSI includes libraries and templates to create
Communicator-compliant servers in C, Java, Python, and
Allegro Common Lisp. However, it's not enough to provide a
software library; this library has to be well-behaved in a
number of ways. In particular, if the GCSI is to be used in
conjunction with CORBA or various windowing systems, i t
must be possible to embed the GCSI server libraries into other
main loops, and to control all the features of the GCSI without
controlling the toplevel flow of control. To enable this goal,
the GCSI is based on a straightforward event-based
programming model, which is used to implement the default
Communicator server main loop, as well as the implementation
of the Python and Allegro server libraries. The GCSI i s
distributed with a number of examples illustrating this
embedding.
7. MAINTENANCE
Finally, GCSI consumers must be able to rely on getting help
when something goes wrong, and expect that design and
implementation problems will be rectified and that desired
complex behaviors will be supported. The importance of
responsiveness and flexibility in maintenance is one of the
reasons we prefer the GCSI for Communicator instead of a
third-party tool such as SRI's Open Agent Architecture [2],
which the Communicator program does not control the
development of.
In addition to maintaining a bug queue for the GCSI, we have
addressed successively more complicated infrastructure
requirements in successive releases of the GCSI. For instance,
in the most recent release (3.0), we addressed infrastructure
support for asynchronous delegation strategies being
explored by the Communicator effort at MIT and issues
relating to consumption of audio input by multiple
recognizers.
8. LEVERAGE
Ultimately, we hope that the GCSI, together with open-source
servers such as recognizers, parsers, synthesizers and dialogue
modules provided by application developers, will foster a
vigorous explosion of work in speech-enabled dialogue
systems. For example:
? The programming-language-independent nature of the
GCSI message-passing paradigm allows the
Communicator program to develop implementation-
independent service standards for recognition, synthesis,
and other better-understood resources.
? The freely available nature of the GCSI allows application
developers to contribute dialogue system modules which
are already configured to work with other components.
? The availability of an "environment" for dialogue system
development will support the development of an open
source "toolkit" of state-of-the art, freely available
modules. A number of Communicator sites are already
releasing such modules.
? A common infrastructure will contribute to the
elaboration of "best practice" in dialogue system
development.
There are certainly a number of emerging and existing
alternatives to the GCSI for dialogue system development
(SRI's Open Agent Architecture, for instance). However, we
believe that the combination of a software package like the
GCSI and the critical mass generated by its use in the DARPA
Communicator program presents a unique opportunity for
progress in this area.
The GCSI is available under an open source license at
http://fofoca.mitre.org/download.
9. ACKNOWLEDGMENTS
This work was funded by the DARPA Communicator program
under contract number DAAB07-99-C201.  ? 2001 The MITRE
Corporation. All rights reserved.
10. REFERENCES
[1] http://www.darpa.mil/ito/research/com/index.html.
[2] D. L. Martin, A. J. Cheyer, and D. B. Moran. The
open agent architecture: A framework for building
distributed software systems. Applied Artificial
Intelligence, vol. 13, pp. 91--128, January-March
1999.
[3] S. Seneff, E. Hurley, R. Lau, C. Pao, P. Schmid, and
V. Zue. Galaxy-II: A Reference Architecture for
Conversational System Development. Proc. ICSLP
98, Sydney, Australia, November 1998.
Exploring Speech-Enabled Dialogue with the Galaxy
Communicator Infrastructure
Samuel Bayer
The MITRE Corporation
 202 Burlington Rd.
Bedford, MA 01730
sam@mitre.org
Christine Doran
The MITRE Corporation
 202 Burlington Rd.
Bedford, MA 01730
cdoran@mitre.org
Bryan George
The MITRE Corporation
11493 Sunset Hills Rd.
Reston, VA 20190
bgeorge@mitre.org
ABSTRACT
This demonstration will motivate some of the significant
properties of the Galaxy Communicator Software Infrastructure
and show  how  they support the goals of the DARPA
Communicator program.
Keywords
Spoken dialogue, speech interfaces
1. INTRODUCTION
The DARPA Communicator program [1], now in its second
fiscal year, is intended to push the boundaries of speech-
enabled dialogue systems by enabling a freer interchange
between human and machine. A crucial enabling technology
for the DARPA Communicator program is the Galaxy
Communicator software infrastructure (GCSI), which provides
a common software platform for dialogue system development.
This infrastructure was initially designed and constructed by
MIT [2], and is now maintained and enhanced by the MITRE
Corporation. This demonstration will motivate some of the
significant properties of this infrastructure and show how they
support the goals of the DARPA Communicator program.
2. HIGHLIGHTED PROPERTIES
The GCSI is a distributed hub-and-spoke infrastructure which
allows the programmer to develop Communicator-compliant
servers in C, C++, Java, Python, or Allegro Common Lisp. This
system is based on message passing rather than CORBA- or
RPC-style APIs. The hub in this infrastructure supports
routing of messages consisting of key-value pairs, but also
supports logging and rule-based scripting. Such an
infrastructure has the following desirable properties:
? The scripting capabilities of the hub allow the
programmer to weave together servers which may not
otherwise have been intended to work together, by
rerouting messages and their responses and transforming
their keys.
? The scripting capabilities of the hub allow the
programmer to insert simple tools and filters to convert
data among formats.
? The scripting capabilities of the hub make it easy to
modify the message flow of control in real time.
? The scripting capabilities of the hub and the simplicity of
message passing make it simple to build up systems bit
by bit.
? The standard infrastructure allows the Communicator
program to develop platform- and programming-
language-independent service standards for recognition,
synthesis, and other better-understood resources.
? The standard infrastructure allows members of the
Communicator program to contribute generally useful
tools to other program participants.
This demonstration will illustrate a number of these
properties.
3. DEMO CONFIGURATION AND
CONTENT
By way of illustration, this demo will simulate a process of
assembling a Communicator-compliant system, while at the
same time exemplifying some of the more powerful aspects of
the infrastructure. The demonstration has three phases,
representing three successively more complex configuration
steps. We use a graphical display of the Communicator hub to
make it easy to see the behavior of this system.
As you can see in Figure 1, the hub is connected to eight
servers:
? MITRE's Java Desktop Audio Server (JDAS)
? MIT SUMMIT recognizer, using MIT's Mercury travel
domain language model
? CMU Sphinx recognizer, with a Communicator-compliant
wrapper written by the University of Colorado Center for
Spoken Language Research (CSLR), using CSLR's travel
domain language model
? A string conversion server, for managing
incompatibilities between recognizer output and
synthesizer input
? CSLR's concatenative Phrase TTS synthesizer, using their
travel domain voice
? CMU/Edinburgh Festival synthesizer, with a
Communicator-compliant wrapper written by CSLR, using
CMU's travel domain language model for Festival's
concatenative voice
? MIT TINA parser, using MIT's Mercury travel domain
language model
? MIT Genesis paraphraser, using MIT's Mercury travel
domain language model
Figure 1: Initial demo configuration
We will use the flexibility of the GCSI, and the hub scripting
language in particular, to change the path that messages follow
among these servers.
3.1 Phase 1
In phase 1, we establish audio connectivity. JDAS is MITRE's
contribution to the problem of reliable access to audio
resources. It is based on JavaSound 1.0 (distributed with JDK
1.3), and supports barge-in. We show the capabilities of JDAS
by having the system echo the speaker's input; we also
demonstrate the barge-in capabilities of JDAS bye showing
that the speaker can interrupt the playback with a new
utterance/input. The goal in building JDAS is that anyone who
has a desktop microphone and the Communicator
infrastructure will be able to use this audio server to establish
connectivity with any Communicator-compliant recognizer or
synthesizer.
3.2 Changing the message path
The hub maintains a number of information states. The
Communicator hub script which the developer writes can both
access and update these information states, and we can invoke
"programs" in the Communicator hub script by sending
messages to the hub. This demonstration exploits this
capability by using messages sent from the graphical display
to change the path that messages follow, as illustrated in
Figure 2. In phase 1, the hub script routed messages from JDAS
back to JDAS (enabled by the message named "Echo"). In the
next phase, we will change the path of messages from JDAS
and send them to a speech recognizer.
Figure 2: Modifying the hub information state
3.3 Phase 2
Now that we've established audio connectivity, we can add
recognition and synthesis. In this configuration, we will route
the output of the preferred recognizer to the preferred
synthesizer. When we change the path through the hub script
using the graphical display, the preferred servers are
highlighted. Figure 3 shows that the initial configuration of
phase 2 prefers SUMMIT and Festival.
Figure 3:  Initial recognition/synthesis configuration
The SUMMIT recognizer and the Festival synthesizer were not
intended to work together; in fact, while there is a good deal of
activity in the area of establishing data standards for various
aspects of dialogue systems (cf. [3]), there are no
programming-language-independent service definitions for
speech. The hub scripting capability, however, allows these
tools to be incorporated into the same configuration and to
interact with each other. The remaining incompatibilities (for
instance, the differences in markup between the recognizer
output and the input the synthesizer expects) are addressed by
the string server, which can intervene between the recognizer
and synthesizer. So the GCSI makes it easy both to connect a
variety of tools to the hub and make them interoperate, as well
as to insert simple filters and processors to facilitate the
interoperation.
In addition to being able to send general messages to the hub,
the user can use the graphical display to send messages
associated with particular servers. So we can change the
preferred recognizer or synthesizer. (as shown in Figure 4), or
change the Festival voice (as shown in Figure 5). All these
messages are configurable from the hub script.
Figure 4: Preferring a recognizer
Figure 5: Changing the Festival voice
3.4 Phase 3
Now that we've established connectivity with recognition and
synthesis, we can add parsing and generation (or, in this case,
input paraphrase). Figure 6 illustrates the final configuration,
after changing recognizer and synthesizer preferences. In this
phase, the output of the recognizer is routed to the parser,
which produces a structure which is then paraphrased and then
sent to the synthesizer. So for instance, the user might say "I'd
like to fly to Tacoma", and after parsing and paraphrase, the
output from the synthesizer might be "A trip to Tacoma".
Figure 6: Adding parsing and paraphrase
4. CONCLUSION
The configuration at the end of phase 3 is obviously not a
complete dialogue system; this configuration is missing
context management and dialogue control, as well as an
application backend, as illustrated by the remaining
components in white in Figure 7. However, the purpose of the
demonstration is to illustrate the ease of plug-and-play
experiments within the GCSI, and the role of these capabilities
to assemble and debug a complex Communicator interface. The
GCSI is available under an open source license at
http://fofoca.mitre.org/download    .
Figure 7: A sample full dialogue system configuration
5. ACKNOWLEDGMENTS
This work was funded by the DARPA Communicator program
under contract number DAAB07-99-C201.  ? 2001 The MITRE
Corporation. All rights reserved.
6. REFERENCES
[1] http://www.darpa.mil/ito/research/com/index.html.
[2] S. Seneff, E. Hurley, R. Lau, C. Pao, P. Schmid, and
V. Zue. Galaxy-II: A Reference Architecture for
Conversational System Development. Proc. ICSLP
98, Sydney, Australia, November 1998.
[3] "'Voice Browser' Activity." http://www.w3.org/Voice.
Finding Errors Automatically in
Semantically Tagged Dialogues
John Aberdeen, Christine Doran, Laurie Damianos,
Samuel Bayer and Lynette Hirschman
The MITRE Corporation
202 Burlington Road
Bedford, MA 01730 USA
+1.781.271.2000
{aberdeen,cdoran,laurie,sam,lynette}@mitre.org
ABSTRACT
We describe a novel method for detecting errors in task-based
human-computer (HC) dialogues by automatically deriving
them from semantic tags. We examined 27 HC dialogues from
the DARPA Communicator air travel domain, comparing user
inputs to system responses to look for slot value
discrepancies, both automatically and manually. For the
automatic method, we labeled the dialogues with semantic tags
corresponding to "slots" that would be filled in "frames" in
the course of the travel task. We then applied an automatic
algorithm to detect errors in the dialogues. The same dialogues
were also manually tagged (by a different annotator) to label
errors directly. An analysis of the results of the two tagging
methods indicates that it may be possible to detect errors
automatically in this way, but our method needs further work
to reduce the number of false errors detected. Finally, we
present a discussion of the differing results from the two
tagging methods.
Keywords
Dialogue, Error detection, DARPA Communicator.
1. INTRODUCTION
In studying the contrasts between human-computer (HC) and
human-human (HH) dialogues [1] it is clear that many HC
dialogues are plagued by disruptive errors that are rarely seen
in HH dialogues. A comparison of HC and HH dialogues may
help us understand such errors. Conversely, the ability to
detect errors in dialogues is critical to understanding the
differences between HC and HH communication.
Understanding HC errors is also crucial to improving HC
interaction, making it more robust, trustworthy and efficient.
The goal of the work described in this paper is to provide an
annotation scheme that allows automatic calculation of
misunderstandings and repairs, based on semantic information
presented at each turn. If we represent a dialogue as a sequence
of pairs of partially-filled semantic frames (one for the user?s
utterances, and one for the user?s view of the system state), we
can annotate the accumulation and revision of information in
the paired frames.  We hypothesized that, with such a
representation, it would be straightforward to detect when the
two views of the dialogue differ (a misunderstanding), where
the difference originated (source of error), and when the two
views reconverge (correction). This would be beneficial
because semantic annotation often is used for independent rea-
sons, such as measurements of concepts per turn [8],
information bit rate [9], and currently active concepts [10].
Given this, if our hypothesis is correct, then by viewing
semantic annotation as a representation of filling slots in user
and system frames, it should be possible to detect errors
automatically with little or no additional annotation.
2. SEMANTIC TAGGING
We tagged 27 dialogues from 4 different systems that
participated in a data collection conducted by the DARPA
Communicator  program in the summer of 2000. These are
dialogues between paid subjects and spoken language
dialogue systems operating in the air travel domain. Each
dialogue was labeled with semantic tags by one annotator. We
focused on just the surface information available in the
dialogues, to minimize inferences made by the annotator.
The semantic tags may be described along two basic
dimensions: slot and type. The slot dimension describes the
items in a semantic frame that are filled over the course of a
dialogue, such as DEPART_CITY and AIRLINE (see Table 1 for
the complete list).
The type dimension describes whether the tag is a PROMPT, a
FILL, or an OFFER. This type dimension is critical to semantic
analysis since it allows one to describe the effect a tag has on
slots in the frame. PROMPTs are attempts to gather values to
fill slots, e.g., "what city do you want to fly to". FILLs are
actual slot fills, e.g., "I?d like to fly to San Francisco". OFFERs
represent actual flight information based on previous slot
FILLs, e.g., "there is a 9:45 flight to San Francisco on Delta".
However, OFFERs often do not exactly match slot FILLs (e.g.,
the user requests a flight at 9:30, but the closest match flight
is at 9:45), and thus must be distinguished from FILLs.
In addition to the two basic dimensions of slot and type, each
tag takes a leg attribute to indicate which leg of a trip is being
discussed. There is also an initial USER_ID slot which has two
types (PROMPT_USER_ID and FILL_USER_ID), but no leg
attribute.
Our semantic tag set alo includes two special tags, YES and
NO, for annotating responses to offers and yes/no questions.
Finally, we have two tags, PROMPT_ERASE_ FRAMES and
FILL_ERASE_FRAMES, for annotating situations where the
frames are erased and the dialogue is restarted (e.g., the user
says "start over"). Figure 1 shows part of a sample dialogue
with semantic tags. Our semantic tagset is summarized in Table
1.
Table 1. Semantic Tagset
PROMPT FILL OFFER
DEPART_CITY X X X
ARRIVE_CITY X X X
DEPART_AIRPORT X X X
ARRIVE_AIRPORT X X X
DATE X X X
DEPART_TIME X X X
ARRIVE_TIME X X X
AIRLINE X X X
USER_ID X X
ERASE_FRAMES X X
YES (single bare tag)
NO (single bare tag)
3. ERROR DETECTION
To provide a baseline for comparison to an algorithm that
detects errors automatically, we had an annotator (not the same
person who did the semantic tagging described above)
manually tag the problem areas. This annotator marked four
items:
(1) occurrence: where the problem first occurs in the
dialogue (e.g. where the user says the item which the
system later incorporates incorrectly)
(2) detection: where the user could first be aware that
there is a problem (e.g. where the system reveals its
mistake)
(3) correction attempt: where the user attempts to repair
the error
(4) correction detection: where the user is first able to
detect that the repair has succeeded
We next developed an algorithm for automatically finding
errors in our semantically tagged dialogues. In this phase of
the research, we concentrated on deriving an automatic method
for assigning the first two of the four error categories,
occurrence and detection (in a later phase we plan to develop
automatic methods for correction attempt and correction
detection). First, the algorithm derives the turn-by-turn frame
states for both the user's utterances and the system's utterances
(i.e., what the user heard the system say), paying special
attention to confirmation tags such as YES or deletion tags
like FILL_ERASE_FRAMES. Then, the algorithm compares
patterns of user and system events to hypothesize errors.
Occurences and detections are hypothesized for three types of
errors: hallucinations (system slot fill without user slot fill),
mismatches (system slot fill does not match user slot fill), and
prompts after fills (system prompt after user slot fill).
Figure 2 shows a sample dialogue that illustrates several error
types. Utterance S12 shows a prompt after fill error ? the user
has already supplied (in utterance U11) the information the
system is requesting. In utterance U13 the user supplies
contradictory information, and the system catches this and
tries to resolve it in utterances S14 and S16. Next a mismatch
error is illustrated ? the user specifies ARRIVE_CITY in
utterance U17, and the system shows that it has misrecognized
Figure 1. Portion of a Sample Dialogue Labeled with Semantic Tags
 S0: System said: Welcome to our travel planning system.
<prompt_user_id>Please say your PIN number</prompt_user_id>.
U1: User said: My PIN is <fill_user_id>four four four four</fill_user_id>.
 S2: Sys tem said: What are your travel plans?
U3: User said: I want to go to <fill_arrive_city leg=?1?>San Francisco</fill_arrive_city>.
 S4: System said: Traveling to <fill_arrive_city leg=?1?>San Francisco</fill_arrive_city>.
<prompt_depart_city leg=?1?>Where are you departing from?</prompt_depart_city>
U5: User said: <fill_depart_city leg=?1?>Boston</fill_depart_city>.
 S6: System said: <prompt_date leg=?1?>When would you like to leave</prompt_date>
<fill_depart_city leg=?1?>Boston</fill_depart_city>?
U7: User said: <fill_date leg=?1?>July twenty-fifth</fill_date> at
<fill_depart_time leg=?1?>12 noon</fill_depart_time>.
 S8: System said: I have a <offer_airline leg=?1?>Delta</offer_airline> flight that leaves
<offer_depart_city leg=?1?>Boston</offer_depart_city> at
<offer_depart_time leg=?1?>11:10AM</offer_depart_time> on
<offer_date leg=?1?>July twenty-fifth</offer_date> and arrives in
<offer_arrive_city leg=?1?>San Francisco</offer_arrive_city> at
<offer_arrive_time>5:19PM</offer_arrive_time>. Is that OK?
it in utterance S18. The user attempts to correct this
misrecognition in utterance U21, and as can be seen from
utterance S22, the system again has misrecognized the user?s
utterance.
Below we describe the results from running the automatic
algorithm on our 27 semantically tagged dialogues.
4. RESULTS
In the 27 dialogues considered, a total of 131 items were
flagged by one or both of the methods as error items (60 occur,
71 detect). A breakdown of these errors and which method
found them is in Table 2.
Table 2. Unique Errors Identified
# errors found by: Occur Detect Total
Both Methods 14 23 37
Automatic Only 28 38 66
Manual Only 18 10 28
Totals 60 71 131
As can be seen in Table 2 the automatic method flagged many
more items as errors than the manual method.
Table 3. Error Judgements
Occur Detect
E NE Q E NE Q
Auto 48% 40% 12% 52% 38% 10%
Man 84% 13% 3% 82% 15% 3%
We carefully examined each of the items flagged as errors by
the two methods. Three judges (the semantic tagging
annotator, the manual error tagging annotator, and a third
person who did not participate in the annotation) determined
which of the errors found by each of the two methods were real
errors (E), not real errors (NE), or questionable (Q). For
calculations in the present analysis, we used E as the baseline
of real errors, rather than E+Q. Table 3 shows the judgements
made for both the automatic and manual method, which are
discussed in the next section. It is important to note that
human annotators do not perform this task perfectly, with error
rates of 13% and 15%. This is also shown in the precision and
recall numbers for the two methods in Table 4.
Table 4. Precision & Recall
Occur DetectPrecision
& Recall P R P R
Automatic 0.48 0.57 0.52 0.84
Manual 0.84 0.77 0.82 0.71
5. ANALYSIS
The automatic method flagged 40 items as errors that the
judges determined were not errors (17 occur, 23 detect). These
40 false errors can be classified as follows:
A. 10 were due to bugs in the algorithm or source data
B. 19 were false errors that can be eliminated with non-
trivial changes to the semantic tagset and/or algorithm
C. 3 were false errors that could not be eliminated
without the ability to make inferences about world
knowledge
D. 8 were due to mistakes made by the semantic
annotator
One example of the 19 false errors above in B is when the first
user utterance in a dialogue is a bare location, it is unclear
whether the user intends it to be a departure or arrival location.
Our semantic tagset currently has no tags for ambiguous
situations such as these. Adding underspecified tags to our
tagset (and updating the automatic algorithm appropriately)
would solve this problem. Another example is a situation
where a system was legitimately asking for clarification about
a slot fill, but the algorithm flagged it as prompting for keys
that had already been filled. This could be fixed by adding a
CLARIFY element to the type dimension (currently PROMPT,
FILL, and OFFER). We believe that making these changes
would not compromise the generality of our semantic tagset.
However, as the point of our approach is to derive errors
without much additional annotation, additions to the semantic
tagset should only be made when there is substantial
justification.
There were also 21 errors (15 occur, 6 detect) that were not
detected by the automatic method, but were judged as real
errors. These 21 errors may be categorized as follows:
A. 2 were due to bugs in the algorithm
B. 8 were situations where the algorithm correctly
flagged the detect point of an error, but missed the
associated occur point
C. 6 were situations that could be fixed by
modifications to the semantic tagset
D. 1 was an error that could be fixed either by a
revision to the semantic tagset or a revision to the
algorithm
E. 2 were situations where the system ignored a user
fill, and the automatic algorithm interpreted it as no
confirmation (not an error). Human judgement is
required to detect these errors
F. 2 were due to mistakes made by the semantic
annotator
6. PREVIOUS WORK
In Hirschman & Pao [5], annotation was done by manual
inspection of the exchanges in the dialogue. Each exchange
was evaluated based on the portion of information "visible to
the other party". Errors and problems were identified manually
and traced back to their point of origin. This is quite similar to
our baseline manual annotation described in section 3.
There have been other approaches to detecting and
characterizing errors in HC dialogues. Danieli [2] used
expectations to model future user ut terances, and Levow [6][7]
used utterance and pause duration, as well as pitch variability
to characterize errors and corrections. Dybkj?r, Bernsen &
Dybkj?r [4] developed a set of principles of cooperative HC
dialogue, as well as a taxonomy of errors typed according to
which of the principles are violated. Finally, Walker et. al.
[11][12] have trained an automatic classifier that identifies
and predicts problems in HC dialogues.
7. DISCUSSION
It is clear that our algorithm and semantic tagset, as they stand
now, need improvements to reduce the number of false errors
detected. However, even now the automatic method offers some
advantages over tagging errors manually, the most important
of which is that many researchers already annotate their
dialogues with semantic tags for other purposes and thus
many errors can be detected with no additional annotation.
Also, the automatic method associates errors with particular
slots, enabling researchers to pinpoint aspects of their
dialogue management strategy that need the most work.
Finally, Day et. al. [3] have shown that correcting existing
annotations is more time efficient than annotating from
scratch. In this way, the automatic method may be used to
"seed" an annotation effort, with later hand correction.
8. ACKNOWLEDGMENTS
This work was funded by the DARPA Communicator program
under contract number DAAB07-99-C201.  ? 2001 The MITRE
Corporation. All rights reserved.
9. REFERENCES
[1] Aberdeen, J. and Doran, C. Human-computer and human-
human dialogues. DARPA Communicator Principle
Investigators Meeting (Philadelphia, PA USA 2000).
http://www.dsic-web.net/ito/meetings/communicator
_sep2000/
[2] Danieli, M. On the use of expectations for detecting and
repairing human-machine miscommunication.
Proceedings of AAAI Workshop on Detecting, Repairing
and Preventing Human-Machine Miscommunication
(Portland OR, USA 1996).
[3] Day, D., Aberdeen, J., Hirschman, L., Kozierok, R.,
Robinson, P. and Vilain, M. Mixed-initiative
development of language processing systems. In
Proceedings of the Fifth Conference on Applied Natural
Language Processing (Washington DC, USA 1997).
[4] Dybkj?r, L., Bernsen, N.O. and Dybkj?r, H. Reducing
miscommunication in spoken human-machine dialogue.
Proceedings of AAAI Workshop on Detecting, Repairing
and Preventing Human-Machine Miscommunication
(Portland OR, USA 1996).
[5] Hirschman, L. and Pao, C. The cost of errors in a spoken
language system. Proceedings of the Third European
Figure 2. Portion of a Sample Dialogue Illustrating Several Errors
   U11: User said: I want to fly from <fill_depart_city leg=?1?>Seattle</fill_depart_city> to
<fill_arrive_city leg=?1?>Tokyo</fill_arrive_city>
     S12: System said: <prompt_arrive_city leg="1">to which city would you like to fly</prompt_arrive_city>
from <fill_depart_city leg="1">seattle</fill_depart_city>
U13: User said: <fill_arrive_city leg="1">seattle washington</fill_arrive_city>
    S14: System said: excuse me, i didn't hear you well. I think you want to fly from
<fill_depart_city leg="1">seattle</fill_depart_city> If this is okay, let's continue. Otherwise,
please specify the locations again.
  U15: User said: <yes>that's okay</yes>
    S16: System said: <prompt_arrive_city leg="1">what city would you like to fly to?</prompt_arrive_city>
    U17: User said: <fill_arrive_city leg="1">tokyo japan</fill_arrive_city>
     S18: System said: flying to <fill_arrive_city leg="1">togiak</fill_arrive_city>
<prompt_date leg="1">on what date?</prompt_date>
  U19: User said: <fill_date leg="1">monday September twenty fifth</fill_date>
  S20: System said: there don't seem to be any flights from <fill_depart_city leg="1">seattle</fill_depart_city>
to <fill_arrive_city leg="1">togiak</fill_arrive_city> which depart
<fill_depart_time leg="1">about ten PM</fill_depart_time> on
<fill_date leg="1">september twenty fifth</fill_date>.
  U21: User said:  destination <fill_arrive_city leg="1">tokyo japan</fill_arrive_city>
  S22: System said: did you say you want to fly to
<prompt_arrive_city leg="1">san diego</prompt_arrive_city>?
Conference on Speech Communication and Technology
(Berlin, Germany 1993).
[6] Levow, G.A. Characterizing and recognizing spoken
corrections in human-computer dialogue. Proceedings of
COLING-ACL (Montreal, Canada 1998).
[7] Levow, G.A. Understanding recognition failures in spoken
corrections in human-computer dialogue. Proceedings of
ECSA Workshop on Dialogue and Prosody (Eindhoven,
The Netherlands 1999).
[8] Luo, X. and Papineni, K. IBM DARPA Communicator v1.0.
DARPA Communicator Principle Investigators Meeting
(Philadelphia, PA USA 2000). http://www.dsic-web.net
/ito/meetings/communicator_sep2000/
[9] Polifroni, J. and Seneff, S. Galaxy-II as an architecture for
spoken dialogue evaluation. Proceedings of the Second
International Conference on Language Resources and
Evaluation (Athens, Greece 2000).
[10] Rudnicky, A. CMU Communicator. DARPA Communicator
Principle Investigators Meeting (Philadelphia, PA USA
2000). http://www.dsic-web.net/ito/meetings
/communicator_sep2000/
[11] Walker, M., Langkilde, I., Wright, J., Gorin, A. and Litman,
D. Learning to predict problematic situations in a spoken
dialogue system: experiments with how may I help you?
Proceedings of the Seventeenth International Conference
on Machine Learning (Stanford, CA USA 2000).
[12] Walker, M., Wright, J. and Langkilde, I. Using natural
language processing and discourse features to identify
understanding errors in a spoken dialogue system.
Proceedings of the North American Meeting of the
Association of Computational Linguistics (Seattle, WA
USA 2000).
Comparing Several Aspects of Human-Computer and
Human-Human Dialogues
Christine Doran, John Aberdeen, Laurie Damianos and Lynette Hirschman
The MITRE Corporation
202 Burlington Road
Bedford, MA 01730 USA
{cdoran,aberdeen,laurie,lynette}@mitre.org
Abstract
While researchers have many intuitions
about the differences between human-
computer and human-human interac-
tions, most of these have not previously
been subject to empirical scrutiny. This
work presents some initial experiments
in this direction, with the ultimate goal
being to use what we learn to improve
computer dialogue systems. Working
with data from the air travel domain,
we identified a number of striking dif-
ferences between the human-human and
human-computer interactions.
1 Introduction
In our initial experiments comparing human-
human (HH) and human-computer (HC) inter-
action we have annotated dialogues from the air
travel domain with several sets of tags: dialogue
act, initiative and unsolicited information. Our
aim is to begin an empirical exploration of how
these aspects of the dialogue shed light on dif-
ferences between HH and HC interactions. We
found striking differences between the human-
human and human-computer interactions. With
many of the issues we examine here, researchers
have voiced strong intuitions about the differences
between HH and HC communication, but these in-
tuitions have not previously been subject to em-
pirical scrutiny.
Why do we want to compare HH and HC in-
teractions? We believe that an examination of
the differences between HH and HC dialogues can
help those working on the HC interactions to im-
prove their systems. This will not necessarily
mean making the HC interactions ?more like? HH
interactions; rather, we believe that such analy-
sis can give us insights about the appropriateness
and success of various communicative approaches
in different settings. We are also interested in
quantifying what it means for a dialogue to be
?mixed-initiative?. There is liberal use of this
term in work on human-computer dialogues, but
there does not seem to be a clear sense of what it
really means and how to define it.
This work is being done in the context of the
Communicator Travel task. Communicator is a
DARPA-funded program involving major indus-
try and academic sites, established to provide the
next generation of intelligent conversational inter-
faces to distributed information. The goal of the
program is to move beyond the current system
initiated voice menu style of dialogue interaction
towards a more flexible strategy of shared con-
versational control between human and system.
Work up to the fall of 2000 concentrated on the
travel task, but groups are now moving into other
domains with their dialogue systems.
2 Our Data
We have tagged 20 HH dialogues and 40
HC dialogues; the HH dialogues consist of
25,208 words and 1742 turns, and the HC
dialogues consist of 8313 words and 957
turns. The HH dialogues are from the SRI
ATIS collection (available at www.ai.sri.com/?
communic/amex/amex.html) and the CMU Travel
data (www.speech.cs.cmu.edu). The HC dia-
logues are from a subset of the systems partici-
pating in the DARPA Communicator data collec-
tion which was run in June and July of 2000.1
Subjects were selected by the U.S. National In-
stitute of Standards and Technology (NIST) and
each subject was paid to call all of the 9 partic-
ipating sites with either a fixed or open travel
itinerary. The fixed itineraries were intended to
balance flight types (one-way, round-trip, multi-
leg) and destinations (large US airport, small for-
1Ideally, of course, we would want HH dialogues
collected under similar circumstances to the HC dia-
logues. However, no such data are available and col-
lecting new HH data is not currently a feasible en-
deavor for us.
eign airport, etc.).2 We made no attempt to bal-
ance the subset of data we analyzed; we merely
selected 10 random users. We then identified four
sites whose systems we expected to differ quite
widely (based on researchers? descriptions of their
systems), and extracted the 10 users? dialogues for
each site. Each dialogue was tagged with three
sets of annotations?for dialogue acts, for initia-
tive and for provision of unsolicited information
by users (HC only). Sections 2.1, 2.2 and 3.5 de-
scribe these in more detail. The passage below
is excerpted from one of the human-computer in-
teractions, using the transcribed versions of the
user?s turns.3
User said: i would like to fly from miami
florida to sydney australia on wednesday
october eleventh please
System said: okay, from Miami to Sydney on
Wednesday October 11. Can you provide the
approximate departure time or airline?
User said: [um] i prefer american airlines
and i can leave anytime
System said: There are no nonstop flights.
I have a flight connecting in Los Angeles
leaving at 7:15 a.m. a flight connecting
in Los Angeles leaving at 5:20 p.m. and a
flight connecting in Los Angeles leaving
at 7:30 p.m. Do you like any of these?
User said: yes how about the morning one
System said: American flight 912 connecting
to American flight 7362 in Los Angeles has
been added to your itinerary. you depart
Miami at 7:15 am and arrive in Sydney at
9:40 pm the following day. Where would you
like to go next?
2.1 Dialogue Act Tagging
We have done two rounds of tagging. Our start-
ing point was a 20-tag subset of the CSTAR Con-
sortium tags (Consortium, 1999). We found the
CSTAR tag set to be the most suitable for our
task of the tagging schemes we considered, based
on information provided in the survey of dialogue
act annotation schemes assembled by the MATE
project (Klein et al, 1998). We picked the CSTAR
tags because they had been designed for task-
2It is important to note that the fixed itineraries
were assigned, i.e. not real trips, and it was also evi-
dent from the transcripts that few if any of the open
itineraries represented real trips. This may well have
had some impact on the data that were collected.
3Both human-human and human-system dialogue
transcripts are reproduced with their native format-
ting, i.e. all caps, no punctuation, etc. The system
side contains punctuation resulting from the genera-
tion process.
oriented dialogues, the tag categories were suffi-
ciently clear and simple that we believed we would
be able to tag the data reliably and, finally, the
categories captured the sorts of distinctions we be-
lieved would be relevant. We rejected the DAMSL
tag set (Core and Allen, 1997; Core et al, 1999)
on the grounds that is was too sophisticated for
our purposes, covering many aspects of dialogue
structure that were not necessarily relevant for our
task such as intentionality, grounding and context
tracking. In addition, the interannotator agree-
ment levels reported for this scheme are quite low.
Some of the other tag sets we considered were
(Carletta et al, 1995; Nakatani et al, 1995; van
Vark et al, 1996; Di Eugenio et al, 1998; Jurafsky
et al, 1997).
In collaboration with AT&T, we arrived at a
set of changes to our tag set that would make
it compatible with their efforts to tag system ut-
terances automatically (Walker and Passonneau,
2001), in the hopes of being able to share re-
sults with them more easily. We added a sit-
uation/conversation/task distinction to a num-
ber of our tags (e.g. give-information split
into give-task-info, give-situation-info and
give-conversation-info). We also added a
not-understand tag and collapsed some orig-
inal tags into super-categories. Our revised tag
set had 26 tags, and two people (one who had
also done the first round of tagging) tagged the
same data set. The situation/conversation/task
distinction turned out to be extremely difficult for
the taggers to make; we believe that revisions to
the tagging guidelines could lead to some improve-
ment on this front, but without enumerating the
kinds of utterances which fall into each category,
this will remain a difficult task.
We tagged each utterance that contained some
speech, i.e. was not composed entirely of non-
speech annotation like *pause* or [click], and
we split turns4 into utterances using guidelines
that had been developed internally for another
purpose. Utterances on this definition were
roughly clause-sized units, and possibly fragmen-
tary.5 This meant that there were often multi-
ple dialogue acts (DAs) per turn, and where there
were multiple sequential DAs of the same type, we
collapsed them under a single tag on the assump-
tion that they were combining to ?perform? that
DA. We initially split some of the CSTAR tags
4Chunk of text labelled with either User said or
Expert said. It was possible for a single speaker to have
more than one sequential turn, i.e. turn 6= speaker
change.
5In hindsight, it would have been preferable to seg-
ment the dialogues in a separate step.
into implicit and explicit versions, but found
that the implicit cases were so hard to identify
that we were not using those tags, and they were
dropped from the tag set.
Tables 1 and 2 show roughly parallel sub-
dialogues from the HH and HC data.6 Each turn
is tagged with its DA, and the first expert turn
in Table 2 shows multiple DAs within a turn, a
give-information followed by an offer.
Expert:WHAT TIME DO [req-task-info]
YOU NEED TO DEPART
User:AS SOON AS [give-task-info]
POSSIBLE AFTER FIVE P.M.
Expert:THE FIRST FLIGHT [give-task-info]
AFTER FIVE P.M. ON THAT DATE IS
AT FIVE THIRTY FIVE P.M. ARRIVING
IN CHICAGO AT SIX OH SIX P.M.
ON U.S. AIR
User: IS THAT O?HARE [req-task-info]
Table 1: DA tagging in an HH Exchange
Expert: i have an American [give-task-info]
Airlines flight departing Seattle at
twelve fifty five p.m., arrives Tokyo
at three p.m. the next day.
Is that OK? [offer]
User: yes I?ll take it [accept]
Expert: Will you return to seattle[req-task-info]
from tokyo?
User: what airport [req-task-info]
Expert: Will you return to seattle[req-task-info]
from tokyo?
Table 2: DA tagging in an HC Exchange
With our first tag set, our Kappa score for
interannotator agreement on these dialogues is
0.90 (with two annotators). Not surprisingly, our
Kappa score on the second, more complex tag set
(cf. Table 10 for a list of the tags) was lower,
0.71 (0.74 on the HC data and 0.66 on the HH
data). Both scores are in line with scores re-
ported in similar tagging tasks (Klein et al, 1998):
0.56 for DAMSL (overall average), 0.83 for Map-
task (experienced coders), 0.8-0.84 for Switch-
board DAMSL and 0.83 for VerbMobil. The drop
in score between our two tag sets emphasizes an
issue which we continue to wrestle with?the trade-
off between tag set complexity and tagging accu-
racy. At what point is it more useful to have re-
6Throughout the paper, we will use expert to refer
to either the human or the computer travel agent, sys-
tem to refer exclusively to the computer travel agent,
and user to refer to the travelers.
liable results from an impoverished tag set than
results of questionable value from a sophisticated
tag set?
2.2 Initiative Tagging
There is not a clearly agreed upon definition of ini-
tiative in the literature on dialogue analysis (but
see e.g., (Chu-Carroll and Brown, 1998; Jordan
and Di Eugenio, 1997; Flammia and Zue, 1997)),
despite the fact the terms initiative and mixed-
initiative are widely used. Intuitively, it seems
that control rests with the participant who is mov-
ing a conversation ahead at a given point, or se-
lecting new topics for conversation.
After experimenting with several tagging meth-
ods, we concluded that the approach presented
in Walker and Whittaker (1990) adopted from
(Whittaker and Stenton, 1988) best captured the
aspects of the dialogue we were interested in and,
as with the DAs, could be tagged reliably on our
data.
Each turn is tagged with which participant has
control at the end of that turn, based on the utter-
ance type. Again, we did not tag turns composed
entirely of non-speech annotation, and we also ex-
cluded conventional openings and closings, follow-
ing Walker and Whittaker. Below, we list the
rules for tagging each utterance type; a prompt
is an utterance ?which did not express proposi-
tional content, such as Yeah, Okay, Uh-huh, . . . .?
(Op cit, p. 3) The classification refers to the il-
locutionary force of the item, rather than to its
particular syntactic form.
Assertion: speaker has initiative unless it is a
response to a question or command7
Question: speaker has initiative unless it is a re-
sponse to a question or command
Command: speaker has initiative
Prompt: hearer has initiative
Tables 3 and 4 show the same passages used
above, but this time tagged for initiative. To give
a sense of how the tagging rules are applied, let us
step through the HC example (Table 4). Turn (1)
is assigned expert-initiative, because it is an
assertion which is not a response to any preceding
question or command. Turn (2) is still expert-
initiative, because it is an answer to the ques-
tion Is that OK?. The third turn is a question
and expert-initiative, but turn (4) is user-
initiative because it is a question that is not a
response to the previous question. The system
7Italics show our modification to the rule.
does not address the user?s question, but rather
repeats its own question, so the final turn (5) is
expert-initiative.
Expert:WHAT TIME DO YOU [exp-init]
NEED TO DEPART
User:AS SOON AS POSSIBLE [exp-init]
AFTER FIVE P.M.
Expert:THE FIRST FLIGHT AFTER [exp-init]
FIVE P.M. ON THAT DATE IS AT
FIVE THIRTY FIVE P.M.
ARRIVING IN CHICAGO AT
SIX OH SIX P.M. ON U.S. AIR
User:IS THAT O?HARE [user-init]
Table 3: Initiative tagging in an HH Exchange
(1)Expert: i have an American [exp-init]
Airlines flight departing Seattle at
twelve fifty five p.m. , arrives Tokyo
at three p.m. the next day.
Is that OK?
(2)User: yes I?ll take it [exp-init]
(3)Expert: Will you return to seattle [exp-init]
from tokyo?
(4)User: what airport [user-init]
(5)Expert: Will you return to seattle [exp-init]
from tokyo?
Table 4: Initiative tagging in an HC Exchange
Our Kappa scores for interannotator agreement
on the initiative tagging were somewhat lower
than for DA tagging. Here, ?=0.68. In fact, our
agreement was rather high, at 87%, but because
there were so few instances of user initiative in
the HC dialogues, our agreement would have to
be exceptional to be reflected in a higher Kappa
score. While we had believed this to be the easier
task, with quite clear guidelines and only a binary
tagging choice, it in fact proved to be quite diffi-
cult. We still believe that this tag set can give
us useful insights into our data, but we would
be interested in attempting further revisions to
the tagging guidelines, particularly as regards the
definition of an ?answer?, i.e. when an answer is
responsive and when it is not.
3 Analysis
We found a number of interesting differences be-
tween the HH and HC dialogues. While we have
not yet been able to test our hypotheses about
why these differences appear, we will discuss our
ideas about them and what sorts of further work
we would like to do to subject those ideas to em-
pirical validation.
3.1 Initiative Distribution
Based on researchers? descriptions of their systems
(i.e. for the most part, ?highly mixed-initiative?),
we had expected to find some variance in the dis-
tribution of initiative across systems. As is ev-
ident from Table 5, the HC systems do not dif-
fer much from each other, but taken as whole,
the dialogues differ dramatically from the HH di-
alogues. In the HH dialogues, users and expert
share the initiative relatively equitably, while in
the HC data the experts massively dominate in
taking the initiative. Here, we are simply counting
the number of turns tagged as user-initiative or
expert-initiative.8
We also show turns to completion and overall
user satisfaction scores for each system as a refer-
ence point. User satisfaction was calculated from
five questions asked of each user after each dia-
logue. The questions use a 5-point Likert scale.
Turns to completion measures the total number
of on-task turns. We found no significant corre-
lations here, but cf. Walker et al (2001) which
provides more detailed analyses of the Communi-
cator dialogues using user satisfaction and other
metrics, within the PARADISE framework. It is
worth noting, however, that the HC D has both
the highest percentage of expert initiative and the
highest satisfaction scores, so we should not con-
clude that more initiative will necessarily lead to
happier users.
% Exp % User Turns to User
Init Init Comp Sat
HC A 86.8% 13.2% 40.5 60.0%
HC B 89.9% 10.1% 41.4 71.5%
HC C 90.6% 9.4% 36.0 68.5%
HC D 93.7% 6.3% 43.9 82.8%
HH SRI 48.3% 51.7% N/A N/A
HH CMU 54.0% 46.0% N/A N/A
Table 5: Percentages of User and Expert Initiative
in HH and HC Dialogues
In the HC dialogues, we also see a difference in
success rate for user-initiative turns. By our defi-
nition, the user ?succeeds? in taking the initiative
in the dialogue if the system responds to the initia-
tive on the first possible turn. The rate of success
8A cautionary note is warranted here. We are
not suggesting that more user-initiative is intrinsically
preferable; it may well turn out to be the case that
a completely system-directed dialogue is more pleas-
ant/efficient/etc. Rather, we are seeking to quantify
and assess what it means to be ?mixed-initiative? so
that we can better evaluate the role of initiative in
effective (task-oriented) dialogues.
is the ratio of successful user-initiatives attempts
to total user-initiatives attempts. There appears
to be a negative relationship between number of
initiative attempts and their success rate. See
Figure 1, below. HC D has a high success rate
for a relatively small number of user-initiative at-
tempts. HC A has many more occurrences of user
initiative, but does not incorporate them as well.
Figure 1: User-Initiative and Success Rate per
System
There is no determinable relationship between
user experience (i.e., the number of calls per sys-
tems) and either the amount of user-initiative or
the success rate of user-initiative.
We also looked at user-initiative with re-
spect to dialogue act type. Most user-initiatives
are request-action (26%) and request-
information (19%). Request-information
dialogue acts (e.g., What cities do you know in
Texas?, Are there any other flights?, Which air-
port is that?) are handled well by the systems
(83% success rate) while request-action dia-
logue acts (e.g., start over, scratch that, book that
flight) are not (48%). Most of the user-initiatives
that are request-action dialogue acts are the
start over command (16% of the total user-
initiatives). Corrections to flight information pre-
sented by the systems consist of 20% of the total
user-initiatives.
3.2 Overall Verbosity
In counting the number of words used, we find
that the computer experts are much more verbose
than their human users, and are relatively more
verbose than their human travel agent counter-
parts. In the HH dialogues, experts average 10.1
words/turn, while users average 7.2. In the HC di-
alogues on average, system have from 16.65-33.1
words/turn vs. the users? 2.8-4.8 words/turn. Fig-
ure 2 shows these differences for each of the four
systems and for the combined HH data.
Figure 2: Words per turn for users and experts in
the HH and HC dialogues
3.2.1 Short vs. Long Confirmations
One DA which is a basic conversational tool and
therefore an interesting candidate for analysis is
the use of confirmations. Instances of short con-
firmation, typically back-channel utterances such
as okay and uh huh were tagged as acknowl-
edge, while instances of long confirmation, as
when one participant explicitly repeats something
that the other participant has said, were tagged
as verify-X, where X=conversation-action,
task-information and task-action, This tag-
ging allows us to easily calculate the distribution
of short and long confirmations.
Overall we found in the HC dialogues a rather
different confirmation profile from the HH dia-
logues. In the HC dialogues, the systems use both
types of confirmation far more than the users do
(246 total system, 8 total user). Moreover, sys-
tems use long confirmation about five times more
often (210 vs. 36) than they use short confirma-
tion. In contrast, the experts in the HH dialogues
use somewhat more confirmations than users (247
vs. 173), but both parties use far more short than
long confirmations (340 vs. 80), just the reverse
of the HC situation. This difference partially ac-
counts for the total word count differences we saw
in the previous section. Tables 6 and 7 show the
breakdowns in these numbers for each system and
for the two sets of HH data, and begin to quantify
the striking contrasts between human and com-
puter confirmation strategies.
3.3 Number of Dialogue Acts
Another observation is that the computer experts
appear to be trying to do more. They have sig-
nificantly more DAs per turn than do their hu-
man users, whereas in the HH dialogues, the two
participants have nearly the same number of DAs
per turn (just over 1.3). In the HC dialogues, sys-
Site Expert User Total
HC A 3 (0.5%) 4 (0.7%) 7 (1.2%)
HC B 13 (1.9%) 0 (0.0%) 13 (1.9%)
HC C 20 (3.1%) 3 (0.5%) 23 (3.6%)
HC D 0 (0.0%) 0 (0.0%) 0 (0.0%)
HH SRI 95 (16.1%) 79 (13.3%) 174 (29.4%)
HH CMU 94 (12.1%) 72 (9.3%) 166 (21.4%)
Table 6: Number of short confirmations, i.e. ac-
knowledge (percentage of total dialogue acts)
Site Expert User Total
HC A 32 (5.7%) 0 (0.0%) 32 (5.7%)
HC B 74 (10.6%) 0 (0.0%) 74 (10.6%)
HC C 59 (9.2%) 1 (0.2%) 60 (9.4%)
HC D 45 (8.6%) 0 (0.0%) 45 (8.6%)
HH SRI 11 (1.9%) 11 (1.9%) 22 (3.7%)
HH CMU 47 (6.1%) 11 (1.4%) 58 (7.5%)
Table 7: Number of long confirmations i.e.
verify-X (percentage of total dialogue acts)
tems have, on average 1.6 DAs per turn where
users have just 1.0, as Figure 3 shows. If we take
a DA as representing a single dialogue ?move?,
then users in the HC dialogues are managing one
move per turn, where the systems have at least one
and often more. A common sequence for the com-
puter experts is a verify-task-information fol-
lowed by a request-task-information, such as
A flight to Atlanta. What city are you departing
from?.
Figure 3: Dialogue acts per turn for users and
experts in the HH and HC dialogues
3.4 Types of Dialogue Acts
One of our main questions going into this work
was whether there would be interestingly differ-
ent distributions of DAs in the HH and HC dia-
logues, and whether different distributions of DAs
across systems would be correlated with user sat-
isfaction. Unfortunately, we do not have user sat-
isfaction scores for the HH data, but if new data
were to be collected, this would be an essential
addition.
Tables 8 and 9 illustrate some of the main dif-
ferences between the HH and HC dialogues, and
as regards our first research question, definitely
give an interesting view of the differences between
the HH and HC conversations.
DA Overall Expert User
GiveTaskInfo 27.7% 29.7% 25.5%
Acknowledge 24.9% 26.9% 22.7%
RequestTaskInfo 11.0% 10.7% 11.4%
VerifyTaskInfo 5.4% 7.5% 3.2%
Affirm 4.8% 4.3% 5.4%
Table 8: Five most frequent DAs in Human-
Human dialogues, by percent of total DAs for col-
umn
DA Overall Expert User
GiveTaskInfo 23.7% 12.9% 46.3%
RequestTaskInfo 15.3% 22.1% 1.3%
Offer 7.7% 11.5% 0.0%
VerifyTaskInfo 7.1% 10.5% 0.1%
Apology 4.5% 6.6% 0.1%
Table 9: Five most frequent DAs in Human-
Computer dialogues, by percent of total DAs for
column
As expected in this domain, all DAs involving
exchange of task information (give-task-info,
request-task-info, and verify-task-info are
frequent in both sets of dialogues. However, in the
HH dialogues, acknowledge (e.g. the tag for
back-channel responses and general confirmations
such as right, uh huh and okay) is the second most
common DA, and does not even appear in the top
five for the HC dialogues. The DA for positive re-
sponses, affirm, is also in the top ranking for the
HH dialogues, but does not appear in the list for
the HC dialogues. Finally, offer and apology
appear frequently in the HC dialogues and not in
the top HH DAs. The appearance of these two is a
clear indication that the systems are doing things
quite differently from their human counterparts.
Turning to differences between experts and
users in these top categories, we can see that hu-
man users and experts are about equally likely
to ask for or give task-related information (give-
task-info and request-task-info). In con-
trast, in the HC dialogues nearly half of the users?
DAs are giving task information and hardly any
are requesting such information, while almost a
quarter of expert DAs are requesting information.
There is some inequity in the use of verify-task-
info in the HH dialogues, where experts perform
about twice as many verifications as users; how-
ever, in the HC dialogues, virtually all verification
is done by the expert. All of these patterns rein-
force our finding about initiative distribution; in
the HC dialogues, one disproportionately finds the
expert doing the asking and verification of task in-
formation, and the user doing the answering, while
in the HH dialogues the exchange of information
is much more balanced.
DA HC A HC B HC C HC D
accept 3.9% 3.1% 4.8% 3.4%
acknowledge 1.2% 1.9% 3.6% 0.0%
affirm 1.8% 2.4% 0.8% 9.5%
apologize 4.6% 3.7% 8.9% 0.0%
demand-conv-info 1.1% 0.0% 0.0% 0.0%
demand-sit-info 0.0% 1.6% 1.4% 1.3%
demand-task-info 3.4% 0.3% 0.0% 1.3%
give-sit-info 5.7% 6.3% 4.7% 1.9%
give-task-info 34.8% 16.0% 24.8% 20.8%
negate 2.1% 1.7% 0.8% 5.2%
not-understand 2.5% 3.7% 7.2% 0.0%
offer 3.5% 8.4% 9.4% 9.4%
open-close 2.3% 3.1% 4.8% 3.4%
please-wait 0.0% 6.2% 1.6% 3.1%
reject 1.1% 4.1% 0.3% 2.5%
req-conv-action 2.7% 4.4% 2.5% 1.0%
req-sit-action 1.1% 1.4% 0.2% 1.9%
req-sit-info 0.0% 3.3% 0.2% 3.2%
req-task-action 1.1% 1.4% 0.3% 0.2%
req-task-info 17.9% 12.6% 10.9% 21.6%
suggest-conv-action 1.6% 0.1% 2.0% 0.0%
thank 2.1% 3.4% 1.4% 1.7%
verify-conv-action 0.7% 0.7% 0.0% 0.0%
verify-task-action 2.5% 0.4% 1.9% 0.0%
verify-task-info 2.5% 9.4% 7.5% 8.6%
user satisfaction9 60.0% 71.5% 68.5% 82.8%
Table 10: Distribution of DAs by System
Table 10 gives an interesting snapshot of each
system, in terms of its overall distribution of DAs.
These numbers are reflective of the system design-
ers? decisions for their systems, and that means all
DAs are not going to be used by all systems (i.e.
0.0% may mean that that DA is not part of the
system?s repertoire).
We will concentrate here on the best and worst
9This figure combines the scores on five user satis-
faction questions. A perfect score is 100%.
received systems in terms of their overall user sat-
isfaction, HC D and HC A; the relevant numbers
are boldfaced. They also have very different di-
alogue strategies, and that is partially reflected
in the table. HC D?s dialogue strategy does not
make use of the ?social nicety? DAs employed by
other systems (acknowledge, apologize, not-
understand), and yet it still had the highest user
satisfaction of the four. This system also has the
highest proportion of affirm (more than three
times as many as the next highest system) and
req-task-info DAs, which suggests that quite a
lot of information is being solicited and the users
(because we know from Table 9 that it is primarily
the users responding) are more often than average
responding affirmatively. The fact that the per-
centage of give-task-infos is somewhere in the
middle of the range and affirms is so high may
indicate that the HC D uses more yes/no than
content questions.
Looking at the lower scoring system, HC A, we
see very different patterns. HC A has most of
the demand-task-infos, the second highest per-
centage of req-task-infos and by far the most
give-task-infos, so its dialogue strategy must
involve a large number of attempts to extract in-
formation from the user, and yet it has the fewest
offer DAs, so these don?t appear to be resulting
in suggestions of particular travel options.
Turning to correlations between DA use by
expert and user (combined across systems) and
user satisfaction, we see some expected results
but also some rather surprising correlations.
Not unexpectedly, apologies and signals of non-
understanding by the system are highly negatively
correlated with satisfaction (-0.7 and -0.9, respec-
tively). While it may seem counter-intuitive that
open-close by the user is negatively correlated
(at -0.8), those familiar with this data will un-
doubtedly have noticed that users often try to say
Goodbye repeatedly to try to end a dialogue that
is going badly. Discussion of situational informa-
tion (e.g. phone use) by the expert is highly neg-
atively correlated, but by the user, the DA req-
situation-info is perfectly positively correlated.
We cannot account for this finding.
3.5 Unsolicited Information
In the HC data we noticed that users often
provided more information than was explicitly
solicited?we call this ?unsolicited information?.
For example, when a system asks for one piece
of information, On what day would you be depart-
ing Portland?, the user might respond with ad-
ditional information such as, Thursday, October
5th before six pm from Portland back to Seattle.
78% of that unsolicited information is offered in
response to open-ended questions (e.g., How can I
help you? or What are your travel plans?). While
our initiative tagging partially captures this, there
are cases where the answer may be considered re-
sponsive (i.e. initiative does not shift away from
the participant asking the question) and yet un-
solicited information has been offered. Thus, this
category is somewhat orthogonal to our charac-
terization of initiative, although it is clearly one
way of seizing control of the conversation.10
To get at this information, we developed a third
tagging scheme for annotating unsolicited infor-
mation. We began examining just the HC doc-
uments, because the phenomenon is prevalent in
these data; we hope to perform a similar analysis
on the HH data as well. We found that the sys-
tems we examined in general handle unsolicited in-
formation well. 70% of all unsolicited information
is handled correctly by the systems, 22% is han-
dled incorrectly, and the rest could not be accu-
rately classified. Information offered in response
to open-ended questions is handled correctly more
often by the systems than unsolicited information
offered at other points in the dialogue (74% versus
56%). The former figure is not surprising, since
the systems are designed to handle ?unsolicited?
information following open-prompts. However, we
were surprised the systems did as well as they did
on unsolicited information in contexts where it
was not expected. Figure 4 shows the relationship
between frequency of various types of unsolicited
information and how well the system incorporates
that information. There appears to be some cor-
relation between the frequency of unsolicited in-
formation and the rate of success, but we do not
have enough data to make a stronger claim.
Furthermore, systems vary in response delay to
pieces of unsolicited information. We define re-
sponse delay as the number of system turns it
takes before the information is acknowledged by
the system (either correctly or incorrectly.) If a
system responds immediately to the unsolicited
information, a count of zero turns is recorded.
Figure 5 shows the difference among systems in re-
sponding to unsolicited information. We graphed
both the average total number of system turns as
well as the average number of turns minus rep-
etitions. HC B responds almost immediately to
10This issue may also be related to where in the
dialogue errors occur. We are pursuing another line
of research which looks at automatic error detection,
described in (Aberdeen et al, 2001). We believe we
may also be able to detect unsolicited information au-
tomatically, as well as to see whether it is likely to
trigger errors by the system.
Figure 4: Unsolicited Fields vs. Success Rate of
Incorporation
unsolicited information while HCs A and C take
more turns to respond. HC D has trouble under-
standing the unsolicited information, and either
keeps asking for clarification or continues to ig-
nore the human and prompts for some other piece
of information multiple times.
Figure 5: Variation of System Response to Unso-
licited Information
Figure 6 shows the different rates at which sys-
tems acknowledge unsolicited information for dif-
ferent fields. For example, departure city is recog-
nized and validated almost immediately. Return
date and flight type are incorporated fairly quickly
when the system understands what is being said.
If we look at the effects of experience on
the amount of unsolicited information offered, as
shown in Figure 7, we can see that users tend
to provide more unsolicited information over time
(i.e., as they make more calls to the systems).
This effect may be the result of increased user
confidence in the systems at handling unsolicited
information. It also may be attributed to user
boredom; as time goes on, users may be trying
to finish the task as quickly as possible. Even if
this is true, however, it demonstrates attempts by
users to take more control of the interactions as
Figure 6: System Response to Different Types of
Unsolicited Information
they become more experienced.
Figure 7: Effect of Experience on Unsolicited In-
formation
Our data also show that the success rate of in-
corporating unsolicited information improves with
user experience. The ratio of successes to failures
increases in later calls to the systems (Figure 8).
4 Discussion
This was a relatively small study, but many of
the results are sufficiently striking that we expect
them to hold over large sets of dialogues. First,
it is clear that (for our definition of the term) ini-
tiative is skewed towards the computer expert in
the human-computer dialogues, despite claims of
developers to the contrary. Whether this is de-
sirable or not is a separate issue, but we believe
it is a move forward to be able to quantify this
difference. Second, there are clear differences in
dialogue act patterns between the HH and HC di-
alogues. When the DAs correspond to basic di-
alogue moves, like questions or signals of agree-
ment, we can begin to see how the dialogue dy-
namic is different in the human computer situa-
Figure 8: Experience versus Success Rate of In-
corporating Unsolicited Information
tion. In general, the conversation was much more
balanced between traveler and expert in the HH
setting, in terms of amount of speech, types of di-
alogue acts and with respect to initiative. In the
HC conversations, the system dominated, in num-
ber of words and dialogue acts and in initiative.
We are very interested in the selection of the
?right? tag set for a given task. As we noted in
our discussion of DA tagging, we had very dif-
ferent outcomes with two closely related tag sets.
Clearly the choice of tag set is highly dependent
on the use the tagged data will be put to, how
easily the task can be characterized in the set of
tagging guidelines, and what trade-offs in accu-
racy vs. richness of representation are acceptable.
A central question we are left with is ?Why
don?t the users talk more in HC dialogues?? Is
it that they are happy to just give short, specific
answers to very directed questions? Or do they
?learn? that longer answers are likely to cause the
systems problems? Or perhaps users have pre-
conceived notions (often justified) that the com-
puter will not understand long utterances? We
may speculate that poor speech recognition per-
formance is a major factor shaping this behav-
ior, leading system designers to attempt to con-
strain what users can say, while simultneously at-
tempting to hold onto the initiative. (Walker et
al. (2001) found sentence accuracy to be one of
the significant predictors of user satisfaction in the
Summer 2000 DARPA Communicator data collec-
tion.) There are some cases where the experts in
the HC dialogues say things their human counter-
parts need not. One obvious case, which appears
in even the small example dialogues we are us-
ing here, is that the systems tend to repeat utter-
ances when there is some processing difficulty. In
the same vein, errors and misunderstandings are
more frequent in the HC data, resulting in (some
fairly verbose) efforts by the systems to identify
the problem and get the conversation back on
track.
5 Future Work
We are currently working with other Communica-
tor sites who are also looking at dialogue issues.
In addition, we are beginning to look at two new
aspects of these dialogues: task complexity and
conversational failure analysis (at the turn level,
(Aberdeen et al, 2001)). We are also interested
in examining patterns of initiative tags, i.e. con-
trol shift types and length of initiative runs, and
at relations between DAs and user satisfaction.
6 Acknowledgments
Thanks to Lori Levin and Alon Lavie at CMU for
sharing the CSTAR tagging guidelines and their
sample tagged corpus.
References
J. Aberdeen, C. Doran, L. Damianos, S. Bayer, and
L. Hirschman. 2001. Finding errors automatically
in semantically tagged dialogues. In Notebook Pro-
ceedings of the First International Conference on
Human Language Technology Research, San Diego,
CA, March.
J. C. Carletta, A. Isard, S. Isard, J. Kowtko,
G. Doherty-Sneddon, and A. Anderson. 1995.
The coding of dialogue structure in a corpus. In
J. A. Andernach, S. P. van de Burgt, and G. F.
van der Hoeven, editors, Proceedings of the Twente
Workshop on Language Technology: Corpus-based
approaches to dialogue modelling, Enschede, The
Netherlands. Universiteit Twente.
Jennifer Chu-Carroll and Michael K. Brown. 1998.
An evidential model for tracking initiative in col-
laborative dialogue interactions. User Modeling and
User-Adapted Interaction, 8(3-4):215?253.
CSTAR Consortium. 1999. Dialogue act annotation.
Unpublished Manuscript, October.
Mark Core and James Allen. 1997. Coding dialogs
with the damsl annotation scheme. In Proceed-
ings of the AAAI Fall Symposium on Communica-
tive Action in Humans and Machines, Boston, MA,
November.
Mark Core, Masato Ishizaki, Johanna Moore, Chris-
tine Nakatani, Nobert Reithinger, David Traum,
and Syun Tutiya, editors. 1999. The Report of The
Third Workshop of the Discourse Resource Initia-
tive, Chiba Univeristy. Technical Report No.3 CC-
TR-99-1.
Barbara Di Eugenio, Pamela W. Jordan, and Liina
Pylkknen. 1998. The COCONUT project: dialogue
annotation manual. Technical Report ISP Techni-
cal Report 98-1, University of Pittsburgh, Decem-
ber.
Giovanni Flammia and Victor Zue. 1997. Learn-
ing the structure of mixed initiative dialogues us-
ing a corpus of annotated conversations. In Proc.
Eurospeech 97, pages 1871?1874, Rhodes, Greece,
September.
Pamela W. Jordan and Barbara Di Eugenio. 1997.
Control and initiative in collaborative problem solv-
ing dialogues. In AAAI Spring Symposium on Com-
putational Models for Mixed Initiative Interaction,
Stanford, CA.
Daniel Jurafsky, Elizabeth Shriberg, and De-
bra Biasca. 1997. Switchboard swbd-damsl
shallow-discourse-function annotation coders man-
ual. Technical Report Technical Report 97-02, Uni-
versity of Colorado Institute of Cognitive Science,
August.
Marion Klein, Niels Ole Bernsen, Sarah Davies, Laila
Dybkj?r, Juanma Garrido, Henrik Kasch, An-
dreas Mengel, Vito Pirelli, Massimo Poesio, Sil-
via Quazza, and Claudia Soria, 1998. Supported
Coding Schemes, MATE Deliverable D1.1, July.
http://mate.nis.sdu.dk/.
Christine H. Nakatani, Barbara J. Grosz, David D.
Ahn, and Julia Hirschberg. 1995. Instructions for
annotating discourse. Technical Report TR-21-95,
Harvard University.
R.J. van Vark, J.P.M. de Vreught, and L.J.M.
Rothkrantz. 1996. Analysing ovr dialogues, coding
scheme 1.0. Technical Report 96-137, Delft Univer-
sity of Technology.
Marilyn Walker and Rebecca Passonneau. 2001. Di-
alogue act tags as qualitative dialogue metrics for
spoken dialogue systems. In Notebook Proceedings
of the First International Conference on Human
Language Technology Research, San Diego, CA,
March.
Marilyn Walker and Steve Whittaker. 1990. Mixed
initiative in dialogue: An investigation into dis-
course segmentation. In Proceedings of ACL90.
M. Walker, J. Aberdeen, J. Boland, E. Bratt, J. Garo-
folo, L. Hirschman, A. Le, S. Lee, S. Narayan,
K. Papineni, B. Pellom, J. Polifroni, A. Potamianos,
P. Prabhu, A. Rudnicky, G. Sanders, S. Seneff,
D. Stallard, and S. Whittaker. 2001. DARPA Com-
municator Dialog Travel Planning Systems: The
June 2000 Data Collection. Submitted., April.
Steve Whittaker and Phil Stenton. 1988. Cues and
control in expert client dialogues. In Proceedings
of the 26th Annual Meeting of the Association for
Computational Linguistics (ACL88), pages 123?
130.
Dialogue complexity with portability? 
Research directions for the Information State approach 
Carl Burke, Christy Doran, Abigail Gertner, 
Andy Gregorowicz, Lisa Harper, Joel Korb, Dan Loehr 
The MITRE Corporation 
202 Burlington Road, Bedford, MA 01730 
{cburke,doran,gertner,andrewg,lisah,jkorb,loehr}@mitre.org 
 
 
Abstract 
We review existing types of dialogue manag-
ers (DMs), and propose that the Information 
State (IS) approach may allow both complex-
ity of dialogue and ease of portability.  We 
discuss implementational drawbacks of the 
only existing IS DM, and describe our work 
underway to develop a new DM resolving 
those drawbacks.  
1 Introduction 
Spoken dialogue systems have shown steady improve-
ments in recent years. To continue advancing the state 
of the field, we must direct research towards reducing a 
tradeoff between complexity and portability. Otherwise, 
we will continue to have systems which can handle 
complex interactions, or systems which can be easily 
modified for new domains, but not both. 
The simplest existing dialogue managers (DMs), fi-
nite-state systems, are suitable for simple, well-
structured system-initiated dialogue tasks. They also 
make it easy for novice developers to create new dia-
logue systems. Yet this type of DM does not scale well 
to mixed-initiative dialogues or complicated tasks with 
a wide variety of possible input. The most well-known 
such DM is VoiceXML. Similar systems include Ore-
gon Graduate Institute?s Rapid Application Developer 
(CSLU 2002), Unisys' Dialog Design Assistant (Unisys 
1998), Nuance?s Speech Objects, the Swedish GULAN 
(yellow pages) system (Gustafson et al1998), and sev-
eral commercial systems by SpeechWorks. 
More sophisticated, mixed-initiative, frame-based 
DMs often make use of semantic ?frames? containing 
multiple ?slots? or ?keys?, each of which can hold a 
value. Either conversational partner can volunteer or 
request information about any slots in the frame, at any 
time, in any order. When enough slots are filled to the 
satisfaction of both parties, the task and conversation 
are complete. This type of DM supports a more flexible, 
arbitrary flow-of-control, often controlled by scripts of 
rules firing upon certain conditions. Examples of these 
types of DMs include Philips? SpeechMania (Aust and 
Schroer 1998), the Dialogue Design Language Tool in 
the Danish Generic Dialogue System (Bernsen et al
1998), and several of the DMs developed (by e.g. MIT 
and the University of Colorado) for the DARPA Com-
municator infrastructure. 
Even more complex plan-based DMs reason about 
?plans? and communicative ?goals?, and try to move the 
conversation along towards achieving these goals. By 
representing the relationships between goals, subgoals, 
and primitive actions in a domain, these systems can 
support dialogues with a broader scope than the frame-
based DMs can. Notably, they are intended to detect 
topic shifts as well as support dynamic re-planning 
when misunderstandings occur. These systems typically 
model communicative goals in terms of speech acts 
where speech acts affect goals, beliefs, intent and/or 
obligations of the participants. These DMs can also be 
complex to develop, and correspondingly difficult to 
port to new applications. Examples of this type are 
COLLAGEN (COLLaborative AGENts), by Mitsubishi 
Electric Research Lab (Rich et. al. 2001), and the Uni-
versity of Rochester?s TRAINS and TRIPS systems 
(CISD 2000). 
The approach we find most promising, however, is 
the Information State (IS) approach, which simplifies 
development by providing a rule-based language for 
specifying dialogue systems while allowing the flexible, 
complex interactions characteristic of plan-based dia-
logues. An IS theory of dialogue proposed by Cooper 
and Larson (1998) models dialogue states (i.e. struc-
tured semantic objects) as dependent record types. Dia-
logue moves (roughly equivalent to speaker turns) are 
characterized as transitions between information states 
in a manner that is neutral with regard to semantic the-
ory. This approach to dialogue modeling enables devel-
opers to model the system information state in such a 
way that arbitrary linguistic theories of dialogue may be 
formalized, implemented, and compared. ISs may be 
used to model relations between various kinds of infor-
mation such as utterances, background knowledge, non-
verbal events and visual scenes. This is crucial to mul-
timodal dialogue processing. Another important feature 
of the IS approach is that developers have the flexibility 
to define levels of dialogue as well as model goals, in-
tent, beliefs and obligations. Thus the IS approach may 
also be used to model more complex dialogues using 
concepts derived from plan-based theories of dialogue - 
perhaps, inheriting some of the same challenges. How-
ever, the same framework may be used to also model 
simpler finite-state dialogues.  
TRINDIKit (TRINDI 2002) is an IS-based open 
source Prolog toolkit. TRINDIKit itself provides the 
basic infrastructure of a dialogue manager. It provides 
structured data types and the means to define an Infor-
mation State from those types, a language for defining 
the modules of a Dialogue Move Engine (DME), and a 
language for controlling the application of individual 
modules to dialogue management.  
We have built two dialogue systems using TRIN-
DIKit (Burke et al2002).  We first developed a multi-
modal information kiosk by adapting GoDiS 
(Gothenburg Dialogue System) (Larsson et al2000), 
which implements the Questions Under Discussion 
model in TRINDIKit. Adapting this existing TRIN-
DIKit DM to a new question-answer domain required 
very little effort (less than two staff-weeks from initial 
downloading of TRINDIKit to an operational system 
open to the public). We then modified the DM to sup-
port control of a search-and-rescue robot using a 
speech-and-sketch interface on a PDA, again with rela-
tively little effort. Based on our experience, we feel that 
the IS approach to dialogue management as espoused by 
TRINDI is a strong candidate for supporting both com-
plexity and portability.  In the remainder of this paper, 
we discuss some implementational drawbacks of 
TRINDIKit, and our work underway to develop a new 
toolkit, inspired by TRINDIKit but re-engineered to 
eliminate its drawbacks. 
2 
3 
Implementational Drawbacks 
Data consistency. TRINDIKit does not exercise good 
controls over asynchronous modifications to the IS. At 
one point we had to build artificial delays into our sys-
tem to work around these limitations. The DM we built 
was based on GoDiS, which requires very structured 
turn-taking. In several cases, however, the interactions 
with the user flowed better if these responses were 
automatic. Processing was sufficiently slow that our 
GUI?s automatic acknowledgement often arrived and 
was processed before TRINDIKit was finished cleaning 
up from the previous utterance. As a result, it was pos-
sible to change the IS twice before the DME could re-
spond to one change, and the system lost track of the 
dialogue state. Consistency of data needs to be assured 
throughout the design of the system. 
Inconsistent semantics. We encountered situations 
where constructs of the GoDiS plan language were in-
terpreted differently depending on the depth of the plan. 
With the proliferation of small languages implemented 
by different sets of macros, it was difficult to track 
down bugs in the rules and conversation scripts. This 
was made more difficult by the nature of Prolog. 
Clauses that fail do not normally generate any error 
messages, because failure is a normal aspect of program 
execution. Unfortunately, database bugs and misspelled 
names often caused unexpected failures, causing the 
system to generate either no response or a response that 
looked reasonable but was in fact incorrect. We feel it?s 
necessary to provide explicit notification of certain 
kinds of failure, such as failure to find a named variable, 
failure to find a matching value in a table, and so on. 
Multimodal processing. Neither TRINDIKit nor 
GoDiS provides any direct support for multimodal 
processing. The primary interface driving the develop-
ment of these systems was language; there is no separa-
tion of events by source, no temporal tagging of input 
events, and no provision for assessing temporal relation-
ships between different inputs. 
Proposed Solutions 
From our experience with TRINDIKit, we are con-
vinced of the advantages of a kit-based approach. We 
feel that TRINDIKit was a good first cut at it, and hope 
that our efforts will lead to a second, somewhat better 
iteration.  We are therefore moving ahead with a new 
DM kit, tentatively called MIDIKI (MITRE DIalogue 
KIt), with the following features. 
Distributed information state. We have chosen to 
model all of our module interactions as if they were 
asynchronous. This provides the cleanest separation of 
modules, and the cleanest conceptual integration with 
the asynchronous requirements of robot control. Our 
approach to solving this problem is to define an explicit 
interface definition language, which will be used to de-
fine every module?s interface with the outside world. 
We explicitly include the information state structure in 
this interface definition, perhaps as a module in itself. 
Since TRINDIKit does not include a separate language 
for specifying module interfaces, we are designing our 
own. This language is analogous to CORBA Interface 
Definition Language, but with less concern for the 
physical implementation. 
Controlled extensibility. Our interface specifications 
will need to be translated into specific computer lan-
guages before they can be executed. The translation will 
vary depending on the underlying protocol used to 
communicate between modules. While we want to sup-
port the widest possible audience, we don?t want to get 
bogged down in the construction of translators for every 
possible set of implementation language and protocol. 
Our approach is to exploit an existing standard set of 
translation software, namely XML and XSLT proces-
sors such as Xalan. We are specifying a dialect of XML 
for modules interface definitions, and a small set of 
templates for realizing interfaces with specific combina-
tions of programming language and protocol. Additional 
templates can be written to extend the kit to other lan-
guages and protocols without requiring modification of 
the kit itself. 
Rule engine. The DME rules in TRINDIKit have 
strong similarities to rules in expert systems. We plan to 
implement these rules in both a sequential form, equiva-
lent to the current TRINDIKit, and in an expert system 
form which may be more efficient. We expect that there 
will be differences in operating characteristics between 
those two styles, and we want to identify and quantify 
those differences. 
Control and synchronization. Our primary focus is 
multimodal communication, potentially multiparty as 
well. We are extending TRINDIKit?s triggers to include 
support for consideration of temporal relationships be-
tween events, both within and across modes. 
Integrated environment. An ideal toolkit would 
have an integrated set of tools for designing, testing, and 
debugging dialogues. We would like to support static 
and dynamic analysis of dialogues, recording and play-
back of dialogues, graphical dialogue design tools, a 
?validation suite? of tests to support extension of the 
toolkit to new programming languages and agent proto-
cols, and above all, the ability to plug-in as-yet-
undefined capabilities. 
4 Future Work 
Significant effort has been devoted to defining our mu-
table language capability. This capability provides both 
a transition path from TRINDIKit scripts and a means 
for specifying module interfaces and information state 
structure using a common XML representation. 
Our intent is to provide support for several different 
transport mechanisms to explore the limitations of our 
approach. To date, we have completed an initial inter-
face definition specification and have developed tem-
plates to realize those interfaces with the OAA.  
DARPA's Galaxy Communicator is the second transport 
mechanism we will be considering.  
We have devoted considerable time to up-front con-
sideration of scripting languages, portable code genera-
tion, and module communications, and are now 
beginning the task of implementing our versions of the 
TRINDIKit scripting languages. Our target realization 
for these scripts is a combination of Java code and ex-
pert systems that can be executed within a Java pro-
gram. 
We plan to port and formally evaluate our dialogue 
toolkit within three domains (question-answering, 
automated tutoring, and multimodal robot control). Our 
dialogue toolkit will be openly available, as well as 
sample implementations for each of these domains. 
References 
Aust, H. and Schroer, O. (1998) An overview of the 
Philips dialog system. DARPA Broadcast News 
Transcription and Understanding Workshop, Lans-
downe, VA. 
Bernsen, N. O., Dybkj?r, H. and Dybkj?r, L. (1998) 
Designing interactive speech systems. From first 
ideas to user testing. Springer Verlag. 
Burke, C., Harper, L., and Loehr, D. (2002) A Flexible 
Architecture for a Multimodal Robot Control Inter-
face.  Intelligent Situation-Aware Media and Presen-
tations Workshop, AAAI '02. 
CISD (Conversational Interaction and Spoken Dialogue 
Research Group) (2000) ?TRIPS: The Rochester In-
teractive Planning System?, URL (Mar 2003): 
http://www.cs.rochester.edu/research/trips. 
Cooper, R., and Larsson S. (1998) Dialogue Moves and 
Information States, Third International Workshop on 
Computational Semantics. 
CSLU (Center for Spoken Language Understanding) 
(2002) ?CSLU Toolkit?, URL (Mar 2003): 
http://cslu.cse.ogi.edu/toolkit. 
Gustafson, J., Elmberg, P., Carlson,R., and J?nsson, A. 
(1998) An educational dialogue system with a user 
controllable dialogue manager. ICSLP? 98. 
Larsson, Staffan, Robin Cooper, Stina Ericsson (2000) 
System Description of GoDis.  Third Workshop in 
Human-Computer Conversation, Bellagio, Italy. 
Rich, C., Lesh, N. and Sidner, C. (2001) COLLAGEN: 
Applying Collaborative Discourse Theory.  AI 
Magazine, Special Issue on Intelligent User Inter-
faces. 
TRINDI (2002) ?TRINDIKit?, URL (Mar 2003): 
http://www.ling.gu.se/projekt/trindi/trindikit. 
Unisys (1998) ?Unisys Corporation: Natural language 
speech assistant (NLSA): capabilities overview?. 
Malvern, PA. 
A Representation for Complex and Evolving Data Dependencies 
in Generation 
C Me l l i sh  $, R Evans  t, L Cah i l l  t, C Doran  t, D Pa iva  t, M Reape $, D Scot t  t, N T ipper  t 
t Information Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UK 
SDivision of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UK 
rags@itri, brighton, ac. uk 
http :/www. itri. brighton, ac. uk/proj ect s/rags 
Abst rac t  
This paper introduces an approach to represent- 
ing the kinds of information that components 
in a natural language generation (NLG) sys- 
tem will need to communicate to one another. 
This information may be partial, may involve 
more than one level of analysis and may need 
to include information about the history of a 
derivation. We present a general representation 
scheme capable of handling these cases. In ad- 
dition, we make a proposal for organising inter- 
module communication i an NLG system by 
having a central server for this information. We 
have validated the approach by a reanalysis of 
an existing NLG system and through a full im- 
plementation of a runnable specification. 
1 In t roduct ion  
One of the distinctive properties of natural an- 
guage generation when compared with other 
language ngineering applications i that it has 
to take seriously the full range of linguistic rep- 
resentation, from concepts to morphology, or 
even phonetics. Any processing system is only 
as sophisticated as its input allows, so while a 
natural language understanding system might 
be judged primarily by its syntactic prowess, 
even if its attention to semantics, pragmatics 
and underlying conceptual analysis is minimal, 
a generation system is only as good as its deep- 
est linguistic representations. Moreover, any at- 
tempt to abstract away from individual gener- 
ation systems to a more generic architectural 
specification faces an even greater challenge: 
not only are complex linguistic representations 
required, able to support the dynamic evolu- 
tionary development of data during the gener- 
* Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran@mitre, org. 
ation process, but they must do so in a generic 
and flexible fashion. 
This paper describes a representation devel- 
oped to meet these requirements. It offers a 
formally well-defined eclarative representation 
language, which provides a framework for ex- 
pressing the complex and dynamic data require- 
ments of NLG systems. The approach supports 
different levels of representation, mixed repre- 
sentations that cut across levels, partial and 
shared structures and 'canned' representations, 
as well as dynamic relationships between data 
at different stages in processing. We are using 
the approach to develop a high level data model 
for NLG systems as part of a generic generation 
architecture called RAGS 1. 
The framework has been implemented in the 
form of a database server for modular genera- 
tion systems. As proof of concept of the frame- 
work, we have reimplemented an existing NLG 
system. The system we chose was the Caption 
Generation System (CGS) (Mittal et al, 1995; 
Mittal et al, 1998). The reimplementation in- 
volved defining the interfaces to the modules of 
CGS in terms of the RAGS representations and 
then implementing modules that had the requi- 
site input and output representations. 
Generation systems, especially end-to-end, 
applied generation systems, have, unsurpris- 
ingly, many things in common. Reiter (1994) 
proposed an analysis of such systems in terms 
of a simple three stage pipeline. More recently, 
the RAGS project attempted to repeat he anal- 
1This work is supported by ESPRC grants 
GR/L77041 (Edinburgh) and GR/L77102 (Brighton), 
RAGS: Reference Architecture for Generation Systems. 
We would also like to acknowledge the contribution of 
Jo Calder to the ideas and formalisation described in 
this paper. In particular, parts of this paper are based 
on (Calder et al, 1999). 
119 
ysis (Cahill et al, 1999a), but found that while 
most systems did implement a pipeline, they 
did not implement the same pipeline - different 
functionalities occurred in different places and 
different orders in different systems. In order 
to accommodate his result, we sought to de- 
velop an architecture that is more general than 
a simple pipeline, and thus supports the range 
of pipelines observed, as well as other more com- 
plex control regimes (see (Cahill et al, 1999a; 
Cahill et al, 1999b)). In this paper, we argue 
that supporting such an architecture requires 
careful consideration of the way data represen- 
tations interact and develop. Any formal frame- 
work for expressing the architecture must take 
account of this. 
2 The  representat iona l  requ i rements  
o f  generat ion  sys tems 
We noted in the introduction that generation 
systems have to deal with a range of linguis- 
tic information. It is natural, especially in the 
context of a generic architecture proposal, to 
model this breadth in terms of discrete layers 
of representation: (1999a) introduce layers such 
as conceptual, semantic, rhetorical, syntactic 
and document structure, but the precise demar- 
cation is not as important here as the princi- 
ple. The different kinds of information are typi- 
cally represented differently, and built up sepa- 
rately. However the layers are far from indepen- 
dent: objects at one layer are directly related to 
those at others, forming chains of dependency 
from conceptual through rhetorical and seman- 
tic structure to final syntactic and document re- 
alisation. This means that data resources, such 
as grammars and lexicons, and processing mod- 
ules in the system, are often defined in terms of 
mixed  data: structures that include informa- 
tion in more than one representation layer. So 
the ability to represent such mixed structures 
in a single formal framework is an important 
property of a generic data proposal. 
In addition, it is largely standard in gener- 
ation as elsewhere in language applications, to 
make extensive use of par t ia l  representations, 
often using a type system to capture grades of 
underspecification. An immediate corollary of 
providing support for partial structures is the 
notion that they may become further specified 
over time, that data structures evolve. If the 
framework seeks to avoid over-commitment to 
particular processing strategies it needs to pro- 
vide a way of representing such evolution ex- 
plicitly if required, rather than relying on de- 
structive modification of a structure. Related 
to this, it should provide explicit support for 
representing a l te rnat ive  specifications at any 
point. Finally, to fully support efficient pro- 
cessing across the range of applications, from 
the simple to the most complex, the represen- 
tation must allow for compact sharing of infor- 
mation in tang led  structures (two structures 
which share components). 
In addition to these direct requirements of the 
generation task itself, additional requirements 
arise from more general methodological consid- 
erations: we desire a representation that is for- 
mally well  def ined,  allows for theoretical rea-  
son ing about the data and performance of sys- 
tems, and supports control regimes from simple 
deterministic pipelines to complex parallel ar- 
chitectures. 
3 The  Representat ion  Scheme 
In this section, we present our proposal for a 
general representation scheme capable of cover- 
ing the above requirements. Our formulation is 
layered: the foundation is a simple, flexible, rig- 
orously defined graph representation formalism, 
on top of which we introduce notions of com- 
plex types and larger data structures and rela- 
tionships between them. This much is sufficient 
to capture the requirements just discussed. We 
suppose a yet higher level of specification could 
capture a more constraining data model but 
make no specific proposals about this here, how- 
ever the following sections use examples that do 
conform to such a higher level data model. 
The lowest level of the representation scheme 
is: 
? re lat iona l :  the basic data entity is x -~ y, 
an ar row representing a relation from ob- 
ject x to object y; 
? typed:  objects and arrows have an asso- 
ciated type system, so it is possible to de- 
fine classes and subclasses of objects and 
arrows. 
At the most fundamental level, this is more or 
less the whole definition. There is no commit- 
ment to what object or arrow types there are or 
120 
how they relate to each other. So a representa- 
tion allowed by the scheme consists of: 
? a set of objects, organised into types; 
? a set of binary relations, organised into 
types; 
? a set of arrows, each indicating that a rela- 
tion holds between one object and another 
object. 
Sets,  sequences  and  funct ions  
For the next level, we introduce more struc- 
ture in the type system to support sets, se- 
quences and functions. Objects are always 
atomic (though they can be of type set, se- 
quence or function) - it is not possible to make 
an object which actually is a set of two other 
objects (as you might with data structures in a 
computer program). To create a set, we intro- 
duce a set type for the object, and a set mem- 
bership arrow type (el), that links the set's el- 
ements to the set. Similarly, for a sequence, we 
introduce a sequence type and sequence mem- 
ber arrow types (1-el, 2-el, 3-el, . . .  ), and for a 
function, we have a complex type which spec- 
ifies the types of the arrows that make up the 
domain and the range of the function. 
SemRep 
~ fun(Role.SemRep) 
7 V show SemRep SemRep 
Figure 1: The partial semantic representation 
of "The second chart shows the number of days 
on the market" 
As an example, consider Figure 1, which 
shows a semantic representation (SemRep) from 
the CGS reimplementation. Here, the tree 
nodes correspond to objects, each labelled with 
its type. The root node is of type SemRep, and 
although it is not an explicit sequence type, we 
can see that it is a triple, as it has three sequence 
member arrows (with types 1-el, 2-el and 3-el). 
Its first arrow's target is an object of type DR 
(Discourse Referent). Its second represents a set 
of SemPred (Semantic Predicate) objects, and in 
this case there's just one, of type show. Its third 
element is a (partial) function, from Role arrow 
types (agent and affected are both subtypes of 
Role) to SemReps. (In this case, the SemReps 
have not yet been fully specified.) 
Local  and  non- loca l  a r rows  
The second extension to the basic representa- 
tion scheme is to distinguish two different ab- 
stract kinds of arrows - local and non-local. 
Fundamentally we are representing just a homo- 
geneous network of objects and relationships. In 
the example above we saw a network of arrows 
that we might want to view as a single data 
structure, and other major data types might 
similarly appear as networks. Additionally, we 
want to be able to express relationships between 
these larger 'structures' - between structures 
of the same type (alternative solutions, or re- 
vised versions) or of different ypes (semantic 
and syntactic for example). To capture these 
distinctions among arrows, we classify our ar- 
row types as local or non-local (we could do 
this in the type system itself, or leave it as an 
informal distinction). Local arrows are used to 
build up networks that we think of as single 
data structures. Non-local arrows express rela- 
tionships between such data structures. 
All the arrow types we saw above were local. 
Examples of non-local arrows might include: 
real ises These arro~vs link something more ab- 
stract to something less abstract hat re- 
alises it. Chains of realises arrows might 
lead from the original conceptual input to 
the generator through rhetorical, seman- 
tic and syntactic structures to the actual 
words that express the input. 
revises These arrows link a structure to an- 
other one of the same type, which is con- 
sidered to be a 'better' solution - perhaps 
because it is more instantiated. It is impor- 
tant to note that parts of larger structures 
can be revised without revising the entire 
structure. 
coreference These arrows link structures 
which are somehow "parallel" and which 
perhaps hare some substructure, i.e., tan- 
gled structures. For instance, document 
representations may be linked to rhetorical 
representations, either as whole isomorphic 
structures or at the level of individual con- 
stituents. 
121 
Notice that the representation scheme does 
not enforce any kind of well-formedness with 
respect o local and non-local arrows. In fact, 
although it is natural to think of a 'structure' as 
being a maximal network of local arrows with 
a single root object, there's no reason why this 
should be so - networks with multiple roots rep- 
resent tangled structures (structures that share 
content), networks that include non-local links 
might be mixed representations, containing in- 
formation of more than one sort. Such tech- 
niques might be useful for improving generator 
efficiency, or representing canned text or tem- 
plates, cf. (Calder et al, 1999). 
Par t ia l  and  Opaque s t ruc tures  
Partial structures are essential when a module 
needs to produce a skeleton of a representa- 
tion that it does not have the competence to 
completely fill out. For instance, lexical choice 
brings with it certain syntactic commitments, 
but in most NLG systems lexical choice occurs 
some time before a grammar is consulted to 
flesh out syntactic structure in detail. 
Figure 2: A partial structure 
By simply leaving out local arrows, we can 
represent a range of partial structures. Con- 
sider Fig. 2, where the triangles represent local 
structure, representing a sentence object and its 
component verb phrase. There is a link to a sub- 
ject noun phrase object, but none of the local 
arrows of the actual noun phrase are present. In 
subsequent processing this local structure might 
be filled in. This is possible as long as the noun 
phrase object has been declared to be of the 
right type. 
An opaque structure is one which has an in- 
complete derivational history - for example part 
of a syntactic structure without any correspond- 
ing semantic structure. Three possible reasons 
for having such structures are (a) to allow struc- 
ture to be introduced that the generator is not 
capable of producing directly, (b) to prevent he 
generator from interfering with the structure 
thus built (for example, by trying to modify an 
idiom in an inappropriate way), or (c) to im- 
prove generator efficiency by hiding detail that 
may lead to wasteful processing. An opaque 
structure is represented simply by the failure 
to include a rea l i ses  arrow to that structure. 
Such structures provide the basis for a gener- 
alised approach to "canning". 
4 Imp lementat ion  
There are many ways that modules in an 
NLG system could communicate information 
using the representation scheme just outlined. 
Here we describe a particularly general model 
of inter-module communication, based around 
modules communicating with a single cen- 
tralised repository of data called the whiteboard 
(Calder et al, 1999). A whiteboard is a cumu- 
lative typed relational blackboard: 
? t yped  and  re lat iona l :  because it is based 
on using the above representation scheme; 
? a b lackboard :  a control architec- 
ture and data store shared between 
processing modules; typically, modules 
add/change/remove objects in the data 
store, examine its contents, and/or ask to 
be notified of changes; 
? cumulat ive :  unlike standard blackboards, 
once data is added, it can't be changed or 
removed. So a structure is built incremen- 
tally by making successive copies of it (or of 
constituents of it) linked by rev ises  links 
(although actually, there's no constraint on 
the order in which they are built). 
A whiteboard allows modules to add ar- 
rows (typically forming networks through ar- 
rows sharing source or target objects), to in- 
spect the set of arrows looking for particular 
configurations of types, or to be informed when 
a particular type of arrow (or group of arrows) 
is added. 
The whiteboard is an active database server. 
This means that it runs as an independent pro- 
cess that other modules connect o by appropri- 
ate means. There are essentially three kinds of 
interaction that a module might have with the 
whiteboard server: 
? pub l i sh  - add an arrow or arrows to the 
whiteboard; 
122 
? query  - look for an arrow or arrows in the 
whiteboard; 
? wa i t  - register interest in an arrow or ar- 
rows appearing in the whiteboard. 
In both query and wait ,  arrows are specified 
by type, and with a hierarchical type system on 
objects and relations, this amounts to a pattern 
that matches arrows of subtypes as well. The 
wait  function allows the whiteboard to take the 
initiative in processing - if a module wai ts  on a 
query then the whiteboard waits until the query 
is satisfied, and then tells the module about it. 
So the module does not have to continuously 
scan the whiteboard for work to do, but can 
let the whiteboard tell it as soon as anything 
interesting happens. 
Typically a module will start up and regis- 
ter interest in the kind of arrow that represents 
the module's input data. It will then wait for 
the whiteboard to notify it of instances of that 
data (produced by other modules), and when- 
ever anything turns up, it processes it, adding 
its own results to the whiteboard. All the mod- 
ules do this asynchronously, and processing con- 
tinues until no module has any more work to 
do. This may sound like a recipe for confusion, 
but more standard pipelined behaviour is not 
much different. In fact, pipelining is exactly a 
data-based constraint - the second module in a 
pipeline does not start until the first one pro- 
duces its output. 
However, to be a strict pipeline, the first mod- 
ule must produce all of its output before the sec- 
ond one starts. This can be achieved simply by 
making the first module produce all its output 
at once, but sometimes that is not ideal - for ex- 
ample if the module is recursive and wishes to 
react to its own output. Alternative strategies 
include the use of markers in the whiteboard, 
so that modules can tell each other that they've 
finished processing (by adding a marker), or 
extending the whiteboard architecture itself so 
that modules can tell the whiteboard that they 
have finished processing, and other modules can 
wait for that to occur. 
5 Reconst ruct ion  o f  the  Capt ion  
Generat ion  System 
In order to prove this representation scheme 
in practice, we have implemented the white- 
board in Sicstus Prolog and used it to support 
data communications between modules in a re- 
construction of the Caption Generation System 
(Mittal et al, 1995). CGS is a system developed 
at the University of Pittsburgh, which takes in- 
put from the SAGE graphics presentation sys- 
tem (Roth et al, 1994) and generates captions 
for the graphics SAGE produces. We selected it 
for this effort because it appeared to be a fairly 
simple pipelined system, with modules perform- 
ing clearly defined linguistic tasks. As such, we 
thought it would be a good test case for our 
whiteboard specification. 
Although the CGS is organised as a pipeline, 
shown in Figure 3, the representations commu- 
nicated between the modules do not correspond 
to complete, separate instances of RAGS data- 
type representations. Instead, the representa- 
tions at the various levels accumulate along the 
pipeline or are revised in a way that does not 
correspond exactly to module boundaries. Fig- 
ure 3 gives a simple picture of how the different 
levels of representation build up. The labels for 
the RAGS representations refer to the following: 
? I = conceptual; 
? II -- semantic; 
? I I I  = rhetorical; 
? IV = document; 
? V = syntactic. 
For instance, some semantic (II) information is 
produced by the Text Planning module, and 
more work is done on this by Aggregation, but 
the semantic level of representation is not com- 
plete and final until the Referring Expression 
module has run. Also, for instance, at the 
point where the Ordering module has run, there 
are partially finished versions of three different 
types of representation. It is clear from this that 
the interfaces between the modules are more 
complex than could be accounted for by just re- 
ferring to the individual evels of representation 
of RAGS. The ability to express combinations of 
structures and partial structures was fundamen- 
tal to the reimplementation of CGS. We high- 
light below a few of the interesting places where 
these features were used. 
123 
AbsSemRep 
I-el ~ ~  .................................... SemRep 
--(~------~_set{KBPredl ~ fun(Role,set(KBId)) I-el ~3-e l  
. . . .  /X  . . . . . . . .  
el agent affected . . . .  DR fun(Role,set(SemRep)) ~i/  ~ ..... ~ el?set(SemPredi~t A ~ . ? 
nresent set(KSld) 0 . . . . . .  v ? ~--"- ................. / agen, /  \a\] Jec,ea 
el / \ el . . . . .  " . . . . . . . . . .  ~ ?J / "k~ present S~mRep SemRep 
chart1 chart2 
Figure 4: Combined Abstract Semantic Representation a d Concrete Semantic Representation for 
the output: "These two charts present information about house sales from data-set ts-1740" 
CG$ aroh i ta ,~ lu 'e  RAGS representat/on$ 
II I l l  IV ~' SAGE 
- -  . . . . . . . . . .  
tuning II 
- . . . . . . . . . .  
I1 I11 iV  
--' . . . . . . . . . .  
I\[ I11 IV 
. . . . . . . . . .  I ;11@ 
11 III I v  v 
. . . . . . . . .  
II I11 IV V 
. . . . . . . . .  III1  
II 111 IV V 
l - -  . . . . . . . . . .  I I I I I  
FUF 
Figure 3: A RAGS view of the CGS system 
5.1 Referr ing Express ion Generat ion  
In many NLG systems, (nominal) referring ex- 
pression generation is an operation that is in- 
voked at a relatively late stage, after the struc- 
ture of individual sentences i  fairly well speci- 
fied (at least semantically). However, referring 
expression generation eeds to go right back to 
the original world model/knowledge base to se- 
lect appropriate semantic ontent o realise a 
particular conceptual item as an NP (whereas 
all other content has been determined much ear- 
lier). In fact, there seems to be no place to 
put referring expression generation i a pipeline 
without there being some resulting awkward- 
ness. 
In RAGS, pointers to conceptual items can 
be included inside the first, "abstract", level of 
semantic representation (AbsSemRep), which is 
intended to correspond to an initial bundling of 
conceptual material under semantic predicates. 
On the other hand, the final, "concrete", level 
of semantic representation (SemRep) is more 
like a fully-fledged logical form and it is no 
longer appropriate for conceptual material to 
be included there. In the CGS reimplementa- 
tion, it is necessary for the Aggregation mod- 
ule to reason about the final high-level semantic 
representation f sentences, which means that 
this module must have access to "concrete" se- 
mantic representations. The Referring Expres- 
sion generation module does not run until later, 
which means that these representations cannot 
be complete. 
Our way around this was to ensure that the 
initial computation of concrete semantics from 
abstract semantics (done as part of Aggrega- 
tion here) left a record of the relationship by 
including realises arrows between correspond- 
ing structures. That computation could not be 
completed whenever it reached conceptual ma- 
terial - at that point it left a "hole" (an ob- 
ject with no further specification) in the con- 
crete semantic representation li ked back to the 
conceptual material. When referring expression 
was later invoked, by following the arrows in the 
124 
resulting mixed structure, it could tell exactly 
which conceptual entity needed to be referred 
to and where in the semantic structure the re- 
sulting semantic expression should be placed. 
Figure 4 shows the resulting arrangement for 
one example CGS sentence. The dashed lines 
indicate realises, i.e. non-local, arrows. 
5.2 Handling Centering Information 
The CGS Centering module reasons about the 
entities that will be referred to in each sentence 
and produces a representation which records the 
forward and backward-looking centers (Grosz et 
al., 1995). This representation is later used by 
the Referring Expression generation module in 
making pronominalisation decisions. This in- 
formation could potentially also be used in the 
Realisation module. 
Since Centering is not directly producing re- 
ferring expressions, its results have to sit around 
until they can actually be used. This posed 
a possible problem for us, because the RAGS 
framework does not provide a specific level of 
representation for Centering information and 
therefore seems on first sight unable to account 
for this information being communicated be- 
tween modules. The solution to the problem 
came when we realised that Centering informa- 
tion is in fact a kind of abstract syntactic in- 
formation. Although one might not expect ab- 
stract syntactic structure to be determined until 
the Realisation module (or perhaps lightly ear- 
lier), the CGS system starts this computation i
the Centering module. 
Thus in the reimplementation, the Centering 
module computes (very partial) abstract syn- 
tactic representations for the entities that will 
eventually be realised as NPs. These represen- 
tations basically just indicate the relevant Cen- 
tering statuses using syntactic features. Figure 
5 shows an example of the semantics for a typi- 
cal output sentence and the two partial abstract 
syntactic representations computed by the Cen- 
tering module for what will be the two NPs in 
that sentence 2. As before, dashed lines indicate 
realises arrows. Of course, given the discussion 
of the last section, the semantic representation 
objects that are the source of these arrows are in 
fact themselves linked back to conceptual enti- 
ties by being the destination of realises arrows 
2FVM = Feature Value Matrix. 
from them. 
When the Referring Expression generation 
module runs, it can recover the Centering infor- 
mation by inspecting the partial syntactic rep- 
resentations for the phrases it is supposed to 
generate. These partial representations are then 
further instantiated by, e.g., Lexical Choice at 
later stages of the pipeline. 
6 Conc lus ion  
The representation scheme we have proposed 
here is designed specifically to support he re- 
quirements of the current state-of-the-art NLG 
systems, and our pilot implementation demon- 
strates the practical applicability of the pro- 
posal. Tangled, partial and mixed structures 
are of obvious utility to any system with a flex- 
ible control strategy and we have shown here 
how the proposed representation scheme sup- 
ports them. By recording the derivational his- 
tory of computations, it also supports decisions 
which partly depend on earlier stages of the 
generation process (e.g., possibly, lexical choice) 
and revision-based architectures which typically 
make use of such information. We have shown 
how the representation scheme might be the ba- 
sis for an inter-module communication model, 
the whiteboard, which supports a wide range of 
processing strategies that require the represen- 
tation of complex and evolving data dependem 
cies. The fact that the whiteboard is cumula- 
tive, or monotonic in a logical sense, means that 
the whiteboard also supports reasoning about 
the behaviour of NLG systems implemented in 
terms of it. This is something that we would 
like to exploit directly in the future. 
The reimplementation f the CGS system 
in the RAGS framework was a challenge to 
the framework because it was a system that 
had already been developed completely inde- 
pendently. Even though we did not always un- 
derstand the detailed motivation for the struc- 
ture of CGS being as it was, within a short time 
we reconstructed a working system with mod- 
ules that corresponded closely to the original 
CGS modules. The representation scheme we 
have proposed here was a key ingredient in giv- 
ing us the flexibility to achieve the particular 
processing scheme used by CGS whilst remain- 
ing faithful to the (relatively simple) RAGS 
data model. 
125 
SemRep 
fun(Role,setlSemRep)) 
sl S " ' .  
t t ~ .  
2 AbsSynRep "~ AbsSynRep _(:5 ~ ,  
, , / \ \ 
ckward-looking-cemer ckward.looking-cenler 
+ + 
Figure 5: Arrangement of centering information for the output sentence above 
The representation scheme is useful in situa- 
tions where modules need to be defined and im- 
plemented to work with other modules, possibly 
developed by different people. In such cases, the 
representation scheme we propose permits pre- 
cise definition of the interfaces of the modules, 
even where they are not restricted to a single 
'level' of representation. Even though the con- 
trol structure of CGS is quite simple, we found 
that the use of a centralised whiteboard was use- 
ful in helping us to agree on interfaces and on 
the exact contribution that each module should 
be making. Ultimately, it is hoped that the use 
of a scheme of this type will permit much more 
widespread 'plug-and-play' among members of 
the NLG community. 
Re ferences  
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999a. In Search of a Reference 
Architecture for NLG Systems. In Proceedings of 
the 7th European Workshop on Natural Language 
Generation, pages 77-85, Toulouse. 
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999b. Towards a Reference 
Architecture for Natural Language Genera- 
tion Systems. Technical Report ITRI-99-14, 
Information Technology Research Institute 
(ITRI), University of Brighton. Available at 
http://www, i t r i  .brighton. ac. uk/proj ects/rags.  
Jo Calder, Roger Evans, Chris Mellish, and Mike 
Reape. 1999. "Free choice" and templates: how 
to get both at the same time. In "May I speak 
freely?" Between templates and free choice in nat- 
ural language generation, number D-99-01, pages 
19-24. Saarbriicken. 
B.J. Grosz, A.K. Joshi, and S. Weinstein. 1995. 
Centering: a framework for modelling the local co- 
herence of discourse. Computational Linguistics, 
21 (2):203-226. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and 
G. Carenini. 1995. Generating explanatory cap- 
tions for information graphics. In Proceedings of 
the 15th International Joint Conference on Ar- 
tificial Intelligence (IJCAI'95), pages 1276-1283, 
Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 
1998. Describing complex charts in natural lan- 
guage: A caption generation system. Computa- 
tional Linguistics, 24(3):431-468. 
Ehud Reiter. 1994. Has a consensus NL generation 
architecture appeared and is it psycholinguisti- 
cally plausible? In Proceedings of the Seventh In- 
ternational Workshop on Natural Language Gen- 
eration, pages 163-170, Kennebunkport, Maine. 
Steven F. Roth, John Kolojejchick, Joe Mattis, and 
Jade Goldstein. 1994. Interactive graphic design 
using automatic presentation knowledge. In Pro- 
ceedings of CHI'9~: Human Factors in Computing 
Systems, Boston, MA. 
126 
Reinterpretation of an existing?NLG system in a Generic Generation 
Architecture 
L. Cahill, C. Doran~ R. Evans, C. Meilish, D. Paiva,:M. Reape, D. Scott,, N. Tipper 
.Universities of Brighton and Edinburgh. 
Email rags@itri, brighton, ac. uk 
Abstract 
The RAGS project aims to define a reference ar- 
chitecture for Natural Language Generation (NLG) 
systems. Currently the major part of this archi- 
tecture consists of a set of datatype definitions for 
specifying the input and output formats for mod- 
ules within NLG systems. In this paper we describe 
our efforts to reinterpret an existing NLG system in 
terms of these definitions. The system chosen was 
the Caption Generation System. 
2. Which aspects of the RAGS repertoire would 
: . . . .  . . . .  - .... -,.= ., ~,~,aemaltybe'requireti~ftrr~strch~a-~reinterpretation; 
which would be unnecessary and which addi- 
tions to the RAGS repertoire would be moti- 
vated. 
1 Introduction 
The RAGS project ~ aims to define a reference ar- 
chitecture for natural anguage generation systems. 
Currently the major part of this architecture consists 
of a set of datatype definitions for specifying the 
input and output formats for modules within NLG 
systems. The intention is that such representations 
can be used to assist in reusability of components 
of NLG systems. System components that adhere 
to these representations, or use a format hat can be 
translated into such representations relatively eas- 
ily, can then, in principle, be substituted into other 
systems. Also, individual components could be de- 
veloped without the need for a complete system if 
datasets, based on the representations, were made 
available. 
In this paper we describe an attempt to reinterpret 
an existing NLG system in terms of the RAGS data 
definitions. The point of this exercise was to lem-n: 
1. Whether these data structures were sufficient 
to describe the input and output functionality 
of an existing, independently developed, ap- 
3. Whether studying the system would generate 
good ideas about possible reusable generation 
modules that could be developed. 
In this exercise it was important o choose a sys- 
tem that had been developed by people outside the 
RAGS project. Equally, it was important o have 
sufficient clear information about the system in the 
available literature, and/or by means of personal 
contact with the developers. The system chosen was 
the Caption Generation System (Mittal et al, 1995; 
Mittal et al, 1998) 3. This system was chosen be- 
cause, as well as fulfilling the criteria above, it ap- 
peared to be a relatively simple pipeline, thus avoid- 
ing complex control issues, with individual modules 
performing the varied linguistic tasks that the RAGS 
data structures had been designed to handle. 
The reinterpretation exercise took the form of 
coming up with an account of how the interfaces 
to the CGS modules corresponded to the RAGS 
model and reimplementing a working version of 
each module (apart from Text Planning and Realisa- 
tion) which was tested to ensure that, given appro- 
priate input, its output was correct (i.e. conforming 
to the global account) on key examples. Naturally, 
given the scope of this exercise, we had to gloss over 
some interesting implementational issues. The aim 
was not to produce a complete system or a system 
as good as CGS, but merely to demonstrate hat the 
broad functionality of the system could be repro- 
plied 2 NLG system. 
? Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran.?mitre, org. 
tThis work was supported by ESPRC grants GR/L77041 
(Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Ar- 
chitecture for Generation Systems. 
-'See (Paiva, 1998) for a definition of applied in this specific 
context. 
" . -ducedwithin:the RAGS .structures. 
In this paper we first describe the RAGS data 
structures. We then describe the CGS system 
3In addition to these published sources, we were greatly 
helped by the developers of the system who gave us the ben- 
efit of their own expertise as well as access to the original code 
of the system and a technical report hat included implementa- 
tional details such as system traces. 
69 
followed by our reinterpretation of the system in Abstract Rhetorical Abstract Rhetorical Repre- 
RAGS terms. Finally we discuss,, the :implications:. :. -._..sentations ,are--tree-structures with,rhetorical .rela- 
for RAGS of this exercise, tions at the internal nodes and Abstract Rhetorical 
2 The RAGS datatypes  
The RAGS project initially set out to develop a ref- 
erence architecture based on the three-stage pipeline 
suggested by Reiter (Reiter, 1994). However, a 
trees or Abstract Semantic Representations at the 
leaves. 
Rhetorical Abstract Rhetorical Representations 
are viewed as descriptions of sets of possible 
Rhetorical Representations. Each one may be trans- 
detailed analysis of existing applied NLG systems formed into some subset of the possible Rhetori- 
(Cahill and Reape~_~ l:998}:suggested~,that~ttch.an~ ar -~: ~<.eaLReprese, ntations by,,means ~ofa,set..o_f~.petmitted 
chitecture was not specific enough and not closely transformations, e.g. reversing the order of nucleus 
enough adhered to by the majority of the systems 
surveyed for this to be used as the basis of the archi- 
tecture. 
The abstract functionality of a generation system 
can be specified without specific reference to pro- 
cessing. The RAGS approach to this is to develop a 
data model, that is, to define the functional modules 
entirely in terms of the datatypes they manipulate 
and the operations they can perform on them. On 
top of such a model, more specific process models 
can be created in terms of constraints on the order 
and level of instantiation of different ypes of data in 
the data model. A 'rational reconstnaction' of some 
pipeline model might then be produced, but other 
process models would also be possible. 
The RAGS levels of representation are as fol- 
lows4: 
Conceptual The conceptual level of representa- 
tion is defined only indirectly through an API via 
which a knowledge base (providing the content 
from which generation takes place) can be viewed 
as if it were defined in a simple KL-ONE (Brach- 
man and Schmolze, 1985) like system. 
Abstract Semantic Abstract semantic representa- 
tions are the first level at which semantic predicates 
are associated with arguments. At this level, seman- 
tic predicates and roles are those used in the API to 
query the knowledge base and arguments are knowl- 
edge base entities. 
Semantic (Concrete) semantic representations 
provide a complete notation for "logical forms" 
where there is no longer any reference to ,the knowl- 
edge base. The representations are based on sys- 
tems such as SPL (Kasper, 1989) and DRT (Kamp 
and Reyle, 1993). 
4More details can be found in (Cahill et 
al., 1999) and at the RAGS project web site: 
ht tp  : / /www.  i t r i  . b r ighton ,  ac. uk/rags.  
and satellite or changing the rhetorical relation to 
one within a permitted set. 
Abstract Document Document structure defines 
the linear ordering of the constituents of the Rhetor- 
ical Representation with a POSITION feature, as 
well as two other features, TEXT-LEVEL, which 
takes values such as paragraph or sentence; and 
LAYOUT, which takes values such as wrapped-text 
and vertical list. It takes the form of a tree, usu- 
ally, but not necessarily, isomorphic to the Rhetor- 
ical Representation a d linked to it, but with these 
three features at the nodes instead of rhetorical rela- 
tions. 
Abstract Syntactic Abstract Syntactic Represen- 
tations capture high-level aspects of syntactic struc- 
ture in terms of notions such as lexical head, speci- 
fiers, modifiers and complements. This level of rep- 
resentation is compatible with approaches such as 
LFG f-structure, HPSG and Meteer's Text Structure. 
3 Partial and Mixed Representations 
For all of the RAGS levels partial representations 
are possible. Without this, it is not possible for a 
module to pass any result to another until that re- 
sult is completely determined, and this would im- 
pose an unwanted bias towards simple pipeline ar- 
chitectures into the model. There are many cases 
in NLG where a representation is built collabora- 
tively by several modules. For instance, many sys- 
tems have a referring expression generation module 
whose task is to complete a semantic representation 
which lacks those structures which will be realised 
as NPs. Such a functionality cannot be described 
unless partially complete semantic representations 
can be communicated. 
In addition, mixed representations are possible, 
where (possibly partial) representations at several 
levels are combined with explicit links between the 
elements. Many NLG modules have to be sensi- 
70 
tive to a number of levels at once (consider, for 
.......... instance, -aggregatiomxeferring,expmssion.,genera- 
tion and lexicalisation, all of which need to take 
into account rhetorical, semantic and syntactic on- 
straints). The input to most reusable realisation sys- 
tems is also best viewed as a mixture of semantic 
and abstract syntactic information. 
The extra flexibility of having partial and mixed 
representations turned out to be vital in the recon- 
struction of the CGS system. (Mellish et al, 2000). 
4 The CGS system 
The Caption Generation System (CGS) generates 
explanatory captions of graphical presentations (2- 
D charts and graphs). Its architecture is a pipeline 
with several modules, shown in the left hand part of 
Figure 1. An example of a diagram and its accom- 
panying text are given in Figure 2. The propositions 
are numbered for ease of reference throughout the 
paper. 
The input to CGS is a picture representation 
(graphical elements and its mapping from the data 
set) generated by SAGE plus its complexity metric. 
The text planning module (Moore and Paris (1993)) 
plans an explanation i  terms of high level discourse 
goals. The output of the planner is a partially or- 
dered plan with speech-acts as leaves. 
The ordering module receives as input the dis- 
course plan with links specifying the ordering re- 
lations between sub-trees and specifies an order for 
them based on heuristics uch as that the description 
should be done from left to right in the visual space. 
The aggregation module "only conjoins pairs of 
contiguous propositions about the same grapheme 
type 5 in the same space" (Mittai et al, 1999) and 
inserts cue phrases compatible with the propositions 
e o ( .=., "whereas" for contrastive ones). The internal 
order of the sentence constituents i determined by 
the centering module using an extension of the cen- 
tering theory of Grosz and colleagues (Grosz et al, 
1995). 
The referring expression module uses Date and 
Reiter's (Dale and Reiter, 1995) algorithm to con- 
struct the set of attributes that can uniquely identify 
a referent. There are'two, situations where the text 
planning module helps specifically in the generation 
of referring expressions: (1) when the complexity 
for expressing a graphic demands an example and 
5"Graphemes are the basic building blocks for constructing 
pictures. Marks, text, lines and bars are some of the different 
grapheme classes available in SAGE." (IVlittal et al, 1999). 
CGS architecture 
SAGE 
RAGS representations 
I I I  I I I  IV  V 
I II HI  IV  V 
? I I I  I I I  IV  " V . 
I I I  In  IV  v 
l -  .......... I /11  
1 It  I I I  IV V 
l -  .......... 
I 11 11I IV V 
.......... III1  
I I I  HI  IV  V 
; "  .......... I I I I I  
FUF 
Figure 1: A RAGS view of the CGS system. The 
labels for the RAGS representations refer to the fol- 
lowing: I = conceptual; II = semantic; III = rhetori- 
cal; IV = document; V = syntactic. 
it signals this both to SAGE (for highlighting the 
corresponding grapheme) and to the rest of the text 
generation modules; and (2) when in a specific sit- 
uation the referring algorithm would need several 
interactions for detecting that an entity is unique in 
? a certain visual space and.the planning could detect 
it in the construction of the description of this space. 
When this occurs, the text planner "circumvents he 
problem for the:.referring ,expression :module at the 
planning stage itself, processing the speech-acts ap- 
propriately to avoid this situation completely". 
After lexicalisation, which adds lexeme and ma- 
jor category information, the resulting functional 
descriptions are passed to the FUF/SURGE realiser 
that generates texts like the caption of Figure 2. 
71 
\ [ \ ]  
O 
te l  
O 
IZl 
ZS:3 
I21 ,:7-. ,,S . . . .  ; . . . .  .' ? 
O ~ ~Ipc~ q~L~ 
\] 
I 
\] 
=::::::;=a___.,____.__,_______~ 
. ,  , : ,  ; .  . ,  
Figure 2: (1) These two charts present information about house sales from data-set ts-1740. (2) In the two 
charts, the y-axis indicates the houses. (7) In the first chart, the left edge of the bar shows the house's elling 
price whereas (8) the right edge shows the asking price. (3) The horizontal position of the mark shows the 
agency estimate. (4) The color shows the neighbourhood and (5) shape shows the listing agency. (6) Size 
shows the number of rooms. (9) The second chart shows the number of days on the market. 
5 Reinterpretat ion f  CGS in RAGS 
Our reinterpretation f the CGS system defines the 
interfaces between the modules of CGS in terms 
of the RAGS data structures discussed above. In 
this section we discuss the input and output inter- 
faces for each CGS module in turn as well as any 
problems we encountered in mapping the structures 
into RAGS structures. Figure 1 shows the incre- 
mental build-up of the RAGS data levels across 
the pipeline. Here we have collapsed the Abstract 
Rhetorical and Rhetorical and the Abstract Seman- 
tic and Semantic. It is-interesting to note that the 
build up of levels of representation does not tend to 
correspond exactly with module boundaries. 
One of the major issues we faced in' our reinter- 
pretation was where to produce representations (or
partial representations) whose emergence was not 
defined clearly in the descriptions of CGS. For in- 
stance, many decisions about document structure 
are made only implicitly by the system. In most 
cases we have opted to produce all types of repre- 
sentations at the earliest point where they can con- 
ceivably have any content. This means, for instance, 
that our reimplementation assumes an (unimple- 
mented) text planner which produces an Abstract 
Rhetorical Representation with Abstract Semantic 
leaves and an Abstract Document Representation. 
Text Planner The input to the Longbow text plan- 
ner discussed in section 4 above is a representation 
of a picture in SAGE format (which has been an- 
notated to indicate the types of complexity of each 
grapheme) together with a goal, which can typi- 
cally be interpreted as "describe". It outputs an es- 
sentially fiat sequence of plan operators, each of 
which corresponds in the output? text .to .a.speech 
act. In our reinterpretation, we have assumed that 
this fiat structure needs to be translated into an Ab- 
stract Rhetorical Representation with (at least) min- 
imal structure. Such a structure is implicit in the 
plan steps, and our interpretation f the rhetorical 
structure for the example text corresponds closely to 
that of the post-processing trace produced by CGS. 
72 
I .AYOI  FII" * 'upped tel l  
" IU  ,I.EVIZL. p J t l~aph 
~ f ~ I O N :  2 
POSlllON I 
I.AYOtr'I+: -~pped tell 
TEX"T.L~ VEL 
(1) 
POSITION: I POSITION: 2 
LAYOUT: *T~,pl~n.l teat 
"IEXT-LEVEL: + 
(2) 
Po$ : I POSITION: 1 
LAYOUT: -mtpFcd te~t 
. TE.ICr-t.EVEL~ ?
0OSFI-K~N. 2 PosmoN: i 
POSIllON: I PosrnoN: I POsmoN. ~ FoSmON: 4 POSt'nON I PosrnoN: 2 
LAYOUT: ~pp~d lesl LAYOU'T. ~ppe,.f ~xt LAYO\[rF. ~apped lesl LAYOUT: ~+r~pS~d I?xt LAYOUT. ~'?~l~,Od ~est LAYOUT: ~Tappe~ text 
TEXT,LEVEL  7 "II~XT,LEVEI.: ~ "II~XT-LEVEL ? "I I~XT-LEVEL: ? TEXT-LEVEL  "+ TIE~XT-L.EVI:I.: ? 
(3) (4) (5) (6) (7) (8) 
Figure 3: Initial Document Structure 
. . .Z., 
However, we are still not entirely sure 
exactly CGS creates this structure, so 
posed it at the very beginning, onto the 
text planner. 
Already at this stage it is necessary 
about where 
we have im- 
output of the 
to make use 
of mixed RAGS representations. As well as this 
Abstract Rhetorical Representation, the text planner 
has to produce an Abstract Document Representa- 
tion, linked to the Abstract Rhetorical Representa- 
tion. This is already partially ordered - although the 
exact value of POSITION features cannot be speci- 
fied at this stage, the document tree is constructed 
so that propositions are already grouped together. 
In addition, we make explicit certain default infor- 
mation that the CGS leaves implicit at this stage, 
namely, that the LAYOUT feature is always wrapped 
text and that the TEXT-LEVEL feature of the top 
node is always paragraph. 
Ordering The ordering module takes the Abstract 
Document Representation a d the Abstract Rhetor- 
ical Representation as input and outputs an Abstract 
Document Representation with the POSITION fea- 
ture 's  value filled,for all :the nodes, .That is, it fixes. ? 
the linear order of the final output of the speech acts. 
In our example, the ordering is changed so that steps 
7 and 8 are promoted to appear before 3, 4, 5 and 6. 
The resulting structure is shown in figure 36 . 
6In this and the.following diagrams, objects are represented 
by circles with (labelled) arrows indicating the relations be-- 
Aggregation Although aggregation might seem 
like a self-contained process within NLG, in prac- 
tice it can make changes at a number of levels of 
representation a d indeed it may be the last opera- 
tion that has an effect on several levels. The aggre- 
gation module in our reinterpretation thus has the fi- 
nal responsibility to convert an Abstract Rhetorical 
Representation with Abstract Semantic Represen- 
tation leaves into a Rhetorical Representation with 
Semantic Representation leaves. The new Rhetori- 
cal Representation may be different from before as 
a result of speech acts being aggregated but whether 
different or not, it can now be considered final as 
it will no longer be changed by the system. The 
resulting Semantic Representations are no longer 
Abstract because further structure may have been 
determined for arguments to predicates. On the 
other hand, referring expressions have not yet been 
generated and so the (Concrete) Semantic Repre- 
sentations cannot be complete. The reconstruc- 
,.tion createspartia.i Semantic Representations with 
"holes" where the referring expressions (Semantic 
Representations) will be inserted. These "holes" are 
linked back to the knowledge base entities tfiat they 
correspond to. 
Because Aggregation affects text levels, it also af- 
fects the Abstract Document Representation, which 
has its TEXT-LEVEL feature's values all filled at this 
tween them. Dashed arrows indicate links between different 
levels of representation. 
73 
SemRep 
fun(Role,SemRep) 
DR preS  , . mRep 
? AbsSynRep ~ AbsSynRe~ 
/ " \  Y^.Z(" 
FVM (~ ~ ,un(Funs,~gS~c) (,~ ~M (~) lun(Funs.ArgSpec) 
0 ~ 0 0 
? + 
Adjs 
. . - ; . .  
Figure 4: Syntactic representations constructed by Centering 
point. It may also need to change the structure 
of the Abstract Document Representation, for in- 
stance, adding in a node for a sentence above two, 
now aggregated, clause nodes. 
Centering Because Centering comes before Re- 
ferring Expression generation and Realisation, all it 
can do is establish constraints that must be heeded 
by the later modules. At one stage, it seemed as if 
this required communicating a kind of information 
that was not covered by the RAGS datatypes. How- 
ever, the fact that an NP corresponds (or not) to a 
center of some kind can be regarded as a kind of 
abstract syntactic information. The reconstruction 
therefore has the centering module building a partial 
(unconnected) Abstract Syntactic representation for 
each Semantic Representation that will be realised 
as an NP, inserting a feature that specifies whether 
it constitutes a forward- or backward-facing cen- 
ter, approximately following Grosz et al(Grosz et 
al., 1995). This information is used to determine 
whether active or passive voice will be used. An 
example of such a partial Abstract Syntactic Repre- 
sentation is given in Figure 4. 
Referring Expression In our reconstruction of 
the CGS system, we have deviated from reproduc- 
ing the exact functionality for the referring expres- 
sion module and part of the lexical choice module. 
In the CGS system, the referring expression module 
computes association lists which can be used by the 
lexical choice module to construct referring expres- 
sions suitable for realisation. In our reconstruction, 
however, the referring expression module directly 
computes the Semantic Representations of referring 
expressions. 
We believe that this is a good example of a 
case where developing a system with the RAGS 
data structures in mind simplifies the task. There 
are undoubtedly many different ways in which the 
same results could be achieved, and there are many 
(linguistic, engineering etc.) reasons for choosing 
one rather than another. Our particular choice is 
driven by the desire for conceptual simplicity, rather 
than any strictly linguistic or computational motiva- 
tions. We considered for each module which RAGS 
level(s) it contributed to and then implemented it to 
manipulate that (or those) level(s). In this case, that 
meant a much more conceptually simple module 
which just adds information to the Semantic Rep- 
resentations. 
Lexical Choice In CGS, this module performs a 
range of tasks, including what we might call the 
later.stages of_referring expression generation and 
lexical choice, before converting the plan leaves 
into FDs (Functional Descriptions), which serve as 
the input to the FUF/SURGE module. In the re- 
construction, on the other hand, referring expres- 
sions have already been computed and the Rhetor- 
ical Representation, with its now complete Seman- 
tic Representations, needs to be "lexicalised" and 
74 
' ,t ~1  
" .  set 
Figure 5: Combined Semantic and Abstract Syntactic Representation 
translated into FUF/SURGE format. Lexicalisa- 
tion in our terms involves adding the lexeme and 
major category information to the Abstract Syntac- 
tic Representations for the semantic predicates in 
each Semantic Representation. The FUF/SURGE 
input format was regarded as a combination of Se- 
mantic and Abstract Syntactic information, and this 
can easily be produced from the RAGS representa- 
tions. The combined Semantic and Abstract Syn- 
tactic Representations for the plan step "These two 
charts present information about house sales from 
data set ts-1740" is shown in Figure 5. The boxes 
indicate suppressed subgraphs of the lexemes cor- 
responding to the word in the boxes and triangles 
indicate suppressed subgraphs of the two adjuncts. 
6 Conclusions 
The reconstruction of CGS has taken the form of 
working out in detail the RAGS representations 
passed between modules at each stage for a set 
of key examples and reimplementing the modules 
(apart from the Planner and Realiser) in a way that 
correctly reproduces these representations. The ac- 
tual implementation used an incrementally growing 
data store for the RAGS representations which the 
modules accessed in turn, though the passing of data 
could also have been achieved in other ways. 
The fact that the reconstruction has been success- 
ful indicates that the RAGS architecture is broadly 
adequate to redescribe this NLG system: 
? No changes to the existing levels of represen- 
tation were needed, though it was necessary to 
make extensive use of partial and mixed repre- 
sentations. 
o No new levels of representation needed to be 
introduced to capture the inter-module com- 
munication of the system. 
o All of the levels of representation_apart from 
the Conceptual level were used significantly in
the reconstruction. 
In some ways, i t  is unfortunate that none of the 
inter-module interfaces of CGS turned out to use a 
single level of RAGS representation. Given the mo- 
tivation for partial and mixed representations above, 
however, this did not really come as a surprise. It 
may well be that any really useful reusable modules 
for NLG will have to have this complexity. 
75 
In spite of the successful testing of the RAGS data 
model, somedifficulties were encountered: 
* It was difficult to determine the exact nature 
of the representations produced by the Planner, 
though in the end we were able to develop a 
system to automatically translate these into a 
format we could deal with. 
o Although the theoretical model o f  CGS has a 
simple modular structure, in practice the mod- 
ules are very tightly inte-gr~ifed and making-the " 
exact interfaces explicit was not always easy. 
? Referring expression generation requires fur- 
ther access to the "knowledge base" holding 
information about he graphic to be produced. 
This knowledge was only available via interac- 
tions with SAGE, and so it was not possible to 
determine whether the RAGS view of Concep- 
tual Representations was applicable. Our own 
implementation f referring expression gener- 
ation had to work around this problem in a non- 
portable way. 
? It became clear that there are many housekeep- 
ing tasks that an NLG system must perform 
following Lexical Choice in order for the final 
Semantic and Abstract Syntactic Representa- 
tions to be appropriate for direct input to a re- 
alisation system such as FUF. 
o The fact that the system was driving 
FUF/SURGE seems to have had a signif- 
icant effect on the internal representations 
used by CGS. The reconstruction echoed this 
and as a result may not be as general as could 
be desired. 
? Even though CGS only performs imple types 
of Aggregation, it is clear that this is a critical 
module for determining the final form of sev- 
eral levels of representation. 
The division of CGS into modules is different from 
that used in any NLG systems we have previously 
worked on and so has been a useful stimulus to think 
about ways in which reusable modules can be de- 
signed. We envisage reusmgat  least,the reimple- 
mentation of the Centering module in our further 
work. 
References 
R. Brachman and J. Schmolze. 1985. An overview of the KL- 
ONE knowledge representation system. Cognitive Science, 
9:171-216. 
Lynne Cahill and Mike Reape. 1998. Component asks 
in applied NLG .systems . . . .  Technical Report ITR!- 
99-05, ITRI, University of Brighton. obtainable at 
http:/lwww.itri.brighton.ac.uk/projects/rags/. 
Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, 
Daniel Paiva, Mike Reape, Donia Scott, and Neil Tipper. 
1999. In Search of a Reference Architecture for NLG Sys- 
tems. In Proceedings of the 7th European Workshop on Nat- 
ural Language Generation, pages 77-85, Toulouse. 
Robert Dale and Ehud Reiter. 1995. Computational interpre- 
tations of the Gricean maxims in the generation ofreferring 
expressions. Cognitive Science, 18:233-263. 
B J .  Grosz, A/K.J6shil-and S.Weinstein. 1995~ Centering: a 
framework for modelling the local coherence of discourse. 
Computational Linguistics, 21 (2):203-226. 
H. Kamp and U. Reyle. 1993. From discourse to logic: Intro- 
duction to model theoretic semantics of natural language, 
formal logic and discourse representation theory. Kluwer, 
Dordrecht; London. 
R. T. Kasper. 1989. A flexible interface for linking applica- 
tions to penman's sentence generator. In Proceedings of the 
DARPA Speech and Natural Language Workshop, Philadel- 
phia. 
C. Mellish, R. Evans, L. Cahill, C. Doran, D. Paiva, M. Reape, 
D. Scott, and N. Tipper. 2000. A representation forcomplex 
and evolving data dependencies in generation. In Proceed- 
ings of the Applied Natural Language Processing (ANLP- 
NAACL2000) Conference, Seattle. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and G. Carenini. 
1995. Generating explanatory captions for information 
graphics. In Proceedings of the 15th International Joint 
Conference on Artificial Intelligence (IJCAI'95), pages 
1276-1283, Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 1998. 
Describing complex charts in natural anguage: A caption 
generation system. Computational Linguistics, 24(3):431- 
468. 
Daniel Paiva. 1998. A survey of applied natural lan- 
guage generation systems. Technical Report ITRI- 
98-03, Information Technology Research Insti- 
tute (ITRI), University of Brighton. Available at 
http://www.itri.brighton.ac.uk/techreports. 
Ehud Reiter. 1994. Has a consensus NL generation architec- 
ture appeared and is it psycholinguistically p ausible? In 
Proceedings of the Seventh International Workshop on Nat- 
ural Language Generation, pages 163-170, Kennebunkport, 
Maine. 
Acknowledgements 
We would like to thank the numerous people who have 
helped us in this work. The developers of CGS, especially 
Giuseppe Carenini and Vibhu Mittal; the RAGS consultants 
and other colleagues at Brighton and Edinburgh, who have con- 
tributed greatly to our development ofthe representations; and 
finally to the anonymous reviewers of this paper. 
76 
Proceedings of the NAACL-HLT 2012: Demonstration Session, pages 9?12,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Navigating Large Comment Threads With CoFi
Christine Doran, Guido Zarrella and John C. Henderson The MITRE Corporation Bedford, MA {cdoran,jzarrella,jhndrsn}@mitre.org  
Abstract 
Comment threads contain fascinating and use-ful insights into public reactions, but are chal-lenging to read and understand without computational assistance. We present a tool for exploring large, community-created com-ments threads in an efficient manner. 1 Introduction The comments made on blog posts and news arti-cles provide both immediate and ongoing public reaction to the content of the post or article. When a given site allows users to respond to each other (?threaded? responses), the comment sets become a genuine public conversation. However, this in-formation can be difficult to access. Comments are typically not indexed by search engines, the vol-ume is often enormous, and threads may continue to be added to over months or even years. This makes it hard to find particular information of in-terest (say, a mention of a particular company in a set of thousands of YouTube comments), or to un-derstand the gist of the discussion at a high-level. Our goal in this work was to create a simple tool which would allow people to rapidly ingest useful information contained in large community-created comment threads, where the volume of data precludes manual inspection. To this end, we created CoFi (Comment Filter), a language-independent, web-based interactive browser for single comment threads. 2 How CoFi works For a given set of comments, we create a distinct CoFi instance. Each instance is over a natural data set, e.g. all comments from a particular discussion group, comments attached to an individual news article, or tweets resulting from a topical search. Creating a CoFi instance has three steps: harvest-
ing the comments, clustering the comments, and responding to user interactions while they visualize and navigate (sorting and filtering) the dataset. 2.1 Harvesting the data Our comments are harvested from individual web sites. These need not be in English, or even in a single language. Typically, sites use proprietary javascript to present comments. Each web site has a unique interface and formatting to serve the comments to web browsers, and there is no general purpose tool to gather comments everywhere. The CoFi approach has been to factor this part of the problem into one harvesting engine per web site. Some sites provide an API that simplifies the prob-lem of harvesting comments that contain particular keywords. On other sites, there seems to be no re-liable alternative to developer ingenuity when it comes to altering the harvesting engines to ac-commodate data formats. Thus, we note that the harvesting activity is only semi-automated. 2.2 Clustering the data Once harvesting is complete, the rest of the process is automatic. Clusters are generated and labeled using a pipeline of machine learning tools. The open source package MALLET provides many of our document ingestion and clustering components (McCallum, 2002). Our processing components are language-independent and can be used with non-English or mixed language data sets. Specifically, we use a combination of Latent Dirichlet Allocation (LDA), K-Means clustering, and calculation of mutual information. LDA mod-els each document (aka comment) as a mixture of latent topics, which are in turn comprised of a probability distribution over words (Chen, 2011, gives a good overview). It?s an unsupervised algo-rithm that performs approximate inference. The topics it infers are the ones that best explain the statistical distributions of words observed in the 
9
data. It is highly parallelizable and so it scales well to very large data sets. In practice we ask LDA to search for 5k topics, where k is the number of clus-ters we will eventually display to the user. The second step is to perform K-Means cluster-ing on the documents, where the documents are represented as a mixture of LDA topics as de-scribed above, and the clustering chooses k clusters that minimize the differences between documents in the cluster while maximizing the difference be-tween documents that are not in the same clusters. This step is fast, in part because of the fact that we have already reduced the number of input features down to 5k (rather than having one feature for each word observed in the entire dataset.) Finally, we give the clusters titles by perform-ing a calculation of mutual information (MI) for each word or bigram in each cluster. Specifically, clustering terms (both words and bigrams) that oc-cur frequently in one cluster but rarely in other clusters will receive high scores. The terms with the highest MI scores are used as cluster labels. One significant advantage of this completely unsupervised approach is that CoFi is more robust to the language of comment data, e.g. grammatical and spelling inconsistency, informal language, which are a challenge for rule-based and super-vised NLP tools.  In addition to the machine-generated topic clus-ters, CoFi allows user-defined topics. These are search terms and topic labels hand-created by a domain expert. CoFi partitions the comments into machine-generated topics and also assigns each comment to any of the matching predefined topics. This approach is useful for domain experts, ena-bling them to quickly find things they already know they want while allowing them to also take advantage of unexpected topics which emerge from the system clustering. 2.3 Creating the visualizations CoFi uses the JQuery, Flot, and g.Raphael javascript libraries to provide a dynamic, respon-sive interface. When the user visits a CoFi URL, the data is downloaded into their browser which then computes the visualization elements locally, allowing fast response times and offline access to 
the data. The JQuery library is central to all of the javascript processing that CoFi performs, and ensures that all features of the interface are cross-compatible with major browser versions. The interface provides the ability to drill down further into any data, allowing the user to click on any aspect of the analysis to obtain more detail. Since the visualization is calculated locally, the software can create dynamically updated timelines that show the user how any subset of their data has changed over time. It is also important to prioritize all data present-ed to the user, allowing them to focus on the most useful documents first. CoFi applies an automatic summarization technique to perform relevance sorting. We evaluated several state-of-the-art au-tomatic document summarization techniques and settled on a Kullback-Leibler divergence inspired by techniques described in Kumar et al (2009). The ?relevance? sort relies on a measure of how representative each comment is relative to the en-tire collection of comments that the user is viewing at the time. This allows us to rapidly rank tens of thousands of comments in the order of their rele-vance to a summary. Several of the approaches we tested were chosen from among the leaders of NIST?s 2004 Document Understanding Conference (DUC) summarization evaluation. Many of them used slight variants of KL divergence for sentence scoring. We also implemented Lin & Bilmes? (2010) Budgeted Maximization of Submodular Functions system, which performed best according to the DUC evaluation. However, even after apply-ing a scaling optimization inspired by the ?buck-shot? technique of Cutting et al (1992) the processing speed was still too slow for dealing with datasets containing more than 10000 small documents. The KL divergence approach scales linearly in the number of comments while still of-fering cutting edge qualitative performance. This means that the calculation can be done on the fly in javascript in the browser when the user requests a relevance sort. This allows CoFi to tailor the re-sults to whatever sub-selection of data is currently being displayed. For CoFi?s typical use cases this computation can be completed in under 2 seconds. 
10
3 The CoFi Interface CoFi takes a set of comments and produces the interactive summary you see in Figure 1. CoFi works best when a user is operating with between 200 and 10,000 comments. With small numbers of comments, there may not be enough data for CoFi to find interesting topic clusters. With very large numbers of comments, a user?s web browser may struggle to display all comments while maintaining sufficient responsiveness.  The raw data is available for inspection in many ways. The summary screen in Figure 1 presents a list of automatically-discovered clusters on the left-hand side (typically 10-30, this is a parameter of the clustering algorithm), the posting volume time-line on the top, and some overall statistics and characteristic words and posters in the middle. The user can return to this view at any point using the Overview button. At the top of the page, CoFi pre-sents the total number of comments and partici-pants, and a summary of the level of threading, which is a good indicator of how interactive the data set is. Where community ratings appear on a site, we also present the highest and lowest rated comments (this is solely based on the community rating, and not on our relevance calculation). In the 
middle of the display are two hyperlinked word clouds containing the highest frequency words and users. Selecting one of the top words or users has the same effect as searching for that term in one of the Search boxes?both of these approaches will present the user with matching comments with the term highlighted, and color coding to indicate clus-ter membership. The links from most popular words and most active users bring up a multi-graph view as in Figure 3.  Each time a set of comments is selected, either via a cluster, full text search, or filtering on a par-ticular commenter, the set is presented to the user in a sorted order with the comments most repre-sentative of the set ordered above those that are less representative. In this way, the user can quick-ly get a handle on what the set is about without reading all of the items in detail. The comments can also be sorted into the original temporal order, which can be useful to see how a comment thread evolves over time, or to view an original comment and threaded replies in a nested ordering. Figure 2 shows a single cluster in CoFi. The full thread timeline now has a red overlay for the selected subset of comments.  
Figure 1: CoFi top level summary view 
11
 At the bottom of the cluster lists, there is a View All Comments option. Sorting the entire set by rel-evance gives a good snapshot of most and least useful comments in the thread. From any of the views, clicking on a user name will display all comments from that user, and clicking on the comment ID will present that sub-thread; top-level comments are numbered X, while replies are la-beled X.X.  The CoFi interface also allows the user to export individual comments, marking those comments as having been ?handled? and routed to a particular person. This makes it easier to incre-mentally process comments as they arrive. We have applied CoFi to 72 distinct data sets, including forum discussions, news article, blog and YouTube comments, Twitter and comments on regulatory changes submitted to government offic-es via Regulations.gov. These last documents are much longer than those CoFi was intended to han-dle, but CoFi was nonetheless able to support in-teresting analysis. In one instance, we identified a clear case of ?astroturfing? (fake grassroots movement) based on the CoFi clusters. Acknowledgements Over the course of this project, many people have supported our work. We?d particularly like to thank Mark Maybury, Robert Peller at USSOUTHCOM, and Marty Ryan, Robert Battle and Nathan Vuong at the MITRE Miami site.  This  
 technical data was produced for the U. S. Govern-ment under Contract No. W15P7T-11-C-F600, and is subject to the Rights in Technical Data-Noncommercial Items clause at DFARS 252.227-7013 (NOV 1995). ? 2012 The MITRE Corpora-tion. All Rights Reserved. Approved for Public Release: 12-1507. Distribution Unlimited. MITRE Document number MP120212. References Chen, Edwin (2011). Introduction to Latent Direchlet Allocation, http://blog.echen.me/2011/08/22/ introduction-to-latent-dirichlet-allocation/#comments Cutting, D., Karger, D., Pedersen, J., and Tukey, J. (1992). Scatter/Gather: a cluster-based approach to browsing large document collections. Proceedings of 15th Annual International ACM SIGIR conference, New York, NY, USA, 318-329 Kumar, C., P. Pingali, and V. Verma (2009). Estimating Risk Of Picking a Sentence for Document Summari-zation. Proceedings of CICLing 2009, LNCS 5449, 571-581. Lin, H. and Bilmes, J. (2010). Multi-document summa-rization via budgeted maximization of submodular functions. Proceedings of Human Language Tech-nologies 2010, Los Angeles, CA, USA, 912-920. McCallum, Andrew Kachites (2002). MALLET: A Ma-chine Learning for Language Toolkit. Mishne, Gilard and Natalie Glance (2006). Leave a re-ply: An Analysis of Weblog Comments. In Workshop on the Weblogging Ecosystem, 15th International World Wide Web Conference, May. 
Figure 3: The "small multiples" view of frequent contributors 
Figure 2: Single cluster view 
12
