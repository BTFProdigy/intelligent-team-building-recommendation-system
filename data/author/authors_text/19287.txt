Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 25?28,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
CASMACAT: A Computer-assisted Translation Workbench
V. Alabau
?
, C. Buck
?
, M. Carl
?
, F. Casacuberta
?
, M. Garc??a-Mart??nez
?
U. Germann
?
, J. Gonz
?
alez-Rubio
?
, R. Hill
?
, P. Koehn
?
, L. A. Leiva
?
B. Mesa-Lao
?
, D. Ortiz
?
, H. Saint-Amand
?
, G. Sanchis
?
, C. Tsoukala
?
?
PRHLT Research Center, Universitat Polit`ecnica de Val`encia
{valabau,fcn,jegonzalez,luileito,dortiz,gsanchis}@dsic.upv.es
?
Copenhagen Business School, Department of International Business Communication
{ragnar.bonk,mc.isv,mgarcia,bm.ibc}@cbs.dk
?
School of Informatics, University of Edinburgh
{cbuck,ugermann,rhill2,pkoehn,hsamand,ctsoukal}@inf.ed.ac.uk
Abstract
CASMACAT is a modular, web-based
translation workbench that offers ad-
vanced functionalities for computer-aided
translation and the scientific study of hu-
man translation: automatic interaction
with machine translation (MT) engines
and translation memories (TM) to ob-
tain raw translations or close TM matches
for conventional post-editing; interactive
translation prediction based on an MT en-
gine?s search graph, detailed recording and
replay of edit actions and translator?s gaze
(the latter via eye-tracking), and the sup-
port of e-pen as an alternative input device.
The system is open source sofware and in-
terfaces with multiple MT systems.
1 Introduction
CASMACAT
1
(Cognitive Analysis and Statistical
Methods for Advanced Computer Aided Trans-
lation) is a three-year project to develop an
advanced, interactive workbench for computer-
assisted translation (CAT). Currently, at the end of
the second year, the tool includes an array of inno-
vative features that combine to offer a rich, user-
focused working environment not available in any
other CAT tool.
CASMACAT works in close collaboration with
the MATECAT project
2
, another open-source web-
based CAT tool. However, while MATECAT is
concerned with conventional CAT, CASMACAT is
focused on enhancing user interaction and facili-
tating the real-time involvement of human trans-
lators. In particular, CASMACAT provides highly
interactive editing and logging features.
1
http://www.casmacat.eu
2
http://www.matecat.com
Through this combined effort, we hope to foster
further research in the area of CAT tools that im-
prove the translation workflow while appealing to
both professional and amateur translators without
advanced technical skills.
GUI
web
server
CAT
server
MT
server
Javascript      PHP
    Python
  Python
web socket
HTTP
HTTP
Figure 1: Modular design of the workbench: Web-
based components (GUI and web server), CAT
server and MT server can be swapped out.
2 Design and components
The overall design of the CASMACAT workbench
is modular. The system consists of four com-
ponents. (1) a front-end GUI implemented in
HTML5 and JavaScript; (2) a back-end imple-
mented in PHP; (3) a CAT server that manages the
editing process and communicates with the GUI
through web sockets; (4) a machine translation
(MT) server that provides raw translation of source
text as well as additional information, such as a
search graph that efficiently encodes alternative
translation options. Figure 1 illustrates how these
components interact with each other. The CAT
and MT servers are written in Python and inter-
act with a number of software components imple-
mented in C++. All recorded information (source,
translations, edit logs) is permanently stored in a
MySQL database.
These components communicate through a
well-defined API, so that alternative implementa-
tions can be used. This modular architecture al-
25
Figure 2: Translation view for an interactive post-editing task.
lows the system to be used partially. For instance,
the CAT and MT servers can be used separately as
part of a larger translation workflow, or only as a
front-end when an existing MT solution is already
in place.
2.1 CAT server
Some of the interactive features of CASMACAT
require real-time interaction, such as interactive
text-prediction (ITP), so establishing an HTTP
connection every time would cause a significant
network overhead. Instead, the CAT server relies
on web sockets, by means of Python?s Tornadio.
When interactive translation prediction is en-
abled, the CAT server first requests a translation
together with the search graph of the current seg-
ment from the MT server. It keeps a copy of the
search graph and constantly updates and visualizes
the translation prediction based on the edit actions
of the human translator.
2.2 MT server
Many of the functions of the CAT server require
information from an MT server. This information
includes not only the translation of the input sen-
tence, but also n-best lists, search graphs, word
alignments, and so on. Currently, the CASMACAT
workbench supports two different MT servers:
Moses (Koehn et al., 2007) and Thot (Ortiz-
Mart??nez et al., 2005).
The main call to the MT server is a request for
a translation. The request includes the source sen-
tence, source and target language, and optionally
a user ID. The MT server returns an JSON object,
following an API based on Google Translate.
3 Graphical User Interface
Different views, based on the MATECAT GUI,
perform different tasks. The translation view is
the primary one, used when translating or post-
editing, including logging functions about the
translation/post-editing process. Other views im-
plement interfaces to upload new documents or to
manage the documents that are already in the sys-
tem. Additionally, a replay view can visualize all
edit actions for a particular user session, including
eye tracking information, if available.
3.1 Post-Editing
In the translation view (Figure 2), the document
is presented in segments and the assistance fea-
tures provided by CASMACAT work at the segment
level. If working in a post-editing task without
ITP, up to three MT or TM suggestions are pro-
vided for the user to choose. Keyboard shortcuts
are available for performing routine tasks, for in-
stance, loading the next segment or copying source
text into the edit box. The user can assign different
status to each segment, for instance, ?translated?
for finished ones or ?draft? for segments that still
need to be reviewed. Once finished, the translated
document can be downloaded in XLIFF format.
3
In the translation view, all user actions re-
lated to the translation task (e.g. typing activity,
mouse moves, selection of TM proposals, etc.) are
recorded by the logging module, collecting valu-
able information for off-line analyses.
3.2 Interactive Translation Prediction
Here we briefly describe the main advanced CAT
features implemented in the workbench so far.
Intelligent Autocompletion: ITP takes place
every time a keystroke is detected by the sys-
tem (Barrachina et al., 2009). In such event, the
system produces a prediction for the rest of the
sentence according to the text that the user has al-
ready entered. This prediction is placed at the right
of the text cursor.
Confidence Measures: Confidence mea-
sures (CMs) have two main applications in
3
XLIFF is a popular format in the translation industry.
26
MT (Gonz?alez-Rubio et al., 2010). Firstly, CMs
allow the user to clearly spot wrong translations
(e.g., by rendering in red those translations
with very low confidence according to the MT
module). Secondly, CMs can also inform the user
about the translated words that are dubious, but
still have a chance of being correct (e.g., rendered
in orange). Figure 3 illustrates this.
Figure 3: Visualisation of Confidence Measures
Prediction Length Control: Providing the user
with a new prediction whenever a key is pressed
has been proved to be cognitively demanding (Al-
abau et al., 2012). Therefore, the GUI just displays
the prediction up to the first wrong word according
to the CMs provided by the system (Figure 4).
Figure 4: Prediction Length Control
Search and Replace: Most of CAT tools pro-
vide the user with intelligent search and replace
functions for fast text revision. CASMACAT fea-
tures a straightforward function to run search and
replacement rules on the fly.
Word Alignment Information: Alignment of
source and target words is an important part of
the translation process (Brown et al., 1993). To
display their correspondence, they are hihglighted
every time the user places the mouse or the text
cursor on a word; see Figure 5.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Figure 5: Visualisation of Word Alignment
Prediction Rejection: With the purpose of eas-
ing user interaction, CASMACAT also supports a
one-click rejection feature (Sanchis-Trilles et al.,
2008). This feature invalidates the current predic-
tion made for the sentence that is being translated,
and provides the user with an alternate one.
3.3 Replay mode and logging functions
The CASMACAT workbench implements detailed
logging of user activity data, which enables both
automatic analysis of translator behaviour and
retrospective replay of a user session. Replay
takes place in the translation view of the GUI
and it displays the screen status of the recorded
translation/post-editing process. The workbench
also features a plugin to enrich the replay mode
with gaze data coming from an eye-tracker. This
eye-tracking integration is possible through a
project-developed web browser extension which,
at the moment, has only been fully tested with SR-
Research EyeLinks
4
.
4 E-pen Interaction
E-pen interaction is intended to be a complemen-
tary input rather than a substitution of the key-
board. The GUI features the minimum compo-
nents necessary for e-pen interaction; see Figure 6.
When the e-pen is enabled, the display of the cur-
rent segment is changed so that the source seg-
ment is shown above the target segment. Then the
drawing area is maximised horizontally, facilitat-
ing handwriting, particularly in tablet devices. An
HTML canvas is also added over the target seg-
ment, where the user?s drawings are handled. This
is achieved by means of MINGESTURES (Leiva
et al., 2013), a highly accurate, high-performance
gesture set for interactive text editing that can dis-
tinguish between gestures and handwriting. Ges-
tures are recognised on the client side so the re-
sponse is almost immediate. Conversely, when
handwritten text is detected, the pen strokes are
sent to the server. The hand-written text recog-
nition (HTR) server is based on iAtros, an open
source HMM decoder.
if any feature not
is available on your network
substitution
Figure 6: Word substitution with e-pen interaction
5 Evaluation
The CASMACAT workbench was recently evalu-
ated in a field trial at Celer Soluciones SL, a
language service provider based in Spain. The
trial involved nine professional translators work-
ing with the workbench to complete different post-
editing tasks from English into Spanish. The pur-
4
http://www.sr-research.com
27
pose of this evaluation was to establish which of
the workbench features are most useful to profes-
sional translators. Three different configurations
were tested:
? PE: The CASMACAT workbench was used
only for conventional post-editing, without
any additional features.
? IA: Only the Intelligent Autocompletion fea-
ture was enabled. This feature was tested sep-
arately because it was observed that human
translators substantially change the way they
interact with the system.
? ITP: All features described in Section 3.2
were included in this configuration, except-
ing CMs, which were deemed to be not accu-
rate enough for use in a human evaluation.
For each configuration, we measured the aver-
age time taken by the translator to produce the fi-
nal translation (on a segment basis), and the aver-
age number of edits required to produce the final
translation. The results are shown in Table 1.
Setup Avg. time (s) Avg. # edits
PE 92.2 ? 4.82 141.39 ? 7.66
IA 86.07 ? 4.92 124.29 ? 7.28
ITP 123.3 ? 29.72 137.22 ? 13.67
Table 1: Evaluation of the different configurations
of the CASMACAT workbench. Edits are measured
in keystrokes, i.e., insertions and deletions.
While differences between these numbers are
not statistically significant, the apparent slowdown
in translation with ITP is due to the fact that all
translators had experience in post-editing but none
of them had ever used a workbench featuring in-
telligent autocompletion before. Therefore, these
were somewhat unsurprising results.
In a post-trial survey, translators indicated that,
on average, they liked the ITP system the best.
They were not fully satisfied with the freedom of
interactivity provided by the IA system. The lack
of any visual aid to control the intelligent auto-
completions provided by the system made transla-
tors think that they had to double-check any of the
proposals made by the system when making only
a few edits.
6 Conclusions
We have introduced the current CASMACAT work-
bench, a next-generation tool for computer as-
sisted translation. Each of the features available
in the most recent prototype of the workbench has
been explained. Additionally, we have presented
an executive report of a field trial that evaluated
genuine users? performance while using the work-
bench. Although E-pen interaction has not yet
been evaluated outside of the laboratory, it will the
subject of future field trials, and a working demon-
stration is available.
Acknowledgements
Work supported by the European Union 7
th
Framework Program (FP7/2007-2013) under the
CASMACAT project (grant agreement n
o
287576).
References
Vicent Alabau, Luis A. Leiva, Daniel Ortiz-Mart??nez,
and Francisco Casacuberta. 2012. User evaluation
of interactive machine translation systems. In Proc.
EAMT, pages 20?23.
Sergio Barrachina et al. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3?28.
Peter Brown et al. 1993. The mathematics of statistical
machine translation: Parameter estimation. Compu-
tational linguistics, 19(2):263?311.
Jes?us Gonz?alez-Rubio, Daniel Ortiz-Mart??nez, and
Francisco Casacuberta. 2010. On the use of confi-
dence measures within an interactive-predictive ma-
chine translation system. In Proc. of EAMT.
Philipp Koehn et al. 2007. Moses: Open source toolkit
for statistical machine translation. In Proc. of ACL,
pages 177?180.
Luis A. Leiva, Vicent Alabau, and Enrique Vidal.
2013. Error-proof, high-performance, and context-
aware gestures for interactive text edition. In Proc.
of CHI, pages 1227?1232.
Daniel Ortiz-Mart??nez, Ismael Garc??a-Varea, and Fran-
cisco Casacuberta. 2005. Thot: a toolkit to train
phrase-based statistical translation models. In Proc.
of MT Summit X, pages 141?148.
G. Sanchis-Trilles et al. 2008. Improving interactive
machine translation via mouse actions. In Proc. of
EMNLP, pages 485?494.
28
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 574?578,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Refinements to Interactive Translation Prediction
Based on Search Graphs
Philipp Koehn
?
, Chara Tsoukala
?
and Herve Saint-Amand
?

Center for Speech and Language Processing, The Johns Hopkins University
?
School of Informatics, University of Edinburgh
phi@jhu.edu, ctsoukal@inf.ed.ac.uk, hsamand@inf.ed.ac.uk
Abstract
We propose a number of refinements to the
canonical approach to interactive trans-
lation prediction. By more permissive
matching criteria, placing emphasis on
matching the last word of the user prefix,
and dealing with predictions to partially
typed words, we observe gains in both
word prediction accuracy (+5.4%) and let-
ter prediction accuracy (+9.3%).
1 Introduction
As machine translation enters the workflow of
professional translators, the exact nature of this
human-computer interaction is currently an open
challenge. Instead of tasking translators to post-
edit the output of machine translation systems, a
more interactive approach may be more fruitful.
One such idea is interactive translation predic-
tion (Langlais et al, 2000b): While the user writes
the translation for a sentence, the system makes
suggestions for sequent words. If the user di-
verges from the suggestions, the system recalcu-
lates its prediction, and offers new suggestions.
This input modality is familiar to anybody who
has used auto-complete functions in text editors,
cell phones, or web applications.
The technical challenge is to come up with a
method that predicts words that the user will ac-
cept. The standard approach to this problem uses
the search graph of the machine translation sys-
tem. Such search graphs may be recomputed in a
constraint decoding process restricted to the par-
tial user input (called the prefix), but this is often
too slow with big models and limited computing
resources, so we use static word graphs.
The user prefix is matched against the search
graph. If the user prefix cannot be found in the
search graph, approximate string matching is used
by finding a path with minimal string edit distance,
i.e., a path in the graph with the minimal number
of insertions, deletions and substitutions to match
the user prefix.
This paper presents a number of refinements
to extend this approach, by allowing more per-
missive matching criterion, placing emphasis on
matching the last word of the user prefix, and deal-
ing with predictions to partially typed words. We
show improvements in word prediction accuracy
from 56.1% to 60.5% and letter prediction accu-
racy from 75.2% to 84.5% on a publicly available
benchmark (English-Spanish news translation).
2 Related Work
The interactive machine translation paradigm was
first explored in the TransType and TransType2
projects (Langlais et al, 2000a; Foster et al,
2002; Bender et al, 2005; Barrachina et al, 2009).
Given the computational cost and need for quick
response time, most current word operates on
search graphs (Och et al, 2003). Such search
graphs can be efficiently represented and pro-
cessed with finite state tools (Civera et al, 2004).
More recently, the approach has been extended to
SCFG-based translation models (Gonz?alez-Rubio
et al, 2013).
There are several ways the sentence completion
predictions can be presented to the user: show-
ing the complete sentence prediction, only a few
words, or multiple choices. User actions may be
also extended to mouse actions to pinpoint the di-
vergence from an acceptable translation (Sanchis-
Trilles et al, 2008), or hand-writing (Alabau et al,
2011) and speech modalities (Cubel et al, 2009).
3 Properties of Core Algorithm
Our implementation of the core algorithm follows
closely Koehn (2009). It is a dynamic program-
ming solution that computes the minimal cost to
reach each node in the search graph by matching
parts of the user prefix. Cost is measured primar-
ily in terms of string edit distance (number of dele-
tions, insertions and substitutions), and secondary
in terms of translation model score for the matched
path in the graph. Search is done iteratively, with
an increasing number of allowable edits.
574
prefix
time
5 10 15 20 25 30 35 40
0ms
8ms
16ms
24ms
32ms
40ms
48ms
56ms
64ms
72ms
80ms
0 edits
1 edit
2 edits
3 edits
4 edits
5 edits
6 edits
7 edits
8 edits
Figure 1: Average response time of baseline
method based on length of the prefix and number
of edits: The main bottleneck is the string edit dis-
tance between prefix and path.
3.1 Experimental Setup
Given the large number of proposed variations of
the algorithm, we do not carry out user studies, but
rather use a simulated setting. We predict transla-
tions that were crafted by manual post-editing of
machine translation output. We also use the search
graphs of the system that produced the original
machine translation output.
Such data has been made available by the CAS-
MACAT project
1
. In the project?s first field trial
2
,
professional translators corrected machine transla-
tions of news stories from a competitive English?
Spanish machine translation system (Koehn and
Haddow, 2012). This test set consists of 24,444
word predictions and 141,662 letter predictions.
3.2 Prediction Speed
Since the interactive translation prediction process
is used in an interactive setting where each key
stroke of the user may trigger a new request, very
fast response time is needed. According to stan-
dards in usability engineering
0.1 second is about the limit for having
the user feel that the system is reacting
instantaneously (Nielsen, 1993).
So, this is the time limit we have to set ourselves
to predict the next words of a translator.
What are the main factors that influence pro-
cessing time in our core algorithm? See Figure 1
for an illustration. We plot processing time against
1
http://www.casmacat.eu/
2
http://www.casmacat.eu/uploads/Deliverables/d6.1.pdf
prefix
failure rate
5 10 15 20 25 30 35 40
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
6 edits
7 edits
9 edits
11 edits
12 edits
13 edits
14 edits
15 edits
Figure 2: Ratio of prefix matching processes aban-
doned due to exceeding the 100ms time limit
(showing only curves with a minimum of 5 edits).
the length of the user prefix and the string edit dis-
tance between the user prefix and the search graph.
The graph clearly shows that the main slowdown
in processing time occurs when the edit rate in-
creases.
To guarantee a response in 100ms, the algo-
rithms aborts when this time is exceeded and re-
lies on a prediction based on string edit distance
against the best path in the graph. The larger the
number of edits, the more often this occurs, as Fig-
ure 2 shows.
3.3 Accuracy
We are mainly interested in the accuracy of the
method: How often does it predict a word that the
user accepts? There is a trade-off between speed
and accuracy.
One way we can balance this trade-off is by re-
moving nodes from the search graph. By thresh-
old pruning (Sanchis-Trilles and Ortiz-Mart??nez,
2014), we remove nodes from the search graph
that are only part of paths that are worse than the
best path by a specified score difference.
See Table 1 how the choice of the score differ-
ence threshold impacts failure rate and accuracy.
A wider threshold has the potential to achieve bet-
ter results (if we allows for up to 1 second of pro-
cessing time), but with the constraint of 100ms re-
sponse time, the optimum is with a threshold of
0.4. Wider thresholds lead to a higher failure rate,
causing overall lower accuracy.
575
Threshold 100ms Max 1000ms Max
Acc. Fail Acc. Fail
0.3 55.8% 4.5% 56.9% 0.0%
0.4 56.1% 6.5% 58.0% 0.0%
0.5 55.9% 9.0% 58.8% 0.0%
0.6 55.5% 11.6% 59.4% 0.0%
0.8 54.4% 17.1% 59.4% 0.0%
1.0 52.7% 21.7% 58.6% 6.5%
Table 1: Impact of threshold pruning on search ac-
curacy and failure rate (i.e., failure to complete
search in given time and resorting to matching
against best translation).
4 Refinements
We now introduce a number of refinements over
the core method. Given the constraints established
in the previous section (maximum response time
of 100ms, pruning threshold 0.4), we set out to
improve accuracy.
4.1 Matching Last Word
The first idea is that it is more important to match
the last word of the user prefix than having mis-
matches in earlier words. We attempt to find the
last word in the predicted path either before or
after the optimal matching position according to
string edit distance.
We combine the matched path in the prefix with
the optimal suffix, and search for the last user pre-
fix word within a window. This means that we
either move words from the suffix to the prefix or
the other way around, without changing the over-
all string along the path.
Table 2 shows the impact on accuracy for differ-
ent window sizes. While we expected some gains
by checking for the word somewhere around the
optimal position in the predicted path, we do see
significant gains by not placing any restrictions to
where the word can be found, except for a bias
to less distant positions. For instance, examining
a window of up to 3 words gives us a word pre-
diction accuracy of 57.2% versus the 56.1% base-
line. Finding the last word anywhere boosts per-
formance to 59.1%.
The table also reports accuracy numbers when
we allow the process to run up to 1 second ?
which is basically an exhaustive search but not
practically useful. These numbers shed some light
on why an unlimited window size in matching the
last word helps: the gains come partially from the
cases where the initial search fails. Finding the
last user word anywhere in the machine transla-
Window 100ms Max 1000ms Max
baseline 56.1% 58.0%
1 word 56.6% 58.4%
2 words 56.9% 58.6%
3 words 57.2% 58.9%
5 words 57.8% 59.3%
anywhere 59.1% 59.5%
Table 2: Search for the last prefix word in a win-
dow around the predicted position in the matched
path.
Word Matching 100ms Max 1000ms Max
baseline 59.1% 59.5%
case-insensitive 58.7% 59.4%
Table 3: Search with case-insensitive word match-
ing (say, University and university).
tion output is a better fallback than computing op-
timal string edit distance. Analysis of the data
suggests that gains mainly come from large length
mismatches between user translation and machine
translation, even in the case of first pass searches.
4.2 Case-Insensitive Matching
Some mismatches between words matter less than
others. For instance, if the user prefix differs only
in casing from the machine translation (say, Uni-
versity instead of university), then we may still
want to treat that as a word match in our al-
gorithm. However, as Table 3 shows, allowing
case-insensitive matching leads to lower accuracy
(58.7% vs. 59.1%).
A major reason is computational cost. The most
inner loop in the algorithm compares words. This
is optimized by representing words as integers.
However, if we allow case-insensitive matching,
this simple method does not work anymore. We do
precompute approximate word matches and store
matching words identifiers in a hash map, but still
the ratio of searches that do not complete in 100ms
increases from 6.5% to 9.7%. By extending the al-
lowable time to 1 second, the accuracy gap is re-
duced to 0.1%.
4.3 Approximate Word Matching
When a word in the user translation differs from
a word in the decoder search graph only by a few
letters, then it should be considered a lesser error
than substitutions of completely different words.
Such word differences may be due to casing, mor-
phological variants, or spelling inconsistencies.
We compute word dissimilarity by computing
576
Max. Dissimilarity 100ms Max. 1000ms Max.
baseline 59.1% 59.5%
30% 60.2% 61.0%
20% 60.4% 61.3%
10% 60.6% 61.5%
Table 4: Counting substitutions between similar
words as half an error. Dissimilarity is measured
as letter edit distance
Min Stem / Max Suffix 100ms 1000ms
baseline 59.1% 59.5%
4 / 3 59.4% 60.1%
3 / 3 59.5% 60.2%
2 / 3 59.5% 60.3%
Table 5: Counting substitutions between morpho-
logical variants as half an error. Morphological
variance is approximated by requiring a minimum
number of initial letters to match and a maximum
of final letters to differ.
the ratio of letter edit operations to the length of
the shorter word.
3
We now set a threshold for
maximum dissimilarity, under which mismatched
words are considered only half the edit cost of
other edit operations.
Table 4 shows that we get significantly higher
word prediction accuracy than with the baseline
approach (up to 60.6% vs. 59.1%), and the best
performance with a 10% threshold. We observe
the same computational problem as in the previous
section (about 9.2% first pass failures, vs. 6.5%),
reflected in a higher accuracy gap for 100ms and
1000ms time limits.
4.4 Stemmed Matching
We suspected that the main benefit of approximate
word matching is the better handling of morpho-
logical variants. In Spanish, this mainly consti-
tutes itself as different word endings. Thus, we re-
define our word dissimilarity measure by consider
words similar, if they agree in at least a number
of leading letters (presumably the stem), and may
differ in at most a number of trailing letters (pre-
sumably the morpheme).
Table 5 shows that this is successful in increas-
ing the word prediction rate (59.5% vs. 59.1%)
but not as much as with the more general approx-
imate word matching in the previous section (re-
call: 60.6%).
3
For instance, if a 6 letter word and a 4 letter word can
be matched with two deletions and one substitution, then the
dissimilarity score is
3
4
= .75.
# Method Word Acc. Letter Acc.
1 baseline 56.0% 75.2%
2 1+matching last word 59.0% 80.6%
3 2+case insensitive 58.7% 80.4%
4 2+dissimilarity 10% 60.5% 80.6%
5 2+stem 2/3 59.4% 80.5%
6 4+desperate 60.5% 84.5%
Table 6: Extending the approach to word com-
pletion. Impact of refinements of letter prediction
accuracy with additional desperate word matching
against the entire vocabulary.
5 Word Completion
Besides word prediction, word completion is also
a useful feature in an interactive translation tool.
When the machine translation system decides for
college over university, but the user types the letter
u, it should change its prediction.
To enable word completion in the canonical al-
gorithm, we allow matching of the final user word
(if not followed by a space character) as a prefix of
any word as a zero cost operation. The predicted
suffix that is returned to the user then starts with
the remaining letters of the word in the path.
Table 6 shows that the refinements that helped
sentence completion also benefit word comple-
tion. From a baseline accuracy of 75.2% correctly
predicted letters, we reach up to 80.6%. Note that
the baseline word prediction accuracy is slightly
lower (56.0% vs. 56.1%) than in the previous ex-
periments, since the previously correctly matched
last word may be mistaken as the prefix of another
word.
We add an additional refinement to this task: If
the potentially incomplete final word of the user
prefix cannot be found in the predicted path, then
we explore the entire vocabulary from the un-
pruned search graph for completions. If multiple
words match, the one with the highest path score
is used. This desperate word completion method
gives significant gains (84.5% over 80.6%).
6 Conclusion and Future Work
We observe most improvements by a focus on
the last word of the user prefix and approximate
word matching. This suggests that there may be
additional gains by a stronger focus on the tail
of the user prefix. Also, the findings from the
time/productivity tradeoffs indicate that more time
efficient algorithms and implementations should
be explored.
577
Acknowledgements
This work was supported under the CASMACAT
project (grant agreement N
o
287576) by the
European Union 7
th
Framework Programme
(FP7/2007-2013).
References
Alabau, V., Sanchis, A., and Casacuberta, F. (2011).
Improving on-line handwritten recognition using
translation models in multimodal interactive ma-
chine translation. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Techologies, pages 389?
394, Portland, Oregon, USA. Association for Com-
putational Linguistics.
Barrachina, S., Bender, O., Casacuberta, F., Civera, J.,
Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Tom?as,
J., Vidal, E., and Vilar, J.-M. (2009). Statistical ap-
proaches to computer-assisted translation. Compu-
tational Linguistics, 35(1).
Bender, O., Hasan, S., Vilar, D., Zens, R., and Ney,
H. (2005). Comparison of generation strategies for
interactive machine translation. In Proceedings of
the 10th Conference of the European Association for
Machine Translation (EAMT), Budapest.
Civera, J., Cubel, E., Lagarda, A. L., Pic?o, D.,
Gonz?alez, J., Vidal, E., Casacuberta, F., Vilar, J. M.,
and Barrachina, S. (2004). From machine translation
to computer assisted translation using finite-state
models. In Lin, D. and Wu, D., editors, Proceedings
of EMNLP 2004, pages 349?356, Barcelona, Spain.
Association for Computational Linguistics.
Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Toms,
J., Vidal, E., and Vilar, J.-M. (2009). Statistical ap-
proaches to computer-assisted translation. Compu-
tational Linguistics, 35(1).
Foster, G., Langlais, P., and Lapalme, G. (2002). User-
friendly text prediction for translators. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 148?
155, Philadelphia. Association for Computational
Linguistics.
Gonz?alez-Rubio, J., Ort??z-Martinez, D., Bened??, J.-
M., and Casacuberta, F. (2013). Interactive ma-
chine translation using hierarchical translation mod-
els. In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing,
pages 244?254, Seattle, Washington, USA. Associ-
ation for Computational Linguistics.
Koehn, P. (2009). A process study of computer-aided
translation. Machine Translation, 23(4):241?263.
Koehn, P. and Haddow, B. (2012). Towards effective
use of training data in statistical machine translation.
In Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 363?367, Montreal,
Canada. Association for Computational Linguistics.
Langlais, P., Foster, G., and Lapalme, G. (2000a).
Transtype: a computer-aided translation typing sys-
tem. In Proceedings of the ANLP-NAACL 2000
Workshop on Embedded Machine Translation Sys-
tems.
Langlais, P., Foster, G., and Lapalme, G. (2000b). Unit
completion for a computer-aided translation typing
system. In Proceedings of Annual Meeting of the
North American Chapter of the Association of Com-
putational Linguistics (NAACL).
Nielsen, J. (1993). Usability Engineering. Morgan
Kaufmann.
Och, F. J., Zens, R., and Ney, H. (2003). Efficient
search for interactive statistical machine translation.
In Proceedings of Meeting of the European Chap-
ter of the Association of Computational Linguistics
(EACL).
Sanchis-Trilles, G. and Ortiz-Mart??nez, D. (2014). Ef-
ficient wordgraph pruning for interactive translation
prediction. In Annual Conference of the European
Association for Machine Translation (EAMT).
Sanchis-Trilles, G., Ortiz-Mart??nez, D., Civera, J.,
Casacuberta, F., Vidal, E., and Hoang, H. (2008).
Improving interactive machine translation via mouse
actions. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 485?494, Honolulu, Hawaii. Association
for Computational Linguistics.
578
