Nanjing  Normal  University  Segmenter  
for  the  Fourth  SIGHAN  Bakeoff 
Xiaohe CHEN, Bin LI, Junzhi LU, Hongdong NIAN, Xuri TANG 
Nanjing Normal University, 
122, Ninghai Road, Nanjing, P. R. China, 210097 
chenxiaohe5209@msn.com,gothere@126.com, 
lujunzhi@gmail.com,nianhong-dong@hotmail.com, 
tangxuriyz@hotmail.com 
 
 
 
Abstract 
This paper expounds a Chinese word seg-
mentation system built for the Fourth 
SIGHAN Bakeoff. The system participates 
in six tracks, namely the CityU Closed, 
CKIP Closed, CTB Closed, CTB Open, 
SXU Closed and SXU Open tracks. The 
model of Conditional Random Field is used 
as a basic approach in the system, with at-
tention focused on the construction of fea-
ture templates and Chinese character cate-
gorization. The system is also augmented 
with some post-processing approaches such 
as the Extended Word String, model inte-
gration and others. The system performs 
fairly well on the 5 tracks of the Bakeoff. 
1 Introduction 
The Nanjing Normal University (NJNU) team par-
ticipated in CityU Closed, CKIP Closed, CTB 
Closed, CTB Open, SXU Closed, SXU Open 
tracks in the WS bakeoff. The system employed in 
the Bakeoff is based mainly on the model of CRF, 
optimized with some pre-processing and post-
processing methods. The team has focused its at-
tention on the construction of feature templates, 
Chinese character categorization, the use of Ex-
tended Word String and the integration of different 
segmentation models in the hope of achieving bet-
ter performance in both IVs?In Vocabulary 
words? and OOVs (Out Of Vocabulary words). 
Due to time limitations, some of these methods are 
still not fully explored. However, the Bakeoff re-
sults show that the performance of the overall sys-
tem is fairly satisfactory.  
The paper is organized as follows: section 2 
gives a brief description of the system; section 3 
and 4 are devoted to the discussion of the results of 
closed test and open test; a conclusion is given to 
comment on the overall performance of the system. 
2 System Description 
Conditonal Ramdom Field (CRF) has been widely 
used by participants in the basic tasks of NLP since 
Peng(2004). In both SIGHAN 2005 and 2006 
Bakeoffs CRF-based segmenters prove to have a 
better performance over other models. We have 
also chosen CRF as the basic model for the task of 
segmentation and uses the package CRF++ devel-
oped by Taku Kudo1. Some post-processing op-
timizations are also employed to improve the over-
all segmentation performance. The general descrip-
tion of the system is illustrated in Figure 1. The 
basic segmenter and post-processing are explained 
in the next two sections. 
2.1 Basic Segmenter 
As in many other segmentation models, our system 
also treats word segmentation as a task of classifi-
cation problem. During the experiment of the 
model, two aspects are taken into consideration, 
namely tag set and feature template. The 6-tag 
(Table 1) set proposed in Zhao(2006) is employed 
to mark various character position status in a Chi-
nese word. The feature template (Table 2) consid-
                                                 
1 Package CRF++, version 0.49, available at 
http://crfpp.sourceforge.net. 
115
Sixth SIGHAN Workshop on Chinese Language Processing
ers three templates of character features and three 
templates of character type features. The introduc-
tion of character type (Table 3) is based on the ob-
servation that many segmentation errors are caused 
by different segmentation standards among differ-
ent corpora, especially between Traditional Chi-
nese corpora and Simplified Chinese Corpora. 
 
 
Figure 1: Flow Chat 
 
Status Tag 
begin B 
2nd B2 
3rd B3 
middle M 
end E 
single S 
Table 1:6-tag Set 
 
Table 2: Feature Templates in Close Test 
 
Character Type Example 
Chinese Character ? ? 
Serial Number ??  ?? 
Roman Number ??? 
Aribic Number 12?? 
Chinese Number ???? 
Ganzhi ???? 
Foreign Character ??? 
National Pronunciation Letters ??? 
Sentence Punctuation ????  
Hard Punctuation \t\r\n 
Punctuation ??-?'' 
Dun ?? 
Dot1 ?? 
Dot2 .? 
Di ? 
At @ 
Other Character ?? 
Table 3:Character Type 
2.2 Post-Processing 
Two methods are used in post-processing to opti-
mize the results obtained from basic segmenter. 
The first is the binding of digits and English Char-
acters. The second is the use of extended word 
string to solve segmentation ambiguity. 
2.2.1 Binding Digits and Roman Letters 
Digits (ranging from ?0? to ?9?) are always bound 
as a word in Chinese corpora, while roman letters 
are treated differently in different corpora, some 
adding a full-length blank between the letters, 
some not. The system employs rule-based ap-
proach to bind both digits and roman letters. We 
also submitted two segmentation results for the 
Bakeoff, please refer to section 3.2 for discussion 
of these results. 
2.2.2 Extended Word String (EWS) Approach 
The CRF model performs well in segmenting IV 
word strings in general, but not in all contexts. Our 
system thus uses a memory based method, which 
is named as Extended Word String approach, to 
prevent CRF from making such error. All the Chi-
nese word strings, which are of character length 
from 2 to 10 and appear more than two times, are 
stored in a hash table, together with information of 
their segmentation forms. An example of EWS is 
given in Table 5. If the same character string ap-
pears in the test data, the system can easily re-
segment them by querying the hash table. If the 
query finds that the character string has only one 
segmentation form and checking shows that the 
string has no overlapping ambiguity with its left or 
right word, the segmentation of the string is then 
modified according to the stored segmentation type. 
Our experiment shows that the approach can pro-
Type Feature Function 
Char  
Unigram 
Cn, n=-2, 
-1, 0, 1, 2 
Character in position n to 
the current character 
Char  
Bigram 
CnCn+1, 
n=-1,0 
Previous(next) character 
and current character 
Char Jump C-1 C1 
Previous character and 
next character 
CharType 
Unigram 
Tn, 
n=-1, 0, 1 
Type of previous (current, 
next) character 
CharType 
Bigram 
TnTn+1, 
n=-1,0 
Type of previous character 
and next character 
CharType 
Jump T-1 T1 
Type of previous character 
and next character 
Input Character Strings 
Basic Segmenter (CRF Tagging) 
Post-processing 
Output Word Strings 
116
Sixth SIGHAN Workshop on Chinese Language Processing
mote the F-measure by 0.2% to 1% on different 
tracks. 
 
Table 5: Example of EWS 
3 Evaluation Results on Closed Test 
3.1 CKIP Closed Test 
In CKIP Closed Test, another kind of post process-
ing is used for OOVs. Examination on the output 
from basic segmenter shows that some OOVs iden-
tified by CRFs are not OOV errors, but IV errors. 
Sometimes it can not always segment the same 
OOV correctly in different context. For example, 
the person name ????? appears three times in 
the test, but it is only correctly detected twice, and 
for once it is wrongly detected. Our approach is to 
re-segment the OOVs string (with its left and right 
word) twice. Firstly the string is segmented using 
the training data wordlist, followed by a second 
segmentation using the OOV wordlist recognized 
by the Basic Segmenter. The result with the mini-
mum number of words is accepted.  
Example: 
Basic Seg Output?/?/??/??/ 
OOV Adjusting?    /?/???/?/ 
Basic Seg Output?/??/??/?/ 
OOV Adjusting?    /?/??/??/ 
With the OOV Adjusting Approach mentioned 
above, we got the third place in the track (Table 6). 
But when we use it on other corpora, the method 
does not promote the performance. Rather, it low-
ers the performance score. The reason is still not 
clear. 
 
System?rank? F Foov Fiv 
Best(1/21) 0.9510 0.7698 0.9667 
Njnu(3/21) 0.9454 0.7475 0.9637 
Table 6: CityU Closed Test 
3.2 CKIP and CTB Closed Test 
In CKIP Closed Test, only the basic segmenter 
introduced in section 2 is used. Two segmentation 
results, namely a and b (Table 7 and 8) are submit-
ted for the Bakeoff. Result a binds the roman let-
ters as a word, while result b does not. The scores 
of the two results show that the approach is not 
stable in terms of score. We suggest that corpora 
submitted for evaluation purposes should pay more 
attention to non-Chinese word tagging and comply 
with the request of Bakeoff organizers. 
 
System?rank? F Foov Fiv 
Best(1/19) 0.9470 0.7524 0.9623 
Njnu a(6/19) 0.9378 0.6948 0.9580 
Njnu b(9/19) 0.9204 0.6341 0.9452 
Table 7: CKIP Closed Test 
 
System?rank? F Foov Fiv 
Best(1/26) 0.9589 0.7745 0.9697 
Njnu a(9/26) 0.9498 0.7152 0.9645 
Njnu b(7/26) 0.9499 0.7142 0.9647 
Table 8: CTB Closed Test 
3.3 SXU Closed Test 
Four results (a, b, c and d) are submitted for this 
track (Table 9). Results a and b are dealt in the 
same way as described in section 3.2. Result c is 
obtained by incorporating results from a memory-
based segmenter. The memory-based segmenter is 
mainly based on memory-based learning proposed 
by Daelemans(2005). We tested it on the training 
data with 90% as training data and 10% as testing 
data. The result shows that performance is im-
proved. However, when the method is applied on 
the Bakeoff test data, the performance is lowered. 
The reason is not identified yet. 
Result d was based on result c. It incorporates 
OOV words recognized by the system introduced 
in (Li & Chen, 2007) in the post-processing stage. 
Based on suffix arrays, Chinese character strings 
with mutual information value above 8.0 are auto-
matically extracted as words without any manual 
operation. We can see from table 9 that the F-
measure of result d improved and Foov of d got 2rd 
place in the test. And it is likely to get higher score 
if we combine it with result a. 
 
System?rank? F Foov Fiv 
Best(1/29) 0.9623 0.7292 0.9752 
Njnu a(9/29) 0.9539 0.6789 0.9702 
Njnu b(10/29) 0.9538 0.6778 0.9701 
Njnu c(15/29) 0.9526 0.6793 0.9688 
Njnu d(14/29) 0.9532 0.6817 0.9694 
Table 9: Sxu Closed Test 
 
EWS Seg Form Freq 
??? /?/??/ 4 
117
Sixth SIGHAN Workshop on Chinese Language Processing
4 Evaluation Results on Open Test 
4.1 Methods 
More features and resources are used in open test, 
mainly applied in the modification of feature tem-
plates. Besides the features used in the close test, 
we add to feature templates more information 
about Chinese characters, such as the Chinese radi-
cals (????), tones (5 tones), and another 6 Boo-
lean values for each Chinese character. The 6 Boo-
lean values indicate respectively whether the char-
acter is of Chinese surnames (????), or of Chi-
nese names (????), or of characters used for 
western person name translation (????), or of 
character used for English location name transla-
tion(????), or of affixes (??-?,?-??), or of sin-
gle character words (????). The feature tem-
plates constructed in this way is given in Table 10. 
 
Type Feature Function 
Char  
Unigram 
Cn, 
 n=-1,0,1 
The prevoius (current, 
next) character 
Char  
Bigram 
Cn Cn+1,  
n=-1,0 
The previous(next) charac-
ter and current character 
Char Jump C-1 C1 
The previous character 
and next character 
CharType 
Unigram T0 
The type of the current, 
next character 
CharType 
Trigram T-1 T0T1 
The type of the previous, 
current and next character 
Char 
Information 
Unigram 
nT0 , 
 n=1,?,6 
The 6 information of the 
current, next character 
Char 
Information 
Trigram 
nnn TTT 101? , 
 n=1,?,6 
The 6 information of the 
previous, current and next 
character 
Table10: Feature Templates for Open Test 
 
In the post-processing stage, we also add a Chi-
nese idiom dictionary (about 27000 items) to help 
increase the OOV word recall. 
4.2 Results 
In SXU open test, we submitted 3 results (a, b and 
c), but only a achieves the 4th rank in F-measure 
(Table 11). Features and resources added to the 
system turns out not to be of much use in the task, 
compared with our score on the closed test. 
Result b, c and all the results in CTB open test 
submitted have errors due to our pre-processing 
stage with CRF. Thus, the scores of them are very 
low, and some are even lower than our scores in 
closed test (see table 12). 
 
System?rank? F Foov Fiv 
Best(1/9) 0.9735 0.8109 0.9820 
Njnu a(4/12) 0.9559 0.6925 0.9714 
Table 11: SXU Open Test 
 
System?rank? F Foov Fiv 
Best(1/12) 0.9920 0.9654 0.9936 
Njnu a(9/12) 0.9346 0.6341 0.9528 
Table 12: CTB Open Test 
5 Conclusions and Future Work 
This is the first time that the NJNU team takes part 
in SIGHAN WS Bakeoff. In the construction of the 
system, we conducted experiments on the CRF-
based segmenter with different feature templates. 
We also employs different post-processing ap-
proaches, including Extended Word String ap-
proach, digit and western roman letter combination, 
and OOV detection. An initial attempt is also made 
on the integration of different segmentation models. 
Time constraint has prevented the team from fuller 
exploration of the methods used in the system.  
Future efforts will be directed towards more com-
plicated segmentation models, the examination of 
the function of different features in the task, the 
integration of different models, and more efficient 
utility of other relevant resources.  
 
References 
Bin Li, Xiaohe Chen. 2007. A Human-Computer Inter-
action Word Segmentation Method Adapting to Chi-
nese Unknown Texts, Journal of Chinese Informa-
tion Processing, 21(3):92-98. 
Daelemans, W. and Van den Bosch. 2005. Memory-
Based Language Processing. Cambridge University 
Press, Cambridge, UK. 
Fuchun Peng, et al 2004. Chinese Segmentation and 
New Word Detection Using Conditional Random 
Fields, COLING2004, 562-568, 23-27 August, Ge-
neva, Switzerland. 
Gina-Anne Levow. 2006. The Third International Chi-
nese Language Processing Bakeoff: Word Segmenta-
tion and Named Entity Recognition, Proceedings of 
the Fifth SIGHAN Workshop on Chinese Language 
Processing, 108-117, 22-23 July, Sydney, Australia. 
118
Sixth SIGHAN Workshop on Chinese Language Processing
Hai Zhao, et al 2006. An Improved Chinese Word 
Segmentation System with Conditional Random 
Field, Proceedings of the Fifth SIGHAN Workshop 
on Chinese Language Processing, 162-165, 22-23 
July, Sydney, Australia. 
Richard Sproat and Thomas Emerson. 2003. The First 
International Chinese Word Segmentation Bakeoff,  
The Second SIGHAN Workshop on Chinese Lan-
guage Procesing, 133-143, Aspporo, Japan. 
Thomas Emerson. 2005. The Second  International Chi-
nese Word Segmentation Bakeoff, Proceedings of the 
Fourth SIGHAN Workshop on Chinese Language 
Processing, 123-133, Jeju Island, Korea. 
119
Sixth SIGHAN Workshop on Chinese Language Processing
Coling 2010: Poster Volume, pages 1238?1246,
Beijing, August 2010
Semi-Supervised WSD in Selectional Preferences
with Semantic Redundancy 
Xuri TANG1,5  , Xiaohe CHEN1 , Weiguang QU2,3 and Shiwen YU4
1. School of Chinese Language and Literature, Nanjing Normal University 
{xrtang,chenxiaohe5209}@126.com
2. Jiangsu Research Center of Information Security & Privacy Technology
3. School of Computer Science, Nanjing Normal University 
 wgqu_nj@163.com 
4. Institute of Computational Linguistics , Peking University 
yusw@pku.edu.cn
5. College of Foreign Studies, Wuhan Textile University 
Abstract
This paper proposes a semi-supervised 
approach for WSD in Word-Class 
based selectional preferences. The 
approach exploits syntagmatic and 
paradigmatic semantic redundancy in 
the semantic system and uses 
association computation and minimum 
description length for the task of WSD. 
Experiments on Predicate-Object 
collocations and Subject-Predicate 
collocations with polysemous 
predicates in Chinese show that the 
proposed approach achieves a precision 
which is 8% higher than the semantic-
association based baseline. The semi-
supervised nature of the approach 
makes it promising for constructing 
large scale selectional preference 
knowledge base. 
1 Introduction 
This paper addresses word sense 
disambiguation (WSD) which is required in 
the construction of selectional preference (SP) 
knowledge database. In previous literature of 
SP, four different types of formalization 
models are explicitly or implicitly employed. 
Two types are distinguished in Li and 
Abe(1998):
Word Model: ?=),|( rvnP     (1) 
Class Model: ?=),|( rvCP         (2) 
where v stands for verb, n for noun, C for the 
semantic class of n, r for the grammatical 
relation between v and n, and P for the 
preference strength. Most of the 
researches(Resnik 1996; Li and Abe 1998; 
Ciaramita and Johnson 2000; Brockmann and 
Lapata 2003; Light and Greiff 2002) uses the 
class model, and a few(Erk 2007) uses the 
word model. The other two types of model are 
given as below: 
Class-Only Model: ?=),|( rCCP vn        (3) 
Word-Class Model: ?=),,|,( rCvCnP vn  (4) 
where ,  are semantic classes for the 
noun and verb respectively. Class-Only model 
considers solely the semantic classes, while 
Word-Class model considers both words and 
semantic classes. Agirre and Martinez(2001) 
and Zheng et al2007) adopted the Class-only 
Model in research, while in McCarthy and  
Carroll(2003) and Merlo and Stevenson(2001) 
the Word-Class Model is employed. 
nC vC
Among the four models, the Word-Class 
Model is the type which possesses the most 
granulated knowledge and is the most potential 
in applications. McCarthy and Carroll(2003) 
reports that the Word-Class Model performs 
well in unsupervised WSD. In other NLP tasks 
such as metaphor recognition, this model may 
be indispensable. For instance, to distinguish 
the  predicate verb  ???(float)?  in  Ex(1a) as 
Ex. 1
a.
? ? ? ?
leaf floats b.
? ? ? ?
price floats
1238
literal and Ex(1b) as metaphorical requires 
different interpretations of the verb.  
The present research is concerned with 
WSD as in the Word-Class model. Particularly, 
it aims at disambiguating predicates in subject-
predicate (Subj-Pred) and predicate-object 
(Pred-Obj) constructions. The motivations 
behind the research are two folds. Firstly, 
semi-supervised and unsupervised WSD in SP 
are not fully explored. Merlo and 
Stevenson(Merlo and Stevenson 2001) 
employs supervised learning from large 
annotated corpus, which is difficult to obtain. 
One known unsupervised learning approach 
for WSD in SP is McCarthy and Carroll(2003) 
which addresses the issue via conditional 
probability. The other motivation derives from 
the fact few research is done on selectional 
preferences in languages other than English, as 
is stated in Brockmann and Lapata(2003). For 
instance, studies on construction of SP 
knowledge database in Chinese can only be 
found in Wu et al2005), Zhen et al2007), Jia 
and Yu(2008) and some others.  
The basic idea of the approach proposed for 
WSD in the paper is that the most acceptable 
interpretation of senses for a given 
construction is the pair of senses which 
encodes the most redundant information in the 
semantic system of the language. Two 
principles, namely Syntagmatic Redundancy 
Principle and Paradigmatic Redundancy 
Principle, are proposed in the paper to capture 
the intuition. Two corresponding devices are 
employed to model the two principles: 
Association for Syntagmatic Redundancy 
Principle and Minimum Description Length for 
Paradigmatic Redundancy Principle. Two 
experiments are conducted in the paper. The 
first is based on semantic association, 
achieving a 61.98% precision for predicates in 
Subj-Preds and 62.54% in Pred-Objs. This 
experiment is used as baseline as the approach 
is also used in McCarthy and Carroll(2003) for 
verb and adjective disambiguation. In the 
second experiment, both semantic association 
and MDL are employed, the precision of WSD 
amounts to 69.88% and 69.09% for predicates 
in Subj-Preds and Pred-Objs respectively, 
indicating that a combination of the two 
devices are fairly effective in disambiguating 
word senses for SP. 
The rest of the paper is organized as below. 
The second part gives further illustration of the 
rationale for the approach. The third part 
describes the procedure and the fourth part 
discusses the experiment result. The thesis 
concludes with some speculations in further 
researches. 
2 Rationale
2.1 Task Formalization 
Consider a Subj-Pred or Pred-Obj 
collocation C=< , > , where  is 
the word of predicate and  is the word of 
argument.  has M senses, denoted by set 
.  has N senses, denoted by .
The possible interpretation of C has M*N 
possibilities, denoted by 
={ | =< , >},
where  is called a sense collocation. The 
task of WSD is to search for a particular sense 
collocation in  and assign it to C as its 
interpretation. At the initial stage, each sense 
collocation in  is considered to have an 
even number of frequency, namely 
. Accordingly, for each 
, , For each 
, .
predW
arg ?
CS
CS
)M?
sf ipred(
s i 1)arg =
argW
W
i
j
i
j
?
) =
N/
predW
argS
jsarg
arg
M/1
predW
arg
S?
/(1 N
pred
f (
predS
SC =
(f ij?
i
preds
args i ?
W
S pred
i
j
?
=
S
argS
i
preds
)
?
2.2 Syntagmatic Redundancy Principle 
Syntagmatic Redundancy Principle (SRP) 
can be stated as following: among all possible 
sense collocations for a word collocation, the 
most appropriate is the one in which senses 
exhibit the most redundant information 
between each other. 
 The syntagmatic redundancy between 
words has been noticed very early by linguists 
and has been applied in WSD. Firth(1957) 
argues that there exists ?mutual expectancy? 
between words in collocations, and the 
meaning of word is partially encoded in its 
juxtaposition. Lyons(1977:261) comments that 
Porzig has noticed in 1934 the ?essential 
meaning relation? between words of 
collocations like ?dog barks? and ?tree fells? 
1239
and emphasizes that the meanings of 
collocationally restricted lexemes such as 
?bark? and ?fell? can only be explained by 
taking into account the collocates they occur 
with. This notion is also employed in 
Yarowsky(1995) for WSD, in which the key is 
the ?one-sense-per-collocation? statement. 
McCarthy and Carroll(2003) also uses this 
type of redundancy for disambiguation in SP.  
SRP can be explained as a statistic 
correlation between  and . The more 
co-relevant these two senses are, the more 
likely the pair is to be accepted as the 
appropriate interpretation.  This can be 
described as below: 
preds args
),(maxarg arg
ji
pred
i
j ssAssoc=?    (5) 
where is the function for 
sense association. Four methods can be 
considered for association computation: 
conditional probability (Formula 6 and 7), 
Lift(Han and Kamber 2006:261) (Formula 8), 
All-Confidence(Han and Kamber 2006:263)  
(Formula 9) and cosine (Formula 10). Note 
that two versions of conditional probability are 
considered, as are denoted in Formula 6 and 7. 
The first version, Cond-Prob 1, takes argument 
sense as condition, while the second version 
Cond-Prob 2 takes predicate sense as condition. 
  ),( arg
ji
pred ssAssoc
)(
),(
)|(
arg
arg
arg j
ij
predji
pred sp
ssp
ssp =             (6) 
)(
),(
)|( argarg i
pred
ij
predj
pred
i
sp
ssp
ssp =                 (7) 
)(*)(
),(
),(
arg
arg
arg ji
pred
ji
predji
pred spsp
ssp
sslift =              (8) 
))(),(max(
),(
),(_
arg
arg
arg j
pred
i
ji
predji
pred cfsf
ssf
ssconfall =         (9) 
)(*)(
),(
),(cos
arg
arg
arg ji
pred
ji
predji
pred
spsp
ssp
ssine =            (10) 
2.3 Paradigmatic Redundancy Principle 
Paradigmatic Redundancy Principle (PRP) 
can be stated as following: among all possible 
sense collocations for a word collocation, the 
most appropriate is the one which is also 
implicitly or explicitly expressed by other 
synonymous, metonymic or metaphorical word 
collocations.
Ex(2) illustrates the explicit redundancy in 
synonymous and metaphorical ways, in which 
the sense collocation ?[Price| ? ? ]
[QuantityChange|??]? is expressed by five 
word collocations, each with a different 
predicate : ?? (change), ?? (float), ??
(adjust),??(go up and down), ??(alter).  
Ex 2.
a.
????
price changes     b.
????
price floats     c.
? ? ? ?
price adjusts
d.
? ? ? ?
SULFHJRHVXSDQGGRZQe. ????price alters
Ex(3) reveals the implicit redundancy in 
metonymic way, in which the meaning ??
(human) ? ? (is eased)? is implicitly 
expressed in all the six collocations, 
established by  semantic relatedness among the 
arguments ????? (Maradona)?, ???
(student)?, ???(work)?, ???(labour)?, ??
?(driving)?, and ???(life)?.
Ex 3. 
a.
???????
Maradona is eased         b.
?? ?? ?
Student is eased
c.
?????
work is eased               d. 
?? ?? ?
labour is eased
e.
?? ?? ?
driving is eased             f. 
?????
Life is eased
To apply PRP, WSD in SP is casted as an 
issue of model selection. Given a set of word 
collocations , the process of WSD is to 
assign to each word collocation one sense 
collocation from a number of possibilities. 
Those assigned sense collocations form a set, 
or a model for ? . The goal of WSD in SP is 
to select from all those models the one which 
best interprets ? . For this purpose, Miminum 
Description Length(Barron et al 1998; Michell  
2003; MacKay 2003) can be used. MDL 
selects models by relying on induction bias 
based on Occam?s Razor, which stipulates that 
the simplest solution is usually the correct one. 
One way to interpret MDL in Bays? analysis is 
as below(Michell 2003:124): 
?
)|()(minarg' mDLmLm DM +=            (11) 
In (11)?  is the model description 
length when model m  is considered, 
 is the data description length when 
model  is used for description. The model 
with minimum length is the best model. 
)(mLM
)|( mDLD
m
1240
For model description length, we have 
adopted the method used in (Li and Abe 1998) 
which considers only the size of the model: 
)log(
2
1)(
)( NmsizemLM
?
=                   (12) 
where size(m) is the number of sense 
collocation contained in model m , and N is 
the number of word collocation in 
consideration. In this study, the set of word 
collocation with the same predicate word, 
denoted by ? , is used as the unit for model 
description length calculation instead of the 
whole corpus, so as to reduce computation 
complexity. Accordingly, each word 
collocation in ?  can be assigned one and only 
one sense collocation in the model m , out of 
all the potential sense collocations as is 
explained in section 2.1. 
Data description length is calculated on 
model and , as is denoted in formulas 
(13),  (14)  and (15) below. The  calculation  is   
m ?
??
?
?=?=? )
)(
log())(log()|(
2Num
f
pmL
i
ji
j
?
?
         (13) 
?
?
+=
m
k
l
i
j
i
j
i
j
i
j
k
l
i
j
wfff
??
?????
,
),(*)()()(         (14) 
??
?
?
?
?
=
=
><><=
k
pred
k
pred
ilj
lk
pred
ji
pred
k
l
i
j
s
sssrel
ssssrelw
i
pred
predargarg
argarg
s if                                 0
s if                ),(
             
),,,(),( ??
 (15) 
based on the probability of sense collocation 
, which in turn is calculated on a 
modified frequency of the collocation 
>=< jipred
i
j ss arg,?
)( ijf ? .
The frequency is modified by counting the 
explicit occurrence of the sense collocation 
itself and the implicit occurrence expressed by 
other sense collocations in ? . This idea is 
equivalent to enlarge the corpus by 1 fold, thus 
the overall collocation number is the two times 
of the original number.  
The modified frequency is a sum of two 
parts, denoted in formula (14). The first part is 
, the frequency of . The second part is 
the weighted frequency of . The weight is 
determined by the relatedness of the sense 
collocation  and all the other sense 
collocation in the model m. According to
this formula, if the sense collocation is found 
to be more similar to other sense collocations, 
it should obtain a higher modified frequency, 
and thus more likely to be the correct one for 
the word collocation.
)( ijf ?
i
j?
i
j?
i
j?
k
l?
The way to calculate the weight is given in 
formula (15). If two sense collocations have 
identical predicate sense, namely ,
then the weight between the two sense 
collocations is measured by rel , the 
semantic relatedness between the argument 
sense and . Otherwise, 0 is returned. 
There are different ways to measure sense 
relatedness. The present study has used 
semantic similarity based on HowNet(Liu and 
i 2002) to calculate the semantic relatedness. 
k
pred
i s=preds
),( argarg
lj ss
jsarg lsarg
L
3 Procedure
Figure 1 maps out the procedure for WSD in 
SP in the present study. The procedure is 
divided into two phases: data collection and 
disambiguation. The collocation data are 
collected from three sources: Sketch Engine, 
Collocation Dictionary and HowNet Examples. 
Two types of collocation data are collected: 
subject-predicate collocations (Subj-Pred) and 
predicate-object collocations (Pred-Obj) from 
Sketch Engine and Collocation Dictionary. 
Collocation Retriever reduces HowNet 
examples into Subj-Preds and Pred-Objs using 
simple heuristic methods. As a result, about 
70,000 subject-predicate collocations and 
106,000 predicate-object collocations are 
obtained.
Figure 1. WSD Procedure 
In disambiguation phase, two devices are
employed to filter out unlikely sense 
collocations: Association-Based Sense 
Collocation Filter, following SRP, and MDL-
Based Sense Collocation Filter, following PRP. 
Colloc Dict. 
HowNet Examples
MDL-Based Sense Colloc Filter
Assoc-Based Sense Colloc Filter
Collocation Retriever
Data Combination
Sketch Engine
Output
1241
In this phase, Subj-Preds and Pred-Objs are 
processed independently but following the 
same route.   
Each phase alone can perform WSD 
independently. Accordingly, two experiments 
are conducted to evaluate the method proposed 
in this paper. The first experiment uses 
association-based filter for word sense 
disambiguation, which is also used as the 
baseline. The approach is also used in 
(McCarthy and Carroll 2003) to disambiguate 
verbs and adjectives in collocations. To be 
particular, the method used by McCarthy and 
Carroll(2003) is formula (6). The second 
experiment is based on the result of the first 
one so as to observe the improvement obtained 
by MDL-Based approach. In the second 
experiment, unsupervised and semi-supervised 
WSD are also investigated by including some 
annotated collocations in the evaluation data. 
Two corpora are constructed for evaluation. 
One corpus is a set of 1034 subject-predicate 
constructions. The other is a set of 1841 
predicate-object constructions. Both are 
manually annotated by the authors with sense 
definitions defined in HowNet(Dong 2006). 
All together there are 52 highly ambiguous 
predicates involved in the study. 
4 Experiments and Discussion 
4.1 Collocation Retriever 
The major task in data collocation is in 
Collocation Retriever, which retrieves 
collocations from HowNet examples. Ex(4) 
gives a partial entry structure in HowNet,  
Ex 4. 
W_C=??
E_C=??~???~???????
?~
DEF=[change|?]
in which W_C stands for Chinese Word, DEF 
for definition, E_C for Examples of Chinese, 
and the wave ?~? for the word in question. 
From E_C, possible Subj-Preds such as ???
(public opinion) ??(floats)?, ???(index) 
??(floats)? can be retrieved, in which the 
sense of ???(float)? is annotated with DEF. 
But there are also noises. A simple heuristic 
method is applied to automatically filter out 
unwanted collocations. The heuristic method 
checks whether the collocation retrieved from 
HowNet share possible sense collocations with 
collocations in Collocation Dictionary. If yes, 
it is accepted as a collocation of the type, 
otherwise, it is rejected. Procedures are given 
below:
(a) Use Subj-Pred collocations and Pred-Obj 
collocations in Collocation Dictionary to build 
sense collocation set edSubj Pr?? and Objed??Pr ;
(b) For each example sentence in E_C, 
segment it using ICTCLAS1 to obtain an array 
of words. Words before ?~? forms potential 
Subj-Pred collocations and Words 
after form potential Pred-Obj collocations 
.
edSubj Pr??
ObjedB ?Pr
(c) For each or ,
construct possible sense collocation set 
edSubja Pr??? edSubjBb Pr??
a?  or 
b? , if ?????
? edSubja Pr
 or ?????
?Objedb Pr , add 
it as a Subj-Pred collocation or Pred-Obj 
collocation.
Evaluation on partial retrieved collocations 
shows that about 70% of obtained collocations 
are valid collocations, while about 30% are 
errors. Thus manual edition has been applied 
to rid those invalid collocations. 
4.2 Association-Based Filter 
Association-Based Sense Collocation Filter 
filters out those sense collocations that are very 
unlikely to be the right interpretation for a 
word collocation. Table 1 gives association 
computation result for the six senses related to 
the predicate ? ? (rough)? in Subj-Pred 
collocation ??? (personality) ? (rough)?. 
The 2nd , 3rd, 4th, and 6th are very unlikely 
interpretations and should be filtered, while the 
5th seems to be the most appropriate. 
Table 1. Association-Based Filter Example 
No.Pred Sense Arg Sense Assoc. Dgr
1 [Behavior|??][careless|??] 0.0019
2 [Behavior|??][coarse|?] 0.0002
3 [Behavior|??][hoarse|??] 0.0004
4 [Behavior|??][roughly|??] 0.0002
5 [Behavior|??][vulgar|?] 0.0071
6 [Behavior|??][widediameter|?] 0.0002
Following the procedure in Figure 1, to filter 
out those unlikely sense collocations, average 
1 A Chinese segmentation system, please refer to 
http://www.ictclas.org for further information. 
1242
association value is used as the filter and those 
below the average are dropped and those above 
are chosen for MDL-Based Filter. In Table 1, 
the average is 0.0017, and the 1rd and 5th are 
chosen.
However, in order to obtain a baseline and 
to decide which association computation 
model to use, we have followed the definition 
in Formula 5 and perform WSD test by 
choosing the sense collocation with highest 
association as the correct sense tags. for used 
this step solely for WSD, as is defined in 
Formula 4. Table 2 gives the experiment 
results for Subj-Pred and Pred-Obj collocations 
with all the association computation models 
denoted in Formula 6-10.
Table 2. WSD Result by Association 
Subj-Pred(%) Pred-Obj(%)
Cond-Prob 1 61.98 62.54
Cond-Prob 2 55.15 42.4
Lift 63.09 40.84
All_Conf 56.16 48.54
Cosine 58.83 55.72
One interesting phenomenon about all the 
five models is null-invariance. In selecting 
models for association computation, null-
invariance is an important feature to be 
considered(Han and Kamber 2006). A model 
with null-invariance is not influenced by 
additional irrelevant data and thus is more 
stable. In the experiment, the model Lift is the 
only one not featured with null-invariance. The 
experiments show that Lift is not stable in 
different collocation types, achieving high 
precision in Subj-Pred but low precision in 
Pred_Obj.
A second interesting phenomenon is 
collocation directionality exposed by the 
experiments, which can be observed in the two 
models of conditional probability: Cond-Prob 
1, with argument as condition, and Cond-Prob 
2, with predicate as condition. Directionality in 
collocation has been noticed earlier in some 
researches, for example Qu(2008). Our 
experiment shows that when using Cond-Prob 
1, we are able to get a precision of 61.98% and 
62.54% for Subj-Pred and Pred-Obj 
respectively, while Cond-Prob 2 gets a much 
lower precision. This fact can be interpreted 
that arguments tend to have a stronger 
selectional preference strength, and the 
possible selection range is comparatively 
narrower, while predicates have weaker 
selectional preference strength and a wider 
selectional range. 
4.3 MDL-Based Filter 
MDL-Based Filter takes as input result from 
Association-Based Filter using Cond-Prob 1 
for association computation and average 
association as filter. Table 3 and 4 give the 
final experiment outcome for Pred-Obj and 
Subj-Pred constructions and individual 
predicates.
It can be seen in Table 3 that MDL-Based 
Filter Several inferences can be made from the 
experiments. Firstly, comparison between 
Association-Based WSD (Table 2) and MDL 
WSD (Table 3) shows that MDL can improve 
overall performance up to 8%. As is mentioned 
earlier, Association-Based WSD is used as 
baseline in the present study. Given the fact 
that the average number of senses for word in 
question is fairly high, the improvement is 
considered as significant.  
Table 3. General WSD Results2
Ave. 
N.O.S.
Assoc.  
WSD (%) 
MDL
WSD (%) 
Subj-Pred 4.16 61.98 69.09
Pred-Obj 5.03 62.54 69.88
Analysis on the individual predicates in 
Table 4 gives a clearer picture of WDL-based 
WSD. Firstly, it can be seen that MDL is 
especially effective when the demarcation of 
word senses is clear-cut. Predicate words such 
as ??? (quiet)?, ??? (dirty)?, ???
(difficult)? in Subj-Preds and ??? (beat)?, 
???(touch)? and ???(break)? in Pred-Objs 
are successfully disambiguated in Table 4. 
These words generally have 2 or 3 senses, and 
the   senses    generally    differ    in   terms   of 
abstractness and concreteness, as is indicated 
in table 5. This is due to the fact that the 
arguments in these collocations are clearly 
delimitated in HowNet and this delimitation is 
well captured by the modified frequency 
calculation defined in formula (14). Via the 
formula, the concrete sense collocations can  
2 In Table 3 and 4, Ave. N.O.S stands for average number 
of senses of predicates, N.O.S stands for number of 
senses of the predicate, Assoc. WSD stands for 
Association-based WSD, and MDL WSD stands for 
MDL-based WSD. 
1243
Table 4. Detailed WSD Experiment Results 
Results for Pred-Obj. Results for Subj-Pred. 
Pred. 
N. 
O. 
S
Assoc. 
WSD
(%)
MDL
WSD
(%)
Pred. 
N. 
O. 
S. 
Assoc.
WSD
(%)
MDL
WSD
(%)
?(v) 5 69.23 80.77 ??(a) 2 61.14 92.00
?(v) 14 70.59 70.59 ?(v) 2 72.73 86.36
?(v) 6 56.25 90.62 ??(a) 2 47.83 58.7
??(v) 3 72.22 88.89 ?(a/v) 5 52.17 78.26
?(v) 9 50 60.53 ??(a) 3 56.76 81.08
?(v) 8 86.67 93.33 ?(a) 5 40 40 
?(v) 5 68.75 62.5 ??(v) 2 55.17 41.38
??(v) 3 73.91 81.16 ??(a) 3 75.76 93.94
?(v) 17 55.93 44.07 ?(a) 4 96.3 66.67
??(v) 3 80.36 78.57 ??(a) 3 47.37 42.11
??(v) 2 66.67 92.31 ?(a) 6 88.24 88.24
??(v) 2 57.14 80.95 ?(a) 6 46 60 
?(v) 6 76.27 79.66 ??(v) 3 44.44 44.44
??(v) 3 83.33 100 ??(a) 2 38.46 65.38
?(v) 8 63.64 63.64 ??(a) 2 93.33 53.33
?(v) 3 77.14 80 ??(v) 3 85.19 88.89
??(v) 2 88.24 100 ?(a) 10 50 50 
??(v) 2 83.87 80.65 ??(v) 2 60.53 63.16
?(v) 9 61.84 68.42 ?(a/v) 9 39.66 53.45
??(v) 3 40.28 51.39 ?(a) 6 59.46 51.35
?(v) 4 48.08 53.85 ?(v) 6 48.72 74.36
??(v) 3 73.49 73.49 ??(v) 3 48.15 44.44
??(v) 2 15.32 40 ??(a) 2 88.57 57.14
??(v) 2 84.91 83.02 ?(a) 6 68.18 40.91
?(v) 3 86.54 85.58 ?(v) 8 52.03 65.04
?(v) 4 72.51 72.99 ??(a) 2 95.35 95.35
Table 5. Word Sense Distinction 
Pred Concrete  Sense Abstract Sense(s) 
?? [quiet|?] [calm|??], 
[peaceful|?]
?? [dirty|?] [despicable|??], 
[immoral|???]
?? [difficult|?] [poor|?]
?? [beat|?] [MakeBetter|??], 
[cultivate|??]
?? [touch|?] [excite|??]
?? [break|??] [obstruct|??]
increase the  modified  frequency  of  concrete 
sense collocations, and the abstract sense 
collocation can increase the modified 
frequency of abstract sense collocations, thus 
leading to the clear demarcation of abstract 
senses and concrete senses. 
The role of semantic relevance can also be 
clearly noticed in the predicates which have a 
decreased precision in MDL in Table 4. Via 
Paradigmatic Redundancy Principle, the 
information encoded in one collocation are 
diffused to other collocations. Consequently, 
errors can be diffused. This explains why the 
precisions of some predicates such as ??
(sink)?, ???(dumb)?, ???(dark)? in Subj-
Pred and ??(open)?, ??(harness)? in Pred-
Objs decrease after MDL. Further analysis 
shows that this is because MDL has diffused 
the errors produced by Association Filter. For 
instance, at Association Filter phase, the 
collocation ???(box) ?(sink)? is assigned 
with the only sense collocation ?[tool|?? ]
[very| ? ]? and all other potential sense 
collocations are filtered. When MDL is applied, 
other collocations such as ???(machine) ?
(heavy)?, ???(pick)?(heavy)?, ???(chaw) 
?(heavy)?, ???(basket) ?(heavy)?, ???
(box) ?(heavy)?, ???(furniture) ?(heavy)?, 
in which the arguments are tightly correlated 
with that of ???(box) ?(sink)?? all takes 
the sense ?[very|? ]?, thus leading to the 
decrease of precision. 
The diffusion of senses can also best seen in 
the comparison between those predicates 
whose WSD are semi-supervised and those 
whose WSD are not supervised. Some 
predicates have collocations successfully 
retrieved from HowNet examples in which the 
word sense is already identified. These 
collocations are diffused in MDL filtering and 
play important roles in improving precision, 
while some other predicates do not have such 
resource. In Table 4, those unsupervised 
predicates are ???(fall)?, ??(collapse)?, ??
?(exquisite)?, ???(dumb)?, ???(wide)?, 
??? (develop)? in Subj-Preds and ???
(spread)?, ??? (brush)?, ??? (get into)?, 
??(bring)?, and ???(mar)? in Pred-Objs. 
The other predicates are semi-supervised. As 
can be seen in Table 4, most of these 
unsupervised predicates generally have a 
precision of 40%-60%, while those semi-
supervised predicates enjoy are much higher 
precision between 50%-100%. The explanation 
1244
for the result is straight forward. When one 
sense collocation of one word collocation is 
correctly identified, by way of Paradigmatic 
Redundancy Principle, the sense collocation 
which is similar to the correctly identified will 
have a higher modified frequency and is thus 
singled out as the best choice. This feature of 
MDL has great significance in the process of 
annotating large scale collocation data. With 
only a small number of annotated collocations 
for each predicate, a fairly high precision can 
be achieved for all the rest of the data through 
MDL.
5 Conclusion
The present paper believes that the Word-
Class Model gives the fullest description for 
selectional preference and thus makes efforts 
to disambiguate predicates in selectional 
preferences. From the perspective of semantic 
system, two principles of semantic redundancy, 
namely the Syntagmatic Redundancy Principle 
and Paradigmatic Redundancy Principle, are 
proposed in the paper and are applied in WSD 
in SP via Association Computation and 
Minimum Description Length. The 
experiments show that the approach proposed 
is fairly encouraging in disambiguation of 
polysemous predicates, especially under semi-
supervised conditions when a small portion of 
data is annotated. With such a tool, we are able 
to build large scale selectional preference 
knowledge database based on Word-Class 
Models, which can be applied in various tasks, 
of which metaphor recognition is the particular 
one we bear in mind.  
Acknowledgement 
This work is supported by Chinese National 
Fund of Social Science under Grant 
07BYY050 and Chinese National Science 
Fund under Grant 60773173 and Chinese 
National Fund of Social Science under Grant 
10CYY021. We are also grateful to the 
autonomous reviewers for their valuable 
advice and suggestions. 
References 
Agirre, E., and D. Mart?nez. 2001. Learning class-
to-class selectional preferences. Paper read at 
Proceedings of the Conference on Natural 
Language Learning, at Toulouse, France. 
Barron, A. R., J. Rissanen, and B. Yu. 1998. The 
Minimum Description Length Principle in 
coding and modeling. IEEE Transactions on 
Information Theory 44 (6):2743-2760. 
Brockmann, C., and M. Lapata. 2003. Evaluating 
and combining approaches to selectional 
preference acquisition. Paper read at Proceedings 
of the European Association for Computational 
Linguistics, at Budapest, Hungary. 
Ciaramita, M., and M. Johnson. 2000. Explaining 
away ambiguity: Learning verb selectional 
preference with Bayesian networks. In 
Proceedingsofthe18thInternationalConferenceon
ComputationalLinguistics (COLING 2000), 187-
193. 
Dong, Z. 2006. HowNet and the Computation of 
Meaning. River Edge, NJ: World Scientific. 
Erk, K. 2007. A Simple, Similarity-based Model for 
Selectional Preferences. Paper read at 
Proceedings of the 45th Annual Meeting of the 
Association of Computational Linguistics, at 
Prague, Czech Republic. 
Firth, J. R. 1957. A Synopsis of Linguistic Theory, 
1930-1955. In Studies in Linguistic Analysis. 
Oxford: Blackwell, 1-32. 
Han, J., and M. Kamber. 2006. Data Ming: 
Concepts and Techniques. Singapore: Elsevier. 
Jia Yuxiang and Yu Shiwen. 2008. Automatic 
Acquisition of Selectional Preference and Its 
Application to Metaphor Processing. Paper read 
at the Fourth National Student Conference on 
Computationl Linguistics, at Taiyuan, Shangxi, 
China. 
Li, H., and N. Abe. 1998. Generalizing Case 
Frames Using a Thesaurus and the MDL 
Principle. Computational Linguistics 24 (2):217-
244. 
Light, M., and W. Greiff. 2002. Statistical models 
for the induction and use of selectional 
preferences. Cognitive Science 87:1-13. 
Liu, Qun and Li Sujian. 2002. Word Similarity 
Computation Based on HowNet. In Proceedings 
of the 3rd Chinese Lexical Semantics. Taibei, 
China. 
Lyons, J. 1977. Semantics. Cambridge: Cambridge 
University Press. 
1245
MacKay, D. J. C. 2003. Information Theory, 
Inference, and Learning Algorithms. Cambridge: 
Cambridge University Press. 
McCarthy, D., and J. Carroll. 2003. Disambiguating 
Nouns, Verbs, and Adjectives Using 
Automatically Acquired Selectional Preferences. 
Computational Linguistics 29 (4):639-654. 
Merlo, P., and S. Stevenson. 2001. Automatic Verb 
Classification Based on Statistical Distributions 
of Argument Structure. Computational 
Linguistics 27 (3):374-408. 
Michell, Tom M.. Machine Learning. Translated by 
Zen Huajun and Zhang Yinkui. Beijing: China 
Machine Press. 
Resnik, P. 1996. Selectional constraints: an 
information-theoretic model and its 
computational realization. Cognition 61:127-159. 
Qu, Weiguang. 2008. Lexical Sense 
Disambiguation in Modern Chinese. Beijing: 
Science Press. 
Wu, Yunfang, Duan Huiming and Yu Shiwen. 2005. 
Verb?s Selectional Preference on Object. Spoken 
and Written Language in Practice 2005(2):121-
128. 
Yarowsky, D. 1995. Unsupervised Word Sense 
Disambiguation Rivaling Supervised Methods. 
Paper read at Proceedings of the 33rd Annual 
Meeting of the Association for Computational 
Linguistics, at Cambridge, MA. 
Zheng, Xuling, Zhou Changle, Li Tangqiu and 
Chen Yidong. 2007. Automatic Acquisition of 
Chinese Semantic Collocation Rules Based on 
Association Rule Mining Technique. Journal of 
Xiamen University (Natural Science) 46(3):331-
336. 
1246
