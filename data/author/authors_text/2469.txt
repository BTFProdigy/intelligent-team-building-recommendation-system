Extracting Information on Pneumonia in Infants Using Natural
Language Processing of Radiology Reports
Eneida A
Mendonca
Biomedical
Informatics
Columbia
University
New York, NY,
USA
em264@
columbia.edu
Janet Haas
Infection Control
New-York
Presbyterian
Hospital
New York, NY,
USA
jah9012@
nyp.org
Lyudmila
Shagina
Biomedical
Informatics
Columbia
University
New York, NY,
USA
ls303@
columbia.edu
Elaine Larson
Pharmaceutical
andTherapeutical
Research
Columbia
University
New York, NY
USA
el123@
columbia.edu
Carol Friedman
Biomedical
Informatics
Columbia
University
New York, NY
USA
cf9@
columbia.edu
Abstract
Natural language processing (NLP) is
critical for improvement of the healthcare
process because it has the potential to en-
code the vast amount of clinical data in
textual patient reports. Many clinical ap-
plications require coded data to function
appropriately, such as decision support
and quality assurance applications. How-
ever, in order to be applicable in the clini-
cal domain, performance of the NLP
systems must be adequate. A valuable
clinical application is the detection of in-
fectious diseases, such as surveillance of
healthcare-associated pneumonia in new-
borns (e.g. neonates) because it produces
significant rates of morbidity and mortal-
ity, and manual surveillance of respiratory
infection in these patients is a challenge.
Studies have already demonstrated that
automated surveillance using NLP tools is
a useful adjunct to manual clinical man-
agement, and is an effective tool for in-
fection control practitioners. This paper
presents a study aimed at evaluating the
feasibility of an NLP-based electronic
clinical monitoring system to identify
healthcare-associated pneumonia in neo-
nates. We estimated sensitivity, specific-
ity, and positive predictive value by
comparing the detection with clinicians?
judgments and our results demonstrated
that the automated method was indeed
feasible. Sensitivity (recall) was 87.5%,
and specificity (true negative rates) was
94.1%.
1 Introduction
Several studies have demonstrated the value of
natural language processing (NLP) technology for
a variety of healthcare applications. For example,
NLP techniques have been used to analyze and
structure narrative patient reports in order to pro-
vide data for applications, such as automated en-
coding, decision support, patient management,
quality assurance, outcomes analysis, and clinical
research (Baud et al, 1995; Fiszman et al, 2000;
Friedman et al, 1994; Friedman et al, 1999b;
Gundersen et al, 1996; Haug, Ranum, and Fre-
derick, 1990; Sager et al, 1995). Additionally, data
mining and knowledge discovery techniques have
been used to automate the development of rules
that detect clinical conditions by interpreting data
generated from the natural language processing
output of narrative reports (Wilcox and Hripcsak,
2000). NLP is potentially an invaluable tool for
healthcare because it enables access to a rich and
varied source of clinical data. However, adequate
performance is critical for practical clinical appli-
cations as well as timeliness.
One type of infectious disease that is important
to monitor is healthcare-associated pneumonia in
preterm and full-term neonates because it remains
a significant cause of morbidity and mortality in
that population (Whitsett et al, 1999). The inci-
dence of pneumonia in Neonatal Intensive Care
Units can be high as 10% in the United States
(Gaynes et al, 1996), with mortality varying from
5-20% in cases of acquired pneumonia (Gaynes et
al., 1996; Zangwill, Schuchat, and Wenger, 1920).
Healthcare-associated pneumonia is an infection
that is acquired during hospitalization, or in emer-
gency departments and outpatient clinics, and it is
neither present nor incubated at the time of admis-
sion.
The diagnosis of healthcare-associated pneu-
monia in neonates is extremely challenging, since
neonates often do not exhibit ?typical? signs and
symptoms of this infection (Bonten, 1999; Cordero
et al, 2002; Cordero et al, 2000; Craven and Ste-
ger, 1998; Flanagan, 1999). In most cases, the final
diagnosis is confirmed only by microbiologic cul-
ture, but it is difficult to obtain adequate specimens
in neonates because of the invasive nature of this
procedure (Heyland et al, 1999). Additionally,
culture results are not timely (Cordero et al, 2002)
because results are produced after 2 days, whereas
results of radiology reports are usually obtained
within 2 hours.
Surveillance require routine collection and
analysis of relevant data, which must be promptly
distributed to the appropriate health care providers,
who then must use the data to take action and fur-
ther prevent morbidity and mortality (Thacker, et
al., 1986). Data provided by surveillance tools can
be used for several purposes: (a) to identify the
natural incidence of particular events, (b) to detect
situations that require epidemiologic control meas-
ures, (c) to guide actions, allocation of resources,
and interventions (Gaynes et al, 1996). Surveil-
lance tools provide baseline information on trends
and geographic distribution of conditions. An im-
portant aspect is the ability to detect an outbreak at
the stage when intervention may affect the ex-
pected course of events (AHRQ, 2002). In order to
facilitate infectious disease surveillance, several
measures have been developed at the national
level. The Centers for Disease Control and Pre-
vention (CDC), for example, has implemented
measures to improve data collection and sharing
for surveillance purposes. The National Nosoco-
mial Infectious Surveillance System (NNISS)
(Richards et al, 2001) is concerned with data stan-
dards and sharing on healthcare associated infec-
tions. The National Electronic Disease
Surveillance System (NEDSS) focuses on stan-
dards and the response to biothreats.
2 Background
At the New York Presbyterian Hospital, a gen-
eral NLP system in the clinical domain, called
MedLEE (Medical Language Extraction and En-
coding System) (Friedman et al, 1994), is rou-
tinely used to parse and encode clinical reports. It
has been satisfactorily evaluated for clinical appli-
cations that require encoded data that is found in
discharge summaries and radiology reports
(Friedman et al, 1999b) (Friedman and Hripcsak,
1998; Friedman et al, 1999a). Hripcsak et al
showed that, for particular clinical conditions
found in chest radiographs, which included pneu-
monia, the performance of MedLEE was the same
as that of physicians, and was significantly supe-
rior to that of lay persons and alternative auto-
mated methods (Hripcsak et al, 1995). In another
study to evaluate a clinical guideline and an auto-
mated computer protocol for detection and isola-
tion of patients with tuberculosis, Knirsch et al
(Knirsch et al, 1998) demonstrated that automated
surveillance is a useful adjunct to clinical man-
agement and an effective tool for infection control
practitioners. That detection system monitored ra-
diology reports encoded by MedLEE for evidence
of radiographic abnormalities suggestive of tuber-
culosis along with other data in the patient reposi-
tory that was already coded, such as the patient?s
hospital location (for isolation status), laboratory
and pharmacy data for immunological compro-
mised status. Most importantly, the system de-
tected patients who should be isolated that were
not detected using the normal protocol (i.e. manual
detection). MedLEE has also been extended to
process pathology reports, echocardiograms, and
electrocardiograms, but evaluations of perform-
ance in these areas have not yet been undertaken
because evaluation is very costly in terms of time
and personnel.
3 Methods
3.1 Overview of NLP System
MedLEE is composed of several different modules
where each module processes and transforms the
text in accordance with a particular aspect of lan-
guage until a final structured output form is ob-
tained. The structured output consists of primary
units of clinical information (i.e. findings, proce-
dures, and medications), along with corresponding
modifiers (e.g. body locations, degree, certainty).
Figure 1 shows an example of a simplified version
of structured output that is generated as a result of
processing the sentence there is evidence of severe
pulmonary congestion with question mild consoli-
dation changes.
The output that is generated represents two
primary clinical findings, congestion and changes.
The first finding has a body location modifier
lung, stemming from pulmonary, a certainty modi-
fier high, stemming from evidence of, and a de-
gree modifier high, stemming from severe. In the
second finding, the certainty modifier moderate,
corresponds to question, the degree modifier low
corresponds to mild, and the descriptor corre-
sponds to consolidation. Values for degree and
certainty modifiers were automatically mapped to
a small set of values in order to facilitate subse-
quent retrieval. The actual form of output gener-
ated by MedLEE is XML, but Figure 1 shows a
compatible and more readable form.
Below is a brief overview of the system. More
detailed descriptions were previously published
(Friedman et al, 1994). When MedLEE was origi-
nally developed, it was intended to be used in
conjunction with decision support applications,
where high precision was critical. Therefore, it was
initially designed to maximize precision and re-
quired a complete parse. However, subsequent
clinical applications required high recall, and we
discovered that flexibility was critical. Currently,
MedLEE attempts to find a complete parse and
only resorts to partial parsing when a full parse
cannot be obtained. When generating the struc-
tured output, the method that was used to obtain
the parse is saved along with the structured output
so that the user can filter in or out findings ac-
cordingly.
Preprocessor - The preprocessor recognizes sen-
tence boundaries, and also performs lexical lookup
in order to recognize and categorize words,
phrases, and abbreviations, and to specify their
target forms. The lexicon was manually developed
using clinical experts because of the need for high
precision. In a study we used the UMLS (Unified
Medical Language System) (Lindberg, Hum-
phreys, and McCray, 1993), a controlled vocabu-
lary developed and maintained by the National
Library of Medicine, to automatically generate a
lexicon. This lexicon was subsequently used by
MedLEE instead of the MedLEE lexicon to proc-
ess a set of reports. Results showed a significant
loss of precision (from 93% to 86%) and recall
(from 81% to 60%) when using the UMLS lexicon
(Friedman, et al, 2001). Terms with ambiguous
senses may be disambiguated in this stage based on
contextual information. The preprocessor can also
handle tagged text so that lexical definitions can be
specified in the text, bypassing the need for lexical
lookup for cases where the text is already tagged.
This feature is particularly useful for handling lo-
cal terminology (such as the names of local facili-
ties), as well as for resolving domain specific
ambiguities.
Parser - The parser uses a grammar and lexicon to
identify and interpret the structure of the sentence,
and to generate an intermediate structure based on
grammar specifications. The grammar is a set of
rules based on semantic and syntactic co-
occurrence patterns. Development of manual rules
finding: congestion
body_location: lung
certainty: high
degree: high
finding: changes
certainty: moderate
degree: low
descriptor: consolidation
Figure 1 ? Sample output in simplified
form for the sentence there is evidence
of severe pulmonary congestion with
question mild consolidation changes.
are costly, and we are currently investigating sto-
chastic methods to help extend the grammar auto-
matically.
Composer - The composer is needed to compose
multi-word phrases that appear separately in the
input sentence to facilitate retrieval later on. For
example, the discontiguous words spleen and en-
la rged  in spleen appears enlarged would be
mapped to a phrase enlarged spleen so that a sub-
sequent retrieval could look for that phrase rather
than the individual components.
Encoder - The encoder maps the target terms in
the intermediate structure to a standard clinical
vocabulary (i.e. enlarged spleen is mapped to the
preferred vocabulary concept splenomegaly) in the
UMLS.
Chunker - The chunker increases sensitivity by
using alternative strategies to break up and struc-
ture the text if the initial parsing effort fails.
3.2 Design of Feasibility Study
A two-year crossover design study was conducted
independently of this NLP effort (03/01/2001-
01/31/2002, 03/01/2002-01/31/2003) in two neo-
natal intensive care units (NICU) in New York
City to study the impact of hand hygiene products
on healthcare acquired infection:
? NICU-A: a 40-bed care unit, which cares
for acutely ill neonates, including those re-
quiring surgery for complex congenital
anomalies and extra corporeal membrane
oxygenation
? NICU-B: a 50-bed unit associated with a
large infertility treatment practice
A trained infection control practitioner (ICP),
using the CDC National Nosocomial Infection
Surveillance System (NNIS) definitions, per-
formed the surveillance for infections in both units.
Cases were reviewed manually, including analysis
of computerized radiology, pathology and micro-
biology reports as well as chart reviews and inter-
views with patient care providers. The diagnosis of
infection was validated with the physician co-
investigator from each unit.
 As part of this study, we evaluated the feasi-
bility of using the NLP system (MedLEE) to auto-
matically identify potential cases of healthcare-
associated pneumonia in neonates. The NLP sys-
tem was not changed, but medical logic rules that
accessed the NLP output had to be developed. The
rules were developed by a medical expert based on
modifications to a previous rule to detect pneumo-
nia in adults (Hripcsak et al, 1995). Modifications
were made in accordance with the CDC NNIS
definition of healthcare-associated pneumonia in
neonates. The final rule was then adapted to func-
tion properly with the output generated by
MedLEE. For example, the rule looks for 38 dif-
ferent findings or modifier-finding combinations,
such as pneumatocele and persistent opacity, and
then filters out findings that are not applicable be-
cause they occur with certain modifiers (e.g. no,
rule out, cannot evaluate, resolved, a total of 62
modifier). Therefore the automated monitoring
system consists of two components: a) the
MedLEE NLP system, and b) medical rules that
access the output generated by MedLEE. In this
first phase, the medical expert defined the rules
broadly, to identify reports consistent with pneu-
monia (and not only healthcare-associated pneu-
monia) with the intention of continuing the effort if
performance in identifying all forms of pneumonia
was satisfactory. This means that the automated
system could not differentiate between pneumonia
and healthcare-associated pneumonia at this point.
There were no probabilities associated with find-
ings or combination of findings. The second phase
of the study will use the results present in this work
to refine the rules in order to differentiate between
healthcare-associated and other types of pneumo-
nia.
All chest radiograph reports of neonates admit-
ted to NICU-A were processed using the auto-
mated monitoring system. To better assess true
performance, no corrections were made to the re-
ports despite misspellings and even the inclusion
of other types of reports in the same electronic files
as the chest radiograph reports. For instance, it is
not uncommon to have a combined chest-abdomen
radiograph in a neonate.
4 Results
During the 2 years of the study, from the total of
1,688 neonates admitted to the NICU-A, 1,277
neonates had 7,928 chest radiographs. Based on
the experts? evaluation, only 7 neonates had
healthcare-associated pneumonia at least one point
during the hospital stay. Cases were definitively
confirmed by cultures. These patients had a total of
168 chest radiographs, but only 13, which were
associated with the 7 patients, were positive be-
cause they contracted pneumonia at some point
after their admission.
The automated system found the presence of
pneumonia in 125 chest radiographs that were as-
sociated with 82 patients, including 6 of the 7 pa-
tients identified by the experts. The missed case
was a neonate with cardiac problems, and the chest
radiograph did not show findings of healthcare-
associated pneumonia. A pulmonary biopsy per-
formed subsequently showed findings which were
consistent with healthcare-associated pneumonia.
For healthcare-associated pneumonia, the sen-
sitivity (recall) of the automated system was
85.7%, while specificity (false positive rate) was
94.1%, and the positive predictive value (preci-
sion) was only 7.32%.
One of the authors (EAM), who is a board certi-
fied pediatric intensive care physician, manually
analyzed the false positive cases (e.g. errors in pre-
cision), and found that several of the false positive
cases actually had radiographic findings corre-
sponding to pneumonia. Other errors require expert
review of the entire patient charts to determine
whether or not healthcare-associated pneumonia
was present.
The expert reviewer (EAM) also encountered
several occurrences of a missed abbreviation
(?BPD?). Another common error was the mis-
spelling of terms.
5 Discussion
Natural language processing has the potential to
extract valuable data from narrative reports. The
significance is that a vast amount of NLP struc-
tured data could then be exploited by automated
tools, such as decision support systems. Automated
alerts (Dexter et al, 2001; Hripcsak et al, 1990;
Kuperman et al, 1999; Rind et al, 1994) require
coded clinical data to do an intelligent analysis of
patient status or condition.  An automated tool,
which notifies appropriate personnel about patients
with a particular condition or infection facilitates
timely and adequate response, including treatment,
medication prophylaxis, and isolation.
Conditions such as healthcare-associated
pneumonia carry significant rates of morbidity and
mortality. Surveillance of respiratory infection in
these patients is a challenge, and especially in neo-
nates admitted to neonatal intensive care units.
Isolated positive cultures alone do not distinguish
between bacterial colonization and respiratory in-
fection. Surveillance based on radiology and labo-
ratory findings can be valuable as a complement to
daily manual chart review and clinical rounds.
An NLP system cannot be used in a clinical en-
vironment without an infrastructure to support its
use. At the NYPH, a clinical event monitor
(Hripcsak et al, 1996) based on Arden Syntax for
Medical Logic Modules ? MLM (Hripcsak et al,
1990; Hripcsak et al, 1994)  provides clinical deci-
sion support.  When a clinical event occurs (such
as uploading of a radiograph reports), appropriate
medical logic modules are triggered based on the
type of event. However, in order to be used by the
monitoring system, narrative data must be coded.
We envision the integration and use of this auto-
mated NLP system to facilitate surveillance of
healthcare-associated pneumonia in a real clinical
environment. An additional issue is that the data
from the NLP system has to be represented in a
way that can be manipulated by the clinical infor-
mation system, and easily retrieved by the medical
rules. Therefore it is not enough to evaluate an
NLP system in isolation of a clinical application.
The NLP system may perform very well in isola-
tion, but the rules that access the data may be very
complex. They may involve complex inferencing,
or may be difficult to write because of the repre-
sentation generated by the NLP system.
 For healthcare-associated pneumonia, sensitiv-
ity (recall) and specificity (rate of true negatives)
were appropriate for the clinical application
(87.7% and 94.1% respectively), but the positive
predictive value (precision) was low (7.32%), as
expected in this phase. Low precision was primar-
ily due to the broad rule that was used to detect
pneumonia, and was not due to the NLP system
itself. This rule now needs to be refined to detect
only healthcare-associated pneumonia, and distin-
guish among radiograph findings moderately or
highly suggestive of healthcare-associated pneu-
monia. That would require substantial effort in-
volving manual chart review by an expert.
Additional data from other sources, such as labo-
ratory results, should also be combined with radio-
graph findings to add precision to the automated
system. This will be done in the future as well as
an evaluation. The data from NICU-B was re-
served as a test set for this purpose.
The MedLEE system was not adapted in any
way for this effort. Additionally, the rules were
based on expert knowledge but there was no train-
ing of the rules because of the sparseness of the
data. One type of NLP error was caused by a
missed abbreviation BPD. A straightforward solu-
tion would be to include the abbreviation in the
lexicon, but, this will create problems because of
the ambiguous nature of the abbreviation. BPD has
multiple meanings, including broncopulmonary
dysplasia, borderline personality disorder, bipa-
rietal diameter, bipolar disorder, and bilio-
pancreatic diversion, among others.  This is not
surprising since abbreviations are known to be
highly ambiguous (Aronson and Rindfleshch,
1994; Nadkarni, Chen, and Brandt, 2001), and are
widespread in clinical text. In chest radiographs of
neonates, BPD generally denotes broncopulmon-
ary dysplasia, a condition that predisposes the pa-
tient to respiratory infection. In other types of
radiology reports, for instance abdominal echogra-
phy, BPD generally means biparietal diameter, a
measure of the gestation age. Word sense disam-
biguation is a difficult problem, which is widely
discussed in the computational linguistics litera-
ture. A review of methods for word sense disam-
biguation is presented by Ide and colleagues (Ide
and Veronis, 1998). In the clinical setting, an im-
portant part of the solution will involve identifying
the particular domain and use of special purpose
domain-specific disambiguators that tag ambigu-
ous abbreviations and specify their appropriate
sense prior to parsing, based on the domain and
other contextual information. Defining the appro-
priate domain granularity will be important, but
may be a difficult task because the granularity may
vary with the abbreviation. For example, in the
case of radiographic reports, possibly the domain
should involve all chest x-rays or only chest x-rays
of neonates, or the specific type of reports.
In this study, we wanted to first evaluate the
feasibility of automated surveillance based on NLP
in a real clinical situation. The situation that pre-
sented itself was important but only involved a
small population of positive cases. The results that
were obtained are not meant to be definitive but to
expose the issues associated with the use of an
automated system that uses NLP in a real environ-
ment,. This study established a relationship with
clinicians who need this technology. It is this col-
laboration, which is critical for furthering use of
and validation of NLP in the clinical domain. In
this study, for instance, upon reviewing our results,
the infection control practitioner felt she may have
missed some cases when following her typical
manual surveillance, and would welcome the as-
sistance of an automated system, even if it gener-
ated a manageable amount of false positives (false
alerts). We do not know what that amount should
be, but estimate that an amount in the range of a
few false positives per week would be acceptable.
In that case, the 82 false positives, accounting for 2
years of cases, would be very acceptable. This
would need further studying.
Routine surveillance of infectious diseases in
hospitals is generally accomplished by manual re-
view of charts and clinical rounds by the ICPs. In
case of suspected infection, the data are collected
using surveillance protocols that target inpatients at
high risk of infection. The CDC NNIS definition
for healthcare-associated pneumonia is a 2-page
written protocol with two different criteria. It is
well known that interpretation of guidelines and
protocols vary among health care providers, even
within the same institution.  A recent study on sur-
veillance of ventilator-associated pneumonia
(VAP) in very-low-weight infants retrospectively
compare VAP surveillance diagnoses made by the
hospital ICPs with those made by a panel of ex-
perts with the same clinical, laboratory, and radi-
ologic data corroborates the variation among
experts (Cordero, et al, 2000).  An accurate NLP
system, which codes reports consistently, should
improve data collection for surveillance.
6 Conclusion
Surveillance of infectious disease is critical for
health care but manual methods are costly, incon-
sistent, and error prone. An automated system us-
ing natural language processing would be an
invaluable tool that could be used to improve sur-
veillance, including emerging infectious diseases
and biothreats. We performed a feasibility study in
conjunction with an infectious disease control
study to detect the presence of healthcare-
associated pneumonia in neonates. The results
showed that an automated system consisting of
NLP and clinical rules could be used for automated
surveillance. Further work will include refinement
of the rules, further evaluation, integration with the
clinical environment, and identification of other
surveillance applications.
Acknowledgment
This work was supported in part by grants
LM06274 from the National Library of Medicine,
1 R01 NR05197-01A1 from the National Institute
of Nursing Research, and by a gift from the
Sulzberger Foundation.
References
AHRQ. Bioterrorism preparedness and response: use of
information technologies and decision support sys-
tems. Evid Rep Technol Assess (Summ) 2002;
(59):1-8.
Aronson AR, Rindfleshch TBA. Exploting a large the-
saurus for information retrieval. Proc. RIAO 1994;
197-216.
Baud RH, Rassinoux AM, Wagner JC et al Represent-
ing clinical narratives using conceptual graphs.
Methods Inf Med 1995; 34(1-2):176-86.
Bonten MJ. Controversies on diagnosis and prevention
of ventilator-associated pneumonia. Diagn Microbiol
Infect Dis 1999; 34(3):199-204.
Cordero L, Ayers LW, Miller RR, Seguin JH, Coley
BD. Surveillance of ventilator-associated pneumonia
in very-low-birth-weight infants. Am J Infect Control
2002; 30(1):32-9.
Cordero L, Sananes M, Coley B, Hogan M, Gelman M,
Ayers LW. Ventilator-associated pneumonia in very
low-birth-weight infants at the time of nosocomial
bloodstream infection and during airway colonization
with Pseudomonas aeruginosa. Am J Infect Control
2000; 28(5):333-9.
Craven DE, Steger KA. Ventilator-associated bacterial
pneumonia: challenges in diagnosis, treatment, and
prevention. New Horiz 1998; 6(2 Suppl):S30-45.
Dexter PR, Perkins S, Overhage JM, Maharry K, Kohler
RB, McDonald CJ. A computerized reminder system
to increase the use of preventive care for hospitalized
patients. N Engl J Med 2001; 345(13):965-70.
Fiszman M, Chapman WW, Aronsky D, Evans RS,
Haug PJ. Automatic detection of acute bacterial
pneumonia from chest X-ray reports. J Am Med In-
form Assoc 2000; 7(6):593-604.
Flanagan PG. Diagnosis of ventilator-associated pneu-
monia. J Hosp Infect 1999; 41(2):87-99.
Friedman C, Alderson PO, Austin JH, Cimino JJ, John-
son SB. A general natural-language text processor for
clinical radiology. Journal of the American Medical
Informatics Association 1994; 1(2):161-74.
Friedman C, Hripcsak G. Evaluating natural language
processors in the clinical domain. Methods of Infor-
mation in Medicine 1998; 37:311-575.
Friedman C, Hripcsak G, Shagina L, Liu H. Represent-
ing information in patient reports using natural lan-
guage processing and the extensible markup
language. J Am Med Inform Assoc 1999a; 6(1):76-
87.
Friedman C, Knirsch C, Shagina L, Hripcsak G. Auto-
mating a severity score guideline for community-
acquired pneumonia employing medical language
processing of discharge summaries. Proc AMIA
Symp 1999b; 256-60.
Friedman C, Liu H, Shagina L, Johnson S, Hripcsak G.
Evaluating the UMLS as a source of lexical knowl-
edge for medical language processing. Proc AMIA
Symp 2001; 189-93.
Gaynes RP, Edwards JR, Jarvis WR, Culver DH, Tolson
JS, Martone WJ. Nosocomial infections among neo-
nates in high-risk nurseries in the United States. Na-
tional Nosocomial Infections Surveillance System.
Pediatrics 1996; 98(3 Pt 1):357-61.
Gundersen ML, Haug PJ, Pryor  TA et al Development
and evaluation of a computerized admission diagno-
ses encoding system. Computers and Biomedical Re-
search 1996; 29(5):351-72.
Haug PJ, Ranum DL, Frederick PR. Computerized ex-
traction of coded findings from free-text radiologic
reports. Work in progress. Radiology 1990;
174(2):543-8.
Heyland DK, Cook DJ, Griffith L, Keenan SP, Brun-
Buisson C. The attributable morbidity and mortality
of ventilator-associated pneumonia in the critically ill
patient. The Canadian Critical Trials Group. Am J
Respir Crit Care Med 1999; 159(4 Pt 1):1249-56.
Hripcsak G, Clayton PD, Jenders RA, Cimino JJ, John-
son SB. Design of a clinical event monitor. Comput
Biomed Res 1996; 29(3):194-221.
 Hripcsak G, Clayton PD, Pryor TA, Haug PJ,  Wigertz
O, van der Lei J . The Arden Syntax for medical
logic modules. Miller RA. Proceedings of the Four-
teenth Annual Symposium on Computer Applications
in Medical Care. Washington, D.C.: IEEE Computer
Press, 1990: 200-4.
Hripcsak G, Friedman C, Alderson PO, DuMouchel W,
Johnson SB, Clayton PD. Unlocking clinical data
from narrative reports: a study of natural language
processing. Annals of Internal Medicine 1995;
122(9):681-8.
Hripcsak G, Ludemann P, Pryor TA, Wigertz OB,
Clayton PD. Rationale for the Arden Syntax. Comput
Biomed Res 1994; 27(4):291-324.
Ide N, Veronis J. Introduction to the special issue on
word sense disambiguation: the state of the art. Com-
putational Linguistics 1998; 24:1-40.
Knirsch CA, Jain NL, Pablos-Mendez A, Friedman C,
Hripcsak G. Respiratory isolation of tuberculosis pa-
tients using clinical guidelines and an automated
clinical decision support system. Infect Control Hosp
Epidemiol 1998; 19(2):94-100.
Kuperman GJ, Teich JM, Tanasijevic MJ et al Im-
proving response to critical laboratory results with
automation: results of a randomized controlled trial. J
Am Med Inform Assoc 1999; 6(6):512-22.
Lindberg DAB, Humphreys BL, McCray AT. The Uni-
fied Medical Language System. Methods of Infor-
mation in Medicine 1993; 32(4):281-91.
Nadkarni P, Chen R, Brandt C. UMLS concept indexing
for production databases: a feasibility study. J Am
Med Inform Assoc 2001; 8(1):80-91.
Richards C, Emori TG, Edwards J, Fridkin S, Tolson J,
Gaynes R. Characteristics of hospitals and infection
control professionals participating in the National
Nosocomial Infections Surveillance System 1999.
Am J Infect Control 2001; 29(6):400-3.
Rind DM, Safran C, Phillips RS et al Effect of com-
puter-based alerts on the treatment and outcomes of
hospitalized patients. Arch Intern Med 1994;
154(13):1511-7.
Sager N, Lyman M, Nhan NT, Tick LJ. Medical lan-
guage processing: applications to patient data repre-
sentation and automatic encoding. Methods Inf Med
1995; 34(1-2):140-6.
Thacker SB, Redmond S, Rothenberg RB, Spitz SB,
Choi K, White MC. A controlled trial of disease sur-
veillance strategies. Am J Prev Med 1986; 2(6):345-
50.
Whitsett JA, Pryhuber GS, Rice WR, Warner BB, Wert
SE. Acute respiratory disorders. Avery GB, Fletcher
MA, MacDonald MG5th edition. New York: Lippin-
cott Williams & Wilkins, 1999: 485-508.
Wilcox A, Hripcsak G. Medical text representations for
inductive learning. Proc AMIA Symp 2000; 923-7.
Zangwill KM, Schuchat A, Wenger JD. Group B strep-
tococcal disease in the United States, 1990: report
from a multistate active surveillance system. MMWR
CDC Surveill Summ 1920; 41(6):25-32.
BioNLP 2007: Biological, translational, and clinical language processing, pages 41?48,
Prague, June 2007. c?2007 Association for Computational Linguistics
Combining Multiple Evidence for Gene Symbol Disambiguation  
Hua Xu 
Dept. of Biomedical Informatics, 
Columbia University 
622 W 168th St. NY, USA 
hux7002@dbmi.columbia.edu 
Jung-Wei Fan 
Dept. of Biomedical Infor-
matics, Columbia University 
622 W 168th St. NY, USA 
fan@dbmi.columbia.edu
Carol Friedman 
Dept. of Biomedical Informatics, 
Columbia University 
622 W 168th St. NY, USA 
friedman@dbmi.columbia.edu
   
Abstract 
Gene names and symbols are important 
biomedical entities, but are highly 
ambiguous. This ambiguity affects the 
performance of both information extraction 
and information retrieval systems in the 
biomedical domain. Existing knowledge 
sources contain different types of 
information about genes and could be used 
to disambiguate gene symbols. In this 
paper, we applied an information retrieval 
(IR) based method for human gene symbol 
disambiguation and studied different 
methods to combine various types of 
information from available knowledge 
sources. Results showed that a combination 
of evidence usually improved performance. 
The combination method using coefficients 
obtained from a logistic regression model 
reached the highest precision of 92.2% on a 
testing set of ambiguous human gene 
symbols.         
1 Introduction 
In the past decade, biomedical discoveries and 
publications have increased exponentially due to 
high-throughput technologies such as automated 
genomic sequencing, and therefore, it is impossible 
for researchers to keep up-to-date with the most 
recent knowledge by manually reading the litera-
ture. Therefore, automated text mining tools, such 
as information retrieval and information extraction 
systems, have received great amounts of interest 
(Erhardt et al, 2006; Krallinger and Valencia, 
2005). Biomedical entity recognition is a  first cru-
cial step for text mining tools in this domain, but is 
a very challenging task, partially due to the ambi-
guity (one name referring to different entities) of 
names in the biomedical field.  
Genes are among the most important biological 
entities for understanding biological functions and 
processes, but gene names and symbols are highly 
ambiguous. Chen et al (2005) obtained gene in-
formation from 21 organisms and found that ambi-
guities within species, across species, with English 
words and with medical terms were 5.02%, 
13.43%, 1.10%, 2.99%, respectively, when both 
official gene symbols and aliases were considered. 
When mining MEDLINE abstracts, they found that 
85.1% of mouse genes in the articles were am-
biguous with other gene names. Recently, Fundel 
and Zimmer (2006) studied gene/protein nomen-
clature in 5 public databases. Their results showed 
that the ambiguity problem was not trivial. The 
degree of ambiguity also varied among different 
organisms. Unlike other abbreviations in the litera-
ture, which usually are accompanied by their cor-
responding long forms, many gene symbols occur 
alone without any mention of their long forms. Ac-
cording to Schuemie et al (2004), only 30% of 
gene symbols in abstracts and 18% in full text 
were accompanied by their corresponding full 
names, which makes the task of gene symbol nor-
malization much harder.  
Gene symbol disambiguation (GSD) is a par-
ticular case of word sense disambiguation (WSD), 
which has been extensively studied in the domain 
of general English. One type of method for WSD 
uses established knowledge bases, such as a ma-
chine readable dictionary (Lesk, 1986; Harley and 
Glennon, 1997). Another type of WSD method 
uses supervised machine learning (ML) technolo-
41
gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; 
Liu et al, 2002).  
In the biomedical domain, there are many gene 
related knowledge sources, such as Entrez Gene 
(Maglott et al, 2005), developed at NCBI (Na-
tional Center for Biotechnology Information), 
which have been used for gene symbol disam-
biguation. Podowski et al (2004) used MEDLINE 
references in the LocusLink and SwissProt data-
bases to build Bayesian classifiers for GSD. A 
validation on MEDLINE documents for a set of 66 
human genes showed most accuracies were greater 
than 90% if there was enough training data (more 
than 20 abstracts for each gene sense). 
More recently, information retrieval (IR) based 
approaches have been applied to resolve gene am-
biguity using existing knowledge sources. Typi-
cally, a profile vector for each gene sense is built 
from available knowledge source(s) and a context 
vector is derived from the context where the am-
biguous gene occurs. Then similarities between the 
context vector and candidate gene profile vectors 
are calculated, and the gene corresponding to the 
gene profile vector that has the highest similarity 
score to the context vector is selected as the correct 
sense. Schijvenaars et al (2005) reported on an IR-
based method for human GSD. It utilized informa-
tion from either Online Mendelian Inheritance in 
Man (OMIM) annotation or MEDLINE abstracts.  
The system achieved an accuracy rate of 92.7% on 
an automatically generated testing set when five 
abstracts were used for the gene profile. Xu et al 
(2007) studied the performance of an IR-based ap-
proach for GSD for mouse, fly and yeast organ-
isms when different types of information from dif-
ferent knowledge sources were used. They also 
used a simple method to combine different types of 
information and reported that a highest precision of 
93.9% was reached for a testing set of mouse genes 
using multiple types of information.  
In the field of IR, it has been shown that com-
bining heterogeneous evidence improves retrieval 
effectiveness. Studies on combining multiple rep-
resentations of document content (Katzer et al, 
1982), combining results from different queries 
(Xu and Croft, 1996), different ranking algorithms 
(Lee, 1995), and different search systems (Lee, 
1997) have shown improved performance of re-
trieval systems. Different methods have also been 
developed to combine different evidence for IR 
tasks. The inference-network-based framework, 
developed by Turtle and Croft (1991), was able to 
combine different document representations and 
retrieval algorithms into an overall estimate of the 
probability of relevance. Fox et al (1988) extended 
the vector space model to use sub-vectors to de-
scribe different representations derived from 
documents. An overall similarity between a docu-
ment and a query is defined as a weighted linear 
combination of similarities of sub-vectors. A linear 
regression analysis was used to determine the 
value of the coefficients. 
 Though previous related efforts (Schijvenaars et 
al., 2005, Xu et al, 2007) have explored the use of 
multiple types of information from different 
knowledge sources, none have focused on devel-
opment of formal methods for combining multiple 
evidence for the GSD problem to optimize per-
formance of an IR-based method. In this study, we 
adapted various IR-based combination models spe-
cifically for the GSD problem. Our motivation for 
this work is that there are diverse knowledge 
sources containing different types of information 
about genes, and the amount of such information is 
continuously increasing. A primary source contain-
ing gene information is MEDLINE articles, which 
could be linked to specific genes through annota-
tion databases. For example, Entrez Gene contains 
an annotated file called ?gene2pubmed?, which 
lists the PMIDs (PubMed ID) of articles associated 
with a particular gene. From related MEDLINE 
articles, words and different ontological concepts 
can be obtained and then be used as information 
associated with a gene. However they could be 
noisy, because one article could mention multiple 
genes. Another type of source contains summa-
rized annotation of genes, which are more specific 
to certain aspects of genes. For example, Entrez 
Gene contains a file called ?gene2go?. This file 
lists genes and their associated Gene Ontology 
(GO) (Ashburner et al, 2000) codes, which include 
concepts related to biological processes, molecular 
functions, and cellular components of genes. 
Therefore, methods that are able to efficiently 
combine the different types of information from 
the different sources are important to explore for 
the purpose of improving performance of GSD 
systems. In this paper, we describe various models 
for combining different types of information from 
MEDLINE abstracts for IR-based GSD systems. 
We also evaluated the combination models using 
two data sets containing ambiguous human genes. 
42
  
 
Figure 1 Overview of an IR combination-based gene symbol disambiguation approach using different 
types of information.
2 Methods 
In this paper, we extend the IR vector space model 
to be capable of combining different types of gene 
related information in a flexible manner, thus im-
proving the performance of an IR-based GSD sys-
tem. Figure 1 shows an overview of the IR combi-
nation-based approach. We generated three differ-
ent sub-vectors for the context and three for the 
profile, so that each sub-vector corresponded to a 
different type of information. The similarity scores 
between context and profile were measured for 
each type of sub-vector and then combined to gen-
erate the overall similarity scores to determine the 
correct sense. We explored five different combina-
tion methods using two testing sets. 
2.1 Knowledge Sources and Available Infor-
mation 
The ?gene2pubmed? file in Entrez Gene was 
downloaded in January 2006. A profile was then 
built for each gene using information derived from 
the related articles. We used the following three 
types of information: 1) Words in the related 
MEDLINE articles (title and abstract). This is the 
simplest type of information about a gene. General 
English stop words were removed and all other 
words were stemmed using the Porter stemming 
algorithm (Porter, 1980). 2) UMLS (Unified 
Medical Language System) (Bodenreider 2004) 
CUIs (Concept Unique Identifier), which were 
obtained from titles and abstracts of MEDLINE 
articles using an NLP system called MetaMap 
(Aronson 2001). 3) MeSH (Medical Subject 
Headings) terms, which are manually annotated by 
curators based on full-text articles at the National 
Library of Medicine (NLM) of the United States. 
2.2 Document Set and Testing Sets 
Using the ?gene2pubmed? file, we downloaded the 
MEDLINE abstracts that were known to be related 
to human genes. Articles associated with more than 
25 genes (as determined by our observation) were 
excluded, since they mostly discussed high-
throughput technologies and provided less valuable 
information for GSD. This excluded 168 articles 
and yielded a collection of 116,929 abstracts, 
which were used to generate gene profiles and one 
of the test sets. Two test sets were obtained for 
evaluating the combination methods: testing set 1 
was based on the ?gene2pubmed? file, and testing 
set 2 was based on the BioCreAtIvE II evaluation. 
  Testing set 1 was automatically generated from 
the 116,929 abstracts, using the following 3 steps:  
1) Identifying ambiguous gene symbols in the 
abstracts. This involved processing the entire col-
lection of abstracts using an NLP system called 
BioMedLEE (Biomedical Language Extracting and 
Encoding System) (Lussier et al 2006), which was 
shown to identify gene names/symbols with high 
precision when used in conjunction with GO anno-
tations. When an ambiguous gene was identified in 
an article, the candidate gene identifiers (GeneID 
from Entrez Gene) were listed by the NLP system, 
but not disambiguated. For each ambiguous gene 
that was detected, a pair was created consisting of 
the PMID of the article and the gene symbol, so 
that each pair would be considered a possible test-
ing sample. Repeated gene symbols in the same 
article were ignored, because we assumed only one 
sense per gene symbol in the same article. Using 
this method, 69,111 PMID and ambiguous human 
gene symbol pairs were identified from the above 
collection of abstracts. 
43
2) Tagging the correct sense of the ambiguous 
gene symbols. The list of candidate PMID/gene 
symbol pairs generated from the articles was then 
compared with the list of gene identifiers known to 
be associated with the articles based on 
?gene2pubmed?. If one of the candidate gene 
senses matched, that gene sense was assumed to be 
the correct sense. Then the PMID/gene-symbol 
pair was tagged with that sense and set aside as a 
testing sample. We identified a pool of 12,289 test-
ing samples, along with the corresponding tagged 
senses. 
3) Selecting testing set 1. We randomly selected 
2,000 testing samples from the above pool to form 
testing set 1. 
Testing set 2 was derived using the training and 
evaluation sets of the BioCreAtIvE II Gene Nor-
malization (GN) task (Morgan 2007). The Bio-
CreAtIvE II GN task involved mapping human 
gene mentions in MEDLINE abstracts to gene 
identifiers (Entrez Gene ID), which is a broader 
task than the GSD task. However, these abstracts 
were useful for creating a testing set for GSD, be-
cause whenever a gene mention mapped to more 
than one identifier, disambiguation was required. 
Therefore, it was possible to derive a list of am-
biguous gene symbols based on data that was pro-
vided by BioCreAtIvE. We combined both manu-
ally annotated training (281 abstracts) and evalua-
tion (262 abstracts) sets provided by BioCreAtIvE. 
Using the same process as described in step 1 of 
testing set 1, we processed the abstracts and identi-
fied 217 occurrences of ambiguous gene symbols 
from the combined set. Following a similar proce-
dure as was used for step 2 in the testing set 1 (ex-
cept that the reference standard in this case was the 
manually annotated results obtained from Bio-
CreAtIvE instead of ?gene2pubmed?), we obtained 
124 PMID/gene-symbol pairs with the correspond-
ing tagged senses, which formed testing set 2. 
Because one article may contain multiple am-
biguous gene symbols, a total of 2,048 PMIDs 
were obtained from both testing sets 1 and 2. Arti-
cles with those PMIDs were excluded from the 
collection of 116,929 abstracts. We used the re-
maining document set to generate gene profiles, 
which were used for both testing sets. 
2.3 Profile and Context Vectors 
For each gene in ?gene2pubmed? file, we created a 
profile. It consisted of three sub-vectors containing 
word, CUI, or MeSH, respectively, using the in-
formation derived from the related MEDLINE ab-
stracts. Similarly, a context vector was also formed 
for each testing sample, using three sub-vectors 
containing word, CUI, or MeSH, which were de-
rived from the abstract whose PMID was stated in 
the testing sample.  The tf-idf weighting schema 
(Salton and Buckley, 1988) was used to assign 
weights to index terms in the profile and context 
sub-vectors. Given a document d, the Term Fre-
quency (tf) of term t is defined as the frequency of 
t occurring in d. The Inverse Document Frequency 
(idf) of term t is defined as the logarithm of the 
number of all documents in the collection divided 
by the number of documents containing the term t. 
Then term t in document d is weighted as tf*idf. 
2.4 Similarity Measurement 
The similarity score between the same type of con-
text and profile sub-vectors were measured as co-
sine similarity of two vectors. The cosine similarity 
between two vectors a and b is defined as the inner 
product of a and b, normalized by the length of 
two vectors. See the formula below: 
Sim(a,b) = cosine ? = 
ba
ba ?
  where  
22
2
2
1 ... naaaa +++=    22221 ... nbbbb +++=   
 
We built three basic classifiers that used only 
one type of sub-vector: word, CUI, or MeSH, re-
spectively, recorded three individual similarity 
scores of each sub-vector for each candidate gene 
of all testing samples. We implemented five meth-
ods to combine similarity scores from each basic 
classifier, which are described as follows: 
1) CombMax - Each individual similarity score 
from a basic classifier was normalized by di-
viding the sum of similarity scores of all 
candidate genes for that basic classifier. 
Then the decision made by the classifier with 
the highest normalized score was selected as 
the final decision of the combined method. 
2) CombSum - Each individual similarity score 
from a basic classifier was normalized by di-
viding the maximum similarity score of all 
candidate genes for that basic classifier. The 
overall similarity score of a candidate gene 
was considered to be the sum of the normal-
ized similarity scores from all three basic 
classifiers for that gene. The candidate gene 
44
with the highest overall similarity was se-
lected as the correct sense. 
3) CombSumVote - The overall similarity score 
was considered as the similarity score from 
CombSum, multiplied by the number of basic 
classifiers that voted for that gene as the cor-
rect sense.  
4) CombLR - The overall similarity score was 
defined as a predicted probability (P) of be-
ing the correct sense, given the coefficients 
obtained from a logistic regression model 
and similarity scores from all three basic 
classifiers for that gene. The relation be-
tween dependent variable (probability of be-
ing the correct sense) and independent vari-
ables (similarity scores from individual basic 
classifiers) of the logistic regression model is 
shown below, where Cs (Cword, Ccui, Cmesh and 
C) are the coefficients, and SIMs (SIMword, 
SIMcui, SIMmesh) are the individual similarity 
scores from the basic classifiers. To obtain 
the model, we divided 2,000 testing samples 
into a training set and a testing set, as de-
scribed in section 2.5. For samples in the 
training set, the correct gene senses were la-
beled as ?1? and incorrect gene senses were 
labeled as ?0?. Then logistic regression was 
applied, taking the binary labels as the value 
of the dependent variable and the similarities 
from the basic classifiers as the independent 
variables. In testing, coefficients obtained 
from training were used to predict each can-
didate gene?s probability of being the correct 
sense for a given ambiguous symbol. 
 
CSIMmeshCmeshSIMcuiCcuiSIMwordCword
CSIMmeshCmeshSIMcuiCcuiSIMwordCword
e
e
P +++
+++
+= ***
***
1
 
 
5) CombRank ? Instead of using the similarity 
scores, we ranked the similarity scores and 
used the rank to determine the combined 
output. Following a procedure called Borda 
count (Black, 1958), the top predicted gene 
sense was given a ranking score of N-1, the 
second top was given N-2, and so on, where 
N is the total number of candidate senses. 
After each sense was ranked for each basic 
classifier, the combined ranking score of a 
candidate gene was determined by the sum 
of ranking scores from all three basic classi-
fiers.  The sense with the highest combined 
ranking score was selected as the correct 
sense. 
2.5 Experiments and Evaluation 
In this study, we measured both precision and cov-
erage of IR-based GSD approaches. Precision was 
defined as the ratio between the number of cor-
rectly disambiguated samples and the number of 
total testing samples for which the disambiguation 
method yielded a decision. When a candidate gene 
had an empty profile or different candidate gene 
profiles had the same similarity scores (e.g. zero 
score) with a particular context vector, the disam-
biguation method was not able to make a decision. 
Therefore, we also reported on coverage, which 
was defined as the number of testing samples that 
could be disambiguated using the profile-based 
method over the total number of testing samples. 
We evaluated precision and coverage of different 
combined methods for gene symbol disambigua-
tion on both testing sets. 
Results of three basic classifiers that used a sin-
gle type of information were reported as well. We 
also defined a baseline method. It used the major-
ity sense of an ambiguous gene symbol as the cor-
rect sense. The majority sense is defined as the 
gene sense which was associated with the most 
MEDLINE articles based on the ?gene2pubmed? 
file.  
To evaluate the CombLR, we used 10-fold cross 
validation. We divided the sense-tagged testing set 
into 10 equal partitions, which resulted in 200 test-
ing samples for each partition. When one partition 
was used for testing, the remaining nine partitions 
were combined and used for training, which also 
involved deriving coefficients for each round. To 
make other combination methods comparable with 
CombLR, we tested the performance of other com-
bination methods on the same partitions as well. 
Therefore, we had 10 measurements for each com-
bination method. Mean precision and mean cover-
age were reported for those 10 measurements. For 
testing set 2, we did not test the CombLR method 
because the set was too small to train a regression 
model. 
We used Friedman?s Test (Friedman, 1937) fol-
lowed by Dunn?s Test (Dunn, 1964), which are 
non-parametric tests, to assess whether there were 
significant differences in terms of median precision 
among the different single or combined methods. 
45
3 Results 
Results of different combination methods for test-
ing set 1 are shown in Table 1, which contains the 
mean precision and coverage for 10-fold cross 
validation, as well as the standard errors in paren-
theses. All IR-based gene symbol disambiguation 
approaches showed large improvements when 
compared to the baseline method. All of the com-
bination methods showed improved performance 
when compared to results from any run that used a 
single type of information. Among the five differ-
ent combination methods, CombLR achieved the 
highest mean precision of 0.922 for testing set 1. 
CombSum, which is a simple combination method, 
also had a good mean precision of 0.920 on testing 
set 1. The third Column of Table 1 shows that cov-
erage was in a range of 0.936-0.938. 
 
Table 1. Results on testing set 1. 
 
Table 2. Results on testing set 2. 
 
We performed Friedman?s test followed by 
Dunn?s test on each single run: word, CUI or 
MeSH, with all combination runs respectively. 
Friedman tests showed that differences of median 
precisions among the different methods were sta-
tistically significant at ?=0.05.  Dunn tests showed 
that combination runs CombSum, CombSumVote, 
CombLR, and CombRank were statistically signifi-
cantly better than single runs using word or CUI. 
For single run using MeSH, combination runs 
CombLR and CombSum were statistically signifi-
cantly better. 
The results of different runs on testing set 2 are 
shown in Table 2. Most combined methods, except 
CombRank, showed improved precision. The high-
est precision of 0.906 was reached when using 
CombSum and CombMax methods. Note that the 
logistic regression method was not applicable. The 
coverage for testing set 2 was 0.944 for all of the 
methods. 
4 Discussion 
4.1 Why Combine? 
As stated in Croft (2002), a Bayesian probabilistic 
framework could provide the theoretical justifica-
tion for evidence combination. Additional evidence 
with smaller errors can reduce the effect of large 
errors from one piece of evidence and lower the 
average error.  
The idea behind CombMax was to use the single 
classifier that had the most confidence, but it did 
not seem to improve performance very much be-
cause it ignored evidence from the other two basic 
classifiers. The CombSum was a simple combina-
tion method, but with reasonable performance, 
which was also observed by other studies for the 
IR task (Fox and Shaw, 1994).  CombSumVote was 
a variant of CombSum. It favors the candidate 
genes selected by more basic classifiers. In Lee 
(1997), a similar implementation of CombSumVote 
(named ?CombMNZ?) also achieved better per-
formance in the IR task. CombLR, the combination 
method trained on a logistic regression model, 
achieved the best performance in this study. It used 
a set of coefficients derived from the training data 
when combining the similarities from individual 
basic classifiers. Therefore, it could be considered 
as a more complicated linear combination model 
than CombSum. In situations where training data is 
not available, CombSum or CombSumVote would 
be a good choice. CombRank did not perform as 
well as methods that used similarity scores, proba-
bly due to the loss of subtle probability information 
in the similarity scores. We explored ranking be-
cause it was independent of the weighting schema 
and could be valuable if it performed well. 
Run Precision Coverage 
Baseline 0.707 (0.032) 0.992 (0.005) 
Word 0.882 (0.023)  0.937 (0.017) 
CUI 0.887 (0.022) 0.938 (0.017) 
MeSH 0.900 (0.021) 0.936 (0.017) 
CombMax 0.909 (0.020) 0.938 (0.017) 
CombSum 0.920 (0.019) 0.937 (0.017) 
CombSumVote 0.917(0.019) 0.938 (0.017) 
CombLR 0.922 (0.019) 0.938 (0.017) 
CombRank 0.918 (0.020) 0.938 (0.017) 
Run Precision Coverage 
Baseline 0.593 0.991 
Word 0.872 0.944 
CUI 0.897 0.944 
MeSH 0.863 0.944 
CombMax 0.906 0.944 
CombSum 0.906 0.944 
CombSumVote 0.897 0.944 
CombRank 0.889 0.944 
46
The typical scenario where combination should 
help is when a classifier based on one type of in-
formation made a wrong prediction, but the 
other(s), based on different types of information, 
made the correct predictions. In those cases, the 
overall prediction may be correct when an appro-
priate combination method applies. For example, 
an ambiguous gene symbol PDK1 (in the article 
with PMID 10856237), which has two possible 
gene senses (?GeneID:5163 pyruvate dehydro-
genase kinase, isoenzyme 1? and ?GeneID:5170 3-
phosphoinositide dependent protein kinase-1?), 
was incorrectly predicted as ?GeneID: 5163? when 
only ?word? was used. But the classifiers using 
?CUI? and ?MeSH? predicted it correctly. When 
the CombSum method was used to combine the 
similarity scores from all three classifiers, the cor-
rect sense ?GeneID: 5170? was selected. When all 
three classifiers were incorrect in predicting a test-
ing sample, generally none of the combination 
methods would help in making the final decision 
correct. Therefore, there is an upper bound on the 
performance of the combined system. In our case, 
we detected that all three classifiers made incorrect 
predictions for 65 testing samples of the 2,000 
samples. Therefore, the upper bound would be 
1,935/2,000=96.7%. 
The methods for combining different types of 
information from biomedical knowledge sources 
described in this study, though targeted to the GSD 
problem, could be also applicable to other text 
mining tasks that are based on similarity measure-
ment, such as text categorization, clustering, and 
the IR task in the biomedical domain.  
4.2 Coverage of the Methods 
The IR-based gene symbol disambiguation method 
described in this paper aims to resolve intra-
species gene ambiguity. We focused on ambiguous 
gene symbols within the human species and used 
articles known to be associated with human genes. 
Fundel and Zimmer (2006) reported that the degree 
of ambiguity of the human gene symbols from En-
trez Gene was 3.16%?3.32%, which is substantial. 
However, this is only part of the gene ambiguity 
problem.  
Based on the ?gene_info? file downloaded in 
January 2006 from Entrez Gene, there were a total 
of 32,852 human genes. Based on the 
?gene2pubmed? file, 24,170 (73.4%) out of 32,852 
human genes have at least one associated MED-
LINE article, which indicates that profiles could be 
generated for at least 73.4% of human genes. On 
average, there are 9.02 MEDLINE articles associ-
ated with a particular human gene. Coverage re-
ported in this study was relatively high because the 
testing samples were selected from annotated arti-
cles as listed in ?gene2pubmed?, and not randomly 
from the collection of all MEDLINE abstracts. 
4.3 Evaluation Issues 
It would be interesting to compare our work with 
other related work, but that would require use of 
the same testing set. For example, it is not straight-
forward to compare our precision result (92.2%) 
with that (92.7%) reported by Schijvenaars et al 
(2005), because they used a testing set that was 
generated by removing ambiguous genes with less 
than 6 associated articles for each of their senses, 
and they did not report on coverage. The data set 
from the BioCreAtIvE II GN task therefore is a 
valuable testing set that enables evaluation and 
comparison of other gene symbol disambiguation 
methods. From the BioCreAtIvE abstracts, we 
identified 217 occurrences of ambiguous gene 
symbols, but only 124 were annotated in the Bio-
CreAtIvE data set. There are a few possible expla-
nations for this. First, the version of the Entrez 
Gene database used by the NLP system was not the 
most recent one, so some new genes were not 
listed as possible candidate senses. The second is-
sue is related to gene families or genes/proteins 
with multiple sub-units. According to the 
?gene_info? file, the gene symbol ?IL-1? is a syno-
nym for both ?GeneID: 3552 interleukin 1, alpha? 
and ?GeneID: 3553 interleukin 1, beta?. Therefore, 
the NLP system identified it as an ambiguous gene 
symbol.  When annotators in the BioCreAtIvE II 
task saw a gene family name that was not clearly 
mapped to a specific gene identifier in Entrez 
Gene, they may not have added it to the mapped 
list. In Morgan et al (2007), it was suggested that 
mapping gene family mentions might be appropri-
ate for those entities. Testing set 2 was a small set 
and results from that set might not be statistically 
meaningful, but it is useful for comparing with 
others working on the same data set. 
In this paper, we focused on the study of im-
provements in precision of the gene symbol dis-
ambiguation system. When combining information 
from different knowledge sources, coverage may 
47
also be increased by benefiting from the cross-
coverage of different knowledge sources.  
5 Conclusion and Future Work 
We applied an IR-based approach for human gene 
symbol disambiguation, focusing on a study of 
different methods for combining various types of 
information from available knowledge sources. 
Results showed that combination of multiple 
evidence usually improved the performance of 
gene symbol disambiguation. The combination 
method using coefficients obtained from a logistic 
regression model reached the highest precision of 
92.2% on an automatically generated testing set of 
ambiguous human gene symbols. On a testing set 
derived from BioCreAtIvE II GN task, the combi-
nation method that performed summation of indi-
vidual similarities reached the highest precision of 
90.6%. However, the regression-based method 
could not be used, because the testing sample was 
small.  
In the future, we will add information that is 
specifically related to genes, such as GO codes, 
into the combination model. Meanwhile, we will 
also study the performance gain in terms of 
coverage by integrating different knowledge 
sources.    
Acknowledgements 
This work was supported in part by Grants R01 
LM7659 and R01 LM8635 from the National Li-
brary of Medicine, and Grant NSF-IIS-0430743 
from the National Science Foundation. We would 
like to thank Alexander Morgan for providing the 
evaluation set from the BioCreAtIvE II GN task.  
References 
Aronson, A. R. 2001. Proc. AMIA. Symp., 17-21. 
Ashburner, M. et al 2000. Nat Genet, 25, 25-29. 
Black, D. 1958. Cambridge University Press. 
Bodenreider, O. 2004. Nucleic Acids Research, 2004, 
32, D267-D270.
Bruce, R. and Wiebe, J. 1994. Proceedings of ACL 
1994, 139-146. 
Chen, L., Liu, H. and Friedman, C. 2005. Bioinformat-
ics, 21, 248-256. 
Croft, W. 2002. Advances in Information Retrieval. 
Springer Netherlands, Chapter 1, 1-36 
Dunn, O. J. 1964. Technometrics, 6, 241-252. 
Erhardt, R.A., Schneider, R. and Blaschke, C. 2006. 
Drug Discov. Today, 11, 315-325. 
Fox, E., Nunn, G., and Lee, W. 1988. Proceedings of 
the 11th ACM SIGIR Conference on Research and 
Development in Information Retrieval, 291?308. 
Fox, E. and Shaw, J. 1994. Proceedings TREC-2, 243?
252. 
Friedman, M. 1937. Journal of the American Statistical 
Association, 32, 675-701. 
Fundel, K. and Zimmer, R. 2006. BMC. Bioinformatics., 
7: 372. 
Harley, A. and Glennon, D. 1997. Proc. SIGLEX Work-
shop "Tagging Text With Lexical Semantics", 74-78. 
Katzer, J., McGill, M., Tessier, J., Frakes,W., and 
DasGupta, P. 1998. Information Technology: Re-
search and Development, 1(4):261?274. 
Krallinger, M. and Valencia, A. 2005. Genome Biol., 6, 
224. 
Lee, J. 1995. Proceedings of the 18th ACMSIGIR Con-
ference on Research and Development in Information 
Retrieval, 180?188. 
Lee, J. 1997. Proceedings of the 20th ACM SIGIR Con-
ference on Research and Development in Information 
Retrieval, 267?276. 
Lee, Y. K. and Ng, H. T. 2002. Proc EMNLP 2002, 41-
48. 
Lesk, M. 1986. 1986 SIGDOC Conference, 24-26. 
Liu, H., Johnson, S. B. and Friedman, C. 2002. J. Am. 
Med. Inform. Assoc., 9, 621-636. 
Lussier, Y., Borlawsky, T., Rappaport, D., Liu, Y., 
Friedman, C. 2006. Pac. Symp. Biocomput., 11, 64-
75. 
Maglott D, Ostell J, Pruitt KD, Tatusova T. 2005. Nu-
cleic Acids Res., 3, D54-D58. 
Morgan, A., Wellner, B., Colombe, J. B., Arens, R., 
Colosimo, M. E., Hirschman L.  2007. Pacific Sym-
posium on Biocomputing 12:281-291. 
Podowski, R.M., Cleary, J.G., Goncharoff, N.T., 
Amoutzias, G., Hayes W.S. 2004. Proc IEEE Com-
put Syst Bioinform Conf, 2004, 415-24. 
Porter,M.F. 1980. Program, 14, 130-137. 
Salton, G. and Buckley, C. 1988. Information 
Processing & Management, 24, 513-523. 
Schijvenaars, B.JA. et al 2005. BMC. Bioinformatics., 
6:149. 
Schuemie, M.J. et al 2004. Bioinformatics, 20, 2597-
2604. 
Turtle, H. and Croft, W. 1991. ACM Transactions on 
Information Systems, 9(3):187?222. 
Xu, H., Fan, J. W., Hripcsak, G., Mendon?a A. E., Mar-
katou, M., Friedman, C. 2007. Bioinformatics, doi: 
10.1093/bioinformatics/btm056 
Xu, J. and Croft,W. 1996. Proceedings of the 19th ACM 
SIGIR Conference on Research and Development in 
Information Retrieval, pages 4?11. 
 
48
