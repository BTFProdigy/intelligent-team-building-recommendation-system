Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 433?440
Manchester, August 2008
Generation of Referring Expressions: Managing Structural
Ambiguities
?
Imtiaz Hussain Khan and Kees van Deemter and Graeme Ritchie
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{i.h.khan,k.vdeemter,g.ritchie}@abdn.ac.uk
Abstract
Existing algorithms for the Generation
of Referring Expressions tend to gen-
erate distinguishing descriptions at the
semantic level, disregarding the ways
in which surface issues can affect their
quality. This paper considers how these
algorithms should deal with surface am-
biguity, focussing on structural ambi-
guity. We propose that not all ambigu-
ity is worth avoiding, and suggest some
ways forward that attempt to avoid un-
wanted interpretations. We sketch the
design of an algorithm motivated by our
experimental findings.
1 Introduction
A Noun Phrase (np) is a referring expression
if its communicative purpose is to identify an
object to a hearer. The Generation of Refer-
ring Expressions (gre) is an integral part of
most Natural Language Generation (nlg) sys-
tems (Reiter and Dale, 2000). The gre task
can informally be stated as follows. Given an
intended referent (i.e., the object to be identi-
fied) and a set of distractors (i.e., other objects
that can be confused with the referent), find a
description that allows a hearer to identify its
referent uniquely (Dale, 1992). Such a descrip-
tion is called a Distinguishing Description
(dd). In practice, however, most gre algo-
rithms build sets of semantic properties avail-
able in a Knowledge Base (kb), rather than
descriptions in natural language; surface issues
are often ignored (exceptions are: (Stone and
?
This work is supported by a University of Ab-
erdeen Sixth Century Studentship, and EPSRC grant
EP/E011764/1.
?
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported.
Some rights reserved.
Webber, 1998; Krahmer and Theune, 2002;
Siddharthan and Copestake, 2004)). This is
an important limitation, for example because
ambiguities can be introduced in the step from
properties to language descriptions. Such ?sur-
face ambiguities? take centerstage in this pa-
per. More specifically, we shall be investigating
situations where they lead to referential ambi-
guity, that is, unclarity as to what the intended
referent of a referring expression is.
Example 1: Consider a scenario in which
there are sheep and goats along with other an-
imals, grazing in a meadow; some of the sheep
and goats are black while others are either
brown or yellow. Suppose our task is to single
out the black sheep and black goats from the
rest of the animals. Suppose an algorithm has
generated the logical form
1
(Black ? Sheep) ?
(Black ? Goats), which could be realised as
either the black sheep and the black goats or,
more briefly, as the black sheep and goats. The
latter np expresses two non-equivalent logical
formulae: (i) (Black ? Sheep) ? Goats, and
(ii) (Black ? Sheep) ? (Black ? Goats). Since
both formulae correspond with a set of animals
in the domain, referential ambiguity can result.
On the other hand, the black sheep and goats
is shorter and possibly more fluent. This ex-
ample highlights the possible tension between
brevity and lack of ambiguity. The question
facing us in this paper is how to balance them.
This paper examines how gre should deal
with structural ambiguity, focussing on ambi-
guity of the form the Adj Noun1 and Noun2,
also known as coordination ambiguity. We
call referring expressions of this form scopally
ambiguous, as the scope of Adj is unclear be-
tween wide scope (Adj applies to both nouns)
and narrow scope (Adj applies only to Noun1).
1
In this paper, we use set-theoretic operators instead
of logical connectives to represent logical forms.
433
2 Approach
A cursory view of corpora such as the British
National Corpus (bnc) reveals that there are
many instances of coordination ambiguity:
1. the black cats and dogs
2. the bearded men and women
3. the old men and women in the hats
Psycholinguistic evidence suggests that, in
many cases, these ambiguities could cause con-
fusion for a hearer (Tanenhaus and Trueswell,
1995). Hence, it seems justifiable to have gre
avoid such kind of ambiguities. However, it
also seems plausible that some readings may
be very unlikely. For example, in (2) a wide-
scope reading is, arguably, very unlikely. Ab-
ney and others have argued that every sentence
is potentially ambiguous between many parses,
even though we may not even notice this ambi-
guity (Abney, 1996; Wasow et al, 2005). This
suggests that, in gre as well, it might not be
feasible to avoid all referential ambiguities all
the time, and that the choice of referring ex-
pression should sometimes involve a balancing
act in which degree of ambiguity is balanced
against other properties of the generated ex-
pression, such as its length or fluency.
Building on earlier work by Inui et al (Inui
et al, 1992), Neumann (Neumann, 1994) sug-
gested a general generate-parse-revise model
for nlg, based on a reversible grammar. His
generator generates a string which is then
parsed to detect any structural ambiguities. If
a string is found to be ambiguous then revi-
sion is used to produce an alternative, non-
ambiguous string instead (if such a string ex-
ists). The likelihood of the different interpre-
tations is not taken into account, however.
Our approach to the problem is to find out
the likelihood of each interpretation of an np,
and to tailor gre to avoid all distractor in-
terpretations (i.e., interpretations that can
be confused with the intended one) as sug-
gested in (van Deemter, 2004). An interpre-
tation can be confused with the intended one
if it is more likely or almost as likely as the in-
tended one. The problem is, how to determine
the likelihood of different interpretations.
3 Getting likelihood from the bnc
In scopally ambiguous referring expressions,
there is a tension between wide- and narrow-
scope interpretations. This can be viewed in
terms of two competing forces: a Coordination
Force, whereby Noun1 and Noun2 attract each
other to form a syntactic unit, and a Modifi-
cation Force, whereby Adj and Noun1 attract
each other to form a syntactic unit. Computa-
tional linguists have proposed using language
corpora to estimate the likelihood of an inter-
pretation (Wu and Furugori, 1998; Chantree
et al, 2006). Chantree et al used information
from the Sketch Engine database (Kilgarriff,
2003) operating on the bnc to resolve coor-
dination ambiguity. The Sketch Engine con-
tains grammatical triples in the form of Word
Sketches for each word, with each triple ac-
companied by a salience value indicating the
likelihood of occurrence of the word with its
argument in a grammatical relation. Word
Sketches summarise the words? grammatical
and collocational behavior.
Chantree et al gathered a dataset of am-
biguous phrases from a corpus of requirements
specifications, and collected human judge-
ments about their interpretations. They then
used machine learning techniques combined
with various heuristics to determine the most
likely interpretation of a coordination. They
identified two heuristics as particularly useful.
One was the Coordination-Matches Heuristic:
if a coordination between two head nouns oc-
curs (at all) within the corpus, then a wide-
scope reading is likely. The other was the
Collocation-Frequency Heuristic: if a modi-
fier is collocated more frequently with the near-
est head word than with the head word further
away, then a narrow-scope reading is likely.
The best performance was achieved by combin-
ing the two heuristics: wide-scope reading is
likely if Coordination-Matches heuristic gives
a positive result and Collocation-Frequency
heuristic gives a negative result. We decided
to modify Chantree et al?s approach in two
ways and apply the modified approach to nlg.
Firstly, it seemed unlikely to us in the gen-
eral case that the deciding factor is always
whether two words co-occur at all. We there-
fore decided to separate cooccurence percent-
ages into ones that are very high and ones
that are very low. Secondly, we observed that
Chantree et al take Coordination Force into
account when they predict wide scope, but not
434
when they predict narrow scope. It would
be more systematic ? and more useful to an
nlg system, which has to cope with all possi-
ble inputs ? to consider all four combinations,
of strong and weak, coordination and modifi-
cation force. We define that there will be a
Strong Coordination Force (SCF) if the collo-
cational frequency between the two nouns is
high, and a Weak Coordination Force (WCF)
otherwise. Similarly, we define that there
will be a Strong Modification Force (SMF) if
the collocational frequency of Adj is high with
Noun1 and low with Noun2, and a Weak Mod-
ification Force (WMF) otherwise.
After a preliminary investigation of the data,
we decided to operationalise high collocational
frequency between two words as meaning that
either of the two words appears among the top
30% collocates of the other word in a gram-
matical relation (of interest); low collocational
frequency means that neither of the two words
appears among the top 70% collocates of the
other word in a grammatical relation. The hy-
potheses resulting from the above changes are
investigated in the following section.
4 Empirical Studies
We conducted three experiments. The first
two experiments ask what interpretation of
a scopally ambiguous np is the most plau-
sible, thereby testing our generalisation of
Chantree?s hypotheses. Knowing how an np
is interpreted is useful for an nlg system but
not sufficient, because ambiguity needs to be
traded off against other factors. For this rea-
son, our third experiment asks which of several
nps are preferred by a reader.
4.1 Interpreting nps
We use all four possible combinations of coor-
dination and modification forces to predict an
interpretation of a scopally ambiguous refer-
ring expression (see Table-1). An SMF would
make a wide-scope reading highly unlikely (cf.
(Wu and Furugori, 1998)). For instance, in the
bearded men and women there is an SCF and
an SMF, but in fact this phrase would be in-
terpreted as a narrow-scope reading because of
the scarcity of bearded women. On the other
hand, a WMF could be in favor of a wide-scope
reading. We expect that human readers would
opt for wide- and narrow-scope readings ac-
cording to Table 1.
Table 1: Predicting an interpretation
Hypothesis 1: SCF ? SMF ? NS
Hypothesis 2: SCF ? WMF ? WS
Hypothesis 3: WCF ? SMF ? NS
Hypothesis 4: WCF ? WMF ? WS
WS: Wide scope; NS: Narrow scope
To test these hypotheses, we conducted two
interpretation experiments, and rather than
asking expert linguists to annotate the strings,
we examined how ordinary readers interpret
structurally ambiguous strings. In these ex-
periments, given a referential domain and an
English np which attempts to identify a sub-
set of objects in the domain, participants were
asked to find the referent set of the np.
4.1.1 Experiment 1
In this experiment, referential domains were
constructed using real photographs of animals
with some of the features printed alongside
each photograph. Features were printed be-
cause 1) in a pilot study, we observed that
some participants had difficulty in discerning
some features in some of the photographs, and
2) we attribute some unusual features to some
objects, e.g., we attributed cats with the fea-
ture barking although cats don?t bark in re-
ality. Two pairs of nouns were used: one with
SCF, and the other with WCF. For each pair
of nouns, four different adjectives were used:
two with SMF, and two with WMF. A trial
in this experiment consists of a set of 9 pic-
tures (placed in a 3 x 3 grid), and an English
np underneath these pictures. A sample trial
is shown in Figure 1. Participants? task was
to remove the pictures (by mouse clicks on the
pictures) that were referred to by the np. A
removed picture was immediately replaced by
a blank rectangle (of the same size).
In each trial, we made sure that both wide-
and narrow-scope readings are applicable. For
example, for the instruction Please, remove the
red lions and horses, in the domain there were
2 red lions, 2 red horses, and some (at least
one) non-red horses. If a participant removes
2 red lions and 2 red horses, we count it as a
wide-scope reading. However, if (s)he removes
all the horses we count it as a narrow-scope
reading. We also used 8 fillers, which do not
435
Figure 1: Interpreting an np (using pictures)
contain a coordination in the np (e.g., the dogs
on the left). 60 self-reported native or fluent
speakers of English, students from various UK
universities, did the experiment on the web.
2
Results and Discussion: Results were anal-
ysed according to whether a participant opted
for a wide- or narrow-scope reading. The par-
ticipants? responses are shown in Table 2. A
two-tailed sign binomial test was used to cal-
culate statistical significance. The data indi-
cate that word distribution information can re-
liably predict a wide-scope reading. However,
our predictions for a narrow-scope reading are
not confirmed. This may have been because
of an intrinsic bias in favour of wide-scope in-
terpretations. Another potential problem with
the experiment is that some of the nps shown
to participants were rather unusual, involving
bearded women, etc. Although the printed fea-
tures underneath the pictures forced partici-
pants to take these unusual cases seriously, the
clash between the picture (of a woman) and the
printed feature (?bearded?) that arose in such
cases may have made participants? responses
unreliable. To avoid this problem we now turn
to an experimental setup where we use Euler
diagrams instead of iconic pictures.
4.1.2 Experiment 2
This experiment mirrors experiment 1, but
we used Euler diagrams instead of pictures
2
Here and in the other experiments reported in this
paper, we ascertained that no important differences ex-
isted between the two groups of subjects. Focussing on
Experiment 1, for example, no significant difference in
the percentages of wide scope interpretations was found
between native speakers and subjects who were merely
fluent in English.
Table 2: Response proportions: Experiment 1
Force PR PJ p-value
SCF SMF NS NS (25/60) 0.52
SCF WMF WS WS (57/60) < 0.001
WCF SMF NS NS (26/60) 0.12
WCF WMF WS WS (53/60) < 0.001
PR: Predicted Reading; PJ: Participants? Judgement
to represent domain entities. Participants re-
ceived a mini-tutorial on our version of Eu-
ler diagrams, where shaded areas denote the
sets to which an NP might refer. The pur-
pose of this tutorial was to make sure that
the participants understand the semantics of
these diagrams. A sample trial is shown in
Figure 2 (where we expect that participants
would remove the diagram on the right, which
is counted as a wide-scope response). 60 self-
reported native or fluent speakers of English,
students from various UK universities, took
part in this web-based experiment.
Figure 2: Interpreting an np (Euler diagrams)
Results and Discussion: Results were
recorded according to whether a participant
opted for a wide- or narrow-scope reading. The
participants? responses are shown in Table 3.
A two-tailed sign binomial test was used to
calculate statistical significance of the results.
This time, all four hypotheses are confirmed.
We also observed, however, that in scopally
ambiguous expressions, a narrow-scope read-
ing tends to be particularly frequent in the ex-
treme case where Adj has a zero co-occurrence
with Noun2 (in the bnc). We note that these
results are in line with Chantree et al
A critic might argue that the problem that
was noted in connection with Experiment 1
applies to Experiment 2 as well, because it
shows diagrams involving a ?problematic? in-
436
Table 3: Response proportions: Experiment 2
Force PR PJ p-value
SCF SMF NS NS (51/60) < 0.001
SCF WMF WS WS (55/60) < 0.001
WCF SMF NS NS (46/60) < 0.001
WCF WMF WS WS (54/60) < 0.001
tersection between, for example, bearded and
women. The fact that women (arguably) can-
not be bearded could cause subjects to re-
ject these diagrams (choosing the other dia-
gram instead, as in the diagram included in
Fig. 3, which does not involve such an inter-
section). We would argue, however, that this
does not cause an unwanted bias. The scarcity
of bearded women is a legitimate reason for
subjects to believe that a diagram that asserts
their existence cannot be a proper interpreta-
tion of ?bearded men and women?; it is just
one of the many things that the corpus-based
approach captures indirectly, without repre-
senting it explicitly. It is equally applicable to
expressions like ?handsome men and women?,
where the corpus tells us that ?handsome? and
?women? do not go together well (even though
one probably would not say they do not exist).
We have seen that Word Sketches can make
reasonable predictions concerning the likeli-
hood of the different interpretations of the nps.
But an np that is clear (i.e., not likely to be
misunderstood) may have other disadvantages.
For example, it may lack fluency or it may be
perceived as unnecessarily lengthy. For this
reason, we also conducted an additional exper-
iment in which we tested readers? preferences.
4.2 Choosing the best np
The question of how to choose between differ-
ent nps could be approached in a number of
different ways: asking hearers which of sev-
eral descriptions they prefer, asking hearers
to rate several descriptions, measuring inter-
pretation effort (time), measuring hearers? er-
rors etc.. We conducted a readers? preference
experiment where participants were asked to
compare pairs of natural language descriptions
of one and the same target set, selecting the
one they found more appropriate. Brief de-
scriptions took the form the Adj Noun1 and
Noun2. Non-brief descriptions took the forms
the Adj Noun1 and the Noun2 (for NS) and the
Adj Noun1 and the Adj Noun2 (for WS). A de-
scription is said to be clear if its predicted read-
ing is the same as the intended one. By def-
inition a non-brief description is always clear.
Each description could either be brief or not
(?b) and also clear or not (?c) (but not (?b,
?c), as this combination is not applicable in
the present setting). We expected to find that:
Hypothesis 5: (+c,+b) descriptions are pre-
ferred over ones that are (+c,?b).
Hypothesis 6: (+c,?b) descriptions are pre-
ferred over ones that are (?c,+b).
4.2.1 Experiment 3
In this experiment, referential domains were
represented using Euler diagrams. In each
trial, participants were shown an Euler dia-
gram, with some of its area filled to indicate
the target referent. They were also shown two
English nps, which attempted to identify the
filled area. A sample trial, where the intended
reading is narrow scope, is shown in Figure
3. Each hypothesis was tested under two con-
Figure 3: Sample Trial: Choosing the best np
ditions: 1) where the intended reading (IR)
was WS; and 2) where the IR was NS. The 4
comparisons thus corresponded to 4 conditions
(where PR stands for predicted reading):
C1. IR = WS & PR = WS
(+c,+b) vs. (+c,?b)
C2. IR = NS & PR = NS
(+c,+b) vs. (+c,?b)
C3. IR = WS & PR = NS
(?c,+b) vs. (+c,?b)
C4. IR = NS & PR = WS
(?c,+b) vs. (+c,?b)
46 self-reported native or fluent speakers of En-
437
glish, students from various UK universities,
did the experiment on the web.
Results and Discussion: Results were
coded according to whether a participant?s
choice was ?b and/or ?c. Table 4 displays
response proportions. A two-tailed sign bino-
mial test was used to calculate statistical sig-
nificance of the results. The results confirm
our hypotheses in all conditions, being highly
statistically significant (p < 0.001).
Table 4: Response proportions: Experiment 3
C1 C2 C3 C4
+b 91.3% 67.9% 26.1 14.5
+c - - 73.9% 88.5%
4.3 Summary of the Empirical Data
As hypothesised, Kilgarriff?s Word Sketches
can be used to predict the most likely read-
ing of a scopally ambiguous expression. It is
also important to note that it is the Modifi-
cation Force which is the deciding factor for
a particular reading. Moreover, other things
being equal, brief descriptions are preferred
over longer ones. Since Experiment 2 (and,
to an extent, Experiment 1) confirmed our hy-
potheses, we could have based our algorithm
on these. As was noted in section 4.1.2, how-
ever, our data also suggest a slight modifica-
tion of Hypotheses 1 and 3, because a pref-
erence for narrow scope existed mainly when
the Adjective and the second Noun co-occurred
very rarely. Therefore, we shall use a modified
version of Strong Modification Force (SMF):
SMF
?
will mean that Adj and Noun2 have zero
(rather than below 30%) cooccurrence in the
bnc.
5 Applying results to gre
In this section, we show how the results of
the previous sections can be exploited in gre.
The patterns explored in the above correspond
to disjunctive plural references. Disjunction is
required whenever there is no conjunction of
atomic properties that sets the elements of a
set of referents apart from all the other ob-
jects in the domain. Recall example 1 (from
?1), where the aim is to single out the black
sheep and black goats from the rest of the an-
imals. This task cannot be performed by a
simple conjunction (i.e., of the form ?the X?,
where X contains adjectives and nouns only),
so disjunctions become unavoidable.
Various proposals have been made for al-
lowing gre algorithms to produce referring
expressions of this kind (Stone, 2000; van
Deemter, 2002; Gardent, 2002; Horacek,
2004). Here we take as our starting point the
approach of (Gatt, 2007) (henceforth Gatt?s
Algorithm with Partitioning or gap). gap is
the only algorithm that produces a dd in Dis-
junctive Normal Form (dnf) while also guar-
anteeing that every ?part? of the partition
contains a noun. The dnf takes the form:
S
1
? S
2
... ? S
n
, where each S
i
itself expresses
a conjunction of atomic properties. (For ex-
ample, S
1
might be Sheep ? Black, while S
2
is Goat ? Black.) We sketch two extensions of
this approach: the first, purely formal exten-
sion ensures that a set of such logical formulae
is generated, rather than just one formula; all
of these formulae are unambiguous, and logi-
cally equivalent with each other; but they all
map to different strings of words. This is be-
cause we assume a very direct Linguistic Real-
isation strategy in which, for example, ((Black
? Sheep) ? Goats) is worded as the black sheep
and goats; syntactic ambiguity results from the
lack of brackets in the English np. The sec-
ond, empirically based extension is to choose
the ?best? element of the set (of formulae) by
making use of our experimental outcomes so as
to balance clarity and brevity.
Since our predictions are based on words,
we propose a model that constructs descrip-
tions from words and in which the description
building process is driven by words. We com-
pute the extension (where the extension of a
word w consists of all objects to which w ap-
plies) of a potentially ambiguous word by uni-
fying the extensions of all its interpretations.
Let p
1
, p
2
, ..., p
n
be the properties that a word
w can express. Then the extension of w is:
[[ w ]] =
i=n
?
i=1
[[ p
i
]] (1)
In what follows, a domain consists of a set D
of objects, and a set P of properties applicable
to objects in D. Given a set of target referents
R ? D, the proposed algorithm will:
? lexicalise each p ? P into words; Lexi-
calisation takes a property as input and
438
returns the set of possible realisations of
that property. For example, a property,
say, aged will be realised as (a set of)
words {old, aged, senior}.
? build a dd in dnf using words, where the
extension of a word is computed as indi-
cated in equation 1. Each S
i
must contain
a head noun. For example, in the sce-
nario presented in Example 1 under ?1, it
would produce a dd like: (black ? sheep)
? (black ? goats).
? apply transformation rules on the dd to
construct a set of dds that are logically
equivalent to the dd. (See below.)
? realise each description in the set as En-
glish nps using appropriate syntax. Each
description is realised as one and only one
np, using the above realisation strategy.
? determine the most likely reading of each
np, by making use of Word Sketches.
? select the np that is optimal given our em-
pirical findings. (See below.)
Transformation Rules: In connection with
reference to sets, it has been proposed to use
the Q-M algorithm (McCluskey, ) to find the
shortest formula equivalent to a given input
formula (van Deemter, 2002). In the present
setting, the shortest formula might lead to a
confusing np after linguistic realisation. For
example, the formula Black ? (Cats ? Dogs)
might be realised as the black cats and dogs,
which could easily be misunderstood as (Black
? Cats) ? Dogs. For this purpose, we propose
to use a set of transformation rules that allow
us to find a set of formulae logically equivalent
to the original formula; the aim is to make the
set large enough that all the relevant expres-
sive choices (as investigated in this paper) are
represented. In particular, we need the follow-
ing rules that operate on dnfs (where A is an
adjective; B
1
and B
2
are nouns; X and Y are
combinations of adjectives and nouns).
1. ((A ?B
1
) ? (A ?B
2
)) ? (A ? (B
1
?B
2
))
2. (X ? Y ) ? (Y ?X)
After application of these transformation
rules, the original description ? (i.e., the for-
mula produced by an algorithm such as gap)
is replaced by a set of formulae F all of whose
elements are logically equivalent to ?. The el-
ements of F are then realised as nps. The clar-
ity of each np is determined as follows (where
PR and IR stand for predicted reading and in-
tended reading, respectively).
If SMF? then PR is NS
Else If WMF then PR is WS
Else PR is {NS, WS}
EndIf
If (PR = IR) then NP is clear
Else NP is unclear
EndIf
If, after transformations, several of the re-
sulting descriptions are clear then the choice
between them needs to be taken on other
grounds. To do this, we give preference to the
shortest of all descriptions that are clear (mea-
sured in terms of number of words in the np).
If ties still arise then we suggest that fluency
is taken into account, for example by prefer-
ring np whose structure is most frequent in
the bnc. This procedure will often result in
nps that are ?clear? even though they are syn-
tactically ambiguous.
Example 2: Let the domain be repre-
sented as: {man(e
1
, e
2
, e
6
), woman(e
3
, e
4
, e
5
),
young(e
5
, e
6
), old(e
1
, e
2
, e
3
, e
4
)}. Our task
is to single out {e
1
, e
2
, e
3
, e
4
} from rest of
the entities. First, properties are lexicalised
into words. Suppose the relevant words are
the ones in the list Q = ?man, woman, old,
young?. Then, the algorithm takes each word
w ? Q in turn and constructs a dd: (old ?
man) ? (old ? woman). The transformation
rules then produce {old?(man?woman), old?
(woman?man), (old?man)? (old?woman),
(old?woman)? (old?man)}. These formulae
are realised as: (1) the old men and women, (2)
the old women and men, (3) the old men and
the old women and (4) the old women and the
old men. The nps (1) and (2) are structurally
ambiguous, but the Word Sketches rule out the
unintended reading of both nps (with narrow
scope for the adjective), so they are both clear.
The nps (3) and (4) are structurally unam-
biguous. All nps are therefore clear, but (1)
and (2) are preferred because they are shorter
than (3) and (4). Corpus frequency suggests
that the tie between (1) and (2) is resolved by
opting for the more frequent pattern (1).
6 Conclusions and future work
We highlighted that structural ambiguity,
which is often ignored in the gre could cause
439
confusion for a hearer and, therefore, should be
dealt with. Based on psycholinguistic evidence
that avoidance of all ambiguity is hard, we sug-
gested an approach that avoids referring ex-
pressions that have distractor interpretations.
We did: (1) interpretation experiments and
found that Word Sketches can be used to make
distractor interpretation precise; and (2) an
experiment with human readers that trades-
off clarity and brevity. A gre algorithm is
sketched that balances these factors based on
our experimental findings.
We aim to extend this work in two direc-
tions. First, we hypothesise that our ap-
proach can help nlg systems handle other sur-
face ambiguities, for instance involving PP-
attachment. Second, we realise that contex-
tual factors are likely to affect people?s inter-
pretive and generative inclinations. Therefore,
in light of the work reported in this paper, it
would be interesting to explore the effect of
co-occurrences in a given text upon the inter-
pretation of nps occurring later in that same
text, since the effect of such earlier occurrences
on readers? interpretation could conceivably
?drown out? the generic likelihoods based on
Word Sketches that have formed the main sub-
ject matter of this paper.
References
Abney, S. 1996. Statistical methods and linguis-
tics. In Klavans, Judith and Philip Resnik, ed-
itors, The Balancing Act: Combining Symbolic
and Statistical Approaches to Language, pages 1?
26. The MIT Press, Cambridge, Massachusetts.
Chantree, F., B. Nuseibeh, A. de Roeck, and
A. Willis. 2006. Identifying nocuous ambigui-
ties in requirements specifications. In Proceed-
ings of 14th IEEE International Requirements
Engineering conference, Minnesota, U.S.A.
Dale, R. 1992. Generating Referring Expressions:
Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Gardent, C. 2002. Generating minimal definite
descriptions. In Proceedings of the 40th Annual
Meeting of the ACL, Philadelphia, USA.
Gatt, A. 2007. Generating Coherent References
to Multiple Entities. Ph.D. thesis, University of
Aberdeen, Aberdeen, Scotland.
Horacek, H. 2004. On referring to sets of objects
naturally. In Proceedings of the 3rd International
Conference on NLG, pages 70?79, UK.
Inui, K., T. Tokunaga, and H. Tanaka. 1992. Text
revision: A model and its implementation. In
Proceedings of the 6th International Workshop
on NLG, pages 215?230, Berlin, Heidelberg.
Kilgarriff, A. 2003. Thesauruses for natural lan-
guage processing. In Proceedings of NLP-KE,
pages 5?13, Beijing, China.
Krahmer, E. and M. Theune. 2002. Efficient
context-sensitive generation of referring expres-
sions. In van Deemter, K. and R. Kibble, editors,
Information Sharing: Reference and Presupposi-
tion in Language Generation and Interpretation,
CSLI Publications, pages 223?264.
McCluskey, E. J. Introduction to the Theory of
Switching Circuits. McGraw-Hill Book Co.
Neumann, G. 1994. A Uniform Computational
Model for Natural Language Parsing and Gener-
ation. Ph.D. thesis, University of the Saarland.
Reiter, E. and R. Dale. 2000. Building Natural
Language Generation Systems. Cambridge Uni-
versity Press.
Siddharthan, A. and A. Copestake. 2004. Gener-
ating referring expressions in open domains. In
Proceedings of the 42nd Annual Meeting of the
ACL, Barcelona, Spain.
Stone, M. and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics.
In Proceedings of the 9th International Workshop
on NLG, pages 178?187, New Brunswick, New
Jersey.
Stone, M. 2000. On identifying sets. In Proceed-
ings of the 1st INLG Conference, pages 116?123,
Mitzpe Ramon.
Tanenhaus, M.K. and J.C. Trueswell. 1995. Sen-
tence comprehension. In Miller, J. and P. Eimas,
editors, Handbook of Perception and Cognition,
Vol. 11: Speech, Language and Communication,
pages 217?262. New York: Academic Press.
van Deemter, K. 2002. Generating referring ex-
pressions: Boolean extensions of the incremental
algorithm. Comp. Linguistics, 28(1):37?52.
van Deemter, K. 2004. Towards a probabilistic
version of bidirectional OT syntax and seman-
tics. Journal of Semantics, 21(3):251?281.
Wasow, T., A. Perfors, and D. Beaver. 2005. The
puzzle of ambiguity. In Orgun, O. and P. Sells,
editors, Morphology and The Web of Grammar:
Essays in Memory of Steven G. Lapointe. CSLI
Publications.
Wu, H. and T. Furugori. 1998. A computational
method for resolving ambiguities in coordinate
structures. In Proceedings of PACLIC-12, pages
263?270, National University of Singapore.
440
Proceedings of the Fourth International Natural Language Generation Conference, pages 89?91,
Sydney, July 2006. c?2006 Association for Computational Linguistics
The Clarity-Brevity Trade-off in Generating Referring Expressions ?
Imtiaz Hussain Khan and Graeme Ritchie and Kees van Deemter
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, U.K.
{ikhan,gritchie,kvdeemte}@csd.abdn.ac.uk
Abstract
Existing algorithms for the Generation of
Referring Expressions (GRE) aim at gen-
erating descriptions that allow a hearer to
identify its intended referent uniquely; the
length of the expression is also considered,
usually as a secondary issue. We explore
the possibility of making the trade-off be-
tween these two factors more explicit, via
a general cost function which scores these
two aspects separately. We sketch some
more complex phenomena which might be
amenable to this treatment.
1 Introduction
Until recently, GRE algorithms have focussed on
the generation of distinguishing descriptions that
are either as short as possible (e.g. (Dale, 1992;
Gardent, 2002)) or almost as short as possible (e.g.
(Dale and Reiter, 1995)). Since reductions in am-
biguity are achieved by increases in length, there
is a tension between these factors, and algorithms
usually resolve this in some fixed way. However,
the need for a distinguishing description is usually
assumed, and typically built in to GRE algorithms.
We will suggest a way to make explicit this bal-
ance between clarity (i.e. lack of ambiguity) and
brevity, and we indicate some phenomena which
we believe may be illuminated by this approach.
The ideas in this paper can be seen as a loosen-
ing of some of the many simplifying assumptions
often made in GRE work.
?This work is supported by a University of Aberdeen
Sixth Century Studentship, and the TUNA project (EPSRC,
UK) under grant number GR/S13330/01. We thank Ielka van
der Sluis and Albert Gatt for valuable comments.
2 Clarity, Brevity and Cost
We consider only simple GRE, where the aim is to
construct a conjunction of unary properties which
distinguish a single target object from a set of po-
tential distractors. Our notation is as follows. A
domain consists of a set D of objects, and a set P
of properties applicable to objects in D. A descrip-
tion is a subset of P. The denotation of S, written
[[ S ]], is {x ? D | ?p ? S : p(x)}.
(Krahmer et al, 2003) describe an approach to
GRE in which a cost function guides search for a
suitable description, and show that some existing
GRE algorithms fit into this framework. However,
they follow the practice of concentrating solely on
distinguishing descriptions, treating cost as a mat-
ter of brevity. We suggest that decomposing cost
into two components, for the clarity and brevity
of descriptions, permits the examination of trade-
offs. For now, we will take the cost of a description
S to be the sum of two terms:
cost(S) = fC(S) + fB(S).
where fC counts ambiguity (lack of clarity) and
fB counts size (lack of brevity). Even with this
decomposition of cost, some existing algorithms
can still be seen as cost-minimisation. For exam-
ple, the cost functions:
fC(S) =| P | ? | [[ S ]] |
fB(S) = | S |
allow the Full Brevity algorithm (Dale, 1992) to
be viewed as minimising cost(S), and the in-
cremental algorithm (Dale and Reiter, 1995) as
hill-climbing (strictly, hill-descending), guided by
the property-ordering which that algorithm re-
quires. Whereas Krahmer et al?s cost functions
are (brevity-based) heuristic guidance functions,
our alternative here is a global quantity for opti-
misation. Hence their simulation of Full Brevity
89
relies on the details of their algorithm (rather than
cost) to ensure clarity, while our own cost function
ensures both brevity and clarity.
3 Exploring the Trade-off
3.1 Varying penalties for distractors
Imagine the following situation. You are prepar-
ing a meal in a friend?s house, and you wish to
obtain, from your own kitchen, a bottle of Italian
extra virgin olive oil which you know is there. The
only way open to you is to phone home and ask
your young child to bring it round for you. You
know that also in your kitchen cupboard are some
distractors: one bottle each of Spanish extra virgin
olive oil, Italian non-virgin olive oil, cheap veg-
etable oil, linseed oil (for varnishing) and cam-
phorated oil (medicinal). It is imperative that you
do not get the linseed or camphorated oil, and
preferable that you receive olive oil. A full ex-
pression, Italian extra virgin olive oil, guarantees
clarity, but may overload your helper?s abilities. A
very short expression, oil, is risky. You might well
settle for the intermediate olive oil.
To model this situation, fC could take a much
higher value if [[ S ]] contains a distractor which
must not be selected (e.g. varnish rather than cook-
ing oil). That is, instead of a simple linear function
of the size of [[ S ]], there is a curve where the cost
drops more steeply as the more undesirable dis-
tractors are excluded. For example, each object
could be assigned a numerical rating of how unde-
sirable it is, with the target having a score of zero,
and the fC value for a set A could be the maxi-
mum rating of any element of A. (This would, of
course, require a suitably rich domain model.)
The brevity cost function fB could still be a rel-
atively simple linear function, providing fB values
do not mask the effect of the shape of the fC curve.
3.2 Fuzziness of target
Suppose Mrs X has dropped a piece of raw
chicken meat on the kitchen table, and immedi-
ately removed the meat. She would now like Mr
X to wipe the area clean. The meat leaves no visi-
ble stain, so she has to explain where it was. In this
case, it appears that there is no such thing as a dis-
tinguishing description (i.e. a description that pins
down the area precisely), although Mrs X can ar-
bitrarily increase precision, by adding properties:
? the edge of the table,
? the edge of the table, on the left (etc.)
The ideal description would describe the dirty area
and nothing more, but a larger area will also do,
if not too large. Here, the domain D is implic-
itly defined as all conceivable subareas of the ta-
ble, the target is again one element of D, but ? un-
like the traditional set-up with discrete elements ?
a description (fuzzily) defines one such area, not
a disjoint collection of individual items. Our fC
operates on the description S, not just on the num-
ber of distractors, so it can assess the aptness of
the denotation of any potential S. However, it has
to ensure that this denotation (subarea of the sur-
face) contains the target (contaminated area), and
does not contain too much beyond that. Hence,
we may need to augment our clarity cost function
with another argument: the target itself. In gen-
eral, more complex domains may need more com-
plicated functions.
3.3 Underspecification in dialogue
Standard GRE algorithms assume that the speaker
knows what the hearer knows (Dale and Reiter,
1995). In practice, speakers can often only guess.
It has been observed that speakers sometimes pro-
duce referring expressions that are only disam-
biguated through negotiation with the hearer, as
exemplified in the following excerpt (quoted in
(Hirst, 2002)).
1. A: What?s that weird creature over there?
2. B: In the corner?
3. A: [affirmative noise]
4. B: It?s just a fern plant.
5. A: No, the one to the left of it.
6. B: That?s the television aerial. It pulls out.
A and B are in the same room, in an informal set-
ting, so A can be relatively interactive in convey-
ing information. Also, the situation does not ap-
pear to be highly critical, in comparison to a mil-
itary officer directing gunfire, or a surgeon guid-
ing an incision. Initially, A produces an expres-
sion which is not very detailed. It may be that he
thinks this is adequate (the object is sufficiently
salient that B will uniquely determine the refer-
ent), or he doesn?t really know, but is willing to
make an opening bid in a negotiation to reach the
goal of reference. In the former case, a GRE algo-
rithm which took account of salience (e.g. (Krah-
mer and Theune, 1999)), operating withA?s model
of B?s knowledge, should produce this sort of ef-
fect. (A dialogue model might also be needed.) In
the latter case, we need an algorithm which can
90
relax the need for complete clarity. This could be
arranged by having fC give similar scores to deno-
tations where there are no distractors and to deno-
tations where there are just a few distractors, with
fB making a large contribution to the cost.
3.4 Over-specification
Recently, interest has been growing in ?overspec-
ified? referring expressions, which contain more
information than is required to identify their in-
tended referent. Some of this work is mainly or ex-
clusively experimental (Jordan and Walker, 2000;
Arts, 2004), but algorithmic consequences are also
being explored (Horacek, 2005; Paraboni and van
Deemter, 2002; van der Sluis and Krahmer, 2005).
Over-specification could also arise in a dialogue
situation (comparable to that in Section 3.3) if a
speaker is unclear about the hearer?s knowledge,
and so over-specifies (relative to his own knowl-
edge) to increase the chances of success.
This goes beyond the classical algorithms,
where the main goal is total clarity, with no rea-
son for the algorithm to add further properties to
an already unambiguous expression. That is, such
algorithms assume that every description S for
which | [[ S ]] |= 1 has the same level of clarity
(fC value). This assumption could be relaxed. For
example, the approach of (Horacek, 2005) to GRE
allows degrees of uncertainty about the effective-
ness of properties to affect their selection. Within
such a framework, one could separately compute
costs for clarity (e.g. likelihood of being under-
stood) and brevity (which might include the com-
plexity of expressing the properties).
4 Conclusion and Future Work
We have argued that the GRE task becomes very
different when some commonly-made assump-
tions are abandoned: some distractors might be
worse than others (section 3.1); the target may be
impossible to distinguish precisely (section 3.2);
the speaker may be unsure what the hearer knows
(section 3.3); or there may be a need for over-
specification (section 3.4)). As a result, it may be
necessary to consider other aspects of the descrip-
tions and their denotations, not simply counting
distractors or numbers of properties. Some effects
could perhaps be modelled using costs which are
not simple linear functions, but which give varying
importance to particular aspects of the denotation
of a description, or of its content. We hope that
this approach will ultimately shed light not only
on the effect of the discourse situation, but also
some aspects of generating indefinite descriptions.
References
Anja Arts. 2004. Overspecification in Instructive Text.
Ph.D. thesis, Tilburg University, The Netherlands.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
18:233?263.
Robert Dale. 1992. Generating Referring Expres-
sions: Building Descriptions in a Domain of Objects
and Processes. MIT Press.
Claire Gardent. 2002. Generating minimal distin-
guishing descriptions. In Proceedings of the 40th
Annual Meeting of the ACL (ACL?02), Philadelphia,
USA.
Graeme Hirst. 2002. Negotiation, compromise, and
collaboration in interpersonal and human?computer
conversations. In Proceedings of Workshop on
Meaning Negotiation, 18th National Conference
on Artificial Intelligence, pages 1?4, Edmonton,
Canada.
Helmut Horacek. 2005. Generating referential de-
scriptions under conditions of uncertainty. In Gra-
ham Wilcock, Kristiina Jokinen, Chris Mellish, and
Ehud Reiter, editors, Proceedings of the 10th Eu-
ropean Workshop on Natural Language Generation
(ENLG-05), pages 58?67.
Pamela Jordan and Marilyn Walker. 2000. Learning
attribute selections for non-pronominal expressions.
In Proceedings of the 38th Annual Meeting of the
ACL (ACL-00), pages 181?190.
Emiel Krahmer and Marie?t Theune. 1999. Efficient
generation of descriptions in context. In Proceed-
ings of the ESSLLI workshop on the generation of
nominals, Utrecht, The Netherlands.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Ivandre? Paraboni and Kees van Deemter. 2002. Gener-
ating easy references: the case of document deixis.
In Proceedings of the Second International Confer-
ence on Natural Language Generation, New York,
USA.
Ielka van der Sluis and Emiel Krahmer. 2005. Towards
the generation of overspecified multimodal referring
expressions. In Proceedings of the Symposium on
Dialogue Modelling and Generation at the 15th An-
nual Meeting of the ST & D (STD-05), Amsterdam,
The Netherlands.
91
Proceedings of the 12th European Workshop on Natural Language Generation, pages 98?101,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Hearer-oriented Evaluation of Referring Expression Generation ?
Imtiaz H. Khan, Kees van Deemter, Graeme Ritchie, Albert Gatt, Alexandra A. Cleland
University of Aberdeen, Aberdeen, Scotland, United Kingdom
{i.h.khan,k.vdeemter,g.ritchie,a.gatt,a.cleland}@abdn.ac.uk
Abstract
This paper discusses the evaluation of a
Generation of Referring Expressions algo-
rithm that takes structural ambiguity into
account. We describe an ongoing study
with human readers.
1 Introduction
In recent years, the NLG community has seen a
substantial number of studies to evaluate Gener-
ation of Referring Expressions (GRE) algorithms,
but it is still far from clear what would constitute
an optimal evaluation method. Two limitations
stand out in the bulk of existing work. Firstly,
most existing evaluations are essentially speaker-
oriented, focussing on the degree of ?human-
likeness? of the generated descriptions, disre-
garding their effectiveness (e.g. Mellish and Dale
(1998), Gupta and Stent (2005), van Deemter et al
(2006), Belz and Kilgarriff (2006), Belz and Re-
iter (2006), Paris et al (2006), Viethen and Dale
(2006), Gatt and Belz (2008)). The limited num-
ber of exceptions to this rule indicate that the dif-
ferences between the two approaches to evaluation
can be substantial (Gatt and Belz, 2008). Sec-
ondly, most evaluations have focussed on the se-
mantic content of the generated descriptions, as
produced by the Content Determination stage of
a GRE algorithm; this means that linguistic re-
alisation (i.e. the choice of words and linguistic
constructions) is usually not addressed (exceptions
are: Stone and Webber (1998), Krahmer and The-
une (2002), Siddharthan and Copestake (2004)).
Our aim is to build GRE algorithms that produce
referring expressions that are of optimal benefit to
a hearer. That is, we are interested in generating
descriptions that are easy to read and understand.
But the readability and intelligibility of a descrip-
tion can crucially depend on the way in which it is
? This work is supported by a University of Aberdeen
Sixth Century Studentship, and EPSRC grant EP/E011764/1.
worded. This happens particularly when there is
potential for misunderstanding, as can happen in
the case of attachment and scope ambiguities.
Suppose, for example, one wants to make it
clear that all radical students and all radical teach-
ers are in agreement with a certain idea. It might
be risky to express this as ?the radical students and
teachers are agreed?, since the reader1 might be
inclined to interpret this as pertaining to all teach-
ers rather than only the radical ones. For this rea-
son, a GRE program might opt for the longer noun
phrase ?the radical students and the radical teach-
ers?. But because this expression is lengthier, the
choice involves a compromise between compre-
hensibiliity and brevity, a special case of a diffi-
cult trade-off that is typical of generation as well
as interpretation of language (van Deemter, 2004).
We previously reported the design of an algo-
rithm (based on an earlier work on expressions re-
ferring to sets (Gatt, 2007)), which was derived
from experiments in which readers were asked to
express their preference between different descrip-
tions and to respond to instructions which used a
variety of phrasings (Khan et al, 2008). Here we
discuss the issues that arise when such an algo-
rithm is evaluated in terms of its benefits for read-
ers.
2 Summary of the algorithm
In order to study specific data, we have focussed
on the construction illustrated in Section 1 above:
potentially ambiguous Noun Phrases of the gen-
eral form the Adj Nouni and Nounj . For such
phrases, there are potentially two interpretations:
wide scope (Adj modifies both Nouni and Nounj)
or narrow scope (Adj modifies Nouni but not
Nounj).
Our algorithm starts from an unambiguous set-
theoretic formula over lexical items (i.e. words
1In this paper, we use the word reader and hearer inter-
changeably.
98
have already been chosen), and thus has to choose
between a number of different realisations. The
possible phrasings for the wide scope meaning are:
(1) the Adj Noun1 and Noun2, (2) the Adj Noun2
and Noun1, (3) the Adj Noun1 and the Adj Noun2,
and (4) the Adj Noun2 and the Adj Noun1. For nar-
row scope, the possibilities are: (1) the Adj Noun1
and Noun2, (2) the Noun2 and Adj Noun1, (3) the
Adj Noun1 and the Noun2, and (4) the Noun2 and
the Adj Noun1. For our purposes, (1) and (2) are
designated as ?brief?, (3) and (4) as ?non-brief?
(that is, ?brevity? has a specialised sense involv-
ing the presence/absence of ?the? and possibly Adj
before the second Noun). Importantly, the ?non-
brief? expressions are syntactically unambiguous,
but the ?brief? NPs are potentially ambiguous, and
hence are the focus of attention in this work.
Our algorithm is based on certain specific hy-
potheses (from the earlier experiments) which
make crucial use of corpus data concerning the
frequency of two types of collocations: the col-
location between an adjective and a noun, and the
collocation between two nouns. At a broader level,
we hypothesise: the most likely reading of an NP
can be predicted using corpus data (Word Sketches
(Kilgarriff, 2003)). The more specific hypotheses
derive from earlier work by Kilgarriff (2003) and
Chantree et al (2006), and were further developed
and tested in our previous experiments. The cen-
tral idea is that this statistical information can be
used to predict a ?most likely? scoping (and hence
interpretation) for the adjective in the ?brief? (i.e.
potentially ambiguous) NPs. We define an NP to
be predictable if our model predicts a single read-
ing for it; otherwise it is unpredictable. Hence, all
?non-brief? NPs are predictable (being unambigu-
ous), but only some of the ?brief? ones are pre-
dictable.
In a nutshell, the model underlying our algo-
rithm prefers predictable expressions to unpre-
dictable ones, but if several of the expressions are
predictable then brief expressions are preferred
over non-brief.
3 Aims of the study
We want to find out whether our generator
makes the best possible choices (for hearers) from
amongst the different ways in which a given de-
scription can be realised. But although our al-
gorithm uses sophisticated strategies for avoiding
noun phrases that it believes to be liable to mis-
understanding, misunderstandings cannot be ruled
out, and if a hearer misunderstands a noun phrase
then secondary aspects such as reading (and/or
comprehension) speed are of little consequence.
We therefore plan first to find out the likelihood of
misunderstanding. For this reason, we will report
on the degree of accuracy, as a percentage of times
that a participant?s understanding of an expression
that we label as predictable fails to match the in-
terpretation assigned by our model. Additionally,
we shall statistically test two hypotheses:
Comprehension Accuracy 1: Predictable ex-
pressions are more often interpreted in
agreement than in disagreement with the
model.
Comprehension Accuracy 2: There is more
agreement among participants on the inter-
pretation of predictable expressions than of
unpredictable expressions.
We will not only test the comprehensibility of the
expressions generated by our algorithm, but their
readability and intelligibility as well. This is nec-
essary because the experiments which led to the
algorithm design considered only certain aspects
of the hearer?s reaction to NPs (e.g. metalinguistic
judgements about a participant?s preferences) and
we wish to check these comprehensibility/brevity
facets from a different, perhaps psycholinguisti-
cally more valid, perspective. It is also necessary
because avoidance of misunderstandings is not the
only decisive factor: if several of the expressions
are predictable then our algorithm chooses be-
tween them by preferring brevity. But why is brief
better than non-brief? Taking readability and intel-
ligibility together as ?processing speed?, our third
hypothesis is:
Processing speed: Subjects process
predictable brief expressions more
quickly than predictable non-brief ones.
Confirmation of this hypothesis would be a strong
indication that our algorithm is on the right track,
particularly if the degree of accuracy (see above)
turns out to be high. Processing speed is a com-
plex concept, but we could decompose it as ?read-
ing speed? and ?comprehension speed?, permitting
us to examine reading and comprehension sepa-
rately. We intend to see what evidence there is for
the following additional propositions, which will
be tested solely to aid our understanding.
99
Reading Speed:
RS1: Subjects read predictable brief NPs more
quickly than unpredictable brief ones.
RS2: Subjects read unpredictable brief NPs more
quickly than predictable non-brief ones.
RS3: Subjects read predictable brief NPs more
quickly than predictable non-brief ones.
Comprehension Speed:
CS1: Subjects comprehend predictable brief NPs
more quickly than unpredictable brief ones.
CS2: Subjects comprehend predictable non-brief
NPs more quickly than unpredictable brief ones.
CS3: Subjects do not comprehend predictable
non-brief NPs more quickly than predictable brief
ones.
(Remember that, in our restricted set of NPs, a
phrase cannot be both ?unpredictable? and ?non-
brief?.) Rejection of any of these statements will
not count against our algorithm.
4 Sketch of experimental procedure
Participants will be presented with a sequence of
trials (on a computer screen), each of which con-
sists of a lead-in sentence followed by a target sen-
tence and a comprehension question that relates to
the two sentences together. The target sentence
might for example say ?the radical students and
teachers were waving their hands?. The compre-
hension question in this case could be ?Were the
moderate teachers waving their hands??. As both
the target sentence and the comprehension ques-
tion make use of definite NPs (e.g. ?the moderate
teachers?), it is necessary to ensure any presuppo-
sitions about the existence of the referent set are
met, without biasing the answer. For this reason,
the target sentence is preceded by a lead-in sen-
tence to establish the existence of the sets within
the discourse (here, ?there were radical and mod-
erate people in a rally?).
Given this set-up we are confident that we
can identify, from a participant?s yes/no answer,
whether the NP in the target sentence was assigned
a narrow-scope or a wide-scope reading for the ad-
jective. The computer will record the participant?s
response as well as the length of time that the par-
ticipant took to answer the question. We will use
Linger2 for presentation of stimuli. Pilots sug-
gest that the complexity of the trials makes it ad-
visable to use masked sentence-based self-paced
2http://tedlab.mit.edu/?dr/Linger/
reading, in which every press of the space bar re-
veals the next sentence and the previous sentence
is replaced by dashes.
The choice of nouns and adjectives (to construct
NPs) is motivated by the fact that there is a bal-
anced distribution of NPs in each of the follow-
ing three classes. Wide scope class is the one for
which our model predicts a wide-scope reading;
narrow scope class is the one for which our model
predicts a narrow-scope reading; and ambiguous
class is the one for which our model fails to pre-
dict a single reading (Khan et al, 2008).
5 Issues emerging from this study
The design of this experiment raised some difficult
questions, some quite unexpected:
1. The quality of the output of a generation al-
gorithm might appear to be a simple and well-
understood concept. However, output quality is
multi-faceted, because an expression may be easy
to read but difficult to process semantically, or the
other way round. A thorough output evaluation
should address both aspects of quality, in our view.
2. If both reading and understanding are ad-
dressed, this raises the question of how these
two dimensions should be traded off against each
other. If one algorithm?s output was read more
quickly than that of another, but understood more
slowly than the second, which of the two should be
preferred? Perhaps there is a legitimate role here
for metalinguistic judgments after all, in which
participants are asked to express their preference
between expressions (see Paraboni et al (2006) for
discussion)? An alternative point of view is that
these questions are impossible to answer indepen-
dent of a realistic setting in which participants ut-
ter sentences with a concrete communicative pur-
pose in mind. If utterances were made in order to
accomplish a concrete task (e.g., to win a game)
then task-based evaluation would be possible.
3. Even though this paper has not focussed on de-
tails of experimental design and analysis, one diffi-
culty is worth mentioning: given the grammatical
options between which the generator is choosing,
only three types of situations are represented: a de-
scription can be brief and predictable (e.g. using
?the old men and women? to convey wide scope,
since the adjective is predicted by our algorithm
to have wide scope), brief and unpredictable (e.g.
?the rowing boats and ships? for wide scope, given
100
a prediction of narrow scope), or non-brief and
predictable (e.g. ?the old men and the old women?
for wide scope). It might appear that there exists
a fourth option: non-brief and unpredictable. But
this is ruled out by our technical sense of ?non-
brief?: as noted earlier, ?non-brief? NPs do not
have the scope ambiguity. Because of this ?miss-
ing cell?, it will not be possible to analyse our data
using an ANOVA test, which would have automat-
ically taken care of all possible interactions be-
tween comprehensibility and brevity. A number
of different tests will be used instead, with Bon-
ferroni corrections where necessary.
6 Conclusion
Human-based evaluation is gaining considerable
popularity in the NLG community. Whereas eval-
uation of GRE has mostly been speaker-oriented,
the present paper has explored a plan for an ex-
perimental hearer-oriented evaluation. The main
conclusion is that hearer-based evaluation is diffi-
cult because the quality of a generated expression
can be measured in different ways, whose results
cannot be assumed to match. One factor we have
not examined is the notion of fluency: it is possible
that our algorithm will sometimes choose a word
order (e.g. ?the women and old men?) that is rela-
tively infrequent, and therefore lacking in fluency.
Such situations might lead to longer reading times.
References
A. Belz and A. Kilgarriff. 2006. Shared-task evalu-
ations in HLT: Lessons for NLG. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 133?135.
A. Belz and E. Reiter. 2006. Comparing automatic
and human evaluation of NLG systems. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 313?320, Trento, Italy, 3-7 April.
F. Chantree, B. Nuseibeh, A. de Roeck, and A. Willis.
2006. Identifying nocuous ambiguities in require-
ments specifications. In Proceedings of 14th IEEE
International Requirements Engineering conference
(RE?06), Minneapolis/St. Paul, Minnesota, U.S.A.
A. Gatt and A. Belz. 2008. Attribute selection for re-
ferring expression generation: New algorithms and
evaluation methods. In Proceedings of the 5th Inter-
national Conference on NLG.
A. Gatt. 2007. Generating Coherent References to
Multiple Entities. Ph.D. thesis, University of Ab-
erdeen, Aberdeen, Scotland.
S. Gupta and A. Stent. 2005. Automatic evaluation
of referring expression generation using corpora. In
Proceedings of the Workshop on Using Corpora for
Natural Language Generation, pages 1?6.
I. H. Khan, K. van Deemter, and G. Ritchie. 2008.
Generation of referring expressions: Managing
structural ambiguities. In Proceedings of the 22nd
International Conference on Computational Lin-
guistics (COLING-8), pages 433?440, Manchester.
A. Kilgarriff. 2003. Thesauruses for natural language
processing. In Proceedings of NLP-KE, pages 5?13,
Beijing, China.
E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R. Kibble, editors, Information
Sharing: Reference and Presupposition in Language
Generation and Interpretation, CSLI Publications,
pages 223?264.
C. Mellish and R. Dale. 1998. Evaluation in the
context of natural language generation. Computer
Speech and Language, 12(4):349?373.
I. Paraboni, J. Masthoff, and K. van Deemter. 2006.
Overspecified reference in hierarchical domain:
measuring the benefits for readers. In Proceedings
of the Fourth International Conference on Natural
Language Generation(INLG), pages 55?62.
C. Paris, N. Colineau, and R. Wilkinson. 2006. Eval-
uations of NLG systems: Common corpus and tasks
or common dimensions and metrics? In Proceed-
ings of the 4th International Conference on Natural
Language Generation, pages 127?129.
A. Siddharthan and A. Copestake. 2004. Generating
referring expressions in open domains. In Proceed-
ings of the 42nd Meeting of the Association for Com-
putational Linguistics Annual Conference (ACL-04).
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proceedings of the Ninth International Workshop on
Natural Language Generation, pages 178?187, New
Brunswick, New Jersey.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the
generation of referring expressions. In Proceedings
of the 4th International Conference on Natural Lan-
guage Generation, pages 130?132.
K. van Deemter. 2004. Towards a probabilistic version
of bidirectional OT syntax and semantics. Journal
of Semantics, 21(3):251?281.
J. Viethen and R. Dale. 2006. Towards the evaluation
of referring expression generation. In Proceedings
of the 4th Australasian Language Technology Work-
shop, pages 115?122, Sydney, Australia.
101
