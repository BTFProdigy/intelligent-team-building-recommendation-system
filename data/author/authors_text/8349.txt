Generating Spatio-Temporal Descriptions in Pollen Forecasts
Ross Turner, Somayajulu Sripada and Ehud Reiter
Dept of Computing Science,
University of Aberdeen, UK
{rturner,ssripada,ereiter}@csd.abdn.ac.uk
Ian P Davy
Aerospace and Marine International,
Banchory, Aberdeenshire, UK
idavy@weather3000.com
Abstract
We describe our initial investigations into
generating textual summaries of spatio-
temporal data with the help of a prototype
Natural Language Generation (NLG) system
that produces pollen forecasts for Scotland.
1 Introduction
New monitoring devices such as remote sensing sys-
tems are generating vast amounts of spatio-temporal
data. These devices, coupled with the wider accessi-
bility of the data, have spurred large amounts of re-
search into how it can best be analysed. There has been
less research however, into how the results of the data
analysis can be effectively communicated. As part of
a wider research project aiming to produce textual re-
ports of complex spatio-temporal data, we have devel-
oped a prototype NLG system which produces textual
pollen forecasts for the general public.
Pollen forecast texts describe predicted pollen con-
centration values for different regions of a country.
Their production involves two subtasks; predicting
pollen concentration values for different regions of a
country, and describing these numerical values textu-
ally.In our work, we focus on the later subtask, tex-
tual description of spatio-temporally distributed pollen
concentration values. The subtask of predicting pollen
concentrations is carried out by our industrial collab-
orator, Aerospace and Marine International (UK) Ltd
(AMI).
A fairly substantial amount of work already exists
on weather forecast generation. A number of systems
have been developed and are currently in commercial
use with two of the most notable being FOG (Goldberg
et al, 1994) and MultiMeteo (Coch, 1998).
2 Knowledge Acquisition
Our knowledge acquisition activities consisted of cor-
pus studies and discussions with experts. We have
collected a parallel corpus (69 data-text pairs) of
pollen concentration data and their corresponding hu-
man written pollen reports which our industrial collab-
orator has provided for a local commercial television
station. The forecasts were written by two expert mete-
orologists, one of whom provided insight into how the
forecasts were written. An example of a pollen fore-
cast text is shown in Figure 1, its corresponding data is
shown in table 1. A pollen forecast in the map form is
shown in Figure 2.
?Monday looks set to bring another day of
relatively high pollen counts, with values up
to a very high eight in the Central Belt. Fur-
ther North, levels will be a little better at a
moderate to high five to six. However, even
at these lower levels it will probably be un-
comfortable for Hay fever sufferers.?
Figure 1: Human written pollen forecast text for the
pollen data shown in table 1
Figure 2: Pollen forecast map for the pollen data shown
in table 1
Analysis of a parallel corpus (texts and their under-
lying data) can be performed in two stages:
? In the first stage, traditional corpus analysis pro-
cedure outlined in (Reiter and Dale, 2000) and
(Geldof, 2003) can be used to analyse the pollen
forecast texts (the textual component of the paral-
lel corpus). This stage will identify the different
message types and uncover the sub language of
the pollen forecasts.
? In the second stage the more recent analysis meth-
ods developed in the SumTime project (Reiter et
163
ValidDate AreaID Value
27/06/2005 1 (North) 6
27/06/2005 2 (North West) 5
27/06/2005 3 (Central) 5
27/06/2005 4 (North East) 6
27/06/2005 5 (South West) 8
27/06/2005 6 (South East) 8
Table 1: Pollen Concentration Data for Scotland - Input
data for Figures 1 and 2
al., 2003) which exploit the availability of the un-
derlying pollen data corresponding to the forecast
texts can be used to map messages to input data
and also map parts of the sub language such as
words to the input data. Due to the fact that we
are modeling the task of automatically producing
pollen forecast texts from predicted pollen con-
centration values, knowledge of how to map in-
put data to messages and words/phrases is abso-
lutely necessary. Studies connecting language to
data are useful for understanding the semantics of
language in a more novel way than the traditional
logic-based formalisms (Roy and Reiter, 2005).
We have performed the first stage of the corpus anal-
ysis and part of the second stage so far. In the first
stage, we abstracted out the different message types
from the forecast texts (Reiter and Dale, 2000). These
are shown in Table 2. The main two message types
are forecast messages and trend messages. The for-
mer communicate the actual pollen forecast data (the
communicative goal) and the latter describe patterns in
pollen levels over time as shown in Figure 3
?Grass pollen counts continue to ease from
the recent high levels?
Figure 3: A trend message describing a fall in pollen
levels
Table 2 also shows three other identified message
types. We have ignored both the forecast explanation
and general message types in our system development
because they cannot be generated from pollen data
alone. For example, the explanation type messages ex-
plain the weather conditions responsible for the pollen
predictions. Hayfever messages in our system are rep-
resented as canned text. Examples of a forecast ex-
planation message and hayfever message are shown in
Figure 4 and Figure 5 respectively.
From our corpus analysis we have also been able to
learn the text structure for pollen forecasts. The fore-
casts normally start with a trend message and then in-
clude a number of forecast messages. Where hayfever
messages are present, they normally occur at the end of
the forecast.
Due to the fact that the input to our pollen text gen-
?Windier and wetter weather over last 24
hours has dampened down the grass pollen
count?
Figure 4: An example forecast explanation message
?Even though values are mostly low, those
sensitive to pollen may still be affected?
Figure 5: An example hayfever message
erator is the pollen data in numerical form, as part of
the second stage of the corpus analysis we need to map
the input data to the messages. In earlier ?numbers
to text? NLG systems such as SumTime (Sripada et
al., 2003) and TREND (Boyd, 1998), well known data
analysis techniques such as segmentation and wavelet
analysis were employed for this task. Since pollen data
is spatio-temporal we need to employ spatio-temporal
data analysis techniques to achieve this mapping. We
describe our method in the next section.
Our corpus analysis revealed that forecast texts con-
tain a rich variety of spatial descriptions for a location.
For example, the same region could be referred to by
it?s proper name e.g. ?Suthlerland and Caithness? or
by its? relation to a well known geographical landmark
e.g. ?North of the Great Glen? or simply by its? geo-
graphical location on the map e.g. ?the far North and
Northwest?. In the context of pollen forecasts which
describe spatio-temporal data, studying the semantics
of phrases or words used for describing locations or re-
gions is a challenge. We are currently analysing the
forecast texts along with the underlying data to under-
stand how spatial descriptions map to the underlying
data using the methods applied in the SumTime project
(Sripada et al, 2003).
As part of this analysis, in a seperate study, we asked
twenty four further education students in the Glasgow
area of Scotland a Geography question. The question
asked how many out of four major place names in Scot-
land did they consider to be in the south west of the
country. The answers we got back were very mixed
with a sizeable number of respondents deciding that
the only place we considered definitely not to be in the
south west of Scotland was in fact there.
3 Spatio-temporal Data Analysis
We have followed the pipeline architecture for text gen-
eration outlined in (Reiter and Dale, 2000). The mi-
croplanning and surface realisation modules from the
Sumtime project (Sripada et al, 2003) have largely
been reused. We have developed new data analysis
and document planning modules for the system and de-
scribe the data analysis module in the rest of this sec-
tion. The data analysis module performs segmentation
and trend detection on the data before providing the re-
sults as input to the Natural Language Generation Sys-
164
Message Type Data Dependency Corpus Coverage
Forecast Pollen data for day of forecast 100%
Trend Past/Future pollen forecasts 54%
Forecast Explanation Weather forecast for day of forecast 35%
Hayfever Pollen levels affect hay fever 23%
General General Domain Knowledge 17%
Table 2: Message Categorisation of the Pollen Corpus
tem. An example of the input data to our system is
shown in Table 1. Our data analysis is based on three
steps:-
1. segmentation of the geographic regions by their
non-spatial attributes (pollen values)
2. further segmentation of the segmented geographic
regions by their spatial attributes (geographic
proximity)
3. detection of trends in the generalised pollen level
for the whole region over time
3.1 Segmentation
The task of segmentation consists of two major sub-
tasks, clustering and classification (Miller and Han,
2001). Spatial clustering involves grouping objects into
similar subclasses, whereas spatial classification in-
volves finding a description for those subclasses which
differentiates the clustered objects from each other (Es-
ter et al, 1998).
Pollen values are measured on a scale of 1 to 10(low
to very high). We defined 4 initial categories for seg-
mentation, these are:-
1. VeryHigh - {8,9,10}
2. High - {6,7}
3. Moderate - {4,5}
4. Low - {1,2,3}
These categories proved rather rigid for our pur-
poses. This was due to the fact that human forecasters
take a flexible approach to classifying pollen values.
For example, in the corpus the pollen value of 4 could
be referred to as both a moderate level of pollen and a
low-to-moderate level of pollen. This lead us to define
3 further categories which are derived from our 4 initial
categories:-
5. LowModerate - {3,4}
6. ModerateHigh - {5,6}
7. HighVeryhigh - {7,8}
Thus, the initial segmentation of data carried out by
our system is a two stage process. Firstly regions are
clustered into the initial four categories by pollen value.
The second stage involves merging adjacent categories
that only contain regions with adjacent values. For ex-
ample if we take the input data from Table 1, after the
first stage we have the sets:-
? {{AreaID=2,Value=5},{AreaID=3,Value=5}}
? {{AreaID=1,Value=6},{AreaID=4,Value=6}}
? {{AreaID=5,Value=8},{AreaID=6,Value=8}}
In stage two we create the union of the moderate and
high sets to give:-
? {{AreaID=1,Value=6},{AreaID=2,Value=5},
{AreaID=3,Value=5},{AreaID=4,Value=6}}
? {{AreaID=5,Value=8},{AreaID=6,Value=8}}
Although this initial segmentation could be accom-
plished all in one step, completing it in two steps pro-
vided a more simple software engineering solution.
We can now carry out further segmentation of these
sets according to their spatial attributes. In our set of
regions with ModerateHigh pollen levels we can see
that AreaIDs 1,2,3,4 are in fact all spatial neighbours.
The north, north east and north west regions can be
described spatially as the northern part of the country.
Therefore we can now say that ?Pollen levels are at a
moderate to high 5 or 6 in the northern and central
parts of the country? . Similarly, as the two members of
our set containing regions with VeryHigh pollen levels
are also spatial neighbours we can also say that ?Pollen
levels are at a very high level 8 in the south of the coun-
try?. This process now yields the following two sets:-
? {{AreaID=1234,Value=[5,6]}}
? {{AreaID=56,Value=[8]}}
Our two sets we have now created can now be passed
to the Document Planner were they will be encapsu-
lated as individual Forecast messages.
3.2 Trend Detection
Trend detection in our system works by generalising
over all sets created by segmentation. From our two
sets we can say that generally pollen levels are high
over the whole of Scotland. Looking at the previous
days forecast we can detect a trend by comparing the
two generalisations. If the previous days forecast was
also high we can say ?pollen levels remain at the high
165
levels of yesterday?. By looking further back, and if
those previous days were also high, we can say ?pollen
levels remain at the high levels of recent days?. If the
previous days forecast was low, we can say ?pollen lev-
els have increased from yesterdays low levels?. Our
data analysis module then conveys the information that
there is a relation between the general pollen level
of today and the general pollen level of some recent
timescale to the Document Planner, which then encap-
sulates the information as a Trend message.
After the results of data analysis have been input into
the NLG pipeline the output in Figure 6 is produced.
?Grass pollen levels for Monday remain at
the moderate to high levels of recent days
with values of around 5 to 6 across most parts
of the country. However, in southern areas,
pollen levels will be very high with values of
8.?
Figure 6: The output text from our system for the input
data in Table 1
4 Evaluation
A demo of the pollen forecasting system can be found
on the internet at 1. The evaluation of the system is be-
ing carried out in two stages. The first stage has used
this demo to obtain feedback from expert meteorolo-
gists at AMI. We found the feedback on the system to
be very positive and hope to deploy the system for the
next pollen season. Two main areas identified for im-
provement of the generated texts:-
? Use of a more varied amount of referring expres-
sions for geographic locations.
? An ability to vary the length of the text dependent
on the context it was being used, i.e in a newspa-
per or being read aloud.
These issues will be dealt with subsequent releases
of the software. The second and more thorough evalu-
ation will be carried out when the system is deployed.
5 Further Research
The current work on pollen forecasts is carried out as
part of RoadSafe2 a collaborative research project be-
tween University of Aberdeen and Aerospace and Ma-
rine International (UK) Ltd. The main objective of
the project is to automatically generate road mainte-
nance instructions to ensure efficient and correct ap-
plication of salt and grit to the roads during the win-
ter. The core requirement of this project is to describe
spatio-temporal data of detailed weather and road sur-
face temperature predictions textually. In a previous
1www.csd.abdn.ac.uk/?rturner/cgi bin/pollen.html
2www.csd.abdn.ac.uk/?rturner/RoadSafe/
research project SumTime (Sripada et al, 2003) we
have developed techniques for producing textual sum-
maries of time series data. In RoadSafe we plan to ex-
tend these techniques to generate textual descriptions
of spatio-temporal data. Because the spatio-temporal
weather prediction data used in road maintenance ap-
plications is normally of the order of a megabyte, we
initially studied pollen forecasts which are based on
smaller spatio-temporal data sets. We will apply the
various techniques we have learnt from the study of
pollen forecasts to the spatio-temporal data from the
road maintenance application.
6 Summary
Automatically generating spatio-temporal descriptions
involves two main subtasks. The first subtask focuses
on the spatio-temporal analysis of the input data to
extract information required by the different message
types identified in the corpus analysis. The second sub-
task is to find appropriate linguistic form for the spatial
location or region information.
References
S. Boyd. 1998. Trend: a system for generating in-
telligent descriptions of time-series data. In IEEE
International Conference on Intelligent Processing
Systems (ICIPS1998).
J. Coch. 1998. Multimeteo: multilingual production
of weather forecasts. ELRA Newsletter, 3(2).
M. Ester, A. Frommelt, H. Kriegel, and J. Sander.
1998. Algorithms for characterization and trend de-
tection in spatial databases. In KDD, pages 44?50.
S. Geldof. 2003. Corpus analysis for nlg. cite-
seer.ist.psu.edu/583403.html.
E. Goldberg, N. Driedger, and R. Kittredge. 1994. Us-
ing natural-language processing to produce weather
forecasts. IEEE Expert, 9(2):45?53.
H. J. Miller and J. Han. 2001. Geographic Data Min-
ing and Knowledge Discovery. Taylor and Francis.
E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge University
Press.
E. Reiter, S. Sripada, and R. Robertson. 2003. Ac-
quiring correct knowledge for natural language gen-
eration. Journal of Artificial Intelligence Research,
18:491?516.
D. Roy and E. Reiter. 2005. Connecting language to
the world. Artificial Intelligence, 167:1?12.
S. Sripada, E. Reiter, and I. Davy. 2003. Sumtime-
mousam: Configurable marine weather forecast gen-
erator. Expert Update, 6:4?10.
166
Proceedings of the 12th European Workshop on Natural Language Generation, pages 1?8,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Using NLG to Help Language-Impaired Users Tell Stories and  
Participate in Social Dialogues 
 
 
Ehud Reiter, Ross Turner 
University of Aberdeen 
Aberdeen, UK 
e.reiter@abdn.ac.uk 
csc272@abdn.ac.uk 
Norman Alm, Rolf Black, 
Martin Dempster, Annalu Waller 
University of Dundee 
Dundee, UK 
{nalm,rolfblack,martindempster, 
awaller}@computing.dundee.ac.uk 
 
 
Abstract 
Augmentative and Alternative Communication 
(AAC) systems are communication aids for 
people who cannot speak because of motor or 
cognitive impairments.  We are developing 
AAC systems where users select information 
they wish to communicate, and this is ex-
pressed using an NLG system.  We believe 
this model will work well in contexts where 
AAC users wish to go beyond simply making 
requests or answering questions, and have 
more complex communicative goals such as 
story-telling and social interaction. 
1 Introduction 
Many people have difficulty in communicating 
linguistically because of cognitive or motor im-
pairments.  Such people typically use communi-
cation aids to help them interact with other peo-
ple.  Such communication aids range from sim-
ple tools that do not involve computers, such as 
picture cards, to complex software systems that 
attempt to ?speak? for the impaired user. 
From a technological perspective, even the 
most complex communication aids have typi-
cally been based on fixed (canned) texts or sim-
ple fill-in-the-blank templates; essentially the 
user selects a text or template from a set of pos-
sible utterances, and the system utters it.  We 
believe that while this may be adequate if the 
user is simply making a request (e.g., please give 
me a drink) or answering a question (e.g., I live 
at home), it is not adequate if the user has a more 
complex communicative goal, such as engaging 
in social interaction, or telling a story. 
We are exploring the idea of supporting such 
interactions by building a system which uses ex-
ternal data and/or knowledge sources, plus do-
main and conversational models, to dynamically 
suggest possible messages (event, facts, or opin-
ions, represented as ontology instances) which 
are appropriate to the conversation. The user se-
lects the specific message which he wishes the 
system to speak, and possibly adds simple anno-
tations (e.g., I like this) or otherwise edits the 
message.  The system then creates an appropriate 
linguistic utterance from the selected message, 
taking into consideration contextual factors. 
In this paper we describe two projects on 
which we are working within this framework.  
The goal of the first project is to help non-
speaking children tell stories about their day at 
school to their parents; the goal of the second 
project is to help non-speaking adults engage in 
social conversation. 
2 Background 
2.1 Augmentative and alternative commu-
nication 
Augmentative and alternative communication 
(AAC) is a term that describes a variety of meth-
ods of communication for non-speaking people 
which can supplement or replace speech.  The 
term covers techniques which require no equip-
ment, such as sign language and cards with im-
ages; and also more technologically complex 
systems which use speech synthesis and a variety 
of strategies to create utterances.  
The most flexible AAC systems allow users to 
specify arbitrary words, but communication rates 
are extremely low, averaging 2-10 words per 
minute. This is because many AAC users interact 
slowly with computers because of their impair-
ments.  For example, some of the children we 
work with cannot use their hands, so they use 
scanning interfaces with head switches.  In other 
words, the computer displays a number of op-
1
tions to them, and then scans through these, 
briefly highlighting each option.  When the de-
sired option is highlighted, the child selects it by 
pressing a switch with her head.   This is ade-
quate for communicating basic needs (such as 
hunger or thirst); the computer can display a 
menu of possible needs, and the child can select 
one of the items.  But creating arbitrary messages 
with such an interface is extremely slow, even if 
word prediction is used; and in general such in-
terfaces do not well support complex social in-
teractions such as story telling (Waller, 2006).  
A number of research projects in AAC have 
developed prototype systems which attempt to 
facilitate this type of human-human interaction.  
At their most basic, these systems provide users 
with a library of fixed ?conversational moves? 
which can be selected and uttered.  These moves 
are based on models of the usual shape and con-
tent of conversational encounters (Todman & 
Alm, 2003), and for example include standard 
conversational openings and closings, such as 
Hello and How are you. They also include back-
channel communication such as Uh-huh, Great!, 
and Sorry, can you repeat that. 
It would be very useful to go beyond standard 
openings, closings, and backchannel messages, 
and allow the user to select utterances which 
were relevant to the particular communicative 
context and goals.  Dye et al(1998) developed a 
system based on scripts of common interactions 
(Schank & Abelson, 1977).  For example, a user 
could activate the MakeAnAppointment script, 
and then could select utterances relevant to this 
script, such as I would like to make an appoint-
ment to see the doctor.  As the interaction pro-
gressed, the system would update the selections 
offered to the user based on the current stage of 
the script; for example during time negotiation a 
possible utterance would be I would like to see 
him next week. This system proved effective in 
trials, but needed a large number of scripts to be 
generally effective.  Users could author their own 
texts, which were added to the scripts, but this 
was time-consuming and had to be done in ad-
vance of the conversation. 
Another goal of AAC is to help users narrate 
stories. Narrative and storytelling play a very 
important part in the communicative repertoire of 
all speakers (Schank, 1990). In particular, the 
ability to draw on episodes from one?s life his-
tory in current conversation is vital to maintain-
ing a full impression of one?s personality in deal-
ing with others (Polkinghorne, 1991). Story tell-
ing tools for AAC users have been developed, 
which include ways to introduce a story, tell it at 
the pace required (with diversions) and give 
feedback to comments from listeners (Waller, 
2006); but again these tools are based on a li-
brary of fixed texts and templates. 
2.2 NLG and AAC 
Natural language generation (NLG) systems 
generate texts in English and other human lan-
guages from non-linguistic input (Reiter and 
Dale, 2000).  In their review of NLP and AAC, 
Newell, Langer, and Hickey (1998) suggest that 
NLG could be used to generate complete utter-
ances from the limited input that AAC users are 
able to provide.  For example, the Compansion 
project (McCoy, Pennington, Badman 1998) 
used NLP and NLG techniques to expand tele-
graphic user input, such as Mary go store?, into 
complete utterances, such as Did Mary go to the 
store?  Netzer and Elhadad (2006) allowed users 
to author utterances in the symbolic language 
BLISS, and used NLG to translate this to English 
and Hebrew texts. 
In recent years there has been growing interest 
in data-to-text NLG systems (Reiter, 2007); 
these systems generate texts based on sensor and 
other numerical data, supplemented with ontolo-
gies that specify domain knowledge.  In princi-
ple, it seems that data-to-text techniques should 
allow NLG systems to provide more assistance 
than the syntactic help provided by Compansion.  
For example, if the user wanted to talk about a 
recent football (soccer) match, a data-to-text sys-
tem could get actual data about the match from 
the web, and generate potential utterances from 
this data, such as Arsenal beat Chelsea 2-1 and 
Van Persie scored two goals; the user could then 
select one of these to utter. 
In addition to helping users interact with other 
people, NLG techniques can also be used to edu-
cate and encourage children with disabilities.  
The STANDUP system (Manurung, Ritchie et 
al., 2008), for example, used NLG and computa-
tional humour techniques to allow children who 
use AAC devices to generate novel punning 
jokes.  This provided the children with successful 
experiences of controlling language, gave them 
an opportunity to play with language and explore 
new vocabulary (Waller et al, in press). In a 
small study with nine children with cerebral 
palsy, the children used their regular AAC tools 
more and also performed better on a test measur-
ing linguistic abilities after they used STANDUP 
for ten weeks. 
2
3 Our Architecture 
Our goal is help AAC users engage in com-
plex social interaction by using NLG and data-
to-text technology to create potential utterances 
and conversational contributions for the users. 
The general architecture is shown in Figure 1, 
and Sections 4 and 5 describe two systems based 
on this architecture. 
 
 
The system has the following components: 
Data analysis: read in data, from sensors, 
web information sources, databases, and so forth.  
This module analyses this data and identifies 
messages (in the sense of Reiter and Dale 
(2000)) that the user is likely to want to commu-
nicate; this analysis is partially based on domain, 
conversation, and user models, which may be 
represented as ontologies. 
Editing: allow the user to edit the messages.  
Editing ranges from adding simple annotations to 
specify opinions (e.g., add BAD to Arsenal beat 
Chelsea 2-1 if the user is a Chelsea fan), to using 
an on-screen keyboard to type free-text com-
ments.  Users can also delete messages, specify 
which messages they are most likely to want to 
utter, and create new messages.  Editing is done 
before the actual conversation, so the user does 
not have to do this under time pressure.  The 
amount of editing which can be done partially 
depends on the extent of the user?s disabilities. 
Narration: allows the user to select mes-
sages, and perhaps conversational moves (e.g., 
Hello), in an actual conversational context.  Edit-
ing is possible, but is limited by the need to keep 
the conversation flowing. 
NLG and Speech Synthesis: Generates actual 
utterances from the selected messages, taking 
into account linguistic context, especially a dia-
logue model. 
4 Narrative for Children: How was 
School Today 
The goal of the How was School Today project is 
to enable non-speaking children with major mo-
tor disabilities but reasonable cognitive skills to 
tell a story about what they did at school during 
the day.  The particular children we are working 
with have cerebral palsy, and use wheelchairs.  A 
few of them can use touch screens, but most of 
them use a head switch and scanning interface, 
as described above.  By ?story?, we mean some-
thing similar to Labov?s (1972) conversational 
narrative, i.e., a series of linked real-world events 
which are unusual or otherwise interesting, pos-
sibly annotated with information about the 
child?s feelings, which can be narrated orally. 
We are not expecting stories in the literary sense, 
with character development and complex plots. 
The motivation of the project is to provide the 
children with successful narrative experience. 
Typically developing children develop narrative 
skills from an early age with adults scaffolding 
conversations to elicit narrative, e.g. ?What did 
you do at school today?? (Bruner, 1975). As the 
child?s vocabulary and language competence 
develops, scaffolding is reduced. This progres-
sion is seldom seen in children with complex 
communication needs ? they respond to closed 
questions but seldom take control of conversa-
Sensor 
data 
Web info 
sources 
Other 
external data 
Data analysis: 
select possible 
messages to 
communicate 
Conversation 
model 
Domain model 
User model 
Editing: User adds 
annotations 
User 
 
NLG: 
Generate 
utterance 
Dialogue 
model 
Speech 
synthesis 
Conversation 
partner 
 
Narration: User 
selects what to say 
Prepare content 
Narrate content 
Figure 1:  General architecture 
3
tion (von Tetzchner and Grove, 2003).  Many 
children who use AAC have very limited narra-
tive skills (Soto et al 2006). Research has shown 
that providing children who use AAC with suc-
cessful narrative experiences by providing full 
narrative text can help the development of writ-
ten and spoken narrative skills  (Waller, 2008).  
The system follows the architecture described 
above.  Input data comes from RFID sensors that 
track where the child went during the day; an 
RFID reader is mounted on the child?s wheel-
chair, and RFID tags are placed around the 
school, especially in doorways so we can moni-
tor children entering and leaving rooms.  Teach-
ers have also been given RFID swipe cards 
which they can swipe against a reader, to record 
that they are interacting with the child; this is 
more robust than attempting to infer interaction 
automatically by tracking teachers? position. 
Teachers can also record interactions with ob-
jects (toys, musical instruments, etc), by using 
special swipe cards associated with these objects. 
Last but not least, teachers can record spoken 
messages about what happened during the day. 
An example of how the child?s wheelchair is set 
up is shown in Figure 2. 
   
 
 
Figure 2: System configuration 
 
The data analysis module combines sensor-
derived location and interaction data with a time-
table which records what the child was expected 
to do during the day, and a domain knowledge 
base which includes information about typical 
activities (e.g., if the child?s location is Swim-
mingPool, the child?s activity is probably 
Swimming).  From this it creates a series of 
events (each of which contain a number of mes-
sages) which describe the child?s lessons and 
activities, including divergences from what is 
expected in the timetable.  Several messages may 
be associated with an event.  The data analysis 
module also infers which events and messages it 
believes are most interesting to the child; this is 
partially based on heuristics about what children 
are interested in (e.g., swimming is more inter-
esting than lunch), and partially based on the 
general principle that unexpected things (diver-
gences from the timetable) are more interesting 
than expected things.  No more than five events 
are flagged as interesting, and only these events 
are shown in the editing interface. 
The editing interface allows children to re-
move events they do not want to talk about (per-
haps for privacy reasons) from the list of interest-
ing events.  It also allows children to add mes-
sages that express simple opinions about events; 
i.e., I liked it or I didn?t like it.  The interface is 
designed to be used with a scanning interface, 
and is based on symbols that represent events, 
annotations, etc. 
The narration interface, shown in Figure 3, is 
similar to the editing interface. It allows children 
to choose a specific event to communicate, 
which must be one of the ones they selected dur-
ing the editing phase.  Children are encouraged 
to tell events in temporal order (this is one of the 
narration skills we are trying to teach), but this is 
not mandated, and they can deviate from tempo-
ral order if they wish.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    Figure 3: Narration Interface 
 
The NLG system generates actual texts from 
the events selected by the children.  Most of this 
Tablet PC with NLG system and 
swipe-card RFID sensor  
long range 
RFID  
sensor for 
location 
tracking 
Events 
Opinion Annotations 
Messages  
for event 
4
is fairly simple, since the system deliberately 
uses simple ?child-like? language (Section 6).  
However, the system does need to make some 
decisions based on discourse context, including 
choosing appropriate referring expressions (es-
pecially pronouns), and temporal expressions 
(especially when children deviate from pure 
temporal order). 
4.1 Example 
For example, assume that the timetable speci-
fies the following information 
 
 
Assume that the sensors then recorded the fol-
lowing information 
 
Event 1 
      Location: CL_SEC2 
      Time: 13:23:00.0 - 14:07:00.0 
      Interactions: Mrs. Smith, Rolf, Ross 
 
Event 2 
      Location: HALL 
      Time: 14:10:00.0 ? 14:39:00.0 
      Interactions: none 
 
The data analysis module associates Event 1 with 
the Arts and Crafts timetable entry, since the lo-
cation is right, the timetabled teacher is present, 
and the times approximately match.  From this 
two messages are produced: one corresponding 
to I had Arts and Crafts this afternoon with Mrs. 
Smith (the core activity description), and the oth-
er corresponding to Rolf and Ross were there 
(additional information about people not time-
tabled to be there).  The child can add opinions 
using the editing interface; for example, if he 
added a positive annotation to the event, this 
would become an additional message corre-
sponding to It was great. 
For Event 2, the data analysis module notes 
that it does not match a timetabled event. The 
timetable indicates the child should be at Physio-
therapy after Art and Crafts; however, the sensor 
information indicates they were in the hall. The 
system generates a single message corresponding 
to Then I went to the Hall instead of Physiother-
apy to describe this event.  If the child added a 
negative annotation to this message, this would 
become an additional message expressed as I 
didn?t like it. 
4.2 Evaluation 
We conducted an initial evaluation of the How 
was School Today system in January, 2009.  
Two children used the system for four days: Ju-
lie, age 11, who had good cognitive skills but 
was non-verbal because of severe motor impair-
ments; and Jessica, age 13, who had less severe 
motor impairments but who had some cognitive 
and memory impairments (these are not the chil-
drens? real names).  Julie used the system as a 
communication and interaction aid, as described 
above; Jessica used the system partially as a 
memory aid.  The evaluation was primarily 
qualitative: we observed how Julie and Jessica 
used the system, and interviewed their teachers, 
speech therapists, care assistants, and Julie?s 
mother (Jessica?s parents were not available). 
The system worked very well for Julie; she 
learned it quickly, and was able to use it to have 
real conversations about her day with adults, al-
most for the first time in her life.  This validated 
our vision that our technology could help AAC 
users engage in real interaction, and go beyond 
simple question answering and communication 
of basic needs.  The system also worked rea-
sonably well as a memory aid for Jessica, but she 
had a harder time using it, perhaps because of her 
cognitive impairments. 
Staff and Julie?s mother were very supportive 
and pleased with the system.  They had sugges-
tions for improving the system, including a wider 
range of annotations; more phrases about the 
conversation itself, such as Guess what happened 
at school today; and allowing children to request 
teenager language (e.g., really cool). 
From a technical perspective, the system 
worked well overall.   School staff were happy to 
use the swipe cards, which worked well.  There 
were some problems with the location sensors, 
we need better techniques for distinguishing real 
readings from noise.  A surprising amount of 
effort was needed to enter up-to-date knowledge 
(e.g., daily lunch menus), this would need to be 
addressed if the system was used for a period of 
months as opposed to days. 
5 Social Conversation for Adults 
In our second project, we want to build a tool to 
help adults with cerebral palsy engage in social 
conversation about a football match, movie, 
weather, and so forth.  Many people with severe 
disabilities have great difficulty developing new 
interpersonal relationships, and indeed report that 
forming new relationships and taking part in new 
Time Activity Location Teacher 
?? ?? ?? ?? 
13.20 -14 Arts and 
Crafts 
CL_SEC2 Mrs Smith 
14 -14.40 Physiotherapy PHYSIO1 Mrs Jones 
?? ?? ?? ?? 
5
activities are major priorities in their lives (Datil-
lo et al, 2007).  Supporting these goals through 
the development of appropriate technologies is 
important as it could lead to improved social out-
comes. 
This project builds on the TALK system 
(Todman and Alm, 2003), which helped AAC 
users engage in active social conversation. 
TALK partially overcame the problem of low 
communication rate by requiring users to pre-
author their conversational material ahead of 
time, so that when it was needed it could simply 
be selected and output. TALK also used insights 
from Conversation Analysis (Sacks, 1995) to 
provide appropriate functionality in the system 
for social conversation. For example, it sup-
ported opening and closing statements, stepwise 
topic change, and the use of quick-fire utterances 
to provide fast, idiomatic responses to commonly 
encountered situations. This approach led to 
more dynamic AAC-facilitated interactions with 
higher communication rates, and had a positive 
impact on the perceived communicative compe-
tence of the user (Todman, Alm et al, 2007).   
TALK requires the user to spend a substantial 
amount of time pre-authoring material; this is 
perhaps its greatest weakness.  Our idea is to re-
duce the amount of pre-authoring needed, by us-
ing the architecture shown in Fig 1, where much 
of the material is automatically created from data 
sources, ontologies, etc, and the user?s role is 
largely to edit and annotate this material, not to 
create it from scratch. 
We developed an initial prototype system to 
demonstrate this concept in the domain of foot-
ball results (Dempster, 2008).  We are now 
working on another prototype, whose goal is to 
support social conversations about movies, mu-
sic, television shows, etc (which is a much 
broader domain than football).  We have created 
an ontology which can describe events such as 
watching a film, listening to a music track, or 
reading a book.  Each ?event? has both temporal 
and spatial properties which allow descriptions to 
be produced about where and when an event took 
place, and other particulars relating to that par-
ticular class of event.  For example, if the user 
listened to a radio show, we record the name of 
the show, the presenter and the station it was 
broadcast on.  Ultimately we plan to obtain in-
formation about movies, music tracks, etc from 
web-based databases such as IMDB (movies) 
and last.fm (music). 
Of course, databases such as IMDB do not 
contain information such as what the user 
thought of the movie, or who he saw it with.  
Hence we will allow users to add annotations 
with such information.  Some of these annota-
tions will be entered via a structured tool, such as 
a calendar interface that allows users to specify 
when they watched or listened to something. We 
would like to use NaturalOWL (Galanis and An-
droutsopoulos, 2007) as the NLG component of 
the system; it is well suited to describing objects, 
and is intended to be integrated with an ontology.  
As with the How Was School Today project, 
some of the main low-level NLG challenges are 
choosing appropriate referring expressions and 
temporal references, based on the current dis-
course context.  Speech output is done using Ce-
reproc (Aylett and Pidcock, 2007). 
An example of our current narration interface 
is shown in Figure 4.  In the editing interface, the 
user has specified that he went to a concert at 
8pm on Thursday, and that he rated it 8 out of 
10.  The narration interface gives the user a 
choice of a number of messages based on this 
information, together with some standard mes-
sages such as Thanks and Agree. 
 
 
 
Note that unlike the How Was School Today 
project, in this project we do not attempt to infer 
event information from sensors, but we allow 
(and expect) the user to enter much more infor-
mation at the editing stage.  We could in princi-
ple use sensors to pick up some information, 
such as the fact that the user was in the cinema 
from 12 to 2PM on Tuesday, but this is not the 
research focus of this project. 
We plan to evaluate the system using groups 
of both disabled and non-disabled users.  This 
has been shown in the past to be an effective ap-
proach for the evaluation of prototype AAC sys-
tems (Higginbotham, 1995). Initially pairs of 
non-disabled participants will be asked to pro-
duce short conversations with one person using 
the prototype and the other conversing normally.   
Quantitative measures of the communication rate 
6
will be taken as well as more qualitative observa-
tions relating to the usability of the system.  Af-
ter this evaluation we will improve the system 
based on our findings, and then conduct a final 
evaluation with a small group of AAC users. 
6 Discussion: Challenges for NLG 
From an NLG perspective, generating AAC texts 
of the sort we describe here presents different 
challenges from many other NLG applications. 
First of all, realization and even microplanning 
are probably not difficult, because in this context 
the AAC system should generate short simple 
sentences if possible.  This is because the system 
is speaking ?for? someone with limited or devel-
oping linguistic abilities, and it should try to pro-
duce something similar to what the user would 
say himself if he or she had the time to explicitly 
write a text using an on-screen keyboard. 
To take a concrete example, we had originally 
considered using past-perfect tense (a fairly 
complex linguistic construct) in the How was 
School project, when the narrative jumped to an 
earlier point in time.  For example I ate lunch at 
12.  I had gone swimming at 11.  But it was clear 
from corpora of child-written texts that these 
children never used perfect tenses, so instead we 
opted for I ate lunch at 12.  I went swimming at 
11.  This is less linguistically polished, but much 
more in line with what the children might actu-
ally produce. 
Given this desire for linguistic simplicity, re-
alisation is very simple, as is lexical choice (use 
simple words) and aggregation (keep sentences 
short).  The main microplanning challenges re-
late to discourse coherence, in particular refer-
ring expressions and temporal descriptions.   
On the other hand, there are major challenges 
in document planning.  In particular, in the How 
Was School project, we want the output to be a 
proper narrative, in the sense of Labov (1972).  
That is, not just a list of facts and events, but a 
structure with a beginning and end, and with ex-
planatory and other links between components 
(e.g., I had math in the afternoon because we 
went swimming in the morning, if the child nor-
mally has math in the morning).  We also wanted 
the narrative to be interesting and hold the inter-
est of the person the child is communicating 
with.  As pointed out by Reiter et al(2008), cur-
rent NLG systems do not do a good job of gener-
ating narratives.  
Similarly, in the Social Conversations project 
we want the system to generate a social dialogue, 
not just a list of facts about movies and songs.  
Little previous research has been done on gener-
ating social (as opposed to task-oriented) dia-
logues.  One exception is the NECA Socialite 
system (van Deemter et al 2008), but this fo-
cused on techniques for expressing affect, not on 
high-level conversational structure. 
For both stories and social conversations, it 
would be extremely useful to be able to monitor 
what the conversational partner is saying.  This is 
something we hope to investigate in the future.  
As most AAC users interact with a small number 
of conversational partners, it may be feasible to 
use a speech dictation system to detect at least 
some of what the conversational partner says. 
Last but not least, a major challenge implicit 
in our systems and indeed in the general architec-
ture is letting users control the NLG system.   
Our systems are intended to be speaking aids, 
ideally they should produce the same utterances 
as the user would if he was able to talk.  This 
means that users must be able to control the sys-
tems, so that it does what they want it to do, in 
terms of both content and expression.  To the 
best of our knowledge, little is known about how 
users can best control an NLG system. 
7 Conclusion 
Many people are in the unfortunate position of 
not being able to speak or type, due to cognitive 
and/or motor impairments.  Current AAC tools 
allow such people to engage in simple needs-
based communication, but they do not provide 
good support for richer use of language, such as 
story-telling and social conversation.  We are 
trying to develop more sophisticated AAC tools 
which support such interactions, by using exter-
nal data and knowledge sources to produce can-
didate messages, which can be expressed using 
NLG and speech synthesis technology.  Our 
work is still at an early stage, but we believe that 
it has the potential to help AAC users engage in 
richer interactions with other people.  
Acknowledgements 
We are very grateful to Julie, Jessica, and their 
teachers, therapists, carers, and parents for their 
help in building and evaluating the system de-
scribed in Section 4.  Many thanks to the anony-
mous referees and our colleagues at Aberdeen 
and Dundee for their very helpful comments.  
This research is supported by EPSRC grants 
EP/F067151/1 and EP/F066880/1, and by a 
Northern Research Partnership studentship. 
7
References 
Aylett, M. and C. Pidcock (2007). The CereVoice 
Characterful Speech Synthesiser SDK. Proceed-
ings of Proceedings of the 7th International Con-
ference on Intelligent Virtual Agents, pages 413-
414. 
Bruner, J. (1975). From communication to language: 
A psychological perspective. Cognition 3: 255-
289. 
Datillo, J., G. Estrella, L. Estrella, J. Light, D. 
McNaughton and M. Seabury (2007). "I have cho-
sen to live life abundantly": Perceptions of leisure 
by adults who use Augmentative and Alternative 
Communication. Augmentative & Alternative 
Communication 24(1): 16-28. 
van Deemter, K., B Krenn, P Piwek, M Klesen, M 
Schr?der and S Baumann. Fully generated scripted 
dialogue for embodied agents. Artificial Intelli-
gence 172: 1219?1244. 
Dempster, M. (2008). Using natural language genera-
tion to encourage effective communication in non-
speaking people. Proceedings of Young Research-
ers Consortium, ICCHP'08. 
Dye, R., N. Alm, J. Arnott, G. Harper, and A. Morri-
son (1998). A script-based AAC system for trans-
actional interaction.  Natural Language Engineer-
ing, 4(1), 57-71. 
Galanis, D. and I. Androutsopoulos (2007). Generat-
ing Multilingual Descriptions from Linguistically 
Annotated OWL Ontologies: the NaturalOWL Sys-
tem. Proceedings of ENLG 2007. 
Higginbotham, D. J. (1995). Use of nondisabled sub-
jects in AAC Research : Confessions of a research 
infidel. Augmentative and Alternative Communica-
tion 11(1): 2-5. 
Labov, W (1972).  Language in the Inner City. Uni-
versity of Pennsylvania Press. 
Manurung, R., G. Ritchie, H. Pain, A. Waller, D. 
O'Mara and R. Black (2008). The Construction of a 
Pun Generator for Language Skills Development. 
Applied Artificial Intelligence 22(9): 841 ? 869. 
McCoy, K., C. Pennington and A. Badman (1998). 
Compansion: From research prototype to practical 
integration. Natural Language Engineering 4:73-
95. 
Netzer, Y and Elhadad, M (2006). Using Semantic 
Authoring for Blissymbols Communication 
Boards. In Proc of HLT-2006. 
Newell, A., S. Langer and M. Hickey (1998). The role 
of natural language processing in alternative and 
augmentative communication. Natural Language 
Engineering 4:1-16. 
Polkinghorne, D. (1991). Narrative and self-concept. 
Journal of Narrative and Life History, 1(2/3), 135-
153 
Reiter, E (2007). An Architecture for Data-to-Text 
Systems. In Proceedings of ENLG-2007, pages 
147-155. 
Reiter, E. and R. Dale (2000).  Building Natural Lan-
guage Generation Systems.  Cambridge University 
Press. 
Reiter, E,  A. Gatt, F Portet, and M van der Meulen 
(2008). The Importance of Narrative and Other 
Lessons from an Evaluation of an NLG System 
that Summarises Clinical Data (2007). In Proceed-
ings of INLG-2008, pages 97-104. 
Sacks, H. (1995). Lectures on Conversation. G. Jef-
ferson. Cambridge, MA, Blackwell. 
Schank, R. C. (1990). Tell me a story: A new look at 
real and artificial intelligence. New York, Macmil-
lan Publishing Co. 
Schank, R., and R. Abelson (1977).  Scripts, plans, 
goals, and understanding. New Jersey: Lawrence 
Erlbaum. 
Soto, G., E. Hartmann, and D. Wilkins (2006). Ex-
ploring the Elements of Narrative that Emerge in 
the Interactions between an 8-Year-Old Child who 
uses an AAC Device and her Teacher. Augmenta-
tive and Alternative Communication 4:231 ? 241. 
Todman, J. and N. A. Alm (2003). Modelling conver-
sational pragmatics in communication aids. Jour-
nal of Pragmatics 35: 523-538. 
Todman, J., N. A. Alm, D. J. Higginbotham and P. 
File (2007). Whole Utterance Approaches in AAC. 
Augmentative and Alternative Communication 
24(3): 235-254. 
von Tetzchner, S. and N. Grove (2003). The devel-
opment of alternative language forms. In S. von 
Tetzchner and N. Grove (eds), Augmentative and 
Alternative Communication: Developmental Issues, 
pages 1-27. Wiley. 
Waller, A. (2006). Communication Access to Conver-
sational Narrative. Topics in Language Disorders 
26(3): 221-239. 
Waller, A. (2008). Narrative-based Augmentative and 
Alternative Communication: From transactional to 
interactional conversation. Proceedings of ISAAC 
2008, pages 149-160.  
Waller, A., R. Black, D. A. O'Mara, H. Pain, G. Rit-
chie and R. Manurung (In Press). Evaluating the 
STANDUP Pun Generating Software with Chil-
dren with Cerebral Palsy. ACM Transactions on 
Accessible Computing. 
8
Proceedings of the 12th European Workshop on Natural Language Generation, pages 42?49,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Generating Approximate Geographic Descriptions
Ross Turner, Yaji Sripada and Ehud Reiter
Dept of Computing Science,
University of Aberdeen, UK
{r.turner,yaji.sripada,e.reiter}@abdn.ac.uk
Abstract
Georeferenced data sets are often large and
complex. Natural Language Generation
(NLG) systems are beginning to emerge that
generate texts from such data. One of the
challenges these systems face is the gener-
ation of geographic descriptions referring to
the location of events or patterns in the data.
Based on our studies in the domain of me-
teorology we present a two staged approach
to generating geographic descriptions. The
first stage involves using domain knowledge
based on the task context to select a frame
of reference, and the second involves using
constraints imposed by the end user to select
values within a frame of reference. Because
geographic concepts are inherently vague our
approach does not guarantee a distinguish-
ing description. Our evaluation studies show
that NLG systems, because they can analyse
input data exhaustively, can produce more
fine-grained geographic descriptions that are
more useful to end users than those generated
by human experts.
1 Introduction
Disciplines such as environmental studies, geography,
geology, planning and business marketing make exten-
sive use of Geographical Information Systems (GIS);
however, despite an explosion of available mapping
software, GIS remains a specialist tool with special-
ist skills required to analyse and understand the infor-
mation presented using map displays. Complement-
ing such displays with textual summaries therefore pro-
vides an immediate niche for NLG systems.
Recently, research into NLG systems that gener-
ate text from georeferenced data has begun to emerge
(Dale et al, 2005; Turner et al, 2006; Turner et al,
2008b; Thomas and Sripada, 2008). These systems are
required to textually describe the geographic distribu-
tion of domain variables such as road surface temper-
ature and unemployment rates. For example, descrip-
tions such as ?road surface temperatures will fall below
zero in some places in the southwest? and ?unemploy-
ment is highest in the rural areas? need to be generated
by these systems. One of the main challenges such sys-
tems face is the generation of geographic descriptions
such as ?in some places in the southwest? and ?in the
rural areas?. Such a task is challenging for a number of
reasons:
? many geographic concepts are inherently vague
(see for example (Varzi, 2001) for a discussion on
this topic);
? often the underlying data sets contain little explicit
geographic information for a generation system to
make use of (Turner et al, 2008b);
? as input to a generation system, georeferenced
data is often complex, constraints imposed on the
output text (such as length) may make the tradi-
tional approach to the Referring Expression Gen-
eration (REG) problem in NLG of finding a dis-
tinguishing description implausible (Turner et al,
2008b).
This paper looks at the problem in the context of
work the authors have carried out on summarising geo-
referenced data sets in the meteorology domain. The
main feature of our approach is that geographic de-
scriptions perform the dual function of referring to
a specific geographic locations unambiguously (tradi-
tional function of REG) and also communicate the re-
lationship between the domain information and the ge-
ography of the region (novel function of geographic de-
scriptions).
We present a two staged approach to generating ge-
ographic descriptions that involve regions. The first
stage involves using domain knowledge (meteorolog-
ical knowledge in our case) to select a frame of ref-
erence and the second involves using constraints im-
posed by the end user to select values within a frame
of reference. While generating geographic descriptions
it is not always possible to produce a distinguishing
description because of the inherent vagueness in ge-
ographic concepts. Therefore, in our case we aim to
produce a distinguishing description wherever possi-
ble, but more often allow non-distinguishing descrip-
tions in the output text, which approximate the location
of the event being described as accurately as possible.
After a short overview of the background in ?2,
some empirical observations on geographic descrip-
42
tions from knowledge acquisition (KA) studies we have
carried out are discussed in ?3. Taking these observa-
tions into account, in ?4 we describe how this problem
is approached using examples from RoadSafe (Turner
et al, 2008b), which generates spatial references to
events in georeferenced data in terms of regions that
approximate their location. It pays particular attention
to the use of different perspectives to describe the same
situation and how factors that affect what makes a good
reference in this domain are taken into account by the
system. In ?5 we present a qualitative discussion of as-
pects of geographic description from the evaluations of
RoadSafe that were carried out, and how this relates to
future possible work on this topic.
2 Background
Much work on generation of spatial descriptions has
concentrated on smaller scale spaces that are imme-
diately perceivable. For example, spatial descriptions
have been studied from the perspective of robot com-
munication (Kelleher and Kruijff, 2006), 3D anima-
tion (Towns et al, 1998) and basic visual scenes (Vi-
ethen and Dale, 2008; Ebert et al, 1996). In a more
geographical context route description generation sys-
tems such as (Dale et al, 2005) and (Moulin and Ket-
tani, 1999) have had wide appeal to NLG researchers.
(Varges, 2005) also generate landmark based spatial de-
scriptions using maps from the map task dialogue cor-
pus.
RoadSafe is an NLG system that has been opera-
tionally deployed at Aerospace and Marine Interna-
tional (AMI) to produce weather forecast texts for win-
ter road maintenance. It generates forecast texts de-
scribing various weather conditions on a road network
as shown in Figure 1.
The input to the system is a data set consisting of
numerical weather predictions (NWP) calculated over
a large set of point locations across a road network. An
example static snapshot of the input to RoadSafe for
one parameter is shown in Figure 2. The complete in-
put is a series of such snapshots for a number of param-
eters (see (Turner et al, 2008b) for details).
In applications such as RoadSafe, the same geo-
graphical situation can be expressed in a variety of dif-
ferent ways dependent upon the perspective employed,
henceforth termed as a frame of reference. Space (ge-
ographic or otherwise) is inherently tied to a frame of
reference that provides a framework for assigning dif-
ferent values to different locations in space. For ex-
ample, locations on Earth?s surface can be specified by
latitude and longitude which provide an absolute frame
of reference for geographic space. Cardinal directions
such as {North, East, West and South} provide an alter-
native frame of reference for geographic space. As was
noted in (Turner et al, 2008b), characterising the data
in terms of frames of reference is important because
often the only geographic information input data con-
tains are coordinates (latitude and longitude), while the
Overview: Road surface temperatures will fall
below zero on all routes during the late evening until
around midnight.
Wind (mph): NE 15-25 gusts 50-55 this afternoon
in most places, backing NNW and easing 10-20
tomorrow morning, gusts 30-35 during this evening
until tomorrow morning in areas above 200M.
Weather: Snow will affect all routes at first,
clearing at times then turning moderate during
tonight and the early morning in all areas, and
persisting until end of period. Ice will affect
all routes from the late evening until early morn-
ing. Hoar frost will affect some southwestern
and central routes by early morning. Road surface
temperatures will fall slowly during the evening
and tonight, reaching zero in some far southern
and southwestern places by 21:00. Fog will af-
fect some northeastern and southwestern routes dur-
ing tonight and the early morning, turning freezing
in some places above 400M.
Figure 1: RoadSafe forecast text showing geographic
descriptions underlined
output texts are required to employ a wider choice of
frames of reference such as altitude, direction, coastal
proximity and population. In RoadSafe the frames of
reference employed are always absolute according to
Levinson?s terminology (Levinson, 2003).
Because the geographic descriptions in RoadSafe do
not fit the traditional formulation of the REG problem
as finding the most distinguishing description, the most
pressing question to address is what makes an adequate
reference strategy in this case? This is of course a dif-
ficult question and is reliant to a large extent on the
communication goal of the system. This paper looks
into this problem in the context of the RoadSafe appli-
cation, that uses a simple spatial sublanguage to gener-
ate the types of descriptions required in this application
domain.
3 Observations on geographic
descriptions from the weather domain
In this section we summarise some empirical observa-
tions on how meteorologists use geographic descrip-
tions in weather forecasts. It describes work carried
out over the course of the RoadSafe project involving
knowledge acquisition (KA) studies with experts on
summarising georeferenced weather data, observations
from data-text corpora (one aimed at the general pub-
lic and one aimed at experts) and a small study with
people from the general public. During RoadSafe we
built two prototype georeferenced data-to-text systems
that summarised georeferenced weather data: one that
produces pollen forecasts based on very simple data
(Turner et al, 2006), and the RoadSafe system, which
43
Figure 2: Input data for ?reaching zero in some far southern and southwestern places? in Figure 1
generates road ice forecasts based on complex data.
Small corpora consisting of forecast texts and their un-
derlying NWP data were collected in both application
domains. Using techniques described in (Reiter et al,
2005) these corpora have been analysed to understand
the experts? strategies to describe georeferenced data.
The major finding from our studies is the fact that
experts tailor their geographic descriptions to the task
context. Not only does the geographic knowledge of
the end user have to be taken into account in their de-
scriptions, but also how the geography of the region
causes events and patterns in the data. The latter con-
sideration has a large affect on the frame of reference
experts employ to describe particular geographic situ-
ations. ?3.1 looks at these observations from the point
of view of end users of weather forecasts, while ?3.2
looks at the descriptive strategies of experts.
3.1 End users? geographic knowledge
It is a well known and accepted fact that geographic
knowledge varies greatly between individuals. To il-
lustrate this point 24 students of a further education
college in Scotland were asked a geography question,
without reference to a map. Which of four major place
names in Scotland (Ayr, Glasgow, Isle of Arran and
Stirling) did they consider to be in the south west of
the country? The responses showed a great variation
in the subjects? geographic knowledge. Half of all sub-
jects considered Glasgow and Ayr to be in the south
west, one third considered Stirling to be in the south
west and most surprisingly only four considered this to
be true of the Isle of Arran. The results of this study
are surprising because Stirling is the least south west-
erly place in the list while Isle of Arran is the most
south westerly. This study actually agrees well with
the studies in psychology on variation in individuals?
mental representation of their geographic environment
(Tversky, 1993).
Contrast this with the detailed knowledge of a road
engineer who the RoadSafe texts are intended for. Road
engineers rely upon a large amount of local geographic
knowledge and experience when treating roads. In-
deed, their spatial mental models are specified at a
much finer detail. For example, they get to know
where frost hollows tend to form and also come to learn
of particular unexpected black spots, such as where
garages allow hose water to cover part of a road during
winter. This is an important point to be taken into ac-
count when communicating georeferenced data as geo-
graphic descriptions should be sensitive to that knowl-
edge because it dictates how accurately they will be in-
terpreted by the end user.
Both task context and structural features of data (e.g.
number of observations, granularity of measurement),
as well as functional features of data (how the entities
being described function in space) influence how it is
44
described geographically. Analysis of a small pollen
forecast corpus (Turner et al, 2006) revealed that fore-
cast texts, contain a rich variety of spatial descrip-
tions for a location despite the data containing only six
data points for the whole of Scotland. In general, the
same region could be referred to by its proper name
e.g. Sutherland and Caithness, by its relation to a well
known geographical landmark e.g. North of the Great
Glen, or simply by its geographical location on the map
e.g. the far North and Northwest. In other words, ex-
perts characterise the limited geographic information
contained within the data according to the task context.
As the consumers of such forecasts are the general pub-
lic, there is a greater onus on the expert to make the
texts more interesting, unlike more restricted domains
such as marine (see (Reiter et al, 2005)) or road ice
forecasts that require consistent terminology.
3.2 Experts? descriptive strategy
Work in psychology has suggested that meteorologists
use a dynamic mental model to arrive at an inference to
predict and explain weather conditions (Trafton, 2007).
Vital to this process is also their ability to take into
account how the geography of a region influences the
general weather conditions. Understanding the weath-
ers interaction with the terrain enables them to make
reliable meteorological inferences particularly when a
certain pattern in the data may appear random. It is
often unfeasible for a human forecaster to spend large
amounts of time inspecting every data point in a de-
tailed visual display. Using experience and expertise a
forecaster can use her mental model to ?play out dif-
ferent hypothetical situations? (Trafton, 2007, p.2) and
thus arrive at a plausible explanation for an apparently
random weather pattern. Consider the following exam-
ple description of a weather event by an expert taken
from our road ice corpus:
? ?exposed locations may have gales at times.?
This is a good example of a forecaster using her me-
teorological expertise to make an inference about a ran-
dom weather pattern. Clearly there is no way from
inspection of a map one can ascertain with certainty
where the exposed locations are in a region. How-
ever, an expert?s knowledge of how the referent entity
(the wind parameter) is affected by geographical fea-
tures allow her to make such an inference. These prag-
matic factors play a large part in determining an experts
descriptive strategy, where certain frames of reference
may be considered more appropriate to describe certain
weather events (Turner et al, 2008a). This comes from
weather forecasters? explicit knowledge of spatial de-
pendence (the fact that observations points in georefer-
enced data at nearby locations are related, and the val-
ues of their non-spatial attributes will be influenced by
certain geographical features). This is one of the most
important and widely understood fact about spatial data
from an analysis point of view, and one of the main rea-
sons that it requires special treatment in comparison to
other types of non-spatial data. This fact is most clearly
outlined by an observation made in (Tobler, 1970, p.3)
that ?everything is related to everything else, but near
things are more related than distant things?. This is
commonly known as the first law of geography and still
resonates strongly today amongst geographers (Miller,
2004). The implication of Tobler?s first law (TFL) is
that samples in spatial data are not independent, and
observations located at nearby locations are more likely
to be similar. Recasting this into meteorological terms,
exposed locations are more likely to be windier and el-
evated areas colder for example.
In fact, an analogy can be drawn between how me-
teorologists consider perspectives in their descriptive
strategy and the preferred attribute list in the semi-
nal work on REG by (Dale and Reiter, 1995). In
their specification of an algorithm for generating refer-
ring expressions content selection is performed through
the iteration over a pre-determined and task specific
list of attributes. In our context, preferred attributes
are replaced by preferred frames of reference. This
means describing georeferenced data requires situa-
tional knowledge of when to apply a particular frame
of reference given a particular geographic distribution
to describe.
The most striking observation about the expert strat-
egy is that the geographic descriptions in the corpora
are approximations of the input (Turner et al, 2008a).
The input is highly overspecified with 1000s of points
for a small forecast region, sampled at sub hourly inter-
vals during a forecast period. Meteorologists use vague
descriptions in the texts to refer to weather events such
as:
? ?in some places in the south, temperatures will
drop to around zero or just above zero.?
There are a number of reasons they use this descrip-
tive strategy: the forecasts are highly compressed sum-
maries, as a few sentences describes megabytes of data;
very specific descriptions are avoided unless the pat-
tern in the data is very clear cut; experts try to avoid
misinterpretation, road engineers often have detailed
local geographic knowledge and experts may not be
aware the more provincial terminology they use to refer
to specific areas. The following section demonstrates
how the problem of generating such descriptions is ad-
dressed in RoadSafe.
4 Generating Approximate Geographic
Descriptions
In its current form, where summaries are meant to give
a brief synopsis of conditions to the user, RoadSafe
follows the approach taken by forecasters as discussed
previously. This is unconventional in comparison to
traditional REG approaches that aim to rule out all dis-
tractors in the domain (properties that are not true of
the referent). In a description such as ?reaching zero
45
in some places above 100M by 16:00? above, distrac-
tors can be defined as the set of points above 100M that
do not satisfy the premise that temperatures will drop
below zero. More succinctly, these can be defined as
false positives. In fact, the problem can be formulated
as a trade off between false positives and false nega-
tives, where false negatives constitute points that are
wrongly omitted from the description. For road grit-
ting purposes, costs can be assigned to each type of
error: road accidents in the case of false negatives and
wasted salt in the case of false positives. As the task
dictates, with the higher associated cost it is impera-
tive that a referring expression eliminates all false neg-
atives. Ideally a truly optimal description should then
seek to minimise false positives as far as possible, thus
reducing the overall cost for the reader. While reduc-
ing errors descriptions should also be meteorologically
correct, as discussed in the previous section. Using cer-
tain frames of reference in certain contexts may result
in a poor inference about a particular weather situation
(Turner et al, 2008b).
Given this domain knowledge, we can formulate
constraints for what makes a good approximate geo-
graphic description in this task context:
1. Meteorological correctness (inferencing about
causal relationships).
2. Minimise false positives.
3. Complete coverage of the event being described
(no false negatives).
These constraints have been realized in a two staged
approach to generating geographic descriptions. The
first stage involves using domain knowledge (meteo-
rological knowledge in our case) to select a frame of
reference, while the second accounts for end-user con-
straints to select values within that frame of reference.
Before we describe the individual stages, two necessary
pre-processing stages for generation are described.
4.1 Geographic characterisation
As noted in ?2, observations in georeferenced data of-
ten contain little explicit geographic information apart
from their coordinates. Geographic characterisation is
responsible for assigning a set of qualitative descrip-
tors to each observation based upon a set of reference
frames, such that observations can be collectively dis-
tinguished from each other. This provides both a cri-
terion for partitioning the data, and a set of properties
to generate geographic descriptions. A frame of ref-
erence in this context consists of a set of descriptions
based upon a common theme such as coastal proximity
e.g. {inland,coastal} or population e.g. {urban,rural}.
In RoadSafe four frames of reference have been imple-
mented: altitude, coastal proximity, population and di-
rection. Those that make use of human (population)
and physical geographical features (altitude, coastal
Proximity) can be represented by existing GIS data
sets; therefore, in these cases geographic characterisa-
tion is simply responsible for mapping observation co-
ordinates to areas of these data sets. In contrast, direc-
tions are abstract and require definition. In RoadSafe,
geographic characterisation maps each observation to a
set of directional areas with crisp boundaries, described
in the following section.
4.2 Pattern formation
To generate descriptions, the geographic distribution
of the event to be communicated has to be approxi-
mated using data analysis techniques such as cluster-
ing. While not new to data-to-text systems, the novel
aspect here is that the data is partitioned based upon
the frames of reference that make up the spatial sublan-
guage of the system. This process summarises the lo-
cation of the event by measuring its density within each
frame of reference?s set of descriptions. An example of
such a distribution is shown in Figure 3.
Reference Frame Description Proportion
Altitude
100M 0.033
200M: 0.017
300M 0.095
400M 0.042
Direction
SSE 0.037
SSW 0.014
WSW: 0.048
TSE 0.489
TSW 0.444
Population
Rural: 0.039
Figure 3: Density of zero temperatures in Figure 2
While the descriptions within each frame of refer-
ence with human and geographical features are dictated
by the granularity of available GIS data sets (altitude
resolution for example), the boundaries of directional
areas require definition. In RoadSafe, because some
flexibility in the generated geographic descriptions is
desirable, the system uses a four by four grid to split
the domain into sixteen equally sized directional areas
defined by their their latitude longitude extents. This
configuration is shown below where T stands for true
and C for central in this case:
TNW NNW NNE TNE
WNW CNW CNE ENE
WSW CSW CSE ESE
TSW SSW SSE TSE
Using a simple set of adjacency matrices based on
this grid, RoadSafe represents a set of descriptions de-
picting the traditional eight main points of the compass
plus a further five that we term gradable (central, far
south, far north, far east and far west). Alternative con-
46
figurations using a greater number of gradable descrip-
tions are possible. These matrices are used by the mi-
croplanner to choose attributes to refer to events using
the direction frame of reference. One example matrix
for each category of directional description are listed
below. In each matrix a value of 1 indicates that the
event has a non-zero density in that area.
Gradable
? Far South:
{TSW,SSW,SSE, TSE} =
?
??
0 0 0 0
0 0 0 0
0 0 0 0
1 1 1 1
?
??
Intercardinal
? South West:
{TSW,WSW,SSW,CSW} =
?
??
0 0 0 0
0 0 0 0
1 1 0 0
1 1 0 0
?
??
Cardinal
? South:
SouthEast ? SouthWest =
?
??
0 0 0 0
0 0 0 0
1 1 1 1
1 1 1 1
?
??
In what follows we describe how our two stage strat-
egy is implemented in our system.
4.3 Frame of reference selection
The main content selection decision made by the doc-
ument planner is the choice of which frame of refer-
ence to describe a specific weather event such as wind
gusts increasing or road surface temperature falling be-
low zero. This decision is based upon both the location
of the event as discussed previously, and situational
knowledge stored in the knowledge base of the system.
Frames of reference where all descriptions have non-
zero densities are not considered. Situational knowl-
edge consists of the probability of using each frame of
reference given the context (the weather parameter to
describe), and is based on corpus frequencies. Rather
than simply choosing the frame of reference with the
highest density, weighting each frame of reference in
this way ensures meteorological correctness as far as
possible.
4.4 Attribute selection
Once a frame of reference has been selected the mi-
croplanner maps the descriptions to abstract syntax
templates. As this is fairly trivial for most frames of
reference in RoadSafe, because they contain a limited
number of descriptions, we will provide an example
how this is accomplished for directional descriptions.
The input to the microplanner is a structure comprised
of the density of the event within the containing area
plus its associated adjacency matrix as shown in Figure
4.
Location {Pointratio : 0.21
Relation : in
Container :
?
???
0 0 0 0
0 0 0 0
1 0 0 0
1 1 1 1
?
???
}
Figure 4: REG input to describe Figure 2
The attribute selection algorithm is based upon four
constraints incorporating the first two principles of the
descriptive strategy outlined at the beginning of this
section. They are:
1. Minimise false positives - The description de-
scribing the distribution should introduce the least
number of distractors. For the above example distri-
bution the set {South} ensures coverage but introduces
three distractors: CSW, CSE and ESE. While the set
of directions {Far South, South West} only introduces
one: CSW. In general, a measure of how distinguishing
a description x is of a distribution y is given by:
distinguishing(x, y) = |x ? y||x|
Thus, for a distribution z and descriptions x and y,
x is a more distinguishing description of z than y iff
distinguishing(x,z) > distinguishing(y,z).
2. Coverage (no false negatives) - The descrip-
tion should completely describe the distribution. The
set of directions {Far South,South West} completely
describes the above example distribution while {Far
South} does not. For the set of directions x and dis-
tribution y, the predicate covers(x, y) is true iff
|x ? y|
|y| = 1
3. Brevity - The set of directions should yield the
shortest description of the distribution. For the above
example distribution there is only one set of direc-
tions that ensures complete coverage. But when faced
with a choice for example {South} and {South West,
South East} brevity constraint favours {South}. In gen-
eral,the set x should be chosen over y because it is a
shorter description. For the distribution z and sets of
directions x, y with equal coverage of z, x is a shorter
description of z than y iff |x| < |y|.
4. Ordering: If two descriptions have equal cov-
erage, cardinality and are equally distinguishing for a
47
given distribution, a description is chosen based upon
a predefined preference ordering. Each type of prop-
erty is assigned a score: Cardinal = 3, Intercardinal =
2 and Gradeable = 1. Therefore, the set of directions
{Far South, South West} would be assigned a value of
3.
In classification terms, the first constraint can be con-
sidered as precision and the second as recall. The algo-
rithm firstly ranks each individual description in the set
described in ?4.2 according to the constraints outlined
above. If a single directional term cannot be used to de-
scribe the distribution it then incrementally tries to find
the highest ranking combination of directions that sat-
isfy the coverage constraint and do not cover the whole
region; otherwise, the algorithm terminates by return-
ing the empty set. So, for the example input provided
at the beginning of this section it would return the ab-
stract syntax template shown in Figure 4. Quantifiers
are selected by applying a simple threshold to the point
ratio (which is recalculated should distractors be intro-
duced): some = > 0, many = > 0.5, most = > 0.7.
This would be realised as ?in some far southern and
southwestern places?.
?
??????????????????????
Type: LocationSyntax
Head: | in |
Object:
?
?????????????????
Head: | place |
Features:
[
definite:false
plural:true
]
Quantifier: | some |
Modifier:
?
??????
Head: | and |
Coord1
[
Head: | southern |
Modifier: | far |
]
Coord2
[
Head | southwestern |
]
?
??????
?
?????????????????
?
??????????????????????
Figure 5: Phrase syntax for input in Figure 4
5 Evaluation and Discussion
RoadSafe has been evaluated in post-edit evaluations
with meteorologists at AMI and by asking potential
users to compare the quality of the summaries to corpus
texts based on the same data. While evaluations have
been intended to test the overall quality of the texts
we have received much feedback on the geographic de-
scriptions the system generates. We have also carried
out some comparison of the direction descriptions to
those in the corpus, by annotating the corpus descrip-
tions with our adjacency matrices and running them
through the system. Descriptions were compared by
calculating the Jaccard coefficient between the two ma-
trices. Overall the mean score was 0.53, with a fairly
low perfect recall percentage of 30%. The low pre-
cision score is perhaps not surprising as the descrip-
tions generated by RoadSafe are crisp and the corpus
descriptions are not solely based on the input data we
have available. However, the majority (67%) of par-
tial alignments were the result of RoadSafe producing
a subset of the human desciprition, e.g. northwest ver-
sus north, which indicates the system descriptions are
more fine grained. In terms of the human descriptions,
what was most apparent from this evaluation is the fact
that they almost exclusively used the eight major points
of the compass.
In terms of feedback experts have commented that
generally the location descriptions generated by the
system are accurate but should be more general. Of
97 post edited texts generated by the system 20% of
the geographic descriptions were edited.
Most notable was feedback from twenty one road
maintenance personnel, who participated in an exper-
iment asking them to compare expert written texts to
RoadSafe generated texts based on the same five data
sets. The details of this experiment are to be published
elsewhere; however, one of the main reasons they gave
for liking the style of the generated texts was because
they contained more geographic descriptions than the
corresponding human ones. The fact that a data-to-text
system can analyse every data point is an advantage. In
contrast experts have a huge amount of knowledge and
experience to draw upon and this reflects in their more
general and conservative approach in their geographic
descriptions. Perhaps one of their biggest criticisms
of the system as a whole is that it doesn?t do a good
job of generating geographic descriptions that involve
motion, such as ?a band of rain works east across the
area?. Indeed, this was the most edited type of gener-
ated phrase during the post-edit evaluation. There has
been little work to our knowledge on describing motion
in the NLG literature.
There are many aspects of the generation of geo-
graphic that haven?t been addressed in this paper and
warrant further exploration. Particularly at the con-
tent level, there is a need to consider how to account
for semantic composition effects caused by overlaying
frames of reference. Another question that arises is
when is it best to use an intensional rather than exten-
sional description. There is also the question of when
to use descriptions that involve relations or gradable
properties. These are all choices that a data-to-text sys-
tem can make that will affect how the summary is in-
terpreted.
6 Conclusions
This paper has described an approach for generating
approximate geographic descriptions involving regions
in the RoadSafe system, which is based on empirical
work carried out in the weather domain. Our strat-
egy takes into account constraints on what constitutes a
good reference in the application domain described, by
taking into account pragmatic factors imposed by both
the task context and the end user. What is most appar-
ent from our empirical studies is that geographic de-
scriptions describing georeferenced data are influenced
48
by not only by location but also task context. An im-
portant observation based on our evaluation studies is
that NLG systems by virtue of their ability to analyse
input data exhaustively can generate descriptions that
are more useful to end users than those generated by
human experts.
References
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the gricean maxims in the generation of re-
ferring expressions. Cognitive Science, 19:233?263.
R Dale, S Geldof, and J-P Prost. 2005. Using natu-
ral language generation in automatic route descrip-
tion. Journal of Research and Practice in Informa-
tion Technology, 37(1):89?105.
C. Ebert, D. Glatz, M. Jansche, R. Meyer-Klabunde,
and R. Porzel. 1996. From conceptualization to
formulation in generating spatial descriptions. In
U. Schmid, J. Krems, and F. Wysotzki, editors, Pro-
ceedings of the First European Workshop on Cogni-
tive Modeling, pages 235?241.
John D. Kelleher and Geert-Jan M. Kruijff. 2006. In-
cremental generation of spatial referring expressions
in situated dialog. In Proceedings of ACL06, pages
1041?1048.
S. Levinson. 2003. Spatial language. In Nadel L.,
editor, Encyclopedia of Cognitive Science, volume 4,
pages 131?137. Nature Publishing Group.
Harvey J. Miller. 2004. Tobler?s first law and spatial
analysis. Annals of the Association of American Ge-
ographers, 93(3),:574?594.
B. Moulin and D. Kettani. 1999. Route generation
and description using the notions of objects influence
area and spatial conceptual map. Spatial Cognition
and Computation, 1:227?259.
E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy.
2005. Choosing words in computer-generated
weather forecasts. In Artificial Intelligence, vol-
ume 67, pages 137?169.
Kavita E Thomas and Somayajulu Sripada. 2008.
What?s in a message? interpreting geo-referenced
data for the visually-impaired. In Proceedings of
INLG08.
Waldo Tobler. 1970. A computer movie simulating
urban growth in the detroit region. Economic Geog-
raphy, 46(2):234?240.
Stuart Towns, Charles Callaway, and James Lester.
1998. Generating coordinated natural language and
3D animations for complex spatial explanations. In
Proceedings of the Fifteenth National Conference on
Artificial Intelligence, pages 112?119, Madison, WI.
J. Gregory Trafton. 2007. Dynamic mental models in
weather forecasting. In Proceedings of the Human
Factors and Ergonomics Society 51st Annual Meet-
ing, pages 311?314.
R. Turner, S. Sripada, E. Reiter, and I. Davy. 2006.
Generating spatio-temporal descriptions in pollen
forecasts. EACL06 Companion Volume, pages 163?
166.
R. Turner, S. Sripada, E. Reiter, and I. Davy. 2008a.
Building a parallel spatio-temporal data-text cor-
pus for summary generation. In Proceedings of
the LREC2008 Workshop on Methodologies and
Resources for Processing Spatial Language, Mar-
rakech, Morocco.
R. Turner, S. Sripada, E. Reiter, and I Davy. 2008b.
Using spatial reference frames to generate grounded
textual summaries of georeferenced data. In Pro-
ceedings of INLG08.
B. Tversky. 1993. Cognitive maps, cognitive col-
lages, and spatial mental models. In A.U. Frank
and I. Campari, editors, Spatial Information Theory,
pages 14?24. Springer-Verlag, Berlin.
Sebastian Varges. 2005. Spatial descriptions as refer-
ring expressions in the maptask domain. In ENLG-
05, Aberdeen, UK.
Achille C. Varzi. 2001. Vagueness in geography. Phi-
losophy & Geography, 4:1:4965.
Jette Viethen and Robert Dale. 2008. The use of spatial
relations in referring expressions. In Proceedings of
INLG08, Salt Fork, Ohio, USA.
49
Using Spatial Reference Frames to Generate Grounded Textual
Summaries of Georeferenced Data
Ross Turner, Somayajulu Sripada and Ehud Reiter
Dept of Computing Science,
University of Aberdeen, UK
{rturner,ssripada,ereiter}@csd.abdn.ac.uk
Ian P Davy
Aerospace and Marine Intl.,
Banchory, Aberdeenshire, UK
idavy@weather3000.com
Abstract
Summarising georeferenced (can be iden-
tified according to it?s location) data in
natural language is challenging because it
requires linking events describing its non-
geographic attributes to their underlying
geography. This mapping is not straightfor-
ward as often the only explicit geographic
information such data contains is latitude
and longitude. In this paper we present an
approach to generating textual summaries
of georeferenced data based on spatial ref-
erence frames. This approach has been im-
plemented in a data-to-text system we have
deployed in the weather forecasting domain.
1 Introduction
Data-to-text systems are NLG systems that gener-
ate texts from raw input data. Many examples of
such systems have been reported in the literature,
which have been applied in a number of domains and
to different types of input. For example, BabyTalk
(Portet et al, 2007) generates medical reports from
sensors monitoring a baby in a Neonatal Intensive
Care Unit, while (Hallett and Scott, 2005) describe a
system for generating reports from events in medical
records. SumTime (Reiter et al, 2005), (Coch, 1998)
and Fog (Goldberg et al, 1994) generate weather
forecasts from the output of weather computer sim-
ulation models, while (Iordanskaja et al, 1992) and
(Ro?sner, 1987) both generate summaries from em-
ployment statistics.
As the above examples show most work in data-to-
text up to now has concentrated almost exclusively
on time series data. Work on generating text from
spatial data has been reported in Coral (Dale et al,
2005), which generates route descriptions of a path
constructed from Geographical Information Systems
(GIS) datasets. Unlike the input to Coral however,
most georeferenced data contains only limited spatial
information(in many cases, only latitude and longi-
tude).
As (Roy and Reiter, 2005) point out, connecting
language to the non-linguistic world is an important
issue in Cognitive Science and Aritificial Intelligence;
moreover, geographic data is becoming increasingly
ubiquitous as the availability of low cost locational
devices such as GPS increases, and GIS become more
user friendly. Therefore, we believe exploring the
issue of generating textual reports grounded in real
world geographical data is an important challenge.
On a more practical level, it is also a natural next
step in the application of data-to-text technology to
apply it to geographically referenced data.
In the RoadSafe project described in the following
section, we have been investigating this issue in a
data-to-text system that generates road ice weather
forecasts. The subsequent focus of this paper is the
adaption of NLG techniques to the task of summaris-
ing georeferenced data. In particular, the incorpora-
tion of spatial reference frames to generate grounded
(from external GIS data sources) spatial references.
2 Background
Weather forecasting has been one of the most suc-
cessful and widely researched application domains for
NLG systems. The main novel aspect that sets Road-
Safe apart from other weather forecast generators
and indeed, other data-to-text systems, is it?s appli-
cation to spatio-temporal data. The input to Road-
Safe is generated by a road ice simulation model,
which outputs a large (in order of Megabytes) mul-
tivariate data set, shown in Figure 1.
The output of the model contains predicted mea-
surements of 9 meteorological parameters for 1000?s
of points across a road network, each measured at
20 minute intervals during a 24 hour forecast pe-
riod. A map of such a network, belonging to a lo-
cal council in the UK, is shown in Figure 2. This
model forms the basis of a road ice forecasting ser-
16
Figure 1: Part of a RoadSafe input data set show-
ing corresponding spatial and non-spatial attribute ta-
bles; T=Air Temperature (Deg C), W=Dew Point (Deg
C), R=Road Surface Temperature (Deg C), C=Weather
Code, D=Wind direction (Degrees), V=Mean wind
Speed (knots), G=Wind Gust (knots),S=Sky Cover (%),
P=Precipitation Water Equivalent (mm).
vice provided by Aerospace and Marine International
(AMI), which is delivered to local councils via an
online Road Weather Information System (RWIS).
This service provides road engineers with up to the
minute weather information using graphs, graphics
and textual reports that allows them to base their
road maintenance operations on during the winter
months. In RoadSafe we have been working on gen-
erating the textual reports, such as the one shown in
Figure 3, automatically from the model data.
The communicative goal of the textual reports is
to complement detailed tabular and graphical pre-
sentations of the model data with a more general
overview of the weather conditions. In the context
of our work this presents a number of challenges:
1. The input data has to be analysed, this is non-
Figure 2: Road Ice Model Data Points Map
trivial due to the complexity and size of the in-
put data.
2. Our system is required to achieve a huge
data/text compression ratio (Human authored
texts are short and concise summaries). There-
fore, content selection is a serious issue for our
system.
3. Describing the effect of the underlying geogra-
phy on weather conditions, such as ?possible gale
force gusts on higher ground?, is an integral part
of the communicative goal of the text. Infor-
mation containing such relationships is not ex-
plicit in the input data and therefore must be
grounded.
?Another night with all routes quickly falling be-
low zero this evening. Only isolated urban spots in
the south will only drop to around zero. Freezing
fog patches will become more widespread during the
night but thin a little tomorrow morning especially
in the south.?
Figure 3: Example Human Authored Corpus Text
3 Architecture
As noted in the previous section, the input data to
our system contains only limited spatial information:
a point identifier that ties the measurement site to
a particular route and a latitude longitude coordi-
nate. Therefore it is necessary for our system to per-
form additional spatial reasoning to characterise the
input in terms of its underlying geography. The ar-
chitecture of our system shown in Figure 4, extends
17
Figure 4: RoadSafe System Architecture
the architecture for data-to-text systems proposed
in (Reiter, 2007) to include this additional process-
ing. In Section 3.1 we explain some of the rationale
behind these design decisions based on observations
from our knowledge acquisition(KA) Studies. In Sec-
tions 3.2 and 3.3 we explain the additional modules
we have introduced in more detail.
3.1 Observations from Knowledge
Acquisition Studies
We have been working closely with experts at AMI
for a number of winters now in the development of
RoadSafe. During this time we have found that two
interrelated aspects in particular have influenced the
architecture of our system, which we describe next.
Spatial Reference Frames Frames of reference
in this context are a particular perspective in which
the domain can be observed. More precisely, they are
sets of related geographical features (such as elevated
areas) which partition the domain into meaningful
sub areas for descriptive purposes. In Levinson?s ter-
minology (Levinson, 2003), they are absolute refer-
ence systems as they employ fixed bearings. In the
RoadSafe domain we have identified 4 main spatial
frames of reference used by experts in our corpus de-
scribed in (Turner et al, 2008):
1. Altitude e.g. ?rain turning to snow on higher
ground?.
2. Absolute Direction e.g. ?some heavier bursts in
the north?.
3. Coastal Proximity e.g. ?strong winds along the
coast?.
4. Population e.g. e.g. ?Roads through the Urban
areas holding just above freezing?.
Communicative Purpose of Spatial Descrip-
tions From our studies we have found that experts
generally follow 4 steps when writing road ice fore-
casts:
1. Build frames of reference to geographical fea-
tures that may affect general weather condi-
tions.
2. Build an overview of the general weather pat-
tern.
3. Select important features to communicate from
the pattern.
4. Communicate the summary.
Building frames of reference to geographical fea-
tures is important for a human forecaster to be able
to take into account how the geography of the region
influences the general weather conditions. Under-
standing the weathers interaction with the terrain
enables them to make reliable meteorological infer-
ences. For example a spatial description such as ?rain
turning to snow in rural areas? may be geographically
accurate, but does not make sense meteorologically
as it is purely by chance that this event is occurring
at that location.
18
From a NLG system perspective it is important to
take into account the communicative purpose of spa-
tial descriptions in this context, which are express-
ing causality (the effect of geographical features on
weather conditions) rather than being purely loca-
tive. For example, changes in precipitation type are
more commonly seen in higher elevation areas where
the air temperature is generally lower, so a spatial de-
scription describing such an event should make use of
a reference frame that reflects this interaction. Simi-
larly, road surface temperatures are generally higher
in urban areas where there is a general population
effect. For a referring expression generation (REG)
strategy this means that this requires not only ade-
quate spatial representation and reasoning capabili-
ties about an objects location, but also additional in-
formation about an objects function in space. This is
a problem which has been acknowledged in the psy-
cholinguistic literature e.g. (Coventry and Garrod,
2004).
3.2 Geographic Characterisation
Geographic Characterisation is responsible for
grounding the location of the data by making the
relationship between it?s underlying geography ex-
plicit. As the first stage of data analysis it assigns
additional spatial properties to each data point by in-
tersecting the point with external GIS data sources
representing the frames of reference we have iden-
tified. For example after characterisation, the first
point in the spatial attribute table shown in Figure
1 is assigned values [0m,SSW,Urban,Coastal] to rep-
resent elevation, absolute compass direction, popula-
tion density of its immediate area and its proximity
to the coast respectively. This process is more com-
monly known as a form of data enrichment in the
Spatial Data Mining community (Miller and Han,
2001). In the scope of our work it is important for
two reasons: most importantly, it provides a set of
properties that are used by the REG module to gen-
erate spatial descriptions; secondly, these properties
can be taken into account by our analysis method
during the initial segmentation of the data.
3.3 Spatial Reasoner and Spatial Database
The spatial database provides a repository of geo-
graphic information. Frames of reference are stored
as thematic layers from various GIS data sources con-
sisting of sets of boundary objects. For example, al-
titude is represented as sets of polygons representing
altitude contours at a given resolution and popula-
tion is a set of town boundary polygons. The spatial
reasoning module provides a high level interface be-
tween the spatial database and the rest of the system.
It is responsible for performing geographic character-
isation and providing spatial query functionality to
the rest of the system.
4 Text Generation
In Section 2 we outlined 3 main challenges that our
system must address. Our approach to the first,
analysis of the input data, is described in (Turner
et al, 2007). In the following Sections 4.1 and 4.2,
we describe the approach taken by our text generator
to the former two: content selection and generating
spatial references.
4.1 Content Selection
The input to the document planning module of our
system is a series of meteorological events (such as
rises in temperature) describing each parameter over
specific periods of time and locations. The basic
events are generated by data analysis which are then
abstracted into higher level concepts by data inter-
pretation. As it is impossible to include all these
events in such a short summary our system also gen-
erates a table as well as text shown in Figure 5.
In our KA studies we have found experts use
a qualitative overview of weather conditions when
writing forecasts to perform this task, confirming
similar observations reported in (Sripada et al,
2001). We take the same approach as experts in
our system by including the internal information
of the table (generated by the data analysis mod-
ule) as input to document planning. This serves as
the overview for content selection and allows con-
struction of an initial document plan consisting of
overview event leaf nodes. An example of this struc-
ture for the system output shown in Figure 5 is given
in Figure 6. Each overview event corresponds to a
column (or columns in the case of snow and rain) in
the table if the column indicates a significant thresh-
old for the parameter it describes (i.e. yes for ice).
Figure 6: Overview event tree for the text output in Fig-
ure 5
19
Figure 5: Example system output with text and partial table
The next stage is to construct messages from the
leaf nodes of the document plan. This is done in a
top down fashion by further annotating the tree with
events from the input list. Additional events are se-
lected by using the information from the overview
events to retrieve them from the list. This has the
benefit of keeping the content of both text and ta-
ble consistent. The final tree comprises the input
to the microplanner where messages are realised as
sentences in the final text and typically contain two
events per message (as observed in our corpus). For
example the overview event describing Precip in Fig-
ure 6 is realised as two sentences in Figure 5: Win-
try precipitation will affect most routes throughout
the forecast period at first [overview event], falling
as snow flurries in some places above 300M at first
[event]. Snow spreading throughout the forecast pe-
riod to all areas [event] and persisting in some places
above 300M until end of period [event].
4.2 Generating Spatial References to
Geographic Areas
Approaches to REG to date have concentrated
on distinguishing descriptions (e.g. (Gatt and
van Deemter, 2007),(van Deemter, 2006),(Horacek,
2006),(Krahmer et al, 2003),(Dale and Reiter,
1995); more specifically that is given a domain, they
look to generate a description of a target object that
uniquely distinguishes it from all other objects within
that domain. In a large geographic environment
such as a road network consisting of 1000?s of points,
where the task is to refer to an event occurring at a
small subset of those points, it is impractical (gen-
erated descriptions may be long and complex) and
prohibitively expensive (large numbers of spatial re-
lations between objects may have to be computed) to
take this approach. A more practical approach is to
generate spatial descriptions in terms of regions that
are not strictly distinguishing (i.e. urban areas, high
ground) rather than in terms of the points contained
within that region. Indeed, this is the strategy em-
ployed by human authors in our corpus. Therefore,
in a description such as ?road surface temperatures
will fall below zero in some places in the south west?,
distractors can be defined as the set of points within
the south western boundary that do not satisfy this
premise.
The relaxation of the requirement to generate a
distinguishing description simplifies the REG task in
this context as a single referring expression may be
deemed acceptable to refer to a wide range of situa-
tions. For example, ?in some places in the south west?
could be used to refer to a large number of possible
subsets of points that fall within the south western
boundary of the network. A simple REG strategy
is to find the set of properties to use in a descrip-
tion that introduce the least number of distractors.
However, as mentioned previously in Section 3.1, an
added constraint is that a spatial description should
use an appropriate frame of reference in the context
of the event it is describing. For example, describing
a change in precipitation type using population as
20
a frame of reference (i.e ?rain turning snow in some
rural places?) is not a sound meteorological inference
because population density does not affect precipi-
tation. This could cause a reader to infer false im-
plicatures (Grice, 1975), and consequently lead to
unnecessary treatment of part of the road network
so should be avoided. To account for this, following
(Dale and Reiter, 1995) we include a preference set
of reference frames for each type of event that must
be described. Absence from the set signifies that the
specified frame of reference should not be used in
that context.
Recall from Section 3.2 that properties in this case
relate directly to sets of boundary objects within a
frame of reference. Our content selection module
takes as input a series of individual proportions de-
scribing the spatial distribution of each parameter
within each frame of reference at a particular time
point. A score is calculated for each set of properties
by averaging over the sum of proportions for each
frame of reference. An appropriate frame of refer-
ence is then selected by choosing the one with the
highest score from the preference set for the given
event. An example1 of the input for the generated
description ?falling as snow flurries in some places
above 300M at first? in Figure 5 is shown in Figure
7.
5 Evaluation
The system presented in this paper is in its first
incarnation, RoadSafe is still actively under devel-
opment in preparation for a full scale user evalua-
tion. We have been evaluating the quality of the
output of the current system using post edit tech-
niques and feedback from expert meteorologists at
AMI. Our prototype has been installed at AMI since
the start of the year and is being used to generate
draft road ice forecasts for one of their local council
clients. One forecast is generated per day which is
then post-edited by an on duty forecaster before it is
sent to the client. While common in Machine Trans-
lation post-edit evaluations are still relatively rare in
NLG. The only large scale post-edit evaluation of an
NLG system to our knowledge has been reported in
(Sripada et al, 2005).
Our current evaluation is small in comparison to
that evaluation; SumTime-Mousam, the system be-
ing evaluated in that work was generating 150 draft
forecasts per day. However, it does try to address
some of the problems the authors encountered during
that evaluation. The main issue outlined by (Sripada
1N.B. this example is taken from route network that is
land locked and therefore coastal proximity is not taken into
account in this case.
Parameter: Snow
Class: Flurries
Time point: 12:00 {
Reference Frame Boundary Proportion
Altitude
0m: 0.0
100m: 0.0
200m: 0.0
300m: 0.07
400m: 1.0
500m: 1.0
Direction
CentralNE: 0.0
CentralNW: 0.0
CentralSE: 0.0
CentralSW: 0.0
EastNorthEast: 0.0
EastSouthEast: 0.0
SouthSouthEast: 0.0
SouthSouthWest: 0.18
TrueNorthEast: 0.0
TrueSouthEast: 0.0
TrueSouthWest: 0.56
WestSouthWest: 0.23
Population
Rural: 0.02
Urban: 0.0
}
Figure 7: Example input to content selection for REG.
Proportions are number of points affected by snow within
given boundary at the specified time point. Scores by
Reference Frame: Altitude = 0.35, Direction = 0.07, Pop-
ulation = 0.01
et al, 2005) was that their analysis was post-hoc and
therefore not supported by authors or by an editing
tool, which made it difficult to analyse why post-edits
were made. We have accounted for this by including
post-editing as part of our development process and
making use of a simple online interface that allows
the editor to select check boxes as they edit and in-
sert any general comments they may have. Check
boxes record edit reasons at a high level, for exam-
ple content, sentence order, spatial description used
etc. This is because it is not reasonable to expect a
time-constrained forecaster to spend time recording
every edit he makes.
Another important lesson pointed out by (Sripada
et al, 2005) is the need for a pilot study to analyse
the post-edit behaviour of individual authors to ac-
count for noisy data. This is certainly worthwhile,
but is difficult to carry out in our domain where fore-
casters work in variable shift patterns and on vari-
able forecasting tasks at different times. Instead, we
21
have used feedback forms as a way to gain qualitative
data on both the general quality of the texts and the
post-editing process. We present our results in Sec-
tion 5.1. In Section 5.2 we provide some discussion
of the results and describe future work.
5.1 Results
Our post-edit corpus currently consists of 112 texts,
2 texts(1 generated,1 edited) for 56 forecast days.
Of the 56 generated texts 54 have been edited before
being released to the user. As a general evaluation
criterion, our generated texts are generally too long
with a mean word length of 72 (standard deviation
of 21) compared to a mean word length of 53 (stan-
dard deviation of 17). The mean word count differ-
ence per forecast is 21 (standard deviation of 15). In
general analysis of the corpus is difficult, as in some
cases (18) texts have been basically rewritten. This
is not reflecting the quality of the text as such, but
the fact that the author has access to other informa-
tion sources such as satellite maps, which can lead
him to draw different inferences to those in the raw
model data available to the system. Furthermore,
(Hopwood, 2004) acknowledge as ice prediction mod-
els have become increasingly advanced, the primary
added value provided by weather forecasters is to
function as quality control and error mitigation for
the model, using their insight and experience to make
amendments particularly on marginal nights (where
the road surface temperature may or may not fall be-
low zero). Such cases can only be considered as noise
for analysis purposes, and the fact that our system
cannot account for this without the additional infor-
mation has been acknowledged by all forecasters in
their editing comments and feedback forms.
Focusing on 74 real post-edits (not attributed to
model data) recorded in our corpus, they can be clas-
sified into the following broad error categories: con-
tent edits - 65% and microplanning edits 35%. One
major problem we have identified with the current
generated text is the way in which overview events
described in 4.1 are realised. Deletions of whole sen-
tences describing overview events such as the one
highlighted in bold in Figure 8 constitute over half
(52%) of content edits, which may help to explain
the large descrepency in word counts. Essentially
forecasters believe they can often communicate sim-
ilar information as subsequent statements about the
same parameter making the texts repetitive at times.
Therefore they suggest they should either be omit-
ted or be realised as more interpretative statements,
such as ?A marginal night for most routes? for the
omitted statement in Figure 8. Forecasters also of-
ten delete subsequent statements following overview
Generated Text:
?Road surface temperatures will reach
near critical levels on some routes from the
late evening until tomorrow morning. Rain
will affect all routes during the afternoon and
evening. Road surface temperatures will fall slowly
during the mid afternoon and evening, reaching
near critical levels in areas above 500M by 21:00.?
Post-edited Text:
?Rain will affect all routes during the after-
noon and evening. Road surface temperatures will
fall slowly during the mid afternoon and evening,
reaching near critical levels in areas above 500M by
21:00.?
Figure 8: Content selection post-edit example (road
surface temperature overview information removed)
Generated Text:
?Road surface temperatures will reach near
critical levels on some routes after midnight until
tomorrow morning. Rain will affect all routes
throughout the forecast period, falling as snow
in some places above 500M by 08:00. Snow
clearing by 08:00. Road surface temperatures
will fall slowly during the late evening and tonight,
reaching near critical levels in areas above 500M by
03:00.?
Post-edited Text:
?Road surface temperatures will reach near
critical levels on some routes after midnight until
tomorrow morning. Rain will affect all routes
during the forecast period, this may fall as sleet
later on highest ground before dying out.
Road surface temperatures will fall slowly during
the late evening and tonight, reaching near critical
levels in areas above 500M by 03:00.?
Figure 9: Microplanning post-edit example (lexicalisa-
tion and aggregation)
sentences when they describe an event (such as rain
turning heavy) occuring only at a small number of
locations. So the spatial extent of an event and not
only its meteorological importance should be con-
sidered during content selection. RoadSafe does not
currently include much domain reasoning at the doc-
ument planning level to be able to do this.
22
Microplanning edits, as highlighted in bold in Fig-
ure 9, are due to individual lexical choice or aggrega-
tion issues. In all questionnaires experts have com-
mented that the generated texts are grammatically
sound but could flow better. Aggregation is done
in a fairly basic fashion in our system at present as
is lexicalisation. There have been no edits to the
frame of reference used in the generated spatial de-
scriptions, which we have taken as indication that
our REG strategy works well.
5.2 Discussion
The general feedback to our system has been encour-
aging. In terms of the exploitability of the system in
its current form it has received mixed reviews from
4 forecasters: 1 forecaster rated the system as good
for content and very poor on fluency; 1 rated it as
ok for both; 1 forecaster rated it as poor for content
and ok for fluency; 1 forecaster rated it as poor for
both. Generally all forecasters believe the generated
texts should tell a more fluent story about weather
conditions with more causal linking between events.
In terms of the techniques and approach outlined in
this paper they have worked well, although as ac-
knowledged in the previous section more sophisti-
cated domain reasoning and aggregation techniques
are required if the text is to function as a concise
summary, and indeed reach the standard of human
authored texts.
Making the required improvements highlighted in
the previous section is the focus of current work. Af-
ter these improvements have been made we plan to
carry out an evaluation with users of the forecasts.
We hope to also extend the functionality of the sys-
tem by generating individual route forecasts, which
can be accessed interactively through the table.
6 Conclusions
We have presented an approach to generating ge-
ographically grounded summaries of georeferenced
data using spatial reference frames. This approach
has been implemented in a data-to-text system for
generating road ice forecasts. An important task in
summarising georeferenced data is to describe the
data in terms of its underlying geography it refer-
ences. This presents an interesting challenge for con-
ventional REG approaches as finding a distinguish-
ing description for large numbers of objects in geo-
graphic space is not practical. We have found char-
acterising the geography in terms of spatial reference
frames provides a good solution as it provides a flex-
ible representation to describe set of objects in terms
of geographic areas.
We have also implemented a simple top down
content selection approach based on the idea of
overview, taken from how we have observed ex-
perts commonly performing the summarisation task.
While this approach works well for content selection,
a post-edit evaluation with experts has highlighted
that realising the overview in the text can make texts
verbose and have the effect of making subsequent
statements describing related events in the discourse
sound repetitive. This is important as experts re-
quire a short concise summary of weather conditions.
Acknowledgments
Many thanks to our collaborators at Aerospace and
Marine International UK, especially Keith Thom-
son and the other Meteorologists, for their helpful
feedback and comments. The RoadSafe project is
supported jointly by Aerospace and Marine Inter-
national UK, and the UK Engineering and Physical
Sciences Research Council (EPSRC), under a CASE
PhD studentship.
References
J. Coch. 1998. Multimeteo: multilingual production of
weather forecasts. ELRA Newsletter, 3(2).
K. R. Coventry and S. C. Garrod. 2004. Saying, Seeing
and Acting: The Psychological Semantics of Spatial
Prepositions. Psychology Press.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the gricean maxims in the generation of refer-
ring expressions. Cognitive Science, 19:233?263.
R Dale, S Geldof, and J-P Prost. 2005. Using natu-
ral language generation in automatic route description.
Journal of Research and Practice in Information Tech-
nology, 37(1):89?105.
A. Gatt and K. van Deemter. 2007. Lexical choice and
conceptual perspective in the generation of plural re-
ferring expressions. Journal of Logic, Language and
Information, 16:423?443.
E. Goldberg, N. Driedger, and R. Kittredge. 1994. Using
natural-language processing to produce weather fore-
casts. IEEE Expert, 9(2):45?53.
H. Grice. 1975. Logic and conversation. In P. Cole and
J. Morgan, editors, Syntax and Semantics, volume 3,
Speech Acts, pages 43?58. Academic Press: New York.
C. Hallett and D. Scott. 2005. Structural variation in
generated health reports. In Proceedings of the 3rd
International Workshop on Paraphrasing (IWP2005),
pages 33?40, Jeju Island, Republic of Korea.
Philip Hopwood. 2004. Improvements in road forecasting
techniques & their applications. In 12th International
Road Weather Conference, Bingen, Germany.
Helmut Horacek. 2006. Generating references to parts
of recursively structured objects. In Proceedings of
the 4th International Conference on Natural Language
Generation, pages 47?54.
23
Lidija Iordanskaja, Richard Kittredge, Benoit Lavoie,
and Alain Polgue`re. 1992. Generation of extended
bilingual statistical reports. COLING-92, pages 1019?
1023.
Emiel Krahmer, Sebastiaan van Erk, and Andr Verleg.
2003. Graph-based generation of referring expressions.
Computational Linguistics, 29(1):53?72.
Stephen C. Levinson. 2003. Space in language and cog-
nition: explorations in cognitive diversity. Cambridge
University Press, Cambridge.
Harvey J. Miller and Jiawei Han. 2001. Geographic data
mining and knowledge discovery: An overview. In Ge-
ographic Data Mining and Knowledge Discovery, chap-
ter 1, pages 1?32. Taylor & Francis.
F. Portet, E. Reiter, J. Hunter, and S. Sripada. 2007.
Automatic generation of textual summaries from
neonatal intensive care data. In 11th Conference on
Artificial Intelligence in Medicine (AIME 07), pages
227?236.
E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy.
2005. Choosing words in computer-generated weather
forecasts. In Artificial Intelligence, volume 67, pages
137?169.
E. Reiter. 2007. An architecture for data-to-text sys-
tems. In ENLG07, pages 97?104.
D. Ro?sner. 1987. The automated news agency: Sem-
tex: A text generator for german. In Natural Lan-
guage Generation: New Results in Artificial Intelli-
gence, Psychology, and Linguistics. Nijhoff.
D. Roy and E. Reiter. 2005. Connecting language to the
world. Artificial Intelligence, 167:1?12.
S. Sripada, E. Reiter, J. Hunter, and Jin Yu. 2001.
A two-stage model for content determination. In
ENLG2001, pages 3?10.
S Sripada, E Reiter, and L Hawizy. 2005. Evaluation of
an nlg system using post-edit data: Lessons learnt. In
10th European Workshop on Natural Language Gener-
ation.
R. Turner, S. Sripada, E. Reiter, and I. Davy. 2007. Se-
lecting the content of textual descriptions of geograph-
ically located events in spatio-temporal weather data.
In Applications and Innovations in Intelligent Systems
XV, pages 75?88.
R. Turner, S. Sripada, E. Reiter, and I. Davy. 2008.
Building a parallel spatio-temporal data-text cor-
pus for summary generation. In Proceedings of the
LREC2008 Workshop on Methodologies and Resources
for Processing Spatial Language, Marrakech, Morocco.
K van Deemter. 2006. Generating referring expressions
that involve gradable properties. Computational Lin-
guistics, 32:195?222.
24
Proceedings of the 8th International Natural Language Generation Conference, pages 1?5,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
A Case Study: NLG meeting Weather Industry Demand for Quality 
and Quantity of Textual Weather Forecasts 
Somayajulu G Sripada, Neil Burnett and 
Ross Turner 
Arria NLG Plc 
{yaji.sripada,neil.burnett, 
ross.turner}@arria.com 
 John Mastin and Dave Evans 
Met Office 
{john.mastin, 
dave.evans}@metoffice.gov.uk 
  
 
  
 
Abstract 
In the highly competitive weather indus-
try, demand for timely, accurate and per-
sonalized weather reports is always on 
the rise. In this paper we present a case 
study where Arria NLG and the UK na-
tional weather agency, the Met Office 
came together to test the hypothesis that 
NLG can meet the quality and quantity 
demands of a real-world use case. 
1 Introduction 
Modern weather reports present weather predic-
tion information using tables, graphs, maps, 
icons and text. Among these different modalities 
only text is currently manually produced, con-
suming significant human resources. Therefore 
releasing meteorologists? time to add value else-
where in the production chain without sacrificing 
quality and consistency in weather reports is an 
important industry goal. In addition, in order to 
remain competitive, modern weather services 
need to provide weather reports for any geo-
location the end-user demands. As the quantity 
of required texts increases, manual production 
becomes humanly impossible. In this paper we 
describe a case study where data-to-text NLG 
techniques have been applied to a real-world use 
case involving the UK national weather service, 
the Met Office. In the UK, the Met Office pro-
vides daily weather reports for nearly 5000 loca-
tions which are available through its public web-
site. These reports contain a textual component 
that is not focused on the geo-location selected 
by the end-user, but instead describes the weath-
er conditions over a broader geographic region. 
This is done partly because the time taken to 
manually produce thousands of texts required 
would be in the order of weeks rather than 
minutes. In this case study a data-to-text NLG 
system was built to demonstrate that the site-
specific data could be enhanced with site-specific 
text for nearly 5000 locations. This system, run-
ning on a standard desktop, was tested to pro-
duce nearly 15000 texts (forecasts for 5000 loca-
tions for 3 days into the future) in less than a mi-
nute. After internally assessing the quality of 
machine-generated texts for nearly two years, the 
Met Office launched the system on their beta site 
(http://www.metoffice.gov.uk/public/weather/for
ecast-data2text/) in December 2013 for external 
assessment. A screenshot of the forecast for 
London Heathrow on 5th March 2014 is shown 
in Figure 1. In this figure, the machine-generated 
text is at the top of the table. Ongoing work has 
extended the processing capabilities of this sys-
tem to handle double the number of locations and 
an additional two forecast days. It has been 
found that the processing time scales linearly. 
2 Related Work 
Automatically producing textual weather fore-
casts has been the second favorite application for 
NLG, with 15 entries on Bateman and Zock?s list 
of NLG application domains (the domain of 
medicine comes on top with 19 entries) [Bate-
man and Zock, 2012]. NLG applications in the 
weather domain have a long history. FOG was an 
early landmark NLG system in the domain of 
weather reports [Goldberg et al, 1994]. Working 
as a module of the Forecast Production Assistant 
(FPA), FOG was operationally deployed at Envi-
ronment Canada to produce weather reports for 
the general public and also for marine users in 
both English and French. Using sampling and 
smoothing over space and time, FOG reduces 
raw data into a few significant events which are 
then organized and realized in textual form. 
MULTIMETEO is another industry deployed mul-
ti-lingual weather report generator [Coch 1998].  
The focus of MULTIMETEO is ?interactive genera-
tion via knowledge administration?.
1
Figure 1. Screenshot of Text-Enhanced Five-day Weather Forecast for London Heathrow on 5 March 2014 
showing only part of the data table 
 
Expert forecasters post-edit texts (interactivity) 
in their native language and this knowledge is 
then reused (knowledge administration) for au-
tomatically generating texts in other languages. It 
is claimed that such interactive generation is bet-
ter than using machine translation for multi-
lingual outputs. SUMTIME-MOUSAM is yet anoth-
er significant weather report generator that was 
operationally deployed to generate forecasts in 
English for oil company staff supporting oil rig 
operations in the North Sea [Sripada et al, 
2003a]. Adapting techniques used for time series 
segmentation, this project developed a frame-
work for data summarization in the context of 
NLG [Sripada et al, 2003b]. This time series 
summarization framework was later extended to 
summarizing spatio-temporal data in the ROAD-
SAFE system [Turner et al, 2008]. ROADSAFE too 
was used in an industrial context to produce 
weather reports (including text in English and a 
table) for road maintenance in winter months. 
The NLG system reported in the current case 
study builds upon techniques employed by earli-
er systems, particularly SUMTIME-MOUSAM and 
ROADSAFE.  
The main dimension on which the applica-
tion described in this paper differs most from the 
work cited previously is the quantity of textual 
weather forecasts that are generated. Previous 
work has either focused on summarising forecast 
sites collectively (in the case of FOG and ROAD-
SAFE), been limited in the number of sites fore-
cast for (15 in the case of MULTIMETEO) or lim-
ited in geographic extent (SUMTIME-MOUSAM 
concentrated on oil rig operations in the North 
Sea). This aspect of the system, amongst others, 
posed a number of challenges discussed in Sec-
tion 3.      
3 System Description 
For reasons of commercial sensitivity, the system 
description in this section is presented at an ab-
stract level. At the architecture level, our system 
uses the Arria NLG Engine that follows the 
standard five stage data-to-text pipeline [Reiter, 
2007]. The system integrates application specific 
modules with the generic reusable modules from 
the underlying engine. Input to the system is 
made up of three components: 
 
1. Weather prediction data consisting of sev-
eral weather parameters such as tempera-
ture, wind speed and direction, precipita-
tion and visibility at three hourly intervals; 
2. Daily summary weather prediction data 
consisting of average daily and nightly 
values for several weather parameters as 
above; and 
3. Seasonal averages (lows, highs and mean) 
for temperature. 
 
Because the system is built on top of the Ar-
ria NLG Engine, input data is configurable 
and not tied to file formats. The system can be 
configured to work with new data files with 
equivalent weather parameters as well as dif-
ferent forecast periods. In other words, the 
system is portable in principle for other use 
cases where site-specific forecasts are required 
from similar input data.  
2
3.1 Expressing Falling Prediction Quality for 
Subsequent Forecast Days 
As stated above, the system can be configured to 
generate forecast texts for a number of days into 
the future. Because prediction accuracy reduces 
going into the future, the forecast text on day 1 
should be worded differently from subsequent 
days where the prediction is relatively more un-
certain. An example output text for day 1 is 
shown in Figure 2 while Figure 3 shows the day 
3 forecast. Note the use of ?expected? to denote 
the uncertainty around the timing of the tempera-
ture peak. 
 
Staying dry and predominantly clear with only a 
few cloudy intervals through the night. A mild 
night with temperatures of 6C. Light winds 
throughout. 
 
Figure 2. Example output text for day 1 
 
Cloudy through the day. Mainly clear into the 
night. Highest temperatures expected during the 
afternoon in the region of 12C with a low of 
around 6C during the night. Light to moderate 
winds throughout. 
 
Figure 3. Example output text for day 3 
3.2 Lack of Corpus for System Development 
A significant feature of the system development 
has been to work towards a target text specifica-
tion provided by experts rather than extract such 
a specification from corpus texts, as is generally 
the case with most NLG system development 
projects. This is because expert forecasters do 
not write the target texts regularly; therefore, 
there is no naturally occurring target corpus. 
However, because of the specialized nature of 
the weather sublanguage (Weatherese), which 
has been well studied in the NLG community 
[Goldberg et al, 1994, Reiter et al 2005, Reiter 
and Williams 2010], it was possible to supple-
ment text specifications obtained from experts. 
In addition, extensive quality assessment (details 
in section 3.4) helped us to refine the system 
output to the desired levels of quality. 
3.3 Achieving Output Quantity 
The main requirements of the case study have 
been 1) build a NLG capability that produces the 
quantity of texts required and 2) achieve this 
quantity without sacrificing the quality expected 
from the Met Office. As stated previously, the 
quantity requirement has been met by generating 
15,000 texts in less than a minute, without need 
for high end computing infrastructure or parallel-
ization. Figure 4 is a box plot showing character 
lengths of forecast texts for an arbitrary set of 
inputs. The median length is 177 characters. The 
outliers, with length 1.5 times the interquartile 
range (1.5 * 134 = 201 characters) above the up-
per quartile or below the lower quartile, relate to 
sites experiencing particularly varied weather 
conditions. Feedback on the appropriateness of 
the text lengths is discussed in Section 3.4. 
 
Figure 4. Boxplot of forecast character length 
 
 
Figure 5. System Processing Time 
 
   The system has recently been extended to gen-
erate 50,000 texts without loss of performance. 
This extension has doubled the number of sites 
processed to 10,000 and extended the forecast to 
5 days. It has also increased the geographic ex-
tent of the system from UK only to worldwide, 
discussed in Section 3.5. The plot in Figure 5 
shows the relationship between processing time 
3
and the addition of new forecast sites. The results 
were obtained over 10 trials using a MacBook 
Pro 2.5 GHz Intel Core i5, running OS X 10.8 
with 4GB of RAM.  
3.4 Achieving Output Quality 
Achieving the required text quality was driven 
by expert assessment of output texts that oc-
curred over a period of two years. This is be-
cause experts had to ensure that the system out-
put was assessed over the entire range of weather 
conditions related to seasonal variations over the 
course of a year. The following comment about 
the output quality made by a Met Office expert 
summarizes the internal feedback: 
 
"They were very, very good and I got lots of ver-
bal feedback to that affect from the audience af-
terwards. Looking back after the weekend, the 
forecasts proved to be correct too! I've been 
looking at them at other times and I think they're 
brilliant." 
 
After successfully assessing the output quality 
internally, the Met Office launched the system on 
the Invent part of their website to collect end-
user assessments. Invent is used by the Met Of-
fice to test new technology before introducing 
the technology into their workflows. With the 
help of a short questionnaire 1  that collects as-
sessment of those end-users that use weather in-
formation for decision-making, quality assess-
ment is ongoing. The questionnaire had three 
questions related to quality assessment shown in 
Figures 6-8. In the rest of the section we describe 
the results of this questionnaire based on 35 re-
sponses received between 1st January 2014 and 
6th March 2014.  
The first question shown in Figure 6 relates to 
assessing the usefulness of textual content in 
helping the end-user understand a weather report 
better. Out of the 35 respondents, 34 (97%) an-
swered ?yes? and 1 (3%) answered ?no? for the 
question in Figure 6. The second question shown 
in Figure 7 relates to assessing if the text size is 
optimal for this use case. Here, out of the 35 re-
spondents, 26 (74%) felt the text is ?about right? 
size, 7 (20%) felt it is either ?too short? or ?too 
long? and 2 (6%) were ?unsure?. The third ques-
tion shown in Figure 8 relates to finding out if 
the end-user might want a forecast that includes 
textual content. Here, 32 (91%) wanted textual 
content while 3 (9%) did not want it.  
                                                 
1
http://www.metoffice.gov.uk/invent/feedback 
The Met Office is currently evaluating the new 
capability based upon the feedback received and 
how it can be applied to meet the demands of 
users across their portfolio of products. 
Did you find the text on the weather forecast 
page helped you to understand the forecast bet-
ter? * 
Yes 
No 
Figure 6. Question about textual content help-
ing the end-user understand the forecast better 
How did you find the text used? * 
Too short 
About right 
Too long 
Unsure / don't know 
Figure 7. Question about length of the forecast 
text 
Would you recommend this feature? * 
Yes 
No 
Figure 8. Question about the end-user?s opin-
ion on textual content as part of a weather report 
 
The questionnaire also asked for free text 
comments. An example of one such comment is: 
 
"Succinct and clear text. Contains all the im-
portant features and is well presented. Saves us 
having to summarise the visual descriptions our-
selves (or rather helps to shape our conclusions 
about the 24 hour weather pattern)." 
    
   A big challenge during the development of 
such a system is providing quality assurance 
4
when generating such a large volume of texts. A 
number of automated checks had to be applied to 
the complete output during system testing as well 
as targeted sampling of input data to produce a 
representative sample of outputs for manual as-
sessment. 
3.5 Extending the Geographic Extent 
Extending the scope of the system from UK-only 
sites to handling worldwide locations brings sub-
tle challenges in addition to scaling the system, 
principally: 
 
1. handling time zone changes; and 
2. adapting to different climates. 
 
In the case of point 1 above, time descriptions 
can become ambiguous where the sunrise and 
sunset time vary across geographies. Such times 
need to be carefully observed to avoid generating 
words such as ?sunny? after dark. For point 2, 
general terminologies relating to description of 
temperatures cannot be universally applied 
across locations. For example, the meaning of 
terms such as ?cool? differs at locations within 
the tropics versus locations north (or south) of 45 
degrees of latitude. 
4 Conclusion 
We have presented a case study describing an 
application of NLG technology deployed at the 
Met Office. The system has been developed to 
meet the text production requirements for thou-
sands of forecast locations that could not have 
been sustainable with human resources. The 
software can write a detailed five-day weather 
forecast for 10,000 locations worldwide in under 
two minutes. It would take a weather forecaster 
months to create the equivalent quantity of out-
put.  
In meeting the requirements of this particular 
use case a number of challenges have had to be 
met. Principally, these challenges have been fo-
cused upon processing speed and output text 
quality. While we have managed to achieve the 
required processing performance relatively 
quickly without the need for large amounts of 
computing resources or high-end computing in-
frastructure, ensuring the necessary output quali-
ty has been a longer process due to the high op-
erating standards required and the high resource 
cost of quality assurance when delivering texts at 
such scale.    
This application of NLG technology to site-
specific weather forecasting has potential for a 
number of enhancements to the type of weather 
services that may be provided in the future, most 
notably the opportunity for very geographically 
localized textual forecasts that can be updated 
immediately as the underlying numerical weather 
prediction data is produced.   
References 
E. Goldberg, N. Driedger, and R. Kittredge. 
Using Natural-Language Processing to Produce 
Weather Forecasts. 
IEEE Expert, 9(2):45--53, 1994. 
J. Coch. Interactive generation and knowledge admin-
istration in MultiMeteo.  
In Proceedings of the Ninth International Work-
shop on Natural Language Generation, pages 300--
303, Niagara-on-the-lake, Ontario, Canada, 1998. 
software demonstration. 
Bateman J and Zock M, (2012) Bateman/Zock list of 
NLG systems, http://www.nlg-wiki.org/systems/. 
S. Sripada, E. Reiter, and I. Davy, (2003a) 
?SumTime-Mousam: Configurable Marine Weather 
Forecast Generator?, Expert Update, 6(3), pp 4-10, 
(2003)  
S. Sripada, E. Reiter, J. Hunter and J. Yu (2003b). 
Generating English Summaries of Time Series Da-
ta using the Gricean Maxims. In Proceedings of 
KDD 2003, pp 187-196. 
E. Reiter, S. Sripada, J. Hunter, J. Yu and Ian Davy 
(2005). Choosing Words in Computer-Generated 
Weather Forecasts. Artificial Intelligence. 167(1-
2):137-169 
E. Reiter (2007). An architecture for data-to-text sys-
tems, In ENLG 07, pp97-104. 
Reiter, Ehud and Williams, Sandra (2010). Generating 
texts in different styles. In: Argamon, Shlomo; 
Burns, Kevin and Dubnov, Shlomo eds. The Struc-
ture of Style: Algorithmic Approaches to Manner 
and Meaning. Heidelberg: Springer, pp. 59?78 
E. Reiter, S. Sripada, J. Hunter, J. Yu, and Ian Da-
vy(2005). Choosing words in computer-generated 
weather forecasts. Artificial Intelligence. 167(1-
2):137-169 (2005) 
R. Turner, S. Sripada, E. Reiter, & I. Davy  
(2008). Using spatial reference frames to generate 
grounded textual summaries of geo-referenced da-
ta. Proceedings of the INLG 2008, Salt Fork, Ohio. 
5
