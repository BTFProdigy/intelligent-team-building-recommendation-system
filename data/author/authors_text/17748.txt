Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 1?6,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
Workshop on Hybrid Approaches to Translation:
Overview and Developments
Marta R. Costa-jussa`, Rafael E. Banchs
Institute for Infocomm Research1
Patrik Lambert
Barcelona Media3
Kurt Eberle
Lingenio GmbH4
Reinhard Rapp
Aix-Marseille Universite?, LIF2
Bogdan Babych
University of Leeds5
1{vismrc,rembanchs}@i2r.a-star.edu.sg, 2reinhardrapp@gmx.de,
3patrik.lambert@barcelonamedia.org, 4k.eberle@lingenio.de,
5b.babych@leeds.ac.uk
Abstract
A current increasing trend in machine
translation is to combine data-driven and
rule-based techniques. Such combinations
typically involve the hybridization of dif-
ferent paradigms such as, for instance,
the introduction of linguistic knowledge
into statistical paradigms, the incorpora-
tion of data-driven components into rule-
based paradigms, or the pre- and post-
processing of either sort of translation sys-
tem outputs. Aiming at bringing together
researchers and practitioners from the dif-
ferent multidisciplinary areas working in
these directions, as well as at creating a
brainstorming and discussion venue for
Hybrid Translation approaches, the Hy-
Tra initiative was born. This paper gives
an overview of the Second Workshop on
Hybrid Approaches to Translation (HyTra
2013) concerning its motivation, contents
and outcomes.
1 Introduction
Machine translation (MT) has continuously been
evolving from different perspectives. Early sys-
tems were basically dictionary-based. These ap-
proaches were further developed to more complex
systems based on analysis, transfer and genera-
tion. The objective was to climb up (and down)
in the well-known Vauquois pyramid (see Figure
1) to facilitate the transfer phase or to even mini-
mize the transfer by using an interlingua system.
But then, corpus-based approaches irrupted, gen-
erating a turning point in the field by putting aside
the analysis, generation and transfer phases.
Although there had been such a tendency right
from the beginning (Wilks, 1994), in the last
Figure 1: Vauquois pyramid (image from
Wikipedia).
years, the corpus-based approaches have reached
a point where many researchers assume that rely-
ing exclusively on data might have serious limi-
tations. Therefore, research has focused either on
syntactical/hierarchical-based methods or on try-
ing to augment the popular phrase-based systems
by incorporating linguistic knowledge. In addi-
tion, and given the fact that research on rule-based
has never stopped, there have been several propos-
als of hybrid architectures combining both rule-
based and data-driven approaches.
In summary, there is currently a clear trend to-
wards hybridization, with researchers adding mor-
phological, syntactic and semantic knowledge to
statistical systems, as well as combining data-
driven methods with existing rule-based systems.
In this paper we provide a general overview
of current approaches to hybrid MT within the
context of the Second Workshop on Hybrid Ap-
proaches to Translation (HyTra 2013). In our
overview, we classify hybrid MT approaches ac-
cording to the linguistic levels that they address.
We then briefly summarize the contributions pre-
sented and collected in this volume.
1
The paper is organized as follows. First, we mo-
tivate and summarize the main aspects of the Hy-
Tra initiative. Then, we present a general overview
of the accepted papers and discuss them within
the context of other state-of-the-art research in the
area. Finally, we present our conclusions and dis-
cuss our proposed view of future directions for
Hybrid MT research.
2 Overview of the HyTra Initiative
The HyTra initiative started in response to the in-
creasing interest in hybrid approaches to machine
translation, which is reflected on the substantial
amount of work conducted on this topic. An-
other important motivation was the observation
that, up to now, no single paradigm has been able
to successfully solve to a satisfactory extent all of
the many challenges that the problem of machine
translation poses.
The first HyTra workshop took part in conjunc-
tion with the EACL 2012 conference (Costa-jussa`
et al, 2012). The Second HyTra Workshop, which
was co-organized by the authors of this paper, has
been co-located with the ACL 2013 conference
(Costa-jussa` et al, 2013). The workshop has been
supported by an extensive programme committee
comprising members from over 30 organizations
and representing more than 20 countries. As the
outcome of a comprehensive peer reviewing pro-
cess, and based on the recommendations of the
programme committee, 15 papers were finally se-
lected for either oral or poster presentation at the
workshop.
The workshop also had the privilege to be hon-
ored by two exceptional keynote speeches:
? Controlled Ascent: Imbuing Statistical MT
with Linguistic Knowledge by Will Lewis and
Chris Quirk (2013), Microsoft research. The
intersection of rule-based and statistical ap-
proaches in MT is explored, with a particular
focus on past and current work done at Mi-
crosoft Research. One of their motivations
for a hybrid approach is the observation that
the times are over when huge improvements
in translation quality were possible by sim-
ply adding more data to statistical systems.
The reason is that most of the readily avail-
able parallel data has already been found.
? How much hybridity do we have? by Her-
mann Ney, RWTH Aachen. It is pointed
out that after about 25 years the statistical
approach to MT has been widely accepted
as an alternative to the classical approach
with manually designed rules. But in prac-
tice most statistical MT systems make use
of manually designed rules at least for pre-
processing in order to improve MT quality.
This is exemplified by looking at the RWTH
MT systems.
3 Hybrid Approaches Organized by
Linguistic Levels
?Hybridization? of MT can be understood as com-
bination of several MT systems (possibly of very
different architecture) where the single systems
translate in parallel and compete for the best re-
sult (which is chosen by the integrating meta sys-
tem). The workshop and the papers do not fo-
cus on this ?coarse-grained? hybridization (Eisele
et al, 2008), but on a more ?fine grained? one
where the systems mix information from differ-
ent levels of linguistic representations (see Fig-
ure 2). In the past and mostly in the framework
of rule-based machine translation (RBMT) it has
been experimented with information from nearly
every level including phonetics and phonology
for speech recognition and synthesis in speech-
to-speech systems (Wahlster, 2000) and includ-
ing pragmatics for dialog translation (Batliner et
al., 2000a; Batliner et al, 2000b) and text coher-
ence phenomena (Le Nagard and Koehn, 2010).
With respect to work with emphasis on statisti-
cal machine translation (SMT) and derivations of
it mainly those information levels have been used
that address text in the sense of sets of sentences.
As most of the workshop papers relate to this
perspective - i.e. on hybridization which is de-
fined using SMT as backbone, in this introduc-
tion we can do with distinguishing between ap-
proaches focused on morphology, syntax, and se-
mantics. There are of course approaches which
deal with more than one of these levels in an in-
tegrated manner, which are commonly refered to
as multilevel approaches. As the case of treat-
ing syntax and morphology concurrently is espe-
cially common, we also consider morpho-syntax
as a separate multilevel approach.
3.1 Morphological approaches
The main approaches of statistical MT that ex-
ploit morphology can be classified into segmen-
tation, generation, and enriching approaches. The
2
Figure 2: Major linguistic levels (image from
Wikipedia).
first one attempts to minimize the vocabulary of
highly inflected languages in order to symmetrize
the (lexical granularity of the) source and the tar-
get language. The second one assumes that, due
to data sparseness, not all morphological forms
can be learned from parallel corpora and, there-
fore, proposes techniques to learn new morpho-
logical forms. The last one tries to enrich poorly
inflected languages to compensate for their lack of
morphology. In HyTra 2013, approaches treating
morphology were addressed by the following con-
tributions:
? Toral (2013) explores the selection of data to
train domain-specific language models (LM)
from non-domain specific corpora by means
of simplified morphology forms (such as
lemmas). The benefit of this technique is
tested using automatic metrics in the English-
to-Spanish task. Results show an improve-
ment of up to 8.17% of perplexity reduction
over the baseline system.
? Rios Gonzalez and Goehring (2013) propose
machine learning techniques to decide on the
correct form of a verb depending on the con-
text. Basically they use tree-banks to train the
classifiers. Results show that they are able
to disambiguate up to 89% of the Quechua
verbs.
3.2 Syntactic approaches
Syntax had been addressed originally in SMT in
the form of so called phrase-based SMT with-
out any reference to linguistic structures; during
the last decade (or more) the approach evolved
to or, respectively, was complemented by - work
on syntax-based models in the linguistic sense of
the word. Most such approaches can be classi-
fied into three different types of architecture that
are defined by the type of syntactic analysis used
for the source language and the type of generation
aimed at for the target language: tree-to-tree, tree-
to-string and string-to-tree. Additionally, there
are also the so called hierarchical systems, which
combine the phrase-based and syntax-based ap-
proaches by using phrases as translation-units and
automatically generated context free grammars as
rules. Approaches dealing with the syntactic ap-
proach in HyTra 2013 include the following pa-
pers:
? Green and Zabokrtsky? (2013) study three dif-
ferent ways to ensemble parsing techniques
and provide results in MT. They compute cor-
relations between parsing quality and transla-
tion quality, showing that NIST is more cor-
related than BLEU.
? Han et al (2013) provide a framework for
pre-reordering to make Chinese word order
more similar to Japanese. To this purpose,
they use unlabelled dependency structures of
sentences and POS tags to identify verbal
blocks and move them from after-the-object
positions (SVO) to before-the-object posi-
tions (SOV).
? Nath Patel et al (2013) also propose a pre-
reordering technique, which uses a limited
set of rules based on parse-tree modification
rules and manual revision. The set of rules is
specifically listed in detail.
? Saers et al (2013) report an unsupervised
learning model that induces phrasal ITGs by
breaking rules into smaller ones using mini-
mum description length. The resulting trans-
lation model provides a basis for generaliza-
tion to more abstract transduction grammars
with informative non-terminals.
3.3 Morphosyntactical approaches
In linguistic theories, morphology and syntax are
often considered and represented simultaneously
(not only in unification-based approaches) and the
same is true for MT systems.
3
? Laki et al (2013) combine pre-reordering
rules with morphological and factored mod-
els for English-to-Turkish.
? Li et al (2013) propose pre-reordering rules
to be used for alignment-based reordering,
and corresponding POS-based restructuring
of the input. Basically, they focus on tak-
ing advantage of the fact that Korean has
compound words, which - for the purpose of
alignment - are split and reordered similarly
to Chinese.
? Turki Khemakhem et al (2013) present
work about an English-Arabic SMT sys-
tem that uses morphological decomposition
and morpho-syntactic annotation of the target
language and incorporates the correspond-
ing information in a statistical feature model.
Essentially, the statistical feature language
model replaces words by feature arrays.
3.4 Semantic approaches
The introduction of semantics in statistical MT has
been approached to solve word sense disambigua-
tion challenges covering the area of lexical seman-
tics and, more recently, there have been different
techniques using semantic roles covering shallow
semantics, as well as the use of distributional se-
mantics for improving translation unit selection.
Approaches treating the incorporation of seman-
tics into MT in HyTra 2013 include the following
research work:
? Rudnick et al (2013) present a combina-
tion of Maximum Entropy Markov Models
and HMM to perform lexical selection in
the sense of cross-lingual word sense disam-
biguation (i.e. by choice from the set of trans-
lation alternatives). The system is meant to
be integrated into a RBMT system.
? Boujelbane (2013) proposes to build a bilin-
gual lexicon for the Tunisian dialect us-
ing modern standard Arabic (MSA). The
methodology is based on leveraging the large
available annotated MSA resources by ex-
ploiting MSA-dialect similarities and ad-
dressing the known differences. The author
studies morphological, syntactic and lexical
differences by exploiting Penn Arabic Tree-
bank, and uses the differences to develop
rules and to build dialectal concepts.
? Bouillon et al (2013) presents two method-
ologies to correct homophone confusions.
The first one is based on hand-coded rules
and the second one is based on weighted
graphs derived from a pronunciation re-
source.
3.5 Other multilevel approaches
In a number of linguistic theories information
from the morphological, syntactic and semantic
level is considered conjointly and merged in cor-
responding representations (a RBMT example is
LFG (Lexical Functional Grammars) analysis and
the corresponding XLE translation architecture).
In HyTra 2013 there are three approaches dealing
with multilevel information:
? Pal et al (2013) propose a combination of
aligners: GIZA++, Berkeley and rule-based
for English-Bengali.
? Hsieh et al (2013) use comparable corpora
extracted from Wikipedia to extract parallel
fragments for the purpose of extending an
English-Bengali training corpus.
? Tambouratzis et al (2013) describe a hybrid
MT architecture that uses very few bilingual
corpus and a large monolingual one. The
linguistic information is extracted using
pattern recognition techniques.
Table 1 summarizes the papers that have been
presented in the Second HyTra Workshop. The
papers are arranged into the table according to the
linguistic level they address.
4 Conclusions and further work
The success of the Second HyTra Workshop con-
firms that research in hybrid approaches to MT
systems is a very active and promising area. The
MT community seems to agree that pure data-
driven or rule-based paradigms have strong lim-
itations and that hybrid systems are a promising
direction to overcome most of these limitations.
Considerable progress has been made in this area
recently, as demonstrated by consistent improve-
ments for different language pairs and translation
tasks.
The research community is working hard, with
strong collaborations and with more resources at
hand than ever before. However, it is not clear
4
Morphological (Toral, 2013) Hybrid Selection of LM Training Data Using Linguistic Information and Perplexity
(Gonzales and Goehring, 2013) Machine Learning disambiguation of Quechua verb morphology
Syntax (Green and Zabokrtsky?, 2013) Improvements to SBMT using Ensemble Dependency Parser
(Han et al, 2013) Using unlabeled dependency parsing for pre-reordering for Chinese-to-Japanese SMT
(Patel et al, 2013) Reordering rules for English-Hindi SMT
(Saers et al, 2013) Unsupervised transduction grammar induction via MDL
Morpho-syntactic (Laki et al, 2013) English to Hungarian morpheme-based SMT system with reordering rules
(Li et al, 2013) Experiments with POS-based restructuring and alignment based reordering for SMT
(Khemakhem et al, 2013) Integrating morpho-syntactic feature for English Arabic SMT
Semantic (Rudnick and Gasser, 2013) Lexical Selection for Hybrid MT with Sequence Labeling
(Boujelbane et al, 2013) Building bilingual lexicon to create dialect Tunisian corpora and adapt LM
(Bouillon et al, 2013) Two approaches to correcting homophone confusions in a hybrid SMT based system
Multilevels (Pal et al, 2013) A hybrid Word alignment model for PBSMT
(Hsieh et al, 2013) Uses of monolingual in-domain corpora for cross-domain adaptation with hybrid MT approaches
(Tambouratzis et al, 2013) Overview of a language-independent hybrid MT methodology
Table 1: HyTra 2013 paper overview.
whether technological breakthroughs as in the past
are still possible are still possible, or if MT will be
turning into a research field with only incremen-
tal advances. The question is: have we reached
the point at which only refinements to existing ap-
proaches are needed? Or, on the contrary, do we
need a new turning point?
Our guess is that, similar to the inflection point
giving rise to the statistical MT approach during
the last decade of the twentieth century, once again
there might occur a new discovery which will rev-
olutionize further the research on MT. We cannot
know whether hybrid approaches will be involved;
but, in any case, this seems to be a good and smart
direction as it is open to the full spectrum of ideas
and, thus, it should help to push the field forward.
Acknowledgments
This workshop has been supported by the Sev-
enth Framework Program of the European Com-
mission through the Marie Curie actions HyghTra,
IMTraP, AutoWordNet and CrossLingMind and
the Spanish ?Ministerio de Econom??a y Competi-
tividad? and the European Regional Development
Fund through SpeechTech4all. We would like to
thank the funding institution and all people who
contributed towards making the workshop a suc-
cess. For a more comprehensive list of acknowl-
edgments refer to the preface of this volume.
References
Anton Batliner, J. Buckow, Heinrich Niemann, Elmar
No?th, and Volker Warnke, 2000a. The Prosody
Module, pages 106?121. New York, Berlin.
Anton Batliner, Richard Huber, Heinrich Niemann, El-
mar No?th, Jo?rg Spilker, and K. Fischer, 2000b. The
Recognition of Emotion, pages 122?130. New York,
Berlin.
Pierrette Bouillon, Johanna Gerlach, Ulrich Germann,
Barry Haddow, and Manny Rayner. 2013. Two ap-
proaches to correcting homophone confusions in a
hybrid machine translation system. In ACL Work-
shop on Hybrid Machine Approaches to Translation,
Sofia.
Rahma Boujelbane, Mariem Ellouze khemekhem, Si-
war BenAyed, and Lamia HadrichBelguith. 2013.
Building bilingual lexicon to create dialect tunisian
corpora and adapt language model. In ACL Work-
shop on Hybrid Machine Approaches to Translation,
Sofia.
Marta R. Costa-jussa`, Patrik Lambert, Rafael E.
Banchs, Reinhard Rapp, and Bogdan Babych, edi-
tors. 2012. Proceedings of the Joint Workshop on
Exploiting Synergies between Information Retrieval
and Machine Translation (ESIRMT) and Hybrid Ap-
proaches to Machine Translation (HyTra). As-
sociation for Computational Linguistics, Avignon,
France, April.
Marta R. Costa-jussa`, Patrik Lambert, Rafael E.
Banchs, Reinhard Rapp, Bogdan Babych, and Kurl
Eberle, editors. 2013. Proceedings of the Sec-
ond Workshop on Hybrid Approaches to Translation
(HyTra). Association for Computational Linguis-
tics, Sofia, Bulgaria, August.
Andreas Eisele, Christian Federmann, Hans Uszkoreit,
Herve? Saint-Amand, Martin Kay, Michael Jelling-
haus, Sabine Hunsicker, Teresa Herrmann, and
Yu Chen. 2008. Hybrid machine translation archi-
tectures within and beyond the euromatrix project.
In John Hutchins and Walther v.Hahn, editors, 12th
annual conference of the European Association for
Machine Translation (EAMT), pages 27?34, Ham-
burg, Germany.
Annette Rios Gonzales and Anne Goehring. 2013.
Machine learning disambiguation of quechua verb
morphology. In ACL Workshop on Hybrid Machine
Approaches to Translation, Sofia.
Nathan Green and Zdenek Zabokrtsky?. 2013. Im-
provements to syntax-based machine translation us-
ing ensemble dependency parsers. In ACL Work-
shop on Hybrid Machine Approaches to Translation,
Sofia.
5
Dan Han, Pascual Martinez-Gomez, Yusuke Miyao,
Katsuhito Sudoh, and Masaaki NAGATA. 2013.
Using unlabeled dependency parsing for pre-
reordering for chinese-to-japanese statistical ma-
chine translation. In ACL Workshop on Hybrid Ma-
chine Approaches to Translation, Sofia.
An-Chang Hsieh, Hen-Hsen Huang, and Hsin-Hsi
Chen. 2013. Uses of monolingual in-domain cor-
pora for cross-domain adaptation with hybrid mt ap-
proaches. In ACL Workshop on Hybrid Machine Ap-
proaches to Translation, Sofia.
Ines Turki Khemakhem, Salma Jamoussi, and Abdel-
majid Ben Hamadou. 2013. Integrating morpho-
syntactic feature in english-arabic statistical ma-
chine translation. In ACL Workshop on Hybrid Ma-
chine Approaches to Translation, Sofia.
La?szlo? Laki, Attila Novak, and Borba?la Siklo?si. 2013.
English to hungarian morpheme-based statistical
machine translation system with reordering rules. In
ACL Workshop on Hybrid Machine Approaches to
Translation, Sofia.
Ronan Le Nagard and Philipp Koehn. 2010. Aiding
pronoun translation with co-reference resolution. In
Proceedings of the Joint Fifth Workshop on Statisti-
cal Machine Translation and MetricsMATR, pages
252?261, Uppsala, Sweden, July. Association for
Computational Linguistics.
Will Lewis and Chris Quirk. 2013. Controlled ascent:
Imbuing statistical mt with linguistic knowledge. In
ACL Workshop on Hybrid Machine Approaches to
Translation, Sofia.
Shuo Li, Derek F. Wong, and Lidia S. Chao.
2013. Experiments with pos-based restructuring and
alignment-based reordering for statistical machine
translation. In ACL Workshop on Hybrid Machine
Approaches to Translation, Sofia.
Santanu Pal, Sudip Naskar, and Sivaji Bandyopadhyay.
2013. A hybrid word alignment model for phrase-
based statistical machine translation. In ACL Work-
shop on Hybrid Machine Approaches to Translation,
Sofia.
Raj Nath Patel, Rohit Gupta, Prakash B. Pimpale, and
Sasikumar M. 2013. Reordering rules for english-
hindi smt. In ACL Workshop on Hybrid Machine
Approaches to Translation, Sofia.
Alex Rudnick and Michael Gasser. 2013. Lexical se-
lection for hybrid mt with sequence labeling. In ACL
Workshop on Hybrid Machine Approaches to Trans-
lation, Sofia.
Markus Saers, Karteek Addanki, and Dekai Wu. 2013.
Unsupervised transduction grammar induction via
minimum description length. In ACL Workshop on
Hybrid Machine Approaches to Translation, Sofia.
George Tambouratzis, Sokratis Sofianopoulos, and
Marina Vassiliou. 2013. Language-independent hy-
brid mt with presemt. In ACL Workshop on Hybrid
Machine Approaches to Translation, Sofia.
Antonio Toral. 2013. Hybrid selection of language
model training data using linguistic information and
perplexity. In ACL Workshop on Hybrid Machine
Approaches to Translation, Sofia.
Wolfgang Wahlster, editor. 2000. Verbmobil: Foun-
dations of Speech-to-Speech Translation. Springer,
Berlin, Heidelberg, New York.
Yorick Wilks. 1994. Stone soup and the french
room: The empiricist-rationalist debate about ma-
chine translation. Current Issues in Computational
Linguistics: in honor of Don Walker, pages 585?
594. Pisa, Italy: Giardini / Dordrecht, The Nether-
lands: Kluwer Academic.
6
Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 1?9,
Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational Linguistics
Meaning Unit Segmentation in English and Chinese: a New Approach toDiscourse PhenomenaJennifer Williams ?1,2, Rafael Banchs2, and Haizhou Li2
1Department of Linguistics, Georgetown University, Washington, D.C., USA
2Institute for Infocomm Research, 1 Fusionpolis Way, Singaporejaw97@georgetown.edu {rembanchs,hli}@i2r.a-star.edu.sgAbstract
We present a new approach to dialogue
processing in terms of ?meaning units?. In
our annotation task, we asked speakers of
English and Chinese to mark boundaries
where they could construct the maximal
concept using minimal words. We com-
pared English data across genres (news,
literature, and policy). We analyzed the
agreement for annotators using a state-of-
the-art segmentation similarity algorithm
and compared annotations with a random
baseline. We found that annotators are
able to identify meaning units systemati-
cally, even though they may disagree on
the quantity and position of units. Our
analysis includes an examination of phrase
structure for annotated units using con-
stituency parses.1 Introduction
When humans translate and interpret speech in
real-time, they naturally segment speech in ?min-
imal sense units? (Ole?ron & Nanpon, 1965;
Ben??tez & Bajo, 1998) in order to convey the
same information from one language to another as
though there were a 1-to-1 mapping of concepts
between both languages. Further, it is known that
people can hold up to 7+/- 2 ?chunks? of informa-
tion in memory at a time by creating and applying
meaningful organization schemes to input (Miller,
1956). However, there is no definitive linguistic
description for the kind of ?meaning units? that
human translators create (Signorelli et al, 2011;
Hamon et al, 2009; Mima et al, 1998).
The ability to chunk text according to units of
meaning is key to developing more sophisticated
machine translation (MT) systems that operate in
? Now affiliated with Massachusetts Institute of Tech-
nology Lincoln Laboratory.
real-time, as well as informing discourse process-
ing and natural language understanding (NLU)
(Kola?r?, 2008). We present an approach to dis-
course phenomena to address Keller?s (2010) call
to find a way to incorporate ?cognitive plausibil-
ity? into natural language processing (NLP) sys-
tems. As it has been observed that human trans-
lators and interpreters naturally identify a certain
kind of ?meaning unit? when translating speech
in real-time (Ole?ron & Nanpon, 1965; Ben??tez &
Bajo, 1998), we want to uncover the features of
those units in order to automatically identify them
in discourse.
This paper presents an experimental approach
to annotating meaning units using human anno-
tators from Mechanical Turk. Our goal was to
use the results of human judgments to inform
us if there are salient features of meaning units
in English and Chinese text. We predicted that
human-annotated meaning units should systemat-
ically correspond to some other linguistic features
or combinations of those features (i.e. syntax,
phrase boundaries, segments between stop words,
etc.). We are interested in the following research
questions:
? At what level of granularity do English and
Chinese speakers construct meaning units in
text?
? Do English and Chinese speakers organize
meaning units systematically such that mean-
ing unit segmentations are not random?
? How well do English and Chinese speakers
agree on meaning unit boundaries?
? Are there salient syntactic features of mean-
ing units in English and Chinese?
? Can we automatically identify a 1-to-1 map-
ping of concepts for parallel text, even if there
is paraphrasing in one or both languages?
1
While we have not built a chunker or classifier
for meaning unit detection, it is our aim that this
work will inform how to parse language system-
atically in a way that is human-understandable. It
remains to be seen that automatic tools can be de-
veloped to detect meaning units in discourse. Still,
we must be informed as to what kinds of chunks
are appropriate for humans to allow them to under-
stand information transmitted during translation
(Kola?r?, 2008). Knowledge about meaning units
could be important for real-time speech process-
ing, where it is not always obvious where an ut-
terance begins and ends, due to any combination
of natural pauses, disfluencies and fillers such as
?like, um..?. We believe this work is a step towards
creating ultra-fast human-understandable simulta-
neous translation systems that can be used for con-
versations in different languages.
This paper is organized as follows: Section 2
discusses related work, Section 3 describes the
segmentation similarity metric that we used for
measuring annotator agreement, Section 4 de-
scribes our experiment design, Section 5 shows
experiment results, Section 6 provides analysis,
and Section 7 discusses future work.2 Related Work
At the current state of the art, automatic simultane-
ous interpretation systems for speech function too
slowly to allow people to conduct normal-paced
conversations in different languages. This prob-
lem is compounded by the difficulty of identifying
meaningful endpoints of utterances before trans-
mitting a translation. For example, there is a per-
ceived lag time for speakers when trying to book
flights or order products over the phone. This lag
time diminishes conversation quality since it takes
too long for each speaker to receive a translation
at either end of the system (Paulik et al, 2009). If
we can develop a method to automatically identify
segments of meaning as they are spoken, then we
could significantly reduce the perceived lag time
in real-time speech-to-speech translation systems
and improve conversation quality (Baobao et al,
2002; Hamon et al, 2009).
The problem of absence of correspondence
arises when there is a lexical unit (single words
or groups of words) that occurs in L1 but not
in L2 (Lambert et al, 2005). It happens when
words belonging to a concept do not correspond to
phrases that can be aligned in both languages. This
problem is most seen when translating speech-to-
speech in real-time. One way to solve this prob-
lem is to identify units for translation that cor-
respond to concepts. A kind of meaning unit
had been previously proposed as information units
(IU), which would need to be richer than seman-
tic roles and also be able to adjust when a mis-
take or assumption is realized (Mima et al, 1998).
These units could be used to reduce the explosion
of unresolved structural ambiguity which happens
when ambiguity is inherited by a higher level syn-
tactic structure, similar to the use of constituent
boundaries for transfer-driven machine translation
(TDMT) (Furuse et al, 1996).
The human ability to construct concepts in-
volves both bottom-up and top-down strategies in
the brain. These two kinds of processes inter-
act and form the basis of comprehension (Kintsch,
2005). The construction-integration model (CI-2)
describes how meaning is constructed from both
long-term memory and short-term memory. One
of the challenges of modeling meaning is that it
requires a kind of world-knowledge or situationalknowledge, in addition to knowing the meanings
of individual words and knowing how words can
be combined. Meaning is therefore constructed
from long-term memory ? as can be modeled by
latent semantic analysis (LSA) ? but also from
short-term memory which people use in the mo-ment (Kintsch & Mangalath, 2011). In our work,
we are asking annotators to construct meaning
from well-formed text and annotate where units of
meaning begin and end.3 Similarity Agreement
We implemented segmentation similarity (S) from
Fournier and Inkpen (2012). Segmentation sim-
ilarity was formulated to address some gaps of
the WindowDiff (WD) metric, including unequal
penalty for errors as well as the need to add
padding to the ends of each segmentation (Pevzner
& Hearst, 2002). There are 3 types of segmenta-
tion errors for (S), listed below:
1. s1 contains a boundary that is off by n poten-
tial boundaries in s2
2. s1 contains a boundary that s2 does not, or
3. s2 contains a boundary that s1 does not
These three types of errors are understood astranspositions in the case of error type 1, and as
2
substitutions in the case of error types 2 and 3.
Note that there is no distinction between insertions
and deletions because neither of the segmentations
are considered reference or hypothesis. We show
the specification of (S) in (1):
S(si1,si2) =
t ? mass(i)  t  d(si1,si2,T )
t ? mass(i)  t
(1)
such that S scales the cardinality of the set of
boundary types t because the edit distance func-
tion d(si1,si2,T ) will return a value for potential
boundaries of [0, t ? mass(i)] normalized by the
number of potential boundaries per boundary type.
The value of mass(i) depends on task, in our
work we treat mass units as number of words, for
English, and number of characters for Chinese.
Since our annotators were marking only units of
meaning, there was only one boundary type, and
(t = 1). The distance function d(si1,si2,T ) is the
edit distance between segments calculated as the
number of boundaries involved in transposition
operations subtracted from the number of substi-
tution operations that could occur. A score of 1.0
indicates full agreement whereas a score of 0 indi-
cates no agreement.
In their analysis and comparison of this new
metric, Fournier and Inkpen (2012) demonstrated
the advantages of using (S) over using (WD)
for different kinds of segmentation cases such
as maximal/minimal segmentation, full misses,
near misses, and segmentation mass scale effects.
They found that in each of these cases (S) was
more stable than (WD) over a range of segment
sizes. That is, when considering different kinds
of misses (false-positive, false-negative, and both),
the metric (S) is less variable to internal segment
size. These are all indications that (S) is a more
reliable metric than (WD).
Further, (S) properly takes into account chance
agreement - called coder bias - which arises in
segmentation tasks when human annotators either
decide not to place a boundary at all, or are un-
sure if a boundary should be placed. Fournier and
Inkpen (2012) showed that metrics that follow (S)
specification reflect most accurately on coder bias,
when compared to mean pairwise 1   WD met-
rics. Therefore we have decided to use segmenta-
tion similarity as a metric for annotator agreement.
4 Experiment Design
This section describes how we administered our
experiment as an annotation task. We surveyed
participants using Mechanical Turk and presented
participants with either English or Chinese text.
While the ultimate goal of this research direc-
tion is to obtain meaning unit annotations for
speech, or transcribed speech, we have used well-
structured text in our experiment in order to find
out more about the potential features of meaning
units in the simplest case.4.1 Sample Text PreparationGenre: Our text data was selected from three dif-
ferent genres for English (news, literature, and
policy) and one genre for Chinese (policy). We
used 10 articles from the Universal Declaration of
Human Rights (UDHR) in parallel for English and
Chinese. The English news data (NEWS) con-
sisted of 10 paragraphs that were selected online
from www.cnn.com and reflected current events
from within the United States. The English liter-
ature data (LIT) consisted of 10 paragraphs from
the novel Tom Sawyer by Mark Twain. The En-
glish and Chinese UDHR data consisted of 12 par-
allel paragraphs from the Universal Declaration of
Human Rights. The number of words and number
of sentences by language and genre is presented
below in Table 1.Preprocessing: To prepare the text samples for
annotation, we did some preprocessing. We re-
moved periods and commas in both languages,
since these markings can give structure and mean-
ing to the text which could influence annotator de-
cisions about meaning unit boundaries. For the
English data, we did not fold to lowercase and we
acknowledge that this was a design oversight. The
Chinese text was automatically segmented into
words before the task using ICTCLAS (Zhang et
al., 2003). This was done in order to encourage
Chinese speakers to look beyond the character-
level and word-level, since word segmentation is
a well-known NLP task for the Chinese language.
The Chinese UDHR data consisted of 856 charac-
ters. We placed checkboxes between each word in
the text.4.2 Mechanical Turk Annotation
We employed annotators using Amazon Mechan-
ical Turk Human Intelligence Tasks (HITs). All
instructions for the task were presented in En-
3
Language and Genre # words # Sentences
Chinese UDHR 485 20
English NEWS 580 20
English LIT 542 27
English UDHR 586 20
Table 1: Number of words and sentences by lan-
guage and genre.
glish. Each participant was presented with a set of
numbered paragraphs with a check-box between
each word where a boundary could possibly ex-
ist. In the instructions, participants were asked
to check the boxes between words correspond-
ing to the boundaries of meaning units. They
were instructed to create units of meaning larger
than words but that are also the ?maximal concept
that you can construct that has the minimal set of
words that can be related to each individual con-
cept?1. We did not provide marked examples to
the annotators so as to avoid influencing their an-
notation decisions.
Participants were given a maximum of 40 min-
utes to complete the survey and were paid USD
$1.00 for their participation. As per Amazon
Mechanical Turk policy, each of the participants
were at least 18 years of age. The annotation
task was restricted to one task per participant, in
other words if a participant completed the English
NEWS annotation task then they could not partic-
ipate in the Chinese UDHR task, etc. We did not
test any of the annotators for language aptitude
or ability, and we did not survey language back-
ground. It is possible that for some annotators,
English and Chinese were not a native language.5 Results
We omitted survey responses for which partici-
pants marked less than 30 boundaries total, as well
as participants who completed the task in less than
5 minutes. We did this in an effort to eliminate
annotator responses that might have involved ran-
dom marking of the checkboxes, as well as those
who marked only one or two checkboxes. We de-
cided it would be implausible that less than 30
boundaries could be constructed, or that the task
1The definition of ?meaning units? we provide is very am-
biguous and can justify for different people understanding the
task differently. However, this is part of what we wanted to
measure, as giving a more precise and operational definition
would bias people to some specific segmentation criteria.
could be completed in less than 5 minutes, con-
sidering that there were several paragraphs and
sentences for each dataset. After we removed
those responses, we had solicited 47 participants
for English NEWS, 40 participants for English
LIT, 59 participants for English UDHR, and 10
participants for Chinese UDHR. The authors ac-
knowledge that the limited sample size for Chi-
nese UDHR data does not allow a direct compar-
ison across the two languages, however we have
included it in results and analysis as supplemental
findings and encourage future work on this task
across multiple languages. We are unsure as to
why there was a low number of Chinese annota-
tors in this task, except perhaps the task was not as
accessible to native Chinese speakers because the
task instructions were presented in English.5.1 Distributions by Genre
We show distributions of number of annotators
and number of units identified for each language
and genre in Figures 1 ? 4. For each of the
language/genres, we removed one annotator be-
cause the number of units that they found was
greater than 250, which we considered to be
an outlier in our data. We used the Shapiro-
Wilk Test for normality to determine which, if
any, of these distributions were normally dis-
tributed. We failed to reject the null hypothesis for
Chinese UDHR (p = 0.373) and English NEWS
(p = 0.118), and we rejected the null hypothe-
sis for English LIT (p = 1.8X10 04) and English
UDHR (p = 1.39X10 05).Dataset N Avg AvgUnits Words/Unit
Chinese UDHR 9 70.1 ?
English NEWS 46 84.9 6.8
English LIT 39 85.4 6.3
English LIT G1 26 66.9 8.1
English LIT G2 13 129.0 4.2
English UDHR 58 90.1 6.5
English UDHR G1 17 52.2 11.2
English UDHR G2 19 77.3 7.6
English UDHR G3 22 132.2 4.4
Table 2: Number of annotators (N), average num-
ber of units identified, average number of words
per unit identified, by language and genre.
Since the number of units were not normally
distributed for English LIT and English UDHR,
4
Figure 1: Distribution of total number of annota-
tions per annotator for Chinese UDHR.
Figure 2: Distribution of total number of annota-
tions per annotator for English UDHR.
Figure 3: Distribution of total number of annota-
tions per annotator for English NEWS.
we used 2-sample Kolmogorov-Smirnov (KS)
Tests to identify separate distributions for each of
these genres. We found 3 distinct groups in En-
glish UDHR (G1?G3) and 2 distinct groups in En-
glish LIT (G1 and G2). Table 2 provides more
Figure 4: Distribution of total number of annota-
tions per annotator for English LIT.
detailed information about distributions for num-
ber of annotations, as well as the average number
of units found, and average words per unit. This
information informs us as to how large or small
on average the meaning units are. Note that in Ta-
ble 2 we include information for overall English
UDHR and overall English LIT distributions for
reference. The authors found it interesting that,
from Table 2, the number of words per meaning
unit generally followed the 7 +/- 2 ?chunks? phe-
nomenon, where chunks are words.5.2 Annotator Agreement
Even though some of the annotators agreed about
the number of units, that does not imply that
they agreed on where the boundaries were placed.
We used segmentation similarity (S) as a metric
for annotator agreement. The algorithm requires
specifying a unit of measurement between bound-
aries ? in our case we used word-level units for
English data and character-level units for Chinese
data. We calculated average similarity agreement
for segment boundaries pair-wise within-group
for annotators from each of the 9 language/genre
datasets, as presented in Table 3.
While the segmentation similarity agreements
seem to indicate high annotator agreement, we
wanted to find out if that agreement was bet-
ter than what we could generate at random, so
we compared annotator agreement with random
baselines. To generate the baselines, we used
the average number of segments per paragraph in
each language/genre dataset and inserted bound-
aries at random. For each of the 9 language/genre
datasets, we generated 30 baseline samples. We
calculated the baseline segmentation similarity
5
Dataset (S) (SBL)
Chinese UDHR 0.930 0.848
English NEWS 0.891 0.796
English LIT 0.875 0.790
English LIT G1 0.929 0.824
English LIT G2 0.799 0.727
English UDHR 0.870 0.802
English UDHR G1 0.929 0.848
English UDHR G2 0.910 0.836
English UDHR G3 0.826 0.742
Table 3: Within-group segmentation similarity
agreement (S) and segmentation similarity agree-
ment for random baseline (SBL).
(SBL) in the same way using average pair-wise
agreement within-group for all of the baseline
datasets, shown in Table 3.
For English UDHR, we also calculated average
pair-wise agreement across groups, shown in Ta-
ble 4. For example, we compared English UDHR
G1 with English UDHR G2, etc. Human annota-
tors consistently outperformed the baseline across
groups for English UDHR.Dataset (S) (SBL)
English UDHR G1?G2 0.916 0.847
English UDHR G1?G3 0.853 0.782
English UDHR G2?G3 0.857 0.778
Table 4: English UDHR across-group segmenta-
tion similarity agreement (S) and random baseline
(SBL).6 Analysis
Constructing concepts in this task is systematic
as was shown from the segmentation similarity
scores. Since we know that the annotators agreed
on some things, it is important to find out what
they have agreed on. In our analysis, we exam-
ined unit boundary locations across genres in addi-
tion to phrase structure using constituency parses.
In this section, we begin to address another of
our original research questions regarding how well
speakers agree on meaning unit boundary posi-
tions across genres and which syntactic features
are the most salient for meaning units.
6.1 Unit Boundary Positions for Genres
Boundary positions are interesting because they
can potentially indicate if there are salient parts
of the texts which stand out to annotators across
genres. We have focused this analysis across gen-
res for the overall data for each of the 4 lan-
guage/genre pairs. Therefore, we have omitted the
subgroups ? English UDHR groups (G1,G2, G3)
and English LIT groups (G1, G2). Although seg-
mentation similarity is greater within-group from
Table 3, this was not enough to inform us of which
boundaries annotators fully agree on. For each of
the datasets, we counted the number of annotators
who agreed on a given boundary location and plot-
ted histograms. In these plots we show the number
of annotators of each potential boundary between
words. We show the resulting distributions in Fig-
ures 5 ? 8.
Figure 5: Annotated boundary positions Chinese
UDHR.
Figure 6: Annotated boundary positions English
UDHR.
While there were not many annotators for the
Chinese UDHR data, we can see from Figure 5
6
Figure 7: Annotated boundary positions English
NEWS.
Figure 8: Annotated boundary positions English
LIT.
that at most 4 annotators agreed on boundary po-
sitions. We can see from Figures 6 ? 8 that there
is high frequency of agreement in the text which
corresponds to paragraph boundaries for the En-
glish data, however paragraph boundaries were ar-
tificially introduced into the experiment because
each paragraph was numbered.
Since we had removed all punctuation mark-
ings, including periods and commas for both lan-
guages, it is interesting to note there was not full
agreement about sentence boundaries. While we
did not ask annotators to mark sentence bound-
aries, we hoped that these would be picked up by
the annotators when they were constructing mean-
ing units in the text. Only 3 sentence boundaries
were identified by at most 2 Chinese UDHR an-
notators. On the other hand, all of the sentence
boundaries were idenfied for English UDHR and
English NEWS, and one sentence boundary was
unmarked for English LIT. However, there were
no sentence boundaries in the English data that
were marked by all annotators - in fact the sin-
gle most heavily annotated sentence boundary was
for English NEWS, where 30% of the annota-
tors marked it. The lack for identifying sentence
boundaries could be due to an oversight by anno-
tators, or it could also be indicative of the difficulty
and ambiguity of the task.6.2 Phrase Structure
To answer our question of whether or not there are
salient syntactic features for meaning units, we did
some analysis with constituency phrase structure
and looked at the maximal projections of meaning
units. For each of the 3 English genres (UDHR,
NEWS, and LIT) we identified boundaries where
at least 50% of the annotators agreed. For the Chi-
nese UDHR data, we identified boundaries where
at least 30% of annotators agreed. We used the
Stanford PCFG Parser on the original English and
Chinese text to obtain constituency parses (Klein
& Manning, 2003), then aligned the agreeable
segment boundaries with the constituency parses.
We found the maximal projection corresponding
to each annotated unit and we calculated the fre-
quency of each of the maximal projections. The
frequencies of part-of-speech for maximal projec-
tions are shown in Tables 5 - 8. Note that the part-
of-speech tags reflected here come from the Stan-
ford PCFG Parser.Max. Projection Description Freq.S, SBAR, SINV Clause 28PP Prepositional Phrase 14VP Verb Phrase 11NP Noun Phrase 5ADJP Adjective Phrase 3ADVP Adverb Phrase 1
Table 5: Frequency of maximal projections for En-
glish UDHR, for 62 boundaries.Max. Projection Description Freq.S, SBAR, SINV Clause 30VP Verb Phrase 23NP Noun Phrase 11PP Prepositional Phrase 3ADVP Adverb Phrase 2
Table 6: Frequency of maximal projections for En-
glish NEWS, for 69 boundaries.
7
Max. Projection Description Freq.S, SBAR Clause 32VP Verb Phrase 10NP Noun Phrase 3PP Prepositional Phrase 2ADVP Adverb Phrase 2
Table 7: Frequency of maximal projections for En-
glish LIT, for 49 boundaries.Max. Projection Description Freq.NN, NR Noun 22VP Verb Phrase 8NP Noun Phrase 8CD Determiner 3ADVP Adverb Phrase 1AD Adverb 1VV Verb 1JJ Other noun mod. 1DP Determiner Phrase 1
Table 8: Frequency of maximal projections for
Chinese UDHR, for 46 boundaries.
Clauses were by far the most salient bound-
aries for annotators of English. On the other hand,
nouns, noun phrases, and verb phrases were the
most frequent for annotators of Chinese. There
is some variation across genres for English. This
analysis begins to address whether or not it is
possible to identify syntactic features of meaning
units, however it leaves open another question as
to if it is possible to automatically identify a 1-to-1
mapping of concepts across languages.7 Discussion and Future Work
We have presented an experimental framework
for examining how English and Chinese speakers
make meaning out of text by asking them to la-
bel places that they could construct concepts with
as few words as possible. Our results show that
there is not a unique ?meaning unit? segmentation
criteria among annotators. However, there seems
to be some preferential trends on how to perform
this task, which suggest that any random segmen-
tation is not acceptable. As we have simplified the
task of meaning unit identification by using well-
structured text from the Universal Declaration of
Human Rights, news, and literature, future work
should examine identifying meaning units in tran-
scribed speech.
Annotators for the English UDHR and English
LIT datasets could be characterized by their dif-
ferent granularities of annotation in terms of num-
ber of units identified. These observations are in-
sightful to our first question: what granularity do
people use to construct meaning units? For some,
meaning units consist of just a few words, whereas
for others they consist of longer phrases or possi-
bly clauses. As we did not have enough responses
for the Chinese UDHR data, we are unable to com-
ment if identification of meaning units in Chinese
fit a similar distribution as with English and we
leave in-depth cross-language analysis to future
work.
A particularly interesting finding was that hu-
man annotators share agreement even across
groups, as seen from Table 4. This means that al-
though annotators may not agree on the number of
meaning units found, they do share some agree-
ment regarding where in the text they are creating
the meaning units. These findings seem to indicate
that annotators are creating meaning units system-
atically regardless of granularity.
Our findings suggest that different people orga-
nize and process information differently. This is a
very important conclusion for discourse analysis,
machine translation and many other applications
as this suggests that there is no optimal solution
to the segmentation problems considered in these
tasks. Future research should focus on better un-
derstanding the trends we identified and the ob-
served differences among different genres. While
we did not solicit feedback from annotators in this
experiment, we believe that it will be important
to do so in future work to improve the annota-
tion task. We know that the perceived lag time in
speech-to-speech translation cannot be completely
eliminated but we are interested in systems that are
?fast? enough for humans to have quality conver-
sations in different languages.Acknowledgments
This work was partly supported by Singapore
Agency for Science, Technology and Research
(A-STAR) and the Singapore International Pre-
Graduate Award (SIPGA) and was partly sup-
ported by the National Science Foundation (NSF)
award IIS-1225629. Any opinions expressed in
this material are those of the authors and do not
necessarily reflect the views of A-STAR and NSF.
8
References
Chang Baobao, Pernilla Danielsson, and Wolfgang
Teubert. 2002. Extraction of translation units from
Chinese-English parallel corpora. In Proceedingsof the first SIGHAN workshop on Chinese languageprocessing - Volume 18 (SIGHAN ?02), 1?5.
Presentacio?n Padilla Ben??tez and Teresa Bajo. 1998.
Hacia un modelo de memoria y atencio?n en inter-
pretacio?n simulta?nea. Quaderns. Revista de tra-duccio?, 2:107?117.
Chris Fournier and Diana Inkpen. 2012. Segmenta-
tion and similarity agreement. In Proceedings ofthe 2012 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies (NAACL HLT ?12),
Montreal, Canada, 152?161.
Osamu Furuse and Hitashi Iida. 1996. Incremental
translation utilizing constituent boundary patterns.
In Proceedings of the 16th conference on Computa-tional linguistics (COLING ?96), Copenhagen, Den-
mark, 412?417.
Olivier Hamon, Christian Fgen, Djamel Mostefa, Vic-
toria Arranz1, Munstin Kolss, Alex Waibel, and
Khalid Choukri. 2009. End-to-End Evaluation in
Simultaneous Translation. In Proceedings of the12th Conference of the European Chapter of theAssociation for Computational Linguistics, (EACL?09), Athens, Greece, 345?353.
Daniel Jurafsky. 1988. Issues in relating syntax and
semantics. In Proceedings of the 12th Internationalconference on Computational Linguistics (COLING?88), Budapest, Hungary, 278?284.
Frank Keller. 2010. Cognitively plausible models of
human language processing. In Proceedings of theACL 2010 Conference Short Papers, Uppsala, Swe-
den, 60?67.
Walter Kintsch. 2005. An Overview of Top-down and
Bottom?up Effects in Comprehension: The CI Per-
spective. Discourse Processes, 39(2&3):125?128.
Walter Kintsch and Praful Mangalath. 2011. The Con-
struction of Meaning. Topics in Cognitive Science,
3:346?370.
Dan Klein and Christopher D. Manning 2003. Ac-
curate Unlexicalized Parsing. In Proceedings of the41st Meeting of the Association for ComputationalLinguistics, 423?430.
Ja?chym Kola?r?. 2008. Automatic Segmentation ofSpeech into Sentence-like Units. Ph.D. thesis, Uni-
versity of West Bohemia, Pilsen, Czech Republic.
Patrik Lambert, Adria`. De Gispert, Rafael Banchs, and
Jose? B. Marin?o. 2005. Guidelines for Word Align-
ment Evaluation and Manual Alignment. LanguageResources and Evaluation (LREC), 39:267?285.
Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu.
2012. Fully automatic semantic MT evaluation. InProceedings of the Seventh Workshop on StatisticalMachine Translation (WMT ?12), Montreal, Canada
243?252.
George A. Miller. 1956. The Magical Number Seven,
Plus or Minus Two: Some Limits on Our Capacity of
Processing Information. The Psychological Review,
Vol 63:81?97.
Hideki Mima, Hitoshi Iida, and Osamu Furuse. 1998.
Simultaneous interpretation utilizing example-based
incremental transfer. In Proceedings of the 17th In-ternational Conference on Computational Linguis-tics (COLING ?98) Montreal, Quebec, Canada, 855?
861.
Pierre Ole?ron and Hubert Nanpon. 1965. Recherches
sur la traduction simultane?e. Journal de PsychologieNormale et Pathologique, 62(1):73?94.
Mathais Paulik and Alex Waibel. 2009. Automatic
Translation from Parallel Speech: Simultaneous In-
terpretation as MT Training Data. IEEE Workshopon Automatic Speech Recognition and Understand-ing, Merano, Italy, 496?501.
Lev Pevzner and Marti A. Hearst 2002. A critique and
improvement of an evaluation metric for text seg-
mentation. Computational Linguistics, 28(1):1936.
MIT Press, Cambridge, MA, USA.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James
H. Mar- tin, and Dan Jurafsky. 2004. Shallow Se-
mantic Parsing Using Support Vector Machines. InProceedings of the 2004 Conference on Human Lan-guage Technology and the North American Chap-ter of the Association for Computational Linguistics(HLT-NAACL-04).
Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar.
2010. Incremental Decoding for Phrase-based Sta-
tistical Machine Translation. In Proceedings of theJoint 5th Workshop on Statistical Machine Transla-tion and Metrics (MATR), Uppsala, Sweden, 222?
229.
Teresa M. Signorelli, Henk J. Haarmann, and Loraine
K. Obler. 2011. Working memory in simultaneous
interpreters: Effects of task and age. InternationalJournal of Billingualism, 16(2): 192?212.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, Qun
Liu. 2003. HHMM-based Chinese Lexical An-
alyzer ICTCLAS. In Proceedings of the SecondSIGHAN Workshop on Chinese Language Process-ing (SIGHAN ?03) - Volume 17, Sapporo, Japan,
184-187.
9
