Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 85?88,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Designing Language Technology Applications:
A Wizard of Oz Driven Prototyping Framework
S. Schl
?
ogl
MCI Management Center Innsbruck
Management, Communication & IT
Innsbruck, AUSTRIA
schlogl@mci.edu
P. Milhorat
?
, G. Chollet
?
, J. Boudy
?
Institut Mines-T?el?ecom
?
T?el?ecom ParisTech &
?
T?el?ecom SudParis
Paris, FRANCE
milhorat@telecom-paristech.fr
Abstract
Wizard of Oz (WOZ) prototyping employs
a human wizard to simulate anticipated
functions of a future system. In Natural
Language Processing this method is usu-
ally used to obtain early feedback on di-
alogue designs, to collect language cor-
pora, or to explore interaction strategies.
Yet, existing tools often require complex
client-server configurations and setup rou-
tines, or suffer from compatibility prob-
lems with different platforms. Integrated
solutions, which may also be used by de-
signers and researchers without technical
background, are missing. In this paper
we present a framework for multi-lingual
dialog research, which combines speech
recognition and synthesis with WOZ. All
components are open source and adaptable
to different application scenarios.
1 Introduction
In recent years Language Technologies (LT) such
as Automatic Speech Recognition (ASR), Ma-
chine Translation (MT) and Text-to-Speech Syn-
thesis (TTS) have found their way into an increas-
ing number of products and services. Technolog-
ical advances in the field have created new possi-
bilities, and ubiquitous access to modern technol-
ogy (i.e. smartphones, tablet computers, etc.) has
inspired novel solutions in multiple application ar-
eas. Still, the technology at hand is not perfect and
typically substantial engineering effort (gathering
of corpora, training, tuning) is needed before pro-
totypes involving such technologies can deliver a
user experience robust enough to allow for poten-
tial applications to be evaluated with real users.
For graphical interfaces, well-known prototyping
methods like sketching and wire-framing allow for
obtaining early impressions and initial user feed-
back. These low-fidelity prototyping techniques
do not, however, work well with speech and nat-
ural language. The Wizard of Oz (WOZ) method
can be employed to address this shortcoming. By
using a human ?wizard? to mimic the functional-
ity of a system, either completely or in part, WOZ
supports the evaluation of potential user experi-
ences and interaction strategies without the need
for building a fully functional product first (Gould
et al., 1983). It furthermore supports the collection
of domain specific language corpora and the easy
exploration of varying dialog designs (Wir?en et al.,
2007). WOZ tools, however, are often application
dependent and built for very specific experimental
setups. Rarely, are they re-used or adapted to other
application scenarios. Also, when used in combi-
nation with existing technology components such
as ASR or TTS, they usually require complex soft-
ware installations and server-client configurations.
Thus, we see a need for an easy ?out-of-the-box?
type solution. A tool that does not require great
technical experience and therefore may be used by
researchers and designers outside the typical NLP
research and development community. This demo
is the result of our recent efforts aimed at building
such an integrated prototyping tool.
We present a fully installed and configured
server image that offers multi-lingual (i.e. English,
German, French, Italian) ASR and TTS integrated
with a web-based WOZ platform. All components
are open-source (i.e. adaptable and extendable)
and connected via a messaging server and a num-
ber of Java programs. When started the framework
requires only one single script to be executed (i.e.
there is a separate script for each language so that
the components are started using the right param-
eters) in order to launch a WOZ driven system en-
vironment. With such a pre-configured setup we
believe that also non-NLP experts are able to suc-
cessfully conduct extended user studies for lan-
guage technologies applications.
85
2 Existing Comparable Tools
Following the literature, existing tools and frame-
works that support prototyping of language tech-
nology applications can be separated into two cat-
egories. The first category consists of so-called
Dialogue Management (DM) tools, which focus
on the evaluation of Language Technologies (LTs)
and whose primary application lies in the areas of
NLP and machine learning. Two well-known ex-
amples are the CSLU toolkit (Sutton et al., 1998)
and the Olympus dialogue framework (Bohus et
al., 2007). Others include the Jaspis dialogue man-
agement system (Turunen and Hakulinen, 2000)
and the EPFL dialogue platform (Cenek et al.,
2005). DM tools explore the language-based inter-
action between a human and a machine and aim at
improving this dialogue. They usually provide an
application development interface that integrates
different LTs such as ASR and TTS, which is then
used by an experimenter to specify a pre-defined
dialogue flow. Once the dialogue is designed, it
can be tested with human participants. The main
focus of these tools lies on testing and improving
the quality of the employed technology compo-
nents and their interplay. Unlike DM tools, rep-
resentatives from the second category, herein af-
ter referred to as WOZ tools, tend to rely entirely
on human simulation. This makes them more in-
teresting for early feedback, as they better sup-
port the aspects of low-fidelity prototyping. While
these applications often offer more flexibility, they
rarely integrate actual working LTs. Instead, a hu-
man mimics the functions of the machine, which
allows for a less restrictive dialogue design and
facilitates the testing of user experiences that are
not yet supported by existing technologies. Most
WOZ tools, however, should be categorized as
throwaway applications i.e. they are built for one
scenario and only rarely re-used in other settings.
Two examples that allow for a more generic ap-
plication are SUEDE (Klemmer et al., 2000) and
Richard Breuer?s WOZ tool
1
.
While both DM and WOZ tools incorporate
useful features, neither type provides a full range
of support for low-fidelity prototyping of LT ap-
plications. DM tools lack the flexibility of ex-
ploring aspects that are currently not supported by
technology, and pure WOZ applications often de-
pend too much on the actions of the wizard, which
can lead to unrealistic human-like behaviour and
1
http://www.softdoc.de/woz/index.html
inconsistencies with its possible bias on evalua-
tion results. A combination of both types of tools
can outweigh their deficiencies and furthermore
allow for supporting different stages of prototyp-
ing. That is, a wizard might complement exist-
ing technology on a continuum by first taking on
the role of a ?controller? who simulates technol-
ogy. Then, in a second stage one could act as a
?monitor? who approves technology output, before
finally moving on to being a ?supervisor? who only
overrides output in cases where it is needed (Dow
et al., 2005). However, to allow for such variation
an architecture is required that on the one hand
supports a flexible use of technology components
and on the other hand offers an interface for real-
time human intervention.
3 Integrated Prototyping Framework
In order to offer a flexible and easy to use pro-
totyping framework for language technology ap-
plications we have integrated a number of exist-
ing technology components using an Apache AC-
TIVEMQ messaging server
2
and several Java pro-
grams. Our framework consists of the JULIUS
Large Vocabulary Continuous Speech Recogni-
tion engine
3
, an implementation of the GOOGLE
SPEECH API
4
, the WEBWOZ Wizard of Oz
Prototyping Platform
5
and the MARY Text-to-
Speech Synthesis Platform
6
. All components are
fully installed and connected running on a VIR-
TUAL BOX server image
7
(i.e. Ubuntu 12.04 LTS
Linux Server). Using this configuration we offer
a platform that supports real-time speech recogni-
tion as well as speech synthesis in English, French,
German and Italian. Natural Language Under-
standing (NLU), Dialog Management (DM), and
Natural Language Generation (NLG) is currently
performed by the human ?wizard?. Respective
technology components may, however, be inte-
grated in future versions of the framework. The
following sections describe the different compo-
nents in some more detail and elaborate on how
they are connected.
2
http://activemq.apache.org/
3
http://julius.sourceforge.jp/en index.php
4
http://www.google.com/intl/en/chrome/demos/speech.html
5
https://github.com/stephanschloegl/WebWOZ
6
http://mary.dfki.de/
7
https://www.virtualbox.org/
86
3.1 Automatic Speech Recognition
The JULIUS open-source Large Vocabulary Con-
tinuous Speech Recognition engine (LVCSR) uses
n-grams and context-dependent Hidden Markov
Models (HMM) to transform acoustic input into
text output (Lee et al., 2008). Its recognition
performance depends on the availability of lan-
guage dependent resources i.e. acoustic models,
language models, and language dictionaries. Our
framework includes basic language resources for
English, German, Italian and French. As those
resources are still very limited we have also in-
tegrated online speech recognition for these four
languages using the Google Speech API. This al-
lows for conducting experiments with users while
at the same time collecting the necessary data for
augmenting and filling in JULIUS language re-
sources.
3.2 Text-to-Speech Synthesis
MARY TTS is a state-of-the-art, open source
speech synthesis platform supporting a variety
of different languages and accents (Schr?oder and
Trouvain, 2003). For the here presented multi-
lingual prototyping framework we have installed
synthesized voices for US English (cmu-slt-
hsmm), Italian (istc-lucia-hsmm), German (dfki-
pavoque-neutral) as well as French (enst-dennys-
hsmm). Additional voices can be downloaded and
added through the MARY component installer.
3.3 Wizard of Oz
WebWOZ is a web-based prototyping platform for
WOZ experiments that allows for a flexible inte-
gration of existing LTs (Schl?ogl et al., 2010). It
was implemented using modern web technologies
(i.e. Java, HTML, CSS) and therefore runs in any
current web browser. It usually uses web services
to integrate a set of pre-configured LT components
(i.e. ASR, MT, TTS). For the presented prototyp-
ing framework, however, we have integrated Web-
WOZ with our ASR solution (i.e. the combined
Google/JULIUS engine) and MARY TTS. Conse-
quently ASR output is displayed in the top area
of the wizard interface. A wizard is then able to
select an appropriate response from a set of pre-
viously defined utterances or use a free-text field
to compose a response on the fly. In both cases
the utterance is sent to the MARY TTS server and
spoken out by the system.
3.4 Messaging Server and Gluing Programs
In order to achieve the above presented integration
of ASR, WOZ and TTS we use an Apache AC-
TIVEMQ messaging server and a number of Java
programs. One of these programs takes the output
from our ASR component and inserts it into the
WebWOZ input stream. In addition it publishes
this output to a specific ASR ActiveMQ queue so
that other components (e.g. potentially an NLU
component) may also be able to process it. Once
an ASR result is available within WebWOZ, it is
up to the human wizard to respond. WebWOZ
was slightly modified so that wizard responses are
not only sent to the internal WebWOZ log, but
also to a WIZARD ActiveMQ queue. A second
Java program then takes the wizard responses from
the WIZARD queue and pushes them to a sepa-
rate MARY queue. While it may seem unneces-
sary to first take responses from one queue just to
publish them to another queue, it allows for the
easy integration of additional components. For
example, we have also experimented with a dis-
tinct NLG component. Putting this component
between the WIZARD and the MARY queue we
were able to conduct experiments where a wiz-
ard instead of sending entire text utterance would
rather send text-based semantic frames (i.e. a se-
mantically unified representation of a user?s in-
put). Such shows the flexibility of using the de-
scribed queue architecture. Finally we use a third
Java program to take text published to the MARY
queue (i.e. either directly coming from the wiz-
ard or produced by an NLG component as with
one of our experimental settings) and send it to the
MARY TTS server. Figure 1 illustrates the differ-
ent framework components and how they are con-
nected to each other.
4 Demo Setup
The optimal setup for the demo uses two computer
stations, one for a wizard and one for a test user.
The stations need to be connected via a LAN con-
nection. The test user station runs the prototyping
framework, which is a fully installed and config-
ured Virtual Box software image (Note: any com-
puter capable of running Virtual Box can serve as a
test user station). The wizard station only requires
a modern web browser to interact with the test user
station. A big screen size (e.g. 17 inch) for the
wizard is recommended as such eases his/her task.
Both stations will be provided by the authors.
87
Figure 1: Prototyping Framework Components.
5 Summary and Future Work
This demo presents an integrated prototyping
framework for running WOZ driven language
technology application scenarios. Gluing together
existing tools for ASR, WOZ and TTS we have
created an easy to use environment for spoken di-
alog design and research. Future work will focus
on adding additional language technology compo-
nents (e.g. NLU, DM, NLG) and on improving the
currently limited ASR language resources.
Acknowledgments
The presented research is conducted as part of the
vAssist project (AAL-2010-3-106), which is par-
tially funded by the European Ambient Assisted
Living Joint Programme and the National Funding
Agencies from Austria, France and Italy.
References
D. Bohus, A. Raux, T. K. Harris, M. Eskenazi, and A. I.
Rudnicky. 2007. Olympus: An open-source frame-
work for conversational spoken language interface
research. In Proc. of NAACL-HLT, pages 32?39.
P. Cenek, M. Melichar, and M. Rajman. 2005. A
framework for rapid multimodal application design.
In Proceedings of TSD, pages 393?403.
S. Dow, B. Macintyre, J. Lee, C. Oezbek, J. D. Bolter,
and M. Gandy. 2005. Wizard of oz support through-
out an iterative design process. IEEE Pervasive
Computing, 4(4):18?26.
J. D. Gould, J. Conti, and T. Hovanyecz. 1983. Com-
posing letters with a simulated listening typewriter.
Communications of the ACM, 26(4):295?308.
S. R. Klemmer, A. K. Sinha, J. Chen, J. A. Landay,
N. Aboobaker, and A. Wang. 2000. SUEDE: A wiz-
ard of oz prototyping tool for speech user interfaces.
In Proc. of UIST, pages 1?10.
C. Lee, S. Jung, and G. G. Lee. 2008. Robust dia-
log management with n-best hypotheses using di-
alog examples and agenda. In Proc. of ACL-HLT,
pages 630?637.
S. Schl?ogl, G. Doherty, N. Karamanis, and S Luz.
2010. WebWOZ: a wizard of oz prototyping frame-
work. In Proc. of the ACM EICS Symposium on En-
gineering Interactive Systems, pages 109?114.
M. Schr?oder and J. Trouvain. 2003. The German
text-to-speech synthesis system MARY: A tool for
research, development and teaching. International
Journal of Speech Technology.
S. Sutton, R. Cole, J. de Vielliers, J. Schalkwyk, P. Ver-
meulen, M. Macon, Y. Yan, E. Kaiser, B. Rundle,
K. Shobaki, P. Hosom, A. Kain, J. Wouters, D. Mas-
saro, and M. Cohen. 1998. Universal speech tools:
The CSLU toolkit.
M. Turunen and J. Hakulinen. 2000. Jaspis- a frame-
work for multilingual adaptive speech applications.
In Proc. of ICSLP, pages 719?722.
M. Wir?en, R. Eklund, F. Engberg, and J. Westermark.
2007. Experiences of an In-Service Wizard-of-
Oz Data Collection for the Deployment of a Call-
Routing Application. In Proc. of NAACL-HLT,
pages 56?63.
88
Proceedings of the SIGDIAL 2013 Conference, pages 157?159,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Multi-step Natural Language Understanding
Pierrick Milhorat, Stephan Schlo?gl, Ge?rard Chollet
Institut Mines-Te?le?com
Te?le?com ParisTech, CNRS LTCI
Paris, France
{lastname}@enst.fr
Je?ro?me Boudy
Institut Mines-Te?le?com
Te?le?com SudParis
Paris, France
boudy@telecom-sudparis.eu
Abstract
While natural language as an interaction
modality is increasingly being accepted by
users, remaining technological challenges
still hinder its widespread employment.
Tools that better support the design, devel-
opment and improvement of these types
of applications are required. This demo
presents a prototyping framework for Spo-
ken Dialog System (SDS) design which
combines existing language technology
components for Automatic Speech Recog-
nition (ASR), Dialog Management (DM),
and Text-to-Speech Synthesis (TTS) with
a multi-step component for Natural Lan-
guage Understanding (NLU).
1 Introduction
Recently speech and other types of natural lan-
guage are experiencing an increased acceptance
when being used for interacting with ?intelli-
gent? computing systems. This trend is particu-
larly reflected by products such as Apple?s Siri1,
Google?s Now2 and Nuance?s Dragon Solutions3.
While these applications demonstrate the indus-
try?s vision of how we should be interacting with
our current and future devices, they also highlight
some of the great challenges that still exist. One
of these challenges may be seen in the fact that
Automatic Speech Recognition (ASR) remains a
highly error-prone technology which influences
subsequent natural language processing compo-
nents such as Natural Language Understanding
(NLU) and Dialog Management (DM) and leads
to often unsatisfying user experiences. Hence we
require appropriate tools that better support the
testing and studying of language as an interaction
1http://www.apple.com/ios/siri/
2http://www.google.com/landing/now/
3http://www.nuance.com/dragon/
modality and consequently allow us to build bet-
ter, more user-centered applications.
This demo presents our approach of develop-
ing a prototyping tool for Spoken Dialog Systems
(SDS). Our solution is particularly focusing on
the natural language understanding aspect of SDS
design. The overall framework is composed of
a set of existing open-source technology compo-
nents (i.e. ASR, DM, TTS) which are expanded
by several additional NLP modules responsible for
natural language understanding as well as genera-
tion. The following sections first provide a general
overview of the entire framework and then focus
particularly on the NLU part of our solution and
the different sub-modules it integrates.
2 Spoken Dialog System Design
A state-of-the-art SDS usually consists of a set of
technology components that are integrated to form
a consecutive processing chain. Starting on the
input side the ASR module produces a hypothe-
sis about the orthographic content of a spoken ut-
terance. The NLU takes this recognized utterance
and converts it into a machine readable command
or input Dialog Act (DA). The DM processes this
input DA and sends the relevant output DA to the
Natural Language Generation (NLG) component.
The NLG is then responsible for converting the
output DA into appropriate natural language text.
Finally, the Text-to-Speech (TTS) synthesis com-
ponent takes the text transmitted by the NLG and
speaks it to a user.
According to this general architecture different
open-source language components have been in-
tegrated to form a loosely coupled SDS frame-
work. The framework includes ASR performed by
the Julius Large Vocabulary Continuous Speech
Recognition engine4, dialog management based
on the Disco DM library (Rich, 2009; Rich
4http://julius.sourceforge.jp/en index.php
157
and Sidner, 2012) and TTS achieved through the
MARY Text-to-Speech Synthesis Platform5. Ad-
ditionally, we have integrated the WebWOZ Wiz-
ard of Oz Prototyping Platform6 (Schlo?gl et al,
2010) in order to allow for the simulation of (flaw-
less) natural language understanding. Expanding
these existing components we have then developed
as a set of modules responsible for actual system-
based natural language processing. The following
section describes these modules in more detail and
highlights the types of challenges they try to over-
come.
3 Natural Language Understanding
Within the processing chain of a spoken/text-
based dialog system, the NLU component is the
link between the wide and informal communica-
tion space of a user?s input and the formal and
rather restrictive semantic space that can be pro-
cessed by the DM (Mori et al, 2007). Trying to
bridge these two spaces we have connected sev-
eral modules to form an NLU processing segment
whose different modules are described below.
3.1 Semantic Parsing
First we use a Semantic Parsing (SP) module to
convert the transcribed speech provided by the
ASR into so-called Semantic Frames (SFs). To
achieve this mapping Jurc???c?ek et al (2009) de-
signed a Transformation-Based Learning Seman-
tic Parser (Brill, 1995) which we adapted to inte-
grate it with our framework. The algorithm applies
an ordered set of rules to hypothetical [utterance,
SF] pairs in order to find the closest matching SF.
3.2 Semantic Unification
Next we use what we call the Semantic Unifier
and Reference Resolver (SURR) module to con-
vert input SFs into SFs that can be processed by
the DM input interface. To do this we imple-
mented a bottom-up search algorithm for rewrit-
ing trees whose nodes contain lists of valued slots.
The algorithm looks for a group of root nodes that
can be reached in the forest (i.e. the existing num-
ber of trees) by transforming an input SF?s set of
slots according to the given rewriting rules. It suc-
ceeds when all slots can be rewritten into a root
list of slots. This module is supported by exter-
nal knowledge sources such as for example the
5http://mary.dfki.de/
6https://github.com/stephanschloegl/WebWOZ
context in which an utterance has been produced
(i.e. it receives input from the Context Catcher
module described below). Furthermore it could
call operating system functions, sensor readings
7 or other knowledge sources capable of provid-
ing relevant data, in order to resolve and disam-
biguate input. For instance, special-valued slots
like ?date=today? are dynamically resolved to the
correct data type and value, making the NLU more
sensitive to its surrounding environment.
3.3 Context Inclusion
In order to optimize information exchange
Human-Human interactions usually build up a
common knowledge between dialog participants.
This inherent grounding process can be compared
to the dialog history recorded in an SDS?s DM.
Using these recordings we have introduced a so-
called Context Catcher (CC) module. The way
this module is currently working is as follows: The
DM requests information from the user to progress
through the task-oriented dialog. The user replies
without specifying the type of data he/she is pro-
viding, the overall intent of the utterance or the re-
lation to any dialog slot. The CC evaluates the re-
quest expressed by the DM and consequently up-
dates various parameters of the SURR component.
Consequently the SURR is able to provide a better,
more context-specific mapping between raw SFs
provided by the SP module and the expected slots
to be filled by the DM component.
3.4 Dialog Act Conversion
An SDS?s DM expects formal meaning represen-
tations to be converted to actual dialog moves or
Dialog Acts (DA); similar to parametrized dialog
commands. A DA is the smallest unit of determin-
istic action to support the dialogue flow. The num-
ber of DAs that are available at any given point is
finite, dynamic and depends on the current state of
the dialog (Note: Here a state does not refer to a
?real? state, such as the ones used in Markov De-
cision Processes or Partially Observable Markov
Decision Processes, but rather to a general status
of the dialog). In other words, two input utter-
ances carrying the same meaning may lead to dif-
ferent consequences depending on a given dialog
state. The right action, i.e. the accurate DA, is to
be determined by the NLU component. As there
7Note: At the moment sensor readings are not imple-
mented as they are currently not available in the developing
environment
158
is usually a many-to-many matching between SFs
and actual DAs we integrated an additional Dialog
Act Converter (DAC) module. This module uses
the context to generate a list of expected slots for
which a user may provide a value (i.e. it converts
possible DAs to SFs). Then a matching between
the actual inputs and the expectations is applied in
order to find the most probable DA.
4 Supporting Mixed Initiatives
SDS dialog designs usually run along an initia-
tive scale that ranges from user-driven to strictly
machine-driven interaction. In the case of a
machine-driven dialog a user has to follow the re-
quests of the system. Interactions that lie out of the
scope of this dialog design are not understood and
may either be discarded or, in the worst case, lead
to a system failure. Despite this potential for fail-
ure, machine-driven designs make the dialog eas-
ier to control and thus less prone to errors, yet,
due to the lack of adaptability exposed by the sys-
tem, also less human-like. On the other hand, pure
user-driven dialog designs minimize the functional
range of a system as they only react to commands
without assuring their functional integrity.
The above described modular approach to NLU
aims to support a mixed initiative design where a
system?s integrity and its goals are sufficiently de-
fined; the user, however, is not restricted by the
type and amount of spoken input he/she can use
to interact. To offer this type of interaction the
system needs to handle three kinds of potential
mis-usages: (1) out-of-application cases, (2) out-
of-dialog cases and (3) out-of-turn cases. To ad-
dress the first one our training corpus has been
augmented so that it includes examples of garbage
SFs. As a result an out-of-application utterance
triggers a generic reply from the system, notifying
the user that he/she is outside the scope of the ap-
plication. In the case where a user stays within
the scope of the application but tries to initiate
a new unrelated dialog (i.e. out-of-dialog case),
the DM?s stack of tasks is incremented with the
new dialog. The system will lead the user back
to the previous topic once the newly added one
is completed. Finally, as for the out-of-turn cases
i.e. the cases where a user would answer a sys-
tem request with a non-expected utterance such as
an over-complete one, the NLU process, retriev-
ing the DM?s expectations, discards unrelated or
over-complete information.
5 Demo Description
Focusing on the NLU aspect of the SDS pipeline
this demo will demonstrate how the different mod-
ules described above (i.e. SP, SURR, CC, and
DAC) work together. An application scenario
from the ambient assisted living domain (i.e. the
operation of a ?Pillbox? application) will serve as
an example use case. It will be shown how the
natural language input potentially recognized by
an ASR component is further interpreted by our
NLU processing segment. All the steps discussed
in Section 3 will be visible.
6 Conclusion
In this paper we described a set of NLU compo-
nents that were integrated as part of a loosely cou-
pled SDS. Separate modules for semantic parsing,
semantic unification and reference resolution, con-
text inclusion as well as dialog act conversion have
been described. Furthermore we have highlighted
how our system offers support for mixed-initiative
dialog interactions. A first test of this NLU pro-
cessing chain showed that the use of our multi-
component approach is feasible, and we believe
that this solution can be seen as a valuable test and
development framework for natural language pro-
cessing research.
References
E. Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational lin-
guistics.
F. Jurc???c?ek, F. Mairesse, M. Gas?ic?, S. Keizer, B. Thom-
son, K. Yu, and S. Young. 2009. Transformation-
based Learning for semantic parsing. Proceedings
of INTERSPEECH, pages 2719?2722.
R. De Mori, F. Be?chet, D. Hakkani-Tur, M. McTear,
G. Riccardi, and G. Tur. 2007. Spoken language
understanding: A survey. Proceedings of ASRU.
C. Rich and C. L. Sidner. 2012. Using collaborative
discourse theory to partially automate dialogue tree
authoring. Intelligent Virtual Agents, pages 327?
340.
C. Rich. 2009. Building task-based user interfaces
with ANSI/CEA-2018. Computer.
S. Schlo?gl, G. Doherty, S. Luz, and N. Karamanis.
2010. WebWOZ: A Wizard of Oz Prototyping
Framework. In Proceedings of ACM EICS, pages
109?114.
159
