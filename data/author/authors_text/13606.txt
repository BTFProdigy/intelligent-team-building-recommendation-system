Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 272?275,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
k-Nearest Neighbor Monte-Carlo Control Algorithm
for POMDP-based Dialogue Systems
F. Lefe`vre?, M. Gas?ic?, F. Jurc???c?ek, S. Keizer, F. Mairesse, B. Thomson, K. Yu and S. Young
Spoken Dialogue Systems Group
Cambridge University Engineering Department
Trumpington Street, Cambridge CB2 1PZ, UK
{frfl2, mg436, fj228, sk561, farm2, brmt2, ky219, sjy}@eng.cam.ac.uk
Abstract
In real-world applications, modelling di-
alogue as a POMDP requires the use of
a summary space for the dialogue state
representation to ensure tractability. Sub-
optimal estimation of the value func-
tion governing the selection of system re-
sponses can then be obtained using a grid-
based approach on the belief space. In
this work, the Monte-Carlo control tech-
nique is extended so as to reduce training
over-fitting and to improve robustness to
semantic noise in the user input. This tech-
nique uses a database of belief vector pro-
totypes to choose the optimal system ac-
tion. A locally weighted k-nearest neigh-
bor scheme is introduced to smooth the de-
cision process by interpolating the value
function, resulting in higher user simula-
tion performance.
1 Introduction
In the last decade dialogue modelling as a Partially
Observable Markov Decision Process (POMDP)
has been proposed as a convenient way to improve
spoken dialogue systems (SDS) trainability, nat-
uralness and robustness to input errors (Young et
al., 2009). The POMDP framework models dia-
logue flow as a sequence of unobserved dialogue
states following stochastic moves, and provides a
principled way to model uncertainty.
However, to deal with uncertainty, POMDPs
maintain distributions over all possible states. But
then training an optimal policy is an NP hard
problem and thus not tractable for any non-trivial
application. In recent works this issue is ad-
dressed by mapping the dialog state representation
?Fabrice Lefe`vre is currently on leave from the Univer-
sity of Avignon, France.
space (the master space) into a smaller summary
space (Williams and Young, 2007). Even though
optimal policies remain out of reach, sub-optimal
solutions can be found by means of grid-based al-
gorithms.
Within the Hidden Information State (HIS)
framework (Young et al, 2009), policies are rep-
resented by a set of grid points in the summary be-
lief space. Beliefs in master space are first mapped
into summary space and then mapped into a sum-
mary action via the dialogue policy. The resulting
summary action is then mapped back into master
space and output to the user.
Methods which support interpolation between
points are generally required to scale well to large
state spaces (Pineau et al, 2003). In the current
version of the HIS framework, the policy chooses
the system action by associating each new belief
point with the single, closest, grid point. In the
present work, a k-nearest neighbour extension is
evaluated in which the policy decision is based on
a locally weighted regression over a subset of rep-
resentative grid points. This method thus lies be-
tween a strictly grid-based and a point-based value
iteration approach as it interpolates the value func-
tion around the queried belief point. It thus re-
duces the policy?s dependency on the belief grid
point selection and increases robustness to input
noise.
The next section gives an overview of the
CUED HIS POMDP dialogue system which we
extended for our experiments. In Section 3, the
grid-based approach to policy optimisation is in-
troduced followed by a presentation of the k-
nn Monte-Carlo policy optimization in Section 4,
along with an evaluation on a simulated user.
272
2 The CUED Spoken Dialogue System
2.1 System Architecture
The CUED HIS-based dialogue system pipelines
five modules: the ATK speech recogniser, an
SVM-based semantic tuple classifier, a POMDP
dialogue manager, a natural language generator,
and an HMM-based speech synthesiser. During
an interaction with the system, the user?s speech
is first decoded by the recogniser and an N-best
list of hypotheses is sent to the semantic classifier.
In turn the semantic classifier outputs an N-best
list of user dialogue acts. A dialogue act is a se-
mantic representation of the user action headed by
the user intention (such as inform, request,
etc) followed by a list of items (slot-value pairs
such as type=hotel, area=east etc). The
N-best list of dialogue acts is used by the dialogue
manager to update the dialogue state. Based on
the state hypotheses and the policy, a machine ac-
tion is determined, again in the form of a dialogue
act. The natural language generator translates the
machine action into a sentence, finally converted
into speech by the HMM synthesiser. The dia-
logue system is currently developed for a tourist
information domain (Towninfo). It is worth not-
ing that the dialogue manager does not contain any
domain-specific knowledge.
2.2 HIS Dialogue Manager
The unobserved dialogue state of the HIS dialogue
manager consists of the user goal, the dialogue his-
tory and the user action. The user goal is repre-
sented by a partition which is a tree structure built
according to the domain ontology. The nodes in
the partition consist mainly of slots and values.
When querying the venue database using the par-
tition, a set of matching entities can be produced.
The dialogue history consists of the grounding
states of the nodes in the partition, generated us-
ing a finite state automaton and the previous user
and system action. A hypothesis in the HIS ap-
proach is then a triple combining a partition, a user
action and the respective set of grounding states.
The distribution over all hypotheses is maintained
throughout the dialogue (belief state monitoring).
Considering the ontology size for any real-world
problem, the so-defined state space is too large for
any POMDP learning algorithm. Hence to obtain a
tractable policy, the state/action space needs to be
reduced to a smaller scale summary space. The set
of possible machine dialogue acts is also reduced
in summary space. This is mainly achieved by re-
Master Space
Masters Sppp c  uamyppp
eus Sers Sppp us SamypppMMM
Mast er S pr
cr S pr uSr pSm Mayt
Summary Space
Master Spcu rmymty
c
um
a
ycr
y rcsProceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1552?1561,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Phrase-based Statistical Language Generation using
Graphical Models and Active Learning
Franc?ois Mairesse, Milica Gas?ic?, Filip Jurc???c?ek,
Simon Keizer, Blaise Thomson, Kai Yu and Steve Young?
Cambridge University Engineering Department, Trumpington Street, Cambridge, CB2 1PZ, UK
{f.mairesse, mg436, fj228, sk561, brmt2, ky219, sjy}@eng.cam.ac.uk
Abstract
Most previous work on trainable language
generation has focused on two paradigms:
(a) using a statistical model to rank a
set of generated utterances, or (b) using
statistics to inform the generation deci-
sion process. Both approaches rely on
the existence of a handcrafted generator,
which limits their scalability to new do-
mains. This paper presents BAGEL, a sta-
tistical language generator which uses dy-
namic Bayesian networks to learn from
semantically-aligned data produced by 42
untrained annotators. A human evalua-
tion shows that BAGEL can generate nat-
ural and informative utterances from un-
seen inputs in the information presentation
domain. Additionally, generation perfor-
mance on sparse datasets is improved sig-
nificantly by using certainty-based active
learning, yielding ratings close to the hu-
man gold standard with a fraction of the
data.
1 Introduction
The field of natural language generation (NLG) is
one of the last areas of computational linguistics to
embrace statistical methods. Over the past decade,
statistical NLG has followed two lines of research.
The first one, pioneered by Langkilde and Knight
(1998), introduces statistics in the generation pro-
cess by training a model which reranks candi-
date outputs of a handcrafted generator. While
their HALOGEN system uses an n-gram language
model trained on news articles, other systems have
used hierarchical syntactic models (Bangalore and
Rambow, 2000), models trained on user ratings of
?This research was partly funded by the UK EPSRC un-
der grant agreement EP/F013930/1 and funded by the EU
FP7 Programme under grant agreement 216594 (CLASSiC
project: www.classic-project.org).
utterance quality (Walker et al, 2002), or align-
ment models trained on speaker-specific corpora
(Isard et al, 2006).
A second line of research has focused on intro-
ducing statistics at the generation decision level,
by training models that find the set of genera-
tion parameters maximising an objective function,
e.g. producing a target linguistic style (Paiva and
Evans, 2005; Mairesse and Walker, 2008), gener-
ating the most likely context-free derivations given
a corpus (Belz, 2008), or maximising the expected
reward using reinforcement learning (Rieser and
Lemon, 2009). While such methods do not suffer
from the computational cost of an overgeneration
phase, they still require a handcrafted generator to
define the generation decision space within which
statistics can be used to find an optimal solution.
This paper presents BAGEL (Bayesian networks
for generation using active learning), an NLG sys-
tem that can be fully trained from aligned data.
While the main requirement of the generator is to
produce natural utterances within a dialogue sys-
tem domain, a second objective is to minimise the
overall development effort. In this regard, a major
advantage of data-driven methods is the shift of
the effort from model design and implementation
to data annotation. In the case of NLG systems,
learning to produce paraphrases can be facilitated
by collecting data from a large sample of annota-
tors. Our meaning representation should therefore
(a) be intuitive enough to be understood by un-
trained annotators, and (b) provide useful gener-
alisation properties for generating unseen inputs.
Section 2 describes BAGEL?s meaning represen-
tation, which satisfies both requirements. Sec-
tion 3 then details how our meaning representation
is mapped to a phrase sequence, using a dynamic
Bayesian network with backoff smoothing.
Within a given domain, the same semantic
concept can occur in different utterances. Sec-
tion 4 details how BAGEL exploits this redundancy
1552
to improve generation performance on sparse
datasets, by guiding the data collection process
using certainty-based active learning (Lewis and
Catlett, 1994). We train BAGEL in the informa-
tion presentation domain, from a corpus of utter-
ances produced by 42 untrained annotators (see
Section 5.1). An automated evaluation metric is
used to compare preliminary model and training
configurations in Section 5.2, while Section 5.3
shows that the resulting system produces natural
and informative utterances, according to 18 hu-
man judges. Finally, our human evaluation shows
that training using active learning significantly im-
proves generation performance on sparse datasets,
yielding results close to the human gold standard
using a fraction of the data.
2 Phrase-based generation from
semantic stacks
BAGEL uses a stack-based semantic representa-
tion to constrain the sequence of semantic con-
cepts to be searched. This representation can be
seen as a linearised semantic tree similar to the
one previously used for natural language under-
standing in the Hidden Vector State model (He
and Young, 2005). A stack representation provides
useful generalisation properties (see Section 3.1),
while the resulting stack sequences are relatively
easy to align (see Section 5.1). In the context of
dialogue systems, Table 1 illustrates how the input
dialogue act is first mapped to a set of stacks of
semantic concepts, and then aligned with a word
sequence. The bottom concept in the stack will
typically be a dialogue act type, e.g. an utterance
providing information about the object under dis-
cussion (inform) or specifying that the request
of the user cannot be met (reject). Other con-
cepts include attributes of that object (e.g., food,
area), values for those attributes (e.g., Chinese,
riverside), as well as special symbols for negat-
ing underlying concepts (e.g., not) or specifying
that they are irrelevant (e.g., dontcare).
The generator?s goal is thus finding the
most likely realisation given an unordered
set of mandatory semantic stacks Sm derived
from the input dialogue act. For example,
s =inform(area(centre)) is a mandatory stack
associated with the dialogue act in Table 1 (frame
8). While mandatory stacks must all be conveyed
in the output realisation, Sm does not contain the
optional intermediary stacks Si that can refer to
(a) general attributes of the object under discus-
sion (e.g., inform(area) in Table 1), or (b) to
concepts that are not in the input at all, which are
associated with the singleton stack inform (e.g.,
phrases expressing the dialogue act type, or clause
aggregation operations). For example, the stack
sequence in Table 1 contains 3 intermediary stacks
for t = 2, 5 and 7.
BAGEL?s granularity is defined by the semantic
annotation in the training data, rather than external
linguistic knowledge about what constitutes a unit
of meaning, i.e. contiguous words belonging to
the same semantic stack are modelled as an atomic
observation unit or phrase.1 In contrast with word-
level models, a major advantage of phrase-based
generation models is that they can model long-
range dependencies and domain-specific idiomatic
phrases with fewer parameters.
3 Dynamic Bayesian networks for NLG
Dynamic Bayesian networks have been used suc-
cessfully for speech recognition, natural language
understanding, dialogue management and text-to-
speech synthesis (Rabiner, 1989; He and Young,
2005; Lefe`vre, 2006; Thomson and Young, 2010;
Tokuda et al, 2000). Such models provide a
principled framework for predicting elements in a
large structured space, such as required for non-
trivial NLG tasks. Additionally, their probabilistic
nature makes them suitable for modelling linguis-
tic variation, i.e. there can be multiple valid para-
phrases for a given input.
BAGEL models the generation task as finding
the most likely sequence of realisation phrases
R? = (r1...rL) given an unordered set of manda-
tory semantic stacks Sm, with |Sm| ? L. BAGEL
must thus derive the optimal sequence of semantic
stacks S? that will appear in the utterance given
Sm, i.e. by inserting intermediary stacks if needed
and by performing content ordering. Any num-
ber of intermediary stacks can be inserted between
two consecutive mandatory stacks, as long as all
their concepts are included in either the previous
or following mandatory stack, and as long as each
stack transition leads to a different stack (see ex-
ample in Table 1). Let us define the set of possi-
ble stack sequences matching these constraints as
Seq(Sm) ? {S = (s1...sL) s.t. st ? Sm ? Si}.
We propose a model which estimates the dis-
1The term phrase is thus defined here as any sequence of
one or more words.
1553
Charlie Chan is a Chinese restaurant near Cineworld in the centre of town
Charlie Chan Chinese restaurant Cineworld centre
name food type near near area area
inform inform inform inform inform inform inform inform
t = 1 t = 2 t = 3 t = 4 t = 5 t = 6 t = 7 t = 8
Table 1: Example semantic stacks aligned with an utterance for the dialogue act
inform(name(Charlie Chan) type(restaurant) area(centre) food(Chinese) near(Cineworld)). Mandatory
stacks are in bold.
tribution P (R|Sm) from a training set of real-
isation phrases aligned with semantic stack se-
quences, by marginalising over all stack sequences
in Seq(Sm):
P (R|Sm) =
?
S?Seq(Sm)
P (R,S|Sm)
=
?
S?Seq(Sm)
P (R|S,Sm)P (S|Sm)
=
?
S?Seq(Sm)
P (R|S)P (S|Sm) (1)
Inference over the model defined in (1) requires
the decoding algorithm to consider all possible or-
derings over Seq(Sm) together with all possible
realisations, which is intractable for non-trivial do-
mains. We thus make the additional assumption
that the most likely sequence of semantic stacks
S? given Sm is the one yielding the optimal reali-
sation phrase sequence:
P (R|Sm) ? P (R|S
?)P (S?|Sm) (2)
with S? = argmax
S?Seq(Sm)
P (S|Sm) (3)
The semantic stacks are therefore decoded first
using the model in Fig. 1 to solve the argmax
in (3). The decoded stack sequence S? is then
treated as observed in the realisation phase, in
which the model in Fig. 2 is used to find the real-
isation phrase sequence R? maximising P (R|S?)
over all phrase sequences of length L = |S?| in
our vocabulary:
R? = argmax
R=(r1...rL)
P (R|S?)P (S?|Sm) (4)
= argmax
R=(r1...rL)
P (R|S?) (5)
In order to reduce model complexity, we fac-
torise our model by conditioning the realisation
phrase at time t on the previous phrase rt?1,
and the previous, current, and following semantic
stacks. The semantic stack st at time t is assumed
last mandatory 
stack
stack set 
validator
first frame
semantic 
stack s
stack set tracker
repeated frame final frame
Figure 1: Graphical model for the semantic decod-
ing phase. Plain arrows indicate smoothed proba-
bility distributions, dashed arrows indicate deter-
ministic relations, and shaded nodes are observed.
The generation of the end semantic stack symbol
deterministically triggers the final frame.
to depend only on the previous two stacks and the
last mandatory stack su ? Sm with 1 ? u < t:
P (S|Sm) =
?
?
?
?T
t=1 P (st|st?1, st?2, su)
if S ? Seq(Sm)
0 otherwise
(6)
P (R|S?) =
T?
t=1
P (rt|rt?1, s
?
t?1, s
?
t , s
?
t+1) (7)
While dynamic Bayesian networks typically
take sequential inputs, mapping a set of seman-
tic stacks to a sequence of phrases is achieved
by keeping track of the mandatory stacks that
were visited in the current sequence (see stack set
tracker variable in Fig. 1), and pruning any se-
quence that has not included all mandatory input
stacks on reaching the final frame (see observed
stack set validator variable in Fig. 1). Since the
number of intermediary stacks is not known at de-
coding time, the network is unrolled for a fixed
number of frames T defining the maximum num-
ber of phrases that can be generated (e.g., T =
50). The end of the stack sequence is then deter-
mined by a special end symbol, which can only
be emitted within the T frames once all mandatory
stacks have been visited. The probability of the re-
sulting utterance is thus computed over all frames
up to the end symbol, which determines the length
1554
L of S? and R?. While the decoding constraints
enforce that L > |Sm|, the search for S? requires
comparing sequences of different lengths. A con-
sequence is that shorter sequences containing only
mandatory stacks are likely to be favoured. While
future work should investigate length normalisa-
tion strategies, we find that the learned transition
probabilities are skewed enough to favour stack
sequences including intermediary stacks.
Once the topology and the decoding constraints
of the network have been defined, any inference al-
gorithm can be used to search for S? and R?. We
use the junction tree algorithm implemented in the
Graphical Model ToolKit (GMTK) for our exper-
iments (Bilmes and Zweig, 2002), however both
problems can be solved using a standard Viterbi
search given the appropriate state representation.
In terms of computational complexity, it is impor-
tant to note that the number of stack sequences
Seq(Sm) to search over increases exponentially
with the number of input mandatory stacks. Nev-
ertheless, we find that real-time performance can
be achieved by pruning low probability sequences,
without affecting the quality of the solution.
3.1 Generalisation to unseen semantic stacks
In order to generalise to semantic stacks which
have not been observed during training, the re-
alisation phrase r is made dependent on under-
specified stack configurations, i.e. the tail l
and the head h of the stack. For example, the
last stack in Table 1 is associated with the head
centre and the tail inform(area). As a re-
sult, BAGEL assigns non-zero probabilities to re-
alisation phrases in unseen semantic contexts, by
backing off to the head and the tail of the stack.
A consequence is that BAGEL?s lexical realisa-
tion can generalise across contexts. For exam-
ple, if reject(area(centre)) was never ob-
served at training time, P (r = centre of town|s =
reject(area(centre))) will be estimated by
backing off to P (r = centre of town|h =
centre). BAGEL can thus generate ?there are
no venues in the centre of town? if the phrase
?centre of town? was associated with the con-
cept centre in a different context, such as
inform(area(centre)). The final realisation
model is illustrated in Fig. 2:
realisation phrase r
repeated frame final framefirst frame
stack head h
semantic 
stack s
stack tail l
Figure 2: Graphical model for the realisation
phase. Dashed arrows indicate deterministic re-
lations, and shaded node are observed.
!"#$%&& '(")*+
11111 ,,,,,,,| +?+?? ttttttttt sssllrlhr
ttttttt sllrlhr ,,,,,| 111 +??
111 ,,,,| +?? tttttt llrlhr
ttt lhr ,|21,| ?? ttt sss
uttt ssss ,,| 21 ??
tt hr |1| ?tt ss
trts
Figure 3: Backoff graphs for the semantic decod-
ing and realisation models.
P (R|S?) =
L?
t=1
P (rt|rt?1, ht, lt?1, lt, lt+1,
s?t?1, s
?
t , s
?
t+1) (8)
Conditional probability distributions are repre-
sented as factored language models smoothed us-
ing Witten-Bell interpolated backoff smoothing
(Bilmes and Kirchhoff, 2003), according to the
backoff graphs in Fig. 3. Variables which are the
furthest away in time are dropped first, and par-
tial stack variables are dropped last as they are ob-
served the most.
It is important to note that generating unseen se-
mantic stacks requires all possible mandatory se-
mantic stacks in the target domain to be prede-
fined, in order for all stack unigrams to be assigned
a smoothed non-zero probability.
3.2 High cardinality concept abstraction
While one should expect a trainable generator
to learn multiple lexical realisations for low-
cardinality semantic concepts, learning lexical
realisations for high-cardinality database entries
(e.g., proper names) would increase the number of
model parameters prohibitively. We thus divide
pre-terminal concepts in the semantic stacks into
two types: (a) enumerable attributes whose val-
ues are associated with distinct semantic stacks in
1555
our model (e.g., inform(pricerange(cheap))),
and (b) non-enumerable attributes whose values
are replaced by a generic symbol before train-
ing in both the utterance and the semantic stack
(e.g., inform(name(X)). These symbolic values
are then replaced in the surface realisation by the
corresponding value in the input specification. A
consequence is that our model can only learn syn-
onymous lexical realisations for enumerable at-
tributes.
4 Certainty-based active learning
A major issue with trainable NLG systems is the
lack of availability of domain-specific data. It is
therefore essential to produce NLG models that
minimise the data annotation cost.
BAGEL supports the optimisation of the data
collection process through active learning, in
which the next semantic input to annotate is de-
termined by the current model. The probabilis-
tic nature of BAGEL allows the use of certainty-
based active learning (Lewis and Catlett, 1994),
by querying the k semantic inputs for which the
model is the least certain about its output real-
isation. Given a finite semantic input space I
representing all possible dialogue acts in our do-
main (i.e., the set of all sets of mandatory seman-
tic stacks Sm), BAGEL?s active learning training
process iterates over the following steps:
1. Generate an utterance for each semantic input Sm ? I
using the current model.2
2. Annotate the k semantic inputs {S1m...S
k
m} yielding
the lowest realisation probability, i.e. for q ? (1..k)
Sqm = argmin
Sm?I\{S1m...S
q?1
m }
(max
R
P (R|Sm)) (9)
with P (R|Sm) defined in (2).
3. Retrain the model with the additional k data points.
The number of utterances to be queried k should
depend on the flexibility of the annotators and the
time required for generating all possible utterances
in the domain.
5 Experimental method
BAGEL?s factored language models are trained us-
ing the SRILM toolkit (Stolcke, 2002), and de-
coding is performed using GMTK?s junction tree
inference algorithm (Bilmes and Zweig, 2002).
2Sampling methods can be used if I is infinite or too
large.
Since each active learning iteration requires gen-
erating all training utterances in our domain, they
are generated using a larger clique pruning thresh-
old than the test utterances used for evaluation.
5.1 Corpus collection
We train BAGEL in the context of a dialogue
system providing information about restaurants
in Cambridge. The domain contains two dia-
logue act types: (a) inform: presenting infor-
mation about a restaurant (see Table 1), and (b)
reject: informing that the user?s constraints can-
not be met (e.g., ?There is no cheap restaurant
in the centre?). Our domain contains 8 restau-
rant attributes: name, food, near, pricerange,
postcode, phone, address, and area, out of
which food, pricerange, and area are treated
as enumerable.3 Our input semantic space is ap-
proximated by the set of information presentation
dialogue acts produced over 20,000 simulated di-
alogues between our statistical dialogue manager
(Young et al, 2010) and an agenda-based user
simulator (Schatzmann et al, 2007), which results
in 202 unique dialogue acts after replacing non-
enumerable values by a generic symbol. Each di-
alogue act contains an average of 4.48 mandatory
semantic stacks.
As one of our objectives is to test whether
BAGEL can learn from data provided by a large
sample of untrained annotators, we collected a
corpus of semantically-aligned utterances using
Amazon?s Mechanical Turk data collection ser-
vice. A crucial aspect of data collection for
NLG is to ensure that the annotators under-
stand the meaning of the semantics to be con-
veyed. Annotators were first asked to provide
an utterance matching an abstract description
of the dialogue act, regardless of the order in
which the constraints are presented (e.g., Offer
the venue Taj Mahal and provide the information
type(restaurant), area(riverside), food(Indian),
near(The Red Lion)). The order of the constraints
in the description was randomised to reduce the
effect of priming. The annotators were then asked
to align the attributes (e.g., Indicate the region of
the utterance related to the concept ?area?), and
the attribute values (e.g., Indicate only the words
related to the concept ?riverside?). Two para-
phrases were collected for each dialogue act in
our domain, resulting in a total of 404 aligned ut-
3With the exception of areas defined as proper nouns.
1556
rt st ht lt
<s> START START START
The Rice Boat inform(name(X)) X inform(name)
is a inform inform EMPTY
restaurant inform(type(restaurant)) restaurant inform(type)
in the inform(area) area inform
riverside inform(area(riverside)) riverside inform(area)
area inform(area) area inform
that inform inform EMPTY
serves inform(food) food inform
French inform(food(French)) French inform(food)
food inform(food) food inform
</s> END END END
Table 2: Example utterance annotation used to estimate the conditional probability distributions of the
models in Figs. 1 and 2 ( rt=realisation phrase, st=semantic stack, ht=stack head, lt=stack tail).
terances produced by 42 native speakers of En-
glish. After manually checking and normalising
the dataset,4 the layered annotations were auto-
matically mapped to phrase-level semantic stacks
by splitting the utterance into phrases at annotation
boundaries. Each annotated utterance is then con-
verted into a sequence of symbols such as in Ta-
ble 2, which are used to estimate the conditional
probability distributions defined in (6) and (8).
The resulting vocabulary consists of 52 distinct se-
mantic stacks and 109 distinct realisation phrases,
with an average of 8.35 phrases per utterance.
5.2 BLEU score evaluation
We first evaluate BAGEL using the BLEU auto-
mated metric (Papineni et al, 2002), which mea-
sures the word n-gram overlap between the gen-
erated utterances and the 2 reference paraphrases
over a test corpus (with n up to 4). While BLEU
suffers from known issues such as a bias towards
statistical NLG systems (Reiter and Belz, 2009), it
provides useful information when comparing sim-
ilar systems. We evaluate BAGEL for different
training set sizes, model dependencies, and active
learning parameters. Our results are averaged over
a 10-fold cross-validation over distinct dialogue
acts, i.e. dialogue acts used for testing are not seen
at training time,5 and all systems are tested on the
same folds. The training and test sets respectively
contain an average of 181 and 21 distinct dialogue
acts, and each dialogue act is associated with two
paraphrases, resulting in 362 training utterances.
4The normalisation process took around 4 person-hour for
404 utterances.
5We do not evaluate performance on dialogue acts used
for training, as the training examples can trivially be used as
generation templates.
!"#$
!"%
!"%$
!"#
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
!"$
!"$$
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
&'(()*+,-(
!".
!".$!"
#
$
%
&
'
(
)
%
*
+
,
-
"
/+)01234)5234+66/+)01234)5234+667)8+)6'1'9-)0-*281:30!";$ <! =! .! #! >! <!! <=! <$! =!! =$! ;!! ;#=
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
.-#/$/$0%*"1%*/2"
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
Figure 4: BLEU score averaged over a 10-fold
cross-validation for different training set sizes and
network topologies, using random sampling.
Results: Fig. 4 shows that adding a dependency
on the future semantic stack improves perfor-
mances for all training set sizes, despite the added
model complexity. Backing off to partial stacks
also improves performance, but only for sparse
training sets.
Fig. 5 compares the full model trained using
random sampling in Fig. 4 with the same model
trained using certainty-based active learning, for
different values of k. As our dataset only con-
tains two paraphrases per dialogue act, the same
dialogue act can only be queried twice during the
active learning procedure. A consequence is that
the training set used for active learning converges
towards the randomly sampled set as its size in-
creases. Results show that increasing the train-
ing set one utterance at a time using active learn-
ing (k = 1) significantly outperforms random
sampling when using 40, 80, and 100 utterances
(p < .05, two-tailed). Increasing the number of
utterances to be queried at each iteration to k = 10
results in a smaller performance increase. A possi-
1557
!"#
!"##
!"$
!"$#
!"%
!"%#
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
&'()*+,-'+./0(1
!"2#
!"3
!"3#
4! 5! 3! $! 6! 4!! 45! 4#! 5!! 5#! 2!! 2$5
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
.-#/$/$0%*"1%*/2"
7890:;,/;'<(0(1,=>47890:;,/;'<(0(1,=>4!
Figure 5: BLEU score averaged over a 10-fold
cross-validation for different numbers of queries
per iteration, using the full model with the query
selection criterion (9).
!"#
!"##
!"$
!"$#
!"%
!"%#
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
&'(()(*+,-*.
!"/#
!"0
!"0#
1! 2! 0! $! 3! 1!! 12! 1#! 2!! 2#! /!! /$2
!
"
#
$
%
&
'
(
)
%
*
+
,
-
"
.-#/$/$0%*"1%*/2"
4*+,-*.),5-)6-7854*9+5:;)<9,';)6<-:;
Figure 6: BLEU score averaged over a 10-fold
cross-validation for different query selection cri-
teria, using the full model with k = 1.
ble explanation is that the model is likely to assign
low probabilities to similar inputs, thus any value
above k = 1 might result in redundant queries
within an iteration.
As the length of the semantic stack sequence
is not known before decoding, the active learn-
ing selection criterion presented in (9) is biased
towards longer utterances, which tend to have a
lower probability. However, Fig. 6 shows that
normalising the log probability by the number of
semantic stacks does not improve overall learn-
ing performance. Although a possible explanation
is that longer inputs tend to contain more infor-
mation to learn from, Fig. 6 shows that a base-
line selecting the largest remaining semantic input
at each iteration performs worse than the active
learning scheme for training sets above 20 utter-
ances. The full log probability selection criterion
defined in (9) is therefore used throughout the rest
of the paper (with k = 1).
5.3 Human evaluation
While automated metrics provide useful informa-
tion for comparing different systems, human feed-
back is needed to assess (a) the quality of BAGEL?s
outputs, and (b) whether training models using ac-
tive learning has a significant impact on user per-
ceptions. We evaluate BAGEL through a large-
scale subjective rating experiment using Amazon?s
Mechanical Turk service.
For each dialogue act in our domain, partici-
pants are presented with a ?gold standard? human
utterance from our dataset, which they must com-
pare with utterances generated by models trained
with and without active learning on a set of 20, 40,
100, and 362 utterances (full training set), as well
as with the second human utterance in our dataset.
See example utterances in Table 3. The judges are
then asked to evaluate the informativeness and nat-
uralness of each of the 8 utterances on a 5 point
likert-scale. Naturalness is defined as whether the
utterance could have been produced by a human,
and informativeness is defined as whether it con-
tains all the information in the gold standard utter-
ance. Each utterance is taken from the test folds of
the cross-validation experiment presented in Sec-
tion 5.2, i.e. the models are trained on up to 90%
of the data and the training set does not contain the
dialogue act being tested.
Results: Figs. 7 and 8 compare the naturalness
and informativeness scores of each system aver-
aged over all 202 dialogue acts. A paired t-test
shows that models trained on 40 utterances or
less produce utterances that are rated significantly
lower than human utterances for both naturalness
and informativeness (p < .05, two-tailed). How-
ever, models trained on 100 utterances or more do
not perform significantly worse than human utter-
ances for both dimensions, with a mean difference
below .10 over 202 comparisons. Given the large
sample size, this result suggests that BAGEL can
successfully learn our domain using a fraction of
our initial dataset.
As far as the learning method is concerned, a
paired t-test shows that models trained on 20 and
40 utterances using active learning significantly
outperform models trained using random sam-
pling, for both dimensions (p < .05). The largest
increase is observed using 20 utterances, i.e. the
naturalness increases by .49 and the informative-
ness by .37. When training on 100 utterances, the
effect of active learning becomes insignificant. In-
1558
Input inform(name(the Fountain) near(the Arts Picture House) area(centre) pricerange(cheap))
Human There is an inexpensive restaurant called the Fountain in the centre of town near the Arts Picture House
Rand-20 The Fountain is a restaurant near the Arts Picture House located in the city centre cheap price range
Rand-40 The Fountain is a restaurant in the cheap city centre area near the Arts Picture House
AL-20 The Fountain is a restaurant near the Arts Picture House in the city centre cheap
AL-40 The Fountain is an affordable restaurant near the Arts Picture House in the city centre
Full set The Fountain is a cheap restaurant in the city centre near the Arts Picture House
Input reject(area(Barnwell) near(Saint Mary?s Church))
Human I am sorry but I know of no venues near Saint Mary?s Church in the Barnwell area
Full set I am sorry but there are no venues near Saint Mary?s Church in the Barnwell area
Input inform(name(the Swan)area(Castle Hill) pricerange(expensive))
Human The Swan is a restaurant in Castle Hill if you are seeking something expensive
Full set The Swan is an expensive restaurant in the Castle Hill area
Input inform(name(Browns) area(centre) near(the Crowne Plaza) near(El Shaddai) pricerange(cheap))
Human Browns is an affordable restaurant located near the Crowne Plaza and El Shaddai in the centre of the city
Full set Browns is a cheap restaurant in the city centre near the Crowne Plaza and El Shaddai
Table 3: Example utterances for different input dialogue acts and system configurations. AL-20 = active
learning with 20 utterances, Rand = random sampling.
!"## !"$%
!"&'!"(% !")* *"%% *"%#
*"%'
++"$
!!"$
**"$
$
!
"
#
$
%
$
#
&
'
(
#
)
$
"
*
*
%
*
+
,
(
"
,-./01
##"$ +% *% #%% !(+
!
"
#
$
%
$
#
&
'
(
#
)
$
"
*
*
%
*
+
,
(
"
-(#.$.$/%*"&%*.0"
234567897-:.5.;<=1-.8=447:-.378>8*"%'
Figure 7: Naturalness mean opinion scores for dif-
ferent training set sizes, using random sampling
and active learning. Differences for training set
sizes of 20 and 40 are all significant (p < .05).
terestingly, while models trained on 100 utterances
outperform models trained on 40 utterances using
random sampling (p < .05), they do not signifi-
cantly outperform models trained on 40 utterances
using active learning (p = .15 for naturalness and
p = .41 for informativeness). These results sug-
gest that certainty-based active learning is benefi-
cial for training a generator from a limited amount
of data given the domain size.
Looking back at the results presented in Sec-
tion 5.2, we find that the BLEU score correlates
with a Pearson correlation coefficient of .42 with
the mean naturalness score and .35 with the mean
informativeness score, over all folds of all systems
tested (n = 70, p < .01). This is lower than
previous correlations reported by Reiter and Belz
(2009) in the shipping forecast domain with non-
expert judges (r = .80), possibly because our do-
main is larger and more open to subjectivity.
!"## !"$$
#"%&!"'& !"()
#"%$ #"%#
#"&!
**"+
!!"+
##"+
+
!
"
#
$
%
&
$
'
(
)
*
#
+
&
,
"
$
"
-
-
%
-
.
(
)
"
,-./01
&&"+ *% #% &%% !)*
!
"
#
$
%
&
$
'
(
)
*
#
+
&
,
"
$
"
-
-
%
-
.
(
)
"
/)#&$&$0%-"+%-&1"
234567897-:.5.;<=1-.8=447:-.378>8#"&!
Figure 8: Informativeness mean opinion scores for
different training set sizes, using random sampling
and active learning. Differences for training set
sizes of 20 and 40 are all significant (p < .05).
6 Related work
While most previous work on trainable NLG re-
lies on a handcrafted component (see Section 1),
recent research has started exploring fully data-
driven NLG models.
Factored language models have recently been
used for surface realisation within the OpenCCG
framework (White et al, 2007; Espinosa et al,
2008). More generally, chart generators for
different grammatical formalisms have been
trained from syntactic treebanks (White et al,
2007; Nakanishi et al, 2005), as well as from
semantically-annotated treebanks (Varges and
Mellish, 2001). However, a major difference with
our approach is that BAGEL uses domain-specific
data to generate a surface form directly from se-
mantic concepts, without any syntactic annotation
(see Section 7 for further discussion).
1559
This work is strongly related to Wong and
Mooney?s WASP?1 generation system (2007),
which combines a language model with an in-
verted synchronous CFG parsing model, effec-
tively casting the generation task as a translation
problem from a meaning representation to natu-
ral language. WASP?1 relies on GIZA++ to align
utterances with derivations of the meaning repre-
sentation (Och and Ney, 2003). Although early
experiments showed that GIZA++ did not perform
well on our data?possibly because of the coarse
granularity of our semantic representation?future
work should evaluate the generalisation perfor-
mance of synchronous CFGs in a dialogue system
domain.
Although we do not know of any work on ac-
tive learning for NLG, previous work has used
active learning for semantic parsing and informa-
tion extraction (Thompson et al, 1999; Tang et al,
2002), spoken language understanding (Tur et al,
2003), speech recognition (Hakkani-Tu?r et al,
2002), word alignment (Sassano, 2002), and more
recently for statistical machine translation (Blood-
good and Callison-Burch, 2010). While certainty-
based methods have been widely used, future work
should investigate the performance of committee-
based active learning for NLG, in which examples
are selected based on the level of disagreement be-
tween models trained on subsets of the data (Fre-
und et al, 1997).
7 Discussion and conclusion
This paper presents and evaluates BAGEL, a sta-
tistical language generator that can be trained en-
tirely from data, with no handcrafting required be-
yond the semantic annotation. All the required
subtasks?i.e. content ordering, aggregation, lex-
ical selection and realisation?are learned from
data using a unified model. To train BAGEL in a di-
alogue system domain, we propose a stack-based
semantic representation at the phrase level, which
is expressive enough to generate natural utterances
from unseen inputs, yet simple enough for data to
be collected from 42 untrained annotators with a
minimal normalisation step. A human evaluation
over 202 dialogue acts does not show any differ-
ence in naturalness and informativeness between
BAGEL?s outputs and human utterances. Addition-
ally, we find that the data collection process can
be optimised using active learning, resulting in a
significant increase in performance when training
data is limited, according to ratings from 18 hu-
man judges.6 These results suggest that the pro-
posed framework can largely reduce the develop-
ment time of NLG systems.
While this paper only evaluates the most likely
realisation given a dialogue act, we believe that
BAGEL?s probabilistic nature and generalisation
capabilities are well suited to model the linguis-
tic variation resulting from the diversity of annota-
tors. Our first objective is thus to evaluate the qual-
ity of BAGEL?s n-best outputs, and test whether
sampling from the output distribution can improve
naturalness and user satisfaction within a dialogue.
Our results suggest that explicitly modelling
syntax is not necessary for our domain, possi-
bly because of the lack of syntactic complexity
compared with formal written language. Never-
theless, future work should investigate whether
syntactic information can improve performance in
more complex domains. For example, the reali-
sation phrase can easily be conditioned on syntac-
tic constructs governing that phrase, and the recur-
sive nature of syntax can be modelled by keeping
track of the depth of the current embedded clause.
While syntactic information can be included with
no human effort by using syntactic parsers, their
robustness to dialogue system utterances must first
be evaluated.
Finally, recent years have seen HMM-based
synthesis models become competitive with unit se-
lection methods (Tokuda et al, 2000). Our long
term objective is to take advantage of those ad-
vances to jointly optimise the language genera-
tion and the speech synthesis process, by combin-
ing both components into a unified probabilistic
concept-to-speech generation model.
References
S. Bangalore and O. Rambow. Exploiting a probabilistic hi-
erarchical model for generation. In Proceedings of the
18th International Conference on Computational Linguis-
tics (COLING), pages 42?48, 2000.
A. Belz. Automatic generation of weather forecast texts us-
ing comprehensive probabilistic generation-space models.
Natural Language Engineering, 14(4):431?455, 2008.
J. Bilmes and K. Kirchhoff. Factored language models and
generalized parallel backoff. In Proceedings of HLT-
NAACL, short papers, 2003.
J. Bilmes and G. Zweig. The Graphical Models ToolKit: An
open source software system for speech and time-series
processing. In Proceedings of ICASSP, 2002.
6The full training corpus and the generated
utterances used for evaluation are available at
http://mi.eng.cam.ac.uk/?farm2/bagel.
1560
M. Bloodgood and C. Callison-Burch. Bucking the trend:
Large-scale cost-focused active learning for statistical ma-
chine translation. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguistics
(ACL), 2010.
D. Espinosa, M. White, and D. Mehay. Hypertagging: Su-
pertagging for surface realization with CCG. In Proceed-
ings of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL), 2008.
Y. Freund, H. S. Seung, E.Shamir, and N. Tishby. Selective
sampling using the query by committee algorithm. Ma-
chine Learning, 28:133?168, 1997.
D. Hakkani-Tu?r, G. Riccardi, and A. Gorin. Active learn-
ing for automatic speech recognition. In Proceedings of
ICASSP, 2002.
Y. He and S. Young. Semantic processing using the Hidden
Vector State model. Computer Speech & Language, 19
(1):85?106, 2005.
A. Isard, C. Brockmann, and J. Oberlander. Individuality and
alignment in generated dialogues. In Proceedings of the
4th International Natural Language Generation Confer-
ence (INLG), pages 22?29, 2006.
I. Langkilde and K. Knight. Generation that exploits corpus-
based statistical knowledge. In Proceedings of the 36th
Annual Meeting of the Association for Computational Lin-
guistics (ACL), pages 704?710, 1998.
F. Lefe`vre. A DBN-based multi-level stochastic spoken lan-
guage understanding system. In Proceedings of the IEEE
Workshop on Spoken Language Technology (SLT), 2006.
D. D. Lewis and J. Catlett. Heterogeneous uncertainty am-
pling for supervised learning. In Proceedings of ICML,
1994.
F. Mairesse and M. A. Walker. Trainable generation of Big-
Five personality styles through data-driven parameter esti-
mation. In Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics (ACL), 2008.
H. Nakanishi, Y. Miyao, , and J. Tsujii. Probabilistic methods
for disambiguation of an HPSG-based chart generator. In
Proceedings of the IWPT, 2005.
F. J. Och and H. Ney. A systematic comparison of various
statistical alignment models. Computational Linguistics,
29(1):19?51, 2003.
D. S. Paiva and R. Evans. Empirically-based control of nat-
ural language generation. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational Lin-
guistics (ACL), pages 58?65, 2005.
K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. BLEU: a
method for automatic evaluation of machine translation. In
Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL), 2002.
L. R. Rabiner. Tutorial on Hidden Markov Models and se-
lected applications in speech recognition. Proceedings of
the IEEE, 77(2):257?285, 1989.
E. Reiter and A. Belz. An investigation into the validity
of some metrics for automatically evaluating natural lan-
guage generation systems. Computational Linguistics, 25:
529?558, 2009.
V. Rieser and O. Lemon. Natural language generation as
planning under uncertainty for spoken dialogue systems.
In Proceedings of the Annual Meeting of the European
Chapter of the ACL (EACL), 2009.
M. Sassano. An empirical study of active learning with sup-
port vector machines for japanese word segmentation. In
Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL), 2002.
J. Schatzmann, B. Thomson, K. Weilhammer, H. Ye, and
S. Young. Agenda-based user simulation for bootstrap-
ping a POMDP dialogue system. In Proceedings of HLT-
NAACL, short papers, pages 149?152, 2007.
A. Stolcke. SRILM ? an extensible language modeling
toolkit. In Proceedings of the International Conference
on Spoken Language Processing, 2002.
M. Tang, X. Luo, and S. Roukos. Active learning for statis-
tical natural language parsing. In Proceedings of the 40th
Annual Meeting of the Association for Computational Lin-
guistics (ACL), 2002.
C. Thompson, M. E. Califf, and R. J. Mooney. Active learn-
ing for natural language parsing and information extrac-
tion. In Proceedings of ICML, 1999.
B. Thomson and S. Young. Bayesian update of dialogue state:
A POMDP framework for spoken dialogue systems. Com-
puter Speech & Language, 24(4):562?588, 2010.
Y. Tokuda, T. Yoshimura, T. Masuko, T. Kobayashi, and
T. Kitamura. Speech parameter generation algorithms for
HMM-based speech synthesis. In Proceedings of ICASSP,
2000.
G. Tur, R. E. Schapire, and D. Hakkani-Tu?r. Active learn-
ing for spoken language understanding. In Proceedings of
ICASSP, 2003.
S. Varges and C. Mellish. Instance-based natural language
generation. In Proceedings of the Annual Meeting of the
North American Chapter of the ACL (NAACL), 2001.
M. A. Walker, O. Rambow, and M. Rogati. Training a sen-
tence planner for spoken dialogue using boosting. Com-
puter Speech and Language, 16(3-4), 2002.
M. White, R. Rajkumar, and S. Martin. Towards broad cov-
erage surface realization with CCG. In Proceedings of the
Workshop on Using Corpora for NLG: Language Genera-
tion and Machine Translation, 2007.
Y. W. Wong and R. Mooney. Generation by inverting a se-
mantic parser that uses statistical machine translation. In
Proceedings of HLT-NAACL, 2007.
S. Young, M. Gas?ic?, S. Keizer, F. Mairesse, J. Schatzmann,
B. Thomson, and K. Yu. The Hidden Information State
model: a practical framework for POMDP-based spoken
dialogue management. Computer Speech and Language,
24(2):150?174, 2010.
1561
Proceedings of the ACL Student Research Workshop, pages 158?164,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Robust Multilingual Statistical Morphological Generation Models
Ondr?ej Du?ek and Filip Jurc??c?ek
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
Malostransk? n?me?st? 25, CZ-11800 Praha, Czech Republic
{odusek,jurcicek}@ufal.mff.cuni.cz
Abstract
We present a novel method of statisti-
cal morphological generation, i.e. the pre-
diction of inflected word forms given
lemma, part-of-speech and morphological
features, aimed at robustness to unseen in-
puts. Our system uses a trainable classifier
to predict ?edit scripts? that are then used
to transform lemmas into inflected word
forms. Suffixes of lemmas are included as
features to achieve robustness. We evalu-
ate our system on 6 languages with a vary-
ing degree of morphological richness. The
results show that the system is able to learn
most morphological phenomena and gen-
eralize to unseen inputs, producing sig-
nificantly better results than a dictionary-
based baseline.
1 Introduction
Surface realization is an integral part of all natu-
ral language generation (NLG) systems, albeit of-
ten implemented in a very simple manner, such
as filling words into ready hand-written templa-
tes. More sophisticated methods use hand-written
grammars (Gatt and Reiter, 2009), possibly in
combination with a statistical reranker (Langkilde
and Knight, 1998). Existing NLG systems are
very often applied to languages with little mor-
phology, such as English, where a small set of
hand-written rules or the direct use of word forms
in the symbolic representation or templates is usu-
ally sufficient, and so the main focus of these sys-
tems lies on syntax and word order.
However, this approach poses a problem in lan-
guages with a complex morphology. Avoiding
inflection, i.e. ensuring that a word lemma will
keep its base form at all times, often leads to
very unnatural results (see Figure 1). Some gen-
erators use a hand-made morphological dictionary
Toto se l?b? u?ivateli Jana Nov?kov?.----------- -- --? ?This is liked by user (name) femininenominativemasculinedative
word inserted to avoid inflecting the name
name left uninflected(correct form: vocative)
D?kujeme, Jan Nov?k , va?e hlasov?n? Thank you, (name) your poll has been createdbylo vytvo?eno.nominativee u
Figure 1: Unnatural language resulting from tem-
plates with no inflection.
The sentences are taken from the Czech translations of Face-
book and Doodle, which use simple templates to generate
personalized texts. Corrections to make the text fluent are
shown in red.
for inflection (Pt?c?ek and ?abokrtsk?, 2006) or a
dictionary learned from automatically tagged data
(Toutanova et al, 2008). That gives good results,
but reaching sufficient coverage with a hand-made
dictionary is a very demanding task and even using
extreme amounts of automatically annotated data
will not generalize beyond the word forms already
encountered in the corpus. Hand-written rules can
become overly complex and are not easily adapt-
able for a different language.
Therefore, the presented method relies on a sta-
tistical approach that learns to predict morpholog-
ical inflection from annotated data. As a result,
such approach is more robust, i.e. capable of gen-
eralizing to unseen inputs, and easily portable to
different languages.
An attempt to implement statistical morpholog-
ical generation has already been made by Bohnet
et al (2010). However, their morphology genera-
tion was only a component of a complex genera-
tion system. Therefore, no deep analysis of the ca-
pabilities of the methods has been performed. In
addition, their method did not attempt to general-
ize beyond seen inputs. In this paper, we propose
158
several improvements and provide a detailed eval-
uation of a statistical morphological inflection sys-
tem, including more languages into the evaluation
and focusing on robustness to unseen inputs.
The paper is structured as follows: first, we
explain the problem of morphological generation
(Section 2), then give an account of our system
(Section 3). Section 4 provides a detailed evalua-
tion of the performance of our system in different
languages. We then compare our system to related
works in Section 5. Section 6 concludes the paper.
2 The Problem of Morphological
Realization
The problem of morphological surface realization
is inverse to part-of-speech tagging and lemma-
tization (or stemming): given a lemma/stem of
a word and its part-of-speech and morphological
properties, the system should output the correctly
inflected form of the word. An example is given
in Figure 2. This does not include generating aux-
iliary words (such as be? will be), which are as-
sumed to be already generated.word NNS words+Wort NN W?rtern+be VBZ is+ser V gen=c,num=s,person=3,mood=indicative,tense=present es+
Neut,Pl,Dat
Figure 2: The task of morphological generation
(examples for English, German, and Spanish).
While this problem can be solved by a set of
rules to a great extent for languages with little mor-
phology such as English (Minnen et al, 2001),
it becomes much more complicated in languages
with a complex nominal case system or multiple
synthetic verbal inflection patterns, such as Ger-
man or Czech. Figure 3 shows an example of am-
biguity in these languages.
This research aims to create a system that is
easy to train from morphologically annotated data,
yet able to infer and apply more general rules and
generate forms unseen in the training corpus.
3 Our Morphological Generation Setup
Similarly to Bohnet et al (2010), our system is
based on the prediction of edit scripts (diffs) be-
tween the lemma and the target word form (see
Section 3.1), which are then used to derive the tar-
get word form from the lemma. This allows the
wordN wordNemSs+Wt?enwWb?VBZWiVThis lkedgdwo gdwoemSs+W=?enwWc?VBZW,VTbyked um+gp3 gon?um+aSs+Wa?enwWv?VBZWiV Ss+Wa?enwWv?VBZWiVT yuredTrlud
Psllsr PsllsrsSs+?iD?anw VVT(niaed!Zn !ZnsVdZ?,l?=sZVVTmuik)hid "srr "srrenVdZ?,l?anw VVTrludan++ a?++erVdZ?,l?anw VVThikd
Figure 3: Morphological ambiguity in German
and Czech.
The same inflection pattern is used to express multiple mor-
phological properties (left) and multiple patterns may express
the same property (right).
system to operate even on previously unseen lem-
mas. The employed classifier and features are de-
scribed in Sections 3.2 and 3.3. Section 3.4 then
gives an overview of the whole morphological in-
flection process.
3.1 Lemma-Form Edit Scripts
Our system uses lemma-form edit scripts based
on the Levenshtein string distance metric (Lev-
enshtein, 1966): the dynamic programming algo-
rithm used to compute the distance can be adapted
to produce diffs on characters, i.e. a mapping from
the source string (lemma) to the target string (word
form) that indicates which characters were added,
replaced or removed.
We use the distance from the end of the word to
indicate the position of a particular change, same
as Bohnet et al (2010). We have added several
enhancements to this general scenario:
? Our system treats separately changes at the
beginning of the word, since they are usually
independent of the word length and always
occur at the beginning, such as the prefix ge-
for past participles in German or ne- for nega-
tion in Czech.
? Adjacent changes in the string are joined to-
gether to produce a total lower number of
more complex changes.
? If the Levenshtein edit script indicates a re-
moval of letters from the beginning of the
word, we treat the target word form as irreg-
ular, i.e. as if the whole word changed.
? In our setup, the edit scripts need not be
treated as atomic, which allows to train sep-
arate classification models for word changes
that are orthogonal (cf. Section 3.4).
159
An example of the edit scripts generated by our
system is shown in Figure 4.
worr wdrrNS >0-er,3:1-?s+ s+Wrt >0-ing
?N We *isenoSNr tNenoSb >2-t,<ge
VVNtoS VVNtB >2-?
Zisib rNZg=N >4-?me,<ne
cNr, cN, >2:1-=orbNrWS =orbWrsSor >0-an,2:1-d,4:1-i
Figure 4: Example edit scripts generated by our
system.
The changes are separated by commas. ?>? denotes a change
at the end of the word, ?N :? denotes a change at the N -th
character from the end. The number of deleted characters
and their replacement follows in both cases. ?<? marks ad-
ditions to the beginning of a word (regardless of its length).
?*? marks irregular forms where the whole word is replaced.
Our diffs are case-insensitive since we believe
that letter-casing and morphology are distinct phe-
nomena and should be treated separately. Case-
insensitivity, along with merging adjacent changes
and the possibility to split models, causes a de-
crease in the number of different edit scripts, thus
simplifying the task for the classifier.
In our preliminary experiments on Czech, we
also explored the possibility of using different dis-
tance metrics for the edit scripts, such as vari-
ous settings of the Needleman-Wunsch algorithm
(Needleman and Wunsch, 1970) or the longest
common subsequence1 post-edited with regular
expressions to lower the total number of changes.
However, this did not have any noticeable impact
on the performance of the models.
3.2 Used Statistical Models
We use the multi-class logistic regression classi-
fier from the LibLINEAR package2 (Fan et al,
2008) for the prediction of edit scripts. We use
L1-regularization since it yields models that are
smaller in size and the resulting trained weights
indicate the important features in a straightforward
way. This direct influence on features (similar to
keyword spotting) allows for a simple interpreta-
tion of the learned models. We examined various
settings of the regularization cost and the termina-
tion criterion (See Section 4.1).
We have also experimented with support vec-
tor machines from the LibSVM package (Chang
1We used the Perl implementation of this algorithm from
https://metacpan.org/module/String::Diff.
2We use it via the Python wrapper in the Scikit-Learn li-
brary (http://scikit-learn.org).
and Lin, 2011), but the logistic regression clas-
sifier proved to be better suited to this task, pro-
viding a higher edit script accuracy on the devel-
opment set for German and Czech (when feature
concatenation is used, cf. Section 3.3), while also
requiring less CPU time and RAM to train.
3.3 Features
While the complete set of features varies across
languages given their specifics, most of the fea-
tures are common to all languages:
? lemma of the word in question,
? coarse and fine-grained part-of-speech tag,
? morphological features (e.g. case, gender,
tense etc., tagset-dependent), and
? suffixes of the lemma of up to 4 characters.
Since morphological changes usually occur near
the end of the word, they mostly depend just on
that part of the word and not on e.g. prefixes or
previous parts of a compound. Therefore, using
suffixes allows the classifier to generalize to un-
known words.
In addition, as we use a linear classifier, we have
found the concatenation of various morphologi-
cal features, such as number, gender, and case in
nouns or tense and person in verbs, to be very ben-
eficial. We created new features by concatenating
all possible subsets of morphological features, as
long as all their values were non-empty (to prevent
from creating duplicate values). To avoid com-
binatorial explosion, we resorted to concatenating
only case, number, and gender for Czech and ex-
cluding the postype feature from concatenation
for Spanish and Catalan.
We also employ the properties of adjacent
words in the sentence as features in our models
for the individual languages (see Section 4). These
are used mainly to model congruency (is vs. are in
English, different adjectival declension after defi-
nite and indefinite article in German) or article vo-
calization (l? vs. el in Catalan). The congruency
information could be obtained more reliably from
elsewhere in a complete NLG system (e.g. features
from the syntactic realizer), which would probably
result in a performance gain, but lies beyond the
scope of this paper.
No feature pruning was needed in our setup as
our classifier was able to handle the large amount
of features (100,000s, language-dependent).
160
3.4 Overall Schema of the Predictor
After an examination of the training data, we de-
cided to use a separate model for the changes that
occur at the beginning of the word since they tend
to be much simpler than and not very dependent on
the changes towards the end of the word (e.g. the
usages of the Czech negation prefix ne- or the Ger-
man infinitive prefix zu- are quite self-contained
phenomena).
The final word inflection prediction schema
looks as follows:
1. Using the statistical model described in Sec-
tion 3.2, predict an edit script (cf. Section 3.1)
for changes at the end or in the middle of the
word.3
2. Predict an edit script for the possible addition
of a prefix using a separate model.
3. Apply the edit scripts predicted by the pre-
vious steps as rules to generate the final in-
flected word form.
4 Experimental Evaluation
We evaluate our morphological generation setup
on all of the languages included in the CoNLL
2009 Shared Task data sets except Chinese (which,
as an isolating language, lacks morphology almost
altogether): English, German, Spanish, Catalan,
Japanese, and Czech. We use the CoNLL 2009
data sets (Hajic? et al, 2009) with gold-standard
morphology annotation for all our experiments
(see Table 1 for a detailed overview).
We give a discussion of the overall performance
of our system in all the languages in Section 4.1.
We focus on Czech in the detailed analysis of the
generalization power of our system in Section 4.2
since Czech has the most complicated morphology
of all these languages. In addition, the morpho-
logical annotation provided in the CoNLL 2009
Czech data set is more detailed than in the other
languages, which eliminates the need for addi-
tional syntactic features (cf. Section 3.3). We also
provide a detailed performance overview on En-
glish for comparison.
4.1 Overall Performance
The performance of our system in the best set-
tings for the individual languages measured on the
3Completely irregular forms (see Section 3.1) are also
predicted by this step.
CoNLL 2009 evaluation test sets is shown in Ta-
ble 2. We used the classifier and features described
in Sections 3.2 and 3.3 (additional features for the
individual languages are listed in the table). We
used two models as described in Section 3.4 for
all languages but English, where no changes at the
beginning of the word were found in the training
data set and a single model was sufficient. We per-
formed a grid search for the best parameters of the
first model4 and used the same parameters for both
models.5
One can see from the results in Table 2 that
the system is able to predict the majority of word
forms correctly and performs well even on data
unseen in the training set.
When manually inspecting the errors produced
by the system, we observed that in some cases the
system in fact assigned a form synonymous to the
one actually occurring in the test set, such as not
instead of n?t in English or tak? instead of taky
(both meaning also) in Czech. However, most er-
rors are caused by the selection of a more frequent
rule, even if incorrect given the actual morpholog-
ical features. We believe that this could possibly
be mitigated by using features combining lemma
suffixes and morphological categories, or features
from the syntactic context.
The lower score for German is caused partly by
the lack of syntactic features for the highly am-
biguous adjective inflection and partly by a some-
what problematic lemmatization of punctuation
(all punctuation has the lemma ?_? and the part-
of-speech tag only distinguishes terminal, comma-
like and other characters).
4.2 Generalization Power
To measure the ability of our system to generalize
to previously unseen inputs, we compare it against
a baseline that uses a dictionary collected from the
same data and leaves unseen forms intact. The per-
formance of our system on unseen forms is shown
in Table 2 for all languages. A comparison with
the dictionary baseline for varying training data
sizes in English and Czech is given in Table 3.
It is visible from Table 3 that our approach
4We always used L1-norm and primal form and modi-
fied the termination criterion tol and regularization strength
C. The best values found on the development data sets for the
individual languages are listed in Table 2.
5As the changes at the beginning of words are much sim-
pler, changing parameters did not have a significant influence
on the performance of the second model.
161
Language Data set sizes In Eval (%)Train Dev Eval -Punct InflF UnkF
English 958,167 33,368 57,676 85.93 15.14 1.80
German 648,677 32,033 31,622 87.24 45.12 8.69
Spanish 427,442 50,368 50,630 85.42 29.96 6.16
Catalan 390,302 53,015 53,355 86.75 31.89 6.28
Japanese 112,555 6,589 13,615 87.34 10.73 6.43
Czech 652,544 87,988 92,663 85.50 42.98 7.68
Table 1: The CoNLL 2009 data sets: Sizes and properties
The data set sizes give the number of words (tokens) in the individual sets. The right column shows the percentage of data in
the evaluation set: -Punct = excluding punctuation tokens, InflF = only forms that differ from the lemma (i.e. have a non-empty
edit script), UnkF = forms unseen in the training set.
Language Additional features Best parameters Rule (%) Form accuracy (%)accuracy Total -Punc InflF UnkF
English W-1/LT C=10, tol=1e-3 99.56 99.56 99.49 97.76 98.26
German W-1/LT, MC C=10, tol=1e-3 96.66 / 99.91 96.46 98.01 92.64 89.63
Spanish MC C=100, tol=1e-3 99.05 / 99.98 99.01 98.86 97.10 91.11
Catalan W+1/C1, MC C=10, tol=1e-3 98.91 / 99.86 98.72 98.53 96.49 94.24
Japanese MC C=100, tol=1e-3 99.94 / 100.0 99.94 99.93 99.59 99.54
Czech MC C=100, tol=1e-3 99.45 / 99.99 99.45 99.35 98.81 95.93
Table 2: The overall performance of our system in different languages.
The additional features include: MC = concatenation of morphological features (see Section 3.3), W-1/LT = lemma and part-
of-speech tag of the previous word, W+1/C1 = first character of the following word.
Rule (edit script) accuracy is given for the prediction of changes at the end or in the middle and at the beginning of the word,
respectively.
The form accuracy field shows the percentage of correctly predicted (lowercased) target word forms: Total = on the whole
evaluation set; -Punct, InflF, UnkF = on subsets as defined in Table 1.
maintains a significantly6 higher accuracy when
compared to the baseline for all training data
sizes. It is capable of reaching high performance
even with relatively small amounts of training in-
stances. The overall performance difference be-
comes smaller as the training data grow; how-
ever, performance on unseen inputs and relative
error reduction show a different trend: the im-
provement stays stable. The relative error reduc-
tion decreases slightly for English where unknown
word forms are more likely to be base forms of
unknown lemmas, but keeps increasing for Czech
where unknown word forms are more likely to re-
quire inflection (the accuracy reached by the base-
line method on unknown forms equals the percent-
age of base forms among the unknown forms).
Though the number of unseen word forms is de-
clining with increasing amounts of training data,
which plays in favor of the dictionary method, un-
seen inputs will still occur and may become very
frequent for out-of-domain data. Our system is
therefore beneficial ? at least as a back-off for un-
seen forms ? even if a large-coverage morpholog-
6Significance at the 99% level has been assessed using
paired bootstrap resampling (Koehn, 2004).
ical dictionary is available.
We observed upon manual inspection that the
suffix features were among the most prominent
for the prediction of many edit scripts, which indi-
cates their usefulness; e.g. LemmaSuffix1=e is
a strong feature (along with POS_Tag=VBD) for
the edit script >0d in English.
5 Related Work
Statistical morphological realizers are very rare
since most NLG systems are either fully based
on hand-written grammars, including morpholog-
ical rules (Bateman et al, 2005; Gatt and Reiter,
2009; Lavoie and Rambow, 1997), or employ sta-
tistical methods only as a post-processing step to
select the best one of several variants generated
by a rule-based system (Langkilde and Knight,
1998; Langkilde-Geary, 2002) or to guide the de-
cision among the rules during the generation pro-
cess (Belz, 2008). While there are fully statistical
surface realizers (Angeli et al, 2010; Mairesse et
al., 2010), they operate in a phrase-based fashion
on word forms with no treatment of morphology.
Morphological generation in machine translation
tends to use dictionaries ? hand-written (?abokrt-
162
Train Czech English
data Unseen Dict. acc. Our sys. acc. Error Unseen Dict acc. Our sys. acc. Error
part forms Total UnkF Total UnkF reduct. forms Total UnkF Total UnkF reduct.
0.1 63.94 62.00 41.54 76.92 64.43 39.27 27.77 89.18 78.73 95.02 93.14 53.91
0.5 51.38 66.78 38.65 88.73 78.83 66.08 19.96 91.34 76.33 97.89 95.56 75.64
1 45.36 69.43 36.97 92.23 83.60 74.60 14.69 92.76 73.95 98.28 95.27 76.19
5 31.11 77.29 35.56 96.63 90.36 85.17 6.82 96.21 75.73 99.05 97.13 74.96
10 24.72 80.97 33.88 97.83 92.45 88.61 4.66 97.31 77.13 99.34 97.76 75.44
20 17.35 85.69 32.47 98.72 94.28 91.02 3.10 98.09 78.52 99.46 97.57 71.65
30 14.17 87.92 31.85 98.95 94.56 91.34 2.46 98.40 79.79 99.48 97.63 67.75
50 11.06 90.34 31.62 99.20 95.25 91.69 1.76 98.69 80.53 99.54 98.04 64.81
75 9.01 91.91 31.54 99.34 95.60 91.89 1.35 98.86 82.23 99.55 98.17 60.61
100 7.68 92.88 30.38 99.45 95.93 92.21 1.12 98.94 82.53 99.56 98.26 58.85
Table 3: Comparison of our system with a dictionary baseline on different training data sizes.
All numbers are percentages. The accuracy of both methods is given for the whole evaluation set (Total) and for word forms
unseen in the training set (UnkF). Error reduct. shows the relative error reduction of our method in comparison to the baseline
on the whole evaluation set.
sk? et al, 2008), learnt from data (Toutanova et
al., 2008), or a combination thereof (Popel and
?abokrtsk?, 2009).
The only statistical morphological generator
known to us is that of Bohnet et al (2010), em-
ployed as a part of a support-vector-machines-
based surface realizer from semantic structures.
They apply their system to a subset of CoNLL
2009 data sets and their results (morphological ac-
curacy of 97.8% for English, 97.49% for German
and 98.48% for Spanish) seem to indicate that our
system performs better for English, slightly bet-
ter for Spanish and slightly worse for German, but
the numbers may not be directly comparable to our
results as it is unclear whether the authors use the
original data set or the output of the previous steps
of their system for evaluation and whether they in-
clude punctuation and/or capitalization.
Since the morphological generator of Bohnet et
al. (2010) is only a part of a larger system, they
do not provide a thorough analysis of the results.
While their system also predicts edit scripts de-
rived from Levenshtein distance, their edit script
representation seems less efficient than ours. They
report using about 1500 and 2500 different scripts
for English and German, respectively, disregard-
ing scripts occurring only once in the training data.
However, our representation only yields 154 En-
glish and 1785 German7 edit scripts with no prun-
ing. Along with the independent models for the
beginning of the word, this simplifies the task
for the classifier. In addition to features used by
7We get this number when counting the edit scripts as
atomic; they divide into 1735 changes at the end or in the
middle of the words and 18 changes at the beginning.
Bohnet et al (2010), our system includes the suf-
fix features to generalize to unseen inputs.
6 Conclusions and Further Work
We have presented a fully trainable morphologi-
cal generation system aimed at robustness to pre-
viously unseen inputs, based on logistic regression
and Levenshtein distance edit scripts between the
lemma and the target word form. The results from
the evaluation on six different languages from the
CoNLL 2009 data sets indicate that the system is
able to learn most morphological rules correctly
and is able to cope with previously unseen input,
performing significantly better than a dictionary
learned from the same amount of data. The sys-
tem is freely available for download at:
http://ufal.mff.cuni.cz/~odusek/flect
In future, we plan to integrate our generator
into a semantic NLG scenario, as well as a sim-
pler template-based system, and evaluate it on
further languages. We also consider employ-
ing transformation-based learning (Brill, 1995) for
prediction to make better use of the possibility of
splitting the edit scripts and applying the morpho-
logical changes one-by-one.
Acknowledgments
This research was partly funded by the Ministry of
Education, Youth and Sports of the Czech Repub-
lic under the grant agreement LK11221 and core
research funding of Charles University in Prague.
The authors would like to thank Mate?j Korvas and
Martin Popel for helpful comments on the draft
and David Marek, Ondr?ej Pl?tek and Luk?? ?ilka
for discussions.
163
References
G. Angeli, P. Liang, and D. Klein. 2010. A simple
domain-independent probabilistic approach to gen-
eration. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, page 502?512.
J. A. Bateman, I. Kruijff-Korbayov?, and G.-J. Krui-
jff. 2005. Multilingual resource sharing across
both related and unrelated languages: An imple-
mented, open-source framework for practical natu-
ral language generation. Research on Language and
Computation, 3(2-3):191?219.
A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engi-
neering, 14(4):431?455.
B. Bohnet, L. Wanner, S. Mille, and A. Burga. 2010.
Broad coverage multilingual deep sentence genera-
tion with a stochastic multi-level realizer. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics, page 98?106.
E. Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational lin-
guistics, 21(4):543?565.
C. C. Chang and C. J. Lin. 2011. LIBSVM: a library
for support vector machines. ACM Transactions on
Intelligent Systems and Technology (TIST), 2(3):27.
R. E Fan, K. W Chang, C. J Hsieh, X. R Wang, and
C. J Lin. 2008. LIBLINEAR: a library for large lin-
ear classification. The Journal of Machine Learning
Research, 9:1871?1874.
A. Gatt and E. Reiter. 2009. SimpleNLG: a realisation
engine for practical applications. In Proceedings of
the 12th European Workshop on Natural Language
Generation, page 90?93.
J. Hajic?, M. Ciaramita, R. Johansson, D. Kawahara,
M. A Mart?, L. M?rquez, A. Meyers, J. Nivre,
S. Pad?, J. ?te?p?nek, et al 2009. The CoNLL-2009
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, page 1?18.
P. Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP, volume 4, page 388?395.
I. Langkilde and K. Knight. 1998. Generation that
exploits corpus-based statistical knowledge. In Pro-
ceedings of the 36th Annual Meeting of the Associ-
ation for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics-
Volume 1, page 704?710.
I. Langkilde-Geary. 2002. An empirical verification of
coverage and correctness for a general-purpose sen-
tence generator. In Proceedings of the 12th Inter-
national Natural Language Generation Workshop,
page 17?24.
B. Lavoie and O. Rambow. 1997. A fast and portable
realizer for text generation systems. In Proceedings
of the fifth conference on Applied natural language
processing, page 265?268.
V. I. Levenshtein. 1966. Binary codes capable of cor-
recting deletions, insertions and reversals. Soviet
Physics Doklady, 10(8):707.
F. Mairesse, M. Ga?ic?, F. Jurc??c?ek, S. Keizer, B. Thom-
son, K. Yu, and S. Young. 2010. Phrase-based sta-
tistical language generation using graphical models
and active learning. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics, page 1552?1561.
G. Minnen, J. Carroll, and D. Pearce. 2001. Applied
morphological processing of English. Natural Lan-
guage Engineering, 7(3):207?223.
S. B. Needleman and C. D. Wunsch. 1970. A general
method applicable to the search for similarities in
the amino acid sequence of two proteins. Journal of
molecular biology, 48(3):443?453.
M. Popel and Z. ?abokrtsk?. 2009. Improv-
ing English-Czech tectogrammatical MT. The
Prague Bulletin of Mathematical Linguistics, 92(-
1):115?134.
J. Pt?c?ek and Z. ?abokrtsk?. 2006. Synthesis of
Czech sentences from tectogrammatical trees. In
Text, Speech and Dialogue.
K. Toutanova, H. Suzuki, and A. Ruopp. 2008. Ap-
plying morphology generation models to machine
translation. In Proc. of ACL, volume 8.
Z. ?abokrtsk?, J. Pt?c?ek, and P. Pajas. 2008. Tec-
toMT: highly modular MT system with tectogram-
matics used as transfer layer. In Proceedings of the
Third Workshop on Statistical Machine Translation,
page 167?170. Association for Computational Lin-
guistics.
164
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 116?123,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Parameter estimation for agenda-based user simulation
Simon Keizer, Milica Gas?ic?, Filip Jurc???c?ek, Franc?ois Mairesse,
Blaise Thomson, Kai Yu, and Steve Young ?
University of Cambridge, Department of Engineering, Cambridge (UK)
{sk561,mg436,fj228,farm2,brmt2,ky219,sjy}@cam.ac.uk
Abstract
This paper presents an agenda-based user
simulator which has been extended to be
trainable on real data with the aim of more
closely modelling the complex rational be-
haviour exhibited by real users. The train-
able part is formed by a set of random de-
cision points that may be encountered dur-
ing the process of receiving a system act
and responding with a user act. A sample-
based method is presented for using real
user data to estimate the parameters that
control these decisions. Evaluation results
are given both in terms of statistics of gen-
erated user behaviour and the quality of
policies trained with different simulators.
Compared to a handcrafted simulator, the
trained system provides a much better fit
to corpus data and evaluations suggest that
this better fit should result in improved di-
alogue performance.
1 Introduction
In spoken dialogue systems research, modelling
dialogue as a (Partially Observable) Markov Deci-
sion Process ((PO)MDP) and using reinforcement
learning techniques for optimising dialogue poli-
cies has proven to be an effective method for de-
veloping robust systems (Singh et al, 2000; Levin
et al, 2000). However, since this kind of optimi-
sation requires a simulated user to generate a suffi-
ciently large number of interactions to learn from,
this effectiveness depends largely on the quality
of such a user simulator. An important require-
ment for a simulator is for it to be realistic, i.e., it
should generate behaviour that is similar to that of
real users. Trained policies are then more likely to
perform better on real users, and evaluation results
on simulated data are more likely to predict results
on real data more accurately.
?This research was partly funded by the UK EPSRC un-
der grant agreement EP/F013930/1 and by the EU FP7 Pro-
gramme under grant agreement 216594 (CLASSiC project:
www.classic-project.org).
This is one of the reasons why learning user
simulation models from data on real user be-
haviour has become an important direction of re-
search (Scheffler and Young, 2001; Cuaya?huitl et
al., 2005; Georgila et al, 2006). However, the data
driven user models developed so far lack the com-
plexity required for training high quality policies
in task domains where user behaviour is relatively
complex. Handcrafted models are still the most
effective in those cases.
This paper presents an agenda-based user simu-
lator which is handcrafted for a large part, but ad-
ditionally can be trained with data from real users
(Section 2). As a result, it generates behaviour that
better reflects the statistics of real user behaviour,
whilst preserving the complexity and rationality
required to effectively train dialogue management
policies. The trainable part is formed by a set of
random decision points, which, depending on the
context, may or may not be encountered during
the process of receiving a system act and decid-
ing on a response act. If such a point is encoun-
tered, the simulator makes a random decision be-
tween a number of options which may directly or
indirectly influence the resulting output. The op-
tions for each random decision point are reason-
able in the context in which it is encountered, but
a uniform distribution of outcomes might not re-
flect real user behaviour.
We will describe a sample-based method for es-
timating the parameters that define the probabili-
ties for each possible decision, using data on real
users from a corpus of human-machine dialogues
(Section 3). Evaluation results will be presented
both in terms of statistics on generated user be-
haviour and the quality of dialogue policies trained
with different user simulations (Section 4).
2 Agenda-based user simulation
In agenda-based user simulation, user acts are gen-
erated on the basis of a user goal and an agenda
(Schatzmann et al, 2007a). The simulator pre-
sented here is developed and used for a tourist in-
116
formation application, but is sufficiently generic to
accommodate slot-filling applications in any do-
main.1 The user goal consists of the type of venue,
for example hotel, bar or restaurant, a list
of constraints in the form of slot value pairs, such
as food=Italian or area=east, and a list
of slots the user wants to know the value of, such
as the address (addr), phone number (phone),
or price information (price) of the venue. The
user goals for the simulator are randomly gener-
ated from the domain ontology describing which
combinations of venue types and constraints are
allowed and what are the possible values for each
slot. The agenda is a stack-like structure contain-
ing planned user acts. When the simulator receives
a system act, the status of the user goal is updated
as well as the agenda, typically by pushing new
acts onto it. In a separate step, the response user
act is selected by popping one or more items off
the agenda.
Although the agenda-based user simulator in-
troduced by Schatzmann et al (2007a) was en-
tirely handcrafted, it was realistic enough to suc-
cessfully test a prototype POMDP dialogue man-
ager and train a dialogue policy that outperformed
a handcrafted baseline (Young et al, 2009). A
method to train an agenda-based user simula-
tor from data was proposed by Schatzmann et
al. (2007b). In this approach, operations on
the agenda are controlled by probabilities learned
from data using a variation of the EM algorithm.
However, this approach does not readily scale to
more complex interactions in which users can, for
example, change their goal midway through a dia-
logue.
2.1 Random decision parameters
Each time the user simulator receives a system act,
a complex, two-fold process takes place involving
several decisions, made on the basis of both the
nature of the incoming system act and the infor-
mation state of the user, i.e., the status of the user
goal and agenda. The first phase can be seen as
an information state update and involves actions
like filling requested slots or checking whether the
provided information is consistent with the user
goal constraints. In the second phase, the user de-
cides which response act to generate, based on the
updated agenda. Many of the decisions involved
are deterministic, allowing only one possible op-
tion given the context. Other decisions allow for
some degree of variation in the user behaviour and
are governed by probability distributions over the
1We have to date also implemented systems in appoint-
ment scheduling and bus timetable inquiries.
options allowed in that context. For example, if
the system has offered a venue that matches the
user?s goal, the user can randomly decide to either
change his goal or to accept the venue and ask for
additional information such as the phone number.
The non-deterministic part of the simulator is
formalised in terms of a set of random decision
points (RDPs) embedded in the decision process.
If an RDP is encountered (depending on the con-
text), a random choice between the options de-
fined for that point is made by sampling from a
probability distribution. Most of the RDPs are
controlled by a multinomial distribution, such as
deciding whether or not to change the goal after
a system offer. Some RDPs are controlled by a
geometric distribution, like in the case where the
user is planning to specify one of his constraints
(with an inform act popped from the agenda) and
then repeatedly adds an additional constraint to the
act (by combining it with an additional inform act
popped from the agenda) until it randomly decides
not to add any more constraints (or runs out of
constraints to specify). The parameter for this dis-
tribution thus controls how cautious the user is in
providing information to the system.
Hence, the user simulator can be viewed as
a ?decision network?, consisting of deterministic
and random decision points. This is illustrated in
Figure 1 for the simplified case of a network with
only four RDPs; the actual simulator has 23 RDPs,
with 27 associated parameters in total. Each time
the simulator receives a system act, it follows a
path through the network, which is partly deter-
mined by that system act and the user goal and
agenda, and partly by random decisions made ac-
cording to the probability distributions for each
random decision point i given by its parameters
?i.
3 Training the simulator from data
The parameterisation of the user simulator as de-
scribed in Section 2.1 forms the basis for a method
for training the simulator with real user data. The
parameters describing the probability distributions
for each RDP are estimated in order to generate
user behaviour that fits the user behaviour in the
corpus as closely as possible. In order to do so,
a sample based maximum likelihood approach is
taken, in which the simulator is run repeatedly
against the system acts in the corpus, and the ran-
dom decisions that lead to simulated acts matching
the true act in the corpus are recorded. The param-
eters are then estimated using the counts for each
of the random decision points.
117
incoming
system act
outgoing
user act
user goal + agenda
?2
?1
?3
?4
Figure 1: User simulator viewed as a ?decision network?: square nodes indicate deterministic decision
points; round nodes indicate random decision points, and have associated parameters ?i; the loop on one
of the nodes indicates it has a geometric distribution associated with it.
3.1 Parameter estimation
Before starting the process of matching simulated
acts with true acts and collecting counts for the
RDPs, the parameters are initialised to values cor-
responding to uniform distributions. Then, the
simulator is run against all dialogues in the cor-
pus in such a way that for each turn in a dialogue
(consisting of a system act and a user act), the user
simulator is provided with the system act and is
run repeatedly to generate several simulated user
response acts for that turn. For the first turn of a di-
alogue, the simulator is initialised with the correct
user state (see Section 3.2). For each response, the
simulator may make different random decisions,
generally leading to different user acts. The deci-
sions that lead to a simulated act that matches the
true act are recorded as successful. By generating
a sufficiently large number of simulated acts, all
possible combinations of decisions are explored to
find a matching act. Given the high complexity of
the simulator, this sampling approach is preferred
over directly enumerating all decision combina-
tions to identify the successful ones. If none of
the combinations are successful, then either a) the
processing of the dialogue is ended, or b) the cor-
rect context is set for the next turn and processing
is continued. Whereas the former approach aims at
matching sequences of turns, the latter only aims
at matching each user turn separately. In either
case, after all data is processed, the parameters are
estimated using the resulting counts of successful
decisions for each of the RDPs.
For each RDP i, let DPi represent the decision
taken, and dij the j?th possible decision. Then, for
each decision point i that is controlled by a multi-
nomial distribution, the corresponding parameter
estimates ?ij are obtained as follows from the de-
cision frequencies c(DPi = dij):
?ij =
c(DPi = dij)
?
j c(DPi = dij)
(1)
Random decision points that are controlled
by geometric distributions involve potentially
multiple random decisions between two options
(Bernoulli trials). The parameters for such RDPs
are estimated as follows:
?i =
(
1
n
n
?
k=1
bik
)?1
(2)
where bik is the number of Bernoulli trials re-
quired at the k?th time decision point i was en-
countered. In terms of the decision network, this
estimate is correlated with the average number of
times the loop of the node was taken.
3.2 User goal inference
In order to be able to set the correct user goal
state in any given turn, a set of update rules is
used to infer the user?s goals from a dialogue be-
forehand, on the basis of the entire sequence of
system acts and ?true? user acts (see Section 4.1)
in the corpus. These update rules are based on
the notion of dialogue act preconditions, which
specify conditions of the dialogue context that
must hold for a dialogue agent to perform that
act. For example, a precondition for the act
inform(area=central) is that the speaker
wants a venue in the centre. The user act model
118
of the HIS dialogue manager is designed accord-
ing to this same notion (Keizer et al, 2008). In this
model, the probability of a user act in a certain dia-
logue context (the last system act and a hypothesis
regarding the user goal) is determined by checking
the consistency of its preconditions with that con-
text. This contributes to updating the system?s be-
lief state on the basis of which it determines its re-
sponse action. For the user goal inference model,
the user act is given and therefore its precondi-
tions can be used to directly infer the user goal.
So, for example, in the case of observing the user
act inform(area=central), the constraint
(area=central) is added to the user goal.
In addition to using the inferred user goals, the
agenda is corrected in cases where there is a mis-
match between real and simulated user acts in the
previous turn.
In using this offline goal inference model, our
approach takes a position between (Schatzmann et
al., 2007b), in which the user?s goal is treated as
hidden, and (Georgila et al, 2006), in which the
user?s goal is obtained directly from the corpus an-
notation.
4 Evaluation
The parameter estimation technique for training
the user simulator was evaluated in two differ-
ent ways. The first evaluation involved compar-
ing the statistics of simulated and real user be-
haviour. The second evaluation involved compar-
ing dialogue manager policies trained with differ-
ent simulators.
4.1 Data
The task of the dialogue systems we are develop-
ing is to provide tourist information to users, in-
volving venues such as bars, restaurants and hotels
that the user can search for and ask about. These
venues are described in terms of features such as
price range, area, type of food, phone number,
address, and so on. The kind of dialogues with
these systems are commonly called slot-filling di-
alogues.
Within the range of slot-filling applications the
domain is relatively complex due to its hierarchi-
cal data structure and relatively large number of
slots and their possible values. Scalability is in-
deed one of the primary challenges to be addressed
in statistical approaches to dialogue system devel-
opment, including user simulation.
The dialogue corpus that was used for training
and evaluating the simulator was obtained from
the evaluation of a POMDP spoken dialogue sys-
tem with real users. All user utterances in the
resulting corpus were transcribed and semanti-
cally annotated in terms of dialogue acts. Dia-
logue acts consist of a series of semantic items,
including the type (describing the intention of
the speaker, e.g., inform or request) and a
list of slot value pairs (e.g., food=Chinese or
area=south). An extensive analysis of the an-
notations from three different people revealed a
high level of inter-annotator agreement (ranging
from 0.81 to 0.94, depending on which pair of an-
notations are compared), and a voting scheme for
selecting a single annotation for each turn ensured
the reliability of the ?true? user acts used for train-
ing the simulator.
4.2 Corpus statistics results
A first approach to evaluating user simulations is
to look at the statistics of the user behaviour that
is generated by a simulator and compare it with
that of real users as observed in a dialogue cor-
pus. Several metrics for such evaluations have
been considered in the literature, all of which have
both strong points and weaknesses. For the present
evaluation, a selection of metrics believed to give
a reasonable first indication of the quality of the
user simulations was considered2 .
4.2.1 Metrics
The first corpus-based evaluation metric is the Log
Likelihood (LL) of the data, given the user simu-
lation model. This is what is in fact maximised by
the parameter estimation algorithm. The log like-
lihood can be computed by summing the log prob-
abilities of each user turn du in the corpus data D:
ll(D|{?ij}, {?i}) =
?
u
log P (du|{?ij}, {?i})
(3)
The user turn probability is given by the prob-
ability of the decision paths (directed paths in the
decision network of maximal length, such as the
one indicated in Figure 1 in bold) leading to a sim-
ulated user act in that turn that matches the true
user act. The probability of a decision path is ob-
tained by multiplying the probabilities of the de-
cisions made at each decision point i that was en-
countered, which are given by the parameters ?ij
2Note that not all selected metrics are metrics in the strict
sense of the word; the term should therefore be interpreted as
a more general one.
119
and ?i:
logP (du|{?ij}, {?i}) =
?
i?Im(u)
log
(
?
j
?ij ? ?ij(u)
)
+ (4)
?
i?Ig(u)
log
(
?
k
(1 ? ?i)k?1 ? ?i ? ?ik(u)
)
where Im(u) = {i ? Im|?j ?ij(u) > 0} and
Ig(u) = {i ? Ig|
?
k ?ik(u) > 0} are the subsets
of the multinomial (Im) and geometric (Ig) de-
cision points respectively containing those points
that were encountered in any combination of deci-
sions resulting in the given user act:
?ij(u) =
?
?
?
?
?
1 if decision DPi = dij was
taken in any of the
matching combinations
0 otherwise
(5)
?ik(u) =
?
?
?
?
?
1 if any of the matching
combinations required
k > 0 trials
0 otherwise
(6)
It should be noted that the log likelihood only
represents those turns in the corpus for which the
simulated user can produce a matching simulated
act with some probability. Hence, it is impor-
tant to also take into account the corpus cover-
age when considering the log likelihood in cor-
pus based evaluation. Dividing by the number of
matched turns provides a useful normalisation in
this respect.
The expected Precision (PRE), Recall (RCL),
and F-Score (FS) are obtained by comparing the
simulated user acts with the true user acts in the
same context (Georgila et al, 2006). These scores
are obtained by pairwise comparison of the simu-
lated and true user act for each turn in the corpus
at the level of the semantic items:
PRE = #(matched items)#(items in simulated act) (7)
RCL = #(matched items)#(items in true act) (8)
FS = 2 ? PRE ? RCLPRE + RCL (9)
By sampling a sufficient number of simulated
acts for each turn in the corpus and comparing
them with the corresponding true acts, this results
in an accurate measure on average.
The problem with precision and recall is that
they are known to heavily penalise unseen data.
Any attempt to generalise and therefore increase
the variability of user behaviour results in lower
scores.
Another way of evaluating the user simulator
is to look at the global user act distributions it
generates and compare them to the distributions
found in the real user data. A common metric
for comparing such distributions is the Kullback-
Leibler (KL) distance. In (Cuaya?huitl et al,
2005) this metric was used to evaluate an HMM-
based user simulation approach. The KL dis-
tance is computed by taking the average of the
two KL divergences3 DKL(simulated||true) and
DKL(true||simulated), where:
DKL(p||q) =
?
i
pi ? log2(
pi
qi
) (10)
KL distances are computed for both full user act
distributions (taking into account both the dia-
logue act type and slot value pairs) and user act
type distributions (only regarding the dialogue act
type), denoted by KLF and KLT respectively.
4.2.2 Results
For the experiments, the corpus data was ran-
domly split into a training set, consisting of 4479
user turns in 541 dialogues, used for estimat-
ing the user simulator parameters, and a test set,
consisting of 1457 user turns in 175 dialogues,
used for evaluation only. In the evaluation, the
following parameter settings were compared: 1)
non-informative, uniform parameters (UNIF); 2)
handcrafted parameters (HDC); 3) parameters es-
timated from data (TRA); and 4) deterministic pa-
rameters (DET), in which for each RDP the prob-
ability of the most probable decision according to
the estimated parameters is set to 1, i.e., at all
times, the most likely decision according to the es-
timated parameters is chosen.
For both trained and deterministic parameters,
a distinction is made between the two approaches
to matching user acts during parameter estimation.
Recall that in the turn-based approach, in each
turn, the simulator is run with the corrected con-
text to find a matching simulated act, whereas in
the sequence-based approach, the matching pro-
cess for a dialogue is stopped in case a turn
is encountered which cannot be matched by the
simulator. This results in estimated parameters
TRA-T and deterministic parameters DET-T for
3Before computing the distances, add-one smoothing was
applied in order to avoid zero-probabilities.
120
PAR nLL-T nLL-S PRE RCL FS KLF KLT
UNIF ?3.78 ?3.37 16.95 (?0.75) 9.47 (?0.59) 12.15 3.057 2.318
HDC ?4.07 ?2.22 44.31 (?0.99) 34.74 (?0.95) 38.94 1.784 0.623
TRA-T ?2.97 - 37.60 (?0.97) 28.14 (?0.90) 32.19 1.362 0.336
DET-T ?? - 47.70 (?1.00) 40.90 (?0.98) 44.04 2.335 0.838
TRA-S - ?2.13 43.19 (?0.99) 35.68 (?0.96) 39.07 1.355 0.155
DET-S - ?? 49.39 (?1.00) 43.04 (?0.99) 46.00 2.310 0.825
Table 1: Results of the sample-based user simulator evaluation on the Mar?09 training
corpus (the corpus coverage was 59% for the turn-based and 33% for the sequence-based
matching approach).
PAR nLL-T nLL-S PRE RCL FS KLF KLT
UNIF ?3.61 ?3.28 16.59 (?1.29) 9.32 (?1.01) 11.93 2.951 2.180
HDC ?3.90 ?2.19 45.35 (?1.72) 36.04 (?1.66) 40.16 1.780 0.561
TRA-T ?2.84 - 38.22 (?1.68) 28.74 (?1.57) 32.81 1.405 0.310
DET-T ?? - 49.15 (?1.73) 42.17 (?1.71) 45.39 2.478 0.867
TRA-S - ?2.12 43.90 (?1.72) 36.52 (?1.67) 39.87 1.424 0.153
DET-S - ?? 50.73 (?1.73) 44.41 (?1.72) 47.36 2.407 0.841
Table 2: Results of the sample-based user simulator evaluation on the Mar?09 test corpus
(corpus coverage 59% for the turn-based, and 36% for sequence-based matching).
the turn-based approach and analogously TRA-S
and DET-S for the sequence-based approach. The
corresponding normalised (see Section 4.2.1) log-
likelihoods are indicated by nLL-T and nLL-S.
Tables 1 and 2 give the results on the training
and test data respectively. The results show that in
terms of log-likelihood and KL-distances, the es-
timated parameters outperform the other settings,
regardless of the matching method. In terms of
precision/recall (given in percentages with 95%
confidence intervals), the estimated parameters
are worse than the handcrafted parameters for
turn-based matching, but have similar scores for
sequence-based matching.
The results for the deterministic parameters il-
lustrate that much better precision/recall scores
can be obtained, but at the expense of variability as
well as the KL-distances. It will be easier to train
a dialogue policy on such a deterministic simula-
tor, but that policy is likely to perform significantly
worse on the more varied behaviour generated by
the trained simulator, as we will see in Section 4.3.
Out of the two matching approaches, the
sequence-based approach gives the best results:
TRA-S outperforms TRA-T on all scores, except
for the coverage which is much lower for the
sequence-based approach (33% vs. 59%).
4.3 Policy evaluation results
Although the corpus-based evaluation results give
a useful indication of how realistic the behaviour
generated by a simulator is, what really should be
evaluated is the dialogue management policy that
is trained using that simulator. Therefore, differ-
ent parameter sets for the simulator were used to
train and evaluate different policies for the Hidden
Information State (HIS) dialogue manager (Young
et al, 2009). Four different policies were trained:
one policy using handcrafted simulation param-
eters (POL-HDC); two policies using simulation
parameters estimated (using the sequence-based
matching approach) from two data sets that were
obtained by randomly splitting the data into two
parts of 358 dialogues each (POL-TRA1 and POL-
TRA2); and finally, a policy using a determin-
istic simulator (POL-DET) constructed from the
trained parameters as discussed in Section 4.2.2.
The policies were then each evaluated on the sim-
ulator using the four parameter settings at different
semantic error rates.
The performance of a policy is measured in
terms of a reward that is given for each dialogue,
i.e. a reward of 20 for a successful dialogue, mi-
nus the number of turns. A dialogue is consid-
ered successful if the system has offered a venue
matching the predefined user goal constraints and
has given the correct values of all requested slots
for this venue. During the policy optimisation, in
which a reinforcement learning algorithm tries to
optimise the expected long term reward, this dia-
logue scoring regime was also used.
In Figures 2, 3, and 4, evaluation results are
given resulting from running 3000 dialogues at
each of 11 different semantic error rates. The
curves show average rewards with 95% confidence
intervals. The error rate is controlled by a hand-
121
-2
 0
 2
 4
 6
 8
 10
 12
 0  0.1  0.2  0.3  0.4  0.5
Av
er
ag
e 
re
wa
rd
Error rate
POL-HDC
POL-TRA1
POL-TRA2
POL-DET
Figure 2: Average rewards for each policy when
evaluated on UM-HDC.
-4
-2
 0
 2
 4
 6
 8
 10
 0  0.1  0.2  0.3  0.4  0.5
Av
er
ag
e 
re
wa
rd
Error rate
POL-HDC
POL-TRA1
POL-TRA2
POL-DET
Figure 3: Average rewards for each policy when
evaluated on UM-TRA1.
 2
 4
 6
 8
 10
 12
 14
 16
 0  0.1  0.2  0.3  0.4  0.5
Av
er
ag
e 
re
wa
rd
Error rate
POL-HDC
POL-TRA1
POL-TRA2
POL-DET
Figure 4: Average rewards for each policy when
evaluated on UM-DET.
 0
 1
 2
 3
 4
 5
 6
 7
 0  0.1  0.2  0.3  0.4  0.5
Av
er
ag
e 
re
wa
rd
 lo
ss
Error rate
POL-HDC
POL-TRA2
POL-DET
Figure 5: Average loss in reward for each policy,
across three different simulators.
crafted error model that converts the user act gen-
erated by the simulator into an n-best list of dia-
logue act hypotheses.
The policy that was trained using the hand-
crafted simulator (POL-HDC) outperforms the
other policies when evaluated on that same sim-
ulator (see Figure 2), and both policies trained us-
ing the trained simulators (POL-TRA1 and POL-
TRA2) outperform the other policies when evalu-
ated on either trained simulator (see Figure 3 for
the evaluation on UM-TRA1; the evaluation on
UM-TRA2 is very similar and therefore omitted).
There is little difference in performance between
policies POL-TRA1 and POL-TRA2, which can
be explained by the fact that the two trained
parameter settings are quite similar, in contrast
to the handcrafted parameters. The policy that
was trained on the deterministic parameters (POL-
DET) is competitive with the other policies when
evaluated on UM-DET (see Figure 4), but per-
forms significantly worse on the other parameter
settings which generate the variation in behaviour
that the dialogue manager did not encounter dur-
ing training of POL-DET.
In addition to comparing the policies when eval-
uated on each simulator separately, another com-
parison was made in terms of the average perfor-
mance across all simulators. For each policy and
each simulator, we first computed the difference
between the policy?s performance and the ?maxi-
mum? performance on that simulator as achieved
by the policy that was also trained on that simu-
lator, and then averaged over all simulators. To
avoid biased results, only one of the trained simu-
lators was included. The results in Figure 5 show
that the POL-TRA2 policy is more robust than
POL-DET, and has similar robustness as POL-
HDC. Similar results are obtained when including
UM-TRA1 only.
Given that the results of Section 4.2 show that
the dialogues generated by the trained simulator
more closely match real corpus data, and given
that the above simulation results show that the
POL-TRA policies are at least as robust as the
122
other policies, it seems likely that policies trained
using the trained user simulator will show im-
proved performance when evaluated on real users.
However, this claim can only be properly
demonstrated in a real user evaluation of the di-
alogue system containing different dialogue man-
agement policies. Such a user trial would also be
able to confirm whether the results from evalua-
tions on the trained simulator can more accurately
predict the actual performance expected with real
users.
5 Conclusion
In this paper, we presented an agenda-based user
simulator extended to be trainable on real user
data whilst preserving the necessary rationality
and complexity for effective training and evalu-
ation of dialogue manager policies. The exten-
sion involved the incorporation of random deci-
sion points in the process of receiving and re-
sponding to a system act in each turn. The deci-
sions made at these points are controlled by prob-
ability distributions defined by a set of parameters.
A sample-based maximum likelihood approach
to estimating these parameters from real user data
in a corpus of human-machine dialogues was dis-
cussed, and two kinds of evaluations were pre-
sented. When comparing the statistics of real ver-
sus simulated user behaviour in terms of a selec-
tion of different metrics, overall, the estimated pa-
rameters were shown to give better results than
the handcrafted baselines. When evaluating dia-
logue management policies trained on the simula-
tor with different parameter settings, it was shown
that: 1) policies trained on a particular parame-
ter setting outperform other policies when evalu-
ated on the same parameters, and in particular, 2)
a policy trained on the trained simulator outper-
forms other policies on a trained simulator. With
the general goal of obtaining a dialogue manager
that performs better in practice, these results are
encouraging, but need to be confirmed by an eval-
uation of the policies on real users.
Additionally, there is still room for improving
the quality of the simulator itself. For example,
the variation in user behaviour can be improved by
adding more random decision points, in order to
achieve better corpus coverage. In addition, since
there is no clear consensus on what is the best met-
ric for evaluating user simulations, additional met-
rics will be explored in order to get a more bal-
anced indication of the quality of the user simu-
lator and how the various metrics are affected by
modifications to the simulator. Perplexity (related
to the log likelihood, see (Georgila et al, 2005)),
accuracy (related to precision/recall, see (Zuker-
man and Albrecht, 2001; Georgila et al, 2006)),
and Crame?r-von Mises divergence (comparing di-
alogue score distributions, see (Williams, 2008))
are some of the metrics worth considering.
References
H. Cuaya?huitl, S. Renals, O. Lemon, and H. Shi-
modaira. 2005. Human-computer dialogue sim-
ulation using hidden markov models. In Proc.
ASRU?05, pages 290?295.
K. Georgila, J. Henderson, and O. Lemon. 2005.
Learning user simulations for information state up-
date dialogue systems. In Proc. Interspeech ?05.
K. Georgila, J. Henderson, and O. Lemon. 2006. User
simulation for spoken dialogue systems: Learning
and evaluation. In Proc. Interspeech/ICSLP.
S. Keizer, M. Gas?ic?, F. Mairesse, B. Thomson, K. Yu,
and S. Young. 2008. Modelling user behaviour in
the HIS-POMDP dialogue manager. In Proc. SLT,
Goa, India.
E. Levin, R. Pieraccini, and W. Eckert. 2000. A
stochastic model of human-machine interaction for
learning dialogue strategies. IEEE Transactions on
Speech and Audio Processing, 8(1).
J. Schatzmann, B. Thomson, K. Weilhammer, H. Ye,
and S. Young. 2007a. Agenda-based user simula-
tion for bootstrapping a POMDP dialogue system.
In Proceedings HLT/NAACL, Rochester, NY.
J. Schatzmann, B. Thomson, and S. Young. 2007b.
Statistical user simulation with a hidden agenda. In
Proc. SIGDIAL?07, pages 273?282, Antwerp, Bel-
gium.
K. Scheffler and S. Young. 2001. Corpus-based dia-
logue simulation for automatic strategy learning and
evaluation. In Proceedings NAACL Workshop on
Adaptation in Dialogue.
S. Singh, M. Kearns, D. Litman, and M. Walker. 2000.
Reinforcement learning for spoken dialogue sys-
tems. In S. Solla, T. Leen, and K. Mu?ller, editors,
Advances in Neural Information Processing Systems
(NIPS). MIT Press.
J. Williams. 2008. Evaluating user simulations with
the Crame?r-von Mises divergence. Speech Commu-
nication, 50:829?846.
S. Young, M. Gas?ic?, S. Keizer, F. Mairesse, B. Thom-
son, and K. Yu. 2009. The Hidden Information
State model: a practical framework for POMDP
based spoken dialogue management. Computer
Speech and Language, 24(2):150?174.
I. Zukerman and D. Albrecht. 2001. Predictive statis-
tical models for user modeling. User Modeling and
User-Adapted Interaction, 11:5?18.
123
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 201?204,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Gaussian Processes for Fast Policy Optimisation of POMDP-based
Dialogue Managers
M. Gas?ic?, F. Jurc???c?ek, S. Keizer, F. Mairesse, B. Thomson, K. Yu and S. Young
Cambridge University Engineering Department
Trumpington Street, Cambridge CB2 1PZ, UK
{mg436, fj228, sk561, farm2, brmt2, ky219, sjy}@eng.cam.ac.uk
Abstract
Modelling dialogue as a Partially Observ-
able Markov Decision Process (POMDP)
enables a dialogue policy robust to speech
understanding errors to be learnt. How-
ever, a major challenge in POMDP pol-
icy learning is to maintain tractability, so
the use of approximation is inevitable.
We propose applying Gaussian Processes
in Reinforcement learning of optimal
POMDP dialogue policies, in order (1) to
make the learning process faster and (2) to
obtain an estimate of the uncertainty of the
approximation. We first demonstrate the
idea on a simple voice mail dialogue task
and then apply this method to a real-world
tourist information dialogue task.
1 Introduction
One of the main challenges in dialogue manage-
ment is effective handling of speech understand-
ing errors. Instead of hand-crafting the error han-
dler for each dialogue step, statistical approaches
allow the optimal dialogue manager behaviour
to be learnt automatically. Reinforcement learn-
ing (RL), in particular, enables the notion of plan-
ning to be embedded in the dialogue management
criteria. The objective of the dialogue manager is
for each dialogue state to choose such an action
that leads to the highest expected long-term re-
ward, which is defined in this framework by the Q-
function. This is in contrast to Supervised learn-
ing, which estimates a dialogue strategy in such a
way as to make it resemble the behaviour from a
given corpus, but without directly optimising over-
all dialogue success.
Modelling dialogue as a Partially Observable
Markov Decision Process (POMDP) allows action
selection to be based on the differing levels of un-
certainty in each dialogue state as well as the over-
all reward. This approach requires that a distribu-
tion of states (belief state) is maintained at each
turn. This explicit representation of uncertainty in
the POMDP gives it the potential to produce more
robust dialogue policies (Young et al, 2010).
The main challenge in the POMDP approach is
the tractability of the learning process. A dis-
crete state space POMDP can be perceived as a
continuous space MDP where the state space con-
sists of the belief states of the original POMDP.
A grid-based approach to policy optimisation as-
sumes discretisation of this space, allowing for
discrete space MDP algorithms to be used for
learning (Brafman, 1997) and thus approximating
the optimal Q-function. Such an approach takes
the order of 100, 000 dialogues to train a real-
world dialogue manager. Therefore, the training
normally takes place in interaction with a simu-
lated user, rather than real users. This raises ques-
tions regarding the quality of the approximation
as well as the potential discrepancy between sim-
ulated and real user behaviour.
Gaussian Processes have been successfully used
in Reinforcement learning for continuous space
MDPs, for both model-free approaches (Engel et
al., 2005) and model-based approaches (Deisen-
roth et al, 2009). We propose using GP Rein-
forcement learning in a POMDP dialogue man-
ager to, firstly, speed up the learning process and,
secondly, obtain the uncertainty of the approxima-
tion. We opt for the model-free approach since it
has the potential to allow the policy obtained in
interaction with the simulated user to be further
refined in interaction with real users.
In the next section, the core idea of the method is
explained on a toy dialogue problem where differ-
ent aspects of GP learning are examined. Follow-
ing that, in Section 3, it is demonstrated how this
methodology can be effectively applied to a real
world dialogue. We conclude with Section 4.
2 Gaussian Process RL on a Toy Problem
2.1 Gaussian Process RL
A Gaussian Process is a generative model of
Bayesian inference that can be used for function
regression (Rasmussen and Williams, 2005). A
Gaussian Process is fully defined by a mean and a
kernel function. The kernel function defines prior
function correlations, which is crucial for obtain-
ing good posterior estimates with just a few ob-
servations. GP-Sarsa is an on-line reinforcement
learning algorithm for both continuous and dis-
crete MDPs that incorporates GP regression (En-
201
gel et al, 2005). Given the observation of rewards,
it estimates the Q-function utilising its correlations
in different parts of the state and the action space
defined by the kernel function. It also gives a vari-
ance of the estimate, thus modelling the uncer-
tainty of the approximation.
2.2 Voice Mail Dialogue Task
In order to demonstrate how this methodology
can be applied to a dialogue system, we first ex-
plain the idea on the voice mail dialogue prob-
lem (Williams, 2006).
The state space of this task consists of three states:
the user asked for the message either to be saved
or deleted, or the dialogue ended. The system
can take three actions: ask the user what to do,
save or delete the message. The observation of
what the user wants is corrupted with noise, there-
fore we model this as a three-state POMDP. This
POMDP can be viewed as a continuous MDP,
where the MDP state is the POMDP belief state,
a 3-dimensional vector of probabilities. For both
learning and evaluation, a simulated user is used
which makes an error with probability 0.3 and ter-
minates the dialogue after at most 10 turns. In the
final state, it gives a positive reward of 10 or a
penalty of ?100 depending on whether the system
performed a correct action or not. Each interme-
diate state receives the penalty of ?1. In order to
keep the problem simple, a model defining tran-
sition and observation probabilities is assumed so
that the belief can be easily updated, but the policy
optimisation is performed in an on-line fashion.
2.3 Kernel Choice for GP-Sarsa
The choice of kernel function is very important
since it defines the prior knowledge about the Q-
function correlations. They have to be defined on
both states and actions. In the voice mail dialogue
problem the action space is discrete, so we opt for
a simple ? kernel over actions:
k(a, a?) = 1 ? ?a(a?), (1)
where ?a is the Kronecker delta function. The
state space is a 3-dimensional continuous space
and the kernel functions over the state space that
we explore are given in Table 1. Each kernel func-
kernel function expression
polynomial k(x,x?) = ?x,x??
parametrised poly. k(x,x?) =
PD
i=1
xix
?
i
r2i
Gaussian k(x,x?) = p2 exp ? ?x ? x
??2
2?2k
scaled norm k(x,x?) = 1 ? ?x ? x
??2
?x?2?x??2
Table 1: Kernel functions
tion defines a different correlation. The polyno-
mial kernel views elements of the state vector as
features, the dot-product of which defines the cor-
relation. They can be given different relevance ri
in the parametrised version. The Gaussian ker-
nel accounts for smoothness, i.e., if two states are
close to each other the Q-function in these states
is correlated. The scaled norm kernel defines posi-
tive correlations in the points that are close to each
other and a negative correlation otherwise. This
is particularly useful for the voice mail problem,
where, if two belief states are very different, tak-
ing the same action in these states generates a neg-
atively correlated reward.
2.4 Optimisation of Kernel Parameters
Some kernel functions are in a parametrised
form, such as Gaussian or parametrised polyno-
mial kernel. These parameters, also called the
hyper-parameters, are estimated by maximising
the marginal likelihood1 on a given corpus (Ras-
mussen and Williams, 2005). We adapted the
available code (Rasmussen and Williams, 2005)
for the Reinforcement learning framework to ob-
tain the optimal hyper-parameters using a dialogue
corpus labelled with states, actions and rewards.
2.5 Grid-based RL Algorithms
To assess the performance of GP-Sarsa, it was
compared with a standard grid-based algorithm
used in (Young et al, 2010). The grid-based ap-
proach discretises the continuous space into re-
gions with their representative points. This then
allows discrete MDP algorithms to be used for pol-
icy optimisation, in this case the Monte Carlo Con-
trol (MCC) algorithm (Sutton and Barto, 1998).
2.6 Optimal POMDP Policy
The optimal POMDP policy was obtained us-
ing the POMDP solver toolkit (Cassandra, 2005),
which implements the Point Based Value Itera-
tion algorithm to solve the POMDP off-line using
the underlying transition and observation proba-
bilities. We used 300 sample dialogues between
the dialogue manager governed by this policy and
the simulated user as data for optimisation of the
kernel hyper-parameters (see Section 2.4).
2.7 Training set-up and Evaluation
The dialogue manager was trained in interaction
with the simulated user and the performance was
compared between the grid-based MCC algorithm
and GP-Sarsa across different kernel functions
from Table 1.
The intention was, not only to test which algo-
rithm yields the best policy performance, but also
to examine the speed of convergence to the opti-
mal policy. All the algorithms use an ?-greedy
approach where the exploration rate ? was fixed
at 0.1. The learning process greatly depends on
1Also called evidence maximisation in the literature.
202
the actions that are taken during exploration. If
early on during the training, the systems discovers
a path that generates high rewards due to a lucky
choice of actions, then the convergence is faster.
To alleviate this, we adopted the following proce-
dure. For every training set-up, exactly the same
training iterations were performed using 1000 dif-
ferent random generator seedings. After every 20
dialogues the resulting 1000 partially optimised
policies were evaluated. Each of them was tested
on 1000 dialogues. The average reward of these
1000 dialogues provides just one point in Fig. 1.
20 60 100 140 180 220 260 300 340 380 420 460 500 540 580 620
?50
?45
?40
?35
?30
?25
?20
?15
?10
?5
0
Training dialogues
Av
er
ag
e 
re
wa
rd
polynomial kernel ? 
? Gaussian kernel with learned hyper?parameters
? scaled norm kernel
polynomial kernel with learned hyper?parameters
?
 
 
Optimal POMDP Policy
GP?Sarsa
Grid?based Monte Carlo Control
Figure 1: Evaluation results on Voice Mail task
The grid-based MCC algorithm used a Euclid-
ian distance to generate the grid by adding every
point that was further than 0.01 from other points
as a representative of a new region. As can be
seen from Fig 1, the grid-Based MCC algorithm
has a relatively slow convergence rate. GP-Sarsa
with the polynomial kernel exhibited a learning
rate similar to MCC in the first 300 training di-
alogues, continuing with a more upward learning
trend. The parametrised polynomial kernel per-
forms slightly better. The Gaussian kernel, how-
ever, achieves a much faster learning rate. The
scaled norm kernel achieved close to optimal per-
formance in 400 dialogues, with a much higher
convergence rate then the other methods.
3 Gaussian Process RL on a Real-world
Task
3.1 HIS Dialogue Manager on CamInfo
Domain
We investigate the use of GP-Sarsa in a real-
world task by extending the Hidden Information
State (HIS) dialogue manager (Young et al, 2010).
The application domain is tourist information for
Cambridge, whereby the user can ask for informa-
tion about a restaurant, hotel, museum or another
tourist attraction in the local area. The database
consists of more than 400 entities each of which
has up to 10 attributes that the user can query.
The HIS dialogue manager is a POMDP-based di-
alogue manager that can tractably maintain belief
states for large domains. The key feature of this
approach is the grouping of possible user goals
into partitions, using relationships between differ-
ent attributes from possible user goals. Partitions
are combined with possible user dialogue actions
from the N-best user input as well as with the di-
alogue history. This combination forms the state
space ? the set of hypotheses, the probability dis-
tribution over which is maintained during the di-
alogue. Since the number of states for any real-
world problem is too large, for tractable policy
learning, both the state and the action space are
mapped into smaller scale summary spaces. Once
an adequate summary action is found in the sum-
mary space, it is mapped back to form an action in
the original master space.
3.2 Kernel Choice for GP-Sarsa
The summary state in the HIS system is a four-
dimensional space consisting of two elements that
are continuous (the probability of the top two hy-
potheses) and two discrete elements (one relating
the portion of the database entries that matches the
top partition and the other relating to the last user
action type). The summary action space is discrete
and consists of eleven elements.
In order to apply the GP-Sarsa algorithm, a kernel
function needs to be specified for both the sum-
mary state space and the summary action space.
The nature of this space is quite different from the
one described in the toy problem. Therefore, ap-
plying a kernel that has negative correlations, such
as the scaled norm kernel (Table 1) might give un-
expected results. More specifically, for a given
summary action, the mapping procedure finds the
most appropriate action to perform if such an ac-
tion exists. This can lead to a lower reward if
the summary action is not adequate but would
rarely lead to negatively correlated rewards. Also,
parametrised kernels could not be used for this
task, since there was no corpus available for hyper-
parameter optimisation. The polynomial kernel
(Table 1) assumes that the elements of the space
are features. Due to the way the probability is
maintained over this very large state space, the
continuous variables potentially encode more in-
formation than in the simple toy problem. There-
fore, we used the polynomial kernel for the con-
tinuous elements. For discrete elements, we utilise
the ?-kernel (Eq. 2.3).
3.3 Active Learning GP-Sarsa
The GP RL framework enables modelling the un-
certainty of the approximation. The uncertainty
estimate can be used to decide which actions
to take during the exploration (Deisenroth et al,
203
2009). In detail, instead of a random action, the
action in which the Q-function for the current state
has the highest variance is taken.
3.4 Training Set-up and Evaluation
Policy optimisation is performed by interacting
with a simulated user on the dialogue act level.
The simulated user gives a reward at the final state
of the dialogue, and that is 20 if the dialogue was
successful, 0 otherwise, less the number of turns
taken to fulfil the user goal. The simulated user
takes a maximum of 100 turns in each dialogue,
terminating it when all the necessary information
has been obtained or if it looses patience.
A grid-based MCC algorithm provides the base-
line method. The distance metric used ensures
that the number of regions in the grid is small
enough for the learning to be tractable (Young et
al., 2010).
In order to measure how fast each algorithm
learns, a similar training set-up to the one pre-
sented in Section 2.7 was adopted and the aver-
aged results are plotted on the graph, Fig. 2.
200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600 2800 3000
2
3
4
5
6
7
8
9
Training dialogues
Av
er
ag
e 
re
wa
rd
?  Grid?based Monte Carlo Control
?  GP?Sarsa with polynomial kernel
?  Active learning GP?Sarsa with polynomial kernel
Figure 2: Evaluation results on CamInfo task
The results show that in the very early stage of
learning, i.e., during the first 400 dialogues, the
GP-based method learns faster. Also, the learning
process can be accelerated by adopting the active
learning framework where the actions are selected
based on the estimated uncertainty.
After performing many iterations in an incremen-
tal noise learning set-up (Young et al, 2010) both
the GP-Sarsa and the grid-based MCC algorithms
converge to the same performance.
4 Conclusions
This paper has described how Gaussian Processes
in Reinforcement learning can be successfully ap-
plied to dialogue management. We implemented
a GP-Sarsa algorithm on a toy dialogue prob-
lem, showing that with an appropriate kernel func-
tion faster convergence can be achieved. We also
demonstrated how kernel parameters can be learnt
from a dialogue corpus, thus creating a bridge
between Supervised and Reinforcement learning
methods in dialogue management. We applied
GP-Sarsa to a real-world dialogue task showing
that, on average, this method can learn faster than
a grid-based algorithm. We also showed that the
variance that GP is estimating can be used in an
Active learning setting to further accelerate policy
optimisation.
Further research is needed in the area of kernel
function selection. The results here suggest that
the GP framework can facilitate faster learning,
which potentially allows the use of larger sum-
mary spaces. In addition, being able to learn ef-
ficiently from a small number of dialogues offers
the potential for learning from direct interaction
with real users.
Acknowledgements
The authors would like to thank Carl Rasmussen
for valuable discussions. This research was partly
funded by the UK EPSRC under grant agreement
EP/F013930/1 and by the EU FP7 Programme un-
der grant agreement 216594 (CLASSiC project).
References
RI Brafman. 1997. A Heuristic Variable Grid Solution
Method for POMDPs. In AAAI, Cambridge, MA.
AR Cassandra. 2005. POMDP solver.
http://www.cassandra.org/pomdp/
code/index.shtml.
MP Deisenroth, CE Rasmussen, and J Peters. 2009.
Gaussian Process Dynamic Programming. Neuro-
comput., 72(7-9):1508?1524.
Y Engel, S Mannor, and R Meir. 2005. Reinforcement
learning with Gaussian processes. In ICML ?05:
Proceedings of the 22nd international conference on
Machine learning, pages 201?208, New York, NY.
CE Rasmussen and CKI Williams. 2005. Gaussian
Processes for Machine Learning. MIT Press, Cam-
bridge, MA.
RS Sutton and AG Barto. 1998. Reinforcement Learn-
ing: An Introduction. Adaptive Computation and
Machine Learning. MIT Press, Cambridge, MA.
JD Williams. 2006. Partially Observable Markov De-
cision Processes for Spoken Dialogue Management.
Ph.D. thesis, University of Cambridge.
SJ Young, M Gas?ic?, S Keizer, F Mairesse, J Schatz-
mann, B Thomson, and K Yu. 2010. The Hid-
den Information State Model: a practical frame-
work for POMDP-based spoken dialogue manage-
ment. Computer Speech and Language, 24(2):150?
174.
204
Proceedings of the SIGDIAL 2013 Conference, pages 452?456,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Comparison of Bayesian Discriminative and Generative Models for
Dialogue State Tracking
Luka?s? Z?ilka, David Marek, Mate?j Korvas, Filip Jurc???c?ek
Charles University in Prague
Faculty of Mathematics and Physics
Malostranske? na?me?st?? 25
118 00 Praha, Czech Republic
lukas@zilka.me, david@marek.me,
korvas@ufal.mff.cuni.cz, jurcicek@ufal.mff.cuni.cz
Abstract
In this paper, we describe two dialogue
state tracking models competing in the
2012 Dialogue State Tracking Challenge
(DSTC). First, we detail a novel discrim-
inative dialogue state tracker which di-
rectly estimates slot-level beliefs using de-
terministic state transition probability dis-
tribution. Second, we present a gener-
ative model employing a simple depen-
dency structure to achieve fast inference.
The models are evaluated on the DSTC
data, and both significantly outperform the
baseline DSTC tracker.
1 Introduction
The core component of virtually any dialogue sys-
tem is a dialogue state tracker. Its purpose is to
monitor dialogue progress and provide compact
representation of the past user input and system
output in the form of a dialogue state. In previ-
ous works on this topics, Williams (2007) used
particle filters to perform inference in a complex
Bayesian network modelling the dialogue state,
Williams (2008) presented a generative tracker
and showed how to train an observation model
from transcribed data, Young et al (2010) grouped
indistinguishable dialogue states into partitions
and consequently performed dialogue state track-
ing on these partitions instead of the individual
states, Thomson and Young (2010) used a dy-
namic Bayesian network to represent the dialogue
model in an approximate form, and Mehta et al
(2010) used probabilistic ontology trees.
In this paper, we describe two probabilistic di-
alogue state trackers: (1) a discriminative dia-
logue state tracker (DT) ? a model using a sim-
ple deterministic state transition probability, re-
sulting in significant computational savings, and
(2), a generative dialogue state tracker (GT) ? a
model using simple conditional dependency struc-
ture with tied and handcrafted model parameters.
Both trackers were evaluated in the DSTC. The
aim of the DSTC was to provide a common testbed
for different dialogue state tracking methods and
to evaluate these methods in a unified way. Be-
cause of limited space, the interested reader is re-
ferred to Williams et al (2013) for information
about the data and evaluation metrics used in the
challenge.
This paper is structured as follows. The de-
terministic and generative trackers are detailed in
Section 2 and the presented models are evaluated
on the DSTC data in Section 3. Section 4 discusses
the obtained results, and Section 5 concludes the
paper.
2 Bayesian Dialogue State Tracking
The goal of dialogue state tracking is to moni-
tor progress in the dialogue and provide a com-
pact representation of the dialogue history in the
form of a dialogue state. Because of the uncer-
tainty in the user input, statistical dialogue sys-
tems maintain a probability distribution over all di-
alogue states called the belief state and every turn,
as the dialogue progresses, updates this distribu-
tion in the light of the new observations in a pro-
cess called belief monitoring.
Since the true observations are hidden, the
belief state depends on the past and current
observation probabilities, p(o1), . . . , p(ot), and
system actions, a0, . . . , at?1, which are re-
ferred to as the observed history: ht =
{a0, p(o1), . . . , at?1, p(ot)}. If the system is
Markovian, the belief state bt depends only on the
previous belief state bt?1, the observation distribu-
tion p(ot), and the last system action at?1. There
are two ways to derive the belief state update using
the Bayes theorem, resulting either in discrimina-
tive or generative probabilistic models.
The discriminative update can be represented as
452
follows:
bt = b(st|ht)
=
?
st?1,ot
p(st|at?1, st?1,ot)b(st?1|ht?1)p(ot) (1)
where the probability p(st|at?1, st?1,ot) repre-
sents the discriminative dialogue model. By fur-
ther factorisation of (1), we can derive the genera-
tive update formula:
bt ?
?
st?1,ot
p(st|at?1, st?1)p(ot|st)?
? b(st?1|ht?1)p(ot) (2)
where the transition probability p(st|at?1, st?1)
and the observation probability p(ot|st) represent
the generative dialogue model.
In our approach, we define the dialogue state
as a vector s = [s1, . . . , sN ] where si are val-
ues for slots in the dialogue domain, e.g. to.desc
or from.monument. The observations are factored
similarly to o = [o1, . . . , oN ], where oi are indi-
vidual slot-level observations, e. g. inform(to.desc
= downtown)? oto.desc = downtown. The prob-
ability of the slot-level observations p(oi) can be
easily obtained by marginalising the observation
probability p(o). Because of limited space, only
the processing of the inform dialogue acts is de-
scribed in detail.
In the next two sections, we present the discrim-
inative and generative models of belief update em-
ployed in the DSTC challenge by using the factori-
sation of the full belief state into independent fac-
tors to obtain computationally efficient updates.
2.1 Discriminative Belief Update
In this work, the belief state bt is defined as a
product of marginal probabilities of the individual
slots, b(st) = ?i b(sit), where sit is the i-th slot at
the turn t and the slot belief b(sit) is a probability
distribution over all values for the slot i. To keep
the notation uncluttered, the slot index, i, will be
omitted in the following text. To further simplify
the belief updates, similarly to the full belief mon-
itoring represented by (1), the slot belief depends
only on the previous slot belief bt?1, the observa-
tion distribution p(ot), and the last system action
at?1. This results in update rules for individual
slots s as follows:
b(st) =
?
st?1,ot
p(st|at?1, st?1, ot)b(st?1)p(ot) (3)
where the conditional probability distribution
p(st|at?1, st?1, ot) represents the slot-level dia-
logue model.
There are two aspects which have to be taken
into account when we consider the presented be-
lief update: (1) the computational complexity and
(2) the parameters of the dialogue model. First,
the complexity of the belief update is given by the
number of slot values and observations because
the sum must be evaluated for all their combina-
tions. This suggests that even this update may be
computationally too expensive for slots where ob-
servations have a large number of values. Second,
the slot-level dialogue model describes probabilis-
tically how the value of a slot changes according
to the context and the observations. Parameters
of this conditional distribution would ideally be
estimated from annotated data. Because of data
sparsity, however, such estimates tend to be rather
poor and either they must be smoothed or the pa-
rameters must be tied. To overcome this problem,
we decided to set the parameters manually on the
basis of two simple assumptions leading to very
computationally efficient updates. First, we as-
sume that our dialogue model should completely
trust what the user says. Second, we assume that
the user goal does not change when the user is
silent. For example, if the user says: ?I want to
go downtown?, oto.desct = downtown, then the
state should be sto.desct = downtown; and when
the user says nothing in the next turn, oto.desct+1 = 
(where the symbol  is a special slot value repre-
senting that the user was silent), the state remains
sto.desct+1 = downtown. This is captured by the fol-
lowing definition of the slot-level dialogue model:
p(st|at?1, st?1, ot) =
?
?
?
1 (st = ot ? ot 6= )?
(st = st?1 ? ot = )
0 otherwise
(4)
When (4) is substituted into (3), the belief up-
date greatly simplifies and appears into the follow-
ing form:
b(st) =
?
??
??
st =  : p(st?1 = )p(ot = )
st 6=  : p(ot = st)+ p(ot = )p(st?1 = st)
(5)
Note that this model effectively accumulates
probability from multiple hypotheses and from
multiple turns. For example, its ability to ?remem-
ber? the belief from the previous turn is propor-
tional to the probability mass assigned to the SLU
453
hypothesis that the user was silent about the slot in
question. In the special case when the user is silent
with probability 1.0, the current belief is equal to
the previous belief.
This belief update is very computationally effi-
cient. First, instead of summing over all combi-
nations of the slot and observation values (3), the
belief can be computed by means of a simple for-
mula (5). Second, if the user does not mention a
particular slot value during the dialogue, this value
will always have a probability of zero. Therefore,
only the probability for values suggested by the
SLU component has to be maintained.
2.2 Generative model for belief update
Similarly to the discriminative belief update, the
generative model relies on factorisation of the full
belief state into a product of marginal slot be-
liefs and a simple dependency structure where a
slot belief depends only on the previous slot be-
lief, the slot observation distribution p(oit), and
the last system action at?1. The dialogue model
p(st|at?1, st?1, ot) is further factored, however,
into the transition model p(st|at?1, st?1) and the
observation model p(ot|st) as given in (2).
The transition model describes the probability
that the user will change his/her goal, given the
previous goal and the last system action. For ex-
ample, if the system asks the user about a specific
slot, then it is reasonable to have a larger prob-
ability of this slot changing its value. As noted
for the discriminative model, estimation of the di-
alogue model parameters requires a large amount
of data, which was not available in the challenge.
Therefore, we used parameter tying as described
by Thomson and Young (2010), and set the tied
parameters manually:
p(st|at?1, st?1) =
{?t if st = st?1
1??t
|values|?1 otherwise (6)
where ?t describes the probability of a slot value
staying the same and |values| denotes the number
of values for the slot. In other words, the probabil-
ity ?t sets a tradeoff between the system?s ability
to remember everything that was said in the past
and accepting new information from the user. If ?t
is too high, the system will put a strong emphasis
on the previous states and will largely ignore what
the user is saying. When testing different values of
?t on heldout data, we observed that if they are se-
lected reasonably, the overall performance of the
system does not change much. Therefore, the ?t
value was fixed at 0.8 for all slots and all datasets.
The observation model p(ot|st) describes the
dependency between the observed values and the
slot values. Similarly to the transition model, pa-
rameters of the observation probability distribu-
tion were tied and set manually:
p(ot|st) =
{?o if ot = st
1??o
|values|?1 otherwise. (7)
where ?o defines the probability of the agreement
between the observation and the slot value. The
probability of agreement describes how the model
is robust to noise and systematic errors in SLU.
When ?o is set high, the model assumes that the
SLU component makes perfect predictions, and
therefore the SLU output must agree with the slot
values. Based on manual tuning on held-out data,
?o was set to 0.8.
Inference in the presented model is performed
with Loopy Belief Propagation (LBP) (Pearl,
1988). LBP is an approximate message passing
inference algorithm for Bayesian networks (BN).
LBP can be computationally intensive if there are
nodes with many parents in the network. There-
fore, as previously described, our model uses a
simple dependency structure where slots depend
only on the same slot from the previous turn, and
slot-level observations depend on the correspond-
ing slot from the same turn. To make the inference
even more efficient, one can take advantage of the
tied observation and transition probabilities. We
group all unobserved values in the nodes of BN
together and maintain only a probability for the
group as a whole, as suggested by Thomson and
Young (2010).
3 Evaluation
The discriminative (DT) and generative dialogue
(GT) trackers described in Sections 2.1 and 2.2
were evaluated on the DSTC data.
The input of DT and GT were the SLU n-best
lists either with original probabilities or the scores
mapped into the probability space. The track-
ers were evaluated on both live and batch data.
The metrics were computed with Schedule 1 (see
Williams et al (2013)). In addition, we include
into the evaluation the DSTC baseline tracker. The
results on the live and batch data are shown in Ta-
ble 1 in the Appendix. Please note that the results
for GT differ from the results submitted for DSTC.
Only after the submission deadline, did we find
454
that some of the parameters in the transition model
were set incorrectly. After the setting was fixed,
the results improved.
The results show that the DT consistently out-
performs the baseline tracker and the DT achieves
comparable or better results than the GT. The DT
clearly provides better estimates of the dialogue
states because of the incorporation of the context
and the processing of multiple hypotheses. To
assess the statistical significance of the accuracy
metric, 95% confidence scores for all measure-
ments were computed. Overall, the confidence in-
tervals were between 0.1% and 0.4% on the indi-
vidual tests. On this basis, all differences larger
than 1.0% can be considered statistically signifi-
cant.
The GT outperforms the baseline tracker on all
but the batch data. Manual inspection of the re-
sults revealed that the generative model is very
sensitive to the probabilities assigned to the obser-
vations. For the batch data, presumably due to the
score normalisation, the probabilities of hypothe-
ses in the n-best lists were very similar to each
other. As a result, the generative model had dif-
ficulties discriminating between the observed val-
ues.
In comparison with all trackers submitted for
DSTC, the DT achieves second-best accuracy
among the submitted trackers and the GT is among
the average trackers. For more details see Table 2
in the Appendix, where the average scores were
computed from the accuracy and the Brier score
on test sets 1, 2, 3, and 4.
Regarding the Brier score, the results show that
the DT outperforms the baseline tracker and esti-
mates the belief state as well as the best tracker
in the DSTC. This can prove especially important
when the tracker is used within a complete dia-
logue system where the policy decisions do not
depend on the best dialogue state but on the belief
state.
4 Discussion
The presented discriminative and generative mod-
els differ in two main areas: (1) how they incorpo-
rate observations into the belief state and (2) com-
putational efficiency.
(1) Both the DT and GT models can accumulate
information from multiple hypotheses and from
multiple turns. The GT, however, tends to ?forget?
the dialogue history because the generative model
indiscriminately distributes some of the probabil-
ity mass from a slot value that was not recently
mentioned to all other slot values each turn. This
behaviour (see Table 3 for an example) is not easy
to control because ?forgetting? is a consequence
of the model being able to represent the dynamics
of a user changing his/her goal. The DT does not
have this problem because the change in the goal
is directly conditioned on the observations. If the
user is silent, then the DT ?copies? the past belief
state and no probability in the belief state is dis-
tributed as described in (5).
(2) The DT tracker is significantly faster com-
pared with the GT tracker while offering compa-
rable or better performance. The slot level belief
update in the discriminative model has a complex-
ity of O(n) whereas in the generative model it has
a complexity of O(n2), where n is the number of
values in the slot. When tested on a regular per-
sonal computer, the DT processed all four DSTC
test sets, 4254 dialogues in total, in 2.5 minutes
whereas the GT tracker needed 51 minutes. There-
fore, the DT tracker is about 20 times more com-
putationally efficient on the DSTC data. Although
GT achieved performance allowing real-time use
(it needed 0.1 seconds per turn) in the Let?s Go do-
main, for more complex applications the GT could
simply be too slow. In this case, the proposed dis-
criminative tracker offers a very interesting alter-
native.
5 Conclusion
This paper described two dialogue state tracking
models submitted for the DSTC challenge: (1)
the discriminative tracker and (2) the generative
tracker. The discriminative tracker is based on
a conceptually very simple dialogue model with
deterministic transition probability. Interestingly,
this discriminative model gives performance com-
parable to the more complex generative tracker;
yet it is significantly more computationally effi-
cient. An extended description of this work can be
found in the technical report (Z?ilka et al, 2013).
Acknowledgements
This research was partly funded by the Ministry of
Education, Youth and Sports of the Czech Repub-
lic under the grant agreement LK11221 and core
research funding of Charles University in Prague.
The authors would like to thank Ondr?ej Dus?ek and
Ondr?ej Pla?tek for useful comments.
455
A Comparison of the BT, DT, and GT
trackers
live data metric BT DT GT
test1 accuracy 0.77 0.88 0.88
Brier score 0.29 0.21 0.21
test2 accuracy 0.79 0.89 0.85
Brier score 0.27 0.20 0.23
test3 accuracy 0.92 0.94 0.93
Brier score 0.14 0.11 0.16
test4 accuracy 0.82 0.86 0.87
Brier score 0.24 0.21 0.20
ALL accuracy 0.83 0.89 0.88
Brier score 0.24 0.18 0.20
batch data metric BT DT GT
test1 accuracy 0.75 0.88 0.74
Brier score 0.35 0.27 0.39
test2 accuracy 0.79 0.88 0.77
Brier score 0.30 0.26 0.33
ALL accuracy 0.77 0.88 0.76
Brier score 0.32 0.27 0.36
Table 1: Accuracy of the trackers on the live and
batch test sets, where BT stands for the DSTC
baseline tracker, DT denotes the discriminative
tracker, and GT denotes the generative tracker.
ALL denotes the average scores over the live and
batch test sets.
B Comparison with the DSTC trackers
team/system accuracy Brier score
BT - C 0.81 0.27
BT 0.83 0.24
DT 0.89 0.18
GT 0.88 0.20
team1 0.88 0.23
team2 0.88 0.21
team4 0.81 0.28
team5 0.88 0.21
team6 0.91 0.18
team7 0.85 0.23
team8 0.83 0.24
team9 0.89 0.20
Table 2: Accuracy of the trackers submitted for
the DSTC, where BT - C denotes the DSTC base-
line tracker without removing the systematically
erroneous SLU hypotheses, BT denotes the DSTC
baseline tracker, DT denotes the discriminative
tracker, GT denotes the generative tracker, and
team* denote the best trackers submitted by other
teams. The scores are averaged scores obtained on
the four DSTC test sets.
C The problem of ?forgetting? of the
observed values in the GT tracker
# P SLU hyp. slot value GS DS
1 1.0 centre centre 0.8 1.0
0.0 null null 0.2 0.0
2 1.0 null centre 0.68 1.0
null 0.32 0.0
3 1.0 null centre 0.608 1.0
null 0.392 0.0
Table 3: Example of three turns in which the gen-
erative system ?forgets? the observed value. # de-
notes the turn number, P denotes the probability
of the observation, SLU hyp. denotes the observed
hypothesis, GS denotes the belief of the generative
system, and DS denotes the belief of the discrimi-
native system.
References
Neville Mehta, Rakesh Gupta, Antoine Raux, Deepak
Ramachandran, and Stefan Krawczyk. 2010. Prob-
abilistic ontology trees for belief tracking in dialog
systems. In Proceedings of SigDial, pages 37?46.
Association for Computational Linguistics.
Judea Pearl. 1988. Probabilistic reasoning in intelli-
gent systems: networks of plausible inference. Mor-
gan Kaufmann Publishers Inc., San Francisco, CA,
USA.
Blaise Thomson and Steve Young. 2010. Bayesian
update of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech and
Language, 24(4):562?588.
Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan W. Black. 2013. The Dialog State
Tracking Challenge. In Proceedings of SigDial,
Metz, France.
Jason D. Williams. 2007. Using particle filters to
track dialogue state. In IEEE Workshop on Auto-
matic Speech Recognition & Understanding, 2007.
ASRU, pages 502?507. IEEE.
Jason D. Williams. 2008. Exploiting the ASR N-best
by tracking multiple dialog state hypotheses. Proc
ICSLP, Brisbane.
Steve Young, Milica Gas?ic?, Simon Keizer, Francois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The Hidden Information State
Model: a practical framework for POMDP-based
spoken dialogue management. Computer Speech
and Language, 24(2):150?174.
Luka?s? Z?ilka, David Marek, Mate?j Korvas, and Filip
Jurc???c?ek. 2013. Bayesian Discriminative and Gen-
erative Models used in the 2012 Dialogue State
Tracking Challenge. Technical report, Faculty of
Mathematics and Physics, Charles University in
Prague, July.
456
