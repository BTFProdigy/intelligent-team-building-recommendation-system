Applying an NVEF Word-Pair Identifier to  
the Chinese Syllable-to-Word Conversion Problem 
 
Jia-Lin Tsai 
Intelligent Agent Systems Lab. 
Institute of Information Science, Academia Sinica, 
Nankang, Taipei, Taiwan, R.O.C. 
tsaijl@iis.sinica.edu.tw 
Wen-Lian Hsu 
Intelligent Agent Systems Lab. 
Institute of Information Science, Academia Sinica, 
Nankang, Taipei, Taiwan, R.O.C. 
hsu@iis.sinica.edu.tw 
 
Abstract  
Syllable-to-word (STW) conversion is important 
in Chinese phonetic input methods and speech 
recognition. There are two major problems in 
the STW conversion: (1) resolving the ambigu-
ity caused by homonyms; (2) determining the 
word segmentation. This paper describes a 
noun-verb event-frame (NVEF) word identifier 
that can be used to solve these problems effec-
tively. Our approach includes (a) an NVEF 
word-pair identifier and (b) other word identifi-
ers for the non-NVEF portion.  
Our experiment showed that the NVEF 
word-pair identifier is able to achieve a 99.66% 
STW accuracy for the NVEF related portion, 
and by combining with other identifiers for the 
non-NVEF portion, the overall STW accuracy is 
96.50%.  
The result of this study indicates that the NVEF 
knowledge is very powerful for the STW con-
version. In fact, numerous cases requiring dis-
ambiguation in natural language processing fall 
into such ?chicken-and-egg? situation. The 
NVEF knowledge can be employed as a general 
tool in such systems for disambiguating the 
NVEF related portion independently (thus 
breaking the chicken-and-egg situation) and 
using that as a good fundamental basis to treat 
the remaining portion. This shows that the 
NVEF knowledge is likely to be important for 
general NLP. To further expand its coverage, we 
shall extend the study of NVEF to that of other 
co-occurrence restrictions such as noun-noun 
pairs, noun-adjective pairs and verb-adverb pairs. 
We believe the STW accuracy can be further 
improved with the additional knowledge. 
1. Introduction 
More than 100 Chinese input methods have been 
created in the past [1-6]. Currently, the most 
popular input method is based on phonetic 
symbols. Phonetic input method requires little 
training because Chinese are taught to write the 
corresponding pinyin syllable of each Chinese 
character in primary school. Since there are 
more than 13,000 distinct Chinese characters 
(with around 5400 commonly-used), but only 
1,300 distinct syllables, the homonym problem 
is quite severe in phonetic input method. 
Therefore, an intelligent syllable-to-word (STW) 
conversion for Chinese is very important. A 
comparable (but easier) problem to the STW 
conversion in English is the word-sense 
disambiguation. 
There are basically two approaches for the STW 
conversion: (a) the linguistic approach based on 
syntax parsing or semantic template matching 
[3,4,7,8] and (b) the statistical approach based 
on the n-gram model where n is usually 2 or 3 
[9-12]. The linguistic approach is more laborious 
but the end result can be more user friendly. On 
the other hand, the statistical approach is less 
labor intensive, but its power is dependent on 
training corpus and it usually does not provide 
deep semantic information. Our approach adopts 
the semantically oriented NVEF word-pairs (to 
be defined formally in Section 2.1) plus other 
statistical methods so that not only the result 
makes sense semantically, but the model is also 
fully automatic provided that enough NVEFs 
have already been collected.  
According to the studies in [13], good syllable 
sequence segmentation is crucial for the STW 
conversion. For example, consider the syllable 
sequence ?zhe4 liang4 che1 xing2 shi3 shun4 
chang4? of the Chinese sentence ??????
?? (This car moves well).? By dictionary, the 
two possible segmentation results are (we use 
?/? to indicate syllable word boundary) 
(1) ?zhe4/liang4/che1 xing2/shi3/shun4 chang4?  
(2) ?zhe4/liang4/che1/xing2 shi3/shun4 chang4? 
using the longest-syllabic-word-first strategy 
[14]. The two ambiguous portions are /che1 
xing2/shi3/ (/{?? ,??}/{?,?,?,?,?,? ,
?}/) and /che1/xing2 shi3/ (/{?,?,? }/{??,
??}/), respectively. In this case, if the system 
has the information that ??-??(car, move)? is 
a permissible NVEF word-pair and its 
corresponding syllable-pair ?che1-xing2shi3? 
has been collected, then the correct segmentation 
and word-pair ?? -?? (che1-xing2shi3)? of 
this syllable sequence can be determined 
simultaneously.  
Since NVEF word-pairs are usually the key 
features of a sentence, if identified correctly, 
they become good reference words for the 
n-gram models to predict the remaining 
unconverted syllables. We [15] showed that the 
knowledge of NVEF sense-pairs and their 
corresponding NVEF word-pairs (NVEF 
knowledge) are useful for effectively resolving 
word sense ambiguity and getting highly 
accurate word-segmentation for those 
ambiguous NVEF word-pairs in Chinese.  
In this paper, we shall show that the NVEF 
knowledge can be used effectively in the STW 
conversion for Chinese. Section 2 describes our 
approach. The experimental result is presented 
in Section 3. Directions for future research will 
be discussed in section 4. 
2 . Development of an NVEF-based Word 
Identifier 
Hownet [16] is adopted as the system?s 
word-sense dictionary, which provides the 
knowledge of Chinese lexicon (58,541 words), 
parts-of-speech (POS) and word senses. We 
have integrated Chinese words in Hownet, 
Sinica corpus [17], Cilin (tong2yi4ci2ci2lin2??
? ? ? ? ?) [18], Chinese dictionary 
(guo2yu2ci2dian3??????) [19] and Chinese 
word lists in [20] into a commonly-used 
machine-readable dictionary (MRD) called 
common MRD, which provides the knowledge of 
Chinese lexicon (in which the top 60,000 words 
are selected from the list of 252,307 words in 
descending order of word frequency), word 
frequencies and syllable words. The syllable of 
each word in common MRD was translated by 
the inversed process of phoneme-to-character 
system presented in [4,8]. Word frequency is 
computed according to a fixed size training 
corpus consisting of 4,539,624 Chinese 
sentences obtained from the on-line United 
Daily News [21] (during the period of 17 
January, 2001 to 30 December, 2001).  
2.1 Definition of the NVEF Sense-Pair, 
Word-Pair and Syllable Word-Pair 
The sense of a word is defined as its DEF 
(concept definition) in Hownet. Table 1 lists 
three different senses of the Chinese word 
??(Che/car/turn).? In Hownet, the DEF of a 
word consists of its main feature and secon-
dary features. For example, in the DEF 
?character|? ? , surname|? , human|? , 
ProperName|?? of the word ??(Che),? the 
first item ?character|??? is the main fea-
ture, and the remaining three items, ?sur-
name|? ,? ?human|? ,? and ?ProperName|
?,? are its secondary features. The main 
feature in Hownet can inherit features in the 
hypernym-hyponym hierarchy. There are 
approximately 1,500 features in Hownet. 
Each feature is called a sememe, which re-
fers to a smallest semantic unit that cannot 
be further reduced. 
 
Table 1. Three different senses of the Chinese 
word ??(Che/car/turn)? 
Word POS/Sense (i.e. DEF in Hownet)  
? Che N/character|?? ,surname|?,human|?,ProperName|? 
? car N/LandVehicle|? 
? turn V/cut|?? 
The Hownet dictionary used in this study con-
tains 58,541 words, in which there are 33,264 
nouns, 16,723 verbs and 16,469 senses (includ-
ing 10,011 noun-senses and 4,462 verb-senses). 
In our experiment, we have also added the DEFs 
for those words not in Hownet. 
A permissible NV word-pair such as ??-??
(car-move)? is called a noun-verb event-frame 
(NVEF) word-pair. According to the sense of the 
word ??(Che/car/turn)? and the word ???
(move),? the only permissible NV sense-pair for 
the NV word-pair ?? - ?? (car, move)? is 
?LandVehicle| ? ?-?VehicleGo| ? .? We call 
such a permissible NV sense-pair an NVEF 
sense-pair. Note that an NVEF sense-pair is a 
class that includes the NVEF word-pair instance 
??-??? as well as the corresponding NVEF 
syllable word-pair ?che1-xing2 shi3.? 
2.2 Definition of the NVEF KR-Tree 
A knowledge representation tree (KR-tree) of 
NVEF sense-pairs is shown in Fig.1. There are 
two types of nodes in the KR-tree: concept 
nodes and function nodes. Concept nodes refer 
to words and features in Hownet. Function 
nodes are used to define the relationships 
between their parent and children concept nodes. 
If a concept node A is the child of another 
concept node B, then A is a subclass of B. 
Following this convention, we shall omit the 
function node ?subclass? between A and B. 
Noun-sense class is divided into 15 subclasses 
according to their main features. They are 
bacteria, animal, human, plant, artifact, natural, 
event, mental, phenomena, shape, place, location, 
time, abstract and quantity.  
Three function nodes are used in the KR-tree as 
shown in Fig. 1: 
 
Figure 1. An illustration of the KR-tree using ???
?(artifact)? as an example noun-sense subclass.  
(1) Major-Event (????): The content of its 
parent node represents a noun-sense subclass, 
and the content of its child node represents a 
verb-sense subclass. A noun-sense subclass 
and a verb-sense subclass linked by a 
Major-Event function node is an NVEF 
subclass sense-pair, such as ?&LandVehicle|
? ? and ?=VehcileGo|?? in Fig. 1. To 
describe various relationships between 
noun-sense and verb-sense subclasses, we 
have designed three subclass sense-symbols, 
in which ?=? means ?exact,? ?&? means 
?like,? and ?%? means ?inclusive.? An 
example using these symbols is given below. 
Given three senses S1, S2 and S3 defined by a 
main feature A and three secondary features 
B, C and D, let S1 = A, B, C, D,             
S2 = A, B, and S3 = A, C, D. Then, we have 
that sense S2 is in the ?=A,B? exact-subclass; 
senses S1 and S2 are in the ?&A,B? 
like-subclass; and senses S1 S2, and S3 are in 
the ?%A? inclusive-subclass. 
(2) Word-Instance (?? ): The content of its 
children are the words belonging to the sense 
subclass of its parent node. These words are 
learned automatically by the NVEF 
sense-pair identifier according to sentences 
under the Test-Sentence nodes. 
(3) Test-Sentence (???): Its content includes 
several selected test sentences in support of 
its corresponding NVEF subclass sense-pair. 
2.3 An NVEF Word-Pair Identifier 
We [15] have developed an NVEF sense-pair 
identifier for word-sense disambiguation (WSD). 
This sense-pair identifier is based on the NVEF 
KR-tree and the techniques of longest syllabic 
NVEF-word-pair first (LS-NVWF) and 
exclusion word list (EWL) checking. By 
modifying this identifier, we obtain our NVEF 
word-pair identifier described below. 
Step 1. Input a syllable sequence. 
Step 2. Generate all possible NV word-pairs 
whose corresponding NV syllable 
word-pairs are found in the input 
sequence. Exclude certain NV word-pairs 
based on EWL checking. 
Step 3. Check each NV word-pair to see if its 
corresponding NV sense-pairs (there can 
be several such pairs) can be matched to 
an NVEF subclass sense-pair in the 
KR-tree. If one such NV sense-pair 
matches an NVEF subclass sense-pair in 
the KR-tree, then this permissible NVEF 
sense-pairs and their corresponding NVEF 
word-pairs can be used for the sentence. 
Resolve conflicts using the LS-NVWF 
strategy. 
Step 4. Arrange all remaining permissible 
NVEF sense-pairs and their corresponding 
NVEF word-pairs in a sentence-NVEF 
tree. If no NVEF word-pair can be 
identified from the input sequence, a null 
sentence-NVEF tree will be produced. 
A system overview of the NVEF word-pair 
identifier is given in Fig. 2. The output of this 
NVEF word-pair identifier is called a 
sentence-NVEF tree, as shown in Fig. 3. 
 
NVEF word-
pair identifier
KR tree
sentence-NVEF treeinput syllables
Hownet
LS-NVWF & EWL checking
Figure 2. A system overview of the NVEF word-pair 
identifier. 
 
 
Figure 3. A sentence-NVEF tree for the Chinese 
syllables ?yin3 liao4 li3 han2 you3 bu4 ming2 wu4 
zhi2(?????????|There are uncertain 
matters in the drink).?  
2.4 A Word Identifier for the non-NVEF 
portion 
To supplement the NVEF word-pair identifier 
for the portion of syllable sequence that is not 
converted by the NVEF knowledge, a separate 
word identifier is developed. A system overview 
of the identifier for the NVEF portion and 
non-NVEF portion is given in Fig. 4. Our word 
identifier for the non-NVEF portion includes 
four sub-identifiers whose details are given be-
low: 
(1) Number-classifier-noun phrase (NCN 
phrase) identifier: There are many specific 
linguistic units, such as names, addresses, 
determinatives-measure compounds (DM) etc. in 
syllables which need to be recognized in order to 
supplement the NVEF word-pair identifier 
(which works in a top-down fashion) Although 
the number of these linguistic units are infinite, 
they can be recognized by finite regular 
expressions [22]. Following this fact and 
Chinese grammar, we have developed an NCN 
phrase identifier to identify phrases consisting of 
the numbers, classifiers, and nouns, in particular, 
the commonly-used number-classifier-noun 
syllable pattern, such as syllables ?yi1 bai3 wu3 
shi2 ge4 guan1 zhong4 (???????|one 
hundred and fifty audience).?  
To develop this identifier, we first divide the 
related words in Hownet into three subclasses 
for the construction of the NCN phrase, i.e. 
numbers (the POS is ?NUM?), classifiers (the 
POS is ?CLAS?) and nouns (the POS is ?N?.) 
Secondly, to enrich the knowledge in Hownet, 
12 new numbers and 172 new classifiers are 
added into the original Hownet. Then we create 
a table listing 13,366 classifier-noun word-pairs 
(CN word-pairs) and their corresponding CN 
syllable word-pairs, such as ?ge4-guan1 zhong4 
( ? - ? ? ).? This table is called the CN 
word-pair list, which is generated by training 
corpus (Monosyllabic nouns are not considered 
in this table). 
NVEF word-
pair identifier
KR tree
segmented sentence and a
sentence-NVEF tree
unsegmented
syllable input
Hownet
NCN word
identifier
specific-
monosyllabic
word identifier
unique-syllabic
word identifier
common MRD training corpus
non-unique-
syllabic word
identifier
Figure 4. A system overview of the NVEF-based 
word identifier. 
Now, take the syllables ?yin1 yue4 ting1 you3 
yi1 bai3 wu3 shi2 ge4 guan1 zhong4 (????
???????|There are one hundred and 
fifty audiences in concert hall)? as an example. 
The NCN phrase identifier will first identify the 
words of number syllables ?yi1 bai3 wu3 
shi2( ? ? ? ? |one hundred and fifty)? 
combined by combining two matching number 
syllables ?yi1 bai3( ?? |one hundred)? and 
?wu3 shi2(?? |fifty).? Secondly, if the number 
of characters of the recognized number syllables 
is greater than 1, the NCN word identifier will 
continue on checking the following syllables 
with the CN word-pair list. In this case, since the 
following syllables ?ge4 guan1 zhong4? are 
found in the CN word-pair list, it will be 
identified as CN word-pair ??-??.? 
(2) Specific-monosyllabic word identifier: 
When a monosyllabic word in Hownet has 
exactly one POS, and that POS is in the set 
{ADJ (adjective), ADV (adverb), AUX 
(auxiliary), COOR (coordinator), CONJ 
(conjunctive), PREP (preposition), STRU 
(structure word)}, we call this word a 
specific-monosyllabic word. There are 525 
specific-monosyllabic words found in the used 
Hownet. 
Consider the following monosyllabic word ??
|already(yi3).? We shall use the POS 
information of polysyllabic words immediately 
preceding and following this word to decide if 
?yi3? should be identified as ?? (already)?. 
According to the training corpus, the top 3 
preferred POSs of words following ? ?
(already)? are V (verb), ADV (adverb) and ADJ 
(adjective). Therefore, the top 3 preferred POSs 
of syllable words following ?yi3? should also be 
V, ADV and ADJ provided that ??(already)? is 
to be identified. The top 3 preferred POSs of 
syllable words preceding and following a 
specific-monosyllabic word will be called the 
top 3 preceding and following preferred POSs, 
respectively. 
Now, consider the syllable sequence ?gong1 
cheng2 yi3 wan2 cheng2 le5 (??????
|The project has been done)? as an example. 
First, by checking syllable-by-syllable from left 
to right, our algorithm recognizes that there is a 
specific-monosyllabic word ?yi3? in this 
sentence. Then, it will use the 
longest-syllabic-word-first strategy to identify 
the syllable word ?wan2 cheng2? following 
?yi3? and the syllable word ?gong1 cheng2? 
preceding ?yi3?. It will check whether at least 
one of the distinct POSs of the preceding and 
following syllable words are within the set of 
top 3 preceding and following preferred POSs of 
?yi3?, respectively . Since this is indeed the case, 
the word ??? will be identified. 
After the input syllables have been processed by 
the NVEF word-pair identifier, the NCN word 
identifier, and the specific-monosyllabic word 
identifier, the remaining unconverted syllables 
will be segmented in a right-to-left fashion using 
the LS-NVWF strategy in the following process. 
(3) Unique-syllabic word identifier: When 
a given syllable word maps to exactly one word 
in the common MRD, we call the mapped word 
in MRD a unique-syllabic word, e.g. the word 
? ? ? ? /yin1 yue4 hui4/?. These 
unique-syllabic words will be identified directly 
from right to left. 
(4) Non-unique-syllabic word identifier: 
This identifier is used at the very end to deal 
with those remaining unconverted syllables. It is 
an n-gram based approach. Define the NVEF 
frequency to be the number of sentences 
including a given NVEF word-pair in the 
training corpus. First of all, the identifier will 
select, from the sentence-NVEF tree, the NVEF 
word-pair having the largest NVEF frequency as 
the main NVEF word-pair. Recall that the 
unconverted syllables have been segmented by 
the longest-syllable-word-first strategy from 
right to left. Finally, it will convert each 
segmented syllable word to its corresponding 
word by the following steps: (a) find all 
distinctly mapped words of a given syllable 
word from the common MRD, (b) compute the 
co-occurrence frequency of each mapped word 
with the key NVEF word-pair one-by-one in 
descending order of mapped words? frequencies, 
(c) whenever the co-occurrence frequency is 
greater than 0, then convert the given syllable 
word to this mapped word, (d) if all the 
computed co-occurrence frequencies in step (b) 
are 0, the given syllable word will be convert to 
its mapped word with the largest word 
frequency. 
Take the non-unique syllable word ?jin4? in 
Table A1 as example, the list of its mapped 
words in descending order of word frequency 
were ??(enter)/212,481?, ??(near)/115,913?, 
??(exhaustive)/58,387? , ??(forbid)/17,702?, 
??(strongly)/8,089?, ??(Jin Dynasty)/4,524?, 
?? (soak)/1,677? , ? ? (cinder)/722? , ? ?
(Jin)/114? and ? ? (red silk)/41.? Since the 
co-occurrence frequency of the mapped words 
with the key NVEF word-pair ??? - ??
(locale, enter)? is first greater than 0 at the word 
??(near)?, the non-unique syllabic word ?jin4? 
will be converted to the word ??.? 
3. Experimental Results 
Define the STW accuracy to be the ratio of the # 
of correct characters identified over the total # of 
characters. We use the inverse translator of 
phoneme-to-character system in [3] to convert a 
test sentence into a syllable sequence, then apply 
our STW algorithm to convert this syllable 
sequence back to characters and calculate its 
accuracy.  
If a sentence contains an NVEF word-pair, this 
sentence is called an NVEF identified sentence. 
Since the purpose of this study is to demonstrate 
the effect of applying NVEF word-pair identifier 
to the STW conversion, we shall focus on 
converting NVEF identified sentences. 
10,000 NVEF identified sentences are randomly 
selected from the test sentences in the KR-tree to 
be the closed test set; and another 10,000 
sentences are randomly selected from Sinica 
corpus to be the open test set. Note that 
sentences in open test set are not necessarily 
NVEF identified sentences. 
The results of the STW experiment are shown in 
Table 2 listed in three columns: (1) the NVEF 
word-pair identifier; (2) the other four 
sub-identifiers for the non-NVEF protion; and (3) 
the combination of (1) and (2).  
 
Table 2. The results of the STW experiment. 
    (1)       (2)    (3)  
Closed test 99.76%    94.65% 97.10% 
Open test 99.55%    93.64% 95.97% 
Average  99.66%    94.08% 96.50% 
  
For more details, the accuracies of the four 
identifiers in Section 2.4 are listed in Table 3 
below. 
 
Table 3. The STW accuracies of the four 
sub-identifiers for the non-NVEF portion 
(1) (2) (3) (4)  
Closed test   100.00% 94.68% 97.45% 89.01% 
Open test     97.25% 94.02% 97.37% 86.10% 
Average       98.31% 94.32% 97.41% 87.35% 
4. Conclusions and Directions for Future 
Research 
In this paper, we have applied an NVEF 
word-pair identifier to the Chinese STW 
conversion problem and obtained excellent rates 
as shown in Table 2. The knowledge used in this 
study includes: (1) the NVEF knowledge, (2) the 
CN word-pair list, (3) the top 3 preferred POSs 
following or preceding the 
specific-monosyllabic words, (4) the 
unique-syllabic word list and (5) the 
co-occurrence frequency of words with a 
selected key NVEF word-pairs. Besides the 
NVEF knowledge in (1), which can be (and has 
been) generated semi-automatically, the other 
knowledge can all be trained automatically. 
Our database for the NVEF knowledge has not 
been completed at the time of this writing. The 
NVEFs are constructed by selecting a 
noun-sense in Hownet and searching for 
meaningful verb-sense associated with it. 
Currently, only 66.34% (=6,641/10,011) of the 
noun-senses in Hownet have been considered in 
the NVEF knowledge construction. This results 
in 167,203 NVEF subclass sense-pairs and 
317,820 NVEF word-pairs created in the 
KR-tree. In the training corpus, about 50% of 
the sentences includes at least one NVEF 
word-pair in it.  
Based on this experiment, we find that the 
NVEF-based approach has the potential to 
provide the following information for a given 
syllable sequence: (1) well-segmented Chinese 
sentence, (2) sentence-NVEF tree including 
main verbs, nouns, NVEF word-pairs, NVEF 
sense-pairs, NVEF phrase-boundaries, and (3) 
the CN word-pairs. This information will likely 
be useful for general NLP, especially for 
sentence understanding.  
The NVEF knowledge is a general linguistic 
key-feature for sentence analysis. We are 
encouraged to note that the NVEF knowledge 
can achieve a high STW accuracy of 99.66% for 
the NVEF related portion. Our NVEF word 
identifier can be easily integrated with other 
existing STW conversion systems by using the 
NVEF word identifier as a first round filter, 
namely, identifying words in the NVEF related 
portion (thus, providing a good fundamental 
basis) and leaving the remaining unconverted 
syllables to other systems with a good potential 
to enhance their accuracies. 
We shall continue our work on covering all the 
noun-senses in Hownet for the NVEF 
knowledge construction. This procedure can 
now be done fully automatically with 99.9% of 
confidence. The study of NVEF will also be 
extended to that of other co-occurrence 
restrictions such as noun-noun (NN) pairs, 
noun-adjective (NA) pairs and verb-adverb (ND) 
pairs. Note, however, that the study of these 
latter pairs will be much simpliefied once the 
key-feature NVEFs of a sentence have been 
correctly extracted. We shall also try to improve 
our NVEF-based approach for the STW 
conversion and further extend it to speech 
recognition. 
The results in [15] indicate that the NVEF 
knowledge can also be used effectively for word 
sense disambiguation. In the future, we shall 
apply the NVEF knowledge to other fields of 
NLP, in particular, document classification, 
information retrieval, question answering and 
speech understanding. 
References 
1. Huang, J. K. 1985. The Input and Output of Chinese 
and Japanese Characters. IEEE Computer, 18(1):18-24. 
2. Chang, J.S., S.D. Chern and C.D. Chen. 1991. Conver-
sion of Phonemic -Input to Chinese Text Through Con-
straint Satisfaction. Proceedings of ICCPOL'91, 30-36. 
3. Hsu, W. L. and K.J. Chen. 1993. The Semantic Analy-
sis in GOING - An Intelligent Chinese Input System. 
Proceedings of the Second Joint Conference of Com-
putational Linguistics, Shiamen, 338-343. 
4. Hsu, W. L. and Y.S. Chen. 1999. On Pho-
neme-to-Character Conversion Systems in Chinese 
Processing. Journal of Chinese Institute of Engineers, 
5:573-579. 
5. Lua, K.T. and K.W. Gan. 1992. A Touch-Typing Pin-
yin Input System. Computer Processing of Chinese and 
Oriental Languages, 6:85-94. 
6. Sproat, R. 1990. An Application of Statistical Optimi-
zation with Dynamic Programming to Phone-
mic-Input-to-Character Conversion for Chinese. Pro-
ceedings of ROCLING III, 379-390. 
7. Chen, B., H. M. Wang and L. S. Lee. 2000. Retrieval of 
broadcast news speech in Mandarin Chinese collected 
in Taiwan using syllable -level statistical characteristics. 
Proceedings of the 2000 International Conference on 
Acoustics Speech and Signal Processing. 
8. Hsu, W. L. 1994. Chinese parsing in a pho-
neme-to-character conversion system based on seman-
tic pattern matching. Computer Processing of Chinese 
and Oriental Languages, 8(2):227-236. 
9. Kuo, J. J. 1995. Phonetic -input-to-character conversion 
system for Chinese using syntactic connection table and 
semantic distance. Computer Processing and Oriental 
Languages, 10(2):195-210. 
10.  Lin, M. Y. and W. H. Tasi. 1987. ?Removing the am-
biguity of phonetic Chinese input by the re laxation 
technique,? Computer Processing and Oriental Lan-
guages, 3(1):1-24. 
11.  Gu, H. Y., C. Y. Tseng and L. S. Lee. 1991. Markov 
modeling of mandarin Chinese for decoding the pho-
netic sequence into Chinese characters. Computer 
Speech and Language, 5(4):363-377. 
12.  Ho, T. H., K. C. Yang, J. S. Lin and L. S. Lee. 1997. 
Integrating long-distance language mode ling to pho-
netic-to-text conversion. Proceedings of ROCLING X 
International Conference on Computational Linguistics, 
287-299. 
13.  Fong, L. A. and K.H. Chung. 1994. Word Segmenta-
tion for Chinese Phonetic Symbols. Proceedings of In-
ternational Computer Symposium, 911-916. 
14.  Chen, C. G., K. J. Chen and L. S. Lee. 1986. A model 
for Lexical Analysis and Parsing of Chinese Sentences. 
Proceedings of 1986 International Conference on Chi-
nese Computing, Singapore, 33-40. 
15.  Tsai, J. L, W. L. Hsu and J. W. Su. 2002. Word sense 
disambiguation and sense-based NV event-frame iden-
tifier. Computational Linguistics and Chinese Lan-
guage Processing, 7(1):29-46. 
16.  Dong, Z. and Q. Dong, Hownet, 
http://www.keenage.com/ 
17.  CKIP. 1995. Technical Report no. 95-02, the content 
and illustration of Sinica corpus of Academia Sinica. 
Institute of Information Science, Academia Sinica, 
http://godel.iis.sinica.edu.tw/CKIP/r_content.html 
18.  Mei, J. et al 1982. Tong2Yi4Ci2Ci2Lin2 ?????
??, Shanghai Dictionary Press. 
19.  Taiwan?s Ministry of Education. 1998. 
Guo2Yu2Ci2Dian3 (Electronic Chinese Dictio nary),  
http://www.edu.tw/mandr/clc/dict/ 
20.  Tsai, C. T. (2001) A Review of Chinese Word Lists 
Accessible on the Internet. Chih-Hao Tsai Research 
Page  
http://www.geocities.com/hao510/wordlist/. 
21.  On-Line United Daily News, 
http://udnnews.com/NEWS/ 
22. Huang, C. R. et al 1996. Readings in Chinese Natural 
Language Processing. Journal of Chinese Linguistics, 
9:1-174.
 
Applying a Mix Word-Pair Identifier to the Chinese Syllable-to-Word 
Conversion Problem 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
 Taipei 222, Taiwan, R.O.C. 
tsaijl@mail.tnit.edu.tw 
 
 
Abstract 
This paper describes a mix word-pair 
mix-WP) identifier to resolve homo-
nym/segmentation ambiguities as well 
as perform STW conversion effec-
tively for Chinese input. The mix-WP 
identifier includes a specific word-pair 
(SWP) identifier and a common word-
pair (CWP) identifier. It is designed as 
a supporting processing with Chinese 
input systems. Our experiments show 
that by applying the mix-WP identifier, 
together with the Microsoft input 
method editor 2003 (MSIME) and an 
optimized bigram model (BiGram), 
the tonal and toneless STW perform-
ance of the two input systems can be 
improved. 
1 Introduction 
Currently, the most popular method for Chinese 
input is phonetic and pinyin based, because Chi-
nese people are taught to write the correspond-
ing phonetic and pinyin syllables of each 
Chinese character and word in primary school. 
In Chinese, each Chinese character corresponds 
to at least one syllable; and each Chinese word 
can be a mono-syllabic word, such as ??
(mouse)?, a bi-syllabic word, such as ???
(kangaroo)?, or a multi-syllabic word, such as 
????(Mickey mouse).? Although there are 
more than 13,000 distinct Chinese characters (of 
which 5,400 are commonly used), there are only 
about 1,300 distinct syllables. Since the size of 
problem space for syllable-to-word (STW) con-
version is much less than that of syllable-to-
character (STC) conversion, the most existing 
Chinese input systems (Hsu 1994, Hsu et al 
1999, Tsai and Hsu 2002, Gao et al 2002, 
MSIME) are addressed on STW conversion.  
Conventionally, there are two approaches for 
STW conversion: (1) the linguistic approach 
based on syntax parsing, semantic template 
matching and contextual information (Hsu 1994, 
Fu et al 1996, Hsu et al 1999, Kuo 1995, Tsai 
and Hsu 2002); and (2) the statistical approach 
based on the n-gram models where n is usually 2 
or 3 (Lin and Tsai 1987, Gu et al 1991, Fu et al 
1996, Ho et al 1997, Sproat 1990, Gao et al 
2002, Lee 2003). Although the linguistic ap-
proach requires considerable effort in designing 
effective syntax rules, semantic templates or 
contextual information, it is more user-friendly 
than the statistical approach on understanding 
why such a system makes a mistake (Hsu 1994, 
Tsai and Hsu 2002). On the other hand, the sta-
tistical language model (SLM) used in the statis-
tical approach requires less effort and has been 
widely adopted in commercial Chinese input 
systems (Gao et al 2002, Lee 2003). 
According to (Fong and Chung 1994, Tsai 
and Hsu 2002), homophone selection and sylla-
ble-word segmentation are two critical problems 
to the STW conversion in Chinese. Incorrect 
homophone selection and failed syllable-word 
segmentation will directly influence the STW 
conversion rate. The goal of this study is to il-
lustrate the effectiveness of specific word-pairs 
and common word-pairs for resolving homo-
nym/segmentation ambiguities to perform STW 
conversion in Chinese. In this paper, we use to-
nal to indicate the syllables with four tones, such 
as ?ji4(?)shu4(?)? and toneless to indicate the 
syllables without four tones, such as ?ji(? ) 
shu(?).? 
55
The remainder of this paper is arranged as 
follows. In Section 2, we firstly propose the 
method for auto-generating the specific word-
pairs and the common word-pairs from given 
Chinese sentences. Then, we develop a mix 
word-pair (mix-WP) identifier includes a spe-
cific word-pair identifier and a common word-
pair identifier. The mix-WP identifier is based 
on pre-collected datasets of specific and com-
mon word-pairs. In Section 3, we present our 
STW experiment results. Finally, in Section 4, 
we give our conclusions and suggest some fu-
ture research directions. 
2 Development of Mix-WP Identifier 
In this study, a mix word-pair identifier includes 
a specific word-pair (SWP) identifier and a 
common word-pair (CWP) identifier. The sys-
tem dictionary of the mix-WP identifier is com-
prised of the CKIP lexicon (CKIP, 1995) and 
those unknown words found automatically from 
the UDN 2001 corpus by a Chinese word auto-
confirmation (CWAC) system (Tsai et al 2003). 
The pinyin syllable-words were translated by 
phoneme-to-pinyin mappings, such as ???
??-to-?ji4.? 
2.1 Development of SWP Identifier 
2.1.1 Auto-Generate SWP Data.  
The steps of auto-generating specific word-pair 
(AUTO-SWP) for a given Chinese sentence: 
Step 1. Generate the segmentation for the given 
Chinese sentence with a backward maximum 
matching (BMM) technique. As pre (Tsai et al 
2004), the performance of BMM is better than 
that of forward maximum matching. 
Step 2. Extract the BEGIN, END and BOUND 
word-pairs from the BMM segmentation of 
Step 1 by following processes, respectively:  
(1) BEGIN word-pair. When the word number 
of segmentation is greater than 1, the first two 
words will be comprised as a BEGIN word-
pair. For the segmentation ????(concert)?
? (locale) ? ? (enter) ? ? (many) ? ?
(audience members),? the ????-??? will 
be generated as a BEGIN word-pair. 
(2) END word-pair. When the word number of 
segmentation is greater than 2, the last two 
words will be comprised as an END word-pair. 
For the segmentation ??? (whole)??
(construction)?? (prearrange)?? (end of 
year)??(complete),? the ???-??? will 
be generated as an END word-pair. 
(3) BOUND word-pair. When the word num-
ber of segmentation is greater than 2, the first 
word and the last word will be comprised as a 
BOUND word-pair. For the segmentation ??
?(price)??(ordinarily)??(maintain)??
(stable),? the ???-??? will be generated as 
a BOUND word-pair. 
Step 3. If the generated SWP was not found in 
its corresponding datasets, insert the generated 
SWP into the BEGIN, END and BOUND 
word-pair datasets, respectively. 
2.1.2 SWP Identifier.  
In Figure 1, the SWP data is a collection of auto-
generated BEGIN, END and BOUND SWP 
datasets. If a SWP identifier only uses one of the 
BEGIN, END or BOUND SWP dataset, it will 
naturally become a BEGIN(BN), END(ED) or 
BOUND(BD) SWP identifier. The algorithm of 
our SWP identifier is as follows: 
Specific word-pair 
(SWP) identifier
SWP data
SWP-sentenceinput syllables
System dic
 
Fig. 1. A system overview of the SWP identifier 
Step 1. Input tonal or toneless syllables. 
Step 2. Generate all found BN, ED and BD 
SWP in the input syllables to be the initial 
SWP set. if the initial SWP set, if the found 
SWP number of the word-syllable pair of a 
BN, ED or BD SWP is greater than one in the 
BN, ED or BD datasets, respectively, the SWP 
will be dropped from the initial SWP set. 
Step 3. Use the longest syllabic word-pair first 
(LS-WPF) strategy (Tsai and Hsu. 2002) to se-
lect the BN, ED and BD word-pair from the 
initial SWP set into the final SWP set. 
Step 4. Replace corresponding syllable-word 
pair of the input syllables with the word-pairs 
of the final SWP set to be a SWP-sentence. As 
per our experiment, the performance of the 
three SWP identifiers is BD < BN < ED. Thus, 
the identifying sequence of our SWP identifier 
is from BD, BN to ED. 
Table 1 is a step by step example that illustrates 
the four steps of our SWP identifier for the Chi-
56
nese syllables ?shu3 dou1 shu3 bu4 qing1 (?
[count]?[always]???[innumerable])).? Note 
that when we used the Microsoft Input Method 
Editor 2003 for Traditional Chinese, a trigram-
like input system (MSIME), to convert the same 
syllables, the output was ??(belong)?(always)
?(mouse)?(not)?(clear).? 
Table 1. An illustration of a SWP-sentence for the 
Chinese syllables ?shu3 dou1 shu3 bu4 qing1(?
[count]?[always]???[innumerable])? 
Step # Results               
Step.1 shu3 dou1 shu3 bu4 qing1 
 (?   ?      ?    ?   ?) 
Step.2 The specific word-pairs found: 
 ?(shu3)-?(dou1)/BEGIN pair 
 ?(dou1)-???(shu3)/END pair 
Step.3 The selected specific word-pairs: 
 ?(shu3)-?(dou1)/BEGIN pair 
 ?(dou1)-???(shu3)/END pair 
Step.4 SWP-sentence: 
 ? ? shu3 bu4 qing1 
 (?shu3 dou1? replace with the BEGIN pair of Step 3) 
  ? ? ? ? ?  
 (?shu3 bu4 qing1? replace with the END pair of Step 3) 
2.2 Development of CWP Identifier 
2.2.1 Auto-Generate CWP Data 
The steps of auto-generating common word-pair 
(AUTO-CWP) for a given Chinese sentence: 
Step 1. Generate the word segmentation for the 
given Chinese sentence by BMM technique. 
Step 2. Extract all the combinations of word-
pairs from the BMM segmentation of Step 1 to 
be the initial CWP set. For the segmentation 
??/??/??,? three CWP will be extracted, 
i.e. ??-???, ??-??? and ???-??.? 
Step 3. Select the word-pairs comprised of two 
multi-syllabic Chinese words (such as ???
(can not)?) to be the finial CWP set. For the 
final CWP set, if the word-pair is not found in 
the CWP database, insert it into the CWP da-
tabase and set its frequency to 1; otherwise, 
increase its frequency by 1. In the above case, 
the final CWP set includes one word-pair, i.e. 
???-??.?  
2.2.2 CWP Identifier 
The system overview of the CWP identifier is 
same with that of the SWP identifier as shown 
in Fig. 1. The algorithm of our CWP identifier 
is as follows: 
Step 1. Input tonal or toneless syllables. 
Step 2. Generate all possible word-pairs com-
prised of two multi-syllabic Chinese words for 
the input syllables to be the input of Step 3. 
Step 3. Select out the word-pairs that match a 
word-pair in the CWP database to be the ini-
tial CWP set, firstly. Then, from the initial 
CWP set, select the word-pair with maximum 
frequency as the key word-pair. Finally, find 
the co-occurrence word-pairs with the key 
word-pair in the training corpus to be the final 
CWP set. If there are two or more word-pairs 
with the same maximum frequency, one of 
them is randomly selected as the key word-
pair. 
Step 4. Arrange all word-pairs of the final CWP 
set into a CWP-sentence. If no word-pairs can 
be identified in the input syllables, a NULL 
CWP-sentence is produced. 
If applying the CWP identifier on the syllables 
?yi1 ge5 wen2 ming2 de5 shuai1 wei2 guo4 
cheng2(?? [a]?? [civilization]? [of]??
[decay]?? [process]),? the generated WP-
sentence will be ????? de5shuai1wei2 ?
? .? For the same syllables, the MSIME will 
convert them into ???[a]??[famous]?[of]
??[decay]??[process].? The detailed analy-
sis and demonstration of our CWP identifier can 
be found in (Tsai 2005). Appendix A presents a 
case of the CWP identified results. 
3 The STW Experiments 
To evaluate the STW performance of our mix-
WP identifier, the STW accuracy, the identified 
character ratio (ICR) and the STW improvement 
were used (Tsai 2005). 
3.1 Experimental Data 
To conduct the STW experiments, firstly, use 
the inverse translator of phoneme-to-character 
(PTC) provided in GOING system to convert 
testing sentences into their corresponding sylla-
bles. All the error PTC translations of GOING 
were corrected by post human-editing. We, then, 
apply our SWP, CWP and mix-WP identifier to 
convert the syllable sequence back to words and 
calculate its STW accuracy and identified char-
acter ratio. All test sentences are composed of a 
string of Chinese characters. 
In following experiments, the training and 
testing corpus, closed/open test sets and the col-
lection of the testing SWP and CWP data were: 
57
Training corpus: The UDN 2001 corpus was 
selected as our training corpus. It is a collection 
of 4,539,624 Chinese sentences extracted from whole 
2001 articles on the United Daily News Website 
(UDN) in Taiwan. 
Testing corpus: The UDN 2002 corpus was 
selected as our testing corpus. It is a collection 
of 3,321,504 Chinese sentences that were ex-
tracted from whole 2002 articles on (UDN).  
Closed testing set: 10,000 sentences were ran-
domly selected from the UDN 2001 corpus as 
the closed testing set. 
Open testing set: 10,000 sentences were ran-
domly selected from the UDN 2002 corpus as 
the open testing set. At this point, we checked 
that the selected open testing sentences were not 
in the closed testing set as well. 
Testing SWP data: By applying our AUTO-
SWP on the UDN 2001 corpus, we created 
1,754,055 BN, 1,594,036 ED and 2,502,241 BD 
specific word-pairs. 
Testing CWP data: By applying our AUTO-
CWP on the UDN 2001 corpus, we created 
25,439,679 common word-pairs. 
In this study, we conducted the STW experiment 
in a progressive manner. The experimental re-
sults of the SWP, CWP and mix-WP identifiers 
are described in Sub-sections 3.2, 3.3.and 3.4, 
respectively. 
3.2 Experiment of SWP Identifier 
This experiment is to demonstrate the tonal and 
toneless STW accuracies by using the SWP 
identifier with the testing BN, ED, BD and ALL 
datasets, respectively. Note that the symbol 
ALL stands for a mixed collection of all BN, 
ED and BD word-pairs generated from the 
UDN 2001 corpus. 
Table 2. The results of tonal/toneless STW experi-
ments for the SWP identifier with BN, ED, BD and 
ALL specific word-pairs 
Data Closed       Open  Average (ICR) 
BN 99.7 / 97.7     99.1 / 96.1       99.4(11.6)/96.7(9.2) 
ED 99.9 / 99.6     99.3 / 97.3 99.6(14.3)/98.4(12.1) 
BD 99.6 / 98.0     99.2 / 95.9 99.3(17.7)/96.3(13.4) 
ALL a 99.7 / 98.3     99.2 / 96.3 99.4(30.7)/97.1(22.8) 
a The performance of SWP identifier with three SWP data and the 
word-pair replacing sequence of the SWP is from BD, BN to ED 
 
Table 2 shows the average tonal and toneless 
STW accuracies of the SWP identifier with ALL 
SWP data for the closed and open test sets are 
99.4% and 97.1%, respectively. Meanwhile, be-
tween the closed and open test sets, the differ-
ences of tonal and toneless STW accuracies of 
the SWP identifier are 0.5% and 2%, respectively.  
3.3 Experiment of CWP Identifier 
This experiment is to demonstrate the tonal and 
toneless STW accuracies among the identified 
word-pairs by using the CWP identifier with the 
testing CWP data. 
Table 3. The results of the tonal and toneless STW 
experiment for the CWP identifier 
   Closed Open     Average (ICR) 
Tonal     99.1  98.4          98.8 (61.9) 
Toneless    94.1  90.9          92.6 (58.6) 
 
Table 3 shows the average tonal and toneless 
STW accuracies of the CWP identifier for closed 
and open test sets are 98.8% and 92.6%, respec-
tively. Meanwhile, between the closed and open 
test sets, the differences of tonal and toneless 
STW accuracies of the CWP identifier are 0.7% 
and 3.2%, respectively. 
3.4 Experiment of Mix-WP Identifier 
This experiment is to demonstrate the tonal and 
toneless STW accuracies among the identified 
word-pairs by using the mix-WP identifier with 
all testing WP data. From Tables 2 and 3, the 
STW performance of the SWP identifier is bet-
ter than that of the CWP identifier. Therefore, 
our mix-WP identifier uses the CWP identifier 
to identify CWP first and the SWP identifier to 
identifier SWP last for a given syllables. 
Table 4. The results of tonal and toneless STW ex-
periments for the mix-WP identifier 
   Closed Open Average (ICR) 
Tonal     99.2  98.4      98.8 (67.6) 
Toneless    94.9  91.8      93.5 (64.6) 
 
Table 4 shows the average tonal and toneless 
STW accuracies of the mix-WP identifier for 
closed and open test sets are 98.8% and 93.5%, 
respectively. Meanwhile, between the closed 
and open test sets, the differences of to-
nal/toneless STW accuracies of the mix-WP 
identifier are 0.8% and 3.1%, respectively. The 
average identified character ratio (ICR) of the 
tonal and the toneless syllables are 67.6% and 
64.6%, respectively. To sum up the results of 
Tables 2 to 4, we conclude that the mix-WP 
(SWP and CWP) data can be used to effectively 
convert Chinese STW on the mix-WP-related 
58
portion (including the SWP-related portion and 
the CWP-related portion, respectively). 
3.5 Commercial IME System and Bigram 
Model with WP Identifier 
We selected Microsoft Input Method Editor 
2003 for Traditional Chinese (MSIME) as our 
experimental commercial Chinese input system. 
In addition, an optimized bigram model called 
BiGram was developed (Tsai et al 2004). The 
BiGram STW system is a bigram-based model 
developing by SRILM (Stolcke 2002) with 
Good-Turing back-off smoothing (Manning and 
Schuetze, 1999), as well as forward and back-
ward LS-WPF strategies (Chen et al 1986, Tsai 
et al 2004). The training corpus and the system 
dictionary of this BiGram system are same with 
that of the mix-WP identifier. In this experi-
ment, the STW output of the MSIME with the 
mix-WP identifier, or the BiGram with the mix-
WP identifier, was collected by directly replac-
ing the identified word-pairs from the corre-
sponding STW output of MSIME or BiGram. 
 
Table 5. The results of tonal and toneless STW ex-
periment for the MSIME and the MSIME with the 
mix-WP identifier 
MSIME      MSIME+WP a     Improvement          
Tonal     94.7% 96.3%  29.3%  
Toneless    86.4% 89.4%  22.5%  
a STW accuracies of the words identified by the MSIME with the 
mix-WP identifier 
Table 6. The results of the tonal and toneless STW 
experiment for the BiGram and the BiGram with the 
mix-WP identifier 
BiGram       BiGram+WP a       Improvement          
Tonal     96.4% 96.9%  12.8%  
Toneless    85.2% 88.1%  19.6%  
a STW accuracies of the words identified by the BiGram with the 
mix-WP identifier 
 
From Table 5, the tonal and toneless STW 
improvements of the MSIME by using the mix-
WP identifier are 29.2% and 22.5%, respec-
tively. On the other hand, from Table 6, the to-
nal and toneless STW improvements of the 
BiGram by using the mix-WP identifier are 
12.8% and 19.6%, respectively. To sum up the 
results of this experiment, we conclude that the 
mix-WP identifier can achieve better WP-
portion STW accuracy than that of the MSIME 
and BiGram Chinese input systems. 
4 Conclusion and Future Directions 
In this paper, we have applied a mix-WP identi-
fier to the Chinese STW conversion and ob-
tained a high STW accuracy on the identified 
word-pairs with ICR of more than 60%. All of 
the testing mix-WP data was auto-generated by 
using the AUTO-SWP and the AUTO-CWP on 
the training corpus. We are encouraged by the 
fact that mix-WP knowledge can achieve tonal 
and toneless STW accuracies of 98.8% and 
93.5%, respectively, for the mix-WP-related 
portion of the testing syllables. The mix-WP 
identifier can be easily integrated into existing 
Chinese input systems or Chinese language 
processing of typical speech recognition sys-
tems by identifying word-pairs in a post-
processing step. Our experimental results show 
that, by applying the mix-WP identifier together 
with the MSIME and the BiGram input systems, 
the tonal and toneless STW improvements are 
29%/23% and 13%/20%, respectively. To the 
adaptive approach, we also tried to use the 
AUTO-SWP and the AUTO-CWP to auto-
extract new SWP and CWP from the open test 
sentences into the mix-WP data, firstly. Then, 
we found the overall tonal and toneless STW 
accuracies of the MSIME and the BiGram for 
closed/open syllables become 96.5%/90% and 
97.1%/89%, respectively. 
Currently, our approach is quite basic when 
more than one SWP or CWP occurs in the same 
sentence. Although there is room for improve-
ment, we believe it would not produce a notice-
able effect as far as the STW accuracy is 
concerned. However, this issue will become 
important as we apply the mix-WP knowledge 
to speech recognition. According to our compu-
tations, the collection of our mix-WP knowl-
edge can cover approximately 70% and 60% of 
the characters in the UDN 2001 and 2002 cor-
pus, respectively. 
We will continue to expand our collection of 
mix-WP knowledge with Web corpus. In other 
directions, we will try to improve our WP-based 
STW conversion with other types of WP data, 
such as NEVF and MWP (Tsai et al 2002 and 
2004), and statistical language models, such as 
HMM, and extend it to other areas of NLP, es-
pecially word segmentation and the mix-WP 
identifier from the word lattice of Chinese 
speech recognition systems. 
59
References 
Chung, K.H. 1993. Conversion of Chinese Phonetic 
Symbols to Characters, M. Phil. thesis, De-
partment of Computer Science, Hong Kong 
University of Science and Technology. 
CKIP. Technical Report no. 95-02. 1995. The content 
and illustration of Sinica corpus of Academia 
Sinica. Institute of Information Science, Aca-
demia Sinica. 
Fong, L.A. and K.H. Chung. 1994. Word Segmenta-
tion for Chinese Phonetic Symbols, Proceed-
ings of International Computer Symposium, 
911-916. 
Fu, S.W.K, C.H. Lee and Orville L.C. 1996. A Sur-
vey on Chinese Speech Recognition, Communi-
cations of COLIPS, 6(1):1-17. 
Gao, J, Goodman, J., Li, M. and Lee K.F. 2002. To-
ward a Unified Approach to Statistical Lan-
guage Modeling for Chinese, ACM 
Transactions on Asian Language Information 
Processing, 1(1):3-33. 
GOING, ?http://www.iqchina.com/? 
Gu, H.Y., C.Y., Tseng and L.S., Lee. 1991. Markov 
modeling of mandarin Chinese for decoding the 
phonetic sequence into Chinese characters, 
Computer Speech and Language 5(4):363-377. 
Ho, T.H., K.C., Yang, J.S., Lin and L.S., Lee. 1997. 
Integrating long-distance language modeling to 
phonetic-to-text conversion, Proceedings of 
ROCLING X International Conference on 
Computational Linguistics, 287-299. 
Hsu, W.L. 1994. Chinese parsing in a phoneme-to-
character conversion system based on semantic 
pattern matching, Computer Processing of Chi-
nese and Oriental Languages 8(2):227-236. 
Hsu, W.L. and Y.S., Chen. 1999. On Phoneme-to-
Character Conversion Systems in Chinese 
Processing, Journal of Chinese Institute of 
Engineers, 5:573-579. 
Kuo, J.J. 1995. Phonetic-input-to-character conver-
sion system for Chinese using syntactic connec-
tion table and semantic distance, Computer 
Processing and Oriental Languages, 10(2):195-
210. 
Lee, Y.S. 2003. Task adaptation in Stochastic Lan-
guage Model for Chinese Homophone Disam-
biguation, ACM Transactions on Asian 
Language Information Processing, 2(1):49-62. 
Lin, M.Y. and W.H., Tasi. 1987. Removing the ambi-
guity of phonetic Chinese input by the relaxa-
tion technique, Computer Processing and 
Oriental Languages, 3(1):1-24. 
Manning, C. D. and Schuetze, H. 1999. Fundations 
of Statistical Natural Language Processing, 
MIT Press: 191-220. 
MSIME, Microsoft Research Center in Beijing,  
?http://research.microsoft.com/aboutmsr/labs/beijing? 
Sproat, R. 1990. An Application of Statistical Opti-
mization with Dynamic Programming to Pho-
nemic-Input-to-Character Conversion for 
Chinese, Proceedings of ROCLING III, 379-
390. 
Stolcke A. 2002. SRILM - An Extensible Language 
Modeling Toolkit, Proc. Intl. Conf. Spoken 
Language Processing, Denver. 
Tsai, J.L. 2005. Using Word-Pair Identifier to Im-
prove Chinese Input System, Proceedings of 
4th SIGHAN workshop on Chinese Language 
Processing, Korea. 
Tsai, J.L, G., Hsieh and W.L., Hsu. 2004. Auto-
Generation of NVEF knowledge in Chinese, 
Computational Linguistics and Chinese Lan-
guage Processing, 9(1):41-64. 
Tsai, J.L. and W.L., Hsu. 2002. Applying an NVEF 
Word-Pair Identifier to the Chinese Syllable-to-
Word Conversion Problem, Proceedings of 19th 
COLING 2002, 1016-1022. 
Tsai, J,L, C.L., T.J., Jiang and W.L., Hsu. 2004. Ap-
plying Meaningful Word-Pairs on Syllabel-to-
Word Conversion Problem in Chinese, Pro-
ceedings of ROCLING XVI, Taiwan, 79-88. 
Tsai, J,L, C.L., Sung and W.L., Hsu. 2003. Chinese 
Word Auto-Confirmation Agent, Proceedings 
of ROCLING XV, Taiwan, 175-192. 
UDN, On-Line United Daily News, 
         ?http://udnnews.com/NEWS/? 
Appendix A.  
Input syllables ?ji2fu4qi2min2zu2te4se4? of the Chinese sentence 
???(abundance)?(it)??(folk)??(characteristic)? 
Tonal STW results 
Methods  STW results 
  ??/??(13)  (Key WP) 
  ??/??(11)  (Co-occurrence WP) 
WP-sentence ?? qi2???? 
MSIME  ??????? 
MSIME+WP ??????? 
BiGram  ??????? 
BiGram+WP ??????? 
Toneless STW results 
Methods  STW results 
  ??/??(13) (Key WP) 
  ??/??(11) (Co-occurrence WP) 
WP-sentence ?? qi???? 
MSIME  ??????? 
MSIME+WP ??????? 
BiGram  ??????? 
BiGram+WP ??????? 
60
Using Word-Pair Identifier to Improve Chinese Input System 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
 Taipei 222, Taiwan, R.O.C. 
tsaijl@mail.tnit.edu.tw
Abstract 
This paper presents a word-pair (WP) 
identifier that can be used to resolve 
homonym/segmentation ambiguities 
and perform syllable-to-word (STW) 
conversion effectively for improving 
Chinese input systems. The experi-
ment results show the following: (1) 
the WP identifier is able to achieve to-
nal (syllables with four tones) and 
toneless (syllables without four tones) 
STW accuracies of 98.5% and 90.7%, 
respectively, among the identified 
word-pairs; (2) while applying the WP 
identifier, together with the Microsoft 
input method editor 2003 and an opti-
mized bigram model, the tonal and 
toneless STW improvements of the 
two input systems are 27.5%/18.9% 
and 22.1%/18.8%, respectively. 
1 Introduction 
More than 100 Chinese input methods have been 
developed in the past (Becker 1985, Huang 1985, 
Gu et al 1991, Chung 1993, Kuo 1995, Fu et al
1996, Lee et al 1997, Hsu et al 1999, Chen et 
al. 2000, Tsai and Hsu 2002, Gao et al 2002, 
Lee 2003). Their underlying approaches can be 
classified into four types: (1) Optical character 
recognition (OCR) based (Chung 1993), (2) On-
line handwriting based (Lee et al 1997), (3) 
Speech based (Fu et al 1996, Chen et al 2000), 
and (4) Keyboard based consists of phonetic 
and pinyin based (Chang et al 1991, Hsu et al
1993, Hsu 1994, Hsu et al 1999, Kuo 1995, Lua 
and Gan 1992); arbitrary codes based [Fan et al
1988]; and structure scheme based (Huang 
1985). 
Currently, the most popular method for Chi-
nese input is phonetic and pinyin based, because 
Chinese people are taught to write the corre-
sponding phonetic and pinyin syllables of each 
Chinese character and word in primary school. 
In Chinese, each Chinese character corresponds 
to at least one syllable; and each Chinese word 
can be a mono-syllabic word, such as ??
(mouse)?, a bi-syllabic word, such as ???
(kangaroo)?, or a multi-syllabic word, such as 
????(Mickey mouse).? Although there are 
more than 13,000 distinct Chinese characters (of 
which 5,400 are commonly used), there are only 
about 1,300 distinct syllables. As per (Qiao et al
1984), each Chinese syllable can be mapped 
from 3 to over 100 Chinese characters, with the 
average number of characters per syllable being 
17. According to our computation, the minimum, 
maximum and average numbers f Chinese words 
per syllable-word in MOE-MANDARIN dic-
tionary ????????? (one of most com-
monly-used Chinese dictionaries published by 
the Ministry of Education in Taiwan, its online 
dictionary is at (MOE)) are 1, 22 and 1.5, re-
spectively. Since the size of problem space for 
syllable-to-word conversion is much less than 
that of syllable-to-character conversion, the 
most existing Chinese input systems (Hsu 1994, 
Hsu et al 1999, Tsai and Hsu 2002, Gao et al
2002, MSIME) are addressed on syllable-to-
word conversion, not syllable-to-character con-
version. To the research field of Chinese speech 
recognition, the STW conversion is the main 
task of Chinese language processing in typical 
Chinese speech recognition systems (Fu et al
1996, Lee et al 1993, Chien et al 1993, Su et al
1992). 
Conventionally, there are two approaches for 
syllable-to-word (STW) conversion: (1) the lin-
guistic approach based on syntax parsing, se-
9
mantic template matching and contextual infor-
mation (Hsu 1994, Fu et al 1996, Hsu et al
1999, Kuo 1995, Tsai and Hsu 2002); and (2) 
the statistical approach based on the n-gram 
models where n is usually 2 or 3 (Lin and Tsai 
1987, Gu et al 1991, Fu et al 1996, Ho et al
1997, Sproat 1990, Gao et al 2002, Lee 2003). 
Although the linguistic approach requires con-
siderable effort in designing effective syntax 
rules, semantic templates or contextual informa-
tion, it is more user-friendly than the statistical 
approach on understanding why such a system 
makes a mistake (Hsu 1994, Tsai and Hsu 2002). 
On the other hand, the statistical language model 
(SLM) used in the statistical approach requires 
less effort and has been widely adopted in com-
mercial Chinese input systems. 
According to previous studies (Chung 1993, 
Fong and Chung 1994, Tsai and Hsu 2002, Gao 
et al 2002, Lee 2003), homophone selection and 
syllable-word segmentation are two critical 
problems to the STW conversion in Chinese. 
Incorrect homophone selection and failed sylla-
ble-word segmentation will directly influence 
the STW conversion rate. For example, consider 
the syllable sequence ?yi1 du4 ji4 yu2 zhong1 
guo2 de5 niang4 jiu3 ji4 shu4? of the sentence 
???(once)??(covet)??(China)?(of)??
(making-wine)?? (technique).? As per the 
MOE-MANDARIN dictionary, the two possible 
syllable-word segmentations (in pinyin) are: 
(F)?yi1/du4ji4/yu2/zhong1guo2/de5/niang4ji
u3/ji4shu4?; and 
(B)?yi1/du4/ji4yu2/zhong1guo2/de5/niang4ji
u3/ji4shu4.? 
(We use the forward (F) and the backward (B) 
longest syllable-word first strategies (Chen et al
1986, Tsai and Hsu 2002), and ?/? to indicate a 
syllable-word boundary). 
Among the above syllable-word segmentations, 
there is an ambiguous syllable-word section: 
/du4ji4/yu2/ (/{??}/{?,?,?,?,?,?,?,?,
?,?,?,?,?,?,?,?,?,?,?,?,?,? ,
?}/); and /du4/ji4yu2/ (/{?,?,?,?,?,?,
?}/{?? ,??}/), respectively. For the am-
biguous syllable-word section, the set of word-
pairs comprised of two multi-syllabic Chinese 
words (including bi-syllabic words in the fol-
lowing) and their corresponding word-pair fre-
quencies found in the UDN2001 corpus are: {?
?-??(1), ??-??(1), ??-??(4), ??-
??(1), ??-??(1), ??-??(26), ??-?
?(19)}. The UDN2001 corpus (Tsai and Hsu 
2002) is a collection of 4,539,624 Chinese sen-
tences extracted from whole 2001 articles on the 
United Daily News Website (UDN) in Taiwan. 
For this case, if the word-pair ???(China)-?
?(technique)? with the maximum frequency 26 
is used to be the key word-pair, the set of co-
occurrence word-pairs with the key word-pair 
found in the UDN2001 will be {??-??, ?
?-??, ??-??, ??-??, ??-??}. 
Then, by the key word-pair ???-??? and its 
co-occurrence word-pair set {??-??, ??-
??, ??-??, ??-??, ??-??}, the 
mentioned ambiguous syllable-word section 
(/du4ji4/yu2/ and /du4/ji4yu2/) and the homo-
phone selection of syllable-word /ji4 shu4/ (/{?
?(technique),??(count)}/) of this case can be 
resolved, simultaneously. Thus, the Chinese 
words ??? (once)?, ??? (covet)?, ???
(China)? and ???(technique)? in the syllable 
sequence ?yi1 du4 ji4 yu2 zhong1 guo2 de5 
niang4 jiu3 ji4 shu4? can then be correctly iden-
tified. If we use the Microsoft Input Method 
Editor 2003 for Traditional Chinese (MSIME) to 
translate the syllables, it will be converted into 
???(once)? (continue)?(to)??(China)?
(of)??(making-wine)??(technique).? As per 
(Gao et al 2002), MSIME is a trigam-like Chi-
nese input system. The two error converted 
words ??(continue)? and ??(to)? are widely 
recognized that unseen event (??-??) and 
over-weighting (?-??) the two major prob-
lems of SLM systems (Fu et al 1996, Gao et al
2002). 
The objective of this study is to illustrate the 
effectiveness of word-pairs for resolving the 
STW conversion for improving the Chinese in-
put systems. We also conduct STW experiments 
to show the tonal and toneless STW accuracies 
of a commercial input product and a bigram 
model can be improved by our word-pair identi-
fier without a tuning process. Here, the ?tonal? 
is to indicate the syllables input with four tones, 
such as ?niang4(?) jiu3(?) ji4(?) shu4(?)?
and the ?toneless? is to indicate the syllables 
input without four tones, such as ?niang(? )
jiu(?) ji(?) shu(?).?  
10
The remainder of this paper is arranged as 
follows. In Section 2, we present a method for 
auto-generating word-pair (AUTO-WP) data-
base from Chinese sentences. Then, we develop 
a word-pair identifier with the WP database to 
effectively resolve homonym and segmentation 
ambiguities of STW conversion on the WP-
related portion in Chinese syllables. In Section 3, 
we present our STW experiment results. Finally, 
in Section 4, we give our conclusions and sug-
gest some future research directions. 
2 Development of Word-Pair Identifier 
The system dictionary of our word-pair identi-
fier is comprised of 155,746 Chinese words 
taken from the MOE-MANDARIN dictionary 
(MOE) and 29,408 unknown words auto-found 
in UDN2001 corpus by a Chinese word auto-
confirmation (CWAC) system (Tsai et al 2003). 
The system dictionary provides the knowledge 
of words and their corresponding pinyin sylla-
ble-words. The pinyin syllable-words were 
translated by phoneme-to-pinyin mappings, such 
as ?????-to-?ji4.?
2.1 Generating the Word-Pair Database 
The steps of our AUTO-WP to auto-discovery 
word-pairs from a given Chinese sentence are as 
below: 
Step 1. Segmentation: Generate the word 
segmentation for a given Chinese sen-
tence by backward maximum matching 
(BMM) techniques (Chen et al 1986) 
with the system dictionary. Take the Chi-
nese sentence ????????(bring 
the military component parts here)? as an 
example. Its BMM  word-segmentation is 
??(get)/??(military)/??(component 
parts)/ ? ? (bring)? and its forward 
maximum matching (FMM) word-
segmentation is ???(a general)/?(use)/ 
?? (component parts)/?? (bring).? 
According to our previous work (Tsai et 
al. 2004), the word segmentation preci-
sion of BMM is about 1% greater than 
that of FMM. 
Step 2. Initial WP set: Extract all the combi-
nations of word-pairs from the word 
segmentations of Step 1 to be the initial 
WP set. For the above case, there are six 
combinations of word-pairs extracted: 
{??/???, ??/???, ??/???, ??
?/???, ???/???, ???/???}. 
Step 3. Final WP set: Select out the word-
pairs comprised of two multi-syllabic 
Chinese words to be the finial WP set. 
For the final WP set, if the word-pair is 
not found in the WP database, insert it 
into the WP database and set its fre-
quency to 1; otherwise, increase its fre-
quency by 1. In the above case, the final 
WP set includes three word-pairs: {???
/???, ???/???, ???/???}.  
By applying our AUTO-WP to the UDN2001 
corpus (the training corpus), totally 25,439,679 
word-pairs were generated. From the generated 
WP database, the frequencies of word-pairs ??
?/???, ???/??? and ???/??? are 1, 
1 and 2, respectively. The frequency of a word-
pair is the number of sentences that contain the 
word-pair with the same word-pair order in the 
training corpus. 
2.2 Word-Pair Identifier 
The algorithm of our WP identifier for a given 
Chinese syllables is as follows: 
Step 1. Input tonal or toneless syllables. 
Step 2. Generate all possible word-pairs com-
prised of two multi-syllabic Chinese 
words for the input syllables to be the in-
put of Step 3. 
Step 3. Select out the word-pairs that match a 
word-pair in the WP database to be the 
initial WP set, firstly. Then, from the ini-
tial WP set, select the word-pair with 
maximum frequency as the key word-pair. 
Finally, find the co-occurrence word-
pairs with the key word-pair in the train-
ing corpus to be the final WP set. If there 
are two or more word-pairs with the same 
maximum frequency, one of them is ran-
domly selected as the key word-pair. 
Step 4. Arrange all word-pairs of the final WP 
set into a WP-sentence. If no word-pairs 
can be identified in the input syllables, a 
NULL WP-sentence is produced. 
11
Table 1 is a step by step example to show 
the details of applying our WP identifier on the 
Chinese syllables ?yi1 ge5 wen2 ming2 de5 
shuai1 wei2 guo4 cheng2( ? ? [a] ? ?
[civilization]?[of]??[decay]??[process]).?  
For this case, we have a WP-sentence ????
?  de5shuai1wei2 ?? .? As we have men-
tioned in Section 1, we found this WP-sentence 
can also be used to correct the MSIME con-
verted errors in its output ???[a]??[famous]
?[of]??[decay]??[process].? 
Table 1. An illustration of a WP-sentence generation 
for the Chinese syllables ?yi1 ge5 wen2 ming2 de5 
shuai1 wei2 guo4 cheng2(??[a]??[civilization]
?[of]??[decay]??[process])? 
Step # Results               
Step.1 yi1 ge5 wen2 ming2 de5 shuai1 wei2 guo4 cheng2 
 (??   ?      ?       ?   ?       ?     ?     ?)
Step.2 The found word-pair / word-pair frequency: 
??(yi1 ge5)-??(wen2 ming2) / 9 
??(yi1 ge5)-??(wen2 ming2) / 1 
??(yi1 ge5)-??(shuai1 wei2) / 0 
??(yi1 ge5)-??(guo4 cheng2) / 65 
??(wen2 ming2)- ??(shuai1 wei2) / 0 
??(wen2 ming2)-??(guo4 cheng2) / 3 
??(shuai1 wei2) -??(guo4 cheng2) / 0 
Step.3 The key word-pair: 
??(yi1 ge5)-??(wen2 ming2) 
The co-occurrence word-pairs: 
??(yi1 ge5)-??(wen2 ming2)  
??(wen2 ming2)-??(guo4 cheng2) 
Step.4 WP-sentence: 
???? de5 shuai1 wei2 ??
3 The STW Experiments 
To evaluate the STW performance of our WP 
identifier, we define the STW accuracy, identi-
fied character ratio (ICR) and STW improve-
ment, by the following equations: 
STW accuracy = # of correct characters / # of 
total characters.             (1) 
Identified character ratio (ICR) = # of characters 
of identified WP / # of total characters in testing 
sentences.                                (2) 
STW improvement (i.e. STW error reduction 
rate) = (accuracy of STW system with WP ? 
accuracy of STW system)) / (1 ? accuracy of 
STW system).                                    (3) 
3.1 Generation of the Word-Pair Database 
To conduct the STW experiments, firstly, use 
the inverse translator of phoneme-to-character 
(PTC) provided in GOING system to convert 
testing sentences into their corresponding sylla-
bles. Then, all the error PTC translations of 
GOING were corrected by post human-editing. 
Then, apply our WP identifier to convert these 
testing syllables back to their WP-sentences. 
Finally, calculate its STW accuracy and identi-
fied character ratio by Equations (1) and (2). 
Note that all test sentences are composed of a 
string of Chinese characters in this study. 
The training/testing corpus, closed/open test 
sets and the testing WP database used in the 
STW experiments are described as below: 
(1) Training corpus: We used the UDN2001 
corpus mentioned in Section 1 as our training 
corpus. All knowledge of word frequencies, 
word-pairs, word-pair frequencies was auto-
generated and computed by this corpus. 
(2) Testing corpus: The UDN2002 corpus was 
selected as our testing corpus. It is a collec-
tion of 3,321,504 Chinese sentences that were 
extracted from whole 2002 articles on the 
United Daily News Website (UDN).  
(3) Closed test set: 10,000 sentences were ran-
domly selected from the UDN2001 corpus as 
the closed test set. The {minimum, maximum, 
and mean} of characters per sentence for the 
closed test set were {4, 37, and 12}. 
(4) Open test set: 10,000 sentences were ran-
domly selected from the UDN2002 corpus as 
the open test set. At this point, we checked 
that the selected open test sentences were not 
in the closed test set as well. The {minimum, 
maximum, and mean} of characters per sen-
tence for the open test set were {4, 43, and 
13.7}. 
(5) Testing WP database: By applying our 
AUTO-WP on the UDN2001 corpus, we cre-
ated 25,439,679 word-pairs as the testing WP 
database. 
We conducted the STW experiment in a pro-
gressive manner. The results and analysis of the 
experiment are described in Sub-sections 3.2 
and 3.3. 
12
3.2 STW Experiment of the WP Identifier 
The purpose of this experiment is to demon-
strate the tonal and toneless STW accuracies 
among the identified word-pairs by using the 
WP identifier with the testing WP database. 
From Table 2, the average tonal and toneless 
STW accuracies of the WP identifier for the 
closed and open test sets are 98.5% and 90.7%, 
respectively. Between the closed and the open 
test sets, the differences of the tonal and tone-
less STW accuracies of the WP identifier are 
0.5% and 1.4%, respectively. These results 
strongly support that the WP identifier can be 
used to effectively perform Chinese STW con-
version on the WP-related portion. 
Table 2. The results of the tonal and toneless STW 
experiment for the WP identifier on the identified 
word-pairs 
 Closed Open Average (ICR)          
Tonal  98.7% 98.2% 98.5%   (47%) 
Toneless  91.4% 90.0% 90.7%   (39%) 
3.3 A Commercial IME System and A Bi-
gram Model with WP Identifier 
We selected Microsoft Input Method Editor 
2003 for Traditional Chinese (MSIME) as our 
experimental commercial Chinese input system. 
In addition, an optimized bigram model called 
BiGram was developed. The BiGram STW sys-
tem is a bigram-based model developing by 
SRILM (Stolcke 2002) with Good-Turing back-
off smoothing (Manning and Schuetze, 1999), 
as well as forward and backward longest sylla-
ble-word first strategies (Chen et al 1986, Tsai 
et al 2004). The training corpus and system 
dictionary of the BiGram system are same with 
that of the WP identifier. All the bigram prob-
abilities were calculated by the UDN2001 cor-
pus. 
Table 3a compares the results of MSIME 
and MSIME with the WP identifier on the 
closed and open test sentences. Table 3b com-
pares the results of BiGram and BiGram with 
the WP identifier on the closed and open test 
sentences. In this experiment, the STW output 
of the MSIME with the WP identifier, or the 
BiGram with the WP identifier, was collected 
by directly replacing the identified word-pairs 
(WP-sentences) from the corresponding STW 
output of MSIME or BiGram. 
Table 3a. The results of the tonal and toneless STW 
experiment for the MSIME and the MSIME with the 
WP identifier 
MSIME      MSIME+WP a     Improvement          
Tonal     94.9% 96.3%  27.5%  
Toneless    86.9% 89.8%  22.1%  
a STW accuracies of the words identified by the MSIME 
with the WP identifier 
Table 3b. The results of the tonal and toneless STW 
experiment for the BiGram and the BiGram with the 
WP identifier 
BiGram       BiGram+WP a       Improvement          
Tonal     96.3% 97.0%  18.9%  
Toneless    86.2% 88.8%  18.8%  
a STW accuracies of the words identified by the BiGram 
with the WP identifier
From Table 3a, the tonal and toneless STW 
improvements of MSIME by using the WP 
identifier are 27.5% and 22.1%, respectively. 
Meanwhile, from Table 3b, the tonal and tone-
less STW improvements of BiGram by using 
the WP identifier are 18.9% and 18.8%, respec-
tively. (Note that we also developed a TriGram 
STW system with the same source and tech-
niques of BiGram. However, the differences 
between the tonal and toneless STW accuracies 
of BiGram and TriGram are only about 0.2%) 
To sum up the results of this experiment, we 
conclude that the WP identifier can achieve a 
better STW accuracy than that of the MSIME 
and BiGram systems on the WP-related portion. 
The results of Tables 3a and 3b indicate that the 
WP identifier can effectively improve the tonal 
and toneless STW accuracies of MSIME and 
BiGram without tuning processing. Appendix A 
presents two cases of STW results that were 
obtained from the experiment. 
3.4 Error Analysis of the STW Conversion 
We examine the Top 300 cases in the tonal and 
toneless STW conversion errors, respectively, 
from the open testing results of BiGram with the 
WP identifier. As per our analysis, the problems 
of STW conversion errors can be classified into 
three major types: 
 (1) Unknown word problem: For any Chinese 
NLP system, unknown word extraction is 
one of the most difficult problems and a 
critical issue (Tsai et al 2003). When an er-
ror is caused only by the lack of words in 
the system dictionary, we call it unknown 
13
word problem.
(2) Inadequate syllable segmentation problem:
When an error is caused by syllable-word 
overlapping (or say ambiguous syllable-
word segmentation), instead of an unknown 
word problem, we call it inadequate sylla-
ble segmentation.
(3) Homophones problem: These are the re-
maining STW conversion errors. 
Table 4. The coverage of three problems caused the   
tonal and toneless STW conversion errors 
Problems                  Coverage (%)          
   Tonal  Toneless 
Unknown Word       12%   11% 
Inadequate Syllable 36%  51% 
Segmentation    
Homophone  53%  39% 
a STW accuracies of the words identified by the BiGram 
with the WP identifier
Table 4 is the coverage of the three problems. 
From Table 4, we have two observations:  
(1) The coverage of unknown word problem 
for tonal and toneless STW systems is 
similar. Since the unknown word problem 
is not specifically a STW problem, it can be 
easily taken care of through manual editing 
or semi-automatic learning during input. In 
practice, therefore, the tonal and toneless 
STW accuracies could be raised to 98% and 
91%, respectively. Although some of un-
known words have been incorporated in the 
system dictionary by a CWCA system (Tsai 
et al 2004), they could still face the prob-
lems: inadequate syllable segmentation and 
failed homophone disambiguation.
(2) The major problem caused error conver-
sions in tonal and toneless STW systems 
is different. To improve tonal STW sys-
tems, the major targets should be the cases 
of failed homophone selection (53% cover-
age). For toneless STW systems, on the 
other hand, the cases of inadequate syllable 
segmentation (51% coverage) should be the 
focus for improvement. 
To sum up the above two observations, the bot-
tlenecks of the STW conversion lie in the sec-
ond and third problems. To resolve these issues, 
we believe one simple and effective approach is 
to extend the size of WP database, because our 
experiment results show that the WP identifier 
can achieve better tonal and toneless STW accu-
racies than those of MSIME and BiGram on the 
WP-related portion. 
4 Conclusion and Future Directions 
In this paper, we have applied a WP identifier 
to support the Chinese language processing on 
the STW conversion and obtained a high STW 
accuracy on the identified word-pairs. All of the 
WP data can be generated fully automatically 
by applying the AUTO-WP on the system and 
user corpus. We are encouraged by the fact that 
WP knowledge can achieve tonal and toneless 
STW accuracies of 98.5% and 90.7%, respec-
tively, for the WP-related portion on the testing 
syllables. The WP identifier can be easily inte-
grated into existing Chinese input systems by 
identifying word-pairs in a post-processing step. 
Our experimental results show that, by applying 
the WP identifier together with MSIME (a tri-
gram-like model) and BiGram (an optimized 
bigram model), the tonal and toneless STW im-
provements of the two Chinese input systems 
are 27.5%/22.1% and 18.9%/18.8%, respec-
tively. For adaptation STW approach, we have 
tried to apply the AUTO-WP to extract the 
word-pairs from the 10,000 open testing sen-
tences into the testing WP database, the tonal 
and toneless STW accuracies of the MSIME 
with the adaptation WP identifier and the Bi-
Gram with the adaptation WP identifier will 
become 97.0%/97.2% and 91.1%/90.0%, re-
spectively. 
Currently, our approach is quite basic when 
more than one WP occurs in the same sentence. 
Although there is room for improvement, we 
believe it would not produce a noticeable effect 
as far as the STW accuracy is concerned. How-
ever, this issue will become important as we 
want to apply the WP knowledge to speech rec-
ognition. According to our computations, the 
collection of testing WP knowledge can cover 
approximately 50% and 40% of the characters 
in the UDN2001 and UDN2002 corpus, respec-
tively. 
We will continue to expand our collection of 
WP knowledge to cover more characters in the 
UDN2001 and UDN2002 corpus with Web 
corpus (search engine results) for improving our 
STW system. In other directions, we will try to 
improve our WP-based STW conversion with 
other statistical language models, such as HMM, 
14
and extend it to other areas of NLP, especially 
word segmentation and speech recognition. 
Acknowledgement 
We thank the Mandarin Promotion Council 
of the Ministry of Education in Taiwan for pro-
viding us the MOE-MANDARIN dictionary. 
References 
Becker, J.D. 1985. Typing Chinese, Japanese, and 
Korean, IEEE Computer 18(1):27-34. 
Chang, J.S., S.D. Chern and C.D. Chen. 1991. Con-
version of Phonemic-Input to Chinese Text 
Through Constraint Satisfaction, Proceedings 
of ICCPOL'91, 30-36. 
Chen, B., H.M. Wang and L.S. Lee. 2000. Retrieval 
of broadcast news speech in Mandarin Chinese 
collected in Taiwan using syllable-level statisti-
cal characteristics, Proceedings of the 2000 In-
ternational Conference on Acoustics Speech 
and Signal Processing.
Chen, C.G., Chen, K.J. and Lee, L.S. 1986. A model 
for Lexical Analysis and Parsing of Chinese 
Sentences, Proceedings of 1986 International 
Conference on Chinese Computing, 33-40. 
Chien, L.F., Chen, K.J. and Lee, L.S. 1993. A Best-
First Language Processing Model Integrating 
the Unification Grammar and Markov Lan-
guage Model for Speech Recognition Applica-
tions, IEEE Transactions on Speech and Audio 
Processing, 1(2):221-240. 
Chung, K.H. 1993. Conversion of Chinese Phonetic 
Symbols to Characters, M. Phil. thesis, De-
partment of Computer Science, Hong Kong 
University of Science and Technology. 
Fong, L.A. and K.H. Chung. 1994. Word Segmenta-
tion for Chinese Phonetic Symbols, Proceed-
ings of International Computer Symposium,
911-916. 
Fu, S.W.K, C.H. Lee and Orville L.C. 1996. A Sur-
vey on Chinese Speech Recognition, Communi-
cations of COLIPS, 6(1):1-17. 
Gao, J, Goodman, J., Li, M. and Lee K.F. 2002. To-
ward a Unified Approach to Statistical Lan-
guage Modeling for Chinese, ACM 
Transactions on Asian Language Information 
Processing, 1(1):3-33.
Gu, H.Y., C.Y. Tseng and L.S. Lee. 1991. Markov 
modeling of mandarin Chinese for decoding the 
phonetic sequence into Chinese characters, 
Computer Speech and Language 5(4):363-377. 
Ho, T.H., K.C. Yang, J.S. Lin and L.S. Lee. 1997. 
Integrating long-distance language modeling to 
phonetic-to-text conversion, Proceedings of 
ROCLING X International Conference on 
Computational Linguistics, 287-299. 
Hsu, W.L. and K.J. Chen. 1993. The Semantic Analy-
sis in GOING - An Intelligent Chinese Input 
System, Proceedings of the Second Joint Con-
ference of Computational Linguistics, Shiamen, 
1993, 338-343. 
Hsu, W.L. 1994. Chinese parsing in a phoneme-to-
character conversion system based on semantic 
pattern matching, Computer Processing of Chi-
nese and Oriental Languages 8(2):227-236. 
Hsu, W.L. and Chen, Y.S. 1999. On Phoneme-to-
Character Conversion Systems in Chinese 
Processing, Journal of Chinese Institute of 
Engineers, 5:573-579. 
Huang, J.K. 1985. The Input and Output of Chinese 
and Japanese Characters, IEEE Computer
18(1):18-24. 
Kuo, J.J. 1995. Phonetic-input-to-character conver-
sion system for Chinese using syntactic connec-
tion table and semantic distance, Computer 
Processing and Oriental Languages, 10(2):195-
210. 
Lee, L.S., Tseng, C.Y., Gu, H..Y., Liu F.H., Chang, 
C.H., Lin, Y.H., Lee, Y., Tu, S.L., Hsieh, S.H., 
and Chen C.H. 1993. Golden Mandarin (I) - A 
Real-Time Mandarin Speech Dictation Machine 
for Chinese Language with Very Large Vocabu-
lary, IEEE Transaction on Speech and Audio 
Processing, 1(2). 
Lee, C.W., Z. Chen and R.H. Cheng. 1997. A pertur-
bation technique for handling handwriting 
variations faced in stroke-based Chinese char-
acter classification, Computer Processing of 
Oriental Languages, 10(3):259-280. 
Lee, Y.S. 2003. Task adaptation in Stochastic Lan-
guage Model for Chinese Homophone Disam-
biguation, ACM Transactions on Asian 
Language Information Processing, 2(1):49-62. 
Lin, M.Y. and W.H. Tasi. 1987. Removing the ambi-
guity of phonetic Chinese input by the relaxa-
tion technique, Computer Processing and 
Oriental Languages, 3(1):1-24. 
Lua, K.T. and K.W. Gan. 1992. A Touch-Typing Pin-
yin Input System, Computer Processing of Chi-
nese and Oriental Languages, 6:85-94. 
Manning, C. D. and Schuetze, H. 1999. Fundations 
of Statistical Natural Language Processing,
MIT Press: 191-220. 
Microsoft Research Center in Beijing,  
?http://research.microsoft.com/aboutmsr/labs/be
ijing/? 
MOE, MOE-MANDARIN online dictionary,  
15
?http://140.111.34.46/dict/?open? 
UDN, On-Line United Daily News, 
?http://udnnews.com/NEWS/? 
Qiao, J., Y. Qiao and S. Qiao. 1984. Six-Digit Coding 
Method, Commun. ACM 33(5):248-267. 
Sproat, R. 1990. An Application of Statistical Opti-
mization with Dynamic Programming to Pho-
nemic-Input-to-Character Conversion for 
Chinese, Proceedings of ROCLING III, 379-
390. 
Stolcke A. 2002. SRILM - An Extensible Language 
Modeling Toolkit, Proc. Intl. Conf. Spoken 
Language Processing, Denver.
Su, K.Y., Chiang, T.H. and Lin, Y.C. 1992. A Uni-
fied Framework to Incorporate Speech and 
Language Information in Spoken Language 
Processing, ICASSP-92, 185-188. 
Tsai, J.L. and W.L. Hsu. 2002. Applying an NVEF 
Word-Pair Identifier to the Chinese Syllable-to-
Word Conversion Problem, Proceedings of 19th
COLING 2002, 1016-1022. 
Tsai, J,L, Sung, C.L. and Hsu, W.L. 2003. Chinese 
Word Auto-Confirmation Agent, Proceedings 
of ROCLING XV, 175-192.
Tsai, J.L, Hsieh, G. and Hsu, W.L. 2004. Auto-
Generation of NVEF knowledge in Chinese, 
Computational Linguistics and Chinese Lan-
guage Processing, 9(1):41-64. 
Appendix A. Two STW results used in 
this study (The frequencies and English 
words in parentheses are included for ex-
planatory purposes only) 
Case I. 
Tonal STW results for the Chinese tonal syllable input 
?ji2fu4qi2min2zu2te4se4? of the Chinese sentence ???
(abundance)?(it)??(folk)??(characteristic)? 
Methods  STW results 
??/??(13)  (Key WP) 
??/??(11)  (Co-occurrence WP) 
WP-sentence ?? qi2????
MSIME  ???????
MSIME+WP ???????
BiGram  ???????
BiGram+WP ???????
Toneless STW results for the Chinese toneless syllable 
input ?jifuqiminzutese? of the Chinese sentence ???
(abundance)?(it)??(folk)??(characteristic)? 
Methods  STW results 
??/??(13) (Key WP) 
??/??(11) (Co-occurrence WP) 
WP-sentence ?? qi????
MSIME  ???????
MSIME+WP ???????
BiGram  ???????
BiGram+WP ???????
Case II. 
Tonal STW results for the Chinese tonal syllable input 
?cong2qian2shui3diao4yu2chong1lang4yang2fan2chu1hai
3you2yong3? of the Chinese sentence ??(from)??(dive)
??(fishing)??(surfing)??(driving sail)??(outward 
bound)??(swim)? 
Methods  STW results 
??/??(2) (Key WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
WP-sentence  
       cong2???? chong1lang4??????
MSIME  ?????????????
MSIME+WP ?????????????
BiGram  ?????????????
BiGram+WP ?????????????
Tonal STW results for the Chinese tonal syllable input 
?congqianshuidiaoyuchonglangyangfanchuhaiyouyong? of 
the Chinese sentence ??(from)??(dive)??(fishing)?
? (surfing)??(driving sail)?? (outward bound)??
(swim)? 
Methods  STW results 
??/??(2) (Key WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
??/??(1) (Co-occurrence WP) 
WP-sentence  
       cong2???? chong1lang4??????
MSIME  ?????????????
MSIME+WP ?????????????
BiGram  ?????????????
BiGram+WP ?????????????
16
Report to BMM-based Chinese Word Segmentor with Context-based 
Unknown Word Identifier for the Second International Chinese Word 
Segmentation Bakeoff 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
 Taipei 222, Taiwan, R.O.C. 
tsaijl@mail.tnit.edu.tw
Abstract 
This paper describes a Chinese word 
segmentor (CWS) based on backward 
maximum matching (BMM) technique 
for the 2nd Chinese Word Segmenta-
tion Bakeoff in the Microsoft Research 
(MSR) closed testing track. Our CWS 
comprises of a context-based Chinese 
unknown word identifier (UWI). All 
the context-based knowledge for the 
UWI is fully automatically generated 
by the MSR training corpus. Accord-
ing to the scored results of the MSR 
closed testing track and our analysis, it 
shows that our BMM-based CWS with 
the context-based UWI is a simple and 
effective system to achieve high Chi-
nese word segmentation performance 
of more than 95.5% F-measure. 
1 Introduction 
In the research fields of Chinese natural lan-
guage processing (NLP), a high-performance 
Chinese word segmentor (CWS) is a useful pre-
processing stage to produce an intermediate re-
sult for later processes, such as search engines, 
text mining and speech recognition, etc. The 
bottleneck of developing a high-performance 
CWS is to comprise of a high-performance Chi-
nese UWI (Lin et al 1993; Tsai et al 2003). It is 
because Chinese is written without any separa-
tion between words and meanwhile more than 
50% words of the Chinese texts in web corpus 
are out-of-vocabulary (Tsai et al 2003). 
Conventionally, there are four approaches to 
develop a CWS: (1) Dictionary-based approach 
(Cheng et al 1999), especial forward and back-
ward maximum matching (Wong  and Chan, 
1996); (2) Linguistic approach based on syntax-
semantic knowledge (Chen et al 2002); (3) Sta-
tistical approach based on statistical language 
model (SLM) (Sproat and Shih, 1990; Teahan et 
al. 2000; Gao et al 2003); and (4) Hybrid ap-
proach trying to combine the benefits of diction-
ary-based, linguistic and statistical approaches 
(Tsai et al 2003; Ma and Chen, 2003). In prac-
tice, statistical approaches are most widely used 
because their effective and reasonable perform-
ance. For a CWS, there are two types of word 
segmentation ambiguities while there are no un-
known words in them: (1) Overlap ambiguity
(OA), take a character string ABC as an exam-
ple. If its segmentation can be either AB/C or 
A/BC depending on different context, the ABC 
is called an overlap ambiguity string (OAS), 
such as ???(a general)/?(use)? and ??(to 
get)/??(for military use)? (the symbol ?/? in-
dicates a word boundary); (2) Combination 
ambiguity (CA), take a character string AB as 
an example. If its segmentation can be either 
A/B or AB depending on different context, the 
AB is called a combination ambiguity string 
(CAS), such as ??(just)/?(can)? and ???
(ability).? Meantime, there are two types of error 
segmentation caused by unknown word problem: 
(1) Lack of unknown word (LUW), it means 
the error segmentation occurred by lack of an 
unknown word in the system dictionary, such as 
??/?/???; (2) Error identified word (EIW), 
it means the error segmentation occurred by an 
error identified unknown words, such as ???
142
?.? To sum up, for a CWS in most case the 
UWI is a pre-processing stage to detect un-
known words for the optimization of LUW-EIW 
tradeoff, and then to disambiguate those auto-
detected OAS and CAS problems from the seg-
mentation results. 
The goal of this paper is to illustrate and re-
port the effectiveness and the scored results of 
our BMM-based CWS for the second Interna-
tional Chinese Word Segmentation Bakeoff in 
the MSR closed (MSR_C) track. For this Bake-
off, our CWS is mainly addressed on optimizing 
the LUW-EIW tradeoff. 
The remainder of this paper is arranged as 
follows. In Section 2, we present the details of 
our BMM-based CWS comprised of a context-
based UWI. In Section 3, we present the scored 
results of the CWS in the MSR_C track and give 
our analysis. Finally, in Section 4, we give our 
conclusions and suggest some future research 
directions. 
2 Development of BMM-based CWS 
As per (Tsai et al 2004), the Chinese word seg-
mentation performance of BMM technique is 
about 1% greater than that of FMM technique. 
Thus, we adopt BMM technique as base to de-
velop our CWS. The descriptions of symbols 
used in our CWS are given as below: 
<BOS>: begin of sentence; 
<EOS>: end of sentence; 
<BOW>: begin of word; 
<EOW>: end of word; 
/: word boundary; 
+: inner word boundaries of the segmentation of 
a system word segmented by BMM tech-
nique with the system dictionary exclusive 
of this system word; 
SWS (stop word string): for a system word  
(such as ??(of)?), if the ratio (non-SWS 
probability) of total frequency of the other 
system words including it (such as ???
(beautiful)?) and its character string fre-
quency is less than or equal to 1%, it is a 
SWS; 
SWBS (stop word bigram string): for a word 
bigram (such as ??(just)/?(can)?), if the 
ratio (non-SWBS probability) of its charac-
ter string (such as ??? (ability)? fre-
quency and its character string frequency is 
less than or equal to 1%, it is a SWBS; 
BMM-ASM (BMM ambiguity string mapping 
table: the BMM-ASM table lists all the 
pairs of correct SS (given in training corpus) 
and the error BMM SS (generated by BMM 
with the training system dictionary). Take 
the Chinese sentence ?????? as an ex-
ample. As per its MSR-standard segmenta-
tion ???(effect)/?(really)/?(good)? and 
its BMM segmentation ?? (follow)/??
(indeed)/?(good),? the pair  ???/??-
??/??? is a BMM-ASM; 
TCT (triple context template): a TCT comprised 
of three items from left to right are: the left 
word, the segmented system word and the 
right word, where the system word is not a 
mono-syllabic Chinese word. Take the Chi-
nese sentence ???/?/?? as an example. 
The two generated TCT are: 
?<BOS>/?+1-char-word/??
 ?<BOS>/1-char-word+?/??; and 
WCT (word context template): a WCT com-
prised of three items from left to right are: 
?<BOW>?, the segmented system word and 
?<EOW>?, where the system word is not a 
mono-syllabic word. Take the system word 
????(lamasery)? as an example. Its two 
WCT are: 
 ?<BOW>/??+1-char-word/<EOW>? 
  ?<BOW>/2-char-word+?/<EOW>.? 
The algorithm of our BMM-based CWS com-
prised of a context-based UWI is as below: 
Step 1. Generate BMM segmentation for the 
input Chinese sentence with system dictionary, 
firstly. The system dictionary comprised of all 
word types found in the training corpus. Then, 
use BMM-ASM table to revise the matched 
BMM ambiguity string. 
Step 2. Use UWI to identify unknown words 
from the segmentation of Step 1 by the TCT 
knowledge, firstly. For the matched TCT, the 
characters between the left word and the right 
word will be combined as an UWI-identified 
word. If the UWI-identified word includes a 
SWS or a SWBS, it will be not an UWI-
identified word. Then, use the system diction-
ary of Step 1 inclusive of the UWI-identified 
words of this step to repeat Step 1 process. 
Step 3. Add tags ?<BOW>? and ?<EOW>? at 
143
the left-side and right-side of the continue 1-
char character segmentations of Step 2, firstly. 
Then, use UWI to identify unknown words by 
the WCT knowledge. If the number of charac-
ters between ?<BOW>? and ?EOW>? is same 
with that of the matched WCT, these 1-char 
characters will be combined as an UWI-
identified word. If the UWI-identified word 
includes a SWS or a SWBS, it will be not an 
UWI-identified word. Finally, use the system 
dictionary of Step 2 inclusive of those UWI-
identified words of this step to repeat Step 1 
process. 
Step 4. Use UWI to combine a word bigram 
into a word by the following two conditions: 
(1) if the non-SWS probability of the right 
first character of the left-side word is greater 
or equal to 99% and (2) if the non-SWS prob-
ability of the left first character of the right-
side word is greater or equal to 99%. Take the 
word bigram ???? /?? as an example. 
Since the non-SWS probability of the right 
first character ??? of the left-side word ??
??? is 99.95%, ?????? is identified as 
an UWI-identified word. If the UWI-identified 
word includes a SWS or a SWBS, it will be 
not an UWI-identified word. Finally, use the 
system dictionary of Step 3 inclusive of those 
UWI-identified words of this step to repeat the 
Step 1 process. 
Step 5. Repeat the Step 2 process. 
Step 6. Repeat the Step 3 process. 
Step 7. Repeat the Step 4 process. 
Step 8. Stop. 
In the above algorithm, Steps 2, 3 and 4 re-
peated at Steps 5, 6 and 7, respectively, are de-
signed to show the recursive effect of our CWS. 
3 The Scored Results and Analysis 
In the 2nd Chinese Word Segmentation Bakeoff, 
there are four training corpus: AS (Academia 
Sinica) and CU (City University of Hong Kong) 
are traditional Chinese corpus, PU (Peking Uni-
versity) and Microsoft Research (MSR) are sim-
plified Chinese corpus. Meanwhile, there are 
two testing tracks of this bakeoff: closed and 
open. We attend MSR_C track. The non-SWS 
and the non-SWBS probabilities of our CWS for 
this bakeoff are all set to 1%. And, the segmen-
tation results of each step of our CWS are col-
lected and scored, respectively. 
3.1 The Scored Results 
Table 1 shows the details of MSR training and 
testing corpus. Note that, in Table 1, the details 
of MSR testing corpus were computed by us 
according to the MSR gold testing corpus. From 
Table 1, it indicates that the MSR testing track 
seems to be a 25-folds experiment design. 
Table 1. The details of MSR_C corpus 
  Training  Testing 
Sentences 86,924  3,985 
Word types 88,119  12,924 
Words  2,368,391 109,002 
Character types 5,167  2,839 
Characters 4,050,469 184,356
Table 2 shows the scored results of our CWS 
in MSR_C track. The performance of ?Step 
1(P)? in Table 2 was computed by us and the 
others were from the scored results. It shows a 
very high performance of 99.1% F-measure can 
be achieved while the BMM-based CWS by us-
ing a system dictionary comprised of word types 
found in the MSR training and testing corpus at 
Step 1 (?P? means ?Perfect?). 
Table 2. The performance of each step of our CWS 
in the MSR-C track (OOV is 0.026) 
Step R P F ROOV RIV
1(P) 0.993 0.989 0.991 - - 
1 0.963  0.924  0.943  0.025  0.989 
2 0.964  0.924  0.944 0.025 0.989 
3 0.968  0.938  0.953  0.205  0.989 
4 0.958  0.949  0.954  0.465  0.972 
5 0.958 0.951 0.954 0.493 0.971 
6 0.958  0.952  0.955  0.503  0.970 
7 0.958  0.952  0.955  0.504  0.970 
3.2 The Analysis 
Table 3 (see next page) shows the differences of 
F-measure and ROOV between each near-by step 
of our CWS. From Table 3, it indicates that the 
most contribution for increasing the overall per-
formance (F-measure) of our CWS is at Step 3, 
which uses WCT knowledge. 
Table 4 (see next page) shows the distribu-
tions of four segmentation error types (OAS, 
CAS, LUW and EIW) for each step of our CWS. 
From Table 4, it shows that our context-based 
UWI with the knowledge of TCT and WCT can 
144
effectively to optimize the LUW-EIW tradeoff. 
Moreover, from Table 4, it also shows that the 
knowledge of SWS, SWBS and BMM-ASM can 
effectively to resolve the CAS errors. 
Table 3. The differences of F-measure and ROOV
between near-by steps of our CWS 
Step F F(d) ROOV ROOV(d)
1 0.943  - 0.025  - 
2 0.944 0.001 0.025 0 
3 0.953  0.011 0.205  0.18 
4 0.954  0.001 0.465  0.26 
5 0.954 0 0.493 0.028 
6 0.955  0.001 0.503  0.01 
7 0.955 0 0.504 0.001 
Table 4. The number of OAS (types), CAS (types), 
LUW (types) and EIW (types) for each step of our 
CWS 
     OAS            CAS          LUW              EIW 
1   210(194)     233(80)     2702(1930)    157(96) 
2   184(173)     233(80)     2698(1927)    157(96) 
3   185(174)     232(80)     2169(1473)    187(126) 
4   250(226)     226(77)     1373(1090)    946(609) 
5   250(226)     226(77)     1283(1018)    991(658) 
6   251(227)     224(77)     1255(1001)    1005(669) 
7   262(216)     224(76)     1260(1005)    1007(668) 
4 Conclusions and Future Directions 
In this paper, we have applied a BMM-based 
CWS comprised of a context-based UWI to the 
Chinese word segmentation and obtained a high 
performance of 95.5% F-measure in the MSR 
closed track. To sum up the results of this study, 
we have following conclusions and future direc-
tions: 
(1)Since the F-measure of Step 1 of our CWS is 
94.3%, it indicates that the BMM with BMM-
ASM knowledge is a simple but probably ef-
fective technique as a good base in developing 
a high performance CWS; 
(2)Since 82% of segmentation errors of our 
CWS caused by LUW problem, this result 
supports that a high performance CWS is re-
lied on a high performance Chinese UWI. 
(3)For a CWS, there are two critical and proba-
bly independent tasks: the optimization of 
LUW-EIW tradeoff and the detection and dis-
ambiguation of OAS and CAS error segmen-
tation. We believe the former task is more 
critical than the later one. 
(4)We will continue to expand our CWS with 
other linguistic knowledge (such as part-of-
speech information and morphology) and 
BTM model (Tsai 2005) to improve our 
BMM-based CWS for attending the third In-
ternational Chinese Word Segmentation 
Bakeoff in both closed and open testing tracks. 
References 
Chen, Keh-Jiann and Wei-Yun, Ma. 2002. Unknown 
Word Extraction for Chinese Documents, Pro-
ceedings of 19th COLING 2002, Taipei, 169-
175. 
Cheng, Kowk-Shing, Gilbert H. Yong and Kam-Fai 
Wong.. 1999. A study on word-based and in-
tegral-bit Chinese text compression algorithms. 
JASIS, 50(3): 218-228. 
Gao, Jianfeng, Mu Li and Chang-Ning uang. 2003. 
Improved Source-Channel Models for Chinese 
Word Segmentation. Proceedings of the 41st 
Annual Meeting of the Association for Compu-
tational Linguistics, 272-279. 
Lin, Ming-Yu, Tung-Hui Chiang and Keh-Yi Su. 
1993. A preliminary study on unknown word 
problem in Chinese word segmentation. 
ROCLING 6, 119-141. 
Ma, Wei-Yun and Keh-Jiann Chen, 2003, "Introduc-
tion to CKIP Chinese Word Segmentation 
System for the First International Chinese 
Word Segmentation Bakeoff", Proceedings of 
ACL, Second SIGHAN Workshop on Chinese 
Language Processing, pp168-171. 
Sproat, R. and C., Shih. 1990. A Statistical Method 
for Finding Word Boundaries in Chinese Text. 
Computer proceeding of Chinese and Oriental 
Language, 4(4):336 349. 
Teahan, W. J., Yingying Wen, Rodger McNad and 
Ian Witten. 2000. A compression-based algo-
rithm for Chinese word segmentation. Compu-
tational Linguistics, 26(3): 375-393. 
Tsai, Jia-Lin, C.L., Sung and W.L., Hsu. 2003. Chi-
nese Word Auto-Confirmation Agent, Pro-
ceedings of ROCLING XV, Taiwan, 175-192. 
Tsai, Jia-Lin, G., Hsieh and W.L., Hsu. 2004. Auto-
Generation of NVEF knowledge in Chinese, 
Computational Linguistics and Chinese Lan-
guage Processing, 9(1):41-64. 
Tsai, Jia-Lin. 2005. A Study of Applying BTM 
Model on the Chinese Chunk Bracketing. Pro-
ceedings of IJCNLP, 6th International Work-
shop on Linguistically Interpreted Corpora, 
Jeju Island. 
Wong, Pak-Kwong and Chorkin ChanWong. 1996. 
Chinese Word Segmentation. based on Maxi-
mum Matching and Word Binding Force. Pro-
ceedings of the 16th International conference 
on Computational linguistic, 1:200-203. 
145
A Study of Applying BTM Model on the Chinese Chunk Bracketing 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
 Taipei 222, Taiwan, R.O.C. 
tsaijl@mail.tnit.edu.tw
Abstract 
The purpose of this paper is to auto-
matically generate Chinese chunk 
bracketing by a bottom-to-top map-
ping (BTM) model with a BTM data-
set. The BTM model is designed as a 
supporting model with parsers. We de-
fine a word-layer matrix to generate 
the BTM dataset from Chinese Tree-
bank. Our model matches auto-learned 
patterns and templates against seg-
mented and POS-tagged Chinese sen-
tences. A sentence that can be matched 
with some patterns or templates is 
called a matching sentence. The ex-
perimental results have shown that the 
chunk bracketing of the BTM model 
on the matching sentences is high and 
stable. By applying the BTM model to 
the matching sentences and the N-
gram model to the non-matching sen-
tences, the experiment results show 
the F-measure of an N-gram model 
can be improved. 
1 Introduction 
The definition of chunk, which has been repre-
sented as groups of words between square 
brackets, was first raised by (Abney, 1991). A 
chunker is to divide sentences into non-
overlapping phrases by starting with finding cor-
related chunks of words. Text chunking has been 
shown a useful pre-processing step for language 
parsing (Sang and Buchholz, 2000). Among the 
chunk types, NP chunking is the first to receive 
the attention (Ramshaw and Marcus, 1995), than 
other chunk types, such as VP and PP chunking 
(Veenstra, 1999). For English (Sang and 
Buchholz, 2000) and Chinese (Li et al, 2004) 
languages, the top 3 most frequent chunk types 
are NP, VP and PP chunks. Meanwhile, the three 
chunk types cover about 80% of chunking prob-
lems. In many natural language processing (NLP) 
applications, such as information retrieval, 
knowledge discovery, example-based machine 
translation (EBMT) and text summarization, can 
benefit with chunks (Le et al, 2003; Munoz et 
al., 1999; Oliver, 2001; Zhou and Su, 2003). 
As per the reports (Menzel, 1995; Sang and 
Buchholz, 2000; Basili and Zanzotto, 2002;
Knutsson et al, 2003; Li et al, 2004; Xu et al, 
2004; Johnny et al, 2005), there are three im-
portant trends in the study of Chinese text 
chunking and parsing. These important trends 
are: (1) Treebank-Derived Approaches for auto-
constructing useful patterns and templates from 
Treebank (TB) as rules combined with statistical 
language models (SLM), such as N-gram mod-
els and support vector machines (SVMs), etc.; (2) 
Robust Chunkers against Treebank sparseness 
and perfect/actual input. Here the perfect input
means the word-segmentation and Part-of-
Speech (POS) tags all are correct. The actual 
input means the word-segmentation and POS 
tags all are generated by a selected segmenter 
and a POS tagger; and (3) High Performance 
Chunk Bracketing has been reported that the 
key issue of Chinese parsing (Li et al, 2004). To 
sum up these trends, one of critical issues for 
developing a high performance Chinese chunker 
is to find methods to achieve high performance 
of chunk bracketing against training size, perfect 
and actual input. 
Following these trends of Chinese chunking 
and parsing, the goals of this paper are: 
(1) Define a Word-Layer Matrix and generate 
the Bottom-to-Top Mapping (BTM) dataset 
to auto-derive useful patterns and templates 
with probabilities from Chinese Treebank 
21
(CTB) as rules for chunking; 
(2) Develop a BTM model with the BTM data-
set to identify the chunks (i.e. phrase bounda-
ries) for a given segmented and POS-tagged 
Chinese sentence; 
(3) Show the chunk bracketing performance of 
the BTM model is high and stable against 
training corpus size, perfect and actual input; 
(4) Show the BTM model can improve the per-
formance (F-measure) of N-gram models on 
chunk bracketing. 
The remainder of this paper is arranged as 
follows. In Section 2, we present the BTM 
model for identifying chunks for each seg-
mented and POS-tagged Chinese sentence. Ex-
perimental results and analyses of the BTM 
model are presented in Section 3. Finally, in 
Section 4, we present our conclusions and dis-
cuss the direction of future research. 
2 Development of the BTM model 
2.1 Introduction of Chinese Treebank 
A Chinese Treebank (CTB) is a segmented, 
POS-tagged and fully bracketed Chinese corpus 
with morphological, syntactic, semantic and dis-
course structures. The CKIP (Chinese Knowl-
edge Information Processing) Chinese-Treebank 
(CCTB) and the Penn Chinese Treebank (PCTB) 
are two of most important Chinese Treebank 
resources for Treebank-derived NLP tasks in 
Chinese (CKIP, 1995; Xia et al, 2000; Xu et al, 
2000; Li et al, 2004). The brief introductions of 
the CCTB and the PCTB are given as below 
(Table 1 is a brief comparison between the 
CCTB and the PCTB): 
(1) CCTB: the CCTB is developed in traditional 
Chinese texts (BIG5 encoded) taken from the 
Academia Sinica Balanced Corpus 3.0 (ASBC3) 
at the Academia Sinica, Taiwan (Chen et al, 
1996; Chen et al, 1999; Huang et al, 2000, 
Chen et al, 2003; Chen et al, 2004). The CCTB 
uses Information-based Case Grammar (ICG) as 
the language framework to express both syntac-
tic and semantic descriptions (Chen and Huang, 
1996). The structural frame of CCTB is based 
on the Head-Driven Principle: it means a sen-
tence or phrase is composed of a core Head and 
its arguments, or adjuncts (Chen and Hsieh,
2004). The Head defines its phrasal category 
and relations with other constituents.  The pre-
sent version CCTB2.1 (CCTB Version 2.1) in-
cludes 54,902 sentences (i.e. trees) and 290,144 
words that are bracketed and post-edited by hu-
mans, based on the computer parsed results 
(CKIP, 1995). There are 1,000 CCTB trees open 
to the public for researchers to download on the 
CCTB portal. The details of supplementary 
principles, symbol illustrations, semantic roles, 
phrasal structures and applications of the CCTB 
can be found in (CCTB portal; Chen et al, 2003; 
Chen and Hsieh, 2004; You and Chen, 2004). 
Table 1. A brief comparison between CCTB2.1 and 
PCTB4 (The number in () is the word frequency and 
the English word in [] is the English Translation for 
the corresponding Chinese word) 
   CCTB2.1         PCTB4 
Developer  CKIP          UPenn 
Content type  Balanced          Newswire 
   corpus          sources 
Language framework ICG          HPSG 
Word standard  Taiwan          China 
   (CKIP, 1996)        (Liu et al,1993)
POS-tagging system type hierarchical    non- 
   (5 layer)          hierarchical
Structure frame  Head-driven     Head-driven 
Code   BIG5          GB 
No. of sentences  54,902          15,162 
No. of distinct POS tags 302          47 
No. of words in CTB 290,144          404,156 
Top 3 one-char words ?(19,212)       ?(15,080) 
    [of]          [of]  
   ?(4,608)         ?(4,055) 
   [is/are]          [at] 
   ?(4,235)         ?(2,965) 
   [at]          [is/are] 
Top 3 two-char words ??(1,057)     ??(2,097) 
   [we]          [China] 
   ??(675)        ??(1,015) 
                                     [a/an/one]         [Economy] 
   ??(564)        ??(989) 
   [they]          [business] 
(2) PCTB: the PCTB is developed in simplified 
Chinese texts (GB encoded) taken from the 
newswire sources (consists of Xinhua newswire, 
Hong Kong news and Sinorama news magazine, 
Taiwan) at the Department of Computer and 
Information Science, University of Pennsylvania 
(UPenn). The PCTB uses Head-driven Phrase 
Structure Grammar (HPSG) to create Chinese 
texts with syntactic bracketing (Xia et al 2000; 
Xue et al 2002). Meanwhile, the semantic anno-
tation of PCTB mainly deals with the predicate-
argument structure of Chinese verbs in Penn 
Chinese Proposition Bank (Xue and Palmer, 2003; 
22
Xue and Palmer, 2005). The present version 
PCTB5 (PCTB Version 5), contains 18,782 sen-
tences, 507,222 words, 824,983 Hanzi and 890 
data files. The PCTB was created by two pass 
approach. The first pass was done by one anno-
tator, and the resulting files were checked by a 
second annotator (the second pass). The details 
and applications of PCTB can be found in 
(PCTB portal; Xia et al 2000; Chiou et al 2001; 
Xue et al 2002; Xue et al 2005). 
Overall, from Table 1, the four major differ-
ences between the CCTB and the PCTB are con-
tent type, language framework, word standard 
and POS-tagging system type. The CCTB is 
natural to be a balanced CTB because its content 
is taken from the Academia Sinica Balanced 
Corpus (CKIP, 1995). On the other hand, since 
the content type of PCTB is newswire sources, it 
is natural to be a newswire-based CTB and not a 
balanced CTB. 
2.2 Generating the BTM Dataset 
Firstly, we use CCTB2.1 as an example to de-
scribe how to generate a BTM dataset from the 
CCTB with the word-layer matrix. Then, we 
define two types of conditional probabilities 
used in this study for constructing the BTM 
model. Finally, the algorithm of our BTM model 
is given in Section 2.3. 
Figure 1. The tree structure of CCTB2.1 for the Chinese 
sentence ???(movie)?(of)??(picture)??
(colorful)??(interesting)? (Note that the content of 
the nodes between the root and the words is [The-
matic role : Syntactic category]) 
(1) Generation of BTM dataset from CCTB2.1:
Figure 1 shows the tree structure of CCTB2.1 
for the Chinese sentence ???(movie)?(of)?
? (picture)?? (colorful)?? (interesting).? 
The content of the nodes between the root layer 
and the words layer (leaves) is comprised of the-
matic roles and syntactic categories. The the-
matic roles can be annotated as a Theme,
Property, etc., while the syntactic categories 
can be annotated as a POS-tag (such as Nac) or 
a phrasal category (such as NP). The details of 
CCTB syntactic and thematic annotations can be 
found in (Chen et al, 2003). 
Table 2. The word-layer matrix extracted from 
CCTB2.1 for the Chinese sentence ???(movie)?
(of)??(picture)??(colorful)??(interesting)? 
Word
1st layer 
(Top) 
2nd layer 
3rd layer 
(Bottom) 
?? Head:Nac 
? Property:NP.? Head:DE 
??
Theme:NP 
Head:Nac Head:Nac 
?? Head:H11 
?? Head:VH11 Head:VH11 Head:H11 
Table 3. The BTM dataset for the CCTB2.1 tree of 
the Chinese sentence ??? (movie)? (of)??
(picture)??(colorful)??(interesting)? 
Type  Content 
BL Word pattern <??\?\??\??\??>                           
TL Word pattern   <??:?:??+??:??>
BL POS pattern <Nac\DE\Nac\VH11\VH11> 
TL POS pattern <Nac:DE:Nac+VH11:VH11> 
TL POS template  <Na%Na+VH11:VH11> 
PC pattern <NP+VH11> 
For each tree structure of CCTB2.1 (as 
shown in Fig.1), we first translate it into a word-
layer matrix as shown in Table 2. In a word-
layer matrix, the left, first row is the word layer 
(with words) and the other rows are the first 
layer to the last layer (with thematic roles and 
syntactic categories). For each word-layer ma-
trix, the first layer and last layer are called the 
Top Layer (TL) and the Bottom Layer (BL), 
respectively. According to the TL and the BL of 
a word-layer matrix (see Table 2), we can trans-
late a CCTB tree into a BTM dataset as shown 
in Table 3. Each BTM dataset includes two 
types of BTM content. One is the BL and TL 
word patterns expressed by Chinese words. The 
other one is the BL and TL POS patterns ex-
pressed by POS tags. Furthermore, for each TL 
23
POS pattern, we also generate its corresponding 
TL POS template (with POS tags) and phrasal 
category (PC) pattern (with POS tags and 
phrasal categories). 
In the Table 3: 
BL stands for the bottom layer (the last layer of 
a word-layer matrix); 
TL stands for the top layer (the first layer of a 
word-layer matrix); 
PC stands for the phrasal category in a TL;  
?\? indicates the word boundary in a BL; 
?+? indicates word/phrase boundaries in a TL; 
?:? indicates next to; for example, 
 ?Nac:DE? means ?Nac? next to ?DE?; 
?%? indicates near by; for example,  
 ?Nac%Nac? means ?Nac?near by ?Nac?; 
?<? indicates the begin of a sentence; and 
?>? indicates the end of a sentence. 
The CKIP POS tagging is a hierarchical system. 
The first layer of CKIP POS tagging include 
eight main syntactic categories, i.e. N (noun), V 
(verb), D (adverb), A (adjective), C (conjunc-
tion), I (interjection), T (particles) and P (prepo-
sition). As per the CKIP technical reports (CKIP, 
1995; CKIP, 1996), the maximum layer number 
of CKIP POS tagging is 5. Take the CKIP POS 
tag ?Ndabe? as an example, we define its POS 
tags with POS layer numbers 1, 2, 3, 4 and 5 as 
?N?, ?Nd?, ?Nda?, ?Ndab? and ?Ndabe?, re-
spectively. Thus, if the POS layer of BTM 
model is set to 2 (called 2 POS-layer mode), the 
BL POS pattern ?<Nac\DE\Nac\VH11\VH11>? 
in Table 3 will become ?<Na\DE\Na\VH\VH>?, 
and so forth. 
Table 4. The BTM dataset for the PCTB4 tree of the 
Chinese sentence ??? (both)?? (major)??
(agent)??(appear)? 
Type   Content           
BL Word pattern  <??\??\??\??>                           
TL Word pattern     <??:??:??+??>
BL POS pattern       <PN\JJ\NN\VV>                       
TL POS pattern  <PN:JJ:NN+VV> 
TL POS template    <PN%NN+VV> 
PC pattern  <NP-SBJ+VP> 
By the word-layer matrix, the BTM dataset of   
PCTB can also be generated. Table 4 shows an 
example BTM dataset for the PCTB4 tree of the 
Chinese sentence ???(both)??(major)??
(agent)??(appear).? Since the POS tagging of 
PCTB is not a hierarchical system, there is no 
POS layer mode can be set to the BTM dataset 
of PCTB. 
 (2) Definitions of Two Types of Probabilities:
In this study, two conditional probabilities were 
used in the BTM model. The Type I conditional 
probability is used to perform full TL POS pat-
tern matching. The Type II conditional prob-
ability is used to perform full TL POS template 
matching. Details of these probabilities are 
given below. 
Type I. Pr(a given TL POS pattern | the BL POS 
pattern of the given TL POS pattern) = 
(# of the given TL POS pattern found in the 
training BTM dataset) /  
(# of the BL POS patterns of the given TL POS 
pattern found in the training BTM dataset). 
Take the BL POS pattern ?Cb\Nc\DE\Na? as an 
example. There are: 
one TL POS pattern ?Cb+Nc:DE:Na? 
four TL POS pattern ?Cb+Nc:DE+Na? and 
five BL POS pattern ?Cb\Nc\DE\Na? in the 
CCTB2.1 BTM dataset. Thus, 
the Pr(Cb+Nc:DE:Na|Cb+Nc+DE+Na) =  1/5 = 
0.2; and 
the Pr(Cb+Nc:DE+Na|Cb+Nc+DE+Na) =  4/5 = 
0.8. 
Table 5a. Top 5 most frequent TL POS patterns 
whose number of POS tags is 5 for 2 POS-layer mo-
de (training size is 45,000 CCTB2.1 trees) 
TL POS pattern (Type I  pro.) 
V_+DM:VH:DE:Na (19/19 = 100%) 
 (Eg. ? [is]+?? [a]:?? [small]:? [of]:??
[village]) 
Nb:A:Na:Nb+VE (11/11 = 100%) 
(Eg. ?? [taiyuan]:?? [inference reader]:??
[manager]:???[gao-zi-neng]+??[point out]) 
Nc:Nb+VH+Nc:Nb  (10/10 = 100%) 
(Eg. ??[Philadelphia]:????[76-people team]+
?[win]+???[Washington]:???[bullet team])) 
VC+Di+Na:DE:Na (9/9 = 100%) 
(Eg. ? [attach]+? [to]+?? :? :?? [bridge of 
friendship]) 
Nh+VA+P2:Na:Nc (8/8 = 100%) 
(Eg. ??[they]+?[sit]+?:???:?[at the aero-
space plane]) 
24
Table 5a gives the Top 5 most frequent TL 
POS patterns whose number of POS tags is 5 
while the POS layer number is 2. 
Type II. Pr(matching patterns | a given TL POS 
template) = 
 (# of matching TL POS patterns of the given 
TL POS template found in the training BTM 
dataset) / (# of matching BL POS pattern of the 
given TL POS template found in the training 
BTM dataset).  
Take the TL POS template ?P3%Na+VA? as an 
example. In the CCTB2.1 BTM dataset, there 
are four matching BL POS patterns and two 
matching TL POS pattern for the template 
?P3%Na+VA?, namely: (Note that ?%? means 
?near by?) 
?P3\Dd\VA\DE\Na\VA? 
?P3:Dd:VA:DE:Na+VA?(matching) 
?P3\Na\P2\VC\Nb\Nc\DE\Na\VA? 
?P3:Na+P2:VC:Nb:Nc:DE:Na+VA?(no matching) 
?P3\Na\VA? 
?P3:Na+VA?(matching) 
?P3\Na\VC\Na\VA? 
?P3:Na+VC+Na+VA?(no matching) 
Thus, the Pr(matching pattern|P3%Na+VA) = 
2/4 = 0.5. 
Table 5b gives 5 randomly selected TL POS 
templates where their POS number is 5 while 
the POS layer number is 2. 
Table 5b. Five randomly selected TL POS templates 
where their POS number is 5 for 2 POS-layer mode 
(training size = 45,000) 
TL POS template  | Type II  pro. 
Na+VF+Nh+VA%Na  | 100% (1/1) 
P1%Nc+VC+Nc%Na  |   50% (1/2) 
Ne+Dd+V_+VH%Na  | 100% (3/3) 
DM%Na+VE+Nc%Na   | 100% (1/1) 
DM%Na+VK+VC%Na     | 100% (1/1) 
2.3 Algorithm of the BTM Model 
Following is the algorithm of our BTM model 
uses Types I (full TL POS pattern matching) and 
Type II (full TL POS template matching) condi-
tional probabilities to determine the chunks for a 
given segmented and POS-tagged Chinese sen-
tence. We use BTM (value1, value2, value3) to 
express the function of our BTM model, where 
value1 is the BTM threshold value, value2 is the 
POS layer number and value3 is the BTM train-
ing size. Table 6 is a step by step example to 
demonstrate the detailed processes and outputs 
of our BTM model. 
Table 6. A step by step example of the application of 
BTM (0.5; 2; 45,000) for the given BL POS pattern 
?Na\Na\DE\Nb(??[boy]\??[age]\?[of]\???
[schweitzer])? 
Step    Output 
1 Na\Na\DE\Nb                                                      
 (??[boy]\??[age]\?[of]\???[schweitzer]) 
2       NULL; Goto Step 4 
3       - 
4       Pr(Na%DE+Nb) = 66.7% (Type II);  and use 
the selected TL POS template ?Na%De+Nb? to 
translate ?Na\Na\DE\Nb? into ?Na:Na:DE+Nb? 
5 TL POS pattern = Na:Na:DE+Nb, and                                                   
 Matching sentence = ??:??:?+???
 Chunks =  ??????? and ?????
Step 1. Give the value1 (BTM threshold value), 
value2 (POS layer number) and value3
(training size), as well as the segmented 
and POS-tagged sentence. In the follow-
ing steps, the POS tagging sequence of 
the given sentence is called the BL POS 
pattern, such as the ?Na\Na\DE\Nb? in 
Table 6. 
Step 2. According to the BL POS pattern in Step 
1, find all matched TL POS patterns 
whose corresponding Type I probabili-
ties are greater than or equal to the BTM 
threshold value. If the number of 
matched TL POS patterns is zero, then 
go to Step 4. 
Step 3. Using the matched TL POS patterns 
from Step 2, select the TL POS pattern 
that has the maximum Type I probabil-
ity as the output. If there are two or 
more TL POS patterns with the same 
maximum Type I probability, randomly 
select one as the output. Go to Step 5. 
Step 4. According to the BL POS pattern, find 
all matched TL POS templates whose 
corresponding Type II probabilities are 
greater than or equal to the BTM thresh-
old value. Select the TL POS template 
that has the maximum Type II probabil-
25
ity to generate the output (see Table 6, 
Step 4). If there are two or more TL 
POS templates with the same maximum 
Type II probability, randomly select 
one to generate the output. If the number 
of matched TL POS patterns is zero, 
then a NULL output will be given. 
Step 5. Stop. If a NULL TL POS pattern output 
is given, this input sentence is a non-
matching sentence. Otherwise, it is a 
matching sentence.
3 Experiment Results 
To conduct the following experiments in ten-
folds, we randomly select 50,000 trees of 
CCTB2.1 and separate them into the following 
two sets: 
(1) Training Set consists of 45,000 CCTB2.1 
trees; and 
(2) Open Testing Set consists of the other 5,000 
CCTB2.1 trees. 
In our computation, 66% of CCTB2.1 BL POS 
patterns in the open testing set are not found in 
the training set. This means the ratio of unseen 
CCTB2.1 BL POS patterns in the open testing 
set is 66%. The PCTB4 BTM dataset was not 
used in this study by two reasons: the first one is 
that the PCTB is not a balanced CTB; the sec-
ond one is that the POS tagging system of PCTB 
is not a hierarchical system. 
We conducted four experiments in this study. 
The first three experiments are designed to show 
the relationships between the chunk bracketing 
performance of the BTM model on the matching 
sentences and the three BTM parameters: POS 
layer number; BTM threshold value; and BTM 
training size. To avoid the error propagation of 
word segmentation and POS tagging, the first 
three experiments only consider open testing 
sentences with correct word segmentations and 
POS tags provided in CCTB2.1 as perfect input.
The fourth experiment is to show the BTM 
model is able to improve the performance (F-
measure) of N-gram models on Chinese chunk 
bracketing for both perfect input and actual in-
put. Here, the actual input means the word 
segmentations and POS tags of the testing sen-
tences were all generated by a forward maxi-
mum matching (FMM) segmenter and a bigram-
based POS tagger, respectively. 
To evaluate the performance of our BTM 
model, we use recall (R), precision (P), and F-
measure (F) (Manning and Schuetze, 1999), 
which are defined as follows: 
Recall (R) = (# of correctly identified chunk 
brackets) / ( # of chunk brackets)        (1) 
Precision (P) = (# of correctly identified chunk 
brackets) / ( # of identified chunk brackets)   (2) 
F-measure (F) = (2 ? recall ? precision) / (re-
call + precision)           (3) 
In addition, we use coverage ratio (CR) to repre-
sent the size of matching sentences (or say, 
matching set) of our BTM model. The CR is 
defined as: 
Coverage Ratio (CR) = (# of not NULL output 
sentences) / (# of total testing sentences)        (4) 
3.1 Relationship between POS layer number 
and BTM performance 
In the 1st experiment, the BTM threshold value 
is set to 1 and the BTM training size is set to 
45,000. Table 7 is the first experimental results 
of BTM performance (P, R, F) and CR for the 
POS layer numbers are 1, 2, 3, 4 or 5. From Ta-
ble 7, it shows the POS layer number is posi-
tively related to the F-measure. Since the BTM 
model with POS layer number 2 is able to 
achieve more than 96% F-measure, we use POS 
layer number 2 to conduct the following ex-
periments. This experimental result seems to 
indicate that the CCTB2.1 dataset with POS 
layer number 2 (including 57 distinct POS tags) 
can provide sufficient information for the BTM 
model to achieve an F-measure of more than 
96% and a maximum CR of 46.88%. 
Table 7. The first experimental results of BTM (1; 
1/2/3/4/5; 45,000) 
POS Layer #    P(%) R(%) F(%) | CR(%) 
1  86.32 85.57 85.94 | 33.43 
2     97.03 95.82 96.42 | 46.88 
3     99.04 98.86 98.95 | 34.07 
4     99.07 98.88 98.97 | 31.92 
5     99.07 98.87 98.97 | 31.84 
3.2 Relationship between BTM threshold 
value and BTM performance 
In the 2nd experiment, the POS layer number is 
set to 2 and the BTM training size is set to 
26
45,000. Table 8 is the second experimental re-
sults of BTM performance and CR when the 
BTM threshold value is 1.0, 0.9, 0.8, 0.7, 0.6 or 
0.5. From Table 8, it shows the BTM threshold 
value is positively related to the F-measure. Be-
sides, the F-measure difference between thresh-
old values 1.0 and 0.5 is only 1.37%. This result 
indicates that the BTM model can robustly 
maintain an F-measure of more than 95% and a 
CR of more than 46% while the POS layer num-
ber is set to 2, BTM training size is set to 45,000 
and the BTM threshold value is t 0.5. 
Table 8. The second experimental results of BTM 
(1/0.9/0.8/0.7/0.6/0.5; 2; 45,000) 
Threshold 
Value  P(%) R(%) F(%) | CR(%) 
1.0  97.03 95.82 96.42 | 46.88 
0.9  96.99 95.71 96.35 | 47.84 
0.8  96.95 95.54 96.24 | 49.42 
0.7  96.94 95.49 96.21 | 50.66 
0.6  96.86 95.26 96.05 | 51.92 
0.5  96.34 93.80 95.05 | 53.72 
3.3 Relationship between BTM training size 
and BTM performance 
In the 3rd experiment, the BTM threshold value 
is set to 0.5 and POS layer number is set to 2. 
Table 9 is the third experimental results of BTM 
performance and CR when the BTM training 
size is 5000, 10000, 15000, 20000, 25000, 
30000, 35000, 40000 or 45000. From Table 9, it 
seems to indicate that the F-measure of the BTM 
model is independent of the training size be-
cause the maximum difference between these 
respective F-measures is only 0.88%. 
Table 9. The third experimental results of BTM (0.5, 
2, 5,000/ 10,000/ 15,000/ 20,000/ 25,000 /30,000 
/35,000 / 40,000/ 45,000) 
Training size P(%) R(%) F(%) | CR(%) 
5,000  95.82 91.33 94.61 | 30.23 
10,000  96.28 92.16 94.64 | 35.13 
15,000  96.29 92.48 94.54 | 40.32 
20,000  96.07 92.59 94.44 | 43.73 
25,000  96.19 92.74 94.43 | 46.70 
30,000  96.17 92.78 94.30 | 48.46 
35,000  96.22 92.92 94.35 | 50.51 
40,000  96.28  93.06 94.17 | 52.29 
45,000  96.34 93.80 95.05 | 53.72 
To sum up the above three experimental results 
(Tables 7-9), it shows that the F-measure (over-
all performance) of our BTM model with POS 
layer number (t 2) is apparently not sensitive to 
BTM threshold value (t 0.5) and BTM training 
size (t 5,000) on the matching set with perfect 
input. Since the CR of our BTM model is posi-
tively related to BTM training size, it indicates 
our BTM model should be able to maintain the 
high performance chunk bracketing (more than 
95% F-measure on the matching set with perfect 
input) and increase the CR only by enlarging the 
BTM training size. 
3.4 Comparative study of the N-gram model 
and the BTM model on perfect/actual input 
To conduct the 4th experiment, we develop N-
gram models (NGM) by the SRILM (Stanford 
Research Institute Language Modeling) toolkit 
(Stolcke, 2002) as the baseline model. SRILM is 
a freely available collection of C++ libraries, 
executable programs, and helper scripts de-
signed to allow both production of, and experi-
mentation with, statistical language models for 
speech recognition and other NLP applications 
(Stolcke, 2002). In this experiment, the TL POS 
patterns (such as ?<Na:DE:Na+VH:VH>?) of  
training set were used as the data for SIRLM to 
build N-gram models. Then, use these N-gram 
models to determine the chunks for each BL 
POS pattern in the testing set. Note that these N-
gram models were trained by the TL POS pat-
terns only, not by each layer?s POS patterns. 
Figure 2 shows the distribution of n-gram pat-
terns of N-gram models (N is from 2 to 44) 
trained by the training set. 
?
?????
?????
?????
?????
?????
?????
?????
?????
?????
? ?? ?? ?? ?? ??
??????
???
???
??
???
???
???
??
Fig.2 The n-gram distribution of N-gram models (N 
is 2 to 44) trained by the 45,000 CCTB2.1 TL POS 
patterns of training set 
27
Tables 10, 11, 12 13 and 14 are the results of the 
fourth experiment. The explanations of the five 
tables are given below. 
Table 10. The fourth experimental results of NGM 
(2/3/4/5/6/N; 45,000) for perfect input 
N-gram P(%) R(%) F(%) 
2  77.62 78.98 78.30 
3  80.16 81.83 80.99 
4  80.36 81.91 81.13 
5  79.58 81.38 80.47 
6  78.98 80.35 79.91 
N (=44) 78.51 80.44 79.46 
Table 11. The comparative experimental results of 
P/R/F and CR between BTM (0.5, 2, 45,000) and a 4-
gram model for perfect input 
Set     BTM(0.5, 2, 45k)    4-gram  | CR(%) 
matching     96.3/93.8/95.1         89.3/89.7/89.5    | 53.6 
no matching    -                   73.5/75.7/74.6    | 46.4 
Table 12. The comparative experimental results of 
P/R/F and CR between BTM (0.5, 2, 45,000) and a 4-
gram model for actual input 
Set     BTM(0.5, 2, 45k)     4-gram           | CR(%) 
matching    97.4/97.3/97.3          95.1/96.7/95.9    | 19.2 
no matching  -                   69.1/68.8/68.9    | 80.8 
Table 13. The comparative experimental results of 
P/R/F of a 4-gram model and a 4-gram with BTM 
(0.5, 2, 45,000) model for perfect input and actual 
input 
Model  Perfect(P/R/F) Actual(P/R/F) 
4-gram  80.4/81.9/81.1 72.63/72.23/72.43 
BTM+4-gram 83.8/83.4/83.6 74.70/73.03/73.42 
From Table 10, it shows the maximum preci-
sion, recall and F-measure of N-gram models all 
occur at the 4-gram model for perfect input. 
Thus, we use the 4-gram model as the baseline 
model in this experiment. Tables 11 and 12 are 
the comparative experimental results of the 
baseline model and the BTM model on the 
matching sets of perfect input and actual input, 
respectively. From Table 11, it shows the per-
formance (95.1% F-measure) of a BTM (0.5, 2, 
45,000) is 5.6% greater than that of a 4-gram 
model (89.5% F-measure) for the matching set 
with perfect input. From Table 12, it shows the 
performance (97.3% F-measure) of a BTM (0.5, 
2, 45,000) is 1.4% greater than that of a 4-gram 
model (95.9% F-measure) for the matching set 
with actual input. Table 13 is the experimental 
results of applying the BTM model to the 
matching set and the 4-gram model to the non-
matching set. From Table 13, it shows the F-
measure of a 4-gram model can be improved by 
the BTM model for both perfect input (2.5% 
increasing) and actual input (1% increasing). 
According to all the four experimental results, 
we have: (1) the BTM model can achieve better 
F-measure performance than N-gram models on 
the matching sets for both perfect input and ac-
tual input; and (2) the chunk bracketing per-
formance of the BTM model for the matching 
sets should be high and stable against training 
size, perfect and actual input while POS layer 
number t 2 and BTM threshold value t 0.5. 
4 Conclusion and Future Directions 
In this paper, we define a word-layer matrix that 
can be used to translate the CKIP Treebank and 
the Penn Chinese Treebank into corresponding 
BTM datasets. By the BTM dataset, we devel-
oped a BTM model, adopting two types of con-
ditional probabilities and using full TL POS 
pattern matching and full TL POS template 
matching to identify the chunks for each seg-
mented and POS-tagged Chinese sentence. 
Our experiment results show that the BTM 
model can effectively achieve precision and re-
call optimization on the matching sets for both 
perfect input and actual input. The experimental 
results also demonstrate that:  
(1) The BTM threshold value is positively re-
lated to the BTM F-measure; 
(2) The POS layer number is positively related 
to the BTM F-measure; 
(3) The F-measure of our BTM model for the 
matching set should be not sensitive to two 
BTM parameters: BTM threshold value and 
BTM training size; 
(4) The chunk bracketing of our BTM model on 
the matching set should be high and stable (or 
say, robust) against training size, perfect and 
actual input while POS layer number is t 2 and 
BTM threshold value is t 0.5; 
(5) The BTM model can provide a matching set 
with high and stable performance (more than 
95% F-measure) for improving N-gram-like 
models without trial-and-error, or say, a tuning 
process. For most statistical language models, 
such N-gram models, need tuning to improve 
their performance and large-scale corpus to 
28
overcome corpus sparseness problem (Manning 
et al, 1999; Gao et al, 2002; Le et al, 2003). 
Furthermore, it is difficult for them to identify 
their ?matching set? with high and stable per-
formance, whereas our BTM model has the abil-
ity to support chunkers and parsers for 
improving chunking performance. According to 
the fourth experiment results, when applying a 
BTM (0.5, 2, 45,000) model on the matching set 
and a 4-gram model on the non-matching set, 
the combined system can improve the F-
measure of 4-gram model 2.5% for perfect input 
and 1.0% for actual input. Among the chunking 
and parsing models, Cascaded Markov Models 
should be the first one to construct the parse tree 
layer by layer with each layer?s Markov Model. 
As per (Brants, 1999), each layer?s chunk brack-
eting of Cascaded Markov Models is dependent 
because the output of a lower layer is passed as 
input to the next higher layer. On the contrast, 
our BTM model can independently generate the 
chunks for top layer without the results of lower 
layer chunk bracketing; and 
(6) Since the F-measures of the BTM model for 
the matching sets of perfect and actual input 
both are greater than 95%, we believe our BTM 
model can be used not only to improve the F-
measure of existing shallow parsing or chunking 
systems, but also to help select valuable sen-
tences from the non-matching set for effectively 
extending the CR of our BTM model. 
In the future, we shall study how to combine 
our BTM model with more conventional statisti-
cal approaches, such as Bayesian Networks, 
Maximum Entropy and Cascaded Markov Mod-
els, etc. Meanwhile, we will also apply our BTM 
model to the Penn English Treebank as a com-
parative study. 
Acknowledgement 
Some work of this paper was done while the 
author was a visitor at the Institute of Informa-
tion Science (Academia Sinica in Taiwan). We 
thank Prof. Wei-Lian Hsu and Cheng-Wei Shih 
for their kind help. We also thank the Chinese 
Knowledge Information Processing group in 
Taiwan for providing us the CKIP Treebank. 
References 
Abney, S. Parsing by chunks. In Principle-Based 
Parsing. Kluwer Academic Publishers, 
Dordrecht: pp.257?278. 1991. 
Basili, R. and Zanzotto, F. M. Parsing engineering 
and empirical robustness. Natural Language 
Engineering, 8(2?3):pp.97?120. 2002. 
Brants, T. Cascaded Markov Models. Proceedings of 
EACL '99. pp.118 ? 125. 1999.  
Chen, K.-J. and Huang C.-R. Information-based Case 
Grammar: A Unification-based Formalism for 
Parsing Chinese. In Huang et al (Eds.): pp.23-
46. 1996. 
Chen, K.-J., Huang C.-R., Chang, L.-P. and Hsu, H.-
L. Sinica Corpus: Design Methodology for Bal-
anced Corpra.? Proceedings of the 11th Pacific 
Asia Conference on Language, Information, 
and Computation (PACLIC II), SeoulKorea, 
pp.167-176. 1996. 
Chen, K.-J., Luo, C.-C., Gao, Z.-M., Chang, M.-C., 
Chen, F.-Y., and Chen, C.-J. The CKIP Chinese 
Treebank. In Journ ees ATALA sur les Corpus 
annot es pour la syntaxe, Talana, Paris VII: 
pp.85-96. 1999. 
Chen, K.-J. et al Building and Using Parsed Corpora. 
(Anne Abeill? ed. s) KLUWER, Dordrecht. 
2003. 
Chen, K.-J and Hsieh Y.-M. Chinese Treebanks and 
Grammar Extraction. Proceedings of IJCNLP-
2004: pp.560-565. 2004. 
Chiou, F.-D., Chiang, D. and Palmer, M. Facilitating 
Treebank Annotation with a Statistical Parser. 
Proceedings of the Human Language Technol-
ogy Conference (HLT 2001), San Diego, Cali-
fornia, 2001. 
 CKIP  portal. 
 http://rocling.iis.sinica.edu.tw/CKIP/treebank.ht
m
CKIP (Chinese Knowledge Information Processing 
Group). Technical Report no. 95-02, the content 
and illustration of Sinica corpus of Academia 
Sinica. Institute of Information Science, Aca-
demia Sinica. 1995. 
CKIP (Chinese Knowledge Information Processing 
Group). A study of Chinese Word Boundaries 
and Segmentation Standard for Information 
processing (in Chinese). Technical Report, Tai-
wan, Taipei, Academia Sinica. 1996. 
Gao, J.-F., Goodman, J., Li, M.-J., and Lee, K.-F. 
Toward a Unified Approach to Statistical Lan-
guage Modeling for Chinese, ACM Transac-
tions on Asian language Information processing. 
1(1): pp.23-33. 2002. 
29
Huang, Chu-Ren, Chen, K.-J., Chen, F.-Y., Gao, Z.-
M. and Chen, K.-Y. Sinica Treebank: Design 
Criteria, Annotation Guidelines, and On-line In-
terface. Proceedings of 2nd Chinese Language 
Processing Workshop (Held in conjunction with 
the 38th Annual Meeting of the Association for 
Computational Linguistics, ACL-2000). Octo-
ber 7, 2000, Hong Kong: pp.29-37. 2000. 
Johnny Bigert, Jonas Sj?bergh, Ola Knutsson and 
Magnus Sahlgren. Unsupervised Evaluation of 
Parser Robustness. In Proc. of CICLing 2005. 
Mexico City, Mexico. 2005. 
Knutsson, O., Bigert, J. and Kann, V. A Robust Shal-
low Parser for Swedish. In: Proc. of 
Nodalida'03. Reykavik, Iceland. 2003. 
Le, Zhang, Lu X.ue-qiang, Shen Yan-na and Yao 
Tian-shun. A Statistical Approach to Extract 
Chinese Chunk candidates from Large Corpora. 
In: Proc. of ICCPOL-2003. ShengYang: 
pp.109-117. 2003. 
Li, Hongqiao, Huang, C.-N., Gao, Jianfeng and Fan, 
Xiaozhong. Chinese chunking with another 
type of spec. In SIGHAN-2004. Barcelona: pp.
41-48. 2004. 
Liu Y., Q. Tan, and X. Shen. Segmentation Standard 
for Modern Chinese Information Processing 
and Automatic Segmentation Methodology. 
1993. 
Jorn Veenstra. Memory-Based Text Chunking. In: 
Nikos Fakotakis (ed), Machine learning in hu-
man language technology, workshop at ACAI 
99. Chania, Greece. 1999. 
Lance A. Ramshaw and Mitchell P. Marcus. Text 
Chunking Using Transformation-Based Learn-
ing. In: Proc. of the Third ACL Workshop on 
Very Large Corpora. Cambridge MA, USA: 
pp.82-94. 1995. 
Manning, C. D. and Schuetze, H. Fundations of Sta-
tistical Natural Language Processing, MIT 
Press: pp.191-220., 1999. 
Menzel, W. Robust processing of natural language. In 
Proc. 19th Annual German Conference on Arti-
ficial Intelligence, Berlin. Springer: pp.19?34. 
1995. 
Munoz, M., V. Punyakanok, D. Roth, and D. Zimak. 
A learning approach to shallow parsing. Tech-
nical Report UIUCDCS-R-99-2087, UIUC 
Computer Science Department. 1999. 
Oliver Streiter. Memory-based Parsing: Enhancing 
Recursive Top-down Fuzzy Match with Bot-
tom-up Chunking. ICCPOL 2001, Seoul. 2001. 
PCTB  portal. 
 http://www.cis.upenn.edu/~chinese/ctb.html 
Ruifeng Xu, Qin Lu, Yin Li and Wanyin Li. The 
Construction of a Chinese Shallow Treebank. In: 
Proc. of 3rd ACL SIGHAN Workshop. Barce-
lona: pp.94-101. 2004. 
Sang, Erik F. Tjong Kim and Buchholz, Sabine. In-
troduction to the CoNLL-2000 Shared Task: 
Chunking. In: Proc. of CoNLL-2000 and LLL-
2000. Lisbon, Portugal: pp.127-132. 2000. 
Stolcke, A. SRILM - An Extensible Lan-guage Mod-
eling Toolkit, in Proc. Intl. Conf. Spoken Lan-
guage Processing, Denver, Colorado. 2003. 
Xia, Fei, Palmer, M., Xue, N., Okurowski, M.E., 
Kovarik, J., Chiou, F.-D., Huang, S., Kroch, T. 
and Marcus, M. Developing Guidelines and En-
suring Consistency for Chinese Text Annotation. 
In: Proc. of LREC-2000. Greece. 2000. 
Xue, N., Chiou, F. and M. Palmer. Building a Large-
Scale Annotated Chinese Corpus, In: Proc. of 
COLING-2002. Taipei, Taiwan. 2002. 
Xue, N. and Palmer, M. Annotating Propositions in 
the Penn Chinese Treebank, In Proceedings of 
the 2nd SIGHAN Workshop on Chinese Lan-
guage Processing, in conjunction with ACL'03. 
Sapporo, Japan. 2003. 
Xue., N. and M. Palmer. Automatic Semantic Role 
Labeling for Chinese Verbs, in Proceedings of 
the 19th International Joint Conference on Arti-
ficial Intelligence. Edinburgh, Scotland. 2005 
Xue, N., Xia, F., Chiou F.-D. and M. Palmer. The 
Penn Chinese TreeBank: Phrase Structure An-
notation of a Large Corpus. Natural Language 
Engineering, 11(2)-207. 2005. 
You Jia-Ming and Chen, K.-J. Automatic Semantic 
Role Assignment for a Tree Structure. Proceed-
ings of SIGHAN workshop. pp.109-115. 2004. 
Zhou, G.-D. and Su, J. A Chinese Efficient Analyser 
Integrating Word Segmentation, Part-Of-Speech 
Tagging, Partial Parsing and Full Parsing. ACL 
Second SIGHAN Workshop on Chinese Lan-
guage Processing. pp.78-83. 2003. 
30
Word Boundary Token Model for the SIGHAN Bakeoff 2007 
Tsai Jia-Lin 
Department of Information Management 
Tungnan University 
Taipei 222, Taiwan 
tsaijl@mail.tnu.edu.tw 
 
 
Abstract 
This paper describes a Chinese word seg-
mentation system based on word boundary 
token model and triple template matching 
model for extracting unknown words; and 
word support model for resolving segmen-
tation ambiguity. 
1 Introduction 
In the SIGHAN bakeoff 2007, we participated in 
the CKIP and the CityU closed tasks. Our Chinese 
word segmentation system is based on three mod-
els: (a) word boundary token (WBT) model and (b) 
triple context matching model for unknown word 
extraction, and (c) word support model for seg-
mentation disambiguation. Since the word support 
model and triple context matching model have 
been proposed in our previous work (Tsai, 2005, 
2006a and 2006b) at the SIGHAN bakeoff 2005 
(Thomas, 2005) and 2006 (Levow, 2006), the ma-
jor descriptions of this paper is on the WBT model. 
The remainder of this paper is arranged as follows. 
In Section 2, we present the WBT model for ex-
tracting words from each Chinese sentence. Scored 
results and analyses of our CWS system are pre-
sented in Section 3. Finally, in Section 4, we pre-
sent our conclusion and discuss the direction of 
future research. 
2 Word Boundary Token Model 
To develop the WBT model, first, we define word 
boundary token. Second, we give definition and 
computation of the WBT probability and the WBT 
frequency for a given corpus. Finally, algorithm of 
our WBT model for word extraction is given. 
2.1 Types of Word Boundary Token 
We classify WBT into three types: left, right and 
bi-direction. The left and right word boundary 
(WB) tokens are the immediately preceding word 
and the following word of a word in a Chinese 
sentence, respectively. Suppose W1W2W3 is a 
Chinese sentence comprised of three Chinese 
words W1, W2 and W3. To this case, W1 and W3 
are the left and the right WB tokens of W2, 
respectively. On the other hand, those words that 
can simultaneously be left and right WB tokens of 
a word in corpus are defined as bi-direction WB 
tokens. Suppose W4W2W1 is a Chinese sentence 
comprised of three Chinese words W4, W2 and W1. 
Following the above cases, W1 can be a bi-
direction WB token for W2. Table 1 is the Top 5 
left, right and bi-direction WB tokens derived by 
the Academia Sinica (AS) corpus (CKIP, 1995 and 
1996). From Table 1, the Top 1 left , right and bi-
direction WB tokens is ??(of).? 
 
 Left      Right Bi-Direction 
Top1 ?(of)      ?(of) ?(of) 
Top2 ?(is)      ?(is) ?(is) 
Top3 ?(at)      ?(already) ?(at) 
Top4 ?(a)      ?(at) ?(already) 
Top5 ?(has)      ?(one) ?(and) 
Table 1. Top 5 left, right and bi-direction WB to-
kens derived from the AS corpus 
151
Sixth SIGHAN Workshop on Chinese Language Processing
2.2 WBT Frequency and WBT Probability 
We first give the computation of WBT frequency, 
then, the computation of WBT probability. 
 
 (1) WBT frequency: we use WBT_F(string, WBT, 
L/R) as the function of WBT frequency, where 
string is a n-char string containing n Chinese 
characters, WBT is a word boundary token, and 
L/R indicates to compute left or right WBT 
frequency. Now, take WBT_F(??? (we)?, 
??(of)?, L) as example. First, we submit the 
query ????? to system corpus. Second, set 
the number of sentences including this query is  
the WBT_F(???(we)?, ??(of), L). 
(2) WBT Probability: we use WBT_P(string1, 
string2, WBT, L/R) as the function of WBT 
probability, where string1 and string2 are two 
n-char strings, WBT is a word boundary token, 
and L/R indicates to compute left or right WBT 
probability. The equations of left and the right 
WBT probability are: 
 
WBT_P(string1, string2, WBT, L) =  
WBT_F(string1, WBT, L) /  
(WBT_F(string1, WBT, L)+WBT_F(string2, WBT, L) )       (1) 
 
WBT_P(string1, string2, WBT, R) =  
WBT_F(string1, WBT, R) / 
(WBT_F(string1, WBT, R)+WBT_F(string2, WBT, R) )       (2) 
 
2.3 Algorithm of WBT Model 
We use WBTM(n, WBT, threshold_p, threshold_f) 
as the function of the WBT model, where n is the 
window size, threshold_p is the threshold value of 
WBT probability and threshold_f is the threshold 
value of WBT frequency. The algorithm of our 
WBT model applied to extract words from a given 
Chinese sentence is as follows: 
Step 1. INPUT: 
    n, WBT, threshold_p and  threshold_f; 
Step 2. IF sentence length is less or equal to n 
THEN GOTO Step 4; 
Step 3. 
SET loopCount to one 
REPEAT 
COMBINE the characters of sentence between 
loopCountth and (loopCount + n ? 1)th to be a 
string_a 
COMBINE the characters of sentence between 
(loopCount+1)th and (loopCount + n)th to be 
a string_b 
IF WBT_P(string_a, string_b, WBT, L) ? 
threshold_p AND 
WBT_P(string_a, string_b, WBT, R) ? 
threshold_p AND 
WBT_F(string_a, WBT, L) ? threshold_f 
AND 
WBT_F(string_a, WBT, R) ? threshold_f 
THEN SET string_a is as word 
ENDIF 
IF WBT_P(string_b, string_a, WBT, L) ? 
threshold_p AND 
WBT_P(string_b, string_a, WBT, R) ? 
threshold_p AND 
WBT_F(string_b, WBT, L) ? threshold_f 
AND 
WBT_F(string_b, WBT, R) ? threshold_f  
THEN SET string_b to a word 
ENDIF 
INCREMENT loopCount 
UNTIL loopCount > sentence length ? n 
Step 4. END. 
 
loopCount is 1 
       string_a = ??; string_b = ?? 
WBT_F(string_a, ???, L) = 0 
WBT_F(string_a, ???, R) = 7 
WBT_F(string_b, ???, L) = 0 
WBT_F(string_b, ???, R) = 0 
WBT_P(string_a, string_b, ???, L) = 0 
WBT_P(string_a, string_b, ???, R) = 1 
WBT_P(string_b, string_a, ???, L) = 0 
WBT_P(string_b, string_a, ???, R) = 0 
SET?? to a word 
loopCount is 2 
string_a = ??; string_b = ?? 
WBT_F(string_a, ???, L) = 0 
WBT_F(string_a, ???, R) = 0 
WBT_F(string_b, ???, L) = 0 
WBT_F(string_b, ???, R) = 0 
WBT_P(string_a, string_b, ???, L) = 0 
WBT_P(string_a, string_b, ???, R) = 0 
WBT_P(string_b, string_a, ???, L) = 0 
WBT_P(string_b, string_a, ???, R) = 0 
Table 2. An example of applying WBTM(2, ???, 0.95, 
1) to extract word ???? from the Chinese sentence 
?????? 
152
Sixth SIGHAN Workshop on Chinese Language Processing
Table 2 is an example of applying  WBTM(2, ???, 
0.95, 1) to extract words from the Chinese sentence 
?????? by the AS corpus 
3 Evaluation 
In the SIGHAN Bakeoff 2007, there are five train-
ing corpus for word segmentation (WS) task: AS 
(Academia Sinica), CityU (City University of 
Hong Kong) are traditional Chinese corpus; CTB 
(University of Colorado, United States), NCC 
(State Language Commission of P.R.C., Beijing) 
and SXU (Shanxi University, Taiyuan) are simpli-
fied Chinese corpus. For each corpus, there are 
closed and open tasks. In this Bakeoff, we attend 
the AS (Academia Sinica) and CityU (City Univer-
sity of Hong Kong) closed WS tasks. Tables 3 and 
4 show the details of CKIP and CityU tasks. From 
Table 3, it indicates that the CKIP should be a 10-
folds design. From Table 4, it indicates that the 
CityU should be a 5-folds design. 
 
  Training Testing 
Sentence 95,303  10,834 
Wordlist 48,114  14,662 
Table 3. The details of CKIP WS task 
 
  Training Testing 
Sentence 36,227    8,093 
Wordlist 43,639  23,303 
Table 4. The details of CityU WS task 
3.1 Our CWS System 
The major steps of our CWS system with word 
boundary token model, triple context matching 
model and word support model are as below: 
Step 0. Combine training corpus and testing corpus 
as system corpus; 
Step 1. Generate the BMM segmentation for the 
given Chinese sentence by system dictionary; 
Step 2. Use WBT model with system corpus to 
extract 2-char, 3-char and 4-char words from 
the given Chinese sentence, where WBT is set 
to ??,? ??,? ??,? ??,? ??,? threshold_p 
is set to 0.95 and threshold_f is set to 1; 
Step 3. Use TCT (triple context template) matching 
model to extract 2-char, 3-char and 4-char 
words from the segmented Chinese sentence 
of Step 1. The details of TCT matching model 
can be found in (Tsai, 2005); 
Step 4. Add the found words of Steps 2 and 3 into 
system dictionary; 
Step 5. Generate the BMM segmentation for the 
given Chinese sentence by system dictionary; 
Step 6. Use word support model to resolve Over-
lap Ambiguity (OA) and Combination Am-
biguity (CA) problems for the BMM seg-
mentation of Step 5. 
3.2 Bakeoff Scored Results 
Table 5 is the comparison of scored results be-
tween our CWS and the SIGHAN Bakeoff 2007 
baseline system for the CKIP closed WS task by 
the SIGHAN Bakeoff 2007. Table 6 is the com-
parison between our CWS and the SIGHAN Bake-
off 2007 baseline system for the CityU closed WS 
task by the SIGHAN Bakeoff 2007. 
 
 Baseline Our CWS Increase 
R 0.8978  0.915  0.0172 
P 0.8232  0.9001  0.0769 
F 0.8589  0.9075  0.0486 
Table 5. The comparison of scored results between 
our CWS system and the SIGHAN Bakeoff 2007 
baseline system for the CKIP closed WS task 
 
 Baseline Our CWS Increase 
R 0.9006  0.9191  0.0185 
P 0.8225  0.9014  0.0789 
F 0.8598  0.9102  0.0504 
Table 6. The comparison of scored results between 
our CWS system and the SIGHAN Bakeoff 2007 
baseline system for the CityU closed WS task 
 
From Tables 5 and 6, it shows the major im-
provement of our CWS for the baseline system is 
on the precision of word segmentation. That is to 
say, the major target system for improving our 
CWS system is the unknown word extraction sys-
tem, i.e. the word boundary model and the triple 
context template matching model. 
3.3 Analysis 
Table 7 is the coverage of 2-char, 3-char, 4-char 
and great than 4-char error words extracting by our 
CWS for the CKIP and the CityU closed WS tasks. 
 
 
153
Sixth SIGHAN Workshop on Chinese Language Processing
               Coverage (%)   
 2-char 3-char 4-char > 4-char 
CKIP  68% 24% 4% 4% 
CityU  78% 19% 2% 1%  
Total  75% 21% 3% 1% 
Table 7. The coverage of 2-char, 3-char, 4-char 
and great than 4-char error words extracting by our 
CWS for the CKIP and the CityU closed WS tasks 
 
From Table 7, it shows the major n-char unknown 
word extraction for improving our CWS system is 
on 2-char unknown word extraction. It is because 
that the total coverage of 2-char word errors ex-
traction of our CWS system for the CKIP and the 
CityU WS tasks is 75%. 
4 Conclusions 
In this paper, we describes a Chinese word seg-
mentation system based on word boundary token 
model and triple context matching model (Tsai, 
2005) for extracting unknown words; and word 
support model (Tsai, 2006a and 2006b) for resolv-
ing segmentation ambiguity. To develop the word 
boundary model, we define WBT and classify 
WBT into three types of left, right and bi-direction. 
As per three types of WBT, we define WBT prob-
ability and WBT frequency. 
 In the SIGHAN Bakeoff 2007, we take part in 
the CKIP and the CityU closed word segmentation 
tasks. The scored results show that our CWS can 
increase the Bakeoff baseline system with 4.86% 
and 5.04% F-measures for the CKIP and the CityU 
word segmentation tasks, respectively. On the 
other hand, we show that the major room for im-
proving our CWS system is the 2-char unknown 
word extraction of the word boundary model and 
triple context matching model. The performance of 
word support model is great and supports our pre-
vious work (Tsai, 2006a and 2006b). 
We believe one major advantage of the WBT 
model is to use it with web as live corpus to mini-
mum the corpus sparseness effect. Therefore, in 
the future, we shall investigate the WBT model 
with the web corpus, such as the searching results 
of GOOGLE and Yahoo!, etc. 
References 
CKIP (Chinese Knowledge Information Processing 
Group). 1995. Technical Report no. 95-02, the 
content and illustration of Sinica corpus of Aca-
demia Sinica. Institute of Information Science, 
Academia Sinica. 
CKIP (Chinese Knowledge Information Processing 
Group). 1996. A study of Chinese Word Bounda-
ries and Segmentation Standard for Information 
processing (in Chinese). Technical Report, Taiwan, 
Taipei, Academia Sinica. 
Levow, Gina-Anne. 2006. The Third International Chi-
nese Language Processing Bakeoff: Word Seg-
mentation and Named Entity Recognition, In 
Proceedings of SIGHAN5 the 3rd International 
Chinese Language Processing Bakeoff at Col-
ing/ACL 2006, July, Sydney, Australia, 108-117. 
Thomas, Emerson. 2005. The Second International Chi-
nese Word Segmentation Bakeoff, In Proceed-
ings of The 2nd International Chinese Word 
Segmentation Bakeoff at SIGHAN-4, October, 
Jeju Island, Korea, 123-133. 
Tsai, Jia-Lin. 2005. Report to BMM-based Chinese 
Word Segmentor with Context-based Unknown 
Word Identifier for the Second International Chi-
nese Word Segmentation Bakeoff, In Proceed-
ings of The 2nd International Chinese Word 
Segmentation Bakeoff at SIGHAN-4, October, 
Jeju Island, Korea, 142-145. 
Tsai, Jia-Lin. 2006. Using Word Support Model to Im-
prove Chinese Input System, In Proceedings of 
Coling/ACL 2006, July, Sydney, Australia, 842-
849. 
Tsai, Jia-Lin. 2006. BMM-based Chinese Word Seg-
mentor with Word Support Model for the 
SIGHAN Bakeoff 2006, In Proceedings of 
SIGHAN5 the 3rd International Chinese Lan-
guage Processing Bakeoff at Coling/ACL 2006, 
July, Sydney, Australia, 130-133. 
154
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 842?849,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Using Word Support Model to Improve Chinese Input System 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
Taipei 222, Taiwan 
tsaijl@mail.tnit.edu.tw 
 
 
Abstract 
This paper presents a word support 
model (WSM). The WSM can effec-
tively perform homophone selection 
and syllable-word segmentation to im-
prove Chinese input systems. The ex-
perimental results show that: (1) the 
WSM is able to achieve tonal (sylla-
bles input with four tones) and tone-
less (syllables input without four tones) 
syllable-to-word (STW) accuracies of 
99% and 92%, respectively, among the 
converted words; and (2) while apply-
ing the WSM as an adaptation proc-
essing, together with the Microsoft 
Input Method Editor 2003 (MSIME) 
and an optimized bigram model, the 
average tonal and toneless STW im-
provements are 37% and 35%, respec-
tively. 
1 Introduction 
According to (Becker, 1985; Huang, 1985; Gu et 
al., 1991; Chung, 1993; Kuo, 1995; Fu et al, 
1996; Lee et al, 1997; Hsu et al, 1999; Chen et 
al., 2000; Tsai and Hsu, 2002; Gao et al, 2002; 
Lee, 2003; Tsai, 2005), the approaches of Chi-
nese input methods (i.e. Chinese input systems) 
can be classified into two types: (1) keyboard 
based approach: including phonetic and pinyin 
based (Chang et al, 1991; Hsu et al, 1993; Hsu, 
1994; Hsu et al, 1999; Kuo, 1995; Lua and Gan, 
1992), arbitrary codes based (Fan et al, 1988) 
and structure scheme based (Huang, 1985); and 
(2) non-keyboard based approach: including 
optical character recognition (OCR) (Chung, 
1993), online handwriting (Lee et al, 1997) and 
speech recognition (Fu et al, 1996; Chen et al, 
2000). Currently, the most popular Chinese in-
put system is phonetic and pinyin based ap-
proach, because Chinese people are taught to 
write phonetic and pinyin syllables of each Chi-
nese character in primary school. 
In Chinese, each Chinese word can be a 
mono-syllabic word, such as ??(mouse)?, a bi-
syllabic word, such as ???(kangaroo)?, or a 
multi-syllabic word, such as ????(Mickey 
mouse).? The corresponding phonetic and pin-
yin syllables of each Chinese word is called syl-
lable-words, such as ?dai4 shu3? is the pinyin 
syllable-word of ???(kangaroo).? According 
to our computation, the {minimum, maximum, 
average} words per each distinct mono-syllable-
word and poly-syllable-word (including bi-
syllable-word and multi-syllable-word) in the 
CKIP dictionary (Chinese Knowledge Informa-
tion Processing Group, 1995) are {1, 28, 2.8} 
and {1, 7, 1.1}, respectively. The CKIP diction-
ary is one of most commonly-used Chinese dic-
tionaries in the research field of Chinese natural 
language processing (NLP). Since the size of 
problem space for syllable-to-word (STW) con-
version is much less than that of syllable-to-
character (STC) conversion, the most pinyin-
based Chinese input systems (Hsu, 1994; Hsu et 
al., 1999; Tsai and Hsu, 2002; Gao et al, 2002; 
Microsoft Research Center in Beijing; Tsai, 
2005) are addressed on STW conversion. On the 
other hand, STW conversion is the main task of 
Chinese Language Processing in typical Chinese 
speech recognition systems (Fu et al, 1996; Lee 
et al, 1993; Chien et al, 1993; Su et al, 1992). 
As per (Chung, 1993; Fong and Chung, 1994; 
Tsai and Hsu, 2002; Gao et al, 2002; Lee, 2003; 
Tsai, 2005), homophone selection and syllable-
word segmentation are two critical problems in 
developing a Chinese input system. Incorrect 
homophone selection and syllable-word seg-
842
mentation will directly influence the STW con-
version accuracy. Conventionally, there are two 
approaches to resolve the two critical problems: 
(1) linguistic approach: based on syntax parsing, 
semantic template matching and contextual in-
formation (Hsu, 1994; Fu et al, 1996; Hsu et al, 
1999; Kuo, 1995; Tsai and Hsu, 2002); and (2)  
statistical approach: based on the n-gram mod-
els where n is usually 2, i.e. bigram model (Lin 
and Tsai, 1987; Gu et al, 1991; Fu et al, 1996; 
Ho et al, 1997; Sproat, 1990; Gao et al, 2002; 
Lee 2003). From the studies (Hsu 1994; Tsai 
and Hsu, 2002; Gao et al, 2002; Kee, 2003; Tsai, 
2005), the linguistic approach requires consider-
able effort in designing effective syntax rules, 
semantic templates or contextual information, 
thus, it is more user-friendly than the statistical 
approach on understanding why such a system 
makes a mistake. The statistical language model 
(SLM) used in the statistical approach requires 
less effort and has been widely adopted in com-
mercial Chinese input systems. 
In our previous work (Tsai, 2005), a word-
pair (WP) identifier was proposed and shown a 
simple and effective way to improve Chinese 
input systems by providing tonal and toneless 
STW accuracies of 98.5% and 90.7% on the 
identified poly-syllabic words, respectively. In 
(Tsai, 2005), we have shown that the WP identi-
fier can be used to reduce the over weighting 
and corpus sparseness problems of bigram mod-
els and achieve better STW accuracy to improve 
Chinese input systems. As per our computation, 
poly-syllabic words cover about 70% characters 
of Chinese sentences. Since the identified char-
acter ratio of the WP identifier (Tsai, 2005) is 
about 55%, there are still about 15% improving 
room left. 
The objective of this study is to illustrate a 
word support model (WSM) that is able to im-
prove our WP-identifier by achieving better 
identified character ratio and STW accuracy on 
the identified poly-syllabic words with the same 
word-pair database. We conduct STW experi-
ments to show the tonal and toneless STW accu-
racies of a commercial input product (Microsoft 
Input Method Editor 2003, MSIME), and an 
optimized bigram model, BiGram (Tsai, 2005), 
can both be improved by our WSM and achieve 
better STW improvements than that of these 
systems with the WP identifier. 
The remainder of this paper is arranged as 
follows. In Section 2, we present an auto word-
pair (AUTO-WP) generation used to generate 
the WP database. Then, we develop a word sup-
port model with the WP database to perform 
STW conversion on identifying words from the 
Chinese syllables. In Section 3, we report and 
analyze our STW experimental results. Finally, 
in Section 4, we give our conclusions and sug-
gest some future research directions. 
2 Development of Word Support Model 
The system dictionary of our WSM is comprised 
of 82,531 Chinese words taken from the CKIP 
dictionary and 15,946 unknown words auto-
found in the UDN2001 corpus by a Chinese 
Word Auto-Confirmation (CWAC) system (Tsai 
et al, 2003). The UDN2001 corpus is a collec-
tion of 4,539624 Chinese sentences extracted 
from whole 2001 UDN (United Daily News, 
2001) Website in Taiwan (Tsai and Hsu, 2002). 
The system dictionary provides the knowledge 
of words and their corresponding pinyin sylla-
ble-words. The pinyin syllable-words were 
translated by phoneme-to-pinyin mappings, such 
as ????-to-?ju2.? 
2.1 Auto-Generation of WP Database 
Following (Tsai, 2005), the three steps of auto-
generating word-pairs (AUTO-WP) for a given 
Chinese sentence are as below: (the details of 
AUTO-WP can be found in (Tsai, 2005)) 
Step 1. Get forward and backward word seg-
mentations: Generate two types of word 
segmentations for a given Chinese sen-
tence by forward maximum matching 
(FMM) and backward maximum match-
ing (BMM) techniques (Chen et al, 1986; 
Tsai et al, 2004) with the system diction-
ary. 
Step 2. Get initial WP set: Extract all the com-
binations of word-pairs from the FMM 
and the BMM segmentations of Step 1 to 
be the initial WP set. 
Step 3. Get finial WP set: Select out the word-
pairs comprised of two poly-syllabic 
words from the initial WP set into the fin-
ial WP set. For the final WP set, if the 
word-pair is not found in the WP data-
843
base, insert it into the WP database and 
set its frequency to 1; otherwise, increase 
its frequency by 1. 
2.2 Word Support Model 
The four steps of our WSM applied to identify 
words for a given Chinese syllables is as follows: 
Step 1. Input tonal or toneless syllables. 
Step 2. Generate all possible word-pairs com-
prised of two poly-syllabic words for the 
input syllables to be the WP set of Step 3. 
Step 3. Select out the word-pairs that match a 
word-pair in the WP database to be the 
WP set. Then, compute the word sup-
port degree (WS degree) for each dis-
tinct word of the WP set. The WS degree 
is defined to be the total number of the 
word found in the WP set. Finally, ar-
range the words and their corresponding 
WS degrees into the WSM set. If the 
number of words with the same syllable-
word and WS degree is greater than one, 
one of them is randomly selected into the 
WSM set. 
Step 4. Replace words of the WSM set in de-
scending order of WS degree with the in-
put syllables into a WSM-sentence. If no 
words can be identified in the input sylla-
bles, a NULL WSM-sentence is produced. 
Table 1 is a step by step example to show the 
four steps of applying our WSM on the Chinese 
syllables ?sui1 ran2 fu3 shi2 jin4 shi4 sui4 yue4 
xi1 xu1(??????????).? For this 
input syllables, we have a WSM-sentence ??
?????????.? For the same syllables, 
outputs of the MSIME, the BiGram and the WP 
identifier are ???????????,? ???
????????? and ??? fu3 shi2 ??
sui4 yue4 xi1 xu1.? 
3 STW Experiments 
To evaluate the STW performance of our WSM, 
we define the STW accuracy, identified charac-
ter ratio (ICR) and STW improvement, by the 
following equations: 
 
STW accuracy = # of correct characters / # of 
total characters.             (1) 
Identified character ratio (ICR) = # of characters 
of identified WP / # of total characters in testing 
sentences.                                (2) 
STW improvement (I) (i.e. STW error reduction 
rate) = (accuracy of STW system with WP ? 
accuracy of STW system)) / (1 ? accuracy of 
STW system).                                           (3) 
 
Step # Results               
Step.1 sui1 ran2 fu3 shi2 jin4 shi4 sui4 yue4 xi1 xu1  
 (?  ?    ?   ?   ?    ?   ?    ?    ?   ?) 
Step.2 WP set (word-pair / word-pair frequency) =  
{??-??/6 (key WP for WP identifier), 
  ??-??/4, ??-??/4, ??-??/3, 
  ??-??/2, ??-??/2, ??-??/2, 
  ??-??/2, ??-??/2, ??-??/2,  
  ??-??/2} 
Step.3 WSM set (word / WS degree) = 
{??/5, ??/4, ??/4, ??/4, ??/4,  
  ??/1} 
Replaced word set = 
??(sui1 ran2), ??(fu3 shi2),  
??(jin4 shi4), ??(sui4 yue4), 
??(xi1 xu1) 
Step.4 WSM-sentence: 
   ?????????? 
Table 1. An illustration of a WSM-sentence for 
the Chinese syllables ?sui1 ran2 fu3 shi2 jin4 
shi4 sui4 yue4 xi1 xu1(?????????
?).? 
3.1 Background 
To conduct the STW experiments, firstly, use 
the inverse translator of phoneme-to-character 
(PTC) provided in GOING system to convert 
testing sentences into their corresponding sylla-
bles. All the error PTC translations of GOING 
PTC were corrected by post human-editing. 
Then, apply our WSM to convert the testing 
input syllables back to their WSM-sentences. 
Finally, calculate its STW accuracy and ICR by 
Equations (1) and (2). Note that all test sen-
tences are composed of a string of Chinese 
characters in this study. 
The training/testing corpus, closed/open test 
sets and system/user WP database used in the 
following STW experiments are described as 
below: 
844
(1) Training corpus: We used the UDN2001 
corpus as our training corpus, which is a col-
lection of 4,539624 Chinese sentences ex-
tracted from whole 2001 UDN (United Daily 
News, 2001) Website in Taiwan (Tsai and 
Hsu, 2002). 
(2) Testing corpus: The Academia Sinica Bal-
anced (AS) corpus (Chinese Knowledge In-
formation Processing Group, 1996) was 
selected as our testing corpus. The AS corpus 
is one of most famous traditional Chinese cor-
pus used in the Chinese NLP research field 
(Thomas, 2005). 
(3) Closed test set: 10,000 sentences were ran-
domly selected from the UDN2001 corpus as 
the closed test set. The {minimum, maximum, 
and mean} of characters per sentence for the 
closed test set are {4, 37, and 12}. 
(4) Open test set: 10,000 sentences were ran-
domly selected from the AS corpus as the 
open test set. At this point, we checked that 
the selected open test sentences were not in 
the closed test set as well. The {minimum, 
maximum, and mean} of characters per sen-
tence for the open test set are {4, 40, and 11}. 
(5) System WP database: By applying the 
AUTO-WP on the UDN2001 corpus, we cre-
ated 25,439,679 word-pairs to be the system 
WP database. 
(6) User WP database: By applying our 
AUTO-WP on the AS corpus, we created 
1,765,728 word-pairs to be the user WP data-
base. 
 
We conducted the STW experiment in a pro-
gressive manner. The results and analysis of the 
experiments are described in Subsections 3.2 
and 3.3. 
3.2 STW Experiment Results of the WSM 
The purpose of this experiment is to demon-
strate the tonal and toneless STW accuracies 
among the identified words by using the WSM 
with the system WP database. The comparative 
system is the WP identifier (Tsai, 2005). Table 
2 is the experimental results. The WP database 
and system dictionary of the WP identifier is 
same with that of the WSM. 
From Table 2, it shows the average tonal and 
toneless STW accuracies and ICRs of the WSM 
are all greater than that of the WP identifier. 
These results indicate that the WSM is a better 
way than the WP identifier to identify poly-
syllabic words for the Chinese syllables. 
 
    Closed   Open    Average (ICR)          
Tonal (WP)    99.1%    97.7%    98.5% (57.8%) 
Tonal (WSM)    99.3%    97.9%    98.7% (71.3%) 
Toneless (WP)     94.0%    87.5%    91.3% (54.6%) 
Toneless (WSM)    94.4%    88.1%    91.6% (71.0%) 
Table 2. The comparative results of tonal and 
toneless STW experiments for the WP identifier 
and the WSM. 
3.3 STW Experiment Results of Chinese 
Input Systems with the WSM 
We selected Microsoft Input Method Editor 
2003 for Traditional Chinese (MSIME) as our 
experimental commercial Chinese input system. 
In addition, following (Tsai, 2005), an opti-
mized bigram model called BiGram was devel-
oped. The BiGram STW system is a bigram-
based model developing by SRILM (Stolcke, 
2002) with Good-Turing back-off smoothing 
(Manning and Schuetze, 1999), as well as for-
ward and backward longest syllable-word first 
strategies (Chen et al, 1986; Tsai et al, 2004). 
The system dictionary of the BiGram is same 
with that of the WP identifier and the WSM. 
Table 3a compares the results of the MSIME, 
the MSIME with the WP identifier and the 
MSIME with the WSM on the closed and open 
test sentences. Table 3b compares the results of 
the BiGram, the BiGram with the WP identifier 
and the BiGram with the WSM on the closed 
and open test sentences. In this experiment, the 
STW output of the MSIME with the WP identi-
fier and the WSM, or the BiGram with the WP 
identifier and the WSM, was collected by di-
rectly replacing the identified words of the WP 
identifier and the WSM from the corresponding 
STW output of the MSIME and the BiGram. 
 
    Ms         Ms+WP (I)a         Ms+WSM (I)b 
Tonal     94.5%    95.5% (18.9%)    95.9% (25.6%) 
Toneless    85.9%    87.4% (10.1%)    88.3% (16.6%) 
a STW accuracies and improvements of the words identi-
fied by the MSIME (Ms) with the WP identifier 
b STW accuracies and improvements of the words identi-
fied by the MSIME (Ms) with the WSM 
Table 3a. The results of tonal and toneless STW 
experiments for the MSIME, the MSIME with 
the WP identifier and with the WSM. 
845
 
    Bi          Bi+WP (I)a        Bi+WSM (I)b 
Tonal     96.0%    96.4% (8.6%)     96.7% (17.1%)  
Toneless    83.9%    85.8% (11.9%)    87.5% (22.0%)  
a STW accuracies and improvements of the words identi-
fied by the BiGram (Bi) with the WP identifier 
b STW accuracies and improvements of the words identi-
fied by the BiGram (Bi) with the WSM 
Table 3b. The results of tonal and toneless STW 
experiments for the BiGram, the BiGram with 
the WP identifier and with the WSM. 
 
From Table 3a, the tonal and toneless STW 
improvements of the MSIME by using the WP 
identifier and the WSM are (18.9%, 10.1%) and 
(25.6%, 16.6%), respectively. From Table 3b, 
the tonal and toneless STW improvements of 
the BiGram by using the WP identifier and the 
WSM are (8.6%, 11.9%) and (17.1%, 22.0%), 
respectively. (Note that, as per (Tsai, 2005), the 
differences between the tonal and toneless STW 
accuracies of the BiGram and the TriGram are 
less than 0.3%). 
Table 3c is the results of the MSIME and the 
BiGram by using the WSM as an adaptation 
processing with both system and user WP data-
base. From Table 3c, we get the average tonal 
and toneless STW improvements of the MSIME 
and the BiGram by using the WSM as an adap-
tation processing are 37.2% and 34.6%, respec-
tively. 
 
  Ms+WSM (ICR, I)a   Bi+WSM (ICR, I) b          
Tonal   96.8% (71.4%, 41.7%)   97.3% (71.4%, 32.6%) 
Toneless  90.6% (74.6%, 33.2%)   97.3% (74.9%, 36.0%) 
a STW accuracies, ICRs and improvements of the words 
identified by the MSIME (Ms) with the WSM 
b STW accuracies, ICRs and improvements of the words 
identified by the BiGram (Bi) with the WSM 
Table 3c. The results of tonal and toneless STW 
experiments for the MSIME and the BiGram 
using the WSM as an adaptation processing. 
 
To sum up the above experiment results, we 
conclude that the WSM can achieve a better 
STW accuracy than that of the MSIME, the Bi-
Gram and the WP identifier on the identified-
words portion. (Appendix A presents two cases 
of STW results that were obtained from this 
study). 
3.4 Error Analysis 
We examine the Top 300 STW conversions in 
the tonal and toneless from the open testing re-
sults of the BiGram with the WP identifier and 
the WSM, respectively. As per our analysis, the 
STW errors are caused by three problems, they 
are: 
 (1) Unknown word (UW) problem: For Chinese 
NLP systems, unknown word extraction is 
one of the most difficult problems and a 
critical issue. When an STW error is caused 
only by the lack of words in the system dic-
tionary, we call it unknown word problem. 
(2) Inadequate Syllable-Word Segmentation 
(ISWS) problem: When an error is caused 
by ambiguous syllable-word segmentation 
(including overlapping and combination 
ambiguities), we call it inadequate syllable-
word segmentation problem. 
(3) Homophone selection problem: The remain-
ing STW conversion error is homophone 
selection problem. 
 
Problem                      Coverage      
   Tonal              Toneless 
   WP, WSM             WP, WSM 
UW          3%,  4%             3%,   4% 
ISWS   32%, 32%          58%, 56%  
HS   65%, 64%          39%, 40% 
# of error characters 170, 153             506, 454 
# of error characters of 100, 94              159, 210 
mono-syllabic words 
# of error characters of     70, 59              347, 244 
  poly-syllabic words 
Table 4. The analysis results of the STW errors 
from the Top 300 tonal and toneless STW con-
versions of the BiGram with the WP identifier 
and the WSM. 
 
Table 4 is the analysis results of the three STW 
error types. From Table 4, we have three obser-
vations:  
(1) The coverage of unknown word problem for 
tonal and toneless STW conversions is 
similar. In most Chinese input systems, un-
known word extraction is not specifically a 
STW problem, therefore, it is usually taken 
care of through online and offline manual 
editing processing (Hsu et al 1999). The 
results of Table 4 show that the most STW 
errors should be caused by ISWS and HS 
846
problems, not UW problem. This observa-
tion is similarly with that of our previous 
work (Tsai, 2005). 
(2) The major problem of error conversions in 
tonal and toneless STW systems is differ-
ent. This observation is similarly with that 
of (Tsai, 2005). From Table 4, the major 
improving targets of tonal STW perform-
ance are the HS errors because more than 
50% tonal STW errors caused by HS prob-
lem. On the other hand, since the ISWS er-
rors cover more than 50% toneless STW 
errors, the major targets of improving tone-
less STW performance are the ISWS errors. 
(3) The total number of error characters of the 
BiGram with the WSM in tonal and tone-
less STW conversions are both less than 
that of the BiGram with the WP identifier. 
This observation should answer the ques-
tion ?Why the STW performance of Chi-
nese input systems (MSIME and BiGram) 
with the WSM is better than that of these 
systems with the WP-identifier?? 
To sum up the above three observations and all 
the STW experimental results, we conclude that 
the WSM is able to achieve better STW im-
provements than that of the WP identifier is be-
cause: (1) the identified character ratio of the 
WSM is 15% greater than that of the WP identi-
fier with the same WP database and dictionary, 
and meantime (2) the WSM not only can main-
tain the ratio of the three STW error types but 
also can reduce the total number of error charac-
ters of converted words than that of the WP 
identifier. 
4 Conclusions and Future Directions 
In this paper, we present a word support model 
(WSM) to improve the WP identifier (Tsai, 
2005) and support the Chinese Language Proc-
essing on the STW conversion problem. All of 
the WP data can be generated fully automati-
cally by applying the AUTO-WP on the given 
corpus. We are encouraged by the fact that the 
WSM with WP knowledge is able to achieve 
state-of-the-art tonal and toneless STW accura-
cies of 99% and 92%, respectively, for the iden-
tified poly-syllabic words. The WSM can be 
easily integrated into existing Chinese input 
systems by identifying words as a post process-
ing. Our experimental results show that, by ap-
plying the WSM as an adaptation processing 
together with the MSIME (a trigram-like model) 
and the BiGram (an optimized bigram model), 
the average tonal and toneless STW improve-
ments of the two Chinese input systems are 
37% and 35%, respectively. 
Currently, our WSM with the mixed WP da-
tabase comprised of UDN2001 and AS WP da-
tabase is able to achieve more than 98% 
identified character ratios of poly-syllabic 
words in tonal and toneless STW conversions 
among the UDN2001 and the AS corpus. Al-
though there is room for improvement, we be-
lieve it would not produce a noticeable effect as 
far as the STW accuracy of poly-syllabic words 
is concerned. 
We will continue to improve our WSM to 
cover more characters of the UDN2001 and the 
AS corpus by those word-pairs comprised of at 
least one mono-syllabic word, such as ???
(we)-?(are)?. In other directions, we will ex-
tend it to other Chinese NLP research topics, 
especially word segmentation, main verb identi-
fication and Subject-Verb-Object (SVO) auto-
construction. 
References 
Becker, J.D. 1985. Typing Chinese, Japanese, and 
Korean, IEEE Computer 18(1):27-34. 
Chang, J.S., S.D. Chern and C.D. Chen. 1991. Con-
version of Phonemic-Input to Chinese Text 
Through Constraint Satisfaction, Proceedings 
of ICCPOL'91, 30-36. 
Chen, B., H.M. Wang and L.S. Lee. 2000. Retrieval 
of broadcast news speech in Mandarin Chinese 
collected in Taiwan using syllable-level statisti-
cal characteristics, Proceedings of the 2000 In-
ternational Conference on Acoustics Speech 
and Signal Processing. 
Chen, C.G., Chen, K.J. and Lee, L.S. 1986. A model 
for Lexical Analysis and Parsing of Chinese 
Sentences, Proceedings of 1986 International 
Conference on Chinese Computing, 33-40. 
Chien, L.F., Chen, K.J. and Lee, L.S. 1993. A Best-
First Language Processing Model Integrating 
the Unification Grammar and Markov Lan-
guage Model for Speech Recognition Applica-
tions, IEEE Transactions on Speech and Audio 
Processing, 1(2):221-240. 
Chung, K.H. 1993. Conversion of Chinese Phonetic 
Symbols to Characters, M. Phil. thesis, De-
partment of Computer Science, Hong Kong 
847
University of Science and Technology. 
Chinese Knowledge Information Processing Group. 
1995. Technical Report no. 95-02, the content 
and illustration of Sinica corpus of Academia 
Sinica. Institute of Information Science, Aca-
demia Sinica. 
Chinese Knowledge Information Processing Group. 
1996. A study of Chinese Word Boundaries and 
Segmentation Standard for Information proc-
essing (in Chinese). Technical Report, Taiwan, 
Taipei, Academia Sinica. 
Fong, L.A. and K.H. Chung. 1994. Word Segmenta-
tion for Chinese Phonetic Symbols, Proceed-
ings of International Computer Symposium, 
911-916. 
Fu, S.W.K, C.H. Lee and Orville L.C. 1996. A Sur-
vey on Chinese Speech Recognition, Communi-
cations of COLIPS, 6(1):1-17. 
Gao, J., Goodman, J., Li, M. and Lee K.F. 2002. To-
ward a Unified Approach to Statistical Lan-
guage Modeling for Chinese, ACM 
Transactions on Asian Language Information 
Processing, 1(1):3-33. 
Gu, H.Y., C.Y. Tseng and L.S. Lee. 1991. Markov 
modeling of mandarin Chinese for decoding the 
phonetic sequence into Chinese characters, 
Computer Speech and Language 5(4):363-377. 
Ho, T.H., K.C. Yang, J.S. Lin and L.S. Lee. 1997. 
Integrating long-distance language modeling to 
phonetic-to-text conversion, Proceedings of 
ROCLING X International Conference on 
Computational Linguistics, 287-299. 
Hsu, W.L. and K.J. Chen. 1993. The Semantic Analy-
sis in GOING - An Intelligent Chinese Input 
System, Proceedings of the Second Joint Con-
ference of Computational Linguistics, Shiamen, 
1993, 338-343. 
Hsu, W.L. 1994. Chinese parsing in a phoneme-to-
character conversion system based on semantic 
pattern matching, Computer Processing of Chi-
nese and Oriental Languages 8(2):227-236. 
Hsu, W.L. and Chen, Y.S. 1999. On Phoneme-to-
Character Conversion Systems in Chinese 
Processing, Journal of Chinese Institute of 
Engineers, 5:573-579. 
Huang, J.K. 1985. The Input and Output of Chinese 
and Japanese Characters, IEEE Computer 
18(1):18-24. 
Kuo, J.J. 1995. Phonetic-input-to-character conver-
sion system for Chinese using syntactic connec-
tion table and semantic distance, Computer 
Processing and Oriental Languages, 10(2):195-
210. 
Lee, L.S., Tseng, C.Y., Gu, H..Y., Liu F.H., Chang, 
C.H., Lin, Y.H., Lee, Y., Tu, S.L., Hsieh, S.H., 
and Chen C.H. 1993. Golden Mandarin (I) - A 
Real-Time Mandarin Speech Dictation Machine 
for Chinese Language with Very Large Vocabu-
lary, IEEE Transaction on Speech and Audio 
Processing, 1(2). 
Lee, C.W., Z. Chen and R.H. Cheng. 1997. A pertur-
bation technique for handling handwriting 
variations faced in stroke-based Chinese char-
acter classification, Computer Processing of 
Oriental Languages, 10(3):259-280. 
Lee, Y.S. 2003. Task adaptation in Stochastic Lan-
guage Model for Chinese Homophone Disam-
biguation, ACM Transactions on Asian 
Language Information Processing, 2(1):49-62. 
Lin, M.Y. and W.H. Tasi. 1987. Removing the ambi-
guity of phonetic Chinese input by the relaxa-
tion technique, Computer Processing and 
Oriental Languages, 3(1):1-24. 
Lua, K.T. and K.W. Gan. 1992. A Touch-Typing Pin-
yin Input System, Computer Processing of Chi-
nese and Oriental Languages, 6:85-94. 
Manning, C. D. and Schuetze, H. 1999. Fundations 
of Statistical Natural Language Processing, 
MIT Press: 191-220. 
Microsoft Research Center in Beijing, 
?http://research.microsoft.com/aboutmsr/labs/b
eijing/? 
Qiao, J., Y. Qiao and S. Qiao. 1984. Six-Digit Coding 
Method, Commun. ACM 33(5):248-267. 
Sproat, R. 1990. An Application of Statistical Opti-
mization with Dynamic Programming to Pho-
nemic-Input-to-Character Conversion for 
Chinese, Proceedings of ROCLING III, 379-
390. 
Stolcke A. 2002. SRILM - An Extensible Language 
Modeling Toolkit, Proc. Intl. Conf. Spoken 
Language Processing, Denver. 
Su, K.Y., Chiang, T.H. and Lin, Y.C. 1992. A Uni-
fied Framework to Incorporate Speech and 
Language Information in Spoken Language 
Processing, ICASSP-92, 185-188. 
Thomas E. 2005. The Second International Chinese 
Word Segmentation Bakeoff, In Proceedings of 
the Fourth SIGHAN Workshop on Chinese Lan-
guage Processing, Oct. Jeju, Koera, 123-133. 
Tsai, J.L. and W.L. Hsu. 2002. Applying an NVEF 
Word-Pair Identifier to the Chinese Syllable-to-
Word Conversion Problem, Proceedings of 19th 
COLING 2002, 1016-1022. 
Tsai, J,L, Sung, C.L. and Hsu, W.L. 2003. Chinese 
Word Auto-Confirmation Agent, Proceedings 
of ROCLING XV, 175-192. 
848
Tsai, J.L., Hsieh, G. and Hsu, W.L. 2004. Auto-
Generation of NVEF knowledge in Chinese, 
Computational Linguistics and Chinese Lan-
guage Processing, 9(1):41-64. 
Tsai, J.L. 2005. Using Word-Pair Identifier to Im-
prove Chinese Input System, Proceedings of 
the Fourth SIGHAN Workshop on Chinese 
Language Processing, IJCNLP2005, 9-16. 
United Daily News. 2001. On-Line United Daily 
News, http://udnnews.com/NEWS/ 
Appendix A. Two cases of the STW re-
sults used in this study. 
Case I.  
(a) Tonal STW results for the Chinese tonal syl-
lables ?guan1 yu2 liang4 xing2 suo3 sheng1 
zhi1 shi4 shi2? of the Chinese sentence ????
??????? 
Methods  STW results 
WP set  ??-??/4  (key WP), 
  ??-??/3, ??-??/1, 
   ??-??/1 
WSM Set ??(guan1 yu2)/3, ??(liang4 xing2)/2, 
  ??(shi4 shi2)/2, ??(zhi1 shi4)/1 
WP-sentence ?? liang4 xing2 suo3 sheng1?? shi2 
WSM-sentence ???? suo3 sheng1 zhi1?? 
MSIME  ????????? 
MSIME+WP ????????? 
MSIME+WSM      ?????????  
BiGram  ????????? 
BiGram+WP ????????? 
BiGram+WSM ????????? 
 
(b) Toneless STW results for the Chinese tone-
less syllables ?guan yu liang xing suo sheng zhi 
shi shi? of the Chinese sentence ???????
???? 
Methods  STW results 
WP set  ??/??/4 (key WP), 
??/??/4, ??/??/3, 
??/??/2, ??/??/2, 
??/??/2, ??/??/1, 
??/??/1, ??/??/1, 
??/??/1, ??/??/1, 
??/??/1 
WSM Set ??(guan yu)/7, ??(shi shi)/4, 
??(liang xing)/3, ??(liang xing)/2, 
??(zhi shi)/2, ??(shi shi)/2, 
??(shi shi)/1, ??(guan yu)/1, 
??(shengzhi)/1 
WP-sentence ?? liang xing suo sheng zhi?? 
WSM-sentence ???? suo???? 
MSIME  ????????? 
MSIME+WP ????????? 
MSIME+WSM      ????????? 
BiGram  ????????? 
BiGram+WP ????????? 
BiGram+WSM ????????? 
 
Case II.  
(a) Tonal STW results for the Chinese tonal syl-
lables ?you2 yu2 xian3 he4 de5 jia1 shi4? of the 
Chinese sentence ????????? 
Methods  STW results 
WP set  ??/??/6 (key WP), 
  ??/??/2, ??/??/2 
  ??/??/1, ??/??/1 
WSM set  ??(you2 yu2)/4, ??(xian 3he4)/2,  
  ??(jia1 shi4)/2, ??(jia1 shi4)/1 
WP-sentence ?? xian2 he4 de5?? 
WSM-sentence ???? de?? 
MSIME  ??????? 
MSIME+WP ??????? 
MSIME+SWM      ???????  
BiGram  ??????? 
BiGram+WP ??????? 
BiGram+SWM ??????? 
 
(b) Toneless STW results for the Chinese tone-
less syllables ?you yu xian he de jia shi? of the 
Chinese sentence ????????? 
Methods  STW results 
WP set  ??-??/14 (key WP), 
  ??-??/6, ??-??/6 
  ??/??/2, ??/??/2 
  ??/??/1, ??/??/1 
WSM set  ??(you yu)/6, ??(xian he)/2,  
  ??(jia shi)/2, ??(jia shi)/1 
WP-sentence ?? xian he de?? 
WSM-sentence ???? de?? 
MSIME  ??????? 
MSIME+WP ??????? 
MSIME+SWM      ???????  
BiGram  ??????? 
BiGram+WP ??????? 
BiGram+SWM ??????? 
849
Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 130?133,
Sydney, July 2006. c?2006 Association for Computational Linguistics
BMM-based Chinese Word Segmentor with Word Support Model for 
the SIGHAN Bakeoff 2006 
Jia-Lin Tsai 
Tung Nan Institute of Technology, Department of Information Management 
 Taipei 222, Taiwan, R.O.C. 
tsaijl@mail.tnit.edu.tw 
 
 
Abstract 
This paper describes a Chinese word 
segmentor (CWS) for the third Inter-
national Chinese Language Processing 
Bakeoff (SIGHAN Bakeoff 2006). We 
participate in the word segmentation 
task at the Microsoft Research (MSR) 
closed testing track. Our CWS is based 
on backward maximum matching with 
word support model (WSM) and con-
textual-based Chinese unknown word 
identification. From the scored results 
and our experimental results, it shows 
WSM can improve our previous CWS, 
which was reported at the SIGHAN 
Bakeoff 2005, about 1% of F-measure. 
1 Introduction 
A high-performance Chinese word segmentor 
(CWS) is a critical processing stage to produce 
an intermediate result for later processes, such 
as search engines, text mining, word spell 
checking, text-to-speech and speech recognition, 
etc. As per (Lin et al 1993; Tsai et al 2003; Tsai, 
2005), the bottleneck for developing a high-
performance CWS is to comprise of high per-
formance Chinese unknown word identification 
(UWI). It is because Chinese is written without 
any separation between words and more than 
50% words of the Chinese texts in web corpus 
are out-of-vocabulary (Tsai et al 2003). In our 
report for the SIGHAN Bakeoff 2005 (Tsai, 
2005), we have shown that a highly performance 
of 99.1% F-measure can be achieved while a 
BMM-based CWS using a perfect system dic-
tionary (Tsai, 2005). A perfect system dictionary 
means all word types of the dictionary are ex-
tracted from training and testing gold standard 
corpus. 
Conventionally, there are four approaches to 
develop a CWS: (1) Dictionary-based ap-
proach (Cheng et al 1999), especial forward 
and backward maximum matching (Wong  and 
Chan, 1996); (2) Linguistic approach based on 
syntax-semantic knowledge (Chen et al 2002); 
(3) Statistical approach based on statistical lan-
guage model (SLM) (Sproat and Shih, 1990; 
Teahan et al 2000; Gao et al 2003); and (4) 
Hybrid approach trying to combine the bene-
fits of dictionary-based, linguistic and statistical 
approaches (Tsai et al 2003; Ma and Chen, 
2003). In practice, statistical approaches are 
most widely used because their effective and 
reasonable performance. 
To develop UWI, there are three approaches: 
(1) Statistical approach, researchers use com-
mon statistical features, such as maximum en-
tropy (Chieu et al 2002), association strength, 
mutual information, ambiguous matching, and 
multi-statistical features for unknown word de-
tection and extraction; (2) Linguistic approach, 
three major types of linguistic rules (knowledge): 
morphology, syntax, and semantics, are used to 
identify unknown words; and (3) Hybrid ap-
proach, recently, one important trend of UWI 
follows a hybrid approach so as to take advan-
tage of both merits of statistical and linguistic 
approaches. Statistical approaches are simple 
and efficient whereas linguistic approaches are 
effective in identifying low frequency unknown 
words (Chen et al 2002).  
To develop WSD, there are two major types 
of word segmentation ambiguities while there 
are no unknown word problems with them: (1) 
Overlap Ambiguity (OA). Take string C1C2C3 
130
comprised of three Chinese characters C1, C2 
and C3 as an example. If its segmentation can be 
either C1C2/C3 or C1/C2C3 depending on con-
text meaning, the C1C2C3 is called an overlap 
ambiguity string (OAS), such as ???(a gen-
eral)/?(use)? and ??(to get)/??(for military 
use)? (the symbol ?/? indicates a word bound-
ary). (2) Combination Ambiguity (CA).  Take 
string C1C2 comprised of two Chinese charac-
ters C1 and C2 as an example. If its segmenta-
tion can be either C1/C2 or C1C2 depending on 
context meaning, the C1C2 is called a combina-
tion ambiguity string (CAS), such as ??(just)/
?(can)? and ???(ability).? Besides the OA 
and CA problems, the other two types of word 
segmentation errors are caused by unknown 
word problems. They are: (1) Lack of unknown 
word (LUW), it means segmentation error oc-
curred by lack of an unknown word in the sys-
tem dictionary, and (2) Error identified word 
(EIW), it means segmentation error occurred by 
an error identified unknown words. 
The goal of this paper is to report the ap-
proach and experiment results of our backward 
maximum matching-based (BMM-based) CWS 
with word support model (WSM) for the 
SIGHAN Bakeoff 2006. In (Tsai, 2006), WSM 
has been shown effectively to improve Chinese 
input system. In the third Bakeoff, our CWS is 
mainly addressed on improving its performance 
of OA/CA disambiguation by WSM. We show 
that WSM is able to improve our BMM-based 
CWS, which reported at the SIGHAN Bakeoff 
2005, about 1% of F-measure. 
The remainder of this paper is arranged as 
follows. In Section 2, we present the details of 
our BMM-based CWS comprised of WSM. In 
Section 3, we present the scored results of the 
CWS at the Microsoft Research closed track and 
give our experiment results and analysis. Finally, 
in Section 4, we give our conclusions and future 
research directions. 
2 BMM-based CWS with WSM 
From our work (Tsai et al 2004), the Chinese 
word segmentation performance of BMM tech-
nique is about 1% greater than that of forward 
maximum matching (FMM) technique. Thus, we 
adopt BMM technique as base to develop our 
CWS. In this Bakeoff, we use context-based 
Chinese unknown word identification (CCUWI) 
(Tsai, 2005) to resolve unknown word problem. 
The CCUWI uses template matching technique 
to extract unknown words from sentences. The 
context template includes triple context template 
(TCT) and word context template (WCT). The 
details of the CCUWI can be found in (Tsai, 
2005). In (Tsai, 2006), we propose a new lan-
guage model named word support model (WSM) 
and shown it can effectively perform homo-
phone selection and word-syllable segmentation 
to improve Chinese input system. For this Bake-
off, we use WSM to resolve OA/CA problems. 
The two steps of our BMM-based CWS with 
WSM are as below: 
Step 1. Generate the BMM segmentation for the 
given Chinese sentence by system dictionary.  
Step 2. Use WSM to resolve OA/CA problems 
for the BMM segmentation of Step 1. Now, 
we give a brief description of how we use 
WSM to resolve OA/CA problem. Firstly, we 
pre-collect OA/CA pattern-pairs (such as ??/
??-????) by compare each training gold 
segmentation and its corresponding BMM 
segmentation. The pattern of OA/CA pattern-
pairs can be a segmentation pattern, such as 
??/?,? or just a word, such as ???.? Sec-
ondly, for a BMM segmentation of Step 1, if 
one pattern matching (matching pattern) with 
at least one pattern of those pre-collected 
OA/CA pattern-pairs (matching OA/CA pat-
tern-pairs), CWS will compute the word sup-
port degree for each pattern of the matching 
OA/CA pattern-pair. Finally, select out the 
pattern with maximum word support degree as 
its segmentation for the matching pattern. If 
the patterns of the matching OA/CA pattern-
pair having the same word support degree, 
randomly select one to be its segmentation. 
The details of WSM can be found in (Tsai, 
2006). 
3 Scored Results and Our Experiments 
In the SIGHAN Bakeoff 2006, there are four 
training corpus for word segmentation (WS) 
task: AS (Academia Sinica) and CU (City Uni-
versity of Hong Kong) are traditional Chinese 
corpus; PU (Peking University) and Microsoft 
Research (MSR) are simplified Chinese corpus. 
And, for each corpus, there are closed and open 
131
track. In the Bakeoff 2006, we attend the Micro-
soft Research closed (MSR_C) track. 
3.1 Scored Results and our Experiments 
Tables 1a and 1b show the details of MSR train-
ing and testing corpus for 2nd (2005) and 3rd 
(2006) bakeoff. From Table 1a and 1b, it indi-
cates that MSR track of 3rd bakeoff seems to be 
a more difficult WS task than that of 2nd bakeoff, 
since (1) the training size of 2nd bakeoff is two 
times as great as that of 3rd bakeoff; (2) in train-
ing data, the word type number of 3rd bakeoff is 
less than that of 2nd bakeoff, and (3) in testing 
data, the word type number of 3rd bakeoff is 
greater than that of 2nd bakeoff. 
 
  Training  Testing 
Sentences 86,924  3,985 
Word types 88,119  12,924 
Words  2,368,391 109,002 
Character types 5,167  2,839 
Characters 4,050,469 184,356 
Table 1a. Details of MSR_C corpus of 2nd bake-
off. 
 
  Training  Testing 
Sentences 46,364  4356 
Word types 63,494  13,461 
Words  1,266,169 100,361 
Character types 4,767  3,103   
Characters 2,169879 172,601 
Table 1b. Details of MSR_C corpus of 3rd bake-
off. 
 
Table 2 shows the scored results of our CWS 
at the MSR_C track of this bakeoff. In Table 2, 
the symbols a, b and c stand for the CWS with a, 
b and c system dictionary. The system diction-
ary ?a? is the dictionary comprised of all word 
types found in the MSR training corpus. The 
system dictionary ?b? is the dictionary com-
prised of ?a? system dictionary and the word 
types found in the testing corpus by CCUWI 
with TCT knowledge. The system dictionary ?c? 
is the dictionary comprised of ?a? system dic-
tionary and the word types found in the testing 
corpus by CCUWI with TCT and WCT knowl-
edge. Table 3 is F-measure differences between 
the BMM-based CWS system and it with WSM 
and CCUWI using ?a?, ?b? and ?c? system dic-
tionary in the MSR_C track. 
From Tables 2 and 3, we conclude that our 
CWS of 3rd bakeoff improve the CWS of 2nd 
bakeoff about 1.8% of F-measure. Among the 
1.8% F-measure improvement, 1% is contrib-
uted by WSM for resolving OA/CA problems 
and the other 0.8% is contributed by CCUWI for 
resolving UWI problem. 
 
System R P F ROOV RIV 
a 0.949 0.897 0.922 0.022 0.982 
b 0.954  0.921  0.937  0.163  0.981 
c 0.950  0.930  0.940  0.272  0.974 
Table 2. The scored results of our CWS in the 
MSR_C track (OOV is 0.034) for 3rd bakeoff. 
 
System  R P F Improve 
a1.BMM 0.949 0.897 0.922   
a2.BMM+WSM 0.958 0.907 0.932 0.010 
b1.BMM 0.946 0.911 0.928  
b2.BMM+WSM 0.954  0.921  0.937 0.009 
c1.BMM 0.938 0.920 0.929  
c2.BMM+WSM 0.950  0.930  0.940 0.011 
Table 3. The F-measure improvement between 
the BMM-based CWS and it with WSM in the 
MSR_C track (OOV is 0.034) using a, b, and c 
system dictionary. 
3.2 Error Analysis 
Table 4 shows the F-measure and ROOV differ-
ences between each result of our CWS with a, b 
and c system dictionaries. From Table 4, it indi-
cates that the most contribution for increasing 
the overall performance (F-measure) of our 
CWS is occurred while our CWS comprised of 
WSM and CCUWI with TCT knowledge. 
 
System F F(d) ROOV ROOV(d) 
a 0.922  - 0.022  - 
b 0.937 0.015 0.163 0.141 
c 0.940  0.003 0.272  0.109 
Table 4. The differences of F-measure and 
ROOV between near-by steps of our CWS. 
 
       OA              CA               LUW              EIW 
a      667(389)     403(194)      3268(2545)    0(0)    
c      160(147)     231(150)      2310(1887)    805(605) 
Table 5. The number of OAS (types), CAS 
(types), LUW (types) and EIW (types) for our 
CWS. 
 
132
Table 5 shows the distributions of four seg-
mentation error types (OA, CA, LUW and EIW) 
for each result of our CWS with a and c system 
dictionaries. From Table 5, it shows CCUWI 
with the knowledge of TCT and WCT can be 
used to optimize the LUW-EIW tradeoff. More-
over, it shows that WSM can effectively to re-
duce the number of OA/CA segmentation errors 
from 1,070 to 391. 
4 Conclusions and Future Directions 
In this paper, we have applied a BMM-based 
CWS comprised of a context-based UWI and 
word support model to the Chinese word seg-
mentation. While we repeat the CWS with the 
MSR_C track data of 2nd bakeoff, we obtained 
96.3% F-measure, which is 0.8% greater than 
that (95.5%) of our CWS at 2nd bakeoff. To sum 
up the results of this study, we have following 
conclusions and future directions: 
(1) UWI and OA/CA problems could be in-
dependent tasks for developing a CWS. 
The experiment results of this study support 
this observation. It is because we found 1% 
improvement is stable contributed by WSM 
and the other 0.8% improvement is stable 
contributed by the CCUWI while the BMM-
based CWS with difference a, b and c sys-
tem dictionaries and different MSR_C train-
ing and testing data of  2nd and 3rd bakeoff. 
(2) About 89% of segmentation errors of our 
CWS caused by unknown word problem. In 
the 89%, we found 66% is LUW problem 
and 23% is EIW problem. This result indi-
cates that the major target to improve our 
CWS is CCUWI. The result also supports 
that a high performance CWS is relied on a 
high performance Chinese UWI (Tsai, 2005). 
(3) We will continue to expand our CWS with 
other unknown word identification tech-
niques, especially applying n-gram extractor 
with the TCT and WCT template matching 
technique to improve our CCUWI for at-
tending the fourth SIGHAN Bakeoff. 
References 
Chen, Keh-Jiann and Wei-Yun, Ma. 2002. Unknown 
Word Extraction for Chinese Documents, Pro-
ceedings of 19th COLING 2002, Taipei, 169-
175. 
Cheng, Kowk-Shing, Gilbert H. Yong and Kam-Fai 
Wong.. 1999. A study on word-based and in-
tegral-bit Chinese text compression algorithms. 
JASIS, 50(3): 218-228. 
Chieu, H.L. and H.T. Ng. 2002. Named Entity Rec-
ognition: A Maximum Entropy Approach Us-
ing Global Information. Proceedings of 19th 
COLING 2002, Taipei, 190-196. 
Gao, Jianfeng, Mu Li and Chang-Ning uang. 2003. 
Improved Source-Channel Models for Chinese 
Word Segmentation. Proceedings of the 41st 
Annual Meeting of the Association for Compu-
tational Linguistics, 272-279. 
Lin, Ming-Yu, Tung-Hui Chiang and Keh-Yi Su. 
1993. A preliminary study on unknown word 
problem in Chinese word segmentation. 
ROCLING 6, 119-141. 
Ma, Wei-Yun and Keh-Jiann Chen, 2003, "Introduc-
tion to CKIP Chinese Word Segmentation 
System for the First International Chinese 
Word Segmentation Bakeoff", Proceedings of 
ACL, Second SIGHAN Workshop on Chinese 
Language Processing, pp168-171. 
Sproat, R. and C., Shih. 1990. A Statistical Method 
for Finding Word Boundaries in Chinese Text. 
Computer proceeding of Chinese and Oriental 
Language, 4(4):336 349. 
Teahan, W. J., Yingying Wen, Rodger McNad and 
Ian Witten. 2000. A compression-based algo-
rithm for Chinese word segmentation. Compu-
tational Linguistics, 26(3): 375-393. 
Tsai, Jia-Lin, C.L., Sung and W.L., Hsu. 2003. Chi-
nese Word Auto-Confirmation Agent, Pro-
ceedings of ROCLING XV, Taiwan, 175-192. 
Tsai, Jia-Lin, G., Hsieh and W.L., Hsu. 2004. Auto-
Generation of NVEF knowledge in Chinese, 
Computational Linguistics and Chinese Lan-
guage Processing, 9(1):41-64. 
Tsai, Jia-Lin. 2005. A Study of Applying BTM 
Model on the Chinese Chunk Bracketing. Pro-
ceedings of IJCNLP, 6th International Work-
shop on Linguistically Interpreted Corpora, 
Jeju Island. 
Tsai, Jia-Lin. 2006. Using Word Support Model to 
Improve Chinese Input System. Proceedings 
of ACL/COLING 2006, Sydney. 
Wong, Pak-Kwong and Chorkin ChanWong. 1996. 
Chinese Word Segmentation. based on Maxi-
mum Matching and Word Binding Force. Pro-
ceedings of the 16th International conference 
on Computational linguistic, 1:200-203. 
133
