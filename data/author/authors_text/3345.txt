Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 868?876, Prague, June 2007. c?2007 Association for Computational Linguistics
Factored Translation Models
Philipp Koehn and Hieu Hoang
pkoehn@inf.ed.ac.uk, H.Hoang@sms.ed.ac.uk
School of Informatics
University of Edinburgh
2 Buccleuch Place, Edinburgh EH8 9LW
Scotland, United Kingdom
Abstract
We present an extension of phrase-based
statistical machine translation models that
enables the straight-forward integration of
additional annotation at the word-level ?
may it be linguistic markup or automati-
cally generated word classes. In a num-
ber of experiments we show that factored
translation models lead to better transla-
tion performance, both in terms of auto-
matic scores, as well as more grammatical
coherence.
1 Introduction
The current state-of-the-art approach to statistical
machine translation, so-called phrase-based models,
is limited to the mapping of small text chunks with-
out any explicit use of linguistic information, may
it be morphological, syntactic, or semantic. Such
additional information has been demonstrated to be
valuable by integrating it in pre-processing or post-
processing steps.
However, a tighter integration of linguistic infor-
mation into the translation model is desirable for two
reasons:
? Translation models that operate on more gen-
eral representations, such as lemmas instead
of surface forms of words, can draw on richer
statistics and overcome the data sparseness
problems caused by limited training data.
? Many aspects of translation can be best ex-
plained on a morphological, syntactic, or se-
mantic level. Having such information avail-
able to the translation model allows the direct
modeling of these aspects. For instance: re-
ordering at the sentence level is mostly driven
word word
part-of-speech
OutputInput
morphology
part-of-speech
morphology
word class
lemma
word class
lemma
......
Figure 1: Factored representations of input and out-
put words incorporate additional annotation into the
statistical translation model.
by general syntactic principles, local agreement
constraints show up in morphology, etc.
Therefore, we extended the phrase-based ap-
proach to statistical translation to tightly integrate
additional information. The new approach allows
additional annotation at the word level. A word in
our framework is not only a token, but a vector of
factors that represent different levels of annotation
(see Figure 1).
We report on experiments with factors such as
surface form, lemma, part-of-speech, morphologi-
cal features such as gender, count and case, auto-
matic word classes, true case forms of words, shal-
low syntactic tags, as well as dedicated factors to en-
sure agreement between syntactically related items.
This paper describes the motivation, the modeling
aspects and the computationally efficient decoding
methods of factored translation models. We present
briefly results for a number of language pairs. How-
ever, the focus of this paper is the description of the
approach. Detailed experimental results will be de-
scribed in forthcoming papers.
868
2 Related Work
Many attempts have been made to add richer in-
formation to statistical machine translation models.
Most of these focus on the pre-processing of the in-
put to the statistical system, or the post-processing
of its output. Our framework is more general and
goes beyond recent work on models that back off
to representations with richer statistics (Nie?en and
Ney, 2001; Yang and Kirchhoff, 2006; Talbot and
Osborne, 2006) by keeping a more complex repre-
sentation throughout the translation process.
Rich morphology often poses a challenge to sta-
tistical machine translation, since a multitude of
word forms derived from the same lemma fragment
the data and lead to sparse data problems. If the in-
put language is morphologically richer than the out-
put language, it helps to stem or segment the input
in a pre-processing step, before passing it on to the
translation system (Lee, 2004; Sadat and Habash,
2006).
Structural problems have also been addressed by
pre-processing: Collins et al (2005) reorder the in-
put to a statistical system to closer match the word
order of the output language.
On the other end of the translation pipeline, addi-
tional information has been used in post-processing.
Och et al (2004) report minor improvements with
linguistic features on a Chinese-English task, Koehn
and Knight (2003) show some success in re-ranking
noun phrases for German-English. In their ap-
proaches, first, an n-best list with the best transla-
tions is generated for each input sentence. Then,
the n-best list is enriched with additional features,
for instance by syntactically parsing each candidate
translation and adding a parse score. The additional
features are used to rescore the n-best list, resulting
possibly in a better best translation for the sentence.
The goal of integrating syntactic information
into the translation model has prompted many re-
searchers to pursue tree-based transfer models (Wu,
1997; Alshawi et al, 1998; Yamada and Knight,
2001; Melamed, 2004; Menezes and Quirk, 2005;
Galley et al, 2006), with increasingly encouraging
results. Our goal is complementary to these efforts:
we are less interested in recursive syntactic struc-
ture, but in richer annotation at the word level. In
future work, these approaches may be combined.
lemma lemma
part-of-speech
OutputInput
morphology
part-of-speech
word word
morphology
Figure 2: Example factored model: morphologi-
cal analysis and generation, decomposed into three
mapping steps (translation of lemmas, translation of
part-of-speech and morphological information, gen-
eration of surface forms).
3 Motivating Example: Morphology
One example to illustrate the short-comings of the
traditional surface word approach in statistical ma-
chine translation is the poor handling of morphol-
ogy. Each word form is treated as a token in it-
self. This means that the translation model treats,
say, the word house completely independent of the
word houses. Any instance of house in the training
data does not add any knowledge to the translation
of houses.
In the extreme case, while the translation of house
may be known to the model, the word housesmay be
unknown and the system will not be able to translate
it. While this problem does not show up as strongly
in English ? due to the very limited morphologi-
cal inflection in English ? it does constitute a sig-
nificant problem for morphologically rich languages
such as Arabic, German, Czech, etc.
Thus, it may be preferably to model translation
between morphologically rich languages on the level
of lemmas, and thus pooling the evidence for differ-
ent word forms that derive from a common lemma.
In such a model, we would want to translate lemma
and morphological information separately, and com-
bine this information on the output side to ultimately
generate the output surface words.
Such a model can be defined straight-forward as
a factored translation model. See Figure 2 for an
illustration of this model in our framework.
Note that while we illustrate the use of factored
translation models on such a linguistically motivated
869
example, our framework also applies to models that
incorporate statistically defined word classes, or any
other annotation.
4 Decomposition of Factored Translation
The translation of factored representations of in-
put words into the factored representations of out-
put words is broken up into a sequence of mapping
steps that either translate input factors into output
factors, or generate additional output factors from
existing output factors.
Recall the example of a factored model motivated
by morphological analysis and generation. In this
model the translation process is broken up into the
following three mapping steps:
1. Translate input lemmas into output lemmas
2. Translate morphological and POS factors
3. Generate surface forms given the lemma and
linguistic factors
Factored translation models build on the phrase-
based approach (Koehn et al, 2003) that breaks up
the translation of a sentence into the translation of
small text chunks (so-called phrases). This approach
implicitly defines a segmentation of the input and
output sentences into phrases. See an example in
Figure 3.
Our current implementation of factored transla-
tion models follows strictly the phrase-based ap-
proach, with the additional decomposition of phrase
translation into a sequence of mapping steps. Trans-
lation steps map factors in input phrases to factors
in output phrases. Generation steps map output
factors within individual output words. To reiter-
ate: all translation steps operate on the phrase level,
while all generation steps operate on the word level.
Since all mapping steps operate on the same phrase
segmentation of the input and output sentence into
phrase pairs, we call these synchronous factored
models.
Let us now take a closer look at one example, the
translation of the one-word phrase ha?user into En-
glish. The representation of ha?user in German is:
surface-form ha?user | lemma haus | part-of-speech
NN | count plural | case nominative | gender neutral.
neue h?user werden gebaut
new houses are built
Figure 3: Example sentence translation by a stan-
dard phrase model. Factored models extend this ap-
proach.
The three mapping steps in our morphological
analysis and generation model may provide the fol-
lowing applicable mappings:
1. Translation: Mapping lemmas
? haus ? house, home, building, shell
2. Translation: Mapping morphology
? NN|plural-nominative-neutral ?
NN|plural, NN|singular
3. Generation: Generating surface forms
? house|NN|plural ? houses
? house|NN|singular ? house
? home|NN|plural ? homes
? ...
We call the application of these mapping steps
to an input phrase expansion. Given the multi-
ple choices for each step (reflecting the ambigu-
ity in translation), each input phrase may be ex-
panded into a list of translation options. The German
ha?user|haus|NN|plural-nominative-neutral may be
expanded as follows:
1. Translation: Mapping lemmas
{ ?|house|?|?, ?|home|?|?, ?|building|?|?,
?|shell|?|? }
2. Translation: Mapping morphology
{ ?|house|NN|plural, ?|home|NN|plural,
?|building|NN|plural, ?|shell|NN|plural,
?|house|NN|singular, ... }
3. Generation: Generating surface forms
{ houses|house|NN|plural,
homes|home|NN|plural,
buildings|building|NN|plural,
shells|shell|NN|plural,
house|house|NN|singular, ... }
870
5 Statistical Model
Factored translation models follow closely the sta-
tistical modeling approach of phrase-based models
(in fact, phrase-based models are a special case of
factored models). The main difference lies in the
preparation of the training data and the type of mod-
els learned from the data.
5.1 Training
The training data (a parallel corpus) has to be anno-
tated with the additional factors. For instance, if we
want to add part-of-speech information on the input
and output side, we need to obtain part-of-speech
tagged training data. Typically this involves running
automatic tools on the corpus, since manually anno-
tated corpora are rare and expensive to produce.
Next, we need to establish a word-alignment
for all the sentences in the parallel training cor-
pus. Here, we use the same methodology as
in phrase-based models (typically symmetrized
GIZA++ alignments). The word alignment methods
may operate on the surface forms of words, or on any
of the other factors. In fact, some preliminary ex-
periments have shown that word alignment based on
lemmas or stems yields improved alignment quality.
Each mapping step forms a component of the
overall model. From a training point of view this
means that we need to learn translation and gener-
ation tables from the word-aligned parallel corpus
and define scoring methods that help us to choose
between ambiguous mappings.
Phrase-based translation models are acquired
from a word-aligned parallel corpus by extracting all
phrase-pairs that are consistent with the word align-
ment. Given the set of extracted phrase pairs with
counts, various scoring functions are estimated,
such as conditional phrase translation probabilities
based on relative frequency estimation or lexical
translation probabilities based on the words in the
phrases.
In our approach, the models for the translation
steps are acquired in the same manner from a word-
aligned parallel corpus. For the specified factors in
the input and output, phrase mappings are extracted.
The set of phrase mappings (now over factored rep-
resentations) is scored based on relative counts and
word-based translation probabilities.
The generation distributions are estimated on the
output side only. The word alignment plays no
role here. In fact, additional monolingual data may
be used. The generation model is learned on a
word-for-word basis. For instance, for a genera-
tion step that maps surface forms to part-of-speech,
a table with entries such as (fish,NN) is constructed.
One or more scoring functions may be defined over
this table, in our experiments we used both condi-
tional probability distributions, e.g., p(fish|NN) and
p(NN|fish), obtained by maximum likelihood esti-
mation.
An important component of statistical machine
translation is the language model, typically an n-
gram model over surface forms of words. In the
framework of factored translation models, such se-
quence models may be defined over any factor, or
any set of factors. For factors such as part-of-speech
tags, building and using higher order n-gram models
(7-gram, 9-gram) is straight-forward.
5.2 Combination of Components
As in phrase-based models, factored translation
models can be seen as the combination of several
components (language model, reordering model,
translation steps, generation steps). These compo-
nents define one or more feature functions that are
combined in a log-linear model:
p(e|f) =
1
Z
exp
n?
i=1
?ihi(e, f) (1)
Z is a normalization constant that is ignored in
practice. To compute the probability of a translation
e given an input sentence f, we have to evaluate each
feature function hi. For instance, the feature func-
tion for a bigram language model component is (m
is the number of words ei in the sentence e):
hLM(e, f) = pLM(e)
= p(e1) p(e2|e1)..p(em|em?1)
(2)
Let us now consider the feature functions intro-
duced by the translation and generation steps of fac-
tored translation models. The translation of the input
sentence f into the output sentence e breaks down to
a set of phrase translations {(f?j , e?j)}.
For a translation step component, each feature
function hT is defined over the phrase pairs (f?j , e?j)
871
given a scoring function ? :
hT(e, f) =
?
j
?(f?j , e?j) (3)
For a generation step component, each feature
function hG given a scoring function ? is defined
over the output words ek only:
hG(e, f) =
?
k
?(ek) (4)
The feature functions follow from the scoring
functions (? , ?) acquired during the training of
translation and generation tables. For instance, re-
call our earlier example: a scoring function for a
generation model component that is a conditional
probability distribution between input and output
factors, e.g., ?(fish,NN,singular) = p(NN|fish).
The feature weights ?i in the log-linear model
are determined using a minimum error rate training
method, typically Powell?s method (Och, 2003).
5.3 Efficient Decoding
Compared to phrase-based models, the decomposi-
tion of phrase translation into several mapping steps
creates additional computational complexity. In-
stead of a simple table look-up to obtain the possible
translations for an input phrase, now multiple tables
have to be consulted and their content combined.
In phrase-based models it is easy to identify the
entries in the phrase table that may be used for a
specific input sentence. These are called translation
options. We usually limit ourselves to the top 20
translation options for each input phrase.
The beam search decoding algorithm starts with
an empty hypothesis. Then new hypotheses are gen-
erated by using all applicable translation options.
These hypotheses are used to generate further hy-
potheses in the same manner, and so on, until hy-
potheses are created that cover the full input sen-
tence. The highest scoring complete hypothesis in-
dicates the best translation according to the model.
How do we adapt this algorithm for factored
translation models? Since all mapping steps operate
on the same phrase segmentation, the expansions of
these mapping steps can be efficiently pre-computed
prior to the heuristic beam search, and stored as
translation options. For a given input phrase, all pos-
sible translation options are thus computed before
word word
part-of-speech
OutputInput
 
 
 
 
3
g
r
a
m
 
 
 
 
7
g
r
a
m
Figure 4: Syntactically enriched output: By gener-
ating additional linguistic factors on the output side,
high-order sequence models over these factors sup-
port syntactical coherence of the output.
decoding (recall the example in Section 4, where we
carried out the expansion for one input phrase). This
means that the fundamental search algorithm does
not change.
However, we need to be careful about combina-
torial explosion of the number of translation options
given a sequence of mapping steps. In other words,
the expansion may create too many translation op-
tions to handle. If one or many mapping steps result
in a vast increase of (intermediate) expansions, this
may be become unmanageable. We currently ad-
dress this problem by early pruning of expansions,
and limiting the number of translation options per
input phrase to a maximum number, by default 50.
This is, however, not a perfect solution. We are cur-
rently working on a more efficient search for the top
50 translation options to replace the current brute-
force approach.
6 Experiments
We carried out a number of experiments using the
factored translation model framework, incorporating
both linguistic information and automatically gener-
ated word classes.
This work is implemented as part of the open
source Moses1 system (Koehn et al, 2007). We used
the default settings for this system.
6.1 Syntactically Enriched Output
In the first set of experiments, we translate surface
forms of words and generate additional output fac-
tors from them (see Figure 4 for an illustration). By
adding morphological and shallow syntactic infor-
1available at http://www.statmt.org/moses/
872
English?German
Model BLEU
best published result 18.15%
baseline (surface) 18.04%
surface + POS 18.15%
surface + POS + morph 18.22%
English?Spanish
Model BLEU
baseline (surface) 23.41%
surface + morph 24.66%
surface + POS + morph 24.25%
English?Czech
Model BLEU
baseline (surface) 25.82%
surface + all morph 27.04%
surface + case/number/gender 27.45%
surface + CNG/verb/prepositions 27.62%
Table 1: Experimental results with syntactically en-
riched output (part of speech, morphology)
mation, we are able to use high-order sequence mod-
els (just like n-gram language models over words) in
order to support syntactic coherence of the output.
Table 1 summarizes the experimental results.
The English?German systems were trained on the
full 751,088 sentence Europarl corpus and evaluated
on the WMT 2006 test set (Koehn and Monz, 2006).
Adding part-of-speech and morphological factors on
the output side and exploiting them with 7-gram
sequence models results in minor improvements in
BLEU. The model that incorporates both POS and
morphology (18.22% BLEU vs. baseline 18.04%
BLEU) ensures better local grammatical coherence.
The baseline system produces often phrases such
as zur(to) zwischenstaatlichen(inter-governmental)
methoden(methods), with a mismatch between the
determiner (singular) and the noun (plural), while
the adjective is ambiguous. In a manual evaluation
of intra-NP agreement we found that the factored
model reduced the disagreement error within noun
phrases of length ? 3 from 15% to 4%.
English?Spanish systems were trained on a
40,000 sentence subset of the Europarl corpus. Here,
we also used morphological and part-of-speech fac-
tors on the output side with an 7-gram sequence
model, resulting in absolute improvements of 1.25%
(only morph) and 0.84% (morph+POS). Improve-
ments on the full Europarl corpus are smaller.
English-Czech systems were trained on a 20,000
sentence Wall Street Journal corpus. Morphologi-
cal features were exploited with a 7-gram language
model. Experimentation suggests that it is benefi-
cial to carefully consider which morphological fea-
tures to be used. Adding all features results in
lower performance (27.04% BLEU), than consider-
ing only case, number and gender (27.45% BLEU)
or additionally verbial (person, tense, and aspect)
and prepositional (lemma and case) morphology
(27.62% BLEU). All these models score well above
the baseline of 25.82% BLEU.
An extended description of these experiments is
in the JHU workshop report (Koehn et al, 2006).
6.2 Morphological Analysis and Generation
The next model is the one described in our motivat-
ing example in Section 4 (see also Figure 2). Instead
of translating surface forms of words, we translate
word lemma and morphology separately, and gener-
ate the surface form of the word on the output side.
We carried out experiments for the language pair
German?English, using the 52,185 sentence News
Commentary corpus2. We report results on the de-
velopment test set, which is also the out-of-domain
test set of the WMT06 workshop shared task (Koehn
and Monz, 2006). German morphological analysis
and POS tagging was done using LoPar Schmidt and
Schulte im Walde (2000), English POS tagging was
done with Brill?s tagger (Brill, 1995), followed by a
simple lemmatizer based on tagging results.
Experimental results are summarized in Table 2.
For this data set, we also see an improvement when
using a part-of-speech language model ? the BLEU
score increases from 18.19% to 19.05% ? consis-
tent with the results reported in the previous section.
However, moving from a surface word translation
mapping to a lemma/morphology mapping leads to
a deterioration of performance to a BLEU score of
14.46%.
Note that this model completely ignores the sur-
face forms of input words and only relies on the
2Made available for the WMT07 workshop shared task
http://www.statmt.org/wmt07/
873
German?English
Model BLEU
baseline (surface) 18.19%
+ POS LM 19.05%
pure lemma/morph model 14.46%
backoff lemma/morph model 19.47%
Table 2: Experimental results with morphological
analysis and generation model (Figure 2), using
News Commentary corpus
more general lemma and morphology information.
While this allows the translation of word forms with
known lemma and unknown surface form, on bal-
ance it seems to be disadvantage to throw away sur-
face form information.
To overcome this problem, we introduce an al-
ternative path model: Translation options in this
model may come either from the surface form model
or from the lemma/morphology model we just de-
scribed. For surface forms with rich evidence in
the training data, we prefer surface form mappings,
and for surface forms with poor or no evidence in
the training data we decompose surface forms into
lemma and morphology information and map these
separately. The different translation tables form dif-
ferent components in the log-linear model, whose
weights are set using standard minimum error rate
training methods.
The alternative path model outperforms the sur-
face form model with POS LM, with an BLEU score
of 19.47% vs. 19.05%. The test set has 3276 un-
known word forms vs 2589 unknown lemmas (out
of 26,898 words). Hence, the lemma/morph model
is able to translate 687 additional words.
6.3 Use of Automatic Word Classes
Finally, we went beyond linguistically motivated
factors and carried out experiments with automati-
cally trained word classes. By clustering words to-
gether by their contextual similarity, we are able to
find statistically similarities that may lead to more
generalized and robust models.
We trained models on the IWSLT 2006 task
(39,953 sentences). Compared to a baseline
English?Chinese system, adding word classes on the
output side as additional factors (in a model as pre-
English?Chinese
Model BLEU
baseline (surface) 19.54%
surface + word class 21.10%
Table 3: Experimental result with automatic word
classes obtained by word clustering
Chinese?English
Recase Method BLEU
Standard two-pass: SMT + recase 20.65%
Integrated factored model (optimized) 21.08%
OutputInput
mixed-cased
lower-cased lower-cased
Table 4: Experimental result with integrated recas-
ing (IWSLT 2006 task)
viously illustrated in Figure 4) to be exploited by
a 7-gram sequence model, we observe a gain 1.5%
BLEU absolute. For more on this experiment, see
(Shen et al, 2006).
6.4 Integrated Recasing
To demonstrate the versatility of the factored trans-
lation model approach, consider the task of recas-
ing (Lita et al, 2003; Wang et al, 2006). Typically
in statistical machine translation, the training data is
lowercased to generalize over differently cased sur-
face forms ? say, the, The, THE ? which neces-
sitates a post-processing step to restore case in the
output.
With factored translation models, it is possible
to integrate this step into the model, by adding a
generation step. See Table 4 for an illustration of
this model and experimental results on the IWSLT
2006 task (Chinese-English). The integrated recas-
ing model outperform the standard approach with an
BLEU score of 21.08% to 20.65%. For more on this
experiment, see (Shen et al, 2006).
874
6.5 Additional Experiments
Factored translation models have also been used
for the integration of CCG supertags (Birch et al,
2007), domain adaptation (Koehn and Schroeder,
2007) and for the improvement of English-Czech
translation (Bojar, 2007).
7 Conclusion and Future Work
We presented an extension of the state-of-the-art
phrase-based approach to statistical machine trans-
lation that allows the straight-forward integration of
additional information, may it come from linguistic
tools or automatically acquired word classes.
We reported on experiments that showed gains
over standard phrase-based models, both in terms
of automatic scores (gains of up to 2% BLEU), as
well as a measure of grammatical coherence. These
experiments demonstrate that within the framework
of factored translation models additional informa-
tion can be successfully exploited to overcome some
short-comings of the currently dominant phrase-
based statistical approach.
The framework of factored translation models is
very general. Many more models that incorporate
different factors can be quickly built using the ex-
isting implementation. We are currently exploring
these possibilities, for instance use of syntactic in-
formation in reordering and models with augmented
input information.
We have not addressed all computational prob-
lems of factored translation models. In fact, compu-
tational problems hold back experiments with more
complex factored models that are theoretically pos-
sible but too computationally expensive to carry out.
Our current focus is to develop a more efficient im-
plementation that will enable these experiments.
Moreover, we expect to overcome the constraints
of the currently implemented synchronous factored
models by developing a more general asynchronous
framework, where multiple translation steps may
operate on different phrase segmentations (for in-
stance a part-of-speech model for large scale re-
ordering).
Acknowledgments
This work was supported in part under the GALE
program of the Defense Advanced Research Projects
Agency, Contract No NR0011-06-C-0022 and in
part under the EuroMatrix project funded by the Eu-
ropean Commission (6th Framework Programme).
We also benefited greatly from a 2006 sum-
mer workshop hosted by the Johns Hopkins Uni-
versity and would like thank the other workshop
participants for their support and insights, namely
Nicola Bertoldi, Ondrej Bojar, Chris Callison-
Burch, Alexandra Constantin, Brooke Cowan, Chris
Dyer, Marcello Federico, Evan Herbst Christine
Moran, Wade Shen, and Richard Zens.
References
Alshawi, H., Bangalore, S., and Douglas, S. (1998). Automatic
acquisition of hierarchical transduction models for machine
translation. In Proceedings of the 36th Annual Meeting of
the Association of Computational Linguistics (ACL).
Birch, A., Osborne, M., and Koehn, P. (2007). CCG supertags
in factored statistical machine translation. In Proceedings
of the Second Workshop on Statistical Machine Translation,
pages 9?16, Prague, Czech Republic. Association for Com-
putational Linguistics.
Bojar, O. (2007). English-to-Czech factored machine transla-
tion. In Proceedings of the Second Workshop on Statistical
Machine Translation, pages 232?239, Prague, Czech Repub-
lic. Association for Computational Linguistics.
Brill, E. (1995). Transformation-based error-driven learning
and natural language processing: A case study in part of
speech tagging. Computational Linguistics, 21(4).
Collins, M., Koehn, P., and Kucerova, I. (2005). Clause re-
structuring for statistical machine translation. In Proceed-
ings of the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL?05), pages 531?540, Ann Arbor,
Michigan. Association for Computational Linguistics.
Galley, M., Graehl, J., Knight, K., Marcu, D., DeNeefe, S.,
Wang, W., and Thayer, I. (2006). Scalable inference and
training of context-rich syntactic translation models. In Pro-
ceedings of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 961?968, Sydney,
Australia. Association for Computational Linguistics.
Koehn, P., Federico, M., Shen, W., Bertoldi, N., Hoang, H.,
Callison-Burch, C., Cowan, B., Zens, R., Dyer, C., Bojar,
O., Moran, C., Constantin, A., and Herbst, E. (2006). Open
source toolkit for statistical machine translation: Factored
translation models and confusion network decoding. Tech-
nical report, John Hopkins University Summer Workshop.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico,
M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R.,
Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open source toolkit for statistical machine transla-
tion. In Proceedings of the Annual Meeting of the Associa-
tion for Computational Linguistics, demonstation session.
Koehn, P. and Knight, K. (2003). Feature-rich translation of
noun phrases. In 41st Annual Meeting of the Association of
Computational Linguistics (ACL).
875
Koehn, P. and Monz, C. (2006). Manual and automatic evalua-
tion of machine translation between European languages. In
Proceedings on the Workshop on Statistical Machine Trans-
lation, pages 102?121, NewYork City. Association for Com-
putational Linguistics.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase
based translation. In Proceedings of the Joint Conference on
Human Language Technologies and the Annual Meeting of
the North American Chapter of the Association of Computa-
tional Linguistics (HLT-NAACL).
Koehn, P. and Schroeder, J. (2007). Experiments in domain
adaptation for statistical machine translation. In Proceed-
ings of the Second Workshop on Statistical Machine Trans-
lation, pages 224?227, Prague, Czech Republic. Association
for Computational Linguistics.
Lee, Y.-S. (2004). Morphological analysis for statistical ma-
chine translation. In Proceedings of the Joint Conference on
Human Language Technologies and the Annual Meeting of
the North American Chapter of the Association of Computa-
tional Linguistics (HLT-NAACL).
Lita, L. V., Ittycheriah, A., Roukos, S., and Kambhatla, N.
(2003). tRuEcasIng. In Hinrichs, E. and Roth, D., editors,
Proceedings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 152?159.
Melamed, I. D. (2004). Statistical machine translation by pars-
ing. In Proceedings of the 42nd Meeting of the Associa-
tion for Computational Linguistics (ACL?04), Main Volume,
pages 653?660, Barcelona, Spain.
Menezes, A. and Quirk, C. (2005). Microsoft research treelet
translation system: IWSLT evaluation. In Proc. of the Inter-
national Workshop on Spoken Language Translation.
Nie?en, S. and Ney, H. (2001). Toward hierarchical models
for statistical machine translation of inflected languages. In
Workshop on Data-Driven Machine Translation at 39th An-
nual Meeting of the Association of Computational Linguis-
tics (ACL), pages 47?54.
Och, F. J. (2003). Minimum error rate training for statistical ma-
chine translation. In Proceedings of the 41st Annual Meeting
of the Association of Computational Linguistics (ACL).
Och, F. J., Gildea, D., Khudanpur, S., Sarkar, A., Yamada, K.,
Fraser, A., Kumar, S., Shen, L., Smith, D., Eng, K., Jain,
V., Jin, Z., and Radev, D. (2004). A smorgasbord of fea-
tures for statistical machine translation. In Proceedings of
the Joint Conference on Human Language Technologies and
the Annual Meeting of the North American Chapter of the
Association of Computational Linguistics (HLT-NAACL).
Sadat, F. and Habash, N. (2006). Combination of arabic pre-
processing schemes for statistical machine translation. In
Proceedings of the 21st International Conference on Com-
putational Linguistics and 44th Annual Meeting of the As-
sociation for Computational Linguistics, pages 1?8, Sydney,
Australia. Association for Computational Linguistics.
Schmidt, H. and Schulte im Walde, S. (2000). Robust German
noun chunking with a probabilistic context-free grammar. In
Proceedings of the International Conference on Computa-
tional Linguistics (COLING).
Shen, W., Zens, R., Bertoldi, N., and Federico, M. (2006). The
JHU Workshop 2006 IWSLT System. In Proc. of the Inter-
national Workshop on Spoken Language Translation, pages
59?63, Kyoto, Japan.
Talbot, D. and Osborne, M. (2006). Modelling lexical redun-
dancy for machine translation. In Proceedings of the 21st
International Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computational
Linguistics, pages 969?976, Sydney, Australia. Association
for Computational Linguistics.
Wang, W., Knight, K., and Marcu, D. (2006). Capitalizing ma-
chine translation. In Proceedings of the Joint Conference on
Human Language Technologies and the Annual Meeting of
the North American Chapter of the Association of Computa-
tional Linguistics (HLT-NAACL).
Wu, D. (1997). Stochastic inversion transduction grammars and
bilingual parsing of parallel corpora. Computational Lin-
guistics, 23(3).
Yamada, K. and Knight, K. (2001). A syntax-based statistical
translation model. In Proceedings of the 39th Annual Meet-
ing of the Association of Computational Linguistics (ACL).
Yang, M. and Kirchhoff, K. (2006). Phrase-based backoff mod-
els for machine translation of highly inflected languages. In
Proceedings of the 11th Conference of the European Chapter
of the Association for Computational Linguistics (EACL).
876
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 485?494,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Improving Interactive Machine Translation via Mouse Actions
Germa?n Sanchis-Trilles and Daniel Ortiz-Mart??nez and Jorge Civera
Instituto Tecnolo?gico de Informa?tica
Universidad Polite?cnica de Valencia
{gsanchis,dortiz,jorcisai}@iti.upv.es
Francisco Casacuberta and Enrique Vidal
Departamento de Sistemas Informa?ticos y Computacio?n
Universidad Polite?cnica de Valencia
{fcn,evidal}@dsic.upv.es
Hieu Hoang
University of Edinburgh
hhoang@sms.ed.ac.uk
Abstract
Although Machine Translation (MT) is a very
active research field which is receiving an in-
creasing amount of attention from the research
community, the results that current MT sys-
tems are capable of producing are still quite
far away from perfection. Because of this,
and in order to build systems that yield correct
translations, human knowledge must be inte-
grated into the translation process, which will
be carried out in our case in an Interactive-
Predictive (IP) framework. In this paper, we
show that considering Mouse Actions as a sig-
nificant information source for the underly-
ing system improves the productivity of the
human translator involved. In addition, we
also show that the initial translations that the
MT system provides can be quickly improved
by an expert by only performing additional
Mouse Actions. In this work, we will be using
word graphs as an efficient interface between
a phrase-based MT system and the IP engine.
1 Introduction
Information technology advances in modern society
have led to the need of more efficient methods of
translation. It is important to remark that current
MT systems are not able to produce ready-to-use
texts (Kay, 1997; Hutchins, 1999; Arnold, 2003).
Indeed, MT systems are usually limited to specific
semantic domains and the translations provided re-
quire human post-editing in order to achieve a cor-
rect high-quality translation.
A way of taking advantage of MT systems is to
combine them with the knowledge of a human trans-
lator, constituting the so-called Computer-Assisted
Translation (CAT) paradigm. CAT offers different
approaches in order to benefit from the synergy be-
tween humans and MT systems.
An important contribution to interactive CAT
technology was carried out around the TransType
(TT) project (Langlais et al, 2002; Foster et al,
2002; Foster, 2002; Och et al, 2003). This project
entailed an interesting focus shift in which interac-
tion directly aimed at the production of the target
text, rather than at the disambiguation of the source
text, as in former interactive systems. The idea
proposed was to embed data driven MT techniques
within the interactive translation environment.
Following these TT ideas, (Barrachina and oth-
ers, 2008) propose the usage of fully-fledged statis-
tical MT (SMT) systems to produce full target sen-
tence hypotheses, or portions thereof, which can be
partially or completely accepted and amended by a
human translator. Each partial correct text segment
is then used by the SMT system as additional infor-
mation to achieve further, hopefully improved sug-
gestions. In this paper, we also focus on the inter-
active and predictive, statistical MT (IMT) approach
to CAT. The IMT paradigm fits well within the In-
teractive Pattern Recognition framework introduced
in (Vidal and others, 2007).
485
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) switch on:
(k) power
(s?h) on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 1: IMT session to translate a Spanish sentence into English. Non-validated hypotheses are displayed in italics,
whereas accepted prefixes are printed in normal font.
Figure 1 illustrates a typical IMT session. Ini-
tially, the user is given an input sentence x to be
translated. The reference y provided is the trans-
lation that the user would like to achieve at the end
of the IMT session. At iteration 0, the user does not
supply any correct text prefix to the system, for this
reason p is shown as empty. Therefore, the IMT sys-
tem has to provide an initial complete translation sh,
as it were a conventional SMT system. At the next
iteration, the user validates a prefix p as correct by
positioning the cursor in a certain position of sh. In
this case, after the words ?To print a?. Implicitly, he
is also marking the rest of the sentence, the suffix sl,
as potentially incorrect. Next, he introduces a new
word k, which is assumed to be different from the
first word sl1 in the suffix sl which was not validated,
k 6= sl1 . This being done, the system suggests a new
suffix hypothesis s?h, subject to s?h1 = k. Again, the
user validates a new prefix, introduces a new word
and so forth. The process continues until the whole
sentence is correct that is validated introducing the
special word ?#?.
As the reader could devise from the IMT session
described above, IMT aims at reducing the effort
and increasing the productivity of translators, while
preserving high-quality translation. For instance, in
Figure 1, only three interactions were necessary in
order to achieve the reference translation.
In this paper, we will show how Mouse Actions
performed by the human expert can be taken advan-
tage of in order to further reduce this effort.
2 Statistical interactive-predictive MT
In this section we will briefly describe the statistical
framework of IMT. IMT can be seen as an evolution
of the SMT framework, which has proved to be an
efficient framework for building state-of-the-art MT
systems with little human effort, whenever adequate
corpora are available (Hutchings and Somers, 1992).
The fundamental equation of the statistical approach
to MT is
y? = argmax
y
Pr(y |x) (1)
= argmax
y
Pr(x |y)Pr(y) (2)
where Pr(x |y) is the translation model modelling
the correlation between source and target sentence
and Pr(y) is the language model representing the
well-formedness of the candidate translation y.
In practise, the direct modelling of the posterior
probability Pr(y|x) has been widely adopted. To
this purpose, different authors (Papineni et al, 1998;
Och and Ney, 2002) propose the use of the so-called
log-linear models, where the decision rule is given
by the expression
y? = argmax
y
M
?
m=1
?mhm(x,y) (3)
where hm(x,y) is a score function representing an
important feature for the translation of x into y, M
is the number of models (or features) and ?m are the
weights of the log-linear combination.
486
One of the most popular instantiations of log-
linear models is that including phrase-based (PB)
models (Zens et al, 2002; Koehn et al, 2003).
Phrase-based models allow to capture contextual in-
formation to learn translations for whole phrases in-
stead of single words. The basic idea of phrase-
based translation is to segment the source sentence
into phrases, then to translate each source phrase
into a target phrase, and finally to reorder the trans-
lated target phrases in order to compose the tar-
get sentence. Phrase-based models were employed
throughout this work.
In log-linear models, the maximisation problem
stated in Eq. 3 is solved by means of the beam search
algorithm1 which was initially introduced in (Low-
erre, 1976) for its application in the field of speech
recognition. The beam search algorithm attempts to
generate partial solutions, called hypotheses, until
a complete sentence is found; these hypotheses are
stored in a stack and ordered by their score. Such a
score is given by the log-linear combination of fea-
ture functions.
However, Eq. 1 needs to be modified according to
the IMT scenario in order to take into account part
of the target sentence that is already translated, that
is p and k
s?h = argmax
sh
Pr(sh|x,p, k) (4)
where the maximisation problem is defined over the
suffix sh. This allows us to rewrite Eq. 4, by decom-
posing the right side appropriately and eliminating
constant terms, achieving the equivalent criterion
s?h = argmax
sh
Pr(p, k, sh|x). (5)
An example of the intuition behind these variables
can be seen in Figure 1.
Note that, since (p k sh) = y, Eq. 5 is very simi-
lar to Eq. 1. The main difference is that the argmax
search is now performed over the set of suffixes sh
that complete (p k) instead of complete sentences
(y in Eq. 1). This implies that we can use the same
models if the search procedures are adequately mod-
ified (Barrachina and others, 2008).
1Also known as stack decoding algorithm.
3 Phrase-based IMT
The phrase-based approach presented above can be
easily adapted for its use in an IMT scenario. The
most important modification is to rely on a word
graph that represents possible translations of the
given source sentence. The use of word graphs
in IMT has been studied in (Barrachina and oth-
ers, 2008) in combination with two different trans-
lation techniques, namely, the Alignment Templates
technique (Och et al, 1999; Och and Ney, 2004),
and the Stochastic Finite State Transducers tech-
nique (Casacuberta and Vidal, 2007).
3.1 Generation of word graphs
A word graph is a weighted directed acyclic graph,
in which each node represents a partial translation
hypothesis and each edge is labelled with a word of
the target sentence and is weighted according to the
scores given by an SMT model (see (Ueffing et al,
2002) for more details). In (Och et al, 2003), the
use of a word graph is proposed as interface between
an alignment-template SMT model and the IMT en-
gine. Analogously, in this work we will be using
a word graph built during the search procedure per-
formed on a PB SMT model.
During the search process performed by the above
mentioned beam search algorithm, it is possible to
create a segment graph. In such a graph, each node
represents a state of the SMT model, and each edge
a weighted transition between states labelled with a
sequence of target words. Whenever a hypothesis is
extended, we add a new edge connecting the state
of that hypothesis with the state of the extended hy-
pothesis. The new edge is labelled with the sequence
of target words that has been incorporated to the ex-
tended hypothesis and is weighted appropriately by
means of the score given by the SMT model.
Once the segment graph is generated, it can be
easily converted into a word graph by the introduc-
tion of artificial states for the words that compose
the target phrases associated to the edges.
3.2 IMT using word graphs
During the process of IMT for a given source sen-
tence, the system makes use of the word graph gen-
erated for that sentence in order to complete the pre-
fixes accepted by the human translator. Specifically,
487
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) |switch on:
(s?h) power on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 2: Example of non-explicit positioning MA which solves an error of a missing word. In this case, the system
produces the correct suffix sh immediately after the user validates a prefix p, implicitly indicating that we wants the
suffix to be changed, without need of any further action. In ITER-1, character | indicates the position where a MA
was performed, sl is the suffix which was rejected by that MA, and s?h is the new suffix that the system suggests after
observing that sl is to be considered incorrect. Character # is a special character introduced by the user to indicate that
the hypothesis is to be accepted.
the system finds the best path in the word graph as-
sociated with a given prefix so that it is able to com-
plete the target sentence, being capable of providing
several completion suggestions for each prefix.
A common problem in IMT arises when the user
sets a prefix which cannot be found in the word
graph, since in such a situation the system is un-
able to find a path through the word graph and pro-
vide an appropriate suffix. The common procedure
to face this problem is to perform a tolerant search
in the word graph. This tolerant search uses the well
known concept of Levenshtein distance in order to
obtain the most similar string for the given prefix
(see (Och et al, 2003) for more details).
4 Enriching user?machine interaction
Although the IMT paradigm has proved to offer in-
teresting benefits to potential users, one aspect that
has not been reconsidered as of yet is the user?
machine interface. Hence, in traditional IMT the
system only received feedback whenever the user
typed in a new word. In this work, we show how
to enrich user?machine interaction by introducing
Mouse Actions (MA) as an additional information
source for the system. By doing so, we will consider
two types of MAs, i.e. non-explicit (or positioning)
MAs and interaction-explicit MAs.
4.1 Non-explicit positioning MAs
Before typing in a new word in order to correct a hy-
pothesis, the user needs to position the cursor in the
place where he wants to type such a word. In this
work, we will assume that this is done by perform-
ing a MA, although the same idea presented can also
be applied when this is done by some other means.
It is important to point out that, by doing so, the user
is already providing some very useful information to
the system: he is validating a prefix up to the posi-
tion where he positioned the cursor, and, in addition,
he is signalling that whatever word is located after
the cursor is to be considered incorrect. Hence, the
system can already capture this fact and provide a
new translation hypothesis, in which the prefix re-
mains unchanged and the suffix is replaced by a new
one in which the first word is different to the first
word of the previous suffix. We are aware that this
does not mean that the new suffix will be correct, but
given that we know that the first word in the previ-
ous suffix was incorrect, the worst thing which can
happen is that the the first word of the new suffix is
incorrect as well. However, if the new suffix hap-
pens to be correct, the user will happily find that he
does not need to correct that word any more.
An example of such behaviour can be seen in
Figure 2. In this example, the SMT system first
provides a translation which the user does not
488
like. Hence, he positions the cursor before word
?postscript?, with the purpose of typing in ?lists?.
By doing so, he is validating the prefix ?To print
a?, and signalling that he wants ?postscript? to be
replaced. Before typing in anything, the system re-
alises that he is going to change the word located
after the cursor, and replaces the suffix by another
one, which is the one the user had in mind in the
first place. Finally, the user only has to accept the
final translation.
We are naming this kind of MA non-explicit be-
cause it does not require any additional action from
the user: he has already performed a MA in order to
position the cursor at the place he wants, and we are
taking advantage of this fact to suggest a new suffix
hypothesis.
Since the user needs to position the cursor before
typing in a new word, it is important to point out
that any improvement achieved by introducing non-
explicit MAs does not require any further effort from
the user, and hence is considered to have no cost.
Hence, we are now considering two different situ-
ations: the first one, the traditional IMT framework,
in which the system needs to find a suffix according
to Eq. 5, and a new one, in which the system needs
to find a suffix in which the first word does not need
to be a given k, but needs to be different to a given
sl1. This constraint can be expressed by the follow-
ing equation:
s?h = argmax
sh:sh1 6=sl1
Pr(p, sh|x, sl) (6)
where sl is the suffix generated in the previous iter-
ation, already discarded by the user, and sl1 is the
first word in sl. k is omitted in this formula because
the user did not type any word at all.
4.2 Interaction-explicit MAs
If the system is efficient and provides suggestions
which are good enough, one could easily picture a
situation in which the expert would ask the system
to replace a given suffix, without typing in any word.
We will be modelling this as another kind of MA,
interaction-explicit MA, since the user needs to in-
dicate explicitly that he wants a given suffix to be
replaced, in contrast to the non-explicit positioning
MA. However, if the underlying MT engine provid-
ing the suffixes is powerful enough, the user would
quickly realise that performing a MA is less costly
that introducing a whole new word, and would take
advantage of this fact by systematically clicking be-
fore introducing any new word. In this case, as
well, we assume that the user clicks before an in-
correct word, hence demanding a new suffix whose
first word is different, but by doing so he is adopting
a more participative and interactive attitude, which
was not demanded in the case of non-explicit posi-
tioning MAs. An example of such an explicit MA
correcting an error can be seen in Figure 3
In this case, however, there is a cost associated to
this kind of MAs, since the user does need to per-
form additional actions, which may or may not be
beneficial. It is very possible that, even after asking
for several new hypothesis, the user will even though
need to introduce the word he had in mind, hence
wasting the additional MAs he had performed.
If we allow the user to perform n MAs before in-
troducing a word, this problem can be formalised in
an analogous way as in the case of non-explicit MAs
as follows:
s?h= argmax
sh:sh1 6=sil1?i?{1..n}
Pr(p, sh|x, s1l , s2l , . . . , snl ) (7)
where sil1 is the first word of the i-th suffix dis-
carded and s1l , s2l , . . . , snl is the set of all n suffixes
discarded.
Note that this kind of MA could also be imple-
mented with some other kind of interface, e.g. by
typing some special key such as F1 or Tab. How-
ever, the experimental results would not differ, and
in our user interface we found it more intuitive to
implement it as a MA.
5 Experimental setup
5.1 System evaluation
Automatic evaluation of results is a difficult problem
in MT. In fact, it has evolved to a research field with
own identity. This is due to the fact that, given an
input sentence, a large amount of correct and differ-
ent output sentences may exist. Hence, there is no
sentence which can be considered ground truth, as is
the case in speech or text recognition. By extension,
this problem is also applicable to IMT.
In this paper, we will be reporting our results as
measured by Word Stroke Ratio (WSR) (Barrachina
489
SOURCE (x): Seleccione el tipo de instalacio?n.
REFERENCE (y): Select the type of installation.
ITER-0 (p) ( )(s?h) Select the installation wizard.
ITER-1
(p) Select the
(sl) |installation wizard.
(s?h) install script.
ITER-2
(p) Select the
(k) type
(s?h) installation wizard.
ITER-3
(p) Select the type
(sl) |installation wizard.
(s?h) of installation.
ITER-4
(p) Select the type of installation.
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) Select the type of installation.
Figure 3: Example of explicit interactive MA which corrects an erroneous suffix. In this case, a non-explicit MA is
performed in ITER-1 with no success. Hence, the user introduces word ?type? in ITER-2, which leaves the cursor
position located immediately after word ?type?. In this situation the user would not need to perform a MA to re-
position the cursor and continue typing in order to further correct the remaining errors. However, since he has learnt
the potential benefit of MAs, he performs an interaction-explicit MA in order to ask for a new suffix hypothesis, which
happens to correct the error.
and others, 2008), which is computed as the quotient
between the number of word-strokes a user would
need to perform in order to achieve the translation
he has in mind and the total number of words in
the sentence. In this context, a word-stroke is in-
terpreted as a single action, in which the user types
a complete word, and is assumed to have constant
cost. Moreover, each word-stroke also takes into ac-
count the cost incurred by the user when reading the
new suffix provided by the system.
In the present work, we decided to use WSR in-
stead of Key Stroke Ratio (KSR), which is used in
other works on IMT such as (Och et al, 2003). The
reason for this is that KSR is clearly an optimistic
measure, since in such a scenario the user is often
overwhelmed by receiving a great amount of trans-
lation options, as much as one per key stroke, and
it is not taken into account the time the user would
need to read all those hypotheses.
In addition, and because we are also introducing
MAs as a new action, we will also present results in
terms of Mouse Action Ratio (MAR), which is the
quotient between the amount of explicit MAs per-
formed and the number of words of the final trans-
lation. Hence, the purpose is to elicit the number of
times the user needed to request a new translation
(i.e. performed a MA), on a per word basis.
Lastly, we will also present results in terms of
uMAR (useful MAR), which indicates the amount
of MAs which were useful, i.e. the MAs that actu-
ally produced a change in the first word of the suffix
and such word was accepted. Formally, uMAR is
defined as follows:
uMAR = MAC ? n ?WSCMAC (8)
where MAC stands for ?Mouse Action Count?,
WSC for ?Word Stroke Count? and n is the max-
imum amount of MAs allowed before the user types
in a word. Note that MAC?n ?WSC is the amount
of MAs that were useful since WSC is the amount
of word-strokes the user performed even though he
had already performed n MAs.
Since we will only use single-reference WSR and
MAR, the results presented here are clearly pes-
simistic. In fact, it is relatively common to have the
underlying SMT system provide a perfectly correct
490
Table 1: Characteristics of Europarl for each of the sub-
corpora. OoV stands for ?Out of Vocabulary? words,
Dev. for Development, K for thousands of elements and
M for millions of elements.
De En Es En Fr En
Tr
ai
n
in
g Sentences 751K 731K 688K
Run. words 15.3M16.1M 15.7M15.2M 15.6M13.8M
Avg. len. 20.3 21.4 21.5 20.8 22.7 20.1
Voc. 195K 66K 103K 64K 80K 62K
D
ev
.
Sentences 2000 2000 2000
Run. words 55K 59K 61K 59K 67K 59K
Avg. len. 27.6 29.3 30.3 29.3 33.6 29.3
OoV 432 125 208 127 144 138
Te
st
Sentences 2000 2000 2000
Run. words 54K 58K 60K 58K 66K 58K
Avg. len. 27.1 29.0 30.2 29.0 33.1 29.3
OoV 377 127 207 125 139 133
translation, which is ?corrected? by the IMT proce-
dure into another equivalent translation, increasing
WSR and MAR significantly by doing so.
5.2 Corpora
Our experiments were carried out on the Eu-
roparl (Koehn, 2005) corpus, which is a corpus
widely used in SMT and that has been used in sev-
eral MT evaluation campaigns. Moreover, we per-
formed our experiments on the partition established
for the Workshop on Statistical Machine Translation
of the NAACL 2006 (Koehn and Monz, 2006). The
Europarl corpus (Koehn, 2005) is built from the pro-
ceedings of the European Parliament. Here, we will
focus on the German?English, Spanish?English and
French?English tasks, since these were the language
pairs selected for the cited workshop. The corpus is
divided into three separate sets: one for training, one
for development, and one for test. The characteris-
tics of the corpus can be seen in Table 1.
5.3 Experimental results
As a first step, we built a SMT system for each of
the language pairs cited in the previous subsection.
This was done by means of the Moses toolkit (Koehn
and others, 2007), which is a complete system for
building Phrase-Based SMT models. This toolkit in-
volves the estimation from the training set of four
different translation models, which are in turn com-
Table 2: WSR improvement when considering non-
explicit MAs. ?rel.? indicates the relative improvement.
All results are given in %.
pair baseline non-explicit rel.
Es?En 63.0?0.9 59.2?0.9 6.0?1.4
En?Es 63.8?0.9 60.5?1.0 5.2?1.6
De?En 71.6?0.8 69.0?0.9 3.6?1.3
En?De 75.9?0.8 73.5?0.9 3.2?1.2
Fr?En 62.9?0.9 59.2?1.0 5.9?1.6
En?Fr 63.4?0.9 60.0?0.9 5.4?1.4
bined in a log-linear fashion by adjusting a weight
for each of them by means of the MERT (Och, 2003)
procedure, optimising the BLEU (Papineni et al,
2002) score obtained on the development partition.
This being done, word graphs were generated
for the IMT system. For this purpose, we used a
multi-stack phrase-based decoder which will be dis-
tributed in the near future together with the Thot
toolkit (Ortiz-Mart??nez et al, 2005). We discarded
the use of the Moses decoder because preliminary
experiments performed with it revealed that the de-
coder by (Ortiz-Mart??nez et al, 2005) performs
clearly better when used to generate word graphs
for use in IMT. In addition, we performed an ex-
perimental comparison in regular SMT with the Eu-
roparl corpus, and found that the performance dif-
ference was negligible. The decoder was set to
only consider monotonic translation, since in real
IMT scenarios considering non-monotonic transla-
tion leads to excessive waiting time for the user.
Finally, the word graphs obtained were used
within the IMT procedure to produce the reference
translation contained in the test set, measuring WSR
and MAR. The results of such a setup can be seen in
Table 2. As a baseline system, we report the tradi-
tional IMT framework, in which no MA is taken into
account. Then, we introduced non-explicit MAs, ob-
taining an average improvement in WSR of about
3.2% (4.9% relative). The table also shows the
confidence intervals at a confidence level of 95%.
These intervals were computed following the boot-
strap technique described in (Koehn, 2004). Since
the confidence intervals do not overlap, it can be
stated that the improvements obtained are statisti-
cally significant.
491
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
German -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
German -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
French -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
French -> English
WSR
uMAR
Figure 4: WSR improvement when considering one to five maximum MAs. All figures are given in %. The left
column lists WSR improvement versus MAR degradation, and the right column lists WSR improvement versus uMAR.
Confidence intervals at 95% confidence level following (Koehn, 2004).
Once the non-explicit MAs were considered and
introduced into the system, we analysed the effect
of performing up to a maximum of 5 explicit MAs.
Here, we modelled the user in such a way that, in
case a given word is considered incorrect, he will
always ask for another translation hypothesis until
he has asked for as many different suffixes as MAs
considered. The results of this setup can be seen in
Figure 4. This yielded a further average improve-
ment in WSR of about 16% (25% relative improve-
ment) when considering a maximum of 5 explicit
MAs. However, relative improvement in WSR and
492
uMAR increase drop significantly when increasing
the maximum allowed amount of explicit MAs from
1 to 5. For this reason, it is difficult to imagine that
a user would perform more than two or three MAs
before actually typing in a new word. Nevertheless,
just by asking twice for a new suffix before typing
in the word he has in mind, the user might be saving
about 15% of word-strokes.
Although the results in Figure 4 are only
for the translation direction ?foreign??English,
the experiments in the opposite direction (i.e.
English??foreign?) were also performed. How-
ever, the results were very similar to the ones dis-
played here. Because of this, and for clarity pur-
poses, we decided to omit them and only display the
direction ?foreign??English.
6 Conclusions and future work
In this paper, we have considered new input sources
for IMT. By considering Mouse Actions, we have
shown that a significant benefit can be obtained, in
terms of word-stroke reduction, both when consid-
ering only non-explicit MAs and when considering
MAs as a way of offering the user several suffix hy-
potheses. In addition, we have applied these ideas
on a state-of-the-art SMT baseline, such as phrase-
based models. To achieve this, we have first ob-
tained a word graph for each sentence which is to be
translated. Experiments were carried out on a refer-
ence corpus in SMT.
Note that there are other systems (Esteban and
others, 2004) that, for a given prefix, provide n-
best lists of suffixes. However, the functionality of
our system is slightly (but fundamentally) different,
since the suggestions are demanded to be different
in their first word, which implies that the n-best list
is scanned deeper, going directly to those hypothe-
ses that may be of interest to the user. In addition,
this can be done ?on demand?, which implies that
the system?s response is faster and that the user is
not confronted with a large list of hypotheses, which
often results overwhelming.
As future work, we are planning on performing a
human evaluation that assesses the appropriateness
of the improvements described.
Acknowledgements
This work has been partially supported by the Span-
ish MEC under scholarship AP2005-4023 and un-
der grants CONSOLIDER Ingenio-2010 CSD2007-
00018, and by the EC (FEDER) and the Spanish
MEC under grant TIN2006-15694-CO2-01.
References
D. J. Arnold, 2003. Computers and Translation: A trans-
lator?s guide, chapter 8, pages 119?142.
S. Barrachina et al 2008. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, page In press.
F. Casacuberta and E. Vidal. 2007. Learning finite-state
models for machine translation. Machine Learning,
66(1):69?91.
J. Esteban et al 2004. Transtype2 - an innovative
computer-assisted translation system. In The Compan-
ion Volume to the Proc. ACL?04, pages 94?97.
G. Foster, P. Langlais, and G. Lapalme. 2002. User-
friendly text prediction for translators. In Proc. of
EMNLP?02, pages 148?155.
G. Foster. 2002. Text Prediction for Translators. Ph.D.
thesis, Universite? de Montre?al.
J. Hutchings and H. Somers. 1992. An introduction to
machine translation. In Ed. Academic Press.
J. Hutchins. 1999. Retrospect and prospect in computer-
based translation. In Proc. of MT Summit VII, pages
30?44.
M. Kay. 1997. It?s still the proper place. Machine Trans-
lation, 12(1-2):35?38.
P. Koehn and C. Monz, editors. 2006. Proc. of the Work-
shop on SMT.
P. Koehn et al 2007. Moses: Open source toolkit for
statistical machine translation. In Proc. of the ACL?07.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. HLT/NAACL?03,
pages 48?54.
P. Koehn. 2004. Statistical significance tests for machine
translation evaluation. In Proc. of EMNLP?04, pages
388?395, Barcelona, Spain.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proc. of the MT Summit X,
pages 79?86.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
Bruce T. Lowerre. 1976. The harpy speech recogni-
tion system. Ph.D. thesis, Carnegie Mellon University,
Pittsburgh, PA, USA.
493
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. In Proc. of the ACL?02, pages 295?302.
F.J. Och and H. Ney. 2004. The alignment template ap-
proach to statistical machine translation. Comput. Lin-
guist., 30(4):417?449.
F. Och, C. Tillmann, and H. Ney. 1999. Improved align-
ment models for statistical machine translation. In
Proc. of EMNLP/WVLC?99, pages 20?28.
F.J. Och, R. Zens, and H. Ney. 2003. Efficient search for
interactive statistical machine translation. In Proc. of
EACL?03, pages 387?393.
F.J. Och. 2003. Minimum error rate training for statis-
tical machine translation. In Proc. of ACL?03, pages
160?167.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and F. Casacuberta.
2005. Thot: a toolkit to train phrase-based statisti-
cal translation models. In Proc. of the MT Summit X,
pages 141?148.
K. Papineni, S. Roukos, and T. Ward. 1998. Maximum
likelihood and discriminative training of direct transla-
tion models. In Proc. of ICASSP?98, pages 189?192.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002.
Bleu: A method for automatic evaluation of machine
translation. In Proc. of ACL?02.
N. Ueffing, F. Och, and H. Ney. 2002. Generation of
word graphs in statistical machine translation. In Proc.
of EMNLP?02, pages 156?163.
E. Vidal et al 2007. Interactive pattern recognition. In
Proc. of MLMI?07, pages 60?71.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Proc. of KI?02, pages
18?32.
494
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 372?379,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Improving Mid-Range Reordering using Templates of Factors
Hieu Hoang
School of Informatics
University of Edinburgh
h.hoang@sms.ed.ac.uk
Philipp Koehn
School of Informatics
University of Edinburgh
pkoehn@inf.ed.ac.uk
Abstract
We extend the factored translation model
(Koehn and Hoang, 2007) to allow trans-
lations of longer phrases composed of fac-
tors such as POS and morphological tags
to act as templates for the selection and re-
ordering of surface phrase translation. We
also reintroduce the use of alignment in-
formation within the decoder, which forms
an integral part of decoding in the Align-
ment Template System (Och, 2002), into
phrase-based decoding.
Results show an increase in transla-
tion performance of up to 1.0% BLEU
for out-of-domain French?English transla-
tion. We also show how this method com-
pares and relates to lexicalized reordering.
1 Introduction
One of the major issues in statistical machine
translation is reordering due to systematic word-
ordering differences between languages. Often re-
ordering is best explained by linguistic categories,
such as part-of-speech tags. In fact, prior work
has examined the use of part-of-speech tags in
pre-reordering schemes, Tomas and Casacuberta
(2003).
Re-ordering can also be viewed as composing
of a number of related problems which can be ex-
plained or solved by a variety of linguistic phe-
nomena. Firstly, differences between phrase or-
dering account for much of the long-range re-
ordering. Syntax-based and hierarchical models
such as (Chiang, 2005) attempts to address this
problem. Shorter range re-ordering, such as intra-
phrasal word re-ordering, can often be predicted
from the underlying property of the words and
its context, the most obvious property being POS
tags.
In this paper, we tackle the issue of shorter-
range re-ordering in phrase-based decoding by
presenting an extension of the factored transla-
tion which directly models the translation of non-
surface factors such as POS tags. We shall call this
extension the factored template model. We use the
fact that factors such as POS-tags are less sparse
than surface words to obtain longer phrase trans-
lations. These translations are used to inform the
re-ordering of surface phrases.
Despite the ability of phrase-based systems to
use multi-word phrases, the majority of phrases
used during decoding are one word phrases, which
we will show in later sections. Using word trans-
lations negates the implicit capability of phrases
to re-order words. We show that the proposed
extension increases the number of multi-word
phrases used during decoding, capturing the im-
plicit ordering with the phrase translation, lead-
ing to overall better sentence translation. In
our tests, we obtained 1.0% increase in absolute
for French-English translation, and 0.8% increase
for German-English translation, trained on News
Commentary corpora 1.
We will begin by recounting the phrase-based
and factored model in Section 2 and describe the
language model and lexicalized re-ordering model
and the advantages and disadvantages of using
these models to influence re-ordering. The pro-
posed model is described in Section 4.
2 Background
Let us first provide some background on phrase-
based and factored translation, as well as the use
of part-of-speech tags in reordering.
2.1 Phrase-Based Models
Phrase-based statistical machine translation has
emerged as the dominant paradigm in machine
translation research. We model the translation of
a given source language sentence s into a target
language sentence t with a probability distribution
p(t|s). The goal of translation is to find the best
translation according to the model
tBEST = argmaxt p(t|s) (1)
The argmax function defines the search objec-
tive of the decoder. We estimate p(t|s) by decom-
1http://www.statmt.org/wmt07/shared-task.html
372
posing it into component models
p(t|s) =
1
Z
?
m
h?m(t, s)
?m (2)
where h?m(t, s) is the feature function for compo-
nent m and ?m is the weight given to component
m. Z is a normalization factor which is ignored in
practice. Components are translation model scor-
ing functions, language model, reordering models
and other features.
The problem is typically presented in log-space,
which simplifies computations, but otherwise does
not change the problem due to the monotonicity of
the log function (hm = log h?m)
log p(t|s) =
?
m
?m hm(t, s) (3)
Phrase-based models (Koehn et al, 2003) are
limited to the mapping of small contiguous chunks
of text. In these models, the source sentence s is
segmented into a number of phrases s?k, which are
translated one-to-one into target phrases t?k. The
translation feature functions hTM(t, s) are com-
puted as sum of phrase translation feature func-
tions h?TM(t?k, s?k):
hTM(t, s) =
?
k
h?TM(t?k, s?k) (4)
where t?k and s?k are the phrases that make up the
target and source sentence. Note that typically
multiple feature functions for one translation table
are used (such as forward and backward probabil-
ities and lexical backoff).
2.2 Reordering in Phrase Models
Phrase-based systems implicitly perform short-
range reordering by translating multi-word
phrases where the component words may be
reordered relative to each other. However, multi-
word phrases have to have been seen and learnt
from the training corpus. This works better when
the parallel corpus is large and the training corpus
and input are from the same domain. Otherwise,
the ability to apply multi-word phrases is lessened
due to data sparsity, and therefore most used
phrases are only 1 or 2 words long.
A popular model for phrasal reordering is lexi-
calized reordering (Tillmann, 2004) which intro-
duces a probability distribution for each phrase
pair that indicates the likelihood of being trans-
lated monotone, swapped, or placed discontinu-
ous to its previous phrase. However, whether a
phrase is reordered may depend on its neighboring
phrases, which this model does not take into ac-
count. For example, the French phrase noir would
be reordered if preceded by a noun when translat-
ing into English, as in as in chat noir, but would re-
main in the same relative position when preceded
by a conjunction such as rouge et noir.
The use of language models on the decoding
output also has a significant effect on reorder-
ing by preferring hypotheses which are more flu-
ent. However, there are a number of disadvantages
with this low-order Markov model over consecu-
tive surface words. Firstly, the model has no infor-
mation about the source and may prefer orderings
of target words that are unlikely given the source.
Secondly, data sparsity may be a problem, even
if language models are trained on a large amount
of monolingual data which is easier to obtain than
parallel data. When the test set is out-of-domain
or rare words are involved, it is likely that the lan-
guage model backs off to lower order n-grams,
thus further reducing the context window.
2.3 POS-Based Reordering
This paper will look at the use of POS tags to con-
dition reordering of phrases which are closely po-
sitioned in the source and target, such as intra-
clausal reordering, however, we do not explicit
segment along clausal boundaries. By mid-range
reordering we mean a maximum distortion of
about 5 or 6 words.
The phrase-based translation model is gener-
ally believed to perform short-range reordering
adequately. It outperforms more complex mod-
els such as hierarchical translation when the most
of the reordering in a particular language pair is
reasonably short (Anonymous, 2008), as is the
case with Arabic?English. However, phrase-based
models can fail to reorder words or phrases which
would seem obvious if it had access to the POS
tags of the individual words. For example, a trans-
lation from French to English will usually cor-
rectly reorder the French phrase with POS tags
NOUN ADJECTIVE if the surface forms exists in
the phrase table or language model, e.g.,
Union Europe?enne ? European Union
However, phrase-based models may not reorder
even these small two-word phrases if the phrase
is not in the training data or involves rare words.
This situation worsens for longer phrases where
the likelihood of the phrase being previously un-
373
seen is higher. The following example has a source
POS pattern NOUN ADJECTIVE CONJUNCTION
ADJECTIVE but is incorrectly ordered as the sur-
face phrase does not occur in training,
difficulte?s e?conomiques et socials
? economic and social difficulties
However, even if the training data does not con-
tain this particular phrase, it contains many similar
phrases with the same underlying POS tags. For
example, the correct translation of the correspond-
ing POS tags of the above translation
NOUN ADJ CONJ ADJ
? ADJ CONJ ADJ NOUN
is typically observed many times in the training
corpus.
The alignment information in the training cor-
pus shows exactly how the individual words in this
phrase should be distorted, along with the POS
tag of the target words. The challenge addressed
by this paper is to integrate POS tag phrase trans-
lations and alignment information into a phrase-
based decoder in order to improve reordering.
2.4 Factor Model Decomposition
Factored translation models (Koehn and Hoang,
2007) extend the phrase-based model by inte-
grating word level factors into the decoding pro-
cess. Words are represented by vectors of fac-
tors, not simple tokens. Factors are user-definable
and do not have any specific meaning within the
model. Typically, factors are obtained from lin-
guistic tools such as taggers and parsers.
The factored decoding process can be decom-
posed into multiple steps to fully translate the in-
put. Formally, this decomposes Equation 4 further
into sub-component models (also called transla-
tion steps)
h?TM(t?, s?) =
?
i
h?iTM(t?, s?) (5)
with an translation feature function h?iTM for each
translation step for each factor (or sets of factors).
There may be also generation models which create
target factors from other target factors but we ex-
clude this in our presentation for the sake of clar-
ity.
Decomposition is a convenient and flexible
method for integrating word level factors into
phrase-based decoding, allowing source and tar-
get sentences to be augmented with factors, while
at the same time controlling data sparsity. How-
ever, decomposition also implies certain indepen-
dence assumptions which may not be justified.
Various internal experiments show that decompo-
sition may decrease performance and that better
results can often be achieved by simply translat-
ing all factors jointly. While we can gain benefit
from adding factor information into phrase-based
decoding, our experience also shows the short-
comings of decomposing phrase translation.
3 Related Work
Efforts have been made to integrate syntactic in-
formation into the decoding process to improve re-
ordering.
Collins et al (2005) reorder the source sentence
using a sequence of six manually-crafted rules,
given the syntactic parse tree of the source sen-
tence. While the transformation rules are specific
to the German parser that was used, they could
be adapted to other languages and parsers. Xia
and McCord (2004) automatically create rewrite
rules which reorder the source sentence. Zhang
and Zens (2007) take a slightly different approach
by using chunk level tags to reorder the source
sentence, creating a confusion network to repre-
sent the possible reorderings of the source sen-
tence. All these approaches seek to improve re-
ordering by making the ordering of the source sen-
tence similar to the target sentence.
Costa-jussa` and Fonollosa (2006) use a two
stage process to reorder translation in an n-gram
based decoder. The first stage uses word classes of
source words to reorder the source sentence into
a string of word classes which can be translated
monotonically to the target sentences in the sec-
ond stage.
The Alignment Template System (Och, 2002)
performs reordering by translating word classes
with their corresponding alignment information,
then translates each surface word to be consis-
tent with the alignment. Tomas and Casacuberta
(2003) extend ATS by using POS tags instead of
automatically induced word classes.
Note the limitation of the existing work of POS-
driven reordering in phrase-based models: the re-
ordering model is separated from the translation
model and the two steps are pipelined, with pass-
ing the 1-best reordering or at most a lattice to the
translation stage. The ATS models do provide an
integrated approach, but their lexical translation is
374
limited to the word level.
In contrast to prior work, we present a inte-
grated approach that allows POS-based reordering
and phrase translation. It is also open to the use of
any other factors, such as driving reordering with
automatic word classes.
Our proposed solution is similar to structural
templates described in Phillips (2007) which was
applied to an example-based MT system.
4 Translation Using Templates of Factors
A major motivation for the introduction of fac-
tors into machine translation is to generalize
phrase translation over longer segments using less
sparse factors than is possible with surface forms.
(Koehn and Hoang, 2007) describes various strate-
gies for the decomposition of the decoding into
multiple translation models using the Moses de-
coder. We shall focus on POS-tags as an example
of a less-sparsed factor.
Decomposing the translation by separately de-
coding the POS tags and surface forms is be the
obvious option, which also has a probabilistic in-
terpretation. However, this combined factors into
target words which don?t exist naturally and bring
down translation quality. Therefore, the decoding
is constrained by decomposing into two transla-
tion models; a model with POS-tag phrase pairs
only and one which jointly translates POS-tags
and surface forms. This can be expressed using
feature-functions
h?TM(t?, s?) = h?
pos
TM (t?, s?)h?
surface
TM (t?, s?) (6)
Source segment must be decoded by both trans-
lation models but only phrase pairs where the over-
lapping factors are the same are used. As an ad-
ditional constraint, the alignment information is
retained in the translation model from the train-
ing data for every phrase pair, and both translation
models must produce consistent alignments. This
is expressed formally in Equation 7 to 9.
An alignment is a relationship which maps a
source word at position i to a target word at po-
sition j:
a : i? j (7)
Each word at each position can be aligned to
multiple words, therefore, we alter the alignment
relation to express this explicitly:
a : i? j (8)
where J is the set of positions, jJ , that I is
aligned to in the other language. Phrase pairs
for each translation model are used only if they
can satisfy condition 9 for each position of every
source word covered.
?a, b  T ?p : JpaJ
p
b 6= ? (9)
where Jpa is the alignment information for trans-
lation model, a, at word position, p and T is the set
of translation models.
4.1 Training
The training procedure is identical to the fac-
tored phrase-based training described in (Koehn
and Hoang, 2007). The phrase model retains the
word alignment information found during train-
ing. Where multiple alignment exists in the train-
ing data for a particular phrase pair, the most fre-
quent is used, in a similar manner to the calcula-
tion of the lexicalized probabilities.
Words positions which remain unaligned are ar-
tificially aligned to every word in the other lan-
guage in the phrase translation during decoding to
allow the decoder to cover the position.
4.2 Decoding
The beam search decoding algorithm is unchanged
from traditional phrase-based and factored decod-
ing. However, the creation of translation options is
extended to include the use of factored templates.
Translation options are the intermediate represen-
tation between the phrase pairs from the transla-
tion models and the hypotheses in the stack de-
coder which cover specific source spans of a sen-
tence and are applied to hypotheses to create new
hypotheses.
In phrase-based decoding, a translation option
strictly contains one phrase pair. In factored de-
coding, strictly one phrase pair from each trans-
lation model is used to create a translation op-
tions. This is possible only when the segmenta-
tion is identical for both source and target span of
each phrase pair in each translation model. How-
ever, this constraint limits the ability to use long
POS-tag phrase pairs in conjunction with shorter
surface phrase pairs.
The factored template approach extend factored
decoding by constructing translation options from
a single phrase pair from the POS-tag translation
model, but allowing multiple phrase pairs from
375
other translation models. A simplified stack de-
coder is used to compose phrases from the other
translation models. This so called intra-phrase de-
coder is constrained to creating phrases which ad-
heres to the constraint described in Section 4. The
intra-phrase decoder uses the same feature func-
tions as the main beam decoder but uses a larger
stack size due to the difficulty of creating com-
pleted phrases which satisfy the constraint. Every
source position must be covered by every transla-
tion model.
The intra-phrase decoder is used for each con-
tiguous span in the input sentence to produce
translation options which are then applied as usual
by the main decoder.
5 Experiments
We performed our experiments on the news com-
mentary corpus2 which contains 60,000 parallel
sentences for German?English and 43,000 sen-
tences for French?English. Tuning was done on
a 2000 sentence subset of the Europarl corpus
(Koehn, 2005) and tested on a 2000 sentence Eu-
roparl subset for out-of-domain, and a 1064 news
commentary sentences for in-domain.
The training corpus is aligned using Giza++
(Och and Ney, 2003). To create POS tag trans-
lation models, the surface forms on both source
and target language training data are replaced with
POS tags before phrases are extracted. The taggers
used were the Brill Tagger (Brill, 1995) for En-
glish, the Treetagger for French (Schmid, 1994),
and the LoPar Tagger (Schmidt and Schulte im
Walde, 2000) for German. The training script sup-
plied with the Moses toolkit (Koehn et al, 2007)
was used, extended to enable alignment informa-
tion of each phrase pair. The vanilla Moses MERT
tuning script was used throughout.
Results are also presented for models trained on
the larger Europarl corpora3.
5.1 German?English
We use as a baseline the traditional, non-factored
phrase model which obtained a BLEU score of
14.6% on the out-of-domain test set and 18.2% on
the in-domain test set (see Table 1, line 1).
POS tags for both source and target languages
were augmented to the training corpus and used in
the decoding and an additional trigram language
2
http://www.statmt.org/wmt07/shared-task.html
3http://www.statmt.org/europarl/
# Model out-domain in-domain
1 Unfactored 14.6 18.2
2 Joint factors 15.0 18.8
3 Factored template 15.3 18.8
Table 1: German?English results, in %BLEU
# Model out-domain in-domain
1 Unfactored 19.6 23.1
2 Joint factors 19.8 23.0
3 Factored template 20.6 24.1
Table 2: French?English results
model was used on the target POS tags. This
increased translation performance (line 2). This
model has the same input and output factors, and
the same language models, as the factored model
we will present shortly and it therefore offers a
fairer comparison of the factored template model
than the non-factored baseline.
The factored template model (line 3) outper-
forms the baseline on both sets and the joint factor
model on the out-of-domain set.
However, we believe the language pair
German?English is not particularly suited for
the factored template approach as many of the
short-range ordering properties of German and
English are similar. For example, ADJECTIVE
NOUN phrases are ordered the same in both
languages.
5.2 French?English
Repeating the same experiments for French?
English produces bigger gains for the factored
template model. See Table 4 for details. Using
the factored template model produces the best re-
sult, with gains of 1.0 %BLEU over the unfactored
baseline on both test sets. It also outperforms the
joint factor model.
5.3 Maximum Size of Templates
Typical phrase-based model implementation use a
maximum phrase length of 7 but such long phrases
are rarely used. Long templates over POS may be
more valuable. The factored template models were
retrained with increased maximum phrase length
but this made no difference or negatively impacted
translation performance, Figure 1.
However, using larger phrase lengths over 5
words does not increase translation performance,
376
Figure 1: Varying max phrase length
as had been expected. Translation is largely un-
affected until the maximum phrase length reaches
10 when performance drops dramatically. This re-
sults suggested that the model is limited to mid-
range reordering.
6 Lexicalized Reordering Models
There has been considerable effort to improve re-
ordering in phrase-based systems. One of the most
well known is the lexicalized reordering model
(Tillmann, 2004).
The model uses the same word alignment that is
used for phrase table construction to calculate the
probability that a phrase is reordered, relative to
the previous and next source phrase.
6.1 Smoothing
Tillmann (2004) proposes a block orientation
model, where phrase translation and reordering
orientation is predicted by the same probability
distribution p(o, s?|t?). The variant of this imple-
mented in Moses uses a separate phrase translation
model p(s?|t?) and lexicalized reordering model
p(o|s?, t?)
The parameters for the lexicalized reordering
model are calculated using maximum likelihood
with a smoothing value ?
p(o|s?, t?) =
count(o, s?, t?) + ?
?
o?(count(o, s?, t?) + ?)
(10)
where the predicted orientation o is either mono-
tonic, swap or discontinuous.
The effect of smoothing lexical reordering ta-
bles on translation is negligible for both surface
forms and POS tags, except when smoothing is
disabled (?=0). Then, performance decreases
markedly, see Figure 2 for details. Note that the
Figure 2: Effect of smoothing on lexicalized re-
ordering
# Model out-domain in-domain
1 Unfactored 19.6 23.1
1a + word LR 20.2 24.0
2 Joint factors 19.8 23.0
2a + POS LR 20.1 24.0
2b + POS LR + word LR 20.3 24.1
3 Factored template 20.6 24.1
3a + POS LR 20.6 24.3
Table 3: Extending the models with lexicalized re-
ordering (LR)
un-smoothed setting is closer to the block orienta-
tion model by Tillmann (2004).
6.2 Factors and Lexicalized Reordering
The model can easily be extended to take advan-
tage of the factored approach available in Moses.
In addition to the lexicalized reordering model
trained on surface forms (see line 1a in Table 3),
we also conducted various experiments with the
lexicalized reordering model for comparison.
In the joint factored model, we have both sur-
face forms and POS tags available to train the lex-
icalized reordering models on. The lexicalized re-
ordering model can be trained on the surface form,
the POS tags, jointly on both factors, or indepen-
dent models can be trained on each factor. It can
be seen from Table 3 that generalizing the reorder-
ing model on POS tags (line 2a) improves perfor-
mance, compared to the non-lexicalized reorder-
ing model (line 2). However, this performance
does not improve over the lexicalized reordering
model on surface forms (line 1a). The surface and
POS tag models complement each other to give an
overall better BLEU score (line 2b).
In the factored template model, we add a POS-
377
based lexicalized reordering model on the level of
the templates (line 3a). This gives overall the best
performance. However, the use of lexicalized re-
ordering models in the factored template model
only shows improvements in the in-domain test
set.
Lexicalized reordering model on POS tags in
factored models underperforms factored template
model as the latter includes a larger context of the
source and target POS tag sequence, while the for-
mer is limited to the extent of the surface word
phrase.
7 Analysis
A simple POS sequence that phrase-based systems
often fail to reorder is the French?English
NOUN ADJ ? ADJ NOUN
We analyzed a random sample of such phrases
from the out-of-domain corpus. The baseline
system correctly reorders 58% of translations.
Adding a lexicalized reordering model or the fac-
tored template significantly improves the reorder-
ing to above 70% (Figure 3).
Figure 3: Percentage of correctly ordered NOUN
ADJ phrases (100 samples)
A more challenging phrase to translate, such as
NOUN ADJ CONJ ADJ ? ADJ CONJ ADJ NOUN
was judge in the same way and the results show the
variance between the lexicalized reordering and
factored template model (Figure 4).
The factored template model successfully uses
POS tag templates to enable longer phrases to
be used in decoding. It can be seen from Fig-
ure 5, that the majority of input sentence is de-
coded word-by-word even in a phrase-based sys-
tem. However, the factored template configura-
Figure 4: Percentage of correctly ordered NOUN
ADJ CONJ ADJ phrases (69 samples)
Figure 5: Length of source segmentation when de-
coding out-of-domain test set
tion contains more longer phrases which enhances
mid-range reordering.
8 Larger training corpora
It is informative to compare the relative per-
formance of the factored template model when
trained with more data. We therefore used the Eu-
roparl corpora to train and tuning the models for
French to English translation. The BLEU scores
are shown below, showing no significant advan-
tage to adding POS tags or using the factored tem-
plate model. This result is similar to many others
which have shown that the large amounts of addi-
tional data negates the improvements from better
models.
# Model out-domain in-domain
1 Unfactored 31.8 32.2
2 Joint factors 31.6 32.0
3 Factored template 31.7 32.2
Table 4: French?English results, trained on Eu-
roparl corpus
378
9 Conclusion
We have shown the limitations of the current fac-
tored decoding model which restrict the use of
long phrase translations of less-sparsed factors.
This negates the effectiveness of decomposing
the translation process, dragging down translation
quality.
An extension to the factored model was imple-
mented which showed that using POS tag transla-
tions to create templates for surface word trans-
lations can create longer phrase translation and
lead to higher performance, dependent on lan-
guage pair.
For French?English translation, we obtained a
1.0% BLEU increase on the out-of-domain and in-
domain test sets, over the non-factored baseline.
The increase was also 0.4%/0.3% when using a
lexicalized reordering model in both cases.
In future work, we would like to apply the fac-
tored template model to reorder longer phrases.
We believe that this approach has the potential for
longer range reordering which has not yet been re-
alized in this paper. It also has some similarity to
example-based machine translation (Nagao, 1984)
which we would like to draw experience from.
We would also be interested in applying this to
other language pairs and using factor types other
than POS tags, such as syntactic chunk labels or
automatically clustered word classes.
Acknowledgments
This work was supported by the EuroMa-
trix project funded by the European Com-
mission (6th Framework Programme) and
made use of the resources provided by
the Edinburgh Compute and Data Facility
(http://www.ecdf.ed.ac.uk/). The
ECDF is partially supported by the eDIKT
initiative (http://www.edikt.org.uk/).
References
Anonymous (2008). Understanding reordering in statistical
machine translation. In (submitted for publucation).
Brill, E. (1995). Transformation-based error-driven learning
and natural language processing: A case study in part of
speech tagging. Computational Linguistics, 21(4).
Chiang, D. (2005). A hierarchical phrase-based model for
statistical machine translation. In Proceedings of the 43rd
Annual Meeting of the Association for Computational Lin-
guistics (ACL?05), pages 263?270, Ann Arbor, Michigan.
Association for Computational Linguistics.
Collins, M., Koehn, P., and Kucerova, I. (2005). Clause
restructuring for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL?05), pages 531?540,
Ann Arbor, Michigan. Association for Computational Lin-
guistics.
Costa-jussa`, M. R. and Fonollosa, J. A. R. (2006). Statisti-
cal machine reordering. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language Pro-
cessing, pages 70?76, Sydney, Australia. Association for
Computational Linguistics.
Koehn, P. (2005). Europarl: A parallel corpus for statistical
machine translation. In Proceedings of the Tenth Machine
Translation Summit (MT Summit X), Phuket, Thailand.
Koehn, P. and Hoang, H. (2007). Factored translation models.
In Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-CoNLL),
pages 868?876.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C.,
Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst,
E. (2007). Moses: Open source toolkit for statistical ma-
chine translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster Ses-
sions, pages 177?180, Prague, Czech Republic. Associa-
tion for Computational Linguistics.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase
based translation. In Proceedings of the Joint Conference
on Human Language Technologies and the Annual Meet-
ing of the North American Chapter of the Association of
Computational Linguistics (HLT-NAACL).
Nagao, M. (1984). A framework of a mechanical translation
between japanese and english by analogy principle. In
Proceedings of Artificial and Human Intelligence.
Och, F. J. (2002). Statistical Machine Translation: From
Single-Word Models to Alignment Templates. PhD thesis,
RWTH Aachen, Germany.
Och, F. J. and Ney, H. (2003). A systematic comparison of
various statistical alignment models. Computational Lin-
guistics, 29(1):19?52.
Phillips, A. B. (2007). Sub-phrasal matching and struc-
tural templates in example-based mt. In Theoretical and
Methodological Issues in Machine Translation, Prague,
Czech Republic.
Schmid, H. (1994). Probabilistic part-of-speech tagger using
decision trees. In International Conference on New meth-
ods in Language Processing.
Schmidt, H. and Schulte im Walde, S. (2000). Robust
German noun chunking with a probabilistic context-free
grammar. In Proceedings of the International Conference
on Computational Linguistics (COLING).
Tillmann, C. (2004). A unigram orientation model for statis-
tical machine translation. In Proceedings of the Joint Con-
ference on Human Language Technologies and the Annual
Meeting of the North American Chapter of the Association
of Computational Linguistics (HLT-NAACL).
Tomas, J. and Casacuberta, F. (2003). Combining phrase-
based and template-based alignment models in statistical
translation. In IbPRIA.
Xia, F. and McCord, M. (2004). Improving a statistical
MT system with automatically learned rewrite patterns.
In Proceedings of Coling 2004, pages 508?514, Geneva,
Switzerland. COLING.
Zhang, Y. and Zens, R. (2007). Improved chunk-level re-
ordering for statistical machine translation. In Interna-
tional Workshop on Spoken Language Translation.
379
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177?180,
Prague, June 2007. c?2007 Association for Computational Linguistics 
Moses: Open Source Toolkit for Statistical Machine Translation 
Philipp Koehn 
Hieu Hoang  
Alexandra Birch 
Chris Callison-Burch 
University of Edin-
burgh1 
Marcello Federico 
Nicola Bertoldi 
ITC-irst2 
Brooke Cowan 
Wade Shen 
Christine Moran 
MIT3 
Richard Zens 
RWTH Aachen4 
Chris Dyer 
University of Maryland5 
 
Ond?ej Bojar 
Charles University6 
Alexandra Constantin 
Williams College7 
Evan Herbst 
Cornell8 
1 pkoehn@inf.ed.ac.uk, {h.hoang, A.C.Birch-Mayne}@sms.ed.ac.uk, callison-burch@ed.ac.uk. 
2{federico, bertoldi}@itc.it. 3 brooke@csail.mit.edu, swade@ll.mit.edu, weezer@mit.edu. 4 
zens@i6.informatik.rwth-aachen.de. 5 redpony@umd.edu. 6 bojar@ufal.ms.mff.cuni.cz. 7 
07aec_2@williams.edu. 8 evh4@cornell.edu 
 
Abstract 
We describe an open-source toolkit for sta-
tistical machine translation whose novel 
contributions are (a) support for linguisti-
cally motivated factors, (b) confusion net-
work decoding, and (c) efficient data for-
mats for translation models and language 
models. In addition to the SMT decoder, 
the toolkit also includes a wide variety of 
tools for training, tuning and applying the 
system to many translation tasks.  
1 Motivation 
Phrase-based statistical machine translation 
(Koehn et al 2003) has emerged as the dominant 
paradigm in machine translation research. How-
ever, until now, most work in this field has been 
carried out on proprietary and in-house research 
systems. This lack of openness has created a high 
barrier to entry for researchers as many of the 
components required have had to be duplicated. 
This has also hindered effective comparisons of the 
different elements of the systems. 
By providing a free and complete toolkit, we 
hope that this will stimulate the development of the 
field. For this system to be adopted by the commu-
nity, it must demonstrate performance that is com-
parable to the best available systems. Moses has 
shown that it achieves results comparable to the 
most competitive and widely used statistical ma-
chine translation systems in translation quality and 
run-time (Shen et al 2006). It features all the ca-
pabilities of the closed sourced Pharaoh decoder 
(Koehn 2004). 
Apart from providing an open-source toolkit 
for SMT, a further motivation for Moses is to ex-
tend phrase-based translation with factors and con-
fusion network decoding. 
The current phrase-based approach to statisti-
cal machine translation is limited to the mapping of 
small text chunks without any explicit use of lin-
guistic information, be it morphological, syntactic, 
or semantic. These additional sources of informa-
tion have been shown to be valuable when inte-
grated into pre-processing or post-processing steps. 
Moses also integrates confusion network de-
coding, which allows the translation of ambiguous 
input. This enables, for instance, the tighter inte-
gration of speech recognition and machine transla-
tion. Instead of passing along the one-best output 
of the recognizer, a network of different word 
choices may be examined by the machine transla-
tion system. 
Efficient data structures in Moses for the 
memory-intensive translation model and language 
model allow the exploitation of much larger data 
resources with limited hardware. 
177
 2 Toolkit 
The toolkit is a complete out-of-the-box trans-
lation system for academic research. It consists of 
all the components needed to preprocess data, train 
the language models and the translation models. It 
also contains tools for tuning these models using 
minimum error rate training (Och 2003) and evalu-
ating the resulting translations using the BLEU 
score (Papineni et al 2002).  
Moses uses standard external tools for some of 
the tasks to avoid duplication, such as GIZA++ 
(Och and Ney 2003) for word alignments and 
SRILM for language modeling.  Also, since these 
tasks are often CPU intensive, the toolkit has been 
designed to work with Sun Grid Engine parallel 
environment to increase throughput.  
In order to unify the experimental stages, a 
utility has been developed to run repeatable ex-
periments. This uses the tools contained in Moses 
and requires minimal changes to set up and cus-
tomize. 
The toolkit has been hosted and developed un-
der sourceforge.net since inception. Moses has an 
active research community and has reached over 
1000 downloads as of 1st March 2007.  
The main online presence is at  
http://www.statmt.org/moses/ 
where many sources of information about the 
project can be found. Moses was the subject of this 
year?s Johns Hopkins University Workshop on 
Machine Translation (Koehn et al 2006). 
The decoder is the core component of Moses. 
To minimize the learning curve for many research-
ers, the decoder was developed as a drop-in re-
placement for Pharaoh, the popular phrase-based 
decoder. 
In order for the toolkit to be adopted by the 
community, and to make it easy for others to con-
tribute to the project, we kept to the following 
principles when developing the decoder: 
? Accessibility 
? Easy to Maintain 
? Flexibility 
? Easy for distributed team development 
? Portability 
It was developed in C++ for efficiency and fol-
lowed modular, object-oriented design. 
3 Factored Translation Model 
Non-factored SMT typically deals only with 
the surface form of words and has one phrase table, 
as shown in Figure 1. 
i am buying you a green cat
using phrase dictionary:
i
 am buying
you
a
green
cat
je
ach?te
vous
un
vert
chat
a une
je vous ach?te un chat vert
Translate:
 
In factored translation models, the surface 
forms may be augmented with different factors, 
such as POS tags or lemma. This creates a factored 
representation of each word, Figure 2.  
1 1 1 / sing /
                                 
je vous achet un chat
PRO PRO VB ART NN
je vous acheter un chat
st st st present masc masc
? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?
1 1 / 1 sing sing
i buy you a cat
PRO VB PRO ART NN
i tobuy you a cat
st st present st
? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?  
 
Mapping of source phrases to target phrases 
may be decomposed into several steps. Decompo-
sition of the decoding process into various steps 
means that different factors can be modeled sepa-
rately. Modeling factors in isolation allows for 
flexibility in their application. It can also increase 
accuracy and reduce sparsity by minimizing the 
number dependencies for each step. 
For example, we can decompose translating 
from surface forms to surface forms and lemma, as 
shown in Figure 3. 
Figure 2. Factored translation 
Figure 1. Non-factored translation 
178
  
Figure 3. Example of graph of decoding steps 
By allowing the graph to be user definable, we 
can experiment to find the optimum configuration 
for a given language pair and available data.  
The factors on the source sentence are consid-
ered fixed, therefore, there is no decoding step 
which create source factors from other source fac-
tors. However, Moses can have ambiguous input in 
the form of confusion networks. This input type 
has been used successfully for speech to text 
translation (Shen et al 2006). 
Every factor on the target language can have its 
own language model. Since many factors, like 
lemmas and POS tags, are less sparse than surface 
forms, it is possible to create a higher order lan-
guage models for these factors. This may encour-
age more syntactically correct output. In Figure 3 
we apply two language models, indicated by the 
shaded arrows, one over the words and another 
over the lemmas. Moses is also able to integrate 
factored language models, such as those described 
in (Bilmes and Kirchhoff 2003) and (Axelrod 
2006). 
4 Confusion Network Decoding 
Machine translation input currently takes the 
form of simple sequences of words. However, 
there are increasing demands to integrate machine 
translation technology into larger information 
processing systems with upstream NLP/speech 
processing tools (such as named entity recognizers, 
speech recognizers, morphological analyzers, etc.). 
These upstream processes tend to generate multiple, 
erroneous hypotheses with varying confidence. 
Current MT systems are designed to process only 
one input hypothesis, making them vulnerable to 
errors in the input.  
In experiments with confusion networks, we 
have focused so far on the speech translation case, 
where the input is generated by a speech recog-
nizer. Namely, our goal is to improve performance 
of spoken language translation by better integrating 
speech recognition and machine translation models. 
Translation from speech input is considered more 
difficult than translation from text for several rea-
sons. Spoken language has many styles and genres, 
such as, formal read speech, unplanned speeches, 
interviews, spontaneous conversations; it produces 
less controlled language, presenting more relaxed 
syntax and spontaneous speech phenomena. Fi-
nally, translation of spoken language is prone to 
speech recognition errors, which can possibly cor-
rupt the syntax and the meaning of the input. 
There is also empirical evidence that better 
translations can be obtained from transcriptions of 
the speech recognizer which resulted in lower 
scores. This suggests that improvements can be 
achieved by applying machine translation on a 
large set of transcription hypotheses generated by 
the speech recognizers and by combining scores of 
acoustic models, language models, and translation 
models. 
Recently, approaches have been proposed for 
improving translation quality through the process-
ing of multiple input hypotheses. We have imple-
mented in Moses confusion network decoding as 
discussed in (Bertoldi and Federico 2005), and de-
veloped a simpler translation model and a more 
efficient implementation of the search algorithm. 
Remarkably, the confusion network decoder re-
sulted in an extension of the standard text decoder. 
5 Efficient Data Structures for Transla-
tion Model and Language Models 
With the availability of ever-increasing 
amounts of training data, it has become a challenge 
for machine translation systems to cope with the 
resulting strain on computational resources. Instead 
of simply buying larger machines with, say, 12 GB 
of main memory, the implementation of more effi-
cient data structures in Moses makes it possible to 
exploit larger data resources with limited hardware 
infrastructure. 
A phrase translation table easily takes up giga-
bytes of disk space, but for the translation of a sin-
gle sentence only a tiny fraction of this table is 
needed. Moses implements an efficient representa-
tion of the phrase translation table. Its key proper-
ties are a prefix tree structure for source words and 
on demand loading, i.e. only the fraction of the 
phrase table that is needed to translate a sentence is 
loaded into the working memory of the decoder. 
179
 For the Chinese-English NIST  task, the mem-
ory requirement of the phrase table is reduced from 
1.7 gigabytes to less than 20 mega bytes, with no 
loss in translation quality and speed (Zens and Ney 
2007). 
The other large data resource for statistical ma-
chine translation is the language model. Almost 
unlimited text resources can be collected from the 
Internet and used as training data for language 
modeling. This results in language models that are 
too large to easily fit into memory. 
The Moses system implements a data structure 
for language models that is more efficient than the 
canonical SRILM (Stolcke 2002) implementation 
used in most systems. The language model on disk 
is also converted into this binary format, resulting 
in a minimal loading time during start-up of the 
decoder.  
An even more compact representation of the 
language model is the result of the quantization of 
the word prediction and back-off probabilities of 
the language model. Instead of representing these 
probabilities with 4 byte or 8 byte floats, they are 
sorted into bins, resulting in (typically) 256 bins 
which can be referenced with a single 1 byte index. 
This quantized language model, albeit being less 
accurate, has only minimal impact on translation 
performance (Federico and Bertoldi 2006). 
6 Conclusion and Future Work 
This paper has presented a suite of open-source 
tools which we believe will be of value to the MT 
research community. 
We have also described a new SMT decoder 
which can incorporate some linguistic features in a 
consistent and flexible framework. This new direc-
tion in research opens up many possibilities and 
issues that require further research and experimen-
tation. Initial results show the potential benefit of 
factors for statistical machine translation, (Koehn 
et al 2006) and (Koehn and Hoang 2007). 
References 
Axelrod, Amittai. "Factored Language Model for Sta-
tistical Machine Translation." MRes Thesis. 
Edinburgh University, 2006. 
Bertoldi, Nicola, and Marcello Federico. "A New De-
coder for Spoken Language Translation Based 
on Confusion Networks." Automatic Speech 
Recognition and Understanding Workshop 
(ASRU), 2005. 
Bilmes, Jeff A, and Katrin Kirchhoff. "Factored Lan-
guage Models and Generalized Parallel Back-
off." HLT/NACCL, 2003. 
Koehn, Philipp. "Pharaoh: A Beam Search Decoder for 
Phrase-Based Statistical Machine Translation 
Models." AMTA, 2004. 
Koehn, Philipp, Marcello Federico, Wade Shen, Nicola 
Bertoldi, Ondrej Bojar, Chris Callison-Burch, 
Brooke Cowan, Chris Dyer, Hieu Hoang, 
Richard Zens, Alexandra Constantin, Christine 
Corbett Moran, and Evan Herbst. "Open 
Source Toolkit for Statistical Machine Transla-
tion". Report of the 2006 Summer Workshop at 
Johns Hopkins University, 2006. 
Koehn, Philipp, and Hieu Hoang. "Factored Translation 
Models." EMNLP, 2007. 
Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 
"Statistical Phrase-Based Translation." 
HLT/NAACL, 2003. 
Och, Franz Josef. "Minimum Error Rate Training for 
Statistical Machine Translation." ACL, 2003. 
Och, Franz Josef, and Hermann Ney. "A Systematic 
Comparison of Various Statistical Alignment 
Models." Computational Linguistics 29.1 
(2003): 19-51. 
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. "BLEU: A Method for Automatic 
Evaluation of Machine Translation." ACL, 
2002. 
Shen, Wade, Richard Zens, Nicola Bertoldi, and 
Marcello Federico. "The JHU Workshop 2006 
Iwslt System." International Workshop on Spo-
ken Language Translation, 2006. 
Stolcke, Andreas. "SRILM an Extensible Language 
Modeling Toolkit." Intl. Conf. on Spoken Lan-
guage Processing, 2002. 
Zens, Richard, and Hermann Ney. "Efficient Phrase-
Table Representation for Machine Translation 
with Applications to Online MT and Speech 
Recognition." HLT/NAACL, 2007. 
180
Proceedings of the Third Workshop on Statistical Machine Translation, pages 139?142,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Towards better Machine Translation Quality
for the German?English Language Pairs
Philipp Koehn Abhishek Arun Hieu Hoang
School of Informatics
University of Edinburgh
pkoehn@inf.ed.ac.uk a.arun@sms.ed.ac.uk h.hoang@sms.ed.ac.uk
Abstract
The Edinburgh submissions to the shared task
of the Third Workshop on Statistical Machine
Translation (WMT-2008) incorporate recent
advances to the open source Moses system.
We made a special effort on the German?
English and English?German language pairs,
leading to substantial improvements.
1 Introduction
Edinburgh University participated in the shared task
of the ThirdWorkshop on Statistical Machine Trans-
lation (WMT-2008), which is partly funded by the
EUROMATRIX project, which also funds our work.
In this project, we set out to build machine trans-
lation systems for all language pairs of official EU
languages. Hence, we also participated in the shared
task in all language pairs.
For all language pairs, we used the Moses decoder
(Koehn et al, 2007), which follows the phrase-based
statistical machine translation approach (Koehn
et al, 2003), with default settings as a starting
point. We recently added minimum Bayes risk de-
coding and reordering constraints to the decoder. We
achieved consistent increase in BLEU scores with
these improvements, showing gains of up to 0.9%
BLEU on the 2008 news test set.
Most of our efforts were focused on the language
pairs German?English and English?German. For
both language pairs, we explored language-specific
and more general improvements, resulting in gains
of up to 1.5% BLEU for German?English and 1.4%
BLEU for English?German.
2 Recent Improvements
Over the last months, we added minimum Bayes risk
decoding and additional reordering constraints to the
Moses decoder. The WMT-2008 shared task offered
the opportunity to assess these components over a
large range of language pairs and tasks.
For all our experiments, we trained solely on the
Europarl corpus, which allowed us to treat the 2007
news commentary test set (nc-test2007) as a stand-
in for the 2008 news test set (news-2008), for which
we have no in-domain training data. This may have
resulted in lower performance due to less (and very
relevant) training data, but it also allowed us to opti-
mize for a true out-of-domain test set.
The baseline training uses Moses default param-
eters. We use a maximum sentence length of 80, a
phrase translation table with the five traditional fea-
tures, lexicalized reordering, and lowercase training
and test data. All reported BLEU scores are not case-
sensitive, computed using the NIST tool.
2.1 Minimum Bayes Risk Decoding
Minimum Bayes risk decoding was proposed by Ku-
mar and Byrne (2004). Instead of selecting the trans-
lation with the highest probability, minimum Bayes
risk decoding selects the translation that is most sim-
ilar to the highest scoring translations. Intuitively,
this avoid the selection of an outlier as the best trans-
lation, since the decision rule prefers translations
that are similar to other high-scoring translations.
Minimum Bayes risk decoding is defined as:
eMBR = argmaxe
?
e?
L(e, e?) p(e?|f)
As similarity function L, we use sentence-level
BLEU with add-one smoothing. As highest scoring
translations, we consider the top 100 distinct trans-
lations, for which we convert the translation scores
into a probability distribution p (with a scaling fac-
tor of 1). We tried other n-best list sizes and scaling
factors, with very similar outcomes.
139
Language Pair Baseline MBR MP MBR+MP
Spanish?German news 11.7 11.8 (+0.1) 11.9 (+0.2) 12.0 (+0.3)
Spanish?German ep 20.7 21.0 (+0.3) 20.8 (+0.1) 21.0 (+0.3)
German?Spanish news 16.2 16.3 (+0.1) 16.4 (+0.2) 16.6 (+0.4)
German?Spanish ep 28.5 28.6 (+0.1) 28.5 (?0.0) 28.6 (+0.1)
Spanish?English news 19.8 20.2 (+0.4) 20.2 (+0.4) 20.3 (+0.5)
Spanish?English ep 33.6 33.7 (+0.1) 33.6 (?0.0) 33.7 (+0.1)
English?Spanish news 20.1 20.5 (+0.4) 20.5 (+0.4) 20.7 (+0.6)
English?Spanish ep 33.1 33.1 (?0.0) 33.0 (?0.1) 33.1 (?0.0)
French?English news 18.5 19.1 (+0.6) 19.1 (+0.6) 19.2 (+0.7)
French?English ep 33.5 33.5 (?0.0) 33.4 (?0.1) 33.5 (?0.0)
English?French news 17.8 18.0 (+0.2) 18.2 (+0.4) 18.3 (+0.5)
English?French ep 31.1 31.1 (?0.0) 31.1 (?0.0) 31.1 (?0.0)
Czech?English news 14.2 14.4 (+0.2) 14.3 (+0.1) 14.5 (+0.3)
Czech?English nc 22.8 23.0 (+0.2) 22.9 (+0.2) 23.0 (+0.2)
English?Czech news 9.6 9.6 (?0.0) 9.7 (+0.1) 9.6 (?0.0)
English?Czech nc 12.9 13.0 (+0.1) 12.9 (?0.0) 13.0 (+0.1)
Hungarian?English news 7.9 8.3 (+0.4) 8.5 (+0.6) 8.8 (+0.9)
English?Hungarian news 6.1 6.3 (+0.2) 6.4 (+0.3) 6.5 (+0.4)
average news - +0.26 +0.33 +0.46
average ep - +0.08 ?0.02 +0.08
Table 1: Improvements in BLEU on the test sets test2008 (ep), newstest2008 (news) and nc-test2008 (nc) for minimum
Bayes risk decoding (MBR) and the monotone-at-punctuation reordering (MP) constraint.
2.2 Monotone at Punctuation
The reordering models in phrase-based translation
systems are known to be weak, since they essentially
relies on the interplay of language model, a general
preference for monotone translation, and (in the case
of lexicalized reordering) a local model based on a
window of neighboring phrase translations. Allow-
ing any kind of reordering typically reduces transla-
tion performance, so reordering is limited to a win-
dow of (in our case) six words.
One noticeable weakness is that the current model
frequently reorders words beyond clause bound-
aries, which is almost never well-motivated, and
leads to confusing translations. Since clause bound-
aries are often indicated by punctuation such as
comma, colon, or semicolon, it is straight-forward
to introduce a reordering constraint that addresses
this problem.
Our implementation of a monotone-at-punc-
tuation reordering constraint (Tillmann and Ney,
2003) requires that all input words before clause-
separating punctuation have be translated, before
words afterwards are covered. Note that this con-
straint does not limit in any way phrase translations
that span punctuation.
2.3 Results
Table 1 summarizes the impact of minimum
Bayes risk decoding (MBR) and the monotone-
at-punctuation reordering constraint (MP). Scores
show higher gains for out-of-domain news test sets
(+0.46) than for in-domain Europarl sets (+0.08).
3 German?English
Translating between German and English is surpris-
ingly difficult, given that the languages are closely
related. The main sources for this difficulty is the
different syntactic structure at the clause level and
the rich German morphology, including the merging
of noun compounds.
In prior work, we addressed reordering with a
pre-order model that transforms German for train-
ing and testing according to a set of hand-crafted
rules (Collins et al, 2005). Employing this method
to our baseline system leads to an improvement of
+0.8 BLEU on the nc-test2007 set and +0.5 BLEU on
the test2007 set.
140
German?English nc-test2007 test2007
baseline 20.3 27.6
tokenize hyphens 20.1 (?0.2) 27.6 (?0.0)
tok. hyph. + truecase 20.7 (+0.4) 27.8 (+0.2)
Table 2: Impact of truecasing on case-sensitive BLEU
In a more integrated approach, factored transla-
tion models (Koehn and Hoang, 2007) allow us to
consider grammatical coherence in form of part-
of-speech language models. When translating into
output words, we also generate a part-of-speech tag
along with each output word. Since there are only 46
POS tags in English, we are able to train high-order
n-gram models of these sequences. In our experi-
ments, we used a 7-gram model, yielding improve-
ments of +0.2/?0.1. We obtained the POS tags using
Brill?s tagger (Brill, 1995).
Next, we considered the problem of unknown in-
put words, which is partly due to hyphenated words,
noun compounds, and morphological variants. Us-
ing the baseline model, 907 words (1.78%) in nc-
test2007 and 262 (0.47%) in test2007 are unknown.
First we separate our hyphens by tokenizing words
such as high-risk into high @-@ risk. This reduces
the number of unknown words to 791/224. Unfor-
tunately, it hurts us in terms of BLEU (?0.1/?0.1).
Second, we split compounds using the frequency-
based method (Koehn and Knight, 2003), reducing
the number of unknown words to than half, 424/94,
improving BLEU on nc-test2007 (+0.5/?0.2).
A final modification to the data preparation is
truecasing. Traditionally, we lowercase all training
and test data, but especially in German, case marks
important distinctions. German nouns are capital-
ized, and keeping case allows us to make the dis-
tinction between, say, the noun Wissen (knowledge)
and the verb wissen (to know). By truecasing, we
only change the case of the first word of a sentence
to its most common form. This method still needs
some refinements, such as the handling of headlines
or all-caps text, but it did improve performance over
the hyphen-tokenized baseline (+0.3/+0.2) and the
original baseline (+0.2/+0.1).
Note that truecasing simplifies the recasing prob-
lem, so a better way to gauge its effect is to look
at the case-sensitive BLEU score. Here the dif-
ference are slightly larger over both the hyphen-
tokenized baseline (+0.6/+0.2) and the original base-
German?English nc-test2007 test2007
baseline 21.3 28.4
pos lm 21.5 (+0.2) 28.3 (?0.1)
reorder 22.1 (+0.8) 28.9 (+0.5)
tokenize hyphens 21.2 (?0.1) 28.3 (?0.1)
tok. hyph. + split 21.8 (+0.5) 28.2 (?0.2)
tok. hyph. + truecase 21.5 (+0.2) 28.5 (+0.1)
mp 21.6 (+0.3) 28.2 (?0.2)
mbr 21.4 (+0.1) 28.3 (?0.1)
big beam 21.3 (?0.0) 28.3 (?0.1)
Table 3: Impact of individual modifications for German?
English, measured in BLEU on the development sets
German?English nc-test2007 test2007
baseline 21.3 28.4
+ reorder 22.1 (+0.8) 28.9 (+0.5)
+ tokenize hyphens 22.1 (+0.8) 28.9 (+0.5)
+ truecase 22.7 (+1.3) 28.9 (+0.5)
+ split 23.0 (+1.7) 29.1 (+0.7)
+ mbr 23.1 (+1.8) 29.3 (+0.9)
+ mp 23.3 (+2.0) 29.2 (+0.8)
Table 4: Impact of combined modifications for German?
English, measured in BLEU on the development sets
line (+0.4/+0.2). See the Table 2 for details.
As for the other language pairs, using the
monotone-at-punctuation reordering constraint
(+0.3/?0.2) and minimum Bayes risk decoding
(+0.1/?0.1) mostly helps. We also tried bigger
beam sizes (stack size 1000, phrase table limit 50),
but without gains in BLEU (?0.0/?0.1).
Table 3 summarizes the contributions of the indi-
vidual modifications we described above. For our fi-
nal system, we added the improvements one by one
(see Table 4), except for the bigger beam size and
the POS language model. This led to an overall in-
crease of +2.0/+0.8 over the baseline. Due to a bug
in splitting, the system we submitted to the shared
task had a score of only +1.5/+0.6 over the baseline.
4 English?German
For English?German, we applied many of the same
methods as for the inverse language pair. Tok-
enizing out hyphens has questionable impact (?
0.1/+0.1), while truecasing shows minor gains
(?0.0/+0.1), slightly higher for case-sensitive scor-
ing (+0.2/+0.3). We have not yet developed a
method that is the analog of the compound splitting
141
English?German nc-test2007 test-2007
baseline 14.6 21.0
tokenize hyphens 14.5 (?0.1) 21.1 (+0.1)
tok. hyph. + truecase 14.6 (?0.0) 21.1 (+0.1)
morph lm 15.7 (+1.1) 21.2 (+0.2)
mbr 14.9 (+0.3) 21.0 (?0.0)
mp 14.8 (+0.2) 20.9 (?0.1)
big beam 14.7 (+0.1) 21.0 (?0.0)
Table 5: Impact of individual modifications for English?
German, measured in BLEU on the development sets
method ? compound merging. We consider this an
interesting challenge for future work.
While the rich German morphology on the source
side mostly poses sparse data problems, on the tar-
get side it creates the problem of which morpholog-
ical variant to choose. The right selection hinges
on grammatical agreement within noun phrases, the
role that each noun phrase plays in the clause, and
the grammatical nature of the subject of a verb. We
use LoPar (Schmidt and Schulte im Walde, 2000),
which gives us morphological features such as
case, gender, count, although in limited form, it of-
ten opts for more general categories such as not gen-
itive. We include these features in a sequence model,
as we used a sequence model over part-of-speech
tags previously. The gains of this method are espe-
cially strong for the out-of-domain set (+1.1/+0.2).
Minimum Bayes risk decoding (+0.3/?0.0),
themonotone-at-punctuation reordering constraint
(+0.2/?0.1), and bigger beam sizes (+0.1/?0.0)
have similar impact as for the other language pairs.
See Table 5 for a summary of all modifications. By
combining everything except for the bigger beam
size, we obtain overall gains of +1.4/+0.4 over the
baseline. For details, refer to Table 6.
5 Conclusions
We built Moses systems trained on either only Eu-
roparl data or, for Czech and Hungarian, the avail-
able training data. We showed gains with minimum
Bayes risk decoding and a reordering constraint in-
volving punctuation. For German?English, we em-
ployed further language-specific improvements.
Acknowledgements: This work was supported in part
under the EuroMatrix project funded by the European
Commission (6th Framework Programme).
English?German nc-test2007 test2007
baseline 14.6 21.0
+ tokenize hyphens 14.5 (?0.1) 21.1 (+0.1)
+ truecase 14.6 (?0.0) 21.1 (+0.1)
+ morph lm 15.4 (+0.8) 21.3 (+0.3)
+ mbr 15.7 (+1.1) 21.4 (+0.4)
+ mp 16.0 (+1.4) 21.4 (+0.4)
Table 6: Impact of combined modifications for English?
German, measured in BLEU on the development sets
References
Brill, E. (1995). Transformation-based error-driven learning
and natural language processing: A case study in part of
speech tagging. Computational Linguistics, 21(4).
Collins, M., Koehn, P., and Kucerova, I. (2005). Clause re-
structuring for statistical machine translation. In Proceed-
ings of the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL?05), pages 531?540, Ann Arbor,
Michigan. Association for Computational Linguistics.
Koehn, P. and Hoang, H. (2007). Factored translation mod-
els. In Proceedings of the 2007 Joint Conference on Empiri-
cal Methods in Natural Language Processing and Computa-
tional Natural Language Learning (EMNLP-CoNLL), pages
868?876.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico,
M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R.,
Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open source toolkit for statistical machine trans-
lation. In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics Companion Vol-
ume Proceedings of the Demo and Poster Sessions, pages
177?180, Prague, Czech Republic. Association for Compu-
tational Linguistics.
Koehn, P. and Knight, K. (2003). Empirical methods for com-
pound splitting. In Proceedings of Meeting of the Euro-
pean Chapter of the Association of Computational Linguis-
tics (EACL).
Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase
based translation. In Proceedings of the Joint Conference on
Human Language Technologies and the Annual Meeting of
the North American Chapter of the Association of Computa-
tional Linguistics (HLT-NAACL).
Kumar, S. and Byrne, W. (2004). Minimum bayes-risk decod-
ing for statistical machine translation. In Proceedings of the
Joint Conference on Human Language Technologies and the
Annual Meeting of the North American Chapter of the Asso-
ciation of Computational Linguistics (HLT-NAACL).
Schmidt, H. and Schulte im Walde, S. (2000). Robust German
noun chunking with a probabilistic context-free grammar. In
Proceedings of the International Conference on Computa-
tional Linguistics (COLING).
Tillmann, C. and Ney, H. (2003). Word reordering and a dy-
namic programming beam search algorithm for statistical
machine translation. Computational Linguistics, 29(1).
142
Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 58?65,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Design of the Moses Decoder for Statistical Machine Translation 
Hieu Hoang  
University of Edinburgh 
h.hoang@sms.ed.ac.uk 
Philipp Koehn 
University of Edinburgh 
pkoehn@inf.ed.ac.uk 
 
Abstract 
We present a description of the implemen-
tation of the open source decoder for statis-
tical machine translation which has become 
popular with many researchers in SMT re-
search. The goal of the project is to create 
an open, high quality phrase-based decoder 
which can reduce the time and barrier to 
entry for researchers wishing to do SMT 
research. We discuss the major design ob-
jective for the Moses decoder, its perform-
ance relative to other SMT decoders, and 
the steps we are taking to ensure that its 
success will continue. 
1 Motivation 
Phrase-based translation has been one of the 
major advances in statistical machine translation 
(Brown et al 1990) in recent years and is currently 
one of the techniques which can claim to be state-
of-the-art in machine translation. Phrase-based 
models are a development of the word based mod-
els as exemplified by the (Brown et al 1990). In 
phrase-based translation, contiguous segments of 
words in the input sentence are mapped to contigu-
ous segments of words in the output sentence.  
In SMT, we are given a source language sen-
tence, s, which is to be translated into a target lan-
guage sentence, t. The goal of machine translation 
is to find the translation, t? , which is defined as: 
? arg max ( | )tt p t s=  
where ( | )p t s is the probability model. The argmax 
implies a search for the best translation t?  in the 
space of possible translations t. This search is the 
task of the decoder, which we will concentrate on 
in this paper. 
There have been numerous implementations of 
phrase-based decoders for SMT prior to our work. 
Early systems such as the Alignment Template 
System (ATS) (Och and Ney 2004) and Pharaoh 
(Koehn 2004) were widely used and accepted by 
the research community. ATS is perhaps the cross-
over system, in that word classes were translated as 
phrases but the surface words were translated word 
by word. Pharaoh substituted the word classes with 
surface words, thereby discarding the use of word 
classes in decoding altogether. 
There has been other phrase-based decoders 
such as PORTAGE (Sadat et al 2005), Phramer 
(Olteanu et al 2006), the MITLL/AFRL system 
(Shen et al 2005), ITC-irst (Bertoldi et al 2004), 
Ramses/Mood (Patry et al 2006) to name but a 
few. Other researchers such as (Kumar and Byrne 
2003) have also used weighted finite state trans-
ducers but they have more difficulty modeling re-
ordering. 
Many early systems came with restrictive li-
censes; ATS has never been publicly released, 
Pharaoh was released in 2003 as a pre-compiled 
binary with documentation. This severely limited 
the extent to which other researchers can study and 
enhance the decoder. Without access to the de-
coder source code research was generally restricted 
to altering the input, augmenting it with extra in-
formation, or modifying the output or re-ranking 
the n-best list output.  
The main contribution of this paper is to show 
how we have created an extensible decoder, has 
acceptable run time performance compared to 
similar systems, and the ease of use and develop-
ment that has made it the preferred choice for re-
searchers looking for a phrase-based SMT decoder.  
58
 As an indication of the take-up of the Moses 
toolkit, out of over 20 competing teams at the re-
cent IWSLT 2007 conference1, half used Moses. 
As an indication of the extensibility of the de-
coder, there are currently four language model im-
plementations which has been integrated with the 
decoder by various researchers. In addition, the 
framework exists to integrate language models, 
such as those described in (Bilmes and Kirchhoff 
2003), which takes advantage of the factored rep-
resentation within Moses. 
 It is noted that Mood/Ramses also supports 
multiple LM implementations, an internally devel-
oped language model, in additional to SRILM, to 
overcome the latter?s licensing restrictions. 
In addition, there are two built-in phrase table 
implementations, one which loads all data into 
memory for fast decoding, and a binary phrase ta-
ble as described in (Zens and Ney 2007) which 
loads on demand to conserve memory usage. 
The Moses decoder has the ability to accept 
simple sentence input, confusion network or lattice 
networks, in common with SMT decoders such as 
the MITLL/AFRL or ITC-irst systems. The de-
coder also produces diverse types of output, rang-
ing from 1-best, n-best lists and word lattices. 
2 Comparison with other projects 
The Moses decoder is designed within a strict 
modular and object-oriented framework for easy 
maintainability and extensibility. 
In designing the decoder, we modeled the soft-
ware design methodology and aims on some re-
search-oriented software libraries outside of the 
SMT and NLP field which is open source, written 
in C++, have a large and diverse user-base, have 
succeeded in becoming the industry norm in their 
field.  
Specifically, we modeled the software on the 
CGAL library (Fabri et al 2000), used in computa-
tional geometry, and DCMTK (Eichelberg et al 
2004) library used in medical imaging. We believe 
they set good examples of the standards that we 
should follow. 
However, there are differences between our pro-
ject and CGAL or DCMTK. 
The first difference is project size, for example, 
whereas CGAL consists of over 500,000 lines of 
                                                 
1
 http://iwslt07.oitc.it/menu/program.html 
code and multiple libraries and example program, 
the Moses decoder consists of 20,000 lines in 2 
libraries. The difference is scale makes implement-
ing some steps in the development life cycle im-
practical or unnecessary. For example, functional-
ity specification before implementation was de-
scribed for CGAL and is typical of large projects 
but would have been cumbersome for Moses. 
Secondly, the aims of Moses and these projects 
are different. The goal of the CGAL project is to 
?make?computational geometry available for in-
dustrial application?2. 
Both CGAL and DCMTK are used extensively 
in commercial applications. Therefore, issues such 
robustness, cross-platform compatibility and ease-
of-use are predominant for these projects. 
Commercialization is not an aim of the Moses 
project but we believe these issues are still as im-
portant as they affect the usability and uptake of 
the system. Therefore, the Moses decoder was built 
to address these issues without compromising the 
academic priorities of the project.  
Thirdly, the correct implementation is easier to 
decide in libraries such as CGAL as the algorithms 
are closely specified by the mathematical specifi-
cation, therefore, testing and specification writing 
is more prevalent and easier than in Moses. For 
DCMTK, the medical imaging standards and pro-
tocols offers a clear guide for implementation. By 
contrast, the function of an SMT decoder is search 
for which there are no correct implementation, we 
can only measure its performance relative to previ-
ous versions and other similar decoders. 
These differences are minor compared to the 
similarities Moses has to CGAL and DCMTK, and 
indeed, to any well developed software project. 
Design goals such as robustness, flexibility, ease of 
use and efficiency are commonality that we share 
and which we will discuss in more detail in the 
next section. 
As a contrast to CGAL and DCMTK whose de-
sign we would like to emulate, we also looked at a 
project within the NLP field which contains certain 
aspect in the design we would like to avoid. 
GIZA++ (Och and Ney 2003) is a very popular 
system within SMT for creating word alignment 
from parallel corpus, in fact, the Moses training 
scripts uses it. The system was release under the 
GPL open source license. However, its lack of 
                                                 
2
 http://cordis.europa.eu/esprit/src/21957.htm 
59
 clear design, documentation and obscure coding 
style makes it difficult for other researcher to con-
tribute or extend the system. For a long time, it 
couldn?t even be compiled on modern GCC com-
pilers. Other systems which seeks to improve word 
alignment and segmentation, such as MTTK (Deng 
et al 2006), have been created to replace GIZA++.  
3 Design Goals 
We decided to develop the Moses decoder as a 
C++ library.  
We steered clear of scripting languages for per-
formance reasons and the fact they often offer even 
less in the way of cross-platform compatibility. 
Java was also avoided for performance reasons but 
it?s rich library and multi-platform support would 
have been useful. 
We note that Hiero (Chiang 2005) is written in a 
scripting language with performance critical com-
ponents rewritten in a compiled language. This is 
not the approach we considered as we believed it 
would have raised the complexity and reduce reli-
ability of the project having to develop (and debug) 
in two languages and managing the interface be-
tween them. We also note that the LinearB and 
Phramer decoders are implemented in Java and 
have reported significantly worse run time speeds, 
(Olteanu et al 2006). 
C++ can be inelegant and difficult for inexperi-
enced developers but using other object oriented 
language such as Smalltalk or C# was out of the 
question as they lack acceptance within the MT 
research community. 
3.1 Comparable Performance 
The Pharaoh decoder (Koehn 2004) represented 
the state-of-the-art in phrase-based decoders prior 
to the introduction of Moses. Moses was designed 
to supersede Pharaoh in performance and function-
ality. Moses was used as the basis for the JHU 
Workshop (Koehn et al 2006) on Factored Ma-
chine Translation where it was extensively en-
hanced; we capitalized on the experience of col-
leagues at the workshop and used Pharaoh as the 
baseline during development to ensure that we ob-
tain comparable performance. Table 1 shows the 
comparison of the translation performance of Phar-
aoh and Moses for a typical decoding of 2000 sen-
tence trained on the news-commentary corpus3. We 
also include Phramer as an example of a Java-
based decoder. Due to improvements in the search 
algorithm, Moses can slightly outperform Pharaoh 
on most tasks, which was confirmed by (Shen et al 
2007). 
Table 1 Comparison with pharaoh & Phramer for a 
typical fr-en translation of 2000 sentences 
 Time 
taken 
Peak 
memory 
usage 
BLEU 
Pharaoh 99min 46MB 19.57 
Moses 69min 154MB 19.57 
Moses, with load 
on-demand PT & 
LM 
102min 239MB 19.57 
Phramer 649min 1218MB 19.44 
 
In addition, most of the functionality of Pharaoh 
has been replicated. 
3.2 Integration of Word-Level Factors 
The Moses decoder isn?t purely a clone of Phar-
aoh, it was created to conduct research into word-
level factors in phrase-base MT. Whereas tradi-
tional, non-factored SMT typically deals only with 
the surface form of words, factored translation 
models augments different factors, such as POS 
tags or lemma, into source and target sentences to 
improve translation. This transforms the represen-
tation of a word from a string to a vector of strings, 
and a phrase or sentence from a sequence of words 
to a sequence of vectors. Such a change to the ba-
sic data structure of a decoder propagated through-
out the rest of the system, therefore, it was simpler 
to build the Moses decoder from scratch rather 
than extend an existing decoder such as Pharaoh. 
Some research into factored machine translation 
has been published by (Koehn and Hoang 2007). 
3.3 Flexibility 
Flexibility is an important software design goal 
which will enable researchers to extend the use of 
the Moses decoders to tasks that were not origi-
nally envisioned.  
Following (Fabri et al 2000), we identify four 
sub-issues which affects flexibility: 
i. Modularity 
                                                 
3
 http://www.statmt.org/wmt07/shared-task.html 
60
 ii. Adaptability 
iii. Extensibility 
iv. Openness 
3.4 Modularity 
Firstly, software modularity enables developers 
to work on one component of the decoder without 
affecting other components. A modular design re-
duces the learning curve for developers by shield-
ing them from having to understand the entire sys-
tem if they are only developing a specific part.  
Modularity also assists in the re-using of com-
ponents by separating the implementation details 
from the module interface. 
Moses takes advantage of C++ support for ob-
ject-oriented and generic programming to enable 
modularity. 
In keeping with the extensible design of CGAL 
and DCMTK, the core of the decoder is compiled 
as a static library which can interact with other 
components through a well-defined API. The sim-
ple application which currently comes with the 
decoder enables users to use the system via the 
command line and also provides an example of the 
API. 
Therefore, the current typical compilation of the 
decoder would combine the libraries from 
IRSTLM, SRILM, Moses, and moses-cmd to cre-
ate a binary executable. 
SRILM IRSTLM
moses
moses-
cmd
 
Figure 1 Project Dependencies 
Any of these libraries can be dropped or re-
placed with other components with the same API. 
We detail some examples of the object-oriented 
design of Moses below. 
The input into the decoder can be one of three 
types: a simple string (sentence), a confusion net-
work or a lattice network, Figure 2. 
 
Figure 2 Input Types 
Language models are abstracted to enable different 
implementations to be used and provide a frame-
work for more complex models such as factored 
LM and the Bloom filter language model (Talbot 
and Osborne 2007). Similarly, phrase tables are 
abstracted to provide support for multiple imple-
mentations. 
Each component model which contributes to the 
log-linear hypothesis score inherits from the 
ScoreProducer base class, Figure 3. 
 
Figure 3 Score Producer 
The Moses library provide a simple API whose 
main entry point is the class 
 Manager 
This class is instantiated in the client application, 
moses-cmd in our case. Each input is decoded by 
calling the class method below: 
 ProcessSentence() 
3.5 Adaptability 
Phrase-based SMT is a fast moving research 
field where virtually all aspects of the theory are 
61
 still being explored and implementations can be 
improved. The Moses decoder has to be amenable 
to researchers to adapt any component of the de-
coder in ways that perhaps wasn?t foreseen in the 
original implementation.  
Certainly, modularity plays an important part 
in this but it can also have the opposite effect of 
allowing obtuse or badly written implementation to 
hide behind the API, reducing the ability for re-
searchers to question, investigate or extend. As a 
voluntary project, there is limited power to enforce 
good implementation and it would be difficult not 
to accept added functionality. 
However, we use coding standards and designs 
during the development of the decoder that we 
hope makes the task of working with Moses easier  
for developers, and that they will continue to use 
those standards to uphold the clarity of the code. 
These coding standards include: 
i. strict object-oriented design 
ii. descriptive variable, class, object and  
function names 
iii. consistent indentation 
iv. use of STL containers 
v. implementation of STL-compatible it-
erators for internal container classes. 
The source code for the Moses decoder has con-
tributions from a number of developers in the last 
two years, Figure 4, including four developers who 
have made significant contributions but were not in 
the original JHU Workshop. However, code clarity 
has, by-and-large, remained intact. 
0%
10%
20%
30%
40%
50%
60%
70%
lex
i_b
irc
h
cc
or
be
tt
nic
ola
be
rto
ldi
ab
ar
un
jdsc
hro
ed
er
eh
er
bs
t
ph
ko
eh
n
ko
nr
ad
_
ra
wli
k
ze
ns
re
dp
on
y
hie
uh
oa
ng
19
72
%
ag
e 
o
f c
o
de
 
co
m
m
ite
d
 
Figure 4 Code committed 
We do not know how the decoder will be 
changed in future, nor do we know where and by 
whom it will be used. Moses is first and foremost 
an academic project but that doesn?t exclude its use 
in commercial applications.  
We also believe that it will be useful as a teach-
ing tool for computational linguists, machine trans-
lation researchers or general computer science stu-
dents. It is important with such a diverse potential 
user base, with widely varying degrees of C++ and 
programming experience, that we make the devel-
opment and use of Moses as easy as possible, 
without imposing a significant burden on advanced 
users. 
We would like to lower the learning curve by 
letting users use Moses in an environment and 
tools where they are most comfortable with. There-
fore, the Moses decoder is operating system and 
compiler neutral. It is known to run on Windows 
(natively, or with Cygwin), Linux 32 and 64 bits, 
Mac OSX and OpenBSD. It is known to be com-
pileable with modern gcc compilers, Visual Stu-
dio.net, Intel C++ for both Linux and Windows. 
We encourage the use of modern graphical inte-
grated development environments (IDE) for Moses 
and include project files for Visual Studio, Eclipse 
and XCode, in addition to conventional makefiles. 
We note that almost half of the source code 
downloads for the Moses toolkit from Sourceforge 
are for the non-Unix version, and that 58% of the 
visitors to the Moses website uses Windows, 
Figure 5. 
Window s
Linux
Mac
Other
 
Figure 5 OS of Moses website visitors 
This heterogeneous approach allows developers 
who have previously been excluded to participate 
within the SMT community and strengthens the 
decoder by allowing people of different back-
grounds to apply their skills. This is of particular 
concern to us as we are attempting to integrate lin-
62
 guistic information into machine translation with 
factored decoding. 
 It also enables best-of-breed tools to be bought 
to the development of the decoder, regardless of 
platform. For example, we use both open source 
and commercial tools on Linux and Windows to 
track down memory issues, as well as performance 
profilers. This greatly enhances the efficiency of 
development and the reliability of the decoder. 
Other NLP libraries, such as SRILM (Stolcke 
2002) can be compiled and executed under multi-
ple platforms but its development are very much 
Unix-centric so requires porting tools for non-Unix 
platforms. We believe the platform and compiler 
agnostic approach is unique for a major open 
source C++ project within recent NLP history.  
3.6 Openness 
An important reason for initiating the Moses 
project was the need to create a competitive de-
coder which could be extended with factors, as 
well as other advances in phrase-based machine 
translation. It is open source to enable other re-
searchers to extend a state-of-the-art decoder with-
out having to recreate what we have already built. 
The decoder was improved at the JHU Work-
shop by a number of researchers so it needed to be 
flexible from the beginning. From this experience, 
we realize that releasing the source code is not 
enough. The decoder must be written and struc-
tured in a clear way to enable other researchers to 
contribute to the project. 
Aside from the legalese of releasing the source 
code under an open source license, we believe that 
open source also means the source code is clear 
and accessible to allow others to examine, critique 
and contribute. Coding standards aimed at source 
code clarity and support for modern tools backs 
this goal. 
Documentation of the algorithms used, and of 
the source code are also essential to allow others to 
understand the details of the decoder. Every class 
and function in the Moses decoder is commented 
in a Doxygen compatible format, HTML docu-
ments and figures, such as those in Figure 2 and 
Figure 3, are generated automatically from these 
comments and accessible via the Web4. 
Development is done through a source control 
system and all code changes are open to inspec-
                                                 
4
 http://www.statmt.org/moses/html/ 
tion. We encourage and enable all developers to 
use and extend Moses and feed back improve-
ments. However, to ensure that the performance of 
the decoder is maintained and that changes to the 
decoder doesn?t break existing setups, we maintain 
certain controls over the commit process.  
There is a regression test suite which should be 
passed before any code can be committed to ensure 
that unintended divergence haven?t crept in.  A 
framework exists for creation of regression tests, 
developers who add new functionality to the de-
coder are encouraged to create additional tests to 
ensure that their functionality will work in future.  
However, no amount of automated testing can 
be exhaustive. New committers are subject to peer 
review by a more experience contributor before the 
code is committed, and before the contributor is 
granted write access to the source control system. 
Also, code commits are monitored via email notifi-
cations to a public mailing list. 
These measures add a little overhead to the de-
velopment process this is necessary to maintain the 
quality of the system and assure to users and de-
velopers. 
We have benefited from the examples of sound 
software engineering principles set by the CGAL 
and DCMTK project and hope that we will emulate 
their success by bringing these engineering princi-
ples into NLP. In contrast to the ?abandonware? 
status of GIZA++, both CGAL and DCMTK are 
still being developed. 
4 Supporting Infrastructure 
Other factors have contributed to the wide adop-
tion of Moses. 
4.1 ?One-Stop Shop? for Phrase-Based SMT 
The Moses project encompasses the decoder and 
many of the other components necessary to create 
a translation system which were previously avail-
able separately. These include scripts for creating 
alignments from a parallel corpus, creating phrase 
tables and language models, binarizing phrase ta-
bles, scripts for weight optimization using MERT 
(Och 2003), and testing scripts.  
Steps such as MERT and testing which are CPU 
intensive have been re-engineered to run in parallel 
using Sun Grid Engine. 
All scripts have also been extended for factored 
translation. 
63
 4.2 Ongoing support 
We assist in the adoption of Moses by offering 
ongoing support to users and developers through 
the support mailing list 5 . Questions relating to 
Moses, phrase-based translation or machine trans-
lation in general are often asked, and usually an-
swered. The archived emails are publicly available 
and searchable, and have become an important 
knowledge source for the community. 
The mailing list popularity has been steadily in-
creasing since its inception, Figure 6, and is now 
the most popular mailing list for machine transla-
tion, based on volume. 
0
20
40
60
80
100
120
140
160
N
ov
-
06
D
ec
-
06
Ja
n
-
07
Fe
b-
07
M
ar
-
07
Ap
r-
07
M
ay
-
07
Ju
n
-
07
Ju
l-0
7
Au
g-
07
Se
p-
07
O
c
t-0
7
N
ov
-
07
D
ec
-
07
Ja
n
-
08
Fe
b-
08
 
Figure 6 Emails to Moses support mailing list 
5 Future Work 
There has been some important developments in 
phrase-based translation in recent years, including 
the hierarchical phrase-based model as described in 
(Chiang 2005).  Research have also been made into 
alternatives to the current log-linear scoring model 
such as discriminative models with millions of fea-
tures (Liang et al 2006), or kernel based models 
(Wang et al 2007). 
From a software engineering point of view, 
these improvements would require fundamental 
changes to the structure if they were to be imple-
mented into Moses. 
We are also interested in seeing the Moses de-
coder employed in search tasks outside of machine 
translation; Moses has been used for OCR correc-
tion, recasing, and transliteration. 
Other improvements such as smaller, faster, 
more efficient phrase tables are also welcomed. 
Lastly, we would like to see the training and 
tuning scripts re-engineered to the same modular 
                                                 
5
 moses-support@mit.edu 
design as the decoder. The future direction of the 
Moses decoder requires even more complex mod-
els which are already stretching the current script 
implementation to the limit of adaptability and re-
liability. 
6 Conclusion 
We have applied the sound software engineering 
principles and design to the implementation of the 
Moses decoder which has enabled other research-
ers to use and extend its functionality. We believe 
this has been a major factor for the widespread 
adoption of Moses within the SMT community. 
We hope that the design of the decoder will enable 
it to maintain it leading edge status into the future. 
Acknowledgements 
This work was supported in part under the 
GALE program of the  Defense Advanced Re-
search Projects Agency, Contract No. HR0011-06-
C-0022 and in part under the EuroMatrix project 
funded by the European Commission (6th Frame-
work Programme. 
References 
Bertoldi, N., R. Cattoni, et al (2004). The ITC-irst Sta-
tistical Machine Translation System for IWSLT-2004. 
IWSLT, Kyoto, Japan. 
  
Bilmes, J. A. and K. Kirchhoff (2003). Factored lan-
guage models and Generalized Parallel Backoff. 
HLT/NACCL. 
  
Brown, P. F., J. Cocke, et al (1990). "A statistical ap-
proach to machine translation." 
  
Chiang, D. (2005). A hierarchical phrase-based model 
for statistical machine translation. ACL. 
  
Deng, Y., S. Kumar, et al (2006). "Segmentation and 
alignment of parallel text for statistical machine transla-
tion." Natural Language Engineering. 
  
Eichelberg, M., J. Riesmeier, et al (2004). "Ten years of 
medical imaging standardization and prototypical im-
plementation: the DICOM standard and the OFFIS DI-
COM toolkit (DCMTK)." Medical Imaging 2004: 
PACS and Imaging Informatics 5371: 57-68 (2004). 
  
Fabri, A., G.-J. Giezeman, et al (2000). "On the Design 
of CGAL, a Computational Geometry Algorithms Li-
64
 brary." Software?Practice & Experience 30(11,  Spe-
cial issue on discrete algorithm engineering). 
  
Koehn, P. (2004). Pharaoh: a Beam Search Decoder for 
Phrase-Based Statistical Machine Translation Models. 
AMTA. 
  
Koehn, P., M. Federico, et al (2006). Open Source 
Toolkit for Statistical Machine Translation. Report of 
the 2006 Summer Workshop at Johns Hopkins Univer-
sity. 
  
Koehn, P. and H. Hoang (2007). Factored Translation 
Models. EMNLP. 
  
Kumar, S. and W. Byrne (2003). A weighted finite state 
transducer implementation of the alignment template 
model for statistical machine translation. ACL, Edmon-
ton, Canada. 
  
Liang, P., A. Bouchard-C?t?, et al (2006). An End-to-
End Discriminative Approach to Machine Translation. 
COLING/ACL. 
  
Och, F. J. (2003). Minimum Error Rate Training for 
Statistical Machine Translation. ACL. 
  
Och, F. J. and H. Ney (2003). "A Systematic Compari-
son of Various Statistical Alignment Models." Compu-
tational Linguistics 29(1): 19-51. 
  
Och, F. J. and H. Ney (2004). "The alignment template 
approach to statistical machine translation." Computa-
tional Linguistics. 
  
Olteanu, M., C. Davis, et al (2006). Phramer - An Open 
Source Statistical Phrase-Based Translator. ACL Work-
shop on Statistical Machine Translation. 
  
Patry, A., F. Gotti, et al (2006). Mood at work: Ramses 
versus Pharaoh. ACL, New York City, USA. 
  
Sadat, F., H. Johnson, et al (2005). PORTAGE: A 
Phrase-based Machine Translation System. ACL Work-
shop on Building and Using Parallel Texts: Data-Driven 
Machine Translation and Beyond, Ann Arbor, Michigan, 
USA. 
  
Shen, W., B. Delaney, et al (2005). The MITLL/AFRL 
MT System. IWSLT, Pittsburgh, PA, USA. 
  
Shen, Y., C.-k. Lo, et al (2007). HKUST Statistical 
Machine Translation Experiments for IWSLT 2007. 
IWSLT, Trento. 
  
Stolcke, A. (2002). SRILM An Extensible Language 
Modeling Toolkit. Intl. Conf. on Spoken Language 
Processing. 
  
Talbot, D. and M. Osborne (2007). Smoothed Bloom 
filter language models: Tera-Scale LMs on the Cheap. 
EMNLP, Prague, Czech Republic. 
  
Wang, Z., J. Shawe-Taylor, et al (2007). Kernel Re-
gression Based Machine Translation. NAACL HLT. 
  
Zens, R. and H. Ney (2007). Efficient phrase-table rep-
resentation for machine translation with applications to 
online MT and speech recognition. HLT/NAACL. 
  
 
65
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 224?232,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
A Systematic Analysis of Translation Model Search Spaces
Michael Auli, Adam Lopez, Hieu Hoang and Philipp Koehn
University of Edinburgh
10 Crichton Street
Edinburgh, EH8 9AB
United Kingdom
m.auli@sms.ed.ac.uk, alopez@inf.ed.ac.uk, h.hoang@sms.ed.ac.uk, pkoehn@inf.ed.ac.uk
Abstract
Translation systems are complex, and
most metrics do little to pinpoint causes of
error or isolate system differences. We use
a simple technique to discover induction
errors, which occur when good transla-
tions are absent from model search spaces.
Our results show that a common prun-
ing heuristic drastically increases induc-
tion error, and also strongly suggest that
the search spaces of phrase-based and hi-
erarchical phrase-based models are highly
overlapping despite the well known struc-
tural differences.
1 Introduction
Most empirical work in translation analyzes mod-
els and algorithms using BLEU (Papineni et al,
2002) and related metrics. Though such met-
rics are useful as sanity checks in iterative sys-
tem development, they are less useful as analyti-
cal tools. The performance of a translation system
depends on the complex interaction of several dif-
ferent components. Since metrics assess only out-
put, they fail to inform us about the consequences
of these interactions, and thus provide no insight
into the errors made by a system, or into the de-
sign tradeoffs of competing systems.
In this work, we show that it is possible to ob-
tain such insights by analyzing translation sys-
tem components in isolation. We focus on model
search spaces (?2), posing a very simple question:
Given a model and a sentence pair, does the search
space contain the sentence pair? Applying this
method to the analysis and comparison of French-
English translation using both phrase-based and
hierarchical phrase-based systems yields surpris-
ing results, which we analyze quantitatively and
qualitatively.
? First, we analyze the induction error of a
model, a measure on the completeness of the
search space. We find that low weight phrase
translations typically discarded by heuristic
pruning nearly triples the number of refer-
ence sentences that can be exactly recon-
structed by either model (?3).
? Second, we find that the high-probability re-
gions in the search spaces of phrase-based
and hierarchical systems are nearly identical
(?4). This means that reported differences be-
tween the models are due to their rankings of
competing hypotheses, rather than structural
differences of the derivations they produce.
2 Models, Search Spaces, and Errors
A translation model consists of two distinct ele-
ments: an unweighted ruleset, and a parameteri-
zation (Lopez, 2008a; 2009). A ruleset licenses
the steps by which a source string f1...fI may be
rewritten as a target string e1...eJ . A parameter-
ization defines a weight function over every se-
quence of rule applications.
In a phrase-based model, the ruleset is simply
the unweighted phrase table, where each phrase
pair fi...fi?/ej ...ej? states that phrase fi...fi? in
the source can be rewritten as ej ...ej? in the tar-
get. The model operates by iteratively apply-
ing rewrites to the source sentence until each
source word has been consumed by exactly one
rule. There are two additional heuristic rules:
The distortion limit dl constrains distances over
which phrases can be reordered, and the transla-
tion option limit tol constrains the number of tar-
get phrases that may be considered for any given
source phrase. Together, these rules completely
determine the finite set of all possible target sen-
tences for a given source sentence. We call this set
of target sentences the model search space.
The parameterization of the model includes all
information needed to score any particular se-
224
quence of rule applications. In our phrase-based
model, it typically includes phrase translation
probabilities, lexical translation probabilities, lan-
guage model probabilities, word counts, and co-
efficients on the linear combination of these. The
combination of large rulesets and complex param-
eterizations typically makes search intractable, re-
quiring the use of approximate search. It is im-
portant to note that, regardless of the parameteri-
zation or search used, the set of all possible output
sentences is still a function of only the ruleset.
Germann et al (2004) identify two types of
translation system error: model error and search
error.1 Model error occurs when the optimal
path through the search space leads to an incorrect
translation. Search error occurs when the approxi-
mate search technique causes the decoder to select
a translation other than the optimum.
Given the decomposition outlined above, it
seems clear that model error depends on param-
eterization, while search error depends on approx-
imate search. However, there is no error type that
clearly depends on the ruleset (Table 1). We there-
fore identify a new type of error on the ruleset: in-
duction error. Induction error occurs when the
search space does not contain the correct target
sentence at all, and is thus a more fundamental
defect than model error. This is difficult to mea-
sure, since there could be many correct transla-
tions and there is no way to see whether they are
all absent from the search space.2 However, if we
assume that a given reference sentence is ground
truth, then as a proxy we can simply ask whether
or not the model search space contains the refer-
ence. This assumption is of course too strong, but
over a sufficiently large test set, it should correlate
with metrics which depend on the reference, since
under most metrics, exactly reproducing the ref-
erence results in a perfect score. More loosely, it
should correlate with translation accuracy?even
if there are many good translations, a model which
is systematically unable to produce any reference
sentences from a sufficiently large test sample is
almost certainly deficient in some way.
3 Does Ruleset Pruning Matter?
The heuristic translation option limit tol controls
the number of translation rules considered per
1They also identify variants within these types.
2It can also be gamed by using a model that can generate
any English word from any French word. However, this is
not a problem for the real models we investigate here.
ruleset induction error
parameterization model error
search search error
Table 1: Translation system components and their
associated error types.
100 101 102 1030
0.2
0.4
0.6
0.8
Translation Options
Phra
se P
roba
bility
 p(e|f)
Figure 1: Distribution p(f |e) of the English trans-
lation options for the French word proble`me.
source span. It plays a major role in keeping the
search space manageable. Ignoring reordering, the
complexity of the search in a phrase-based model
is O(ntol), where n is the number of French spans.
Therefore tol has a major effect on efficiency.
Tight pruning with tol is often assumed without
question to be a worthwhile tradeoff. However,
we wish to examine this assumption more closely.
Consider the French word proble`me. It has 288
different translation options in the phrase table
of our French-English phrase-based system. The
phrase translation probability p(e|f) over these
options is a familiar Zipf distribution (Figure 1).
The most likely candidate translation for the word
is problem with a probability of 0.71, followed by
issue with a much smaller probability of 0.12. Fur-
ther down, we find challenge at rank 25, obsta-
cle at 44 and dilemma at rank 105. Depending on
the context, these might be perfectly good transla-
tions. However, with a typical tol of 20, most of
these options are not considered during decoding.
Table 2 shows that 93.8% of rules are available
during decoding with the standard tol setting and
only about 0.1% of French spans of the entire rule-
set have more than 20 translation options. It seems
as if already most of the information is available
when using the default limit. However, a tol of
20 can clearly exclude good translations as illus-
trated by our example. Therefore we hypothesize
the following: Increasing the translation option
limit gives the decoder a larger vocabulary which
in turn will decrease the induction error. We sup-
225
tol Ruleset Size French Spans
20 93.8 99.9
50 96.8 100.0
100 98.3 100.0
200 99.2 100.0
400 99.7 100.0
800 99.9 100.0
All 100.0 100.0
Table 2: Ruleset size expressed as percentage of
available rules when varying the limit of transla-
tion options tol per English span and percentage
of French spans with up to tol translations.
port this hypothesis experimentally in ?5.4.
4 How Similar are Model Search Spaces?
Most work on hierarchical phrase-based transla-
tion focuses quite intently on its structural differ-
ences from phrase-based translation.
? A hierarchical model can translate discon-
tiguous groups of words as a unit. A phrase-
based model cannot. Lopez (2008b) gives in-
direct experimental evidence that this differ-
ence affects performance.
? A standard phrase-based model can reorder
phrases arbitrarily within the distortion limit,
while the hierarchical model requires some
lexical evidence for movement, resorting to
monotone translation otherwise.
? While both models can indirectly model
word deletion in the context of phrases, the
hierarchical model can delete words using
non-local context due to its use of discontigu-
ous phrases.
The underlying assumption in most discussions
of these models is that these differences in their
generative stories are responsible for differences
in performance. We believe that this assumption
should be investigated empirically.
In an interesting analysis of phrase-based and
hierarchical translation, Zollmann et al (2008)
forced a phrase-based system to produce the trans-
lations generated by a hierarchical system. Unfor-
tunately, their analysis is incomplete; they do not
perform the analysis in both directions. In ?5.5 we
extend their work by requiring each system to gen-
erate the 1-best output of the other. This allows us
to see how their search spaces differ.
5 Experiments
We analyse rulesets in isolation, removing the in-
fluence of the parametrization and heuristics as
much as possible for each system as follows: First,
we disabled beam search to avoid pruning based
on parametrization weights. Second, we require
our decoders to generate the reference via disal-
lowing reference-incompatible hypothesis or chart
entries. This leaves only some search restrictions
such as the distortion limit for the phrase-based
system for which we controlled, or the maximum
number of source words involved in a rule appli-
cation for the hierarchical system.
5.1 Experimental Systems
Our phrase-based system is Moses (Koehn et al,
2007). We set its stack size to 105, disabled the
beam threshold, and varied the translation option
limit tol. Forced translation was implemented by
Schwartz (2008) who ensures that hypothesis are
a prefix of the reference to be generated.
Our hierarchical system is Hiero (Chiang,
2007), modified to construct rules from a small
sample of occurrences of each source phrase in
training as described by Lopez (2008b). The
search parameters restricting the number of rules
or chart entries as well as the minimum threshold
were set to very high values (1050) to prevent prun-
ing. Forced translation was implemented by dis-
carding rules and chart entries which do not match
the reference.
5.2 Experimental Data
We conducted experiments in French-English
translation, attempting to make the experimental
conditions for both systems as equal as possible.
Each system was trained on French-English Eu-
roparl (Koehn, 2005), version 3 (40M words). The
corpus was aligned with GIZA++ (Och and Ney,
2003) and symmetrized with the grow-diag-final-
and heuristic (Koehn et al, 2003). A trigram
language model with modified Kneser-Ney dis-
counting and interpolation was used as produced
by the SRILM toolkit (Stolcke, 2002). Systems
were optimized on the WMT08 French-English
development data (2000 sentences) using mini-
mum error rate training (Och, 2003) and tested
on the WMT08 test data (2000 sentences). Rules
based on unaligned words at the edges of foreign
and source spans were not allowed unless other-
wise stated, this is denoted as the tightness con-
226
20 50 100 200 400 800 All10
15
20
25
30
35
Translation Option Limit
Rea
chab
ility 
(%)
 
 dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16
Figure 2: Coverage for phrase-based reference
aligned translation on test data when varying the
translation option and the distortion limits (dl).
straint. Ayan and Dorr (2006) showed that under
certain conditions, this constraint could have sig-
nificant impact on system performance. The max-
imum phrase lengths for both the hierarchical and
phrase-based system were set to 7. The distortion
limit (dl) for the phrase-based system was set to
6 unless otherwise mentioned. All other settings
were left at their default values as described by
Chiang (2007) and Koehn et al (2007).
5.3 Metric: Reference Reachability
We measure system performance in terms of ref-
erence reachability, which is the inverse of in-
duction error: A system is required to be able to
exactly reproduce the reference, otherwise we re-
gard the result as an error.
5.4 Analysis of Ruleset Pruning
In ?3 we outlined the hypothesis that increas-
ing the number of English translation options per
French span can increase performance. Here we
present results for both phrase-based and hierar-
chical systems to support this claim.
5.4.1 Quantitative Results
Figure 2 shows the experimental results when
forcing our phrase-based system to generate un-
seen test data. We observe more than 30% in-
crease in reachability from tol = 20 to tol = 50
for all dl ? 6 which supports our hypothesis that
increasing tol by a small multiple can have a sig-
nificant impact on performance. With no limit on
tol, reachability nearly triples.
French Spans Number of Translations
des 3006
les 2464
la 1582
de 1557
en 1428
de la 1332
fait 1308
une 1303
a` 1291
le 1273
d? 1271
faire 1263
l? 1111
c? est 1109
a` la 1053
, 1035
Table 3: French spans with more than 1000 trans-
lation options.
Notably, the increase stems from the small frac-
tion of French spans (0.1%) which have more than
20 translation options (Table 2). There are only
16 French spans (Table 3) which have more than
1000 translation options, however, utilising these
can still achieve an increase in reachability of up
to 5%. The list shown in Table 3 includes common
articles, interpuncutation, conjunctions, preposi-
tions but also verbs which have unreliable align-
ment points and therefore a very long tail of low
probability translation options. Yet, the largest in-
crease does not stem from using such unreliable
translation options, but rather when increasing tol
by a relatively small amount.
The increases we see in reachability are pro-
portional to the size of the ruleset: The high-
est increases in ruleset size can be seen between
tol = 20 and tol = 200 (Table 2), similarly, reach-
ability performance has then the largest increase.
For higher tol settings both the increases of ruleset
size and reachability are smaller.
Figure 3 plots the average number of words per
sentence for the reachable sentences. The average
sentence length increases by up to six words when
using all translation options. The black line repre-
sents the average number of words per sentence of
the reference set. This shows that longer and more
complex sentences can be generated when using
more translation options.
Similarly, for our hierarchical system (see Fig-
227
20 50 100 200 400 800 All14
16
18
20
22
24
26
28
30
32
Translation Option Limit
Ave
rage
 Num
ber o
f Wo
rds p
er S
ente
nce
 
 dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16Reference
Figure 3: Average number of words per sen-
tence for the reachable test data translations of the
phrase-based system (as shown in Figure 2).
25 50 100 200 400 800 1600 3200 6400 12800 Inf5
10
15
20
25
30
35
40
Sample Limit (SL)
Rea
chab
ility 
(%)
 
 
Figure 4: Coverage for hierarchical reference
aligned translation on test data when varying the
number of matching French samples (sl) drawn
from the training data. The baseline setting is
sl = 300.
ure 4) we find that reachability can be more than
doubled when drawing a richer ruleset sample than
in the baseline setting. Those results are not di-
rectly comparable to the phrase-based system due
to the slightly different nature of the parameters
which were varied: In the phrase-based case we
have tol different English spans per French span.
In the hierarchical system it is very likely to have
duplicate French spans in the sample drawn from
training data. Yet, the trend is the same and thus
supports our claim.
5.4.2 Qualitative Results
We were interested how the performance increase
could be achieved and therefore looked into which
kind of translation options were involved when a
translation was generable with a higher tol setting.
One possibility is that the long tail of translation
options includes all kinds of English spans that
match some part of the reference but are simply
an artifact of unreliable alignment points.
We looked at the first twenty translations pro-
duced by our phrase-based system under dl = 10
which could not be generated with tol = 20 but
with tol = 50. The aim was to find out which
translation options made it possible to reach the
reference under tol = 50.
We found that nearly half (9) involved transla-
tion options which used a common or less com-
mon translation of the foreign span. The first four
translations in Table 4 are examples for that. When
allowing unaligned words at the rule edges it turns
out that even 13 out of 20 translations are based on
sound translation options.
The remaining sentences involved translation
options which were an artifact of unreliable align-
ment points. An example rule is la / their, which
erroneously translates a common determiner into
an equally common adjective. The last translation
in Figure 4 involves such a translation option.
This analysis demonstrates that the performance
increase between tol = 20 to tol = 50 is to a
considerable extent based on translation options
which are meaningful.
5.5 Analysis of Mutual Reachability
The aim of this analysis was to find out by how
much the high-probability search spaces of the
phrase-based and hierarchical models differ. The
necessary data was obtained via forcing each sys-
tem to produce the 1-best translation of the other
system denoted as the unconstrained translation.
This unconstrained translation used the standard
setting for the number of translation options.
We controlled for the way unaligned words
were handled during rule extraction: The phrase-
based system allowed unaligned words at the
edges of phrases while the hierarchical system did
not. We varied this condition for the phrase-based
system. The distortion limit of the phrase-based
system was set to 10. This is equal to the maxi-
mum span a rule can be applied within the hierar-
chical system.
We carried out the same experiment for
German-English and English-German translation
which serve as examples for translating into a mor-
228
S: je voterai en faveur du projet de re`glement .
R: i will vote to approve the draft regulation .
O: i shall be voting in favour of the draft regulation .
S: ... il npeut y avoir de de?lai transitoire en matie`re de respect des re`gles de?mocratiques .
R: ... there can be no transitional period for complying with democratic rules .
O: ... there can be no transitional period in the field of democratic rules .
S: je souhaite aux ne?gociateurs la poursuite du succe`s de leur travail dans ce domaine important .
R: i wish the negotiators continued success with their work in this important area .
O: i wish the negotiators the continuation of the success of their work on this important area .
S: mais commencons par les points positifs .
R: but let us begin with the good news .
O: but let us begin with the positive points .
S: ... partage la plupart des conclusions que tire le rapporteur .
R: ... share the majority of conclusions that he draws .
O: ... share most of the conclusions that is the rapporteur .
Table 4: Example translations which could be generated with tol = 50 but not with tol = 20. For each
translation the source (S), reference (R) and the unconstrained output (O) are shown. Bold phrases mark
translation options which were not available under tol = 20.
phologically simpler and more complex language
respectively. The test and training sets for these
languages are similarly sized and are from the
WMT08 shared task.
5.5.1 Quantitative Results
Table 5 shows the mutual reachability perfor-
mance for our phrase-based and hierarchical sys-
tem. The hierarchical system can generate almost
all of the 1-best phrase-based translations, partic-
ularly when unaligned words at rule edges are dis-
allowed which is the most equal condition we ex-
perimented with. The phrase-based reachability
for English-German using tight rulesets is remark-
ably low. We found that this is because the hi-
erarchical model allows unaligned words around
gaps under the tight constraint. This makes it very
hard for the phrase-based system to reach the hi-
erarchical translation. However, the phrase-based
system can overcome this problem when the tight-
ness constraint is loosened (last row in Table 5).
Table 6 shows the translation performance mea-
sured in BLEU for both systems for normal un-
constrained translation. It can be seen that the dif-
ference is rather marginal which is in line with our
reachability results.
We were interested why certain translations of
one system were not reachable by the other sys-
tem. The following two subsections describe
our analysis of these translations for the French-
English language pair.
Translation Direction fr-en de-en en-de
Ht ? Pt 99.40 97.65 98.50
Ht ? Pnt 95.95 93.95 94.30
Pt ? Ht 93.75 92.30 82.95
Pnt ? Ht 97.55 97.55 96.30
Table 5: Mutual reachability performance for
French-English (fr-en), German-English (de-en)
and Enlgish-German (en-de). P? H denotes how
many hierarchical (H) high scoring outputs can be
reached by the phrase-based (P) system. The sub-
scripts nt (non-tight) and t (tight) denote the use
of rules with unaligned words or not.
5.5.2 Qualitative Analysis of Unreachable
Hierarchical Translations
We analysed the first twenty translations within
the set of unreachable hierarchical translations
when disallowing unaligned words at rule edges to
find out why the phrase-based system fails to reach
them. Two aspects were considered in this anal-
ysis: First, the successful hierarchical derivation
and second, the relevant part of the phrase-based
ruleset which was involved in the failed forced
translation i.e. how much of the input and the ref-
erence could be covered by the raw phrase-pairs
available to the phrase-based system.
Within the examined subset, the majority of
sentences (14) involved hierarchical rules which
could not be replicated by the phrase-based sys-
229
System fr-en de-en en-de
Phrase-based 31.96 26.94 19.96
Hierarchical 31.62 27.18 20.20
Difference absolute 0.34 0.24 0.24
Difference (%) 1.06 0.90 1.20
Table 6: Performance for phrase-based and hier-
archical systems in BLEU for French-English (fr-
en), German-English (de-en) and English-German
(en-de).
tem. We described this as the first structural dif-
ference in ?4. Almost all of these translations
(12 out of 14) could not be generated because
of the third structural difference which involved
rule that omits the translation of a word within
the French span. An example is the rule X ?
estX 1 ordinaireX 2 /isX 1 X 2 which omits a trans-
lation for the French word ordinaire in the English
span. For this particular subset the capability of
the hierarchical system to capture long-distance
reorderings did not make the difference, but rather
the ability to drop words within a translation rule.
The phrase-based system cannot learn many
rules which omit the translation of words because
we disallowed unaligned words at phrase edges.
The hierarchical system has the same restriction,
but the constraint does not prohibit rules which
have unaligned words within the rule. This allows
the hierarchical system to learn rules such as the
one presented above. The phrase-based system
can learn similar knowledge, although less gen-
eral, if it is allowed to have unaligned words at
the phrase edges. In fact, without this constraint
13 out of the 20 analysed rules can be generated
by the phrase-based system.
Figure 5 shows a seemingly simple hierarchi-
cal translation which fails to be constructed by the
phrase-based system: The second rule application
involves both the reordering of the translation of
postaux and the omittance of a translation for con-
currence. This translation could be easily captured
by a phrase-pair, however, it requires that the train-
ing data contains exactly such an example which
was not the case. The closest rule the phrase-based
rulestore contains is des services postaux / postal
services which fails since it does not cover all of
the input. This is an example for when the gen-
eralisation of the hierarchical model is superior to
the phrase-based approach.
5.5.3 Qualitative Analysis of Unreachable
Phrase-based Translations
The size of the set of unreachable phrase-based
translations is only 0.6% or 12 sentences. This
means that almost all of the 1-best outputs of the
phrase-based translations can be reached by the hi-
erarchical system. Similarly to above, we analysed
which words of the input as well as which words
of the phrase-based translation can be covered by
the available hierarchical translation rules.
We found that all of the translations were not
generable because of the second structural differ-
ence we identified in ?4. The hierarchical rule-
set did not contain a rule with the necessary lex-
ical evidence to perform the same reordering as
the phrase-based model. Figure 6 shows a phrase-
based translation which could not be reached by
the hierarchical system because a rule of the form
X ? e?lectoralesX 1 /X 1 electoral would be re-
quired to move the translation of e?lectorales (elec-
toral) just before the translation of re?unions (meet-
ings). Inspection of the hierarchical ruleset reveals
that such a rule is not available and so the transla-
tion cannot be generated.
The small size of the set of unreachable phrase-
based translations shows that the lexically in-
formed reordering mechanism of the hierarchical
model is not a large obstacle in generating most of
the phrase-based outputs.
In summary, each system can reproduce nearly
all of the highest-scoring outputs of the other sys-
tem. This shows that the 1-best regions of both
systems are nearly identical despite the differ-
ences discussed in ?4. This means that differences
in observed system performance are probably at-
tributable to the degree of model error and search
error in each system.
6 Related Work and Open Questions
Zhang et al (2008) and Wellington et al (2006)
answer the question: what is the minimal gram-
mar that can be induced to completely describe a
training set? We look at the related question of
what a heuristically induced ruleset can translate
in an unseen test set, considering both phrase- and
grammar-based models. We also extend the work
of Zollmann et al (2008) on Chinese-English, per-
forming the analysis in both directions and provid-
ing a detailed qualitative explanation.
Our focus has been on the induction error of
models, a previously unstudied cause of transla-
230
Source: concurrence des services postaux
Reference: competition between postal services
Hierarchical: postal services
Deviation:
( [0-4: @S -> @X?1 | @X?1 ]
( [0-4: @X -> concurrence @X?1 postaux | postal @X?1 ] postal
( [1-3: @X -> des services | services ] services
)
)
)
Figure 5: Derivation of a hierarchical translation which cannot be generated by the phrase-based system,
in the format of Zollmann et al (2008). The parse tree contains the outputs (shaded) at its leaves in infix
order and each non-leaf node denotes a rule, in the form: [ Source-span: LHS?RHS ].
Source: ceux qui me disaient cela faisaient par exemple re`fe`rence a` certaines des
re?unions e?lectorales auxquelles ils avaient assiste? .
Phrase-based: those who said to me that were for example refer to some of which
they had been electoral meetings .
Reference: they referred to some of the election meetings , for example , that
they had gone to .
Figure 6: Phrase-based translation which cannot be reached by the hierarchical system because no rule to
perform the necessary reordering is available. Marked sections are source and reference spans involved
in the largest possible partial hierarchical derivation.
tion errors. Although the results described here
are striking, our exact match criterion for reach-
ability is surely too strict?for example, we re-
port an error if even a single comma is missing.
One solution is to use a more tolerant criterion
such as WER and measure the amount of devia-
tion from the reference. We could also maximize
BLEU with respect to the reference as in Dreyer et
al. (2007), but it is less interpretable.
7 Conclusion and Future Work
Sparse distributions are common in natural lan-
guage processing, and machine translation is no
exception. We showed that utilizing more of the
entire distribution can dramatically improve the
coverage of translation models, and possibly their
accuracy. Accounting for sparsity explicitly has
achieved significant improvements in other areas
such as in part of speech tagging (Goldwater and
Griffiths, 2007). Considering the entire tail is chal-
lenging, since the search space grows exponen-
tially with the number of translation options. A
first step might be to use features that facilitate
more variety in the top 20 translation options. A
more elaborate aim is to look into alternatives to
maximum likelihood hood estimation such as in
Blunsom and Osborne (2008).
Additionally, our expressiveness analysis shows
clearly that the 1-best region of hierarchical and
phrase-based models is nearly identical. Dis-
counting cases in which systems handle unaligned
words differently, we observe an overlap of be-
tween 96% and 99% across three language pairs.
This implies that the main difference between the
models is in their parameterization, rather than in
the structural differences in the types of transla-
tions they can produce. Our results also suggest
that the search spaces of both models are highly
overlapping: The results for the 1-best region al-
low the conjecture that also other parts of the
search space are behaving similarly since it ap-
pears rather unlikely that spaces are nearly disjoint
with only the 1-best region being nearly identical.
In future work we aim to use n-best lists or lattices
to more precisely measure search space overlap.
We also aim to analyse the effects of the model
and search errors for these systems.
Acknowledgements
This research was supported by the Euromatrix
Project funded by the European Commission (6th
Framework Programme). The experiments were
conducted using the resources provided by the
Edinburgh Compute and Data Facility (ECDF).
Many thanks to the three anonymous reviewers for
very helpful comments on earlier drafts.
231
References
N. F. Ayan and B. Dorr. 2006. Going beyond AER:
An extensive analysis of word alignments and their
impact on MT. In Proc. of ACL-COLING, pages 9?
16, Jul.
P. Blunsom and M. Osborne. 2008. Probabilistic infer-
ence for machine translation. In Proc. of EMNLP.
D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
M. Dreyer, K. B. Hall, and S. P. Khudanpur. 2007.
Comparing reordering constraints for SMT using ef-
ficient BLEU oracle computation. In Proc. of Work-
shop on Syntax and Structure in Statistical Transla-
tion, pages 103?110, Apr.
U. Germann, M. Jahr, K. Knight, D. Marcu, and K. Ya-
mada. 2004. Fast and optimal decoding for machine
translation. Artificial Intelligence, 154(1?2):127?
143, Apr.
S. Goldwater and T. Griffiths. 2007. A fully Bayesian
approach to unsupervised part-of-speech tagging. In
Proc. of ACL, pages 744?751, Prague, Czech Re-
public, June.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of HLT-NAACL,
pages 48?54, Morristown, NJ, USA.
P. Koehn, H. Hoang, A. B. Mayne, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proc. of ACL
Demonstration Session, pages 177?180, Jun.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT Summit.
A. Lopez. 2008a. Statistical machine translation.
ACM Computing Surveys, 40(3).
A. Lopez. 2008b. Tera-scale translation models via
pattern matching. In Proc. of COLING, pages 505?
512, Aug.
A. Lopez. 2009. Translation as weighted deduction.
In Proc. of EACL.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19?51.
F. J. Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. of ACL, pages
160?167, Morristown, NJ, USA.
K. Papineni, S. Roukos, T. Ward, and W. jing Zhu.
2002. BLEU: A method for automatic evaluation
of machine translation. In Proc. of ACL, pages 311?
318.
L. Schwartz. 2008. Multi-source translation methods.
In Proc. of AMTA, October.
A. Stolcke. 2002. SRILM ? an extensible language
modeling toolkit. In Proc. Int. Conf. Spoken Lan-
guage Processing (ICSLP 2002).
B. Wellington, S. Waxmonsky, and I. D. Melamed.
2006. Empirical lower bounds on the complexity
of translational equivalence. In Proc. of ACL, pages
977?984, Morristown, NJ, USA.
H. Zhang, D. Gildea, and D. Chiang. 2008. Extracting
synchronous grammar rules from word-level align-
ments in linear time. In Proc. of COLING, pages
1081?1088, Manchester, UK.
A. Zollmann, A. Venugopal, F. Och, and J. Ponte.
2008. A systematic comparison of phrase-based, hi-
erarchical and syntax-augmented statistical MT. In
Proc. of COLING.
232
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 148?153,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Integrating an Unsupervised Transliteration Model into
Statistical Machine Translation
Nadir Durrani
University of Edinburgh
dnadir@inf.ed.ac.uk
Hieu Hoang Philipp Koehn
University of Edinburgh
hieu.hoang,pkoehn@inf.ed.ac.uk
Hassan Sajjad
Qatar Computing Research Institute
hsajjad@@qf.org.qa
Abstract
We investigate three methods for integrat-
ing an unsupervised transliteration model
into an end-to-end SMT system. We in-
duce a transliteration model from parallel
data and use it to translate OOV words.
Our approach is fully unsupervised and
language independent. In the methods
to integrate transliterations, we observed
improvements from 0.23-0.75 (? 0.41)
BLEU points across 7 language pairs. We
also show that our mined transliteration
corpora provide better rule coverage and
translation quality compared to the gold
standard transliteration corpora.
1 Introduction
All machine translation (MT) systems suffer from
the existence of out-of-vocabulary (OOV) words,
irrespective of the amount of data available for
training. OOV words are mostly named entities,
technical terms or foreign words that can be trans-
lated to the target language using transliteration.
Much work (Al-Onaizan and Knight, 2002;
Zhao et al., 2007; Kashani et al., 2007; Habash,
2009) has been done on transliterating named enti-
ties and OOVs, and transliteration has been shown
to improve MT quality. Transliteration has also
shown to be useful for translating closely related
language pairs (Durrani et al., 2010; Nakov and
Tiedemann, 2012), and for disambiguation (Her-
mjakob et al., 2008; Azab et al., 2013). How-
ever, despite its utility, a transliteration module
does not exist in the commonly used MT toolk-
its, such as Moses (Koehn et al., 2007). One of the
main reasons is that the training data, a corpus of
transliteration pairs, required to build a translitera-
tion system, is not readily available for many lan-
guage pairs. Even if such a training data is avail-
able, mechanisms to integrate transliterated words
into MT pipelines are unavailable in these toolkits.
Generally, a supervised transliteration system is
trained separately outside of an MT pipeline, and
a na??ve approach, to replace OOV words with their
1-best transliterations in the post/pre-processing
step of decoding is commonly used.
In this work i) we use an unsupervised model
based on Expectation Maximization (EM) to in-
duce transliteration corpus from word aligned par-
allel data, which is then used to train a translitera-
tion model, ii) we investigate three different meth-
ods for integrating transliteration during decoding,
that we implemented within the Moses toolkit. To
the best of our knowledge, our work is the fore-
most attempt to integrate unsupervised translitera-
tion model into SMT.
This paper is organized as follows. Section 2
describes the unsupervised transliteration mining
system, which automatically mines transliteration
pairs from the same word-aligned parallel corpus
as used for training the MT system. Section 3 de-
scribes the transliteration model that is trained us-
ing the automatically extracted pairs. Section 4
presents three methods for incorporating translit-
eration into the MT pipeline, namely: i) replac-
ing OOVs with the 1-best transliteration in a post-
decoding step, ii) selecting the best translitera-
tion from the list of n-best transliterations using
transliteration and language model features in a
post-decoding step, iii) providing a transliteration
phrase-table to the decoder on the fly where it
can consider all features to select the best translit-
eration of OOV words. Section 5 presents re-
sults. Our integrations achieved an average im-
provement of 0.41 BLEU points over a competi-
tive baseline across 7 language pairs (Arabic, Ben-
gali, Farsi, Hindi, Russian, Telugu and Urdu-into-
English). An additional experiment showed that
our system provides better rule coverage as op-
posed to another built from gold standard translit-
eration corpus and produces better translations.
148
2 Transliteration Mining
The main bottleneck in building a transliteration
system is the lack of availability of translitera-
tion training pairs. It is, however, fair to assume
that any parallel data would contain a reasonable
number of transliterated word pairs. Transliter-
ation mining can be used to extract such word
pairs from the parallel corpus. Most previous
techniques on transliteration mining generally use
supervised and semi-supervised methods (Sherif
and Kondrak, 2007; Jiampojamarn et al., 2010;
Darwish, 2010; Kahki et al., 2012). This con-
strains the mining solution to language pairs for
which training data (seed data) is available. A few
researchers proposed unsupervised approaches to
mine transliterations (Lee and Choi, 1998; Sajjad
et al., 2011; Lin et al., 2011). We adapted the work
of Sajjad et al. (2012) as summarized below.
Model: The transliteration mining model is a
mixture of two sub-models, namely: a translit-
eration and a non-transliteration sub-model. The
idea is that the transliteration model would as-
sign higher probabilities to transliteration pairs
compared to the probabilities assigned by a non-
transliteration model to the same pairs. Consider a
word pair (e, f), the transliteration model prob-
ability for the word pair is defined as follows:
p
tr
(e, f) =
?
a?Align(e,f)
|a|
?
j=1
p(q
j
)
where Align(e, f) is the set of all possible se-
quences of character alignments, a is one align-
ment sequence and q
j
is a character alignment.
The non-transliteration model deals with the
word pairs that have no character relationship be-
tween them. It is modeled by multiplying source
and target character unigram models:
p
ntr
(e, f) =
|e|
?
i=1
p
E
(e
i
)
|f |
?
i=1
p
F
(f
i
)
The transliteration mining model is defined
as an interpolation of the transliteration sub-model
and the non-transliteration sub-model:
p(e, f) = (1? ?)p
tr
(e, f) + ?p
ntr
(e, f)
? is the prior probability of non-transliteration.
The non-transliteration model does not change
during training. We compute it in a pre-processing
step. The transliteration model learns character
alignment using expectation maximization (EM).
See Sajjad et al. (2012) for more details.
3 Transliteration Model
Now that we have transliteration word pairs, we
can learn a transliteration model. We segment the
training corpus into characters and learn a phrase-
based system over character pairs. The translitera-
tion model assumes that source and target charac-
ters are generated monotonically.
1
Therefore we
do not use any reordering models. We use 4 basic
phrase-translation features (direct, inverse phrase-
translation, and lexical weighting features), lan-
guage model feature (built from the target-side of
mined transliteration corpus), and word and phrase
penalties. The feature weights are tuned
2
on a dev-
set of 1000 transliteration pairs.
4 Integration to Machine Translation
We experimented with three methods for integrat-
ing transliterations, described below:
Method 1: involves replacing OOVs in the out-
put with the 1-best transliteration. The success of
Method 1 is solely contingent on the accuracy of
the transliteration model. Also, it ignores con-
text which may lead to incorrect transliteration.
For example, the Arabic word transliterates
to ?Bill? when followed by ?Clinton? and ?Bell?
if preceded by ?Alexander Graham?.
Method 2: provides n-best transliterations to
a monotonic decoder that uses a monolingual
language model and a transliteration phrase-
translation table to rescore transliterations. We
carry forward the 4 translation model features used
in the transliteration system to build a transliter-
ation phrase-table. We additionally use an LM-
OOV feature which counts the number of words
in a hypothesis that are unknown to the lan-
guage model. Smoothing methods such as Kneser-
Ney assign significant probability mass to unseen
events, which may cause the decoder to make in-
correct transliteration selection. The LM-OOV
feature acts as a prior to penalize such hypotheses.
Method 3: Method 2 can not benefit from all in-
decoding features and phenomenon like reorder-
ing. It transliterates Urdu compound
(Arabian Sea) to ?Sea Arabian?, if is an un-
known word. In method 3, we feed the translitera-
tion phrase-table directly into the first-pass decod-
ing which allows reordering of UNK words. We
1
Mining algorithm also makes this assumption.
2
Tuning data is subtracted from the training corpus while
tuning to avoid over-fitting. After the weights are tuned, we
add it back, retrain GIZA, and estimate new models.
149
use the decoding-graph-backoff option in Moses,
that allows multiple translation phrase tables and
back-off models. As in method 2, we also use the
LM-OOV feature in method 3.
3
5 Evaluation
Data: We experimented with 7 language pairs,
namely: Arabic, Bengali, Farsi, Hindi, Russian,
Telugu and Urdu-into-English. For Arabic
4
and
Farsi, we used the TED talks data (Cettolo et al.,
2012) made available for IWSLT-13, and we used
the dev2010 set for tuning and the test2011 and
test2012 sets for evaluation. For Indian languages
we used the Indic multi-parallel corpus (Post et
al., 2012), and we used the dev and test sets pro-
vided with the parallel corpus. For Russian, we
used WMT-13 data (Bojar et al., 2013), and we
used half of the news-test2012 for tuning and other
half for testing. We also evaluated on the news-
test2013 set. For all, we trained the language
model using the monolingual WMT-13 data. See
Table 1 for data statistics.
Lang Train
tm
Train
tr
Dev Test
1
Test
2
AR 152K 6795 887 1434 1704
BN 24K 1916 775 1000
FA 79K 4039 852 1185 1116
HI 39K 4719 1000 1000
RU 2M 302K 1501 1502 3000
TE 45K 4924 1000 1000
UR 87K 9131 980 883
Table 1: No. of sentences in Training Data and
Mined Transliteration Corpus (Types) (Train
tr
)
Baseline Settings: We trained a Moses system
replicating the settings used in competition-grade
systems (Durrani et al., 2013b; Birch et al., 2013):
a maximum sentence length of 80, GDFA sym-
metrization of GIZA++ alignments (Och and Ney,
2003), an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, a 5-gram OSM (Dur-
rani et al., 2013a), msd-bidirectional-fe lexical-
3
Method 3 is desirable in cases where the decoder can
translate or transliterate a word. For example Hindi word
can be translated to ?Border? and also transliterated
to name ?Seema?. Identifying such candidates that can be
translated or transliterated is a challenge. Machine learning
techniques (Goldwasser and Roth, 2008; Kirschenbaum and
Wintner, 2009) and named entity recognizers (Klementiev
and Roth, 2006; Hermjakob et al., 2008) have been used for
this purpose. Though, we only focus on OOV words, method
3 can be used if such a classifier/NE tagger is available.
4
Arabic and Urdu are segmented using MADA (Habash
and Sadat, 2006) and UWS (Durrani and Hussain, 2010).
ized reordering, sparse lexical and domain fea-
tures (Hasler et al., 2012), a distortion limit of
6, 100-best translation options, MBR decoding
(Kumar and Byrne, 2004), Cube Pruning (Huang
and Chiang, 2007), and the no-reordering-over-
punctuation heuristic. We tuned with the k-best
batch MIRA (Cherry and Foster, 2012).
5
Transliteration Miner: The miner extracts
transliterations from a word-aligned parallel cor-
pus. We only used word pairs with 1-to-1 align-
ments.
6
Before feeding the list into the miner, we
cleaned it by removing digits, symbols, word pairs
where source or target is composed from less than
3 characters, and words containing foreign char-
acters that do not belong to this scripts. We ran
the miner with 10 iterations of EM. The number
of transliteration pairs (types) extracted for each
language pair is shown in Table 1 (Train
tr
).
Transliteration System: Before evaluating our
integrations into the SMT system, we performed
an intrinsic evaluation of the transliteration system
that we built from the mined pairs. We formed
test data for Arabic?English (1799 pairs), Hindi?
English (2394 pairs) and Russian?English (1859
pairs) by concatenating the seed data and gold
standard transliteration pairs both provided for the
Shared Task on Transliteration mining (Kumaran
et al., 2010). Table 2 shows precision and recall of
the mined transliteration system (MTS).
AR HI RU
Precision (1-best Accuracy) 20.0% 25.3% 46.1%
Recall (100-best Accuracy) 80.2% 79.3% 87.5%
Table 2: Precision and Recall of MTS
The precision (1-best accuracy) of the translit-
eration model is quite low. This is because the
transliteration corpus is noisy and contains imper-
fect transliteration pairs. For example, the miner
extracted the pair ( , Australasia), while
the correct transliteration is ?Australia?. We can
improve the precision by tightening the mining
threshold probability. However, our end goal is to
improve end-to-end MT and not the transliteration
system. We observed that recall is more important
than precision for overall MT quality. We provide
an empirical justification for this when discussing
the final experiments.
5
Retuning the transliteration features was not helpful, de-
fault weights are used.
6
M-N/1-N alignments are less likely to be transliterations.
150
MT Experiments: Table 3 gives a comprehen-
sive evaluation of the three methods of integra-
tion discussed in Section 4 along with the num-
ber
7
of OOV words (types) in different tests. We
report BLEU gains (Papineni et al., 2002) obtained
by each method. Method 1 (M
1
), that replaces
OOV words with 1-best transliteration gave an av-
erage improvement of +0.13. This result can be at-
tributed to the low precision of the transliteration
system (Table 2). Method 2 (M
2
), that translit-
erates OOVs in second pass monotonic decoding,
gave an average improvement of +0.39. Slightly
higher gains were obtained using Method 3 (M
3
),
that integrates transliteration phrase-table inside
decoder on the fly. However, the efficacy of M
3
in
comparison to M
2
is not as apparent, as M
2
pro-
duced better results than M
3
in half of the cases.
Lang Test B
0
M
1
M
2
M
3
OOV
AR iwslt
11
26.75 +0.12 +0.36 +0.25 587
iwslt
12
29.03 +0.10 +0.30 +0.27 682
BN jhu
12
16.29 +0.12 +0.42 +0.46 1239
FA iwslt
11
20.85 +0.10 +0.40 +0.31 559
iwslt
12
16.26 +0.04 +0.20 +0.26 400
HI jhu
12
15.64 +0.21 +0.35 +0.47 1629
RU wmt
12
33.95 +0.24 +0.55 +0.49 434
wmt
13
25.98 +0.25 +0.40 +0.23 799
TE jhu
12
11.04 -0.09 +0.40 +0.75 2343
UR jhu
12
23.25 +0.24 +0.54 +0.60 827
Avg 21.9 +0.13 +0.39 +0.41 950
Table 3: End-to-End MT Evaluation ? B
0
=
Baseline, M
1
= Method
1
, M
2
= Method
2
, M
3
=
Method
3
, BLEU gains shown for each method
In an effort to test whether improving translit-
eration precision would improve end-to-end SMT
results, we carried out another experiment. Instead
of building a transliteration system from mined
corpus, we built it using the gold standard corpus
(for Arabic, Hindi and Russian), that we also used
previously to do an intrinsic evaluation. We then
replaced our mined transliteration systems with
the gold standard transliteration systems, in the
best performing SMT systems for these languages.
Table 4 shows a comparison of performances. Al-
though the differences are small, systems using
mined transliteration system (MTS) outperformed
its counterpart that uses gold standard translitera-
tion system (GTS), except in Hindi?English where
7
Note that not all OOVs can be transliterated. This num-
ber is therefore an upper bound what can be transliterated.
both systems were equal.
AR HI RU
iwslt
11
iwslt
12
jhu
12
wmt
12
iwslt
13
MTS 27.11 29.33 16.11 34.50 26.38
GST 26.99 29.20 16.11 34.33 26.22
Table 4: Comparing Gold Standard Transliteration
(GST) and Mined Transliteration Systems
In the error analysis we found that the GST
system suffered from sparsity and did not pro-
vide enough coverage of rules to produce right
transliterations. For example, Arabic drops the
determiner (al), but such additions were not
observed in gold transliteration pairs. Arabic
word (Gigapixel) is therefore translit-
erated to ?algegabksl?. Similarly the GST system
learned no transliteration pairs to account for the
rule ?b ? p? and therefore erroneously translit-
erated (Spurlock) to ?Sbrlok?. Similar
observations were true for the case of Russian?
English. The rules ?a? u? and ?y? ? were not
observed in the gold set, and hence
(hurricane) was transliterated to ?herricane? and
(Talbot) to ?Talboty?. This shows that
better recall obtained from the mined pairs led to
overall improvement.
6 Conclusion
We incorporated unsupervised transliteration min-
ing model into standard MT pipeline to automati-
cally transliterate OOV words without needing ad-
ditional resources. We evaluated three methods
for integrating transliterations on 7 language pairs
and showed improvements ranging from 0.23-0.75
(? 0.41) BLEU points. We also showed that our
mined transliteration corpus provide better recall
and overall translation quality compared to the
gold standard transliteration corpus. The unsu-
pervised transliteration miner and its integration
to SMT has been made available to the research
community via the Moses toolkit.
Acknowledgments
We wish to thank the anonymous reviewers and
Kareem Darwish for their valuable feedback on
an earlier draft of this paper. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n
?
287658. This publication only reflects the au-
thors? views.
151
References
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing Named Entities Using Monolingual and Bilin-
gual Resources. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics.
Mahmoud Azab, Houda Bouamor, Behrang Mohit, and
Kemal Oflazer. 2013. Dudley North visits North
London: Learning When to Transliterate to Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 439?444, Atlanta, Georgia, June. Association
for Computational Linguistics.
Alexandra Birch, Nadir Durrani, and Philipp Koehn.
2013. Edinburgh SLT and MT System Description
for the IWSLT 2013 Evaluation. In Proceedings
of the 10th International Workshop on Spoken Lan-
guage Translation, pages 40?48, Heidelberg, Ger-
many, December.
Ondrej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut,
and Lucia Specia. 2013. Findings of the 2013
Workshop on Statistical Machine Translation. In
Eighth Workshop on Statistical Machine Transla-
tion, WMT-2013, pages 1?44, Sofia, Bulgaria.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT
3
: Web Inventory of Transcribed
and Translated Talks. In Proceedings of the 16
th
Conference of the European Association for Ma-
chine Translation (EAMT), pages 261?268, Trento,
Italy, May.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427?436, Montr?eal, Canada, June. Associa-
tion for Computational Linguistics.
Kareem Darwish. 2010. Transliteration Mining with
Phonetic Conflation and Iterative Training. In Pro-
ceedings of the 2010 Named Entities Workshop, Up-
psala, Sweden.
Nadir Durrani and Sarmad Hussain. 2010. Urdu Word
Segmentation. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 528?536, Los Angeles, California,
June. Association for Computational Linguistics.
Nadir Durrani, Hassan Sajjad, Alexander Fraser, and
Helmut Schmid. 2010. Hindi-to-Urdu Machine
Translation through Transliteration. In Proceedings
of the 48th Annual Conference of the Association for
Computational Linguistics, Uppsala, Sweden.
Nadir Durrani, Alexander Fraser, Helmut Schmid,
Hieu Hoang, and Philipp Koehn. 2013a. Can
Markov Models Over Minimal Translation Units
Help Phrase-Based SMT? In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013b. Edinburgh?s Machine Trans-
lation Systems for European Language Pairs. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
Dan Goldwasser and Dan Roth. 2008. Active Sam-
ple Selection for Named Entity Transliteration. In
Proceedings of ACL-08: HLT, Short Papers, pages
53?56, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Nizar Habash and Fatiha Sadat. 2006. Arabic Pre-
processing Schemes for Statistical Machine Transla-
tion. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Companion Vol-
ume: Short Papers, pages 49?52, New York City,
USA, June. Association for Computational Linguis-
tics.
Nizar Habash. 2009. REMOOV: A Tool for Online
Handling of Out-of-Vocabulary Words in Machine
Translation. In Proceedings of the Second Interna-
tional Conference on Arabic Language Resources
and Tools, Cairo, Egypt, April. The MEDAR Con-
sortium.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised Features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268?275.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187?197, Edinburgh, Scotland, United King-
dom, 7.
Ulf Hermjakob, Kevin Knight, and Hal Daum?e III.
2008. Name Translation in Statistical Machine
Translation - Learning When to Transliterate. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Columbus, Ohio.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144?151, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane
Bergsma, Aditya Bhargava, Qing Dou, Mi-Young
Kim, and Grzegorz Kondrak. 2010. Transliteration
152
Generation and Mining with Limited Training Re-
sources. In Proceedings of the 2010 Named Entities
Workshop, Uppsala, Sweden.
Ali El Kahki, Kareem Darwish, Ahmed Saad El Din,
and Mohamed Abd El-Wahab. 2012. Transliter-
ation Mining Using Large Training and Test Sets.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ?12.
Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George
Foster, and Fred Popowich. 2007. Integration of
an Arabic Transliteration Module into a Statistical
Machine Translation System. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, Prague, Czech Republic.
Amit Kirschenbaum and Shuly Wintner. 2009. Lightly
Supervised Transliteration for Machine Translation.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 433?
441, Athens, Greece, March. Association for Com-
putational Linguistics.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proceedings of the
Human Language Technology Conference of the
NAACL, Main Conference, pages 82?88, New York
City, USA, June. Association for Computational
Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics, Demon-
stration Program, Prague, Czech Republic.
Shankar Kumar and William J. Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In HLT-NAACL, pages 169?176.
A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010.
Whitepaper of news 2010 shared task on transliter-
ation mining. In Proceedings of the 2010 Named
Entities Workshop, pages 29?38, Uppsala, Sweden,
July. Association for Computational Linguistics.
Jae-Sung Lee and Key-Sun Choi. 1998. English
to Korean Statistical Transliteration for Information
Retrieval. Computer Processing of Oriental Lan-
guages, 12(1):17?37.
Wen-Pin Lin, Matthew Snover, and Heng Ji. 2011.
Unsupervised Language-Independent Name Trans-
lation Mining from Wikipedia Infoboxes. In Pro-
ceedings of the First workshop on Unsupervised
Learning in NLP, pages 43?52, Edinburgh, Scot-
land, July. Association for Computational Linguis-
tics.
Preslav Nakov and J?org Tiedemann. 2012. Com-
bining Word-Level and Character-Level Models for
Machine Translation Between Closely-Related Lan-
guages. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 301?305, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics, 29(1).
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, ACL ?02, pages 311?318, Mor-
ristown, NJ, USA.
Matt Post, Chris Callison-Burch, and Miles Osborne.
2012. Constructing Parallel Corpora for Six Indian
Languages via Crowdsourcing. In Proceedings of
the Seventh Workshop on Statistical Machine Trans-
lation, pages 401?409, Montr?eal, Canada, June. As-
sociation for Computational Linguistics.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An Algorithm for Unsupervised Translitera-
tion Mining with an Application to Word Alignment.
In Proceedings of the 49th Annual Conference of
the Association for Computational Linguistics, Port-
land, USA.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A Statistical Model for Unsupervised and
Semi-supervised Transliteration Mining. In Pro-
ceedings of the 50th Annual Conference of the Asso-
ciation for Computational Linguistics, Jeju, Korea.
Tarek Sherif and Grzegorz Kondrak. 2007. Bootstrap-
ping a Stochastic Transducer for Arabic-English
Transliteration Extraction. In Proceedings of the
45th Annual Meeting of the Association for Compu-
tational Linguistics, Prague, Czech Republic.
Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-
gel. 2007. A Log-Linear Block Transliteration
Model based on Bi-Stream HMMs. In Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics, Rochester, New York.
153
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 399?405,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Can Markov Models Over Minimal Translation Units Help Phrase-Based
SMT?
Nadir Durrani
University of Edinburgh
dnadir@inf.ed.ac.uk
Hieu Hoang Philipp Koehn
University of Edinburgh
hieu.hoang,pkoehn@inf.ed.ac.uk
Alexander Fraser Helmut Schmid
Ludwig Maximilian University Munich
fraser,schmid@cis.uni-muenchen.de
Abstract
The phrase-based and N-gram-based
SMT frameworks complement each other.
While the former is better able to memo-
rize, the latter provides a more principled
model that captures dependencies across
phrasal boundaries. Some work has been
done to combine insights from these two
frameworks. A recent successful attempt
showed the advantage of using phrase-
based search on top of an N-gram-based
model. We probe this question in the
reverse direction by investigating whether
integrating N-gram-based translation and
reordering models into a phrase-based
decoder helps overcome the problematic
phrasal independence assumption. A large
scale evaluation over 8 language pairs
shows that performance does significantly
improve.
1 Introduction
Phrase-based models (Koehn et al, 2003; Och
and Ney, 2004) learn local dependencies such as
reorderings, idiomatic collocations, deletions and
insertions by memorization. A fundamental draw-
back is that phrases are translated and reordered
independently of each other and contextual infor-
mation outside of phrasal boundaries is ignored.
The monolingual language model somewhat re-
duces this problem. However i) often the language
model cannot overcome the dispreference of the
translation model for nonlocal dependencies, ii)
source-side contextual dependencies are still ig-
nored and iii) generation of lexical translations and
reordering is separated.
The N-gram-based SMT framework addresses
these problems by learning Markov chains over se-
quences of minimal translation units (MTUs) also
known as tuples (Marin?o et al, 2006) or over op-
erations coupling lexical generation and reorder-
ing (Durrani et al, 2011). Because the mod-
els condition the MTU probabilities on the previ-
ous MTUs, they capture non-local dependencies
and both source and target contextual information
across phrasal boundaries.
In this paper we study the effect of integrating
tuple-based N-gram models (TSM) and operation-
based N-gram models (OSM) into the phrase-
based model in Moses, a state-of-the-art phrase-
based system. Rather than using POS-based
rewrite rules (Crego and Marin?o, 2006) to form
a search graph, we use the ability of the phrase-
based system to memorize larger translation units
to replicate the effect of source linearization as
done in the TSM model.
We also show that using phrase-based search
with MTU N-gram translation models helps to ad-
dress some of the search problems that are non-
trivial to handle when decoding with minimal
translation units. An important limitation of the
OSM N-gram model is that it does not handle un-
aligned or discontinuous target MTUs and requires
post-processing of the alignment to remove these.
Using phrases during search enabled us to make
novel changes to the OSM generative story (also
applicable to the TSM model) to handle unaligned
target words and to use target linearization to deal
with discontinuous target MTUs.
We performed an extensive evaluation, carrying
out translation experiments from French, Spanish,
Czech and Russian to English and in the opposite
direction. Our integration of the OSM model into
Moses and our modification of the OSM model to
deal with unaligned and discontinuous target to-
kens consistently improves BLEU scores over the
399
baseline system, and shows statistically significant
improvements in seven out of eight cases.
2 Previous Work
Several researchers have tried to combine the ideas
of phrase-based and N-gram-based SMT. Costa-
jussa` et al (2007) proposed a method for combin-
ing the two approaches by applying sentence level
reranking. Feng et al (2010) added a linearized
source-side language model in a phrase-based sys-
tem. Crego and Yvon (2010) modified the phrase-
based lexical reordering model of Tillman (2004)
for an N-gram-based system. Niehues et al (2011)
integrated a bilingual language model based on
surface word forms and POS tags into a phrase-
based system. Zhang et al (2013) explored multi-
ple decomposition structures for generating MTUs
in the task of lexical selection, and to rerank the
N-best candidate translations in the output of a
phrase-based. A drawback of the TSM model is
the assumption that source and target information
is generated monotonically. The process of re-
ordering is disconnected from lexical generation
which restricts the search to a small set of precom-
puted reorderings. Durrani et al (2011) addressed
this problem by coupling lexical generation and
reordering information into a single generative
process and enriching the N-gram models to learn
lexical reordering triggers. Durrani et al (2013)
showed that using larger phrasal units during de-
coding is superior to MTU-based decoding in an
N-gram-based system. However, they do not use
phrase-based models in their work, relying only
on the OSM model. This paper combines insights
from these recent pieces of work and show that
phrase-based search combined with N-gram-based
and phrase-based models in decoding is the over-
all best way to go. We integrate the two N-gram-
based models, TSM and OSM, into phrase-based
Moses and show that the translation quality is im-
proved by taking both translation and reordering
context into account. Other approaches that ex-
plored such models in syntax-based systems used
MTUs for sentence level reranking (Khalilov and
Fonollosa, 2009), in dependency translation mod-
els (Quirk and Menezes, 2006) and in target lan-
guage syntax systems (Vaswani et al, 2011).
3 Integration of N-gram Models
We now describe our integration of TSM and
OSM N-gram models into the phrase-based sys-
Figure 1: Example (a) Word Alignments (b) Un-
folded MTU Sequence (c) Operation Sequence (d)
Step-wise Generation
tem. Given a bilingual sentence pair (F,E) and
its alignment (A), we first identify minimal trans-
lation units (MTUs) from it. An MTU is defined
as a translation rule that cannot be broken down
any further. The MTUs extracted from Figure 1(a)
are A ? a,B ? b, C . . .H ? c1 and D ? d.
These units are then generated left-to-right in two
different ways, as we will describe next.
3.1 Tuple Sequence Model (TSM)
The TSM translation model assumes that MTUs
are generated monotonically. To achieve this ef-
fect, we enumerate the MTUs in the target left-
to-right order. This process is also called source
linearization or tuple unfolding. The resulting se-
quence of monotonic MTUs is shown in Figure
1(b). We then define a TSM model over this se-
quence (t1, t2, . . . , tJ ) as:
ptsm(F,E,A) =
J?
j=1
p(tj |tj?n+1, ..., tj?1)
where n indicates the amount of context used. A
4-gram Kneser-Ney smoothed language model is
trained with SRILM (Stolcke, 2002).
Search: In previous work, the search graph in
TSM N-gram SMT was not built dynamically
like in the phrase-based system, but instead con-
structed as a preprocessing step using POS-based
rewrite rules (learned when linearizing the source
side). We do not adopt this framework. We use
1We use . . . to denote discontinuous MTUs.
400
phrase-based search which builds up the decoding
graph dynamically and searches through all pos-
sible reorderings within a fixed window. During
decoding we use the phrase-internal alignments to
perform source linearization. For example, if dur-
ing decoding we would like to apply the phrase
pair ?C D H ? d c?, a combination of t3 and t4 in
Figure 1(b), then we extract the MTUs from this
phrase-pair and linearize the source to be in the
order of the target. We then compute the TSM
probability given the n ? 1 previous MTUs (in-
cluding MTUs occurring in the previous source
phrases). The idea is to replicate rewrite rules
with phrase-pairs to linearize the source. Previ-
ous work on N-gram-based models restricted the
length of the rewrite rules to be 7 or less POS tags.
We use phrases of length 6 and less.
3.2 Operation Sequence Model (OSM)
The OSM model represents a bilingual sentence
pair and its alignment through a sequence of oper-
ations that generate the aligned sentence pair. An
operation either generates source and target words
or it performs reordering by inserting gaps and
jumping forward and backward. The MTUs are
generated in the target left-to-right order just as in
the TSM model. However rather than linearizing
the source-side, reordering operations (gaps and
jumps) are used to handle crossing alignments.
During training, each bilingual sentence pair is de-
terministically converted to a unique sequence of
operations.2 The example in Figure 1(a) is con-
verted to the sequence of operations shown in Fig-
ure 1(c). A step-wise generation of MTUs along
with reordering operations is shown in Figure 1(d).
We learn a Markov model over a sequence of oper-
ations (o1, o2, . . . , oJ ) that encapsulate MTUs and
reordering information which is defined as fol-
lows:
posm(F,E,A) =
J?
j=1
p(oj |oj?n+1, ..., oj?1)
A 9-gram Kneser-Ney smoothed language model
is trained with SRILM.3 By coupling reorder-
ing with lexical generation, each (translation or
reordering) decision conditions on n ? 1 previ-
ous (translation and reordering) decisions span-
ning across phrasal boundaries. The reordering
decisions therefore influence lexical selection and
2Please refer to Durrani et al (2011) for a list of opera-
tions and the conversion algorithm.
3We also tried a 5-gram model, the performance de-
creased slightly in some cases.
vice versa. A heterogeneous mixture of translation
and reordering operations enables the OSM model
to memorize reordering patterns and lexicalized
triggers unlike the TSM model where translation
and reordering are modeled separately.
Search: We integrated the generative story of
the OSM model into the hypothesis extension pro-
cess of the phrase-based decoder. Each hypothesis
maintains the position of the source word covered
by the last generated MTU, the right-most source
word generated so far, the number of open gaps
and their relative indexes, etc. This information
is required to generate the operation sequence for
the MTUs in the hypothesized phrase-pair. After
the operation sequence is generated, we compute
its probability given the previous operations. We
define the main OSM feature, and borrow 4 sup-
portive features, the Gap, Open Gap, Gap-width
and Deletion penalties (Durrani et al, 2011).
3.3 Problem: Target Discontinuity and
Unaligned Words
Two issues that we have ignored so far are the han-
dling of MTUs which have discontinuous targets,
and the handling of unaligned target words. Both
TSM and OSM N-gram models generate MTUs
linearly in left-to-right order. This assumption be-
comes problematic in the cases of MTUs that have
target-side discontinuities (See Figure 2(a)). The
MTU A? g . . . a can not be generated because of
the intervening MTUs B ? b, C . . .H ? c and
D ? d. In the original TSM model, such cases are
dealt with by merging all the intervening MTUs
to form a bigger unit t?1 in Figure 2(c). A solu-
tion that uses split-rules is proposed by Crego and
Yvon (2009) but has not been adopted in Ncode
(Crego et al, 2011), the state-of-the-art TSM N-
gram system. Durrani et al (2011) dealt with
this problem by applying a post-processing (PP)
heuristic that modifies the alignments to remove
such cases. When a source word is aligned to a
discontinuous target-cept, first the link to the least
frequent target word is identified, and the group
of links containing this word is retained while the
others are deleted. The alignment in Figure 2(a),
for example, is transformed to that in Figure 2(b).
This allows OSM to extract the intervening MTUs
t2 . . . t5 (Figure 2(c)). Note that this problem does
not exist when dealing with source-side disconti-
nuities: the TSM model linearizes discontinuous
source-side MTUs such as C . . .H ? c. The
401
Figure 2: Example (a) Original Alignments (b)
Post-Processed Alignments (c) Extracted MTUs ?
t?1 . . . t?3 (from (a)) and t1 . . . t7 (from (b))
OSM model deals with such cases through Insert
Gap and Continue Cept operations.
The second problem is the unaligned target-side
MTUs such as ? ? f in Figure 2(a). Inserting
target-side words ?spuriously? during decoding is
a non-trival problem because there is no evidence
of when to hypothesize such words. These cases
are dealt with in N-gram-based SMT by merging
such MTUs to the MTU on the left or right based
on attachment counts (Durrani et al, 2011), lexical
probabilities obtained from IBM Model 1 (Marin?o
et al, 2006), or POS entropy (Gispert and Marin?o,
2006). Notice how ?? f (Figure 2(a)) is merged
with the neighboring MTU E ? e to form a new
MTU E ? ef (Figure 2 (c)). We initially used the
post-editing heuristic (PP) as defined by Durrani et
al. (2011) for both TSM and OSM N-gram mod-
els, but found that it lowers the translation quality
(See Row 2 in Table 2) in some language pairs.
3.4 Solution: Insertion and Linearization
To deal with these problems, we made novel modi-
fications to the generative story of the OSM model.
Rather than merging the unaligned target MTU
such as ? ? f , to its right or left MTU, we gen-
erate it through a new Generate Target Only (f)
operation. Orthogonal to its counterpart Generate
Source Only (I) operation (as used for MTU t7 in
Figure 2 (c)), this operation is generated as soon
as the MTU containing its previous target word
is generated. In Figure 2(a), ? ? f is generated
immediately after MTU E ? e is generated. In
a sequence of unaligned source and target MTUs,
unaligned source MTUs are generated before the
unaligned target MTUs. We do not modify the de-
coder to arbitrarily generate unaligned MTUs but
hypothesize these only when they appear within
an extracted phrase-pair. The constraint provided
by the phrase-based search makes the Generate
Target Only operation tractable. Using phrase-
based search therefore helps addressing some of
the problems that exist in the decoding framework
of N-gram SMT.
The remaining problem is the discontinuous tar-
get MTUs such as A? g . . . a in Figure 2(a). We
handle this with target linearization similar to the
TSM source linearization. We collapse the target
words g and a in the MTU A ? g . . . a to occur
consecutively when generating the operation se-
quence. The conversion algorithm that generates
the operations thinks that g and a occurred adja-
cently. During decoding we use the phrasal align-
ments to linearize such MTUs within a phrasal
unit. This linearization is done only to compute
the OSM feature. Other features in the phrase-
based system (e.g., language model) work with the
target string in its original order. Notice again how
memorizing larger translation units using phrases
helps us reproduce such patterns. This is achieved
in the tuple N-gram model by using POS-based
split and rewrite rules.
4 Evaluation
Corpus: We ran experiments with data made
available for the translation task of the Eighth
Workshop on Statistical Machine Translation. The
sizes of bitext used for the estimation of translation
and monolingual language models are reported in
Table 1. All data is true-cased.
Pair Parallel Monolingual Lang
fr?en ?39 M ?91 M fr
cs?en ?15.6 M ?43.4 M cs
es?en ?15.2 M ?65.7 M es
ru?en ?2 M ?21.7 M ru
?287.3 M en
Table 1: Number of Sentences (in Millions) used
for Training
We follow the approach of Schwenk and Koehn
(2008) and trained domain-specific language mod-
els separately and then linearly interpolated them
using SRILM with weights optimized on the held-
out dev-set. We concatenated the news-test sets
from four years (2008-2011) to obtain a large dev-
setin order to obtain more stable weights (Koehn
and Haddow, 2012). For Russian-English and
English-Russian language pairs, we divided the
tuning-set news-test 2012 into two halves and used
402
No. System fr-en es-en cs-en ru-en en-fr en-es en-cs en-ru
1. Baseline 31.89 35.07 23.88 33.45 29.89 35.03 16.22 23.88
2. 1+pp 31.87 35.09 23.64 33.04 29.70 35.00 16.17 24.05
3. 1+pp+tsm 31.94 35.25 23.85 32.97 29.98 35.06 16.30 23.96
4. 1+pp+osm 32.17 35.50 24.14 33.21 30.35 35.34 16.49 24.22
5. 1+osm* 32.13 35.65 24.23 33.91 30.54 35.49 16.62 24.25
Table 2: Translating into and from English. Bold: Statistically Significant (Koehn, 2004) w.r.t Baseline
the first half for tuning and second for test. We test
our systems on news-test 2012. We tune with the
k-best batch MIRA algorithm (Cherry and Foster,
2012).
Moses Baseline: We trained a Moses system
(Koehn et al, 2007) with the following settings:
maximum sentence length 80, grow-diag-final-
and symmetrization of GIZA++ alignments, an
interpolated Kneser-Ney smoothed 5-gram lan-
guage model with KenLM (Heafield, 2011) used at
runtime, msd-bidirectional-fe lexicalized reorder-
ing, sparse lexical and domain features (Hasler
et al, 2012), distortion limit of 6, 100-best
translation options, minimum bayes-risk decoding
(Kumar and Byrne, 2004), cube-pruning (Huang
and Chiang, 2007) and the no-reordering-over-
punctuation heuristic.
Results: Table 2 shows uncased BLEU scores
(Papineni et al, 2002) on the test set. Row 2 (+pp)
shows that the post-editing of alignments to re-
move unaligned and discontinuous target MTUs
decreases the performance in the case of ru-en, cs-
en and en-fr. Row 3 (+pp+tsm) shows that our in-
tegration of the TSM model slightly improves the
BLEU scores for en-fr, and es-en. Results drop
in ru-en and en-ru. Row 4 (+pp+osm) shows that
the OSM model consistently improves the BLEU
scores over the Baseline systems (Row 1) giving
significant improvements in half the cases. The
only result that is lower than the baseline system
is that of the ru-en experiment, because OSM is
built with PP alignments which particularly hurt
the performance for ru-en. Finally Row 5 (+osm*)
shows that our modifications to the OSM model
(Section 3.4) give the best result ranging from
[0.24?0.65] with statistically significant improve-
ments in seven out of eight cases. It also shows im-
provements over Row 4 (+pp+osm) even in some
cases where the PP heuristic doesn?t hurt. The
largest gains are obtained in the ru-en translation
task (where the PP heuristic inflicted maximum
damage).
5 Conclusion and Future Work
We have addressed the problem of the indepen-
dence assumption in PBSMT by integrating N-
gram-based models inside a phrase-based system
using a log-linear framework. We try to replicate
the effect of rewrite and split rules as used in the
TSM model through phrasal alignments. We pre-
sented a novel extension of the OSM model to
handle unaligned and discontinuous target MTUs
in the OSM model. Phrase-based search helps us
to address these problems that are non-trivial to
handle in the decoding frameworks of the N-gram-
based models. We tested our extentions and modi-
fications by evaluating against a competitive base-
line system over 8 language pairs. Our integra-
tion of TSM shows small improvements in a few
cases. The OSM model which takes both reorder-
ing and lexical context into consideration consis-
tently improves the performance of the baseline
system. Our modification to the OSM model pro-
duces the best results giving significant improve-
ments in most cases. Although our modifications
to the OSM model enables discontinuous MTUs,
we did not fully utilize these during decoding, as
Moses only uses continous phrases. The discon-
tinuous MTUs that span beyond a phrasal length
of 6 words are therefore never hypothesized. We
would like to explore this further by extending the
search to use discontinuous phrases (Galley and
Manning, 2010).
Acknowledgments
We would like to thank the anonymous reviewers
for their helpful feedback and suggestions. The re-
search leading to these results has received fund-
ing from the European Union Seventh Framework
Programme (FP7/2007-2013) under grant agree-
ment n ? 287658. Alexander Fraser was funded by
Deutsche Forschungsgemeinschaft grant Models
of Morphosyntax for Statistical Machine Transla-
tion. Helmut Schmid was supported by Deutsche
Forschungsgemeinschaft grant SFB 732. This
publication only reflects the authors views.
403
References
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427?436, Montre?al, Canada, June. Associa-
tion for Computational Linguistics.
Marta R. Costa-jussa`, Josep M. Crego, David Vilar,
Jose? A.R. Fonollosa, Jose? B. Marin?o, and Her-
mann Ney. 2007. Analysis and System Combina-
tion of Phrase- and N-Gram-Based Statistical Ma-
chine Translation Systems. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Compu-
tational Linguistics; Companion Volume, Short Pa-
pers, pages 137?140, Rochester, New York, April.
Josep M. Crego and Jose? B. Marin?o. 2006. Improving
Statistical MT by Coupling Reordering and Decod-
ing. Machine Translation, 20(3):199?215.
Josep M. Crego and Franc?ois Yvon. 2009. Gappy
Translation Units under Left-to-Right SMT Decod-
ing. In Proceedings of the Meeting of the European
Association for Machine Translation (EAMT), pages
66?73, Barcelona, Spain.
Josep M. Crego and Franc?ois Yvon. 2010. Improv-
ing Reordering with Linguistically Informed Bilin-
gual N-Grams. In Coling 2010: Posters, pages 197?
205, Beijing, China, August. Coling 2010 Organiz-
ing Committee.
Josep M. Crego, Franc?ois Yvon, and Jose? B. Marin?o.
2011. Ncode: an Open Source Bilingual N-gram
SMT Toolkit. The Prague Bulletin of Mathematical
Linguistics, 96:49?58.
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A Joint Sequence Translation Model with In-
tegrated Reordering. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
1045?1054, Portland, Oregon, USA, June.
Nadir Durrani, Alexander Fraser, and Helmut Schmid.
2013. Model With Minimal Translation Units, But
Decode With Phrases. In The 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Atlanta, Georgia, USA, June. Association
for Computational Linguistics.
Minwei Feng, Arne Mauser, and Hermann Ney. 2010.
A Source-side Decoding Sequence Model for Statis-
tical Machine Translation. In Conference of the As-
sociation for Machine Translation in the Americas
2010, Denver, Colorado, USA, October.
Michel Galley and Christopher D. Manning. 2010.
Accurate Non-Hierarchical Phrase-Based Transla-
tion. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 966?974, Los Angeles, California, June. As-
sociation for Computational Linguistics.
Adria` Gispert and Jose? B. Marin?o. 2006. Linguis-
tic Tuple Segmentation in N-Gram-Based Statistical
Machine Translation. In INTERSPEECH.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised Features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268?275.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187?197, Edinburgh, Scotland, United King-
dom, 7.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144?151, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Maxim Khalilov and Jose? A. R. Fonollosa. 2009. N-
Gram-Based Statistical Machine Translation Versus
Syntax Augmented Machine Translation: Compar-
ison and System Combination. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 424?432, Athens, Greece,
March. Association for Computational Linguistics.
Philipp Koehn and Barry Haddow. 2012. Towards Ef-
fective Use of Training Data in Statistical Machine
Translation. In Proceedings of the Seventh Work-
shop on Statistical Machine Translation, pages 317?
321, Montre?al, Canada, June. Association for Com-
putational Linguistics.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proceed-
ings of HLT-NAACL, pages 127?133, Edmonton,
Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In ACL 2007 Demonstrations, Prague, Czech Re-
public.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388?395, Barcelona, Spain, July.
Shankar Kumar and William J. Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In HLT-NAACL, pages 169?176.
404
Jose? B. Marin?o, Rafael E. Banchs, Josep M. Crego,
Adria` de Gispert, Patrik Lambert, Jose? A. R. Fonol-
losa, and Marta R. Costa-jussa`. 2006. N-gram-
Based Machine Translation. Computational Lin-
guistics, 32(4):527?549.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 198?206, Edinburgh,
Scotland, July. Association for Computational Lin-
guistics.
Franz J. Och and Hermann Ney. 2004. The Alignment
Template Approach to Statistical Machine Transla-
tion. Computational Linguistics, 30(1):417?449.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ?02, pages 311?318,
Morristown, NJ, USA.
Christopher Quirk and Arul Menezes. 2006. Do We
Need Phrases? Challenging the Conventional Wis-
dom in Statistical Machine Translation. In HLT-
NAACL.
Holger Schwenk and Philipp Koehn. 2008. Large and
Diverse Language Models for Statistical Machine
Translation. In International Joint Conference on
Natural Language Processing, pages 661?666, Jan-
uary 2008.
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Intl. Conf. Spoken Lan-
guage Processing, Denver, Colorado.
Christoph Tillman. 2004. A Unigram Orienta-
tion Model for Statistical Machine Translation. In
HLT-NAACL 2004: Short Papers, pages 101?104,
Boston, Massachusetts.
Ashish Vaswani, Haitao Mi, Liang Huang, and David
Chiang. 2011. Rule Markov Models for Fast Tree-
to-String Translation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 856?864, Portland, Oregon, USA, June.
Hui Zhang, Kristina Toutanova, Chris Quirk, and Jian-
feng Gao. 2013. Beyond Left-to-Right: Multi-
ple Decomposition Structures for SMT. In The
2013 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, Atlanta, Georgia,
USA, June. Association for Computational Linguis-
tics.
405
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 115?120,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
More Linguistic Annotation for Statistical Machine Translation
Philipp Koehn, Barry Haddow, Philip Williams, and Hieu Hoang
University of Edinburgh
Edinburgh, United Kingdom
{pkoehn,bhaddow,p.j.williams-2,h.hoang}@inf.ed.ac.uk
Abstract
We report on efforts to build large-scale
translation systems for eight European
language pairs. We achieve most gains
from the use of larger training corpora and
basic modeling, but also show promising
results from integrating more linguistic an-
notation.
1 Introduction
We participated in the shared translation task of
the ACL Workshop for Statistical Machine Trans-
lation 2010 in all language pairs. We continued
our efforts to integrate linguistic annotation into
the translation process, using factored and tree-
based translation models. On average we out-
performed our submission from last year by 2.16
BLEU points on the same newstest2009 test set.
While the submitted system follows the factored
phrase-based approach, we also built hierarchical
and syntax-based models for the English?German
language pair and report on its performance on the
development test sets. All our systems are based
on the Moses toolkit (Koehn et al, 2007).
We achieved gains over the systems from last
year by consistently exploiting all available train-
ing data, using large-scale domain-interpolated,
and consistent use of the factored translation
model to integrate n-gram models over speech
tags. We also experimented with novel domain
adaptation methods, with mixed results.
2 Baseline System
The baseline system uses all available training
data, except for the large UN and 109 corpora, as
well as the optional LDC Gigaword corpus. It uses
a straight-forward setup of the Moses decoder.
Some relevant parameter settings are:
? maximum sentence length 80 words
? tokenization with hyphen splitting
? truecasing
? grow-diag-final-and alignment heuristic
? msd-bidirectional-fe lexicalized reordering
? interpolated 5-gram language model
? tuning on newsdev2009
? testing during development on newstest2009
? MBR decoding
? no reordering over punctuation
? cube pruning
We used most of these setting in our submission
last year (Koehn and Haddow, 2009).
The main difference to our baseline system
from the submission from last year is the use of ad-
ditional training data: larger releases of the News
Commentary, Europarl, Czeng, and monolingual
news corpora. The first two parallel corpora in-
creased roughly 10-20% in size, while the Czeng
parallel corpus and the monolingual news corpora
are five times and twice as big, respectively.
We also handled some of the corpus preparation
steps with more care to avoid some data incon-
sistency problems from last year (affecting mostly
the French language pairs).
An overview of the results is given in Table 1.
The baseline outperforms our submission from
last year by an average of +1.25 points. The gains
for the individual language pairs track the increase
in training data (most significantly for the Czech?
English pairs), and the French?English data pro-
cessing issue.
Note that last year?s submission used special
handling of the German?English language pair,
which we did not replicate in the baseline system,
but report on below.
The table also contains results on the extensions
discussed in the next section.
115
Language Pair ?09 Baseline GT Smooth. UN Data Factored Beam
Spanish-English 24.41 25.25 (+0.76) 25.48 (+0.23) 26.03 (+0.55) 26.20 (+0.17) 26.22 (+0.02)
French-English 23.88 25.23 (+1.35) 25.37 (+0.14) 25.92 (+0.55) 26.13 (+0.21) 26.07 (?0.08)
German-English 18.51 19.47 (+0.96) 19.51 (+0.04) - 21.09 (+0.24) 21.10 (+0.01)
Czech-English 18.49 20.74 (+2.25) 21.19 (+0.45) - 21.33 (+0.14) 21.32 (?0.01)
English-Spanish 23.27 24.20 (+0.93) 24.65 (+0.45) 24.65 (+0.30) 24.37 (?0.28) 24.42 (+0.05)
English-French 22.50 23.83 (+1.33) 23.72 (?0.11) 24.70 (+0.98) 24.74 (+0.04) 24.92 (+0.18)
English-German 14.22 14.68 (+0.46) 14.81 (+0.13) - 15.28 (+0.47) 15.34 (+0.06)
English-Czech 12.64 14.63 (+1.99) 14.68 (+0.05) - - -
avg +1.25 +0.17 +0.60 +0.14 +0.03
Table 1: Overview of results: baseline system and extensions. On average we outperformed our sub-
mission from last year by 1.87 BLEU points on the same newstest2009 test set. For additional gains for
French?English and German?English, please see Tables 7 and 8.
Czech?English
Corpus Num. Tokens Pplx. Weight
EU 29,238,799 582 0.054
Fiction 15,441,105 429 0.028
Navajo 561,144 671 0.002
News (czeng) 2,909,322 288 0.127
News (mono) 1,148,480,525 175 0.599
Subtitles 23,914,244 526 0.019
Techdoc 8,322,958 851 0.099
Web 4,469,177 441 0.073
French?English
Corpus Num. Tokens Pplx. Weight
Europarl 50,132,615 352 0.105
News Com. 2,101,921 311 0.204
UN 216,052,412 383 0.089
News 1,148,480,525 175 0.601
Table 2: English LM interpolation: number of to-
kens, perplexity, and interpolation weight for the
different corpora
2.1 Interpolated Language Model
The WMT training data exhibits an increasing di-
versity of corpora: Europarl, News Commentary,
UN, 109, News ? and seven different sources
within the Czeng corpus.
It is well known that domain adaptation is an
important step in optimizing machine translation
systems. A relatively simple and straight-forward
method is the linear interpolation of the language
model, as we explored previously (Koehn and
Schroeder, 2007; Schwenk and Koehn, 2008).
We trained domain-specific language models
separately and then linearly interpolated them us-
ing SRILM toolkit (Stolke, 2002) with weights op-
Language Pair Cased Uncased
Spanish-English 25.25 26.36 (+1.11)
French-English 25.23 26.29 (+1.06)
German-English 19.47 20.63 (+1.16)
Czech-English 20.74 21.76 (+1.02)
English-Spanish 24.20 25.47 (+1.27)
English-French 23.83 25.02 (+1.19)
English-German 14.68 15.18 (+0.50)
English-Czech 14.63 15.13 (+0.50)
avg +0.98
Table 3: Effect of truecasing: cased and uncased
BLEU scores
timized on the development set newsdev2009.
See Table 2 for numbers on perplexity, corpus
sizes, and interpolation weights. Note, for in-
stance, the relatively high weight for the News
Commentary corpus (0.204) compared to the Eu-
roparl corpus (0.105) in the English language
model for the French-English system, despite the
latter being about 25 times bigger.
2.2 Truecasing
As last year, we deal with uppercase and lowercase
forms of the same words by truecasing the corpus.
This means that we change each surface word oc-
currence of a word to its natural case, e.g., the, Eu-
rope. During truecasing, we change the first word
of a sentence to its most frequent casing. During
de-truecasing, we uppercase the first letter of the
first word of a sentence.
See Table 3 for the performance of this method.
In this table, we compare the cased and uncased
BLEU scores, and observe that we lose on average
roughly one BLEU point due to wrong casing.
116
Count Count of Count Discount Count*
1 357,929,182 0.140 0.140
2 24,966,751 0.487 0.975
3 8,112,930 0.671 2.014
4 4,084,365 0.714 2.858
5 2,334,274 0.817 4.088
Table 4: Good Turing smoothing, as in the
French?English model: counts, counts of counts,
discounting factor and discounted count
3 Extensions
In this section, we describe extensions over the
baseline system. On average, these give us im-
provements of about 1 BLEU point over the base-
line.
3.1 Good Turing Smoothing
Traditionally, we use raw counts to estimate con-
ditional probabilities for phrase translation. How-
ever, this method gives dubious results for rare
counts. The most blatant case is the single oc-
currence of a foreign phrase, whose sole English
translation will receive the translation probability
1
1 = 1.
Foster et al (2006) applied ideas from language
model smoothing to the translation model. Good
Turing smoothing (Good, 1953) uses counts of
counts statistics to assess how likely we will see
a word (or, in our case, a phrase) again, if we have
seen it n times in the training corpus. Instead of
using the raw counts, adapted (lower) counts are
used in the estimation of the conditional probabil-
ity distribution.
The count of counts are collected for the phrase
pairs. See Table 4 for details on how this ef-
fects the French?English model. For instance,
we find singleton 357,929,182 phrase pairs and
24,966,751 phrase pairs that occur twice. The
Good Turing formula tells us to adapt singleton
counts to 24,966,751357,929,182 = 0.14. This means for our
degenerate example of a single occurrence of a
single French phrase that its single English transla-
tion has probability 0.141 = 0.14 (we do not adjust
the denominator).
Good Turing smoothing of the translation table
gives us a gain of +0.17 BLEU points on average,
and improvements for 7 out of 8 language pairs.
For details refer back to Table 1.
Model BLEU
Baseline 14.81
Part-of-Speech 15.03 (+0.22)
Morphogical 15.28 (+0.47)
Table 5: English?German: use of morphological
and part-of-speech n-gram models
3.2 UN Data
While we already used the UN data in the lan-
guage model for the Spanish?English and French?
English language pairs, we now also add it to the
translation model.
The corpus is very large, four times bigger than
the already used training data, but relatively out
of domain, as indicated by the high perplexity and
low interpolation weight during language model
interpolation (recall Table 2).
Adding the corpus to the four systems gives im-
provements of +0.60 BLEU points on average.
For details refer back to Table 1.
3.3 POS n-gram Model
The factored model approach (Koehn and Hoang,
2007) allows us to integrate 7-gram models over
part-of-speech tags. The part-of-speech tags are
produced during decoding by the phrase mapping
of surface words on the source side to a factored
representation of surface words and their part-of-
speech tags on the target side in one translation
step.
We previously used this additional scoring com-
ponent for the German?English language pairs
with success. Thus we now applied to it all other
language pairs (except for English?Czech due to
the lack of a Czech part-of-speech tagger).
We used the following part-of-speech taggers:
? English: mxpost1
? German: LoPar2
? French: TreeTagger3
? Spanish: TreeTagger
For English?German, we also used morpholog-
ical tags, which give better performance than just
basic part-of-speech tags (+0.46 vs. +0.22, see Ta-
ble 5). We observe gains for all language pairs
except for English?Spanish, possibly due to the
1www.inf.ed.ac.uk/resources/nlp/local doc/MXPOST.html
2www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/
LoPar.html
3www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
117
Model BLEU
Baseline 14.81
Part-of-Speech 15.03 (+0.22)
Morphogical 15.28 (+0.47)
Table 6: English?German: use of morphological
and part-of-speech n-gram models
Language Pair Baseline with 109
French?English 25.92 27.15 (+1.23)
English?French 24.70 24.80 (+0.10)
Table 7: Use of large French?English corpus
faulty use of the Spanish part-of-speech tagger.
We gain +0.14 BLEU points on average (includ-
ing the ?0.28 drop for Spanish). For details refer
back to Table 1.
3.4 Bigger Beam Sizes
As a final general improvement, we adjusted the
beam settings during decoding. We increased the
pop-limit from 5,000 to 20,000 and the translation
table limit from the default 20 to 50.
The decoder is quite fast, partly due to multi-
threaded decoding using 4 cores machines (Had-
dow, 2010). Increasing the beam sizes slowed
down decoding speed from about 2 seconds per
sentence to about 8 sec/sentence.
However, this resulted only in minimal gains,
on average +0.03 BLEU. For details refer back to
Table 1.
3.5 109 Corpus
Last year, due to time constraints, we were not
able to use the billion word 109 corpus for the
French?English language pairs. This is largest
publicly available parallel corpus, and it does
strain computing resources, for instance forcing
us to use multi-threaded GIZA++ (Gao and Vogel,
2008).
Table 7 shows the gains obtained from us-
ing this corpus in both the translation model and
the language model opposed to a baseline sys-
tem trained with otherwise the same settings. For
French?English we see large gains (+1.23), but not
for English?French (+0.10).
Our official submission for the French?English
language pairs used these models. They did not in-
clude a part-of-speech language model and bigger
beam sizes.
Model BLEU
Baseline 19.51
+ compound splitting 20.09 (+0.58)
+ pre-reordering 20.03 (+0.52)
+ both 20.85 (+1.34)
Table 8: Special handling of German?English
Language Pair Baseline Weighted TM
Spanish-English 26.20 26.15 (?0.05)
French-English 26.11 26.30 (+0.19)
German-English 21.09 20.81 (?0.28)
Czech-English 21.33 21.21 (?0.12)
English-German 15.28 15.01 (?0.27)
avg. ?0.11
Table 9: Interpolating the translation model with
language model weights
3.6 German?English
For the German?English language direction, we
used two additional processing steps that have
shown to be successful in the past, and again re-
sulted in significant gains.
We split large words based on word frequen-
cies to tackle the problem of word compounds in
German (Koehn and Knight, 2003). Secondly, we
re-order the German input to the decoder (and the
German side of the training data) to align more
closely to the English target language (Collins
et al, 2005).
The two methods improve +0.58 and +0.52 over
the baseline individually, and +1.34 when com-
bined. See also Table 8.
3.7 Translation Model Interpolation
Finally, we explored a novel domain adaption
method for the translation model. Since the in-
terpolation of language models is very success-
ful, we want to interpolate translation models sim-
ilarly. Given interpolation weights, the resulting
translation table is a weighted linear interpolation
of the individual translation models trained sepa-
rately for each domain.
However, while for language models we have a
effective method to find the interpolation weights
(optimizing perplexity on a development set), we
do not have such a method for the translation
model. Thus, we simply recycle the weights we
obtained from language model interpolation (ex-
cluding the weighting for monolingual corpora).
118
Model BLEU
phrase-based 14.81
factored phrase-based 15.28
hierarchical 14.86
target syntax 14.66
Table 10: Tree-based models for English?German
Over the Spanish?English baseline system, we
obtained gains of +0.39 BLEU points. Unfortu-
nately, we did not see comparable gains on the sys-
tems optimized by the preceding steps. In fact, in
4 out of 5 language pairs, we observed lower BLEU
scores. See Table 9 for details.
We did not use this method in our submission.
4 Tree-Based Models
A major extension of the capabilities of the Moses
system is the accommodation of tree-based mod-
els (Hoang et al, 2009). While we have not yet
carried out sufficient experimentation and opti-
mization of the implementation, we took the occa-
sion of the shared translation task as a opportunity
to build large-scale systems using such models.
We build two translation systems: One using
tree-based models without additional linguistic an-
notation, which are known as hierarchical phrase-
based models (Chiang, 2005), and another sys-
tem that uses linguistic annotation on the target
side, which are known under many names such as
string-to-tree models or syntactified target models
(Marcu et al, 2006).
Both models are trained using a very similar
pipeline as for the phrase model. The main dif-
ference is that the translation rules do not have to
be contiguous phrases, but may contain gaps with
are labeled and co-ordinated by non-terminal sym-
bols. Decoding with such models requires a very
different algorithm, which is related to syntactic
chart parsing.
In the target syntax model, the target gaps and
the entire target phrase must map to constituents
in the parse tree. This restriction may be relaxed
by adding constituent labels such as DET+ADJ or
NP\DET to group neighboring constituents or indi-
cate constituents that lack an initial child, respec-
tively (Zollmann and Venugopal, 2006).
We applied these models to the English?
German language direction, which is of particu-
lar interest to us due to the rich target side mor-
phology and large degree of reordering, resulting
in relatively poor performance. See Table 10 for
experimental results with the two traditional mod-
els (phrase-based model and a factored model that
includes a 7-gram morphological tag model) and
the two newer models (hierarchical and target syn-
tax). The performance of the phrase-based, hierar-
chical, and target syntax model are close in terms
of BLEU.
5 Conclusions
We obtained substantial gains over our systems
from last year for all language pairs. To a large
part, these gains are due to additional training data
and our ability to exploit them.
We also saw gains from adding linguistic an-
notation (in form of 7-gram models over part-of-
speech tags) and promising results for tree-based
models. At this point, we are quite satisfied be-
ing able to build competitive systems with these
new models, which opens up major new research
directions.
Everything we described here is part of the open
source Moses toolkit. Thus, all our experiments
should be replicable with publicly available re-
sources.
Acknowledgement
This work was supported by the EuroMatrixPlus
project funded by the European Commission (7th
Framework Programme).
References
Chiang, D. (2005). A hierarchical phrase-based
model for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics
(ACL?05), pages 263?270, Ann Arbor, Michi-
gan. Association for Computational Linguistics.
Collins, M., Koehn, P., and Kucerova, I. (2005).
Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational
Linguistics (ACL?05), pages 531?540, Ann Ar-
bor, Michigan. Association for Computational
Linguistics.
Foster, G., Kuhn, R., and Johnson, H. (2006).
Phrasetable smoothing for statistical machine
translation. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 53?61, Sydney, Aus-
119
tralia. Association for Computational Linguis-
tics.
Gao, Q. and Vogel, S. (2008). Parallel implemen-
tations of word alignment tool. In ACL Work-
shop on Software Engineering, Testing, and
Quality Assurance for Natural Language Pro-
cessing, pages 49?57.
Good, I. J. (1953). The population frequency of
species and the estimation of population param-
eters. Biometrika, 40:237?264.
Haddow, B. (2010). Adding multi-threaded de-
coding to moses. The Prague Bulletin of Math-
ematical Linguistics, (93):57?66.
Hoang, H., Koehn, P., and Lopez, A. (2009). A
unified framework for phrase-based, hierarchi-
cal, and syntax-based statistical machine trans-
lation. In Proceedings of IWSLT.
Koehn, P. and Haddow, B. (2009). Edinburgh?s
submission to all tracks of the WMT2009
shared task with reordering and speed improve-
ments to Moses. In Proceedings of the Fourth
Workshop on Statistical Machine Translation,
pages 160?164, Athens, Greece. Association
for Computational Linguistics.
Koehn, P. and Hoang, H. (2007). Factored trans-
lation models. In Proceedings of the 2007
Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL),
pages 868?876.
Koehn, P., Hoang, H., Birch, A., Callison-Burch,
C., Federico, M., Bertoldi, N., Cowan, B., Shen,
W., Moran, C., Zens, R., Dyer, C. J., Bo-
jar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open source toolkit for statistical ma-
chine translation. In Proceedings of the 45th
Annual Meeting of the Association for Com-
putational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions,
pages 177?180, Prague, Czech Republic. Asso-
ciation for Computational Linguistics.
Koehn, P. and Knight, K. (2003). Empirical meth-
ods for compound splitting. In Proceedings of
Meeting of the European Chapter of the Associ-
ation of Computational Linguistics (EACL).
Koehn, P. and Schroeder, J. (2007). Experiments
in domain adaptation for statistical machine
translation. In Proceedings of the Second Work-
shop on Statistical Machine Translation, pages
224?227, Prague, Czech Republic. Association
for Computational Linguistics.
Marcu, D., Wang, W., Echihabi, A., and Knight,
K. (2006). Spmt: Statistical machine transla-
tion with syntactified target language phrases.
In Proceedings of the 2006 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 44?52, Sydney, Australia. Associa-
tion for Computational Linguistics.
Schwenk, H. and Koehn, P. (2008). Large and
diverse language models for statistical machine
translation. In Proceedings of the 3rd Interna-
tional Joint Conference on Natural Language
Processing (IJCNLP).
Stolke, A. (2002). SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the
International Conference on Spoken Language
Processing.
Zollmann, A. and Venugopal, A. (2006). Syntax
augmented machine translation via chart pars-
ing. In Proceedings on the Workshop on Statis-
tical Machine Translation, pages 138?141, New
York City. Association for Computational Lin-
guistics.
120
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 409?417,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Improved Translation with Source Syntax Labels
Hieu Hoang
School of Informatics
University of Edinburgh
h.hoang@sms.ed.ac.uk
Philipp Koehn
School of Informatics
University of Edinburgh
pkoehn@inf.ed.ac.uk
Abstract
We present a new translation model
that include undecorated hierarchical-style
phrase rules, decorated source-syntax
rules, and partially decorated rules.
Results show an increase in translation
performance of up to 0.8% BLEU for
German?English translation when trained
on the news-commentary corpus, using
syntactic annotation from a source lan-
guage parser. We also experimented with
annotation from shallow taggers and found
this increased performance by 0.5% BLEU.
1 Introduction
Hierarchical decoding is usually described as a
formally syntactic model without linguistic com-
mitments, in contrast with syntactic decoding
which constrains rules and production with lin-
guistically motivated labels. However, the decod-
ing mechanism for both hierarchical and syntactic
systems are identical and the rule extraction are
similar.
Hierarchical and syntax statistical machine
translation have made great progress in the last
few years and can claim to represent the state of
the art in the field. Both use synchronous con-
text free grammar (SCFG) formalism, consisting
of rewrite rules which simultaneously parse the in-
put sentence and generate the output sentence. The
most common algorithm for decoding with SCFG
is currently CKY+ with cube pruning works for
both hierarchical and syntactic systems, as imple-
mented in Hiero (Chiang, 2005), Joshua (Li et al,
2009), and Moses (Hoang et al, 2009)
Rewrite rules in hierarchical systems have gen-
eral applicability as their non-terminals are undec-
orated, giving hierarchical system broad coverage.
However, rules may be used in inappropriate sit-
uations without the labeled constraints. The gen-
eral applicability of undecorated rules create spu-
rious ambiguity which decreases translation per-
formance by causing the decoder to spend more
time sifting through duplicate hypotheses. Syntac-
tic systems makes use of linguistically motivated
information to bias the search space at the expense
of limiting model coverage.
This paper presents work on combining hier-
archical and syntax translation, utilizing the high
coverage of hierarchical decoding and the in-
sights that syntactic information can bring. We
seek to balance the generality of using undeco-
rated non-terminals with the specificity of labeled
non-terminals. Specifically, we will use syntac-
tic labels from a source language parser to label
non-terminal in production rules. However, other
source span information, such as chunk tags, can
also be used.
We investigate two methods for combining the
hierarchical and syntactic approach. In the first
method, syntactic translation rules are used con-
currently with a hierarchical phrase rules. Each
ruleset is trained independently and used concur-
rently to decode sentences. However, results for
this method do not improve.
The second method uses one translation model
containing both hierarchical and syntactic rules.
Moreover, an individual rule can contain both
decorated syntactic non-terminals, and undeco-
rated hierarchical-style non-terminals (also, the
left-hand-side non-terminal may, or may not be
decorated). This results in a 0.8% improvement
over the hierarchical baseline and analysis suggest
that long-range ordering has been improved.
We then applied the same methods but using
linguistic annotation from a chunk tagger (Abney,
1991) instead of a parser and obtained an improve-
ment of 0.5% BLEU over the hierarchical base-
line, showing that gains with additional source-
side annotation can be obtained with simpler tools.
2 Past Work
Hierarchical machine translation (Chiang, 2005)
extends the phrase-based model by allowing the
use of non-contiguous phrase pairs (?production
rules?). It promises better re-ordering of transla-
tion as the reordering rules are an implicit part of
the translation model. Also, hierarchical rules fol-
low the recursive structure of the sentence, reflect-
ing the linguistic notion of language.
However, the hierarchical model has several
limitations. The model makes no use of linguis-
tic information, thus creating a simple model with
broad coverage. However, (Chiang, 2005) also
describe heuristic constraints that are used during
409
rule extraction to reduce spurious ambiguity. The
resulting translation model does reduces spurious
ambiguity but also reduces the search space in an
arbitrary manner which adversely affects transla-
tion quality.
Syntactic labels from parse trees can be used
to annotate non-terminals in the translation model.
This reduces incorrect rule application by restrict-
ing rule extraction and application. However,
as noted in (Ambati and Lavie, 2008) and else-
where,the na??ve approach of constraining every
non-terminal to a syntactic constituent severely
limits the coverage of the resulting grammar,
therefore, several approaches have been used to
improve coverage when using syntactic informa-
tion.
Zollmann and Venugopal (2006) allow rules to
be extracted where non-terminals do not exactly
span a target constituent. The non-terminals are
then labeled with complex labels which amalga-
mates multiple labels in the span. This increase
coverage at the expense of increasing data sparsity
as the non-terminal symbol set increases dramati-
cally. Huang and Chiang (2008) use parse infor-
mation of the source language, production rules
consists of source tree fragments and target lan-
guages strings. During decoding, a packed for-
est of the source sentence is used as input, the
production rule tree fragments are applied to the
packed forest. Liu et al (2009) uses joint decod-
ing with a hierarchical and tree-to-string model
and find that translation performance increase for a
Chinese-English task. Galley et al (2004) creates
minimal translation rules which can explain a par-
allel sentence pair but the rules generated are not
optimized to produce good translations or cover-
age in any SMT system. This work was extended
and described in (Galley et al, 2006) which cre-
ates rules composed of smaller, minimal rules, as
well as dealing with unaligned words. These mea-
sures are essential for creating good SMT systems,
but again, the rules syntax are strictly constrained
by a parser.
Others have sought to add soft linguistic con-
straints to hierarchical models using addition fea-
ture functions. Marton and Resnik (2008) add fea-
ture functions to penalize or reward non-terminals
which cross constituent boundaries of the source
sentence. This follows on from earlier work in
(Chiang, 2005) but they see gains when finer grain
feature functions which different constituency
types. The weights for feature function is tuned
in batches due to the deficiency of MERT when
presented with many features. Chiang et al (2008)
rectified this deficiency by using the MIRA to tune
all feature function weights in combination. How-
ever, the translation model continues to be hierar-
chical.
Chiang et al (2009) added thousands of
linguistically-motivated features to hierarchical
and syntax systems, however, the source syntax
features are derived from the research above. The
translation model remain constant but the parame-
terization changes.
Shen et al (2009) discusses soft syntax con-
straints and context features in a dependency tree
translation model. The POS tag of the target head
word is used as a soft constraint when applying
rules. Also, a source context language model and
a dependency language model are also used as fea-
tures.
Most SMT systems uses the Viterbi approxi-
mation whereby the derivations in the log-linear
model is not marginalized, but the maximum
derivation is returned. String-to-tree models build
on this so that the most probable derivation, in-
cluding syntactic labels, is assumed to the most
probable translation. This fragments the deriva-
tion probability and the further partition the search
space, leading to pruning errors. Venugopal et al
(2009) attempts to address this by efficiently es-
timating the score over an equivalent unlabeled
derivation from a target syntax model.
Ambati and Lavie (2008); Ambati et al (2009)
notes that tree-to-tree often underperform models
with parse tree only on one side due to the non-
isomorphic structure of languages. This motivates
the creation of an isomorphic backbone into the
target parse tree, while leaving the source parse
unchanged.
3 Model
In extending the phrase-based model to the hier-
archical model, non-terminals are used in transla-
tion rules to denote subphrases. Hierarchical non-
terminals are undecorated so are unrestricted to the
span they cover. In contrast, SCFG-based syntac-
tic models restrict the extraction and application
of non-terminals, typically to constituency spans
of a parse tree or forest. Our soft syntax model
combine the hierarchical and source-syntactic ap-
proaches, allowing translation rules with undeco-
rated and decorated non-terminals with informa-
tion from a source language tool.
We give an example of the rules extracted from
an aligned sentence in Figure 1, with a parse tree
on the source side.
Lexicalized rules with decorated non-terminals
are extracted, we list five (non-exhaustive) exam-
ples below.
410
Figure 1: Aligned parsed sentence
NP ? Musharrafs letzter Akt
# Musharraf ?s Last Act
NP ? NE1 letzter Akt # X1 Last Act
NP ? NE1 ADJA2 Akt # X1 X2 Act
NP ? NE1 letzter NN2 # X1 Last X2
TOP ? NE1 ADJA2 Akt ? # X1 X2 Act ?
Hierarchical style rules are also extracted where
the span doesn?t exactly match a parse constituent.
We list 2 below.
X ? letzter Akt # Last Act
X ? letzter X1 # Last X1
Unlexicalized rules with decorated non-
terminals are also extracted:
TOP ? NP1 PUNC2 # X1 X2
NP ? NE1 ADJA2 NN3 # X1 X2 X3
Rules are also extracted which contains a mix-
ture of decorated and undecorated non-terminals.
These rules can also be lexicalized or unlexical-
ized. A non-exhaustive sample is given below:
X ? ADJA1 Akt # X1 Act
NP ? NE1 X2 # X1 X2
TOP ? NE1 letzter X2 # X1 Last X2
At decoding time, the parse tree of the input
sentence is available to the decoder. Decorated
non-terminals in rules must match the constituent
span in the input sentence but the undecorated X
symbol can match any span.
Formally, we model translation as a string-
to-string translation using a synchronous CFG
that constrain the application of non-terminals to
matching source span labels. The source words
and span labels are represented as an unweighted
word lattice, < V,E >, where each edge in the
lattice correspond to a word or non-terminal label
over the corresponding source span. In the soft
syntax experiments, edges with the default source
label, X , are also created for all spans. Nodes
in the lattice represent word positions in the sen-
tence.
We encode the lattice in a chart, as described
in (Dyer et al, 2008). A chart is is a tuple of 2-
dimensional matrices < F,R >. Fi,j is the word
or non-terminal label of the jth transition starting
word position i. Ri,j is the end word position of
the node on the right of the jth transition leaving
word position i.
The input sentence is decoded with a set of
translation rules of the form
X ?< ?Ls, ?,?>
where ? and ? and strings of terminals and non-
terminals. Ls and the string ? are drawn from the
same source alphabet, ?s. ? is the target string,
also consisting of terminals and non-terminals. ?
is the one-to-one correspondence between non-
terminals in ? and ?. Ls is the left-hand-side of
the source. As a string-to-string model, the left-
hand-side of the target is always the default target
non-terminal label, X .
Decoding follows the CKY+ algorithms which
process contiguous spans of the source sentence
bottom up. We describe the algorithm as inference
rules, below, omitting the target side for brevity.
Initialization
[X ? ??Ls, i, i]
(X ? ?Ls) ? G
Terminal Symbol
[X ? ? ? Fj,k?Ls, i, j]
[X ? ?Fj,k ? ?Ls, i, j + 1]
Non-Terminal Symbol
[X ? ? ? Fj,k?Ls, i, j] [X, j,Rj,k]
[X ? ?Fj,k ? ?Ls, i, Rj,k]
411
Left Hand Side
[X ? ? ? Ls, i, Ri,j ] [Fi,j = Ls]
[X ? ?Ls?, i, Ri,j ]
Goal
[X ? ?Ls?, 0, |V | ? 1]
This model allows translation rules to take ad-
vantage of both syntactic label and word context.
The presence of default label edges between every
node allows undecorated non-terminals to be ap-
plied to any span, allowing flexibility in the trans-
lation model.
This contrasts with the approach by (Zollmann
and Venugopal, 2006) in attempting to improve the
coverage of syntactic translation. Rather than cre-
ating ad-hoc schemes to categories non-terminals
with syntactic labels when they do not span syn-
tactic constituencies, we only use labels that are
presented by the parser or shallow tagger. Nor do
we try to expand the space where rules can ap-
ply by propagating uncertainty from the parser in
building input forests, as in (Mi et al, 2008), but
we build ambiguity into the translation rule.
The model also differs from (Marton and
Resnik, 2008; Chiang et al, 2008, 2009) by adding
informative labels to rule non-terminals and re-
quiring them to match the source span label. The
soft constraint in our model pertain not to a ad-
ditional feature functions based on syntactic infor-
mation, but to the availability of syntactic and non-
syntactic informed rules.
4 Parameterization
In common with most current SMT systems, the
decoding goal of finding the most probable target
language sentence t?, given a source language sen-
tence s
t? = argmaxt p(t|s) (1)
The argmax function defines the search objec-
tive of the decoder. We estimate p(t|s) by decom-
posing it into component models
p(t|s) =
1
Z
?
m
h?m(t, s)
?m (2)
where h?m(t, s) is the feature function for compo-
nent m and ?m is the weight given to component
m. Z is a normalization factor which is ignored in
practice. Components are translation model scor-
ing functions, language model, and other features.
The problem is typically presented in log-space,
which simplifies computations, but otherwise does
not change the problem due to the monotonicity of
the log function (hm = log h?m)
log p(t|s) =
?
m
?m hm(t, s) (3)
An advantage of our model over (Marton and
Resnik, 2008; Chiang et al, 2008, 2009) is the
number of feature functions remains the same,
therefore, the tuning algorithm does not need to be
replaced; we continue to use MERT (Och, 2003).
5 Rule Extraction
Rule extraction follows the algorithm described in
(Chiang, 2005). We note the heuristics used for hi-
erarchical phrases extraction include the following
constraints:
1. all rules must be at least partially lexicalized,
2. non-terminals cannot be consecutive,
3. a maximum of two non-terminals per rule,
4. maximum source and target span width of 10
word
5. maximum of 5 source symbols
In the source syntax model, non-terminals are re-
stricted to source spans that are syntactic phrases
which severely limits the rules that can be ex-
tracted or applied during decoding. Therefore, we
can adapt the heuristics, dropping some of the con-
straints, without introducing too much complexity.
1. consecutive non-terminals are allowed
2. a maximum of three non-terminals,
3. all non-terminals and LHS must span a parse
constituent
In the soft syntax model, we relax the constraint
of requiring all non-terminals to span parse con-
stituents. Where there is no constituency spans,
the default symbol X is used to denote an undeco-
rated non-terminal. This gives rise to rules which
mixes decorated and undecorated non-terminals.
To maintain decoding speed and minimize spu-
rious ambiguity, item (1) in the syntactic extrac-
tion heuristics is adapted to prohibit consecutive
undecorated non-terminals. This combines the
strength of syntactic rules but also gives the trans-
lation model more flexibility and higher coverage
from having undecorated non-terminals. There-
fore, the heuristics become:
1. consecutive non-terminals are allowed, but
consecutive undecorated non-terminals are
prohibited
2. a maximum of three non-terminals,
3. all non-terminals and LHS must span a parse
constituent
412
5.1 Rule probabilities
Maximum likelihood phrase probabilities, p(?t|?s),
are calculated for phrase pairs, using fractional
counts as described in (Chiang, 2005). The max-
imum likelihood estimates are smoothed using
Good-Turing discounting (Foster et al, 2006). A
phrase count feature function is also create for
each translation model, however, the lexical and
backward probabilities are not used.
6 Decoding
We use the Moses implementation of the SCFG-
based approach (Hoang et al, 2009) which sup-
port hierarchical and syntactic training and decod-
ing used in this paper. The decoder implements
the CKY+ algorithm with cube pruning, as well as
histogram and beam pruning, all pruning param-
eters were identical for all experiments for fairer
comparison.
All non-terminals can cover a maximum of 7
source words, similar to the maximum rule span
feature other hierarchical decoders to speed up de-
coding time.
7 Experiments
We trained on the New Commentary 2009 cor-
pus1, tuning on a hold-out set. Table 1 gives more
details on the corpus. nc test2007 was used for
testing.
German English
Train Sentences 82,306
Words 2,034,373 1,965,325
Tune Sentences 2000
Test Sentences 1026
Table 1: Training, tuning, and test conditions
The training corpus was cleaned and filtered us-
ing standard methods found in the Moses toolkit
(Koehn et al, 2007) and aligned using GIZA++
(Och and Ney, 2003). Standard MERT weight tun-
ing was used throughout. The English half of the
training data was also used to create a trigram lan-
guage model which was used for each experiment.
All experiments use truecase data and results are
reported in case-sensitive BLEU scores (Papineni
et al, 2001).
The German side was parsed with the Bitpar
parser2. 2042 sentences in the training corpus
failed to parse and were discarded from the train-
ing for both hierarchical and syntactic models to
1http://www.statmt.org/wmt09/
2http://www.ims.uni-stuttgart.de/tcl/SOFTWARE/BitPar.html
# Model % BLEU
Using parse tree
1 Hierarchical 15.9
2 Syntax rules 14.9
3 Joint hier. + syntax rules 16.1
4 Soft syntax rules 16.7
Using chunk tags
5 Hierarchical 16.3
6 Soft syntax 16.8
Table 2: German?English results for hierarchical
and syntactic models, in %BLEU
ensure that train on identical amounts of data.
Similarly, 991 out of 1026 sentences were parsable
in the test set. To compare like-for-like, the base-
line translates the same 991 sentences, but evalu-
ated over 1026 sentences. (In the experiments with
chunk tags below, all 1026 sentences are used).
We use as a baseline the vanilla hierarchical
model which obtained a BLEU score of 15.9%
(see Table 2, line 1).
7.1 Syntactic translation
Using the na??ve translation model constrained
with syntactic non-terminals significantly de-
creases translation quality, Table 2, line 2. We
then ran hierarchical concurrently with the syntac-
tic models, line 3, but see little improvement over
the hierarchical baseline. However, we see a gain
of 0.8% BLEU when using the soft syntax model.
7.2 Reachability
The increased performance using the soft syn-
tax model can be partially explained by studying
the effect of changes to the extraction and decod-
ing algorithms has to the capacity of the transla-
tion pipeline. We run some analysis in which we
trained the phrase models with a corpus of one
sentence and attempt to decode the same sentence.
Pruning and recombination were disabled during
decoding to negate the effect of language model
context and model scores.
The first thousand sentences of the training cor-
pus was analyzed, Table 3. The hierarchical model
successfully decode over half of the sentences
while a translation model constrained by a source
syntax parse tree manages only 113 sentences, il-
lustrating the severe degradation in coverage when
a naive syntax model is used.
Decoding with a hierarchical and syntax model
jointly (line 3) only decode one extra sentence
over the hierarchical model, suggesting that the
expressive power of the hierarchical model almost
413
# Model Reachable sentences
1 Hierarchical 57.8%
2 Syntax rules 11.3%
3 Joint hier. + syntax rules 57.9%
4 Soft syntax rules 58.5%
Table 3: Reachability of 1000 training sentences:
can they be translated with the model?
Figure 2: Source span lengths
completely subsumes that of the syntactic model.
The MERT tuning adjust the weights so that the
syntactic model is very rarely applied during joint
decoding, suggesting that the tuning stage prefers
the broader coverage of the hierarchical model
over the precision of the syntactic model.
However, the soft syntax model slightly in-
creases the reachability of the target sentences,
lines 4.
7.3 Rule Span Width
The soft syntactic model contains rules with three
non-terminals, as opposed to 2 in the hierarchical
model, and consecutive non-terminals in the hope
that the rules will have the context and linguistic
information to apply over longer spans. There-
fore, it is surprising that when decoding with a
soft syntactic grammar, significantly more words
are translated singularly and the use of long span-
ning rules is reduced, Figure 2.
However, looking at the usage of the glue rules
paints a different picture. There is significantly
less usage of the glue rules when decoding with
the soft syntax model, Figure 3. The use of
the glue rule indicates a failure of the translation
model to explain the translation so the decrease
in its usage is evidence of the better explanatory
power of the soft syntactic model.
An example of an input sentence, and the best
translation found by the hierarchical and soft syn-
tax model can be seen in Table 4. Figure 4 is the
Figure 3: Length and count of glue rules used de-
coding test set
Figure 4: Example input parse tree
parse tree given to the soft syntax model.
Input
laut Ja?nos Veres wa?re dies im ersten Quartal 2008
mo?glich .
Hierarchical output
according to Ja?nos Veres this in the first quarter of 2008
would be possible .
Soft Syntax
according to Ja?nos Veres this would be possible in the
first quarter of 2008 .
Table 4: Example input and best output found
Both output are lexically identical but the output
of the hierarchical model needs to be reordered to
be grammatically correct. Contrast the derivations
produced by the hierarchical grammar, Figure 5,
with that produced with the soft syntax model,
Figure 6. The soft syntax derivation makes use
of several non-lexicalized to dictate word order,
shown below.
X ? NE1 NE2 # X1 X2
X ? V AFIN1 PDS2 # X1 X2
X ? ADJA1 NN2 # X1 X2
X ? APPRART1 X2 CARD3 # X1 X2 X3
X ? PP1 X2 PUNC3 # X2 X1 X3
414
Figure 5: Derivation with Hierarchical model
Figure 6: Derivation with soft syntax model
The soft syntax derivation include several rules
which are partially decorated. Crucially, the last
rule in the list above reorders the PP phrase
and the non-syntactic phrase X to generate the
grammatically correct output. The other non-
lexicalized rules monotonically concatenate the
output. This can be performed by the glue rule, but
nevertheless, the use of empirically backed rules
allows the decoder to better compare hypotheses.
The derivation also rely less on the glue rules than
the hierarchical model (shown in solid rectangles).
Reducing the maximum number of non-
terminals per rule reduces translation quality but
increasing it has little effect on the soft syntax
model, Table 5. This seems to indicate that non-
terminals are useful as context when applying
rules up to a certain extent.
7.4 English to German
We experimented with the reverse language direc-
tion to see if the soft syntax model still increased
# non-terms % BLEU
2 16.5
3 16.8
5 16.8
Table 5: Effect on %BLEU of varying number of
non-terminals
# Model % BLEU
1 Hierarchical 10.2
2 Soft syntax 10.6
Table 6: English?German results in %BLEU
translation quality. The results were positive but
less pronounced, Table 6.
7.5 Using Chunk Tags
Parse trees of the source language provide use-
ful information that we have exploited to create a
better translation model. However, parsers are an
expensive resource as they frequently need manu-
ally annotated training treebanks. Parse accuracy
is also problematic and particularly brittle when
given sentences not in the same domain as the
training corpus. This also causes some sentences
to be unparseable. For example, our original test
corpus of 1026 sentences contained 35 unparsable
sentences. Thus, high quality parsers are unavail-
able for many source languages of interest.
Parse forests can be used to mitigate the accu-
racy problem, allowing the decoder to choose from
many alternative parses, (Mi et al, 2008).
The soft syntax translation model is not depen-
dent on the linguistic information being in a tree
structure, only that the labels identify contiguous
spans. Chunk taggers (Abney, 1991) does just
that. They offer higher accuracy than syntactic
parser, are not so brittle to out-of-domain data and
identify chunk phrases similar to parser-based syn-
tactic phrases that may be useful in guiding re-
ordering.
We apply the soft syntax approach as in the pre-
vious sections but replacing the use of parse con-
stituents with chunk phrases.
Figure 7: Chunked sentence
415
7.6 Experiments with Chunk Tags
We use the same data as described earlier in
this chapter to train, tune and test our approach.
The Treetagger chunker (Schmidt and Schulte im
Walde, 2000) was used to tag the source (German)
side of the corpus. The chunker successfully pro-
cessed all sentences in the training and test dataset
so no sentences were excluded. The increase train-
ing data, as well as the ability to translate all sen-
tences in the test set, explains the higher hierar-
chical baseline than the previous experiments with
parser data. We use the noun, verb and preposi-
tional chunks, as well as part-of-speech tags, emit-
ted by the chunker.
Results are shown in Table 2, line 5 & 6. Using
chunk tags, we see a modest gain of 0.5% BLEU.
The same example sentence in Table 4 is shown
with chunk tags in Figure 7. The soft syntax
model with chunk tags produced the derivation
tree shown in Figure 8. The derivation make use
of an unlexicalized rule local reordering. In this
example, it uses the same number of glue rule as
the hierarchical derivation but the output is gram-
matically correct.
Figure 8: Translated chunked sentence
However, overall, the number of glue rules used
shows the same reduction that we saw using soft
syntax in the earlier section, as can be seen in Fig-
ure 9. Again, the soft syntax model, this time us-
ing chunk tags, is able to reduce the use of the glue
rule with empirically informed rules.
8 Conclusion
We show in this paper that combining the gener-
ality of the hierarchical approach with the speci-
ficity of syntactic approach can improve transla-
Figure 9: Chunk - Length and count of glue rules
used decoding test set
tion. A reason for the improvement is the bet-
ter long-range reordering made possible by the in-
crease capacity of the translation model.
Future work in this direction includes us-
ing tree-to-tree approaches, automatically created
constituency labels, and back-off methods be-
tween decorated and undecorated rules.
9 Acknowledgement
This work was supported in part by the EuroMa-
trixPlus project funded by the European Commis-
sion (7th Framework Programme) and in part un-
der the GALE program of the Defense Advanced
Research Projects Agency, Contract No. HR0011-
06-C-0022.
References
Abney, S. (1991). Parsing by chunks. In Robert Berwick,
Steven Abney, and Carol Tenny: Principle-Based Parsing.
Kluwer Academic Publishers.
Ambati, V. and Lavie, A. (2008). Improving syntax driven
translation models by re-structuring divergent and non-
isomorphic parse tree structures. In AMTA.
Ambati, V., Lavie, A., and Carbonell, J. (2009). Extraction of
syntactic translation models from parallel data using syn-
tax from source and target languages. In MT Summit.
Chiang, D. (2005). A hierarchical phrase-based model for
statistical machine translation. In Proceedings of the 43rd
Annual Meeting of the Association for Computational Lin-
guistics (ACL?05), pages 263?270, Ann Arbor, Michigan.
Association for Computational Linguistics.
Chiang, D., Knight, K., and Wang, W. (2009). 11,001 new
features for statistical machine translation. In Proceedings
of Human Language Technologies: The 2009 Annual Con-
ference of the North American Chapter of the Association
for Computational Linguistics, pages 218?226, Boulder,
Colorado. Association for Computational Linguistics.
Chiang, D., Marton, Y., and Resnik, P. (2008). Online large-
margin training of syntactic and structural translation fea-
tures. In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages 224?
233, Honolulu, Hawaii. Association for Computational
Linguistics.
Dyer, C., Muresan, S., and Resnik, P. (2008). Generalizing
word lattice translation. In Proceedings of ACL-08: HLT,
pages 1012?1020, Columbus, Ohio. Association for Com-
putational Linguistics.
416
Foster, G., Kuhn, R., and Johnson, H. (2006). Phrasetable
smoothing for statistical machine translation. In Proceed-
ings of the 2006 Conference on Empirical Methods in Nat-
ural Language Processing, pages 53?61, Sydney, Aus-
tralia. Association for Computational Linguistics.
Galley, M., Graehl, J., Knight, K., Marcu, D., DeNeefe, S.,
Wang, W., and Thayer, I. (2006). Scalable inference and
training of context-rich syntactic translation models. In
Proceedings of the 21st International Conference on Com-
putational Linguistics and 44th Annual Meeting of the As-
sociation for Computational Linguistics, pages 961?968,
Sydney, Australia. Association for Computational Lin-
guistics.
Galley, M., Hopkins, M., Knight, K., and Marcu, D. (2004).
What?s in a translation rule? In Proceedings of the Joint
Conference on Human Language Technologies and the
Annual Meeting of the North American Chapter of the As-
sociation of Computational Linguistics (HLT-NAACL).
Hoang, H., Koehn, P., and Lopez, A. (2009). A Unified
Framework for Phrase-Based, Hierarchical, and Syntax-
Based Statistical Machine Translation. In Proc. of the
International Workshop on Spoken Language Translation,
pages 152?159, Tokyo, Japan.
Huang, L. and Chiang, D. (2008). Forest-based translation
rule extraction. In EMNLP, Honolulu, Hawaii.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C.,
Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst,
E. (2007). Moses: Open source toolkit for statistical ma-
chine translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster Ses-
sions, pages 177?180, Prague, Czech Republic. Associa-
tion for Computational Linguistics.
Li, Z., Callison-Burch, C., Dyer, C., Khudanpur, S.,
Schwartz, L., Thornton, W., Weese, J., and Zaidan, O.
(2009). Joshua: An open source toolkit for parsing-based
machine translation. In Proceedings of the Fourth Work-
shop on Statistical Machine Translation, pages 135?139,
Athens, Greece. Association for Computational Linguis-
tics.
Liu, Y., Mi, H., Feng, Y., and Liu, Q. (2009). Joint decod-
ing with multiple translation models. In In Proceedings of
ACL/IJCNLP 2009, pages 576?584, Singapore.
Marton, Y. and Resnik, P. (2008). Soft syntactic constraints
for hierarchical phrased-based translation. In Proceedings
of ACL-08: HLT, pages 1003?1011, Columbus, Ohio. As-
sociation for Computational Linguistics.
Mi, H., Huang, L., and Liu, Q. (2008). Forest-based trans-
lation. In Proceedings of ACL-08: HLT, pages 192?199,
Columbus, Ohio. Association for Computational Linguis-
tics.
Och, F. J. (2003). Minimum error rate training for statistical
machine translation. In Proceedings of the 41st Annual
Meeting of the Association of Computational Linguistics
(ACL).
Och, F. J. and Ney, H. (2003). A systematic comparison of
various statistical alignment models. Computational Lin-
guistics, 29(1):19?52.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2001).
BLEU: a method for automatic evaluation of machine
translation. Technical Report RC22176(W0109-022),
IBM Research Report.
Schmidt, H. and Schulte im Walde, S. (2000). Robust
German noun chunking with a probabilistic context-free
grammar. In Proceedings of the International Conference
on Computational Linguistics (COLING).
Shen, L., Xu, J., Zhang, B., Matsoukas, S., and Weischedel,
R. (2009). Effective use of linguistic and contextual infor-
mation for statistical machine translation. In Proceedings
of the 2009 Conference on Empirical Methods in Natural
Language Processing, pages 72?80, Singapore. Associa-
tion for Computational Linguistics.
Venugopal, A., Zollmann, A., Smith, N. A., and Vogel, S.
(2009). Preference grammars: Softening syntactic con-
straints to improve statistical machine translation. In Pro-
ceedings of Human Language Technologies: The 2009 An-
nual Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 236?244,
Boulder, Colorado. Association for Computational Lin-
guistics.
Zollmann, A. and Venugopal, A. (2006). Syntax augmented
machine translation via chart parsing. In Proceedings on
the Workshop on Statistical Machine Translation, pages
138?141, New York City. Association for Computational
Linguistics.
417
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 486?498,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
Augmenting String-to-Tree and Tree-to-String Translation with
Non-Syntactic Phrases
Matthias Huck and Hieu Hoang and Philipp Koehn
School of Informatics
University of Edinburgh
10 Crichton Street
Edinburgh EH8 9AB, UK
{mhuck,hhoang,pkoehn}@inf.ed.ac.uk
Abstract
We present an effective technique to easily
augment GHKM-style syntax-based ma-
chine translation systems (Galley et al.,
2006) with phrase pairs that do not comply
with any syntactic well-formedness con-
straints. Non-syntactic phrase pairs are
distinguished from syntactic ones in or-
der to avoid harming effects. We apply
our technique in state-of-the-art string-to-
tree and tree-to-string setups. For tree-to-
string translation, we furthermore investi-
gate novel approaches for translating with
source-syntax GHKM rules in association
with input tree constraints and input tree
features.
1 Introduction
Syntax-based statistical machine translation sys-
tems utilize linguistic information that is obtained
by parsing the training data. In tree-to-string
translation, source-side syntactic tree annotation is
employed, while string-to-tree translation exploits
target-side syntax. The syntactic parse tree an-
notation constrains phrase extraction to syntacti-
cally well-formed phrase pairs: spans of syntactic
phrases must match constituents in the parse tree.
Standard phrase-based and hierarchical phrase-
based statistical machine translation systems, in
contrast, allow all phrase pairs that are consistent
with the word alignment (Koehn et al., 2003; Chi-
ang, 2005).
A restriction of the phrase inventory to syntac-
tically well-formed phrase pairs entails that possi-
bly valuable information from the training data re-
mains disregarded. While we would expect phrase
pairs that are not linguistically motivated to be less
reliable, discarding them altogether might be an
overly harsh decision. The quality of an inventory
of syntactic phrases depends heavily on the tree
annotation scheme and the quality of the syntac-
tic parses of the training data. Phrase pairs that
do not span constituents in the tree annotation ob-
tained from syntactic parses can provide reason-
able alternative segmentations or alternative trans-
lation options which prove to be valuable to the
decoder.
In this work, we augment the phrase invento-
ries of string-to-tree and tree-to-string translation
systems with phrase pairs that are not induced in
the syntax-based extraction. We extract continu-
ous phrases that are consistent with the word align-
ment, without enforcing any constraints with re-
spect to syntactic tree annotation. Non-syntactic
phrases are added as rules to the baseline syntactic
grammar with a fill-up technique. New rules are
only added if their right-hand side does not exist
yet. We extend the glue grammar with a special
glue rule to allow for application of non-syntactic
phrases during decoding. A feature in the log-
linear model combination serves to distinguish
non-syntactic phrases from syntactic ones. During
decoding, the decoder can draw on both syntactic
and non-syntactic phrase table entries and produce
derivations which resort to both types of phrases.
Such derivations yield hypotheses that make use of
the alternative segmentations and translation op-
tions provided through non-syntactic phrases. The
search space is more diverse, and in some cases
all hypotheses from purely syntax-based deriva-
tions score worse than a translation that applies
one or more non-syntactic phrases. We empiri-
cally demonstrate that this technique can lead to
substantial gains in translation quality.
Our syntactic translation models conform to the
GHKM syntax approach as proposed by Galley,
Hopkins, Knight, and Marcu (Galley et al.,
2004) with composed rules as in (Galley et al.,
2006) and (DeNeefe et al., 2007). State-of-the-
art GHKM string-to-tree systems have recently
shown very competitive performance in public
486
evaluation campaigns (Nadejde et al., 2013; Bo-
jar et al., 2013). We apply the GHKM approach
not only in a string-to-tree setting as in previous
work, but employ it to build tree-to-string sys-
tems as well. We conduct tree-to-string translation
with text input and additionally adopt translation
with tree input and input tree constraints as sug-
gested for hierarchical translation by Hoang and
Koehn (2010). We also implement translation with
tree input and feature-driven soft tree matching.
The effect of augmenting the systems with non-
syntactic phrases is evaluated for all variants.
2 Outline
The remainder of the paper is structured as fol-
lows: We review some of the basics of syntax-
based translation in the next section (Section 3)
and sketch the characteristics of our GHKM
string-to-tree and tree-to-string translation frame-
works.
In Section 4, we describe our technique to
augment GHKM-style syntax-based systems with
phrase pairs that do not comply with any syntactic
well-formedness constraints.
Section 5 contains the empirical part of the pa-
per. We first describe our experimental setup (5.1),
followed by a presentation of the translation re-
sults (5.2). We also include a few translation ex-
amples (5.3) in order to illustrate the differences
between the syntax-based baseline systems and
the setups augmented with non-syntactic phrases.
The empirical part is concluded with a brief dis-
cussion (5.4).
In the final part of the paper (Section 6), we
give a survey of previous work that has dealt
with problems related to overly restrictive syntac-
tic grammars for statistical machine translation,
inadequate syntactic parses, and insufficient cov-
erage of syntactic phrase inventories. A broad
spectrum of diverse methods has been proposed in
the literature, many of which are quite dissimilar
from ours but nevertheless related. We conclude
the paper in Section 7.
3 Syntax-based Translation
In syntax-based translation, a probabilistic syn-
chronous context-free grammar (SCFG) is in-
duced from bilingual training corpora. The par-
allel training data is word-aligned and annotated
with syntactic parses on either target side (string-
to-tree), source side (tree-to-string), or both (tree-
to-tree). A syntactic phrase extraction procedure
extracts rules which are consistent with the word-
alignment and conform with certain syntactic va-
lidity constraints.
Extracted rules are of the form A,B???,? ,
?
?.
The right-hand side of the rule ??,? ? is a bilingual
phrase pair that may contain non-terminal sym-
bols, i.e. ? ? (V
F
? N
F
)
+
and ? ? (V
E
? N
E
)
+
,
where V
F
and V
E
denote the source and target
terminal vocabulary, and N
F
and N
E
denote the
source and target non-terminal vocabulary, respec-
tively. The non-terminals on the source side and
on the target side of rules are linked in a one-to-
one correspondence. The
?
relation defines this
one-to-one correspondence. The left-hand side
of the rule is a pair of source and target non-
terminals, A ? N
F
and B ? N
E
.
Decoding is typically carried out with a parsing-
based algorithm, in our case a customized version
of CYK
+
(Chappelier and Rajman, 1998). The
parsing algorithm is extended to handle transla-
tion candidates and to incorporate language model
scores via cube pruning (Chiang, 2007).
3.1 GHKM String-to-Tree Translation
In GHKM string-to-tree translation (Galley et al.,
2004; Galley et al., 2006; DeNeefe et al., 2007),
rules are extracted from training instances which
consist of a source sentence, a target sentence
along with its constituent parse tree, and a word
alignment matrix. This tuple is interpreted as a
directed graph (the alignment graph), with edges
pointing away from the root of the tree, and word
alignment links being edges as well. A set of
nodes (the frontier set) is determined that con-
tains only nodes with non-overlapping closure of
their spans.
1
By computing frontier graph frag-
ments?fragments of the alignment graph such
that their root and all sinks are in the frontier set?
the GHKM extractor is able to induce a minimal
set of rules which explain the training instance.
The internal tree structure can be discarded to ob-
tain flat SCFG rules. Minimal rules can be assem-
bled to build larger composed rules.
Non-terminals on target sides of string-to-tree
rules are syntactified. The target non-terminal vo-
cabulary of the SCFG contains the set of labels
of the frontier nodes, which is in turn a subset
1
The span of a node in the alignment graph is defined
as the set of source-side words that are reachable from this
node. The closure of a span is the smallest interval of source
sentence positions that covers the span.
487
TOP
PUNC.
.
CS-TOP
S-TOP
NP-OA
NN
Autonomie
ADJA
politische
ART
die
ADV
auch
VMFIN
wollten
NP-SB
PPER
sie
PUNC,
,
S-TOP
ADV
. . .leider
unfortunately , . . . , they also wanted political autonomy .
Figure 1: Word-aligned training sentence pair with target-side syntactic annotation.
of (or equal to) the set of constituent labels in
the parse tree. It furthermore contains an initial
non-terminal symbol Q. Source sides of the rules
are not decorated with syntactic annotation. The
source non-terminal vocabulary contains a single
generic non-terminal symbol X.
In addition to the extracted grammar, the trans-
lation system makes use of a special glue grammar
with an initial rule, glue rules, a final rule, and top
rules. The glue rules provide a fall back method
to just monotonically concatenate partial deriva-
tions during decoding. As we add tokens which
mark the sentence start (?<s>?) and the sentence
end (?</s>?), the rules in the glue grammar are of
the following form:
Initial rule:
X,Q? ?<s> X
?0
,<s> Q
?0
?
Glue rules:
X,Q? ?X
?0
X
?1
,Q
?0
B
?1
?
for all B ? N
E
Final rule:
X,Q? ?X
?0
</s>,Q
?0
</s>?
Top rules:
X,Q? ?<s> X
?0
</s>,<s> B
?0
</s>?
for all B ? N
E
3.2 GHKM Tree-to-String Translation
The described techniques for GHKM string-to-
tree translation can be adjusted for tree-to-string
translation in a straightforward manner. Rules are
extracted from training instances which consist of
a source sentence along with its constituent parse
tree, a target sentence, and a word alignment ma-
trix. We omit the details.
For GHKM tree-to-string translation, we inves-
tigate three decoding variants:
Tree-to-string translation with text input. The
decoder can construct any source-side syn-
tactic analysis that the grammar permits, very
similar to string-to-tree translation.
Tree-to-string translation with tree input and
input tree constraints. Syntactic annotation
over the input data is provided to the decoder.
The source-side syntactic non-terminals of a
tree-to-string translation rule need to match
the constituent span in the input sentence,
otherwise the rule cannot be applied. This
variant follows the method that was sug-
gested for hierarchical translation by Hoang
and Koehn (2010).
Tree-to-string translation with tree input and
input tree features. Syntactic annotation
over the input data is provided to the decoder.
No hard matching constraints are imposed,
but the decoder is informed about matches
and mismatches of the syntactic annotation in
the rules and in the input tree. It takes them
into account for the score computation.
4 Non-Syntactic Phrases for GHKM
Translation
The syntactic constraints in GHKM extraction can
unfortunately prevent useful phrase pairs from be-
ing included in the phrase inventory. Consider the
example in Figure 1: the highlighted phrase pair
?also wanted,wollten auch? cannot be extracted
from this training instance for string-to-tree trans-
lation.
488
In the standard phrase-based approach, in con-
trast, all continuous phrases that are consistent
with the word alignment are extracted (Och et al.,
1999; Och, 2002). The set of continuous bilingual
phrases BP( f
J
1
,e
I
1
,A), given a training instance
comprising a source sentence f
J
1
, a target sentence
e
I
1
, and a word alignment A?{1, ..., I}?{1, ...,J},
is defined as follows:
BP( f
J
1
,e
I
1
,A) =
{
? f
j
2
j
1
,e
i
2
i
1
? : ?(i, j) ? A : i
1
? i? i
2
? j
1
? j ? j
2
??(i, j) ? A : i
1
? i? i
2
? j
1
? j ? j
2
}
Consistency for continuous phrases is based upon
merely two constraints in this definition: (1.) At
least one source and target position within the
phrase must be aligned, and (2.) words from inside
the source phrase may only be aligned to words
from inside the target phrase and vice versa. The
highlighted phrase pair from the example does not
violate these constraints.
In order to augment our GHKM syntax-based
systems with non-syntactic phrases, we obey the
following procedure:
? The setBP is extracted from all training in-
stances, and phrase translation probabilities
are computed separately from those in the
syntactic phrase inventory.
? Non-syntactic phrases are converted to rules
by providing a special left-hand side non-
terminal X.
? A phrase table fill-up method is applied to
enhance the syntactic phrase inventory with
entries from the non-syntactic phrase inven-
tory. Non-syntactic rules are only added to
the final grammar if no syntactic rule with
the same (source and target) right-hand side
is present. This method is inspired by pre-
vious work in domain adaptation (Bisazza et
al., 2011).
? The glue grammar is extended with a new
glue rule
X,Q? ?X
?0
X
?1
,Q
?0
X
?1
?
that enables the system to make use of non-
syntactic rules in decoding.
? A binary feature is added to the log-linear
model (Och and Ney, 2002) to distinguish
non-syntactic rules from syntactic ones, and
to be able to assign a tuned weight to the non-
syntactic part of the grammar.
5 Empirical Evaluation
We evaluate the effect of augmenting GHKM
syntax-based translation systems?both string-to-
tree and tree-to-string?with non-syntactic phrase
pairs on the English?German language pair using
the standard newstest sets of the Workshop on Sta-
tistical Machine Translation (WMT) for testing.
2
The experiments are conducted with the open-
source Moses implementations of GHKM rule ex-
traction (Williams and Koehn, 2012) and decoding
with CYK
+
parsing and cube pruning (Hoang et al.,
2009).
5.1 Experimental Setup
We work with an English?German parallel train-
ing corpus of around 4.5 M sentence pairs (af-
ter corpus cleaning). The parallel data origi-
nates from three different sources which have
been eligible for the constrained track of the
ACL 2014 Ninth Workshop on Statistical Ma-
chine Translation shared translation task: Europarl
(Koehn, 2005), News Commentary, and the Com-
mon Crawl corpus as provided on the WMT web-
site. Word alignments are created by aligning the
data in both directions with MGIZA
++
(Gao and
Vogel, 2008) and symmetrizing the two trained
alignments (Och and Ney, 2003; Koehn et al.,
2003). For string-to-tree translation, we parse the
German target side with BitPar (Schmid, 2004).
3
For tree-to-string translation, we parse the English
source side of the parallel data with the English
Berkeley Parser (Petrov et al., 2006).
When extracting syntactic phrases, we impose
several restrictions for composed rules, in partic-
ular a maximum number of twenty tree nodes per
rule, a maximum depth of five, and a maximum
size of five. We discard rules with non-terminals
on their right-hand side if they are singletons in the
training data.
Only the 100 best translation options per dis-
tinct source side with respect to the weighted
phrase-level model scores are loaded by the de-
coder. The decoder is configured with a maximum
chart span of 25 and a rule limit of 100.
A standard set of models is used in the base-
lines, comprising phrase translation probabilities
and lexical translation probabilities in both direc-
2
http://www.statmt.org/wmt14/
translation-task.html
3
We remove grammatical case and function information
from the annotation obtained with BitPar.
489
system dev newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
phrase-based 33.0 48.8 18.8 64.5 18.2 66.9
+ lexicalized reordering 34.2 48.1 19.2 64.5 18.3 67.1
string-to-string (syntax-directed extraction) 32.6 49.4 18.2
}
+0.5
65.4
}
?0.4
17.8
}
+0.5
68.0
}
?0.4
+ non-syntactic phrases 33.4 49.0 18.7 65.0 18.3 67.6
string-to-tree 33.6 48.7 19.5
}
+0.3
63.9
}
?0.3
18.6
}
+0.5
66.9
}
?0.7
+ non-syntactic phrases 34.3 48.0 19.8 63.6 19.1 66.2
tree-to-string 34.0 48.5 19.5
}
?0.2
63.8
}
+0.2
18.5
}
+0.2
67.0
}
?0.4
+ non-syntactic phrases 33.9 48.4 19.3 64.0 18.7 66.6
+ input tree constraints 33.7 48.4 19.3
}
+0.4
63.9
}
?0.3
18.3
}
+0.3
67.0
}
?0.5
+ non-syntactic phrases 34.2 48.2 19.7 63.6 18.7 66.5
+ input tree features 34.3 48.3 19.6
}
+0.3
63.7
}
?0.3
18.6
}
+0.2
67.0
}
?0.5
+ non-syntactic phrases 34.4 48.1 19.9 63.4 18.8 66.5
Table 1: English?German experimental results (truecase). BLEU scores are given in percentage.
tions, word and phrase penalty, an n-gram lan-
guage model, a rule rareness penalty, and the
monolingual PCFG probability of the tree frag-
ment from which the rule was extracted (Williams
et al., 2014). Phrase translation probabilities are
smoothed via Good-Turing smoothing.
The language model (LM) is a large inter-
polated 5-gram LM with modified Kneser-Ney
smoothing (Kneser and Ney, 1995; Chen and
Goodman, 1998). The target side of the parallel
corpus and the monolingual German News Crawl
corpora are employed as training data. We use
the SRILM toolkit (Stolcke, 2002) to train the LM
and rely on KenLM (Heafield, 2011) for language
model scoring during decoding.
Model weights are optimized to maximize
BLEU (Papineni et al., 2002) with batch MIRA
(Cherry and Foster, 2012) on 1000-best lists. We
selected 2000 sentences from the newstest2008-
2012 sets as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and do each contain less than
30 words for more rapid tuning. newstest2013 and
newstest2014 are used as unseen test sets. Trans-
lation quality is measured in truecase with BLEU
and TER (Snover et al., 2006).
4
We apply a phrase length limit of five when
extracting non-syntactic phrases for the fill-up of
syntactic phrase tables.
4
TER scores are computed with tercom version 0.7.25
and parameters -N -s.
5.2 Translation Results
Table 1 comprises the results of our empirical eval-
uation of the translation quality achieved by the
different systems.
5.2.1 Phrase-based Baselines
We set up two phrase-based baselines for com-
parison. Their set of models is the same as for
the syntax-based baselines, with the exception of
the PCFG probability. One of the phrase-based
systems moreover utilizes a lexicalized reorder-
ing model (Galley and Manning, 2008). No non-
standard advanced features (like an operation se-
quence model or class-based LMs) are engrafted.
The maximum phrase length is five, search is car-
ried out with cube pruning at a k-best limit of
1000. A maximum number of 100 translation op-
tions per source side are taken into account.
5.2.2 String-to-String Contrastive System
A further contrastive experiment is done with a
string-to-string system. The extraction method
for this string-to-string system is GHKM syntax-
directed with syntactic target-side annotation from
BitPar, as in the string-to-tree setup. We actually
extract the same rules but strip off the syntactic la-
bels. The final grammar contains rules with a sin-
gle generic non-terminal instead of syntactic ones.
Note that a side effect of this is that the phrase
inventory of the string-to-string system contains
490
a larger amount of hierarchical phrases
5
than the
string-to-tree system, though the same rules are
extracted. The reason is that we discard single-
ton hierarchical rules when we normalize the fre-
quencies after extraction. Many rules that are sin-
gletons when the syntax decoration is taken into
account have in fact been seen multiple times if
syntactic labels are not distinguished, due to pool-
ing of counts.
The string-to-string system is on newstest2013
1.0 points BLEU worse than the phrase-based
system with lexicalized reordering and on news-
test2014 0.5 points BLEU. We gain 0.5 points
BLEU on both of the test sets if we augment the
string-to-string system with non-syntactic phrases
from the standard phrase-based extractor accord-
ing to our procedure from Section 4.
5.2.3 String-to-Tree System
The translation quality of the string-to-tree sys-
tem surpasses the translation quality of the bet-
ter phrase-based baseline slightly (by 0.3 points
BLEU on both test sets). The string-to-tree system
is clearly superior to the string-to-string system,
which verifies that syntactic non-terminals are in-
deed vital. We get a nice gain of 0.5 points BLEU
and 0.7 points TER on newstest2014 if we aug-
ment the string-to-tree system with non-syntactic
phrases. The phrase-based system is outperformed
by 0.8 points BLEU.
5.2.4 Tree-to-String Systems
The tree-to-string baseline with text input per-
forms at the level of the string-to-tree baseline, but
augmenting it with non-syntactic phrases yields
only a small improvement or even harms a little
(on newstest2013).
Decoding with tree input and input tree con-
straints causes a minor loss in translation qual-
ity. We however observed a decoding speed-up. If
we employ non-syntactic phrases to augment the
tree-to-string setup with input tree constraints, we
provide the new non-syntactic rules in the gram-
mar with a particular property: their left-hand side
non-terminal X can match any constituent span in
the input sentence. The decoder would not be
able to utilize non-syntactic phrases without this
relaxation. Syntactic phrases amount to an in-
crease of up to 0.4 points BLEU (newstest2013)
5
We define hierarchical phrases as rules with non-
terminals on their right-hand side, in contrast to lexical
phrases which are continuous rules with right-hand sides that
contain terminal symbols only.
and 0.5 points TER (newstest2014) in the tree-
constrained setup.
Our best tree-to-string setup takes tree input, but
involves soft matching features instead of hard in-
put tree constraints. We incorporate two features,
one that fires for matches and another one that fires
for mismatches. The motivation for not relying on
just one feature which would penalize mismatches
is that the number of syntactic non-terminals in
the derivation can differ between hypotheses. Not
all constituent spans need to be matched (or mis-
matched) by non-terminals, some can be over-
laid through larger rules.
6
Tree-to-string transla-
tion with input tree features benefits from being
augmented with non-syntactic phrases by 0.2 to
0.3 points BLEU. The resulting system is mini-
mally better than the best string-to-tree system on
newstest2013, and slightly worse than it on news-
test2014.
5.3 Translation Examples
We illustrate the differences between the syntax-
based baseline systems and the setups augmented
with non-syntactic phrases by means of two trans-
lation examples from newstest2014. Both exam-
ples are string-to-tree translations.
Figures 2 and 3 depict an example that cor-
responds well to the word-aligned training sen-
tence pair with target-side syntactic annotation
from Figure 1. Figure 2 shows the translation, seg-
mentation, and parse tree derived by the string-
to-tree baseline system as single-best output for
the preprocessed input sentence: ?the lessees were
against this and also wanted longer terms .? The
reference translation is: ?Die P?chter waren dage-
gen und wollten zudem l?ngere Laufzeiten.? Fig-
ure 3 shows the translation, segmentation, and
parse tree derived by the string-to-tree system aug-
mented with non-syntactic phrases. There are
two word substitutions with respect to the ref-
erence in the latter translation, but they convey
the same meaning. The baseline translation fails
to convey the meaning, mostly because ?terms?
is translated to the verb ?gesehen?, which is a
wrong syntactic analysis in the given context. In-
terestingly, the segmentation applied by the two
systems is rather similar, apart from the interval
?also wanted? which cannot be translated en bloc
by the baseline. All rules in the baseline gram-
6
Also remember that we discarded the internal tree struc-
ture to obtain flat SCFG rules.
491
Q</s>
Q
TOP
.
VP-OC
VVPP
gesehenmehr
ADV
auch
VMFIN
wollteund
S-TOP
dagegen
VAFIN
waren
NP-SB
Mieter
Q
ART
die
Q
<s>
<s> the lessees were against this and also wanted longer terms . </s>
Reference: Die P?chter waren dagegen und wollten zudem l?ngere Laufzeiten.
Figure 2: Translation and parse tree from the string-to-tree system.
Q
</s>
Q
PUNC.
.
Q
NP-OA
NN
Laufzeitenl?ngere
Q
X
auchwollten
Q
KON
und
Q
S-TOP
dagegen
VAFIN
waren
NP-SB
Mieter
Q
ART
die
Q
<s>
<s> the lessees were against this and also wanted longer terms . </s>
Reference: Die P?chter waren dagegen und wollten zudem l?ngere Laufzeiten.
Figure 3: Translation and parse tree from the string-to-tree system augmented with non-syntactic phrases.
mar that contain ?also wanted? as part of their
source side imply a larger source-side lexical con-
text that is not present in the given sentence. None
of those rules matches the input. The baseline
has to translate ?also? and ?wanted? separately
and fails to translate the verb to a plural form
German verb. The next rule in bottom-up order
is already involved in the incorrect choice of a
verb for ?terms?. The string-to-tree system aug-
mented with non-syntactic phrases applies more
glue rules, but this is beneficial in the present
example, as it breaks apart the faulty syntactic
derivation.
Figures 4 and 5 depict a second example. Com-
pared to the baseline, filling up the phrase table
with non-syntactic phrases had the effect of disas-
sembling the originally nicely built syntactic tree
structure over the translation nearly completely.
Four non-syntactic phrases are applied, three of
them span over target-side punctuation marks. The
baseline translation is more literal and conveys
the meaning, but the system augmented with non-
syntactic phrases produces a more fluent output.
Its translation seems more natural and happens to
match the reference in this case.
492
Q</s>
TOP
.
S-TOP
AP-PD
beeindruckendist,
NP-SB
S-RC
VVFIN
spielt
NP-SB
Teamdasderin,WeiseundArtdie,
S-TOP
allenvon
AA-MO
meistenam<s>
<s> most of all , the manner in which the team is playing is impressive . </s>
Reference: Vor allem die Art und Weise, wie die Mannschaft spielt, ist beeindruckend.
Figure 4: Translation and parse tree from the string-to-tree system.
Q
</s>
Q
X
.beeindruckendist
Q
X
,spielt
Q
NP-SB
Mannschaftdie
Q
X
wie,WeiseundArt
Q
ART
die
Q
X
allemvor
Q
<s>
<s> most of all , the manner in which the team is playing is impressive . </s>
Reference: Vor allem die Art und Weise, wie die Mannschaft spielt, ist beeindruckend.
Figure 5: Translation and parse tree from the string-to-tree system augmented with non-syntactic phrases.
phrase table entries unfiltered dev newstest2013 newstest2014
hier. lexical hier. lexical hier. lexical hier. lexical
phrase-based ? 184.9 M ? 25.3 M ? 29.0 M ? 28.0 M
string-to-string 58.3 M 19.9 M 4.3 M 2.9 M 5.7 M 3.3 M 5.3 M 3.3 M
+ non-syntactic phrases 58.3 M 191.1 M 4.3. M 25.4 M 5.7 M 29.1 M 5.3 M 28.1 M
string-to-tree 39.7 M 21.2 M 4.9 M 3.4 M 5.7 M 3.8 M 5.5 M 3.7 M
+ non-syntactic phrases 39.7 M 192.4 M 4.9 M 25.8 M 5.7 M 29.6 M 5.5 M 28.6 M
tree-to-string 29.5 M 21.1 M 7.7 M 2.8 M 9.0 M 3.3 M 8.7 M 3.2 M
+ non-syntactic phrases 29.5 M 192.6 M 7.7 M 26.1 M 9.0 M 29.9 M 8.7 M 28.9 M
Table 2: Phrase inventory statistics for the different English?German translation systems. ?hier.? de-
notes hierarchical phrases, i.e. rules with non-terminals on their right-hand side, ?lexical? denotes con-
tinuous phrases.
493
5.4 Discussion
A drawback of our method is that it increases
the size of the synchronous context-free gram-
mar massively. Most phrase pairs from standard
phrase-based extraction are actually not present in
the GHKM rule set, even with composed rules.
A large fraction of the extracted non-syntactic
phrases is such added to the phrase inventory
through phrase table fill-up. Table 2 shows the
phrase inventory statistics for the different sys-
tems.
Another question relates to the glue rule appli-
cations. The application of a non-syntactic rule
is always accompanied with a respective glue rule
application in our implementation. The string-
to-tree baseline utilizes glue rules on average 3.0
times in each single-best translation (measured
on newstest2014), the string-to-tree system aug-
mented with non-syntactic phrases utilizes glue
rules on average 7.0 times. We considered an im-
plementation that allows for embedding of non-
syntactic rules into hierarchical rules (other than
the glue rules) but did not see improvements with
it as yet. Furthermore, efficiency concerns become
more relevant in such an implementation.
6 Related Work
Issues with overly restrictive syntactic grammars
for statistical machine translation, inadequate syn-
tactic parses, and insufficient coverage have been
tackled from several different directions in the lit-
erature.
A proposed approach to attain better syntac-
tic phrase inventories is to restructure the syntac-
tic parse trees in a preprocessing step (Wang et
al., 2007; Wang et al., 2010; Burkett and Klein,
2012). This line of research aims at rearranging
parse trees in a way that makes them a better fit
for the requirements of the bilingual downstream
application. Conversely, Fossum et al. (2008) re-
tain the structure of the parse trees and modify the
word alignments.
Marcu et al. (2006) relax syntactic phrase ex-
traction constraints in their SPMT Model 2 to al-
low for phrases that do not match the span of one
single constituent in the parse tree. SPMT Model 2
rules are created from spans that are consistent
with the word alignment and covered by multiple
constituents such that the union of the constituents
matches the span. Pseudo non-syntactic non-
terminals are introduced for the left-hand sides of
SPMT Model 2 rules. Special additional rules al-
low for combination of those non-syntactic left-
hand side non-terminals with genuine syntactic
non-terminals on the right-hand sides of other
rules during decoding.
Another line of research took the hierarchical
phrase-based model (Chiang, 2005; Chiang, 2007)
as a starting point and extended it with syntactic
enhancements. In their SAMT system, Zollmann
and Venugopal (2006) labeled the non-terminals
of the hierarchical model with composite symbols
derived from the syntactic tree annotation. Similar
methods have been applied with CCG labels (Al-
maghout et al., 2012). Venugopal et al. (2009)
and Stein et al. (2010) keep the grammar of the
non-terminals of the hierarchical model unlabeled
and apply the syntactic information in a separate
model. Other authors added features which fire
for phrases complying with certain syntactic prop-
erties while retaining all phrase pairs of the hier-
archical model (Marton and Resnik, 2008; Vilar et
al., 2008).
In a tree-to-tree translation setting, Chiang
(2010) proposed techniques to soften the syntac-
tic constraints. A fuzzy approach with complex
non-terminal symbols as in SAMT is employed
to overcome the limitations during phrase extrac-
tion. In decoding, substitutions of non-terminals
are not restricted to matching ones. Any left-
hand side non-terminal can substitute any right-
hand side non-terminal. The decoder decides on
the best derivation based on the tuned weights of a
large number of binary features.
Joining phrase inventories that come from mul-
tiple origins is a common method in domain adap-
tation (Bertoldi and Federico, 2009; Niehues and
Waibel, 2012) but has also been applied in the
contexts of lightly-supervised training (Schwenk,
2008; Huck et al., 2011) and of forced alignment
training (Wuebker et al., 2010). For our purposes,
we apply a fill-up method in the manner of the one
that has been shown to perform well for domain
adaptation in earlier work (Bisazza et al., 2011).
Previous research that resembles our work most
has been presented by Liu et al. (2006) and by
Hanneman and Lavie (2009).
Liu et al. (2006) allow for application of non-
syntactic phrase pairs in their tree-to-string align-
ment template (TAT) system. The translation
probabilities for the non-syntactic phrases are ob-
tained from a standard phrase-based extraction
494
pipeline. A non-syntactic phrase pair can how-
ever only be applied if its source side matches
a subtree in the parsed input sentence. Syn-
tactic and non-syntactic phrases are not distin-
guished, and overlap between the syntactic and
non-syntactic part of the phrase inventory is not
avoided. The decoder picks the entry with the
higher phrase translation probability, which means
that non-syntactic phrase table entries can super-
sede syntactic entries. The authors report im-
provements of 0.6 points BLEU on the 2005 NIST
Chinese?English task with four reference trans-
lations.
Hanneman and Lavie (2009) examine non-
syntactic phrases for tree-to-tree translation with
the Stat-XFER framework as developed at
Carnegie Mellon University (Lavie, 2008). They
combine syntactic and non-syntactic phrase in-
ventories and reestimate the probabilities for both
types of phrase pairs by adding up the observed
absolute frequencies. Two combination schemes
are evaluated: combination with all extractable
valid non-syntactic phrases (?direct combination?)
and combination with only those non-syntactic
phrases whose source sides are not equal to the
source side of any syntactic phrase (?syntax-
prioritized combination?). On a French?English
translation task, Hanneman and Lavie (2009) re-
port improvements of around 2.6 points BLEU by
adding non-syntactic phrases on top of their Stat-
XFER syntactic baselines. Their best setup how-
ever does not reach the performance of a stan-
dard phrase-based system, which is still 1.6 points
BLEU better.
Apart from the differences in the underly-
ing syntax-based translation technology (string-
to-tree/tree-to-string GHKM vs. TAT vs. Stat-
XFER), our work also constitutes a novel contri-
bution as compared to the previous approaches by
Liu et al. (2006) and Hanneman and Lavie (2009)
with respect to the following:
? The phrase inventory is augmented with non-
syntactic phrases by means of a fill-up tech-
nique. Overlap is prevented, whereas not
only new source sides, but also new target-
side translation options can be added.
? The probabilities of syntactic phrase pairs are
the same as in the syntax-based baseline, and
the probabilities of the non-syntactic phrase
pairs are the same as in a phrase-based sys-
tem. Counts of syntactic and non-syntactic
phrases are not summed up to obtain new es-
timates.
? Non-syntactic phrase pairs are distinguished
from syntactic ones with an additional fea-
ture.
7 Conclusions
String-to-tree and tree-to-string translation sys-
tems can easily be augmented with non-syntactic
phrases by means of phrase table fill-up, a special
non-terminal symbol for left-hand sides of non-
syntactic rules in the grammar, and an additional
glue rule. A binary feature enables the system to
distinguish non-syntactic phrases from syntactic
ones and?on the basis of the respective feature
weight?to favor syntactically motivated phrases
during decoding.
Our results on an English?German translation
task demonstrate the beneficial effect of augment-
ing GHKM translation systems with non-syntactic
phrase pairs. Empirical gains in translation qual-
ity are up to 0.5 points BLEU and 0.7 points TER
over the baseline on the recent test set of the shared
translation task of the ACL 2014 Ninth Workshop
on Statistical Machine Translation.
While GHKM-style syntactic translation has
typically been utilized in string-to-tree settings in
previous research, we have also adopted it to build
tree-to-string systems in this work. Source syn-
tax establishes interesting further directions for
GHKM systems. We investigated two of them: in-
put tree constraints and input tree features.
String-to-tree and tree-to-string GHKM sys-
tems perform roughly at the same level in terms
of translation quality. Our best string-to-tree
setup outperforms a phrase-based baseline by up
to 0.8 points BLEU and 0.9 points TER (on
newstest2014), our best tree-to-string setup out-
performs the phrase-based baseline by up to
0.7 points BLEU and 1.1 points TER (on news-
test2013).
Acknowledgements
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreements n
o
287658 (EU-BRIDGE)
and n
o
288487 (MosesCore).
495
References
Hala Almaghout, Jie Jiang, and Andy Way. 2012. Ex-
tending CCG-based Syntactic Constraints in Hierar-
chical Phrase-Based SMT. In Proc. of the Annual
Conf. of the European Assoc. for Machine Transla-
tion (EAMT), pages 193?200, Trento, Italy, May.
Nicola Bertoldi and Marcello Federico. 2009. Domain
Adaptation for Statistical Machine Translation with
Monolingual Resources. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
182?189, Athens, Greece, March.
Arianna Bisazza, Nick Ruiz, and Marcello Federico.
2011. Fill-up versus Interpolation Methods for
Phrase-based SMT Adaptation. In Proc. of the
Int. Workshop on Spoken Language Translation
(IWSLT), pages 136?143, San Francisco, CA, USA,
December.
Ond?rej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut,
and Lucia Specia. 2013. Findings of the 2013
Workshop on Statistical Machine Translation. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 1?44, Sofia, Bulgaria, August.
David Burkett and Dan Klein. 2012. Transforming
Trees to Improve Syntactic Convergence. In Proc.
of the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), Jeju Island, South Ko-
rea, July.
Jean-C?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, USA, August.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proc. of the Human Language Technology Conf. /
North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 427?436,
Montr?al, Canada, June.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 263?270, Ann Ar-
bor, MI, USA, June.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228, June.
David Chiang. 2010. Learning to Translate with
Source and Target Syntax. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 1443?1452, Uppsala, Sweden, July.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What Can Syntax-Based MT Learn
from Phrase-Based MT? In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 755?763,
Prague, Czech Republic, June.
Victoria Fossum, Kevin Knight, and Steven Abney.
2008. Using Syntax to Improve Word Alignment
Precision for Syntax-Based Machine Translation. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 44?52, Columbus, OH, USA,
June.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proc. of the Conf. on Empirical Meth-
ods for Natural Language Processing (EMNLP),
pages 847?855, Honolulu, HI, USA, October.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st International Conf. on Computa-
tional Linguistics and 44th Annual Meeting of the
Assoc. for Computational Linguistics, pages 961?
968, Sydney, Australia, July.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Columbus, OH, USA, June.
Greg Hanneman and Alon Lavie. 2009. Decoding with
Syntactic and Non-syntactic Phrases in a Syntax-
based Machine Translation System. In Proceedings
of the Third Workshop on Syntax and Structure in
Statistical Translation, SSST ?09, pages 1?9, Boul-
der, CO, USA, June.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
187?197, Edinburgh, Scotland, UK, July.
Hieu Hoang and Philipp Koehn. 2010. Improved
Translation with Source Syntax Labels. In Proc. of
the Workshop on Statistical Machine Translation
(WMT), pages 409?417, Uppsala, Sweden, July.
496
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. In Proc. of the Int. Workshop on Spoken Lan-
guage Translation (IWSLT), pages 152?159, Tokyo,
Japan, December.
Matthias Huck, David Vilar, Daniel Stein, and Her-
mann Ney. 2011. Lightly-Supervised Training for
Hierarchical Phrase-Based Machine Translation. In
Proc. of the EMNLP 2011 Workshop on Unsuper-
vised Learning in NLP, pages 91?96, Edinburgh,
Scotland, UK, July.
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-gram Language Model-
ing. In Proceedings of the International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 181?184, Detroit, MI, USA, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmon-
ton, Canada, May/June.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of the MT
Summit X, Phuket, Thailand, September.
Alon Lavie. 2008. Stat-XFER: A General
Search-Based Syntax-Driven Framework for Ma-
chine Translation. In Alexander Gelbukh, editor,
Computational Linguistics and Intelligent Text Pro-
cessing, volume 4919 of Lecture Notes in Computer
Science, pages 362?375. Springer Berlin Heidel-
berg.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string Alignment Template for Statistical Machine
Translation. In Proc. of the 21st International Conf.
on Computational Linguistics and the 44th Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 609?616, Sydney, Australia, July.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proc. of the Conf. on Empirical Methods
for Natural Language Processing (EMNLP), pages
44?52, Sydney, Australia.
Yuval Marton and Philip Resnik. 2008. Soft Syn-
tactic Constraints for Hierarchical Phrased-Based
Translation. In Proc. of the Annual Meeting of the
Assoc. for Computational Linguistics (ACL), pages
1003?1011, Columbus, OH, USA, June.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s Syntax-Based Machine Transla-
tion Systems. In Proc. of the Workshop on Statistical
Machine Translation (WMT), pages 170?176, Sofia,
Bulgaria, August.
Jan Niehues and Alex Waibel. 2012. Detailed Analy-
sis of Different Strategies for Phrase Table Adapta-
tion in SMT. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), San
Diego, CA, USA, October/November.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive Training and Maximum Entropy Models for Sta-
tistical Machine Translation. In Proc. of the Annual
Meeting of the Assoc. for Computational Linguistics
(ACL), pages 295?302, Philadelphia, PA, USA, July.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved Alignment Models for
Statistical Machine Translation. In Proc. of the
Joint SIGDAT Conf. on Empirical Methods in Nat-
ural Language Processing and Very Large Corpora
(EMNLP99), pages 20?28, University of Maryland,
College Park, MD, USA, June.
Franz Josef Och. 2002. Statistical Machine Transla-
tion: From Single-Word Models to Alignment Tem-
plates. Ph.D. thesis, RWTH Aachen University,
Aachen, Germany, October.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. of the
Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 311?318, Philadelphia, PA,
USA, July.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 433?440, Sydney,
Australia, July.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Holger Schwenk. 2008. Investigations on Large-Scale
Lightly-Supervised Training for Statistical Machine
Translation. In Proc. of the Int. Workshop on Spo-
ken Language Translation (IWSLT), pages 182?189,
Waikiki, HI, USA, October.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), pages
223?231, Cambridge, MA, USA, August.
497
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Proc.
of the Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), Denver, CO, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Hu-
man Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), pages 236?244, Boulder, CO, USA,
June.
David Vilar, Daniel Stein, and Hermann Ney. 2008.
Analysing Soft Syntax Features and Heuristics for
Hierarchical Phrase Based Machine Translation. In
Proc. of the Int. Workshop on Spoken Language
Translation (IWSLT), pages 190?197, Waikiki, HI,
USA, October.
Wei Wang, Kevin Knight, and Daniel Marcu. 2007.
Binarizing Syntax Trees to Improve Syntax-Based
Machine Translation Accuracy. In Proceedings
of the 2007 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 746?754, Prague, Czech Republic,
June.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, Re-labeling, and
Re-aligning for Syntax-based Machine Translation.
Computational Linguistics, 36(2):247?277, June.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 388?394, Montr?al, Canada,
June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proc. of the Workshop on Statistical
Machine Translation (WMT), Baltimore, MD, USA,
June.
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training Phrase Translation Models with
Leaving-One-Out. In Proc. of the Annual Meeting
of the Assoc. for Computational Linguistics (ACL),
pages 475?484, Uppsala, Sweden, July.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax Augmented Machine Translation via Chart Pars-
ing. In Proc. of the Workshop on Statistical Machine
Translation (WMT), pages 138?141, New York City,
NY, USA, June.
498
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 148?156,
October 25, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Preference Grammars and Soft Syntactic Constraints
for GHKM Syntax-based Statistical Machine Translation
Matthias Huck and Hieu Hoang and Philipp Koehn
School of Informatics
University of Edinburgh
10 Crichton Street
Edinburgh EH8 9AB, UK
{mhuck,hhoang,pkoehn}@inf.ed.ac.uk
Abstract
In this work, we investigate the effec-
tiveness of two techniques for a feature-
based integration of syntactic information
into GHKM string-to-tree statistical ma-
chine translation (Galley et al., 2004):
(1.) Preference grammars on the tar-
get language side promote syntactic well-
formedness during decoding while also al-
lowing for derivations that are not linguis-
tically motivated (as in hierarchical trans-
lation). (2.) Soft syntactic constraints aug-
ment the system with additional source-
side syntax features while not modifying
the set of string-to-tree translation rules or
the baseline feature scores.
We conduct experiments with a state-
of-the-art setup on an English?German
translation task. Our results suggest that
preference grammars for GHKM trans-
lation are inferior to the plain target-
syntactified model, whereas the enhance-
ment with soft source syntactic constraints
provides consistent gains. By employ-
ing soft source syntactic constraints with
sparse features, we are able to achieve im-
provements of up to 0.7 points BLEU and
1.0 points TER.
1 Introduction
Previous research in both formally syntax-based
(i.e., hierarchical) and linguistically syntax-based
statistical machine translation has demonstrated
that significant quality gains can be achieved via
integration of syntactic information as features in
a non-obtrusive manner, rather than as hard con-
straints.
We implemented two feature-based extensions
for a GHKM-style string-to-tree translation sys-
tem (Galley et al., 2004):
? Preference grammars to soften the hard
target-side syntactic constraints that are im-
posed by the target non-terminal labels.
? Soft source-side syntactic constraints that
enhance the string-to-tree translation model
with input tree features based on source syn-
tax labels.
The empirical results on an English?German
translation task are twofold. Target-side prefer-
ence grammars do not show an improvement over
the string-to-tree baseline with syntactified trans-
lation rules. Source-side syntactic constraints, on
the other hand, yield consistent moderate gains if
applied as supplementary features in the string-to-
tree setup.
2 Outline
The paper is structured as follows: First we give an
overview of important related publications (Sec-
tion 3). In Section 4, we review the fundamentals
of syntax-based translation in general, and in par-
ticular those of GHKM string-to-tree translation.
We present preference grammars for GHKM
translation in Section 5. Our technique for ap-
plying soft source syntactic constraints in GHKM
string-to-tree translation is described in Section 6.
Section 7 contains the empirical part of the pa-
per. We first describe our experimental setup (7.1),
followed by a presentation and discussion of the
translation results (7.2). We conclude the paper in
Section 8.
3 Related Work
Our syntactic translation model conforms to the
GHKM syntax approach as proposed by Galley,
Hopkins, Knight, and Marcu (Galley et al., 2004)
with composed rules as in (Galley et al., 2006)
and (DeNeefe et al., 2007). Systems based on
148
this paradigm have recently been among the top-
ranked submissions to public evaluation cam-
paigns (Williams et al., 2014; Bojar et al., 2014).
Our soft source syntactic constraints features
borrow ideas from Marton and Resnik (2008) who
proposed a comparable approach for hierarchical
machine translation. The major difference is that
the features of Marton and Resnik (2008) are only
based on the labels from the input trees as seen in
tuning and decoding. They penalize violations of
constituent boundaries but do not employ syntactic
parse annotation of the source side of the training
data. We, in contrast, equip the rules with latent
source label properties, allowing for features that
can check for conformance of input tree labels and
source labels that have been seen in training.
Other groups have applied similar techniques
to a string-to-dependency system (Huang et al.,
2013) and?like in our work?a GHKM string-
to-tree system (Zhang et al., 2011). Both Huang
et al. (2013) and Zhang et al. (2011) store source
labels as additional information with the rules.
They however investigate somewhat different fea-
ture functions than we do.
Marton and Resnik (2008) evaluated their
method on the NIST Chinese?English and
Arabic?English tasks. Huang et al. (2013) and
Zhang et al. (2011) present results on the NIST
Chinese?English task. We focus our attention on
a very different task: English?German.
4 Syntax-based Translation
In syntax-based translation, a probabilistic syn-
chronous context-free grammar (SCFG) is in-
duced from bilingual training corpora. The par-
allel training data is word-aligned and annotated
with syntactic parses on either target side (string-
to-tree), source side (tree-to-string), or both (tree-
to-tree). A syntactic rule extraction procedure ex-
tracts rules which are consistent with the word-
alignment and comply with certain syntactic va-
lidity constraints.
Extracted rules are of the form A,B???,? ,
?
?.
The right-hand side of the rule ??,? ? is a bilingual
phrase pair that may contain non-terminal sym-
bols, i.e. ? ? (V
F
? N
F
)
+
and ? ? (V
E
? N
E
)
+
,
where V
F
and V
E
denote the source and target
terminal vocabulary, and N
F
and N
E
denote the
source and target non-terminal vocabulary, respec-
tively. The non-terminals on the source side and
on the target side of rules are linked in a one-to-
one correspondence. The
?
relation defines this
one-to-one correspondence. The left-hand side
of the rule is a pair of source and target non-
terminals, A ? N
F
and B ? N
E
.
Decoding is typically carried out with a parsing-
based algorithm, in our case a customized version
of CYK
+
(Chappelier and Rajman, 1998). The
parsing algorithm is extended to handle transla-
tion candidates and to incorporate language model
scores via cube pruning (Chiang, 2007).
4.1 GHKM String-to-Tree Translation
In GHKM string-to-tree translation (Galley et al.,
2004; Galley et al., 2006; DeNeefe et al., 2007),
rules are extracted from training instances which
consist of a source sentence, a target sentence
along with its constituent parse tree, and a word
alignment matrix. This tuple is interpreted as a
directed graph (the alignment graph), with edges
pointing away from the root of the tree, and word
alignment links being edges as well. A set of
nodes (the frontier set) is determined that con-
tains only nodes with non-overlapping closure of
their spans.
1
By computing frontier graph frag-
ments?fragments of the alignment graph such
that their root and all sinks are in the frontier set?
the GHKM extractor is able to induce a minimal
set of rules which explain the training instance.
The internal tree structure can be discarded to ob-
tain flat SCFG rules. Minimal rules can be assem-
bled to build larger composed rules.
Non-terminals on target sides of string-to-tree
rules are syntactified. The target non-terminal vo-
cabulary of the SCFG contains the set of labels of
the frontier nodes, which is in turn a subset of (or
equal to) the set of constituent labels in the parse
tree. The target non-terminal vocabulary further-
more contains an initial non-terminal symbol Q.
Source sides of the rules are not decorated with
syntactic annotation. The source non-terminal vo-
cabulary contains a single generic non-terminal
symbol X.
In addition to the extracted grammar, the trans-
lation system makes use of a special glue grammar
with an initial rule, glue rules, a final rule, and top
rules. The glue rules provide a fall back method
to just monotonically concatenate partial deriva-
tions during decoding. As we add tokens which
1
The span of a node in the alignment graph is defined
as the set of source-side words that are reachable from this
node. The closure of a span is the smallest interval of source
sentence positions that covers the span.
149
mark the sentence start (?<s>?) and the sentence
end (?</s>?), the rules in the glue grammar are of
the following form:
Initial rule:
X,Q? ?<s> X
?0
,<s> Q
?0
?
Glue rules:
X,Q? ?X
?0
X
?1
,Q
?0
B
?1
?
for all B ? N
E
Final rule:
X,Q? ?X
?0
</s>,Q
?0
</s>?
Top rules:
X,Q? ?<s> X
?0
</s>,<s> B
?0
</s>?
for all B ? N
E
5 Preference Grammars
Preference grammars store a set of implicit label
vectors as additional information with each SCFG
rule, along with their relative frequencies given
the rule. Venugopal et al. (2009) have introduced
this technique for hierarchical phrase-based trans-
lation. The implicit label set refines the label set
of the underlying synchronous context-free gram-
mar.
We apply this idea to GHKM translation by
not decorating the target-side non-terminals of the
extracted GHKM rules with syntactic labels, but
with a single generic label. The (explicit) tar-
get non-terminal vocabulary N
E
thus also con-
tains only the generic non-terminal symbol X, just
like the source non-terminal vocabulary N
F
. The
extraction method remains syntax-directed and is
still guided by the syntactic annotation over the
target side of the data, but the syntactic labels are
stripped off from the SCFG rules. Rules which
differ only with respect to their non-terminal la-
bels are collapsed to a single entry in the rule ta-
ble, and their rule counts are pooled. However,
the syntactic label vectors that have been seen with
this rule during extraction are stored as implicit la-
bel vectors of the rule.
5.1 Feature Computation
Two features are added to the log-linear model
combination in order to rate the syntactic well-
formedness of derivations. The first feature is
similar to the one suggested by Venugopal et al.
(2009) and computes a score based on the relative
frequencies of implicit label vectors of those rules
which are involved in the derivation. The second
feature is a simple binary feature which supple-
ments the first one by penalizing a rule application
if none of the implicit label vectors match.
We will now formally specify the first feature.
2
We give a recursive definition of the feature score
h
syn
(d) for a derivation d.
Let r be the top rule in derivation d, with n
right-hand side non-terminals. Let d
j
denote the
sub-derivation of d at the j-th right-hand side non-
terminal of r, 1 ? j ? n. h
syn
(d) is recursively
defined as
h
syn
(d) =
?
t
syn
(d)+
n
?
j=1
h
syn
(d
j
) . (1)
In this equation,
?
t
syn
(d) is a simple auxiliary
function:
?
t
syn
(d) =
{
log t
syn
(d) if t
syn
(d) 6= 0
0 otherwise
(2)
Denoting with S the implicit label set of the
preference grammar, we define t
syn
(d) as a func-
tion that assesses the degree of agreement of
the preferences of the current rule with the sub-
derivations:
t
syn
(d) =
?
s?S
n+1
(
p(s|r) ?
n+1
?
k=2
?
t
h
(s[k]|d
k?1
)
)
(3)
We use the notation [?] to address the elements of a
vector. The first element of an n+ 1-dimensional
vector s of implicit labels is an implicit label bind-
ing of the left-hand side non-terminal of the rule r.
p(s|r) is the preference distribution of the rule.
Here,
?
t
h
(Y |d) is another auxiliary function that
renormalizes the values of t
h
(Y |d):
?
t
h
(Y |d) =
t
h
(Y |d)
?
Y
?
?S
t
h
(Y
?
|d)
(4)
It provides us with a probability that the derivation
d has the implicit label Y ? S as its root. Finally,
the function t
h
(Y |d) is defined as
t
h
(Y |d) =
?
s?S
n+1
:s[1]=Y
(
p(s|r) ?
n+1
?
k=2
p
h
(s[k]|d
k?1
)
)
.
(5)
Note that the denominator in Equation (4) thus
equals t
syn
(d).
2
Our notational conventions roughly follow the ones by
Stein et al. (2010).
150
This concludes the formal specification of the
first features. The second feature h
auxSyn
(d) penal-
izes rule applications in cases where t
syn
(d) evalu-
ates to 0:
h
auxSyn
(d) =
{
0 if t
syn
(d) 6= 0
1 otherwise
(6)
Its intuition is that rule applications that do not
contribute to h
syn
(d) should be punished. Deriva-
tions with t
syn
(d) = 0 could alternatively be
dropped completely, but our approach is to avoid
hard constraints. We will later demonstrate empir-
ically that discarding such derivations harms trans-
lation quality.
6 Soft Source Syntactic Constraints
Similar to the implicit target-side label vectors
which we store in preference grammars, we can
likewise memorize sets of source-side syntactic la-
bel vectors with GHKM rules. In contrast to pref-
erence grammars, the rule inventory of the string-
to-tree system remains untouched. The target non-
terminals of the SCFG stay syntactified, and the
source non-terminal vocabulary is not extended
beyond the single generic non-terminal.
Source-side syntactic labels are an additional la-
tent property of the rules. We obtain this property
by parsing the source side of the training data and
collecting the source labels that cover the source-
side span of non-terminals during GHKM rule ex-
traction. As the source-side span is frequently not
covered by a constituent in the syntactic parse tree,
we employ the composite symbols as suggested
by Zollmann and Venugopal (2006) for the SAMT
system.
3
In cases where a span is still not covered
by a symbol, we nevertheless memorize a source-
side syntactic label vector but indicate the failure
for the uncovered non-terminal with a special la-
bel. The set of source label vectors that are seen
with a rule during extraction is stored with it in the
rule table as an additional property. This informa-
tion can be used to implement feature-based soft
source syntactic constraints.
Table 1 shows an example of a set of source
label vectors stored with a grammar rule. The
first element of each vector is an implicit source-
syntactic label for the left-hand side non-terminal
of the rule, the remaining elements are implicit
3
Specifically, we apply relax-parse --SAMT 2 as
implemented in the Moses toolkit (Koehn et al., 2007).
source label vector frequency
(IN+NP,NN,NN) 7
(IN+NP,NNP,NNP) 3
(IN++NP,NNS,NNS) 2
(IN+NP,NP,NP) 2
(PP//SBAR,NP,NP) 1
Table 1: The set of source label vec-
tors (along with their frequencies in the
training data) for the rule X,PP-MO ?
?between X
?1
and X
?0
,zwischen NN
?0
und NN
?1
?.
The overall rule frequency is 15.
source-syntactic labels for the right-hand side
source non-terminals.
The basic idea for soft source syntactic con-
straints features is to also parse the input data in
a preprocessing step and try to match input labels
and source label vectors that are associated with
SCFG rules.
6.1 Feature Computation
Upon application of an SCFG rule, each of the
non-terminals of the rule covers a distinct span of
the input sentence. An input label from the input
parse may be available for this span. We say that
a non-terminal has a match in a given source la-
bel vector of the rule if its label in the vector is the
same as a corresponding input label over the span.
We define three simple features to score
matches and mismatches of the impicit source syn-
tactic labels with the labels from the input data:
? A binary feature that fires if a rule is applied
which possesses a source syntactic label vec-
tor that fully matches the input labels. This
feature rewards exact source label matches of
complete rules, i.e., the existance of a vector
in which all non-terminals of the rule have
matches.
? A binary feature that fires if a rule is applied
which does not possess any source syntactic
label vector with a match of the label for the
left-hand side non-terminal. This feature pe-
nalizes left-hand side mismatches.
? A count feature that for each rule application
adds a cost equal to the number of right-hand
side non-terminals that do not have a match
with a corresponding input label in any of the
source syntactic label vectors. This feature
penalizes right-hand side mismatches.
151
The second and third feature are less strict than the
first one and give the system a more detailed clue
about the magnitude of mismatch.
6.2 Sparse Features
We can optionally add a larger number of sparse
features that depend on the identity of the source-
side syntactic label:
? Sparse features which fire if a specific input
label is matched. We say that the input la-
bel is matched in case the corresponding non-
terminal that covers the span has a match in
any of the source syntactic label vectors of
the applied rule. We distinguish input label
matches via left-hand side and via right-hand
side non-terminals.
? Sparse features which fire if the span of a spe-
cific input label is covered by a non-terminal
of an applied rule, but the input label is not
matched.
The first set of sparse features rewards matches,
the second set of sparse features penalizes mis-
matches.
All sparse features have individual scaling fac-
tors in the log-linear model combination. We how-
ever implemented a means of restricting the num-
ber of sparse features by providing a core set of
source labels. If such a core set is specified, then
only those sparse features are active that depend
on the identity of labels within this set. All sparse
features for source labels outside of the core set
are inactive.
7 Experiments
We empirically evaluate the effectiveness of
preference grammars and soft source syntac-
tic constraints for GHKM translation on the
English?German language pair using the stan-
dard newstest sets of the Workshop on Statisti-
cal Machine Translation (WMT) for testing.
4
The
experiments are conducted with the open-source
Moses implementations of GHKM rule extraction
(Williams and Koehn, 2012) and decoding with
CYK
+
parsing and cube pruning (Hoang et al.,
2009).
4
http://www.statmt.org/wmt14/
translation-task.html
7.1 Experimental Setup
We work with an English?German parallel train-
ing corpus of around 4.5 M sentence pairs (af-
ter corpus cleaning). The parallel data origi-
nates from three different sources which have
been eligible for the constrained track of the
ACL 2014 Ninth Workshop on Statistical Ma-
chine Translation shared translation task: Europarl
(Koehn, 2005), News Commentary, and the Com-
mon Crawl corpus as provided on the WMT web-
site. Word alignments are created by aligning the
data in both directions with MGIZA
++
(Gao and
Vogel, 2008) and symmetrizing the two trained
alignments (Och and Ney, 2003; Koehn et al.,
2003). The German target side training data is
parsed with BitPar (Schmid, 2004). We remove
grammatical case and function information from
the annotation obtained with BitPar and apply
right binarization of the German parse trees prior
to rule extraction (Wang et al., 2007; Wang et al.,
2010; Nadejde et al., 2013). For the soft source
syntactic constraints, we parse the English source
side of the parallel data with the English Berkeley
Parser (Petrov et al., 2006) and produce composite
SAMT-style labels as discussed in Section 6.
When extracting syntactic rules, we impose sev-
eral restrictions for composed rules, in particular
a maximum number of 100 tree nodes per rule,
a maximum depth of seven, and a maximum size
of seven. We discard rules with non-terminals on
their right-hand side if they are singletons in the
training data.
For efficiency reasons, we also enforce a limit
on the number of label vectors that are stored
as additional properties. Label vectors are only
stored if they occur at least as often as the 50th
most frequent label vector of the given rule. This
limit is applied separately for both source-side la-
bel vectors (which are used by the soft syntactic
contraints) and target-side label vectors (which are
used by the preference grammar).
Only the 200 best translation options per dis-
tinct rule source side with respect to the weighted
rule-level model scores are loaded by the decoder.
Search is carried out with a maximum chart span
of 25, a rule limit of 500, a stack limit of 200, and
a k-best limit of 1000 for cube pruning.
A standard set of models is used in the base-
line, comprising rule translation probabilities and
lexical translation probabilities in both directions,
word penalty and rule penalty, an n-gram language
152
system dev newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
GHKM string-to-tree baseline 34.7 47.3 20.0 63.3 19.4 65.6
+ soft source syntactic constraints 35.1 47.0 20.3 62.7 19.7 64.9
+ sparse features 35.8 46.5 20.3 62.8 19.6 65.1
+ sparse features (core = non-composite) 35.4 46.8 20.2 62.9 19.6 65.1
+ sparse features (core = dev-min-occ100) 35.6 46.7 20.2 62.9 19.6 65.2
+ sparse features (core = dev-min-occ1000) 35.4 46.9 20.3 62.8 19.6 65.2
+ hard source syntactic constraints 34.6 47.4 19.9 63.4 19.4 65.6
string-to-string (GHKM syntax-directed rule extraction) 33.8 48.0 19.3 63.8 18.7 66.2
+ preference grammar 33.9 47.7 19.3 63.7 18.8 66.0
+ soft source syntactic constraints 34.6 47.0 19.8 62.9 19.5 65.2
+ drop derivations with t
syn
(d) = 0 34.0 47.5 19.7 63.0 18.8 65.8
Table 2: English?German experimental results (truecase). BLEU scores are given in percentage.
A selection of 2000 sentences from the newstest2008-2012 sets is used as development set.
model, a rule rareness penalty, and the monolin-
gual PCFG probability of the tree fragment from
which the rule was extracted (Williams et al.,
2014). Rule translation probabilities are smoothed
via Good-Turing smoothing.
The language model (LM) is a large inter-
polated 5-gram LM with modified Kneser-Ney
smoothing (Kneser and Ney, 1995; Chen and
Goodman, 1998). The target side of the parallel
corpus and the monolingual German News Crawl
corpora are employed as training data. We use
the SRILM toolkit (Stolcke, 2002) to train the LM
and rely on KenLM (Heafield, 2011) for language
model scoring during decoding.
Model weights are optimized to maximize
BLEU (Papineni et al., 2002) with batch MIRA
(Cherry and Foster, 2012) on 1000-best lists. We
selected 2000 sentences from the newstest2008-
2012 sets as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and do each contain less than
30 words for more rapid tuning. newstest2013 and
newstest2014 are used as unseen test sets. Trans-
lation quality is measured in truecase with BLEU
and TER (Snover et al., 2006).
5
7.2 Translation Results
The results of the empirical evaluation are given in
Table 2. Our GHKM string-to-tree system attains
state-of-the-art performance on newstest2013 and
newstest2014.
5
TER scores are computed with tercom version 0.7.25
and parameters -N -s.
7.2.1 Soft Source Syntactic Constraints
Adding the three dense soft source syntactic con-
straints features from Section 6.1 improves the
baseline scores by 0.3 points BLEU and 0.6 points
TER on newstest2013 and by 0.3 points BLEU and
0.7 points TER on newstest2014.
Somewhat surprisingly, the sparse features from
Section 6.2 do not boost translation quality further
on any of the two test sets. We observe a consid-
erable improvement on the development set, but it
does not carry over to the test sets. We attributed
this to an overfitting effect. Our source-side soft
syntactic label set of composite SAMT-style la-
bels comprises 8504 different labels that appear on
the source-side of the parallel training data. Four
times the amount of sparse features are possible
(left-hand side/right-hand side matches and mis-
matches for each label), though not all of them fire
on the development set. 3989 sparse weights are
tuned to non-zero values in the experiment. Due to
the sparse nature of the features, overfitting cannot
be ruled out.
We attempted to take measures in order to avoid
overfitting by specifying a core set of source la-
bels and deactivating all sparse features for source
labels outside of the core set (cf. Section 6.2).
First we specified the core label set as all non-
composite labels. Non-composite labels are the
plain constituent labels as given by the syntactic
parser. Complex SAMT-style labels are not in-
cluded. The size of this set is 71 (non-composite
labels that have been observed during rule extrac-
tion). Translation performance on the develop-
ment set drops in the sparse features (core = non-
153
system (tuned on newstest2012) newstest2012 newstest2013 newstest2014
BLEU TER BLEU TER BLEU TER
GHKM string-to-tree baseline 17.9 65.7 19.9 63.2 19.4 65.3
+ soft source syntactic constraints 18.2 65.3 20.3 62.6 19.7 64.7
+ sparse features 18.6 64.9 20.4 62.5 19.8 64.7
+ sparse features (core = non-composite) 18.4 65.1 20.3 62.7 19.8 64.7
+ sparse features (core = dev-min-occ100) 18.4 64.8 20.6 62.2 19.9 64.4
Table 3: English?German experimental results (truecase). BLEU scores are given in percentage.
newstest2012 is used as development set.
composite) setup, but performance does not in-
crease on the test sets.
Next we specified the core label set in another
way: We counted how often each source label oc-
curs in the input data on the development set. We
then applied a minimum occurrence count thresh-
old and added labels to the core set if they did not
appear more rarely than the threshold. We tried
values of 100 and 1000 for the minimum occur-
rence, resulting in 277 and 37 labels being in the
core label set, respectively. Neither the sparse fea-
tures (core = dev-min-occ100) experiment nor the
sparse features (core = dev-min-occ1000) experi-
ment yields better translation quality than what we
see in the setup without sparse features.
We eventually conjectured that the choice of our
development set might be a reason for the ineffec-
tiveness of the sparse features, as on a fine-grained
level it could possibly be too different from the
test sets with respect to its syntactic properties.
We therefore repeated some of the experiments
with scaling factors optimized on newstest2012
(Table 3). The sparse features (core = dev-min-
occ100) setup indeed performs better when tuned
on newstest2012, with improvements of 0.7 points
BLEU and 1.0 points TER on newstest2013 and
of 0.5 points BLEU and 0.9 points TER on news-
test2014 over the baseline tuned on the same set.
Finally, we were interested in demonstrating
that soft source syntactic constraints are superior
to hard source syntactic constraints. We built a
setup that forces the decoder to match source-side
syntactic label vectors in the rules with input la-
bels.
6
Hard source syntactic constraints are in-
deed worse than soft source syntactic constraints
(by 0.4 BLEU on newstest2013 and 0.3 BLEU on
newstest2014). The setup with hard source syntac-
tic constraints performs almost exactly at the level
of the baseline.
6
Glue rules are an exception. They do not need to match
the input labels.
7.2.2 Preference Grammar
In the series of experiments with a preference
grammar, we first evaluated a setup with the un-
derlying SCFG of the preference grammar sys-
tem, but without preference grammar. We de-
note this setup as string-to-string (GHKM syntax-
directed rule extraction) in Table 2. The ex-
traction method for this string-to-string system is
GHKM syntax-directed with right-binarized syn-
tactic target-side parses from BitPar, as in the
string-to-tree setup. The constituent labels from
the syntactic parses are however not used to dec-
orate non-terminals. The grammar contains rules
with a single generic non-terminal instead of syn-
tactic ones. The string-to-string (GHKM syntax-
directed rule extraction) setup is on newstest2013
0.7 BLEU (0.5 TER) worse and on newstest2014
0.7 BLEU (0.6 TER) worse than the standard
GHKM string-to-tree baseline.
We then activated the preference grammar as
described in Section 5. GHKM translation with a
preference grammar instead of a syntactified target
non-terminal vocabulary in the SCFG is consider-
ably worse than the standard GHKM string-to-tree
baseline and barely improves over the string-to-
string setup.
We added soft source syntactic constraints on
top of the preference grammar system, thus com-
bining the two techniques. Soft source syntactic
constraints give a nice gain over the preference
grammar system, but the best setup without a pref-
erence grammar is not outperformed. In another
experiment, we investigated the effect of dropping
derivations with t
syn
(d) = 0 (cf. Section 5.1). Note
that the second feature h
auxSyn
(d) is not useful in
this setup, as the system is forced to discard all
derivations that would be penalized by that fea-
ture. We deactivated h
auxSyn
(d) for the experi-
ment. The hard decision of dropping derivations
with t
syn
(d) = 0 leads to a performance loss of
154
0.1 BLEU on newstest2013 and a more severe de-
terioration of 0.7 BLEU on newstest2014.
8 Conclusions
We investigated two soft syntactic extensions for
GHKM translation: Target-side preference gram-
mars and soft source syntactic constraints.
Soft source syntactic constraints proved to be
suitable for advancing the translation quality over
a strong string-to-tree baseline. Sparse features
are beneficial beyond just three dense features, but
they require the utilization of an appropriate devel-
opment set. We also showed that the soft integra-
tion of source syntactic constraints is crucial: Hard
constraints do not yield gains over the baseline.
Preference grammars did not perform well in
our experiments, suggesting that translation mod-
els with syntactic target non-terminal vocabular-
ies are a better choice when building string-to-tree
systems.
Acknowledgements
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreements n
o
287658 (EU-BRIDGE)
and n
o
288487 (MosesCore).
References
Ondrej Bojar, Christian Buck, Christian Federmann,
Barry Haddow, Philipp Koehn, Johannes Leveling,
Christof Monz, Pavel Pecina, Matt Post, Herve
Saint-Amand, Radu Soricut, Lucia Specia, and Ale?
Tamchyna. 2014. Findings of the 2014 Work-
shop on Statistical Machine Translation. In Proc. of
the Workshop on Statistical Machine Translation
(WMT), pages 12?58, Baltimore, MD, USA, June.
Jean-C?dric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochas-
tic CFG. In Proc. of the First Workshop on Tab-
ulation in Parsing and Deduction, pages 133?137,
Paris, France, April.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, USA, August.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proc. of the Human Language Technology Conf. /
North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 427?436,
Montr?al, Canada, June.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228, June.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What Can Syntax-Based MT Learn
from Phrase-Based MT? In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 755?763,
Prague, Czech Republic, June.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st Int. Conf. on Computational Lin-
guistics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 961?968, Sydney,
Australia, July.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Columbus, OH, USA, June.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proc. of the Workshop
on Statistical Machine Translation (WMT), pages
187?197, Edinburgh, Scotland, UK, July.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. In Proc. of the Int. Workshop on Spoken Lan-
guage Translation (IWSLT), pages 152?159, Tokyo,
Japan, December.
Zhongqiang Huang, Jacob Devlin, and Rabih Zbib.
2013. Factored Soft Source Syntactic Constraints
for Hierarchical Machine Translation. In Proc. of
the Conf. on Empirical Methods for Natural Lan-
guage Processing (EMNLP), pages 556?566, Seat-
tle, WA, USA, October.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In
Proceedings of the Int. Conf. on Acoustics, Speech,
and Signal Processing, volume 1, pages 181?184,
Detroit, MI, USA, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Proc.
of the Human Language Technology Conf. / North
American Chapter of the Assoc. for Computational
Linguistics (HLT-NAACL), pages 127?133, Edmon-
ton, Canada, May/June.
155
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Proc.
of the Annual Meeting of the Assoc. for Computa-
tional Linguistics (ACL), pages 177?180, Prague,
Czech Republic, June.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of the MT
Summit X, Phuket, Thailand, September.
Yuval Marton and Philip Resnik. 2008. Soft Syn-
tactic Constraints for Hierarchical Phrased-Based
Translation. In Proc. of the Annual Meeting of the
Assoc. for Computational Linguistics (ACL), pages
1003?1011, Columbus, OH, USA, June.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s Syntax-Based Machine Transla-
tion Systems. In Proc. of the Workshop on Statistical
Machine Translation (WMT), pages 170?176, Sofia,
Bulgaria, August.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proc. of the
Annual Meeting of the Assoc. for Computational
Linguistics (ACL), pages 311?318, Philadelphia, PA,
USA, July.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st Int.
Conf. on Computational Linguistics and 44th An-
nual Meeting of the Assoc. for Computational Lin-
guistics, pages 433?440, Sydney, Australia, July.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proc. of the Conf. of the Assoc. for
Machine Translation in the Americas (AMTA), pages
223?231, Cambridge, MA, USA, August.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Proc.
of the Conf. of the Assoc. for Machine Translation
in the Americas (AMTA), Denver, CO, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Spoken Language Processing (ICSLP), volume 3,
Denver, CO, USA, September.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference Grammars:
Softening Syntactic Constraints to Improve Statis-
tical Machine Translation. In Proc. of the Hu-
man Language Technology Conf. / North American
Chapter of the Assoc. for Computational Linguistics
(HLT-NAACL), pages 236?244, Boulder, CO, USA,
June.
Wei Wang, Kevin Knight, and Daniel Marcu. 2007.
Binarizing Syntax Trees to Improve Syntax-Based
Machine Translation Accuracy. In Proc. of the 2007
Joint Conf. on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 746?754,
Prague, Czech Republic, June.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, Re-labeling, and
Re-aligning for Syntax-based Machine Translation.
Computational Linguistics, 36(2):247?277, June.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proc. of the Workshop on Statistical Machine Trans-
lation (WMT), pages 388?394, Montr?al, Canada,
June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proc. of the Workshop on Statis-
tical Machine Translation (WMT), pages 207?214,
Baltimore, MD, USA, June.
Jiajun Zhang, Feifei Zhai, and Chengqing Zong. 2011.
Augmenting String-to-Tree Translation Models with
Fuzzy Use of Source-side Syntax. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 204?215, Edinburgh,
Scotland, UK, July.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax Augmented Machine Translation via Chart Pars-
ing. In Proc. of the Workshop on Statistical Machine
Translation (WMT), pages 138?141, New York City,
NY, USA, June.
156
