Proceedings of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP 2009, pages 40?46,
Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLP
Mining Complex Predicates In Hindi Using A Parallel  
Hindi-English Corpus  
 
R. Mahesh K. Sinha
Department of Computer Science & Engineering 
Indian Institute of Technology, Kanpur 
Kanpur 208016 India 
rmk@iitk.ac.in 
 
 
 
Abstract 
Complex predicate is a noun, a verb, an ad-
jective or an adverb followed by a light verb 
that behaves as a single unit of verb. Com-
plex predicates (CPs) are abundantly used in 
Hindi and other languages of Indo Aryan 
family.  Detecting and interpreting CPs con-
stitute an important and somewhat a diffi-
cult task. The linguistic and statistical 
methods have yielded limited success in 
mining this data. In this paper, we present a 
simple method for detecting CPs of all kinds 
using a Hindi-English parallel corpus. A CP 
is hypothesized by detecting absence of the 
conventional meaning of the light verb in 
the aligned English sentence. This simple 
strategy exploits the fact that CP is a multi-
word expression with a meaning that is dis-
tinct from the meaning of the light verb. Al-
though there are several shortcomings in the 
methodology, this empirical method surpri-
singly yields mining of CPs with an average 
precision of 89% and a recall of 90%.   
1 Introduction 
Complex predicates (CPs) are abundantly used in 
Hindi and other languages of Indo-Aryan family 
and have been widely studied (Hook, 1974; Ab-
bi, 1992; Verma, 1993; Mohanan, 1994; Singh, 
1994; Butt, 1995; Butt and Geuder, 2001; Butt 
and Ramchand, 2001; Butt et al, 2003). A com-
plex predicate is a multi-word expression 
(MWE) where a noun, a verb or an adjective is 
followed by a light verb (LV) and the MWE be-
haves as a single unit of verb. The general theory 
of complex predicate is discussed in Alsina 
(1996).  These studies attempt to model the lin-
guistic facts of complex predicate formation and 
the associated semantic roles. 
CPs empower the language in its expressive-
ness but are hard to detect. Detection and inter-
pretation of CPs are important for several tasks 
of natural language processing tasks such as ma-
chine translation, information retrieval, summa-
rization etc. A mere listing of the CPs constitutes 
a valuable linguistic resource for lexicographers, 
wordnet designers (Chakrabarti et al, 2007) and 
other NLP system designers. Computational me-
thod using Hindi corpus has been used to mine 
CPs and categorize them based on statistical 
analysis (Sriram and Joshi, 2005) with limited 
success. Chakrabarti et al (2008) present a me-
thod for automatic extraction of V+V CPs only 
from a corpus based on linguistic features. They 
report an accuracy of about 98%.  An attempt has 
also been made to use a parallel corpus for de-
tecting CPs using projection POS tags from Eng-
lish to Hindi (Soni, Mukerjee and Raina, 2006). 
It uses Giza++ word alignment tool to align the 
projected POS information. A success of 83% 
precision and 46% recall has been reported.  
In this paper, we present a simple strategy for 
mining of CPs in Hindi using projection of 
meaning of light verb in a parallel corpus. In the 
following section the nature of CP in Hindi is 
outlined and this is followed by system design, 
experimentation and results. 
2 Complex Predicates in Hindi   
A CP in Hindi is a syntactic construction consist-
ing of either  a verb, a noun, an adjective or an 
adverb as main predicator followed by a light 
verb (LV). Thus, a CP can be a noun+LV, an 
adjective+LV, a verb+LV or an adverb+LV. Fur-
ther, it is also possible that a CP is followed by a 
LV (CP+LV). The light verb carries the tense 
and agreement morphology.  In V+V CPs, the 
contribution of the light verb denotes aspectual 
terms such as continuity, perfectivity, inception, 
completion, or denotes an expression of forceful-
ness, suddenness, etc. (Singh, 1994; Butt, 1995). 
The CP in a sentence syntactically acts as a sin-
gle lexical unit of verb that has a meaning dis-
40
tinct from that of the LV. CPs are also referred as 
the complex or compound verbs.   
Given below are some examples: 
 
(1): CP=noun+LV 
noun = ashirwad {blessings} 
LV = denaa {to give} 
usane mujhe ashirwad diyaa. 
???? ??? ??????? ???? 
{he     me   blessings  gave} 
he blessed me. 
 
(2) No CP 
usane mujhe ek pustak dii. 
???? ??? ??? ????? ?? 
{he    me  one  book  gave} 
he gave me a book. 
 
In (1), the light verb diyaa (gave) in its past tense 
form with the noun ashirwad (blessings) makes a 
complex predicate verb form ashirwad diyaa 
(blessed) in the past tense form.  The CP here is 
ashirwad denaa and its corresponding English 
translation is ?to bless?. On the other hand in ex-
ample (2), the verb  dii (gave) is a simple verb in 
past tense form and is not a light verb. Although, 
same Hindi verb denaa (to give) is used in both 
the examples, it is a light verb in (1) and a main 
verb in (2). Whether it acts as a light verb or not, 
depends upon the semantics of the preceding 
noun. However, it is observed that the English 
meaning in case of the complex predicate is not 
derived from the individual meanings of the con-
stituent words. It is this observation that forms 
basis of our approach for mining of CPs. 
 
(3) CP=adjective+LV 
adjective=khush {happy} 
LV=karanaa {to do} 
usane mujhe khush kiyaa. 
???? ??? ???? ???? 
{he   me  happy did} 
he pleased me. 
 
Here the Hindi verb kiyaa (did) is the past tense 
form of a light verb karanaa (to do) and the pre-
ceding word khush (happy) is an adjective. The 
CP here is khush karanaa (to please). 
 
(4) CP=verb+LV 
verb = paRhnaa {to read} 
LV = lenaa {to take} 
usane pustak paRh liyaa. 
???? ????? ?? ???? 
{he    book  read took} 
he has read  the book. 
 
Here the Hindi verb liyaa (took) is the past tense 
form of the light verb lenaa (to take) and the pre-
ceding word paRh (read) is the verb paRhnaa (to 
read) in its stem form. The CP is paRh lenaa (to 
finish reading). In such cases the light verb acts 
as an aspectual /modal or as an intensifier.  
 
(5) CP=verb+LV 
verb = phaadanaa {to tear} 
LV = denaa {to give} 
usane pustak phaad diyaa. 
???? ????? ??? ???? 
{he    book   tear  gave} 
he has torn  the book. 
 
Here the Hindi verb diyaa (gave) is the past tense 
form of the light verb denaa (to give) and the 
preceding word phaad (tear) is the stem form of 
the  verb phaadanaa (to tear) . The CP is phaad 
denaa (to cause and complete act of tearing).  
 
(6) CP=verb+LV 
verb = denaa {to give} 
LV = maaranaa{to hit/ to kill} 
usane pustak de maaraa. 
???? ????? ?? ????  
{he   book  give  hit} 
he threw the book. 
 
Here the Hindi verb maaraa (hit/killed) is the 
past tense form of the light verb maaranaa (to 
hit/ to kill) and the preceding word de (give) is a 
verb denaa (to give) in its stem form. The CP is 
de maranaa (to throw). The verb combination 
yields a new meaning. This may also be consi-
dered as a semi-idiomatic construct by some 
people. 
 
(7) CP=adverb+LV1+LV2 
adverb = vaapas{back} 
LV1 = karanaa{to do} 
LV2 = denaa{to give} 
or 
CP = CP+LV 
CP = vaapas karanaa{to return} 
LV = denaa{to give} 
usane pustak vaapas kar  diyaa. 
???? ????? ???? ?? ???? 
{he    book   back   do  gave} 
41
he returned the book. 
 
Here there are two Hindi light verbs used. The 
verb kar (do) is the stem form of the light verb 
karanaa (to do) and the verb diyaa (gave) is the 
past tense form of the light verb denaa (to give). 
The preceding word vaapas (back) is an adverb. 
One way of interpretation is that the CP (a con-
junct verb) vaapas karanaa (to return) is fol-
lowed by another LV denaa (to give) signifying 
completion of the task. Another way of looking 
at it is to consider these as a combination of two 
CPs, vaapas karanaa (to return) and kar denaa 
(to complete the act). The semantic interpreta-
tions in the two cases remain the same. It may be 
noted that the word vaapas (return) is also a noun 
and in such a case the CP is a noun+LV. 
 
From all the above examples, the complexity 
of the task of mining the CPs is evident. Howev-
er, it is also observed that in the translated text, 
the meaning of the light verb does not appear in 
case of CPs. Our methodology for mining CPs is 
based on this observation and is outlined in the 
following section.  
3 System Design 
As outlined earlier, our method for detecting a 
CP is based on detecting a mismatch of the Hindi 
light verb meaning in the aligned English sen-
tence. The steps involved are as follows: 
1) Align the sentences of Hindi-English corpus; 
2) Create a list of Hindi light verbs and their 
common English meanings as a simple verb; 
(Table 1) 
3) For each Hindi light verb, generate all the 
morphological forms (Figure 1); 
4) For each English meaning of the light verb as 
given in table 1, generate all the morphologi-
cal forms (Figure 2); 
5) For each Hindi-English aligned sentence, 
execute the following steps: 
a) For each light verb of Hindi (table 1), 
execute the following steps:  
i) Search for a Hindi light verb (LV) 
and its morphological derivatives 
(figure 1) in the Hindi sentence and 
mark its position in the sentence (K); 
ii) If the LV or its morphological deriv-
ative is found, then search for the 
equivalent English meanings for any 
of the morphological forms (figure 
2) in the corresponding aligned Eng-
lish sentence; 
iii) If no match is found, then scan the 
words in the Hindi sentence to the 
left of the Kth position (as identified 
in step (i)); else if a match is found, 
then exit {i.e. go to step (a)}. 
iv) If the scanned word is a ?stop word? 
(figure 3), then ignore it and contin-
ue scanning; 
v) Stop the scan when it is not a ?stop 
word? and collect the Hindi word 
(W); 
vi) If W is an ?exit word? then exit {i.e. 
go to step (a)}, else the identified CP 
is W+LV. 
Hindi has a large number of light verbs. A list 
of some of the commonly used light verbs along 
with their common English meanings as a simple 
verb is given in table 1. The light verb kar (do) is 
the most frequently used light verb. Using its 
literal meaning as ?do?, as a criterion for testing 
CP is quite misleading since ?do? in English is 
used in several other contexts. Such meanings 
have been shown within parentheses and are not 
used for matching.  
 
light verb base form root verb meaning 
baithanaa ????? sit 
bananaa ???? make/become/build/construct/ 
manufacture/prepare 
banaanaa ????? make/build/construct/manufact-
ure/ prepare 
denaa ???? give  
lenaa ???? take 
paanaa ????  obtain/get 
uthanaa 3??? rise/ arise/ get-up  
uthaanaa 3???? raise/lift/ wake-up 
laganaa ???? feel/appear/ look /seem  
lagaanaa ????? fix/install/ apply 
cukanaa ?????  (finish)  
cukaanaa ?????? pay 
karanaa ????  (do) 
honaa ???? happen/become /be 
aanaa ??? come 
jaanaa ???? go 
khaanaa ???? eat 
rakhanaa ???? keep / put 
maaranaa ????? kill/beat/hit 
daalanaa ????? put 
haankanaa ?????? drive  
    
Table 1. Some of the common light verbs in Hindi 
42
For each of the Hindi light verb, all morpho-
logical forms are generated. A few illustrations 
are given in figures 1(a) and 1(b). Similarly, for 
each of the English meaning of the light verb, all 
of its morphological derivatives are generated. 
Figure 2 shows a few illustrations of the same. 
There are a number of words that can appear 
in between the nominal and the light verb in a 
CP. These words are ignored in search for a CP 
and are treated as stop words. These are words 
that denote negation or are emphasizers, inten-
sifiers, interrogative pronoun or a particle. A list 
of stop words used in the experimentation is giv-
en in figure 3.   
 
 
 
Figure 1(a). Morphological derivatives of sample 
Hindi light verb ?jaanaa?  ???? {to go} 
 
 
Figure 1(b). Morphological derivatives of  
sample Hindi light verb ?lenaa?  ???? {to take}  
 
 
        
     Figure 2. Morphological derivatives of  
            sample English meanings  
 
We use a list of words of words that we have 
named as ?exit words? which cannot form part of 
a CP in Hindi. We have used Hindi case (vibhak-
ti) markers (also called parsarg), conjunctions 
and pronouns as the ?exit words? in our imple-
mentation. Figure 4 shows a partial list used. 
However, this list can be augmented based on 
analysis of errors in LV identification. It should 
be noted that we do not perform parts of speech 
(POS) tagging and so the nature of the word pre-
ceding the LV is unknown to the system. 
English word: sit 
Morphological derivations: 
  sit sits sat sitting   
English word: give 
Morphological derivations: 
  give gives gave given giving  
?????
LV: jaanaa  ???? {to go} 
Morphological derivatives: 
jaa jaae jaao jaae.M jaauu.M  jaane jaanaa jaanii jaataa 
jaatii jaate jaanii.M jaatii.M jaaoge jaaogii gaii 
jaauu.MgA jaayegaa jaauu.Mgii jaayegii gaye gaii.M 
gayaa gayii jaaye.Mge jaaye.MgI jaakara  
?? (go: stem) ??? (go: imperative)  
??? (go: imperative) ???? (go: imperative)  
???? (go: first-person) ???? (go: infinitive, oblique)  
???? (go: infinitive, masculine, singular)  
???? (go: infinitive, feminine, singular)  
???? (go: indefinite, masculine, singular)  
???? (go: indefinite, feminine, singular)  
???? (go: indefinite, masculine, plural/oblique)  
????? (go: infinitive, feminine, plural)  
????? (go: indefinite, feminine, plural)  
????? (go: future, masculine, singular)  
????? (go: future, feminine, singular)  
?? (go: past, feminine, singular)  
?????? (go: future, masculine, first-person, singular) 
?????? (go: future, masculine, third-person, singular) 
?????? (go: future, feminine, first-person, singular) 
?????? (go: future, feminine, third-person, singular) 
??? (go: past, masculine, plural/oblique) 
??? (go: past, feminine, plural)  
??? (go: past, masculine, singular)  
??? (go: past, feminine, singular)  
?????? (go: future, masculine,  plural)  
?????? (go: future, feminine,  plural)  
???? (go: completion) 
?????
LV: lenaa  ???? {to take} 
Morphological derivatives: 
le lii le.M lo letaa letii lete  lii.M luu.M legaa legii 
lene lenaa lenii liyaa le.Mge loge letii.M luu.Mgaa 
luu.Mgii lekara  
?? (take: stem)   ?? (take: past)  
?? (take: imperative) ?? (take: imperative) 
???? (take: indefinite, masculine, singular) 
???? (take: indefinite, feminine, singular) 
???? (take: indefinite, masculine, plural/oblique) 
???(take:past,feminine,plural) ???(take: first-person) 
????(take: future, masculine, third-person,singular) 
????(take: future, feminine, third-person, singular) 
???? (take: infinitive, oblique)   
???? (take: infinitive, masculine, singular) 
???? (take: infinitive, feminine, singular) 
???? (take: past, masculine, singular) 
???? (take: future, masculine,  plural) 
???? (take: future, masculine, singular) 
????? (take: indefinite, feminine, plural) 
????? (take: future, masculine,first-person,singular) 
????? (take: future, feminine, first-person, singular) 
???? (take: completion)  
????? 
43
 
 
Figure 3. Stop words in Hindi used by the system 
 
 
 
Figure 4. A few exit words in Hindi used by the 
system 
The inner loop of the procedure identifies mul-
tiple CPs that may be present in a sentence. The 
outer loop is for mining the CPs in the entire 
corpus. The experimentation and results are dis-
cussed in the following section. 
4 Experimentation and Results  
The CP mining methodology outlined earlier has 
been implemented and tested over multiple files 
of EMILLE  (McEnery, Baker, Gaizauskas and 
Cunningham, 2000) English-Hindi parallel cor-
pus. A summary of the results obtained are given 
in table 2. As can be seen from this table, the 
precision obtained is 80% to 92% and the recall 
is between 89% to 100%. The F-measure is 88% 
to 97%. This is a remarkable and somewhat sur-
prising result from the simple methodology 
without much of linguistic or statistical analysis. 
This is much higher than what has been reported 
on the same corpus by Mukerjee et al 2006 
(83% precision and 46% recall) who use projec-
tion of POS and word alignment for CP identifi-
cation. This is the only other work that uses a 
parallel corpus and covers all kinds of CPs. The 
results as reported by Chakrabarti et al (2008) 
are only for V-V CPs. Moreover they do not re-
port the recall value. 
 
 File 
1 
File 
2 
File 
3 
File 
4 
File 
5 
File 
6 
No. of 
Sentences 
112 193 102 43 133 107 
Total no. of 
CP(N) 
200 298 150 46 188 151 
Correctly 
identified CP 
(TP) 
195 296 149 46 175 135 
V-V CP 56 63 9 6 15 20 
Incorrectly 
identified CP 
(FP) 
17 44 7 11 16 20 
Unidentified CP
(FN) 
5 2 1 0 13 16 
Accuracy % 
 
97.50 99.33 99.33 100,0 93.08 89.40
Precision  % 
(TP/  (TP+FP)) 
91.98 87.05 95.51 80.70 91.62 87.09
Recall % 
( TP / (TP+FN))
97.50 98.33 99.33 100.0 93.08 89.40
F-measure % 
( 2PR / ( P+R)) 
94.6 92.3 97.4 89.3 92.3 88.2 
 
Table 2. Results of the experimentation  
 
?? (ergative case marker), ?? (accusative 
case marker), ?? (possessive case marker), 
?? (possessive case marker), ?? (possessive 
case marker), ?? (from/by/with), ?? (in/into), 
?? (on/but), ?? (and/ Hindi particle), ??? 
(and), ?? (or), ????? (but), ???? ? (but), ?? 
(that/ Hindi particle), ?? (I), ??? (you), ?? 
(you), ?? (he/she), ???? (my), ???? (my), ???? 
(my), ??????? (your), ??????? (your), ??????? 
(your), ???? (his), ???? (her), ???? 
(his/her), ???? (own), ???? (own), ???? 
(own), ???? (their), ???? (I ergative), ????? (to 
you), ???? (to you), ???? (to him/her), 
???? (to them), ???? (to them), ????? (to 
me), ??? ? (to me), ????? (whose), ????? 
(whose), ????? (whose), ????? (to whom), 
????? (to whom)  
???? (no/not),  
? (no/not /Hindi particle),  
?? (also /Hindi particle),  
??(only /Hindi particle),  
?? (then /Hindi particle),  
??? (why),  
??? (what /Hindi particle),  
??? ?(where /Hindi particle),  
?? (when),  
???? (here),  
???? (there),  
??? ?(where),  
???? (before),  
??? ?? (after),  
??? ?? (beginning),  
???? ?? (beginning),  
??? ?? (in the end),  
????? ?? (in the end). 
44
Given below are some sample outputs: 
 
(1) 
English sentence: 
I also enjoy working with the children's parents 
who often come to me for advice - it's good to 
know you can help. 
  
Aligned Hindi sentence: 
???? ???? ?? ???? - ????? ? ?? ??? ??? ???? ?? 
???? ???? ?? ?? ?? ???? ???? ???? ??? ?? - ?? 
?????? ???? ???? ?? ?? ?? ???? ?? ??? ?? ???? 
?? | 
 
The CPs identified in the sentence:  
i. ??? ???? (to work), ii. ???? ???? (to feel 
good: enjoy), iii. ???? ???? (to seek advice), iv. 
???? ???? (to feel happy: good), v. ??? ???? (to 
help) 
 
Here the system identified 5 different CPs all 
of which are correct and no CP in the sentence 
has gone undetected. The POS projection and 
word alignment method (Mukerjee et al, 2006) 
would fail to identify  CPs ???? ???? (to seek 
advice), and ???? ???? (to feel happy). 
 
(2) 
English sentence: 
Thousands of children are already benefiting 
from the input of people like you - people who 
care about children and their future, who have 
the commitment, energy and enthusiasm to be 
positive role models, and who value the opportu-
nity for a worthwhile career. 
 
Aligned Hindi sentence: 
?? ???? ??? ?? ?? ???? ?? ???? ????? ?? ???? ?? 
????? ?? - ?? ??? ?? ????? ???? ?? ??? ?????? ??? 
?? |  ???? ???[ ???? ?? ??? ??? ???? ?? ??????? 
, ?????? ?? ??? ?? ?? ?? ?? ???[? - ???? 
?????? ?? ?? ???? ?? | 
 
The CPs identified in the sentence: 
i. ???[ ???? (to be role model), ii. ?? ???? (to 
respect)  
 
Here also the two CPs identified are correct. 
    
It is obvious that this empirical method of 
mining CPs will fail whenever the Hindi light 
verb maps on to its core meaning in English. It 
may also produce garbage as POS of the preced-
ing word is not being checked. However, the 
mining success rate obtained speaks of these be-
ing in small numbers in practice.  Use of the 
?stop words? in allowing the intervening words 
within the CPs helps a lot in improving the per-
formance. Similarly, use of the ?exit words? 
avoid a lot of incorrect identification.   
5 Conclusions 
The simple empirical method for mining CPs 
outlined in this work, yields an average 89% of 
precision and 90% recall which is better than the 
results reported so far in the literature. The major 
drawback is that we have to generate a list of all 
possible light verbs. This list appears to be very 
large for Hindi. Since no POS tagging or statis-
tical analysis is performed, the identified CPs are 
merely a list of mined CPs in Hindi with no lin-
guistic categorization or analysis. However, this 
list of mined CPs is valuable to the lexicograph-
ers and other language technology developers. 
This list can also be used for word alignment 
tools where the identified components of CPs are 
grouped together before the word alignment 
process. This will increase both the alignment 
accuracy and the speed. 
The methodology presented in this work is 
equally applicable to all other languages within 
the Indo-Aryan family. 
References  
Anthony McEnery, Paul Baker, Rob Gaizauskas, Ha-
mish Cunningham. 2000. EMILLE: Building a 
Corpus of South Asian Languages, Vivek, A Quar-
terly in Artiificial Intelligence, 13(3):23?32. 
Amitabh Mukerjee, Ankit Soni, and Achala M. Raina, 
2006. Detecting Complex Predicates in Hindi using 
POS Projection across Parallel Corpora, Proceed-
ings of the Workshop on Multiword Expressions: 
Identifying and Exploiting Underlying Properties, 
Sydney, 11?18, 
Alex Alsina. 1996. Complex Predicates:Structure and 
Theory. CSLI Publications,Stanford, CA. 
Anvita Abbi. 1992. The explicator compound 
verb:some definitional issues and criteria for iden-
tification. Indian Linguistics, 53, 27-46. 
Debasri Chakrabarti, Vaijayanthi Sarma and Pushpak 
Bhattacharyya. 2007.  Complex Predicates in In-
dian Language Wordnets, Lexical Resources and 
Evaluation Journal, 40 (3-4). 
Debasri Chakrabarti, Hemang Mandalia, Ritwik Priya, 
Vaijayanthi Sarma and Pushpak Bhattacharyya. 
2008. Hindi Compound Verbs and their Automatic 
Extraction, Computational Linguistics 
(COLING08), Manchester, UK. 
45
Manindra K. Verma (ed.) 1993. Complex Predicates 
in South Asian Languages. Manohar Publishers and 
Distributors, New Delhi 
Miriam Butt. 1995. The Structure of Complex Predi-
cates in Urdu. CSLI Publications. 
Mirium  Butt and  Gillian Ramchand. 2001. Complex 
Aspectual Structure in Hindi/Urdu.  In Maria Lia-
kata, Britta Jensen and Didier Maillat (Editors), 
Oxford University Working Papers in Linguistics, 
Philology & Phonetics, Vol. 6. 
Miriam Butt, Tracy Holloway King, and John T. 
Maxwell III. 2003. Complex Predicates via Re-
striction, Proceedings of the LFG03 Conference. 
Miriam Butt and Wilhelm Geuder. 2001. On the 
(semi)lexical status of light verbs. In Norbert Corv-
er and Henk van Riemsdijk, (Editors), Semi-lexical 
Categories: On the content of function words and 
the function of content words, Mouton de Gruyter, 
Berlin, 323?370. 
Mona Singh. 1994. Perfectivity, Definiteness, and 
Specificity: A Classification of Verbal Predicates 
Hindi. Doctoral dissertation, University of Texas, 
Austin. 
Peter Edwin Hook. 1974. The Compound Verb in 
Hindi. Center for South and Southeast Asian Stu-
dies: The University of Michigan. 
Tara Mohanan. 1994. Argument Structure in Hindi. 
CSLI Publications, Stanford, California 
Venkatapathy Sriram and Aravind K. Joshi, 2005. 
Relative compositionality of multi-word expres-
sions: a study of verb-noun (V-N) collocations, In 
Proceedings of International Joint Conference on 
Natural Language Processing - 2005, Jeju Island, 
Korea, 553-564. 
 
 
 
 
46
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 48?54,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Automated Mining Of Names Using Parallel Hindi-English Corpus  
R. Mahesh K. Sinha 
Indian Institute of Technology, Kanpur, India 
rmk@iitk.ac.in 
 
Abstract 
Machine transliteration has a number of ap-
plications in a variety of natural language 
processing related tasks such as machine 
translation, information retrieval and ques-
tion-answering. For automated learning of 
machine transliteration, a large parallel cor-
pus of names in two scripts is required. In 
this paper we present a simple yet powerful 
method for automatic mining of Hindi-
English names from a parallel corpus. An 
average 93% precision and 85% recall is 
achieved in mining of proper names. The 
method works even with a small corpus. We 
compare our results with Giza++ word 
alignment tool that yields 30% precision and 
63% recall on the same corpora. We also 
demonstrate that this very method of name 
mining works for other Indian languages as 
well.  
1 Introduction 
Transliteration of names from one 
script/language to another has a number of appli-
cations in a variety of natural language 
processing tasks. These include machine transla-
tion, information retrieval, question-answering, 
multilingual directories, reservation charts, name 
lists etc.  
Machine transliteration has been studied by a 
number of researchers (Knight et al, 1998; Al-
Onaizan et al, 2002; Goto et al, 2003; Huang et 
al., 2003; Feng et al, 2004; Asif et al, 2006; 
Kuo et al 2006); Knight and Graehl(1998) use 
a modular approach in which five probability 
distributions are obtained for various phases of 
the transliteration - generation and pronunciation 
of English word sequences, conversion of Eng-
lish sounds to Japanese and then Japanese sounds 
to Katakana writing. Al-Onaizan and Knight 
(2002) present work on transliteration from Eng-
lish to Arabic. It relies on an existing named enti-
ty recognition system, which identifies possible 
named entities in English. A predefined phoneme 
mapping is used to generate all possible translite-
rations. The validity of transliterations is ex-
amined by rating it based on web counts, and co-
references by querying for the candidate transli-
teration on popular search engines such as 
Google. Huang et al (2003) have worked on ex-
tracting Hindi-English named entity pairs 
through alignment of a parallel corpus. Chinese-
English pairs are first extracted using a dynamic 
programming string matching. This Chinese-
English model is then adapted to Hindi-English 
iteratively, by using already extracted Hindi-
English named entity pairs to bootstrap the mod-
el. The precision achieved by this model is 
91.8%. Feng et al (2004) have used a maximum 
entropy model, in which an alignment probability 
for target/source named entities is defined over 4 
features - translation score, transliteration score, 
co-occurrence score and distortion score. The 
extraction of each feature is involved, but the 
maximum entropy model over these features is 
straightforward. Kuo et al (2006) uses a syllable 
alignment algorithm for cross-language syllable-
phoneme conversion. Asif et al (2006) have con-
sidered Bengali to English transliteration. They 
present a model which upon supervised training 
provides direct orthographical mapping. They 
report an accuracy of 69-89%. The success of all 
of these works depends upon the volume and 
nature of name corpora used.  
In this paper, we present a simple yet power-
ful method for mining of Hindi-English names 
from a parallel text corpus. In Hindi, the words 
are written as they are spoken i.e. it is phonetic in 
nature. On the other hand, English is non-
phonetic in the sense that there is a specified 
usage of a spelling for every word. Hindi names 
when written in English have a similar problem 
that the users have developed their own spellings 
for names that are commonly accepted. Though 
these English spellings do retain the phonetic 
structure of Hindi to a large extent, there are var-
iations that cannot be easily captured through 
rules. In table 1 a few illustrative examples are 
given. It is evident that the Hindi vowel modifi-
ers (called ?matra?) do not have unique mappings 
to English vowel combinations. It is difficult to 
derive simple mapping rules for these. The map-
48
ping of semivowels ?y? and ?v? and ?schwa? dele-
tions are highly contextual. However, for the 
consonants, the mappings are straightforward 
barring a few exceptions.  
Our strategy for automatic mining of Hindi-
English proper names from parallel corpus ex-
ploits this near-invariance in consonant mapping. 
We compare our results with Giza++ word 
alignment. In the following section, we present 
our design methodology followed by experimen-
tal results and conclusions.  
 
Hindi word in 
Devanagari 
Hindi word in 
IITK-Roman 
(Appendix-A) 
Corresponding commonly used 
English (Roman) transliteration 
Unacceptable English 
(Roman) transliterations 
Observations 
???? harISa Harish Hareesh / Hariesh / Hare-
ish 
i. long vowel map-
ping 
ii. ?schwa? deletion 
iii. consonant cluster 
mapping 
????? saMjIva Sanjeev or Sanjiv Sanjiiv / Sanjiev /Sanjeiv i. variation in long 
vowel mapping 
ii. ?schwa? deletion 
??????? PAlgunI Phalguni Falguni i. long vowel map-
ping 
ii. consonant map-
ping 
???? mUnA Moona Muna / Muuna / Moonaa preferred long vo-
wel mapping 
???? sUraja Suraj Sooraj / Suuraj / Suraz 
/Surag 
i. long vowel map-
ping 
ii. ?schwa? deletion 
iii. consonant map-
ping 
?????? somanAWa Somenath or Somnath Somanath / Somanaath i. long vowel map-
ping 
ii. ?schwa? deletion 
iii. peculiar vowel 
mapping to ?e?  
?????? saksenA Saxena Saksena i. long vowel map-
ping 
ii. preferred conso-
nant mapping 
????? xIkSiwa Dixit or Dikshit Deexit / Dikchhit etc. i. long vowel map-
ping 
ii. ?schwa? deletion 
iii. preferred conso-
nant mapping 
???? moxI Modi Modee / Modii / Mody 
etc. 
preferred long vo-
wel mapping 
?????? soniyA Sonia Soniya preferred semivowel 
mapping 
?????? 
??? 
rAmaxeva 
xeva 
Ramdeo 
Deva 
Ramdev /Ramadev / Ra-
madeo 
Deo / Dev  
preferred semivowel 
mapping 
 
Table 1: An Illustration of Hindi to English Name Transliteration Variations 
 
2 Hindi-English Name Corpus Creation 
We use an aligned parallel Hindi-English text 
corpus for creation of Hindi-English name cor-
pus. The size of the corpus is immaterial and it 
could be as small as a few lines. The sentence 
alignment also need not be perfect as long as the 
aligned set of sentences contain the translated 
sentences. Our methodology is even capable of 
capturing to some extent mapping between old 
city names with new city names such as Bombay 
and Mumbai. Figure 1 depicts the process of 
name mining diagrammatically. 
The Hindi text written in Devanagari is first 
converted to IITK-Roman form (appendix-A). 
IITK-Roman has become a de-facto standard 
used by a large number of researchers in India. 
The conversion to IITK-Roman form is 
straightforward and is a direct representation of 
UTF-8 or ISSCII-8 coding schemes without any 
49
loss of constituent information in terms of pho-
nemes or constituent symbols. The usage of 
IITK-Roman form is more for entry and pro-
gramming convenience. 
 
 
As outlined earlier, in order to simplify the 
learning process, the trivial consonant (C) and 
consonant cluster (C
+
) mappings are provided 
separately in the form of rules. The main conso-
nant mappings from IITK-Roman to English are 
shown in figure 2. 
 
k(?)?k/c/ck; K(?)?kh; g(?)?g; G(?)?gh; 
f(?)?n;  
c(?)?ch; C(?)?chh; j(?)?j/z; J(?)?jh; F(?)?n;  
t(?)?t; T(?)?th; d(?)?d; D(?)?dh; N(?)?n;  
w(?)?t; W(?)?th; x(?)?d; X(?)?dh; n(?)?n;  
p(?)?p; P(?)?ph/f; b(?)?b; B(?)?bh; m(?)?m;  
y(?)?y; r(?)?r; l(?)?l; v(?)?v/w;  
s(?)?s; S(?)?sh; R(?)?sh; h(?)?h;  
kR(?)?x; jF(?)? gy; dZ(?) ?r;  
q (?)??r/k;  M(?)??n; H(??)?h;  
ks(??)?x; kZ (?)?q; jZ (?)?z; PZ (?)?f  
Figure 2: IITK-Roman to English consonant mapping 
 
A (??)? a;  i (??)? i; I (??)? i;   u (??)?u;   
U(??)?u;   e(?)??e;  E(??)?ai;   o (??)?o;  
O(??)?ou;   
Figure 3: IITK-Roman to English vowel mapping 
 
The consonant mappings are exploited in hy-
pothesizing plausible name transliterations. Fol-
lowing steps explain the process of mining of 
Hindi-English name pairs:  
 
i. For each aligned line, collect all the words 
in the English sentence that have first letter in 
upper case. These are potential English proper 
names excepting the first word that may or may 
not be a proper name.  
 
ii. For each word, apply consonant cluster 
map-ping from English to Hindi (using the map-
ping as given in figure 2 in reverse fashion). In 
absence of a defined mapping, the consonant is 
ignored. This yields one or more plausible Hindi 
names as there are one to many reverse map-
pings. The following three mappings are very 
rare and so are ignored for efficiency: f?n; 
F?n; H?h. Further, the semivowel ?y? is not 
treated as a consonant if it is the last character of 
the word.  It is treated as a consonant if it is pre-
ceded or followed by a vowel.  
 
iii. Collapse each of the above word into be-
ing part of the plausible Hindi name by deleting 
all vowels in it.  
 
iv. Each collapsed plausible Hindi name, as 
de-rived in the preceding step, is string-matched 
with the Hindi words in the corresponding 
aligned Hindi line. The process of matching 
looks for maximal ordered string match omitting 
the Hindi vowels.  
? In case no match is found, it is ig-
nored.  
? In case of multiple matches, mi-
nimal word length distance is tak-
en as the criterion for selection.  
Aligned Parallel Text Corpus 
Convert to IITK-Roman form 
Collect all English words starting with upper case 
For each word, apply consonant cluster map-
ping using mapping of fig. 2 in reverse fashion 
Collapse each of the above word by  
deleting all intervening vowels
Each collapsed word is string matched  
with the Indian language words in  
the corresponding aligned Indian language line. 
Select the maximal ordered match word.  
In case of a tie, match the intervening  
vowels using mapping of figure 3 
Perform Smoothening & Filtering on the data 
collected from the entire corpus (see text) 
Figure 1: Schematic flow diagram of the 
name mining process 
50
? In order to avoid false matching, 
length must be greater than 1 and 
at least 30% of characters must 
match.  
? Further, a constraint that the first 
character of the mapped words 
must both be either a consonant or 
both be a vowel, is imposed. 
 
v. In case two or more matches have same 
maximal length match, then the maximal match 
with the plausible un-collapsed (i.e. including the 
intervening vowels with their mapping using fig-
ure 3) Hindi name is matched and the ordered 
maximal length match is selected. Usually such a 
situation is encountered when two or more simi-
lar names are encountered in the aligned lines. 
An example of this would be say the two names 
?Hindi? and ?Hindu? occur in the same sentence. 
These will get matched to the same degree by 
step (iv) above. The way to resolve this is to also 
take intervening vowels into account. The IITK 
Roman vowel mapping to English used here is 
given in figure 3. It may be noted that only one 
vowel mapping out of the many possibilities, has 
been taken. This is the most frequent mapping 
and is taken as the baseline vowel mapping. 
 
vi. The final stage is that of filtering and 
smoothening.  
? For every English name, the corres-
ponding Hindi name mapping(s) with 
their frequency of occurrence is rec-
orded for the entire corpus.  
? In case of multiple mappings, each 
mapping is examined. The suffix that 
represent the post-position markers 
such as ne (ne ??), ka(kA ??), ko (ko 
??), ki(kI ??), ke(ke ??), se(se ??), 
men(meM ??), par(para ??), vala (vA-
lA ????) etc. in Hindi  are stemmed. 
Further, other morphological co-
joiners (?sandhi?) for other Indian 
scripts are also stemmed.  
? After stemming, the frequency is re-
computed.  
? The mapping with the highest fre-
quency is selected.  
 
Although these post-position markers in Hindi 
are separate words and are usually written with a 
preceding blank, many a time it is not properly 
observed and appears as a suffix. 
 
Given below is an illustrative example:  
English sentence:  
It goes daily from Delhi to Mumbai, Bangalore, 
Varanasi and Lucknow.  
Aligned Hindi Sentence:  
?? ?????? ????? ?? ?????, ??????, ??????? 
?? ???? ???? ?? ?  
(Converted to IITK-Roman)  
yaha rojAnA xillI se mumbaI, bEMgaluru,  
vArANasI Ora laKanaU jAwI hE.  
Probable English Proper Nouns:  
It Delhi Mumbai Bangalore Varanasi Lucknow  
Plausible Hindi Names after reverse consonant 
substitutions:  
{it iw} {delhi xelhi} {mumbai}  
{bangalore baMgalore} {varanasi varaNasi va-
raMasi}{luknov lukNov lukMov}  
Collapsed plausible corresponding Hindi Names:  
{t w} {dlh xlh} {mmb} {bnglr bMglr}  
{vrns vrNs vrMs} {lknv lkNv lkMv}  
Hypothesized Hindi Names after matching:  
Delhi? xillI ????? ;  
Mumbai ?mumbaI ?????;  
Bangalore ?bEMgaluru ??????;  
Varanasi ? vArANasI ???????;  
Lucknow ?laKanaU ????.  
In the above example, the first word ?It? does not 
get matched to any of the Hindi words because of 
the constraint that the matching length has to be 
greater than 1 and a minimum of 30% of length 
must match.  
It is interesting to note the method outlined 
captures even those names that differ in their 
forms or spelling such as Delhi & ????? (xillI), 
Bangalore & ?????? (bEMgaluru) and Lucknow 
& ???? (laKanaU) based on maximal match. 
For transliteration, these have to made table dri-
ven.  
Given below is an illustration of step (v) of 
the procedure: 
English sentence:  
Mr. Handa speaks Hindi and he is a Hindu. 
Aligned Hindi Sentence:  
?? ????? ????? ????? ?? ?? ?? ?? ???? ??? ?  
(Converted to IITK-Roman)  
SrI hAMdA hinxI bolawe hEM Ora vaha eka hin-
xU hEM.  
51
Probable English Proper Nouns:  
Mr Handa Hindi Hindu. 
Plausible Hindi Names after reverse consonant 
substitutions:  
{mr mq} {haNda handa haMda haNxa hanxa 
haMxa} {hiNdi hindi hiMdi hiNxi hinxi hiMxi} 
{hiNdu hindu hiMdu hiNxu hinxu hiMxu}    
Collapsed plausible corresponding Hindi Names:  
{mr mq} {hNd hnd hMd hNx hnx hMx} {hNd hnd 
hMd hNx hnx hMx} {hNd hnd hMd hNx hnx 
hMx}    
Hypothesized Hindi Names after matching:  
Handa? hAMdA ?????; hinxI ?????; hinxU ????;?  
Hindi ? hAMdA ?????; hinxI ?????; hinxU ????;? 
Hindu ? hAMdA ?????; hinxI ?????; hinxU ????;? 
Now since these are equiprobable multiple 
matches, step (v) will get invoked. For each 
matching target word, the vowel mapping of fig-
ure 3 is applied. This yields the following: 
hAMdA ?????? haMda;  
hinxI ??????hinxi;  
hinxU ??????hinxu; 
Now the English source word is matched and 
minimal distance word is selected. This finally 
yields the desired result as follows: 
Handa? hAMdA ?????;   
Hindi ?  hinxI ?????; 
Hindu ?  hinxU ????;? 
 
Given below is an illustration of step (vi) of 
the procedure: 
Suppose in the entire corpus the city name 
?Agra? yields the following matches: 
i. Agra ?AgarA ????; count=20; 
ii. Agra ?Agare ????; count=12; 
iii. Agra ?AgarAse ??????; count=5; 
iv. Agra ?AgarAmeM ??????; count=4; 
v. Agra ?AgarAkA ??????; count=2; 
Now the process of smoothening will convert 
AgarAse ?????? to AgarA ???? by deleting 
post-position suffix ?se???; AgarAmeM ?????? 
to AgarA ???? by deleting post-position suffix 
?meM???; and AgarAkA ?????? to AgarA ???? 
by deleting post-position suffix ?kA???.  This 
will yield the final table as follows: 
i. Agra ?AgarA ????; count=31; 
ii. Agra ?Agare ????; count=12; 
The filtering process will select the mapping 
of Agra ?AgarA ????. 
It may be noted that the word Agare ????  is 
the oblique form of the name AgarA ???? and 
such usage is very common in Indian languages. 
A morphological processing is required to make 
the conversion and this has not been imple-
mented in the current implementation. 
3 Experimentation and Results 
For experimentation, we took a text that con-
tained a lot of names. Two sentence aligned files 
were created from a Indian freedom fighters? 
story. This story contains a lot of names of indi-
viduals and places in the text. The results of our 
name mining methodology are summarized in 
table 2. We also used Giza++ word alignment 
tool (Och and Ney, 2003) on the same files and 
collected figures pertaining to the alignment of 
proper names in Hindi and English. In case of 
multiple mappings for a proper name in which 
one of them is a correct mapping, it is considered 
as ?false positive?. These results are also shown 
in table 2 for comparison. 
 
File1 File2
Name?
map?
ping?
Giza++? Name?
mapping?
Giza++
Total?no.?of?
words?
2439 2439? 4909 4909
Total?no.?of?
Names(N)?
192 192? 343 343
Correct?map?
ping?(TP)?
155 57? 262 74
Incorrect??
mapping?(FP)?
13 117? 35 200
Not?captured?
(FN)?
24 18? 46 69
Accuracy?
(TP/N)?
0.8073 0.2969? 0.7638 0.2157
Precision?
(TP/(TP+FP))?
0.9226??? 0.3276? ?0.9495 0.2701
Recall?
(TP/(TP+FN))?
0.8659 0.7600? ?0.8506 0.5175
F?measure?
(2PR/(P+R))?
0.8934 0.4578? ?0.8968 0.3549
Table 2. Result for name mining and 
word-alignment algorithms. 
 
52
Our experimentation reveals that our name 
mining methodology yields a precision of 92 to 
95% and a recall of 85 to 86% resulting in F-
measure of 0.89. On the other hand, the Giza++ 
word alignment tool yields a precision of 27 to 
33% and a recall of 52 to 76% resulting in F-
measure of 0.35 to 0.46. The results are a clear 
demonstration of effectiveness our approach of 
mining proper names from the parallel Hindi-
English corpora. Most of the errors using our 
approach have been found to be due to short 
names, words not properly delineated in the tar-
get text, morphological changes in the target text, 
the first word in English not being a proper noun 
or different forms of names that are used denot-
ing the same place. It should be noted that our 
approach works even for a corpus of a few lines 
as it is primarily a rule-based method.  
The method as outlined above is equally appli-
cable to other Indian languages. In order to dem-
onstrate this, we conducted a limited experiment 
with Punjabi and Bengali languages. A corpus of 
about 200 sentences was taken. The same pro-
gram as was used for Hindi with no change in the 
mapping tables was used for the experimentation.  
The results obtained were remarkable and a per-
formance of about 90% and 70% of correct min-
ing of proper names for Punjabi and Bengali 
respectively is yielded. The poorer performance 
in case of Bengali is primarily due to morpholog-
ical changes that take place in the proper names 
based on their role in the sentence. Unlike in 
Hindi where the post-positions are written sepa-
rately or simply suffixed, for most of the other 
Indian languages, these post-position markers are 
co-joined (?Sandhi?) with the preceding word 
leading to a morphological change. This is less 
frequent in Punjabi. Further, Bengali has no con-
sonant for ?va? ? and this is mapped to ?ba? ?. 
So some consonant mapping changes are re-
quired to yield better results for another Indian 
language but the methodology remains the same.  
Here are some example mappings:  
Bengali: 
   i. Cath hasn't phoned since she went to Berlin. 
bArline yAoyZA Weke kyAWa Pona kareni? 
??????? ??o?? ???? ???? ???? ?????? 
  ii. Jo was the next oldest after Martin. 
mArtinera parei badZa Cila jo? 
???? ??? ???i ?? ??? ???? 
Names extracted:  
  Cath ? kyAWa ????;    
  Berlin ? bArline ???????  
Here the correct mapping is ?bArlina ??????? but 
the name has got morphologically transformed to 
?bArline ???????? (to Berlin) based on co-joining 
of post-position marker. 
  Martin ? mArtinera ???? ???  
Here the correct mapping is ?mArtina ???? ?? 
but the name has got morphologically trans-
formed to ?mArtinera ???? ???? (after Martin) ) 
based on co-joining of post-position marker. 
 
Punjabi: 
i. Sam Sand Dunes is one of the best nature's gift 
to the human beings. 
   sEma sEzda diUnasa manuYKa xe laI prakira-
wI xe saraba SreSata wohaPZiAz viYcoz iYka 
hE. 
  ??? ??? ????? ????? ?? ?? ??????? ?? ??? 
????? ??????? ????? ??? ??? 
ii. Bikaner is located to the north of Rajasthan 
popularly known as a camel country. 
bIkAnera rAjasaWAna xe uYwara viYca sa-
Wiwa hE awe saXAraNa wOra we UTa-praxeSa 
xe rUpa viYca jANiA jAzxA hE. 
  ?????? ? ??????? ?? ??? ???? ???? ?? ?? ?
????? ??? ?? ??-????? ?? ??? ???? ????? ??? 
??? 
Names extracted:  
 Sam ? sEma ??? ;   
 Sand ? sEzda ??? ;  
 Dunes ? diUnasa ????? ;  
 Bikaner ? bIkAnera ?????? ? ; 
 Rajasthan  ? rAjasaWAna ??????? 
4 Conclusions 
In this paper, we have presented a simple yet 
powerful method for mining of Hindi-English 
proper name corpus with a success of mining 
being 93% precision. In contrast, GIZA+ word 
alignment tool on same sized corpus yielded 29% 
precision. The proposed method works even for a 
single line text. Moreover, there is no strict re-
quirement of sentence alignment as it works 
equally well for one to many and many to many 
sentence alignment as long as the target group of 
sentences contain the corresponding translation. 
53
Thus it works under noisy environments where 
sentence boundaries are not correctly identified. 
Our approach also yields a table of similar old 
city names with new city names that is very fre-
quently encountered in Indian context. 
The methodology outlined in this paper for au-
tomatic mining of proper names are equally ap-
plicable to all Indian languages as all Indian 
scripts are phonetic in nature in the same way as 
Devanagari (used for Hindi). We have also dem-
onstrated that this very method of name mining 
without making any changes in the program or 
the mapping table as used for Hindi, works for 
other Indian languages. Our limited experimenta-
tion for Punjabi and Bengali and have yielded 
performance of 90% and 70% respectively of 
correct mining of proper names. 
There are several other advantages of our ap-
proach. Since the proper name mining is cap-
tured with a high accuracy over a rough or noisy 
aligned corpus, it is possible to use these as anc-
hors (the same way as numerals) for improve-
ment of the alignment results. These anchors will 
also be useful in word alignment programs for 
speedy convergence. Accurate word alignment is 
crucial to the success of any statistical machine 
translation system. Another byproduct of our 
approach is that it also yields the table of old city 
names with new city names.  In India, a large 
number of city names that were used during Brit-
ish time, have undergone a change and most of 
these changes are phonetic variations of the old 
names.  
Acknowledgements  
Author is thankful to Saleem Siddiqui and Abhay 
Singh for experimentation and testing. 
References 
Al-Onaizan Y. and Knight K.2002. Translating 
Named Entities Using Monolingual and Bilingual 
Resources. Proceedings of  ACL 2002, 400-408. 
Ekbal Asif, Sudip Kumar Naskar and Sivaji Bandyo-
padhyay. 2006. A Modified Joint Source-Channel 
Model for Transliteration, Proceedings of  ACL 
2006. 
Feng Dong-Hui, Ya-Juan Lv, and Ming Zhou. 2004.A 
New Approach for English-Chinese Named Entity 
Alignment. Proceedings of  ACL 2004. 
Goto I., N. Kato, N. Uratani, and T. Ehara. 2003. 
Transliteration considering Context Information 
based on the Maximum Entropy Method. Proceed-
ing of the MT-Summit IX, New Orleans, USA, 125-
132. 
Huang Fei, Stephan Vogel, and Alex Waibel. 2003. 
Extracting Named Entity Translingual Equivalence 
with Limited Resources. ACM Transactions on 
Asian Language Information Processing (TALIP), 
2(2):124?129. 
Knight K. and J. Graehl. 1998. Machine Translitera-
tion, Computational Linguistics, 24(4): 599-612. 
Kuo Jin-Shea , Haizhou Li and Ying-Kuei Yang. 
2006. Learning Transliteration Lexicons from the 
Web, The 44th Annual Meeting of Association for 
Computational Linguistics (COLING-ACL2006), 
Sydney, Australia, 1129 ? 1136. 
Och Franz Josef and Hermann Ney. 2003. A Syste-
matic Comparison of Various Statistical Alignment 
Models, Computational Linguistics, 29( 1):19-51.  
    (http://www.fjoch.com/GIZA++.html) 
Mansur Arbabi, Scott M. Fischthal, Vincent C. 
Cheng, and Elizabeth Bar. 1994. Algorithms for 
Arabic name transliteration. IBM Journal of Re-
search and Development, 38(2): 183-193. 
Paola Virga and Sanjeev Khudanpur. 2003. Translite-
ration of Proper Names in Crosslingual Informa-
tion Retrieval. Proceedings of the ACL 2003 
Workshop on Multilingual and Mixedlanguage 
Named Entity Recognition, Sapporo, Japan, 57-60. 
 
Appendix-A: IITK-Roman code for Hindi 
(Devanagari) 
? ? ? ?  ? ? ? ? ? ? ?  
     ?? ?? ?? ? ?? ? ? ?? ?? ??? ??  ? ???  ? ?? ?? ? 
a    A   i     I     u   U  q   e  E   o   O  M  H   V  z   Z  
 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? 
k   K   g  G  f    c   C   j  J   F   t   T  d   D  N  w W  x  X  
n 
 
? ? ? ? ? ? ? ? ? ? ? ? ?   
 p  P  b  B   m   y  r   l   v   s   S  R  h   
          
54
Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 95?101,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Improving Statistical Machine Translation through co-joining parts of 
verbal constructs in English-Hindi translation 
 
 
Karunesh Kumar Arora R Mahesh K Sinha 
CDAC, Anusandhan Bhawan JSS Academy of Technical Education, 
C 56/1, Sector 62, C 20/1, Sector 62, 
Noida, India Noida, India 
karunesharora@cdac.in sinharmk@gmail.com 
 
 
Abstract 
Verb plays a crucial role of specifying the 
action or function performed in a sentence. 
In translating English to morphologically 
richer language like Hindi, the organization 
and the order of verbal constructs 
contributes to the fluency of the language. 
Mere statistical methods of machine 
translation are not sufficient enough to 
consider this aspect. Identification of verb 
parts in a sentence is essential for its 
understanding and they constitute as if they 
are a single entity. Considering them as a 
single entity improves the translation of the 
verbal construct and thus the overall 
quality of the translation. The paper 
describes a strategy for pre-processing and 
for identification of verb parts in source 
and target language corpora. The steps 
taken towards reducing sparsity further 
helped in improving the translation results.  
1 Introduction 
With the availability of parallel content, increased 
memory and processing speed, there has been 
growing trend moving towards Statistical Machine 
Translation. Most of the phrase based machine 
translation systems are based on the noisy-channel 
based IBM models (Koehn, Och & Marcu, 2003,   
Zens et al, 2004). Phrases refer to a number of 
consecutive words that may not be a valid syntactic 
phrase but are learnt through the statistical 
alignment between two languages. English and 
Hindi have differing syntactical structure and pose 
great challenge in aligning phrases of the two 
languages. The former follows SVO pattern while 
the later adheres to the SOV pattern. Hindi being 
morphologically richer offers several verbal 
constructs governed through Tense, Aspect and 
Modality (TAM). The non-monotonocity between 
the two languages causes inferior alignment of 
phrases especially verbal constructs. 
There have been efforts towards single 
tokenization of MWE parts. Ueffing and Ney, 
2003 reported use of POS information for SMT to 
morphologically richer language. They tried to 
transform the source language while the approach 
proposed here attempts transformations on both 
source and target laguage sides. Recent related 
works use statistical measures like Mutual 
Information and Log Likelihood Ratio (Seretan 
and Wehrli, 2007) to know the degree of cohesion 
between constituents of a MWE. These require 
defining threshold value above which the extracted 
phrase is qualified as a MWE.  
Minkov et al (2007) utilized the rich syntactic 
and morphological analyzers to generate the 
inflections. Hindi lacks availability of robust 
parsers and complex morphological analyzers.  
The paper describes the process of identifying 
verbal constructs of both languages and grouping 
them in single units to reduce the search space. For 
identification of the verbal constructs, the POS 
information is utilized with simple combining rules 
to make verb phrases. This yields better alignment 
of verbal phrases and results in more grammatical, 
fluent and acceptable translations. Besides that, the 
data sparseness generated from chunking is 
95
handled through extending the phrase table with 
verbal parts entries.  
The paper is organized in sections, describing 
the phrase based SMT in brief, Hindi language and 
its verbal properties followed by sections 
describing identification of verbal constructs in 
English and Hindi. Further to it, corpus and pre-
processing activities are detailed alongwith the 
experimental setup, process adopted to reduce 
sparcity, the translation process, observations and 
conclusion. 
2 Overview of SMT 
Candide SMT system [Brown et al, 1990], 
presented by the IBM researchers paved the path 
for statistical approach to machine translation.  
In statistical machine translation, we are given a 
source language sentence S = sI1 = s1 . . . si . . . sI , 
which is to be translated into a target language 
(?English?) sentence T = tJ1 = t1 . . . tj . . . tJ.  
Statistical machine translation is based on a noisy 
channel model. It considers T to be the target of a 
communication channel, and its translation S to be 
the source of the channel. System may generate 
multiple translation sentences options and the 
problem of translation becomes identifying 
sentence T which fits as the best translation of the 
source sentence S. Hence the machine translation 
task becomes to recover the source from the target. 
So, we need to maximize P(T|S). According to the 
Bayes rule, 
 
  
 
As, P(S) is constant,  
 
 
Here,  P(s|t) represents Translation model and 
P(t) represents language model.  Translation model 
plays the role of ensuring translation faithfulness 
and Language model to ensure the fluency of 
translated output. 
3 Hindi language and its verbal 
properties  
Indian languages are classified in four major 
families: Indo-Aryan (a branch of the Indo-
European family), Dravidian, Austro-Asiatic 
(Austric), and Sino-Tibetan, with the 
overwhelming majority of the population speaking 
languages belonging to the first two families. 
There are 22 languages listed in eighth schedule of 
constitution of India. The four major families are 
different in their form and construction, but they 
share many orthographic similarities, because their 
scripts originate from Brahmi (Ishida, 2002).  
Hindi language belongs to the Indo-Aryan 
language family. It is spoken in vast areas of 
northern India and is written in Devanagari script. 
In Hindi, words belonging to various grammatical 
categories appear in lemma and inflectional forms. 
Hindi Verbal constructs system is based on the 
TAM of the action. The Verbal costructs are 
formed by placement of auxiliary verbs after the 
main verb. The main verb that carries the lexical 
meaning may appear in the root or inflected form. 
Auxiliary verbs of the main verb denote the TAM 
property of the verbal construct.  
Tense is a grammatization of the relations 
between time of some event and the refrence time. 
Aspect markers are semantically very sensitive and 
often convey subtle meanings and nuances that are   
not generally expressed through simple lexical 
words. Here we look at the two example sentences,  
1. ?? ??? ?? ???? ???? ??  
    vaha din bhar baithaa rahataa hai  
    (?He remains seated whole day?).   
2. ?? ???-??? ????? ???? ??  
    vaha baar-baar baithtaa rahataa hai 
    (?He sits frequetly?)  
Here, aspect marker ?? ?? ?yaa raha? in first 
sentence, denotes the resultant state of the action 
and ?? ?raha? gives perception of a longer period of 
time. While in a slightly modified second sentence, 
the aspect marker ?? ?? ?taa raha? gives the sense 
of repetition or infinity of the action and ?? ?raha? 
gives the perception of a time spread.  
The mood reflects speaker?s attitude towards the 
action and is manifested in many ways in a 
language. In Hindi the moods can be of Imperative, 
? ? ? ? ? ?
? ?sP
tPtsP
stPt
tt
*|
maxarg|maxarg* ??
? ? ? ?tPtsPt
t
*|maxarg* ?
96
Subjunctive, Indefinite and definite potential, 
conditional and future etc. Here we look at the 
following three sentences. 
1. ? ???   tu padh  (?You read?) 
2. ?? ????  tu padh (?You read?) 
3. ?? ???? tu padh (?You read?) 
All the above three sentences are imperative in 
nature but there is subtle difference in speaker?s 
attitude. The first sentence is the impolite form of 
expression, the second one is common form and 
the third sentence is the polite form of expressing 
the same thing.  
All constituents of the verbal constructs are 
obligatory. Semantically TAM markers are so 
closely interlinked that it would be appropriate to   
treat them as a single entity rather than treating 
them sperately. Besides that, the main verb appears 
frequently in compound and conjunct forms in the 
verbal constrcuts (Singh, 2010). Compound verbs 
follow the pattern of verb-verb (V-V) combination 
while conjunct verbs are formed with either noun-
verb (N-V) or adjective-verb (A-V) combinations. 
In V-V expressions the first verb word carries 
verbal stem while successive verb words play the 
role of auxiliary or light verbs (LV). The LVs 
loose their independent meaning and are used to 
reflect the shade of main verb. The compound and 
conjunct verb expressions are also referred as 
complex predicates (CP). The CPs are multi-word 
expressions (MWEs) which may be compositional 
or non-compositional in nature (Sinha, 2011). 
These should be treated as a single verbal unit to 
infer the intended meaning or semantics. The CP 
adds to the expressiveness of the expression but 
pose difficulty for automatic identification.  
4 Identification and treatment verbal 
constructs  
The elements of verbal constructs, if treated as 
individual words leave too many entries in the 
sentences to get algned through statistical 
alignment. This makes the probability distribution 
unfocussed. Co-joining parts of verbal constructs 
reduces the sentence length and thus helps in better 
alignment. 
4.1 English verbal constructs 
The Stanford POS tagger (Kristina Toutanova et 
al., 2003) is used for tagging words in a sentence 
with their POS categories. The POS tags are based 
on Penn Treebank POS tagset (Mitchell et al, 
1993). The verbal parts to be chunked together are 
identified with the help of a set of rules. Some of 
these rules are listed in the Table 1. As an example, 
the rule ?get NP VBN? specifies, that if Noun 
Phrase appears in between the word ?get? and 
VBN, this is considered as a verbal construct. 
 
POS based Verb Chunking Rules 
VBP/VBD/VBZ  VBG 
MD not VB 
get  NP VBN 
 
Table 1: Sample rules for identiying English 
Verbal constructs 
These rules are impletemented in the form of a 
Finite State Machine (FSM). The NP-phrase 
appearing in between the verb construct parts is 
identified and FSM implementation helps in 
achieving this. Similarly, the model auxiliaries like 
?can be? are also co-joined with successive verbs. 
These simple rules help in identifying the 
constituents of verbal constructs. The negation 
markers or noun phrases that appear in between 
verbal constructs are moved out to reduce sparsity. 
Table 2 shows some English verbal constructs and 
how these are co-joined. 
 
Verbal Constructs Co-joined Verbal Constructs 
is going is_going 
can not be done not can_be_done 
get the work done get_done the work 
 
Table 2: Sample English Verbal constructs 
4.2 Identification of Hindi verbal constructs 
For identifying the Hindi verbal constructs, a 
combination of POS tagging and presence of the 
TAM markers appearing as verb ending sequences 
are used. The POS tags are based on modified 
Penn Treebank POS tagset. The POS tagging 
identifies possible verbal parts to be chunked, 
while the TAM rules help in confirmation of them. 
Table 3 lists some of the TAM rules. Here $ 
indicates the presence of main verb stem. 
97
Verbal constructs TAM Rules 
?? ???? ??  
jaa saktaa hai 
$_????_?? 
$_saktaa_hai 
??? ??? ?? 
jaane mat do 
?? $? ?_?? 
mat $ne_do 
???? ?? ??? ???? 
khaaya jaa rahaa hogaa 
$??_??_???_???? 
$yaa_jaa_rahaa_hogaa 
?? ??? ???? ?? 
jaa nahi rahaa hai 
??? ?$_???_?? 
nahi $_rahaa_hai 
???? ?? ?? 
jaataa to thaa 
?? $??_?? 
to $taa_thaa 
 
Table 3: Sample rules for identiying Hindi Verbal 
constructs 
Table 4 shows some of the verbal constrcts and 
their co-joined forms after processing. The 
negation markers, such as, ??? ? nahi (?not?) and 
particles, such as, ?? (emphatic marker) occurring 
in between are moved out of the verbal expressions 
to reduce the sparsity.  
 
Verbal Constructs Co-joined Verbal Constructs 
?? ???? ?? 
jaa saktaa hai 
??_????_?? 
jaa_saktaa_hai 
??? ??? ?? 
jaane mat do 
?? ??? ?_?? 
mat jaane_do 
???? ?? ??? ???? 
khaayaa jaa rahaa 
hogaa 
????_??_???_???? 
khaaya_jaa_rahaa_hogaa 
?? ???? ??? ?? 
jaa nahi rahaa hai 
??? ???_???_?? 
nahi jaa_rahaa_hai 
???? ?? ?? 
jaataa to thaa 
?? ????_?? 
to jaataa_thaa 
 
Table 4: Sample Hindi Verbal constructs 
Complex Predicates are identified using the 
approach of Sinha (2009). Here, we make use of 
parallel corpus, English-Hindi dictionary of Light 
Verbs and TAM rules. Table below shows some 
sample Complex predicates in Compound and 
Conjuct forms and their treatment. 
 
 
 Compound Verbs  
Verbal Constructs Co-joined Verbal Constructs 
??? ??  
baith jaa 
???_??  
baith_jaa 
?? ???? ???? 
padh liyaa hogaa 
??_????_???? 
padh_liyaa_hogaa 
?? ???? 
kar diyaa 
??_???? 
kar_diyaa 
Conjunct Verbs 
Verbal Constructs Co-joined Verbal Constructs 
????? ?? 
parikshaa de 
?????_?? 
parikshaa_de 
??? ?? ??? ?? 
baat kar rahaa hai 
??? _??_???_?? 
baat_kar_rahaa_hai 
??? ?? ???  
band ho gayaa 
???_??_???  
band_ho_gayaa 
 
Table 5: Sample Hindi complex predicates  
5 Corpus and pre-processing 
Basic Travel Expressions Corpus (BTEC) 
containing travel conversations is used for 
performing the experiments (Kikui, 2006). This 
contains travel expressions which are generally 
used when a person travels to another country and 
covers the utterances of potential subjects in travel 
situations. The expressions contained more than 
one sentence in single expression. These have been   
separated by sentence end markers (dot). Such 
sentences have been treated as separate sentence 
entities. This increased the number of independent 
sentences in parallel corpus. The Tables 6 and 7  
list corpus statistics. 
 
Corpus  Training Development Test 
English: 
# sentences 19972 2343 2371 
# words 153066 17806 18257 
# avg words       
/ sentence 
7.7 7.6 7.7 
Hindi: 
# sentences 19972 2043 2071 
# words 171347 17774 17811 
# avg words       
/ sentence 
8.6 8.7 8.6 
 
Table 6: Corpus Statistics before pre-processing 
98
Corpus  Training Development Test 
English: 
# sentences 24056 2581 2575 
# avg words       
/ sentence 
6.3 6.4 6.3 
Hindi: 
# sentences 24056 2581 2575 
# avg words       
/ sentence 
7.2 7.1 7.2 
 
Table 7: Corpus Statistics after pre-processing 
The average sentence length in the English 
corpus before pre-processing was 7.7 words per 
sentence and after pre-processing it came down to 
6.3 words per sentence. Hindi corpus had 8.7   
words per sentence and it became 7.2 words per 
sentence after pre-processing.  
The pre-processing activity also included 
expanding of common abbreviated expressions e.g. 
I?ll to ?I will? etc. This has been performed with a 
set of simple expansion rules. Besides that, dots 
appearing after titles are also replaced with hash 
(#), to avoid being treated them as sentence end-
markers. 
6 Experimental setup 
For the training of the statistical models, standard 
word alignment GIZA++ (Och & Ney, 2003) and 
language modelling toolkit SRILM (Stolcke, 2002) 
tools were used. For translation, MOSES phrase-
based SMT decoder (Koehn, 2007) has been used. 
For evaluation, the automatic evaluation metrics, 
BLEU (Papineni, 2002) was applied to the 
translation output. 
7 Translation process 
The overall process can be classified as Training 
and Testing processes. The training process 
describes the steps involved in building models. 
These steps include ? pre-processing of training 
corpus, POS tagging source and target language 
training corpus, chunking words forming the 
verbal constructs, building translation and 
language models.  
 
Figure 1: Training process 
Testing process describes steps while 
translating. It involves - pre-processing of test 
corpus, POS tagging of test corpus, chunking the 
words forming the verbal constructs and searching 
words in the vocabulary of training models. If 
some words are unseen but are lexical words of 
verbal constructs, they are handled as described in 
section 8 below.  
 
Figure 2: Testing process 
99
8 Handling sparsity 
Due to limited size of parallel corpus used for 
training the models, it is quite probable that some 
verbal constructs may appear which is unseen by 
the training model and is out of vocabulary (OOV). 
The probability of such occurrence increases due 
to the co-joining of words forming verbal 
constructs. To meet this situation, templates of 
different verbal constructs with their translations 
are used. The Table 8 shows some sample 
templates with their translations. 
If verbal construct is OOV, it is changed to its 
translation template form. After that, its equivalent 
translation is picked up and is replaced in the 
sentence to be translated. As an example, if the 
verbal construct ?would_have_been_cleaning? is 
OOV. It is changed to its template form   
would_have_been_VBG and its respective 
translation VB_???_???? is picked up from the 
translation template table. Now, with the help of 
English-Hindi dictionary, translation of verbal 
construct ?would_have_been_cleaning? in the 
sentence is replaced with the translated as 
????_??_???_???? and is sent for final translation. 
 
Verbal construct template Translation template 
can_VB VB_????_?? 
VB_saktaa_hai 
would_have_been_VBG VB_???_???? 
VB_rahaa_hogaa 
has_not_VBN ???_?VB??_?? 
nahi_VByaa_hai 
 
Table 8: Verbal Construct template translation 
If the verb is not present in the English-Hindi 
dictionary too, it is translierated and ???? is added 
to it. Now, the verbal construct in the source 
sentence is replaced with its transliterated form   
before sending for translation. As an example, if  
word ?clean? is not found in English-Hindi 
dictionary, its translterated form ?????? is 
generated and ???? is added to it. The verbal 
construct ?would_have_been_cleaning? in the 
source sentence is replaced with transliterated 
verbal construct ?????_??_???_????? before 
sending for SMT. For trnasliteration in-house 
statistical transliteration system is used.  
9 Experiments 
The experiments were carried on original, pre-
processed and chunked verbal constructs based 
models. Table 9 below show that there is 
improvement in BLUE score when we pre-process 
the raw corpus. Better alignment is achieved due to 
reduced sentence length and data being in 
normalized form. The chunked verbal constructs 
corpus further improves the BLUE score. Though 
the BLUE score gain is marginal but on human   
inspection, better order and organization of Verbal 
constructs is observed. The table below shows the 
BLEU score for experiments. 
 
Corpus BLEU  
Score 
Gain in  
BLEU score 
BPP * 0.1596  
APP * 0.1672 0.0076 
APP + VCC * 0.1694 0.0022 
 
Table 9: BLEU scores for different experiments 
* BPP   -  Before Pre-processing the corpus 
* APP   -  After Pre-processing the corpus 
* APP + VCC  -  After Pre-Processing corpus + 
                                Verbal Constructs Chunking 
10 Conclusion and Future Work 
Results show, moderate gain in BLUE score is 
obtained with pre-processing of the corpus. This 
can be attributed to better alignment due to   
reduced length of sentences. Marginal gain is 
observed with chunking of Verbal constructs, yet   
manual inspection show fluent translation of verbal 
parts.  
Hindi verb forms are sensitive to gender, 
number and person information, which is not 
considered in current implementation. Work on 
interrogatives, prepositional phrases and other   
multi-word expressions, is in progress. There is 
scope to improve the statistical alignment using 
linguitic knowledge. The investigations on these 
are currently in progress. 
 
 
100
Acknowledgments 
We would like to thank Centre for Development of 
Advanced Computing (CDAC) for providing 
conducive environment for this work.  We also 
would like to thank NICT, Japan for providing the 
English version of BTEC corpus for performing 
experiments. Thanks are also due to Mr Mukund 
Kumar Roy and Mr Pramod Kumar Gupta for 
setting up the software and programming efforts. 
Thanks are also extended to Mr VN Shukla for 
extending support. 
References  
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation, Proc. of 
the Human Language Technology Conference 
(HLT/NAACL) 
Richard Zens and Hermann Ney. 2004. Improvements 
in Phrase-Based Statistical Machine Translation, 
Proc. of the Human Language Technology 
Conference (HLT-NAACL) , Boston, MA, pp. 257-
264. 
Nicola Ueffing and Hermann Ney. 2003. Using pos 
information for statistical machine translation into 
morphologically rich languages. In Proc. of the 10th 
Conference of the European Chapter of the ACL 
(EACL), Budapest, Hungary 
Seretan V. and Wehrli E. 2007. Collocation translation 
based onalignment and parsing. Proceedings of 
TALN. Toulouse, France. 
 Einat Minkov, Krishna Toutanova and Hisami Suzuki. 
2007. Generating Complex Morphology for Machine 
Translation, in Proc. 45th Annual Meeting of the 
Association for Computational Linguistics, pp 128-
135. 
Brown, P., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., 
Jelinek, F., La_erty, J. D., Mercer, R. L., and Rossin, 
P. 1990. A statistical approach to machine 
translation. Computational Linguistics, 16(2):76{85. 
R. Ishida. 2002. An introduction to Indic scripts, in 
Proc. of the 22nd International Unicode Conference. 
Singh, Suraj Bhan. 2010. A Syntactic Grammar of 
Hindi (first ed.), Ocean Books.  
R. Mahesh K. Sinha. 2011.  Stepwise Mining of Multi-
Word Expressions in Hindi, ACL-HLT, Workshop 
on Multiword expressions, Portland, USA 
Kristina Toutanova, Dan Klein, Christopher Manning, 
and Yoram Singer. 2003. Feature-Rich Part-of-
Speech Tagging with a Cyclic Dependency Network. 
In Proceedings of HLT-NAACL, pp. 252-259.  
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann 
Marcinkiewicz. 1993. Building a Large Annotated 
Corpus of English: The Penn Treebank, in 
Computational Linguistics, Volume 19, Number 2, 
pp. 313--330 
R. Mahesh K. Sinha. 2009. Mining Complex Predicates 
In Hindi Using Parallel Hindi-English Corpus, ACL-
IJCNLP, Workshop on Multi Word Expression, 
Singapore.  
G. Kikui et al 2006. Comparative study on 
corpora for speech translation, IEEE Transactions on 
Audio, Speech and Language, vol. 14(5), pp. 1674?
1682.  
F. Och and H. Ney. 2003. A Systematic Comparison of 
Various Statistical Alignment Models, 
Computational Linguistics, vol. 29(1), pp. 19?51.  
A. Stolcke. 2002. SRILM -an extensible language 
modelling   toolkit, in Proc. of ICSLP, Denver, pp. 
901?904.  
P. Koehn et al 2007. Moses: Open Source Toolkit for 
SMT,? in Proc. of the 45th ACL, Demonstration Ses-
sion, Prague, Czech Republic, , pp. 177?180.  
K. Papineni et al 2002. BLEU: a Method for 
Automatic Evaluation of Machine Translation, in 
Proc. of the 40th ACL, Philadelphia, USA, , pp. 311?
318. 
101
