Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 929?937,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Hypernym Discovery Based on Distributional Similarity                     
and Hierarchical Structures 
Ichiro Yamada?, Kentaro Torisawa?, Jun?ichi Kazama?, Kow Kuroda?,  
Masaki Murata?, Stijn De Saeger?, Francis Bond? and Asuka Sumida? 
 
?National Institute of Information and Communications Technology 
3-5 Hikaridai, Keihannna Science City 619-0289, JAPAN 
{iyamada,torisawa,kazama,kuroda,murata,stijn,bond}@nict.go.jp
?Japan Advanced Institute of Science and Technology 
1-1 Asahidai, Nomi-shi, Ishikawa-ken 923-1211, JAPAN 
a-sumida@jaist.ac.jp 
 
Abstract 
This paper presents a new method of devel-
oping a large-scale hyponymy relation data-
base by combining Wikipedia and other Web 
documents. We attach new words to the hy-
ponymy database extracted from Wikipedia 
by using distributional similarity calculated 
from documents on the Web. For a given tar-
get word, our algorithm first finds k similar 
words from the Wikipedia database. Then, 
the hypernyms of these k similar words are 
assigned scores by considering the distribu-
tional similarities and hierarchical distances 
in the Wikipedia database. Finally, new hy-
ponymy relations are output according to the 
scores. In this paper, we tested two distribu-
tional similarities. One is based on raw verb-
noun dependencies (which we call ?RVD?), 
and the other is based on a large-scale clus-
tering of verb-noun dependencies (called 
?CVD?). Our method achieved an attachment 
accuracy of 91.0% for the top 10,000 rela-
tions, and an attachment accuracy of 74.5% 
for the top 100,000 relations when using 
CVD. This was a far better outcome com-
pared to the other baseline approaches. Ex-
cluding the region that had very high scores, 
CVD was found to be more effective than 
RVD. We also confirmed that most relations 
extracted by our method cannot be extracted 
merely by applying the well-known lexico-
syntactic patterns to Web documents. 
1 Introduction 
Large-scale taxonomies such as WordNet (Fell-
baum 1998) play an important role in informa-
tion extraction and question answering. However, 
extremely high costs are borne to manually en-
large and maintain such taxonomies. Thus, appli-
cations using these taxonomies tend to face the 
drawback of data sparseness. This paper presents 
a new method for discovering a large set of hy-
ponymy relations. Here, a word1 X is regarded as 
a hypernym of a word Y if Y is a kind of X or Y 
is an instance of X. We are able to generate 
large-scale hyponymy relations by attaching new 
words to the hyponymy database extracted from 
Wikipedia (referred to as ?Wikipedia relation 
database?) by using distributional similarity cal-
culated from Web documents. Relations ex-
tracted from Wikipedia are relatively clean. On 
the other hand, reliable distributional similarity 
can be calculated using a large number of docu-
ments on the Web. In this paper, we combine the 
advantages of these two resources.  
Using distributional similarity, our algorithm 
first computes k similar words for a target word. 
Then, each k similar word assigns a score to its 
ancestors in the hierarchical structures of the 
Wikipedia relation database. The hypernym that 
has the highest score for the target word is se-
lected as the hypernym of the target word. Figure 
1 is an overview of the proposed approach. 
In the experiment, we extracted hypernyms for 
approximately 670,000 target words that are not 
included in the Wikipedia relation database but 
are found on the Web. We tested two distribu-
tional similarities: one based on raw verb-noun 
dependencies (RVD) and the other based on a 
large-scale clustering of verb-noun dependencies 
(CVD). The experimental results showed that the 
proposed methods were more effective than the 
other baseline approaches. In addition, we con-
firmed that most of the relations extracted by our 
method could not be extracted using the lexico-
syntactic pattern-based method.  
In the remainder of this paper, we first intro-
                                                 
1 In this paper, we use the term ?word? for both ?a 
single-word word? and ?a multi-word word.? 
929
duce some related works in Section 2. Section 3 
describes the Wikipedia relation database. Sec-
tion 4 describes the distributional similarity cal-
culated by the two methods. In Section 5, we 
describe a method to discover an appropriate 
hypernym for each target word. The experimen-
tal results are presented in Section 6 before con-
cluding the paper in Section 7. 
2 Related Works 
Most previous researchers have relied on lex-
ico-syntactic patterns for hyponymy acquisition. 
Lexico-syntactic patterns were first used by 
Hearst (1992). The patterns used by her included 
?NP0 such as NP1,? in which NP0 is a hypernym 
of NP1. Using these patterns as seeds, Hearst dis-
covered new patterns by which to semi-
automatically extract hyponymy relations. Pantel 
et al (2004a) proposed a method to automatical-
ly discover the patterns using a minimal edit dis-
tance. Ando et al (2003) applied predefined lex-
ico-syntactic patterns to Japanese news articles. 
Snow et al (2005) generalized these lexico-
syntactic pattern-based methods by using depen-
dency path features for machine learning. Then, 
they extended the framework such that this me-
thod was capable of making use of heterogenous 
evidence (Snow et al 2006). These pattern-based 
methods require the co-occurrences of a target 
word and the hypernym in a document. It should 
be noted that the requirement of such co-
occurrences actually poses a problem when we 
extract a large set of hyponymy relations since 
they are not frequently observed (Shinzato et al 
2004, Pantel et al 2004b). 
Clustering-based methods have been proposed 
as another approach. Caraballo (1999), Pantel et 
al. (2004b), and Shinzato et al (2004) proposed a 
method to find a common hypernym for word 
classes, which are automatically constructed us-
ing some measures of word similarities or hierar-
chical structures in HTML documents. Etzioni et 
al. (2005) used both a pattern-based approach 
and a clustering-based approach. The required 
amount of co-occurrences is significantly re-
duced due to class-based generalization 
processes. Note that these clustering-based me-
thods obtain the same hypernym for all the words 
in a particular class. This causes a problem for 
selecting an appropriate hypernym for each word 
in the case when the granularity or the construc-
tion of the classes is incorrect. Figure 2 shows 
the drawbacks of the existing approaches. 
Ponzetto et al (2007) and Sumida et al (2008) 
proposed a method for acquiring hyponymy rela-
tions from Wikipedia. This Wikipedia-based ap-
proach can extract a large volume of hyponymy 
relations with high accuracy. However, it is also 
true that this approach does not account for many 
words that usually appear in Web documents; 
this could be because of the unbalanced topics in 
Wikipedia or merely because of the incomplete 
coverage of articles on Wikipedia. Our method 
can target words that frequently appear on the 
Web but are not included in the Wikipedia rela-
tion database, thus making the results of the Wi-
kipedia-based approach richer and more ba-
lanced. Our approach uses distributional similari-
Figure 1: Overview of the proposed approach. 
hypernym : 
Target word:  Selected from the Web 
: word
k similar words
No direct co-occurrences of 
hypernym and hyponym in 
corpora are needed.
Selected from hypernyms in the 
Wikipedia relation database.
A hypernym is selected for 
each word independently.
Wikipedia relation database
Wikipedia-based approach
(Ponzetto et al 2007 and 
Sumida et al 2008)
Hyponymy relations are 
extracted using the layout 
information of Wikipedia.
Wikipedia
Figure 2: Drawbacks in existing approaches for hypo-
nymy acquisition. 
Pattern-based method
(Hearst 1992, Pantel et al 
2004a, Ando et al 2003, 
Snow et al 2005, Snow et al 
2006, and Etzioni et al 2005)
Clustering-based method
(Caraballo 1999, Pantel et al 
2004b, Shinzato et al 2004, 
and Etzioni et al 2005)
DocumentsCorpus/documents
Co-occurrences 
in a pattern are 
needed 
hypernym such as word hypernym ..?   word
word
word
wordword
Word Class
word
The same hypernym 
is selected for all 
words in a class.
930
ty, which is computed based on the noun-verb 
dependency profiles on the Web. The use of dis-
tributional similarity resembles the clustering-
based approach; however, our method can select 
a hypernym for each word independently, and it 
does not suffer from class granularity mismatch 
or the low quality of classes. In addition, our ap-
proach exploits the hierarchical structures of the 
Wikipedia hypernym relations.  
3 Wikipedia Relation Database 
Our Wikipedia relation database is based on the 
extraction method of Sumida et al (2008). They 
proposed a method of automatically acquiring 
hyponymy relations by focusing on the hierar-
chical layout of articles on Wikipedia. By way of 
an example, Figure 3 shows part of the source 
code clipped from the article titled ?Penguin.? 
An article has hierarchical structures composed 
of titles, sections, itemizations, etc. The entire 
article is divided into sections titled ?Anatomy,? 
?Mating habits,? ?Systematics and evolution,? 
?Penguins in popular culture,? and so on. The 
section ?Systematics and evolution? has a sub-
section ?Systematics,? which is further divided 
into ?Aptenodytes,? ?Eudyptes,? and so on. 
Some of these section-subsection relations can be 
regarded as valid hyponymy relations. In this 
article, relations such as the one between ?Apte-
nodytes? and ?Emperor Penguin? and that be-
tween ?Book? and ?Penguins of the World? are 
valid hyponymy relations.  
First, Sumida et al (2008) extracted hypony-
my relation candidates from hierarchical struc-
tures on Wikipedia. Then, they selected proper 
hyponymy relations using a support vector ma-
chine classifier. They used several kinds of fea-
tures for the hyponymy relation candidate, such 
as a POS tag for each word, the appearance of 
morphemes of each word, the distance between 
two words in the hierarchical structures of Wiki-
pedia, and the last character of each word. As a 
result of their experiments, approximately 2.4 
million hyponymy relations in Japanese were 
extracted, with a precision rate of 90.1%.  
Compared to the traditional taxonomies, these 
extracted hyponymy relations have the following 
characteristics (Fellbaum 1998, Bond et al 2008). 
(a) The database includes a more extensive 
vocabulary. 
(b)  The database includes a large number of 
named entities. 
Popular Japanese taxonomies GoiTaikei (Ike-
hara et al 1997) and Bunrui-Goi-Hyo (1996) 
contain approximately 300,000 words and 
96,000 words, respectively. In contrast, the ex-
tracted hyponymy relations contain approximate-
ly 1.2 million hyponyms and are undoubtedly 
much larger than the existing taxonomies. 
Another difference is that since Wikipedia covers 
a large number of named entities, the extracted 
hyponymy relations also contain a large number 
of named entities.  
Note that the extracted relations have a hierar-
chical structure because one hypernym of a cer-
tain word may also be the hyponym of another 
hypernym. However, we observed that the depth 
of the hierarchy, on an average, is extremely 
shallow. To make the hierarchy appropriate for 
our method, we extended these into a deeper hie-
rarchical structure. The extracted relations in-
clude many compound nouns as hypernyms, and 
we decomposed a compound noun into a se-
quence of nouns using a morphological analyzer. 
Since Japanese is a head-final language, the suf-
fix of a noun sequence becomes the hypernym of 
the original compound noun if the suffix forms 
another valid compound noun. We extracted suf-
fixes of compound nouns and manually checked 
whether they were valid compound nouns; then, 
we constructed a hierarchy of compound nouns. 
The hierarchy can be extended such that it in-
cludes the hyponyms of the original hypernym 
and the resulting hierarchy constitutes a hierar-
chical taxonomy. We use this hierarchical tax-
onomy as a target for expansion.2  
                                                 
2  Note that this modification was performed as part of 
another project of ours aimed at constructing a large-scale 
and clean hypernym knowledge base by human annotation. 
We do not think this cost is directly relevant to the method 
proposed here. 
Figure 3: A part of source code clipped from the 
article ?Penguin? in Wikipedia. 
'''Penguins''' are a group of 
[[Aquatic animal|aquatic]], 
[[flightless bird]]s. 
== Anatomy == 
== Mating habits == 
==Systematics and evolution== 
===Systematics=== 
* Aptenodytes 
**[[Emperor Penguin]] 
** [[King Penguin]] 
* Eudyptes 
== Penguins in popular culture == 
== Book == 
* Penguins 
* Penguins of the World 
== Notes == 
* Penguinone 
* the [[Penguin missile]] 
[[Category:Penguins]] 
[[Category:Birds]]
931
4 Distributional Similarity 
The distributional hypothesis states that words 
that occur in similar contexts tend to be semanti-
cally similar (Harris 1985). In this section, we 
first introduce distributional similarity based on 
raw verb-noun dependencies (RVD). To avoid 
the sparseness problem of the co-occurrence of 
verb-noun dependencies, we also use distribu-
tional similarity based on a large-scale clustering 
of verb-noun dependencies (CVD). 
In the experiment mentioned in the following 
section, we used the TSUBAKI corpus (Shinzato 
et al 2008) to calculate distributional similarity. 
This corpus provides a collection of 100 million 
Japanese Web pages containing 6 ? 109
 
sentences. 
4.1 Distributional Similarity Based on RVD 
When calculating the distributional similarity 
based on RVD, we use the triple <v, rel, n>, 
where v is a verb, n is a noun phrase, and rel 
stands for the relation between v and n. In Japa-
nese, a relation rel is represented by postposi-
tions attached to n and the phrase composed of n 
and rel modifies v. Each triple is divided into two 
parts. The first is <v, rel> and the second is n. 
Then, we consider the conditional probability of 
occurrence of the pair <v, rel>: P(<v, rel>|n).  
P(<v, rel>|n) can be regarded as the distribution 
of the grammatical contexts of the noun phrase n. 
The distributional similarity can be defined as 
the distance between these distributions. There 
are several kinds of functions for evaluating the 
distance between two distributions (Lee 1999). 
Our method uses the Jensen-Shannon divergence. 
The Jensen-Shannon divergence between two 
probability distributions, )|( 1nP ?  and )|( 2nP ? , 
can be calculated as follows: 
 
)),
2
)|()|(
||)|((
)
2
)|()|(
||)|(((
2
1
))|(||)|((
21
2
21
1
21
nPnP
nPD
nPnP
nPD
nPnPD
KL
KL
JS
?+??+
?+??=
??
 
 
where DKL indicates the Kullback-Leibler diver-
gence and is defined as follows: 
 
.
)|(
)|(
log)|())|(||)|((
2
1
121 ? ???=?? nP nPnPnPnPDKL  
 
Finally, the distributional similarity between 
two words, n1 and n2, is defined as follows: 
 
)).|(||)|((1),( 2121 nPnPDnnsim JS ???=  
 
This similarity assumes a value from 0 to 1. If 
two words are similar, the value will be close to 
1; if two words have entirely different meanings, 
the value will be 0.
 
In the experiment, we used 1,000,000 noun 
phrases and 100,000 pairs of verbs and postposi-
tions to calculate the probability P(<v, rel>|n) 
from the dependency relations extracted from the 
above-mentioned Web corpus (Shinzato et al 
2008). The probabilities are computed using the 
following equation by modifying for the fre-
quency using the log function: 
 
?
>?<
+><
+><=><
Drelv
nrelvf
nrelvf
nrelvP
,
1),,(log(
1)),,(log(
)|,(
,0),,(if >>< nrelvf
  
where f(<v, rel, n>) is the frequency of a triple 
<v, rel, n> and D is the set defined as { <v, rel > | 
f(<v, rel, n>) > 0 }. In the case of f(<v, rel, n>) = 
0, P(<v, rel>|n) is set to 0.  
Instead of using the observed frequency di-
rectly as in the usual maximum likelihood esti-
mation, we modified it as above. Although this 
might seems strange, this kind of modification is 
common in information retrieval as a term 
weighing method (Manning et al 1999) and  it is 
also applied in some studies to yield better word 
similarities (Terada et al 2006, Kazama et al 
2009). We also adopted this idea in this study. 
4.2 Distributional Similarity Based on CVD 
Rooth et al (1999) and Torisawa (2001) showed 
that EM-based clustering using verb-noun de-
pendencies can produce semantically clean noun 
clusters. We exploit these EM-based clustering 
results as the smoothed contexts for noun n. In 
Torisawa?s model (2001), the probability of oc-
currence of the triple <v, rel, n> is defined as 
follows: 
 
,)()|()|,(
),,(
? ? ><=
><
Aadef aPanParelvP
nrelvP
 
 
where a denotes a hidden class of <v,rel> and n. 
In this equation, the probabilities P(<v,rel>|a), 
P(n|a), and P(a) cannot be calculated directly 
because class a is not observed in a given corpus. 
The EM-based clustering method estimates these 
probabilities using a given corpus. In the E-step, 
932
the probability P(a|<v,rel>) is calculated. In the 
M-step, the probabilities P(<v,rel>|a), P(n|a), 
and P(a) are updated to arrive at the maximum 
likelihood using the results of the E-step. From 
the results of estimation of this EM-based clus-
tering method, we can obtain the probabilities 
P(<v,rel>|a), P(n|a), and P(a) for each <v, rel>, n, 
and a. Then, P(a|n) is calculated by the following 
equation: 
 
.
)()|(
)()|(
)|( ? ?= Aa aPanP
aPanP
naP  
 
P(a|n) can be used to find the class of n. For 
example, the class that has the maximum P(a|n) 
can be regarded as the class to which n belongs. 
Noun phrases that occur with similar pairs 
<v,rel> tend to be classified in the same class. 
Kazama et al (2008) proposed the paralleliza-
tion of this EM-based clustering with the aim of 
enabling large-scale clustering and using the re-
sulting clusters in named entity recognition. Ka-
zama et al (2009) reported the calculation of 
distributional similarity using the clustering re-
sults. The distributional similarity was calculated 
by the Jensen-Shannon divergence, which was 
used in this paper. Similar to the case in Kazama 
et al, we performed word clustering using 
1,000,000 noun phrases and 2,000 classes. Note 
that the frequencies of dependencies were mod-
ified with the log function, as in RVD, described 
in the previous section. 
5 Discovering an Appropriate Hyper-
nym for a Target word 
In the Wikipedia relation database, there are 
about 95,000 hypernyms and about 1.2 million 
hyponyms. In both RVD and CVD, the words 
used were selected according to the number (the 
number of kinds, not the frequency) of <v, rel >s 
that n has dependencies in the data. As a result, 1 
million words were selected. The number of 
common words that are also included in the Wi-
kipedia relation database are as follows: 
 
Hypernyms     28,015 (common hypernyms) 
Hyponyms   175,022 (common hyponyms) 
 
These common hypernyms become candidates 
for hypernyms for a target word. On the other 
hand, the common hyponyms are used as clues 
for identifying appropriate hypernyms. 
In our task, the potential target words are 
about 810,000 in number and are not included in 
the Wikipedia relation database. These include 
some strange words or word phrases that are ex-
tracted due to the failure of morphological analy-
sis. We exclude these words using simple rules. 
Consequently, the number of target words for our 
process is reduced to about 670,000.  
In the following section, we outline the scor-
ing method that uses k similar words to discover 
an appropriate hypernym for a target word. We 
also explain several baseline approaches that use 
distributional similarity. 
5.1 Scoring with k similar Words 
In this approach, we first calculate the similari-
ties between the common hyponyms and a target 
word and select the k most similar common hy-
ponyms. Here, we use a similarity threshold val-
ue Smin to avoid the effect of words having lower 
similarities. If the similarity is less than the thre-
shold value, the word is excluded from the set of 
k similar words. Next, each k similar word votes 
a score to its ancestors in the hierarchical struc-
tures of the Wikipedia relation database. The 
score used to vote for a hypernym nhyper is as fol-
lows: 
 
,),(
)(
)()(
1),(?
??
? ?=
trghyperhypo
hypohyper
nksimilarnDescn
hypotrg
nnr
hyper
nnsimd
nscore
 
 
where ntrg is the target word, Desc(nhyper) is the 
descendant of the hypernym nhyper, ksimilar(ntrg) 
is the k similar word of ntrg, 
1),( ?hypohyper nnrd is a 
penalty that depends on the differences in the 
depth of hierarchy, d is a parameter for the penal-
ty value and has a value between 0 and 1, and 
r(ntrg, nhypo) is the difference in the depth of hie-
rarchy between ntrg and nhypo. sim(ntrg,nhypo) is a 
distributional similarity between ntrg and nhypo.  
As a result of scoring, each hypernym has a 
score for the target word. The hypernym that has 
the highest score for the target word is selected 
as its hypernym. The hyponymy relations thus 
produced are ranked according to the scores. 
Figure 4 shows an example of the scoring 
process. In this example, we use CitroenAX as the 
target word whose hypernym will be identified. 
First, the k similar words are extracted from the 
common hyponyms in the Wikipedia relation: 
Opel Astra, TVR Tuscan, Mitsubishi Minica, and 
Renault Lutecia are extracted. Next, each k simi-
lar word votes a score to its ancestors. The words 
Opel Astra, TVR Tuscan, and Renault Lutecia 
vote to their parent car and the word Mitsubishi 
933
Minica votes to its parent mini-vehicle and its 
grandparent car with a small penalty. Finally, the 
hypernym car, which has the highest score, is 
selected as the hypernym of the target word Ci-
troenAX. 
5.2 Baseline Approaches 
Using distributional similarity, we can also de-
velop the following baseline approaches to dis-
cover hyponymy relations. 
 
Selecting the hypernym of the most similar hy-
ponym (baseline approach 1) 
We use the heuristics that similar words tend to 
have the same hypernym. In this approach, we 
first calculate the similarities between the com-
mon hyponyms and the target word. The com-
mon hyponym most similar to the target word is 
extracted. Then, the parent of the extracted 
common hyponym is regarded as the hypernym 
of the target word. This approach outputs several 
hypernyms when the most similar hyponym has 
several hypernyms. This approach can be consi-
dered to be the same as the scoring method using 
k similar words when k = 1. We use the distribu-
tional similarity between the target word and the 
most similar hyponym in the Wikipedia relation 
database as the score for the appropriateness of 
the resulting hyponymy. 
 
Selecting the most similar hypernym (baseline 
approach 2) 
The distributional similarity between the com-
mon hypernym and the target word is calculated. 
Then, the hypernym that has the highest distribu-
tional similarity is regarded as the hypernym of 
the target word. The similarity is used as the 
score of the appropriateness of the produced hy-
ponymy. 
 
Scoring based on the average similarity of the 
hypernym?s children (baseline approach 3) 
This approach uses the probabilistic distributions 
of the hypernym?s children. We define the prob-
ability )|( hyperchild nP ? characterized by the children 
of the hypernym nhyper, as follows: 
 
,
)(
)()|(
)|(
)(
)(
?
?
?
?
?
=?
hyperhypo
hyperhypo
nChn
hypo
nChn
hypohypo
hyperchild nP
nPnP
nP  
 
where Ch(nhyper) is a set of all children of nhyper. 
Then, distributional similarities between a com-
mon hypernym nhyper and the target word nhypo are 
calculated. The hypernym that has the highest 
distributional similarity is selected as the hyper-
nym of the word. This distributional similarity is 
used as the score of the appropriateness of the 
produced hyponymy. 
If a hypernym has only a few children, the re-
liability of the probabilistic distribution of 
hypernym defined here will be low because the 
Wikipedia relation database includes some incor-
rect relations. For this reason, we use the hyper-
nym only if the number of children it has is more 
than a threshold value.  
6 Experiments 
We evaluated our proposed methods by using it 
in experiments to discover hypernyms from the 
Wikipedia relation database for the target words 
extracted from about 670,000 noun phrases.  
6.1 Parameter Estimation by Preliminary 
Experiments 
In the proposed methods, there are several para-
meters. We performed parameter optimization by 
randomly selecting 694 words as development 
data in our preliminary experiments. The hyper-
nyms of these words were determined manually. 
We adjusted the parameters so that each method 
achieved the best performance for this develop-
ment data. 
The parameters in the scoring method with k 
similar words were adjusted as follows3:  
 (RVD) 
Number of similar words:         k = 100. 
Similarity threshold:           Smin = 0.05. 
Penalty value for ancestors:    d = 0.6. 
                                                 
3 We tested the parameter values k = {100, 200, 300, 400, 
500, 600, 700, 800, 900, 1000}, Smin={0, 0.05, 0.1, 0.15, 0.2, 
0.25, 0.3, 0.35, 0.4} and d={0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 
0.8, 0.85, 0.9, 0.95, 1.0}. 
Figure 4: Overview of the scoring process.
car
CitroenAX
mini
vehicle
hybrid 
vehicle
Opel 
Astra
Renault 
Lutecia
Mitsubishi
Minica
k similar words
Each k-similar word
votes the score to its 
ancestors in the Wikipedia 
relation database.
Target word selected 
from the Web text (ntrg).
TVR 
Tuscan
: common hypernym(nhyper)
: k similar word &  
common hyponym(nhypo)
x d1
x d0
x d0
934
(CVD) 
Number of similar words:         k = 200. 
Similarity threshold:                Smin = 0.3. 
Penalty value for ancestors:    d = 0.6. 
 
The parameter in baseline approach 3 was ad-
justed as follows: 
Threshold for the number of children: 20. 
6.2 Evaluation of the Experimental Results 
on the Basis of Score Ranking 
Using the adjusted parameters, we conducted 
experiments to extract the hypernym of each tar-
get word with the help of the scoring method 
based on k similar words. In these experiments, 
two kinds of distributional similarity mentioned 
in Section 4 were exploited individually. The 
words that were used in the development data 
were excluded.  
We also conducted a comparative experiment 
in which the parameter value for the penalty of 
the hierarchal difference, d, was set to 0 to clari-
fy the ability of using hierarchal structures in the 
k similar words method. This means each k simi-
lar word votes only to their parent. 
We then judged the quality of each acquired 
hypernym. The evaluation data sets were sam-
pled from the top 1,000, 10,000, 100,000, and 
670,000 results that were ranked according to the 
score of each method. Then, against 200 samples 
that were randomly sampled from each set, one 
of the authors judged whether the hypernym ex-
tracted by each method for the target word was 
correct or not. In this evaluation, if the sentence 
?The target word is a kind of the hypernym? or 
?The target word is an instance of the hypernym? 
was consistent, the extracted hyponymy was 
judged as correct. It should be noted that the out-
puts of the compared methods are combined and 
shuffled to enable fair comparison. In addition, 
baseline approach 1 extracted several hypernyms 
for the target word. In this case, we judged the 
hypernym as correct when the case where one of 
the hypernyms was correct.  
The precision of each result is shown in Table 
1. The results of the k similar words method are 
far better than those of the other baseline me-
thods. In particular, the k similar words method 
with CVD outperformed the methods of the k 
similar words where the parameter value d was 
set to 0 and the method using RVD except for the 
top 1,000 results. This means that the use of hie-
rarchal structures and the clustering process for 
calculating distributional similarity are effective 
for this task. We confirmed the significant differ-
ences of the proposed method (CVD) as com-
pared with all the baseline approaches at the 1% 
significant level by the Fisher?s exact test (Hays 
1988). 
The precision of baseline approach 2 that se-
lected the most similar hypernym was the worst 
among all the methods. There were words that 
were similar to the target word among the hyper-
nyms extracted incorrectly. For example, the 
word semento-kojo (cement factory) was ex-
tracted for the hypernym of the word kuriningu-
kojo (dry cleaning plant). It is difficult to judge 
whether the word is a hypernym or just a similar 
word by using only the similarity measure. 
As for the results of baseline approach 1 using 
the most similar hyponym and baseline approach 
3 using the similarity of the set of hypernym?s 
children, the noise on the Wikipedia relation da-
tabase decreased the precision. Moreover, over-
specified hypernyms were extracted incorrectly 
by these methods. In contrast, the method of 
scoring based on the use of k similar words was 
robust against noise because it uses the voting 
approach for the similarities. Further, this me-
thod can extract hypernyms that are not over-
specific because it uses all descendants for scor-
ing.  
Table 2 shows some examples of relations ex-
tracted by the k similar words method using 
CVD. 
 
Table 1:  Precision of each approach based on the score ranking. CVD represents the method that uses the dis-
tributional similarity based on large-scale of clustering of verb-noun dependencies. RVD represents the 
one based on raw verb-noun dependencies. 
 k-similar words
(CVD) 
k-similar words
(RVD) 
k-similar words
(CVD, d = 0)
Baseline  
approach 1 
(CVD) 
Baseline  
approach 2 
(CVD) 
Baseline  
approach 3 
(CVD) 
1,000 0.940 1.000 0.850 0.730 0.290 0.630 
10,000 0.910 0.875 0.875 0.555 0.300 0.445 
100,000 0.745 0.710 0.730 0.500 0.280 0.435 
670,000 0.520 0.500 0.470 0.345 0.115 0.170 
935
6.3 Investigation of the Extracted Relation 
Overlap with a Conventional Method 
We randomly sampled 300 hyponymy rela-
tions that were extracted correctly using the k 
similar words method exploiting CVD and inves-
tigated whether or not these relations can be ex-
tracted by the conventional method based on the 
lexico-syntactic pattern. The possible hyponymy 
relations were extracted using the pattern-based 
method (Ando et al 2003) from the TSUBAKI 
corpus (Shinzato et al 2008). From a comparison 
of these relations, we found only 57 common 
hyponymy relations. That is, the remaining 243 
hyponymy relations were not included in the 
possible hyponymy relations. This result indi-
cates that our method can acquire the hyponymy 
relations that cannot be extracted by the conven-
tional pattern-based method. 
6.4 Discussions 
We investigated the reason for the errors gener-
ated by the method of scoring using k similar 
words exploiting CVD. We conducted experi-
ments on hypernym extraction targeting 694 
words in the development data mentioned in Sec-
tion 6.1. Among these, 286 relations were ex-
tracted incorrectly. In these relations, there were 
some frequent hypernyms. For example, the 
word sakuhin (work) appeared 28 times and hon 
(book) appeared 20 times. As shown in Table 2, 
hon (book) was also extracted for the target word 
meru-seminah (mail seminar). It is really diffi-
cult even for a human to identify whether the 
title is that of the book or the event. If we can 
identify these difficult hypernyms in advance, we 
can improve precision by excluding them from 
the target hypernyms. This will be one of the top-
ics for future study. 
7 Conclusion 
In this paper, we proposed a method for disco-
vering hyponymy relations between nouns by 
fusing the Wikipedia relation database and words 
from the Web. We demonstrated that the method 
using k similar words has high accuracy. The 
experimental results showed the effectiveness of 
using hierarchal structures and the clustering 
process for calculating distributional similarity 
for this task. The experimental results showed 
that our method could achieve 91.0% attachment 
accuracy for the top 10,000 hyponymy relations 
and 74.5% attachment accuracy for the top 
100,000 relations when using the clustering-
based similarity. We confirmed that most rela-
tions extracted by the proposed method could not 
be handled by the lexico-syntactic pattern-based 
method. Future work will be to filter out difficult 
hypernyms for hyponymy extraction process to 
achieve higher precision. 
References 
M. Ando, S. Sekine and S. Ishizaki. 2003. Automatic 
Extraction of Hyponyms from Newspaper Using 
Lexicosyntactic Patterns. IPSJ SIG Notes, 2003-
NL-157, pp. 77?82 (in Japanese). 
F. Bond, H. Isahara, K. Kanzaki and K. Uchimoto. 
2008. Boot-strapping a WordNet Using Multiple 
Existing WordNets. In the 6th International Confe-
rence on Language Resources and Evaluation 
(LREC), Marrakech.  
Bunruigoihyo. 1996. The National Language Re-
search Institute (in Japanese). 
S. A. Caraballo. 1999. Automatic Construction of a 
Hypernym-labeled Noun Hierarchy from Text. In 
Proceedings of the Conference of the Association 
for Computational Linguistics (ACL). 
O. Etzioni, M. Cafarella, D. Downey, A. Popescu, T. 
Shaked, S. Soderland, D. Weld and A. Yates. 2005. 
Unsupervised Named-Entity Extraction from the 
Web: An Experimental Study. Artificial Intelli-
gence, 165(1):91?134. 
C. Fellbaum. 1998. WordNet: An Electronic Lexical 
Table2:  Hypernym discovery results by the k-similar 
words based approach (CVD). The underline indi-
cates the hypernyms which are extracted incorrectly.
Score Target word Extracted hypernym 
58.6 INDIVI burando 
(fashion label)
54.3 kureome (Cleome) hana (flower)
34.4 UOKR  gemu (game)
21.7 Okido (Okido) machi (town)
20.5 Sumatofotsu 
(Smart fortwo) 
kuruma  
(car) 
15.6 Fukagawameshi 
(Fukagawa rice)
ryori (dish) 
8.9 John Barry sakkyokuka 
 (composer)
8.5 JVM sofuto-wea 
(software) 
6.6 metangasu 
(methane gas) 
genso 
(chemical element)
5.4 me-ru semina 
(mail seminar) 
Hon (book) 
3.9 gurometto 
(grommet) 
shohin 
(merchandise)
3.1 supuringubakku  
(spring back) 
gensho 
(phenomenon)
936
Database. Cambridge, MA: MIT Press. 
Z. Harris. 1985. Distributional Structure. In Katz, J. J. 
(ed.) The Philosophy of Linguistics, Oxford Uni-
versity Press, pp. 26?47. 
W. L. Hays. 1988. Statistics: Analyzing Qualitative 
Data, Rinehart and Winston, Inc., Ch. 18, pp. 769?
783. 
M. Hearst. 1992. Automatic Acquisition of Hypo-
nyms from Large Text Corpora. In Proceedings of 
the 14th Conference on Computational Linguistics 
(COLING), pp. 539?545.  
S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo, H. Na-
kaiwa, K. Ogura, Y. Ooyama and Y. Hayashi. 1997. 
Goi-Taikei A Japanese Lexicon, Iwanami Shoten. 
J. Kazama and K. Torisawa. 2008. Inducing Gazet-
teers for Named Entity Recognition by Large-scale 
Clustering of Dependency Relations. In Proceed-
ings of ACL-08: HLT, pp. 407?415. 
J. Kazama, Stijn De Saeger, K. Torisawa and M. Mu-
rata. 2009. Generating a Large-scale Analogy List 
Using a Probabilistic Clustering Based on Noun-
Verb Dependency Profiles. In 15th Annual Meeting 
of the Association for Natural Language 
Processing, C1?3 (in Japanese). 
L. Lee. 1999. Measures of Distributional Similarity. 
In Proceedings of the 37th Annual Meeting of the 
Association for Computational Linguistics, pp. 25?
32. 
C. D. Manning and H. Schutze. 1999. Foundations of 
Statistical Natural Language Processing. The MIT 
Press. 
P. Pantel, D. Ravichandran and E. Hovy. 2004a. To-
wards Terascale Knowledge Acquisition. In Pro-
ceedings of the 20th International Conference on 
Computational Linguistics. 
P. Pantel and D. Ravichandran. 2004b. Automatically 
Labeling Semantic Classes. In Proceedings of the 
Human Language Technology and North American 
Chapter of the Association for Computational Lin-
guistics Conference. 
S. P. Ponzetto, and M. Strube. 2007. Deriving a Large 
Scale Taxonomy from Wikipedia. In Proceedings 
of the 22nd National Conference on Artificial Intel-
ligence, pp. 1440?1445. 
M. Rooth, S. Riezler, D. Presher, G. Carroll and F. 
Beil. 1999. Inducing a Semantically Annotated 
Lexicon via EM-based Clustering. In Proceedings 
of the 37th annual meeting of the Association for 
Computational Linguistics, pp. 104?111. 
K. Shinzato and K. Torisawa. 2004. Acquiring Hypo-
nymy Relations from Web Documents. In Proceed-
ings of HLT-NAACL, pp. 73?80. 
K. Shinzato, D. Kawahara, C. Hashimoto and S. Ku-
rohashi. 2008. A Large-Scale Web Data Collection 
as A Natural Language Processing Infrastructure. 
In the 6th International Conference on Language 
Resources and Evaluation (LREC). 
R. Snow, D. Jurafsky and A. Y. Ng. 2005. Learning 
Syntactic Patterns for Automatic Hypernym Dis-
covery. NIPS 2005. 
R. Snow, D. Jurafsky, A. Y. Ng. 2006. Semantic Tax-
onomy Induction from Heterogenous Evidence. In 
Proceedings of the 21st International Conference 
on Computational Linguistics and the 44th annual 
meeting of the Association for Computational Lin-
guistics, pp. 801?808. 
A. Sumida, N. Yoshinaga and K. Torisawa. 2008. 
Boosting Precision and Recall of Hyponymy Rela-
tion Acquisition from Hierarchical Layouts in Wi-
kipedia. In the 6th International Conference on 
Language Resources and Evaluation (LREC). 
A. Terada, M. Yoshida, H. Nakagawa. 2006. A Tool 
for Constructing a Synonym Dictionary using con-
text Information. In proceedings of IPSJ SIG Tech-
nical Reports, vol.2006 No.124, pp. 87-94. (In Jap-
anese). 
K. Torisawa. 2001. An Unsupervised Method for Ca-
nonicalization of Japanese Postpositions. In Pro-
ceedings of the 6th Natural Language Processing 
Pacific Rim Symposium (NLPRS), pp. 211?218. 
K. Torisawa, Stijn De Saeger, Y. Kakizawa, J. Kaza-
ma, M. Murata, D. Noguchi and A. Sumida. 2008. 
TORISHIKI-KAI, An Autogenerated Web Search 
Directory. In Proceedings of the second interna-
tional symposium on universal communication, pp. 
179?186, 2008. 
937
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 842?850,
Beijing, August 2010
Co-STAR: A Co-training Style Algorithm for Hyponymy Relation
Acquisition from Structured and Unstructured Text
Jong-Hoon Oh, Ichiro Yamada, Kentaro Torisawa, and Stijn De Saeger
Language Infrastructure Group, MASTAR Project,
National Institute of Information and Communications Technology (NICT)
{rovellia,iyamada,torisawa,stijn}@nict.go.jp
Abstract
This paper proposes a co-training style
algorithm called Co-STAR that acquires
hyponymy relations simultaneously from
structured and unstructured text. In Co-
STAR, two independent processes for hy-
ponymy relation acquisition ? one han-
dling structured text and the other han-
dling unstructured text ? collaborate by re-
peatedly exchanging the knowledge they
acquired about hyponymy relations. Un-
like conventional co-training, the two pro-
cesses in Co-STAR are applied to dif-
ferent source texts and training data.
We show the effectiveness of this al-
gorithm through experiments on large-
scale hyponymy-relation acquisition from
Japanese Wikipedia and Web texts. We
also show that Co-STAR is robust against
noisy training data.
1 Introduction
Acquiring semantic knowledge, especially se-
mantic relations between lexical terms, is re-
garded as a crucial step in developing high-level
natural language applications. This paper pro-
poses Co-STAR (a Co-training STyle Algorithm
for hyponymy Relation acquisition from struc-
tured and unstructured text). Similar to co-
training (Blum and Mitchell, 1998), two hy-
ponymy relation extractors in Co-STAR, one for
structured and the other for unstructured text, it-
eratively collaborate to boost each other?s perfor-
mance.
Many algorithms have been developed to auto-
matically acquire semantic relations from struc-
tured and unstructured text. Because term pairs
are encoded in structured and unstructured text in
different styles, different kinds of evidence have
been used for semantic relation acquisition:
Evidence from unstructured text: lexico-
syntactic patterns and distributional similar-
ity (Ando et al, 2004; Hearst, 1992; Pantel
et al, 2009; Snow et al, 2006; De Saeger et
al., 2009; Van Durme and Pasca, 2008);
Evidence from structured text: topic hierarchy,
layout structure of documents, and HTML
tags (Oh et al, 2009; Ravi and Pasca, 2008;
Sumida and Torisawa, 2008; Shinzato and
Torisawa, 2004).
Recently, researchers have used both structured
and unstructured text for semantic-relation acqui-
sition, with the aim of exploiting such different
kinds of evidence at the same time. They ei-
ther tried to improve semantic relation acquisition
by putting the different evidence together into a
single classifier (Pennacchiotti and Pantel, 2009)
or to improve the coverage of semantic relations
by combining and ranking the semantic relations
obtained from two source texts (Talukdar et al,
2008).
In this paper we propose an algorithm called
Co-STAR. The main contributions of this work
can be summarized as follows.
? Co-STAR is a semi-supervised learning
method composed of two parallel and iter-
ative processes over structured and unstruc-
tured text. It was inspired by bilingual co-
training, which is a framework for hyponymy
relation acquisition from source texts in two
languages (Oh et al, 2009). Like bilingual
co-training, two processes in Co-STAR op-
erate independently on structured text and
unstructured text. These two processes are
trained in a supervised manner with their
initial training data and then each of them
tries to enlarge the existing training data of
the other by iteratively exchanging what they
842
have learned (more precisely, by transfer-
ring reliable classification results on com-
mon instances to one another) (see Section
4 for comparison Co-STAR and bilingual
co-training). Unlike the ensemble semantic
framework (Pennacchiotti and Pantel, 2009),
Co-STAR does not have a single ?master?
classifier or ranker to integrate the differ-
ent evidence found in structured and unstruc-
tured text. We experimentally show that, at
least in our setting, Co-STAR works better
than a single ?master? classifier.
? Common relation instances found in both
structured and unstructured text act as a
communication channel between the two ac-
quisition processes. Each process in Co-
STAR classifies common relation instances
and then transfers its high-confidence classi-
fication results to training data of the other
process (as shown in Fig. 1), in order to im-
prove classification results of the other pro-
cess. Moreover, the efficiency of this ex-
change can be boosted by increasing the
?bandwidth? of this channel. For this pur-
pose each separate acquisition process auto-
matically generates a set of relation instances
that are likely to be negative. In our experi-
ments, we show that the above idea proved
highly effective.
? Finally, the acquisition algorithm we propose
is robust against noisy training data. We
show this by training one classifier in Co-
STAR with manually labeled data and train-
ing the other with automatically generated
but noisy training data. We found that Co-
STAR performs well in this setting. This is-
sue is discussed in Section 6.
This paper is organized as follows. Sections 2
and 3 precisely describe our algorithm. Section 4
describes related work. Sections 5 and 6 describe
our experiments and present their results. Conclu-
sions are drawn in Section 7.
2 Co-STAR
Co-STAR consists of two processes that simul-
taneously but independently extract and classify
Structured	 ?Texts	 Unstructured	 ?Texts	
Itera?on	
Training	 ?Data	 ?for	 ?Structured	 ?Texts	
Classifier	 Classifier	Training	 Training	
Enlarged	 ?	 ?Training	 ?Data	 ?for	 ?Structured	 ?Text	
Enlarged	 ?	 ?Training	 ?Data	 ?for	 ?Unstructured	 ?Texts	
Training	 ?Data	 ?For	 ?Unstructured	 ?Texts	
Classifier	Classifier	
Further	 ?Enlarged	 ?Training	 ?Data	 ?for	 ?Structured	 ?Texts	
Further	 ?Enlarged	 ?Training	 ?Data	 ?for	 ?Unstructured	 ?Texts	
Training	
Training	 Training	
Training	
?..	 ?..	Common	 ?instances	Transferring	 ?reliable	 ?classifica?on	 ?results	 ?of	 ?classifiers	
Transferring	 ?reliable	 ?classifica?on	 ?results	 ?of	 ?classifiers	
Figure 1: Concept of Co-STAR.
hyponymy relation instances from structured and
unstructured text. The core of Co-STAR is the
collaboration between the two processes, which
continually exchange and compare their acquired
knowledge on hyponymy relations. This collabo-
ration is made possible through common instances
shared by both processes. These common in-
stances are classified separately by each process,
but high-confidence classification results by one
process can be transferred as new training data to
the other.
2.1 Common Instances
Let S and U represent a source (i.e. corpus)
of structured and unstructured text, respectively.
In this paper, we use the hierarchical layout of
Wikipedia articles and the Wikipedia category
system as structured text S (see Section 3.1), and
a corpus of ordinary Web pages as unstructured
text U . Let XS and XU denote a set of hyponymy
relation candidates extracted from S and U , re-
spectively. XS is extracted from the hierarchi-
cal layout of Wikipedia articles (Oh et al, 2009)
and XU is extracted by lexico-syntactic patterns
for hyponymy relations (i.e., hyponym such as hy-
ponymy) (Ando et al, 2004) (see Section 3 for a
detailed explanation)
We define two types of common instances,
called ?genuine? common instances (G) and ?vir-
tual? common instances (V ). The set of common
instances is denoted by Y = G ? V . Genuine
common instances are hyponymy relation candi-
dates found in both S and U (G = XS ?XU ). On
843
the other hand, term pairs are obtained as virtual
common instances when:
? 1) they are extracted as hyponymy relation
candidates in either S or U and;
? 2) they do not seem to be a hyponymy rela-
tion in the other text
The first condition corresponds to XS ? XU .
Term pairs satisfying the second condition are de-
fined as RS and RU , where RS ? XS = ? and
RU ?XU = ?.
RS contains term pairs that are found in the
Wikipedia category system but neither term ap-
pears as ancestor of the other1. For example, (nu-
trition,protein) and (viruses,viral disease), respec-
tively, hold a category-article relation, where nu-
trition is not ancestor of viruses and vice versa in
the Wikipedia category system. Here, term pairs,
such as (nutrition, viruses) and (viral disease, nu-
trition), can be ones in RS .
RU is a set of term pairs extracted from U
when:
? they are not hyponymy relation candidates in
XU and;
? they regularly co-occur in the same sentence
as arguments of the same verb (e.g., A cause
B or A is made by B);
As a result, term pairs in RU are thought as hold-
ing some other semantic relations (e.g., A and B
in ?A cause B? may hold a cause/effect relation)
than hyponymy relation. Finally, virtual common
instances are defined as:
? V = (XS ?XU ) ? (RS ?RU )
The virtual common instances, from the view-
point of either S or U , are unlikely to hold a hy-
ponymy relation even if they are extracted as hy-
ponymy relation candidates in the other text. Thus
many virtual common instances would be a nega-
tive example for hyponymy relation acquisition.
On the other hand, genuine common instances
(hyponymy relation candidates found in both S
1A term pair often holds a hyponymy relation if one term
in the term pair is a parent of the other in the Wikipedia cat-
egory system (Suchanek et al, 2007).
and U ) are more likely to hold a hyponymy re-
lation than virtual common instances.
In summary, genuine and virtual common in-
stances can be used as different ground for collab-
oration as well as broader collaboration channel
between the two processes than genuine common
instances used alone.
2.2 Algorithm
We assume that classifier c assigns class label
cl ? {yes, no} (?yes? (hyponymy relation) or
?no? (not a hyponymy relation)) to instances in
x ? X with confidence value r ? R+, a non-
negative real number. We denote the classifica-
tion result by classifier c as c(x) = (x, cl, r). We
used support vector machines (SVMs) in our ex-
periments and the absolute value of the distance
between a sample and the hyperplane determined
by the SVMs as confidence value r.
1: Input: Common instances (Y = G ? V ) and
the initial training data (L0S and L0U )
2: Output: Two classifiers (cnS and cnU )
3: i = 0
4: repeat
5: ciS := LEARN(LiS)
6: ciU := LEARN(LiU )
7: CRiS := {ciS(y)|y ? Y , y /? LiS ? LiU}
8: CRiU := {ciU (y)|y ? Y , y /? LiS ? LiU}
9: for each (y, clS , rS) ? TopN(CRiS) and
(y, clU , rU ) ? CRiU do
10: if (rS > ? and rU < ?)
or (rS > ? and clS = clU ) then
11: L(i+1)U := L
(i+1)
U ? {(y, clS)}
12: end if
13: end for
14: for each (y, clU , rU ) ? TopN(CRiU ) and
(y, clS , rS) ? CRiS do
15: if (rU > ? and rS < ?)
or (rU > ? and clS = clU ) then
16: L(i+1)S := L
(i+1)
S ? {(y, clU )}
17: end if
18: end for
19: i = i+ 1
20: until stop condition is met
Figure 2: Co-STAR algorithm
844
The Co-STAR algorithm is given in Fig. 2. The
algorithm is interpreted as an iterative procedure
1) to train classifiers (ciU , ciS) with the existing
training data (LiS and LiU ) and 2) to select new
training instances from the common instances to
be added to existing training data. These are re-
peated until stop condition is met.
In the initial stage, two classifiers c0S and c0U
are trained with manually prepared labeled in-
stances (or training data) L0S and L0U , respec-
tively. The learning procedure is denoted by
c = LEARN(L) in lines 5?6, where c is a re-
sulting classifier. Then ciS and ciU are applied
to classify common instances in Y (lines 7?8).
We denote CRiS as a set of the classification re-
sults of ciS for common instances, which are not
included in the current training data LiS ? LiU .
Lines 9?13 describe a way of selecting instances
in CRiS to be added to the existing training data
in U . During the selection, ciS acts as a teacher
and ciU as a student. TopN(CRiS) is a set of
ciS(y) = (y, clS , rS), whose rS is the top-N high-
est in CRiS . (In our experiments, N = 900.) The
teacher instructs his student the class label of y if
the teacher can decide the class label of y with a
certain level of confidence (rS > ?) and the stu-
dent satisfies one of the following two conditions:
? the student agrees with the teacher on class
label of y (clS = clU ) or
? the student?s confidence in classifying y is
low (rU < ?)
rU < ? enables the teacher to instruct his student
in spite of their disagreement over a class label.
If one of the two conditions is satisfied, (y, clS)
is added to existing labeled instances L(i+1)U . The
roles are reversed in lines 14?18, so that ciU be-
comes the teacher and ciS the student.
The iteration stops if the change in the differ-
ence between the two classifiers is stable enough.
The stability is estimated by d(ciS , ciU ) in Eq. (1),
where ?i represents the change in the average
difference between the confidence values of the
two classifiers in classifying common instances.
We terminate the iteration if d(ciS , ciU ) is smaller
than 0.001 in three consecutive rounds (Wang and
Zhou, 2007).
d(ciS , ciU ) = |?i ? ?(i?1)|/|?(i?1)| (1)
3 Hyponymy Relation Acquisition
In this section we explain how each process ex-
tracts hyponymy relations from its respective text
source either Wikipedia or Web pages. Each pro-
cess extracts hyponymy relation candidates (de-
noted by (hyper,hypo) in this section). Because
there are many non-hyponymy relations in these
candidates2, we classify hyponymy relation can-
didates into correct hyponymy relation or not. We
used SVMs (Vapnik, 1995) for the classification
in this paper.
3.1 Acquisition from Wikipedia
(a) Layout structure
Range
Siberian tiger
Bengal tiger
Subspecies
Taxonomy
Tiger
Malayan tiger
(b) Tree structure
Figure 3: Example borrowed from Oh et al
(2009): Layout and tree structures of Wikipedia
article TIGER
We follow the method in Oh et al (2009) for
acquiring hyponymy relations from the Japanese
Wikipedia. Every article is transformed into a tree
structure as shown in Fig. 3, based on the items in
its hierarchical layout including title, (sub)section
headings, and list items. Candidate relations are
extracted from this tree structure by regarding a
node as a hypernym candidate and all of its subor-
dinate nodes as potential hyponyms of the hyper-
nym candidate (e.g., (TIGER, TAXONOMY) and
(TIGER, SIBERIAN TIGER) from Fig. 3). We ob-
tained 1.9?107 Japanese hyponymy relation can-
didates from Wikipedia.
2Only 25?30% of candidates was true hyponymy relation
in our experiments.
845
Type Description
Feature from Wikipedia Lexical Morphemes and POS of hyper and hypo; hyper and hypo themselves
(?WikiFeature?) Structure Distance between hyper and hypo in a tree structure;
Lexical patterns for article or section names, where listed items often appear;
Frequently used section headings in Wikipedia (e.g., ?Reference?);
Layout item type (e.g., section or list); Tree node type (e.g., root or leaf);
Parent and children nodes of hyper and hypo
Infobox Attribute type and its value obtained from Wikipedia infoboxes
Feature from Web texts Lexical Morphemes and POS of hyper and hypo; hyper and hypo themselves
(?WebFeature?) Pattern Lexico-syntactic patterns applied to hyper and hypo;
PMI score between pattern and hyponymy relation candidate (hyper,hypo)
Collocation PMI score between hyper and hypo
Noun Class Noun classes relevant to hyper and hypo
Table 1: Feature sets (WikiFeature and WebFeature): hyper and hypo represent hypernym and hyponym
parts of hyponymy relation candidates, respectively.
As features for classification we used lex-
ical, structure, and infobox information from
Wikipedia (WikiFeature), as shown in Table 1.
Because they are the same feature sets as those
used in Oh et al (2009), here we just give a brief
overview of the feature sets. Lexical features3
are used to recognize the lexical evidence for
hyponymy relations encoded in hyper and hypo.
For example, the common head morpheme tiger
in (TIGER, BENGAL TIGER) can be used as the
lexical evidence. Such information is provided
along with the words/morphemes and the parts of
speech of hyper and hypo, which can be multi-
word/morpheme nouns.
Structure features provide evidence found in
layout or tree structures for hyponymy relations.
For example, hyponymy relations (TIGER, BEN-
GAL TIGER) and (TIGER,MALAYAN TIGER) can
be obtained from tree structure ?(root node, chil-
dren nodes of Subspecies)? in Fig 3.
3.2 Acquisition from Web Texts
As the target for hyponymy relation acquisition
from the Web, we used 5 ? 107 pages from
the TSUBAKI corpus (Shinzato et al, 2008),
a 108 page Japanese Web corpus that was de-
pendency parsed with KNP (Kurohashi-Nagao
Parser) (Kurohashi and Kawahara, 2005). Hy-
ponymy relation candidates are extracted from the
corpus based on the lexico-syntactic patterns such
as ?hypo nado hyper (hyper such as hypo)? and
?hypo to iu hyper (hyper called hypo)? (Ando
3MeCab (http://mecab.sourceforge.net/)
was used to provide the lexical features.
et al, 2004). We extracted 6 ? 106 Japanese
hyponymy relation candidates from the Japanese
Web texts. Features (WebFeature) used for classi-
fication are summarized in Table 1. Similar to the
hyponymy relation acquisition from Wikipedia,
lexical features are used to recognize the lexical
evidence for hyponymy relations.
Lexico-syntactic patterns for hyponymy rela-
tion show different coverage and accuracy in hy-
ponymy relation acquisition (Ando et al, 2004).
Further if multiple lexico-syntactic patterns sup-
port acquisition of hyponymy relation candidates,
these candidates are more likely to be actual hy-
ponymy relations. The pattern feature of hy-
ponymy relation candidates is used for these ev-
idence.
We use PMI (point-wise mutual information)
of hyponymy relation candidate (hyper, hypo) as
a collocation feature (Pantel and Ravichandran,
2004), where we assume that hyper and hypo in
candidates would frequently co-occur in the same
sentence if they hold a hyponymy relation.
Semantic noun classes have been regarded as
useful information in semantic relation acquisi-
tion (De Saeger et al, 2009). EM-based clus-
tering (Kazama and Torisawa, 2008) is used for
obtaining 500 semantic noun classes4 from 5 ?
105 nouns (including single-word and multi-word
ones) and their 4? 108 dependency relations with
5 ? 105 verbs and other nouns in our target Web
4Because EM clustering provides a probability distri-
bution over noun class nc, we obtain discrete classes of
each noun n with a probability threshold p(nc|n) ?
0.2 (De Saeger et al, 2009).
846
Co-training Bilingual co-training Co-STAR
(Blum and Mitchell, 1998) (Oh et al, 2009) (Proposed method)
Instance space Same Different Almost different
Feature space Split by human decision Split by languages Split by source texts
Common instances Genuine-common Genuine-common Genuine-common and
(or All unlabeled) instances instances (Translatable) virtual-common instances
Table 2: Differences among co-training, bilingual co-training, and Co-STAR
corpus. For example, noun class C311 includes
biological or chemical substances such as tatou
(polysaccharide) and yuukikagoubutsu (organic
compounds). Noun classes (i.e., C311) relevant to
hyper and hypo, respectively, are used as a noun
class feature.
4 Related Work
There are two frameworks, which are most rele-
vant to our work ? bilingual co-training and en-
semble semantics.
The main difference between bilingual co-
training and Co-STAR lies in an instance space.
In bilingual co-training, instances are in different
spaces divided by languages while, in Co-STAR,
many instances are in different spaces divided by
their source texts. Table 2 shows differences be-
tween co-training, bilingual co-training and Co-
STAR.
Ensemble semantics is a relation acquisition
framework, where semantic relation candidates
are extracted from multiple sources and a single
ranker ranks or classifies the candidates in the fi-
nal step (Pennacchiotti and Pantel, 2009). In en-
semble semantics, one ranker is in charge of rank-
ing all candidates extracted from multiple sources;
while one classifier classifies candidates extracted
from one source in Co-STAR.
5 Experiments
We used the July version of Japanese Wikipedia
(jawiki-20090701) as structured text. We ran-
domly selected 24,000 hyponymy relation candi-
dates from those identified in Wikipedia and man-
ually checked them. 20,000 of these samples were
used as training data for our initial classifier, the
rest was equally divided into development and test
data for Wikipedia. They are called ?WikiSet.?
As unstructured text, we used 5 ? 107 Japanese
Web pages in the TSUBAKI corpus (Shinzato et
al., 2008). Here, we manually checked 9,500
hyponymy relation candidates selected randomly
from Web texts. 7,500 of these were used as train-
ing data. The rest was split into development and
test data. We named this data ?WebSet?.
In both classifiers, the development data was
used to select the optimal parameters, and the test
data was used to evaluate our system. We used
TinySVM (TinySVM, 2002) with a polynomial
kernel of degree 2 as a classifier. ? (the threshold
value indicating high confidence), ? (the thresh-
old value indicating low confidence), and TopN
(the maximum number of training instances to be
added to the existing training data in each iter-
ation) were selected through experiments on the
development set. The combination of ? = 1,
? = 0.3, and TopN=900 showed the best perfor-
mance and was used in the following experiments.
Evaluation was done by precision (P ), recall (R),
and F-measure (F ).
5.1 Results
We compare six systems. Three of these, B1?B3,
show the effect of different feature sets (?Wik-
iFeature? and ?WebFeature? in Table 1) and dif-
ferent training data. We trained two separate clas-
sifiers in B1 and B2, while we integrated feature
sets and training data for training a single classi-
fier in B3. The classifiers in these three systems
are trained with manually prepared training data
(?WikiSet? and ?WebSet?). For the purpose of our
experiment, we consider B3 as the closest possible
approximation of the ensemble semantics frame-
work (Pennacchiotti and Pantel, 2009).
? B1 consists of two completely independent
classifiers. Both S and U classifiers are
trained and tested on their own feature and
data sets (respectively ?WikiSet + WikiFea-
ture? and ?WebSet + WebFeature?).
847
? B2 is the same as B1, except that both clas-
sifiers are trained with all available training
data ? WikiSet and WebSet are combined
(27,500 training instances in total). However,
each classifier only uses its own feature set
(WikiFeature or WebFeature)5.
? B3 adds a master classifier to B1. This third
classifier is trained on the complete 27,500
training instances (same as B2) using all
available features from Table 1, including
each instance?s SVM scores obtained from
the two B1 classifiers6. The verdict of the
master classifier is considered to be the final
classification result.
The other three systems, BICO, Co-B, and Co-
STAR (our proposed method), are for compari-
son between bilingual co-training (Oh et al, 2009)
(BICO) and variants of Co-STAR (Co-B and Co-
STAR). Especially, we prepared Co-B and Co-
STAR to show the effect of different configura-
tions of common instances on the Co-STAR al-
gorithm. We use both B1 and B2 as the initial
classifiers of Co-B and Co-STAR. We notate Co-
B and Co-STAR without ??? when B1 is used as
their initial classifier and those with ??? when B2
is used.
? BICO implements the bilingual co-training
algorithm of (Oh et al, 2009), in which
two processes collaboratively acquire hy-
ponymy relations in two different languages.
For BICO, we prepared 20,000 English and
20,000 Japanese training samples (Japanese
ones are the same as training data in the
WikiSet) by hand.
? Co-B is a variant of Co-STAR that uses only
the genuine-common instances as common
instances (67,000 instances)7, to demonstrate
5Note that training instances from WebSet (or WikiSet)
can have WikiFeature (or WebFeature) if they also appear
in Wikipedia (or Web corpus). But they can always have
lexical feature, the common feature set between WikiFeature
and WebFeature.
6SVM scores are assigned to the instances in training data
in a 10-fold cross validation manner.
7Co-B can be considered as conventional co-
training (Blum and Mitchell, 1998) in the sense that
two classifiers collaborate through actual common instances.
the effectiveness of the virtual common in-
stances.
? Co-STAR is our proposed method, which
uses both genuine-common and virtual-
common instances (643,000 instances in to-
tal).
WebSet WikiSet
P R F P R F
B1 84.3 65.2 73.5 87.8 74.7 80.7
B2 83.4 69.6 75.9 87.4 79.5 83.2
B3 82.2 72.0 76.8 86.1 77.7 81.7
BICO N/A N/A N/A 84.5 81.8 83.1
Co-B 86.2 63.5 73.2 89.7 74.1 81.2
Co-B? 85.5 69.9 77.0 89.6 76.5 82.5
Co-STAR 85.9 76.0 80.6 88.0 81.8 84.8
Co-STAR? 83.3 80.7 82.0 87.6 81.8 84.6
Table 3: Comparison of different systems
Table 3 summarizes the result. Features for
common instances in Co-B and Co-STAR are pre-
pared in the same way as training data in B2, so
that both classifiers can classify the common in-
stances with their trained feature sets.
Comparison between B1?B3 shows that B2 and
B3 outperform B1 in F-measure. More train-
ing data used in B2?B3 (27,500 instances for
both WebSet and WikiSet) results in higher per-
formance than that of B1 (7,500 and 20,000 in-
stances used separately). We think that the lexical
features, assigned regardless of source text to in-
stances in B2?B3, are mainly responsible for the
performance gain over B1, as they are the least
domain-dependent type of features. B2?B3 are
composed of different number of classifiers, each
of which is trained with different feature sets and
training instances. Despite this difference, B2 and
B3 showed similar performance in F-measure.
Co-STAR outperformed the algorithm similar
to the ensemble semantics framework (B3), al-
though we admit that a more extensive com-
parison is desirable. Further Co-STAR outper-
formed BICO. While the manual cost for build-
ing the initial training data used in Co-STAR
and BICO is hard to quantify, Co-STAR achieves
better performance with fewer training data in
total (27,500 instances) than BICO (40,000 in-
stances). The difference in performance between
Co-B and Co-STAR shows the effectiveness of
848
the automatically generated virtual-common in-
stances. From these comparison, we can see that
virtual-common instances coupled with genuine-
common instances can be leveraged to enable
more effective collaboration between the two clas-
sifiers in Co-STAR.
As a result, our proposed method outperforms
the others in F-measure by 1.4?8.5%. We ob-
tained 4.3 ? 105 hyponymy relations from Web
texts and 4.6? 106 ones from Wikipedia8.
6 Co-STAR with Automatically
Generated Training Data
For Co-STAR, we need two sets of manually pre-
pared training data, one for structured text and the
other for unstructured text. As in any other su-
pervised system, the cost of preparing the training
data is an important issue. We therefore investi-
gated whether Co-STAR can be trained for a lower
cost by generating more of its training data auto-
matically.
We automatically built training data for Web
texts by using definition sentences9 and category
names in the Wikipedia articles, while we stuck to
manually prepared training data for Wikipedia. To
obtain hypernyms from Wikipedia article names,
we used definition-specific lexico-syntactic pat-
terns such as ?hyponym is hypernym? and ?hy-
ponym is a type of hypernym? (Kazama and Tori-
sawa, 2007; Sumida and Torisawa, 2008). Then,
we extracted hyponymy relations consisting of
pairs of Wikipedia category names and their mem-
ber articles when the Wikipedia category name
and the hypernym obtained from the definition
of the Wikipedia article shared the same head
word. Next, we selected a subset of the extracted
hyponymy relations that are also hyponymy re-
lation candidates in Web texts, as positive in-
stances for hyponymy relation acquisition from
Web text. We obtained around 15,000 positive in-
stances in this way. Negative instances were cho-
sen from virtual-common instances, which also
originated from the Wikipedia category system
and hyponymy relation candidates in Web texts
8We obtained them with 90% precision by setting the
SVM score threshold to 0.23 for Web texts and 0.1 for
Wikipedia.
9The first sentences of Wikipedia articles.
(around 293,000 instances).
The automatically built training data was noisy
and its size was much bigger than manually pre-
pared training data in WebSet. Thus 7,500 in-
stances as training data (the same number of man-
ually built training data in WebSet) were ran-
domly chosen from the positive and negative in-
stances with a positive:negative ratio of 1:410.
WebSet WikiSet
P R F P R F
B1 81.0 47.6 60.0 87.8 74.7 80.7
B2 80.0 55.4 65.5 87.1 79.5 83.1
B3 82.0 33.7 47.8 87.1 75.6 81.0
Co-STAR 82.2 60.8 69.9 87.3 80.7 83.8
Co-STAR? 79.2 69.6 74.1 87.0 81.8 84.4
Table 4: Results with automatically generated
training data
With the automatically built training data for
Web texts and manually prepared training data for
Wikipedia, we evaluated B1?B3 and Co-STAR,
which are the same systems in Table 3. The results
in Table 4 are encouraging. Co-STAR was robust
even when faced with noisy training data. Further
Co-STAR showed better performance than B1?
B3, although its performance in Table 4 dropped a
bit compared to Table 3. This result shows that we
can reduce the cost of manually preparing training
data for Co-STAR with only small loss of the per-
formance.
7 Conclusion
This paper proposed Co-STAR, an algorithm for
hyponymy relation acquisition from structured
and unstructured text. In Co-STAR, two indepen-
dent processes of hyponymy relation acquisition
from structured texts and unstructured texts, col-
laborate in an iterative manner through common
instances. To improve this collaboration, we in-
troduced virtual-common instances.
Through a series of experiments, we showed
that Co-STAR outperforms baseline systems and
virtual-common instances can be leveraged to
achieve better performance. We also showed that
Co-STAR is robust against noisy training data,
which requires less human effort to prepare it.
10We select the ratio by testing different ratio from 1:2 to
1:5 with our development data in WebSet and B1.
849
References
Ando, Maya, Satoshi Sekine, and Shun Ishiza. 2004.
Automatic extraction of hyponyms from Japanese
newspaper using lexico-syntactic patterns. In Proc.
of LREC ?04.
Blum, Avrim and Tom Mitchell. 1998. Combin-
ing labeled and unlabeled data with co-training. In
COLT? 98: Proceedings of the eleventh annual con-
ference on Computational learning theory, pages
92?100.
De Saeger, Stijn, Kentaro Torisawa, Jun?ichi Kazama,
Kow Kuroda, and Masaki Murata. 2009. Large
scale relation acquisition using class dependent pat-
terns. In Proc. of ICDM 2009, pages 764?769.
Hearst, Marti A. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th conference on Computational linguistics,
pages 539?545.
Kazama, Jun?ichi and Kentaro Torisawa. 2007. Ex-
ploiting Wikipedia as external knowledge for named
entity recognition. In Proc. of Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learn-
ing, pages 698?707.
Kazama, Jun?ichi and Kentaro Torisawa. 2008. In-
ducing gazetteers for named entity recognition by
large-scale clustering of dependency relations. In
Proceedings of ACL-08: HLT, pages 407?415.
Kurohashi, Sadao and Daisuke Kawahara. 2005. KNP
(Kurohashi-Nagao Parser) 2.0 users manual.
Oh, Jong-Hoon, Kiyotaka Uchimoto, and Kentaro
Torisawa. 2009. Bilingual co-training for mono-
lingual hyponymy-relation acquisition. In Proc. of
ACL-09: IJCNLP, pages 432?440.
Pantel, Patrick and Deepak Ravichandran. 2004. Au-
tomatically labeling semantic classes. In Proc. of
HLT-NAACL ?04, pages 321?328.
Pantel, Patrick, Eric Crestan, Arkady Borkovsky, Ana-
Maria Popescu, and Vishnu Vyas. 2009. Web-scale
distributional similarity and entity set expansion. In
Proceedings of EMNLP ?09, pages 938?947.
Pennacchiotti, Marco and Patrick Pantel. 2009. En-
tity extraction via ensemble semantics. In Proceed-
ings of the 2009 Conference on Empirical Methods
in Natural Language Processing, pages 238?247.
Ravi, Sujith and Marius Pasca. 2008. Using structured
text for large-scale attribute extraction. In CIKM-
08, pages 1183?1192.
Shinzato, Keiji and Kentaro Torisawa. 2004. Ex-
tracting hyponyms of prespecified hypernyms from
itemizations and headings in web documents. In
Proceedings of COLING ?04, pages 938?944.
Shinzato, Keiji, Tomohide Shibata, Daisuke Kawa-
hara, Chikara Hashimoto, and Sadao Kurohashi.
2008. Tsubaki: An open search engine infrastruc-
ture for developing new information access. In Pro-
ceedings of IJCNLP ?08, pages 189?196.
Snow, Rion, Daniel Jurafsky, and Andrew Y. Ng.
2006. Semantic taxonomy induction from heteroge-
nous evidence. In Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, pages 801?808.
Suchanek, Fabian M., Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: A Core of Semantic Knowl-
edge. In Proc. of WWW ?07, pages 697?706.
Sumida, Asuka and Kentaro Torisawa. 2008. Hack-
ing Wikipedia for hyponymy relation acquisition.
In Proc. of the Third International Joint Conference
on Natural Language Processing (IJCNLP), pages
883?888, January.
Talukdar, Partha Pratim, Joseph Reisinger, Marius
Pasca, Deepak Ravichandran, Rahul Bhagat, and
Fernando Pereira. 2008. Weakly-supervised acqui-
sition of labeled class instances using graph random
walks. In Proc. of EMNLP08, pages 582?590.
TinySVM. 2002. http://chasen.org/?taku/
software/TinySVM.
Van Durme, Benjamin and Marius Pasca. 2008. Find-
ing cars, goddesses and enzymes: Parametrizable
acquisition of labeled instances for open-domain in-
formation extraction. In Proc. of AAAI08, pages
1243?1248.
Vapnik, Vladimir N. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Wang, Wei and Zhi-Hua Zhou. 2007. Analyzing co-
training style algorithms. In ECML ?07: Proceed-
ings of the 18th European conference on Machine
Learning, pages 454?465.
850
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 825?835,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Relation Acquisition using Word Classes and Partial Patterns
Stijn De Saeger?? Kentaro Torisawa? Masaaki Tsuchida? Jun?ichi Kazama?
Chikara Hashimoto? Ichiro Yamada? Jong Hoon Oh? Istva?n Varga? Yulan Yan?
? Information Analysis Laboratory, National Institute of
Information and Communications Technology, 619-0289 Kyoto, Japan
{stijn,torisawa,kazama,ch,rovellia,istvan,yulan}@nict.go.jp
? Information and Media Processing Laboratories, NEC Corporation, 630-0101 Nara, Japan
m-tsuchida@cq.jp.nec.com
? Human & Information Science Research Division,
NHK Science & Technology Research Laboratories, 157-8510 Tokyo, Japan
yamada.i-hy@nhk.or.jp
Abstract
This paper proposes a semi-supervised rela-
tion acquisition method that does not rely on
extraction patterns (e.g. ?X causes Y? for
causal relations) but instead learns a combi-
nation of indirect evidence for the target re-
lation ? semantic word classes and partial
patterns. This method can extract long tail
instances of semantic relations like causality
from rare and complex expressions in a large
JapaneseWeb corpus? in extreme cases, pat-
terns that occur only once in the entire cor-
pus. Such patterns are beyond the reach of cur-
rent pattern based methods. We show that our
method performs on par with state-of-the-art
pattern based methods, and maintains a rea-
sonable level of accuracy even for instances
acquired from infrequent patterns. This abil-
ity to acquire long tail instances is crucial for
risk management and innovation, where an ex-
haustive database of high-level semantic rela-
tions like causation is of vital importance.
1 Introduction
Pattern based relation acquisition methods rely on
lexico-syntactic patterns (Hearst, 1992) for extract-
ing relation instances. These are templates of natu-
ral language expressions such as ?X causes Y ? that
signal an instance of some semantic relation (i.e.,
causality). Pattern based methods (Agichtein and
Gravano, 2000; Pantel and Pennacchiotti, 2006b;
Pas?ca et al, 2006; De Saeger et al, 2009) learn many
? This work was done when all authors were at the National
Institute of Information and Communications Technology.
such patterns to extract new instances (word pairs)
from the corpus.
However, since extraction patterns are learned us-
ing statistical methods that require a certain fre-
quency of observations, pattern based methods fail
to capture relations from complex expressions in
which the pattern connecting the two words is rarely
observed. Consider the following sentence:
?Curing hypertension alleviates the deteriora-
tion speed of the renal function, thereby lower-
ing the risk of causing intracranial bleeding?
Humans can infer that this sentence expresses a
causal relation between the underlined noun phrases.
But the actual pattern connecting them, i.e., ?Cur-
ing X alleviates the deterioration speed of the re-
nal function, thereby lowering the risk of causing
Y ?, is rarely observed more than once even in a 108
page Web corpus. In the sense that the term pat-
tern implies a recurring event, this expression con-
tains no pattern for detecting the causal relation be-
tween hypertension and intracranial bleeding. This
is what we mean by ?long tail instances? ? words
that co-occur infrequently, and only in sparse extrac-
tion contexts.
Yet an important application of relation extraction
is mining the Web for so-called unknown unknowns
? in the words of D. Rumsfeld, ?things we don?t
know we don?t know? (Torisawa et al, 2010). In
knowledge discovery applications like risk manage-
ment and innovation, the usefulness of relation ex-
traction lies in its ability to find many unexpected
remedies for diseases, causes of social problems,
and so on. To give an example, our relation extrac-
825
tion system found a blog post mentioning Japanese
automaker Toyota as a hidden cause of Japan?s de-
flation. Several months later the same connection
was made in an article published in an authoritative
economic magazine.
We propose a semi-supervised relation extraction
method that does not rely on direct pattern evidence
connecting the two words in a sentence. We argue
that the role of binary patterns can be replaced by a
combination of two types of indirect evidence: se-
mantic class information about the target relation
and partial patterns, which are fragments or sub-
patterns of binary patterns. The intuition is this: if
a sentence like the example sentence above contains
some wordX belonging to the class of medical con-
ditions and another word Y from the class of trau-
mas, and X matches the partial pattern ?. . . causing
X?, there is a decent chance that this sentence ex-
presses a causal relation between X and Y . We
show that just using this combination of indirect
evidence we can pick up semantic relations with
roughly 50% precision, regardless of the complexity
or frequency of the expression in which the words
co-occur. Furthermore, by combining this idea with
a straightforward machine learning approach, the
overall performance of our method is on par with
state-of-the-art pattern based methods. However,
our method manages to extract a large number of
instances from sentences that contain no pattern that
can be learned by pattern induction methods.
Our method is a two-stage system. Figure 1
presents an overview. In Stage 1 we apply a state-
of-the-art pattern based relation extractor to a Web
corpus to obtain an initial batch of relation instances.
In Stage 2 a supervised classifier is built from vari-
ous components obtained from the output of Stage
1. Given the output of Stage 1 and access to a
Web corpus, the Stage 2 extractor is completely
self-sufficient, and the whole method requires no
supervision other than a handful of seed patterns
to start the first stage extractor. The whole proce-
dure is therefore minimally supervised. Semantic
word classes and partial patterns play a crucial role
throughout all steps of the process.
We evaluate our method on three relation acqui-
sition tasks (causation, prevention and material re-
lations) using a 600 million Japanese Web page cor-
Figure 1: Proposed method: data flow.
pus (Shinzato et al, 2008) and show that our sys-
tem can successfully acquire relations from both
frequent and infrequent patterns. Our system ex-
tracted 100,000 causal relations with 84.6% preci-
sion, 50,000 prevention relations with 58.4% preci-
sion and 25,000 material relations with 76.1% preci-
sion. In the extreme case, we acquired several thou-
sand word pairs co-occurring only in patterns that
appear once in the entire corpus. We call such pat-
terns single occurrence (SO) patterns. Word pairs
that co-occur only with SO patterns represent the
theoretical limiting case of relations that cannot be
acquired using existing pattern based methods. In
this sense our method can be seen as complemen-
tary with pattern based approaches, and merging our
method?s output with that of a pattern based method
may be beneficial.
2 Stage 1 Extractor
This section introduces our Stage 1 extractor: the
pattern based method from (De Saeger et al, 2009),
which we call CDP for ?class dependent patterns?.
We give a brief overview below, and refer the reader
to the original paper for a more comprehensive ex-
planation.
CDP takes a set of seed patterns as input, and au-
tomatically learns new class dependent patterns as
paraphrases of the seed patterns. Class dependent
patterns are semantic class restricted versions of or-
dinary lexico-syntactic patterns. Existing methods
use class independent patterns such as ?X causes
Y ? to learn causal relations betweenX and Y . Class
dependent patterns however place semantic class re-
826
strictions on the noun pairs they may extract, like
?Yaccidents causes Xincidents?. The accidents and
incidents subscripts specify the semantic class of the
X and Y slot fillers.
These class restrictions make it possible to distin-
guish between multiple senses of highly ambiguous
patterns (so-called ?generic? patterns). For instance,
given the generic pattern ?Y by X?, if we restrict
Y and X in to the semantic classes of injuries and
accidents (as in ?death by drowning?), the class de-
pendent pattern ?Yinjuries by Xaccidents? becomes a
valid paraphrase of ?X causes Y ? and can safely be
used to extract causal relations, whereas other class
dependent versions of the same generic pattern (e.g.,
?Yproducts byXcompanies?, as in ?iPhone by Apple?)
may not.
CDP ranks each noun pair in the corpus accord-
ing to a score that reflects its likelihood of being
a proper instance of the target relation, by calcu-
lating the semantic similarity of a set of seed pat-
terns to the class dependent patterns this noun pair
co-occurs with. The output of CDP is a list of noun
pairs ranked by score, together with the highest scor-
ing class dependent pattern each noun pair co-occurs
with. This list becomes the input to Stage 2 of our
method, as shown in Figure 1. We adopted CDP as
Stage 1 extractor because, besides having generally
good performance, the class dependent patterns pro-
vide the two fundamental ingredients for Stage 2 of
our method ? the target semantic word classes for a
given relation (in the form of the semantic class re-
strictions attached to patterns), and partial patterns.
To obtain fine-grained semantic word classes we
used the large scale word clustering algorithm from
(Kazama and Torisawa, 2008), which uses the EM
algorithm to compute the probability that a word w
belongs to class c, i.e., P (c|w). Probabilistic cluster-
ing defines no discrete boundary between members
and non-members of a semantic class, so we simply
assume w belongs to c whenever P (c|w) ? 0.2. For
this work we clustered 106 nouns into 500 classes.
Finally, we adopt the structural representation of
patterns introduced in (Lin and Pantel, 2001). All
sentences in our corpus are dependency parsed, and
patterns consist of words on the path of dependency
relations connecting two nouns.
3 Stage 2 Extractor
We use CDP as our Stage 1 extractor, and the top
N noun pairs along with the class dependent pat-
terns that extract them are given as input to Stage 2,
which represents the main contribution of this work.
As shown in Figure 1, Stage 2 consists of three mod-
ules: a candidate generator, a training data gener-
ator and a supervised classifier. The training data
generator builds training data for the classifier from
the top N output of CDP and sentences retrieved
from the Web corpus. This classifier then scores and
ranks the candidate relations generated by the can-
didate relation generator. We introduce each module
below.
Candidate Generator This module generates
sentences containing candidate word pairs for the
target relation from the corpus. It does so using the
semantic class restrictions and partial patterns ob-
tained from the output of CDP. The set of all seman-
tic class pairs obtained from the class dependent pat-
terns that extracted the topN results become the tar-
get semantic class pairs from which new candidate
instances are generated. We extract all sentences
containing a word pair belonging to one of the target
class pairs from the corpus.
From these sentences we keep only those that con-
tain a trace of evidence for the target semantic re-
lation. For this we decompose the class dependent
patterns from the Stage 1 extractor into partial pat-
terns. As mentioned previously, patterns consist of
words on the path of dependency relations connect-
ing the two target words in a syntactic tree. To obtain
partial patterns we split this dependency path into its
two constituent branches, each one leading from the
leaf word (i.e. variable) to the syntactic head of the
pattern. For example, ?X subj?? causes obj?? Y ? is
split into two partial patterns ?X subj?? causes? and
?causes obj?? Y ?. These partial patterns capture the
predicate structures in binary patterns.1 We discard
partial patterns with syntactic heads other than verbs
or adjectives.
The candidate genarator retrieves all sentences
from the corpus in which two nouns belonging to
one of the target semantic classes co-occur and
1 In Japanese, case information is encoded in post-positions
attached to the noun.
827
where at least one of the nouns matches a partial pat-
tern. As shown in Figure 1, these sentences and the
candidate noun pairs they contain (called (noun pair,
sentence) triples hereafter) are submitted to the clas-
sifier for scoring. Restricting candidate noun pairs
by this combination of semantic word classes and
partial pattern matching proved to be quite powerful.
For instance, in the case of causal relations we found
that close to 60% of the (noun pair, sentence) triples
produced by the candidate generator were correct
(Figure 6).
Training Data Generator As shown in Figure 1,
the (noun pair, sentence) triples used as training data
for the SVM classifier were generated from the top
results of the Stage 1 extractor and the corpus. We
consider the noun pairs in the top N output of the
Stage 1 extractor as true instances of the target re-
lation (even though they may contain erroneous ex-
tractions), and retrieve from the corpus all sentences
in which these noun pairs co-occur and that match
one of the partial patterns mentioned above. In our
experiments we set N to 25, 000. We randomly se-
lect positive training samples from this set of (noun
pair, sentence) triples.
Negative training samples are also selected ran-
domly, as follows. If one member of the target noun
pair in the positive samples above matches a partial
pattern but the other does not, we randomly replace
the latter by another noun found in the same sen-
tence, and generate this new (noun pair, sentence)
triple as a negative training sample. In the causal
relation experiments this approach had about 5%
chance of generating false negatives ? noun pairs
contained in the top N results of the Stage 1 extrac-
tor. Such samples were discarded. Our experimen-
tal results show that this scheme works quite well in
practice. We randomly sample M positive and neg-
ative samples from the autogenerated training data
to train the SVM. M was empirically set to 50,000
in our experiments.
SVM Classifier We used a straightforward fea-
ture set for training the SVM classifier. Because
our classifier will be faced with sentences contain-
ing long and infrequent patterns where the distance
between the two target nouns may be quite large,
we did not try to represent lexico-syntactic patterns
as features but deliberately restricted the feature set
to local context features of the candidate noun pair
in the target sentence. Concretely, we looked at bi-
grams and unigrams surrounding both nouns of the
candidate relation, as the local context around the
target words may contain many telling expressions
like ?increase in X? or ?X deficiency? which are use-
ful clues for causal relations. Also, in Japanese case
information is encoded in post-positions attached to
the noun, which is captured by the unigram features.
In addition to these base features, we include the
semantic classes to which the candidate noun pair
belongs, the partial patterns they match in this sen-
tence, and the infix words inbetween the target noun
pair. Note that this feature set is not intended to
be optimal beyond the actual claims of this paper,
and we have deliberately avoided exhaustive fea-
ture engineering so as not to obscure the contribu-
tion of semantic classes and partial pattern to our
approach. Clearly an optimal classifier will incorpo-
rate many more advanced features (see GuoDong et
al. (2005) for a comprehensive overview), but even
without sophisticated feature engineering our clas-
sifier achieved sufficient performance levels to sup-
port our claims. An overview of the feature set is
given in Table 1. The relative contribution of each
type of features is discussed in section 4. In prelim-
inary experiments we found a polynomial kernel of
degree 3 gave the best results, which suggests the ef-
fectiveness of combining different types of indirect
evidence.
The SVM classifier outputs (noun pair, sentence)
triples, ranked by SVM score. To obtain the final
output of our method we assign each unique noun
pair the maximum score from all (noun pair, sen-
tence) triples it occurs in, and discard all other sen-
tences for this noun pair. In section 4 below we eval-
uate the acquired noun pairs in the context of the
sentence that maximizes their score.
4 Evaluation
We demonstrate the effectiveness of semantic word
classes and partial pattern matching for relation ex-
traction by showing that the method proposed in this
paper performs at the level of other state-of-the-art
relation acquisition methods. In addition we demon-
strate that our method can successfully extract re-
lation instances from infrequent patterns, and we
828
Feature type Description Number of features
Morpheme features Unigram and bigram morphemes surrounding both target words. 554,395
POS features Coarse- and fine-grained POS tags of the noun pair and morpheme features. 2,411
Semantic features Semantic word classes of the target noun pair. 1000 (500 classes ?2)
Infix word features Morphemes found inbetween the target noun pair. 94,448
Partial patterns Partial patterns matching the target noun pair. 86
Table 1: Feature set used in the Stage 2 classifier, and their number for the causal relation experiments.
explore several criteria for what constitutes an in-
frequent pattern ? including the theoretical limit-
ing case of patterns observed only once in the en-
tire corpus. These instances are impossible to ac-
quire by pattern based methods. The ability to ac-
quire relations from extremely infrequent expres-
sions with decent accuracy demonstrates the utility
of combining semantic word classes with partial pat-
tern matching.
4.1 Experimental Setting
We evaluate our method on three semantic relation
acquisition tasks: causality, prevention and mate-
rial. Two concepts stand in a causal relation when
the source concept (the ?cause?) is directly or indi-
rectly responsible for the subsequent occurrence of
the target concept (its ?effect?). In a prevention rela-
tion the source concept directly or indirectly acts to
avoid the occurrence of the target concept, and in a
material relation the source concept is a material or
ingredient of the target concept.
For our experiments we used the latest version
of the TSUBAKI corpus (Shinzato et al, 2008),
a collection of 600 million Japanese Web pages
dependency parsed by the Japanese dependency
parser KNP2. In our implementation of CDP, lexico-
syntactic patterns consist of words on the path con-
necting two nouns in a dependency parse tree. We
discard patterns from dependency paths longer than
8 constituent nodes. Furthermore, we estimated pat-
tern frequencies in a subset of the corpus (50 million
pages, or 1/12th of the entire corpus) and discarded
patterns that co-occur with less than 10 unique noun
pairs in this smaller corpus. These restrictions do
not apply to the proposed method, which can extract
noun pairs connected by patterns of arbitrary length,
even if found only once in the corpus. For our pur-
2 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html
pose we treat dependency paths whose observed fre-
quency is below this threshold as insufficiently fre-
quent to be considered as ?patterns?. This threshold
is of course arbitrary, but in section 4 we show that
our results are not affected by these implementation
details.
We asked three human judges to evaluate ran-
dom (noun pair, sentence) triples, i.e. candidate
noun pairs in the context of some corpus sentence
in which they co-occur. If the judges find the sen-
tence contains sufficient evidence that the target re-
lation holds between the candidate nouns, they mark
the noun pair correct. To evaluate the performance
of each method we use two evaluation criteria: strict
(all judges must agree the candidate relation is cor-
rect) and lenient (decided by the judges? majority
vote). Over all experiments the interrater agreement
(Kappa) ranged between 0.57 and 0.82 with an aver-
age of 0.72, indicating substantial agreement (Lan-
dis and Koch, 1977).
4.1.1 Methods Compared
We compare our results to two pattern based
methods: CDP (the Stage 1 extractor) and Espresso
(Pantel and Pennacchiotti, 2006a).
Espresso is a popular bootstrapping based method
that uses a set of seed instances to induce extraction
patterns for the target relation and then acquire new
instances in an iterative bootstrapping process. In
each iteration Espresso performs pattern induction,
pattern ranking and selection using previously ac-
quired instances, and uses the newly acquired pat-
terns to extraction new instances. Espresso com-
putes a reliability score for both instances and pat-
terns based on their pointwise mutual information
(PMI) with the top-scoring patterns and instances
from the previous iteration.3 We refer to (Pantel and
3 In our implementation of Espresso we found that, despite
the many parameters for controlling the bootstrapping process,
829
30%
40%
50%
60%
70%
80%
90%
100%
0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100K
Proposed (L)
Proposed (S)
Prop. w/o CDP (L)
Prop. w/o CDP (S)
Prop. w/o pattern (L)
Prop. w/o pattern (S)
Espresso (L)
Espresso (S)CDP (L)CDP (S)
Figure 2: Precision of acquired relations (causality). L
and S denote lenient and strict evaluation.
Pennacchiotti, 2006a) for a more detailed descrip-
tion.
For all methods compared we rank the acquired
noun pairs by their score and evaluated 500 random
samples from the top 100,000 results. For noun pairs
acquired by CDP and Espresso we select the pattern
that extracted this noun pair (in the case of Espresso,
the pattern with the highest PMI for this noun pair),
and randomly select a sentence in which the noun
pair co-occurs with that pattern from our corpus. For
the proposed method we evaluate noun pairs in the
context of the (noun pair, sentence) triple with the
highest SVM score.
4.2 Results and Discussion
The performance of each method on the causality,
prevention and material relations are shown in Fig-
ures 2, 3 and 4 respectively. In the causality exper-
iments (Figure 2) the proposed method performs on
par with CDP for the top 25,000 results, both achiev-
ing close to 90% precision. But whereas CDP?s per-
it remains very difficult to prevent semantic drift (Komachi et
al., 2008) from occurring. One small adjustment to the al-
gorithm stabilized the bootstrapping process considerably and
gave overall better results. In the pattern induction step (sec-
tion 3.2 in (Pantel and Pennacchiotti, 2006a)), Espresso com-
putes a reliability score for each candidate pattern based on the
weighted PMI of the pattern with all instances extracted so far.
As the number of extracted instances increases this dispropor-
tionally favours high frequency (i.e. generic) patterns, so in-
stead of using all instances for computing pattern reliability we
only use the m most reliable instances from the previous iter-
ation, which were used to extract the candidate patterns of the
current iteration (m = 200, like the original).
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100K
Proposed (L)
Proposed (S)
Prop. w/o CDP (L)
Prop. w/o CDP (S)
Prop. w/o pattern (L)
Prop. w/o pattern (S)
Espresso (L)
Espresso (S)CDP (L)CDP (S)
Figure 3: Precision of acquired relations (prevention). L
and S denote lenient and strict evaluation.
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100K
Proposed (L)
Proposed (S)
Prop. w/o CDP (L)
Prop. w/o CDP (S)
Prop. w/o pattern (L)
Prop. w/o pattern (S)
Espresso (L)
Espresso (S)CDP (L)CDP (S)
Figure 4: Precision of acquired relations (material). L
and S denote lenient and strict evaluation.
formance drops from there our method maintains
the same high precision throughout (84.6%, lenient).
Both our method and CDP outperform Espresso by
a large margin.
For the prevention relation (Figure 3), precision
is considerably lower for all methods except the top
10,000 of CDP (82% precision, lenient). The pro-
posed method peaks at around 20,000 results (67%
precision, lenient) and performance remains more or
less constant from there on. The proposed method
overtakes CDP?s performance around the top 45,000
mark, which suggests that combining the results of
both methods may be beneficial.
In the material relations the proposed method
slightly outperforms both pattern based methods
in the top 10,000 results (92% precision, lenient).
830
However for this relation our method produced only
35,409 instances. The reason is that the top 25,000
results of CDP were all extracted by just 12 patterns,
and these contained many patterns whose syntactic
head is not a verb or adjective (like ?Y rich in X? or
?Y containing X?). Only 12 partial patterns were ob-
tained, which greatly reduced the output of the pro-
posed method. Taking into account the high perfor-
mance of CDP for material relations, this suggests
that for some relations our method?s N and M pa-
rameters could use some tuning. In conclusion, in
all three relations our method performs at a level
comparable to state-of-the-art pattern based meth-
ods, which is remarkable given that it only uses in-
direct evidence.
Dealing with Difficult Extractions How does our
method handle noun pairs that are difficult to ac-
quire by pattern based methods? The graphs marked
?Prop. w/o CDP? (Proposed without CDP) in Fig-
ures 2 , 3 and 4 show the number and precision of
evaluated samples from the proposed method that do
not co-occur in our corpus with any of the patterns
that extracted the top N results of the first stage ex-
tractor. These graphs show that our method is not
simply regenerating CDP?s top results but actually
extracts many noun pairs that do not co-occur in pat-
terns that are easily learned. Figure 2 shows that
roughly two thirds of the evaluated samples are in
this category, and that their performance is not sig-
nificantly worse than the overall result. The same
conclusion holds for the prevention results (Figure
3), where over 80% of the proposed method?s sam-
ples are noun pairs that do not co-occur with eas-
ily learnable patterns. Their precision is about 5%
worse than all samples from the proposed method.
For material relations (Figure 4) about half of all
evaluated samples are in this category, but their pre-
cision is markedly worse compared to all results.
For genuinely infrequent patterns, the graphs
marked ?Prop. w/o pattern? (Proposed without pat-
tern) in Figures 2 , 3 and 4 show the number and
precision of noun pairs evaluated for the proposed
method that were acquired from sentences without
any discernible pattern. As explained in section 4
above, these constitute noun pairs co-occurring in a
sentence in which the path of dependency relations
connecting them is either longer than 8 nodes or can
 0
 5
 10
 15
 20
1 2 32 1024 32768 1.05x106 3.36x107
% o
f al
l sa
mp
les
# of noun pairs co-occurring with patterns
Pattern frequency, CDPPattern frequency, ProposedPattern frequency, Espresso
Figure 5: Frequencies of patterns in the evaluation data
(causation).
extract fewer than 10 noun pairs in 50 million Web
pages. Note that in theory it is possible that these
noun pairs could not be acquired by pattern based
methods due to this threshold ? patterns must be
able to extract more than 10 different noun pairs in
a subset of our corpus, while the proposed method
does not have this constraint. So at least in the-
ory, pattern based methods might be able to acquire
all noun pairs obtained by our method by lowering
this threshold. To see that this is unlikely to be the
case, consider Figure 5, which shows the pattern fre-
quency of the patterns induced by CDP and Espresso
for the causality experiment. The x-axis represents
pattern frequency in terms of the number of unique
noun pairs a pattern co-occurs with in our corpus (on
a log scale), and the y-axis shows the percentage of
samples that was extracted by patterns of a given fre-
quency.4 Figure 5 shows that for the pattern based
methods, the large majority of noun pairs was ex-
tracted by patterns that co-occur with several thou-
sand different noun pairs. Extrapolating the original
frequency threshold of 10 nounpairs to the size of
our entire corpus roughly corresponds to about 120
distinct noun pairs (10 times in 1/12th of the entire
corpus). In Figure 5, the histograms for the pattern
based methods CDP and Espresso start around 1000
noun pairs, which is far above this new lowerbound.
4 In the case of CDP we ignore semantic class restrictions
on the patterns when comparing frequencies. For Espresso, the
most frequent pattern (?Y by X? at the 24,889,329 data point
on the x-axis) extracted up to 53.8% of the results, but the graph
was cut at 20% for readability.
831
Cau
sali
ty
??????? ??????????????????????????????????????????[????]??????
Because ?catecholamine? causes a rapid increase of heart rate, the change of circulation inside the blood vessels leads to blood vessel
disorders and promotes [thrombus generation].
????? ??????????????????????????????????? [????]?????????????
When we injected Xylocaine during a ?tachycardia seizure?, the patient suddenly lost consciousness and fell into a fit of [convulsions].
???????? ????????? ????????? [???]???????????????
(. . . ) The reason is that by taking a lot of ?animal proteins? the causative agents of [tragomaschalia] increase.
*???????????? ?????? ?????????????????????? [???]?
* [Radon] heightens the (body?s) antioxidative function and is effective for eliminating activated oxygen, which is a cause of aging and
?lifestyle-related? diseases.
Pre
ven
tion
???????????????????? ???? ??????????????[???]?????????????
Because the fatty meat of tuna contains DHA and ?EPA? in abundance, it is effective for preventing [neuralgia].
??????? ????? ??????? [????]?????????
If you use ?nitrogen gas? instead of air you may prevent [dust explosions].
??????????? ??????? ???????????????????????? [???]???????????
In ancient Europe ?orthosiphon aristatus? tea was called a ?diet tea?, and supposedly it helps preventing triglycerides and [adult diseases].
* ?? ???????????????????????? [????]????????
* (It) is something that prevents [scratches] on the screen if the ?calash? gets stuck between the screens during storage.
Table 2: Causality and Prevention relations acquired from Single Occurrence (SO) patterns. ?X? and [Y] indicate the
relation instance?s source and target words, and ?*? indicates erroneous extractions.
Thus, pattern based methods naturally tend to induce
patterns that are much more frequent than the range
of patterns our method can capture, and it is unlikely
that this is a result of implementation details like pat-
tern frequency threshold.
The precision of noun pairs in the category ?Prop.
w/o pattern? is clearly lower than the overall re-
sults, but the graphs demonstrate that our method
still handles these difficult cases reasonably well.
The 500 samples evaluated contained 155 such in-
stances for causality, 403 for prevention and 276 for
material. For prevention, the high ratio of these noun
pairs helps explain why the overall performance was
lower than for the other relations.
Finally, the theoretical limiting case for pattern
based algorithms consists of patterns that only co-
occur with a single noun pair in the entire corpus
(single occurrence or SO patterns). Pattern based
methods learn new patterns that share many noun
pairs with a set of reliable patterns in order to extract
new relation instances. If a noun pair that co-occurs
with a SO pattern also co-occurs with more reliable
patterns there is no need to learn the SO pattern. If
that same noun pair does not co-occur with any other
reliable pattern, the SO pattern is beyond the reach
of any pattern induction method. Thus, SO patterns
are effectively useless for pattern based methods.
For the 500 samples evaluated from the causality
and prevention relations acquired by our method we
found 7 causal noun pairs that co-occur only in SO
patterns and 29 such noun pairs for prevention. The
precision of these instances was 42.9% and 51.7%
respectively. In total we found 8,716 causal noun
pairs and 7,369 prevention noun pairs that co-occur
only with SO patterns. Table 2 shows some example
relations from our causality and prevention experi-
ments that were extracted from SO patterns. To con-
clude, our method is able to acquire correct relations
even from the most extreme infrequent expressions.
Semantic Classes, Partial Patterns or Both? In
the remainder of this section we look at how the
combination of semantic word classes and partial
patterns benefits our method. For each relation we
evaluated 1000 random (noun pair, sentence) triples
satisfying the two conditions from section 3 ?
matching semantic class pairs and partial patterns.
Surprisingly, the precision of these samples was
59% for causality, 40% for prevention and 50.4%
for material, showing just how compelling these two
types of indirect evidence are in combination.
To estimate the relative contribution of each
heuristic we compared our candidate generation
method against two baselines. The first baseline
evaluates the precision of random noun pairs from
832
 50
 60
 70
 80
 90
 100
 0  200  400  600  800  1000
pre
cis
ion
 (%
)
(noun pair, sentence) triples ranked by score
Base features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll features
Figure 6: Contribution of feature sets (causality).
 30
 40
 50
 60
 70
 80
 90
 100
 0  200  400  600  800  1000
pre
cis
ion
 (%
)
(noun pair, sentence) triples ranked by score
Base features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll features
Figure 7: Contribution of feature sets (prevention).
the target semantic classes that co-occur in a sen-
tence. The second baseline does the same for the
second heuristic, selecting random sentences con-
taining a noun pair that matches some partial pat-
tern. Evaluating 100 samples for causality and pre-
vention, we found the precision of the semantic class
baseline was 16% for causality and 5% for preven-
tion. The pattern fragment baseline gave 9% for
causality and 22% for prevention. This is consid-
erably lower than the precision of random samples
that satisfy both the semantic class and partial pat-
tern conditions, showing that the combination of se-
mantic classes and partial patterns is more effective
than either one individually.
Finally, we investigated the effect of the various
feature sets used in the classifier. Figures 6, 7 and
8 show the results for the respective semantic re-
lations. The ?Base features? graph shows the per-
 30
 40
 50
 60
 70
 80
 90
 100
 0  200  400  600  800  1000
pre
cis
ion
 (%
)
(noun pair, sentence) triples ranked by score
Base features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll features
Figure 8: Contribution of feature sets (material).
formance the unigram, bigram and part-of-speech
features. ?All features? uses all features in Table
1. The other graphs show the effect of removing
one type of features. These graphs suggest that the
contribution of the individual feature types (seman-
tic class information, partial patterns or infix words)
to the classification performance is relatively minor,
but in combination they do give a marked improve-
ment over the base features, at least for some rela-
tions like causation and material. In other words,
the main contribution of semantic word classes and
partial patterns to our method?s performance lies not
in the final classification step but seems to occur at
earlier stages of the process, in the candidate and
training data generation steps.
5 Related Work
Using lexico-syntactic patterns to extract semantic
relations was first explored by Hearst (Hearst, 1992),
and has inspired a large body of work on semi-
supervised relation acquisition methods (Berland
and Charniak, 1999; Agichtein and Gravano, 2000;
Etzioni et al, 2004; Pantel and Pennacchiotti,
2006b; Pas?ca et al, 2006; De Saeger et al, 2009),
two of which were used in this work.
Some researchers have addressed the sparse-
ness problems inherent in pattern based methods.
Downey et al (2007) starts from the output of
the unsupervised information extraction system Tex-
tRunner (Banko and Etzioni, 2008), and uses lan-
guage modeling techniques to estimate the reliabil-
ity of sparse extractions. Pas?ca et al (2006) alle-
833
viates pattern sparseness by using infix patterns that
are generalized using classes of distributionally sim-
ilar words. In addition, their method employs clus-
tering based semantic similarities to filter newly ex-
tracted instances in each iteration of the bootstrap-
ping process. A comparison with our method would
have been instructive, but we were unable to imple-
ment their method because the original paper con-
tains insufficient detail to allow replication.
There is a large body of research in the super-
vised tradition that does not use explicit pattern rep-
resentations ? kernel based methods (Zelenko et
al., 2003; Culotta, 2004; Bunescu and Mooney,
2005) and CRF based methods (Culotta et al, 2006).
These approaches are all fully supervised, whereas
in our work the automatic generation of candi-
dates and training data is an integral part of the
method. An interesting alternative is distant super-
vision (Mintz et al, 2009), which trains a classi-
fier using an existing database (Freebase) containing
thousands of semantic relations, with millions of in-
stances. We believe our method is more general, as
depending on external resources like a database of
semantic relations limits both the range of seman-
tic relations (i.e., Freebase contains only relations
between named entities, and none of the relations
in this work) and languages (i.e., no resource com-
parable to Freebase exists for Japanese) to which
the technology can be applied. Furthermore, it is
unclear whether distant supervision can deal with
noisy input such as automatically acquired relation
instances.
Finally, inference based methods (Carlson et al,
2010; Schoenmackers et al, 2010; Tsuchida et al,
2010) are another attempt at relation acquisition that
goes beyond pattern matching. Carlson et al (2010)
proposed a method based on inductive logic pro-
gramming (Quinlan, 1990). Schoenmackers et al
(2010) takes relation instances produced by Tex-
tRunner (Banko and Etzioni, 2008) as input and in-
duces first-order Horn clauses, and new instances are
infered using a Markov Logic Network (Richardson
and Domingo, 2006; Huynh and Mooney, 2008).
Tsuchida et al (2010) generated new relation hy-
potheses by substituting words in seed instances
with distributionally similar words. The difference
between these works and ours lies in the treatment
of evidence. While the above methods learn infer-
ence rules to acquire new relation instances from in-
dependent information sources scattered across dif-
ferent Web pages, our method takes the other option
of working with all the clues and indirect evidence a
single sentence can provide. In the future, a combi-
nation of both approaches may prove beneficial.
6 Conclusion
We have proposed a relation acquisition method that
is able to acquire semantic relations from infrequent
expressions by focusing on the evidence provided by
semantic word classes and partial pattern matching
instead of direct extraction patterns. We experimen-
tally demonstrated the effectiveness of this approach
on three relation acquisition tasks, causality, preven-
tion and material relations. In addition we showed
our method could acquire a significant number of
relation instances that are found in extremely infre-
quent expressions, the most extreme case of which
are single occurrence patterns, which are beyond
the reach of existing pattern based methods. We be-
lieve this ability is of crucial importance for acquir-
ing valuable long tail instances. In future work we
will investigate whether the current framework can
be extended to acquire inter-sentential relations.
References
Eugene Agichtein and Luis Gravano. 2000. Snowball:
extracting relations from large plain-text collections.
In Proc. of the fifth ACM conference on Digital li-
braries, pages 85?94.
Michele Banko and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proc. of the 46th ACL-08:HLT, pages 28?36.
Matthew Berland and Eugene Charniak. 1999. Find-
ing parts in very large corpora. In Proceedings of the
37th Annual Meeting of the Association for Computa-
tional Linguistics, pages 57?64, College Park, Mary-
land, USA, June.
Razvan C. Bunescu and Raymond J. Mooney. 2005. A
shortest path dependency kernel for relation extrac-
tion. In Proceedings of the Conference on Human
Language Technology and Empirical Methods in Nat-
ural Language Processing (HLT ?05), pages 724?731.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka Jr., and Tom M.
Mitchell. 2010. Toward an architecture for neverend-
ing language learning. In Proc of the 24th AAAI, pages
1306?1313.
834
Aron Culotta, Andrew McCallum, and Jonathan Betz.
2006. Integrating probabilistic extraction models and
data mining to discover relations and patterns in text.
In Human Language Technology Conference of the
North American Chapter of the Association of Com-
putational Linguistics (HLT/NAACL), pages 296?303.
Aron Culotta. 2004. Dependency tree kernels for rela-
tion extraction. In In Proceedings of the 42nd Annual
Meeting of the Association for Computational Linguis-
tics (ACL-04, pages 423?429.
Stijn De Saeger, Kentaro Torisawa, Jun?ichi Kazama,
Kow Kuroda, and Masaki Murata. 2009. Large Scale
Relation Acquisition Using Class Dependent Patterns.
In Proc. of the 9th International Conference on Data
Mining (ICDM), pages 764?769.
Doug Downey, Stefan Schoenmackers, and Oren Etzioni.
2007. Sparse information extraction: Unsupervised
language models to the rescue. In Proceedings of the
45th Annual Meeting of the Association for Computa-
tional Linguistics (ACL2007).
Oren Etzioni, Michael Cafarella, Doug Downey, Stanley
Kok, Ana-Maria Popescu, Tal Shaked, Stephen Soder-
land, Daniel Weld, and Alexander Yates. 2004. Web-
scale information extraction in KnowItAll. In Proc. of
the 13th international conference on World Wide Web
(WWW04), pages 100?110.
Zhou GuoDong, Su Jian, Zhang Jie, and Zhang Min.
2005. Exploring various knowledge in relation extrac-
tion. In Proc. of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, ACL ?05, pages
419?444.
Marti Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proc. of the 14th In-
ternational Conference on Computational Linguistics
(COLING?92), pages 539?545.
Tuyen N. Huynh and Raymond J. Mooney. 2008.
Discriminative structure and parameter learning for
markov logic networks. In Proc. of the 25th ICML,
pages 416?423.
Jun?ichi Kazama and Kentaro Torisawa. 2008. Inducing
gazetteers for named entity recognition by large-scale
clustering of dependency relations. In Proc. of the
46th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies
(ACL-08: HLT), pages 407?415.
Mamoru Komachi, Taku Kudo, Masashi Shimbo, and
Yuji Matsumoto. 2008. Graph-based analysis of se-
mantic drift in espresso-like bootstrapping algorithms.
In Proc. of EMNLP?08. Honolulu, USA, pages 1011?
1020.
Dekang Lin and Patrick Pantel. 2001. Dirt - discovery
of inference rules from text. In Proc. of the ACM
SIGKDD Conference on Knowledge Discovery and
Data Mining, pages 323?328.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-
sky. 2009. Distant supervision for relation extraction
without labeled data. In Proc. of the Joint Conference
of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP, pages 1003?1011.
Marius Pas?ca, Dekang Lin, Jeffrey Bigham, Andrei Lif-
chits, and Alpa Jain. 2006. Names and Similarities on
the Web: Fact Extraction in the Fast Lane. In Proc. of
the COLING-ACL06, pages 809?816.
Patrick Pantel and Marco Pennacchiotti. 2006a.
Espresso: Leveraging generic patterns for automati-
cally harvesting semantic relations. In Proc. of the
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics (COLING-ACL-06,
pages 113?120.
Patrick Pantel and Pennacchiotti Pennacchiotti, Marco.
2006b. Espresso: Leveraging generic patterns for au-
tomatically harvesting semantic relations. In Proc. of
the COLING-ACL06, pages 113?120.
J. R. Quinlan. 1990. Learning logical definitions from
relations. Machine Learning, 5(3):239?266.
Matthew Richardson and Pedro Domingo. 2006.
Markov logic networks. Machine Learning, 26:107?
136.
Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld,
and Jesse Davis. 2010. Learning first-order horn
clauses from web text. In Proc. of EMNLP2010, pages
1088?1098.
Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara,
Chikara Hashimoto, and Sadao Kurohashi. 2008.
TSUBAKI: An open search engine infrastructure for
developing new information access. In Proc. of IJC-
NLP, pages 189?196.
Kentaro Torisawa, Stijn De Saeger, Jun?ichi Kazama,
Asuka Sumida, Daisuke Noguchi, Yasunari Kakizawa,
Masaaki Murata, Kow Kuroda, and Ichiro Yamada.
2010. Organizing the web?s information explosion to
discover unknown unknowns. New Generation Com-
puting, 28(3):217?236.
Masaaki Tsuchida, Stijn De Saeger, Kentaro Torisawa,
Masaki Murata, Jun?ichi Kazama, Kow Kuroda, and
Hayato Ohwada. 2010. Large scale similarity-based
relation expansion. In Proc of the 4th IUCS, pages
140?147.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation
extraction. Journal of Machine Learning Research,
pages 1083?1106.
835
