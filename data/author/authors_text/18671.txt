Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 79?89,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
Logical Inference on Dependency-based Compositional Semantics
Ran Tian Yusuke Miyao Takuya Matsuzaki
National Institute of Informatics, Japan
{tianran,yusuke,takuya-matsuzaki}@nii.ac.jp
Abstract
Dependency-based Compositional Se-
mantics (DCS) is a framework of natural
language semantics with easy-to-process
structures as well as strict semantics. In
this paper, we equip the DCS framework
with logical inference, by defining ab-
stract denotations as an abstraction of
the computing process of denotations in
original DCS. An inference engine is built
to achieve inference on abstract denota-
tions. Furthermore, we propose a way to
generate on-the-fly knowledge in logical
inference, by combining our framework
with the idea of tree transformation.
Experiments on FraCaS and PASCAL
RTE datasets show promising results.
1 Introduction
Dependency-based Compositional Semantics
(DCS) provides an intuitive way to model seman-
tics of questions, by using simple dependency-like
trees (Liang et al, 2011). It is expressive enough
to represent complex natural language queries on
a relational database, yet simple enough to be
latently learned from question-answer pairs. In
this paper, we equip DCS with logical inference,
which, in one point of view, is ?the best way
of testing an NLP system?s semantic capacity?
(Cooper et al, 1996).
It should be noted that, however, a framework
primarily designed for question answering is not
readily suited for logical inference. Because, an-
swers returned by a query depend on the specific
database, but implication is independent of any
databases. For example, answers to the question
?What books are read by students??, should al-
ways be a subset of answers to ?What books are
ever read by anyone??, no matter how we store the
data of students and how many records of books
are there in our database.
Thus, our first step is to fix a notation which ab-
stracts the calculation process of DCS trees, so as
to clarify its meaning without the aid of any exist-
ing database. The idea is to borrow a minimal set
of operators from relational algebra (Codd, 1970),
which is already able to formulate the calculation
in DCS and define abstract denotation, which is
an abstraction of the computation of denotations
guided by DCS trees. Meanings of sentences then
can be represented by primary relations among
abstract denotations. This formulation keeps the
simpleness and computability of DCS trees mostly
unaffected; for example, our semantic calculation
for DCS trees is parallel to the denotation compu-
tation in original DCS.
An inference engine is built to handle inference
on abstract denotations. Moreover, to compensate
the lack of background knowledge in practical in-
ference, we combine our framework with the idea
of tree transformation (Bar-Haim et al, 2007), to
propose a way of generating knowledge in logical
representation from entailment rules (Szpektor et
al., 2007), which are by now typically considered
as syntactic rewriting rules.
We test our system on FraCaS (Cooper et al,
1996) and PASCAL RTE datasets (Dagan et al,
2006). The experiments show: (i) a competi-
tive performance on FraCaS dataset; (ii) a big
impact of our automatically generated on-the-fly
knowledge in achieving high recall for a logic-
based RTE system; and (iii) a result that outper-
forms state-of-the-art RTE system on RTE5 data.
Our whole system is publicly released and can
be downloaded from http://kmcs.nii.ac.
jp/tianran/tifmo/.
2 The Idea
In this section we describe the idea of represent-
ing natural language semantics by DCS trees, and
achieving inference by computing logical relations
among the corresponding abstract denotations.
79
SUBJreadstudent bookOBJARG ARG
Figure 1: The DCS tree of ?students read books?
student
ARG
Mark
John
Emily
...
book
ARG
A Tale of Two Cities
Ulysses
...
read
SUBJ OBJ
Mark New York Times
Mary A Tale of Two Cities
John Ulysses
... ...
Table 1: Databases of student, book, and read
2.1 DCS trees
DCS trees has been proposed to represent natu-
ral language semantics with a structure similar to
dependency trees (Liang et al, 2011) (Figure 1).
For the sentence ?students read books?, imagine
a database consists of three tables, namely, a set
of students, a set of books, and a set of ?reading?
events (Table 1). The DCS tree in Figure 1 is in-
terpreted as a command for querying these tables,
obtaining ?reading? entries whose ?SUBJ? field
is student and whose ?OBJ? field is book. The
result is a set {John reads Ulysses, . . .}, which is
called a denotation.
DCS trees can be extended to represent linguis-
tic phenomena such as quantification and coref-
erence, with additional markers introducing addi-
tional operations on tables. Figure 2 shows an ex-
ample with a quantifier ?every?, which is marked
as ??? on the edge (love)OBJ-ARG(dog) and in-
terpreted as a division operator q
OBJ
?
(?2.2). Op-
timistically, we believe DCS can provide a frame-
work of semantic representation with sufficiently
wide coverage for real-world texts.
The strict semantics of DCS trees brings us the
idea of applying DCS to logical inference. This is
not trivial, however, because DCS works under the
assumption that databases are explicitly available.
Obviously this is unrealistic for logical inference
on unrestricted texts, because we cannot prepare
a database for everything in the world. This fact
fairly restricts the applicable tasks of DCS.
Our solution is to redefine DCS trees without
the aid of any databases, by considering each node
of a DCS tree as a content word in a sentence (but
may no longer be a table in a specific database),
while each edge represents semantic relations be-
tween two words. The labels on both ends of
an edge, such as SUBJ (subject) and OBJ (ob-
ject), are considered as semantic roles of the cor-
SUBJreadstu enbueoOBJARG ARGotadARGOBJ
SUBJotadke?? ?t?OBJARG ARG
stu SUBJread ??OBJARG ARG ke??SUBJARG
T: H:?
Figure 2: DCS trees of ?Mary loves every dog?
(Left-Up), ?Tom has a dog? (Left-Down), and
?Tom has an animal that Mary loves? (Right).
responding words
1
. To formulate the database
querying process defined by a DCS tree, we pro-
vide formal semantics to DCS trees by employing
relational algebra (Codd, 1970) for representing
the query. As described below, we represent mean-
ings of sentences with abstract denotations, and
logical relations among sentences are computed
as relations among their abstract denotations. In
this way, we can perform inference over formulas
of relational algebra, without computing database
entries explicitly.
2.2 Abstract denotations
Abstract denotations are formulas constructed
from a minimal set of relational algebra (Codd,
1970) operators, which is already able to formu-
late the database queries defined by DCS trees.
For example, the semantics of ?students read
books? is given by the abstract denotation:
F
1
= read ? (student
SUBJ
? book
OBJ
),
where read, student and book denote sets repre-
sented by these words respectively, and w
r
repre-
sents the set w considered as the domain of the
semantic role r (e.g. book
OBJ
is the set of books
considered as objects). The operators? and? rep-
resent intersection and Cartesian product respec-
tively, both borrowed from relational algebra. It
is not hard to see the abstract denotation denotes
the intersection of the ?reading? set (as illustrated
by the ?read? table in Table 1) with the product of
?student? set and ?book? set, which results in the
same denotation as computed by the DCS tree in
Figure 1, i.e. {John reads Ulysses, . . .}. However,
the point is that F
1
itself is an algebraic formula
that does not depend on any concrete databases.
Formally, we introduce the following constants:
? W : a universal set containing all entities.
1
The semantic role ARG is specifically defined for denot-
ing nominal predicate.
80
example phrase abstract denotation / statement
compound noun pet fish pet ? fish
modification nice day day ? (W
ARG
? nice
MOD
)
temporal relation boys study at night study ? (boy
SUBJ
? night
TIME
)
relative clause books that book ? pi
OBJ
(read
students read ?(student
SUBJ
?W
OBJ
))
quantification all men die man ? pi
SUBJ
(die)
hypernym dog ? animal
derivation all criminals commit criminal ? pi
SUBJ
(commit?
a crime (W
SUBJ
? crime
OBJ
))
antonym rise ? fall
negation no dogs are hurt dog ? pi
OBJ
(hurt)
Table 2: Abstract denotations and statements
? Content words: a content word (e.g. read)
defines a set representing the word (e.g.
read={(x, y) | read(x, y)}).
In addition we introduce following functions:
? ?: the Cartesian product of two sets.
? ?: the intersection of two sets.
? pi
r
: projection onto domain of semantic role
r (e.g. pi
OBJ
(read) = {y | ?x; read(x, y)}).
Generally we admit projections onto multiple
semantics roles, denoted by pi
R
where R is a
set of semantic roles.
? ?
r
: relabeling (e.g. ?
OBJ
(book) = book
OBJ
).
? q
r
?
: the division operator, where q
r
?
(A,B) is
defined as the largest set X which satisfies
B
r
?X ? A.
2
This is used to formulate uni-
versal quantifiers, such as ?Mary loves every
dog? and ?books read by all students?.
An abstract denotation is then defined as finite ap-
plications of functions on either constants or other
abstract denotations.
2.3 Statements
As the semantics of DCS trees is formulated by
abstract denotations, the meanings of declarative
sentences are represented by statements on ab-
stract denotations. Statements are declarations
of some relations among abstract denotations, for
which we consider the following set relations:
Non-emptiness A 6= ?: the set A is not empty.
Subsumption A ? B: set A is subsumed by B.
3
Roughly speaking, the relations correspond to the
logical concepts satisfiability and entailment.
2
If A and B has the same dimension, q
?
(A,B) is either
? or {?} (0-dimension point set), depending on if A ? B.
3
Using division operator, subsumption can be represented
by non-emptiness, since for setsA,B of the same dimension,
q
?
(A,B) 6= ? ? A ? B.
Abstract denotations and statements are conve-
nient for representing semantics of various types
of expressions and linguistic knowledge. Some
examples are shown in Table 2.
4
2.4 Logical inference on DCS
Based on abstract denotations, we briefly describe
our process to apply DCS to textual inference.
2.4.1 Natural language to DCS trees
To obtain DCS trees from natural language, we
use Stanford CoreNLP
5
for dependency parsing
(Socher et al, 2013), and convert Stanford depen-
dencies to DCS trees by pattern matching on POS
tags and dependency labels.
6
Currently we use
the following semantic roles: ARG, SUBJ, OBJ,
IOBJ, TIME and MOD. The semantic role MOD
is used for any restrictive modifiers. Determiners
such as ?all?, ?every? and ?each? trigger quanti-
fiers, as shown in Figure 2.
2.4.2 DCS trees to statements
A DCS tree T = (N , E) is defined as a rooted tree,
where each node ? ? N is labeled with a content
word w(?) and each edge (?, ?
?
) ? E ? N ?
N is labeled with a pair of semantic roles (r, r
?
)
7
.
Here ? is the node nearer to the root. Furthermore,
for each edge (?, ?
?
) we can optionally assign a
quantification marker.
Abstract denotation of a DCS tree can be cal-
culated in a bottom-up manner. For example, the
abstract denotation of H in Figure 2 is calculated
from the leaf node Mary, and then:
Node love (Mary loves):
F
2
= love ? (Mary
SUBJ
?W
OBJ
)
Node animal (Animal that Mary loves):
F
3
= animal ? pi
OBJ
(F
2
)
Node have (Tom has an animal that Mary loves):
F
4
= have ? (Tom
SUBJ
? (F
3
)
OBJ
).
Formally, suppose the root ? of a DCS tree T has
children ?
1
, . . . , ?
n
, and edges (?, ?
1
), . . . , (?, ?
n
)
labeled by (r
1
, r
?
1
), . . . , (r
n
, r
?
n
), respectively. The
abstract denotation of T is defined as:
[[T ]]=w(?) ? (
n
?
i=1
?
r
i
(pi
r
?
i
([[T
?
i
]]))?W
R
?
\r
i
),
4
Negation and disjointness (???) are explained in ?2.5.
5
http://nlp.stanford.edu/software/
corenlp.shtml
6
In (Liang et al, 2011) DCS trees are learned from QA
pairs and database entries. We obtain DCS trees from depen-
dency trees, to bypass the need of a concrete database.
7
The definition differs slightly from the original Liang et
al. (2011), mainly for the sake of simplicity and clarity.
81
piOBJ
(F
4
) = F
3
? F
7
pi
OBJ
(F
6
) = dog ? F
7
T
F
6
6= ? Axiom 4
dog ? F
7
6= ?
T
dog ? pi
OBJ
(F
2
) dog ? animal Axiom 8
dog ? F
3
dog ? F
7
? F
3
? F
7
Axiom 6
F
3
? F
7
6= ? Axiom 4
F
4
6= ?
Figure 3: An example of proof using abstract denotations
1. W 6= ?
2. A ? B ? A
3. B
r
? q
r
?
(A,B) ? A
4. pi
R
(A) 6= ? ? A 6= ?
5. (A ? B & B ? C)? A ? C
6. (A ? B & A 6= ?)? B 6= ?
7. A ? B ? pi
R
(A) ? pi
R
(B)
8. (C ? A & C ? B)? C ? A ? B
Table 3: An excerpt of axioms
where T
?
i
is the subtree of T rooted at ?
i
, and
R
?
is the set of possible semantic roles for con-
tent word w(?) (e.g. R
love
= {SUBJ,OBJ}), and
W
R
?
\r
i
is the product of W which has dimension
R
?
\ r
i
(e.g. W
{SUBJ,OBJ}\SUBJ
= W
OBJ
).
When universal quantifiers are involved, we
need to add division operators to the formula.
If (?, ?
i
) is assigned by a quantification marker
???
8
, then the abstract denotation is
9
[[T ]]=q
r
i
?
(pi
R
?
\{r
1
,...,r
i?1
}
([[T
?
]]), pi
r
?
i
([[T
?
i
]])),
where T
?
is the same tree as T except that the
edge (?, ?
i
) is removed. For example, the ab-
stract denotation of the first sentence of T in Fig-
ure 2 (Mary loves every dog) is calculated from F
2
(Mary loves) as
F
5
= q
OBJ
?
(pi
OBJ
(F
2
),dog).
After the abstract denotation [[T ]] is calcu-
lated, the statement representing the meaning of
the sentence is defined as [[T ]] 6= ?. For ex-
ample, the statement of ?students read books?
is read ? (student
SUBJ
? book
OBJ
) 6= ?, and
the statement of ?Mary loves every dog? is
q
OBJ
?
(pi
OBJ
(F
2
),dog) 6= ?, which is logically
equivalent to dog ? pi
OBJ
(F
2
).
10
2.4.3 Logical inference
Since meanings of sentences are represented by
statements on abstract denotations, logical infer-
ence among sentences is reduced to deriving new
relations among abstract denotations. This is done
by applying axioms to known statements, and ap-
proximately 30 axioms are implemented (Table 3).
8
Multiple quantifiers can be processed similarly.
9
The result of [[T ]] depends on the order of the children
?
1
, . . . , ?
n
. Different orders correspond to readings of differ-
ent quantifier scopes.
10
See Footnote 2,3.
These are algebraic properties of abstract denota-
tions, among which we choose a set of axioms that
can be handled efficiently and enable most com-
mon types of inference seen in natural language.
For the example in Figure 2, by constructing the
following abstract denotations:
Tom has a dog:
F
6
= have ? (Tom
SUBJ
? dog
OBJ
)
Objects that Tom has:
F
7
= pi
OBJ
(have ? (Tom
SUBJ
?W
OBJ
)),
we can use the lexical knowledge dog ? animal,
the statements of T (i.e. dog ? pi
OBJ
(F
2
) and
F
6
6= ?), and the axioms in Table 3,
11
to prove
the statement of H (i.e. F
4
6= ?) (Figure 3).
We built an inference engine to perform logical
inference on abstract denotations as above. In this
logical system, we treat abstract denotations as
terms and statements as atomic sentences, which
are far more easier to handle than first order pred-
icate logic (FOL) formulas. Furthermore, all im-
plemented axioms are horn clauses, hence we can
employ forward-chaining, which is very efficient.
2.5 Extensions
Further extensions of our framework are made
to deal with additional linguistic phenomena, as
briefly explained below.
Negation To deal with negation in our forward-
chaining inference engine, we introduce one more
relation on abstract denotations, namely disjoint-
ness A ? B, meaning that A and B are dis-
joint sets. Using disjointness we implemented two
types of negations: (i) atomic negation, for each
content word w we allow negation w? of that word,
characterized by the property w ? w?; and (ii) root
negation, for a DCS tree T and its denotation [[T ]],
the negation of T is represented by T ? T , mean-
ing that T = ? in its effect.
Selection Selection operators in relational alge-
bra select a subset from a set to satisfy some spe-
11
Algebraic identities, such as pi
OBJ
(F
4
) = F
3
? F
7
and
pi
OBJ
(F
6
) = dog ? F
7
, are also axioms.
82
cific properties. This can be employed to rep-
resent linguistic phenomena such as downward
monotonicity and generalized quantifiers. In the
current system, we implement (i) superlatives,
e.g. s
highest
(mountain? (W
ARG
?Asia
MOD
)) (the
highest mountain in Asia) and (ii) numerics, e.g.
s
two
(pet ? fish) (two pet fish), where s
f
is a se-
lection marker. Selection operators are imple-
mented as markers assigned to abstract denota-
tions, with specially designed axioms. For ex-
ample superlatives satisfy the following property:
A ? B & s
highest
(B) ? A ? s
highest
(B) =
s
highest
(A). New rules can be added if necessary.
Coreference We use Stanford CoreNLP to re-
solve coreferences (Raghunathan et al, 2010),
whereas coreference is implemented as a special
type of selection. If a node ? in a DCS tree T be-
longs to a mention cluster m, we take the abstract
denotation [[T
?
]] and make a selection s
m
([[T
?
]]),
which is regarded as the abstract denotation of that
mention. Then all selections of the same mention
cluster are declared to be equal.
3 Generating On-the-fly Knowledge
Recognizing textual entailment (RTE) is the task
of determining whether a given textual statement
H can be inferred by a text passage T. For this,
our primary textual inference system operates as:
1. For a T-H pair, apply dependency parsing
and coreference resolution.
2. Perform rule-based conversion from depen-
dency parses to DCS trees, which are trans-
lated to statements on abstract denotations.
3. Use statements of T and linguistic knowledge
as premises, and try to prove statements of H
by our inference engine.
However, this method does not work for real-
world datasets such as PASCAL RTE (Dagan et
al., 2006), because of the knowledge bottleneck:
it is often the case that the lack of sufficient lin-
guistic knowledge causes failure of inference, thus
the system outputs ?no entailment? for almost all
pairs (Bos and Markert, 2005).
The transparent syntax-to-semantics interface
of DCS enables us to back off to NLP techniques
during inference for catching up the lack of knowl-
edge. We extract fragments of DCS trees as para-
phrase candidates, translate them back to linguis-
  
T/H DCS trees AbstractdenotationsParsingCoreference InferenceYes/NoOn-the-flyknowledge Axioms
Languageresources
Figure 4: RTE system
tic expressions, and apply distributional similar-
ity to judge their validity. In this way, our frame-
work combines distributional and logical seman-
tics, which is also the main subject of Lewis and
Steedman (2013) and Beltagy et al (2013).
As follows, our full system (Figure 4) addition-
ally invokes linguistic knowledge on-the-fly:
4. If H is not proven, compare DCS trees of T
and H, and generate path alignments.
5. Aligned paths are evaluated by a similar-
ity score to estimate their likelihood of be-
ing paraphrases. Path alignments with scores
higher than a threshold are accepted.
6. Convert accepted path alignments into state-
ments on abstract denotations, use them in
logical inference as new knowledge, and try
to prove H again.
3.1 Generating path alignments
On-the-fly knowledge is generated by aligning
paths in DCS trees. A path is considered as joining
two germs in a DCS tree, where a germ is defined
as a specific semantic role of a node. For example,
Figure 5 shows DCS trees of the following sen-
tences (a simplified pair from RTE2-dev):
T: Tropical storm Debby is blamed for deaths.
H: A storm has caused loss of life.
The germ OBJ(blame) and germ ARG(death) in
DCS tree of T are joined by the underscored path.
Two paths are aligned if the joined germs are
aligned, and we impose constraints on aligned
germs to inhibit meaningless alignments, as de-
scribed below.
3.2 Aligning germs by logical clues
Two germs are aligned if they are both at leaf
nodes (e.g. ARG(death) in T and ARG(life) in H,
Figure 5), or they already have part of their mean-
ings in common, by some logical clues.
83
  
readsT?: H?: ARGtunsb obnek?btt?ARG ARGOBJreadsARG ARG
IOBJ
eda??nuARG MOD
??b uarru?b
ARG
SUBJ
ARG
MOD
OBJ
Figure 5: Aligned paths (underscored by the solid
lines) and aligned germs (joined by the dotted line)
To formulate this properly, we define the ab-
stract denotation of a germ, which, intuitively, rep-
resents the meaning of the germ in the specific sen-
tence. The abstract denotation of a germ is defined
in a top-down manner: for the root node ? of a
DCS tree T , we define its denotation [[?]]
T
as the
denotation of the entire tree [[T ]]; for a non-root
node ? and its parent node ?, let the edge (?, ?) be
labeled by semantic roles (r, r
?
), then define
[[? ]]
T
= [[T
?
]] ? (?
r
?
(pi
r
([[?]]
T
))?W
R
?
\r
?).
Now for a germ r(?), the denotation is defined as
the projection of the denotation of node ? onto the
specific semantic role r: [[r(?)]]
T
= pi
r
([[?]]
T
).
For example, the abstract denotation of germ
ARG(book) in Figure 1 is defined as pi
ARG
(book?
pi
OBJ
(read?(student
SUBJ
?book
OBJ
))), meaning
?books read by students?. Similarly, denotation
of germ OBJ(blame) in T of Figure 5 indicates
the object of ?blame? as in the sentence ?Tropi-
cal storm Debby is blamed for death?, which is
a tropical storm, is Debby, etc. Technically, each
germ in a DCS tree indicates a variable when the
DCS tree is translated to a FOL formula, and the
abstract denotation of the germ corresponds to the
set of consistent values (Liang et al, 2011) of that
variable.
The logical clue to align germs is: if there exists
an abstract denotation, other than W , that is a su-
perset of both abstract denotations of two germs,
then the two germs can be aligned. A simple ex-
ample is that ARG(storm) in T can be aligned
to ARG(storm) in H, because their denotations
have a common superset other than W , namely
pi
ARG
(storm). A more complicated example is that
OBJ(blame) and SUBJ(cause) can be aligned,
because inference can induce [[OBJ(blame)]]
T
=
[[ARG(Debby)]]
T
= [[ARG(storm)]]
T
, as well as
[[SUBJ(cause)]]
H
= [[ARG(storm)]]
H
, so they also
have the common superset pi
ARG
(storm). How-
ever, for example, logical clues can avoid align-
ing ARG(storm) to ARG(loss), which is obviously
  
T?: T'?:
What is tropical storm, Debby,       and is blamed for death ]][[ What is tropical storm, Debby,           and cause loss of life ]][[?blame deathDebbyARG ARGOBJstormARG ARG
IOBJ
tropicalARG MOD
cause losslife
ARG
SUBJ
ARG
MOD
OBJDebbyARGstormARG ARGtropicalARG MOD
Figure 6: Tree transformation and generated on-
the-fly knowledge (subsumption of denotations
shown above the trees)
meaningless.
3.3 Scoring path alignments by similarity
Aligned paths are evaluated by a similarity score,
for which we use distributional similarity of the
words that appear in the paths (?4.1). Only path
alignments with high similarity scores can be ac-
cepted. Also, we only accept paths of length ? 5,
to prevent too long paths to be aligned.
3.4 Applying path alignments
Accepted aligned paths are converted into state-
ments, which are used as new knowledge. The
conversion is done by first performing a DCS tree
transformation according to the aligned paths, and
then declare a subsumption relation between the
denotations of aligned germs. For example, to ap-
ply the aligned path pair generated in Figure 5,
we use it to transform T into a new tree T? (Fig-
ure 6), and then the aligned germs, OBJ(blame)
in T and SUBJ(cause) in T?, will generate
the on-the-fly knowledge: [[OBJ(blame)]]
T
?
[[SUBJ(cause)]]
T?
.
Similar to the tree transformation based ap-
proach to RTE (Bar-Haim et al, 2007), this pro-
cess can also utilize lexical-syntactic entailment
rules (Szpektor et al, 2007). Furthermore, since
the on-the-fly knowledge is generated by trans-
formed pairs of DCS trees, all contexts are pre-
served: in Figure 6, though the tree transformation
can be seen as generated from the entailment rule
?X is blamed for death? X causes loss of life?, the
generated on-the-fly knowledge, as shown above
the trees, only fires with the additional condition
that X is a tropical storm and is Debby. Hence,
the process can also be used to generate knowl-
edge from context sensitive rules (Melamud et al,
2013), which are known to have higher quality
(Pantel et al, 2007; Clark and Harrison, 2009).
However, it should be noted that using on-the-
fly knowledge in logical inference is not a trivial
84
task. For example, the FOL formula of the rule ?X
is blamed for death? X causes loss of life? is:
?x; (?a; blame(x, a) & death(a))?
(?b, c; cause(x, b) & loss(b, c) & life(c)),
which is not a horn clause. The FOL formula for
the context-preserved rule in Figure 6 is even more
involved. Still, it can be efficiently treated by our
inference engine because as a statement, the for-
mula [[OBJ(blame)]]
T
? [[SUBJ(cause)]]
T?
is an
atomic sentence, more than a horn clause.
4 Experiments
In this section, we evaluate our system on FraCaS
(?4.2) and PASCAL RTE datasets (?4.3).
4.1 Language Resources
The lexical knowledge we use are synonyms, hy-
pernyms and antonyms extracted from WordNet
12
.
We also add axioms on named entities, stopwords,
numerics and superlatives. For example, named
entities are singletons, so we add axioms such as
?x; (x ? Tom & x 6= ?)? Tom ? x.
To calculate the similarity scores of path align-
ments, we use the sum of word vectors of the
words from each path, and calculate the cosine
similarity. For example, the similarity score of the
path alignment ?OBJ(blame)IOBJ-ARG(death)
? SUBJ(cause)OBJ-ARG(loss)MOD-ARG(life)? is
calculated as the cosine similarity of vectors
blame+death and cause+loss+life. Other struc-
tures in the paths, such as semantic roles, are ig-
nored in the calculation. The word vectors we
use are from Mikolov et al (2013)
13
(Mikolov13),
and additional results are also shown using Turian
et al (2010)
14
(Turian10). The threshold for ac-
cepted path alignments is set to 0.4, based on pre-
experiments on RTE development sets.
4.2 Experiments on FraCaS
The FraCaS test suite contains 346 inference prob-
lems divided into 9 sections, each focused on a cat-
egory of semantic phenomena. We use the data by
MacCartney and Manning (2007), and experiment
on the first section, Quantifiers, following Lewis
and Steedman (2013). This section has 44 single
premise and 30 multi premise problems. Most of
12
http://wordnet.princeton.edu/
13
http://code.google.com/p/word2vec/
14
http://metaoptimize.com/projects/
wordreprs/
Single Prem. Multi Prem.
Lewis13 70 50
MacCartney07 84.1 -
MacCartney08 97.7 -
Our Sys. 79.5 80.0
Table 4: Accuracy (%) on FraCaS
the problems do not require lexical knowledge, so
we use our primary textual inference system with-
out on-the-fly knowledge nor WordNet, to test the
performance of the DCS framework as formal se-
mantics. To obtain the three-valued output (i.e.
yes, no, and unknown), we output ?yes? if H is
proven, or try to prove the negation of H if H is
not proven. To negate H, we use the root negation
as described in ?2.5. If the negation of H is proven,
we output ?no?, otherwise we output ?unknown?.
The result is shown in Table 4. Since our sys-
tem uses an off-the-shelf dependency parser, and
semantic representations are obtained from sim-
ple rule-based conversion from dependency trees,
there will be only one (right or wrong) interpre-
tation in face of ambiguous sentences. Still, our
system outperforms Lewis and Steedman (2013)?s
probabilistic CCG-parser. Compared to MacCart-
ney and Manning (2007) and MacCartney and
Manning (2008), our system does not need a pre-
trained alignment model, and it improves by mak-
ing multi-sentence inferences. To sum up, the re-
sult shows that DCS is good at handling universal
quantifiers and negations.
Most errors are due to wrongly generated DCS
trees (e.g. wrongly assigned semantic roles) or
unimplemented quantifier triggers (e.g. ?neither?)
or generalized quantifiers (e.g. ?at least a few?).
These could be addressed by future work.
4.3 Experiments on PASCAL RTE datasets
On PASCAL RTE datasets, strict logical inference
is known to have very low recall (Bos and Markert,
2005), so on-the-fly knowledge is crucial in this
setting. We test the effect of on-the-fly knowledge
on RTE2, RTE3, RTE4 and RTE5 datasets, and
compare our system with other approaches.
4.3.1 Impact of on-the-fly knowledge
Results on test data are shown in Table 5. When
only primary knowledge is used in inference (the
first row), recalls are actually very low; After we
activate the on-the-fly knowledge, recalls jump to
over 50%, with a moderate fall of precision. As a
result, accuracies significantly increase.
85
RTE2 RTE3 RTE4 RTE5
Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc.
Primary 70.9 9.8 52.9 73.2 7.3 51.1 89.7 5.2 52.3 82.6 6.3 52.5
+On-the-fly 57.6 66.5 58.8 63.7 64.6 63.0 60.0 57.4 59.6 69.9 55.7 65.8
Table 5: Impact of on-the-fly knowledge
RTE2 RTE3 RTE4 RTE5
Bos06 60.6 - - -
MacCartney08 - 59.4 - -
Clark08 - - 56.5 -
Wang10 63.0 61.1 - -
Stern11 61.6 67.1 - 63.5
Stern12 - - - 64.0
Our Sys. 58.8 63.0 59.6 65.8
Table 6: Comparison with other systems
4.3.2 Comparison to other RTE systems
A comparison between our system and other RTE
systems is shown in Table 6. Bos06 (Bos and
Markert, 2006) is a hybrid system combining
deep features from a theorem prover and a model
builder, together with shallow features such as lex-
ical overlap and text length. MacCartney08 (Mac-
Cartney and Manning, 2008) uses natural logic to
calculate inference relations between two superfi-
cially aligned sentences. Clark08 (Clark and Har-
rison, 2008) is a logic-based system utilizing vari-
ous resources including WordNet and DIRT para-
phrases (Lin and Pantel, 2001), and is tolerant to
partially unproven H sentences in some degree.
All of the three systems pursue a logical approach,
while combining various techniques to achieve ro-
bustness. The result shows that our system has
comparable performance. On the other hand,
Wang10 (Wang and Manning, 2010) learns a tree-
edit model from training data, and captures entail-
ment relation by tree edit distance. Stern11 (Stern
and Dagan, 2011) and Stern12 (Stern et al, 2012)
extend this framework to utilize entailment rules
as tree transformations. These are more tailored
systems using machine learning with many hand-
crafted features. Still, our unsupervised system
outperforms the state-of-the-art on RTE5 dataset.
4.3.3 Analysis
Summing up test data from RTE2 to RTE5, Fig-
ure 7 shows the proportion of all proven pairs and
their precision. Less than 5% pairs can be proven
primarily, with a precision of 77%. Over 40%
pairs can be proven by one piece of on-the-fly
knowledge, yet pairs do exist in which more than
2 pieces are necessary. The precisions of 1 and 2
pieces on-the-fly knowledge application are over
  
0 1 2 >=30
0.10.2
0.30.4
0.50.6
0.70.8
0.9 Proportion of proven pairsPrecision
Applied on-the-fly knowledge
Figure 7: Proportion of proven pairs and their pre-
cision, w.r.t. pieces of on-the-fly knowledge.
60%, which is fairly high, given our rough estima-
tion of the similarity score. As a comparison, Dinu
and Wang (2009) studied the proportion of proven
pairs and precision by applying DIRT rules to tree
skeletons in RTE2 and RTE3 data. The proportion
is 8% with precision 65% on RTE2, and propor-
tion 6% with precision 72% on RTE3. Applied
by our logical system, the noisy on-the-fly knowl-
edge can achieve a precision comparable to higher
quality resources such as DIRT.
A major type of error is caused by the igno-
rance of semantic roles in calculation of simi-
larity scores. For example, though ?Italy beats
Kazakhstan? is not primarily proven from ?Italy
is defeated by Kazakhstan?, our system does
produce the path alignment ?SUBJ(beat)OBJ ?
OBJ(defeat)SUBJ? with a high similarity score.
The impact of such errors depends on the data
making methodology, though. It lowers precisions
in RTE2 and RTE3 data, particularly in ?IE? sub-
task (where precisions drop under 0.5). On the
other hand, it occurs less often in ?IR? subtask.
Finally, to see if we ?get lucky? on RTE5 data
in the choice of word vectors and thresholds, we
change the thresholds from 0.1 to 0.7 and draw
the precision-recall curve, using two types of word
vectors, Mikolov13 and Turian10. As shown in
Figure 8, though the precision drops for Turian10,
both curves show the pattern that our system keeps
gaining recall while maintaining precision to a cer-
tain level. Not too much ?magic? in Mikolov13 ac-
tually: for over 80% pairs, every node in DCS tree
of H can be covered by a path of length ? 5 that
86
  0 012 01> 01= 013 01. 014 01501.
01..
014
014.
015
015.
016
016. What tisropchlms,
789Prr
op89t
itn 
Figure 8: Precision-Recall curve.
has a corresponding path of length ? 5 in T with
a similarity score > 0.4.
5 Conclusion and Discussion
We have presented a method of deriving abstract
denotation from DCS trees, which enables logi-
cal inference on DCS, and we developed a textual
inference system based on the framework. Exper-
imental results have shown the power of the rep-
resentation that allows both strict inference as on
FraCaS data and robust reasoning as on RTE data.
Exploration of an appropriate meaning repre-
sentation for querying and reasoning on knowl-
edge bases has a long history. Description logic,
being less expressive than FOL but featuring more
efficient reasoning, is used as a theory base for Se-
mantic Web (W3C, 2012). Ideas similar to our
framework, including the use of sets in a repre-
sentation that benefits efficient reasoning, are also
found in description logic and knowledge repre-
sentation community (Baader et al, 2003; Sowa,
2000; Sukkarieh, 2003). To our knowledge, how-
ever, their applications to logical inference beyond
the use for database querying have not been much
explored in the context of NLP.
The pursue of a logic more suitable for natural
language inference is not new. For instance, Mac-
Cartney and Manning (2008) has implemented a
model of natural logic (Lakoff, 1970). While
being computationally efficient, various inference
patterns are out of the scope of their system.
Much work has been done in mapping natu-
ral language into database queries (Cai and Yates,
2013; Kwiatkowski et al, 2013; Poon, 2013).
Among these, the (?-)DCS (Liang et al, 2011;
Berant et al, 2013) framework defines algorithms
that transparently map a labeled tree to a database
querying procedure. Essentially, this is because
DCS trees restrict the querying process to a very
limited subset of possible operations. Our main
contribution, the abstract denotation of DCS trees,
can thus be considered as an attempt to charac-
terize a fragment of FOL that is suited for both
natural language inference and transparent syntax-
semantics mapping, through the choice of opera-
tions and relations on sets.
We have demonstrated the utility of logical in-
ference on DCS through the RTE task. A wide
variety of strategies tackling the RTE task have
been investigated (Androutsopoulos and Malaka-
siotis, 2010), including the comparison of surface
strings (Jijkoun and De Rijke, 2005), syntactic and
semantic structures (Haghighi et al, 2005; Snow
et al, 2006; Zanzotto et al, 2009; Burchardt et
al., 2009; Heilman and Smith, 2010; Wang and
Manning, 2010), semantic vectors (Erk and Pad?o,
2009) and logical representations (Bos and Mark-
ert, 2005; Raina et al, 2005; Tatu and Moldovan,
2005). Acquisition of basic knowledge for RTE
is also a huge stream of research (Lin and Pantel,
2001; Shinyama et al, 2002; Sudo et al, 2003;
Szpektor et al, 2004; Fujita et al, 2012; Weis-
man et al, 2012; Yan et al, 2013). These previ-
ous works include various techniques for acquir-
ing and incorporating different kinds of linguistic
and world knowledge, and further fight against the
knowledge bottleneck problem, e.g. by back-off
to shallower representations.
Logic-based RTE systems employ various ap-
proaches to bridge knowledge gaps. Bos and
Markert (2005) proposes features from a model
builder; Raina et al (2005) proposes an abduction
process; Tatu and Moldovan (2006) shows hand-
crafted rules could drastically improve the perfor-
mance of a logic-based RTE system.
As such, our current RTE system is at a proof-
of-concept stage, in that many of the above tech-
niques are yet to be implemented. Nonetheless,
we would like to emphasize that it already shows
performance competitive to state-of-the-art sys-
tems on one data set (RTE5). Other directions of
our future work include further exploitation of the
new semantic representation. For example, since
abstract denotations are readily suited for data
querying, they can be used to verify newly gen-
erated assumptions by fact search in a database.
This may open a way towards a hybrid approach
to RTE wherein logical inference is intermingled
with large scale database querying.
Acknowledgments This research was supported
by the Todai Robot Project at National Institute of
Informatics.
87
References
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A survey of paraphrasing and textual entail-
ment methods. J. Artif. Int. Res., 38(1).
Franz Baader, Diego Calvanese, Deborah L. McGuin-
ness, Daniele Nardi, and Peter F. Patel-Schneider,
editors. 2003. The Description Logic Handbook:
Theory, Implementation, and Applications. Cam-
bridge University Press, New York, NY, USA.
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI 2007.
Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Gar-
rette, Katrin Erk, and Raymond Mooney. 2013.
Montague meets markov: Deep semantics with
probabilistic logical form. In Second Joint Con-
ference on Lexical and Computational Semantics
(*SEM).
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on Freebase from
question-answer pairs. In Proceedings of EMNLP
2013.
Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of EMNLP 2005.
Johan Bos and Katja Markert. 2006. When logical
inference helps determining textual entailment (and
when it doesnt). In Proceedings of the 2nd PASCAL
RTE Challenge Workshop.
Aljoscha Burchardt, Marco Pennacchiotti, Stefan
Thater, and Manfred Pinkal. 2009. Assessing the
impact of frame semantics on textual entailment.
Nat. Lang. Eng., 15(4).
Qingqing Cai and Alexander Yates. 2013. Large-scale
semantic parsing via schema matching and lexicon
extension. In Proceedings of ACL 2013.
Peter Clark and Phil Harrison. 2008. Recognizing tex-
tual entailment with logical inference. In Proceed-
ings of 2008 Text Analysis Conference (TAC?08).
Peter Clark and Phil Harrison. 2009. Large-scale ex-
traction and use of knowledge from text. In Pro-
ceedings of the Fifth International Conference on
Knowledge Capture (K-CAP?09).
E. F. Codd. 1970. A relational model of data for large
shared data banks. Commun. ACM, 13(6).
Robin Cooper, Dick Crouch, Jan Van Eijck, Chris
Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp,
David Milward, Manfred Pinkal, Massimo Poesio,
and et al 1996. Using the framework. FraCaS De-
liverable D, 16.
Ido Dagan, O. Glickman, and B. Magnini. 2006. The
pascal recognising textual entailment challenge. In
Machine Learning Challenges. Evaluating Predic-
tive Uncertainty, Visual Object Classification, and
Recognising Tectual Entailment.
Georgiana Dinu and Rui Wang. 2009. Inference rules
and their application to recognizing textual entail-
ment. In Proceedings of EACL 2009.
Katrin Erk and Sebastian Pad?o. 2009. Paraphrase as-
sessment in structured vector space: Exploring pa-
rameters and datasets. In Proceedings of the Work-
shop on Geometrical Models of Natural Language
Semantics.
Atsushi Fujita, Pierre Isabelle, and Roland Kuhn.
2012. Enlarging paraphrase collections through
generalization and instantiation. In Proceedings of
EMNLP 2012.
Aria Haghighi, Andrew Ng, and Christopher Manning.
2005. Robust textual inference via graph matching.
In Proceedings of EMNLP 2005.
Michael Heilman and Noah A. Smith. 2010. Tree edit
models for recognizing textual entailments, para-
phrases, and answers to questions. In Proceedings
of NAACL 2010.
Valentin Jijkoun and Maarten De Rijke. 2005. Rec-
ognizing textual entailment: Is word similarity
enough? In Machine Learning Challenge Work-
shop, volume 3944 of LNCS, Springer.
Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke
Zettlemoyer. 2013. Scaling semantic parsers with
on-the-fly ontology matching. In Proceedings of
EMNLP 2013.
George Lakoff. 1970. Linguistics and natural logic.
Synthese, 22(1-2).
Mike Lewis and Mark Steedman. 2013. Combined
distributional and logical semantics. Transactions
of ACL, 1.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning dependency-based compositional seman-
tics. In Proceedings of ACL 2011.
Dekang Lin and Patrick Pantel. 2001. Discovery of
inference rules for question-answering. Nat. Lang.
Eng., 7(4).
Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Proceedings of Col-
ing 2008.
88
Oren Melamud, Jonathan Berant, Ido Dagan, Jacob
Goldberger, and Idan Szpektor. 2013. A two level
model for context sensitive inference rules. In Pro-
ceedings of ACL 2013.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL
2013.
Patrick Pantel, Rahul Bhagat, Bonaventura Coppola,
Timothy Chklovski, and Eduard Hovy. 2007. ISP:
Learning inferential selectional preferences. In Pro-
ceedings of NAACL 2007.
Hoifung Poon. 2013. Grounded unsupervised seman-
tic parsing. In Proceedings of ACL 2013.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nate Chambers, Mihai Surdeanu, Dan Ju-
rafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceed-
ings of EMNLP 2010.
Rajat Raina, Andrew Y. Ng, and Christopher D. Man-
ning. 2005. Robust textual inference via learning
and abductive reasoning. In Proceedings of AAAI
2005.
Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.
2002. Automatic paraphrase acquisition from news
articles. In Proceedings of HLT 2002.
Rion Snow, Lucy Vanderwende, and Arul Menezes.
2006. Effectively using syntax for recognizing false
entailment. In Proceedings of NAACL 2006.
Richard Socher, John Bauer, Christopher D. Manning,
and Ng Andrew Y. 2013. Parsing with compo-
sitional vector grammars. In Proceedings of ACL
2013.
John F. Sowa. 2000. Knowledge Representation:
Logical, Philosophical and Computational Founda-
tions. Brooks/Cole Publishing Co., Pacific Grove,
CA, USA.
Asher Stern and Ido Dagan. 2011. A confidence model
for syntactically-motivated entailment proofs. In
Proceedings of RANLP 2011.
Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.
2012. Efficient search for transformation-based in-
ference. In Proceedings of ACL 2012.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An improved extraction pattern representa-
tion model for automatic ie pattern acquisition. In
Proceedings of ACL 2003.
JanaZ. Sukkarieh. 2003. An expressive efficient rep-
resentation: Bridging a gap between nlp and kr.
In Vasile Palade, RobertJ. Howlett, and Lakhmi
Jain, editors, Knowledge-Based Intelligent Informa-
tion and Engineering Systems. Springer Berlin Hei-
delberg.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of EMNLP
2004.
Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007.
Instance-based evaluation of entailment rule acqui-
sition. In Proceedings of ACL 2007.
Marta Tatu and Dan Moldovan. 2005. A semantic ap-
proach to recognizing textual entailment. In Pro-
ceedings of EMNLP 2005.
Marta Tatu and Dan Moldovan. 2006. A logic-
based semantic approach to recognizing textual en-
tailment. In Proceedings of the COLING/ACL 2006.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of ACL 2010.
W3C. 2012. Owl 2 web ontology language document
overview (second edition). www.w3.org/TR/owl2-
overview/.
Mengqiu Wang and Christopher Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question answer-
ing. In Proceedings of Coling 2010.
Hila Weisman, Jonathan Berant, Idan Szpektor, and Ido
Dagan. 2012. Learning verb inference rules from
linguistically-motivated evidence. In Proceedings of
EMNLP 2012.
Yulan Yan, Chikara Hashimoto, Kentaro Torisawa,
Takao Kawai, Jun?ichi Kazama, and Stijn De Saeger.
2013. Minimally supervised method for multilin-
gual paraphrase extraction from definition sentences
on the web. In Proceedings of NAACL 2013.
Fabio massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learn-
ing approach to textual entailment recognition. Nat.
Lang. Eng., 15(4).
89
Proceedings of the ACL 2014 Workshop on Semantic Parsing, pages 71?75,
Baltimore, Maryland USA, June 26 2014.
c?2014 Association for Computational Linguistics
Efficient Logical Inference for Semantic Processing
Ran Tian
?
Yusuke Miyao Takuya Matsuzaki
National Institute of Informatics, Japan
{tianran,yusuke,takuya-matsuzaki}@nii.ac.jp
Abstract
Dependency-based Compositional Se-
mantics (DCS) provides a precise and
expressive way to model semantics of
natural language queries on relational
databases, by simple dependency-like
trees. Recently abstract denotation is pro-
posed to enable generic logical inference
on DCS. In this paper, we discuss some
other possibilities to equip DCS with
logical inference, and we discuss further
on how logical inference can help textual
entailment recognition, or other semantic
precessing tasks.
1 Introduction
Dependency-based Compositional Semantics
(DCS) was proposed as an interface for querying
relational databases by natural language. It
features DCS trees as semantic representation,
with a structure similar to dependency trees. In
its basic version, a node of a DCS tree indicates
a table in the database, and an edge indicates a
join relation. Both ends of an edge are labeled by
a field of the corresponding table (Liang et al.,
2011). However, when DCS is applied to logical
inference on unrestricted texts, it is unrealistic to
assume an explicit database, because we cannot
prepare a database for everything in the world.
For this reason, DCS trees are detached from any
specific relational database, in a way that each
node of a DCS tree indicates a content word in a
sentence (thus no fixed set of possible word labels
for a DCS tree node), and each edge indicates
?
Current affiliation of the first author: Graduate School
of Information Sciences, Tohoku University, Japan. Email
address: tianran@ecei.tohoku.ac.jp
a semantic relation between two words. Labels
on the two ends of an edge, initially indicating
fields of tables in a database, are considered
as semantic roles of the corresponding words.
Abstract denotation is proposed to capture the
meaning of this abstract version of DCS tree,
and a textual inference system based on abstract
denotation is built (Tian et al., 2014).
It is quite natural to apply DCS trees, a simple
and expressive semantic representation, to textual
inference; however the use of abstract denotations
to convey logical inference is somehow unusual.
There are two seemingly obvious way to equip
DCS with logical inference: (i) at the tree level, by
defining a set of logically sound transformations
of DCS trees; or (ii) at the logic level, by convert-
ing DCS trees to first order predicate logic (FOL)
formulas and then utilizing a theorem prover. For
(i), it may not be easy to enumerate all types of
logically sound transformations, but tree transfor-
mations can be seen as an approximation of logical
inference. For (ii), abstract denotation is more ef-
ficient than FOL formula, because abstract deno-
tation eliminates quantifiers and meanings of nat-
ural language texts can be represented by atomic
sentences.
To elaborate the above discussion and to pro-
vide more topics to the literature, in this paper we
discuss the following four questions: (?2) How
well can tree transformation approximate logical
inference? (?3) With rigorous inference on DCS
trees, where does logic contribute in the system
of Tian et al. (2014)? (?4) Does logical inference
have further potentials in Recognizing Textual En-
tailment (RTE) task? and (?5) How efficient is ab-
stract denotation compared to FOL formula? We
provide examples or experimental results to the
above questions.
71
  
stormT?: H?: ARGblame deathDebbyARG ARGOBJstormARG ARG
IOBJ
tropicalARG MOD
cause losslife
ARG
SBJ
ARG
MOD
OBJ
Figure 1: DCS trees of T: Tropical storm Debby is
blamed for death and H: A storm has caused loss
of life
2 Tree transformation vs. logical
inference
In the tree transformation based approach to RTE,
it has been realized that some gaps between T and
H cannot be filled even by a large number of tree
transformation rules extracted from corpus (Bar-
Haim et al., 2007a). For example in Figure 1, it
is possible to extract the rule blamed for death?
cause loss of life, but not easy to extract tropical
storm Debby? storm, because ?Debby? could be
an arbitrary name which may not even appear in
the corpus.
This kind of gaps was typically addressed by
approximate matching methods, for example by
counting common sub-graphs of T and H, or by
computing a cost of tree edits that convert T to
H. In the example of Figure 1, we would expect
that T is ?similar enough? (i.e. has many common
sub-graphs) with H, or the cost to convert T into H
(e.g. by deleting the node Debby and then add the
node storm) is low. As for how similar is enough,
or how the cost is evaluated, we will need a statis-
tical model to train on RTE development set.
It was neglected that some combinations of tree
edits are logical (while some are not). The entail-
ment pair in Figure 1 can be easily treated by log-
ical inference, as long as the apposition tropical
storm = Debby is appropriately handled. In con-
trast to graph matching or tree edit models which
theoretically admit arbitrary tree transformation,
logical inference clearly discriminate sound trans-
formations from unsound ones. In this sense, there
would be no need to train on RTE data.
When coreference is considered, logically
sound tree transformations can be quite compli-
cated. The following is a modified example from
RTE2-dev:
T: Hurricane Isabel, which caused significant
damage, was a tropical storm when she entered
Virginia.
  
stoormblaedbhDypi
mbtdD
drclrurmblf??bcD
fo?rmby
df??
?rocrlrbd?pi
ARG
DlfDo
DlfDo mbtdD
?b?cD
df??T?: H?:ARG TIMEARG MOD TIME
ARG
SBJ
OBJ
ARG
ARG
MOD
OBJSBJ
ARG ARG
ARGARG SBJ
SBJ
SBJ
OBJ
ARG
OBJ
?rocrlrb
Figure 2: DCS trees with coreference
H: A storm entered Virginia, causing damage.
The corresponding DCS trees are shown in Fig-
ure 2. Though the DCS trees of T and H are
quite different, H can actually be proven from T.
Note the coreference between Hurricane Isabel
and she, suggesting us to copy the subtree of Hur-
ricane Isabel to she, in a tree edit approach. This
is not enough yet, because the head storm in T is
not placed at the subject of cause. The issue is in-
deed very logical: from ?Hurricane Isabel = she?,
?Hurricane Isabel = storm?, ?she = subject of en-
ter? and ?Hurricane Isabel = subject of cause?,
we can imply that ?storm = subject of enter = sub-
ject of cause?.
3 Alignment with logical clues
Tian et al. (2014) proposed a way to generate on-
the-fly knowledge to fill knowledge gaps: if H is
not proven, compare DCS trees of T and H to
generate path alignments (e.g. blamed for death
? cause loss of life, as underscored in Figure 1);
evaluate the path alignments by a similarity score
function; and path alignments with a score greater
than a threshold (0.4) are accepted and converted
to inference rules.
The word vectors Tian et al. (2014) use to
calculate similarities are reported able to cap-
ture semantic compositions by simple additions
and subtractions (Mikolov et al., 2013). This is
also the case when used as knowledge resource
for RTE, for example the similarities between
blamed+death and cause+loss+life, or between
found+shot+dead and killed, are computed >
0.4.
However, generally such kind of similarity is
very noisy. Tian et al. (2014) used some logical
clues to filter out irrelevant path alignments, which
helps to keep a high precision. To evaluate the
effect of such logical filters, we compare it with
some other alignment strategies, the performance
of which on RTE5-test data is shown in Table 1.
Each strategy is described in the following.
72
Strategy Prec. Rec. Acc.
LogicClue + Inference 69.9 55.0 65.7
LexNoun + Inference 64.2 57.3 62.7
LexNoun + Coverage 57.1 75.0 59.3
NoFilter + Coverage 54.2 87.7 56.8
Table 1: Comparison of different alignment strate-
gies
LogicClue + Inference This is the system of
Tian et al. (2014)
1
, which use logical clues to filter
out irrelevant path alignments, and apply accepted
path alignments as inference rules.
LexNoun + Inference The same system as
above, except that we only align paths between
lexically aligned nouns. Two nouns are aligned
if and only if they are synonyms, hyponyms or
derivatively related in WordNet.
LexNoun + Coverage As above, paths between
lexically aligned nouns are aligned, and aligned
paths with similarity score > 0.4 are accepted. If
all nodes in H can be covered by some accepted
path alignments, then output ?Y?. This is very
similar to the system described in Bar-Haim et al.
(2007b).
NoFilter + Coverage Same as above, but all
paths alignments with similarity score > 0.4 are
accepted.
4 How can logical inference help RTE?
Logical inference is shown to be useful for RTE,
as Tian et al. (2014) demonstrates a system with
competitive results. However, despite the expec-
tation that all entailment matters can be explained
logically, our observation is that currently logical
inference only fills very limited short gaps from T
to H. The logical phenomena easily addressed by
Tian et al. (2014)?s framework, namely universal
quantifiers and negations, seems rare in PASCAL
RTE data. Most heavy lifting is done by distribu-
tional similarities between phrases, which may fail
in complicated sentences. An especially complex
example is:
T: Wal-Mart Stores Inc. said Tuesday that a Mas-
sachusetts judge had granted its motion to decer-
tify a class action lawsuit accusing the world?s
largest retailer of denying employees breaks.
H: Employee breaks had been denied by a motion
granted by a Massachusetts judge.
1
http://kmcs.nii.ac.jp/tianran/tifmo/
  100 1000 10000 100000 10000001
2
3
4
5
6
R? = 0.24
?? ? ? ? ?? ??? ? ? ? ? ? ?
???? ??????
Figure 3: Time of forward-chaining (seconds) in
our system, plotted on weights of statements (log-
arithmic scale).
Orig. 3 Sec. Orig. 5 Min. Red. 5 Min.
Proof found 8 16 82
Too many variables 5 24 3
Failed to find proof 0 1 3
Memory limit 0 2 0
Time out 86 57 13
Table 2: Proportion (%) of exit status of Prover9
The system of Tian et al. (2014) generated on-
the-fly knowledge to join several fragments in T
and wrongly proved H. In examples of such com-
plexity, distributional similarity is no longer reli-
able. However, it may be possible to build a pri-
ori logical models at the meta level, such as on
epistemic, intentional and reportive attitudes. The
models then can provide signals for semantic pars-
ing to connect the logic to natural language, such
as the words ?grant?, ?decertify?, and ?accuse? in
the above example. We hope this approach can
bring new progress to RTE and other semantic pro-
cessing tasks.
5 Efficiency of abstract denotations
To evaluate the efficiency of logical inference on
abstract denotations, we took 110 true entailment
pairs from RTE5 development set, which are also
pairs that can be proven with on-the-fly knowl-
edge. We plot the running time of Tian et al.
(2014)?s inference engine (single-threaded) on a
2.27GHz Xeon CPU, with respect to the weighted
sum of all statements
2
, as shown in Figure 3. The
graph shows all pairs can be proven in 6 seconds,
and proof time scales logarithmically on weight of
statements.
On the other hand, we converted statements on
abstract denotations into FOL formulas, and tried
to prove the same pairs using Prover9,
3
a popu-
2
If a statement is translated to FOL formula, the weight of
this statement equals to the weighted sum of all predicates in
the FOL formula, where an n-ary predicate is weighted as n.
3
www.cs.unm.edu/
?
mccune/prover9/
73
lar FOL theorem prover. As the result turns out
(Table 2), only 8% of the pairs can be proven in
3 seconds (the ?Orig. 3 Sec.? column), and only
16% pairs can be proven in 5 minutes (the ?Orig.
5 Min.? column), showing severe difficulties for
an FOL prover to handle textual inferences with
many (usually hundreds of) on-the-fly rules. As
such, we use Tian et al. (2014)?s inference engine
to pin down statements that are actually needed for
proving H (usually just 2 or 3 statements), and try
to prove H by Prover9 again, using only necessary
statements. Proven pairs in 5 minutes then jump
to 82% (the ?Red. 5 Min.? column), showing that
a large number of on-the-fly rules may drastically
increase computation cost. Still, nearly 20% pairs
cannot be proven even in this setting, suggesting
that traditional FOL prover is not suited for tex-
tual inference.
6 Conclusion and future work
We have discussed the role that logical infer-
ence could play in RTE task, and the efficiency
of performing inference on abstract denotations.
Though currently logical inference contributes at
places that are somehow inconspicuous, there is
the possibility that with some meta level logical
models and the methodology of semantic parsing,
we can build systems that understand natural lan-
guage texts deeply: logic implies (in)consistency,
which is in turn used as signals to produce more
accurate semantic interpretation. And after all, as
there may be many possible variations of seman-
tic representations, it is good to have an efficient
inference framework that has the potential to con-
nect them. It would be exciting if we can combine
different types of structured data with natural lan-
guage in semantic processing tasks. Directions of
our future work are described below.
Improvement of similarity score To calculate
phrase similarities, Tian et al. (2014) use the co-
sine similarity of sums of word vectors, which ig-
nores syntactic information. We plan to add syn-
tactic information to words by some supertags,
and learn a vector space embedding for this struc-
ture.
Integration of FreeBase to RTE It would be
exciting if we can utilize the huge amount of Free-
Base data in RTE task. Using the framework of
abstract denotation, meanings of sentences can be
explained as relational database queries; to convert
it to FreeBase data queries is like relational to on-
tology schema matching. In order to make effec-
tive use of FreeBase data, we also need to recog-
nize entities and relations in natural language sen-
tences. Previous research on semantic parsing will
be very helpful for learning such mapping.
Winograd Schema Challenge (WSC) As the
RTE task, WSC (Levesque et al., 2012) also pro-
vides a test bed for textual inference systems. A
Winograd schema is a pair of similar sentences but
contain an ambiguity of pronouns that is resolved
in opposite ways. A complicated partial example
is:
Michael decided to freeze himself in
cryo-stasis even though his father was
against it, because he hopes to be un-
frozen in the future when there is a cure
available.
The logical interplay among decided, hopes,
even though, because, and the realization that he
is coreferent to Michael (but not his father) is in-
triguing. By working on the task, we hope to gain
further understanding on how knowledge can be
gathered and applied in natural language reason-
ing.
Acknowledgments This research was supported
by the Todai Robot Project at National Institute of
Informatics.
References
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007a. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI 2007.
Roy Bar-Haim, Ido Dagan, Iddo Greental, Idan Szpek-
tor, and Moshe Friedman. 2007b. Semantic in-
ference at the lexical-syntactic level for textual en-
tailment recognition. In Proceedings of the ACL-
PASCAL Workshop on Textual Entailment and Para-
phrasing.
Hector Levesque, Ernest Davis, and Leora Morgen-
stern. 2012. The winograd schema challenge. In
Knowledge Representation and Reasoning Confer-
ence.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning dependency-based compositional seman-
tics. In Proceedings of ACL 2011.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL
2013.
74
Ran Tian, Yusuke Miyao, and Matsuzaki Takuya.
2014. Logical inference on dependency-based com-
positional semantics. In Proceedings of ACL 2014.
75
