Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 57?64,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Acceptability Prediction by Means of Grammaticality Quantification
Philippe Blache, Barbara Hemforth & Ste?phane Rauzy
Laboratoire Parole & Langage
CNRS - Universite? de Provence
29 Avenue Robert Schuman
13621 Aix-en-Provence, France
{blache,hemforth,rauzy}@lpl.univ-aix.fr
Abstract
We propose in this paper a method for
quantifying sentence grammaticality. The
approach based on Property Grammars,
a constraint-based syntactic formalism,
makes it possible to evaluate a grammat-
icality index for any kind of sentence, in-
cluding ill-formed ones. We compare on
a sample of sentences the grammaticality
indices obtained from PG formalism and
the acceptability judgements measured by
means of a psycholinguistic analysis. The
results show that the derived grammatical-
ity index is a fairly good tracer of accept-
ability scores.
1 Introduction
Syntactic formalisms make it possible to describe
precisely the question of grammaticality. When
a syntactic structure can be associated to a sen-
tence, according to a given grammar, we can de-
cide whether or not the sentence is grammatical.
In this conception, a language (be it natural or not)
is produced (or generated) by a grammar by means
of a specific mechanism, for example derivation.
However, when no structure can be built, nothing
can be said about the input to be parsed except,
eventually, the origin of the failure. This is a prob-
lem when dealing with non canonical inputs such
as spoken language, e-mails, non-native speaker
productions, etc. From this perspective, we need
robust approaches that are at the same time ca-
pable of describing precisely the form of the in-
put, the source of the problem and to continue the
parse. Such capabilities render it possible to arrive
at a precise evaluation of the grammaticality of the
input. In other words, instead of deciding on the
grammaticality of the input, we can give an indica-
tion of its grammaticality, quantified on the basis
of the description of the properties of the input.
This paper addresses the problem of ranking the
grammaticality of different sentences. This ques-
tion is of central importance for the understanding
of language processing, both from an automatic
and from a cognitive perspective. As for NLP,
ranking grammaticality makes it possible to con-
trol dynamically the parsing process (in choosing
the most adequate structures) or to find the best
structure among a set of solutions (in case of non-
deterministic approaches). Likewise the descrip-
tion of cognitive processes involved in language
processing by human has to explain how things
work when faced with unexpected or non canoni-
cal material. In this case too, we have to explain
why some productions are more acceptable and
easier to process than others.
The question of ranking grammaticality has
been addressed from time to time in linguistics,
without being a central concern. Chomsky, for
example, mentioned this problem quite regularly
(see for example (Chomsky75)). However he
rephrases it in terms of ?degrees of ?belonging-
ness? to the language?, a somewhat fuzzy notion
both formally and linguistically. More recently,
several approaches have been proposed illustrat-
ing the interest of describing these mechanisms
in terms of constraint violations. The idea con-
sists in associating weights to syntactic constraints
and to evaluate, either during or after the parse,
the weight of violated constraints. This approach
is at the basis of Linear Optimality Theory (see
(Keller00), and (Sorace05) for a more general per-
spective) in which grammaticality is judged on the
basis of the total weights of violated constraints. It
is then possible to rank different candidate struc-
57
tures. A similar idea is proposed in the framework
of Constraint Dependency Grammar (see (Men-
zel98), (Schro?der02)). In this case too, acceptabil-
ity is function of the violated constraints weights.
However, constraint violation cannot in itself
constitute a measure of grammaticality without
taking into account other parameters as well. The
type and the number of constraints that are sat-
isfied are of central importance in acceptability
judgment: a construction violating 1 constraint
and satisfying 15 of them is more acceptable than
one violating the same constraint but satisfying
only 5 others. In the same way, other informa-
tions such as the position of the violation in the
structure (whether it occurs in a deeply embedded
constituent or higher one in the structure) plays an
important role as well.
In this paper, we propose an approach over-
coming such limitations. It takes advantage of a
fully constraint-based syntactic formalism (called
Property Grammars, cf. (Blache05b)) that of-
fers the possibility of calculating a grammatical-
ity index, taking into account automatically de-
rived parameters as well as empirically determined
weights. This index is evaluated automatically and
we present a psycholinguistic study showing how
the parser predictions converge with acceptability
judgments.
2 Constraint-based parsing
Constraints are generally used in linguistics as a
control process, verifying that a syntactic struc-
ture (e.g. a tree) verifies some well-formedness
conditions. They can however play a more general
role, making it possible to express syntactic infor-
mation without using other mechanism (such as a
generation function). Property Grammars (noted
hereafter PG) are such a fully constraint-based for-
malism. In this approach, constraints stipulate dif-
ferent kinds of relation between categories such as
linear precedence, imperative co-occurrence, de-
pendency, repetition, etc. Each of these syntactic
relations corresponds to a type of constraint (also
called property):
? Linear precedence: Det ? N (a determiner
precedes the noun)
? Dependency: AP ; N (an adjectival phrase
depends on the noun)
? Requirement: V[inf] ? to (an infinitive
comes with to)
? Exclusion: seems < ThatClause[subj] (the
verb seems cannot have That clause subjects)
? Uniqueness : UniqNP {Det} (the determiner
is unique in a NP)
? Obligation : ObligNP {N, Pro} (a pronoun or
a noun is mandatory in a NP)
? Constituency : ConstNP {Det, AP, N, Pro}
(set of possible constituents of NP)
In PG, each category of the grammar is de-
scribed with a set of properties. A grammar is then
made of a set of properties. Parsing an input con-
sists in verifying for each category of description
the set of corresponding properties in the gram-
mar. More precisely, the idea consists in verifying,
for each subset of constituents, the properties for
which they are relevant (i.e. the constraints that
can be evaluated). Some of these properties are
satisfied, some others possibly violated. The re-
sult of a parse, for a given category, is the set of its
relevant properties together with their evaluation.
This result is called characterization and is formed
by the subset of the satisfied properties, noted P+,
and the set of the violated ones, noted P?.
For example, the characterizations associated to
theNPs ?the book? and ?book the? are respectively
of the form:
P+={Det ? N; Det ; N; N < Pro; Uniq(Det),
Oblig(N), etc.}, P?=?
P+={Det ; N; N < Pro; Uniq(Det), Oblig(N),
etc.}, P?={Det ? N}
This approach allows to characterize any kind
of syntactic object. In PG, following the pro-
posal made in Construction Grammar (see (Fill-
more98), (Kay99)), all such objects are called
constructions. They correspond to a phrase (NP,
PP, etc.) as well as a syntactic turn (cleft, wh-
questions, etc.). All these objects are described by
means of a set of properties (see (Blache05b)).
In terms of parsing, the mechanism consists
in exhibiting the potential constituents of a given
construction. This stage corresponds, in constraint
solving techniques, to the search of an assignment
satisfying the constraint system. The particular-
ity in PG comes from constraint relaxation. Here,
the goal is not to find the assignment satisfying
the constraint system, but the best assignment (i.e.
the one satisfying as much as possible the system).
In this way, the PG approach permits to deal with
more or less grammatical sentences. Provided that
58
some control mechanisms are added to the pro-
cess, PG parsing can be robust and efficient (see
(Blache06)) and parse different material, includ-
ing spoken language corpora.
Using a constraint-based approach such as the
one proposed here offers several advantages. First,
constraint relaxation techniques make it possi-
ble to process any kind of input. When pars-
ing non canonical sentences, the system identi-
fies precisely, for each constituent, the satisfied
constraints as well as those which are violated.
It furnishes the possibility of parsing any kind
of input, which is a pre-requisite for identifying
a graded scale of grammaticality. The second
important interest of constraints lies in the fact
that syntactic information is represented in a non-
holistic manner or, in other words, in a decentral-
ized way. This characteristic allows to evaluate
precisely the syntactic description associated with
the input. As shown above, such a description is
made of sets of satisfied and violated constraints.
The idea is to take advantage of such a represen-
tation for proposing a quantitative evaluation of
these descriptions, elaborated from different indi-
cators such as the number of satisfied or violated
constraints or the number of evaluated constraints.
The hypothesis, in the perspective of a gradi-
ence account, is to exhibit a relation between a
quantitative evaluation and the level of grammat-
icality: the higher the evaluation value, the more
grammatical the construction. The value is then
an indication of the quality of the input, according
to a given grammar. In the next section we propose
a method for computing this value.
3 Characterization evaluation
The first idea that comes to mind when trying to
quantify the quality of a characterization is to cal-
culate the ratio of satisfied properties with respect
to the total set of evaluated properties. This infor-
mation is computed as follows:
Let C a construction defined in the grammar by
means of a set of properties SC , let AC an assign-
ment for the construction C,
? P+ = set of satisfied properties for AC
? P? = set of violated properties for AC
? N+ : number of satisfied properties N+ =
card(P+)
? N? : number of violated properties N? =
card(P?)
? Satisfaction ratio (SR): the number of satis-
fied properties divided by the number of eval-
uated properties SR = N
+
E
The SR value varies between 0 and 1, the two
extreme values indicating that no properties are
satisfied (SR=0) or none of them are violated
(SR=1). However, SR only relies on the evalu-
ated properties. It is also necessary to indicate
whether a characterization uses a small or a large
subpart of the properties describing the construc-
tion in the grammar. For example, the VP in our
grammar is described by means of 25 constraints
whereas the PP only uses 7 of them. Let?s imag-
ine the case where 7 constraints can be evaluated
for both constructions, with an equal SR. However,
the two constructions do not have the same qual-
ity: one relies on the evaluation of all the possible
constraints (in the PP) whereas the other only uses
a few of them (in the VP). The following formula
takes these differences into account :
? E : number of relevant (i.e. evaluated) prop-
erties E = N+ +N?
? T= number of properties specifying con-
struction C = card(SC)
? Completeness coefficient (CC) : the number
of evaluated properties divided by the num-
ber of properties describing the construction
in the grammar CC = ET
These purely quantitative aspects have to be
contrasted according to the constraint types. Intu-
itively, some constraints, for a given construction,
play a more important role than some others. For
example, linear precedence in languages with poor
morphology such as English or French may have a
greater importance than obligation (i.e. the neces-
sity of realizing the head). To its turn, obligation
may be more important than uniqueness (i.e. im-
possible repetition). In this case, violating a prop-
erty would have different consequences according
to its relative importance. The following examples
illustrate this aspect:
(1) a. The the man who spoke with me is my brother.
b. The who spoke with me man is my brother.
In (1a), the determiner is repeated, violating
a uniqueness constraint of the first NP, whereas
(1c) violates a linearity constraint of the same NP.
59
Clearly, (1a) seems to be more grammatical than
(1b) whereas in both cases, only one constraint is
violated. This contrast has to be taken into account
in the evaluation. Before detailing this aspect, it is
important to note that this intuition does not mean
that constraints have to be organized into a rank-
ing scheme, as with the Optimality Theory (see
(Prince93)). The parsing mechanism remains the
same with or without this information and the hi-
erarchization only plays the role of a process con-
trol.
Identifying a relative importance of the types of
constraints comes to associate them with a weight.
Note that at this stage, we assign weights to con-
straint types, not directly to the constraints, dif-
ferently from other approaches (cf. (Menzel98),
(Foth05)). The experiment described in the next
section will show that this weighting level seems
to be efficient enough. However, in case of neces-
sity, it remains possible to weight directly some
constraints into a given construction, overriding
thus the default weight assigned to the constraint
types.
The notations presented hereafter are used to
describe constraint weighting. Remind that P+
and P? indicate the set of satisfied and violated
properties of a given construction.
? p+i : property belonging to P
+
? p?i : property belonging to P
?
? w(p) : weight of the property of type p
? W+ : sum of the satisfied properties weights
W+ =
N+?
i=1
w(p+i )
? W? : sum of the violated properties weights
W? =
N??
i=1
w(p?i )
One indication of the relative importance of the
constraints involved in the characterization of a
construction is given by the following formula:
? QI: the quality index of a construction
QI =
W+ ?W?
W+ +W?
The QI index varies then between -1 and 1.
A negative value indicates that the set of violated
constraints has a greater importance than the set of
satisfied one. This does not mean that more con-
straints are violated than satisfied, but indicates the
importance of the violated ones.
We now have three different indicators that can
be used in the evaluation of the characterization:
the satisfaction ratio (noted SR) indicating the ra-
tio of satisfied constraints, the completeness coef-
ficient (noted CC) specifying the ratio of evalu-
ated constraints, and the quality index (noted QI)
associated to the quality of the characterization ac-
cording to the respective degree of importance of
evaluated constraints. These three indices are used
to form a global precision index (noted PI). These
three indicators do not have the same impact in the
evaluation of the characterization, they are then
balanced with coefficients in the normalized for-
mula:
? PI = (k?QI)+(l?SR)+(m?CC)3
As such, PI constitutes an evaluation of the
characterization for a given construction. How-
ever, it is necessary to take into account the ?qual-
ity? of the constituents of the construction as well.
A construction can satisfy all the constraints de-
scribing it, but can be made of embedded con-
stituents more or less well formed. The overall
indication of the quality of a construction has then
to integrate in its evaluation the quality of each of
its constituents. This evaluation depends finally
on the presence or not of embedded constructions.
In the case of a construction made of lexical con-
stituents, no embedded construction is present and
the final evaluation is the precision index PI as de-
scribed above. We will call hereafter the evalua-
tion of the quality of the construction the ?gram-
maticality index? (noted GI). It is calculated as
follows:
? Let d the number of embedded constructions
? If d = 0 then GI = PI , else
GI = PI ?
?d
i=1GI(Ci)
d
In this formula, we note GI(Ci) the grammat-
icality index of the construction Ci. The general
formula for a construction C is then a function of
its precision index and of the sum of the grammat-
icality indices of its embedded constituents. This
60
formula implements the propagation of the quality
of each constituent. This means that the grammati-
cality index of a construction can be lowered when
its constituents violate some properties. Recipro-
cally, this also means that violating a property at
an embedded level can be partially compensated at
the upper levels (provided they have a good gram-
maticality index).
4 Grammaticality index from PG
We describe in the remainder of the paper predic-
tions of the model as well as the results of a psy-
cholinguistic evaluation of these predictions. The
idea is to evaluate for a given set of sentences on
the one hand the grammaticality index (done auto-
matically), on the basis of a PG grammar, and on
the other hand the acceptability judgment given by
a set of subjects. This experiment has been done
for French, a presentation of the data and the ex-
periment itself will be given in the next section.
We present in this section the evaluation of gram-
maticality index.
Before describing the calculation of the differ-
ent indicators, we have to specify the constraints
weights and the balancing coefficients used in PI.
These values are language-dependent, they are
chosen intuitively and partly based on earlier anal-
ysis, this choice being evaluated by the experiment
as described in the next section. In the remainder,
the following values are used:
Constraint type Weight
Exclusion, Uniqueness, Requirement 2
Obligation 3
Linearity, Constituency 5
Concerning the balancing coefficients, we give
a greater importance to the quality index (coeffi-
cient k=2), which seems to have important conse-
quences on the acceptability, as shown in the pre-
vious section. The two other coefficients are signi-
ficatively less important, the satisfaction ratio be-
ing at the middle position (coefficient l=1) and the
completeness at the lowest (coefficient m=0,5).
Let?s start with a first example, illustrating the
process in the case of a sentence satisfying all con-
straints.
(2)
Marie a emprunte? un tre`s long chemin
pour le retour.
Mary took a very long way for the return.
The first NP contains one lexical constituent,
Mary. Three constraints, among the 14 describing
the NP, are evaluated and all satisfied: Oblig(N),
stipulating that the head is realized, Const(N), in-
dicating the category N as a possible constituent,
and Excl(N, Pro), verifying that N is not realized
together with a pronoun. The following values
come from this characterization:
N+ N- E T W+ W- QI SR CC PI GI
3 0 3 14 10 0 1 1 0.21 1.04 1.04
We can see that, according to the fact that
all evaluated constraints are satisfied, QI and SR
equal 1. However, the fact that only 3 constraints
among 14 are evaluated lowers down the gram-
matical index. This last value, insofar as no con-
stituents are embedded, is the same as PI.
These results can be compared with another
constituent of the same sentence, the VP. This
construction also only contains satisfied prop-
erties. Its characterization is the following :
Char(VP)=Const(Aux, V, NP, PP) ; Oblig(V) ;
Uniq(V) ; Uniq(NP) ; Uniq(PP) ; Aux?V[part]
; V?NP ; Aux?V ; V?PP. On top of this set
of evaluated constraints (9 among the possible
25), the VP includes two embedded constructions
: a PP and a NP. A grammaticality index has
been calculated for each of them: GI(PP) = 1.24
GI(NP)=1.23. The following table indicates the
different values involved in the calculation of the
GI.
N+ N- E T W+ W- QI SR CC PI
9 0 9 25 31 0 1 1 0.36 1.06
GI Emb Const GI
1.23 1.31
The final GI of the VP reaches a high value. It
benefits on the one hand from its own quality (in-
dicated by PI) and on another hand from that of
its embedded constituents. In the end, the final GI
obtained at the sentence level is function of its own
PI (very good) and the NP and VP GIs, as shown
in the table:
N+ N- E T W+ W- QI SR CC PI
5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
1.17 1.28
Let?s compare now these evaluations with those
obtained for sentences with violated constraints,
as in the following examples:
(3) a.
Marie a emprunte? tre`s long chemin un
pour le retour.
Mary took very long way a for the return.
b. Marie a emprunte? un tre`s chemin pour le retour.
Mary took a very way for the return.
In (2a), 2 linear constraints are violated: a de-
terminer follows a noun and an AP in ?tre`s long
chemin un?. Here are the figures calculated for
this NP:
N+ N- E T W+ W- QI SR CC PI GI
8 2 10 14 23 10 0.39 0.80 0.71 0.65 0.71
61
The QI indicator is very low, the violated con-
straints being of heavy weight. The grammatical-
ity index is a little bit higher because a lot of con-
straints are also satisfied. The NP GI is then prop-
agated to its dominating construction, the VP. This
phrase is well formed and also contains a well-
formed construction (PP) as sister of the NP. Note
that in the following table summarizing the VP
indicators, the GI product of the embedded con-
stituents is higher than the GI of the NP. This is
due to the well-formed PP constituent. In the end,
the GI index of the VP is better than that of the
ill-formed NP:
N+ N- E T W+ W- QI SR CC PI
9 0 9 25 31 0 1 1 0.36 1.06
GI Emb Const GI
0.97 1.03
For the same reasons, the higher level construc-
tion S also compensates the bad score of the NP.
However, in the end, the final GI of the sentence
is much lower than that of the corresponding well-
formed sentence (see above).
N+ N- E T W+ W- QI SR CC PI
5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
1.03 1.13
The different figures of the sentence (2b) show
that the violation of a unique constraint (in this
case the Oblig(Adj) indicating the absence of the
head in the AP) can lead to a global lower GI than
the violation of two heavy constraints as for (2a).
In this case, this is due to the fact that the AP only
contains one constituent (a modifier) that does not
suffice to compensate the violated constraint. The
following table indicates the indices of the differ-
ent phrases. Note that in this table, each phrase is
a constituent of the following (i.e. AP belongs to
NP itself belonging to VP, and so on).
N+ N- E T W+ W- QI SR CC PI
AP 2 1 3 7 7 3 0.40 0.67 0.43 0.56
NP 10 0 10 14 33 0 1 1 0.71 1.12
VP 9 0 9 25 31 0 1 1 0.36 1.06
S 5 0 5 9 17 0 1 1 0.56 1.09
GI Emb Const GI
AP 1 0.56
NP 0.56 0.63
VP 0.93 0.99
S 1.01 1.11
5 Judging acceptability of violations
We ran a questionnaire study presenting partic-
ipants with 60 experimental sentences like (11)
to (55) below. 44 native speakers of French
completed the questionnaire giving acceptability
judgements following the Magnitude Estimation
technique. 20 counterbalanced forms of the ques-
tionnaire were constructed. Three of the 60 ex-
perimental sentences appeared in each version in
each form of the questionnaire, and across the 20
forms, each experimental sentence appeared once
in each condition. Each sentence was followed
by a question concerning its acceptability. These
60 sentences were combined with 36 sentences of
various forms varying in complexity (simple main
clauses, simple embeddings and doubly nested
embeddings) and plausibility (from fully plausible
to fairly implausible according to the intuitions of
the experimenters). One randomization was made
of each form.
Procedure: The rating technique used was mag-
nitude estimation (ME, see (Bard96)). Partici-
pants were instructed to provide a numeric score
that indicates how much better (or worse) the cur-
rent sentence was compared to a given reference
sentence (Example: If the reference sentence was
given the reference score of 100, judging a tar-
get sentence five times better would result in 500,
judging it five times worse in 20). Judging the ac-
ceptability ratio of a sentence in this way results in
a scale which is open-ended on both sides. It has
been demonstrated that ME is therefore more sen-
sitive than fixed rating-scales, especially for scores
that would approach the ends of such rating scales
(cf. (Bard96)). Each questionnaire began with a
written instruction where the subject was made fa-
miliar with the task based on two examples. After
that subjects were presented with a reference sen-
tence for which they had to provide a reference
score. All following sentences had to be judged
in relation to the reference sentence. Individual
judgements were logarithmized (to arrive at a lin-
ear scale) and normed (z-standardized) before sta-
tistical analyses.
Global mean scores are presented figure 1. We
tested the reliability of results for different ran-
domly chosen subsets of the materials. Construc-
tions for which the judgements remain highly sta-
ble across subsets of sentences are marked by an
asterisk (rs > 0.90; p < 0.001). The mean relia-
bility across subsets is rs > 0.65 (p < 0.001).
What we can see in these data is that in par-
ticular violations within prepositional phrases are
not judged in a very stable way. The way they
are judged appears to be highly dependent on the
preposition used and the syntactic/semantic con-
text. This is actually a very plausible result, given
that heads of prepositional phrases are closed class
items that are much more predictable in many syn-
tactic and semantic environments than heads of
62
noun phrases and verb phrases. We will there-
fore base our further analyses mainly on violations
within noun phrases, verb phrases, and adjectival
phrases. Results including prepositional phrases
will be given in parentheses. Since the constraints
described above do not make any predictions for
semantic violations, we excluded examples 25, 34,
45, and 55 from further analyses.
6 Acceptability versus grammaticality
index
We compare in this section the results coming
from the acceptability measurements described in
section 5 and the values of grammaticality indices
obtained as proposed section 4.
From the sample of 20 sentences presented in fig-
ure 1, we have discarded 4 sentences, namely sen-
tence 25, 34, 45 and 55, for which the property
violation is of semantic order (see above). We are
left with 16 sentences, the reference sentence sat-
isfying all the constraints and 15 sentences violat-
ing one of the syntactic constraints. The results
are presented figure 2. Acceptability judgment
(ordinate) versus grammaticality index (abscissa)
is plotted for each sentence. We observe a high
coefficient of correlation (? = 0.76) between the
two distributions, indicating that the grammatical-
ity index derived from PG is a fairly good tracer of
the observed acceptability measurements.
The main contribution to the grammaticality in-
dex comes from the quality index QI (? = 0.69)
while the satisfaction ratio SR and the complete-
No violations
11. Marie a emprunte? un tre`s long chemin pour le retour 0.465
NP-violations
21. Marie a emprunte? tre`s long chemin un pour le retour -0.643 *
22. Marie a emprunte? un tre`s long chemin chemin pour le retour -0.161 *
23. Marie a emprunte? un tre`s long pour le retour -0.871 *
24. Marie a emprunte? tre`s long chemin pour le retour -0.028 *
25. Marie a emprunte? un tre`s heureux chemin pour le retour -0.196 *
AP-violations
31. Marie a emprunte? un long tre`s chemin pour le retour -0.41 *
32. Marie a emprunte? un tre`s long long chemin pour le retour -0.216 -
33. Marie a emprunte? un tre`s chemin pour le retour -0.619 -
34. Marie a emprunte? un grossie`rement long chemin pour le retour -0.058 *
PP-violations
41. Marie a emprunte? un tre`s long chemin le retour pour -0.581 -
42. Marie a emprunte? un tre`s long chemin pour pour le retour -0.078 -
43. Marie a emprunte? un tre`s long chemin le retour -0.213 -
44. Marie a emprunte? un tre`s long chemin pour -0.385 -
45. Marie a emprunte? un tre`s long chemin dans le retour -0.415 -
VP-violations
51. Marie un tre`s long chemin a emprunte? pour le retour -0.56 *
52.Marie a emprunte? emprunte? un tre`s long chemin pour le retour -0.194 *
53.Marie un tre`s long chemin pour le retour -0.905 *
54. Marie emprunte? un tre`s long chemin pour le retour -0.322 *
55. Marie a persuade? un tre`s long chemin pour le retour -0.394 *
Figure 1: Acceptability results
ness coefficient CC contributions, although signif-
icant, are more modest (? = 0.18 and ? = 0.17
respectively).
We present in figure 3 the correlation between
acceptability judgements and grammaticality in-
dices after the removal of the 4 sentences pre-
senting PP violations. The analysis of the experi-
ment described in section 5 shows indeed that ac-
ceptability measurements of the PP-violation sen-
tences is less reliable than for others phrases. We
thus expect that removing these data from the sam-
ple will strengthen the correlation between the two
distributions. The coefficient of correlation of the
12 remaining data jumps to ? = 0.87, as expected.
Figure 2: Correlation between acceptability judgement and
grammaticality index
Figure 3: Correlation between acceptability judgement and
grammaticality index removing PP violations
Finally, the adequacy of the PG grammatical-
ity indices to the measurements was investigated
by means of resultant analysis. We adapted the
parameters of the model in order to arrive at a
good fit based on half of the sentences materials
(randomly chosen from the full set), with a cor-
relation of ? = 0.85 (? = 0.76 including PPs)
between the grammaticality index and acceptabil-
ity judgements. Surprisingly, we arrived at the
best fit with only two different weights: A weight
of 2 for Exclusion, Uniqueness, and Requirement,
and a weight of 5 for Obligation, Linearity, and
Constituency. This result converges with the hard
63
and soft constraint repartition idea as proposed by
(Keller00).
The fact that the grammaticality index is based
on these properties as well as on the number of
constraints to be evaluated, the number of con-
straints to the satisfied, and the goodness of em-
bedded constituents apparently results in a fined
grained and highly adequate prediction even with
this very basic distinction of constraints.
Fixing these parameters, we validated the pre-
dictions of the model for the remaining half of the
materials. Here we arrived at a highly reliable cor-
relation of ? = 0.86 (? = 0.67 including PPs) be-
tween PG grammaticality indices and acceptabil-
ity judgements.
7 Conclusion
The method described in this paper makes it pos-
sible to give a quantified indication of sentence
grammaticality. This approach is direct and takes
advantage of a constraint-based representation of
syntactic information, making it possible to repre-
sent precisely the syntactic characteristics of an in-
put in terms of satisfied and (if any) violated con-
straints. The notion of grammaticality index we
have proposed here integrates different kind of in-
formation: the quality of the description (in terms
of well-formedness degree), the density of infor-
mation (the quantity of constraints describing an
element) as well as the structure itself. These three
parameters are the basic indicators of the gram-
maticality index.
The relevance of this method has been ex-
perimentally shown, and the results described in
this paper illustrate the correlation existing be-
tween the prediction (automatically calculated)
expressed in terms of GI and the acceptability
judgment given by subjects.
This approach also presents a practical interest:
it can be directly implemented into a parser. The
next step of our work will be its validation on large
corpora. Our parser will associate a grammatical
index to each sentence. This information will be
validated by means of acceptability judgments ac-
quired on the basis of a sparse sampling strategy.
References
Bard E., D. Robertson & A. Sorace (1996) ?Magnitude
Estimation of Linguistic Acceptability?, Language
72:1.
Blache P. & J.-P. Prost (2005) ?Gradience, Construc-
tions and Constraint Systems?, in H. Christiansen &
al. (eds), Constraint Solving and NLP, Lecture Notes
in Computer Science, Springer.
Blache P. (2005) ?Property Grammars: A Fully
Constraint-Based Theory?, in H. Christiansen & al.
(eds), Constraint Solving and NLP, Lecture Notes in
Computer Science, Springer.
Blache P. (2006) ?A Robust and Efficient Parser for
Non-Canonical Inputs?, in proceedings of Robust
Methods in Analysis of Natural Language Data,
EACL workshop.
Chomsky N.. (1975) The Logical Structure of Linguis-
tic Theory, Plenum Press
Croft W. & D. Cruse (2003) Cognitive Linguistics,
Cambridge University Press.
Foth K., M. Daum & W. Menzel (2005) ?Parsing Unre-
stricted German Text with Defeasible Constraints?,
in H. Christiansen & al. (eds), Constraint Solv-
ing and NLP, Lecture Notes in Computer Science,
Springer.
Fillmore C. (1998) ?Inversion and Contructional In-
heritance?, in Lexical and Constructional Aspects of
Linguistic Explanation, Stanford University.
Kay P. & C. Fillmore (1999) ?Grammatical Construc-
tions and Linguistic Generalizations: the what?s x
doing y construction?, Language.
Keller F. (2000) Gradience in Grammar. Experimental
and Computational Aspects of Degrees of Grammat-
icality, Phd Thesis, University of Edinburgh.
Keller F. (2003) ?A probabilistic Parser as a Model
of Global Processing Difficulty?, in proceedings of
ACCSS-03
Menzel W. & I. Schroder (1998) ?Decision procedures
for dependency parsing using graded constraints?,
in S. Kahane & A. Polgue`re (eds), Proc. Colin-
gACL Workshop on Processing of Dependency-
based Grammars.
Prince A. & Smolensky P. (1993) Optimality The-
ory: Constraint Interaction in Generative Gram-
mars, Technical Report RUCCS TR-2, Rutgers Cen-
ter for Cognitive Science.
Sag I., T. Wasow & E. Bender (2003) Syntactic Theory.
A Formal Introduction, CSLI.
Schro?der I. (2002) Natural Language Parsing with
Graded Constraints. PhD Thesis, University of
Hamburg.
Sorace A. & F. Keller (2005) ?Gradience in Linguistic
Data?, in Lingua, 115.
64
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 186?191,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Multimodal Annotation of Conversational Data
P. Blache1, R. Bertrand1, B. Bigi1, E. Bruno3, E. Cela6, R. Espesser1, G. Ferr?4, M. Guardiola1, D. Hirst1,
E.-P. Magro6, J.-C. Martin2, C. Meunier1, M.-A. Morel6, E. Murisasco3, I Nesterenko1, P. Nocera5,
B. Pallaud1, L. Pr?vot1, B. Priego-Valverde1, J. Seinturier3, N. Tan2, M. Tellier1, S. Rauzy1
(1) LPL-CNRS-Universit? de Provence (2) LIMSI-CNRS-Universit? Paris Sud
(3) LSIS-CNRS-Universit? de Toulon (4) LLING-Universit? de Nantes
(5) LIA-Universit? d?Avignon (6) RFC-Universit? Paris 3
blache@lpl-aix.fr
Abstract
We propose in this paper a broad-coverage
approach for multimodal annotation of
conversational data. Large annotation pro-
jects addressing the question of multimo-
dal annotation bring together many dif-
ferent kinds of information from different
domains, with different levels of granula-
rity. We present in this paper the first re-
sults of the OTIM project aiming at deve-
loping conventions and tools for multimo-
dal annotation.
1 Introduction
We present in this paper the first results of the
OTIM1 project aiming at developing conventions
and tools for multimodal annotation. We show
here how such an approach can be applied in the
annotation of a large conversational speech cor-
pus.
Before entering into more details, let us men-
tion that our data, tools and conventions are des-
cribed and freely downlodable from our website
(http ://www.lpl-aix.fr/ otim/).
The annotation process relies on several tools
and conventions, most of them elaborated within
the framework of the project. In particular, we pro-
pose a generic transcription convention, called En-
riched Orthographic Trancription, making it pos-
sible to annotate all specific pronunciation and
speech event, facilitating signal alignment. Dif-
ferent tools have been used in order to prepare
or directly annotate the transcription : grapheme-
phoneme converter, signal alignment, syllabifica-
tion, prosodic analysis, morpho-syntactic analysis,
chunking, etc. Our ambition is to propose a large
corpus, providing rich annotations in all the dif-
1OTIM stands for Outils pour le Traitement de l?Informa-
tion Multimodale (Tools for Multimodal Annotation). This
project in funded by the French ANR agency.
ferent linguistic domains, from prosody to gesture.
We describe in the following our first results.
2 Annotations
We present in this section some of the annota-
tions of a large conversational corpus, called CID
(Corpus of Interactional Data, see (Bertrand08)),
consisting in 8 dialogues, with audio and video si-
gnal, each lasting 1 hour.
Transcription : The transcription process is
done following specific conventions derived from
that of the GARS (Blanche-Benveniste87). The
result is what we call an enriched orthographic
construction, from which two derived transcrip-
tions are generated automatically : the standard or-
thographic transcription (the list of orthographic
tokens) and a specific transcription from which
the phonetic tokens are obtained to be used by the
grapheme-phoneme converter.
From the phoneme sequence and the audio si-
gnal, the aligner outputs for each phoneme its
time localization. This aligner (Brun04) is HMM-
based, it uses a set of 10 macro-classes of vowel
(7 oral and 3 nasal), 2 semi-vowels and 15 conso-
nants. Finally, from the time aligned phoneme se-
quence plus the EOT, the orthographic tokens is
time-aligned.
Syllables : The corpus was automatically seg-
mented in syllables. Sub-syllabic constituents (on-
set, nucleus and coda) are then identified as well
as the syllable structure (V, CV, CCV, etc.). Sylla-
bic position is specified in the case of polysyllabic
words.
Prosodic phrasing : Prosodic phrasing refers
to the structuring of speech material in terms of
boundaries and groupings. Our annotation scheme
supposes the distinction between two levels of
phrasing : the level of accentual phrases (AP, (Jun,
2002)) and the higher level of intonational phrases
186
(IP). Mean annotation time for IPs and APs was
30 minutes per minute.
Prominence : The prominence status of a syl-
lable distinguishes between accentuability (the
possibility for syllable to be prominent) and pro-
minence (at the perception level). In French the
first and last full syllables (not containing a
schwa) of a polysyllabic word can be prominent,
though this actual realization depends on spea-
kers choices. Accentuability annotation is auto-
matic while prominence annotation is manual and
perceptually based.
Tonal layer : Given a lack of consensus on the
inventory of tonal accents in French, we choose to
integrate in our annotation scheme three types of
tonal events : a/ underlying tones (for an eventual
FrenchToBI annotation) ; b/ surface tones (anno-
tated in terms of MOMel-Intsint protocol Hirst et
al 2000) ; c/ melodic contours (perceptually anno-
tated pitch movements in terms of their form and
function). The interest to have both manual and
automatic INTSINT annotations is that it allows
the study of their links.
Hand gestures : The formal model we use for
the annotation of hand gestures is adapted from
the specification files created by Kipp (2004) and
from the MUMIN coding scheme (Allwood et al,
2005). Among the main gesture types, we anno-
tate iconics, metaphoric, deictics, beats, emblems,
butterworths or adaptors.
We used the Anvil tool (Kipp, 2004) for the ma-
nual annotations. We created a specification files
taking into account the different information types
and the addition of new values adapted to the
CID corpus description (e.g. we added a separate
track Symmetry). For each hand, the scheme has 10
tracks. We allowed the possibility of a gesture per-
taining to several semiotic types using a boolean
notation. A gesture phrase (i.e. the whole gesture)
can be decomposed into several gesture phases i.e.
the different parts of a gesture such as the prepara-
tion, the stroke (the climax of the gesture), the hold
and the retraction (when the hands return to their
rest position) (McNeill, 1992). The scheme also
enables to annotate gesture lemmas (Kipp, 2004),
the shape and orientation of the hand during the
stroke, the gesture space, and contact. We added
the three tracks to code the hand trajectory, ges-
ture velocity and gesture amplitude.
Discourse and Interaction : Our discourse an-
notation scheme relies on multidimensional fra-
meworks such as DIT++ (Bunt, 2009) and is com-
patible with the guidelines defined by the Semantic
Annotation Framework (Dialogue Act) working
group of ISO TC37/4.
Discourse units include information about their
producer, have a form (clause, fragment, dis-
fluency, non-verbal), a content and a communi-
cative function. The same span of raw data may
be covered by several discourse units playing dif-
ferent communicative functions. Two discourse
units may even have exactly the same temporal ex-
tension, due to the multifonctionality that cannot
be avoided (Bunt, 2009).
Compared to standard dialogue act annotation
frameworks, three main additions are proposed :
rhetorical function, reported speech and humor.
Our rhetorical layer is an adaptation of an exis-
ting schema developed for monologic written data
in the context of the ANNODIS project.
Disfluencies : Disfluencies are organized
around an interruption point, which can occur al-
most anywhere in the production. Disfluencies can
be prosodic (lenghtenings, silent and filled pauses,
etc.), or lexicalized. In this case, they appear as a
word or a phrase truncation, that can be comple-
ted. We distinguish three parts in a disfluency (see
(Shriberg, 1994), (Blanche-Benveniste87)) :
? Reparandum : what precedes the interruption
point. This part is mandatory in all disfluen-
cies. We indicate there the nature of the inter-
rupted unit (word or phrase), and the type of
the truncated word (lexical or grammatical) ;
? Break interval. It is optional, some disfluen-
cies do not bear any specific event there.
? Reparans : the part following the break, repai-
ring the reparandum. We indicate there type
of the repair (no restart, word restart, determi-
ner restart, phrase restart, etc.), and its func-
tion (continuation, repair without change, re-
pair with change, etc.).
3 Quantitative information
We give in this section some indication about
the state of development of the CID annotation.
Hand gestures : 75 minutes involving 6 spea-
kers have been annotated, yielding a total number
of 1477 gestures. The onset and offset of gestures
correspond to the video frames, starting from and
187
going back to a rest position.
Face and gaze : At the present time, head move-
ments, gaze directions and facial expressions have
been coded in 15 minutes of speech yielding a to-
tal number of 1144 movements, directions and ex-
pressions, to the exclusion of gesture phases. The
onset and offset of each tag are determined in the
way as for hand gestures.
Body Posture : Our annotation scheme consi-
ders, on top of chest movements at trunk level,
attributes relevant to sitting positions (due to the
specificity of our corpus). It is based on the Pos-
ture Scoring System (Bull, 1987) and the Annota-
tion Scheme for Conversational Gestures (Kipp et
al., 2007). Our scheme covers four body parts :
arms, shoulders, trunk and legs. Seven dimensions
at arm level and six dimensions at leg level, as well
as their related reference points we take in fixing
the spatial location, are encoded.
Moreover, we added two dimensions to describe
respectively the arm posture in the sagittal plane
and the palm orientation of the forearm and the
hand. Finally, we added three dimensions for leg
posture : height, orientation and the way in which
the legs are crossed in sitting position.
We annotated postures on 15 minutes of the cor-
pus involving one pair of speakers, leading to 855
tags with respect to 15 different spatial location
dimensions of arms, shoulder, trunk and legs.
Annotation Time (min.) Units
Transcript 480 -
Hands 75 1477
Face 15 634
Gaze 15 510
Posture 15 855
R. Speech 180
Com. Function 6 229
Disfluencies At the moment, this annotation is
fully manual (we just developed a tool helping the
process in identifying disfluencies, but it has not
yet been evaluated). Annotating this phenomenon
requires 15mns for 1 minute of the corpus. The
following table illustrates the fact that disfluen-
cies are speaker-dependent in terms of quantity
and type. These figures also shows that disfluen-
cies affect lexicalized words as well as grammati-
cal ones.
Speaker_1 Speaker_1
Total number of words 1,434 1,304
Disfluent grammatical words 17 54
Disfluent lexicalized words 18 92
Truncated words 7 12
Truncated phrases 26 134
Transcription and phonemes The following
table recaps the main figures about the different
specific phenomena annotated in the EOT. To the
best of our knowledge, these data are the first of
this type obtained on a large corpus. This informa-
tion is still to be analyzed.
Phenomenon Number
Elision 11,058
Word truncation 1,732
Standard liaison missing 160
Unusual liaison 49
Non-standard phonetic realization 2,812
Laugh seq. 2,111
Laughing speech seq. 367
Single laugh IPU 844
Overlaps > 150 ms 4,150
Syntax We used the stochastic parser developed
at the LPL (Blache&Rauzy, 2008) to automaticaly
generate morppho-syntactic and syntactic annota-
tions. The parser has been adapted it in order to ac-
count for the specificities of speech analysis. First,
the system implements a segmentation technique,
identifying large syntactic units that can be consi-
dered as the equivalent of sentences in written
texts. This technique distinguishes between strong
and weak or soft punctuation marks. A second mo-
dification concerns the lexical frequencies used by
the parser model in order to capture phenomena
proper to conversational data.
The categories and chunks counts for the whole
corpus are summarized in the following figure :
Category Count Group Count
adverb 15123 AP 3634
adjective 4585 NP 13107
auxiliary 3057 PP 7041
determiner 9427 AdvP 15040
conjunction 9390 VPn 22925
interjection 5068 VP 1323
preposition 8693 Total 63070
pronoun 25199
noun 13419 Soft Pct 9689
verb 20436 Strong Pct 14459
Total 114397 Total 24148
4 Evaluations
Prosodic annotation : Prosodic annotation of
1 dialogue has been done by 2 experts. The
annotators worked separately using Praat. Inter-
transcriber agreement studies were done for the
annotation of higher prosodic units. First anno-
tator marked 3,159 and second annotator 2,855
188
Intonational Phrases. Mean percentage of inter-
transcriber agreement was 91.4% and mean
kappa-statistics 0.79, which stands for a quite sub-
stantial agreement.
Gesture : We performed a measure of inter-
reliability for three independent coders for Gesture
Space. The measure is based on Cohen?s correc-
ted kappa coefficient for the validation of coding
schemes (Carletta96).
Three coders have annotated three minutes for
GestureSpace including GestureRegion and Ges-
tureCoordinates. The kappa values indicated that
the agreement is high for GestureRegion of right
hand (kappa = 0.649) and left hand (kappa =
0.674). However it is low for GestureCoordinates
of right hand (k= 0.257) and left hand (k= 0.592).
Such low agreement of GestureCoordinates might
be due to several factors. First, the number of ca-
tegorical values is important.
Second, three minutes might be limited in terms
of data to run a kappa measure. Third, GestureRe-
gion affects GestureCoordinates : if the coders di-
sagree about GestureRegion, they are likely to also
annotate GestureCoordinates in a different way.
For instance, it was decided that no coordinate
would be selected for a gesture in the center-center
region, whereas there is a coordinate value for ges-
tures occurring in other parts of the GestureRe-
gion. This means that whenever coders disagree
between the center-center or center region, the an-
notation of the coordinates cannot be congruent.
5 Information representation
5.1 XML encoding
Our approach consists in first precisely define
the organization of annotations in terms of typed-
feature structures. We obtain an abstract descrip-
tion from which we automatically generate a for-
mal schema in XML. All the annotations are then
encoded following this schema.
Our XML schema, besides a basic encoding of
data following AIF, encode all information concer-
ning the organization as well as the constraints on
the structures. In the same way as TFS are used
as a tree description language in theories such as
HPSG, the XML schema generated from our TFS
representation also plays the same role with res-
pect to the XML annotation data file. On the one
hand, basic data are encoded with AIF, on the
other hand, the XML schema encode all higher
level information. Both components (basic data +
structural constraints) guarantee against informa-
tion loss that otherwise occurs when translating
from one coding format to another (for example
from Anvil to Praat).
5.2 Querying
To ease the multimodal exploitation of the data,
our objective is to provide a set of operators dedi-
cated to concurrent querying on hierarchical an-
notation. Concurrent querying consists in que-
rying annotations belonging to two or more mo-
dalities or even in querying the relationships bet-
ween modalities. For instance, we want to be able
to express queries over gestures and intonation
contours (what kind of intonational contour does
the speaker use when he looks at the listener ?).
We also want to be able to query temporal relation-
ships (in terms of anticipation, synchronization or
delay) between both gesture strokes and lexical af-
filiates.
Our proposal is to define these operators as an
extension of XQuery. From the XML encoding
and the temporal alignment of annotated data, it
will possible to express queries to find patterns and
to navigate in the structure. We also want to en-
able a user to check predicates on parts of the cor-
pus using classical criteria on values, annotations
and existing relationships (temporal or structural
ones corresponding to inclusions or overlaps bet-
ween annotations). First, we shall rely on one of
our previous proposal called MSXD (MultiStruc-
tured XML Document). It is a XML-compatible
model designed to describe and query concurrent
hierarchical structures defined over the same tex-
tual data which supports Allen?s relations.
6 Conclusion
Multimodal annotation is often reduced to
the encoding of gesture, eventually accompa-
nied with another level of linguistic information
(e.g. morpho-syntax). We reported in this paper a
broad-coverage approach, aiming at encoding all
the linguistic domains into a unique framework.
We developed for this a set of conventions and
tools making it possible to bring together and align
all these different pieces of information. The result
is the CID (Corpus of Interactional Data), the first
large corpus of conversational data bearing rich
annotations on all the linguistic domains.
189
References
Allen J. (1999) Time and time again : The many way to re-
present time. International Journal of Intelligent Systems,
6(4)
Allwood, J., Cerrato, L., Dybkjaer, L., Jokinen, K., Navar-
retta, C., Paggio, P. (2005) The MUMIN Multimodal Co-
ding Scheme, NorFA yearbook 2005.
Baader F., D. Calvanese, D. L. McGuinness, D. Nardi, P.
F. Patel-Schneider (2003) The Description Logic Hand-
book : Theory, Implementation, Applications. Cambridge
University Press.
Bertrand, R., Blache, P., Espesser, R., Ferr?, G., Meunier, C.,
Priego-Valverde, B., Rauzy, S. (2008) ?Le CID - Corpus
of Interactional Data - Annotation et Exploitation Multi-
modale de Parole Conversationnelle?, in revue Traitement
Automatique des Langues, 49 :3.
Bigi, C. Meunier, I. Nesterenko, R. Bertrand 2010. ?Syllable
Boundaries Automatic Detection in Spontaneous Speech?,
in proceedings of LREC 2010.
Blache P. and Rauzy S. 2008. ?Influence de la qualit? de
l??tiquetage sur le chunking : une corr?lation d?pendant de
la taille des chunks?. in proceedings of TALN 2008 (Avi-
gnon, France), pp. 290-299.
Blache P., R. Bertrand, and G. Ferr? 2009. ?Creating and
Exploiting Multimodal Annotated Corpora : The ToMA
Project?. In Multimodal Corpora : From Models of Natu-
ral Interaction to Systems and Applications, Springer.
Blanche-Benveniste C. & C. Jeanjean (1987) Le fran?ais
parl?. Transcription et ?dition, Didier Erudition.
Blanche-Benveniste C. 1987. ?Syntaxe, choix du lexique et
lieux de bafouillage?, in DRLAV 36-37
Browman C. P. and L. Goldstein. 1989. ?Articulatory ges-
tures as phonological units?. In Phonology 6, 201-252
Brun A., Cerisara C., Fohr D., Illina I., Langlois D., Mella O.
& Smaili K. (2004- ?Ants : Le syst?l?me de transcription
automatique du Loria?, Actes des XXV Journ?es d?Etudes
sur la Parole, F?s.
E. Bruno, E. Murisasco (2006) Describing and Querying hie-
rarchical structures defined over the same textual data, in
Proceedings of the ACM Symposium on Document Engi-
neering (DocEng 2006).
Bull, P. (1987) Posture and Gesture, Pergamon Press.
Bunt H. 2009. ?Multifunctionality and multidimensional
dialogue semantics.? In Proceedings of DiaHolmia?09,
SEMDIAL.
B?rki A., C. Gendrot, G. Gravier & al.(2008) ?Alignement
automatique et analyse phon?tique : comparaison de dif-
f?rents syst?mes pour l?analyse du schwa?, in revue TAL
,49 :3
Carletta, J. (1996) ?Assessing agreement on classification
tasks : The kappa statistic?, in Computational Linguistics
22.
Corlett, E. N., Wilson,John R. Manenica. I. (1986) ?Influence
Parameters and Assessment Methods for Evaluating Body
Postures?, in Ergonomics of Working Postures : Models,
Methods and Cases , Proceedings of the First International
Occupational Ergonomics Symposium.
Di Cristo & Hirst D. (1996) ?Vers une typologie des unites in-
tonatives du fran?ais?, XXI?me JEP, 219-222, 1996, Avi-
gnon, France
Di Cristo A. & Di Cristo P. (2001) ?Syntaix, une approche
m?trique-autosegmentale de la prosodie?, in revue Traite-
ment Automatique des Langues, 42 :1.
Dipper S., M. Goetze and S. Skopeteas (eds.) 2007. Informa-
tion Structure in Cross-Linguistic Corpora : Annotation
Guidelines, Working Papers of the SFB 632, 7 :07
FGNet Second Foresight Report (2004) Face
and Gesture Recognition Working Group.
http ://www.mmk.ei.tum.de/ waf/fgnet-intern/3rd-
fgnet-foresight-workshop.pdf
Gendner V. et al 2003. ?PEAS, the first instantiation of a
comparative framework for evaluating parsers of French?.
in Research Notes of EACL 2003 (Budapest, Hungaria).
Hawkins S. and N. Nguyen 2003. ?Effects on word re-
cognition of syllable-onset cues to syllable-coda voicing?,
in Papers in Laboratory Phonology VI. Cambridge Univ.
Press.
Hirst, D., Di Cristo, A., Espesser, R. 2000. ?Levels of des-
cription and levels of representation in the analysis of in-
tonation?, in Prosody : Theory and Experiment, Kluwer.
Hirst, D.J. (2005) ?Form and function in the representation
of speech prosody?, in K.Hirose, D.J.Hirst & Y.Sagisaka
(eds) Quantitative prosody modeling for natural speech
description and generation (Speech Communication 46 :3-
4.
Hirst, D.J. (2007) ?A Praat plugin for Momel and INTSINT
with improved algorithms for modelling and coding into-
nation?, in Proceedings of the XVIth International Confe-
rence of Phonetic Sciences.
Hirst, D. (2007), Plugin Momel-Intsint. Inter-
net : http ://uk.groups.yahoo.com/group/praat-
users/files/Daniel_Hirst/plugin_momel-intsint.zip,
Boersma, Weenink, 2007.
Jun, S.-A., Fougeron, C. 2002. ?Realizations of accentual
phrase in French intonation?, in Probus 14.
Kendon, A. (1980) ?Gesticulation and Speech : Two Aspects
of the Porcess of Utterance?, in M.R. Key (ed.), The Re-
lationship of Verbal and Nonverbal Communication, The
Hague : Mouton.
Kita, S., Ozyurek, A. (2003) ?What does cross-linguistic va-
riation in semantic coordination of speech and gesture re-
veal ? Evidence for an interface representation of spatial
thinking and speaking?, in Journal of Memory and Lan-
guage, 48.
Kipp, M. (2004). Gesture Generation by Imitation - From
Human Behavior to Computer Character Animation. Boca
Raton, Florida, Dissertation.com.
Kipp, M., Neff, M., Albrecht, I. (2007). An annotation
scheme for conversational gestures : how to economically
capture timing and form. Language Resources and Eva-
luation, 41(3).
Koiso H., Horiuchi Y., Ichikawa A. & Den Y.(1998) ?An ana-
lysis of turn-taking and backchannels based on prosodic
and syntactic features in Japanese map task dialogs?, in
Language and Speech, 41.
McNeill, D. (1992). Hand and Mind. What Gestures Re-
veal about Thought, Chicago : The University of Chicago
Press.
McNeill, D. (2005). Gesture and Thought, Chicago, London :
The University of Chicago Press.
Milborrow S., F. Nicolls. (2008). Locating Facial Features
with an Extended Active Shape Model. ECCV (4).
Nesterenko I. (2006) ?Corpus du parler russe spontan? : an-
notations et observations sur la distribution des fronti?res
prosodiques?, in revue TIPA, 25.
190
Paroubek P. et al 2006. ?Data Annotations and Measures in
EASY the Evaluation Campaign for Parsers in French?. in
proceedings of the 5th international Conference on Lan-
guage Resources and Evaluation 2006 (Genoa, Italy), pp.
314-320.
Pierrehumbert & Beckman (1988) Japanese Tone Structure.
Coll. Linguistic Inquiry Monographs, 15. Cambridge,
MA, USA : The MIT Press.
Platzer, W., Kahle W. (2004) Color Atlas and Textbook of
Human Anatomy, Thieme. Project MuDis. Technische
Universitat Munchen. http ://www9.cs.tum.edu/research
Scherer, K.R., Ekman, P. (1982) Handbook of methods in
nonverbal behavior research. Cambridge University Press.
Shriberg E. 1994. Preliminaries to a theory of speech dis-
fluencies. PhD Thesis, University of California, Berkeley
Wallhoff F., M. Ablassmeier, and G. Rigoll. (2006) ?Mul-
timodal Face Detection, Head Orientation and Eye Gaze
Tracking?, in proceedings of International Conference on
Multisensor Fusion and Integration (MFI).
White, T. D., Folkens, P. A. (1991) Human Osteology. San
Diego : Academic Press, Inc.
191
