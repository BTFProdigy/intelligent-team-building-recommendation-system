A Transitive Model for Extracting Translation Equivalents of Web 
Queries through Anchor Text Mining 
 
Wen-Hsiang Lu 
Institute of Information Science 
Academia Sinica; 
Dept. of Computer Science and 
Information Engineering 
National Chiao Tung University 
Hsinchu 300, Taiwan, ROC 
whlu@iis.sinica.edu.tw 
Lee-Feng Chien 
Institute of Information 
Science, Academia Sinica 
Nangang 115, Taiwan, ROC 
lfchien@iis.sinica.edu.tw 
Hsi-Jian Lee 
Dept. of Computer Science and 
Information Engineering 
National Chiao Tung University 
 Hsinchu 300, Taiwan, ROC 
 hjlee@csie.nctu.edu.tw 
 
Abstract  
One of the existing difficulties of 
cross-language information retrieval (CLIR) 
and Web search is the lack of appropriate 
translations of new terminology and proper 
names. Different from conventional 
approaches, in our previous research we 
developed an approach for exploiting Web 
anchor texts as live bilingual corpora and 
reducing the existing difficulties of query 
term translation. Although Web anchor texts, 
undoubtedly, are very valuable multilingual 
and wide-scoped hypertext resources, not 
every particular pair of languages contains 
sufficient anchor texts in the Web to extract 
corresponding translations in the language 
pair. For more generalized applications, in 
this paper we extend our previous approach 
by adding a phase of transitive (indirect) 
translation via an intermediate (third) 
language, and propose a transitive model to 
further exploit anchor-text mining in term 
translation extraction applications. 
Preliminary experimental results show that 
many query translations which cannot be 
obtained using the previous approach can be 
extracted with the improved approach. 
 
1. Introduction 
Cross-language information retrieval (CLIR), 
addressing the special need where users can 
query in one language and retrieve relevant 
documents written or indexed in another 
language, has become an important issue in the 
research of information retrieval (Dumais et al, 
1996; Davis et al, 1997; Ballesteros & Croft, 
1998; Nie et al, 1999). However, its application 
to practical Web search services has not lived up 
to expectations, since they suffer a major 
bottleneck that lacks up-to-date bilingual 
lexicons containing the translation of popular 
query terms 1  such as proper nouns (Kwok, 
2001). 
To enable capability of CLIR, existing IR 
systems mostly rely on bilingual dictionaries for 
cross-lingual retrieval. In these systems, queries 
submitted in a source language normally have to 
be translated into a target language by means of 
simple dictionary lookup. These 
dictionary-based techniques are limited in 
real-world applications, since the queries given 
by users often contain proper nouns. 
Another kind of popular approaches to 
dealing with query translation based on 
corpus-based techniques uses a parallel corpus 
containing aligned sentences whose translation 
pairs are corresponding to each other (Brown et 
al., 1993; Dagan et al, 1993; Smadja et al, 
1996). Although more reliable translation 
equivalents can be extracted by these techniques, 
the unavailability of large enough parallel 
corpora for various subject domains and 
multiple languages is still in a thorny situation. 
On the other hand, the alternative approach 
using comparable or unrelated text corpora were 
studied by Rapp (1999) and Fung et al (1998). 
This task is more difficult due to lack of parallel 
correlation between document or sentence pairs.  
                                                   
1
 In our collected query logs, most of user queries 
contain only one or two words, so we use query term, 
query or term interchangeably in this paper. 
In our previous research we have developed 
an approach to extracting translations of Web 
queries through mining of Web anchor texts and 
link structures (Lu, et al, 2001). This approach 
exploits Web anchor texts as live bilingual 
corpora to reduce the existing difficulties of 
query translation.  Anchor text sets, which are 
composed of a number of anchor texts linking to 
the same pages, may contain similar description 
texts in multiple languages, thus it is more likely 
that user?s queries and their corresponding 
translations frequently appear together in the 
same anchor text sets. The anchor-text mining 
approach has been found effective particularly 
for proper names, such as international company 
names, names of foreign movie stars, worldwide 
events, e.g., ?Yahoo?, ?Anthrax?, ?Harry Potter?, 
etc. 
Discovering useful knowledge from the 
potential resource of Web anchor texts is still 
not fully explored. According to our previous 
experiments, the extracted translation 
equivalents might not be reliable enough when a 
query term whose corresponding translations 
either appear infrequently in the same anchor 
text sets or even do not appear together. 
Especially, the translation process will be 
unavailable if there is a lack of sufficient anchor 
texts for a particular language pair. Although 
Web anchor texts, undoubtedly, are live 
multilingual resources, not every particular pair 
of languages contains sufficient anchor texts. 
To deal with the problems, this paper 
extends the previous anchor-text-based approach 
by adding a phase of indirect translation via an 
intermediate language. For a query term which 
is unable to be translated, our idea is to translate 
it into a set of translation candidates in an 
intermediate language, and then seek for the 
most likely translation from the candidates, 
which are translated from the intermediate 
language into the target language (Gollins et al, 
2001; Borin, 2000). We therefore propose a 
transitive translation model to further exploit 
anchor text mining for translating Web queries. 
A series of experiments has been conducted to 
realize the performance of the proposed 
approach. Preliminary experimental results show 
that many query translations which cannot be 
obtained using the previous approach can be 
extracted with the improved approach. 
 
2 The Previous Approach  
For query translation, the anchor-text-based 
approach is a new technique compared with the 
bilingual-dictionary- and parallel-corpus-based 
approaches. In this section we will introduce the 
basic concept of the anchor-text-based approach. 
For more details please refer to our initial work 
(Lu, et al, 2001). 
 
2.1 Anchor-Text Set 
An anchor text is the descriptive part of an 
out-link of a Web page. It represents a brief 
description of the linked Web page. For a Web 
page (or URL) ui, its anchor-text set is defined 
as all of the anchor texts of the links, i.e., ui's 
in-links, pointing to ui. In general, the 
anchor-text set records ui's alternative concepts 
and textual expressions such as titles and 
headings, which are cited by other Web pages. 
With different preferences, conventions and 
language competence, the anchor-text set could 
be composed of multilingual phrases, short texts, 
acronyms, or even ui's URL. For a query term 
appearing in the anchor-text set, it is likely that 
its corresponding translations also appear 
together. The anchor-text sets can be considered 
as a comparable corpus of translated texts, from 
the viewpoint of translation extraction.  
 
2.2 The Probabilistic Inference Model 
To determine the most probable target 
translation t for source query term s, we 
developed a probabilistic inference model 
(Wong et al, 1995). This model is adopted for 
estimating probability value between source 
query and each translation candidate that 
co-occur in the same anchor-text sets. The 
estimation assumes that the anchor texts linking 
to the same pages may contain similar terms 
with analogous concepts. Therefore, a candidate 
translation has a higher chance to be an effective 
translation if it is written in the target language 
and frequently co-occurs with the source query 
term in the same anchor-text sets. In the field of 
Web research, it has been proven that the use of 
link structures is effective for estimating the 
authority of Web pages (Kleinberg, 1998; 
Chakrabarti et al, 1998). The model further 
assumes that the translation candidates in the 
anchor-text sets of the pages with higher 
authority may have more reliability in 
confidence. The similarity estimation function 
based on the probabilistic inference model is 
defined below: 
 
(1)              . 
)()|(
)()|(
                    
))((
)(
)(
)()(
1
1
1
1
?
?
?
?
=
=
=
=
?
?
=
??
??
=
?
?
=?
n
i
n
i
n
i
n
i
ii
ii
i
i
uPutsP
uPutsP
utsP
utsP
tsP
tsP
tsP
 
 
The above measure is adopted to estimate the 
degree of similarity between source term s and 
target translation t. The measure is estimated 
based on their co-occurrence in the anchor text 
sets of the concerned Web pages U = {u1, u2, ... 
un}, in which ui is a page of concern and P(ui) is 
the probability value used to measure the 
authority of page ui. By considering the link 
structures and concept space of Web pages, P(ui) 
is estimated with the probability of ui being 
linked, and its estimation is defined as follows: 
P(ui)= L(ui)/?j=1,n L(uj), where L(uj)= the number 
of in-links of page uj. Such estimation is 
simplified from HITS algorithm (Kleinberg, 
1998).  
In addition, we assume that s and t are 
independent given ui, then the joint probability 
P(s?t|ui) is equal to the product of P(s|ui) and 
P(t|ui), and the similarity measure becomes: 
(2). 
)(]||)|()|([
)(||
 
)(
1
1
?
?
=
=
?+
?
=?
n
i
n
i
iiiii
iii
uP)u)P(tuP(sutPusP
u)Pu)P(tuP(s
tsP
 
The values of P(s|ui) and P(t|ui) are defined to 
be estimated by calculating the fractions of the 
numbers of ui?s in-links containing s and t over 
L(ui), respectively. 
Therefore, a candidate translation has a higher 
confidence value to be an effective translation if 
it frequently co-occurs with the source term in 
the anchor-text sets of the pages with higher 
authority. 
 
2.3 The Estimation Process  
For each source term, the probabilistic inference 
model extracts the most probable translation that 
maximizes the estimation. The estimation 
process based on the model was developed to 
extract term translations through mining of 
real-world anchor-text sets. The process contains 
three major computational modules: anchor-text 
extraction, term extraction and term translation 
extraction. The anchor-text extraction module 
was constructed to collect pages from the Web 
and build up a corpus of anchor-text sets. On the 
other hand, for each given source term s, the 
term extraction module extracts key terms as the 
translation candidate set from the anchor-text 
sets of the pages containing s. At last, the term 
translation module extracts the translation that 
maximizes the similarity estimation. For more 
details about the estimation process, please refer 
to our previous work (Lu et al, 2001). 
To make a difference from the translation 
process via an intermediate language, the above 
process is called direct translation, and the 
adopted model called direct translation model 
hereafter. Meanwhile, we will use function 
Pdirect in Equation (3) for the estimation of the 
direct translation. 
 
 
(3)                         ).(log),( tsPtsPdirect ?=
 
3 The Improved Approach 
3.1 The Indirect Translation Model  
As mentioned above, for those query terms 
whose corresponding translations either appear 
infrequently in the same anchor text sets or do 
not appear together, the estimation with equation 
(2) is basically unreliable. To increase the 
possibility of translation extraction especially 
for the source terms whose corresponding 
translations do not co-occur, we add a phase of 
indirect translation through an intermediate 
language. For example, as shown in Fig. 1, our 
idea is to obtain the corresponding target 
translation ???? in simplified Chinese by 
translating the source term ???? in traditional 
Chinese into an intermediate term ?Sony? in 
English, and then seek for translating ?Sony? 
into a target term ???? in simplified Chinese. 
For both the source query and the target 
translation, we assume that their translations in 
the intermediate language are the same and can 
be found.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The above assumption is not unrealistic. 
For example, it is possible to find the Chinese 
translation of a Japanese movie star through 
submitting his/her English name to a search 
engine and browsing the retrieved Chinese pages 
containing the English name. The Web contains 
large amounts of multilingual pages, and 
English is the most likely intermediate language 
between other languages. Based on this 
assumption, we extend the probabilistic 
inference model and propose an indirect 
translation model as the following formula: 
 
(4)      ).(log)(log                    
)]()(log[                    
),(log),(
tmPmsP
tmPmsP
tmmsPtsPindirect
?+?=
????
??=
 
 
, where m is the transitive translation of s and t 
in the intermediate language, P(s?m) and 
P(m?t) are the probability values obtained with 
the direct translation model which can be 
calculated by Equation (2). 
 
3.2 The Transitive Translation Model 
The transitive model is developed to combine 
both the direct and indirect translation models 
and improve the translation accuracy. By 
combining Equation (3) and (4), the transitive 
translation model is defined as follows: 
 
??
? >
=
(5)                           otherwise.  ),,(
 if  ),,(
),(
tsPindirect
?t)Pdirect(s,tsPdirect
tsPtrans
 
, where ? is a predefined threshold value. 
 
4 Experimental Results 
4.1 Analysis of Anchor-Text Sets and 
Query Logs 
In the initial experiments, we took traditional 
Chinese and simplified Chinese as the source 
and target language respectively, and used 
English as the intermediate language. We have 
collected 1,980,816 traditional Chinese Web 
pages in Taiwan. Among these pages, 109,416 
pages whose anchor-text sets contained both 
traditional Chinese and English terms were 
taken as the anchor-text set corpus. We also 
collected 2,179,171 simplified Chinese Web 
pages in China and extracted 157,786 pages 
whose anchor-text sets contained both simplified 
Chinese and English terms. In addition, through 
merging the two Web page collections into a 
larger one, we extracted 4,516 Web pages 
containing both traditional and simplified 
Chinese terms. The three comparable corpora 
provide a potential resource of translation pairs 
for some Web queries. In order to realize the 
feasibility in translating query terms via 
transitive translation, we aim at finding out the 
corresponding simplified Chinese translations of 
traditional Chinese query terms via English as 
the intermediate language.  
Fig. 1. An abstract diagram showing the 
concepts of direct translation and indirect 
translation. 
m 
t s 
Sony 
(English) 
??
(Traditional 
Chinese) 
s : source term 
t : target translation 
m : intermediate translation 
??
(Simplified 
Chinese) 
We also collected popular query terms with 
the logs from two real-world Chinese search 
engines in Taiwan, i.e., Dreamer and GAIS2. 
The Dreamer log contained 228,566 unique 
query terms from a period of over 3 months in 
1998, and the GAIS log contained 114,182 
unique query terms from a period of two weeks 
in 1999. There were 9,709 most popular query 
terms whose frequencies were above 10 in both 
of the logs and 1,230 of them were English 
terms. After filtering out the terms which were 
used locally, we obtained 258 terms. These 
query terms were taken as the major test set in 
the term translation extraction analysis. The 
traditional Chinese translations of the test query 
terms were determined manually and taken as 
the source query set in the following 
experiments. 
According to our previous work (Lu et al, 
2001), there were three methods for term 
extraction, which is a necessary process step in 
extracting translations from anchor-text corpus. 
Since we have not yet collected a query log in 
simplified Chinese, in the following experiments 
we adopted the PAT-tree-based keyword 
extraction method, which is an efficient 
statistics-based approach that can extract longer 
terms without using a dictionary (Chien, 1997). 
To evaluate the achieved performance of 
query translation, we used the average top-n 
inclusion rate as a metric. For a set of test query 
terms, its top-n inclusion rate is defined as the 
percentage of the query terms whose effective 
translation(s) can be found in the top n extracted 
translations. 
 
4.2 Performance with the Direct 
Translation Model 
In order to realize the feasibility of the transitive 
translation model, we carried out some 
experiments based on the direct translation 
models and the three different anchor-text set 
corpora in the first step. Table 1 shows the 
results of the obtained top-5 inclusion rates, 
                                                   
2
 These two search engines are second-tier portals in 
Taiwan, whose logs have certain representatives in 
the Chinese communities, and whose URL?s are as 
follows: http://www.dreamer.com.tw/ and 
http://gais.cs.cu.edu.tw/. 
where terms ?TC?, ?SC? and ?ENG? represent 
traditional Chinese, simplified Chinese and 
English terms respectively. The performance of 
translating TC into SC is worse than that of the 
other two since the size of the anchor-text set 
corpus containing both TC and SC is relatively 
small in comparison with the others. This is why 
we are pursuing in this paper to integrate the 
direct translation with the indirect translation via 
a third language. However, the performance of 
the direct translation from TC to SC is used as a 
reference in comparison with our proposed 
models in the following experiments.  
 
Table 1. Top-n inclusion rates obtained with the 
direct translation model and the three specific 
language pairs corpora. 
Type Top1 Top2 Top3 Top4 Top5 
TC=>SC 35.7% 43.0% 46.9% 49.6% 51.2% 
TC=>ENG 68.6% 82.2% 85.7% 88.0% 88.8% 
ENG=>SC 45.3% 55.8% 59.3% 61.6% 64.0% 
 
4.3 Performance with the Indirect and 
Transitive Translation Models 
To realize the improvement using the transitive 
translation model, some further experiments 
were conducted. As shown in Table 2, the 
indirect and transitive translation models 
outperform than the direct translation model. As 
mentioned above, the size of the anchor-text 
corpus that contains both TC and SC is small. 
The indirect translation model is, therefore, 
helpful to find out the corresponding translations 
for some terms with low-frequency values in the 
corpora. For example, the traditional Chinese 
term ???? ? was found can obtain its 
corresponding translation equivalent ????? 
in simplified Chinese via the intermediate 
translation ?Siemens?, which cannot be found 
only using the direct translation. 
By examining the top-1 translations 
obtained with the three different models, it was 
found that the inclusion rates can be from 44.2% 
using the indirect translation to 49.2% using the 
transitive translation model. Table 3 illustrates 
some of the translations extracted using the 
transitive translation model. 
 
Table 2. Top-n inclusion rates obtained with 
different models. 
Model Top1 Top2 Top3 Top4 Top5 
Direct 
Translation 
35.7% 43.0% 46.9% 49.6% 51.2% 
Indirect 
Translation 
44.2% 55.1% 58.0% 59.7% 60.5% 
Transitive 
Translation 
49.2% 58.1% 60.9% 61.6% 62.0% 
Combination 
of Transitive 
Translation 
and Lexicon 
55.8% 60.8% 64.0% 65.9% 67.8% 
 
4.4 Performance with an Integration of 
Lexicon Lookup 
An additional experiment was also made to 
compare with the use of a translation lexicon for 
query translation. The lexicon contained more 
than 23,948 word/phrase entries in both 
traditional Chinese and simplified Chinese. It 
was found the top-1 inclusion rate that using the 
lexicon lookup was 12.4% which is obviously 
lower than the 49.2% that using the proposed 
transitive translation model. In addition, the 
top-1 inclusion rate can reach to 55.8% (see the 
last row of Table 2) if both of the approaches are 
combined. With the combined approach, the  
translation(s) of a query term is picked up from 
the lexicon if such a translation is already in the 
lexicon, otherwise it is obtained based on the 
transitive translation model.  
 
5 Concluding Remarks 
Anchor-text set corpus is a valuable resource for 
extracting translations of Web queries. How to 
exploit such kind of corpora in query translation 
is a challenging and potential research task. In 
this paper, we extend our previous approach by 
proposing a transitive translation model and 
achieve some improvements on translating those 
queries whose translations cannot be extracted 
using the previous approach. The improved 
approach has been proven particularly useful for 
the specific language pairs whose anchor texts 
are insufficient. However, there are still some 
problems need to be further investigated in the 
future. 
 
References  
Ballesteros, L. and Croft, W. B. (1997) Phrasal 
Translation and Query Expansion Techniques for 
Cross-Language Information Retrieval, 
Proceedings of ACM-SIGIR ?97, pp. 84-91. 
Borin, L. (2000) You?ll Take the High Road and I?ll 
Take the Low Road: Using a Third Language to 
Improve Bilingual Word Alignment, Proceedings 
of the 18th COLING, pp. 97-103. 
Brown, P., Pietra, S. A. D., Pietra, V. D. J., Mercer, R. 
L. (1993) The Mathematics of Machine Translation, 
Computational Linguistics, 19(2), pp. 263-312. 
Chakrabarti, S., Dom, B., Gibson, D., Kleinberg, J., 
Raghavan, P., Rajagopalan, S. (1998) Automatic 
Resource List Compilation by Analysing Hyperlink 
Structure and Associated Text, Proceedings of the 
seventh World Wide Web Conference. 
Chien, L. F. (1997) PAT-Tree-Based Keyword 
Extraction for Chinese Information Retrieval, 
Proceedings of ACM-SIGIR ?97, pp. 50-59. 
Dagan, I., Church, K. W., Gale, W. A (1993) Robust 
Bilingual Word Alignment for Machine Aided 
Translation. Proceedings of the Workshop on Very 
Large Corpora, pp. 1-8. 
Davis, M. and Ogden, W. C. (1997) Quilt: 
Implementing a large-scale cross-language text 
retrieval system, Proceedings of ACM-SIGIR?97 
Conference, pp. 92-98. 
Dumais, S. T., Landauer, T. K., Littman, M. L. (1996) 
Automatic Cross-linguistic Information Retrieval 
Using Latent Semantic Indexing, SIGIR?96 
Workshop on Cross-Linguistic Information 
Retrieval, pp. 16-24. 
Fung, P. and Yee, L. Y. (1998) An IR Approach for 
Translating New Words from Nonparallel, 
Comparable Texts, Proceedings of The 36th 
Annual Conference of the Association for 
Computational Linguistics, pp. 414-420. 
Gollins, T., Sanderson, M. (2001) Improving Cross 
language Information with Triangulated 
Translation, Proceedings of ACM-SIGIR2001 
Conference, pp. 90-95. 
Kleinberg, J. (1998) Authoritative Sources in a 
Hyperlinked Environment, Proceedings of 9th 
ACM-SIAM Symposium on Discrete Algorithms. 
Kwok, K. L. (2001) NTCIR-2 Chinese, Cross 
Language Retrieval Experiments Using PIRCS, 
Proceedings of NTCIR workshop meeting. 
Lu, W. H., Chien, L. F., Lee, H. J. (2001) Anchor 
Text Mining for Translation of Web Queries, 
Proceedings of The 2001 IEEE International 
Conference on Data Mining. 
Nie, J. Y., Isabelle, P., Simard, M., and Durand, R. 
(1999) Cross-language Information Retrieval 
Based on Parallel Texts and Automatic Mining of 
Parallel Texts from the Web, Proceedings of 
ACM-SIGIR?99 Conference. 
Rapp, R. (1999) Automatic Identification of Word 
Translations from Unrelated English and German 
Corpora, Proceedings of The 37th Annual 
Conference of the Association for Computational 
Linguistics. 
Smadja, F., McKeown, K., Hatzivassiloglou, V. 
(1996) Translating Collocations for Bilingual 
Lexicons: A Statistical Approach, Computational 
Linguistics, 22(1), pp. 1-38. 
Wong, S. K. M., Yao Y. Y. (1995) On Modeling 
Information Retrieval with Probabilistic Inference, 
ACM transactions on Information Systems, Vol.13, 
pp. 38-68. 
 
 
Table 3. Some examples of extracted target translations with the three different models. (the asterisk 
indicates the correct translation) 
 
 
Top-5 extracted target translations in simplified Chinese  Source terms in 
traditional Chinese Direct Translation  
Model 
Indirect Translation 
Model 
Transitive Translation Model 
???(Siemens) Not available 
???* (Siemens) 
??(Company) 
??(China) 
??(website) 
??(cooperation) 
???* (Siemens) 
??(Company) 
??(China) 
??(website) 
??(cooperation) 
??(Compaq) Not available ??* (Compaq) 
????(computer company) 
??(company) 
??(America) 
??(computer) 
??* (Compaq) 
????(computer company) 
??(company) 
??(America) 
??(computer) 
??(Sony) 
 
??* (Sony) 
???(our company) 
??* (Sony) 
??(record) 
???(Chinese version) 
??* (Sony) 
??* (Sony) 
???(movie site) 
??(entertainment) 
????(record company) 
??* (Sony) 
??* (Sony) 
???(movie site) 
??(entertainment) 
????(record company) 
 
Creating Multilingual Translation Lexicons with Regional Variations 
Using Web Corpora 
 
Pu-Jen Cheng*, Yi-Cheng Pan*, Wen-Hsiang Lu+, and Lee-Feng Chien*?  
* Institute of Information Science, Academia Sinica, Taiwan 
+ Dept. of Computer Science and Information Engineering, National Cheng Kung Univ., Taiwan 
? Dept. of Information Management, National Taiwan University, Taiwan 
{pjcheng, thomas02, whlu, lfchien}@iis.sinica.edu.tw 
 
Abstract 
The purpose of this paper is to automatically 
create multilingual translation lexicons with 
regional variations. We propose a transitive 
translation approach to determine translation 
variations across languages that have insuffi-
cient corpora for translation via the mining 
of bilingual search-result pages and clues of 
geographic information obtained from Web 
search engines. The experimental results 
have shown the feasibility of the proposed 
approach in efficiently generating translation 
equivalents of various terms not covered by 
general translation dictionaries. It also re-
vealed that the created translation lexicons 
can reflect different cultural aspects across 
regions such as Taiwan, Hong Kong and 
mainland China. 
1 Introduction 
Compilation of translation lexicons is a crucial proc-
ess for machine translation (MT) (Brown et al, 1990) 
and cross-language information retrieval (CLIR) 
systems (Nie et al, 1999). A lot of effort has been 
spent on constructing translation lexicons from do-
main-specific corpora in an automatic way 
(Melamed, 2000; Smadja et al, 1996; Kupiec, 1993). 
However, such methods encounter two fundamental 
problems: translation of regional variations and the 
lack of up-to-date and high-lexical-coverage corpus 
source, which are worthy of further investigation.  
The first problem is resulted from the fact that 
the translations of a term may have variations in dif-
ferent dialectal regions. Translation lexicons con-
structed with conventional methods may not adapt to 
regional usages. For example, a Chinese-English 
lexicon constructed using a Hong Kong corpus can-
not be directly adapted to the use in mainland China 
and Taiwan. An obvious example is that the word 
?taxi? is normally translated into ???? (Chinese 
transliteration of taxi) in Hong Kong, which is com-
pletely different from the translated Chinese words 
of ????? (rental cars) in mainland China and ??
??? (cars with meters) in Taiwan. Besides, trans-
literations of a term are often pronounced differently 
across regions. For example, the company name 
?Sony? is transliterated into ???? (xinli) in Tai-
wan and ???? (suoni) in mainland China. Such 
terms, in today?s increasingly internationalized 
world, are appearing more and more often. It is be-
lieved that their translations should reflect the cul-
tural aspects across different dialectal regions. 
Translations without consideration of the regional 
usages will lead to many serious misunderstandings, 
especially if the context to the original terms is not 
available.  
Halpern (2000) discussed the importance of 
translating simplified and traditional Chinese lex-
emes that are semantically, not orthographically, 
equivalent in various regions. However, previous 
work on constructing translation lexicons for use in 
different regions was limited. That might be resulted 
from the other problem that most of the conventional 
approaches are based heavily on domain-specific 
corpora. Such corpora may be insufficient, or un-
available, for certain domains. 
The Web is becoming the largest data repository 
in the world. A number of studies have been re-
ported on experiments in the use of the Web to com-
plement insufficient corpora. Most of them 
(Kilgarriff et al, 2003) tried to automatically collect 
parallel texts of different language versions (e.g. Eng-
lish and Chinese), instead of different regional ver-
sions (e.g. Chinese in Hong Kong and Taiwan), from 
the Web. These methods are feasible but only certain 
pairs of languages and subject domains can extract 
sufficient parallel texts as corpora. Different from the 
previous work, Lu et al (2002) utilized Web anchor 
texts as a comparable bilingual corpus source to ex-
tract translations for out-of-vocabulary terms (OOV), 
the terms not covered by general translation diction-
aries. This approach is applicable to the compilation 
of translation lexicons in diverse domains but requires 
powerful crawlers and high network bandwidth to 
gather Web data.  
It is fortunate that the Web contains rich pages in 
a mixture of two or more languages for some lan-
guage pairs such as Asian languages and English. 
Many of them contain bilingual translations of terms, 
including OOV terms, e.g. companies?, personal and 
technical names. In addition, geographic information 
about Web pages also provides useful clues to the 
regions where translations appear. We are, therefore, 
interested in realizing whether these nice character-
istics make it possible to automatically construct 
multilingual translation lexicons with regional varia-
tions. Real search engines, such as Google 
(http://www.google.com) and AltaVista (http://www. 
altavista.com), allow us to search English terms only 
for pages in a certain language, e.g. Chinese or 
Japanese. This motivates us to investigate how to 
construct translation lexicons from bilingual search-
result pages (as the corpus), which are normally re-
turned in a long ordered list of snippets of summaries 
(including titles and page descriptions) to help users 
locate interesting pages. 
The purpose of this paper is trying to propose a 
systematic approach to create multilingual transla-
tion lexicons with regional variations through min-
ing of bilingual search-result pages. The bilingual 
pages retrieved by a term in one language are 
adopted as the corpus for extracting its translations 
in another language. Three major problems are 
found and have to be dealt with, including: (1) ex-
tracting translations for unknown terms ? how to 
extract translations with correct lexical boundaries 
from noisy bilingual search-result pages, and how to 
estimate term similarity for determining correct 
translations from the extracted candidates; (2) find-
ing translations with regional variations ? how to 
find regional translation variations that seldom co-
occur in the same Web pages, and how to identify 
the corresponding languages of the retrieved search-
result pages once if the location clues (e.g. URLs) in 
them might not imply the language they are written 
in; and (3) translation with limited corpora  ? how 
to translate terms with insufficient search-result 
pages for particular pairs of languages such as Chi-
nese and Japanese, and simplified Chinese and tradi-
tional Chinese. 
The goal of this paper is to deal with the three 
problems. Given a term in one language, all possible 
translations will be extracted from the obtained bi-
lingual search-result pages based on their similarity to 
the term. For those language pairs with unavailable 
corpora, a transitive translation model is proposed, 
by which the source term is translated into the target 
language through an intermediate language. The 
transitive translation model is further enhanced by a 
competitive linking algorithm. The algorithm can 
effectively alleviate the problem of error propagation 
in the process of translation, where translation errors 
may occur due to incorrect identification of the am-
biguous terms in the intermediate language. In addi-
tion, because the search-result pages might contain 
snippets that do not be really written in the target lan-
guage, a filtering process is further performed to 
eliminate the translation variations not of interest.  
Several experiments have been conducted to ex-
amine the performance of the proposed approach. 
The experimental results have shown that the ap-
proach can generate effective translation equivalents 
of various terms ? especially for OOV terms such as 
proper nouns and technical names, which can be 
used to enrich general translation dictionaries. The 
results also revealed that the created translation lexi-
cons can reflect different cultural aspects across re-
gions such as Taiwan, Hong Kong and mainland 
China.  
In the rest of this paper, we review related work in 
translation extraction in Section 2. We present the 
transitive model and describe the direct translation 
process in Sections 3 and 4, respectively.  The con-
ducted experiments and their results are described in 
Section 5. Finally, in Section 6, some concluding re-
marks are given. 
2 Related Work 
In this section, we review some research in generat-
ing translation equivalents for automatic construc-
tion of translational lexicons. 
Transitive translation: Several transitive transla-
tion techniques have been developed to deal with the 
unreliable direct translation problem. Borin (2000) 
used various sources to improve the alignment of 
word translation and proposed the pivot alignment, 
which combined direct translation and indirect trans-
lation via a third language. Gollins et al (2001) pro-
posed a feasible method that translated terms in 
parallel across multiple intermediate languages to 
eliminate errors. In addition, Simard (2000) ex-
ploited the transitive properties of translations to 
improve the quality of multilingual text alignment. 
Corpus-based translation: To automatically con-
struct translation lexicons, conventional research in 
MT has generally used statistical techniques to ex-
tract translations from domain-specific sentence-
aligned parallel bilingual corpora. Kupiec (1993) 
attempted to find noun phrase correspondences in 
parallel corpora using part-of-speech tagging and 
noun phrase recognition methods. Smadja et al 
(1996) proposed a statistical association measure of 
the Dice coefficient to deal with the problem of col-
location translation. Melamed (2000) proposed sta-
tistical translation models to improve the techniques 
of word alignment by taking advantage of pre-
existing knowledge, which was more effective than 
a knowledge-free model. Although high accuracy of 
translation extraction can be easily achieved by these 
techniques, sufficiently large parallel corpora for
     
(a) Taiwan (Traditional Chinese)   (b)  Mainland China (Simplified Chinese) (c)  Hong Kong (Traditional Chinese) 
Figure 1: Examples of the search-result pages in different Chinese regions that were obtained via the English 
query term ?George Bush? from Google.
various subject domains and language pairs are not 
always available. 
Some attention has been devoted to automatic ex-
traction of term translations from comparable or 
even unrelated texts. Such methods encounter more 
difficulties due to the lack of parallel correlations 
aligned between documents or sentence pairs. Rapp 
(1999) utilized non-parallel corpora based on the 
assumption that the contexts of a term should be 
similar to the contexts of its translation in any lan-
guage pairs. Fung et al (1998) also proposed a simi-
lar approach that used a vector-space model and 
took a bilingual lexicon (called seed words) as a fea-
ture set to estimate the similarity between a word 
and its translation candidates. 
Web-based translation: Collecting parallel texts of 
different language versions from the Web has re-
cently received much attention (Kilgarriff et al, 
2003). Nie et al (1999) tried to automatically dis-
cover parallel Web documents. They assumed a Web 
page?s parents might contain the links to different 
versions of it and Web pages with the same content 
might have similar structures and lengths. Resnik 
(1999) addressed the issue of language identification 
for finding Web pages in the languages of interest. 
Yang et al (2003) presented an alignment method to 
identify one-to-one Chinese and English title pairs 
based on dynamic programming. These methods of-
ten require powerful crawlers to gather sufficient 
Web data, as well as more network bandwidth and 
storage. On the other hand, Cao et al (2002) used 
the Web to examine if the arbitrary combination of 
translations of a noun phrase was statistically impor-
tant. 
3 Construction of Translation Lexicons 
To construct translation lexicons with regional varia-
tions, we propose a transitive translation model 
Strans(s,t) to estimate the degree of possibility of the 
translation of a term s in one (source) language ls 
into a term t in another (target) language lt. Given 
the term s in ls, we first extract a set of terms C={tj}, 
where tj in lt acts as a translation candidate of s, from 
a corpus. In this case, the corpus consists of a set of 
search-result pages retrieved from search engines 
using term s as a query. Based on our previous work 
(Cheng et al, 2004), we can efficiently extract term 
tj by calculating the association measurement of 
every character or word n-gram in the corpus and 
applying the local maxima algorithm. The associa-
tion measurement is determined by the degree of 
cohesion holding the words together within a word n-
gram, and enhanced by examining if a word n-gram 
has complete lexical boundaries. Next, we rank the 
extracted candidates C as a list T in a decreasing or-
der by the model Strans(s,t) as the result.  
3.1 Bilingual Search-Result Pages 
The Web contains rich texts in a mixture of multiple 
languages and in different regions. For example, 
Chinese pages on the Web may be written in tradi-
tional or simplified Chinese as a principle language 
and in English as an auxiliary language. According 
to our observations, translated terms frequently oc-
cur together with a term in mixed-language texts. 
For example, Figure 1 illustrates the search-result 
pages of the English term ?George Bush,? which 
was submitted to Google for searching Chinese 
pages in different regions. In Figure 1 (a) it contains 
the translations ?????? (George Bush) and ??
?? (Bush) obtained from the pages in Taiwan. In 
Figures 1 (b) and (c) the term ?George Bush? is 
translated into ????(busir) or ????(buson) in 
mainland China and ????(busu) in Hong Kong. 
This characteristic of bilingual search-result pages is 
also useful for other language pairs such as other 
Asian languages mixed with English. 
For each term to be translated in one (source) 
language, we first submit it to a search engine for 
locating the bilingual Web documents containing the 
term and written in another (target) language from a 
specified region. The returned search-result pages 
containing snippets (illustrated in Figure 1), instead 
of the documents themselves, are collected as a cor-
pus from which translation candidates are extracted 
and correct translations are then selected. 
Compared with parallel corpora and anchor texts, 
bilingual search-result pages are easier to collect and 
can promptly reflect the dynamic content of the Web. 
In addition, geographic information about Web 
pages such as URLs also provides useful clues to the 
regions where translations appear. 
3.2 The Transitive Translation Model 
Transitive translation is particularly necessary for 
the translation of terms with regional variations be-
cause the variations seldom co-occur in the same 
bilingual pages. To estimate the possibility of being 
the translation t ?T of term s, the transitive transla-
tion model first performs so-called direct translation, 
which attempts to learn translational equivalents di-
rectly from the corpus. The direct translation method 
is simple, but strongly affected by the quality of the 
adopted corpus. (Detailed description of the direct 
translation method will be given in Section 4.) 
If the term s and its translation t appear infre-
quently, the statistical information obtained from the 
corpus might not be reliable. For example, a term in 
simplified Chinese, e.g. ??? (Internet) does not 
usually co-occur together with its variation in tradi-
tional Chinese, e.g. ????  (Internet). To deal 
with this problem, our idea is that the term s can be 
first translated into an intermediate translation m, 
which might co-occur with s, via a third (or interme-
diate) language lm. The correct translation t can then 
be extracted if it can be found as a translation of m. 
The transitive translation model, therefore, combines 
the processes of both direct translation and indirect 
translation, and is defined as: 
??
??
?
??=
>
=
?
"
otherwise ),(),(),(),(
 ),( if                                                ),,(
),(
mtmSmsStsS
tsStsS
tsS
directdirectindirect
directdirect
m
trans
v
q
where m is one of the top k most probable interme-
diate translations of s in language lm, and v is the 
confidence value of m?s accuracy, which can be es-
timated based on m?s probability of occurring in the 
corpus, and q is a predefined threshold value. 
3.3 The Competitive Linking Algorithm 
One major challenge of the transitive translation 
model is the propagation of translation errors. That 
is, incorrect m will significantly reduce the accuracy 
of the translation of s into t. A typical case is the 
indirect association problem (Melamed, 2000), as 
shown in Figure 2 in which we want to translate the 
term s1 (s=s1). Assume that t1 is s1?s corresponding 
translation, but appears infrequently with s1. An in-
direct association error might arise when t2, the 
translation of s1?s highly relevant term s2, co-occurs 
often with s1. This problem is very important for the 
situation in which translation is a many-to-many 
mapping. To reduce such errors and enhance the 
reliability of the estimation, a competitive linking 
algorithm, which is extended from Melamed?s work 
(Melamed, 2000), is developed to determine the 
most probable translations. 
Figure 2: An illustration of a bipartite graph. 
The idea of the algorithm is described below. For 
each translated term tj?T in lt, we translate it back 
into original language ls and then model the transla-
tion mappings as a bipartite graph, as shown in Fig-
ure 2, where the vertices on one side correspond to 
the terms {si} or {tj} in one language. An edge eij 
indicates the corresponding two terms si and tj might 
be the translations of each other, and is weighted by 
the sum of Sdirect(si,tj) and Sdirect(tj,si,). Based on the 
weighted values, we can examine if each translated 
term tj?T in lt can be correctly translated into the 
original term s1. If term tj has any translations better 
than term s1 in ls, term tj might be a so-called indirect 
association error and should be eliminated from T. In 
the above example, if the weight of e22 is larger than 
that of e12, the term ?Technology? will be not con-
sidered as the translation of ?????? (Internet). 
Finally, for all translated terms {tj} ? T that are not 
eliminated, we re-rank them by the weights of the 
edges {eij} and the top k ones are then taken as the 
translations. More detailed description of the algo-
rithm could be referred to Lu et al (2004). 
4 Direct Translation 
In this section, we will describe the details of the di-
rect translation process, i.e. the way to compute Sdi-
rect(s,t). Three methods will be presented to estimate 
the similarity between a source term and each of its 
translation candidates. Moreover, because the search-
result pages of the term might contain snippets that do 
not actually be written in the target language, we will 
introduce a filtering method to eliminate the transla-
tion variations not of interest. 
4.1 Translation Extraction 
The Chi-square Method: A number of statistical 
measures have been proposed for estimating term 
association based on co-occurrence analysis, includ-
ing mutual information, DICE coefficient, chi-square 
test, and log-likelihood ratio (Rapp, 1999).  Chi-
square test (?2) is adopted in our study because the 
required parameters for it can be obtained by submit-
Internet 
Technology 
???? (Internet) 
?? (Technology) 
??? (Browser) 
?? (Computer) 
?? (Information) 
t1 
t2 
s2 
eij 
s3 
s4 
s5 
s1 
ting Boolean queries to search engines and utilizing 
the returned page counts (number of pages). Given a 
term s and a translation candidate t, suppose the total 
number of Web pages is N; the number of pages con-
taining both s and t, n(s,t), is a; the number of pages 
containing s but not t, n(s,?t), is b; the number of 
pages containing t but not s, n(?s,t), is c; and the 
number of pages containing neither s nor t, n(?s, ?t), 
is d. (Although d is not provided by search engines, it 
can be computed by d=N-a-b-c.) Assume s and t are 
independent. Then, the expected frequency of (s,t), 
E(s,t), is (a+c)(a+b)/N; the expected frequency of 
(s,?t), E(s,?t), is (b+d)(a+b)/N; the expected fre-
quency of (?s,t), E(?s,t), is (a+c)(c+d)/N; and the ex-
pected frequency of (?s,?t), E(?s,?t), is (b+d)(c+d)/N.  
Hence, the conventional chi-square test can be com-
puted as: 
.)()()()(
)(
),(
)],(),([
) ,(
2
},{},,{
2
2
dcdbcaba
cbdaN
YXE
YXEYXn
tsS
ttYssX
direct
+?+?+?+
?-??=
-= ?
??"??"
c
 
Although the chi-square method is simple to com-
pute, it is more applicable to high-frequency terms 
than low-frequency terms since the former are more 
likely to appear with their candidates. Moreover, cer-
tain candidates that frequently co-occur with term s 
may not imply that they are appropriate translations. 
Thus, another method is presented. 
The Context-Vector Method: The basic idea of this 
method is that the term s?s translation equivalents 
may share common contextual terms with s in the 
search-result pages, similar to Rapp (1999). For both 
s and its candidates C, we take their contextual terms 
constituting the search-result pages as their features. 
The similarity between s and each candidate in C will 
be computed based on their feature vectors in the vec-
tor-space model. 
Herein, we adopt the conventional tf-idf weighting 
scheme to estimate the significance of features and 
define it as: 
 )log(),(max
),( n
N
ptf
ptfw
jj
i
ti ?= , 
where f(ti,p) is the frequency of term ti in search-result 
page p, N is the total number of Web pages, and n is 
the number of the pages containing ti. Finally, the 
similarity between term s and its translation candidate 
t can be estimated with the cosine measure, i.e. 
CV
directS (s,t)=cos(cvs, cvt), where cvs and cvt are the con-
text vectors of s and t, respectively. 
In the context-vector method, a low-frequency 
term still has a chance of extracting correct transla-
tions, if it shares common contexts with its transla-
tions in the search-result pages. Although the method 
provides an effective way to overcome the chi-square 
method?s problem, its performance depends heavily 
on the quality of the retrieved search-result pages, 
such as the sizes and amounts of snippets. Also, fea-
ture selection needs to be carefully handled in some 
cases. 
The Combined Method: The context-vector and chi-
square methods are basically complementary. Intui-
tively, a more complete solution is to integrate the 
two methods. Considering the various ranges of simi-
larity values between the two methods, we compute 
the similarity between term s and its translation can-
didate t by the weighted sum of 1/R?2(s,t) and 
1/RCV(s,t). R?2(s,t) (or RCV(s,t)) represents the similar-
ity ranking of each translation candidate t with respect 
to s and is assigned to be from 1 to k (number of out-
put) in decreasing order of similarity measure 
SX2direct(s,t) (or SCVdirect(s,t)). That is, if the similarity 
rankings of t are high in both of the context-vector 
and chi-square methods, it will be also ranked high in 
the combined method. 
4.2 Translation Filtering 
The direct translation process assumes that the re-
trieved search-result pages of a term exactly contain 
snippets from a certain region (e.g. Hong Kong) and 
written in the target language (e.g. traditional Chi-
nese). However, the assumption might not be reliable 
because the location (e.g. URL) of a Web page may 
not imply that it is written by the principle language 
used in that region. Also, we cannot identify the lan-
guage of a snippet simply using its character encoding 
scheme, because different regions may use the same 
character encoding schemes (e.g. Taiwan and Hong 
Kong mainly use the same traditional Chinese encod-
ing scheme).  
From previous work (Tsou et al, 2004) we know 
that word entropies significantly reflect language 
differences in Hong Kong, Taiwan and China. 
Herein, we propose another method for dealing with 
the above problem. Since our goal is trying to elimi-
nate the translation candidates {tj} that are not from 
the snippets in language lt, for each candidate tj we 
merge all of the snippets that contain tj into a docu-
ment and then identify the corresponding language of 
tj based on the document. We train a uni-gram lan-
guage model for each language of concern and per-
form language identification based on a 
discrimination function, which locates maximum 
character or word entropy and is defined as: 
??
?
??
?= ?
??
)|(ln)|(maxarg)(
)(
lwplwptlang
tjNwLl
j , 
where N(tj) is the collection of the snippets containing 
tj and L is a set of languages to be identified. The can-
didate tj will be eliminated if ?)( jtlang lt. 
To examine the feasibility of the proposed 
method in identifying Chinese in Taiwan, mainland 
China and Hong Kong, we conducted a preliminary 
experiment. To avoid the data sparseness of using a 
tri-gram language model, we simply use the above 
unigram model to perform language identification. 
Even so, the experimental result has shown that very 
high identification accuracy can be achieved. Some 
Web portals contain different versions for specific 
regions such as Yahoo! Taiwan (http://tw.yahoo. 
com) and Yahoo! Hong Kong (http://hk.yahoo.com). 
This allows us to collect regional training data for 
constructing language models. In the task of translat-
ing English terms into traditional Chinese in Taiwan, 
the extracted candidates for ?laser? contained ??
?? (translation of laser mainly used in Taiwan) and 
???? (translation of laser mainly used in mainland 
China). Based on the merged snippets, we found that 
???? had higher entropy value for the language 
model of mainland China while ???? had higher 
entropy value for the language models of Taiwan  
and Hong Kong.  
5 Performance Evaluation 
We conducted extensive experiments to examine the 
performance of the proposed approach. We obtained 
the search-result pages of a term by submitting it to 
the real-world search engines, including Google and 
Openfind (http://www.openfind.com.tw). Only the 
first 100 snippets received were used as the corpus.  
Performance Metric: The average top-n inclusion 
rate was adopted as a metric on the extraction of 
translation equivalents. For a set of terms to be trans-
lated, its top-n inclusion rate was defined as the per-
centage of the terms whose translations could be 
found in the first n extracted translations. The ex-
periments were categorized into direct translation and 
transitive translation. 
5.1 Direct Translation  
Data set: We collected English terms from two real-
world Chinese search engine logs in Taiwan, i.e. 
Dreamer (http://www.dreamer.com.tw) and GAIS 
(http://gais.cs.ccu.edu.tw). These English terms were 
potential ones in the Chinese logs that needed correct 
translations. The Dreamer log contained 228,566 
unique query terms from a period of over 3 months in 
1998, while the GAIS log contained 114,182 unique 
query terms from a period of two weeks in 1999. The 
collection contained a set of 430 frequent English 
terms, which were obtained from the 1,230 English 
terms out of the most popular 9,709 ones (with fre-
quencies above 10 in both logs). About 36% (156/430) 
of the collection could be found in the LDC (Linguis-
tic Data Consortium, http://www.ldc.upenn. 
edu/Projects/Chinese) English-to-Chinese lexicon 
with 120K entries, while about 64% (274/430) were 
not covered by the lexicon.  
English-to-Chinese Translation: In this experiment, 
we tried to directly translate the collected 430 English 
terms into traditional Chinese. Table 1 shows the re-
sults in terms of the top 1-5 inclusion rates for the 
translation of the collected English terms. ??2?, ?CV?, 
and ??2+CV? represent the methods based on the chi-
square, context-vector, and chi-square plus context-
vector methods, respectively. Although either the 
chi-square or context-vector method was effective, 
the method based on both of them (?2+CV) achieved 
the best performance in maximizing the inclusion 
rates in every case because they looked complemen-
tary. The proposed approach was found to be effec-
tive in finding translations of proper names, e.g. 
personal names ?Jordan? (?? , ?? ), ?Keanu 
Reeves? (????, ????), companies? names 
?TOYOTA? (??), ?EPSON? (???), and tech-
nical terms  ?EDI? (??????), ?Ethernet? (?
???), etc.  
English-to-Chinese Translation for Mainland 
China, Taiwan and Hong Kong: Chinese can be 
classified into simplified Chinese (SC) and tradi-
tional Chinese (TC) based on its writing form or 
character encoding scheme. SC is mainly used in 
mainland China while TC is mainly used in Taiwan 
and Hong Kong (HK). In this experiment, we further 
investigated the effectiveness of the proposed ap-
proach in English-to-Chinese translation for the 
three different regions. The collected 430 English 
terms were classified into five types: people, organi-
zation, place, computer and network, and others. 
Tables 2 and 3 show the statistical results and 
some examples, respectively. In Table 3, the number 
stands for a translated term?s ranking. The under-
lined terms were correct translations and the others 
were relevant translations. These translations might 
benefit the CLIR tasks, whose performance could be 
referred to our earlier work which emphasized on 
translating unknown queries (Cheng et al, 2004). The 
results in Table 2 show that the translations for 
mainland China and HK were not reliable enough in 
the top-1, compared with the translations for Taiwan. 
One possible reason was that the test terms were 
collected from Taiwan?s search engine logs. Most of 
them were popular in Taiwan but not in the others. 
Only 100 snippets retrieved might not balance or be 
sufficient for translation extraction. However, the 
inclusion rates for the three regions were close in the 
top-5. Observing the five types, we could find that 
type place containing the names of well-known 
countries and cities achieved the best performance in 
maximizing the inclusion rates in every case and al-
most had no regional variations (9%, 1/11) except 
 
 
 
 
 
 
 
 
Table 4: Inclusion rates of transitive translations of proper names and technical terms 
Type Source Language 
Target 
Language 
Intermediate 
Language Top-1 Top-3 Top5 
Chinese English None 70.0% 84.0% 86.0% 
English Japanese None 32.0% 56.0% 64.0% 
English Korean None 34.0% 58.0% 68.0% 
Chinese Japanese English 26.0% 40.0% 48.0% 
Scientist Name 
Chinese Korean English 30.0% 42.0% 50.0% 
Chinese English None 50.0% 74.0% 74.0% 
English Japanese None 38.0% 48.0% 62.0% 
English Korean None 30.0% 50.0% 58.0% 
Chinese Japanese English 32.0% 44.0% 50.0% 
Disease Name 
Chinese Korean English 24.0% 38.0% 44.0% 
 
that the city ?Sydney? was translated into ?? (Syd-
ney) in SC for mainland China and HK and ?? 
(Sydney) in TC for Taiwan. Type computer and 
network containing technical terms had the most 
regional variations (41%, 47/115) and type people 
had 36% (5/14). In general, the translations in the two 
types were adapted to the use in different regions. On 
the other hand, 10% (15/147) and 8% (12/143) of the 
translations in types organization and others, respec-
tively, had  regional variations, because most of the 
terms in type others were general terms such as 
?bank? and ?movies? and in type organization many 
local companies in Taiwan had no translation varia-
tions in mainland China and HK. 
Moreover, many translations in the types of peo-
ple, organization, and computer and network were 
quite different in Taiwan and mainland China such 
as the personal name ?Bred Pitt? was translated into 
????? in SC and ??????? in TC, the com-
pany name ?Ericsson? into ????? in SC and ??
??? in  TC, and the computer-related term ?EDI? 
into ???????? in SC and ???????? in 
TC. In general, the translations in HK had a higher 
chance to cover both of the translations in mainland 
China and Taiwan. 
5.2 Multilingual & Transitive Translation 
Table 1: Inclusion rates for Web query terms using various similarity measurements 
Dic OOV All Method Top-1 Top-3 Top-5 Top-1 Top-3 Top-5 Top-1 Top-3 Top-5 
?2 42.1% 57.9% 62.1% 40.2% 53.8% 56.2% 41.4% 56.3% 59.8% 
CV 51.7% 59.8% 62.5% 45.0% 55.6% 57.4% 49.1% 58.1% 60.5% 
?2+ CV 52.5% 60.4% 63.1% 46.1% 56.2% 58.0% 50.7% 58.8% 61.4% 
Table 2: Inclusion rates for different types of Web query terms  
Extracted Translations 
Taiwan (Big5) Mainland China (GB) Hong Kong (Big5) Type 
Top-1 Top-3 Top-5 Top-1 Top-3 Top-5 Top-1 Top-3 Top-5 
People (14) 57.1% 64.3% 64.3% 35.7% 57.1% 64.3% 21.4% 57.1% 57.1% 
Organization (147) 44.9% 55.1% 56.5% 47.6% 58.5% 62.6% 37.4% 46.3% 53.1% 
Place (11) 90.9% 90.9% 90.9% 63.6% 100.0% 100.0% 81.8%   81.8% 81.8% 
Computer & Network (115) 55.8% 59.3% 63.7% 32.7% 59.3% 64.6% 42.5% 65.5% 68.1% 
Others (143) 49.0%  58.7% 62.2% 30.8% 49.7% 58.7% 28.7% 50.3% 60.8% 
Total (430) 50.7% 58.8% 61.4% 38.1% 56.7% 62.8% 36.5% 54.0% 60.5% 
Table 3: Examples of extracted correct/relevant translations of English terms in three Chinese regions 
Extracted Correct or Relevant Target Translations English Terms 
Taiwan (Traditional Chinese) Mainland China (Simplified Chinese) Hong Kong (Traditional Chinese) 
Police ?? (1) ??? (2) ??? (4) ?? (1) ?? (2) ?? (4) ??? (1) ?? (3) ?? (5) 
Taxi ??? (1) ?? (3) ??? (1) ?? (4) ?? (1) ???? (2) ??? (15) 
Laser ?? (1) ???? (3) ???(4) ?? (1) ?? (2) ??? (3) ?? (4) ?? (1) ?? (2) ??? (3) ?? (4) 
Hacker ?? (1) ?? (2) ?? (7) ?? (1)  ???? (5) ??? (6) ?? (1) ?? (2) ??? (9) 
Database ??? (1) ????? (3)  ??? (1) ????? (9) ??? (1) ??? (3) ?? (5) 
Information ?? (1) ??  (3) ??? (4) ?? (1) ??? (3) ?? (7) ?? (1) ?? (6) 
Internet caf? ???? (3) ?? (4) ?? (5) ???? (1) ????? (2) ?? (6) ?? (1) ?? (3) ?? (4) 
Search Engine ??? (2) ???? (5) ?????? (1) ???? (3) ??? (1)  ??? (8) 
Digital Camera ?? (1) ???? (2) ???? (1) ???? (6) ?? (1) ???? (2) ?? (3) 
Data set: Since technical terms had the most region 
variations among the five types as mentioned in the 
previous subsection, we collected two other data sets 
for examining the performance of the proposed ap-
proach in multilingual and transitive translation. The 
data sets contained 50 scientists? names and 50 dis-
ease names in English, which were randomly se-
lected from 256 scientists (Science/People) and 664 
diseases (Health/Diseases) in the Yahoo! Directory 
(http://www.yahoo.com), respectively.  
English-to-Japanese/Korean Translation: In this 
experiment, the collected scientists? and disease 
names in English were translated into Japanese and 
Korean to examine if the proposed approach could 
be applicable to other Asian languages. As the result 
in Table 4 shows, for the English-to-Japanese trans-
lation, the top-1, top-3, and top-5 inclusion rates 
were 35%, 52%, and 63%, respectively; for the Eng-
lish-to-Korean translation, the top-1, top-3, and top-
5 inclusion rates were 32%, 54%, and 63%, respec-
tively, on average. 
Chinese-to-Japanese/Korean Translation via 
English: To further investigate if the proposed tran-
sitive approach can be applicable to other language 
pairs that are not frequently mixed in documents 
such as Chinese and Japanese (or Korean), we did 
transitive translation via English. In this experiment, 
we first manually translated the collected data sets in 
English into traditional Chinese and then did the 
Chinese-to-Japanese/Korean translation via the third 
language English. 
The results in Table 4 show that the propagation 
of translation errors reduced the translation accuracy. 
For example, the inclusion rates of the Chinese-to-
Japanese translation were lower than those of the 
English-to-Japanese translation since only 70%-86% 
inclusion rates were reached in the Chinese-to-
English translation in the top 1-5. Although transi-
tive translation might produce more noisy transla-
tions, it still produced acceptable translation 
candidates for human verification. In Table 4, 45%-
50% of the extracted top 5 Japanese or Korean terms 
might have correct translations. 
6 Conclusion 
It is important that the translation of a term can be 
automatically adapted to its usage in different dialec-
tal regions. We have proposed a Web-based transla-
tion approach that takes into account limited 
bilingual search-result pages from real search en-
gines as comparable corpora. The experimental re-
sults have shown the feasibility of the automatic 
approach in generation of effective translation 
equivalents of various terms and construction of 
multilingual translation lexicons that reflect regional 
translation variations. 
References 
L. Borin. 2000. You?ll take the high road and I?ll take the 
low road: using a third language to improve bilingual 
word alignment. In Proc. of COLING-2000, pp. 97-103. 
P. F. Brown, J. Cocke, S. A. D. Pietra, V. J. D. Pietra, F. 
Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. 
1990. A statistical approach to machine translation. 
Computational Linguistics, 16(2):79-85. 
Y.-B. Cao and H. Li. 2002. Base noun phrase translation 
using Web data the EM algorithm. In Proc. of 
COLING-2002, pp. 127-133. 
P.-J. Cheng, J.-W. Teng, R.-C. Chen, J.-H. Wang, W.-H. 
Lu, and L.-F. Chien. 2004. Translating unknown que-
ries with Web corpora for cross-language information 
retrieval. In Proc. of ACM SIGIR-2004. 
P. Fung and L. Y. Yee. 1998. An IR approach for translat-
ing new words from nonparallel, comparable texts. In 
Proc. of ACL-98, pp. 414-420.  
T. Gollins and M. Sanderson. 2001. Improving cross lan-
guage information with triangulated translation. In 
Proc. of ACM SIGIR-2001, pp. 90-95. 
J. Halpern. 2000. Lexicon-based orthographic disam-
biguation in CJK intelligent information retrieval. In 
Proc. of Workshop on Asian Language Resources and 
International Standardization.  
A. Kilgarriff and G. Grefenstette. 2003. Introduction to 
the special issue on the web as corpus. Computational 
Linguistics 29(3): 333-348. 
J. M. Kupiec. 1993. An algorithm for finding noun phrase 
correspondences in bilingual corpora. In Proc. of ACL-
93, pp. 17-22.  
W.-H. Lu, L.-F. Chien, and H.-J. Lee. 2004. Anchor text 
mining for translation of web queries: a transitive trans-
lation Approach. ACM TOIS 22(2): 242-269. 
W.-H. Lu, L.-F. Chien, and H.-J. Lee. 2002. Translation 
of Web queries using anchor text mining. ACM TALIP: 
159-172. 
I. D. Melamed. 2000. Models of translational equivalence 
among words. Computational Linguistics, 26(2): 221-
249. 
J.-Y. Nie, P. Isabelle, M. Simard, and R. Durand. 1999. 
Cross-language information retrieval based on parallel 
texts and automatic mining of parallel texts from the 
Web. In Proc. of ACM SIGIR-99, pp. 74-81. 
R. Rapp. 1999. Automatic identification of word transla-
tions from unrelated English and German corpora, In 
Proc. of ACL-99, pp. 519-526. 
P. Resnik. 1999. Mining the Web for bilingual text. In 
Proc. of ACL-99, pp. 527-534. 
M. Simard. 2000. Multilingual Text Alignment. In ?Paral-
lel Text Processing?, J. Veronis, ed., pages 49-67, 
Kluwer Academic Publishers, Netherlands. 
F. Smadja, K. McKeown, and V. Hatzivassiloglou. 1996. 
Translating collocations for bilingual lexicons: a statis-
tical approach. Computational Linguistics, 22(1): 1-38. 
B. K. Tsou, T. B. Y. Lai, and K. Chow. 2004. Comparing 
entropies within the Chinese language. In Proc. of 
IJCNLP-2004. 
C. C. Yang and K.-W. Li. 2003. Automatic construction 
of English/Chinese parallel corpora. JASIST 54(8): 
730-742. 
