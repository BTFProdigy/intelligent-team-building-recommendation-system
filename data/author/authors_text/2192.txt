A Representation for Complex and Evolving Data Dependencies 
in Generation 
C Me l l i sh  $, R Evans  t, L Cah i l l  t, C Doran  t, D Pa iva  t, M Reape $, D Scot t  t, N T ipper  t 
t Information Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UK 
SDivision of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UK 
rags@itri, brighton, ac. uk 
http :/www. itri. brighton, ac. uk/proj ect s/rags 
Abst rac t  
This paper introduces an approach to represent- 
ing the kinds of information that components 
in a natural language generation (NLG) sys- 
tem will need to communicate to one another. 
This information may be partial, may involve 
more than one level of analysis and may need 
to include information about the history of a 
derivation. We present a general representation 
scheme capable of handling these cases. In ad- 
dition, we make a proposal for organising inter- 
module communication i an NLG system by 
having a central server for this information. We 
have validated the approach by a reanalysis of 
an existing NLG system and through a full im- 
plementation of a runnable specification. 
1 In t roduct ion  
One of the distinctive properties of natural an- 
guage generation when compared with other 
language ngineering applications i that it has 
to take seriously the full range of linguistic rep- 
resentation, from concepts to morphology, or 
even phonetics. Any processing system is only 
as sophisticated as its input allows, so while a 
natural language understanding system might 
be judged primarily by its syntactic prowess, 
even if its attention to semantics, pragmatics 
and underlying conceptual analysis is minimal, 
a generation system is only as good as its deep- 
est linguistic representations. Moreover, any at- 
tempt to abstract away from individual gener- 
ation systems to a more generic architectural 
specification faces an even greater challenge: 
not only are complex linguistic representations 
required, able to support the dynamic evolu- 
tionary development of data during the gener- 
* Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran@mitre, org. 
ation process, but they must do so in a generic 
and flexible fashion. 
This paper describes a representation devel- 
oped to meet these requirements. It offers a 
formally well-defined eclarative representation 
language, which provides a framework for ex- 
pressing the complex and dynamic data require- 
ments of NLG systems. The approach supports 
different levels of representation, mixed repre- 
sentations that cut across levels, partial and 
shared structures and 'canned' representations, 
as well as dynamic relationships between data 
at different stages in processing. We are using 
the approach to develop a high level data model 
for NLG systems as part of a generic generation 
architecture called RAGS 1. 
The framework has been implemented in the 
form of a database server for modular genera- 
tion systems. As proof of concept of the frame- 
work, we have reimplemented an existing NLG 
system. The system we chose was the Caption 
Generation System (CGS) (Mittal et al, 1995; 
Mittal et al, 1998). The reimplementation in- 
volved defining the interfaces to the modules of 
CGS in terms of the RAGS representations and 
then implementing modules that had the requi- 
site input and output representations. 
Generation systems, especially end-to-end, 
applied generation systems, have, unsurpris- 
ingly, many things in common. Reiter (1994) 
proposed an analysis of such systems in terms 
of a simple three stage pipeline. More recently, 
the RAGS project attempted to repeat he anal- 
1This work is supported by ESPRC grants 
GR/L77041 (Edinburgh) and GR/L77102 (Brighton), 
RAGS: Reference Architecture for Generation Systems. 
We would also like to acknowledge the contribution of 
Jo Calder to the ideas and formalisation described in 
this paper. In particular, parts of this paper are based 
on (Calder et al, 1999). 
119 
ysis (Cahill et al, 1999a), but found that while 
most systems did implement a pipeline, they 
did not implement the same pipeline - different 
functionalities occurred in different places and 
different orders in different systems. In order 
to accommodate his result, we sought to de- 
velop an architecture that is more general than 
a simple pipeline, and thus supports the range 
of pipelines observed, as well as other more com- 
plex control regimes (see (Cahill et al, 1999a; 
Cahill et al, 1999b)). In this paper, we argue 
that supporting such an architecture requires 
careful consideration of the way data represen- 
tations interact and develop. Any formal frame- 
work for expressing the architecture must take 
account of this. 
2 The  representat iona l  requ i rements  
o f  generat ion  sys tems 
We noted in the introduction that generation 
systems have to deal with a range of linguis- 
tic information. It is natural, especially in the 
context of a generic architecture proposal, to 
model this breadth in terms of discrete layers 
of representation: (1999a) introduce layers such 
as conceptual, semantic, rhetorical, syntactic 
and document structure, but the precise demar- 
cation is not as important here as the princi- 
ple. The different kinds of information are typi- 
cally represented differently, and built up sepa- 
rately. However the layers are far from indepen- 
dent: objects at one layer are directly related to 
those at others, forming chains of dependency 
from conceptual through rhetorical and seman- 
tic structure to final syntactic and document re- 
alisation. This means that data resources, such 
as grammars and lexicons, and processing mod- 
ules in the system, are often defined in terms of 
mixed  data: structures that include informa- 
tion in more than one representation layer. So 
the ability to represent such mixed structures 
in a single formal framework is an important 
property of a generic data proposal. 
In addition, it is largely standard in gener- 
ation as elsewhere in language applications, to 
make extensive use of par t ia l  representations, 
often using a type system to capture grades of 
underspecification. An immediate corollary of 
providing support for partial structures is the 
notion that they may become further specified 
over time, that data structures evolve. If the 
framework seeks to avoid over-commitment to 
particular processing strategies it needs to pro- 
vide a way of representing such evolution ex- 
plicitly if required, rather than relying on de- 
structive modification of a structure. Related 
to this, it should provide explicit support for 
representing a l te rnat ive  specifications at any 
point. Finally, to fully support efficient pro- 
cessing across the range of applications, from 
the simple to the most complex, the represen- 
tation must allow for compact sharing of infor- 
mation in tang led  structures (two structures 
which share components). 
In addition to these direct requirements of the 
generation task itself, additional requirements 
arise from more general methodological consid- 
erations: we desire a representation that is for- 
mally well  def ined,  allows for theoretical rea-  
son ing about the data and performance of sys- 
tems, and supports control regimes from simple 
deterministic pipelines to complex parallel ar- 
chitectures. 
3 The  Representat ion  Scheme 
In this section, we present our proposal for a 
general representation scheme capable of cover- 
ing the above requirements. Our formulation is 
layered: the foundation is a simple, flexible, rig- 
orously defined graph representation formalism, 
on top of which we introduce notions of com- 
plex types and larger data structures and rela- 
tionships between them. This much is sufficient 
to capture the requirements just discussed. We 
suppose a yet higher level of specification could 
capture a more constraining data model but 
make no specific proposals about this here, how- 
ever the following sections use examples that do 
conform to such a higher level data model. 
The lowest level of the representation scheme 
is: 
? re lat iona l :  the basic data entity is x -~ y, 
an ar row representing a relation from ob- 
ject x to object y; 
? typed:  objects and arrows have an asso- 
ciated type system, so it is possible to de- 
fine classes and subclasses of objects and 
arrows. 
At the most fundamental level, this is more or 
less the whole definition. There is no commit- 
ment to what object or arrow types there are or 
120 
how they relate to each other. So a representa- 
tion allowed by the scheme consists of: 
? a set of objects, organised into types; 
? a set of binary relations, organised into 
types; 
? a set of arrows, each indicating that a rela- 
tion holds between one object and another 
object. 
Sets,  sequences  and  funct ions  
For the next level, we introduce more struc- 
ture in the type system to support sets, se- 
quences and functions. Objects are always 
atomic (though they can be of type set, se- 
quence or function) - it is not possible to make 
an object which actually is a set of two other 
objects (as you might with data structures in a 
computer program). To create a set, we intro- 
duce a set type for the object, and a set mem- 
bership arrow type (el), that links the set's el- 
ements to the set. Similarly, for a sequence, we 
introduce a sequence type and sequence mem- 
ber arrow types (1-el, 2-el, 3-el, . . .  ), and for a 
function, we have a complex type which spec- 
ifies the types of the arrows that make up the 
domain and the range of the function. 
SemRep 
~ fun(Role.SemRep) 
7 V show SemRep SemRep 
Figure 1: The partial semantic representation 
of "The second chart shows the number of days 
on the market" 
As an example, consider Figure 1, which 
shows a semantic representation (SemRep) from 
the CGS reimplementation. Here, the tree 
nodes correspond to objects, each labelled with 
its type. The root node is of type SemRep, and 
although it is not an explicit sequence type, we 
can see that it is a triple, as it has three sequence 
member arrows (with types 1-el, 2-el and 3-el). 
Its first arrow's target is an object of type DR 
(Discourse Referent). Its second represents a set 
of SemPred (Semantic Predicate) objects, and in 
this case there's just one, of type show. Its third 
element is a (partial) function, from Role arrow 
types (agent and affected are both subtypes of 
Role) to SemReps. (In this case, the SemReps 
have not yet been fully specified.) 
Local  and  non- loca l  a r rows  
The second extension to the basic representa- 
tion scheme is to distinguish two different ab- 
stract kinds of arrows - local and non-local. 
Fundamentally we are representing just a homo- 
geneous network of objects and relationships. In 
the example above we saw a network of arrows 
that we might want to view as a single data 
structure, and other major data types might 
similarly appear as networks. Additionally, we 
want to be able to express relationships between 
these larger 'structures' - between structures 
of the same type (alternative solutions, or re- 
vised versions) or of different ypes (semantic 
and syntactic for example). To capture these 
distinctions among arrows, we classify our ar- 
row types as local or non-local (we could do 
this in the type system itself, or leave it as an 
informal distinction). Local arrows are used to 
build up networks that we think of as single 
data structures. Non-local arrows express rela- 
tionships between such data structures. 
All the arrow types we saw above were local. 
Examples of non-local arrows might include: 
real ises These arro~vs link something more ab- 
stract to something less abstract hat re- 
alises it. Chains of realises arrows might 
lead from the original conceptual input to 
the generator through rhetorical, seman- 
tic and syntactic structures to the actual 
words that express the input. 
revises These arrows link a structure to an- 
other one of the same type, which is con- 
sidered to be a 'better' solution - perhaps 
because it is more instantiated. It is impor- 
tant to note that parts of larger structures 
can be revised without revising the entire 
structure. 
coreference These arrows link structures 
which are somehow "parallel" and which 
perhaps hare some substructure, i.e., tan- 
gled structures. For instance, document 
representations may be linked to rhetorical 
representations, either as whole isomorphic 
structures or at the level of individual con- 
stituents. 
121 
Notice that the representation scheme does 
not enforce any kind of well-formedness with 
respect o local and non-local arrows. In fact, 
although it is natural to think of a 'structure' as 
being a maximal network of local arrows with 
a single root object, there's no reason why this 
should be so - networks with multiple roots rep- 
resent tangled structures (structures that share 
content), networks that include non-local links 
might be mixed representations, containing in- 
formation of more than one sort. Such tech- 
niques might be useful for improving generator 
efficiency, or representing canned text or tem- 
plates, cf. (Calder et al, 1999). 
Par t ia l  and  Opaque s t ruc tures  
Partial structures are essential when a module 
needs to produce a skeleton of a representa- 
tion that it does not have the competence to 
completely fill out. For instance, lexical choice 
brings with it certain syntactic commitments, 
but in most NLG systems lexical choice occurs 
some time before a grammar is consulted to 
flesh out syntactic structure in detail. 
Figure 2: A partial structure 
By simply leaving out local arrows, we can 
represent a range of partial structures. Con- 
sider Fig. 2, where the triangles represent local 
structure, representing a sentence object and its 
component verb phrase. There is a link to a sub- 
ject noun phrase object, but none of the local 
arrows of the actual noun phrase are present. In 
subsequent processing this local structure might 
be filled in. This is possible as long as the noun 
phrase object has been declared to be of the 
right type. 
An opaque structure is one which has an in- 
complete derivational history - for example part 
of a syntactic structure without any correspond- 
ing semantic structure. Three possible reasons 
for having such structures are (a) to allow struc- 
ture to be introduced that the generator is not 
capable of producing directly, (b) to prevent he 
generator from interfering with the structure 
thus built (for example, by trying to modify an 
idiom in an inappropriate way), or (c) to im- 
prove generator efficiency by hiding detail that 
may lead to wasteful processing. An opaque 
structure is represented simply by the failure 
to include a rea l i ses  arrow to that structure. 
Such structures provide the basis for a gener- 
alised approach to "canning". 
4 Imp lementat ion  
There are many ways that modules in an 
NLG system could communicate information 
using the representation scheme just outlined. 
Here we describe a particularly general model 
of inter-module communication, based around 
modules communicating with a single cen- 
tralised repository of data called the whiteboard 
(Calder et al, 1999). A whiteboard is a cumu- 
lative typed relational blackboard: 
? t yped  and  re lat iona l :  because it is based 
on using the above representation scheme; 
? a b lackboard :  a control architec- 
ture and data store shared between 
processing modules; typically, modules 
add/change/remove objects in the data 
store, examine its contents, and/or ask to 
be notified of changes; 
? cumulat ive :  unlike standard blackboards, 
once data is added, it can't be changed or 
removed. So a structure is built incremen- 
tally by making successive copies of it (or of 
constituents of it) linked by rev ises  links 
(although actually, there's no constraint on 
the order in which they are built). 
A whiteboard allows modules to add ar- 
rows (typically forming networks through ar- 
rows sharing source or target objects), to in- 
spect the set of arrows looking for particular 
configurations of types, or to be informed when 
a particular type of arrow (or group of arrows) 
is added. 
The whiteboard is an active database server. 
This means that it runs as an independent pro- 
cess that other modules connect o by appropri- 
ate means. There are essentially three kinds of 
interaction that a module might have with the 
whiteboard server: 
? pub l i sh  - add an arrow or arrows to the 
whiteboard; 
122 
? query  - look for an arrow or arrows in the 
whiteboard; 
? wa i t  - register interest in an arrow or ar- 
rows appearing in the whiteboard. 
In both query and wait ,  arrows are specified 
by type, and with a hierarchical type system on 
objects and relations, this amounts to a pattern 
that matches arrows of subtypes as well. The 
wait  function allows the whiteboard to take the 
initiative in processing - if a module wai ts  on a 
query then the whiteboard waits until the query 
is satisfied, and then tells the module about it. 
So the module does not have to continuously 
scan the whiteboard for work to do, but can 
let the whiteboard tell it as soon as anything 
interesting happens. 
Typically a module will start up and regis- 
ter interest in the kind of arrow that represents 
the module's input data. It will then wait for 
the whiteboard to notify it of instances of that 
data (produced by other modules), and when- 
ever anything turns up, it processes it, adding 
its own results to the whiteboard. All the mod- 
ules do this asynchronously, and processing con- 
tinues until no module has any more work to 
do. This may sound like a recipe for confusion, 
but more standard pipelined behaviour is not 
much different. In fact, pipelining is exactly a 
data-based constraint - the second module in a 
pipeline does not start until the first one pro- 
duces its output. 
However, to be a strict pipeline, the first mod- 
ule must produce all of its output before the sec- 
ond one starts. This can be achieved simply by 
making the first module produce all its output 
at once, but sometimes that is not ideal - for ex- 
ample if the module is recursive and wishes to 
react to its own output. Alternative strategies 
include the use of markers in the whiteboard, 
so that modules can tell each other that they've 
finished processing (by adding a marker), or 
extending the whiteboard architecture itself so 
that modules can tell the whiteboard that they 
have finished processing, and other modules can 
wait for that to occur. 
5 Reconst ruct ion  o f  the  Capt ion  
Generat ion  System 
In order to prove this representation scheme 
in practice, we have implemented the white- 
board in Sicstus Prolog and used it to support 
data communications between modules in a re- 
construction of the Caption Generation System 
(Mittal et al, 1995). CGS is a system developed 
at the University of Pittsburgh, which takes in- 
put from the SAGE graphics presentation sys- 
tem (Roth et al, 1994) and generates captions 
for the graphics SAGE produces. We selected it 
for this effort because it appeared to be a fairly 
simple pipelined system, with modules perform- 
ing clearly defined linguistic tasks. As such, we 
thought it would be a good test case for our 
whiteboard specification. 
Although the CGS is organised as a pipeline, 
shown in Figure 3, the representations commu- 
nicated between the modules do not correspond 
to complete, separate instances of RAGS data- 
type representations. Instead, the representa- 
tions at the various levels accumulate along the 
pipeline or are revised in a way that does not 
correspond exactly to module boundaries. Fig- 
ure 3 gives a simple picture of how the different 
levels of representation build up. The labels for 
the RAGS representations refer to the following: 
? I = conceptual; 
? II -- semantic; 
? I I I  = rhetorical; 
? IV = document; 
? V = syntactic. 
For instance, some semantic (II) information is 
produced by the Text Planning module, and 
more work is done on this by Aggregation, but 
the semantic level of representation is not com- 
plete and final until the Referring Expression 
module has run. Also, for instance, at the 
point where the Ordering module has run, there 
are partially finished versions of three different 
types of representation. It is clear from this that 
the interfaces between the modules are more 
complex than could be accounted for by just re- 
ferring to the individual evels of representation 
of RAGS. The ability to express combinations of 
structures and partial structures was fundamen- 
tal to the reimplementation of CGS. We high- 
light below a few of the interesting places where 
these features were used. 
123 
AbsSemRep 
I-el ~ ~  .................................... SemRep 
--(~------~_set{KBPredl ~ fun(Role,set(KBId)) I-el ~3-e l  
. . . .  /X  . . . . . . . .  
el agent affected . . . .  DR fun(Role,set(SemRep)) ~i/  ~ ..... ~ el?set(SemPredi~t A ~ . ? 
nresent set(KSld) 0 . . . . . .  v ? ~--"- ................. / agen, /  \a\] Jec,ea 
el / \ el . . . . .  " . . . . . . . . . .  ~ ?J / "k~ present S~mRep SemRep 
chart1 chart2 
Figure 4: Combined Abstract Semantic Representation a d Concrete Semantic Representation for 
the output: "These two charts present information about house sales from data-set ts-1740" 
CG$ aroh i ta ,~ lu 'e  RAGS representat/on$ 
II I l l  IV ~' SAGE 
- -  . . . . . . . . . .  
tuning II 
- . . . . . . . . . .  
I1 I11 iV  
--' . . . . . . . . . .  
I\[ I11 IV 
. . . . . . . . . .  I ;11@ 
11 III I v  v 
. . . . . . . . .  
II I11 IV V 
. . . . . . . . .  III1  
II 111 IV V 
l - -  . . . . . . . . . .  I I I I I  
FUF 
Figure 3: A RAGS view of the CGS system 
5.1 Referr ing Express ion Generat ion  
In many NLG systems, (nominal) referring ex- 
pression generation is an operation that is in- 
voked at a relatively late stage, after the struc- 
ture of individual sentences i  fairly well speci- 
fied (at least semantically). However, referring 
expression generation eeds to go right back to 
the original world model/knowledge base to se- 
lect appropriate semantic ontent o realise a 
particular conceptual item as an NP (whereas 
all other content has been determined much ear- 
lier). In fact, there seems to be no place to 
put referring expression generation i a pipeline 
without there being some resulting awkward- 
ness. 
In RAGS, pointers to conceptual items can 
be included inside the first, "abstract", level of 
semantic representation (AbsSemRep), which is 
intended to correspond to an initial bundling of 
conceptual material under semantic predicates. 
On the other hand, the final, "concrete", level 
of semantic representation (SemRep) is more 
like a fully-fledged logical form and it is no 
longer appropriate for conceptual material to 
be included there. In the CGS reimplementa- 
tion, it is necessary for the Aggregation mod- 
ule to reason about the final high-level semantic 
representation f sentences, which means that 
this module must have access to "concrete" se- 
mantic representations. The Referring Expres- 
sion generation module does not run until later, 
which means that these representations cannot 
be complete. 
Our way around this was to ensure that the 
initial computation of concrete semantics from 
abstract semantics (done as part of Aggrega- 
tion here) left a record of the relationship by 
including realises arrows between correspond- 
ing structures. That computation could not be 
completed whenever it reached conceptual ma- 
terial - at that point it left a "hole" (an ob- 
ject with no further specification) in the con- 
crete semantic representation li ked back to the 
conceptual material. When referring expression 
was later invoked, by following the arrows in the 
124 
resulting mixed structure, it could tell exactly 
which conceptual entity needed to be referred 
to and where in the semantic structure the re- 
sulting semantic expression should be placed. 
Figure 4 shows the resulting arrangement for 
one example CGS sentence. The dashed lines 
indicate realises, i.e. non-local, arrows. 
5.2 Handling Centering Information 
The CGS Centering module reasons about the 
entities that will be referred to in each sentence 
and produces a representation which records the 
forward and backward-looking centers (Grosz et 
al., 1995). This representation is later used by 
the Referring Expression generation module in 
making pronominalisation decisions. This in- 
formation could potentially also be used in the 
Realisation module. 
Since Centering is not directly producing re- 
ferring expressions, its results have to sit around 
until they can actually be used. This posed 
a possible problem for us, because the RAGS 
framework does not provide a specific level of 
representation for Centering information and 
therefore seems on first sight unable to account 
for this information being communicated be- 
tween modules. The solution to the problem 
came when we realised that Centering informa- 
tion is in fact a kind of abstract syntactic in- 
formation. Although one might not expect ab- 
stract syntactic structure to be determined until 
the Realisation module (or perhaps lightly ear- 
lier), the CGS system starts this computation i
the Centering module. 
Thus in the reimplementation, the Centering 
module computes (very partial) abstract syn- 
tactic representations for the entities that will 
eventually be realised as NPs. These represen- 
tations basically just indicate the relevant Cen- 
tering statuses using syntactic features. Figure 
5 shows an example of the semantics for a typi- 
cal output sentence and the two partial abstract 
syntactic representations computed by the Cen- 
tering module for what will be the two NPs in 
that sentence 2. As before, dashed lines indicate 
realises arrows. Of course, given the discussion 
of the last section, the semantic representation 
objects that are the source of these arrows are in 
fact themselves linked back to conceptual enti- 
ties by being the destination of realises arrows 
2FVM = Feature Value Matrix. 
from them. 
When the Referring Expression generation 
module runs, it can recover the Centering infor- 
mation by inspecting the partial syntactic rep- 
resentations for the phrases it is supposed to 
generate. These partial representations are then 
further instantiated by, e.g., Lexical Choice at 
later stages of the pipeline. 
6 Conc lus ion  
The representation scheme we have proposed 
here is designed specifically to support he re- 
quirements of the current state-of-the-art NLG 
systems, and our pilot implementation demon- 
strates the practical applicability of the pro- 
posal. Tangled, partial and mixed structures 
are of obvious utility to any system with a flex- 
ible control strategy and we have shown here 
how the proposed representation scheme sup- 
ports them. By recording the derivational his- 
tory of computations, it also supports decisions 
which partly depend on earlier stages of the 
generation process (e.g., possibly, lexical choice) 
and revision-based architectures which typically 
make use of such information. We have shown 
how the representation scheme might be the ba- 
sis for an inter-module communication model, 
the whiteboard, which supports a wide range of 
processing strategies that require the represen- 
tation of complex and evolving data dependem 
cies. The fact that the whiteboard is cumula- 
tive, or monotonic in a logical sense, means that 
the whiteboard also supports reasoning about 
the behaviour of NLG systems implemented in 
terms of it. This is something that we would 
like to exploit directly in the future. 
The reimplementation f the CGS system 
in the RAGS framework was a challenge to 
the framework because it was a system that 
had already been developed completely inde- 
pendently. Even though we did not always un- 
derstand the detailed motivation for the struc- 
ture of CGS being as it was, within a short time 
we reconstructed a working system with mod- 
ules that corresponded closely to the original 
CGS modules. The representation scheme we 
have proposed here was a key ingredient in giv- 
ing us the flexibility to achieve the particular 
processing scheme used by CGS whilst remain- 
ing faithful to the (relatively simple) RAGS 
data model. 
125 
SemRep 
fun(Role,setlSemRep)) 
sl S " ' .  
t t ~ .  
2 AbsSynRep "~ AbsSynRep _(:5 ~ ,  
, , / \ \ 
ckward-looking-cemer ckward.looking-cenler 
+ + 
Figure 5: Arrangement of centering information for the output sentence above 
The representation scheme is useful in situa- 
tions where modules need to be defined and im- 
plemented to work with other modules, possibly 
developed by different people. In such cases, the 
representation scheme we propose permits pre- 
cise definition of the interfaces of the modules, 
even where they are not restricted to a single 
'level' of representation. Even though the con- 
trol structure of CGS is quite simple, we found 
that the use of a centralised whiteboard was use- 
ful in helping us to agree on interfaces and on 
the exact contribution that each module should 
be making. Ultimately, it is hoped that the use 
of a scheme of this type will permit much more 
widespread 'plug-and-play' among members of 
the NLG community. 
Re ferences  
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999a. In Search of a Reference 
Architecture for NLG Systems. In Proceedings of 
the 7th European Workshop on Natural Language 
Generation, pages 77-85, Toulouse. 
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999b. Towards a Reference 
Architecture for Natural Language Genera- 
tion Systems. Technical Report ITRI-99-14, 
Information Technology Research Institute 
(ITRI), University of Brighton. Available at 
http://www, i t r i  .brighton. ac. uk/proj ects/rags.  
Jo Calder, Roger Evans, Chris Mellish, and Mike 
Reape. 1999. "Free choice" and templates: how 
to get both at the same time. In "May I speak 
freely?" Between templates and free choice in nat- 
ural language generation, number D-99-01, pages 
19-24. Saarbriicken. 
B.J. Grosz, A.K. Joshi, and S. Weinstein. 1995. 
Centering: a framework for modelling the local co- 
herence of discourse. Computational Linguistics, 
21 (2):203-226. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and 
G. Carenini. 1995. Generating explanatory cap- 
tions for information graphics. In Proceedings of 
the 15th International Joint Conference on Ar- 
tificial Intelligence (IJCAI'95), pages 1276-1283, 
Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 
1998. Describing complex charts in natural lan- 
guage: A caption generation system. Computa- 
tional Linguistics, 24(3):431-468. 
Ehud Reiter. 1994. Has a consensus NL generation 
architecture appeared and is it psycholinguisti- 
cally plausible? In Proceedings of the Seventh In- 
ternational Workshop on Natural Language Gen- 
eration, pages 163-170, Kennebunkport, Maine. 
Steven F. Roth, John Kolojejchick, Joe Mattis, and 
Jade Goldstein. 1994. Interactive graphic design 
using automatic presentation knowledge. In Pro- 
ceedings of CHI'9~: Human Factors in Computing 
Systems, Boston, MA. 
126 
203
204
205
206
211
212
213
214
From RAGS to RICHES: exploiting the potential of a flexible generation
architecture  
Lynne Cahill  , John Carroll  , Roger Evans  , Daniel Paiva  ,
Richard Power

, Donia Scott  and Kees van Deemter 

ITRI, University of Brighton
Brighton, BN2 4GJ, UK
Firstname.Lastname@itri.bton.ac.uk
 School of Cognitive and Computing Sciences, University of Sussex
Brighton, BN1 9QH, UK
johnca@cogs.susx.ac.uk
Abstract
The RAGS proposals for generic speci-
fication of NLG systems includes a de-
tailed account of data representation,
but only an outline view of processing
aspects. In this paper we introduce a
modular processing architecture with a
concrete implementation which aims to
meet the RAGS goals of transparency
and reusability. We illustrate the model
with the RICHES system ? a generation
system built from simple linguistically-
motivated modules.
1 Introduction
As part of the RAGS (Reference Architecture for
Generation Systems) project, Mellish et al(2000)
introduces a framework for the representation of
data in NLG systems, the RAGS ?data model?.
This model offers a formally well-defined declar-
ative representation language, which supports the
complex and dynamic data requirements of gen-
eration systems, e.g. different levels of repre-
sentation (conceptual to syntax), mixed represen-
tations that cut across levels, partial and shared
structures and ?canned? representations. However

We would like to acknowledge the financial support of
the EPSRC (RAGS ? Reference Architecture for Generation
Systems: grant GR/L77102 to Donia Scott), as well as the
intellectual contribution of our partners at Edinburgh (Chris
Mellish and Mike Reape: grant GR/L77041 to Mellish) and
other colleagues at the ITRI, especially Nedjet Bouayad-
Agha. We would also like to acknowledge the contribution
of colleagues who worked on the RICHES system previ-
ously: Neil Tipper and Rodger Kibble. We are grateful to
our anonymous referees for their helpful comments.
RAGS, as described in that paper, says very little
about the functional structure of an NLG system,
or the issues arising from more complex process-
ing regimes (see for example Robin (1994), Inuie
et al, (1992) for further discussion).
NLG systems, especially end-to-end, applied
NLG systems, have many functionalities in com-
mon. Reiter (1994) proposed an analysis of such
systems in terms of a simple three stage pipeline.
More recently Cahill et al(1999) attempted to re-
peat the analysis, but found that while most sys-
tems did implement a pipeline, they did not im-
plement the same pipeline ? different functional-
ities occurred in different ways and different or-
ders in different systems. But this survey did
identify a number of core functionalities which
seem to occur during the execution of most sys-
tems. In order to accommodate this result, a ?pro-
cess model? was sketched which aimed to support
both pipelines and more complex control regimes
in a flexible but structured way (see (Cahill et al,
1999),(RAGS, 2000)). In this paper, we describe
our attempts to test these ideas in a simple NLG
application that is based on a concrete realisation
of such an architecture1 .
The RAGS data model aims to promote com-
parability and re-usability in the NLG research
community, as well as insight into the organisa-
tion and processing of linguistic data in NLG. The
present work has similar goals for the processing
aspects: to propose a general approach to organis-
ing whole NLG systems in a way which promotes
1More details about the RAGS project, the
RICHES implementation and the OASYS subsys-
tem can be found at the RAGS project web site:
http://www.itri.bton.ac.uk/projects/rags.
the same ideals. In addition, we aim to test the
claims that the RAGS data model approach sup-
ports the flexible processing of information in an
NLG setting.
2 The RAGS data model
The starting point for our work here is the RAGS
data model as presented in Mellish et al(2000).
This model distinguishes the following five levels
of data representation that underpin the genera-
tion process:
Rhetorical representations (RhetReps) define how propo-
sitions within a text are related. For example, the sen-
tence ?Blow your nose, so that it is clear? can be con-
sidered to consist of two propositions: BLOW YOUR
NOSE and YOUR NOSE IS CLEAR, connected by a re-
lation like MOTIVATION.
Document representations (DocReps) encode information
about the physical layout of a document, such as tex-
tual level (paragraph, orthographic sentence, etc.),
layout (indentation, bullet lists etc.) and their relative
positions.
Semantic representations (SemReps) specify information
about the meaning of individual propositions. For
each proposition, this includes the predicate and its
arguments, as well as links to underlying domain ob-
jects and scoping information.
Syntactic representations (SynReps) define ?abstract?
syntactic information such as lexical features (FORM,
ROOT etc.) and syntactic arguments and adjuncts
(SUBJECT, OBJECT etc.).
Quote representations These are used to represent literal
unanalysed content used by a generator, such as
canned text, pictures or tables.
The representations aim to cover the core com-
mon requirements of NLG systems, while avoid-
ing over-commitment on less clearly agreed is-
sues relating to conceptual representation on the
one hand and concrete syntax and document ren-
dering on the other. When one considers process-
ing aspects, however, the picture tends to be a lot
less tidy: typical modules in real NLG systems
often manipulate data at several levels at once,
building structures incrementally, and often work-
ing with ?mixed? structures, which include infor-
mation from more than one level. Furthermore
this characteristic remains even when one consid-
ers more purely functionally-motivated ?abstract?
NLG modules. For example, Referring Expres-
sion Generation, commonly viewed as a single
task, needs to have access to at least rhetorical and
document information as well as referencing and
adding to the syntactic information.
To accommodate this, the RAGS data model in-
cludes a more concrete representational proposal,
called the ?whiteboard? (Calder et al, 1999), in
which all the data levels can be represented in
a common framework consisting of networks of
typed ?objects? connected by typed ?arrows?. This
lingua franca allows NLG modules to manipulate
data flexibly and consistently. It also facilitates
modular design of NLG systems, and reusability
of modules and data sets. However, it does not in
itself say anything about how modules in such a
system might interact.
This paper describes a concrete realisation of
the RAGS object and arrows model, OASYS,
as applied to a simple but flexible NLG system
called RICHES. This is not the first such re-
alisation: Cahill et al, (2000) describes a par-
tial re-implementation of the ?Caption Generation
System? (Mittal et al, 1999) which includes an
objects and arrows ?whiteboard?. The OASYS
system includes more specific proposals for pro-
cessing and inter-module communication, and
RICHES demonstrates how this can be used to
support a modular architecture based on small
scale functionally-motivated units.
3 OASYS
OASYS (Objects and Arrows SYStem) is a soft-
ware library which provides:
  an implementation of the RAGS Object and
Arrows (O/A) data representation,
  support for representing the five-layer RAGS
data model in O/A terms,
  an event-driven active database server for
O/A representations.
Together these components provide a central core
for RAGS-style NLG applications, allowing sepa-
rate parts of NLG functionality to be specified in
independent modules, which communicate exclu-
sively via the OASYS server.
The O/A data representation is a simple
typed network representation language. An O/A
database consists of a collection of objects, each
of which has a unique identifier and a type, and
arrows, each of which has a unique identifier,
a type, and source and target objects. Such a
database can be viewed as a (possibly discon-
nected) directed network representation: the fig-
ures in section 5 give examples of such networks.
OASYS pre-defines object and arrow types re-
quired to support the RAGS data model. Two ar-
row types, el (element) and el(<integer>),
are used to build up basic network structures ?
el identifies its target as a member of the set rep-
resented by its source, el(3), identifies its tar-
get as the third element of the tuple represented
by its source. Arrow type realised by re-
lates structures at different levels of representa-
tion. for example, indicating that this SemRep
object is realised by this SynRep object. Arrow
type revised to provides for support for non-
destructive modification of a structure, mapping
from an object to another of the same type that
can be viewed as a revision of it. Arrow type
refers to allows an object at one level to indi-
rectly refer to an object at a different level. Object
types correspond to the types of the RAGS data
model, and are either atomic, tuples, sets or se-
quences. For example, document structures are
built out of DocRep (a 2-tuple), DocAttr (a set
of DocFeatAtoms ? feature-value pairs), DocRe-
pSeq (a sequence of DocReps or DocLeafs) and
DocLeafs.
The active database server supports multiple
independent O/A databases. Individual modules
of an application publish and retrieve objects and
arrows on databases, incrementally building the
?higher level?, data structures. Modules com-
municate by accessing a shared database. Flow
of control in the application is event-based: the
OASYS module has the central thread of execu-
tion, calls to OASYS generate ?events?, and mod-
ules are implemented as event handlers. A mod-
ule registers interest in particular kinds of events,
and when those events occur, the module?s hander
is called to deal with them, which typically will
involve inspecting the database and adding more
structure (which generates further events).
OASYS supports three kinds of events: pub-
lish events occur whenever an object or arrow is
published in a database, module lifecycle events
occur whenever a new module starts up or termi-
nates, and synthetic events ? arbitrary messages
passed between the modules, but not interpreted
by OASYS itself ? may be generated by mod-
ules at any time. An application starts up by ini-
tialising all its modules. This generates initialise
events, which at least one module must respond
to, generating further events which other modules
may respond to, and so on, until no new events
are generated, at which point OASYS generates
finalise events for all the modules and terminates
them.
This framework supports a wide range of archi-
tectural possibilities. Publish events can be used
to make a module wake up whenever data of a
particular sort becomes available for processing.
Lifecycle events provide, among other things, an
easy way to do pipelining: the second module in a
pipeline waits for the finalise event of the first and
then starts processing, the third waits similarly
for the second to finalise etc. Synthetic events
allow modules to tell each other more explicitly
that some data is ready for processing, in situa-
tion where simple publication of an object is not
enough.
RICHES includes examples of all three
regimes: the first three modules are pipelined us-
ing lifecycle events; LC and RE, FLO and REND
interact using synthetic events; while SF watches
the database specifically for publication events.
4 RICHES
The RICHES system is a simple generation sys-
tem that takes as input rhetorical plans and pro-
duces patient advice texts. The texts are intended
to resemble those found at the PharmWeb site
(http://www.pharmweb.net). These are
simple instructional texts telling patients how to
use certain types of medicines, such as nosedrops,
eye drops, suppositories etc.. An example text
from PharmWeb is shown in figure 1, alongside
the corresponding text produced by RICHES.
The main aim of RICHES is to demonstrate
the feasibility of a system based on both the RAGS
data model and the OASYS server model. The
modules collectively construct and access the data
representations in a shared blackboard space and
this allows the modules to be defined in terms of
their functional role, rather than say, the kind of
data they manipulate or their position in a pro-
cessing pipeline. Each of the modules in the sys-
 How to Use Nose Drops
1. Blow your nose gently, so that it is clear. 
  
2. Wash your hands. 
  
3. Unscrew the top of the bottle and draw some liquid into the dropper. 
  
4. Tilt your head back. 
  
5. Hold the dropper just above your nose and put the correct number of drops into your nostril. 
  
6. DO NOT let the dropper touch the inside of your nose. 
  
7. Keep your head tilted back for two to three minutes to help the drops run to the back of your nose. 
  
8. Replace the top on the bottle. 
 
KEEP ALL MEDICINES OUT OF THE REACH OF CHILDREN 
PharmWeb - Copyright?1994-2001. All rights reserved
  
  
Blow your nose so that it is clear. 
Wash your hands
Unscrew the top. Then draw the liquid into the dropper. 
Tilt your head back
Hold the dropper above your nose. Then put the drops into your nostril.
The dropper must not touch the inside.
Keep your head tilted back for two to three minutes so that the drops run to the back.
Replace the top on the bottle
Generated by RICHES version 1.0 (9/5/2001) on 9/5/2001 
?2001, ITRI, University of Brighton 
Figure 1: An example text from PharmWeb, together with the corresponding text generated by RICHES
tem is in itself very simple ? our primary interest
here is in the way they interact.
Figure 2 shows the structure of the system2.
The functionality of the individual modules is
briefly described below.
Rhetorical Oracle (RO) The input to the sys-
tem is a RhetRep of the document to be gen-
erated: a tree with internal nodes labelled with
(RST-style) rhetorical relations and RhetLeaves
referring to semantic proposition representations
(SemReps). RO simply accesses such a represen-
tation from a data file and initialises the OASYS
database.
Media Selection (MS) RICHES produces doc-
uments that may include pictures as well as text.
As soon as the RhetRep becomes available, this
module examines it and decides what can be il-
lustrated and what picture should illustrate it. Pic-
2The dashed lines indicate flow of information, solid ar-
rows indicate approximately flow of control between mod-
ules, double boxes indicate a completely reused module
(from another system), while a double box with a dashed
outer indicates a module partially reused. Ellipses indicate
information sources, as opposed to processing modules.
tures, annotated with their SemReps, are part of
the picture library, and Media Selection builds
small pieces of DocRep referencing the pictures.
Document Planner (DP) The Document Plan-
ner, based on the ICONOCLAST text planner
(Power, 2000) takes the input RhetRep and pro-
duces a document structure (DocRep). This
specifies aspects such as the text-level (e.g.,
paragraph, sentence) and the relative or-
dering of propositions in the DocRep. Its
leaves refer to SynReps corresponding to syntac-
tic phrases. This module is pipelined after MS,
to make sure that it takes account of any pictures
that have been included in the document.
Lexical Choice (LC) Lexical choice happens in
two stages. In the first stage, LC chooses the lex-
ical items for the predicate of each SynRep. This
fixes the basic syntactic structure of the proposi-
tion, and the valency mapping between semantic
and syntactic arguments. At this point the ba-
sic document structure is complete, and the LC
advises REND and SF that they can start pro-
cessing. LC then goes into a second phase, in-
TEXT
SENTENCE
RHETORICAL 
ORACLE
LEXICAL
FINALISER
RENDERER
LINGO
PICTURE
LIBRARY
SELECTION
MEDIUM FLO
LEXICON
CHOICE
OASYS
REFERRING
EXPRESSIONS
DOCUMENT
PLANNER
Figure 2: The structure of the RICHES system
terleaved with RE and FLO: for each sentence,
RE determines the referring expressions for each
noun phrase, LC then lexicalises them, and when
the sentence is complete FLO invokes LinGO to
realise them.
Referring Expressions (RE) The Referring
Expression module adapts the SynReps to add in-
formation about the form of a noun phrase. It de-
cides whether it should be a pronoun, a definite
noun phrase or an indefinite noun phrase.
Sentence Finaliser (SF) The Sentence Fi-
naliser carries out high level sentential organisa-
tion. LC and RE together build individual syntac-
tic phrases, but do not combine them into whole
sentences. SF uses rhetorical and document struc-
ture information to decide how to complete the
syntactic representations, for example, combin-
ing main and subordinate clauses. In addition, SF
decides whether a sentence should be imperative,
depending on who the reader of the document is
(an input parameter to the system).
Finalise Lexical Output (FLO) RICHES uses
an external sentence realiser component with its
own non-RAGS input specification. FLO provides
the interface to this realiser, extracting (mostly
syntactic) information from OASYS and convert-
ing it to the appropriate form for the realiser. Cur-
rently, FLO supports the LinGO realiser (Carroll
et al, 1999), but we are also looking at FLO mod-
ules for RealPro (Lavoie and Rambow, 1997) and
FUF/SURGE (Elhadad et al, 1997).
Renderer (REND) The Renderer is the module
that puts the concrete document together. Guided
by the document structure, it produces HTML for-
matting for the text and positions and references
the pictures. Individual sentences are produced
for it by LinGO, via the FLO interface. FLO actu-
ally processes sentences independently of REND,
so when REND makes a request, either the sen-
tence is there already, or the request is queued,
and serviced when it becomes available.
LinGO The LinGO realiser uses a wide-
coverage grammar of English in the LKB HPSG
framework, (Copestake and Flickinger, 2000).
The tactical generation component accepts in-
put in the Minimal Recursion Semantics formal-
ism and produces the target text using a chart-
driven algorithm with an optimised treatment of
modification (Carroll et al, 1999). No domain-
specific tuning of the grammar was required for
the RICHES system, only a few additions to the
lexicon were necessary.
5 An example: generation in RICHES
In this section we show how RICHES generates
the first sentence of the example text, Blow your
nose so that it is clear and the picture that accom-
panies the text.
The system starts with a rhetorical represen-
tation (RhetRep) provided by the RO (see Fig-
ure 3)3. The first active module to run is MS
3In the figures, labels indicate object types and the sub-
script numbers are identifiers provided by OASYS for each
which traverses the RhetRep looking at the se-
mantic propositions labelling the RhetRep leaves,
to see if any can be illustrated by pictures in the
picture library. Each picture in the library is en-
coded with a semantic representation. Matching
between propositions and pictures is based on the
algorithm presented in Van Deemter (1999) which
selects the most informative picture whose repre-
sentation contains nothing that is not contained in
the proposition. For each picture that will be in-
cluded, a leaf node of document representation is
created and a realised by arrow is added to it
from the semantic proposition object (see Figure
4).
  	


  



el(1) el(2)
  		
(motivation)
  	ffWysiwym with wider coverage
Richard Power and Roger Evans
Information Technology Research Institute
University of Brighton
Lewes Road
Brighton BN2 4AT, UK
Firstname.Lastname@itri.bton.ac.uk
Abstract
We describe an extension of the Wysiwym
technology for knowledge editing through nat-
ural language feedback. Previous applications
have addressed relatively simple tasks requiring
a very limited range of nominal and clause pat-
terns. We show that by adding a further editing
operation called reconfiguration, the technology
can achieve a far wider coverage more in line
with other general-purpose generators. The ex-
tension will be included in a Java-based library
package for producing Wysiwym applications.
1 Introduction
Wysiwym (What You See Is What You Meant)
is a user-interface technology through which a
domain expert can formally encode knowledge
by structured editing of an automatically gener-
ated feedback text (Power and Scott, 1998). The
technology has hitherto addressed two practical
contexts: the automatic production of multilin-
gual technical documentation, and the formula-
tion of queries to a database or expert system.
In the first case, Wysiwym editing encodes the
desired content of the document in an interlin-
gua, from which versions can be generated in
mutliple languages; in the second case, it yields
a query encoded in a formal query language such
as SQL. The benefit is the same in either con-
text: since editing is mediated through a presen-
tation in natural language, there is no need for
the user to be acquainted with the formal details
of knowledge representation or query languages.
Elsewhere (Evans and Power, 2003) we have
described a library package for developing
Wysiwym applications. This package was a
consolidation of work carried out in a series of
early applications (Power and Scott, 1998; Pi-
wek et al, 2000; Bouayad-Agha et al, 2002),
requiring a very restricted linguistic coverage,
especially as regards the range of clausal and
nominal patterns. We present here an exten-
sion to this library which allows a coverage
more in line with general-purpose generators
like FUF/SURGE (Elhadad and Robin, 1992),
KPML/PENMAN (Bateman, 1996) and Real-
Pro (Lavoie and Rambow, 1997). The exten-
sion is based on two new ideas: first, a change
to the underlying semantic model, replacing
atomic entity types with feature structures; sec-
ondly, a corresponding change in the user inter-
face, which now offers an extra editing operation
(called reconfiguration) through which complex
entity types may be modified. The purpose of
this paper (and the accompanying demonstra-
tion) is to describe these novelties.
2 Editing with simple types
take
patient
aspirin
ARG?1
ARG?2
Figure 1: A-box with simple types
In early Wysiwym applications, the editing
process served to build an A-box like that shown
in figure 1, comprising a set of entities (repre-
sented by rectangles), each entity having a sim-
ple type (represented by labels within rectan-
gles) and a set of relationships (represented by
labelled arcs). The graph in this figure is rooted
in a take entity, denoting a taking event, the
participants being a patient entity (the taker)
and an an aspirin entity (the takee). The in-
tended meaning of the graph is expressed by the
English sentence ?the patient takes an aspirin?.
The construction of the graph through Wysi-
wym editing proceeds as follows. The starting
point is an empty A-box, which consists only
in a constraint on the root entity ? for in-
stance, the requirement that it should be some
kind of event. This unpromising A-box is sup-
plied as input to a natural language generator
with two special features: (a) it can generate
texts from an A-box in any state of completion
(even empty); (b) it can generate menus open-
ing on anchors within the text, in addition to
the text itself. The resulting feedback text is
presented to the user through a special interface
in which some spans are mouse-sensitive an-
chors, marking points where a new entity may
be added to the A-box. Anchors are normally
shown through a colour code; here we will em-
ploy square brackets:
[Some event].
When the user mouse-clicks on an anchor, a
menu pops up listing all entity types allowed
in the relevant context ? in this case, all event
types.
arrive
breathe
. . .
take
. . .
After the user chooses one of these options, such
as ?take?, a new entity of the specified type is
created, and added to the A-box at the current
location (in this case, the root of the graph). As-
suming the ontology decrees that a take event
has two participants, a person and an object,
the new A-box will include two anchors allow-
ing these entities to be defined:
[Some person] takes [some object].
Opening the anchor ?some person? will yield a
list of options including ?patient?; opening ?some
object? will yield options including ?an aspirin?;
in this way two more entities can be introduced,
so obtaining the complete graph in figure 1.
3 Limitations in coverage
For some applications, the above procedure
works well, but it allows far too few variations to
cope with real documents or queries of normal
linguistic complexity. A single choice of event
type (?take?) is assumed by default to imply just
one out of the thousands of possible clause pat-
terns that could be obtained by varying mood,
tense, polarity, modality, etc., or by adding ad-
verbial modifiers:
force
does the patient take an aspirin?
take an aspirin
time
the patient took an aspirin
the patient will take an aspirin
polarity
the patient does not take an aspirin
modality
the patient may take an aspirin
the patient must take an aspirin
the patient might take an aspirin
the patient should take an aspirin
modifier
the patient takes an aspirin [at some time]
the patient takes an aspirin [somewhere]
the patient takes an aspirin [in some manner]
the patient takes an aspirin [with some frequency]
By combining just the above features, we ob-
tain over 300 combinations; these would mul-
tiply further if we included the semantic fea-
tures controlling perfective, progressive, voice,
and wh-questions. Such a large set of options
challenges the feasibility of Wysiwym, or in-
deed any other approach to knowledge editing
by domain experts.
4 Editing with complex types
Our favoured (indeed, only) proposal for em-
bracing these variations is based on an analogy
with a drawing tool. In Wysiwym, choosing
take from a menu of event types introduces
an event entity, implicitly defaulted to present
time, positive polarity, and so forth. In a draw-
ing tool, choosing the rectangle icon from a
palette of shapes introduces a rectangle entity,
implicitly defaulted to a certain size, colour, and
border (to name just three features). Having
introduced a rectangle entity, however, the user
can reconfigure it by changing these features one
at a time. Why should an equivalent operation
not be provided for the semantic features un-
derlying a clause?
take
TIME  present
POLARITY  positive
MODALITY  undef
ARG?1
ARG?2
MULTIPLICITY  single
IDENTIFIABILITY  unidentifiable
aspirin
patient
MULTIPLICITY  single
IDENTIFIABILITY  identifiable
Figure 2: A-box with complex types
To add this extra editing operation we must
replace the simple entity types employed in
early Wysiwym systems by complex types, as
illustrated in figure 2 (to simplify, just a few of
the possible features are shown). To reconfig-
ure an entity, the user selects the corresponding
span in the feedback text (all such spans will be
mouse-sensitive), and chooses from a menu of
options, each corresponding to a change in just
one feature.
With this potentially huge increase in the
number of editing operations for a given feed-
back text, the idea of precomputing all possi-
ble menus and popping one up on demand be-
comes less attractive, both computationally and
to the user. Instead, when the user selects a
span of text, the menu of reconfigurations for
that span is computed on the fly, and displayed
in a static menu pane adjacent to the main text
pane, which can be browsed and searched - see
figure 3. At every stage during the interaction,
the user sees a feedback text (right pane), with
one span highlighted through a colour code, and
a list of options for reconfiguring the currently
selected unit (left pane). If the selected unit
happens to be an anchor (square brackets), the
operation will be one of choosing an initial en-
tity type rather than reconfiguring an existing
one, but the appearance of the interface will be
the same. The user can continue the interaction
in two ways: either by choosing an option from
the menu pane, or by selecting a different cur-
rent unit by mouse-clicking within the feedback
text pane.
To illustrate, we will suppose that the current
A-box is as depicted in figure 2, and that the
?patient? entity is currently selected. Highlight-
ing the selected span in bold face rather than a
colour code, the feedback text and the menu of
reconfiguration options might be as follows:
The patient takes an aspirin.
identifiability
A patient
multiplicity
The patients
The labels (identifiability etc.) could of
course be replaced by more familiar words (e.g.,
article, number). Assuming that the user is
happy with the subject of the sentence, he/she
will ignore the reconfiguration options and in-
stead click around the word ?takes? in the feed-
back text, so selecting the whole event entity:
The patient takes an aspirin.
polarity
The patient does not take an aspirin.
time
The patient took an aspirin.
The patient will take an aspirin.
modality
The patient must take an aspirin.
The patient may take an aspirin.
The patient might take an aspirin.
If the first reconfiguration option is chosen, set-
ting polarity to negative, the revised options
will conserve this new value throughout, except
for the new polarity option, which will now be
to change the value back to positive:
The patient does not take an aspirin.
polarity
The patient takes an aspirin.
time
The patient did not take an aspirin.
The patient will not take an aspirin.
modality
The patient must not take an aspirin.
The patient may not take an aspirin.
The patient might not take an aspirin.
Figure 3 also shows the use of tags in the feed-
back text, such as Leaflet, Section, Paragraph.
These provide anchor points to select and re-
configure linguistic units which have no exclu-
sive text of their own. Such tags would not form
part of the final output text in a document au-
thoring scenario.
5 Benefits of the approach
These techniques make it possible to construct
complex, fluent and expressive texts using a
point-and-click interface, with no typing of text.
The benefits of previous Wysiwym systems are
also retained here: the text is guaranteed to
have a coherent internal representation which
can be constrained to conform to a controlled
language or house style specification, or gener-
ated (and edited) in a different language. The
internal representation can be used to monitor
the document content, for example to provide
authoring support, or it can be transformed into
an alternative representation for further pro-
cessing.
Although the motivation for this extension
was to provide effective support for document
authoring, the underlying model offers addi-
tional functionality in other knowledge creation
scenarios as well. The examples in this paper
use the complex types of the knowledge objects
to represent linguistic variation, but might just
Figure 3: Snapshot of application
as easily represent other kinds of semantic de-
tail, for example in an object-oriented program
specifciation scenario.
6 Conclusion
In this paper we have described an extension to
our earlier Wysiwym approach which supports
more sophisticated interactions with the under-
lying knowledge base, allowing a far wider range
of linguistic expressions to be constructed. This
makes the system more suitable for real author-
ing tasks, particularly in controlled language
or multilingual contexts, while also enhancing
its potential for constructing and editing other
kinds of complex knowledge.
The system has been implemented as an ex-
tension to our Wysiwym library (Evans and
Power, 2003), using a wide-coverage grammar
based on the subcategorisation frames found in
the XTAG (Doran et al, 1994) categories, and
deployed in the domain of medical informatics.
The demonstration requires a PC with Java and
Sicstus Prolog.
References
John A. Bateman. 1996. KPML: The komet-
Penman (Multilingual) Development Envi-
ronment. Technical report, Institut fu?r In-
tegrierte Publikations- und Informationssys-
teme (IPSI), GMD, Darmstadt, March. Re-
lease 0.9.
Nadjet Bouayad-Agha, Richard Power, Donia
Scott, and Anja Belz. 2002. PILLS: Multilin-
gual generation of medical information docu-
ments with overlapping content. In Proceed-
ings of the Third International Conference on
Language Resoures and Evaluation (LREC
2002), pages 2111?2114, Las Palmas.
Christy Doran, Dania Egedi, Beth Ann Hockey,
B. Srinivas, and Martin Zaidel. 1994. XTAG
system - a wide coverage grammar for english.
In Proceedings of the 15th International Con-
ference on Computational Linguistics (COL-
ING 94), pages 922?928, Kyoto, Japan.
Michael Elhadad and Jacques Robin. 1992.
Controlling content realization with func-
tional unification grammars. In Aspects
of Automated Natural Language Generation,
pages 89?104. Springer Verlag.
Roger Evans and Richard Power. 2003. Wysi-
wym: Building user interfaces with natu-
ral language feedback. In Research notes
and demonstration papers at EACL-03, pages
203?206, Budapest, Hungary.
B. Lavoie and O. Rambow. 1997. RealPro: A
fast, portable sentence realizer. In Proceed-
ings of the Conference on Applied Natural
Language Processing (ANLP?97), Washing-
ton, DC.
Paul Piwek, Roger Evans, Lynne Cahill, and
Neil Tipper. 2000. Natural language genera-
tion in the mile system. In Proceedings of the
IMPACTS in NLG Workshop, pages 33?42,
Schloss Dagstuhl, Germany.
R. Power and D. Scott. 1998. Multilingual au-
thoring using feedback texts. In Proceedings
of the 17th International Conference on Com-
putational Linguistics and 36th Annual Meet-
ing of the Association for Computational Lin-
guistics, pages 1053?1059, Montreal, Canada.
Proceedings of the 43rd Annual Meeting of the ACL, pages 58?65,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Empirically-based Control of Natural Language Generation 
 
Daniel S. Paiva Roger Evans 
Department of Informatics Information Technology Research Institute 
University of Sussex University of Brighton 
Brighton, UK Brighton, UK 
danielpa@sussex.ac.uk Roger.Evans@itri.brighton.ac.uk 
 
Abstract 
In this paper we present a new approach to 
controlling the behaviour of a natural lan-
guage generation system by correlating in-
ternal decisions taken during free generation 
of a wide range of texts with the surface sty-
listic characteristics of the resulting outputs, 
and using the correlation to control the gen-
erator. This contrasts with the generate-and-
test architecture adopted by most previous 
empirically-based generation approaches, 
offering a more efficient, generic and holis-
tic method of generator control. We illus-
trate the approach by describing a system in 
which stylistic variation (in the sense of 
Biber (1988)) can be effectively controlled 
during the generation of short medical in-
formation texts.  
1 Introduction 
This paper1 is concerned with the problem of con-
trolling the output of natural language generation 
(NLG) systems. In many application scenarios the 
generator?s task is underspecified, resulting in mul-
tiple possible solutions (texts expressing the de-
sired content), all equally good to the generator, 
but not equally appropriate for the application. 
Customising the generator directly to overcome 
this generally leads to ad-hoc, non-reusable solu-
tions. A more modular approach is a generate-and-
test architecture, in which all solutions are gener-
ated, and then ranked or otherwise selected accord-
ing to their appropriateness in a separate post-
                                                          
1
  Paiva and Evans (2004) provides an overview of our 
framework and detailed comparison with previous 
approaches to stylistic control (like Hovy (1988), 
Green and DiMarco (1993) and Langkilde-Geary 
(2002)). This paper provides a more detailed account 
of the system and reports additional experimental re-
sults. 
process. Such architectures have been particularly 
prominent in the recent development of empiri-
cally-based approaches to NLG, where generator 
outputs can be selected according to application 
requirements acquired directly from human sub-
jects (e.g.  Walker et al (2002)) or statistically 
from a corpus (e.g. Langkilde-Geary (2002)). 
However, this approach suffers from a number of 
drawbacks: 
1. It requires generation of all, or at least 
many solutions (often hundreds of thou-
sands), expensive both in time and space, 
and liable to lead to unnecessary interac-
tions with other components (e.g. knowl-
edge bases) in complex systems. Recent 
advances in the use of packed representa-
tions ameliorate some of these issues, but 
the basic need to compare a large number 
of solutions in order to rank them remains. 
2. The ?test? component generally does not 
give fine-grained control ? for example, 
in a statistically-based system it typically 
measures how close a text is to some sin-
gle notion of ideal (actually, statistically 
average) output. 
3. Use of an external filter does not combine 
well with any control mechanisms within 
the generator: e.g. controlling combinato-
rial explosion of modifier attachment or 
adjective order. 
In this paper we present an empirically-based 
method for controlling a generator which over-
comes these deficiencies. It controls the generator 
internally, so that it can produce just one (locally) 
optimal solution; it employs a model of language 
variation, so that the generator can be controlled 
within a multidimensional space of possible vari-
ants; its view of the generator is completely holis-
tic, so that it can accommodate any other control 
mechanisms intrinsic to the generation task.  
58
To illustrate our approach we describe a system 
for controlling ?style? in the sense of Biber (1988) 
during the generation of short texts giving instruc-
tions about doses of medicine. The paper continues 
as follows. In ?2 we describe our overall approach. 
We then present the implemented system (?3) and 
report on our experimental evaluation (?4). We end 
with a discussion of conclusions and future direc-
tions (?5). 
2 Overview of the Approach 
Our overall approach has two phases: (1) offline 
calculation of the control parameters, and 
(2) online application to generation. In the first 
phase we determine a set of correlation equations, 
which capture the relationship between surface 
linguistic features of generated texts and the inter-
nal generator decisions that gave rise to those texts 
(see figure 1). In the second phase, these correla-
tions are used to guide the generator to produce 
texts with particular surface feature characteristics 
(see figure 2).  
 
corpus 
linguistic 
features 
factor 
analysis 
variation 
dimensions 
NLG 
system 
text 
CP2 
CP1 
CPn 
variation 
scores  
variation 
model 
correlation 
analysis 
correlation 
equations 
?
 
generator 
decisions 
at different 
choice 
points 
input 
 
Figure 1: Offline processing  
The starting point is a corpus of texts which 
represents all the variability that we wish to cap-
ture. Counts for (surface) linguistic features from 
the texts in the corpus are obtained, and a factor 
analysis is used to establish dimensions of varia-
tion in terms of these counts: each dimension is 
defined by a weighted sum of scores for particular 
features, and factor analysis determines the combi-
nation that best accounts for the variability across 
the whole corpus. This provides a language varia-
tion model which can be used to score a new text 
along each of the identified dimensions, that is, to 
locate the text in the variation space determined by 
the corpus. 
The next step is to take a generator which can 
generate across the range of variation in the cor-
pus, and identify within it the key choice points 
(CP1, CP2, ? CPn) in its generation of a text. We 
then allow the generator to freely generate all pos-
sible texts from one or more inputs. For each text 
so generated we record (a) the text?s score accord-
ing to the variation model and (b) the set of deci-
sions made at each of the selected choice points in 
the generator. Finally, for a random sample of the 
generated texts, a statistical correlation analysis is 
undertaken between the scores and the correspond-
ing generator decisions, resulting in correlation 
equations which predict likely variation scores 
from generator decisions. 
 
NLG 
system 
text in 
specified 
style 
CP2 
CP1 
CPn 
correlation 
equations 
?
 
target 
variation 
score 
input 
 
Figure 2: Online processing 
In the second phase, the generator is adapted to 
use the correlation equations to conduct a best-first 
search of the generation space. As well as the usual 
input, the generator is supplied with target scores 
for each dimension of variation. At each choice 
point, the correlation equations are used to predict 
which choice is most likely to move closer to the 
target score for the final text. 
This basic architecture makes no commitment to  
what is meant by ?variation?, ?linguistic features?, 
?generator choice points?, or even ?NLG system?. 
The key ideas are that a statistical analysis of sur-
face features of a corpus of texts can be used to 
define a model of variation; this model can then be 
used to control a generator; and the model can also 
be used to evaluate the generator?s performance. In 
the next section we describe a concrete instantia-
tion of this architecture, in which ?variation? is sty-
listic variation as characterised by a collection of 
shallow lexical and syntactic features. 
3 An Implemented System 
In order to evaluate the effectiveness of this gen-
eral approach, we implemented a system which 
attempts to control style of text generated as de-
59
fined by Biber (1988) in short text (typically 2-3 
sentences) describing medicine dosage instruc-
tions. 
3.1 Factor Analysis 
Biber characterised style in terms of very shallow 
linguistic features, such as presence of pronouns, 
auxiliaries, passives etc. By using factor analysis 
techniques he was able to determine complex cor-
relations between the occurrence and non-
occurrence of such features in text, which he used 
to characterise different styles of text.2  
We adopted the same basic methodology, ap-
plied to a smaller more consistent corpus of just 
over 300 texts taken from proprietary patient in-
formation leaflets. Starting with around 70 surface 
linguistic features as variables, our factor analysis 
yielded two main factors (each containing linguis-
tic features grouped in positive and negative corre-
lated subgroups) which we used as our dimensions 
of variation. We interpreted these dimensions as 
follows (this is a subjective process ? factor 
analysis does not itself provide any interpretation 
of factors): dimension 1 ranges from texts that try 
to involve the reader (high positive score) to text 
that try to be distant from the reader (high negative 
score); dimension 2 ranges from texts with more 
pronominal reference and a higher proportion of 
certain verbal forms (high positive score) to text 
that use full nominal reference (high negative 
score).3 
3.2 Generator Architecture 
The generator was constructed from a mixture of 
existing components and new implementation, us-
ing a fairly standard overall architecture as shown 
in figure 3. Here, dotted lines show the control 
flow and the straight lines show data flow ? the 
choice point annotations are described below. 
The input constructor takes an input specifica-
tion and, using a background database of medicine 
information, creates a network of concepts and re-
                                                          
2
 Some authors (e.g. Lee (1999)) have criticised Biber 
for making assumptions about the validity and gener-
alisability of his approach to English language as a 
whole. Here, however, we use his methodology to 
characterise whatever variation exists without need-
ing to make any broader claims. 
3
  Full details of the factor analysis can be found in 
(Paiva 2000). 
lations (see figure 4) using a schema-based ap-
proach (McKeown, 1985).  
input 
constructor 
split 
network 
network 
ordering 
referring 
expression 
NP pruning 
realiser 
initial input networks 
sentence-size networks 
subnetwork chosen 
referring expression net 
pruned network 
sentence 
input 
specification 
choice 
point 1: 
number of 
sentences 
choice 
point 2: 
type of 
referring 
expression 
choice 
point 3: 
choice of 
mapping 
rule 
 
Figure 3: Generator architecture with choice points 
Each network is then split into subnetworks by 
the split network module. This partitions the net-
work by locating ?proposition? objects (marked 
with a double-lined box in figure 4) which have no 
parent and tracing the subnetwork reachable from 
each one. We call these subnetworks propnets. In 
figure 4, there are two propnets, rooted in [1:take] 
and [9:state] ? proposition [15:state] is not a root 
as it can be reached from [1:take]. A list of all pos-
sible groupings of these propnets is obtained4, and 
one of the possible combinations is passed to the 
network ordering module. This is the first source 
of non-determinism in our system, marked as 
choice point one in figure 3. A combination of 
subnetworks will be material for the realisation of 
one paragraph and each subnetwork will be real-
ised as one sentence. 
                                                          
4
  For instance, with three propnets (A, B and C) the list 
of combinations would be [(A,B,C), (A,BC), (AB, C), 
(AC,B), (ABC)]. 
60
 2:patient 1:take 
3:medicine 
12:freq 
15:state 
13:value(2xday) 
4:pres 
7:dose 
9:state 
8:value(2gram) 
10:pres 
14:pres 
arg0 arg1 
6:of 
11:of 
arg0 arg0 
arg0 
arg0 
arg0 
arg0 
arg1 
arg1 
tense 
tense 
tense 
freq 
5:patient 
proxy 
 
Figure 4: Example of semantic network produced by the 
input constructor5 
The network ordering module receives a combi-
nation of subnetworks and orders them based on 
the number of common elements between each 
subnetwork. The strategy is to try to maximise the 
possibility of having a smooth transition from one 
sentence to the next in accordance with Centering 
Theory (Grosz et al, 1995), and so increase the 
possibility of having a pronoun generated. 
The referring expression module receives one 
subnetwork at a time and decides, for each object 
that is of type [thing], which type of referring ex-
pression will be generated. The module is re-used 
from the Riches system (Cahill et al, 2001) and it 
generates either a definite description or a pronoun. 
This is the second source of non-determinism in 
our system, marked as choice point two in figure 3. 
Referring expression decisions are recorded by 
introducing additional nodes into the network, as 
shown for example in figure 5 (a fragment of the 
network in figure 4, with the additional nodes). 
NP pruning is responsible for erasing from a re-
ferring expression subnetwork all the nodes that 
can be transitively reached from a node marked to 
be pronominalised. This prevents the realiser from 
trying to express the information twice. In figure 5, 
[7:dose] is marked to be pronominalised, so the 
concepts [11:of] and [3:medicine] do not need to be 
realised, so they are pruned. 
                                                          
5
 Although some of the labels in this figure look like 
words, they bear no direct relation to words in the 
surface text ? for example, ?of? may be realised as a 
genitive construction or a possessive.  
3:medicine 
7:dose 
11:of 
arg0 
arg0 
21:pronoun refexp 
22:definite refexp 
 
Figure 5: Referring expressions and pruning 
The realiser is a re-implementation of Nicolov?s 
(1999) generator, extended to use the wide-
coverage lexicalised grammar developed in the 
LEXSYS project (Carroll et al, 2000), with further 
semantic extensions for the present system. It se-
lects grammar rules by matching their semantic 
patterns to subnetworks of the input, and tries to 
generate a sentence consuming the whole input. In 
general there are several rules linking each piece of 
semantics to its possible realisation, so this is our 
third, and most prolific, source of non-determinism 
in the architecture, marked as choice point three in 
figure 3. 
A few examples of outputs for the input repre-
sented in figure 4 are: 
the dose of the patient 's medicine is taken twice a 
day. it is two grams. 
the two-gram dose of the patient 's medicine is 
taken twice a day. 
the patient takes the two-gram dose of the patient 's 
medicine twice a day. 
From a typical input corresponding to 2-3 sen-
tences, this generator will generate over a 1000 
different texts. 
3.3 Tracing Generator Behaviour 
In order to control the generator?s behaviour we 
first allow it to run freely, recording a ?trace? of the 
decisions it makes at each choice point during the 
production of each text. Although there are only 
three choice points in figure 3, the control structure 
included two loops: an outer loop which ranges 
over the sequence of propnets, generating a sen-
tence for each one, and an inner loop which ranges 
over subnetworks of a propnet as realisation rules 
are chosen. So the decision structure for even a 
small text may be quite complex.  
In the experiments reported here, the trace of the 
generation process is simply a record of the num-
ber of times each decision (choice point, and what 
choice was made) occurred. Paiva (2004) discusses 
more complex tracing models, where the context of 
each decision (for example, what the preceding 
decision was) is recorded and used in the correla-
tion. However the best results were obtained using 
61
just the simple decision-counting model (perhaps 
in part due to data sparseness for more complex 
models). 
3.4 Correlating Decisions with Text Features 
By allowing the generator to freely generate all 
possible output from a single input, we recorded a 
set of <trace, text> pairs ranging across the full 
variation space. From these pairs we derived corre-
sponding <decision-count, factor-score> pairs, to 
which we applied a very simple correlational tech-
nique, multivariate linear regression analysis, 
which is used to find an estimator function for a 
linear relationship (i.e., one that can be approxi-
mated by a straight line) from the data available for 
several variables (Weisberg, 1985).  In our case we 
want to predict the value for a score in a stylistic 
dimension (SSi) based on a configuration of gen-
erator decisions (GDj) as seen in equation 1.  
(eq. 1) SSi = x0 + x1GD1 + ? + xnGDn + ? 6 
We used three randomly sampled data sets of 
1400, 1400 and 5000 observations obtained from a 
potential base of about 1,400,000 different texts 
that could be produced by our generator from a 
single input. With each sample, we obtained a re-
gression equation for each stylistic dimension 
separately. In the next subsections we will present 
the final results for each of the dimensions sepa-
rately. 
Regression on Stylistic Dimension 1 
For the regression model on the first stylistic di-
mension (SS1), the generator decisions that were 
used in the regression analysis7 are: imperative 
with one object sentences (IMP_VNP), V_NP_PP 
agentless passive sentences (PAS_VNPP), V_NP by-
passives (BYPAS_VN), and N_PP clauses (NPP) and 
these are all decisions that happen in the realiser, 
i.e., at the third choice point in the architecture. 
This resulted in the regression equation shown in 
equation 2.  
                                                          
6
 SSi represents a stylistic score and is the dependent 
variable or criterion in the regression analysis; the 
GDj?s represent generator decisions and are called the 
independent variables or predictors; the xj?s are 
weights, and ? is the error. 
7
 The process of determining the regression takes care 
of eliminating the variables (i.e. generator decisions) 
that are not useful to estimate the stylistic dimensions. 
(eq. 2)  
SS1 = 6.459 ? (1.460?NPP) ? (1.273*BYPAS_VN) 
 ? (1.826?PAS_VNPP) + (1.200?IMP_VNP)8 
The coefficients for the regression on SS1 are 
unstandardised coefficients, i.e. the ones that are 
used when dealing with raw counts for the genera-
tor decisions.  
The coefficient of determination (R2), which 
measures the proportion of the variance of the de-
pendent variable about its mean that is explained 
by the independent variables, had a reasonably 
high value (.895)9 and the analysis of variance ob-
tained an F test of 1701.495. 
One of the assumptions that this technique as-
sumes is the linearity of the relation between the 
dependent and the independent variables (i.e., in 
our case, between the stylistic scores in a dimen-
sion and the generator decisions). The analysis of 
the residuals resulted in a graph that had some 
problems but that resembled a normal graph (see 
(Paiva, 2004) for more details). 
Regression on Stylistic Dimension 2 
For the regression model on the second stylistic 
dimension (SS2) the variables that we used were: 
the number of times a network was split (SPLIT-
NET), generation of a pronoun (RE_PRON), auxil-
iary verb (VAUX), noun with determiner (NOUN), 
transitive verb (VNP), and agentless passive 
(PAS_VNP) ? the first type of decision happens in 
the split network module (our first choice point); 
the second, in the referring expression module 
(second choice point); and the rest in the realiser 
(third choice point).  
The main results for this model are as follows: 
the coefficient of determination (R2) was .959 and 
the analysis of variance obtained an F test 
of 2298.519. The unstandardised regression coeffi-
cients for this model can be seen in eq. 3.  
(eq. 3) 
SS2 = ? 27.208 ? (1.530?VNP) + (2.002?RE_PRON) 
 ? (.547?NOUN) + (.356?VAUX) 
 + (.860?SPLITNET) + (.213?PAS_VNP)10 
                                                          
8
  This specific equation came from the sample with 
5,000 observations ? the equations obtained from 
the other samples are very similar to this one. 
9
  All the statistical results presented in this paper are 
significant at the 0.01 level (two-tailed). 
10
 This specific equation comes from one of the samples 
of 1,400 observations. 
62
With this second model we did not find any prob-
lems with the linearity assumptions as the analysis 
of the residuals gave a normal graph. 
4 Controlling the Generator 
These regression equations characterise the way in 
which generator decisions influence the final style 
of the text (as measured by the stylistic factors). In 
order to control the generator, the user specifies a 
target stylistic score for each dimension of the text 
to be generated. At each choice point during gen-
eration, all possible decisions are collected in a list 
and the regression equations are used to order 
them. The equations allow us to estimate the sub-
sequent values of SS1 and SS2 for each of the pos-
sible decisions, and the decisions are ordered 
according to the distance of the resulting scores 
from the target scores ? the closer the score, the 
better the decision.  
Hence the search algorithm that we are using 
here is the best-first search, i.e., the best local solu-
tion according to an evaluation function (which in 
this case is the Euclidian distance from the target 
and the resulted value obtained by using the re-
gression equation) is tried first but all the other 
local solutions are kept in order so backtracking is 
possible. 
In this paper we report on tests of two internal 
aspects of the system11. First we wish to know how 
good the generator is at hitting a user-specified 
target ? i.e., how close are the scores given by the 
regression equations for the first text generated to 
the user?s input target scores. Second, we wish to 
know how good the regression equation scores are 
at modelling the original stylistic factors ? i.e., we 
want to compare the regression scores of an output 
text with the factor analysis scores. We address 
these questions across the whole of the two-
dimensional stylistic space, by specifying a rectan-
gular grid of scores spanning the whole space, and 
asking the generator to produce texts for each grid 
point from the same semantic input specification. 
                                                          
11
  We are not dealing with external (user) evaluation of 
the system and of the stylistic dimensions we ob-
tained ? this was left for future work. Nonetheless, 
Sigley (1997) showed that the dimensions obtained 
with factor analysis and people?s perception have a 
high correlation. 
-25-30-35-40-45
10
8
6
4
2
0
-2
-4
-6
-8
-10
80797877767574737271
70696867666564636261
60595857565554535251
50494847464544434241
40393837363534333231
30292827262524232221
20191817161514131211
10987654321
 
Figure 6: Target scores for the texts 
In this case we divided the scoring space with 
an 8 by 10 grid pattern as shown in figure 6.12 Each 
point specifies the target scores for each text that 
should be generated (the number next to each point 
is an identifier of each text). For instance, text 
number 1 was targeted at coordinate (?7, ?44), 
whereas text number 79 was targeted at coordinate 
(+7, ?28). 
4.1 Comparing Target Points and Regression 
Scores 
In the first part of this experiment we wanted to 
know how close to the user-specified target coor-
dinates the resulting regression scores of the first 
generated text were. This can be done in two dif-
ferent ways. The first is to plot the resulting regres-
sion scores (see figure 7) and visually check if it 
mirrors the grid-shape pattern of the target points 
(figure 6) ? this can be done by inspecting the text 
identifiers13. This can be a bit misleading because 
there will always be variation around the target 
point that was supposed to be achieved (i.e., there 
is a margin for error) and this can blur the com-
parison unfavourably.  
                                                          
12
 The range for each scale comes from the maximum 
and minimum values for the factors obtained in the 
samples of generated texts. 
13
 Note that some texts obtained the same regression 
score and, in the statistical package, only one was 
numbered. Those instances are: 1 and 7; 18 and 24; 
22 and 28. 
63
-25-30-35-40-45
10
8
6
4
2
0
-2
-4
-6
-8
-10
80797877767574372
70
6968
6766
6564636261
6059
5857
56555453
5251
5049
48
47
4645
444342
41
4039
3837
363543332
31
3029282726
25
24
2322
21
20
1918
17
1615
1413
12
11
1098
765
43
2
1
 
Figure 7: Texts scored by using the  
regression equation 
A more formal comparison can be made by plot-
ting the target points versus the regression results 
for each dimension separately and obtaining a cor-
relation measure between these values. These cor-
relations are shown in figure 8 for SS1 (left) and 
SS2 (right). The degree of correlation (R2) between 
the values of target and regression points is 0.9574 
for SS1 and 0.942 for SS2, which means that the 
search mechanism is working very satisfactorily on 
both dimensions.14  
86420-2-4-6-8-10
8
6
4
2
0
-2
-4
-6
-8
-10
-25-30-35-40-45
-25
-30
-35
-40
-45
 
Figure 8: Plotting target points versus regression results 
on SS1 (left) and SS2 (right) 
4.2 Comparing Target Points and Stylistic 
Scores 
In the second part of this experiment we wanted to 
know whether the regression equations were doing 
the job they were supposed to do by comparing the 
regression scores with stylistic scores obtained 
(from the factor analysis) for each of the generated 
texts. In figure 9 we plotted the texts in a graph in 
accordance with their stylistic scores (once again, 
some texts occupy the same point so they do not 
appear).  
                                                          
14
  All the correlational figures (R2) presented for this 
experiment are significant at the 0.01 level (two-
tailed). 
-25-30-35-40-45
10
8
6
4
2
0
-2
-4
-6
-8
-10
80
79
78
777675
743
72
71 70696867
66
6564
63
6261
6059
58
57
56
55
54
53
5251
5049
48
47
46
45
44
4342
41
4039
38
37
36
354
33
32
31
302928
27
262524
23
2221
20
1918
17
16
15
14
1312
11
1098
76
54
321
 
Figure 9: Texts scored using the two stylistic dimension 
obtained in our factor analysis 
In the ideal situation, the generator would have 
produced texts with the perfect regression scores 
and they would be identical to the stylistic scores, 
so the graph in the figure 9 would be like a grid-
shape one as in figure 6. However we have already 
seen in figure 7, that this is not the case for the re-
lation between the target coordinates and the re-
gression scores. So we did not expect the plot of 
stylistic scores 1 (SS1) against stylistic scores 2 
(SS2) to be a perfect grid. 
Figure 10 (left-hand side) shows the relation be-
tween the target points and the scores obtained 
from the original factor equation of SS1. The value 
of R2, which represents their correlation, is high 
(0.9458), considering that this represents the possi-
ble accumulation of errors of two stages: from the 
target to the regression scores, and then from the 
regression to the actual factor scores. On the right 
of figure 10 we can see the plotting of the target 
points and their respective factor scores on SS2. 
The correlation obtained is also reasonably high 
(R2 = 0.9109). 
1086420-2-4-6-8-10
10
8
6
4
2
0
-2
-4
-6
-8
-10
-25-30-35-40-45
-25
-30
-35
-40
-45
 
Figure 10: Plotting target points versus factor scores on 
SS1 (left) and SS2 (right) 
5 Discussion and Future Work 
These results demonstrate that it is possible to pro-
vide effective control of a generator correlating 
internal generator behaviour with characteristics of 
the resulting texts. It is important to note that these 
64
two sets of variables (generator decision and sur-
face features) are in principle quite independent of 
each other. Although in some cases there are 
strong correlations (for example, the generator?s 
use of a ?passive? rule, correlates with the occur-
rence of passive participles in the text), in others  
the relationship is much less direct (for example, 
the choice of how many subnetworks to split a net-
work into, i.e., SPLITNET, does not correspond to 
any feature in the factor analysis), and the way in-
dividual features combine into significant factors 
may be quite different.  
Another feature of our approach is that we do 
not assume some pre-defined notion of parameters 
of variation ? variation is characterised completely 
by a corpus (in contrast to approaches which use a 
corpus to characterise a single style). The disad-
vantage of this is that variation is not grounded in 
some ?intuitive? notion of style: the interpretation 
of the stylistic dimensions is subjective and tenta-
tive. However, as no comprehensive computation-
ally realisable theory of style yet exists, we believe 
that this approach has considerable promise for 
practical, empirically-based stylistic control. 
The results reported here also make us think that 
a possible avenue for future work is to explore the 
issue of what types of problems the generalisation 
induced by our framework (which will be dis-
cussed below) can be applied to. This paper dealt 
with an application to stylistic variation but, in 
theory, the approach can be applied to any kind of 
process to which there is a sorting function that can 
impose an order, using a measurable scale (e.g., 
ranking), onto the outputs of another process.  
Schematically the approach can be abstracted to 
any sort of problem of the form shown in fig-
ure 11. Here there is a producer process outputting 
a large number of solutions. There is also a sorter 
process which will classify those solutions in a cer-
tain order. The numerical value associated with the 
output by the sorter can be correlated with the de-
cisions the producer took to generate the output. 
The same correlation and control mechanism used 
in this paper can be introduced in the producer 
process, making it controllable with respect to the 
sorting dimension. 
 
pr
o
du
ce
r 
output 1 
output 2 
output m 
output 3 
output 4 
.
.
.
 
 
so
rti
n
g 
di
m
en
sio
n
 
so
rte
r 
output 3 
output 1 
output 14 
output 10 
output m 
.
.
.
 
 
.
.
.
 
 
.
.
.
 
 
.
.
.
 
 
 
Figure 11: The producer-sorter scheme. 
References 
Biber, Douglas (1988) Variation across speech and writing. 
Cambridge University Press. 
Cahill, Lynne; J. Carroll; R. Evans; D. Paiva; R. Power; D. Scott; and 
K. van Deemter From RAGS to RICHES: exploiting the potential 
of a flexible generation architecture. Proceedings of ACL/EACL 
2001, pp. 98-105. 
Carroll, John; N. Nicolov; O. Shaumyan; M. Smets; and D. Weir 
(2000) Engineering a wide-coverage lexicalized grammar. Pro-
ceedings of the Fifth International Workshop on Tree Adjoining 
Grammars and Related Frameworks. 
Green, Stephen J.; and C. DiMarco (1993) Stylistic decision-making 
in NLG. In Proceedings of the 4th  European Workshop on Natu-
ral Language Generation. Pisa, Italy. 
Grosz, Barbara J.; A.K. Joshi; and S. Weinstein (1995) Centering: A 
Framework for Modelling the Local Coherence of Discourse. In-
stitute for Research in Cognitive Science, IRCS-95-01, University 
of Pennsylvania.  
Hovy, Eduard H. (1988) Generating natural language under prag-
matic constraints. Lawrence Erlbaum Associates. 
Langkilde-Geary, Irene. (2002) An empirical verification of coverage 
and correctness for a general-purpose sentence generator. Proceed-
ing of INLG?02, pp. 17-24. 
Lee, David (1999) Modelling Variation in Spoken And Written Eng-
lish: the Multi-Dimensional Approach Revisited. PhD thesis, Uni-
versity of Lancaster, UK.  
McKeown, Kathleen R. (1985) Text Generation: Using Discourse 
Strategies and Focus Constraints to Generate Natural Language 
Text. Cambridge University Press. 
Nicolov, Nicolas (1999) Approximate Text Generation from Non-
hierarchical Representations in a Declarative Framework. PhD 
Thesis, University of Edinburgh. 
Paiva, Daniel S. (2000) Investigating style in a corpus of pharmaceuti-
cal leaflets: results of a factor analysis. Proceedings of the Student 
Workshop of the 38th Annual Meeting of the Association for Com-
putational Linguistics (ACL'2000), Hong Kong, China. 
Paiva, Daniel S. (2004) Using Stylistic Parameters to Control  
a Natural Language Generation System. PhD Thesis, University of 
Brighton, Brighton, UK. 
Paiva, Daniel S.; R. Evans (2004) A Framework for Stylistically Con-
trolled Generation. In Proceedings of the 3rd International Confer-
ence on Natural Language Generation (INLG?04). New Forest, 
UK. 
Sigley, Robert (1997) Text categories and where you can stick them: a 
crude formality index. International Journal of Corpus Linguistics, 
volume 2, number 2, pp. 199-237. 
Walker, Marilyn; O. Rambow, and M. Rogati (2002) Training a Sen-
tence Planner for Spoken Dialogue Using Boosting. Computer 
Speech and Language, Special Issue on Spoken Language Genera-
tion. July. 
Weisberg, Sanford (1985) Applied Linear Regression, 2nd edition. 
John Wiley & Sons. 
65
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 699?706,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Implementing a Characterization of Genre for                              
Automatic Genre Identification of Web Pages 
 
Marina Santini 
NLTG 
University of Brighton 
UK 
M.Santini@brighton.ac.uk 
Richard Power 
Computing Department 
Open University 
UK 
r.power@open.ac.uk  
Roger Evans 
NLTG 
University of Brighton 
UK 
R.P.Evans@brighton.ac.uk 
 
 
Abstract 
In this paper, we propose an 
implementable characterization of genre 
suitable for automatic genre 
identification of web pages. This 
characterization is implemented as an 
inferential model based on a modified 
version of Bayes? theorem. Such a model 
can deal with genre hybridism and 
individualization, two important forces 
behind genre evolution. Results show 
that this approach is effective and is 
worth further research. 
1 Introduction 
The term ?genre? is employed in virtually all 
cultural fields: literature, music, art, architecture, 
dance, pedagogy, hypermedia studies, computer-
mediated communication, and so forth. As has 
often been pointed out, it is hard to pin down the 
concept of genre from a unified perspective (cf. 
Kwasnik and Crowston, 2004). This lack is also 
experienced in the more restricted world of non-
literary or non-fictional document genres, such 
as professional or instrumental genres, where 
variation due to personal style is less pronounced 
than in literary genres. In particular, scholars 
working with practical genres focus upon a 
specific environment. For instance Swales (1990) 
develops his notion of genre in academic and 
research settings, Bathia (1993) in professional 
settings, and so on. In automatic genre 
classification studies, genres have often been 
seen as non-topical categories that could help 
reduce information overload (e.g. Mayer zu 
Eissen and Stein, 2004; Lim et al, 2005).  
Despite the lack of an agreed theoretical 
notion, genre is a well-established term, 
intuitively understood in its vagueness. What 
humans intuitively perceive is that there are 
categories created within a culture, a society or a 
community which are used to group documents 
that share some conventions. Each of these 
groups is a genre, i.e. a cultural object or artefact, 
purposely made to meet and streamline 
communicative needs. Genres show sets of 
standardized or conventional characteristics that 
make them recognizable, and this identity raises 
specific expectations.   
Together with conventions and expectations, 
genres have many other traits. We would like to 
focus on three traits, namely hybridism, 
individualization and evolution. Genres are not 
mutually exclusive and different genres can be 
merged into a single document, generating 
hybrid forms. Also, genres allow a certain 
freedom of variation and consequently can be 
individualized. Finally, genre repertoires are 
dynamic, i.e. they change over time, thus 
triggering genre change and evolution. It is also 
important to notice that before genre conventions 
become fully standardized, a genre does not have 
an official name. A genre name becomes 
acknowledged when the genre itself has an active 
role and a communicative function in a 
community or society (Swales, 1990). Before 
this acknowledgement, a genre shows hybrid or 
individualized forms, and indistinct functions. 
Putting all these traits together, we suggest the 
following broad theoretical characterization of 
genre of written texts: genres are named 
communication artefacts characterized by 
conventions, raising expectations, showing 
hybridism and individualization, and undergoing 
evolution. 
This characterization is flexible enough to 
encompass not only paper genres (both literary 
and practical genres), but also digital genres, and 
more specifically web genres. Web genres or 
cybergenres (Shepherd and Watters 1998) are 
those genres created by the combination of the 
use of the computer and the Internet.   
699
Genre hybridism and individualization are very 
evident on the web. In fact, web pages are often 
very hybrid because of the wider intra-genre 
variation and the smaller inter-genre 
differentiation. They can also be highly 
individualized because of the creative freedom 
provided by HTML tags (the building blocks of 
web pages) or programming languages such as 
Javascript. We suggest that genre hybridism and 
individualization can be seen as forces acting 
behind genre evolution. They allow the upgrade 
of existing genres and the creation of novel 
genres.  
The change of genre repertoire and the 
creation of new genres were well illustrated by 
Crowston and Williams (2000) and Shepherd and 
Watters (1998). Both these studies describe a 
similar process. Web genres can start either as 
reproductions or as unprecedented types of 
documents. In the first case, existing genres are 
gradually upgraded and modified to adapt to 
potentials offered by the web. These variants 
might become very different from the original 
genres with time passing by. In the second case, 
novel genres can be generated from specific 
needs and requirements of the web. Crowston 
and Williams (2000) have traced this evolution 
through a manual qualitative survey of 1000 web 
pages. Shepherd and Watters (1998) have 
proposed a fuzzy taxonomy for web genres. 
We would like to add a new force in this 
scenario, namely emerging genres. Emerging 
genre are those genres still in formation, not fully 
standardized and without any name or fixed 
function. For example, before 1998 web logs (or 
blogs) were already present on the web, but they 
were not yet identified as a genre. They were just 
?web pages?, with similar characteristics and 
functions. In 1999, suddenly a community sprang 
up using this new genre (Blood, 2000). Only at 
this point, the genre ?web log? or ?blog? started 
being spread and being recognized. 
Emerging genres may account for all those 
web pages, which remain unclassified or 
unclassifiable (cf. Crowston and Williams, 2000) 
because they show genre mixture or no genre at 
all. Authors often point out that assigning a genre 
to a web page might be difficult and 
controversial (e.g. Roussinov et al, 2001; Meyer 
zu Eissen and Stein, 2004; Shepherd et al, 2004) 
because web pages can appear hybrid or peculiar. 
Genre-mixed web pages or web pages without 
any evident genre can represent the antecedent of 
a future genre, but currently they might be 
considered as belonging to a genre still in 
formation. It is also important to highlight, 
however, that since the acknowledgement of 
genre relies on social acceptance, it is impossible 
to define the exact point at which a new genre 
emerges (Crowston and Williams 2000). The 
multi-facetted model capable of hosting new 
genres wished for by Kwasnik and Crowston 
(2004), and the adaptive learning system that can 
identify genre as they emerge announced by 
Shepherd et al (2004) are hard to implement.  
For this reason, the focus of the method proposed 
below is not to detect emerging genres, but to 
show a flexible approach capable of giving 
account of genre hybridism and 
individualization.  
Flexible genre classification systems are 
uncommon in automatic genre classification 
studies. Apart from two notable exceptions, 
namely Kessler et al (1997) and Rehm (2006) 
whose implementations require extensive manual 
annotation (Kessler et al, 1997) or analysis 
(Rehm, 2006), genres are usually classified as 
single-label discrete entities, relying on the 
simplified assumption that a document can be 
assigned to only one genre. 
In this paper, we propose a tuple 
representation that maps onto the theoretical 
characterization of genre suggested above and 
that can be implemented without much overhead. 
The implementable tuple includes the following 
attributes: 
(genre(s)) of web pages=<linguistic features, HTML, text types, [...]> 
This tuple means that web pages can have zero, 
one or more genres ((genre(s)) of web pages) 
and that this situation can be captured by a 
number of attributes. For the time being these 
attributes are limited to linguistic features, 
HTML tags, text types, but in future other 
attributes can be added ([...]). The attributes of 
the tuple can capture the presence of textual 
conventions or their absence. The presence of 
conventions brings about expectations, and can 
be used to identify acknowledged genres. The 
absence of conventions brings about hybridism 
and individualisation and can be interpreted in 
terms of emerging genres and genre evolution.  
In this paper we present a simple model that 
implement the tuple and can deal with this 
complex situation. This model is based on 
statistical inference, performs automatic text 
analysis and has a classification scheme that 
includes zero labels, one label or multiple labels. 
More specifically, in addition to the traditional 
single-label classification, a zero-label 
700
classification is useful when, for example, a web 
page is so peculiar from a textual point of view 
that it does not show any similarity with the 
genres included in the model. Conversely, a 
multi-label classification is useful when web 
pages show several genres at the same time. As 
there is no standard evaluation metrics for a 
comprehensive evaluation of such a model, we 
defer to further research the assessment of the 
model as a whole. In this paper, we report a 
partial evaluation based on single-label 
classification accuracy and predictions.  
From a theoretical point of view, the 
inferential model makes a clear-cut separation 
between the concepts of ?text types? and 
?genres?. Text types are rhetorical/discourse 
patterns dictated by the purposes of a text. For 
example, when the purpose of a text producer is 
to narrate, the narration text type is used. On the 
contrary, genres are cultural objects created by a 
society or a community, characterized by a set of 
linguistic and non-linguistic conventions, which 
can be fulfilled, personalized, transgressed, 
colonized, etc., but that are nonetheless 
recognized by the members of the society and 
community that have created them, raising 
predictable expectations. For example, what we 
expect from a personal blog is diary-form 
narration of the self, where opinions and 
comments are freely expressed.  
The model presented here is capable of 
inferring text types from web pages using a 
modified form of Bayes? theorem, and derive 
genres through if-then rules.  
With this model, emerging genres can be 
hypothesized through the analysis of unexpected 
combinations of text types and/or other traits in a 
large number of web pages. However, this 
potential will be investigated in future work. The 
results presented here are just a first step towards 
a more dynamic view of a genre classification 
system. 
Automatic identification of text types and 
genres represents a great advantage in many 
fields because manual annotation is expensive 
and time-consuming. Apart from the benefits that 
it could bring to information retrieval, 
information extraction, digital libraries and so 
forth, automatic identification of text types and 
genres could be particularly useful for problems 
that natural language processing (NLP) is 
concerned with. For example, parsing accuracy 
could be increased if parsers were tested on 
different text types or genres, as certain 
constructions may occur only in certain types of 
texts. The same is true for Part-of-Speech (POS) 
tagging and word sense disambiguation. More 
accurate NLP tools could in turn be beneficial for 
automatic genre identification, because many 
features used for this task are extracted from the 
output of taggers and parsers, such as POS 
frequencies and syntactic constructions. 
The paper is organized as follows: Section 2 
reports previous characterization that have been 
implemented as statistical or computational 
models; Section 3 illustrates the attributes of the 
tuple; Section 4 describes the inferential model 
and reports evaluation; finally in Section 5 we 
draw some conclusions and outline points for 
future work. 
2 Background 
Although both Crowston and Williams (2000) 
and Shepherd and Watters (1998) have well 
described the evolution of genres on the web, 
when it comes to the actual genre identification 
of web pages (Roussinov et al, 2001; and 
Shepherd et al, 2004, respectively), they set 
aside the evolutionary aspect and consider genre 
from a static point of view. For Crowston and 
Williams (2000) and the follow-up Roussinov et 
al. (2001) most genres imply a combination of 
<purpose/function, form, content>, and, as they 
are complex entities, a multi-facetted 
classification seems appropriate (Kwasnik and 
Crowston, 2004). For Shepherd and Watters 
(1998) and the practical implementation 
Shepherd et al (2004), cybergenres or web 
genres are characterized by the triple <content, 
form, functionality>, where functionality is a key 
evolutionary aspect afforded by the web. 
Crowston and co-workers have not yet 
implemented the combination of 
<purpose/function, form, content> together with 
the facetted classification in any automatic 
classification model, but the tuple <content, 
form, function> has been employed by Rehm 
(2006) for an original approach to single-web 
genre analysis, the personal home pages in the 
domain of academia. Rehm (2006) describes the 
relationship between HTML and web genres and 
depicts the evolutionary processes that shape and 
form web genres. In the practical 
implementation, however, he focuses only on a 
single web genre, the academic?s personal home 
page, that is seen from a static point of view. As 
far as we know, Boese and Howe (2005) is the 
only study that tries to implement a diachronic 
view on genre of web pages using the triple 
701
<style, form, content>. This study has the 
practical aim of finding out whether feature sets 
for genre identification need to be changed or 
updated because of genre evolution. They tried to 
detect the change through the use of a classifier 
on two parallel corpora separated by a six-year 
gap. Although this study does not focus on how 
to detect newly created web genres or how to 
deal with difficult web pages, it is an interesting 
starting point for traditional diachronic analysis 
applied to automatic genre classification.  
In contrast, the model described in this paper 
aims at pointing out genre hybridism and 
individualisation in web pages. These two 
phenomena can be interpreted in terms of genre 
evolution in future investigations. 
3 Attributes of the Tuple 
The attributes <linguistic features, HTML tags, 
text types> of the tuple represent the 
computationally tractable version of the 
combination <purpose, form> often used to 
define the concept of genre (e.g. cf. Roussinov et 
al. 2001).  
In our view, the purpose corresponds to text 
types, i.e. the rhetorical patterns that indicate 
what a text has been written for. For example, a 
text can be produced to narrate, instruct, argue, 
etc. Narration, instruction, and argumentation are 
examples of text types. As stressed earlier, text 
types are usually considered separate entities 
from genres (cf. Biber, 1988; Lee, 2001). 
Form is a more heterogeneous attribute. Form 
can refer to linguistic form and to the shape 
(layout etc.). From an automatic point of view, 
linguistic form is represented by linguistic 
features, while shape is represented by HTML 
tags. Also the functionality attribute introduced 
by Shepherd and Watters (1998) can be seen in 
terms of HTML tags (e.g. tags for links and 
scripts). While content words or terms show 
some drawbacks for automatic genre 
identification (cf. Boese and Howe, 2005), there 
are several types of linguistic features that return 
good results, for instance, Biberian features 
(Biber, 1988). In the model presented here we 
use a mixture of Biberian features and additional 
syntactic traits. The total number of features used 
in this implementation of the model is 100. 
These features are available online at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
4 Inferential Model 
The inferential model presented here (partially 
discussed in Santini (2006a) combines the 
advantages of deductive and inductive 
approaches. It is deductive because the co-
occurrence and the combination of features in 
text types is decided a priori by the linguist on 
the basis on previous studies, and not derived by 
a statistical procedure, which is too biased 
towards high frequencies (some linguistic 
phenomena can be rare, but they are nonetheless 
discriminating). It is also inductive because the 
inference process is corpus-based, which means 
that it is based on a pool of data used to predict 
some text types. A few handcrafted if-then rules 
combine the inferred text types with other traits 
(mainly layout and functionality tags) in order to 
suggest genres. These rules are worked out either 
on the basis of previous genre studies or of a 
cursory qualitative analysis. For example, rules 
for personal home pages are based on the 
observations by Roberts (1998), Dillon and 
Gushrowski (2000). When previous studies were 
not available, as in the cases of eshops or search 
pages, the author of this paper has briefly 
analysed these genres to extract generalizations 
useful to write few rules.  
It is important to stress that there is no hand-
coding in the model. Web pages were randomly 
downloaded from genre-specific portals or 
archives without any further annotation. Web 
pages were parsed, linguistic features were 
automatically extracted and counted from the 
parsed outputs, while frequencies of HTML tags 
were automatically counted from the raw web 
pages. All feature frequencies were normalized 
by the length of web pages (in tokens) and then 
submitted to the model. 
As stated earlier, the inferential model makes 
a clear-cut separation between text types and 
genres. The four text types included in this 
implementation are: descriptive_narrative, 
expository_informational, argumentative_persuasive, 
and instructional. The linguistic features for these 
text types come from previous (corpus-)linguistic 
studies (Werlich 1976; Biber, 1988; etc.), and are 
not extracted from the corpus using statistical 
methods. For each web page the model returns 
the probability of belonging to the four text 
types. For example, a web page can have 0.9 
probabilities of being argumentative_persuasive, 
0.7 of being instructional and so on. Probabilities 
are interpreted in terms of degree or gradation. 
For example, a web page with 0.9 probabilities 
702
of being argumentative_persuasive shows a high 
gradation of argumentation. Gradations/ 
probabilities are ranked for each web page.  
The computation of text types as intermediate 
step between linguistic and non-linguistic 
features and genres is useful if we see genres as 
conventionalised and standardized cultural 
objects raising expectations. For example, what 
we expect from an editorial is an ?opinion? or a 
?comment? by the editor, which represents, 
broadly speaking, the view of the newspaper or 
magazine. Opinions are a form of 
?argumentation?. Argumentation is a rhetorical 
pattern, or text type, expressed by a combination 
of linguistic features. If a document shows a high 
probability of being argumentative, i.e. it has a 
high gradation of argumentation, this document 
has a good chance of belonging to argumentative 
genres, such as editorials, sermons, pleadings, 
academic papers, etc. It has less chances of being 
a story, a biography, etc. We suggest that the 
exploitation of this knowledge about the 
textuality of a web page can add flexibility to the 
model and this flexibility can capture hybridism 
and individualization, the key forces behind 
genre evolution. 
4.1 The Web Corpus  
The inferential model is based on a corpus 
representative of the web. In this implementation 
of the model we approximated one of the 
possible compositions of a random slice of the 
web, statistically supported by reliable standard 
error measures. We built a web corpus with four 
BBC web genres (editorial, Do-It-Yourself 
(DIY) mini-guide, short biography, and feature), 
seven novel web genres (blog, eshop, FAQs, 
front page, listing, personal home page, search 
page), and 1,000 unclassified web pages from 
SPIRIT collection (Joho and Sanderson, 2004). 
The total number of web pages is 2,480. The four 
BBC genres represent traditional genres adapted 
to the functionalities of the web, while the seven 
genres are novel web genres, either 
unprecedented or showing a loose kinship with 
paper genres. Proportions are purely arbitrary 
and based on the assumption that at least half of 
web users tend to use recognized genre patterns 
in order to achieve felicitous communication. We 
consider the sampling distribution of the sample 
mean as approximately normal, following the 
Central Limit Theorem. This allows us to make 
inferences even if the population distribution is 
irregular or if variables are very skewed or 
highly discrete. The web corpus is available at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
4.2 Bayesian Inference: Inferring with 
Odds-Likelihood 
The inferential model is based on a modified 
version of Bayes? theorem. This modified 
version uses a form of Bayes? theorem called 
odds-likelihood or subjective Bayesian method 
(Duda and Reboh, 1984) and is capable of 
solving more complex reasoning problems than 
the basic version.  Odds is a number that tells us 
how much more likely one hypothesis is than the 
other. Odds and probabilities contain exactly the 
same information and are interconvertible. The 
main difference with original Bayes? theorem is 
that in the modified version much of the effort is 
devoted to weighing the contributions of 
different pieces of evidence in establishing the 
match with a hypothesis. These weights are 
confidence measures: Logical Sufficiency (LS) 
and Logical Necessity (LN). LS is used when the 
evidence is known to exist (larger value means 
greater sufficiency), while LN is used when 
evidence is known NOT to exist (a smaller value 
means greater necessity). LS is typically a 
number > 1, and LN is typically a number < 1. 
Usually LS*LN=1. In this implementation of the 
model, LS and LN were set to 1.25 and 0.8 
respectively, on the basis of previous studies and 
empirical adjustments. Future work will include 
more investigation on the tuning of these two 
parameters.  
The steps included in the model are the 
following: 
1) Representation of the web in a corpus that is 
approximately normal. 
2) Extraction, count and normalization of genre-
revealing features. 
3) Conversion of normalized counts into z-scores, 
which represent the deviation from the ?norm? 
coming out from the web corpus. The concept of 
?gradation? is based on these deviations from the 
norm. 
4) Conversion of z-scores into probabilities, which 
means that feature frequencies are seen in terms 
of probabilities distribution. 
5) Calculation of prior odds from prior probabilities 
of a text type. The prior probability for each of 
the four text types was set to 0.25 (all text types 
were given an equal chance to appear in a web 
page). Prior odds are calculated with the formula:   
 
prOdds(H)=prProb(H)/1-prProb(H)  
 
6) Calculation of weighted features, or multipliers 
(Mn). If a feature or piece of evidence (E) has a 
703
probability >=0.5, LS is applied, otherwise LN is 
applied. Multipliers are calculated with the 
following formulae: 
 
if  Prob (E)>=0.5 then  
M(E)=1+(LS-1)(Prob(E)-0.5)/0.25 
if Prob (E)<0.5 then 
M(E)=1-(1-LN)(0.5-Prob(E))/0.25 
 
7) Multiplication of weighted probabilities together, 
according to the co-occurrence decided by the 
analyst on the basis of previous studies in order to 
infer text types. In this implementation the 
feature co-occurrence was decided following 
Werlich (1976) and Biber (1988). 
8) Posterior odds for the text type is then calculated 
by multiplying prior odds (step 5) with co-
occurrence of weighted features (step 7).  
9) Finally, posterior odds is re-converted into a 
probability value with the following formula: 
 
Prob(H)=Odds(H)/1+Odds(H) 
 
Although odds contains exactly the same 
information as probability values, they are not 
constrained in 0-1 range, like probabilities.  
Once text types have been inferred, if-then 
rules are applied for determining genres. In 
particular, for each of the seven web genre 
included in this implementation, few hand-
crafted rules combine the two predominant text 
types per web genre with additional traits. For 
example, the actual rules for deriving a blog are 
as simple as the following ones: 
 
if (text_type_1=descr_narrat_1|argum_pers_1) 
if (text_type_2=descr_narrat_2|argum_pers_2) 
if (page_length=LONG) 
if (blog_words >= 0.5 probabilities) 
then good blog candidate. 
 
That is, if a web page has description_narration 
and argumentation_persuasion as the two 
predominant text types, and the page length is > 
500 words (LONG), and the probability value for 
blog words is >=0.5 (blog words are terms such 
as web log, weblog, blog, journal, diary, posted 
by, comments, archive plus names of the days 
and months), then this web page is a good blog 
candidate.  
For other web genres, the number of rules is 
higher, but it is worth saying that in the current 
implementation, rules are useful to understand 
how features interact and correlate.  
One important thing to highlight is that each 
genre is computed independently for each web 
page. Therefore a web page can be assigned to 
different genres (Table 1) or to none (Table 2).  
Multi-label and no-label classification cannot be 
evaluated with standard metrics and their 
evaluation requires further research. In the next 
subsection we present the evaluation of the 
single label classification returned by the 
inferential model.  
4.3 Evaluation of the Results 
Single-label classification. For the seven web 
genres we compared the classification accuracy 
of the inferential model with the accuracy of 
classifiers. Two standard classifiers ? SVM and 
Naive Bayes from Weka Machine Learning 
Workbench (Witten, Frank, 2005) ? were run on 
the seven web genres. The stratified cross-
validated accuracy returned by these classifiers 
for one seed is ca. 89% for SVM and ca. 67% for 
Na?ve Bayes. The accuracy achieved by the 
inferential model is ca. 86%. 
An accuracy of 86% is a good achievement for 
a first implementation, especially if we consider 
that the standard Na?ve Bayes classifier returns 
an accuracy of about 67%.  Although slightly 
lower than SVM, an accuracy of 86% looks 
promising because this evaluation is only on a 
single label. Ideally the inferential model could 
be more accurate than SVM if more labels could 
be taken into account. For example, the actual 
classification returned by the inferential model is 
shown in Table 1. The web pages in Table 1 are 
blogs but they also contain either sequences of 
questions and answers or are organized like a 
how-to document, like in the snippet in Figure 1 
 
blog 
augustine 
0000024 
GOOD 
blog 
BAD 
eshop 
GOOD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
blog 
britblog 
00000107 
GOOD 
blog 
BAD 
eshop 
GOOD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
Table 1. Examples of multi-label classification 
 
Figure 1. Snippet blog_augustine_0000024 
 
704
The snippet shows an example of genre 
colonization, where the vocabulary and text 
forms of one genre (FAQs/How to in this case) 
are inserted in another (cf. Beghtol, 2001). These 
strategies are frequent on the web and might give 
rise to new web genres. The model also captures 
a situation where the genre labels available in the 
system are not suitable for the web page under 
analysis, like in the example in Table 2. 
 
SPRT_010_049 
_112_0055685 
BAD 
blog 
BAD 
eshop 
BAD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
Table 2. Example of zero label classification 
This web page (shown in Figure 2) from the 
unannotated SPIRIT collection (see Section 4.1) 
does not receive any of the genre labels currently 
available in the system. 
 
Figure 2. SPRT_010_049_112_0055685 
If the pattern shown in Figure 2 keeps on 
recurring even when more web genres are added 
to the system, a possible interpretation could be 
that this pattern might develop into a stable web 
genre in future. If this happens, the system will 
be ready to host such a novelty. In the current 
implementation, only a few rules need to be 
added. In future implementations hand-crafted 
rules can be replaced by other methods. For 
example, an interesting adaptive solution has 
been explored by Segal and Kephart (2000). 
Predictions. Precision of predictions on one web 
genre is used as an additional evaluation metric. 
The predictions on the eshop genre issued by the 
inferential model are compared with the 
predictions returned by two SVM models built 
with two different web page collections, Meyer-
zu-Eissen collection and the 7-web-genre 
collection (Santini, 2006).  Only the predictions 
on eshops are evaluated, because eshop is the 
only web genre shared by the three models. The 
number of predictions is shown in Table 3. 
 
Models Total 
Predictions 
Correct 
Predictions 
Incorrect 
Predictions and 
Uncertain 
Meyer-zu-Eissen 
and SVM 
6 3 3 
7-web-genre and 
SVM 
11 3 8 
Web corpus and 
inferential model 
17 6 11 
Table 3. Predictions on eshops 
The number of retrieved web pages (Total 
Predictions) is higher when the inferential model 
is used. Also the value of precision (Correct 
Predictions) is higher. The manual evaluation of 
the predictions is available online at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
5 Conclusions and Future Work 
From a technical point of view, the inferential 
model presented in this paper is a simple starting 
point for reflection on a number of issues in 
automatic identification of genres in web pages. 
Although parameters need a better tuning and 
text type and genre palettes need to be enlarged, 
it seems that the inferential approach is effective, 
as shown by the preliminary evaluation reported 
in Section 4.3.  
More importantly, this model instantiates a 
theoretical characterization of genre that includes 
hybridism and individualization, and interprets 
these two elements as the forces behind genre 
evolution. It is also worth noticing that the 
inclusion of the attribute ?text types? in the tuple 
gives flexibility to the model. In fact, the model 
can assign not only a single genre label, as in 
previous approaches to genre, but also multiple 
labels or no label at all. Ideally other 
computationally tractable attributes can be added 
to the tuple to increase flexibility and provide a 
multi-facetted classification, for example register 
or layout analysis. 
However, other issues remain open. First, the 
possibility of a comprehensive evaluation of the 
model is to be explored. So far, only tentative 
evaluation schemes exist for multi-label 
classification (e.g. McCallum, 1999). Further 
research is still needed.  
Second, in this model the detection of emerging 
genres can be done indirectly through the 
analysis of an unexpected combination of text 
types and/or genres. Other possibilities can be 
explored in future. Also the objective evaluation 
705
of emerging genres requires further research and 
discussion. 
More feasible in the short term is an 
investigation of the scalability of the model, 
when additional web pages, classified or not 
classified by genre, are added to the web corpus.  
Also the possibility of replacing hand-crafted 
rules with some learning methodology can be 
explored in the near future. Apart from the 
approach suggested by Segal and Kephart (2000) 
mentioned above, many other pieces of 
experience are now available on adaptive 
learning (for example those reported in the 
EACL 2006 on Workshop on Adaptive Text 
Extraction and Mining).  
References 
Bathia V. 1993. Analysing Genre. Language Use in 
Professional Settings. Longman, London-NY. 
Beghtol C. 2001. The Concept of Genre and Its 
Characteristics. Bulletin of The American Society 
for Inform. Science and Technology, Vol. 27 (2). 
Biber D. 1988. Variations across speech and writing. 
Cambridge University Press, Cambridge. 
Blood, R. 2000. Weblogs: A History and Perspective, 
Rebecca's Pocket.  
Boese E. and Howe A. 2005. Effects of Web 
Document Evolution on Genre Classification. 
CIKM 2005, Germany. 
Crowston K. and Williams M. 2000. Reproduced and 
Emergent Genres of Communication on the World-
Wide Web, The Information Society, 16(3), 201-
216. 
Dillon, A. and Gushrowski, B. 2000. Genres and the 
Web: is the personal home page the first uniquely 
digital genre?, JASIS, 51(2). 
Duda R. and Reboh R. 1984. AI and decision making: 
The PROSPECTOR experience. In Reitman, W. 
(Ed.), Artificial Intelligence Applications for 
Business, Norwood, NJ. 
Joho H. and Sanderson M. 2004. The SPIRIT 
collection: an overview of a large web collection, 
SIGIR Forum, December 2004, Vol. 38(2). 
Kessler B., Numberg G. and Sh?tze H. (1997), 
Automatic Detection of Text Genre, Proc. 35 ACL 
and 8  EACL. 
Kwasnik B and Crowston K. 2004. A Framework for 
Creating a Facetted Classification for Genres: 
Addressing Issues of Multidimensionality. Proc. 
37 Hawaii Intern. Conference on System Science. 
Lee D. 2001. Genres, Registers, Text types, Domains, 
and Styles: Clarifying the concepts and navigating 
a path through the BNC Jungle. Language 
Learning and Technology, 5, 37-72. 
Lim, C., Lee, K. and Kim G. 2005. Automatic Genre 
Detection of Web Documents, in Su K., Tsujii J., 
Lee J., Kwong O. Y. (eds.) Natural Language 
Processing, Springer, Berlin. 
Meyer zu Eissen S. and Stein B. 2004. Genre 
Classification of Web Pages: User Study and 
Feasibility Analysis, in Biundo S., Fruhwirth T., 
Palm G. (eds.), Advances in Artificial Intelligence, 
Springer, Berlin, 256-269. 
McCallum A. 1999. Multi-Label Text Classification 
with a Mixture Model Trained by EM, AAAI'99 
Workshop on Text Learning. 
Rehm G. 2006. Hypertext Types and Markup 
Languages. In Metzing D. and Witt A. (eds.), 
Linguistic Modelling of Information and Markup 
Languages. Springer, 2006 (in preparation). 
Roberts, G. 1998. The Home Page as Genre: A 
Narrative Approach, Proc. 31 Hawaii Intern. 
Conference on System Sciences. 
Roussinov D., Crowston K., Nilan M., Kwasnik B., 
Cai J., Liu X. 2001. Genre Based Navigation on 
the Web, Proc. 34 Hawaii Intern. Conference on 
System Sciences. 
Santini M. 2006a. Identifying Genres of Web Pages, 
TALN 06 - Actes de la 13 Conference sur le 
Traitement Automatique des Langues Naturelles, 
Vol. 1, 307-316. 
Santini M. 2006b. Some issues in Automatic Genre 
Classification of Web Pages,  JADT 06 ? Actes des 
8 Journ?es internationales d?analyse statistiques 
des donn?s textuelles, Vol 2, 865-876. 
Segal R. and Kephart J. 2000. Incremental Learning 
in SwiftFile. Proc.  17 Intern. Conf. on Machine 
Learning. 
Shepherd M. and Watters C. 1998. The Evolution of 
Cybergenre,  Proc. 31 Hawaii Intern. Conference 
on System Sciences. 
Shepherd M.,  Watters C., Kennedy A. 2004. 
Cybergenre: Automatic Identification of Home 
Pages on the Web. Journal of Web Engineering, 
Vol. 3(3-4), 236-251. 
Swales, J. Genre Analysis. English in academic and 
research settings, Cambridge University Press, 
Cambridge, 1990. 
Werlich E. (1976). A Text Grammar of English. 
Quelle & Meyer, Heidelberg. 
706
A large-scale inheritance-based morphological lexicon for Russian 
R. Evans 
ITRI 
University of Brighton 
roger.evans@itri.bton.ac.uk  
C. Tiberius, D. Brown, G.G. Corbett  
Surrey Morphology Group 
University of Surrey 
{c.tiberius,d.brown,g.corbett}
@surrey.ac.uk 
 
Abstract 
In this paper we describe the mapping of 
Zaliznjak?s (1977) morphological classes 
into the lexical representation language 
DATR (Evans and Gazdar 1996).  On the 
basis of the resulting DATR theory a set of 
fully inflected forms together with their as-
sociated morphosyntax can automatically 
be generated from the electronic version of 
Zaliznjak?s dictionary (Ilola and Mustajoki  
1989). From this data we plan to develop a 
wide-coverage morphosyntactic lemma-
tizer and tagger for Russian. 
 
1 Introduction 
Our goal is to undertake a detailed corpus analysis 
of Russian texts, focusing on the relationship be-
tween morphological ambiguity (syncretism) in 
nouns and adjectives and the comparative fre-
quency of the relevant grammatical categories. For 
this purpose, we will use two corpora, the Uppsala 
corpus (L?nngren 1993, Maier 1994) and a corpus 
of Russian newspaper texts from the late 1990?s, 
for which we require detailed morphosyntactic an-
notation. However, suitably annotated versions of 
these corpora are not yet freely available and cor-
pus analysis tools for Russian in general are 
scarce.1 
We have chosen, therefore, to develop our own 
lemmatization and tagging technology, based on 
the electronic version of Zaliznjak?s (1977) dic-
                                                          
1 For an indication of what is available see: http://talrusse.free.fr. 
For natural language processing of Slavic languages in general see for example 
work on the MULTEXT-EAST project by Dimitrova, Erjavec, Ide, Kaalep, 
Petkevi? and Tufis (1998) and work within the INTEX system by Vitas (2001). 
tionary (Ilola and Mustajoki  1989), combined with 
a more detailed and validated hand-crafted analysis 
of 1500 most frequent noun lexemes (Brown, Cor-
bett, and Fraser 1995; Brown, Hippisley, Corbett 
and Fraser 1995). In this paper we describe the 
first step in this process: mapping the basic Zalizn-
jak data into a hierarchical lexical database imple-
mented in DATR.  
1.1 The Zaliznjak dictionary 
Zaliznjak (1977) is a reverse dictionary in book 
form, dealing primarily with Russian inflectional 
morphology.  For each of the almost 100,000 lexi-
cal entries, indexes refer the reader to declension 
types and conjugations, together with stress pat-
terns. Other symbols indicate subregularities and 
irregularities. As the dictionary uses such indica-
tors, it gives explicit information about every in-
flectional form and stress. Ilola and Mustajoki 
(1989: 1-5) describe how the material was adapted 
for computer use.  
Zaliznjak's dictionary has been the starting point 
for a number of applications. Anciaux (1991) made 
use of it in the creation of a spell-checker for Rus-
sian, and Pavlova, Pavlov, Sproat, Shih and van 
Santen (1997) used the electronic version to create 
language-specific tables to fit into the modular ar-
chitecture of the Bell Laboratories Text-to-Speech 
system. Brown, Corbett and Fraser (1995) and 
Brown, Hippisley, Corbett and Fraser (1995) cre-
ated a DATR lexicon of the 1500 most frequent 
noun lexemes from Zasorina (1977). The derived 
forms from this inheritance-based lexicon were all 
checked manually against Zaliznjak. The forms are 
represented in a phonological transcription, to-
gether with stress information (Brown, Corbett, 
Fraser, Hippisley and Timberlake 1996).  An up-
dated version of this lexicon was used in Brown 
(1998) to compare different morphological theo-
ries.  
1.2 Outline 
The paper is structured as follows. Section 2 de-
scribes the general principles of the mapping and 
examples. In Section 3, we discuss the technical 
framework of our approach and the issues and 
problems that arise. In Section 4 we discuss the 
current status of the mapping and principal areas 
for further development including our approach to 
lemmatization and tagging. Section 5 concludes 
the paper. 
2 Mapping Zaliznjak into DATR 
2.1 The overall approach 
In book form, Zaliznjak?s dictionary has two 
parts. The first is a set of tables identifying mor-
phosyntactic classes and defining the realization 
of morphological features with them. The sec-
ond is a listing of lexical entries, each followed 
by an index referring to a table in the first part 
which gives the paradigm for this particular 
type. For example, the word ?????? 'lamp 
shade' is a masculine noun of type 1A and as 
such follows the inflectional pattern of ?????  
?factory? which is given as the example para-
digm for masculine nouns of type 1A. 
 
1A  
? ????? 
nom ????? 
gen ?????? 
dat ?????? 
acc  ????? 
instr ??????? 
Sg 
loc ?????? 
nom ?????? 
gen ??????? 
dat ??????? 
acc ?????? 
instr ???????? 
Pl 
loc ??????? 
 
Table 1. Zaliznjak?s paradigm for masculine inanimate 
nouns of type 1A. 
 
The electronic form contains just the set of lexi-
cal entries (101401 lines, 98729 lexical entries). 
Thus our mapping process has two distinct compo-
nents: 
 
1. manual construction of a DATR representation 
of the morphosyntactic class and realization in-
formation from the printed paradigm tables; 
 
2. automatic construction of the individual lexical 
entries from the electronic dictionary data. 
 
In practice we also introduce a third component, 
interfacing between the morphosyntactic classes 
and the automatic entries. As we discuss below, 
this gives us increased flexibility in the way we 
interpret the Zaliznjak data.  
The information in Zaliznjak's dictionary in-
cludes a fair number of subregular and idiosyn-
cratic cases. The target representation, DATR, is 
specifically designed to support such situations, 
providing concise representation of hierarchically 
organized lexicons containing generalizations and 
exceptions. We have already a formal theoretical 
model of Russian morphology (Corbett and Fraser 
1993; Brown, Corbett, Fraser, Hippisley and Tim-
berlake 1996; Brown 1998) which underlies our 
approach. In addition, as we have a frequency 
based resource to check against (Brown, Corbett 
and Fraser 1995; Brown, Hippisley, Corbett and 
Fraser 1995), we are in a good position to check 
the accuracy of our automatic creation of lexical 
entries for the high frequency, least regular cases. 
The same framework can also be used to capture 
generalisations across languages (cf. Cahill and 
Gazdar 1999; Tiberius 2001), but this is not our 
current goal. 
2.2 The hand-crafted realization         
component 
Zaliznjak does not use the traditional division of 
words into declension types in his dictionary, but 
divides nouns into types according to the last 
grapheme of the stem. (Ilola and Mustajoki 
1989:9) For example, he distinguishes eight types 
for masculine nouns numbered 1 to 8. These mor-
phological types are then further divided according 
to stress. The masculine noun types can occur with 
six different stress patterns indicated by subcatego-
ries A to F. Thus the most basic masculine noun 
classes might be named M 1A, M 3C, etc.  
Special characters are used to further character-
ize the different morphological types. For instance, 
types with an * indicate the presence of a fleeting 
vowel such as in ?????? 'father-in-law (husband?s 
father)' which has the instrumental ???????.  Ani-
macy is indicated in combination with gender, so 
that a class such as MO 1*A is masculine, animate, 
type 1, stress pattern A with a fleeting vowel. 
This information for each lexical entry is used to 
refer to a table at the beginning of the dictionary 
which gives an example of the inflectional forms. 
These tables form the basis of a hand-crafted 
DATR theory in which each type is represented by 
a node in the DATR inheritance hierarchy.  This 
results in a hierarchical structure of noun classes,  
part of which is shown here: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Extract of the DATR hierarchy 
 
In each node, definitions of morphosyntactic reali-
zations specific to that noun class are given. In-
formation that is shared between (or default for) 
classes is inherited from the parent node. A small 
fragment of the theory is provided here:2 
 
NOMINAL: 
   <mor> == "<stem>" "<mor suffix>". 
                                                          
2 The DATR code is slightly simplified for expository purposes.  Note that the 
code is written to reflect Zaliznjak?s system.  The main goal has not been ele-
gance and economy of representation. For theoretically-driven inheritance 
representations of Russian morphology using DATR see Corbett and Fraser 
(1993), Fraser and Corbett (1995),  and Brown (1998). 
 
NOUN: 
    <> == NOMINAL 
    <mor suffix pl dat> == ?? 
    <mor suffix pl instr> == ??? 
    <mor suffix pl loc> == ??. 
 
NOUN_M: 
    <> == NOUN 
    <syn gender> == masculine 
    <syn animacy> == inanimate. 
 
NOUN_M_1A: 
 <> == NOUN_M  
 <mor suffix sg nom> == Null 
 <mor suffix sg gen> == ? 
 <mor suffix sg dat> == ? 
 <mor suffix sg acc> ==  
"<mor suffix sg nom>" 
 <mor suffix sg instr> == ?? 
 <mor suffix sg loc> == ? 
 <mor suffix pl nom> == ? 
 <mor suffix pl gen> == ?? 
 <mor suffix pl acc> ==  
"<mor suffix pl nom>". 
 
Here, NOMINAL defines the morphotactics of Rus-
sian nominals (nouns and adjectives), comprising a 
stem followed by a suffix that realizes the morpho-
logical features. NOUN inherits this definition and 
defines three plural suffixes that are generally 
shared between nouns, NOUN_M adds specific syn-
tactic features and finally NOUN_M_1A fills out the 
rest of the possible suffixes. Notice that <stem> 
is not defined in this theory ? it will be determined 
on a per-lexical entry basis from the automatically 
generated entries described below. Notice also the 
syncretic definitions for suffixes associated with 
sg acc and pl acc in terms of their nominative 
counterparts for inanimate nouns ? for a more de-
tailed discussion of the techniques used for repre-
senting such a syncretism, see Corbett and Fraser 
(1993:131) and Brown (1998:154-155). 
Classes of feminine and neuter nouns are han-
dled similarly; for feminine nouns, eight types and 
nine different stress patterns are identified, 
whereas for neuter nouns eight types and six stress 
patterns are distinguished. In addition, most of 
these types are found with both animate and in-
animate nouns, and in the DATR theory, two noun 
classes are distinguished for each type occurring 
with both animate and inanimate nouns. In total 
NOMINAL 
NOUN 
NOUN_M NOUN_MO NOUN_F .  .  . 
 NOUN_M_1A 
about 100 different noun classes are distinguished 
per gender in the DATR theory. 
In order to make use of this theory, a lexical en-
try needs to inherit from the node representing its 
noun class and provide the specific morphotactic 
elements associated with the class. So for example, 
a possible definition for ?????? 'lamp shade' 
might be: 
 
??????: 
<> == NOUN_M_1A 
<stem> == ??????. 
 
From this definition, plus the preceding example 
fragment, the standard inference rules of DATR 
allow all the relevant inflectional forms to be de-
rived: 
 
??????: 
<mor sg nom> = ?????? 
 <mor sg gen> = ?????? ? 
 <mor sg dat> = ?????? ? 
 <mor sg acc> = ?????? 
 <mor sg instr> = ?????? ?? 
 <mor sg loc> = ?????? ? 
 <mor pl nom> = ?????? ? 
 <mor pl gen> = ?????? ?? 
<mor pl dat> = ?????? ?? 
    <mor pl acc> = ?????? ? 
<mor pl instr> = ?????? ??? 
<mor pl loc> = ?????? ??. 
 
Note that stress is not currently indicated in the 
derived forms. Our research involves the morpho-
syntactic analysis of written text which generally 
does not mark stress. However, as the distinctions 
related to stress that are made in Zaliznjak (1977) 
have been kept in the DATR theory, the stress pat-
terns can easily be used in our analysis of syncre-
tism and frequency. 
2.3 Automatic generation of lexical en-
tries 
In its electronic form, Zaliznjak represents each 
lexical entry as a text string of the sort given here 
for the word ?????? 'lamp shade': 
 
??????    0101 ????<?? ? 1? 
 
Here, the first item is the (uppercase) citation form 
of the word, the second is a line identifier (line 01 
of 01 lines), the third is the word annotated with 
stress information, the fourth is gender/animacy 
information and the fifth morphological type. 
However, inevitably, many of the entries are 
more complex than this in various ways: 
 
1. Entries can spread over several lines, 
requiring textual concatenation of just the 
parts following the line identifier informa-
tion to build the complete entry. 
2. Where inflectional class does not corre-
spond to gender/animacy, it may be speci-
fied separately between angle brackets. For 
example, ??????? ?? <?? 3*?> 
?grandfather? is a masculine noun which 
declines as a feminine noun of type 3*A. 
 
3. Alternative values for stress patterns and 
sometimes classes may be present between 
square brackets. 
4. Additional annotations indicate second 
locative, second genitive, pluralia tantum, 
irregular forms, etc. 
5. Additional comments may be present en-
closed in parentheses. 
6. Other punctuation (commas etc.) may or 
may not be present. 
In order to deliver lexical entry information in the 
form required by the hand-crafted theory, this data 
needs to be parsed and interpreted into the kind of 
format we saw above. A standard approach to this 
task is to use regular expression search and substi-
tute commands to incrementally rewrite the data 
strings into a more uniform format and ultimately 
into the required input. However, DATR itself also 
provides powerful string-rewriting functionality, 
particularly suited for dealing with awkward ex-
ceptional cases, but less efficient for more routine 
rewriting.  
The approach we have taken strikes a balance 
between these two technologies. Initially we use 
regular expression rewriting to achieve a basic 
parse of the input data: joining multiple lines to-
gether, removing duplicate spaces, isolating vari-
ous bracketed expressions, parsing the remaining 
fields and finally mapping into a DATR definition 
for each entry. However this DATR definition is 
very surface-oriented ? little more than a basic 
segmentation of the input data. This process can be 
carried out completely automatically with a fairly 
high accuracy. But in order to link such entries to 
the core morphological classes, further interpreta-
tion of the data fields identified is necessary, and 
this is achieved dynamically in DATR. 
For example, a typical simple lexical entry is the 
lexeme ???????????? ?female aristocrat?. Its 
entry in Zaliznjak is: 
 
   ???????????? 0101 ????????<???? ?? 3*? 
 
In the first phase of processing, this is mapped via 
regular expression search and substitute into a 
DATR node definition as follows: 
 
Z-????????????: 
    <> == ZALNODE 
    <index> == 30 
    <src txt> == ' ... ' 
    <src cit> == '????????????' 
    <src str> == '????????<????' 
    <src gen> == '??' 
    <src cls> == '3*?'. 
 
This node is an instance of the predefined node 
ZALNODE with index number 30 (meaning simply 
that it was the 30th node to be processed in this 
batch). The <src txt> feature (omitted due to 
lack of space) is the whole original source string, 
and the other features provide the key components 
of the entry (cit ? citation, str ? stressed, gen ? 
gender/animacy, cls ? class). 
This is the ?surface level? representation of the 
lexical entry. The DATR node ZALNODE inter-
prets this information to define implicitly a ?deep? 
representation as required by the morphological 
classes, roughly equivalent to this: 
 
Z-????????????: 
    <> == NOUN_FO_3*A 
    <root_begin> == ?????????? 
    <root_end> == ?. 
 
Here, the gender/animacy and class information 
have been combined (and transliterated to Latin 
script) to determine the declension class for this 
form. The stem forms for this class have been de-
termined from the citation form (the morphotactic 
specification for NOUN_FO_3*A indicates what 
components are required ? different from the sim-
pler NOUN_M_1A case above, to allow for the pos-
sible insertion of a fleeting vowel). 
ZALNODE does not actually create a new node 
definition for the deep representation. Rather, ap-
propriate values for deep features are calculated 
dynamically when the declension class code re-
quests them, by rewriting and transforming the 
values provided by the surface form definitions. 
The overall effect is that, just as we saw previ-
ously, the declension class definitions can use this 
information to provide the syntax and all the in-
flected forms for this word: 
 
Z-????????????: 
   <syn gender> = feminine 
   <syn animacy> = animate 
   <mor sg nom> = ?????????? ? ? 
   <mor sg gen> = ?????????? ? ? 
   <mor sg dat> = ?????????? ? ? 
   <mor sg acc> = ?????????? ? ? 
   <mor sg instr> = ?????????? ? ?? 
   <mor sg loc> = ?????????? ? ? 
   <mor pl nom> = ?????????? ? ? 
   <mor pl gen> = ?????????? ? ? 
   <mor pl dat> = ?????????? ? ?? 
   <mor pl acc> = ?????????? ? ? 
   <mor pl instr> = ?????????? ? ??? 
   <mor pl loc> = ?????????? ? ??. 
 
For most of these forms the inflection follows the 
value of <root_begin> and <root_end>. 
Notice, however, that in the genitive and accusa-
tive plural forms, a fleeting vowel, ? in this case, is 
inserted between these two components.  
An example of a more complex lexical entry is 
?????? 'soldier' which is a masculine animate 
noun of type 5*A. This noun has a fleeting vowel 
which appears in the nominative singular ?????? 
(phonologically armejec). The writing system also 
indicates the presence of the phoneme /j/ by the 
use of ? in the other case and number combina-
tions. To deal with this allomorphy, the DATR 
node ZALNODE introduces two values for 
<root_begin> in the ?deep? representation of 
this lexical entry, one which is used in the nomina-
tive singular, i.e. ????, and one which is used for 
all other cases, i.e. ?????. The ?deep? representa-
tion for ?????? looks roughly like this: 
 
Z-??????: 
    <> == NOUN_MO_5*A 
    <root_begin 1> == ???? 
<root_begin> == ????? 
    <root_end> == ?. 
3 The technical framework 
The key technical challenge of this exercise was 
actually rather mundane: we needed to find an en-
vironment or set of environments that would allow 
us to do all the processing required (manual edit-
ing, regular expression search and substitute, 
DATR compilation and dumping) with data that 
included both Latin and Cyrillic script. In addition, 
we wanted the resources we created to be maxi-
mally reusable in other contexts, so a solution in 
line with agreed standards was highly desirable. 
To achieve these goals, we adopted Unicode as 
the standard representation for all our data, and 
identified or adapted tools to work with data in that 
form. Furthermore we used the simplest encoding 
of Unicode in data files, the ?ucs2? encoding, 
which stores each 16 bit Unicode character simply 
as two bytes of data. This is not as compact as 
other encodings (such as ?utf8?) but is supported 
by a wider range of applications, in particular Mi-
crosoft Wordpad. 
3.1 A Unicode version of Zaliznjak 
It is a fairly straightforward task to convert the  
transliteration used in the electronic form of Zal-
iznjak to Unicode Cyrillic, using Microsoft Word 
macros. Disambiguation of the hard and soft signs 
is required for the first field, (the index word field), 
as the + character is used for both symbols. How-
ever, the third field differentiates the hard and soft 
sign and, as the number of lexical items written 
with a hard sign is not great, it is a trivial task to 
check these. The resulting files are then saved as 
plain text (ie ?ucs2?) Unicode files. 
3.2 DATR and Unicode 
The DATR compiler used for this project was the 
Sussex/Brighton DATR compiler, which is written 
in Prolog. The DATR compiler inherits its charac-
ter-level processing from the underlying Prolog 
compiler, so in order to process Unicode DATR it 
was simply necessary to run it in a Prolog system 
capable of handling Unicode, and modify it 
slightly to detect when it was given a Unicode file 
as input. This was achieved using Poplog Prolog,3 
plus a customized version of Sussex/Brighton 
DATR (soon to be released as version 2.10). This 
version also includes new support for batch mode 
processing of DATR theories and a number of 
compiler enhancements for compiling larger 
DATR theories. 
3.3  Editing and search and substitute in 
Unicode 
Unicode files stored in ?ucs2? encoding can be 
conveniently viewed and edited using Microsoft 
Word or Wordpad, the latter being more straight-
forward for the simple text-editing requirements of 
most of the data files involved here. The automatic 
rewriting of Zaliznjak entries required a more so-
phisticated regular expression engine, which we 
obtained by adapting the Poplog editor?s regular 
expression functionality to work with Unicode. 
These functions are particularly powerful in allow-
ing multi-line regular expression matching, so that 
one can match patterns spanning several lines 
(such as Zaliznjak data continuation lines) and re-
write them to a single line. Limited manual editing 
of Unicode using the Poplog editor is also possi-
ble: it can manipulate arbitrary Unicode data, but 
its ability to display non-Latin data is platform de-
pendent, and on our platform (Windows 2000) all 
the Cyrillic characters were displayed as ???. 
4 Current status and future work 
The system described in this paper is still very 
much work-in-progress. The core technologies and 
                                                          
3 See http://www.cs.bham.ac.uk/research/poplog/freepoplog.html. Unicode 
support is only available in version 15.53, although currently it is completely 
undocumented. 
structures of the approach have been developed 
and validated as a viable approach. Population and 
validation of the data is an on-going process, the 
current state of which can be summarized as fol-
lows: 
 
1. The hand-crafted DATR theory for Zalizn-
jak?s morphological classes has been com-
pleted for the noun classes, with adjective 
classes next to be done. Other classes are 
lower priority for the present project. 
2. Automatic compilation of all 98729 
Zanliznjak entries into ?surface? DATR 
nodes is complete but not validated. 
3. Processing of a sample set containing 2062 
entries has been undertaken with the 
following (not fully validated) results: 
 
No. of Zaliznjak entries 2062 100% 
No. of DATR nodes  2000 97% 
Nodes identified as nouns 1192 60% 
Nouns  successfully classi-
fied 
1066 89% 
 
Principal areas for further development include: 
 
1. Completion and validation of noun entries 
2. Extension to adjectives (and possibly 
verbs) 
3. Integration of data from the manually vali-
dated lexicon of 1500 most frequent 
nouns, to improve accuracy, particular for 
irregular forms. 
4. Development of a lemmatizer and tagger 
for Russian using this data. 
 
The last point here deserves further expansion. As 
we discussed in the introduction, the DATR encod-
ing of Zaliznjak is in part the first step towards 
lemmatization and tagging technology for Russian. 
We distinguish lemmatization, that is identifying 
all possible lemmas (plus morphosyntactic fea-
tures) for a word, which can be carried out on the 
word in isolation, from tagging, that is, identifying 
the most likely lemma (plus features) for a word in 
context. The primary aim of the project of which 
this work is a part is to explore ambiguity in lem-
matization and its relationship to frequency. For 
this a high quality lemmatizer is essential.  
In principle, once we have a complete set of in-
flected forms, we could automatically compile it 
into a lemmatizer. However such a lemmatizer 
would be extremely cumbersome to produce and 
use, contain much redundancy and be quite inca-
pable of coping with unknown forms. The ap-
proach we intend to take will exploit the hand-
crafted components of the framework to the full, 
using them to construct recognisers for suffixes 
(and for verbs, prefixes) and identify potential 
roots, and then using the full lexicon to filter and 
validate the resulting candidate analyses (we ex-
pect the recognition process to overgenerate solu-
tions). This will be more compact, probably faster, 
and able to cope with unknown root forms. 
Beyond such a lemmatizer, we are currently in-
vestigating how to combine inheritance-based lexi-
cal representation with traditional part-of-speech 
tagging technology, and hope to apply this work to 
the Zaliznjak data, to deliver a high quality de-
tailed morphosyntactic tagger for Russian texts. 
On the more technological front, current plans 
include: 
 
1. Consolidating Unicode support in DATR 
(extending to the Sicstus Prolog version, 
supporting other file encodings). 
2. Packaging key technologies for wider use. 
3. Delivering the whole Zaliznjak lexicon as 
an XML-based DATR database. 
 
5 Conclusions 
Zaliznjak?s dictionary, both in its book form and 
electronic version, has proved an invaluable tool. 
In this paper we have shown how the classes from 
Zaliznjak can be mapped into a DATR representa-
tion. This representation is a structured lexicon 
from which we can derive all of the associated 
forms for the entries in Zaliznjak. As well as con-
stituting a valuable computation resource for Rus-
sian in its own right, our next step will be to use 
this lexical database as the foundation for high 
quality lemmatization and morphosyntactic tag-
ging software for Russian text. 
Acknowledgements 
The research reported here is supported by the 
Economic and Social Research Council  (UK) un-
der grant RES-000-23-0082 'Paradigms in Use'. 
Their support is gratefully acknowledged.  
Availability 
At the time of writing, the Zaliznjak data files are 
still work in progress, and the tool adaptations (to 
DATR, Poplog etc.) are still custom extensions. 
However, it is our intention to make these re-
sources publically available, as far as is consistent 
with existing licences etc., in the near future. 
References 
Anciaux, Michele. 1991. Word-form Recognition and 
Generation: A Computational Approach to Russian 
Morphology. PhD dissertation, University of 
Washington. 
Brown, Dunstan, Greville Corbett and Norman Fraser. 
1995. rusnoms.dtr ? a fragment for the nominal sys-
tem of Russian. Available from the DATR archive 
http://www.datr.org   
Brown, Dunstan, Andrew Hippisley, Greville Corbett 
and Norman Fraser. 1995. rusnlex.dtr - lexicon of 
frequent Russian noun. Available from the DATR ar-
chive http://www.datr.org 
Brown, Dunstan, Greville Corbett, Norman Fraser, An-
drew Hippisley and Alan Timberlake. 1996. Russian 
noun stress and network morphology. Linguistics  34. 
53-107. 
Brown, Dunstan. 1998. From the General to the Excep-
tional: A Network Morphology Account of Russian 
Nominal Inflection. PhD thesis, University of Surrey. 
Cahill, Lynne and Gerald Gazdar. 1999. The 
POLYLEX architecture: multilingual lexicons for re-
lated languages. Traitement Automatique des Lan-
guages, 40(2):5-23. 
Corbett, Greville G. and Norman M. Fraser. 1993. Net-
work morphology: A DATR account of Russian 
nominal inflection. Journal of Linguistics 29. 113-42. 
Dimitrova, Ludmila, Toma? Erjavec, Nancy Ide, Heiki 
Jaan Kaalep, Vladimir Petkevi?, Dan Tufis. 1998. 
Multext-East: Parallel and Comparable Corpora and 
Lexicons for Six Central and Eastern European Lan-
guages. In Proceedings of COLING-ACL '98. 315-
319. 
Evans, Roger and Gerald Gazdar. 1996. DATR: A Lan-
guage for Lexical Knowledge Representation. Com-
putational Linguistics  22. 167-216. 
Fraser, Norman M. and Greville G. Corbett.  1995. Gen-
der, animacy and declensional class assignment: a 
unified account for Russian. In G. Booij and J. van 
Marle (eds.) Yearbook of Morphology 1994. 
Dordrecht: Kluwer. 123-150.  
Ilola, Eeva & Mustajoki, Arto. 1989. Report on Russian 
Morphology as it appears in Zaliznyak's Grammatical 
Dictionary. Helsinki: Helsinki University Press. 
L?nngren, Lennart (ed.) 1993. ?astotnyj slovar? sovre-
mennogo russkogo jazyka. Uppsala: Uppsala Univer-
sity. (=Studia Slavica Upsaliensia 32). 
Maier, I. 1994. Review of L?nngren (ed.) ?astotnyj 
slovar? sovremennogo russkogo jazyka. Rusistika Se-
godnja 1. 130-136. 
Pavlova, E., Y. Pavlov, R. Sproat, C. Shih and J. van 
Santen. 1997. Bell Laboratories Russian Text-to-
Speech System. In G. Kokkinakis, N. Fakotakis, E. 
Dermatas (eds.) Eurospeech ?97 Proceedings. Vol-
ume 5. 2451 ? 2454. 
Tiberius, Carole. 2001. Architectures for Multilingual 
Lexical Representation. PhD Thesis, ITRI, Univer-
sity of Brighton. 
Vitas, Dusko. 2001. Intex and Slavonic Morphology. In 
Proceedings of the 4th Intex workshop. Bordeaux. 
Available online at: http://grelis.univ-
fcomte.fr/intex/downloads/Dusko Vi-
tas.pdf 
Zaliznjak, A. A. 1977. Grammati?eskij slovar' russkogo 
jazyka. Moscow: Russkij jazyk. 
Zasorina, L. N. 1977. ?astotnyj slovar' russkogo jazyka.  
Moscow: Russkij jazyk. 
 
 
Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 55?62,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Towards a validated model for affective classification of texts
Michel Ge?ne?reux and Roger Evans
Natural Language Technology Group (NLTG)
University of Brighton, United Kingdom
{M.Genereux,R.P.Evans}@brighton.ac.uk
Abstract
In this paper, we present the results of
experiments aiming to validate a two-
dimensional typology of affective states as
a suitable basis for affective classification
of texts. Using a corpus of English weblog
posts, annotated for mood by their authors,
we trained support vector machine binary
classifiers to distinguish texts on the ba-
sis of their affiliation with one region of
the space. We then report on experiments
which go a step further, using four-class
classifiers based on automated scoring of
texts for each dimension of the typology.
Our results indicate that it is possible to
extend the standard binary sentiment anal-
ysis (positive/negative) approach to a two
dimensional model (positive/negative; ac-
tive/passive), and provide some evidence
to support a more fine-grained classifica-
tion along these two axes.
1 Introduction
We are investigating the subjective use of language
in text and the automatic classification of texts ac-
cording to their subjective characteristics, or ?af-
fect?. Our approach is to view affective states
(such as ?happy?, ?angry?) as locations in Osgood?s
Evaluation-Activation (EA) space (Osgood et al ,
1957), and draws on work in psychology which
has a long history of work seeking to construct a
typology of such affective states (Scherer, 1984).
A similar approach has been used more recently
to describe emotional states that are expressed in
speech (Cowie and Cornelius, 2002; Schro?der and
Cowie, 2005). Our overall aim is to determine
the extent to which such a typology can be vali-
dated and applied to the task of text classification
using automatic methods. In this paper we de-
scribe some initial experiments aimed at validating
a basic two dimensional classification of weblog
data, first with Support Vector Machine (SVM)
binary classifiers, then with Pointwise Mutual In-
formation - Information Retrieval (PMI-IR). The
domain of weblog posts is particularly well-suited
for this task given its highly subjective nature and
the availability of data , including data which has
been author-annotated for ?mood?, which is a rea-
sonable approximation of ?affect?.
Recent attempts to classify weblog posts have
shown modest, but consistent improvements over
a 50% baseline, only slightly worse than human
performance (Mishne, 2005). One important mile-
stone is the elaboration of a typology of affec-
tive states. To devise such a typology, our start-
ing point is Figure 1, which is based on a model
of emotion as a multicomponent process (Scherer,
1984). In this model, the distribution of the af-
fective states is the result of analysing similar-
ity judgments by humans for 235 emotion terms1
using cluster-analysis and multidimensional scal-
ing techniques to map out the structure as a two-
dimensional space. The positioning of words is
not so much controversial as fuzzy; an affective
state such as ?angry? to describe facial expression
in speech may have a slightly different location
than an ?angry? weblog post. In this model, the
well-studied ?sentiment? classification is simply a
specific case (left vs. right halves of the space).
The experiments we describe here seek to go be-
yond this basic distinction. They involve an addi-
tional dimension of affect, the activity dimension,
allowing textual data to be classified into four cat-
egories corresponding to each of the four quad-
1Reduced to less than 100 in Figure 1.
55
Figure 1: Typology of affective states based on (Scherer, 1984)
rants in the space. Ultimately, once scores have
been ?promoted? to real measures, classification
can be more precise; for example, a text is not only
negative and passive, it is more precisely ?depres-
sive?. With such a more precise classification one
might, for example, be able to detect individuals
at risk of suicide. In Experiment 1, we use bi-
nary classifiers to investigate how the four quad-
rants defined by the typology hold together, the
assumption being that if the typology is correct,
the classifiers should perform substantially better
than a random baseline. In Experiment 2, we go
a step closer towards a more fine-grained classifi-
cation by evaluating the performance of an unsu-
pervised automated technique for scoring texts on
both axes. Both these experiments are preliminary
? our long term goal is to be able to validate the
whole typology in terms of computationally effec-
tive classification.
2 Corpus
We have collected from Livejournal2 a total of
346723 weblogs (mood-annotated by authors) in
2http://www.livejournal.com.
English, from which almost half are annotated
with a mood belonging to one of the four quad-
rants, described as follows:
Quadrant1 bellicose, tense, alarmed, envious,
hateful, angry, enraged, defiant, annoyed, jealous,
indignant, frustrated, distressed, disgusted, sus-
picious, discontented, bitter, insulted, distrustful,
startled, contemptuous and impatient.
Quadrant2 apathetic, disappointed, miserable,
dissatisfied, taken aback, worried, languid, feel
guilt, ashamed, gloomy, sad, uncomfortable, em-
barrassed, melancholic, depress, desperate, hes-
itant, bored, wavering, droopy, tired, insecured,
anxious, lonely and doubtful.
Quadrant3 feel well, impressed, pleased,
amourous, astonished, glad, content, hopeful,
solemn, attentive, longing, relaxed, serious,
serene, content, at ease, friendly, satisfied,
calm, contemplative, polite, pensive, peaceful,
conscientious, empathic, reverent and sleepy.
Quadrant4 happy, ambitious, amused, adven-
turous, aroused, astonished, triumphant, excited,
56
conceited, self confident, courageous, feeling su-
perior, enthusiastic, light hearthed, determined,
passionate, expectant, interested, joyous and de-
lighted.
In our experiments, we used 15662 from quad-
rant Q1 (see Figure 1), 54940 from Q2, 49779
from Q3 and 35634 from Q4.
3 Experiment 1: Distinguishing the four
Quadrants
Our hypothesis is that the classification of two dis-
joint sets of moods should yield a classification ac-
curacy significantly above a baseline of 50%. To
verify our hypothesis, we conducted a series of ex-
periments using machine learning to classify we-
blog posts according to their mood, each class cor-
responding to one particular quadrant. We used
Support Vector Machines (Joachims, 2001) with
three basic classic features (unigrams, POS and
stems) to classify the posts as belonging to one
quadrant or one of the three others. For each clas-
sification task, we extracted randomly 1000 test-
ing examples, and trained separately with 2000,
4000, 8000 and 16000 examples. In each case, ex-
amples were divided equally among positive and
negative examples3. The set of features used var-
ied for each of these tasks, they were selected by
thresholding each (distinct) training data set, after
removing words (unigrams) from the categories
poor in affective content (prepositions, determin-
ers, etc.). To qualify as a feature, each unigram,
POS or stem had to occur at least three times in
the training data. The value of each feature corre-
sponds to its number of occurence in the training
examples.
3.1 Results
Our hypothesis is that, if the four quadrants de-
picted in Figure 1 are a suitable arrangement for
affective states in the EA space, a classifier should
perform significantly better than chance (50%).
Table 1 shows the results for the binary classifi-
cation of the quadrants. In this table, the first col-
umn identifies the classification task in the form
?P vs N?, where ?P? stands for positive examples
and ?N? for negative examples. The ?Random? row
shows results for selecting positive and negative
examples randomly from all four quadrants. By
3For instance, 1000 = 500 positives from one QUAD-
RANT + 500 negatives among the other three QUAD-
RANTS.
micro-averaging accuracy for the classification of
each quadrant vs all others (rows 10 to 13), we
obtain at least 60% accuracy for the four binary
classifications of the quadrants4. The first six rows
show evidence that each quadrant forms a distinc-
tive whole, as the classifer can easily decide be-
tween any two of them.
Testing Size of training set
1000 examples 2k 4k 8k 16k
Q1 vs Q3 67% 70% 72% 73%
Q2 vs Q4 61% 64% 65% 67%
Q1 vs Q2 64% 66% 68% 69%
Q2 vs Q3 58% 59% 59% 59%
Q3 vs Q4 59% 60% 60% 61%
Q4 vs Q1 69% 72% 73% 75%
Q1+4 vs Q2+3 56% 58% 58% 61%
Q3+4 vs Q1+2 62% 65% 67% 66%
Random 49% 52% 50% 50%
Q1 vs Q2+3+4 67% 72% 72% 73%
Q2 vs Q1+3+4 59% 60% 63% 63%
Q3 vs Q1+2+4 57% 58% 58% 59%
Q4 vs Q1+2+3 60% 63% 65% 65%
Micro-accuracy 61% 64% 65% 65%
Table 1: Accuracy of binary classification
3.2 Analysis of Results
We introduce now table 2 that shows two thresh-
olds of significance (1% and 5%) for the interpre-
tation of current and coming results. For exam-
ple, if we have 1000 trials with each trial having a
probability of success of 0.5, the likelihood of get-
ting at least 53.7% of the trials right is only 1%.
This gives us a baseline to see how significantly
well above chance a classifier performs. The SVM
algorithm has linearly separated the data for each
quadrant according to lexical and POS content (the
features). The most sensible explanation is that the
features for each class (quadrant) are semantically
related, a piece of information which is relevant
for the model (see section 4). It is safe to conclude
that the results cannot be allocated to chance, that
there is something else at work that explains the
4Micro-averaged accuracy is defined as:
?
i (tpi + tni)
?
i (tpi + tni + fpi + fni)
where tp stands for ?true positive?, fn for ?false negative?,
etc.
57
Trials Prob(Success) 1% 5%
1000 0.50 53.7% 52.6%
750 0.50 54.3% 53.1%
500 0.50 55.2% 53.6%
250 0.50 57.2% 55.2%
1000 0.25 28.2% 27.3%
750 0.25 28.7% 27.6%
500 0.25 29.6% 28.2%
250 0.25 31.6% 29.6%
Table 2: Statistical Significance
accuracies consistently well above a baseline, and
this something else is the typology. These results
show that the abstraction offered by the four quad-
rants in the model seems correct. This is also sup-
ported by the observation that the classifier shows
no improvements over the baseline if trained over
a random selection of examples in the entire space.
4 Experiment 2: Classification using
Semantic Orientation from Association
Our next goal is to be able to classify a text accord-
ing to more than four classes (positive/negative,
active/passive), by undertaking multi-category
classification of texts according to particular re-
gions of the space, (such as ?angry?, ?sad?, etc.). In
order to do that we need a scoring system for each
axis. In the following experiments we explore the
use of such scores and give some insights into how
to transform these scores of affect as measures of
affect.
Using binary classifiers, we have already estab-
lished that if we look at the lexical contents of we-
blog posts tagged according to their mood by their
author, these mood classes tend to cluster accord-
ing to a two-dimensional typology defined by their
semantic orientation: positive or negative (evalu-
ation), active or passive (activity). Beyond aca-
demic importance, the typology really becomes of
practical interest if we can classify the posts us-
ing pre-defined automated scores for both axis.
One strategy of scoring is to extract phrases, in-
cluding single words, which are good indicators
of subjectivity in texts, and score them accord-
ing to how they relate or ?associate? to one or the
other extremity of each axis. This strategy, called
Semantic Orientation (SO) from Association (A)
has been used successfully (Turney and Littman,
2003) to classify texts or adjectives of all sorts ac-
cording to their sentiments (in our typology this
corresponds to the evaluation dimension). Ac-
cording to these scores, a text or adjective can be
said to have, for example, a more or less positive
or negative evaluation. We will use this strategy to
go further in the validation of our model of affec-
tive states by scoring also the activity dimension;
to our knowledge, this is the first time this strat-
egy is employed to get (text) scores for dimen-
sions other than evaluation. In SO-A, we score
the strength of the association between an indica-
tor from the text and a set of positive or negative
words (the paradigms Pwords and Nwords) cap-
turing the very positive/active or negative/passive
semantic orientation of the axis poles. To get the
SO-A of a text, we sum over positive scores for
indicators positively related to Pwords and nega-
tively related to Nwords and negative scores for
indicators positively related to Nwords and nega-
tively related to Pwords. In mathematical terms,
the SO-A of a text is:
Text
?
ind
(
Pwords
?
p
A(ind, p) ?
Nwords
?
n
A(ind, n))
where ind stands for indicator. Note that the quan-
tity of Pwords must be equal to Nwords.
To compute A, (Kamps et al , 2004) focus
on the use of lexical relations defined in Word-
Net5 and define a distance measure between two
terms which amounts to the length of the short-
est path that connects the two terms. This strat-
egy is interesting because it constrains all values
to belong to the [-1,+1] range, but can be applied
only to a finite set of indicators and has yet to
be tested for the classification of texts. (Turney
and Littman, 2003) use Pointwise Mutual Infor-
mation - Information Retrieval (PMI-IR); PMI-IR
operates on a wider variety of multi-words indi-
cators, allowing for contextual information to be
taken into account, has been tested extensively on
different types of texts, and the scoring system can
be potentially normalized between [-1,+1], as we
will soon see. PMI (Church and Hanks, 1990) be-
tween two phrases is defined as:
log2
prob(ph1 is near ph2)
prob(ph1) ? prob(ph2)
PMI is positive when two phrases tend to co-occur
and negative when they tend to be in a comple-
mentary distribution. PMI-IR refers to the fact
5http://wordnet.princeton.edu/.
58
that, as in Informtion Retrieval (IR), multiple oc-
currences in the same document count as just one
occurrence: according to (Turney and Littman,
2003), this seems to yield a better measure of
semantic similarity, providing some resistance to
noise. Computing probabilities using hit counts
from IR, this yields to a value for PMI-IR of:
logn
N ? (hits(ph1 NEAR ph2) + 1/N)
(hits(ph1) + 1) ? (hits(ph2) + 1)
where N is the total number of documents in the
corpus. We are going to use this method for com-
puting A in SO-A, which we call SO-PMI-IR. The
configuration depicted in the remaining of this sec-
tion follows mostly (Turney and Littman, 2003).
Smoothing values (1/N and 1) are chosen so that
PMI-IR will be zero for words that are not in the
corpus, two phrases are considered NEAR if they
co-occur within a window of 20 words, and log2has been replaced by logn, since the natural log ismore common in the literature for log-odds ratio
and this makes no difference for the algorithm.
Two crucial aspects of the method are the choice
of indicators to be extracted from the text to be
classified, as well as the sets of positive and neg-
ative words to be used as paradigms for the eval-
uation and activity dimensions. The five part-of-
speech (POS) patterns from (Turney, 2002) were
used for the extraction of indicators, all involving
at least one adjective or adverb. POS tags were
acquired with TreeTagger (Schmid, 1994)6. Ide-
ally, words used as paradigms should be context
insensitive, i.e their semantic orientation is either
always positive or negative. The adjectives good,
nice, excellent, positive, fortunate, correct, supe-
rior and bad, nasty, poor, negative, unfortunate,
wrong, inferior were used as near pure representa-
tions of positive and negative evaluation respec-
tively, while fast, alive, noisy, young and slow,
dead, quiet, old as near pure representations of ac-
tive and passive activity (Summers, 1970).
Departing from (Turney and Littman, 2003),
who uses the Alta Vista advanced search with ap-
proximately 350 millions web pages, we used the
Waterloo corpus7, with approximately 46 millions
pages. To avoid introducing confusing heuristics,
we stick to the configuration described above, but
(Turney and Littman, 2003) have experimented
with different configuation in computing SO-PMI-
IR.
6(Turney and Littman, 2003) uses (Brill, 1994).
7http://canola1.uwaterloo.ca/.
4.1 The Typology and SO-PMI-IR
We now use the typology with an automated scor-
ing method for semantic orientation. The results
are presented in the form of a Confusion Matrix
(CM). In this and the following matrices, the top-
left cell indicates the overall accuracy8, the POS-
itive (ACTive) and NEGative (PASsive) columns
represent the instances in a predicted class, the
P/T column (where present) indicates the average
number of patterns per text (blog post), E/P indi-
cates the average evaluation score per pattern and
A/P indicates the average activity score per pat-
tern. Each row represents the instances in an ac-
tual class9.
First, it is useful to get a clear idea of how
the SO-PMI-IR experimental setup we presented
compares with (Turney and Littman, 2003) on a
human-annotated set of words according to their
evaluation dimension: the General Inquirer (GI,
(Stone, 1966)) lexicon is made of 3596 words
(1614 positives and 1982 negatives)10. Table 3
summarizes the results. (Turney and Littman,
(U) 76.4% POS NEG E/P
POS(1614) 59.3% 40.7% 1.5
NEG(1982) 9.6% 90.4% -4.3
(T) 82.8% POS NEG E/P
POS(1614) 81.2% 18.8% 3.2
NEG(1982) 15.8% 84.2% -3.6
Table 3: CM for the GI: (U)Us and (T)(Turney and
Littman, 2003)
2003) reports an accuracy of 82.8% while clas-
sifying those words, while our experiment yields
an accuracy of 76.4% for the same words. Their
results show that their classifier errs very slightly
towards the negative pole (as shown by the accura-
cies of both predicted classes) and has a very bal-
anced distribution of the word scores (as shown
by the almost equal but opposite in signs values
of E/Ps). This is some evidence that the paradigm
words are appropriate as near pure representations
of positive and negative evaluation. By contrast,
8Recall that table 2 gives an interpretation of the statistical
signifiance of accuracy, with trials ? 750 and Prob(success)
= 0.5.
9For example, in the comparative evaluation shown in ta-
ble 3, our classifier classified 59.3% of the 1614 positive in-
stances as positive and 40.7% as negative, with an average
score of 1.5 per pattern.
10Note that all moods in the typology present in the GI
have the same polarity for evaluation in both, which is some
evidence in favour of the typology.
59
our classifier appears to be more strongly biased
towards the negative pole, probably due to the use
of different corpora. This bias11should be kept in
mind in the interpretation of the results to come.
The second experiment focuses on the words
from the typology. Table 4 shows the results. The
81.1% POS NEG P/T E/P
POS(43) 60.5% 39.5% 1 0.4
NEG(47) 0.0% 100.0% 1 -6.4
66.7% ACT PAS P/T A/P
ACT(39) 33.3% 66.7% 1 -0.9
PAS(51) 7.8% 92.2% 1 -2.9
Table 4: CM for the Typology affective states
value of 1 under P/T reflects the fact that the ex-
periment amounts, in practical terms, to classify-
ing the annotation of the post (a single word). For
the evaluation dimension, there is another shift to-
wards the negative pole of the axis, which suggests
that words in the typology are distributed not ex-
actly as shown on figure 1, but instead appear to
have a true location shifted towards the negative
pole. The activity dimension also appear to have
a negative (i.e passive) bias. There are two main
possible reasons for that: words in the typology
should be shifted towards the passive pole (as in
the evaluation case), or the paradigm words for the
passive pole are not pure representations of the ex-
tremity of the pole 12.
Having established that our classifier has a neg-
ative bias for both axes, we now turn to the classifi-
cation of the quadrants per se. In the next section,
we used SO-PMI-IR to classify 1000 randomnly
selected blog posts from our corpus, i.e 250 in
each of the four quadrants. Some of these posts
were found to have no pattern and were therefore
not classified, which means that less than 1000
posts were actually classified in each experiment.
We also report on the classification of an impor-
tant subcategory of these moods called the Big Six
emotions.
11Bias can be introduced by the use of a small corpus, inad-
equate paradigm words or typology. In practice, a quick fix
for neutralizing bias would be to normalize the SO-PMI-IR
values by subtracting the average. This work aims at tuning
the model to remove bias introduced by unsound paradigm
words or typology.
12At the time of experimenting, we were not aware
of an equivalent of the GI to independently verify our
paradigm words for activity, but one reviewer pointed out
such a resource, see http://www.wjh.harvard.edu/
?inquirer/spreadsheet_guide.htm.
4.2 Results
Of the 1000 blog posts, there were 938 with at
least one pattern. Table 5 shows the accuracy for
the classification of these posts.
56.8% POS NEG P/T E/P
POS(475) 76.2% 23.8% 10 5.2
NEG(463) 63.1% 36.9% 9 3.5
51.8% ACT PAS P/T A/P
ACT(461) 20.6% 79.4% 8 -4.3
PAS(477) 18.0% 82.0% 11 -4.2
Table 5: CM for all Moods
An important set of emotions found in the liter-
ature (Ekman, 1972) has been termed the Big Six.
These emotions are fear, anger, happiness, sad-
ness, surprise and disgust. We have used a mini-
mally extended set, adding love and desire (Cowie
and Cornelius, 2002), to cover all four quadrants
(we called this set the Big Eight). Fear, anger and
disgust belong to quadrant 1, sadness and surprise
(we have taken it to be a synonym of ?taken aback?
in the typology) belong to quadrant 2, love and
desire (taken to be synonyms of ?amorous? and
?longing? in the typology) belong to quadrant 3
and happy to quadrant 4. Table 6 shows the results
for the classification of the blog posts that were
tagged with one of these emotions. This amounts
to classifying the posts containing only the Big
Eight affective states.
59.0% POS NEG P/T E/P
POS(467) 72.4% 27.6% 9 5.1
NEG(351) 58.7% 41.3% 6 2.3
54.9% ACT PAS P/T A/P
ACT(357) 23.8% 76.2% 8 -4.4
PAS(461) 21.0% 79.0% 8 -4.6
Table 6: CM for the Big Eight
In the remaining two experiments, blog posts
have been classifed using a discrete scoring sys-
tem. Disregarding the real value of SO, each pat-
tern was scored with a value of +1 for a positive
score and -1 for a negative score. This amounts to
counting the number of patterns on each side and
has the advantage of providing a normalized value
for E/T and A/T between -1 and +1. Normalized
values are the first step towards a measure of af-
fect, not merely a score, in the sense that it gives
an estimate of the strength of affect. We have not
60
classified the posts for which the resulting score
was zero, which means that even fewer posts (741)
than the previous experiment were actually evalu-
ated. Table 7 shows the results for all moods and
table 8 for the Big Eight.
55.7% POS NEG P/T E/P
POS(374) 53.2% 46.8% 11 0.03
NEG(367) 41.7% 58.3% 9 -0.11
53.3% ACT PAS P/T A/P
ACT(357) 21.8% 78.2% 8 -0.3
PAS(384) 17.4% 82.6% 12 -0.34
Table 7: CM for all Moods: Discrete scoring
59.8% POS NEG P/T E/P
POS(373) 52.3% 47.7% 10 0.01
NEG(354) 32.2% 67.8% 9 -0.2
52.8% ACT PAS P/T A/P
ACT(361) 25.8% 74.2% 10 -0.3
PAS(366) 20.5% 79.5% 9 -0.4
Table 8: CM for the Big Eight: Discrete scoring
4.3 Analysis of Results
Our concerns about the paradigm words for eval-
uating the activity dimension are clearly revealed
in the classification results. The classifier shows a
heavy negative (passive) bias in all experiments.
The overall accuracy for activity is consistently
below that for evaluation: three of them are not
statistically significant at 1% (51.8%, 53.3% and
52.8%) and two at even 5% (51.8% and 52.8%).
The classifier appears particularly confused in ta-
ble 5, averaging a score for active posts (-4.3)
smaller than for passive posts (-4.2). It is not
impossible that the moods present in the typol-
ogy may have to be shifted towards the passive
dimension, but further research should look first
at finding better paradigm words for activity. A
good starting point for the calibration of the clas-
sifier for activity is the creation of a list of human-
annotated words for activity, comparable in size to
the GI list, combined with an experiment similar
to the one for which results are reported in table 3.
With regards to the evaluation dimension, ta-
bles 5 and 6 reveal a positive bias (despite having a
classifier which has a ?built-in? negative bias, see
section 4.1). Possible explanations for this phe-
nomenon include the use of irony by people in
negative posts, blogs which are expressed in more
positive terms than their annotation would suggest,
and failure to detect ?negative? contexts for pat-
terns ? one example of the latter is provided in
table 9. This phenomena appears to be alleviated
Mood: bored (evaluation-)
Post: gah!! i need new music, any
suggestions? by the way,
GOOD MUSIC.
Patterns: new music [JJ NN] +4.38
GOOD MUSIC [JJ NN] +53.40
Average SO: +57.78 (evaluation+)
Table 9: Missclassified post
by the use of discrete scores (see tables 7 and 8).
One way of refining the scoring system is to re-
duce the effect of scoring antonyms as high as syn-
onyms by not counting co-occurences in the cor-
pus where the word ?not? is in the neighbourhood
(Turney, 2001). Also,
The long-term goal of this research is to be
able to classify texts by locating their normal-
ized scores for evaluation and activity between
-1 and +1, and we have suggested a simple
method of achieving that by averaging over dis-
crete scores. However, by combining individual
results for evaluation and activity for each post13,
we can already classify text into one of the four
quadrants, and we can expect the average accuracy
of this classification to be approximately the prod-
uct of the accuracy for each dimension. Table 10
shows the results for the classification directly into
quadrants of the 727 posts already classified into
halves (E?, A?) in table 8. The overall accuracy
is 31.1% (expected accuracy is 59.8% * 52.8% =
31.6%). There are biases towards Q2 and Q3, but
no clear cases of confusion between two or more
classes.
31.1% Q1 Q2 Q3 Q4
Q1(180) 21.1% 47.8% 22.2% 8.9%
Q2(174) 15.5% 51.1% 25.3% 8.0%
Q3(192) 9.9% 42.2% 40.1% 7.8%
Q4(181) 9.4% 33.7% 44.8% 12.2%
Table 10: CM for Big Eight: Discrete scoring
Finally, our experiments show no correlation
between the length of a post (in number of pat-
terns) and the accuracy of the classification.
13For example, a post with E- and A+ would be classified
in Q1.
61
5 Conclusion and Future Work
In this paper, we have used a machine learning ap-
proach to show that there is a relation between the
semantic content of texts and the affective state
they (wish to) convey, so that a typology of affec-
tive states based on semantic association is a good
description of the distribution of affect in a two-
dimensional space. Using automated methods to
score semantic association, we have demonstrated
a method to compute semantic orientation on both
dimensions, giving some insights into how to go
beyond the customary ?sentiment? analysis. In the
classification experiments, accuracies were always
above a random baseline, although not always sta-
tistically significant. To improve the typology and
the accuracies of classifiers based on it, a better
calibration of the activity axis is the most press-
ing task. Our next steps are experiments aiming
at refining the translation of scores to normalized
measures, so that individual affects can be distin-
guished within a single quadrant. Other interest-
ing avenues are studies investigating how well the
typology can be ported to other textual data do-
mains, the inclusion of a ?neutral? tag, and the
treatment of texts with multiple affects.
Finally, the domain of weblog posts is attractive
because of the easy access to annotated data, but
we have found through our experiments that the
content is very noisy, annotation is not always con-
sistent among ?bloggers?, and therefore classifica-
tion is difficult. We should not underestimate the
positive effects that cleaner data, consistent tag-
ging and access to bigger corpora would have on
the accuracy of the classifier.
Acknowledgement
This work was partially funded by the European
Commission through the Network of Excellence
EPOCH (?Excellence in Processing Open Cultural
Heritage?). Thanks to Peter Turney for the provi-
sion of access to the Waterloo MultiText System.
References
Eric Brill. 1994. Some advances in transformation-
based part of speech tagging. Proc. of 12th National
Conference on AI. pp. 722-727. Menlo Park, CA:
AAAI Press.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics. Vol. 16, No 1.
pages 22?29, MIT Press, Cambridge, MA, USA.
Roddy Cowie and Randolph R. Cornelius. 2002. De-
scribing the emotional states that are expressed in
speech. Speech Communication 1228. Elsevier Sci-
ence B.V.. 20 June 2002, 28 pages.
Paul Ekman. 1972. Universal and cultural differences
in facial expression of emotion. J.K. Cole (Eds),
Nebraska Symposium on Motivation. pp 207-282.
Lincoln, University of Nebraska Press.
Thorsten Joachims. 2001. Learning to Classify Text
Using Support Vector Machines. Kluwer Academic
Publishers.
Jaap Kamps and Robert J. Mokken and Maarten Marx
and Maarten de Rijke. 2004. Using WordNet to
measure semantic orientation of adjectives. Proc.
of LREC 2004. Vol. IV, pages 1115-1118.
Gilad Mishne. 2005. Experiments with mood classifi-
cation in blog posts. In Style2005 - the 1st Work-
shop on Stylistic Analysis Of Text For Information
Access, at SIGIR 2005.
Charles E. Osgood, George J. Suci, and Percy H. Tan-
nenbaum. 1957. The Measurement of Meaning.
University of Illinois.
Klaus R. Scherer. 1984. Emotion as a Multicompo-
nent Process: A model and some cross-cultural data.
In P. Shaver (Ed.) Review of Personality and Social
Psych. Vol. 5 (pp. 37-63). Beverley Hills, CA: Sage.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In International Conf. on New
Methods in Language Processing. Manchester UK.
Marc Schro?der and Roddy Cowie. 2005. Towards
emotion-sensitive multimodal interfaces. Invitated
talk at the Workshop on ?Adapting the interaction
style to affective factors? pp. 235-253. User Mod-
elling 2005, July 25, Edinburgh.
Philip J. Stone and Dexter C. Dunphy and Marshall S.
Smith and Daniel M. Ogilvie. 1966. The General
Inquirer: A Computer Approach to Content Anal-
ysis. MIT Press. http://www.webuse.umd.
edu:9090/.
Gene F. Summers. 1970. Attitude measurement.
Chicago: Rand McNally. pp. 235-253.
Peter Turney. 2001. Mining the Web for Syn-
onyms: PMI-IR versus LSA on TOEFL. Eu-
ropean Conference on Machine Learning.
pp 491?502. citeseer.nj.nec.com/
turney01mining.html.
Peter D. Turney. 2002. Thumbs Up or Thumbs
Down? Semantic Orientation Applied to Unsuper-
vised Classification of Reviews. Proc. of the ACL
2002. Philadelphia, USA. July 8-10, 2002, pp 417-
424.
Peter D. Turney and Michael L. Littman. 2003. Mea-
suring praise and criticism: Inference of semantic
orientation from association. ACM Trans. Inf. Syst.
21(4):315346.
62
Reinterpretation of an existing?NLG system in a Generic Generation 
Architecture 
L. Cahill, C. Doran~ R. Evans, C. Meilish, D. Paiva,:M. Reape, D. Scott,, N. Tipper 
.Universities of Brighton and Edinburgh. 
Email rags@itri, brighton, ac. uk 
Abstract 
The RAGS project aims to define a reference ar- 
chitecture for Natural Language Generation (NLG) 
systems. Currently the major part of this archi- 
tecture consists of a set of datatype definitions for 
specifying the input and output formats for mod- 
ules within NLG systems. In this paper we describe 
our efforts to reinterpret an existing NLG system in 
terms of these definitions. The system chosen was 
the Caption Generation System. 
2. Which aspects of the RAGS repertoire would 
: . . . .  . . . .  - .... -,.= ., ~,~,aemaltybe'requireti~ftrr~strch~a-~reinterpretation; 
which would be unnecessary and which addi- 
tions to the RAGS repertoire would be moti- 
vated. 
1 Introduction 
The RAGS project ~ aims to define a reference ar- 
chitecture for natural anguage generation systems. 
Currently the major part of this architecture consists 
of a set of datatype definitions for specifying the 
input and output formats for modules within NLG 
systems. The intention is that such representations 
can be used to assist in reusability of components 
of NLG systems. System components that adhere 
to these representations, or use a format hat can be 
translated into such representations relatively eas- 
ily, can then, in principle, be substituted into other 
systems. Also, individual components could be de- 
veloped without the need for a complete system if 
datasets, based on the representations, were made 
available. 
In this paper we describe an attempt to reinterpret 
an existing NLG system in terms of the RAGS data 
definitions. The point of this exercise was to lem-n: 
1. Whether these data structures were sufficient 
to describe the input and output functionality 
of an existing, independently developed, ap- 
3. Whether studying the system would generate 
good ideas about possible reusable generation 
modules that could be developed. 
In this exercise it was important o choose a sys- 
tem that had been developed by people outside the 
RAGS project. Equally, it was important o have 
sufficient clear information about the system in the 
available literature, and/or by means of personal 
contact with the developers. The system chosen was 
the Caption Generation System (Mittal et al, 1995; 
Mittal et al, 1998) 3. This system was chosen be- 
cause, as well as fulfilling the criteria above, it ap- 
peared to be a relatively simple pipeline, thus avoid- 
ing complex control issues, with individual modules 
performing the varied linguistic tasks that the RAGS 
data structures had been designed to handle. 
The reinterpretation exercise took the form of 
coming up with an account of how the interfaces 
to the CGS modules corresponded to the RAGS 
model and reimplementing a working version of 
each module (apart from Text Planning and Realisa- 
tion) which was tested to ensure that, given appro- 
priate input, its output was correct (i.e. conforming 
to the global account) on key examples. Naturally, 
given the scope of this exercise, we had to gloss over 
some interesting implementational issues. The aim 
was not to produce a complete system or a system 
as good as CGS, but merely to demonstrate hat the 
broad functionality of the system could be repro- 
plied 2 NLG system. 
? Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran.?mitre, org. 
tThis work was supported by ESPRC grants GR/L77041 
(Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Ar- 
chitecture for Generation Systems. 
-'See (Paiva, 1998) for a definition of applied in this specific 
context. 
" . -ducedwithin:the RAGS .structures. 
In this paper we first describe the RAGS data 
structures. We then describe the CGS system 
3In addition to these published sources, we were greatly 
helped by the developers of the system who gave us the ben- 
efit of their own expertise as well as access to the original code 
of the system and a technical report hat included implementa- 
tional details such as system traces. 
69 
followed by our reinterpretation of the system in Abstract Rhetorical Abstract Rhetorical Repre- 
RAGS terms. Finally we discuss,, the :implications:. :. -._..sentations ,are--tree-structures with,rhetorical .rela- 
for RAGS of this exercise, tions at the internal nodes and Abstract Rhetorical 
2 The RAGS datatypes  
The RAGS project initially set out to develop a ref- 
erence architecture based on the three-stage pipeline 
suggested by Reiter (Reiter, 1994). However, a 
trees or Abstract Semantic Representations at the 
leaves. 
Rhetorical Abstract Rhetorical Representations 
are viewed as descriptions of sets of possible 
Rhetorical Representations. Each one may be trans- 
detailed analysis of existing applied NLG systems formed into some subset of the possible Rhetori- 
(Cahill and Reape~_~ l:998}:suggested~,that~ttch.an~ ar -~: ~<.eaLReprese, ntations by,,means ~ofa,set..o_f~.petmitted 
chitecture was not specific enough and not closely transformations, e.g. reversing the order of nucleus 
enough adhered to by the majority of the systems 
surveyed for this to be used as the basis of the archi- 
tecture. 
The abstract functionality of a generation system 
can be specified without specific reference to pro- 
cessing. The RAGS approach to this is to develop a 
data model, that is, to define the functional modules 
entirely in terms of the datatypes they manipulate 
and the operations they can perform on them. On 
top of such a model, more specific process models 
can be created in terms of constraints on the order 
and level of instantiation of different ypes of data in 
the data model. A 'rational reconstnaction' of some 
pipeline model might then be produced, but other 
process models would also be possible. 
The RAGS levels of representation are as fol- 
lows4: 
Conceptual The conceptual level of representa- 
tion is defined only indirectly through an API via 
which a knowledge base (providing the content 
from which generation takes place) can be viewed 
as if it were defined in a simple KL-ONE (Brach- 
man and Schmolze, 1985) like system. 
Abstract Semantic Abstract semantic representa- 
tions are the first level at which semantic predicates 
are associated with arguments. At this level, seman- 
tic predicates and roles are those used in the API to 
query the knowledge base and arguments are knowl- 
edge base entities. 
Semantic (Concrete) semantic representations 
provide a complete notation for "logical forms" 
where there is no longer any reference to ,the knowl- 
edge base. The representations are based on sys- 
tems such as SPL (Kasper, 1989) and DRT (Kamp 
and Reyle, 1993). 
4More details can be found in (Cahill et 
al., 1999) and at the RAGS project web site: 
ht tp  : / /www.  i t r i  . b r ighton ,  ac. uk/rags.  
and satellite or changing the rhetorical relation to 
one within a permitted set. 
Abstract Document Document structure defines 
the linear ordering of the constituents of the Rhetor- 
ical Representation with a POSITION feature, as 
well as two other features, TEXT-LEVEL, which 
takes values such as paragraph or sentence; and 
LAYOUT, which takes values such as wrapped-text 
and vertical list. It takes the form of a tree, usu- 
ally, but not necessarily, isomorphic to the Rhetor- 
ical Representation a d linked to it, but with these 
three features at the nodes instead of rhetorical rela- 
tions. 
Abstract Syntactic Abstract Syntactic Represen- 
tations capture high-level aspects of syntactic struc- 
ture in terms of notions such as lexical head, speci- 
fiers, modifiers and complements. This level of rep- 
resentation is compatible with approaches such as 
LFG f-structure, HPSG and Meteer's Text Structure. 
3 Partial and Mixed Representations 
For all of the RAGS levels partial representations 
are possible. Without this, it is not possible for a 
module to pass any result to another until that re- 
sult is completely determined, and this would im- 
pose an unwanted bias towards simple pipeline ar- 
chitectures into the model. There are many cases 
in NLG where a representation is built collabora- 
tively by several modules. For instance, many sys- 
tems have a referring expression generation module 
whose task is to complete a semantic representation 
which lacks those structures which will be realised 
as NPs. Such a functionality cannot be described 
unless partially complete semantic representations 
can be communicated. 
In addition, mixed representations are possible, 
where (possibly partial) representations at several 
levels are combined with explicit links between the 
elements. Many NLG modules have to be sensi- 
70 
tive to a number of levels at once (consider, for 
.......... instance, -aggregatiomxeferring,expmssion.,genera- 
tion and lexicalisation, all of which need to take 
into account rhetorical, semantic and syntactic on- 
straints). The input to most reusable realisation sys- 
tems is also best viewed as a mixture of semantic 
and abstract syntactic information. 
The extra flexibility of having partial and mixed 
representations turned out to be vital in the recon- 
struction of the CGS system. (Mellish et al, 2000). 
4 The CGS system 
The Caption Generation System (CGS) generates 
explanatory captions of graphical presentations (2- 
D charts and graphs). Its architecture is a pipeline 
with several modules, shown in the left hand part of 
Figure 1. An example of a diagram and its accom- 
panying text are given in Figure 2. The propositions 
are numbered for ease of reference throughout the 
paper. 
The input to CGS is a picture representation 
(graphical elements and its mapping from the data 
set) generated by SAGE plus its complexity metric. 
The text planning module (Moore and Paris (1993)) 
plans an explanation i  terms of high level discourse 
goals. The output of the planner is a partially or- 
dered plan with speech-acts as leaves. 
The ordering module receives as input the dis- 
course plan with links specifying the ordering re- 
lations between sub-trees and specifies an order for 
them based on heuristics uch as that the description 
should be done from left to right in the visual space. 
The aggregation module "only conjoins pairs of 
contiguous propositions about the same grapheme 
type 5 in the same space" (Mittai et al, 1999) and 
inserts cue phrases compatible with the propositions 
e o ( .=., "whereas" for contrastive ones). The internal 
order of the sentence constituents i determined by 
the centering module using an extension of the cen- 
tering theory of Grosz and colleagues (Grosz et al, 
1995). 
The referring expression module uses Date and 
Reiter's (Dale and Reiter, 1995) algorithm to con- 
struct the set of attributes that can uniquely identify 
a referent. There are'two, situations where the text 
planning module helps specifically in the generation 
of referring expressions: (1) when the complexity 
for expressing a graphic demands an example and 
5"Graphemes are the basic building blocks for constructing 
pictures. Marks, text, lines and bars are some of the different 
grapheme classes available in SAGE." (IVlittal et al, 1999). 
CGS architecture 
SAGE 
RAGS representations 
I I I  I I I  IV  V 
I II HI  IV  V 
? I I I  I I I  IV  " V . 
I I I  In  IV  v 
l -  .......... I /11  
1 It  I I I  IV V 
l -  .......... 
I 11 11I IV V 
.......... III1  
I I I  HI  IV  V 
; "  .......... I I I I I  
FUF 
Figure 1: A RAGS view of the CGS system. The 
labels for the RAGS representations refer to the fol- 
lowing: I = conceptual; II = semantic; III = rhetori- 
cal; IV = document; V = syntactic. 
it signals this both to SAGE (for highlighting the 
corresponding grapheme) and to the rest of the text 
generation modules; and (2) when in a specific sit- 
uation the referring algorithm would need several 
interactions for detecting that an entity is unique in 
? a certain visual space and.the planning could detect 
it in the construction of the description of this space. 
When this occurs, the text planner "circumvents he 
problem for the:.referring ,expression :module at the 
planning stage itself, processing the speech-acts ap- 
propriately to avoid this situation completely". 
After lexicalisation, which adds lexeme and ma- 
jor category information, the resulting functional 
descriptions are passed to the FUF/SURGE realiser 
that generates texts like the caption of Figure 2. 
71 
\ [ \ ]  
O 
te l  
O 
IZl 
ZS:3 
I21 ,:7-. ,,S . . . .  ; . . . .  .' ? 
O ~ ~Ipc~ q~L~ 
\] 
I 
\] 
=::::::;=a___.,____.__,_______~ 
. ,  , : ,  ; .  . ,  
Figure 2: (1) These two charts present information about house sales from data-set ts-1740. (2) In the two 
charts, the y-axis indicates the houses. (7) In the first chart, the left edge of the bar shows the house's elling 
price whereas (8) the right edge shows the asking price. (3) The horizontal position of the mark shows the 
agency estimate. (4) The color shows the neighbourhood and (5) shape shows the listing agency. (6) Size 
shows the number of rooms. (9) The second chart shows the number of days on the market. 
5 Reinterpretat ion f  CGS in RAGS 
Our reinterpretation f the CGS system defines the 
interfaces between the modules of CGS in terms 
of the RAGS data structures discussed above. In 
this section we discuss the input and output inter- 
faces for each CGS module in turn as well as any 
problems we encountered in mapping the structures 
into RAGS structures. Figure 1 shows the incre- 
mental build-up of the RAGS data levels across 
the pipeline. Here we have collapsed the Abstract 
Rhetorical and Rhetorical and the Abstract Seman- 
tic and Semantic. It is-interesting to note that the 
build up of levels of representation does not tend to 
correspond exactly with module boundaries. 
One of the major issues we faced in' our reinter- 
pretation was where to produce representations (or
partial representations) whose emergence was not 
defined clearly in the descriptions of CGS. For in- 
stance, many decisions about document structure 
are made only implicitly by the system. In most 
cases we have opted to produce all types of repre- 
sentations at the earliest point where they can con- 
ceivably have any content. This means, for instance, 
that our reimplementation assumes an (unimple- 
mented) text planner which produces an Abstract 
Rhetorical Representation with Abstract Semantic 
leaves and an Abstract Document Representation. 
Text Planner The input to the Longbow text plan- 
ner discussed in section 4 above is a representation 
of a picture in SAGE format (which has been an- 
notated to indicate the types of complexity of each 
grapheme) together with a goal, which can typi- 
cally be interpreted as "describe". It outputs an es- 
sentially fiat sequence of plan operators, each of 
which corresponds in the output? text .to .a.speech 
act. In our reinterpretation, we have assumed that 
this fiat structure needs to be translated into an Ab- 
stract Rhetorical Representation with (at least) min- 
imal structure. Such a structure is implicit in the 
plan steps, and our interpretation f the rhetorical 
structure for the example text corresponds closely to 
that of the post-processing trace produced by CGS. 
72 
I .AYOI  FII" * 'upped tel l  
" IU  ,I.EVIZL. p J t l~aph 
~ f ~ I O N :  2 
POSlllON I 
I.AYOtr'I+: -~pped tell 
TEX"T.L~ VEL 
(1) 
POSITION: I POSITION: 2 
LAYOUT: *T~,pl~n.l teat 
"IEXT-LEVEL: + 
(2) 
Po$ : I POSITION: 1 
LAYOUT: -mtpFcd te~t 
. TE.ICr-t.EVEL~ ?
0OSFI-K~N. 2 PosmoN: i 
POSIllON: I PosrnoN: I POsmoN. ~ FoSmON: 4 POSt'nON I PosrnoN: 2 
LAYOUT: ~pp~d lesl LAYOU'T. ~ppe,.f ~xt LAYO\[rF. ~apped lesl LAYOUT: ~+r~pS~d I?xt LAYOUT. ~'?~l~,Od ~est LAYOUT: ~Tappe~ text 
TEXT,LEVEL  7 "II~XT,LEVEI.: ~ "II~XT-LEVEL ? "I I~XT-LEVEL: ? TEXT-LEVEL  "+ TIE~XT-L.EVI:I.: ? 
(3) (4) (5) (6) (7) (8) 
Figure 3: Initial Document Structure 
. . .Z., 
However, we are still not entirely sure 
exactly CGS creates this structure, so 
posed it at the very beginning, onto the 
text planner. 
Already at this stage it is necessary 
about where 
we have im- 
output of the 
to make use 
of mixed RAGS representations. As well as this 
Abstract Rhetorical Representation, the text planner 
has to produce an Abstract Document Representa- 
tion, linked to the Abstract Rhetorical Representa- 
tion. This is already partially ordered - although the 
exact value of POSITION features cannot be speci- 
fied at this stage, the document tree is constructed 
so that propositions are already grouped together. 
In addition, we make explicit certain default infor- 
mation that the CGS leaves implicit at this stage, 
namely, that the LAYOUT feature is always wrapped 
text and that the TEXT-LEVEL feature of the top 
node is always paragraph. 
Ordering The ordering module takes the Abstract 
Document Representation a d the Abstract Rhetor- 
ical Representation as input and outputs an Abstract 
Document Representation with the POSITION fea- 
ture 's  value filled,for all :the nodes, .That is, it fixes. ? 
the linear order of the final output of the speech acts. 
In our example, the ordering is changed so that steps 
7 and 8 are promoted to appear before 3, 4, 5 and 6. 
The resulting structure is shown in figure 36 . 
6In this and the.following diagrams, objects are represented 
by circles with (labelled) arrows indicating the relations be-- 
Aggregation Although aggregation might seem 
like a self-contained process within NLG, in prac- 
tice it can make changes at a number of levels of 
representation a d indeed it may be the last opera- 
tion that has an effect on several levels. The aggre- 
gation module in our reinterpretation thus has the fi- 
nal responsibility to convert an Abstract Rhetorical 
Representation with Abstract Semantic Represen- 
tation leaves into a Rhetorical Representation with 
Semantic Representation leaves. The new Rhetori- 
cal Representation may be different from before as 
a result of speech acts being aggregated but whether 
different or not, it can now be considered final as 
it will no longer be changed by the system. The 
resulting Semantic Representations are no longer 
Abstract because further structure may have been 
determined for arguments to predicates. On the 
other hand, referring expressions have not yet been 
generated and so the (Concrete) Semantic Repre- 
sentations cannot be complete. The reconstruc- 
,.tion createspartia.i Semantic Representations with 
"holes" where the referring expressions (Semantic 
Representations) will be inserted. These "holes" are 
linked back to the knowledge base entities tfiat they 
correspond to. 
Because Aggregation affects text levels, it also af- 
fects the Abstract Document Representation, which 
has its TEXT-LEVEL feature's values all filled at this 
tween them. Dashed arrows indicate links between different 
levels of representation. 
73 
SemRep 
fun(Role,SemRep) 
DR preS  , . mRep 
? AbsSynRep ~ AbsSynRe~ 
/ " \  Y^.Z(" 
FVM (~ ~ ,un(Funs,~gS~c) (,~ ~M (~) lun(Funs.ArgSpec) 
0 ~ 0 0 
? + 
Adjs 
. . - ; . .  
Figure 4: Syntactic representations constructed by Centering 
point. It may also need to change the structure 
of the Abstract Document Representation, for in- 
stance, adding in a node for a sentence above two, 
now aggregated, clause nodes. 
Centering Because Centering comes before Re- 
ferring Expression generation and Realisation, all it 
can do is establish constraints that must be heeded 
by the later modules. At one stage, it seemed as if 
this required communicating a kind of information 
that was not covered by the RAGS datatypes. How- 
ever, the fact that an NP corresponds (or not) to a 
center of some kind can be regarded as a kind of 
abstract syntactic information. The reconstruction 
therefore has the centering module building a partial 
(unconnected) Abstract Syntactic representation for 
each Semantic Representation that will be realised 
as an NP, inserting a feature that specifies whether 
it constitutes a forward- or backward-facing cen- 
ter, approximately following Grosz et al(Grosz et 
al., 1995). This information is used to determine 
whether active or passive voice will be used. An 
example of such a partial Abstract Syntactic Repre- 
sentation is given in Figure 4. 
Referring Expression In our reconstruction of 
the CGS system, we have deviated from reproduc- 
ing the exact functionality for the referring expres- 
sion module and part of the lexical choice module. 
In the CGS system, the referring expression module 
computes association lists which can be used by the 
lexical choice module to construct referring expres- 
sions suitable for realisation. In our reconstruction, 
however, the referring expression module directly 
computes the Semantic Representations of referring 
expressions. 
We believe that this is a good example of a 
case where developing a system with the RAGS 
data structures in mind simplifies the task. There 
are undoubtedly many different ways in which the 
same results could be achieved, and there are many 
(linguistic, engineering etc.) reasons for choosing 
one rather than another. Our particular choice is 
driven by the desire for conceptual simplicity, rather 
than any strictly linguistic or computational motiva- 
tions. We considered for each module which RAGS 
level(s) it contributed to and then implemented it to 
manipulate that (or those) level(s). In this case, that 
meant a much more conceptually simple module 
which just adds information to the Semantic Rep- 
resentations. 
Lexical Choice In CGS, this module performs a 
range of tasks, including what we might call the 
later.stages of_referring expression generation and 
lexical choice, before converting the plan leaves 
into FDs (Functional Descriptions), which serve as 
the input to the FUF/SURGE module. In the re- 
construction, on the other hand, referring expres- 
sions have already been computed and the Rhetor- 
ical Representation, with its now complete Seman- 
tic Representations, needs to be "lexicalised" and 
74 
' ,t ~1  
" .  set 
Figure 5: Combined Semantic and Abstract Syntactic Representation 
translated into FUF/SURGE format. Lexicalisa- 
tion in our terms involves adding the lexeme and 
major category information to the Abstract Syntac- 
tic Representations for the semantic predicates in 
each Semantic Representation. The FUF/SURGE 
input format was regarded as a combination of Se- 
mantic and Abstract Syntactic information, and this 
can easily be produced from the RAGS representa- 
tions. The combined Semantic and Abstract Syn- 
tactic Representations for the plan step "These two 
charts present information about house sales from 
data set ts-1740" is shown in Figure 5. The boxes 
indicate suppressed subgraphs of the lexemes cor- 
responding to the word in the boxes and triangles 
indicate suppressed subgraphs of the two adjuncts. 
6 Conclusions 
The reconstruction of CGS has taken the form of 
working out in detail the RAGS representations 
passed between modules at each stage for a set 
of key examples and reimplementing the modules 
(apart from the Planner and Realiser) in a way that 
correctly reproduces these representations. The ac- 
tual implementation used an incrementally growing 
data store for the RAGS representations which the 
modules accessed in turn, though the passing of data 
could also have been achieved in other ways. 
The fact that the reconstruction has been success- 
ful indicates that the RAGS architecture is broadly 
adequate to redescribe this NLG system: 
? No changes to the existing levels of represen- 
tation were needed, though it was necessary to 
make extensive use of partial and mixed repre- 
sentations. 
o No new levels of representation needed to be 
introduced to capture the inter-module com- 
munication of the system. 
o All of the levels of representation_apart from 
the Conceptual level were used significantly in
the reconstruction. 
In some ways, i t  is unfortunate that none of the 
inter-module interfaces of CGS turned out to use a 
single level of RAGS representation. Given the mo- 
tivation for partial and mixed representations above, 
however, this did not really come as a surprise. It 
may well be that any really useful reusable modules 
for NLG will have to have this complexity. 
75 
In spite of the successful testing of the RAGS data 
model, somedifficulties were encountered: 
* It was difficult to determine the exact nature 
of the representations produced by the Planner, 
though in the end we were able to develop a 
system to automatically translate these into a 
format we could deal with. 
o Although the theoretical model o f  CGS has a 
simple modular structure, in practice the mod- 
ules are very tightly inte-gr~ifed and making-the " 
exact interfaces explicit was not always easy. 
? Referring expression generation requires fur- 
ther access to the "knowledge base" holding 
information about he graphic to be produced. 
This knowledge was only available via interac- 
tions with SAGE, and so it was not possible to 
determine whether the RAGS view of Concep- 
tual Representations was applicable. Our own 
implementation f referring expression gener- 
ation had to work around this problem in a non- 
portable way. 
? It became clear that there are many housekeep- 
ing tasks that an NLG system must perform 
following Lexical Choice in order for the final 
Semantic and Abstract Syntactic Representa- 
tions to be appropriate for direct input to a re- 
alisation system such as FUF. 
o The fact that the system was driving 
FUF/SURGE seems to have had a signif- 
icant effect on the internal representations 
used by CGS. The reconstruction echoed this 
and as a result may not be as general as could 
be desired. 
? Even though CGS only performs imple types 
of Aggregation, it is clear that this is a critical 
module for determining the final form of sev- 
eral levels of representation. 
The division of CGS into modules is different from 
that used in any NLG systems we have previously 
worked on and so has been a useful stimulus to think 
about ways in which reusable modules can be de- 
signed. We envisage reusmgat  least,the reimple- 
mentation of the Centering module in our further 
work. 
References 
R. Brachman and J. Schmolze. 1985. An overview of the KL- 
ONE knowledge representation system. Cognitive Science, 
9:171-216. 
Lynne Cahill and Mike Reape. 1998. Component asks 
in applied NLG .systems . . . .  Technical Report ITR!- 
99-05, ITRI, University of Brighton. obtainable at 
http:/lwww.itri.brighton.ac.uk/projects/rags/. 
Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, 
Daniel Paiva, Mike Reape, Donia Scott, and Neil Tipper. 
1999. In Search of a Reference Architecture for NLG Sys- 
tems. In Proceedings of the 7th European Workshop on Nat- 
ural Language Generation, pages 77-85, Toulouse. 
Robert Dale and Ehud Reiter. 1995. Computational interpre- 
tations of the Gricean maxims in the generation ofreferring 
expressions. Cognitive Science, 18:233-263. 
B J .  Grosz, A/K.J6shil-and S.Weinstein. 1995~ Centering: a 
framework for modelling the local coherence of discourse. 
Computational Linguistics, 21 (2):203-226. 
H. Kamp and U. Reyle. 1993. From discourse to logic: Intro- 
duction to model theoretic semantics of natural language, 
formal logic and discourse representation theory. Kluwer, 
Dordrecht; London. 
R. T. Kasper. 1989. A flexible interface for linking applica- 
tions to penman's sentence generator. In Proceedings of the 
DARPA Speech and Natural Language Workshop, Philadel- 
phia. 
C. Mellish, R. Evans, L. Cahill, C. Doran, D. Paiva, M. Reape, 
D. Scott, and N. Tipper. 2000. A representation forcomplex 
and evolving data dependencies in generation. In Proceed- 
ings of the Applied Natural Language Processing (ANLP- 
NAACL2000) Conference, Seattle. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and G. Carenini. 
1995. Generating explanatory captions for information 
graphics. In Proceedings of the 15th International Joint 
Conference on Artificial Intelligence (IJCAI'95), pages 
1276-1283, Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 1998. 
Describing complex charts in natural anguage: A caption 
generation system. Computational Linguistics, 24(3):431- 
468. 
Daniel Paiva. 1998. A survey of applied natural lan- 
guage generation systems. Technical Report ITRI- 
98-03, Information Technology Research Insti- 
tute (ITRI), University of Brighton. Available at 
http://www.itri.brighton.ac.uk/techreports. 
Ehud Reiter. 1994. Has a consensus NL generation architec- 
ture appeared and is it psycholinguistically p ausible? In 
Proceedings of the Seventh International Workshop on Nat- 
ural Language Generation, pages 163-170, Kennebunkport, 
Maine. 
Acknowledgements 
We would like to thank the numerous people who have 
helped us in this work. The developers of CGS, especially 
Giuseppe Carenini and Vibhu Mittal; the RAGS consultants 
and other colleagues at Brighton and Edinburgh, who have con- 
tributed greatly to our development ofthe representations; and 
finally to the anonymous reviewers of this paper. 
76 
