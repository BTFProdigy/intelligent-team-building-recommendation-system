Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 136?141,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
The DCU-ICTCAS MT system at WMT 2014 on German-English
Translation Task
Liangyou Li
?
, Xiaofeng Wu
?
, Santiago Cort
?
es Va??llo
?
Jun Xie
?
, Andy Way
?
, Qun Liu
??
?
CNGL Centre for Global Intelligent Content, School of Computing
Dublin City University, Dublin 9, Ireland
?
Key Laboratory of Intelligent Information Processing, Institute of Computing Technology
Chinese Academy of Sciences, Beijing, China
{liangyouli,xiaofengwu,scortes,away,qliu}@computing.dcu.ie
xiejun@ict.ac.cn
Abstract
This paper describes the DCU submis-
sion to WMT 2014 on German-English
translation task. Our system uses phrase-
based translation model with several pop-
ular techniques, including Lexicalized
Reordering Model, Operation Sequence
Model and Language Model interpolation.
Our final submission is the result of sys-
tem combination on several systems which
have different pre-processing and align-
ments.
1 Introduction
On the German-English translation task of WMT
2014, we submitted a system which is built with
Moses phrase-based model (Koehn et al., 2007).
For system training, we use all provided
German-English parallel data, and conducted sev-
eral pre-processing steps to clean the data. In ad-
dition, in order to improve the translation quali-
ty, we adopted some popular techniques, includ-
ing three Lexicalized Reordering Models (Axel-
rod et al., 2005; Galley and Manning, 2008), a 9-
gram Operation Sequence Model (Durrani et al.,
2011) and Language Model interpolation on sev-
eral datasets. And then we use system combina-
tion on several systems with different settings to
produce the final outputs.
Our phrase-based systems are tuned with k-best
MIRA (Cherry and Foster, 2012) on development
set. We set the maximum iteration to be 25.
The Language Models in our systems are
trained with SRILM (Stolcke, 2002). We trained
Corpus Filtered Out (%)
Bilingual 7.17
Monolingual (English) 1.05
Table 1: Results of language detection: percentage
of filtered out sentences
a 5-gram model with Kneser-Ney discounting
(Chen and Goodman, 1996).
In the next sections, we will describe our system
in detail. In section 2, we will explain our pre-
processing steps on corpus. Then in section 3, we
will describe some techniques we have tried for
this task and the experiment results. In section 4,
our final configuration for submitted system will
be presented. And we conclude in the last section.
2 Pre-processing
We use all the training data for German-English
translation, including Europarl, News Commen-
tary and Common Crawl. The first thing we no-
ticed is that some Non-German and Non-English
sentences are included in our training data. So we
apply Language Detection (Shuyo, 2010) for both
monolingual and bilingual corpora. For mono-
lingual data (only including English sentences in
our task), we filter out sentences which are detect-
ed as other language with probability more than
0.999995. And for bilingual data, A sentence
pair is filtered out if the language detector detect-
s a different language with probability more than
0.999995 on either the source or the target. The
filtering results are given in Table 1.
In our experiment, German compound word-
s are splitted based on frequency (Koehn and
136
Knight, 2003). In addition, for both monolingual
and bilingual data, we apply tokenization, nor-
malizing punctuation and truecasing using Moses
scripts. For parallel training data, we also filter out
sentence pairs containing more than 80 tokens on
either side and sentence pairs whose length ratio
between source and target side is larger than 3.
3 Techniques
In our preliminary experiments, we take newstest
2013 as our test data and newstest 2008-2012 as
our development data. In total, we have more
than 10,000 sentences for tuning. The tuning step
would be very time-consuming if we use them al-
l. So in this section, we use Feature Decay Al-
gorithm (FDA) (Bic?ici and Yuret, 2014) to select
2000 sentences as our development set. Table 2
shows that system performance does not increase
with larger tuning set and the system using only
2K sentences selected by FDA is better than the
baseline tuned with all the development data.
In this section, alignment model is trained
by MGIZA++ (Gao and Vogel, 2008) with
grow-diag-final-and heuristic function.
And other settings are mostly default values in
Moses.
3.1 Lexicalized Reordering Model
German and English have different word order
which brings a challenge in German-English ma-
chine translation. In our system, we adopt three
Lexicalized Reordering Models (LRMs) for ad-
dressing this problem. They are word-based LRM
(wLRM), phrase-based LRM (pLRM) and hierar-
chal LRM (hLRM).
These three models have different effect on the
translation. Word-based and phrase-based LRMs
are focus on local reordering phenomenon, while
hierarchical LRM could be applied into longer re-
ordering problem. Figure 1 shows the differences
(Galley and Manning, 2008). And Table 3 shows
effectiveness of different LRMs.
In our system based on Moses, we
use wbe-msd-bidirectional-fe,
phrase-msd-bidirectional-fe and
hier-mslr-bidirectional-fe to specify
these three LRMs. From Table 2, we could see
that LRMs significantly improves the translation.
Figure 1: Occurrence of a swap according to
the three orientation models: word-based, phrase-
based, and hierarchical. Black squares represen-
t word alignments, and gray squares represen-
t blocks identified by phrase-extract. In (a), block
b
i
= (e
i
, f
a
i
) is recognized as a swap according to
all three models. In (b), b
i
is not recognized as a
swap by the word-based model. In (c), b
i
is rec-
ognized as a swap only by the hierarchical model.
(Galley and Manning, 2008)
3.2 Operation Sequence Model
The Operation Sequence Model (OSM) (Durrani
et al., 2011) explains the translation procedure as
a linear sequence of operations which generates
source and target sentences in parallel. Durrani
et al. (2011) defined four translation operations:
Generate(X,Y), Continue Source Concept, Gener-
ate Source Only (X) and Generate Identical, as
well as three reordering operations: Insert Gap,
Jump Back(W) and Jump Forward. These oper-
ations are described as follows.
? Generate(X,Y) make the words in Y and the
first word in X added to target and source
string respectively.
? Continue Source Concept adds the word in
the queue from Generate(X,Y) to the source
string.
? Generate Source Only (X) puts X in the
source string at the current position.
? Generate Identical generates the same word
for both sides.
? Insert Gap inserts a gap in the source side for
future use.
? Jump Back (W) makes the position for trans-
lation be the Wth closest gap to the current
position.
? Jump Forward moves the position to the in-
dex after the right-most source word.
137
Systems Tuning Set newstest 2013
Baseline ? 24.1
+FDA ? 24.2
+LRMs 24.0 25.4
+OSM 24.4 26.2
+LM Interpolation 24.6 26.4
+Factored Model ? 25.9
+Sparse Feature 25.6 25.9
+TM Combination 24.1 25.4
+OSM Interpolation 24.4 26.0
Table 2: Preliminary results on tuning set and test set (newstest 2013). All scores on test set are case-
sensitive BLEU[%] scores. And scores on tuning set are case-insensitive BLEU[%] directly from tuning
result. Baseline uses all the data from newstest 2008-2012 for tuning.
Systems Tuning Set (uncased) newstest 2013
Baseline+FDA ? 24.2
+wLRM 23.8 25.1
+pLRM 23.9 25.2
+hLRM 24.0 25.4
+pLRM 23.8 25.1
+hLRM 23.7 25.2
Table 3: System BLEU[%] scores when different LRMs are adopted.
The probability of an operation sequence O =
(o
1
o
2
? ? ? o
J
) is:
p(O) =
J
?
j=1
p(o
j
|o
j?n+1
? ? ? o
j?1
) (1)
where n indicates the number of previous opera-
tions used.
In this paper we train a 9-gram OSM on train-
ing data and integrate this model directly into log-
linear framework (OSM is now available to use
in Moses). Our experiment shows OSM improves
our system by about 0.8 BLEU (see Table 2).
3.3 Language Model Interpolation
In our baseline, Language Model (LM) is trained
on all the monolingual data provided. In this sec-
tion, we try to build a large language model by in-
cluding data from English Gigaword fifth edition
(only taking partial data with size of 1.6G), En-
glish side of UN corpus and English side of 10
9
French-English corpus. Instead of training a s-
ingle model on all data, we interpolate language
models trained on each subset (monolingual data
provided is splitted into three parts: News 2007-
2013, Europarl and News Commentary) by tuning
weights to minimize perplexity of language model
measured on the target side of development set.
In our experiment, after interpolation, the lan-
guage model doesn?t get a much lower perplexity,
but it slightly improves the system, as shown in
Table 2.
3.4 Other Tries
In addition to the techniques mentioned above, we
also try some other approaches. Unfortunately al-
l of these methods described in this section are
non-effective in our experiments. The results are
shown in Table 2.
? Factored Model (Koehn and Hoang, 2007):
We tried to integrate a target POS factored
model into our system with a 9-gram POS
language model to address the problem of
word selection and word order. But ex-
periment doesn?t show improvement. The
English POS is from Stanford POS Tagger
(Toutanova et al., 2003).
? Translation Model Combination: In this ex-
periment, we try to use the method of (Sen-
nrich, 2012) to combine phrase tables or re-
ordering tables from different subsets of data
138
to minimize perplexity measured on develop-
ment set. We try to split the training data in
two ways. One is according to data source,
resulting in three subsets: Europarl, News
Commentary and Common Crawl. Another
one is to use data selection. We use FDA to
select 200K sentence pairs as in-domain data
and the rest as out-domain data. Unfortunate-
ly both experiments failed. In Table 2, we on-
ly report results of phrase table combination
on FDA-based data sets.
? OSM Interpolation: Since OSM in our sys-
tem could be taken as a special language
model, we try to use the idea of interpolation
similar with language model to make OSM
adapted to some data. Training data are s-
plitted into two subsets with FDA. We train
9-gram OSM on each subsets and interpolate
them according to OSM trained on the devel-
opment set.
? Sparse Features: For each source phrase,
there is usually more than one corresponding
translation option. Each different translation
may be optimal in different contexts. Thus
in our systems, similar to (He et al., 2008)
which proposed a Maximum Entropy-based
rule selection for the hierarchical phrase-
based model, features which describe the
context of phrases, are designed to select the
right translation. But different with (He et
al., 2008), we use sparse features to mod-
el the context. And instead of using syn-
tactic POS, we adopt independent POS-like
features: cluster ID of word. In our experi-
ment mkcls was used to cluster words into 50
groups. And all features are generalized to
cluster ID.
4 Submission
Based on our preliminary experiments in the sec-
tion above, we use LRMs, OSM and LM inter-
polation in our final system for newstest 2014.
But as we find that Language Models trained on
UN corpus and 10
9
French-English corpus have
a very high perplexity and in order to speed up
the translation by reducing the model size, in this
section, we interpolate only three language model-
s from monolingual data provided, English Giga-
word fifth edition and target side of training data.
In addition, we also try some different methods for
final submission. And the results are shown in Ta-
ble 4.
? Development Set Selection: Instead of using
FDA which is dependent on test set, we use
the method of (Nadejde et al., 2013) to se-
lect tuning set from newstest 2008-2013 for
the final system. We only keep 2K sentences
which have more than 30 words and higher
BLEU score. The experiment result is shown
in Table 4 ( The system is indicated as Base-
line).
? Pre-processing: In our preliminary exper-
iments, sentences are tokenized without
changing hyphen. Thus we build another sys-
tem where all the hyphens are tokenized ag-
gressively.
? SyMGIZA++: Better alignment could lead to
better translation. So we carry out some ex-
periments on SyMGIZA++ aligner (Junczys-
Dowmunt and Sza, 2012), which modifies the
original IBM/GIZA++ word alignment mod-
els to allow to update the symmetrized mod-
els between chosen iterations of the original
training algorithms. Experiment shows this
new alignment improves translation quality.
? Multi-alignment Selection: We also try to use
multi-alignment selection (Tu et al., 2012)
to generate a ?better? alignment from three
alignmens: MGIZA++ with function grow-
diag-final-and, SyMGIZA++ with function
grow-diag-final-and and fast alignment (Dy-
er et al., 2013). Although this method show
comparable or better result on development
set, it fails on test set.
Since we build a few systems with different
setting on Moses phrase-based model, a straight-
forward thinking is to obtain the better transla-
tion from several different translation systems. So
we use system combination (Heafield and Lavie,
2010) on the 1-best outputs of three systems (in-
dicated with
?
in table 4). And this results in our
best system so far, as shown in Table 4. In our final
submission, this result is taken as primary.
5 Conclusion
This paper describes our submitted system to
WMT 2014 in detail. This system is based on
139
Systems Tuning Set newstest 2014
Baseline
?
34.2 25.6
+SyMGIZA++
?
34.3 26.0
+Multi-Alignment Selection 34.4 25.6
+Hyphen-Splitted 33.9 25.9
+SyMGIZA++
?
34.0 26.0
+Multi-Alignment Selection 34.0 25.7
System Combination ? 26.5
Table 4: Experiment results on newstest 2014. We report case-sensitive BLEU[%] score on test set and
case-insensitive BLEU[%] on tuning set which is directly from tuning result. Baseline is the phrase-based
system with LRMs, OSM and LM interpolation on smaller datasets, tuned with selected development set.
Systems indicated with
?
are used for system combination.
Moses phrase-based model, and integrates Lexi-
calized Reordering Models, Operation Sequence
Model and Language Model interpolation. Al-
so system combination is used on several system-
s which have different pre-processing and align-
ment.
Acknowledgments
This work is supported by EC Marie-Curie initial
training Network EXPERT (EXPloiting Empiri-
cal appRoaches to Translation) project (http:
//expert-itn.eu). Thanks to Johannes Lev-
eling for his help on German compound splitting.
And thanks to Jia Xu and Jian Zhang for their ad-
vice and help on this paper and experiments.
References
Amittai Axelrod, Ra Birch Mayne, Chris Callison-
burch, Miles Osborne, and David Talbot. 2005. Ed-
inburgh system description for the 2005 iwslt speech
translation evaluation. In Proceedings of the Inter-
national Workshop on Spoken Language Translation
(IWSLT).
Ergun Bic?ici and Deniz Yuret. 2014. Optimizing in-
stance selection for statistical machine translation
with feature decay algorithms. IEEE/ACM Transac-
tions On Audio, Speech, and Language Processing
(TASLP).
Stanley F. Chen and Joshua Goodman. 1996. An em-
pirical study of smoothing techniques for language
modeling. In Proceedings of the 34th Annual Meet-
ing on Association for Computational Linguistics,
ACL ?96, pages 310?318, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAA-
CL HLT ?12, pages 427?436, Stroudsburg, PA, US-
A. Association for Computational Linguistics.
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A joint sequence translation model with in-
tegrated reordering. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Vol-
ume 1, HLT ?11, pages 1045?1054, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proceedings of NAACL.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 848?856, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ?08, pages 49?
57, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexical-
ized rule selection. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008), pages 321?328, Manchester, UK,
August. Coling 2008 Organizing Committee.
Kenneth Heafield and Alon Lavie. 2010. Combining
machine translation output with open source: The
Carnegie Mellon multi-engine machine translation
scheme. The Prague Bulletin of Mathematical Lin-
guistics, 93:27?36, January.
Marcin Junczys-Dowmunt and Arkadiusz Sza. 2012.
Symgiza++: Symmetrized word alignment models
for statistical machine translation. In Pascal Bouvry,
MieczysawA. Kopotek, Franck Leprvost, Magorza-
ta Marciniak, Agnieszka Mykowiecka, and Henryk
140
Rybiski, editors, Security and Intelligent Informa-
tion Systems, volume 7053 of Lecture Notes in Com-
puter Science, pages 379?390. Springer Berlin Hei-
delberg.
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868?876.
Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In Proceedings of
the Tenth Conference on European Chapter of the
Association for Computational Linguistics - Volume
1, EACL ?03, pages 187?193, Stroudsburg, PA, US-
A. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 177?180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh?s syntax-based machine transla-
tion systems. In Proceedings of the Eighth Work-
shop on Statistical Machine Translation, pages 170?
176, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Rico Sennrich. 2012. Perplexity minimization for
translation model domain adaptation in statistical
machine translation. In Proceedings of the 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 539?549,
Avignon, France, April. Association for Computa-
tional Linguistics.
Nakatani Shuyo. 2010. Language detection library for
java.
Andreas Stolcke. 2002. Srilm ? an extensible language
modeling toolkit. In Proceedings of the Internation-
al Conference Spoken Language Processing, pages
901?904, Denver, CO.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1, NAACL ?03, pages 173?180, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Zhaopeng Tu, Yang Liu, Yifan He, Josef van Genabith,
Qun Liu, and Shouxun Lin. 2012. Combining mul-
tiple alignments to improve machine translation. In
COLING (Posters), pages 1249?1260.
141
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 122?131,
October 25, 2014, Doha, Qatar.
c
?2014 Association for Computational Linguistics
Transformation and Decomposition for Efficiently Implementing and
Improving Dependency-to-String Model In Moses
Liangyou Li
?
, Jun Xie
?
, Andy Way
?
and Qun Liu
??
?
CNGL Centre for Global Intelligent Content, School of Computing
Dublin City University, Dublin 9, Ireland
?
Key Laboratory of Intelligent Information Processing, Institute of Computing Technology
Chinese Academy of Sciences, Beijing, China
{liangyouli,away,qliu}@computing.dcu.ie
junxie@ict.ac.cn
Abstract
Dependency structure provides grammat-
ical relations between words, which have
shown to be effective in Statistical Ma-
chine Translation (SMT). In this paper, we
present an open source module in Moses
which implements a dependency-to-string
model. We propose a method to trans-
form the input dependency tree into a cor-
responding constituent tree for reusing the
tree-based decoder in Moses. In our ex-
periments, this method achieves compara-
ble results with the standard model. Fur-
thermore, we enrich this model via the
decomposition of dependency structure,
including extracting rules from the sub-
structures of the dependency tree during
training and creating a pseudo-forest in-
stead of the tree per se as the input dur-
ing decoding. Large-scale experiments
on Chinese?English and German?English
tasks show that the decomposition ap-
proach improves the baseline dependency-
to-string model significantly. Our sys-
tem achieves comparable results with the
state-of-the-art hierarchical phrase-based
model (HPB). Finally, when resorting to
phrasal rules, the dependency-to-string
model performs significantly better than
Moses HPB.
1 Introduction
Dependency structure models relations between
words in a sentence. Such relations indicate
the syntactic function of one word to another
word. As dependency structure directly encodes
semantic information and has the best inter-lingual
phrasal cohesion properties (Fox, 2002), it is be-
lieved to be helpful to translation.
In recent years, dependency structure has been
widely used in SMT. For example, Shen et al.
(2010) present a string-to-dependency model by
using the dependency fragments of the neighbour-
ing words on the target side, which makes it easier
to integrate a dependency language model. How-
ever such string-to-tree systems run slowly in cu-
bic time (Huang et al., 2006).
Another example is the treelet approach
(Menezes and Quirk, 2005; Quirk et al., 2005),
which uses dependency structure on the source
side. Xiong et al. (2007) extend the treelet ap-
proach to allow dependency fragments with gaps.
As the treelet is defined as an arbitrary connected
sub-graph, typically both substitution and inser-
tion operations are adopted for decoding. How-
ever, as translation rules based on the treelets
do not encode enough reordering information di-
rectly, another heuristic or separate reordering
model is usually needed to decide the best target
position of the inserted words.
Different from these works, Xie et al. (2011)
present a dependency-to-string (Dep2Str) model,
which extracts head-dependent (HD) rules from
word-aligned source dependency trees and target
strings. As this model specifies reordering infor-
mation in the HD rules, during translation only the
substitution operation is needed, because words
are reordered simultaneously with the rule being
applied. Meng et al. (2013) and Xie et al. (2014)
extend the model by augmenting HD rules with the
help of either constituent tree or fixed/float struc-
ture (Shen et al., 2010). Augmented rules are cre-
ated by the combination of two or more nodes in
122
the HD fragment, and are capable of capturing
translations of non-syntactic phrases. However,
the decoder needs to be changed correspondingly
to handle these rules.
Attracted by the simplicity of the Dep2Str
model, in this paper we describe an easy way to
integrate the model into the popular translation
framework Moses (Koehn et al., 2007). In or-
der to share the same decoder with the conven-
tional syntax-based model, we present an algo-
rithm which transforms a dependency tree into a
corresponding constituent tree which encodes de-
pendency information in its non-leaf nodes and is
compatible with the Dep2Str model. In addition,
we present a method to decompose a dependency
structure (HD fragment) into smaller parts which
enrich translation rules and also allow us to cre-
ate a pseudo-forest as the input. ?Pseudo? means
the forest is not obtained by combining several
trees from a parser, but rather that it is created
based on the decomposition of an HD fragment.
Large-scale experiments on Chinese?English and
German?English tasks show that the transforma-
tion and decomposition are effective for transla-
tion.
In the remainder of the paper, we first describe
the Dep2Str model (Section 2). Then we describe
how to transform a dependency tree into a con-
stituent tree which is compatible with the Dep2Str
model (Section 3). The idea of decomposition in-
cluding extracting sub-structural rules and creat-
ing a pseudo-forest is presented in Section 4. Then
experiments are conducted to compare translation
results of our approach with the state-of-the-art
HPB model (Section 5). We conclude in Section 6
and present avenues for future work.
2 Dependency-to-String Model
In the Dep2Str model (Xie et al., 2011), the HD
fragment is the basic unit. As shown in Figure
1, in a dependency tree, each non-leaf node is the
head of some other nodes (dependents), so an HD
fragment is composed of a head node and all of its
dependents.
1
In this model, there are two kinds of rules for
translation. One is the head rule which specifies
the translation of a source word:
Juxing
??? holds
1
In this paper, HD fragment of a node means the HD frag-
ment with this node as the head. Leaf nodes have no HD
fragments.
Boliweiya
????/NN
Juxing
??/VV
Zongtong
??/NN
Yu
?/CC
Guohui
??/NN
Xuanju
??/NN
Figure 1: Example of a dependency tree, with
head-dependent fragments being indicated by dot-
ted lines.
The other one is the HD rule which consists of
three parts: the HD fragment s of the source
side (maybe containing variables), a target string
t (maybe containing variables) and a one-to-one
mapping ? from variables in s to variables in t, as
in:
s = (
Boliweiya
????)
Juxing
?? (x
1
:
Xuanju
?? )
t = Bolivia holds x
1
? = {x
1
:
Xuanju
??? x
1
}
where the underlined element denotes the leaf
node. Variables in the Dep2Str model are con-
strained either by words (like x
1
:??) or Part-of-
Speech (POS) tags (like x
1
:NN).
Given a source sentence with a dependency tree,
a target string and the word alignment between the
source and target sentences, this model first an-
notates each node N with two annotations: head
span and dependency span.
2
These two spans
specify the corresponding target position of a node
(by the head span) or sub-tree (by the depen-
dency span). After annotation, acceptable HD
fragments
3
are utilized to induce lexicalized HD
2
Some definitions: Closure clos(S) of set S is the small-
est superset of S in which the elements (integers) are contin-
uous. Let H be the set of indexes of target words aligned to
node N . Head span hsp(N) of node N is clos(H). Head
span hsp(N) is consistent if it does not overlap with head
span of any other node. Dependency span dsp(N) of node
N is the union of all consistent head spans in the subtree
rooted at N .
3
A head-dependent fragment is acceptable if the head
span of the head node is consistent and none of the depen-
dency spans of its dependents is empty. We could see that
in an acceptable fragment, the head span of the head node
and dependency spans of dependents are not overlapped with
each other.
123
          Boliweiya Juxing  Xuanju
R ule:  ( ????)  ?? ( x1 :??) Boliv ia hold s  x1
                       Xuanju
R ule:  ( x1: N N )  ?? x1 elec tions
           Guohui
R ule:  ?? p ar liam ent
           Zongtong Yu      Guohui
R ule:    ( ??)    ( ?)  x1:?? p r es id ential and  x1
Boliweiya
????/NN
Juxing
??/VV
Zongtong
??/NN
Yu
?/CC
Guohui
??/NN
Xuanju
??/NN
Zongtong
??/NN
Yu
?/CC
Guohui
??/NNBoliv ia hold s elec tions
Boliv ia hold s
Zongtong
??/NN
Yu
?/CC
Guohui
??/NN
Xuanju
??/NN
Boliv ia hold s  p r es id ential and  p ar liam ent elec tions
Boliv ia hold s  p r es id ential and
Guohui
??/NN elec tions
( a)
( b )
( c )
( d )
( e)
Figure 2: Example of a derivation. Underlined el-
ements indicate leaf nodes.
rules (the head node and leaf node are represented
by words, while the internal nodes are replaced by
variables constrained by word) and unlexicalized
HD rules (nodes are replaced by variables con-
strained by POS tags).
In HD rules, an internal node denotes the whole
sub-tree and is always a substitution site. The head
node and leaf nodes can be represented by either
words or variables. The target side corresponding
to an HD fragment and the mapping between vari-
ables are determined by the head span of the head
node and the dependency spans of the dependents.
A translation can be obtained by applying rules
to the input dependency tree. Figure 2 shows a
derivation for translating a Chinese sentence into
an English string. The derivation proceeds from
top to bottom. Variables in the higher-level HD
rules are substituted by the translations of lower
HD rules recursively.
The final translation is obtained by finding the
best derivation d
?
from all possible derivations
D which convert the source dependency structure
into a target string, as in Equation (1):
d
?
= argmax
d?D
p(d) ? argmax
d?D
?
i
?
i
(d)
?
i
(1)
where ?
i
(d) is the ith feature defined in the deriva-
tion d, and ?
i
is the weight of the feature.
3 Transformation of Dependency Trees
In this section, we introduce an algorithm to trans-
form a dependency tree into a corresponding con-
stituent tree, where words of the source sentence
are leaf nodes and internal nodes are labelled with
head words or POS tags which are constrained by
dependency information. Such a transformation
makes it possible to use the traditional tree-based
decoder to translate a dependency tree, so we can
easily integrate the Dep2Str model into the popu-
lar framework Moses.
In a tree-based system, the CYK algorithm
(Kasami, 1965; Younger, 1967; Cocke and
Schwartz, 1970) is usually employed to translate
the input sentence with a tree structure. Each time
a continuous sequence of words (a phrase) in the
source sentence is translated. Larger phrases can
be translated by combining translations of smaller
phrases.
In a constituent tree, the source words are leaf
nodes and all non-leaf nodes covering a phrase are
labelled with categories which are usually vari-
ables defined in the tree-based model. For trans-
lating a phrase covered by a non-leaf node, the de-
coder for the constituent tree can easily find ap-
plied rules by directly matching variables in these
rules to tree nodes. However, in a dependency tree,
each internal node represents a word of the source
sentence. Variables covering a phrase cannot be
recognized directly. Therefore, to share the same
decoder with the constituent tree, the dependency
tree needs to be transformed into a constituent-
style tree.
As we described in Section 2, each variable in
the Dep2Str model represents a word (for the head
and leaf node) or a sequence of continuous words
(for the internal node). Thus it is intuitive to use
these variables to label non-leaf nodes of the pro-
duced constituent tree. Furthermore, in order to
preserve the dependency information of each HD
fragment, the created constituent node needs to be
constrained by the dependency information in the
HD fragment.
Our transformation algorithm is shown in Al-
gorithm 1, which proceeds recursively from top to
bottom on each HD fragment. There are a maxi-
mum of three types of nodes in an HD fragment:
head node, leaf nodes, and internal nodes. The
124
Algorithm 1 Algorithm for transforming a depen-
dency tree to constituent tree. Dnode means node
in dependency tree. Cnode means node in con-
stituent tree.
function CNODE(label, span)
create a new Cnode CN
CN.label? label
CN.span? span
end function
function TRANSFNODE(Dnode H)
pos? POS of H
constrain pos . with H0, like: NN:H0
CNODE(label,H.position)
for each dependent N of H do
pos? POS of N
word? word of N
constrain pos . with Li or Ri, like: NN:R1
constrain word . with Li or Ri
if N is leaf then
CNODE(pos,N.position)
else
CNODE(word,H.span)
CNODE(pos,H.span)
TRANSFNODE(N )
end if
end for
end function
leaf nodes and internal nodes are dependents of
the head node. For the leaf node and head node,
we create constituent nodes that just cover one
word. For an internal node N , we create con-
stituent nodes that cover all the words in the sub-
tree rooted at N . In Algorithm 1, N.position
means the position of the word represented by the
node N . N.span denotes indexes of words cov-
ered by the sub-tree rooted at node N .
Taking the dependency tree in Figure 1 as an
example, its transformation result for integration
with Moses is shown in Figure 3. In the Dep2Str
model, leaf nodes can be replaced by a vari-
able constrained by its POS tag, so for leaf node
?
Zongtong
?? ? in HD fragment ?
Zongtong
(??)
Yu
(?)
Guohui
???,
we create a constituent node ?NN:L2?, where
?NN? is the POS tag and ?L2? denotes that the leaf
node is the second left dependent of the head node.
For the internal node ?
Guohui
??? in the HD fragment
?
Guohui
(??)
Xuanju
???, we create two constituent nodes
Boliweiya
????
Juxing
??
Zongtong
??
Yu
?
Guohui
??
Xuanju
??
N N : L 1 V V : H 0 N N : L 2 C C : L 1 N N : H 0N N : H 0
N N : L 1
N N : R 1
S
Guohui
??: L 1
Xuanju
??: R 1
Figure 3: The corresponding constituent tree af-
ter transforming the dependency tree in Figure 1.
Note in our implementation, we do not distinguish
the leaf node and internal node of a dependency
tree in the produced constituent tree and induced
rules.
which cover all words in the dependency sub-tree
rooted at this node, with one of them labelled by
the word itself. Both nodes are constrained by de-
pendency information ?L1?. After such a transfor-
mation is conducted on each HD fragment recur-
sively, we obtain a constituent tree.
This transformation makes our implementation
of the Dep2Str model easier, because we can use
the tree-to-string decoder in Moses. All we need
to do is to write a new rule extractor which extracts
head rules and HD rules (see Section 2) from the
word-aligned source dependency trees and target
strings, and represents these rules in the format de-
fined in Moses.
4
Note that while this conversion is performed
on an input dependency tree during decoding, the
training part, including extracting rules and cal-
culating translation probabilities, does not change,
so the model is still a dependency-to-string model.
4
Taking the rule in Section 2 as an example, its represen-
tation in Moses is:
s =
Boliweiya
????
Juxing
??
Xuanju
[??:R1][X] [H1]
t = Bolivia holds
Xuanju
[??:R1][X] [X]
? = {2 ? 2}
where ?H1? denotes the position of the head word is 1, ?R1?
indicates the first right dependent of the head word, ?X? is the
general label for the target side and ? is the set of alignments
(the index-correspondences between s and t). The format has
been described in detail at http://www.statmt.org/
moses/?n=Moses.SyntaxTutorial.
125
In addition, our transformation is different from
other works which transform a dependency tree
into a constituent tree (Collins et al., 1999; Xia and
Palmer, 2001). In this paper, the produced con-
stituent tree still preserves dependency relations
between words, and the phrasal structure is di-
rectly derived from the dependency structure with-
out refinement. Accordingly, the constituent tree
may not be a linguistically well-formed syntactic
structure. However, it is not a problem for our
model, because in this paper what matters is the
dependency structure which has already been en-
coded into the (ill-formed) constituent tree.
4 Decomposition of Dependency
Structure
The Dep2Str model treats a whole HD fragment
as the basic unit, which may result in a sparse-
data problem. For example, an HD fragment with
a verb as head typically consists of more than four
nodes (Xie et al., 2011). Thus in this section, in-
spired by the treelet approach, we describe a de-
composition method to make use of smaller frag-
ments.
In an HD fragment of a dependency tree, the
head determines the semantic category, while
the dependent gives the semantic specification
(Zwicky, 1985; Hudson, 1990). Accordingly, it
is reasonable to assume that in an HD fragment,
dependents could be removed or new dependents
could be attached as needed. Thus, in this paper,
we assume that a large HD fragment is formed by
attaching dependents to a small HD fragment. For
simplicity and reuse of the decoder, such an at-
tachment is carried out in one step. This means
that an HD fragment is decomposed into two
smaller parts in a possible decomposition. This
decomposition can be formulated as Equation (2):
L
i
? ? ?L
1
HR
1
? ? ?R
j
= L
m
? ? ?L
1
HR
1
? ? ?R
n
+ L
i
? ? ?L
m+1
HR
n+1
? ? ?R
j
subject to
i ? 0, j ? 0
i ? m ? 0, j ? n ? 0
i+ j > m+ n > 0
(2)
whereH denotes the head node, L
i
denotes the ith
left dependent and R
j
denotes the jth right depen-
dent. Figure 4 shows an example.
s m ar t/ JJ
v er y/ R BS he/ P R P
s m ar t/ JJ
is / V BZ
S he/ P R P
s m ar t/ JJ
is / V BZ v er y/ R B
+
Figure 4: An example of decomposition on a head-
dependent fragment.
Algorithm 2 Algorithm for the decomposition of
an HD fragment into two sub-fragments. Index of
nodes in a fragment starts from 0.
function DECOMP(HD fragment frag)
fset ? {}
len? number of nodes in frag
hidx? the index of head node in frag
for s = 0 to hidx do
for e = hidx to len? 1 do
if 0 < e? s < len? 1 then
create sub-fragment core
core? nodes from s to e
add core to fset
create sub-fragment shell
initialize shell with head node
shell? nodes not in core
add shell to fset
end if
end for
end for
end function
Such a decomposition of an HD fragment en-
ables us to create translation rules extracted from
sub-structures and create a pseudo-forest from
the input dependency tree to make better use of
smaller rules.
4.1 Sub-structural Rules
In the Dep2Str model, rules are extracted on
an entire HD fragment. In this paper, when
the decomposition is considered, we also extract
sub-structural rules by taking each possible sub-
fragment as a new HD fragment. The algorithm
for recognizing the sub-fragments is shown in Al-
gorithm 2.
In Algorithm 2, we find all possible decom-
126
positions of an HD fragment. Each decom-
position produces two sub-fragments: core and
shell. Both core and shell include the head node.
core contains the dependents surrounding the head
node, with the remaining dependents belonging to
shell. Taking Figure 4 as an example, the bottom-
right part is core, while the bottom-left part is
shell. Each core and shell could be seen as a
new HD fragment. Then HD rules are extracted as
defined in the Dep2Str model.
Note that different from the augmented HD
rules, where Meng et al. (2013) annotate rules with
combined variables and Xie et al. (2014) create
special rules from HD rules at runtime by com-
bining several nodes, our sub-structural rules are
standard HD rules, which are extracted from the
connected sub-structures of a larger HD fragment
and can be used directly in the model.
4.2 Pseudo-Forest
Although sub-structural rules are effective in our
experiments (see Section 5), we still do not use
them to their best advantage, because we only en-
rich smaller rules in our model. During decod-
ing, for a large input HD fragment, the model is
still more likely to resort to glue rules. However,
the idea of decomposition allows us to create a
pseudo-forest directly from the dependency tree to
alleviate this problem to some extent.
As described above, an HD fragment can be
seen as being created by combining two smaller
fragments. This means, for an HD fragment in the
input dependency tree, we can translate one of its
sub-fragments first, then obtain the whole trans-
lation by combining with translations of another
sub-fragment. From Algorithm 2, we know that
the sub-fragment core covers a continuous phrase
of the source sentence. Accordingly, we can trans-
late this fragment first and then build the whole
translation by translating another sub-fragment
shell. Figure 5 gives an example of translating
an HD fragment by combining the translations of
its sub-fragments.
Instead of taking the dependency tree as the in-
put and looking for all rules for translating sub-
fragments of a whole HD, we directly encode the
decomposition into the input dependency tree with
the result being a pseudo-forest. Based on the
transformation algorithm in Section 3, the pseudo-
forest can also be represented in the constituent-
tree style, as shown in Figure 6.
          Yu  Guohui
R ule:  ( ?)  ?? and  p ar lim ent
Zongtong
??/NN
Yu
?/CC
Guohui
??/NN
Zongtong
R ule:  ( ??)  x 1 : N N p r es id ential x1
p r es id ential and  p ar liam ent
Zongtong
??        and  p ar liam ent
Guohui
??/NN
( a)
( b )
( c )
Figure 5: An example of translating a large HD
fragment with the help of translations of its de-
composed fragments.
S
N N : L 1 V V : H 0
N N : L 2 C C : L 1 N N : H 0N N : H 0
N N : R 1
Xuanju
??: R 1
N N : L 1
Guohui
??: L 1
Boliweiya
????
Juxing
??
Zongtong
??
Yu
?
Guohui
??
Xuanju
??
N N : L 1
N N : H 0
V V : H 0
V V : H 0
Figure 6: An example of a pseudo-forest for the
dependency tree in Figure 1. It is represented us-
ing the constituent-tree style described in Section
3. Edges drawn in the same type of line are owned
by the same sub-tree. Solid lines are shared edges.
In the pseudo-forest, we actually only create a
forest structure for each HD fragment. For ex-
ample, based on Figure 5, we create a constituent
node labelled with ?NN:H0? that covers the sub-
fragment ?
Yu
(?)
Guohui
???. In so doing, a new node la-
belled with ?NN:L1? is also created, which covers
the Node ?
Zongtong
?? ?, because it is now the first left
dependent in the sub-fragment ?
Zongtong
(??)
Guohui
?? ?.
Compared to the forest-based model (Mi et al.,
2008), such a pseudo-forest cannot efficiently re-
duce the influence of parsing errors, but it is easily
available and compatible with the Dep2Str Model.
127
corpus sentences words(ch) words(en)
train 1,501,652 38,388,118 44,901,788
dev 878 22,655 26,905
MT04 1,597 43,719 52,705
MT05 1,082 29,880 35,326
Table 1: Chinese?English corpus. For the English
dev and test sets, words counts are averaged across
4 references.
corpus sentences words(de) words(en)
train 2,037,209 52,671,991 55,023,999
dev 3,003 72,661 74,753
test12 3,003 72,603 72,988
test13 3,000 63,412 64,810
Table 2: German?English corpus. In the dev and
test sets, there is only one English reference for
each German sentence.
5 Experiments
We conduct large-scale experiments to exam-
ine our methods on the Chinese?English and
German?English translation tasks.
5.1 Data
The Chinese?English training corpus is from
the LDC data, including LDC2002E18,
LDC2003E07, LDC2003E14, LDC2004T07,
the Hansards portion of LDC2004T08 and
LDC2005T06. We take NIST 2002 as the de-
velopment set to tune weights, and NIST 2004
(MT04) and NIST 2005 (MT05) as the test data to
evaluate the systems. Table 1 provides a summary
of the Chinese?English corpus.
The German?English training corpus is from
WMT 2014, including Europarl V7 and News
Commentary. News-test 2011 is taken as the de-
velopment set, while News-test 2012 (test12) and
News-test 2013 (test13) are our test sets. Table 2
provides a summary of the German?English cor-
pus.
5.2 Baseline
For both language pairs, we filter sentence pairs
longer than 80 words and keep the length ratio
less than or equal to 3. English sentences are to-
kenized with scripts in Moses. Word alignment is
performed by GIZA++ (Och and Ney, 2003) with
the heuristic function grow-diag-final-and (Koehn
et al., 2003). We use SRILM (Stolcke, 2002) to
Systems MT05
XJ 33.91
D2S 33.79
Table 3: BLEU score [%] of the Dep2Str model
before (XJ) and after (D2S) dependency tree be-
ing transformed. Systems are trained on a selected
1.2M Chinese?English corpus.
train a 5-gram language model on the Xinhua por-
tion of the English Gigaword corpus 5th edition
with modified Kneser-Ney discounting (Chen and
Goodman, 1996). Minimum Error Rate Train-
ing (Och, 2003) is used to tune weights. Case-
insensitive BLEU (Papineni et al., 2002) is used to
evaluate the translation results. Bootstrap resam-
pling (Koehn, 2004) is also performed to compute
statistical significance with 1000 iterations.
We implement the baseline Dep2Str model
in Moses with methods described in this paper,
which is denoted as D2S. The first experiment we
do is to sanity check our implementation. Thus
we take a separate system (denoted as XJ) for
comparison which implements the Dep2Str model
based on (Xie et al., 2011). As shown in Table
3, using the transformation of dependency trees,
the Dep2Str model implemented in Moses (D2S)
is comparable with the standard implementation
(XJ).
In the rest of this section, we describe exper-
iments which compare our system with Moses
HPB (default setting), and test whether our de-
composition approach improves performance over
the baseline D2S.
As described in Section 2, the Dep2Str model
only extracts phrase rules for translating a source
word (head rule). This model could be enhanced
by including phrase rules that cover more than one
source word. Thus we also conduct experiments
where phrase pairs
5
are added into our system. We
set the length limit for phrase 7.
5.3 Chinese?English
In the Chinese?English translation task, the Stan-
ford Chinese word segmenter (Chang et al., 2008)
is used to segment Chinese sentences into words.
The Stanford dependency parser (Chang et al.,
2009) parses a Chinese sentence into the projec-
tive dependency tree.
5
In this paper, the use of phrasal rules is similar to that of
the HPB model, so they can be handled by Moses directly.
128
Systems MT04 MT05
Moses HPB 35.56 33.99
D2S 33.93 32.56
+pseudo-forest 34.28 34.10
+sub-structural rules 34.78 33.63
+pseudo-forest 35.46 34.13
+phrase 36.76* 34.67*
Table 4: BLEU score [%] of our method and
Moses HPB on the Chinese?English task. We use
bold font to indicate that the result of our method
is significantly better than D2S at p ? 0.01 level,
and * to indicate the result is significantly better
than Moses HPB at p ? 0.01 level.
Table 4 shows the translation results. We find
that the decomposition approach proposed in this
paper, including sub-structural rules and pseudo-
forest, improves the baseline system D2S sig-
nificantly (absolute improvement of +1.53/+1.57
(4.5%/4.8%, relative)). As a result, our sys-
tem achieves comparable (-0.1/+0.14) results with
Moses HPB. After including phrasal rules, our
system performs significantly better (absolute im-
provement of +1.2/+0.68 (3.4%/2.0%, relative))
than Moses HPB on both test sets.
6
5.4 German?English
We tokenize German sentences with scripts in
Moses and use mate-tools
7
to perform morpho-
logical analysis and parse the sentence (Bohnet,
2010). Then the MaltParser
8
converts the parse
result into the projective dependency tree (Nivre
and Nilsson, 2005).
Experimental results in Table 5 show that incor-
porating sub-structural rules improves the base-
line D2S system significantly (absolute improve-
ment of +0.47/+0.63, (2.3%/2.8%, relative)), and
achieves a slightly better (+0.08) result on test12
than Moses HPB. However, in the German?
English task, the pseudo-forest produces a neg-
ative effect on the baseline system (-0.07/-0.45),
despite the fact that our system combining both
methods together is still better (+0.2/+0.11) than
the baseline D2S. In the end, by resorting to
6
In our preliminary experiments, phrasal rules are also
able to significantly improve our system on their own on both
Chinese?English and German?English tasks, but the best per-
formance is achieved by combining them with sub-structural
rules and/or pseudo-forest.
7
http://code.google.com/p/mate-tools/
8
http://www.maltparser.org/
Systems test12 test13
Moses HPB 20.44 22.77
D2S 20.05 22.13
+pseudo-forest 19.98 21.68
+sub-structural rules 20.52 22.76
+phrase 20.91* 23.46*
+pseudo-forest 20.25 22.24
+phrase 20.75* 23.20*
Table 5: BLEU score [%] of our method and
Moses HPB on German?English task. We use
bold font to indicate that the result of our method
is significantly better than baseline D2S at p ?
0.01 level, and * to indicate the result is signifi-
cantly better than Moses HPB at p ? 0.01 level.
Systems
# Rules
CE task DE task
Moses HPB 388M 684M
D2S 27M 41M
+sub-structural rules 116M 121M
+phrase 215M 274M
Table 6: The number of rules in different sys-
tems On the Chinese?English (CE) and German?
English (DE) corpus. Note that pseudo-forest (not
listed) does not influence the number of rules.
phrasal rules, our system achieves the best perfor-
mance overall which is significantly better (abso-
lute improvement of +0.47/+0.59 (2.3%/2.6%, rel-
ative)) than Moses HPB.
5.5 Discussion
Besides long-distance reordering (Xie et al.,
2011), another attraction of the Dep2Str model is
its simplicity. It can perform fast translation with
fewer rules than HPB. Table 6 shows the number
of rules in each system. It is easy to see that all of
our systems use fewer rules than HPB. However,
the number of rules is not proportional to transla-
tion quality, as shown in Tables 4 and 5.
Experiments on the Chinese?English corpus
show that it is feasible to translate the dependency
tree via transformation for the Dep2Str model de-
scribed in Section 2. Such a transformation causes
the model to be easily integrated into Moses with-
out making changes to the decoder, while at the
same time producing comparable results with the
standard implementation (shown in Table 3).
The decomposition approach proposed in this
129
paper also shows a positive effect on the base-
line Dep2Str system. Especially, sub-structural
rules significantly improve the Dep2Str model on
both Chinese?English and German?English tasks.
However, experiments show that the pseudo-forest
significantly improves the D2S system on the
Chinese?English data, while it causes translation
quality to decline on the German?English data.
Since using the pseudo-forest in our system is
aimed at translating larger HD fragments via split-
ting it into pieces, we hypothesize that when trans-
lating German sentences, the pseudo-forest ap-
proach more likely results in much worse rules be-
ing applied. This is probably due to the shorter
Mean Dependency Distance (MDD) and freer
word order of German sentences(Eppler, 2013).
6 Conclusion
In this paper, we present an open source mod-
ule which integrates a dependency-to-string model
into Moses.
This module transforms an input depen-
dency tree into a corresponding constituent tree
during decoding which makes Moses perform
dependency-based translation without necessitat-
ing any changes to the decoder. Experiments on
Chinese?English show that the performance if our
system is comparable with that of the standard
dependency-based decoder.
Furthermore, we enhance the model by de-
composing head-dependent fragments into smaller
pieces. This decomposition enriches the Dep2Str
model with more rules during training and allows
us to create a pseudo-forest as input instead of
a dependency tree during decoding. Large-scale
experiments on Chinese?English and German?
English tasks show that this decomposition can
significantly improve the baseline dependency-
to-string model on both language pairs. On
the German?English task, sub-structural rules are
more useful than the pseudo-forest input. In the
end, by resorting to phrasal rules, our system
performs significantly better than the hierarchical
phrase-based model in Moses.
Our implementation of the dependency-to-
string model with methods described in this pa-
per is available at http://computing.dcu.
ie/
?
liangyouli/dep2str.zip. In the fu-
ture, we would like to conduct more experiments
on other language pairs to examine this model,
as well as reducing the restrictions on decompo-
sition.
Acknowledgments
This research has received funding from the Peo-
ple Programme (Marie Curie Actions) of the Eu-
ropean Union?s Seventh Framework Programme
FP7/2007-2013/ under REA grant agreement no.
317471. This research is also supported by the
Science Foundation Ireland (Grant 12/CE/I2267)
as part of the Centre for Next Generation Local-
isation at Dublin City University. The authors of
this paper also thank the reviewers for helping to
improve this paper.
References
Bernd Bohnet. 2010. Very High Accuracy and Fast
Dependency Parsing is Not a Contradiction. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics, pages 89?97, Beijing,
China.
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing Chinese Word Seg-
mentation for Machine Translation Performance. In
Proceedings of the Third Workshop on Statistical
Machine Translation, pages 224?232, Columbus,
Ohio.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative Re-
ordering with Chinese Grammatical Relations Fea-
tures. In Proceedings of the Third Workshop on Syn-
tax and Structure in Statistical Translation, pages
51?59, Boulder, Colorado.
Stanley F. Chen and Joshua Goodman. 1996. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. In Proceedings of the 34th Annual
Meeting on Association for Computational Linguis-
tics, pages 310?318, Santa Cruz, California.
John Cocke and Jacob T. Schwartz. 1970. Program-
ming Languages and Their Compilers: Preliminary
Notes. Technical report, Courant Institute of Math-
ematical Sciences, New York University, New York,
NY.
Michael Collins, Lance Ramshaw, Jan Haji?c, and
Christoph Tillmann. 1999. A Statistical Parser for
Czech. In Proceedings of the 37th Annual Meeting
of the Association for Computational Linguistics on
Computational Linguistics, pages 505?512, College
Park, Maryland.
Eva M. Duran Eppler. 2013. Dependency Distance
and Bilingual Language Use: Evidence from Ger-
man/English and Chinese/English Data. In Proceed-
ings of the Second International Conference on De-
pendency Linguistics (DepLing 2013), pages 78?87,
Prague, August.
130
Heidi J. Fox. 2002. Phrasal Cohesion and Statis-
tical Machine Translation. In Proceedings of the
ACL-02 Conference on Empirical Methods in Nat-
ural Language Processing - Volume 10, pages 304?
3111, Philadelphia.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
A Syntax-directed Translator with Extended Do-
main of Locality. In Proceedings of the Workshop
on Computationally Hard Problems and Joint Infer-
ence in Speech and Language Processing, pages 1?
8, New York City, New York.
Richard Hudson. 1990. English Word Grammar.
Blackwell, Oxford, UK.
Tadao Kasami. 1965. An Efficient Recognition and
Syntax-Analysis Algorithm for Context-Free Lan-
guages. Technical report, Air Force Cambridge Re-
search Lab, Bedford, MA.
Philipp Koehn. 2004. Statistical Significance Tests
for Machine Translation Evaluation. In Proceedings
of EMNLP 2004, pages 388?395, Barcelona, Spain,
July.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
ACL on Interactive Poster and Demonstration Ses-
sions, pages 177?180, Prague, Czech Republic.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, pages 48?54, Edmonton, Canada.
Arul Menezes and Chris Quirk. 2005. Dependency
Treelet Translation: The Convergence of Statistical
and Example-Based Machine-translation? In Pro-
ceedings of the Workshop on Example-based Ma-
chine Translation at MT Summit X, September.
Fandong Meng, Jun Xie, Linfeng Song, Yajuan L?u,
and Qun Liu. 2013. Translation with Source Con-
stituency and Dependency Trees. In Proceedings of
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1066?1076, Seattle,
Washington, USA, October.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
Based Translation. In Proceedings of ACL-08: HLT,
pages 192?199, June.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-
Projective Dependency Parsing. In Proceedings of
the 43rd Annual Meeting on Association for Com-
putational Linguistics, pages 99?106, Ann Arbor,
Michigan.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics - Volume 1, pages 160?167,
Sapporo, Japan.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
Pennsylvania.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency Treelet Translation: Syntactically In-
formed Phrasal SMT. In Proceedings of the 43rd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL?05), pages 271?279, Ann
Arbor, Michigan, June.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2010.
String-to-Dependency Statistical Machine Transla-
tion. Computational Linguistics, 36(4):649?671,
December.
Andreas Stolcke. 2002. SRILM-an Extensible Lan-
guage Modeling Toolkit. In Proceedings Interna-
tional Conference on Spoken Language Processing,
pages 257?286, November.
Fei Xia and Martha Palmer. 2001. Converting De-
pendency Structures to Phrase Structures. In Pro-
ceedings of the First International Conference on
Human Language Technology Research, pages 1?5,
San Diego.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A Novel
Dependency-to-string Model for Statistical Machine
Translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 216?226, Edinburgh, United Kingdom.
Jun Xie, Jinan Xu, and Qun Liu. 2014. Augment
Dependency-to-String Translation with Fixed and
Floating Structures. In Proceedings of the 25th In-
ternational Conference on Computational Linguis-
tics, pages 2217?2226, Dublin, Ireland.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2007. A De-
pendency Treelet String Correspondence Model for
Statistical Machine Translation. In Proceedings of
the Second Workshop on Statistical Machine Trans-
lation, pages 40?47, Prague, June.
Daniel H. Younger. 1967. Recognition and Parsing of
Context-Free Languages in Time n
3
. Information
and Control, 10(2):189?208.
Arnold M. Zwicky. 1985. Heads. Journal of Linguis-
tics, 21:1?29, 3.
131
