Reasoning in Metaphor Understanding:
The ATT-Meta Approach and System
John Barnden, Sheila Glasbey, Mark Lee, Alan Wallington
School of Computer Science
University of Birmingham
Birmingham B15 2TT
{J.A.Barnden, S.R.Glasbey, M.G.Lee, A.M.Wallington}@cs.bham.ac.uk
Abstract
A detailed approach has been developed for
core aspects of the task of understanding a
broad class of metaphorical utterances. The
utterances in question are those that depend
on known metaphorical mappings but that
nevertheless contain elements not mapped
by those mappings. A reasoning system has
been implemented that partially instantiates
the theoretical approach. The system, called
ATT-Meta, will be demonstrated. The paper
briefly indicates how the system works, and
outlines some specific aspects of the system,
approach and the overall project.
Introduction
The sentence In the far reaches of her mind,
Anne believed that Kyle was having an affair1
can be analyzed as depending on metaphorical
views of MIND AS PHYSICAL SPACE and
IDEAS AS PHYSICAL OBJECTS (see Barnden
2001a). These views are, plausibly, familiar to
typical users of English. However, it is
reasonable to assume that typical users do not
already have a mapping into the mental domain
of the physical notion of "far reaches". Our
approach to metaphor is predicated on the notion
that one should, when possible, avoid
constructing source-to-target mappings for such
elements of a metaphorical utterance that
transcend the already known mappings in the
metaphorical views underlying the utterance.
Instead, we advocate the use of metaphor-
pretence "cocoons" (reasoning spaces) where the
utterance is taken as literally true. Within-
                                                     
1
 Slightly adapted from real discourse.
cocoon reasoning will attempt to connect these
"map-transcending" elements to aspects of the
source using a set of specified conversion rules.
The far-reaches qualification in the sentence
implies by source-domain reasoning that Anne
could only to a very low degree physically
manipulate the idea that Kyle was having an
affair. Then, if we can appeal to a conversion
rule, i.e. a known mapping of ability to
physically manipulate an idea to ability to
consciously process it, we can draw the
reasonable conclusion that Anne only had a very
low degree of ability to consciously process the
idea. In our presentation, we shall demonstrate
how the ATT-Meta system deals with this
example.
Note that the rules of reasoning are given a
qualitative certainty level, and that predicates
can be graded, using a scale of qualitative
degrees. For instance, someone can be
represented as understanding a situation to a
"medium" degree.
Our approach also makes heavy use of "view-
neutral mapping adjuncts" (VNMAs). These are
general mapping principles (inspired by the
work of Carbonell 1982) that apply, though only
by default, no matter what metaphorical views
are in play. For instance, the ability to do things
and the degrees with which states of affairs hold
are automatically mapped by VNMAs. In many
examples of metaphor, most of the real mapping
work is done by VNMAs.
Much of the approach has been implemented in
the ATT-Meta system, which is an uncertain
rule-based system operating by backchaining
(see also Barnden 1998, Barnden 2001, Lee &
Barnden, 2001a). ATT-Meta performs
reasoning, but does not yet interface directly to
natural language. Instead, hand-constructed
logical forms couching the source-domain
meaning of metaphorical sentences are passed to
it. In the above example, the source-domain
meaning is that Anne?s believing was literally
physically located in the physical far reaches of
her mind.
The following sections summarize various
abilities of the system, principles of the
approach, and aspects of ongoing theoretical
work aimed at further extensions to the system.
A major item of current implementational work
is a fuller realization of VNMAs.
1 Uncertainty
Although reasoning conflict and uncertainty are
intricately involved in metaphor, very few
approaches attempt to grapple with the issues.
Propositions and reasoning within both the
target and source domains, being largely of
common-sense varieties, are typically uncertain.
It can be uncertain what metaphorical views are
involved; information transferred from the
source domain can conflict with target-domain
information; and transfers can even conflict with
each other. The ATT-Meta system handles all
these types of uncertainty and conflict. Its
uncertainty handling is based on fairly crude
qualitative uncertainty annotations on rules and
propositions, but there is a sophisticated
conflict-resolution mechanism.
The uncertainty-handling and conflict-resolution
are almost entirely orthogonal to the provisions
for metaphor. This leads to clean design and
helps to address long-standing issues about
metaphor. One such issue is the conflict between
information transferred from the source domain
and the target information. ATT-Meta allows
either side to win, depending on standard
specificity principles. This goes against a naive
assumption in most of the literature that target
information should automatically override
transfers. But, this is only convincing when the
target information is certain. Indeed, we claim
that metaphor is often used precisely to describe
an exception to a target-domain default.
2 Mixed Metaphors
Issues such as reasoning about uncertainty are
particularly important in the processing of mixed
metaphors. Mixed metaphors need not feature
obvious cases of conflict but can include
graceful combinations of metaphors, such as the
following sentence to be examined below: One
part of John hotly resented the verdict. This
combines a view of John as made up of sub-
agents and a view of agents? emotional states as
things that can have temperature. It is possible to
distinguish two types of mixed metaphor:
parallel mixes and serial mixes. In a parallel
mixed metaphor, the target (A) is seen partly
through an A-as-B metaphor and partly through
another metaphor, A-as-B?. B and B? are in
general different domains, but may overlap.
Also, different aspects of A may be involved in
the two metaphors. In a serial mixed metaphor
(commonly called a chained metaphor), the
target (A) is seen as a source (B), which is in
turn then seen as a different source (C).
Previous work on the understanding of metaphor
has assumed that mixing is a relatively rare
phenomenon that can be handled once a more
theory of simple metaphor is developed. We
argue that this assumption is detrimental to
progress since mixed metaphors rely on the
same conceptual knowledge as simple
metaphors and can, therefore, provide valuable
insight into the processes and representations
underlying metaphorical reasoning. Moreover,
we claim that the reasoning processes and data
structures involved in understanding mixed
metaphors are identical to those used in
understanding simple metaphors. Therefore, any
current theory of metaphor should (at least in
principle) be extensible to deal with mixing. To
this end, ATT-Meta handles mixed metaphor in
a manner consistent with the way it handles
simple metaphors. The two types of metaphor
are processed in subtly different ways. Parallel
mixed metaphors create separate pretence-
cocoons that are mapped in parallel to the target
domain where their respective contributions are
understood. Serial mixed metaphors create
nested pretence cocoons where the metaphorical
view of B as C is nested within a pretence
cocoon with the view of A as B.
3 Reverse Transfers in Metaphor
The use of metaphor involves a flow of effects
of some kind from the source domain to the
target domain, where effects can include insights
into the target, hypotheses about the target, or
the highlighting of parts of the target. However,
although the overall effect flow is always from
source to target, in many cases, this does not
preclude a reverse flow where a literal
proposition, command, or question is mapped
onto an equivalent within the current
metaphorical domain.
The ATT-Meta system allows conversion rules
to map from propositions in the source domain
to propositions in the target domain and also in
the opposite direction. So a source domain
proposition such as "Socrates was the midwife
for an idea" might be mapped onto the target
domain proposition "Socrates helped in the
production of the idea". However, the rules
would equally allow the proposition "Socrates
helped in the production of the idea" to be
mapped to the source domain proposition
"Socrates was the midwife for an idea". We
argue that there are at least three reasons why
ATT-Meta should have this ability:
(1) Given that metaphors are ultimately used to
have an effect on the target domain, the use of a
metaphorical utterance can be seen as
answering, in some sense, a target domain
query. This sets up a choice between taking the
metaphorical utterance and applying all
conversion rules to it in the hope that one of the
resulting propositions might provide a suitable
answer, or taking the question and converting it
into a question in terms of the current metaphor.
We argue that the latter is often more efficient.
(2) Certain source domain propositions would
allow ATT-Meta to draw a tentative conclusion,
which would, were it more strongly supported,
provide an argument via a chain of reasoning for
some other, target level, proposition or query. A
target-level statement might give the added
support, but for this to be the case it would first
need to be converted into its source-level
equivalent.
(3) The combination of source and target domain
information within a discourse that only
intermittently maintains a metaphorical view of
the target domain may best be done in the source
domain after the target domain information has
been "metaphorized". This would be especially
so if the source domain was information-rich
compared to the target domain, so allowing
much more reasoning to be carried out than
would be possible in the target domain.
4 Non-Declarative Metaphor
Almost all examples of metaphorical language
discussed in the literature are of declarative
utterances rather than questions, commands,
ejaculations, etc. However, these other forms of
utterance can obviously occur. For instance, just
as one can state "John is a steamroller?? one can
ask "Is John a steamroller??? Just as one can state
"The champion knocked the cream-puff out?? one
can issue the command "Knock that cream-puff
out!?? The observation that questions, in
particular, can be metaphorical, plays a
significant role in our theoretical approach. This
is because their processing is contiguous with
that of implicit queries generated within the
metaphorical pretence cocoon (see Introduction)
during ATT-Meta?s goal-directed reasoning.
However, the theoretical significance of non-
declarative metaphorical utterances is even
greater, because such utterances call into
question accounts of metaphor that assume the
task of understanding is to work out what claim
about the target domain the metaphorical
utterance is making.
Compiling such examples is an additional goal
of our corpus work (see section 6).
5 Time and change
Work is ongoing which addresses the temporal,
aspectual and causal facets of metaphor. A
survey of metaphors in the ATT-Meta Databank
reveals, unsurprisingly, that the metaphorical
expressions there involve a wide range of tense
and aspectual constructions in English, including
past, present and future tenses, simple and
progressive aspects, and the full set of aspectual
classes. A wide variety of temporal adverbials is
also present. A key topic under investigation is
the mapping of temporal and aspectual
information between source and target domains.
For example, if an event is telic in the source
domain, to what extent does that telicity carry
over to the target domain? Preliminary
investigations confirm the expectation that such
aspectual information is preserved in the
majority of cases. Exceptions exist, however,
and these merit further study.
The mapping of temporal duration between
domains is also being investigated. In some
cases, a mapping appears to exist whereby an
event of long duration relative to the source
domain maps to an event with long duration
relative to the target domain. This can be
captured by an appropriate VNMA, which maps
relative durations between domains. The logic of
ATT-Meta is episode-based, which means that it
is relatively straightforward to express this kind
of constraint and employ it in reasoning.
Currently underway is a detailed examination of
metaphorical expressions involving both explicit
and implicit temporal durations. This will result
in a set of VNMAs covering a wide range of
tense/aspect/temporal-adverbial constructions.
A second strand of the work on time involves a
detailed study of the metaphors used to describe
times, states and events, including spatial
metaphor for time (Lakoff 1994).
6 Corpus Studies of Metaphor
As an adjunct to the development of the ATT-
Meta approach and system, we have been
conducting corpus studies of metaphor, mainly
using the British National Corpus but also using
the Bank of English and, to a limited extent, web
search engines. We have used both hand-
annotation of small numbers of documents from
the BNC and automated search for particular
types of metaphorical phraseology (mainly
relatively fixed metaphorical phrases concerning
mental states) over the whole of corpora.
Current objectives are (a) to develop large
databanks of examples of various types of
metaphorical utterance, for the benefit of
metaphor researchers in general, (b) to
demonstrate more extensively and objectively
the importance in discourse of "map-
transcending" metaphorical utterances (see
Introduction), (c) relatedly, to reveal the degree
to which relatively conventional metaphor
phraseology can be varied in real discourse (cf.
Moon 1998), and (d) to uncover (in small
numbers of documents) the degree to which
metaphorical utterances relate to context: how
much their understanding depends on context
and how much the understanding of the context
depends in turn on them. We are interested in (d)
because in the ATT-Meta approach the process
of metaphorical understanding is partially
guided by discourse goals set up by context.
This feature goes a long way to side-stepping
problems of apparent indeterminacy of meaning
of metaphorical utterances when taken in
isolation.
We also have the methodological objectives of
developing a good annotation regime for
metaphor and better-automated search
techniques for metaphor. As part of the latter,
we plan to investigate the usefulness of a large
set of morphological, lexical, syntactic and
phraseological clues to the presence of
metaphor, inspired by the clues discussed by
Goatly (1997). These clues are only present in a
minority of metaphorical utterances but could
nevertheless form a useful weapon in the
automated search armoury.
Metaphor detection techniques developed for
corpus study should also help with developing a
means for an understanding system to notice the
presence of metaphor. Such noticing is not
currently performed by ATT-Meta but is an
important topic for future research.
Conclusion
The ATT-Meta project is making headway in
showing how metaphorical utterances can be
computationally processed. It is based on a
distinctive set of principles as to how to
understand metaphor, some of which are original
and some related to those of previous
researchers. In particular, it seeks to avoid
expensive computation of new analogical
mappings between domains as a regular part of
metaphorical understanding. This is inspired
partly by the observation that genuinely novel
pairings of domains are relatively rare in real
discourse. What are more common are novel
extensions of familiar metaphorical views, and
novel mixes of views. This is true even in poetry
(Lakoff and Turner 1989). The project is also
seeking to take full account of the important role
that uncertainty, gradedness and dynamism of
situations plays in metaphor.
The approach and system have been evaluated in
a number of ways. We have applied the
implemented system or the theoretical approach
to (simplified versions of) selected real-
discourse examples from an existing databank
(http://www.cs.bham.ac.uk/~jab/
ATT-Meta/Databank): see Barnden (2001a),
Barnden & Lee (2001a) and Barnden & Lee
(2001b). We have applied the implemented
system to examples of all the metaphors of
mental states listed in the Master Metaphor List
(Lakoff 1994, Lee & Barnden 2001a). The
examples here were found by search over the
Bank of English. Finally, we have applied the
theoretical approach to various real-discourse
examples included in Goatly (1997): see
Barnden (2001b).
Acknowledgements
This research is supported by grant GR/M64208
from the Engineering and Physical Sciences
Research Council of the UK.
References
Barnden, J. A. (1998a)  Combining uncertain belief
reasoning and uncertain metaphor-based
reasoning. In "Procs. Twentieth Annual Meeting of
the Cognitive Science Society", Lawrence Erlbaum
Associates, Hillsdale, N.J, pp.114-119.
Barnden, J.A. (2001a)  Application of the ATT-Meta
Metaphor-Understanding Approach to Various
Examples in the ATT-Meta Project Databank.
Technical Report CSRP-01-02, School of
Computer Science, The University of Birmingham,
U.K.
Barnden, J.A. (2001b)  Application of the ATT-Meta
metaphor-understanding approach to selected
examples from Goatly. Technical Report CSRP-01-
01, School of Computer Science, The University of
Birmingham, U.K.
Barnden, J.A (2001c)  Uncertainty and conflict
handling in the ATT-Meta context-based system for
metaphorical reasoning. In ?Lecture Notes in
Artificial Intelligence?, J.G.Carbonell and
J.Siekmann, eds, Springer Verlag, Berlin.
Barnden, J.A. and Lee, M.G. (1999)  An implemented
context system that combines belief reasoning,
metaphor-based reasoning and uncertainty
handling. In " Modelling and Using Context", P.
Bouquet, P. Brezillon, L. Serafini ed., Lecture
Notes in Artificial Intelligence, No. 1688,
Springer-Verlag, pp. 28-41.
Barnden, J.A. and Lee, M.G. (2001a)  Understanding
open-ended usages of familiar conceptual
metaphors: An approach and artificial intelligence
system. Technical Report CSRP-01-05, School of
Computer Science, The University of Birmingham,
U.K.
Barnden, J.A. and Lee, M.G. (2001b)  Application of
the ATT-Meta metaphor-understanding system to
an example of the metaphorical view of MIND
PARTS AS PERSONS. Technical Report CSRP-01-
09, School of Computer Science, The University of
Birmingham, U.K.
Carbonell, J.G. (1982)  Metaphor: an inescapable
phenomenon in natural-language comprehension.
In "Strategies for Natural Language Processing",
W. Lehnert & M. Ringle ed., Lawrence Erlbaum,
Hillsdale, N.J, pp.415-434.
Goatly, A. (1997)  The language of metaphors.
Routledge, London and New York.
Lakoff, G. (1994)  The Master Metaphor List.
http://cogsci.berkeley.edu/, University of
California, Berkeley.
Lakoff, G. and Turner, M. (1989)  More than cool
reason: a field guide to poetic metaphor.
University of Chicago Press, Chicago.
Lee, M. G. and Barnden, J. A. (2001a)  Reasoning
about mixed metaphors within an implemented AI
system. Metaphor and Symbol 16, 1& 2, pp. 29-42.
Lee, M. G. and Barnden, J. A. (2001b)  Mental
Metaphors from the Master Metaphor List:
Empirical Examples and the Application of the
ATT-Meta System Technical Report CSRP-01-03,
School of Computer Science, The University of
Birmingham, U.K.
Moon, R. (1998)  Fixed idioms and expressions in
English. Clarendon Press, Oxford, U.K.
57
58
59
60
61
62
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 37?40,
Prague, June 2007. c?2007 Association for Computational Linguistics
Don?t worry about metaphor: affect extraction for conversational agents
Catherine Smith, Tim Rumbell, John Barnden, Bob Hendley, Mark Lee & Alan Wallington
School of Computer Science, University of Birmingham
Birmingham B15 2TT, UK
J.A.Barnden@cs.bham.ac.uk
Abstract
We demonstrate one aspect of an affect-
extraction system for use in intelligent con-
versational agents. This aspect performs a
degree of affective interpretation of some
types of metaphorical utterance.
1 Introduction
Our demonstration is of one aspect of a system
for extracting affective information from individ-
ual utterances, for use in text-based intelligent con-
versational agents (ICAs). Affect includes emo-
tions/moods (such as embarrassment, hostility) and
evaluations (of goodness, importance, etc.). Our
own particular ICA [Zhang et al 2006] is for use
in an e-drama system, where human users behave as
actors engaged in unscripted role-play. Actors type
in utterances for the on-screen characters they con-
trol to utter (via speech bubbles). Our ICA is an-
other actor, controlling a bit-part character. Through
extracting affect from other characters? utterances it
makes responses that can help keep the conversation
flowing. The same algorithms are also used for in-
fluencing the characters? gesturing (when a 3D ani-
mation mode is used).
The system aspect demonstrated handles one im-
portant way in which affect is expressed in most dis-
course genres: namely metaphor. Only a relatively
small amount of work has been done on computa-
tional processing of metaphorical meaning, for any
purpose, let alne in ICA research. Major work
apart from ours on metaphorical-meaning compu-
tation includes (Fass, 1997; Hobbs, 1990; Mar-
tin, 1990; Mason, 2004; Narayanan, 1999; Veale,
1998). The e-drama genre exhibits a variety of types
of metaphor, with a significant degree of linguistic
open-endedness. Also, note that our overarching re-
search aim is to study metaphor as such, not just how
it arises in e-drama. This increases our need for sys-
tematic, open-ended methods.
2 Metaphor and Affect
Conveying affect is one important role for metaphor,
and metaphor is one important way of conveying
affect. Emotional states and behavior often them-
selves described metaphorically (Ko?vecses, 2000;
Fussell & Moss, 1998), as in ?He was boiling
inside? [feelings of anger]. But another impor-
tant phenomenon is describing something X using
metaphorical source terms that are subject to that
affect, as in ?My son?s room [= X] is a bomb site?
or ?smelly attitude? (an e-drama transcript exam-
ple). Such carry-over of affect in metaphor is well-
recognized, e.g. in the political domain (Musolff,
2004). Our transcript analyses indicate that this type
of affect-laden metaphor is a significant issue in e-
drama: at a conservative estimate, in recent user
studies in secondary schools at least one in every
16 speech-turns has contained such metaphor (each
turn is   100 characters, and rarely more than one
sentence; 33K words across all transcripts).
There are other specific, theoretically interesting
metaphorical phenomena arising in e-drama that are
important also for discourse in general, and plausi-
bly could be handled reasonably successfully in an
ICA using current techniques. Some are:
1) Casting someone as an animal. This often con-
veys affect, from insultingly negative to affection-
ately positive. Terms for young animals (?piglet?,
?wolf cub?, etc.) are often used affectionately, even
37
when the adult form is negative. Animal words can
have a conventional metaphorical sense, often with
specific affect, but in non-conventional cases a sys-
tem may still be able to discern a particular affective
connotation; and even if it cannot, it can still plausi-
bly infer that some affect is expressed, of unknown
polarity (positivity/negativity).
2) Rather similarly, casting someone as a monster
or as a mythical or supernatural being, using words
such as ?monster?, ?dragon,? ?angel,? ?devil.?
3) Casting someone as a special type of human, us-
ing words such as ?baby? (to an adult), ?freak,? ?girl?
(to a boy), ?lunatic.?
4) Metaphorical use of size adjectives (cf. Sharoff,
2006). Particularly, using ?a little X? to convey af-
fective qualities of X such as unimportance and con-
temptibility, but sometimes affection towards X, and
?big X? to convey importance of X (?big event?) or
intensity of X-ness (?big bully?)?and X can itself
be metaphorical (?baby?, ?ape?).
Currently, our system partially addresses (1), (2) and
(4).
3 Metaphor Recognition & Analysis
3.1 The Recognition Component
The basis here is a subset of a list of
metaphoricity signals we have compiled
[http://www.cs.bham.ac.uk/?jab/ATT-
Meta/metaphoricity-signals.html], by modify-
ing and expanding a list from Goatly (1997). The
signals include specific syntactic structures, phrase-
ological items and morphological elements. We
currently focus on two special syntactic structures,
X is/are Y and You/you Y, and some lexical strings
such as ?[looks] like?, ?a bit of a? and ?such a?. The
signals are merely uncertain, heuristic indicators.
For instance, in the transcripts mentioned in section
2, we judged X is/are Y as actually indicating the
presence of metaphor in 38% of cases (18 out of
47). Other success rates are: you Y ? 61% (22 out of
36); like (including looks like)? 81% (35 out of 43).
In order to detect signals we use the Grammatical
Relations (GR) output from the RASP robust parser
[Briscoe et al, 2006] This output shows typed word-
pair dependencies between the words in the utter-
ance. E.g., the GR output for ?You are a pig? is:
|ncsubj| |be+_vbr| |you_ppy| |_|
|xcomp| _ |be+_vbr| |pig_nn1|
|det| |pig_nn1| |a_at1|
For an utterance of the type X is/are Y the GRs will
always give a subject relation (ncsubj) between X
and the verb ?to be?, as well as a complement re-
lation (xcomp) between the verb and the noun Y.
The structure is detected by finding these relations.
As for you Y, Rasp also typically delivers an easily
analysable structure, but unfortunately the POS tag-
ger in Rasp seems to favour tagging Y as a verb?
e.g., ?cow? in ?You cow?. In such a case, our system
looks the word up in a list of tagged words that forms
part of the RASP tagger. If the verb can be tagged
as a noun, the tag is changed, and the metaphoricity
signal is deemed detected. Once a signal is detected,
the word(s) in relevant positions (e.g. the Y posi-
tion) position are pulled out to be analysed. This
approach has the advantage that whether or not the
noun in, say, the Y position has adjectival modifiers
the GR between the verb and Y is the same, so the
detection tolerates a large amount of variation. Any
such modifiers are found in modifying relations and
are available for use in the Analysis Component.
3.2 The Analysis Component
We confine attention here to X?is/are?Y and You?Y
cases. The analysis element of the processing takes
the X noun (if any) and Y noun and uses Word-
Net 2.0 to analyse them. First, we try to determine
whether X refers to a person (the only case the sys-
tem currently deals with), partly by using a specified
list of proper names of characters in the drama and
partly by WordNet processing. If so, then the Y and
remaining elements are analysed using WordNet?s
taxonomy. This allows us to see if the Y noun in one
of its senses is a hyponym of animals or supernatural
beings. If this is established, the system sees if an-
other of the senses of the word is a hyponym of the
person synset, as many metaphors are already given
as senses in WordNet. If different senses of the given
word are hyponyms of both animal and person, other
categories in the tree between the noun and the per-
son synset may provide information about the eval-
uative content of the metaphor. For example the
word ?cow? in its metaphorical usage has the ?un-
pleasant person? synset as a lower hypernym, which
heuristically suggests that, when the word is used in
a metaphor, it will be negative about the target.
There is a further complication. Baby animal
names can often be used to give a statement a more
affectionate quality. Some baby animal names such
as ?piglet? do not have a metaphorical sense in Word-
38
Net. In these cases, we check the word?s gloss to see
if it is a young animal and what kind of animal it
is. We then process the adult animal name to seek a
metaphorical meaning but add the quality of affec-
tion to the result. A higher degree of confidence is
attached to the quality of affection than is attached
to the positive/negative result, if any, obtained from
the adult name. Other baby animal names such as
?lamb? do have a metaphorical sense in WordNet in-
dependently of the adult animal, and are therefore
evaluated as in the previous paragraph. They are
also flagged as potentially expressing affection but
with a lesser degree of confidence than that gained
from the metaphorical processing of the word. How-
ever, the youth of an animal is not always encoded
in a single word: e.g., ?cub? may be accompanied
by specification of an animal type, as in ?wolf cub?.
An extension to our processing would be required to
handle this and also cases like ?young wolf? or ?baby
wolf?.
If any adjectival modifiers of the Y noun were rec-
ognized the analyser then goes on to evaluate their
contribution to the metaphor?s affect. If the analyser
finds that ?big? is one of the modifying adjectives
of the noun it has analysed the metaphor is marked
as being more emphatic. If ?little? is found the fol-
lowing is done. If the metaphor has been tagged as
negative and no degree of affection has been added
(from a baby animal name, currently) then ?little? is
taken to be expressing contempt. If the metaphor
has been tagged as positive OR a degree of affection
has been added then ?little? is taken to be expressing
affection.
4 Examples of Course of Processing
?You piglet?:
(1) Detector recognises the you Y signal with Y =
?piglet?.
(2) Analyser finds that ?piglet? is a hyponym of ?an-
imal?.
(3) ?Piglet? does not have ?person? as a WordNet hy-
pernym so analyser retrieves the WordNet gloss.
(4) It finds ?young? in the gloss (?a young pig?) and
retrieves all of the following words (just ?pig? ? the
analysis process is would otherwise be repeated for
each of the words captured from the gloss), and finds
that ?pig? by itself has negative metaphorical affect.
(5) The input is labelled as an animal metaphor
which is negative but affectionate, with the affection
having higher confidence than the negativity.
?Lisa is an angel?:
(1) Detector recognises the X is Y signal with Y =
?angel?, after checking that Lisa is a person.
(2) Analyser finds that ?angel? is a hyponym of ?su-
pernatural being?.
(3) It finds that in another sense ?angel? is a hyponym
of ?person?.
(4) It finds that the tree including the ?person? synset
also passes through ?good person,? expressing posi-
tive affect.
(5) Conclusion: positive supernatural-
being metaphor.
Results from Some Other Examples:
?You cow?, ?they?re such sheep?: negative
metaphor.
?You little rat?: contemptuous metaphor.
?You little piggy?: affectionate metaphor with a neg-
ative base.
?You?re a lamb?: affectionate metaphor.
?You are a monster?: negative metaphor.
?She is such a big fat cow?: negative metaphor, in-
tensified by ?big? (currently ?fat? is not dealt with).
5 Concluding Remarks
The demonstrated processing capabilities make par-
ticular but nevertheless valuable contributions to
metaphor processing and affect-detection for ICAs,
in e-drama at least. Further work is ongoing on the
four specific metaphorical phenomena in section 3
as well as on other phenomena, such as the vari-
ation of conventional metaphorical phraseology by
synonym substitution and addition of modifiers, and
metaphorical descriptions of emotions themselves.
As many extensions are ongoing or envisaged,
it is premature to engage in large-scale evaluation.
Also, there are basic problems facing evaluation.
The language in the e-drama genre is full of mis-
spellings, ?texting? abbreviations, acronyms, gram-
matical errors, etc., so that fully automated evalua-
tion of the metaphorical processing by itself is dif-
ficult; and application of the system to manually
cleaned-up utterances is still dependent on Rasp ex-
tracting structure appropriately. Also, our own ul-
timate concerns are theoretical, to do with the na-
ture of metaphor understanding. We are interested
in covering the qualitative range of possibilities and
complications, with no strong constraint from their
39
frequency in real discourse. Thus, statistical evalua-
tion on corpora is not particularly relevant except for
practical purposes.
However, some proto-evaluative comments that
can be made about animal metaphors are as fol-
lows. The transcripts mentioned in section 2 (33K
words total) contain metaphors with the following
animal words: rhino, bitch, dog, ape, cow, mole,
from 14 metaphorical utterances in all. Seven of
the utterances are recognized by our system, and
these involve rhino, dog, ape, mole. No WordNet-
based metaphorical connotation is found for the
rhino case. Negative affect is concluded for bitch,
dog and cow cases, and affect of undetermined po-
larity is concluded for ape and mole.
The system is currently designed only to do rela-
tively simple, specialized metaphorical processing.
The system currently only deals with a small mi-
nority of our own list of metaphoricity signals (see
section 3.1), and these signals are only present in a
minority of cases of metaphor overall. It does not
do either complex reasoning or analogical structure-
matching as in our own ATT-Meta metaphor sys-
tem (Barnden, 2006) or the cited approaches of Fass,
Hobbs, Martin, Narayanan and Veale. However, we
plan to eventually add simplified versions of ATT-
Meta-style reasoning, and in particular to add the
ATT-Meta view-neutral mapping adjunct feature to
implement the default carry-over of affect (see sec-
tion 2) and certain other information, as well as han-
dling more signals.
Other work on metaphor has exploited WordNet
(see, e.g., Veale, 2003, and panel on Figurative Lan-
guage in WordNets and other Lexical Resources
at GWC?04 (http://www.fi.muni.cz/gwc2004/.
Such work uses WordNet in distinctly different ways
from us and largely for different purposes. Our sys-
tem is also distinctive in, for instance, interpreting
the contribution of size adjectives.
Acknowledgments
The research has been aided by Sheila Glasbey and
Li Zhang, and supported by ESRC/EPSRC/DTI Pac-
cit LINK grant (ESRC RES-328-25-0009) and EP-
SRC grant EP/C538943/1.
References
John Barnden. 2006. Artificial Intelligence, Figurative
Language and Cognitive Linguistics. In G. Kristiansen
et al (Eds), Cognitive Linguistics: Current Applica-
tions and Future Perspectives, 431?459. Berlin: Mou-
ton de Gruyter.
Ted Briscoe, John Carroll and Rebecca Watson. 2006.
The Second Release of the RASP System. In Procs.
COLING/ACL 2006 Interactive Presentation Sessions.
Sydney, Australia.
Dan Fass. 1997. Processing Metaphor and Metonymy.
Greenwich, Connecticut: Ablex.
Susan Fussell & Mallie Moss. 1998. Figurative Lan-
guage in Emotional Communication. Social and Cog-
nitive Approaches to Interpersonal Communication.
Lawrence Erlbaum.
Andrew Goatly. 1997. The Language of Metaphors.
Routledge, London.
Jerry Hobbs. 1990. Literature and Cognition. CSLI Lec-
ture Notes, 21, Stanford University, 1990.
Zolta?n Ko?vecses. 2000. Metaphor and Emotion: Lan-
guage, Culture and Body in Human Feeling. Cam-
bridge University Press, Cambridge.
James Martin. 1990. A Computational Model of
Metaphor Interpretation. Academic Press.
Zachary Mason. 2004. CorMet: A computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1), 23?44.
Andreas Musolff. 2004. Metaphor and political dis-
course: Analogical reasoning in debates about Eu-
rope. Palgrave Macmillan.
Srini Narayanan. 1999. Moving right along: A compu-
tational model of metaphoric reasoning about events.
Procs. National Conference on Art. Int., 121?128.
Serge Sharoff. 2006. How to Handle Lexical Semantics
in SFL: A Corpus Study of Purposes for Using Size
Adjectives. System and Corpus: Exploring Connec-
tions. Equinox, London.
Tony Veale. 1998. ?Just in Time? analogical mapping, an
iterative-deepening approach to structure-mapping. In
Procs. 13th European Conference on Art. Intell.
Tony Veale. 2003. Dynamic Type Creation in Metaphor
Interpretation and Analogical Reasoning: A Case-
Study with WordNet. In Procs. International Confer-
ence on Conceptual Structures (Dresden).
Li Zhang, John Barnden, Bob Hendley & Alan Walling-
ton. 2006. Exploitation in Affect Detection in Impro-
visational E-Drama. In Procs. 6th Int. Conference on
Intelligent Virtual Agents: Lecture Notes in Computer
Science, 4133, 68?79. Springer.
40
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 109?112,
Prague, June 2007. c?2007 Association for Computational Linguistics
On the formalization of Invariant Mappings for Metaphor Interpretation
Rodrigo Agerri, John Barnden, Mark Lee and Alan Wallington
School of Computer Science, Univ. of Birmingham
B15 2TT Birmingham, UK
r.agerri@cs.bham.ac.uk
Abstract
In this paper we provide a formalization of
a set of default rules that we claim are re-
quired for the transfer of information such
as causation, event rate and duration in the
interpretation of metaphor. Such rules are
domain-independent and are identified as in-
variant adjuncts to any conceptual metaphor.
We also show a way of embedding the in-
variant mappings in a semantic framework.
1 Introduction
It is generally accepted that much of everyday lan-
guage shows evidence of metaphor. We assume the
general view that metaphor understanding involves
some notion of events, properties, relations, etc. that
are transferred from the source domain into the tar-
get domain. In this view, a metaphorical utterance
conveys information about the target domain. We
are particularly interested in the metaphorical utter-
ances that we call map-transcending. Consider the
following example:
(1) ?McEnroe starved Connors to death.?
We do not address in this paper the issue of
when an utterance is to be considered metaphor-
ical. Instead, we aim to offer an explanation of
how a metaphorical utterance such as (1) can be in-
terpreted. If we infer, using our knowledge about
McEnroe and Connors, that (1) is used to describe
a tennis match, it can be understood as an exam-
ple of the conceptual metaphors (or, in our termi-
nology, ?metaphorical views?) DEFEAT AS DEATH
and NECESSITIES AS FOOD. However, these
metaphorical views would not contain any relation-
ship that maps the specific manner of dying that con-
stitutes being starved to death (we say that ?starv-
ing? is a map-transcending entity). Yet one could
argue that the manner of Connors?s death is a cru-
cial part of the informational contribution of (1).
A possible solution would be to create a new
view-specific mapping that goes from the form of
killing involved in starving to death to some process
in sport, but such enrichment of mappings would be
needed for many other verbs or verbal phrases that
refer to other ways in which death is brought about,
each requiring a specific specific mapping when oc-
curring in a metaphorical utterance. Thus, finding
adequate mappings could become an endless and
computational intensive process. Moreover, there
are even cases in which we may not find a plausi-
ble mapping. Consider the following description of
the progress of a love affair:
(2) ?We?re spinning our wheels.?
It is not very clear what could be a target corre-
spondent for ?wheels?. We have developed an AI
system called ATT-Meta for metaphor interpretation
(Barnden et al, 2002) that employs reasoning within
the terms of the source domain using various sources
of information including world and linguistic knowl-
edge. The reasoning connects unmapped ideas used
by utterances, such as wheels and starving, to other
source-domain ideas for which a mapping is already
known. These known mappings may be constituents
of particular metaphorical view, but previous work
(Barnden et al, 2003; Wallington et al, 2006) has
109
shown evidence that there are metaphorical aspects
(such as causal relations between events) that, sub-
ject to being called, invariantly map from source to
target (we call these mappings View-Neutral Map-
ping Adjuncts or VNMAs) irrespective of whatever
specific metaphorical views are in play. These allow
many mapping effects, which would otherwise have
to be duplicated across all view-specific mappings,
to be factored out into separate mappings. In our
approach, source domain reasoning takes place in a
special, protected computational context that we call
the ?pretence space?. We use the term ?reality? to
refer to the space outside the pretence where propo-
sitions are about reality as the understander sees it.
Currently ATT-Meta implements the VNMAs by
including them in view-specific rules, but we plan to
make the system more modular and its view-specific
mappings more economical by implementing VN-
MAs as separate default rules. The first step to-
wards that goal is to provide a formalization of these
mappings and to show their role in metaphor in-
terpretation. In order to do so, we provide a se-
mantic representation of how these VNMAs work
by adopting Segmented Discourse Representation
Theory (Asher and Lascarides, 2003) to capture the
main aspects of the ATT-Meta approach.
2 Knowledge and Inference
If (1) is being used metaphorically to describe the
result of a tennis match, a plausible target interpre-
tation would be that McEnroe defeated Connors in a
slow manner by performing some actions to deprive
him of his usual playing style. Assuming a com-
monsensical view of the world, a within-pretence
meaning would be that McEnroe starved Connors to
death in the real, biological sense. The inferencing
within the pretence can then conclude that McEnroe
caused Connors?s death by depriving or disabling
him. Leaving some details aside, the partial logical
form (in the pretence) of the metaphorical utterance
(1) may be represented as follows (without taking
into account temporal issues):
(i) ?x, y, e(McEnroe(x) ? Connors(y)
?starve? to? death(e, x, y))
This says that there is an event e of x starving y to
death (we also use the notion of event to describe sit-
uations, processes, states, etc.). It may be suggested
that if we were trying to map the partial expression
(i), its correspondent proposition in the target could
be expressed by this formula:
(ii) ?x, y, e(McEnroe(x) ? Connors(y)?
defeat(e, x, y))
According to this, the event of x defeating y in
the reality would correspond to the event of x starv-
ing y to death in the pretence. However, by say-
ing ?McEnroe starved Connors to death? instead of
simply ?McEnroe killed Connors? the speaker is not
merely intending to convey that McEnroe defeated
Connors, but rather something related to the man-
ner in which Connors was defeated. Following this,
starving may be decomposed into the cause e1 and
its effect, namely, ?being deprived of food?:
(iii) ?x, y, z, e1, e2, e3(McEnroe(x)?
Connors(y) ? food(z) ? starve(e1, x, y) ?
death(e2, y) ? deprived(e3, y, z)?
cause(e1, e3))
Now, by means of lexical information regarding
?starving?, it can be inferred that McEnroe deprived
Connors of a necessity (see, e.g., Wordnet), namely,
of the food required for his normal functioning (the
NECESSITIES AS FOOD metaphorical view would
provide mappings to transfer food to the type of
shots that Connors needs to play his normal game).
In other words, Connors is defeated by the partic-
ular means of depriving him of a necessity (food)
which means that being deprived causes Connors?s
defeat. This fits well with the interpretation of (1)
where McEnroe?s playing deprived Connors of his
usual game. Moreover, linguistic knowledge also
provides the fact that starving someone to death is a
gradual, slow process. The result of within-pretence
inferencing may be represented as follows:
(iv) ?x, y, z, e1, e2, e3(McEnroe(x)?
Connors(y) ? food(z) ? starve(e1, x, y) ?
death(e2, y) ? deprived(e3, y, z)?
cause(e1, e3)?cause(e3, e2)?rate(e1, slow))
?Slow? refers to a commonsensical concept in the
pretence related to the progress rate of starving.
Now, the existing mapping DEFEAT AS DEATH
can be applied to derive, outside the pretence, that
McEnroe defeated Connors, but no correspondences
110
are available to account for the fact that McEnroe
caused the defeat of Connors by depriving him of
his normal play. We appear to have a problem also
to map the slow progress rate of a process like starv-
ing.
3 VNMAs in a Semantic Framework
In the ATT-Meta approach to metaphor interpreta-
tion, the mappings of caused and rate discussed
above are accomplished by a type of default map-
pings that we specify as VNMAs (the Causation
and Rate VNMAs, respectively; see (Wallington and
Barnden, 2006) for an informal but detailed de-
scription of a number of VNMAs). The idea is
that there are relationships and properties (causation,
rate, etc.) between two events or entities that iden-
tically transfer from the pretence to the reality. We
use the 7? symbol to express that this mapping is a
default. The VNMAs involved in the interpretation
of (1) can be represented as follows:
Causation: ?e1, e2(cause(e1, e2)pret 7?
cause(e1, e2)rlt)
The Rate VNMA transfers the qualitative rate of
progress of events in the source domain to the qual-
itative rate of progress of its mappee:
Rate: ?e, r(rate(e, r)pret 7? rate(e, r)rlt)
Embedding the VNMAs in a semantic framework
for metaphor interpretation is useful as a first step
towards their implementation as default rules in the
ATT-Meta system, but it is also interesting in its
own right to show the contribution that the ATT-
Meta approach can make towards the semantics of
metaphor. In the somewhat simplified discussion
on the within-pretence reasoning and mappings nec-
essary to interpret metaphorical utterances such as
(1), we have been using various sources of informa-
tion that interact in the processing of the utterance:
a) View-specific mappings provided by the relevant
metaphorical views (DEFEAT AS DEATH and NE-
CESSITIES AS FOOD); b) Linguistic and contex-
tual information necessary for reasoning in the pre-
tence; c) Relations and properties between events
such as causation and rate that are inferred in the
pretence; d) VNMAs that transfer within-pretence
event relations and properties to reality.
There are two prominent computationally-
oriented semantic approaches (Hobbs, 1996) and
(Asher and Lascarides, 2003) that take into account
contextual and linguistic information and stress the
importance of relations between text segments in
discourse interpretation. In fact, the incorporation
of the above types of information ties in well with
the SDRT (Asher and Lascarides, 2003) view of
language understanding. For example, we can think
of the pretence space as a Segmented Discourse
Representation Structure (SDRS) representing the
result of within-pretence inference which can be
mapped by using various view-specific and invariant
mappings to reality. In other words, we can see the
pretence SDRS as the input for what the ATT-Meta
system does when interpreting metaphor ? it will
reason with it, producing an output of inferred
reality facts which we may also represent by means
of an SDRS. The result of reasoning in the pretence
to interpret (1) would now looks as follows:
PRET:
?, ?, ?
?:
x, y, e1
McEnroe(x)
Connors(y)
starve(e1, x, y)
?:
e2
death(e2, y)
?:
e3 ,z
food(z)
deprived(e3, y, z)
cause(e1, e3)
cause(e3 ,e2)
rate(e1 ,slow)
7??
where ? and ? are labels for DRSs representing
events, PRET for a pretence space and 7?? map-
pings (VNMAs and central mappings) needed in the
interpretation of the metaphorical utterance. Impor-
tantly, the VNMAs would pick upon aspects such
as causation and rate from pretence to transfer them
to reality producing an output which could also be
represented as a SDRS:
RLT:
?, ?, ?
?:
x, y, e1
McEnroe(x)
Connors(y)
tennis-play(e1, x, y)
?:
e2
defeat(e2, y)
?:
e3 ,z
necessity(z)
deprived(e3, y, z)
cause(e1, e3)
cause(e3,e2)
rate(e1 ,slow)
Note that this formal representation integrates the
systematicity of mapping invariantly certain aspects
of metaphorical utterances by formulating them as
relations between events that can be represented as
111
relations and properties of DRSs. For this purpose
we need to modify the construction rules of SDRSs
to be able to infer properties and relations involving
individuals and not only DRSs? labels. In addition
to this, we have shown in the previous section how
ATT-Meta source domain reasoning captures the in-
teraction of the various sources of knowledge used
to infer causation and rate in the pretence. Further-
more, studying the interaction between VNMAs and
discourse relations may allow us to extend the study
of metaphor to discourse.
4 Concluding Remarks
Following the ATT-Meta claim metaphors often con-
vey crucial information via VNMAs, we can re-
analyze example (1) so that the effects of the NE-
CESSITIES AS FOOD mapping are obtained by
VNMAs. In the pretence, the food is something
Connors needs for proper functioning: i.e., it is nec-
essary that Connors have the food in order to func-
tion properly. The necessity here is covered by the
Modality VNMA, which maps relative degrees of
necessity, possibility, obligation, etc., from pretence
to reality. Moreover, the functioning properly would
be covered by the Function and Value-Judgement
(levels of goodness, importance, etc. map identi-
cally to levels of goodness, etc.). So all that is left is
the possession which could be covered by a STATE
AS POSSESSION mapping.
Formal semantic approaches (Asher and Las-
carides, 2003) do not account for metaphorical ut-
terances including map-transcending entities. Other
works (Carbonell, 1982; Hobbs, 1990; Martin,
1990; Narayanan, 1997) have addressed source do-
main reasoning to a limited extent, but its role in
metaphor interpretation has not previously been ad-
equately investigated. Moreover, map-transcending
entities pose a problem for analogy-based ap-
proaches to metaphor interpretation (Falkenhainer
et al, 1989), which require the discovery of an
elaborate structural similarity between the source
and target domains and/or the imposition of un-
mapped source domain structures on the target do-
main, whereas part of our approach is that the un-
mapped source domain structure introduced by the
utterance is by default not carried over.
Acknowledgements Supported by EPSRC
EP/C538943/1 and GR/M64208 grants.
References
Nicholas Asher and Alex Lascarides. 2001. The seman-
tics and pragmatics of metaphor. In P. Bouillon and F.
Busa, editors, The Language of Word Meaning, pages
262?289. Cambridge University Press.
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
John Barnden, Sheila Glasbey, Mark Lee, and Alan
Wallington. 2002. Reasoning in metaphor under-
standing: The att-meta approach and system. In 19th
Conference on Computational Linguistics (COLING-
2002).
John Barnden, Sheila Glasbey, Mark Lee, and
Alan Wallington. 2003. Domain-transcending
mappings in a system for metaphorical reasoning.
In Conference Companion to the 10th Conference
of the European Chapter of the Association for
Computational Linguistics (EACL 2003), pages
57?61.
Jaime Carbonell. 1982. Metaphor: An inescapable
phenomenon in natural-language comprehension. In
W. Lehnert and M. Ringle, editors, Strategies for Nat-
ural Language Processing, pages 415?434. Lawrence
Erlbaum, Hillsdale, NJ.
BrianFalkenhainer, Kenneth Forbus, and Dedre Gentner.
1989. The structure-mapping engine: algorithm and
examples. Artificial Intelligence, 41(1):1?63.
Jerry Hobbs. 1990. Literature and Cognition. CSLI,
Lecture Notes, Stanford.
Jerry Hobbs. 1996. An approach to the structure of dis-
course. In D. Everett, editor, Discourse: Linguistic,
Computational and Philosophical Perspectives.
James Martin. 1990. A computational model of
metaphor interpretation. Academic Press, New York.
Srini Narayanan. 1997. KARMA: Knowledge-based ac-
tion representations for metaphor and aspect. Ph.D.
thesis, Computer Science Division, EECS Depart-
ment, University of California, Berkeley, August.
Alan Wallington and John Barnden. 2006. Similarity as
a basis for metaphor: Invariant transfer and the role
of VNMAs. Technical Report CSRP-06-02, School of
Computer Science, Univ. of Birmingham, December.
Alan Wallington, John Barnden, Sheila Glasbey, and
Mark Lee. 2006. Metaphorical reasoning with an eco-
nomical set of mappings. Delta, 22(1).
112
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 984?995, Dublin, Ireland, August 23-29 2014.
A Hybrid Approach to Features Representation for Fine-grained Arabic
Named Entity Recognition
Fahd Alotaibi
School of Computer Science
University of Birmingham, UK
fsa081@cs.bham.ac.uk
Faculty of Computing
King Abdulaziz University, KSA
fsalotaibi@kau.edu.sa
Mark Lee
School of Computer Science
University of Birmingham, UK
m.g.lee@cs.bham.ac.uk
Abstract
Despite considerable research on the topic of Arabic Named Entity Recognition (NER), almost
all efforts focus on a traditional set of semantic classes, features and token representations. In
this work, we advance previous research in a systematic manner and devise a novel method
to represent these features, relying on a dependency-based structure to capture further evidence
within the sentence. Moreover, the work also describes an evaluation of the method involving the
capture of global features and employing the clustering of unannotated textual data. To meet this
set of goals, we conducted a series of evaluations to evaluate different aspects that demonstrate
great improvement when compared with the baseline model.
1 Introduction
Traditionally, the focus of Arabic NER has been on a very limited number of semantic classes, i.e.
PERSON, ORGANISATION and LOCATION, utilising the newswire domain such as those described
by Benajiba and Rosso (2008), Benajiba et al. (2010) and Abdul-Hamid and Darwish (2010) . This limits
higher-level applications (such as question answering) from extracting in-depth knowledge and working
on a relatively open domains.
This paper addresses the issue of a fine-grained NER of 50 classes for Arabic and presents a com-
prehensive set of experiments that evaluate innovative means of representing the features set. Thus, the
contribution of this paper falls into different categories with unique outcomes, as follows:
1. A novel approach to representing the features is used, relying on dependency representation. This
representation overcomes the drawback of current window-based representations of features.
2. The representation of global evidence involves clustering unannotated textual data, employing hier-
atical clusters (Brown et al., 1992).
3. Due to the fact that there is no comparable work to use as a comparison in the task of Arabic fine-
grained NER, a baseline model was developed, based on Conditional Random Fields (CRF), using
the best features, as established and used elsewhere in the literature.
4. Development of publically available gold-standard fine-grained NER corpora
1
from two different
genres, i.e. Newswire and Wikipedia.
Each contribution is discussed in more detail during in the remainder of this paper.
2 Arabic Fine-grained Named Entity Corpora
The majority of Arabic NER approaches are supervised, ensuring that the machine learns from an an-
notated corpus and aims to predict unseen text. This approach requires a reasonable bank of labelled
data. This section examines the availability of such an annotated dataset at the fine-grained level, and the
creation of gold-standard corpora.
This work is licensed under a Creative Commons Attribution 4.0 International Licence.
1
Available at: http://sourceforge.net/projects/arabic-named-entity-corpora/ and
Mirror at: http://fsalotaibi.kau.edu.sa/Pages-Arabic-NE-Corpora.aspx
984
2.1 Available Corpora
One of the earliest corpora publically released was ANERcorp, developed by Benajiba et al. (2007). This
is a newswire based corpus and follows the CoNLL format. It annotates into four coarse-grained classes:
PERSON, ORGANISATION, LOCATION, and MISCELLANEOUS. This dataset has been extensively
used such as in (Benajiba et al., 2008b; Benajiba et al., 2010; Abdul-Hamid and Darwish, 2010).
Among corpora applying a fine-grained level of classes are those released by the Linguistic Data
Consortium
2
(LDC). They released two multilingual NE corpora including Arabic (Mitchell et al., 2005;
Walker et al., 2006). Both corpora were used in the Automatic Content Extraction (ACE) technology
evaluation, at the coarse-grained level only. However, these corpora are governed by a costly annual
license, which prevents the researcher from accessing and utilising them. At present, we are not aware
of a study tackling fine-grained Arabic NER using this dataset.
Alotaibi and Lee (2013) released fine-grained Arabic NE corpora - WikiFANE
Selective
and
WikiFANE
Whole
. These were built automatically using the Arabic version of Wikipedia and released
under the Creative Commons Attribution-ShareAlike 3.0 Unported Licence.
3
. These corpora apply a
similar annotation taxonomy to that of the ACE corpus, but deliver increased coverage through the in-
clusion of a new class, i.e. PRODUCT, which includes Books, Movies, Sound, Hardware, Software,
Food, Drugs and Other. Moreover, the corpora divide the PERSON class into 10 fine-classes, in order
to provide wider coverage (i.e. Politician, Athlete, Businessperson, Artist, Scientist, Police, Religious,
Engineer and Group). It is notable that this taxonomy can be easily mapped into CoNLL and ACE at
either the coarse or fine-grained levels.
2.2 Creating Gold-standard Fine-grained Named Entity Corpora
Since the aim of this paper is to conduct an in-depth experiment for fine-grained Arabic NE, we manually
created gold-standard fine-grained NE corpora for Arabic, drawing on two different genres. This gives a
critical benchmark for evaluation and comparison with the automatically constructed corpus.
The first corpus is newswire-based, using the same textual data appearing in ANERcorp. The complete
corpus was re-annotated to the fine-grained level. The second corpus is drawn from the Arabic version of
Wikipedia. The selection of articles was made using a random heuristic, i.e. selecting articles discussing
a named entity and maintaining a fair level of distribution among the classes. Moreover, the amount of
textual data drawn from the Wikipedia article was restricted by avoiding such elements as lists, headings,
and captions on images and tables.
2.3 Annotation Strategy and Quality Evaluation
For both corpora, the two-level taxonomy presented by Alotaibi and Lee (2013) was applied. This con-
sists of 8 coarse-grained classes and 50 fine-grained classes. An in-house tool to facilitate the annotation
process was developed. Two independent graduate-level Arabic native speakers were engaged to anno-
tate the entire corpora. They were provided with extended instructions to guide them in the annotation
process and a number of feedback sessions were conducted in the early stages of the process to ensure
that any difficulties could be resolved.
After its completion, the quality of the annotation was evaluated by calculating the inter-
annotator agreement between both annotators. The entity F-measure was used to evaluate the inter-
annotation agreement as in (Hripcsak and Rothschild, 2005; Zhang, 2013). The corpora were named
NewsFANE
Gold
and WikiFANE
Gold
, referring to News-based, and Wikipedia-based, Fine-grained Ara-
bic Named Entity Gold corpus, respectively. Micro-averaging was used while matching exact phrases, in
order to calculate the agreement. The size and the inter-annotator agreement of NewsFANE
Gold
is 170K
of tokens and 91% while WikiFANE
Gold
is 500K of tokens and 89% .
2
https://www.ldc.upenn.edu/
3
Available at: http://www.cs.bham.ac.uk/?fsa081/resources.html
Mirror at: http://sourceforge.net/projects/arabic-named-entity-corpora/
985
Corpus Token level Phrase level
NewsFANE
Gold
10.7 6.7
WikiFANE
Gold
13.1 7.4
WikiFANE
Selective
10.8 6.4
WikiFANE
Whole
7.08 4.9
Table 1: The density of NEs on token and phrase levels
Corpus
Length
1 2 3 4 5 6 7 8
NewsFANE
Gold
58.19 30.77 8 1.73 0.82 0.21 0.2 0.04
WikiFANE
Gold
51.75 31.55 10.88 3.48 1.34 0.46 0.21 0.12
WikiFANE
Selective
48.27 37.95 10.22 2.98 0.41 0.11 0.05 0.01
WikiFANE
Whole
66.22 25.85 6.02 1.58 0.05 0.02 0.01 0.01
Table 2: The distribution of NE phrases relative to length.
3 Corpus-based Evaluation and Comparison
It is important to closely evaluate and compare different corpora. The nature of the distribution of NE
phrases is expected to differ to some extent, affecting the performance of learning the probabilistic model.
Therefore, the coverage of NE phrases related to different aspects was studied, including the distribution
of density, length and semantic classes.
3.1 The Density of NE
The density represents the coverage of NEs at the level of tokens and phrases. As can be seen in Ta-
ble 1, WikiFANE
Gold
has the greater density at both levels. This demonstrates that the Wikipedia-
based gold corpus tends to represent more NE phrases in context than that of the newswire-based.
Although WikiFANE
Gold
is 0.7% denser than NewsFANE
Gold
in the phrase level, it reveals a notable
difference (2.4%) in the token level. This indicates that WikiFANE
Gold
possess a greater variety in the
length of NE phrases than the newswire-based corpus. However, the automatically developed corpus,
WikiFANE
Selective
, has a similar density of coverage as NewsFANE
Gold
whereas the WikiFANE
Whole
demonstrates a low level of density, due to its method of compilation.
3.2 The Distribution of the Length of Named Entity Phrases
It can be seen in Table 2, NewsFANE
Gold
and WikiFANE
Whole
tend to have more single-word NE
phrases than other corpora. When it comes to the newswire corpus, this is due to differences in the way
the NE phrases are written in a newswire domain. On the other hand, the boundaries of multi-word NE
phrases are difficult to detect, in Arabic, due to the fact that the language has a complex morphology.
This is demonstrated in the Wikipedia corpora, i.e. the gold and the selective - less than half the NE
phrases in WikiFANE
Selective
are single-word, with a slightly higher rate found in WikiFANE
Gold
.
3.3 The Distribution of the Fine-grained Classes
This demonstrates the distribution of NE phrases into fine-grained classes according to their annotation.
As shown in Figure 1, the majority of classes tend (to some extent) to have a relatively harmonic dis-
tribution. In general, the newswire-based corpus tends to include more NE phrases related to politics,
government, commerce, nations and cities, whereas the automatically-built corpora score a very high
frequency on NE types such as ?Nation? and ?Population-centre?. Moreover, WikiFANE
Gold
shows wide
distribution on most of the fine-grained classes of ?PERSON?, ?LOCATION?, ?FACILITY?, ?VEHICLE?
and ?PRODUCT?, compared to other corpora.
986
Figure 1: Distribution of Fine-grained Classes
4 The Baseline Model for Fine-grained Arabic NER
In order to prepare the baseline model and conduct successive experiments, the dataset for each corpus
was divided into training, development and test. It is important to emphasise that, due to the limitations
of computation power and the space allocated for the machine used, only a portion of WikiFANE
Selective
and WikiFANE
Whole
were selected with a size of ?500K tokens each. The following table shows each
corpus and its size.
Corpus Type Training Dev Test
NewsFANE
Gold
gold-standard 120K 25K 25K
WikiFANE
Gold
gold-standard 350K 75K 75K
WikiFANE
Selective
automatically-developed 354K 73K 73K
WikiFANE
Whole
automatically-developed 356K 72K 72K
Table 3: The size of the training, development and test for each corpus
Since there is no comparative work in the form of a fine-grained Arabic NER to use as a comparison,
a baseline model based on Conditional Random Fields (CRF) was developed. It was decided to use the
most successful features of the coarse-grained NER. For this purpose, the following features were ex-
tracted: Lexical and contextual features (current token, two tokens before and after the current token,
first and last three characters of the token, and length of the token); Morphological features (gender,
number and person); Syntactical features (part of speech and base phrase chunk); and External knowl-
edge (the presence of the token in the gazetteer developed by Alotaibi and Lee (2013)). It was decided to
use the BILOU scheme representation for the baseline model and successive experiments, as suggested
by Ratinov and Roth (2009). The performance of the baseline model is presented in Table 4.
Corpus
Development Test
P R F P R F
NewsFANE
Gold
79.58 57.87 67.01 73.07 53.34 61.67
WikiFANE
Gold
62.19 43.67 51.31 68.13 44.78 54.04
WikiFANE
Selective
89.01 68.92 77.69 88.69 60.37 71.84
WikiFANE
Whole
82.35 49.83 62.09 84.27 58.63 69.15
Table 4: The results of the baseline model by learning CRF classifier with traditional features
987
5 Dependency based Features Representation
The current representation of the sequence tagging classifier involves using a predefined window of to-
kens (e.g. with size 5, including the current token) in order to capture local evidence. This representation
has the following three drawbacks:
1. It is restricted to only capturing local evidence.
2. It fails to capture the relationship between dependent tokens, particularly for long sentences and
multiword NE phrases.
3. Since Arabic has a relatively free word order, the window-based feature representation cannot cap-
ture the order variation for different examples.
In this paper, a new approach has been devised to utilise further evidence within a sentence in the classifi-
cation process. The key idea informing this approach was to rely on the dependency-based representation
of sentences in order to extract valuable features.
The dependency structure is one of syntactical representations, where a sentence is analysed by con-
necting its words in a word-to-word relationship. These relationships specify the head and dependent
tokens in context, and assign a grammatical role for each token, e.g. subject, object and modifier.
To elaborate on the amount of knowledge that can be utilised based on the dependency structure,
consider the following sentences:
? (?A... dm yJ ??rJ yJ ?A?wO?  ?? Ty??F?  ??Am?   A  Hl? Hy?C ?A? /qAl
r?yys mjls AtHAd AlmHAkm AlAslAmy~ fy AlSwmAl ?syx ?sryf ?syx OHmd fy ...Alx/ ?The head of
the Council of the Islamic Courts Union, Sheikh Sharif Sheikh Ahmed, said in Somalia ...etc.?)
? (Cwy? ?w Ah ?A? ?t?  ?ry?  ?CA?z?  d` ?zyl??  ?FAys?  ??Cw? z?CAJ ?wq?
?A... Ay?AW?r ? CE? Hy?C /yqwl ?sArlz mwrfy AlsyAsy AlAnjlyzy b?d AlzyAr~ AlOxyr~ Alty
qAm bhA jwn myjwr r?yys wzrA? bryTAnyA ...Alx/ ?Charles Murphy, the English politician, said
after the recent visit by John Major, Britain?s prime minister ... etc.?)
? (2000 
 HWs?  ?? ?A?wOl? ?Asy?C 	t?  ?s  ?} ? r?@? /y?kr On SlAd Hsn Antxb
r?yysA?a llSwmAl fy A?sTs
?
Ab 2000/ ?It was mentioned that, Salad Hassan was elected as president
of Somalia in August 2000?)
The dependency representation and an English gloss of each example are shown in Figure 2. The parsed
output includes a new set of information, which can be utilised as features, as follows:
1. Head and Dependent Relation: The relationship between the head and the dependent is one
of the most important features to capture. Consider the token (yJ /?syx/ ?Shaikh?), in Figure 2a; the
head (Hy?C /r?yys/ ?the head of?) is located far away and cannot be captured in the local window-based
representation. Moreover, the vice versa relationship between the dependent and head is also useful.
Consider the example in Figure 2b: the token (?w /jwn/ ?John?) has two dependents (Cwy? /myjwr/
?Major?) and (Hy?C /r?yys/ ?Prime?)4 where the latter dependent (i.e. ?Hy?C?) gives a useful clue of the
way in which it has been used in political contexts. The sequence of heads or dependents can also be
utilised in the same way.
2. Sibling Relation: The sibling tokens are those dependent on the same head. Siblings can be
located near each other in context, or appear at a distance. For example: the sibling of the token (yJ
/?syx/ ?Shaikh?) is (Hl? /mjls/ ?council?), in Figure 2a, is expected to appear in a political context,
which gives a clue towards the target NE class. Meanwhile, the token (?? /fy/ ?in?) is also a sibling, and
can be avoided as it is a stop word. This is also the case in the example presented in Figure 2c, where
the token ( ?} /SlAd/ ?Salad?) is a sibling to the token (	t?  /Antxb/ ?elected?), which relates to the
political context.
4
Different contexts yield different English translation of the token ?Hy?C? as ?the head of? and ?Prime?
988
?A? Hy?C Hl?  A  ??Am?  Ty??F?  ?? ?A?wO?  yJ ??rJ yJ dm
11110010 1110000110 1110000111 111000010 1000 1101100 1111110 10100 1100100 1100100 1100100 1100100
qAl rYys mjls At.hAd Alm.hAkm AlAslAmyh fy Al.swmAl ?syx ?sryf ?syx A.hmd
said head council union courts islamic in Somalia Shaikh Sheriff Shaikh Ahmed
VRB NOM NOM NOM Al-NOM Al-NOM-p PRT-PREP NOM-PROP NOM-PROP NOM-PROP NOM-PROP NOM-PROP
O O B-Gov I-Gov I-Gov L-Gov O U-Nation B-Poli I-Poli I-Poli L-Poli
root
SBJ
IDF
IDF
IDF
MOD
MOD
OBJ
MOD
? ? ?
(a) The first example. (The second row represents the clusters according to the Brown algorithm)
?wq? z?CAJ ??Cw? ?FAys?  ?zyl??  d` ?CA?z?  ?ry?  ?t?  ?A? 
 A? ?w Cwy? Hy?C ? CE? Ay?AW?r
yqwl ?sArlz mwrfy AlsyAsy AlAnjlyzy bEd AlzyArp AlAxyrp Alty qAm b hA jwn myjwr rYys wzrA? bryTAnyA
says Charles Murphy politician English after visit recent which did for it John Major prime minister Britain
VRB NOM NOM-y Al-NOM-y Al-NOM-y NOM-PREP Al-NOM-p Al-NOM-p Al-NOM-y VRB PRT NOM-PRON NOM-PROP NOM-PROP NOM NOM NOM-PROP
O B-Poli L-Poli O O O O O O O O O B-Poli L-Poli O O B-Nation
root
SBJ
IDF
MOD
MOD
MOD
IDF
MOD
MOD
MOD
MOD
OBJ
SBJ
?
MOD
IDF
IDF
(b) The second example
r?@? ?  ?} ?s 	t?  ?Asy?C ? ?A?wO?  ?? HWs?  
 2000
mentioned that Salad Hasan elected president for Somalia in August August 2000
y*kr An SlAd Hsn Antxb rYysA l AlSwmAl fy AgsTs Ab 2000
mentioned that Salad Hasan elected president for Somalia in August August 2000
VRB PRT-An NOM NOM-PROP VRB-PASS NOM PRT-l NOM-PROP PRT-PREP NOM-PROP NOM-PROP NUM-NOM
O O B-Politician L-Politician O O B-Nation L-Nation O O O O
root
SBJ
SBJ
MOD
MOD
MOD
MOD
OBJ
MOD
OBJ
?
MOD
(c) The third example
Figure 2: The examples of a dependency structure. The rows show the Arabic token, Buckwalter translit-
eration, English gloss, POS and NE tag, respectively (the sentence is displayed left to right).
3. Syntactic Roles: The syntactical roles also benefit by being utilised to capture NE phrases in
context. Among those with concern for NER are:
a. SBJ and OBJ: defines which subject and object roles are assigned to the head token of the NE
phrase. For example, the tokens ( ?} /SlAd/ ?Salad?) and (z?CAJ /?sArlz/ ?Charles?) are tagged as
subjects.
b. IDF
5
: the Idafa chain is another important syntactical role, which helps to identify multiword NE
phrases. For example: the token (??Cw? /mwrfy/ ?Murphy?) is tagged as an IDF of its previous token
(z?CAJ /?sArlz/ ?Charles?), where this indicates a multiword NE phrase. This is also the case for the
example (Ty??F?  ??Am?   A  Hl? /mjls AtHAd AlmHAkm AlIslAmy~/ ?Council of the
Islamic Courts Union?) where all tokens are assigned an IDF role except the last token.
c. Flat relation (?): is a special role used by a CATiB pipeline parser for the sequence of proper
nouns. For example: NE phrases such as (dm yJ ??rJ yJ /?syx ?sryf ?syx OHmd/ ?Sheikh Sharif
Sheikh Ahmed?), in which all tokens are assigned a flat relation.
5
The naming of this abbreviation is used in CATiB to represent the syntactical role of idafa.
989
Corpus
Development Test
+|-
P R F P R F
NewsFANE
Gold
79.84 56.75 66.34 76.14 57.70 65.65 +3.98
WikiFANE
Gold
71.17 46.95 56.58 75.18 45.10 56.38 +2.34
WikiFANE
Selective
87.00 73.55 79.71 85.78 69.18 76.59 +4.75
WikiFANE
Whole
88.58 66.97 72.22 85.15 59.01 69.71 +0.56
Table 5: The results of the dependency-based features representation. (?+|-? represents the variation
compared with the previous experiment)
5.1 Dependency-based Features set
The representation of the dependency structure presents each token as a node. A particular token (T)
should have one node and only one head (H), except for the root, and zero or more dependents (D). A
token (T) can have zero or more siblings (S), where they are connected, (i.e. are dependent), to the same
head. Therefore, the following set of features has been extracted:
1. The current token T
2. POS of T
3. The presence of T in the Gazetteer
4. Syntactical role of T
5. Token of 1st, 2nd and 3rd Head H
6. Syntactical role of 1st, 2nd and 3rd H
7. POS of 1st, 2nd and 3rd H
8. Token of 1st, 2nd and 3rd Dependent D or ?NA? otherwise
9. Syntactical role of 1st, 2nd and 3rd D or ?NA? otherwise
10. POS of 1st, 2nd and 3rd D or ?NA? otherwise
11. Token of 1st, 2nd and 3rd Sibling S or ?NA? otherwise
12. Syntactical role of 1st, 2nd and 3rd S or ?NA? otherwise
13. POS of 1st, 2nd and 3rd S or ?NA? otherwise
The 1st, 2nd and 3rd ?H? represent the parent, grandparent and great grandparent heads; while the 1st,
2nd and 3rd ?S? represent the first three siblings (if any).
5.2 Evaluation
It was decided to use the CATiB pipeline tool
6
(produced by Marton et al. (2013)), to parse all corpora
and produce the set of features presented in the previous section. Since the POS tag set produced using
the CATiB pipeline tool is very limited, it was decided instead to rely on the output of the AMIRA to-
keniser and POS tagger produced by Diab (2009). The same classifier (CRF) was used, with a similar
encoding scheme. Two experiments were conducted: the first was intended to evaluate the dependency-
based representations. This was important in examining the effectiveness of the approach, compared
with the window-based representation of local evidence. This is shown in Table 5, where in all corpora
the performance of dependency-based representation alone outperforms that with window-based repre-
sentation. The recall metrics reveal improvement across corpora, suggesting that the dependency-base
representation has the ability to capture an increased number of NE phrases comparing to the traditional
window-based representation.
The second experiment is intended to evaluate the integration in the classification process of
dependency-based and window-based representations. This evaluation is expected to attain maximum
benefit from both approaches in one model. The results in Table 6 demonstrate that the classifier tends to
efficiently utilise both dependency-based and window-based representations in all corpora, apart from
WikiFANE
Whole
. The reason behind the degradation of the performance over the WikiFANE
Whole
dataset is due to the nature of the compiling of the corpus. Alotaibi and Lee (2013) state that this
version includes entire sentences from Wikipedia articles, with no further filtering, ensuring that it is
6
Not yet released to the public. We would like to thank the author for permission for its use.
990
Corpus
Development Test
+|-
P R F P R F
NewsFANE
Gold
82.08 57.77 67.81 80.21 61.58 69.68 +4.03
WikiFANE
Gold
89.31 49.11 63.37 83.34 50.48 62.88 +4.63
WikiFANE
Selective
87.03 73.29 79.57 87.31 76.17 77.81 +1.22
WikiFANE
Whole
82.44 57.91 68.03 75.88 52.45 62.03 -7.68
Table 6: The results of the hybrid approach using dependency-based and window-based features repre-
sentation
possible to have sentences including NE phrases that are mistakenly assigned to ?O? class when using an
automatic approach, as these NE phrases have no known destination in a Wikipedia article. This vari-
ety of mis-annotation is expected to propagate at this stage. It is worth noting that NewsFANE
Gold
and
WikiFANE
Gold
, as gold-standard corpora of different genres, reveal notable improvements of 4.03 and
4.63 F-measure respectively by using hybrid representation.
6 Further Exploiting of Global Evidences
Thus far, this study has examined the window-based and dependency-based representation of evidence,
in order to increase the performance of the classification process. However, there is still room for im-
provement. Both approaches focus only at the sentence level. This section will investigate the approach
to capturing global evidence. One means of achieving this is by utilising unannotated textual data, by
clustering tokens into semantic groups based on context similarity. The reasoning behind this approach
is that a NE token such as (??AW?  /AlTA?yf/ ?Taif?) (which is not seen in the training process) cannot be
correctly classified, as it contains neither window-based nor dependency-based evidence in the training
phase. Meanwhile, the token ???AW? ? is assigned to the same cluster of (?dn? /lndn/ ?London?) where
the classifier knows that ??dn?? is a location. In this way, the knowledge capacity of the classifier has
been broadened to a global level. A number of efforts have been undertaken for languages other than
Arabic that demonstrate the usefulness of injecting clustering into NLP tasks, e.g. PCFG parsing (Can-
dito and Crabb?e, 2009) and dependency parsing (Koo et al., 2008). Utilising unannotated textual data in
the supervised NER has already been variously studied with reference to English. The studies in (Turian
et al., 2009; Turian et al., 2010; Tkachenko et al., 2012; Ratinov and Roth, 2009; Miller et al., 2004)
reveal improvements when using the Brown clustering algorithm (Brown et al., 1992) to extract useful
features.
This paper focuses on extracting a useful set of features from unannotated Arabic textual data, by
relying on the Brown algorithm. We are not aware of any other study employing the Brown algorithm to
Arabic textual data and in an Arabic NER task.
6.1 Brown Clustering and NER
The Brown clustering algorithm works by maximising the mutual information of bigrams. It uses hier-
archical representation for the clusters. The hierarchal representation of the Brown clusters algorithm
allows inclusion of different semantic levels of granularity. The output from the clustering delivers valu-
able information, which can be utilised by NER. This information can be divided into three categories:
1. The cluster of tokens belongs to the named entity category. For example, (w?AkyJ /?sykA?w/
?Chicago?) and (wy?wV /Twkyw/ ?Tokyo?) belong to the same cluster, where both are NE type
?LOCATION?. In addition, (??d? /hdyl/ ?Hadeel?) and (Textual Entailment as an
Evaluation Framework for
Metaphor Resolution:
A Proposal
Rodrigo Agerri
John Barnden
Mark Lee
Alan Wallington
University of Birmingham (UK)
email: r.agerri@cs.bham.ac.uk
Abstract
We aim to address two complementary deficiencies in Natural Language
Processing (NLP) research: (i) Despite the importance and prevalence of
metaphor across many discourse genres, and metaphor?s many functions,
applied NLP has mostly not addressed metaphor understanding. But,
conversely, (ii) difficult issues in metaphor understanding have hindered
large-scale application, extensive empirical evaluation, and the handling
of the true breadth of metaphor types and interactions with other language
phenomena. In this paper, abstracted from a recent grant proposal, a new
avenue for addressing both deficiencies and for inspiring new basic re-
search on metaphor is investigated: namely, placing metaphor research
within the ?Recognizing Textual Entailment? (RTE) task framework for
evaluation of semantic processing systems.
357
358 Agerri, Barnden, Lee, and Wallington
1 Introduction
The RTE task and annual Challenges (Dagan et al, 2007), starting in 2005, have arisen
as an evaluation framework for applied semantics in response to the fact that in NLP
applications ? such as Question Answering (QA), Information Retrieval/Extraction
(IR, IE), etc. ? the development of semantic algorithms and models have been scat-
tered, or tailored to specific applications, making it difficult to compare and evaluate
them within one framework. RTE is interesting because QA, IE, etc. can all be cast
as RTE problems. In RTE, one text fragment, the Text T, is said to entail another one,
the Hypothesis H, when humans considering T and H judge that H follows from T
(perhaps only plausibly/defeasibly). Thus, entailment is a commonsense matter, not a
precise logic-based one. An example of a T/H pair is as follows (metaphor in italics):
(1) T: Lyon is actually the gastronomic capital of France.
H: Lyon is the capital of France.
Metaphor can roughly be characterized as describing something (the target) as if it
were something else (the source) to which it is perceived, or set forth, as being some-
how analogous. Metaphor has long been identified as being ubiquitous in language
(Goatly, 1997), including ordinary conversation, newspaper articles, popular novels,
popular science writing, classroom dialogue, etc. In a study (Tech. Rept. CSRP-03-05
at our School, 2003) we found one metaphorical term per 17.3 words, averaging across
various discourses of different genres. This is in line with other researchers? studies
though counts vary widely because of theory-relativity, researchers? aims, and marked
usage differences between genres. Gedigian et al (2006) note that 90% of uses of a
set of verbs of spatial motion, manipulation, and health in a Wall Street Journal corpus
were metaphorical. Some metaphor examples arising in past RTE datasets are the Ts
in T/H pairs (1?4), with human judgments No, Yes, No and No respectively.
(2) T: The technological triumph known as GPS was incubated in the mind of Ivan
Getting.
H: Ivan Getting invented the GPS.
(3) T: Convinced that pro-American officials are in the ascendancy in Tokyo, they
talk about turning Japan into the Britain of the Far East.
H: Britain is located in the Far East.
(4) T: Even today, within the deepest recesses of our mind, lies a primordial fear
that will not allow us to enter the sea without thinking about the possibility of
being attacked by a shark.
H: A shark attacked a human being.
Importantly, metaphor is often not just a matter of particular terms with particular
metaphorical senses that are entrenched (i.e., that are commonly used, default senses;
and possibly listed in dictionaries). Certainly the metaphorical senses of ?capital? and
?incubate? used in (1) and (2) are at least moderately entrenched. For ?incubate,?
Textual Entailment as an Evaluation Framework for Metaphor Resolution 359
some dictionaries list a slow, protective sense of development (in a general, possibly
non-physical sense), or for ?capital? a sense like ?a city [or place more generally]
preeminent in some special activity? [Merriam-Websters]. But (3) shows one common
type of non-entrenchedmetaphor, of the general form ?the X of Y?, where X and/or Y
are often named entities. The point of such a metaphor is typically only clear with the
help of context. Reference to recesses of a mind as in (4) is common, and a lexicon
could reasonably include a metaphorical sense of ?recess? that was directly applicable
to minds (though WordNet 3.0, e.g, does not), or include ?within the recesses of [X?s]
mind? as a stock phrase with a sense of relative inaccessibility or unmodifiability of
a thought or feeling. But the phraseology can be productively varied: e.g., ?deepest?
can be omitted or replaced by ?dim?, ?darkest?, ?foulest?, ?hidden?, etc. ? by any
compatible qualifier that emphasizes hiddenness or obstacles to accessibility. And the
fact that such access difficulties are being emphasized is a matter for general semantic
reasoning about the qualifier.
2 Why Metaphor in NLP?
Generally, in metaphor understanding research, a specialized system has been fed a
relatively small number of metaphorical inputs, and the correct outputs have been
dictated by the researcher, (e.g. Fass, 1997; Falkenhainer et al, 1989; Martin, 1990;
Barnden et al, 2003). However, metaphor in particular and figurative language in
general suffers a chronic lack of shared resources for proper evaluation of systems
(Markert and Nissim, 2007). In using the RTE evaluation framework, computational
metaphor researchers may for the first time have sizable, shared datasets, and a uni-
form evaluation method based on systematically and transparently collected human
judgments. Also, metaphor researchers will be challenged and inspired to connect
metaphor more than before to other complex linguistic phenomena.
NLP applications that RTE serves have mostly not addressed metaphor, and nei-
ther have RTE systems themselves. Indeed, despite examples (1-4), RTE datasets
have tended to avoid metaphor of more difficult types. Metaphor in general can in-
troduce additional context-sensitivity and indeterminacy in entailment, whereas RTE
Challenges have mainly concentrated on T/H pairs supporting relatively crisp, uncon-
troversial judgments (Zaenen et al (2005); RTE organizers (personal communication);
our own analysis of existing RTE datasets in Tech. Rept. CSRP-08-01, 2008). In fact,
on examples such as (1), a system must interpret ?capital? metaphorically, but as Bos
and Markert (2006) reported, the inability of their system to process metaphor meant
that it was incorrect on this example.
Further evidence is given by results on example (1) of the four RTE-1 systems avail-
able to us (out of 16 systems; the 4 include the 1st, 3rd and 4th best systems in terms of
accuracy over whole dataset). Only one reported system run was correct. The systems
mostly performed worse across (1) together with 10 other metaphor cases than on the
whole dataset, with statistical significance at 0.05 level (Fisher?s independence test);
only one system run gave a better performance. In RTE-2 (23 systems), analysis of
10 system runs shows that, across 9 metaphorical examples in the dataset, the systems
(including the most accurate one over the whole dataset) performed worse than they
did over the rest of the dataset; in 7 of the 10 RTE-2 runs compared the deficit was
statistically significant at < 0.05 level (Fisher?s test, see Tech Rept. CSRP-08-01).
360 Agerri, Barnden, Lee, and Wallington
3 RoadMap: Datasets and Metaphor Processing
Our initiative mainly consists of (A): Create a public, annotated, metaphor-focussed
text dataset suitable for RTE evaluation and testing of metaphor processing systems;
and (B): Develop a prototype RTE system centred on processing (at least) the types
of metaphor arising in (A). We will mainly address point (B) in this paper. As for
A, metaphors vary along several dimensions of interest, such as: the target subject
matter (e.g., Lyon?s food, GPS development, Japanese foreign politics, shark fear in
examples 1?4); the source subject matter; what particular, familiar metaphorical views
(e.g., Idea as Living Being, in (2)) are used; whether the meaning in context is listed
in dictionaries, WordNet, etc; whether the wording is (a variant of) a familiar idiom;
the syntax used. Based on such dimensions, we will analyse the types of metaphor
present in past RTE datasets and in the genres of text (e.g., newspapers) they drew
from. One particular source will be the 242K-word metaphor-orientated corpus that
we derived from the British National Corpus. To find metaphor examples elsewhere,
we will use known metaphorical phrases and lexical/syntactic templates as seeds for
automated search over general corpora or web. We will also investigate the use or
adaptation of other researchers? automated detection/mining techniques (e.g. Birke
and Sarkar, 2006; Gedigian et al, 2006).
4 Metaphor Processing
We will develop metaphor processing algorithms on an integrated spectrum going
from relatively ?shallow? forms of processing to relatively ?deep? forms. The deeper
are for when more inference is necessary and feasible; when less necessary or feasible,
the shallower are appropriate (but they can still involve at least partial parsing, approx-
imate semantic analysis, etc.). A significant research issue will be how to choose the
attempted depth(s) of analysis and how to choose or combine different methods? re-
sults. The deeper and shallower ends of the spectrum will take as starting points our
two previous metaphor-understanding approaches, from our ATT-Meta and E-Drama
projects respectively (Barnden et al, 2003; Wallington et al, 2008).
For detectingmetaphor, we can extendmethods from our E-drama project (Walling-
ton et al, 2008). This involves a mixture of light semantic analysis via tools such as
WordNet and recognition of lexical and syntactic signals of metaphoricity (Goatly,
1997). We aim also to recognize specific idiomatic phrases and systematic variations
of them. We will consider looking for semantic restriction violations, which some-
times accompany metaphor (cf. Fass (1997) and Mason (2004)), and using statistical
techniques borrowed from such work as Gedigian et al (2006).
Example (4) about ?recesses? is similar to metaphor examples studied in the ATT-
Meta project, and ATT-Meta-style reasoning could handle the Text. As for (2), note
that the word ?incubate? may have a directly usable lexicon-listed meaning (e.g., help
to develop much as in WordNet 3.0). However, if the system?s lexicon did not contain
such a sense, ATT-Meta-style processing would apply. ATT-Meta processing would
involve commonsense reasoning in source-domain terms (here, biological and other
physical terms): e.g., to infer that the idea was a living being, Getting?s mind was
a physical region, the idea was kept warm in that region, and the idea consequently
biologically developed there. Hence, there was a relatively protracted, continuous
Textual Entailment as an Evaluation Framework for Metaphor Resolution 361
process; the idea became more functional as a living being; and the idea needed pro-
tection from physical harm (= disenablement of function-inhibiting influences). These
default conclusions can then be translated into reality (target-based) terms: there was
a protracted, (non-physical) continuous process of change; the idea needed protection
during it; and the idea ended up being more functional. The basis for such translation
is View-Neutral Mapping Adjuncts, a special type of mappings that cover the shape
of events and processes, temporal properties and relationships, causation, functioning,
mental states, emotional states, value judgments and various other matters (Agerri
et al, 2007; Barnden et al, 2003).
RTE-2 organisers claimed there has been a trend towards using more deep inference
and that this has been beneficial provided that it is based on enough knowledge. (See
also Bos and Markert (2006) and Clark et al (2007)). The depth and knowledge needs
of ATT-Meta?s processing are like those of deeper parts of existing RTE systems, but
ATT-Meta is currently equipped only with small, hand-constructed knowledge bases.
So, our main focus in deeper processing will actually be on a shallowed, broadened
form of ATT-Meta-style reasoning. In this sense, we aim to look at common-sense
knowledge resources such as ConceptNet 3.0 which contains relationships such as
causation, function, etc. ? the types of information transferred by some of ATT-
Meta?s VNMAs ? or modified WordNets enriched by extra, web-mined knowledge
(Veale and Hao, 2008), where the extra knowledge is especially relevant to metaphor-
ical usages.
ATT-Meta?s reasoning is by backwards chaining from goals derivable from context
surrounding a metaphor. This relevance-based inference-focussingwill be key in other
processing we develop, and is highly RTE-compatible. An RTE Hypothesis can act as
(part of) a reasoning goal, with the metaphor?s within-Text context supplying further
information or goal parts. T?s own original context is of course unavailable, but this
obstacle faces human judges as well.
We will also further extend our E-Drama project?s methods, based there on robust
parsing using the Rasp system and computation over WordNet. The methods are cur-
rently largely confined to metaphors of ?X is Y? form where X is a person and Y
is some type of animal, supernatural being, artefact or natural physical object. We
will generalize to other categories for X and Y, and to cases where the categorization
is only implicit. We will make the syntactic/semantic analysis of WordNet synset-
glosses and the way the system traverses the network more advanced. We will extend
our associated treatment of metaphorically-used size adjectives (as in ?little bully?).
However, the methods are also currently confined to detecting emotional/value
judgments about X (unpleasantness, etc.), and mainly exploit metaphorical informa-
tion that is already implicitly in WordNet, e.g., ?pig? meaning a coarse, obnoxious
person, in one synset. Substantial research is needed to go beyond these limitations.
One avenue will be to apply VNMAs: when a synset gloss couches a metaphorical
sense, we could extract not just affect but other types of information that VNMAs
handle (causation, process shape, etc.); and when a gloss couches a non-metaphorical
sense, we could translate some aspects of it via VNMAs.
362 Agerri, Barnden, Lee, and Wallington
5 Concluding Remarks
This paper aims to provide an avenue for giving metaphor-understanding the promi-
nence it merits in NLP applications and in RTE, and thereby also to engender basic
and applied research advances on metaphor by ourselves and others.
RTE researchers and NLP applications developers will benefit, as systems will gain
added accuracy and coverage by addressing metaphor. Beneficiary application areas
aside from QA, IR, etc., include Knowledge Management, Information Access, and
intelligent conversation agents.
References
Agerri, R., J. Barnden, M. Lee, and A. Wallington (2007). Metaphor, inference and
domain independent mappings. In Proceedings of Research Advances in Natural
Language Processing (RANLP 2007), Borovets, Bulgaria, pp. 17?24.
Barnden, J., S. Glasbey, M. Lee, and A. Wallington (2003). Domain-transcending
mappings in a system for metaphorical reasoning. In Companion Proceedings of
the 10th Conference on the European Chapter of the Association for Computational
Linguistics (EACL-03), pp. 57?61.
Birke, J. and A. Sarkar (2006). A clustering approach for the nearly unsupervised
recognition of nonliteral language. In Proceedings of the 11th Conference on the
European Chapter of the Association for Computational Linguistics (EACL 2006),
Trento, Italy, pp. 329?336.
Bos, J. and K. Markert (2006). Recognizing textual entailment with robust logical
inference. In J. Qui?onero-Candela, I. Dagan, B. Magnini, and F. d?Alch? Buc
(Eds.), MLCW 2005, Volume 3944 of LNAI, pp. 404?426. Springer-Verlag.
Clark, P., W. Murray, J. Thompson, P. Harrison, J. Hobbs, and C. Fellbaum (2007). On
the role of lexical and world knowledge in RTE3. In Proceedings of the Workshop
on Textual Entailment and Paraphrasing, Prague, pp. 54?59. ACL 2007.
Dagan, I., O. Glickman, and B. Magnini (2007). The PASCAL Recognising Tex-
tual Entailment challenge. In J. Qui?onero-Candela, I. Dagan, B. Magnini, and
F. d?Alch? Buc (Eds.), MLCW 2005, Volume 3944 of LNAI, pp. 177?190. Springer-
Verlag.
Falkenhainer, B., K. Forbus, and D. Gentner (1989). The structure-mapping engine:
algorithm and examples. Artificial Intelligence 41(1), 1?63.
Fass, D. (1997). Processing metaphor and metonymy. Greenwich, Connecticut:
Ablex.
Gedigian, M., J. Bryant, S. Narayanan, and B. Ciric (2006). Catching metaphors. In
Proceedings of the 3rd Workshop on Scalable Natural Language Understanding,
New York, pp. 41?48.
Goatly, A. (1997). The Language of Metaphors. Routledge.
Textual Entailment as an Evaluation Framework for Metaphor Resolution 363
Markert, K. and M. Nissim (2007, June). Semeval-2007: Metonymy resolution at
semeval-2007. In International Workshop on Semantic Evaluations (SemEval-
2007), Prague, pp. 36?41. Association for Computational Linguistics (ACL-07).
Martin, J. (1990). A computational model of metaphor interpretation. New York:
Academic Press.
Mason, Z. (2004). CorMet: a computational, corpus-based conventional metaphor
extraction system. Computational Linguistics 30(1), 23?44.
Veale, T. and Y. Hao (2008). EnrichingWordNet with folk knowledge and stereotypes.
In Proceedings of the 4th Global WordNet Conference, Szeged, Hungary.
Wallington, A., R. Agerri, J. Barnden, M. Lee, and T. Rumbell (2008, May). Affect
transfer by metaphor for an intelligent conversational agent. In Proceedings of the
LREC 2008 Workshop on Sentiment Analysis: Emotion, Metaphor, Ontology and
Terminology (EMOT 08), Marrakech, Morocco, pp. 102?107.
Zaenen, A., L. Karttunen, and R. Crouch (2005). Local textual inference: Can it be
defined or circumscribed? In Proceedings of the ACL 05 Workshop on Empirical
Modelling of Semantic Equivalence and Entailment, pp. 31?36.
Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 79?83,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Cross-discourse Development of Supervised Sentiment Analysis in the
Clinical Domain
Phillip Smith
School of Computer Science
University of Birmingham
pxs697@cs.bham.ac.uk
Mark Lee
School of Computer Science
University of Birmingham
M.G.Lee@cs.bham.ac.uk
Abstract
Current approaches to sentiment analysis as-
sume that the sole discourse function of
sentiment-bearing texts is expressivity. How-
ever, the persuasive discourse function also
utilises expressive language. In this work,
we present the results of training supervised
classifiers on a new corpus of clinical texts
that contain documents with an expressive dis-
course function, and we test the learned mod-
els on a subset of the same corpus containing
persuasive texts. The results of this indicate
that despite the difference in discourse func-
tion, the learned models perform favourably.
1 Introduction
Examining the role that discourse function holds is
a critical part of an in-depth analysis into the capa-
bilities of supervised sentiment classification tech-
niques. However, it is a field that has not been com-
prehensively examined within the domain of sen-
timent analysis due to the lack of suitable cross-
discourse corpora to train and test various machine
learning methods upon.
In order to carry out such an investigation, this
study will focus on the relationship between senti-
ment classification and two types of discourse func-
tion: Expressive and Persuasive. The expressive
function denotes the feelings or attitudes of the au-
thor of a document. This is demonstrated in the fol-
lowing examples:
1. ?I didn?t like the attitude of the nursing staff.?
2. ?The doctors treated me with such care.?
Intuitively, the associated polarity of each exam-
ple is trivial to determine in these explicit examples.
However, expressive statements do not operate in
isolation of other respective discourse functions. As
Biber (1988) notes, a persuasive statement incorpo-
rates elements of the expressive function in order to
advise an external party of a proposed action that
should be taken. The following example shows how
persuasive statements make use of expressive func-
tions:
1. ?The clumsy nurse who wrongly diagnosed me
should be fired.?
The role of a persuasive statement is to incite
an action in the target, dependent upon the inten-
tion that the author communicates. By using plain,
sentiment-neutral language, the reader may misin-
terpret why the request for action is being given, and
in the worst-case scenario not carry it out. Through
the incorporation of expressive language, the weight
of the persuasive statement is increased. This en-
ables the speaker to emphasise the underlying senti-
ment of their statement, thereby increasing the like-
lihood of the intended action being undertaken, and
their goals being accomplished. In the above ex-
ample, the intention communicated by the author
is the firing of the nurse. This in itself holds neg-
ative connotations, but through the use of the word
?clumsy?, the negative sentiment of the statement be-
comes clearer to understand.
The inclusion of expressive aspects in the lan-
guage of the persuasive discourse function, enables
us to identify the sentiment of a persuasive com-
ment. As there is this cross-over in the language of
the two discourse functions, we can hypothesise that
79
if we train a supervised classifier on an expressive
corpus, a learned model will be created that when
applied to a corpus of persuasive documents, will
classify these texts to an adequate standard.
As the corpus that we developed is in the clin-
ical domain, it is worth noting the important role
that sentiment analysis can play for health practi-
tioners, which unfortunately has not received a great
deal of attention. In assessing the effectiveness of
treatments given by the health service for a condition
which is curable, the results themselves indicate the
effectiveness of such a process. However, for pallia-
tive treatments which merely alleviate the symptoms
of an illness or relieve pain, it is vital to discover the
extent to which these are effective. Feedback has
progressed from the filling in of paper forms to the
ability to give feedback through web pages and mo-
bile phones. Text is stored in a highly accessible
way, and is now able to be efficiently processed by
sentiment classification algorithms to determine the
opinions that patients are expressing. This in turn
should enable health services to make informed de-
cisions about the palliative care which they provide.
2 Patient Feedback Corpus
NHS Choices1 is a website run by the National
Health Service (NHS), which acts as an extensive
knowledge base for any health-related queries. This
website not only provides comprehensive articles
about various ailments, but also gives the users of
the site the option to rate and comment on the ser-
vices that are provided to them at hospitals and GP
surgeries. This user feedback provides an excellent
basis for the sentiment classification experiments of
this work.
The reviews that are submitted are typically pro-
vided by a patient or close relative who has experi-
enced the healthcare system within a hospital. When
submitting feedback, the user is asked to split their
feedback into various fields, as opposed to submit-
ting a single documents detailing all the comments
of the user. During corpus compilation, each com-
ment was extracted verbatim, so spelling mistakes
remain in the developed corpus. All punctuation
also remains in order to enable future experiments to
be carried out on either the sentence or phrase level
1http://nhs.uk
Corpus D W Davglength V
Expressive
Positive 1152 75052 65.15 6107
Negative 1108 76062 68.65 6791
Persuasive
Positive 768 46642 60.73 4679
Negative 864 113632 131.52 7943
Table 1: Persuasive & expressive corpus statistics.
within each comment.
In developing the corpus, we leverage the fact that
the data was separated into subfields, as opposed
to one long review, where the all data is merged
into a single document. We extracted comments
which came under three categories in the NHS Pa-
tient Feedback dataset: Likes, Dislikes and Advice.
The Likes were assumed to express positive senti-
ment and highlight elements of the health service
that patients appreciated. Conversely, the documents
given under the Dislikes header were assumed to
convey a negative sentiment. These two subsets
make up the Expressive subset of the compiled cor-
pus. The Advice documents did not have an initial
sentiment associated with them, so each comment
was labelled by two independent annotators at the
document level as being either a positive or nega-
tive comment. These Advice comments contributed
to the Persuasive subcorpus. In compiling the per-
suasive document sets, we automatically discarded
those comments that contained the term ?N/A ? or
any of its derivative forms.
3 Method
The aim in this work was to examine the effect of
training a supervised classifier on a corpus whose
discourse function differs to that of the training
set. We experimented with three standard super-
vised machine learning algorithms: standard Na??ve
Bayes (NB), multinomial Na??ve Bayes (MN NB)
and Support Vector Machines (SVM) classification.
Each has proven to be effective in previous senti-
ment analysis studies (Pang et al , 2002), so as
this experiment is rooted in sentiment classification,
these methods were also assumed to perform well in
this cross-discourse setting.
For the cross-discourse sentiment classification
80
experiments, two variants of the Na??ve Bayes algo-
rithm are used. The difference between the stan-
dard NB and MN NB is the way in which the fea-
tures for classification, the words, are modelled. In
the standard NB learning method, a binary presence
approached is taken in modelling the words of the
training documents. This differs to the MN NB clas-
sifier, which takes into account term frequency when
modelling the documents. Each has proven to be a
high performing classifier across various sentiment
analysis domains, but no distinction has been given
as to which is the preferable method to use. There-
fore in this paper, both were implemented.
In the literature, results from the use of SVMs in
classification based experiments have outperformed
other algorithms (Joachims, 1998; Pang et al ,
2002). For these cross-discourse experiments we use
the Sequential Minimal Optimization training algo-
rithm (Platt, 1998), in order to achieve the maximal
hyperplane, and maximise the potential of the cre-
ated classifier. Traditionally SVMs have performed
well in text classification, but across discourse do-
mains the results of such classification has not been
examined.
Each document in the corpus was modelled as
a bag of words. Features used within this repre-
sentation were unigrams, bigrams and bigrams aug-
mented with part-of-speech information. Due to
this, and observing the results of preliminary experi-
mentation that included rare features, it was decided
to remove any feature that did not occur more than
5 times throughout the training set. A stopword list
and stemmer were also used.
Each supervised classification technique was then
trained using a random sample of 1,100 documents
from both the positive and negative subsections of
the expressive corpus. Following this we tested the
classifiers on a set of 1,500 randomly selected per-
suasive documents, using 750 documents from each
of the positive and negative subcorpora.
The results of cross-validation (Table 2) sug-
gested that unigram features may outperform both
bigram and part-of-speech augmented bigrams for
all learning methods. In particular, the accuracy
results produced by the NB algorithm surpassed
the results of other classifiers in the tenfold cross-
validation. This suggests that within a single dis-
course domain, presence based features are prefer-
Features NB Multinomial NB SVM
Unigrams 79.65 78.14 76.11
Bigrams 57.79 60.84 63.36
Bigrams + POS 74.25 75.71 72.83
Table 2: Average tenfold cross-validation accuracies on
only the expressive corpus. Boldface: best performance
for a given classifier.
able to considering the frequency of a term when
generating a machine learning model.
4 Results
Table 3 shows the classification accuracies achieved
in all experiments. For each classifier, with each fea-
ture set, if we take the most basic baseline for the
two-class (positive/negative) problem to be the ran-
dom baseline of 50% classification accuracy, then
this is clearly exceeded. However if we take the re-
sults of the tenfold cross-validation as a baseline for
each classifier in the experiments, then only the re-
sults given by the MN NB classifier with unigram
and bigram features are able to surpass this.
The results given from the NB and the MN NB
classifier imply that using frequency based fea-
tures are preferable to using presence based features
when performing cross-discourse sentiment classi-
fication. The MN NB is one of the few classifiers
tested that exceeds the results of the cross-validated
model. These results support experiments carried
out for topic based classification using Bayesian
classifiers by McCallum and Nigam (1998), but dif-
fers from sentiment classification results from Pang
et al (2002) that suggest that term-based models
perform better than the frequency-based alternative.
This also differs to the results that were returned
during the cross-validation of the classifiers, where
presence based features produced the greatest clas-
sification accuracy.
In our tests, the feature set which yielded the high-
est degree of classification accuracy across all clas-
sifiers is the unigram bag of words model. Tan et
al. (2002) suggest that using bigrams enhances text
classification, but as sentiment classification goes
beyond this task, the assumption does not hold, as
the results here show. The difference in discourse
function could also contribute to bigrams yielding
81
Positive Negative
Accuracy Precision Recall F1 Precision Recall F1
NB Uni 76.07 78.29 72.13 75.09 74.17 80.00 76.97
NB Bi 58.93 55.19 94.93 69.80 81.90 22.93 35.83
NB Bi + POS 65.00 71.84 49.33 58.50 61.42 80.67 69.74
MN NB Uni 83.53 82.04 85.87 83.91 85.17 81.20 83.14
MN NB Bi 57.00 63.78 32.40 42.97 54.69 81.60 65.49
MN NB Bi + POS 69.97 69.59 69.87 69.73 69.75 69.47 69.61
SVM Uni 69.00 68.43 70.53 69.47 69.60 67.47 68.52
SVM Bi 55.40 60.98 30.00 40.21 53.58 80.80 64.43
SVM Bi + POS 63.27 63.11 63.87 63.49 63.43 62.67 63.04
Table 3: Results of experimentation, with the expressive corpus as the training set, and the persuasive corpus as the
test set. Boldface indicates the best performance for each metric.
the lowest accuracy results. Bigrams model quite
specific language patterns, but as the expressive and
persuasive language differs in structure and content,
then the patterns learnt in one domain do not accu-
rately map to another domain. Bigrams contribute
the least to sentiment classification in this cross-
discourse scenario, and only when they are aug-
mented with part of speech information does the ac-
curacy sufficiently pass the random baseline. How-
ever for good recall, using bigram based features
produces excellent results, at the sacrifice of ade-
quate precision, which suggests that bigram mod-
els overfit when they are used as features in such a
learned model.
The SVM classifier with a variety of features does
not perform as well as the multinomial Na??ve Bayes
classifier. Joachims (1998) suggests that for text
categorization, the SVM algorithm regularly outper-
forms other classifiers, but unfortunately the out-
come of our experiments do not correlate with these
results. This suggests that SVMs struggle with text
classification when the discourse function between
the training and test domains differ.
5 Discussion
The results produced through training supervised
machine learning methods on an expressive corpus,
and testing on a corpus which contains documents
with a persuasive discourse function indicate that
cross-discourse sentiment classification is feasible.
The best performance occurred when the classi-
fier took frequency based features into account, as
opposed to solely presence based features. The rea-
soning for this could be attributed to the way that pa-
tients were asked to submit their feedback. Instead
of asking a patient to submit a single comment on
their experience with the health service, they were
asked to submit three distinct comments on what
they liked, disliked and any advice that they had.
This gave the user the opportunity to separate their
sentiments, and clearly communicate their thoughts.
It is of interest to note that the cross-discourse ac-
curacy should surpass the cross-validation accuracy
on the training set. This was not to be expected, due
to the differences in discourse function, and there-
fore features used. However, where just the presence
of a particular word may have made the difference
in a single domain, across domains, taking into ac-
count the frequency of a word in the learned model
is effective in correctly classifying a comment by
its sentiment. Unigram features outperform both the
bigram and bigrams augmented with part-of-speech
features in our experiments. By using single tokens
as features, each word is taken out of the context
that its neighbours provide. In doing so the language
contributing to the relative sentiment is generalised
enough to form a robust model which can then be
applied across discourse domains.
6 Related Work
A number of studies (Cambria at al. , 2011; Xia et
al. , 2009) have used patient feedback as the domain
for their sentiment classification experiments. How-
ever our work differs to these studies as we consider
82
the effect that cross-discourse evaluation has on the
classification outcome. Other work that has consid-
ered different discourse functions in sentiment anal-
ysis, have experimented on detecting arguments (So-
masundaran et al , 2007) and the stance of political
debates (Thomas et al , 2006).
Machine learning approaches to text classification
have typically performed well when using a Sup-
port Vector Machine (Joachims, 1998) classifier or
a Na??ve Bayes (McCallum and Nigam, 1998) based
classifier. Pang et al (2002) applied these classi-
fiers to the movie review domain, which produced
good results. However the difference in domain,
and singularity of discourse function differentiates
the scope of this work from theirs.
7 Conclusion & Future Work
In this study we focused on the cross-discourse
development of supervised machine learning algo-
rithms in the clinical domain, that trained and tested
across the expressive and persuasive discourse func-
tions. We demonstrated that despite the differences
in function of a corpus of patient feedback, the
greatest classification accuracy was achieved when
considering word frequency in the features of the
learned model.
This study centred on the expressive and persua-
sive discourse functions, but it would be interesting
to examine other such functions that convey a sen-
timent, such as argumentation. Another interesting
avenue of investigation for this work would be to ex-
plore the lexical semantics of the different discourse
functions, that could be used in sentiment classifica-
tion, and factor this into the evaluation of the overall
sentiment of persuasive documents within a corpus.
References
Douglas Biber. 1988. Variation Across Speech and
Writing. Cambridge University Press.
John Blitzer, Mark Dredze and Fernando Pereira. 2007.
Biographies, Bollywood, Boom-boxes, and Blenders:
Domain Adaptation for Sentiment Classification. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pp. 440?447.
Erik Cambria, Amir Hussain and Chris Eckl. 2011.
Bridging the Gap between Structured and Unstruc-
tured Health-Care Data through Semantics and
Sentics. In Proceedings of ACM WebSci, Koblenz.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A Publicly Available Lexical Resource
for Opinion Mining In Proceedings of Language
Resources and Evaluation (LREC), pp 417?422.
Thorsten Joachims. 1998. Text categorization with
support vector machines: learning with many relevant
features. In Proceedings of ECML-98, 10th European
Conference on Machine Learning, pp. 137?142.
Andrew McCallum and Kamal Nigam. 1998. A
Comparison of Event Models for Naive Bayes Text
Classification. In Proceedings of the AAAI/ICML-98
Workshop on Learning for Text Categorization, pp.
41?48.
Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classification using
Machine Learning Techniques. In Proceedings of the
2002 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pp. 79?87.
John Platt. Sequential Minimal Optimization: A Fast
Algorithm for Training Support Vector Machines.
In Advances in Kernel Methods - Support Vector
Learning.
Swapna Somasudaran and Josef Ruppenhofer and Janyce
Wiebe. 2007. Detecting Arguing and Sentiment in
Meetings. In Proceedings of the SIGdial Workshop on
Discourse and Dialogue, pp.26?34.
Chade-Meng Tan, Yuan-Fang Wang and Chan-Do Lee.
2002. The use of bigrams to enhance text catego-
rization. In Information Processing & Management,
38(4) pp. 529?546.
Matt Thomas, Bo Pang and Lillian Lee. 2006. Get out
the vote: Determining support or opposition from
Congressional floor-debate transcripts. In Proceeding
of the 2006 Conference on Emperical Methods in
Natural Language Processing (EMNLP), pp.327?335.
Lei Xia, Anna Lisa Gentile, James Munro and Jose? Iria.
2009. Improving Patient Opinion Mining through
Multi-step Classification. In Proceedings of the 12th
International Conference on Text, Speech and Dia-
logue (TSD?09), pp. 70?76.
83
