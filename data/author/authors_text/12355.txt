Proceedings of the Workshop on BioNLP: Shared Task, pages 128?136,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Analyzing text in search of bio-molecular events:
a high-precision machine learning framework
Sofie Van Landeghem1,2, Yvan Saeys1,2, Bernard De Baets3, Yves Van de Peer1,2
1. Dept. of Plant Systems Biology, VIB
2. Dept. of Plant Biotechnology and Genetics, Ghent University
3. Dept. of Applied Mathematics, Biometrics and Process Control, Ghent University
B-9000 Gent, Belgium
yves.vandepeer@psb.vib-ugent.be
Abstract
The BioNLP?09 Shared Task on Event Ex-
traction is a challenge which concerns the de-
tection of bio-molecular events from text. In
this paper, we present a detailed account of
the challenges encountered during the con-
struction of a machine learning framework for
participation in this task. We have focused
our work mainly around the filtering of false
positives, creating a high-precision extraction
method. We have tested techniques such as
SVMs, feature selection and various filters for
data pre- and post-processing, and report on
the influence on performance for each of them.
To detect negation and speculation in text,
we describe a custom-made rule-based sys-
tem which is simple in design, but effective in
performance.
1 Introduction
BioNLP recently emerged from the combined exper-
tise of molecular biology and computational linguis-
tics. At first, the community was mainly focused
on named entity recognition (NER) and simple rela-
tion extraction, such as protein-protein interactions
(Plake et al, 2005; Giuliano et al, 2006; Fundel et
al., 2007; Saetre et al, 2008). However, the future
of BioNLP lies in the ability to extract more com-
plex events from text, in order to fully capture all
available information (Altman et al, 2008).
Two recent community-wide challenges, Biocre-
ative I (Hirschman et al, 2005) and II (Krallinger et
al., 2008) have shown their merits by providing com-
mon benchmarking data and a meaningful compari-
son of various techniques. In contrast to the mono-
lithic Biocreative tasks, the BioNLP?09 Shared Task
has a more modular nature (Kim et al, 2009). It
is not concerned with named entity recognition or
normalization, but focuses on the task of event ex-
traction itself.
This article is organized as follows: we first de-
scribe the Shared Task in a little more detail. Next,
we present the methods used in our machine learn-
ing framework, carefully discussing our choices in
design and their influence on performance. We then
present the final results of our approach. Finally, we
draw conclusions from our participation in this task,
and suggest some future work for our own research
as well as on a community-wide level.
2 BioNLP?09 Shared Task
2.1 Subtasks
The BioNLP?09 Shared Task was divided into three
subtasks, of which only the first one was mandatory.
We have participated in tasks 1 and 3, and will there-
fore only briefly discuss task 2. In accordance with
the provided gold entity annotation, we will refer to
all genes and gene products as proteins.
Task 1 represents the core of the challenge: de-
tection and characterization of bio-molecular events
from text. There are 9 distinct event types. Six
events influence proteins directly, and we will refer
to them as ?Protein events?. Five of them are unary:
Localization, Gene expression, Transcription, Pro-
tein catabolism and Phosphorylation. The Binding
event can be related to one protein (e.g. protein-
DNA binding), two proteins (e.g. protein-protein in-
128
teraction) or more (e.g. a complex). On top of these
event types, there are three Regulation events: Reg-
ulation, Positive regulation and Negative regulation.
Each of them can be unary or binary. In the latter
case, an extra argument specifying the cause of the
regulation is added. Each argument of a Regulation
event can be either a protein or any other event.
Participants in task 2 had to recognise extra ar-
guments for the events from task 1. For example,
the cellular location should be added to a Localiza-
tion event, and Site arguments had to be specified
for Phosphorylation, Binding and Regulation.
Finally, task 3 was about detecting negation and
speculation in text.
2.2 Examples
Suppose we are dealing with this sentence:
?MAD-3 masks the nuclear localization signal
of p65 and inhibits p65 DNA binding.?
There are three proteins in this sentence:
? T1 : Protein : ?MAD-3?
? T2 : Protein : ?p65? (first occurrence)
? T3 : Protein : ?p65? (second occurrence)
There are also three triggers, which are defined by
a contiguous stream of characters from the original
text, and point to a specific event type:
? T27 : Negative regulation : ?masks?
? T29 : Negative regulation : ?inhibits?
? T30 : Binding : ?binding?
In this example, we see there is one binding event
which involves trigger T30 and protein T3. Further-
more, this binding event is being influenced by pro-
tein T1, using trigger T29 which implies a Negative
regulation event. Similarly, T1 has a negative effect
on protein T2, which is expressed by trigger T27.
When participating in subtask 2, one should also find
the extra Site argument T28 for this last event:
? T28 : Entity : ?nuclear localization signal?
Now look at the following example:
?NF-kappa B p50 is not directly regulated by
I kappa B.?
This sentence expresses a Regulation event involv-
ing the trigger ?regulated? and protein ?p50?. Partic-
ipation in subtask 3 requires detecting the negation
of this event.
2.3 Datasets
Both training and testing data consist of PubMed ab-
stracts extracted from the GENIA corpus (Kim et al,
2008). All proteins are annotated and extra informa-
tion is provided, such as analysis of sentence seg-
mentation and tokenization, dependency graphs and
phrase structure parses.
The training data consists of 800 articles. The
development data contains an additional 150 arti-
cles with gold standard annotations. During devel-
opment (6 weeks), the system?s performance could
be estimated with this dataset, using an online sub-
mission system. Participants had one week time to
provide predictions for the final test dataset of 260
articles.
3 Methods
Our machine learning framework is tailored towards
specific properties of different events, but is still kept
sufficiently general to deal with new event types.
The nature of the event extraction task leads to un-
balanced datasets, with much more negative exam-
ples than positive ones. This is due to the fact
that proteins could be involved in all possible event
types, and each of the words in the text could be a
trigger for an event. Finding the right events thus
seems like looking for a needle in a haystack, which
is why it is crucial to start with a good definition
of candidate instances. This problem has motivated
us to try and filter out as many irrelevant negative
instances as possible by introducing specific pre-
processing methods and filters. This reduces un-
balancedness of the datasets and will lead to better
precision as there will be less false positives (FPs).
High-precision systems produce less noise and can
be considered to be more useful when a researcher
is trying to extract reliable interaction networks from
text. There is a considerable degree of information
redundancy in the original PubMed articles, which
makes up for low recall when using the system in
a real-world application. We have also tested a few
post-processing techniques in order to remove FPs
after classification.
Figure 1 shows a high-level overview of the dif-
ferent modules in our framework. More details are
described in the next sections.
129
Predictions
Training data
Triggerdictionaries Instancecreation
Post-processingmodules
Testing data
Featuregeneration Classification(SVM)
Resultssubtask 1Rule based systemfor Negation and Speculation
Resultssubtask 3
1
43
2
Figure 1: High-level overview of the modules used in our
framework.
3.1 Parsing
For sentence segmentation, we made use of the pro-
vided tokenization files. Analysis of part-of-speech
tags and dependency graphs was done using the
Stanford parser (de Marneffe et al, 2006).
3.2 Dictionaries of triggers
From the training data, we automatically compiled
dictionaries of triggers for each event type, applying
the Porter stemming algorithm (Porter, 1980) to each
trigger. This resulted in some entries in the dictio-
naries which were of limited use, such as ?through?
for Binding, or ?are? for Localization. Such words
are too general or too vague, and lead to many neg-
ative and irrelevant instances. For this reason, we
manually cleaned the dictionaries, only keeping spe-
cific triggers for each event type (e.g. ?interaction?
for Binding and ?secretion? for Localization).
During development, we noticed a significant
difference between the triggers for unary Bind-
ing events (e.g. ?homodimer?, ?binding site?) and
those for Binding events with multiple arguments
(e.g. ?heterodimer?, ?complex?). This motivated our
choice to create two separate dictionaries and classi-
fiers, thus discarding irrelevant candidate instances.
Such an example would be a candidate binary Bind-
ing event with the trigger ?homodimer?, while ho-
modimerization is clearly a unary event. In the
rest of this article, we will refer to these two event
types as Single binding and Multiple binding events.
The revision of the dictionaries resulted in a signifi-
cant drop in the number of Binding instances in the
training data, and improved the balancedness of the
datasets: from a total of 34 612 instances (of which
2% positives) to 4708 Single binding instances (11%
positives) and 3861 Multiple binding instances (5%
positives).
Following the same reasoning, Regulation was
also divided into unary and binary events. Further-
more, we have carefully analysed the nature of Bi-
nary regulation events, and noticed that a vast major-
ity of these events had a protein in the ?cause? slot.
We decided to split up the dictionaries of Binary reg-
ulations accordingly, differentiating between regu-
lation events caused by proteins and those caused
by other events. This keeps the more general words
(e.g. ?causes?) out of the dictionaries of events reg-
ulated by proteins (e.g. ?response?), again resulting
in better balance of the datasets.
3.3 Instance creation
In a machine learning framework, a classifier tries
to distinguish between positive instances (true bio-
molecular events) and negative instances (candidates
which should be discarded). To run such a frame-
work, one has to define candidate instances automat-
ically by scanning the text. The first step towards
instance creation consists of looking up triggers
in text, using the constructed dictionaries for each
event type. To this end, we have implemented a fast
algorithm using Radix trees1. Next, candidate argu-
ments have to be found. Initially, we have selected
all (combinations of) proteins that were mentioned
in the same sentence. However, this may result in
a lot of negative and irrelevant instances, mainly in
long sentences. This is why we have implemented a
Negative-instances (NI) filter, which checks whether
the length of the sub-sentence spanned by a candi-
date event does not exceed a certain value. Figure 2
shows the distribution of positive and negative Mul-
tiple binding events, according to the length of the
relevant sub-sentence. It seems reasonable to only
keep instances with a sub-sentence of less than 175
characters, as this includes almost all positive exam-
ples, while at the same time removing a significant
amount of irrelevant negatives.
1Java implementation by Tahseen Ur Rehman,
http://code.google.com/p/radixtree/
130
Figure 2: Distribution of Multiple binding instances, ac-
cording to the length of the sub-sentence (training data).
Furthermore, for each instance, a minimal sub-
graph of the dependency graph was extracted, con-
taining the full trigger and all arguments. The size of
this subgraph was also used as a parameter for the NI
filter, as positive instances are usually expressed in a
smaller subtree than negative examples. In Figure 3
we see how the subgraphs of positive Multiple bind-
ing instances are never larger than 10 edges, while
negative instances can contain up to 18 edges. In this
case, only keeping instances with subgraphs smaller
than 8 edges will discard many irrelevant negatives,
while keeping most of the positive instances.
The NI filter further reduces noise in the data and
unbalancedness. We now end up with 4070 Sin-
gle binding instances (of which 13% positives) and
2365 Multiple binding instances (8% positives). Ta-
ble 1 shows the final distribution of instances for all
event types. Transcription, Localization and Mul-
tiple binding have the lowest percentage of posi-
tive instances, ranging between 7% and 8%, while
Phosphorylation has up to 48% positive instances. It
should be noted that the number of positive instances
in Table 1 is lower than the actual number of posi-
tive examples in the training set, due to limitations
of our instance definition method. However, a study
regarding maximal recall shows that we do not re-
move too many true positives (TPs) (more details in
Section 4.1).
3.4 Feature generation
For feature generation, we base our method on the
rich feature set we previously used in our work on
Figure 3: Distribution of Multiple binding instances, ac-
cording to the size of the subgraph (training data).
protein-protein interactions (Van Landeghem et al,
2008). The goal of that study was to extract bi-
nary relations and only one path in the dependency
graph was analyzed for each instance. In the present
work however, we are processing larger and more
complex subgraphs. This is why we have excluded
?edge walks?, i.e. patterns of two consecutive edges
and their common vertex (e.g. ?nsubj VBZ prep?).
To compensate for the loss of information, we have
added trigrams to the feature set. These are three
stemmed consecutive words from the sub-sentence
spanning the event, e.g. ?by induc transcript?, which
is the stemmed variant of ?by inducing transcrip-
tion?. Other features include
? A BOW-approach by looking at all the words
which appear at a vertex of the subgraph. This
automatically excludes uninformative words
such as prepositions.
? Lexical and syntactic information of triggers.
? Size of the subgraph.
Event type # neg. # pos. % pos.
inst. inst. inst.
Localization 3415 249 7
Single binding 3548 522 13
Multiple binding 2180 185 8
Gene expression 5356 1542 22
Transcription 6930 489 7
Protein catabolism 175 96 35
Phosphorylation 163 153 48
Table 1: Distribution of instances
131
Event type Features
Localization 18 121
Single binding 21 332
Multiple binding 11 228
Gene expression 31 332
Transcription 30 306
Protein catabolism 1 883
Phosphorylation 2 185
Table 2: Dimensionality of the datasets
? Length of the sub-sentence.
? Extra features for Regulation events, storing
whether the arguments are proteins or events,
specifying the exact event type.
? Vertex walks which consist of two vertices
and their connecting edge. For these patterns,
both lexical as well as syntactic information is
kept. When using lexical information, protein
names and triggers were blinded in order to ex-
tract more general patterns (e.g. ?trigger nsubj
protx? which expresses that the given protein is
the subject of a trigger). Blinding avoids over-
fitting of the classifier.
In the training phase, each instance generates dif-
ferent patterns, and each pattern is stored as a nu-
meric feature in the feature vector. During testing,
we count how many times each feature is found for
each instance. This results in very sparse and high-
dimensional datasets. Table 2 shows the dimen-
sionality of the datasets for all event types. Protein
catabolism has the lowest dimensionality with 1883
features, while Transcription and Gene expression
produce over 30 000 features.
3.5 Classification
To process our dataset, we had to find a classi-
fier able to deal with thousands of instances, thou-
sands of features, and an unbalancedness of up to
93% negative instances. We have used the Lib-
SVM implementation as provided by WEKA2, as a
few preliminary tests using different classifiers (such
as Random Forests) gave worse results. We inte-
grated an internal 5-fold cross-validation loop on
the training portion of the data to determine a use-
ful C-parameter. All other parameters were left un-
2Available at http://www.cs.waikato.ac.nz/ml/
weka/
changed, including the type of kernel which is a ra-
dial basis function by default.
In combination with the LibSVM, we have tried
applying feature selection (FS). At first sight, FS did
not seem to lead to gain in performance, although we
were not able to test this hypothesis more thoroughly
due to time limitations of the task. Finally, we have
also tested the influence of assigning higher weights
to positive training instances, in order to make up
for the unbalanced nature of the data, but this had
almost no effect on overall performance.
3.6 Post-processing
We have implemented a few custom-made post-
processing modules, designed to further reduce FPs
and improve precision of our method. We report
here on their influence on performance.
Overlapping triggers of different event types
Predictions for different event types were processed
in parallel and merged afterwards. This means that
two triggers of different event types might overlap,
based on the same words in the text. However, a
word in natural language can only have one mean-
ing at a time. When two such triggers lead to events
with different event types, this means that some of
these events should be FPs. When testing on the de-
velopment data, we found a few predictions where
this problem occurred. For example, the trigger ?ex-
pression? can lead to both a Transcription and a Gene
expression event, but not at the same time. In such a
case, we only select the prediction with the highest
SVM score. However, thanks to careful construc-
tion of the dictionaries (Section 3.2), their mutual
overlap is rather small, and thus this post-processing
module has almost no influence on performance.
Events based on the same trigger
One trigger might be involved in different events
from the same event type. For example, the sentence
?it induces expression of STAT5-regulated genes in
CTLL-2, i.e. beta-casein, and oncostatin M (OSM)?
mentions two Gene expression events based on the
trigger ?expression?, one involving beta-casein, and
one involving OSM. For these two events, the sub-
graphs will be very similar, resulting in similar fea-
tures and SVM scores. However, often a trigger
only leads to one true event, while all other candi-
132
dates from the same event type are false positives.
We have carefully benchmarked this hypothesis, and
found that for Protein catabolism and Phosphoryla-
tion, we could achieve better performance by only
keeping the top-ranked prediction. Up to 5% in F-
score could be gained for these events. This is due to
the fact that for these two event types, usually only
one true event is linked to each trigger.
3.7 Negation
We found that there are three major categories of
event negation:
1. A negation construct is found in the close vicin-
ity of the trigger (e.g. ?no?, ?failure to?).
2. A trigger already expresses negation by itself
(e.g. ?non-expressing?, ?immobilization?).
3. A trigger in a certain sentence expresses both
positive as negative events. In this case, the
pattern ?but not? is often used (e.g. ?overexpres-
sion of Vav, but not SLP-76, augments CD28-
induced IL-2 promoter activity?).
We have created a custom-made rule-based system
to process these three categories. The rules make
use of small dictionaries collected from the train-
ing data. For rule 1, we checked whether a nega-
tion word appears right in front of the trigger. To
apply rule 2, we used a list of inherent negative trig-
gers deduced from the training set. For rule 3, we
checked whether we could find patterns such as ?but
not? or ?whereas?, negating only the event involving
the protein mentioned right after that pattern.
3.8 Speculation
We identified two major reasons why the description
of an event could be regarded as speculation instead
of a mere fact. These categories are:
1. Uncertainty: the authors state the interactions
or events they are investigating, without know-
ing the true results (yet). This is often indicated
with expressions such as ?we have examined
whether (...)?.
2. Hypothesis: authors formulate a hypothesis to
try and explain the results of an experiment.
Specific speculation words such as ?might? or
?appear to? often occur right before the trigger.
Event type Maximal recall
Localization 84.91 %
Binding 78.23 %
Gene expression 91.57 %
Transcription 90.24 %
Protein catabolism 100 %
Phosphorylation 95.74 %
Regulation 46.15 %
Positive regulation 39.71 %
Negative regulation 43.88 %
Negation 28.97 %
Speculation 25.26 %
Table 3: Maximal recall for the development data
Similar to detecting negation, we compiled a list of
relevant expressions from the training data and have
used this to implement a simple rule-based system.
For rule 1, we checked the appearance of such an ex-
pression in a range of 60 characters before the trig-
ger and up to 60 characters after the trigger. Rule 2
was applied on a smaller range: only 20 characters
right before the trigger were scanned.
4 Results
Our final machine learning framework consists of all
the modules described in the previous section. To
summarize, these design choices were made: auto-
matically compiled dictionaries which were cleaned
manually, usage of the NI filter, no weights on pos-
itive instances, a LibSVM classifier and no feature
selection. We used both post-processing modules,
but the second one only for Protein catabolism and
Phosphorylation events. The best SVM cut-offs
were chosen by determining the best F-score on the
development data for each classifier.
4.1 Benchmarking on the development data
Protein events
To evaluate maximal recall of our instance extrac-
tion method, we executed an evaluation using an
all-true classifier. As can be seen in Table 3, maxi-
mal recall is quite high for almost all Protein events,
meaning that dictionary coverage is good, our NI fil-
ter does not remove too many TPs, and not too many
events are expressed across sentences and thus not
picked up by our method. Binding and Localization
are the only events with less than 90% recall. Due to
133
Event type Recall Precision F-score
Localization 77.36 91.11 83.67
Binding 45.16 37.21 40.80
Gene expression 70.79 79.94 75.08
Transcription 60.98 75.76 67.57
Protein catabolism 80.95 89.47 85.00
Phosphorylation 68.09 88.89 77.11
Total 62.45 64.40 63.41
Regulation 23.67 41.67 30.19
Positive regulation 21.56 38.00 27.51
Negative regulation 30.10 41.26 34.81
Total 23.63 39.39 29.54
Task 1 41.03 53.50 46.44
Negation 15.89 45.95 23.61
Speculation 20.00 26.87 22.93
Total 17.82 33.65 23.30
Task 3 38.77 52.24 44.51
Table 4: Final performance of all events for the develop-
ment data
time constraints, we were not able to test which of
our modules leads to false negative (FN) instances.
For each event, we have determined the best clas-
sifier cut-offs to achieve maximal F-score. Results
of the final performance for the predictions of Pro-
tein events on the development data, can be seen in
Table 4. For most events, we achieve very high pre-
cision, thanks to our careful definition of instances
in combination with the NI-filter.
Looking at the F-measures, Transcription, Gene
expression and Phosphorylation all perform be-
tween 67 and 77%, while Localization and Protein
catabolism have an F-score of more than 83%. It be-
comes clear that Binding is the most difficult event
type, with a performance of 41% F. Unfortunately,
this group of events contains 44% of all Protein
events, greatly influencing total performance. Aver-
age performance of predicting Protein events results
in 63.41% F.
Regulation
When evaluating the predictions of Regulation
events, one has to take into account that the perfor-
mance greatly depends on the ability of our system
to predict Protein events. Indeed, one FN Protein
event can lead to multiple FN Regulation events, and
the same holds for FPs. Furthermore, we do not try
to extract events across sentences, which may lead
to more FNs. To study maximal recall of the Regu-
lation events, we have again applied an all-true clas-
sifier. Table 3 shows that the highest possible recall
of the Regulation events is never above 50%, greatly
limiting the performance of our method.
As regulation events can participate in new regu-
lation events, one should run the regulation pipeline
repeatedly until no more new events are found. In
our experiments, we have found that even the first re-
cursive run did not lead to much better performance,
and only a few more Regulation events were found.
Final results are shown in Table 4. With recall
being rather low, between 21% and 30%, at least
we achieve relatively good precision: around 40%
for each of the three regulation types. On average,
the F-score is almost 30% for the regulation events,
which is significantly lower than the performance of
Protein events. On average, we obtain an F-score of
46.44% on the development data for task 1.
Negation and speculation
The performance of this subtask depends heavily on
the performance of subtask 1. Again we have ap-
plied an all-true classifier to determine maximal re-
call (Table 3). Less than 30% of the events necessary
for task 3 can be found with our setup; all of these
FNs are due to FNs in task 1.
Final results are shown in Table 4. Performance
of around 23% F-score is achieved on the develop-
ment data. We take into consideration that according
to the maximal recall study, only 29% of the neces-
sary events for Negation were extracted by task 1. In
the final results, 16% of all the negation events were
found. This means that our rule-based method by
itself achieves about 55% recall for Negation. Sim-
ilarly, the system has a recall of 80% for Specula-
tion when only considering events found in task 1.
We conclude that our simple rule-based system per-
forms reasonably well.
4.2 Scoring and ranking on final test set
Finally, our system was applied to the test data.
Achieving a global F-score of 40.54% for subtask 1,
we obtain a 5th place out of 24 participating teams.
For subtask 3 of finding negation and speculation,
we obtain a second place with a 37.80% F-score.
Final results for each of the event types are shown
in Table 5. As on the development data, we see
134
Event type Recall Precision F-score
Localization 43.68 78.35 56.09
Binding 38.04 38.60 38.32
Gene expression 59.42 81.56 68.75
Transcription 39.42 60.67 47.79
Protein catabolism 64.29 60.00 62.07
Phosphorylation 56.30 89.41 69.09
Total 50.75 67.24 57.85
Regulation 10.65 22.79 14.52
Positive regulation 17.19 32.19 22.41
Negative regulation 22.96 35.22 27.80
Total 17.36 31.61 22.41
Task 1 33.41 51.55 40.54
Negation 10.57 45.10 17.13
Speculation 8.65 15.79 11.18
Total 9.66 24.85 13.91
Task 3 30.55 49.57 37.80
Table 5: Performance of all events for the final test set
that the Binding event performs worst, and the same
trend is found when analyzing results of other teams.
In general however, we achieve a high precision:
67% for Protein events, 52% on average on subtask
1, and 50% on average on subtask 3. Another trend
which is confirmed by other teams, is the fact that
predicting Protein events achieves much higher per-
formance than the prediction of Regulation events.
Compared to our results on the development data
(Table 4), we notice a drop of performance for the
Protein events of about 0.06F. This loss is prop-
agated to the Regulation events and to Negation
and Speculation, each also performing about 0.06F
worse than on the development data. We believe
this drop in performance might be due to overfitting
of the system during training. It is difficult to find
the best SVM cut-offs to achieve maximal perfor-
mance. We have tuned these cut-offs on the devel-
opment data, but they might not be ideal for the final
test set. For this reason, we believe that it might be
more representative to use evaluation schemes such
as the area under the receiver operating character-
istics curve (AUC) measure (Hanley and McNeil,
1982; Airola et al, 2008).
5 Conclusions and future work
We have participated in the BioNLP?09 Shared Task,
joining the rest of the community in the progression
of relation-based extraction towards the extraction
of events from bio-molecular texts. Out of the 24
participants, we see quite some teams with a very
good performance, with the highest result achieving
an F-score of nearly 52%. We believe the commu-
nity is off to a good start in this task, and we hope
work in this field will continue afterwards.
In our own study, we notice that the task
of extracting bio-molecular events leads to high-
dimensional and unbalanced datasets. We carefully
designed our system in order to improve balance of
the datasets and to avoid false positives. For feature
generation, we have made use of a modified bag-of-
words approach, included trigrams extracted from
the sentence, and derived patterns from dependency
graphs. Our high-precision framework achieves a
fifth position out of 24 participating teams in sub-
task 1, and second position out of six for subtask 3.
In the future, we would like to investigate the use
of feature selection to produce better models for the
classification task. Another interesting topic would
be how to combine coreference resolution with de-
pendency graphs in order to process events which
span multiple sentences in text.
For the community as a whole, we think the next
step would be to work on full articles instead of mere
abstracts. Also, it might be interesting to investigate
the use of text-bound annotation which is not neces-
sarily contiguous, such as is the case in the Bioinfer
corpus (Pyysalo et al, 2007), to be able to fully cap-
ture the semantics of a certain event.
Acknowledgments
SVL and YS would like to thank the Research Foun-
dation Flanders (FWO) for funding their research.
Furthermore, the authors would like to thank the or-
ganizers of the BioNLP?09 Shared Task for offering
to the community a very valuable and well organized
task about event extraction. We believe careful eval-
uation and discussion of the results will lead to a
significant step forward in this domain.
135
References
A. Airola, S. Pyysalo, J. Bjo?rne, T. Pahikkala, F. Gin-
ter and T. Salakoski. 2008. All-paths graph kernel
for protein-protein interaction extraction with evalua-
tion of cross-corpus learning. BMC Bioinformatics,
9(Suppl 11):S2
R.B. Altman, C.M. Bergman, J. Blake, C. Blaschke, A.
Cohen, F. Gannon, L. Grivell, U. Hahn, W. Hersh, L.
Hirschman, L.J. Jensen, M. Krallinger, B. Mons, S.I.
O?Donoghue, M.C. Peitsch, D. Rebholz-Schuhmann,
H. Shatkay and A. Valencia. 2008. Text mining for
biology - the way forward: opinions from leading sci-
entists. Genome Biology, 9(Suppl 2):S7
B. Boser, I. Guyon and V.N. Vapnik. 1992. A training
algorithm for optimal margin classifiers. Proceedings
of the 5th annual workshop on Computational learning
theory (COLT), 144-152
K. Fundel, R. Ku?ffner and R. Zimmer. 2007. RelEx?
Relation extraction using dependency parse trees.
Bioinformatics, 23(3):365-371
C. Giuliano, A. Lavelli and L. Romano 2006. Exploiting
shallow linguistic information for relation extraction
from biomedical literature. Proceedings of the 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL), 401-408
J. Hanley and B. J. McNeil. 1982. The meaning and
use of the area under a receiver operating characteristic
(roc) curve. Radiology, 143(1):29-36
L. Hirschman, A. Yeh, C. Blaschke and A. Valencia.
2005. Overview of BioCreAtIvE: critical assessment
of information extraction for biology. BMC Bioinfor-
matics, 6(Suppl 1):S1
J.-D. Kim, T. Ohta and J. Tsujii. 2008. Corpus anno-
tation for mining biomedical events from literature.
BMC Bioinformatics, 19(Suppl 1):i180-i182
J.-D. Kim, T. Ohta, S. Pyssalo, Y. Kano and J. Tsujii.
2009. Overview of BioNLP?09 Shared Task on Event
Extraction, Proceedings of Natural Language Pro-
cessing in Biomedicine (BioNLP) NAACL 2009 Work-
shop, to appear
M. Krallinger, A. Morgan, L. Smith, F. Leitner, L.
Tanabe, J. Wilbur, L. Hirschman and A. Valencia.
2008. Evaluation of text-mining systems for biology:
overview of the Second BioCreative community chal-
lenge. Genome Biology, 9(Suppl 2):S1
MC. de Marneffe, B. MacCartney and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. Proceedings of the 5th In-
ternational Conference on Language Resources and
Evaluation (LREC), 449-454
C. Plake, J. Hakenberg and U. Leser. 2005. Optimizing
syntax patterns for discovering protein-protein inter-
actions. Proceedings of the 2005 ACM symposium on
Applied computing (SAC), 195-201
M.F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3), 130-137
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjo?rne, J. Boberg,
J. Ja?rvinen and T. Salakoski. 2007. BioInfer: A corpus
for information extraction in the biomedical domain.
BMC Bioinformatics, 8(50)
R. Saetre, K. Sagae and J. Tsujii. 2008. Syntactic fea-
tures for protein-protein interaction extraction. Pro-
ceedings of the 2nd International Symposium on Lan-
guages in Biology and Medicine (LBM), 6.1-6.14
S. Van Landeghem, Y. Saeys, B. De Baets and Y. Van
de Peer. 2008. Extracting protein-protein interactions
from text using rich feature vectors and feature selec-
tion. Proceedings of the Third International Sympo-
sium on Semantic Mining in Biomedicine (SMBM), 77-
84.
136
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 144?152,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Integration of Static Relations to Enhance Event Extraction from Text
Sofie Van Landeghem1,2, Sampo Pyysalo3, Tomoko Ohta3, Yves Van de Peer1,2
1. Dept. of Plant Systems Biology, VIB, Gent, Belgium
2. Dept. of Plant Biotechnology and Genetics, Ghent University, Gent, Belgium
3. Department of Computer Science, University of Tokyo, Tokyo, Japan
yves.vandepeer@psb.vib-ugent.be
Abstract
As research on biomedical text mining is
shifting focus from simple binary relations
to more expressive event representations,
extraction performance drops due to the
increase in complexity. Recently intro-
duced data sets specifically targeting static
relations between named entities and do-
main terms have been suggested to enable
a better representation of the biological
processes underlying annotated events and
opportunities for addressing their com-
plexity. In this paper, we present the first
study of integrating these static relations
with event data with the aim of enhanc-
ing event extraction performance. While
obtaining promising results, we will argue
that an event extraction framework will
benefit most from this new data when tak-
ing intrinsic differences between various
event types into account.
1 Introduction
Recently, biomedical text mining tools have
evolved from extracting simple binary relations
between genes or proteins to a more expressive
event representation (Kim et al, 2009). Further-
more, new data sets have been developed target-
ing relations between genes and gene products
(GGPs) and a broader category of entities, cov-
ering terms that can not be annotated as named
entities (NEs) but that are still highly relevant
for biomedical information extraction (Ohta et al,
2009b). In contrast to relations involving change
or causality, the annotation for this data covers re-
lations such as part-of, here termed ?static rela-
tions? (SR) (Pyysalo et al, 2009).
Tissue-specific expression of interleukin-3
expression event GGP
is mediated via cis-acting elements located 
regulation event               term part-of GGP 
within 315 base pairs of the transcription start.
term part-of GGP
Figure 1: A sentence from PMID:8662845, show-
ing how the event data set (single line) and the SR
data set (double line) offer complementary infor-
mation, enabling a more precise model of the bio-
logical reality.
As an example, Figure 1 depicts a sentence con-
taining complementary annotations from the event
data set and the SR data. The event annotation
indicates an expression event involving the GGP
?interleukin-3?. Furthermore, regulation of this
expression event is stated by the trigger word ?me-
diated?. In addition, the SR annotation marks two
terms that refer to parts of the GGP, namely ?cis-
acting elements? and ?transcription starts?. These
two terms provide more detailed information on
the regulation event. Thus, by combining the two
types of annotation, a text mining algorithm will
be able to provide a more detailed representation
of the extracted information. This would be in par-
ticular beneficial in practical applications such as
abstract summarization or integration of the pre-
dictions into complex regulatory pathways.
In addition to providing enhanced represen-
tation of biological processes, the SR data set
also offers interesting opportunities to improve on
event extraction. As an example, consider the sen-
tence presented in Figure 2, in which ?c-Rel? and
?p50? are both annotated as being subunits of the
144
We show here that c-Rel binds to
GGP_1   binding event
kappa B sites as heterodimers with p50.
GGP_1 subunit-of Term GGP_2
GGP_2 subunit-of Term
Figure 2: A sentence from PMID:1372388, show-
ing how SR data (double line) can provide strong
clues for the extraction of biomolecular events
(double line) from text.
term ?heterodimers?. The SR data thus provides
strong clues for the extraction of a Binding event
involving both c-Rel and p50.
During the last few years, event extraction
has gained much interest in the field of nat-
ural language processing (NLP) of biomedical
text (Pyysalo et al, 2007; Kim et al, 2008; Kim
et al, 2009). However, owing to the more com-
plex nature of this task setting, performance rates
are lower than for the extraction of simple bi-
nary relations. The currently best performing
framework for event extraction obtains 53.29% F-
score (Miwa et al, 2010), which is considerably
lower than the performance reported for extrac-
tion of protein-protein interaction relations, rang-
ing between 65% and 87% depending on the data
set used for evaluation (Miwa et al, 2009).
In this paper, we will study how data on static
relations can be applied to improve event extrac-
tion performance. First, we describe the various
data sets (Section 2) and the text mining frame-
work that was applied (Section 3). The main con-
tributions of this paper are presented in Section 4,
in which we study how static relation information
can be integrated into an event extraction frame-
work to enhance extraction performance. Finally,
Section 5 presents the main conclusions of this
work.
2 Data
In this section, we provide an overview of the two
main data sets used in this work: event annotation
(Section 2.1) and static relation annotation (Sec-
tion 2.2).
2.1 Event Data
The BioNLP?09 Shared Task data, derived from
the GENIA Event corpus (Kim et al, 2008), de-
Event type Args Train Devel Test
Gene expression T 1738 356 722
Transcription T 576 82 137
Protein catabolism T 110 21 14
Localization T 265 53 174
Phosphorylation T 169 47 139
Binding T+ 887 249 349
Regulation T, C 961 173 292
Positive regulation T, C 2847 618 987
Negative regulation T, C 1062 196 379
TOTAL - 8615 1795 3193
Table 1: BioNLP ST events, primary argument
types and data statistics. Arguments abbreviate for
(T)heme and (C)ause, with + marking arguments
that can occur multiple times for an event. We re-
fer to the task definition for details.
fines nine types of biomolecular events and is di-
vided into three data sets: training data, develop-
ment data and final test data, covering 800, 150
and 260 PubMed abstracts respectively. The event
types and their statistics in the three data sets are
shown in Table 1.
In the shared task setting, participants were pro-
vided with the gold annotations for Gene/Gene
Product (GGP) named entities, and for all three
data sets the texts of the abstracts and the gold
GGP annotations are publicly available. However,
while full gold event annotation is available for the
training and development data sets, the shared task
organizers have chosen not to release the gold an-
notation for the test data set. Instead, access to
overall results for system predictions is provided
through an online interface. This setup, adopted in
part following a similar design by the organizers of
the LLL challenge (Ne?dellec, 2005), is argued to
reduce the possibility of overfitting to the test data
and assure that evaluations are performed identi-
cally, thus maintaining comparability of results.
For the current study, involving detailed analy-
sis of the interrelationships of two classes of anno-
tations, the lack of access to the gold annotations
of the test set rules this data set out as a poten-
tial target of study. Consequently, we exclude the
blind test data set from consideration and use the
development set as a test set.
To simplify the analysis, we further focus our
efforts in this study on simple events involving
only the given GGPs as participants. In the full
shared task, events of the three Regulation types
may take events as arguments, resulting in re-
cursive event structures. These event types were
found to be the most difficult to extract in the
145
SR type Examples
term variant-of GGP [RFX5 fusion protein], [Tax mutants], [I kappa B gamma isoforms]
term part-of GGP [murine B29 promoter], [c-fos regulatory region], [transactivation domain] of Stat6,
the nearby [J element] of the human DPA gene,
the [consensus NF-kappa B binding site] of the E-selectin gene
GGP member-of term The [Epstein-Barr virus oncoprotein] latent infection membrane protein 1,
[Ikaros family members], PU.1 is a transcription factor belonging to the [Ets-family]
GGP subunit-of term the [NF-kappa B complex] contains both RelA and p50,
Human TAFII 105 is a cell type-specific [TFIID] subunit, [c-Rel/p65 heterodimers]
Table 2: Training examples of some of the SR types, including both noun phrase relations as well as
relations between nominals. GGPs are underlined and terms are delimited by square brackets.
shared task evaluation (Kim et al, 2009). Fur-
thermore, their inclusion introduces a number of
complications for evaluation as well as analysis,
as failure to extract a referenced event implies fail-
ure to extract events in which they appear as argu-
ments. We note that even with the limitations of
considering only the smallest of the three data sets
and excluding Regulation events from considera-
tion, the ST data still contains over 800 develop-
ment test events for use in the analysis.
2.2 Static Relation Data
The data on relations is drawn from two recently
introduced data sets. Both data sets cover specifi-
cally static relations where one of the participants
is a GGP and the other a non-GGP term. The
GGPs are drawn from the data introduced in (Ohta
et al, 2009a) and the terms from the GENIA cor-
pus term annotation (Kim et al, 2003), excluding
GGPs. The first data set, introduced in (Pyysalo et
al., 2009), covers static relations involving GENIA
corpus terms that are annotated as participants
in the events targeted in the BioNLP?09 shared
task. The second data set, introduced in (Ohta et
al., 2009b), contains annotation for relations hold-
ing between terms and GGPs embedded in those
terms. In this study, we will use the non-embedded
relations from the former data set, referring to this
data as RBN for ?Relations Between Nominals?
in recognition of the similarity of the task setting
represented by this data set and the task of learn-
ing semantic relations between nominals, as stud-
ied e.g. in SemEval (Girju et al, 2007; Hendrickx
et al, 2009). We use all of the latter data set,
below referred to as NPR for ?Noun Phrase Re-
lations?. The NPR data set extends on the em-
bedded part of the data introduced by (Pyysalo
et al, 2009), increasing the coverage of terms in-
cluded and the granularity of the annotated event
types. While RBN only differentiates between a
domain-specific Variant relation and four different
part-whole relations, in NPR these are refined into
more than 20 different types.
To apply these data sets together in a single
framework, it was necessary to resolve the differ-
ences in the annotated relation types. First, as the
finer-grained NPR types are organized in a hier-
archy that includes the four part-whole relations
of the RBN categorization as intermediate types
(see Fig. 1 in Ohta et al (2009b)), we collapsed
the subtypes of each into these supertypes. While
this removes some potentially useful distinctions,
many of the finer-grained types are arguably un-
necessarily detailed for the purposes of the event
extraction task which, for example, makes no dis-
tinctions between events involving different gene
components. Furthermore, the NPR annotations
also define an Object-Variant class with multiple
subtypes, but as these were judged too diverse to
process uniformly, we did not collapse these sub-
types as was done for part-whole relations. Rather,
we divided them into ?near? and ?far? variants by
a rough ?functional distance? to the related GGP,
as suggested by Ohta et al (2009b). The relations
GGP-Modified Protein, GGP-Isoform and GGP-
Mutant were accepted into the ?near? set, expected
to provide positive features for inclusion in events,
and the remaining subtypes into the ?far? set, ex-
pected to provide negative indicators.
In addition to the primary annotation covering
static relations, the RBN annotation only recog-
nizes a mixed ?other relation/out? category, used
to annotate both GGP-term pairs for which the
stated relation is not one of the targeted types (e.g.
a causal relation) and pairs for which no relation is
stated. Due to the heterogeneity of this category,
146
it is difficult to make use of these annotations, and
we have chosen not to consider them in this work.
By contrast, the NPR annotation also subdi-
vides the ?other relation? category into five spe-
cific types, providing an opportunity to also use
the part of the data not strictly involving static re-
lations. We judged the classes labeled Functional,
Experimental Method and Diagnosis and Ther-
apeutics to involve terms where contained GGP
names are unlikely to be participants in stated
events and thus provide features that could serve as
potentially useful negative indicators for event ex-
traction. As an example, the Functional category
consists of GGP-term pairs such as GGP inhibitor
and GGP antibody, where the term references an
entity separate from the GGP, identified through
a functional or causal relation to the GGP. As
such terms occur in contexts similar to ones stat-
ing events involving the GGP, explicit marking of
these cases could improve precision. Consider, for
example, GGP1 binds GGP2, GGP1 binds GGP2
promoter, GGP1 binds GGP2 inhibitor and GGP1
binds GGP2 antagonist: a binding event involving
GGP1 and GGP2 should be extracted for the first
two statements but not the latter two.
Table 2 lists some interesting examples of static
relation grouped by type, including both noun
phrase relations as well as relations between nom-
inals. The consolidated data combining the two
static relations - related data sets are available at
the GENIA project webpage.1
3 Methods
The text mining tool used for all analyses in this
paper is based on the event extraction frame-
work of Van Landeghem et al (2009), which
was designed specifically for participation in the
BioNLP?09 Shared Task. In this framework, trig-
gers are discovered in text by using automati-
cally curated dictionaries. Subsequently, candi-
date events are formed by combining these triggers
with an appropriate number of GGPs co-occurring
in the same sentence. For each distinct event type,
a classifier is then built using all training examples
for that specific type. Final predictions are merged
for all types, forming a complex interaction graph
for each article in the test set.
To distinguish between positive instances and
negatives, the framework extracts rich feature vec-
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA
binds
c-Rel
nsu
bj
heterodimer
p50
prep_as
pr e
p_
wi t
h
we
show
nsubj
here
advmod
complm
that
cc
om
p
sites
Bkappa
nn nn
pre
p_
to
Figure 3: Dependency graph for the sentence ?We
show here that c-Rel binds to kappa B sites as het-
erodimers with p50?. Words of the sentence form
the nodes of the graph, while edges denote their
syntactic dependencies.
tors by analyzing lexical and syntactic information
from the training data. Subsequently, a support
vector machine (SVM) is built with these training
patterns. The patterns include trigrams, bag-of-
word features, vertex walks and information about
the event trigger. As part of the current study dis-
cusses the extension and generalization of these
feature patterns (Section 4.4), we will briefly dis-
cuss the various types in this section.
To derive syntactic patterns, dependency pars-
ing is applied using the Stanford parser (Klein and
Manning, 2003; De Marneffe et al, 2006). Specif-
ically, for each candidate event, the smallest sub-
graph is built including the relevant nodes for the
trigger and the GGP names. Each edge in this sub-
graph then gives rise to a pattern including the in-
formation from the connecting nodes (or vertices)
in combination with the syntactic relation speci-
fied by the edge. Trigger words and GGP names
are blinded by replacing their text with the strings
protx and trigger (respectively), resulting in highly
general features.
Figure 3 depicts an exemplary dependency
graph. For the Binding event between c-Rel and
p50, the following vertex walks would be ex-
tracted: ?trigger nsubj protx?, ?trigger prep-as het-
erodimer? and ?heterodimer prep-with protx?.
147
Events Training Dev. test
Pos. SR data 1190 32% 227 28%
Neg. SR data 841 22% 207 26%
All SR data 1635 44% 350 43%
Table 3: Number of events that can be linked to at
least one static relation, including explicitly anno-
tated ?near miss? negative annotations, also show-
ing percentage of all gold-standard events.
Furthermore, lexical information is provided by
bag-of-word (BOW) features and trigrams. BOW
features incorporate all words occurring as nodes
in the dependency sub-graph. They include highly
informative words such as ?promoter?. Trigrams
are formed by combining three consecutive words
in the sub-sentence delimited by the trigger and
GGP offsets in text. They are capable of captur-
ing common phrases such as ?physical association
with?.
Finally, the lexical tokens of the event trigger
are highly relevant to determine the plausibility of
the event being a correct one. For example, ?se-
cretion? points to a Localization event, but more
general words often lead to false candidate events,
such as ?present?. The part of speech tags of the
trigger words are also included as separate fea-
tures.
During feature generation, all lexical patterns
are stemmed using the Porter stemming algo-
rithm (Porter, 1980), creating even more general
features and reducing sparseness of the feature
vectors.
4 Experiments
This section describes a thorough study on how
data on static relations can be integrated into an
event extraction framework. First, we will analyze
the amount of useful complementary annotations
across both data sets (Section 4.1). Next, we de-
scribe the generation and evaluation of new candi-
date events using terms involved in static relations,
in an effort to boost recall of the event predictions
(Section 4.2). To additionally improve on preci-
sion, we have implemented a false positive filter
exploiting SR annotations of GGPs involved in re-
lations judged to serve as negative indicators, such
as ?GGP inhibitor? (Section 4.3). Finally, Section
4.4 details experiments on the creation of more ex-
tensive features for event extraction by including
static relation data.
Predicted Percentage
instances of data set
Gene expression 63 17.70%
Transcription 34 41.46%
Protein catabolism 4 19.05%
Phosphorylation 20 42.55%
Localization 4 7.55%
Binding 73 29.44%
All events 198 24.54%
Table 4: Maximal recall performance of event in-
stances involving at least one non-NE term as ar-
gument. These terms are functioning as aliases for
the GGPs they are positively associated with.
4.1 Analysis of complementary data across
the two data sets
To assess the usability of the SR data set for event
extraction, we first analyze the amount of comple-
mentary annotations across the two data sets. On
the document level, the static relations data con-
tains some annotation for 87.6% of all training set
articles and for 94.67% of the development test
set, including both positive static relations as well
as explicitly negated ones. Most articles from the
event data set thus involve terms at least poten-
tially involved in static relations.
Analyzing the overlap in more detail, we de-
termined the number of events that could benefit
from adding SR data by counting the number of
events for which at least one GGP is also involved
in a static relation (either a positive or a negative
one). Table 3 shows the results of this evalua-
tion. In the training data, 1635 events involve at
least one GGP with SR annotation, which is 44%
of all events in the gold-standard annotation. For
the development test set, the number is 350 out of
the 808 gold standard events, i.e. 43% of events.
These development set events in particular will be
the subject of this study.
4.2 Terms as aliases for related GGPs
Our first application of static relations in an event
extraction framework involves the use of non-NE
terms appearing in the SR data set as aliases for the
GGPs they are positively associated with. In the
event extraction framework, new candidate events
can thus be formed by treating the terms as GGPs,
and mapping them back to the real GGPs after
classification. This procedure is motivated by the
definition of the various SR types and the under-
lying biological processes. For example, if a com-
plex is known to activate the expression of a cer-
148
Recall Precision F-score
Gene expression 11.24% 81.63% 19.75%
Transcription 20.73% 89.47% 33.66%
Protein catabolism 19.05% 100.00% 32.00%
Phosphorylation 36.17% 100.00% 53.12%
Localization 3.77% 25.00% 6.56%
Binding 12.50% 45.59% 19.62%
All events 13.75% 67.27% 22.84%
Table 5: Performance of event instances involv-
ing at least one non-NE term as argument. These
terms are functioning as aliases for the GGPs they
are positively associated with.
tain target GGP, then the various subunits of this
complex can be annotated as participants in that
event.
Obviously, this approach has some intrinsic lim-
itations as not all GGPs occurring as arguments
in events have a corresponding term that could be
used as alias. However, from Table 3 it is clear
that it should still be possible to extract 227 gold
standard cases. To test the limitation, we have
used the event extraction framework detailed in
Section 3, removing the SVM classifier from the
pipeline and simply labeling all candidate events
as positive predictions. The result indicates that
the framework is capable of retrieving 198 of the
227 gold standard cases (Table 4). The 29 missing
events are due to trigger words not appearing (fre-
quently) in the training set and thus missing from
the dictionary, preventing the event to be formed
as a candidate in the framework.
Our results thus show that nearly 25% of all
events are potentially retrievable by using non-NE
terms as aliases for GGPs. However, the analy-
sis also indicates that in this approach, some event
types are much easier to extract than others. For
example, less than 8% of Localization events can
be found with this setup, while maximal recall for
Phosphorylation events is over 40%. These re-
sults reflect the intrinsic differences between event
types and the ways in which they are typically ex-
pressed, and suggest that it should be beneficial
for event extraction to take these differences into
account when incorporating static relations.
Having established an upper bound for recall, a
subsequent experiment involves treating the newly
created instances as normal candidate events. For
classification, we use an SVM trained on regular
candidate events involving GGPs, as this ensures
sufficient training material.
Both lexical and syntactic patterns are expected
Baseline Merged
predictions predictions
Gene expression 77.01% 77.56%
Transcription 63.41% 64.24%
Protein catabolism 86.36% 86.36%
Phosphorylation 70.10% 76.47%
Localization 80.00% 76.77%
Binding 38.69% 40.52%
All events 64.71% 65.33%
All events (precision) 69.11% 67.19%
All events (recall) 60.84% 63.57%
Table 6: Performance of the event extraction
framework. First column: using only normal
events involving GGPs (?baseline?). Second col-
umn: merging the new predictions (Table 5) with
the first ones. All performance rates indicate F-
score, except for the last two rows.
to be similar for events involving either non-NE
terms or GGPs. To test this hypothesis, we have
run the event-extraction pipeline for these new in-
stances. Evaluation is performed with the stan-
dard evaluation script provided by the BioNLP?09
Shared Task organizers, which measures the per-
centage of true events amongst all predictions
(precision), the percentage of gold-standard events
recovered (recall) and the harmonic mean of these
two metrics (F-score). The results are detailed in
Table 5. While we have already established that
recall is subject to severe limitations (Table 4), we
note in particular the high precision rates of the
predictions. In particular, four out of six event
types achieve a precision rate higher than 80%.
To allow for a meaningful comparison, these re-
sults should be put into perspective by merging the
new predictions with the predictions of a baseline
extractor and comparing against this baseline (Ta-
ble 6). This analysis reveals interesting results:
while overall performance increases slightly from
64.71% to 65.33% F-score, this trend is not com-
mon to all event types. For instance, prediction of
Localization drops 3.23% points F-score. Consid-
ering the maximum recall results, this is not en-
tirely surprising and confirms the hypothesis that
the prediction of Localization events will not ben-
efit from static relation data in this approach.
However, we do observe a considerable increase
in performance for Phosphorylation (6.37% points
F-score) events and some increase for Binding
events (1.83% points F-score). This performance
boost is mainly caused by an increase in recall
(10.64% and 4.43% points, respectively). When
considering all protein events, recall is increased
149
from 60.84% to 63.57% (Table 6, last row). These
results clearly indicate that the inclusion of static
relations can improve recall while retaining and
even slightly improving general performance.
4.3 Using static relations to filter false
positive events
To further improve event extraction performance,
we have designed a false-positive (FP) filter using
specific categories of relations serving as negative
indicators for event extraction. In particular, we
have used the ?far variants? and Functional rela-
tion annotations, as described in Section 2.2. For
each such relation, we add the GGP involved to
the FP filter, as the GGP should not participate in
any event. Thus, for example, the GGP in ?GGP
antibodies? would be filtered as the GGP is con-
sidered too far removed from the containing term
to be a participant in any event in the context.
In the development test set, this strategy has au-
tomatically identified 24 relevant GGP mentions
that should not be annotated as being involved in
any event. Even though this number is relatively
small, we aim at designing a high specificity FP
filter while relying on the SVM classifier to solve
more ambiguous cases.
Applying the FP filter to the baseline result de-
tailed in Table 6, we find that 3 events are dis-
carded from the set of predictions. All three in-
stances represented false positives; two of them
were Binding events and one a Gene expression
event. Overall precision and F-score increased by
0.30% points and 0.13% points, respectively.
4.4 Extended feature representation
incorporating information on static
relations
The last type of experiment aims to boost both
precision and recall by substantially extending the
feature generation module for event extraction us-
ing the newly introduced SR data. Table 3 shows
that such an enhanced feature representation could
influence 1190 events in the training data (1635
events including negative annotations) and 227
events in the development test data (350 including
negative), covering a significant part of the data
set.
Building further on the feature generation mod-
ule described in Section 3, we have added a range
of new features to the feature vectors while also
providing enhanced generalization of existing fea-
tures. Generalization is crucial for the text mining
framework as it enables the extraction of relations
from new contexts and forms of statements.
First, for each term involved in a static rela-
tion with a GGP, the string of the term is included
as a separate feature. This generates relation-
associated features such as ?tyrosine?, which is
strongly correlated with Phosphorylation events.
For terms spanning multiple tokens, we addition-
ally include each token as a separate feature, cap-
turing commonly used words such as ?promoter?
or ?receptor?. Each distinct feature is linked to its
specific relation type, such as Part-of or Member-
collection (Section 2.2). To make use of annota-
tion for ?near-miss? negative cases, we generate
features also for these relations, marking each fea-
ture to identify whether it was derived from a pos-
itive or negative annotation.
Additionally, we introduced a new feature type
expressing whether or not the trigger of the event
is equal to a term related to one or more GGPs in-
volved in the event. As an example, suppose the
candidate event is triggered by the word ?homod-
imer?. If the GGP involved is annotated as being a
subunit of this homodimer, this provides a strong
clue for a positive event. Similarly, the explicit
negation of the existence of any static relation in-
dicates a negative event.
Apart from these new features, we have also in-
vestigated the use of static relations to create more
general lexical patterns. In particular, we have ad-
justed the lexical information in the feature vector
by blinding terms involved in relevant relations,
depending on the specific type of relation. For
each such term, the whole term string is replaced
by one word, expressing the type of the static re-
lation and whether the relation is positive or neg-
ative. This results in more general patterns such
as ?inhibit prep-to partx? (vertex walk) or ?activ
in nonpartx? (trigram). In Figure 3, ?heterodimer?
would be blinded as ?complexx? as both c-Rel and
p50 are members of this complex.
Initial experiments with the extended feature
representation showed that an increase in perfor-
mance could be obtained on the development test
set, achieving 61.34% recall, 69.58% precision
and 65.20% F-score. However, it also became
clear that not all event types benefit from the new
features. Surprisingly, Binding is one such exam-
ple. We hypothesize that this is mainly due to the
intrinsic complexity of Binding events, requiring
an even more advanced feature representation.
150
Baseline New
predictions predictions
Gene expression 77.01% 78.06%
Transcription 63.41% 63.80%
Protein catabolism 86.36% 86.36%
Phosphorylation 70.10% 76.29%
Localization 80.00% 84.21%
Binding 38.69% 38.34%
All events 64.71% 65.73%
All events (precision) 69.11% 69.99%
All events (recall) 60.84% 61.96%
Table 7: Performance of the event extraction
framework. First column: using the baseline fea-
ture representation. Second column: using the
extended feature representation. All performance
rates indicate F-score, except for the last two rows.
To take the inherent differences between vari-
ous event types into account, we selected the opti-
mal set of features for each type. In a new experi-
ment, the feature generation step thus depends on
the event type under consideration. Table 7 details
the results of this optimization: an overall F-score
of 65.73% is achieved. Similar to the experiments
in Section 4.2, the F-score for the prediction of
Phosphorylation events increases by 6.19% points.
Additionally, in this experiment we obtain an in-
crease of 4.21% points in F-score for Localization
events, even though we were unable to improve
on them when using terms as aliases for additional
candidate events (Section 4.2). Additional exper-
iments suggested the reason to be that while the
Localization event type in general does not ben-
efit from positive static relations, negative static
relations seem to provide strong clues to the SVM
classifier.
5 Conclusion
We have presented the first study on the appli-
cability of static relations for event prediction
in biomedical texts. While data on static rela-
tions can offer a more detailed representation of
biomolecular events, it can also help to boost
the performance of event prediction. We have
performed three sets of experiments to investi-
gate these opportunities. First, we have designed
new candidate events by treating non-NE terms
as aliases for the GGPs they are associated with.
By augmenting the normal event predictions with
predictions for these new candidates, we have es-
tablished a considerable increase in recall. Next,
we have implemented a false positive filter to im-
prove precision, by exploiting annotation for re-
lations judged to imply only distant associations
of the GGP and the enclosing term. Finally, the
last type of experiment involves integrating com-
plementary data on static relations to obtain more
informative feature vectors for candidate events.
Results show that both recall and precision can be
increased slightly by this last, more complex con-
figuration.
During the experiments, it has become clear that
there are important differences between the data
sets of distinct event types. For example, we have
found that Phosphorylation events benefit the most
from added static relations data, while Localiza-
tion events can be enhanced using only features
of negative static relation annotations. For some
event types, such as Protein catabolism, the cur-
rent techniques for integration of static relations
do not generate a performance boost. However,
our findings pave the way for experiments involv-
ing more detailed representations, taking the in-
trinsic properties of the various event types into
account and combining the various ways of inte-
grating the new information. We regard these op-
portunities as promising future work.
Finally, having established the potential added
value offered by data on static relations in an event
extraction framework, additional future work will
focus on the automatic extraction of the static re-
lations. Similar relations have been considered in
numerous recent studies, and while challenges to
reliable prediction remain, several methods with
promising performance have been proposed (Girju
et al, 2007; Hendrickx et al, 2009). By inte-
grating predictions from both static relations and
events instead of using gold standard relation an-
notations, we will be able to study the effect of
the relation information on new data, including the
shared task test set. Such experiments are key to
establishing the practical value of static relations
for biomolecular event extraction.
Acknowledgments
SVL would like to thank the Research Founda-
tion Flanders (FWO) for funding her research.
The work of SP and TO was partially supported
by Grant-in-Aid for Specially Promoted Research
(MEXT, Japan).
References
M. De Marneffe, B. Maccartney, and C. Manning.
2006. Generating typed dependency parses from
151
phrase structure parses. In Proceedings of LREC-
06, pages 449?454.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
Semeval-2007 task 04: Classification of semantic
relations between nominals. In Proceedings of the
Fourth International Workshop on Semantic Evalu-
ations (SemEval-2007), pages 13?18, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid O? Se?aghdha, Sebastian
Pado?, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2009. Semeval-2010 task
8: Multi-way classification of semantic relations
between pairs of nominals. In Proceedings of
the Workshop on Semantic Evaluations: Recent
Achievements and Future Directions (SEW-2009),
pages 94?99, Boulder, Colorado, June. Association
for Computational Linguistics.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and
Jun?ichi Tsujii. 2003. GENIA corpus - a seman-
tically annotated corpus for bio-textmining. Bioin-
formatics, 19(suppl. 1):i180?i182.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008. Corpus annotation for mining biomedi-
cal events from literature. BMC Bioinformatics,
9(1):10.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
bionlp?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting of the Association for Com-
putational Linguistics, pages 423?430, Sapporo,
Japan, July. Association for Computational Linguis-
tics.
Makoto Miwa, Rune Saetre, Yusuke Miyao, and
Jun?ichi Tsujii. 2009. A rich feature vector for
protein-protein interaction extraction from multiple
corpora. In EMNLP ?09: Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 121?130, Morristown, NJ,
USA. Association for Computational Linguistics.
Makoto Miwa, Rune Saetre, Jin-Dong D. Kim, and
Jun?ichi Tsujii. 2010. Event extraction with com-
plex event classification using rich features. Jour-
nal of bioinformatics and computational biology,
8(1):131?146, February.
Claire Ne?dellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Proceed-
ings of the Learning Language in Logic Workshop
(LLL?05).
Tomoko Ohta, Jin-Dong Kim, Sampo Pyysalo, Yue
Wang, and Jun?ichi Tsujii. 2009a. Incorporating
genetag-style annotation to genia corpus. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 106?
107, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Tomoko Ohta, Sampo Pyysalo, Kim Jin-Dong, and
Jun?ichi Tsujii. 2009b. A re-evaluation of biomedi-
cal named entity - term relations. In Proceedings of
LBM?09.
M. F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130?137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. Bioinfer: a corpus for information
extraction in the biomedical domain. BMC bioinfor-
matics, 8(1):50+.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 1?9,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2009. Analyzing text in
search of bio-molecular events: a high-precision ma-
chine learning framework. In BioNLP ?09: Pro-
ceedings of the Workshop on BioNLP, pages 128?
136, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
152
Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 28?37,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
EVEX: A PubMed-Scale Resource for Homology-Based Generalization
of Text Mining Predictions
Sofie Van Landeghem1,2, Filip Ginter3, Yves Van de Peer1,2 and Tapio Salakoski3,4
1. Dept. of Plant Systems Biology, VIB, Belgium
2. Dept. of Plant Biotechnology and Genetics, Ghent University, Belgium
3. Dept. of Information Technology, University of Turku, Finland
4. Turku Centre for Computer Science (TUCS), Finland
solan@psb.ugent.be, ginter@cs.utu.fi
yvpee@psb.ugent.be, tapio.salakoski@utu.fi
Abstract
In comparative genomics, functional annota-
tions are transferred from one organism to an-
other relying on sequence similarity. With
more than 20 million citations in PubMed, text
mining provides the ideal tool for generating
additional large-scale homology-based predic-
tions. To this end, we have refined a recent
dataset of biomolecular events extracted from
text, and integrated these predictions with
records from public gene databases. Account-
ing for lexical variation of gene symbols, we
have implemented a disambiguation algorithm
that uniquely links the arguments of 11.2 mil-
lion biomolecular events to well-defined gene
families, providing interesting opportunities
for query expansion and hypothesis genera-
tion. The resulting MySQL database, includ-
ing all 19.2 million original events as well
as their homology-based variants, is publicly
available at http://bionlp.utu.fi/.
1 Introduction
Owing to recent advances in high-throughput se-
quencing technologies, whole genomes are being se-
quenced at an ever increasing rate (Metzker, 2010).
However, for the DNA sequence to truly unravel its
secrets, structural annotation is necessary to identify
important elements on the genome, such as coding
regions and regulatory motifs. Subsequently, func-
tional annotation is crucial to link these structural
elements to their biological function.
Functional annotation of genomes often requires
extensive in vivo experiments. This time-consuming
procedure can be expedited by integrating knowl-
edge from closely related species (Fulton et al,
2002; Proost et al, 2009). Over the past few
years, homology-based functional annotation has
become a widely used technique in the bioinformat-
ics field (Loewenstein et al, 2009).
Unfortunately, many known genotype-phenotype
links are still buried in research articles: The largest
biomolecular literature database, PubMed, consists
of more than 20 million citations1. Due to its expo-
nential growth, automated tools have become a ne-
cessity to uncover all relevant information.
There exist several text mining efforts focusing
on pairwise interactions and co-occurrence links of
genes and proteins (Hoffmann and Valencia, 2004;
Ohta et al, 2006; Szklarczyk et al, 2011). In
this paper, we present the first large-scale text min-
ing resource which both utilizes a detailed event-
based representation of biological statements and
provides homology-based generalization of the text
mining predictions. This resource results from the
integration of text mining predictions from nearly
18M PubMed citations with records from public
gene databases (Section 2). To enable such inte-
gration, it is crucial to first produce canonical forms
of the automatically tagged biological entities (Sec-
tion 3.1). A gene symbol disambiguation algorithm
then links these canonical forms to gene families and
gene identifiers (Section 3.2). Finally, a MySQL-
driven framework aggregates the text-bound event
occurrences into generalized events, creating a rich
resource of homology-based predictions extracted
from text (Section 3.3).
1http://www.ncbi.nlm.nih.gov/pubmed/
28
IL-2
NF-kappa B
Pos. regulation
Binding
p55
ca th
th th
Figure 1: Event representation of the statement IL-2 acts
by enhancing binding activity of NF-kappa B to p55, il-
lustrating recursive nesting of events where the (th)eme
of the Positive regulation event is the Binding event. The
(ca)use argument is the gene symbol IL-2.
2 Data
Our integrative approach is based on two types
of data: text mining predictions generated for the
whole of PubMed (Section 2.1) and publicly avail-
able gene database records (Section 2.2).
2.1 Text mining predictions
Bjo?rne et al (2010) have applied to all PubMed ab-
stracts an event extraction pipeline comprising of
the BANNER named entity recognizer (Leaman and
Gonzalez, 2008) and the Turku Event Extraction
System (Bjo?rne et al, 2009). The resulting dataset
contains 36.5M occurrences of gene / gene product
(GGP) entities and 19.2M occurrences of events per-
taining to these entities.
The file format and information scheme of
the resource correspond to the definition of the
BioNLP?09 Shared Task on Event Extraction (Kim
et al, 2009). Events are defined as typed relations
between arguments that are either entity occurrences
or, recursively, other events. There are nine possi-
ble event types: Localization, Binding, Gene expres-
sion, Transcription, Protein catabolism, Phosphory-
lation, Regulation, Positive regulation, and Negative
regulation. Further, arguments are assigned a role:
Theme or Cause for the core arguments and AtLoc,
ToLoc, Site, and CSite for auxiliary arguments that
define additional information such as cellular loca-
tion of the event. In addition, each event occurrence
may be marked as negative and/or speculative. Fig-
ure 1 depicts an example event.
2.2 Database records
During the last few decades, several large-scale
databases have been designed to deal with the abun-
dance of data in the field of life sciences. In this
study, we are particularly interested in databases of
gene symbols and homologous gene groups or gene
families. These families are composed by clustering
pairwise orthologs, which are genes sharing com-
mon ancestry evolved through speciation, often hav-
ing a similar biological function.
Entrez Gene2 is the default cross-species gene
nomenclature authority, hosted by NCBI (Sayers et
al., 2009). It bundles information from species-
specific resources as well as from RefSeq records3.
More than 8M Entrez Gene identifiers were col-
lected from over 8,000 different taxa, all together
referring to more than 10M distinct gene symbols,
descriptions, abbreviations and synonyms. While
Entrez Gene IDs are unique across taxa, gene sym-
bols are highly ambiguous. Section 3 describes how
we tackle gene symbol ambiguity across and within
species.
The HomoloGene4 database is also hosted at
NCBI and provides the results of automated de-
tection of orthologs in 20 completely sequenced
eukaryotic genomes. From this resource, around
43,700 HomoloGene families were extracted, con-
taining about 242,000 distinct genes. A second set
of gene families was retrieved from Ensembl (Flicek
et al, 2011). More than 13,000 Ensembl clusters
were assembled comprising about 220,000 genes.
As a general rule, the functional similarity scores
per homologous pair in a gene family are higher
when more stringent criteria are used to define the
families (Hulsen et al, 2006). While HomoloGene
consists of many strict clusters containing true or-
thologs, bigger Ensembl clusters were obtained by
assembling all pairwise orthologous mappings be-
tween genes. Ultimately, such clusters may also in-
clude paralogs, genes originated by duplication. As
an example, consider the nhr-35 gene from C. el-
egans, which has both Esr-1 and Esr-2 as known
orthologs, resulting in the two paralogs being as-
signed to the same final Ensembl cluster. The En-
sembl clustering algorithm can thus be seen as a
more coarse-grained method while the HomoloGene
mapping results in more strictly defined gene fami-
lies. The implications are discussed on a specific
use-case in Section 4.3.1.
2http://www.ncbi.nlm.nih.gov/gene
3http://www.ncbi.nlm.nih.gov/refseq
4http://www.ncbi.nlm.nih.gov/homologene
29
3 Methods
Widely known biomolecular events occur in many
different articles, often mentioning a different gene
synonym or lexical variant. Canonicalization of the
entity occurrences deals with these lexical variants
(Section 3.1), while the disambiguation algorithm
then uniquely links canonical forms to a gene fam-
ilies (Section 3.2). In a final step, these links can
be used to generalize the text mining events to their
homology-based variants (Section 3.3).
3.1 Canonicalization of the entity occurrences
The entity occurrences predicted by BANNER (Sec-
tion 2.1) follow the guidelines of GENETAG (Tan-
abe et al, 2005), the corpus it was trained on. These
guidelines allow not only gene and gene products,
but also related entities such as protein complexes
and gene promoters. Furthermore, BANNER fre-
quently tags noun phrases such as human Esr-1 gene
rather than only the minimal symbol Esr-1.
To enable integration of text mining predictions
with external databases, it is necessary to refine the
entity occurrences to canonical forms that can be
linked to gene records such as those in Entrez Gene.
To this end, common prefixes and suffixes such as
gene and wild-type should be removed.
In a first step towards canonicalization of the en-
tities, a mapping table was assembled containing
common contexts in which a gene symbol appears
and where the full noun phrase can be reduced to
that embedded symbol for the sake of information
retrieval (Table 1). This mapping table was created
by matching5 a list of candidate minimal gene sym-
bols to the extracted BANNER entities.
To define the list of candidate minimal gene sym-
bols, two approaches have been combined. First,
a set of around 15,000 likely gene symbols is ex-
tracted by looking for single token strings that were
tagged by BANNER at least 50% of the times they
occur in a PubMed abstract. Secondly, all official
gene names are extracted from Entrez Gene. As this
latter list also contains common English words such
as was and protein, we have only selected those that
were likely to be standalone gene symbols. We cal-
culate this likelihood by Cs/(Cs + Cn) where Cs
5All string matching steps have been implemented using the
SimString string retrieval library (Okazaki and Tsujii, 2010).
GGP contexts
-ORG- -GGP- gene
-GGP- sequences
mutant -GGP- proteins
-GGP- homologs
cytoplasmic wild-type -GGP-
Table 1: This table lists a few examples of entity occur-
rences extracted with BANNER that are resolved to the
embedded minimal gene symbol (marked as -GGP-).
is the number of times a string is tagged standalone
and Cn is the number of times the string occurs in
PubMed but is not tagged (neither as standalone,
nor as part of a larger entity). This likelihood rep-
resents the proportion of standalone occurrences of
the string that are tagged. We experimentally set a
threshold on this value to be higher than 0.01, ex-
cluding a list of 2,865 common English words.
Subsequently, all BANNER entity occurrences
are screened and likely minimal gene symbols sub-
stituted with -GGP-, resulting in generalized con-
texts. Then, we have matched these contexts with an
extensive list of organism names from the Linneaus
distribution (Gerner et al, 2010) and a small col-
lection of miscellaneous non-formal organism terms
(e.g. monkey), replacing all known organisms with
an -ORG- placeholder. Finally, we have excluded
all contexts where the embedded GGP is likely to
be functionally too far removed from the embed-
ding noun phrase (e.g. ?-GGP- inhibitor?), rely-
ing on a corpus defining and categorizing such re-
lationships (Ohta et al, 2009). Some of the contexts
that were retained after this step, such as ?-GGP-
mutant? or ?-GGP- promoter? still refer to entities
that are distinctly different from the embedded GGP.
These results are considered valid, as the goal of the
affix stripping algorithm is to increase recall and of-
fer explorative results involving various types of in-
formation on gene symbols.
The final list of contexts, generalized with -GGP-
and -ORG- placeholders, is split into two separate
lists of prefixes and suffixes, ranked by frequency.
Also, numerical affixes as well as those shorter than
3 characters are discarded from these lists.
30
Each text-bound entity occurrence can then be
canonicalized by applying the following algorithm:
1. Replace all organism names with the place-
holder -ORG-
2. If the string can be matched6 to a known sym-
bol in Entrez Gene, stop the algorithm
3. Find all occurring affixes and strip the one as-
sociated with the highest count
4. Repeat (2-3) until no more affixes match
5. Strip remaining -ORG- placeholders and all
whitespace and non-alphanumeric characters
For example, the canonicalization of human anti-
inflammatory il-10 gene proceeds as -ORG- anti-
inflamatory il-10 gene ? anti-inflammatory il-10
gene ? anti-inflammatory il-10 ? il-10, at which
point the string il10 is matched in Entrez Gene, be-
coming the final canonical form. In the following
section, we describe how these canonical forms are
assigned to unique gene families.
3.2 Disambiguation of gene symbols
Gene name ambiguity is caused by the lack of
community-wide approved standards for assigning
gene symbols (Chen et al, 2005). Furthermore, au-
thors often introduce their own lexical variants or ab-
breviations for specific genes.
From Entrez Gene, we have retrieved 8,034,512
gene identifiers that link to 10,177,542 unique sym-
bols. Some of these symbols are highly ambiguous
and uninformative, such as NEWENTRY. Others are
ambiguous because they are abbreviations. Finally,
many symbols can not be linked to one unique gene,
but do represent a homologous group of genes shar-
ing a similar function. Often, orthologs with similar
functions are assigned similar official gene names.
The first step towards gene symbol disambigua-
tion involves collecting all possible synonyms for
each gene family from either Ensembl or Homolo-
Gene. We strip these symbols of all whitespace and
non-alphanumeric characters to match the final step
in the canonicalization algorithm.
The disambiguation pipeline then synthesizes the
ambiguity for all gene symbols by counting their oc-
currences in the gene families. Each such relation
6The comparison is done ignoring whitespace and non-
alphanumeric characters.
Family Type of symbol Count
HG:47906 Default symbol 7
HG:99739 Synonym 1
HG:3740 Synonym 1
ECL:10415 Default symbol 12
ECL:8731 Synonym 1
ECL:8226 Synonym 1
Table 2: Intrinsic ambiguity of esr1, analysed in both Ho-
moloGene (HG) and Ensembl clusters (ECL).
records whether the symbol is registered as an offi-
cial or default gene symbol, as the gene description,
an abbreviation, or a synonym. As an example, Ta-
ble 2 depicts the intrinsic ambiguity of esr1.
In a subsequent step, the ambiguity is reduced by
applying the following set of rules, relying on a pri-
ority list imposed on the type of the symbol, ensur-
ing we choose an official or default symbol over a
description or synonym.
1. If one family has the most (or all) hits for a
certain symbol and these hits refer to a sym-
bol type having priority over other possibilities,
this family is uniquely assigned to that symbol.
2. If a conflict exists between one family having
the highest linkage count for a certain sym-
bol, and another family linking that symbol to
a higher priority type, the latter is chosen.
3. If two families have equal counts and type pri-
orities for a certain symbol, this symbol can
not be unambiguously resolved and is removed
from further processing.
4. If the ambiguity is still not resolved, all fami-
lies with only one hit for a certain symbol are
removed, and steps 1-3 repeated.
The above disambiguation rules were applied to
the 458,505 gene symbols in HomoloGene. In the
third step, 6,891 symbols were deleted, and when
the algorithm ends, 555 symbols remained ambigu-
ous. In total, 451,059 gene symbols could thus be
uniquely linked to a HomoloGene family (98%). In
the esr1 example depicted in Table 2, only the link to
HG:47906 will be retained. The results for Ensembl
were very similar, with 342,252 out of 345,906 sym-
bols uniquely resolved (99%).
31
All Ensembl HomoloGene
No stripping 39.9 / 67.5 / 50.2 62.8 / 70.0 / 66.2 64.2 / 69.2 / 66.6
Affix stripping 48.7 / 82.3 / 61.1 61.7 / 88.0 / 72.5 62.8 / 87.9 / 73.3
Table 3: Influence on precision, recall and F-measure (given as P/R/F) of the affix stripping algorithm on the entity
recognition module, as measured across all BioNLP?09 ST entity occurrences and also separately on the subsets which
can be uniquely mapped to Ensembl and HomoloGene (77.3% and 75.5% of all occurrences, respectively).
3.3 Homology-based generalization of the text
mining events
In order to gain a broader insight into the 19.2M
event occurrences obtained by Bjo?rne et al (2010),
it is necessary to identify and aggregate multiple oc-
currences of the same underlying event. This gen-
eralization also notably simplifies working with the
data, as the number of generalized events is an or-
der of magnitude smaller than the number of event
occurrences.
To aggregate event occurrences into generalized
events, it is necessary to first define equivalence
of two event occurrences: Two event occurrences
are equivalent, if they have the same event type,
and their core arguments are equivalent and have
the same roles. For arguments that are themselves
events, the equivalence is applied recursively. The
equivalence of arguments that are entities can be es-
tablished in a number of different ways, affecting
the granularity of the event generalization. One ap-
proach is to use the string canonicalization described
in Section 3.1; two entities are then equivalent if
their canonical forms are equal. This, however, does
not take symbol synonymy into account. A differ-
ent approach which we believe to be more power-
ful, is to disambiguate gene symbols to gene fam-
ilies, as described in Section 3.2. In this latter ap-
proach, two entity occurrences are deemed equiv-
alent if their canonical forms can be uniquely re-
solved to the same gene family. Consequently, two
event occurrences are considered equivalent if they
pertain to the same gene families.
As both approaches have their merits, three dis-
tinct generalization procedures have been imple-
mented: one on top of the canonical gene symbols,
and one on top of the gene families defined by Ho-
moloGene and Ensembl, respectively.
4 Results and discussion
4.1 Evaluation of entity canonicalization
The affix stripping step of the canonicalization al-
gorithm described in Section 3.1 often substantially
shortens the entity strings and an evaluation of its
impact is thus necessary. One of the primary objec-
tives of the canonicalization is to increase the pro-
portion of entity occurrences that can be matched
to Entrez Gene identifiers. We evaluate its im-
pact using manually tagged entities from the pub-
licly available BioNLP?09 Shared Task (ST) train-
ing set, which specifically aims at identifying enti-
ties that are likely to match gene and protein sym-
bol databases (Kim et al, 2009). Further, the ST set
comprises of PubMed abstracts and its underlying
text is thus covered in our data. Consequently, the
ST training set forms a very suitable gold standard
for the evaluation.
First, we compare7 the precision and recall of
the BANNER output before and after affix stripping
(Table 3, first column). The affix stripping results in
a notable gain in both precision and recall. In partic-
ular, the nearly 15pp gain on recall clearly demon-
strates that the affix stripping results in entity strings
more likely to match existing resources.
Second, the effect of affix stripping is evaluated
on the subset of entity strings that can be uniquely
mapped into Ensembl and HomoloGene (77.3% and
75.5% of the ST entity strings, respectively). This
subset is of particular interest, since the generalized
events are built on top of the entities that can be
found in these resources and any gain on this par-
ticular subset is thus likely to be beneficial for the
overall quality of the generalized events. Here, af-
fix stripping leads to a substantial increase in re-
call when compared to no stripping being applied
7The comparison is performed on the level of bags of strings
from each PubMed abstract, avoiding the complexity of align-
ing character offsets across different resources.
32
Entities Ent. occ.
Canonical 1.6M (100%) 36.4M (100%)
HomoloGene 64.0K (3.9%) 18.8M (51.7%)
Ensembl 54.6K (3.3%) 18.7M (51.2%)
Table 4: Entity coverage comparison. The entities col-
umn gives the number of canonical entities, also shown
as a percentage of all unique, canonical BANNER entities
(1.6M). The entity occurrences column shows the num-
ber of occurrences for which the generalization could be
established, out of the total number of 36.4M extracted
BANNER entities.
(around 18pp), which is offset by a comparatively
smaller drop in precision (less than 2pp). Global
performance increases with about 6.5pp in F-score
for both the Ensembl and HomoloGene subsets.
Bjo?rne et al (2010) used a simpler, domain-
restricted affix stripping algorithm whereby candi-
date affixes were extracted only from NP-internal
relations in the GENIA corpus (Ohta et al, 2009).
This original algorithm affects 11.5% unique en-
tity strings and results in 3.5M unique canonical
forms and 4.5M unique events. In comparison,
our current affix stripping algorithm results in 1.6M
unique canonical forms and 3.2M unique events,
thus demonstrating the improved generalization ca-
pability of the current affix stripping algorithm.
4.2 Evaluation of homology-based
disambiguation
The symbol to gene family disambiguation algo-
rithm succesfully resolves almost all gene symbols
in HomoloGene or Ensembl (Section 3.2). However,
not all genes are a member of a known gene family,
and the event generalization on top of the gene fam-
ilies will thus inevitably discard a significant portion
of the text mining predictions.
Table 4 shows that only a small fraction of all
unique canonical entities matches the gene families
from HomoloGene or Ensembl (3.9% and 3.3%, re-
spectively). However, this small fraction of symbols
accounts for approximately half of all entity occur-
rences in the text mining data (51.7% and 51.2%).
The algorithm thus discards a long tail of very in-
frequent entities. Table 5 shows a similar result for
the events and event occurrences. We find that map-
ping to HomoloGene and Ensembl results in a con-
siderably smaller number of generalized events, yet
Events Ev. occ.
Canonical 3223K 19.2M (100%)
HomoloGene 614K 10.2M (53%)
Ensembl 505K 10.2M (52.9%)
Table 5: Comparison of the three event generalization
methods. The events column gives the number of gen-
eralized events and the event occurrences column shows
the number of occurrences for which the generalization
could be established, out of the total number of 19.2M
text-bound event occurrences.
accounts for more than half of all event occurrences
(53% and 52.9%, respectively).
Finally, merging the canonical entities and the
corresponding generalized events for both Homolo-
Gene and Ensembl, we can assess the percentage of
all text mining predictions that can be linked to at
least one homology-based variant: 21.8M (59.8%)
of all entity occurrences and 11.2M (58.4%) of all
event occurrences can be resolved. Nearly 60% of
entity and event occurrences in the original text min-
ing data could thus be uniquely linked to well de-
fined gene families. Also, as shown in Section 4.1,
the 60% entities retained are expected to contain
proportionally more true positives, compared to the
40% entities that could not be mapped. One might
speculate that a similar effect will be seen also
among events.
4.3 MySQL database and Use-cases
As the PubMed events extracted by Bjo?rne et
al. (2010) are purely text-bound and distributed as
text files, they can not easily be searched. One im-
portant contribution of this paper is the release of all
text mining predictions as a MySQL database. Dur-
ing the conversion, all original information is kept,
including links to the PubMed IDs and the offsets
in text for all entities and triggers, referring to the
original strings as they were obtained by BANNER
and the event extraction system. This allows for fast
retrieval of text mining data on a PubMed-scale.
As described in Section 3.3, three distinct gener-
alization methods have been applied to the original
events. On the database level, each generalization is
represented by a separate set of tables for the gen-
eralized events and their arguments, aggregating im-
portant event statistics such as occurrence count and
33
Figure 2: Database scheme of the generalized events. Three instantiations of the general scheme (i.e. the three leftmost
tables) exist in the database. Following the dotted lines, each instance links to a different table in which the canonical
forms and the gene identifiers can be looked up.
negation/speculation information (Figure 2). Table 5
states general statistics for the three different sets.
Finally, a mapping table is provided that links the
generalized events to the event occurrences from
which they were abstracted. More technical details
on the MySQL scheme and example queries can be
found at http://bionlp.utu.fi/.
4.3.1 Use case: Query expansion
The MySQL database is the ideal resource to re-
trieve information on a PubMed-scale for a certain
gene or set of genes. Suppose there would be an in-
terest in Esr-1, then all abstract events on top of the
canonical form esr1 can be retrieved. However, re-
sults will display events for both the Estrogen recep-
tor as well as for the much less common Enhancer of
shoot regeneration. Furthermore, it makes no sense
to add known synonyms of both genes to the query,
as this will generate an incoherent list of synonyms
and even more false positive hits.
In such a case, it is to be recommended to use
the homology-based generalization of the events.
For example, esr1 hits the HomoloGene family
HG:47906, which contains all Estrogen receptor-
alpha genes across eukaryotic species. Canonical
symbols linked to this family include era, estra,
nr3a1 and estrogenreceptor1alpha.
A similar analysis can be done for the Ensembl
clustering, where esr1 links to ECL:10415. How-
ever, this more coarse-grained Ensembl family con-
tains all genes from the two closely related sub-
groups Estrogen receptor and Estrogen related re-
ceptor, both belonging to the Estrogen Receptor-
like group of the superfamily of nuclear recep-
tors (Zhang et al, 2004). On top of the synonyms
mentioned previously, this family thus also includes
erb, esr2b, errbetagamma and similartoesrrbpro-
tein. By using this list for query expansion, more
general text mining predictions can be retrieved.
It is to be noted that both homology-based ap-
proaches will also include events mentioning Esr-1
as the abbreviation for Enhancer of shoot regener-
ation. While this usage is much less common, it
will result in a few false positive hits. These false
positives may be prevented by taking into account
local context such as organism mentions, as the En-
hancer of shoot regeneration gene is only present
in A. thaliana. We believe our current homology-
based approach could be integrated with existing
or future normalization algorithms (Krallinger and
Hirschman, 2007; Wermter et al, 2009) to provide
such fine-grained resolution. This is regarded as in-
teresting future work.
4.3.2 Use case: Homology-based hypotheses
Consider a newly annotated, protein-coding gene
for which no database information currently ex-
ists. To generate homology-based text mining hy-
potheses, the orthologs of this gene first have to
be defined by assessing sequence similarity through
BLAST (Altschul et al, 1997).
Imagine for example a newly sequenced genome
X for which a gene similar to the mouse gene Esr-
1 is identified. This gene will soon be known as
?genome X Esr-1? and thus related to the Esr-1 gene
family. As described in Section 4.3.1, homology-
34
based query expansion can then be used to retrieve
all events involving lexical variants and synonyms
of the canonical string esr1.
5 Conclusions
We present a large-scale resource for research and
application of text mining from biomedical litera-
ture. The resource is obtained by integrating text
mining predictions in the dataset of Bjo?rne et al
(2010) with public databases of gene symbols and
gene families: Entrez Gene, Ensembl, and Homolo-
Gene. The integration is performed on the level of
gene families, allowing for a number of novel use
cases for both text mining and exploratory analysis
of the biological statements in PubMed literature. To
achieve the linking between text-based event predic-
tions and gene databases, several algorithms are in-
troduced to solve the problems involved.
First, we propose an algorithm for stripping af-
fixes in entity occurrences tagged by the BAN-
NER named entity recognizer, addressing the prob-
lem of such entities often including wider context
which prevents direct matching against gene symbol
databases. Using the BioNLP?09 Shared Task data
as gold standard, we show that the algorithm sub-
stantially increases both precision and recall of the
resulting canonical entities, the gain in recall being
particularly pronounced.
Second, we propose an algorithm which assigns
to the vast majority of gene symbols found in Ho-
moloGene and Ensembl a single unique gene fam-
ily, resolving the present intra-organism ambiguity
based on symbol occurrence statistics and symbol
type information. Matching these disambiguated
symbols with the affix-stripped canonical forms of
entity occurrences, we were able to assign a unique
gene family from either HomoloGene or Ensembl to
nearly 60% of all entities in the text, thus linking the
text-bound predictions with gene databases.
Finally, we use the resolution of entity occur-
rences to unique gene families to generalize the
events in the text mining data, aggregating together
event occurrences whose arguments are equivalent
with respect to their gene family. Depending on
whether HomoloGene or Ensembl is used for the
gene family definition, this generalization process
results in 500K-600K generalized events, which to-
gether aggregate over 11.2M (58.4%) of all event
occurrences in the text mining data. Being able
to link the literature-based events with well-defined
gene families opens a number of interesting new
use-cases for biomedical text mining, such as the
ability to use the homology information to search for
events relevant to newly discovered sequences. The
remaining 41.6% of event occurrences not general-
izable to gene families can still be retrieved through
an additional generalization on the level of entity
canonical forms.
All relevant data, namely all original events and
entities together with their canonical forms, the
generalizations of events based on canonical entity
forms and gene families, as well as the gene symbol
to unique family mapping are made publicly avail-
able as records in a MySQL database. We also pro-
vide detailed online documentation of the database
scheme and example queries. Finally, we release the
affix lists used in the canonicalization algorithm.
We believe this resource to be very valuable
for explorative analysis of text mining results and
homology-based hypothesis generation, as well as
for supporting future research on data integration
and biomedical text mining.
One important future work direction is a further
disambiguation of canonical gene symbols to unique
gene identifiers rather than entire gene families,
which would allow for more fine-grained event gen-
eralization. There is an ongoing active, community-
wide research focusing on this challenge and the cur-
rent resource could be integrated as an additional
source of information. Another future work direc-
tion is to create a visualization method and a web
interface which would allow simple, user-friendly
access to the data for researchers outside of the
BioNLP research community itself.
Acknowledgments
The authors would like to thank Sampo Pyysalo
(University of Tokyo) and Jari Bjo?rne (University
of Turku) for their contribution. SVL would like
to thank the Research Foundation Flanders (FWO)
for funding her research and a travel grant to Turku.
This work was partly funded by the Academy of Fin-
land and the computational resources were provided
by CSC IT Center for Science Ltd., Espoo, Finland.
35
References
Stephen F. Altschul, Thomas L. Madden, Alejandro A.
Scha?ffer, Jinghui Zhang, Zheng Zhang, Webb Miller,
and David J. Lipman. 1997. Gapped BLAST and PSI-
BLAST: a new generation of protein database search
programs. Nucleic acids research, 25(17):3389?3402,
September.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In BioNLP ?09: Proceedings of the Work-
shop on BioNLP, pages 10?18, Morristown, NJ, USA.
Association for Computational Linguistics.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010. Scaling up biomed-
ical event extraction to the entire PubMed. In Pro-
ceedings of the 2010 Workshop on Biomedical Natu-
ral Language Processing, BioNLP ?10, pages 28?36,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Lifeng Chen, Hongfang Liu, and Carol Friedman. 2005.
Gene name ambiguity of eukaryotic nomenclatures.
Bioinformatics, 21:248?256, January.
Paul Flicek, M. Ridwan Amode, Daniel Barrell, Kathryn
Beal, Simon Brent, Yuan Chen, Peter Clapham, Guy
Coates, Susan Fairley, Stephen Fitzgerald, Leo Gor-
don, Maurice Hendrix, Thibaut Hourlier, Nathan John-
son, Andreas Ka?ha?ri, Damian Keefe, Stephen Keenan,
Rhoda Kinsella, Felix Kokocinski, Eugene Kulesha,
Pontus Larsson, Ian Longden, William McLaren, Bert
Overduin, Bethan Pritchard, Harpreet Singh S. Riat,
Daniel Rios, Graham R. Ritchie, Magali Ruffier,
Michael Schuster, Daniel Sobral, Giulietta Spudich,
Y. Amy Tang, Stephen Trevanion, Jana Vandrov-
cova, Albert J. Vilella, Simon White, Steven P.
Wilder, Amonida Zadissa, Jorge Zamora, Bronwen L.
Aken, Ewan Birney, Fiona Cunningham, Ian Dunham,
Richard Durbin, Xose? M. Ferna?ndez-Suarez, Javier
Herrero, Tim J. Hubbard, Anne Parker, Glenn Proc-
tor, Jan Vogel, and Stephen M. Searle. 2011. Ensembl
2011. Nucleic acids research, 39(Database issue), Jan-
uary.
Theresa M. Fulton, Rutger Van der Hoeven, Nancy T.
Eannetta, and Steven D. Tanksley. 2002. Identifica-
tion, analysis, and utilization of conserved ortholog
set markers for comparative genomics in higher plants.
Plant Cell, 14(5):1457?1467.
Martin Gerner, Goran Nenadic, and Casey M. Bergman.
2010. LINNAEUS: a species name identification sys-
tem for biomedical literature. BMC bioinformatics,
11(1):85+, February.
Robert Hoffmann and Alfonso Valencia. 2004. A gene
network for navigating the literature. Nat Genet,
36(7):664, Jul.
Tim Hulsen, Martijn Huynen, Jacob de Vlieg, and Peter
Groenen. 2006. Benchmarking ortholog identification
methods using functional genomics data. Genome Bi-
ology, 7(4):R31+, April.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of the BioNLP 2009 Workshop Companion
Volume for Shared Task, pages 1?9, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Martin Krallinger and Lynette Hirschman, editors. 2007.
Proceedings of the Second BioCreative Challenge
Evaluation Workshop, Madrid, April.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedi-
cal named entity recognition. Pacific Symposium on
Biocomputing. Pacific Symposium on Biocomputing,
pages 652?663.
Yaniv Loewenstein, Domenico Raimondo, Oliver C.
Redfern, James Watson, Dmitrij Frishman, Michal
Linial, Christine Orengo, Janet Thornton, and Anna
Tramontano. 2009. Protein function annotation
by homology-based inference. Genome biology,
10(2):207, February.
Michael L. Metzker. 2010. Sequencing technolo-
gies - the next generation. Nature reviews. Genetics,
11(1):31?46, January.
Tomoko Ohta, Yusuke Miyao, Takashi Ninomiya, Yoshi-
masa Tsuruoka, Akane Yakushiji, Katsuya Masuda,
Jumpei Takeuchi, Kazuhiro Yoshida, Tadayoshi Hara,
Jin-Dong Kim, Yuka Tateisi, and Jun?ichi Tsujii.
2006. An intelligent search engine and GUI-based ef-
ficient MEDLINE search tool based on deep syntactic
parsing. In Proceedings of the COLING/ACL 2006 In-
teractive Presentation Sessions, pages 17?20, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Tomoko Ohta, Sampo Pyysalo, Kim Jin-Dong, and
Jun?ichi Tsujii. 2009. A re-evaluation of biomedi-
cal named entity - term relations. In Proceedings of
LBM?09.
Naoaki Okazaki and Jun?ichi Tsujii. 2010. Simple and
efficient algorithm for approximate dictionary match-
ing. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (Coling 2010),
pages 851?859, Beijing, China, August.
Sebastian Proost, Michiel Van Bel, Lieven Sterck, Kenny
Billiau, Thomas Van Parys, Yves Van de Peer, and
Klaas Vandepoele. 2009. PLAZA: A comparative ge-
nomics resource to study gene and genome evolution
in plants. Plant Cell, 21(12):3718?3731, December.
36
Eric W. W. Sayers, Tanya Barrett, Dennis A. A. Ben-
son, Stephen H. H. Bryant, Kathi Canese, Vyacheslav
Chetvernin, Deanna M. M. Church, Michael Dicuc-
cio, Ron Edgar, Scott Federhen, Michael Feolo, Lewis
Y. Y. Geer, Wolfgang Helmberg, Yuri Kapustin, David
Landsman, David J. J. Lipman, Thomas L. L. Madden,
Donna R. R. Maglott, Vadim Miller, Ilene Mizrachi,
James Ostell, Kim D. D. Pruitt, Gregory D. D.
Schuler, Edwin Sequeira, Stephen T. T. Sherry, Martin
Shumway, Karl Sirotkin, Alexandre Souvorov, Grig-
ory Starchenko, Tatiana A. A. Tatusova, Lukas Wag-
ner, Eugene Yaschenko, and Jian Ye. 2009. Database
resources of the National Center for Biotechnology
Information. Nucleic Acids Research, 37(Database
issue):D5?15, January.
Damian Szklarczyk, Andrea Franceschini, Michael
Kuhn, Milan Simonovic, Alexander Roth, Pablo
Minguez, Tobias Doerks, Manuel Stark, Jean Muller,
Peer Bork, Lars J. Jensen, and Christian von Mer-
ing. 2011. The STRING database in 2011: functional
interaction networks of proteins, globally integrated
and scored. Nucleic acids research, 39(Database
issue):D561?D568, January.
Lorraine Tanabe, Natalie Xie, Lynne H. Thom, Wayne
Matten, and W. John Wilbur. 2005. GENETAG: a
tagged corpus for gene/protein named entity recogni-
tion. BMC bioinformatics, 6 Suppl 1.
Joachim Wermter, Katrin Tomanek, and Udo Hahn.
2009. High-performance gene name normalization
with GENO. Bioinformatics, 25(6):815?821.
Zhengdong Zhang, Paula E. Burch, Austin J. Cooney,
Rainer B. Lanz, Fred A. Pereira, Jiaqian Wu,
Richard A. Gibbs, George Weinstock, and David A.
Wheeler. 2004. Genomic analysis of the nuclear re-
ceptor family: New insights into structure, regulation,
and evolution from the rat genome. Genome Research,
14(4):580?590, April.
37
Proceedings of BioNLP Shared Task 2011 Workshop, pages 147?148,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
Detecting Entity Relations as a Supporting Task
for Bio-Molecular Event Extraction
Sofie Van Landeghem1,2, Thomas Abeel1,2,3, Bernard De Baets4 and Yves Van de Peer1,2
1. Dept. of Plant Systems Biology, VIB, Belgium
2. Dept. of Plant Biotechnology and Genetics, Ghent University, Belgium
3. Broad Institute of MIT and Harvard, Cambridge, MA, USA
4. Dept. of Applied Mathematics, Biometrics and Process Control, Ghent University, Belgium
yves.vandepeer@psb.ugent.be
Abstract
Recently, the focus in the BioNLP domain
has shifted from binary relations to more ex-
pressive event representations, largely owing
to the international popularity of the BioNLP
Shared Task (ST) of 2009. This year, the
ST?11 provides a further generalization on
three key aspects: text type, subject domain,
and targeted event types. One of the sup-
porting tasks established to provide more fine-
grained text predictions is the extraction of en-
tity relations. We have implemented an ex-
traction system for such non-causal relations
between named entities and domain terms, ap-
plying semantic spaces and machine learning
techniques. Our system ranks second of four
participating teams, achieving 37.04% preci-
sion, 47.48% recall and 41.62% F-score.
1 Introduction
Understanding complex noun phrases with embed-
ded gene symbols is crucial for a correct interpre-
tation of text mining results (Van Landeghem et al,
2010). Such non-causal relations between a noun
phrase and its embedded gene symbol are referred
to as entity relations. As a supporting task for
the BioNLP ST?11, we have studied two types of
such entity relations: Subunit-Complex and Protein-
Component. These relationships may occur within
a single noun phrase, but also between two different
noun phrases. A few examples are listed in Table 1;
more details on the datasets and definitions of entity
relations can be found in (Pyysalo et al, 2011).
Valid entity relations involve one GGP (gene or
gene product) and one domain term (e.g. ?pro-
moter?) and they always occur within a single sen-
tence. In the first step towards classification of entity
relations, we have calculated the semantic similar-
ity between domain terms (Section 2). Supervised
learning techniques are then applied to select sen-
tences likely to contain entity relations (Section 3).
Finally, domain terms are identified with a novel
rule-based system and linked to the corresponding
GGP in the sentence (Section 4).
2 Semantic analysis
To fully understand the relationship between a GGP
and a domain term, it is necessary to account for
synonyms and lexical variants. We have imple-
mented two strategies to capture this textual varia-
tion, grouping semantically similar words together.
The first method takes advantage of manual anno-
tations of semantic categories in the GENIA event
corpus. This corpus contains manual annotation of
various domain terms such as promoters, complexes
and other biological entities in 1000 PubMed arti-
cles (Kim et al, 2008).
The second method relies on statistical proper-
ties of nearly 15.000 articles, collected by search-
ing PubMed articles involving human transcription
factor blood cells. From these articles, we have
then calculated a semantic space using latent seman-
tic analysis (LSA) as implemented by the S-Space
Package (Jurgens and Stevens, 2010). The algo-
rithm results in high-dimensional vectors that rep-
resent word contexts, and similar vectors then re-
fer to semantically similar words. We have applied
the Markov Cluster algorithm (MCL) (van Dongen,
2000) to group semantically similar terms together.
147
Type of relation Examples
Subunit-Complex ?the c-fos content of [AP-1]? / ?c-jun, a component of the transcription factor [AP-1]?
Protein-Component ?the [IL-3 promoter]? / ?the activating [ARRE-1 site] in the IL-2 promoter?
Table 1: Examples of entity relations. GGPs are underlined and domain terms are delimited by square brackets.
3 Machine learning framework
Our framework tries to define for each GGP in the
data whether it is part of any of the two entity re-
lations, by analysing the sentence context. To cap-
ture the lexical information for each sentence, we
have derived bag-of-word features. In addition, 2-
and 3-grams were extracted from the sentence. Fi-
nally, the content of the gene symbol was also used
as lexical information. All lexical information in
the feature vectors has undergone generalization by
blinding the gene symbol with ?protx? and all other
co-occurring gene symbols with ?exprotx?. Further-
more, terms occurring in the semantic lexicons de-
scribed in Section 2 were mapped to the correspond-
ing cluster number or category. For each generaliza-
tion, a blinded and a non-blinded variant is included
in the feature vector.
Dependency graphs were further analysed for the
extraction of grammatical patterns consisting of two
nodes (word tokens) and their intermediate edge
(grammatical relation). For the nodes, the same gen-
eralization rules as in the previous paragraph are ap-
plied. Finally, similar patterns are generated with
the nodes represented by their part-of-speech tag.
The final feature vectors, representing sentences
with exactly one tagged gene symbol, are classified
using an SVM with a radial basis function as kernel.
An optimal parameter setting (C and gamma) for
this kernel was obtained by 5-fold cross-validation
on the training data.
4 Entity detection
Once a sentence with a gene symbol is classified as
containing a certain type of entity relation, it is nec-
essary to find the exact domain term that is related
to that gene symbol. To this end, we have designed
a pattern matching algorithm that searches within a
given window (number of tokens) around the gene
symbol. The window size is increased to a prede-
fined maximum as long as a maximal number of do-
main terms was not found.
Within the search window, a rule-based algorithm
decides whether a given token qualifies as a relevant
domain term, employing first a high-precision dic-
tionary and then high-recall dictionaries.
5 Results
Our system achieves a global performance of
37.04% precision, 47.48% recall and 41.62% F-
score, coming in second place after the university
of Turku who obtained an F-score of 57.71%, and
ranking before Concordia University who scores
32.04%. It remains an open question why the final
results of the top ranked systems differ so much.
Acknowledgments
SVL and TA would like to thank the Research Foun-
dation Flanders (FWO) for funding their research.
TA is a post doctoral fellow of the Belgian Ameri-
can Education Foundation. The authors thank Jari
Bjo?rne for his help with the manuscript.
References
David Jurgens and Keith Stevens. 2010. The S-Space
package: an open source package for word space mod-
els. In Proceedings of the ACL 2010 System Demon-
strations, ACLDemos ?10, pages 30?35.
Jin-Dong Kim, Tomoko Ohta, and Jun?ichi Tsujii. 2008.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(1):10.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii. 2011.
Overview of the Entity Relations (REL) supporting
task of BioNLP Shared Task 2011. In Proceedings
of the BioNLP 2011 Workshop Companion Volume for
Shared Task, June.
Stijn van Dongen. 2000. Graph Clustering by Flow Sim-
ulation. Ph.D. thesis, University of Utrecht.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of the 2010 Workshop on Biomedical Natural
Language Processing, BioNLP ?10, pages 144?152.
148
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 82?90,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
PubMed-Scale Event Extraction for Post-Translational Modifications,
Epigenetics and Protein Structural Relations
Jari Bjo?rne 1,2, Sofie Van Landeghem 3,4, Sampo Pyysalo 5, Tomoko Ohta 5,
Filip Ginter 2, Yves Van de Peer 3,4, Sophia Ananiadou 5 and Tapio Salakoski 1,2
1Turku Centre for Computer Science (TUCS), Joukahaisenkatu 3-5B, 20520 Turku, Finland
2Department of Information Technology, 20014 University of Turku, Finland
3Department of Plant Systems Biology, VIB, Technologiepark 927, 9052 Gent, Belgium
4Department of Plant Biotechnology and Bioinformatics, Ghent University, Gent, Belgium
5National Centre for Text Mining and University of Manchester,
Manchester Interdisciplinary Biocentre,131 Princess Street, Manchester, UK
Abstract
Recent efforts in biomolecular event extrac-
tion have mainly focused on core event types
involving genes and proteins, such as gene
expression, protein-protein interactions, and
protein catabolism. The BioNLP?11 Shared
Task extended the event extraction approach
to sub-protein events and relations in the Epi-
genetics and Post-translational Modifications
(EPI) and Protein Relations (REL) tasks. In
this study, we apply the Turku Event Ex-
traction System, the best-performing system
for these tasks, to all PubMed abstracts and
all available PMC full-text articles, extract-
ing 1.4M EPI events and 2.2M REL relations
from 21M abstracts and 372K articles. We
introduce several entity normalization algo-
rithms for genes, proteins, protein complexes
and protein components, aiming to uniquely
identify these biological entities. This nor-
malization effort allows direct mapping of
the extracted events and relations with post-
translational modifications from UniProt, epi-
genetics from PubMeth, functional domains
from InterPro and macromolecular structures
from PDB. The extraction of such detailed
protein information provides a unique text
mining dataset, offering the opportunity to fur-
ther deepen the information provided by ex-
isting PubMed-scale event extraction efforts.
The methods and data introduced in this study
are freely available from bionlp.utu.fi.
1 Introduction
Biomedical domain information extraction has in re-
cent years seen a shift from focus on the extraction
of simple pairwise relations (Pyysalo et al, 2008;
Tikk et al, 2010) towards the extraction of events,
represented as structured associations of arbitrary
numbers of participants in specific roles (Ananiadou
et al, 2010). Domain event extraction has been pop-
ularized in particular by the BioNLP Shared Task
(ST) challenges in 2009 and 2011 (Kim et al, 2009;
Kim et al, 2011). While the BioNLP ST?09 em-
phasized protein interactions and regulatory rela-
tionships, the expressive event formalism can also
be applied to the extraction of statements regarding
the properties of individual proteins. Accordingly,
the EPI (Epigenetics and Post-Translational Modi-
fications) subchallenge of the BioNLP ST?11 pro-
vided corpora and competitive evaluations for the
detection of epigenetics and post-translational mod-
ification (PTM) events, while the REL (Entity Re-
lations) subchallenge covers structural and complex
membership relations of proteins (Ohta et al, 2011b;
Pyysalo et al, 2011). The complex memberships
and domains define the physical nature of an indi-
vidual protein, which is closely linked to its func-
tion and biological activity. Post-translational mod-
ifications alter and regulate this activity via struc-
tural or chemical changes induced by the covalent
attachment of small molecules to the protein. In
epigenetic regulation, gene expression is controlled
by the chemical modification of DNA and the his-
tone proteins supporting chromosomal DNA. All of
these aspects are important for defining the biologi-
cal role of a protein, and thus the EPI and REL tasks
enable the development of text mining systems that
can extract a more complete picture of the biomolec-
ular reactions and relations than previously possible
(cf. Table 1). Furthermore, previous work has shown
promising results for improving event extraction by
82
integration of ?static? entity relations (Pyysalo et al,
2009), in particular for the previously only available
PTM event, phosphorylation (Van Landeghem et al,
2010).
Information on protein modifications is avail-
able in general-purpose protein databases such as
UniProt, and there are also a number of dedicated
database resources covering such protein modifica-
tions (Wu and others, 2003; Lee et al, 2006; Li et
al., 2009). While the automatic extraction of PTMs
from text has also been considered in a number of
earlier studies, these have primarily involved single
PTM reactions extracted with special-purpose meth-
ods (Hu et al, 2005; Yuan et al, 2006; Lee et al,
2008). The EPI task and associated work (Ohta et
al., 2010) were the first to target numerous PTM re-
actions in a general framework using retrainable ex-
traction methods. The automatic detection of mod-
ification statements using keyword matching-based
methods has been applied also in support of DNA
methylation DB curation (Ongenaert et al, 2008;
Fang et al, 2011). However, as for PTM, the EPI
task and its preparatory efforts (Ohta et al, 2011a)
were the first to consider DNA methylation using the
general event extraction approach. To the best of our
knowledge, the present study is the first to extend the
event extraction approach to PTM and DNA methy-
lation event extraction to the scale of the entire avail-
able literature.
The Turku Event Extraction System (TEES), first
introduced for the BioNLP ST?09 (Bjo?rne et al,
2009), was updated and generalized for participa-
tion in the BioNLP ST?11, in which it had the best
performance on both the EPI and REL challenges
(Bjo?rne and Salakoski, 2011). With an F-score of
53.33% for the EPI and 57.7% for the REL task, it
performed over 16 pp better than the next best sys-
tems, making it well suited for our study. We apply
this system to the extraction of EPI events and REL
relations from all PubMed abstracts and all PMC
open access articles, using a pipeline of open source
text mining tools introduced in Bjo?rne et al (2010).
We further process the result using a recently
created bibliome-scale gene normalization dataset1.
This normalization effort connects protein and gene
mentions in text to their database IDs, a prerequi-
1Data currently under review.
site for effective use of text mining results for most
bioinformatics applications. In addition to protein
names, the EPI and REL challenges refer to the
protein substructures, modifications and complexes,
which we also need to normalize in order to deter-
mine the biological context of these events. In this
work, we develop a number of rule-based algorithms
for the normalization of such non-protein entities.
With both proteins and other entities normalized,
we can align the set of events extracted from the
literature with biological databases containing an-
notations on protein features, such as UniProt. We
can determine how many known and unknown fea-
tures we have extracted from text, and what percent-
age of various protein feature annotations our text
mining results cover. This association naturally also
works in the other direction, as we can take a gene or
protein and find yet unannotated post-translational
modifications, domains, or other features from sci-
entific articles, a promising use case for supporting
biomedical database curation.
2 Methods
2.1 PMC preprocessing
PMC full texts are distributed in an XML format that
TEES cannot use directly for event extraction. We
convert this XML into a flat ASCII text format with
a pipeline built on top of BioNLP ST?11 supporting
resource tools (Stenetorp et al, 2011). This process-
ing resolves embedded LATEX expressions, separates
blocks of text content (titles, sections, etc.) from
others, maps non-ASCII characters to corresponding
ASCII sequences, and normalizes whitespace. Re-
solving non-ASCII characters avoids increased error
rates from NLP tools trained on ASCII-only data.
2.2 Event Extraction
We use the Turku Event Extraction System for ex-
tracting both REL relations and EPI events. TEES is
a modular event extraction pipeline, that has recently
been extended for all the subtasks of the BioNLP?11
ST, including EPI and REL (Bjo?rne and Salakoski,
2011). TEES performs all supported tasks using
a shared graph scheme, which can represent both
events and relations (Figure 1 D). The system also
provides confidence scores enabling selection of the
most likely correct predictions. Before event extrac-
83
Event/relation type Example
Hydroxylation HIF-alpha proline hydroxylation
Phosphorylation (D) siRNA-mediated ATM depletion blocks p53 Serine-15 phosphorylation.
Ubiquitination K5 ubiquitinates BMPR-II on a Membrane-proximal Lysine
DNA methylation RUNX3 is frequently inactivated by P2 methylation in solid tumors.
Glycosylation Also, two asparagine residues in alpha-hCG were glycosylated.
Acetylation This interaction was regulated by Tat acetylation at lysine 50.
Methylation Methylation of lysine 37 of histone H2B is conserved.
Catalysis GRK2 catalyzed modest phosphorylation of BAC1.
Protein-Component Three enhancer elements are located in the 40 kb intron of the GDEP gene.
Subunit-Complex The most common form is a heterodimer composed of the p65/p50 subunits.
Table 1: Sentences with examples of the eight EPI event and two REL relation types, with highlighted triggers, and
protein and site arguments. Relations have no trigger and Catalysis takes as an argument another event.
Protein
Serine
Phosphorylation
of
Catalysis
is
Protein
mediated by CKI .
Cause>
REL detectionD
C
B
parsing
phosphorylation T-bet
Entity
<Theme
<Site
E
named entity recognition and normalization BANNER + GenNorm
McCJ-parser + Stanford Conversion
TEES
sentence splitting GENIA Sentence Splitter
PubMed Article Data
conversion to ST format and database import
A
Theme>
Serine of is mediated by CKI .phosphorylation T-betProteinEntity
<Protein-Component
Serine of is mediated by CKI .phosphorylation T-betNN VBN NN .NNNN VBZIN IN
<nn prep_of>
<nsubjpass
<auxpass agent>
Serine of is mediated by CKI .phosphorylation T-betProtein Protein
57765 27373
Serine of is mediated by CKI .phosphorylation T-bet
EPI detection
REL EPI
Figure 1: Event and relation extraction. Article text is
split into sentences (A), where gene/protein entities are
detected and normalized to their Entrez Gene IDs (B).
Each sentence with at least one entity is then parsed
(C). EPI events and REL relations are extracted from
the parsed sentences (D) and following conversion to
the BioNLP ST format are imported into a database (E).
(Adapted from Bjo?rne and Salakoski (2011)).
tion, protein/gene names are detected and sentences
are parsed. TEES handles all these preprocessing
steps via a pipeline of tool wrappers for the GE-
NIA Sentence Splitter (Kazama and Tsujii, 2003),
the BANNER named entity recognizer (Leaman and
Gonzalez, 2008), the McClosky-Charniak-Johnson
(McCCJ) parser (Charniak and Johnson, 2005; Mc-
Closky, 2010) and the Stanford tools (de Marneffe
et al, 2006). For a detailed description of TEES
we refer to Bjo?rne and Salakoski (2011) and for the
computational requirements of PubMed-scale event
extraction to Bjo?rne et al (2010).
2.3 Entity normalization
The extraction of events and relations as described in
the previous sections is purely text-based and does
not rely on any domain information from external
resources. This ensures generalizability of the meth-
ods to new articles possibly describing novel inter-
actions. However, practical use cases often require
integration of text mining results with external re-
sources. To enable such an integration, it is crucial to
link the retrieved information to known gene/protein
identifiers. In this section, we describe how we link
text mining data to biomolecular databases by pro-
viding integration with Entrez Gene, UniProt, Inter-
Pro and the Protein Data Bank.
2.3.1 Protein annotations
A crucial step for integrating statements in do-
main text with data records is gene name normaliza-
tion As part of a recent PubMed-scale effort,2 gene
2Data currently under review.
84
normalizations were produced by the GenNorm sys-
tem (Wei and Kao, 2011), assigning unique Entrez
Gene identifiers (Sayers and others, 2010) to am-
biguous gene/protein symbols. The GenNorm sys-
tem represents the state-of-the-art in gene normal-
ization, having achieved first rank by several evalua-
tion criteria in the BioCreative III Challenge (Lu and
others, 2011).
For practical applications, the Entrez Gene iden-
tifiers have been mapped to UniProt (The UniProt
Consortium, 2011) through conversion tables pro-
vided by the NCBI. As Entrez Gene and UniProt
are two of the most authoritative resources for gene
and protein identification, these annotations ensure
straightforward integration with other databases.
2.3.2 Complex annotations
The REL task Subunit-Complex relations all in-
volve exactly one protein complex and one of its
subunits, but the same complex may be involved in
many different Subunit-Complex relations (Pyysalo
et al, 2011). A key challenge for making use
of these relations thus involves retrieving a unique
identification of the correct complex. To identify
protein complexes, we use the Protein Data Bank
(PDB), an archive of structural data of biological
macromolecules (Berman et al, 2000). This re-
source currently contains more than 80,000 3-D
structures, and each polymer of a structure is anno-
tated with its respective UniProt ID.
To assign a unique PDB ID to an entity involved
in one or more Subunit-Complex relations, there
is usually no other lexical context than the protein
names in the sentence, e.g. ?the Rad9-Hus1-Rad1
complex?. Consequently, we rely on the normal-
ized protein names (Section 2.3.1) to retrieve a list
of plausible complexes, using data downloaded from
UniProt to link proteins to PDB entries. Ambiguity
is resolved by selecting the complex with the high-
est number of normalized proteins and giving pref-
erence to so-called representative chains. A list of
representative chains is available at the PDB web-
site, and they are determined by clustering similar
protein chains3 and taking the most confident ones
based on resolution quality.
Each assignment of a PDB identifier is annotated
with a confidence value between 0 and 1, express-
3Requiring at least 40% sequence similarity.
ing the percentage of proteins in the complex that
could be retrieved and normalized in text. For ex-
ample, even if one out of three UniProt identifiers is
wrongly assigned for a mention, the correct complex
might still be assigned with 0.66 confidence.
2.3.3 Domain annotations
Protein-Component relations define a relation be-
tween a gene/protein and one of its components,
such as a gene promoter or a protein domain. To
identify at least a substantial subset of these di-
verse relations, we have integrated domain knowl-
edge extracted from InterPro. InterPro is a rich re-
source on protein families, domains and functional
sites, integrating data from databases like PROSITE,
PANTHER, Pfam, ProDom, SMART and TIGR-
FAMs (Hunter and others, 2012). Over 23,000 dis-
tinct InterPro entries were retrieved, linking to more
than 16.5 million protein identifiers.
To assign an InterPro ID to an entity involved in
one or more Protein-Component relations, a set of
candidates is generated by inspecting the InterPro
associations of each of the proteins annotated with
that domain in text. For each such candidate, the
description of the InterPro entry is matched against
the lexical context around the entity by comparing
the number of overlapping tokens, excluding gen-
eral words, such as domain, and prepositions. The
amount of overlap is normalized against the length
of the InterPro description and expressed as a per-
centage, creating confidence values between 0 and 1.
Additionally, a simple pattern matching algorithm
recognizes statements expressing an amino acid in-
terval, e.g. ?aristaless domain (aa 527-542)?. When
such expressions are found, the intervals as anno-
tated in InterPro are matched against the retrieved
interval from text, and the confidence values express
the amount of overlap between the two intervals.
2.3.4 PTM site normalization
Six of the eight4 EPI event types refer to
post-translational modification of proteins. These
events are Hydroxylation, Phosphorylation, Ubiq-
uitination, Glycosylation, Acetylation and (Protein)
Methylation. To evaluate the events predicted
4As we are interested in PTM sites, we make no distinc-
tion between ?additive? PTMs such as Acetylation and their ?re-
verse? reactions such as Deacetylation.
85
from text, we compare these to annotated post-
translational modifications in UniProt. UniProt is
one of the largest manually curated databases for
protein knowledge, and contains annotations corre-
sponding to each of the EPI PTM event types.
We use the reviewed and manually annotated
UniProtKB/Swiss-Prot dataset (release 2012 02) in
XML format. We take for each protein all feature
elements of types modified residue, cross-link and
glycosylation site. Each of these feature elements
defines the site of the modification, either a single
amino acid, or a sequence of amino acids. We select
only annotations based on experimental findings,
that is, features that do not have a non-experimental
status (potential, probable or by similarity) to avoid
e.g. features only inferred from the sequence.
The modified residue feature type covers the event
types Hydroxylation, Phosphorylation, Acetylation
and Methylation. We determine the class of the mod-
ification with the UniProt controlled vocabulary of
post-translational modifications5. The description
attribute is the ID attribute of an entry in the vocabu-
lary, through which we can determine the more gen-
eral keyword (KW) for that description, if defined.
These keywords can then be connected to the corre-
sponding event types in the case of Hydroxylation,
Phosphorylation, Acetylation and Methylation. For
Ubiquitination events, we look for the presence of
the string ?ubiquitin? in the description attribute of
cross-link features. Finally, features corresponding
to Glycosylation events are determined by their fea-
ture element having the type glycosylation site.
The result of this selection process is a list of in-
dividual modification features, which contain a type
corresponding to one of the EPI PTM event types,
the UniProt ID of the protein, and the position and
amino acid(s) of the modification site. This data can
be compared with extracted events, using their type,
normalized protein arguments and modification site
arguments. However, we also need to normalize the
modification site arguments.
PTM sites are defined with a modification type
and the numbered target amino acid residue. In EPI
events, these residues are defined in the site argu-
ment target entities. To convert these into a form
that can be aligned with UniProt, we apply a set
5http://www.uniprot.org/docs/ptmlist/
Event Type Extracted PMC (%)
Hydroxylation 14,555 34.17
Phosphorylation 726,757 44.00
Ubiquitination 74,027 70.46
DNA methylation 140,531 52.27
Glycosylation 154,523 42.31
Acetylation 114,585 69.40
Methylation 122,015 74.86
Catalysis 45,763 67.86
Total EPI 1,392,756 51.53
Protein-Component 1,613,170 52.59
Subunit-Complex 537,577 51.18
Total REL 2,150,747 52.23
Table 2: Total number of EPI events and REL relations
extracted from PubMed abstracts and PMC full-text arti-
cles, with the fractions extracted from PMC.
of rules that try to determine whether a site is an
amino acid. We start from the main site token, and
check whether it is of the form AA#, where AA is an
amino acid name, or a one or three letter code, and
# an optional site number, which can also be in a to-
ken following the amino acid. For cases where the
site entity is the word ?residue? or ?residues?, we
look for the amino acid definition in the preceding
and following tokens. All strings are canonicalized
with removal of punctuation, hyphens and parenthe-
sis before applying the rules. In total, of the 177,994
events with a site argument, 75,131 could be nor-
malized to an amino acid, and 60,622 of these to a
specific residue number.
3 Results
The source for extraction in this work is the set of 21
million PubMed abstracts and 372 thousand PMC
open-access full-text articles. From this dataset,
1.4M EPI events and 2.2M REL relations were ex-
tracted (Table 2). For both tasks, about half of the
results were extracted from PMC, confirming that
full-text articles are an important source of infor-
mation for these extraction targets. The total num-
bers of events and relations are considerably lower
than e.g. the 21.3M events extracted for the GENIA
task from PubMed abstracts (Bjo?rne et al, 2010;
Van Landeghem et al, 2012), likely relating to the
comparatively low frequency with which EPI and
REL extraction targets are discussed with respect to
the basic GENIA biomolecular reactions.
86
Event type UniProt Events Match Coverage Events (site) Match Coverage
Hydroxylation 1,587 14,555 1,526 19 4,298 130 5
Phosphorylation 57,059 726,757 286,978 4,795 86,974 9,732 748
Ubiquitination 792 74,027 4,994 143 10,562 54 20
Glycosylation 6,708 154,523 18,592 897 22,846 68 31
Acetylation 6,522 114,585 15,470 764 25,689 158 30
Methylation 1,135 122,015 2,178 113 27,625 36 10
Total 73,803 1,206,462 329,738 6,731 177,994 10,178 844
Table 3: PTM events. PTMs that are not marked with non-experimental qualifiers are taken from UniProt. The
Events column lists the total number of predicted events, and the Events (site) the number of events that also have a
predicted site-argument. For these groups, Match is the number of events that matches a known PTM from UniProt,
and Coverage the number of UniProt PTMs for which at least one match exists. For Events matching takes into account
the PTM type and protein id, for Events (site) also the amino acid and position of the modified residue.
Event type AA UP # Highest confidence event Article ID
Phosphorylation S9 ? 2 p53 isolated from ML1, HCT116 and RKO cells, after short
term genotoxic stress, were phosphorylated on Ser 6, Ser 9
PMC:2777442
Acetylation S15 4 phosphorylated (Ser15), acetylated p53(Lys382) PMC:2557062
Methylation S15 1 phosphorylation of p53 at serine 15 and acetylation PM:10749144
Phosphorylation S15 ? 238 Chk2, as well as p53 Ser(15) phosphorylation and its PM:16731759
Phosphorylation T18 ? 12 p53 stabilization and its phosphorylation in Thr18 PMC:3046209
Phosphorylation S20 ? 45 that phosphorylation of p53 at Ser20 leads to PMC:3050855
Phosphorylation S33 ? 14 phosphorylation of p53 at serine 33 may be part of PMC:35361
Phosphorylation S37 ? 20 serine 33 of p53 in vitro when serine 37 is already PMC:35361
Phosphorylation S46 ? 55 phosphorylation of p53, especially at Serine 46 by PMC:2634840
Phosphorylation T55 ? 7 that phosphorylation of p53 at Thr55 inhibits its PMC:3050855
Phosphorylation S99 ? 0
Phosphorylation S183 ? 0
Phosphorylation S269 ? 0
Phosphorylation T284 ? 0
Ubiquitination K291 ? 0
Acetylation K292 ? 0
Ubiquitination K292 ? 0
Acetylation K305 ? 0
Phosphorylation S313 ? 1 hyperphosphorylation of p53, particularly of Ser313 PM:8649812
Phosphorylation S314 ? 0
Phosphorylation S315 ? 6 to require phosphorylation of p53 at serine 315 (35) PMC:2532731
Methylation K370 ? 6 by methylating lysine 370 of p53 PMC:1636665
Acetylation K372 1 for lysine 372 and 383 acetylated p53 (Upstate, PMC:1315280
Methylation K372 ? 5 methylation of p53 by the KMT7(SET7/9) methyltransferase
enzyme on Lys372
PMC:2794343
Acetylation K373 ? 16 p53 and acetylated p53 (lysine-373 and lysine-382) PMC:1208859
Methylation K373 ? 4 EHMT1-mediated p53 methylation at K373 PM:20588255
Acetylation K381 ? 0
Acetylation K382 ? 82 p53 acetylation at lysine 382 was found not PM:17898049
Methylation K382 ? 6 SET8 specifically monomethylates p53 at lysine 382 PM:17707234
Methylation K386 ? 1 that sumoylation of p53 at K386 blocks subsequent PM:19339993
Phosphorylation S392 ? 35 and phosphorylation of p53 at S392 PM:17237827
Table 4: Extracted and known PTM sites of p53. The type and site of the modification are in the first two columns.
UP indicates whether the PTM is present in the UniProt annotation for p53. Column # shows the number of extracted
events, followed by the event with the highest confidence score and the PubMed abstract or PMC full-text article it has
been extracted from.
87
3.1 Extracted PTMs compared to UniProt
The EPI PTM events were compared to annotated
PTMs from UniProt (Table 3). The majority of ex-
tracted PTM events (85%) have only a protein ar-
gument, and no information about the modification
site, so these can only be compared by the protein
id and PTM type. For the subset of proteins that
also have a site, which can be normalized to an
amino acid position, we can make a detailed com-
parison with UniProt. Finding a match for these
normalized amino acids is more difficult, and for
both categories, only a small fraction of proteins
from UniProt is covered. In part this may be due
to the limitations of the gene name normalization, as
finding the exact species-specific protein ID remains
a challenging task (Lu and others, 2011). How-
ever, even if the overall coverage is limited, well-
known protein modifications can be assigned to spe-
cific residues, as we show in the next section.
3.2 Extracted PTMs for a single protein
For an in-depth example of PTM modifications, we
study the protein p53, a central tumor suppressor
protein that is the subject of many studies. p53 is
also among the proteins with the most UniProt PTM
sites for which EPI events were predicted, making it
a good example for a case study (see Table 4).
We take from UniProt all known p53 PTMs corre-
sponding to our EPI event types and list the number
of predicted events for them (see Table 4). When
the number of predicted events is high, the most
confident prediction is usually a correctly extracted,
clear statement about the PTM. All events for PTMs
known in UniProt are correct except for the type
of K386. For events not in UniProt, the two S15
ones are false positives, and K372 acetylation, while
correctly extracted, is most likely a typo in the arti-
cle. For the PTMs for which no event was extracted,
we checked the reference article from UniProt an-
notation. K291, K292 ubiquitination, and K305 are
from abstracts, and thus missed events. S183, S269
and T284 are from a non-open access PMC article,
while S99, K292 acetylation, K305, S314 and K381
are from Excel or PDF format supplementary tables,
sources outside our extraction input.
In total, we have extracted 561 PTM events re-
lated to p53, 554 of which correspond to a PTM an-
Item PubMeth Extracted Recall
PMID+UPID 2776 1698 61.2%
UPID 392 363 92.6%
PMID 1163 1120 96.3%
Table 5: Evaluation of DNA methylation event extraction
recall against PubMeth.
notated in UniProt. Of the 28 EPI-relevant PTMs on
p53, 17 have at least one predicted event. The high-
est confidence events are about equally often from
abstracts as from full texts.
3.3 DNA methylation analysis
Two recently introduced databases, PubMeth (On-
genaert et al, 2008) and MeInfoText (Fang et al,
2011) provide manually curated information on
DNA methylation, primarily as it relates to cancer.
To evaluate the coverage of DNA methylation event
extraction, we focus here on PubMeth, as the full
content of this database could be directly used. Each
PubMeth DB record provides the primary name of
the methylated gene and the PMID of the publica-
tion supporting the curation of the record. We used
these two pieces of information to evaluate the recall
6 of DNA methylation event extraction.
We mapped PubMeth entries to UniProt iden-
tifiers (UPIDs), and extracted all unique (PMID,
UPID) pairs from both PubMeth and the automat-
ically extracted DNA methylation/demethylation
events. The results of comparison of these sets of
ID pairs are given in Table 5. We find that for over
60% of PubMeth entries, the system is able to re-
cover the specific (document, gene) pair. This result
is broadly in line with the recall of the system as
evaluated in the BioNLP ST. However, if the match-
ing constraint is relaxed, asking either 1) can the sys-
tem extract the methylation of each gene in PubMeth
somewhere in the literature or, inversely, 2) can the
system detect some DNA methylation event in each
document included in PubMeth as evidence, recall
is over 90%. In particular, the evaluation indicates
that the system shows very high recall for identify-
ing documents discussing DNA methylation.
6As PubMeth does not aim for exhaustive coverage, preci-
sion cannot be directly estimated in this way. For example, Pub-
Meth covers fewer than 2,000 documents and DNA methylation
events were extracted from over 20,000, but due to differences
in scope, this does not suggest precision is below 10%.
88
REL Type Extracted Match (p) Match (e)
Prot-Cmp 1613.1K 561.8K 150.7K
SU-Cmplx 537.6K 226.5K 99.6K
Table 6: Numbers of extracted entity relations, with the
protein (p) or both protein and entity (e) identified.
3.4 REL statistics
Table 6 presents the amount of extracted entity re-
lations and the coverage of the normalization algo-
rithms assigning protein, domain and complex iden-
tifiers. From a total of 537.6K Subunit-Complex re-
lations, 226.5K (42%) involve a protein that could be
unambiguously identified (Section 2.3.1). From this
subset, 99.6K relations (44%) could be assigned to a
PDB complex identifier (Section 2.3.2), accounting
for 3800 representative 3D protein structures.
The Protein-Component relations are much more
frequent in the data (1.6M relations) and here 35%
of the relations (561.8K) involve a normalized pro-
tein mention. The assignment of InterPro domains
to these Protein-Component relations (Section 2.3.3)
further covers 150.7K relations in this subset (27%),
identifying 5500 distinct functional domains. The
vast majority of these annotations (99%) are pro-
duced by matching the lexical context against the
InterPro descriptions, and only a few cases (200)
matched against the amino-acid pattern.
4 Conclusions
We have combined state-of-the-art methods for
gene/protein name normalization together with the
best available methods for event-based extraction
of protein post-translational modifications, reactions
relating to the epigenetic control of gene expres-
sion, and part-of relations between genes/proteins,
their components, and complexes. These methods
were jointly applied to the entire available litera-
ture, both PubMed abstracts and PMC full-text doc-
uments, creating a text mining dataset unique in both
scope and breadth of analysis. We further performed
a comprehensive analysis of the results of this au-
tomatic extraction process against major biological
database resources covering various aspects of the
extracted information. This analysis indicated that
text mining results for protein complexes, substruc-
tures and epigenetic DNA methylation provides al-
ready quite extensive coverage of relevant proteins.
For post-translational modifications, we note that
coverage still needs to be improved, but conclude
that the extracted events already provide a valuable
link to PTM related literature. In future work we
hope to further extend the event types extracted by
our PubMed-scale approach. The extraction meth-
ods as well as all data introduced in this study are
freely available from bionlp.utu.fi.
Acknowledgments
We thank the Academy of Finland, the Research
Foundation Flanders (FWO) and the UK BBSRC
(reference number: BB/G013160/1) for funding,
and CSC ? IT Center for Science Ltd for compu-
tational resources.
References
Sophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, and
Douglas B. Kell. 2010. Event extraction for sys-
tems biology by text mining the literature. Trends in
Biotechnology, 28(7):381?390.
Helen M. Berman, John Westbrook, Zukang Feng,
Gary Gilliland, T. N. Bhat, Helge Weissig, Ilya N.
Shindyalov, and Philip E. Bourne. 2000. The protein
data bank. Nucleic Acids Research, 28(1):235?242.
Jari Bjo?rne and Tapio Salakoski. 2011. Generalizing
biomedical event extraction. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 183?191.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Extract-
ing complex biological events with rich graph-based
feature sets. In Proceedings of the BioNLP 2009 Work-
shop, pages 10?18.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,
and Tapio Salakoski. 2010. Scaling up biomedical
event extraction to the entire PubMed. In Proceedings
of the BioNLP 2010 Workshop, pages 28?36.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of
ACL, pages 173?180.
Y.C. Fang, P.T. Lai, H.J. Dai, and W.L. Hsu. 2011. Me-
infotext 2.0: gene methylation and cancer relation ex-
traction from biomedical literature. BMC bioinformat-
ics, 12(1):471.
Z. Z. Hu, M. Narayanaswamy, K. E. Ravikumar,
K. Vijay-Shanker, and C. H. Wu. 2005. Literature
mining and database annotation of protein phospho-
rylation using a rule-based system. Bioinformatics,
21(11):2759?2765.
89
Sarah Hunter et al 2012. Interpro in 2011: new devel-
opments in the family and domain prediction database.
Nucleic Acids Research, 40(D1):D306?D312.
Jun?ichi Kazama and Jun?ichi Tsujii. 2003. Evaluation
and extension of maximum entropy models with in-
equality constraints. In Proceedings of EMNLP 2003,
pages 137?144.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview of
BioNLP?09 shared task on event extraction. In Pro-
ceedings of BioNLP 2009, pages 1?9.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Proceed-
ings of the BioNLP Shared Task 2011, pages 1?6.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedical
named entity recognition. Pacific Symposium on Bio-
computing, pages 652?663.
Tzong-Yi Lee, Hsien-Da Huang, Jui-Hung Hung, Hsi-
Yuan Huang, Yuh-Shyong Yang, and Tzu-Hao Wang.
2006. dbPTM: an information repository of pro-
tein post-translational modification. Nucleic acids re-
search, 34(suppl 1):D622?D627.
Hodong Lee, Gwan-Su Yi, and Jong C. Park. 2008.
E3Miner: a text mining tool for ubiquitin-protein lig-
ases. Nucl. Acids Res., 36(suppl.2):W416?422.
Hong Li, Xiaobin Xing, Guohui Ding, Qingrun Li, Chuan
Wang, Lu Xie, Rong Zeng, and Yixue Li. 2009.
SysPTM: A Systematic Resource for Proteomic Re-
search on Post-translational Modifications. Molecular
& Cellular Proteomics, 8(8):1839?1849.
Zhiyong Lu et al 2011. The gene normalization task
in BioCreative III. BMC Bioinformatics, 12(Suppl
8):S2+.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC-06, pages 449?454.
David McClosky. 2010. Any domain parsing: auto-
matic domain adaptation for natural language pars-
ing. Ph.D. thesis, Department of Computer Science,
Brown University.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, Jin-Dong
Kim, and Jun?ichi Tsujii. 2010. Event extraction
for post-translational modifications. In Proceedings of
BioNLP?10, pages 19?27.
Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, and
Jun?ichi Tsujii. 2011a. Event extraction for
DNA methylation. Journal of Biomedical Semantics,
2(Suppl 5):S2.
Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011b. Overview of the epigenetics and post-
translational modifications (EPI) task of BioNLP
Shared Task 2011. In Proceedings of BioNLP Shared
Task 2011 Workshop, pages 16?25.
Mate? Ongenaert, Leander Van Neste, Tim De Meyer,
Gerben Menschaert, Sofie Bekaert, and Wim
Van Criekinge. 2008. PubMeth: a cancer methy-
lation database combining text-mining and expert
annotation. Nucl. Acids Res., 36(suppl 1):D842?846.
Sampo Pyysalo, Antti Airola, Juho Heimonen, and Jari
Bjo?rne. 2008. Comparative analysis of five protein-
protein interaction corpora. BMC Bioinformatics,
9(Suppl. 3):S6.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun?ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Proceed-
ings of the BioNLP 2009 Workshop, pages 1?9.
Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii. 2011.
Overview of the entity relations (REL) supporting task
of BioNLP Shared Task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 83?88.
Eric W. Sayers et al 2010. Database resources of the na-
tional center for biotechnology information. Nucleic
Acids Research, 38(suppl 1):D5?D16.
Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, Tomoko
Ohta, Jin-Dong Kim, and Jun?ichi Tsujii. 2011.
Bionlp shared task 2011: Supporting resources. In
Proceedings of BioNLP Shared Task 2011 Workshop,
pages 112?120.
The UniProt Consortium. 2011. Ongoing and future de-
velopments at the universal protein resource. Nucleic
Acids Research, 39(suppl 1):D214?D219.
Domonkos Tikk, Philippe Thomas, Peter Palaga, Jo?rg
Hakenberg, and Ulf Leser. 2010. A comprehen-
sive benchmark of kernel methods to extract protein-
protein interactions from literature. PLoS Comput
Biol, 6(7):e1000837, 07.
Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,
and Yves Van de Peer. 2010. Integration of static re-
lations to enhance event extraction from text. In Pro-
ceedings of BioNLP?10, pages 144?152.
Sofie Van Landeghem, Kai Hakala, Samuel Ro?nnqvist,
Tapio Salakoski, Yves Van de Peer, and Filip Ginter.
2012. Exploring biomolecular literature with EVEX:
Connecting genes through events, homology and indi-
rect associations. Advances in Bioinformatics.
Chih-Hsuan Wei and Hung-Yu Kao. 2011. Cross-species
gene normalization by species inference. BMC bioin-
formatics, 12(Suppl 8):S5.
Cathy H. Wu et al 2003. The Protein Information Re-
source. Nucl. Acids Res., 31(1):345?347.
X. Yuan, ZZ Hu, HT Wu, M. Torii, M. Narayanaswamy,
KE Ravikumar, K. Vijay-Shanker, and CH Wu. 2006.
An online literature mining tool for protein phospho-
rylation. Bioinformatics, 22(13):1668.
90
Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 63?71,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Evaluating large-scale text mining applications
beyond the traditional numeric performance measures
Sofie Van Landeghem1,2, Suwisa Kaewphan3,4, Filip Ginter3, Yves Van de Peer1,2
1. Dept. of Plant Systems Biology, VIB, Belgium
2. Dept. of Plant Biotechnology and Bioinformatics, Ghent University, Belgium
3. Dept. of Information Technology, University of Turku, Finland
4. Turku Centre for Computer Science (TUCS), Turku, Finland
solan@psb.ugent.be, sukaew@utu.fi
ginter@cs.utu.fi, yvpee@psb.ugent.be
Abstract
Text mining methods for the biomedical
domain have matured substantially and
are currently being applied on a large
scale to support a variety of applica-
tions in systems biology, pathway cura-
tion, data integration and gene summa-
rization. Community-wide challenges in
the BioNLP research field provide gold-
standard datasets and rigorous evaluation
criteria, allowing for a meaningful com-
parison between techniques as well as
measuring progress within the field. How-
ever, such evaluations are typically con-
ducted on relatively small training and
test datasets. On a larger scale, sys-
tematic erratic behaviour may occur that
severely influences hundreds of thousands
of predictions. In this work, we per-
form a critical assessment of a large-scale
text mining resource, identifying system-
atic errors and determining their underly-
ing causes through semi-automated analy-
ses and manual evaluations1.
1 Introduction
The development and adaptation of natural lan-
guage processing (NLP) techniques for the
biomedical domain are of crucial importance to
manage the abundance of available literature. The
inherent ambiguity of gene names and complex-
ity of biomolecular interactions present an intrigu-
ing challenge both for BioNLP researchers as well
as their targeted audience of biologists, geneticists
and bioinformaticians. Stimulating such research,
various community-wide challenges have been or-
ganised and received international participation.
1The supplementary data of this study is freely avail-
able from http://bioinformatics.psb.ugent.
be/supplementary_data/solan/bionlp13/
The BioCreative (BC) challenge (Hirschman et
al., 2005; Krallinger et al, 2008; Leitner et al,
2010; Arighi et al, 2011) touches upon a variety of
extraction targets. The identification of gene and
protein mentions (?named entity recognition?) is a
central task and a prerequisite for any follow-up
work in BioNLP. Linking these mentions to their
respective gene database identifiers, ?gene normal-
ization?, is a crucial step to allow for integration
of textual information with authoritative databases
and experimental results. Other BC tasks are en-
gaged in finding functional and physical relations
between gene products, including Gene Ontology
annotations and protein-protein interactions.
Focusing more specifically on the molecu-
lar interactions between genes and proteins, the
BioNLP Shared Task on Event Extraction (Kim et
al., 2009; Kim et al, 2011b; Nedellec and others,
2013) covers a number of detailed molecular event
types, including binding and transcription, regula-
tory control and post-translational modifications.
Additionally, separate tracks involve specific ap-
plications of event extraction, including infectious
diseases, bacterial biotopes and cancer genetics.
Performance of the participants in each of these
challenges is measured using numeric metrics
such as precision, recall, F-measure, slot error
rate, MAP and TAP scores. While such rig-
urous evaluations allow for a meaningful compar-
ison between different systems, it is often difficult
to translate these numeric values into a measure-
ment of practical utility when applied on a large
scale. Additionally, infrequent but consistent er-
rors are often not identified through small-scale
evaluations, though they may result in hundreds of
thousands of wrongly predicted interactions on a
larger scale. In this work, we perform an in-depth
study of an open-source state-of-the-art event ex-
traction system which was previously applied to
the whole of PubMed. Moving beyond the tra-
ditional numeric evaluations, we identify a num-
63
Figure 1: Example event and relation represen-
tations, depicted in solid and dotted lines respec-
tively. Picture by Kim et al (2011a).
ber of systematic errors in the large-scale data,
analyse their underlying causes, and design post-
processing rules to resolve these errors. We be-
lieve these findings to be highly relevant for any
practical large-scale implementation of BioNLP
techniques, as the presence of obvious mistakes in
a text mining resource might undermine the credi-
bility of text mining techniques in general.
2 Data and methods
In this section, we first describe the data and meth-
ods used in previous work for the construction
of the large-scale text mining resource that is the
topic of our error analyses (Section 3).
2.1 Event extraction
Event extraction has become a widely studied
topic within the field of BioNLP following the
first Shared Task (ST) in 2009. The ST?09 in-
troduced the event formalism as a more detailed
representation of the common binary relation an-
notation (Figure 1). Each event occurrence con-
sists of an event trigger; i.e. one or more con-
secutive tokens that are linked to a specific event
type. While the ST?09 included only 9 event types,
among which 3 regulatory event types, the ST?11
further broadened the coverage of event extraction
to post-translational modifications and epigenetics
(EPI).
To compose a fully correct event, an event trig-
ger needs to be connected to its correct arguments.
Within the ST, these arguments are selected from a
set of gold-standard gene and gene product anno-
tations (GGPs). The ST guidelines determine an
unambiguous formalism to which correct events
must adhere: most event types only take one theme
argument, while Binding events can be connected
to more than one theme. Regulation events further
have an optional cause slot (Figure 1). Connecting
the correct arguments to the correct trigger words
is denoted as ?edge detection?.
To perform event extraction, we rely on the
publicly available Turku Event Extraction System
(TEES) (Bjo?rne et al, 2012), which was origi-
nally developed for the ST?09. The TEES mod-
ules for trigger and edge detection are based upon
supervised learning principles, employing support
vector machines (SVMs) for multi-label classifi-
cation. TEES has been shown to obtain state-of-
the-art performance when measured on the gold-
standard datasets of the Shared Tasks of 2009,
2011 and 2013.
2.2 Large-scale processing
Previously, the whole of PubMed has been anal-
ysed using a large-scale event extraction pipeline
composed of the BANNER named entity rec-
ognizer, the McClosky-Charniak parser, and the
Turku Event Extraction System (Bjo?rne et al,
2010). BANNER identifies gene and protein sym-
bols in text through a machine learning approach
based on conditional random fields (Leaman and
Gonzalez, 2008). While the resulting large-scale
text mining resource EVEX was focused only on
abstracts and ST?09 event types (Van Landeghem
et al, 2011), it has matured substantially during
the past few years and now includes ST?11 EPI
event types, full-text processing and gene normal-
ization (Van Landeghem et al, 2013a). In this
work, we use the version of EVEX as publicly
available on 16 March 2013, containing 40 million
event occurrences among 122 thousand gene and
protein symbols in 22 million PubMed abstracts
and 460 thousand PubMed Central full-text arti-
cles. Each event occurrence is linked to a normal-
ized confidence value, automatically derived from
the original TEES SVM classification step and the
distance to the hyperplane of each prediction.
While this study focuses on the EVEX resource
as primary dataset, the findings are also highly rel-
evant for other large-scale text mining resources,
especially those based on supervised learning,
such as the BioContext (Gerner et al, 2012).
2.3 Cross-domain evaluation
Recently, a plant-specific, application-oriented as-
sessment of the EVEX text mining resource has
been conducted by manually evaluating 1,800
event occurrences (Van Landeghem et al, 2013b).
In that study, it was established that the general
performance rates as measured previously on the
ST, are transferrable also to other domains and or-
ganisms. Specifically, the 58.5% TEES precision
64
Event type Five most frequent trigger words
Binding binding interaction associated bind association
Gene expression expression expressed production expressing levels
Localization secretion release localization secreted localized
Protein catabolism degradation degraded cleavage proteolysis degrade
Transcription transcription expression levels transcribed detected
Acetylation acetylation acetylated deacetylation hyperacetylation activation
Glycosylation glycosylated glycosylation attached N-linked absence
Hydroxylation hydroxylation hydroxylated hydroxylate beta-hydroxylation hydroxylations
Methylation radiation methylation methylated diffractometer trimethylation
DNA methylation methylation hypermethylation methylated hypermethylated unmethylated
Phosphorylation phosphorylation phosphorylated dephosphorylation phosphorylates phosphorylate
Ubiquitination ubiquitination ubiquitinated ubiquitylation ubiquitous polyubiquitination
Regulation effect regulation effects regulated control
Positive regulation increased activation increase induced induction
Negative regulation reduced inhibition decreased inhibited inhibitor
Catalysis mediated dependent mediates removes induced
Table 1: The top-5 most frequently tagged trigger words per event type in EVEX. The first 5 rows
represent fundamental event types, the next 7 post-translational modifications (PTMs), and the last 4
rows are regulatory event types. In this analysis, the PTMs and their reverse types are pooled together.
Trigger words that refer to systematic errors are in italic and are discussed further in the text.
rate measured in the ST?09, with the literature data
concerning human blood cell transcription factors,
corresponded with a 58.6% precision rate for the
plant-specific evaluation dataset (?PLEV?). This
encouraging result supports the general applicabil-
ity of large-scale text mining methods trained on
relatively small corpora. The findings of this pre-
vious study and the resulting data are further inter-
preted and analysed in more detail in this study.
3 Results
While the text mining pipeline underlying the
EVEX resource has been shown to produce state-
of-the-art results which are transferrable across
domains and organisms, it is conceivable that the
mere scale of the resource allows the accumula-
tion of systematic errors. In this section, we per-
form several targeted semi-automated evaluations
to identify, explain and resolve such cases. It is
important to note that our main focus is on im-
proving the precision rate of the resource, rather
than the recall, aiming to increase the credibility
of large-scale text mining resources in general.
3.1 Most common triggers
The trigger detection algorithm of the TEES soft-
ware is based upon SVM classifiers (Section 2.1),
and has been shown to outperform dictionary-
based approaches (Kim et al, 2009; Kim et al,
2011c). To investigate its performance in a large-
scale application, we first analyse the most fre-
quent trigger words of each event type in EVEX
(Table 1). We notice the presence of different in-
flections of the same word as well as related verbs
and nouns, such as ?inhibition?, ?inhibited? and
?inhibitor?. The trigger recognition module suc-
cessfully uses character bigrams and trigrams in
its SVM classification algorithm to allow for the
identification of such related concepts, even when
some of these trigger words were not encountered
in the training phase (Bjo?rne et al, 2009).
However, occasionally this approach results in
confusion between words with small edit dis-
tances, such as the trigger word ?ubiquitous? for
Ubiquitination events. Similarly, the Acetylation
trigger ?activation? is found within the context of
a correct event structure in most cases, but should
actually be of the type Positive regulation. The
implementation of custom post-processing rules
to automatically detect and resolve these specific
cases would ultimately deal with more than 6,000
false-positive event predictions.
Further, the trigger ?radiation? seems to occur
frequently for a Methylation event, of which 82%
of the instances can be identified in the ?Exper-
imental? subsection of the article. The majority
of these articles relate to protein crystallography,
and that subsection describes the data from the ex-
perimental set-up. Within such sections, phrases
like ?Mo Kalpha radiation? are wrongly tagged as
Methylation events. Similarly, many false-positive
Methylation predictions refer to the trigger word
?diffractometer?. Removing these instances from
the resource would result in the deletion of more
65
Trigger word s Most frequent type t2 Count Frequency Infrequent type t1 Count Frequency
acetylation Acetylation 40,291 0.298383 Binding 1,332 0.000216
Phosphorylation 1,050 0.001045
Gene expression 969 0.000093
Localization 1,045 0.000579
secretion Localization 376,976 0.208888 Acetylation 243 0.001800
glycosylation Glycosylation 24,226 0.141052 Phosphorylation 389 0.000387
Gene expression 214 0.000020
phosphorylation Phosphorylation 589,681 0.586772 Binding 454 0.000074
DNA methylation 225 0.001297
ubiquitylation Ubiquitination 4961 0.055976 Binding 128 0.000021
hypermethylation Methylation 19,501 0.112434 Phosphorylation 365 0.000363
cleavage Protein catabolism 20,552 0.073728 Gene expression 2,451 0.000234
Binding 3,011 0.000489
decreased Negative regulation 374,859 0.062372 Positive regulation 1,721 0.000173
Binding 855 0.000139
Gene expression 2,928 0.000280
reduced Negative regulation 442,400 0.073610 Positive regulation 1,091 0.000110
reduction Negative regulation 164,736 0.027410 Positive regulation 389 0.000039
absence Negative regulation 65,180 0.010845 Positive regulation 226 0.000071
Table 2: Examples of trigger words that correspond to the type which has the highest relative frequency
(left), but are also found with much lower frequencies in other types (right). The instances corresponding
to the right-most column can thus be interpreted as wrong predictions. The full list is available as a
machine readible translation table in the supplementary data.
than 82,000 false-positive event predictions.
Finally, we notice that the trigger word ?ab-
sence? for Glycosylation usually refers to a Neg-
ative regulation. Similarly, some words appear as
most frequent for more than one event type, such
as ?levels? (Gene expression and Transcription).
This type of error in trigger type disambiguation
is analysed in more detail in the next section.
3.2 Event type disambiguation
While previous work has focused on the disam-
biguation of event types on a small, gold-standard
dataset (Martinez and Baldwin, 2011), the rich-
ness of a large-scale text mining resource provides
additional opportunities to detect plausible errors.
To exploit this large-scale information, we anal-
yse all EVEX trigger words and their correspond-
ing event types, summarizing their raw event oc-
currence counts as Occ(t, s) where t denotes the
trigger type and s the trigger string. As some
event types are more abundantly described in lit-
erature, we normalize these counts to frequen-
cies (Freq(t, s)) depending on the total number
of event occurrences per type (Tot(t)):
Freq(t, s) =
Occ(t, s)
Tot(t)
with
Tot(t) =
n?
i=1
Occ(t, si)
and n the number of different triggers for event
type t. We then compare all trigger words and their
relative frequencies across different event types.
First, we inspect those cases where a trigger
word appears with comparable frequencies for two
event types t1 and t2:
Freq(t1, s) ? Freq(t2, s) ? 10? Freq(t1, s)
(1)
A first broad category of these cases are trig-
ger words that refer to both regulatory and non-
regulatory events at the same time, such as ?over-
expression? (Gene expression and Positive regula-
tion), or ?ubiquitinates? (Ubiquitination and Catal-
ysis). The majority of these cases are perfectly
valid and are in fact modeled explicitly by the
TEES software (Bjo?rne et al, 2009).
Further, we find that two broad groups of non-
regulatory event types are semantically similar and
share common trigger words: Methylation and
DNA methylation (e.g. ?methylation?, ?unmethy-
lated?, ?hypomethylation?), as well as Gene ex-
pression and Transcription (?expression?, ?synthe-
sis?, ?levels?), with occasional overlap also with
Localization (?abundance?, ?found?). Similarly,
trigger words are often shared among the four
regulatory event types (?dependent?, ?role?, ?regu-
late?), as the exact type may depend on the broader
context within the sentence.
While the previous findings do not necessar-
66
Predicted event type
Curated event type Localization Transcription Expression
Localization 15 0 3
Transcription 0 12 1
Expression 0 2 12
No event 0 2 3
Total 15 16 19
Table 3: Targeted evaluation of 50 mixed events of type Localization, Transcription and Gene expression.
The curated event type is compared to the original (hidden) predicted type.
ily refer to wrong predictions, we also notice the
usage of punctuation marks as trigger words for
various event types. This option was specifically
provided in the TEES trigger detection algorithm
as the ST?09 training data contains Binding in-
stances with ?-? as trigger word. However, these
punctuation triggers are found to be largely false
positives in the PubMed-scale event dataset. Re-
moving them in an additional post-processing step
would result in the filtering of more than 130,000
event occurrences, of which the largest part is ex-
pected to be incorrect predictions. Similarly, we
can easily remove 25,000 events that are related to
trigger words that are numeric values.
In a second step, we analyse those cases where
k ? Freq(t1, s) ? Freq(t2, s). (2)
When this condition holds, it can be hypothesized
that trigger predictions of the word s as type t1
are false positives and should have instead been of
type t2. Automatically generating such lists from
the data, we have experimentally determined an
optimal value of k = 100 that represents a reason-
able trade-off between the amount of false posi-
tives that can be identified and the manual work
needed for this.
From the resulting list, we can easily identify a
number of such cases that are clearly incorrect (Ta-
ble 2, right column). Specifically, a large number
of Positive regulation events actually refer to Neg-
ative regulation, providing an explanation of the
lower precision rate of Positive regulation predic-
tions in the previous PLEV evaluation (Van Lan-
deghem et al, 2013b). This semi-automated de-
tection procedure can ultimately result in the cor-
rection of more than 242,000 events.
The remaining cases for which condition (2)
holds are more ambiguous and can not be au-
tomatically corrected. However, these cases are
more likely to be incorrect and their confidence
values could thus be automatically decreased de-
pending on the ratio between Freq(t1, s) and
Freq(t2, s). A general exception to this rule is
formed by the broad groups of semantically simi-
lar events, such as Transcription-Gene expression-
Localization, which we analyse in more detail in
the next section.
3.3 Gene expression, Transcription and
Localization
Transcription is a sub-process of Gene expression,
with both event types relating to protein produc-
tion. However, the distinction between the two in
text may not always be straightforward. Addition-
ally, the ST training data for Transcription events
is significantly smaller than for Gene expression
events, which may be the reason why not only the
TEES performance, but also those of other sys-
tems, is considerably lower for Transcription than
for Gene expression (Kim et al, 2011c). Further,
cell-type specific gene expression should be cap-
tured by additional site arguments connected to a
Localization event, which represents the presence
or a change in the location of a protein.
To gain a deeper insight into the interplay be-
tween these three different event types, we have
performed a manual curation of 50 event occur-
rences, sampled at random from the Gene expres-
sion, Transcription and Localization events avail-
able in EVEX. For each event, the trigger word
and the corresponding sentence was extracted, but
the predicted event type was hidden. An expert an-
notator subsequently decided on the correct event
type of the trigger. Within this evaluation we fol-
lowed the ST guidelines to only annotate Gene ex-
pression when there is no evidence for the more
detailed Transcription type.
Table 3 shows the results. All 15 predicted
Localization triggers are recorded to be correct.
From the 16 predicted Transcription events, two
involve incorrect event triggers, and two other
events refer to the more general Gene expression
type (75% overall precision). Likewise, only one
Gene expression event should be of the more spe-
67
Curated event type Error type Instances (%)
1 Single-argument Binding No error 5 10%
2 Single-argument Binding Edge detection error 0 0%
3 Multiple-argument Binding Edge detection error 4 8%
4 Single-argument Binding Entity recognition error 1 2%
5 Multiple-argument Binding Entity recognition error 19 38%
6 Other Trigger detection error 21 42%
Table 4: Targeted evaluation of 50 single-argument Binding event triggers. Row 1: Fully correct event.
Row 2: The correct argument was annotated but not linked. Row 3: At least one correct multiple-
argument Binding event could have been extracted using the annotated entities in the sentence. Row 4:
The correct argument was not annotated. Row 5: No event could be extracted due to missing argument
annotations. Row 6: The trigger did not refer to a Binding event.
Unannotated entity type Entity occurrence count Examples
GGP 10 SPF30, spinal muscular atrophy gene
Generic GGP 9 primary antibodies, peptides, RNA
Chemical compound 10 Ca(2+), iron, manganese(II)
Table 5: Manual inspection of the textual entity types for those Binding events where a relevant theme
argument was not annotated in the entity recognition step.
cific Transcription type, three instances should be
Localization, and three more are considered not to
be correct events at all (63% overall precision). In
general, we remark that the predicted event type
largely corresponds to the curated type (78% of
all predictions and 87% of all otherwise correct
events).
3.4 Binding
Moving beyond the event type specification as
determined by the ST guidelines, the previous
PLEV analysis (Section 2.3) has established a re-
markable difference between single-argument and
multiple-argument Binding. In contrast to the reg-
ular ST evaluations, this work considered single-
and multiple-argument Binding as two separate
event types, resulting in a precision rate of 93% for
multiple-argument Binding triggers and only 8%
precision for single-argument Binding triggers.
As the PLEV study only focused on textual
network data, single-argument Bindings were not
analysed further. In this work however, we fur-
ther investigate this performance discrepancy and
perform an in-depth manual evaluation to try and
detect the main causes of this systematic error.
Several hypotheses can be postulated to explain
the low precision rate of single-argument Binding
events. Firstly, a false negative instance of the
entity recognition module might result in the ab-
sence of annotation for a relevant second interac-
tion partner. Another plausible explanation is an
error by the edge detection module of the event
extraction mechanism, which would occasionally
decide to produce one or several single-argument
Binding events rather than one multiple-argument
Binding, even when all involved entities are cor-
rectly annotated. Finally, it is conceivable that
predicted single-argument triggers simply do not
refer to Binding events, i.e. they contain false pos-
itive predictions of the trigger detection module of
the event extraction system.
In some cases, one trigger leads to many dif-
ferent Binding events, such as the trigger ?bind?
in the sentence ?Sir3 and Sir4 bind preferentially
to deacetylated tails of histones H3 and H4?. In
these cases, error types may accumulate: some
events could be missed due to unannotated enti-
ties, while others may be due to errors in the edge
detection step. However, multiple events with the
same trigger word are often represented by very
similar feature vectors in the classification step,
and consequently have almost identical final con-
fidence values. For this reason, we summarize the
error as ?Edge detection error? as soon as one pair
of entities was correctly annotated but not linked,
and as ?Entity recognition error? otherwise.
Table 4 summarizes the results of a curation
effort of 50 event triggers linked to a single-
argument Binding event in EVEX. We notice
that in fact, 46% should have been multiple-
argument Binding events. The main underlying
reason for the prediction of an incorrect single-
argument Binding event, when it should have been
a multiple-argument one, is apparently caused by
68
Curated event type Error type Instances (%)
1 Phosphorylation No error 34 68%
2 Phosphorylation Edge detection error 4 8%
3 Invalid Phosphorylation Edge detection error 2 4%
4 Phosphorylation Edge directionality detection error 4 8%
5 Invalid Phosphorylation Edge directionality detection error 1 2%
6 Phosphorylation Entity recognition error 3 6%
7 Other Trigger detection error 2 4%
Table 6: Targeted evaluation of 50 Phosphorylation event triggers and their theme arguments. Row 1:
Fully correct event. Row 2: The correct argument was annotated but not linked. Row 3: An argument
was linked but should not have been. Row 4: A causal argument was wrongly annotated as the theme
argument. Row 5: A causal argument was wrongly annotated as the theme argument. Row 6: The correct
argument was not annotated. Row 7: The trigger did not refer to a Phosphorylation event.
an entity recognition error (19/23 or 83%), while
an edge detection error is much less frequent
(17%). When we examine these entity recogni-
tion errors in more detail, we find that 10 rele-
vant entities are true GGPs in the sense of the
Shared Task annotation. However, 9 entities refer
to generic GGPs, and 10 instances relate to chemi-
cal compounds (Table 5). As these type of entities
can not be unambiguously normalized to unique
gene identifiers, they fall out-of-scope of the orig-
inal ST challenge. However, we feel this practice
introduces an artificial bias on the classifier and
the evaluation. Additionally, this information can
prove to be of value within a large-scale text min-
ing resource geared towards practical applications
and explorative browsing of textual information.
Finally, we notice that a remarkable 42% of all
predicted events contain trigger detection errors.
Analysing this subclass in more detail, we found
that 5 cases are invalid event triggers, 6 cases re-
fer to other event types such as Localization and
Gene expression, and 10 more cases were consid-
ered to be out-of-scope of the ST challenge, such
as a factor-disease association.
3.5 Phosphorylation
Within the PLEV evaluation (Section 2.3), it be-
came apparent that Phosphorylation is easy to
recognise from the sentence (98%) but the full cor-
rect event has a much lower precision rate (65%).
As we have seen in the previous section, even
when a trigger word is correctly predicted, errors
may still be generated by the edge detection or en-
tity recognition step. For instance, we might hy-
pothesize that the main underlying reason for the
reduced final performance is an error by the en-
tity recognition step, forcing the edge detection
mechanism to link an incorrect theme due to lack
of other options. Other plausible explanations in-
volve genuine errors by the edge detection algo-
rithm when the correct argument is annotated, as
well as problems with the identification of causal-
ity. As the TEES version applied in this work was
developed for the Shared Task 2009 and 2011, it
does not predict causal arguments for a Phospho-
rylation event directly, but instead adds Regulation
events on top of the Phosphorylations. Occasion-
ally, we have noticed that the theme of a Phospho-
rylation event should in fact have been the cause
of the embedding Regulation association, resulting
in a wrongly directed causal relationship.
To investigate these possibilities, we have man-
ually inspected 50 Phosphorylation events picked
at random from the EVEX resource. Table 6 sum-
marizes the results of this effort. Only two events
are found not to be Phosphorylation events: one
is in fact a Gene expression mention, the other
involves an incorrect trigger. Additionally, three
more events can semantically be regarded as Phos-
phorylations, but do not follow the ST specifica-
tions (?Invalid Phosphorylation?), for instance be-
cause they only mention causal arguments (?an
inhibition of Ca2+/calmodulin-dependent protein
phosphorylation?). Among the 45 cases which
correctly refer to the Phosphorylation type, 34
events are fully correct (68% of the total). Four
cases are wrongly extracted by misinterpreting the
causal relationship (?Edge directionality detection
error?) and four more instances refer to genuine
mistakes of the edge detection algorithm. Only
three other cases can be attributed to a missing en-
tity annotation. In contrast to the previous find-
ings on single-argument Bindings, we thus es-
tablish that the incorrect Phosphorylation events
are mainly caused by errors in the edge detection
mechanism, which either picks the wrong theme
69
from the set of annotated GGPs, or misinterprets
the causality direction.
4 Discussion and conclusion
We have performed several semi-automated eval-
uations and targeted manual curation experiments,
identifying and explaining systematic errors in a
large-scale event dataset. As a first observation,
we notice that a few frequent trigger words are
almost always associated to incorrect event pre-
dictions, such as the trigger words ?ubiquitous?
and ?radiation?, or a punctuation symbol. These
cases were identified through a large-scale auto-
matic analysis in combination with a limited man-
ual evaluation effort. The results are distributed as
a blacklist of event triggers for the implementation
or filtering of future large-scale event predictions
efforts.
Further, a semi-automated procedure has iden-
tified a list of likely incorrect predictions, by
comparing the type-specific frequencies of trigger
words across all event types. Manual inspection of
the most frequent cases allowed us to determine a
number of trigger words for which the event type
can automatically be corrected. These results are
also made publicly available.
Additionally, after removal of the most obvi-
ous and frequent errors, a fully automated script
can automatically reduce the confidence scores of
those event occurrences where the trigger words
are found to be much more frequent for another
event type. We have established that this proce-
dure should disregard triggers identified within a
few specific semantically similar clusters: DNA
methylation/Methylation, Regulation/Positive reg-
ulation/Negative regulation/Catalysis and Gene
expression-Transcription/Localization. An addi-
tional targeted evaluation of these last three types
revealed that, despite their semantic overlap, the
largest fraction of these predictions refers to the
correct event type (78? 11.5%).
Finally, we note that trigger detection (47 ?
14.6%) and entity recognition errors (44?14.6%)
are the main causes of wrongly predicted Bind-
ing events. The latter causes the event extraction
mechanism to artificially produce single-argument
Bindings instead of multiple-argument Bindings.
We believe this issue can be resolved by broaden-
ing the scope of the entity recognition module to
generic GGPs and chemical compounds, and re-
applying the TEES algorithm to these entities as
if they were normal GGPs as defined in the ST
formalism. In contrast, edge detection errors are
much more frequently the cause of a wrongly pre-
dicted Phosphorylation event (statistically signifi-
cant difference with p < 0.05), caused by wrongly
identifying the thematic object or the causality of
the event. To resolve this issue, we propose fu-
ture annotation efforts to specifically annotate the
protein adding the phosphate group to the target
protein as a separate class than the regulation of
such a phosphorylation process by other cellular
machineries and components (Kim et al, 2013).
In conclusion, we have performed several
statistical analyses and targeted manual eval-
uations on a large-scale event dataset. As a
result, we were able to identify a set of rules
to automatically delete or correct a number
of false positive predictions (supplementary
material at http://bioinformatics.
psb.ugent.be/supplementary_data/
solan/bionlp13/). When applying these
rules to the winning submission of the recent
ST?13 (GE subchallenge), which was based
on the TEES classifier (Hakala et al, 2013),
3 false positive predictions could be identified
and removed. Even though this procedure only
marginally improves the classification results
(50.97% to 50.99% F-score), we believe the
cleaning procedure to be crucial specifically for
the credibility of any large-scale text mining
application. For example, applied on the EVEX
resource, it would ultimately result in the removal
of 242,000 instances and a corrected event type of
230,000 more cases (1.2% of all EVEX events in
total). These corrections will be implemented as
part of the next big EVEX release. Additionally,
the confidence score of more than 120,000 am-
biguous cases could be automatically decreased.
Alternatively, these cases could be the target of
a large-scale re-annotation, for instance using
the brat annotation tool (Stenetorp et al, 2012).
The resulting dataset could then serve as a new
training set to enable active learning on top of
existing event extraction approaches.
Acknowledgments
The authors thank Cindy Martens and the anony-
mous reviewers for a critical reading of the
manuscript and constructive feedback. SVL
thanks the Research Foundation Flanders (FWO)
for funding her research.
70
References
Cecilia Arighi, Zhiyong Lu, Martin Krallinger, Kevin
Cohen, J. Wilbur, Alfonso Valencia, Lynette
Hirschman, and Cathy Wu. 2011. Overview of
the BioCreative III workshop. BMC Bioinformatics,
12(Suppl 8):S1.
Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,
Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-
tracting complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop, pages 10?18.
Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-
jii, and Tapio Salakoski. 2010. Scaling up biomed-
ical event extraction to the entire PubMed. In Pro-
ceedings of the BioNLP 2010 Workshop, pages 28?
36.
Jari Bjo?rne, Filip Ginter, and Tapio Salakoski. 2012.
Generalizing biomedical event extraction. BMC
Bioinformatics, 13(suppl. 8):S4.
Martin Gerner, Farzaneh Sarafraz, Casey M. Bergman,
and Goran Nenadic. 2012. BioContext: an in-
tegrated text mining system for large-scale extrac-
tion and contextualization of biomolecular events.
Bioinformatics, 28(16):2154?2161.
Kai Hakala, Sofie Van Landeghem, Tapio Salakoski,
Yves Van de Peer, and Filip Ginter. 2013. EVEX
in ST13: Application of a large-scale text mining
resource to event extraction and network construc-
tion. In Proceedings of the BioNLP Shared Task
2013 Workshop (in press).
Lynette Hirschman, Alexander Yeh, Christian
Blaschke, and Alfonso Valencia. 2005. Overview
of BioCreAtIvE: critical assessment of informa-
tion extraction for biology. BMC Bioinformatics,
6(Suppl 1):S1.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun?ichi Tsujii. 2009. Overview
of BioNLP?09 Shared Task on event extraction. In
Proceedings of the BioNLP 2009 Workshop, pages
1?9.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Junichi Tsujii. 2011a. Ex-
tracting bio-molecular events from literature - the
BioNLP?09 Shared Task. Computational Intelli-
gence, 27(4):513?540.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun?ichi Tsujii. 2011b.
Overview of BioNLP Shared Task 2011. In Pro-
ceedings of the BioNLP Shared Task 2011 Work-
shop, pages 1?6.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011c. Overview of Genia event
task in BioNLP Shared Task 2011. In Proceedings
of the BioNLP Shared Task 2011 Workshop, BioNLP
Shared Task ?11, pages 7?15.
Jin-Dong Kim, Yue Wang, Yamamoto Yasunori,
Sabine Bergler, Roser Morante, and Kevin Cohen.
2013. The Genia Event Extraction Shared Task,
2013 edition - overview. In Proceedings of the
BioNLP Shared Task 2013 Workshop (in press).
Martin Krallinger, Alexander Morgan, Larry Smith,
Florian Leitner, Lorraine Tanabe, John Wilbur,
Lynette Hirschman, and Alfonso Valencia. 2008.
Evaluation of text-mining systems for biology:
overview of the second BioCreative community
challenge. Genome Biology, 9(Suppl 2):S1.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedi-
cal named entity recognition. Pacific Symposium on
Biocomputing. Pacific Symposium on Biocomputing,
pages 652?663.
F. Leitner, S.A. Mardis, M. Krallinger, G. Cesareni,
L.A. Hirschman, and A. Valencia. 2010. An
overview of BioCreative II.5. Computational Bi-
ology and Bioinformatics, IEEE/ACM Transactions
on, 7(3):385?399.
David Martinez and Timothy Baldwin. 2011. Word
sense disambiguation for event trigger word detec-
tion in biomedicine. BMC Bioinformatics, 12(Suppl
2):S4.
Claire Nedellec et al 2013. Overview of BioNLP
Shared Task 2013. In Proceedings of the BioNLP
Shared Task 2013 Workshop (in press).
Pontus Stenetorp, Sampo Pyysalo, Goran Topic?,
Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-
jii. 2012. brat: a web-based tool for NLP-assisted
text annotation. In Proceedings of the Demonstra-
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 102?107.
Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,
and Tapio Salakoski. 2011. EVEX: a PubMed-scale
resource for homology-based generalization of text
mining predictions. In Proceedings of the BioNLP
2011 Workshop, pages 28?37.
Sofie Van Landeghem, Jari Bjo?rne, Chih-Hsuan Wei,
Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,
Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, Yves
Van de Peer, and Filip Ginter. 2013a. Large-
scale event extraction from literature with multi-
level gene normalization. PLoS ONE, 8(4):e55814.
Sofie Van Landeghem, Stefanie De Bodt, Zuzanna J.
Drebert, Dirk Inz, and Yves Van de Peer. 2013b.
The potential of text mining in data integration and
network biology for plant research: A case study on
arabidopsis. The Plant Cell, 25(3):794?807.
71
Proceedings of the BioNLP Shared Task 2013 Workshop, pages 26?34,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
EVEX in ST?13: Application of a large-scale text mining resource
to event extraction and network construction
Kai Hakala1, Sofie Van Landeghem3,4, Tapio Salakoski1,2,
Yves Van de Peer3,4 and Filip Ginter1
1. Dept. of Information Technology, University of Turku, Finland
2. Turku Centre for Computer Science (TUCS), Finland
3. Dept. of Plant Systems Biology, VIB, Belgium
4. Dept. of Plant Biotechnology and Bioinformatics, Ghent University, Belgium
kahaka@utu.fi, solan@psb.ugent.be, yvpee@psb.ugent.be,
ginter@cs.utu.fi, tapio.salakoski@utu.fi
Abstract
During the past few years, several novel
text mining algorithms have been de-
veloped in the context of the BioNLP
Shared Tasks on Event Extraction. These
algorithms typically aim at extracting
biomolecular interactions from text by in-
specting only the context of one sen-
tence. However, when humans inter-
pret biomolecular research articles, they
usually build upon extensive background
knowledge of their favorite genes and
pathways. To make such world knowl-
edge available to a text mining algorithm,
it could first be applied to all available lit-
erature to subsequently make a more in-
formed decision on which predictions are
consistent with the current known data. In
this paper, we introduce our participation
in the latest Shared Task using the large-
scale text mining resource EVEX which
we previously implemented using state-of-
the-art algorithms, and which was applied
to the whole of PubMed and PubMed Cen-
tral. We participated in the Genia Event
Extraction (GE) and Gene Regulation Net-
work (GRN) tasks, ranking first in the for-
mer and fifth in the latter.
1 Introduction
The main objective of our entry was to test the
usability of the large-scale text mining resource
EVEX to provide supporting information to an
existing state-of-the-art event extraction system.
In the GE task, EVEX is used to extract addi-
tional features for event extraction, capturing the
occurrence of relevant events in other documents
across PubMed and PubMed Central. In the GRN
task, EVEX is the sole source of information, i.e.
our entry consists of a modified subset of EVEX,
rather than a new text mining system specifically
trained for the task.
In the 2011 GE task, the majority of partici-
pating systems used features solely extracted from
the immediate textual context of the event candi-
date, typically restricted to a single sentence (Kim
et al, 2012; McClosky et al, 2012; Bjo?rne et al,
2012b; Vlachos and Craven, 2012). Several stud-
ies have subsequently incorporated coreference re-
lations, capturing information also from surround-
ing sentences (Yoshikawa et al, 2011; Miwa et al,
2012). However, no prior work exists on extend-
ing the event context to the information extracted
from other documents on a large scale. The moti-
vation for this entry is thus to test whether a gain
can be obtained by aggregating information across
documents with mutually supporting evidence.
In the following sections, we first introduce
EVEX as the underlying text mining resource, and
then describe the methods developed specifically
for the GRN and GE task entries. Finally, a de-
tailed error analysis of the results offers insight
into the performance of our systems and provides
possible directions of future development.
2 EVEX
EVEX1 is a text mining resource built on top
of events extracted from all PubMed abstracts
and PubMed Central Open-Access full-text doc-
uments (Van Landeghem et al, 2013a). The ex-
traction was carried out using a combination of
the BANNER named entity detector (Leaman and
Gonzalez, 2008) and the TEES event extraction
system as made publicly available subsequent to
the last Shared Task (ST) of 2011 (Bjo?rne et al,
2012a). Specifically, this version of TEES was
trained on the ST?11 GE data.
1http://www.evexdb.org
26
On top of the individual event occurrences,
EVEX provides event generalizations, allowing
the integration and summarization of knowledge
across different articles (Van Landeghem et al,
2011). For instance, the canonicalization algo-
rithm deals with small lexical variations by re-
moving non-alphanumerical characters (e.g. ?Esr-
1? to ?esr1?). The canonical generalization then
groups those events together with the same event
type and the same canonicalized arguments. Addi-
tionally, gene normalization data has recently been
integrated within the EVEX resource, assigning
taxonomic classification and database identifiers
to gene mentions in text using the GenNorm sys-
tem (Wei and Kao, 2011). Finally, the assignment
of genes to homologous families allows a more
coarse-grained generalization of the textual data.
For each generalized event, a confidence score is
automatically calculated based upon the original
TEES classification procedure, with higher values
representing more confident predictions.
Finally, the EVEX resource provides a network
interpretation which transforms events into pair-
wise gene/protein relations to represent a typed,
directed network. The primary advantage of such
a network, as compared to the complex, recursive
event structures, is that a network is more eas-
ily analysed and integrated with other external re-
sources (Kaewphan et al, 2012; Van Landeghem
et al, 2013b).
3 GRN Task
The Gene Regulatory Network subtask of the
ST?13 aims at evaluating the ability of text min-
ing systems to automatically compile a gene regu-
lation network from the literature. The task is fo-
cused specifically on sporulation in Bacillus sub-
tilis, a thoroughly studied process.
3.1 Challenge definition
The primary goal of our participation in this task
was assessing the ability to reconstruct regulatory
networks directly from the EVEX resource. Con-
sequently, we have applied the EVEX data as it
is publicly available. This decision has two major
consequences. First, we have used the predicted
BANNER entities rather than the gold-standard
entity annotation, artificially rendering the chal-
lenge more difficult. Second, we did not adapt the
EVEX events, which follow the ST?11 GE formal-
ism, to the novel annotation scheme of the GRN
EVEX type GRN type
Binding Binding
Regulation* of Transcription Transcription
Regulation* of Gene expression Transcription
Positive regulation of Any* Activation
Negative regulation of Any* Inhibition
Regulation of Any* Regulation
Table 1: Conversion of EVEX event types to the
GRN types. The table is traversed from top to
bottom, and the first rule that matches is applied.
Regulation* refers to any type of regulatory event,
and Any* refers to any other non-regulatory event
type.
challenge, but rather derived the network data di-
rectly from the EVEX interactions. For example,
given these trigger annotations
T1 Protein 37 43 sigmaB
T2 Gene 54 58 katX
T3 Transcription 59 69 expression
a GE Transcription event looks like
E1 Transcription:T3 Theme:T2 Cause:T1
while the GRN annotation is given by
R1 Transcription Target:E1 Agent:T1
E1 Action_Target:T3 Target:T2
However, both formalisms can easily be trans-
lated into the required GRN network format:
sigB Interaction.Transcription katX
where ?sigB? is annotated as the Gene identifier
of ?sigmaB?. These gene identifiers are provided
in the gold-standard entity annotations. Note that
in this context, ?gene identifiers? are standardized
gene symbols rather than numeric identifiers, and
full gene normalization is thus not required.
3.2 From EVEX to GRN data
As a first step towards creating a gene regula-
tory network directly from EVEX, we have down-
loaded all pairwise relations of the canonical gen-
eralization (Section 2). For each such relation,
we also obtain important meta-data, including the
confidence value, the PubMed IDs in which a re-
lation was found, whether or not those articles
describe Bacillus subtilis research, and whether
or not those articles are part of the GRN train-
ing or test set. In the most stringent setting, we
could then limit the EVEX results only to those
relations found in the articles of the GRN dataset
(72 in training, 45 in the development set, 55 in
the test set). Additionally, we could test whether
performance can be improved by also adding all
Bacillus subtilis articles (17,065 articles) or even
27
GRN event type Possible target types Possible agent types
Interaction.Binding Protein Gene
Interaction.Transcription Protein, PolymeraseComplex Gene, Operon
Interaction.Regulation
Protein, PolymeraseComplex Gene, Operon, Protein, ProteinComplexInteraction.Activation
Interaction.Inhibition
Table 2: Entity-type filtering of event predictions. Only those events for which the arguments (the target
as well as the agent) have the correct entity types, are retained in the result set.
all EVEX articles in which at least one event was
found (4,107,953 articles).
To match the canonicalized BANNER entities
from EVEX to the standardized gene symbols
required for the GRN challenge, we have con-
structed a mapping based on the GRN data. First,
we have scanned all gold-standard entities and
removed non-alphanumerical characters from the
gene symbols as tagged in text. Next, these canon-
ical forms were linked to the corresponding stan-
dardized gene symbols in the gold-standard anno-
tations. From the EVEX data, we then only re-
tained those relations that could be linked to two
gene symbols occurring together in a sentence.
Finally, it was necessary to convert the origi-
nal EVEX event types to the GRN relation types.
This mapping is summarized in Table 1. Because
EVEX Binding events are symmetrical and GRN
Bindings are not, we add both possible directions
to the result set. Note that some GRN types could
not be mapped because they have no equivalent
within the EVEX resource, such as the GRN type
?Requirement? or ?Promoter?.
3.3 Filtering the data
After converting the EVEX pairwise relations to
the GRN network format, it is necessary to fur-
ther process the set of predictions to obtain a co-
herent network. One additional filtering step con-
cerns the entity types of the arguments of a specific
event type. From the GRN data, we can retrieve
a symbol-to-type mapping, recording whether a
specific symbol referred to e.g. a gene, protein
or operon in a certain article. After careful in-
spection of the GRN guidelines and the training
data, we enforced the filtering rules as listed in
Table 2. For example, this procedure success-
fully removes protein-protein interactions from
the dataset, which are excluded according to the
GRN guidelines. Even though these rules are oc-
casionally more restrictive than the original GRN
guidelines, their effectiveness to prune the data
was confirmed on the training set.
Further, the GRN guidelines specify that a set
of edges with the same Agent and Target should
be resolved into a single edge, giving preference
to a more specialized type, such as Transcription
in favour of Regulation. Further, contradictory
types between a specific entity pair (e.g. Inhibition
and Activation) may occur simultaneously in the
GRN data. For the EVEX data however, it is more
beneficial to try and pick one single correct event
type from the set of predictions, effectively reduc-
ing the false positive rate. To this end, the EVEX
confidence values are used to determine the single
most plausible candidate. Further analyses on the
training data suggested that the best performance
could be achieved when only retaining the ?Mech-
anism? edges (Transcription and Binding) in cases
when no regulatory edge was found. Finally, we
noted that the EVEX Binding events more often
correspond to the GRN Transcription type, and
they were thus systematically refactored as such
(after entity-type filtering). We believe this shift
in semantics is caused by the fact that a promoter
binding is usually extracted as a binding event by
the TEES classifier, while it can semantically be
seen as a Transcription event, especially in those
cases where the Theme is a protein name, and the
Cause a gene symbol (Table 2).
3.4 Results
Table 3 lists the results of our method on the GRN
training data, which was primarily used for tun-
ing the parameters described in Section 3.3. The
highest recall (42%) could be obtained when using
all EVEX data, without restrictions on entity types
and without restricting to Bacillus subtilis articles.
As a result, this set of predictions may contain re-
lations between homologs in related species which
have the same name. While the relaxed F-score
(41%) is quite high, the Slot Error Rate (SER)
score (1.56) is unsatisfying, as SER scores should
be below 1 for decent predictions.
When applying entity type restrictions to the
prediction set, relaxed precision rises from 39%
28
Dataset ETF SER F Rel. P Rel. R Rel. F Rel. SER
All EVEX data no 1.56 8.86 39.29% 41.98% 40.59% 1.23
All EVEX data yes 1.15 11.53 59.74% 35.11% 44.23% 0.89
B. subtilis PMIDs yes 0.954 20.81 71.43% 22.90% 34.68% 0.86
GRN PMIDs yes 0.939 17.39 80.00% 18.32% 29.81% 0.86
Table 3: Performance measurement of a few different system settings, applied on the training data. The
SER score is the main evaluation criterion of the GRN challenge. The relaxed precision, recall, F and
SER scores are produced by scoring the predictions regardless of the specific event types. ETF refers to
entity type filtering.
to 60%, the relaxed F-score obtains a maximum
score of 44%, and the SER score improves to
1.15. The SER score can further be improved
when restricting the data to Bacillus subtilis arti-
cles (0.954). The optimal SER score is obtained by
further limiting the prediction set to only those re-
lations found in the articles from the GRN dataset
(0.939), maximizing at the same time the relaxed
precision rate (80%).
The final run which obtained the best SER score
on the training data was subsequently applied on
the GRN test data. It is important to note that the
parameter selection of our system was not overfit-
ted on the training data, as the SER score of our
final submission on the test data is 0.92, i.e. higher
than the best run on the training data.
Table 4 summarizes the official results of all
participants to the GRN challenge. Interestingly,
the TEES classifier has been modified to retrain
itself on the GRN data and to produce event
annotations in the GRN formalism (Bjo?rne and
Salakoski, 2013), obtaining a final SER score of
0.86. It is remarkable that this score is only 0.06
points better than our system which needed no re-
training, and which was based upon the original
GE annotation format and predicted gene/protein
symbols rather than gold-standard ones. Addition-
ally, the events in EVEX have been produced by a
version of TEES which was maximized on F-score
rather than SER score, and these measurements
are not mutually interchangeable (Table 3). We
conclude that even though our GRN system ob-
tained last place out of 5 participants, we believe
that its relative close performance to the TEES
submission demonstrates that large-scale text min-
ing resources can be used for gene regulatory net-
work construction without the need for retraining
the text mining component.
3.5 Error analysis
To determine the underlying reasons of our rela-
tively low recall rate, we have analysed the 117
SER Relaxed SER
University of Ljubljana 0.73 0.64
K.U.Leuven 0.83 0.66
TEES-2.1 0.86 0.76
IRISA-TexMex 0.91 0.60
EVEX 0.92 0.81
Table 4: Official GRN performance rates.
false negative predictions of our final run on the
training dataset. We found that 23% could be at-
tributed to a missing or incompatible BANNER
entity, 59% to a false negative TEES prediction,
15% to a wrong GRN event type and 3% to incor-
rectly mapping the gene symbol to the standard-
ized GRN format. Analysing the 16 false positives
in the same dataset, 25% could be attributed to an
incorrectly predicted event structure, and 62.5% to
a wrongly predicted event type. One case was cor-
rectly predicted but from a sentence outside the
GRN data, and in one case a correctly predicted
negation context was not taken into account. In
conclusion, future work on the GRN conversion of
TEES output should mainly focus on refining the
event type prediction, while general performance
could be enhanced by further improving the TEES
classification system.
4 GE Task
Our GE submission builds on top of the TEES 2.1
system2 as available just prior to the ST?13 test pe-
riod. First applying the unmodified TEES system,
we subsequently re-ranked its output and enforced
a cut-off threshold with the objective of removing
false positives from the TEES output (Section 4.1).
In the official evaluation, this step results in a mi-
nor 0.23pp increase of F-score compared to unpro-
cessed TEES output (Table 5). This yields the first
rank in the primary measure of the task with TEES
ranking second.
The main motivation for the re-ranking ap-
2https://github.com/jbjorne/TEES/wiki/
TEES-2.1
29
P R F
EVEX 58.03 45.44 50.97
TEES-2.1 56.32 46.17 50.74
BioSEM 62.83 42.47 50.68
NCBI 61.72 40.53 48.93
DlutNLP 57.00 40.81 47.56
Table 5: Official precision, recall and F-score rates
of the top-5 GE participants, in percentages.
proach was the ability to incorporate external in-
formation from EVEX to compare the TEES event
predictions and identify the most reliable ones.
Further, such a re-ranking approach leads to an in-
dependent component which is in no way bound to
TEES as the underlying event extraction system.
The component can be combined with any system
with sufficient recall to justify output re-ranking.
4.1 Event re-ranking
The output of TEES is re-ranked using SVMrank,
a formulation of Support Vector Machines which
is trained to optimize ranking, rather than classifi-
cation (Joachims, 2006). It differs from the basic
linear SVM classifier in the training phase, when a
query structure is defined as a subset of instances
which can be meaningfully compared among each
other ? in our case all events from a single sen-
tence. During training, only instances within a
single query are compared and the SVM does not
aim to learn a global ranking across sentences and
documents. We also experimented with polyno-
mial and radial basis kernels, feature vector nor-
malization and broadening the ranking query sets
to whole sections or narrowing them to only events
with shared triggers, but none of these settings
were found to further enhance the performance.
The re-ranker assigns a numerical score to each
event produced by TEES, and all events below
a certain threshold score are removed. To set
this threshold, a linear SVM regressor is applied
with the SVMlight package (Joachims, 1999) to
each sentence individually, i.e. we do not apply a
data-wide, pre-set threshold. Unlike the re-ranker
which receives features from a single event at a
time, the regressor receives features describing the
set of events in a single sentence.
Re-ranker features
Each event is described using a number of fea-
tures, including the TEES prediction scores for
triggers and arguments, the event structure, and
the EVEX information about this as well as simi-
lar events. Events can be recursively nested, with
the root event containing other events as its ar-
guments. The root event is of particular impor-
tance as the top-most event. A number of fea-
tures are thus dedicated specifically to this root
event, while other features capture properties of
the nested events.
Features derived from TEES confidence scores:
? TEES trigger detector confidence of the root
event and its difference from the confidence
of the negative class, i.e. the margin by which
the event was predicted by TEES.
? Minimum and maximum argument confi-
dences of the root event.
? Minimum and maximum argument confi-
dences, including recursively nested events
(if any).
? Minimum and maximum trigger confidences,
including recursively nested events (if any).
? Difference between the minimum and max-
imum argument confidences compared to
other events sharing the same trigger word.
Features describing the structure of the event:
? Event type of the root trigger.
? For each path in the event from the root to
a leaf argument, the concatenation of event
types along the path.
? For each path in the event from a leaf argu-
ment to another leaf argument, the concate-
nation of event types along the path.
? The event structure encoded in the bracketed
notation with leaf (T)heme and (C)ause argu-
ments replaced by a placeholder string, e.g.
Regulation(C:_, T:Acetylation(T:_)).
Features describing other events in the same sen-
tence:
? Event counts for each event type.
? Event counts for each unique event structure
given by the bracketed structure notation.
All event counts extracted from EVEX are rep-
resented as their base-10 logarithm to compress
the range and suppress differences in counts of
very common events.
The following features are generated in two ver-
sions, one by grouping the events according to the
EVEX canonical generalization and one for the
Entrez Gene generalization (Section 2)3.
3The generalizations based on gene families were evalu-
ated as well, but did not result in a positive performance gain.
30
? All occurrences of the given event in EVEX.
? For each path from root to a leaf gene/protein,
all occurrences of that exact path in EVEX.
? For each pair of genes/proteins in the event,
all occurrences of that pair in the network in-
terpretation of EVEX.
? For each pair of genes/proteins in the event,
all occurrences of that pair with a different
event type in the network interpretation of
EVEX.
For each event, path, or pair under considera-
tion, features are created for the base-10 logarithm
of the count in EVEX and of the number of unique
articles in which it was identified, as well as for
the minimum, maximum, and average confidence
values, discretized into six unique categories.
Regressor features
While the re-ranker features capture a single event
at a time, the threshold regressor features aggre-
gate information about events extracted within one
sentence. The features include:
? For each event type, the average and mini-
mum re-ranker confidence score, as well as
the count of events of that type.
? For each event type, the count of events shar-
ing the same trigger.
? For each event type, the count of events shar-
ing the same arguments.
? Minimum and maximum confidence values
of triggers and arguments in the TEES out-
put for the sentence.
? The section in the article in which the sen-
tence appears, as given in the ST data.
4.2 Training phase
To train the re-ranker and the regressor, false pos-
itive events are needed in addition to the true pos-
itive events in the training data. We thus apply
TEES to the training data and train the re-ranker
using the correct ranking of the extracted events.
A true positive event is given the rank 1 and a false
positive event gets the rank -1. A query structure
is then defined, grouping all events from a sin-
gle sentence to avoid mutual comparison of events
across sentences and documents during the train-
ing phase.
The trained re-ranker is then again applied to
the training data. For every sentence, the optimal
threshold is set to be the re-ranker score of the last
event which should be retained so as to maximize
# P R F
Simple events 833 -0.08 -0.36 -0.23
Protein mod. 191 +0.09 -2.09 -1.12
Binding 333 +0.43 -1.20 -0.44
Regulation 1944 +2.38 -0.67 +0.36
All 3301 +1.71 -0.73 +0.23
Table 6: Performance difference in percentage
points against the TEES system in the official test
set results, shown for different event types.
the F-score. In case the sentence only contains
false positives, the highest score is used, increased
by an empirically established value of 0.2. A sim-
ilar strategy is applied for sentences only contain-
ing true positives by using the lowest score, de-
creased by 0.2.
In both steps, the SVM regularization parameter
C is set by a grid search on the development set.
Applying TEES and the re-ranker back to the
training set results in a notably smaller propor-
tion of false positives than would be expected on
a novel input. To obtain a fully realistic train-
ing dataset for the re-ranker and threshold regres-
sor would involve re-training TEES in a cross-
validation setting, but this was not feasible due to
the tight schedule constraints of the shared task,
and is thus left as future work.
4.3 Error analysis
Although the re-ranking approach resulted in a
consistent gain over the state-of-the-art TEES sys-
tem on both the development and the test sets,
the overall improvement is only modest. As sum-
marized in Table 6, the gain over the TEES sys-
tem can be largely attributed to regulation events
which exhibit a 2.38pp gain in precision for a
0.67pp loss in recall. Regulation events are at the
same time by far the largest class of events, thus
affecting the overall score the most.
In this section, we analyse the re-ranker and
threshold regressor in isolation to understand their
individual contributions to the overall result and to
identify interesting directions for future research.
To isolate the re-ranker from the threshold re-
gressor and to identify the maximal attainable per-
formance, we set an oracle threshold in every sen-
tence so as to maximize the sentence F-score and
inspect the performance at this threshold, effec-
tively bypassing the threshold regressor. This,
however, provides a very optimistic estimate for
sentences where all predicted events are false pos-
itives, because the oracle then simply obtains the
31
All events P R F
B-C oracle (re-ranked) 81.32 39.61 53.27
W-C oracle (re-ranked) 54.92 39.61 46.02
W-C oracle (random) 51.06 39.19 44.34
Current system 47.15 39.61 43.05
TEES 45.46 40.39 42.77
Single-arg. events
B-C oracle (re-ranked) 81.37 50.58 62.38
W-C oracle (re-ranked) 56.09 50.58 53.19
W-C oracle (random) 52.73 50.00 51.33
Current system 48.66 50.44 49.53
TEES 47.16 51.09 49.04
Multiple-arg. events
B-C oracle (re-ranked) 81.02 16.83 27.87
W-C oracle (re-ranked) 48.61 16.83 25.00
W-C oracle (random) 42.66 16.75 24.05
Current system 39.64 17.12 23.91
TEES 37.57 18.17 24.50
Table 7: Performance comparison of the best case
(B-C) and worst case (W-C) oracles, the current
system with the re-ranker and threshold regressor,
and TEES. As an additional baseline, the worst
case oracle is also calculated for randomly ranked
output. All results are reported also separately for
single and multiple-argument events.
decisions from the gold standard and the rank-
ing itself is irrelevant. This effect is particu-
larly pronounced in sentences where only a sin-
gle, false positive event is predicted (15.9% of all
sentences with at least one event). Therefore, in
addition to this best case oracle score, we also de-
fine a worst case oracle score, where no events
are removed from sentences containing only false-
positives. This error analysis is carried out on the
development set using our own implementation of
the performance measure to obtain per-event cor-
rectness judgments.
The results are shown in Table 7. Even for the
worst case oracle, the re-ranked output has the po-
tential to provide a 9.5pp increase in precision for
a 0.8pp loss in recall over the baseline TEES sys-
tem. How much of this potential gain is realized
depends on the accuracy of the threshold regres-
sor. In the current system, only a 1.7pp precision
increase for a 0.8pp recall loss is attained, demon-
strating that the threshold regressor leaves much
room for improvement.
The best case oracle precision is 26.4pp higher
than the worst case oracle, indicating that substan-
tial performance losses can be attributed to sen-
tences with purely false positive events. Indeed,
sentences only containing one or two incorrect
events account for 26% of all sentences with at
least one predicted event. Due to their large impact
TEES 1-arg N-arg Full
Simple events 64.43 +0.07 ?0.00 +0.07
Protein mod. 40.47 +0.06 ?0.00 +0.06
Binding 82.03 ?0.00 ?0.00 ?0.00
Regulation 30.34 +0.70 -0.14 +0.53
All events 45.04 +0.66 ?0.00 +0.64
Table 8: Performance of the system on the de-
velopment set when applied to single-argument
events only (1-arg), to multiple-argument events
only (N-arg), and to all events (Full).
on the overall system performance, these cases
may justify a focused effort in future research.
To establish the relative merit of the re-ranker,
we compare the worst-case oracle scores of the re-
ranked output against random ranking, averaged
over 10 randomization runs. While the difference
between TEES output and the random ranking re-
flects the effect of using an oracle to optimize per-
sentence score, the difference between the ran-
dom ranking and the re-ranker output shows an
actual added value of the re-ranker, not attained
from the use of oracle thresholds. Here it is of
particular interest to note that this difference is
more pronounced for events with multiple argu-
ments (5.95pp of precision) as opposed to single-
argument events (3.36pp of precision), possibly
due to the fact that such events have a much richer
feature representation and also employ the EVEX
resource. To assess the contribution of EVEX
data, a re-ranker was trained solely on features de-
rived from EVEX. This re-ranker achieved an F-
score of 1.26pp higher than randomized ranking,
thus suggesting that these features have a positive
influence on the overall score.
To verify these results and measure their im-
pact on the official evaluation, Table 8 summa-
rizes the performance on the development set us-
ing the official evaluation service. To study the
effect on single-argument events (column 1-arg),
the re-ranker score for multiple-argument events
is artificially increased to always fall above the
threshold. A similar strategy is used to study
the effect on multiple-argument events (column
N-arg). These results confirm that the overall
performance gain of our system on top of TEES
is obtained on single-argument events. Further,
multiple-argument events have only a negligible
effect on the overall score, demonstrating that, due
to their low frequency, little can be gained or lost
purely on multiple-argument events.
To summarize the error analysis, the results in
32
Table 7 suggest that the re-ranker is more effec-
tive on multiple-argument events where it receives
more features including external information from
EVEX. On the other hand, the results in Table 8
clearly demonstrate that the system is overall more
effective on single-argument events. This would
suggest a ?mismatch? between the re-ranker and
the threshold regressor, each being more effective
on a different class of events. One possible expla-
nation is the fact that the threshold regressor pre-
dicts a single threshold for all events in a sentence,
regardless of their type and number of arguments.
If these cannot be distinguished by one threshold,
it is clear that the threshold regressor will optimize
for the largest event type, i.e. a single-theme regu-
lation. Studying ways to allow the regressor to act
separately on various event types will be important
future work.
4.4 Discussion and future work
One of the main limitations of our approach is
that it can only increase precision, but not recall,
since it removes events from the TEES output, but
is not able to introduce new events. As TEES
utilizes separate processing stages for predicting
event triggers and argument edges, recall can be
adjusted by altering either of these steps. We
have briefly experimented with modifying TEES
to over-generate events by artificially lowering the
prediction threshold for event triggers. However,
this simple strategy of over-generating triggers
leads to a number of clearly incorrect events and
did not provide any performance gain. As future
work, we thus hope to explore effective ways to
over-generate events in a more controlled and ef-
fective fashion. In particular, a more detailed eval-
uation is needed to assess whether the rate of trig-
ger over-generation should be adjusted separately
for each event type. Another direction to explore
is to over-generate argument edges. This will en-
tail a detailed analysis of partially correct events
with a missing argument in TEES output. As in
the case of triggers, it is likely that each event type
will need to be optimized separately.
A notable amount of sentences include only
false positive predictions, severely complicating
the threshold regression. In an attempt to over-
come this issue, we trained a sentence classifier
for excluding sentences that should not contain
any events. This classifier partially utilized the
same features as the threshold regressor, as well
as bag of words and bag of POS tags. This
method showed some promise when used together
with trigger over-generation, but the gain was not
enough to surpass the lost precision caused by the
over-generation. If the event over-generation can
be improved, the feasibility of this method should
be re-evaluated.
5 Conclusions
We have presented our participation in the latest
BioNLP Shared Task by mainly relying on the
large-scale text mining resource EVEX. For the
GRN task, we were able to produce a gene reg-
ulatory network from the EVEX data without re-
training specific text mining algorithms. Using
predicted gene/protein symbols and the GE for-
malism, rather than gold standard entities and the
GRN annotation scheme, our final result on the
test set only performed 0.06 SER points worse
as compared to the corresponding TEES submis-
sion. This encouraging result warrants the use of
generic large-scale text mining data in network bi-
ology settings. As future work, we will extend the
EVEX dataset with information on the entity types
to enable pruning of false-positive events and
more fine-grained classification of event types,
such as the distinction between promoter binding
(Protein-Gene Binding) and protein-protein inter-
actions (Protein-Protein Binding).
In the GE task, we explored a re-ranking ap-
proach to improve the precision of the TEES
event extraction system, also incorporating fea-
tures from the EVEX resource. This approach
led to a modest increase in the overall F-score
of TEES and resulted in the first rank on the GE
task. In the subsequent error analysis, we have
demonstrated that the re-ranker provides an oppor-
tunity for a substantial increase of performance,
only partially realized by the regressor which sets
a per-sentence threshold. The analysis has identi-
fied numerous future research directions.
Acknowledgments
Computational resources were provided by CSC
IT Center for Science Ltd., Espoo, Finland. The
work of KH and FG was supported by the
Academy of Finland, and of SVL by the Research
Foundation Flanders (FWO). YVdP and SVL ac-
knowledge the support from Ghent University
(Multidisciplinary Research Partnership Bioinfor-
matics: from nucleotides to networks).
33
References
Jari Bjo?rne and Tapio Salakoski. 2013. TEES 2.1: Au-
tomated annotation scheme learning in the BioNLP
2013 Shared Task. In Proceedings of BioNLP
Shared Task 2013 Workshop. In press.
Jari Bjo?rne, Filip Ginter, and Tapio Salakoski. 2012a.
Generalizing biomedical event extraction. BMC
Bioinformatics, 13(suppl. 8):S4.
Jari Bjo?rne, Filip Ginter, and Tapio Salakoski. 2012b.
University of Turku in the BioNLP?11 Shared Task.
BMC Bioinformatics, 13(Suppl 11):S4.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Advances in Kernel Methods -
Support Vector Learning.
Thorsten Joachims. 2006. Training linear SVMs in
linear time. In Proceedings of the ACM Conference
on Knowledge Discovery and Data Mining (KDD).
Suwisa Kaewphan, Sanna Kreula, Sofie Van Lan-
deghem, Yves Van de Peer, Patrik Jones, and Filip
Ginter. 2012. Integrating large-scale text mining
and co-expression networks: Targeting NADP(H)
metabolism in E. coli with event extraction. In Pro-
ceedings of the Third Workshop on Building and
Evaluating Resources for Biomedical Text Mining
(BioTxtM 2012).
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsu-
jii, Toshihisa Takagi, and Akinori Yonezawa. 2012.
The Genia event and protein coreference tasks of the
BioNLP Shared Task 2011. BMC Bioinformatics,
13(Suppl 11):S1.
Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: an executable survey of advances in biomedi-
cal named entity recognition. Pacific Symposium on
Biocomputing. Pacific Symposium on Biocomputing,
pages 652?663.
David McClosky, Sebastian Riedel, Mihai Surdeanu,
Andrew McCallum, and Christopher Manning.
2012. Combining joint models for biomedical event
extraction. BMC Bioinformatics, 13(Suppl 11):S9.
Makoto Miwa, Paul Thompson, and Sophia Ana-
niadou. 2012. Boosting automatic event ex-
traction from the literature using domain adapta-
tion and coreference resolution. Bioinformatics,
28(13):1759?1765.
Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,
and Tapio Salakoski. 2011. EVEX: a PubMed-scale
resource for homology-based generalization of text
mining predictions. In Proceedings of the BioNLP
2011 Workshop, pages 28?37.
Sofie Van Landeghem, Jari Bjo?rne, Chih-Hsuan Wei,
Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,
Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, Yves
Van de Peer, and Filip Ginter. 2013a. Large-
scale event extraction from literature with multi-
level gene normalization. PLoS ONE, 8(4):e55814.
Sofie Van Landeghem, Stefanie De Bodt, Zuzanna J.
Drebert, Dirk Inze?, and Yves Van de Peer. 2013b.
The potential of text mining in data integration and
network biology for plant research: A case study on
Arabidopsis. The Plant Cell, 25(3):794?807.
Andreas Vlachos and Mark Craven. 2012. Biomedical
event extraction from abstracts and full papers using
search-based structured prediction. BMC Bioinfor-
matics, 13(Suppl 11):S5.
Chih-Hsuan Wei and Hung-Yu Kao. 2011. Cross-
species gene normalization by species inference.
BMC Bioinformatics, 12(Suppl 8):S5.
Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-
rao, Masayuki Asahara, and Yuji Matsumoto. 2011.
Coreference based event-argument relation extrac-
tion on biomedical text. Journal of Biomedical Se-
mantics, 2(Suppl 5):S6.
34
