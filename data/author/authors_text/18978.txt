Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1224?1234,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Exploiting Multiple Sources for Open-domain Hypernym Discovery
Ruiji Fu, Bing Qin, Ting Liu?
Research Center for Social Computing and Information Retrieval
School of Computer Science and Technology
Harbin Institute of Technology, China
{rjfu, bqin, tliu}@ir.hit.edu.cn
Abstract
Hypernym discovery aims to extract such
noun pairs that one noun is a hypernym of
the other. Most previous methods are based
on lexical patterns but perform badly on open-
domain data. Other work extracts hypernym
relations from encyclopedias but has limited
coverage. This paper proposes a simple yet ef-
fective distant supervision framework for Chi-
nese open-domain hypernym discovery. Giv-
en an entity name, we try to discover its hy-
pernyms by leveraging knowledge from mul-
tiple sources, i.e., search engine results, ency-
clopedias, and morphology of the entity name.
First, we extract candidate hypernyms from
the above sources. Then, we apply a statistical
ranking model to select correct hypernyms. A
set of novel features is proposed for the rank-
ing model. We also present a heuristic strate-
gy to build a large-scale noisy training data for
the model without human annotation. Exper-
imental results demonstrate that our approach
outperforms the state-of-the-art methods on a
manually labeled test dataset.
1 Introduction
Hypernym discovery is a task to extract such noun
pairs that one noun is a hypernym of the other (S-
now et al, 2005). A noun H is a hypernym of an-
other noun E if E is an instance or subclass of H. In
other word, H is a semantic class of E. For instance,
?actor? is a hypernym of ?Mel Gibson?; ?dog? is a
hypernym of ?Caucasian sheepdog?; ?medicine? is
a hypernym of ?Aspirin?. Hypernym discovery is
an important subtask of semantic relation extraction
?Email correspondence.
and has many applications in ontology construction
(Suchanek et al, 2008), machine reading (Etzion-
i et al, 2006), question answering (McNamee et al,
2008), and so on.
Some manually constructed thesauri such as
WordNet can also provide some semantic relations
such as hypernyms. However, these thesauri are lim-
ited in its scope and domain, and manual construc-
tion is knowledge-intensive and time-consuming.
Therefore, many researchers try to automatically ex-
tract semantic relations or to construct taxonomies.
Most previous methods on automatic hypernym
discovery are based on lexical patterns and suffer
from the problem that such patterns can only cov-
er a small part of complex linguistic circumstances
(Hearst, 1992; Turney et al, 2003; Zhang et al,
2011). Other work tries to extract hypernym rela-
tions from large-scale encyclopedias like Wikipedia
and achieves high precision (Suchanek et al, 2008;
Hoffart et al, 2012). However, the coverage is limit-
ed since there exist many infrequent and new entities
that are missing in encyclopedias (Lin et al, 2012).
We made similar observation that more than a half
of entities in our data set have no entries in the en-
cyclopedias.
This paper proposes a simple yet effective distan-
t supervision framework for Chinese open-domain
hypernym discovery. Given an entity name, our goal
is to discover its hypernyms by leveraging knowl-
edge from multiple sources. Considering the case
where a person wants to know the meaning of an un-
known entity, he/she may search it in a search engine
and then finds out the answer after going through the
search results. Furthermore, if he/she finds an en-
try about the entity in an authentic web site, such as
Wikipedia, the information will help him/her under-
1224
stand the entity. Also, the morphology of the enti-
ty name can provide supplementary information. In
this paper, we imitate the process. The evidences
from the above sources are integrated in our hyper-
nym discovery model.
Our approach is composed of two major steps:
hypernym candidate extraction and ranking. In the
first step, we collect hypernym candidates from mul-
tiple sources. Given an entity name, we search it in
a search engine and extract high-frequency nouns as
its main candidate hypernyms from the search re-
sults. We also collect the category tags for the entity
from two Chinese encyclopedias and the head word
of the entity as the candidates.
In the second step, we identify correct hypernyms
from the candidates. We view this task as a rank-
ing problem and propose a set of effective features
to build a statistical ranking model. For the param-
eter learning of the model, we also present a heuris-
tic strategy to build a large-scale noisy training data
without human annotation.
Our contributions are as follows:
? We are the first to discover hypernym for Chi-
nese open-domain entities by exploiting mul-
tiple sources. The evidences from different
sources can authenticate and complement each
other to improve both precision and recall.
? We manually annotate a dataset containing
1,879 Chinese entities and their hypernyms,
which will be made publicly available. To the
best of our knowledge, this is the first dataset
for Chinese hypernyms.
? We propose a set of novel and effective fea-
tures for hypernym ranking. Experimental re-
sults show that our method achieves the best
performance.
Furthermore, our approach can be easily ported
from Chinese to English and other languages, except
that a few language dependent features need to be
changed.
The remainder of the paper is organized as fol-
lows: Section 2 discusses the related work. Section
3 introduces our method in detail. Section 4 de-
scribes the experimental setup. Section 5 shows the
experimental results. Conclusion and future work
are presented in Section 6.
2 Related Work
Previous methods for hypernym discovery can be
summarized into two major categories, i.e., pattern-
based methods and encyclopedia-based methods.
Pattern-based methods make use of manually
or automatically constructed patterns to mine hyper-
nym relations from text corpora. The pioneer work
by Hearst (1992) finds that linking two noun phras-
es (NPs) via certain lexical constructions often im-
plies hypernym relations. For example, NP1 is a hy-
pernym of NP2 in the lexical pattern ?such NP1 as
NP2?. Similarly, succeeding researchers follow her
work and use handcrafted patterns to extract hyper-
nym pairs from corpora (Caraballo, 1999; Scott and
Dominic, 2003; Ciaramita and Johnson, 2003; Tur-
ney et al, 2003; Pasca, 2004; Etzioni et al, 2005;
Ritter et al, 2009; Zhang et al, 2011).
Evans (2004) considers the web data as a large
corpus and uses search engines to identify hyper-
nyms based on lexical patterns. Given an arbitrary
document, he takes each capitalized word sequence
as an entity and aims to find its potential hypernyms
through pattern-based web searching. Suppose X is
a capitalized word sequence. Some pattern queries
like ?such as X? are threw into the search engine.
Then, in the retrieved documents, the nouns that im-
mediately precede the pattern are recognized as the
hypernyms of X. This work is most related to ours.
However, the patterns used in his work are too strict
to cover many low-frequency entities, and our ex-
periments show the weakness of the method.
Snow et al (2005) for the first time propose to au-
tomatically extract large numbers of lexico-syntactic
patterns and then detect hypernym relations from
a large newswire corpus. First, they use some
known hypernym-hyponym pairs from WordNet as
seeds and collect many patterns from a syntactical-
ly parsed corpus in a bootstrapping way. Then, they
consider all noun pairs in the same sentence as po-
tential hypernym-hyponym pairs and use a statistical
classifier to recognize the correct ones. All patterns
corresponding to the noun pairs in the corpus are
fed into the classifier as features. Their method re-
lies on accurate syntactic parsers and it is difficult to
guarantee the quality of the automatically extracted
patterns. Our experiments show that their method is
inferior to ours.
1225
Encyclopedia-based methods extract hyper-
nym relations from encyclopedias like Wikipedia
(Suchanek et al, 2008; Hoffart et al, 2012). The
user-labeled information in encyclopedias, such as
category tags in Wikipedia, is often used to derive
hypernym relations.
In the construction of the famous ontology YA-
GO, Suchanek et al (2008) consider the title of each
Wikipedia page as an entity and the corresponding
category tags as its potential hypernyms. They ap-
ply a shallow semantic parser and some rules to dis-
tinguish the correct hypernyms. Heuristically, they
find that if the head of the category tag is a plural
word, the tag is most likely to be a correct hyper-
nym. However, this method cannot be used in Chi-
nese because of the lack of plurality information.
The method of Suchanek et al (2008) cannot han-
dle the case when the entity is absent in Wikipedia.
To solve this problem, Lin et al (2012) connect the
absent entities with the entities present in Wikipedia
sharing common contexts. They utilize the Freebase
semantic types to label the present entities and then
propagate the types to the absent entities. The Free-
base contains most of entities in Wikipedia and as-
signs them semantic types defined in advance. But
there are no such resources in Chinese.
Compared with previous work, our approach tries
to identify hypernyms from multiple sources. The
evidences from different sources can authenticate
and complement each other to improve both preci-
sion and recall. Our experimental results show the
effectiveness of our method.
3 Method
Our method is composed of two steps. First, we col-
lect candidate hypernyms from multiple sources for
a given entity. Then, a statistical model is built for
hypernym ranking based on a set of effective fea-
tures. Besides, we also present a heuristic strategy
to build a large-scale training data.
3.1 Candidate Hypernym Collection from
Multiple Sources
In this work, we collect potential hypernyms from
four sources, i.e., search engine results, two ency-
clopedias, and morphology of the entity name.
We count the co-occurrence frequency between
the target entities and other words in the returned
snippets and titles, and select top N nouns (or noun
phrases) as the main candidates. As the experiments
show, this method can find at least one hypernym
for 86.91% entities when N equals 10 (see Section
5.1). This roughly explains why people often can in-
fer semantic meaning of unknown entities after go-
ing through several search results.
Furthermore, the user-generated encyclopedia
category tags are important clues if the entity exist-
s in a encyclopedia. Thus we add these tags into
the candidates. In this work, we consider two Chi-
nese encyclopedias, Baidubaike and Hudongbaike1,
as hypernym sources.
In addition, the head words of entities are also
their hypernyms sometimes. For example, the head
word of ??2? (Emperor Penguin)? indicates
that it?s a kind of ?? (penguins)?. Thus we put
head words into the hypernym candidates. In Chi-
nese, head words are often laid after their modifiers.
Therefore, we try to segment a given entity. If it can
be segmented and the last word is a noun, we take
the last word as the head word. In our data set, the
head words of 41.35% entities are real hypernyms
(see Section 5.1).
We combine all of these hypernym candidates to-
gether as the input of the second stage. The final
coverage rate reaches 93.24%.
3.2 Hypernym Ranking
After getting the candidate hypernyms, we then
adopt a ranking model to determine the correct hy-
pernym. In this section, we propose several effective
features for the model. The model needs training da-
ta for learning how to rank the data in addition to
parameter setting. Considering that manually anno-
tating a large-scale hypernym dataset is costly and
time-consuming, we present a heuristic strategy to
collect training data. We compare three hypernym
ranking models on this data set, including Support
Vector Machine (SVM) with a linear kernel, SVM
with a radial basis function (RBF) kernel and Logis-
tic Regression (LR).
1Baidubaike (http://baike.baidu.com) and
Hudongbaike (http://www.baike.com) are two largest
Chinese encyclopedias containing more than 6.26 million and
7.87 million entries respectively, while Chinese Wikipedia
contains about 0.72 million entries until September, 2013.
1226
Feature Comment Value Range
Prior the prior probability of a candidate being a potential hypernym [0, 1]
Is Tag
whether a candidate is a category tag in the encyclopedia
page of the entity if it exists
0 or 1
Is Head whether a candidate is the head word of the entity 0 or 1
In Titles
some binary features based on the frequency of occurrence of
a candidate in the document titles in the search results
0 or 1
Synonyms
the ratio of the synonyms of the candidate in the candidate
list of the entity
[0, 1]
Radicals
the ratio of the radicals of characters in a candidate matched
with the last character of the entity
[0, 1]
Source Num the number of sources where the candidate is extracted 1, 2, 3, or 4
Lexicon the hypernym candidate itself and its head word 0 or 1
Table 1: The features for ranking
3.2.1 Features for Ranking
The features for hypernym ranking are shown in
Table 1. We illustrate them in detail in the following.
Hypernym Prior: Intuitively, different words
have different probabilities as hypernyms of some
other words. Some are more probable as hypernyms,
such as animal, plant and fruit. Some other words
such as sun, nature and alias, are not usually used
as hypernyms. Thus we use a prior probability to
express this phenomenon. The assumption is that if
the more frequent that a noun appears as category
tags, the more likely it is a hypernym. We extract
category tags from 2.4 million pages in Baidubaike,
and compute the prior probabilities prior(w) for a
word w being a potential hypernym using Equation
1. countCT (w) denotes the times a word appeared
as a category tag in the encyclopedia pages.
prior(w) =
countCT (w)
?
w? countCT (w
?)
(1)
In Titles: When we enter a query into a search
engine, the engine returns a search result list, which
contains document titles and their snippet text. The
distributions of hypernyms and non-hypernyms in ti-
tles are compared with that in snippets respectively
in our training data. We discover that the average
frequency of occurrence of hypernyms in titles is
15.60 while this number of non-hypernyms is only
5.18, while the difference in snippets is very small
(Table 2). Thus the frequency of candidates in titles
can be used as features. In this work the frequency
Avg. Frequency in
titles snippets
Hypernym 15.60 33.69
Non-Hypernym 5.18 30.61
Table 2: Distributions of candidate hypernyms in titles
and snippets
is divided into three cases: greater than 15.60, less
than 5.18, and between 5.18 and 15.60. Three binary
features are used to represent these cases.
Synonyms: If there exist synonyms of a candi-
date hypernym in the candidate list, the candidate is
probably correct answer. For example, when ???
(medicine)? and ??? (medicine)? both appear in
the candidate list of an entity, the entity is probably
a kind of medicine. We get synonyms of a candidate
from a Chinese semantic thesaurus ? Tongyi Cilin
(Extended) (CilinE for short)2 and compute the s-
core as a feature using Equation 2.
ratiosyn(h, le) =
countsyn(h, le)
len(le)
(2)
Given a hypernym candidate h of an entity e and
the list of all candidates le, we compute the ratio of
the synonyms of h in le. countsyn(h, le) denotes the
count of the synonyms of h in le. len(le) is the total
count of candidates.
2CilinE contains synonym and hypernym relations among
77 thousand words, which is manually organized as a hierarchy
of five levels.
1227
Radicals: Chinese characters are a form of
ideogram. By far, the bulk of Chinese characters
were created by linking together a character with a
related meaning and another character to indicate its
pronunciation. The character with a related meaning
is called radical. Sometimes, it is a important clue to
indicate the semantic class of the whole character.
For example, the radical ??? means insects, so it
hints ?|n (dragonfly)? is a kind of insects. Simi-
larly ??? hints ?nJ (lymphoma)? is a kind of
diseases. Thus we use radicals as a feature the value
of which is computed by using Equation 3.
radical(e, h) =
countRM (e, h)
len(h)
(3)
Here radical(e, h) denotes the ratio of characters
radical-matched with the last character of the entity
e in the hypernym h. countRM (e, h) denotes the
count of the radical-matched characters in h. len(h)
denotes the total count of the characters in h.
3.2.2 Training Data Collection
Now training data is imperative to learn the
weights of the features in Section 3.2.1. Hence, we
propose a heuristic strategy to collect training data
from encyclopedias.
Firstly, we extract a number of open-domain enti-
ties from encyclopedias randomly. Then their hyper-
nym candidates are collected by using the method
proposed in Section 3.1. We select positive training
instances following two principles:
? Principle 1: Among the four sources used for
candidate collection, the more sources from
which the hypernym candidate is extracted, the
more likely it is a correct one.
? Principle 2: The higher the prior of the candi-
date being a hypernym is, the more likely it is a
correct one.
We select the best candidates following Principle
1 and then select the best one in them as a positive
instance following Principle 2. And we select a can-
didate as a negative training instance when it is from
only one source and its prior is the lowest. If there
are synonyms of training instances in the candidates
list, the synonyms are also extended into the training
set.
Domain
# of entities
Dev. Test
Biology 72 351
Health Care 61 291
Food 75 303
Movie 51 204
Industry 56 224
Others 35 136
Total 350 1529
Table 3: The evaluation data
In this way, we collect training data automatically,
which are used to learn the feature weights of the
ranking models.
4 Experimental Setup
In this work, we use Baidu3 search engine, the most
popular search engine for Chinese, and get the top
100 search results for each entity. The Chinese seg-
mentation, POS tagging and dependency parsing is
provided by an open-source Chinese language pro-
cessing platform LTP4 (Che et al, 2010).
4.1 Experimental Data
In our experiments, we prepare open-domain enti-
ties from dictionaries in wide domains, which are
published by a Chinese input method editor soft-
ware Sogou Pinyin5. The domains include biology,
health care, food, movie, industry, and so on. We
sample 1,879 entities from these domain dictionaries
and randomly split them into 1/5 for developmen-
t and 4/5 for test (Table 3). We find that only 865
(46.04%) entities exist in Baidubaike or Hudong-
baike. Then we extract candidate hypernyms for the
entities and ask two annotators to judge each hyper-
nym relation pair true or false manually. A pair (E,
H) is annotated as true if the annotators judge ?E is a
(or a kind of) H? is true. Finally, we get 12.53 candi-
date hypernyms for each entity on average in which
about 2.09 hypernyms are correct. 4,330 hypernym
relation pairs are judged by both the annotators. We
measure the agreement of the judges using the Kap-
pa coefficient (Siegel and Castellan Jr, 1988). The
3http://www.baidu.com
4http://ir.hit.edu.cn/demo/ltp/
5http://pinyin.sogou.com/dict/
1228
0 5 10 15 20
0.2
0.4
0.6
0.8
1.0
Top N
Cove
rage 
Rate
SRNSRN + ET+HW
Figure 1: Effect of candidate hypernym coverage rate
while varying N
Kappa value is 0.79.
Our training data, containing 11,481 positive in-
stances and 18,378 negative ones, is extracted from
Baidubaike and Hudongbaike using the heuristic s-
trategy proposed in Section 3.2.2.
4.2 Experimental Metrics
The evaluation metrics for our task include:
Coverage Rate: We evaluate coverage rate of the
candidate hypernyms. Coverage rate is the number
of entities for which at least one correct hypernym is
found divided by the total number of all entities.
Precision@1: Our method returns a ranked list
of hypernyms for each entity. We evaluate precision
of top-1 hypernyms (the most probable ones) in the
ranked lists, which is the number of correct top-1
hypernyms divided by the number of all entities.
R-precision: It is equivalent to Precision@R
where R is the total number of candidates labeled
as true hypernyms of an entity.
Precision, Recall, and F-score: Besides, we can
convert our ranking models to classification models
by setting thresholds. Varying the thresholds, we can
get different precisions, recalls, and F-scores.
5 Results and Analysis
5.1 The Coverage of Candidate Hypernyms
In this section, we evaluate the coverage rate of the
candidate hypernyms. We check the candidate hy-
pernyms of the whole 1,879 entities in the develop-
ment and test sets and see how many entities we can
collect at least one correct hypernym for.
Source
Coverage
Rate
Avg. #
SR10 0.8691 9.44?
ET 0.3938 3.07
HW 0.4135 0.87?
SR10 + ET 0.8909 12.02
SR10 + HW 0.9117 9.75
ET + HW 0.7073 3.92
SR10 + ET + HW 0.9324 12.53
Table 4: Coverage evaluation of the candidate hypernym
extraction
There are four different sources to collect candi-
dates as described in Section 3.1, which can be di-
vided into three kinds: search results (SR for short),
encyclopedia tags (ET) and head words (HW). For
SR, we select top N frequent nouns (SRN ) in the
search results of an entity as its hypernym candi-
dates. The effect of coverage rate while varying N
is shown in Figure 1. As we can see from the fig-
ure, the coverage rate is improved significantly by
increasing N until N reaches 10. After that, the
improvement becomes slight. When the candidates
from all sources are merged, the coverage rate is fur-
ther improved.
Thus we set N as 10 in the remaining experi-
ments. The detail evaluation is shown in Table 4.
We can see that top 10 frequent nouns in the search
results contain at least one correct hypernym for
86.91% entities in our data set. This coincides with
the intuition that people usually can infer the seman-
tic classes of unknown entities by searching them in
web search engines.
The coverage rate of ET merely reaches 39.38%.
We find the reason is that more than half of the enti-
ties have no encyclopedia pages. The average num-
ber of candidate hypernyms from ET is 3.07. Note
that the number is calculated among all the enti-
ties. We also calculate the average number only for
the present entities in encyclopedias. The number
reaches 6.68. The reason is that for many present en-
tities, the category tags include not only hypernyms
?For some of entities are rare, there may be less than 10
nouns in the search results. So the average count of candidates
is less than 10.
?Not all of the entities can be segmented. We cannot get the
head words of the ones that cannot be segmented.
1229
Method
Present Entities Absent Entities All Entities
P@1 R-Prec P@1 R-Prec P@1 R-Prec
MPattern 0.5542 0.4937 0.4306 0.3638 0.5229 0.4608
MSnow 0.3199 0.2592 0.2827 0.2610 0.3092 0.2597
MPrior 0.7339 0.5483 0.3940 0.3531 0.5494 0.4423
MSVM?linear 0.8569 0.6899 0.6157 0.5837 0.7260 0.6322
MSVM?rbf 0.8484 0.6940 0.6241 0.5901 0.7266 0.6376
MLR 0.8612 0.7052 0.6807 0.6258 0.7632 0.6621
Table 5: Precision@1 and R-Precision results on the test set. Here the present entities mean the entities existing in the
encyclopedias. The absent entities mean the ones not existing in the encyclopedias.
but also related words. For example, ??.|?
% (Bradley Center)? in Baidubaike have 5 tags, i.e.,
?NBA?, ?N? (sports)?, ?N?$? (sports)?, ?;
? (basketball)?, and ?|, (arena)?. Among them,
only ?|, (arena)? is a proper hypernym whereas
the others are some related words indicating mere-
ly thematic vicinity. Comparing the results of SR10
and SR10 + ET, we can see that collecting candidates
from ET can improve coverage, although many in-
correct candidates are added in at the same time.
The HW source provides 0.87 candidates on av-
erage with 41.35% coverage rate. That is to say, for
these entities, people can infer the semantic classes
when they see the surface lexicon.
At last, we combine the candidates from all of the
three sources as the input of the ranking methods.
The coverage rate reaches 93.24%.
We also compare with the manually construct-
ed semantic thesaurus CilinE mentioned in Section
3.2.1. Only 29 entities exist in CilinE (coverage rate
is only 1.54%). That is why we try to automatically
extract hypernym relations.
5.2 Evaluation of the Ranking
5.2.1 Overall Performance Comparison
In this section, we compare our proposed methods
with other methods. Table 5 lists the performance
measured by precision at rank 1 and R-precision of
some key methods. The precision-recall curves of
all the methods are shown in Figure 2. Table 7 lists
the maximum F-scores.
MPattern refers to the pattern-based method of
Hearst (1992). We craft Chinese Hearst-style
patterns (Table 6), in which E represents an entity
and H represents one of its hypernyms. Following
Pattern Translation
E?(??/??) H E is a (a kind of) H
E (!) H E(,) and other H
H (?)(?) E H(,) called E
H (?)(?)X E H(,) such as E
H (?)AO? E H(,) especially E
Table 6: Chinese Hearst-style lexical patterns
Evans (2004), we combine each pattern and each en-
tity and submit them into the Baidu search engine.
For example, for an entity E, we search ?E ??
? (E is a)?, ?E  (E and other)?, and so on. We
select top 100 search results of each query and get
1,285,209 results in all for the entities in the test set.
Then we use the patterns to extract hypernyms from
the search results. The result shows that 508 cor-
rect hypernyms are extracted for 568 entities (1,529
entities in total). Only a small part of the entities
can be extracted hypernyms for. This is mainly be-
cause only a few hypernym relations are expressed
in these fixed patterns in the web, and many ones are
expressed in more flexible manners. The hypernyms
are ranked based on the count of evidences where
the hypernyms are extracted.
MSnow is the method originally proposed by S-
now et al (2005) for English but we adapt it for Chi-
nese. We consider the top 100 search results for each
known hypernym-hyponym pairs as a corpus to ex-
tract lexico-syntactic patterns. Then, an LR classi-
fier is built based on this patterns to recognize hy-
pernym relations. This method considers all noun-
s co-occurred with the focused entity in the same
sentences as candidate hypernyms. So the number
of candidates is huge, which causes inefficiency. In
1230
0.0 0.2 0.4 0.6 0.8 1.0
0.0
0.2
0.4
0.6
0.8
1.0
Precision?Recall Curves on the Test Set
Recall
Prec
ision
l l l l llll l llll ll l l l l ll l l ll ll lll ll llllll
l
MSnowMPriorMSVM?l inearMSVM?rbfMLRMPatternMHeurist ic
Figure 2: Precision-Recall curves on the test set
our corpus, there are 652,181 candidates for 1,529
entities (426.54 for each entity on average), most of
which are not hypernyms. One possible reason is
that this method relies on an accurate syntactic pars-
er and it is difficult to guarantee the quality of the
automatically extracted patterns. Even worse, the
low quality of the language in the search results may
make this problem more serious.
MPrior refers to the ranking method based on on-
ly the prior of a candidate being a hypernym. As
Table 5 shows, it outperforms MSnow and achieves
comparable results with MPattern on Precision@1
and R-Precision.
Based on the features proposed in Section 3.2.1,
we train several statistical models based on SVM
and LR on the training data. MSVM?linear and
MSVM?rbf refer to the SVM models based on linear
kernels and RBF kernels respectively. MLR refers
to the LR model. The probabilities6 output by the
models are used to rank the candidate hypernyms.
All of the parameters which need to be set in the
models are selected on the development set. Table
5 shows the best models based on each algorithm.
These supervised models outperform the previous
methods. MLR achieves the best performance.
The precision-recall plot of the methods on the
test set is presented in Figure 2. MHeuristic refers
to the heuristic approach, proposed in Section 3.2.2,
to collect training data. Because this method cannot
6The output of an SVM is the distance from the decision
hyper-plane. Sigmoid functions can be used to convert this un-
calibrated distance into a calibrated posterior probability (Platt,
1999).
Method Max. F-score
MPattern 0.2061
MSnow 0.1514
MHeuristic 0.2803
MPrior 0.5591
MSVM?linear 0.5868
MSVM?rbf 0.6014
MLR 0.5998
Table 7: Summary of maximum F-score on the test set
Feature P@1 R-Prec
Max.
F-score
All 0.7632 0.6621 0.5998
? Prior 0.7534 0.6546 0.5837
? Is Tag 0.6965 0.6039 0.5605
? Is Head 0.7018 0.6036 0.5694
? In Titles 0.7436 0.6513 0.5868
? Synonyms 0.7495 0.6493 0.5831
? Radicals 0.7593 0.6584 0.5890
? Source Num 0.7364 0.6556 0.5984
? Lexicon 0.7377 0.6422 0.5851
? Source Info 0.6128 0.5221 0.5459
Table 8: Performance of LR models with different fea-
tures on the test set
provide ranking information, it is not listed in Ta-
ble 5. For fair comparison of R-precision and recall,
we add the extra correct hypernyms from MPattern
and MSnow to the test data set. The models based
on SVM and LR still perform better than the other
methods. MPattern and MSnow suffer from low re-
call and precision. MHeuristic get a high precision
but a low recall, because it can only deal with a part
of entities appearing in encyclopedias. The preci-
sion of MHeuristic reflects the quality of our training
data. We summarize the maximum F-score of dif-
ferent methods in Table 7.
5.2.2 Feature Effect
Table 8 shows the impact of each feature on the
performance of LR models. When we remove any
one of the features, the performance is degraded
more or less. The most effective features are Is Tag
and Is Head. The last line in Table 8 shows the
performance when we remove all features about
the source information, i.e., Is Tag, Is Head, and
1231
Entity
Top-1
Hypernym
Entity
Top-1
Hypernym
??b??(cefoperazone sodium) ??(drug) ?y(bullet tuna) ~a(fish)
???(finger citron rolls) ?(snack) =?(zirconite) ??(ore)
E????(The Avengers) >K(movie) ?|?d?(Felixstowe) l?(port)
@U=(mastigium) ?O(datum) ?!?(coxal cavity) ??(plant)
?UX?=?s
(Ethanolamine phosphotransferase)
)?
(organism)
?u
(coma)
?
(knowledge)
Table 10: Examples of entity-hypernym pairs extracted by MLR
Domain P@1 R-Prec
Max.
F-score
Biology 0.8165 0.7203 0.6424
Health Care 0.7354 0.5962 0.6061
Food 0.7450 0.6634 0.6938
Movie 0.9310 0.8069 0.7031
Industry 0.6286 0.5841 0.4624
Others 0.6324 0.4936 0.4318
Table 9: Performance of MLR in various domains
Source Num. The performance is degraded sharply.
This indicates the importance of the source informa-
tion for hypernym ranking.
5.2.3 The Performance in Each Domain
In this section, we evaluate the performance of
MLR method in various domains. We can see from
Table 9 that the performance in movie domain is best
while the performance in industry domain is worst.
That is because the information about movies is
abundant on the web. Furthermore, most of movies
have encyclopedia pages. It is easy to get the hy-
pernyms. In contrast, the entities in industry domain
are more uncommon. On the whole, our method is
robust for different domains. In Table 10, some in-
stances in various domains are presented.
5.3 Error Analysis
The uncovered entities7 and the false positives8 are
analyzed after the experiments. Some error exam-
ples are shown in Table 10 (in red font).
7Uncovered entities are entities which we do not collect any
correct hypernyms for in the first step.
8False positives are hypernyms ranked at the first places, but
actually are not correct hypernyms.
Uncovered entities: About 34% of the errors are
caused by uncovered entities. It is found that many
of the uncovered entities are rare entities. Nearly
36% of them are very rare and have only less than
100 search results in all. When we can?t get enough
information of an unknown entity from the search
engine, it?s difficult to know its semantic meaning,
such as ?@U= (mastigium)?, ??!? (coxal cav-
ity)?, ??u (coma)?. The identification of their hy-
pernyms requires more human-crafted knowledge.
The ranking models we used are unable to select
them, as the true synonyms are often below rank 10.
False positives: The remained 66% errors are
false positives. They are mainly owing to the
fact that some other related words in the candi-
date lists are more likely hypernyms. For exam-
ple, ?)? (organism)? is wrongly recognized as
the most probable hypernym of ??UX?=
?s (Ethanolamine phosphotransferase)?, because
the entity often co-occurs with word ?)? (organ-
ism)? and the latter is often used as a hypernym of
some other entities. The correct hypernyms actu-
ally are ?s (enzyme)?, ?z??? (chemical sub-
stance)?, and so on.
6 Conclusion
This paper proposes a novel method for finding
hypernyms of Chinese open-domain entities from
multiple sources. We collect candidate hypernyms
with wide coverage from search results, encyclope-
dia category tags and the head word of the entity.
Then, we propose a set of features to build statisti-
cal models to rank the candidate hypernyms on the
training data collected automatically. In our exper-
iments, we show that our method outperforms the
state-of-the-art methods and achieves the best preci-
1232
sion of 76.32% on a manually labeled test dataset.
All of the features which we propose are effective,
especially the features of source information. More-
over, our method works well in various domains, e-
specially in the movie and biology domains. We al-
so conduct detailed analysis to give more insights
on the error distribution. Except some language de-
pendent features, our approach can be easily trans-
fered from Chinese to other languages. For future
work, we would like to explore knowledge from
more sources to enhance our model, such as seman-
tic thesauri and infoboxes in encyclopedias.
Acknowledgments
This work was supported by National Natu-
ral Science Foundation of China (NSFC) via
grant 61133012, 61073126 and the National 863
Leading Technology Research Project via grant
2012AA011102. Special thanks to Zhenghua Li,
Wanxiang Che, Wei Song, Yanyan Zhao, Yuhang
Guo and the anonymous reviewers for insightful
comments and suggestions. Thanks are also due to
our annotators Ni Han and Zhenghua Li.
References
Sharon A. Caraballo. 1999. Automatic construction of a
hypernym-labeled noun hierarchy from text. In Pro-
ceedings of the 37th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 120?126,
College Park, Maryland, USA, June.
Wanxiang Che, Zhenghua Li, and Ting Liu. 2010. Ltp:
A chinese language technology platform. In Coling
2010: Demonstrations, pages 13?16, Beijing, China,
August.
Massimiliano Ciaramita and Mark Johnson. 2003. Su-
persense tagging of unknown nouns in wordnet. In
Proceedings of the 2003 conference on Empirical
methods in natural language processing, pages 168?
175.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S Weld, and Alexander Yates. 2005. Unsuper-
vised named-entity extraction from the web: An exper-
imental study. Artificial Intelligence, 165(1):91?134.
Oren Etzioni, Michele Banko, and Michael J Cafarella.
2006. Machine reading. In AAAI, volume 6, pages
1517?1519.
Richard Evans. 2004. A framework for named enti-
ty recognition in the open domain. Recent Advances
in Natural Language Processing III: Selected Papers
from RANLP 2003, 260:267?274.
Marti A Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of the
14th conference on Computational linguistics-Volume
2, pages 539?545.
Johannes Hoffart, Fabian M Suchanek, Klaus Berberich,
and Gerhard Weikum. 2012. Yago2: a spatially and
temporally enhanced knowledge base from wikipedia.
Artificial Intelligence, pages 1?63.
Thomas Lin, Mausam, and Oren Etzioni. 2012. No noun
phrase left behind: Detecting and typing unlinkable
entities. In Proceedings of the 2012 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 893?903, Jeju Island, Korea, July.
Paul McNamee, Rion Snow, Patrick Schone, and James
Mayfield. 2008. Learning named entity hyponyms
for question answering. In Proceedings of the Third
International Joint Conference on Natural Language
Processing, pages 799?804.
Marius Pasca. 2004. Acquisition of categorized named
entities for web search. In Proceedings of the thir-
teenth ACM international conference on Information
and knowledge management, pages 137?145.
John Platt. 1999. Probabilistic outputs for support vec-
tor machines and comparisons to regularized likeli-
hood methods. Advances in large margin classifiers,
10(3):61?74.
Alan Ritter, Stephen Soderland, and Oren Etzioni. 2009.
What is this, anyway: Automatic hypernym discovery.
In Proceedings of the 2009 AAAI Spring Symposium
on Learning by Reading and Learning to Read, pages
88?93.
Cederberg Scott and Widdows Dominic. 2003. Using lsa
and noun coordination information to improve the pre-
cision and recall of automatic hyponymy extraction. In
Proceedings of the seventh conference on Natural lan-
guage learning at HLT-NAACL 2003-Volume 4, pages
111?118.
Sidney Siegel and N John Castellan Jr. 1988. Nonpara-
metric statistics for the behavioral sciences. McGraw-
Hill, New York.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2005.
Learning syntactic patterns for automatic hypernym
discovery. In Lawrence K. Saul, Yair Weiss, and Le?on
Bottou, editors, Advances in Neural Information Pro-
cessing Systems 17, pages 1297?1304.
Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2008. Yago: A large ontology from
wikipedia and wordnet. Web Semantics: Science, Ser-
vices and Agents on the World Wide Web, 6(3):203?
217.
1233
Peter Turney, Michael L Littman, Jeffrey Bigham, and
Victor Shnayder. 2003. Combining independent mod-
ules to solve multiple-choice synonym and analogy
problems. In Proceedings of the International Con-
ference RANLP-2003, pages 482?489.
Fan Zhang, Shuming Shi, Jing Liu, Shuqi Sun, and Chin-
Yew Lin. 2011. Nonlinear evidence fusion and prop-
agation for hyponymy relation mining. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 1159?1168, Portland, Oregon, USA,
June.
1234
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1199?1209,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
Learning Semantic Hierarchies via Word Embeddings
Ruiji Fu
?
, Jiang Guo
?
, Bing Qin
?
, Wanxiang Che
?
, Haifeng Wang
?
, Ting Liu
??
?
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
?
Baidu Inc., Beijing, China
{rjfu, jguo, bqin, car, tliu}@ir.hit.edu.cn
wanghaifeng@baidu.com
Abstract
Semantic hierarchy construction aims to
build structures of concepts linked by
hypernym?hyponym (?is-a?) relations. A
major challenge for this task is the
automatic discovery of such relations.
This paper proposes a novel and effec-
tive method for the construction of se-
mantic hierarchies based on word em-
beddings, which can be used to mea-
sure the semantic relationship between
words. We identify whether a candidate
word pair has hypernym?hyponym rela-
tion by using the word-embedding-based
semantic projections between words and
their hypernyms. Our result, an F-score
of 73.74%, outperforms the state-of-the-
art methods on a manually labeled test
dataset. Moreover, combining our method
with a previous manually-built hierarchy
extension method can further improve F-
score to 80.29%.
1 Introduction
Semantic hierarchies are natural ways to orga-
nize knowledge. They are the main components
of ontologies or semantic thesauri (Miller, 1995;
Suchanek et al, 2008). In the WordNet hierar-
chy, senses are organized according to the ?is-a?
relations. For example, ?dog? and ?canine? are
connected by a directed edge. Here, ?canine? is
called a hypernym of ?dog.? Conversely, ?dog?
is a hyponym of ?canine.? As key sources
of knowledge, semantic thesauri and ontologies
can support many natural language processing
applications. However, these semantic resources
are limited in its scope and domain, and their
manual construction is knowledge intensive and
time consuming. Therefore, many researchers
?
Email correspondence.
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite ???medicinal plant
??medicine
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite
???medicinal plant
??medicine
Figure 1: An example of semantic hierarchy con-
struction.
have attempted to automatically extract semantic
relations or to construct taxonomies.
A major challenge for this task is the auto-
matic discovery of hypernym-hyponym relations.
Fu et al (2013) propose a distant supervision
method to extract hypernyms for entities from
multiple sources. The output of their model is
a list of hypernyms for a given enity (left pan-
el, Figure 1). However, there usually also exists
hypernym?hyponym relations among these hy-
pernyms. For instance, ??? (plant)? and
???? (Ranunculaceae)? are both hyper-
nyms of the entity ??? (aconit),? and ??
? (plant)? is also a hypernym of ????
(Ranunculaceae).? Given a list of hypernyms
of an entity, our goal in the present work is to
construct a semantic hierarchy of these hypernyms
(right panel, Figure 1).
1
Some previous works extend and refine
manually-built semantic hierarchies by using other
resources (e.g., Wikipedia) (Suchanek et al,
2008). However, the coverage is limited by the
scope of the resources. Several other works relied
heavily on lexical patterns, which would suffer
from deficiency because such patterns can only
cover a small proportion of complex linguistic cir-
cumstances (Hearst, 1992; Snow et al, 2005).
1
In this study, we focus on Chinese semantic hierarchy
construction. The proposed method can be easily adapted to
other languages.
1199
Besides, distributional similarity methods (Kotler-
man et al, 2010; Lenci and Benotto, 2012) are
based on the assumption that a term can only be
used in contexts where its hypernyms can be used
and that a term might be used in any contexts
where its hyponyms are used. However, it is not
always rational. Our previous method based on
web mining (Fu et al, 2013) works well for hy-
pernym extraction of entity names, but it is unsuit-
able for semantic hierarchy construction which in-
volves many words with broad semantics. More-
over, all of these methods do not use the word
semantics effectively.
This paper proposes a novel approach for se-
mantic hierarchy construction based on word em-
beddings. Word embeddings, also known as dis-
tributed word representations, typically represent
words with dense, low-dimensional and real-
valued vectors. Word embeddings have been
empirically shown to preserve linguistic regular-
ities, such as the semantic relationship between
words (Mikolov et al, 2013b). For example,
v(king) ? v(queen) ? v(man) ? v(woman),
where v(w) is the embedding of the word w. We
observe that a similar property also applies to the
hypernym?hyponym relationship (Section 3.3),
which is the main inspiration of the present study.
However, we further observe that hypernym?
hyponym relations are more complicated than a
single offset can represent. To address this chal-
lenge, we propose a more sophisticated and gen-
eral method ? learning a linear projection which
maps words to their hypernyms (Section 3.3.1).
Furthermore, we propose a piecewise linear pro-
jection method based on relation clustering to
better model hypernym?hyponym relations (Sec-
tion 3.3.2). Subsequently, we identify whether an
unknown word pair is a hypernym?hyponym re-
lation using the projections (Section 3.4). To the
best of our knowledge, we are the first to apply
word embeddings to this task.
For evaluation, we manually annotate a dataset
containing 418 Chinese entities and their hyper-
nym hierarchies, which is the first dataset for this
task as far as we know. The experimental results
show that our method achieves an F-score of
73.74% which significantly outperforms the pre-
vious state-of-the-art methods. Moreover, com-
bining our method with the manually-built hier-
archy extension method proposed by Suchanek et
al. (2008) can further improve F-score to 80.29%.
2 Background
As main components of ontologies, semantic hi-
erarchies have been studied by many researchers.
Some have established concept hierarchies based
on manually-built semantic resources such as
WordNet (Miller, 1995). Such hierarchies have
good structures and high accuracy, but their cov-
erage is limited to fine-grained concepts (e.g.,
?Ranunculaceae? is not included in Word-
Net.). We have made similar obsevation that about
a half of hypernym?hyponym relations are absent
in a Chinese semantic thesaurus. Therefore, a
broader range of resources is needed to supple-
ment the manually built resources. In the construc-
tion of the famous ontology YAGO, Suchanek et
al. (2008) link the categories in Wikipedia onto
WordNet. However, the coverage is still limited
by the scope of Wikipedia.
Several other methods are based on lexical
patterns. They use manually or automatically
constructed lexical patterns to mine hypernym?
hyponym relations from text corpora. A hierarchy
can then be built based on these pairwise relations.
The pioneer work by Hearst (1992) has found
out that linking two noun phrases (NPs) via cer-
tain lexical constructions often implies hypernym
relations. For example, NP
1
is a hypernym of NP
2
in the lexical pattern ?such NP
1
as NP
2
.? Snow et
al. (2005) propose to automatically extract large
numbers of lexico-syntactic patterns and subse-
quently detect hypernym relations from a large
newswire corpus. Their method relies on accurate
syntactic parsers, and the quality of the automat-
ically extracted patterns is difficult to guarantee.
Generally speaking, these pattern-based methods
often suffer from low recall or precision because
of the coverage or the quality of the patterns.
The distributional methods assume that the con-
texts of hypernyms are broader than the ones of
their hyponyms. For distributional similarity com-
puting, each word is represented as a semantic
vector composed of the pointwise mutual infor-
mation (PMI) with its contexts. Kotlerman et al
(2010) design a directional distributional measure
to infer hypernym?hyponym relations based on
the standard IR Average Precision evaluation mea-
sure. Lenci and Benotto (2012) propose anoth-
er measure focusing on the contexts that hyper-
nyms do not share with their hyponyms. However,
broader semantics may not always infer broader
contexts. For example, for terms ?Obama? and
1200
?American people?, it is hard to say whose
contexts are broader.
Our previous work (Fu et al, 2013) applies a
web mining method to discover the hypernyms of
Chinese entities from multiple sources. We as-
sume that the hypernyms of an entity co-occur
with it frequently. It works well for named enti-
ties. But for class names (e.g., singers in Hong
Kong, tropical fruits) with wider range of mean-
ings, this assumption may fail.
In this paper, we aim to identify hypernym?
hyponym relations using word embeddings, which
have been shown to preserve good properties for
capturing semantic relationship between words.
3 Method
In this section, we first define the task formally.
Then we elaborate on our proposed method com-
posed of three major steps, namely, word embed-
ding training, projection learning, and hypernym?
hyponym relation identification.
3.1 Task Definition
Given a list of hypernyms of an entity, our goal is
to construct a semantic hierarchy on it (Figure 1).
We represent the hierarchy as a directed graph
G, in which the nodes denote the words, and the
edges denote the hypernym?hyponym relations.
Hypernym-hyponym relations are asymmetric and
transitive when words are unambiguous:
? ?x, y ? L : x
H
??y ? ?(y
H
??x)
? ?x, y, z ? L : (x
H
??z ? z
H
??y)? x
H
??y
Here, L denotes the list of hypernyms. x, y and
z denote the hypernyms in L. We use
H
?? to
represent a hypernym?hyponym relation in this
paper. Actually, x, y and z are unambiguous as
the hypernyms of a certain entity. Therefore, G
should be a directed acyclic graph (DAG).
3.2 Word Embedding Training
Various models for learning word embeddings
have been proposed, including neural net lan-
guage models (Bengio et al, 2003; Mnih and
Hinton, 2008; Mikolov et al, 2013b) and spec-
tral models (Dhillon et al, 2011). More recent-
ly, Mikolov et al (2013a) propose two log-linear
models, namely the Skip-gram and CBOW model,
to efficiently induce word embeddings. These two
models can be trained very efficiently on a large-
scale corpus because of their low time complexity.
No. Examples
1
v(?)? v(??) ? v(?)? v(??)
v(shrimp)? v(prawn) ? v(fish)? v(gold fish)
2
v(??)? v(??) ? v(??)? v(??)
v(laborer)? v(carpenter) ? v(actor)? v(clown)
3
v(??)? v(??) 6? v(?)? v(??)
v(laborer)? v(carpenter) 6? v(fish)? v(gold fish)
Table 1: Embedding offsets on a sample of
hypernym?hyponym word pairs.
Additionally, their experiment results have shown
that the Skip-gram model performs best in identi-
fying semantic relationship among words. There-
fore, we employ the Skip-gram model for estimat-
ing word embeddings in this study.
The Skip-gram model adopts log-linear classi-
fiers to predict context words given the current
word w(t) as input. First, w(t) is projected to its
embedding. Then, log-linear classifiers are em-
ployed, taking the embedding as input and pre-
dict w(t)?s context words within a certain range,
e.g. k words in the left and k words in the
right. After maximizing the log-likelihood over
the entire dataset using stochastic gradient descent
(SGD), the embeddings are learned.
3.3 Projection Learning
Mikolov et al (2013b) observe that word em-
beddings preserve interesting linguistic regulari-
ties, capturing a considerable amount of syntac-
tic/semantic relations. Looking at the well-known
example: v(king) ? v(queen) ? v(man) ?
v(woman), it indicates that the embedding offsets
indeed represent the shared semantic relation be-
tween the two word pairs.
We observe that the same property also ap-
plies to some hypernym?hyponym relations. As
a preliminary experiment, we compute the em-
bedding offsets between some randomly sampled
hypernym?hyponym word pairs and measure their
similarities. The results are shown in Table 1.
The first two examples imply that a word can
also be mapped to its hypernym by utilizing word
embedding offsets. However, the offset from
?carpenter? to ?laborer? is distant from
the one from ?gold fish? to ?fish,? indicat-
ing that hypernym?hyponym relations should be
more complicated than a single vector offset can
represent. To verify this hypothesis, we com-
pute the embedding offsets over all hypernym?
1201
???-????sportsman - footballer ??-???staff - civil servant??-??laborer - gardener??-???seaman - navigator??-??actor - singer ??-??actor - protagonist??-??actor - clown
??-??position - headmaster
??-???actor - matador
??-???laborer - temporary worker ??-??laborer - carpenter ??-???position ? consul general
??-??staff - airline hostess??-???staff - salesclerk??-???staff - conductor?-??chicken - cock?-????sheep - small-tail Han sheep?-??sheep - ram ?-??equus - zebra ?-??shrimp - prawn
?-??dog - police dog?-???rabbit - wool rabbit
??-???dolphin - white-flag dolphin ?-??fish - shark ?-???fish - tropical fish?-??fish - gold fish
?-??crab - sea crab
?-??donkey - wild ass
Figure 2: Clusters of the vector offsets in training data. The figure shows that the vector offsets distribute
in some clusters. The left cluster shows some hypernym?hyponym relations about animals. The right
one shows some relations about people?s occupations.
hyponym word pairs in our training data and vi-
sualize them.
2
Figure 2 shows that the relations
are adequately distributed in the clusters, which
implies that hypernym?hyponym relations in-
deed can be decomposed into more fine-grained
relations. Moreover, the relations about animals
are spatially close, but separate from the relations
about people?s occupations.
To address this challenge, we propose to learn
the hypernym?hyponym relations using projection
matrices.
3.3.1 A Uniform Linear Projection
Intuitively, we assume that all words can be pro-
jected to their hypernyms based on a uniform tran-
sition matrix. That is, given a word x and its hy-
pernym y, there exists a matrix ? so that y = ?x.
For simplicity, we use the same symbols as the
words to represent the embedding vectors. Ob-
taining a consistent exact ? for the projection of
all hypernym?hyponym pairs is difficult. Instead,
we can learn an approximate ? using Equation 1
on the training data, which minimizes the mean-
squared error:
?
?
= arg min
?
1
N
?
(x,y)
? ?x? y ?
2
(1)
where N is the number of (x, y) word pairs in
the training data. This is a typical linear regres-
sion problem. The only difference is that our pre-
dictions are multi-dimensional vectors instead of
scalar values. We use SGD for optimization.
2
Principal Component Analysis (PCA) is applied for di-
mensionality reduction.
3.3.2 Piecewise Linear Projections
A uniform linear projection may still be under-
representative for fitting all of the hypernym?
hyponym word pairs, because the relations are
rather diverse, as shown in Figure 2. To better
model the various kinds of hypernym?hyponym
relations, we apply the idea of piecewise linear re-
gression (Ritzema, 1994) in this study.
Specifically, the input space is first segmented
into several regions. That is, all word pairs (x, y)
in the training data are first clustered into sever-
al groups, where word pairs in each group are
expected to exhibit similar hypernym?hyponym
relations. Each word pair (x, y) is represented
with their vector offsets: y ? x for clustering.
The reasons are twofold: (1) Mikolov?s work has
shown that the vector offsets imply a certain lev-
el of semantic relationship. (2) The vector off-
sets distribute in clusters well, and the word pairs
which are close indeed represent similar relations,
as shown in Figure 2.
Then we learn a separate projection for each
cluster, respectively (Equation 2).
?
?
k
= arg min
?
k
1
N
k
?
(x,y)?C
k
? ?
k
x? y ?
2
(2)
where N
k
is the amount of word pairs in the k
th
cluster C
k
.
We use the k-means algorithm for clustering,
where k is tuned on a development dataset.
3.3.3 Training Data
To learn the projection matrices, we extract train-
ing data from a Chinese semantic thesaurus,
Tongyi Cilin (Extended) (CilinE for short) which
1202
?
?
?
?
?
Root
L ev el 1
L ev el 2
L ev el 3
L ev el 4
L ev el 5
?  ob j ect
??  animal
??  insect
- -
??  dragonf ly
B
i
18
A
06@
?? : ?? 
( dragonf ly  :  animal)
?? : ?? 
( dragonf ly  :  insect)
C ilinEh y perny m-h y pony m pairs
S ense C ode:  B i1 8 A0 6 @
S ense C ode:  B i1 8 A
S ense C ode:  B i1 8
S ense C ode:  B i
S ense C ode:  B
?? : ?? 
( insect :  animal)
Figure 3: Hierarchy of CilinE and an Example of
Training Data Generation
contains 100,093 words (Che et al, 2010).
3
CilinE
is organized as a hierarchy of five levels, in which
the words are linked by hypernym?hyponym
relations (right panel, Figure 3). Each word in
CilinE has one or more sense codes (some words
are polysemous) that indicate its position in the hi-
erarchy.
The senses of words in the first level, such as
?? (object)? and ??? (time),? are very gen-
eral. The fourth level only has sense codes without
real words. Therefore, we extract words in the sec-
ond, third and fifth levels to constitute hypernym?
hyponym pairs (left panel, Figure 3).
Note that mapping one hyponym to multi-
ple hypernyms with the same projection (?x is
unique) is difficult. Therefore, the pairs with the
same hyponym but different hypernyms are ex-
pected to be clustered into separate groups. Fig-
ure 3 shows that the word ?dragonfly? in the
fifth level has two hypernyms: ?insect? in the
third level and ?animal? in the second level.
Hence the relations dragonfly
H
?? insect and
dragonfly
H
?? animal should fall into differ-
ent clusters.
In our implementation, we apply this constraint
by simply dividing the training data into two cat-
egories, namely, direct and indirect. Hypernym-
hyponym word pair (x, y) is classified into the di-
rect category, only if there doesn?t exist another
word z in the training data, which is a hypernym of
x and a hyponym of y. Otherwise, (x, y) is classi-
fied into the indirect category. Then, data in these
two categories are clustered separately.
3
www.ltp-cloud.com/download/
x
y
?k
? 
x'
?l
Figure 4: In this example, ?
k
x is located in the
circle with center y and radius ?. So y is consid-
ered as a hypernym of x. Conversely, y is not a
hypernym of x
?
.
x
y
z
x
y
(a) (b)
z
x
y
Figure 5: (a) If d(?
j
y, x) > d(?
k
x, y), we re-
move the path from y to x; (b) if d(?
j
y, x) >
d(?
k
x, z) and d(?
j
y, x) > d(?
i
z, y), we reverse
the path from y to x.
3.4 Hypernym-hyponym Relation
Identification
Upon obtaining the clusters of training data and
the corresponding projections, we can identify
whether two words have a hypernym?hyponym re-
lation. Given two words x and y, we find cluster
C
k
whose center is closest to the offset y ? x, and
obtain the corresponding projection ?
k
. For y to
be considered a hypernym of x, one of the two
conditions below must hold.
Condition 1: The projection ?
k
puts ?
k
x close
enough to y (Figure 4). Formally, the euclidean
distance between ?
k
x and y: d(?
k
x, y) must be
less than a threshold ?.
d(?
k
x, y) =? ?
k
x? y ?
2
< ? (3)
Condition 2: There exists another word z sat-
isfying x
H
??z and z
H
??y. In this case, we use the
transitivity of hypernym?hyponym relations.
Besides, the final hierarchy should be a DAG
as discussed in Section 3.1. However, the pro-
jection method cannot guarantee that theoretical-
ly, because the projections are learned from pair-
wise hypernym?hyponym relations without the w-
hole hierarchy structure. All pairwise hypernym?
hyponym relation identification methods would
suffer from this problem actually. It is an inter-
esting problem how to construct a globally opti-
1203
mal semantic hierarchy conforming to the form
of a DAG. But this is not the focus of this paper.
So if some conflicts occur, that is, a relation cir-
cle exists, we remove or reverse the weakest path
heuristically (Figure 5). If a circle has only two
nodes, we remove the weakest path. If a circle has
more than two nodes, we reverse the weakest path
to form an indirect hypernym?hyponym relation.
4 Experimental Setup
4.1 Experimental Data
In this work, we learn word embeddings from a
Chinese encyclopedia corpus named Baidubaike
4
,
which contains about 30 million sentences (about
780 million words). The Chinese segmentation
is provided by the open-source Chinese language
processing platform LTP
5
(Che et al, 2010).
Then, we employ the Skip-gram method (Section
3.2) to train word embeddings. Finally we obtain
the embedding vectors of 0.56 million words.
The training data for projection learning is
collected from CilinE (Section 3.3.3). We ob-
tain 15,247 word pairs of hypernym?hyponym
relations (9,288 for direct relations and 5,959 for
indirect relations).
For evaluation, we collect the hypernyms for
418 entities, which are selected randomly from
Baidubaike, following Fu et al (2013). We then
ask two annotators to manually label the seman-
tic hierarchies of the correct hypernyms. The final
data set contains 655 unique hypernyms and 1,391
hypernym?hyponym relations among them. We
randomly split the labeled data into 1/5 for de-
velopment and 4/5 for testing (Table 2). The hi-
erarchies are represented as relations of pairwise
words. We measure the inter-annotator agreement
using the kappa coefficient (Siegel and Castel-
lan Jr, 1988). The kappa value is 0.96, which indi-
cates a good strength of agreement.
4.2 Evaluation Metrics
We use precision, recall, and F-score as our met-
rics to evaluate the performances of the methods.
Since hypernym?hyponym relations and its re-
verse (hyponym?hypernym) have one-to-one cor-
respondence, their performances are equal. For
4
Baidubaike (baike.baidu.com) is one of the largest
Chinese encyclopedias containing more than 7.05 million en-
tries as of September, 2013.
5
www.ltp-cloud.com/demo/
Relation
# of word pairs
Dev. Test
hypernym?hyponym 312 1,079
hyponym?hypernym
?
312 1,079
unrelated 1,044 3,250
Total 1,668 5,408
Table 2: The evaluation data.
?
Since hypernym?
hyponym relations and hyponym?hypernym
relations have one-to-one correspondence, their
numbers are the same.
1 5 
10 15 
20 
0.45 
0.5 
0.55 
0.6 
0.65 
0.7 
0.75 
0.8 
1 10 20 30 40 50 60 Indirect 
F1-
Sco
re 
Direct 
Figure 6: Performance on development data w.r.t.
cluster size.
simplicity, we only report the performance of the
former in the experiments.
5 Results and Analysis
5.1 Varying the Amount of Clusters
We first evaluate the effect of different number of
clusters based on the development data. We vary
the numbers of the clusters both for the direct and
indirect training word pairs.
As shown in Figure 6, the performance of clus-
tering is better than non-clustering (when the clus-
ter number is 1), thus providing evidences that
learning piecewise projections based on clustering
is reasonable. We finally set the numbers of the
clusters of direct and indirect to 20 and 5, respec-
tively, where the best performances are achieved
on the development data.
5.2 Comparison with Previous Work
In this section, we compare the proposed method
with previous methods, including manually-built
hierarchy extension, pairwise relation extraction
1204
P(%) R(%) F(%)
M
Wiki+CilinE
92.41 60.61 73.20
M
Pattern
97.47 21.41 35.11
M
Snow
60.88 25.67 36.11
M
balApinc
54.96 53.38 54.16
M
invCL
49.63 62.84 55.46
M
Fu
87.40 48.19 62.13
M
Emb
80.54 67.99 73.74
M
Emb+CilinE
80.59 72.42 76.29
M
Emb+Wiki+CilinE
79.78 80.81 80.29
Table 3: Comparison of the proposed method with
existing methods in the test set.
Pattern Translation
w?[??|??] h w is a [a kind of] h
w [?]? h w[,] and other h
h [?]?[?] w h[,] called w
h [?] [?]? w h[,] such as w
h [?]??? w h[,] especially w
Table 4: Chinese Hearst-style lexical patterns. The
contents in square brackets are omissible.
based on patterns, word distributions, and web
mining (Section 2). Results are shown in Table 3.
5.2.1 Overall Comparison
M
Wiki+CilinE
refers to the manually-built hierar-
chy extension method of Suchanek et al (2008).
In our experiment, we use the category taxonomy
of Chinese Wikipedia
6
to extend CilinE. Table 3
shows that this method achieves a high precision
but also a low recall, mainly because of the limit-
ed scope of Wikipedia.
M
Pattern
refers to the pattern-based method of
Hearst (1992). We extract hypernym?hyponym
relations in the Baidubaike corpus, which is al-
so used to train word embeddings (Section 4.1).
We use the Chinese Hearst-style patterns (Table
4) proposed by Fu et al (2013), in which w rep-
resents a word, and h represents one of its hy-
pernyms. The result shows that only a small part
of the hypernyms can be extracted based on these
patterns because only a few hypernym relations
are expressed in these fixed patterns, and many are
expressed in highly flexible manners.
In the same corpus, we apply the method
M
Snow
originally proposed by Snow et al (2005).
The same training data for projections learn-
6
dumps.wikimedia.org/zhwiki/20131205/
ing from CilinE (Section 3.3.3) is used as
seed hypernym?hyponym pairs. Lexico-syntactic
patterns are extracted from the Baidubaike corpus
by using the seeds. We then develop a logistic re-
gression classifier based on the patterns to recog-
nize hypernym?hyponym relations. This method
relies on an accurate syntactic parser, and the qual-
ity of the automatically extracted patterns is diffi-
cult to guarantee.
We re-implement two previous distribution-
al methods M
balApinc
(Kotlerman et al, 2010)
and M
invCL
(Lenci and Benotto, 2012) in the
Baidubaike corpus. Each word is represented as a
feature vector in which each dimension is the PMI
value of the word and its context words. We com-
pute a score for each word pair and apply a thresh-
old to identify whether it is a hypernym?hyponym
relation.
M
Fu
refers to our previous web mining
method (Fu et al, 2013). This method mines hy-
pernyms of a given word w from multiple sources
and returns a ranked list of the hypernyms. We
select the hypernyms with scores over a threshold
of each word in the test set for evaluation. This
method assumes that frequent co-occurrence of a
noun or noun phrase n in multiple sources with w
indicate possibility of n being a hypernym of w.
The results presented in Fu et al (2013) show that
the method works well when w is an entity, but
not when w is a word with a common semantic
concept. The main reason may be that there are
relatively more introductory pages about entities
than about common words in the Web.
M
Emb
is the proposed method based on word
embeddings. Table 3 shows that the proposed
method achieves a better recall and F-score than
all of the previous methods do. It can significantly
(p < 0.01) improve the F-score over the state-of-
the-art method M
Wiki+CilinE
.
M
Emb
and M
CilinE
can also be combined. The
combination strategy is to simply merge all pos-
itive results from the two methods together, and
then to infer new relations based on the transitiv-
ity of hypernym?hyponym relations. The F-score
is further improved from 73.74% to 76.29%. Note
that, the combined method achieves a 4.43% re-
call improvement over M
Emb
, but the precision is
almost unchanged. The reason is that the infer-
ence based on the relations identified automatical-
ly may lead to error propagation. For example, the
relation x
H
??y is incorrectly identified by M
Emb
.
1205
P(%) R(%) F(%)
M
Wiki+CilinE
80.39 19.29 31.12
M
Emb+CilinE
71.16 52.80 60.62
M
Emb+Wiki+CilinE
69.13 61.65 65.17
Table 5: Performance on the out-of-CilinE data in
the test set.
0.0 0.2 0.4 0.6 0.8 1.0
0.0
0.2
0.4
0.6
0.8
1.0
Recall
Prec
ision
l l lllllll
l
l
l ll
l MEmb+Wiki+Ci l inEMEmb+Ci l inEMWiki+Ci l inE
Figure 7: Precision-Recall curves on the out-of-
CilinE data in the test set.
When the relation y
H
??z from M
CilinE
is added, it
will cause a new incorrect relation x
H
??z.
Combining M
Emb
with M
Wiki+CilinE
achieves
a 7% F-score improvement over the best baseline
M
Wiki+CilinE
. Therefore, the proposed method
is complementary to the manually-built hierarchy
extension method (Suchanek et al, 2008).
5.2.2 Comparison on the Out-of-CilinE Data
We are greatly interested in the practical perfor-
mance of the proposed method on the hypernym?
hyponym relations outside of CilinE. We say a
word pair is outside of CilinE, as long as there
is one word in the pair not existing in CilinE. In
our test data, about 62% word pairs are outside
of CilinE. Table 5 shows the performances of the
best baseline method and our method on the out-
of-CilinE data. The method exploiting the tax-
onomy in Wikipedia, M
Wiki+CilinE
, achieves the
highest precision but has a low recall. By con-
trast, our method can discover more hypernym?
hyponym relations with some loss of precision,
thereby achieving a more than 29% F-score im-
provement. The combination of these two meth-
ods achieves a further 4.5% F-score improvement
over M
Emb+CilinE
. Generally speaking, the pro-
posed method greatly improves the recall but dam-
ages the precision.
Actually, we can get different precisions and re-
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite
???medicinal plant
??medicine
( a)  C ilinE
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite
???medicinal plant
??medicine
( b )  W ik ipedia+ C ilinE
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite
???medicinal plant
??medicine
( c)  E mb edding
??organism
??plant
???Ranunculaceae
???Aconitum
??aconite
???medicinal plant
??medicine
( d)  E mb edding+ W ik ipedia+ C ilinE
Figure 8: An example for error analysis. The
red paths refer to the relations between the named
entity and its hypernyms extracted using the web
mining method (Fu et al, 2013). The black paths
with hollow arrows denote the relations identified
by the different methods. The boxes with dotted
borders refer to the concepts which are not linked
to correct positions.
calls by adjusting the threshold ? (Equation 3).
Figure 7 shows that M
Emb+CilinE
achieves a high-
er precision than M
Wiki+CilinE
when their recalls
are the same. When they achieve the same preci-
sion, the recall of M
Emb+CilinE
is higher.
5.3 Error Analysis and Discussion
We analyze error cases after experiments. Some
cases are shown in Figure 8. We can see that
there is only one general relation ??? (plant)?
H
?? ??? (organism)? existing in CilinE. Some
fine-grained relations exist in Wikipedia, but the
coverage is limited. Our method based on
word embeddings can discover more hypernym?
hyponym relations than the previous methods can.
When we combine the methods together, we get
the correct hierarchy.
Figure 8 shows that our method loses the
relation ???? (Aconitum)? H?? ????
(Ranunculaceae).? It is because they are
very semantically similar (their cosine similarity
is 0.9038). Their representations are so close to
each other in the embedding space that we have
not find projections suitable for these pairs. The
1206
error statistics show that when the cosine similari-
ties of word pairs are greater than 0.8, the recall is
only 9.5%. This kind of error accounted for about
10.9% among all the errors in our test set. One
possible solution may be adding more data of this
kind to the training set.
6 Related Work
In addition to the works mentioned in Section 2,
we introduce another set of related studies in this
section.
Evans (2004), Ortega-Mendoza et al (2007),
and Sang (2007) consider web data as a large cor-
pus and use search engines to identify hypernyms
based on the lexical patterns of Hearst (1992).
However, the low quality of the sentences in the
search results negatively influence the precision of
hypernym extraction.
Following the method for discovering patterns
automatically (Snow et al, 2005), McNamee et
al. (2008) apply the same method to extract hy-
pernyms of entities in order to improve the perfor-
mance of a question answering system. Ritter et al
(2009) propose a method based on patterns to find
hypernyms on arbitrary noun phrases. They use
a support vector machine classifier to identify the
correct hypernyms from the candidates that match
the patterns. As our experiments show, pattern-
based methods suffer from low recall because of
the low coverage of patterns.
Besides Kotlerman et al (2010) and Lenci and
Benotto (2012), other researchers also propose di-
rectional distributional similarity methods (Weeds
et al, 2004; Geffet and Dagan, 2005; Bhagat et al,
2007; Szpektor et al, 2007; Clarke, 2009). How-
ever, their basic assumption that a hyponym can
only be used in contexts where its hypernyms can
be used and that a hypernym might be used in all
of the contexts where its hyponyms are used may
not always rational.
Snow et al (2006) provides a global optimiza-
tion scheme for extending WordNet, which is d-
ifferent from the above-mentioned pairwise rela-
tionships identification methods.
Word embeddings have been successfully ap-
plied in many applications, such as in sentiment
analysis (Socher et al, 2011b), paraphrase detec-
tion (Socher et al, 2011a), chunking, and named
entity recognition (Turian et al, 2010; Collobert
et al, 2011). These applications mainly utilize
the representing power of word embeddings to al-
leviate the problem of data sparsity. Mikolov et
al. (2013a) and Mikolov et al (2013b) further ob-
serve that the semantic relationship of words can
be induced by performing simple algebraic oper-
ations with word vectors. Their work indicates
that word embeddings preserve some interesting
linguistic regularities, which might provide sup-
port for many applications. In this paper, we
improve on their work by learning multiple lin-
ear projections in the embedding space, to model
hypernym?hyponym relationships within different
clusters.
7 Conclusion and Future Work
This paper proposes a novel method for seman-
tic hierarchy construction based on word em-
beddings, which are trained using a large-scale
corpus. Using the word embeddings, we learn
the hypernym?hyponym relationship by estimat-
ing projection matrices which map words to their
hypernyms. Further improvements are made us-
ing a cluster-based approach in order to model
the more fine-grained relations. Then we propose
a few simple criteria to identity whether a new
word pair is a hypernym?hyponym relation. Based
on the pairwise hypernym?hyponym relations, we
build semantic hierarchies automatically.
In our experiments, the proposed method signif-
icantly outperforms state-of-the-art methods and
achieves the best F1-score of 73.74% on a manual-
ly labeled test dataset. Further experiments show
that our method is complementary to the previous
manually-built hierarchy extension methods.
For future work, we aim to improve word
embedding learning under the guidance of
hypernym?hyponym relations. By including the
hypernym?hyponym relation constraints while
training word embeddings, we expect to improve
the embeddings such that they become more suit-
able for this task.
Acknowledgments
This work was supported by National Natu-
ral Science Foundation of China (NSFC) via
grant 61133012, 61273321 and the National 863
Leading Technology Research Project via grant
2012AA011102. Special thanks to Shiqi Zhao,
Zhenghua Li, Wei Song and the anonymous re-
viewers for insightful comments and suggestions.
We also thank Xinwei Geng and Hongbo Cai for
their help in the experiments.
1207
References
Yoshua Bengio, R?ejean Ducharme, Pascal Vincent, and
Christian Janvin. 2003. A neural probabilistic lan-
guage model. The Journal of Machine Learning Re-
search, 3:1137?1155.
Rahul Bhagat, Patrick Pantel, Eduard H Hovy, and Ma-
rina Rey. 2007. Ledir: An unsupervised algorith-
m for learning directionality of inference rules. In
EMNLP-CoNLL, pages 161?170.
Wanxiang Che, Zhenghua Li, and Ting Liu. 2010. Ltp:
A chinese language technology platform. In Coling
2010: Demonstrations, pages 13?16, Beijing, Chi-
na, August.
Daoud Clarke. 2009. Context-theoretic semantics for
natural language: an overview. In Proceedings of
the Workshop on Geometrical Models of Natural
Language Semantics, pages 112?119. Association
for Computational Linguistics.
Ronan Collobert, Jason Weston, L?eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. The Journal of Machine Learning Re-
search, 12:2493?2537.
Paramveer Dhillon, Dean P Foster, and Lyle H Ungar.
2011. Multi-view learning of word embeddings via
cca. In Advances in Neural Information Processing
Systems, pages 199?207.
Richard Evans. 2004. A framework for named entity
recognition in the open domain. Recent Advances in
Natural Language Processing III: Selected Papers
from RANLP 2003, 260:267?274.
Ruiji Fu, Bing Qin, and Ting Liu. 2013. Exploiting
multiple sources for open-domain hypernym discov-
ery. In EMNLP, pages 1224?1234.
Maayan Geffet and Ido Dagan. 2005. The distribution-
al inclusion hypotheses and lexical entailment. In
Proceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics, pages 107?114.
Association for Computational Linguistics.
Marti A Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th conference on Computational linguistics-
Volume 2, pages 539?545. Association for Compu-
tational Linguistics.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional distribution-
al similarity for lexical inference. Natural Language
Engineering, 16(4):359?389.
Alessandro Lenci and Giulia Benotto. 2012. Identify-
ing hypernyms in distributional semantic spaces. In
Proceedings of the Sixth International Workshop on
Semantic Evaluation, pages 75?79. Association for
Computational Linguistics.
Paul McNamee, Rion Snow, Patrick Schone, and James
Mayfield. 2008. Learning named entity hyponyms
for question answering. In Proceedings of the
Third International Joint Conference on Natural
Language Processing, pages 799?804.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word rep-
resentations in vector space. arXiv preprint arX-
iv:1301.3781.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013b. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL-
HLT, pages 746?751.
George A Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39?41.
Andriy Mnih and Geoffrey E Hinton. 2008. A s-
calable hierarchical distributed language model. In
Advances in neural information processing systems,
pages 1081?1088.
Rosa M Ortega-Mendoza, Luis Villase?nor-Pineda, and
Manuel Montes-y G?omez. 2007. Using lexical
patterns for extracting hyponyms from the web. In
MICAI 2007: Advances in Artificial Intelligence,
pages 904?911. Springer.
Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009. What is this, anyway: Automatic hypernym
discovery. In Proceedings of the 2009 AAAI Spring
Symposium on Learning by Reading and Learning
to Read, pages 88?93.
HP Ritzema. 1994. Drainage principles and
applications.
Erik Tjong Kim Sang. 2007. Extracting hypernym
pairs from the web. In Proceedings of the 45th An-
nual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, pages 165?168. Associa-
tion for Computational Linguistics.
Sidney Siegel and N John Castellan Jr. 1988. Non-
parametric statistics for the behavioral sciences.
McGraw-Hill, New York.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2005.
Learning syntactic patterns for automatic hypernym
discovery. In Lawrence K. Saul, Yair Weiss, and
L?eon Bottou, editors, Advances in Neural Informa-
tion Processing Systems 17, pages 1297?1304. MIT
Press, Cambridge, MA.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computation-
al Linguistics, pages 801?808, Sydney, Australia,
July. Association for Computational Linguistics.
1208
Richard Socher, Eric H Huang, Jeffrey Pennin, Christo-
pher D Manning, and Andrew Ng. 2011a. Dynam-
ic pooling and unfolding recursive autoencoders for
paraphrase detection. In Advances in Neural Infor-
mation Processing Systems, pages 801?809.
Richard Socher, Jeffrey Pennington, Eric H Huang,
Andrew Y Ng, and Christopher D Manning. 2011b.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151?161. Association for
Computational Linguistics.
Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2008. Yago: A large ontology from
wikipedia and wordnet. Web Semantics: Sci-
ence, Services and Agents on the World Wide Web,
6(3):203?217.
Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007.
Instance-based evaluation of entailment rule acqui-
sition. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
456?463, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 384?394. Association for
Computational Linguistics.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional
similarity. In Proceedings of the 20th internation-
al conference on Computational Linguistics, page
1015. Association for Computational Linguistics.
1209
