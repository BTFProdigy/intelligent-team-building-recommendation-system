Discovering Synonyms and Other Related Words
Krister LINDE?N and Jussi PIITULAINEN
Helsinki University, Department of General Linguistics,
P.O.Box 9 (Siltavuorenpenger 20 A),
FIN-00014 University of Helsinki,
Finland,
Krister.Linden@helsinki.fi, Jussi.Piitulainen@helsinki.fi
Abstract
Discovering synonyms and other related words
among the words in a document collection can
be seen as a clustering problem, where we ex-
pect the words in a cluster to be closely related
to one another. The intuition is that words oc-
curring in similar contexts tend to convey simi-
lar meaning.
We introduce a way to use translation dictio-
naries for several languages to evaluate the rate
of synonymy found in the word clusters. We also
apply the information radius to calculating sim-
ilarities between words using a full dependency
syntactic feature space, and introduce a method
for similarity recalculation during clustering as
a fast approximation of the high-dimensional
feature space. Finally, we show that 69-79% of
the words in the clusters we discover are useful
for thesaurus construction.
1 Introduction
Finding related words among the words in a
document collection can be seen as a clustering
problem, where we expect the words in a cluster
to be closely related to the same sense or to be
distributional substitutes or proxies for one an-
other. A number of language-technology tasks
can benefit from such word clusters, e.g. docu-
ment classification applications, language mod-
elling, resolving prepositional phrase attach-
ment, conjunction scope identification, word
sense disambiguation, word sense separation,
automatic thesaurus generation, information re-
trieval, anaphor resolution, text simplification,
topic identification, spelling correction (Weeds,
2003).
At present, synonyms and other related
words are available in manually constructed
ontologies, such as synonym dictionaries, the-
sauri, translation dictionaries and terminolo-
gies. Manually constructing ontologies is time-
consuming even for a single domain. On the
world-wide web there are documents on many
topics in different languages that could bene-
fit from having an ontology. For many of them
some degree of automation is eventually needed.
Humans often infer the meaning of an un-
known word from its context. Lets look at a less
well-known word like blopping. We look it up on
the Web. Some of the hits are: Blopping through
some of my faves, i.e. leafing through favourite
web links, A blop module emits strange elec-
tronic blopping noises, i.e. an electronic sound,
The volcano looked like something off the cover
of a Tolkien novel - perfectly conical, billowing
smoke and blopping out chunks of bright orange
lava, i.e. spluttering liquid. At first we find
all of them different and perhaps equally im-
portant. When looking at further links, we get
an intuition that the first instance is perhaps
a spurious creative metonym, whereas the two
others can be regarded as more or less conven-
tional and represent two distinct senses of blop-
ping. However, the meaning of all three seems
to be related to a sound, which is either clicking
or spluttering in nature.
The intuition is that words occurring in the
same or similar contexts tend to convey similar
meaning. This is known as the Distributional
Hypothesis (Harris, 1968). There are many ap-
proaches to computing semantic similarity be-
tween words based on their distribution in a cor-
pus. For a general overview of similarity mea-
sures, see (Manning and Schu?tze, 1999), and for
some recent and extensive overviews and evalu-
ations of similarity measures for i.a. automatic
thesaurus construction, see (Weeds, 2003; Cur-
ran, 2003; Lee, 2001; Dagan et al, 1999). They
show that the information radius and the ?-
skew distance are among the best for finding
distributional proxies for words.
If we assume that a word w is represented as a
sum of its contexts and that we can calculate the
similarities between such word representations,
we get a list Lw of words with quantifications
of how similar they are to w. Each similarity
CompuTerm 2004  -  3rd International Workshop on Computational Terminology 63
list Lw contains a mix of words related to the
senses of the word w.
If we wish to identify groups of synonyms
and other related words in a list of similarity-
rated words, we need to find clusters of simi-
lar words that are more similar to one another
than they are to other words. For a review of
general clustering algorithms, see (Jain et al,
1999) and for a recent evaluation of clustering
algorithms for finding word categories, see (Pan-
tel, 2003). (Pantel, 2003) shows that among the
standard algorithms the average-link and the k-
means clustering perform the best when trying
to discover meaningful word groups.
In order to evaluate the quality of the discov-
ered clusters three methods can be used, i.e.
measuring the internal coherence of clusters,
embedding the clusters in an application, or
evaluating against a manually generated answer
key. The first method is generally used by the
clustering algorithms themselves. The second
method is especially relevant for applications
that can deal with noisy clusters and avoids
the need to generate answer keys specific to the
word clustering task. The third method requires
a gold standard such as WordNet or some other
ontological resource. For an overview of eval-
uation methodologies for word clustering, see
(Weeds, 2003; Curran, 2003; Pantel, 2003).
The contribution of this article is four-fold.
The first contribution is to apply the informa-
tion radius in a full dependency syntactic fea-
ture space when calculating the similarities be-
tween words. Previously, only a restricted set
of dependency relations has been applied. The
second contribution is a similarity recalcula-
tion during clustering, which we introduce as a
fast approximation of high-dimensional feature
space and study its effect on some standard clus-
tering algorithms. The third contribution is a
simple but efficient way to evaluate the synonym
content of clusters by using translation dictio-
naries for several languages. Finally we show
that 69-79% of the words in the discovered clus-
ters are useful for thesaurus construction.
The rest of this article is organized as fol-
lows. Section 2 presents the corpus data and
the the feature extraction. Section 3 introduces
the discovery methodology. Section 4 presents
the evaluation methodology. In Section 5 we
present the experiments and evaluate the results
and their significance. Sections 6 and 7 contain
the discussion and conclusion, respectively.
2 Corpus Data
Our corpus consists of nouns in a sentence con-
text. We used all the nouns (in base form) that
occurred more than 100 times (in any inflected
form) in a corpus of Finnish newspaper text.
The corpus contained 245 000 documents total-
ing 48 million words of the Finnish newspaper
Helsingin sanomat from 1995?1997. Excluding
TV and radio listings, there were 196 000 doc-
uments with 42 million words. As corpus data
we selected all the 17 835 nouns occurring more
than 100 times comprising 14 million words of
the corpus.
3 Methodology
First we present the types of features we have
extracted from the corpus. Then we briefly de-
scribe the similarity measure which we use in
order to calculate the similarity between the
nouns in the corpus data. We also introduce
a method for creating derived similarity infor-
mation in a low-dimensional space. Finally we
present the clustering algorithms which we ap-
ply to the similarity information.
3.1 Feature extraction
The present experiments aim at discovering the
nouns that are most similar in meaning to a
given noun. The assumption is that words oc-
curring in similar syntactic contexts belong to
the same semantic categories (Harris, 1968). In
order to determine the similarity of the syntac-
tic contexts, we represent a word w as a proba-
bility distribution over a set of features a occur-
ring in the context of w: P (a|w). The context
features a are the major class words w? (nouns,
adjectives and verbs) with direct dependency
links to the word w. The context feature is the
word w? in base form labeled with the depen-
dency relation r. For example, the noun might
occur as an object of a verb and with an adjec-
tive modifier; both the verb and the adjective
including their dependency relations are context
features.
We used Connexor?s dependency parser FDG
for Finnish (Connexor, 2002) for parsing the
corpus. A sample of the parser output is shown
in Table 1. Tokens of each sentence are num-
bered starting from zero, each token is on its
own line, the token number first, the actual
word form second and the base form in the third
field. The fourth field links dependent tokens to
their heads using a grammatical label and the
CompuTerm 2004  -  3rd International Workshop on Computational Terminology64
# Token Base form Dependency Morphosyntax Gloss
0
1 Toisessa toinen &NH PRON SG INE In the other
2 esiteta?a?n esitta?a? main:>0 &+MV V PASS IND PRES they showed
3 videoita video obj:>2 &NH N PL PTV videos
4 ja ja cc:>3 &CC CC and
5 filmeja? filmi cc:>3 &NH N PL PTV films
6 . .
7 <s> <s> >6
Table 1: Sample output from the FDG parser for Finnish (with an English gloss added).
number of the head token. The fifth field con-
tains morphosyntactic information.
Two tokens, 3 and 5, are labeled as nouns N.
The noun video is a direct object to the verb
esitta?a?, and the noun filmi is coordinated
with video, so video gets two feature occur-
rences from this sentence:
esitta?a?-obj
cc-filmi.
Also, filmi gets
video-cc
as a feature occurrence. The pronoun toinen is
not a potential feature because of its word class
and because it is not linked. The coordinating
conjunction ja is not a potential feature because
of its word class.
The parsed corpus contained a to-
tal of 18 516 609 unambiguous noun oc-
currences, 69 314 noun/verb ambigui-
ties, 39 104 noun/adjective ambiguities,
20 847 noun/adverb ambiguities and 11 739
noun/numeral ambiguities, i.e. the amount
of remaining ambiguities was less than 0.8%.
When its analyses were underspecified with
more than one morphological analysis re-
maining, we took the relatively small risk
(p < 0.008) of committing to a noun analysis.
As a straightforward weighting of the context
features of a word, we used the number of occur-
rences with all the instances of the word. In our
choice of similarity formula, the representation
of a word w must be a probability distribution.
This is formally just a matter of normalizing the
weights of the features. Thus, a word w is rep-
resented as w : a 7? P (a|w), i.e. the conditional
probability distribution of all features a given
the word w, such that
?
a P (a|w) = 1.
Extracting features only from direct depen-
dency relations produces few feature occur-
rences for each instance of a noun. This keeps
the number of distinct features tolerable for all
but the most frequent words, and still retains
the most promising co-occurring words. As we
use only linear frequency weighting, very fre-
quent features tend to get more weight than
they should. Additionally, many rare features
could have been dropped without much loss of
information.
3.2 Similarity calculations
In (Weeds, 2003; Lee, 2001), i.a. the informa-
tion radius is applied to finding words that can
be used as proxies or substitutes for one an-
other. Their tests show that the information
radius is among the best for finding such words.
Here we briefly recapitulate the details of the
similarity estimate, which is rather an estimate
of dissimilarity.
Two words are distributionally similar to the
extent that they co-occur with the same words,
i.e., to the extent that they share features. We
define the dissimilarity of two words, p and q,
as
J(p, q) = (D(p?m) +D(q?m))/2, (1)
where D(p?m) =
?
a p(a)(log2 p(a)? log2 m(a))
and m(a) = (p(a) + q(a))/2 for any feature a.
This is the symmetrically weighted case of the
Jensen?Shannon divergence (Lin, 1991), also
known as the information radius or the mean di-
vergence to the mean (Dagan et al, 1999). For
complete identity, J(p, p) = 0. For completely
disjoint feature sets, J(p, q) = 1. The formula is
symmetric but does not satisfy the triangle in-
equality. For speed the estimate may be calcu-
lated from the shared features alone (Lee, 1999).
After calculating all the pairwise estimates,
we retained lists of the 100 most similar nouns
for each of the nouns in the corpus data. No
other data is used in the similarity calculations.
CompuTerm 2004  -  3rd International Workshop on Computational Terminology 65
3.3 Low-dimensional similarity
measures
Performing all the calculations in high-
dimensional feature space is time-consuming.
Here we introduce a method that can be used
as an approximation in low-dimensional feature
space based on the initial similarity estimates.
Assume that we have lists of the words that
are distributionally most similar to a given word
w. Each list Lw contains 100 words with an
estimate of their similarity to w. The words in
Lw represent a mix of the different meanings of
the word w. We create a similarity matrix disw
for these words such that disw(p, q) = J(p, q),
where p, q ? Lw. The similarity matrix disw is a
symmetric matrix of the dimensions 101 by 101,
as we also include the word w in the matrix.
A vector pw = disw(p, .) in the similarity
matrix disw is regarded as a projection of the
word p from a high dimensional feature space
onto a 101-dimensional space, i.e. p is projected
onto the 101 most important dimensions of w.
The new matrix is not orthogonal, so we ap-
ply single-value decomposition (SVD) disw =
T S D and use T to rotate the matrix so that the
first axis runs along the direction of the largest
variation among the word similarity estimates,
the second dimension runs along the direction
of the second largest variation and so forth. Af-
ter this rotation we can cluster the new vec-
tors pw,T = T t pw as low-dimensional represen-
tatives of the original high-dimensional feature
space. Often SVD is used for dimensionality re-
duction, but here we use its left singular vectors
only for rotating the matrix in order to achieve
noise reduction during clustering.
In the new low-dimensional vector repre-
sentation pw,T we apply the cosine distance
cosd(pw,T , qw,T ) = 1 ? cos(pw,T , qw,T ) in order
to calculate the similarity between words. As a
comparison we also tried the squared Euclidean
distance eucld(pw,T , qw,T ) = ?pw,T ? qw,T ?2 be-
tween words in the low-dimensional space. We
first normalize the vectors to unit length, which
effectively makes the squared Euclidean dis-
tance the same as two times the cosine distance:
?A?B?2 = ?A?2+?B?2?2?A? ?B? cos(A,B),
and when ?A? = 1 and ?B? = 1, we have
?A?B?2 = 2 (1? cos(A,B)).
3.4 Clustering
When we wish to discover the potential senses
of w by clustering, we are currently only inter-
ested in the 100 words in Lw with a similarity
estimate for w. The other words are deemed to
be too dissimilar to w to be relevant.
We cluster the words related to w with
standard algorithms such as complete-link and
average-link clustering (Manning and Schu?tze,
1999). Complete-link and average-link are hier-
archical clustering methods. We compare them
with flat clustering methods like k-means and
self-organizing maps (SOM) (Kohonen, 1997).
In k-means the clusters have no ordering. The
potential benefit of using SOM with a two-
dimensional display compared to k-means is
that related data samples get assigned into
nearby clusters as the SOM converges forming
cluster areas with related content.
We use the MATLAB implementation (The
MathWorks, Inc., 2002) of the algorithms. We
use both the original similarity measures in
disw and the distance measures cosd and eucld,
which we defined on the low-dimensional space.
In order to use methods like k-means and SOM,
we need to be able to calculate the similar-
ity between cluster centroids and words to be
clustered each time a centroid is updated. We
do this in the low-dimensional space pw,T using
cosd and eucld.
For SOM, the MATLAB implementation sup-
ported only the squared Euclidean distance. It
should be noted that the centroids are not nec-
essarily of unit length, so the squared Euclidean
distance is different from the cosine distance be-
tween the samples and the centroids, when the
centroids are based on more than one sample.
Our clustering setup currently produces hard
clusters, where each word w in Lw belong to
one cluster, as opposed to soft clustering, where
a word may belong to several clusters. We call
the cluster containing the word w itself the key
cluster.
4 Evaluation methodology
In order to evaluate the quality of the clusters
we need a gold standard. English and a num-
ber of other languages have resources such as
WordNet (Fellbaum, 1998; Vossen, 2001). For
Finnish there is no WordNet and there are no
large on-line synonym dictionaries available. In
fact, our experiment can be seen as a feasibility
study for automatically extracting information
that could be used for building a WordNet for
Finnish. The synsets of WordNet contain syn-
onyms, so we can evaluate the feasibility of the
clusters for WordNet development by rating the
amount of synonyms and related words in the
CompuTerm 2004  -  3rd International Workshop on Computational Terminology66
Language Target word Back translation
English deficit vaje, vajaus, alija?a?ma?; tilivajaus
shortfall vaje, alija?a?ma?
German Defizit vajaus, vaje, alija?a?ma?; kassavajaus, tappio; tilivajaus; puutos, puute
Unterbilanz alija?a?ma?, vajaus, vaje, kauppavaje
Fehlbetrag vajaus, alija?a?ma?, tappio, virhemaksu
French de?ficit alija?a?ma?, miinus, tilivajaus; vajaus, vaje; tappio
Table 2: Translations of the Finnish source word alija?a?ma? into English, German and French with
the back translations into Finnish. The shared back translations vaje, vajaus, alija?a?ma?, tilivajaus
are highlighted.
discovered clusters.
We note that when translating a word from
the source language the meaning of the word is
rendered in a target language. Such meaning
preserving relations are available in translation
dictionaries. If we translate into the target lan-
guage and back we end up i.a. with the syn-
onyms of the original source language word. In
addition, we may also get some spurious words
that are related to other meanings of the target
language words. If we assume that the other
words represent spurious cases of polysemy or
homonymy in the target language, we can re-
duce the impact of these spurious words by con-
sidering several target languages and for each
source word we use only the back-translated
source words that are common to all the tar-
get languages. We call such a group of words a
source word synonym set. For an example, see
Table 2.
In addition to the mechanical rating of the
synonym content we also manually classified the
words of some cluster samples into synonymy,
antonymy, hyperonymy, hyponymy, comple-
mentarity and other relations.
4.1 Evaluation data
In order to evaluate the clusters we picked a
random sample of 1759 nouns from the corpus
data, which represented approximately 10% of
the words we had clustered. For these words
we extracted the translations in the Finnish-
English, Finnish-German and Finnish-French
MOT dictionaries (Kielikone, 2004) available in
electronic form. We then translated each tar-
get language word back into Finnish using the
same resources. The dictionaries are based on
extensive hand-made dictionaries. The choice of
words may be slightly different in each of them,
which means that the words in common for all
the dictionaries after the back translation tend
to be only the core synonyms.
For evaluation purposes it would be unfair to
demand that the clustering generate words into
the clusters that are not in the corpus data, so
we also removed those back translations from
the source word synonym sets. Finally, only
synonym sets that had more than one word re-
maining were interesting, i.e. they contained
more than the original source word. There were
453 of the 1759 test words that met the quali-
fications. The average number of synonyms or
back translations for these test words was 3.53
including the source word itself.
For manual classification we used a sample of
50 key clusters from the whole set of clusters and
an additional sample of 50 key clusters from the
words qualifying for the mechanical evaluation.
4.2 Evaluation method
The mechanical evaluation was performed by
picking the key cluster produced by a cluster-
ing algorithm for each of the test words. The
key cluster was the cluster which contained the
original source word. The evaluation was a sim-
ple overlap calculation with the gold standard
generated from the translation dictionaries. By
counting the number of cluster words in a source
word synonym set and dividing by the synonym
set size, we get the recall R. By counting the
number of of source word synonyms in a clus-
ter and dividing by the cluster size, we get the
precision P .
The manual evaluation was performed inde-
pendently by the two authors and an external
linguist. We then discussed the result in order
to arrive at a common view.
5 Testing
First we did some initial experimenting with a
preliminary test sample in order to tune the pa-
rameters. We then clustered the corpus data
and evaluated the clusters against the gold stan-
dard, which gave an estimate of the synonym
content of the clusters. In addition, we per-
formed a manual evaluation of the result of the
CompuTerm 2004  -  3rd International Workshop on Computational Terminology 67
Clustering method Information radius Cosine distance Euclidean distance
R P R P R P
Average link 47 42 43 41 43 41
Complete link 47 40 42 39 42 38
K-means - - 43 36 42 36
SOM - - - - 41 35
Table 3: Cluster synonym content as average recall (R) and precision (P) in per cent (%) with a
standard deviation of 2% using different clustering methods and similarity measures.
Clustering method Cosine distance Cosine distance
w rotated feature space w/o rotation
R P R P
Average link 43 41 42 32
Complete link 42 39 41 33
Table 4: Cluster synonym content as average recall (R) and precision (P) in per cent (%) with a
standard deviation of 2% using a denoised and a noisy low-dimensional feature space.
best clustering algorithm.
5.1 Parameter selection
We clustered the words in Lw with the
complete-link and average-link clustering algo-
rithms using the disw similarity information.
The algorithms form hierarchical cluster trees
which need to be split into clusters at some
level. The inconsistency coefficient c character-
izes each link in a cluster tree by comparing its
length with the average size of other links at
the same level of the hierarchy. The higher the
value of this coefficient, the less similar the ob-
jects connected by the link (The MathWorks,
Inc., 2002). We selected the inconsistency coef-
ficient c = 1 by testing on a separate initial test
set different from the final evaluation data.
Using the cosine distance cosd(pw,T , qw,T )
as a similarity measure on the projected and
rotated representation of the words we clus-
tered with the above mentioned standard clus-
tering algorithms as well as with the k-
means algorithm. Using the euclidean dis-
tance eucld(pw,T , qw,T ) we also produced self-
organizing maps (SOM). For k-means and SOM
an initial number of clusters need to be selected.
We selected 35 clusters as this was close to the
average of what the other algorithms produced,
which we were comparing with. For k-means
we used the best out of 10 iterations and for
SOM we trained a 5 ? 7 hexagonal gridtop for
10 epochs. We also tried a considerably longer
training period for SOM but noticed only an
insignificant improvement on the cluster preci-
sion.
We also tried a number of other algorithms in
the MATLAB package, but they typically pro-
duced a result either containing only the word
itself or clusters containing more than one fifth
of the words in the key cluster. We deemed such
clustering results a failure on our data without
need for formal evaluation.
5.2 Experiments
After evaluating against the translation dictio-
nary gold standard, the result of the experiment
with complete-link, average-link, k-means and
SOM clustering using different similarity mea-
sures is shown in Table 3. The best recall with
the best precision was achieved with the average-
link clustering using the information radius on
the original feature space with 47 ? 2% recall
and and 42?2% precision. This produced clus-
ters with an average size of 6.05 words.
The difference between complete-link and
average-link clustering is not statistically sig-
nificant even if the average-link is slightly bet-
ter. The recall is statistically significantly better
in the original feature space than in the low-
dimensional space at the risk level p = 0.05,
whereas the precision remains roughly the same.
The average-link and complete-link clustering
have a statistically significantly better precision
than k-means and SOM, respectively, at the risk
level p < 0.05. We can also see that there is
hardly any difference in practice between the
Euclidean distance on normalized word vectors
and the cosine distance despite the fact that the
centroids were not normalized when using the
squared Euclidean distance with k-means.
As can be seen from Table 4 the rotation of
the low-dimensional feature space using SVD
has the effect of increasing precision statistically
significantly at the risk level p < 0.005, i.e. the
CompuTerm 2004  -  3rd International Workshop on Computational Terminology68
Word alija?a?ma?/deficit maatalous/agriculture tuki/aid
Synonymy vaje/deficiency avustus/subsidy
vajaus/shortfall apu/help
Antonymy ylija?a?ma?/surplus
Complementarity teollisuus/industry
vientiteollisuus/export industry
elintarviketeollisuus/food industry
Hyperonymy elinkeinoela?ma?/business
talousela?ma?/economy
Hyponymy rahoitus/financing
Table 5: Semantic relations of the cluster content of some sample words (English glosses added)
Content Dictionary All words
Relations sample sample
Synonymy 52% 38%
Antonymy 1% 1%
Complementarity 12% 34%
Hyperonymy 2% 4%
Hyponymy 1% 3%
Other 31% 21%
Total 100% 100%
Table 6: Manual evaluation of the percentage
of different semantic relations in the cluster con-
tent in two different samples of 50 clusters each.
clusters become less noisy.
We then performed a manual evaluation of
the output of the best clustering algorithm. We
used one cluster sample from the 453 clusters
qualifying for mechanical evaluation and one
sample from the whole set of 1753 clusters. The
results of the manual evaluation is shown in Ta-
ble 6. The evaluation shows that 69-79% of the
material in the clusters is relevant for construct-
ing a thesaurus.
The manual evaluation agrees with the me-
chanical evaluation, when the manual evalua-
tion found a synonym content of 52%, com-
pared to the minimum synonym content of
42% found by the mechanical evaluation. This
means that the clusters actually contain a
few more synonyms than those conservatively
agreed on by the three translation dictionaries.
If we evaluate the sample of key clusters
drawn from all the words in the test sample, we
get a synonym content of 38%. This figure is
rather low, but can be explained by the fact that
many of the words were compound nouns that
had no synonyms, which is why the translation
dictionaries either did not have them listed or
contained no additional source word synonyms
for them.
In Table 5, we see a few sample clusters whose
words we rated during manual evaluation.
6 Discussion
The feature selection and the feature weighting
radically influences the outcome of the results
of any machine learning task. This has been
noted in several evaluations of supervised ma-
chine learning algorithms (Voorhees et al, 1995;
Yarowsky and Florian, 2002; Linde?n, 2003).
During clustering, i.e. unsupervised learning,
the features extracted from the corpus are the
only information guiding the machine learning
in addition to the clustering principle, which
makes successful feature extraction, good fea-
ture weighting and accurate similarity measure-
ments crucial for the success of the clustering.
The clustering algorithms only exploit and pre-
serve the information provided by the features
and the similarity measure.
In (Weeds, 2003; Lee, 2001; Dagan et al,
1999), the information radius is applied to find
words that can be used as distributional prox-
ies for one another. They extract features only
from verb relations whereas we use the full range
of dependency syntactic relations. One inten-
tion of this study was to evaluate whether the
selected corpus and the features extracted pro-
vide a basis for forming linguistically meaning-
ful clusters that are useful in thesaurus con-
struction. The result showed that 69-79% of
the words found in the key clusters are useful,
which is very encouraging. It turned out that
the chosen features as such were useful, even if
the over-all result probably could benefit from
a more nuanced feature weighting scheme. We
do not yet fully understand how the initial fea-
ture weighting affects the outcome of the clus-
tering. Perhaps there are features that would
contribute to a more fine-grained clustering if
properly weighted.
Next we intend to identify more than a sin-
gle key cluster for each word, which poses addi-
CompuTerm 2004  -  3rd International Workshop on Computational Terminology 69
tional challenges for the evaluation. We also aim
at evaluating the generated clusters in an infor-
mation retrieval setting in order to see if they
improve performance despite the fact that they
contain more than synonyms. This would also
shed some light on exactly how much synonymy
we need to aim at in a practical application.
7 Conclusion
We have demonstrated that it is feasible to cal-
culate similarities between words using a full
dependency syntactic feature space. We have
also introduced similarity recalculation during
clustering as a fast approximation of the high-
dimensional feature space. In addition we intro-
duced a way to use translation dictionaries for
evaluating the rate of synonymy found in the
word clusters, which is useful for languages that
do not yet have publicly available thesaurus re-
sources like WordNet. Finally we have shown
that 69-79% of the words in the discovered clus-
ters are useful for thesaurus construction.
Acknowledgements
The second author made the Jensen-Shannon
similarity lists and the corpus processing de-
scribed in Sections 2, 3.1 and 3.2, and the
first author did the rest. We are grateful
to Lauri Carlson, Kimmo Koskenniemi and
Mathias Creutz for helpful comments on the
manuscript and to Juhani Jokinen for manually
evaluating the test samples.
References
Connexor. 2002. Machinese phrase tagger.
[http://www.connexor.com/].
James Richard Curran. 2003. From Distribu-
tional to Semantic Similarity. Ph.D. thesis,
Institute for Communicating and Collabora-
tive Systems, School of Informatics, Univer-
sity of Edinburgh.
Ido Dagan, Lillian Lee, and Fernando C. N.
Pereira. 1999. Similarity-based models of
word co-occurrence probabilities. Machine
Learning, 34(1?3):43?69.
Christiane Fellbaum. 1998. WordNet, An Elec-
tronic Lexical Database. The MIT Press.
Zellig Harris. 1968. Mathematical structures
of language. Interscience Tracts in Pure and
Applied Mathematics, 21(ix):230 pp.
A. K. Jain, M. N. Murty, and P. J. Flynn. 1999.
Data clustering: a review. ACM Computing
Surveys, 31(3):264?323.
Kielikone. 2004. Dictionary service
mot - dictionaries and terminologies.
[http://www.kielikone.fi/en/].
Teuvo Kohonen. 1997. Self-Organizing Maps
(Second Edition), volume 30 of Springer
Series in Information Sciences. Springer,
Berlin.
Lillian Lee. 1999. Measures of distributional
similarity. In 37th Annual Meeting of the
Association for Computational Linguistics,
pages 25?32.
Lillian Lee. 2001. On the effectiveness of the
skew divergence for statistical language anal-
ysis. In Artificial Intelligence and Statistics
2001, pages 65?72.
Jianhua Lin. 1991. Divergence measures based
on the Shannon entropy. IEEE Transactions
on Information Theory, 37(1):145?151, Jan-
uary.
Krister Linde?n. 2003. Word sense disam-
biguation with thessom. In Proceedings of
the WSOM?03 ? Intelligent Systems and In-
novational Computing, Kitakuyshu, Japan,
September.
Christopher D. Manning and Hinrich Schu?tze.
1999. Foundations of Statistical Natural Lan-
guage Processing. The MIT Press, Cam-
bridge, Massachusetts.
Patrick Andre? Pantel. 2003. Clustering by
Committee. Ph.D. thesis, University of Al-
berta, Edmonton, Alberta, Canada.
The MathWorks, Inc. 2002. Matlab with
statistics toolbox and neural network tool-
box. [http://www.mathworks.com/], June
18. Version 6.5.0.180913a Release 13.
Ellen M. Voorhees, Claudia Leacock, and Ge-
offrey Towell, 1995. Computational Learn-
ing Theory and Natural Language Learning
Systems 3: Selecting Good Models, chap-
ter Learning context to disambiguate word
senses, pages 279?305. MIT Press, Cam-
bridge.
Piek Vossen. 2001. Eurowordnet.
[http://www.hum.uva.nl/?ewn/].
Julie Elisabeth Weeds. 2003. Measures and Ap-
plications of Lexical Distributional Similarity.
Ph.D. thesis, University of Sussex, Septem-
ber.
David Yarowsky and Radu Florian. 2002. Eval-
uating sense disambiguation across diverse
parameter spaces. Natural Language Engi-
neering, 8(4):293?310, December.
CompuTerm 2004  -  3rd International Workshop on Computational Terminology70
Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 108?115,
Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational Linguistics
Refining the Design of a Contracting Finite-State Dependency Parser
Anssi Yli-Jyra? and Jussi Piitulainen and Atro Voutilainen
The Department of Modern Languages
PO Box 3
00014 University of Helsinki
{anssi.yli-jyra,jussi.piitulainen,atro.voutilainen}@helsinki.fi
Abstract
This work complements a parallel paper of
a new finite-state dependency parser archi-
tecture (Yli-Jyra?, 2012) by a proposal for
a linguistically elaborated morphology-syntax
interface and its finite-state implementation.
The proposed interface extends Gaifman?s
(1965) classical dependency rule formalism
by separating lexical word forms and morpho-
logical categories from syntactic categories.
The separation lets the linguist take advantage
of the morphological features in order to re-
duce the number of dependency rules and to
make them lexically selective. In addition,
the relative functional specificity of parse trees
gives rise to a measure of parse quality. By fil-
tering worse parses out from the parse forest
using finite-state techniques, the best parses
are saved. Finally, we present a synthesis of
strict grammar parsing and robust text pars-
ing by connecting fragmental parses into trees
with additional linear successor links.
1 Introduction
Finite-state dependency parsing aims to combine de-
pendency syntax and finite-state automata into a sin-
gle elegant system. Deterministic systems such as
(Elworthy, 2000) are fast but susceptible to garden-
path type errors although some ambiguity is encoded
in the output. Some other systems such as (Oflazer,
2003; Yli-Jyra?, 2005) carry out full projective de-
pendency parsing while being much slower, espe-
cially if the syntactic ambiguity is high. In the worst
case, the size of the minimal finite-state automa-
ton storing the forest is exponentially larger than
the sentence: an 80-word sentence has potentially
1.1?1062 unrooted unlabeled dependency trees that
are stored ?compactly? into a finite-state lattice that
requires at least 2.4?1024 states, see Table 4 in Yli-
Jyra? (2012).
A truly compact representation of the parse forest
is provided by an interesting new extended finite-
state parsing architecture (Yli-Jyra?, 2012) that first
recognizes the grammatical sentences in quadratic
time and space if the nested dependencies are lim-
ited by a constant (in cubic time if the length of the
sentence limits the nesting). The new system (Yli-
Jyra?, 2012) replaces the additive (Oflazer, 2003) and
the intersecting (Yli-Jyra?, 2005) validation of depen-
dency links with reductive validation that gradually
contracts the dependencies until the whole tree has
been reduced into a trivial one. The idea of the con-
tractions is illustrated in Example 1. In practice, our
parser operates on bracketed trees (i.e., strings), but
the effect will be similar.
(1) a. time flies like an arrow
SUBJ ADVL
NOBJ
DET
b. time flies like an arrow
NOBJ
c. time flies like an arrow
108
Despite being non-deterministic and efficient,
there are two important requirements that are not ful-
filled by the core of the new architecture (Yli-Jyra?,
2012):
1. A mature finite-state dependency parser must
be robust. The outputs should not be restricted
to complete grammatical parses. For exam-
ple, Oflazer (2003) builds fragmental parses but
later drops those fragmental parses for which
there are alternative parses with fewer frag-
ments. However, his approach handles only
gap-free bottom-up fragments and optimizes
the number of fragments by a counting method
whose capacity is limited.
2. Besides robustness, a wide-coverage parser
should be able to assign reasonably well-
motivated syntactic categories to every word in
the input. This amounts to having a morpho-
logical guesser and an adequate morphology-
syntax interface. Most prior work trivializes
the complexity of the interface, being compara-
ble to Gaifman?s (1965) legacy formalism that
is mathematically elegant but based on word-
form lists. A good interface formalism is pro-
vided, e.g., by Constraint Grammar parsers
(Karlsson et al, 1995) where syntactic rules
can refer to morphological features. Oflazer
(2003) tests morphological features in compli-
cated regular expressions. The state complexity
of the combination of such expressions is, how-
ever, a potential problem if many more rules
would be added to the system.
This paper makes two main contributions:
1. It adapts Gaifman?s elegant formalism to the re-
quirements of morphologically rich languages.
With the adapted formalism, grammar writing
becomes easier. However, efficient implemen-
tation of the rule lookup becomes inherently
trickier because testing several morphological
conditions in parallel increases the size of the
finite-state automata. Fortunately, the new for-
malism comes with an efficient implementation
that keeps the finite-state representation of the
rule set as elegant as possible.
2. The paper introduces a linguistically motivated
ranking for complete trees. According to it, a
tree is better than another tree if a larger propor-
tion of its dependency links is motivated by the
linguistic rules. In contrast to Oflazer (2003),
our method counts the number of links needed
to connect the fragments into a spanning tree.
Moreover, since such additional links are in-
deed included in the parses, the ranking method
turns a grammar parser into a robust text parser.
The paper is structured as follows. The next section
will give an overview of the new parser architecture.
After it, we present the new morphology-syntax in-
terface in Section 3 and the parse ranking method in
Section 4. The paper ends with theoretical evalua-
tion and discussion about the proposed formalism in
Section 5.
2 The General Design
2.1 The Internal Linguistic Representation
We need to define a string-based representation for
the structures that are processed by the parser. For
this purpose, we encode the dependency trees and
then augment the representation with morphological
features.
Dependency brackets encode dependency links
between pairs of tokens that are separated by an (im-
plicit) token boundary. The four-token string abcd
has 12 distinct undirected unlabeled dependency
bracketings a((()b)c)d, a((b())c)d, a(()b()c)d,
a(()bc())d, a(()b)c()d, a(b(()c))d, a(b(c()))d,
a(b()c())d, a(b())c()d, a()b(()c)d, a()b(c())d,
a()b()c()d.1
The basic dependency brackets extend with labels
such as in (LBL LBL) and directions such as in <LBL
LBL\ and in /LBL LBL>. Directed dependency links
designate one of the linked words as the head and
another as the dependent. The extended brackets let
us encode a full dependency tree in a string format
as indicated in (2).2 The dependent word of each
1Dependency bracketing differs clearly from binary phrase-
structure bracketings that put brackets around phrases: the
string abcd has only five distinct bracketings ((ab)(cd)),
(((ab)c)d), ((a(bc))d), (a((bc)d)), and (a(b(cd))).
2The syntactic labels used in this paper are: AG=Agent,
by=Preposition ?by? as a phrasal verb complement,
D=Determiner, EN=Past Participle, FP=Final Punctuation,
P=adjunctive preposition, PC=Preposition Complement,
S=Subject, sgS=Singular Subject.
109
link is indicated in trees with an arrowhead but in
bracketing with an angle bracket.
(2) it
<S
was
S\ /FP/EN
inspired
EN> /AG
by
AG> /PC
the
<D
writings
D\PC> FP>
.
S EN
G
PC
D
FP
In Table 1, the dependency bracketing is com-
bined with a common textual format for morpho-
logical analyses. In this format, the base forms are
defined over the alphabet of orthographical symbols
? whereas the morphological symbols and syntactic
categories are multi-character symbols that belong,
respectively, to the alphabets ? and ?. In addition,
there is a token boundary symbol #.
Table 1: One morpho-syntactic analysis of a sentence
1 i t PRON NOM SG3 <S #
2 b e V PAST SG13 S\ /FP /EN #
3 i n s p i r e EN EN> /AG #
4 b y PREP AG> /PC #
5 t h e DET SG/PL <D #
6 w r i t i n g N NOM PL D\ PC> #
7 . PUNCT FP> #
Depending on the type of the languages, one or-
thographical word can be split into several parts such
as the inflectional groups in Turkish (Oflazer, 2003).
In this case, a separate word-initial token boundary
can be used to separate such parts into lines of their
own.
The current dependency bracketing captures pro-
jective and weakly non-projective (1-planar) trees
only, but an extended encoding for 2-planar and
multi-planar dependency trees seems feasible (Yli-
Jyra?, 2012):
2.2 The Valid Trees
We are now going to define precisely the semantics
of the syntactic grammar component using finite-
state relations.
The finite-state languages will be defined over a
finite alphabet ? and they include all finite subsets of
the universal language ??. The (binary) finite-state
relations are defined over ?? and include all finite
subsets of ?? ? ??. In addition, they are closed un-
der the operations over finite-state languages L and
M and finite-state relations R and S according to
Table 2. The language relation Id(L) restricts the
identity relation to a language L. The composition
of language relations corresponds to the intersection
of their languages.
Table 2: The relevant closure properties
language relation meaning
LM RS concatenation
L? R? (Kleene) star
L+ R+ (Kleene) plus
L ?M R ? S union
Id(L) language relation
Id?1(R) L for R = Id(L)
L?M Id(L)?Id(M) set difference
L?M cross product
R|L input restriction
R ? S composition
R?1 inverse
Proj1(R) Id(the input side of R)
Proj2(R) Id(the output side of R)
For notational convenience, the empty string is
denoted by ?. A string x is identified with the sin-
gleton set {x}.
The syntactic component of the grammar defines
a set of parse strings where the bracketing is a valid
dependency tree. In these parses, there is no mor-
phological information. One way to express the set
is to intersect a set of constraints as in (Yli-Jyra?,
2005). However, the contracting dependency parser
expresses the Id relation of the set through a compo-
sition of simple finite-state relations:
Synt = Proj1(Abst ?R ? ... ?R? ?? ?
t
?Root), (1)
Root = Id(#). (2)
In (1), Abst is a relation that removes all non-
syntactic information from the strings,
Abst = (Id(?) ? Id(#) ? Delete)?, (3)
Delete = {(x, ?) | x ? ? ??}, (4)
110
and R is a relation that performs one layer of con-
tractions in dependency bracketing.
R = (Id(?) ? Id(#) ? Left ? Right)?, (5)
Left = {(<? # ?\, ?) | <?, ?\ ? ?}, (6)
Right = {(/? # ?>, ?) | /?, ?> ? ?}. (7)
The parameter t determines the maximum number
of layers of dependency links in the validated brack-
etings. The limit of Synt as t approaches ? is not
necessarily a finite-state language, but it remains
context-free because only projective trees are as-
signed to the sentences.
2.3 The Big Picture
We are now ready to embed the contraction based
grammar into the bigger picture.
Let x ? ?? be an orthographical string to be
parsed. Assume that it is segmented into n tokens.
The string x is parsed by composition of four rela-
tions: the relation {(x, x)}, the lexical transducer
(Morph), the morphology-syntax interface (Iface),
and the syntactic validator Synn?1.
Parses(x) = Id(x) ?Morph ? Iface ? Synn?1. (8)
The language relation Proj2(Parses(x)) encodes
the parse forest of the input x.
In practice, the syntactic validator Synn?1 cannot
be compiled into a finite-state transducer due to its
large state complexity. However, when each copy of
the contracting transducer R in (1) is restricted by
its admissible input-side language, a compact rep-
resentation for the input-side restriction (Synn?1)|X
where X = Proj2(Id(x)?Morph?Iface) is computed
efficiently as described in (Yli-Jyra?, 2012).
3 The Grammar Formalism
In the parser, the linguistic knowledge is organized
into Morph (the morphology) and Iface (the lexical-
ized morphology-syntax interface), while Syn has
mainly a technical role as a tree validator. Imple-
menting the morphology-syntax interface is far from
an easy task since it is actually the place that lexical-
izes the whole syntax.
3.1 Gaifman?s Dependency Rules
Gaifman?s legacy notation (Gaifman, 1965; Hays,
1964) for dependency grammars assigns word forms
to a finite number of potential morpho-syntactic cat-
egories that relate word forms to their syntactic func-
tions. The words of particular categories are then
related by dependency rules:
X0(Xp, . . . , X?1,*, X1, . . . , Xm). (9)
The rule (9) states that a word in category X0 is the
head of dependent words in categories Xp, . . . , X?1
before it and words in categories X1, . . . , Xm after
it, in the given order. The rule expresses, in a cer-
tain sense, the frame or the argument structure of the
word. Rule X(*) indicates that the word in category
X can occur without dependents.
In addition, there is a root rule *(X) that states
that a word in category X can occur independently,
that is, as the root of the sentence.
In the legacy notation, the distinction between
complements and adjuncts is not made explicit, as
both need to be listed as dependents. To compact the
notation, we introduce optional dependents that will
be indicated by categories Xp?, . . . , X?1? and cat-
egories X1?, . . . , Xm?. This extension potentially
saves a large number of rules in cases where sev-
eral dependents are actually adjuncts, some kinds of
modifiers.3
3.2 The Decomposed Categories
In practice, atomic morpho-syntactic categories are
often too coarse for morphological description but
too refined for convenient description of syntactic
frames. A practical description requires a more ex-
pressive and flexible formalism.
In our new rule formalism, each morpho-syntactic
category X is viewed as a combination of a morpho-
logical category M (including the information on
the lexical form of the word) and a syntactic cate-
gory S. The morphological category M is a string
of orthographical and morphological feature labels
while S is an atomic category label.
The morphological category M0 and the syntactic
category S0 are specified for the head of each de-
pendency rule. Together, they specify the morpho-
syntactic category (M0, S0). In contrast, the rule
specifies only the syntactic categories Sp, . . . , S?1,
3Optional dependents may be a worthwhile extension even
in descriptions that treat the modified word as a complement of
a modifier.
111
and S1, . . . , Sm of the dependent words and thus
delegates the selection of the morphological cate-
gories to the respective rules of the dependent words.
The categories Sp, . . . , S?1, and S1, . . . , Sm may
again be marked optional with the question mark.
The rules are separated according to the direction
of the head dependency. Rules (10), (11) and (12)
attach the head to the right, to the left, and in any di-
rection, respectively. In addition, the syntactic cate-
gory of the root is specified with a rule of the form
(13).
? S0(Sp, . . . , S?1,*[M0], S1, . . . , Sm), (10)
? S0(Sp, . . . , S?1,*[M0], S1, . . . , Sm), (11)
S0(Sp, . . . , S?1,*[M0], S1, . . . , Sm), (12)
*(S0). (13)
The interpretations of rules (10) - (12) are similar to
rule (9), but the rules are lexicalized and directed.
The feature string M0 ? (??%?? ? ??)?? defines
the relevant head word forms using the features pro-
vided by Morph. The percent symbol (%) stands for
the unspecified part of the lexical base form.
The use of the extended rule formalism is illus-
trated in Table 3. According to the rules in the table,
a phrase headed by preposition by has three uses:
an adjunctive preposition (P), the complement of a
phrasal verb (by), or the agent of a passive verb (AG).
Note that the last two uses correspond to a fully lexi-
calized rule where the morphological category spec-
ifies the lexeme. The fourth rule illustrates how mor-
phological features are combined in N NOM SG and
then partly propagated to the atomic name of the
syntactic category.
Table 3: Extended Gaifman rules
1 P (*[% PREP], PC) % prepos.
2 by (*[b y PREP], PC) % phrasal
3 AG (*[b y PREP], PC) % agent
4 sgS (D?, M?, *[% N NOM SG], M?) % noun
3.3 Making a Gaifman Grammar Robust
Dependency syntax describes complete trees where
each node is described by one of the dependency
rules. Sometimes, however, no complete tree for an
input is induced by the linguistically motivated de-
pendency rules. In these cases, only tree fragments
can be motivated by the linguistic knowledge. To
glue the fragments together, we interpret the roots
of fragments as linear successors ? thus dependents
? for the word that immediately precedes the frag-
ment.
The link to a linear successor is indicated with a
special category ++ having a default rule ++(*). Since
any word can act as a root of a fragment, every word
is provided with this potential category. In addi-
tion, there is, for every rule (12), an automatic rule
++(Sp, . . . , S?1,*[M ], S1, . . . , Sm) that allows the
roots of the fragments to have the corresponding de-
pendents. Similar automatic rules are defined for the
directed rules.
The category ++ is used to indicate dependent
words that do not have any linguistically motivated
syntactic function. The root rule *(++) states that
this special category can act as the root of the whole
dependency tree. In addition to the root function ex-
pressed by that rule, an optional dependent ++? is
appended to the end of every dependency rule. This
connects fragments to their left contexts.
With the above extensions, all sentences will have
at least one complete tree as a parse. A parse with
some dependents of the type ++ are linguistically in-
ferior to parses that do not have such dependents or
have fewer of them. Removing such inferior analy-
ses from the output of the parser is proposed in Sec-
tion 4.
3.4 The Formal Semantics of the Interface
Let there be r dependency rules. For each rule i,
i ? {1, ..., r} of type (10), let
Fi = M0, (14)
Gi = S?1\ . . . Sp\ S0> /Sm.../S1, (15)
where S?1\, . . . , Sp\, S0>, /Sm, . . . , /S1 ? ?. For
each rule of type (11), S0> in (15) is replaced with
<S0. Rules with optional dependents are expanded
into subrules, and every undirected rule (12) splits
into two directed subrules.
In (16), Iface is a finite-state relation that injects
dependency brackets to the parses according to the
112
dependency rules.
Iface = Intro ? Chk, (16)
Intro = (Id(????)(????)Id(#))?, (17)
Chk = Proj1(Match ? Rules), (18)
Rules = Id (?ri=1FiGi#)? . (19)
Match = (Id(??) Mid Id(??) Tag? Id(#))? (20)
Mid = Id(?) ? (???%), (21)
Tag = Id(?) ? (???). (22)
Iface is the composition of relations Intro and Chk.
Relation Intro inserts dependency brackets between
the morphological analysis of each token and the fol-
lowing token boundary. Relation Chk verifies that
the inserted brackets are supported by dependency
rules that are represented by relation Rules.
In order to allow generalizations in the specifi-
cation of morphological categories, the relation In-
tro does not match dependency rules directly, but
through a filter. This filter, Match, optionally re-
places the middle part of each lexeme with % and ar-
bitrary morphological feature labels with the empty
string.
In addition to the dependency rules, we need to
define the semantics of the root rules. Let H be the
set of the categories having a root rule. The category
of the root word will be indicated in the dependency
bracketing as an unmatched bracket. It is checked by
relation Root = Id(H#) that replaces Root = Id(#)
in the composition formulas (1) .
3.5 An Efficient Implementation
The definition of Iface gives rise to a naive parser
implementation that is based on the formula
Parses(x) = MIx ? Chk ? Synn?1, (23)
MIx = Id(x) ?Morph ? Intro. (24)
The naive implementation is inefficient in practice.
The main efficiency problem is that the state com-
plexity of relation Chk can be exponential to the
number of rules. To avoid this, we replace it with
Chkx, a restriction of Chk. This restriction is com-
puted lazily when the input is known.
Parses(x) = MIx ? Chkx ? Synn?1, (25)
Chkx = Proj1(Matchx?Rules) (26)
Matchx = Proj2(MIx) ?Match. (27)
In this improved method, the application of Iface de-
mands only linear space according to the number of
rules. This method is also fast to apply to the input,
as far as the morphology-syntax interface is con-
cerned. Meanwhile, one efficient implementation of
Synn?1 is already provided in (Yli-Jyra?, 2012).
4 The Most Specific Parse
The parsing method of (Yli-Jyra?, 2012) builds the
parse forest efficiently using several transducers,
but there is no guarantee that the whole set of
parses could be extracted efficiently from the com-
pact representation constructed during the recogni-
tion phase. We will now assume, however, that
the number of parses is, in practice, substantially
smaller than in the theoretically possible worst case.
Moreover, it is even more important to assume that
the set of parses is compactly packed into a finite au-
tomaton. These two assumptions let us proceed by
refining the parse forest without using weights such
as in (Yli-Jyra?, 2012).
In the following, we restrict the parse forest to
those parses that have the smallest number of ?linear
successor? dependencies (++). The number of such
dependencies is compared with a finite-state relation
Cp ? (??{#})??(??{#})? constructed as follows:
?? = ?? {++>}, (28)
Cp = Mapi?(Id(++>?)(??++>)+)?Map?1i , (29)
Mapi = (Id(++>) ? (????))?. (30)
In practice, the reduction of the parse forest is pos-
sible only if the parse forest Proj2(Parses(x)) is rec-
ognized by a sufficiently small finite-state automa-
ton that can then be operated in Formula (33). The
parses that minimize the number of ?linear succes-
sor? dependencies are obtained as the output of the
relation Parses?(x).
Parses?(x) = MIx ? Chkx ? Tx,1, (31)
Tx,0 = Proj2(Parses(x)), (32)
Tx,1 = Tx,0 ? Proj2(Tx,0 ? Cp ? Tx,0). (33)
This restriction technique could be repeatedly ap-
plied to further levels of specificity. For example,
lexically motivated complements could be preferred
over adjuncts and other grammatically possible de-
pendents.
113
5 Evaluation and Discussion
5.1 Elegance
We have retained most of the elegancy in the
contracting finite-state dependency parser (Yli-Jyra?,
2012). The changes introduced in this paper are
modular and implementable with standard opera-
tions on finite-state transducers.
Our refined design for a parser can be imple-
mented largely in similar lines as the general ap-
proach (Yli-Jyra?, 2012) up to the point when the
parses are extracted from the compact parse forest.
Parsing by arc contractions is closely related
to the idea of reductions with restarting automata
(Pla?tek et al, 2003).
5.2 Coverage
The representation of the parses can be extended to
handle word-internal token boundaries, which facil-
itates the adequate treatment of agglutinative lan-
guages, cf. (Oflazer, 2003).
The limit for nested brackets is based on the psy-
cholinguistic reality (Miller, 1956; Kornai and Tuza,
1992) and the observed tendency for short depen-
dencies (Lin, 1995; Eisner and Smith, 2005) in nat-
ural language.
The same general design can be used to produce
non-projective dependency analyses as required by
many European languages. The crossing dependen-
cies can be assigned to two or more planes as sug-
gested in (Yli-Jyra?, 2012). 2-planar bracketing al-
ready achieves very high recall in practice (Go?mez-
Rodr??guez and Nivre, 2010).
5.3 Ambiguity Management
Oflazer (2003) uses the lenient composition opera-
tion to compute the number of bottom-up fragments
in incomplete parses. The current solution improves
above this by supporting gapped fragments and un-
restricted counting of the graph components.
Like in another extended finite-state approach
(Oflazer, 2003), the ambiguity in the output of our
parsing method can be reduced by removing parses
with high total link length and by applying filters
that enforce barrier constraints to the dependency
links.
5.4 Computational Complexity
Thanks to dynamically applied finite-state opera-
tions and the representation of feature combinations
as strings rather than regular languages, the depen-
dency rules can be compiled quickly into the trans-
ducers used by the parser. For example, the actual
specifications of dependency rules are now com-
piled into a linear-size finite-state transducer, Chk.
The proposed implementation for the morphology-
syntax interface is, thus, a significant improvement
in comparison to the common approach that com-
piles and combines replacement rules into a single
transducer where the morphological conditions of
the rules are potentially mixed in a combinatorial
manner.
Although we have started to write an experimental
grammar, we do not exactly know how many rules
a mature grammar will contain. Lexicalization of
the rules will increase the number of rules signifi-
cantly. The number of syntactic categories will in-
crease even more if complements are lexicalized.
5.5 Robustness
In case the grammar does not fully disambiguate or
build a complete dependency structure, the parser
should be able to build and produce a partial anal-
ysis. (In interactive treebanking, it would be useful
if an additional knowledge source, e.g. a human, can
be used to provide additional information to help the
parser carry on the analysis to a complete structure.)
The current grammar system indeed assumes that
it can build complete trees for all input sentences.
This assumption is typical for all generative gram-
mars, but seems to contradict the requirement of ro-
bustness. To support robust parsing, we have now
proposed a simple technique where partial analyses
are connected into a tree with the ?linear succes-
sor? links. The designed parser tries its best to avoid
these underspecific links, but uses the smallest pos-
sible number of them to connect the partial analyses
into a tree if more grammatical parses are not avail-
able.
5.6 Future Work
Although Oflazer (2003) does not report significant
problems with long sentences, it may be difficult to
construct a single automaton for the parse forest of a
114
sentence that contains many words. In the future,
a more efficient method for finding the most spe-
cific parse from the forest can be worked out us-
ing weighted finite-state automata. Such a method
would combine the approaches of the companion pa-
per (Yli-Jyra?, 2012) and the current paper.
It seems interesting to study further how the speci-
ficity reasoning and statistically learned weights
could complement each other in order to find the
best analyses. Moreover, the parser can be modified
in such a way that debugging information is pro-
duced. This could be very useful, especially when
learning contractions that handle the crossing depen-
dencies of non-projective trees.
A dependency parser should enable the building
of multiple types of analyses, e.g. to account for
syntactic and semantic dependencies. Also adding
more structure to the syntactic categories could be
useful.
6 Conclusions
The current theoretical work paves the way for a full
parser implementation. The parser should be able to
cope with large grammars to enable efficient devel-
opment, testing and application cycles.
The current work has sketched an expressive and
compact formalism and its efficient implementation
for the morphology-syntax interface of the contract-
ing dependency parser. In addition, the work has
elaborated strategies that help to make the grammar
more robust without sacrificing the optimal speci-
ficity of the analysis.
Acknowledgments
The research has received funding from the
Academy of Finland under the grant agreement #
128536 and the FIN-CLARIN project, and from the
European Commission?s 7th Framework Program
under the grant agreement # 238405 (CLARA).
References
Jason Eisner and Noah A. Smith. 2005. Parsing with
soft and hard constraints on dependency length. In
Proceedings of the International Workshop on Parsing
Technologies (IWPT), pages 30?41, Vancouver, Octo-
ber.
David Elworthy. 2000. A finite state parser with de-
pendency structure output. In Proceedings of Sixth In-
ternational Workshop on Parsing Technologies (IWPT
2000, Trento, Italy, February 23-25. Institute for Sci-
entific and Technological Research.
Haim Gaifman. 1965. Dependency systems and
phrase-structure systems. Information and Control,
8:304?37.
Carlos Go?mez-Rodr??guez and Joakim Nivre. 2010. A
transition-based parser for 2-planar dependency struc-
tures. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
1492?-1501, Uppsala, Sweden, 11-16 July.
David G. Hays. 1964. Dependency theory: A formalism
and some observations. Language, 40:511?525.
Fred Karlsson, Atro Voutilainen, Juha Heikkia?, and
Arto Anttila, editors. 1995. Constraint Grammar:
a Language-Independent System for Parsing Unre-
stricted Text, volume 4 of Natural Language Process-
ing. Mouton de Gruyter, Berlin and New York.
Andra?s Kornai and Zsolt Tuza. 1992. Narrowness, path-
width, and their application in natural language pro-
cessing. Discrete Applied Mathematics, 36:87?92.
Dekang Lin. 1995. A dependency-based method for
evaluating broad-coverage parsers. In Proceedings
of the Fourteenth International Joint Conference on
Artificial Intelligence, IJCAI 95, Montre?al Que?bec,
Canada, August 20-25, 1995, volume 2, pages 1420?
1425.
George A. Miller. 1956. The magical number seven,
plus or minus two: Some limits on our capacity
for processing information. Psychological Review,
63(2):343?355.
Kemal Oflazer. 2003. Dependency parsing with an ex-
tended finite-state approach. Computational Linguis-
tics, 29(4):515?544.
Martin Pla?tek, Marke?ta Lopatkova?, and Karel Oliva.
2003. Restarting automata: motivations and applica-
tions. In M. Holzer, editor, Workshop ?Petrinetze? and
13. Theorietag ?Formale Sprachen und Automaten?,
pages 90?96, Institut fu?r Informatik, Technische Uni-
versita?t Mu?nchen.
Anssi Yli-Jyra?. 2005. Approximating dependency
grammars through intersection of star-free regular lan-
guages. International Journal of Foundations of Com-
puter Science, 16(3).
Anssi Yli-Jyra?. 2012. On dependency analysis via con-
tractions and weighted FSTs. In Diana Santos, Krister
Linde?n, and Wanjiku Ng?ang?a, editors, Shall we Play
the Festschrift Game? Essays on the Occasion of Lauri
Carlson?s 60th Birthday. Springer-Verlag, Berlin.
115
