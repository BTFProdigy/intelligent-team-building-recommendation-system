Semiautomatic labelling of semantic features 
Arantza D?az de Ilarraza, Aingeru Mayor and Kepa Sarasola 
IXA Group. Computer Science Faculty. University of the Basque Country 
Donostia/San Sebastian. The Basque Country 
jipdisaa/jibmamaa/jipsagak@si.ehu.es 
 
Abstract 
This paper presents the strategy and design 
of a highly efficient semiautomatic method for 
labelling the semantic features of common 
nouns, using semantic relationships between 
words, and based on the information extracted 
from an electronic monolingual dictionary. The 
method, that uses genus data, specific relators 
and synonymy information, obtains an accuracy 
of over 99% and a scope of 68,2% with regard to 
all the common nouns contained in a real corpus 
of over 1 million words, after the manual 
labelling of only 100 nouns. 
1 Introduction 
Semantic information is essential in a lot of 
NLP applications. In our case, the feature 
[?animate] is necessary to disambiguate between 
the possible Basque translations for the English 
preposition "of" and the Spanish preposition 
"de", when referring to location or possession. 
This ambiguity appears very often when 
translating to Basque [D?az de Ilarraza et al, 
2000]. A complete manual labelling of semantic 
information would prove extremely expensive.  
This study aims to outline the strategy and 
design of a semiautomatic method for labelling 
semantic features of common nouns in Basque, 
expanding and improving the idea outlined in 
[D?az de Ilarraza et al 2000]. Due to the poor 
results obtained, this study dismissed the 
possibility of an initial approach aimed at 
extracting the information corresponding to the 
(?animate) feature automatically from corpus. 
Instead, an alternative idea was proposed, i.e. 
that of using semantic relationships between 
words extracted from the Basque monolingual 
dictionary Euskal Hiztegia (Sarasola 1996). In 
this context, we used genus data and specific 
relators, together with a few words manually 
labelled, to extract the information 
corresponding to the (?animate) feature. The 
results obtained were very promising: 8,439 
common nouns were labelled automatically after 
the manual labelling of just 100.  
This paper describes the work carried out with 
the aim of expanding this idea this idea through 
the inclusion of information about synonymy, 
repeating the automatic process iteratively in 
order to obtain better results  and, monitoring the 
reliability of the labelling of each individual 
noun. After studying the ideal relationship 
between the manual part of the operation and the 
scope of the automatic process, we generalised 
the process in order to adapt it to other semantic 
features. We obtained very satisfactory results 
considering the labelling of common nouns 
contained in the dictionary: for the [?animate] 
feature, we labelled 12,308 nouns with an 
accuracy of 99.2%, after the manual labelling of 
only 100.  
 This paper is organised as follows: section 2 
presents the semantic relationships between 
words extracted from the Basque monolingual 
dictionary, and used by our semiautomatic 
labelling method. The method itself is described 
in section 3. The experiments carried out with 
the aim of optimising the efficiency of the 
method are described in section 4, and section 5 
outlines the accuracy and scope of the labelling 
process for the [?animate] semantic feature. 
Finally, section 6 describes how the method was 
generalised to cover other semantic features. The 
study finishes by underlining the results obtained 
and suggesting future research. 
2 Superficial semantic relationships 
between words in dictionaries  
According to Smith and Maxwell, there are 
three basic methods for defining a lexical entry 
[Smith and Maxwell., 1980]: 
? By means of a synonym: a word with the 
same sense as the lexical entry. 
finish. conclude(sin), terminate(sin) 
? By means of a classical definition: ?genus + 
differentia?. The genus is the generic term or 
 Figure 1. Implementation of the automatic process using genus and relater information 
procedure Labelling_of_the_dictionary { 
foreach (common Noun of the dictionary) { 
(Label, Reliability) = Find_its_label (Noun)  }   
} 
procedure Find_its_label (Noun) { 
foreach (Sense with Noun Genus/Relator) { 
if (Genus/Relator labelled){ Sense.Label  = Genus/Relator.Label 
 Sense.Reliability = Genus/Relator.Reliability 
} 
   else {(  Sense.Label, 
 Sense.Reliability) = Find_its_label(Genus) } #recursion 
if (Noun.Label != Sense.Label) { Noun.Label = [?] } 
   else  { Noun.Label =  Sense.Label } 
} # end foreach 
Noun.Reliability = ? Reliability labelled senses / number of senses 
return (Noun.Label, Noun.Reliability) 
}  
hyperonym, and the lexical entry a more 
specific term or hyponym.  
aeroplane. vehicle (genus) that can fly 
(differentia) 
? By means of specific relators, that will often 
determine the semantic relationship between 
the lexical entry and the core of the 
definition. 
horsefly. Name given to (relator) certain 
insects (related term) of the Tabanidae family  
One method for identifying the semantic 
relationship that exists between different words 
is to extract the information from monolingual 
dictionaries.  
Agirre et al (2000) applied it for Basque, 
using the definitions contained in the 
monolingual dictionary Euskal Hiztegia. We use 
for our research the information about genus, 
specific relators and synonymy extracted by 
them. 
3 Semiautomatic labelling using genus, 
specific relators and synonymy  
In order to label the common nouns that 
appear in the dictionary, we used the definitions 
of the 26,461 senses of the 16,380 common 
nouns defined by means of genus/relators 
(14,569) or synonyms (11,892).  
The experiment was carried out as follows: 
firstly, we used the information relative to genus 
and specific relators to extract the information 
regarding the [?animate] feature (3.1). 
Subsequently, we also incorporated the 
information relative to synonymy (3.2). Finally, 
we repeated the automatic process iteratively in 
order to obtain better results (3.3). An example 
of the whole process is given in section 3.4. 
3.1 Labelling using information relative to 
genus and specific relators 
Our strategy consisted of manually labelling 
the semantic feature for a small number of words 
that appear most frequently in the dictionary as 
genus/relators. We used these words to infer the 
value of this feature for as many other words as 
possible. 
This inference is possible because in the 
hyperonymy/hyponymy relationship, that 
characterises the genus, semantic attributes are 
inherited. For example, if ?langile? (worker) has 
the [+animate] feature, all its hyponyms (or in 
other words, all the words whose hyperonym is 
?langile?) will have the same [+animate] feature. 
Certain genus are ambiguous, since they 
contain senses with opposing semantic features. 
For example ?buru? (head/boss) has the [-
animate] feature when it means ?head? and the 
[+animate] feature when it means ?boss?. The 
semantic feature of the sense defined can also be 
deduced from some specific relators. In this way, 
the semantic feature of words whose relator is 
?nolakotasuna? (quality) would be [-animate], 
such as in the case of ?aitatasuna? (paternity), for 
example. There are also certain relators that offer 
no information, such as ?mota? (type), ?izena? 
(name), and ?banako? (unit, individual). 
We used four types of labels during the 
manual operation: [+], [-], [?] and [x]. [?] for 
ambiguous cases; and [x] for relators that do not 
offer information regarding this semantic feature. 
 In order to establish the reliability of the 
automatic labelling process for a particular noun, 
we considered the number of senses labelled, 
taking into account the reliability of the labels of 
the genus (or relator) that provided the 
information. The result was calculated as 
follows:   
 Rel_noun = ? Rel_genus_per_sense / n_senses 
During manual labelling, we assigned 
reliability value 1 to all labels, since all the 
senses of these nouns are taken into account.  
Figure 1 shows the algorithm used. For each 
common noun defined in the dictionary, we take, 
one by one, all their senses containing genus or 
relator, assigning in each case the first label 
associated to a genus or relator in the hierarchy 
of hyperonyms. When the sign of all the labels 
are coincident we use it to label the entry, in 
other case, we use the label [?]. In all cases, their 
reliability is calculated.  
When we detect a cycle, the search is 
interrupted and the sense to be tagged remains 
unlabelled.  
3.2 Labelling using synonymy information  
Labelling using genus and relators can be 
expanded by using synonymy. Since the 
synonymy relationship shares semantic features, 
we can deduce the semantic label of a sense if 
we know the label of its synonymes.  
Therefore, the information obtained during the 
previous phase can now be used to label new 
nouns. It also serves to increase the reliability of 
nouns already been labelled thanks to the genus 
information of some of their senses. If the 
synonymy information provided corroborates the 
genus information, the noun?s reliability rating 
increases. If, on the other hand, the new label 
does not coincide with the previous one, a 
special label: [?] is assigned to the noun 
indicating this ambiguity.  
The automatic process using synonymy was 
implemented in the same way as in the previous 
process. 
3.3 Iterative repetition of the automatic 
process  
Our next idea was to repeat the process; since 
the information gathered so far using synonymy 
may also be applied hereditarily through the 
genus? hyperonymy relationship. 
We therefore repeated the process from the 
beginning, trying to label all the senses of the 
nouns that had not been fully labelled during the 
initial operations, by using the information 
contained in the senses of the nouns that had 
been fully labelled (reliability 1). 
As with the initial operation, we first used 
information about genus and relators, and then, 
synonymy.  
This process can be repeated any number of 
times, thereby labelling more and more words 
while increasing the reliability of the labelling 
itself. However, repetition of the process also 
increases the number of words labelled as 
ambiguous [?], since more senses are labelled 
during each iteration, thereby increasing the 
chances of inconsistencies. As we shall see, this 
iterative process improves the results 
logarithmically up to a certain number of 
repetitions, after which it has no further 
advantageous effects.  
3.4 Example of semiautomatic labelling for 
the [?animate] feature 
The 100 words that are most frequently used 
as genus (g) or relators (r) were labelled 
manually for the [?animate] feature, as shown in 
table 2 (tables 3, 4 and 5 contain the Basque 
words processed during the explained operation, 
along with their English translation in italics). 
Noun  ?anim Freq Gen/rel 
nolakotasun (quality) - 531   Relator 
pertsona (person) + 377   Genus   
multzo (collection)  - 362   Relator 
txikigarri (collection)  x  213 Relator 
zati (part) - 230   Relator 
gai (material)  - 202   Genus 
tresna (instrument)  - 188   Genus 
...     
buru (head) ? 54 Genus 
Table 2. Manual labelling 
We shall now trace the implementation of the 
automatic labelling process for certain nouns.  
Table 3 shows the results of the first labelling 
process using information about genus and 
relators. The words printed in bold in the results 
column are nouns that were labelled during the 
manual labelling process. We can see how the 
noun ?babesgarri? (protector) is labelled as [-] 
thanks to the information provided by the relator 
of its only sense, which was manually labelled. 
Th
In
(
r
n
t
i
h
r
(
w
g
a
N
b
(
a
(
  
a
(
i
(
  
g
(
  
g
(
e
(
  
a
(
a
(
  
a
(
  
f
(
i
(
j
(
z
(oun N. sense N. genus Result of process using genus and relators  Lab Rel. 
abesgarri 
protector)   
1 1 (zer[-]1) 
(thing)   
[-] 1 
rmadura 
armour) 
3 3 (multzo[-]1) (babesgarri[-]1)(soineko[]) 
(collection) (protector)     (garment)   
[-] 0.66 
          
ma 
mother) 
5 3 (emakume[+]1)(animalia[+]1)(eme[]) 
(woman)      (animal)      (female) 
[+] 0.4 
turburu 
spring)   
3 1 (aterabide[]) 
(outlet)   
[] 0 
          
ertaera 
event)   
1 1 (gauza[-]1) 
(thing) 
[-] 1 
          
iltzape 
prison)   
2 1 (toki[-]1) 
(place)   
[-] 0.5 
spetxe 
jail) 
2 2 (eraikuntza[-]1)(leku[-]1) 
(construction)  (place) 
[-] 1 
          
diskide 1 1 (pertsona[+]1) [+] 1 e noun therefore has a reliability rating of 1. 
 the same way, 2 of the 3 senses of ?armadura? 
1. The reliability rating obtained for ?zinismo? 
was therefore 0.87 (f=(1+0.75)/2=0.87). 
friend)   (person) 
diskidetzako 
friend)   
1 1 (lagun[]) 
(companion) 
[] 0 
          
pio 
celery) 
2 2 (jateko[])  (landare[-]1) 
(food)      (plant) 
[-] 0.5 
          
ilosofia 
philosophy) 
2 2 (jakintza[-]1)(multzo[-]1) 
(knowledge)   (collection)   
[-] 1 
kusgune 
viewpoint)   
2 1 (gune[-]1) 
(point)   
[-] 0.5 
arrera 
attitude) 
2 2 (era[-]1)(ikusgune[-]0.5) 
(way)    (viewpoint)   
[-] 0.75 
inismo 
cynicism) 
2 2 (filosofia[-]1)(jarrera[-]0.75 ) 
(philosophy)   (attitude) 
[-] 0.87 
Table 3. Result of automatic labelling using genus and relator information armour) had coincident labels, thereby giving a 
eliability rating of 0.66 (f=(1+1)/3=0.66). The 
oun ?ama? (mother) was labelled as [+], thanks 
o the information about genus and relator of 2 of 
ts 3 senses, out of a total of 5 (the remaining two 
ave synonymy information). The reliability 
ating was therefore calculated as 0.4 
f=(1+1)/5=0.4). The word ?zinismo? (cynicism) 
as labelled as [-] thanks to the fact that the 
enus of its 2 senses were both labelled as such, 
lthough one did not have a reliability rating of 
Table 4 shows some examples of the process 
using synonym information.  
As we can see, ?iturburu? (spring), which the 
previous process had not managed to tag, is now 
labelled as [-] thanks to the synonymy 
information associated to one of the two senses. 
The resulting reliability rating is 0.06 
(f=0.2/3=0.06). If we look at the term ?ama?, 
which had previously been labelled as [+] on the 
basis of genus information, we see that the 
synonyms of the two senses that use synonymy 
Noun Genus lab. N. sens N. syn Results of the process using synonymy Lab. Relia. 
iturburu 
(spring)   
[] 3 2 (etorki[])  (hasiera[-]0.20) 
(origin)    (start)   
[-] 0.06 
ama 
(mother) 
[+] 5 2 (iturburu[-])(jatorri[-]) 
(spring)     (origin)   
[?] 1 
            
gertakuntza 
(event)   
1 1 (gertaera[-]1) 
(happening)   
[-] 1 
lagun 
(companion) 
1 1 (adiskide[+]1) 
(friend) 
[+] 1 
jateko 
(food)   
1 1 (janari[-]1) 
(food) 
[-] 1 
            
giltzape 
(prison)   
[-] 2 1 (espetxe[-]1) 
(jail) 
[-] 1 
ikusgune 
(viewpoint) 
[-] 2 1 (ikuspen[-]0.33) 
(view)   
[-] 0.66 
Table 4. Results of automatic labelling using synonymy information  
 Noun 
armadur
(armour
adiskid
(friend
apio 
(celery
  
ikusgun
(viewpo
jarrera
(attitu
zinismo
(cynici
informa
inconsi
The 
(compa
previou
thanks to synonym information. The words 
?giltzape? (prison) and ?ikusgune? (viewpoint), 
which had had one sense labelled on the basis of 
genus, now have both senses labelled. The 
reliability rating for ?ikusgune? is calculated as 
f=(1+0.33)/2=0.66. 
We then repeated the process using first the 
genus/relator information (table 4) followed by 
the synonymy information (table 5).   
The aim of this repetition was to label only 
those words that had not been fully labelled, 
using the information provided by the terms that 
had been and that had a reliability rating of 1, 
such as  ?babesgarri?, ?gertaera?, ?espetxe?, 
?adiskide?, ?filosofia?, ?ama?, ?gertakuntza?, 
?lagun?, ?jateko? and ?giltzape? (tables 4 and 5).  
This process succeeded in labelling the senses 
information. On the other hand, ?ikusgune? 
(viewpoint), ?jarrera? (attitude) and ?zinismo? 
(cynicism), did not benefit from this repetition.  
Following this process, we applied the 
synonymy information, thus completing the 
second iteration. The process may be repeated as 
many times as you wish.  
4 Experiments for optimising the 
efficiency of the method  
We carried out a number of different tests for 
the [?animate] semantic feature labelling the 2, 
5, 10, 50, 100, 125 and 150 words most 
frequently used as genus/relators, and repeating 
the whole process (using both genus and relator 
and synonymy information) 1, 2 and 3 times.   
The first 5 terms that appear most frequently 
0
2000
4000
6000
8000
10000
12000
14000
0 20 40 60 80 100 120 140
Manual labelling
Au
to
ma
tic
 la
be
llin
g
0
400
800
1200
1600
2000
Re
lat
ive
 in
cr
ea
se
  
Fig. 2. Automatic labelling and relative increase N. sense N. genus Result of process using genus and relators  Lab. Relia. 
a 
) 
3 3 (multzo[-]1)(babesgarri[-]1)(soineko[-]1) 
(collection)  (protector)     (garment)        
[-] 1 
etzako 
) 
1 1 (lagun[+]1) 
(companion) 
[+] 1 
) 
2 2 (jateko[-]1)(landare[-]1) 
(food)    (plant) 
[-] 1 
          
e 
int) 
2 2 (gune[-]1) 
(point)   
[-] 0.5 
 
de) 
2 2 (era[-]1)(ikusgune[-]0.5) 
(way)   (viewpoint) 
[-] 0.75 
 
sm) 
2 2 (filosofia[-]1)(jarrera[-]0.75 ) 
(philosophy)    (attitude)        
[-] 0.87 
Table 5. Results of the 2nd iteration of automatic labelling using genus and relator information 
tion are labelled as [-]. Due to this 
stency, the word is now labelled as [?]. 
terms ?gertakuntza? (event), ?lagun? 
nion) and ?jateko? (food), which 
sly only had one sense, are now labelled 
of ?armadura? (protector), ?adiskidetzako? 
(friend) and ?apio? (celery), previously left 
unlabelled, since their genus ?soineko? 
(garment), ?lagun? (friend) and ?jateko? (food) 
had been fully labelled using the synonym 
 as genus/relators are also the most productive 
during the automatic labelling process. From 
here on, the rate of increase gradually falls, until 
only 7 terms are labelled automatically for every 
noun labelled manually.  
On average, the first 2 nouns each enabled 
1840 terms to be labelled, the next 3 enabled 
1112 while the next 5 enabled only 250. After 
the hundredth noun, this average dropped to just 
7 new terms labelled automatically for every 
term labelled manually. These results are 
illustrated in figure 2. 
For efficiency reasons, we decided that when 
labelling other semantic features, we will label 
manually the 100 nouns most frequently used as 
genus/relators.  
In order to decide the number of iterations 
required for optimum results, we compared the 
results obtained after 1 to 10 iterations after 
manually labelling 100 nouns (Figure 3). 
Although no increase was recorded for the 
number of nouns with reliability rating 1 (i.e. 
with all senses labelled) after the 3rd iteration, the 
results for other reliability ratings continued to 
increase up until the 8th iteration, since as more 
and more information is gathered, new 
contradictions are generated and the number of 
ambiguous labels increases. When the results 
stabilise, we can affirm that all the available 
information has been used and the most accurate 
results possible with this manual labelling 
operation have been obtained. It is important to 
check that the process does indeed stabilise, and 
that it does so after a fairly low number of 
iterations (in this case, after 8). 
The repetition of the process does not 
significantly increase execution time. 10 
iterations of the automatic labelling process for 
the [?animate] feature takes just 11 minutes 33 
seconds using the total capacity of the CPU of a 
Sun Sparc 10 machine with 512 Megabytes of 
memory running at 360 MHz.  
We can therefore conclude that the method is 
viable and that, in the automatic process for 
other semantic features, the necessary iterations 
should be carried out until the results are totally 
stabilised. 
5 Accuracy and scope of the labelling 
process for the [?animate] feature   
In order to calculate the accuracy of the 
automatic labelling process, we took 1% of the 
labelled words as a sample and checked them 
manually. The results are shown in table 6. 
Reliability  
f=1 1>f>0.5 0.5>f>0 Total 
Accuracy 100% 100% 94% 99.2% 
Table 6. Accuracy of automatic labelling 
Although we initially planned to use only the 
labels with a reliability rating of 1, after seeing 
the accuracy of the others, we decided to use all 
the labels obtained during the process, thereby 
achieving an overall accuracy rating of 99.2%. 
We can affirm that the semiautomatic process 
designed and implemented here is very efficient.  
The scope for the automatic labelling of the 
[?animate] feature (table 7) was 75.14% of all 
the nouns contained in the dictionary (12,308 of 
16,380), having manually labelled 100 nouns and 
0
2000
4000
6000
8000
10000
12000
14000
0 2 4 6 8 10 12
Number of iterations
Au
to
ma
tic
 la
be
llin
g
Automatic labelling
f=1
1>f>0.5
0.5>f>0
?
 
Fig. 3. Automatic labelling according to number of iterations 
 carried out 8 iterations.  
Labelling  
f=1 1>f>0.5 0.5>f>0 
 
? 
6132 4513 1663 Auto 
lab. 12308 (75.14%) 
 
1301 
Table 7. Scope of the dictionary 
We also calculated the scope of this labelling 
in a real context, using the corpus gathered from 
the newspaper Euskaldunon Egunkaria, which 
contains 1,267,453 words and 311,901 common 
nouns, of which 7,219 are different nouns. Table 
8 shows the results ? a scope of 69.2% with 
regard to the nouns that appear in the text (47.6% 
of the total number of different common nouns 
contained in the corpus). In other words, after 
carrying out a very minor manual operation, we 
managed to label two out of every three nouns 
that appear in the corpus. Similarly, we noted 
that of the 500 nouns that appear most frequently 
in the corpus, 348 (69.6%) were labelled.  
 Appearances in 
the corpus 
Different 
nouns 
Total 311,901 7,219 
Labelled (68.2%) 212,887 (47.6%) 3,434 
[+] 17,408 356 
[-] 195,479 3,078 
Table 8. Scope of labelling within the corpus 
6 Generalisation for use with other 
semantic features  
Given the process?s efficiency, it can be 
generalised for use with other semantic features. 
To this end, we have adapted its implementation 
to enable the automatic process to be carried out 
on the basis of the manual labelling of any 
semantic feature.  
So far, we have carried out the labelling 
process for the [?animate], [?human] and 
[?concrete] semantic features. Table 12 shows 
the corresponding results.  
Label ?animate ?human ?concrete 
[+] 1,643 1,118 7,611 
[-] 10,665 10,684 1,143 
Total 12,308 11,802 8,754 
Table 12. Labelling data for different semantic 
features 
Conclusions 
We have presented a highly efficient 
semiautomatic method for labelling the semantic 
features of common nouns, using the study of 
genus, relators and synonymy as contained in the 
Euskal Hiztegia dictionary. The results obtained 
have been excellent, with an accuracy of over 
99% and a scope of 68,2% with regard to all the 
common nouns contained in a real corpus of over 
1 million words, after the manual labelling of 
only 100 nouns.   
As far as we know, no so method of semantic 
feature labelling has been described in the 
literature, although many authors [Pustejovsky, 
2000; Sheremetyeva & Nirenburg, 2000] claim 
the significance of semantic features in general, 
and [animacy] in particular, for NLP systems. 
One of the possible applications of these 
experiments is to enrich the Basque Lexical 
Database, EDBL, using the semantic information 
obtained.  
Acknowledgements 
The Basque Government Department of 
Education, Universities and Research sponsored 
this study.  
Bibliography 
Agirre E., Ansa O., Arregi X., Artola X., D?az de 
Ilarraza A., Lersundi M., Martinez D., Sarasola K., 
Urizak R., 2000, ?Extraction of semantic relations 
from a Basque monolingual dictionary using 
Constraint Grammar?, EURALEX?2000. 
Diaz de Ilarraza A., Lersundi M., Mayor A., Sarasola 
K., 2000. Etiquetado semiautom?tico del rasgo 
sem?ntico de animicidad para su uso en un sistema 
de traducci?n autom?tica. SEPLN?2000. Vigo.. 
Diaz de Ilarraza A., Mayor A., Sarasola K., 2000. 
?Reusability of Wide-Coverage Linguistic 
Resources in the Construction of a Multilingual MT 
System?.MT 2000. Exeter. UK. 
Pustejovsky J., 2000. ?Syntagmatic Processes?. 
Handbook of Lexicology and Lexicography. de 
Gruyter, 2000. 
Sheremetyeva S. and Nirenburg S., 2000. "Towards A 
Universal Tool for NLP Resource Acquisition". 
LREC2000. Greece.  
Smith, R.N., Maxwell, E., 1980, ?An English 
dictionary for computerised syntactic and semantic 
processing systems?, Proceedings of the 
International Conference on Computational 
Linguistics. 1980. 
Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 59?64,
Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language Processing
Strategies for sustainable MT for Basque:  
incremental design, reusability, standardization and open-source 
 I. Alegria, X. Arregi, X. Artola, A. Diaz de Ilarraza, G. Labaka,  
M. Lersundi, A. Mayor, K. Sarasola 
Ixa taldea.  
University of the Basque Country. 
i.alegria@ehu.es 
 
 
 
Abstract 
We present some Language Technology 
applications that have proven to be effec-
tive tools to promote the use of Basque, a 
European less privileged language. We also 
present the strategy we have followed for 
almost twenty years to develop those appli-
cations as the top of an integrated environ-
ment of language resources, language 
foundations, language tools and other ap-
plications. When we have faced a difficult 
task such as Machine Translation to 
Basque, our strategy has worked well. We 
have had good results in a short time just 
reusing previous works for Basque, reusing 
other open-source tools, and developing 
just a few new modules in collaboration 
with other groups. In addition, new reus-
able tools and formats have been produced.  
1 Introduction and Basque Language 
Basque is a highly inflected minority language 
with free order of sentence constituents. Machine 
Translation for Basque is thus both, a real need and 
a test bed for our strategy to develop NLP tools for 
Basque.          
Basque is an isolate language, and little is 
known of its origins. It is likely that an early form 
of the Basque language was already present in 
Western Europe before the arrival of the Indo-
European languages. 
Basque is an agglutinative language, with a rich 
flexional morphology. In fact for nouns, for 
example, at least 360 word forms are possible for 
each lemma. Each of the declension cases such as 
absolutive, dative, associative? has four different 
suffixes to be added to the last word of the noun 
phrase. These four suffix variants correspond to 
undetermined, determined singular, determined 
plural and ?close? determined plural.  
Basque is also an ergative-absolutive language. 
The subject of an intransitive verb is in the 
absolutive case (which is unmarked), and the same 
case is used for the direct object of a transitive 
verb. The subject of the transitive verb (that is, the 
agent) is marked differently, with the ergative case 
(shown by the suffix -k). This also triggers main 
and auxiliary verbal agreement. 
The auxiliary verb, which accompanies most 
main verbs, agrees not only with the subject, but 
with the direct object and the indirect object, if 
present. Among European languages, this 
polypersonal system (multiple verb agreement) is 
only found in Basque, some Caucasian languages, 
and Hungarian. The ergative-absolutive alignment 
is rare among European languages, but not 
worldwide. 
Although in last centuries Basque suffered 
continuous regression it still remains alive. The 
region in which Basque is spoken is smaller than 
what is known as the Basque Country, and the 
distribution of Basque speakers is not 
homogeneous there. The main reasons of this 
regression (Amorrortu, 2002) are that Basque was 
not an official language, and that it was out of 
educational system, out of media and out of 
industrial environments. Besides, the fact of being 
six different dialects made the wide development 
of written Basque difficult.  
However, after 1980, some of those features 
changed and many citizens and some local 
59
governments promote recovering of Basque 
Language.  
Today, Basque holds co-official language status 
in the Basque regions of Spain: the whole 
autonomous community of the Basque Country 
and some parts of Navarre. Basque has no official 
standing in the Northern Basque Country.   
In the past, Basque was associated with lack of 
education, stigmatized as uneducated, rural, or 
holding low economic and power resources. There 
is not such an association today; Basque speakers 
do not differ from Spanish or French monolinguals 
in any of these characteristics.  
Standard Basque, called Batua (unified) in 
Basque, was defined by the Academy of Basque 
Language (Euskaltzaindia) in 1968. At present, its 
morphology is completely standardized, but the 
lexical standardization process is still underway. 
Now this is the language model taught in most 
schools and used on some media and official 
papers published in Basque.  
Basque speakers are about 700,000, about 25% 
of the total population of the Basque Country, but 
they are not evenly distributed. Still the use of 
Basque in industry and specially in Information 
and Communication Technology is not 
widespread. A language that seeks to survive in the 
modern information society has to be present also 
in such field and this requires language technology 
products. Basque, as other minority languages, has 
to make a great effort to face this challenge (Petek, 
2000; Williams et al, 2001).  
2 Strategy to develop Human Language 
Technology (HLT) in Basque 
IXA group is a research Group created in 1986 by 
5 university lecturers in the computer science fac-
ulty of the University of the Basque Country with 
the aim of laying foundations for research and de-
velopment of NLP software mainly for Basque. 
We wanted to face the challenge of adapting 
Basque to language technology. 
Twenty one years later, now IXA is a group 
composed of 28 computer scientists, 13 linguists 
and 2 research assistants. It works in cooperation 
with more than 7 companies from Basque Country 
and 5 from abroad; it has been involved in the birth 
of two new spin-off companies; and it has devel-
oped more than seven language technology prod-
ucts. 
In recent years, several private companies and 
technology centers in the Basque Country have 
begun to get interested and to invest in this area. At 
the same time, more agents have come to be aware 
of the fact that collaboration is essential to the de-
velopment of language technologies for minority 
languages. One of the fruits of this collaboration 
are HIZKING21 (2002-2005) and ANHITZ (2006-
2008) projects. Both projects were accepted by the 
Government of the Basque Country in a new 
strategical research line called ?Language Infoen-
gineering?. 
At the very beginning, twenty years ago, our 
first goal was just to create a Spanish-Basque 
translation system, but after some preliminary 
work we realized that instead of wasting our time 
in creating an ad hoc MT system with small accu-
racy, we had to invest our effort in creating basic 
tools such as a morphological analyzer/generator 
for Basque, that could later be used to build not 
only a more robust MT system but also other ap-
plications. 
This thought was the seed to design our strategy 
to make progress in the adaptation of Basque to 
Language Technology. Basque language had to 
face up scarcity of resources and tools that could 
make possible its development in Language Tech-
nology at a reasonable and competitive rate. 
We presented an open proposal for making pro-
gress in Human Language Technology (Aduriz et 
al., 1998). Anyway, the steps proposed did not cor-
respond exactly with those observed in the history 
of the processing of English, because the high ca-
pacity and computational power of new computers 
allowed facing problems in a different way.  
Our strategy may be described in two points: 
1) The need for standardization of resources to 
be useful in different researches, tools and applica-
tions 
2) The need for incremental design and devel-
opment of language foundations, tools, and appli-
cations in a parallel and coordinated way in order 
to get the best benefit from them. Language foun-
dations and research are essential to create any tool 
or application; but in the same way tools and ap-
plications will be very helpful in the research and 
improvement of language foundations. 
Following this strategy, our steps on standardi-
zation of resources led us to adopt TEI and XML 
standards and also to define a methodology for 
60
stand-off corpus tagging based on TEI, feature 
structures and XML (Artola et al, 2005). 
In the same way, taking as reference our experi-
ence in incremental design and development we 
proposed four phases as a general strategy for lan-
guage processing. These are the phases defined 
with the products to be developed in each of them. 
1. Initial phase: Foundations. Corpus I (collection 
of raw text with no tagging mark). Lexical da-
tabase I (the first version could be a list of 
lemmas and affixes). Machine-readable dic-
tionaries. Morphological description.  
2. Second phase: Basic tools and applications. 
Statistical tools for the treatment of corpora. 
Morphological analyzer/generator. Lemma-
tizer/tagger. Spelling checker and corrector (al-
though in morphologically simple languages a 
word list could be enough). Speech processing 
at word level. Corpus II (word-forms are 
tagged with their part of speech and lemma). 
Lexical database II (lexical support for the con-
struction of general applications, including part 
of speech and morphological information). 
3. Third phase: Advanced tools and applications. 
An environment for tool integration. Web 
search engine.  A traditional search machine 
that integrates lemmatization and language 
identification. Surface syntax. Corpus III (syn-
tactically tagged text). Grammar and style 
checkers. Structured versions of dictionaries 
(they allow enhanced functionality not avail-
able for printed or raw electronic versions). 
Lexical database III (the previous version is en-
riched with multiword lexical units. Integration 
of dictionaries in text editors). Lexical-
semantic knowledge base. Creation of a con-
cept taxonomy (e.g.: Wordnet). Word-sense 
disambiguation. Speech processing at sentence 
level. Basic Computer Aided Language Learn-
ing (CALL) systems 
4. Fourth phase: Multilingualism and general 
applications. Information extraction. Transla-
tion aids (integrated use of multiple on-line 
dictionaries, translation of noun phrases and 
simple sentences). Corpus IV (semantically 
tagged text after word-sense disambiguation). 
Dialog systems. Knowledge base on multilin-
gual lexico-semantic relations and its applica-
tions.  
We will complete this strategy with some sug-
gestions about what shouldn?t be done when work-
ing on the treatment of minority languages. a) Do 
not start developing applications if linguistic foun-
dations are not defined previously; we recommend 
following the above given sequence: foundations, 
tools and applications. b) When a new system has 
to be planned, do not create ad hoc lexical or syn-
tactic resources; you should design those resources 
in a way that they could be easily extended to full 
coverage and reusable by any other tool or applica-
tion. c) If you complete a new resource or tool, do 
not keep it to yourself; there are many researchers 
working on English, but only a few on each minor-
ity language; thus, the few results should be public 
and shared for research purposes, for it is desirable 
to avoid needless and costly repetition of work. 
3 Machine Translation for Basque 
After years working on basic resources and tools 
we decided it was time to face  the MT task (Hut-
chins and Somers, 1992). Our general strategy was 
more specifically for Machine Translation defined 
bearing in mind the following concepts:  
? reusability of previous resources, specially 
lexical resources and morphology of Basque 
? standardization and collaboration: using a 
more general framework in collaboration 
with other groups working in NLP 
? open-source: this means that anyone having 
the necessary computational and linguistic 
skills will be able to adapt or enhance it to 
produce a new MT system,  
Due to the real necessity for translation in our 
environment the involved languages would be 
Basque, Spanish and English. 
From the beginning we wanted to combine the 
two basic approaches for MT (rule-based and cor-
pus-based) in order to build a hybrid system, be-
cause it is generally agreed that there are not 
enough corpora for a good corpus-based system in 
minority languages like Basque.  
Data-driven Machine Translation (example-
based or statistical) is nowadays the most prevalent 
trend in Machine Translation research. Translation 
results obtained with this approach have already 
reached a high level of accuracy, especially when 
the target language is English. But these Data-
driven MT systems base their knowledge on 
aligned bilingual corpora, and the accuracy of their 
61
output depends heavily on the quality and the size 
of these corpora. Large and reliable bilingual cor-
pora are unavailable for many language pairs. 
3.1 The rule-based approach 
First, we present the main architecture and the pro-
posed standards of an open source MT engine, the 
first implementation of which translates from 
Spanish into Basque using the traditional transfer 
model and based on shallow and dependency pars-
ing. 
The design and the programs are independent 
from the languages, so the software can be used for 
other projects in MT. Depending on the languages 
included in the adaptation, it will be necessary to 
add, reorder and change some modules, but this 
will not be difficult because a unique XML format 
is used for the communication among all the mod-
ules. 
The project has been integrated in the OpenTrad 
initiative (www.opentrad.com), a government-
funded project shared among different universities 
and small companies, which also include MT en-
gines for translation among the main languages in 
Spain. The main objective of this initiative is the 
construction of an open, reusable and interoperable 
framework. 
In the OpenTrad project, two different but coor-
dinated designs have been carried out: 
? A shallow-transfer machine translation en-
gine for similar languages (Spanish, Catalan 
and Galician by the the time being). The 
MT architecture uses finite-state transducers 
for lexical processing, hidden Markov mod-
els for part-of-speech tagging, and chunking 
based on finite-state for structural transfer. 
It is named Apertium and it can be 
downloaded from apertium.sourceforge.net. 
(Armentano-Oller et al, 2004) 
? A deeper-transfer engine for the Spanish-
Basque pair. It is named Matxin (Alegria et 
al., 2007) and it is stored in 
matxin.sourceforge.net. It is an extension of 
previous work in our group. In order to re-
use resources in this Spanish-Basque system 
the analysis module for similar languages 
was not included in Matxin; another open 
source engine, FreeLing (Carreras et al, 
2004), was used here, of course, and its out-
put had to be converted to the proposed in-
terchange format. 
Some of the components (modules, data formats 
and compilers) from the first architecture in Open-
Trad were used in the second one. Indeed, an im-
portant additional goal of this work was testing 
which modules from the first architecture could be 
integrated in deeper-transfer architectures for more 
difficult language pairs. 
The transfer module is also based on three main 
objects in the translation process: words or nodes, 
chunks or phrases, and sentences.  
? First, lexical transfer is carried out using a 
bilingual dictionary compiled into a finite-
state transducer. We use the XML specifica-
tion of Apertium engine.  
? Then, structural transfer at the sentence 
level is applied, and some information is 
transferred from some chunks to others, and 
some chunks may disappear. Grammars 
based on regular expressions are used to 
specify these changes. For example, in the 
Spanish-Basque transfer, the person and 
number information of the object and the 
type of subordination are imported from 
other chunks to the chunk corresponding to 
the verb chain. 
? Finally the structural transfer at the chunk 
level is carried out. This process can be 
quite simple (e.g. noun chains between 
Spanish and Basque) or more complex (e.g. 
verb chains between these same languages). 
The XML file coming from the transfer module 
is passed on the generation module. 
? In the first step, syntactic generation is per-
formed in order to decide the order of 
chunks in the sentence and the order of 
words in the chunks. Several grammars are 
used for this purpose.  
? Morphological generation is carried out in 
the last step. In the generation of Basque, 
the main inflection is added to the last word 
in the phrase (in Basque: the declension 
case, the article and other features are added 
to the whole noun phrase at the end of the 
last word), but in verb chains other words 
need morphological generation. A previous 
morphological analyzer/generator for 
Basque (Alegria et al, 1996) has been 
adapted and transformed to the format used 
in Apertium. 
The results for the Spanish/Basque system using 
FreeLing and Matxin are promising. The quantita-
62
tive evaluation uses the open source evaluation 
tool IQMT and figures are given using Bleu and 
NIST measures (Gim?nez et al, 2005). An user 
based evaluation has been carried out too. 
3.2 The corpus-based approach 
The corpus-based approach has been carried out in 
collaboration with the National Center for Lan-
guage Technology in Dublin.  
The system exploits both EBMT and SMT tech-
niques to extract a dataset of aligned chunks. We 
conducted Basque to English and Spanish to 
Basque translation experiments, evaluated on a 
large corpus (270, 000 sentence pairs).  
Some tools have been reused for this purpose: 
? GIZA++: for word/morpheme alignment we 
used the GIZA++ statistical word alignment 
toolkit, and following the ?refined? method 
of (Och and Ney, 2003), extracted a set of 
high-quality word/ morpheme alignments 
from the original unidirectional alignment 
sets. These along with the extracted chunk 
alignments were passed to the translation 
decoder.                                         
? Pharaoh/Moses decoder: the decoder is also 
a hybrid system which integrates EBMT 
and SMT. It is capable of retrieving already 
translated sentences and also provides a 
wrapper around the PHARAOH SMT de-
coder (Koehn, 2004). 
? MaTrEx: the MATREX (Machine Transla-
tion using Examples) system used in our 
experiments is a data-driven MT engine, 
built following an extremely modular de-
sign. It consists of a number of extensible 
and re-implementable modules (Way and 
Gough, 2005). 
   For this engine, we reuse a toolkit to chunk the 
Basque sentences. After this processing stage, a 
sentence is treated as a sequence of morphemes, in 
which chunk boundaries are clearly visible. Mor-
phemes denoting morphosyntactic features are re-
placed by conventional symbolic strings. After 
some adaptation, the chunks obtained in this man-
ner are actually very comparable to the English 
chunks obtained with the marker-based chunker. 
The experimental results have shown that our 
system significantly outperforms state-of-the-art 
approaches according to several common auto-
matic evaluation metrics: WER, Bleu and PER 
(Stroppa et al, 2006; Labaka et al, 2007). 
4 Conclusions 
A language that seeks to survive in the modern 
information society requires language technology 
products. "Minority" languages have to do a great 
effort to face this challenge. The Ixa group has 
been working since 1986 on adapting Basque to 
language technology, having developed several 
applications that are effective tools to promote the 
use of Basque. Now we are planning to define the 
BLARK for Basque (Krauwer, 2003).  
From our experience, we defend that research 
and development for a minority language should to 
be faced following these points: high standardiza-
tion,  reusing language foundations, tools, and ap-
plications, and their incremental design and devel-
opment. We know that any HLT project related to 
a less privileged language should follow those 
guidelines, but from our experience we know that 
in most cases they do not. We think that if Basque 
is now in an good position in HLT is because those 
guidelines have been applied even  when it was 
easier to define "toy" resources and tools useful to 
get good short term academic results, but not reus-
able in future developments.  
This strategy has been completely useful when 
we have created MT systems for Basque. Reusing 
previous works for Basque (that were defined fol-
lowing XML and TEI standards) and reusing other 
open-source tools have been the key to get satisfac-
tory results in a short time.  
Two results produced in the MT track are pub-
licly available:  
? matxin.sourceforge.net for the free code for 
the Spanish-Basque RBMT system 
? www.opentrad.org for the on-line demo  
Acknowledgments 
This work has been partially funded by the Spanish 
Ministry of Education and Science (OpenMT: 
Open Source Machine Translation using hybrid 
methods,TIN2006-15307-C03-01) and the Local 
Government of the Basque Country (AnHITZ 
2006: Language Technologies for Multingual In-
teraction in Intelligent Environments., IE06-185). 
Andy Way, Declan Groves and Nicolas Stroppa 
from National Centre for Language Technology in 
Dublin are kindly acknowledged for providing 
their expertise on the Matrex system and the 
evaluation of the output. 
63
References 
I. Aduriz, E. Agirre, I. Aldezabal, I. Alegria, O. Ansa, 
X. Arregi, J. Arriola, X. Artola, A. D?az de Ilarraza, 
N. Ezeiza, K.Gojenola, M. Maritxalar, M. Oronoz, K. 
Sarasola, A. Soroa, R. Urizar. 1998. A framework for 
the automatic processing of Basque. Proceedings of 
Workshop on Lexical Resources for Minority Lan-
guages.  
I. Alegria, X. Artola, K. Sarasola. 1996.Automatic mor-
phological analysis of Basque. Literary & Linguistic 
Computing Vol. 11, No. 4, 193-203. Oxford Univer-
sity Press. Oxford. 1996. 
I. Alegria, A. D?az de Ilarraza, G. Labaka, M Lersundi, 
A. Mayor, K. Sarasola.  2007. Transfer-based MT 
from Spanish into Basque: reusability, standardiza-
tion and open source. LNCS 4394. 374-384. Cicling 
2007.  
E. Amorrortu. 2002. Bilingual Education in the Basque 
Country: Achievements and Challenges after Four 
Decades of Acquisition Planning. Journal of Iberian 
and Latin American Literary and Cultural Stud-
ies.Volume 2 Number 2 (2002) 
C. Armentano-Oller, A. Corb?-Bellot, M. L. Forcada, 
M. Ginest?-Rosell, B. Bonev, S. Ortiz-Rojas, J. A. 
P?rez-Ortiz, G. Ram?rez-S?nchez, F. S?nchez-
Mart?nez, 2005. An open-source shallow-transfer 
machine translation toolbox: consequences of its re-
lease and availability. Proceedings of OSMaTran: 
Open-Source Machine Translation workshop, MT 
Summit X. 
X. Artola, A. D?az de Ilarraza, N. Ezeiza, K. Gojenola, 
G. Labaka, A. Sologaistoa, A. Soroa.  2005. A 
framework for representing and managing linguistic 
annotations based on typed feature structures. Proc. 
of RANLP 2005. 
X. Carreras,, I. Chao, L. Padr? and M. Padr?. 2004. 
FreeLing: An open source Suite of Language Ana-
lyzers, in  Proceedings of the 4th International Con-
ference on Language Resources and Evaluation 
(LREC'04).  
J. Gim?nez, E. Amig?, C. Hori. 2005. Machine 
Translation Evaluation Inside QARLA. In Proceed-
ings of the International Workshop on Spoken Lan-
guage Technology (IWSLT'05) 
W. Hutchins and H. Somers. 1992. An Introduction to 
Machine Translation. Academic Press. 
P. Koehn. 2004. Pharaoh: A Beam Search Decoder for 
Phrase-Based Statistical Machine Translation Mod-
els.  In Proceedings of AMTA-04, pages 115?124, 
Washington, District of Columbia. 
S. Krauwer. 2003. The Basic Language Resource Kit 
(BLARK) as the First Milestone for the Language 
Resources Roadmap. Proc. of the International 
Workshop  Speech and Computer. Moscow, Russia. 
G. Labaka, N. Stroppa, A. Way, K. Sarasola  2007 
Comparing Rule-Based and Data-Driven Approaches 
to Spanish-to-Basque Machine Translation Proc. of 
MT-Summit XI, Copenhagen 
F. Och and H. Ney. 2003. A Systematic Comparison of 
Various Statistical Alignment Models. Computa-
tional Linguistics, 29(1): 19?51. 
B. Petek. 2000. Funding for research into human lan-
guage technologies for less prevalent languages, Sec-
ond International Conference on Language Re-
sources and Evaluation (LREC 2000). Athens, 
Greece. 
N. Stroppa, D. Groves, A. Way, K. Sarasola K. 2006. 
Example-Based Machine Translation of the Basque 
Language. AMTA. 7th conference of the Association 
for Machine Translation in the Americas.. 
A. Way and N. Gough. 2005. Comparing Example-
Based and Statistical Machine Translation. Natural 
Language Engineering, 11(3):295?309. 
B. Williams, K. Sarasola, D. ??Cr?inin, B. Petek. 2001. 
Speech and Language Technology for Minority Lan-
guages. Proceedings of Eurospeech 2001 
 
 
64
Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 65?69,
Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational Linguistics
Developing an open-source FST grammar for verb chain transfer in a
Spanish-Basque MT System
Aingeru Mayor, Mans Hulden, Gorka Labaka
Ixa Group
University of the Basque Country
aingeru@ehu.es, mhulden@email.arizona.edu, gorka.labaka@ehu.es
Abstract
This paper presents the current status of de-
velopment of a finite state transducer gram-
mar for the verbal-chain transfer module in
Matxin, a Rule Based Machine Translation
system between Spanish and Basque. Due to
the distance between Spanish and Basque, the
verbal-chain transfer is a very complex mod-
ule in the overall system. The grammar is
compiled with foma, an open-source finite-
state toolkit, and yields a translation execution
time of 2000 verb chains/second.
1 Introduction
This paper presents the current status of develop-
ment of an FST (Finite State Transducer) grammar
we have developed for Matxin, a Machine Transla-
tion system between Spanish and Basque.
Basque is a minority language isolate, and it is
likely that an early form of this language was already
present in Western Europe before the arrival of the
Indo-European languages.
Basque is a highly inflected language with free
order of sentence constituents. It is an agglutinative
language, with a rich flexional morphology.
Basque is also a so-called ergative-absolutive lan-
guage where the subjects of intransitive verbs ap-
pear in the absolutive case (which is unmarked),
and where the same case is used for the direct ob-
ject of a transitive verb. The subject of the transi-
tive verb (that is, the agent) is marked differently,
with the ergative case (in Basque by the suffix -k).
The presence of this morpheme also triggers main
and auxiliary verbal agreement. Auxiliary verbs, or
?periphrastic? verbs, which accompany most main
verbs, agree not only with the subject, but also with
the direct object and the indirect object, if present.
Among European languages, this polypersonal sys-
tem (multiple verb agreement) is rare, and found
only in Basque, some Caucasian languages, and
Hungarian.
The fact that Basque is both a morphologically
rich and less-resourced language makes the use of
statistical approaches for Machine Translation dif-
ficult and raises the need to develop a rule-based
architecture which in the future could be combined
with statistical techniques.
The Matxin es-eu (Spanish-Basque) MT engine
is a classic transfer-based system comprising three
main modules: analysis of the Spanish text (based
on FreeLing, (Atserias et al, 2006)), transfer, and
generation of the Basque target text.
In the transfer process, lexical transfer is first
carried out using a bilingual dictionary coded in
the XML format of Apertium dictionary files (.dix)
(Forcada et al, 2009), and compiled, using the FST
library implemented in the Apertium project (the lt-
toolbox library), into a finite-state transducer that
can be processed very quickly.
Following this, structural transfer at the sentence
level is performed, and some information is trans-
ferred from some chunks1 to others while some
chunks may be deleted. Finally, the structural trans-
1A chunk is a non-recursive phrase (noun phrase, preposi-
tional phrase, verbal chain, etc.) which expresses a constituent
(Abney, 1991; Civit, 2003). In our system, chunks play a cru-
cial part in simplifying the translation process, due to the fact
that each module works only at a single level, either inside or
between chunks.
65
fer at the verb chunk level is carried out. The verbal
chunk transfer is a very complex module because of
the nature of Spanish and Basque auxiliary verb con-
structions, and is the main subject of this paper.
This verb chain transfer module is implemented
as a series of ordered replacement rules (Beesley and
Karttunen, 2003) using the foma finite-state toolkit
(Hulden, 2009). In total, the system consists of 166
separate replacement rules that together perform the
verb chunk translation. In practice, the input is given
to the first transducer, after which its output is passed
to the second, and so forth, in a cascade. Each rule in
the system is unambiguous in its output; that is, for
each input in a particular step along the verb chain
transfer, the transducers never produce multiple out-
puts (i.e. the transducers in question are functional).
Some of the rules are joined together with composi-
tion, yielding a total of 55 separate transducers. In
principle, all the rules could be composed together
into one monolithic transducer, but in practice the
size of the composed transducer is too large to be
feasible. The choice to combine some transduc-
ers while leaving others separate is largely a mem-
ory/translation speed tradeoff.
2 Spanish and Basque verb features and
their translation
In the following, we will illustrate some of the main
issues in translating Spanish verb chains to Basque.
Since both languages make frequent use of auxiliary
verb constructions, and since periphrastic verb con-
structions are frequent in Basque, transfer rules can
get quite complex in their design.
For example, in translating the phrase
(Yo) compro (una manzana)
(I) buy (an apple)
[PP1CSN00] [VMIP1S0] [DI0FS0] [NCFS000]
we can translate it using the imperfective partici-
ple form (erosten) of the verb erosi (to buy), and a
transitive auxiliary (dut) which itself contains both
subject agreement information (I: 1st sg.) and num-
ber agreement with the object (an apple: 3rd sg.):
(nik) (sagar bat) erosten dut. The participle carries
information concerning meaning, aspect and tense,
whereas the auxiliaries convey information about ar-
gument structure, tense and mood.
Table 1 illustrates the central idea of the verb
chunk transfer. In the first four examples the form of
the transitive auxiliary changes to express agreement
with different ergative arguments (the subject of the
clause), absolutive arguments (the direct object) and
dative arguments (the indirect object). In the fifth
example the future participle is used. The last ex-
ample shows the translation of a periphrastic con-
struction, in which the the Spanish and the Basque
word orders are completely different: this is re-
flected in the Spanish tengo que-construction (have
to) which appears before the main verb, whereas in
the Basque, the equivalent (behar) appears after the
main verb (erosi).
3 The FST grammar
We carry out the verbal chunk transfer using finite-
state transducers (Alegria et al, 2005). The gram-
mar rules take as input the Spanish verbal chunk,
perform a number of transformations on the input,
and then create and output the verbal chunk for
Basque.
To illustrate the functioning of the grammar, let us
consider the following example sentence in Spanish:
?Un tribunal ha negado los derechos constitu-
cionales a los presos polticos? (A court has denied
constitutional rights to political prisoners). The cor-
rect translation into Basque given by the system for
this example is as follows: Auzitegi batek eskubide
konstituzionalak ukatu dizkie preso politikoei. Fig-
ure 1 shows a detailed overview of how the whole
transfer of the verbal chunk is performed for this par-
ticular example.
First, the input to the grammar is assumed to be a
string containing (separated by the ?&? symbol) the
following information :
? the morphological information (using
EAGLES-style tags Leech and Wilson
(1996)) for all nodes (separated by ?+?
symbol) in the Spanish verbal chunk
(haber[VAIP3S0]+negar[VMP00SM]);
? the morphological information of the subject
([sub3s]), the direct object ([obj3p]) and the
indirect object ([iobj3p]);
? the translation of the main verb in Basque
(ukatu) and information about its transitivity
66
Spanish sentence English Basque translation
(Yo) compro (una manzana) (I) buy (an apple) (Nik) (sagar bat) erosten dut
(Yo) compro (manzanas) (I) buy (apples) (Nik) (sagarrak) erosten ditut
(Tu?) compras (manzanas) (You) buy (apples) (Zuk) (sagarrak) erosten dituzu
(Yo) (te) compro (una manzana) (I) buy (you) (an apple) (Nik) (zuri) (sagar bat) erosten dizut
(Yo) comprare? (una manzana) (I) will buy (an apple) (Nik) (sagar bat) erosiko dut
(Yo) tengo que comprar (manzanas) (I) must buy (apples) (Nik) (sagarrak) erosi behar ditut
Table 1: Examples of translations
  
Un    tribunal     ha negado    los    derechos    constitucionales         a   los    presos    pol?ticosA     court     has denied     (the)   rights           constitutional            to (the)   prisoners  political
uka  +tu              d     +i      +zki   +e    +?
 Subject                Verb                                     Object                                                      Indirect                                                                                                                                           Object
haber[VAIP3S0]+negar[VMP00SM]   &   [sub3s] [obj3p] [iobj3p]   &   ukatu [DIO] 
haber[VAIP3S0]+negar[VMP00SM]  &  [sub3s] [obj3p] [iobj3p]  & ukatu [DIO]SimpleVerb   (main) AspectMain  /  Aux TenseMood Abs Dat Erg
1. Identification      of the schema [ SimpleVerbEsType  -> ...  SimpleVerbEuSchema ]
niega[VMIP3S0]   &   [sub3s] [obj3s] [dat3p]   &  ukatu [DIO] + SimpleVerb   (main)[perfPart]  /  edun(aux) [indPres] [abs3p][dat3p][erg3s]
2. Resolution      of the values Attrib.               ->  Value             || Context                             AspectMain  -> [perfPart]  || ?* VAIP ?* SimpleVerb ?* _Aux  -> edun(aux) || ?* DIO ?* _TenseMood  -> [indPres] || ?* VAIP ?* _Abs  -> [abs3p] || ?* [obj3p] ?* edun(aux) ?* _Dat  -> [dat3p] || ?* [iobj3p] ?* _Erg  -> [erg3s] || ?* V???3S ?* edun(aux) ?* _
3. Elimination of     source information 
ukatu(main)[perfPart]   /  edun(aux) [indPres] [abs3p][dat3p][erg3s]
Input
Output
deny     perf.             ind.    trans.   3rdpl     3rdpl    3rdsg             part.            pres.  aux.   abs.     dat.    erg.           
Figure 1: Example of the transfer of a verbal chunk.
67
([DIO]), indicating a ditransitive construction:
haber[VAIP3S0]+negar[VMP00SM] &
[sub3s][obj3p][iobj3p] & ukatu[DIO]
The grammatical rules are organized into three
groups according to the three main steps defined for
translating verbal chunks:
1. Identification of the Basque verbal chunk
schema corresponding to the source verbal
chunk.
There are twelve rules which perform this task,
each of which corresponds to one of the follow-
ing verbal chunks in Spanish: non-conjugated
verbs, simple non-periphrastic verbs as well
as four different groups reserved for the pe-
riphrastic verbs.
The verbal chunk of the example in figure 1 is
a simple non-periphrastic one, and the rule that
handles this particular case is as follows:
[simpleVerbEsType -> ...
simpleVerbEuSchema]
When this rule matches the input string
representing a simple non-periphrastic ver-
bal chunk (simpleVerbEsType) it adds the
corresponding Basque verbal chunk schema
(simpleVerbEuSchema) to the end of the input
string. simpleVerbEsType is a complex au-
tomaton that has the definition of the Spanish
simple verbs. simpleVerbEuSchema is the type
of the verbal chunk (SimpleVerb) and an au-
tomaton that contains as strings the pattern of
elements (separated by the ?/? symbol) that the
corresponding Basque verb chunk will need to
have (in this case, the main verb and the auxil-
iary verb):
SimpleVerb (main) AspectMain /
Aux TenseMood Abs Dat Erg
2. Resolution of the values for the attributes in the
Basque schema.
A total of 150 replacement rules of this type
have been written in the grammar. Here are
some rules that apply to the above example:
[AspectMain -> [perfPart] || ?* VAIP
?* SimpleVerb ?* ]
[Aux -> edun(aux) || ?* DIO ?* ]
[Abs -> [abs3p] || ?* [obj3p] ?*
edun(aux) ?* ]
3. Elimination of source-language information (4
rules in total).
The output of the grammar for the example is:
ukatu(main)[perfPart] /
edun(aux)[indPres][abs3p][dat3p][erg3s]
The first node has the main verb (ukatu) with
the perfective participle aspect, and the sec-
ond one contains the auxiliary verb (edun) with
all its morphological information: indicative
present and argument structure.
In the output string, each of the elements contains
the information needed by the subsequent syntactic
generation and morphological generation phases.
4 Implementation
When the verbal chunk transfer module was first de-
veloped, there did not exist any efficient open-source
tools for the construction of finite state transduc-
ers. At the time, the XFST-toolkit (Beesley and
Karttunen, 2003) was used to produce the earlier
versions of the module: this included 25 separate
transducers of moderate size, occupying 2,795 kB
in total. The execution speed was roughly 250 verb
chains per second. Since Matxin was designed to be
open source, we built a simple compiler that con-
verted the XFST rules into regular expressions that
could then be applied without FST technology, at the
cost of execution speed. This verbal chunk transfer
module read and applied these regular expressions
at a speed of 50 verbal chunks per second.
In the work presented here, we have reimple-
mented and expanded the original rules written for
XFST with the foma2 toolkit (Hulden, 2009). Af-
ter adapting the grammar and compiling it, the 55
separate transducers occupy 607 kB and operate at
roughly 2,000 complete verb chains per second.3
Passing the strings from one transducer to the next in
the chain of 55 transducers in accomplished by the
depth-first-search transducer chaining functionality
available in the foma API.
2http://foma.sourceforge.net
3On a 2.8MHz Intel Core 2 Duo.
68
References
Abney, S. (1991). Principle-Based Parsing: Com-
putation and Psycholinguistics, chapter Parsing
by Chunks, pages 257?278. Kluwer Academic,
Boston.
Alegria, I., D??az de Ilarraza, A., Labaka, G., Ler-
sundi, M., Mayor, A., and Sarasola, K. (2005).
An FST grammar for verb chain transfer in a
Spanish?Basque MT system. In Finite-State
Methods and Natural Language Processing, vol-
ume 4002, pages 295?296, Germany. Springer
Verlag.
Atserias, J., Casas, B., Comelles, E., Gonza?lez, M.,
Padro?, L., and Padro?, M. (2006). Freeling 1.3:
Syntactic and semantic services in an open-source
NLP library. In Proceedings of LREC, volume 6,
pages 48?55.
Beesley, K. R. and Karttunen, L. (2003). Finite State
Morphology. CSLI Publications, Stanford, CA.
Civit, M. (2003). Criterios de etiquetacio?n y desam-
biguacio?n morfosinta?ctica de corpus en Espan?ol.
PhD thesis, Universidad de Barcelona.
Forcada, M., Bonev, B. I., Ortiz-Rojas, S.,
Pe?rez-Ortiz, J. A., Ram??rez-Sanchez, G.,
Sa?nchez-Mart??nez, F., Armentano-Oller, C.,
Montava, M. A., Tyers, F. M., and Ginest??-
Rosell, M. (2009). Documentation of the
open-source shallow-transfer machine trans-
lation platform Apertium. Technical report,
Departament de Llenguatges i Sistemes In-
formatics. Universitat d?Alacant. Available
at http://xixona.dlsi.ua.es/ fran/apertium2-
documentation.pdf.
Hulden, M. (2009). Foma: a finite-state compiler
and library. In Proceedings of EACL 2009, pages
29?32.
Leech, G. and Wilson, A. (1996). EAGLES rec-
ommendations for the morphosyntactic annota-
tion of corpora. Technical report, EAGLES Expert
Advisory Group on Language Engineering Stan-
dards, Istituto di Linguistica Computazionale,
Pisa, Italy.
69
